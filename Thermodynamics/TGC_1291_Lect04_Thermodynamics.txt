In the last lecture, we talked about the most basic thermodynamic concept of all, namely
temperature. Since the thermal part of thermodynamics means heat, you can imagine how important
our understanding of temperature is for this course. It serves as the foundational concept
to measure and compare how hot or cold our particular object gets. But to complete the
title of our subject, we need to lay the foundation for the dynamics part of thermodynamics.
That is a framework for understanding how heat changes and flows from one object to
another and from one form of energy to another. In this lecture, we are going to explore the
other basic concepts that are critical to thermodynamics and that will serve as a kind
of language for the rest of this course. For many of these, many of these involve some
simple but crucial definitions and terms, while other concepts will involve a bit of
discussion. One that falls into this latter category is entropy, which I am very excited
to introduce to you today, but I don't want to get ahead of myself.
So first of all, we need to define the different types of systems that are possible in thermodynamics.
There are four important kinds I will discuss, but before I do that, perhaps I should clarify
what I even mean by the word system itself. The definition of a system is a group of materials
or particles or simply a space of interest with definable boundaries that exhibit thermodynamic
properties. Okay, so the key word there is boundary and that's really what I want to
distinguish here. More specifically, the four different systems that are possible in thermodynamics
have unique boundary conditions that limit the exchange of energy or atoms and molecules
with their surroundings. First, an isolated system is one in which the boundaries do not
allow for passage of energy or particles or matter of any form. Think of this type of
system as one with the absolute ultimate walls around it, a barrier that permits nothing
at all, not even energy to pass through it. Second, we have a closed system. Here, the
boundaries do not allow for the passage of matter or mass of any kind. However, unlike
the isolated system in a closed system, the boundaries do allow for the passage of energy.
Third, there is an adiabatic system where the boundaries do not allow for the passage
of heat. Matter can flow through a boundary in this type of system, but only if it carries
no heat. The key here is that no heat can enter or leave this type of system. And last,
we have an open system, which is pretty much how it sounds. In this case, the boundaries
allow for the passage of energy and particles or any type of matter. Pretty much anything
can flow, both in and out of an open system. Now, don't worry about memorizing these definitions.
Or for that matter, all the rest of the definitions I'm going to set forth in this lecture. More
important than the actual words we use, I'll remind you of them as we continue to use them
throughout this course. I want you to start thinking about the basic concepts we're discussing.
In this case, the point is that when we solve for problems in thermodynamics, the first
thing we must do is define our system and how it interacts with the rest of the universe.
And now that we've defined types of systems, the next thing we need to define are the kinds
of processes that can occur in our systems. We've stated that thermodynamics is a theory
for predicting what changes will happen to a material or a system. A key part of making
correct predictions about a system is identifying what processes can happen within the system.
What is even possible? To do this, we have to first introduce the language for the different
types of processes. First, we have the same word, adiabatic, that I used for a type of
system. But in this case, I'm referring to an adiabatic process. Here, the meaning is
similar. This type of process is one in which no heat is transferred during the process.
Second, we have an isothermal process. In this case, the temperature during the process
remains a constant. Next, we have an isobaric process, for which, as you might have guessed,
the pressure remains constant. And then we have an isochoric process. In this case, the
volume remains constant during the process. And last, we can combine these types of processes
together. For example, an isobarothermal process is one in which both temperature and pressure
are held constant. This way of thinking about different thermodynamic processes is essential
since these are just the types of variables we know how to control when we manipulate
a material. Let's look at a few examples. Suppose I place
water in a pot to boil on the stove to make some pasta. As we know, it will boil faster
if I put a cover on the pot. In this case, the system is the saucepan with the water
in it. So it's a closed system since at the boundaries, including the lid, make it so
that no matter can pass in or out. Note, though, that although mass does not pass through the
boundary of my system, heat can and does pass through the metal boundary and into the water.
As for the types of processes that can occur, it depends on the water temperature. If the
water is in the process of getting hot, then we would define the type of process that occurs
as isobaric and isochoric, since both the pressure and volume are constant. On the other
hand, if the water is already boiling, then it's also isothermal since the temperature
of my system, the pot and the water, is constant. Note that once the water boils, little bits
of matter in the form of steam will leak out of the top, so technically it's no longer
a closed system. If I were to seal the lid, then it stays a closed system, but now the
process is no longer isobaric, at least at first, since the pressure of steam will build
up inside. Let's consider another example. What if my system is simply a nice cold glass
of water that I set out on the porch on a warm sunny day? In this case, what type of
system do we have? Well, the open glass container allows pretty much anything to pass. Heat
mass, you name it. So the system here is open. And what about the types of processes that
can occur? The temperature is not held constant, since the water is cold, but in a warm environment.
The volume could change if it wanted to, since the top of the glass is open. But one thing
that will remain fixed here is the pressure. With the open top of our glass, the water
is going to be at a constant pressure, set by the pressure of the environment. That would
be one atmosphere. So the processes that will occur in this case, we can categorize as isobaric
processes. And finally, if I poured the glass of water into a perfect thermos, instead of
an open glass, we'd have only adiabatic processes that can occur in my system, which would become
an isolated system since both matter and energy can no longer pass across the boundaries of
the thermos. So those are systems and types of processes in which thermodynamic variables
can either change or be held constant. But what about the classification of the variables
themselves, like temperature, pressure, and volume? The broadest kind of classification
is whether a variable is intensive or extensive. And the definitions are quite simple. An intensive
variable is one whose magnitude does not vary with the size of the system, but can vary
from point to point in space. Let's use a box to illustrate. Suppose this box is at
some pressure and temperature, designated by the variables P and T. Now suppose I have
two such boxes at the same values of P and T. I bring them together. Once I merge them,
I have a box that is twice as big. But the values for P and T did not change. They're
simply the original values of each box separately. Thus, pressure and temperature are intensive
variables. The other kind of variable is called extensive. In this case, the magnitude of
the variable varies linearly with the size of the system. So if we go back to those two
boxes and consider the volume of each box, then you can see quite easily that when I
bring the two boxes together, the volume doubles. This means that volume is an extensive variable.
As we'll see later, intensive and extensive variables can form coupled pairs, that when
multiplied together, give a form of thermodynamic work, which means a kind of energy. Pressure
and volume are one example of such a pair, which we'll dive into in some detail in the
next lecture. Now let's move on to two other very important definitions in thermodynamics.
First, we need to define the meaning of the state of the system. And second, we'll discuss
what it means for a system to be in something called equilibrium. The state of a system is
a unique set of values for the variables that describe a material on the macroscopic level.
Remember our discussion in the second lecture regarding the difference between a microscopic
and a macroscopic picture? A macroscopic variable means something you can measure related to
the whole entire system. Examples of macroscopic variables are pressure, temperature, volume,
and the amount of a material. And all of these variables are also called state variables.
It doesn't matter if the variable is intensive or extensive for it to be considered a state
variable. What does matter is whether the variable depends on how it got there. Allow
me to explain. The molecules and materials heat up, react, rearrange, change shape,
form and break bonds with one another, and undergo myriad other changes in response to
changes in their environment. Remember that we do not keep track of those changes at the
molecular scale in classical thermodynamics. Rather, we keep track of the changes in macroscopic
properties that occur due to these internal molecular interactions. These are the changes
in the state of the material. Now, for a variable to be a state variable, it must not depend
on the sequence of changes it went through to get to where it is. So, I can take a system
in some state, let's call it state A, and I can apply some kind of thermodynamic force
to the system in this state, like pressure or temperature, and the system will go into
some new state, call it state B. The state variables for the initial and final states
do not depend in any way on the intermediate steps or the path taken to get from A to B,
only on the initial and final values of the variables of the system. By the way, if this
is a little confusing, since it's the first time you're hearing such a thing, don't worry.
The concept of state variables and state functions is so important in thermodynamics that we're
going to devote our entire next lecture to them. For now, let's keep going with some
more definitions. Here's another really important aspect of thermodynamics we need to know,
and it's related to our definition of state and also gets us to our next important concept.
That is, thermodynamics only makes predictions for equilibrium states. Thermodynamics does
not make predictions for the manner in which a system changes from one state to another.
Rather, it takes the approach that eventually it will happen, and it is a science that tells
us what the system will be like once it does happen. So, in that example of a system going
from state A to state B, thermodynamics will let us predict, given the forces applied, what
state B is, but it will not predict what happens to the system along the way. For that, one
needs to study kinetics, which is a different topic that we might mention here and there,
but will not be the focus of this course. Okay, so I've used the word equilibrium now
a few times, and I've told you that thermodynamics tells us about the behavior of equilibrium
states. Let's look more closely at what this means. Equilibrium is a state from which a
material has no tendency to undergo a change, as long as external conditions remain unchanged.
That's one of those statements that's so important I'd like to repeat it. Equilibrium
is a state from which a material has no tendency to undergo a change, as long as external conditions
remain unchanged. Take a look at this simple plot of the energy of a system versus some
parameter. It could be any variable of the system, but let's just call it generically
x. The energy of the system can vary in different ways as a function of this variable, as shown
here. I'll use this to point out how this variation in energy can tell us something about
the equilibrium of a system. Now, the lower the energy of the system, the more stable
the system will be, and the higher the energy, the less stable. So in this graph, going down
means going to more stability, while going up is less stable. If our variable of interest
were position, and the energy represented by only gravitational potential energy, then
you could imagine this path as a roller coaster, and our discussion about a ball rolling around
on top of it. So you can imagine that at this point here, the system is in an unstable state.
That is, it is actively going to tend towards a new equilibrium state. On the other hand,
at this point in the energy landscape, the system is in what is called a metastable equilibrium
state. That is, the system can change to a lower total energy state, but it may stay
stable in this higher energy state as well. At this other point, the system is in an unstable
equilibrium state, which means that any perturbation or small change will cause the material to
change to a new equilibrium state. And finally, at least for this variable in energy landscape,
at this point for the variable X, the system is in a stable equilibrium state. The material
does not change its state in response to perturbations. In physics, you learn that stable mechanical
equilibrium is achieved when the potential energy is at its lowest level. The potential
energy is minimized when the ball rolls down to the bottom of the track. Or a roller coaster
car comes to the bottom of a hill. Similar principles will come into play in reaching
internal equilibrium in materials. We may look for the maximum or the minimum of a thermodynamic
function to identify equilibrium states. Now that we've talked about what the state
of a system is and what equilibrium means, I'd like to turn to two more extremely important
thermodynamic definitions, namely the internal energy of a system and entropy. Now, in freshman
physics, you learn that the total energy is equal to the sum of two terms. First, there's
the potential energy, which we usually write as P e, and which is related to how much energy
the system has to potentially be released. Gravity is a good example of this, since if
I lift up a block in the air, it has the potential to fall back down due to gravity. A spring
is another good example of potential energy, since if I stretch it out, now it has the
potential to spring back to its starting point. Second, there's the kinetic energy, which
is due to the motion of the system. But the thing is that here we must add to these two
energy terms a third one, namely the thermodynamic concept of internal energy, such that the
total energy is now a sum over all three of these individual energy terms, potential,
kinetic, and internal. The additional energy term represented by the internal energy is
of central importance. And what does it represent? Well, stated in words, the internal energy
of a system is a quantity that measures the capacity of the system to induce a change
that would not otherwise occur. As always, it's nice to ground such statements with a
concrete example. Take a look at this comparison between ice and water. Both are sitting on
a table, so their potential energy, at least the gravitational potential energy, will be
exactly the same, since they're at the same height off of the ground. And we could call
this potential energy zero at the table surface. And if the water is perfectly still, neither
the ice nor the water is moving, then they both also will have zero kinetic energy as
well. Without the concept of internal energy, you might then think that the ice and water
both have zero total energy. But this is not true. We certainly know intuitively that these
two forms or phases of the same material are very different from one another. For example,
one is a solid, and the other is a liquid. One is cold, and the other, well, not as cold.
It could even be hot. Internal energy in a material can be thought of as its stored
energy. But it's not the same kind of stored energy as in the potential energy. In this
case, we're talking about energy storage in the basic building blocks of the material
itself, namely the atoms. Energy is transferred to a material through all of the possible
forces that act upon it, pressures, thermal energy, chemical energy, magnetic energy,
and many others. And this internal energy is stored within the random thermal motions
of the molecules, their bonds, vibrations, rotations, and excitations. These are the
things that lead to the difference between the two states of our same material, water,
same material being water. And this is quantified by the concept of internal energy. The internal
energy of the ice is different than the internal energy of the liquid. And that is the only
energy term that captures the difference between these two phases. As we'll see, using the
laws of thermodynamics, we're going to be able to predict the phase of material for
any given set of thermodynamic state variables. And these predictions will lead to phase diagrams,
which are one of the holy grails of thermodynamics. It's like having GPS navigation for materials.
And now last, but certainly not least, let's turn to the one other concept I'd like to
introduce to you today, namely entropy. Entropy is a non-intuitive but absolutely critical
parameter of materials, along with the more common parameters like volume, pressure, temperature,
and number of molecules that I've already mentioned. This concept is different than these
other concepts because it's not as straightforward to grasp, at least at first. For example, when
I just discussed the concept of internal energy a minute ago, you may already have had a sense
of what it means, or at least could mean, since you may have already heard of the concept
of other forms of energy, like kinetic or gravitational potential energy. For entropy,
it's likely that we'll be blazing an entirely new trail. In fact, there has been quite a
bit of confusion over what entropy really is. And unfortunately, it gets misrepresented
or misunderstood often, even by the way, among scientists. Entropy has been used synonymously
with words like disorder, randomness, smoothness, dispersion, and homogeneity, to name only
a few. The great thermodynamicists Gibbs called it mixed-uppedness. And another brilliant
scientist famously said, nobody really knows what entropy is anyway. That was von Neumann.
But actually, we do know what entropy is. And today, we can measure it, calculate it,
and understand it. I'm going to be talking a lot about entropy throughout this course.
And we will introduce more rigorous thermodynamic definitions for entropy in the coming lectures.
We'll be using lots of examples as we go. But for now, I'd like to give you just the
first glimpse of what this critical thermodynamic variable is about in simple conceptual terms.
By the end of these lectures, I hope that you will have an intuitive grasp of entropy.
OK, so we just talked about how internal energy is a measure of the stored energy in a material.
And we gave an example of the difference between ice and water. Entropy can be thought of as
an index or a counter of the number of ways a material can store this type of energy.
Let's consider again that molecular view of water. Here's a snapshot of the water molecules
at one instant in time. You can see that the water has a number of degrees of freedom.
That means that each molecule can rotate, translate, vibrate, and bond to another molecule, and
so on. And at any instant in time, if I take a snapshot like this of the water molecules,
they would each have their given position, velocity, bonding, and so on. All of these
individual molecular details of each water molecule come together and give rise to a
macroscopically observed temperature, pressure, and volume. Now, you may already know this,
but a water molecule is pretty small, like only a few angstroms across. An angstrom is
a distance of only 1 over 10 to the 10th meters, so pretty small. So what that means is that
there are a whole lot of water molecules in just an ordinary cup of water, around 10 raised
to the 22nd power to be more precise. Now, here's the key point. If I measure, say, the
temperature of that cup of water, then the temperature I'm measuring is a collective
effect of those degrees of freedom of each water molecule, collected over a 10 with 22
zeroes number of molecules. Quite amazing when you think about it. As you can imagine,
with so many molecules and so many possible arrangements and degrees of freedom, more
than one snapshot could give the same temperature. In fact, if I hold the temperature of this
cup of water constant, then even though at this macro scale I see a constant value, all
the way down at the micro scale, the scale of the water molecule, things are in continuous
flux, and each water molecule is undergoing continuous changes in its position, velocity,
bonding, and so on. For a given set of state variables, like the temperature, pressure,
and volume of this cup of water, it is equally likely to be in any of the possible microstates
consistent with the macro state that gives that temperature, pressure, and volume. By
the way, I also just stated one version of the second law of thermodynamics, but I'm
getting a little ahead of myself here. So, what is entropy? It's directly related to
the number of those microstates that the system can have for a given macro state. Basically,
entropy is a measure of the number of degrees of freedom a system has. Sometimes people confuse
this with randomness, or things being somehow more spread out and smooth. And you may hear
people say that if something is more uniform or less ordered, then it must have more entropy,
but that's not quite right. As a counter example, take a look at these two pictures showing
simply a grid of points. These two pictures represent a situation where 169 squares have
been filled in a grid originally containing 1,225 empty spaces. So, which one do you think
has the higher entropy? The one on the left or the one on the right? Well, if you went
with the one on the right, you'd be going with the one that appears to be more random
or uniform. And in fact, that's the one that most people I've asked this question will
pick. But actually, it's the one on the left with the higher entropy, much higher in fact.
If you look carefully, you can see that in the grid on the right, no black squares are
next to one another. In fact, for this case, it was an explicit rule in the way the squares
were filled in. On the left, on the other hand, no rules were set forth. And so, you
see, some black squares right next to others. The rule that we used for placing the squares
on the right limits the number of ways the grid can be filled in. So, it has much fewer
degrees of freedom or possible microstates, if we think back to the water example. And
in this case, the state that is shown on the right therefore has a much lower entropy
than the one on the left. So, I've talked about internal energy and entropy as key thermodynamic
variables that describe the state of a system. I'll conclude this lecture with an example
that shows how they're connected in real life. Let's use a bowl of soup that needs some salt.
As you shake the salt into the soup, what's happening to those little crystals of salt
that come out of the container? If we want to have a nice, evenly salted soup, hopefully
they dissolve. So, I'm talking about dissolving salt in a liquid. What's that got to do with
entropy? Well, as it turns out, everything. Just as it is quite a common experience for
us to salt our soup, it is an equally common experience that once dissolved, the salt crystal
will never spontaneously reform. And here's what is actually strange about that. The bonding
energy between atoms in the salt crystal is really strong. In fact, the internal energy
of the salt crystal is much more favorable when it's a crystal as opposed to when those
salt atoms are dissolved in the liquid. From an energetic point of view, it really, really
wants to be a solid crystal, even when it's put into the soup. And yet, we all know from
experience that salt does not remain a crystal, but rather simply dissolves in our soup. So
what's going on? As you may have already guessed, it's all in the entropy, or number of degrees
of freedom in the salt. When the salt dissolves, it increases the entropy of the system. The
balance between internal energy and entropy is what determines the behavior of our salted
soup, and indeed, all real systems. Let's go back to those microstates of the water,
just to make sure we understand this example. You can see by looking at this picture that
if you count the number of possible ways the atoms can arrange to form a solid piece of
salt, or a crystal of salt, well, there's only one possible way the atoms can be arranged.
Now, if you look over here on the right, you can see that on a molecular level, once the
atoms are released from the crystal, their thermal energy will scramble them thoroughly
and randomly through the solution. And once the salt atoms are scrambled like this, there
are many, many ways in which they can be arranged. The number of degrees of freedom, meaning
the entropy of the system, has skyrocketed compared to the crystal. And it's that higher
entropy that drives the salt to dissolve in your soup. Make sure you point that out to
your friend next time you have soup together. Finding the balance between energy and entropy
is what defines equilibrium states. And the connection between energy, entropy, and those
equilibrium states, well, that connection is governed by the four thermodynamic laws.
