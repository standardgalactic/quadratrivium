Lecture 26, Simple Learning, Operant Conditioning
This is our second lecture in our three lecture sequence on simple learning and complex learning.
What we would like to do today is talk about operant conditioning.
You will recall last time that we talked about classical conditioning and went into
what is required for classical conditioning to take place.
What I would like for you to do today when we are talking about operant conditioning
is ask whether classical conditioning that we talked about last time and operant conditioning
from today can be used as building blocks for talking about more complex learning.
As we will see when I start talking about B.F. Skinner,
he thought that in fact you could take these basic building blocks
and try to explain all sorts of far more complex learning.
So I would like for you to think about that as I am going through operant conditioning today.
I will go over the basics of operant conditioning including shaping,
which is one way of getting operant conditioning more quickly.
We will talk about the time course of events as you are undergoing operant conditioning
and finally we will talk about various kinds of reinforcement schedules that can produce
operant conditioning. Operant conditioning is also sometimes called instrumental conditioning
and I think that may be a better term but it is certainly not the most widely used term.
So I will refer to it as operant conditioning.
And we referred to operant conditioning earlier in the course
when we were talking about behavior therapies based upon operant conditioning.
Operant conditioning is really a rather simple process.
You have a response that is made and that response is followed by a reinforcement
and that reinforcement makes the response more likely to recur.
Now it is a bit circular because if you ask then the definition of a reinforcement,
a reinforcement is anything that makes a response more likely to recur.
So it kind of defines itself and is not too informative.
Reinforcements can be all sorts of different kinds of things.
Primary reinforces such as food and water or secondary reinforces such as money
and other kinds of tokens. So that is the very simple process for operant conditioning
but fortunately there is more to it than that or I would not have much to talk about today.
Let me move on and talk for a minute about B.F. Skinner
because he is usually considered to be the father of operant conditioning.
B.F. is his initials, his actual name was Burris Frederick Skinner.
He lived from 1904 until 1990.
He is an American psychologist and as I say considered to be the father of operant conditioning.
And what is interesting about Skinner besides the fact he did an awful lot of science
and wrote many books on science is he also wrote several books of general interest to people
well beyond the science. For example he wrote a book called Walden II
based upon the original book Walden Pond and in Walden II he was talking about an idealistic
utopian society that is based entirely upon reinforcement principles.
And he was contending that you could build the whole society where everybody would be perfectly
happy because they were reinforced in ways that were important to them and so you could get somebody
to be as happy being a garbage collector as being a professor if the reinforcement were
appropriately structured for them. He wrote another book called Beyond Freedom and Dignity
which was even more controversial than that. Beyond Freedom and Dignity claimed that
we none of us are really free and that we choose the way we are and what our lives are like.
That in fact we're kind of dealt our lives based upon the reinforcements that we have as we're
growing up and as we go through our lives. And based upon those reinforcements we become the
people that we are and we behave the way that we do. And he contended that because we don't have
freedom to begin with it would be better if society took charge of the reinforcements rather
than having them happen sort of haphazardly as they do to us in our lives. So he was a great
believer in social engineering where society would get people to do things that were beneficial
to society by reinforcing them properly and that was quite a controversial kind of suggestion.
He was a bit of a Marxist himself and really believed that societies could be built and controlled
using reinforcements. But he also did a lot of science and that's mainly what we're going to
talk about today. The behavior with operant conditioning is usually a voluntary and usually
even a skeletal behavior that is reaching out to touch something, pushing a lever, speaking in a
certain way as opposed to the kind of behavior that we were talking about last time with classical
conditioning where we were generally talking about an involuntary behavior, one that's controlled
by the autonomic nervous system often a visceral behavior like producing saliva. So that's one
thing that usually distinguishes between operant conditioning and classical conditioning.
Now let me describe a sort of standard laboratory situation, the one that Skinner used a whole
lot. If you'll picture a box that has a plexiglass side on it so that you can see the animal that's
in there and in that box we'll put a white rat, a laboratory rat and this is usually called a
Skinner box although it's a bit of a misnomer. Skinner didn't like it called a Skinner box,
he wanted it to be called an operant conditioning chamber. He invented another box that he kept
his kids in and when they were growing up that was a highly environmentally controlled kind of box
and he preferred that it be called the Skinner box. One of my faculty members at my previous
university raised his kids in a Skinner box and they seemed to be no worse for the wear.
But at any rate this is an operant conditioning box that is sometimes called a Skinner box.
We put the rat in there at one end of the box on one of the walls is a lever, a little bar that
can be pressed and below the lever is a little trough and in this trough you can put food pellets.
So you have a little food pellet dispenser behind the box and a food pellet can be released and
rolled down into this trough and the rat can eat it. And what you are going to try to do with
operant conditioning is train the rat to go over and push the lever in order to get the
reinforcement in this case a food pellet. So that's the general principle involved here with the
operant conditioning chamber. Now one of the problems is that rats don't know how to do this
initially so you have to train the rat to do it and that this does not happen very rapidly.
So if you simply stick the rat in the box and have it turned on so that every time it presses the
lever it gets a food pellet the rat will not immediately rush over and do this. It might not
push the lever for a couple of days and experimenters are impatient so in fact they figured out that
the best way to do this is a process called shaping. With shaping what you do is reinforce
successive approximations to the response that you're looking for. So if we're going to shape
this rat we may have set up several criteria that are successively more stringent for the rat
and will reinforce once the rat meets this particular criterion. So the first criterion
might be it's got to be in the end of the box that has the lever on it. Obviously the rat
can't press the lever if he's in the wrong side of the box. So the rat starts wandering around the
box gets over into that half of the box and we hit the button to deliver a food pellet and the rat
goes over and eats the food pellet and then starts wandering around the box a little bit more gets
over to that side we give him another food pellet. We might do this five six seven times and then we
discover the rat's spending all of its time over in that end of the box. Now we say that's not good
enough we want him facing the wall that has the lever on it. So the rat wanders around a little
bit finally faces the wall give him a food pellet. Wanders around faces the wall give him a food
pellet and we do that five six seven times until the rat is now sitting in that side of the box
facing the wall. We say now that's not good enough either we want him to be within say an inch of
the lever when he's over there too. So every time he gets within an inch of the lever we give him
a food pellet and now he's spending all of his time near the lever but that's not good enough
either we want him up on his hind legs because he's got to use his front paws to push the lever
and you might think that's a real problem but rats get up on their hind legs all the time wash
their front paws and that sort of thing so he's sitting over there nothing's happening nothing's
he gets up on his hind on his hind legs to give him a food pellet does that a number of times
now only when he touches the lever with his paw do we reinforce him give him that kind for that
kind of reinforcement five or six times and now whenever he pushes the lever and that's the final
thing that we're looking for the response we're looking for so what we've done with shaping
is is successively reinforce these approximations to the response until we get the full blown
response now this process is probably nothing new to you you probably use it yourself if you're a
mother and you're trying to raise kids at first when two-year-old Susie gets puts her shoes on
the first time you say good job Susie good job you got your shoes on even though they're on the wrong
feet you still say that's fine at first you wouldn't say that when Susie's 30 years old
so you might wait in that case until she gets them on the right feet and we do that if we're
training our dog for example we know we have to reinforce the dog we know that we have to give
the reinforcement fairly close to when the response is made and we know that the dog will probably
not do something complex right away so we bring the dog in we want to teach it to roll over
so we say roll over roll over roll over finally it lies down well that's the first step in rolling
over so we give it a little we give it some food at that point and now the next time we might wait
till he gets on his side finally we wait till he rolls over and then we give him the food
so we know a lot about shaping and we use it in our lives daily okay so that's the general situation
with operant conditioning we now have a rat that's trained to push the lever we can turn on the
machine so that every time the lever is pressed he reliably gets a food pellet now I want to talk
a little bit about the time course of events with operant conditioning and we use the same words
that we used when we were talking about classical conditioning the words of acquisition extinction
and spontaneous recovery although we use those words to describe different things with operant
conditioning again if you would picture a graph where on the vertical axis we might have something
like a number of food pellets eaten per unit of time and then on the horizontal axis we have time
and we start at time zero and that would be defined as the very first time that the rat pushes the
lever to get a reinforcement to get a food pellet and if we go back say five minutes prior to this
how many times did he push the lever well by definition he hasn't pushed the lever so at time
zero the number of lever presses would be zero and then we look at the next five minutes and see
how many times that the rat has pressed the lever and we discover perhaps he's pressed it three or
four times and so that gives us a data point and then we go over and look at the next five minutes
so 10 minutes now into the learning and perhaps he's pressed the lever seven eight times something
like that and we look at the next five minutes 15 minutes into learning and we look at how many
times he pressed the lever during that five minute period of time and perhaps it's nine ten times
and in the next five minutes again it's about nine or ten times he's now pressing the lever
about as fast as he can eat the food all right so we've produced a function now which initially
increases rather rapidly and then levels off much like we did with classical conditioning
and we call it acquisition again he's acquired the response and in order for acquisition to occur
with operant conditioning you must be reinforcing so now we have an acquired response the functions
leveled off somewhat and then we change the conditions and in this case we take away the
reinforcements so now you can press the lever but every time he presses the lever nothing happens
no food pellet comes down the trough so he continues to press the lever not surprisingly
and for a period of time continues to press the lever but after a time he quits pressing the lever
don't want to be anthropomorphic here and crawl inside the rat's head but somehow he has figured
out I suppose that the food's no longer coming and so his response dies out and again we call that
extinction the response has become extinct and in this case we have produced extinction by simply
turning off the reinforcements after extinction takes place we can take the rat out of the apparatus
let five or ten minutes pass and if we put the rat back in the apparatus we will discover he'll
go over and start pounding on the lever again at a very rapid rate in fact at a rate that is
similar to what happened at the end of acquisition and we have no longer we have not
subsequently reinforced the rat so he's pressing this lever spontaneously after the passage of some
time so again we call that spontaneous re spontaneous recovery he's recovered the response
and it appears to be spontaneous because we've not done any additional reinforcement again
extinction will occur and it'll it'll occur quicker we can take the rat back out put him
back in he'll go over and press the bar a few times won't be as strong a recovery the second time
and it'll it'll go away even quicker we may be able to get one more as well but these are the
terms then acquisition that occurs when you're reinforcing extinction when the reinforcement
is withdrawn and then spontaneous recovery after the passage of time with no further reinforcement
at this point you may be saying to yourself well that's uh that's all well and good but uh
we're talking about rats here what about humans does this do these do these principles apply for
humans as well well let me describe a situation which i think is a pretty good approximation to
what's happening with this rat suppose that uh you're learning to drive a car and this car has
a stick shift in it so you have a clutch and you have a gear shift lever and you have to learn to
engage the clutch in order to make the car go forward and you have a driving instructor or
your parent with you when you're first learning to do this kind of thing and so this driving
instructor explains to you how the how the car works and how you need to engage the clutch and
every time you come to a stop you have to put the clutch back in shift back down into the first gear
and so forth and you think you got it and so now you you very carefully engage the clutch and
haltingly get the car started and you're going down the road quite nicely and steering and and
using the accelerator and so forth and you come to the first stop sign and you put on the break
you remember you have to do that and as you come to the to come to a stop you have forgotten to
push in the clutch and the car jumps a little bit and stalls on you and the driving instructor or
your parent looks over and says i think you forgot to put in the clutch and you say oh gosh i forgot
to put in the clutch how stupid of me you told me i had to put in the clutch okay i'll i'll put in
the clutch from now on i promised and so you get it started again you get the car started and
you're going down the road and you come to the next stop sign and you put on the brake and the car
starts to stall a little bit and you push in the clutch all right your driving instructor says good
job you got the clutch pushed in that time you got reinforced for pushing in the clutch and so you
come to the next stop sign uh you you start to a little slower but but you get on the clutch pretty
well the next one pretty smoothly you're getting on the clutch good job good job you nobody's honking
at you because you stole the car and you're moving along pretty nicely come to the next stop sign
you're on the clutch and then you learn this uh acquisition is occurring you're up to the flatter
part of the curve and you're pretty well pushing in the clutch very reliably and maybe you do this
for weeks or months at a time and now you're doing just great now you decide to fly off and visit grandma
and you get there in the airport and you get a rental car and this car doesn't have a clutch in it
it's a it's an automatic transmission car and so you get in the car you drive out of the airport
and come to the first stop sign and boom your left foot goes down onto the floor board there's no
clutch in this car how embarrassing i just tried to step on a clutch there wasn't even one there
i didn't get reinforced for it in fact i got embarrassed for it and so i promised myself
i'm not going to do that again you come to the next stop sign you start to go for no i'm not
going to do that next stop sign a little bit and then fourth fifth stop sign you're no longer going
for the clutch what's happened extinction has happened at this point you're no longer being
reinforced you no longer make the response so you do great that day you go to grandma's house sleep
overnight come out the next morning jump in your rental car drive down the street come to the first
stop sign bang your foot's back on the floor again overnight spontaneous recovery occurred
and you're now making the response again it'll die out even quicker this time maybe only one
or two times and you'll no longer go for the clutch again all right so that's a simple example a
simple human example of operant conditioning and the principles and the time course of events with
operant conditioning all right up to this point i've been pretending that there's only one way
to reinforce and that's for every response you give a reinforcement every time that rat pushed the
lever we gave him a food pellet and that is one way of reinforcing but there are other ways of
reinforcing and these other ways of reinforcing have some very interesting characteristics to them
and skinner extensively studied these other schedules of reinforcement in fact wrote a whole
book on schedules of reinforcement so let me talk a little bit about those these schedules
of reinforcement are made up out of two words and the words are fixed and variable and the words
ratio and interval fixed and variable you obviously understand ratio has to do with reinforcing
based upon the number of responses that are made interval has to do with reinforcing based on the
passage of time and so when we put those those words together we can come up with four different
schedules of reinforcement the first one is fixed ratio and that's actually what we've
been talking about when we're talking about reinforcing every response that's a one to one
fixed ratio you remember ratio has to do with the number of responses so in this case you
make one response you get one reinforcement so one to one is a fixed ratio but it could be other
ratios as well you could make it a five to one that the rat has to push the the lever five times
in order to get a reinforcement or you could make it ten to one and if you change the reinforcement
this way you can get the the rat to press the the lever a whole lot more times if you're looking for
amount of work you can get the rat to work a lot harder if you put them under a ten to one ratio
so the rat has to go over there and press the bar very quickly ten times in order to get a food
pellet in which case it will increase his frequency of response and you say well what's that got to
do with humans well if you want to get people to work faster suppose you're in management and
you're in a particular company and you want people to work faster you might want to change their
reinforcement schedule so you pay them a fixed amount for laying a certain number of bricks
or for wiring up a certain number of widgets in your plant and so one way to get them to work
faster is to pay them a dollar for every five widgets they wire up instead of for every widget
they wire up and they may wire up more widgets that way so that's one way of increasing the
frequency of response is by moving to higher fixed ratio schedules another schedule is a fixed
interval schedule and you remember interval has to do with the passage of time and here it's a fixed
amount of time so if we take our rat in our operant conditioning apparatus and we say you
compress the lever you get a food pellet but then we turn off the the food pellet machine for 20
seconds and then not until 20 seconds passes will a lever press bring about another food pellet
we have now put the rat on a fixed interval schedule fixed at 20 seconds and you might be
curious about what happens in that case if you plot what happens cumulatively so you have the
number of responses being made and you plot it as a function of time what you discover will happen
as soon as the rat learns this fixed interval is that you get a burst of responses right toward
the end of this interval so you'll the rat will push the the lever and then 20 seconds will go
past and the rat will be pretty much uninterested in the lever and tell about two or three seconds
before the end of that interval and then rush over and start pounding on the on the the lever again
and then he'll let time pass and then again after about 20 seconds we'll run over and start pushing
on the lever so you get this kind of scalloped like function with a burst of responses toward the
end of the fixed interval so that shows that he does pretty well learn the interval now what's
this got to do with human behavior well most people are actually paid on a fixed interval schedule
people are paid at the end of the week for example are paid on a fixed interval schedule now as you
might expect we don't get quite the striking scalloped behavior where we have bursts of responses
people may work a little bit harder on Fridays than they work on Mondays when they're paid on
Friday but we have some other kind of rules here too if you don't work all week long until Friday
you might get fired they might take you out of your skin or box altogether and so it doesn't
follow exactly the same rules but it is possible for to get more work right right toward the time
a person might be paid the most interesting schedule is undoubtedly a variable ratio schedule
we're talking ratio here so it has to do with a reinforcement based upon the number of responses
but in this case it's variable so they can't predict it it may be after five lever presses
the rat gets a food pellet but then it might be the next time after three presses he gets a gets
a food pellet and the next time maybe after eight presses the next time after six and the next time
after five and the next time after seven and there's no way to predict ahead of time how many presses
it's going to take to get the food pellet now that may may seem kind of a silly sort of way of
reinforcing but I might also point out that we do a lot of reinforcement in this manner
and what it leads to one of the most striking characteristics is it leads to
a high resistance to extinction we can now turn off the food pellet machine and if we've had the
rat on a variable ratio schedule the rat is far more likely to continue to respond for a long
period of time than if we had him on a fixed ratio schedule again if we want to crawl into the rat's
brain and sort of think what the rat's thinking about if it's a one-to-one whoops the machine
must be broken after three times of pressing and not getting the food pellet but if it's
sometimes been five and sometimes seven and sometimes three maybe it's 12 this time maybe
it's 24 this time and so it's not surprising perhaps that the rat is fairly resistant to extinction
I would point out that gambling games are usually based upon variable ratio schedules
and one of the the best examples if you want the thing closest to an operant conditioning chamber
is a slot machine a one-arm bandit if you go to Las Vegas Las Vegas was built on variable ratio
schedules if you go to Las Vegas you'll see people standing in front of their levers just like rats
pulling those those arms down on the slot machine and looking for their pellets in this case a pay
off of a silver dollar perhaps in the trough in front of them and they'll stand there and
and pull these levers for long periods of time seen little old ladies in Las Vegas with their
with their coin cups in their hands playing three or four of these things at the same time pulling
the levers as fast as they can never seeming to wear out somehow we've invented a very a way of
being very resistant to extinction even if it doesn't pay off for a period of time imagine if
you will changing this to a different reinforcement schedule let's make it a one-to-one reinforcement
schedule and the folks at Las Vegas take about 16 percent of the slot machines so you put in your
dollar pull down the lever on a one-to-one ratio what do you get you get 84 cents put in a dollar
pull the lever 84 cents put in a dollar pull how long are you going to play this do you think
I think you're not going to play it very it's like a broken change machine
for you and I think you're going to extinguish fairly quickly from this kind of lever it's
the same ultimate payoff the same average payoff that you're getting with the the slot machine
because the house is still taking at 16 percent but when you put the same thing on a variable
ratio schedule it's very resistant to extinction other gambling games are the same way I would
contend that a lot of people in our lives that have us kind of hooked on a relationship have us
on a variable ratio schedule if you've ever had a friend who's very very consistent smiles at you
every time is nice to you every time and then this friend stops being nice to you say well I guess
this person doesn't like me anymore and you don't have much to do with this person anymore but then
there are people who put us on variable ratio schedules and these people are sometimes nice to
us sometimes great to us sometimes terrible to us and they get us conditioned to this kind of behavior
and then they try to extinguish us or they quit being nice to us all together and we much like
the rat thinking well maybe it's 12 times maybe it's 24 times maybe they're going to come back
and be my friend I would contend that those kind of people are fairly hard to to get rid of now
the variable interval schedule is a little less interesting there technically people are paid
once a month where some days it's 30 some months it's 30 days some it's 31 days are paid on a
variable interval schedule but it tends to be a little little less interesting before I quit the
day let me just tell you about a little BF Skinner story he was supposedly at a hotel one time at
a convention in Las Vegas and the fella called him over the manager the hotel said oh I got a
problem and you're supposed to be the the the big expert on these things my elevator operators quit
on me all of the time and we don't pay him very much and this is back in the days where they had
elevator operators and he said I wonder if you could figure out a way to get them to to stay on
so he thought about it a little bit he said now why don't you try this he said instead of having
them just go up and down the floors we'll have them when they go to a certain pattern of floors
they'll get a payoff a $10 prize and we'll change the pattern from time to time so if they go to
the sixth floor down to the second floor up to the eighth floor down to the first floor
bells will ring and they'll get this big prize well he said that sounds like an interesting
idea so he tried it a year later Skinner came back and he said well how did that system work
the hotel manager said well it works great I haven't had an elevator operator quit he said I do have a
problem though he says the problem is a customer gets into the elevator and wants to go to the
seventh floor he takes him to the sixth floor up to the eighth floor down to the second well you see
what the problem is sometimes we get ourselves into trouble with our own reinforcement schedules
but you see how powerful these kinds of things are so today we've talked about the conditions for
operant conditioning we've talked about how it's really a fairly simple process we've talked about
the time course of events of acquisition extinction and spontaneous recovery talked about the process
of shaping and finally we talked about the power of various reinforcement schedules
next time we're going to talk about more complex learning situations thank you
