who's joining us from London to talk to us today
about his work in active inference,
the free energy principle, many things.
I'm sure many of us who've signed on today
are excited to hear about work
that we've spent a lot of time thinking about ourselves.
Just as a point of order, so what we'll do,
Karl will talk to us for 45 minutes,
then we'll have 15 minutes of questions
and maybe a little bit more, but I shouldn't say that.
We'll be good and we'll let Karl do 45 minutes of talking.
If you can, in the chat box,
if you'd like to ask a question, chat it to me.
So just send a chat message to me.
I'll see it here.
I'll keep a list to make sure
that we get to everybody in an equitable fashion.
So sort of in the order of the questions get asked.
We'll save those for the end.
You don't need to just put your name
and say I have a question I'm gonna ask.
I'll go through, I'll call on you.
If you have a question that you really, really need to ask
as a clarifying thing for Karl,
just sort of put that in all caps or something
and I will do my best to graciously interrupt Karl
and deliver that quick clarifying question.
But I think we're all really keen to hear
what Karl has in store for us.
And so by and large, we hope to keep the questions
till the end of Karl's formal presentation.
So with that point of order in place,
I'll keep an eye on my chat.
It's my great pleasure to introduce Dr. Karl Friston,
who will speak to us about me and my Markov Blanket.
Thank you, Karl.
Well, thank you.
So it's a great pleasure to be able to talk to you.
I've heard so many great things
about the Santa Fe Institute.
I've always wanted to visit you and virtually I am now.
So I'm very honored and pleased to be able to do that.
45 minutes.
So I should apologize in advance.
I have a habit of trying to pack everything I know
into each talk.
So I'm going to be stopped at about 40 minutes
and then rush through to the end,
to the part of the presentation that I find the most useful,
which is the questions and answers.
So I'm going to go through this quickly
using most of the graphics and figures,
really as icons,
just to sketch the landscape
and the thinking behind the free energy principle
and active inference.
I'm going to hopefully present the talk in three parts.
First, addressing the statistics of life.
A physics of sentient, in particular, sentient behavior.
With a particular focus on Markov blankets,
they will be playing a special role
and the emergence of Bayesian mechanics
rests very much upon Markov blankets.
I can try and demystify what I mean by all that
by presenting some simulations of a primordial soup.
And then I'm going to tell exactly the same story
from the point of view of a neurobiologist.
So the first part is going to be something
I suspect that you'll be more engaged by,
which is the physics of self-organization.
But then the second part is going to be
how we can translate those principles
those mechanics to neurobiology
to understand creatures like ourselves.
And I'm going to tell that story
with reference to things like predictive coding
and neural networks.
With a view to at the end,
just talking about two different kinds of self-organization
just to foreshadow this,
a simple reflexive sort of action upon the world
versus a more deliberative planning
that characterizes the way that we engage in self-organize
and as we will see self-evidence.
So I start this talk with a question posed by Schrodinger.
How can the events in space and time,
which take place within the spatial boundary
of a living organism,
be accounted for by physics and chemistry?
Now, clearly I cannot answer that,
but I want to just focus on the notion
of a spatial boundary.
And Schrodinger will be the first person to acknowledge
that that boundary is in and of itself
a statistical boundary.
It is a probabilistic construct.
So I'm going to take the boundary of anything
to be a Markov blanket.
For those of you not familiar with a Markov blanket,
I've tried to cartoon the idea here.
If we imagine that this graph here
represents all the states of the little universe
and all the edges on this graph
correspond to causal influences or dynamical coupling,
then if we select a particular set of states
and we call those internal states,
then the blanket states here in pink
separate the internal states from the external states.
And they basically comprise the parents
of the internal states, the children,
and the parents of the children.
And the idea is that if I wanted to know statistically
about my dynamics here, given the rest of the universe,
I would only actually need to know the blanket states.
So that these blanket states provide
a statistical veil or insulation or partition
that separates me or my internal states
from states that are not me, the external states.
Technically, if I condition on the blanket states,
then the internal states are conditionally independent.
I'm going to make a further move here.
I'm going to divide or bipartisan the blanket states
into sensory states that influence,
but are not influenced by internal states
and active states that are not influenced
by external states, but are influenced by internal states.
So this partition speaks to a carving up of all states
into the states of a particle.
I'm going to refer to those as particular states.
Now, this could be a person, it could be a small particle,
it could be a mouse or a man, a virus,
that is composed of internal states
on their blanket states that in turn
are divided into sensory and active states.
And the rationale for that, well,
the intuitive rationale will be evident
if I just show those dependencies in a familiar setting.
For example, if I was a neurobiologist,
then the internal states will correspond
to all internal brain states
that generate actions upon the world via active states,
say my actuators or my autonomic reflexes
that change the external milieu,
it could be a homeostasis or physical states of the world,
that then impinge upon my sensory states,
my sensory impressions that are then used
to update my internal states.
And so the cycle continues.
And exactly the same conditional independent structure
is in play for nearly, well, strictly speaking,
anything that you can imagine.
So for example, it could be a cell
where the internal states for the intracellular states,
the active states could be the atomized in active filaments
that support the surface of the sensory states
that impinge upon the external states
that supply information or influence sensory states.
And again, the cycle and the reciprocal exchange
between the internal and external states
vicariously through the blanket states
has exactly the same structure.
So that's the Markov blanket.
What I want you to do now is to forget about that
for a moment.
And I just want to rehearse an almost not a schoolboy,
but certainly a graduate level physics of things.
And in particular, random dynamical systems
that can be cast in terms of a long line equation
with some rate of change of states decomposed
into some flow, state dependent flow,
and some random fluctuations omega.
And I just cartoon that here in terms of two states,
tracing out a trajectory over time.
And these could be at any scale spatially or temporally.
For example, it could be the beating of my heart
as it goes through its different cardiac phases.
It could be the trajectory over the years.
I have my birthday, go to Christmas, some holidays,
and the like.
The key thing that I am going to restrict myself
to discussing is that these random dynamical systems possess
a Markov blanket, which is defined
in terms of conditional independences that
speak to the need for a probability density.
And that is going to be, I'm going
to frame that in terms of a non-equilibrium steady state
density, which simply means that this system, these states,
have a global random attractor.
They're an attracting set of states,
which just means that the trajectory over time,
at some point in the future, will revisit the neighborhood
on this attracting set or this attracting manifold.
That's basically the key assumption
upon which everything else rests,
that there is in play an attracting set.
If that is the case, then in the fullness of time,
the probability density described
by the density of these trajectories
will converge to steady state, at which point
the equation, the Fokker-Planck equation,
the Maastricht equation, the Schrodinger equation,
however you want to talk about this,
the equation describing the rate of change
of this non-equilibrium steady state density will be zero.
And that has an interesting implication.
Because the solution to the Fokker-Planck equation
can be rearranged and decomposed using, say,
a Helmholtz decomposition, what that means is,
I can write down the flow at any point in state space
here in terms of a gradient flow on the log
of this non-equilibrium steady state density
that decomposes into two parts.
There's a gradient flow that depends
upon the amplitude gamma of random fluctuations
and then a solenoidal component.
So for those people not familiar with the Helmholtz
decomposition, let me just illustrate what I mean,
or what it means intuitively.
Imagine I place a drop of ink in some solvent.
Now, in normal circumstances, the ink molecules
will be dispersed by all the random molecular fluctuations
and the ink would be distributed through the solvent.
And I cartoon that here in terms of a diffusion
of the probability mass of the different ink molecules,
that's what would happen normally.
But if a system has an attracting set,
then we'd see something very different.
We'd see a behavior where it looked
as if it was gathering itself up together again,
as if the flow was up concentration gradients.
And that's basically what that Helmholtz decomposition says
must be the case if you have attained some non-equilibrium
steady state.
So I've just written it down here in terms of the solenoidal
flow circulating on isoprobability contours
and the gradient flow as we're flowing up the log probability
gradients here.
So intuitively, we're just looking
at the two components of flow that circulate going down
the plug hole here and the gradient flow was actually
going down the plug hole.
So with that equation in place, the solution
to the density dynamics, which we're assuming
exists given that we have some kind of steady state,
what now can we say about the Markov blanket?
Well, those expected flows still hold
for all the partitions of the Markov blanket.
And in particular, I just want to focus
on the internal states, which we'll denote by mu here,
and the active states here.
And crucially, because of the conditional independence,
they are only functions of the blanket states,
given a Markov blanket m here.
So that's very interesting.
What's that he's saying is that any system that possesses
a Markov blanket will look as if its internal active states
are trying to optimize the same quantity,
in virtue of the fact that they both are performing
a gradient flow on the log probability of the blanket states,
given there is a Markov blanket in play.
And without going into any details,
I'm going to celebrate that simple consequence
of there being a Markov blanket from the perspective
of different people in the life sciences
and the physical sciences.
So if I was a psychologist or in machine learning,
for example, I would interpret this log probability
as something that is valuable.
The states that constitute this attracting set
are the sets that I am attracted to,
and my behavior evinces an implicit value in those states.
And from that, we can spin off reinforcement learning
right through to expected utility theory in economics.
But this quantity is just the self-information
and information theory.
And if that, as we'll see later, is upper bounded
or lower bounded, depending upon the sign of the free energy
by a free energy functional here.
So this self-information,
surprise or more simply surprise,
also gives us a perspective on what these gradient flows
would look like.
It would look like you're trying to minimize
surprise or self-information.
And then through that, you could access principles
like the infimax principle, minimum redundancy,
reducing self-information by the free energy principle,
which is what we're going to be talking about.
Interestingly, or crucially,
this, the expected value of this self-information
is just entropy.
So it would look if I were trying to minimize
my expected surprising as if I was trying
to minimize my entropy.
And of course, that's a holy grail of many formulations
of self-organization from synergistic through to,
as a physiologist, homeostasis.
I'm going to take another perspective on this
and just note that the probability of my blanket states,
given a Markov blanket can also be interpreted
as a probability of some data given a model
of how those data were generated by the external states.
And on that reading,
the, this quantity becomes model evidence,
Bayesian model evidence, also known as marginal likelihood,
which means we can interpret this
fundamental gradient flow behavior
in terms of self-evidencing in your biology,
the Bayesian brain evidence accumulation
and the machine learning predictive coding.
This slide is a slightly more formal take on the basic idea.
What I wanted to do, although I'm sure
that you will know this already,
is just emphasize how central this solution
to the Pocke-Planck equation is to all that we know
in terms of the physics of self-organization
or indeed physics, just to take a couple of examples
and then look at the implication again
of having a Markov blanket partition.
So without the Markov blanket partition,
there are some obvious special cases of this equation.
So let's just set the amplitude
of the random fluctuations to zero,
say the averaged away,
we're talking about the motion of heavenly bodies.
And then what we have is essentially an equation,
equations of motion that correspond formerly
to Newton laws of motion
or in more generally classical or Lagrangian dynamics.
If we go to the other end of the scale,
look at very small, hot things that jump around
where the random fluctuations dominate
to the extent we can ignore the solenoidal component
of the flow.
Then what we have is essentially a statement
of thermodynamics that often articulate
in terms of fluctuation, dissipation
or integral fluctuation theorems
and all our favorite statistical mechanics
where the amplitude of the random fluctuations
is just proportional to the temperature
and Boltzmann's constant of proportionality.
I could play the same trick,
but here I just work with the complex root
of the non-equilibrium steady-state density
and this equation transpires
to be the time-independence Schrodinger equation.
And from that we can get to quantum electrodynamics
and everything else at that level.
But what I want to pursue is a special case
of this equation here
where we've unpacked it in terms of flows
pertaining to the internal states and the active states
where I've made a little move here
instead of expressing it as a gradient flow
on that log probability,
I'll replace the log probability
with a variational free energy
where the variational free energy is just
the self-information,
but written down in a way that it becomes a functional.
So this is a little bit subtle,
but we'll come back to this later.
So instead of writing down
or formulating this in terms of a log probability,
what I formulated as is as a functional
of a probability distribution over external states
that is parameterized by internal states.
So it's still a function of the blanket states,
which we know has to be true,
but now we're interpreting some of those blanket states
in particular, sorry, the internal states,
some of those particular states
as parameterizing a belief distribution
or a probability distribution over external states.
If I make that substitution,
then this variational free energy here
is just is simply the self-information.
So what we have in this interpretation
is a picture of dynamics of the internal
and active states of any particle
that can be construed as self-evidencing
by performing a gradient flow
on this free energy functional
of beliefs about what's out there,
beliefs about the external states
beyond the Markov blanket.
So summary, three important moves.
Could I ask a question?
Yes, of course.
I honestly don't know what you mean
by the word or phrase self-evidencing.
So it's quite simply,
but it's a phrase that actually comes from philosophy,
but I don't know what it means there.
All I'm saying here is that because this quantity here
is negative Bayesian log Bayesian evidence,
then we can interpret these gradient flows
as if they were hill climbing model evidence.
So it's just a way of interpreting
the kinds of gradient flows that would have to be in play
for any system that has attained non-equilibrium steady state.
There's a way of formulating those gradients flows
in terms of a gradient flow
on a function of
or on something that a Bayesian statistician
would call model evidence.
But it appears so far as if this,
you're saying this applies to formalisms
at an enormous level of generality,
like if I had the Lorenzo tractor
with a little bit of diffusion,
so that it was getting attracted over time
to some somewhat noisy version of its attractor,
you would then describe that as a form of inference.
Yes, yes.
And that's quite prescient as an example,
because we'll see an example of that
in the next bit of the talk, yeah.
Okay, so I guess the challenge for me,
and I think for a number of people
who have wanted to understand your ideas for a while,
is taking sort of the very general mathematical fact
that some things converge
to some probability distribution,
and then understanding your interpretation of that fact
as climbing upward in terms of fitness, evidence,
inference, and so on,
and trying to figure out,
well, presumably that interpretation is,
meaningful for particular systems,
and maybe not for every system
which is arriving at an equilibrium probability distribution
through some arbitrary stochastic dynamical process.
So I'm trying to understand sort of the ontological status
of the words, evidence, and inference,
and perception, and action,
and because I can imagine systems
where placing those interpretations
on the variables would be very compelling,
and others where it would seem less so.
Right, that's a great question.
So I'm using them in all of these words
in a very deflationary way.
So you're absolutely right,
that an ensemble of rents of tractors
that had a Markov blanket would certainly,
if it attained some form of non-equilibrium steady state,
then it would certainly fall under this rubric
and this rhetoric, and you could say,
yes, it was self-evidencing.
That will be a rather trivial kind of self-evidencing
in relation to the kind of self-evidencing
which we do with sort of explicit notions of selfhood,
but in the same sense that self-information
just means a statement about functionals
that pertain to the intrinsic properties
of the systemic states at hand.
I'm using self-evidencing in that sense,
but it's a good question because, you know,
we're probably not gonna get to the end of the talk,
but the end of the talk would have said, well, look,
you know, this is just really a read statement
of things that have to be the case
if you accept that everything can be cast
as a random dynamical attractor over some,
that shows steady state over some suitable timescale.
What kind, what special moves would you need to make
to explain sentient behavior, you know,
the perception that a layperson would accept?
And the answer is going to be basically it's about planning.
So at the moment, we're just talking about Lorenzo tractors
as self-evidencing in a mindless way
that is just an interpretation you put on the dynamics.
Things will get a lot more interesting
when the generative model implicit
in having a model evidence starts to entertain
the consequences of action.
And then I think we move much more into
the rich non-deflationary kind of self-evidencing
that that phrase evokes.
Does that make sense?
I think so, I look forward to the rest of the talk.
We may not get there, but that's where I want it to be.
But yeah, just to reiterate, things like beliefs,
I just mean a Bayesian belief in the sense
of Bayesian belief dating or belief propagation.
These are not sort of propositional personal beliefs.
They're just ways of describing
the mathematical concepts that we're dealing with.
So it is very deflationary, but deliberately imbued
with potential meaning that we're going to try and realize
by looking at what kind of systems
are possessed those properties that make them interesting
and truly self-evidencing in a philosophical sense.
So in fact, let me now quickly go on then
to give you that example.
So what I've done here is take 128
Lorentz attractor systems or Lorentz systems,
equip them with interactions,
strong and weak interactions based upon simulated
electrochemical forces and a physical proximity
that you can think of in terms of Newtonian attraction
and just integrated these 128 Lorentz systems
until convergence to some steady state distribution.
So here, each of those little molecules,
if you like, synthetic molecules is color-coded,
showing them sort of wriggling around
at a non-equilibrium steady state.
And you may be asking, well, why have I done this?
Well, remember, everything interesting starts happening
when you can identify the Markov blanket
and because I've written down the equations of motion,
both the dynamics of the Lorentz system
and the interactions between states of the Lorentz systems,
I know exactly the dependency structure.
So I know the adjacency matrix mediating that dependency
from that I can derive for any given set of internal states,
the parents, the children, the parents, the children
and identify the blanket states of that structure.
And therefore, can do the partition
of all of those simulated molecules
into internal states in blue here
that generally find themselves supporting
the active states in red here,
that themselves lie beneath the sensory states
that are directly exposed to the external states
external milieu here.
So, can I just clarify a question?
If you could just go back a slide here.
Sure.
Just so I can follow what's going on.
So you have all these little atoms,
they have internal degrees of freedom.
The internal evolution of those degrees of freedom
follows the Lorentz equation.
Yep.
The interaction between the atoms is governed by,
the strength of it is how far away they are from each other
and the nature of the interaction is governed
by the particular internal values of each atom.
Is that right?
Absolutely.
Yeah, so I was sort of selling that
as a sort of electrochemical interaction,
but yes, it's just a coupling between
one of the three states of each of the red systems.
So these are the complete equations of motion
that you've just described very simply.
Yeah, you have like,
we're sort of thinking of this as each atom
has three internal degrees of freedom,
the evolution within,
and then the extraction or repulsion.
So then these atoms are physically moving around in space
and it's just the nature,
like whether that attraction is positive or negative
is governed by the internal degrees of freedom
of the two creatures in question.
Absolutely, yeah.
So to simulate this,
you just basically replace one of the states
of an events attractor with a state
that actually sums or gathers other,
the values of other states of the other systems.
So you just substitute these things into here
and generate this ensemble.
I should say it's not terribly important what you do.
You could use any autonomous system
with or without random fluctuations.
There were random fluctuations in this,
but it also works without random fluctuations.
The only key thing is to get the temperature about right
because it either explodes
and it immediately dissipates.
So there is no attracting set
or it forms a little crystal.
So you've just got to get the autonomous dynamics
and the time constants in the right Goldilocks range
to get something that sort of bubbles away,
quite happy, a little bit of active matter.
But in principle, you should be able to do that
with any set of your classical attracting systems.
There's nothing special about the event system,
it's just the one that I'm most familiar with.
Got it.
And then the colors of these guys here,
those colors are some representation
of the internal state of the...
Absolutely, yeah.
So each little molecule actually has three little balls here
and the color is just reflecting the value
of the three states of an event system, absolutely.
And so it isn't just the physical position
of the atoms that are modified
and I'll finish in a moment.
It isn't just the physical position
of the atoms that are modified
but also the location of the atom
within its internal state is also coupled
to the other atoms, right?
That's why you can get this non-equilibrium
kind of circulation.
Excellent, thank you.
Absolutely, so there are five, well, six states.
So the states of the system are the standard Lorentz
three states and then you've got sort of states
in a Euclidean space and then you can equip that
with Newtonian or Lagrangian mechanics.
Yeah, absolutely.
And then, you know, what I'm showing here
is exactly the same solution as in the previous slide
but now the three colored balls being replaced
by little small blue balls and then the center
in Euclidean space by the larger colored balls
just to visually partition the system
into its Markov blanket in the internal
and the external states, illustrating that, you know,
now there's a Markov blanket in play
and what we see is, you know, basically a synthetic,
very, very simple little creature,
little pry on a little virus-like particle
with a little tail here,
riddling around at steady state.
And the reason that we've done this
is just to revisit this notion of self-evidencing
and the Bayesian mechanics interpretation
of what just is there, you know, this is just dynamics
on, you know, on an attracting manifold.
So heuristically, what we can now do is ask the question,
do internal states appear to infer
or predict in some way the causes of the sensory states,
namely the external states,
through this gradient flow on the model evidence
and that we're calling that self-evidencing.
So I'm just going to illustrate that
with a sort of eyeballable example
to make a particular point.
The example here, which is in the original description
of this work, addresses the question,
can we, with some appropriate linear mixture
of lagged internal states, predict the motion
of external states?
And in this instance, the color coding here,
the weight of the cyan reflects the degree
to which the motion of this external state
could be predicted by the states that are in system,
electrochemical states of each of the internal molecules here.
And the dotted and dashed lines here show the prediction
and the actual velocity of this external state,
illustrating the little excursions
of this external molecule here or particle here
as it's spat out of the ensemble
that is pulled back in again,
are faithfully predicted by the appropriate linear mixture
of the internal states.
You can see that very clearly with this event here.
You can also see if I actually plot out the fluctuations
in the internal states over time,
you can actually see the internal fluctuations
surrounding this particular event here.
And this takes a question,
did these states cause this or did this,
the internal state cause changes of fluctuations
in the internal states?
And then I would normally ask the audience,
which do you think, and then they would vote?
And of course, everybody says, well, it's both,
they will be absolutely right.
So the point, the particular point I wanted to make here
is all we are doing is interpreting
generalized synchronization or synchronization of chaos
that has to be there for this random dynamical system
at steady state as a form of prediction.
And then just illustrating that in terms of Huygens' clocks,
this is a drawing by Huygens,
where on this interpretation,
we can associate one pendulum with an internal states,
the other with external states,
and the beam or the wall from which both clocks
are suspended or the coupling,
the done coupling is mediated in a loose way.
That beam now becomes the blanket states.
And then I normally make a joke that if you subscribe
to this self-evidence and interpretation,
that the internal states,
you're making inferences about the external states,
then it has to be exactly true and symmetrically the case
that the external states are also making inferences
and learning about you.
And there's an interesting story about that
when it comes to things like eco-neutral construction
and the like.
So just to summarize the background
to self-evidence as a dynamical phenomenon,
the existence of a particle implies a partition
of systemic states into internal blanket,
namely sensory and active,
and external or states that are hidden behind
the Markov blanket from the point of view
of the internal states.
And because active states change,
but are not changed by external states,
they appear to reduce the entropy of the blanket states.
And this means that action will appear
to maintain the structural and functional integrity
of the Markov blanket.
And that could be construed in terms of auto-poesis
in the biological sciences.
Internal states will appear to infer the hidden causes
of sensory states by increasing Bayesian model evidence
and actively influence those causes.
In my world, we refer to that as active inference.
But again, just as a nod to our previous discussions,
notice I'm talking about appear to a lot.
This is an interpretation.
It's not saying that this is self-evident.
It will look as if or you can interpret
these dynamics along these lines.
Ah, see that little interlude here.
One of my post-docs went to America
and had a baby with his wife.
And then his wife bought their baby a Markov blanket.
So this is actually a Markov blanket.
You should, you want to buy one.
You only get them in America.
So this is Likia making her inferences
from her Markov blanket from France.
So I'll race through the next bit
because this might not be so compelling
from your point of view.
It is exactly the same story,
but now with the parlance of neurobiology
and psychology and notions of global directed behavior
put on top of that basic mechanics
or that Bayesian mechanics.
And I would normally introduce this
from the perspective of the Bayesian brain
predicting and being predicted by the outside world.
There by having a constructive aspect
that the inside states, if we associate those
with the brain, for example,
will look as if they are trying to generate explanations,
trying to generate predictions of the sensory states
that are caused by the external states.
So I use this example of the 16th century oil painter
who was famed for doing still lives
but when viewed from a different perspective,
evoke a very different interpretation.
So if you saw a bowl of fruit and now you see a face,
the point being that you made that face,
that this is an inside out constructive active perception.
The face is only there because you entertain it
as a plausible explanation for the sensory impressions,
the sensory states on your Markov blanket.
And that notion can be traced right back through
from the students of Plato,
but to my mind, most beautifully articulated by Helmholtz,
for example, this notion that objects are always imagined
as being present in the field of vision
as would have to be there in order to produce
the same impression on the nervous mechanism.
And this is very close to notions of deception
as a hypothesis testing by people like Richard Gregory.
And if one then formalizes the bound on this evidence,
this free energy bound or proxy
for Bayesian model evidence or marginal likelihood,
then you move into the world of machine learning.
So pioneering work by people like Geoffrey Hinton
and Peter Diane, positing the notion of brain
as a Helmholtz machine, a statistical organ
that is doing this self-evidencing in a Bayesian
or statistical sense, boring ideas from Richard Feynman
in terms of inducing the bound on this evidence
or log evidence quantity.
From our point of view,
focusing on the role of the Markov blanket,
this is a nice, if like mathematical image
of impressions on the nervous mechanism.
So the idea is that the outside world
provides these sensory impressions
on your sensory veil or your Markov blanket.
And it looks as if your job is to try and infer
the causes out there that generated this sensory input.
And much of my Dave job is focused
on trying to understand the dynamics,
the message passing,
the computational architectures of the sort
that you see in brains that enable it to do
this kind of perceptual inference.
And it is much simpler than you might think.
So I've just written down that sort of solution
to the Fokker Planck equation again,
but in a slightly different way.
So I got my expected flow of the internal states
as a gradient flow on this free energy functional here.
But I'm just rearranging the terms
in the form of what's known as a Bayesian filter
in particular this instance, a Kalman-Busey filter
where I can think about the changes
in the internal states having an interpretation
of being composed of a prediction.
So this is how I think my internal states will change
or the external states will change
given my expectations about the current states of the world.
Plus the gradient flow part,
or this would be the solenoidal part in the gradient flow,
is effectively just a gradient flow
on the precision weighted sum of squared prediction error.
So what did I mean by prediction error?
Well, if I had this expectation about the external states
that were causing my sensory input here,
then if I had a generative model
that could generate the sensory states that I would see
if this expectation or explanation was correct,
then I could compare my sensory samples with my prediction
and the error is just the prediction error
or the mismatch or the difference between the sensed
and the predicted sensory states.
So that provides, if you like, to my mind,
a very graceful link between something
which has been used for decades
and certainly hasn't become very popular
to understand belief updating in the brain,
namely predictive coding and the solution
to the Fokker-Planck equation
that we've been championing or celebrating
in the first half of the talk.
Notice that this reading of predictive coding
doesn't mean to say you're ever gonna know what's out there.
All it says is it looks as if you're trying
to minimize prediction error through this gradient flow.
The actual cause of your sensations,
you will never ever know,
they're on the other side of your Markov-Plancket.
But in terms of...
You asked for a five minute warning,
so you asked for a warning too, sir.
That went so quickly,
it must have been so enjoyable for one of us, right?
Okay, what I'm gonna do now is show you
what you're not gonna see,
just so you knew what I wanted to share with you.
So I'm gonna whip through this like a movie,
just to survey what the journey
that I would have liked to have pursued with you,
but that was clearly far too ambitious.
So I was just gonna say that,
you can interpret minimizing prediction errors
in terms of action and perception
by changing internal to make predictions better
or by resubbing the sensations
to make them more like the predictions.
I would then unpack that in terms of the wiring
and the message passing the dynamics in brains
in terms of hierarchical message passing,
reinterpreting that gradient flow
in terms of neuronal dynamics in deep models
or hierarchical models of what and where,
talking about ascending prediction errors
and descending predictions,
give your worked example in terms of ocular motor control,
but highlighting the active part of this.
And coming back to this notion that there are two kinds of action.
There's the action that we've just talked about,
which is this basically a gradient flow of prediction error,
basically fulfilling my proprioceptive predictions,
and I've given you some numerical analysis
or simulations to illustrate how I can generate handwriting.
Again, you've got a lens tractor here
using a lot of Volterra systems,
but just integrating these systems,
you can make them look if they're doing this action
via a gradient flow,
as if they're self-organizing in quite a sophisticated way
and then illustrating that with handwriting
out of then taking us back to the physics
and start just to remind you without going into the equations
of the structure of the argument here.
So we're just starting off
with a long van formulation of a universe.
We're talking about the solution to the density dynamics,
but in a special instance that we have a Markov blanket
and how that leads to this interpretation
of a deflationary sort of self-evidencing
by invoking a free energy functional,
which is a function of beliefs
that are bound to external states
and encoded by internal states.
And this will be fit for purpose
for describing everything from particles to viruses,
but probably wouldn't be fit for purpose
in terms of describing you and me.
So what's missing?
I would then say, well, look,
there's a bit more to the ensemble dynamics
than is offered simply by the solution
to the Planck equation.
We can also formulate this
in terms of pathological formulation
and start to think about trajectories over time
and the particular trajectories of active states.
So what are they?
They're plans, they're policies,
they're courses of action.
And of course, we have a probability distribution
over those courses of action.
And that can be formulated in terms of a path integral
or an expected free energy.
And I would have unpacked that
in terms of the action perception cycle.
And in particular, just taking you into a bit more detail
into the functional form of the free energy
and what it looks like when you take a path integral
or an expectation over the predictive density
of outcomes or sensory states that have not yet occurred
and they become random variables.
And that gives you a different perspective
on things like accuracy and complexity
in terms of risk and ambiguity.
And I've linked that to visual search and information gain,
KL control and engineering
and expected utility theory and economics.
I'd have given you an example of this different kind of action
which I think now takes us slightly more into the realm
where self-evidencing takes on a less deflationary nature
in the sense that there's an ecostemic drive
to these kinds of trajectories of action into the future,
which is all about reducing expected surprise
or reducing uncertainty by maximizing information gain.
So basically, we get for free a formulation of systems
that have an inherent curiosity,
a drive to respond to epistemic affordances
and perhaps the most beautiful example of that,
which was simulated for you,
would be the way that we palpate the world
in order to resolve our uncertainty about the state,
the external states of affairs
that are generating our sensory impressions.
And then I would have concluded by going back to Helmholtz
who basically summarized everything
that I would have told you in the past 20 minutes
by saying that each movement we make
by which we altered the appearance of objects
should be thought of as an experiment
designed to test whether we would have understood correctly
the invariant relations of the phenomena before us,
that is their existence in definite spatial relations.
I would then thank everybody
whose ideas I was talking about
and then I would have thanked you for your attention.
Oh, right, thank you very much.
We're all clapping, there's not an easy way
for us to clap simultaneously, girl.
There's lots of questions for you here,
so I hope you don't feel disappointed
and I think people should also feel totally open if they want
just to put in the chat and we will,
we can dig deeper into some of these things
you gave us a preview of here Carl, so that's really fun.
I desperately wanna ask questions, but I'm gonna be good.
Our first person on the list here is David Kinney,
so David, please go ahead.
All right, thanks a lot, Simon, and thanks a lot, Carl.
So, asking just a really just a clarifactory question.
At the very beginning of the talk,
you framed Markov blankets in terms of something
that looked at least to me like a causal Bayesian network,
and in that you have the Markov blanket
as this very well-defined set of variables
for any given variable in the network,
and it's gonna be just those variables
that screen it off from the rest of the network.
And then that understanding of a Markov blanket,
as far as I could tell, which again,
maybe I just missed something,
sort of drops out of the presentation.
You go to examples in which there's a simulation
of a dynamical system in which it converges on some state,
and that's all really cool and interesting.
There's lots of different connections between that
and all sorts of things in physics and cognition.
But at least I was wondering if I could push you
maybe just say a little more about what that connection is
and where that kind of causal Bayesian
and statistical understanding of a Markov blanket,
how that through line gets drawn from all of the other things
that you then go on to do over the course of the talk,
because at least for me,
I had trouble sort of following that thread.
Right, but that's a really great question
in the sense that everything inherits
from the existence of a Markov blanket.
So that the thread you're talking about
is just the presence of this Markov blanket partition
or particular partition.
And I use the word particular partition
in the sense that it has a Dublantondra.
It is a particular partition that appeals
to Pearl's notion of Markov blankets
and those shielding states that you get
in a causal net or a Bayes net.
But also it is the definition of a particle.
So the idea here is you start from a very simple question,
what is a thing?
And if you want to define a thing,
you have to be able to distinguish it between
from something that is not that thing or no thing.
And if you think about it,
the only way that you can really do that
is via conditional independence.
And if you think about it even further,
then there is no other way of really defining a thing
that is in some sense,
separable from the rest of a universe.
And yet it has a two-way traffic exchange
with the rest of the universe.
So it has to be open, it can't be isolated,
and yet it has to be separable.
So the notion is that all particles from people,
from men to mice, all are stipulatively defined
in terms of them possessing a Markov blanket.
So that is the thread that if you like,
everything else unfolds from.
And the origins of that thread are almost stipulated,
or they are stipulated in the sense
that we are defining anything,
anything that can be distinguished from everything else,
but in virtue of the existence or the possession
of a Markov blanket.
So the first half of my talk was essentially to say,
let's just take physics or one flavor of physics
as we know and love it.
Let's boil it down to the essence of physics,
which is going to be the solution
to the Fokker-Planck equation.
And then you say, well, okay, so if something exists,
it has to have a Markov blanket.
So we put the Markov blanket in
and then everything else emerges.
Ah, that's interesting.
It looks as though internal and active states
are optimizing the same Lyapunov function.
Other things that inherit from that,
well, let me go back to
the connection that you asked about,
which is specifically the sort of the connection
with sort of Bayes-Nex
and Bayes-Independency graph.
It is essentially exactly the same
and has all the usefulness in terms of finessing
the computational complexity
in terms of leap propagation
and the like you would find in machine learning.
However, there is a bit of a twist here,
which you actually mentioned in your question.
This is defining conditional independences
for dynamical systems,
which is not quite as simple as the instantaneous
statistical dependencies that are considered
by the usual formulation in Bayes-Ind Networks.
So there are extra conditions in play here
that you need to be,
that are sometimes quite delicate to handle.
So you can't always just assume
because there is a particular deployment
of these dynamical couplings
that there will emerge a Markov blanket.
There are other conditions
that basically inherit from the fact
that you're dealing with a probability distribution,
that is a steady state distribution
of a dynamical system,
which is not usually considered
when you're talking about Bayes-Ind Networks.
That's an interesting and active area of research.
Thanks, I mean, there's so much you could follow up on,
but I wanna let other people ask questions.
So thank you for your answer.
Excellent.
Our next question is Andres Ortiz.
So I noticed that there seems to be a symmetry
between internal and external states,
meaning that there's no distinction between them
other than declaring that the internal states are internal,
but they are, I guess, if I understand it correctly,
they are mutually conditionally independent.
So would this mean then that the claims remain true
duly, so that is would the external states
appear to have a model of the internal states and act
so as to minimize their surprise based on that model
and related to that, are the claims still true
if the internal states are disconnected?
So are there any assumptions
about whether the internal states
are from a connected component
or can they be disconnected?
Again, two great questions.
So the symmetry that you speak about
is mathematically self-evident.
You're absolutely right that you could just swap
the internal and the external states around,
and which means exactly that the external states
are in some sense inferring your internal states.
That idea has been taken as the basis
of one understanding of niche construction.
So now you are looking at the environment as a system
that it's trying to learn about you,
particularly the denizens that occupy it.
So my favorite example is the notion of a desire path
or an elephant path.
So if you don't know what that is,
that I did in a few years ago,
it's the path that is worn through grass
where lots of people see a good shortcut.
So you're walking to work,
you want to take the shortcut to the coffee, the cafe,
and you take a shortcut across a grassy path
and you leave a record of that by eroding that path.
So, and then that has other implications
in terms of providing deontic cues for other people,
other creatures like me and you.
If somebody else is using it,
that's the good shortcut to take,
that's going to take you somewhere really interesting,
and it gets used more and more and more.
But from the point of view of the environment,
it's learning about the kinds of behavior
that the phenotypes in that environment
that have their internal and blanket states typically do.
So this notion of eco-niche construction
can be inverted to talk about the environment,
learning about the kinds of things that inhabit.
And you can take that even further,
just at least conceptually,
to actually look at the environment
as doing a particular form of self-evidencing
via Bayesian model selection.
So if you treat the free energy as an adaptive fitness,
then one way you can construe natural selection
is effectively a Bayesian model selection,
where each phenotype in the environment
now becomes a hypothesis.
And the idea is that the environment
is now trying to find the best model or hypothesis
for the kinds of creature or phenotype
that this environment or this eco-niche can play host to.
But that's a very environment-centric view of things.
Of course, the whole point of this
is that there's a circular causality
or reciprocal coupling between the two.
So that gets very interesting.
The other way in which that gets interesting
is when you actually partition the environment
into lots of other Markov blankets.
And now you have an ensemble of Markov blankets.
And that becomes important
when you think about populations of particles
that all have a shared form,
which means that they have a shared generative model.
So one way of minimizing variational free energy
or maximizing Bayesian model evidence
is to ensure that everybody else
is as predictable as possible.
So what that means is any ensemble of Markov blankets
that get together and attain some kind of steady state
must basically share the same hymn sheet
or generative model and language
which renders them all mutually predictable.
So then there's an interesting translation of that
into an encultured or sort of formal social setting
to understand communication and multi-agent systems.
The question about the,
do you have to have a large connected graph for?
I think most of the questions
about what kind of connectivity or adjacency matrix
you might find on the inside of a system
are probably best answered by reference to an old principle
which Ashby's good regulator theorem,
which says effectively that if you survive
in a given environment,
you have to be a good model of the causal structure
of that environment
or the controllable structure of that environment,
which in the, from the perspective
of what we've just been talking about,
just means that this generalized synchronization of chaos
between the internal and the external states
requires a structural synchronization as well.
So that the causal structure on the outside
has to be distilled and recapitulated on the inside.
So if you live in a world
which is deeply and hierarchically structured
because it comprises other people, for example,
then it has to be the case
that your internal connectivity
will also have that deep hierarchical structure.
And in turn, that requires there to be a lot of disconnections
and conditional independences.
So the hierarchical structure is defined
by the connections that are not there.
So your question about,
what is the connectivity architecture
dynamically amongst the internal states
is basically the same question
that people like me have spent their lives addressing
in terms of the connect them in the human brain
and trying to understand it's the hierarchical organization
in a way that reflects a causal structure
of the things that it has to recognize or infer.
Does that make sense?
Is that?
Thank you.
Yes.
Yeah.
Next is Melanie Mitchell has a question.
Thank you.
Hey, thanks so much for your talk.
I wanted to ask about your thoughts
about how some of these ideas,
especially predictive coding interface
with developmental psychology.
There's been a lot of work
about how the dynamics of learning changes
from infancy throughout life.
And I'm wondering if there's any testable predictions
that this whole framework can make in that area.
Yeah, that is,
I'm sure there are lots of testable predictions
and I suspect that some people are already embarking
on using predictive processing
in its sort of general sense to frame questions
about attachment, neurodevelopment,
the relationship between learning and inference
and indeed structure learning.
So the way that I look at this formally,
and we haven't talked about that previously,
is that the states, the internal states
come along in many different flavors.
So there are states that show very rapid fluctuations.
There will be states that stand in for things
that endure over time like contingencies and laws,
connection strengths, say the neural network
or synaptic efficacies in a brain or neuronal network.
And then there's a very structural form
of the genetic model that we're just talking about
in terms of a hierarchical structure.
All of these quantities should slowly change
to appear to optimize their free energy.
So in terms of structure learning,
one can look at that as neurodevelopment,
basically drawing the right number of neurons,
the right number of hierarchical levels,
get the right connectivity in place.
In terms of learning,
that would translate to associated plasticity
and inference would translate into belief updating
as mediated by synaptic activity
and message passing in response to ongoing stimuli.
So crucially, of course,
because we're talking about a system
that is performing a gradient flow
on the same functional,
on the same probability distribution,
everything is contextualized.
So what that means is you cannot learn optimally
unless you've got the right structure.
So the structure, which is usually evolved
over a slower timescale,
so neurodevelopment,
possibly even on the Rushi timescale,
puts the context in place for the learning
that in turn contextualizes
or provides empirical priors on the inference.
So with that sort of,
if you're like carving up the problem
of self-evidencing into structural learning,
parameter learning and inference,
then that makes some quite strong predictions
about what it must,
the challenges that say a neonate face
is when it is born into a world
and has to start inferring
the causal architecture of that world.
And I could go on and I won't because we're running out of time,
but a lot of work in this instance
focuses on basically realizing
that mum is a thing like me.
And from that,
you can start to develop a theory of selfhood
as you build models of your world
that are occupied and caused by things like mum
and then the realization sometime later
that perhaps I'm a thing like mum
and then you get selfhood
and then it all gets very interesting
from a point of view of attachment theory,
autism and possibly forms of self-awareness.
Great, thank you very much.
Thanks, Carl.
Next is Sarah Walker.
Hi, thanks.
That was really great.
I have two questions.
I think they're kind of related
and they're both more on the philosophical side.
The first one is just to try to understand more of your motivation
about why you think this is sort of a unifying concept
for understanding life.
Like why is that the thing to focus on about life?
And part of that is if you're thinking about the original life,
does it make predictions
that other theories about what the original life might entail?
Like could you test it against other theories
based on the predictions that you might make?
And then the other question is like based on your idea
that all things are marked,
like the definition of thing is based on this idea
of a markup blanket,
then that seems to suggest that like life is a very,
is on a spectrum of very general phenomena
basically based on how many internal states it has
and how much active inference it can make,
which means everything's sort of like a little bit alive,
but other things become more alive
based on how much inference they do.
And I just wanted to have you comment on
whether that was like the correct interpretation of the ideas.
Yeah, yes.
I think on both counts.
So the focus on the origins of life,
that is not a focus of the free energy principle.
So it's not that ambitious at all.
It's just saying that if stuff exists,
be it biotic or otherwise,
then it must show these properties.
It doesn't, in any sense,
tell you why these things came into existence
or the most likely trajectory that you would,
you would bring to the table to explain why they are possibly
necessarily emergent phenomena.
So there's lots of wonderful work.
I'm sure that you know much more about this than I do.
And asking questions about, you know,
why is this degree of self-organization
and delicate structure
possibly an emergent phenomenon?
And where did it come from?
That's not what the free energy principle is.
It's much less ambitious.
It's just saying if things exist,
as defined by the Markov blanket that enables you
to separate the thing from anything else,
then it must be the case that it can be interpreted like this.
The second question, I think, again, you're absolutely right.
And it speaks to the very first question that we have
during the presentation.
Interpreted like this means that there is a whole spectrum
of different kinds of sophistication of this kind of
self-evidencing ranging from small particles
through to political movements.
And philosophically, I think that that's a nice thing
because it gives you the opportunity to introduce
formally the notion of vagueness.
So again, I only learned about this in the past few years,
but the notion of vagueness, for example,
when does a pile become a pile?
Is it one, two, three, four grains of sand?
And once you say, well, actually,
possibly all most interesting things in philosophy
may be vague constructs.
And I think that's what you were saying
in terms of this spectrum.
There will be things from prions through to priests.
And at some point you're going to have different kinds
of generative models or put it another way,
it will look as if there are different kinds
of generative models that are accounting
for their gradient flows.
And as soon as you articulate it like that,
you can start to talk about generative models
of the future and planning and then generative models
that do and do not have the hypothesis that I am a thing.
And then you can get into philosophically
the notion of selfhood and self-awareness
and consciousness.
But it is all, as you say, exactly so you can't say.
It's all, as you say, on that spectrum
from small particles through to politicians.
Excellent, Carl.
Sorry, Sarah, thank you very much.
We have a little bit more time than expected,
which is nice.
So I'm going to jump the queue briefly to ask you,
this is a question that's sort of bothering me.
I mean, in the end, Carl, with your model
of the Lorenzo Tractor Adams, couldn't I just say,
in complicated worlds, everything's kind of correlated
with everything.
So one chunk of the world predicts another chunk
of the world pretty well.
And so therefore, I have an internal state
that predicts an external or has a model of it.
I can find some conditional dependencies roughly.
I can always draw boundaries.
What am I missing in that kind of deflationary account
of the first part of your talk?
I don't think you are.
And I don't think we've used the word deflationary a lot.
And I think it's quite proper to use it a lot.
I mean, the whole point of the free energy framework
is trying to reduce things to a simple,
a description of the way things are as you can,
and then provide a license or a motivation
or an intricate take on many things, usually in psychology,
but also elsewhere in the life and social sciences.
There are just manifestations of this thing,
a first principle account.
It's just the way things are.
If you want a slightly more, less deflationary answer,
then yes, you're absolutely right.
Then any interesting bit of active matter
is going to have Markov blankets.
And they're going to be a very large number
of potential Markov blankets you can play with.
So notice I had to specify which internal states
I wanted to tell my story about.
There was no room for that.
I could have chosen one of a million different combinations
of internal states.
I told a different story.
And then I ended up by saying, well,
this is just generalized synchrony,
as noted by Christine Huygens in the 17th century
whenever I think that, you know,
that's the right deflationary perspective.
However, in virtue of that generalized synchrony
between two manifolds on the inside,
sorry, on the inside, on the outside,
you do actually introduce a nice formalism
and information geometry that has a dual aspect.
So we've got the standard information geometry
that describes the probabilistic evolution
of internal states that would be apt for understanding
the thermodynamics of brain function
and say integrated information theory
if you were Julio Tononi.
It's about the actual internal states.
But because you've got this statistical mapping
with the other outside external manifold,
every point, every physical internal state
stands in for or encodes a probability distribution
over or about external states.
So there's another information geometry.
And this information geometry is much more interesting
because it's about something.
So you can now cast belief updating
or simply the thermodynamic or the physical movement
in some internal state space
or on some internal manifold
as literally movement in an information geometry
about the outside world,
that is literally belief updating.
And the metrics of that belief updating
can be articulated in terms of fish information
that can be reduced to things like precision
and the curvature or the free energy landscape
that directly translate into things.
How competent do I feel?
Or how much is my dopamine working in this brain?
So you can actually think of a long way
just by noting that this almost unavoidable
generalized synchrony brings to the table
this other kind of information geometry
which is inherently representational.
And now it provides you with a mechanics and a rhetoric
to talk about this set of internal states
representing or having beliefs about
that set of states over there.
So I would, you know,
that would be the answer I would give
if you were getting
bored with the deflationary perspective on this.
There's a lot of machinery at hand
that could be
usefully deployed to understand
a representationalist stance
to understand
how,
do I understand, our belief updating
in terms of this generalized,
in terms of generalized synchrony.
Excellent, thank you.
Chris is up next with more.
Thank you very much.
Yeah, thanks.
I had had, one of my questions was the same as David Kinney
who said that when you've, on the very first slide,
showed this network of nodes with arrows,
I assumed it was some kind of causal model.
And then I was confused.
Why do we need to include the children's parents
in the definition of the markup link it,
but you've already said that that has to do with,
that this is somehow a more dynamical thing
and not just a description of a joint distribution
in terms of a graphical model.
So the other question I wanted to ask,
and I guess the last two questions sort of got at this and,
I mean, I think, you know, there's always this,
this tension between metaphor and interpretation
and trying to nail down sort of,
is something, is a piece of formalism
a useful piece of mathematics,
or does it have sort of explanatory power?
Do you know what I mean?
Another example I saw recently was someone sort of
from the evolutionary biology side saying,
oh, we'll look a lot of equations with, you know,
some sort of lounge of undynamic,
some kind of flow plus diffusion look like the Fisher equation.
And so there's fitness everywhere and so on.
And there the question was,
okay, to what extent is this a metaphor
and in which systems would the word fitness
sort of earn its own way, right?
Pay us on way by actually being a useful interpretation.
And I think you've answered that question
in response to the last two questioners.
In my field, sort of there's this, you know,
people say, oh, well, are the planets computing their trajectories
or does it not really deserve to be called computation, right?
When does dynamics deserve to be called computation?
Or as Simon was asking,
and as Sarah was asking sort of,
when do correlations deserve to be called,
this variable has learned something about that variable
or is predicting that variable.
But so for instance,
to just bring this in for a landing
in your primordial soup of Lorenzo tractors,
where you had this sort of cell-like object
and the Markov blanket looked like spatially a membrane.
I'm just wondering if you had instead chosen
these other variables up in this corner of the figure
and chosen them to be the interior,
then if I understand the model,
they would have had a Markov blanket,
which is sort of around to them.
So could you in fact have chosen any part of that picture
to declare as the interior of the cell
and then whatever you focused on,
the blanket would have been a membrane around that,
or was there something in particular about that cell
in that region of the picture that made that,
those interiors is different from anywhere else?
Another wonderful question.
So the simple answer is yes.
I chose the eight cells that have the highest weighting
on the principal eigenvector of the graphoplasma
of the adjacency.
So there was something,
the largest connected cluster, if you like,
of those particular eight cells.
However, your point is more important.
I could have chosen any cell or any combination of cells
and you'd have got a very different picture,
but there would have been something consistent
about that picture, which you've also picked up
because the causal dependencies
and the dynamical coupling was local
because you had local interactions
that had a sort of one over two or three form.
That means all the coupling is local
and that actually produces a very, very sparse adjacency matrix
because I can only talk to the things
that are physically next to me.
And that inevitably produces the form of Markov blankets
that you were imagining in your head.
There's going to be the internal,
the active states and then the sensory states
are like the little onions,
which have this sort of spatial interpretation.
And that is a direct consequence of just the structure,
the causal structure of this little universe
where there is no action at a distance.
If you put action at a distance in,
say gravitational forces,
or maybe be able to see you,
things get much more interesting
and you destroy the spatial structure,
the simple cellular structure that emerges
from this particular kind of coupling,
which is basically a nearest neighbour like coupling.
Another aspect of that, of course,
is that you can not just take one Markov blanket,
but then you can take the external Markov states
and then partition those.
So now you have an ensemble of Markov blankets.
And then that ensemble can now have its own Markov blanket.
And then you get into a world of Markov blankets
of Markov blankets
to which the apparatus of the renormalization group
applies very gracefully
because you're conserving the dynamics at every level
or every scale.
So not only are there a multitude of Markov blankets
in that simulation,
but also there's a multitude of scales
I could have had now 128 of those little soups
and then 128 of those.
And at each level,
there would have been a Markov blanket.
There is nothing specific
about any particular Markov blanket.
In answer to your commentary upon your first point,
which wasn't really a question,
I agree entirely that the free energy principle
is not a theory.
It's a principle, it's like Hamilton's principle.
It is a variation principle of least action.
That may or may not apply.
If it applies,
then it can be applied to prune a set of process theories
in this application domain.
So that's where it's useful in that sense.
If you can say, well, predictive coding
certainly conforms to the free energy principle,
then you're reassured
that that's the right kind of process theory
to consider worthy of empirical test.
It may be rubbish.
It may be that the brain doesn't use predictive coding.
It uses variational message passing
or belief propagation,
both of which are, if you like, entailed
or to which you can apply the free energy principle.
But you have to go and then get the empirical evidence
for your particular process theory.
So in that sense,
the free energy principle is as vacuous
as the principles of natural selection.
It doesn't tell you why you've grown an eye
or why you speak French.
But at least it shapes the,
it constrains the particular process theories
that have to do all the actual heavy lifting
that have the expiry power.
Thank you.
Thank you.
So we only have time for two more questions.
It looks like I haven't been able to get to everyone on the list.
I'm very sorry.
But we have a question from Artemis Kaczynski,
who should have been a bit earlier.
Sorry, Artemis.
And then the last question will come from Aaron King.
So Artemis, please.
Oh, I had a question about this little model,
the simulation of active matter,
which I like because it's so concrete.
And, you know,
I think Simon already brought up that just when you have
interacting degrees of freedom,
things and Chris also says something similar.
You will get correlations and you will get some degrees
of freedom predicting other degrees of freedom.
That seems like a very generic phenomenon.
My question was at some point you said, you know,
and then the active, I believe you said the active degrees of
freedom will actually act to lower the entropy of the membrane,
thus preserving auto poesis or the structure.
And I was, I was kind of confused by this because it seems that,
you know, in stationarity, I mean,
if anything,
if anything would act to increase the entropy just as much as
decreased entropy, or we could say,
or they have to maintain the entropy the same.
I mean, these interpretations seem unwarranted.
You know, the stationary distribution is what it is.
It has the entropy it has. So I guess my question was probably
given this Markov-Blake's structure,
is there a notion in which, you know,
there's a directionality of the action of the active states?
I'm going to answer the last part of your question by agreeing with
you entirely. So I think, you know,
when I say that it looks as if the active states are minimizing
their entropy, that's disingenuous.
You're absolutely right that, you know,
the entropy in question here is just the appropriate
rational of the non-equilibrium steady state distribution,
which neither goes up nor down. It's just there.
That's its shape.
So if I was,
if I thought carefully about who I was talking to as opposed to
lecturing psychology students,
I would have used a slightly more careful language.
So there is no, the expected flow in the absence of the random
fluctuations around that expected flow will certainly,
if you took away the random fluctuations and you would collapse
to a point mass on that non-equilibrium steady state,
but that's not the point because the shape of that flow,
that gradient flow and the solenoidal parts is just a statement
about the shape of the non-equilibrium steady state.
And I think that's where all the deep answers lie in relation
to some of the other questions.
For example, that question about the vagueness of sophistication.
You know, very simplest is more the questions,
do planets compute?
So I think that the answer, the answers to those kinds of questions
are all answers about the shape of the non-equilibrium steady state
distribution.
And I'm pretty sure that that,
well, I'm sure that you have ideas about what constitutes
an interesting shape and a not interesting shape.
It could be a low entropy shape, it could be a high entropy shape.
I'm not sure that really matters.
I think it's much more to do with the two and three way
mutual informations between, amongst the internal
blanket and external states.
So I think that's where the shape information comes in.
It may be that you're going to need some measure of itinerancy
on the manifold that has the shape that forms the probability density.
Maybe that you can use information geometry or specifically
information length or the information entropy to say,
no, this shape, this system, this non-equilibrium steady state
with its Markov blanket really does think about the future.
And it's really complicated and it takes a long, long time.
It moves through many different probability configurations before it gets
back to a particular state like having a cup of coffee in the morning.
You know, it has cycle upon cycle upon cycle.
So I think that, you know, that's probably where the, you know,
the more challenging story is in terms of finding what characterizes
interesting bits of self-organization that could be cast as
automatic as opposed to stuff that just exists like, you know, the moon.
And I'm sure that in that information length or at least information
theoretic treatment and dynamical systems,
there will be an answer to the kind of question, does the moon compute?
And so if you define compute as a, you know,
moving bluing bays in belief updating through a non-trivial
information length over a trajectory of information length,
then you probably say the moon doesn't compute, but you do.
And you quantify that in a vague way just by the, you know,
the amount that you've moved on these information geometries
that in this instance, you prepare the system in a particular state.
And then it will move to its non-equilibrium steady state.
And then you can measure the information length on the statistical
manifold from the initial state to the final state.
And I think the interesting systems are likely to be those that
take a very convoluted trajectory and pass through many configurations
into the future before they actually end up in some distant future
in the non-equilibrium steady state from the initial state,
as opposed to things that snap back to the non-equilibrium steady state
almost immediately and are probably very trivial and uninteresting things.
Excellent, thank you, Carl.
We have, we're rather over time, that's all right.
We have time for just one more question.
Aaron actually says he doesn't need to ask.
So the next person on the list is Alison Herter.
So Alison, please go ahead.
Hi, thank you so much.
My, I'm a family psychiatrist.
And so when I listen to you talk,
I see everything through the lens of a family psychiatrist
and how relationships are formed and bounded by Markov blankets
and how a family develops and is shaped by the various Markov blankets
of all the individual people within the family
and also how the family is protected by its Markov blanket from the neighbors
down the street.
And I wondered if anyone was doing any work in this area,
other than thinking about it more metaphorically, which is an easy,
everybody can grasp the idea of a Markov blanket from metaphorically,
but I wondered if there was anybody doing more in-depth work
looking at interpersonal relationships and open and closed systems.
Yes, but not quite, not quite, I think,
the detail of the direction you're suggesting,
which is an exciting and important application of these things.
If you look at the work of Maxwell Ramstead, A-R-A-M-S-T-E.
Yes, I know his work.
Oh, good.
And he's got friends like Axel Constant,
who used to work with Eric Reitfeld in sort of theoretical evolutionary biology,
but particularly in terms of cultural niche construction.
There is some work in terms of communication and inferring what sort of person I am
in terms of attachment and systemic family dynamics.
But there isn't at this stage any work on actually family groups
and beyond family groups in terms of sympathy groups or community groups
of political groups.
I know that Maxwell has an international group of people who are interested in doing that.
So I would recommend if you want to find out who's playing this game at the moment,
I'd email him and get him to send you his favourite papers or his favourite people and ask them.
So two weeks ago, we were talking to economists who were interested in climate change
and sustainable ways of re-engineering or using Markov blankets to understand ways
in a sustainable way of reworking the way that we use electricity in California, for example.
It's all a little bit outside of my comfort zone, but there's certainly an interest in applying these things.
I should say that I'm also a psychiatrist.
So one of the reasons we do all of this work is to understand how the brain works
so you understand when it goes wrong.
So your false inference for me is the best way to understand the broken beliefs
that people bring to the table in the clinic.
Thank you.
Thank you, that's great.
Carl, thank you very much.
We should be good.
Michael Garfield says he's hoping to get you on the SFI podcast.
So that will be another chance for people to hear some of your work.
In any case, thank you very much for graciously coming on and staying over quite a bit longer
than you maybe expected to, but we're all very grateful.
And there are many applause emojis in the audience there.
So thanks very much.
And Carl, I'm sure you will hear plenty from us going forward.
