Okay, great. It's 10 o'clock. We should start. It's a great, great pleasure to welcome all
of the participants and in particular also Peter and Dustin to this master class on
condensed mathematics. I think there is not much more to be said, so Peter, the stage
is yours.
All right. Yeah, thanks a lot for organizing this event. I'm looking forward to giving
all these lectures. All right, so Dustin and I want to give some lectures about our project
on what we termed condensed mathematics. And so before I start to give some, so let me
first give some kind of overview of what we want to talk about each day. So we made some
plan. So today on Monday, so in the morning, 10 to 12, we will talk about just the general
theory of topoi. And then so once the afternoon session, I actually forget to start at two.
One 30.
One 30. Okay. One 32. I guess it's also not quite right. But anyway, so we will actually
talk about condensed sets and etc. Then on Tuesday, so again in the morning,
we will talk about the chronology of condensed sets. And some see how certain classical types
of nice topological being group like colloquially compacted being groups, how they embed into
the series of condenser being groups. And then in the afternoon, we'll talk about basically
the series of solid to be in groups, which is some kind of notion of complete condenser
being groups was very nice properties. Then Wednesday is some of the algebraic topology
day. So in the morning, I want to talk about what we call condensed anima. And I mean,
this notion of solidness, it also extends to, to spectra. And we want to apply this to
the case here, maybe of the complex numbers of the periodic numbers to where there's a
certain natural way to make seeming decent to condense spectra and then one can solidify
them and compute what this is. In the afternoon, we will see that certain spectra that studied
a lot in algebraic topology naturally actually have a structure of such a solid spectrum.
So one example might be more rather easier and so on. Giving a new perspective on what
it actually means that you have section of division algebra group acting. And actually,
our impression is that there's one lecture to free here, but probably while you realize
that it's good to have a free lecture to fill in some other stuff. So Thursday is a function
analysis day. So in the morning, we will talk about periodic functional analysis.
And in the afternoon, about real functional analysis. And finally, Friday, I mean, roughly,
we want to talk about a little bit of analytic geometry, but just a tiny bit. So in the morning,
we will have a more real functional analysis, probably. That can actually take a while to
get through this. And in the afternoon, we will discuss how this very nice framework
of dealing with functional analysis allows us to give quite quick proofs of some foundational
theorems about compact Riemann surfaces. I mean, that's very classical stuff, but we
want to see how many of the basic theorems are actually really formal once you have this
formalism, and maybe apply not just to Riemann surfaces, but more general complex manifolds
and so on. It's really quite flexible the framework, but we want to present this in the
simplest possible situation. Alright, so that's the plan for the week. So what is this
cause about? So this course about is about a different way to deal with topological spaces.
And we claim that in some sense, one should replace topological space at least in many respects
by something that's much better behaved as much as much better categorical properties that we call
condensed sets. At least when you use topological spaces to model some nice geometric object,
topological spaces are used to model other things. So they are sometimes also used to model,
say, homotopy types. For some reason, we started calling these things Anima.
And that's like a completely separate way in which topological spaces are used, and it's actually
very good to keep these completely separate. And within this language of condensed mathematics,
it's actually possible to combine the two things. And this will somehow happen, we will talk about
this on Wednesday, that there's something called condensed Anima, which mixes some kind of actual
topological space direction with an homotopy theoretic direction. So these are different things.
And yet another thing which topological spaces, some kind of generalization of topological spaces
that's important is what I call topoi. And these are again a little bit separate. So for me,
there are like three different things that historically are also come or modeled as topological
space. But for me, it's like three different separate mathematical concepts. One is some
of what topological space were historically meant to be. And I think these are better condensed sets,
because there's a much better category. There are also the different things that
they use as models for homotopy types. But to me, a homotopy type is not at all a topological
space. And then yet a different thing where they give examples for a topoi.
And but there is some kind of indirect relation again between topoi and condensed sets in that
condensed sets themselves are an example of a topos, except for set theoretic problems.
And so in any case, it's somewhat important to first recall a little bit about topoi
for this course. So it's a topic for my morning session is topoi. So those sites
and topoi.
So what is this about? So there's an abstraction
of the notion
of sheaves on topological space.
So let me recall a little bit about what is sheaf on topological spaces.
So let X be some topological space.
Then definition.
Appreciate.
Is a functor from
as a category of open subsets of X. So these form naturally a category where
most of them are inclusions. So between any two open subsets, there's at most one map.
Two sets.
So you.
Well, that's already the definition. And so they form in the category in the obvious way,
just a diagram category and then a sheaf.
Or next is a pre-sheaf.
Yeah, with a fine property.
For any open and.
For any open cover of you.
Let me write the categorical thing first and then explain it a little bit.
So the value. So the thing is that a sheaf is something that's somehow determined locally. So
the value on any you should be determined by the values on all the UIs and the way you say this is
that giving a section of F on you, you just have to give a section on all the UIs in such a way
that's a agree on overlaps. So if a few
is a set of all tuples, set of all tuples, S I
as the s is a sections on the UIs and
you.
We lost your video of your sound.
Thank you.
I'm sure that happened.
Um,
so,
whoop, whoop, whoop, whoop.
Sorry, what was I about to say?
All right. So there's a notion of restricting a section. So I mean,
the set F of U is called the sections of F over the open subset U.
And if I have a smaller open subset V inside of U,
then by contrary and funcularity of F, you can somehow restrict, you get a function from F of
U to F of B. And this is called restriction. So I just note this in this way. And yeah,
we want this to be determined locally. So what are some examples of sheaves?
So if, I don't know,
that's why is any other topological space
sending you to the continuous maps from U to V
because, uh, what does, I mean, what does, uh, so it's obviously contrary to the factorial
if you have an open subset, then you can just restrict such a continuous map to the open subset.
And conversely, and for the second part, why is it a sheave? Well, if you want to map
some topological space U to Y, it's enough to map all the open subsets Ui to Y in such
a way that the maps on the overlaps agree. And the maps are already continuous if it's continuous
when you're restricted to all the open subset Ui. So if Y is discrete,
these are the locally constant functions.
And this is known as a constant sheave.
It's usually called a constant sheave for value Y,
which is a slight misnomer when you first hear this story because it's not true
that for the constant sheave for value Y, that this is really
given by the pre-sheaves that takes any U to Y. Rather, it's locally constant functions only.
And what happens here is that you might try to define it in this way where you always send it
to Y, but then you realize that it's not a sheave because this property will not be satisfied.
But then there's a way to turn any pre-sheave into a sheave. And this is actually the
simplification of the pre-sheave. So this is also the simplification of the pre-sheave.
So in this sense, it is somehow the best possible sheave if you want something that's basically
just always Y. So what is sheification?
Yeah, so this is a very important proposition.
It's a fully-facelow inclusion.
So I write pre-sheave on X into sheaves on X, and I hope the notation is self-explanatory.
Is that explaining?
Admits.
I left that joined.
I think inclusion is in the opposite direction.
Sorry, of course. Yes. Sorry.
Thank you.
Sorry. Let's close the F-sharp vacation.
I guess there are several ways to seize this. One way would be to just deduce this from some
very abstract adjoint function theorem. Because I mean, both of these are certain very nice
categories. And functor commutes with all limits. Because if you have any limit of sheaves,
then it's again a sheave. Why is that? Because the conditions that it's a sheave,
it's a self-described only in terms of limits. Products are limits and equalizers are limits.
And so a limit of sheaves is again a sheave. And so this fully-facelow inclusion here
commutes with all limits and then has a left to join. But you can also just construct this explicitly.
And for this, let's have natural...
Well, actually, that's two ways.
So what you do, it takes a co-limit over all possible
covers of you. Offs is equalizer.
And then
F naturally maps to this. And this is an isomorphism. If this map here would be an isomorphism,
if F already is a sheave. But in general, of course, it's not.
One would hope that this might already be the sheafification, because in some sense,
you feel like you've enforced now that this is an isomorphism, except that
not quite, because you did it with... Here, it's still F, and here on the left it's F natural.
But it turns out that if you do this twice,
you actually get the sheafification. So here it is. I think it's the only case in mathematics,
which I know where, is somewhat doing something where you need to do some natural operation
twice to get a natural left to join. But I think the first operation makes it
separated pre-sheaf. Right. So what happens here is that the first operation
makes it a separated pre-sheaf. And then if you have a separated pre-sheaf, then it turns it into a sheave.
So
F of U injects into the product of F of UIs for any cover.
And then
this first operation will always make it separated, just because
yeah, this F natural of U is always determined by very local data, and it's quite easy to see
that this is separated. And if F is already separated,
then this operation will actually produce a sheave.
And so what happens there is that to check that this is a sheave, you need to check that certain
some equalizer diagram has the right property where you have some F naturals here.
I believe an analog of this, he said this doesn't happen, but for topological space is at least
linear ones. You can first do the house dwarfization, killing the closure of zero, and then the completion.
Yeah, but it's not the same function that you do there. I mean, of course, you can make things better
in steps, but that's somewhat do the same operation twice. And then I don't know.
Okay, so these are quite easy to check. And then
some of the way you construct this to be adjoint, it comes already with a unit map,
and that is an equivalent if you start with a sheave and then from these properties is quite
easy to see that this is really the left edge one. That's all I want to say, but
all right, so there's it.
Okay, now maybe let me talk about stocks.
So, for any x and x,
fx is a cool limit of all you that contain x, f of u, stock.
I mean, you can do this both for sheaves and pre-sheaves. And then
yes, the front proposition
that a sheafification does not change stocks.
Um,
and on the other hand,
um,
I don't want to say this, uh,
if you have two sections,
so if f is a sheave,
then s1 is equal to s2, different only for x and x. The stock of s1 and x is equal to the
stock of s2, and so on.
For for sheaves, all the information is determined at the stock in some sense.
Um,
right, so, uh, in fact,
all right.
And, uh,
yeah, again, let me, these are quite simple.
Okay, so, uh, so maybe the first thing I want to talk about really is commodity of sheaves.
Maybe I should first, I mean, like before, yeah, so for this, uh, of the bean sheaves, I should
say. So, I mean, for any kind of category, you can also consider sheaves of sets, but sheaves
of the bean groups and so on, so, and also groups of the bean groups,
uh, rings, etc. One thing that's nice about the examples I've given is that in all these cases,
um, for all these cases, there's a forgetful function down to sets, and this forgetful
function commutes with all limits. So, if you want to check that something is a sheave,
someone just check it on the underlying set.
And, uh,
so, I mean, regarding some of our exact sequences. So,
yeah, I can call this up x. So, this is the category of the bean sheaves on x,
sheaves of the bean groups, bean sheaves,
on x, where a bean sheaves is just a word for sheaf of the bean groups.
This isn't bean category.
You can check whether something is exact.
I'm checking on the stocks.
And,
and, well, again, there's pretty much a formality. So,
it's definitely true that some of our pre-sheaves of the bean groups form in the bean category
because it's just a function. So, you just have diagrams of bean groups and all kernels,
cork cones, whatever, it can all be computed on each open individually. And then you need to
show that when you pass to the sheaves, um, that all the good properties stay. And,
yeah, some of the sheification is an exact function.
So, I don't know. But you somehow have to be aware that when you form the kernel of a map,
then that is a limit. So, that's, you can compute this in pre-sheaves and it is a sheave.
But when you form the core kernel of a map, then you still, you have to sheaf your file again.
And so, only locally on stocks, you know that you get exact sequences still.
But globally on sections, you need not get such an exact sequence.
So, let me do one quick sample.
You might take for
x, the unit circle.
You can take for f prime, the constant sheaves,
uh, given by the integers. For f, I mean, some of the reals, meaning
U maps to the continuous functions. U to the reals.
Then, you can actually check that the quotient f mod f prime is somehow r mod z. And it's actually
really given by the function that takes U to the continuous functions from U r mod z.
Because locally, whenever you have a continuous function from U to r mod z,
then, well, locally it's contained somehow in some semi circle or something like this.
So, you can locally, you can lift it to a continuous map to the reals.
But there's no reason that you can do so globally. So,
if you look at f double prime of x, then this is the continuous maps
from x to r mod z. And because I chose x to be r mod z, it contains the identity.
And we have f of x, which would be the continuous maps from x to r.
And there's no lift of the identity on the circle to the universal cover, which is the real numbers.
Okay. And so,
so we see that there is a, that, yeah, this map need not be subject to.
I mean, it's even some kind of geometric reason here. And in general,
you should think that there always is.
Right. And so, this leads to the definition of homology.
Yeah, homology.
Yeah, this is function h i, which go from x, blank, which go from x to r.
That's the right right function.
Well, that's called h zero of it.
The global subjects.
And so, this is well defined
as the category of a BN sheaves in this case has enough injectives.
Um,
so if M is any divisible being good.
And you have any X in X,
then I X was staff M. And I will explain what it means in general, but
the thing that's on you, it takes a value M. If X is in you, it's your else.
This thing is injected.
Okay, so
and so then we get long sequences.
So, in particular, in the example,
we see that's the first homology group.
Of the circle with coefficients in Z must be non zero because
the example, the kernel of this triangle here was given by Z. And so the next term coming,
which will be the H one of Z. And this must be on zero.
And so more generally, it's amount.
If F from Y to X
is any map of topological spaces,
we get a pullback function.
And the push forward function.
And so how is this given? So F lower stars, the one that's actually easy. So the value of F
low star F on any U is just the value of F on the premature view.
And F upper star F on
So this is actually an instance where you need to chiffify this verification
of B mapping to the core limit of all
U that contains the image of B.
So what's the pullback of F? So the sheaf is actually hard to say what it is. But
what's easy to say what it is, is if you take the stock of
the stock of it at any point, then that's actually just the stock of it at the image point.
And generally, some of you want to section on a whole subset V, then you should start with
a section defined on a whole subset Q. Some of you want to have it defined on V by a little bit.
And then
then F upper star is exact. Defines us now on a B in groups,
sheafs of B in groups, you could also define it in the same way on all sheafs.
Now the pullback is exact. And F lower star is only left exact.
Actually define the right-right function.
All right, F lower star.
And you can actually also say a little bit more about what they are. They are the sheafification.
Now, some of what you would expect on, but obviously obvious extension
of this kind of formula to higher chromology groups. So you just send it to the chromology
on the pre-image of these coefficients.
For any opening in an X, you can consider the chromology of the pre-image and this
because you appreciate when you can sheafify again.
Okay, so if it makes the point, it's just a projection to the point.
Then
sheafs on a point are just sets or at the end groups in this case.
This is just the constant sheafs.
And F lower star.
It's a global section.
So what we discussed previously in terms of these global sections is just a special case
where your map is just a projection to the point.
Yeah, you have this picture where to any topological space X you can associate this
category of sheaves on X or you'd be in sheaves on X and then you have these
for any map of topological space, you get these pullback and push forward maps.
And actually when you think about topois and topois will be an abstraction just of the
category of sheaves on some topological space and then morphisms will be defined formally
in terms of certain adjunctions of punctures between the categories of sheaves.
So this will come after the break.
Let me just end by noting to further property to further structures that we have on
on a BN sheaves or two or three things.
So first of all, there's
there's free BN sheaves.
So for any
so I should say that
the forgetful function
BN sheaves
just sheaves admits a left adjoint
that I will formally write as f maps to the free a BN sheaves on on the set F
I will do not spicy adjoint F.
So if X was just a point, then you would take an a BN group here to the underlying set,
and then this has a left adjoint which somewhat takes a set to the free a BN group on that set.
And this also exists in the relative setting. And so this is the sheaf vacation
U maps to the free BN group on F of U.
And it's really critical here to the sheaf defy. So this
free sheaf itself will unusual be very far from being a sheaf.
And then in fact, there's some
notation. So if F is a free sheaf is always a sheaf
represented by some
U and X, i.e. F of B is
into you. So in general, you always have this notion of representable sheaves
like just take the maps into into some object in your category where you defined your free
sheaf zone. So in this case, you open subsets on U.
Then we write the adjoint.
And then you can actually compute the homology on some U of any sheaf F.
Let me write G here to avoid a little confusion.
It's actually canonically the same thing as the X group.
Is there some question?
In the category of the BN sheaves, I offer free guy on U into G.
This is not precisely the extension by zero sheaf of the constant sheaf on U.
Yes. Yes. Good point. In this case, it's just the extension by zero sheaf. Yes.
So in this case, it's actually, yeah, sorry.
Yeah. So and in general, these will be flat Z modules.
These will be flat Z modules.
Yeah, that's not, I mean, sorry.
Some of them as a pre-sheaf, they take torsion free values, flat Z modules as sheaves.
And then if you think about what sheaf vacation does, they would keep torsion free.
Keep torsion free. So it will definitely be flat.
I want to make the point that you can compute these homology groups here
in terms of just X groups in this BN category.
So you can somehow translate all the calculations into
this BN category here. And this will be quite useful later on when we do
some stuff about condensed BN groups or condensed sets.
All right. So you have these free BN sheaves.
Yeah. Let me also use some of this slightly fancy notation. It's
maybe not entirely justified in the simple case, but when we go to more difficult sites later on,
this will not at all be some kind of extension by zero function.
Then we have tensor products.
Okay. So BN category.
Not fixed. It's a natural symmetric monoidal.
Tender product.
Commuting these columns in both variables.
And so my F tensor G, the sheaf vacation
of
UMAPS 2.
And so again, it's critical
that
that you should be far here. So this appreciate you again, be very popular.
And
it also admits a partial writer joint.
Moving to our home.
Our home.
So this takes, oh, sorry.
Okay.
And so
it takes you to the homomorphisms.
from f restricted to you to the homomorphisms defined over you from one chip to the other.
So then the adjunction is that the homomorphisms from f into the internal home from g to h
is naturally the same as homomorphisms from f tends to g into h.
And in fact, there's a similar thing even on just all sheaves. Similarly,
sheaves on x, you have just a symmetric monodal structure given by product.
And also there you have a partial writer joint which is somehow
internal home in sheaves.
Again, it's given by the same formula.
But no homes in sheaves, not in the b in sheaves. So they are not forgetful fun to some of those
and still doesn't compute this. And the function that takes any
any sheaves on x to the b in sheaves is symmetric monoidal for these structures.
So,
I mean all of these properties are rather formal to prove and I don't want to go into this here.
So in this category of sheaves you have lots and lots of nice formal properties so you can
tend those and you can take an internal home and this all comes from a free order structure.
And this will actually when we turn to condense sets later, this will give us a lot of structure
just completely for free. There was a question why is the partial writer joint because somehow
there's a function of two variables here and I'm only taking the writer joint and one of the variables.
Like in usual topological spaces say, so if f and g, if you think of f and g here as topological
space, sorry, as topological spaces and there's this issue that topological spaces don't form
what's called a Cartesian closed category. So you don't have a home object between topological
spaces having the right property that having something else in this map. And for condense
sets, we will have these properties and they will just come completely for free while some kind
of general sheaves heretic nonsense. Right, before I make the break, let me end by saying a few
things about special case of compact host of spaces. So here's a proposition that somehow identifies what
what this co-mology is in the case of compact host of spaces so that x be a compact host of space.
And m say in a being group.
Define so if x is actually happens to be a CW complex.
So somehow you get it by successfully gluing in cells.
Then the sheaves heretic co-mology that we define for m agrees
with a singular co-mology of x with coefficients in m. So in other words, this kind of usual
co-mology that you would consider an algebraic topology is
agrees with this thing defined in terms of the category of sheaves on x. So somehow what happens
here is that when you do singular co-mology, that's a co-mology theory where you somehow let x vary
and then it's characterized by some properties. Whereas what we do here is we fix x completely
and then we let the coefficients vary and this how we define the co-mology and they end up defining
the same thing. In general, the co-mology on x agrees with what's called the Chesh call
module in x. So that's the co-limit overall.
So for any cover of x, you can write down the Chesh complex which is a following. So you can take
the product of the sections of f on all the UJs. You can take the product of all
J1 and J2. That's the value on the intersection.
And then there are certain alternating sum maps
that you can use to somehow continue this complex.
And so for any cover, you can write down this complex and you can take it as a co-mology group
and then you can take a co-limit of all possible covers of x. We're finding further and further
and then it turns out that this gives you a way of computing what's called a co-mology of MS.
This actually implies certain properties that we will need later on. That if x happens to be written
as a limit over certain xj, where all the xj are still compacting house both,
then the co-mology.
So because x maps to the xj's, there are pullback maps from sheaves on xj's to the sheaves on x,
which induce similar pullbacks to make some co-mology. And so the co-mology of all the xj's
will make compatibility to the co-mology of x. And that's actually an isomorphism.
So you can compute the co-mology of even large infinite limits.
So for examples, might apply if x is an infinite product.
Of copies of the circle.
And so something you see is that, I mean in this...
If you're in this setting, then for CW complex, you somehow learn that the more fundamental
object is actually homology instead of co-mology. So you first define homology, then co-mology was
a dual of it. And just with regard to homology as a more primitive object. But if you think that
co-mology should always be the dual of something else, then you see that this, at least naively,
can't be right in this setting where you somehow allow such infinite dimensional objects here.
Because here you have a co-limit of certain things. So in particular, for example,
the co-mology groups here would be countably dimensional. And it's impossible for the dual
of somebody being grouped with countable rank. And so this can't possibly be the dual of something
else in general, only in this CW complex. And then one final thing. If f from y to x is now a map
of compact cosmic spaces, then you can actually get a better formula for what
the push forward is. So in general, we just have this formula that you can compute the push forward,
you can compute the values, I mean, you can compute the stratification of the co-mology
and the pre-images. But here you can actually compute the fiber of this thing at some point,
purely in terms of, or the stock of this at some point, purely in terms of the fiber.
Because this is the same thing as a co-mology on the fiber.
And so this last thing is probably called a proper base change.
But it actually again follows from part three. So what happens here is that
you can think of the stock at x, well, it's a co-limit of all the open neighborhoods of the value
of f of the co-mology on the open neighborhood. So let me, I'm already slightly over time,
but let me just finish this thought. So this here is the co-limit
over all open neighborhoods of the co-mology of that inverse of u.
But there's also the co-limit over all when you bar in x closed neighborhoods.
Because in the compact house of space, the open and the closed neighborhoods are co-final.
It's a co-mology of the pre-image of these two bars.
And this is actually the same thing. Well, I say this for constant coefficients here,
it's actually true for all coefficients. So this is the same thing here by part three.
That you can somehow kind of write the fiber as some of the intersection of all the compact
house of spaces you get as such neighborhoods. Three in turn is somehow rather simple once you
have such complex things, such complex things. So it's also not so. All right.
Let me stop, make a break here.
Okay, great. Thanks, Peter. Sorry. Yeah, that was a question. So this
limit here should be co-filtered.
And so this is a filter code.
Good. Peter, should we resume in 15 minutes or 10? What is
