Thank you very much.
Thank you.
Thank you.
Thank you.
Thank you very much.
Thank you.
Thank you very much.
Thank you very much.
Thank you very much.
Thank you very much.
Hello.
Can you hear me? Yeah.
Hello. So, I guess we'll start in five minutes sharply and then I will do it for the introduction of them.
Just one question.
How would you pronounce your surname to be correct. Well, to be correct with the Iraq, that's the Spanish.
Yeah, you can say sirac.
I'm actually learning Spanish beginner level and kind of it's really hard to pronounce the sort of, you know, C with the use and like other Spanish countries. Yeah.
Yeah, you could imagine in Spain is like T H sirac something like that. Yeah, in the South American, they would say like an S sirac.
Yeah, much easier to pronounce. Yeah.
Are you currently in Germany?
Are you currently in Germany? Yeah, yes, yes, yeah.
I've been here already for 20 years.
Yeah.
I don't maybe COVID make possible to travel this much.
I cannot see you well so there is some echo.
Maybe it's my microphone.
I can hear you, but that's a lot of noise when you speak.
I will try to.
Oh, how about now?
That's much better.
Okay.
Thank you.
So your society.
It's built on. Yeah, so we are using sports talks, professors, everybody who wants to join.
So it started as a student society, so it's run by essentially mostly graduate students and then undergrads and yeah, we do a range of talks, inviting a lot of different interesting speakers, essentially for our own hobby and yeah,
it's essentially to show more about quantum information quantum computing essentially to people and other physics topics. So yeah, so we're not really tied with any department but
again, we're all students at like I'm a theoretical chemist, the president of the society's physicists, he's in laser and atomic physics.
So there's a lot of people around here.
Okay, yeah.
Okay, so a few minutes.
Slowly people are gathering.
I guess we were starting for the people here, I will just give a few different announcements. So before the talk.
Obviously, for people who don't know this is Oxford quantum information society. As I said before, this is a suit on that initiative initiative and essentially society that interested by quantum information computing and we deal out of different
and so really happy to attract different great speakers but we also do flash stocks.
Last year, we did one a few different workshops well this year but essentially not only talks but we organize different workshops for example introduction to quantum computing even for those people who are not really had an experience with physics
before and I want to essentially after I will done the introduction we're now will be having our society committee essentially elections at the end of this term.
So we're looking for people who would replace the current committee for the society for the next year, and hopefully, maybe someone who would want to contribute in organizing this events either from writing to different people,
maybe the talks itself setting up the zoom and seminars or hopefully maybe sometime in the future, doing the real life events or maybe helping finding different sponsors that could help us with money and other different things.
Thanks, welcome to join our society and come to the election so we'll now send out the form in the chat as well, we will have a few nice talks next week.
There will be one talk by Professor Jens Eiser on the topic towards closing the loops holds of showing of showing a quantum advantage.
It will be on Monday and there will be another really great talk when they're really great speaker, Professor Mikhail looking on exploring new scientific frontiers with programmable quantum systems.
And that would be on 4th of March, and I will also send out the registration links.
And today we're really happy, and not us but probably everyone who come here, we're happy to have Professor Ignacio T. Rack for giving us a talk this evening and Professor Ignacio has really prolific scientific career and he's one of the most probably
scientists alive currently and sure about him he's originally from Manresa, Spain. And in 1991 he received his PhD from Complutancy University Madrid.
And really really quickly after that he first was an associate professor at University of Castilla-La Mancha. And then he became a professor of physics at University of Austria and from 2001 he became the director at the Max Planck Institute of quantum optics in Germany.
And in 2002 he also became a honorary professor at the Technical University of Munich Germany. These two titles he has been holding until this day and he for as many contributions to science became a recipient of many different awards and honors.
Such as in 2016 he got the Prince of Asturias Award for Technical and Scientific Research in 2009. He got BBBA Foundation Frontiers of Knowledge Award.
In 2010 he got Benjamin Franklin Medal. In 2013 he got the famous Wolf Prize in Physics. Then in 2018 he got the Max Planck Medal from the German Physical Society and in 2018 he got the Quantum Computer Prize of the Missius Foundation, China.
His research spans many different topics and notably in quantum information, quantum computation and quantum many body phases. Yet today as you will hear he will focus on the last topic and tell us more about why it's really difficult to solve many problems and how these analog quantum simulators could maybe speed up this process.
Thank you for joining us and we really have to have you here today.
Okay, thank you very much. So I hope that you can see my screen.
Yep.
Okay, very good. Well, okay, perfect. So thank you very much for the very kind introduction.
And so I'm going to talk about quantum simulations and the difficulty of solving many body problems. So that would be not a technical talk even though at some points I will introduce a couple of technical terms.
But I would basically give you a tour on quantum simulation of many body systems. And, in particular, I will present some work that we did together with these people here.
So Yiming, Poritura, Sibiru, and my Canon manuals, all of them are or have been at our institute. This is the Max Plan Institute of Quantum Optics.
Okay, so let me start with something that you, your members of this Quantum Information Society should know very well is that there are some problems in nature that that very difficult to simulate and much more difficult than the ones that we are typically used to.
So one can say that simulating the weather or predicting the weather, it's very difficult.
However, there are some problems that are intrinsically more difficult than those and those are that appear in areas like chemistry or or physics, material science or high energy physics.
And the reason behind that is that even if you would make the simplest problem, the simplest model in order to study these problems.
Namely, one in which you just discretize a space in one way or another so that you have a lattice and in each side of the lattice you put the quantum system which is the simplest that we have like a qubit or a two level system or spin one half particle.
Then if we want to make any prediction about any of the systems with the simplest is very simple model.
Then we will realize that the, since they are described by the loss of quantum physics, then the physical information about these systems will be contained in what we call the state quantum state of the system, which would be in a linear superposition of all porous possible
configurations will have the configuration of our qubits, all of them in zero or all of them in zero one and two or one.
And we will have a linear superposition and everything that we are interested in when we describe the systems will be contained in these coefficients this complex coefficients here which characterize the physical properties of that system.
You can see right away that if we have n of these qubits, then the number of configurations that we have is two to the power n, and therefore the number of coefficients that we need in order to describe this quantum state will be two to the power n complex
coefficient. And so you want to do any computation with a computer, then you will have to store these coefficients.
And this means that you will have to have a memory that grows exponentially with the number of qubits that you have in your system and this number of qubits, you discretize space will be something like the volume so the memory resources in your computer grow exponentially with the
system that you want to describe. And in the same way, since you will have to compute these coefficients for each of the coefficient, you will have to do at least one operation.
And therefore, the number, the time that it will require to complete your computation will also scale exponentially with the number of qubits or volume of your system.
So we see right away that when we have these kind of problems that are many body problems where there are many particles like in this case there are many atoms or electrons in this case there are many atoms or in this case that they're also elementary particles.
Then we have to pay a price when we saw it with a classical computer, which is both in memory and in time, and both of them grow exponentially with the number of qubits that we have.
And this makes the problems very difficult. So as soon as we have something like 20 or 30 qubits, then we cannot simulate the systems and this is a very strong constraint to describe physical or chemical properties of the system.
In fact, one could, and this will be important for what I say later on, one could trade memory by time. So for example, what happens if I have a memory that only grows linearly with the size of my system or is constant.
I can't compute it with a constant memory and I cannot scale with the size of my system.
Then the you'll have to pay the price in time and the price in time. So it could be something like it's super exponential in n typically.
Now, I mean the message of these transparencies that simulating many but quantum many body system is very difficult with classical computers because this double exponential in time, or because you have an exponential scaling of the memory and time
causes with the number of qubits. That's something that is very well known already for many years and there are many people realize that and maybe the one who voiced it first was Richard Feynman in his famous paper of 1981, where he at that time he was
having problems in high energy physics and he realized that if you want to solve them with classical computers that's very, very inappropriate in a sense because this proliferation of coefficients and therefore these requirements that I mentioned before.
So at the time this was the late 70s beginning of the 80s so people just discover a quantum chromodynamics and standard model and things like that and they were trying to solve those problems with classical computers and they realized right away that it was very, very difficult and that's why this paper written by Richard Feynman.
And what he realized in that paper is that in fact you have a quantum many body system, you've better try to compute things using a many bodies a quantum many body system as well.
So what he proposed you have to solve one of the products that I mentioned before, instead of taking a classical computer with classical bits and trying to encode their this coefficients.
So why don't you use a quantum system which has quantum bits, let me a quantum computing see if in fact you call it quantum computer in which now you just use n qubits in order to encode the n qubits that you want to describe.
And similarly, you want to predict properties about the certain state of your many body system just take a quantum computer with n qubits and prepare the state such that you only need n qubits in your quantum computer and now you perform measurements and average.
You can also quantum physics, then you will be able to characterize the physical properties of that system. And you see that right away, you gain in memory, because, again, the, in order to store and curious you will need n qubits in your quantum computer.
The requirements are linear in N. And at the time, he did not care about time requirements, but now we know that there is also depending on the problem that we want to solve, there is also a speed up or an advantage with your user quantum computer in time so it may scale not
in N, but maybe linearly in N, or even maybe exponentially in N, but even if he could scale exponentially in N, since we have a linear dependence in memory, then we should compare here with this super exponential that I mentioned before.
So even if there is an exponential dependence in time, we will have some game with a quantum computer with respect to classical computers.
But something that is well known for many years, what has changed during the last, let's say five to 10 years is that now we have prototypes of quantum computers.
And let me distinguish two kinds of quantum computers, one of them is the digital quantum computer in which any operation is divided in terms of discrete operations, what we call quantum gates.
And there's another kind of quantum computer which is called analog computer, and in which you want to study one problem of the one that I mentioned before, what you can do is to take another system.
And this other system is a system that you can control very well this would be your quantum computer. And in this quantum computer you engineer the interactions between the different components of the system could be for example atoms, in such a way that they are
described, the interactions between your analog quantum computer are the same as the one that you want to describe.
So this is why it's called analog because you just replace the physical system that you want to solve by some system that you have in the lab and you engineer the interactions in such a way that it behaves like the problem that you want to solve.
In both cases you have this exponential gain in memory.
As compared to classical computers. And here, you will have to do things in a discrete way and here you want to study the problem then you have to do it in an analog way, and both of them are to some extent available nowadays.
In particular, you heard very well that we have now in several places in the world, and notably in Google IBM but also in Figuetti and many companies and universities we have these niche devices, which is something a little bit in between is a quantum
computer is can be space on gates. However, it's noisy and is a small but still, it may be able to solve some problems in a better way that the classical computer.
In fact, the Google experiment that took place one and a half years ago demonstrated that with this device, even though it's a kind of a prototype and it's noisy can solve some academic problem in a more efficient way than with classical
computers. So the problem I want to address is with the systems that are here either with an ideal quantum computer digital quantum computer or with an existing analog quantum computer or with an existing digital MISC quantum
computer. So can you solve problems in many body physics that you cannot solve with classical computers can these systems that already that are already available or will be built in the near future can give us some advantage to solve these
problems, many body physics with respect to the classical computers.
And so, now to formulate the problem so typically this would be problems in lattices so like I mentioned before this happens in a very natural way in promising condensed metaphysics in high physics this happens because you discretize space in chemistry then you can also put them on the lattice.
And at the end the problem is typically specified by Hamiltonian, which tells you how the different particles that are here in the lattice, which will be typically qubits fermions or particles, how they interact with each other.
So what I will assume through how this talk is that the Hamiltonian that describe this interaction is a sum of Hamiltonians that act locally. So for example, it could be a term in your Hamiltonian that acts here, which describes interaction between these particles and another term.
We describe interaction between these particles. What will be important here is that this is local even though many of the things that I will say also apply to the case where these Hamiltonians are not local but anyway so local means that act on a small region.
And we know that this finally any fundamental theory in physics is local because otherwise with parallel causality.
So, and so this is the problem, somebody gives us a Hamiltonian and the lattice and then we want to find properties physical properties describe physical properties corresponding to the system and these physical properties would correspond to either dynamical problems in which you start with some initial
state and then you switch on this Hamiltonian and then there will be some evolution and then you want to predict how the physical properties of the system change as a function of time. That's what I will call dynamics.
Or it can be thermal equilibrium you assume that the system has thermalized because it's in contact with environmental around it has certain temperature, and then I would like to compute what are the physical properties at this even temperature.
And maybe this temperature could be zero temperature and so I will specify also what happens when we are considering like the zero temperatures one particular case of thermal equilibrium.
And we will be interested, not in the whole state so we are never interested in the, sorry, in the whole state.
So the whole state doesn't be this two to the end coefficients this doesn't tell us anything we're interested in physical properties, which in quantum physics means an expectation values of physical observables or operations of operators, I will describe this more in detail later on.
So that's a summary of my talk.
So I'm going to talk about quantum anybody systems and algorithms for to solve this quantum anybody systems quantum algorithms for dynamical problems for zero temperature problems and then here, find out energy and temperature will specify what I mean by that.
So, but a particular attention to whether these algorithms can run already with analog quantum computers, or digital quantum computer with these devices so with present or plant technology, and also I would also, I would pay attention to whether these algorithms
have some advantage some quantum advantage so if the time that requires to solve a problem with the system scales linearly or exponentially or super exponentially with the number of qubits that you're trying to simulate.
Okay, so, again, we'll talk is about quantum algorithms to solve relevant problems in physics maybe in chemistry with existing and future devices, and I'll pay, I'll put pay attention.
So how they scale, whether there is a quantum advantage whether you will work better than a classical faster than a classical computer or not.
Okay, so I start with the dynamics so algorithms to describe the dynamics.
So that's a typical problem. So, again, that's the lattice somebody gives you lattice. And so it could be one two or three dimensions gives you a Hamiltonian.
So it means that specifies this local Hamiltonian so it tells you how the particles interact with each other. That's what is contained in this Hamiltonian.
It also gives you some particular state it tells you, let me start with some initial state size zero. And this initial state should be some state that is easy to prepare with your quantum computer, for example, a product state state in which each of the qubits has a well assigned
state example 0000 all of them are in the state zero.
And what you would like to know and it's, you want to compute the expectation values of some observable this will be some physical property so for example what is the magnetization here, or if you're interested in high energy physical
you can use the Wilson loop here, or to be the energy per particle any other property.
And you would like to compute this for the state that is dynamically a both according to a Schrodinger equation.
Okay, so physically this means that you start with some initial state, then you plug this Hamiltonian then there will be some changes that are described by this formula here, and you will have to know how the physical property changes as a function of time.
So what is represented here, and this is the physical property corresponding to one of these observable so one physical property.
And actually it's a problem for which there exists a quantum algorithm. This was proposed by a set Lloyds, back in 96.
And he basically translated finance idea into some quantum algorithm and showed that it was efficient that this is efficient.
And he said is okay so what I will do with my quantum computer is very simple, I will prepare the state side, my quantum algorithm will prepare the state.
And if I want to compute some expectation value but I will do that I will measure this observable in my state, and I will measure it many times.
So all the results and at the end I will take the average and the average, when the number of measurement is very large will coincide with this number here and then I can predict any observable in this way, just by preparing measure
preparing measure many times repeating, and at the end, I'll get what I want to compute.
So the question is now how did you do that, how do you now prepare your quantum computer in this state in the state that is a dynamically evolved, he proposed an algorithm for that, and the algorithm.
It's, it's relatively simple.
And so you can distinguish the algorithm for two cases the first one is very simple.
In the case now that's a little bit technical, when these Hamiltonians that are here, commute with each other.
Then this operator the exponential of the sum is equal to the product of the exponentials. This, this is only true if the Hamiltonians commute.
And you see that this you can read this formula like having some initial state, and then applying this operator here but this operator, it's just acting on some region because I say that is local.
So this will require some quantum gates, then the next operator some other quantum gates then some other quantum gates some other quantum gates. So it automatically tells you how your algorithm will work.
So you have to prepare your initial state and apply certain quantum gates, like the ones that are applied quantum computer you can decompose them into qubit gates.
And that's the algorithm.
Now, if the Hamiltonians commutes is typically the case these Hamiltonians on commute with each other, then you cannot do that.
And then what you use is a trick what is called totalization.
The first step is that you say that the exponential of the evolution, this evolution operator can be written as an exponential of h divided by m to the m power that's an exact formula, of course.
And then he took this, and then he said, Well, now you see we have h t divided by m, and let's take m very, very large.
What it means is that this exponent here, if m is very large will be very small.
And so you, this operator will be e to the power zero which is almost the identity operator, maybe with some corrections, and then you can easily show that it is true.
Then, actually, you can use the same formula as before, even though they don't commute.
Now you can approximate by the product of operators. And the reason the technical reason is that the commutator now that you're neglecting would be quadratic in one over m.
So it would be much smaller.
And so now you can read this formula also in terms of quantum gates what you have to do is to apply this quantum gate the next one the next one the next one, and then you will have to do it and times.
And what if you're out is that if I'm sufficiently large, then this will converge, they will give you the right result. And now you can check how m has to convert has to scale.
And so he came up with this formula says, Well, if the state if I want to make an error epsilon in the prediction of my observable remember that.
Remember that we wanted to compute this is the goal. And if you want to compute this plus minus epsilon with an epsilon error, then the time that your quantum computer will require would scale like the number of quits.
That's just the I mean some value depends on your local Hamiltonians is the operator know it's called the Hamiltonians time the times that you want to simulate square.
So you see that this case polynomially with n, like n square, and also polynomially with a time that you want to make the simulation. So it's extremely efficient.
This algorithm, because in a quantum computer, this would take exponential time, sorry, in a classical computer, this would take an exponential time so you see that that's an algorithm, a quantum algorithm, where with a quantum computer, you gain memory, because you only need
two quits instead of two to the n quits, and you gain in time because you don't require two to the n, but you require just n square. So there's a huge advantage in this problem for a quantum computer.
So after that, then there were many quantum algorithms improving on this idea now very different or based on totalization and the most efficient one that I know scales now like linear with them linear with T and the logarithm of one divided by the by the
arrow that you want to make. Okay, so the summary of that is that you want to describe the dynamics of a many body system you'd better use a quantum computer, because you have a big game with that very big game.
I think that this is the largest game that we have with a large advantage that we have with a quantum computer as compared to a classical computer.
And in fact, I mean not these algorithms that I mentioned but some similar algorithms could work with NISC and analog devices and that's why you look at some of the companies and also some people building this analog quantum computers.
Then there, I mean, one of the goals is to solve these dynamical problems with them because then they will have a very big advantage with respect to classical computers.
Okay, so this was the problem number one is starting the dynamics of this quantum many body system. Now, I'm talking about the other kind of problems I tell you now let's not consider dynamics let's consider equilibrium.
Let's imagine that you take your problem and you could your piece of material or your molecule you could it to zero temperature to very, very low temperature and we want to make predictions about the physical properties in thermal equilibrium and in particular at zero
temperature. Okay, so this is how we specify these problems. Again, we are given the lattice. We are told how the particles interact with each other through this Hamiltonian.
And now you take this Hamiltonian and then you compute the eigenvalues and they will give you the spectrum will tell you what are the possible energies in the system and then they will be discretized because we have a finite system.
So we are interested now in this lowest energy the state here the corresponding eigenvector to this Hamiltonian of this eigenvalue is called the ground state and corresponds to the state at zero temperature.
We want to compute properties of this state. So again, somebody gives us gives us an observable and wants to make a prediction.
What is this observable now at zero temperature so mathematically it means that wants to compute the expectation value of this operator in the eigenstate size zero of this Hamiltonian what is called the ground state so we should do this operation with the system.
Now the situation is very, very different from the one that we saw in the dynamics, because it's not already for many years that this problem is very difficult is you, you can probably know, then you can classify problems in how difficult they are.
You can solve it with classical or with quantum computers there for example, the class of problems that can be solved in polynomial time with a classical computer decision problems.
There are the ones that cannot be solved in polynomial times with a classical computer can be checked in polynomial time, and then there are the ones that can be solved in polynomial time with a quantum computer.
So this is like the, the, the same, the counterpart of P for a quantum computer, and then there is this QMA, which is the counterpart of NP with a quantum computer so these are problems that cannot be solved in polynomial time with a quantum computer, although they can be
checked in polynomial time. So these are difficult problems either for quantum computers and it turns out that the problem that just spelt out here belongs to this class.
So it's very hard. So this means that the computational time in a quantum computer would scale will scale exponentially with the size of your system.
Okay, no longer polynomially, like the case of the dynamics. So that's a very difficult problem here for a quantum computer. Still, I mean you have to compete still we gain in memory.
So the third comparison would be this time with the one of a classical computer that has the same memory and then it was super exponential so still there is some game.
I mean, it's not so good that that's a game. That's still exponential.
Nevertheless, so let me give you an algorithm. Let me tell you how they work.
A very, and a very intuitive algorithm to solve this problem. So you think about that is not so simple. Okay, to take a quantum computer and to show how can you prepare this ground state.
How do you convince the quantum computer to find this eigenvector.
And one idea is the following so I'll explain it with a little bit detail because it's very simple.
You consider now all the possible eigenvectors, eigenstates in and the corresponding eigenvalues in. So this will be all these energy levels here.
And as you know, they form a basis.
And if they form a basis, it means that any state that you give me can be written as a linear superposition of the states.
And the number of states that you have will be two to the power and right because this Hilbert space has two to the dimension two to the power and you haven't cured with corresponds to all possible configuration so
basically can write any state as a linear combination of those.
So what you do is that you create a random product state so you take here and then you put some product state some state for example zero plus one so here zero minus one so here zero here.
I know the square root of two zero plus something one whatever so you just take random states everywhere.
And then you take random states you can always write this product state as a linear combination like I wrote here.
And now what you could do is to measure this observable this is an observable so in principle, it can be measured. So now you can measure this observable in that state, and according to the loss of quantum physics that you learn in an undergraduate
physics, then you measure this observable you will obtain as an outcome one of the eigenvalues, and the probability of obtaining these eigenvalue would be just the absolute value of this corresponding coefficient alpha square.
And if this measurement is filtering, we measure the energy, then the state that you will have after the measurement will be just you measure the energy in would be the corresponding eigenvector so you would project corresponding eigenvectors.
So what you can do is that you can just measure this observable and of course you will not obtain the ground state so you will obtain certain energy.
And so you note this energy so this is you want the first one, then you prepare the same state and you measure again, and then you will obtain another energy.
And then you repeat it repeat it repeat it repeat it repeat it many times how many times. Well, an exponential number of times in such a way that you are mature with a very, very high probability that in one of your outcomes you had the ground state is zero.
Because you don't know what how much is zero. So you repeated many times many times sufficient that you know that you have for sure one of the times it was this is zero.
And then you just take out of the possible values that you annotated you take the minimum one, and then you will know that this is the ground state energy.
And once you have done that, then you continue repeating the experiment, and you wait until next time that you measure you obtain this value is zero.
And since you know that this is zero. Now you know how much is zero because you check it before. Now when you measure your zero again just by chance, then you know that the state that you will have prepared will be the ground state.
And once you have the ground state, then you measure this expectation value. Now you have to repeat it many times. And at the end you will have answered this question.
So now, so the question is how many times you see what is the probability that I obtained the ground state, and you can easily check that you have a random state.
Then this alpha n will be typically one divided by two to the n half so the probability which is the square of that will be one divided by two to the n.
So it means that you will have to repeat it this, I mean, two to the n times times something in such a way that you make sure that what I told you before is true.
So it will be like some n times two to the n, the number of repetitions so it scales exponentially within the number of repetitions, because it has to be exponential.
Because I'm sure is a problem QMA. And therefore, I mean we expect that this will be exponential.
Okay, so the number of repetitions and computational time is one divided by the probability, which is what I told you before time some, I mean, you have to repeat it many times.
There will be an extra factor in front.
Now, actually, this is not going to work as I explained you. And the reason why it doesn't work is because I told you just measure the energy.
So measuring the energy is not something that you can do right away. So if I do this observable is very complicated is a sum of other observables.
So probably, you know how to measure each of them individually.
And therefore, measuring this H cannot be done you can measure one of these observables, but if you measure one of them, then you will not project your state, you will not obtain this energy with this will not work what I told you before.
And this is why this algorithm doesn't work like that.
So, we cannot measure the energy, but only this term separately, and this is not equivalent to measuring this observable H that you use the rules of quantum physics, but instead with H with one of these hn, then you will project it to an eigenstate of this hn, but this is not the same are the
of the H. So this is not going to work. So this knife algorithm doesn't work, even though it scales very badly in that's not even work like that. So you have to do something else.
And what is this something else. Well, fortunately, I mean there were some people in the 90s that developed some algorithms to measure the energy.
So there is an algorithm that is due to Alexei Kitayev that tells you that you have some state here.
And this state is an eigenstate of a Hamiltonian, what in order to measure the energy what you can do is to add some auxiliary qubits, all of them in zero.
You can do some circuit in front so how the more transformations and control unit dynamics do some quantum Fourier transform and measure at the end is auxiliary system.
And so what will happen actually, what the circuit it does is that it takes your state, if this is an eigenstate in you evolve according to this operator and control to the other qubits.
And what will happen is that you use your eigenstate doesn't change, but in the encilers, it will appear the energy.
Okay, so this algorithm takes state and writes in this auxiliary register the energy.
I mean, and first of all, be careful there are many details but that's basically what it does. And the only thing that you have to be able to do is to be able to both to apply these gates apart from hallmark.
You're not able to do these gates, but these gates correspond to some evolution.
And this evolution we know how to do it because that was the first algorithm that I told you that was the dynamical algorithm so you can use now the algorithm that I mentioned before the one by Lloyd or the one that was developed later on to put it here with everything together and now you can use it with what I told you before.
And then you will have your product state, that's the random state. It's a random superposition of energy against states.
Then you run through this algorithm you use the superposition principle. So you copy here now the value of the energy in this auxiliary qubits. And now we just measure these auxiliary qubits, and then you will get the energy, and now you can do what I told you before, you will get some value.
You get another value, you repeat it, you get another value until you are convinced that the value is here is there. And once you have that, then you repeat it until you get again this value and then you know that your state.
So this algorithm works indeed.
This is the experiment of this algorithm that is to use yet another very famous quantum algorithm that is due to Robert and it was formulated in a different way that is much more useful by these people here is called amplitude amplification.
The idea is that if you have this superposition, and then you would like to measure the energy then the probability that you get the ground state energy somehow will be like absolute value of alpha square.
Instead of doing so you will have to repeat it one divided by alpha square times instead of doing that, what you can do is just discover algorithm and then will amplify the coefficient corresponding to the ground state energy.
And if you do something like that, then you can repeat a number of times that's case like the inverse of alpha zero, but to the power one, not to the power two.
So this is more efficient.
So it means that in practice, now you can build an algorithm to find the ground state energy, just using the method that I told before with face estimation with amplitude amplification.
However, there's still many details that I were hiding behind. For example, for the face estimation, what I told you would work you have an infinite number of ancillas, but you don't have an infinite number of ancillas so you cannot get the energy to all possible digits.
Okay, you will have a finite number of digits. And then there are many details and if you put all the details and you do the calculation.
Then you find that the first algorithm in which you do only face estimation, the computational time is case like two to the power two and divided by epsilon where epsilon is the error that you're going to make.
And you measure this observable. And the one that includes amplitude amplification with juices. Also, the growers algorithm, then scales a little bit better is case like two to the power three and divided by two.
Okay, so again, when this is a very trivial algorithm that use some other algorithms, and this shows a little bit how quantum algorithms are built nowadays.
So it's not that you discovered a new algorithm, you want to solve a problem then you take a little bit of an algorithm that exists from here another one from there then you add something and then you look at how it scales you optimize it and then you add one of these algorithms.
So it's not that you can do quite better much better than that. There is a more sophisticated sophisticated algorithm. That's what is called a filter method that we propose some time ago, in which now the computational time is case like two to the power and
it's case like the logarithm of one divided by the error, not like the one of the other the error and skates like this delta and this delta is this gap is called a gap is the energy difference between the ground state and the first excited state.
This case like this quantity here. So if this gap, it's polynomial in then so it may decrease as a function of M.
Then this will give you a very efficient algorithm. However, if this gap scales exponentially within so it's like two to the minus M, then this will scale like the previous one so that's, that's an advantage as long as your gap is not exponentially small.
There are these systems that I was mentioning that appear in physical systems and in many of the systems and so on. So the gap never goes exponentially down.
And even when you have for experts when you have a phase transition or quantum phase transition, then the gap typically in critical systems this case like one divided by the number of qubits or one divided by the number of qubits case in which case this provides you an advantage.
So the first state of the art of the algorithm is exponential as it should be and I want to describe a little bit this filtering method.
And I will give you just some of the ideas I will flash some of the ideas. And again, so it's based on first taking a random product state like before.
This would be written as a linear superposition of the eigenstate. And now what you do is that you filter the state in the same way as you filter light so you have a light which has many colors and you have to have only red light and you would have filter and only the red light will come through.
So the idea is very similar. So you have a linear superposition of all possible states with your product state and now what you can do is that you can filter this.
So you can just get rid of the energies that are here or the superposition the terms that are here and the terms that are here.
And then you can be done just by applying this filtering operator to your product state, and this filtering operator is nothing else like a Gaussian, which is center at this energy.
Okay, so you apply this operator here, you can check right away, you put it here that this is what we'll do out of the linear superposition of all of them with the random state you will end up only with the ones that are around this energy.
And, okay, so you're going to do that, when you do that, then now that you have filtered and you can measure this energy and do something similar to what we say before.
Now the problem where is the problem the problem is that this operator that is here is not unitary. So this means that it doesn't correspond to some quantum gates set of quantum gates.
What you can do is like what you do in optics, the euphoria transform. So you write this operator as the sum of operators in the form e to the minus xt that's like the Fourier transform of that can write it as a sum.
And then you see that what you have here is like a linear superposition of evolving according to different times.
But this is the evolution operator. So again, this is the dynamics. So you see that you can implement the dynamics of your system with an algorithm and there exists one.
And you know how to do superpositions of dynamics, then you will be able to implement this filter. And in fact, that's something that there are algorithms that do that.
In fact, it's possible now to create this algorithm. And now that's the way it works. And so, at the end, you even use this face estimation and amplitude amplification to speed it up.
And that's the way that you get this scaling that I mentioned before. So it's a combination of what I told you before preparing random state using face estimation amplitude in adding this filtering this, this Fourier kind of part.
And then you get a better scaling that shows you also that there are people who do that to take some algorithms and then improve these algorithms improve the performance just by adding new pieces.
I mean, the problem is that unlike the dynamical algorithms that I mentioned before, this cannot be used with analog and these devices. So the fact that you can prepare superpositions of evolution and things like that requires auxiliary system gates and so on.
So it's very, and you will need a full tolerant quantum computing and scalable quantum computing with that. So this doesn't work in practice.
However, as you probably know very well, there exists some heuristic methods that work with these devices and with analog simulator. So one of them is the adiabatic algorithm, in which, instead of trying to aim at the ground state just by measuring and producing a random state
you start with some state, and that is one known for example a product state and then you change your Hamiltonian is lonely and you try to drag along the state in such a way that at the end, you end up with a Hamiltonian that you want to solve.
And the state is the ground state of that system.
So this adiabatic algorithm is heuristic, meaning that nobody can promise that you that it will work. So you don't know what is the time that that will take their variational quantum algorithms.
The variational algorithms are also heuristic the idea is to prepare, you will apply some gates, and in this case you, you optimize the parameters of the gate in order to minimize the energy, and if you do that, then this may work.
And I mean the good part of these two algorithms for finding ground states is that they work with NISC devices.
The good part is that they are heuristic. So, I mean, may not work in practice.
Okay, so now I move on to find a temperature so I remember that I first say quantum algorithms to describe the dynamics of your system, then quantum algorithms to compute physical properties of the ground state.
And now this one to find physical properties of finite energies, or finite temperatures. And so what I will do is that I will formulate a little bit precisely the problem that I want to solve.
And then I will tell you so how classical algorithms of this problem, I will give you just a very overview, brief overview, and then I will tell you how with a quantum algorithm then you can have an exponential speed up also in time for some of these problems.
Okay, so what is the problem so the problem, roughly speaking, is that now, instead of computing the expectation value of some of several in the ground state and you would like to do it now with some state that has certain finite energy is not the ground state
but is somewhere in the middle of the spectrum somebody tells you I want that this energy what are the properties of states of that energy.
Okay, and to formulate a little bit more precisely I have to tell you something about now Hamiltonians and the spectrum. So, again, you remember that I had here, what was the spectrum so all the energies of the Hamiltonian.
Now I put them horizontally so this is what is the spectrum here I brought the energy, and since we have a finite system then we'll have all these discrete energies and then there will be two to the m in total because we have in curious.
Okay, so again so these are these energies these values of the spectrum so you recognize here this is the ground state.
This is the lowest energy.
And this would be the highest energy. And now we are interested in some energy that is here somewhere in some somewhere in the spectrum and we'd like to compute now the same as we did for the ground state for this energy.
So, now, what happens if you take the Hamiltonian and then you draw the spectrum, like I did it before. Then, if you start increasing the number of curious, then, of course, they are two to the n states or you will have to fill.
I mean, this will be filled, and then you will not see anything you will see just everything is black. So this is why people just study the distribution of the energy, but something that is called the density of states so what you can do is that you can take some
interval and count how many energy eigenstates are in this interval and you plot it then you take the interval you move it to the right and plot how many states you put it to the right.
And you see that in the interval as I'm moving to the right there are more and more states. So here in the center there are many states.
And then if I go to the right there are less states and if I go to the other boundary and the energy the rest of this plot this curve here, which is not so smooth in practice because you have a discrete spectrum is what is called the density of states.
If I increase the number of qubits now we'll have to to the end as I told you before and you don't see anything but the density of states what happens is that will grow in this one.
And it's very easy to show that if you have a local Hamiltonian so the Hamiltonians that I was dealing here, then this density of states will be centered somewhere in the spectrum and has a width here that scales with the spirit of the number of qubits.
Now, another concept that I need to define in order to describe what is the problem that I'm addressing here is that of energy density.
So the energy you learn in some dynamics and statistical physics that is an extensive quantity. So you see here you have a Hamiltonian, the Hamiltonian has n terms.
So the total energy would be the sum of n terms so we proportional to n.
And so this is why the total energy is proportional to the number of qubits that you have typically this case like total number of qubits because this is the number of terms that you have here.
So what you're typically interested in physics is not the total energy by the energy per cubic and to do what is called the energy density so you divide the energy by n.
So instead of plotting here the energy of the spectrum like before, let's divide by n.
And so what will happen now is that the density of states that we had before since we have divided by n and before this has a width, which was a square root of n, you divide by n, then the width is like one divided by a square root of n.
So you plot here the energy density as a function for different values of n, if n increases then you see that it's getting narrower and narrower.
So the density of state is getting very, very narrow and in the limit and going to infinite what is called the thermodynamic limit we'll get something like a delta function there.
So all the states are then concentrated in some region.
And so the problem that I want to solve is the one of finite energy so I will give you some energy density here.
And I would like to compute physical properties of states that have this energy density, and I would like to know what happens if I scale and I make it n larger.
As you can see, that's, that's a problem. And that's, that's a kind of a bottleneck because, as I increase n, I mean there are less proportion of states here.
Right, because it's getting narrow narrow imagine that these are Gaussian and there will be a tail here and there are few states here so very difficult to get them.
And that's why this one will be difficult in general.
Okay, so now we can formulate more precisely the problems for the mathematically oriented audience.
So, somebody gives you some energy density. Okay, so it gives you this small e and fixes that.
And now, given this energy density, the precise formulation is the following.
Okay, well, the first thing that you notice is, well, you would like to compute the value of somebody is used an observable, and you would like to compute the expectation value of this observable for states which have this energy density.
And here, since this is a discrete spectrum, there is very unlikely that you choose, well, the probability zero that you take one energy here, it will be an eigenstate there.
So what you will have to take is some width. So what you would like to find is some state, which has a mean value, the energy that I gave you. Okay, so the total energy e is like the one that I gave you times m.
We compute small e, we compute capital E.
With the capital E, you have to find a state which has this expectation value of the energy and has a variance, which is this quantity here, which is proportional to some delta, so prescribed delta.
Okay, so now we can formulate it again.
So I give you some e energy density, I give you an observable, and I give you some variance, and I give you some prescribed precision so I would like to make an error epsilon in my computation.
So what I would like to know is this quantum algorithm, in order to do that, what is the computational time and how it scales with N, and also with epsilon and delta, especially with M.
So now you can also ask, so what is a reasonable delta.
Okay, because now I'm telling you that there is a variance, so should the variance be N or 22 or something.
Again, I mean some physicists have found that for relevant physical problems, then this delta has to scale like one over N, so keep it in mind. Okay, so this problem one is compute the properties of a state which has this energy and has some with some variance here, which
is of the order of one over N.
And this would be a relevant physical problem that we want to solve in computing, we want to know how this scales with N.
A second kind of problems is very similar, but now it's what is called in thermal equilibrium so it's what called canonical ensemble.
What we would like to do is to take now, to weight each of the states in the spectrum by this Gibbs distribution by this Boltzmann distribution with a probability that this case like e to the minus the energy at some particular point.
What we would like to compute now expectation values of average values of the expectation values with respect to all possible energies but weighted with this factor, this is what is called the computation with the Gibbs state.
Okay, and so this would correspond to the physics physical properties and so given temperature which is the parameter that tells you how is this exponential here.
And we let it more mathematically somebody gives you a finite temperature.
So what gives you an observable. The goal would be to compute the expectation value of this observable with the Gibbs state the state that is like that is described by this density operator from some prescribed error.
Right, and you would like to know how the algorithms case with N with the size of your system the number of qubits and also with epsilon and the temperature.
So, again, this was the formulation of the problem, you want to compute now physical properties, finite energies or finite temperature so this extends what I was telling you before it's not zero temperature now can be zero, non zero
temperatures or finite energy is not against the energy.
Very briefly, so classical algorithms, so there exists classical algorithms for solving these problems. And for example, you can use something that is called tensor networks, it's a very practical technique.
So for example, for one dimensional system, when your lattice is in one dimension that's the best method that exists for solving this kind of problems.
And then you can show that this classical methods to solve this problem that I mentioned before.
For the end finite energy, the one that I told you before this case exponentially with one divided by delta and remember that in the problem I had to specify the variance.
It's still exponentially with one divided by the variance of the, the smallest the variance that the longer it takes. And, as I mentioned before, to obtain relevant physical information with the delta of the order of one divided by N.
And so you plug it here. You see that this classical algorithm is called is this case exponentially within.
And this, this means that in general, this problem that I was quoting before this problem number one of computing properties at finite energies with a classical computer is case exponentially with the best known algorithms.
There is another kind of algorithms that are very famous classical algorithms is called quantum Monte Carlo but is a classical algorithm is for a classical computer.
Which is especially suitable for final temperature. And what it does is that it samples configuration. Okay, so it takes the, I mean, the states of the qubits randomly, and then chooses another one randomly computes expectation values and then the probability
distribution, according to which you're sampling. Okay, it's the one that you have to calculate, and there is a method for doing that.
And here in many problems, this method of sampling doesn't converge. And this is problems that are called that have signed problem.
And in this case, these Monte Carlo algorithms require an exponential time with the size of the system. So, say from the point of view of many body physics there are two kinds of problems for Monte Carlo quantum Monte Carlo, some of them have no sign
problems. And then quantum Monte Carlo works wonderfully well. And the ones for which there is a sign problem for which name this algorithm. It's very bad, because they have designed problem doesn't work and many problems are like that have designed problem and that's why quantum Monte Carlo can work for all the
Okay, what about quantum algorithms.
Well, the first thing that you have to notice is that the problem that I mentioned here, the one of the finite energy or the one of the finite temperature, both of them include the zero temperature.
Okay, because if I give you as the energy, this energy here, then this would be the ground state energy, or if I give you zero temperature, so there will be a picked here.
There will be what happens with the ground state. So, it means that in general for generality, these two problems are QMA hard, so they will be exponential.
However, have we increased the energy, so we'll be taking larger and larger energies or air or temperatures that it may happen that then the problem jumps from here to here, and then it's polynomial and that's what I want to show that if you increase the energy or you increase the
you can avoid the problems that you have with classical algorithm and have even an exponential, the quantum advantage with the systems.
And so, get this will be the last part of my talk in which I will tell you about these algorithms.
And, okay, so again, that's the problem that I was mentioning before, somebody gives you some energy density.
You have to compute physical properties at this energy density, as you increase the number of qubit you go in this direction.
And so the algorithm works as follows. So first of all, it takes a state that is easy to prepare and has this expectation value of the energy so you're giving this energy E.
And it just prepares some state which has this energy, however, it has a width which is much larger than that.
And this would be a state that your quantum computer could prepare, however, it's not the one that solves the problem, because I told you that I want to state that has this mean energy but has some width delta some variance delta.
So for the second step, what we do is the same thing that you with it before, and that you do with light. So you want to make the spectrum.
Let's put a filter. So we will put a filter spectrum filter that would make this much narrower and to the desired value of delta.
And the third point is that, instead of creating the state, instead of saying, okay, let me just create, take the state and do something and create some state and then do a measurement actually we do something that is more clever than that.
So we will use this quantum computer, not to create the state but to compute the things that it requires in order to calculate the physical properties I will I will explain in a second what I mean by that so we will not create the state, because this requires.
I mean, some resources that for example they are not available with these devices or quantum simulators and we'll do it in a more efficient way than that.
Okay, so now, let me show you the first step. The first step is take first state that is physically easy to prepare and that has this energy, for example, a product states, maybe there exists a product state that has this energy, and therefore just prepare the state.
You can see your many body system and prepare a product state, and it's very easy to show that this product state that you prepare, then it will have a width here variance which is proportional to a square root of n that's very big.
So this is why that's not good enough for the problem that we're trying to solve because we want to have something not only that has this energy, but also that has a very, very narrow here and that's will be very, very, very.
Okay, so now is this always possible to do that so is it always possible so if I give you some energy, let's say so.
I mean, energy density. Can you always find the product state for example that has this energy. Well, actually, this is only true.
If the energy is smaller than some prescribed values, for example, for the ground state this will not work in general and it shouldn't work because this is a problem that is good and may harm.
We want to have something efficient. So they would be some energy such that if the energy is larger than this one.
And it is always possible to do that. And so now we will concentrate on these energies, because for those energies, this algorithm will be efficient.
And so this gives you a restriction but we knew that we will have to have a restriction, because you're trying otherwise to solve a problem which is exponentially difficult even for quantum computers.
Okay, so the problem here is that I mentioned we have the product state with the right expectation value but it's too broad.
There's a linear superposition of product of eigenstates but actually it has too many not concentrating on some energy so now let's make it narrow and the idea is to use the same filter that I introduced for the ground state.
To apply this operator here. And so that's the same filter that I had before. And as before, we could write it at the Fourier, take the Fourier transform so to write it as in terms of the evolution operator.
And so, in principle, what we could do is like we did with the algorithm for the ground state, we could try to apply this filter and to create this linear superposition.
But now there is a better, a better way of doing that. And this better way is never create this state, you never, I mean you are going to apply this filter, but you will never create this state we're going to use a trick.
And what is this trick. Well, well, let me first mention that. Okay, so now, how many terms doing it so we have the superposition.
And it's very easy to show that you want to have a value variance delta, then the number of terms will scale like the square root of the number of qubits divided by delta.
And the maximum time that will appear here will be one divided by delta and that is important.
Why it's important is because you see that the number of terms in order to apply this filter.
It scales polynomially within and with one divided by delta so there is no exponential scaling and this will be important because we have an efficient algorithm and the maximum time in which you will have to apply the dynamics.
It's also this case like one divided by delta so everything is polynomial. So that's good. Okay.
However, as I mentioned we will not prepare the state because this is a state that will be difficult to prepare now becomes the third trick, the third step.
And the third step is say well at the end I don't want to prepare the state at the end I want to compute this expectation value.
So, this expectation values is defined like that.
I mean I divided now why the norm, because the state is not normalized.
And so what you can do is replace this formula in this formula and expand it and so you will have a quotient of something in the numerator and something in the denominator and it's very easy to show.
I mean I'm not going to do here that it will depend on these quantities, depend on this quantity, which is yes, we start with the state P evolved and then look at P, and some other quantities which is very similar.
The trick is that if you at the end want to get this number, you don't have to prepare the state.
What you have to do is with a quantum computer to compute this A and B, and you can compute this A and B, then you replace it in the formula and you have your value.
Okay, so the idea is not to prepare state because it's very difficult and we have a superposition highly entangled, but rather than that you use the quantum computer to compute the parts that you need in your formula.
And that's another trick that appears in quantum algorithms is namely that, I mean, you don't prepare states all the time, but you just say, at the end I want to compute some quantity.
So you just look at the quantity and then see what your quantum computer has to do. And then you have to compute these quantities and yes that to me that you see is that this quantity, for example, this quantity here for an analog quantum simulation has a very simple interpretation.
We start, I mean, let me compute the absolute value of this quantity, which is simple.
So the absolute value is that you start with some product state, you evolve, and then you want to compute what is the probability that you're still in your initial state, this quantity squared.
Okay, so what you have to do is that you start with some configuration, for example, your quantum simulation has qubits or spins.
Then you put the product state which has the property energy, then you use your dynamical algorithm to evolve it.
And then you measure all your qubits, and then you see if they are in the original state or not. If they are in the original state, you say a is equal to one.
And if they are not, you say a is equal to zero.
Repeat it, repeat it, repeat it, repeat it, repeat it, compute the average, and this will be this quantity here.
And then for the phase, you have to do something similar with the same things for a phase, and then you compute this quantity.
So altogether, what this algorithm does is that solves the problem that I told you before using tricks, but in particular, it's the quantum computer is just doing is use a sub routine.
It's a sub routine which is doing some specific jobs and the classical computer is doing all the computations like here.
Okay, so now I can summarize, but this quantum algorithm, this quantum algorithm prepares a product state of the energy that you asked me, then it evolves for certain times.
And then you do it in the order of the order of one over delta, and then measure, roll, measure, every measure, and then you do it even for different times, and at the end you collect all the information of the measurements, and without you compute this quantity.
And now you can do the calculation and see what is the computational time with this method, and you see that this grows polynomially with N with one over delta and one over epsilon and you can trace back the fact that skates only polynomially within to what I mentioned before
and the number of times that we have polynomial in N and polynomial in one over delta and the maximum time that you have to run your evolution is one over and or is N or one over delta and this is why this is there is an exponential speed up with respect to the classical one, the classical
one I mentioned that was scaling.
Take Delta equal to one over and that's case exponential here everything is polynomial so that's a quantum kind of supremacy algorithm.
And the nice thing also is that can be used with analog quantum computer and these devices and in fact so now we are collaborating with people who have these devices and who have analog quantum computers to implement them for problems for which classical computers don't work well.
Okay, and I just to finish things that I'm out of time now that you can do the same thing for the final temperature.
And it's very similar. The only thing is that now what you can do is that you can use this Monte Carlo algorithm that I told you before.
You remember that I told you that there is a classical method that is a Monte Carlo method that it works normally but whenever there is a sign problem doesn't work.
What you do is to use the quantum computer to overcome the sign problem. So you still sample with a classical computer but you would use this quantum computer as a sub routine to do the sampling right.
I mean to compute the probabilities that that you have to sample, and this avoids this, this problem, and that's how it works. I mean we did some simulations to show that it would work with analog computers and these devices.
Again, so we expect that if you have something like 100 qubits, then you would be able to have a quantum supremacy and already with the system to solve problems that are difficult with classical computers or better than with classical computers, but they're still relevant from the physical
point of view. So it would be a quantum supremacy experiment if this works well, that not with an academic problem like Google did but this would be with a relevant physical problem and that's
a working progress. Okay, so as a summary, we're talking about quantum algorithms to solve many body problems, quantum many body problems. I talk about the dynamics, zero temperature, finite temperature, and finite energy.
So the zero temperature, I give you an algorithm that takes exponential time, still it's better than classical algorithm. For finite energy, I give you an algorithm that takes polynomial time, and that's an exponential speed up.
And for finite temperature, actually it turns out that this quantum Monte Carlo is a heuristic algorithm, but what this quantum computer avoids overcomes the well known sign problem in Monte Carlo simulations.
And in particular these two could work with these kind of existing technologies.
So the requirements are to prepare the states and measure, and so there are things that typically can be done with these devices. And with that, sorry for being a bit late. I'd like to thank you for your attention.
Yes. Thank you very much for a really interesting talk.
So please, everyone if anyone has any questions, we have a bit of time, hopefully, to answer them and write them in the Q&A section.
So first one, I just want to just more general question. What kind of systems are currently either use or are promising for analog quantum computers and whether their advantages disadvantages compared to digital ones.
Okay, so, so the most advanced system for analog quantum computer is called atoms in optical lattices.
So the idea there is to have neutral atoms that you make them levitate with light, and then you put the periodic potential created by standing wave.
And so this way you create a lattice and these atoms can move, for example, in the lattice by tunneling and behave like electrons.
And that's the most popular one, but there's also analog simulators with trap ions with photons and with superconducting computers and superconducting qubits, as well as with quantum dots but I would say that the most advanced probably are the first two that I mentioned.
Now, the advantage is that you, I mean, so typically, if you want to solve problems in physics, then these problems have certain symmetries, for example, they are translational invariant, because they are homogeneous models.
So this means that in practice, you don't have to apply an independent gate to each of the qubits but you can do it globally. And this makes the experience much, much simpler than the, than the ones with the digital quantum computer.
Another advantage is that you see this, you may have errors, and this analog quantum computers, somehow, they are very robust to errors and the reason behind that I don't have time to explain it in detail, is that at the end in physical problems you're interested in intensive quantities.
So I mentioned here that you're interested in energy per particle, in the same way the physical property would be like the magnetization per particle properties per particle.
And it turns out that if you compute properties per particle, then this analog simulator are very robust to error. So even if there are errors, they will give you some small error in this quantity.
So that's the advantage. The big disadvantage is that they cannot be programmed, they are not universal. So you can solve some specific problems, you may be able to change a couple of parameters, but not to change all possible parameters.
So they have limited their utility.
So I guess a few questions coming in. So,
I guess it's a more
question tied with machine learning. So,
CL asks, are there algorithms leveraging machine deep learning tools. So what means essentially all is this knowledge, probably from quantum computation is transferable to other areas besides physics and speed up in those problems.
It's something that you're.
Okay, so then a couple of connections to this question. So the first thing is that, indeed, you can use now machine learning classical machine learning to solve many body problems and their people working on that.
And that's a very promising area. Okay, however, still, you don't have algorithms that would work. I mean, I mean, they are all heuristic.
Okay, so nobody promised that they will will will work.
The second thing is whether now these algorithms that I mentioned in here and some of the quantum algorithms can influence machine learning, and they can influence in two particular ways.
So one of them is because you can now use quantum systems for machine learning, and then you can enhance the express ability or your networks, for example, and that's an area of research.
You use a quantum computer just to solve classical problems of machine learning.
And the other one is that you can get inspired by some quantum algorithms in order to develop even classical machine learning.
I mean to develop classical machine learning tools, and there are people who have been working on that. So now, there are many connections between machine learning and quantum computing.
And it's not only in one topic, but in many connections so the classical can help quantum computers quantum can help classical models and so on. So there are many, many connections.
Okay, so there's one question probably aimed at clarifying different points into your presentation. So, essentially, are there any useful Hamiltonians for which finding the ground state is not QMA hard.
Yes, there are Hamiltonians for which it's, it's actually if you want in in P.
And this would be like three fermions free bosons.
And so that's those those are Hamiltonians or quadratic Hamiltonians busy as Hamiltonian for fermions the ones that describe superconductivity.
For example, all these Hamiltonians can be solved efficiently with classical computer so they're even in P.
Now, if you ask me about a problem that is in BQ for a ground state that is in BQP, but it's not in P I don't know of any but that's interesting to find one of course you can never prove it because we don't know if P is different than BQP we don't know the relation between the complexity classes.
There's one that can be solved.
Okay, so well I could give you one, actually, I can give you one now that I come to my mind is related to tensor networks which is in different areas but yeah so I think that there are there are some I don't know if they're useful if they're connected to some physically relevant property that appears in the same another field of physics,
but there are indeed some some problems that are in BQP and not known to be in P or corresponding to ground states of Hamiltonians.
So there's one question that essentially was more also similar to might be for essentially analog versus digital for molecular systems.
Okay. Yeah, so I think that for molecular systems.
At the moment, most of the algorithms, if not all of them but one are for digital quantum computers so they're these variational algorithms that people are using for molecular systems or some other algorithms is adiabatic algorithms and so on.
And the problem with analog systems is that in chemical systems or in molecules there are long range interactions. Okay, so there is cool of interaction between electrons and the cool of interaction the case of one over our but still is long range.
And the problem is that the quantum simulator that people use in practice they all have local interactions are called atoms the ones that I mentioned before, they have local or very local interaction so it's you cannot tune the Hamiltonian in such a way that they describe cool of interactions.
So this is why there's more.
They're not so many analogs quantum simulators analog quantum computers for molecule systems, there is one exception though.
There was a and we ourselves wrote a paper, a couple of years ago, together with Peter solar and some other people in which we showed that with call atoms and optical lattices you could simulate chemistry problems molecules and the idea there is that to do to imitate nature.
So you probably know when you started for the ones who studied physics and we started quantum electrodynamics is that you can understand the cool of interaction between two electrons as the exchange of photons.
Okay, so you write this.
I mean you just couple your electrons to the electromagnetic field.
And now you eliminate the magnetic field, because there are some exchange of photons and you get as an effective interaction the cool of interaction so that's the way that you derive from quantum electrodynamics the cool of interaction that is electrostatics.
And so, now what you could do with an analog simulator is the same thing so to have two atoms that they don't interacting with each other but now they can interact with a third atom that mediates the interaction that plays the role of the photons.
And these atoms play the role of the electrons in the quantum simulator and this can give rise to a cool on potential.
And so, indeed, there is a proposal for quantum simulation of chemistry systems that is analog, and the idea is to imitate nature, and to use.
To get this analog emulation of cool of interaction through the interaction with an external with another particle that would be these interactions.
Okay, so what are the current interest interactions and that tensor network research.
Okay, that's a different topic.
Yeah, but it's related to simulation of many body systems but now with classical computers, and there's a method of tensor network, and I would say that the big challenges now is to go to solve problems in three dimensions in three special dimensions.
The tensor networks, and also in for condensed metaphysics and high energy physics and chemistry.
So we know that this tensor networks method work very well in one dimension.
Start working relatively well in two dimensions, but they don't work in three dimensions, and or even for dynamical problems. So that's the current trend to try to develop them for these moments where they don't work.
That will, and then there are many more theoretical problems or mathematical problems and one problem that is very interesting that actually we will, we will pose a paper.
Next week is how to create tense quantum algorithms to create tensor networks.
And so that's, I think that connects to my talk. In fact, that's why I mentioned.
Okay, there's quite a long question, but just ask how much time do you have.
How would you say like, I mean, two free questions and then finish. Okay, that's fine. Okay, so there's three questions in total so Nikita ask in your computational complexity plots.
In your excellent talk, you plotted there might exist MP problems in BQP, but is this really possible.
And essentially he said that he thought that MP problems are impossible to solve unless you have a non deterministic Turing machine available, which is not possible because physics is deterministic.
Okay, no, no, I mean, I give you an example of the problem that is in and that is in BQP is factoring.
You probably have heard of shores algorithm.
Shores algorithm is an efficient algorithm in a quantum computer, but is not known to be efficient in a classical computer.
So in fact, factory is in NP is not in P, but it's in BQP.
That's one example, however, is not NP complete. So maybe that's, I mean, the question was referring not if it's in NP, but in NP complete.
So, so my plot shows that there can be problems in NP that are also in BQP, but they are not in P. However, we don't know and we believe that there are no problems in NP that are NP complete or NP hard in BQP.
Do you see the possibility to use quantum computing for SME the near future. I'm not sure what SME means for and gives an example example for simulation and product development and optimization.
Small and medium enterprises, I guess it is what yeah, yeah.
Okay, so I would say that at the moment the only ones that I know that I believe that could work is for solving hover problems, material problems.
I think I'm not sure that this that there are many as SMEs, I mean relate and interesting this problems. But, okay, so that's sort of the ones that I know.
There is a lot of hope, however, and there's a lot of interest in using quantum computers, let's say for the first generations for for solving optimization problems.
We know that we had a scalable quantum computer, not a nice device but the scalable one. There are some problems of optimization, especially that could be solved with these quantum computers.
And now, I guess that if you talk to us as a me as a me is working on retail, then maybe they have to bring the tracks from somewhere and go to different.
If it has 20 shops, then I mean they have to optimize the path of the tracks of the gasoline expenses or whatever. And for that, this could be used. However, this requires a quantum computer that is scalable we don't have a quantum computer that are scalable it will take a very long time to have them.
And so the question and that's the one that is very interesting and very exciting and many people working on that is whether with these next devices with these first generations of quantum computers, we can find some problems that would be interesting for the industry.
I think that SMEs is, I don't believe that there will be anything relevant in the near future, but maybe for the industry.
It could be something related to optimization. There are many hopes, but for the moment, as far as I know, there is no evidence of something like that or 100% evidence of something like that.
And the last one is a bit more tears toward tensor networks and I might rephrase the question is essentially whether essentially the most used libraries are the ones that you recommend for someone who would want to use these tensor networks and implement their work in research.
I think, well, I mean, I mean, I was programming sometime ago and don't promise the last three years of ideas.
And I was having my own libraries but people in my group they use libraries from different places. So we have our own libraries here that's why we use these libraries.
I know that there is, there are in Google has some very good libraries, and also at the Flatiron Institute.
And those two are very good. So these are two that I would recommend because they're very, very optimized.
Probably there are some that I don't know, but it's these two, especially you're very, very good.
Yeah, and that's it. So, again, thank you very much for a really interesting time.
That's been quite a lot of things. And I hope that everyone got at least something out of your time. So again, thank you very much.
Thank you. Thanks.
Bye.
Bye. Have a nice evening.
