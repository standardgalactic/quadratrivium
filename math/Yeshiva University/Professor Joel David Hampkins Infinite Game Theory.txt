I'm happy to speak on the topic of the theory of infinite games, and I just want to just
dive right in.
The topic really is games of perfect information, and this is a phrase that's often used to
refer to particular kind of games where both play all the information is sort of on the
table.
There's no hidden secret information that one player knows about that the other doesn't.
So let's just start off with a finite example.
Of course there's hundreds of examples, but let's talk about NIM.
How many have heard of the game of NIM?
Have you heard of NIM?
Okay, so the way you play NIM is you have finitely many stacks.
You can play it with coins like at a cafe or something, or chips or something, but let's
just draw lines on the board here.
So it's common to do 1, 3, 5, and 7, but you can start with any number of stacks or heaps,
and then the players, there's two players, and they take turns removing as many coins
from one stack as they want, and the goal is to take the last one.
So a move consists of picking a stack and removing some.
You can remove all of them.
So this would be a valid move to take away that whole stack, or another valid move would
be to take away three from that stack, and you want to take the last one.
So would anyone like to play me a game?
Would you like to play?
If you go first, then you're going to win.
You can choose whether you go first or not.
So shall we play with this one here?
So would you like to play?
Okay.
Do you want to go first or second?
I'll go second.
You'll go second.
So in that case, so you want me to go first?
Absolutely.
Okay.
So I'm going to go like this.
That's my move.
Okay.
And now you can pick any stack you like, and you want to take the last one.
Okay.
In that case, I take this whole stack.
Okay.
Oh, I get to take the last one.
So shall we play again?
So does someone else want to play?
So shall we do?
Yeah.
This is one player.
Who else would like to play?
Yes?
Do you want to go first or second?
I'll go first.
Okay.
Here you go.
I believe there's exactly one correct move.
Okay.
But that, unfortunately, that wasn't it.
Okay.
All right.
So I get the last one.
Okay.
So this game is a really fantastic game because you can play it with your kids and so on.
And once you know the winning strategy, even a child can beat someone an adult who doesn't
know how to play.
You saw a few times, for example, I was able to reduce it to two stacks of the same height.
And that's a winning position because if I leave a balanced position like this to you,
then whatever you do, I can copy you.
And so in particular, I will always have a move.
And so it's always winning to leave a balanced position, two stacks of the same height.
You saw I left two stacks of height one.
That's a winning position.
But two stacks of height three is also winning because whatever you do to one of them, I'm
going to do it to the other one.
And so I'm always going to have a move and so I'll make the last move.
So a more complicated strategy involves something like this where you make it balanced in the
sense of not just two stacks of equal height, but you divide each stack into a sum of substacks
whose height is a power of two.
So we think of this three as really two plus one.
And we think of this five as really four plus one.
So the four is not balanced currently because there's no other stack of size four.
So what we should do is work on this one to make it balanced.
There's a stack of size two there and the two ones are balanced.
So the winning move is like this.
Now I've got two twos that are balanced and two ones that are balanced.
So if you take away this one, I take away this one and it's a winning position, right?
If you do something to the two, if you take away this one, then what I have to do is get
rid of my stack of height two.
And I go like this and now it's balanced again.
So you leave balanced positions with sums of substacks of height of power of two.
Is there a question here?
Did you have a question?
Okay, so there's a game of perfect information and there's a winning strategy which is not
too difficult to describe.
And you can win every time as long as you have a winning start with a winning position
in this sense.
Okay, so that's an example of a finite game of perfect information.
But in this talk really what I want to talk about are infinite games.
One can give an analysis.
So let me assign it as a homework problem to analyze NIM with finitely many infinite height
stacks.
So you use stacks whose height is a transfinite ordinal.
And you can have a theory of NIM, sort of an infinite version of NIM where the stacks
have height some ordinal like omega squared plus two or something like this.
And you can play this sort of transfinite NIM.
Let's go to this more general setting now of infinite games.
So the setup that I have in mind is that there are two players and these infinite games are
games with infinitely many moves.
And the first player makes a move which we'll call x0.
Maybe they play a natural number or some finite sequence or some piece of information.
So we just call the move that they made x0.
And then player two plays x1 and x2, x3 and so on.
So they take turns alternating, you know.
So and together they build, they construct the infinite sequence x0, x1, x2, x3 and
so on.
So and then we imagine what happens at the end of that play, this infinitely long play,
right?
And we say that player one wins if this play that they made is in the payoff set.
So this is the winning set for player one.
And otherwise player two wins.
So this is a very general setup to analyze infinite games of perfect information.
So the players take turns playing and they build a sequence and then you have a certain
payoff set which is fixed and player one is trying to make sure that the sequence is
in that set and player two is trying to make sure that the sequence is not in that set.
And so now, well, let's do some examples.
So suppose that the payoff set A is the set of eventually constant sequences, sequences
of zeros and ones, okay?
So the plays are just zeros and ones, so together the two players are building an infinite binary
sequence and the player one wins if that sequence is eventually constant.
What does it mean to be eventually constant?
That's right.
At some point it either starts to become all zeros or at some point it becomes all ones.
So is this a win?
Do you want to be player one or player two in this game?
Player two because player two can ensure that it's not eventually constant by just making
sure to every other move play a zero and every other move play a one and that will make sure
that even on player two's positions it's not eventually constant and so the whole combined
sequence can't be eventually constant.
So two wins this game.
Okay, how about B, the set of eventually periodic sequences?
What does it mean to be periodic?
What is a sequence that's periodic?
What does that mean?
It repeats.
So a periodic sequence is one that repeats with a certain period, right?
So maybe every hundred steps it's just repeating the same length, one hundred sequence over
and over again.
Eventually periodic means it's a weaker condition than periodic.
It means that okay maybe there's some junk in the beginning but eventually it settles
into this repeating pattern.
So like the digits of a rational number are eventually repeating.
So do you want to be player one or player two?
Player two because player two can ensure that the sequence is not eventually repeating
by just how can you do that?
So you could say player two can play a zero and then a one and then a zero, zero and a
one and then a zero, zero, zero and a one and then zero, zero, zero and a one and so
on.
So just these longer strings of zeros with ones in between them and then no matter what
player one does there's no way that the whole sequence combined can be eventually periodic
if on player two's moves it's not even eventually periodic.
So player two can ensure that the sequence is not eventually periodic and therefore this
payoff set is winning for player two.
Player two has a winning strategy in that case.
Well let's do some more examples.
So let's do the universal numbers or universal sequences.
So a universal sequence is a sequence such that every finite sequence of zeros and ones
appears somewhere in it.
So do you understand what I mean?
So it's a sequence of zeros and ones such that somewhere in it is the sequence zero
one one and somewhere in it is the sequence one, one, one, zero, one, one and somewhere
in this infinite sequence is for any finite binary sequence you can find a copy of it
inside the universal sequence, yes?
So for example many people believe that pi is universal although this is an open question
actually it's not proved yet.
So for example it would follow if you think of universal sequences say of letters instead
of numbers.
So take the letters a through z or whatever letters you want then a universal sequence
of letters would be an infinite sequence of letters such that every possible thing
that you could say that you could write down using those letters why don't we have a space
also in our alphabet so we allow spaces as a character, right?
Every possible thing you could write using those letters and spaces would appear somewhere
in that universal sequence so all the complete works of William Shakespeare written out would
appear in the universal sequence and also for example all the complete works of William
Shakespeare but every time the name Horatio appears it's replaced by Howard because that's
also just another sequence, right?
So the complete text of all the all the greatest pieces of literature that have ever been written
would appear inside such a universal sequence.
Okay so that's what a universal sequence is.
So let's play the game where the payoff set is universal then who wins?
Player two.
Just play one all the time and then you know that the sequence zero zero zero never appears
because in order to have zero zero zero appear in the sequence at least one of those must
have been player two's moves so therefore player two can win the game for universal sequences.
So now let's have D be a countable set.
Actually some of these are these are countable sets.
I just want to take any countable set, a countable set of sequences so we've got so a zero a one
a two and so on.
These are infinite sequences.
I claim that one of the players has a winning strategy if the payoff set is countable.
So the total number of elements in the winning set for player one in the payoff set is countable.
I claim that one of the players has a winning strategy in this case.
So who is it?
Can you see?
Wait, by countable we mean out and out twice?
Yes exactly so we have a list of all of the elements of D okay.
We can put them on a list.
Each one of these is an infinite sequence.
So I claim that player two can win because on the nth move of player two yeah can you explain it?
The actualization is that on the nth move you do something, you look at the nth side of the list and then on the nth move you do what isn't on the nth side.
On the nth move you make sure that you're not the same as the corresponding position of the nth element.
So on your first move of player two he should make sure that the resulting play is different from A's year.
And on his next move he should make sure that the resulting sequence is different from A1.
And he can do that because you look at the corresponding digit of this sequence and you just play the other one.
So if the corresponding digit of this one isn't the zero digit, it's the player two's first move digit which is actually the second digit of this one.
So you just flip the bit and make sure that it's different right?
So thereby player two can ensure that he's different from any member of a countable.
It's the entire conversation argument of the old time countable.
Exactly right it's exactly the same.
So okay so those are some examples and player two happens to win all those examples.
Okay so what I want to ask is let's be a little bit more precise.
So what is a strategy?
A strategy for the game let's call it G sub X.
This is the game G sub X.
Of course once you specify the payoff set then that determines the game right?
And there could be many different plays of the game.
They could play it once or twice and so on all with the same payoff set.
So we're thinking about that game and a strategy for this game is a function.
What should a strategy do?
A strategy should tell you what to do while you're playing the game right?
So given a finite play so far the strategy should tell you what to do next.
So it's a function mapping finite sequences to the next move to be played.
So it maps X0, X1, X2, X3 and so on up to Xn and maps it to Xn plus 1 the move to be played.
That's what a strategy is.
It's just a function.
I'm not saying whether it's a good strategy or a bad strategy.
A strategy is a function that tells you how to play.
A winning strategy.
A winning strategy is a strategy such that for player one a winning strategy for player one
is a strategy such that all plays that are played in accordance with the strategy are
in the payoff set.
So it's a strategy player one can follow and if he follows that strategy he will always
be inside the payoff set.
And a strategy for player two all plays according to it are not in X.
If X has to be uncountable if X has to be uncountable and player one is to win right?
Yes because we said if X is countable then player two has a winning strategy and the winning
strategy is to diagonalize against that countable set.
And the fundamental question is the following.
So the fundamental question.
Must every game.
Have a winning strategy.
For player one or two.
Yes question.
Okay so for tic-tac-toe is different because in the game's g-stab X there's always a winner.
There's no ties.
In tic-tac-toe the reason there's not a strategy is because there's ties.
So if you put tic-tac-toe into this kind of framework then you should say that in a tie
a designated player wins say X's win or something and then there would be a strategy in that
game.
So because in g-stab X if player one has not won if the play is not in X then player two
has won that play right?
So there's no ties in these kind of games yes?
So question.
Yeah we're dealing with infinite games right?
Yes.
So the plays are infinitely long.
So couldn't you get into a sort of infinite loop where player one is going to be winning
and player two is going to be winning.
Okay well let's think about that.
Must every game have a winner.
So yes every game has a winner because once you have the play then either it's in X or
it's not and if it's in X then player one has won the game and if it's not in X then
player two has won the game.
So every game has a determined outcome.
A winner for that play yeah but just because you won that play doesn't mean you have a
winning strategy because maybe your opponent played badly and if they had played differently
maybe you wouldn't have won.
So just because you know what happened in one play of the game doesn't mean you know
that you understand the whole game right?
So this is the fundamental question.
Should we expect one of the players to have a winning strategy yes?
Yes.
Okay so we have a vote for yes.
Okay so keep that thought.
So let's just first observe.
There's an easy observation.
So it can't happen that both players have a winning strategy.
That's obvious.
Why is that obvious?
You play them against each other right and then they both have to win so the resulting play
has to be in X and it has to also not be in X the contradiction right?
Okay so at most one of the players has a winning strategy.
Okay so what I want to do is talk about a special case.
So it's called open games.
Open games are games where if a play is winning for player one this was already revealed at
a finite stage.
In other words every winning play there was a point where no matter what happened after
that it would have been in the payoff set.
So this is a condition and it corresponds exactly to saying that the set X is an open
set in the product topology if you know what that means.
So we can think about an open game is a game which if player one wins then they have essentially
won at a finite stage.
There's a finite stage of the game where no matter what they did after that they would
have still won.
So think about a game like say infinite chess where we played chess on an infinite board.
If you win in chess it's because you made a checkmate happen and if you made the checkmate
happen then it occurred at some finite stage of the game and then no matter what happened
after the checkmate I mean the game sort of is over at that stage right?
So that's an example of an open game.
So open games are games which when they're won they're won at a finite stage and you have
all the information you need at that finite stage in order to say who the winner is.
So it's a beautiful theorem of Gale and Stewart that says every open game is determined.
In other words has a winning strategy for one or two.
This was proved in the 50s I believe and one of them was an economist actually thinking
about sort of game theory in economics.
So it's really quite remarkable.
So it's answering this question at least in the case of the open games.
What's that?
Finite games are all determined because they are also open games.
So it follows from this that all finite games are determined.
So a finite game is a game whose outcome is known after a finite game.
So the open games are sort of half finite because if player one wins it happens at a finite stage
but if player two wins it's just because they avoided losing.
But it might be an infinite play still.
Yes?
So does this mean that there's a bigger chance of determinants?
Yes.
So is it necessarily a winning strategy for black holes or is it necessarily a winning strategy for more?
We don't know.
We don't know which one.
We don't know which one.
Well the way infinite chess works there isn't a standard starting configuration.
You have to say what the position is first and certainly you can set up positions for
which black can win and other positions for which white can win.
So there's no standard starting.
That's true.
That's another complication.
Yes.
So you have to think about the draw.
Okay.
So all right.
So let me just hint at how this proof goes.
Okay.
So the proof.
The proof uses transplanted ordinals.
So let's just count a little bit in the ordinals.
Does anybody know how to count up to omega squared?
So we can start.
I think everybody knows how to start counting zero, one, two, three, four and so on.
Okay.
But then the first infinite ordinal.
What is it called?
You know?
Yeah.
Well that's the sort of first infinite cardinality.
When you're thinking about the order, which is what we are when we're counting in the
ordinals, then we call it omega.
But omega and all of null are sort of names for the same thing.
Okay.
Well whenever you have an ordinal, then you can add one to it.
So omega plus one, omega plus two, omega plus three and so on.
Those are the next ordinals that come after omega.
And then what do you think is the first ordinal that comes after all those ones?
So omega plus a finite number.
What's the first one that's bigger than all those?
What's it called?
Do you think?
No.
Well not two omega, that's the complication.
But it's omega times two.
And that's not the same thing.
So omega plus omega is what it is.
And this is omega times two.
Two times omega means two plus two plus two and so on.
Omega many times.
And it turns out that if you think about that, if you take two dots and two more dots and
two more dots and so on and you do that omega many times.
Then the number of dots you've got is omega.
So two omega is the same thing as omega actually.
But omega times two is totally different because it means that you take omega many
dots and then after that you take omega many more dots.
And these are just fundamentally different order types.
So omega times two is not the same as two times omega.
Ordinal multiplication is not, what is the word?
It's not commutative.
So we have omega times two, omega times two plus one, omega times two plus two and so on.
And then what comes after all that?
Omega times three.
Omega times three.
Okay.
And then omega times three plus one, omega times three plus two and so on.
And then omega times four.
Okay.
And then so on.
And then finally after we do that whole process, omega many times we get two.
Omega times omega, which is also called omega squared.
Okay.
So it's counted up to omega.
And of course counting up to omega means you count up to omega, omega many times.
So does that have a cardinality out of one?
No.
It's still countable because it's countably many countable steps.
So it still has cardinality omega out of zero.
It's still a countable ordinal.
Okay.
So then we go omega squared plus one, omega squared plus two and so on.
It's like, if you start at any point and then keep counting, it looks just the same as
what it did from the beginning, right?
So, okay.
Then you get omega cubed, omega to the fourth and so on.
And then omega to the omega and so on.
Okay.
So this is counting in the transmitted ordinals.
I once had a big argument online about whether children can learn how to count up to omega
squared.
And I think it's not that hard to count up to omega squared.
We just did it.
I was arguing that even a child can count to omega squared.
It's just like counting up to 100 because to count to 100, right, what do you do?
You count to 10, 10 times, right?
I mean, you count up to 10 and then you count up to 10 again.
I mean, going between 10 and 20, right?
And then you count up to 10 again, you know, between 20 and 30 and so on.
You do that whole thing 10 times.
You count up to 10, 10 times.
You count up to omega squared.
You just count up to omega many times.
And so it's fundamentally just like counting up to 100.
So every number less than omega squared has the form omega times n plus k.
So there's like two digits, just like the numbers below 100 have two digits, right?
Except now those digits are natural numbers instead of just the digits from one to, I
mean, from zero to nine.
Okay.
So those are the ordinals.
And the ordinals arise in the proof of this theorem.
So the idea is this.
So we think about the game value, okay?
So we say a position has value zero if one has already won in the sense of the open game, right?
So the open game means that for everything that's winning, there's some point such that
every extension of it is in the payoff set.
So if you've got a sequence like that, then we say it has value zero.
So player one has already won that game.
Okay.
Now if we have a position P, if we have a position and it's one's turn, then we say the value
is alpha plus one.
If one can play to a position of value alpha.
Okay.
So a position with value one is, player one hasn't won yet, but there's a winning move,
which if player one plays that move, then he will be in a winning position, right?
Okay.
If it's two's turn, then we say the value, no.
If it's two's turn and all moves lead to a position with value having some value, then
the value is the supremum of those values.
Okay.
So in other words, the value of a position when it's player two's turn is the supremum
of the values that he can get to.
Okay.
So you should think of, player one wants to make the value low.
He wants to get value zero, because that's how he wins.
Player two wants to keep the value high.
Okay.
So now the observation is that, what's that?
Yeah, some positions might not have a value.
Okay.
Yeah.
Okay.
And that's part of the argument.
So if a position has value, then one can play the value reducing strategy.
Okay.
So the point is that suppose a position has value, then no matter what two does, he's
going to play to a position with value if it's two's turn.
And one can play so as to reduce the value from alpha plus one to alpha.
So if a position has value, then one can play to reduce the value and two can't make it
go up.
So therefore the values will inevitably go down and they must go to zero because there's
no infinite descending sequence of ordinals.
So therefore if a position has value, then player one has a winning strategy.
And if a position has no value, then two can play to preserve this.
Because if a position does not have a value, then if it's player two's turn, there's another
move to make where it still doesn't have a value.
Because if they all had values, then that original position would have had a value.
So therefore if a position has no value, player two can play so as to preserve the fact that
the position has no value.
And if a position has no value, then one can't play to a position of value because if he
could, then the original position would have had a value.
So there's nothing one can do to make a value and player two can play so as to preserve
the value.
So in that case, player two has a winning strategy.
So either the position has a value, in which case player one has a winning strategy, or
the position does not have a value, in which case player two has a winning strategy.
So that's the kind of sketch of the proof.
Yes?
Well, the supremum is the least over bound.
We're assuming that there's only finite choices you can make per move?
No, no, maybe infinitely many.
Any supremum of, even infinitely many ordinals still has a supremum, at least over bound.
So the ordinals have the least over bound property.
A sort of value has to be a number?
Well it's an ordinal.
The value is an ordinal, one of these ordinals.
It might be much bigger than omega squared in fact.
So those are just comparatively small ordinals.
Okay?
Alright, so I just wanted to give you a kind of sketch of how this kind of infinite way
of thinking about ordinals can lead you to prove quite remarkable theorems like this.
Okay, so let me go on now.
So we still haven't really answered the question, does every game have a winning strategy?
So let's introduce the axiom.
Well, it's the axiom of determinacy.
It's called AD axiom of determinacy, and it asserts that every game is determined.
So in other words, every game has a winning strategy for one of the players, for exactly
one of the players.
So let's think a little bit about this axiom.
If you think about the assertion that player one has a winning strategy, what's the way
of kind of writing it in maybe, so we're thinking about the game say g sub x, so the payoff
set is x, then to say that player one has a winning strategy is to assert that there
is a move for player one, so that no matter what player two responds, there is a counterplay
for player one, right?
So that no matter what two does, there's a counterplay and so on, such that the resulting
sequence is in the payoff set.
So how many have seen this kind of quantifier for all in there, is this familiar to you?
So this is there exists, and this is for all.
So what does it mean to say player one has a winning strategy is to assert that there
is a play so that no matter what the opponent does, there's a counterplay so that no matter
what the opponent does, there's a counterplay and so on, such that the thing is in.
And now two has a winning strategy is the assertion, no matter what the first player
does, the second player has a play, so that no matter how the first player responds, the
second player has a play, so that no matter how the first player responds and so on, such
that the resulting play is not in the payoff set, because player two wants to be out of
the payoff set.
So I want to just think logically about what happens when you negate a kind of statement
like this.
So what happens if I say not there is an x, phi of x.
So this is logically the same as, can someone sort of, I want to push this not inside.
For all x, not phi of x.
So when you negate a quantifier, it changes to the other one, and then the not is still
inside.
And if you negate, say if I have two statements like this, the alternating quantifier, I could
push it in, what does it turn into?
For all x there is a y, not phi of x.
If it's not the case that there is an x such that for all y something happens, then there
must be, I mean it must be that for every x there's some y for which it doesn't happen.
Those are logically equivalent.
And so let's think about this axiom of determinacy now in terms of, I mean AD is asserting that
one of the players has a winning strategy, right?
So AD asserts that if one, if it's not the case that one has a winning strategy, then
two has a winning strategy.
We already know that they can't both have winning strategies.
So AD is exactly asserting that one does not have a winning strategy if and only if two
does.
Yes?
Because if two does have one, then one doesn't.
And if one doesn't have one, then under AD, two has to have one.
That's exactly what AD asserts.
So let's just translate it.
So AD is asserting that not there is an x0 for all x1, there is an x2 for all x3 and
so on, such that this thing is in x is equal to for all x0.
There is an x1 for all x2, there is an x3 and so on such that x vector is not in x.
So it's just exactly asserting the analog of these laws.
Does anybody know what these laws are called?
So these are the DeMorgan laws of logic.
So the point is that AD is an infinitary DeMorgan law.
DeMorgan doesn't actually imply AD though, right?
No.
No.
So because although we believe the finite DeMorgan laws, we can prove them as a matter
of logic, the only interpretation we have for this infinitely many alternating quantifiers
is this game theoretic one.
And so this is just a very suggestive way of asserting the axiom of determinacy.
But really the only interpretation of what it means to have this infinite string of quantifiers
is that there is a strategy of a certain kind in the game.
And so I'm not saying that AD is following from DeMorgan's laws and that this DeMorgan
law can be established as a matter of logic.
That's not the case.
So this is pretty good evidence though that AD is true, I think, because it's asserting
the analog, the infinitary analog, of logic.
Yes?
So you couldn't write an inductive proof for the infinite case?
No.
There isn't one.
For a reason that I'll explain.
Okay.
So let me just mention quickly that AD has amazing consequences.
So, for example, it implies that every set of reals is Lebesgue measurable.
If you've looked at Lebesgue measure, maybe in your analysis course, you know about measure.
It implies that every set of reals differs from an open set by a meager set.
So every set is almost open.
It's quite remarkable.
This is called the property of bear.
So AD implies every uncountable set contains a perfect set, which is a closed set with
no isolated points.
And that implies a version of the continuum hypothesis.
So it implies that every set of reals is either countable or else in bijective correspondence
with the entire set of reals.
Yes?
By a meager set, it's called a meager set.
I mean, it's a technical thing.
I'm not expecting everyone to know what all these words mean, but if you happen to, then
that's great.
A meager set is a countable union of closed, no-word and set.
So it's a very tiny set in the sense of what's called category.
So you can think of it as something like a measure zero set, except it's the category
analog of measure.
Yes?
Exactly.
So what's going on?
AD implies that every set of reals is Lebesgue measurable, but you know you've heard probably
from Vitaly or somebody like that who proved that there's a non-measurable set.
So what is going on?
Okay.
So the thing that's going on is the following.
Meanwhile, the axiom of choice implies that AD is false.
So the axiom of choice is one of the axioms of set theory that asserts that if you have
a family of sets, of non-empty sets, then there's another set that picks exactly one
of non-empty disjoint sets, then there's another set that selects exactly one element from
each of them.
So it chooses an element from each set.
It's quite a natural axiom, but it contradicts AD.
In particular, this observation follows from the fact that Vitaly used the axiom of choice
when he proved that there's a non-measurable set.
So we can prove that there are non-measurable sets, but we have to use this controversial
axiom of choice in order to do that.
So you have to sort of take your pick.
What do you want?
Do you want the axiom of choice or do you want the axiom of determinacy?
So the axiom of choice has all kinds of other crazy kind of consequences like the Banach-Tarski
paradox and so on, if you've heard of it.
There's some quite strange consequences of the axiom of choice in terms of measure and
non-measurable sets, but the AD has these totally beautiful consequences that imply everything
is totally nice with the theory of the reels and with measure and so on.
So the question really is, is AD true?
So it's contradicting the axiom of choice, which we think is true, but we seem to have
an independent reason to think that AD is true because it seems like a law of logic.
And also it has these beautiful consequences.
So how is it that you determine which axioms of mathematics are true, right?
So this is, I know this is a meeting of the philosophy club also, and so there's quite
a lot of deep philosophical questions connected with these issues.
And you might think of the philosophical position of consequentialism as a criteria
for deciding the truth of mathematical statements by looking at the consequences of those statements.
So AD is pretty competitive on the grounds of consequentialism because it implies this
totally regular theory of the reels and of the theory of Lebesgue measure and so on.
And so whereas AC, the axiom of choice, has all kinds of somewhat unpleasant consequences
for the theory of Lebesgue measure and non-Lebesgue measurable sets and so on.
So we have to compare these two axioms, and how do we decide which is true and what criteria
should we use to decide whether AD is true or AC?
Question?
That's like asking if there's only one line that can be drawn through a point to another
line that does not intersect that other line.
I see.
So you want to propose that, look, we can have both of them if we compartmentalize.
So on Tuesdays and Thursdays, we work in the theory of the axiom of determinacy, and on
Monday, Wednesday, Friday, we work in the theory of the axiom of choice.
I think that's quite a reasonable position, and in fact, this is what's done, right?
Because of course, mathematicians are studying the axiom of determinacy and looking at its
consequences.
Of course, when they do that, they don't use the axiom of choice because we know that
it's inconsistent to have both of them.
So when we study AD, we can't use the axiom of choice.
But then on other times, when we're doing analysis of some other kind of mathematics,
then we use the axiom of choice because there's independent reason to think that that's true.
So I think that, in fact, that position is the default position.
This is, in fact, what's being done.
Yes?
Are we sure that neither of these axioms leads to a contradiction with any of the other axioms
in that?
Okay, that's an excellent question.
So in the case of the axiom of choice, we have the following theorem of, well, two theorems,
the first one due to Gertl.
And what he proved is that if the Zermelo-Frankel axioms, these are the standard axioms of set
theory.
If they are consistent, then it's consistent to also have the axiom of choice, okay?
So assuming the axiom of choice is no more dangerous than not assuming it by a theorem
of Gertl.
He didn't prove that ZF is equivalent.
He proved that if it's consistent with the axiom of choice, then it's consistent also
without assuming AC at all.
Now Paul Cohen proved the corresponding fact that if ZF is consistent, then it's also
consistent that the axiom of choice fails, okay?
And this is using the method of forcing.
So it's quite a brilliant theorem that has led to hundreds of theorems, thousands of theorems
using his method.
And so those are quite remarkable.
So in fact, both of these are, the arrows reversed, they're equivalent.
Because of course, a consistency of a stronger theory implies the consistency of the base
theory.
So these are equiconsistency results and then you might ask, well, what about AD?
Can we do the same thing for AD?
So can we expect that ZF is consistent if and only if con ZF plus the axiom of determinacy
or a corresponding theorem?
Can we prove that AD is safe in the same way that we know that AC is safe?
Yes?
Can you just say that's an equivalent state to one of the two colors?
No, because we don't know that AD is equivalent to not AC.
It implies not AC, but in fact, it's far, far stronger.
The reason is that the answer to this question is no, we cannot have that.
And the reason is a remarkable theorem due to wooden, which is that the consistency of
ZF plus AD is equivalent to the consistency of what's called ZFC plus there exists infinitely
many wooden cardinals.
So I'm not expecting you to know what this means, but this is an example of a large cardinal
consistency strength.
So we can prove that the consistency of these large cardinals is strictly stronger than the
consistency of ZF.
So if you could prove a theorem like this, it would mean that in fact ZF was just inconsistent
as a result.
We have the consistency strength of AD is quite strong, and we can measure the strength
by using this large cardinal hierarchy.
So that's a bit technical.
So let me move on and talk a little bit about infinite chess.
In fact, I don't want to write on this word because we're going to turn the projector
on.
So I just want to show you some examples of positions in infinite chess that realize high
game values.
So high game values in infinite chess.
Okay so let me erase this.
Okay so in infinite chess, let me turn this on here again, is it going to go?
Oh it has to warm up, do I have to push it again?
Yes.
Okay.
So while it's warming up.
So infinite chess is chess played on an infinite chess board.
So it's, you imagine a chess board that is, there's no edges, it just is continuing in
all four directions, but you still have pieces like knights and bishops and roaks and pawns
and so on, and they move in just the way that you would expect.
And so let me show you an example position here, let's see, antenna game values in here.
So let's look at this position.
Can everybody see that position?
Let's see.
I wonder if I can zoom in here, I can do control L, no that's no good.
Let's see, let's go like this.
Oops, oh maybe I can zoom in a little more.
Okay, oops.
Okay so we should think, there's no edge on the board, okay it keeps going, you know.
So this is a position that has three black rooks and a black king and there's a white
queen and white rook.
And this is the start of the game, as I said in infinite chess we don't, there's no standard
starting condition, the way you play the game is you describe a finite position or a position
on the board and then you play from that position, right?
So who's going to win?
It's black's turn, which is what this triangle indicates, who would you rather be?
What's the, what way of the game?
Check mate.
There's no white king.
Right, okay so therefore black cannot win, okay but maybe black could hope for a draw.
Okay so black is playing for a draw because white has no king, okay.
So can black, can black get a draw or not?
These are white pawns.
There's no pawn promotion because there's no edge, right?
There's no empassade or anything like that, okay.
If black moves his rook up then white has a, has a mating net because white can check
with the rook here and there's no place for the king to go except up and then the queen
comes up which is protected by the rook and it's check again and the king has to go up
again and then the rook goes up, it's check and then, I'm sorry.
Oh let's see what happens.
Oh, okay so, okay so the rook comes up and then it's check with the rook, king goes up,
check with the queen, king goes up again, check with the rook again, king goes up, queen comes
up, check.
So, so the, there's a mating net with a roller with the queen and the rook that pushes the
black king into the rook and it's checkmate.
Okay, so white can win and you can, it's easy to see that if black makes any other move
then white checkmate's almost immediately.
For example, this one here is queen here is checkmate unless, unless this rook gets out
of the way and if, if black moves here there's, there's checkmate here, if black moves this
rook here then it's checkmate here.
So, there's, there's many, many checkmates for white if black doesn't follow the main
line which is to move the rook up.
Okay, so now observe though that white has a winning strategy, we argue, because black
better move this rook up or else he's going to lose very quickly.
But black can cause a delay, an arbitrary delay because suppose black moves his rook up
10 million light years.
There's plenty of room up there, right?
Then it's going to take white a long time to, to mate that king.
He's got to chase it all the way up, right?
Black can move the rook up in arbitrary height and thereby control how long it will take
white to win.
Yes?
Good.
He theoretically shoot his rook so far up that it's just gone.
That it's just like, it's just an increment.
No, no, because every position on the board is some finite distance.
Sorry, this keeps turning up.
So the point is that this, this game is a win for white.
So it has a value but black can control how long it's going to take on his first move.
He can move in arbitrary height up and thereby get a position whose value will be some finite
number because it will be that many steps before the checkmate happens.
So what is the value of this position?
The game value.
It's a, it's a position with value omega.
So this is a position with infinite game value and the character of a position with infinite
game value is it, it's black's turn and he is going to lose but he can cause an indefinite
delay by playing, there's infinitely many moves to make that make the game cause take
longer and longer.
Okay, so let's look at a few more examples because we don't have much time here.
So, so those are some variations.
Let's see.
I want to show you.
Okay.
Here's another one.
Let's look at this one here.
Okay.
So, so this position also has infinite value.
So it's a similar kind of thing.
The pawns keep going.
So now basically black doesn't have too many moves.
If, if, if black allows white to take with the pawn then, then this pawn comes up and
the rook comes up checkmate.
Right.
So, so basically white's, white wants to move some pawns out of the way so the rook can
make checkmate.
So black is going to say, no, no, no, no, you can't get those pawns out of the way.
He moves way up.
Okay.
And then white catches him with a pawn and then white has to move these pawns up one by
one.
Yeah.
Down, down, down to make room and then finally there's room and the rook comes up checkmate.
Okay.
So that's a position with value omega and there's sort of variations here.
You can see these ones have a similar feature.
Okay.
So now let's, let's look at this one which is a variation on that idea.
Okay.
So the position inside here is the same as before.
Black moves up, white captures the rook and aims to move the pawns up.
There's a hole in that pawn column and white is going to advance the pawns one by one
so as to get this pawn up and then checkmate.
Right.
But meanwhile, out here, black has a rook and the white king.
So when the rook is captured, then instead of allowing white to advance the pawns, black
says check, right, instead of thumbing his nose.
Okay.
The king can't just run away because then black just says check, check, check, check, check
and it's then infinite.
If the king goes, oh, okay.
If the king goes to the left, it's fine.
The rook, when white advances the pawn, this rook goes way out here and checks from this
side.
Okay.
And then if white is hanging around over here, then it's just infinitely many checks
and then the checkmate never happens and black gets the draw.
So if the black rook comes out here and then checks, white cannot allow that black is just
going to check him over and over again because he wants to advance the pawns and make the
checkmate, right.
And so what is he going to do?
He's going to chase this rook down.
He's going to move diagonally towards the rook and then check, move diagonally, check,
move diagonally again and keep doing that for as long as the rook was away.
Okay.
So can you see how it happens?
Okay.
So basically every time white wants to advance the pawn, black moves very far away, 10 light
years and then makes a check and then white has to spend 10 million light years worth
of moves to chase the rook down and then almost capture the rook.
But then black doesn't check one more time.
Instead, he moves 20 million light years out.
Okay.
And white moves one pawn and then black does it again.
Yeah.
So every time white moves one pawn, black causes this huge delay, this harassing check
sequence, yeah, and then happens again and then one more pawn and then black goes even
farther out and check, check, check, check, check, check, check, check, check, you know,
for eons.
And then finally white chases him down and black moves away again and then one more pawn
and so on.
So depending on how high this rook goes, it's the number of those huge delays that black
gets to cause.
So eventually white is going to win, but black really can control it.
Okay.
Let me just.
It's omega squared.
It's omega squared, exactly.
Yeah.
Who said that?
Yes.
It's exactly omega squared.
Okay.
Here's another omega squared position.
So this one is called releasing the hordes.
So it's a similar idea.
White wants to open the door and let the queens in, but it's the same pattern.
So the rook goes up, is captured, and then the rook is causing this infinite delay.
Eventually the pawn moves out, bishop, and then the door opens and the queen's going.
Okay.
So that's omega squared.
Let me just show you two more positions.
Oh, there's a lock, door, and key.
So, okay, this is positioned.
This one has value, omega squared times four.
It's just four rooks here, but each one, these ones are stable.
You have to do this one first, and then there's the harassing rook and king that you can't see.
So this rook happens, and then it's caught up, and then eventually these bishops are released,
and the pawn comes up, and then it sets the next one in motion.
So there's four of them.
So that's omega squared times four.
I don't really do constructive mathematics so much, but it's a very good question,
and I don't know if AED has been looked at by the constructive mathematicians.
But I'll definitely think about that, actually.
So that's a really good question.
Is the axiom of determinacy the standard axiom of the theory?
Does that mean the axiom of the rule?
Well, not really, because most of the games that the game theorists look at are open games, actually,
and they are all determined.
And in fact, even when you're looking at a game that's not an open game,
then it's almost certainly a Borel game, and actually the Gale-Stewart theorem is proved for Borel games also.
So games that you can define in a very simple way are known to be determined.
So the non-determined games are the games that are coming from the axiom of choice and so on.
You have to really build the counter examples.
And so if you're looking at an actual game that arises in the context of game theory, then almost certainly it's determined.
