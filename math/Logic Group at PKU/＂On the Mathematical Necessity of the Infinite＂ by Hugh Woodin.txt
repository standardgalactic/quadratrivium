Good evening, or maybe, maybe morning, maybe afternoon.
Anyway, I'm very pleased to welcome everyone to be here.
All of today's lecture as a speaker
is Professor Hugh Wooding from Harvard University.
He's one of the most important mathematicians
and logistic in today's world.
Professor Wooding was a professor at Caltech,
then at Berkeley, even before he earned his PhD
from UC Berkeley in 1984.
In 1988, he came back to Berkeley as a professor, I think.
In 2014, he moved to Harvard.
Now he's a professor at Harvard University
from both Department of Mathematics
and the Department of Philosophy.
Professor Wooding has made significant contributions
in many areas of mathematics and logic,
but he concentrated himself on set theory,
the concept of infinite.
His workers, for example, the equiconsistence
of Wooding Cardinals and the projective determinacy,
the hard dichotomy, the universality of in a model
of super compact Cardinals are so fundamental.
They have changed the whole scribing of this area.
And I would also like to mention that Professor Wooding
is a philosopher too.
At least he published one Philosophical Papers.
His argument against the so-called
the generic multiverse position of mathematical truth
is a model of today's philosophy of mathematics.
Just as Bertrand Russell's classical paper denoting,
these arguments show a new trend in philosophy
of mathematics.
That is, when you try to argue for a philosophical point of view
about mathematics,
you should ask for evidence from mathematics itself
rather than from language, human mind or some other things.
In recent years, Professor Wooding has been advancing
a program that search for ultimate in a model
of large Cardinals.
Though it was, it has not been finished.
I believe there are tremendous work needed to do
and a verse to do to understand
the philosophical significance of this program.
So let's welcome Professor Wooding's talk.
Thank you for the introduction
and thank you for the invitation to speak at this meeting,
celebrating the anniversary of Russell's visit to China.
Okay, I'm gonna be talking
on the mathematical necessity of the infinite.
It's gonna be a math talk,
but I'll try not to make too many definitions.
So I wanna begin with formal number theory.
The axioms are the piano axioms, that's PA.
What are the objects or the natural numbers?
One, two, dot, dot, dot.
Or as a set theorist, view them zero, one, two, dot, dot, dot.
But I'm gonna do the one, two, dot, dot, dot.
We have the formal axioms of number theory,
the piano axioms, these have the algebra axioms
and the induction axiom, these are well-known.
And the natural question is,
is all of mathematics in essence
just a study of the formal consequences of these axioms?
And if so, where does that lead the study of infinity?
Okay, there's also a companion,
second order number theory, which I'll call SOPA, or SOPA.
The objects are the natural numbers together
with all sets of natural numbers.
That we have the formal axioms of second order number theory,
the SOPA axioms, we have the algebra axioms,
the induction axiom, and the comprehension axioms.
So we have two fundamental structures in mathematics.
We have the integers with plus and times,
and we have the standard structure
for second order number theory,
which is just the integers, all sets of integers,
plus and times, and of course,
we need to know which integers and in which sets,
so we need the epsilon relation.
Okay, for Maslow's theorem, the theorem of Wiles states
that suppose n is bigger than two and n is a natural number,
then for all natural numbers x, y, and z,
x to the n plus y to the n is not equal to z to the n.
So Wiles' proof of this is considered one of the great theorems
of modern mathematics.
Curiously, Wiles' published proof is not even in ZFC.
Incept theory, and it's certainly far from a proof
in second order number theory.
So the natural question, that's been much discussed,
is can Wiles' theorem be proved from just the piano axioms?
Well, I want to say that's not the right question.
So let's introduce a new theory, finite number theory.
So the objects of the natural number starting with one,
and continuing up to some largest number.
We can write down the formal axioms of finite number theory,
and we'll call those FPFA, finite.
So we have the algebra axioms,
those are the axioms you would write down,
but remember plus and times aren't total.
So the algebra axioms have to be reformulated
to take that into account.
But I do want to focus on the induction axioms.
So just as with PA, this is a scheme,
and it's not quite what you might have expected.
So suppose F is a function on numbers,
and F is defined by a formal property,
then the following are equivalent.
The function is one to one, that's the first property,
and the second is it's a surjection.
So the first one just says,
if you have two different numbers,
they are sent to different numbers,
and the second property is saying every number
is the value of the function somewhere.
So this is sometimes called the pigeonhole principle,
and you may wonder why I don't use the usual induction axiom.
Well, in this context of finite number theory,
it's a weaker axiom,
and it's not even known if it's equivalent.
Okay, so for every natural number n,
if we look at the numbers starting with one,
and ending with n, we get a model of FPFA.
So we could look at the model that has only one in it,
that's the simplest model.
So we can work in FPFA,
and after a while you get used to it,
and there's some interesting things.
You can actually define the relation,
z is equal to x to the y, in FPFA.
That takes a little work, but it can be done.
And the point of that is that,
for Ma's last theorem is a statement, then, of FPFA.
Once you can define the relation,
z is equal to x to the y,
you can write down the statement of for Ma.
So the question is, can wilds theorem be proved in FPFA?
Now, if the answer is yes,
then mathematical infinity plays absolutely no role
in wilds theorem.
So this, to me, is the correct question.
If you want to ask,
what could you prove from Ma's last theorem?
Okay, so if you take many of the famous problems of mathematics,
perhaps the most famous is the Riemann hypothesis,
that can be formulated in FPFA.
In fact, most of the questions can open,
famous open problems of number theory,
can be refined to problems in FPFA.
And the FPFA perspective naturally generates many new questions.
And so what's fair to ask,
is all of mathematics really just the study
of the formal consequences of FPFA?
No infinity at all.
Okay, so I want to talk about Ramsey's theorem.
So suppose I have to make some definitions.
Suppose n is a natural number.
A set x is an n set.
If x has exactly n elements.
For each set y,
we'll let bracket y n denote all the n sets such that x is a subset of y.
And now we have the famous Ramsey theorem or one version of it.
It says that for every natural number n,
and for every natural number k bigger than n,
there is a natural number m large enough,
so that if you take any function from the n sets from one up to m,
into one up to n,
then you can find a k set on which the functions constant on all of the n subsets are there.
So this is sometimes stated in terms of coloring.
What it says is that if you color the n sets from m with n colors,
you can find a k set where the coloring is constant.
People also describe this as order within chaos,
because if you restrict the function pi to the n subsets of a, it's constant.
It's as simple as possible.
Okay, that's Ramsey's theorem and there's an infinite version.
So n is a natural number.
And now we color all n sets of numbers by the numbers one up to n.
And then the conclusion is that there's an infinite set of numbers,
such that the function is constant on all of the n subsets of that infinite set.
Now Ramsey's theorem is proved in PA, and there's actually a stronger version,
and that version is proved in FPFA.
The infinite Ramsey theorem is proved in second order number theory,
makes no sense in FPFA.
Okay, the Paris Harrington theorem is a slight variant of the Ramsey theorem.
So here's the statement for every natural number n, there is a natural number m,
such that if you color the n sets from m with n colors,
you can find a set on which the coloring is constant.
So far it's just Ramsey's theorem, but now there's a key additional property that a has to have.
It has to have as many elements as its least member.
That's the only change.
So if I didn't have the third bullet, this would just be Ramsey's theorem with K equal to n plus one.
So we're adding one property, and that is a also has to have, I guess, as I stated that more elements than its least element.
Now this theorem follows easily from the infinite Ramsey theorem,
because an infinite set has more members and it's least element.
So it's a nice exercise to deduce it from the infinite Ramsey theorem to prove the Paris Harrington theorem for n.
The finite Ramsey theorem with that with n plus one.
And the remarkable theorem is that the Paris Harrington theorem cannot be proved from PA, unless PA is inconsistent.
So here we have an almost natural mathematical statement, which can't be proved from PA but can be proved invoking infinity.
So a theorem was a big generated a lot of excitement is approved in the 70s.
Now you can use the Paris Harrington theorem to define Paris Harrington numbers.
And that's what I want to do next. So suppose n is a natural number, then pH and this is in standard notation.
The nth Paris Harrington number is the least natural number m such that if you color the n sets from m with n colors, you can find the set a as required by the Paris Harrington theorem.
So a has to be have at least an L it has to have more than an elements, and it has to have more elements than its least member, and the coloring is constant on a.
So we're looking for the least witness for the Paris Harrington theorem for exponent n.
The numbers are extraordinarily large. The 10th Paris Harrington number cannot be written in decimal notation in our universe and back probably the fifth one can or even the fourth.
And these grow very fast pH 11 the 11th Paris Harrington number is vastly larger than the 10th Paris Harrington number.
So we can now form a girdle sentence, and I'm working again and find out arithmetic. And so there's first, we need to deal with the Paris Harrington number so you can write down a formula.
We'll call it fees of pH or size of pH, and it just expresses that it's a property of acts and it says there exists why, why is the X Paris Harrington number, and we'll say two to the two to the Y exists.
Now remember we can talk to talk about two to the two to the Y so that's not a problem it's just giving enough room.
So the girdle sense we'll call it theta G. It's in the language of finite arithmetic.
That's a specific formula you can write down and this is what it expresses theta G expresses that there is a proof of its negation from finite arithmetic of length less than Paris Harrington 10.
And Paris Harrington 100 exists.
So more precisely, size of pH 100 holes.
But not quite a girdle sense because I added the second clause. So it's saying there's a proof of my negation and something big exists.
Now if you assume PA, then there's a proof of not theta G from FPFA of length less than the 11th Paris Harrington number.
I'm certain that there's no proof from of the negation of theta G from FPFA of length less than the 10th Paris Harrington number, and why should we care.
Oh wait, if you had a proof of length less than the 10th Paris Harrington number, then the 100th Paris Harrington number can't exist. You'd have a contradiction.
So, if we had a proof of FPFA of length less than the 10th Paris Harrington number, we have falsified large finite.
In particular we falsified the infinite.
So we don't want to find such a sentence.
So how can we secure the finite.
So there's no proof of not theta G from FPFA of length less than the 10th Paris Harrington number. That's a theorem from PA.
But why does this apply that there's no proof of not theta G from FPFA of length less than the 10th Paris Harrington number, maybe PA is inconsistent.
So we want to work on a weaker theory.
Well FPFA plus the 101th Paris Harrington number exists does prove that there's no proof of not theta G from FPFA of length less than the 10th Paris Harrington number.
But this isn't really helping.
Maybe Paris Harrington 101 can't exist.
The question is how do we know we cannot find by any physical or mathematical means a proof of the of not theta G from FPFA of length say less than 10 to the 24th, something we could verify if we could find it, or that we cannot
find accessible verifiable evidence, which converts to a proof of not beta G from FPFA of length less than pH 10.
Maybe we have a more efficient notion of proof.
Well, if we could find it, we would falsify the large finite we falsify the infinite we'd wipe out all of mathematics.
And you might say well clearly it doesn't exist, but notice you can't use pH 50 to show that it doesn't exist and pH 50 is enormously large much it and it does FPFA with the assumption that pH 50 exists is an incredibly powerful theory for the finite.
So there's no evidence in our world that such a proof of not beta G can't exist.
Okay, well one way you could secure the finite is to secure the infinite. Right, if the finite in jeopardy can lead to a contradiction then it should be easier to find the contradiction if you look at the infinite.
So the simplest setting for the study of the infinite is second order number theory, and we have the axioms of so pa axioms.
So we could ask, can we answer the basic questions of second order number theory using the soap axioms, and thereby show that the conception of arbitrary sets of natural numbers makes sense.
And therefore increase our confidence in the finite by increasing our confidence in the infinite.
So I wanted to find the project of sets, the standard structure for second order number theory is the power set of the integers the integers plus times and membership.
This structures really the structure of the real numbers with plus and times, together with a collection of simply defined sets of real numbers. These are the projective sets of real numbers.
There are two equivalent ways to define the projective sets. You can do it the logical way, you view the reals as contained in the power set event.
And you consider those sets of reals which can be logically defined in the structure for second order number theory from parameters.
That's the logic, the logicians way.
You can also define the projective sets just using calculus. So you consider all the sets of real numbers, which can be generated from the open sets and finally many steps, using the operations complement and taking the image by continuous function.
Those are pretty simple operations or standard, you know, the continuous function as a standard notion in calculus, as is an open set.
Okay, so we have our objects now. What are our questions.
We can define projective subsets of the plane in exactly the same two equivalent ways.
And once we have that, we can localize the axiom of choice to the projective sets and we'll call this the projective axiom of choice.
So suppose X is a subset of the plane and X is projective.
Suppose it has a property that for every real number are there exists a real number S such that the pair RS belongs to X. So that says that X touches every vertical line.
Then there exists a projective subset of X with that same property.
For every R there exists an S such that RS belongs to why so why touches every vertical line.
But why also has the property that for all real numbers RS and T, if RS belongs to why and RT belongs to why, then s equals T.
So it says that you can choose one point in every vertical section.
So all I've done is take an instance of done is take an instance of the axiom of choice, namely for localize to the reels but we're restricting our objects to the projective sets.
The axiom of choice tells us that why exists, but it doesn't tell us that we can find why to be projective.
So we simplified the problem by only looking at projective sets, but we've made the solution harder to find, because we require that the solution also be a projective set.
The same thing with the continuum hypothesis. So if we have two projective sets of real numbers X and Y, we have the notion of a projective function from X to Y it's simply a function whose graph is a projective subset of the plane.
And with that we can now define a projective continuum hypothesis. Suppose X is an infinite projective set, then one of the following holes.
There's either a projective bijection of the natural numbers with X, or there's a projective bijection of the real numbers with X.
So again, if we had the continuum hypothesis, we would know that excess cardinality and or and excess cardinality are, but here, the witnesses for that are required to be projective.
So again, we both made the problem easier and harder.
By the time of Russell's visit to China, the two problems, the problems of the projective axiom of choice, and the projective continuum hypothesis which were studied in the early 1900s were considered hopeless.
This basically loosens comment in 1925.
They had some success, but they just ran into a wall.
And of course we know now why the problems are unsolvable.
So by results of girdle and by Colin, both of the problems given by the projective axiom of choice and the projective continuum hypothesis are formally unsolvable on the basis of the axioms of second order number theory.
In fact, the two problems are each unsolvable on the basis of the ZFC axioms of set theory. So they are really unsolvable.
But one could hope that all is not lost. Maybe these questions can be answered by sharpening our conception of second order number theory, maybe we just don't have all the axioms.
Okay, so let's introduce a notion of a projective frame. This is not a standard notion is just for this talk.
A projective frame is an extension of the formal SOPA axioms, which provides a complete description of the standard structure of second order number theory.
This extension should be specified by most a recursive set of formal axioms, maybe a finite set added to the SOPA axioms.
The important thing is that this extension should be immune to Cohen's method, more precisely that Cohen's method cannot be used to show that questions are unsolvable on the basis of the projective frame.
So I'm not going to say much about Cohen's method but Cohen's method is the main source that challenges our conception of the universe of sets or even a second order number theory.
There's a girdle frame. There's a projective frame given by girdle's axiom v is equal to L this I will call the girdle frame, the girdle frame implies a projective continuum hypothesis, and the girdle frame implies the projective axiom of choice.
But there are other projective frames, the PD frame. This is the projective frame given by the Mychelski Steinhaus axiom of determinacy.
The girdle frame implies the projective continuum hypothesis and the PD frame implies the projective axiom of choice. So now it looks a little bit like the girdle frame, perhaps.
But there's a stronger version of the projective continuum hypothesis. We'll call this a strong projective continuum hypothesis.
The first set, if you have an infinite projective set and X is not countable, then X contains an uncountable closed subset. So a large set contains a large simple set.
And it's pretty easy to show that the strong projective continuum hypothesis implies the projective continuum hypothesis.
It's basically the Schroder Bernstein theorem.
But they're not equivalent statements.
So projectify the well-ordering principle and form the projective well-ordering principle, and that simply asserts that there's a projective well-ordering of the reals.
Remember that a well-ordering is a linear ordering where every subset that's not empty has a least element. So the standard order on the real numbers is not a well-ordering.
The projective well-ordering principle implies the projective axiom of choice, just as the well-ordering principle implies the axiom of choice.
But we'll see that the converse is not true.
The projective well-ordering principle refutes the strong projective continuum hypothesis.
So we have divergent projective frames.
So Gertl really showed, assumed the Gertl frame, then the projective well-ordering principle holds. That's how Gertl was able to prove the projective axiom of choice.
Davis showed that if you assume the PD frame, then the strong projective continuum hypothesis holds. In particular, the projective well-ordering principle does not hold.
So the frames are very different.
Well, in fact, there are many, many projective frames. There's a well-ordering array of divergent projective frames.
Many other projective frames that have been discovered. Collins' method actually yields projective frames in which the projective axiom of choice fails and the projective continuum hypothesis fails.
In 25 years, the PD frame remained in essence the only projective frame known in which the projective axiom of choice holds and the strong projective continuum hypothesis holds.
And that led to a conjecture that the PD frame is implied by those two consequences.
But if you have the projective axiom of choice and you have the strong projective continuum hypothesis, then you must be in the PD frame.
That would help form a basis for selecting the PD frame.
Remember, we're trying to sharpen our conception of second-order number theory.
But in the 80s, a new class of projective frames was discovered.
And the theorem is that assume the PD frame is consistent.
Then there are projective frames in which the strong or projective continuum hypothesis holds.
The PD frame is false and by a theorem of steel, the projective axiom of choice holds. So that conjecture does not hold.
So it looks like our attempt to understand second-order number theory, and this is the first step into the infinite, really, is failing.
All we have is a whole bunch of options.
For it to succeed, we have to be able to identify the one true projective frame among the ever-expanding and bewildering array of projective frames.
So it looks like we're not in the right setting. We have no way to choose one of these frames over any other one.
So we need to change our perspective, and to keep a new perspective is going to be set theory.
So set theory begins with the transfinite numbers or the ordinals. So the empty set is the smallest ordinal. That's zero.
The set is only members. The empty set is the next ordinal. That's one.
The next set is two. The set that has the empty set and the other set in it.
If alpha is an ordinal, then alpha is just a set of all ordinals that are smaller than alpha.
So the ordinal plus one, that's the next largest ordinal, is the ordinal you get by adding alpha to alpha.
Okay, so the ordinals measure lengths of well-orderings. That's why they're numbers.
Omega denotes the least infinite ordinal. It's a set of all finite ordinals.
Now we come to the universe of sets. So if X is a set, the power set of X is the collection of all subsets of that set, and it's denoted P of X.
And in a transfinite construction, we can unravel the universe of sets defining the cumulative hierarchy of sets. So the universe of sets is generated by defining V alpha by induction on alpha.
V zero is as simple as possible. It's the empty set.
V alpha plus one, that's a successor step. Let's just take the power set of V alpha.
But we have other stages. Those are the limit stages. If alpha is a limit ordinal, then V alpha is just a union of all the smaller V betas.
All the V betas for beta less than alpha. So every set appears.
And that's the consequence of the axioms. Vex is a set, then X belongs to V alpha for some alpha. In fact, if you take this conception for the universe of sets, you're naturally led to the axioms for set theory.
These V zeros empty, there's V one, there's V two, V three as four elements, V four as 16 elements, V five has 65,536 elements, these are getting big fast.
V omega is infinite. And it's the set of all hereditary finite sets.
And interestingly, if you look at V omega as a structure where with membership that's mathematically identical to the structure of number theory, each structure can be interpreted in the other.
If we go one more step and look at V omega plus one, that's mathematically identical to the structure for second order number theory, each structure can be interpreted in the other.
And we have the two canonical structures of mathematics at the first two level infinite levels of the V alpha hierarchy.
And we have the basic axioms and beyond large cardinal axioms, the ZFC axioms are the accepted basic axioms for set theory will not define those are the analog of the PA axioms for the universe of sets, or if you want the analog of the SOPA axioms for second order number theory.
The ZFC axioms are naturally augmented by additional axioms which assert the existence of very large infinite sets.
And these axioms insert the existence of large cardinals.
These large cardinals include in order of increasing strength not an order of discovery inaccessible cardinals measurable cardinals and then it goes on strong cardinals wouldn't cardinal supercap extendable huge axiom I zero car.
There are many other large cardinal notions axiom I zero cardinal is among the largest large cardinal notion that has been discovered to date.
In set theory, logical definability plays a very important role we've already seen that that's how we define the project of sets in a logician's way, but we can do that for any set.
So for every set x p death and this is for a definable power set.
So it's the set of all subsets of x, call it wise, which are logically defined in x with parameters from x. So you view x as a structure with a membership relation, and you just do logical definability.
So be a p death of access a collection of just those subsets of x, which are intrinsic to x itself. You don't need to look outside.
The final set of x depends upon the ambient universe of sets. So these are very different operations in general.
The collection of all projective sets of real numbers is exactly the definable power set of the omega plus one intersect the power of the reels.
The definable power set one can alter the definition of the cumulative hierarchy and this is what girdle did when he defined L.
So let me remind you about the cumulative hierarchy it's the transfinite iteration of the power set operation, and every set is eventually generated.
So what we're going to do is take that definition and just alter the second line.
So we define the L alphas by induction on alpha we start the same way L zeros the empty set, but now at a successor step we don't take the power set we take the definable power set that intrinsic power set.
And at limits ages we take unions, and then L is the class of all sets x such that x belongs to L alpha for some out.
We have an axiom V is equal to L, and simply the axiom that every set belongs to allow for for some ordinal alpha.
And girdle showed that if you assume V is equal to L then the continuum hypothesis holds. That's how girdle showed that the continuum hypothesis was consistent with the axioms of set theory.
Now the axiom V is equal to L implies the girdle frame.
The girdle frame was just talking about the projective sets.
Now adopting the axiom V is equal to L completely negates the ramification of Collins method. Collins method cannot be used to show unsolvability on the basis of the axiom V is equal to L.
And remember Collins method which I haven't talked about is the main source of ambiguity in our conception of sets.
Now the axiom that there is a measurable cardinal is a fundamental large cardinal axiom.
And Scott, this is proved before Colin, assume there's a measurable cardinal and V is not L.
So before Scott's theorem, it might have, one didn't know that you couldn't just prove V is equal to L from the axioms of set theory.
You can't, or you can't.
More remarkably a few years later robot and prove that if there's a measurable cardinal than the girdle frame is false.
What's remarkable about robot and theorem is that it's saying that the existence of a measurable cardinal which is saying some very large set exists is giving you information about small sets.
Because remember the girdle frame is about small sets it's about sets of integers.
Scott's theorem is not of that form.
So the conception of the universe of sets and tails rejecting the girdle frame, because we have to have large cardinals we have to have everything.
So what about the other project of frames we now have a means to reject the girdle frame, but they're all those other frames.
So there was an unexpected and perfect alignment. It began with the theorem of Martin and steel from 35 years ago now, assume there are infinitely many wooden cardinals and the PD frame holes.
But something much better happens.
But this tells us the PD frame is this and the next theorem tell us that the PD frame is the one true project of frame. Here's the alignment.
The PD frame is equivalent to the theory of second order number theory as given by the ZFC axioms with the axioms there exist and many wooden cardinals for each natural number and so we have an exact alignment.
So we have a new truth of FPFA, the PD frame is consistent.
The second order number theory we can define the PD frame I basically did but we don't know it's a consistent frame.
Now we can say it's a consistent frame because it's true, but the consistency of the PD frame. That's a statement of FPFA.
The PD frame is a prediction that this claim that this PD frame is consistent will not have been falsified by the 1000th anniversary of Russell's visit to China.
But has this success really secured the infinite. The PD frame is secured by the conception of V, but this is only by enlarging the scope of investigation from that of second order number theory to be itself.
So this then demands one transition from considering projective frames to be frames.
The basis within second order number theory to argue for the PD frame was only by moving the set theory that we generated that basis, but then we have to understand the new arena. So we need the frames.
The question is, is there an expansion of the ZFC axioms, which yields a conception of the universe of sets, which is both immune to Cohen's method, and compatible with all large cardinal axioms, that is for which there's no
generalization of Scott's theorem.
15 years ago, this seemed completely hopeless.
How would you even show that there's no generalization without identifying all large cardinal axioms which you can never do.
But that was based on a misconception. So I'm going to get a little more technical not to make a number of definitions, but I'm going to lead you to what is the candidate for the V frame.
And it ends with the ultimate generalization of the projective sets.
And it's a definition of Fang Magador and myself.
I'm not going to explain this I'm just giving the definition I'm generalizing on the calculus way of defining the projective sets.
So a set of reels is universally there. If for all topological spaces Omega for all continuous functions from Omega to the reels, the pre image of a by pi has the property of bear in the space Omega.
So those are fundamental notions in analysis.
It's it's
assume there's a proper class of wooden cardinals and every projective set is universally there.
And the Martin steel theorem is really assume there's a proper class of wooden cardinals and every universally bear set is determined.
So the PV frame generalizes to all the universally bear sense.
And there's a key difference here the projective sets are generated from the reels.
The universally bear sets are generated from the universe of sets.
So the other component and the new in the V frame involves relativizing girdle's construction of L to sets of reels.
The only difference is that in the first step. So there is a set of reels we define L alpha of a and R by induction on alpha L zero of a and R is just the Omega plus one together with a that's the only change.
Remember before L zero is the empty set. And then we just iterate taking definable power sets and successive steps and unions at limit stages, and then L of a and R is a class of all sets such that x belongs to allow for for some alpha.
And the reason that we're bringing this in besides I will need it is that we get the following theorem assume there's a proper class of wooden cardinals both a is universally there, then every set we can generate from a using the definition of L of a and R is universally
there.
And so, L of a and R models, the axiom of determines the fact by the Martin steel theorem.
The next component, and this V frame is girdle's class od.
So od is for ordinal definable is the class of all sets acts such that there exists an ordinal alpha such that x belongs to the alpha and access definable and the alpha.
So this is exactly how girdle define it this is really a theorem but for our purposes it's works as a definition, quite elegant, in fact, just as every sets definable somewhere.
The definition of od does not use the axiom of choice nowhere in that definition involves the axiom of choice, and curiously.
So, girdle's point the axiom V is equal to od implies the axiom of choice. So this gives a completely different perspective on the axiom of choice in terms of definability, not in terms of the well ordering principle.
It also pushes back on the skeptical the skepticism on the axiom of choice, which usually goes like this.
I don't believe the reels can be well ordered show me a well ordering of the reels.
That requires that there be a real that's not definable in any V alpha so show me a real it's not definable in any V alpha, because of every real is definable and some the alpha I'll show you a definable well order the reels.
Okay, for the next thing I just recall a notion sets transitive that every element is a subset of the set.
It's like an initial segment of the universe, each the alpha is a transitive set. If M is a finite transitive set it belongs to the Omega and the Omega simply the union of all the finite transitive sets.
So with the transitive set and od we can define hot.
Hot is the class of all sets X such that there is a transitive set M such that X belongs to M, and both M, it belongs to od and M is a subset of od. So we're cutting something out of od.
If V is equal to od, then hot is equal to V, and that's the usual formulation of the axiom V is equal to hot.
One can show that the axiom of choice holds some hot.
Every set that's in hot can be well ordered, and that well ordering is in hot.
So we can now relativize this we have a set of reels we let hot elevator be hot is defined within elevator.
So that's easily done. We first define od elevator it's a class of all x and elevator, such that for some ordinal alpha access definable not in the alpha but in the alpha intersect elevator.
And then we can get hot elevator from od elevator exactly as we got hot from od.
So now we have all the pieces in place, and I can define the candidate axiom V is ultimate L.
So first let me make a comment. Assume there's a proper class of wooden cardinals. If a is a set of reels and a is universally bear, then L of a is not equal to the heart of L of a and R.
Why will the axiom of choice fails and L of a and R because the determinacy axiom holds, and the axiom of choice has to hold in the heart of L of a and R.
So we have L of a and R, and we in this case know that the heart of L of a and R must be smaller.
So here is the axiom for be as ultimate L.
The first axiom part of the axiom is there's a proper class of wooden cardinals that just says for every ordinal alpha there's a wooden cardinal delta such that delta is bigger than alpha.
I'm not going to define wouldn't card.
For each sentence fee.
This is the second part of the axiom for each sentence fee, if he holds and be alpha for some ordinal alpha.
Then there's a universally bear set a such that in hot of L of a and R fee holds and be alpha for some alpha.
It's a reflection of something happening in V into something happening in one of the models hot of L of a and R. So that's the axiom.
In fact, I have to find everything in this axiom except for wooden cardinals.
So it's not a terribly complicated axiom.
The key difference though, between the axiom V is equal to L.
In case of L you define the construction of L and then get the axiom V is equal to L. There's no construction here. It's just the axiom. So this is really kind of a prediction. We don't know how to construct the model yet.
Because of the coupling with the axiom determinacy, we can, we can use the machinery that's been developed in the study of ad to get consequences from this axiom.
So the first consequence if you assume V is ultimate L the continuum hypothesis holds.
It's not so hard. Well, that's a theorem, much harder is assumed V is ultimate L then V is equal to hot.
If you adopt the axiom V is ultimate L a completely negates the ramifications of Cohen's method.
So, ZFC plus the one axiom V is ultimate L is a V frame.
It's immune to Cohen's method.
It's the ultimate generalization of the girdle frame to a V frame.
But now we we've been here before.
And we have to ask the key question is there a generalization of Scott's theorem for the axiom V is ultimate L, because if there is we have to reject the axiom.
And how could we even hope to show there isn't.
What turns out, there is a way.
So, I have to make some more definitions. So I have to talk about the modern language for large cardinals remember those are those axioms asserting the existence of very large sets.
And the basic language involves elementary embeddings which is a logical motion.
Those x and y are transitive sets and we have a function j from x to y. It's an elementary embedding if it preserves truth.
So you take any formula in the language of set theory take any elements from x, and you get x thinks that formula holds at those elements if and only if y thinks the formula holds at the image of those elements.
So the function preserves truth.
So if j were the identity and x is equal to why that would certainly be an elementary embedding that would be trivial.
Okay, so we're going to be interested in more complicated transitive sets so suppose we have an elementary embedding from the alpha to the beta.
Then the following are equivalent.
So j is not the identity.
And the second is that there's an ordinal so such a beta is not equal to Ada.
So the critical point of j denotes the least ordinal such that j of a does not equal to Ada, we're not going to be interested in elementary embeddings that are the identity.
So Reinhardt 45 years ago introduced the notion of an extendable cardinal suppose Delta's a cardinal. Delta's an extendable cardinal if for every lambda bigger than Delta.
There's an elementary embedding from J from V lambda plus one to V J of lambda plus one critical point of J is equal to Delta, and J of Delta is bigger than lambda so it's a kind of push up.
I need one more notion, inner models.
So a transitive class is an inner model if it contains the ordinals and all the axioms of ZFC hold in M.
So transitive class, every element of the class is a subset of the class so the ordinals are a transitive class, but the ordinals are not an inner model.
Since I want to be talking about classes, we have to be a little bit careful.
It's understood that classes have to be definable and be from parameters.
Classes aren't elements of the second number theory you can talk about sets of numbers, and we talk about sets of numbers which are definable like the sets of primes or the sets of twin primes.
Unfortunately, stating that Amazon model of ZSC is not a legal thing we can say because it refers to truth.
So there's a meta lemma that reformulates that into something that we can say.
So if M is a transitive class containing the ordinals, then the following are equivalent M is an inner model and model ZFC that thing we're not allowed to say.
And the second thing is the equivalence is the following hold M intersect the alpha is an element of M for all alpha I'm allowed to say that I just said it.
And for every set X and M the definable power set of axes and M.
So again, the definable power set is playing a role.
So L and hot are inner models.
If the A contained in the reels, the hot and L of a and R is an inner model. Now I'm requiring inner model satisfy the axiom of choice. So in general, L of a and R is not an inner models and inner models the.
So,
we now need some notion of closeness.
We introduced by Hampton for about almost 20 years ago now, and these are the Delta cover and approximation properties. Suppose n is an inner model and Delta is an uncountable regular cards know then delta and has a delta cover property.
So if for all Sigma contained in N.
If the cardinality of Sigma is less than Delta, then there's a set towel in N, such that Sigma is a subset of towel, and the cardinality towels less than Delta. So the slogan is small sets are covered by small sets in N.
There's no assumption here that Sigma is in N otherwise it would be trivial, and small just means of size less than Delta.
And that's the opinion property and that's the approximation property, and has a delta approximation property if for all sets X contained in N, the following are equivalent.
X is in N.
And the second clause, the second property is for every Sigma in N if the cardinality of Sigma is less than Delta, then Sigma intersect axis in N.
So the approximation property is, if your small approximations are in N, then you're in N.
And the first one just so small sets are covered by small cells. Now what was the motivation for these.
If the extension of an inner model by Collins method, then N has a delta approximation property and the delta cover property for all sufficiently large regular cardinals Delta.
I guess I should point out why do we want Delta to be uncountable.
Why not consider the case of Omega.
Well, every inner model has the Omega cover property. And if an inner model has the Omega approximation property, it must be V.
So if you try to do it for Omega becomes trivial and uninteresting.
Okay, so Hamkins proved two theorems. Suppose N zero and N one both have the Delta approximation property and the Delta cover property.
And following our equivalent and zero equals and one and zero intersect the power set of Delta plus equals and one intersect the power set of Delta plus in other words, if you have two models inner models with the Delta approximation and cover property.
If they have the same subsets of Delta plus they must be the same model.
And this shows that, or the proof shows that inner models with Delta approximation property and the Delta cover property are necessarily definable classes. Remember we wanted to restrict the definable classes is necessary.
Hamkins also proves something else. Suppose N is an inner model with the Delta cover and approximation properties. Suppose Kappa is bigger than Delta, and Kappa is an extendable cardinal.
Kappa is an extendable cardinal in N.
Well that's quite interesting. And the theorem holds for all the large cardinals on the list that I gave, except the strongest one, the axiom I zero cardinals. So these are the universality theorems basically if you have an inner model with the Delta cover and
approximation property, large cardinals in the above Delta, go down to N as large cardinals in N, except of course for the largest one.
And there's faults, but there and fails in the case that Kappa is an axiom I zero card. We need another property.
So suppose N is an inner model and Sigma is a subset of N, then N bracket Sigma is the smallest inner model M that contains M and Sigma and bracket Sigma always exists.
So suppose N is an inner model and Delta is strongly inaccessible that just means two to the Kappa is less than Delta for all Kappa less than Delta and Delta is regular so Omega is strongly inaccessible.
So suppose N has a Delta generosity property for all Sigma contained in Delta, if the cardinality of Sigma is less than Delta, then N bracket Sigma intersect the Delta is a colon extension of N intersect the Delta.
So it looks like I'm cheating I'm bringing in colon, but that's okay.
And then we have the strong universality theorem. Suppose that N has a Delta approximation property the Delta cover property and the Delta generosity property.
Suppose the axiom I zero holds at Lambda for a proper class of Lambda, then in N, the axiom I zero holds at Lambda for a proper class of Lambda.
So this is an indication that we really need the three properties, and there are other theorems that make the same case. So we have three properties cover approximation and generosity.
Well now we can state a conjecture. And this is the ultimate L conjecture.
Suppose that Delta is an extendable cardinal, then provably there's an inner model and such that and has a Delta cover and Delta approximation properties, and has a Delta generosity property, and N satisfies the axiom V is ultimate L.
So this is a conjecture of set theory, right because we can talk about inner models with approximation and cover.
The ultimate L conjecture is an existential number theoretic statement. Notice the conjecture says provably there is so that says ZFC plus Delta is extendable prove something.
So it's an existential number theoretic statement if it's undecidable it must be false.
The ultimate L conjecture must be either true or false it can't be meaningless it can't be like CH.
So set theory faces one of two futures.
The ultimate L conjecture reduces the entire post column debate on set theoretic truth to a single question which must have an answer reduces it to an existential number theoretic statement.
What's the first future.
The ultimate L conjecture is true.
Then the axiom V is ultimate L is very likely the key missing axiom for V.
There's no generalization of the Scott's theorem for the axiom V is ultimate L by the strong universality theorem. That was the whole point of bringing in approximation cover and generosity.
One could also say that all the questions which have been shown to be unsolvable by Cohen's method are resolved modular large cardinal absolute.
So if the ultimate L conjecture is true and you assume V is ultimate L, the only ambiguity and V is the height to V.
In other words what large cardinals exist. The reason V is ultimate L is immune to Cohen's method is that Cohen's method is a way of altering the width of the universe.
But if you're going to maintain V is ultimate L you can't alter with without altering height. And that's why Cohen's method is useless in the context of V is ultimate L.
So the other future, the other future is that the ultimate L conjecture is false. In this case, the program to understand V by generalizing the success and understanding the omega plus one and the project of sets fails.
Which is it.
So that's where we are.
We know so much about the ultimate L conjecture now there are many paths to trying to show it's true and there are many paths to trying to show that it's false.
So it will get resolved.
And it's a cliffhanger.
So, if it's true, we had the V frame so we've completed the tax that we secured the infinite arguably.
I mean if it's true that's success in our understanding of V beyond anything that seemed possible 30 years ago.
The idea that you could add one axiom to V that crystallizes out V always seemed impossible.
Based on a misconception.
The ultimate L conjecture is false, then we have to start all over again, and trying to understand the infinite.
Okay, thank you.
Okay, okay, thank you, thank you.
So great talks.
So I do I stop my share.
Sorry.
I often know for discussion.
So I stop sharing.
Yeah, okay.
Okay.
So, any questions and remarks and comment.
Very nice talk.
Yeah, okay.
I saw.
I saw questions on the Q and answer.
So I go to the Q and answer.
Yeah.
Okay.
Am I supposed to type my answer or do my answer live.
Just see it.
Okay, so it's not known.
It's
in part because we don't have the construction of ultimate L if you if we're able to prove the ultimate L conjecture, that would give a construction of ultimate L and that would show that it implies GCH.
There's very strong evidence that it implies GCH. What's known is it implies GCH up to the least measurable cardinal and a bit more.
Okay, it's just the way it's stated.
You're looking basically at the hard of an arbitrary AD plus model that's the L of a and R model.
And really the question is whether GCH holds in that hot and it's known in many cases, but until you have the full analysis we don't know.
We don't know the GCH, but we know a lot. Again, up to the first measurable cardinal. We do know the GCH.
Okay.
I will make the slides available.
I'll send them to Professor Wang after that.
Do you believe that the physical universe is finite?
Well, I believe my experience of it is finite.
That's what the physicists say they say it's finite.
You use it that the pH 11 is much longer than the digits.
Well, so it's, if the strength theorists are right, it's much larger than anything you could ever represent in the universe.
I mean, pH 11 is much bigger than Ackerman. I mean, it's a big number.
It's probably, I didn't do the sit down and think about it, but I bet pH four is really, really big.
So the point of that girdle sentence is in the setting of finite number theory,
what plays the role of large cardinals are the axioms that assert the existence of specific numbers.
So pH 10 exists is a large cardinal axiom and finite number theory.
Remember, finite number theory has no existence terms at all. All you know that exists is one.
So, if you take a, if you take that girdle sentence, you can't use pH 50 to help show that that proof doesn't exist.
You have a contradiction. And if you take finite number theory with pH 50 exists, that seems like a very rich setting.
And all you're looking asking about is strings of length pH 10, which is infinitely smaller than pH 50.
So,
so I see there are more questions.
Well, the difference between the ultimate L approach is it's not just concerned with CH.
It's concerned with V itself.
And all the questions.
So,
you can believe as some many set theorists do that CH has a determinant truth value.
But we're interested in finding that value.
But if you're, if you assume that the universe of sets is a meaningful conception, then all set theoretic statements have a truth value.
Maybe those are truth values we can never discover or understand, in which case, saying it has a determinant truth value doesn't really add anything.
The challenge and set there, I think, is to deal with the independence that's the legacy of Colin.
Colin has created a created a powerful technique for generating ambiguity and the universe of sets the width extensions.
And the question is, can one come to a conception of the universe of sets that's immune to that.
Well, V is equal to L is such a conception, but we have to reject it because of large cardinals so the real question is, is there something like V is equal to L which is immune to Cohen's method.
And there's no example known, even at Hawke.
Except for possibly the V is ultimate L axiom. So that's a that has a candidate.
We know it's immune to Cohen's method, we can prove that now.
But we don't know whether we're going to be forced to reject the axiom because maybe axiom I zero cardinals imply V is not ultimate L.
Or maybe an extendable cardinal implies V is not ultimate L.
So if the affinity forces us to reject the axiom, then we have to reject it, and we have to find another then we have no candidate for an axiom that is immune to Cohen's method.
So, I mean, that's the issue. The issue is
Okay, so the next one is the P max axiom question.
Well,
obviously there and the P max axiom is this canonical axiom in which that gives you a for the sets of reels which implies CH is false lies to continue mizala to
obviously that contradicts V is ultimate L the trouble with the P max axiom is that it doesn't give you any understanding for beyond sets of reals.
There's a remarkable recent theorem so there's a competitor, there was a competitor to the P max axiom, and this is a whole nother line to generate axioms forcing axioms and Martin's maximum.
And about a year ago, a sparrow and Schindler showed that the P max axiom is implied by Martin's maximum and the plus plus form.
There's remarkable convergence.
But there's a footnote.
There's a generalization of the P max axiom. So the P max axiom is usually called the star axiom. There's the star plus axiom and the star plus plus axiom, which I will not define.
I'm going to show these axioms are the same equivalent the star plus and the star plus plus, and as a corollary of that proof.
I also showed that if you look at all the known models of Martin's maximum, the star plus axiom fails.
So before the sparrow Schindler result.
It wasn't known whether the star axiom can hold with mark, whether it holds and some of the mm models or all of them.
So the star plus axiom we now know it fails and all the known models.
But the star plus axiom gives a rich structure to the power of the reels the star axiom just gives a rich structure to the power will make a one.
So now we have a competitor acts I mean we have a collision.
The motivation from Martin's axiom is based on maximality. There's an analogous maximality argument for the star plus axiom.
And these cold these are likely going to collide.
So, again, the is ultimate L is an axiom gives much more information about the universe of sets.
The star axiom or even the forcing axioms. The forcing axioms look like they're giving you a lot of information but they're not really.
They're not answering fundamental questions there are things independent of the forcing axioms, which the forcing axioms cannot settle, or very likely.
So,
which are so
Cohen's method can be applied for the omega plus one, but that's not what you normally do you apply it to be and change the omega plus one within the
Okay, so
because they're not many for things in the omega plus one that you could use
or Cohen forces.
So the
robustness of the PD frame is actually in the ambient universe of sets.
If you have a proper class of wooden cardinals, and you do any with extension by Cohen's method.
We can certainly create new reels, but you can't change the theory of second order number theory, it is immune to Cohen's method you can change what objects there are, but you can't change their properties.
So the theory of second order number theory is unaffected by Cohen's method. I mean, the PD frame is unaffected by Cohen's method.
This is now in the setting of the universe of sets for the proper class of wood.
So in that sense, it's a very canonical frame.
The point I was trying to make was that if your view is second order number theory if that's your universe.
There is no basis that you can cite on why you should choose the PD frame.
You have all these other frames. For all you know the PD frame is inconsistent.
So which frame do you pick and that setting.
It seems to make a choice. It's only by moving to be that you can make the choice and you see that the PD frame is the true frame.
But when you make that move to be.
Well then you should be talking about the frames.
If we're trying to secure the infinite. If we move to a more complicated setting to secure a lesser notion of infinity. Is that really doing anything, unless we can secure the expanded notion.
So that's why one's forced to consider the frames.
And that's why I mean, it's a little bit like
I mean, I'll be somewhat controversial here. I don't think the assertion that PD is true makes any sense, except as within a universe of sets where you have large cardinals.
Okay, there's a
Okay.
I'm looking at a
So Hamkins Hamkins is my student, former student, and students rebel.
So Hamkins is rebelling against me that's good.
He argues that, or he has he has a actually a very extreme multiverse conception, not just a multiverse conception for sets, but a much broader multiverse conception.
It's not anything to me.
The resistance to the conception of V.
It's a set there as much of the energy and research that's been going on and set theory for the last 50 years is an independence is basically studying the generic multiverse.
But that's not studying V.
It's not a model theory of set theory, I would say, I'm being a little bit controversial here.
Now it can help you discover aspects to V.
So when I was a graduate student, projective determinacy was thought to be stronger than all large cardinals.
I remember my advisor solid a telling me that.
So there was a fundamental misconception in the relationship between determinacy and large cardinals.
And that resolution, the under the realization that it was a misconception came from forcing methods that came from exploring the landscape of possibilities for sets for universes of sets.
So exploring the model theory of set theory, if you will, can be an important tool and guiding your intuitions about the universe of sets.
But it is a different subject.
It's the model theory of set theory.
Set theory should be about the, or at least about whether there is a V.
Take the view that there is no V so a multiverse conception.
First of all, why take that view unless there are reasons to take that view.
How does it help understand anything is giving up.
It's just saying that there's no V, or that if there is a V we can never understand it now maybe that's the way.
But we didn't we're not there yet.
And there's a conjecture on the table.
This ultimate al conjecture.
There's a program to prove that conjecture it's not like it's a hopeless conjecture.
And if one can prove that conjecture, then one really has a candidate for a V frame.
Maybe then, trans finite mathematics can really get started with trouble and set theory now is almost any question you ask is unsolvable.
How do you develop a rich mathematical structure, when all the questions are unsolvable.
You want to study a given structure and find truths about that structure.
The questions are unsolvable you're not studying a structure, you're studying possible structures. That's a different subject.
So I think that it's too early to give up on the universe of sense.
There were fundamental misconceptions about why there could be no ultimate L.
We now see that it's possible that there be an ultimate L we have a conjecture.
And we have a path toward proving that conjecture.
Now, you know, I really think this is going to get resolved and the not too distant future.
It's a cliffhanger, but there are ways to refute the ultimate al conjecture and there are ways to prove it.
It's not like we don't know what to do.
And one can debate, you know, you have to choose which side you want to work on, and pursue it.
But until it's had a chance, I think disregarding the idea that there might be a VM is premature.
If the ultimate L conjecture is true, you have a true candidate for a V frame.
You have a setting for rich mathematics where things are not going to be independent, except for height.
So you ask basic questions about sets, you're going to resolve them.
They're not there's no colon method that can be applied to ultimate L, just like there's no colon method for number theory.
So, ZFC plus the axiom V is ultimate L almost puts set theory in the same campus number theory.
There's no method except for girdle sentences for showing independence.
And so maybe in that setting.
We will transform our mathematics, we can penetrate more deeply into the uncountable sets because we're not proving independence results or proving theorems.
That would be the hope.
So as a question, again, this is a question about cardinal characteristics.
The question about cardinal characteristics for me is in the.
Okay, first the first question, how does ultimate L deal with Reinhardt cardinals.
So, that's a evolving story.
But if the ultimate L conjecture is true.
Then,
and you have an extendable cardinal which is a modest large cardinal.
Indeed, then they're no Reinhardt cardinals.
And that's a proof in ZF.
So the ultimate L conjecture which is Z, which is a ZFC conjecture will show that most of the large cardinals that we've identified, which contradict the axiom of choice are inconsistent with the exception of the Reinhardt cardinal itself.
Because there's just, but if you can't have two Reinhardt cardinals where you count Reinhardt cardinals in the appropriate way.
If the ultimate L, so I don't want to get into how you count Reinhardt cardinals, but a Reinhardt cardinals, there's a Reinhardt cardinals as an elementary embedding from V to V.
Okay, and then what do you mean if you have two so I'm being a little evasive. There's a much more elegant large cardinal notion as much stronger called a Berkeley cardinal.
And the Delta is a Berkeley cardinal if for any transit of set to which Delta belongs any transit of set M.
There's an elementary embedding from M to M with critical point less than Delta.
And the ultimate L conjecture the ZFC ultimate L conjecture will show that Berkeley cardinals are inconsistent.
There's another theorem I didn't talk about, because I was trying to not talk about too many technical things.
Going on in the background is something called the hot dichotomy theorem.
So I defined hot.
And in some sense if you're interested in the axiom of choice the question is whether V is equal to hot.
That would be the simplest accounting for the axiom of choice. So something remarkable happens if Delta has is a extendable cardinal.
Then either hot is very close to the, in fact it has the Delta cover and approximation properties, or hot is very far from the, there's no middle ground.
The question is, is that really a dichotomy theorem.
Maybe hot has to be close to be.
If you have an extendable cardinal, and the ultimate L conjecture would imply that it would imply that hot must be close to be.
And so, if you know that hot is close to be from large cardinals that makes it more likely that hot is V.
So the hot dichotomy theorem is a generalization of a famous dichotomy theorem of Jensen.
So Jensen showed that V is either very close to L or very far from L.
And then measurable cardinals imply that the close option is not true.
L is far from the hot is not canonical.
The fact that you could even have a dichotomy theorem was a bit of a surprise.
And you need large cardinals for it without large cardinals the hot dichotomy theorem isn't true.
So large cardinals are trying to give us information.
So if you have an extendable cardinal hot must be very close to be a very far from the, you can't prove this with less than an extendable really.
And the conjecture is that hot must be close to be.
And so that's the hot conjecture provably.
So that's the hot conjecture, and the ultimate out conjecture implies the hot conjecture.
If the hot conjecture is true that would give a lot of evidence for the ultimate out conjecture, and it's possible that the hot conjecture have a simple proof, not known.
Okay, I have a question.
So, first of all, thanks for the talk it's really, it's really enlightening.
Can you say a little bit more about the status quo about the more chaotic future that you've outlined.
I know there's this proposed hierarchy of choiceless large cardinals that you and Peter have worked on.
Can you can say a little bit about what the present status of that line of research is.
So this is this hierarchy of Berkeley cardinals and it looks like there's a hierarchy and the questions one can ask, but and you get some progress, and then you just run into a wall.
So it looks like there's no structure.
I mean, for example, as an indication of how hard things are without choice.
Basically, if you have two natural large cardinal notion, say a cardinal and b cardinal.
You could ask, well, suppose I have an a cardinal and a b cardinal I look at the least a cardinal the least b cardinal.
Well, maybe the least a cardinal is less than the least b cardinal or the other way around.
And you can just, you can decide which is stronger.
You take an extendable cardinal.
I define that.
And you take Reinhardt cardinal, which I only informally defined.
Now, usually, Reinhardt cardinal says there's an elementary embedding from B to V.
And you would think that the critical point of the embedding is the Reinhardt cardinal, but that's not how you want to count them.
It's a j of j, but any embedding from V and the V has a first fixed point. There's a first lambda bigger than the critical point that's sent to itself.
So okay, suppose I have extendable cardinal and a Reinhardt card.
Delta is extendable and land is the fixed point.
So I could ask whether for the least one delta is less than lambda or lamb is less than Delta.
And take two theories.
The least extendable cardinal is less than the least Reinhardt cardinal, theory one, the least Reinhardt cardinal is less than the least extendable cardinal, that's theory two.
Which is stronger.
Doesn't seem to be any way to settle it.
Now, if the ultimate L conjecture is true, then both are inconsistent.
So, you can align them in that case.
So but that just shows you how subtle these choiceless axioms are basic questions, which are usually easy to answer, just become impenetrable.
So, that's, is that an indication that there isn't a structure here I don't know.
So in the Berkeley hierarchy, there's not much that's been done since that paper with Peter and Joanne, and those questions, they just look impossible.
It's the trouble with, if you're in a setting without choice, this is very hard to do anything.
You do some things I mean large cardinal seem to be trying to mimic the axiom of choice there are a number of theorems which show that large cardinals have choice like consequences.
I'll give you one.
Suppose you have a gammas singular of cofinality omave and a limit of extendable cardinals.
Gamma plus is regular.
This is a ZF there.
And not only is gamma plus regular the club filter on gamma plus is gamma plus complete.
So these are the kinds of theorems which are trivial from the axiom of choice, but can fail without the axiom of choice, and large cardinals are trying to mimic the axiom of choice.
And if the, if the hard conjecture is true, then the existence of an extendable cardinal almost implies the accident choice.
So the hard conjecture is true in ZF, if Delta is extendable, all successor cardinals bigger than Delta are regular.
So it all feels like large cardinals are trying to help us understand the universe of sets.
And what they're doing is trying to prove the axiom of choice.
It seems.
So we'll see.
That's a long winded answer to your question but it doesn't seem to be yet a rich structure and the choice was hierarchy just there's some partial results that looks like it's like a make progress and then you just run into a wall.
And it doesn't seem like we have the techniques to resolve that wall.
Okay.
So there are several more questions but I think time is, is.
So you want to answer one more questions.
I'm sure.
Okay.
So I read it for you.
The question is, is it right to expect the GCH would be automatically solved.
Once it came to the future that the RTL program was fulfilled positively.
Yeah, where's the question.
No, the question is not in the queue.
Okay.
So the question is, is reasonable to expect a solution of the GCH.
Again, large cardinal seem to be trying to tell us that GCH is true.
Because you have a solid base theorem.
That if you take a singular cardinal above a singular strong limit above a super compact the GCH must hold there.
So again, it's large cardinals are trying to give us information. No large cardinal can imply the GCH. We know that.
But they seem to be implying as that good approximation as one could hope.
I mean, I think the GCH question is a great question because the forcing axioms give you information about CH.
They don't seem anywhere close to resolving the GCH, either positively or negatively.
And it can't be that we'll never know whether GCH is true.
Say for all large enough cardinals.
No, and it can't be and the trouble is that if the GCH is failing, then you have to the question about what is the power set function.
What's two to the alpha omega what's two to the alpha omega one, you have endless questions. If you assume that the GCH is if you're not assuming GCH.
And they're trans finite number of questions.
And it's hard to see how we would ever answer them all.
Maybe we can never know, but then that's going down the road of we have the universe of sets.
These questions all have to determine the truth values, but we will never know the answers.
And that to me is a somewhat of a discouraging view. So maybe we shouldn't be doing set theory then.
I mean, it's we can never know the answers to the question we want that these are the basic questions in the universe of sets.
So, I mean, I just
we have done.
It's our tasks to set there is to come up with answers not just say there is no answer.
The multiverse view is like saying the multiverse view is more extreme of course it's saying the same they're not determinant questions.
But again, one has to ask what does the multiverse view give you.
If you're going to have the multiverse view.
How do you know the PD frame is consistent.
Because they're going to be universes where it's inconsistent if you allow non standard models.
So the extreme multiverse view can't account for consistency statements.
And I challenge the skeptic
saying the PD frame is consistent as a falsifiable claim.
That's the argument for the truth of the consistency of the PD frame.
No one has come up with an argument that's not eventually the argument it's consistent because it's true PD is true.
So the challenge of the skeptic into the multiverse person is, well, in your mall is P is the PD frame consistent.
It's so why.
When you're rejecting the universe of sets, I don't see how you can take a position on the consistency of the PD frame.
And so what I mean, you can't take.
And, and there's not just a PD frame.
It's, you know, every large card and all comes with a new consistency statement.
And I think it's a remarkable fact and set theory that at least some will make the declaration the PD frame is consistent.
I mean, there's something interesting there. We know we can't prove it, you know, we're willing to say it's true.
But I think the Riemann hypothesis that has the same if you reformulate it has the same syntactic form as the consistency of the PD frame.
There are a lot of number of theorists who believe the Riemann hypothesis is true.
But I've never heard anyone just declare it's true.
And I'll give you a consistent I'll give you a sociological proof.
The seven problems were proposed in 2000 into the seven problems once been solved the Riemann hypothesis is on that list.
According to the original rules and I haven't checked to see if the rules have been modified.
If you came up with a counter example to the Riemann hypothesis you don't get the million dollars.
You have to prove the Riemann hypothesis.
That's some indication that their scientific advisory board wouldn't even make the commitment with someone else's money that the Riemann I pop, you know, either way is interesting.
You know, so what is it about.
We know we can't prove PD is consistent yet we're willing to say it's true. Does that mean.
If we show that you can't prove the Riemann hypothesis we're going to say it's true.
I don't think so. What if Reinhardt cardinal and what if con a Reinhardt cardinal implies the Riemann hypothesis, which may actually be a true theorem that Reinhardt cardinals are inconsistent.
Suppose, you know we discover someone's proved that theorem.
The Riemann Reinhardt cardinal implies a Riemann hypothesis. Are we going to say the Riemann hypothesis is true. I don't think so.
If you prove con ZFC implies the Riemann hypothesis I think everyone would say the Riemann hypothesis is true.
So what is it about con PD why is it we know we can't prove it, yet we say it's true.
There's something going on there that's different in set theory, and the multiverse view just washes that out or the extreme multiverse view.
The extreme multiverse view can't take a position on any con statement.
I mean, you know it depends what multiverse.
Are you going to take the integers as standard and it's just all the standard models, but then how do you know PD is consistent.
You know, if you don't know I don't see in a multiverse conception of the universe of sets I don't understand a coherent basis for the claim, the PD frame is consistent.
PD is consistent.
It's only when you have the, and the truth of PD and the, that you and you can conclude that PD is consistent.
And I challenge anyone to come up with another proof.
I mean, 40 years ago, when PD look like it was so strong.
Not as unclear it was consistent the structure theory gave powerful evidence for it.
But what about the stronger forms of determinacy ADR.
Those were less clear, but now we see how they all fit together and, and we can now make the declaration that ADR is consistent.
But again, this is lost in the multiverse view.
So that's to me is the fundamental issue with a multiverse view.
It's, I don't see how you can make any kind of declaration.
