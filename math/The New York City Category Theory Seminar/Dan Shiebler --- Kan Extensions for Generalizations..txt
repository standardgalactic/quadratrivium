Hello, and welcome to the New York City Category Theory Seminar.
Today is October 20th, 2021, and we are delighted to have Dan Schiebler.
Dan, you spoke in December of last year.
You spoke about manifold learning and overlapping clustering and different types of metric spaces.
Dan is a PhD student in Oxford, and he's working.
Are you still working for Twitter?
Yep.
Okay, good.
Anyways, he's talking about, well, he changed his title, but he's talking about, your new
title is much more, he's talking about con extensions and machine learning, that's a
good title.
Anyways, Dan, take it away.
Totally.
Okay.
All right, so I'll be talking about some of the applications of con extensions to machine
learning, and especially for kind of the process of generalizing from a training data set to
a testing data set, which is something that we do very commonly in machine learning and
sort of the flow of inference in this process of machine learning matches nicely to the
flow of con extensions, and so I'm trying to kind of formalize this intuition.
So to stay up front, this work is sort of inspired by a number of conversations I've
had over a while with Bruno Gavronovic, and then also with my advisors, K's, R, and Jeremy.
All right.
So I'll just start with a quick background on con extensions.
I'm sure most of you are pretty familiar with them.
And I found that this work was, I've always sort of known the definitions of con extensions,
but it can be difficult sometimes to really get an intuition unless you have a particular
example, a couple of particular examples that you like to work with.
So this gave me an opportunity to kind of dive in and develop some intuition around
what's really going on there.
And then we don't know.
I mean, don't assume we know anything.
I'm going to go through the...
It is a hard...
I think it is the hardest topic in category theory, and obviously the most powerful, but
no, go on.
Yeah.
I mean, I think a lot of this stuff, it's always you have...
People have different types of expertise and different types of things that they've
spent a lot of time thinking about.
I didn't get a chance really to think about con extensions before I started this project.
And so it was a good opportunity for me personally to learn more about them.
So basically, the structure of a con extension is we have three categories, A, B, C, and two
functors, a functor from A to B, and a functor from A to C. And we would like to derive the
best functor, F, from B to C. So this is sort of the general pattern of what con extensions
look like.
So kind of intuitively, if we think of G as an inclusion of A and to B, then we're sort
of trying to build some kind of extension of this functor K from A to C to a functor
that goes from B to C. So basically extending from A to B as the domain of this functor.
So we can sort of think of this extension as like interpolations or extrapolations of
our functor K from A to all of B when we have G as the inclusion functor.
And for basically all of the work that I'm doing here, we're going to be using the inclusion
functor for G, a couple of very small exceptions.
So this should substantially simplify the kinds of math that comes out of this.
So more formally, we have the left and right con extensions are actually pairs of these
functors B to C along with a natural transformation from K to the composition of these con extensions
with G or from this composition to K. This is what distinguishes the left and the right.
So basically whether we're kind of talking about the best among all of the functors
that have natural transformations to K or natural transformations from K.
So a very concrete example that I think really helps to sometimes clear up some of the details
here is simply interpolating monotonic functions.
So let's say that K is a function from the integers to the wheels.
So this could be any function and we want to extend K to a function from the wheels
to the wheels.
So basically we want to come up with some meaningful things for K to be equal to on
the numbers that are the non-integer real numbers.
So in this case, K and F are these monotonic functions, Z and R are just pre-orders, the
integers, the wheels, and the left and right con extensions end up being the composition
of K with the floor and ceiling function, so the rounding down and rounding up.
And so this kind of gives a little bit of intuition here on what these are doing.
We sort of have the largest among everything that's lower bounded and the smallest above
everything that's upper bounded.
If there's another example here with unions and intersections with sets that's kind of
very similar to the pattern here, but you can kind of get the sense that we're talking
about a sort of max and min based interpolation strategy.
Okay, so now I'm going to dive into a application here of how we can utilize con extensions
for classification.
So maybe just to start with like what is the classification use case and what are we really
trying to accomplish?
So in machine learning terminology, we'll say we have some kind of training data set.
So some sort of set of samples, which are each pairs of something like an image or set
of text or some sort of feature vector and labels of true or false or zero or one.
And the one being true and then zero again false.
And so in this case, we have the objective to come up with a function that maps each
of these samples given a element of our training data sets produces a true false value that's
in line with what we see on this data set.
And usually we think of this training data set as being a subset of some much larger
sets and the function that we develop on this training data set is something that we can
then generalize to a larger set.
So for instance, we might be trying to classify images of dogs and cats.
Our training data set is a whole bunch of pictures of dogs and cats.
And we have labels for each of them or whether or not they're dogs or cats.
We take this training data set, we build a function that's as good as possible over this
training data set that mapping these images of dogs and cats to the correct true false
labels.
And then we can apply this function over the full set of all dogs and cats and see how
it does.
So this is sort of the generalization procedure that's kind of why I've called this a conic
center generalization and sort of generalizing from the training data sets to a larger set.
Okay, so kind of back to categories and con extensions.
So we can try to characterize this structure, this classification structure in terms of
this pattern of categories and functors that we can apply a con extension to.
So let's say that I is a preorder.
This is kind of our full, I is like our full set of all dog and cat images or whatever else
we have that's where we want to classify and there's some kind of ordering relationship
and we'll talk a little bit about what kinds of ordering relationships are most meaningful
in the moment.
And we have some subset I prime, which is our training data set essentially with the
set of subset of images or subset of data that we're going to build our function over.
And we have some kind of mapping K that maps from I prime to true false or to zero one.
And we would like to learn a monotone of function from I to zero one that approximates K on
I prime.
So just in terms of what the categories are here exactly I prime is just a discrete category.
So it's just the samples that we want to learn over and K because I prime is a discrete category
K can be whatever it wants.
It doesn't need to obey any sort of ordering relationship or respect any kind of composition
that could just map any thing and I prime willy-nilly two zeros or one similar to what
we might observe if we actually looked at natural data, whereas I has I prime as a subset
of it and has actual pre-order structure where there's there's some kind of relationship
between the objects.
And so the if we try to take the con extension in this case from I to false true or to zero
one, there's sort of two pieces that are in play here.
One is our original training data set labels.
So how K assigned labels to everything and I prime.
And the other is whatever is the pre-order relationship that we've placed over I.
So whatever is the kind of set of morphisms that we are assuming exists or choosing to
apply over our data sets that is the kind of full testing sets that we would like to
perform inference over.
So the derivation of a mapping from I to false true is something that we can do with the
con extension.
And so this is what it looks like when we just actually take the con extensions here.
So basically we are, it's like sort of a very simple rule based structure.
And just to kind of, they can intuitively, oh, this should be I am sorry, I mis-wrote
this error.
So basically the left and right con extension splits I into three regions.
So I is a pre-order, and it sort of partitions it into three regions, a region where both
of them agree that all the points should be mapped to zero, a region where both agree
that all points should be mapped to one, and a region where the left con extension maps
everything to one, and the right con extension maps everything to zero.
So we can kind of think of these as sort of setting thresholds, both left and right set
thresholds at different amounts of once you've sort of, for everything that's in our pre-order
that's above this line, we are going to be mapping that to true and everything that's
below that line will be mapping it to false.
And so the left and right con extensions have different policies about what the conservativeness
that they'll apply to this rule set.
The left con extension is really trying to minimize false negatives.
So it's mapping lots of things to true.
The right con extension is trying to minimize false positives.
So it's mapping lots of things to zero or to false, when it's not sure.
So here's just a concrete example, which should make things a little bit more clear.
So let's say I is R and I prime is one, two, three, four.
So we just have a very simple structure here.
And we have K, our base functor that we want to base our con extension off having this sort of
false true, false true structure.
So it's not increasing or decreasing.
It's not monetizing.
It's just alternating.
So in this case, we have that the left con extension is going to be pretty aggressive.
It's going to map everything over two to true and everything less than two to false.
Whereas the right con extension will be more conservative.
It will map everything above three to true and map everything else to false.
So the right con extension is not trying to not have any false positives.
And the left con extension is not trying to not have any false negatives.
And there's a disagreement region between these two of between two and three,
the left con extension and the right con extension disagree.
And on the other end, yes.
I'm not sure I fully understand what is going on right now.
Doesn't the con extension and K have to agree on I prime?
They don't because the requirement is that there's a natural transformation
from K to the composition of left con extension of the inclusion function or vice versa for
the right con extension.
So it's more like the con extension needs to be a lower bound or an upper bound or the best
lower or best upper bound.
In the case of floors and seals, they're able to agree.
But in this case, the tricky piece here is that because K is not necessarily monotonic,
it might be the case that there is no functor that agrees with K on I prime because F needs
to be monotonic because I actually has these morphisms that add additional structure.
So this is like the kind of two pieces that mediates what the con extension will be like.
What are the morphisms in I that are going to create restrictions and what F can be,
as well as what is K actually doing?
One second, don't change.
The category zero one is discrete.
There's no maps between zero and one.
The category zero one has a map, it is a pre-order.
So it's from zero to one.
And I and I prime are just pre-orders.
Pre-orders are partial pre-orders.
Yeah, I as a pre-order, I prime is just a discrete category.
Whose objects are a subset of the objects of I.
Oh, okay.
Yeah, so that's why K can kind of map all willy-nilly because I prime doesn't have any structure.
It's just the objects and identities.
Whereas I is a pre-order and so it needs to kind of,
F needs to sort of respect this pre-order structure.
Okay.
Is there a reason why you don't want I prime to be a sub pre-order?
Yeah, yeah.
So it's like, for instance, I prime is representing natural data,
like data we actually observe in the wild.
And so that data might have any kind of labels.
It might be corrupted.
There might be just the fact that whatever function we're going to learn here is going
to be something that's going to have to have some structure,
but the data that we're training over is more complex.
And so there's some structure that we're not capturing.
It's very common for there to not be the same amount of structure in the natural data
as in whatever function we're going to learn.
And so the idea here is what we learn from I needs to be robust
to the kind of noise that might be present in I prime.
And that's why the left and right cond extensions can disagree over I prime,
because they're sort of have different strategies for dealing with that uncertainty.
And for dealing with the area of points where things are pointing in a way that
don't supports having K itself be functorial.
Okay. Thank you.
Hey, hello. I'm wondering if you could expand upon what you said about the natural transformation.
And is it would you say that the natural transformation encodes the error in the approximation?
You mean from the natural transformations, these natural transformations from K to the
left cond extension and from the right cond extension to K?
Oh, okay. Okay. That helps. Yeah. Yeah. Yeah.
Yeah. I mean, I think I wouldn't say that these are encoding anything about the approximation.
I think these are more just defining what the strategy needs to be.
So in that the left cond extension, right cond extension have different
restrictions with respect to their ability to be above K or below K.
So the left cond extension needs to be above K. It needs to have no false negatives.
Whereas the right cond extension needs to be below K. It can't have any false positives.
So it sort of dictates what the strategy is for dealing with this intermediate region.
Yeah. So this kind of comes to the question of looking at this and sort of thinking through
the, how would we actually utilize this in practice and how would we kind of build something that
is meaningful when we have this region where the left and right cond extensions disagree?
And this region can be quite large. We have a lot of data that has a lot of kind of edge cases and
can be pretty noisy, like a natural, like the situation of natural data. It can be the case that
this region is quite substantial and the left cond extension or right cond extension disagree on a
pretty substantial portion of the data. So one strategy that we can try to do
is to transform our data before we actually derive the cond extension and try to minimize the size
of this disagreement region to minimize the size of the region where the places the left and right
cond extension map our data to is itself minimized. So basically, we tried to structure here. I
apologize for switching between false true and zero one. I meant to have everything be false true,
but I missed it on the previous slides. But so it's false true is zero one or the same thing here.
But basically, we have instead of just simply taking the cond extension
from I to false true, instead we first transform I to I start using some kind of
intelligently chosen function and then apply our cond extension over our transformed data.
And
one thing that we could do is try to minimize what I'm sort of calling the ordering loss.
So this is basically a approximation of the size of this disagreement region.
This can be kind of this is specifically for the case where I is our and we're trying to
minimize the size of this disagreement region directly. In this case, the the ordering loss
is only equal to zero when we have the left and right cond extensions equal to each other.
It's a kind of nice non negative functions, aggressively non differentiable, but that's
not a huge deal because we can use sub gradient descent to solve for not to solve non differentiable
functions without too much of an issue. It's well behaved enough to support sub gradient descent,
which I'm not going to talk about because it's kind of irrelevant to everything else.
The bottom line is it's just it's if we can minimize this function, we can minimize the
disagreement region. And it's relatively easy for us to minimize this function using sub gradient
descent and TensorFlow. So the the objective here is kind of just like a sample. I have
an actual experiment. We actually implemented this in Python. It's pretty simple to show that we could
do this. We can sort of take this function, minimize it, map everything according to these
con extensions and see what our actual performance is on natural data. So I took the fashion MNIST
data sets, which is a pretty simple data set, a bunch of really small 28 by 28 images of clothing
to minimize our our ordering loss over the the task of distinguishing shirts from t-shirt images.
So this is about a tenth of this data set. So it's around like six thousand images
telling the difference of shirts and t-shirts. And then we can actually compute the left and
right con extensions, according to this diagram, over those samples and check what the performance
is, what is our false positive and true positive rates that we get after we kind of take this data,
transform it so that it's kind of mapped onto a preorder so that taking the left and right
con extensions along that behave nicely and then see how well that actually performs in terms of
like what's the false positive rate and true positive rate on those images. And if we look at
extra new images of shirts that we didn't train it on. So we see pretty, you know,
okay results, not what I would call state-of-the-art, but pretty good everything considered.
So the first thing to note is that as we would expect on our trading data sets,
our left con extension has a kind of perfect true positive rates and right con extensions,
perfect true negative rates. This is sort of exactly based on the constraints
that's of how these are defined, the fact that there needs to exist this natural transformation
or these two natural transformations is why we get these perfect true positive and true negative
rates on our training sets. So on the set of samples we actually fit the data on. And when we
generalize this to a larger set to the testing data set images that we didn't try to fit the model on,
this pattern somewhat holds up where we still have better true positive rates for the left
con extension, better true negative rates for the right con extension. So this is sort of an
illustration of how we can utilize this kind of pretty simple con extension structure for actually
doing classification on real data. So what I'll do now is talk about a totally different
example of kind of utilizing the exact same structure, the same pattern of con extensions
and the same pattern of manipulating data for a totally different kind of application and a
different set of categories. And these things are very closely mirror each other.
So this is kind of a big block of text. So just the definitions of these categories.
So there's sort of two main categories that's what we care about in the kind of world of
functorial clustering. So the first is the category of metric spaces and non-expansive maps.
So in this category our objects are metric spaces and our morphisms are just functions
that don't expand the distance between any two points. So that's our if we kind of have a metric
space to apply this function, the image of any two points has either a smaller distance or the
same distance, no expansion. And our category of partitions is the category where all the objects
are a set and a partition of that set. And our morphisms are functions that are essentially
refinement preserving. So if two points are together in our source partition,
then their images are together in our target partition. So if we kind of have these two
structures are sort of very similar to each other in that when we have points that are
together or close together in metric spaces and our morphisms preserve this togetherness,
this is sort of mirrored in parts in that if two points are in the same partition in our domain,
then they're in the same partition in the image as well. And so a clustering functor
is just a functor from a subcategory of the category of metric spaces to parts itself.
That's the identity of the underlying sense. So basically what that's just saying is it's
like a map from a metric space to a partition of that sets that respects the distances. So
if two points are close together in the metric space, then they'll be put, they'll be more likely
to be put into the same partition as parts in kind of a nice way that obeys composition and
has a nice structure. So there's a bunch of interesting research on this stuff,
of kind of digging into what are the implications of these structures and how can you derive
clustering functors and different sets of conditions. It's all very cool. I've looked into
it a good deal myself. There's a lot of very, very cool research that has sort of inspired
everything. And you spoke about it last year and the video is online. Indeed I did.
A plug for the New York City Category 30 seminar.
Anyway, I love this stuff. I think it's Jared Colbertson and Gunnar Carlson,
both are kind of two people who've done a ton of work on the stuff that I've used as inspiration.
Cool. So the objective of supervised clustering is basically if we have a
clustering functor over some category of metric spaces, we want to find the best clustering
functor over another category of metric spaces that might be more restrictive or
have a sort of different amount of structure. So here we have kind of a
diagram here. So let's say we have, so T is some subcategory of mechs,
that's a subcategory, D and then D is a subcategory of mechs. And so we have some clustering
functor tech and we have an inclusion from T and to D. And what we want to do is want to take our
clustering functor over our training center, our sort of smaller category or smaller metrics
based on category and derive a clustering functor over our larger metrics. So this,
the interesting thing here is that D might have more objects, in which case what we're trying
to do with this con extension is come up with a meaningful way to start clustering those objects,
or it might have more morphisms, in which case we might be mapping things quite differently,
rather than try to, it's so similar to the previous case, rather than try to just expand
the same strategy for clustering, we need to adapt the strategy to clustering in a way that obeys the
new set of constraints. So this role, there's kind of two additional potential areas for how D
might be larger. This is the same pattern we have with I prime and I. So I, our preorder,
has all these additional morphisms that I prime doesn't have, and it also has a bunch of additional
objects that I prime doesn't have. And so F needs to both obey the structure in these additional
morphisms, the structure in this preorder structure, in addition, meaningful overall of these objects
that aren't in I prime. And it's the same pattern here, except rather than just kind of elements
of a preorder and preorder relationships, we're looking at metric spaces and not expansive maps
between them as sort of our source of structure. And so we can sort of think once again of K as our
set of labels, essentially, so sort of a clustering of each of the different partish, each of the
different metric spaces in T and F as our sort of function that we're trying to learn, our new
clustering factor that maps metric spaces to clusterings. So in terms of how the con extensions
are actually defined, the essentially the two, again, are kind of the opposite end of the spectrum,
we could sort of think of the left con extension as coming up with the finest, most clusters
extension of K, whereas the right con extension is sort of the coarsest, fewest clusters extension
of K. So the left con extension is basically saying, if it's possible for these two points
to be in different clusters, then put them in different clusters. Whereas the right con extension
is basically saying if it's possible for these two points to be the same cluster, then put them in
the same cluster. And you can sort of think about like if for a particular metric space in D, and
we're trying to figure out like, where do we want to map this metric space? How do we want to cluster
this? The constraints on how this gets clustered is encoded in the set of morphisms that go into D
and set of morphisms that go out of D. The set of morphisms that go into D sort of mediate
which points need to be put together. And the set of morphisms that go out of D sort of mediate
the set of points that need to be pushed apart. And so that then to this kind of like inward and
outward sets of morphisms has a implication on what the which which points can be put need to
put together, which points need to be pushed apart. So there's some like subset of points that's
both Lon and Ron are going to have to agree based on like same cluster, different cluster,
based on the sets of morphisms. There's a whole bunch of other points that are not constrained.
And Lon is going to come up with a coherent clustering that's going to be pushing all those
points into as many different clusters as possible. And Ron is going to be coming up with a clustering
that groups all those points together as much as possible. And so these are kind of two reasonably
coherent strategies to build the clustering for an arbitrary metric space based on the
clustering of a whole bunch of other metric spaces and morphisms between them that were defined.
So here is another little toy example now on what these can look like. So let's say we have
T and D being these sort of simple categories where we have our
I said they're discrete. I'm sorry, that's a mistake. I meant as in there's there are
morphisms between them, but the morphisms are the identity maps from X1 to X1, X2, X2, etc.
But essentially the mapping here is K will map X1 and X2 together,
but X1, X3, X2, X3 will map apart. So Lon, because Lon tries to create as many clusters as possible,
and there's nothing forcing X2 and X3 or X1 and X3 to be in the same cluster,
it will map X1, X2 into a different cluster from X3. However, because X1, X2 are forced to
be together by K, Lon will keep them together. So the only restriction on Lon is that
those two are together, and otherwise it will be able to push everything else apart.
Ron on the other hand is trying to push as many things together as possible,
and since there's no restriction that's preventing it from pushing everything together,
it will do that. So there's no set in T that is X1, X2, X3, where X1 and X3
are different in different clusters, for example. Everything is just two sets,
so there's nothing stopping Ron from just pushing everything into the same set.
So this is sort of the structure here. We have the morphisms mediating what is possible,
then Lon and Ron taking the most conservative and most liberal perspectives on how to map things
based on that set of structure that they both must obey.
Okay, so I have another example. Again, with fashion MS, because it's a great data set and a
lot of fun, kind of trying to categorize how can we actually visualize what kinds of clusterings
we can form there. So this example is a little bit more involved. So we have basically a
training set of images in which
we like to cluster.
Just say that sentence again, because your voice was off for a second. The training set.
Yes, a training set of images that we would already have categories for or already are pre-clustered
and a testing set of images that we would like to cluster.
So just in terms of what that looks like, we have this fashion MS data sets where
there's already labels assigned to these images. So we have all these t-shirts and pants and shirts
and dresses and all these different categories of clothing, 10 categories of clothing.
And this categorization that's already been defined on these clothing images already forms
our training data set. This is our pre-clustered metric space or pre-clustered set. So we still
need to actually define a metric over it. I'll just describe it in a second.
But we can start by sort of thinking that this is a set and we already have a partition of that
set. That partition is the categories that the images fall into or the classes they fall into
avoid confusion. And we can construct the metric space from this with manifold learning,
which I talked about a year ago. But basically we can kind of utilize a whole bunch of different
strategies to take images and define metrics over them based on any number of different types
of strategies. We can put them all into a really big matrix, factorize the matrix and then utilize
distances between the factorized vectors and a lot of fancier nonlinear techniques,
sort of identifying ways that we can use the pixel values that describe these images to then
come up with some sort of distances between them that describe something a little bit more meaningful
than just what their pixel vectors would be. So UMAP is a very popular technique for doing this.
It works pretty well for a lot of types of data. It works very well for small images.
So that was what I used is to UMAP to just sort of take these, take this fashion MNIST
and then map it onto a metric space, metric space for the training data sets
and a metric space for the testing data sets. So now we have, so we have our training data set
metric space, which is just a category of a single object. That object is just our metric space
for our training data sets. And K is our sort of a mapping of this training data sets to a
single partition of that training data set of like, what is the partitioning of this into
like the 10 classes that fashion MNIST applies. Now we have another category, which has two objects.
So we sort of are like i prime and i here are simpler in that i prime is just a single object
category and i is just a two object category. And that category has the same metric space
and then also a testing data metric space, the metric space that we want to apply our
clustering to. We want to cluster this second metric space in a way that is similar to how
we clustered the first metric space. So this is sort of a very different take on supervised
learning. We sort of have a clustering of one, we want to cover the clustering of another
based on morphisms between these two. And so morphisms between these two just need to be
non-expansive maps of ways that we can map images in one, two images in the other that respects
non-expansive relationship. And then we can generate a partition of our testing data set by
taking the left and right con extensions, which will be based on two things. So we based on
what are the morphisms that we choose to include between our training data set and testing data
sets. It can be sort of any set of morphisms as long as this forms a category, as long as we have
the kind of composition being respected and dissociative and all the other pieces.
And that we have a respecting the structure that's in K, where K is mapping
our training data set to a partitioning of it. And so what I did is I just generated a
random category, basically, and I generated a bunch of random categories and tried to see
what would the con extensions here look like, what we actually actually learned.
And so here's what we get. So here on the top left is an image of what the
images our fashion MNIST look like. Once we use UMAC to project it down to two dimensions,
and then we color them based on the category they fall into. So you see usually images in the same
category tend to be close to each other. There's some exceptions, not perfect. There's some overlap,
but there's a reasonably okay categorization of location and images. And so we utilize this
metric called the RAND score. The RAND score allows us to test how similar two clusterings are to
each other. So we can compare our left and right con extensions to the ground truth with the RAND
score. So that's what we get. We just generated a random category and looked at what our left
and right con extensions actually look like. So unsurprisingly, the left con extension has
generates more clusters than the right con extension, as we would expect based on their
definitions. And they both have reasonably good RAND scores with ground truth. So here I have
just a sort of comparison. I utilized the Delta single linkage algorithm where I chose the
type of parameter based on like a grid search to pick the parameter with the best RAND score.
And the RAND score is comparable, but a little worse than this approach, which makes sense because
this approach is actually trying to copy the ground truth clustering directly, whereas this
is just utilizing sort of a best guess of what the clustering should be in unsupervised fashion.
All right. There's other stuff here, but I figured I'd try to keep this short. Take questions.
Thank you, everybody. Thank you. Thank you. It was perfect. I understood it.
Any questions? Any questions? Any discussion?
Anybody?
Okay. I'm going to shut off the recorder. Maybe there's questions after the recording.
