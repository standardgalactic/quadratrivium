Hello, I'm Jay Jay Wachin and welcome to Philosophy and What Matters where we discuss things that matter from a philosophical point of view.
Now, today's episode is about the philosophy of probability.
Britain Russell once said that probability is the most important concept in modern science, especially as nobody has the slightest notion what it is.
Now claims like there's a 30% of rain, Trump will likely win this election, there's a million to one odds that you'll win the lottery, all carry probability information.
But what do they really are probably something out there in the world, or do they only measure our degree of confidence that some event will happen.
Now joining us to discuss a philosophy of probability and why it matters, we have Brandon Finkelson, distinguished professor of philosophy at the Northeast University.
So hello Professor Finkelson, welcome to Philosophy and What Matters.
Hi, JJ. Thanks a lot for having me. It's a pleasure.
Okay, so before getting into our main topic, let's first discuss your philosophical background. You trained in mathematics and physics, and you've been a research science scientist in NASA.
So how did you end up in philosophy.
So my dad's a theoretical physicist, and so I grew up, I was always interested in math and physics for that reason. And I studied those things as an undergraduate at the University of Wisconsin.
I also had a chance to take a few philosophy courses as an undergrad there with some really great people, Malcolm Forrester, Elliott Sober, Ellery Ells, Fred Dretzky, so I was really lucky.
I've been very lucky in general. I was fortunate enough to get an internship at NASA right early on in college, and then I ended up with a permanent research position there.
But I decided pretty much right away after starting that job that it wasn't really for me.
I think partly there are a couple reasons. One, I started to realize that the questions that I was really interested in were more foundational in nature than the questions that the scientists were pursuing.
Another thing was, even then, and this was back in the early 90s, even then in the United States, science in some sense was kind of a rat race.
You know, you really had to apply for grants, and so a lot of what you did was like ask people for money, and then you had to make long term commitments to work on a particular thing.
None of this really appealed to me. And so I thought for a while about what I want to do and for a combination of lifestyle reasons and things I was interested in, I thought being a philosophy professor made sense.
So I reached out to my old professor, Malcolm Forrester, and one thing led to another, and eventually I was back in grad school in Wisconsin again, this time getting a PhD in philosophy.
That took nine years, though, because I didn't really have a lot of philosophy background, so I had to get a master's first, and that took four years, and then I took five years to get a PhD.
I had a lot of philosophy in those nine years and was, again, just very important to work with people who were interested in very similar things, probability in science and in epistemology and decision theory.
And so it was kind of perfect for me. And so I ended up just sort of falling into that. And I really never looked back, you know, since then.
So what is philosophy for you? You mentioned about foundational issues in science and mathematics, but what do you think is philosophy all about?
Yeah. Yeah, you know, that's interesting. I don't think too much about metaphilosophy, but I guess one thing that always fascinated me about philosophy was, at least, ideally, normatively, I always think of philosophy as a discipline that
has to take all questions seriously. And that always appealed to me because I always was interested in just understanding the world better.
And in order to understand the world, you know, one question leads to another question leads to another question, and there's just no predicting where those questions will lead.
And philosophy, it really is still the only, I mean, being a philosopher is the only occupation I know where you can just spend your life following the arguments where they lead.
Wherever that may end up, without regard to that in advance, and that kind of freedom and seriousness about all questions, that's what appeals to me about philosophy.
So who else influenced you to pursue a career in philosophy?
I would say it really was just those folks that I met in my undergrad, the few undergrad courses I took, Terry Penner was another person who I took ancient philosophy with as an undergrad, and he had a big impact on me.
Again, someone who takes all questions seriously and really just wants to discuss and figure things out. And, you know, everyone in Wisconsin was like that when I was there.
That really, I try to carry that spirit with me when I'm in my life now.
So your undergrad training had a huge impact in your philosophical thinking?
It did, really. And then grad school, of course, I was there for nine more years just doing philosophy with those same folks. And yeah, it was just that kind of place where you just did philosophy and you thought about things and talked about philosophy all the time and just tried to figure things out.
Yep. So how did your mathematical training and your physics training help you in doing philosophy?
Well, you know, yeah. So what I've been, I guess, been most interested in is the application of mathematical models to generally to all questions. So I'm interested in how they're applied in mathematics and physics, you know, in the special sciences.
And I'm also interested in how they might be applied in philosophy. And so that led me into this field of formal epistemology, which really is about, you know, the application of mathematics, certain kinds of mathematical models to, if you will, the clarification of epistemological concepts.
Like belief and knowledge and so on.
Yeah, and degree of belief and preference and, you know, all these related concepts. Yeah.
Yeah, so let's go now to our main topic. So what's probability all about. Perhaps you can distinguish between probability with respect to arguments and inferences and probability with respect to claims and sentences.
Yeah, so I guess I tend to just think about probability as something that attaches fundamentally to proposition. So for instance, think about the truth predicate. If you say, oh, that statement is true or that proposition is true or that proposition is false.
I tend to think of probability is similar structurally to that kind of thing. So instead of saying something's true, you could say, oh, it's, you know, it's more probable than not.
Or, you know, it's has a has a 50% chance of being true or something like that. Okay, yeah, I tend to think of that way as fundamentally attached to propositions.
Okay, so you're thinking about probability like to predicate. So it's a property of sentence or sorry propositions.
Yeah, that's how I think of it. I tend to think of it as just fundamentally applying to propositions. Some propositions are more probable than others.
Just like some are true and some are false.
Okay, so probability theory is used in a lot of branches of knowledge you have natural sciences using probability theory, decision sciences, economics, and so on.
But you could, could you tell us about the history behind the theory.
Well, you know, I'm, I'm not so much of a historian. I mean, most of my work on probability has been about the application of what would be morally understood in contemporary terms as probability models.
And so the content, the concept of a probability model is a relatively new one.
So the way we understand probability models in the modern sense really started with Kamogorov in the 1930s.
And so it's a relatively new idea, but but the basic ideas behind before we got to that level of precision with with the concept of a probability model, which is what the modern people are talking about when they talk about probability.
Before then, you know, the history probably is not that long. I mean, really, you know, it's basically that not until the 17th century that you get people who are doing things that we would now call sort of forebears of probability theory.
You know, so Pascal Fairmont, people like that in the in the 17th century.
And then in the 18th century, you had Thomas Bayes and
until that point, I would say that first hundred years of what we would now call the precursors of probability theory.
Most people, I think it's fair to say a lot of the applications were to things like games of chance.
You know, dice and coins and you know, things where physical systems where there's physical symmetries, you know, that you can turn into like lotteries or games of chance.
And I think that was really a large part of the early emphasis.
And then you get into the 19th century, people like Gauss and Laplace and John Venn. And there you're getting more into also what would now be known as mathematical statistics, the theory of errors of observation and normal distributions and things like that.
But it really I would say it really isn't until the 20th century that you get a really rigorous presentation of what we would now call probability models or probability theory.
And that would be I actually think John Maynard Keynes's book, a treatise on probability from the 1921.
I think that book deserves a lot more credit that there's a lot more stuff in there that really appears in a rigorous way for the first time that he usually gets credit for.
Usually people credit Kamogorov and later people, but actually a lot of the stuff's already in John Maynard Keynes's work in the 20s.
And his teacher, W.E. Johnson, did a lot of really interesting work on probability theory before that back in the late 19th century.
But like I said, most of my work on the on in the philosophy of probability, I would say, really starts with Keynes, you know, or, or maybe Frank Ramsey, who was a contemporary of Keynes's.
He wrote a very famous paper called probability and truth, truth and probability and, but they were contemporaries that was around the same time.
And so, for me, that's where really the modern notion of probability and philosophy probability really starts with people like Keynes and Ramsey.
And then of course, Kamogorov in the 30s.
So that's kind of a potted history of it.
Like I said, my work is mostly the stuff in the 20th century in the 21st century.
So let's get to me, John Maynard Keynes. So what, what's your interest here in Keynes idea about probability?
Well, yeah, so Keynes is his book is really the, I would say the most serious attempt to try to codify a notion of probability.
That's really very general.
That's what we call Margaret of actions, right? Yeah, yeah, this is this is before that. So he presents, he presents a theory though that's basically equivalent to some of the simple theories that Kamogorov later presented.
But Keynes's idea was, he was thinking of probability as an extension of logic. So really, it's a general kind of relation between propositions, just like logical consequences, a general relation between propositions, right?
You could talk about some some conclusion following from some premises, or you could talk about some conclusion being made probable by some premises, right?
That was the kind of notion that Keynes was interested in. And I'm very much interested in logic and the relation to probability. So that really appealed to me, like, could you have some general notion of how strong an argument is that uses probabilistic ideas to try to measure the
strength of arguments in a very general way. That was sort of the dream, you know, that Keynes had and people later, like Carnap tried to pick up on that and work that out.
Unfortunately, I wouldn't say that that was a very successful research program. But I do think it led to some really important insights and a lot of really good work and all subsequent work in probability.
So I still think there's tons of wisdom in that Keynes book. There's still a lot of things. I just learned something new the other day that really Keynes had introduced a concept that I thought had only been introduced much later in the war.
But, you know, so every time I picked up, I feel like I learned something that I didn't know was in there.
So what is this concept? This new concept?
Well, it's a thing that's known as a Bayes factor. And what is that? Well, that's like a measure of how strong a piece of evidence is for a hypothesis.
And it's basically would now think of it as a measure of how strong two propositions are correlated, how strongly are they correlated with each other. And there's one way of measuring that which is called the Bayes factor.
It's sometimes called a likelihood ratio. And I had always thought that it was people like Turing and I.J. Good and people like that who had really come up with the Bayes factors.
And well, they certainly did a lot of work with them, but actually Keynes gives a rigorous presentation of them in his in his book.
So that was new to me. I just discovered that recently.
Yeah, so so Keynes had a big impact on me and then later car nap.
And what appealed to me was the is the generality of really trying to do use probability in a way that's as general as logical concepts are.
Like I said, I don't think it worked out, but but it's a cool idea.
Okay, so what's the relationship between that notion of probability with inductive inference or inductive arguments.
Yeah, yeah, that's basically the same kind of thing. So, yeah, so the idea is to have a general notion, a general way of measuring how strong is an argument and using probabilistic concepts to model that.
And there's various ways you can you can of course do that.
So, that's basically is when people talk about the strength of inductive arguments.
That's they're talking about what Keynes was trying to explicate and then later what car nap was trying to explicate is very is a very similar idea.
So yeah, it's this it was a dream that I don't think really was ever realized but.
But it led to a lot of really interesting interesting work and probability.
Okay, now let's turn to our main question, the philosophical issues concerning public value.
I think the big philosophical issue is about the interpretation of what exactly is probability. Is it something out there in the world, or is it something about the scope of our knowledge about things.
There are several interpretations of probability in the literature. So let's begin with the classical interpretation. What is this theory all about.
Well, let's see, would it be alright if I reframe the discussion here a little bit. It's alright. I, I have a different way of framing the discussion so.
Traditionally, you're right. The way people usually frame the discussion is that you've got this theory, like, say, call McGraw's theory of probability or Keynes. This doesn't matter.
You've got some formal theory of probability and then there's all these different ways of interpreting it. Right. So there's subjective interpretations and objective into it. I actually don't.
I don't really like that framing. Okay, I think that's not really the best way to think about what's going on. So let me let me reframe it and then we can we can address all the same questions within the different frame I think.
So you've got these formal models, these mathematical models. Let's just call them probability models. And there's lots of different kinds of probability models out there. Right.
And there have been and new ones are developed all the time. You know, this is what mathematical statisticians do and machine learning people. And so people are always developing new problems.
So let's just talk about probability models. And these are just mathematical models that obey certain principles of probability. Right.
And now I tend to think of it this way. So you've got these models. And now the question is, well, what are they useful for.
Okay.
So, so, so let me give you an analogy. So, you know, in physics, there's all kinds of models. For instance, there are Newtonian models of planetary motion and then there are Einsteinian models and for that matter there are Keplerian or Ptolemaic models.
And I just tend to think, well, okay, we've got these models. What are they good for. So it turns out some of them are better for certain purposes than others.
Some of them are better for making predictions or explaining certain phenomena and others are better for other explanations or other predictions and so on.
So that's how I tend to think in general in science of the application of mathematical models, you can ask, well, what are they useful for and in which contexts.
And that shifts the question you see so we're now we're not we're now we're not asking what is probability. I'm not sure I understand that question.
But I do understand the question, hey, we've got these mathematical models. What are they useful for and in which contexts.
It just becomes like any other part of science where you've got mathematical models and you're applying them for different purposes.
You can ask, well, are they useful for this purpose. Are they more or less useful than these other models for this purpose in this context.
Okay, that's how I prefer to frame this. And so this means also I'm a pluralist. So I think there are many things in nature and in the world that can be modeled in better or worse ways for various purposes
using probability models. And so let's take some examples.
Let's let's just take physics for instance that's not even and then we can get to we can get to other kinds of other applications of probability models but let's just take modern physics.
There's plenty of applications of probability models in modern physics for instance in quantum mechanics.
When we we we use probability models to model how likely it is that certain measurements will be made in certain systems.
And we and we think those are really good useful models for that purpose.
And also in statistical physics, you know, we use probability models to model things even even in classical statistical physics.
So, you know, they're, they appear to be very useful and they make good predictions they seem to be explanatory about certain things in nature.
And so I would put it this way, if you take your best theory of the physical world.
Let's, and I'm going to assume it includes like quantum mechanics for instance, then I think if you accept that theory, then you've got good reason to think that there are natural phenomena which are well modeled using probability theory using probability models.
I think that's pretty much all there is to thinking there's good reason that there's probably to think there's probabilities in nature.
Okay, forget about probability.
Think about any theoretical property think about mass, think about energy.
Think about space time curvature.
Why do we think that those things exist in nature. Well, because our best theories postulate them in a way that seems to be predictively and explanatory and dispensable.
That's why we think they exist.
Same thing's true of probability and physics. So of course there's probability in nature. I mean, I'm just not sure what the question is.
If you accept modern physics, then I think you are basically committed to there being probabilities in nature.
Because what does that mean it just means that probability models play an indispensable explanatory predictive role in the theories we accept as best of nature.
That's all there is to being committed to probabilities in nature, or for that matter to being committed to there being mass in nature, or energy, or any other theoretical entity, or electrons.
You accept the electrode theory it says they're electrodes so you think they're electrons end of story. That's it. So I think the same thing about probably so yes I think there are probabilities in nature.
Now, of course, that view could be revised. If a future theory came along and and no longer appear that probability was indispensable, then sure, we could, we could change our minds.
But I think there's very, very good reason to think that there are probabilities in nature as good as there are reasons to think there are electrons in nature.
No, I like that argument so you're basically presenting and in this in dispensability argument, a kind of pragmatic argument for this one as well.
I mean, like, I, but I had to be a very naive realist about everything so like when I read Euclid I proved there are infinitely many prime numbers, from which it follows there are numbers. So I think there are numbers.
What's the problem.
Look, you can talk yourself out of anything. And if you're in the epistemology seminar and you're paying very close attention to skeptical doubts, then you can talk yourself out of anything, but that's just not reasonable.
No one's a skeptic. So if you accept physics, then you think there's lots of things electrons, space time curvature.
All kinds of weird stuff.
I like the idea about models so probability models represent things in the world. So it might represent the quantum phenomenon, it might represent as well as our decision making.
Yes, exactly. And in fact, I think it can be very useful as well.
For those purposes. And but we see this a lot right, I mean, there's lots of mathematical models that are useful all over the place for instance take linear algebra.
I mean, take matrix mechanics, it's everywhere, right where linear algebra is everywhere.
Right, it's it's useful as a modeling tool, all over the place in science. And so is probability. And to that extent. Yeah, there's good reason to think that quote unquote there are probabilities and all of these domains.
Okay, so let's go to the interpretations of these models in terms of how they work in explaining phenomenon. For example, in classical classical interpretation, the fair mom Pascal interpretation, what is it good for.
Okay, so, um, well, again, I wouldn't I that question is a little strange to me. So the way I would put it is, here's how I would say it now. I mean, you know, they didn't have the technology and the and the language to say this back in those days.
But I think what I would say now is well, what what those guys who are working on games of chance, what they were onto was the fact that there's a class of probability models.
That's very useful for describing certain phenomena that exhibit certain kinds of symmetries.
So, you know, if you've got a die that's six sided and it's, it obeys certain physical symmetries, then, you know, when you throw it, there's roughly an equal chance that it's going to come up on one of the faces, you know, um, that's be due to physical symmetries and things like that.
And I think that just shows that probabilities very useful for making predictions about those kinds of games of chance, or take a lottery, for instance, if you've got a big lottery and you you mix up a bunch of balls in an earn you shake them up, and you mix them up real good and you pick one out.
There's a roughly equal chance that you're going to draw each of the balls. And so those classical models which work on, they're basically finite frequency models right there basically you divide by the number of cases you assume each one's equally probable.
They apply really well to cases where there are these kinds of physical symmetries like lotteries or games of chance. And so I think that's where those models are most applicable.
Um, or that's one of the areas where they're very applicable, but you see, they're also applicable in statistical physics. I mean, so when you talk about the motion of Brownian motion or motion of lots of small particles, you can describe those also using, I mean,
essentially, very similar kinds of probability models that exploit certain physical symmetries.
So how does, how does relative frequency theory, Bayesianism fit in your picture of interpreting probability?
Well, okay, so, so, yeah, so Bayesianism is a little bit, I would say a little bit different. So the, so the classical theory is, is I would just consider it.
I mean, I tend to think of everything ultimately in more or less Bayesian terms. But to me, that just means, I think of everything in terms of what class of probability models are we talking about.
And then what are they useful for modeling? You know, so those classical models are useful for games of chance. They're useful for things where there are certain kinds of symmetries.
And that corresponds roughly to a kind of finite frequency way of thinking about probability.
Finite frequencies, those are basically just probability models, right? So finite frequencies obey the laws of probability.
And so that's another thing probabilities very useful for modeling finite frequencies with, because those obey the laws of probability.
So, so yeah, I mean, I guess I would just say, you know, let's talk about some phenomenon or other, whether it's in the natural world, or it might not be, you might get into normative things. Okay, but those to me those are just phenomena to
you know, then there's things you can use to model to model those. So, um, so yeah, so, but you know, usually this objective subjective distinction.
I don't really love those words, but I think normally what people mean by that is like, basically you've got some problem class of probability models and then the question is, well, are you modeling some, let's say phenomenon in nature that say doesn't intrinsically
have human minds. So like lotteries or you know, other things where there's basically finite frequencies going on or something like that.
Or quantum mechanics. That's another example of an objective kind of probability, because you're modeling a physical phenomenon. Right.
That's, let's just say, minded dependent depending on your interpretation of mechanics.
But you know, I would think of it as being minded dependent.
And then there are the, let's say the mind dependent applications of probability models, and there's plenty of those, because there's plenty of things involving human minds that we think we can also model with probability models.
And so when people talk about Bayesianism, I mean, that's that word means a lot of things. But I think typically they're now now you're getting into a discussion usually of degrees of belief.
And so now we're talking about mental things that we're modeling, or, you know, either mental or epistemological kinds of phenomena that were that we're modeling.
And it turns out to be useful for a lot of those things too.
To varying degrees. So for instance, if you're a psychologist. Well, then what you're mainly interested in is how people actually, what are their degrees of confidence actually like so when we talk about how confident a person actually is.
What's the structure of those degrees of confidence? How do they behave? Are they accurately modeled using probability models? Well, sometimes they are. But as, as we know from a lot of research and behavioral economics, people's degrees of confidence don't always line up with the probability
calculus too, too well. Sometimes they do sometimes they don't we have your biases and heuristics that we fall into which can make us deviate from probability in certain ways.
But we still think probability is useful, you know, even for the for modeling some of those phenomena. And when it's not useful, like when it when it goes wrong when it's not accurate say, then I think we think that's interesting as well.
So when people like Kahneman and Tversky discovered that people's actual degrees of belief, often systematically deviate from probability, they don't obey the laws of probability, and certain systematic ways.
That was very interesting.
And the reason they won the Nobel Prize for that stuff was because it wasn't just because Oh, that's interesting psychology, it was because people thought that there was something normative about probability.
So that the deviations were somehow bad.
Right, it wasn't just Oh, this is how people's minds work so give me a Nobel Prize. It was, here's how people's minds work and there are systematic deviations from this structure of probability which we somehow think is normative in some way.
And that's why it was so interesting that's why they won the Nobel Prize, it was the deviation between the models which are taken to be normative, and the actual behavior of human confidence.
So that's something I've done a lot of research on because I'm most interested in the application of probability to normative concepts.
So to like rational degrees of confidence or rational degrees of evidential support or things like that things that would come up in epistemology.
And that's really what my focus has been on how to use probability to model those normative concepts, but I still think of it the same way. Okay, so you've got some phenomenon. It's a normative phenomenon.
Okay, so it's a normative phenomenon. That's fine. I mean we're all naturalists, ultimately right.
I mean okay it's normative, but still it's a phenomenon. And then we use probability to model those normative phenomena in certain ways.
And I think probability is pretty useful for modeling some of these normative concepts.
A lot of people seem to agree with that. If they didn't, then Conom and Tversky never would have won the Nobel Prize because why would they know would care.
I mean, you know, the reason that was important was because people thought there was something normative about probably that is, they thought that probabilities were useful for modeling the normative structure of confidence, not just the descriptive structure of actual psychological
And that's really that interface. That's something that I'm very, very interested in that descriptive normative interface of people's beliefs or degrees of belief, and how they're structured and the extent to which probability models are useful for modeling them.
And so that's the way I tend to think about this. But as I said, I'm a pluralist because I look at the world and think, well there's all these phenomena out there. Some of them are are used to be modeled using probability.
Those are the ones I'm interested in because I like probability.
If you do your research, the rational norms and how probability fits into this picture.
But before that, let's just ask a question. So we're thinking about probability models in terms of the standard probabilities here.
Yeah, yeah, yeah, there's, and that's pretty, that's pretty universal. I mean, so for the most part, I mean philosophers worry about non standard probabilities and weird, weird probabilities but for the most part when people talk about probability
in science, you can understand them is talking about you know what common ground was talking about or what Keynes was talking about those things have the same formal structure.
Okay, so could you give us some of the principles of probabilities here standard probabilities here.
Oh, yeah, yeah, so probabilities actually really simple.
You can think of it they're basically just three principles that probability satisfies.
One is that if if some proposition is true in every possible world, then its probability is one, or that is it has 100% chance of happening.
It's true in every, it's true in every possible world. Okay, okay, so that's, that's like one principle, anything that's true in all possible worlds has maximal probability.
That makes sense.
Here's another principle, there are no negative probabilities.
That's just like, you know, also like we assume there are no negative lengths.
Right. Okay, so it's similar to that. I mean that's not really that substantive. And then the only really substantive principle is the third one, which is called the additivity principle.
And that says if you have two mutually exclusive propositions, then the probability that at least one of them is true is just the sum of the individual probabilities of each claim.
Okay.
Well, another way to put it is the probability of a disjunction right of mutually exclusive propositions is just the sum of the probabilities of the distance.
And that's it.
That's that's all that's it any measure satisfying those three things is a probability measure and any model satisfying those as a probability model.
Okay, so let's go to your work about you mentioned about the kind of diversity literature. So what is the probabilities you're doing here.
Yeah, so, um, so my research, a lot of it early especially early on was about and this relates to the car that popper thing that you that that we'll get to later.
And Carnap and popper were both interested in this thing called confirmation.
And Keynes was to in a way what Keynes was talking about was also confirmation. So what is confirmation.
Think of it this way, it's a relation between propositions. It's, and you can think of it as a relation of support.
So, you could say one proposition supports the truth of one proposition supports the truth of the other, to some degree. And if that happens, then the former said to confirm the ladder.
Right, so we can talk about an evidential proposition confirming or supporting a hypothesis.
And then you can talk about degrees of support.
So, and there's turns out there's lots of ways of measuring degrees of support that disagree with each other in interesting ways.
And that's what my original my dissertation research was on I've done a lot of research on that how to measure degree of evidential support degree of confirmation.
So, that, and as I said, there's many proposals out there, and they disagree with each other in interesting ways.
And I advocated for a certain way of measuring measuring that which is basically what the base factor the thing I was saying that Keynes actually talked about before anyone else did but he doesn't get credit for it.
I mean he rigorously to he really defined what it was, he didn't call it that but by the way people only call it a base factor out of deference to base but you know base was writing, you know, 150 years before that.
But, but it's really not even right to attribute this to base. That's, it's not in there. It's not in there. It was really Keynes that rigorously identified this thing.
So, base factors were used in World War two to help decrypt the the German enigma code. That was work of Alan Turing and I do good.
They use that as a measure of evidential support to try to gauge how strong the evidence was for certain certain codes and things like that.
So it's got a pretty long history and I give certain defenses of it.
And psychologists got interested in this too. So a bunch of psychologists. It was Dan Osherson I think a Princeton who reached out to me originally, and said, you know, we're interested in the psychology of confirmation the psychology of evidential support how do people make those judgments and are these measures
of modeling those judgments. And, you know, it turned out that the measures I was defending actually are the ones that make the best predictions about people's judgments about confirmation.
But that was like a coincidence because I was giving like normative just, you know epistemological justifications for the normative status of these models.
And it turned out though that actually those were pretty good predictors of certain kinds of judgments of support that people were making.
And that got me into working on things like the conjunction fallacy and other other things because it turns out you can use confirmation to explain away some of these deviations from rationality quote unquote that people focused on.
So, but instead of talking about probability you focus on confirmation.
And by doing that you actually a lot of the things people say, don't sound that crazy anymore. So a lot of the responses to some of those experimental stimuli that Conor and Tversky were using actually make a lot of sense if if you understand them as being about confirmation
and not just probability. So if you understand them as being about degree of evidential support, and not just how probable one thing is given another thing.
So, yeah, so, so there's so basically Carnot described this in his work, there's two different notions basically at play here. There's conditional probability, like how probable one claim is given another.
That's one thing, but then there's degree of confirmation, as we would call it now and that's different because that has to do with not just how probable one thing is given another.
But how much the probability is changed. So, how much, if you learn one thing how much does that change the probability assigned to another thing.
Right. So, when you're thinking about arguments for instance you can think, there's a couple different ways of thinking about how strong an arguments you can think, how probable is the conclusion, given that the premises are true.
That's one thing, but you could also ask a different question. How relevant are the premises to the question that is how much the premises raise the probability of the conclusion over and above its prior probability value.
That is before having taken into account the premises.
Completely different thing. Those are just different. And so my whole view about this is that there's really two dimensions of argument strength or of support, there's conditional probability and then there's confirmation.
And my work has been on confirmation because I think relations of relevance are just more interesting and more subtle than relations of conditional probability.
And so, modeling relations of relevance as confirmation turns out to be much more subtle, and that's why there's much more disagreement about how to do it, what the right ways to do it are.
And because it's more, it's more subtle, it's a more subtle thing to do. And, in fact, that was what the current proper debate was, was about, really, it was about these two different concepts and how they relate to each other.
Okay, so my work has, yeah.
Yeah, so could you give us first an example of each of these notions of conditional probability and relevance.
Yeah, so, so, right, so conditional probabilities is like this.
You suppose that some premise is true. And then you ask yourself, okay, given that a supposition, how likely is it that the conclusion is true.
That's one notion. So let me give it, so let me give you an example that'll give you the contrast right away.
So suppose I tell you that there's this guy Fred Fox, and he's a male. And, and I tell you, I asked you find question.
How probable is it that Fred is not pregnant, given that he's been taking birth control pills, you know, rigorously for the last year.
Well, answer, it's very probable that he's not pregnant 100%.
That's right. So the conditional probability is very high, but notice, it's not because the premise has any relevance there.
Right, right.
Right. So, so, yes, the probability that he's not pregnant is very high given that he's taking birth control pills, but it's the same as it would be.
It's independent of whether he's taking it would be high regardless of whether or not he took the pill.
That's the difference. So if what you're interested in is how relevant the premises are, well, in that case, there's zero relevance, even though there's very high probability.
And that's the shortcoming of the traditional the traditional way to measure argument strength and this goes back to Keynes and many people since then.
And when people talk this way, they think, Oh, you just take the conditional probability of the, but that doesn't make sense because would you say it's a strong argument for his non pregnancy that he's been taking the pill, given knowing that he's male.
No, that's not any reason at all to believe that he's not going to be pregnant.
It's not relevant, because whether or not he does it, he's not going to get pregnant.
I think relevance is a necessary condition for something being a reason for something else.
If it's not relevant, it's not a reason.
Nice.
Right. So, so, so that's, so my view is that there's actually two dimensions of argument straight they're both important.
So high probabilities good, but also relevance matters.
And that's where the theory of confirmation comes in, because that's about relevance, how to measure it, what's its structure. And it turns out to be very subtle and complicated and behave in a much different way than than just probably conditional probability does.
So where does the car nap, Paul for debate come in here.
Right. So, so car nap, as I mentioned, he wrote this book called logical fundage the probabilities amazing work on probability.
And there's a lot of stuff in that book.
But a lot of it is just about conditional probability, not all of it, but a lot of it is just about conditional probability, right. The way Keynes was talking about conditional probability.
So that was also what Keynes was really interested in.
Popper wrote a review of the book and he said, well, you know, car nap, you're using this word confirmation, but confirmation has these two senses, right, it has the relevant sense and then the conditional probability sense.
And so, car nap, in response to popper wrote just a preface to the second edition of his logical foundations, in which he says, yeah, yep, that's right there is two notions.
And in fact, the book already had contained a whole chapter on relevance. So it's, so it's not like he didn't know about relevance. He did.
And, you know, so he acknowledged that and, you know, was a little more careful in the preface about that but the other book was already, I think, fine.
So I think, so my view on the proper kind of controversy is that, you know, it was a little it was basically popper was being somewhat unfair and uncharitable to to car nap because because in the book there's a whole chapter on relevance which is tons of good stuff and then very informative about the nature of
relevance.
On the other hand, I will say popper is right that more work needed to be done on different ways of measuring relevance different ways of measuring confirmation. And, you know, kind of basically concede at that point, eventually, he was originally going to write another volume about that.
He never got around to it.
Partly because, you know, that dispute with popper got pretty nasty and kind of did not like, kind of was, he was not a fighter, you know, popper like to like fight with people.
And Karnap was not like that he was, he was a much more, much more of a gentleman, I guess is what I would say.
And so he wrote that preface and then he never, he never actually and so my dissertation was really that was the inspiration my inspiration was the popper kind of controversy and then Karnap's response and I'm like well, why don't I just write my dissertation on the different ways of measuring
conference.
That's what I did.
So, how do you measure confirmation how what's this relevant relation between premise and conclusion.
Yeah, so there's so right so because this is just relevance, right.
Well, there's lots of ways of saying that two propositions are probabilistically relevant to that is that one raises the probability of another.
The way you could say it is that the conditional probabilities greater than the unconditional probability. Right. So, like the probability of h given e is greater than probability of h unconditionally.
That's one way to say it, but you could also say the probability of e given h is greater than the probability given knowledge. Those are equivalent.
Those inequalities are and in fact there's a whole bunch of inequalities that are like that they're equivalent they're all true if and only if the others are true and probably three.
That's the whole thing. If you define measures, based on each of those inequalities so like you could take the difference between the conditional probability and the unconditional problem, or you could take the ratio.
Or you could take the difference between the probability of e given h and the probability of e given knowledge, etc. And you could, you could, or the ratio of those. Right.
So there's like a ton of ways of defining measures based on the same qualitative concept.
Here's what surprising, which is what I really explored in my dissertation, which is they all behave in different ways. They all place different orderings on pairs of evidence and hypotheses, so they don't even agree on which arguments are stronger than which.
And so that means in a sense they're all measuring different kinds of relevance.
Right. And so now the question becomes this is cool because what this does is it introduces it opens up a whole class of different models of kinds of relevance.
And so now you get into the question of well, which of these models are useful for modeling which relevance relations in which context.
I think there's depending on the context of what, what kind of relevance you're measuring and what you're what the application is.
There's lots of different answers to that.
However, I would say that if what you're interested in is what Keynes and Carnap were interested in, which is thinking of these things as generalizations of deductive entailment or deductive implication.
Right. So if you if you're thinking that way, then what you want is you want the measures to be such that if the evidence guarantees the truth of the hypothesis, then that's maximal confirmation.
And it turns out there are very few measures of relevance that obey that property.
But there are some.
Taking deductive logic as a special case. Right. So you want the valid are you at least the non trivial valid arguments. Right. I mean, not the ones with contradictory premises or okay forget those right.
Forget the paradoxes of relevance or whatever just like the ordinary the ordinary valid arguments. You want those to be the strongest.
Right. That's that's the old idea of inductive logic as a, it's a generalization of deductive.
If you impose that constraint, then you get down to a much smaller set of measures.
And now you there's there's a lot that's just turns out to be a surprisingly strong constraint. And so now you're down to a small number of measures of argument strength in the logical tradition.
And that's that those are the kinds of things that I those are the kind of models I've been exploring the most.
I'm not interested in this project of argument strength in a logical sense in a way that generalizes logic.
Okay, so you might not be interested. Maybe you're interested in a different notion of relevance. And that'd be fine too.
So I'm a pluralist, like I said, but, but that's a particular kind of relevance relation that we apply to argument evaluation that that's as a logician one that I'm very interested in.
So what is the relationship now between this kind of idea and kind of an reverse key literature.
Oh, yeah, yeah, good. So, so one of the great examples that kind of reverse you talk about is the conjunction fallacy.
So what is that. Okay, so those are cases in which people say that a conjunction is more probable than one of its constructs.
It can't be true, because a conjunction is logically stronger so there are strictly fewer possible worlds in which the conjunction is true.
So that means any measure of how many worlds there are, which is all probably really is, would have to be smaller for the can it can't be bigger for the conjunction that it is for one of the conjuncts right because there's just strictly fewer worlds in which the conjunction is true.
So that can't be more probable. Okay, because again, probably is just a measure of how many roughly the proportion of worlds in which a claim is true or something like that.
So, the conjunction strong the conjuncts.
So, so that's true. And so that looks like people are being irrational they're giving this incorrect answer about probability and that's, that's fair, and that's fair but here's a really cool thing that me and and some colleagues in psychology mainly been
and Katya Tentori and then their colleagues that who have done a lot of work on this since then. What we showed is that, yes, of course a conjunction can't be more probable than one of its contracts.
But, if you ask a different question, which is, can a piece of evidence, confirm a conjunction more strongly than it confirms one of the conjuncts. That is, can it raise the probability of the conjunction more than it raises the problem and the answer of course is yes.
And in fact, you can prove some very general results that in all the kinds of examples that come into first you talk about.
That's actually what's happening. There are cases in which the evidence that they give you confirms the conjunction more strongly because it's more relevant to the conjunction than it is to one of the conjuncts.
In fact, it might just be irrelevant to the one of the conjuncts, but strongly relevant to the conjunction and there's no problem with that. And that's one of the ways in which relevance behaves differently than probability, right.
Relevance is weird. You can have something that's strongly relevant to a conjunction but irrelevant to one of the conjuncts.
That's weird, right. How could something be strongly relevant to one to the conjunction but irrelevant to this logical consequence of the conjunction.
Right. And if you want a simple example, here's a simple example.
So, suppose you're going to draw a card at random from a standard deck. Okay.
And you want to know, you're considering two hypotheses, right. It's the ace of spades versus it's an ace.
Now, it being the ace of spades entails that it's an ace.
Right, right. So you can think of ace as a conjunct in the ace of spades conjunction. So it's like a case like that. Okay.
Now, suppose you learn that the card is black.
That's very relevant to the claim that it's the ace of spades.
Right, right.
Because that now becomes twice as probable than it was a priori. It goes from one over 52 to one over 26.
Because there are 26 black cards.
Exactly. And only one of them is the ace of spades. But now ask yourself, has it, if you learn the cards black, does that tell you anything about whether it's an ace?
Nope.
There you go. And there you go.
Right, right.
And so that's a very simple case that shows you that relevance just behaves differently than conditional probability.
Yeah, but it raises my beliefs that I have the ace of spades.
Yes, and that's exactly, exactly. And so, yes, it would be crazy to say that it's more probable, given that it's black, that it's the ace of spades, than that it's an ace.
Right.
That's crazy. But would it be crazy to say that the evidence that it's black confirms the ace of spades hypothesis more strongly than the ace hypothesis? No.
No, because it's not even relevant to the ace hypothesis at all.
But it's strongly relevant to the ace of spades hypothesis.
So you have two notions here that's pulling you to different directions.
Exactly. And this was Popper's point in his review of Carnap. He was saying, hey, look, yeah, conditional probability is great, but you've also got this relevance thing. And sometimes they come apart.
There's an even simpler kind of case where they come apart. So again, a Kahneman Tversky case, the base rate fallacy, the so-called base rate fallacy. So when you ask people to calculate how probable it is they have a rare disease based on a single positive test result from a pretty reliable
test, they'll say, oh, it's very probable. I had a disease when in fact, if you calculate using base name, you find out it's still very improbable that you have the disease.
Okay, again, notice this can be understood as a conflation of two senses of confirmation. The probability that you have the disease given just the single test result is still very low.
Right.
But does that mean that the test result is not relevant to whether you have the disease?
Of course it is.
Of course it is. That's why you get the test.
Again, relevance goes a different way than probability. You can have strong relevance and low probability or you can have high probability and no relevance.
Okay, so what does it tell us about the norms of our rationality, the normative principles of rationality?
Yeah, so that's a really good question.
I tend to think that, and there's actually a lot of research on this now, this is a really popular research which is taking phenomena that appear to be irrational.
Right, if you just apply some very naive probabilistic model to them, right?
Very simplistic, like you just say, oh, we're just talking about the conditional probability, but we're not taking account of relevance relations or anything like that.
What we did was we said, well, okay, that's one way to apply probability models to this, but if you apply it in a more sophisticated way, taking into account this distinction between two notions of confirmation,
then maybe the responses don't actually seem that crazy at all and you recognize there are these two different things pulling in opposite directions.
And people are going one way rather than another, but does that really mean that these people are acting or answering irrationally?
So that's a really interesting question, and now in the more recent literature, you've got people doing even more sophisticated things.
So Kevin Dorst, who is now at Oxford, but will be starting a professorship at the University of Pittsburgh, he's doing work on higher-order probabilities.
So all my work's just been on first-order probabilities, just probabilities of propositions, right?
But what if you're uncertain about how confident you are in something, or how confident you should be, right?
What if you're uncertain about that, and that's a second-order probability, right?
So Kevin's research is fascinating because he shows that if there's uncertainty about, if there's this second-order uncertainty about our own confidence and how confident we should be in some things,
I can actually explain a lot of things that looked irrational if you just had only first-order probability models to work with.
And that's another example of this kind of research, which I love, because it goes back to what I was saying, the beginning about probability modeling and the way I like to think about things,
there are lots of different kinds of probability models of lots of different kinds of phenomena, both in the natural world and in the psychological realm and in the normative or epistemological realm.
And it pays to be very careful about which models you're using, which families of models you're allowing to draw from before you make any conclusions, right?
So it might be that some of your conclusions you're drawing are just because you have too limited a set of probability models at your disposal,
that if you had a little bit more sophisticated use of those probability models or just maybe richer class of probability models,
that you could actually see these things in a different light and maybe you could model them better and maybe that would mean, for instance, that things we once thought were irrational maybe aren't always irrational.
Maybe it was just because we had to impoverish the set of models to really understand the true probabilistic phenomena in all the detail that we needed to understand them.
Okay, so we're still talking about standard probability theory. How about non-standard models of probability?
Yeah, so there's also some of that.
You know, this gets into an interesting, a more interesting, a general philosophical question.
So, for instance, let me just, so just to give an analogy to a related field and a related dialectic that has come up in the 20th century.
So I mentioned that in logic, there are these so-called paradoxes of relevance, right? So if you just look at the classical definition of what it means for an argument to be valid,
well, it just means that it's impossible for the premises to be true while the conclusions false, right? So if the premises are already impossible, then the arguments valid doesn't matter what the conclusion is.
Or if the conclusion is a logical truth, then the arguments valid doesn't matter what the premises are.
So you might think, oh, that's weird. Doesn't that show some kind of weakness in the definition of validity?
I don't actually think it does. And, but for me, it's because I think in order to give a proper analysis of relevance, you need probability models.
The probability models just aren't rich enough to capture relations of relevance.
And then once you have probability models on board, you can see that these cases are not problematic. Take the case where you have a tautological conclusion.
Okay, that has probability one given any premise, but are any premises relevant to it? No, because they are probably, they're like the Fred Fox case, but at the extreme.
They have probability one, no matter what. So when you have this richer notion of argument strength, you realize these aren't strong arguments.
Yeah, once you take relevance into account in the right way using probability realize, oh, these are just cases of valid arguments, but they're irrelevant. So they're harmless.
And so I think the attempt to revise classical deductive logic to make it relevant was just a mistake.
There's no wrong thing to do. Or to put another way. Yes, you can do that but the way to do it is to add probabilities to the truth tables.
Put probabilities on the propositions and talk about relevance and boom, there you have an explanation of relevance. Well, you don't need a new, you don't need a new logic.
I'll tell Grand Priest about this.
We've talked about.
Yeah, I love, I love Grand Priest. Yeah.
So what's the feature of research and philosophy or probability?
Oh, wait, wait, let me get back to the, but just one sec. Let me get back to the thing because that was just a metaphor.
Then what I was going to say was the same sorts of things might happen in classical probability. So you might have cases where certain classical probabilistic notions like confirmation, for instance, you get these weird cases that don't seem to make sense.
Now, some, I agree, something has to change there. You're going to need a new class of models. And that's right.
But the question is going to be what kind of revisions to those models are required.
And now it depends. It might be that there's still a way to explain those things using classical probability. It might, for instance, it might be that there's higher order probabilities you have to take into account.
Or maybe, or maybe it's just a richer class of probabilities that that are required to supervene on the phenomenon or something like that. So, yes, these are cases where something has to change.
So I agree with that. I would definitely agree that the classical definition of validity, there's something weird about the paradox of relevance. I just think the best way to explain that and to move beyond that is to move to probabilistic notions, rather than revising the deductive notions.
And I would say something similar. I would say, yeah, if you come up with cases where classical probability doesn't seem to work, then something's going to have to change. You're going to need some richer class of models.
But then I think I would tend to want to be as conservative as possible when I'm extending the old models to new ones.
Okay, that you know, and then you just have to look on a case by case basis as to how you're going to do that revision.
Yeah, and you know, it just depends on the case. But I would be inclined, I'm generally inclined to stick with classical logic.
And classical probably unless there's really I've tried everything. And there's just so for instance the liar paradox. Yeah, I mean, I don't see a way out of that that preserve. I mean, there are ways out of it that preserve classical logic.
But, but you've got to give up some pretty. So for instance, one way out of it is to say, yeah, you know, this idea that whenever you prove something, it's true.
Maybe not.
You know, I mean, okay, so something's got to give within the classical cluster of concepts. Okay.
I don't know what maybe maybe the logic in that case does have to go. I don't know. So, yeah, so there are cases in their cases. And that happens in probability to so I think you just have to take it on a case by case basis.
Okay, so what's the future of research and philosophy or problem.
There's so much interesting work being done in probability right now if there's a really a flourishing community of formal epistemologists who work specifically on probability. And like I said, the higher order probability stuff that worse than other people are doing is is fascinating.
I think there's sort of a ton of that we're just sort of scratching the surface of higher order probability.
There's the old perennial question of what's the relation between the traditional epistemic concepts and, you know, the more contemporary probabilistic ones like degree of belief and belief and you know what's the relation between those.
I think there's a lot of interesting work being done on that. Honest like I've just wrote a book a few years ago that's really interesting about about the relation between full belief and partial belief.
It's a fascinating kind of new way of thinking about that. So, and then there's, there's a lot of really interesting recent work on that I think will continue into the future on, if you will, sort of, reliable list or veritist epistemology and how to how does that bear on formal epistemology
What would a reliable list or veritist formal epistemology look like philosophy of probability or degree of belief. And so, there, there have been all this work on how to use the concept of accuracy to justify, or to ground probabilistic models of belief or degree of belief.
And that stuff is fascinating. So Richard Pettigrew has written a bunch of really great stuff on that and a lot of other researchers also are working on that stuff.
So, yeah, there's there's tons of there's tons of there's so many things that are going on in relating to probability. There's also just there's work on comparative probability or qualitative probability rather than quantitative probability.
And what how do you provide a foundation for those more qualitative notions, you know, just that the relation that one thing's more probable than the other.
What's the right way to give a foundation for that or to understand where those principles come from. So there, you know, there's, there's tons of stuff. There's tons of the good thing about probability is it hasn't been around that long right I mean it's like I said it's basically 100 years.
That's, I mean, in its real, you know, in its in the form of probability models as we now know them. And that just means there's tons of work to be done. I also would say a very important thing is that there's a lot of interdisciplinary
projects. So, machine learning, AI, statistics, all of these fields make heavy use of probability models of different sorts. Philosophers of probability need to get in there and be involved in those interdisciplinary projects, I would say, because we have a lot to
do, we have a very interesting perspective on probability and how it works. And I think we could be very helpful on a lot of interdisciplinary work across, you know, the boundaries of computer science or physics or other areas where probability is used.
So, I think people should be doing doing more of that kind of thing interdisciplinary work that relates because probability is one of these things that's in every field of inquiry if you think about it, it's everywhere.
And I think that's what Dr. Russell said, no one knows what it means but everyone uses it.
That means there's great opportunities for philosophers to contribute to interdisciplinary projects and that's something that I'm trying to do it and a lot of people I think there's a lot of opportunity for that for people to be doing that.
So I'm hoping more of that will happen.
And finally, your tips for academic philosophers or what's your advice for those who want to get into academic philosophy.
Yeah, wow. So, you know, I spend a lot of time talking to to junior people in the field and and really trying to be as supportive as I can and trying to help people who want to want to get into philosophy and or doing it.
And, you know, a lot of a lot of this now depends on, you know, socioeconomic and political things that are that are happening in the world.
There's not as much investment in philosophy as I would as I would like.
But I think I would say personally, it's incumbent upon philosophers to seek out people and to convince them to invest in philosophy.
I think philosophy is maybe more important now than it's ever been.
Because think of all the ethical questions, think of all the philosophical questions that are that are arising now in all areas, especially, you know, with the explosion of information technology.
There's there's just tons of places where philosophers can be useful and where philosophical philosophical questions are really important and need to be answered and taken seriously.
So I think we need to do a better job of convincing and communicating to people why philosophy is important and and why people should invest in philosophy and in philosophy departments.
Having said that, having said all that, my view on things is pretty simple.
I'm pretty simple minded. I think I got into philosophy knowing that it was a really improbable thing for me to be able to do.
I got really lucky and I ended up being very successful in the field.
Okay, that was really super fortunate and very lucky, but I will tell you this, it doesn't it didn't matter. I was never that was never, it was never on my radar.
You know, when I was coming out of Wisconsin, I was like, look, if I could just get a job teaching logic and that allows me to think about philosophy, that'd be a win.
So, and so I think, look, it's philosophy. It's the kind of thing that you really got to love it. I mean, you really got to be in it because you just love it and you can't see yourself doing anything else.
And for me, that was that was the case. I consciously decided to get into it knowing that I mean, I carried huge amounts of debt for decades.
Okay, I never worried about that. I never worried about any of that because I couldn't see myself doing anything else.
And I would say, if that's who you are, if that's what you're like, if you just can't help but do philosophy, you can't picture your life really without being a philosopher, then you should just you should just go for it.
You should do it. You should do it knowing that it's going to be challenging, practically speaking, it's going to be challenging.
It's going to be easy. It's going to be a difficult road, for sure, in practical terms.
But, you know, if you're like me, and you just can't imagine you're doing, doing anything else, then, then you should just go for it, you know, you should go for it.
And, you know, there are still a lot of opportunities for for careers in philosophy. A lot of them are in ethical in ethics or applied ethics and things like that.
All right, you know, I view that as more a strategic question about how to become a flop, how to make it a profession, right, so that you can actually do it.
And I so in my mind, that's a practical question, you know, and, and there's many different ways of doing that.
But like I said, I think if you really love philosophy, and you really can't picture yourself doing anything else, then you should absolutely go for it.
Now you should be aware it's going to be a long road. You don't get into it for the money. That would be a mistake.
That's, you know, if you know, it better not be for that reason, because that's not a good idea.
Not that that can never happen, but you know, it's a long shot.
And so yeah, I mean, I think, I think you've really got to be got to love it if you just say so what like when I was at NASA, and I was like, I can't do this.
I didn't just I can't live this way. I could just picture myself years hence just not being able to motivate myself to keep doing that.
And so I knew I had to become a philosopher because that was the only thing I could see myself doing.
And, and I did and that's why I did it. And I never look back because I just there was, I just didn't see any other thing that I could be happy doing.
But I but I do think it, at least for me, it helped that it was a calling in that way it was really, it wasn't just a job. It was like, I'm going to be doing this no matter what whether I like it or not so let me find a way to do it and survive.
Like what it was.
Yeah, so I would say, you know, try to if you're going to do it, try to seek out people like myself or other people who are interested in trying to help people do that and be successful.
So go to summer schools go to conferences, go to, you know, try to really network and get to know people in the field.
And I would say reach out to me if you're out there and you're listening to this and you want to get into philosophy, reach out to me, I will do whatever I can to help.
And there's a lot of helpers out there. You know, it's like, yeah, you got to find the helpers.
If you want to do this because you're going to need them, but they're out there. There are people who are helpful and there are communities that are supportive.
So like the formal epistemology means very supportive of each other that, especially the junior scholars, they support each other and they really help each other.
And I think having that kind of network really helps.
You know, you need that, you know, so seek out people who are like minded, go to conferences, go to summer schools, get as involved in the network of philosophy, the social network of philosophy as you can.
And I, and I think if you do that, you absolutely can do it. Of course, it can be done.
Yes, it's challenging and they're, and right now, especially with the pandemic, it's hard. But I, but, but look, philosophy is going to, if I have anything to say about it, philosophy is going to be around.
And people are going to be investing in it. And I know that I'm going to be working on that. And I'm going to be trying to support people who want to do it.
And I know a lot of people feel that way. And there's a lot of people working on that to try to make that happen.
So, yeah, I would say reach out to people, try to find people who can give you advice or encouragement, and try to find a community you can get into where you have peers that will also support you in philosophy.
And, and that can be done. That this is a thing you can do.
So yeah, I would just encourage people if they if they really love it, they should do it. They should go for it.
Okay, not not in a Pollyanna way where you think, you know, it's easy, but, but it's doable. It's doable. And you just have to find the right network, the right way to get into it, and to have your own community and your own set of peers that are doing it.
I think that's really important. So yeah, summer schools conferences, anything you could do to meet as many people interested in philosophy as possible and make as many connections in philosophy as you can.
Yeah, that's what I always did. And that works.
Okay, so would you say that your career in philosophy is worth it?
Oh, Jesus.
Yeah, I mean, yeah, but you know, in a way, like I said, that's sort of, I mean, you know, that's, yeah, but I'm like, I'm like one of the luckiest people in the in the in the field, maybe ever.
Yeah, for sure. I mean, I could not imagine myself doing anything else. And I'm just so fortunate I have an amazing set of colleagues at Northeastern I love my department.
And I just love my students and everything I'm doing I couldn't imagine doing anything else.
Yeah, it's the only it's the best of all possible lives for me for sure. But I did get super lucky, obviously, but, but I think I'd feel that way, no matter what, as long as I could teach philosophy and do philosophy and support myself, that's really all I ever wanted.
I kind of won the lottery. But even if I hadn't, I would be just as happy I think.
Okay, so thanks again, Professor Michael sense for sharing your time with us and your expertise for you guys join me again for another episode of philosophy and what matters where we discuss things that matter from philosophical point of view. Cheers.
