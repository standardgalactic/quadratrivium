I will be speaking about a series of recent papers we put forward, where we put forward
a connection between quantum error-corrected codes and conformal theories, and we'll be
speaking mostly about past work, the papers which are already on archive, but also we'll
mention an ongoing work where this whole topic is developing even further, and we are giving
some physical interpretation to the results. So here's my outline. I will first start by
discussing what codes are. I will assume that people in the audience might not, might not
heard of codes, but might not, might never work with codes extensively, so I will first try to
explain what codes are, and then what quantum codes are, and then I will try to explain how the
relation with CT works, and I will be sticking with the original formulation, which we put
forward last year. It's sort of more straightforward, it's very explicit, but it's a little bit at
the back, so it's not clear why I'm doing what I'm doing. There will be an upcoming paper, hopefully
next week, where we are trying to explain more physically why the construction, the way it is.
And then while speaking about codes and CTs, I will try to explain how codes are helpful in the
context of modular bootstraps, modular bootstrap. Then next important topic is how codes can be
used to understand some aspects of holographic correspondence, and this refers to ongoing work
where we try to relate codes to extended series. So what is a code? A good example of a code is
what is called a phonetic alphabet. When you are speaking over the phone and the connection is not
good, or you are speaking a foreign language, which happens with most of us, and people don't
understand you well, because you have strong accents like I have, or something like that, then
you resort to what is called a phonetic alphabet. Instead of saying words how they stand, you split
the word in their individual letters, and then you try to say each letter one by one, and instead
of saying a letter, instead of saying A, B, or C, you are saying what is called the code word.
Instead of letter A, you are saying alpha, instead of B, you say bravo, instead of C, you say
Charlie, and so on, so forth. You can use names instead of alpha, beta, instead of alpha, bravo,
and Charlie can use names, you can use states, whatever familiar words you can use. It is very
intuitive and clear that when you use this kind of phonetic alphabet, there are certain rules
which make this phonetic alphabet successful. So first of all, the words you use should be
familiar to the person who are listening to you. If you are saying words which the person doesn't
know, then he will not understand. Second thing, the words you are using should be very distinctive
from each other. If you say alpha and bravo, it is very clear that alpha and bravo are chosen such
that alpha doesn't sound like bravo, and bravo doesn't sound like Charlie. So I can say those words
with a strong accent, I can say those words over a faulty communication line which is not very good,
still people will be able to recognize them because those words sound very distinctively,
and once the person hears that word, since the person knows the words I'm saying,
the person would recognize, will reconstruct. So this is all very intuitive, but mathematically
this means that the person gets the message, the message is corrupted, but there is an error
correction procedure which allows the person to reconstruct the original message. So I'm appealing
here to intuition, but we also want to formalize it somehow mathematically. To formalize it
mathematically, I will resort to the formalism of binary codes. Binary code is a collection of
binary strings, there will be capital K binary strings, which means that there is capital K
letters, and for each letter I associate a message, and the message is a code word, it's not the
message I'm trying to convey, each letter will be associated a code word. A code word is a binary
string of length N, and then if I need to say something meaningful, I will construct my meaningful
message out of those letters and substitute each letter by the code word, and I will send person
with whom I want to communicate a sequence of code words. On the other side of the line,
the person would know code words and will be able to recognize them even though they're corrupted.
So to make sure that the person will be able to recognize them even though they're corrupted,
those code words should be as distinctive as possible. So let's try to formalize the notion of
distinctiveness of two binary strings, and this is done with what is called Hamming distance.
We have two binary strings of length M, and we simply say that the measure of how different
those strings are is the number of bits, the number of zeros and ones, which we need to flip,
we need to change zero into one, and we need to change one into zero. The number of bits we need
to flip to turn one binary string into another. Now if you have a collection of code words,
which we call a code, you want to characterize how code as a whole is good or how bad it is,
what is the quality of the code. The quality of the code, like people say that the strength of a
chain is in its weakest link. So the same applies to the codes. The strength of the code or the
weakness of the code is associated with the proximity of two closest code words. So you
exhaust all possible pairs of the code words, you calculate the distance between them,
you choose the minimal, which means that you choose two most similarly sounding code words,
and how similarly they sound, that determines how good your code is as a whole.
If you have binary strings, which consist of zeros and ones, with just a little bit of imagination,
you can say that those strings are coordinates of a point in an n-dimensional space,
and since each coordinate is either zero or one, it means that each binary string parameterizes
the vertex on a unit cube. That's what I have shown here. For example, I can have a binary
string zero zero zero, that will be an origin of a cube, and have a binary string one one one,
that will be this vertex of a cube. Then you can try to calculate the distance between those two
points, and the distance is very simple. It's equal to three because you need to flip every single bit,
but geometrically it means that there are three edges you need to walk through
to go from one point to another point. So this distance, which measures how different two code
words are, is also called ant distance. The distance and ant, a small animal, needs to walk
along the edges of a cube to go from one vertex to another. So to reiterate, a code is a collection
of vertices on a unit cube, and you try to keep those vertices as far away from each other as
possible, but at the same time you try to put as many vertices on a unit cube as possible
to make your alphabet rich, and to make your number of letters large enough, because the bigger
the number of letters, the more capacity your code has with respect to communicating useful
information. You can always put just one point, or you can use always put, let's say you always,
you only choose one point, then your alphabet consists of one letter. With one letter you cannot
send any information at all, because all the messages you have consist of one letter. There is
no meaning to it. The minimal meaningful alphabet would consist of two letters, that will be two
points, and you can put them farther away, rather farther away from each other, but with two points
you will have a code which only can encode two signals, zero and one if you wish, and you will
need to use them a lot, a lot, a lot to communicate, let's say, English language. If you have an
alphabet which includes 26 code words, then each letter of an English alphabet will be communicated
by its own code word. It will be much more efficient, but then you will have problem to stick in 26
points on vertices of a cube such that they stay far away from each other. So you see very clearly
that designing a good code seems to be an optimization problem, and it's rather easy to
formulate how it works. The optimization problem just requires a unit cube and choosing vertices
of a unit cube in a smart way such that they stay away from each other. So it sounds simple enough
such that you can explain that to a high school student, but the problem apparently is very
complicated, and we do not know the solution to this problem, which means that if you take
dimension large enough, let's say, of order 40, people simply would not know, or 50,
for the sake of an argument, around 50, around 40, certainly hundreds, several hundreds,
people simply wouldn't be able to tell you what's the best code is, and even worse,
people don't even know what's the capacity of the best code is. It's a little bit embarrassing
that people, these are not my words, I'm not criticizing the other community, but I'm just
trying to convey how people, the practitioners and theorists of classical codes, how they think
about it, they say it's embarrassing that this subject has been started for decades.
It seems like there are a lot of results, but people don't even know asymptotic bounds. If you
take n to infinity, if you take the number of dimensions to infinity, and you keep the capacity
k, the number of, the number which parameterizes the size of the alphabet, you keep the ratio
k over n fixed, which means that the capacity of your code will be kept fixed, and you try to
understand what will be the best possible hemming distance, the quality of the code,
people don't know what it is. There are bounds, but the exact answer is not known.
This is from some point of view, looks surprising, but I will explain in the talk that the problem
of understanding the best capacity of a code is in many ways similar and at certain level
just equivalent to the problem of finding the largest spectral gap of a two-dimensional CFT
where dimension of the code plays the role of the central charge. Basically, the question is,
you're trying to consider two-dimensional CFT with rather large central charge, let's say 10 or 20
or 100 or 1000, and you try to understand what's the best, what's the largest spectral gap is,
and as many of you know, we have some bounds and we have a conjecture what the asymptotic
best value could be, but we don't have a proof, and certainly we don't have a constructive
way to build such a CFT. My point in this talk today is that the problem with the code
is a very simple example of this modular bootstrap problem of trying to maximize spectral gap and
construct the CFT which will maximize the spectral gap. Okay, let me go rather quickly through a
mathematical basics of code theory. Once we have a code, and I will stick with the linear code,
and linear code means that those binary strings, there's a vectors, and I can add them to each
other and I will require that they form a vector space, but since I always want to sit in a unit
cube, I will define all of my algebraic operations, mod 2, and therefore if I add two binary strings
to each other and apply mod 2, it still will be a binary string, so two vectors on a unit cube,
there are some also will be a vector a point on the unit cube, so such a code is called linear code,
so if you have a linear code, you can characterize it, it forms a vector space,
and you can characterize it with what is called a spectrum. The spectrum is the following thing,
apparently if you have a linear code, you don't have to, and you want to characterize the distance
between pairs of points, mathematically you don't need to go through all possible pairs of points,
one of the points on the unit cube can always be chosen to be origin, that's because of linearity,
so if you want to characterize how good your code is, all you need to know is the distance
of the point on the unit cube closes to the origin, but not the origin itself, and when I say
point on the unit cube, I don't mean any point on the unit cube, of course meant only the highlighted
point which belongs to the code, so the spectrum of the code is the following mathematical information,
you have a bunch of highlighted points on the cube, and you want to know which distance from the
origin they are located, you want to know how far they are located from the origin, this information
of course will not parameterize the code uniquely, let me maybe sketch, let me maybe sketch, so you
have the origin, and you have a bunch of points, they're all vertices on the unit cube, I'm trying
to put a lot of them because I'm assuming that this is a multidimensional space, I'm not parameterizing
them uniquely, but I'm characterizing them by measuring the distance between them and the origin,
and this information, simply the distance between them and the origin, this is called the spectrum
of the code, as you see that will be a bunch of numbers, simply keeping track of the distance,
mathematicians advise us that the right way to package this information, the right way
to remember how far away from the origin those points are, is to put these numbers in the form
of a polynomial, this polynomial called enumerator polynomial, x and y are auxiliary variables,
they're not physical variables, and this polynomial, it's homogeneous, so there's only one variable
meaningful, and the coefficient in front of this variable to a particular power is literally the
number of code words located given distance away from the origin, okay, so if you have distance
zero from the origin, there is always one code word, and therefore the first coefficient of
this polynomial is always one, if there are no code words located distance away from the origin,
next coefficient of this polynomial will be zero, let's say there is five code words located distance
10 away from the origin, it means that this polynomial will have a term 5xn-10y to the 10,
this is a distance, this is the number of vectors located that distance away from the origin,
so this is just a mathematical way to package this information, okay, so this is all I wanted to
say about classical codes at this point, let me jump and try to explain what the quantum code is,
because at least superficially the quantum code looks to be completely different thing, the
quantum code seems to be a way to preserve quantum information when I have a state of a quantum system,
and then somehow because of the noise or imperfection or whatever, my quantum states become corrupted
and I want to restore information by applying certain recovery procedure, recovery mechanism.
To understand how quantum error correction works, let me consider a stupid example where I managed
to design an ideal quantum computer, this is a laptop, but this laptop stands for a quantum computer,
which I assume to be ideal, there are no errors, there are no problems at all, and the state of
a quantum computer will be psi L, L stands for logical, this is a state of my logical qubits,
which are at this point understood as the physical qubits of this quantum computer,
and then for the sake of the argument, I will also consider an imperfect quantum computer,
which I have shown here as a microwave, and the microwave heats things inside it, which means
that the qubits of this imperfect quantum computer will be subject to noise, they will be subject
to thermal fluctuations, it's not important that there's a thermal fluctuations, there could be
noise of any kind, I just wanted to show that this is not a quantum computer, this is like a
microwave, something stupid, something not good, but here the structure between this quantum computer
and this noise thin is a direct, excuse me, it's a tensor product, not a direct one, it's a tensor
product, and the state of a quantum computer and the microwave are unentangled, so it's according
to rules of quantum mechanics, I don't have to consider them together, I can consider a quantum
computer by itself, and I can consider a microwave by itself, and then there is no errors to correct
because my quantum computer is perfect by assumption, but for the sake of the argument,
I want to consider this system as a whole, I insist to consider them as a whole, I have a
state which is an unentangled state of a logical qubits and some auxiliary qubits,
and then I insist that this is a state of my full system, if this is a state of my full system,
then the ideal situation is when, at least initially, the states of the qubits inside the
microwave are all lined up, there are zeros, but once I start applying some things, whatever,
time passes, I apply some logical operations to this thing, this is completely faulty,
this is completely fine, but then because of the fluctuations, qubits of my microwave become
completely random, they are subject to noise. Now, after some time, because of the coherence,
I have this state, and in principle, all information stored here, and I can do measurements on a
quantum computer and just extract this information fault-free and completely fine, but I'm a purist
and I'm saying, you know what, I'm looking on the state and I see that the state doesn't have this
structure because the structure here was that I had zeros, and since I'm a purist, I recognize those
random states here as an error, and as a purist, I request that we fix the error before we proceed
to do any measurements on a quantum computer. So to fix those errors is very easy to do,
because to fix those errors, all I need to do is to put those qubits in the position up again,
and to put those qubits in the position up again, it's also very easy to do. I have,
well, according to this picture, I have n minus k auxiliary qubits, I measure every single one of
them using sigma z, this is the syndrome measurement, this is a syndrome measurement operation,
and if it shows that one of the qubits is down instead of up, I flip it with the corresponding
sigma x and put it in the up position, and sigma x is my recovery operation. So after applying
syndrome measurement and recovery, I can make all those qubits again look like this. This is
completely trivial and even stupid thing to do because they're completely unentangled,
but as a purist, I can insist on this recovery procedure. Well, you can think of it as an error
correction procedure. I started with a state which is not in this form, so the states of this form,
they form the code subspace. The states of this form with arbitrary
psychological code, they form the code subspace. Obviously, a linear superposition of any two
states of this form, again, will be states of this form because this could be anything,
and this is just zero. If I recognize that my state is not having this form, it means that
error has occurred. I can do syndrome measurement, and I can do recovery, and then I can bring it
back to my original code subspace. So this is a recovery procedure. Now, this is, of course,
stupid because I did not entangle my microwave with a quantum computer. What if I have a real
quantum computer, which is a big device, and there is some logical part which I want to protect,
but it's a logical one inside the Hilbert space, so I don't know where it is.
Physically, it's not separated in any way. Mathematically, it means that whatever
syndrome measurements procedures or syndrome measurements operators I had, mathematically,
they still will look like Pauli matrices in some basis, but this basis is not the conventional
basis of physical qubits of my real quantum computer. When I have a real quantum computer,
I have physical qubits, the basis of those qubits called computational bases, and my syndrome
measurement operator Sigma Z will look conventional in a completely different basis, not on the
computational basis. So there is some unitary transformation, a very complicated one, which
involves the whole Hilbert space, it acts on the whole Hilbert space, which brings my syndrome
measurement to a very simple form in a particular basis, but in the computational basis,
the syndrome measurement looks complicated. Nevertheless, since those generators, since
those operators G, as Pauli matrices in disguise, they satisfy sort of very simple
identities. Square of those generators is one, I want to call them generators for purpose.
The square of them is one, and they commute obviously. Since they commute, they form the
abelian group, and that's why I'm calling them the generators, because they are the generators of
an abelian group, and this abelian group is called the stabilizer group, because it stabilizes the
code subspace exactly the same way, exactly the same way how states of this kind form the code
subspace, and I can define code subspace by requiring that code subspace states are invariant
under my syndrome measurement operators. The same is here. I will say that I have an abelian group,
and this abelian group will stabilize the code subspace. It will not move it. It will move other
parts of Hilbert space, but the code subspace is invariant under my abelian group. So this abelian
group is called a stabilizer group, and the code is called a stabilizer code. This is a completely
general procedure how stabilizer codes are defined, but then quantum computation theories come,
and they say, you know what? You should hold your horses. You have the general mathematical
structure of the stabilizer group, but if you want this to be useful for real quantum computing,
you need to remember that in practice, there is no way to implement very difficult measurements
which affect many qubits in a complicated way. Therefore, if you really hope for those syndrome
measurement operators G to be measured in practice, you should make them as simple as possible in the
computational basis. We know they're very, very simple in a very special basis, which is not
computational basis, but we should also make them as simple as possible in the computational
basis, and the idea is that we should make those stabilizers to look as follows in the
computational basis. In the computational basis, they should look like a product of
Pauli matrices, because if you have an operator which is a product of Pauli matrices, it means
that you can measure it individually on every single qubit. So essentially, it will be a single
qubit measurement performed many times instead of true, non-trivial, multi-qubit measurement.
So with this requirement, it's a requirement which is just put forward by quantum computing
people 20 years ago. They recognized that stabilizers must be sufficient or simple in the
computational basis. They cannot be too simple because then they will not be able to create
a good code, but they should be sufficiently simple. They demand that stabilizers will be
products of Pauli matrices, and a product of Pauli matrices can be characterized by a string
of zeros and ones. All Pauli matrices is either sigma x or sigma z or a product of sigma x and
sigma z, and therefore, every possible stabilizer is parameterized by two binary vectors, alpha
and beta. So basically, this is the link which relates quantum codes, which look completely
different from the classical one, to classical codes because apparently, a stabilizer can be
parameterized by two binary strings, alpha and beta, and you can combine two binary strings,
alpha and beta into one long binary strings, which will have length to n, where n is the
number of qubits, n is the number of qubits. Apparently, this code will be a linear code
because if you have one generator, which is parameterized by string one, and you multiply it
by another generator, which is parameterized by string two, then you will have a generator
parameterized by the strings c1 plus c2, where this is understood mod two. And here, this is
equivalence in the physical sense, and physical sense means that an overall phase of the wave
function doesn't matter, so this is really not equivalent but proportional, but these are all
details from the physical point of view. They are equal, and I just don't have time to explain the
details, and the function here is the following. Quantum code, in fact, can be understood as some
very special linear classical code with some additional structure. Okay, once we made the
connection between classical and quantum codes, next step is the Narayan CFTs. I assume that the
audience is very familiar with the Narayan CFTs, so I will go quickly. Narayan CFTs are perhaps
the simplest two-dimensional CFTs. We consider it's a sigma model, but it's a sigma model living
not on some complicated Taylor manifold, just living on the torus, and you have a metric on
the torus, essentially the size of the torus, and you have the billfield, and the verdicts operators
are just exponents of refills, but since your field lives on the torus, there are certain
quantization conditions. You will have a left and right movers individually, and left and right
movers together, they form a vector which monks belong to a lattice. That's exactly the same as
if you have a particle, let's say you have a physical particle moving on a circle, since you
have a periodic boundary condition, so it's actually all is on the slide, since you have
periodic boundary conditions, your wave function has to be an exponent of i k x, where x is a
periodic variable, therefore k has to quantize. It's the same as here, phi lives on a torus,
therefore k have to quantize, k will live in a lattice, and we all know that this lattice will
have certain special properties, it will be even and so dual, so such such lattices we call Narayan
lattices in corresponding CFTs are called Narayan CFTs. Okay, now I mentioned the word lattice,
but I need to explain what the lattice is. Of course, I assume that you know, but I will
just refresh your memory to make sure that we are on the same page. The lattice is just the
collection of vectors, and you take a bunch of vectors which form the basis in n-dimensional space,
and then you will consider linear combinations, and if you allow yourself to consider linear
combinations with arbitrary coefficients k, you of course will spend the whole physical,
you will spend the whole, not physical, you will spend the whole geometrical space you're
dealing with, but you only allow yourself to consider integer-valued combinations of those
vectors, and since you only have integer-valued combinations, you have something like a crystalline
lattice, you have two vectors in this picture, and then you have a grid, so essentially the
lattice is a grid, and lattices, they're ubiquitous in mathematics, and people have many
interesting things associated with lattice, and one of them is called the theta series.
Theta series is when you say, okay, I have lattice, I call it lambda, I take vectors x,
which are points on the lattice, these are vertices, and I want to calculate this funny
sum, it's a sum of exponent i tau, where tau is a completely auxiliary variable, and then x squared,
it's a length squared of this point to the origin. So what is theta series? Theta series, well,
if you're a little bit familiar with Narayan theories and you read Polchinsky textbook,
you will immediately will know that theta series likely have some nice modular properties, it becomes
the modular form, so there is a lot of beautiful mathematics, but just from the definition, you
immediately see that the theta series is nothing but a mathematical vehicle to store the following
information about the lattice. If you consider the origin and certain distance away from the origin,
how many vectors, how many lattice vectors allocated given distance away from the origin?
So theta series only knows about the spectrum of the lattice, and spectrum of the lattice is simply
the information how far away from the origin lattice vectors are. If you consider a special lattice,
which is called integral, which means that the distance from the origin from each point will
be an integer number, and that means that for each integer number, you simply keep information how
many lattice points are located that distance away from the origin. From the definition, you see that
this is very, very similar to what I call the spectrum of the code, but now instead of spectrum
of the code, I'm talking about the spectrum of the lattice, and mathematicians tell us
that this dry and seemingly uninteresting information, how many points located given
distance away from the origin, this dry, dull, uninteresting information should be packaged
in the form of a function of an auxiliary variable, and then this function becomes
mathematical beautiful because usually it becomes the modular form.
Okay, what is the relation between codes and lattices?
If you have a code, you can form a lattice. Otherwise, it's not always possible. If you
have a lattice, you may not have a code, but if you have a code, you can form a lattice. There are
many ways to do it. I will explain the simplest what is called construction A. Let's consider
first a cubic lattice, a very simple cubic lattice, like I agreed I have shown here.
Let's consider a unit cube. We know that a code is a bunch of points on a unit cube.
I have shown two codes. I have shown two points on the unit cube. This is the code we already
dealt with. That was three-dimensional, but here I have two-dimensional example.
So this is my code. It's two points on the unit cube, and then the idea to make the lattice out
of code is the following. You take the unit cube and you move it in all possible directions with
a step two. So you move it with a step two and you have these two points. You move it to the
step two and you have these two points. You move it with a step two and you have these two points.
And then you move it in all directions to the right and to the left, up and down. So you move
it here, then you move it here. Therefore, you will have these two points. You will have these two
points. And then you see that each point has many, many, many avatars. And this point has many,
many, many avatars. But if you put all of them on the plane or n-dimensional space,
you will have a crystalline structure, which is a lattice. And actually, you can prove that this
is a lattice. And this is a lattice associated with the code. And if you try to calculate the
spectrum of the slates, simple enough, it will be completely parameterized, contained by the
spectrum of the code. And more concretely, the theta function, the theta series of a lattice,
will be simply a numerator polynomial of the code, where instead of the arguments, you stick
in to Jacobi theta series. Why you have Jacobi theta series? Because Jacobi theta series is
roughly a theta series for the simplest lattice you can imagine. It's a one-dimensional lattice
with a step one or something like that. So the theta series of that is a Jacobi function.
And here, you clearly saw that each point, each code word, each code word has infinitely many
avatars, which form a cubic lattice. And therefore, for each code word, it makes sense that for each
code word, you will have some combination of Jacobi theta series. Okay, so this relation
is mathematically simple, but it's crucial for us, because now we go back to the Narayan theories
and we say, you know what, Narayan theories, they're basically lattice based. And the torus
partition function of Narayan theory, I'm sorry, I have a typo and I forget fixing this typo.
You say that the torus partition function of a Narayan theory is simply theta series
of a Narayan lattice. Okay, that's something very well understood. So we need to calculate
the theta series of a Narayan lattice. And now comes our non-trivial result. Combining everything
together, this is contained in this paper, I'll just announce the result. Combining everything
together, you can start with the quantum code. You can understand the quantum code as a classical
binary code with some additional structure. You can use construction A I announced before,
just on a previous slide, to construct a lattice associated with this quantum code.
This additional structure will ensure that the result in lattice is in the Narayan lattice,
which means that it is even, so do a lattice with a Lorentz and metric. And then with help of
that Narayan lattice, you can define a Narayan CFT. And therefore you achieve the following,
you start with a quantum code of a particular kind, you define the lattice, then you define a CFT.
And therefore you can associate to a quantum code, a particular Narayan CFT. Then you can
go ahead and calculate the partition function of that Narayan CFT. And surely enough, it will be
completely expressible in a concise way through enumerator polynomial of your quantum code.
And then arguments of this enumerator polynomial, there will be, there are four variables because
quantum code has more ingredients with respect to classical one. And those parameters A, B, C,
and D are particular combinations of Jacobi theta functions, which are written on the paper.
And I didn't want to write them here because I wanted to save space. So basically what we achieved,
we started with particular quantum codes and we associated to them special subfamil of Narayan
theories, which we call code CFTs. So this is the picture. We have a space of all two-dimensional
CFTs, a space we don't fully understand. It's a hypothetical space. We don't really have any
mathematical way to describe it. Then we have a completely well-defined mathematical space of
Narayan CFTs. It's a continuous space. And then we have a large but finite subfamily,
which is probably occupying only particular corner of this Narayan CFTs. And this subfamily,
I'm not saying, it's certainly not ever dense. I'm just, for pictorial reasons, I'm putting it
in a corner to emphasize that it is not dense, but it's a large family. It's exponential large
if the central charge, number of qubits, number of qubits, it's a central charge.
So this large family of code CFTs, you can associate to them quantum codes. So that's our
construction. You immediately have a lot of questions, how general this construction is.
Can I take more general theory here and associate to them different quantum codes and so on and so
forth? And I partially have answers, but at this point, I just covered only some subfamily.
An interesting thing is the following. Can I ask you questions? Of course.
Yeah, the question might be also to what you want to explain. So the Narayan CFT has a modular space.
That modular parameter have any meaning in this quantum code problem or it doesn't mean anything?
Right. So the Narayan modular space is a continuous space. So you can move in this space freely.
Code CFTs is a discrete space, which means that you cannot start with the code theory and change
the parameter infinitesimally. You have to jump from one point to another.
Why is that? You, of course, my hope, I will try to talk a little bit about generalizations when
we can have more points, but so far you are talking about real codes which deal with qubits.
It's a discreet algebraic structure. So there is no viable way to deform it continuously,
because if you deform it continuously, it's a little bit like this. Imagine you have,
it's an analogy. It's not what is happening. Imagine you have two dimensional torus. A very
well, a very famous mathematical question is the following. If you put a line here,
geodesic line, how would it look like? If you chose rational number of windings,
then it will be just a periodic line. But if you choose irrational number of windings,
and it will immediately cover everything like this. So the same happens with Narayan theories.
If you chose rational CFTs, if you wish, it's more like periodic windings. And then you might have
something like an algebraic structure of a code associated with this rational CFT.
But as soon as you move away from the rational point, you have something like this,
when the code must be infinite dimensional or something like that. So I hope that there is
a physically meaningful generalization of codes which will be associated to any theory here,
and then we can move continuously. But you should be ready that in a general point,
a code will be infinitely dimensional, complicated beast. And only for rational
CFTs, it will be something simple. All right. Okay, understood. Thank you.
Okay. What if you don't care about codes at all? I don't care about codes. Explain to me
everything you did without codes. There is a way to do it. All I did is the following. I proposed
a smart whatever, I don't know, smart, interesting algebraic ansatz to express partition function
of a Narayan CFT or two dimensional CFT through a polynomial. This is an algebraic ansatz.
I say that I have a polynomial w, which satisfies two algebraic identities. They are rather
complicated, but they're algebraic identities. And in fact, you can solve those algebraic
identities at the level of polynomials once and for all. You can simply write down explicitly
generator polynomials which satisfy these identities. You can prove a theorem that
any polynomial which satisfies this two identities is a combination of those basic
elementary polynomials. I'm sorry. There is some sound. I do not know how much it bothers you.
Okay. So you have the algebraic ansatz. You have the algebraic ansatz.
Could you give me a feedback if you can hear me well or it's very disturbing?
It's fine. It's fine. Okay. You can continue. Yeah. Okay. Thank you. So you have the algebraic ansatz
and basically any polynomial which satisfies this two identities, if you stick in the arguments
of these two polynomials, Jacobi theta functions, you will have an object which will have all
correct modular properties of a two-dimensional CFT partition function. And therefore, you can
simply say, I forget about codes. This is my algebraic ansatz and I will use it to solve
modular bootstrap. So this is one viable approach. So I want to skip a little bit because I'm running
out of time. I want to give you some concrete results we have. So one concrete result is that,
well, we defined this family of Narayan theories associated with codes. We'll call it a code CFT.
Then you can actually try to investigate this space of code CFTs. And we found many examples of
Isospectral CFTs, which means that you have two distinct conformal field theories, but they have
exactly the same spectrum, which means that they have exactly the same two-dimensional torus
partition function. If you consider high-genius partition function, it will not be the same.
If you consider flavored partition function, where you introduce chemical potentials for charges,
it will not be the same. But if you consider simply torus partition function, so the information
you keep track of is dimension and spin of the operators, you will have two different theories
with exactly the same partition function, which means that if you try to bootstrap those theories,
you will never be able to distinguish one from another. And to the extent I know,
in the context of non-carrel CFTs, this is the first non-travel example we have. People didn't
think of examples such that before. That's one thing. Second thing, you can have an algebraic
answer as I presented before. You can find a solution. You can find a polynomial. You can write
down a partition function, but it will be fake because there will be no code associated to it.
You can have a particular polynomial w, which satisfies both identities, but there is no code
associated to it. It's possible. And then it will have a partition function, which we'll call a fake
partition function. We call it fake partition function because you have z, but there is no
obvious CFT with which you can associate this partition function. So it's a fake partition
function. And then also there are very special theories for small central charge, which maximize
spectral gap. So we don't have, of course, nobody has an explicit construction how to
maximize spectral gap for any given value of central charge. But for certain small values
of central charge, people know such CFTs and we recognize that those CFTs are really our
code CFTs associated with quantum codes. So these are our results. Now, what are the generalizations
and extensions? We are very close to proving that those fake partition functions are really not
associated with any CFT at all. And once we prove that, that would be also interesting in the context
of modular bootstrap because you can try to bootstrap those functions z. Again, they satisfy
all the identities. They're positive, expressible in terms of the characters with integer positive
coefficients. They have the correct modular transformations. Everything is completely fine,
but there is no CFT associated to them. And you can discover such z using modular bootstrap
and never know that there is no CFT associated to them. Then you can go to Hyogenius and extend
the extension to codes to Hyogenius that was done very, very recently, past week,
by a bunch of young fellows. Ashish is my student and I'm very happy that they just
took on themselves this question of understanding how this relation works for Hyogenius. And with
Hyogenius, of course, you know that you can probe OP coefficients. So presumably, if one
can start thinking seriously about Hyogenius, you can have much more stringent constraints
similar to even exceeding the modular bootstrap because Hyogenius knows about OP coefficients.
And then we also, some time ago, we also had an extension of our procedure to include
to include different Narayan theories to this consideration and relate them to different types
of quantum codes. And then you can also associate new algebraic ansatz with this construction. And
now we are trying to generalize this algebraic ansatz to make it even more generic. And the
question here, or even a program here, is to relate to bootstrap. I want to reformulate the
bootstrap, modular bootstrap, not the whole thing, but I want to reformulate modular bootstrap in
terms of this algebraic constraints. And I say full modular bootstrap is difficult to solve,
but can I at least try to write down all possible, I want to discuss the space of all possible
ansatzes and choose the best ansatz such that I can write down a conformal theory with the largest
possible central charge. There have been works started in 2019. There have been works by Leonardo
Resteli, Tom Hartman, Deli Milmazak, and then other people from Tom Hartman's group, where they
related conformal bootstrap to sphere packing. So what we do here is somewhat similar in spirit
and maybe even at technical level, it's becoming similar. We are trying to reformulate modular
bootstrap in terms of a simpler problem. What those guys did, they related modular bootstrap to
sphere packing. And in the language of sphere packing, there is this linear constraints of cone
and elkis. And Resteli and company have shown that modular bootstrap becomes in that in that
corner and that limit becomes equal to cone-elkis linear programming bounds. What we show here
is very similar in spirit. We show that modular bootstrap in that particular corner becomes
equivalent to linear programming bounds on classical or whatever codes. And linear programming bounds
on classical codes, they precede cone-elkis and cone-elkis is essentially a generalization
to spherical story, this linear programming bounds on codes. So in some sense, this is just a whole
viable program to reformulate modular bootstrap in some simpler algebraic terms. We will not be
able to discuss a generic theory this way, but there is a good chance that we'll be able to discuss
theories with a large spectral gap. Okay. I do not know how clearly I explained this. Obviously,
I'm a little bit in a rush because I'm trying to go to some more recently interesting stuff,
but please ask me if something caught your attention. And then there is this generalization
which we are working on right now with Matthew Buchan and Rajat Rathaprishna. And this is a paper
which should appear soon. And this paper, in my view, answers a very important question.
The question is the following. Okay. I presented a construction. I connected quantum codes with
the CVTs. I have proved to that. I have Narayan lattices. Everything works. I have calculated
something. I found some interesting applications, maybe for bootstrap, something else, very, very
good. Then the question is, where did I get this from? Everything was at Hock. The fact that I
was able to prove something doesn't explain the meaning of this and doesn't explain the origin of
this. If I claim that the relation to codes is more than some mathematical curiosity,
what is the emerging picture? I never talked about meaning of the codes. If I have qubits,
if I have code subspace, what's the physical meaning of that in the CVT language? And of
course, if your quantum gravity inclined as everyone in this workshop is, you want to know
what's the meaning for holography. These are very important questions. I wanted to understand them
from the day one. And I think we are coming close on this upcoming paper. So I'll try to tell you
the story schematically the way I understand it. So first of all, you can extend this construction
to pretty much any rationale in the Ryan CVT. We know since the summer that sometimes you can
even extend it to non-binary codes. Yeah. So what is important about this work is that here you have
non-rational CVT. It's a finite CVT in a sense that it has a finite number of characters,
but it's a non-rational theory. So it's a family of non-rational theories. So this example is
interesting because they're non-rational, but still finite in some sense, which means that this
understanding we have now might not be final, but at least you can extend this construction to
pretty much all rational theories. There are some constraints here, but I think those constraints
can be relaxed if you allow yourself considering non-binary codes, which means that instead of
qubits, you will have qubits with different dimension of the Hilbert space of the elementary
qubit. So first of all, you can expand this to any rational CVT. Second, we understand physically
what code is. The stabilizers of the code are associated with the conformal characters,
and you have representation of some extended group, and you have characters of that group,
and characters go in one-to-one correspondence with the stabilizers.
And of course, I'm doing things schematically. I'm not writing any formulas because I feel like
if I start writing formulas, I will basically don't have time to do anything. And I decided in
this talk to go through the simple procedure explicitly and just announce the answer in
my general case. And then an interesting question, of course, what's the physical meaning of a code?
What's the qubit? What's the code subspace? So the story goes like that. Our quantum codes are
of special stabilizer type, which means there is one dimensional code subspace. You have n qubits.
Excuse me. You have n qubits. You have n qubits. The dimension of the full Hilbert space is two
to the n, but the code subspace is just one-dimensional. And this one-dimensional code
subspace should be associated with the Hilbert space of a CFT. The full Hilbert space of a CFT
in this construction compresses into one-dimensional code subspace. You'll say, okay, that's not very
interesting. Well, this is not maybe the most interesting thing. Maybe this is a cartoonish
thing, but then it's not a trivial thing because you still have two to the n-dimensional Hilbert
space subspace around it. And you can ask what that is. And this is the Hilbert space of the
boundary defects. If you just have a CFT itself without boundary defects, the Hilbert space of
that is a code subspace. But if you include boundary defects, the Hilbert space with the
boundary defects is a Hilbert space of the qubits. And then you can even have
a holographic picture. It's not the conventional holography where you have quantum gravity in
the bulk. This is a picture more in the spirit of two-dimensional CFT,
Chern-Sammons correspondence, where you have two boundaries and you have Chern-Sammons theory
living in the bulk. And you have a chiral part living on this boundary and anti-chiral living
on this boundary. You have Wilson lines stretching in between. And then if you don't have boundary
defects and all of those Wilson lines, they will act trivially on your states. And those
Wilson lines will be stabilizers. They will act trivially on your states because all of your
states belong to code subspace. But once you start having boundary defects, you will have
non-trivial action. And you can explicitly see that this action is the action of Pauli matrices
in this Hilbert space of qubits. I hope I intrigued you enough with this. This is
maybe all I wanted to say about this part. I have three minutes. I just wanted to mention
very, very quickly another useful application of codes in the context of holography.
A year ago, there was this series of interesting papers by Tom Harman and collaborators and also
by Malone and Witten when they considered Narayan theories. They averaged over modular space and
they said this is equal to quantum gravity in the bulk where it actually was more like
Chen-Samen's theory. But these works, they belong to this idea that holographic correspondence
may not equate quantum gravity to a particular safety on the boundary, but rather equates
quantum gravity in the bulk to an ensemble of safeties on the boundary. This is an interesting
thing because if you have an ensemble of theories dual to quantum gravity
and you hope that your quantum gravity admits quasi-classical regime, then you immediately
have the following question. Wait a second. If I have, let's say this is your holographic
correspondence. This is your bulk. You have quasi-classical theory here. It doesn't matter
what the theory is. If it's quasi-classical, then the measurement and the classical theory is
unambiguous. There is no uncertainty associated with the measurement. If you have classical theory,
you have no uncertainty. If I have an ensemble here, I will have an uncertainty associated
with an ensemble. Isn't this attention? How do I resolve this? This tension, by the way,
is very similar to the tension associated with lack of factorization. Now, to have this kind
of correspondence work, to have a classical theory dual to an ensemble, the only way out
is to declare that the ensemble is very, very special and allows what is called self-averaging,
which means that if you choose randomly a representative from this ensemble, it will
be typical enough and it will describe the whole ensemble. In mathematical terms,
self-averaging means that the variance of physically meaningful quantities will be
vanishingly small. You can formalize that in the context of Narayan theories. We did that
in a paper a year ago and you can conjecture different things starting from this picture
of self-averaging, including the bound on the spectral gap of Narayan theories. This is the
analog of the famous C over 12 bound for conventional Virasaurus CFTs. For Narayan
theories, you have slightly different bound. It's a conjecture, but for all of these conjectures to
hold, and this is a conjecture we formulated in our paper, again, based on self-averaging,
for all of this to work, variance have to be vanishingly small. And instead of starting
variance of all Narayan theories, you can consider variance of code CFTs. And we calculated an
ensemble of code CFTs and you can start ensemble of code CFTs and you can see that variance is
exponentially small. So in other words, my time is up. So in other words, I'm concluding,
you can use ensemble of code theories to probe different ensemble properties of CFTs.
This is especially important because we don't understand ensemble of all two-dimensional CFTs,
therefore we have nothing to work with, and we need a concrete, simple playground where we can
study ensemble properties. And code theories provide such an example. And the calculations we did
and the calculations, similar calculations, which may appear soon in an upcoming paper
with Mihab Durkouz, the point is code theories, they capture essential properties of this ensemble
when ensemble self-averages and can be associated to something classical in the book.
Okay, my conclusions. So the main thing is that we made a connection between quantum codes
and CFTs. And I think this is physically meaningful. At the technical level, that provides new tools
to solve modular bootstrap constraints, this algebraic answers to solve modular bootstrap
constraints. You can try to find optimal theories, by definition, these are those which multiply
spectral gap. You can find isospectral theories with the same spectrum, you can find fake partition
functions associated with anything. So you can just play with this algebraic construction and
leverage it. You also can study ensemble properties. And I tried to rush very quickly through this,
but I was trying to argue that those ensemble properties, they actually capture essential
properties which you hope the ensemble of all CFTs will exhibit. And we now have in the upcoming
paper a physical picture, the physical meaning of codes. The physical meaning of codes is that you
can actually see them emerging and CFTs if you add boundary defects. And then you have a code
subspace associated with the Hilbert space of the original CFT and the full Hilbert space of
qubits associated with the Hilbert space of boundary defects. And then I think one next step
which we are working on right now is to learn the lessons for the holographic correspondence.
We all know that there are holographic codes of Harlow and France and those holographic codes,
they are essential mechanism which is necessary to have locality in the bulk. And we hope that the
codes we uncovered here is a simple cartoon of that picture where you can start with the
holographic correspondence and the whole low energy Hilbert space of the bulk theory
will be mapped to the code subspace which I talk about in this talk. This is work in progress,
but I hope to return back to you with some results next year. Thank you very much for your attention.
Thank you very much for the excellent talk. Any question?
So I have one question. So if you just average over your code CFT, do you get the same bulk gravity,
you want gravity in 8S3? No, you do not. So this code theories, they are not ever dense,
they are not covering the whole space. It would be some strange mathematical miracle which has no
reason to happen and it doesn't happen in a sense that averaging over this whole thing is not the
same as averaging over this. You can ask if averaging over this would give you something
which can have a bulk interpretation. I am not sure about that. We are working on this
in our original paper a year ago. We argued that there is a chance that averaging over this would
have a holographic interpretation. We are still working on this. But even if it would, it will
not be your vanilla you want gravity. It will be something much more complicated because remember
these are only rational CFTs and we are only averaging over rational CFTs. So what you will
have in the bulk will have some additional structure for sure. But this is not the point
that I am suggesting that averaging over this will help you study you want gravity. You don't care
about you want gravity per se. You just want to understand how ensemble versus gravity
correspondence works. And to understand this correspondence you are happy to start with any
ensembles. So far you can understand that ensemble and you can understand what has happened on the
gravity side. So that was the point I was trying to advocate. Okay, thank you very much.
Any other question?
So what is the logic to tell whether a patient function from the modular bootstrap master
is a fake patient function from the call theory? That is something you don't know. I give you z.
It satisfies all the properties z should satisfy. You can expand it in characters
with integer positive coefficients. This z is modular and variant and you never know
if it is associated with the CFT or not. It's a big question. In the context of codes this
question has its own name and it's a difficult question even to understand the level of codes.
People give you a polynomial. Literally this is the question mathematicians don't know answer to.
People give you a polynomial of degree 72. It's a particular polynomial and they don't know if that
polynomial is associated with any code or not. And you can say dimension 72 I can probably do
something with a computer or something but 2 to 72 is such a large number that you simply cannot go
through all possible binary codes. Binary codes is a finite number. It's zeros and ones. You can
try to do that on a computer but with 2 to 71 being such a huge number there is no way to go
through all the codes and people simply don't know if there is a code associated with a particular
polynomial. Even worse CFT case what I was trying to advocate in the stock is that all of those
polynomials is a simplification. That's what is easier than the CFT. The CFT case is even more
complicated. I give you z. It seems to satisfy all properties but you never know if it is related
to a true CFT or not. And to rule out to show that given z is not a partition function of a CFT
we are working very hard picking on particular properties of that particular z. So there is
nothing universal about what we do. We just took a particular z and we try to
disassemble it to smallest pieces and say oh this piece means that there is this operator but then
if there is this operator this and that and it's a mess and there is no generalization to this
procedure. All right okay thank you. Any more question?
So can you extend your work something beyond the Narain CFT such as some random rational CFT?
Not yet of course of course we very much want. Right now we are sort of finishing
understanding the rational Narain CFT case. So it looks like we can include pretty much
all Narain rational CFTs. Well when I say all we're only dealing with the binary codes but there
is rather straightforward generalization to include non-binary codes. So perhaps for the
sake of an argument we are basically understanding all rational Narain CFTs. And the next step of
course would be to try to understand other rational CFTs which are not Narain and you hope
that would be possible and I hope this is possible but I have no concrete result to report in that
regard. I think this is like a very very obvious very very interesting open question out there.
All right thank you.
I have one question. So you mentioned about some dimensionality of the code subspace
and the boundary defects. So could you elaborate on it a bit?
Right so all the codes we consider in this story what is called self-dual codes. So it means that
you have so many stabilizers that there is only unique state environment under all of those
stabilizers which means that the code subspace is just one-dimensional. From the quantum computing
point of view these are not error correcting codes because one-dimensional code subspace
means that it has no capacity to store any information. A state of your logical quantum
computer is always the same so there is no way for logical quantum computer to store any information.
But those codes are still considered in the context of quantum computing because they're called
quantum error detection codes. You put your quantum computer in a logical state and then
you do some logical operations which should return that state into itself but because of error
it moves the state outside and then you can detect that there was an error. So this is a meaningful
thing. From our construction point of view this one-dimensional code subspace becomes
the full Hilbert space of the original CFT. All states in the original CFT have operator
states correspondence so all verdicts operators of the original CFT they simply get mapped into
this code subspace at the level of states. But then you can ask what is the Hilbert space of
qubits? The Hilbert space of qubits these are boundary defects and boundary defects these are
operators which are not of this kind these are not verdicts operators of your original CFT.
And then you can try to study in the in the in the theories we consider what the boundary defects
are and see that there is exactly two to the n of them such that you literally can populate the
full Hilbert space of qubits. Is this yeah yeah that's what I wanted to ask. Any more question?
I apologize for the sound the wrong that's why okay if not this time to speak again thank you
thank you very much
