Okay. Thank you so much, Raph. That was very nice. Very nice. All right. So I guess I
should start sharing before I.
You've already started sharing with us, Chris.
All right. Let's see here. Back to business. This is not...
One of my favorite quotes is from Yo-Yo Ma, who said, sharing is better than proving.
It's really deep, you know, quote, you have to think about for a while what it means.
Oh, I like it. I feel like I've just learned that for myself again recently. Okay. This
share screen is not doing what I asked it to. Okay. Let's try again. I'm going to close
this. Not that talk. This talk. Okay. Where do Hilbert spaces come from? Everybody sees
that.
Looks good.
All right. So, yeah, today, I think a half hour of this talk is just going to be me talking
about history, because I want to show you guys something that happened that I think
is very interesting. So many of you maybe are aware that Vile was a student of Hilbert.
And well, because Vile intersected with Schrodinger, that influenced the theory that we use today
greatly. But Vile are also intersected with other mathematicians. He had the knack to
work in many different fields. And in particular, he intersected with this guy Carton. And it
is through the work of Carton that I've been able to bring my own perspective to some quantum
information problems, which I hope to share with you. All right. So I think a great place
to start is, well, I think all of you know, a Hilbert space is a vector space that has
an inner product, right? And in fact, it's this inner product, which is the foundation
for any quantum mechanical prediction. And the inner product still today continues to
inspire quantum physicists to tell this story of states and measurements, being the subtly
distinct things, the subtlety not appearing in classical theories. But I want to point
out that even it took a while, perhaps 50 years between when the inner product was
envisioned by Hilbert to when it had the solid interpretation it does today. Okay. So I think
a good moment in time is to remember this 1954, when Max Born himself was given the award. I
believe this is a picture of him at his award ceremony. Yeah. But what Hilbert was doing
originally is he was just thinking about the real line. Okay. So I think a lot of you will be
familiar with this particular inner product. That is the inner product over the Hilbert space of
square integrable functions, square integrable functions on the real line. And this is the
direction I want to start with. But before I talk even more technically, I'd like to tell you guys
a few stories. Okay. So I think one of the most interesting ones at this point is the story
about Minkowski and Hilbert. So by the time 1912 comes around, Hilbert has basically mastered
every branch of mathematics that existed at his time. And from that point on, he would only think
about physics problems. And while at Göttingen, he created these fantastic mathematical physics
courses with Klein and Minkowski. And in fact, Max Born attended these classes. So that's an
important little fact. But none of that probably would have happened if it wasn't for an event in
1890 with Minkowski. You see, Minkowski became a professor at the University of Bonn. And at the
University of Bonn, he had inadequate mathematical colleagues. But Bonn also had Heinrich Hertz,
who at the time was experiencing a lot of excitement verifying Maxwell's equations. Okay,
so that year that Minkowski met Hertz, he actually decided not to go back to Konigsberg,
where he normally would go for holiday. By the way, Minkowski and Hilbert were old friends.
So Minkowski would write Hilbert often. And that's what this little letter down here is,
Minkowski has just met Hertz, and he's telling Hilbert about what's going on. So I might as well
read this because I thought this was fun. So Minkowski writes to Hilbert, perhaps I even would
have had to pass through a 10 day quarantine period before you and Horwitz would have admitted me
again, mathematically pure and unapplied to your joint walks. You can imagine how delighted I was
to read this recently. Oh God, everybody's quarantining themselves. So this is really
important. Minkowski started to think about physics and 20 years later, because of the ideal
situation that he was in with Hilbert, mathematical physics would essentially become a thing.
All right, I have another story for you guys. So over here, this little box that has Hilbert
Lee and Klein. So maybe you're aware, well, maybe you're not aware, probably you're not aware. So
1869 is the year that Lee and Klein were doing their first postdoc in Berlin. So Klein was from
a family of nobility. He was professionally trained by Pluker, probably heard the name Pluker when
you're thinking about identities between elements of a Clifford algebra. While Lee came from a family
of Norwegian farmers, I believe he was the first in his family to go to university. And in fact,
Lee thought he wanted to do astronomy. But in his first year of university, he had quickly found that
he was gifted mathematically, and he was expedited into a postdoc at Berlin. So Lee has a
reputation for the next 40 years for being quite wild. And in fact, it was because of the hard work
of Klein that Lee would even have a job years later. Yeah, and that's interesting. So Klein
created this whole vision called the Erlangian program while he was a professor at Leipzig.
But while he was doing all of that work, he was actually an intense competition with Poincaré.
And in fact, this competition became so intense that at some point Klein would have a mental
breakdown. And after that, he stopped doing creative work and had invested himself completely in
academic maneuvering. So he moved to Göttingen. He was the chair at Leipzig. And so he gave that
position, he took care to make sure Lee got that position. Then he moved to Göttingen. And at that
point, I just said that the greatest thing he did was to bring David Hilbert to Göttingen.
Okay. So I just told you guys two stories that changed the world. Germany was a great time
at the turn of the century, last century. All right. How long did that take? Maybe I should
move on. Did you guys know that a vial actually dated Schrodinger's wife, Anna-Marie,
while they were married? That's fun. They met in 1921. They were both chairs of their department,
Sensorich. Yeah. I think it's important to note that everyone knew about it, involved. It was not.
There was no shame about it at all. Yeah, no scandal. I think maybe the proper term is vial was
Anna-Marie's mister, is that, is that what you would say? He wasn't her mistress. He was her
mister? I don't know how you would describe that. I think they're just part of the same
polycule vial. Yeah. All right. Yeah. And in 1924 is when vial met Carton. So three years after vial
had inspired Schrodinger to think about inner products. In fact, I think it was in 26 that
Schrodinger actually published the Schrodinger equation. And in that same year, Schrodinger
published a review article on color theory, which uses inner products to think about how
every power spectrum can be written in terms of an RGB triple of numbers. So Schrodinger was
thinking about inner products intensely thanks to vial in ways quantum mechanically and beyond.
All right. Are there any questions at this point? I hope you guys enjoyed the story time.
Okay. So now. Maybe just a comment. Yeah. We did enjoy them.
I'm gonna try to put you guys down here so I can see the titles of my slides.
Okay. I guess you can't see the comments that you're presenting, but this is a side note.
Mr. Schiff is the only word in the English language that has a triple letter combination.
It's got three S's in a row. Wait, would you spell it M-I-S-S-S? No.
Oh, I see. Not consecutively, I see.
No, consecutively.
Insectively, but it's the other S that's tripled. Yeah. Mr. Schiff.
Hmm. Yeah, my phonetic abilities are not good enough to dictate what you're telling me.
I'll take a look at the comments in a moment. Thank you.
All right. So now another point about the real line and the inner product of
first square integrable functions that you might have forgotten,
which is that the inner product also, so once you have an inner product,
you can talk about self-adjoint operators and you can talk about unitarity,
but in particular for a manifold such as the real line, there's actually a sort of very privileged
self-adjoint operator, which is the Laplacian. I could be talking about multiple real lines,
so I apologize. I sort of toggle back and forth between the two multiple real lines,
three real lines maybe. Now there's a privileged self-adjoint operator, which is the Laplacian
invariant under translations, but there's also the privileged unitary, which is the
transformation from direct space to reciprocal space, if you want to think of it that way.
And in fact, it's through these simple subtleties that the entire story of scattering theory
emerges, right, where instead of thinking of Gauss's law as doing these divergence theorems,
you can think of Gauss's law as an expansion in terms of a quadratic theory,
a quadratic theory again corresponding to the structures that the inner product originally
was designed to elaborate on. All right, so and if you think about it for a while, you realize that
well, you know, the thing that defined the inner product ultimately was this property that the
measure had, that it was translation invariant. So if you're not aware, I believe Haar was either
late 1800s. I know Haar was quite a time after Helmholtz, and Helmholtz thought a lot about
spaces of rigid motion. So I threw Helmholtz in here because I think his name deserves to be
in them too, even though normally you would call this property of the measure of Haar.
Certainly, Haar wasn't around by the time Hilbert was thinking about these things.
Hilbert was inspired by Helmholtz. Okay, so why am I telling you all about this? Oh, hello.
What is the condition that is making the Laplacian so privileged here? Not just translation invariants,
right? I missed that. Why is the... Oh, okay, so I think it is the quadratic differential operator
that is self-adjoint under the Haar measure. Okay, sure. All right, thanks. Yeah, and I love
quadratic theories, and I hope I'll convince you that you can love them beyond flat spaces.
All right. Are there any other questions?
Okay, so why am I talking about this original inner product? Well, because actually this way
of using the inner product allows you to understand a great deal about manifolds in general.
Okay, so maybe you're familiar that you have a similar kind of equality between direct and
reciprocal space for the circle, and maybe you're also familiar that you have a relationship between
inner products and direct and reciprocal space on the sphere. Okay, maybe something you might not
have noticed is, well, actually, everything about the measure on the circle can be encapsulated in
algebraic properties of the complex plane, and thus, you know, the notion of residues, etc.
emerges. Well, the same thing also happens for the sphere, but you have to think a little bit
more about what you're doing. So right now, I just have sort of a formal expression for
the measure of the sphere. I'm sort of defining it as having its invariance under rotations,
and that somehow that measure is, in fact, uniquely defined by an object that looks very
residue-y. You just, because it's multi-dimensional, you have to work it a little bit more.
All right. Are there any questions here? Right now, I'm just suggestively
showing you guys things. I hope you don't mind that. I will leave details of actually understanding
how to calculate with these things to the papers I've written. Are there any questions?
I feel like I've lost the story a little bit, but only a little bit.
So the point I was making is that inner products can be used to understand manifolds,
and what I was trying to do is remind you guys of things that you enjoy when it comes to inner
products over square integrable functions on the real line, and then suggesting to you that
actually you can do entirely the same treatments for manifolds in general, especially when you have
a measure that can be defined by its invariance properties. So the first two lines are supposed
to say everything that you love about Gaussians and propagators and things that you know how to
calculate very well ultimately emerge out of a Harmeasure, and things like spheres and circles
also have Harmeasures. Chris, just to puncture that, so it seems also
that the right hand side of those qualities are, I should be thinking of spherical harmonics
or harmonic functions. Thank you for pointing that out. Yeah, so I guess I should point out to you
guys that, you know, when you look at these expressions, especially for the circle,
there's something, there is a problem that you've already solved, right, which is understanding
the spectrum of the manifold itself, right. So in this case, I explicitly said for the circle that
the spectrum is just either the i and thetas or, you know, they're enumerated by this number
that ranges over the integers. And then when I wrote this sum over L and M, I guess I was assuming
that you were familiar with the structure of these, maybe you'll call them quantum numbers L and M.
Okay, yes, so the sum is already represent, is representing an already solved problem.
Yes, thank you. And in fact, but you can solve that problem just from Harmeasure,
just like you can define e to the i k x, right. These spherical harmonics are defined by a
privileged aplastium, etc. Yes, yes, those are exactly the points that need to be emphasized.
Thank you. Are there any other questions or comments?
All right. Okay, what do we have next here? Okay, I want to make another point. So group theory
as applied to physics seems to default to a particular kind of application. So I wanted
to make this point in the following way. So probably if you ask any physicists why do groups,
why are groups useful in physics problems, they'll say, oh, because groups are a way to describe
symmetries. But usually, people like to emphasize that the symmetries you're talking about are the
symmetries of fields, say, in a Lagrangian. Okay, so you think of all of the sort of order parameters
you can put on a spacetime, for example, if you're doing high energy physics. And then you turn
a crank, right, Feynman has demonstrated to us that almost everything you could ever want to
predict in a field theory can be perturbed from vacuum expectation values of a Gaussian problem.
Yeah, so that's what I mean when I say these is usually symmetries are thought of as the
symmetries of fields used in your theory. But what I'm trying to reemphasize to you guys is that
group theory actually has a totally different application, which is to describe spaces that
have symmetries. And this is, and in particular, I'm thinking of continuous symmetries.
Yeah. So I could think of a field theory on a sphere, for example. These are the kind of
group applications of group theory I'm thinking of. And this isn't very popular.
Would you say that, you know, people just think about those vanilla geometries and fancier fields
on them, and you're sort of emphasizing that you can put these fields on different background
geometries? And certainly, if you're calculating cross sections for the LHC, the manifold that
you're putting all your fields on is locally flat. So, but of course, so Witten is known for
thinking hard about putting field theories on a two-sphere and a three-sphere. And now there's
the WZW models. I think Zhao Yang Wen has thought a lot about discrete analogs of the WZW model.
But yeah, so field theories on curved spaces is certainly a thing you can think deeply about.
But most people don't. Are there any, did that answer your question? Yeah, yeah, exactly, exactly.
Are there any other questions?
Cool. Okay, what else do I have here? So,
gosh, what do I even want to say here? So, these methods of carton, which I sort of learned to
use during my time at CQIC, have not been utilized in physics much. In fact, it's interesting how
I found a couple of books where Churn, maybe you guys are familiar with Churn, knows his topological
field theory very well. Even Cheyony likes to talk about Churn numbers. Churn once wrote an
introduction to a book on differential geometry. And he marveled that somehow you could get to this.
So, Churn was a field theorist. And he sort of admitted that he didn't understand this carton
way of thinking about things, or at least he couldn't understand how it motivated basically
the secrets of the fiber bundle that every field theorist eventually enjoys. So, what I'm trying
to say here is carton was, you know, thinking about just what does it even mean to move through
spaces and somehow arrived at these same wonderful structures, these better ways of thinking about
wave functions. Yeah, and I think one of the big reasons why carton's methods did not make it into
physics is actually because of something that Hilbert overlooked. So, there's this thing called
Hilbert's fifth problem. So, when Hilbert was thinking about Har Measures,
he recognized that Har Measures could be calculated using the differential properties
of the manifolds they describe. But he somehow didn't like that because he knew that continuity
was deeper than differentiability, and that measure theory shouldn't care about being able
to differentiate. So, Hilbert sort of got at the deep places he wanted to go in the fashion that
he did by sort of dismissing differentiability. And so, he did his own thing, but eventually would
create during these lectures he gave in 1900 Paris, what's called Hilbert's Problems. I think there's
23 of them. And the fifth one is this. He was pretty sure, but he didn't know, probably wasn't
willing to do the work at that point, because I mean, you can only do this kind of work so longer
if you're tired. The question was, are differentiable groups the same thing as integrable groups?
And, yeah, integrable groups are called topological groups. But I use the word integrable
because topological, there are subtly different things that should bring in your mind
than what you're probably thinking when I say topological. So, integrable groups, groups that
have harm measures. It turned out Gleason himself would be the guy who would partially resolve this
problem. I don't remember the last time. Oh, Gleason's theorem is something about the foundations of
quantum mechanics. I don't know Gleason's theorem, but I know the fifth problem. And so, I appreciate
Gleason suddenly. Okay. Is there anything else I want to say here? Oh, yeah. So, Carton's method
basically in the end is taking advantage of when you have an Euler decomposition.
That really is the heart of his entire methodology. And eventually, what's great is,
even when you don't have a Euler decomposition, you have locally Euler-like
decompositions. And that's sort of how you get into the secrets of non-Nebula-engaged theories,
et cetera. I'd love to talk to you guys about that, maybe offline. But if you look up, say,
the West Sumino-Witton model, so here's a field theory that gets put on a space time,
you'll notice them go on a lot about teleparallelism and how it affects renormalization group.
And it took me a while to realize that teleparallelism is basically just,
so all manifolds have Lie algebras, but not all manifolds have Lie algebras that are constant.
And the manifolds that do have Lie algebras that are constant still have curvature,
but are said to have teleparallelism. So, that sort of explains why, for example,
you can calculate all the harmonics of a sphere just by playing around with commutators,
which is really cool. That just blows me away.
I hope some of you have appreciated that, that you can somehow calculate, just playing with
commutators, all of these LM states for a system that has spherical symmetry.
That's kind of amazing because these LMs are supposed to be harmonics on some entire manifold,
and yet here you are diddling around with linear terms that appear in a Hamiltonian,
and yet you arrive at all the LMs. So, this is called teleparallelism.
Chris, can I ask just so I understand? Please. It seems you're emphasizing that playing around
with these local objects, these generators, somehow holistically gives you the geometry
of the full manifold, you're on something global from something local, and that's what
you're saying is called teleparallelism? Yeah, that the whole manifold is connected,
and it's connected in a way that the Lie algebra at every point has its structure because of the
Lie algebra at one point. It somehow knows. It knows because of how it's connected to itself.
Yes. Great. In fact, that's what this R inverse dr is all about.
Yeah. Are there any other questions? Let me get a time device. There we are. Okay. Half hour. Good.
Let's see. What else do we have here? Okay. Cartons list. So, I think one of the,
I think it's fair to say that the climax of Carton's career was in his 50s, soon after he met
Vile, where he finally answered this question on the top, which is when are translations,
because manifolds are just sets of translations in a sense, when are translations the same as
global isometries, modular local rotations? So, for example, the two sphere is such a thing.
So, and this takes some time. So, SO3, maybe you're aware, has three generators,
column JX, JY, and JZ. It takes time to realize that one of them is describing local rotations.
You know, if I put a point on the North Pole, it's fixed under Z rotations,
but actually Z rotations transform the space around that point. So, Z transformations don't
do nothing. They actually generate local rotations. And then maybe you're familiar
that, well, all manifolds are going to have local translations and local rotations.
But in fact, SO3 itself, you know, is two local translations plus one local rotation generator.
And you can just take advantage of that. And that's, that's one way of thinking about
Euler decomposition. Of course, you know, once you figure that out, you want to ask yourself,
well, when do you have the ability to do this in general? And eventually you find out that actually
all such manifolds with this property are made out of a basic 27. And this is just a really
wonderful thing. So why should you guys care about that? Well, I'll hope that you might care about
it a little bit by appreciating that actually these 27 types of manifolds that have nice translation
rotation relationships is actually the same thing as certain types of matrix diagonalizability.
All right. So here is a list of physics problems that have nice solutions you might be familiar with.
So random matrix theories, super fluidity, super conductivity. You might think of these problems
as special kinds of matrix diagonalization. Similarly, standard singular value decompositions.
But then there's many more. So even the Foucault pendulum and Thomas Procession
fall into taking advantage of these nice manifold properties. And also, I'm so happy to say this
quantum illumination. So, you know, Raph has loved listening to me talk about this stuff for years now.
And I was so happy to see it inspire him to think about quantum illumination in a
good theoretical way. So that's very cool. Quantum illumination was a term that Seth Lloyd
hyped up. And at some point, Carl and Raph got so exhausted that how many people were thinking
about quantum illumination in a broken fashion. This SU-1-1 structure, though, was also appreciated
long time ago by Bernier-Key in a different context. Perhaps that also inspired Raph and Carl.
All right. And actually, my favorite application of these manifolds is the falling cat.
Yeah. So if you ever look up, you know, the physics of falling cats, you will not probably
see this sort of symmetric space way of thinking as an answer. So the point is you're supposed to
think of a cat as a head that's an SO3 and a tail that's an SO3. And then you have this control
problem, which is the cat wants to do this. But of course, the cat can only do this kind of stuff.
But then you can solve the time optimal control problem and see that actually the best way for
the cat to do this globally is to do this. Let me do that again. I'll do this.
This. Yeah. So falling cats also fall under the category of physics problems that can be solved
using these special manifolds. Are there any questions?
Oh, these little yellow balls are called a dingin diagram. So it turns out all the structure,
all of these circles represent SU2s, manifolds in the shape of SU2. And the way that these circles
are connected to each other is describing how the whole manifold is shaped by how its SU2s are
sort of weaved together. Could I ask a question? Carl, is that you?
What is these, those with the 27 with constant curvature? What does that have to do with the
aforementioned teleparallelism? Okay, so all of these manifolds have teleparallelism,
which is to say that all of their translation structure can be described by a single realgebra.
So I feel like I need to ask you to re-ask your question if I can, if you're not satisfied
with the answer, I'm just kidding. Was the question, what is teleparallelism for each of these?
No, the question was whether, probably the question was whether these
27-lay algebras with constant curvature are the whole deal with teleparallelism.
Yeah, so
is it, I think it's the whole deal. My only, so as far as I understand, I see
string theorists and field theorists talk about the effect of teleparallelism on the normalization
group. I see that they're talking about it in the context of West Amino-Witton models. Meanwhile,
differential geometers such as Helgeson, who I think still can be found at MIT,
use the term parallelism to say, to mean when all the covariant derivatives of the Riemann
curvature are zero. So what I just told you was there are two very different looking communities
using the word parallelizable and teleparallelism, and I think it is intentional. I don't think
they're talking about different terms, but then their agendas are different, right? Field theorists
want to renormalize the hell out of theories, geometers, I don't know, it's not so obvious to
me that they're all about renormalization. Does that-
We'll ask another question if you think you have time to answer it.
Oh, yeah, I'm happy to just talk about whatever. I'll try to race to one of the punch lines.
So, you know, an arbitrary Einstein spacetime has a local structure, which is Minkowski
everywhere, that is, Lorentz transformations everywhere, but there's no such thing as the
global Lorentz transformation unless the space is flat. And I'm wondering to what extent these
spaces of constant curvature and the teleparallelism are equivalent to saying that there is a
global transformation. Okay, sorry. So I think I've left out a crucial word then. So all of
these manifolds are said to be globally Riemannian. So the Riemannian means-
Yeah, but I'm not worried about the Riemannian. I mean, I'm not worried about the pseudo Riemannian
of this time. I'm just worried about what I'm just asking about whether the global
symmetry transformation is equivalent to the same as sort of like constant curvature and quantum
and teleparallelism. Would you ask me one more time that last question?
It is the global ability to do global transformations instead of just local transformations.
Is that the same thing as having constant curvature and as having
Yes, teleparallelism. Yes, and that is in fact considered to be the work of Helgeson. So Carton
arrived at all of these lists with kind of a broken idea of what he was doing. He knew very well
what he was doing. But in the end, to say that actually manifolds with constant Riemannian
curvature are the same thing as manifolds that have global isometries. Yeah, okay. Cool. Thank you.
Fantastic. Any other questions or comments? I'll appreciate it.
Okay. Okay, I think I have one more slide and then I'll start talking about what I've done
while I've been at secret. So I want to give you another provocative fact. So this slide is titled
What is SU2? So I think most of you will immediately answer a particular way, which is,
which has to do with sets of two by two matrices with certain properties, right?
Unit determinant and the old U dagger U equals one. And maybe some of you have played around
with that enough to realize that SU2 is in fact the same thing as a three-sphere.
And I just want to point out to you guys that it's in the last 15 years because of the proof
of the Poincare conjecture, we actually have an alternative, more topological definition of what
is SU2. Okay, because SU2 is a three-sphere. In other words, the Poincare conjecture,
what is now a theorem, asserts that the three-sphere is the only compact 3D simply connective manifold.
And yeah, if you're, I really developed an appreciation for simply connected thinking
about control problems. And you know, when you're talking about paths that connect you to a target
and thinking about the kind of problems that make optimizing over all paths difficult,
I came to really appreciate what simply connected means. And yeah, I think you guys would also like
simply connected if you only spent a little time with it. Usually simply connected is described in
terms of path properties. But you can also think of those paths as gradients to phase structures
that you put on your manifold. And I don't know, that's another way of thinking in case you find
that helpful. What else? So maybe you guys are aware that even though Perlman hit this punch line,
he actually turned down the Millennium Prize. By the way, this was the only Millennium Prize ever
offered up to date. And the reason why he turned it down was actually because the program to actually
prove this, actually a generalization of it, was his friend's invention, his friend Hamilton.
So Perlman really felt like it wasn't ethical to accept the prize when the hardest part of the
work had already been done by his friend. He just hit the punch line.
This generalization may be just in the spirit of classifying manifolds. Is this idea that every
three dimensional manifold is basically a finite number of stitching between eight kinds of geometry.
Eight kinds of geometry is a little bit of a generalization of the kind of things that we're
showing up on the list of the previous slide. There's other things I could talk about here.
You notice I have a quote from Vile in this funny picture of Coxeter. But I think I'll
elaborate on that some other time or if asked. Otherwise, I'm going to move on.
Maybe I could elaborate on that briefly. Jonathan Gross and I managed to get a paper published on
just published in JFizA about estimating a single parameter out of many that is a Fisher
approach to that. We used a very geometric approach where everything we derive in it is from pictures.
We got a lot of flack from referees who said people have done information geometry before and
you need to reference all that. We did. But then instead of heaping scorn on all that work ourselves,
we quoted Chris Jackson as saying it was all algebra fever that is people who refuse to think
geometrically and reduce everything to algebra before they even start. That's published now.
Chris Jackson is out there as the author of the phrase algebra fever.
That's interesting to think how in 1946 this quote from Vile even demonstrates
that. I'll just read the quote. It says, my vindication for having proceeded in a much more
conservative manner than our young generation of algebras who probably deemed desirable is
a wish not to sacrifice the past. So you see once people realized you could calculate a boatload
of harmonics just using algebraic properties, people didn't want to think about derivatives
anymore. So even Vile himself was fighting or you had to explain himself to this new attitude
that mathematicians had, which I thought was funny. It's not often you see an authority
feel like they need to explain why they're not doing it the way everybody else is doing.
That's cute. Thank you, Carl, for bringing that up.
Other questions?
Coxeter has a couple of books on projective spaces that do all of their proofs using picture
drawing and I haven't studied any of them. If I ever had the time, boy would I like to spend it
with those books. Maybe some of you are familiar that projective spaces are a great way of thinking
about quantum mechanical problems. Okay. All right, so now with the times. How much time do I have?
Speaking of time, I have 10 minutes. Okay, I'll try to. Well, Chris, we can go a little over that
because we normally afford our speakers say an hour talking with an extra half hour of
discussions throughout and we've been interrupting you. So, yeah. Well, in that case, I'm going to
leave it to you, Raph, to cut me off. Okay, I can do that. Keep going. I apologize to any of you who.
I'll make sure to hit the multi-cubit tomography slide in the next 10 minutes in case you're here
for that reason. Okay. Okay, so when I came to Albuquerque, it's 2017. Soon after I came,
I had to finish up a couple of papers I was writing with Van Inck on how you would even know
if you had misbehaving state preparation and measurement devices when they're both misbehaving.
After I finish that up, both Ivan and Carl asked me to pay attention to their most senior students at the time.
So, both of them had given these students these incredibly large projects and, yeah, it was really
hard for these students to wrap it into something that they felt good about when they left, but also
they had learned so much that they were right with someone to have a new perspective to come in
and appreciate all of their hard labors. So, I feel very grateful. This has really set the stage
for my entire career, the work that these two students have done. And, yeah, for that, I am
truly grateful. So, what are these two projects? So, this guy on the left, Ivan's student is
Azad. He was thinking about measuring many-body spin correlations. I think even our drought box
folder was titled, measuring many-body correlations. But by the time they had brought this project to
my attention, Ivan was doing a bunch of these gestures, and they were thinking about this
spin-coherent state measurement, the so-called spin-coherent state measurement, and they were
pretty sure that they had found a way to implement it. Now, the spin-coherent state measurement
is something people became interested in in 95, but I think by the time 2001 came around,
there were all kinds of papers written saying, oh, the spin-coherent state measurement is not
something you could do practically because of all kinds of arguments based on the way that
you're thinking about things. It turns out that if you know how to think about continuous measurement
in just the right way, suddenly the spin-coherent measurement doesn't look so intimidating.
Meanwhile, Minot, this guy, Carl's student, was thinking about fermion simulability. In particular,
demonstrating problems are simulable by how you would solve them with a face-based correspondence,
continuous face-based correspondence. Maybe just to say what's on this slide. Under Izzad,
I have this Krause operator somehow always go to things that look like this, where these things on
the left and right are spin-coherent states. This little figure is a description of the isotropic
measurement, where I have this putting of spins that are being collectively coupled to in their
x, y, and z components by a Stokes interaction, I believe, where these red lines, I'm suggesting
lasers. I have polarizations that are coupling and then being detected. And then you have these
readouts that I'm representing by vener processes. On the right, we have the vigner function
of a fermionic vacuum state in the face-based correspondence, where the face-space is the
space of VCS superconducting states. It's a funny kind of face-space to think about,
but it's sort of the only continuous face-space you can think about because fermions are
my maintenance. Maybe that's a way to put them. All of these funny squiggly lines are actually
harmonics for parafermionic systems, and I just enjoy them so much that I want to show them to
you guys. And the reason I have this New Mexico symbol with these four extra lines in the corner
is because it turns out that there is everything you want to know about fermionic systems in four
modes. I was showing you guys these Dinkin diagrams earlier, and those Dinkin diagrams
describe these sort of angles that are in your space that determine the structure of everything
else. And for four fermionic modes, you have these fourfold degeneracies in certain directions,
and then you have these other kinds of operators. So these lines are supposed to be arrangements
of operators that displace in the manifold of VCS coherent states. And when I saw the fourfold
degeneracies in the edges like this, it just made me think of the New Mexico sign, so I couldn't help
myself. There it is. Okay, I think I said everything about what's on the slide. Oh, Chris Ferry was a
postdoc that I think was the main inspiration for this project. And then Carlos Riofrio and Amir Kalev
inspired this project with his art. Any other comments or questions?
So this was, I guess I've said things that I've done with these projects as well,
but I now want to focus on the points I want to make before I leave the center.
So I've been writing furiously for basically ever since the pandemic happened, it's been kind of a
blessing for me to suddenly have the devoted time to just think about writing. Very grateful for that.
And I think there are two points that I want to make to all of you
through writing. And I'm going to do my best to explain to you what to expect in these two
things I'm about to write. So when we realized that the spin coherent state measurement
is implemented by an isotropic measurement, we had a particular way of showing that,
which had to do with taking derivatives of the singular value decomposition. And that was great.
However, I found it not satisfying because of another perspective I've always had. So
I don't know if you guys are familiar with, I don't want to say this, if you've ever done
stochastic calculus deeply, you might appreciate that there's always three ways to do stochastic
calculus. There's the Fokker Planck equation or diffusion equation way of thinking about
random processes. There's the stochastic equation way of thinking about random processes. And
there's the path integral way of thinking about random processes. So what we did here was the
stochastic equation way back in 2018. And it really haunted me that I could not do it the other two
ways as well. It sort of demonstrated to me just how much I didn't quite understand everything
about what we had just done. So I'm happy to tell you guys, thanks to the attention of Carl,
actually, I was able to figure out how to do this problem in those two other ways as well.
And that's what I'd like to share with you guys. Yeah, the best way I can. So in the end,
I think the point of this slide is that the isotropic measurement can be partitioned
in terms of operators that take their value in a particular manifold. And once you get there,
then basically, Bob's your uncle. And the analog of Gaussian diffusion
for the isotropic measurement is Fokker Planck equations that look like this,
where this important z function is, in fact, what it is based on these different diagrams.
That's fun. In other words, these diagrams are telling you what the set of R pluses is.
I think Raffy even told me recently, he was very excited about polyhedra and sums over
polyhedral reflections. And I told him, oh, yeah, I've been thinking about those two. And that's
where they are in case you were curious about that. Okay, and I'll talk about how this has to do
with multicubic tomography soon. This other thing I want to tell you guys about is basically how
a carton's list translates to a whole bunch of problems you can solve explicitly in time-optimal
unitary control. So I think in the words of Michael Nielsen, so the thing that's hard about
time-optimal control in general is actually performing the optimization over all paths.
So thanks to teleparallelism, probably, I'll have to work out how true that is. I mean,
all of these manifolds have teleparallelism. So probably, thanks to teleparallelism,
it's actually not hard to do the global optimization for these problems. So in the end,
these problems degenerate to this minimization problem, where these Thetas and Phi's that are
being minimized over are, again, have their structure as described by the corresponding
Dinkin diagrams. So perhaps it'll be useful for people to realize that there are a whole bunch
of second easiest time-optimal control problems that might sort of help them navigate through
much more complicated problems. That's always my hope. And one of the problems I'll be happy to
explain in this paper is the fallen cat. And so this figure is sort of me making a joke,
which is that if the cat was globally symmetric, it would be able to do these things.
But lucky for the cat, the time-optimal solution doesn't require such dramatic contortions.
So in fact, having a spine that's barely flexible is good enough. And that's probably on purpose,
right? I mean, being able to perform a time-optimal solution is definitely going to help you survive.
And so maybe that's part of why cats are the way they are.
So Chris, hello.
So in the abstract for your talk, the thing that piqued my interest the most was this
final sentence where you said, we could do scalable complete tomography for multi-cubits,
because I'm thinking of n-cubits. You're going to have exponentially many
coefficients. How could you possibly do that in a scalable way? And so I was just wondering,
is this the only slide you're going to use to address that topic? Or are you planning on talking
more about that? Yeah, so let me run up to it now. And then I'll run backwards as questions
arise, because I did just promise you guys I would hit that point in 10 minutes, and I didn't. So I
apologize. Okay, so here is a slide devoted to this point. Okay, so maybe you're aware that
I can have a, oh, how do I want to save this? Let's start with the standard argument of why
multi-cubit systems don't have scalable complete tomography. The standard argument is, well,
given any Hilbert space of dimension D, the measurements you normally think of will only
give you D numbers. And so you would have to actually do D such measurements in order to get
enough numbers to zero in on the D squared numbers you need to specify a density matrix. So those D
numbers, though, come from strong measurements. Every time I do a strong measurement, then I get a
distribution over at most D different outcomes. But you can think of doing, instead, continuous
measurement. So the continuous measurement literally is to just continuously measure
isotropically the 3M1 local observables. That is the continuous isotropic measurement.
And it performs this so-called, this coherent measurement, okay, where the POVM elements are
projectors onto, well, these sort of spin half coherent states per cubic.
Okay. And once you do that, well, actually, you can do all kinds of predictions.
If you stay in the phase space correspondence of these M copies of the two-sphere,
let me try to move this so I can see the bottom. In particular, you might be interested in
K local expectation values. So I included this little thing on the bottom right that, well,
K local expectation values are just products of Y1Ms for the corresponding
dimensions that they care about. So this is the scalable, complete tomography for
multi-cubate systems. Scalable because you only have to measure 3M observables, in fact,
easy observables, one local palette, but you have to measure them isotropically and continuously.
Okay. So if you have M qubits and you're trying to do tomography on them,
how long do you have to wait to know the, you know, the parameters describing that state to,
say, some number of bits of precision? I mean, is that time scale polynomial or exponentially
with that? I mean, you could be hiding it that way. Yeah, so that, no. So in fact, it turns out
that the coherent state measurement is implemented exponentially in time.
Yeah. So did I have a little? Oh, no. Yeah. So this, this collapse in general is exponential in time.
The, the POVM elements of the isotropic measurement become projectors onto coherent states
in exponential time. But that's also the optimal, right?
Uh, what is optimal? Is, isn't this protocol something, something the optimal?
Oh, um, so that's, that's a different problem. Okay. Good. So, sorry, sorry. Well, it's, it's,
okay, I sort of ignored that. So the original motivation of this problem had to do with,
if I had a whole bunch of qubits that were prepared in the same way, then there is another kind of
spin coherent state measurement, which measures that unknown direction optimally. But that's not
what, um, that's not what this is. Okay. So maybe I tried to emphasize that by taking,
leaving only one qubit per, per black area. While the, the optimal stuff had to do with
having identically prepared qubits all being collectively coupled too. So this is not that.
I know it looks a lot the same because it's still multiple qubits. It's just not collectively coupling.
So maybe I'll ask my question another way. Is this efficient in the dimension of the
Hilbert space and not the number of qubits? Because fundamentally, I just don't understand
how you can even write down an exponential amount of information and a polynomial amount of time.
Merely the act of writing it down seems like it would take too long.
I think I'm missing something somewhere. Right. I think, and maybe I'm also missing it
and for the following reason. Uh, so, so how is the information actually organized in a sense?
Right. So in this phase space, there are sort of high frequency variations and low frequency
variations, uh, or low wave number. How do you say that? There's, you know, these,
these M cartesian, this cartesian product of M2 spheres has a bunch of hormones
that describe its details. And, and the question is how, to what precision do you know,
say, the expectation value of a K local term? Right. I think is precisely where,
um, inefficiency comes in. Right. That you probably do have to do more work,
wait a little bit longer, uh, the higher the K local, the K is in a K local term you want to predict.
Maybe I can ask a related question because to, to just to maybe make a related point to this.
Is this POVM informationally complete on the space that's two to the n dimensional?
If I wanted to, uh, I wanted to ask, you know, which state in my tensor product space
is this, are the outcomes to this POVM
informationally complete on that space? Right. But I would need, I would get us,
I do this measurement and I'd get one outcome ultimately. Right. And so, and so that's not
going to be, I mean, unlike the original motivation, as you said, in relation to
the Maasar and Popescu optimal problem is that you had n qubits all in the same
pure state specified by a block vector. And you wanted to say what's the optimal POVM I should do
given n copies of that, right, uh, to deduce what that direction is. And the answer is
do a spin coherent state POVM and whatever outcome you get, that determines the direction.
But this is not the same doing this POVM is not going to allow you to deduce two to the n
numbers, even if it's a pure state. Okay. So I think the point you're making is, uh,
preparing a bunch of copies is also going to be a lot of work. Yeah. And I do agree that, uh,
the amount of work that you have to do in making copies is going to be just as hard
as in standard tomography. The only part that scales better is well, I guess the question is,
I'm given, you know, I'm given a many body state of n qubits. Okay. And it's prepared
I can even be generous and say it's prepared on a pure state.
Some it's some heart, you know, in the in the full Hilbert space.
I'm I'm I want to then do tomography to determine what that state is.
Well, I'm going to have to have many copies of that many body state to do it.
Right. So this is going to be give me one outcome on that many, but I'd have to do it
on many, many, many ensembles to ultimately, but this is, this is telling me that there is a more
generalized formulation to do multi qubit, to do this particular POVM, which is more general
than the spin coherent POVM that we worked on together. Is that a correct statement?
Yeah. Yeah. So, you know, the point of this measurement is to do complete tomography,
not single shot guessing. Right. That's an important point. And it's true that I don't think
this is going to solve all our problems because indeed something is hard. But I think the point
I'm trying to tell you guys is the part that isn't hard is that, you know, you can have,
you can just isotropically measure 3M observables. And that's somehow much nicer than the protocol
standard tomography suggests you would have to do. I wonder whether I was just thinking
whether this is a path forward to the problem that we originally were trying to solve, which was
it is exactly. So yeah. So we need to do that.
Yeah. I'm so glad that you had the sense. Yeah. Yeah.
Andrew, do you feel like you got the information you needed?
Yeah. I think still there's this exponential effort, and even a number of copies needed to get
information on all the difficult equations. Any one measurement only gives you part of that.
And I think you're saying just that you can make each of the measurements you do simpler than the
sort of standard way of doing things. So that they're not as difficult as you might think.
Yeah. I don't think they get harder, but I don't think all those copies and orders of observables
sources of difficulty get harder. I don't think those get harder.
I think those are just as hard. Okay. Thanks, Ivan, too.
All right. Okay. I think so one other point maybe I want to make is this whole work I've
done on how to analyze isotropic measurements has inspired me greatly. And I hope maybe it can
inspire you because the isotropic measurement really is the most basic kind of continuous
measurement you can think about. It's basic enough that I can give you these wonderful
analytic solutions. So it immediately suggests the following vision to me, which is, well, okay,
so if field theorists love that you can solve Gaussian problems, and then because you can solve
Gaussian problems, you can perturb to your heart's content any other problem that's close to Gaussian.
Well, actually, you can do the same thing for any kind of measurement that's close to the
isotropic measurement. And who knows what kind of stuff you could learn about measurement
just doing perturbation theory around this most basic of continuous measurements. Okay. In this
case, the propagator is a little more complicated because of this z factor because of the curvature
of the space that everything is propagating in. And you're very much going to care about that
curvature because the whole manifold in a sense is explored before you get these projectors.
Yeah. And I just love the idea of, you know, measurement theory propagators.
So that's what I find exciting about this. Another thing is so these path integrals that come
into the way I've analyzed the isotropic measurement are sort of inside out in the
sense that what you're integrating over is not virtual paths, but literal measurement records.
So that's cool. Normally, you think about path integrals as sums over virtual paths,
but actually you can use path integrals to talk about sums over measurement records too.
And yeah, propagate and perturb to the heart's content.
Maybe somebody will care about that someday. Who knows?
First of all, that's really cool. Do you say actual paths? Do you mean the actual
measurement records or different possible measurement records?
It depends on if you want to think of it in a Boltzmann way or Gibbs way.
So yeah, you pick your interpretation. Do you think of a DW as the DW? You just
didn't know what it was, and that's why we're doing all this math? Or are you thinking of
having sampled a bunch of DWs? So the first is the Boltzmann interpretation. The second is the
Gibbs interpretation. So like when you're talking about gas, for example, it actually doesn't matter
if you're talking about an unknown molecule in a box, or if you're talking about a gajillion
molecules that are not interacting in a box. So same thing goes here. You can. And maybe that
goes to the point that Ivan was making that, yeah, you could think about doing this measurement in
single shot, or you could think about doing this measurement a whole bunch of times to do tomography.
I guess that would be the analogy of the Boltzmann and the Gibbs interpretation.
Either you did this a whole bunch, and now you've got a bunch of stuff to look at, and they're
distributed the way they are. Or what you're witnessing is actually typical according to the
statistics of your ignorance. Either there's one, or there's not one. Did that answer? No, I make a
comment. Carl? Could I make a comment on? Just a moment. Yeah, just a moment. Did that answer your
question? No, I wanted to make a question. You hadn't finished and then asked me to comment.
Oh, right. So Carl, go right ahead. So, you know, these measurement records, they're exactly like
what's called unraveling a master equation. You can think of that as actual measurements
and actual records that determine how the density operator is evolving. Or you can think of them
as just a tool to think about what underlies that the preparation of some density operator. The new
thing here is this is not master equations. This is equations for the cross operators themselves.
So you're unraveling the, in some sense, the diffusion equation satisfied by the cross operators.
And that's a new thing.
What does that mean, Carl? I mean, I understand I'm unraveling, you know, these trajectories.
This trajectory concept for states. But what's the notion of a trajectory for cross operators?
Are you thinking of some like Heisenberg representative picture or something like that?
What's going on? Chris, maybe you could answer that because you probably have some equations
there that say exactly what it is. Yes. So here we, here you have it. Okay. So the main important part
is, oh, maybe I'll back up a little more. So here is a cross operator you're probably familiar with.
It's the cross operator you get from coupling a Gaussian pointer state to a observable X.
The outcome of that meter state is DW. I've just written it in a certain way that I like.
Okay. And so then the, the isotropic measurement is you just let this X be X, Y, and Z,
say, observables or whatever are the linear observables in your theory. Okay. So, and then
the question is how to think about the behavior of these cross operators as a function of the
measurement. Okay. So there are three ways as in any good stochastic model, there are three ways to
think about how these cross operators evolve. Okay. So in this case, so now what I've done is I book
keep, what's great about the isotropic measurement is that the quadratic generators that come from
that Gaussian pointer basically go away. In which case now all you have to do is think about products
like this. And so these are the things that we're talking about having trajectories
are the cross operators themselves for every measurement record.
Yeah. And so you get great, you know, sub manifold closure properties you can talk about,
you know, all of the things you love to talk about when you do stochastic analysis,
you can think of a distribution which is though over cross operators, which is a sum over all
measurement records that give you such a cross operator, you can ask how does that diffuse.
And the point of what I'll be publishing soon is you can solve this and that's great.
And you can also think of it in a stochastic differential equation.
But we're talking about cross operators as a function of the measurement record.
Yeah, I guess I'm just used to maybe this more Schrodinger picture type thing when I think about
trajectories where these cross operators act on a state. And you get, you know, a differential
of the state the density matrix say it does have these DWs on it, but it's you think of the Ws is
acting on the state, you know, they came from cross operators if you like from this picture,
but then when you actually get to the differential equation, you think of the DWs as being related
to this measurement record. And so you think about unraveling trajectories of the state.
And so here, you know, you ask for money, I guess we can write the cross operators as functions
these infinitesimal still the stochastic infinitesimal, but I'm just having a hard time wrapping
my head around what it means for those to be trajectories, unless I'm thinking of some
Heisenberg type picture where I think of the operators is evolving or something like that.
Yes, maybe I can add a comment to it. You know, what we were originally thinking about it when
you do a continuous measurement, well, you're performing some POVM.
The POVM you might think about as all the different POVM outcomes are related to the
measurement record. But if you have a measurement model for that POVM, then there's a cross
a cross way you can think about it in terms of cross operators. Sure. And then those operators
those operators are evolving as a function of the measurement record.
So the actual POVM you get at the end of the thing depends on the whole measurement record.
So you can, it's not a typical thing. No one ever has talked about this until we did. That's why it
And this is not just the Heisenberg picture though by saying, well, the changes in measurement
records changing, you know, the operating to the measurement operator itself.
So you can think about it, you know, you have some unitary that couples the ancilla to the system.
And then, you know, you do some measurement. And that gives you on the ancilla that gives
your cross operator. But then that happens that evolves in time, as opposed to the thing about
it's a one shot deal. Okay.
Chris, could I make a comment? Cross operators are inherently showed in your picture.
And this is more like the path integral formulation of a green function. But at the level of states
as operators and measurements that underlie the way the cross operators are evolving in time.
But it's all Schrodinger picture. That's right. But about the measurement, which is different
than, you know, Schrodinger Heisenberg using about the unitary, this is about the measurement.
What do you think about just as a quantum trajectory for the measurement device,
because you're doing a measurement that could be adaptive? Or is that an oversimplification?
Want to add add activity? That's a different story.
Add activity in here included? Because I mean, no, no, no, no, this is not this is a non adaptive
measurement. You could include add activity. But that's not the problem I'm solving. And in fact,
if you if you added a little bit of add activity, I would suggest you do a nice perturbative approach
to. If it's not adaptive, why does the measurement, you're doing it a later time,
depend on the measurement you're doing at a previous time? It doesn't. You are measuring
the same observables continuously. Right. Right. Okay. Or before we get too deep here,
could I ask that we wrap up in five minutes? Okay.
Are there any other burning points or questions before I wrap up?
Okay. So where am I headed next? So maybe you guys are aware I was scheduled to move to Sydney
at the end of March. And guess what happened? Well, COVID happened. Luckily, because of the sort of
other things I had up my sleeve. So the original plan was Chris very had a postdoc. It would have
only lasted until May 2021. So I was trying to get another fellowship so that I could stay in Sydney
longer and maybe even ultimately move to Australia. That was the plan. And so the Sydney Quantum
Academy showed up and I applied for that and that went very well. But then pandemic started
happening. The Academy decided they weren't going to hire any non resident non citizens,
the gates closed. Oh my God. Luckily, on the SQA interview committee was MacRamner.
And soon after my interview, Mohan asked him if he knew of any people who were interested
in differential geometry. And so he thought of me and yeah, that interview went well.
And I will be starting working with him in January. So that was incredibly dramatic and
then incredibly fortunate for me. Yeah, I really look forward to it. Yeah. Okay. So I really want
to thank all of you. My time at CQA has been very nice. It's also been dramatic. But in the end,
I guess I am leaving with a better sense of myself. And what more could you ask for?
So I particularly want to thank Carl, Elizabeth and the postdocs and Gloria for
their personal relationships with me. I feel like I've been,
I don't know, I would almost say this is the most insecure period of my life.
Because, you know, it's taken me a long time to accomplish the things I set out to.
But somehow with all of these personal relationships, I think I'm going to make it.
And that's very valuable. It's been very nice working with all of the students here.
These are the ones who are still around, I believe. Last I checked.
But of course, I've been touched by a lot more students than just these.
Including Gopi, Zod, you know, etc. So I look forward to seeing you guys around.
I do. Yeah. All right. So if there's anything that you take away from this talk, I hope it's
the following things. First of all, history is great. It's important. It's amazing how much you
can see the people and the techniques that we use today. I certainly learned so much
about math by learning about the people who made the math.
I also pointed out that isotropic measurements are, or I'm telling you, and then asking you to
read my papers later, I'm asserting that isotropic measurements are really the most basic kind of
continuous measurement you could think about. And once you know how to solve that problem,
well, you actually have a program to understand very many continuous measurements. I have this
dream of creating a relatively coherent theory of how to analyze continuous measurements
based on this most basic kind of measurement.
I've got two papers coming. Carl has been spending so much attention on this coherent
state measurement paper, and it really is going to have a quality of writing that
it would not have been without his attention. So I had to put his picture here because
he's been keeping me sane during this whole pandemic. And I hope you guys will benefit
from the fruits of all that labor as well, because the papers will be well written.
I think most of all, hopefully you guys will always remember me as someone who really likes
the manifolds. All right, so with that, I'd like to thank you for your attention.
Thank you, Chris.
Well, that was very valuable, very deep, and yeah, we really liked it. So I'm going to make
Chris the host in case he wants to hang around.
Have any further questions, but the official seminar is over, and I'm going to stop recording.
