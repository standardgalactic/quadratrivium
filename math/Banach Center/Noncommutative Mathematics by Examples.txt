Okay, welcome everybody to the afternoon lecture.
The lecture will be given by Anna Kula, Anna is a professor at the University of Wroclaw.
She does research in harmonic analysis and in non-commutative probability.
She is interested particularly in quantum groups and at some point of development of
quantum groups, Professor Varanovic defined a special family of such groups and everybody
was interested how do they look like and Anna gave a complete classification of this class
of groups in dimension three. She obtained a number of grants for her research in particular
and she was a principal investigator in these grants and in particular polonium
for collaboration between Poland and France.
And finally, she is a mother of two, as you can see and still a very successful researcher.
Please Anna, the floor is yours. Okay, thank you very much for the introduction and
trying to organize this ever. So, please, Anna for inviting me to give the talk here.
I chose the topic non-commutative mathematics, which is not actually any specific domain in
mathematics. It's rather a certain idea that was applied, hopefully, to different domains.
I'm going to talk about it, but I have to warn you, I'm not like Thomas Maastricht,
who tries to see what is down below the iceberg. I'm rather the example person.
So, I thought it will be nice to see some specific examples in this domain that I'm going to
present to you. So, maybe we won't dig too deep, but rather see the tops of the icebergs,
but I hope that if you will get interested in the topic, you might try to dive below.
Okay, so let me present you shortly an overview. I will first try to explain what I mean by
non-commutative mathematics in general, and then I will present your three applications of this idea
to the group theory, to probability, and maybe if we have time to geometry, but very shortly.
And at the end, I would like to show you that all of this is by the vivid research topic nowadays.
Actually, the whole idea of non-commutative mathematics developed in the 80s and 90s
plus the centuries, and it's still under construction. So, let us start with something
very basic. I'm always afraid of saying that everybody knows what the matrix is.
Let's start from square matrices, complex values. What can we do with them? Well,
surely we can add them up. They are of the same size. We can add them coefficient wisely.
We can also multiply them by colors by the same way, and there is a more complicated operation
you already know it, and we can multiply it to matrices. This is like
like acting with two linear operators one after the other. What is more, we can form an adjoint
matrix, just taking a transpose and the conjugation of the numbers. And finally, what we can do with
matrices is that we can compute their norm. The norm is more or less a distance of even
matrix from the matrix with all coefficient of zero of these vectors. So all this shows that
the set of matrices has a structure of a vector space, a structure of a norm space,
the vector space is this, the norm space is this, and the third that we can multiply and
take the adjoint shows us that this is actually something called involutive algebra.
Moreover, we have a lot of compatibility conditions in between these operations,
but the most important one for us is that when we mix multiplication of two matrices
taking other joints of the matrices and computing the norm, we know how this all behaves.
Yes, so there is this condition that links these three operations all together.
And a structure that satisfies this kind of condition is called a fitter algebra.
The set of matrices and an example of such a fitter algebra, which is unital, because
the identity of matrix is a unit in this algebra, which is finite dimensional,
because we are dealing with finite space, and what is more non-commutative, because multiplying
matrices is a non-commutative operation. More generally, we can take any Hilbert space,
P n such an example, but in general it can be infinite dimensional. We can form a set of bounded
linear operators on this space, and this will be again a fitter algebra.
Let us have a look at another example. If you take a topological space, which is compact,
this makes a few things about just close bounded interval on the real line.
You mean compact house stuff?
Yes, compact house stuff. And we can form a set of all continuous functions from
this compact space with compact numbers. And here again, we can define point-wise addition,
point-wise multiplication, involution, which is in fact a conjugation of the function,
and the norm. And all these operations will satisfy the same properties as the one
I mentioned at the previous slide. So this p of x, the space of continuous functions on x,
will be a unital system algebra, but this time it will be...
And in 1943, Gelsant and Neibach studied the structure of system algebra in general,
and they proved several nice results about them. And in particular, they showed that every commutative
system algebra, unital system algebra, will be of the form shown at the previous slide. So it will
be actually a set of continuous functions on some compact topological
along those spaces. So yeah, I think that for me, topological space is a compact house.
So to be more precise, Gelsant and Neibach showed something more than just this isomorphism
between spaces and functions on the space, which we will sum up in the language of categories,
by the way, saying that the category of compact topological spaces is equivalent to the category
of commutative unital system algebra. So in a sense, this means that we can look at one
or the other and it doesn't really matter. We can recover one from the other.
So this gave this general idea that we can study spaces without referring to their points
to elements of the space x, but rather via functions. And this started the whole program
of commutative mathematics, which may be shown on this kind of picture. So let us start with
by this result of Gelsant and Neibach, compact sets are in one to one correspondence
with commutative unital algebra. Okay, but then why we need this commutativity? Maybe we can
live without it. So let's forget about commutativity. Let's pass the river of
non commutativity and think about non commutative unital system algebra. You still may think about
them as being something like continuous functions on some, continuous functions on some
strange object, which we call this one. So this is the basic idea that first we start,
we try to forget about the points of the space, you rather think about functions on them. And then
this would be a commutative algebra. So we try to talk about this algebra without
commutativity property and think about them as being functions on some virtual objects,
non commutative. But this is only the first level, let's say, because there is another one.
If we know that this set has some structure, this structure probably is somehow reflected
on the algebra of functions. If we are able to axiomatize it without referring to points of
space, then we can keep it axiom, pass them to the other side of our river.
And think about non commutative unital system algebra, satisfying the same properties
as continuous functions on some virtual space, which has the same virtual structure.
Okay, yet another level. Once we have the space with our structure, there are some,
perhaps some related objects or some properties. And again, they will be reflected on the level
of algebra by some other specific properties of the algebra. So what we are doing, I guess,
all expect, we keep the axiomatization of these objects or properties and we pass them
to the non commutative algebra and see how they live there. And this gives us
like a virtual analogs of certain properties. So you're going to see this kind of idea at the
three examples, which I plan to present you. And they are due to this, we gentlemen down there.
So this was like a knowledge, never locked in 18th, the theory of compact quantum books.
Dan Vojkulesko said it's the probability theory, and along comes the father of non commutative
mathematics. Before we go further, let me give you at least two reasons why non commutative
mathematics should be for the interesting subject. The first, well, probably every
mathematician working in this area has its own written, but let me present two which are,
I think, kind of easy to explain. First one comes from quantum mechanics. The general idea about
quantum mechanics is that instead of thinking that a particle is at some specific point, which
was our classical thinking, we think about a particle as a wave function. So
she is probably there with kind of high probability, but actually it can be everywhere
until we measure it. So this is the first idea why we should resign from looking at the space
with points, but rather possible to the algebra function. And why this algebra should be non
commutative? Well, that's one of the postulate of quantum mechanics that observables that you can
measure are actually self-adjoint operators on some Hilbert space and what we are actually able
to measure are only the eigenvalues of this. Sorry, I have a quick remark to the first point that
the state of a particle is determined by the wave function. So most of physicists agree with this
point, but there are some controversies regarding the various interpretations of quantum mechanics.
So I believe that not every physicist was subscribed to this point. Yes, I agree,
there are different interpretations. Okay, so once we have our measurable quantities
of operators, we can see how they behave. And in particular, the most basic operators, position
and momentum, they turned out not to commute. By which we mean that if we try to measure position
first and then momentum, this will give a different, this possibly give a different
effect comparing to the situation with the reverse order. So the algebra generated by the
basic operators will be non-committal. That's why we feel, well, we think this is important to
understand. So this may be more typical reason to think about quantum mathematics. Another one
comes from probability theorem. There is a famous theorem which lies at the background of every
statistical, well, most statistical experiment. If we take a sequence of independent identically
distributed random variables, like we sample from some population, then some normalized means
will always tend to a normal distribution, independently on the original distribution
of the random variable we are measuring. So the normal distribution is bell shaped,
well, it has been bell shaped basically at the bottom. But now... Sorry, I have a question
already related to this central limit theorem. So would you agree that there is already some
non-committal activity in this theorem? The argument would go like that. In the proof of this
theorem, you're using this, it is called improbability theory characteristic function,
but in fact it is the inverse Fourier transform. And this is something which is important in
quantum mechanics. So okay, you can have the proof via Fourier transform, but you can also
have the proof via moment computing moment. This is more or less combinatorial. Okay.
So not necessary that there is already there a link. Yes. Okay.
So this passage to function is possible, but not necessarily.
Okay, so we have this central limit theorem for independent identically distributed random
variables, but now we can try to put this random variables into a matrix form. So if
consider two families of independent and identically distributed random variables,
so one is in here on the diagonal, the other is up here in the upper triangular part,
and then we symmetrize it. We normalize it in an appropriate way. This kind of matrix,
we call a beginner matrix, and we can study the eigenvalues of some such matrix. This will be
random matrices, but any time you choose some numbers, you can compute the eigenvalues and
then the average over there. So the measure related to the eigenvalues are called empirical
spectral distribution, and basically it's delta measure associated to any eigenvalue.
Now we can try to do some simulation, and what happens if our matrix has size 100,
then the empirical distribution has this kind of histogram. So the height means how many
eigenvalues are in this particular small interval. So in the beginning, we don't see any
specific shape, but once the sample size grows, well sample size means here the dimension of
the matrix grows, there is a common shape that appears, something like this. Surely it's not
a normal distribution. And actually it was Winkler who proved in 1955 that if you compute the
limit of this empirical spectral distribution with a growing size of the matrix, it tends to
something that's called a Wigner's semicircle load, and the density is exactly the one so
like approximated on the previous slide. So comparing to the bell shaped density that you
have in the background is very much different, particularly because this is compactly supported,
which is not the case. So we see that when we pass from the commutative
structure of classical one-dimensional random variables to matrix
structure, something strange happens. Okay, so let's get another one to study this
non-commutative. Okay, so let us now start to see the specific example.
I decided to start from the groups, so I think the first, well, one of the first
you learn the studies. I will, well, should I remind you what the group is?
Okay, so maybe it's worth reminding people because this is something that sometimes overlooks that
groups grew up from observing symmetry. Actually, if you take any mathematical object,
any geometrical object, then the transformation that leaves the object invariant from a group.
Yes, so we have a lot of examples of groups coming from symmetries of objects.
That's what, by the way, was already mentioned during one of the talk today, or
yeah. So now let us have a look at the special case, the SU2 group, over the future,
talk at least. This is a group of two-by-two matrices, two-by-two unitary matrices with the
determinant one. And it may be an example to show that this matrix has to have this form,
but actually it is parametrized only by two complex numbers, not four, and these complex numbers
are from the two-dimensional complex here. And it's maybe one more exercise to show that this
is indeed a compact group. But since we want to pass from studying the group to studying functions,
on the group, we need to ask ourselves, what are continuous functions on such a group?
Do you have any proposition? What could be a continuous function on SU?
We learned yesterday that associating to a matrix its eigenvalue is not a continuous function.
Yes, do you remember? Anything else?
What can we do with the matrix? Take a trace. Determinant, okay, let's wait.
Determinant of you, what else? Take a trace. Take a trace.
Okay. Well, so in terms of the
coefficients of the matrix, it will be like that. Yes, a two, a one, two, a two, one, and here it will be a one, one.
Anything else?
Some polynomials in you and also in the trace.
Yeah, okay, so we can mix up both.
How about this?
Will this be continuous? We associate to a matrix its one, one, one.
It will be a proper continuous function.
In our case, since we showed that this is always, well, if we parameterize this, you
too, by two parameters, a and p, this will be a. Well, also we can think about
associating the two one, two parameter, sorry, two one parameter. We just see, yeah.
And, well, yet another, we can associate to you a to two, for instance, this will be a bar, yes.
So actually, this will be like, if we associate this function and take the adjoint of it.
So let's call this alpha and this gamma. So this will be actually
something like alpha star, sorry, alpha star not bar.
Okay. And, well, we still need to write down the third one.
A one, two, a gradient, this would be like gamma star.
And you see now that determinants, both, both the functions determinant and the trace can be
obtained out of this alpha, gamma, alpha star and gamma star.
So actually, well, there is yet another easy function.
We associate to a metric, it's also a constant.
This function is already written as a determinant, yes, as you too.
Okay. So basically, we have two functions alpha and gamma and all of them possibly taking the
adjoint functions, the conjugate functions, we can construct polynomials and, in fact,
all continuous functions on SU2. But there is a strange, well, there is one thing we should
observe. So of course, if these are complex values functions, they will, they will commute,
alpha, gamma, alpha star and gamma star and so on. But if you compute the product alpha, alpha star,
plus gamma and gamma star on any given metric, what we get is this condition, which is always one.
So these functions will satisfy the conditions that they sum up. And actually,
this is how the algebra of SU2 or functions on SU2 looks like. This is a unital
pistol algebra generated by two generators by the functions alpha and gamma, which commutes,
which is commutative in the sense that everything alpha and gamma also commutes with the adjoints.
And with the property of this condition. So this is how the algebra of functions look like.
It can be also put into a matrix form. Maybe I don't spend time on that.
But let us now see how the multiplication is reflected on the level of alpha.
So let us see what happens with the function alpha if we apply it to a multiplication.
So I'm not going to present you all the computations, you can have a look at them.
But actually, what is happening is that we apply the function alpha to the first
of these two elements. And the same we apply to the second one and we subtract from it
the gamma star applying to the first element and the gamma star applying to the second element.
So this is how alpha will behave under the multiplication.
So in fact, this multiplication map we have on the group
transform the function alpha into a function in two variables by this.
And in general, any continuous function will give us
another function in two variables that will leave on the time to G. And this will be a
star homomorphism. And now the notation delta is just the same.
Excuse me, question. Can we see already here the other border of the river? I mean,
can we see the quantum space and functions on the quantum space already here?
Not yet.
Not yet, okay.
We will see it like two or three slides. So this is still very classical.
I just wanted to show you that really we can see how the multiplication
heard about it at the talk of Algebra today that multiplication induces the operation on the level
of continuous functions, so-called commultiplication. And then I don't want to give too much too
technical, but then if we write down the co-associativity of the multiplication in terms of
functions, then we get this formula, if you saw one, on Thomas' talk, and that is called a
co-associativity convention. So the commultiplication is just a way to see how the function
behaves under the multiplication. And now the existence of the neutral element and the inverse
can also be reflected on the level of algebra. And the standard way is to associate to a function
its value in this particular element, which is the unit of the identity of the book.
So in our case, it will be identity matrix, and the one-one coefficient of the identity
matrix is just one, whereas the two-one coefficient of the identity matrix is zero.
So this is how our co-unit will be defined on the generators, and then you extend this
polynomial in this way. And the same happens with the antipode, looking how the inverse of a
matrix looks like. We can see what is the first index of the inverse matrix, and this will be
should behave. So you've heard already today that such a structure where apart from an
algebra we have commulti-cation, the co-unit, and the antipode is called a hop-algebra, and in
here we also have this involution, and everything is compatible with the involution that is called
a hop-algebra. Okay, so now let us have a look on, well, let us pass the river.
Let's think about more or less the same algebra, but let's make it noncommutative.
How to make something noncommutative? Well, instead, a possibility of the unique one
is to insert some parameter into the commutation relation. So instead of saying that alpha and
gamma commute, we say that they commute absolute color, which is not one. By the way, we assume
here 2, 2, 0, and 1, more general. Okay, so we already, well, in our case, in our classical case,
q was 1, so this, the first three relations would mean that everything, well, the alpha and gamma
commute also would be adjoined. These two relations were basically the same in the classical case,
now since alpha, alpha, it might not be the same, actually, it is not the same as alpha, alpha star.
We need to write down the modulus square in two different ways, so we get two relations,
and we say that our algebra is the universal unit of the algebra generated by two generators.
Now they are abstract, they are no longer functions, but more or less we adopt the same
relations accepted, they are no longer functions. And now we can play a little bit and see how to
modify the definition of the commutation, so that it is a homomorphism, we can extend it.
The same happens for the unit, and it turns out that everything works nicely and we almost are there,
except that when we try to do the same with the antipodes, well, basically we define it
from the generators alpha and gamma, and since antipode is not a star homomorphism,
we have to also give value on the adjoined element.
So I have a quick question, could you justify why we put q precisely in this place?
Well, the justification is hidden here in the spot that I decided to omit.
Yes, yes, but still I can imagine that you also somehow deformed the other
gamma, appearing without a star with some appropriate function of q. Is it reasonable to do so?
Okay, first answer is that that was a smart idea of Voronovich to find this kind of
modification. Not every modification you can imagine will lead to something that makes
sense in the quantum circle, and will happen in the quantum circle. You will see an example in a moment,
but it's not a completely hazardous way. He made this modification in the paper
where this attitude group was defined. Voronovich gave the idea, well, basically,
I think that the idea is that he looks at
some condition that fixes certain eigenvector. Maybe I don't go into details, but there was
an idea in the paper by Voronovich given why he defined it that way.
It turns out that this is more or less the unique way that gives anything sensible.
But it's only part, surely, an answer to his question. Another one is about the
matrix. It's a representation matrix. So if you would pull around with using a different way,
it would not be a representation. Okay, thank you.
Okay, so once we agree that this is a proper way to define our modification,
you may try to define the antipode, and it turns out that on the adjoints of gamma,
this has to be defined as the minus one over two times gamma adjoint, which doesn't seem very
problematic. But if you will think about polynomials, then s on nth power of gamma
will have q to minus nth power. So it will grow because q is smaller than one.
So in fact, what you get is an unbounded operator. There is no way you can extend this
to the theta algebra out of the algebra of polynomial. So this
one to, well, this group structure reflected on the level of the algebra has some problems
when we pass them on commutative case. And that was the brilliant idea of Voronovich,
that maybe we don't bother with co-units and the antipodes. Maybe we use another definition of this.
Well, not the definition, but the result that says that if you are given only a semi-group
with this compact, that satisfies some consolation rule, then this is necessarily a group. So you
can define on such an object or the inverse of the neutral element and the inverse. And that's
basically what Voronovich used to define the reporting group. So as I tried to extend and
also credit you in previous talks, this, let's say, a compact quantum group will be a pair of
c-star, unital c-star algebra together with a co-multiplication that is co-associative.
And such that the analog of consolation, the load,
holds. Perhaps we have no co-algebra structure. Yet, that was proved by Voronovich in the paper
where he first defined compact quantum rules. Any compact quantum group will have the underlying
co-algebra big enough because this underlying co-algebra will be dense in the group.
So we do have this structure reflecting inverses and neutral elements, but not everywhere.
Okay, and now maybe, well, let me go into details about quantum attitude to it.
Well, I repeat my question again. So what is the quantum space? I understand that a is the
algebra. So this virtual object behind the algebra will be called the compact quantum group.
Well, actually, well, we define it as any this virtual space, we can see it only via
algebras. So the algebra with this structure given by delta, we say this is our quantum group.
Okay, so let me again keep running over time much, but let me explain why the c-star algebra setting
is really the proper one because there have been several attempts to define compact quantum
groups. And apart from the fact that it really fits in this classical case. So for commutative
algebras, you really get all the compact quantum groups, the compact groups, the main results
in this area due to Voronovich were the existence of feature via theory of representations of
quantum groups and the existence of the power space. So you've heard about it at the talk
by Nigel Fickstone, whenever you have a group, you can talk about the representations of the group
and the representations can be decomposed into irreducible pieces, which really makes it possible
to work well to describe it. So with the small brick, with which you build the whole theory.
And exactly the same situation happens here. Whenever you have a compact quantum group,
there is enough of irreducible representations to describe all possible representations of the
group. Even though the representation of the group will be something, will be the analog
of the representation of the classical group on the level of algebras. And the existence of the
hard state, this is the statement that there is a unique invariant state on this algebra.
And again, it's analog to be the hard state on the quantum group. And it's exactly as in the
classical case, we have this also the gonality condition. So this hard state, in a sense, defines
this color. Okay, there is yet another way to get compact quantum groups by changing
commutative algebras into non-commutative ones. And I'd like to shortly explain it to you,
but also a source of many examples. So think about permutation. One, two, three goes to two, three,
one, yes. And now it's such permutation, write down as a matrix.
One is tends to one, it's a two, so we will put one on the one two place. So it tends to three,
so we put one in here. And three is tends to one, so we have one like that. This gives us an embedding
of S of the permutation group into the orthogonal group. So in particular, this will be a compact
group. And exactly similarly to the case that I explained to you, continuous functions on such
group will be basically built up of functions that associate to a given sigma, one of its
coefficients of the matrix. Yes, so this will be the PIJ function. And then the classical
algebra of continuous functions on Sn can be defined as the unital commutative system
algebra generated by this n square function. And we can observe that they satisfy a relation
that I wrote here. So the first set of relations means that PIJs are projection, orthogonal
projections. This means that if we think about them as, you know, as a matrix, P11 and so on.
Then projections that are in the same row or column will be orthogonal. And in the same row,
they will sum up to one and in the same column they will sum up. And so now what we can do
is to define the algebra as more or less the same except that we completely
destroy commutativity. So it's not that we replace commutativity by commutativity
afterwards. Color, we just read the regenerators. So there is no longer any further conditions
between them. And one can show, it was Wang who proved it in 1995, that this
algebra can be in doubt with commutification and together they form a compact one.
Okay, let me give more information about this group.
Last example, which is actually a non-example, is the torus. So a torus is a very nice compact group.
Yes, two circles, the product of two circles. And at the level of algebra, we can see, well,
the continuous functions on the torus, we can see are being generated by two unitarus. One is
multiplication along this circle, and the other is multiplication along this circle.
So this will be a compact one. So now let us try to define a non-commutative
analog of such an algebra. Well, the algebra is this algebra of commuting of two unitary,
two commuting unitary. And this is something called rotation algebra. So given any
real parameter, we can think about a piece of algebra with a unit that is generated by
elements u and v. They are unitary, and they commute up to the color which
necessarily is of module as well. And it has been shown not so long ago that this is an algebra
non-commutative algebra, which cannot have the structure of a one. So it's not that any
deformation that we can imagine will lead us to a compact one. Okay, I'm running out of time
a lot, but let me shortly present you an idea related to non-commutative probability. So now
let us recall what the classical probability is. The classical probability is the most
probability space. So we have a set of events, like the basic events, like if we
if we have two dices and we throw them, we can have two numbers, a pair of numbers,
one and six. And then we had a set of all events of possible measurable subsets of omega,
and we can measure probability of each of these events. So we have a probability to measure.
So within this example, a probability will be the same for every pair. Yes, one, one probability,
one over 36, one two has probability, one over 36 and so on. And now we can form a random variable,
which is just a function over this sample space. For instance, think about a sum of the outcome.
Then of course, the sum can take values between two and 12. And of course, not every number is
polyprobable. So associated to any random variable, we have a distribution, which is a measure that
shows us how likely is certain event, a certain result of this random variable.
And also together with any random variable, well, for any random variable, we can compute the
expectation, which is like a mean value of the outcome if we repeat the same experiment again.
And now if we, well, you already seen that random variables are functioned on the space.
So now we can consider a very specific algebra of these functions, namely the algebra of all
essentially bounded functions. And this will be a pistol algebra, actually even something more
and non-convenient algebra, which of course will be commutative because of the functions of p-values.
And on this... Sorry, Anja, could you say again, please, what is the sample space in this particular
case of throwing a dice? Yes, just first, like 1, 1, 1, 2, 2, 1, 1, 2, and so on, up to 6, 2.
Yes, so this is our omega. So then what is F? F, all subspaces. All subspaces. Yes.
So these are like elementary events, and F will be all events for students.
Okay, so on our algebra, we can define a functional, actually we already have it,
the expectation associated to any random variable, a number, a function about a value of function,
so we just linear, we just normalize it to a constant function 1, if you apply number 1.
And one can show that it is positive and also normal as a function of a non-convenient algebra,
which basically means some version of continuity. Okay, so now we made the first step in our idea
of a girl's fund that we managed to translate the properties of the
base-inclusive properties of the algebra of functions on it, and indeed we can go the other
way around. Maybe there is a theorem saying that any commutative for name an algebra with
such a linear unit of positive function now, which is called a state, will be isomorphic to some
algebra of functions on the probability. Or just a quick comment, unlike this girl's
fund, I mark theorem, this construction is not functional. Yes, so that's another proof yet.
Yes, and also that will not be a function. Anyway, we can now subtract the idea that
it stands behind this algebra function and this axioms we need to specify the structure,
and it seems that the proper way to see the non-commutative counterpart of probability
states is to consider von Neumann algebra A and this normal state phi, which is the analog of the
expectation. But now this allows, well, this more general framework allows us to consider more
examples, so the classical one is of course in there, but also if you consider, think about
all matrices, then trace, the normalized trace is a state, or a state, and this will give us an
example of a non-commutative probability state. Also, whenever you have a Hilbert space and a
algebra of bounded operators on it, and if you choose a unit vector, you can define the so-called
vector state by this formula, and this will form a non-commutative probability state. Actually,
I'm not going to talk about it, but maybe I mentioned, if you mix up these two examples,
you've got a proper framework to consider random matrices. So you see that this non-commutative
probability space is a kind of good notion to think about. Okay, so now we have the space,
we have the structure, and the next step is to see the related objects and their analogs on the
one side of the loop. Okay, so the very basic element is the random variable, so by non-commutative
random variable, we will mean an element in this non-commutative probability space, but we will
require it to be a self-adjoint. This is like often if a problem happens with the random variables,
we want them to be real. And with such a random, with such a self-adjoint element,
we can associate a distribution. So since we are in the c-star algebra case, this
the element a will be, can be represented as a bounded operator, and so the the measure
associated to the element a via impact vector theorem will be bounded, will be a compactly
supported measure. So to see an example, if you take the strange non-commutative space of matrices
with the trace, and you take such a nice self-adjoint element of the identity matrix, then you can see
that the distribution of such an element will be just the derogatory element. Sorry, this measure
is not uniquely defined. So once you have bounded elements, the moments, the moments will be bounded,
I mean mk will be bounded by r to, some r to power k, and you will, you can show that the
measure will be compactly supported, and then it is unique. Oh, okay, okay. Yeah, there are some
more general, well, you can generalize it to get also not compact, non-compactly supported
measures, but let's say another story. Okay, so now the main notion in the probability theory is the
independence. Classically, two random variables are independent if they are joined distribution
of the product of the distribution of the random variable. Here it would be kind of, well,
it would, I think there is no, it's not that there is no
notion of joint distribution. There is one, but let me not go through this way, but let us
think, look at the classically independent random variable in a slightly different way.
So for such a variable, you can see that the expectation has been taken very nicely,
yes, under the product. And in particular, this means that if you take the sum of such
independent random variables, you can compute their moments, the moments of this x plus y
out of the moments of x and the moments of y. So independence gives us a rule to compute
the moments of the sum. And this is basically the idea that's were taken from the classical
probability to the non-commutative one. So roughly speaking, by independence, we mean something that
follows us to compute the moments of the sum once we know the moment of the
respective element. And Daniele Kulesko in 1980 suggested this kind of independent,
which he called free independent. So that's again a rule, well, let's say the definition is not
that clear. So we say that two elements are free independent. If whenever you take an element in
the algebra generated by A, so think about polynomial close in some norm and elements
which are kind of, well, let's say, stick to polynomials in B, then whenever they are centered,
so they vanish under the expectation, we have this rule. So that's quite a mysterious,
but to see that this really allows to compute the moments of the sum, you can observe how to
compute just the moments of product, like pi over A times B. So A might not be centered,
but always this element, so A shifted by its value on the expectation, will be
centered. So pi on this will be zero. So the product of two such terms should be zero. And now
if we multiply them and apply a linearity of pi, we get the rule that pi of A times B will be the
product of pi. That's exactly the same as in the classical case, but if you go to pi or dimensional
moments, like you multiply four such terms, then you see that the effect will be different.
So this really, this definition which seems quite tough at the very first
at first, we really can serve to compute moments of the sum and also all mixed moments.
And now we can, well, this will make the long story short, you can try to see what happens
with the limit theorem. So for the classical case, let me recall that if the random variables are
independent, then the normalized sum will attend to the normal distribution. So in our non-commutative
case, what it means that some random variable tends to some measure, in here we mean that the moment,
that the moment of this random variable behaves, well, has some limits. And if we assume that the
random variables are really independent, then again, well, we have two options, but one of the
options is to do the combinatorics. So we multiply all terms and we see how many they are and so on.
And it turns out that the moments of this y and are like that. Definitely these are not
the moments of the normal load. Do you know what are these numbers? We recognize them.
Anya, sorry about this. This is that formula is false. I should have different n, capital n and small n.
Oh, you're right. Thank you. So this formula is false. Yes, yes, yes. Okay, let me, thank you, Marek.
Yeah. Oh, and capital n tends to infinity. Yes, yes. Okay, now it's okay. Yes, thank you. Thank you.
Okay, these are Catalan numbers. And this is only for even numbers and not for odd.
Yes, thank you. Zero for odd, yes. Zero for odd, yes, exactly odd. Okay, okay. I made so much,
so many mistakes in here. Okay, so the moments you find are the odd, the even moments are the
Catalan numbers. And you can check that these are exactly the moments of the Wigner measure that
you see when I was presenting the random matrix. So that was kind of, well, that was very surprising
when a very close school showed the theorem and realized that this measure has already appeared
in random matrix theory. But that's what happened. Okay, I see that I'm running out of time.
So let me just pass over shortly speaking there together with the addition of random variables,
independent random variables, which have associated convolution of measures. And
there is a free analog of the convolution of measure, which I'm not able to talk about.
Then I have to skip geometry part, but the general message is that we still can apply this idea to
parts from space. In the geometric case, it will be a manifold to the algebra of functions from the
manifold and then to non-commutative situation. And first, I want to end it to you. And just to
let you know that they are interesting things happen in these two domains, which are more like
my field of expertise. So once you have compact quantum groups, of course, you can study the
representation theory that I flashed to you. But you can also study different kinds of properties
that you know from group theories, like from an ability for instance, but also you can study the
algebra, the operator algebra goes together with this compact quantum groups. Also, quantum groups
can act on different kinds of mathematical structures like graphs. So there's a vivid area
of research concerning quantum symmetries of graphs. People are also interested in studying
quantum subgroups. So there is an open problem for instance, what are quantum subgroups of
prepermutation group? Not all of them are known. Well, okay. And concerning in non-commutative
probability, the notion of three independence that I have shortly showed you, it's not the
unique one you can have. Actually, there are many, well, in the classical case, we have just one
notion of independence, but in the non-commutative case, you have, I would think, plenty of them.
So there was a result showing that there are five total universal
independences, three Boolean classical monotone and non-ton one, but then out of them you can
build much more. And so with any such different, such independence, you can build up your own
theory. And then you can study transformations or analogues of Fourier transformations,
as well as appropriate for each particular independence and also infinite divisibility. So
all this is really a vivid area of research. But the message to take away is that we can
do this kind of, we can apply this Gelfand's idea to pass from the set to study functions on
summit. And then instead of having this algebra of functions commutative, we can
study the non-commutative counterpart, which will lead us to non-commutative
virtual object having analogous structure. I didn't want to put you too many references,
but if you would like to know more about it, then I would recommend you to read the origin
of Ronovic papers in quantum books. They are really nice written, but otherwise I strongly
recommend any overview papers by Moritz Weber. Of course, there are plenty other
persons, but this is the person that has really nice introductory papers, and in particular,
quantum symmetry, an upshot from Oberwolfer is a popular, kind of popular paper to start with.
And as for non-commutative, as for free probability, I would recommend any materials
prepared by Ronan Speicher. So you have to book, well, at least to book, many notes in the internet
and also some videos. So this is also a person to learn from. Okay, I think I stop now. I'm
a little minute to time for that. Thank you. There is one more.
Okay, don't be sorry. I think you started a little bit later. Okay, let's thank the speaker.
Well, any questions or comments?
May I ask? In the topic of non-commutative probability, you mentioned random matrices,
and especially symmetric ones. So can you tell if there are some other natural examples that are not?
Because oftentimes appear, especially the work of Manchin-Druller Speicher, the classical matrices
like symmetric ones or unitary or orthogonal, but other places in mathematics where non-commutative
probability. Okay, there is a famous thing that I can just cite, but without giving any details,
it seems like, well, this free setting. Okay, maybe I understood you wrong. You would like to
see where free probability can be applied outside of random matrices. Yes, yes. It is
natural to consider it. So, free probability grew up from Viglescu's trial to deal with the
problem of free groups. So, the problem is that once you have free groups with say,
n-generator and another one with n-generator, and you consider a von Neumann algebra generated by
them, are they the same or different? So, I think that this is still an open problem. You cannot
show that whenever you have two such von Neumann algebras, and they are with two different numbers,
they are. So, this is the famous problem. Viglescu's construction of free probability came
exactly from free groups. So, this is one place where... This problem is very easy when you replace
von Neumann algebras by cistern. So, cistern algebras is false, but not for von Neumann algebras. So,
this is one thing that comes to my mind.
Well, there is a... Maybe I will use my slide. There is a result in non-commutative probability
in free probability linking quantum groups with this kind of non-commutative probability.
So, classically, if you have independent random variables, which have the same distribution,
they will be invariant under permuting elements. And this shows that you have a reciprocal
implication. So, whenever you have invariant under finite permutations variable,
they must be conditionally independent. And it has been shown by Kessler and Speicher that
a similar situation happens for free probability, but here you have the independence with respect to
quantum permutations. So, the elements for f and plus. So, now, if you think... Well, if you ask
yourself what are random variables that you can have that are independent invariant under
this action of f and plus, then you find this free independent. So, that I would say... Of course,
it's not the way it was found, yes, but this is also a kind of result, which somehow pops up here.
Just to briefly continue this line of inquiry, you started from quantum mechanics. So,
Woodward is not going to probably have any meaning application, interpretation, physics,
quantum mechanics, whatever. Preprobability in physics. I haven't... I haven't heard about...
I think that there is one. So, there is this at least two versions of Fox Space, Bosonic one,
and Fermionic, but there is also a free version. And somehow, if you investigate this Fox Space
and consider some algebras related to this creation and annihilation operator corresponding to this
free Fox Space without any symmetrization or anti-symmetrization, you rediscover this from
my ma algebra of a free group. That's true, but do you mean that free Fox Space has any physical
meaning? I don't know. I'm agnostic in this, yes, but... So, they are also... Well, there are many
constructions of Fox Space, including something like anionic, which has fancy names, but I'm not
entirely sure that they have anything to do with real physics. Yeah, so demanding some connections
with real physics is more than some connection with physics, just some vague connection.
Okay, any other questions or comments or from people on Zoom?
Marek, Marek, you're coming. Hello. Maybe now. If I can say something. Yes, please. Because...
So, I thank to Anya for such a beautiful talk, for nice introduction and a lot of examples
and connection with probability, and maybe only... I would like to say that Catalan number was also
discovered in Wroclaw, 75, so at least five years before Wojculesku. Wait, wait, that should be
because Silesian number. And the central limit also I discovered, this is paper, my paper in
Proceeding American Mathematical Society, 75. Anyway, so... But coming to that question was
related about commutation relation with Roland Speicher, series of paper about... So,
Q-canonical commutation relation, which comes really from Voronowicz, what Anya
expended quantum group, SUQ, and a lot of nice result. And the main things is the
central limit measure is theta function of Jacobi, what professor, I don't know who
works from Poznan, said to us. So, theta function is just... And Wigner law is very special case.
This is Q equal zero, but the most important is Q equal one, where is the classical normal law,
and Q equal minus one is fermionic law, so this is corresponding to anti-commuting relation.
So, and that business is... So, I am happy that Anya now gives so nice propaganda, and welcome to
Wroclaw, when it's a lot of lectures, and I hope Anya will be also such a lecture about that,
because in one hour it's difficult to say such a beautiful... So, thanks, Anya, once more, and
also I wish you nice ideas on your school. Thank you, Marek. Okay, just one remark related to
this question was previously asked by you, Eva. So, usually it happens that the non-commutative
space is something which exists virtually as some sort of non-existent object which manifests
itself through this non-commutative algebra, but still there are some instances where you,
for example, take some set, for example topological space, and the group is acting on this topological
space, and this action is not nice, meaning that the quotient orbit space is no longer
housed on space. So, okay, you can consider continuous function on such space, but usually
what you get is a trivial algebra, one-dimensional, so continuous function on some sort of this
pathological spaces does not give you any information about the space. So, the better
way to do this is to consider the so-called cross-product, and it always does make sense.
It leads to non-commutative algebra, and in this situation where this action is, in fact,
nice, such that the quotient space, orbit space, is housed there, these two algebras,
the cross-product and this function on the quotient space, are more retic-equivalent,
so this is not, in some sense, not an empty identification.
So, and with this bad space, you also have c-star algebra, yes?
Yeah, this cross-product.
Okay, it's great. Okay.
Okay, good.
That's autonomous-to-vici-stud-evaluation.
Okay, very good, very good.
That's transversal geometry.
I have a technical question. Could you please go to your first slide?
Maybe second, but maybe first. Well, not the title page. Okay, second slide.
Yeah, yeah. Not this one, earlier.
Okay, yeah.
This one.
Exactly, yes. So, what's wrong with your formula for the norm?
For the norm.
Yeah.
I should add modulus, modulus.
Modulus, of course.
Of course.
Yes, thank you.
Yeah, I'm not going to be.
Something else?
Well,
yeah, it's not the operator norm.
Ah, sure.
Oh, yes.
Thank you.
So, yeah, that's just the matrix norm.
Yeah, on square root, yes.
Yeah, that norm is much better, yes.
Sorry.
Yeah, sure.
Thank you.
It was, it was his question.
Then I need to correct the slide.
Oh, there's also spelling mistake in original.
Original papers borrow knowledge, different spelling.
Okay, so let's thank the speaker again.
