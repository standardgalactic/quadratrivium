Yeah, okay, the floor is yours.
Good, so good afternoon, everybody.
I was asked to introduce today's speaker,
Professor Emil Proudhon from Yeshiva University
in New York City.
And following this request is much of a pleasure for me
because he is a pioneer and a renowned world expert
on topological materials, including metamaterials,
which I guess is why we invited him
for this special anniversary lecture today.
The title of which is going to be
Applications of K-Theory in Materials Science.
But allow me to say a couple of words about his vita
before we let him speak.
Professor Proudhon received his bachelor and master's degrees
in theoretical and mathematical physics
from the University of Bucharest.
He received another master's degree in theoretical physics
from the University of Houston,
and he then graduated with a PhD in theoretical physics
from Rice University, where Peter Nordlander
was his advisor.
Emil Proudhon received further post-doctoral training
at the University of California at Santa Barbara,
working with Nobel laureate Walter Kohn.
Thereafter, he was a fellow of the Princeton Center
for Complex Materials at Princeton University,
where he worked with Roberto Karr and Duncan Haldane.
Dr. Proudhon joined the physics department
of Yeshiva University in 2007,
where he is a full professor of physics today.
Emil received several awards and honors,
of which I mentioned two in chronological order.
In 2011, he received the NSF Career Award
for his proposal, Strong Disorder and Electron Interaction
Effects in Topological Insulators.
And in 2016, he was among the recipients
of the Keck Foundation Research Awards
for the Collaborative Project Engineering,
new materials based on topological phonon edge modes.
So Emil, the stage is all yours, please.
Thank you, thank you very much for the kind introduction.
You already heard the title of my talk,
and it, well, it's a little bit unusual actually to,
it's a little bit unusual actually to,
okay, to have the concluding talk
for a very successful year of Metamart seminars,
which actually contain this word, K-theory.
And the subject of the talk actually was suggested
by the organizers.
And I'm so pleased that, okay, there is interest
in these techniques.
And they are not my techniques.
So here, perhaps I'm celebrating the work
of many other people from which I learn,
and they are my heroes.
And now I am so pleased that this idea
slowly penetrating in materials, in metamaterials.
And if I have to say, they are not conceptually
not difficult at all.
And the flavor of all these calculations or analysis,
it's very much like when you learn integration
by residue theorem.
So you have to make a jump.
You calculate things a little bit different,
but then there is so much reward after you learn
the new technique.
So let's see, my next slide will be setting the stage.
And in my previous talks, I always started
with very complicated systems, so I can impress audience.
Well, that was a mistake.
And this time I will do a little bit different,
and I'll start with periodic systems
because we all understand what's going on here.
So I have in this picture,
a set of identical discrete resonators.
They carry an internal space of internal degrees of freedom,
where some internal dynamics already happen.
And now if I put this identical resonators
in a homogeneous medium,
then this internal degrees of freedom will couple.
And here, I always like to say,
let's take out any human interventions
and let these resonators couple as they want,
once placed in a homogeneous medium.
Well, in that case, if the homogeneous medium,
then you see here I wrote the dynamical matrix.
And since the system is periodic in the dimensions,
I can label each resonator by D integers,
therefore an element of this Z to power D.
And the dynamical matrix looks as shown here,
and due to Galilean invariance,
the coupling matrix is the plan only on the relative index.
So this N minus M.
So let me explain a little bit more of this formula.
So N and M are two sides, like this side and this side.
And W is a matrix,
which tells me how, for example,
this resonant mode couples with this resonant mode,
or how this resonant mode is coupled to this resonant mode.
It is some people, okay, when they see this tensor product,
they say, oh, I complicate things,
but in fact, it's a very efficient way to encode
how two resonators, one located here
and maybe one located here, couple to each other.
So all I need to specify is this matrix,
and now Galilean invariance assures me
that this coupling matrix only depends
on the relative index.
It's important because I'm not imposing this fact,
but rather it follows from my setting,
the fact that I took out any human interventions.
So of course, if we engineer this coupling by hand,
then this might not be true
because we might choose to make a coupling stronger,
another or weaker, and all of that is within our means.
So we can easily break Galilean invariance.
We can also break Galilean invariance
if they are external fields
or if this layer of resonators sits on top of a substrate.
So all of that needs to be,
will be denied throughout this time.
Okay, so we have this dynamical matrix.
This n will be led to be arbitrary.
So you'll see in the next slide,
M infinity instead of Mn,
which means matrices of arbitrary order,
they can be, and this n can be 100, 200.
And, well, this expression here is still not simple,
even though we talk about periodic system.
But there is a new state of mind,
which it's very important
when you apply the techniques I will describe.
For example, if you ask a first year graduate student
to diagonalize this operator,
it will not be easy if the student hasn't seen such a matrix
will have difficulties.
However, if you use the shift operators,
what the shift operators acting on site n creates n plus Ej,
so we are moving in the j direction when we apply SJ.
We see that the dynamical matrix actually simplify
to this expression and you have to agree
that this is much simpler than what we have here.
The upshot here is that if you diagonalize the shift operators,
then you are already in good shape
for diagonalizing D itself.
The shift operators, we know how to diagonalize.
But at the end of the day,
the conclusion is that any dynamical matrix
of any periodic array of resonators fall
into this algebra.
What do we have here?
So we have this coupling matrix,
which comes from this M infinity tensor
with the algebra generated by D shift operators.
And it turns out that this algebra
is actually the group C star algebra
of the abelian group Z to the power D.
And if you follow what I said,
what is that we take any human intervention,
the coupling is through a homogeneous medium,
there is no escape to this conclusion.
Always any dynamical matrix will fall into this algebra.
And this will be a common theme during this talk.
Dynamical matrices,
no matter how the couplings are generated,
as long as the physics is Galilean invariance,
they all fall into well-defined topological algebras,
which can be computed.
So for a person who studies operators algebra,
just this statement here opens up
actually trivialize the whole thing.
And in fact, that's the point.
The point is, okay, you are sitting drinking a coffee
in the morning and you want to communicate
huge amounts of information.
So we will be talking about this class of metamaterials
and the other person asked me,
well, what is the algebra of dynamical matrices?
And then I say, well, the algebra is just this
and I give a name.
And if the person has a background in operator algebra,
he immediately opens, I mean,
he knows a lot about that algebra
and basically by communicating this information,
if he's a specialist in operator algebra,
he will know more than I know
about the dynamics of these systems and so on.
So that's the point.
Now, what can be inside this algebra?
Here are a set of Hamiltonians
and here we have a name which is generating
topological models.
So we have this J which is a subset of indices
taken from the indices that indicate a direction.
We are in dimension D, so we have the directions.
And then we form this very particular Hamiltonian
which involves the shift operator
and tensor products with the Cliford algebras
and these Cliford algebras are tailored
to this set of indices.
And now if we try to see what happens,
all these Hamiltonians have a spectrum
which looks like two bands and the gap.
The gap will be closed at the specific values of M,
but we can take Hamiltonians
which for which the gaps are open
and we can take different J's and different M's
and what we will find is that if we try to interpolate
continuously between two models,
let's say a linear interpolation between the two,
closing of the gap is unavoidable.
So it means these models are topologically different
or distinct because we cannot connect one to another
without closing the spectral gap.
The question now is did we miss
any generating topological models?
Is this all there is inside this algebra?
So we'll see that K theory answers very nicely this question.
Now, when you say unavoidable gap closing,
it's a really strong statement.
So always when we say unavoidable,
it's really, really a strong statement.
So how can that be?
Well, it is true this unavoided gap closings happens
only if the deformation take place
inside this topological algebra.
If you break the translation symmetry,
then you can avoid this gap closing.
So this is something one has to keep in mind.
And in fact, when the classification table
of topological insulators was put forward,
this information was missing.
What are the allowed deformations of the models
and it took some time to understand what are the models
and what is the space in which you are allowed
to deform the model.
Now, what happens here?
Each band carries a topological number,
a topological numbers and there are many of them.
So let's say in the dimensions,
we have a the dimension below in torus.
And here it's an example of a 3D Brillouin torus.
Okay, it's unfolded, but the faces are equivalent.
So this face should be glued to the bottom face and so on.
And for this 3D Brillouin torus, we will take sections
and they are three even dimensional section.
These are two dimensional section.
And for each this section, we can generate a chair number.
So chair numbers exist for any even dimension
and they have this formula here.
It involves some permutations of the indices,
derivatives of the band projection.
So the band projection is okay, form as usual
and we have a formula in the momentum space
and we also have a formula in the physical space.
And of course I like this formula in the physical space
because we don't need really the momentum.
After all, chair numbers are related
to transport coefficients, linear and non-linear.
And they should be a system which is periodic or not
should have well-defined response functions.
Therefore this response function should be,
could be written in real space and here they are.
So then taking even dimensional sections of the D torus,
we can find lower a number of chair numbers.
And the conclusion will be that a band carries
two to the power D minus one topological invariance.
At least, but did we miss any,
are these all there is for these systems?
So that's the big question.
And well, you have to admit that even for this simple algebra,
you will say, but how can we answer this question?
They are so, I mean, we can cook
so many other topological invariance.
How can you be so sure how many independent topological
invariance are there?
Good, so I'm moving to the second part,
the K-theoretic group defined.
And before the first thing we need to define
is the notion of complete invariant.
The notion of complete invariant involves this
if and only if statement.
So I'll get to this at the end of this slide.
And I took a very familiar setting.
So we have the plane, it's punctured.
Here it has one puncture.
Here it has three punctures.
And I am looking at curves, which are continuous
and now we can deform this curves without breaking them
or without passing over the puncture.
And now we see here this curve
which can be contracted to a point and make it disappear.
I see the blue curve encircling the point once
and then I see the red curve and the orange curve,
both encircling the point twice.
Here it's more complicated.
We can have so many other options.
But the point is even my daughter,
when she was six years old,
could tell which curves can be deformed into each other
without actually having any notion of a winding number.
And in fact, really to define an invariant for a curve
like this, we don't need any number.
We can define it like so.
The invariant associated with the curve gamma
is really the set of all gammas
that can be deformed into the original gamma.
This is not a numerical invariant,
but it is a topological invariant.
Why?
Because the set gamma does not change
upon continuous deformations of gamma
because that's how it was defined.
But that's, it's a topological.
Now, even more, if we got two gammas somewhere in the plane,
they can be deformed one into another
if and only if these sets coincide.
Therefore, this if and only if is the attribute.
We need to be a complete invariant.
So here we have it in this setting.
Of course, now we will,
the task will be to calculate all these topological invariants
and classify these curves.
We will do exactly the same thing for band projections.
So for periodic resonators,
we have band projections living inside this.
It's a topological algebra.
Therefore, it's a topological space.
We have a topology and we know
how to deform this one continuously.
So when you talk the formation, continuous deformation,
you have to ask what is the topological space
and what is the topology that underlines
this continuous work.
So then as it does in the familiar setting of curves,
we declare that two band projections are equivalent.
If there is a family of projections,
all living in the allowed algebra of dynamical matrices
such that when this S parameter is zero, we are at 10.
So we recover the first band projection
and when S is equal one,
we recover the B prime band projections.
So this is just a homotopy equivalent with the caveat
that in fact, we still have this
algebra of arbitrary matrices.
And I should note here that the formations
inside this algebra allows turning on or off
new and old degrees of freedom.
So in other words, when we do these deformations,
we can activate new degrees of freedom
which we either ignore in the previous models
or for example, we can couple to external structures.
And because of this fact,
which is actually very physical,
if you don't allow this turn on and off
of the degrees of freedom,
you are not reflecting the reality.
The reality is we always work with effective models,
therefore neglecting, for example,
high frequency degrees of freedom.
But when we do these deformations,
we need to put these degrees of freedom back
and allow these deformations to engage
these degrees of freedom.
And anyway, this is why we have this stable homotopy
rather than just plain homotopy.
And then we have the equivalent class
of a band projection represents
the complete topological invariant of a projection.
So now, if we are able to calculate
these equivalent classes, we can be sure
we will not miss any topological band.
They are this homotopy or stable homotopy,
in fact, is the same as two other equivalent relations.
There is this one here,
which says that two band projections are equivalent
if there is a unitary operator
or unitary element from this algebra,
such that PB prime is PB conjugated
with this unitary operator.
Or if there is a partial iso,
if there are two partial isometries,
PB prime, such that when you multiply PB prime,
you get PB, and when you multiply V prime B,
and it turns out this equivalent relation implies this one,
this one implies this one,
and this one implies this one.
Therefore, they are all the same
and they can be used,
all three of them in different situations
to produce useful statements.
For example, if you have a map,
so here is this map CHI,
for which you can exchange if you apply this CHI
on a product AB, and then you get the same result
if you apply it on BA, then certainly CHI on P,
it's equal to CHI applied on P prime.
Therefore, immediately this kind of maps
produce topological invariance on projections,
on band projections.
Of course, this CHI when applied on PB
or when applied on PB prime is the same.
Why?
Because you can move this operator,
you can move it on this side,
then you have your prime U, which becomes identity,
and this is why the CHI applied on PB
will be the same as CHI applied on PB prime.
In particular, any trace will actually supply
the topological invariant for the band projections.
So far, we talk about equivalent classes,
but there is additional structure on it,
which is very important.
If I have a projection from this algebra,
so somehow this P is generated from a model
with n degrees of freedom,
and this P prime is generated from a model
with m degrees of freedom,
then I can generate a projection
which comes from a model with n plus m degrees of freedom.
Well, what do I do?
I just sandwich this or stack on top,
stack the two models,
and I'll generate a projection which is just like so.
So then the set of equivalent classes together
with this quite trivial operation
becomes an abelian group called the K group of the algebra.
And I always have this question,
for example, from my students,
why do we complicate with all these structures?
Well, if you calculate,
now we have an abelian group,
and if we calculate the generators of these group,
usually they are finite,
there is a finite number of them.
Here in this, it's P1, P2, all the way to PK,
therefore they are these capital K generators,
then any element or any projection,
rather set the equivalent class of any projection
accept this kind of expansion,
and here we have N1 of P1,
N2 of P2 and NK of PK,
so we will write this in short, like so.
So then it turns out that the set of integers N1, N2, NK,
represent the complete set of the logical invariance
of a projection.
Why? Because as long as you move this P,
you deform it continuously,
it cannot escape from its equivalent class,
but then its equivalent class is just this,
so clearly we cannot change these numbers.
So if we want to go from abstract topological invariance,
which were just these classes to numerical invariance,
all we have to do is to calculate this
integer numbers here,
therefore the decomposition of the projection
in terms of the generators of the group.
I should say that these generators are not unique,
so when you do the calculation of the K group,
you have to also specify a very particular set of projections,
and that's why topological invariance
are actually need to be linearly independent,
and you can form linear combinations of them,
and you will get new topological invariance,
but that it's almost like changing the base
for your abelian group.
So now we go back to periodic arrays,
and one does a calculation,
finds that the K theory of this c-star algebra
of dynamical matrices takes this form,
it's z to the power two to the power d-bar minus one,
where d-bar is equal to dimension if it's even,
and d-bar is d-minus one otherwise,
and then if we recall this generating models
from my previous slide,
you will see that how many,
this j was a subset of indices,
how many of them can we generate?
If the cardinal of this set is even,
well, there is exactly this many subsets,
and now we can be absolutely sure
that all topological bands can be produced
from the above models,
and there is nothing in this algebra
above this topological models.
So it's important,
at the beginning of this boom
in topological insulators,
people were very excited.
They produce models with churn number three, churn number six.
Well, they are just stacks of topological model
with churn number one.
So you just stack six of them,
and you get a topological model with churn number six,
and you can be sure that the model,
which perhaps was found in a very complicated lattice,
can be continuously deformed
until this stack of, trivial stack of six models
with churn number one.
So if you know this information,
then you basically are done.
There is nothing new to be said
about this class of metamaterials.
So for periodic ones,
this is all you could find,
even though the coupling matrices can be any N by N matrix
with N 100 or 200,
there is nothing else in here.
So now I will be talking about
a more interesting class of resonators,
which is the class of quasi-periodic.
Let me start with two examples.
I have a pattern,
and I'm generating with, in a dynamical fashion,
which involves a circle
and stepping on the circle by a theta.
I start with, from this point,
and I project on this horizontal axis,
and I got my first point, x zero.
I move on the circle by a theta,
and I project down,
I move by a two theta, I project down,
and I can also go to the left
by moving by a minus theta.
At the end of the day, I get a set of points
and I can put a resonator,
let's say with a single mode resonator,
and I assume in that they couple via evanescent tails,
so the coupling Hamiltonian,
what should be, should be a hopping between x and y side
and a coupling strength,
which decays exponentially
with the distance between the sides.
And this type of Hamiltonian,
actually I can evaluate it on any lattice,
and it will be my model Hamiltonian.
For example, this Hamiltonian has been evaluated here
for this pattern or for this pattern of red points,
and then here we see the spectrum.
Here we recognize the Hofstadter spectrum very nicely.
Here, somehow it's the same fractal structure,
but can we be sure that here
we actually are we seeing the same thing,
except maybe here we are using a bed lens,
and all this actually is the form in something else,
but other than that, this is the same as this.
And I wanna intrigue you
because this pattern was generated by what?
I just simply deformed this circle into a loop like this,
but other than that, everything is the same as here.
I use the same algorithm.
I am moving on the circle by a theta,
and I'm not doing any projection anymore,
and this is kind of a weird pattern that one generates,
yet if you calculate the integrated density of states,
you will see that the integrated density of states
corresponding to this spectrum or to this spectrum,
they are the same, they look this way.
So what is the integrated density of states?
It's evaluated at a certain energy.
Now here I have theta is the same theta here,
the same theta here,
and if I choose a theta,
then I will pick an energy, say here,
I will count all the eigenvalues below that energy,
so number of eigenvalues below E,
and I divide by dimension of the Hilbert space.
Therefore, I will get a table with three columns.
So I should be talking about the three-dimensional plot,
and this is what we see here.
It's a three-dimensional plot
where the third dimension is encoded in the color,
and this, therefore, energy is encoded in the color,
and every time we see such a drastic change in color,
it means we have a three-dimensional plot.
The graph, actually, in three-dimension,
jumps straight at us,
and in fact, we are going through a gap.
Clearly, the integrated density of states doesn't change
as we change this E inside the gap,
so the IDS stays the same, stay the same, stay the same,
so the graph really, if we imagine how it will look in 3D,
it comes straight to us.
Therefore, any such change, abrupt change in color,
in fact, indicates that we cross a gap,
and we can detect which gaps are.
So this line corresponds to this big gap.
This finer line corresponds to this gap.
Then we have some lines here.
This line corresponds to this gap.
This line corresponds to the other gap.
There are finer lines here.
Well, so this is IDS,
and we see that they are the same.
It's quite amazing that this ugly-looking patterns
produces the same IDS,
so there must be something fundamental behind this,
so here is a hint of what is going on.
When the energy belongs to a spectral gap,
and only then, then PE belongs to the algebra
of dynamical matrices, this to be computed later.
And the next observation is that the integrated density
of states computed or defined
in terms of the eigenvalue, counting eigenvalues,
in fact, is the same as taking the trace
of the spectral projection
and normalizing by the dimension of the lattice,
okay, the size of the number of points in the lattice,
and here one has to take the thermodynamic limit,
which I omitted.
Now, here I have a trace,
but trace, we know that inside the trace,
if I have operators inside the trace,
I can exchange the order
and if you remember my previous observation,
then this actually, it's easy to understand
why the integrated density of states
is in fact a topological invariant.
It's constant on the stable homotopy class
of the gap projection PG.
The conclusion is that when we calculate
the integrated density of states,
we actually see an image or a representation
of the K naught group.
How?
You simply, it's a map,
which takes value on the equivalent classes
from the K naught group.
And for example, here the class of this gap projection,
you simply take the trace of PG
and you normalize here by the number of points in the lattice
and I also put the number of internal degrees of freedom.
So what must happen is that the two patterns
belong, the two patterns of,
the algebra of dynamical matrices
for the two patterns are identical
and therefore the same can be said about the K groups.
And this is why this graph
of the integrated density of states
are the same.
So if that's the case, then we can be sure,
for example, that this gap projection here
can be continuously deformed into this one
without closing the gap and so on.
So in other words, I can deform this pattern
into this linear pattern
and I can keep this gap open
and eventually we would land into this one.
And same for many of these.
So some of this at here,
we have this gap will land over here
and how wonderful this conclusion is.
I remember when I made the jump in my early postdoctoral year,
I made the jump from periodic to aperiodic structures
and I was simply powerless because
I felt that there are no tools
to look at this aperiodic structures
and the only thing you could do
is to go with brute force calculations
and numerical calculations
and that's all there it is.
While here we have this so easy breezy conclusion
that this, we are looking at the same Hofstadter spectrum
and we can be sure that we can connect these gaps
one with another, all this on this quite complicated structure.
Let me briefly go about more examples.
So here is a incommensurate bilayer
and if you modify this,
so if you scale this one to be two pi
and the distance between the points,
so these are all periodic but they have different periodicities
and if you plot the spectrum of the same Hamiltonian
as a function of theta, you arrive to this spectrum.
If you calculate the integrated density of states,
then you start to see these very specific lines,
question what we are looking here
but we will see that it's the same Hofstadter spectrum
just before through a specific lens.
Patterns in two dimensions, as you can see,
they look drastically different.
They all produce fractal-ish, Hofstadter fractal-ish spectrum,
same Hamiltonian, I mean same dynamical matrix
but just evaluated on different patterns
and when we calculate the integrated density of states,
they resemble, in fact, these two are exactly the same.
This one is a little bit different
but at the end of the day,
I will show you how we can fit all these curves
with a very generic prediction.
Here are the twisted by-layer
and so we have degrees of freedom which are on this layer.
Think of masses and springs,
the masses can go only in the z direction
and below we have a potential
and this potential is also when a line can be aligned
and then it's two perfect lattices
sitting on top of each other as shown here in panel B
but then we can rotate the potential,
the plane of the potential
and then we have a twisted incommensurate lattice
and it looks like here,
there is no repeating cell or anything.
Well, you compute the spectrum
and the spectrum again show as a function
of the twist angle
and the spectrum reveals again a Hofstadter like picture.
You calculate the integrated density of states
and you see these verifying curves
which certainly are not random
and you will see that we have a prediction for this.
Just to know everybody now,
especially those who don't know me,
in fact, producing topological metamaterials
by this patterning is the simplest thing you could do.
Here, for example, we have magnetic spinners
and all it takes is to change the distance
between the magnets by a certain algorithm.
For example, the one with a circle
and here you take this tube is empty inside
and you pattern the walls again with an algorithm
and you will find that you can generate
interface modes and Hofstadter spectrum.
Here we can nicely,
we can have discrete acoustic resonators
and simply we can change the length of the resonators
which dictates the onsite frequencies.
Here is an acoustic resonator
which involves an incommensurate bilayer,
a two-dimensional pattern.
So these resonators here are coupled to a thin layer,
same here.
So therefore here we cannot engineer,
we don't have much control over the coupling
but just because they come like so,
we know for sure what is the algebra of dynamical matrices
and here is another example,
very much in the same class as this one
where we achieve topological wave steering
in Guo Liang's lab.
Many of these come from Camelia's lab.
Certainly we had lots and lots of fun with this structure
and we thought when we started this project
with a periodic structure,
we thought that oh, we will have now something
to work on for years and we will produce many,
many different periodic structures
but at the end of the day,
once we calculated the K groups and everything,
well, we saw that pretty much everything is the same.
So let's see how it goes.
So how you generate quasi-periodic structures
you have an abstract torus, which is the phase of space
and you start from a periodic lattice
and then you perturb the periodic lattice
using this abstract space.
So what do we do?
First we stay on the origin,
in the phase on space we took a point and we project.
Then for example, we move in this direction
on the unperturbed lattice I will end here
but what I will do, I will actually move on the torus
and then I will arrive at this point
and I will project here,
therefore achieving the perturbation I want
and then I can move to this point.
I will have now two moves on this torus
and I will get the next point.
So there is an unperturbed lattice
it has these generators
and then there is an independent lattice
with its fundamental domain.
So this torus obtained here is the fundamental domain
of another independent lattice L prime.
So this, as you can see, this can be in some other,
it's not in the physical space, the physical space is RD
but this one lives in a fictitious RD prime
and I take RD quotient by L prime
and I get my torus where it's the phase on space
and then simply I can generate the,
there is an induced translation on the phase on space.
So if I take any phi, any point on this torus,
I can act with some number N
and here is how this rule tells me
how I moved to this fictitious torus.
And then at the end, this is how you generate the pattern.
So every quasi-periodic pattern is in fact generated
by this algorithm.
So all those patterns that I show you,
including by the by layer is generated by this.
So pinot is the initial point.
You move on the, on the phase on space
according to the index of the point.
So you move this phi.
So for example, this N here lives in ZD.
In this case, it will, the D is two.
So this N, for example, is one one
and here is the moves that I done.
So this is how we should understand this DN.
Then we apply any function from this fictitious torus
to the play and then I get a perturbation of the origin
and then I shift it to the proper,
to the proper, to the proper point
and here is how I generate the lattice.
The quasi-periodic lattice.
And you can be sure that any quasi-periodic pattern
comes this way.
We can write what is the,
and now all this pattern in fact is in one to one
correspondence to the original phase and value
that is the original point on this fictitious lattice
that I chose.
Once I chose this point, I applied the algorithm
and I can generate the pattern.
So the pattern really is encoded in the original,
original point chosen on this phase and space.
That's why this dynamical matrices
actually are indexed by this phase and value.
What can they be?
Well, again, we have, this is the most generic thing
you could imagine.
Each sides can be labeled by an MNN.
We have a coupling element.
And guess what?
Because of the Galilean invariance,
you can take this dynamical matrix to this form.
Now this is a very particular form.
What we see here are the shift operators.
You already know them.
And over here, we have this type of the diagonal operators.
So they are very particular.
You have diagonal, so site N, site N,
and then it's a continuous function f evaluated on the phasen
which is shifted N times with the proper shift.
So therefore we can, not only,
but I can derive what is the commutation relation
between this and operator of this type and the shift.
And we will find that if I move the shift operator
from right side to the left side,
then this f gets composed with the shifts
on the phase and space.
And then if I multiply two of these fellows,
then they commute and at the end you get f multiplied with G.
Now Fourier decomposition assures me
that any such continuous functions on the torus
can be actually written in terms of very simple functions.
What are the functions?
The functions are just these exponentials
of e to the two pi and the J component of the phasen.
So if we put everything together, we will say,
well, all these dynamical matrices can be written
in terms of sums and products of operators, DJs
and my shift operators.
Therefore, it's an algebra
which has D prime plus D generators.
You can actually calculate
because we already have this commutation relation
written here explicitly.
And now if I take this f to be any
of these particular functions,
we will find these commutation relations.
So T i, T j is nothing but e to the power two pi,
a number, T i, j and T j, T i.
And even more, we have explicit relations
of this of this data matrix values.
So let me go back.
So here I was talking about two independent lattices.
One would generate a i, one would generate a j.
And what we have here is a j written in terms of a i's.
And this is how we generate this,
what is this transformation matrix A
and it is precisely this transformation A
which goes over there.
So we are talking about non-commutative
the dimensional torus and this is the same
as the algebra of magnetic translations
with certain flux through the metasurfaces
of the unit cell.
And this is in fact why we can be sure now
that these two patterns are exactly the same.
So what happens here, the patterns were generated
with the same lattice L and L prime.
What was different was just this map F.
That's what all the difference,
but the algebra doesn't depend on that F.
It only depends on L and L prime.
So as long as these things are the same,
we got the same algebra.
And this is why we can be sure that dynamical matrices
fall in the same algebra for these two patterns.
Very quickly, I know I'm over it
over the time a little bit.
So the elements of A theta takes this form
with their, as I said, it's linear combinations
and products of the generators.
We have here the K naught group in front of our eyes.
It's just the same K naught group
as for the periodic structures.
They are generators.
In two dimension, we have explicit expression
for these generators here.
What is important is that they can be labeled
by a set of sub indices and any gap projection
carries two to the power,
this D bar minus one to logical invariance.
And therefore any gap projection can be written
as linear combinations of these generators
with integer coefficients.
Furthermore, trace per volume,
which it's connected with the integrated density of states.
For this particular algebra,
we know how this trace per volume look like
when acted on the generators.
So you have E j, I said is corresponds
to a set of indices.
Well, you take the matrix, the theta matrix
and you restrict it to this set of indices
and then you take the paffeine of that
and here is the prediction.
And therefore what we can say is that
if you have any gap projection,
then the integrated density of states
which is nothing but trace per volume
of the gap projection is sum over the number,
the subset of indices and J and paffeine of T J.
So therefore every line that I showed
in those integrated density of states
before can be fitted with this one.
Why?
Because for each of the models,
I know precisely what this matrix is.
Therefore I can calculate this theta ijs.
When I calculate those theta ijs,
I know what this paffeine is and here it is.
For this structure, all these curves can be fitted
by just straight lines over here.
If you recall, we had this pattern for the IDS
with many, many different curves.
Now each of them can be fitted
with the prediction showed in the previous line.
For this twisted lattice,
we have this fitting.
In fact, we try more to fit every single line
and every single line that you see
in this complicated picture can be fitted
with this prediction.
I didn't put the explicit form of the fittings.
They will look quite complicated.
And what's funny is that, for example,
in this pattern, it doesn't matter
how what is the precise form of this background potential
that we put, these lines can be always fitted
with the same line.
I was optimistic and I was planning to show you
how quickly the program goes to another class
of patterns, but I am way over and I'll stop here
with the conclusion that in the process
of this fitting, you see once I fit one of these curves,
what do I do?
What are the three parameters?
The three parameters, this is already fixed.
The three parameters are only these integers.
So by fitting these curves, in fact,
I already calculate all topological invariants,
for example, associated to this gap.
So this gap corresponds to this curve.
Once I fit this curve, I calculated all topological
invariants associated with this curve.
Now, this gap here is associated with this
integrated density of states curve and the same.
So it's a high throughput of topological invariants
and this is one way to do it.
So this is a way of using the K theory
and it's only for the bulk.
I didn't say anything about bulk boundary correspondence
because one will need another lecture
and perhaps another lecture to cover all of them.
So thank you so much.
And I'll be waiting for interesting questions
and discussion.
Yeah, thank you very much, Emil,
for this fascinating talk on making connections
between seemingly, I mean, at least to me,
seemingly unconnected systems,
be it periodic or quasi-periodic by exploiting topology.
And I hope there will be some questions,
but I guess I can make a start.
