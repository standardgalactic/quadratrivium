Hello everyone, I'm Norman Wahlberger. Today we're going to carry on with introducing
diffusion symmetry as a possible large-scale alternative to thinking about symmetry in
mathematics and physics. And this is part of a series of lectures that I hope will be
particularly interesting to physicists as I hope to get towards aspects of the standard
model and give you some new alternative mathematical tools that you might use to investigate that
and related issues. So today I want to talk about character tables of finite groups and
I want to do it in the context of a specific example because I'm going to be really example-oriented
in this set of lectures. I hope to be rather light on theory and illustrate things sort
of directly with examples. Today we're going to look at the symmetric group S3 and its character
table here it is right here and I'm going to first of all review some of the standard meanings
and interpretations and a little bit of story and properties of the character table and then
I'm going to give you somewhat of an alternative point of view towards it which actually historically
goes back more than 100 years to Frobenius. And at the end even those who have a lot of
experience with group theory will see a new aspect of this character table. So it's this
little table here is a three by three table with columns indexed by C0, C1 and C2 and
those are the conjugacy classes of the group S3. So I want you to think about the symmetric
group as a group of matrices, a group of permutation matrices that have the property
that there's exactly one one in each row and column and otherwise there are zeros. So here
are the six elements of S3 arranged in conjugacy classes. So there's C0 which is just the identity
and here is C1 along this row here. It's a conjugacy class consisting of things whose
square is the identity or if you like the transpositions and here are the things of
order three. That's the conjugacy class C2. Okay, what's the character table giving us?
The character table is giving us the values of the three characters. Let's call them
X0, X1, X2 and you can think about these things as being functions on the conjugacy classes.
So X0 is the function which is one on this conjugacy class, one on this class and one
on this class. This one is the function which is one on this class minus one on this class,
one on this class. And this is the function which is a two on this class, zero on this
class and minus one on this class. Of course, you can also, if you like, think about that
as representing a function on the group,
which happens to be constant on conjugacy classes.
Okay, so this is the character table
and it has all kinds of interesting properties
and the whole story generalizes
to the more general symmetric group.
So the symmetric group is a very important family
of groups, sort of a foundational centerpiece
to group theory, and it's also connected
with the AN family of Dinkin or Coxeter diagrams
in the AD classification story
that I talk all about in my Dynamics on Graphs lectures,
which are over in the member section of my Wild Egg Maths
channel, I hope you have a chance to partake in that.
And this particular group S3 is associated
to the graph A2, it's a very simple graph,
but it generates all kinds of important mathematics
and also physics.
Physics because this graph is also connected to SU3,
which is the group of symmetries of the strong
nuclear force, and that's an important component
in the standard model, which usually involves S1, SU2 and SU3.
And of course the three here and the three here
are connected, we're talking about three dimensional space,
symmetries of three dimensional space
in two different ways, so continuous symmetries here
and discrete symmetries here.
So the mathematics behind what I'm telling you about today
actually quite directly influences the story of SU3,
so that's particularly of interest to physicists.
So where do these characters come from?
Well, these days we think about them
as being associated to what are called
irreducible representations of the group.
So let's explain that, so here again is our group S3
consisting of our six permutation matrices,
here are the conjugacy classes, that's like C0,
that's C1 and that's C2, and here's some alternate names
or ways of representing these elements.
So in terms of generators, we could say define this matrix
to be S1 and this matrix to be S2.
Then those two elements generate the other elements
in the group in the sense that if you take appropriate
products of S1 and S2, you get the other ones.
So this one is S1 times S2, just the matrix product
of these two, this one is S2 times S1,
and this one is S1 times S2 times S1,
which I should point out
has an alternate representation as S2, S1, S2.
So those two expressions are equal
and this is called the braid relation
and it's an important relation in this group.
The other important relation is that
these two generators squared give you the identity.
So these relations then allow you to do arithmetic
with these elements without actually having to do
the three by three matrix arithmetic.
Okay, and then another sort of point of view
which often is found in terms of cycle notation
describing these things in terms of cycles,
that's gonna be less important for us
because from my point of view,
this is not entirely well-defined.
There's a little bit of ambiguity
as to whether you're talking about a left action
or a right action, whether you're talking about
permutations on objects or on positions,
and I talk about that in my dynamics on graphs lectures.
Okay, so the claim is that the characters,
the three characters that I showed you in that table
are actually coming from the three irreducible
representations of S3.
So what is a representation?
Well, a representation is an incarnation
of the group elements as matrices,
but we require that the relations
between the matrices involved
are reflecting the relations in the group.
Now, in this case here, the group is already
represented as matrices, and that's true,
but we're interested in other ways
of representing the same algebraic relations in matrices,
and in particular, such representations
which are irreducible.
So I'll explain that in a second,
but here are the three irreducible representations
of this group.
So the first one is called the trivial representation.
It's really one by one matrices, okay?
And all of the matrices are equal to one, and okay,
so trivially, the fact that this times this
happens to be this, well, that's reflected
in the fact that this times this happens to be this, okay?
So, okay, it's a little bit trivial,
but it's still a representation, and it's irreducible.
It's a one dimensional representation
because these are one by one matrices.
There's a second one dimensional representation
which is the determinant.
If you take the determinant of a matrix,
then that respects the multiplication structure,
and so that has values one on these elements
and on these elements, and these ones here,
the transpositions have determinant minus one.
So that's another irreducible representation.
Now there's a third irreducible representation
which is the two by two representation.
And again, if you go to the dynamics on graphs, lectures,
you will see how these matrices arise naturally
from the mutation game, which can be played
on a general graph.
So these matrices here satisfy the same relations
as do these ones here.
So the fact that this times this equals this one
is reflected by the fact that this times this
equals this one, and so on.
The fact that this is squared gives you this one,
this one squared gives you this one.
The fact that this one times this one times this one
is this one, this is reflected by this one times this one
times this one is this one, et cetera.
Okay, so these are the only three irreducible
representations, and the one that we have here,
sort of the original representation, is not irreducible.
It's not irreducible because it's actually,
in a certain fashion, the sum of, in fact,
this representation and this representation.
And that kind of can be seen at the level of characters.
So now I have to tell you how do you get characters
from irreducible representations.
So what you do is you take one of these rows
representing your representation,
and you take the traces of the matrices involved.
So the trace of a matrix is just the sum
of the diagonal elements, so that's a number.
So the representation is assigning matrices
to the group elements.
When we take the trace, we get numbers
associated to the group elements.
And that's what these things here are capturing.
Now, the trace of a representation has the property
that if you take the conjugate of a matrix,
it has the same trace.
And that ensures that these functions that we're getting
are actually constant on conjugacy classes.
So the fact that these two are conjugate
means that their trace is gonna be the same.
And you hear the trace is zero,
here's the trace is zero, here's the trace is zero.
All of these are represented by that trace zero
on this conjugacy class.
These ones here all have trace minus one.
And this one here has trace two.
What about this one here?
What's the trace of this thing here?
Well, here the trace is three.
The trace of these ones here are all one.
And the trace here are all zero.
So that's also a character,
but it's not an irreducible character.
And these irreducible characters associated
to these three representations are happily a basis
for the space of functions on these conjugacy classes.
So any other function like the one I've just shown you,
the function three, one, zero,
can be written as a combination of these three.
And in fact, you can see that the function three, one, zero
is the sum of what I'm calling chi zero and chi two.
Although that probably should replace these with x's
because that's to be consistent
with what I was using before.
So actually, let's change this to x, all right?
Not a big deal, but x zero, x one, x two.
So x zero plus x two gives us a value of three,
one and zero, okay?
That's sort of reflecting the fact that this representation
can actually be decomposed in a certain way
as a sum of this representation and this representation.
In fact, more precisely what that means
is that you can conjugate,
sort of uniformly conjugate these matrices
to give you, to put them in a form
where it's sort of like in block diagonal,
there's a copy of this thing in one corner
and there's a copy of these guys in the other corner
along the diagonal.
Okay, so this is the story,
the usual story of how characters arise.
So this is the character table of S3.
It arises by, so first of all,
by looking at the irreducible representations
of the given group, which are maps into matrices
and then taking traces of those matrices,
which are then conjugation in variant functions
so they can be interpreted as functions
on the conjugacy classes.
Now the notion of a character of a non-commutative group
is actually an extension or a generalization
of a prior notion of character
for a commutative or abelian group.
So it's important that I mention this part of the story.
So commutative or abelian groups,
their theory is hugely more simple
than that of non-commutative groups,
vastly simpler, like orders of magnitude simpler.
And there the character theory has
a somewhat different and simpler aspect
and it's probably good to start with appreciating
what characters are for commutative or abelian groups.
So again, let me illustrate things with an example.
Here is a small but significant commutative or abelian group
called the Klein-4 group, sometimes C2 squared,
who's got four elements, E, A, B and C, E is the identity
and then there are these three other elements, A, B and C.
So the group is determined by a multiplication table.
Here's the multiplication table.
So A times B is C and A times C is B
and B squared is the identity
and the identity times anything,
of course it's just the anything.
So this is a relatively simple group
and it also has characters.
But for a commutative group, characters are defined
in a somewhat more direct and simple fashion.
For a commutative group, a character is a function,
a function from the group to numbers,
which satisfies the properties that it reflects
or preserves the fundamental group operations.
That means that the identity element always has
number one associated to it, because it's the identity,
that the inverse of an element,
the number associated to that is the inverse
of the number associated to the element.
And this homomorphism property that the character evaluated
at a product G times H is the product of chi G times chi H.
So the character is a kind of a number valued function,
which has the same erythmetical properties as the group does,
except that we're talking about numbers
instead of group elements.
So for the client for group,
there are exactly four characters.
And here they are as functions on the elements of the group.
So there's the identity character
and then there are these characters that have a couple of ones
and a couple of minus ones.
The value at the identity always has to be one,
so it has to be one down that column.
And then otherwise, well, these are the possibilities
and there's some symmetry here.
So it's, you can think about it this way,
that the theory of characters for non-community groups
is an attempt to generalize this well-known theory
for abelian groups.
So for abelian groups, there's a lot more to say.
There's a beautiful theory of duality.
And it turns out that the characters themselves form a group.
That is, you can multiply two characters
and get another character and then they form a group.
And then the original group is the dual of this character group.
So it's a lovely theory that somehow is like a fine idea,
analog of say Fourier analysis roughly on a circle.
So in trying to extend this to non-community groups,
Frobenius and others,
where they realized that you couldn't quite get away
with something as simple as this.
So it wasn't enough to just look at functions
on the group that respect the properties
because the non-commutativity of the group elements
is somehow interfering with that.
You don't get enough characters.
So that's why you have to go to looking at images
in matrices because matrices are supporting
a non-commutative arithmetic.
So that's sort of a natural sort of reflection
of the non-commutativity of the group
that you're trying to represent.
So being a little bit more formal about it,
what Frobenius did is to generalize this sort of harmonic
analysis on community groups to non-community groups,
he introduced the notion of character of a representation.
So a representation is a map from the group
to matrices now.
That satisfies basically the same properties
that we want characters to satisfy
in the commutative situation.
So the identity elements should map to the identity matrix,
which is the matrix with ones down the diagonal.
The image of an element is the inverse of the group element
and the homomorphism property satisfied
that the matrix associated to a product GH
is the product of the matrices associated
to G and H in that order.
Okay, so that's a representation.
And then he defined the associated character
to be the function, which you get by taking
the trace of a representation.
So you take an element G, you look at the associated matrix
given by some representation, then you take the trace
of that matrix, the sum of the diagonal elements
and that's then a number.
Then this function that you get this way
does not have the property that satisfies these things,
but it does have some nice properties.
That first of all, the image of the identity,
the number associated to identity
will be the dimension of the representation
because the trace of an identity matrix
is just the number of elements in it.
So that's giving the dimension.
And this homomorphism property is replaced
by this somewhat weaker property
that chi of H inverse GH equals chi of G.
And so that's a reflection of the fact
that if you take two matrices A and B
and you take the trace of AB,
it's the same as the trace of BA.
So from that it follows that the trace of H inverse GH,
some kind of conjugate like this is the trace of G.
So it has this conjugation invariance property
and that's what makes it a function on the conjugacy classes.
So now we can define the character table.
The character table then of group G
is a listing of the irreducible characters
as functions on the conjugacy classes.
So that means these correspond to irreducible representations
and roughly what that means is these are representations
that don't have any non-trivial invariant
left or right subspaces.
So if you think about a matrix, say,
as acting on the right, on row vectors,
then that space of row vectors cannot,
you cannot find a proper subspace
which is preserved under all the action
of all the group elements.
So there's a condition of irreducibility
and that's what we're seeing
when we look at the character table.
We're not seeing all the characters,
we're just seeing the ones that correspond
to irreducible representations
and you think of them as being sort of like building blocks
of a representation.
So it turns out that more general representations
are appropriate sort of sums of these irreducible ones.
Okay, so this is the modern view of characters
of a finite non-commutative group
and this was Frobenius' actually second,
his second approach to the character table.
It's not sufficiently appreciated
that Frobenius actually had a prior intuition
about what characters of a group were
and it's by exploring Frobenius'
original orientation to characters
that we can find this link
to what I'm calling diffusion symmetry,
that its origins is already there
in Frobenius' original orientation to characters
and it has to do with multiplication of conjugacy classes.
So let me introduce what we might call
the conjugacy class fusion algebra for S3.
So here are the conjugacy classes of S3,
now expressed not in terms of these three by three matrices
but rather in terms of the generators S1 and S2.
So C1 is S1, S2 followed by the element S1, S2, S1
and here this conjugacy class is S1, S2 and S2, S1
and this is just the identity
and I just remind you here are the relations
satisfied by these generators.
S1 squared is S2 squared equals the identity
and here's the braid relation.
Okay, so what I'm going to now show you
is that you can multiply conjugacy classes.
You can multiply them.
As multisets, it's important to make this shift
to multisets here.
So in a lot of standard group theory courses,
one uses sets a lot but there's a serious advantages
in expanding our flexibility
and allowing multiset language and notions.
That's what we're going to be using.
So let's have a look at C1 squared, here's C1.
So there's C1 and there's C1.
I have to multiply these two things.
What does that mean?
Well, that means I'm going to form all possible products
between elements here and elements here
with these ones on the left and these ones on the right.
So I'm going to take S1 times S1, S1 times S2,
S1 times this, et cetera.
They'll give me nine different entries.
So let's go through them.
So S1 times S1 is S1 squared, S1 times S2 there.
S1 times this is S1 squared times S2, S1.
And then we have S2 times S1, S2 times S2
and S2 times this is that.
And then this times this one is S1, S2, S1 squared.
This times this is S1, S2, S1, S2
and this times this is that thing squared.
Okay, now we can use the relations to simplify these things.
So that's the identity, that's S1, S2.
That's, aha, so this S1 squared is the identity.
So it disappears.
We just get S2, S1 out of this product.
Here, similarly the S2 squared is the identity.
Here it's a little bit trickier.
What we have to realize is that we can replace S2, S1, S2
say that first triple with S1, S2, S1 by the braid relation.
When we do that, then there's an S1 squared at the end
which will drop off and we'll just get S1, S2.
Similarly here, this one here, the S1 squared
just disappear and we get S1, S2.
Here, again we can replace the S1, S2, S1
with the braid relation equivalent, S2, S1, S2.
Then the two S2s cancel and we just get S2, S1.
And finally this thing squared, well that's the identity
because it's in this conjugacy class
or you can just multiply it out.
When you put this one beside itself, the S1 squareds
will disappear then the S2 squareds will disappear
and then the S1 squareds will disappear
just giving you the identity.
So there are the nine elements that you get
by multiplying this multi-set by this multi-set
and we're doing multi-set arithmetic here.
And now we can stare at this and say,
ah, well the identity is appearing three times
so it's three times C0.
And all of these guys here are all from C2.
And in fact, each one of the elements is appearing three times
S1, S2, S1, S2, S1, S2 three times
and S2, S1, S2, S1, S2, S1 three times.
So we really are getting three times this class here.
In particular, we're getting something
which is still conjugation invariant.
In other words, a sum of conjugacy classes.
And this then is the product of C1 squared
at the level of multi-sets.
And it reminds us a lot of the kind of fusion rule algebra
kind of manipulations I was making
when I was talking about the skeleton
of the icosahedral graph, right?
It looks a lot like that.
Okay, so now we can put that kind of thinking together
and have a look at this fusion rule algebra
which emerges from the conjugacy classes of S3.
So here's the conjugacy classes again.
Now I'm writing them out in an honest way
with the actual group elements,
three by three permutation matrices involved.
There's C0, there's C1, and there's C2.
And in terms of the multiplication,
well, C0 is obviously the identity, okay?
If we multiply this conjugacy class by either of the other
ones, we're gonna get the other ones,
like C0 times C1 is obviously gonna be C1
and C0 times C2 is gonna be C2.
And so I've just shown you that C1 squared
equals three C0 plus three C2.
And now you can check that the product of this class
with this class, C1 times C2 is two times C1.
So one way of thinking about that is that these ones here
all have determinant minus one,
these have determinant plus one.
When you multiply one of these with one of these,
you're gonna get another one of these kind, okay?
And you're gonna get two times C1.
Altogether there's six possible products.
And so what this is saying is you're gonna get
each one of these things here twice.
And finally, if you take C2 squared,
you get two times C0 plus C2.
So please check that, okay?
So these are then,
it's like a diffusion algebra kind of situation,
similar to what I was telling you about
with the random walk on an icosahedron.
But now it's being generated by the arithmetic
of the algebra of this finite group,
in particular the conjugation classes of this finite group.
And Frobenius realized that characters could actually
be defined in terms of these relations.
So but before we get to the characters,
I want to make a renormalization of this fusion algebra
in the same way that I renormalized our icosahedral
fusion algebra by converting things
into the world of probability.
And we do that by renormalizing the basis elements
so that they all end up having sort of equal weight,
if you like.
So here are the relations that I've just shown you.
And now we're going to renormalize.
We're gonna replace capital C0 with little C0,
which is exactly the same.
But we're going to agree that little C1
is one third of capital C1.
Remember, capital C1 has three elements.
So we're gonna divide by three
to sort of have total weight of one.
And we're gonna introduce C2, which is one half of C2.
So it also has weight, how one.
Now, if you replace the capital Cs here
with the little Cs by using these relations,
then these algebra relations become these relations
for the little Cs.
We get little C1 squared is one third C0
plus two thirds C2, these are all little.
C1 times C2 is C1.
And C2 squared is one half C0 plus one half C2.
And this we call the class hypergroup
of the symmetric group S3.
So as a set, it has these three elements.
And here is the algebra structure
that is supported by those three elements.
And notably, these things have the interpretation
of probabilities because the sum of these numbers
is always one and they're all positive numbers
between zero and one.
So they have an interpretation as probabilities.
So for example, we can interpret this by saying that
if you take two elements at random in C2
and you multiply them, you have a one half chance
of ending up in C0, or you have a one half chance
of ending up in C2.
Okay, so now, Frobenius' characters arise
by asking this very reasonable question.
Can we find numbers that satisfy these relations?
These relations are satisfied by these abstract entities
that sort of represent these averages
of these conjugacy classes of this finite group
that we've been studying.
Now we wanna ask, can we find actual numbers
that obey exactly the same laws?
So we effectively are solving these three quadratic equations.
These are all quadratic equations ultimately
because there's a quadratic term in each of them.
So we have three quadratic equations in three unknowns.
And we wanna know, can we find any solutions?
And if so, what are they?
All right, so let's see if we can do this.
Here is a copy of the relations that we have,
but now I'm including also another one
that I didn't actually formally put there
because it's kind of obvious.
Namely that C0 times Cj is Cj for any j.
Okay, like C0 is representing the identity
and that's gonna act as the identity in this multiplication.
So I want to find characters, functions,
or numbers that I can associate to C0, C1, and C2
that will satisfy these same relations.
And we're gonna see that there's exactly three of them.
It's exactly three of them.
And how could we find these things?
Well, actually this one here
is perhaps the first one to start with.
If you want C0 times Cj to be equal to Cj for any Cj
and Cj's are gonna be numbers.
Then if Cj is not zero for some j,
then you can cancel that out
and you can get C0 equals one.
So the only way that C0 is not equal to one
is if all the Cj's are in fact zero.
And in fact, that is a solution, right?
I mean, if we assign zeros to everything,
then yes, we get a solution.
So we're not however going to include that one.
Okay, that's two tribules.
So we're not gonna write our row of zeros, okay?
So with that possibility excluded,
we can deduce that the number that is associated to C0
has to be one in order for this relation to hold.
So whatever assignment of values we're gonna get,
there has to be a one in the C0 place.
Okay, so what possibilities are there?
Well, it's pretty clear that if all of them
are equal to one, that will work
because we've already said that these coefficients
on the right hand side sum to one.
So if we replace all of the C's with one,
then all of these equations
are gonna be automatically satisfied.
So this is kind of a simple solution
that we can immediately write down.
Okay, so what are some other possibilities?
Well, suppose, have a look at this one here.
C1 times C2 equals C1.
Suppose that C1 is not zero.
Suppose that C1 is not zero, okay?
In that case, C2, then we can cancel,
we get C2 equals one.
So if C2 equals one, then what will C1 be?
So if we put C2 equal to one up here,
we know C0 has to be equal to one,
and then we're gonna get a total of one on this side.
So that means that C1 squared equals one,
and the possibilities for C1 are either one or minus one.
We already have the possibility one,
so the other possibility is minus one.
So that's another possibility.
That's what you necessarily get
if C1 is non-zero.
So if C1 is non-zero,
we're gonna get one of these possibilities.
So the other possibility is what happens
if C1 equals zero?
Well, in that case,
this equation doesn't tell us anything.
And in that case, this equation tells us
that the left-hand side is zero,
and we can say multiply by three,
and we get C0 plus two C2 equals zero.
But C0 has to be one,
so that means that C2 has to be minus a half.
So if C1 is not zero,
then we get one of these solutions,
and if C1 is zero,
then we are forced to get this solution,
and we should check that in each case.
It's true that C2 squared actually is one-half C0
plus one-half C2.
So here it's already satisfied.
So over here, this one squared equals one-half of this
plus one-half of this, yeah, that's true.
And over here, this thing squared, which is one-quarter,
is one-half of this plus one-half of this.
It's like one-half minus a quarter,
which is a quarter, so that works.
So these are the characters
of this hypergroup structure.
So here is the original character table of S3,
and I want you to compare them, okay?
We see that there's quite a correspondence.
This one is the same as that, that's the same as that,
and the relationship between the third row here
and the third row here is just one of scaling.
What we've just done is we've scaled this thing here
so that the first entry is one,
like we've agreed it has to be in this case here.
So you can see that effectively we're kind of recovering,
except for this small scaling factor,
where essentially recovering the character table for S3
by understanding the hypergroup character table,
which comes about just by analyzing this hypergroup.
And in particular, I want you to note
that this issue of irreducibility
does not figure in this analysis.
We have not had a notion of irreducible characters
in this context, we've just calculated all the characters.
And somehow that's captured what Frobenius requires
to introduce via irreducibility over here
in the character table for the group.
So I believe that this understanding
that I'm sharing here with you
would not have been appreciably novel to Frobenius.
Frobenius would have recognized his own insight here,
but I'm maybe presenting it in a slightly different way
because I'm focused on the hypergroup structure,
which turns out to be quite clean, okay?
With this probabilistic aspect,
sort of renormalizing things
so that we have probabilities involved.
But that's not really essential
to getting the character table,
essentially by looking at the multiplicative structures
of the conjugacy classes,
and then sort of analyzing
how to represent that with numbers directly.
So with that method, we basically forego
examining in detail the group structure, right?
We're just really operating at the conjugacy level.
And we're obtaining this very interesting object,
class hypergroup of S3, elements C1, C2, and C0,
are satisfying these relations.
And once we've done this, and just written it down here,
you could ask, well, this looks a lot like
that icosahedral diffusion algebra
that we were talking about in our last lecture,
which I remind you was obtained by looking at the icosahedron
and looking at random walks, essentially,
on the vertices of the icosahedron
with the nearest neighbor kind of random walk.
So a natural question might be,
well, can we perhaps give another interpretation
of this structure in terms of a geometric object,
something like an icosahedron?
Let's think about that.
That's quite an interesting thing.
So suppose that we have some kind of geometrical object,
and we have some initial point,
let's call that, say, C0.
So let's see if we can find a geometrical structure
that captures these same relations.
So by looking at the first equation,
the C1 squared equals 1 third C0.
That's suggesting that there's three things
in the C1 circle.
So let me put this, I won't put the circle around it,
but okay, like this.
And we'll put bonds like this, okay?
And we'll think of this thing here
as being the circle of radius one from C0, okay?
So this is telling us that if you choose one of these at random
and then go radius one, take a nearest neighbor walk
from that one, we should get a one third chance
of getting back to C0,
and a two third chance of getting to C2.
Well, that suggests that we should put two elements here,
and that we should connect like this,
maybe also like this to be symmetrical,
and maybe like this to be symmetrical.
Okay, so that's going to be C2.
So this is going to be C1, and this is C2.
All right, let's see this coincides with this thing here.
So C1 times C2 equals C1, what does that mean?
So it means say if we take a step of size one there, okay, good.
And now we go step of size two from here.
How do we go step of size two?
Well, this is distance two from here, okay?
That's one there, one there.
And this one is also distance two, one there and one there.
And what about this?
No, this is distance one, this is also distance one,
this is distance one.
So if we take C1 times C2,
we are certainly going to end up back in C1.
And if we do it in the other order,
if we first do a C2 step, and then do a C1,
so the nearest neighbor of this one is either here, here or here,
we're certainly back in C1.
So this actually fits with that second line.
And what about this one?
If you choose a random element in C2,
and then go a distance two from that,
what are the possibilities?
So distance two from here is where?
Well, that's distance two.
That is not, that is not, that's not,
but this is because that's distance two.
So the neighbors of, the two neighbors of this point here
are that one and that one.
So random walk of step size two from here
will give us a one half chance of getting back to C0
and a one half chance of staying in C2.
So yes, indeed, this graph actually has a diffusion
algebra source structure that exactly corresponds
with this class hypergroup of S3.
So we have in this way found a purely geometrical incarnation
of what formerly we were thinking of
as essentially an algebraic object.
And now a little bit of further thought
shows that you could actually rearrange this
because I mean, this C0 and this C2,
they're kind of symmetrical.
So a little bit of thought suggests that this thing here
is actually really the same as this famous graph
that you get by taking these three elements here
and these three elements here
and doing a complete bipartite graph.
So joining all of these ones with all of these ones
like this, making those bonds,
these bonds and these bonds.
So this is a complete bipartite graph on three and three.
You can see that as a graph,
that's the same as that one.
I've just moved these guys over here.
And when we do it this way,
then it's completely clear that this is symmetrical.
That is this really does not depend on our choice of C0,
whether this is C0 or that's C0,
it doesn't matter.
We're going to get the same structure.
So this structure really is associated to this graph.
This is a very famous graph.
It's something that's called like the three utilities graph
because it's a famous non-planar graph.
If you try to connect three houses with three utilities
with some roads that don't overlap.
Okay, there's a road, there's a road,
good, maybe from here, there's a road.
We'll go around like this to that one there.
Maybe we'll go around like this to that one there, okay.
And now this one here, let's connect it to that one there.
We can connect it to this one there.
But we can't get to this last utility
without crossing one of the roads that we already have.
So this is a, what's called a non-planar graph.
It's a famous example of a non-planar graph.
So this is like a standard graph in graph theory
students see even in a first year course
and undergraduate course.
And it's, I think, curious that in fact,
the character table of the symmetric group on three letters
is essentially contained in just the graph connectivity
of this graph.
This follows from this, from this diffusion,
algebra point of view, and the character table
follows from this just by evaluating characters
as Frobenius suggested it to us more than 100 years ago.
I'm Noah LaBurger, thanks for listening.
