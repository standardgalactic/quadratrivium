Okay, so hello everybody, it's my great pleasure to introduce our Distinguished Lecture Series
speaker, which is going to be Professor Hugh Woodin. He is, let me give a brief introduction,
he's a professor at the Department of Mathematics and Philosophy at Harvard University, and he's
also a Distinguished Emeritus Professor at University of California Berkeley. Hugh got his
PhD in 84 at UC Berkeley under the supervision of Robert Sullivan, and since then he's become
like the leading step theorist. He is his work includes contribution to the theory of
inner models, determinacy, functional analysis, recursion theory, large cardinals, and a very
famous large cardinal, the so-called Woodin cardinal, bears his name. Hugh has had many honors
just to highlight a couple of them. In 1989, he received the Carol Carr Prize from the Association
of Steam Body Logic. He was also a plenary speaker at the International Congress of
Mathematicians in 2007, and he's also a managing editor of the Journal of Mathematical Logic.
Today, he's going to be talking about infinite necessity.
Well, thank you all for coming. This is actually the first lecture I've given since the before
time without a mask, so it's going to be a new experience for me. I was looking at the clock
and I realized this almost became a very long lecture because that clock is not running.
That would have been a different form of infinite.
See if this works. Okay, maybe it doesn't. Okay, so I'm going to start with number theory.
So we have the natural numbers, one, two, three, and so forth, or as a set theorist,
I view them as zero, one, two, and so forth.
They're the formal axioms of number theory, the piano axioms.
They include the algebra axioms, the axioms you would write down, and the induction axiom,
which basically says if you can define a non-empty set of numbers, it has a least element.
And the question is, is all of mathematics just the study of the formal consequences of PA?
If it is, there's no infinity. Okay, well, we can move a little bit beyond that
and go to second order number theory, formal second order number theory.
So now the objects are the natural numbers, together with all sets of natural numbers.
And we have similar axioms. We have the algebra axioms of number theory. We have the induction
axiom, which is now just a single axiom, which just says that every set of numbers,
which is non-empty, contains the least element. And then we have the comprehension axioms,
which say that if you can define a set with a formal property, it exists.
And I'm not going to specify the axioms any more than that.
So we have two fundamental structures of mathematics, the structures of number theory
and the structure of second order number theory. Okay, so probably one of the most famous modern
theorems is Weyl's theorem from Weyl's last theorem. If you have a natural number bigger than
two, then for all natural numbers x, y, and z, x to the n plus y to the n doesn't equal z to the n.
Okay, that was group 20 years ago, bish. Now, ZFC are the formal axioms for v,
the universe of sets. And v is kind of, is the ultimate generalization of the natural numbers.
Curiously, the published proof of Weyl's is not even in ZFC. And it's certainly far from a proof
in second order number theory that uses infinitary methods. And so a much discussed problem is can
Weyl's theorem be proved in number theory? But I'm going to make the claim that's not the right
question. What is the right question? Well, let's talk about finite number theory. So in finite
number theory, we have the objects are the numbers starting with one up to some unspecified largest
number. So we have the formal axioms of finite number theory. We have the algebra axioms,
but addition is not total. And multiplication is not total. So you just write the obvious
variant, their relations, when does x plus y equals z and so forth. This is not addition
and multiplication mod n. I literally mean we restrict the integers to one up to n,
plus and times our partial operations. What about the induction axiom? Well,
there are many different ways you might do it. But this seems to be the most interesting one.
It's the pigeonhole principle. And it's not known if it's equivalent to how you would
use the, how you would usually formulate induction. So this just says that if you have a function on
numbers and f is defined by a formal property, then it's one to one if and only if it's on two.
You know, if you think about it, that makes sense, right? So that's going to be the induction
axiom. All right, what can you do? Okay, so for every natural number n, if we look at the numbers
one up to n, that's a model of finite number theory, finite FPFA, FPA, not FPA, FPA. One's a
simplest model. And then you have a model which has just one and two, and then a model with just
one, two, and three, and so forth. So it's fun to play around in this theory. And if you do that,
you realize you can define the relation z is equal to x to the y as a partial relation
in finite arithmetic. It's a trick where you break down the exponents.
So for Ma's last theorem is a formal statement in FPFA, FPA, in finite arithmetic.
So can you prove it in finite arithmetic? If the answer is yes, then mathematical infinity plays
absolutely no role in Wiles' proof. There is no room to use infinitary methods. You can't even do
asymptotic methods in finite arithmetic. You're going to have to do nitty, gritty, fine estimates.
The Riemann hypothesis can be reformulated in finite arithmetic. In fact, most of the famous
open problems of number theory can be refined to problems in finite arithmetic. Usually it's a
sharp reform where you've actually made some explicit estimate. If you take the ABC conjecture,
which has been much in the news, that looks far from a universal statement in finite arithmetic.
And yet there's a refinement of it due to Baker that makes perfect sense in finite arithmetic.
So is all of mathematics really just the formal consequences of finite arithmetic?
No infinity at all. Well, let's look at a simple example. Euclid's theorem that there are infinitely
many prime numbers makes no sense in finite arithmetic. But Bertrand's postulate does.
So Bertrand's postulate is the statement that for every number n, bigger than or equal to one,
there's a prime number in the interval from n to two n. That makes perfect sense.
Clearly a stronger theorem than saying there are infinitely many prime numbers.
Now the best proof of Bertrand's postulate is due to Erdos, the so-called book proof. And if you
look at that proof, one can probably verify that in finite arithmetic, if you assume that two to the
n exists, then you can prove there's a prime number in the interval from n to two n.
But what if you just assume that two n exists? There doesn't seem to be any room to do the
sums you need to do to prove, to implement Erdos's proof. Looks like you need a new proof.
All right, Ramsey's theorem. So I have to introduce some notation.
Suppose n's a natural number. A set x is an n set if it has exactly n elements.
For each set y and for each natural number n, we'll let bracket y to the n be the collection
of all n subsets of y. It's not standard notation, but it's simple enough. So here's Ramsey's theorem.
Says take any natural number n and take another natural number k bigger than n.
Then there's a natural number m such that if you color the n sets from the numbers one up to m
with n colors, that's the function pi, then there's a k set all of whose n subsets are colored the
same. So you have a coloring of the n sets from m objects. You specified a threshold k,
and then you can find a k set of those objects, all of whose n sets are colored the same.
That's a starting point for a whole area of combinatorics.
Okay, there's the infinite version of Ramsey's theorem. Now we color the n sets of all integers.
So if n is a natural number, we color the n sets of natural numbers with n colors,
then there's an infinite set of natural numbers all of whose n sets are colored the same.
Okay, so that's more elegant than state.
Now Ramsey's theorem is proved in arithmetic. There's a stronger version which is proved in
finite arithmetic because you have to be more specific about the estimates,
and the infinite Ramsey theorem of course makes no sense in arithmetic because you don't have
infinite sets of natural numbers, so it's a theorem of second order arithmetic.
So there's the Erdos party problem. So for every positive integer k, let's let e sub k,
e for Erdos, be the least m bigger than t such that if you color the two sets with two colors,
you'll find a k set, all of whose two sets are colored the same. So why is this the party
problem? Well if you invite e sub k many guests to a party or a lecture, then you'll be guaranteed
to find k many individuals who mutually have never met or mutually have met. So the coloring
it, did you meet or have you met or have you not met? Okay, so now you can drill down
and look at e5. So what's known? Well it's bigger than or equal to 43, less than or equal to 48.
What about e6? It's bigger than or equal to 102, less than or equal to 165.
So what's Erdos' conjecture? It's within human capability to determine the value of e5,
it is beyond human capability to determine the value of e6. So these are hard problems, possibly.
Okay, so let's move on. Paris Harrington theorem, similar to the Ramsey theorem. So for every
number n, there exists a natural number m. We color the n sets with n colors exactly as before.
We find a set a, all of whose n sets are colored the same.
Cardinality of a is bigger than n, so far I'm just Ramsey. Now we're going to add one thing,
that the cardinality of a is greater than or equal to its least element.
Seems like an innocuous change. Now this easily follows from the infinite Ramsey theorem.
It's a good exercise. And what's the idea? Well look, an infinite set has more elements than its
least element. So if you use the infinite Ramsey theorem with exponent m plus 1,
you can easily prove the Paris Harrington theorem with exponent n. So what's the punch line?
Theorem can't be proved in arithmetic, unless arithmetic is inconsistent.
So just change the Ramsey theorem a little bit and you get something about the finite,
which the finite cannot prove. So this suggests we can define numbers now. So I'll call them the
Paris Harrington numbers. So for every n, let pH n, pH for Paris Harrington, be the least witness
for the Paris Harrington theorem with exponent n. So it's the least m such that if you color the n
sets from 1 up to m with n colors, you can find a set A, all of whose n sets are colored the same.
It has of course more than n elements in it, otherwise it's not so interesting,
and it has more elements than its least member. So what can we say about these numbers?
pH 10 cannot be written in decimal notation in our universe. In fact, pH 5 can't be. These are
numbers large beyond imagining. And necessarily so, or you'd be able to prove the Paris Harrington
theorem. The Paris Harrington theorem is just a theorem that for every n, pH n exists.
So these are much bigger than the usual large numbers you may have seen, like the Canuth numbers
with the up arrow notation. These are just staggeringly large.
So pH 10 can't be written in decimal notation in our universe. pH 11 is vastly bigger than pH 10.
These numbers grow in enormous leaps and bounds.
Okay, so now as a logician, we can do girdle sentences.
So there's a formula first. I have to set this up. There's a formula in finite arithmetic that I
need to be able to talk about the Paris Harrington numbers. So there's a formula in the language
of finite arithmetic. It holds of X expresses that a pH X exists. So there exists a Y such
that Y is equal to the X Paris Harrington number and 2 to the 2 to the Y exists. The reason for the
2 to the 2 to the Y is to give ourselves enough room to verify that what we're claiming is the
Paris Harrington number is. So we have to be able to look at all the colorings. So 2 to the 2 to the
Y is overkill, but it's a security blanket. Okay, so now the girdle sentence theta G, it's in the
language of finite arithmetic. It's a small length, you can write it down on one slide. It expresses
that there's a proof of my negation, a formal proof, from finite arithmetic of length less than pH
10. Remember that impossibly large number. And pH 100 exists. So more precisely that a
phi sub pH of 100 holes. That's why we introduced the formula. So this is a standard girdle like
sentence. It's the paradox, the Lyre paradox. You know, the statement is false. It's the paradoxes
all lead to interesting theorems. This is the interesting theorem or the original girdle proof
was the interesting theorem you get from the Lyre paradox. There's a wrinkle here, though.
And that there's a proof of the negation, but something really big exists. So the chaos isn't
around the length of that proof. It's way, way far away. All right, assume arithmetic math. Now I
should say arithmetic does not prove that pH n exists for all n. But it does prove that pH 100
exists. It proves for each specific n that pH n exists. It just can't prove that for all n,
pH n exists. And how'd I done my homework? So it's not too hard to write down a proof in arithmetic
that pH 10 exists. But what about pH n, where n is pH 10? That can't be proved from arithmetic in
any proof that can be written down in our universe. So how do we know that the Paris Harrington numbers
aren't a contradictory notion? So assume PA. There is a proof of not beta G from finite arithmetic
of length less than pH 11. You just look at all the proofs of length less than our pH 10 and just
verify that none of them is proof. But how can we be certain that there's no proof from FPFA of
less than that enormous number, pH 10? All right, so let's look at this a little more. Maybe we
shouldn't even care. So the real question is how can we secure the finite? So in PA, we know there's
no proof of the negation of theta G from FPFA of length less than pH 10. But that doesn't obviously
imply there's no proof of length less than pH 10. Well, if you work in finite arithmetic and you
assume that pH 101 exists, which is that enormously large thing over pH 100, then you can show that
there's no proof of not theta G from FPFA of length less than pH 10. But is that a convincing
argument? If pH 100 is a contradictory notion in finite arithmetic, we're working from a false
hypothesis, a contradictory hypothesis. Not helping. But how do we know we can't find by physical or
mathematical means a proof of not theta G from finite arithmetic of length less than 10 to the 24th?
Forget about length less than pH 10. Or that we can't find accessible verifiable evidence
which converts to a proof. We built of not theta G from FPFA of length less than pH 10. We built
some weird quantum machine. It flips a lot of coins and voila, we find evidence that there's
such a proof. Well, we have to care about this. Because a proof of length 10 to the 24, if we
have it, we can see it. It's verifiable. What would the consequence be? It's the end of days
for mathematics. If there is a proof of not theta G from finite arithmetic of length less than 10
to the 24th, all of mathematics is wiped out. Because it says that pH 101 is a contradictory
conception. So number theory is dead. All of mathematics that rests on number theory is gone.
You can't define this away. So how can we be sure? Now, I might say, well, that's silly.
I have my, I look at the world. Mathematics is successful in the world. But wait a minute.
What is not, you can't use pH 50 in finite arithmetic to accelerate the proof.
Otherwise, you'd have a contradiction. Because remember what the sentence says. The sentence
says there's a proof of my negation of length less than pH 10 and pH 100 exists. So if I could
work from the assumption that pH 50 exists and use all that rich structure which dwarfs the
structure of the physical universe to show that this string doesn't exist, well, I've in fact shown
it does. So the richness of FPFA in the context of pH 50 exists is far beyond anything you would
need to do a model of the observable universe. So you can't use the regularity we see in the
physical universe as evidence that this string doesn't exist. Something to think about.
I'm not crazy. Don't worry. Okay, so one way you could secure the finite would be to secure the
infinite. If pH 100 is an inconsistent conception, well, then second order number theory is, of
course, an inconsistent conception and that should be easier to see. So let's go further to see if
things unravel. And if they don't, maybe that's evidence that we're okay. So I really want to
emphasize that if that string, so I remember when I took my first analysis class, I remember the
professor saying, yeah, you know, they might find a contradiction in these axioms, but we'll just
define it away. Like we defined away Russell's paradox. You're not going to do that here. There
is no way to define away this contradiction. All right, so the simplest setting for the study of
the infinite is second order number theory. And we have the axioms. So can we answer the basic
questions of second order number theory using or starting from the formal axioms and thereby show
that the conception of arbitrary sets of numbers makes sense. Okay, so we're going to look at the
very simple collections, the projective sets. Now these are not the projective sets of algebraic
geometry. So the standard structure for, so we have the standard structure for second order
number theory. And that's really the structure of the real numbers in disguise. I should have put
the integers in there as a predicate and I didn't. So amazing how many times you can look at slides
and still miss things. Together with a collection of, well, actually what I wrote is accurate.
Together with a collection of simply defined sets of real numbers, the natural numbers are pretty
simple. So these are the projective sets. How do we generate them? There are two equivalent ways to
define the projective sets. The first way is the model theoretic way. You view the reals as a subset
of the sets of all natural numbers. That's easy by dedication cuts, identifying the natural numbers
of the rationales. And then you consider those sets of real numbers which can be logically defined in
our structure for second order number theory from parameters. That's another way to do it.
And that's the calculus, these calculus. So you look at all the sets of real numbers which can be
generated from the initial set R of all real numbers in finitely many steps using two very
simple operations. First operation is from a set take its complement. And the second operation
is if you have a set, you're allowed to use a function from reals to reels which is continuous
if you restrict it to the space of all irrational numbers. And then you take the image of the set.
So you can take a set, go to its complement. You can take a set, take one of these functions.
There's a basic notion in calculus and look at the image of the set. So it's important here that
this is continuous when restricted to the space of all irrational numbers. That's slightly different
than saying it's continuous at every irrational number because we're restricting to the space
rather than looking at the whole space. But what question should we consider?
We have our objects. The natural choice is given by localizing two of the most famous
questions of set theory, the axiom of choice and the continuum hypothesis. So let me just quickly
do that. So we're going to localize the axiom of choice to this arena. We'll call that the
projective axiom of choice. And here's the definition. So first of all, we can define
projective subsets of the plane exactly the same way as we define projective subsets of the real
line. So if we have a projective subset of the plane and we have a projective set x,
let's suppose that for every real number r, there is a real number s such that r s belongs to x.
In other words, x intersects every vertical line.
And then there exists a projective set y contained in x so that in every vertical line it picks one
point. So what the axiom of choice would tell you there is such a set y, but it wouldn't tell you
that it's a projective set. So we're localizing the axiom of choice to the universe of projective
subsets. So that's a projective axiom of choice. It's not clear whether it should be true or not,
but it's certainly an interesting question. What about the projective continuum hypothesis?
We do the same thing. So remember the continuum hypothesis is the assertion that if you have an
infinite set of real numbers, you can either match it with a natural number. There's a bijection
or you can match it with all the real numbers by bijection.
So now it's clear how we would localize that. We just need the notion of a projective function.
Well, that's obvious. Identify a function with its graph, graphs a subset of the plane.
We've already defined projective subsets of the plane. And so for a projective set of real numbers
xy, we have the notion of a projective function. It's a function whose graph is projective.
And so now we can just state the continuum hypothesis. It says that if you have an infinite
projective set of real numbers, then it's either projectively bijective with natural numbers
or it's projectively bijective with all the real numbers. Again, we're just localizing to the projective
subsets. By 1925, so almost 100 years ago, these problems were considered hopeless.
Lose at 1925. And there's a reason they're both unsolvable. Both of the problems given by the
projective axiom of choice and projective continuum hypothesis are formally unsolvable
from our axioms. In fact, they can't even be solved from the ZFC axioms. Something is seriously missing.
Well, maybe all's not lost and these questions can be answered by sharpening our conception
of the structure given by all sets of natural numbers. We had our initial set of axioms.
This tells us we're missing some axioms. We need to sharpen our conception.
And maybe in doing that, we can answer these questions. And maybe in doing so,
show that we're successful in studying the infinite and maybe thereby secure the infinite.
So one way we could do this is introduce a notion of a projective frame.
Projective frame is an extension of the formal axioms of second order number theory.
It's supposed to provide a complete description, scare quotes. The extension should be specified
by at most a recursive set of formal axiom. The extension should be immune to Cohen's method.
More precisely, Cohen's method should not be able to be used to show that
questions are unsolvable on the basis of the frame.
Now, there is a projective frame given by Gertl's axiom for set theory. The axiom D is equal to L.
We'll call that the Gertl frame. The Gertl frame implies the projective continuum hypothesis
and it implies the projective axiom of choice. Great. And it's a frame, so it's immune to Cohen's method.
Good. But there are other projective frames. The projective frame given by the Mychelsky
Steinhaus axiom, the axiom of determinacy. We'll call this the PD frame, PD for projective determinacy.
Determinacy asserts that certain infinite games are determined. They're winning strategies for one
of the players. I'm not going to define it further. So the PD frame also implies a projective
continuum hypothesis and the PD frame implies a projective axiom of choice. Great. Looks like the Gertl frame.
So, but we can strengthen the projective continuum hypothesis and introduce the strong
projective continuum hypothesis. So this just says that if you have an infinite projective set
and X is not countable, then it contains an uncountable closed set. So a big projective set
contains a big simple projective set. The closed sets are, in some sense, the simplest sets.
But they're not equivalent statements. Now, there's also the projective well-ordering principle.
It asserts that there's a projective well-ordering of the reels. In other words, there's a linear
order on the reels, not the standard order, which is a well-ordering. Every subset has a least element.
Okay. And you could restrict a projective. The projective well-ordering principle refutes the
strong, first of all, it implies the projective axiom of choice because you just choose the least
element and it needs vertical line that hits your set. The projective well-ordering principle
refutes the strong projective continuum hypothesis. That's a projective version of the theorem that
if you had the axiom of choice, there is an uncountable set of real numbers that doesn't
contain an uncountable closed set. You just projectify that proof. Okay. So let's go back
to our two frames. If you assume the girdle frame, then the projective well-ordering principle holds.
And that's why the girdle frame implies the projective axiom of choice.
If you assume the PD frame, theorem of Martin Davis, then the strong projective continuum
hypothesis holds. So the projective well-ordering principle does not hold. So the PD frame is
in conflict with the girdle frame. They're incompatible. Okay. In fact, there's a bewildering array
of divergent projective frames. Many other frames have been discovered. Cohen's method actually
yields projective frames in which both the projective axiom of choice and the projective and the
strong projective and the projective continuum hypothesis fail. But for 25 years, the PD frame
was in essence the only frame known in which the projective axiom of choice held and the
strong projective continuum hypothesis holds. And during that time, a conjecture emerged that
the PD frame is implied by those consequences. That it's the only frame where you can have both
the projective axiom of choice as I defined it and the strong projective continuum hypothesis.
Well, that would be great because that would enable us to pick a preferred frame. Remember,
that's what we're trying to do. Unfortunately, a whole new class of projective frames was
discovered. These are frames in which the strong projective continuum hypothesis holds.
The PD frame is false and by theorem of steel, the projective axiom of choice holds.
So that conjecture is false. So it looks like the attempt to understand second order number theory
is completely failing. We just have a huge array of incompatible possibilities.
So to succeed, we need to somehow identify, and that is a typo, the one true projective frame
among this ever-expanding collection of projective frames.
So, well, we'll move to a different perspective, the V perspective. So the axiom that there is a
measurable cardinal is a fundamental large cardinal axiom. It was first defined by Ulam in 1930.
So a large cardinal axiom doesn't be very much a theme tomorrow. These are axioms which assert
the existence of really big sets. So big, you can't prove they exist.
So robot in 1964 showed that if there's a measurable cardinal, the girdle frame is false.
Oh, so now we can cast out the girdle frame.
So the conception of V, the universe of sets and tails rejecting the girdle frame,
V is all about as many infinite sets as possible. It should be everything.
So what about the other projective frames? So there was an unexpected and perfect alignment.
So there's a Martin Steele theorem in 1985, assume there are infinitely many wooden cardinals,
then the PD frame holds. That's great. That suggests, especially for me,
that suggests the PD frame is true. But the connection is even tighter.
A few years later, I showed that the PD frame is actually equivalent to the theory of second
order number theory given by the ZFC axioms. Together with the axioms, there exists and many
wooden cardinals, one axiom for each end. So that's a perfect alignment. That's great. We've
succeeded. But have we really? Well, first of all, now I'll be controversial. I'm not crazy.
We now have a new truth of FPFA. The PD frame is consistent.
Can't deduce that from the fact that ZFC is consistent. It's a genuinely new
prediction of FPFA, a finite arithmetic. How do you account for it?
No one has been able to account for such predictions from the study of infinity,
except for the conception of the universe of sets, where those axioms actually hold
or equivalent axioms do. So that's something to think about. Here's a truth. It's a mathematical
truth that the PD frame is not contradictory. But it's a truth you cannot prove. So the idea that
all mathematics is we're all sitting around calculating, isn't going to help. But that's not it.
It's not going to tell you. You're not going to prove that the projected determinism is consistent.
So it's truth beyond proof.
Since I'm in a philosophy department, I kind of have to say these kinds of things.
Oops, this is recorded. I want the last three minutes. Okay, so I'll make my usual
controversial claim. I'm going to turn this into a prediction about the real world.
My prediction is that this claim will not be falsified in this millennium.
By any means. If we contact extraterrestrial civilizations in 100 years that have been
working on this for five billion years, they won't have found the contradictions.
How do you account for that? Now, at the end of this millennium, we're going to know whether
my prediction is correct or not. But has this success secured the infinity?
The PD frame is secured by the conception of V.
But we're enlarging the scope of our investigation from second order number theory
to the structure of V. We're just kicking the can down the road.
So to be consistent or fair, we should transition from considering
projective frames to considering V frames. We went down the road to projective frames to try
to solve problems that were unsolvable. We succeeded, but only by looking at a vastly larger
structure of the universe of sets. So we really need to apply the same standards to that structure,
where we're not being consistent. So is there an expansion of the ZFC axioms,
which yields a conception of the universe of sets? That's V, which is immune to Cohen's method.
Cohen's method is a spoiler and which is compatible with all large particles. This is the large
cardinal test. So Gertl's axiom V is equal to L is immune to Cohen's method, but by robot and serum,
it doesn't pass a large cardinal test. So up to about 15 years ago, this seemed completely hopeless.
And if I had been giving these lectures 20 years ago, and I would have given you
five different reasons why there could be no such frame, there was a fundamental misunderstanding.
Possibly. So the ultimate frame. So by generalizing the another misprint,
projective sets to a vastly larger collection of sets of real numbers, one is naturally led
to a generalization of the PD frame to a single new axiom. And that axiom is called
V is ultimate L. And that's homage to Gertl's V equals L axiom. And this is an axiom for the
universe of sets in addition to the ZFC axioms. The axiom settles the problem of the continuum
hypothesis. We know that. It implies it's true. It implies PD. That's less interesting.
The axiom yields a V frame. We can already prove that. So Cohen's method can't be used to show that
statements are independent of this axiom. That's great.
But is V equal to ultimate L, the one true missing axiom we seek?
Does V equals ultimate L even pass the large cardinal test? So let's go back to that.
So Robotton's theorem was a successor of this theorem of Scott. That if you assume V is equal
to L, there are no measurable cardinals. Now Robotton's theorem was more subtle.
Robotton's theorem was that if you had a measurable cardinal, the Gertl frame was false.
So the difference between the two theorems is Scott's theorem is saying in L, there are no
measurable cardinals. Robotton's theorem is a little more surprising that if you have a measurable
cardinal, there are real numbers that can't be in L. So the existence of big cardinals
gives you new infinite sets of integers. So Gertl's axiom V is equal to L
fails a large cardinal test and its first interesting instance, measurable cardinal.
So again because, okay, so now the ultimate L conjecture, which I won't state, is a precise
mathematical conjecture, which if true, implies that the axiom V is ultimate L passes a large
cardinal test. Now you may say, well, how can I make that claim? We don't even know what an
abstract large cardinal axiom is, but it's quite convincing that this conjecture will show that
V is ultimate L passes a large cardinal test. But we've been here before.
Great. We have this conjecture. If it's true, maybe this is the true missing axiom.
Maybe we can't solve the question. Maybe it's like the continuum hypothesis.
Have we just traded one unsolvable problem for another?
Well, the ultimate L conjecture, also if true, provides compelling evidence that the axiom
V is ultimate L is true. And so is the missing axiom. So we're being teased with a possibility.
One axiom does everything we want, pass a large cardinal test. All we have to do is prove
this conjecture. And then we have to worry it maybe has no answer or just back to square one.
So the ultimate L conjecture, it turns out, is an existential statement of number theory.
It must be true or false. It can't be meaningless. The ultimate L conjecture is not a conjecture
about sets. It's a conjecture about numbers. It's a conjecture, one theory proves one sentence.
That's an existential statement of number theory. Either true or false. If it's unsolvable,
it's false. Because if the theory proves a sentence, we can see that it proves a sentence.
So we haven't traded one unsolvable problem for another.
Why is it set there at a crossroads? Now, make my controversial claim, if the ultimate L conjecture
is false, that would arguably say that the whole methodology we've been using to understand these
large cardinal axioms reaches a ceiling. And so we need a whole new method to understand the
universe of sets. It will be back to square one. So we've got a 50, 60 year development
of trying to understand large cardinals. It's all coming to a head now. We've got this one conjecture.
We have the tools in hand to solve the conjecture. It's not like we have no idea what to do.
It's also a level playing field. There are attacks to show the conjecture is false.
So you could, you know, cast your lot that the conjecture is true, develop the tools to try
to prove it. There's a lot of partial results there. You could say, well, I don't think that's
the way it goes. You could explore the other half. There are plenty of ways that the ultimate L
conjecture might be false. It really is a bimodal future. And every year, the two possibilities
get further and further separated and sharpened. So this is going to get resolved. And if the
ultimate L conjecture is true, in some sense, then the fun begins, because then we can fight
about whether it be as ultimate L. And if it's false, then we have to go back to our drawing,
back to the drawing board, and start all over in trying to understand the universe of sets.
Maybe we have to entertain the idea that we can't come to a sharp view of the universe of sets.
But if that's true, then what about the consistency claims?
You know, there are some who say the continuum hypothesis has no answer.
The universe of sets is inherently vague. But then why is PD consistent? How could you say,
well, I know nothing about CH. That's inherently vague. But way up there in the stratosphere,
in the lofty peaks, I see wooden particles. I'm making sense. They say that big things exist,
and you can see them clearly, and yet give up on small sets. To me, it's an incoherent position.
So the argument that wooden cardinals, or pick your favorite large cardinals, super compact,
or whatever, are consistent because of their existence in the universe of sets,
demands that we be able to answer questions like the continuum hypothesis.
And we should have a deeper understanding on why those axioms are consistent. The
ultimate alkanjecture gives perfect clarity at some level. It crystallizes out the universe of sets,
and you can't use forcing. You can really start doing transphonic mathematics, and that's the
problem in set theory right now. You can't really do, you know, if every problem you want to look
at is unsolvable, how do you develop a structure theory? All you can do is develop a theory of
possibility. But that's not a structure theory about the universe of sets. And if you're hamstrung
by unsolvability, there's no way to build a structure theory for the universe of sets. So
the vehicle of the ultimate L-axiom offers the possibility of a genuine structure theory for
the universe of sets. It's also the only axiom known that has a candidate for doing that.
See, normally if you're in this situation, you can find surrogate axioms that do kind of what
you, it's like an existence proof that the axiom might exist because here is one. It's like I'm
looking for a unicorn. Well over there there's a horse with a little horn, so it's a pseudo unicorn,
so maybe unicorns exist. There's no known artificial axiom that is both passed as a large cardinal
test and is immune to Cohen's method and crystallizes at the universe of sets. So the
old, via ultimate L is really the only possibility right now. So if it goes down because the ultimate
L conjecture is false, our methodology hits a ceiling, it really is back to square one.
Okay, that's it. Thank you.
