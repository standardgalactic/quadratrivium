Thank you very much. It's a pleasure to be able to speak here. As you all know, according
to the theory of inflation, paramaria fluctuations were produced by quantum mechanical effects
in the early universe. Of course, the fluctuations we now see are classical. The theory behind
this is extremely simple. Each inflation is approximated by the Zitter spacetime. This
pointer doesn't seem to work if there is another pointer. That would be great. Then we take
all the fluctuations, we Fourier decompose them, and then each Fourier mode is governed
by a Lagrangian, which is simply the Lagrangian of a harmonic oscillator, except that its
mass is time-dependent. Otherwise, you can say that the h-bar is time-dependent in such
a way that h-bar is going to zero at the end of inflation, or the oscillator is becoming
more and more classical. You can see this very explicitly by computing the commutation
relations between the amplitude of the wave for each particular mode, and its proper time
derivative, and it certainly goes to zero as the physical wavelength becomes bigger
than the Hubble scale during inflation. Now, this results in the fact that at reheating,
so by the time the universe is reheated, for all these modes that we'll ever observe, we
basically are going to have a classical probability distribution. In fact, we don't measure actually
the conjugate momentum. We don't even, in practice, measure even the time derivative,
which as we said, even that goes to zero, the commutative goes to zero. In the end,
we are having a classical probability distribution for the shape of the curvature of the universe
at reheating. Now, one question we would like to ask is whether we can distinguish this
classical probability distribution that was produced for us by quantum mechanics from
a classical probability distribution that could have been produced by other processes
during inflation. Let's say something was going on, or inflation generated in some thermal
distribution of particles or some other classical process which is not quantum mechanical. Now,
how do we distinguish this in ordinary quantum mechanics? In ordinary quantum mechanics,
we can test quantum mechanics by testing many of its successful predictions, like energy
levels in atoms, g minus 2, et cetera. But the test that tells us that there is a fundamental
deviation from classical physics is the bell inequality. Bell inequality is the test that
most clearly shows you that you have something you cannot possibly reproduce using classical
physics. A quick reminder of bell inequalities. You imagine you have a system that consists
of a pair of spins which starts in an entangled state, let's say the spin singlet state. Then,
on one of the sides, you choose to measure one observable, either A or A prime. You think
of these observables as being the sigma dot n, where n is the direction in space and sigma
is the polymatrices. All of these are operators that have eigenvalues plus or minus 1. A and
A prime means two different directions in space. Similarly, you do the same on the second
spin, so you measure B and B prime, and then you consider various correlations. Sometimes
you can measure A and B, so you measure A on one side, B on the other side, sometimes
you measure A and B prime, and so on. You form the statistics, you measure the correlations
of all these observables, and you can show that if the laws of physics originated from
some hidden variables that were subject to the principle of causality, the principle of
special relativity, that you cannot propagate signals faster than light, then if we make
the decision to measure either B or B prime in the right, the statistics of A and A prime
are going to be independent of that choice. In that classical model, which is given here
by this line over here, you can rewrite the observable in this way, and then if, let's
say, independently of whether I choose A or A prime, the distributions of B and B prime
are determined by the hidden variables, and for each configuration of the hidden variables,
B and B prime are either plus or minus 1, and so either the first term is 0, or the second
term is 0, and the term that is non-zero has a maximal value, which is plus or minus 2.
Those terms are independent of where I choose A and A prime, so we get that the maximal
possible expectation value according to classical hidden variables is 2, while in quantum mechanics,
you can show that the maximum value is 2 times the square root of 2, so it's bigger, and
that you can show easily by taking this operator and you take the square of the operator, and
so the square of each of the pieces is equal to 1, so A and B commutate with each other,
of course, but then there is a piece that you get from the various cross products that
you can write as A commutator A prime times B commutator B prime, and the crucial point
that in quantum mechanics, these operators don't commute imply that this C square can
have eigenvalues which are bigger than 4, so when you take the square root, you get something
bigger than 2.
Now, in cosmology, as we said, the only observables we observe are all these positions of these
harmonic oscillators, they're all commuting, so at first sight, it seems that we just cannot
do the same, and then we certainly cannot do the same, so in other words, so if the
analogy we're trying to make is that, so we have in the bell case, we had a common origin
for the particles, and then at space like separated regions, we measure A or A prime
or B or B prime, so in cosmology, we have something similar, we have a common origin
for everything, we have a unique initial state, and then we have causally separated regions
during reheating, and we could imagine measuring A and A, well, we could imagine doing measurements,
but they're all A's, they're not A and A primes, therefore, it doesn't work.
But then we can think of it slightly differently, so we can think that this point where we make
the measurement, so in the Bell experiment, there is a time at which we imagine the measurement
having happened, or that we do the measurement, and we can imagine that time is happening
earlier in the universe, so we have the reheating surface, and then we go back in time to some
early time, and so we imagine these fluctuations that have a common origin, and then there
is some self-measurement of the fluctuations that we'll have to discuss in more detail,
and then so that things become classical already in the early universe, and we saw that fluctuations
are becoming classical as they cross the horizon, so we can really think of this happening,
and then we have the late early universe reheating and the signals coming to us, and in this
way we can really have something that looks a little more like a value inequality if we
imagine that the measurement occurred earlier.
Of course, we put this boundary between quantum to classical at very late times, for example,
even in the Bell case, if we put that boundary very close to where the observer sits, where
the signals are getting from these two experiments that measure the spins, then we also don't
have any value inequality, so everything that this guy measures is purely classical and
commuting.
Okay, so just to convince you that there could be such a measurement, we'll just choose
a universe that will make it easy, so we're not claimed that this is the model for the
early universe, so I'm not going to claim that this, we're just simply going to choose
a model for the early universe where value inequalities can be tested with primordial
fluctuations, and so we'll just design a universe that makes it easy, we basically will build
all the features of the Bell experiment in this universe, so the idea is imagine a universe
where besides having the inflaton, we have three other massless fields, we form an isospin
triplet, the isospin is an internal SO3 symmetry during inflation, and in such a way that this
field exists during the early universe and survives till today, so it has some imprint,
leaves some imprint in the distribution of galaxies, whatever, that we could measure in
principle today, so we imagine this, of course.
So if we looked at the universe in the skies, besides the usual picture we saw at the beginning,
we would also have, at each region in the sky, we'll assign an arrow, a direction that
is the direction in which this isospin triplet field points.
Then in addition, we'll assume that there are massive particles that are isospin doublets
that get created during inflation, and they get created at some particular time during
inflation because perhaps they were very massive, they became light, and then they become massive
again, and then these particles get created and they decay, and when they decay, they
decay in a way that depends on the relative spin projection of the isospin doublet and
the triplet background fields, and they decay into ordinary curvature fluctuations, and
they decay in a way that they create a disturbance, which has high signal, local high signal to
noise ratio, so that you can get a new pattern of non-gaussianities, which is visible event
by event.
So this is what we assume, and if we assume, make all these assumptions, this is the picture
of roughly what we would see in the sky, so we see the some effect of the isospin triplet
that we see today, and then in the pattern of primordial fluctuations, we'll see regions
that deviate from Gaussianity, and there are regions which deviate from Gaussianity
in one way, so let's say the red dots, and regions that deviate from Gaussianity in some
other ways, so one could give rise to a large, let's say four point function, and the other
one could give rise to a large five point function, for example, those are the regions,
and then the idea is that we interpret this as a measurement that occurred in the early
universe, so for example, here, unfortunately this pointer doesn't work, but let's say we
take a pair, this pair, it doesn't matter with that pointer.
So we take this pair, this is a pair of particles that was produced during the beginning of
inflation, then decay, thank you.
I have the quality of not being able to work point, anyway, the first one, okay, very good.
So the idea is that here, so the arrow here is analogous to the N, the direction along
which the measurement apparatus is pointing, and so this is measuring the spin of this
particle along this direction, and the result is let's say minus one, that's what green
is, and here we are pointing along, let's say the same direction in this case, the arrow
points along the same direction, and the result is also happens to be minus one.
So in some other case, we also measured along various directions, and the result in this
case was plus one, and in this case was minus one, and in this case, you can then out of
all this data, you can select the configuration of arrows which were like A and A prime, that
would be a subset of all this data, and then form the correlations in the bell inequality
and get confirmation that this could not have been produced using classical physics.
If you make the assumption that by the time this guy is decayed, these two were causally
disconnected, so you have to make this extra assumption that we'll always have to do when
we do the bell experiment.
So this is what I was explaining before, so we look at the direction, the field is pointing
that we can see in the sky, and this is a local deviation from Gaussianity that is of
one type or another type, and this reduces to the measurements of these spin projections,
and then we find the pairs and we form the inequalities.
Now, of course, this is a very weird model for the early universe, but if our own universe
right now is undergoing a period of inflation, and let's say it's slow roll inflation, W
is different than minus 1, and the universe were to reheat and so on, that's how the observers
in the further universe, very far future, will see our bell experiments.
So they will think it's a crazy universe, but anyway, our goal is not to describe those
late observers, but us, and so one something that would be nice, and I don't know how to
do it precisely, is to do something like this with only curvature fluctuations.
So the only the curvature fluctuations we see, and somehow use them to think about some
complicated observable, some more sophisticated observable, where the curvature fluctuations
self-measure themselves, and in this way, find something of that kind.
Some intermediate goals could be to understand this purely with curvature and gravity fluctuations,
or perhaps curvature fluctuations, and you postulate the existence of other perhaps particles
which perhaps exist during inflation and using them, maybe we can get this goal.
And we could also sometimes, so there was a sharp, an important assumption that we had
in the previous discussion, which was the idea that each pin was very sharply measured,
and that's an important feature of the bell discussion, and we could drop that too, and
then show some measure, something, some kind of interference patterns, kind of two-slit
experiment ideas, and this you can do if you think, if you have massive spinning particles
during inflation, such as the, so here we postulate the existence of an extra massive
spinning particle which might exist during inflation with a mass of order of the Hubble
scale, and if those masses existed, then if those particles existed, then it is possible
that we might be able to see in three-point functions the effects of these particles,
and we see a kind of interference effect in the three-point function which is proportional
to the cosine of the angle between the short, the momenta corresponding to short distances
and the long distance, so we look at the particular limit of the three-point function where the
Fourier momenta are very large for two of them, that means these are two points that
are very close to each other, and the third momentum which is small, that's a longer
distance, and then we get the characteristic Legendre polynomials that correspond to the
correlations between spins, and this is again one of the correlators we have in this type
of spin experiments, very good, so this doesn't have all the features of the Bell experiment,
but it has some of the features, and some would be further evidence of quantum mechanical
effects, so I think perhaps we were tasked with the idea of predicting what the future
in five years, so perhaps in five years we'll understand perhaps more sophisticated experiments
where we can actually do test the Bell inequalities in a sharper way using cosmological observables,
and we'll be theoretically constructed, and is it going to be possible to measure them
experimentally, almost for sure, not in the next five years, but perhaps in 30 years and
everyone says that the big hope is the 21-centimeter tomography, but we'll see what happens, thank
you.
So it is a logical possibility that the approximate cause of the perturbations is classical radiation
emanating from sources that are produced quantum mechanically, and I'm being slow, does your
diagnostic test that as opposed to the standard vacuum fluctuations?
The diagnostic, this Bell, sorry, yeah, it does, it does, it would test the difference,
but it would be impossible to get these correlations, so if in this toy universe, so this was true
in the toy universe, right, this is a question about the toy universe where we really had
the sharp, so in this toy universe you could not produce the patterns with the correct
statistics, if you assume that you have to make one assumption, which is that when these
particles decay they were out of causal contact, which you can somehow, this is the underlying
assumption that distance scales correspond to time, so if you make this assumption that
distance scales correspond to time, then you conclude that these two particles due to their
distance were causally separated when those fluctuations were produced, then you conclude
it's definitely not classical at the time, so.
Oh, is that testing quantum nature of the spin triplet, suddenly for doublet?
What?
This is spin triplet fluctuation, the quantum nature of that.
This is testing the quantum nature of the spins of this extra massive particles that
we've postulated, yeah, that's it, right, yeah, Andrej?
Oh, sorry.
So is there any relation whatsoever between what you are doing and what people were discussing
many years ago, at some stage Neil Turg suggested an idea that you can redistribute some very
specific, well, defects on the sky, I'm not talking about textures, but something else
on the sky, so that it would mimic all of these peaks in CMB observations and everything,
and then after WMAP have found an under correlation between normal adiabatic perturbations and
polarization, this mechanism when you specifically adjust stuff in the beginning, this was ruled
out.
Right.
Is there any relation between this or not, because people were trying to do something
like what inflation and perturbations do by classical something?
Right, right, right, well, of course you can rule out specific models, the beauty of the
Belly inequalities is that they rule out all models, so we're trying to find something
that would rule out all models, so I'm pretty sure that if you think about specific models,
you run into difficulties very quickly, so already this last thing I was discussing,
so getting these Legendre polynomials from a classical model is very difficult.
We tried and we didn't succeed, but maybe there is a way to get them from a classical
model.
Any other questions?
Do you still see this, this has, even if it's a slow roll, a Gaussian regime, can you imagine
something like this can be done in that, non-Gaussianity would be probably?
Well I think again, so in the far future, so it all depends on what our experimental
colleagues can do, and so maybe in 30 years we have these huge precise maps of 21 centimeter
tomography, for some reason we're extremely lucky and we can see a huge number of modes
and then many of these things will be possible, but theoretically it's easy to consider these
things and it's fun and I think it might, I mean it's interesting to understand even
conceptually how you would do this.
Okay, great, thank you, and Juan, and let's thank all the speakers in a session.
