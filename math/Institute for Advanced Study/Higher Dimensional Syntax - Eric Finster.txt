What I'm going to call something like higher dimensional syntax, and it's motivated by
what's going on here this year, the special program, which is about studying the connection
between homotopy theory, higher category theory, and logic programming languages, things like
this. The key idea motivating most of what's going on this year is that type theory is
what I would consider to be in contrast with set theory, a syntactic and computational
formal system. We've found out now that a consequence of this formal system being more
rigid by focusing more closely on syntax and computation is that the objects it describes
are much weaker than your typical formal system like set theory. What it ends up describing
is what a higher category theorist would call infinity group odds, or what a homotopy
theorist would call homotopy types. In a sense, it solves these problems. If you know much
about higher category theory, the main difficulty you have when talking about higher categories
is something called coherence. We have morphisms. In a two category, you can ask that the one
morphism is only composed up to isomorphism, but then those should have isomorphisms connecting
and things get out of hand. The interesting thing about what type theory does is it solves
coherence issues by just disallowing them from consideration. You just sort of don't
admit any statements when aren't compatible with coherence and then suddenly the problem
goes away. My question is or the problem that most interests me for this year is what can
you do for higher categories? What falls out of type theory, everything is invertible.
This is why we get homotopy theory. I'm interested in what can be done for higher categories
as well. To do that, the idea is to focus on a model of higher category theory, which
is in a sense built out of syntax. There are many approaches to defining what higher categories
are. Most of them involve choosing certain shapes. The shapes I'm going to choose are
motivated by thinking of them syntactically. They're going to be trees. They're going
to be higher dimensional trees. I'm going to sort of define tree what that means. These
shapes have been invented by various authors before and written about. They're most often
called the opotopes and models of higher categories based on them are what we'll call opotopic
models. You can roughly think of them as the continuation of the following idea. You start
with characters or formulas or atoms or whatever you want to call them of your logical language
and think of them as zero dimensional things. The next step is if you want to describe a
language is to think about strings on those formal atoms, but then actually formal languages
aren't really built from strings. They're really trees. If you're writing in a language,
what you're writing down is a presentation of a tree. We use punctuation and key words
and things like this to parse it. Anyone who's written a compiler or something like that knows
that the first step to doing anything with your programming language is to turn into
a tree. These shapes are what can be thought of as the continuation of the sequence, zero
dimensional, one dimensional, two dimensional. I'm going to show you how to go to n dimensions.
Let's fix an alphabet. I'm going to think of it as just atoms. I'm just going to describe
for you how you can denote trees of arbitrarily high dimension. These are going to be pasting
diagrams of a certain special form. We start with just a single character A right here.
I'm going to draw the geometry on the bottom and I'm going to draw my syntactic presentation
on the top. The first thing that it looks like is A just lands in this little box with
a line that goes like that. We can add a bunch of more points to our diagram and the way
we do that is we stick little cards under this A right here. I'm going to add a couple
more points like this. Everything here is in dimension zero. It represents a point and
I've got a geometric configuration of points. If I want to pass to the next dimension, what
I'm going to do is you should look at this picture and think of this top as like a stack
of cards, a stack of labeled cards. What I'm going to do is I'm going to stare down through
the page and the thing that is connected to the line lands on the top. If I do that, what
I see is a tree. Let me draw that tree. It looks like this. Just to help you, the edges
of this tree correspond to the labels on the cards. Does this make sense? The new nodes
of my tree, which I'm leaving open like this for a particular reason, correspond to the
space in between the stack of cards. If I label those things, suddenly I've filled
in the spaces in between these things with one dimensional information. Now, what I can
do is just repeat. I'm going to think of any of these boxes that's connected to this line
here as connected to a line. By the way, this is my string. It's a little bit more general
than the analogy I gave you before because we're keeping lower dimensional information
as we pass to the next. The string in this analogy is FGH, not the lower dimensional
stuff. I'm going to stack more cards underneath. If I put an I right here, remember this one
corresponded to B and this was I. This says there's a one dimensional piece of information
below F right there. I can do things that are more complicated like this. If I stick
a J in between G and H, that looks like this because D was the lowest thing down here and
B is that one right there. Then I could stick a K over all of them. Now, I've suddenly made
a configuration of characters in dimension, well, it lives in dimension one, but it's
composed of one dimensional pieces. Now, I'd repeat. I stare vertically through the page,
notice everything that was on the line and not covered by it becomes this tree right
here. The labels in between look, does that make sense? If I stare vertically through
this page, I now see this tree. If I label them with letters, I think of suddenly those
two cells as inhabiting those pieces right there. Now, before I had a one dimensional
configuration, now I've glued two dimensional space in between those pieces right there.
Now, this is it. That's the only rule. I consider any arrangement of symbols generated by this
sort of form to be, in a sense, a higher dimensional word. Let me just do one more. If I put a
card down here and call it, oh, that means I have a two cell. If you look at the things
that it intersects, it's supposed to be F, G and H, but suddenly I can't draw it anymore.
It has to land over here. I just repeated. You have to imagine this thing is folded together
with a little pocket like that. There's space in between. If you draw the tree that comes
next, it looks like this. If I label it, I've glued in a three dimensional cell between
these pieces right here. Does this make sense? This expression right here is what I want to
think of as a higher dimensional word. It's a collection of my atoms configured in space
in a certain tree-like structure. This process, that's sort of simple. I'm doing something
kind of childish. If I just continue this process, there's a couple places I can stop
and let me just point out, give them special names. If the diagram is sort of complicated,
it has a bunch of stacks of cards, I'm going to call that a web. If it has no cards, I'm
going to call that a pasting diagram. If it's just the tree with nothing underneath. If
it has exactly one, I'll call that a frame. If it has just a frame in particular, it's
just a special case of what I was calling a web of things. The web comes from the fact
that when I did with one dimension, it looked like sort of just a web of things like that.
If it has exact, it's a pasting diagram with just one box right there, I'll call it a cell.
Notice by, it's necessary that a cell sits inside of a frame. That's the only way I
could get something like that. Now, like I said, this idea is, these shapes have been
presented in different ways by many authors. If I just forget the labeling and consider
all possible expressions that I could make like this that end with a cell, that's what
people refer to as the opotopes. They form a category. You can denote morphisms in this
category by just starring a particular box, whichever one you like. The typical approach
to defining higher categories is to say, consider pre-sheeps on this category with its face
structure and give lifting properties and things like that. But I want to sort of take
a different approach, which is motivated by what we're doing here this year. The question
is, if we take these expressions to be thought of as our syntactical units, what should the
logical system of deductions be that we're thinking about? It's kind of clear we're
trying to think about category theory. The only sort of inference rule I want to have
is composition. Composition works like this. If you have a pasting diagram, if you've constructed
a pasting diagram, you get a composite of that pasting diagram. Here's how it works.
I will just color the cell differently. Composite cells will be colored red. This is my sort
of analog of having a lambda in my expression, of having something denote a cell that has
a different syntactic or semantic function. What ends up happening, it's not easy to figure
it out. It's not hard to figure out. You just delete everything that was in between on the
cell below. Then the question is, what should you label that by? The answer is, you should
label that new cell by the pasting diagram you just drew. This is why these sort of syntactic
units are inseparable. If you think about if you have just a sequence of arrows in a category
and you're trying to compose it, you want to write, well, this thing should be called
G composed with F. If you go to higher and higher dimensions, the name that you want
to give to this composite gets harder and harder and harder. Well, the name you should
give it is this expression. That's sort of the point. Remember, each little box is a
cell. Whenever you have a pasting diagram, what you're staring at is a configuration
of cells glued together. What I've done is I've composed this diagram of three-dimensional
cells into a single cell which sits inside this frame. To denote that composition, the
only choice you have is to use the pasting diagram itself. That's why you should think
of these things syntactically. What is this good for? What can you do with this? The idea
is in type theory, type theory is a language in which the inhabitants of a type are syntactic
expressions for that type. There are derivations that there is something there. Let's take
a category and see if we can do something similar. Let's take the free category on a
graph. Here's a stupid graph. What I want to do is I want to think of this graph as
a set of axioms, logical axioms, and here they are. What I'm going to do is I'm going
to add one extra box at the bottom which I'm going to think of as the type. My type here
is G. First axiom says G has a zero-dimensional cell called A. Second axiom says G has a
zero-dimensional cell called B. This one says just if you decode the picture into the geometry
it says there's a one cell connecting A and B and a one cell connecting B and A. The question
is in my logical system where composition is the only inference rule, what are the
theorems based on these axioms? Let me just give you an example. An example of well-formed
expression would be this pasting diagram right here. When I compose that pasting diagram
I get this composite cell which goes from A to A. What I'm saying is the fact that I've
constructed the free category on a graph is just a consequence of the inference rules
in this language of expressions. I don't need to sort of define the category as consisting
of objects and consisting of morphisms and things like that. It just consists of axioms
which have consequences. The inhabitants of this free category are just all possible consequences.
In fact there are many, many more. This is why it's higher category theory that I'm sort
of aiming at because there are many things that are provably isomorphic to A and there
are identities and iterated identities and things like this which are all just consequences
of composition and some more things about composition which I haven't told you.
Before I do another example let me just show you something else. In this theory unlike
in sort of traditional type theories the higher dimensional information is gotten by introducing
a new type which people refer to as the identity type. You'll probably hear a lot if you're
around here this semester. What's the analog of that? I said that in my expressions I'm
going to write the type on the left hand side over here. The introduction rule says this.
If I have a frame which remember I said is just a pasting diagram with exactly one box
below then there's a new type. It's the type of objects which fill that frame. How can
I denote that? Well I just put a box around it and I keep going. The rest of these expressions
here actually technically denotes a two cell but I've shifted it. It's a two cell filling
in this pasting diagram here but I've shifted it down so that it's a zero cell of the new
type. For example here is the denotation in this language of the identity type and here
is the denotation of the identity type on the identity type between A and B and F and
G. But the difference is in this language that there's no distinction. The expressions
have an intrinsic dimension already to them. The second observation is that you can encode
all of our families of inductive types this way. For example if I want to encode binary
trees here are the axioms. I can encode them all in dimension two. I don't need anything
more than dimension two. What I'm going to do is define this data type of binary trees
to be this shifted version which describes for you the fillings of this cell right here.
You can tell because the prefix is the same. What things live in this type that I've just
defined according to my things? Well one thing is the root. This is an axiom. The other things
are compositions of cells and because of the cells that I've given you because of the shape
of them the only compositions I can make except for the identities and I don't want to get
into that here is binary trees. You can tell right here the actual syntactic description
of the binary tree I've created from this inductive type is a picture of that binary
tree itself. That's why I picked this example. In a sense all I'm asking you to do if you're
a type theorist or whatever is work with the abstract syntax tree instead of working with
the one dimensional expression for something and as a consequence you can sort of go to
higher dimensions. That's the idea. But you can even do dependent types as well. So for
example if you want to do vectors it looks like this. I need a special kind of extra
box which I would have to sort of tell you about later but you see sort of everything
appear very nicely. The index will always appear in dimension one and parameters will
sort of appear in dimension two and the green box here is meant to mean that any natural
number, anything that I can produce that's a natural number I can stick on and just tack
on and it will be an endomorphism of x in any case. Okay so open questions. So this is
a sort of interior theory of higher dimensional types which can have non-invertible cells
or I think of it as that. What is the corresponding theory of functions? Is there one? How do
you define them? What properties need they have? Is a theory of functions between types
like this even possible? All the types I describe the answer is yes because everything, because
I've replaced in a sense inductive by free. A second thing is what would co-free objects
look like or co-inductive definitions because those should be crucially important to a theory
of higher categories and a second is semantic theorems. I mean I would say that I have a
proof or non, it's hard to call it a proof that I can denote the free omega category
on an open topic set as a set of expressions in this language. The problem is how do you
state the universal property of free. So this is an almost theorem which is, still needs
some work. So yeah, that's kind of things I'm working on. So thank you very much.
