Alright, so welcome back everyone. So we're going to hear three talks, but I think the
first had an announcement from the organizer, so please go ahead.
Yeah, absolutely. So in case you missed it, the gong show today is starting at 10 past four,
so a little bit of a change of a plan because we have too many participants.
And also I wanted to announce that today at 3.40, please, all the speakers from all the
sessions today, there's going to be a photo for the speakers outside. So 3.40, this is after the
last talk today, and also the members of the Universe Plus collaboration, there's also going
to be a photo at 3.40 as well, so please be there outside of the tent. Okay, so with that.
Alright, thanks for that announcement. So okay, so now we're going to hear three talks,
and we're going to start with Haydn Lee, and he's going to tell us about kinematic flow
and emergence of time. Please go ahead. Is this working? Alright, so I'd like to thank the organizer
for the opportunity to present this work at this wonderful conference. This is my first time at
Amplitude. So my background is in cosmology, so in case you're wondering about the title,
I'll be talking about cosmological correlators. So not exactly on scattering amplitudes, but in
recent years, we've been seeing many fascinating connections between these two fields, so I'll
be highlighting some of them in my talk. Specifically, I'll be talking about some interesting hidden
pattern that we have discovered in the kinematic space of cosmological correlators, and hence
the origin of the title, and see how the physics of time evolution simply emerged from this
interesting pattern. So hopefully by the end of the talk, you'll be understanding what this picture
is supposed to represent. Alright, so this is based on these recent papers that we wrote together
with Neema, Daniel Baumann, Aaron Hillman, Austin Joyce, and Keith Pimentel. Okay, so since this is
a conference on amplitudes not on cosmology, let me begin with a big picture and explain what
cosmological correlators are and why we care about them. So one of the fundamental questions
we want to address in cosmology is what is the origin of structures in the universe,
and we try to understand this by measuring correlation functions that we can see on the sky.
So for instance, we can see that the densities of galaxies on the sky are correlated as functions
of spatial distances separating them, and similarly, if you look at the cosmic micro
background, the background temperature is not perfectly uniform on the sky, but there are cold
and hot spots in the universe, and these are correlated as a function of the angular separations
on the sky. And modern cosmology is essentially a study of these types of correlation functions.
So from the detailed pattern that we see in these correlations, we can infer the physics
of the primordial universe. And the way we go about doing this is that we measure these
late-time correlation functions and trace them all the way back to the very beginning of the
hot big bang, and there we see that there's a spatial surface called the reheating surface
that encodes the initial conditions for these late-time correlation functions.
And importantly, this is not exactly the beginning of time, and in the standard picture,
we think that this initial condition was generated from a preceding period of
excitable expansion called inflation. So you can think of this surface as corresponding to
the end of inflation in the preceding period or the asymptotic future boundary of a quality
disorder space. So now the question is, what is the initial condition and what general
physics generate this initial condition? So what do we currently know about this?
Well, currently, it turns out that all that is needed to expand the current observation
is just a simple, very simple two-point function in this initial condition,
and this happens to very nicely agree with the predictions of inflation. So this is very good.
However, it turns out that the information contained in the two-point function essentially
just kinematics. It's just given by the free propagator. So in order to really learn about
the dynamical content of the theory, such as the particle spectrum, their interactions and
scattering, and so on, they're all contained in the nonlinearities of the theory that generate
higher-point correlation functions. So in order to really learn about this detailed physics of
inflation and the origin of structures in the universe, we really need to go out and measure
these higher-point functions in the sky and understand their theoretical properties.
And now is a very timely to pursue this study because that case is going to be very exciting
time for observation cosmology. So we're going to have a whole array of new generations of
galaxy surveys that will measure this correlation function in the galaxy distribution in detail,
that will go beyond the precision of the CMB measurements that have been in the state of
there for a long time. So just to give you a rough sense of the numbers involved, so here,
for certain class of inflation models, the next generation of galaxy experiments will
measure, will balance this size of the three-point function for inflation
by an order of magnitude better than the CMB constraints. So we will have much larger access
to the theory space of inflation in the coming decades, which is very exciting, and Misha will
probably talk about in his tomorrow's talk. Okay, so next step is going to be very exciting with
lots of observation data. At the same time, it is essential that we also gain a better theoretical
understanding of these correlation functions. So ideally, we'd like to understand these properties
and structures sufficiently well so that if given any measurement of this correlation function,
we would like to fully reconstruct the physics of inflation by just looking at the patterns that
we see in these observed correlations, which exist on the boundary of inflation spacetime.
Okay, so obviously, we don't get to directly measure and see what happened during inflation,
but only get to measure its output. Okay, so the big question I would like to understand
is what really governs the patterns that we observe in these correlation functions that exist on
this boundary surface. And I'm guessing that this question will resonate with many of you
in the audience, because this is the type of question that arises in the modern study of
scattering amplitudes. And especially over the past decade, we have seen a radical reformulation
of scattering amplitudes in terms of more abstract combinatorial geometric ideas,
which are giving important insights into these foundational questions. So one of the important
concepts is positive geometry, as we heard in this morning, which is a certain class of geometric
spaces which have well-defined volumes that directly give the amplitudes in terms of the
boundary kinematic data, which encode, whose properties encode the basic underlying principles
of quantum mechanics of relativity. Okay, so this is an indication that there's a fundamentally
different way of getting this basic physics involving the unitarity and locality of spacetime
in terms of more fundamentally combinatorial geometric ideas that might underlie the scattering
amplitudes. Okay, so clearly this boundary way of thinking about the problem has been highly
influential in the study of scattering amplitudes. So motivated by this, we'd like to ask similar
questions in cosmology. So whether there exist some novel mathematical questions formulated
directly in the boundary of kinematic space, whose answer is going to be these correlation
functions that exist on this boundary surface. Okay, so I need to admit that our current such
an understanding in cosmology is still very primitive, but in recent paper, we think we might
have seen some possibly first glimpses of such interesting structures in cosmology,
so I'll be excited to tell you about this story in the rest of the talk.
Okay, so here's the outline. So first, I'm going to tell you more precise definition of
cosmological correlators and explain how these correlations can be written as certain
integrals called twisted integrals, and then tell you how we can go about solving these integrals.
And next, I'll tell you about some interesting hidden pattern underlying the results
and show how the entire problem solving this integral can be formulated in terms of combinatorics.
And finally, I'll conclude. Okay, so let me begin with the first part. Okay, so we have
studied this correlation function in the context of a certain toy model. Okay, so here's the toy
model that we studied. So this is a model involving a conformally coupled scalar, okay, and with a
non-conformal five-quip interaction. So obviously, this simple model doesn't quite describe our
integral universe. However, it turns out that the result in this theory can be used as an useful
input for the calculation for the actual observable correlation functions that we can see on the sky.
So understanding this particularly simple theory is actually very helpful as a first step.
And so we'll study this theory. In particular, we'll study this theory in a general effort of the
spacetime expanding as a power law. Okay, so here's the metric in conformal time, and A is the
scale factor that expands as a power law in eta, and epsilon here is a parameter that
parameterizes different expanding backgrounds, such as the sitter, flat space, radiation,
meta-domain universes. So here, we are going to be completely agnostic about the background
evolution and not assume that epsilon is necessarily small as an inflation or take any of these
special integer values, but treat this epsilon as a completely general parameter. Okay, so that's
the setup. So specifically, the object we will be studying is the tree-level cosmological wave
function in this theory. Okay, so first some terminologies. So in cosmology, we sometimes
like to make the distinction between the wave function versus correlators, where the latter
quantity is obtained by integrating over the square of the wave function just as in quantum
mechanics. So this is somewhat similar to the distinction we make between amplitudes and cross
sections, where the latter quantity is obtained by integrating over the square of the amplitude.
Okay, so in this sense, the wave function is a slightly more primitive quantity that we can
study compared to correlation functions. So this is the object we will study first.
Okay, so here, I've shown some represented Feynman diagrams that we'll study, and these wave
functions are related to this future boundary surface at beta equal zero. Okay, and the kinematic
data that labels these various wave functions are given by these certain energy variables
that I'm calling axes and y's. So axes label the energy associated with the vertices, and the y's
label the energy associated with the internal edges of these graphs. Okay, all right, so in the
standard picture, the way we go about computing this wave function is by performing some time
integrals, time integration over some various propagators, all going all the way up to this
A-0 surface. In particular, there's a one time integration that we have to do for each interaction
vertex. So that means that as we go to higher points, we're going to get a multi-layer time
integrals that we need to do even at tree level. Okay, so this is a very complicated
integral that we have to do in general. However, in flat space, our things are particularly simple,
and it turns out that the wave function in flat space is given by some simple rational functions
with simple poles in the denominator that label their singularities of the wave function. Okay,
and in particular, there's a very nice combinatorial method of getting this wave function directly.
So the way to derive this is to take these Feynman diagrams and truncate all the external lines,
and then start drawing, we start drawing tubings around these vertices, and to get the wave function,
we basically have to take the total energy that is enclosed inside each of the tubings,
and then take the product in the denominator, and that gives the flat-space wave function.
Okay, so this suggests that there's some nice connection between this cosmological wave function
calculation and combinatorials in these graph tubings, and later on I'll explain that generalization
of this story will play a crucial role in this calculation of the actual F-R-W wave function
that we want to compute. All right, so let me now show you the expression for the F-R-W
wave function in this theory. Turns out that because of the conformally coupled scalar that
we're dealing with, it turns out that this wave function in F-R-W can be expressed as a certain
integral over the previous flat-space result. Okay, so here I've written in this general form,
where u here is the so-called twist vector that includes this epsilon-deformed measure,
and omega-si is the rational differential form that comes from the flat-space wave function
that we computed, whose argument is shifted by this little x variable that it integrated over,
and there's one interval we have to do for each vertex over 0 to infinity. Okay, so this is a very
concrete expression for the F-R-W wave function that we can try to study and compute, and this falls
into a type of integral called twisted intervals, and you might recognize that this written in this
form, this wave function integral looks very similar to the type of intervals that we do for
scattering amplitudes at loop level in certain representations. So we can borrow all these
interesting and advanced techniques that has been developed for amplitude calculations over the
decades and more, and these include things like twisted cohomology and the method of differential
equations that we've been hearing about from these different talks throughout the conference.
And not surprisingly, this technique can be also useful for studying these cosmological
correlator calculations. So let me explain how we go about doing this. So first of all,
what is twisted cohomology? So this has to do with the fact that the total differential of
a twisted integral actually vanishes. So this is the total differential, and you can write this
in a way as a certain covariant derivative acting on the rational form, omega. So that means that
anything that differs by this covariant derivative at the level of the integrand actually gives us
exactly the same integral upon integration. And twisted cohomology is just a fancy name for
the set of equivalent causes of these integrands that differ by covariant derivative and giving
the same integral. And a slightly lower way of saying the same thing is that this basically counts
the number of independent integrals in a given vector space of a given integral family. So
what's nice about this framework is that it gives us access to powerful theorem that allows
to do this counting for us in a geometric way. So this theorem states that the size of the basis
for this vector space is given by the number of bounded regions formed by the singular hyperplanes
of this integrand. What is very nice about this is that if we know that the base is finite,
then it automatically implies that the given basis satisfies the closed system of differential
equations, as has been reviewed in many talks throughout the conference. So this automatically
implies that the twisted integral that we are dealing with are guaranteed to satisfy differential
equations. So let's now see how this gets applied to our cosmology problem. So we will be looking at
this simplest non-trivial example of two-side chain, which is equivalent to the four-point
function at tree level. So this has two vertices, so we can write it as a two-dimensional integral
over twist multiplying the deformed flat-space wave function that we saw before. And now we want
to enlarge this system to consider a family of integrals with the same singularities of the
original integral. So now I've defined this omega as the most general two-form, rational form that
has these singular factors in the denominator raised to arbitrary integer powers. So these are
the same singularities of the original integral, where I've labeled t1 and t2 as the twist factors,
and there's a b1, b2, b3 labeled the three singularities of the original wave function.
All right, very good. So now the zeroth of the thing that we should determine is the size of the
basis for this family of integrals. And we can use theorem to do this. So basically we can count
the number bounded regions from this singular hyperplanes. In our problem, we have these five
singular factors, and four of them form this square, and then there's one diagonal line here. So
in this picture, you can easily count the number of bounded regions, there are four of them,
so that immediately implies the dimension of the vector space is four. So we have four independent
master integrals. All right, so in principle we can choose any of them to be our basis, but it
turns out that there is a particularly convenient choice that is given by the so-called canonical
forms of these bounded regions. So the canonical form is defined to be a differential form that
has logarithmic singularities on this boundary and no singularities elsewhere. So for example,
for a triangle, it's given by this particular formula. So I'm going to choose, as our basis,
just the four different triangles formed by these regions. So I'm just going to give some names.
So omega psi, omega f, omega f tilde, omega z. And omega psi is the canonical form that gives
the original wave function. So because we are computing the wave function, we can just include
it as a part of the basis. Now the key next step is to take the differential of this basis vector
and then use various IVP relations to derive the differential equation. And this is the final
form that we get. So on the left, we are taking the differential with respect to kinematic variables.
And thanks to the choice of the basis, we have this nice epsilon vectorized form,
and A is a four by four matrix that takes an expressive form. And with the constant matrices
multiply the deloc forms, and we're calling the argument of these deloc forms as the letters.
So this is a concrete expression that we get. And this should be very familiar to the people
in the audience working on related problems for scattering amplitudes. And you might think that
we can just continue to use this standard method to work at this higher point functions.
However, it turns out that this method actually breaks down if you're being naive about this.
This is due to the following two reasons. So first of all, twisty columnology actually gives the
most general counting for this generic hyperplane arrangement, whereas our cosmological integrals
are actually highly non-generic. So it actually satisfies a much smaller size of the basis
with a less number of singularities. So we have to be somewhat careful about the choice of the basis
here. And secondly, the challenge is that deriving differential equations typically requires using
many, many integration by parts identities, as we heard from the other talks. And typically,
this is the major bottleneck of applying this technology to higher loop amplitudes, where
the system side of the system becomes really large. And initially, when we face this challenge,
we couldn't also go much beyond the two side example that I showed you. But it turns out that
after working on this for a couple of years, we've discovered some nice pattern underlying
these differential equations that basically allow to derive the equation for arbitrary
triggers by drawing some pictures according to some graphical rules. So this is the story that
I want to tell you in the next part. So this is the concrete expression for this two side example,
the differential equation for the two side example, where the A matrix had this particular form as
constant matrices multiplying these various D log forms. But just by looking at this entry,
it wasn't totally clear what the underlying principles were, what the underlying structures were,
and the entries of the matrix looked more or less random numbers. And this was even more true
for if we looked at the higher point function examples. However, something interesting happened
when we drew pictures of the result, and a hidden pattern was revealed when we did this. So let me
explain what we did and what happened. So basically, all the entries of these eight matrices consist of
these D log singularities, which are some combination of these x and y variables. And there's
a one-to-one mapping, there's a natural way of representing these various singularities in terms
of these tubings of the graphs. So here I've shown some examples. So the D log singularity of the x1
variable has this tubing of the left vertex and so on. And so we can represent only the entries
of the matrix in terms of the graphical tubings. And what happened is that this reveals some nice
pattern among the entries of the matrix. Basically, there was some sort of a directed growth that
happens as we go from the first entry of the matrix to the last entry. So starting from some
simple tubings from the first entry, basically as you go down the columns and rows of the matrix,
these tubings grow in a very specific way. And when the tubing fully grows to include the full
graph, this is the point where the differential equation closes. So some simple set of graphical
rows allow you to predict all the entries of the matrix by just drawing some pictures without using
any IVP relations in the end. And if you go to higher points, the system becomes pretty complicated.
So this is the example for the free-side chain, or the five-point function at tree level. And
I believe the matrix entry is really complicated, but exactly the same rows of pi that predicts
the entries of this matrix. So starting from the first entry with these simple tubings,
they grow in a specific way, and then the system closes when the tubing fully includes the graph.
Okay? So what's nice about these graphical rows is that if you ask me or any of our collaborators
to reconstruct the whole matrix in real time, I think we can do this. So this is the graphical
rule that we have found in this differential system. So let me give you slightly more detail about this,
what this graphical representation is really about. So we have two ingredients in our differential
system, which are the letters and the functions. Okay? So functions also have some nice graphical
representation in terms of these disconnected tubings, and the letters are represented by these
colored tubings, which are some connected tubings. And just to distinguish these two types of tubings,
we color the tubings for the letters and then call them activated. And what's nice about these
tubing rules is that we can automatically get all of the entry, all of the physical letters of the
wave function, and also the function that contributes to the minimal size of the basis.
Okay? And in particular, there are 16 of them for this three-side example, which is much less than
the knife counting that we get from this counting all the bounded regions in the three-dimensional
space. And this becomes even better for the full-site, where we're comparing 64 versus 201.
So it was really crucial for us to work out this physical basis, canonical basis, where things
simplify and then they satisfy nice graphical rules. Okay? So let me finally show you what these
rules actually look like. Okay? So I'll be very schematic, but if you want more details, just
find me offline and I'll be happy to explain the details. Okay? So the general rule is that the
tubings always grow when we take the differential of it. Okay? So for example, if you take this
particular tubing, okay, and then you try to take the differential of this guy, what happens is that
we simply activate all of the tubes around these individual vertices. Okay? So when we do this in
the first step, we get these three types of letters that correspond to these colored tubings.
And what happens next is that these tubings always grow to enclose the cross in the intermediate cross
next to it. Okay? So in the process, these tubings can grow, or it can even merge with the exactly
tubings, or it can absorb another tubing. Okay? And basically, this four phenomenon,
activation merger, growth, and absorption basically constitute all possible ways
in this graph tubings can grow for arbitrary tree graphs that we have considered. Okay?
So in the way we have defined these graphite tubings and the growth rules,
this has really no obvious connection to the original time intervals that we started with.
So this graph tubing seems to have a life of its own, and it was interesting for us
to recast all of the ingredients in this graphical language to reveal some interesting
pattern in this system. All right? So that was the option. So let me now conclude.
Okay? So just like in the case of scattering amplitude, it was interesting that this differential
equation technology was very useful to understand the structure of this effort of the wave function
that we have studied in this toy model of conformly coupled scalars at tree level. And
beyond this, just getting the result out of the differential equations. So usually,
differential equations are just effectively just a tool for getting the results. But it was
interesting for us that our colliders actually had a physical interpretation for these differential
equations. So there was a simple set of rules that are to detect, predict all the equation,
differential equations, and predict all the entries of the matrix equations using some
simple set of rules. This works for all tree graphs. All right. So in the last slide,
let me quickly mention some of the interesting future directions that we can pursue.
So obviously, the analysis that we have done is for restricted to this particular toy model.
And for phenomenological applications, it will be important to generalize this story to more
complicated and other types of graphs, such as those involving massive particles and also
loop diagrams and cosmology. And lastly, let me mention that even though we find this
interesting pattern in the differential equations, we don't have a first principle
understanding of where the rules actually come from. But in this business, if you have discovered
this kind of hidden simplicity or structure in the system, it almost always implies that there's
some underlying structure that could explain this pattern. So it will be extremely interesting to
see whether there's some sort of an underlying geometric structure or positive geometry that
can explain the patterns that we have found in the system. So overall, I think that this
presents a very interesting connection between scattering amplitudes and cosmology with lots of
avenues for future exploration. So I'll stop here. Thank you for listening.
Thanks, Aiden, for a very interesting talk. So now there's time for questions. So maybe we start here.
Yeah, so if I understand correctly, your model is working after the recombination, right?
So this correlation actually before recombination, so right after inflation. So we're computing
the correlation function from inflation or any early universe scenarios that
generate these initial conditions. So is this correlation for math or correlation so for CMB?
Yeah, so we are imagining that we are computing the inflat-tone correlation function, so mass
discolor fluctuations from this initial period. And then this can evolve into the future and then
generate this CMB fluctuations. So what we are doing is we are computing the density correlation
functions in this initial time. And then this density correlation function can generate
some different types of correlation function in the late universe. For example, the CMB fluctuations
in the temperature fluctuations or density correlation function in the galaxy distribution.
So there are many different types of correlation functions you can look at in the late universe,
but what's underlying it is this initial condition, which is generated from
pre-help big bang. Thanks. All right, then there was a question in the back.
Nice talk. I had a question about the size of the matrices. So this is smaller usually than the
size of the number of mass integrals and you're usually considering sub matrices like block
basically that are smaller. I was wondering if you have an understanding of the dimension of
these matrices. Also considering that your definition of tubings is not the canonical
definition in the mathematical literature. So I was wondering if you knew how this size scales
or what's the combinatorial interpretations of the size of the matrices. Yeah, that's a very
interesting, very good question. So yeah, so the way, so I was asking through this in my talk,
but the way we did this tubing for the function, for example, we are defining them as the complete
tubings of these graphs. So by complete, I mean that all of the vertices, you can't quite see
these little circles here on this slide, but there's a little circles circling all the vertices.
And you can, in this way of defining things, there's an interesting hierarchy between the functions
where in this column, all the functions include just one cross in the middle. And in this column,
these tubings include two crosses and in the last column, they include all the crosses as well as
the vertices. And there's an interesting combinatorial problem you can solve. And actually the size of
the basis, if you go to larger systems, it basically grows as a power of four. So you get four,
sixteen, sixty-four and so on. And so it's a different, so it's a slightly modified definition
from the standard tubing picture that mathematicians consider where we have this extra marking for
the internal edge. Actually, we spent quite some time trying to find some definition of this tubing
picture in the mathematical region, but we couldn't. But I think this is an indication that this is a
very interesting object to study further. All right, I think there was one or two questions here.
Yeah, so you know the weight shifting operators and the other differential operators have been
derived in the bootstrap literature. Do they commute with the differential operations that
you're doing here in terms of activation and so? Let's see. So weight shifting operators are
defined in this digital limit, right? Because weight shifting operators, for those of you
not familiar with the weight shifting operators, there are some certain differential operators
that is conformally invariant that can be used to shift the masses of the scalar field
in digital space. So if you take the digital limit, I think,
yes, if you take the digital limit carefully first and then a differential equation should
commute with this operator. But I think you have to take the limit first and then apply this operator
because taking this limit is actually quite subtle. If you're not even thinking of taking
this epsilon-dot digital limit or the right end of the furnaces, but actually that's not the case
because some of the functions in this basis actually scales with epsilon inversely. So actually
what happens when you take this epsilon-dot digital limit, all the diagonal entries actually
vanish because they're just proportioned to themselves. But then the off-diagon entries are
some of them are non-zero and some of the functions actually become just constant in this
particular limit. So the matrix actually becomes much simplified in this particular limit.
And once you have taken this limit properly, I think you can commute with the differential
operators. So my question is two parts, I guess. One, is there any obstruction to doing
tubings for more complicated topology? Let's say you have a vertex kind of diagram.
Like I saw like all of the diagrams that you had were like one, like four-side, five-side.
So yeah, exactly the same tubing picture holds for this different types of graph that have like
star topology or more interesting topology. Basically our understanding is that why this
works for arbitrary tree graphs is that this growth of tubing picture is really local, right?
So this particular growth of the tubing, activated tubings, only grows locally around this
activated vertex. So it doesn't quite matter what kind of complex topology you have in the
other part of the diagram, the growth is always local. So if you were to look at the differential
system for the larger matrix, you will find a sub-sector which is really given by this smaller
growth picture that comes from the smaller side, for example.
And you know, like you're talking at the level of the diagram right now,
is can tubing give any intuition about the sum of all diagrams?
Yeah, so here, yeah, very good question. So here we are talking about just a single Feynman diagram,
okay? So even for a single Feynman diagram, we have to deal with these integrals, so therefore
this differential technique is useful. Now we can think about the sum of the diagrams.
So this is closely related to this trace five cube theory that Kevin talked about.
So in that picture, these tubings of a graph really becomes a particular triangulation of a
kinematic polygon, okay? And there, there's also a nice generalization of this tubing picture to
these sub-polygons of this triangulation. So there's something also we want to understand in the picture.
All right. I see that's a questionnaire, but let me also sneak in a question for myself.
As the chairman, I take the opportunity. So maybe you can say a few words about how,
how would you include tensor modes or graviton amplitudes? Is that something you thought about?
Yeah. So yeah, generalization to higher speed would be extremely interesting. So from inflation,
we have two types of observable, which is the density correlation function and the graviton
gravitation waves. So very naively, if you think about computing graviton correlation functions
by Feynman diagrams, you will have many different Feynman diagrams and each of them will be
accompanied by certain tensor structures. So very naively, you can at least apply this technology
to individual Feynman graphs that contributed to Feynman diagram computation for graviton waves.
But obviously, it will be much nicer if there's a way to see that, if you combine all of the
different diagrams for the graviton wave, we see some nice simplified structure. So we don't have
that kind of example in cosmology yet, unlike at four-scale amplitudes, but it will be very
interesting. So the last question from Lance and a very quick question, hopefully. Okay, thanks.
Just a simple question of how much did you test this pattern against the actual, you know,
in particular, if you go to a new topology like this star, were you able to check it directly?
You were able to check for the, I think we went up to something like eight-side graphs. And then,
so we also developed a completely algebraic algorithm for derive these different equations,
and then we checked up to some eight-side graph with different topologies. We were pretty confident
that this should work. All right, we're running out of time, so let's thank Haydn. Haydn, good.
