Okay, thank you.
So I'll get right started.
Then as Vladimir said, this is concerning a newly discovered and perhaps surprising
connection between constructive logic and constructive mathematics, especially in the
form of Martin Lof's constructive type theory and homotopy theory and higher dimensional
algebra.
And the Martin Lof constructive type theory is especially interesting from a computational
point of view because there are existing implementations of it in proof assistance,
such as Koch and others as Vladimir mentioned.
And so the possibility of introducing these methods into homotopy theory provides for
a new area of research.
So that's what I want to give you a survey of some of the recent work in this area.
So let's start with the Martin Lof type theory.
And let's just go through this a little bit slowly.
Martin Lof type theory consists of, first of all, some basic types, which you can think
of also as sets, and then some operations on these basic types of product and function
types.
And associated with each of the types, there are some term-forming operations.
Among the terms are variables of each type, perhaps some basic terms, and then operations
corresponding to the type-forming operations.
Sure.
The letters indicate, first of all, some basic types, and then some common types.
Some constructors on the basic types.
So we could have some basic types to begin with, and then we can construct new types
out of old using the constructors.
And similarly, this one is a variable.
And then...
Of type.
Of type.
Exactly.
A term of type A. And we can think of it also as an element of the corresponding set.
The type theorist tends to use the notion of type rather than set to indicate a kind
of constructive character.
Good?
Now, the distinctive feature of the Martin Lof type theory is this notion of...
A pair of...
Yeah, that's a pair of this type.
And then this indicates that if I have a term of type B, depending on a variable of type
A, the lambda notation indicates the function which takes the argument x to the value B
of x.
So the whole thing will be a term of type A arrows B. It'll be a function.
If I start with B of x being a term of type B containing a variable of type A, I'm defining
terms here recursively as I go.
I start with a variable, start with some basic terms, and I build up new ones using these
operations.
Is it good?
Yeah.
Okay.
Pardon me?
Mm-hmm.
Now, a distinctive feature of the type theory is the notion of type dependency where I can
have a type which depends on a variable of another type.
And this idea is that this is a family of types which are indexed over a given type.
And now I can iterate that indexing in this way.
If I have a new variable of this dependent type, I can have a new type that depends on
both variables.
And then there are some type forming operations on the dependent types.
For example, I can take a sum or a product according to one of the indices of such a
family.
That's the basic setup for the type theory.
Of course, there are equations also between terms just like in any algebraic theory.
Not between terms.
Well, you could have, but it's not going to play any role in this topic.
Okay.
Now, the system has a curious dual interpretation.
On the one hand, we can think of the types as mathematical objects like sets and the
construction rules as constructing elements or terms of those sets or types.
And on the other hand, we can think of the types as logical formulas or propositions.
And then the terms of the corresponding types are proofs or verifications which are being
constructed as we go along.
This is known as the Curry-Howard correspondence or the propositions as types interpretation.
And it's what gives the type theory its constructive character.
Because whenever you prove in the type theory a proposition, say an existential proposition,
there is automatically then a witness for that existential proposition, namely an element
of the corresponding type, which has the property expressed by the existential statement.
So that gives this constructive interpretation.
Now according to the logical interpretation, the second one, we then have propositional
logic given by the simple type-forming operations.
The product is a kind of conjunction because a proof of a product statement, a conjunction,
should be a proof of this together with a proof of this.
And the function type is a kind of implication because a proof of a function type should
be a procedure or a proof that given anything of this type, you return a thing of this type.
So that's the constructive interpretation there of the function space.
The dependent types are interpreted, as we said, as type index families and therefore
their predicates or relations on the types.
And the pi and sigma are then the universal and existential quantifiers of logic.
So this is a kind of unusual but well-developed and now standard interpretation of constructive
validity.
And given that logical interpretation, it's then natural to add to the logic also a primitive
relation of equality at every type.
So we add now this new relation here of equality and the type id Axy, we think of as the type
of proofs that x equals y.
The rules for the identity are such that if I have two terms, A and B, yes, sure.
So I have these primitive types and I'm thinking of them as under the dual interpretation.
Exactly, that's what the sigma is, is the existence, the pi is the function type.
And now I add a primitive type of identity.
That's a type, it's a type, id Axy, it's a primitive dependent type.
It's indexed over two variables, so it's a relation on A.
It makes sense from the logical point of view, it makes less sense from the type theoretic
point of view, but again we have this dual interpretation and so the logical side drives
us to introduce this new type and the question is what does it mean from a set theoretic or
type theoretic perspective?
So from a logical point of view it's perfectly natural to have a relation of identity, so
that's what we do.
Now we have this notion of identity of terms as in an equational calculus and that given
such an identity we can prove that there is a term witnessing the identity, namely a term
of the identity type.
But the converse is generally not the case and that's the intentional character of this
system of type theory.
If you have a term of an identity type between two terms it's not necessarily the case that
the two terms are equal in the sense of equality of terms.
So this gives rise to on the one hand a system of type theory which is computationally tractable,
you could introduce a rule simply saying given any term like this infer that these things
are equal.
That would destroy the constructive character of the system, it destroys what the logician
praises as the effectiveness or the decidability of type checking and so on.
So it destroys the computational character of the system.
So we leave it in, we leave the intentionality in and we learn to live with it and it gives
rise to a structure within the type theory of great combinatorial complexity.
In fact it's a structure that has occurred independently elsewhere in mathematics twice,
once in homotopy theory and once in higher dimensional category theory and that's the
purpose of the talk now is to explain how this structure of intentionality mirrors or
reflects or is analogous to similar structures occurring elsewhere.
So let me start with the homotopy interpretation.
Suppose I have two types here, A and B of some type A. Now A and B may be, A and B allow
me to build this new type, dependent type over A and B of proofs that A equals B and
it may well be that there are several different terms of that type and they need not be identical.
However, I can build a new type now over terms P and Q and they too can be related by what
we'll call higher order identity terms and so on.
So this structure allows a kind of iteration there and now let's consider the following
interpretation of the structure, the types I think of as spaces, the terms as maps between
the spaces, continuous maps, a closed term of a given type then will be a point of the
space, an identity term between two points will be a path in the space from A to B,
an identity term of higher order between two paths will be a homotopy from one path to
the next and so on.
So that's the idea.
The homotopy interpretation seems to capture a certain logic of homotopy that has not been
formalized previously and it allows us to use the type theory to reason formally about
a homotopy theory and in particular to use the machine implementations that I talked
about before to implement this reasoning.
Yes, that's going to appear in just a moment, Jess.
So let's complete the interpretation.
I need to tell you how to interpret the dependent types and I need to tell you how to interpret
the identity types.
So there's no avoiding it, we're going to have to look at the actual rules of the type
theory so let's get it over with.
So here are the rules.
If I have a type A then there's a corresponding identity type indexed over A, this turn style
indicates, yeah the turn style indicates type dependency here as before.
So there is a type of all types, yes.
So I don't need to make any use of that.
At this point it simply is notation but one can add it as a further type in the type theory.
Then we introduce a universe and the universe is type and its elements are all the smaller
types.
Now that universe itself cannot be a type, it has to be something bigger.
That's the way the type theory is set up.
So I have the identity types.
Given any term of identity type there's a corresponding term of the contracted identity
type which is the reflexivity term.
It's a witness of the fact that A is itself equal to A.
And now here's the elimination rule, it's a little bit awkward the first time you see
it.
What it's saying is that if I have a type indexed over A and its identity and I have
a term of the contraction that is if x equals x then there's a corresponding term of type
x, y.
So maybe to make this a little bit, yeah can I explain this a little bit?
Can you see if I write something on the board?
So it says something like this, it says that if I know that x equals y and I know that
some relation holds for x and x well then I can infer that it must also hold for x
and y.
That's the basic format, form of this rule, however now I have to also doctor this up
by witnesses of the statements because that's the principle of type theory that everything
has to carry with it a tag or a witness of the proof of it.
And so here I need to also put in the witness and then here I'll need to put in the corresponding
P. So that's the form of that rule.
And then there's a computation rule here which is a kind of bookkeeping for these witness
terms.
Now the rules of the identity types force the dependent types to have the following
lifting property, as long as I'm using the board here I might as well continue.
I can see that I'm not going to make it in the amount of time anyway so I can just do
what I have to do.
So here's say the type A and here's the dependent type B over A and we think of it as indexed
over A like this.
Now the dependent type B looks like this and if I have an element here a term of type A
then I look at this fiber over A that's B of A and now given any path from A to B that's
our interpretation of an identity term, right?
Well then if I look at the fiber here over B and if I select an element up here what
did I call it A bar?
If I select an element up there A bar then this path will act up here to give me a map
P star from this fiber to that fiber and it will allow me to pick out here P star A bar
over in the fiber over B. So that's a familiar property there of lifting and in fact if I
fuss around a little bit more I can actually lift not just the end point but I can lift
this entire path, so I guess that would be like that and moreover I can do it with additional
parameters, I've lost the clip, I guess that speaks against using the shock board, there
we go.
I can do it also with additional parameters here so that if I have a whole homotopy down
here I can actually lift the whole homotopy up here.
So that's a familiar property to people working in homotopy theory, it tells us that the dependent
types are vibrations and so that's how I'm going to continue the interpretation.
I'll interpret a dependent type as a vibration and now to interpret the identity type I'm
going to need some vibration of this form over A cross A because it's a relation on
A, a binary relation on A. Since the fiber of the identity type over a pair AB is supposed
to be the space of all paths from A and B I'll take the entire path space as the interpretation
of the identity type.
So that's the basic idea of interpreting these identity types, the path space of course
classifies homotopies into the type A. Okay, now that's the basic idea, I've given you
the impression that I'm going to actually do this in spaces and continuous maps but
that's not what I'm going to do, what I'm going to do instead is I'm going to do it
into abstract homotopy theory as axiomatized by a Quillen model category.
There are two good reasons for doing it that way, one is of course as always in the axiomatic
method it encompasses then a range of different interpretations.
I get the concrete homotopical interpretation but I also get one in simplicial sets in group
voids and chain complexes and so on.
So that's one good reason to do it, the other good reason to do it is it allows me to give
a proof of completeness of the interpretation and if I have time at the end of the talk
I'll explain where that comes in.
Now in fact I only need half of the structure of a Quillen model category namely weak vectorization
system.
So let me just briefly describe what that is for those of you who are not familiar with
it.
A weak factorization system on a category consists of two classes of maps, the left
maps and the right maps and I think of the right maps as the vibrations and the left
maps as the weak equivalence co-fibrations or trivial co-fibrations and these are required
to satisfy two axioms now.
First axiom says that if I have any map F I can factor it into a trivial co-fibration
followed by a vibration and the second axiom says if I have a commutative square like this
where on the left I have a left map and on the right I have a right map then there exists
a diagonal filler that is a map across the diagonal here making both triangles commute.
There's also an axiom of retracts that I don't need to make any use of.
Now I'm going to give my interpretation the way I said before, I'm going to interpret
the closed types as fibrant objects that is objects whose map to the terminal object
is a right map and the dependent types, pardon me, closed means it doesn't have any type
dependency left so if it started out as a dependent type I've applied sigmas or pi's
or other operations to close all the variables and the dependent types will then be fibrations
over such fibrant objects and the dependent terms will be sections of the fibrations.
This is a very natural I would say interpretation now given the intuition that we're working
with.
So the interpretation of the identity type as I said before has got to be a path space
and so using the Quill and Model axioms or the weak factorization system axioms I take
the diagonal from A into A cross A and I factor it into a left map followed by a right
map and I call that the path space and this then is the interpretation of the identity
type and having done that I satisfy already the first of the rules namely the identity
formation rule tells me that this needs to be a vibration or a right map and that is
indeed the case here with P and I satisfy the second of the rule, second of the rules
the formation rule for the reflexivity term tells me if I contract over a single variable
there needs to be a term of that type well that just tells me that there's a section
of this over the diagonal and that's of course this first part of the factorization.
So I've satisfied both of these identity rules let's see how to satisfy the elimination
rule.
So the elimination rule had these two premises and if we interpret these premises the first
one says that B is a vibration over the identity type the second premise says that B has a
section over this particular contraction with the reflexivity term so if you analyze this
a little bit you see what it says is that this reflexivity term admits a map across
the top making this square commute because the B is indexed over only one variable on
A and then it gives us a section of this particular contraction of that family.
So I have a commutative square here and now this map R I got from factoring the diagonal
so that's a trivial co-fibration.
This map Q is by assumption a vibration because it's the interpretation of a dependent type.
So by the second axiom I get a diagonal filler in that square.
Now the diagonal filler is what I'll use to interpret this term J. The commutativity
of the first triangle tells me exactly that this J is a section of Q that is it's a term
of exactly this type so that's the conclusion of the elimination rule.
Moreover the commutativity of the top triangle tells me if I apply J to R the result is B
that's exactly this bookkeeping computation rule.
So these four rules for the identity types I didn't make them up Martin Lef made them
up about ten years ago I think it's astonishing that they're precisely captured by the laws
for a weak factorization system so that's the well maybe 30 years ago that long the
intention oh you're right the intentional theory was in yeah absolutely the intentional
theory was in the end of the 70s 78 79 that's right absolutely okay so just to kind of summarize
what I've just done Martin Lef type theory with the intentional identity types has a
sound interpretation into any Quillen model category or even a weak factorization system.
Now pardon me for this this is a little bit of logician's terminology if I have a logical
system and a range of interpretations I say that an interpretation that the system is
sound if whenever I can prove something it always comes out true in the interpretation
so what I've just shown you is that the interpretation of Martin Lef type theory into weak factorization
systems is going to be sound it's a it's a derivable statement in this system of type
theory where I can iterate these rules that I showed you finitely many times to construct
new terms so a statement is under the logical interpretation of the type theoretics system
it's a type a complex type right I can interpret it as a logical statement by interpreting
dependent families of relations sigmas and pisers quantifiers and so on and then to prove
such a thing is to derive a term of the corresponding type a closed term of that type okay now the
converse notion is of course completeness it says that if something comes out to be true
in all models then you can actually prove it and there's also a completeness theorem
and the completeness theorem was given a couple of years ago I guess the dates I'm giving
are dates of publication here so that tells us that if something is true under the homotopy
interpretation in general then you can actually prove it in Martin Lef type theory so that's
a very tight correspondence there between the type theory and the homotopy interpretation
so the summary of part one of my talk I guess I'm doing okay for time here is that Martin
Lef type theory gives us a logic of homotopy theory now one can certainly ask at this point
okay how expressive is this logic of homotopy theory that is I could take a very weak system
of logic right let's just say equations I can interpret that anywhere and I can get
a sound maybe even complete interpretation that doesn't tell me very much because I don't
know how expressive the theory is so the next question that's reasonable to ask is what
homotopical properties or structures, constructions can be formulated in this type theory and reasoned
about in a formal way so that's what I want to do next let's go back to our system of
identity terms of various orders right so we start out with some primitive terms and
then we build the identity type over those terms that's the type of all proofs that
A equals B and then we build the identity type over that that's the type of all proofs
alpha and beta that the proof P is somehow identical to the proof Q and so on up and
that gives us a never ending sequence there of higher and higher identity terms and we've
shown one way of interpreting them as homotopies and higher homotopies another way of interpreting
them is suggested by this diagram where the sources and targets of the arrows indicate
the corresponding indexing here within the identity types so here A and B have a 0 dimension
there of the lowest type here and then a P has as a source A and a target B and so I
indicate that as an arrow here and alpha and beta similarly have this type and theta will
have this type and so on well that certainly is a suggestive idea and it corresponds to
the notion of a well on the one hand a set and then here a category and then here a two
dimensional category and a three dimensional category and so on now just as in homotopy
theory the terms of the lowest type namely just these and these actually form a group
oid or at least the structure of a groupoid in the following way the familiar laws of
identity here reflexivity symmetry and transitivity are of course all provable in the type theory
and so one can prove that there exist terms of the corresponding types here and a term
of this type is then an arrow from A to A a reflexivity term there's a term of this
type which tells me that any time I have an arrow going this way there's a corresponding
arrow coming back that's the symmetry of identity and there's a term of this type
which tells me that if I have a pair of terms like this and like this that I can compose
them to get a term like this so that's exactly the usual structure of a groupoid it's a category
with inverses however the actual laws for a groupoid for example the associativity of
composition don't hold up to equality rather they only hold up to the existence of a term
of the next higher order that is up to homotopy so for example if I represent here transitivity
or if I represent composition here with a dot then I can build these two different composites
and associativity would ask for them to be equal but instead of being equal they're
witnessed by a term of the next higher identity type and this goes on if I have compound
associativity terms they satisfy certain coherence properties of even higher identity
type so the entire situation is very much like in homotopy theory where one gets a higher
dimensional indeed infinite dimensional structure an infinite dimensional graph if you will
as in the diagram that I showed you before with vertices and edges and then higher dimensional
edges and even higher dimensional edges namely what's called a globular set and this globular
set has the structure of an infinite dimensional groupoid but a weak one and by weak I mean
just as in homotopy theory or higher dimensional category theory the laws the actual groupoid
laws are satisfied only up to terms of the next higher order and that's a rather complicated
combinatorial arrangement that has been formulated in higher dimensional category theory by people
like Botanin and Tom Leinster and others and there is a rigorous notion of a weak omega
groupoid in the sense of Botanin and in recent work we've shown that if you fix a type and
look at this tower of identity terms of arbitrary order that actually does give a weak omega
groupoid in the sense of Botanin so there's the second connection that I mentioned between
the constructive type theory and higher dimensional algebra these weak omega group oids that occur
originally in homotopy theory also occur here in the intentional type theory so the conclusion
is that the fundamental groupoid of a space is actually a logical construction so I was
asking how much homotopy theory can be expressed in the constructive type theory and this is
an answer to that question the fundamental groupoid construction fundamental weak omega
groupoid can actually be constructed in the logic the logical system of homotopy theory
so what we're seeing here is that this topological fact that the fundamental groupoid of a space
is not an actual groupoid but rather only a weak higher dimensional groupoid this is
actually a fact in the logic of homotopy theory it can be proven as it were once and for all
in the logical system and then interpreted into any different any given space or any
other model of homotopy theory and realized in these different in these different instances
so what I want to say here is that this is not just a coincidental analogy or something
like that it really is a formal a formal system in which we can prove results and then interpret
them into different cases and they will be meaningful statements for example in homotopy
theory alright so now the next question that one might ask is how special are these weak
omega groupoids that arise in this way in a system of constructive type theory given
the soundness and completeness results that we have it stands to reason that these things
should be quite general in fact in many cases we construct free algebraic objects in a in
a similar way and a reasonable conjecture I think is that these things are in some sense
free weak omega group so we have the homotopy hypothesis which goes back to Groten-Diek which
says that the weak omega group oids themselves classify the different homotopy types of spaces
we can formulate a similar type theory hypothesis at least it's a kind of motivating conjecture
that the logical group oids constructed in this way in type theory are essentially the
same as the arbitrary group oids I know it's that's why it's a conjecture well that let
me let me try to make it precise and then I hope you'll see that it's not that far fetched
okay so let me conclude then by sketching a way of making this conjecture more precisely
so let's start with an arbitrary globular set arbitrary yeah that's a infinite dimensional
graph just a sequence of sets and some labelings of sources and targets for the different domains
and co-domains and over such a globular set now I'm going to make a type theory now of
course if this globular set is not countable well then this type theory won't be a conventional
type theory but it will still be in principle a type theory namely I take for each of the
sets I throw in a basic type which I call a here and then at each level I use the elements
of the globular set as primitive terms in my type theory so I use the elements of a not
as primitive zero dimensional terms and then I put in the elements of a one as identity
terms of the corresponding identity types using the index indexing here of source and
target to tell me which identity type to put it into so that gives me now a primitive a
system of primitive terms over which I can build a type theory the idea clear then I
will interpret the dependent sums and products over this primitive system so I start out with
basic types just of identity types and then I build the system around that that is to say
I turn the crank right and I let the type theory start to spit out more and more and more terms
I build the type theory over these basic terms and now I know that the result will be a weak
omega groupoid I know that by the results that I just mentioned that whenever I have
a type theory and some type in there the result is a weak omega groupoid so this allows me
to generate a logical weak omega groupoid from a given globular set I'm going to fix
that basic type and then I just look at the tower of identity types over that with all
the derived terms that came from all of the primitive terms that I put in to start with
that good so that's a logical groupoid generated by a not and as we said before we can even
get a computer to systematically calculate all of these cells of all the dimensions
successfully systematically and calculate their relations so this is a cool way of making
weak omega groupways right I start with some infinity graph or even a lower dimensional
graph right so I have some elements here A B C D and then I put in some vertices and
some edges and so on and then maybe I put in a couple of terms like this and then I
give it to the computer and then the computer starts to crank and crank and crank and crank
and it systematically produces well no more zero cells some more one cells some more two
cells and so on but it generates in a systematic way all of the higher dimensional cells over
this thing it generates something that is like a free weak omega groupoid over such
a graph so the construction is functorial in the graph that I start with of course and
in fact you can show not difficult to show that it's a monad on the category of globular
sets and what that means is it's a kind of a specification of an algebraic theory or
a type of algebras and if I look at the algebras for this monad what I get is a notion of an
algebra of this logical type so these will be the weak omega group oids generated by
systems of type theory together with equations among the primitive terms or equations among
arbitrary terms yeah absolutely and that will change things that exactly that's right that's
absolutely so whether we have dependent sums whether we have dependent products and which
rules we give for them the strong ones the weak ones whether we have eta reductions or
not will change things and the question of which of those rules give the various corresponding
answers is something that needs to be investigated that's absolutely correct but now I can make
my conjecture at least a little bit more precise that I could say if I start with an arbitrary
globular set and I build the free martin-liff complex in this sense on that globular set
that should be equivalent to the free weak omega groupoid generated by that globular set
which is a an algebraic higher categorical construction and moreover I can say that
over the category of all such martin-liff complexes we could speculate should be equivalent
to the category of all weak omega group oids we're here to be sure there's a good deal
of slack in the notions of equivalence here of individual weak omega group oids and then
equivalence here in the categories especially in the higher dimensional case of weak omega
group oids it's not exactly obvious what the notions of correct notions of equivalence
should be we can make this more precise at least by starting with the lower dimensional
case and that's what we've done we start with a one dimensional case so a one dimensional
the basic data is going to be just a one graph so no higher dimensional cells and then we
generate from that a group oid an actual group oid using the type theory truncated
at higher dimensions that is we put in extensionality axioms at dimensions higher than higher
than one that is we collapse all of the higher dimensional structure in just the same way
that you do in homotopy theory where you make the actual fundamental group oid or group
of a space by identifying paths that are homotopic so that's a familiar construction and now
we can show that indeed the one dimensional truncated martin-liff complex is indeed equivalent
to the free group oid on that graph where equivalence now is absolutely precise this
is equivalence of group oids and moreover the category of all such one dimensional martin-liff
complexes admits equivalent model structure and now the notion of equivalence that we
use is equivalent equivalence to the category of group oids and that tells us that the one
dimensional case at least actually does classify homotopy one types so that's at least a step
toward this more precise correspondence between such logically generated group oids and the
algebraically generated group oids so that's the one dimensional case and now all we need
to do is go from n to n plus 1 and we'll be done so let me conclude then by saying that
I think it's apparent that the amount of homotopy theory that one can formulate in this system
is indeed at least significant amount because it captures the notion of a weak fundamental
group oid of a type or space and I guess I can mention a couple of further topics if
we look at the entire category generated by a type theory as Vladimir was saying a moment
ago it's not just a group oid it's really a category with more structure it's an infinity
one category if you look at all the types and that's a recent result of a PhD student
of mine it should be an infinity topos yeah so here if we make the nerve of it if we make
the nerve of such a thing we get a quasi category in the sense of in the sense of joy out with
a simplicial set that satisfies a a horn filling condition so a weak con complex and this relates
then what we're doing now to the work of Joao and Luri and allows us to interpret the other
type theoretic operations which I haven't talked about and it should be an infinity topos I
think that's reasonable oops end of presentation oh there was one more oh there we go of course
but this is closely connected then with Vojbanski's Univalent Foundations Program so okay that's
it thanks for your attention
