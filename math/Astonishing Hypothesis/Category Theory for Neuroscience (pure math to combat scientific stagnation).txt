I actually feel like I owe everybody a little bit of an explanation, so I jump right in.
The first thing is, what do I mean by scientific impasse?
And so I keep this very brief.
So the question is, are we stuck?
Is there a problem in science?
Is there an impasse?
And I will just let somebody else do the argument for me.
So this was published in Nature not too long ago.
And based on a lot of data, the conclusion was that there's indeed a problem in science
overall.
If you look at the past and what happens now, things seem to have slowed.
In neuroscience in particular, I could point out, for example, this time period in the
1950s to 1960s, and show you various findings that happened.
I took this from this excellent book in neuroscience.
And I think it's quite striking that we went from basically inventing the intracellular
electrode to finding what DNA is, what GABA is, serotonin, dopamine, the full genetic
code.
We found action potentials, EPSPs, IPSPs, we're explaining all of this all the way to orientation
tuning.
We're still in the 1960s, where all of this got discovered, REM sleep, reward hippocampus
in memory, and on the theoretical side, we went from cybernetics to the Hodgkin-Huxey
model to artificial intelligence, which started in the 60s and this whole brain is a computer
metaphor.
So what has changed?
Not much has changed since this time, it seems.
And yet, if we look at the number of publications starting in the 1950s in neuroscience and
neurology, they have exploded exponentially.
If we look at the number of PhDs that have graduated in the last 30 years, they have
gone exponentially.
So there seems to be a mismatch here, perhaps, I suggest, between the effort, the money,
and what is going into science and what's coming out of it, and it seems that that pertains
to neuroscience as well.
Now, how could this be fixed?
Well, as a biologist who learned that the biggest theory in biology, the theory of evolution,
did not come about by people sitting in an armchair, my first instinct would be to say
we need more data or better techniques.
Again, I'm not alone in thinking this way.
So starting with the Obama administration, a lot of money got pumped specifically into
neuroscience for finding better techniques, finding more data and the equivalent of this
kind of approach in Europe as well.
And yet here we are, that just a couple of weeks ago, Nature wrote that disruptive research
is declining.
So if it's not a problem of getting more data, then maybe we should rethink our approach
and think if there's something we can do on the theoretical side.
And that will be my entire talk today.
So what I will argue is that other fields that had similar impasse, they found that
when they looked more into theory and specifically into certain parts of mathematics, things
worked out for them.
So what I will highlight here is particle physics.
And just to familiarize real quick, starting from last century where we realized that an
atom is actually made out of smaller particles, such as electrons and nucleus, we found that
the nucleus itself is made of smaller particles and you might have heard about this.
So the proton and the neutron each consist of three different smaller particles that
have been termed quarks.
And people found out that there seems to be two types of these quarks, the up quarks in
a proton and one down quark, and in a neutron we find two down quarks and one up quark.
That doesn't blow anybody away, but somebody realized that when it comes to mathematics
and particular group theory, things become very interesting.
So those scientists realized that if you take the neutron and the proton and you put them
in a coordinate system, specifically looking at the number of strange quarks, the electric
charge and the spin of these particles, that there seems to be a symmetry, they fall onto
opposite sides.
And there is a large field of mathematics that's specifically interested in symmetry
and they basically said that if we apply group theory to these kind of findings, there should
be other particles as well, specifically there should be particles that have two up quarks
and one strange quark or let's say two strange quarks and one up quark and so on.
And then indeed when they went and looked, they found exactly that.
So in physics, we're at the point where we go from theory to new data.
It's almost the exact other way around of what we learned in biology from Darwin.
And more specifically, they do this not just with the kind of high school or undergraduate
level math that most of us are used to, they do this with pure math.
And so I took this accent quote from Mark Collivan, who wrote that sometimes the answers
to scientific questions sit already on the shelf of the mathematics department.
I just showed you one of these examples when it comes to physics.
But as I said, I'm going to make this point specifically about pure math, not about applied
math because applied math is what we already do.
So applied math is that if we look at certain phenomena in nature, we measure, we come up
with certain numbers and then those numbers we can convert in other numbers and eventually
out of these numbers, we can derive mathematical laws, mathematical equations.
The mathematics that I will talk about today, pure math, is what some people would say higher
level math.
And so when people hear higher level math, they usually think about something like this.
Well, I'm here to tell you that this is wrong.
This is still applied math.
Pure math doesn't usually have numbers, for example.
So it's a completely different way of thinking about things.
And so this nice diagram that I modified a little bit shows you how we can go from regular
theoretical thinking, computer modeling, all of these things that we readily do to pure
math.
And the difference as we deepen down in this hierarchy of theories is that pure math is
a very high abstraction.
So of course, numbers already are an abstraction.
There's no such thing as numbers.
It is something where we abstract from concrete things and allows us to do math.
Math is all about abstraction.
But pure math, as you will see in a moment, is abstraction from abstraction.
And in a way, what we're doing here is we're going deeper into what math is itself.
We're trying to find out what have different fields that use numbers, for example, in common.
And we're finding, if you will, the grammar or the rules of mathematics itself.
That is what group theory does and what has helped physics.
So maybe it's going to help us as well.
So we're looking at high abstraction because it comes with low complexity and new things
can be discovered.
This again, I find myself being not the only one thinking about it, but maybe even being
late to the party, the last couple of years have seen an explosion of papers in various
no-design zones that do exactly that.
So the pure math that these groups are using is topology, which in some ways is related
to geometry, but for the longest time it was housed in mathematics department as pure,
as non-applied, something that you can't use in science or anything for good.
It was just math for the sake of mathematics.
And lo and behold, there's an increasing number of papers that's coming out that are
using pure math topology for data analysis.
Well, I would like to talk about a very different kind of pure math today called category theory.
And I want to show you a success that category theory has had that I think is not very well
known yet.
And then hopefully trigger a little bit of discussion or debate.
And what I will tell you about category theory is largely based off your blog taken from
Tyler A Bradley, including actually some of her slides.
So I want to give credit where credit is due.
In fact, the whole work, the whole insight, the success that I will talk about today,
I know from the people that have done this work that they got inspired by Tyler's work.
But there's also a large number of other people that inspired me and allowed me to talk about
this today, people whose online work or books I read, including people that have talked
to me personally and educated me a little bit on category theory.
Now specifically what I would like to talk today about is what is category theory and
how does this apply to neuroscience, in particular to vision science or consciousness, which
is my deep interest.
And to start out, I would like to start on common ground.
So most of us are familiar with set theory, which in some ways is a kind of pure math
as well.
And a set is basically just a collection of things.
So here we have a collection of numbers, here's a collection of letters.
Those are two sets.
And set theory usually is using this as a starting ground to launch into deeper mathematics.
What category theory is not as interested in these objects, what category theory is
interested in is the relationships between them.
So in set theory, the relationships that we typically find are mappings from one set to
another set.
And in set theory, we call these functions.
So the definition of a function is basically a mapping, a certain kind of mapping from
one set to another set.
And again, what category theory is interested in is this mapping rather than what is being
that.
That's the big difference to set theory.
So you could compare in some ways set theory to the semantics of mathematics, whereas category
theory is more syntax or rules.
It's about form rather than any substance.
And so this might become clearer more in a moment.
Now the probably biggest finding in all of category theory is the so-called UNEDA lemma.
So the moment you hear about category theory, you will hear about the UNEDA lemma.
And it is exactly this finding that I would like to talk about today and want to show
you how this has led to massive breakthrough.
So what is the UNEDA lemma?
The story of the UNEDA lemma goes to the 1954, where a young mathematician, Nubua UNEDA,
who had just graduated, went to Paris to work with other mathematicians there and got interested
in this new field, in this new buzz, in this new theory category theory that started out
in mathematics.
And in fact, one of the founders of category theory, Saunders-McLaine, was interested
in writing a book about category theory and thought that a good way to do that would be
to visit all of the various mathematicians that are already working on category theory
and he would do interviews with these mathematicians.
And so Nubua UNEDA and Saunders-McLaine, they met, the story goes, in a tiny, small Parisian
café in 1954 and it was at a train station because Nubua was waiting for a train.
And so there was limited time for Saunders-McLaine, Nubua UNEDA, to chat.
And in this discussion, they came towards this interesting finding and so the story goes
that they had to rush towards the train and while they were walking to the train, they
were still talking about mathematics.
And in fact, even though the train was only supposed to be taken by Nubua UNEDA, Saunders-McLaine
went on the train with Nubua and barely made it out in time before the train left.
But at that point, the UNEDA lemma was established.
Okay, so what is the UNEDA lemma?
This is the UNEDA lemma and so this, of course, in the equation by itself doesn't make any
sense, so let me write it out.
So if f is a functor from a category c to set, then the natural transformations from
hom c dash to f correspond by a bijection to f of c.
Now, if you're like me, then this doesn't make any sense because, of course, without
any help, you will be wondering, what do you mean, what is this, a functor?
What is a category?
What do you mean by set?
What is a natural transformation?
What's hom c dash dash and what's a bijection?
So what I would like to do is to help to understand the UNEDA lemma, basically take
all of these words of jargon that might not make a whole lot of sense, and then one by
one, just in slightly different order, go over each of these terms and explain them
to you.
So it's basically, as you will see, an introduction to category theory in a nutshell.
The first thing, it's not really category theory, it's standard in math.
What is a bijection?
And so if we go back to set theory, where there's mappings between different elements
of a set, of course a set, the mapping in between is a function, and the definition
of a function is that there is an assignment of each element of one set, let's call it
x, exactly to one element of another set, let's call it y.
So if we had set x here and set y here, then what we should find in a function is that
again there's an assignment where each element of x is assigned to exactly one element of
y.
So this is a legitimate function.
Each element of x is assigned to exactly one element of y, even though of course two
elements of x are assigned to exactly just one element in y.
That's still a legitimate function.
This is what most people think immediately when they think of a function, which is more
straightforward.
You have an assignment of every element of x to exactly an element of y, and it's exactly
only one of them, and this is a bijection.
So another word for bijection that's less fancy, it's a one-to-one mapping.
So each time we have a one-to-one mapping between different elements of mathematics,
we call this a bijection.
Okay, so that's a bijection.
Now I told you that a category theory is interested in relations, such as functions, but it goes
beyond that.
So what is a function?
I just told you it's a mapping, but there's other forms as well.
We don't have to go too deeply into that, I'll do it in a moment, but for now all I want
to tell you is that category theory, because it's abstracting from its section, it's basically
saying that any time you have a mathematical structure, and another mathematical structure,
such as one set and another set, and there's some kind of mapping in between them, we called
it amorphism.
So it's a more general term for function, if you will.
So another way that this is done in category theories is that we often don't talk about
morphisms, but just about an arrow.
So an arrow in category theory is just this mapping, the fact that there's a relation,
some kind of assignment between different elements in mathematics.
So from now on, I might say morphism, I might just say arrow.
So as you can see, category theory at the get-go is very visual.
Okay, so here are different kinds of morphisms that some of you might be familiar with.
So when it comes to vector spaces, for example, a linear transformation is just another mapping,
it's a morphism.
When we measure things, measurable functions and z functions are morphisms, and there's
other ways, such as homomorphisms in group theory, that are all basically structure preserving
mappings.
They have one thing in common, which is that they're relations, they're morphisms, okay.
So we abstract away from these specifics, and we say, what do all of these have in common?
So we have mathematical objects and other mathematical objects and arrows between them.
And that is already a definition of our next term that we have to define a category.
So a category are objects with relations between them.
Each time you have something that relates to something else, there's some kind of mapping
between them, some kind of morphism, we call it a category.
So it's a very broad starting point.
And as I said, it's a very visual language.
So this beautiful drawing by Tydenay, it shows you that we can basically now use these dots
as objects, and then these arrows as relations, and we can start drawing diagrams, or if
you will, some kind of algebra.
How do these things relate to each other?
Okay.
So if we have a category where you have an object and another object and an arrow in
between, and another category, and an object and object and morphism in between, what
if there's a morphism between categories?
Can we have a mapping from one category to another category?
The answer is yes.
Of course, there can be relations between them, and we call that a functor.
So a functor is a mapping between categories.
It's an arrow between things that have arrows between them.
And I told you, this is just, we can keep going.
This is what category theory does.
So here's a beautiful diagram of a functor where you have one object and some kind of
relationship, let's say a function, onto another object.
This whole thing is a category, and we have a functor that maps that onto a second category.
And that's how we get the f of x and the f of f and the f of y, because there's a mapping.
This functor tells us how these relate, and it's structure-preserving.
If we have an object here, another object here with an arrow in between, that's exactly
what we come up with over here as well.
Now if there can be a functor as an arrow between categories, could there be an arrow
between arrows?
So could we have an arrow from one functor to another?
Could there be a mapping from one functor to another?
And again, why not?
So this arrow in category theory is called, it's a very important one, a natural transformation.
So the natural transformation is just another arrow.
It's an arrow from one arrow to another arrow.
You can see it's very, very abstract.
So everything that I told you so far basically is that we can have mathematical objects,
could be anything, could be a set, could just be a number, and morphisms between them.
And it's this structure, this relationship, this web of relations between these objects
that category theory is interested in.
So it finds maps for different other categories that have the same kind of structure that
would be a functor.
And if there's multiple functors, we can find the natural transformation between them.
So the relation between the relations between the relations.
Okay, so now we already made most of these terms, and you might be wondering, why would
you bother?
Why is this interesting?
I got some data.
I want to do some analysis.
I'm writing computer code.
The thing that I told you so far, which seems very abstract, is just diagrammatic.
You can implement in computer code, and you can do calculations just as you're used to.
It's just a different way of thinking about things.
Not only this, there's also emerging programming languages in Python, for example, that really
go to the heart of it where you can just put in these diagrams, and you can let the computer
do the math, follow it on these diagrams, so you don't even have to do the translation
from the diagrams to symbols, and then back again.
So there is practical application to everything that I'm telling you.
Okay.
So we talked about what a bijection is, what a category is, what a functor is, and what
natural transformations are.
What I still owe you is what set is and what this is, hom.
Well, set is the category of sets.
That's it.
So if there's a category where you have different sets and the functions between them, which
is called a set, set is the category of sets.
That's very simple.
And if there are two objects that say A and B in a category, then the hom factor AB assigns
them to a new object that consists of all the morphisms from A to B. So there's a set
of all morphisms between these objects.
That's why this hom factor is so important.
And it's a very important part of the UNEDA lemma.
Okay.
So this is the crucial point.
So if we look at the network of relationships that say this object, C, sets with all objects
in capital C in the category, then what we see is there's different kinds of relationships,
if you will, different kinds of arrows, some pointing in and some pointing out.
And that corresponds to these two different hom functors where we're leaving the stash
for all of the other objects that might exist in the category.
And you can see that we're going from those objects towards C or from C towards these
objects.
So you can think of these as almost like two sets of morphisms of relationships.
And the important thing that seems immediately obvious is that if there are two objects that
say C and A and they have the exact same functors, this functor and this functor is the same,
then they also must be the same.
That's in a nutshell the principle insight of the UNEDA lemma.
And I find with this abstraction, it might actually be quite difficult to fully appreciate
that.
I find that if you break this down in a practical example, it immediately makes sense.
The one thing I want to say first is that I'm going to use for now the term isomorphic
and being the same as almost synonymous.
So isomorphic just means that it has the exact same structure.
And so when it comes to, for example, you and all of the people that you have relationships
with, you can think of yourself in a way as having in or outgoing arrows.
These are all the relationships that you do, that you have.
And so everything that I just told you is that if there would be another object, another
you, and it would have the exact same home functors, the exact same relationships with
other people that you have, that person would have to be isomorphic with you.
It would have to be the same with you.
It has to be you.
So you were born to certain people, you might give birth or be a parent to other people.
You will have certain romantic partners, friends, colleagues.
If you take all of these relationships, there cannot be another person that has exactly
those relationships to be born to the exact same people, give birth to the exact same
people, have exactly the same colleagues and exact same friends.
So the totality of your relationships defines you uniquely.
There cannot be another person that has the exact same relationships, but is not you.
That's the fundamental insight of the Yone da Lema, that just by the relations, anything
is uniquely determined.
And so if I explain it this way in concrete terms, it can seem awfully trivial, but it
is mathematics.
So I haven't just shown you something that in a way is trivial.
I have shown it to you formally, that this works not just for humans in relationships,
but for anything that can be described mathematically.
So this, what Tidenay calls the Yone da worldview, the generalization of this, that objects
are fully defined by their relations, I just showed you not just in something that's
trivially trivial, but also I showed you, and this is another nice quote, that the purpose
of category theory is to show that which is formal, is formally formal.
So I showed you formal definitions for this very simple statement.
I did not show you the formal proof.
I let a lot of rig a go in the end, but I hope that you still caught the gist of it.
Okay, so now I'm going to take a big break, and I'm going to tell you a very big problem,
and then I'm going to show you how the Yone da problem solves this problem.
This problem is in the neuroscience of vision, in fact, it generalizes to all of neuroscience,
in particular, it bugs the neuroscience of consciousness.
And this problem is called the inverted spectrum problem.
So the idea is the following, and it started with Berkeley thinking about these things
more than four hundred years ago.
All of us see a spectrum of colors, more or less, some of us have some color weakness,
but we can order colors from, in this case, as we think about it, long wavelength light
to short wavelength light, and the idea is that if there would be some people who for
whatever reason would see that spectrum that I showed you left to right exactly flipped,
you would not be able to find out.
So the idea is that there are two people, and they talk about color, and their behavior
about color exactly identically.
But one C screen is red, and the other person sees red as red.
And if you think this through, you will not find any logical contradiction.
So why does this make sense?
Well, let's imagine that I would be the odd one here, and all of you see apples, or let's
say the strawberry, all of you see that the same way as red.
Red is red for you.
But this would be my strawberry.
But my whole life, ever since I was a baby, whenever I see this, everybody calls this
red.
So how would I know that this isn't red?
If each time anybody sees red and shows me something that is red, that's the color that
I get.
So any attempt now of us talking about what makes up red, I would always agree.
If you would say, well, red is the color of fire, it's warm, it's what you see if something
heats up.
And I would say, yeah, because that's what I see.
So based on just talking about it, in fact, even psychophysics, if we just discriminate,
it seems that we cannot tell apart two people where one would have an inverted spectrum
from the other person.
And what's worse is that there's no logical reason that this couldn't happen even with
exactly identical brains.
So you could say, well, if we look in Alex's brain, we would find things are different
and are weird.
And that's why Alex's strawberry appears different to him.
But if you really think this through, there is no metaphysical reason that if my brain
is exactly like your brain, and we're seeing the same thing, and there's the same retinal
processes, the same neuronifying in higher areas, that this would be my mental experience.
So that is why it's a very troubling finding.
So there are some arguments that maybe there are even people that have inverted spectra,
we would never find out.
But the really troubling finding is that identical brains could have more than one experience
because there doesn't seem to be a hardening.
There's no mathematical mapping, if you will, between certain brain states and a mental
state, at least not one we found yet or that we're aware of.
And that allows for this scenario.
OK, so does this mean that even if we know everything, including the connectivity, the
past, the current states, everything about all neurons, I give you all glia cells, the
blood vessels, everything about the brain, we could never find out what exactly somebody
is conscious of because it could be greenish, it could be reddish.
We can't defer from the brain.
Well, that's where the Ionata lemma comes in.
So the first thing I have to basically refine a little bit is that when we think about the
color spectrum, of course we put it on a spectrum because color perception in its most simple
way is dependent on the wavelength of light.
And we go from very long wavelength to short wavelength.
And we have three receptors, most of us, cone receptors in the retina that sample the spectrum.
And it's the activation, the relative activation between the three of them that gives us color
perception.
But if you think about this, and if that is your knowledge about how we perceive color,
you would not be able to explain this, which is that we can order color continuously.
So somehow this wraps around.
So how do we take a linear phenomenon and we make it circular?
Well, the answer to that is in the early visual system because of color-opponency.
So we have a cone circuit diagram that leads us to oppose yellow from blue and red versus
green.
They're literally inhibiting each other.
And that gives us two opposing poles, a yellow-blue pole and a green-red pole.
That gives rise to a two-dimensional structure.
So this is how we wrap that one-dimensional linear spectrum around in a two-dimensional
spectrum.
And in fact, this right here would only be a slice of something more complicated because
we can go all the way from black from complete darkness to white, complete brightness.
So this is not just a two-dimensional circle.
Each time I'm showing you a color circle like that, we're actually taking a slice through
a three-dimensional structure such as a sphere.
And we can do psychophysics on that.
So one thing we can do, for example, is we can take the color red and we can psychophysically
measure precisely with numbers the distances that exist between red and another color.
And then find out if that is a certain difference that people assign to that is the difference
between this red and this yellow or greenish color is that twice as large or three times
as large as this distance.
So that is very simple to do with standard psychophysics.
So we can actually, for each of these colors, we can come up with these distances and psychophysicists
do that, and it turns out it's not a perfect sphere where we see color.
It actually is this distorted space, this distorted color gamut that we perceive.
That really means, which is interesting, that if you map the distance of any point in here,
it's unique.
So you would not be able to take the green over here and then measure all distance with
all other colors and come up with a similar matrix of differences.
So the differences that we find for the color of red are unique for the color of red.
So in other words, if we just look at these arrows, what emerges is the yoneda lemma.
And this was first realized by Nao Tukia and his coworker Yato Saigo.
So remember, the yoneda lemma is that objects are fully defined by their relations.
I told you that relations are just the structure of arrows.
And that means this structure of arrows, this relation between red and all the other colors,
uniquely defines the color red.
This means everything I told you about the inverted spectrum doesn't make any sense.
Because if my perception of red would be over here and we would map all of these distances,
I would actually yield a different map.
It's mathematically impossible that you would have the exact same relation of red and all
other colors, but the spectrum is inverted.
That is what the yoneda lemma shows.
And so if you're more interested, more deeply into that, if you want to read the full formalism,
there's a white paper and a published paper on that.
I'm just going to point this out briefly.
So that actually is about it.
Another one of the, arguably, one of the greatest mathematicians, certainly one of the most
interesting mathematicians of the last century, was Alexander Kotendi.
And so he had this beautiful quote, the development of general abstract theory, so pure math by
abstracting away from everything, eventually brings with it effortless solutions to concrete
problems that if you take a nut and you can't quite crack it, but if you put it in saltwater
again and again and again, eventually it softens it up to the point that you can loosen it.
And with that, thank you.
