All right, it's our pleasure today to have Emily Pervoing from PNNL who will be telling us about applied topology for discrete structures.
Take it away.
So, I'm really pleased to be here to talk to you today about applied topology for discrete structures. This is the work that I've been doing with a large team for a while now, and really excited to share with you all.
So, I credited Cliff Jocelyn and Auden Myers on these slides who they may or may not be on I can't see everybody.
But really, it's a huge team.
Cliff and Auden helped me with a few of the specific slides so I credit them on the front but I want to acknowledge everybody.
I'm down here and you work with me I'm sorry I probably just missed people in my fray of looking for all the folks that I work with on this large pile of work.
But it's a great group and I wouldn't be able to talk to you today without all of these folks.
So just a little brief, I don't know commercial I suppose about the capability that we're developing that this work fits under at Pacific Northwest National Lab where I work.
This is we call it topology and networks.
We have mathematics of hyper network science hyper graphs and also computational topology and data analysis of multi dimensional data to include discrete things like hyper graph walks and connectivity I'll talk about some of those, as well as the computational
topology of homology and topological data analysis. We have software tool that we use frequently and we're in development all the time hypernetics. I encourage you to use that if you enjoy any of these graphics that are on this.
These slides, or if you are interested in the hyper graph work, particularly at the discrete level, but we're working on getting the homological stuff in there as well.
And we have a number of different kinds of applications I'm only going to be able to touch on a little bit of that in this talk, but if you're interested in any of these applications and learning more about what we do in this area, please reach out I'm happy to talk, give you some more information.
So let me dive into the to the meat of the talk so I'm going to put it into basically three sections starting out with hyper network science this is the discrete side of the talk.
I'm going to spend a bit of time here because I'm going to assume that most of the folks in this talk no more about the topology than about the discrete hyper network science. So I'll give some definitions there.
And then I'll talk about the topological interpretations of actually just hypergraphs in this talk.
And then close with some dynamics of topology. When when those hypergraphs are changing.
How do we measure those changes in a discrete way and in a topological way.
And I'll have some motivating examples throughout.
So, our work focuses, because we're applied science lab, we have applications so we, we deal with relational data very frequently.
This is when you have data in which objects and are related in a pair wise or multi way way so objects and the relationships between or among those objects.
So, one example is a publication database think math sign that PubMed your favorite publication database, you have objects that are authors, and they have relationships that are collaboration so if two people collaborated on a paper there's a relationship between those two if four people collaborated on a paper there's a bunch of relationships
between all those. And you can study how authors cluster based on their discipline maybe. Maybe there's bridge authors that work between areas of math.
Those are the kinds of things you might want to know.
One example is protein interactions or opera objects are proteins and the relationships are things like measured or predicted co expression or interactions between those proteins.
We want to study how again they cluster maybe based on function, or there.
Proteins that are more or less important in various systems. On the right here we've got a couple of pictures of the string database this is a protein interaction database and some network science co authors up here.
So relational data is really important but sometimes pair wise relationships as those were depicted on this slide here all of these edges.
We all know we're talking about graphs right vertices and edges are pair wise, sometimes those pair wise relationships aren't enough to capture everything of the complexity of the data.
So, I, we encourage people to think what is your data natively. Do you get groups or do you get pairs if you get pairs. Great. But if you get groups and you squash it down to all of the sub pairs, then you're losing some information so for example in a co authorship.
You could really think about it as multi way collaborations papers are sometimes written by two people but sometimes they're written by five people or nine people or 27 people, and you want to capture that multi way interaction.
Similarly friendship and following relationships. You know, on Facebook you have friendships right I'm friends with you your friends with me those are pair wise. You have following in on Twitter and other social networks.
But you also have group membership, and those groups are, you know, lots of people can talk and it's not just two people talking with each other it's the whole group is seeing it.
And so those are groups that are important to be modeled. And finally, here on this slide with protein interactions proteins don't always interact just pair wise sometimes you need three proteins or four or seven.
In order to have some relationship or some reaction happen and if one of them is missing, nothing happens. And so you need to have that complexity of the, the high order relationships.
And so if you need that, if you it's important to track the multi way relationships, then hyper graphs are the tool for you. So they provide this mathematical model of data.
When multi way relationships are the thing, and you can ask questions like connectivity and clustering, just like you can in graphs, and, and model these, these multi way relationships.
So, and I'm kind of purposely not not introducing graphs here I'm going to hope that everybody knows something about graphs but if you don't, if you're not familiar with graphs.
Don't worry about it. We're just talking about hyper graphs in this talk, and you can think of a graph as a hyper graph or every edge is size to so everything that I'm talking about for hyper graphs works for graphs.
And so don't, don't worry if you're not familiar with graphs, or networks.
So, my phone is buzzing.
So, you have a vertices vertices, the dots, and we have hyper edges, the big blobs.
And those dots what makes up a hyper graph the edges are all are any subset of the vertices.
So to just get a little bit more formal with this, a hyper graph.
Again has has vertices set V and a family of edges and specifically not calling it a set of edges, because sometimes we want repeated edges we want multiple edges to have the same membership the same set of vertices.
So every edge is a subset of vertices, you could think of it as a multi set as well. Typically, we think of it as that he sub I are the names of the edges.
And then you map those names of the edges to the set of vertices and for shorthand and just say that the edges contained within the vertex set.
And this is what I said on the prior slide a graph is a hyper graph where all of the edges have size to.
All right.
So, we have some special cases that we like to treat.
Maybe we have an empty edge, perhaps you had a group of people that were pretty active, but everybody left, or nobody showed up or whatever that's that would be an empty edge and that's allowed in a hyper graph multi edges edges I already mentioned, isolated vertices.
Not in any hyper edge, these are common in graphs as well, and redundant vertices these are two vertices, which are in exactly the same set of hyper edges this this does not happen in a graph, unless you have a multi graph.
So these are special cases that you have to treat when you're thinking about hyper graphs.
So here we've got ways to represent pictorially or or in data structures visually Euler diagram is what we're going to focus on in this talk sometimes we'll see the central diagrams but in a very special case later.
So we just put the dots down on the page and we draw rubber bands around all of the vertices that are contained within an edge so here we've got a singleton edge and a three way edge and then three pairwise edges.
This diagram is another way of looking at hypergraphs by putting all of the vertices of the hyper graph on the left and all of the names of the hyper edges on the right, and then connecting a vertex to a hyper edge if there's a containment.
And this is, I'll say something more about this on the next slide incidents matrix is another important structure, often for computation.
We have our rows as vertices and our columns as hyper edges, and we put a one or a zero depending on the membership.
And then sometimes we'll write as set notation.
So that's the basic definition of what a hyper graph is any when we pause for any kind of brief questions about the definition.
Nothing.
Alrighty.
One, another thing that's special about hypergraphs is this notion of duality so on the prior slide I mentioned that we have this incidence matrix where the rows are vertices and the columns are hyper edges.
I could have switched that matrix I could have transposed that matrix and gotten an entirely different hypergraph but the same sort of underlying structure and the exact same underlying bipartite graph representation.
And so we want to think of hypergraphs not as just a hypergraph but as a dual pair because these are mutually defining right once you have the hypergraph the dual to it is unique and vice versa.
So, think about hypergraphs as dual pairs it's a choice of which rows or columns you make to be the vertices or the edges.
There are also graph approximations of hypergraphs that people use very frequently.
The first common would be this, we call the clique expansion or the underlying graph. It takes every vertex of the hypergraph puts it down in your graph, and puts a clique for every hyper edge so this is a three way hyper edge you get this clique here.
This is a two way hyper edge you get this to click on this to click, but notice that you've lost that three way interaction, these two triangles are now indistinguishable if you forget where it came from you can't tell where there might have been a three way relationship.
Similarly, you can do the clique expansion of the dual turns out this is also known as the line graph of the hypergraph, where for the original hypergraph you put down a vertex in your line graph for every edge that's in your hypergraph so that they're color coded should be color coded
correctly. So edge one here the yellow one is this vertex here and so forth. And then you put an edge between these hyper edge vertices.
If there's an intersection between the two hyper edges. So you get this underlying thing, but notice that this is exactly the clique expansion of the dual and that'll come back a bit later in the talk.
Emily. Yes, there was a question by Sayed.
Sayed is asking what is the importance of empty hyper edges, and what does empty hyper edge corresponds to the importance of an empty hyper edge is more for understanding your data.
And I think about it, kind of in the case of dynamic data which we'll get to at the very end of the talk.
Let's say you've got a Facebook group or a Reddit subreddit.
It's pretty active, right, maybe there's a lot of people that are talking but then some period of time passes, and nobody's posting and not subreddit that would that subreddit still exists, but nobody's talking in it.
And so it would consider you can consider it as an empty hyper edge you could also just consider it as gone, but, but it's not gone it's it's available for somebody to use later.
So help.
Hearing no objection. I'll say that that's good.
All right.
So, so one thing that I want to say about these graph approximations is that you might think, oh, well, great if I have this hyper graph, I can just do graph theory stuff on its click expansion and it's line graph those those must be determining just like the dual is is determining
the graph and vice versa, you must be able to determine the hyper graph from its click expansion and line graph. This is not true, unfortunately, there are examples and not all that big, where you have two completely different hyper graphs that have the exact same click expansion
and line graph.
You really need the full hyper graph to, to study those multi way interactions you can't go, you can't find a graph approximation, besides kind of a bipartite graph that will completely determine the hyper graph.
Because of that, we need to generalize network science concepts to hyper graphs. And so we do that in fairly straightforward way, degree is the number of edges at a vertex edge sizes, well in a graph it's always to but in a hyper graph we can think of what are all the edge sizes in my
graph paths walks diameters connecting component centrality all these things can be
thought about and generalized from graphs to hyper graphs. I'm going to dive into these, these three here for a moment here to give you an example of where it's not quite so straightforward, but it generalizes pretty nicely and this is all
the hyper network science via high order hyper graph walks that was led by synon oxy. It's a very lovely paper in, I think, and if you're interested in this kind of hyper network science stuff I really encourage you to check out that paper.
So, in a graph, if you have a walk, you go from a vertex to an edge to a vertex to an edge, and so forth, back and forth.
You can think about that as a sequence of just vertices, because unless you've got a multigraph every pair of vertices have has a unique edge that they are in right.
Similarly, you could think of it as a sequence of edges because every pair of edges has a unique vertex that they intersect in so they're mutually determining for a set of vertices gives you a set of unique edges and vice versa.
In a hyper graph, this is not the case, I can have two vertices, these two vertices here that belong to two completely different hyper edges. This is not a multi hyper graph.
And E one and E four are totally different hyper edges.
I can have two hyper edges that intersect in many vertices. So if I have just a sequence of edges it does not determine a unique sequence of vertices. And if I have a sequence of vertices it does not determine a unique sequence of edges.
So you need to have two notions of walks, one between edges and one between vertices.
In the next few slides I'm going to focus on the edge walks because they for me they're more intuitive, but the vertices vertex walks you can define actually in the dual sense.
So, we come up with this notion of an S walk this is a sequence of edges, such that every pair next to each other has to intersect in at least s vertices.
So a one walk is a typical graph walk every pair of edges intersects in at least one exactly one vertex.
But the nice thing here is that you can kind of get a strength of your walk, but or a width of your walk by increasing s. So here's a graph walk where every pair of edges intersects it when size one.
So here's a graph walk with the same property interactions, weak interactions you would say with one, but over here, I might think that be and I and J are a little bit more related than on the left hyper graph because there's so much intersection between the different
more potential for inner intersection between be and I and J.
So, once you have a definition of a walk, you can define a path distance and components from it that's how you do this, you build it up in a graph to go from a walk to a path and so forth.
So we can do that with S walks as well, an S path is an S walk where edges are not repeated so here's a S walk from five to three to one back to five to 10 to 12, I can get rid of that so that loop here and just turn it into a path.
So five to 10 to 12. This is a one walk or one path rather. Now if I add in these two edges, the maroon ish one and the blue dark blue one. Now I have a two path from five to 12 because all of my intersections are size to know
the distance then is the length that's the shortest S path between two edges, the diameter is the longest S distance in the hyper graph, and the components are collections of edges so that any pair are connected via an S path.
So here's a three component. These two edges, brown and pink intersect in size four so that's a three component. This is a two component. There's any pair of edges you can choose within this dotted line.
And finally, you can define centrality. So once you have a notion of walks and paths, you can end diameter and shortest path, you can define between the centrality. So in a graph up here so that the question is, which nodes are on many
shortest paths in the graph it's a node based question. And so given a vertex you sum up overall pairs of vertices that are not itself and ask how many shortest paths are there between S and T on the denominator and then in the numerator how many of those
shortest paths go through V. So, if this is a close to one then that means that V is very central and if it's close to one for all of the pairs S and T it means it's very very central.
And so the higher between the centrality means it's on a lot of these walks so the red nodes in this graph are the most central and then the ones on the periphery here are lighter colored they have lower between the centrality.
You can do the exact same thing in a hypergraph for a hyper edge E, you look at all of the hyper edges G and F that are not E, that are at least size S, and asked the same question about shortest paths.
So we did this in an example in biological data.
We had cells infected with viral strains of these five viruses and we, we didn't actually collect this data I should say this we were handed this data samples were analyzed at various time points post infection, and looked at which genes are expressed more or less than a control
So we created a hypergraph where the nodes are conditions a condition means a virus, a strain of that virus, a cell type, a time point, and then you sample and you get all of the gene expressions for that particular condition or that particular cell state.
Those are the nodes of our hypergraph, and the edges are genes those things that we're measuring the expression of. And we say, you can read the description down here but I'll say it a little bit differently that a condition vertex is contained in a gene hyper edge.
If that can, if that gene is significantly perturbed from the base from the control in that condition.
If a vertex is not in a gene it means that that gene is really kind of not moving not doing anything between control and the current condition, but if it is in a gene hyper edge that gene is significant doing something significant in that particular condition.
And we want to study the structure of this hyper graph, in particular we wanted to find the genes that are central in viral infection.
So we, we hypothesized that if we compute hyper network science measures particular between the centrality and closeness centrality which I didn't describe this up to find.
Then, and I look at the ranking so what are the most central down to the least central.
The immune response will be higher, more concentrated towards the top of that list, then if you build a graph representation.
And we measure this using this thing called enrichment score. So if I have my ranking so this is high between the centrality low between the centrality and a target set of known immune response genes.
If the things are kind of distributed more towards the top we have a high enrichment score.
If they're more towards the bottom which is what we don't want we have a low enrichment score even negative. And if they're kind of uniformly distributed through my range list we get around zero.
And so we, we did this we built this hyper graph and we measured the rankings from hyper graph between this closeness hyper edge size really simple measurement.
Some graph measures and then a measure that's not graphy or hyper graphy.
And what we found is the enrichment score measured here on the y axis is much higher in all of our hyper graph measures then in any of our graph measures.
In fact, yes, the hyper graph does give us a better ranking things that are more known to be more central are in fact more central in in the graph, or in the hyper graph than they are in the graph.
So that was a nice win for our hyper network science theory into into some real practice.
So, at this point I'm going to pivot I've hopefully I've convinced you that hyper graphs are both useful and interesting mathematically.
But of course this is an applied topology seminar so I'm going to talk about topology.
Yes.
There's a question on our chat by Alex.
I'll read it and I think it might be related to couple slides back. Is there a way to describe this as applying a threshold to entries in a matrix might have been on slide 16.
That's my guess, but I was, I was just asking about the genes, the state versus gene.
I was hoping that there was a way that I could wrap my head around it as I have a giant matrix and a threshold. Yes.
So this is the, the, like, the matrix you can think about.
So we have our, now I've flipped it so my vertices are on the columns and my edges are on the rows.
These are the actual values of, of my sample versus control log two of the sample versus control so positive means it's up regulated negative means done regulated.
And what we did here is we, we applied a threshold, we took the absolute value applied a threshold, and we said, okay, if it's above Z score above two, then we put a one if it's below two we put a zero and now we've got an incidence matrix for hyper graph.
Yeah.
Thank you. Yeah.
Okay, so jumping into topology and in this case, I'm not going to define things like some official complex. I'm going to. But if somebody does not know a simple complex do please jump in.
And I'll go through a quick definition.
But I'm hoping that in an applied topology seminar we have majority of folks that have that background.
Or if you don't, you'll kind of get it from the description.
So, how do we interpret a hyper graph as a topological object, we've talked about already so far how we interpret a hyper graph as a discrete object, but a topological object is a bit different.
One thing we can do is build a simple complex from our hyper graph so here's a hyper graph it's got a three way to three way edges and a four way edge.
We can add in all of the sub edges to my hyper graph so all of the singles and vertices are hyper edges all of the pairs are hyper edges all of the three ways that aren't already there are hyper edges.
And this kind of hardens my hyper graph into a simple complex, this tetrahedra with a triangle attached to it a solid tetrahedra triangle attached to it in this particular case.
So what we're doing here we're adding information, right. I said at the very beginning of this talk.
We might have a case where a three way edge really does not imply the pair wise edges, particularly like in a protein interaction at work, the pair wise things might not be real interactions we're adding information is somehow is not satisfying to me at least.
We can do something that's a bit more complex we can build other simple complexes, or chain complexes without adding or removing information, at least that's what the hope is. Okay, so I'm going to talk only about the restricted very centric subdivision that's all I think I'll have time for in the in this talk, but there are
a number of building some additional complexes from hyper graphs that aren't just adding in all of the sub edges that might capture additional structure. And that question then is what hyper graph properties do each of these different interpretations capture.
What do we want them to capture what do they capture.
The specific thing that we're going to be used to study the topological structure is homology. So I will say a little bit about homology, given one of these topological objects and plus your complexes.
We want to look at what are the different voids or holes in different dimensions in dimension zero a whole is a connected component.
Noted noted as Betty zero is the number of connected components. Betty one is one dimensional holes, these are cycles or loops.
Two dimensional are like soccer balls hollow, or hollow tourists or anything that's hollow, but bounded by a two dimensional surface and then three dimensional is the higher generalizations of those kinds of holes.
So some examples of three hypergraphs, where if you take the simple shell complex of those hypergraph you end up with some simple shell complex, and all of them have one component.
All of them have at least one one dimensional loop you can really only see it here in DNS one I have no idea where the loops are in two and three.
And in in two and three there's at least one void, which in three I've got no clue where it is in two at least we've pulled out this is where one of these voids are we've got three solid tetrahedra with like a kind of window pain stuck on the end to give a hollow tetrahedra here
between these four and so this is data from a cyber network, where IP addresses resolved to different domain names.
And so this is the DNS hypergraph.
So this is the tool we're going to use to study the simple shell complexes that we build is is homology.
Let me step back for a moment and ask this question. What was it about a hypergraph that we want to capture using homology, rather than just willy nilly building any kind of solution complex that we want let's ask this question of ourselves.
One potential answer is that we want to study the structure of interactions among the hyper edges. If that's the answer that you have to this question, then the nerve complex might be what you're looking for.
We put a nerve for every hyper edge every blue hyper edge we put a vertex and every multi way intersection among the hyper edges we put a simplex.
So in this case our nerve is just two to one dimensional, there's only hair wise intersections, but that's not necessarily the case.
What's interesting, and I said this earlier, is that if I take the nerve of my hypergraph. It's exactly the same as the simple shell complex closure of my dual hypergraph so here's a hypergraph it's dual.
The nerve and the closure are equal they're not isomorphic but not, they're not homotopy equivalent well they are but they're not just isomorphic they're not just homotopy equivalent they are equal.
So, if if the homo and then the Dauker theorem tells us that the closure of a hypergraph and the closure of its dual are homotopy equivalent.
So, if what you're looking for in homology of a hypergraph is the structure of interactions among the hyper edges, that is, the homology of its nerve.
You can actually get that information at least the Betty numbers by looking at the homology of its closure, and just stopping there. So when I said we're adding information to this hypergraph by adding in all the sub edges.
So, but if you're just looking for the shape of the interactions, you could, you could do that with the shape of its underlying.
Well not underlying graph but underlying simple shell complex.
Okay, so I just want to point that out but if this is not the answer to your question, the structure of interactions then let's proceed.
And I optimistically told Henry that I only had 35 minutes of content and here I am at 33 minutes and we're not done, but I will not take the full hour, promise you that.
So, restricted very centric subdivision is a concept that that was developed by a group of of us. I subgroup of the folks that were mentioned on that first slide.
To give another interpretation of, and I'm not naming them all because there's seven or eight of us and I'll probably miss somebody.
I think I have the name somewhere on a different side. So, the restricted very centric subdivision is a different way of creating a simple shell complex from a hypergraph.
So, the very centric subdivision of a simple shell complex takes each face and replaces it with a vertex so that AC edge is a face or replace that with a vertex the ABC face is a face triangle.
I put a vertex there and then I connect all of the sub faces so AC is connected to ABC is connected to AC, so forth, and then I take the clique complex of this one skeleton so because a is connect is contained in AC which is contained in ABC.
I put a triangle here, so that's the very centric subdivision of a simple shell complex.
But what about how we do how do we do this for a hypergraph when we don't have, it's not a simple shell complex right we could build the simple shell complex but we already said we don't want to do that.
We figured out what that means and we want to do something else.
So what we want to do is we build the edge containment post set. So, edge C is contained in BC, which is contained in ABC, it's also contained in CD.
And then I can take the clique complex of this post set. So, note that this is just the Hossa diagram. See is actually also connected to ABC because there's a containment order there.
So when I take the clique complex, I get a triangle here for the left chain, and a single edge for the right chain.
And notice that, if I took away the labels of this hyper or of this simple shell complex, it would be exactly the same as the closure of the, this hypergraph the simple shell complex closer.
Right, so maybe you're thinking, or what did we do, but if you remove edge C, then that becomes not the case. The simple shell complex closure remains the same a triangle with a tail.
So if you remove edge C, the restricted barycentric subdivision becomes just two edges, BC connected to ABC and CD all in its own.
I also wanted to point out that this is the viatorium seminar and clique complexes are the torsion complexes. So, I qualify for this seminar.
Yay.
So what structure do we capture with this notion of a simple shell complex coming from a hyper graph.
One thing is to note that intersections are not preserved, unless we have them present as hyper edges so, noting that again if, if C were not a hyper edge in its own we'd have two different components, even though the hyper graph in the notion of a walk sense is in fact connected.
And so that's one thing that you're capturing is kind of the ability for you to transit through intersections by virtue of another hyper edge.
So the easy, it's fairly easy to show that the number of connected components in your restricted barycentric subdivision is bounded above by the number of top lexes, which are hyper edges that are not contained in any other hyper edge so that ABC hyper edge here is a top
lex, the CD is a top lex, but BC and C are not top lexes. So this, the number of components is bounded above by the number of top lexes.
And it's sharp if there are no hyper edges contained within a top lex intersection. So that's one structure thing.
Another thing is looking at the one dimensional and two dimensional voids and how we can get those.
These are all one dimensional cycles that would be present in a hyper edge if you look at the labels of the vertices here. Those are the names of the hyper the sets of the hyper edges.
And so what we notice is to get one of these one dimensional cycles we have to go containment and then contains containment and then contains so one is contained in 124, which contains to which contained in 123 which contains one and round and round
So that is how you get one dimensional cycles you need this reverse back and forth containment, which means you can only have even length cycles which is kind of interesting. If you have a, even like open cycles, if you have a triangle it must be filled in.
You can also get higher order higher dimensional homology by this. This is here's an example of a hyper graph that has two dimensional void and it's restricted very centric subdivision.
Remember these triangles have to be filled in because of what I said on the prior slide. This is the post set diagram and we see, we can see how we get from the hyper graph to the edge containment post set to the octahedron.
And notice that what we're basically doing is taking a cone and a cone and putting it on our prior cycle.
This is a suspension in a topological sense where we take something with homology and dimension.
Okay, and add a cone off that dimension k homology and end up with something in a homology in dimension k plus one.
You can do this in the simple complex land but it turns out that those, when you do that suspension, you, you can pull it back to the hyper graph and find out that there is in fact a hyper graph that has that suspension as it's restricted very centric subdivision.
So here's the example again on the prior slide of taking a cycle and coning it off to get octahedron and two dimensional void.
In the in the hyper graph sense where what we're doing is we're taking what we had. So here's our one dimensional cycle, going from hybrids two to 123 to one to one to four back to two.
That's our one dimensional cycle in the restricted very centric subdivision in order to make the octahedron we added two hyper edges and two vertices.
We added five vertex six, and then we added hyper edge that contains five and everything else that was already there. And then when it contains six and everything else that was already there.
This serves as the two top bounds.
So here, of my post set, which cones off everything below it so we're adding this purple vertex and all of the simplices with all of the prior simplices and the F vertex plus triangles with all of the previously existing simplices.
And again, so every time we want to increase the homology of our restricted very centric subdivision. All we have to do is add two new vertices and two hyper edges one that contains the one new vertex and everything else one that contains the other and everything else.
This will cone off our, our homology. Notice that if I were to create the some partial complex. It would be not terribly interesting here. It would be, you know, two, two large simplices, completely filled in with the intersect very highly.
And that's all it would be. We have no higher order fromology but in this way we can create arbitrarily higher order fromology in in a hypergraph, which gives us kind of a new tool to explore the intersection structure of these hypergraphs.
So, I am going to move on to the last part of my talk which is not super long about dynamics.
So, just kind of roadmap where we are we talked about the discrete part of hypergraphs we talked about homology of a single hypergraph from this partial complex, and this restricted very centric subdivision.
And then I'm going to talk about evolution. So let's say I've got a, when we call it temporal hypergraph we can think of all of these. These are vertices that are entities and hyper edges that are events entities and events so an entity is part of an event.
Then they have a hybrid. But what if there's a time stamp on each of my hyper edges that events happen before or after each other.
We can think of them a trajectory of sub hypergraph so if I look at only the time span between four and five. I have these 123456 hyper edges. If I go then forward in time, I've lost one or a couple of my hyper edges and I've gained a hyper edge and so I have this temporal evolution of my system.
What we want to do is measure the change in structure of this change in homology the change in other kinds of distributions in our system.
We can do that in a discrete way by looking at edit cost. This is something again borrowed from graph theory. If I've got two graphs, I want to quantify how much work I need to do to turn one into the other.
If I am given a vertex map like saying edge vertex a maps to this vertex B maps to this and vertex C maps to this. I get an edge map for free the green house to map to the green blue pink so forth.
So that's, you can think of the edit cost of this mapping from ABC to f of a b and f of c is is a cost of two because I have to remove one edge and I have to add another edge.
But I could find a better mapping of vertices that would give me an edit distance of zero if I instead mapped aids up to this guy and B and C over here, I could get an edit cost of zero.
You can do the same kind of thing in a hypergraph but it's a lot more nuanced because you need to specify not just vertex maps, but edge maps. So if I map the vertices from this left hypergraph to the right by name so a goes to a and so forth.
You could make an argument for either of the sets of colored arrows for edge maps so this BCD edge could map to the BC edge, or it could map to the ACD edge you could make an argument either way.
So you have to have vertex and edge maps, and then edges have size not just existence so if you remove a vertex from an edge.
Is it still the same vertex if you just leave if one person leaves a subreddit subreddit is still there right so so you can remove things and add things, depending on the rules that you provide.
There's about three different kinds of edit cost frameworks one where you can remove wholesale a vertex or an edge, and it's just one edit costs one one operation.
That's right that's the collective edits individual edits says, if I want to leave a system I have to say goodbye to every group individually and then I got to leave so that's all of these different edits.
And then there's cases where you would want edges to be immutable. If I change membership if I lose if my edge loses somebody. Now I'm a completely different system.
So all of these are valid in different kinds of applications. What else is valid is topological measurement.
So this is in the case. We're going to talk about zigzag persistent homology persistent homology has a case of a sequence of spaces where one is successfully contained in the next and I track when a cycle or any of these topological objects cycles voids components appears and disappears in my sequence of containment.
There's a general generalization of this which is the exact persistence that has arrows going either direction.
And, but you can make an arbitrary case where you have just a sequence of spaces these are going to be temporal sequence of spaces, and you can put in unions and interest or intersections to get one of these general case where the arrows go in, in both directions.
And still look at when cycles or other topological features are born and die but now it's not.
Well, it's still like what space, you know, did I was it space one space to space three or one of these half spaces at which these things are born and die.
So as an example here's a temporal sequence at the bottom of some partial complexes and we want to know if features persist over time so here's a two components there's a loop what what kinds of things persist.
We have time stamps on either of that and all of them at an empty set at the end so that everything dies. And then we compute this persistence zigzag persistence diagram that tells us that this single loop here is born at time to it's still there at 2.5 and it's it dies at three.
So we have a one dimensional tracking of that loop, and then the single connected components as well can can be tracked so starts off with two, and then turns into one and at the end we get to again.
So a final example is, I've been alluding to Reddit data kind of all along is one of the hypergraph examples, but here's some actual data of COVID subreddit from early in the pandemic, the end of January to the end of March, and we have
almost 4000 threads, and almost 2000 authors so we're going to have a node as the author and the edges are threads. So if an author posts in a thread, then there's then it's in that hyper edge.
And there's a bunch of different subreddit so we just look this is just looking at one of them as you look at all of them and getting even bigger system.
So at the time here we're tracking the size is the number of vertices in the hypergraph for a two hour window shifted forward by one every one hour, and the number of edges. This work by odd admirers by the way.
And then we can look at you know where these subreddits come in at what time.
So what is the zigzag homology tell us.
And here we have tracking the one dimensional loops and the connected components over time so there's some interesting long living connected components that aren't just the obvious this one that's there for the whole time.
We have some long living ones I'm not sure what these threads are but there it's worth looking into what the threads are that persisted for so long.
So what are these loops really mean here's some pictorial examples of a hyper graph and it's special complex picked out just from one of these times.
And then we can compare that to this edit costs of the different kinds of at cost individual collective immutable these are normalized by the number of vertices and edges.
And really seeing much of a pattern much of a correlation here. And that's kind of where we are. We are going to leave you with this kind of open question of, how do we tie some of our topological measurements to our discrete measurements.
If, if at all, are we, or are we getting something completely different. And I think mostly we're getting something completely different.
But, but there are some ties that we see. So just to put it all in one slide take home message that discrete relational structures are really prevalent when modeling data hopefully, if I've convinced you of anything it's that it's graphs and hypergraphs are really prevalent when
modeling real data either static or dynamic and the discrete network science can provide insight into these but there are interesting topological properties or at least there are topological properties and we think that they're
they're available and starting to really be explored.
But there's a lot of open questions still. How do we interpret the topology that we're discovering in these discrete structures. How do we tie it back to the real data. And this is where we really need partnerships between mathematicians and subject matter experts those people to tell us.
Well, you found this loop and I could tell you what that means in the case of a biological system or a cyber system or a subreddit.
And, and that's, that's where I'm going to leave it and leave it on this slide and I'm not going to stop my screen share because I'm afraid that will crash soon. So, I'll take any questions that there might be.
I suggest we unmute ourselves to thank Emily for a wonderful talk.
I can see there were two comments or questions on the chat window.
And feel free to unmute yourself and you know, make these comments allowed.
Yeah, so people have been quite active on the chat.
I'll wait for a couple seconds if not I'll start reading this.
I'll ask one. Yeah, go ahead.
Hi Emily it's Steve Huntsman.
Thanks for the talk. You guys.
Thanks to go put it out of paper on top logical analysis of temporal stuff. Yeah, you were working with the opti see data at DARPA. Yes.
And I have some experience working on on TC and I was curious if you guys thought about doing sort of Dauker style things for hosts versus processes, or hosts versus users I say I'm like like the sort of data that Los Alamos put out.
The short answer, I think is yes we've built a lot of different hypergraphs and topological structures from that opti see data that paper really just scratched the surface, and we're diving into it a lot more in a different project so I think.
Stay tuned. We were really turning over and over and over that that data from a hypergraph and a hypergraph topology perspective.
So, yeah, yes, I think.
I think the doctor stuff is likely to bear fruit for stuff like for bona fide, like malice or, you know, true anomalies. Right. Like, say if you have like one, one, you know, APT sort of the person they're going to try to establish multiple
footholds to get to a certain place and all of a sudden you've got like one homology. Right. Right.
Yeah. And, and yes I think we can see some of that stuff.
The, another yet another project we are looking at some Dauker stuff as well so I think it's it's coming together and maybe we should chat over an email thread to to brainstorm a bit but I think we're definitely thinking along the same lines.
Thanks.
See there's a bunch of stuff in chat I'm not sure what I should.
Let's see.
Are there any more questions for comments I mean people should feel free to unmute themselves and.
Let's see.
I have to to little things.
So I guess one is, I'm reminded of a talk that I heard by Michael Erdman, a while back, looking at the topology of privacy, which I think, which, which was very similar, I mean, it was dealing with the same basic problem or not the same basic problem.
The basic structure of, you have, you know, say test subjects and conditions, and, and you want to minimize the chances that someone looking at the table of anonymized test subjects and conditions can infer who the person is.
Okay.
So you've got a, so you've got a hypergraph or a post that you know everyone to think about it. Yeah.
That's just something I thought of, but I've been doing a lot of work on essentially hypergraphs, but looking at the, the, essentially, the equivalent of a Stanley reason or ideal for a hypergraph, where you take you you treat it as a you treat your
hypergraph as a variety in F2.
And then the appropriate ideal is generated by pseudomonomials so it looks like a monomial ideal except that sometimes instead of xj you have one minus xj.
And this turns and there's been a lot of work to try and take that and like find say a free resolution which would give you the Betty numbers.
And now wondering if I'm wondering which of the complexes that you have talked about today that you built out of your hypergraph might be encoded in this way.
Yeah.
Um,
those are not interpretations that I'm familiar with. I mean, I know, polynomial, polynomial ideals and rings.
I want to think more about the specific construction that you're talking about to see if there is a connection. One thing that that is worth pointing out is that there's a slew of these interpretations of hypergraphs as topological structures, right.
Yeah, you.
Once you think you've come up with all of them you can come up with another defensible one, and it's going to capture something else about your hypergraph.
And so it could be something that we've already looked at or it could be something totally different and capturing yet a different lens or did let you get a different property of the underlying system.
Yeah.
So, yeah, I don't know, but I'd be interested to explore it.
Yeah, I'll maybe send you an email because this is stuff that I'm actively thinking about. Also, I've got some hypergraph problems that I need to look at.
Sure. Yeah, love to connect. Thanks.
Emily, on your like first or second slide there were these two versions of what looked like making these relationship matrices that describe these into square matrices.
I saw one that took away the, the identity in the middle.
Yeah.
And I'm wondering what those get used for some sort of like a spectral decomposition or something. I was talking about these. Yeah. Yeah.
So,
excuse me.
Yes, they.
Well, they're, they're the adjacency matrices, the weighted adjacency matrices of the underlying peak expansion and line graph.
Oh, so yeah, that's exactly what these are. You can think of them in your favorite way either pictorially set wise or in this linear algebra sense.
So, and I don't want to say anything false, but I believe these would be the two to one dimension, one dimensional boundary matrices if you were to
know that might not be true. No, that's, that's not true.
But yeah, these are adjacency matrices so you can start doing spectral analysis.
All that.
And they're weighted.
Yeah, yeah, that's what I was wondering because you know I'm not normally used to seeing those as just ones of course because they're graphs.
I mean, is that something that people commonly do and get use out of in the case of hypergraphs.
The waiting here, or the, or the like doing spectral decomposition on this kind of stuff.
Oh, there.
There are works out there on well like hodge decompositions of related to hypergraphs and some pleasure complexes.
I know those are people get use out of those.
And I believe the answer would be yes for spectral.
For that you probably want to ask more.
My colleagues and on x away and Steven young. They are graph theory folks and they work heavily with spectral analysis and I believe they are looking at some spectral to compositions of
these kinds of interpretations, but also looking at what you can't see, because, as I mentioned, you know, the, even if you have this matrix and this matrix, even if you have the weights in the two matrices, not just the underlying
graphs but the weights as well.
You can't recover the full hypergraph. So, you can get information for sure, but you're not.
You're not narrowing it down to a single hypergraph you might have multiple hypergraphs that are consistent.
Yeah, that's interesting I wonder what the extensions are there hey thank you. Yeah.
I'm stop recording but let's thank you very much for the for the talk and but if people want to stay stick around for a few more minutes and have additional comments for questions, please.
Thank you.
