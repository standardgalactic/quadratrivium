So I'm going to just give like 20 minutes of introduction about what are you
going to hear in this series of four lectures. And then, so in the beginning
will be a pretty vague but then I will define everything a bit carefully. So
the goal of my course is to tell you the link between two apparently separate
field. The first one is about the study of simple random curves. They have their
called Schramm-Lovner evolution. And originally it's called the Stochastic
Lovner evolution but it's introduced by the Schramm and later people just
replace the Stochastic by Schramm. That's why you see S before L. So it will be
denoted by SLE and there will be a parameter kappa which is a positive
number. And where it arises from originally comes from studying some
simple random curves in Stochastic Mechanics models. For instance, if you
look at in the critical easy model, there are plus being minus being and you look
at the boundary in between the two clusters and it has to be a simple
curve and they should be pretty random. And think about there's a loops they're
more or less fractal and depending on different models there will be the
number kappa will be different. And for easy this will be kappa equal 3 and it's
only about at the critical temperature. Alright so this is coming from second
Mechanics model and always we will be only looking at the 2D second Mechanics
models the curves will be always dimension 1 and well their house of
dimension will be larger than 1 however. And so that's you can imagine because of
the coming from the critical Stochastic Mechanics models there will happen to
have some conformal invariance. So it's closely related to a conformal field
theory and there is the central charge which would be a function of a kappa.
It will be a number which is less or equal to 1. Some explicit formula like that.
And where it also arises from coming from a random conformal geometry and objects
of interest such as random surfaces, random planar graphs, Brownian maps and
simple random walks on surfaces etc. So these are studies of geometric objects
which will be a random but also has a very nice probability under conformal
mappings. Okay so this is the realm of the first world and on the other side I
will be looking into something called the Vapeter's entitlement space.
It's a Vapeter's universal entitlement space.
And the universal entitlement space, this is denoted by T1 and it can be realized as a
homogeneous space of quasi-symmetric homomorphism of the circle when you mode
out some subgroup of Mervis transformation of the circle. So these are
homomorphism of the circle under modulo some Mervis transformation. And Vapeter's
a universal entitlement space is something which is in between of this
universal entitlement space and there is a subgroup of this quasi-symmetric
homomorphism. There is the infinity smooth homomorphism of the circle.
And this is the one that we call Vapeter's entitlement space. And that's the one that we're interested in.
And where does it come from? In fact if you just think about this
the homomorphism group is an infinite dimensional group and you can think
this as the group which parameterizing closed circles, closed strings. And so
actually even in the beginning is actually some string series who are
studying who are interested in the geometric properties about this
homogeneous space. Maybe James just cite Bovic Rajiv and also the study of this
quotient group. It's also by Kurelov Yulyev in the early 80s. And they have shown
that on this homogeneous space there exists a very natural complex structure
and for which there's a unique Taylor metric on this space which is will be
invariant under the action, the right action of the defense one. And somehow
there is a very natural group structure on this on the group action on this
space and the metric will be invariant under this group action and that metric
is more or less unique up to a scaling factor. And then it was but yeah right
and then it was Nagin Fyovsky, maybe I'm just right down, who says that okay
this metric that the string series are looking at is actually can be put into
the Tajma theory in a very nice way and this metric you look like it's very much
look like the vaporization metric on the on the compact surfaces. So here that's
why this name of vaporization comes from and this space will be the closure of
this space under the vaporization metric. But to make this everything a concrete
and precise this is by work of Takhtaijong and tail. Okay so what are how these
two things will be related so this is the this one and here is the SLE. So the
goal of my talk on my course is to tell you that they're still connected by a
same object called the Love-Know energy. So what is the Love-Know energy? I would
be denoted by iL of gamma, gamma a Jordan curve inside the Riemann sphere. This
will be a quantity which is always larger or equal to zero it can be infinite.
And this is a quantity which is zero if and only if gamma is a circle and also
invariant under Mervis transformation of the sphere by PSL2C. And sometimes it's
saying that this is the energy which is measured how round this Jordan curve is.
And the relation to SLE is that this is so-called large deviation rate function.
So when kappa goes to zero. So this energy is measuring how likely this SLE to be
staying close to this curve and the SLE would really like to stay close to a
round circle but however if I have another curve this probability is going to decay
to zero very fast but with a certain rate given by the Love-Know energy. And on the
other side this energy they also by the work of Taktajong tail they show you
that they define something called a universal ideal action S1. So Vantina 1 to R they define
something called it. And this is also a number which is a positive. And they show that this
quantity they defined is actually a scalar potential for the Bay-Petersen metric. For
being a scalar potential in some sense it's a scalar function which characterize all the
information you need to know about the metric by taking two derivatives you can
obtain the metric itself. So this is a fundamental quantity which is defined
only on the space in the middle and is tightly related to this unique scalar
metric already you can be observed under this smaller space. So the main
connection between these two fields is that in fact this Love-Know energy is exactly equal to
this universal ideal action. Up to actually a factor of pi but there's a lot of constant
normalization so just put it under the rug. So the goal of my talk would be just to show you how
this equality is shown. And since it's an introductory course I suppose not everyone's
probabilist. So I will start by telling you why we care about SLE and what this large deviation
mean and why everything on the probabilistic side is very very natural to define this Love-Know energy.
And then I will show you this equality hold, why it's hold. And another mention is that in order to show
this identity we need to go through something called determinants of Laplacian and in order to
define it, if this is don't care so much how it is defined but we were to choose a one special way
to call the zeta regularization. Determinants of Laplacian and these zeta regular determinants of
Laplacian will relate this quantity and this give you a bit of intuition about why I would try to
give you the intuition why these two things are equal through the determinants of Laplacian.
Another mention about the current research which has been very active is to study the
class of Jordan curves for which this Love-Know energy is finite or for which this universally
of action is well defined. It's not all the curves would have finite Love-Know energy,
it's a relatively small class. If you have the Love-Know energy of the curve is finite then
this curve will be rectifiable. They have a well-defined length so it's a pretty smooth.
And in fact there are now currently more than 20 equivalent descriptions. It might not be too
fair to count different definitions as being different but just to show you there's many
ways to just to determine for which curve this is finite has finite Love-Know energy. For instance
one of the characterization that you see is using this large deviation there are some characterization
using some spectral theory. One can associate a certain operator to each of the Jordan curve
called Gransky operator and that operators if it's Heber Schmidt if and only if this curve
is Vape-Pederson. This curve if it's finite Love-Know energy we call it Vape-Pederson
quality circle. And there are a lot of different characterization of that and so it has been
actually very active. And also recent work by Chris Bishop is also showing you there is a certain
holography of this class of Jordan curves we can be characterized in terms of minimal surface
embedded in hyperbolic three spaces.
Okay. So this is roughly an introduction. Are there questions?
Yeah. So what's the rate for the mass deviation? This is the rate function.
Because you mentioned rate function so I just curious but what's the rate?
Yeah, I will going to define it.
The determinants of Laplacian will be on the inside of a curve and outside of a curve.
So I will there will be a precise.
What's the value of C at the key for zero limit?
Right. It's a good question. So when kappa goes to zero
this is the central charge goes to minus infinity.
It's a semi-classical limit.
But however I want you to probably think about the large deviation not like just a semi-classical
limit but it's a regime in between the limit and the actual limit would be just a circle.
But the large deviation rate function still can measure a certain how rare it is.
Okay.
All right. So today I'm just going to stay on the left hand side and I will define what is
the large deviation and what rates that I'm going to talk about and what SLEs are.
And I love my talk is here.
Okay.
My apologies for the probabilists here.
All right. So in probability what we are, one of the fascinating thing I find is there's a
universality, a lot of universality results.
Like everyone would know like it would be for instance the large deviation,
sorry, the law of large number. If you take identically, independent identically distributed
random variables, you take the average of them as long as expect is L1 random variables then
you will just see the mean of this random variable.
So one instance of a universality happens.
One can also think about the large, the central limit theorem is that you take the sum instead
of divided by the number of them, you divide by square root of the number of them,
you see the Gaussian distributions.
And one definition, we will be looking at the Brownian motion and one of my favorite
definition of a Brownian motion is that, so this 1D Brownian motion
is the unique random continuous function. Let's look at the processes.
B, search that B at time 0 equals 0.
So as a notation thing I would put the time as a subscript, it doesn't mean it's a derivative,
just saying this is at time 0. And have an independent and the stationary increments,
so that means for any 0 less than t1, t2 less than tn, if you look at the increments, so
bt1, bt2 minus bt1, bt3 minus bt2, btn minus btn minus 1.
This is an independent family of random variables, independent.
The next one is that you have a stationary distribution, it means that for any t less
than s, larger than 0, you have bs minus bt distributed has the same law as b of t minus s.
So how much the increment of the Brownian motion only depends how much time you run on the time interval.
Okay, so this is not totally correct. For instance, if you multiply the Brownian motion
by a constant number, it will also satisfy this property. So maybe we'll add one condition,
is that the variance of Brownian motion at time 1 equals 1.
It's still not totally correct, for instance, if I add my Brownian motion a linear function,
deterministic linear function a times t, this also will satisfy this property.
And to get rid of that, I will going to assume that expected value of b1 equals 0.
So just for the prevalence, so these two properties and the continuity,
this tells you that it is a continuous Levy process,
which is in the form, it will always be a times the Brownian motion plus b times t,
so deterministic drift. So these two conditions will tell you that a has to be 1 and b has to be 0.
So it is extremely natural to consider this kind of a process. For instance,
study the scaling limits of simple random walks and the only limit possible will be
multiple of the Brownian motion as long as you know the limit is continuous and
is relatively centered in the sense that the mean is always 0.
So as a consequence of this, because you have such a simple characterization,
it already will tell you, give you completely the law of this continuous function, random
continuous function. For instance, the Gaussianity will be a consequence.
This will tell you that Brownian motion at times t
will distribute it as the normal Gaussian random variable, so the mean has to be 0,
of course, and how you see the variance. So even why there is a Gaussianity coming from here,
if you just look at these two conditions that the station and independent
increments, I just assume that you're able, we know we can cut this interval into a million
of small pieces and my Brownian motion at time 1 or time t, it will have to be a sum of
like a million of each individual independent random variable. And you can imagine like how
the Gaussian Gaussianity will come from the fact that we're adding a lot of independent elements.
And if you add two random variables which are independent and then their variance will just
be add up. And again, this also shows you that there's only possible, the variance can only
be possibly a linear in t. And maybe also one can write down it's easy to check the covariance
of bt and bs is the minimum of t and s. And for a Gaussian process, if you know what is the
covariance, it also completely determines its law.
Okay, large deviation.
Before defining large deviation, what it means, let me give you an example.
So if I am a random variable x, which has this Gaussian distribution with mean 0
variance sigma squared, the density of x, this is 1 over square root of 2 pi
sigma squared is exponential minus x squared divided by 2 sigma squared.
Now I take a very small number, epsilon, thinking small.
And I multiply square root of epsilon times x. This is the random variable which would have
this distribution and 0 epsilon sigma squared. And we ask for m, a number which is given.
Let's see, got to then 0. What is the probability of square root of epsilon times x being greater
than n? All right, we just apply this formula. This is exactly equal to 1 over square root of
2 pi sigma squared times epsilon to integral from n to infinity of exponential minus x squared
over 2 sigma squared epsilon dx, right?
So if m is strictly positive, this probability is going to be very, very small.
x is 10 to a localize at 0, so this thing doesn't happen very often. And we can quantify how
rare it is. So one can actually look at this quantity, if you like. You can
give some upper bound, lower bound, but it's something like very close to just minus m squared
of 2 like this. And there is some term, maybe m like this. So for this I need the m to be
strictly positive. If m is equal to 0, it's just one half.
All right. So here you can see that because if you look at the point which is a little bit
far, like say m plus 1, so this term will be really small compared to the density at time m.
That's why you only see this asymptotic when epsilon goes to 0 of, so here epsilon went 0.
This term, you pick up this m, which is just the n of this interval.
Or if I can take, if I take epsilon on time of log of this probability being greater than m,
when I take log, this would be, this is just a polynomial term in epsilon.
I multiply by epsilon, you won't see this term. So here when epsilon goes to 0,
I would just see minus m squared of 2 sigma.
So let me just continue here. And similarly,
what is the probability of square root of epsilon x? Say b in some interval a, b.
Here you can see that all the contribution, if you are looking at epsilon go to 0,
behavior, all the biggest contribution comes from the point for which this functional
is the largest. I will call this the right hand side to be this i of n.
So this probability, if I take similarly log times epsilon, when epsilon goes to 0,
they will only pick up the point for which the i function is the smallest.
So this will converge to minus the infimum of all the x belonging to a, b of i of x.
All right. This is the contribution for which gives the most probability
in epsilon goes to 0 behavior.
That's one question. When you did the evaluation in green, right? This one, yes.
This one, yes.
That corresponds to the integral simply, not to the pre-factor, is that correct?
I think this is the whole thing here.
I'm not so sure. I would think it's just into it. It doesn't change your conclusions
in any way, I guess. Not to the issue, but it seems to me.
Yeah, I might be wrong. Yes, yes.
It doesn't change here, I guess.
But I think if I would kind of like pass to you, and usually pass to a normal
Gaussian random variable, it's a variance one, and you won't see this term.
Yeah, so this is a computation like how we do in probability one class,
like you can bound into integral by something over m, the other.
Basically, there's some polynomial term which comes from.
So anyway, this term, maybe this term is not totally correct,
but this would be a polynomial depending on epsilon.
All right, okay. So this is just to, in order to remember this, I would probably just say
that the probability of my square root of epsilon times x being roughly equal to this number x
is, as epsilon goes to zero, something like exponential minus this rate function divided
by epsilon. All right, it's actually here being close to x, and how wide this
interval around x it is, it doesn't really matter. Like here, we can take ab,
there are take infinite interval. In any case, you will just see the one which minimizes this
rate function. And so here, if I'm taking a small interval around x, this probability
will be decaying like exponential, the minimum of the rate function around x.
If the interval is not too large, this is basically the value of x.
So maybe this is the intuition thing, idea that one can keep in mind what this rate function
means. And how, maybe the question of home being like the rate is here, I put square root of epsilon
and here will be. What's the rate in terms of kappa? Yeah, kappa would be epsilon in this case,
but later in the course, I will use epsilon to be one over kappa, 16 over kappa or one over kappa.
So it will be a two different thing.
Sorry, I'm not familiar with this probability field. What is this example supposed to illustrate
overall? Here, I'm trying to illustrate, I'm going to state the large deviation principle
in general, what that means. Here, I'm trying to tell you this, if I have a Gaussian random variable,
I'm looking at some rare event, like this small multiple of this Gaussian random variable
to do something to be larger than m, or this epsilon times x to be inside the interval.
And when epsilon goes to zero, this probability is going to decay to zero, but
there's a rate which is given by this infimum of this rate function.
Yeah, so let me just now state what do I mean by large deviation principle? So
this is a little bit pedantic, but let me just set it up. x is a polished space.
A polished space means a separable and a complete separable metric, metrizable space.
Usually, this is a space where people do a probability theory on. Then, this is a sigma
algebra. I'm taking the Borel sigma algebra. You can think this as a collection of subsets
you can measure the probability is. So this is the collection of a measurable set.
The Borel sigma algebra just means it's the sigma algebra which contains all the open sets,
all the closed sets. Basically, you can tell how large, what does the measure open set has.
This is a bit pedantic, but if we have a family mu epsilon
a family of probability measure
xb. So each of them are going to assign a number to every element in this measurable set.
And the probability measure means the total, the whole set would have probability one.
The whole total measure is one. That's all it means. And for being a probability measure,
there are some obvious action to put. If you take the union of the two disjoint sets,
their probability will just add up. We say that this family of probability measures
satisfies a large deviation principle with rate function
with good rate function
i. So this is a function going from x to zero infinity included.
If two of the following things happens, so to be a good rate function,
it means for any positive number c, if you look at the set for which the set x is in this kai,
in this big x space, the rate is less than c, is compact.
So this is a good rate function and LDP, it means
for any open set
and any closed set of kai, we have the following. You take the measure
inside this open set, you take log n times epsilon, I take the lim nth,
so that everything will be well defined. This is larger or equal to minus
the infimum over all the x inside all of this rate.
And lim sub, take epsilon log epsilon of a closed set
is less or equal to minus infimum of all the x inside this closed set of this rate function.
So whenever I say some family of probability measure satisfies a large deviation principle
with good rate function, it just means like that. So you have some property just about
the rate function which depends on the topology on which you're studying this measure.
And also some behavior of this family of measures when the epsilon goes to zero.
But also it depends on which topology that you take because it tells you it's a condition on
old open sets and closed sets. So maybe just a word about why we want this rather complicated.
First of all this, you can imagine like this limit aren't always defined, so lim infimum sub
they will be always defined. And the equality don't always hold. If you take this f even in
the Gaussian case like say f is just a set with just one element, mu epsilon is the distribution
given by this Gaussian random variable. This probability is always zero. Okay so this is always
okay so even log of this is even not so well defined. Okay so basically this
will you will get something which is less minus infinity. We get to set a convention if it is
zero then it's minus infinity. All right for instance if we take a very nice set let's take
example if o is some epsilon neighborhood of a point x, sorry epsilon is delta neighborhood.
And f is the closure
of this delta neighborhood. You can try to apply this
result. Assume if we have a large deviation rate function and then
we'll see that one can show that for almost every delta this infimum and this these two
infimum they will actually coincide. The main reason is that you can you can compare different
delta and they have to be increasing function but one is intricate to the other. So one cannot
have a there should be only constantly many jumps for which they are not equal. This is
some detail but you can believe me that for almost all this at the delta with the exception of only
constantly many delta these two quantities are the same. Delta
the closure. And then these two inequality will just tell you
that this limit will be an honest limit.
Epsilon log mu epsilon this b delta of x
is exactly equal to minus the infimum over x and now we cannot use x.
Sorry let me use x prime x prime x prime x prime. So this will be infimum over all the x prime
inside o delta or b delta of this rate function.
And because this rate function is a good rate function I can also show that this if I let
delta go to zero this will converge to exactly minus the rate function at x.
So this is to show you it's pretty safe to think again
that this just means the epsilon mu epsilon of small neighborhood
of element of x is decaying when epsilon goes to zero
like exponential of minus epsilon of the rate function at x.
All right.
Any other questions?
Okay from the computation about the Gaussian so what do we just do say that the distribution
of x
where x is this Gaussian random variable with variance sigma squared satisfies
the LDP with rate function.
The rate function is even continuous so it's a very good one. It's also a good rate function.
i of x equals minus x square sorry plus of two sigma squared.
It's just to put that example I gave in the beginning into this framework.
All right.
Sorry so not only the Gaussian but also everything that decay is faster than like
exponential to minus linear on the line yeah we'll have this property or?
Well if you want to show something satisfied this Gaussian random has a large deviation
you basically these are the two inequalities that you have to check.
I for instance other famous result ballerge deviation is sort of the Kramer's theorem
which says if you take a id got random variables and you take the mean
there usually they converge to this the mean of each of the random variable
but if you ask the what is the probability for this mean to be away from this expected value
and there is a rate function which would depend on the precise information of this distribution.
Yeah and
but we will be saying just in the Gaussian realm and that that will be enough.
Okay let me just finally state the large deviation of the Brownian motion.
Okay.
Serum shoulders.
So let t be positive and I will view the Brownian motion up to time t
is a random function continuous function
in the space of real valued. I will put the topology on it I'm only looking at the metric spaces so
I'll just take the sup norm
and now the distribution
of square root of b s square root times epsilon of epsilon times b so this is a random function
you can it gives you a probability measure on the space of continuous function
satisfies
the LDP
with rate function
i t I will call the i t of
defined as
one half the Dirichlet energy
square dt so of course it's well defined if w is absolutely
continuous so that you can talk about the derivative and if not I would just say it's infinity
so
so how one should think about this maybe let me just draw
so the Brownian motion itself it's a very fractal function
usually wants to jump up and down it's nowhere differentiable a very rough
function and if I give you a function w it's relatively smooth
in the way like you can take its derivative this derivative almost exists almost everywhere
it's pretty smooth function and for which this the function is in w12 so that you can talk about
this Dirichlet energy and then what is the probability of Brownian motion to stay close
to this yellow curve if I multiply my Brownian motion by square root of epsilon it's very unlikely
to happen so because if I just multiply it by square root of epsilon it is want to just stay
close to zero right if now I ask it to stay close to this yellow curve it's very unlikely to happen
and how unlikely it is going to be it's decaying like this will be the rate function
and like for for physicists so maybe this is the exactly the action functional of the Brownian
motion and for problems maybe you know it's the karmarmati norm it's something associated to all
this Gaussian measure on Hebrew spaces but I'm going to just give you an idea of why this should
be the rate function of Brownian motion it's not the proof at all but I think I hope that
will convince you why we will see this Dirichlet energy naturally popping up
Yeah it's the same rate but you will see the infimum the rate will be the
infimum of all the function will be staying in that tube it's not exactly the Dirichlet energy
of the curve in the middle of the tube but you probably want to
oh if you shrink yeah if you shrink it is exactly this super normal be an epsilon tube
yeah so this is exactly you're looking at it's put a small
yeah yeah
yeah
okay well let me just give you a heuristic
of why this is true um so it's still like I managed to keep this I just haven't erased this
so if I'm this function w is given okay fixed for once very for all and if I want my Brownian
motion to stay close to this yellow curve it's better to stay close to the curve at
all the discrete times if I put some discrete times
t1 t2 t3 okay t is tn
so let me just say that the probability of square root of Brownian motion to be close
to my w function if I take a lot of points enormously many a lot of them
this will be roughly equal to the probability of each of the time
bt1 is roughly equal to wt1 square root of epsilon btn wtn right I take a lot of points
and so this will be equal to the probability of square root of epsilon bt1 be roughly
wt1 square root of bt2 minus bt1 is roughly equal to wt2 minus wt1
the last term is btn minus btn minus one is wtn minus wtn minus one
I won't do much so now these quantities these increments they're independent
as just written so this probability will just become the probability of the product
the product of the all the product of the individual term and we also know that
like this guy has a Gaussian random variable zero t2 minus t1
right and then so here this is independence
it's the probability of ground emotion you can we can apply this a large deviation of the single
random variable single that one so this would be I can write this exponential
so when epsilon goes to zero this is already the heuristic part
of here will be minus wt1 squared of two t1 here I should have two times the variance
times exponential of minus two t2 minus t1 wt2 minus wt1 squared
I'm just applying this the Gaussian the Gaussian one
so
okay on the right hand side I will just rearrange it a bit so this is the exponential of minus
sorry there is an epsilon that was missing somewhere yeah
so I will have one over epsilon here this will be the sum so this is the sum of
wtk minus tk minus one square from one to n here you will have two times let me put the two in front
you will have this tk minus tk minus one
all right I have all the terms
all right and what is this guy
so you can just compute well this is exactly the Dirichlet energy of the linear interpolation
this term
term
the Dirichlet energy of linear interpolate
and you can imagine like if I let the number of points go to infinity this linear interpolation
is going to approximate our Dirichlet energy this is roughly equal to exponential of minus
one over epsilon
okay so the actual proof of this result one needs to be pretty careful like it
seems the topology is uniform topology like one can actually never get any good enough
estimates by just considering finitely many points
but however I think this at least show you like why Dirichlet energy pops up very naturally
in this this Brownian motion and here if you think about what we actually used there's not
not much right we just need this family of distribution this family of continuous function
random continuous function which certifies this independent and stationary increments
which will tell you this has to be a Gaussian has to be the correct variance to be linear
and once you know the variance to be linear you will see this linear term of the variance the
time increments happening on the denominator and that really singles out the Dirichlet energy for you
and I hope that convinced you that it's really a purely ideas from probability this would tell
you okay there's a one functional if one of the souveless phase which would make a lot of sense
this Dirichlet energy the h1 w12 space
do you want to take a break
yeah maybe we can take a break we can take a break and after the break I will start talking
about what is SLE and what the large deviation of SLE and yeah we can take like five minutes break
all right uh maybe just one comment is that we only talk about the Dirichlet energy for
relatively smooth functions like for instance Brownian motion almost really will have an infinite
Dirichlet energy but still like it's measuring although it's infinite for Brownian motion but
still it is the large differential rate function in the sense like if I start with this curve and if
I take a small neighborhood no matter how small it is and the probability of Brownian motion staying
close to this curve this is positive measure although the measure doesn't charge any of
this w function but it charges some neighborhood of it and you can study with probability how
fast its k is to zero all right one way to see why Brownian motion has infinite Dirichlet energy
maybe you can see it from here already for the linear interpolation now you imagine your w is
Brownian motion uh let's take expectation for instance if I put expectation here
this is exactly uh tk minus tk minus 1 right expectation of this random variable is tk minus
tk minus one and so each of them is not far from it it's at least it's of the same order of magnitude
right it's uh then you divide by tk minus tk minus one this ratio is of order one
in here I'm adding up uh end of them it's going to blow up if I take a lot of uh so this is one way
maybe you can see the Dirichlet energy for Brownian motion almost really infinite
so we don't talk about Dirichlet energy of Brownian motion but it's still the rate function of Brownian motion
okay
um from leaven evolution so
so first I will have to define uh what is we call the Levener transform
the Levener transform uh it's Levener called Levener introduced exactly 100 years ago
um so it will give you a way to encode a simple curve into a real value driving function
so let's let's start in the case uh in the upper half plane
infinity okay as I tell you like as the lead we will be going to describe some interface
of simple simple random curve uh which bounding to different clusters for instance
but this uh idea of the Levener transform say okay you're saying instead of studying this loop
I'm going to explore my loop a little bit so I'm just going to zoom in into this picture
in order to force a certain curve going from one boundary to the other boundary I would just say
okay I would put some force a boundary condition with different spins
and say I have a spin system with a minus and plus here and then there will force a certain
macroscopic interface from this point to this point
and SLE the one I'm going to present the Kodo SLE is going to describe this kind of interface
for you we have to use this Levener transform and let me first describe it in the upper half
plane going from zero to infinity so this is my upper half plane I have a curve going from zero to
infinity the Riemann mapping theorem tells you like all the simply connected domain as long as not
the whole complex plane or the whole sphere you can always conformally map to the upper half plane
if I take my curve I cut it at this uh open up this slit the complement of this curve
is going to be simply connected domain right I can there exists a conformal map
so I'll confirm what I mean by holomorphic functions
it's going to open up your slit
and going from
okay now this green curve is cut into two you have a one side left hand side and right hand side
and here is map to here left hand side and right hand side
there's many choice about this conformal map
this is a group of three-dimensional real dimension so we are allowed to fix three
parameters to uniquely determine this conformal map I'm going to choose this conformal map such
that its expansion at infinity is exactly identity plus something which is going to vanish
okay so without this term say here there's something which is going to vanish
so how many parameters are we fixed so this g we're going to map infinity to infinity
its derivative at infinity is one and usually there should be a next term it's the constant term
or like after you map to here you have the freedom to move slide slide it left and right
which doesn't change the image and it doesn't change the derivative at infinity
so this is a constant term which also we fixed to be zero we fixed all the three parameters
so this map is uniquely determined and there will appear a certain number here
and this number is called a capacity hot plane capacity of this green part
so this number is a positive number and is monotone in the sense if I make this set larger
this number will be larger
it's not obvious to see but you have to trust me on this
so I was going to choose the parameterization of this curve such that this number here is
exactly equal to 2t and then I call this conformal map gt
t is the capacity so I will parametrize my curve gamma I will call this part of gamma
zero t I would parametrize my curve gamma such that if I unzip this part it'll give you exactly
2t there so once I have the curve I have the parameterization
so I'm a little bit confused you said once you define you want this conformal map you
still have three parameters to fix yeah yeah so it seems to me that you could fix constant to be
zero then you tend to be one and one over z term to be anything you want oh here here this is z
infinity is mapped to infinity okay yeah so this is already fixed I have fixed infinity is yeah
you can't choose the one over z term yeah this term is determined yeah this will be determined
all right so so this parameterization will have given you some very good property for this
gt map you'll see immediately later but let me just first define this thing now this point here
is sent to somewhere on the real line I will call it wt
all right this is some real number
now the map t to wt is called the driving function
of gamma
yeah it's the position the value of the image
wt is gt of gamma t
hmm
I may just uh I think I will
erase this part
uh maybe just to uh when properties is that this
w is continuous function
w at zero so here my curves start from zero w at zero uh actually the it's just the the map is
just identity map uh so this is w zero uh is zero um maybe one remark is that
if I am just looking at this part of curve uh each there is a t each point is this curve is
parameterized by this capacity uh so they should correspond to a function w at the in some interval
but if I just look at what is the driving function on this part of the curve
I cannot tell uh unless I know what is happening before
right if I want to know what is the driving function associated to this point exactly I
need to know what is the map uh completely but it doesn't depend on what's happening in the future
it's a driving function is very no local but it only depends on one side of the curve
um
hey let me just also say that there are a few very good property about this uh
this way to write down your uh driving function is that uh this first additivity
so now if I look at this yellow curve this yellow curve is g t of gamma t to infinity
minus uh sorry just this image under g t the yellow curve and if I take minus w t so I translate
back
gamma t
and now if I call this curve uh let me just draw here
now this again starting from zero the point say the capacity s this let me call this curve eta
all right eta at time s so the capacity of eta s is determined totally by this curve itself
but this point will come exactly from the point which was gamma t plus s
so in the sense that this capacity parameterization is behaves super nicely if I do this composition
you can see this by expanding you can see this capacity will just add up
um but let me just write down for this new curve eta eta has driving function
equals to exactly t plus s minus w t and this is something you can really just check
uh from the definition
the new curve just have the driving function which is the increment
the second property scaling property
is that if let c being a positive number
c times gamma I'm just doing scaling to my curve
has driving function
hat t equals c w c minus 2 t
so
okay so this thing I haven't shown it but uh it's pretty straightforward just follow from definition
so these two properties there is actually a super nice if you allow random functions
uh in fact uh the only function only continuous function
square root times the Brownian motion uh there's the only
continuous random function so guess processes
whose law is invariant
under these two transformations
so let's see why would this if you are invariant under this transformation
basically that would transform to uh the second and third independent stationary
increments for the driving function if you have a so I mean if w s has the same law as
as the original function and also independent with what's happening before and this would have
the second and third property so from the second and third you will tell you that there will be
a levy process which would be the form of a times a Brownian motion plus
b t okay a I cannot determine this a will be this square root of kappa
and b will be ruled out in fact by this property so if you have okay let's see why Brownian
motion will satisfy this invariance let me assume that w is just following the law of a Brownian
motion uh what I know is the covariance of w t w s is the mean of t and s and if I apply this
transformation I look at covariance of c w c minus 2 t c w c minus 2 s
okay you will have a covariance is by linear you get c squared you got the minimum between these
you get still minimum of t and s if you have a Gaussian process uh there are covariance
determines its law so the if you have a Brownian motion then this term will still have the same
law as before but if you have a deterministic drift say if if w t equals b t c w c minus 2 t
equals c times b times c minus 2 t this will be over c t this is not going to be preserved
so uh basically this one will tell you if my driving function will be invariant under these
two transformations it has to be a levy process and this one telling you that b has to be zero
so the only uh possible thing is this square root kappa times Brownian motion
excuse me kappa shows up here uh kappa is uh kappa will basically be the a because we i cannot
determine it so any multiple of Brownian motion will be invariant under these two processes
yeah so uh the definition of a le will be this will be the kappa in the le
but right now it's just a fact yeah now it's just a fact it's just about these two transformations
anything i can finally erase this part
yeah uh by law you mean like uh the variance and covariance is that all the times okay yeah yeah
and uh can you have something with w t equals like square root of b t b square root of t because
it seems like it would be right uh so if it's uh it won't be
so only the covariance will determine the law if you know a priori this is a Gaussian process
so at each time it's a Gaussian processes and the linear combination of them is still a Gaussian
random variables so if you take a square root of a Brownian motion it wouldn't be a Gaussian
so so the covariance definitely doesn't determine everything but here i'm saying like
if you i just ask the process to have this independent stationary increment
then it must be something like a Brownian motion plus b t
yeah yeah so if if my distribution the increments if you take a square root it won't have this
property like the increments won't have behave like the original thing right uh
so i'm asking what are kind of continuous function which would be invariant under these two
transformation this be translated to this property here there must be a Brownian motion
all right okay so but before defining the SLE
um i haven't tell you how one can get the curve back coming from the driving function
the SLE would be determined defined to be the continuous curve whose driving function is square
root of kappa times Brownian motion in the end this is what we're coming to
uh but okay here i explain to you if i have a continuous curve how i can get this driving
function conversely and conversely
we observe that
in fact is if i take time derivative of gt so if gt comes from the curve
uh i can take time derivative in t this will have a very simple form there's two
the gt of z minus wt and initial condition g0 of t equals z
so here i'm saying like if i start with a point on upper half plane each t gives you a conformal
map so it will map to somewhere on the plane again and it will follow a path depending on time
so if your curve your point is outside of your curve this flow is defined for all time
at some point it's going to getting close to the boundary and going to flow
towards infinity or something like that but if i start with a point on the curve
it will going to come down flow somewhere but say this point is now at this point is a t plus s
at time t plus s it's going to hit the driving function so you can think of this this is a vector
field depending on time t so wt is here if i draw this vector field uh it's
it's smaller when you are far from the point the map to the small when you large
and it's a singularity here right you have a singular vector field this equation might
blow up if you start from the point the point i'm here and then gt after this t plus s it won't
be defined anymore so if i consider this and then gamma t
gamma 0 t is exactly the point for which let me call this family of equation
tz easy blows up
before time t
if it doesn't blow up gt is well defined gt will be a conformal map from the outside of this to the
upper half plane okay so we can do because of this observation like for arbitrary a continuous function
w
i can consider the set kt equals to the collection of point for which
the same here
before t
all right well this is a well defined compact set and we have that gt will be the map from
upper half plane outside of kt is well defined and you can show that it's actually onto a rough plane
if i just solve this equation i forget about curve i start with a continuous function i can solve
it i look at the solution these are the points for which is well defined and gt will be a conformal
map if i start with a curve if the function comes from curve this kt will be just gamma 0 t
all right so no one tells me that this kt is a curve what we all i know is kt
is increasing
and because it's conformal i know h in the complement kt is simply connected
okay this is all i know so in fact it's an open question about what are the continuous
function which will give you that curve is the exact given giving you a simple curve this we don't
know increasing means that if t is larger the kt is included in ks if s is larger than t
yeah this is the point for which it blows up before t so if time is larger it already blew up
so you can think this as a a growing family of set so this curve it will be this green part is growing
yeah but at least we know like for arbitrary continuous function i'm able to define for you
this family of function
so it's a highly non-trivial result by stefan roder or the shrump
is that for s le mean if w driving function s square root of kappa times brownie motion
there is three cases where kappa is less or equal to four
then the picture you see the growing family is almost surely a simple curve
one kappa is between four and eight
it can be described by a curve which is self-touching
so what is kt k kt would be the part which you cut out the whole set
and they show there exists a curve which is touching the self such that kt
uh gts defined in the infinite kinetic component of this curve
also almost surely everything's open sure and when kappa is greater or equal to eight
people have the curve to be almost surely space filling like a piano curve but it's a random
all right
so so i just tell you like we don't know what are the continuous set of continuous function
for which we know there are simple curve it's very hard but here in probability
you're not going to say like which brownie motion what what what set of a brownie motion like
it's going to give you this property but you can show is it happens with probability one
and we have tools like a variety of contention lemmas you can
there's a lot of tools in probability theory we can tell you things happens with property one
but analytically actually we people don't really understand what precise property of the brownie
motion which makes these things happen but you can already see it's a highly non-linear behavior
i change the kappa the behavior changes totally
yeah so but this is let me call this is the set at least we call the s le
okay so this so these are the curve the s le we should usually we mean this
curve here in also the curve which is touching here and s le here will be the curve which is
space filling okay why we care about s le and again this is related to this to invariant property
here and i don't understand this middle case so if you fix if i fix w yeah that fixes except
kappa t which you know is compact yeah uh is that set the curve where is the set the thing
the set is i in in green i'm green so what so what is the curve inside of it no the curve uh
the theorem is saying that there exists a curve continuous curve which is touching itself such
that k t is is that the field but the curves are not unique oh this is unique because it's a
continuously growing as well defined for for for a Brownian motion like one realization of the
Brownian motion almost sure realization of the Brownian motion you can find the curve which is
growing it's a process it's not just a set you know you get t is a when t is zero you just have
one point when it grows a little bit it is still a curve well actually it will hit the boundary
like immediately but okay so it's the same for every t and one curve that works for every t
yeah yeah when t is larger it's going to grow uh yeah here as well it's growing
if t is larger the curve inside doesn't change doesn't work anymore exactly yeah
okay maybe let me first also motivate a bit more so these two properties what does
does it translate to the curve itself
so the additivity
it will allow us to define s le
kappa in any simply connected domain with two distinct boundary point
okay so that means if i have a simply connected domain
ab now i know how to define s le in the upper half plane from zero to infinity
so in different cases it's a different behavior but still it's well defined
now i'm just taking any formal map phi
from d to upper half plane phi a equals zero phi b equals infinity
uh i know how s le is i just pull it back this is my s le in d ab
okay but this phi isn't unique but the only degree of freedom that is left is the scaling
so but it actually doesn't matter because under the scaling uh this is the second sorry the
scaling property it tells you okay no matter which phi you you choose uh it's the same s le you
will be defining here so we can talk about s le in d ab and as a consequence this will be saying
okay s le in any simply connected domain there will be a conformal invariant which is
uh basically by definition or defined by conformal invariance
the second property uh is the domain markup property this will be the consequence of the
additivity that if i explore my curve up to a certain capacity so either is here
like assuming that i know my curve has this property is it contains this part of the curve
then the remainder of the uh curve okay it will be what what is that so in order to describe this
i will have to map this green part to the upper half uh the complement of the domain of the red
part i will have to map it to the upper half plane
all right this will be the new uniformizing map
okay the additivity will tell you okay this new curve it has driving function just the
increment of the original driving function of this guy has the same which has the same
law as before is again s le so this property is saying that s le is the unique
curve which would satisfy conformal invariance and the domain markup property
so my macro property says if i condition on what i i see before the remainder of the curve is a
curve uh again s le and why it's really important model is because like in static mechanics models
if you believe that this scaling limits of a mechanics model at a critical temperature they
would have this property they will conform invariance and this these are the interface coming from
these two different spins and if you explore it to the point you know the left hand side is plus
the other side is minus and the remainder curve is okay it doesn't see the original curve it just
think this is part of the boundary so this curve has to be has the same law as before if we assume
conformal invariance that's why people are able to show that this s le curves there are the scaling
limits of a lot of interfaces let me give you examples s le 2 this will be the scaling limit of
loop erase random walk s le 3 a critical easy model
s le 4 level lines of Gaussian free field s le 6 interfaces in percolation critical percolation
s le uh i should put the 16 over 3 above it's smaller than six this interface of f k easing
and s le 8 this contour lines of uniform spanning tree
so these are the simple case uh these are the self-touching case between four and eight and this
is one example of space filling curse and always just coming from the fact that if you can show
that the scale limit has these two property conform invariance and domain macro property
then there must be one of the s le and to determine which kappa it is uh usually it's a
it's very model dependent you want me to see certain observables uh and to determine what what
this what kappa exactly is
but at this s le itself you can see that it is well defined for any kappa
um maybe let me just uh do another trivial example and let's say what kappa equals to zero what do you get
okay in the upper half plane what is is just
it is curved
if you want in a more intrinsically uh for any simply connected domain what you
do is just push forward by conformal map
uh it's the image of this straight line uh for geometry this is the hyperbolic geodesic
maybe for problems uh this is the set of points for which if you start the 2d Brownian motion
you will have equal chance to hit the left hand side uh versus the right hand side
Brownian motion I use this term because of uh Brownian motion the trace of Brownian motion
is conformal invariant uh so it's really a conform invariant quantity and here you can think of
to tell whether this point is on this curve or not you just run the Brownian motion starting
from this point 2d Brownian motion and uh it has property one half to hit this side before that side
then this is on the hyperbolic geodesic on this curve okay it just uh
okay so finally
since I just tell you about the shoulder serum now you can imagine the large division of uh SLE
uh will be given by the Dirichlet energy of the driving function okay so let me just state it
so now we define the Levena energy
of gamma in a curve in domain DAB
here uh is Levena energy of gamma is defined as the Dirichlet energy
we define the Levena energy as the Dirichlet energy of the driving function
and the serum
there's another version but let me just state the latest one
okay this is going to be the rate function of SLE and what topology I put on space of SLE
I will consider SLE kappa as a measure probability measure
um uh compact sets
in the bar minus one one okay I'm going to look at SLE in the unit disc
just to give a bit of a massimetry of the starting point and end point
and I put the topology uh so here this space of compact set in this closed disc
uh I will put the house of metric
and as I'm going to let kappa go to zero uh so these are really some simple curve
but I will view the simple curve as a compact set and can measure their distance by the house of
distance and we should show that uh SLE kappa satisfy
kappa will be epsilon all right okay uh satisfies the
uh large deviation principle with good rate function
the Levena energy I will probably put the Levena energy I can keep this dA b here so the rate
function will be d minus one one
okay uh in other words what it says is that
if I start with a continuous function a continuous curve a relatively smooth for which the Levena
energy is finite I ask what is the probability of SLE stay close to do the purple curve in the
house of metric the house of metric uh with respect to Euclidean uh distance on the disc
okay so this is really the uh you see how is epsilon close to this curve how likely that's
happened and this is saying that the probability of SLE kappa is roughly equal to this curve gamma
decays as kappa goes to zero like exponential minus the Levena energy of gamma
over kappa this is what it means and the reason we we take this disc you can take any compact set
and you can then uh well at least it's it's a homomorphic to the disc you can push forward this
to the use the house of metric so it's this isn't a very particular choice it's just to
say the infinity this direction the endpoint has a probably a similar rule play than the starting
point yeah is this the generalization of the shoulders theorem
um no not exactly but it's rather the key part is the shoulder theorem uh there are two difficulties
one is that this uh shoulder theorem is stated for the Brownian motion stop at the finite time
and if you stop by the finite time it will tell you something about the curve uh up to a point
and one can promote this shoulder theorem to a bit stronger like you can have a topology of
uniform convergence on all compact so that you can define the large deviation on the infinite
time interval but that topology is too weak to tell you any constraint about how uh it's going to
approach into one and you can have a curve which do very widely near one but still converging
in that topology so this is one difficulty the other thing is that the map from the continuous
function to the curve itself is not continuous at all the if i i take a continuous function it
gives me a curve so first of all i'm not sure it's a curve right and the second thing is that
if my driving function converges whether my curve converges not at all uh so if it's a continuous
map then we can get directly from the shoulder theorem to this theorem
that will say okay the probability of s a kappa is close to w is similar to probability of square
root of kappa brannium motion being closer to driving function okay if it's continuous then
these two probabilities are the same and then you can have this decay using the shoulder theorem
but that but here this is not um but still like the one of the key parts of the proof is using
shoulder theorem and i'll give you one consequence of this result which is actually quite surprising
if i you just tell a complex analyst
okay let me let me just do it here i remember there was a when we defined the driving function
there is a capacity parameterization right i mapped this to the upper half plane
the capacity parameterization here is time zero time one if you increase if
but when when come to the end point the capacity is going to be infinity
so the driving function uh at priority you would think that they encode a lot of information
near the end because the capacity the driving function will have a starting from time 100 to
infinity this part um but in fact a corollary
try to say corollary
the love of the energy
current zero one to one over the gamma will be the same as if i reverse the curve
but going from the outer direction
or if you want if in the upper half plane this is the curve if i apply a map one minus one over z
give you another curve there is usually energy of the driving function are the same
so why this is not obvious at all because if you already the capacity parameterization
here is finite and went towards the end it will be infinite when you reverse it it totally
reversed the the parameterization the other thing is as i said let's say look at the driving
function on this part on this picture it would depend on what's happening here but if you reverse
it it would depend on the other side of the curve so it's totally everything's messed up
but how we get this we can using this this theorem we're saying that okay there's a
probabilistic interpretation about this love and energy as the decay rate of s le kappa
and s le kappa is proved to be reversible it's a very non-trivial result but
if you look at the particular cases like for instance the critical easy model
the interface apparently doesn't end have any direction so s le curve whether if i look at s le
inside the disc from minus one to one uh i can't tell s le comes from minus one to one
or it comes from one to minus one so they have the same law if i reverse it
and now using this relation and also this well-chosen topology i can say okay the probability of
s le staying close to the purple curve going from minus one to one is the same as the probability
of the s le staying close to the curve coming from the other side the house of distance doesn't
mess up if i reverse it so these two properties are the same therefore they have the same decay rate
and you get this result but this result a priori is totally a deterministic
statement if i give you a curve i can write down its driving function i can also reverse it and
write down its driving function again their usual energy just happened to be the same
okay so tomorrow i will give you a determinist proof of this result but before that i'm going
to generalize this laminar energy of a simple core to the laminar energy of a Jordan curve
actually there will be even more symmetries than this orientation reversing symmetry and
that is that that version of the laminar energy to the Jordan curve which will tie the links to
the vaporous and universal tritium space and but i hope today i'm just trying to tell you
a very basic idea basic idea from probability theory like we're starting from very simple axioms
stationary increments independent independent increments will give you this Brownian motion
and this property will single out SLE as well for the curve which will satisfy conformal invariance
and domain markup property they have to be SLE also the large evasion principle of the Brownian
motion also tells you that Dirichlet energy is an important quantity at least for the
large evasion point of view and you can guess even the formula of the rate function
just from the stationary and independent increment so it also singles out this Dirichlet energy for
you and therefore this studying the laminar energy it should be supernatural for this simple curves
and i think the later on this development into a Jordan curve that you will see tomorrow
that's actually even better than one would have expected so but okay and just stop here
