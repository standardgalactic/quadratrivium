Thank you very much, Ritek, and I wanted to thank the organizers both for organizing
and for inviting me to participate in this really spectacular summer school.
So I wanted to tell you a story that's joint work before I just make sure they're on the
board with Harrison Chen, who's somewhere here, hopefully.
No?
No.
Okay.
There you go.
So hard questions go that way.
So joined with Harrison Chen, David Helm and David Nadler.
And so what is our, what is the story we want to talk about?
The goal in my talk is to try to bridge kind of two different realms of the local Anglican
correspondence, two different ways of formulating what local Anglican correspondence should
be about.
And we try to, we want to present a mechanism of relating the two of them in some settings.
So maybe just some notation that G is going to be connected and a reductive group.
I'm going to be very lazy a lot of the time and assume it's split.
Maybe a lot of things you can assume only quasi-split.
Some things are more general, but I want to indicate some principles that I think you can
see already in the split case.
And F is going to be a local field.
Okay.
So what is the, the story?
So one thing that we've heard a lot about in this summer school, so in the lectures of
Datt and Zhu and Emmerton G and Helman and Fargan Schultz, is this idea of a categorical
version of local Anglican correspondence.
And I want to add an adjective there.
In all of these talks, the field F was non-Archimedean and the categorical, the kind of category
you get was a category of coherent sheaves.
So the kind of general format that we saw again in many talks was the idea that you
have some category of coherent sheaves on some stack, let me call it L, just to be very
vague, some stack of Langland's parameters, or maybe L maybe stands for Langland's, maybe
I can think of it as some stack of local systems of some kind, but some space of local systems
of Galois representations.
And what the format of these conjectures said is that we can think of representations of
G of F, so we mean smooth representations of this group.
So we look at a category of smooth representations and there's this kind of conjecture of, I
don't know, sometimes called A, that there's a fully faithful embedding into a category
of coherent sheaves on Langland's parameters.
So that was the format in these talks of what you might call categorical coherent local
Langland's correspondence.
Okay, I'm going to be very, just to caveat, there's going to be lots of technical things
I'm not going to be trying to be careful about.
In particular, I'm not going to be careful about size issues, whether I talk about coherent
or kind of large versions like quasi-coherent or incoherent sheaves.
I'm just going to use co to symbolize just kind of a general symbol for that.
We can say more precise things if there's questions.
Okay, so we want to embed representations into coherent sheaves and in the Farg-Schultz
lectures we heard in some settings there's much stronger statements you can make.
You can think about these representations naturally sitting inside of some big out of
the morphic category that should be conjecturally equivalent to coherent sheaves.
So there should be a counterpart to this, which is, let me just kind of schematically
say as sheaves on some automorphic space bungee.
So this is a form, a picture of the Farg-Schultz conjecture or there's, in Shenouen-Ju's work,
there's a different models of what you might take here.
And again, what you should think of this is this is some kind of union.
It has a semi-orthogonal decomposition.
It's a kind of union of representations of some infinite family of groups which are labeled
by these isocrystals or whatever.
So it's an infinite, so we have this small category we're most interested in.
We put it inside of this infinite family of groups, this kind of semi-orthogonal decomposition
and we get, this is supposed to be equivalent to coherent sheaves online with parameters.
Okay?
Is that okay?
That's kind of supposed to be an executive summary of a theme.
Okay, so what I'd like to do today is I'd like to do a couple of things, okay, maybe
just to illustrate just an example, just to have something concrete on the board.
This appeared in Jean-Francois talks in particular and others.
There's a space, let me call it say LU.
This is kind of the tame, unipotent, unipotent Langland's parameters, again for non-comedian
field.
So example of, just to give a picture of what these stacks of Langland's parameters look
like, this looks like something like pairs of sigma in the dual group and n in the nilpotent
cone inside of the Lie algebra, where sigma acts on n by multiplication by q, which is
the residue field cardinality up to conjugation.
Okay, this is just a picture, so these spaces of Langland's parameters, at least in some
small chunks like this unipotent chunk, are not too scary.
I mean, there are things you can write down concretely.
And then in Jean-Francois's talk, we heard how the whole spaces in some cases can be
understood in terms of these pieces.
Let me just say that this is where the kind of the Iwahori block sits.
So for example, if you look at Langland's parameters for representations with an Iwahori
fixed vector, they factor through the tame quotient of the Galois group.
And here I'm assuming moreover that you have rather than a sigma and, I don't know what
letter I'm supposed to use.
So this is the, for me, this is the generator of tame inertia, and I want that to be nilpotent
rather than log of it to be nilpotent rather than arbitrary.
So okay, that's great.
So I'd like to tell you two things.
The main content of the talk, I want to kind of propose a mechanism, if you like, not exactly,
but roughly a mechanism to pick out this small chunk out of this big category, or pick
out something that's relatively close to this.
So if you're studying these coherent sheets on the space of Langland's parameters, how
do you pick out this very small piece out of it, or at least I won't be able to do quite
that well, but I'll pick out something relatively close to it.
That's one kind of, in a kind of a geometric way.
So what's a geometric mechanism to pick out something like this?
I'll say it more precisely later.
For me, my involvement in this all started from work I was doing with David Nadler, and
maybe I just wanted to, a long time ago, so this is around 2007, we formulated something
which, you know, you in a historically might say some version, some kind of real analog
of the far conjecture.
It's not exactly, I can explain some of the deficits compared to the far conjecture, but
I want to do an analog of this picture where f is now our comedian.
So just to fill in in our workshop, what can we do when f is our comedian, and there's
a picture that's basically the words, the words are basically, sound exactly the same.
So maybe I should just, here it is.
Okay, now that's kind of too obnoxious, so let's, what is the analog of the far front
end curve?
In this case, learned from Schultz and Farg, that there's a natural analog of the far
front end curve, which I'll denote, I think the notation they use is this P1r, this is
called the twister P1, or the twister line.
This is, I don't know, we didn't use those words then, this is just, if you'd like, you
take Cp1, and you give it the real structure, the kind of non-split real structure.
This is the antipodal map, as the real form, so if you like, the quotient is RP, I just
usually think of this as just RP2, the quotient of Cp1 by the antipodal map, but you can think
of it as this complex curve with the real structure which has no real points.
So that's going to be, so this is, there's all kinds of reasons to think that this is
the Archimedean analog of the far front end curve, and then you can study, now you can
say all the words the same.
So we can look at, so here's the kind of conjecture from 2007, and I guess you could call it,
you know, maybe twister langans, twister geometric langans, it's just a geometric langans conjecture
on this curve, and it says that sheaves, some suitable version of sheaves, we don't have
these leaf sheaves, we have these beddy sheaves, just a much more naive thing.
You look at G bundles, so here G is my complex group, but it has a real involution, so G
theta, theta is a real structure on my complex reductive group, and I look at bundles on
this real curve that are real for this, so now, no theta is on the group, so I have a
group G, I'm using G for the complex group, and theta is the real structure on it, and
I'm looking at bundles on P1 that when you imply the antipodal involution are isomorphic
to their theta conjugate, so that's a real bundle on this real curve.
So I look at real bundles on this real curve, now the main diff, you know, one of the main
deficits, or I don't know differences with the kind of far, the conjecture, is I'm going
to add a point, I'm going to have tamarimfication at one point, so I'm going to have kind of
a, a hory level structure, so I have a bundle with a reduct, with a flag at one point, that's
something that didn't appear in the FARC story, I can say later why, anyway the geometric
angle conjecture in this case says that this should be equivalent to again, let me call
it co, really should write some inco, but I'm going to be lazy, and you write the same
space, Langland's parameters on this RP2, so what does this mean, I have sigma is the
involution, so I should have said I want theta to be quasi-split, and so it induces an involution
just combinatorially on the dual group, so sigma is as algebraic automorph involution
on the dual group, I look at local systems on P1, Cp1 that are, that are equivariant
for this conjugation, okay, and again with a pole at one point, and a flag preserving
the monodrome, okay, so this is, this is all spelled out in the notes, but I just wanted
to write down the formula, I think of this as really local systems on the mobius strip,
it's RP2 minus the point, you have a mobius strip and you have some, some monodrome there,
so sigma is an involution, so sigma is the involution of G check, that's dual to the real
conjugation of G, just combinatorially, so I can say this in terms of the L group, probably
better to think about this in terms of the L group, but, but I, I won't, okay, so this
is a, this conjecture, I'm not, so this looks a lot like the, like this, and one of the
main points that I wanted to say is that inside of here, why did we want to study this space,
is the same kind of idea, so in the FARG story you had a locus, which is the kind of the
trivial bundle locus, which is point mod G of f, you had an object whose automorphisms
was G of f, so here you might hope to a version, we have point mod G of r, and you might try
to imitate the same thing, except that then you would need some crazy category of sheaves,
you probably need to say words like liquid that I don't understand, you need some category
of sheaves, so it's that sheaves on point mod a real group looks like, you know, things like
discrete series, like big infinite dimensional representations, I don't know that story, but
what you can do is inside of here there's a trivial bundle locus, instead of being point mod
the real group, you have the flag variety, the complex flag variety mod the real group, maybe
I should be a little more careful, maybe it's G mod n, I'm gonna be a little, get G mod n,
you can cut down to G mod b, and so inside of this space you have not point mod the group,
but flag variety mod the group, which is great because there's a whole history in representation
theory, balance and Bernstein localization, and in particular there's a version of balance and
Bernstein, due to Kashiwara and Schmidt, kind of a real analog of balance and Bernstein that
tells you that this category is very closely related, and again I can say more precisely later,
but it's very closely related to Harishandra modules, let me just call it smooth representations of
this real group. So you have some subcategory that's very close to representation of the real
group sitting as a piece in here, there's a semi orthogonal decomposition with all kinds of
similar looking pieces, but this sits inside of here as a full subcategory, so this conjecture
kind of looks a lot like those things. Okay, yeah.
I mean you can say that, I mean I'm just saying I look at bundles on P1 and I choose a flag at one
point, a reduction to Borrel. Yeah, sure, yeah, if I knew the words log better I would say that way,
but yeah, so it's bundles with parabolic structure, and here the same thing is parabolic local systems.
Yes, but can I do it later? I'll say more precisely, so this category, if you'd like maybe this
category, roughly looks like the category of Harishandra modules or representation here,
but kind of collapsed by translation functions, so that category has an extra symmetry, which is
translation functions that shift infinitesimal character, so this category in some sense doesn't
depend on infinitesimal category, category in the Lie algebra, but a version in the group,
so it's roughly a collapsed version of that category. If you fix infinitesimal category,
you can get out of this exactly categories of representation out of fixed infinitesimal
character, and you have to be careful about singular, this is discussed in the notes, but yeah.
Okay, so now I wanted to put this out here just to get something, or convenient, but really it's
going to be just a good example for the mechanism I want to describe. One point I wanted to make is
just like in the Unipo in case above, this space of local systems, I wrote some big formula for it,
something super simple and concrete. It's, you know, it's this local systems on a mobius strip
with a flag, and you start thinking what that means, it becomes something extremely simple,
it's an element, you can write it as an element delta in the dual group, such that delta times
its sigma conjugate lies in a fixed borrel, so it's really a pair of delta and a borrel,
and with this one equation up to conjugation. That's what this space is. So it's a very
concrete stack, nothing derived about it, but if you want it's just a simple space. That's the
analog of the stack of Lagrange parameters we're proposing. Yeah. It's a, you fix a quasi-split
form, and as I'll explain later, you know, this is something, going back, you know, you will see
representation theory, if say it's G semi-simple, or you'll be careful, but you see representation
theory of all these whole bunch of forms in the same stack. So it's not really a story about
quasi-split forms, but that's a way to get, get a place, that's a way to write this modular stuff.
Yes.
Well, this is a geometric Lagrange conjecture, right? So it has the same status as geometric
Lagrange conjectures in general. There's a lot of stuff you can say. There's a spectral action. These
are things we know, you know, there's a spectral action one side or the other. You can use that
spectral action to construct functors by acting on a Whitaker object. We have a preprint that's
been around for, in some dropbox for a while, where you prove this in the case of SL2, just as
kind of a reality, because there are things are small enough that David is able to calculate
everything. So, I don't know, but it's very close to work of his with G-way, and you're now able to
calculate some of these categories. Because this is, again, it's P1, it's not a higher genus geometric
conjecture. You, you can label all the objects, and you might hope to just match them. But so it's,
should be easier than a general geometric conjecture, but it's, but it, yeah, and it's, so you can
write functors, I think, but that's not what, okay. Anyway, this is where, this is, I wanted to put
this out there as just to have an Archimedean counterpart, but also because I'm going to, this
concrete space is going to be very useful for the mechanism I want to describe. But, okay, so this
is going to happen a couple of times in this talk. You've gotten lost at this point. You can
wake up now. I want to, I want to take you back a long, a long time ago to week one of this workshop.
So, in the week one of this workshop, we have lectures of Olivier Tebi and Lucas Mason-Brown.
And then I want to take you back a little further to 1993. So, this is a Vogan paper in 1993 about
the local Anglian's conjecture. And I want to describe a picture of the local Anglian's
correspondence that long before these kind of words were appearing. How did people think about
what, this is what Olivier Tebi described as the refined, called the refined local Anglian's
course conjecture. So, what did that conjecture say? So, you look at smooth, irreducible representations.
What does the local Anglian's say? You look at smoother, irreducible representations of G of F.
And Langlian's tells us we're supposed to attach to them Langlian's parameters. And I'm not going
to be careful about dual groups and C groups or whatever. But anyway, there's a map to Langlian's
parameters. And with the fiber over, so this is some Galois representation, a Bay representation.
So, the fiber over here is, that's the L packet. And that's the definition. And the refined local
Anglian's conjecture says that these fibers you can describe, namely, these are going to be irreducible
representations of some quotient of, which was written in Olivier's talk, but it's quotient of
the group of components of the centralizer. Let me call it G check of row. I'm just gonna, I just
like the G check of row, this notation just for the centralizer of row. I don't know. So, I don't
keep writing Z's. Okay, so it's a representation of the quotient that parameterizes the L packet. So,
this is the, this kind of refinement of local Anglian's correspondence. And Vogan in his article
proposed, and I think this has also been come up, but that we should, we get a slightly nicer picture
by, in particular, I want to drop this quotient. Just want to get representations of this, this, a
bigger collection of object that no longer looks like smooth representations of G of F. This looks
like, now this gives a representation of some collection of forms. I don't know, let's just call
theta i. So, this is some collection of these pure, pure inner forms, forms of, of my group. So,
if I consider not a single group at once, but a small, now notice this is a small kind of finite
collection of forms. If I consider this, this collection together, I get a slightly nicer
picture. In particular, I get just these representations. So, this is what I, this is
kind of Vogan's picture. And why does Vogan like this, clustering this together, many reasons,
but one reason, just geometrically. So, this data has a natural geometric interpretation.
And, and what is that natural geometric interpretation? It looks like the data that defines
equivalent local systems. So, so the point is that representations of a centralizer
are exactly the representation. So, maybe let's, let's, let's just make a,
if I have a representation of a, of a, of a, of a centralizer of due check of row, you can think
of this as an equivariant coherent sheaf on the orbit of row. But a representation of the
component group, that's exactly the data that describes an equivariant local systems,
local system on the orbit. So, what's really going on in this refined local language is we're
saying let's look at equivariant local systems on the orbit, or if you'd like local system on a stack
of language parameters, but just sitting on that orbit. And then Vogan says, oh well, we know what
to do if you have a local system on an orbit, we should extend it to a perverse sheave or
constructible complex, some kind. And so, these objects sit inside of some natural constructible
category of sheaves on spaces of language parameters. So, what, so now let me, so yeah,
so the kind of the picture is, is that I should, the picture that Vogan gets out of this is I
should relate, I should study, study these representations together via constructible
sheaves, constructible sheaves on the stack of language parameters. That's, so these, the simple
objects and categories of constructible sheaves will look like equivariant local systems,
will be parameterized by equivariant local systems on an orbit. Now, what do I mean by
stack of language parameters? The stacks are different than the ones that appeared, so Jean
Francois explained that when we want to talk about these big stacks of language parameters,
it's very important to let, say, Frobenius not act semi-simply, to drop that hypothesis
in order to get a nice modularized space. In this Vogan story, we're, we're not dropping that,
Frobenius is acting semi-simply, or there's some, some simplicity on the vague group,
but we're going to be fixing the, fixing some, all the continuous parameters. So, in this
representation theory story, there's some continuous parameters, some action of a center,
or Bernstein center, center of enveloping algebra, or other side, you have things like
eigenvalues of Frobenius, we're going to work at a fixed parameter. And what Vogan suggests is that
representation theory, so this is representation theory at fixed parameter, and these parameters
are, this Vogan calls infinitesimal character in general. When you study a fixed parameter,
these representations can be accessed through this, and there's a very beautiful series of
pictures of how you could use this to get things like described the Grundy group of
representations, extensions between representations, standard objects, the relations. Okay, so this
is what I want to say is, is some version of what I want to call the, the kind of, the constructible
local angular correspondence. So this is, here was the coherent local angular correspondence,
but there's this kind of older story, which is, so let's say, constructible sheaves on a space of
Langland's correspondence for some fixed parameter, let me just call that parameter, I don't know,
so kind of lambda, this lambda is not supposed to have some particular meaning, this is just to
remind you that here I'm looking at Langland's parameters with some fixed eigenvalues of Frobenius
or some fixed infinitesimal character. So they're not the same stack, they're smaller stacks, but,
and constructible sheaves, and should correspond to now represent, union of representations,
but only of pure inner form, so here's really actually direct sum of pure inner forms,
so a finite collection of groups rather than this infinite collection of groups.
And this is what I'd like to call the kind of constructible local angular correspondence.
So one can make this, there's various versions of this, so if you look at Lucas Mason's Brown's
notes, he explains there the, the Adams-Barbish-Vogan picture for real groups,
and the Adams-Barbish-Vogan, they slightly, they have to be careful, you have to be careful
exactly what you mean by this space to get the right, to make it, you have to add a little bit
of unipotence to make the, to get the right space that has these nice interesting geometry,
but, but this is, this is exactly the, what Adams-Barbish-Vogan kind of carried out this
Vogan vision in the Archimedean setting. Oh yeah, so yeah, so this is also representations
with some fixed parameter lambda. Good, so, and, and in fact, so Adams-Barbish-Vogan didn't make
any categorical statements, but there is a statement of this. This is really, again, supposed
to be a categorical equivalence. In the real case, this was formulated by, by, by Surgl.
It's really going to be some equivalence of derived categories between representations
and now constructible sheets on Langland's parameters. I think such things are known
in various cases in the piatic setting, mainly due to works of, of a Lustig and Solveld and others.
So let me put here Lustig, certainly should be mentioned in this context, but I haven't seen a
very general conjecture of this point. I don't know, maybe just don't know the literature enough,
but this is definitely something that's expected. And so what I'd like to, to do is try to relate
these two rows. This is the constructible local Langland's correspondence. It's basically a very,
it's almost just this, so you know, rep of GF sits inside of both, but here it's, you know,
almost everything. It's a small collection. Here it's a much, much bigger thing. And question is,
how do you cut down from here to here? Of course, I think, you know, in, in the Fargo Schultz
lectures, we, they tell you how to do it on one side. You just restrict, you could just restrict
an open piece. These forms are some of the GBs. There's an open locus in Bungee and you just restrict.
So maybe I want to tell you what to put on this side. Okay.
My inclusion.
Oh, I didn't write lamp. Yeah, sorry. So this rep out of fixed lambda sits inside of here.
Okay, sorry. This was maybe two, this was supposed to be a schematic picture. Yeah,
if I look at representations out of fixed lambda, at a fixed infinitesimal character,
I can think of them inside of here. I could, I mean, I can fix infinitesimal character here too.
I mean, I could just impose it. So maybe I shouldn't write it this way, just to be careful.
But there's this picture for fixed infinitesimal character in using constructible sheaves. There's
a picture for arbitrary representations using coherent sheaves. And I'd like to sort of try to
relate the two. Okay. Any questions?
So in the constructible picture, can you also make a version without fixing lambda?
That's a, yeah, that's great. Thank you. So that's somehow one of the problems in the ABV
picture, in Vogan's picture, is that the spaces that you're studying, depending on,
there's these spaces of language parameters you study, and they vary very poorly. They don't,
they're not kind of continuous in lambda. So the kind of conjecture that formulated
in Vogan don't make sense in families. So this story is kind of a family's version.
That's somehow one of the, you know, we also learned that's one of the motivations of this.
It's for studying families. This doesn't make sense for families. The spaces just don't
continue. And again, this is the same issue I'll get to it later, what appeared in John
Francois' talk, why you need Frobenius to have not required to be semi-simple. You just don't get a
nice space this way. Those, you know, spaces, semi-simple, the semi-simple locus is a bad
locus if you vary the eigenvalues. So that's basically what we're going to do is going to add
the unipons. Okay, so I want to switch gears soon into, so I'll wake you up in a couple minutes
to a very different topic, but for now, before I, to do some derived algebraic geometry,
but for now, let me just do one more, a little bit more abrupt theory,
just to give you maybe what this ABV story looks like more concretely. So I said there is a space,
let me, let me write down those spaces. What is the story again in the real setting? And before
that, let me, maybe you could say, if you're like me and you're, get lost in the zoo of different
forms of groups, you might say, where do, what are these pure inner forms? Where do they come from?
These are explained in Olivia's talk. Let me explain a geometric, geometric way,
which explains, for example, very nicely in an article of Bernstein. Like, why are, why, why should
we be studying not representations of a single group, but a collection of groups? And there's a
nice answer. One answer is this, that suppose I have a group G, and I have some Galois actions,
I have some finite group, well, I don't have a group action on G, I'm thinking about the real case.
So I think of this as Z mod two. And let me, and here I'm thinking about this, you know, as really
being the, maybe this, my real involution. And one thing you could ask is representations, so
representations of, of G, of the fixed points, okay, I guess they're called the real group, G,
the fixed points. I mean, I can think of that as relating to, if you'd like, to the stack point mod
this group. So geometrically, okay, there's an interesting stack, which is a classifying
stack of a group that has to do with representations here of that group. But there's something else
you can do, which is instead of taking point mod this group, I, I could take point mod G
and take the fixed points of theta. So there's a notion of homotopy fixed points or fixed points
on a stack. And if you think, what are the fixed points of this involution on, or let me just
call it gamma? What are the fixed points of a group on point mod G? And the answer is not
point mod the stabilizer. That sits inside as a connected component. But what you get is exactly
this union over pure inner forms, forms, let me call it theta i, of point mod G theta i. So if
you like, you can take this as a definition of where pure inner forms are coming from. They're
just studying, you're studying a covariant geometry, you study your group studying from the, say, the
group of algebraic closure, and you work geometrically, you're naturally going to end up with
this collection of groups. So that's somehow why this is going to be very natural to look at this.
It just comes from the geometry. You don't have to put it in by hand. Okay. So what is the,
this Adams-Varbash-Vogan parameterization length, the space of Langley's parameters,
and let me give a non-traditional formulation that's in, that different reformulation of it.
The traditional one you can see in Lucas's notes. So, and let me just, to be simple, I can,
let me just put trivial infinitesimal character. I can, can vary the infinitesimal character
later if you want. But what is the Adams-Varbash stack, the stack of Langley's parameter?
So I have this, again, I have this algebraic involution of G-check. That's involution,
that's, that's, again, that's involution, that's dual to my real form, to my quasi-split real form,
theta. And I'm just going to look at, I'm going to look at the union over the kind of pure inner
forms of sigma, sigma i are, you know, I'd like forms of sigma, of, of, I look at the flag variety
for the dual group, and I mod out by the corresponding symmetric subgroups.
Or if you like, you can call it k sub-sigma. These are symmetric subgroups of G-check,
which are the fixed points of this collection of involution. So we have a collection of
involution that should all be considered together in a family. And this is the space on which you
should be studying constructible sheets. Adams-Varbash will say it slightly differently,
but it's equivalent to that. Let me say it even, even kind of a simpler version,
way of saying it. I look at the flag variety twice, two copies of flag variety. I'm going to mod out
by the diagonal action. This is, you know, thing we usually just, it's easier to just write down
the double cosets, but look at this space. And this has an action of Z mod two, an action of gamma,
where I combine the action on the group and flipping the factors. That's why I wrote it this way.
And this is just the fixed points for that. Okay. So the Adams-Varbash working space,
you can write down in one, in one line, it's this. It's a fixed point of gamma on double cosets.
That's what appears for trivial central character. That's the stack on which constructible sheets are
supposed to describe Harishandra modules. So, you know, so Harishandra modules for this whole inner
class. So, do my notations make sense? Okay. So, I don't know if people really are unhappy by,
some people will be unhappy by not having any general interest. I can write the general one,
but I think it's just adds a little notation. So, again, you can look at my notes for the general
version. And so, what this, what this means is, what is the category, the constructible,
constructible real local angle conjecture, constructible local angle conjecture over
an FR comedian, aka, Surgl's conjecture. It just says that if I look at the direct sum over this
theta i in this pure inner class. Can you clarify what you mean by trivial central character?
Oh, probably not. I think I want the trivial representation.
Yeah, yeah, I want non-singular. Integral non-singular.
Yeah. Okay. And if you want, there's very nice notes of Yanisicularides where he works us out.
So, okay, so now, so what is Surgl's conjecture? So, I look at this theta in this, I don't know,
let me just, and this is my notation for my pure, this pure inner forms. And again,
this is a geometric thing. It's this collection of, if you like, fixed points for inner forms.
I look at the Harishandra modules or representations with some fixed central character, let's say,
generalized infinitesimal character. Let's, here I'm doing zero. You can put something more general
of this G theta i. So, the category that you're interested on the automorphic side
represent, here this means Harishandra modules, if you like, is supposed to be equivalent, or this
is this kind of casual duality equivalence to just constructible sheaves on the ABB space,
which I'm going to write in this very concise form. Okay. So, this is, this is, this is the
real constructible local unknown conjecture. Okay. And if you remember, I mentioned this
Kashiwara Schmidt story. Kashiwara Schmidt says that this also has a geometric description.
Representations of a group by a version of Baylinson Bernstein can be thought of as sheaves
on flag varieties for that group. Like, here it's flag varieties for the dual group. This is Langland's
parameters. Actually, if you think of what this says, this is supposed to be sheaves on the flag
variety for G, again, fixed points. So, actually, the sort of conjecture becomes this very beautiful
looking thing. It's a duality between sheaves on flag varieties for G and duality of sheaves
on flag varieties for G dual. Yeah. So, in the Kashiwara Schmidt story, we're looking at a really
constructible, equivalent, the constructible derived, everything is derived, by the way.
Sorry. Everything is derived. Yeah. So, it means the constructible derived category
or the large version, in version, if you're, I promise not to worry about size.
Yeah. So, in the complex case, in the, for complex groups, you just remove the gamma.
That's the case of complex groups. And that's a theorem of, of, of Sorigal reinterpretation
of, of, of Balanson-Ginsberg, Balanson-Ginsberg and Sorigal. This is in the complex case
for F equals to complex numbers. So, duality between flag varieties for Langland's dual groups.
All right. So, that's, I just, okay. So, I don't know. For representation theorists, I wanted to at
least have something specific written on the board involving representations of real groups.
Are there questions before I change gear?
Balanson-Ginsberg-Sorigal is this statement without the gammas.
So, Balanson-Ginsberg-Sorigal tells you that if you look at the finite Hecke category,
so the derived category of G mod B mod B, and the derived category of G dual mod B dual mod B
dual, they're equivalent, or they're equivalent in the sense of causal duality. It means there's
a graded lifts that are equivalent, or you can, they're equivalent up, equivalent up to fussing
with grading. Let's, let's just say that way. And that, that equivalent up to fussing with grading
is, in the real case, what gives you this Vogan character duality, whether the duality between
Gordney groups rather than isomorphism. But, okay. Yeah, now you can say, so okay, what's
going to happen soon is I'm going to, to replace constructable sheets by D modules.
All of the stacks that are going to appear in my story are going to be these kind of finite
orbit stacks. And so I can, and all the, all the D modules will be regular homonomic. So,
when you say sheets, again, Yanis' question, sheaves, I could say, in the, in the complex case,
I could just say D modules. In the real case, I have to be careful what do I mean.
This is a covariance for a real group. On this side, you could just say D modules without blinking.
Yeah, so you can, by sheave, I mean a kind of constructable version of sheave,
the constructable derived category of D modules. And they'll be the same in all the examples. So,
I'm going to just identify those words. Okay. Other, okay. All right, so now,
now other group of people can wake up. I want to do a complete gear shift. I want to explain a
paradigm for how to relate these two via, via circle actions in derived algebraic geometry.
So, what I'm going to spend much of my next, I hope I get somewhere else, but in any case,
for, for a while now, we're going to be doing some, some nice derived algebraic geometry.
Okay. Okay. And, and so let me maybe at least say the, the structure that we want to get out of
derived algebraic geometry. And the structure I want to get is the following. Let me just,
so let me write it very schematically. So, the paradigm will be, I'm going to get
something, a circle action. I'll have to tell you what do I mean by the circle,
what do I mean by an action. But anyway, but this is a, so the paradigm is we're going to get some
version of the circle, which is going to act on my category of coherent sheaves on these
Langen's parameters in some settings. And now one of the things that gives you whatever this is,
when you have a group acting, you can look at a covariant things. So, I can look at this coherent
sheaves, and I look at a covariant sheaves. Now, this is now, so if this category was, you know,
was K linear, K is my field of coefficients. And I should maybe write once and for all that
everything is going to be living over a field K of characteristic zero. And really, I think of
K as being the complex numbers. So, I don't know, you might as well take K to be complex numbers,
nothing piatic going on. So, K is going to be characteristic zero field. So, when you think
about a covariance for anything, this is always going to be, if this is K linear, this is linear
over K of BS1. It's a natural field of coefficients. Let me, I'll explain where this comes from,
or it co-chains on BS1, and maybe I could just think of it co-chains on BS1 with K coefficient,
which is isomorphic to polynomials in one variable. Okay, I'll explain this. I'm just trying to say,
what happens out of this mechanism is I'll get a category that's now depends on a new variable.
So, it's a deformation.
Degree of view, so the degree of view is going to be two. So, this is the cohomology of Cp infinity.
And so, it's polynomials in a variable of degree two. I'm not going to fuss too much about the
degree. I'm thinking of this as just a one parameter deformation. So, you can think of this
mechanism as giving you a one parameter deformation. Now, what can you do with this
deformation? I could do two things. I can specialize to u equals zero.
Yeah, it's, I'm calling it a covariance sheaves. So, it's, so it's invariant objects in the kind
of derived set, homotopy. Yes, yes, exactly. Yeah, so it's homotopy fixed ones, if you like,
or just think of a covariance sheaves. So, if you have a category depending on a parameter,
so this depends on a parameter u in some graded version of A1. And if I set this u to zero,
I'm going to, in other words, I take this covariance sheaves and I tensor over k of u
with k. So, that's what I'll call, if you'd like, invariant sheaves. The key point is that this
is going to be a full subcategory of what I had before. That's a general principle, again,
general statement that this deformation, when you specialize to zero, you don't get the whole
category. So, it's not actually a deformation of the entire category, it's a deformation of some
full subcategory. So, the claim is some full subcategory of this is going to deform over u,
and when u is generic, so really, I can't really specialize, I want to say u equals one, that
doesn't quite make sense, I have to invert u. So, u is generic, I look at this coherent category
and I tensor over k of u with k of u, u inverse, when you invert, what you'll get is this constructable
category, is what I was calling sheaves, the constructable category of sheaves.
But now, well, okay, that didn't depend on k u inverse, and so I just can, if you'd like,
add this u variable in some auxiliary way, it's just the base change of this.
Yeah, that's going to be the next topic. Yeah, I'm going to, so I'm just trying to say whatever
it is, this is what I want to get out of it. Whatever the last one action is, it's going to
give me a full subcategory, and a deformation of that full subcategory, which generically
will give me the constructable sheaves. So, this is going to be this paradigm,
some full subcategory of coherent sheaves will get this u deformation, which generically will give
these guys. Yeah, yeah, there's two things you could do. So, this thing makes sense on then to
big L. This deformation makes sense over the big L. Once you specialize an infinitesimal character,
you'll get an identification of this. So, this is for each infinitesimal character. So, I mean,
the nice thing is you get a category that doesn't depend on infinitesimal category. So, if you'd
like, it's a family's version of the constructable category. In the sense that whenever I specialize
the infinitesimal character, I'll identify this junk with constructable sheaves.
It's almost. So, there's a very beautiful general statement that I'll say.
So, this category makes sense, and this once you fix lambda,
fix lambda will give this sheaves to lambda, this constructable category for lambda.
I'll state all these things more precisely. I just wanted to have a kind of picture of what
I'm going to get at. Oh, no, because I just couldn't decide on, I don't know, is it, can't,
I don't know. You choose D-modules. Maybe I'll let me call D-modules. So, really, it's naturally
going to be about D-modules. But yeah, okay, so just to add a third notation to confuse everyone.
Okay, so that's the structure I want to present. So, I want to say some abstract nonsense,
some general story about it, and then hopefully I'll have some time at the end,
and I'll spell out in the examples, in these kind of examples exactly what happens, how this,
how this, so I want to explain, for example, is how these, these kind of zortical conjectures
follow from this geometric angular type conjectures by S1 equivalent localization.
Okay, so, but this story is really for me, for David and I learned me, I think this is where we
first decided we needed to learn derived algebraic geometry. We were thinking about this representation
theory problem, and you look at one side and there was some geometric, so on the, on Cp1,
there's an action of a circle, you know, the usual, you can rotate, and it fixes the two poles.
There's an honest circle action. Now, you follow like some of these geometric angular equivalents,
it's like this, you look on the other side and you say, wait, there's supposed to be some circle
action on these space of langauge parameters. Those space of langauge parameters where there's
nothing derived about them. They're just these concretely little stacks I wrote down, you know,
deltas and flags with some equation. There's no S1 symmetry out there. This is where you need
derived algebraic geometry to see this, some kind of, something that on the automorphic side,
in the real case, is really just a manifest rotation symmetry. On the spectral side is
somehow much more derived.
Yeah, because I was, I was cheating. I mean, it's a graded a1. Maybe you should say a1 mod gm.
I mean, if you have an x, you should really think.
Yeah, okay.
Yeah, exactly. Yeah, so u is an element in degree two. This a, this affine line is a line of degree
two. If you have things that have some auxiliary kind of mixed structures, some auxiliary gm action,
you can, you can shift that two back to zero. So there's this various games you can play with
this degree. But the affine line, the deformations that I'm going to construct are naturally
live over a base of degree two. Yeah.
Yeah, right. Otherwise, you have to think much more smartly.
Yeah, I just, I just meant that I look at it. That's a terrible notation. I just meant
sheaves on the space of Langland's parameters for fixed lambda. So I'm not,
so I had these spaces of Langland's parameters and they have, you know, in the, in the unipotent
case, there's this eigenvalues of Frobenius. There's a big space where I let those vary.
There's a small space where I fix them.
That's right. So I'm saying if you look at co as one of the entire space,
it has this nice deformation, which one eigenvalue at a time gives you the constructable category.
Okay. All right. So now we shift. When does my talk end?
12, 25. It always feels like there's a lot of time when someone else is speaking and then,
okay. All right. All right. So now I want to talk, tell you a story about this
story. We kind of give it a name. It's kind of loop spaces, the relation between loop spaces
and D modules or loop spaces and connections. So it's a story in derived algebraic geometry.
And it's really just a geometric. It's kind of a geometric interpretation.
It's a geometric or derived geometric take on the theory of a Hawkshield and cyclic homology.
So the theory of Hawkshield and cyclic homology has, which you may won't need to know for this
story, has a geometric interpretation that makes it sort of very cute. So first of all,
as I said, there are going to be no more constructable sheaves. I'm going to replace them with D
modules. I'm going to study D modules in the settings. I'm interested in those two will be the same.
Okay. So what I'd like to understand is how to get D, so you know, so if you look at what I've
been talking about so far, I have some category of D modules on one side and I have some category of
coherent sheaves on a maybe different space and you're supposed to relate them.
So if you, so how are you supposed to think there's an obvious thing to say if you know
something about D modules, the ring of differential operators is a deformation.
So the ring of differential operators is a deformation
of the symmetric algebra of the tangent space. So here, so here X is going to be a smooth scheme
and characteristic zero. So it looks like a symmetric algebra of the tangent bundle and
this is just the Ries construction. By deformation, I just mean this is the associated graded of D
and so there's a family over A1, which is the Ries family, where at lambda equals zero, I get
the symmetric algebra of the tangent bundle and away from zero, I get the ring of differential
operators. Okay, so the ring of differential operators has an associated graded, which is
symmetric algebra tangent bundle, which is functions on the cotangent bundle.
So now it passed to modules. Modules for differential operators sit in a natural Ries family
with quasi-coherent sheaves, so D modules have a natural
deformation to sheaves on the cotangent bundle. So that's the kind of
theory if you'd like. You can think about this arrow as deformation quantization
or this arrow you can think of as just associated grade or microlocalization.
There's a nice relation between geometry of D modules or sheaves in general
and the geometry of the cotangent bundle. So that's a basic mechanism that relates,
if you like, constructible sheaves to cotangent bundles, to coherent sheaves on a cotangent bundle.
So at some level, that's all we're going to be doing. That's how we're going to pass between
coherent and constructible. It's going to be some version of this,
but you'll have to be an adapted version. Does this make sense, everyone?
What I mean by the Ries construction here? Okay, so the basic idea is I can relate
differential operators with sheaves on the cotangent bundle as a family over the affine line,
and here it's really a graded affine line. It's an A1, which this is a GM-equivariant family over A1.
It's also taking something filtered and deforming it to associated graded.
There's a GM-equivariant family over the line. Now, okay, that's the family I want to get,
but there's a kind of a causal dual picture of this family that's going to be
the way I'm going to actually, what I'm actually going to study. So there's a causal dual picture,
which is given by the state of cyclic homology. So what do I mean by this casual duality?
So I'm just going to replace, basically it's just the, okay, so I'm going to replace
the cotangent bundle of X by some shifted version of the tangent bundle of X.
Now, this is a fancy way of saying on the level of functions, here I looked at the symmetric
algebra of the tangent space. This thing is built so that I get the exterior algebra on the
cotangent space, aka differential forms. I'm going to be a little sloppy about plus versus minus
degrees, but so, okay, but so the idea is that rather than the thing of symmetric algebra with
tangent space, you can think about the exterior algebra with cotangent space, in other words,
differential forms. And this thing has, now if you like, why am I calling this casual duality?
If you look at modules for this, so if you look at sheaves on this, so if I look at modules
for this algebra and modules for this algebra, these two are derived equivalent.
They're derived equivalent. And again, I have to be a little careful about adjectives,
about sizes of modules, but there's some kind of standard yoga of how to write this. This is the
casual duality of Bernstein-Gelfand-Gelfand. Okay, so there's, you can rewrite things instead
of a tangent bundle using a cotangent bundle, but really what I was interested in, I was interested
in deforming this to differential operators. This has, there's a natural deformation here,
which is the DRAM complex. You might say, where is the deformation of the DRAM complex? I could
just put a parameter lambda in front of the DRAM differential. That's a family, which at zero
gives me differential forms, at one gives me the usual DRAM complex. So this is reconstruction
for differential operators is dual to the DRAM complex. And so you can rewrite the whole theory
of D modules and differential operators and so on, instead of using differential operators,
you don't need to ever talk about differential operators, you could just use the DRAM complex.
This is the usual story that a flat connection is given by an operator, Navla, with the usual
stuff. Okay, so that's just, it's just a fancy way of saying the usual thing. A flat connection is
given by a connection operator. That's right. This is a DG algebra with trivial differential,
and now I'm deforming that, I'm adding this DRAM differential. So that's an interesting
G algebra. Okay, so I'm going to rewrite things in terms of differential forms, and the,
these algebra differential forms has this very beautiful
source in derived algebraic geometry. The very beautiful picture of this, which again is
an interpretation of, so algebraically differential forms can be, so this is,
what I want to tell you now is an interpretation of the statement that differential forms are
isomorphic to the Hockschild homology of functions. This is known as the Hockschild
Causton-Rosenberg theorem. So this has a geometric interpretation, which is what I want to explain.
You haven't seen Hockschild homology. You don't need to think about it for this. So what is this,
so what, what is, how do I want to get, what is this saying? If I want to get differential forms,
I can get them up to, and this is an annoying but sadly necessary part of the subject,
you have to change the degrees. You have to put them in negative degrees, rather than
positive degrees, like we usually think of the Diracombe. Think of this kind of homologically,
and why do I want to think about them homologically? Because then I can get them as a tour.
So here's the, you know, the formula, if I look at functions, the structure sheet of the diagonal,
so here I have the diagonal inside of x cross x, again x was my smooth scheme.
If I look at functions on diagonal, and I take their derived intersection
with functions on the diagonal over functions on x cross x, I get differential forms.
That's a way to get differential forms. So in, in derived algebraic geometry, we just think of
these rings as rings of coefficient, we just expect. And what this is, so I take spec of this.
Yes? Yes, so this is end of being formal, of course. So these statements are actually all
true for x singular as well, where you replace tangent bundles by tangent complexes, and then,
then there'll be differentials around. But in the smooth case, this is really just.
Okay, so, so let me take spec of this. I'm going to think about these as ring of functions or
something, and what this is saying is that if I take the diagonal inside of x cross x,
and I take its derived self-intersection, which I'll stop writing derived because I
promised everything was derived, the self-intersection of the diagonal, that's a thing whose functions
should be calculated by this. And the claim is that derived self, this statement is saying that
the self-intersection of diagonal is isomorphic to a shifted version of the tangent bundle.
That's just names for this equality. Okay, now, but so we're getting a differential form, but
something here, this is something kind of very fundamental, self-intersection of the diagonal
is something very fundamental. And so I'm going to give it another name, I'm going to call it the
derived loop space of x. So this is called the derived loop space. Why is it called the derived
loop space? Because it has a description as a loop space. So if you like, maybe let's write it,
write the writing diagonal, let me write it, it's fiber product of x with itself over x cross x.
That's a self-intersection diagonal. You can think about this as maps from, what is, what is this
saying? You have two points in x. Okay, this is x cross x, it's two points in x, except that I want
them to be on the diagonal, so they should be equal. But I also want them to be on the diagonal,
so they should be equal. So this is my S1. Okay, I think Harrison wrote this nicely,
there's no, you know, you can write this in some funny way like that. But anyway, it's two points
that are glued over, that are glued twice. That's when you map from this to x, you get the
self-intersection of the diagonal. Now, so this is the circle, so where does this thing live?
I don't know, I guess I'm supposed to use the word anima. It's an anima, it's a homotopy type,
it's a simplicial set, it's a topological space. These are all different words for kind of the
same thing here, except I'm not supposed to use the word topological space anymore.
I'm being recorded, so you know, I don't know what, you know. Okay, but so here,
but another name, of course, the name I prefer for this is bz. So it's, so rather than two
points and two arrows, you can think of it as one point and one loop. It's the classifying space of
the circle. So I like to study bz, and it's, so this is, so this is the kind, that's a better
intuition when you say, this one really has relatively little to do with gm. I mean, if you
like, it has to do with the homotopy type of gm, it's not the algebraic object gm,
it's more like bz, it's a classifying stack of the integers. And
you can, yeah, no, absolutely, you can definitely think of the derived tensor product.
Well, that's right, but you know, but you know, but you already heard the beginning of my talk
when I said that the whole point was about circle actions. So if I think about this derived
tensor product, if I think about the complex of differential forms, I don't see any
symmetry. But if I think about this as maps from s1 to x, if I just use this notation,
whatever it means, it's clear that, you know, that if this s1 is a group, this group acts.
So s1 as a group object in whatever world this is, will act on this mapping space.
And a wonderful thing that was discovered by Kahn and Fagan-Sigan, not in this language,
was that that action, so you ask, what does that mean to give an action of s1 on something like
that? So Kahn formalizes this in the language of cyclic objects. But you can just spell out what
that means very concretely that, so yeah, so what does it mean to have a circle action? And there's
kind of two manifestations, and it's hard for me to keep them both in my head at once, but there's
kind of two versions. So what does it mean for a circle action to act, say, on, say, let's say,
to act on x, a scheme? And let me, might as well assume, it's affine, let me just think of it as
being speck of r, some ring. What it means is really, so you say, okay, the circle is this abstract
guy, let me linearize it. It has a linearization, which is, well, okay, let me just write it. So
you have this algebra, so it's a, when you have an act, what does it mean to act a group on something,
you should think of an action of the corresponding group algebra, a module for the group algebra.
So I need to tell you, what do I mean when I say an s1 action, what kind of group algebra am I allowed
to take? And I said s1 you should think of as a homotopic object, so you're not allowed to think
of like smooth functions or any kind of functions like that, you need to some homotopic functions.
So my, or distributions for the group algebra, and this is my group algebra. So chains on the circle,
or if you like in characteristic zero, I might as well just think of homology of the circle.
It has a convolution product, this is the group algebra of the circle. And so what this means is
an action, it just means that r is acted on by this DGA, well it's actually differential, DGA with no
differential, which is just a, this is just means an action of this corresponds to a degree minus
one derivation. That's all it means, you have this algebra, chains over the circle, it's generated by
the fundamental clause of the circle with square zero, just kind of square zero, you have just a
single operator of square zero. Well it's, it's the group algebra operation, right, so it's, it's,
it's, I guess called Pontriagin product, right, so if I have a map from g cross g to g, I can push
forward, which is convolution, right, so, so I have chains on, on g, tensor chains on g goes to
chains on g by push, by push forward. I mean this for the entire complex of chains, I'm just saying
that the chain, let's just forget about chains, the homology, homology of a topological group
is, is always an associative algebra, which in the discrete cases is the group algebra of that
finite group, the discrete group. That's, yeah, yeah, yeah. Okay, so, so the point is that what,
and what Kahn discovered is that, so all you're looking for is a single operator of degree minus
one, but notice that I put differential forms in negative degrees, so there's a natural thing of
degree minus one, namely the Durand differential. Yeah, so, so it looks like, you know, K of eta,
eta squared, where degree of eta is minus one, so it's just a single operator,
which is, if you like, integrating over a circle on differential forms, it's a single operator,
of degree minus one was raised to zero, and so this, when, if you take r in the case where r was
differential forms, this action of the circle is just given by the Durand differential. This is
Kahn's interpretation. This is what cyclic homology is about. The Durand differential can be interpreted
as this S1 action. Okay, so, you know, at this point, you should complain, and you have a perfectly,
right, to complain. I'm going very, very far to just tell you about the Durand differential, right?
You already knew the Durand differential. You didn't need all of this to tell you the Durand
differential. Similarly, you don't need all of this to tell you D-modules. I can, I can,
but let me still do it. Let me still tell you how to say D-modules in this language.
And so, let me, let me say a couple of things. So, if I give you a group, you know, if I give you a,
if I have a group acting on a vector space over K, then if I look at the invariance,
right, that's from the trivial representation to B, this carries an action of endomorphisms
of the trivial. And, and since I'm cheating in everything you derive, this is really
co-chains on BG. Okay, so, when you take invariance in the derived setting,
you get an act, if you like, this is a usual Hecker algebra pattern. We were familiar with
what acts on invariance. There's something that acts, which is like this is G-mod G-mod G.
That's what acts on the invariance. So, in the case of the circle, when I take invariance for
the circle action, I'll get an action. So, if G is my S1, this co-chains on BG, that's co-chains
on the homology of Cp infinity, which is polynomials in a variable U of degree two.
Okay. So, if I have a circle action in this sense, if I take a covariant
object, I'm going to get things that are linear, I'm going to get this parameter U.
Okay. So, sorry, I forgot again what I'm supposed to end. 25. Okay. So, now, if I give you,
if, similarly, if you have a group acting on a category, which is k-linear category,
and I take the equivalent object, these are the, you know,
equivalent objects, this is going to be linear again over the same ring, over this
chromology of BG.
In general, it's not. In general, it's not at all a full subcategory. I mean, in fact,
I never, basically, yeah. Sorry. And the question was, is this a full subcategory,
and the answer is essentially never. Yeah. So, this is more structure, and this is an object
together with the diagram of equivalence. So, you have identifications of, you know,
pullback and projection.
Let me cheat. One answer is that, you know, I said there's two ways to think of the circle.
There's a way of thinking about the circle as this differential, it's coming from this
homology. The other way is to just think of it as BZ. An action of a circle. So, S1
acting on a category, this is BZ. So, what does it mean for BZ to act on a category? It means
an automorphism, an automorphism of the identity functor. So, that's a different kind of flavor
takes, if you'd like. But you have an automorphism of the identity functor, and so these are objects
together with the trivialization of that automorphism. That's what equivalence means.
Okay. So, now, so, now, so about John Frantz's question about full subcategory,
of course, you know, it's not at all a full subcategory in general, but something cool
happens for the circle is that the trivial representation, the heck algebra for the
trivial representation is sort of smart enough. In other words, what do I mean by that? You know,
if I have a heck algebra, the best thing I could hope is, you know, some representations
generated by their invariance would be equivalent to modules for the heck algebra.
In this case, I have that if V carries a vector space with a circle action,
and I take V in invariant objects, so now that's a module for this polynomials in U,
this crochet and then BS1, this polynomials in U, I can then try to go the adjoint functor,
I could take the invariance and I can tensor over K of U with K, I can set U to zero. So,
I set U equals zero. And the beautiful thing, which is special to, I mean, somehow because the
group is connected, this is total nonsense for a finite group, this is isomorphic to V.
So, if you like, the category represents, everything is generated by the trivial representation,
and you're just equivalent to modules for this heck algebra. So, this is a, if you like,
Goreski-Cottwitz and McPherson version of causul duality. So, the point is that in the case of
circle actions, you can actually set U to zero and recover the original vector space from where
you are. So, in this case of categories with the circle action, if C, if S1 acts on a category,
then I could take C S1, this is now K of U linear category, and if I set U to zero,
you might have hoped to get back where you started, but sadly you don't quite, but you do get a full
subcategory. So, on level of vector spaces, which is on level of hums, taking S1 invariance is kind
of painless. You can undo it, if you remember this action. On level categories, some objects just
won't be seen by, will not talk to, equivalent objects at all. You just take the circle acting
on itself, for example. You'll see, you know, so there might not be a lot of equivalent objects,
but you get a full subcategory out of this, out of this picture. So, let me call this the S1
invariance. Just to give it a name. This too, yeah.
In the first data, you have G acts on G. So, G makes it in some stable, in this category.
The additivity is not necessary for, to talk about, so the question was, what do I mean by
circle action on a category, where I understand in linear setting, but you can talk about a group
acting on a category, the category doesn't have to have any linearity property. Here,
it's really a topological object, a topological group can act on any, any infinity category of
any kind. But my conclusion is that how, how you, you get, you get an action of a non-connective thing.
It's just, it just means it's linear. I mean, you can talk about notion of a category linear
over any ring, but added, you know, connective or not. You have a commutative ring, you could
talk about a category being linear over that commutative ring. It just means the home spaces
are enriched in, in modules. So, okay. So, now I'm sure I've lost people again. So, let me,
let me just write some statements. Okay. I guess I'm, I'm going to miss my main punch line,
but that's, that's okay. So, what, so the state, what, here's a kind of statement and there's a
theorem. And this theorem you can think of as being very formal, as just kind of reinterpretation
of all this kind of deem, of this cyclic homology story. It appears in a paper of mine and, and
David Nadler, and also in work of Toeann and Vitzosi around the same time. And for singular
schemes, this, it was extended by, by Pregel. So, I don't need to write x smooth. And it says that
if I look at coherent sheaves on this derived loop space, so here x is a scheme. And let me
remind you that this derived loop space is really just an annoying name for this shifted
tangent bundle, which is just an annoying name for differential forms. But now if I take circle
equivalence, that this is the same as, as filtered D modules. But let me just, rather than doing the
filtered version, we're maybe more familiar with just ordinary D module. So if I tensor with this k
of u, let's invert u. So think of this as the s one tape construction and inverting this equivalent
parameter. What I get is just D modules. Well, except the D modules didn't have this annoying
u parameter in them. So I just add it by hand. So you can get D modules out of coherent sheaves
by this circle action. This is a fancy way of saying, look at coherent sheaves, add the action
of the dram differential. You're looking at DG modules for the dram complex. That's what D modules
are. So again, so far I've been spending a lot of time of derived algebraic geometry,
and I'm just telling you things you already know, or in a very complicated way. So let me just
finish with, why is this a useful point of view? And the thing that makes us useful is that we're
going to take x is now going to be a stack. And I say, okay, things are going to get much worse.
But they're going to get much more interesting in interesting ways. So for example, so first
of all, the stacks I'm going to care about are going to be finite orbit stacks, like a
quotient of a nice smooth scheme, say by a group with finitely many orbits. If it's a finite orbit
stack, then this derived loop space nonsense will not be derived. There'll be nothing derived about
it. It'll be an ordinary algebraic stack. So the spaces I'm going to be talking about
are not going to be derived unlike the case of a scheme. So the content is going to be very
different. So again, what is this derived loop space? Again, I defined it as maps from a circle,
or if you'd like a self-intersection of the diagonal, what does mean self-intersection
of diagonal? It means a point together with an automorphism. So this is just what's known as the
inertia stack. Given a stack, you can talk about the inertia stack. It's a point together with
an automorphism, the collection of all the inertia groups. So in general, if x is not a finite orbit
stack, this will be a derived version of the inertia stack. But in our setting, it literally is
just going to be the name thing you write down, a point with an automorphism. Now, so maybe to
write down an example, the only example, one example is just to write down x to be,
so if you take x, what's my favorite stack? It's point mod a group. And then this derived
loop space maps from a circle to point mod g. It just means g local systems on the circle.
So, and so that means I have a single element of g, which is the monodrome as I go around the
circle up to conjugation. So that's what this, this is the prototypical example of a derived
loop space. Or if you want another example, so I could write down lots of examples that appeared
in the talk in the beginning, they won't have, I don't have much time. But for example, if you look
at this kind of stack, double cosets for the borrel, then you get a version of the Steinberg
variety. You get a group element in g and two flags, such that g sits in the intersections.
That's the kind of a version of the Steinberg variety up to the group. So that's a kind of
space that we're getting in the case of loop spaces. The space of unipot and langenlens parameters
that appeared in the talk also appears naturally as a, essentially as a loop space.
I don't know if I should write that down. Okay, maybe I should write that down. If you take the
nilpont cone of a Lie algebra and you mod out by the group, but also by gm,
I'm going to throw in this extra gm rescaling the nilpont cone. If I take the loop space,
I get basically this set of obtained parameters. I get an element g in g, q in gm,
n in the nilpont cone, such that gn equals qn up to conjugation.
So the space of unipot and langenlens parameters is essentially a loop space.
Okay. So the, unfortunately, I'm kind of, oh, I'm already past that. So
I'm sorry? Oh, I just meant the adjoint action. I don't know, add g of, sorry. Yeah.
G acting on n. So the first message to say is that loop spaces appear very naturally. Spaces
of langenlens parameters tend to have s1 actions on them. And since I'm not of time,
I won't give an example. The next thing to say is that when you do this s1 localization
on these space of langenlens parameters, you exactly go from these categorically
hidden sheets by a version of that theorem, you go to categories of constructible sheets.
So can you write this down? Yeah.
I mean, I'm over time, but an organizer just asked me a question. So I said,
you asked this. I apologize to those who did not want to hear this.
Let me just write down the following simple thing, which is Jordan decomposition for a group.
So if I look at g mod g, this is the loop space of x in the case of x is bg. So this is going to be
my lx. That has a map to the adjoint quotient or carton mod w. Now inside of here, I have the
formal completion of the loop space along constant loops. That's again something you can
define in general. In this case, it's just if you like the formal group, if you like x of the
Lie algebra mod g. So that's something I can do in general. The claim is that if you do this
s1 localization story on here, you're going to get d-modules. The same theorem that I stated up
there works for stacks if you put in formal loop spaces. Now that's not so useful still,
but here's the cool thing. And the cool thing is there's this in the middle. I'm going to just move
that. There's a beautiful theorem of Harrison Chen in his thesis. So Chen, there's a theorem
which is called Jordan decomposition. That's not the paper. The theorem is Jordan decomposition
of loops. And it gives a version of Jordan decomposition for let me say the usual Jordan
decomposition and his generalizes it. So if I take the class of a semi-simple element in here,
and I look at its formal neighborhood, the formal neighborhood of a semi-simple element,
so that's what happens when I fix parameters. So what happens here? Well, you have a semi-simple
element and you have automorphisms, things that commute with it. So the claim is what you get here
is something that you might call what we, Nadler and I defined as the unipwned loop space of x.
This is something you can define in general. Let me not give the formula. It makes sense for any
stack. There's something called the unipwned loop space, which in this case just means you look at
the centralizer of s and you look at unipwned elements, things formally close, formal neighborhood
of unipwned elements, mod, mod the group. Or so in other words, this unipwned loop space of x,
sorry, of x, s, sorry, I'm trying to go too fast. So what I want to say is that if you pick a parameter,
so let me state the Jordan decomposition theorem. So if you look at the inverse image,
inverse image in Lx of the formal neighborhood of a semi-simple element,
yeah, I don't know, formal neighborhood of the class, s is an element of semi-simple element of the
group. I'm looking at the formal neighborhood of the semi-simple element. It's identified with the
unipwned loop space of the fixed points of s, mod the centralizer of s.
And this is true for any x where x is, let's say, a scheme mod a reductive group. So here
it's say a scheme and here I have a reductive group, so I can make sense of all these words.
So the cool thing, so just finish with this last sentence, that what happens is
s1 equivalence sheets on loop spaces are much more interesting than d-modules.
They have this cool dependence on parameters. If you fix those parameters,
one parameter at a time, you get a much simpler space, this thing called the unipwned loop space,
where the same naive picture holds. So we prove that the s1 localization story on unipwned loop
spaces just gives d-modules. So when you take this unipwned loop space and do s1 equivalent
sheaves, you get d-modules on this xs. So that's exactly the pattern that's going on here. You
look at coherent sheaves here, you do s1 localization, one parameter at a time, you're getting these
not loop spaces but these unipwned loop spaces and you get exactly categories of d-modules. So
that's the mechanism that relates it to. So I'm happy to say a lot more in Q&A but I should really stop.
