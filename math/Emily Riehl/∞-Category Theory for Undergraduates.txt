Okay, welcome everyone. It's a pleasure to have this opportunity to speak to you. So
firstly I want to acknowledge this talk was originally prepared for the Berkeley Logic
Colloquium last week. It was at the invitation of Piero Simone and I'm very grateful for
them to having this opportunity to speak and I guess grateful for you for encouraging
me to give a second iteration of this talk. So the audience in the Berkeley Logic Colloquium
are people who pay attention to the aspects of mathematics that many of the rest of the
practicing mathematicians don't. So the formal logic that goes into rigorous understanding
of mathematical proof or the axioms of set theory upon which many of those proofs are
implicitly based and you know there's something a bit curious in that sort of the generic
mathematician often doesn't know any of the axioms of set theory and has never taken a
course in propositional logic. That certainly was my experience as well. So what was fun
about that talk was having an opportunity to speak to the experts as a non-expert and
I want to make clear that I'm sort of very much a non-expert in foundations or type theory
which will be one of the subjects of the talk. So I thought I'd start by reading the abstract
actually because the title I think can be a little bit confusing and I just want to make
it clear what the project of this talk is going to be. So what the abstract said is
that at its current state-of-the-art infinity category theory is challenging to explain
even to specialists in closely related mathematical areas. Nevertheless, historical experience
suggests that in say a century's time we will routinely teach this material to undergraduates.
This talk describes one dream about how this might come about under the assumption that
twenty-second century undergraduates have absorbed the background intuitions of homotopy
type theory also known as univalent foundations. So that's kind of the thesis of this talk.
So what I'm inviting us to do today is let's imagine that we're sort of a hundred years
in the future and the sort of informal understanding of set theory and logic that undergraduate
mathematics students pick up today in our courses has been replaced by some sort of
new foundations that are still under development. So this is definitely a speculative aspect
of this. And so under that imagining that rather than learning how to write mathematical
proofs as is classically done today, we've learned how to write proofs based on homotopy
type theory, then I couldn't imagine an advanced undergraduate course on infinity category
theory. So the plan is I'm going to sketch this out for you in two parts. Firstly, I'm
going to try to give a lightning fast introduction to undergraduate level informal homotopy type
theory. And I want to emphasize both the undergraduate level and the informal aspects of that part.
And then the second part, I'm going to sketch how we could use those foundations to more
simply describe what an infinity category is, improve some basic results of infinity
category theory. Experience suggests I'm not going to have a lot of time to get too deep
into that, but maybe enough to give a sense of how it's how this dream could perhaps be
true. Okay, so I guess let's just go ahead and begin with the undergraduate level informal
homotopy type theory. And I should say, right, so firstly, what is type theory? It's a formal
system for writing mathematical proofs. It's also a programming language, I'm really going
to deemphasize that aspect in the talk today. And but what I'm going to, the way I'm going to
introduce type theory here is sort of deliberately informally, like, again, when you're a
mathematics student today, you don't learn how to write a formal proof. Though there, there is such
a thing in sort of classical foundations, there's a meaning of formal proof, but we're not, we're
not doing anything like that. And instead, this is sort of an informal proof of proof on paper,
very much like we write proofs on paper today, but based on the sort of dependent type theory and
later homotopy type theory foundations as opposed to classical foundations. And one other thing I
would say is, is if I were, if this were meant to be a sketch of a graduate level introduction
to homotopy type theory, I would talk about its categorical semantics. So how we interpret a proof
in homotopy type theory in the foundations that most of us work in today. But that's really
an advanced topic. So understanding the precise relationship between this type of mathematics
and the type of mathematics you might be familiar with is very technical and very challenging.
And this is a talk for undergraduates quote unquote, so I don't want to get into that at all.
I want to invite you, when you're in this talk, to pretend that you're, you've never learned how
to write a proof. You have no idea what mathematics is, and you're seeing all of this for the first
time. And if that's too difficult, you can imagine that you're a computer and you're trying to learn
how to recognize what a mathematical proof is. That is, that's kind of what we're doing with
these computer proof assistants is we're training a computer who knows nothing about mathematics,
how to recognize some valid mathematical arguments. Okay, so look at this from fresh
eyes and try not to think about how this relates to set theory, because I mean, there is an explanation
there, there is sort of mutual consistency proofs, but it's, it's quite a bit more complicated. And
I think if we approach this a little bit more naively, we might be able to develop the intuitions
more quickly, you know, kind of like, if you're, well, I don't know, or I'm trying to help everyone
learn a new language, let's just go ahead and begin. So homotopy type theory is based on something
called dependent type theory. And this is quite a bit older than homotopy type theory, which is
really quite new. So type theory goes back to Russell and church, dependent type theory, the
rules that I'll talk about today are due to per Martin Lyft, the 1970s. And the point is this all
predates the homotopy interpretation by several decades. So what is it? Firstly, it's a formal
system of inference rules that can be combined to form derivations. So it is a way to write formal
mathematics proofs that I'm not going to emphasize those aspects so much today. So independent type
theory, there are four kinds of well formed formulas. So that's a phrase that's familiar to
the logicians. But what it, what it means is there are sort of four types of grammatically
correct sentences. So a proof is built by concatenating a bunch of these grammatically
correct sentences and a particular order that's permitted by the rules. And so we're only going
to require two of those types of sentences. These are technically called judgments. And
what the judgments are is I can say that something is a type. So that's one of these
sort of primitive judgments, one of these valid things to say in type theory. And then the other
thing I can say is that something is a term of a given type. And those are the only two types of
mathematical sentences we're going to need today. So it's, it's valid to assert that something is
a type and it's valid to assert that something is a term of a given type. All right. So I want to
sort of emphasize a color scheme. Firstly, I'm using red for types and I'm using orange for
terms and red and orange are exclusively used in that way. So if it's in red and you're not sure
whether it's a type, it's a type. If you're, if it's an orange, it's going to be a term of a given
type. I guess one thing to note to say that something is a term, you always have to say what
type it is in and terms will only belong to a given type. So there's no, there's no sort of
ambiguity of an element being an element of many different sets. A term just belongs to
one type and you could sort of map it into a different type if you wanted, but that, you know,
everything is sort of well typed. So the way that we're going to write these things informally
and informal proof is what I've written over here. We'll say something is a type or something is a
term of a given type. The way it looks formally is in gray. I'm including some of these sort of
formal syntax, but again, I don't want to emphasize that too much. So if we, if we do look at the
formal syntax, there's something that I've hidden in gray. Gray is a color that I'm inviting you
to ignore, but I'll briefly mention what it is. This gamma here is something called a context and
what it does is it declares the types of any variables that appear in sort of the rest of the
judgment, the rest of the well formed formula. So the sort of most basic example of this is
in the context of a variable X of type A, so a term of type A, we could have another type B of X
where the specification of B of X might depend on the particular value of that X. So an example
that would be familiar is there's a Euclidean space, there's a vector space, r to the n,
for each natural number n. So if you have a natural number n in mind, maybe two or three,
then you get two or three dimensional Euclidean space. But you know, once you've declared that
n is a natural number, you can think about rn for any n. And then there's a corresponding thing for
terms that a term might also depend on a previously specified term and a previously specified type,
we think of these as being sort of families of types or families of terms. An example is there's
a zero vector in any Euclidean space. Though the specification, the definition of that zero
vector depends on knowing what n is because you need to know sort of how many zeros does to stick
in in some sense. Okay, so this is the dependent aspect of dependent type theory is that types
can depend on terms of other things. And I remember when I was learning for this for the first time,
I found context very confusing. But one thing to think about is when you state a theorem, you sort
of say, you know, let n be a natural number and let p be a prime and let a and b be relatively
prime integers or whatever. All that let stuff is the context, you're sort of declaring the variables.
And then the thing that you say at the end is the probably the type in context, but I'll get to that.
Okay, so again, type theory is a formal system. So we have these two sort of valid things we can
say, we can say that something is a type or something is a term of a type. And then there
are four different kinds of rules that can be used in derivations. So if I want to stick these
judgments together, if I want to stick these sentences together in a way that makes a valid
proof that your computer can recognize is a proof. There are four rules that sort of tell me when
it's valid to assert a judgment. So they're called the formation rule, the introduction rule,
the elimination rule, and the computation rules. And I'll introduce all of these in an example.
So what the formation rule says is it said, if I'm given two types a and b, then I can form a new
type. Here, I'll tell you about the rules for something called the product type. So the formation
rule for the product types is given types a and b, there is a product type, a times b. And product
type is just a name. This is just a notation. The symbol doesn't mean anything in absence of the
notation. But the other rules that I'll tell you about the introduction, the elimination,
computation rules are what makes this behave like a product that you may be familiar with.
And in gray, we won't see this very much again, but just very briefly. There is a way to sort of
make this formal so that proofs now look like derivation trees. And this is what this rule
looks like from that perspective. So if I'm given a pair of types, then I'm allowed to assert that I
have this other type. Okay, so then the introduction rules, what they do is they introduce new terms
and the types that were just formed by the formation rule. So now that we have a product type, we
might want to have terms of the product type. And what the introduction rule says, in the case of the
product type, is it says that if I'm given any terms little a and a and little b and b, then
there is a term little a comma b in a times b. And again, this pairing thing is just notation. So I
could have written this in a different way. I could call this p if I want. But I mean, it's good to
indicate it had some dependency on a and b because it certainly does. So the introduction rule says
that whenever I have terms of the given types, I can pair them and get a term of the product type.
All right. So then the next type of rule is something called an elimination rule. And what it
does is it allows us to use these new terms. So it says if you're given an arbitrary term of the
product type, so an arbitrary p, then what the elimination rule for the product type tells us
is that from this, we can get a term of type a and also a term of type b. And again, I'm using
notation for this just to suggest to those of you who are familiar with products what this
would look like. So this you can think of as the first projection of p. And this would be the
second projection of p. And then there's a final class of rules, the computation rules that relate
two and three. And this is going to say in the case of the product type that if I pair terms a and b
and then take the first projection, I recover the term a and vice versa for b. And then there's also
a computation rule that says that if I take a term of the product type, I take its projections
and I pair them back, I recover the original term. So I haven't written that out because the
computational aspects of type theory aren't going to play a big role today, though certainly they're
very important to thinking of type theory as a programming language. The other reason I haven't
written it is it requires the other two types of judgments. I mentioned there are four kinds of
judgments and I only told you about two of them. And I'm just trying to sort of limit the number
of things that we have to pay attention to to follow this talk. So anyway, so I apologize for
deemphasizing the computational aspects, but I think that's the right thing to do.
Okay, so this is sort of the basic bones of type theory. I'd like to pause for a moment in hopes
that somebody will ask me a question. So I guess for the computation rules, is it like valid to
think about it as the intro rules and elimination rules are sort of inverses of each other and
they're like one to one? Right, so there's a reason, right, so that's a great question.
So I mean, in general, the introduction rules are, there's a sense in which, so the introduction
rules are kind of about mapping into a type. Because of the presence of context, what really
what the introduction rules tell you about is the functions that you have from an arbitrary
family of types into the type that's just been formed, while the elimination rules tell you
about the functions mapping out of them. It's better not to think, though, in terms of these being
inverses or establishing a bijection between certain things. I mean, there's a sense in which
these rules give something like the universal property of the Cartesian product that you might
be familiar with, but there's also a sense in which they don't. And I'll get to that a little bit
later. So one of the reasons I'm de-emphasizing the computational aspects here is there are two
sort of notions of equality in type theory. There's one that would be expressed by the
computation rules, which is, can a computer reduce a given term to another term? And then
there's the sort of equality that you prove. And that's the one that's going to be important today.
And this is one of the most confusing aspects, for sure. So I'm trying to avoid the confusion
by just not acknowledging that there is something to be confused about here.
Yeah. So that is a good question. And I realized I didn't give a very satisfying answer.
Thank you. Sure. Other questions?
I had a question. I was curious about the gamma. Is that similar to like a consistent theory of
sentences in terms of some language? I have no idea what that means. So I don't know.
Maybe somebody else does. Oh, okay. Thank you. Sure.
Okay. Right. So let's try and go on a bit more. So let me give another example of a type. So there
are many, many type-forming operations, which allow us to do many different mathematical
constructions. So another one, another really important one is something called function types.
And again, they have formation, introduction, elimination, and computation rules. So the
formation rule says that if I'm given types A and B, there is a type. And this is the standard
notation for that type. But again, it's just notation. It's a type, which is called the function type.
The introduction rule in this case is a little bit complicated. So let's just sort of pretend
that we understand it. But it says if in the context of any term, there is a way to define. So
in the context of any term of type A, there's a way to define a term of type B, then you can
use something called the lambda abstraction. This is, to mathematicians, this would be more
familiar as saying sort of little x maps to B of x. This is just a concise notation for that.
But if there were a way to produce a term of type B from a term of type A, you can sort of package
that into a function A to B. This is what that looks like a little bit more formally. And then
the elimination rule is a little easier in this case. It says that if I'm given a term of the
function type, note this is a very convenient notation for that. And if I'm given a term
of type A, then I can evaluate the function at that term and get a term here. And the
computation rule will say if this F is defined using this lambda abstraction and then applied to this
A, what I should recover here is B of A. So you can imagine, I know these rules might be hard
to think about, but you can imagine teaching a computer about these rules. But now you want
your computer or your undergraduates to know how to prove theorems. And if we were talking about
sort of ordinary kind of classical foundations of mathematics, there's sort of two aspects of
proving theorems. Firstly, there's the underlying propositional logic or predicate logic and first
order logic. And then there's also sort of axioms of something like set theory and sort of combining
the set theory and the logic is how we prove theorems. One of the things that's interesting
about type theory is I've told you the whole story. So we have these judgments that say,
I can say that something is a term or something is a type and I have these rules and that's it.
So you could ask them, well, how do we state improved theorems? Well, it's exactly by sort
of doing the things that we just mentioned. So if I want to prove a proposition, what you do is,
well, first, if I want to state a proposition, what you do is you construct a type whose
sort of form, I guess, encodes the statement you're trying to prove. And then to prove the
proposition, what you do is you construct a term in the type, the type that's encoding its statement.
So this sounds very abstract. So let me just illustrate. So here's our first proposition.
It says that for any types P and Q, sort of more formally, this is saying we have a P and a Q in the
context. There is a term in the type P times P implies Q implies Q. But now let me tell you
how I would read this. So I've called this term modus ponens. What we're proving is one of the
tautologies that are familiar from propositional logic. And what I'm trying to illustrate here
is that we can think of this type, which you can build from P and Q by applying the
formation rule for function type and the formation rule for product type.
We can think of this type as encoding the statement that says P and P implies Q implies Q.
So right now, it just sort of looks like that because this symbol is similar to the and symbol
and the symbol is similar to the implies symbol. But the point is that the rules that I've introduced
here, the rules for the product type and the rules for the function type, mean that it makes sense
to think of this in this sort of logical way. And I guess the proof is sort of by experience once you
the proof that this interpretation sort of makes sense is sort of by experience. And I think
but let's just try and give an illustration. So what I'm going to do is I'm going to construct
a term of this type. What's term I'm going to call modus ponens that you should think about
as being some sort of constructive proof that P and P implies Q implies Q. Okay.
So let's and we're going to do this just by applying these rules. So the task again is to
construct a term of a given type. So to construct a term of a type, we can use the introduction
rule for that. So that's the first step of the proof. So by the introduction rule for function
types, if I were to try and construct a term of this type, what I need to do is explain how to
use a generic term X, like a variable term in this type, and then produce a term of type Q.
That's what this introduction rule says is if I can get a term of a function type by explaining how
to use a term of its domain to produce a term of its codomain. Okay. But by the elimination rule
for the product type, if I have this term little x in a product type, I can take its projections
and get two terms, a term of type P and a term of type P implies Q. And then by the elimination
rule for function types, if I had a term here and a term here, I can evaluate this function
at that term and get a term of type Q. So packaging this all together, if I were writing this in a
computer, I could write this proof in one line, I would say we can define modus ponens to be the
term that's given by the lambda abstraction lambda x dot second projection evaluated at first projection.
Okay. So that's a little wacky. But it really is kind of the way that we understand modus ponens.
So here I'm assuming P and P implies Q is true. From that assumption, I can conclude that P is
true. So this PR 1x is a proof of whatever proposition is encoded by the type P. And this
PR 2x is a proof of whatever proposition is encoded by this type P implies Q.
And now the rules for the function types say that really thinking of this as an implication is
valid. So modus ponens is somehow encoded in these rules. And actually, there are a lot of
tautologies from first order logic that can be proven similarly, that can be proven just by
applying the rules, so on. Okay. So right. So now I want to get back to the question about
mathematical equality. And this is definitely the most subtle aspect of this story. So we have this
idea that I've illustrated here that a proposition, a mathematical proposition can be encoded just by
forming a type that looks like its statement. So if we've got implication, we've got conjunction,
there are a whole lot of other types that correspond to things like disjunction and the
quantifier, as we will see the quantifier is a little bit later. But a lot of mathematical
statements are of the form x equals y. And if we want to talk about those sorts of statements
in type theory, we need a type for that. And that's what these identity types are all about.
So these rules were devised by Martin Lyft in the 1970s. So let me just sort of tell you what
they are. So there's a formation rule that says that if I'm given any type A and any two terms
x and y of type A, then I'm entitled to form a type. And here's the notation x equals y over A.
And this type, again, is asking the question, is x equal to y? So that may or may not be true.
You can ask whether 0 is equal to 1. That's definitely a valid type. But if 0 and 1 are
terms of the type of natural numbers, for instance, there won't be a proof of that,
there won't be a term in this type. Okay, so the formulation rule again says that if I'm given any
two terms of the same type, it is valid to ask, are they equal? I may or may not have a term in
here. So I may or may not have a proof that x is equal to y, but it's certainly a valid question.
There wouldn't be valid if x and y lived in different types. All right, the introduction
rule says that, well, there's one case that we know for sure that this is true, and that's in the
case when it's x and x. So the introduction rule says given a term x, then there is a term
which is called reflx in the type x is equal to x. And that's the only introduction rule for the
mathematical equality type. So that's the only term that we're ever guaranteed to have is a proof
of reflexivity. Sorry, the refl is for reflexivity. This is a proof that x is equal to x. So the
elimination rule for the identity type, I declined to write out because it's a bit complicated when
you're seeing it for the first type. But it can be packaged into a proof technique, which I'm going
to call path induction. And I'll explain the name path and the path induction later on. So
I promise that's coming. So, right, so this is a proof technique. And really, it's an encoding
of the elimination rule, which I'm not spelling out. And let's, I'll state the proof technique,
and then we'll practice using it. Sorry about that. Right, so the proof technique says that if I'm
given any type family, that depends on two terms of type A, and a proof that x equals y, in other
words, a term of this identity type. So b x y p is any other type. So any type that you can form,
given the data of two terms of type A, and a proof that x is equal to y, then if I'm trying to
produce a term of this type, you know, for, again, any x y and p, it suffices to do so only in a
special case. So it suffices to assume that y is x, and p is raffle. Okay, so that's the statement
of the path induction principle. And I know this is confusing if you're seeing this for the first
time. So let's just see an example of the sort of way it can be used. And you can imagine, you know,
well, maybe remember being an undergraduate, when you learn about mathematical induction for the
first time, the technical statement of mathematical induction is very complicated. And it's very
confusing for a while. But after you've done, you know, 10 exercises, writing induction proofs,
you sort of start to get the hang of it. And path induction is similar. So because you're
seeing this for the first time, it's going to be a little confusing now. But you might imagine
that if you wrote 10 proofs using path induction, you'd start to get a hang of it. I'll give two
proofs today, which won't be quite enough, but we'll start us on the path. Okay, so firstly,
the rules for the identity type guaranteed that this identity relation is reflexive. So we have
an introduction rule that produces a reflexive term. But we haven't mentioned symmetry or
transitivity. And the reason that is that those follow. So the elimination rule, this path induction
principle, is going to be powerful enough to prove symmetry, which I'm stating as this. So what does
symmetry mean? It says for any terms x and y and type A, I can form a type, which is in red here,
this is a single type. It's the type. So it's a function type that relates this identity type to
this identity type. And the way you should think about it is this, and this type is asserting the
proposition that x equals y implies y equals x. So the statement of the lemma is really this type.
And the proof of the lemma, I'm going to construct a term now of this type, like we constructed
the modus ponens term just above. What I'm going to do is I'm going to construct a term of this type,
which is then a proof of the implication that's asserted by the type. Okay, so I'm proving symmetry
of equality. How do we do it? So I'm just going to apply all the rules. So by the introduction rule
for function types, if I'm trying to prove, if I'm trying to get a term of a function type,
I'm allowed to assume I have a term of the domain. So I'm going to assume there's a
proof P that x is equal to y. And then my task is to produce a term of this type here.
Okay, so that might look challenging because, you know, our introduction rules don't give us
ways to produce terms of type y equals x. But that's exactly what path induction is good for.
So by path induction, what this induction principle says is that if I'm trying to inhabit the type
family, the notation here was b x y p, but here it's this type y equals x, whose statement depends
on x and y and this proof that x is equal to y, then it suffices to assume that y is x and p is
refl. So it suffices to only inhabit sort of special cases of this type family, the ones where
it's x equals x. And in that case, I can do that because the introduction rule for the identity
type tells us I have these terms, reflux. Okay, so this seems crazy. But this is the
sort of the magic of path induction. You can reduce a lot of statements involving equality to just
cases, trivial cases of reflexivity. Let's see another. Yes, please go ahead.
Our definition of b here didn't actually use p. Is that normal?
So this sort of statement of, I mean, it sort of doesn't include p and it doesn't include p.
So you're right that in the formation of the type y equals ax, p is not required to form
that type. But having a proof that x equals y is definitely required to make this path
induction principle work. So, right, the reason that I'm allowed,
this is going to be easier to, this will be a little bit easier to explain once we have the
homotopy interpretation yet. So, right, so let's imagine real quick that a is the natural numbers.
So the terms of the natural numbers are the zero, one, two, three, four, and none of those
identity types are going to be inhabited. So three is not equal to four, four is not equal to five,
et cetera, et cetera, et cetera. So path induction implies, applies in that case.
And, you know, would sort of allow us to reduce a term or a, I could, so I could apply this proof
to that case, to that particular case. And it says exactly as before that to inhabit the type
family b, x, y, p, which in this case is like saying y is equal to x as terms of the natural
numbers, it suffices to assume blah, blah, blah, blah, blah, blah, blah, blah. But the point is
I'm only going to, you know, I'm only, when I'm trying to prove this implication after all,
you know, the only time I'm going to be trying to prove that y and x are equal as terms of type
naturals is when x is equal to y as terms of type naturals, if that makes sense. So when I don't
actually have a p in here, this will be empty. And so this kind of implication is automatic.
It's the, it's that sort of thing. So, so you're right that the, the formation rule for this type
does not require p, but the path induction principle, it does require p in some way.
So the reason, yeah, the reason that I'm allowed to conclude this from, you know, the reason that
I'm allowed to conclude that y is equal to x from the special case where y is sort of judgmentally
equal to x, where I've substituted x for y is because of the presence of this p. That's maybe
a better way about it. Great. Okay, so here's, here's an even more complicated instantiation
of path induction. So again, if I were teaching this to undergraduates, we're learning this for
the first time, I would, this proof would be five times as long as I would spell out every step. But
here's kind of a high level overview of this. So similarly, we can prove the transitivity of
equality. So for any terms x, y, z of type A, if x is equal to y, and y is equal to z, then x is
equal to z. And here's how it would go. So firstly, the statement is encoded by this type here that
I've formed by applying the formation rules for identity types and for function types. Now by
the introduction rule for function types, which I'm, I guess, applying twice, if I want to get a
term of this type, then I'm allowed to assume that I have a proof that x is equal to y. And then
I'm also allowed to assume that I have a proof that y is equal to z. And now what I'm trying to do
is get a proof that x is equal to z. That's allowed to use these two proofs as input. And there's
several ways to do that. But one way is to do a double path induction. So I'm going to do a path
induction on p and on q. And use that to assume that y and z are both x and p and q are both
reflexivity. But in that case, by the introduction rule again, I have this reflexivity term and
I'm only trying to inhabit the reflexivity case. So that's one way to do this. It's also possible
to prove this with a single path induction. And that might be something that's fun to explore
on your own. Okay, maybe this is a good place for questions too before I get onto the homotopical
interpretation.
What's the proof for path induction?
Right. So I mean, if I had, I mean, essentially path induction is a packaging. That's a great
question. Thanks for it. So essentially, it's a packaging of the elimination rule. So had I
written out the elimination rule formally, so here we wrote out the introduction rule
formally had I written out the elimination rule, and then just read it to you, it's essentially
this this path induction. So that's one way to say it. What's less clear is that it's a valid rule.
So the elimination rule is more or less just exactly this path induction. So
what's what's surprising, I mean, this is this was really a very insightful definition of
permart and lift. What's surprising is that it's a valid rule. And I will say a little bit about
that using the homotopical interpretation. So maybe I'll maybe I'll go there right now.
So really, it is just the elimination rule. It's just sort of how it's given to you in
type theory. And what's crazy is that it's actually reasonable. Okay, so before let me try and
explain that. So the homotopy type theory is sort of a new way of thinking about dependent type
theory, which has had been around for several decades. And it has to do with this new way of
thinking about what we're doing with these types and terms and all of that. This is this homotopical
interpretation of dependent type theory. So this should be some sort of intuition for type theory
that what type theory still means is it's the rules that I've been talking about before it
hasn't changed. We're just changing how we think about how we think about it, what the basic
intuitions are. So the intuition in this homotopical interpretation is that we can think of a type as
being something like a topological space. But that's not quite right. It's really something more
like a homotopy type, which is kind of a flabbier way to think about topological spaces. So here
I've drawn a space that looks like a surface of genus tube. That's an example of a topological space.
A term in the type now we're thinking of as being like a point in that topological space.
And now we're explaining this path and path induction. If we had a term in an identity type,
so to form this identity type X and Y must be terms of type A. So those are interpreted as
points in the space A. Now we're going to think of a term and an identity type as a path from X
to Y in A. So here I've drawn a picture of a path P from the point X to the point Y in the space A.
And here's some things that are good about that interpretation. I mean firstly I can apply these
formation rules iteratively. So once I have two terms X and Y in type A, I can form the identity
type and then I can think about terms in the identity type that are paths from X to Y. But if
I have two paths from X to Y, this P and this Q, those are then both terms in the same identity
type. So I can form an identity type that is asking the question, is P equal to Q as paths from X to
Y in A? This is an iterated identity type. And I can imagine having a term in that. And so what
should that be? Well a term in a path type should be a path between paths. And there's a name for
that in sort of algebraic topology. It's called a homotopy. A homotopy is a path between paths.
I've drawn a picture here. I really should have given it a direction. This you can imagine as
being a path of paths from P to Q, where P and Q are both paths from X to Y in A. That's sort of a
picture of a homotopy. And one of the interesting things about this interpretation is, so in the
picture I've drawn here, some paths are homotopic. So P and Q are two paths from X to Y. And there is
a homotopy between them. You could prove that P is equal to Q as proofs that X are equal to Y as
terms of type A. But other paths are not homotopic. So I could consider the composite of Q with R.
We're composition, by the way, is the new way to think about this transitivity proof. I can compose
a path from X to Y and a path from Y to Z to get a path from X to Z. So I can imagine applying
that to this Q and this R and get a composite path from X to Z. But here I've drawn another
path from X to Z, which I didn't give a name. And because of the presence of this whole, those paths
will not be homotopic. So you can imagine from this homotopy interpretation that you might have two
terms in this iterated identity type, or sorry, two terms in an identity type. So two paths from
X to Z in the picture here that are not equal so that the iterated identity type will not be
inhabited. And this was an open research question and type theory for a long time. There was this
conjecture called indiscernible of identicals that said if I have two proofs P and Q that X
are equal to Y, then I should always be able to prove P is equal to Q. People thought you might
be able to use the rules of type theory in a very clever way to prove this, and they weren't able
to do so. And the reason they weren't is they're now these counter models. It was shown by Hoffman
and Stryker, firstly, with a groupoid model and then later with this homotopy model that you
shouldn't expect to be able to prove necessarily that two terms of an identity type are equal.
So that's one cool thing about this homotopy interpretation.
So from this point of view, the two properties of the identity types that we've just discussed,
this symmetry and this transitivity now become reversal and composition of paths. So if we think
of P, a proof that X equals Y as a path from X to Y, then a proof that Y equals X as a path from Y
to X. And what this symmetry proof above was explaining is how to reverse a path,
sort of proving that every path can be reversed. And similarly, transitivity, as we just discussed,
is a composition rule for paths. And of course, all of these apply for any, you know, there were
these, this context here, this reversal property applies for any X and Y in A. So A could itself
be an identity type and P and Q could then be proofs of equality and then these could be iterated
identity types. So in other words, I get the same reversal and composition rules for homotopies. These
are the paths between paths. And they're also higher homotopies. So if I had an H and a K,
two homotopies from P to Q as paths from X to Y and A, I could form the identity type that is asking
whether H and K are equal as homotopies. And a higher homotopy would be a term in that type.
And this just sort of goes all the way up. And there's a way to sort of make all this
precise. This is a theorem of Peter Lumsdain or Ben O'Vandenberg and Richard Garner,
which say that types inherit the structure of something called an infinity groupoid.
And the way you should think about an infinity groupoid is it's sort of something like this.
It's got points and it's got paths and it's got paths between paths and paths between paths and
paths and so on and so on and forth. And you're always allowed to, you can compose at each level
and invert things at each level. And then there's some sort of associativity principle and there's
some sort of identity principle, though those relationships are generally hold up to higher
paths rather than up to kind of strict equality. So the only, whenever we talk about equality
going on, we're going to be using this sort of equality that's given by this identity type.
So to prove, I guess what I'm trying to say there is that to prove that P
composed with the reversal of P is the reflexivity proof. What you would do is you would construct
a term of an identity type. So you're constructing a homotopy then between the composite of P with
the reversal of P and the identity. So is the model for infinity group oids that they used
equivalent to kind of complexes or is it some other model? Right. So I mean there's a sense
in which all models for infinity group oids are equivalent. They did not use the con complex
model. They used something that's sort of more globular because that's, that's more,
that's closer to the sort of shapes that are involved in this presentation.
But if you, if you Google, you'll be able to find the paper reference.
Okay. So if we have two paths that are not a homotopic, would that
kind of interpret interpretable as we have having two proofs that are fundamentally different in a
way? Yes, absolutely. That's right. Okay. That's right. Great. So in the homotopy, so this is one
aspect of this homotopy interpretation. So I mean one of, in my view, the very compelling
aspects of this homotopy interpretation is it gives us a really natural way to think about
these rules for the identity type that predated the homotopy interpretation by like four decades.
But it continues to sort of all of type theory. So there are other formation rules in, there are
other aspects of dependent type theory that we haven't really emphasized that I want to introduce
now. So firstly, we talked about this notion of a type family. So we can have a family of types
that varies depending on a term in a given type. And the interpretation of that in the homotopy
theory is something called a vibration. So what a vibration is, is it's two different spaces.
There's something called the base space. And that's the type here. So here in the picture,
I've drawn the base space as a circle. And then what a vibration means is it's, then there's a
total space. So there's another space here. I've drawn a cylinder. But I should think of this
as being a family of spaces over the circle. So for each point in the circle, the fiber of the
vibration, there's some space above it. In that case, that's this interval. And yeah, I mean,
that's kind of the big idea of a vibration. So there are two formation rules for these type
families that I want to briefly mention now. There's one called a dependent sum
that takes a type family and forms a new type that's denoted this way that's interpreted as
the total space of the vibration. And what its introduction rule says is that
to give a term in here, it suffices to firstly give a term of type A. So like this little A
downstairs. And then also give a term in the fiber. So give a term in the type B of A. So that
would be like giving a point along this thing. So the terms in this total space are pairs comprised
of a term in the base type, and then a term in the fiber over that base. And then the other
formation rule is something called the dependent function type, which this is the notation for
that. And this is a less familiar concept. It's the space of sections. So a term in the dependent
function type, that's this little f. What it will be is it will give, I guess by its elimination
rule, what it will give is a function that takes a term, maybe little a and a, and then produces
a term in B of A. So here, so there's a name for that, it's a section, it's a continuous section.
So a function that maps from this circle back into this total space in such a way that each
point lies in the fiber over the point on the circle is like this thing that I've illustrated here,
this sort of wavy circle that's mapping through the cylinder. Okay, so we have these things called
dependent sum types and dependent function types. We will see them later on. I should note that these
are generalizations of the types that we've seen already. So it's possible that we have a constant
type family that I guess came up above. So maybe B is just a type that doesn't actually depend on
this x at all. And in the case of a constant type family, this is exactly the product type,
or this reduces to the product type. And this reduces to the function type. So I should think
of this as some sort of generalization of the product type construction and some sort of generalization
of the function type construction, where the type of the second bit might vary depending on what the
first term was. Okay, so one of the useful things about this homotopical interpretation is that it
then inspires new definitions. So all of the definitions that I'm about to give, these make
sense in the in the dependent type theory per Martin Liff's dependent type theory that we'd
already introduced. So I'm not, you know, as yet changing any of the rules of type theory, but I'm
using these homotopical ideas to give new definitions in the type theory.
So in homotopy theory, what it means to say that something exists uniquely or to say that
there exists a unique term of type a means that the space a should be contractable contractable
means it's equivalent as a space to just the point the one point space. And so here's a type
which is encoding the statement that a is a contractable type. So to show something as contractable
or to show that something exists uniquely, what you would need to do is the way you prove a unique
existence usually is firstly, you prove that a is true, you prove that there exists something in type
a. So that's this part here. If so if I were to produce a term of this type, what I would have to
do is firstly construct a term in type a and then show that for every so this dependent sum you
should think of as being something like existence though really it's more of a constructive existence.
And then what I would need to do show is that for every x and a this product you can think of as
being like the universal quantifier for all, then I can prove that a is equal to x. So you can sort
of naively read this as a statement of the usual strategy for proving something exists uniquely.
Firstly you show that there exists a term little a and a and then you prove that if you had another
term x and a that a and x are in fact equal. But under the homotopical interpretation this becomes
well this is the statement that the type a is contractable. And this is one of the things that
we're going to use later on where I'm going to say something exists uniquely. And what I really
mean by that is that a type formed in this way is a contractable type. Okay. Sorry may I ask? Yes.
I'm seeing this and I'm thinking about this looks more like a is connected not not contractable.
Yes, absolutely. So that's a that's a great observation. You're totally right. When this
so this definition is due to Boyvotsky and when Boyvotsky first started telling people about it
everyone was surprised because it absolutely looks a lot more like path connectedness. So
I should say that sort of from the homotopical point of view a way to understand what this
type theory is is it's you're sort of synthetically doing homotopy theory and in this sort of synthetic
language sort of governed by the rules of type theory everything is automatically continuous. So
while it looks like I'm just while it looks like here to construct a term of this part I would just
be constructing a path from little a path from each term X back to a really I'm constructing a
continuous family of paths that sort of continuous in this space a down here and that's what makes
it really a contracting homotopy rather than just the path. So everything's kind of more
continuous than you think and sort of automatically as somehow enforced by this homotopy interpretation.
A bit of a surprise. That was a great question.
Great. And then the last thing I want to say about this homotopy interpretation
is it also there's a natural definition of when two spaces are equivalent or homotopy equivalent.
And so the now that we're thinking about types as spaces we can import that definition into
homotopy type theory. And the definition is going to again this is going to look a little
differently than the definition you'd expect and I want to try and explain why that is.
So firstly I'm going to define what I'm doing here is I'm defining a type that is asserting
that the types A and B are equivalent. So if I had a term on that type that term should be a proof
that A and B are equivalent as types where equivalent is in the sense of homotopy equivalence.
Okay so let's try and read this type. You know this is the sort of thing that will get easier
with practice. So a term in this type would provide the data I guess by the elimination rules.
A term in this type would provide the data of well so firstly let me just read it out in words.
So this the type A is equivalent to B says that there exists a term F a function F from A to B
and then there also exists a function G from B to A so that for all little a and a there is a
path from G of F of A back to A or really this is going to be a homotopy because this is a continuous
family of paths as before. And similarly there exists a function H from B to A so that for all
terms little b and b there is a path from F of H of B back to B. Again this is a homotopy.
Okay so by the elimination rule if I had a term in this type of equivalences what it would give me
is firstly a term F in the function type so a function from A to B and then two terms of the
function type from B to A the G here and the H here I'd have two terms like that together with
homotopies that's sort of an natural way to think about a term in these sort of dependent function
types so this is a sort of continuous family of paths from G of F of A back to A and a continuous
family of paths from F of H of B back to B. So if I have this data so if I had my F and my G
and my H and my alpha and my beta then you can compose these homotopies and get a homotopy
between G and H so you can prove that G and H are really the same function or at least homotopic
functions a posteriori from the data here so that might suggest that this was kind of a more
complicated definition that needed to be you know it seems strange that I have two dependent sums
in here rather than just a single one and have it like that but there's a reason to define equivalence
to be in this way rather than that way and this is because you know we had this idea that I
stated above that we're thinking about a mathematical proposition as being encoded by a type so we
have a type that encodes a mathematical statement but there's something a little bit subtle there
the way in classical logic we think about a proposition as a proposition is something that's
either true or false and that's sort of the end of the story but now with this homotopical
interpretation a type is really a space and as we were discussing we can have proofs of points in
that space that are not connected by a path or we can have proofs that are not equal and so there's
some sort of higher complexity level sort of sitting on top of the propositions and it's
sort of in attention to this higher homotopy or higher proof theory aspects that we've
preferred this definition of equivalence to the one that you might have guessed first so I can say
that sort of more precisely as follows so if I define an equivalence to be a function f from a
to b that is equipped with a priori distinct left and right inverses so that's this g and h that might
be different then it follows that if I had any two terms in this type so if I had any two proofs
that there exists a g and a homotopy and exists an h and a homotopy then I can always prove that
those proofs are equal so in other words this type here is it's called a mere proposition this type is
either inhabited or contractible so the data that would equip a given function with an equivalence
in this sense is unique in the sense of homotopy type theory if it exists whereas if I had expressed
the property of f being an equivalence in this more naive way just saying there exists a single
function g from b to a together with a pair of homotopies this type might have distinct terms
so this this type might have some sort of higher homotopical structure whereas this type is really
just encoding the proposition as we usually understand it something that's either true or
false that f is an equivalence okay so that's I know that's not sufficient as an introduction
to homotopy type theory but that's all that's all you're going to get today but I'll stop here
and ask the questions questions please yeah um I thought I heard you say that it's this can can
you hear me all right oh I thought I thought I heard you say that um that it's a mere proposition
meaning it's either inhabited or contractible that's but uh did you mean uh either uninhabited or
contractible uh yes sorry that's correct okay yeah I'm not sure if I misheard I just wanted
to clarify thank you so much yeah thanks um right inhabited means there is a yeah uninhabited would
mean right thanks yeah I have a question sure why is it desirable that having these inverses
be a mere proposition right uh so one way to one advantage there is I can understand if I
define the type of equivalences uh um in this way um it's uh it's kind of a subtype of the type
of function so this is uh right I guess this is giving it a tighter relationship to the type of
function so um that's maybe one way to say it uh I guess um so if I were you could also imagine
building a more complicated type where one of the hypotheses so one of the pieces of that type
is that your given math is an equivalence and uh you want this more complicated type to be as simple
as possible so you want to have the hypothesis that f is an equivalence uh to be one of these
propositions to be sort of simple as possible so that a term in that is a contractible type and you
can kind of contract it away and so on so um right I mean this is the sort of thing that matters if
I'm you know if I'm building a very very complicated type and one of the hypotheses is that f is an
equivalence I want to say that in as an efficient way as possible so you definitely want to phrase it
using one of these mere propositions rather than something more complicated otherwise it's just
giving you all this data that you're carrying around um maybe another thing to say is there's a
philosophy that uh uh sort of doing mathematics and type theory is like doing proof relevant
mathematics because um you know all of these terms are proofs and which term you have might matter
um that's just the sort of thing that you start to realize that you should attend to
right so that I mean I guess there's a reason I mean there's a reason that I prefer this particular
proof of transitivity as opposed to a different proof that uh required only a single path induction
rather than a double path induction it's um it's kind of an aesthetic that uh that uh the community
shares so should it be obvious why the second one might not be um contractible no uh it's
no um and it's I mean right it's not it's not at all obvious but it's the sort of thing that uh
um a homotopy theorist might have experience with um you know and it might also be contractible too
depending on what a and b are so um to have uh priori distinct terms you know a and b need to have
some kind of non-trivial higher homotopy yeah but I think uh I guess kind of all I wanted to say is
one of one of the things that I found cool about homotopy type theory one of the things I found
compelling is you know there are a lot of logically equivalent statements I mean if there is a term
of this type there is a term of this type and if there is a term of this type there is a term of
this type so that's the sense in which these are logically equivalent that are not sort of
homotopy equivalent so um you know how this works is in you know sort of mathematics you learn a
lot of equivalent definitions of the same concept and what homotopy type theory is saying is that
some of them are sort of genuinely equivalent in the sense of defining equivalent spaces
but others aren't sort of equivalent in that strongest sense they're more merely logically
equivalent and I think that's an interesting thing to know um can I ask you to give an example of this
either in that two equivalent definitions are not really equivalent or in that two proofs are really
different right so the two equivalent definitions that are not really equivalent are the two here
so that this type in red and uh well uh this type and this type are logically equivalent but not
really equivalent so that's that's the only example I'll give you right now so I I recently learned
an example of two proofs that are not equivalent so here's a tautology from classical logic
if I have uh so p and q implies p or q is is a true statement and you can imagine two different
ways of proving that uh you can prove that p and q implies p which then implies p or q
or you can prove that p and q implies q which implies p or q so uh if I want to do something
like this in homotopy type theory I have to say what I mean by or and there are some there are
different choices you could make um if you interpret or as something called a co-product type or
something like a disjoint union then those two terms that I've just described are provably not equal
you know arbitrary p and q so that's that's a sort of example interesting thank you sure
okay so in the last uh 25 minutes or so let me try and give you some sort of introduction to
infinity category theory so again uh you know this won't be sufficient this is only uh you know
ideally this would be a semester long course in infinity category theory so really I'm going
to give you an impression that might convince you that it would be possible to teach a semester
long course in infinity category theory to undergraduates assuming this homotopy type
theory stuff was like down cold you know understood really well okay so this is based on uh joint
work with Mike Shulman uh there's a paper that is included in the references at the end that I'll get to
and um so we're using homotopy type theory as our background foundations but we're the type
theory that we're working in has a little bit of an extension of homotopy type theory um for those
of you who are familiar with cubicle type theory this is a similar sort of an extension to that in
that um the contexts are going to be something a little bit more elaborate um for those of you
aren't familiar with cubicle type theory I should just say that um type theorists are generally pretty
flexible in what they mean by a type theory and there's an idea that you should be able to
sort of redesign your type theory to um be particularly efficient for whatever setting
you're working in and that's the move that we're making here um so so this is homotopy type theory
like before but I my context sort of the kind of background uh variables that I'm allowed to use
are going to be a little bit more complicated in that I want to have these uh polytopes as part
of the context and you can say what a polytope means uh syntactically in a formal language
I'm not going to emphasize that so much I'd rather you just sort of grant me that polytopes exist
but um the way you do it is uh you can aximatize a directed interval which uh has two constants
and this inequality relation that's you should think of it as a directed interval in the direction
from zero to one and then you could imagine cutting out shapes inside that directed interval
so if I had um there's our products of that directed interval with itself so if I had a
box an n-dimensional box inside that dimensional box I could take the sort of the coordinates
that satisfy this relation and that'll give you an n-symplex so I've drawn the picture here of the
the two-symplex a triangle sat inside a two-dimensional box
and I could impose additional conditions uh that say that your uh your points here s and t
aren't just in this two-symplex but are on the boundary of the two-symplex because one of these
equations holds or I could say that maybe I'm along these two specified edges of the boundary
of the symplex so they're these geometric shapes that you can describe in a syntactic language that
is built from this directed interval together with some sort of intuitionistic logic but let's
let's just pretend that these polytopes make sense and I'll use only some very simple shapes below
and then I'm going to need one additional type forming operation so this is another one of these
like formation rules and this is something called an extension type and uh here's sort of how these
extension types work it says that if I were given two polytopes uh psi and phi and one of them
should be a sub polytope of the other so you could think of like the boundary of the n-symplex
in the n-symplex or this horn thing sorry the boundary of the two-symplex inside the two-symplex
or maybe this horn thing inside the two-symplex so I've given two of these polytopes and one of
them is a sub polytope of the other and I had a term and a function type so I had a function
from the smaller polytope into some type A then I'm allowed to form an extension type whose terms
will then be functions from the larger polytope into A that restrict along the inclusion to the
given term before so this picture is meant to be kind of a cartoon of this extension type to help
us remember what it is because I realize this formulation is a little bit complicated so the
inputs to form the extension type are a specified function like this and a specified polytope
inclusion and then the terms of the extension type are functions here that restrict to the specified one
okay so um here's why we need all of that so uh I'm about I'm trying to develop the theory of
infinity categories and a highlight is I'm going to define an infinity category for you
and uh so this is going to refer to well I guess the first definition we need is
is something that I'm given here so using this extension type construction I can define
for two terms of type A a type which I'm going to denote like this ham A x y and what it's give
how it's given is as one of these extension types so this is going to be the type of arrows
a term in this I'll think of as an arrow in A from x to y and what is it well um so one of
these polytopes is this shape delta one which ends up just being the same as this directed interval
a sub polytope is its boundary which are two points and so if I'm given a function from two
points into A that's just the data of two terms of type A an extension of that to a directed
interval that's exactly kind of the geometric intuition for an arrow so we're defining an
arrow to be a map from a directed interval into A whose source is x and whose target is y
all right so now now that I have this type that whose terms are arrows from x to y and A
I can give a definition of what it means for a type to be an infinity groupoid that sort of
connects back to this homotopy interpretation and here's what it is so a type is an infinity
groupoid if a particular function that I'll tell you about momentarily from the identity type
to the type of arrows is an equivalence so what is this particular function so it's I'm calling
it path to error it's some function that converts a proof that x equals y or a path from x to y
into an arrow from x to y and I can define a function like this by appealing to the path
induction principle so if I'm trying to define a term in this function type by the introduction
rule for a function types I can assume I have a path p from x to y and then I need to define
an arrow from x to y but by the path induction principle to inhabit this type of arrows it
suffices to assume that y is the same as x and p is reflexivity so I really only need to define
this mapping in that particular case and there I can say that I want to define this function
to be the function that sends the reflexivity term to the identity arrow which I haven't
defined for you yet but it's coming I promise so there's a particular function
a path to error and if that function gives an equivalence between this type of paths and
this type of arrows that's what I'm going to say is an infinity groupoid and that sort of
makes sense we have the sense already that any type can be thought of as an infinity groupoid
or its infinity groupoid structure comes from its identity types so here in this sort of category
world if it's ham types if it's types of arrows are really just these identity types that we had
before then it does make sense to think of that type as being an infinity groupoid.
Sorry so here it seems like you're defining infinity groupoids as a property of types not
structure is that correct? Yes yeah that's right so and that's going to be true for
infinity categories a bit as well and that's a little weird I should say to justify all of this
we need so this is kind of confidential to the graduate students or the experts there there's
a model of everything that I'm going to say which is familiar to people who work with infinity
categories this is the complete seagull space model of infinity one categories and complete
seagull spaces are certain types of seagull spaces which are certain types of reedy fibrant
bismplitial sets and this is mirroring the observation that you just made so the types
will be the reedy fibrant bismplitial sets in this particular model a certain property of them will
make them seagull spaces which I'll call pre-infinity categories in just a second and then a certain
further property will make them infinity categories and it's a bit strange but that's how the model
works so we want the theorems that we prove in this type theory to interpret in a place that
mathematicians care about today and that's that's kind of why we've set it up in this particular
way and is it something we should expect that it should be a structure not a proper you know the
structure or is it no you can think about that as a choice that Mike and I made and you can imagine
other people preparing to make a different choice okay thanks okay so the aim is to tell you about
infinity categories and what's kind of remarkable about this story is that I can define infinity
categories at all so there's a you know last spring at the Mathematical Sciences Research
Institute there was this semester long program on derived algebraic geometry that's a community
of researchers that might want to work with infinity categories so they aren't experts in
infinity categories so there was an introductory lecture a three-hour lecture series beautiful
lecture series by Carlos Simpson illustrating sort of what infinity categories are why you
would want to use them where this higher dimensional structure comes from lower dimensional things
and it ended the three hours ended with a definition of infinity categories so that's
kind of how hard it is to say what infinity categories are today and here I can give a much
shorter definition because these new foundations are really more amenable to saying what it is
but let me let me try to get there so so now I'm going to tell you I mean it right from some point
of view it's not impressive that I'm really excited that I can just define the thing that
this talk is meant to be about but from another experience that is actually somewhat surprising
so yeah so you are seeing here that or you said before actually that a type can be thought of a
space but here you are singling out a type of or a well a type of type that's our infinity group
point but the amazapy hypothesis tells us that spaces are infinity group points and so so we
think as a type as a temporal set so that's not all our infinity group points or
right so that I mean what's a little subtle here is there's lots of different possible
interpretations of so there are lots of different models of homotopy type theory there are lots
of different interpretations and it's hard to it's hard to answer your question without getting a
little too deeply into the semantics so what this I guess this notion of infinity groupoid
we'll see later is that this coincides with the infinity categories in which all arrows are
invertible so it's a little it's a little bit right it's a little bit more structured than
the background infinity groupoid this is kind of a subtle question so maybe I won't sort of say
anything more about that but okay but no I mean in the models the types are really more like
con complexes rather than arbitrary simple sets so okay so let's let's try and say what a pre-infinity
category is so there's so this is going to be most of the way to a definition of an infinity
category there'll be one additional piece that comes along for those of you who are familiar
with semantics this is these are the seagull spaces but not yet the complete seagull spaces
and that's what this pre is referring to so we're going to say that a type is a pre-infinity
category if every composable pair of arrows has a unique composite and the kind of the key point
here and this is why we're really we're really starting to make use of these new foundations
uniqueness is now in the sense that we discussed above uniqueness means some type is contractible
so that's so the definition and a type is a pre-infinity category if every composable pair
of arrows has a unique composite what this means is if the type that says uh you know yeah the the
type that says uh here's the data of a composite of a composable pair of arrows is contractible
so an elaboration of this says that if f and g are arrows f from x to y g from y to z the fact
that this y is that y is what composable means then i'm entitled to form this extension type
here's a cartoon for you so this is one of these uh polytopes this is the polytope that
corresponds to a particular directed boundary of the two simplex uh that's a sub polytope of the
two simplex and i'm what i'm saying is the type of two simplices that extend this horn that extend
this composable pair is a contractible type that's the technical meaning of this informal sentence
every composable pair of arrows has a unique composite so the type of two simplices in a
that extend the data of this given composable pair is contractible okay so what are we going to do
with that so firstly um if a type is contractible what we know is that it's inhabited so i definitely
have a term of this type so under the hypothesis that a is a pre-infinity category if i have a
pair of arrows f and g i get a term of this type and i'm introducing some notation here for the
term of this type so really a term of this type is a function from this two simplex into a so it's
like this entire triangle here where part of the boundary is given by f and part of the boundary
is given by g i didn't tell you what the elimination rules are for these extension types but had i
done you would see that i could extract out from this function a thing like this and i can restrict
to just this edge so from a term of this function type i get an arrow from x to z so this would
be a term in ham a x z and that's this uh what i'm denoting by g circ f so um from the hypothesis
that i have a unique composite in other words a contractible type here i get various terms one
of the terms is this two simplex which i've drawn here and another term is a particular arrow from
x to z that i've called g composed f now this data is not unique again in the sense of classical
mathematics so it's not the case that in an infinity category as if i were trying to describe what an
infinity category were to you using classical foundations it's not at all the case that any
composable pair of arrows has a unique composite that's not true but what is true is that any
composable pair of arrows uh there's a contractable space of choices of data of a composite and that's
exactly what i get what uniqueness means in this homotopy type theory context so this type may well
have other terms in fact it quite likely does have other terms but what contractability means
what contractability means is that if i were given some other term of this type then i could prove
that that term was equal to the one that i've specified previously and in type theory you're
allowed to sort of substitute along equal things this is kind of related to this path induction
principle uh so i can pretend i just i guess the upshot the informal upshot is i can pretend that
i just have one term of this type i can pretend that i have a well-defined composition operation
that uh goes from my f and my g to my composite arrow g composed f even though uh you know that's
not true in the sense that we ordinarily understand it it is really true in these new
foundations and this is part of why these new foundations are sort of so powerful from this
perspective okay so let's let's try and get used to this idea by proving some lemmas so i've given
a definition of a pre-infinity category that's really pretty sparse it says that every composable
pair of arrows has a unique composite so uh so for any f and any g uh i have some contractable type
which gives me these terms i haven't referred to identity arrows though i guess implicitly it's
there and i haven't referred to associativity of composition and um what's nice is those things
are actually going to follow formally so what i'm going to prove for you now is that every term in
type a has an identity arrow um that then acts as an identity for composition so the first thing
i'm going to do is i'm going to construct this identity arrow and then i'll prove that for any
arrow from x to y or you could imagine an arrow from w to x that f composed with the identity
where composition is defined up here by this pre-infinity category axiom i'm going to construct
or prove that f composed identity of x is equal to f so this is proving the identity axiom in a
pre-infinity category okay so the first task again is firstly just just define this identity
arrow at all i'm going to use the introduction rule for these extension types that i didn't
tell you about but it's similar to the introduction rule for the function type so uh so to produce
so an identity arrow again should be a term in this uh hom type which was defined as one of
these extension types so in other words i need to define a function from my polytope my directed
arrow polytope into a and that function needs to start at x and end at x uh there's a particularly
simple function that starts at x and ends at x it's just this constant function so in the lambda
abstraction it would look like this but you can you know the constant function does satisfy the rule
of being a term in this extension type and that's how i define the identity arrow so geometrically
i'm thinking of the identity arrow as just the constant function at x okay so that gives me the
identity arrow and makes rigorous the definition of infinity group boy that i had above now uh
i need to prove further this composition relation so i'm going to assume that i have a
arrow f from x to y what i want to prove now is that f composed identity at x is equal to f
so the way i'm going to do that so firstly this is the extension type that uh you know
governs the composition relation f composed identity and i'm going to construct a particular
well and by the sorry by the uh sort of contractability assumption that any composable pair of arrows has
a unique composite there is a unique term in this extension type and it's the one that defines the
arrow f composed identity at x but i can construct another term of this type uh again using the
introduction rule for extension types so i'm going to define for you another map from the
the polytope that's this two simplex into a and i'm going to use it define it again by this lambda
abstraction so remember this is sort of a subshape of uh the sort of directed square two times two
so coordinates for that s and t and i'm going to project on to just one of the coordinates
and apply the function f so this is some formula that refers to the syntax that governs these shapes
and it's you can check that it does in fact define a term of this extension type that sort of looks
like this it'll have the identity arrow along one boundary the arrow f along the other boundary
and crucially it has the arrow f along this boundary here so what i have now is i have two
different terms of a contractable type i have the one that i hypothesized to exist by saying that i had
a pre-infinity category and that defined what i meant by this notation f composed identity x
but i have another term that i've just constructed which is given here and the boundary arrow in
this case is this f but because this type is contractable these terms must be equal i must
have a proof of equality that says that f composed identity of x is equal to f and that's the end of
the story so here i've constructed a witness that f could well be regarded as the composite of the
identity with f and that means that f is the composite because by uniqueness there is only one
composite okay so again this all takes a little bit of getting used to but um but once you do it's
kind of cool uh and then there's a proof of associativity along the same lines so i didn't
need to ask that composition is associative because you can actually prove it so what the
statement says is if i have three composable arrows now i could use this sort of unique
composition thing to define what i mean by g composed f and then h composed g composed f or i
could first compose h and g and then compose with f and these will be two different arrows from x to
w and a and i can prove that those two arrows are equal so the proof of this is a little bit
geometrically more sophisticated and it relies on a lemma that you'd also have to prove that says
that if a is a pre-infinity category then so a is a type that's a pre-infinity category then
so is the type of functions from the arrow into a and so what's cool about that is now that i know
that this is a pre-infinity category i can say that any pair of composable pair of arrows in
here has a unique composite and what this picture is illustrating is a composable pair of arrows
in here so these would be arrows in the pre-infinity category of arrows in a so an arrow of arrows is
really a commutative square so that's what's drawn here here i'm taking f and g and their composites
g and f and this is a commutative square of arrows of arrows and then i have another commutative
square involving g and h which is using the composite h composed g and when i compose them
i'm now going to get a two simplex of arrows or in other words this sort of prismy shape
and if i look at the this three simplex that sits inside this two simplex and i look at the faces
of these three simplexes what you'll see along the back is there's a two simplex face that has f
as one of its boundary edges h composed g is its other boundary edge and that means that the diagonal
is necessarily h composed g composed f but then that diagonal edge was the same as the diagonal
edge for another two simplex face which is g composed f and h so that that two simplex witnesses
that this boundary edge can be regarded as the composite h composed g composed f while simultaneously
it can be regarded as the composite h composed g composed f and that's the sense or that's the sort
of strategy for proving that these two composites are equal okay let me end with a definition and
a statement of a theorem and then i'll take further questions so i haven't yet defined
infinity category for you but we're really very close so there's one additional axiom in an
infinity category and what it refers to is a notion of isomorphism in a pre-infinity category
and the definition of an isomorphism is very similar to the definition of an equivalence
that we stated previously so an arrow from x to y is an isomorphism if it has left and right
composition inverses so in other words the type of isomorphism from x to a is defined to be the
type whose terms are firstly an arrow from x to a together with two arrows from y back to x
so that the composite each way around is equal to the identity and as before
if you had a term of this type you could then prove that g and h are equal
but the reason for preferring to type to find the type of isomorphisms this way is
because this part of the type is now one of these near propositions so if f is an isomorphism it's
an isomorphism in a unique way when given this particular data okay so we're going to say that a
type a is an infinity category if firstly every composable pair of arrows has a unique
composite so this was the pre-infinity category axiom that we had previously
and then secondly there's something that goes by the name completeness condition which says that
isomorphisms are equivalent to identities and so what that meant is this is very similar to this
infinity groupoid axiom for all x y and a we have this function path to iso kind of like we had this
function path to air which by the path induction principle is defined by just saying that I'm
going to send reflexivity to the identity so you need to prove that the identity arrow is an example
of an isomorphism but that's not so hard to show and to say that something is an infinity category
I say that isomorphisms are equivalent to identities in the sense that this arrow is an equivalence
and I'll end by just displaying the statement of this theorem that relates the notion of
infinity groupoid that we had previously it turns out that a type is an infinity groupoid
sort of if and only if a type is an infinity category in the sense of the definition given here
and all of its arrows are isomorphisms and maybe I'll let you read the proof on your own
thanks very much that's a good place to stop and invite further questions
so
I guess maybe I'll take questions first that people don't mind having recorded
but I will turn off the recording at some point and we'll have questions
else I forgot to say that slides have been available this whole time so if you want to
have a look there on the web
I'll maybe I'll display the references page as well
I have another question that's related to related to the fact that being an infinity
groupoid is a property not a structure it seems like there are two sort of two
simplicial directions like homotopical directions and that by this fact you're actually emerging
them in a way is that something like that you can comment on or yes that's right so in so in the
there's an intended model for the type three that I just discussed which is this complete
seagull space model as bi-simplicial sets and in that particular model everything that you said
is exactly true there is so bi-simplicial set means there's two different simplicial directions
one you think of as the categorical direction and the other one you think of as sort of the
space direction what this completeness axiom is so the second axiom that says that isomorphisms
are equivalent to paths it says that the sort of paths in the spatial direction coincide with the
isomorphisms in the categorical direction so that's that's sort of what's tying together those two
different dimensions and then the the group right condition is saying that in addition all of the
arrows in the categorical direction are in fact visible in the spatial direction as paths
okay thanks sure
can I ask you a question about the definition of directed cubes
you say that they are product of the directed interval two and all we know about this interval
is that it has element zero and one and an order relation that's correct yeah what are the rules
for this interval in type theory because it's not just the Booleans
right that's right so assuming that there are other elements between zero and one
right so yeah so I mean the really the thing I should say is you should look at the paper
where we sort of spell this out in full but
right all that's so the the interval is axiomatized sort of in exactly that way so we have this
I guess it's sort of the directed interval axioms so we have axioms that says that for all
terms in the directed interval whatever they are zero is less than or equal to the term
and the term is less than or equal to one things like that
I guess I don't I don't know quite what to say so the these polytopes sort of I mean they're a
little bit weird in the theory in the model they do end up being types but we shouldn't really think
of them as being types in the type theory so these are sort of defining shapes that it's kind of
valid to map out of and uh that's um yeah it's it's a little bit confusing so um yeah
what's this approach oh sorry uh no it's not really about the the presentation but
it's more about the introduction you say that in the future we we will learn to
end the undergraduate students infinity category and why do you think that
yes so what what are our arguments for you that infinity category could be
uh um teach teach to uh to students
to undergraduate students so sorry for my bad english
sure okay so it's the question why would anybody care about infinity categories why
should we teach infinity categories no no why could we uh teach uh teach it because it seems
very uh an abstract theory right instead of abstract algebra which is more simple
sure I think right yeah okay sure fair enough so I should say um this talk was really meant to
be very speculative in a number of different ways so um so you know absolutely it's it's
certainly possible that in a hundred years we won't be teaching infinity category theory
to undergraduates I mean a counter argument for any of this would be the fact that we don't
teach category theory to undergraduates today typically um even though I mean obviously my
point of view is biased but I would argue that uh category theory is you know kind of an increasingly
important part of mathematics and yet we don't teach it to undergraduates so uh similarly it's
it's certainly plausible that we won't be teaching this material to undergraduates ever um but I
thought it would be fun to imagine if we were to teach infinity category theory to undergraduates
how might that come to pass and that's sort of what this is about okay okay thanks so
is it reasonable to expect that such um such a way to define infinity categories could could be
used for um infinity categories which aren't infinity one categories or is it uh unreasonable
to expect something of the sort right I think that would be awesome um because there's even less
so I should say uh the thing that isn't speculative about this is um you know there is a so uh this
paper which is what the second part of the talk was based on um it sort of explains in more detail
the the type theory with these polytopes and these directed cubes which I didn't present very well
partially because I'm not a type theorist um and also how to interpret this in a model of
infinity categories are in a um and sort of a setting for developing infinity category theory
that people work with today so this does give a way to prove theorems about infinity one categories
it would be really wonderful if we had a type theory that allowed us to prove theorems about
infinity two or infinity n categories because that theory is much less developed um my instinct is you
would have to start uh with a different kind of modification of the homotopy type theory so
like here we introduced um these uh simplicial shapes and these directed polytopes maybe you'd
have to introduce something like the theta n which is this uh category that indexes the
compositions in a higher category like delta indexes the compositions in a one category
but nobody's done that yet so that's an open problem and if you'd like to think about it I'd
really encourage that great thank you I also have a question about these speculation aspects
um basically I I feel that maybe one of the most complicated things to approach
is there is is what you mentioned about there being many models and interpretations of everything
so do you think in this speculation where uh undergraduate are taught infinity categories
would it be that in in this in this world uh people have actually converged to one particular
model that is like always used at least in you know introductory situations or like in a standard
way so that it's easier for people to approach it or would it be that uh everyone gets used to
thinking about various models all the time and like that's included in in the like basic intuition
for mathematics great I'm really glad you asked that question I should have said something about
this in the talk so the way that uh let me explain sort of how infinity categories are
worked with today um I mean I can tell that you know already but just for everyone else
so um it is I don't really well it's um so it's really hard to say what an infinity
category is in set theory and sort of the moral reason for that is it's there's just not a lot
of sets involved in infinity categories so um you know uh so firstly even an ordinary category
doesn't really have a well-defined set of objects because sort of morally you should only ever work
with categories up to equivalents in which case uh you don't have a well-defined set of objects um
so there's that issue and then there's a compounding one in an infinity category between any two
objects you should have a space of arrows but that space is really only well defined up as
to a homotopy type or as an infinity group right up to equivalents
so it's kind of hard to say what that is and then composition isn't a
function with a unique value it's sort of a function that's valued in some contractable
space of choices um there's just kind of a not a lot of sets or sort of functions or
burbaki style mathematics involved in infinity categories um so what these models of infinity
categories refer to is their ways to make precise in sort of classical set theory what it means to
say that you have uh you know some objects and some arrows and some higher arrows and some higher
arrows and you have composition that's sort of weakly well defined up to some higher arrows that
and that those compose in a sense that's weakly well defined up to higher arrows and you have
some weak invertibility and so these models are sort of ways to make all of those ideas precise
the experts or sort of researchers in this area have always had a sense that the models are really
beside the point so you know people have always wanted to work with infinity categories model
independently but it's until recently it has been unclear how you could do that rigorously
in a set based system so I think so you're correct in intuiting that my vision for you know teaching
infinity category theory or you know whether or not we're teaching this to undergraduates my vision
for infinity category theory a hundred years in the future is that models will be completely beside
the point that uh you know we'll have you know perhaps because we have some sort of improved
foundations we'll have uh sort of we'll be able to think about infinity categories sort of as they
really are without spending so much time worrying about the different sort of presentations of an
infinity category in a particular model and people would be glad of that development I think
you know yeah that sounds like it would be great um yeah thank you I should maybe one other thing
I should mention uh you know there's another kind of synthetic approach to infinity category theory
that sort of is a mature technology today and that's described in another joint project of mine
with Dominic Verity we're writing a book about this um so this is the the audience for this are
really you know sort of graduate students and researchers who want to work with infinity
categories now and have a very solid one category theory background but this this does give a way
to work model independently with infinity categories sort of using classical foundations so set theory
as the ambient meta theory in this case awesome thank you I have what I think is my last question
about so you mentioned a couple of times the intended model where seagull spaces or complete
seagull spaces um I wonder how far you've gotten in um actually uh relating uh notions in your
synthetic approach to the actual like the models so for instance if you want uh the notion of limits
in uh complete seagull spaces is it the same as the notion of limit you could
define with your with your uh synthetic approach great yeah uh yeah so thanks for the question so
what we've done uh so we've developed sort of basic basic theory kind of along the lines I've
discussed here um we have a reasonably comprehensive theory of adjunctions um where the data of what
witnesses the fact that a functor is a left adjoint is presented in a number of different ways
some logically equivalent ways and then some genuinely equivalent ways we have a theory of
what infinity category theorists would call left vibrations but we call sort of co-variantly
functorial type families this has to do with the yuneta lemma there's a little tiny bit of that
here there is a proof of the yuneta lemma and in fact a proof of something called the dependent
yuneta lemma which is a better yuneta lemma than I was aware of being true um which we here I've
described as a principle of arrow induction um we do not have uh anything about Cartesian vibrations
though um that has uh sort of more recently been developed by uh Ulrich Buchholz and Jonathan
Weinberger um we do not yet have any theory of limits and co-limits um though somebody's mentioned
to me that they might give that problem to a student for their phd thesis so that might be coming
soon um and in general I'd say there's real there's relatively uh little sort of sophisticated
category theory in this setting um there's one big technical open question which has to do with the
issue of universes that are appropriate for um classifying these different sort of vibration
notions and that's also there's work in progress though not by us okay so so in the coming years
we might we might get to see uh uh like a theory of limits and co-limits in the setting yeah I
think that would be I think that would be really wonderful um we won't be the ones to do it though
so somebody should somebody should take that okay okay thanks thank you very much it was great talk
so there was something that confused me uh
so you said uh that you work in an extension where where types are allowed to depend on polytopes
yeah uh and uh in in what follows is when you say type does that mean that type implicitly
means something that depends on a polytope or um so so my my my my interpretation is that
from this point on type means really a pre-chief of types on a category of of polytopes is that
correct right that's a good way to think about it um so in the uh so yes this and what I'll say is a
little bit different but is consistent with your intuition um so the usual so this this is relating
again to like the categorical semantics of the type theory um the usual way uh so if you if you had
if your context was empty so if there's sort of no no variables or types in the context uh
then when you interpret a type you interpret it as an object in a category or if you have this
homotopical interpretation it's a vibrant object whatever that means um and then if you have a
dependent type um so if you have a type family b that's dependent on a type a or so the context
has this type a then you interpret that as a vibration or a map over a um so you're you're
working in some slice category um so here these polytopes appear like in the base and the type
that's dependent on the polytope is a type over or is it is a thing over that base um so the reason
this was consistent with the pre-chief interpretation is um really the category we're interpreting in
is this category of pre-sheeps these are these bison pliscial sets and when you slice a pre-sheaf
category over a fixed object um that's equivalent to another pre-sheaf category where that you
sort of add into the pre-sheaf the category of elements for the fixed object that you sliced
over and in fact it's better to think about pre-sheafs um than these slice categories because
the substitution operations are stricter there so from the point of view of the model that's
actually the best intuition to have um so the tl dr was you were right yes that's correct
no thank you that makes sense sure um and i should say uh you know we i didn't uh describe
this type theory very clearly i mean partially because i'm not a type theorist and i'm not
so fluent in the language but um i should say in them so uh you know we want to keep these shapes
sort of apart from the types because uh this has to do with the computational aspects which i
haven't really emphasized all along um we want uh the data of a term in here to be something
whose restriction to the boundary or restriction to the sub-shape is really sort of computationally
equal very strictly equal to the given function um just because otherwise the the data involved in
the the types proliferates kind of uncontrollably um and uh so this now has to do with sort of
technical aspects of certain things being co-fibrant and certain things being vibrant um it turns out
these shapes end up being both sort of vibrant and co-fibrant so we can think about gluing them
together strictly but we we could also in fact map into them if we really wanted to um but yeah
there are some technical things to be aware of in setting this all up correctly
question from the bottom of the class here if you go back to the homotopical interpretation
when you were saying that um you know x equal y and if i were to think about visualizing that i
would have expected x and y to be overlapping each other in kind of a visual in the space
but they're stretched apart here we talked and i'm curious as to what that gives us um and it
seems like it's playing with the notion of what it means for things to be equal to each other
yeah and allows for different variants of that is that yeah that's great so your intuition is the
intuition that people had for a very long time uh that if x if you have a term in an identity type
then what does that mean that means x and y are really equal they're the same
in the picture they should be the same point so that that was definitely the intuition that
people had for a very long time what this homotopical interpretation refers to as a new
intuition let's sort of imagine instead of equal meaning the two points were the same
uh meaning there's sort of a continuous way to move from one point to another
it's it's sort of a new imagination and it turns out that this new intuition in a sense uh
sort of better reflected what was going on in the rules of the type theory already
but it's definitely a new way of thinking about equality and um you know there's a lot of
interesting kind of philosophical considerations with that so one of the references i've mentioned
here um this is this uh essay of mike's homotopy type theory a synthetic approach to
higher qualities it's in uh a book of elaine landry categories for the working philosopher
and a number of the essays in that book concern aspects of homotopy type theory um and really
discuss in some detail sort of what these sort of new intuitions are so it sounds like this might
be an essay that's nice to read thank you
are you a quick question or quick you mentioned for the working philosopher what were you
referring to uh so this is a book uh of essays compiled by edited by elaine landry it's called
categories for the working philosopher and i particularly recommend this one but they're
an actually a number of essays in there are very nice got you thank you
if i may uh here we we worked in homotopy time theory and uh i was wondering i know there are
different kinds of foundations based on the dependent types theories that are more or less
equivalent to homotopy time theory and uh i'm particularly thinking about a cubicle type theory
which takes which takes as an axiomatic definition the the existence of an interval type
which is more of a pre-type and then goes on as defining a path as a function from the
interval type into any other type and then defines the concatenation and other general
principles using hornfielders uh couldn't all that i thought about that when you you talked about
these ideas of polytopes uh it wouldn't be more natural to to see this definition of
infinity categories in a setting such as a cubical theory great so uh yeah so absolutely
there's a lot of similarity between this sort of simplicial type theory that we're using
for infinity categories here in cubicle type theory um and whether there's a way to develop
infinity category theory in something like one of these cubicle type theories is an active
research area um one of the things that uh is kind of an open question is whether there is
sort of a good model of infinity one category sort of in the sense of classical mathematics
that's based on one of these cube categories i mean there are ways to transfer the model structures
for uh quasi categories or for complete seagull spaces to cubicle pre-sheeps instead there's
sort of formal ways to transfer these model structures but uh those formal ways don't
necessarily give you a nice characterization of the fibrin objects so you don't necessarily
know exactly how to think about infinity categories as cubicle sets um so that's one of the
sort of open research areas um uh so i think the reason that i'd say it's not more natural
from this point of view is that on the categorical semantic side it's not really well understood how
to think about uh infinity one categories as something that are governed by cubicle shapes
rather than simplicial ones but uh you're not the only one who has this idea and people are working
on it okay thank you very much sure
all right um i might turn off the recording uh if i can figure out how to do that
