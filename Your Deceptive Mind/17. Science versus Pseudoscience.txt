It is common to claim that one's beliefs are based upon legitimate science.
The mantle of good science is often used to market products or promote ideas, while the
counterclaim that a belief is pseudoscience or junk science is equally used to denigrate
beliefs and practices that one does not hold.
Science still carries a very high degree of respect in our society.
So many claims and beliefs label themselves as scientific, but are they?
For example, is anthropogenic global warming a legitimate science or a pseudoscience as
some claim?
What about cryptozoology, the study of unusual creatures unknown to current science such
as Bigfoot, the Loch Ness Monster, or the Chupacabra?
Or how about string theory that is held by prominent cosmologists of today?
Or ESP, thigh research.
Are these legitimate sciences?
Are they on the fringe of science?
Or are they pseudosciences?
The term pseudoscience refers to beliefs and practices that claim to be scientific,
but lack the true method and essence of science.
They have the patina of legitimate science, but something has gone terribly wrong.
Pseudoscience goes beyond just making a few errors or a few sloppy practices.
The methods are so flawed that the entire endeavor is suspect.
The practice doesn't even warrant the label of legitimate science.
But in reality, there is not a clean division between pristine science on one end and rank
pseudoscience on the other.
There is rather a continuum or spectrum between these two extremes.
Many legitimate sciences may incorporate one or more features normally associated with
pseudoscience.
A well-trained, respected, successful scientist may still make errors in judgment, poor methodology,
may overinterpret their results.
For example, they may commit all or many of the errors in cognitive thinking that I have
discussed in this course.
And some pseudoscientists may occasionally get something right.
They may in fact use some legitimate or valid scientific methods in order to promote their
ideas and beliefs.
In the middle between these two extremes of science and pseudoscience, there is a fuzzy
grazedone, the borderlands between legitimate science and what Carl Sagan has called the
cheap imitation.
Philosophers call the difficulty in drawing a sharp line between the two ends of this
spectrum the demarcation problem.
However, this doesn't mean that there aren't sciences that are mostly legitimate and other
practices that are hopelessly pseudoscientific.
Remember, that's the false continuum logical fallacy.
The denial of two extremes of a continuum simply because there is no sharp demarcation
line in between the two of them.
This fuzziness in the middle does not mean that these two extremes do not exist and that
we cannot meaningfully speak about them.
The key is to know how to recognize the features of pseudoscience and the features of legitimate
science.
In a previous lecture, I discussed the philosophy of science and another of the types of evidence
I described in these lectures, those practices that go into good and rigorous science.
Examining extreme cases of pseudoscience is like a doctor studying an advanced form of
a disease.
The features will be much more obvious and extreme.
They will therefore help a doctor to recognize the more subtle signs and milder forms of
the pathology.
It's for this reason that I think it's very instructive to examine those belief systems
which, while they purport to be scientific, are on the fringe of science like cold fusion,
cryptozoology, belief in UFOs, for example.
Some people may denigrate spending any time on such beliefs because they're on the fringe
and they're unusual.
When I maintain they are excellent learning examples, by studying the fringes of science,
we will learn a great deal about legitimate science and how to do the best science possible.
In the same way, we can study these extreme pseudosciences and develop a picture of what
extreme pseudoscientific pathological features have in common.
We also will then see the patterns, the commonality among them.
What are the types of cognitive flaws that those practicing pseudoscience tend to make?
It is an excellent opportunity for studying the features of what are even called sometimes
pathological science.
So what are the features of a pseudoscience that we need to be on the lookout for?
I think the most prominent feature and the one that often determines much of what is
flawed about pseudoscience is that it tends to work backward from desired results rather
than following logic and evidence where it leads.
This is also referred to as motivated reasoning.
If we know where we want to get cognitively, human beings are very good at getting there,
but backfilling in justifications, making evidence fit into preconceived notions.
We saw this effect in many of the scientific blunders that I discussed in a previous lecture.
So essentially, pseudoscience starts with the conclusion and then works backwards from
there, rather than open-mindedly and fairly going forward from the evidence wherever it
may lead.
This is similar to what I described in a previous lecture on reason and logic as the difference
between reason using logic and evidence to arrive at a valid conclusion and to make sure
that our conclusions are sound and rationalizing using biased logic and cherry-picked data
in order to defend a conclusion at all costs.
In essence, pseudoscientists use the processes of science, the superficial processes or similarities
of science to science in order to scientifically rationalize a conclusion that they wish to
be true rather than using the methods of science to determine if their belief is true or not.
What they fail to do is make a concerted effort, therefore, to prove their own theories wrong.
That should always be the first step of any scientist.
When you come up with a new idea, a new hypothesis, the first thing you should do is everything
possible in order to disprove your own theory.
Find every way possible to conduct an experiment or an observation that can falsify the theory.
When the theory or the hypothesis has survived every attempt you can think of to prove it
wrong, only then is it reasonable to give it provisional assent to think, all right,
now this is a theory that may be true.
Then it's a good idea to check with your colleagues, publish your results in peer-reviewed journals
and see what other scientists believe, other experts.
Can they think of any ways that maybe you missed that could be an alternate to the theory that
you have or that could potentially prove it wrong?
They also consider alternate theories and not just their pet theory, good scientists,
that is.
But pseudoscientists will often simply make attempts at proving their pet theory correct
and will only in a very perfunctory manner address other theories which might also explain
the observations that they're making.
Otherwise you fall prey to what I previously described as the congruence bias, the tendency
to only test your own hypothesis.
But this can easily lead to cherry-picking data that appears to support your theory because
you'll be missing the fact that the same data also can be used to support other theories
or that other ideas also can produce the same evidence without your theory being correct.
Only testing one's own theory by looking for positive evidence therefore is a typical
feature of pseudoscience, but not testing alternatives or evidence that might prove
one's own theory incorrect.
Pseudoscientists in fact endeavor to prove their theory correct.
They will in fact avoid or explain away disconfirming evidence.
They may engage in special pleading in order to explain why disconfirming evidence doesn't
in fact disprove their theory even though it may seem to.
They also do what we call shifting the burden of proof onto others.
They might say something like, prove my theory wrong.
Or if you can't prove my theory wrong then you must accept it as correct.
But in fact proving their theory wrong or at least attempting sincerely to do so should
be their job.
It's their theory, their claim.
The burden of proof is entirely upon them to show that their theory is correct because
it has survived attempts at falsification.
And that no alternate theory, especially a simpler one, can also explain the data that
they are presenting.
Pseudoscientists also commonly fall prey to confirmation bias, which as I described is
perhaps the most powerful bias that affects our thinking when we're assessing different
ideas.
Confirmation bias is the process of looking for supportive evidence that leads to conclusions
we wish to be true.
This gives us a false sense of where there's smoke, there's fire.
There's all this evidence circumstantial or maybe even direct or indirect that suggests
that my theory is correct.
If my theory weren't correct, how could this be?
How could there be so much evidence that appears to support my argument?
But confirmation bias leads to cherry picking of only the evidence which supports one's
own theory.
You have to collect data in a systematic way to know if it really does support a theory.
This favoring of positive evidence, regardless of quality, is therefore a key feature to
look out for in a pseudoscience.
The flip side of that is that negative evidence, regardless of quality, is also dismissed.
Or for example, a scientist may look at a study which confirms their belief and accept
it uncritically.
While looking at another study that seems to contradict their evidence, they will delve
into the details and look for subtle flaws, look for reasons to reject the study as solid
or conclusive because they don't want to accept its conclusions.
For any particular question, there is especially now that so much scientific evidence is out
there, thousands of new papers are being published every year in every field.
There is so much noise, if you will, that if you are truly dedicated to supporting any
notion, you can probably find studies in the peer-reviewed published literature that seem
to support that position.
Maybe by looking at all the data systematically, though, can you know if the bulk of evidence
or the consensus of evidence really supports your position?
There is also a tendency to rely upon anecdotal evidence and testimony.
This is part of the more general feature of relying upon weaker forms of evidence while
eschewing stronger or more reliable forms of evidence.
Now, anecdotes are uncontrolled or ad hoc observations.
They are not systematic.
They are therefore plagued with confirmation bias and recall bias.
For example, if we are trying to assess the safety and effectiveness of a medical treatment,
we can't rely upon the testimonies of people, of patients who have taken that treatment.
Let's say, for example, we are trying to decide whether or not a particular treatment
helps to cure cancer.
And you may go to a meeting in which that treatment is being supported by anecdotes
or testimonies of people who took the treatment and are now alive and doing well, maybe even
cured from their cancer.
However, those testimonies are being systematically biased.
People who took the treatment and died are not there to tell their story.
Dead men tell no tales, literally.
Also, we don't know that they didn't take other treatments.
Variables were not controlled for.
Maybe they tried three or four or five different things, both standard and non-standard treatments.
How do we know which one is responsible for the fact that they're doing well?
So anecdote is a pejorative term that scientists use to mean evidence which is uncontrolled
and therefore plagued by biases, not systematic, subject to cherry picking, perhaps even systematically
biased, and therefore unreliable as evidence.
But pseudoscientists will often heavily rely upon this evidence because, essentially, they
could make it say whatever they want it to say.
Favoring such low-grade evidence over more rigorous evidence, because it gives the desired
results, can be used to support just about any belief, no matter how implausible it is.
And there is this tendency to feel or to be more compelled by this kind of evidence.
It takes critical thinking skills to understand that we shouldn't really listen seriously
to stories that other people tell us, at least not as confirmatory definitive evidence.
But people will often say things to the effect of, well, what are you going to believe, numbers
on a paper or real people, as if real people, quote-unquote, should be more compelling data?
That kind of emotional appeal is also common among pseudoscientists who are trying to defend
positions which the numbers on a piece of paper do not support.
Another feature to be wary of is the fact that core principles of a particular area
of pseudoscience may be based upon a single case or observation, rather than a large body
of carefully collected data.
They use preliminary evidence or even a single anecdote as a basis for then an elaborate
later system of belief.
They are essentially making the hasty generalization logical fallacy, basing far-reaching principles
on a single piece of perhaps unreliable evidence.
An excellent example of this is D. D. Palmer, the father of chiropractic.
He based the principles of subluxation theory on a single case, an alleged curing of a person
of deafness with neck manipulation.
He then extrapolated from this all of chiropractic theory, at least the classic theory of subluxation,
the notion that a blockage in the flow of some essence or life force that he called innate
or innate intelligence through the spinal cord and through the nerves are what keep
the organs and the parts of the body healthy.
Blockage in that flow therefore causes illness, disease, and symptoms.
We believe that he freed up the flow of this life energy in this patient, enabling them
to hear, curing their deafness.
At the time though, he was not aware apparently that the nerves that subsume hearing at no
point pass through the neck.
So there really isn't any plausibility to the notion that manipulating the neck can relieve
the underlying neurological pathways that we need to hear.
Another example is the founder of iridology.
Iridology is the notion that the iris of the eyes reflect health and disease of the whole
body.
This is based upon a general approach called the homunculus approach to diagnosis, the
belief that the entire body is represented in one small part or piece of the body, in
this case the iris of the eye.
The founder of iridology made a single observation of an owl who had broken its wing, and he
observed that a gold fleck in the owl's eye went away when the wing was healed.
From this single observation, he elaborated the entire fanciful homunculus based notion
that all diseases and ailments can be diagnosed and even predicted by simply looking at the
random colors of flecks in a patient's eye.
Or principles may not be based on just a simple or a single observation, but on a philosophical
idea, a philosophy that itself has not been empirically tested or developed as a scientific
theory or discipline.
The notion of life energy, for example, that I mentioned in a previous example, is a pre-scientific
idea, but it forms the basis of many so-called alternative therapies like therapeutic touch
or Reiki, acupuncture, straight chiropractic, and even homeopathy to some degree.
In essence, prior to us having a thorough understanding of all of the physiology, anatomy, biochemistry,
all the processes that go to make up a living organism, it was hypothesized that there must
be some energy, a life energy that makes some things alive and other things not alive.
In the final analysis, it was really a placeholder, an argument from ignorance, if you will.
Whatever we currently didn't understand, that's what life energy did.
Eventually, we were able, however, to explain all the processes of life, at least to a reasonable
degree of detail, and there simply was nothing left for life energy to do.
It was a philosophy, a philosophical idea of how the body works, never supported or
tested by science.
Now it's an obsolete philosophical idea, but it still forms the core principle of many
healing modalities.
Another feature that should send up a quote unquote red flag that you might be dealing
with the pseudoscientific end of the spectrum are grandiose claims based upon preliminary
or flimsy evidence.
We sometimes call this the Galileo syndrome for the frequent tendency to compare oneself
to Galileo.
In other words, far-reaching claims that overturn entire segments of well-established science
are extrapolated from very little research or small bits of evidence.
This tends to occur with pseudoscientific endeavors because when their theory conflicts
with established science, rather than saying, hmm, there must therefore be something wrong
with my theory, or at the very least there is some anomaly that is not understood or
I don't understand.
However, the pseudoscientist, rather, will simply broaden the implications of their own
theory claiming that, well, I guess all of this area of mainstream science must be wrong
because it conflicts with my theory.
One example of this kind of process, which leads all the way to what proponents even
call alternative science, is a book written by a researcher called Lloyd Pie called Everything
You Think You Know Is Wrong.
This results from this chain reaction of pseudoscientific claims.
Pie believes, for example, that there were ancient civilizations, unknown to modern archaeology,
that aliens were somehow involved in human history and even evolution, and that this
can tie into observations of Bigfoot and other humanoid creatures, again, unknown to
science.
In each case, when he has a specific explanation or a specific claim that conflicts with archaeology
or paleontology or biology or even modern physics, he simply dismisses the modern findings
of science and replaces them with yet another pseudoscientific belief system, in this what
I call chain reaction, until, by the end of it all, you have replaced all of science with
an alternative version of reality, or everything that scientists claim must therefore be wrong.
Another example is the comic book artist turned pseudoscientist, in my opinion, Neil Adams,
who is a proponent of the hollow or growing Earth idea.
This is the notion that the planet Earth was much, much smaller in the historical past
and has been slowly getting larger over time by the generation of new matter.
He believes this is true because the continents of the Earth fit together like puzzle pieces.
We know that they do fit together to some extent because of plate tectonics, but he
thinks they fit together all the way around, because at one point in time they were all
connected on a small Earth, which later expanded, the oceans filling in the cracks that emerged
in between.
However, there are major scientific problems with this theory.
Where is this new matter coming from?
How is gravity increasing on the Earth?
If all of the planets of the solar system were increasing as he believes, how could
their orbits be stable?
Each time one of these reasonable scientific objections is raised to this theory, he simply
waves his hand and wipes away an entire other discipline of science.
Well, perhaps it's magnetism, he says, that holds the planets in their orbits and not
gravity.
So now all of gravitation and magnetism has to be rethought just to fix this problem with
the growing Earth theory.
He also adds spontaneous creation of matter from nothing.
This is something that simply is unknown to physics.
There is the generation of virtual pairs of particles, but then they immediately annihilate
each other.
But the creation of new stable matter from nothing would violate the conservation of matter
and energy, a very well-established law of physics.
It would also, his growing Earth hypothesis, would violate much of what we know about from
modern geology and plate tectonics and volcanism, for example.
Again, he would overturn virtually all of modern science that touches on his theories in order
to protect or defend his one idea that he does not want to surrender.
Pseudoscientists are also known for making very bold claims, claims that are not just
bold but often absolute.
But the bottom line is that they go beyond the evidence.
It's okay to make big and grandiose claims as long as you have the evidence to back it
up.
And even modest claims could be pseudoscientific if they extend too far beyond what the evidence
can meaningfully support.
Good science, rather, is very careful and conservative.
It tends not to make claims which exceed the evidence.
For example, in the process of peer review when experts in a field will review a paper
submitted by one of their colleagues in the hopes of being published, one of the specific
things that they have to decide is, do the conclusions of the researcher extend from
the evidence?
Can they be supported by the actual data that is being presented in this study?
If the authors are making conclusions which are too bold, which go beyond the evidence,
they will often be required to fix that before the paper can be accepted for publication.
Another aspect of pseudoscience I think related to the boldness and the extravagance of their
claims are that simple answers are often offered to very complex or multifactorial problems.
While scientific process often leads to simpler, elegant solutions, pseudoscientists offer
simplistic solutions even to very, very complex phenomena.
So for example, we often call these a theory of everything.
Now scientists are legitimately looking for more and more powerful and elegant theories
that can explain more and more of the natural world.
But when that process is taken to an extreme, and again leapfrogs over the evidence, where
one tiny little phenomenon is used to explain our entire understanding of the universe,
for example, then that becomes a theory of everything, a theory that's exceeding really
the justification.
In medicine we often see this as the cause for all disease or the cure for all disease.
One example of that is Hilda Clark.
She believed that liver flukes are the cause of all human disease.
Therefore all diseases can be cured by treating this liver fluk.
Therefore she has the cure for all disease, or at least she had before she died.
Pseudoscientists also often demonstrate hostility towards scientific criticism.
Science as we say is a harsh mistress.
I spoke about the process of peer review, where a community of scientists are essentially
highly critical of any new claims that are made.
They will pick over data, make sure that their colleagues are accounting for all the evidence,
are not making claims which go beyond the data, are being logical and rigorous that
they've gotten their math correct.
All of these things.
Publication in the peer review journal is a meat grinder, but it's supposed to be.
That is how science is supposed to work.
That's the only way to separate out those ideas that are useful and have potential from
those that are a dead end.
Now while no one likes to be criticized, scientists have to develop a thick skin because criticism
is part and parcel of the process of science.
Pseudoscientists however generally cannot accept this mainstream harsh criticism.
They often do not engage with the scientific community.
They claim that they are the victim of a conspiracy or a dedicated campaign against their ideas.
Perhaps because their ideas are simply too revolutionary.
They may appeal to anti-elitist sentiments to say that they're not on the inside in the
old boys network.
But these are all attempts to deflect the legitimate process of self-criticism that is supposed
to drive science forward.
They also may use pseudo-scientific terms, but in an imprecise or unscientific way.
Science does tend to be a bit overwhelmed with what we call jargon, and this can make
it inaccessible or difficult to understand for the non-expert.
But at its best jargon is the use of terms that have very precise and unambiguous definitions.
They are used so that experts can communicate to each other in an efficient and precise way,
without misunderstanding exactly what they're talking about.
This gives legitimate science this jargony feel that we all recognize, talking in technical
highly sophisticated terminology.
Pseudoscientists exploit this to use fancy jargony terms, but not to make their claims
more specific, but to obfuscate, to hide what they're really saying.
They may use jargony terms that are vaguely defined or have a shifting meaning.
As an example, there are the intelligent design proponents who often use the term information
as if they were using it in a precise scientific way.
But in fact, there are many different specific kinds of information that mathematicians have
specifically identified and named, whereas intelligent design proponents simply use the
term information vaguely, and in fact they shift the definition around using it in different
ways at different times, in order to confuse, not in order to explain a specific point.
Pseudoscientists are also marked by a failure to progress.
Pseudoscientists that are legitimate and useful will tend to progress over time, whereas pseudosciences
tend to be stagnant, they're chasing their tail, or they are endlessly trying to establish
their basic principles, never moving off of even doing just that, or the very existence
of the phenomenon that they're studying.
There's still 100 years later, for example, trying to establish that Psi or ESP even exists,
not alone progressing to define how it works and what are the other principles of ESP.
Anomaly hunting is another feature that is common to pseudosciences.
Now I spoke previously about the fact that anomalies are very useful in science, because
they point to a shortage or a hole in our current understanding.
They point to the way to new discoveries.
However, looking for anomalies as a way of establishing a conclusion is what we call
anomaly hunting.
It does not seek to falsify or to explore alternatives, but just to say, look, there's
something unknown here, there is some anomaly, and of course it's easy, there's always anomalies
to find if you look hard enough.
Therefore, their view, their claim is true.
So the real fallacy they're committing is in using anomalies to prove or confirm a conclusion
rather than just as a starting point for later investigation.
In the next lecture, we will explore specific pseudosciences, and we will see how they manifest
all of the features that I described in this lecture.
