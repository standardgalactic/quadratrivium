Lecture 36 Philosophy and Science
I'd like to begin this last lecture by expressing my sincere admiration for those who have made
it this far.
You have received a moderately massive dose of philosophy and of science, and if this
is the way you choose to spend a good chunk of your leisure time, you're my kind of person.
I admire anybody who has made it this far.
I have not generally thought it's been my job in this course to give you my opinion
about the material we've been discussing, because I don't honestly think you have much
reason to care what I think about it.
But I will, in this last lecture, take the liberty of making some suggestions about themes
that have emerged from the course, and I mean them seriously as suggestions, but I seriously
don't mean them as more than suggestions.
I find this material enormously difficult, and I find it difficult to be articulate,
much less decisive about these matters.
So my suggestion will be that the most interesting themes are tensions between individually attractive
positions.
I'm not going to tell you what I think the right answer to these questions ends up being,
so much as the right way to try to be articulate about how to face the difficulties that these
questions pose for us.
Intermittently I think some tolerably clear morals emerge from the story, but by and large
what I think we learn is how to inhabit profound intellectual tensions successfully.
We began the course by wondering what is special about science.
The idea that there's something distinctive about the sciences is attractive and remains
attractive, but it sits awkwardly with attractive aspects of holism and of naturalized epistemology.
Like many of our questions, this one has actually morphed into several reasonably distinct questions.
The empirical sciences are different, not just from pseudosciences and their ilk, but
also from philosophy, from everyday theorizing about the world, and from other worthwhile
enterprises, and those are different distinctions that might have to be unpacked rather differently
one from another.
As we saw in the last lecture, it's not clear to what extent we want to distinguish scientific
from everyday theorizing. This is itself one of those tensions that resists a clear and
decisive answer.
Folk psychology probably does not aspire to the kind of explanatory depth we associate
with scientific theories. It's a theory, if it's a theory, driven as much by a need
to cope with one another, as by some aspirational project for unifying or explaining what's
really going on with one another.
But it's dangerous to say that folk psychology is in a different business from scientific
psychology or even from neuroscience, in part because the function of such a claim is largely
to deflect serious criticism that might be aimed at the laws or ontology of folk psychology.
So maybe we don't take ourselves to be doing full-fledged science in our everyday lives,
but we do need and want to hold ourselves in our everyday lives, and not just about
folk psychology, to many of the standards of science.
So this issue arises in many of our everyday explanatory enterprises. We don't give rigorously
scientific explanations most of the time. But scientists don't give rigorously scientific
explanations most of the time. This is the notion of irrational reconstruction that
has figured so prominently in this course.
But though we don't hold ourselves to highly formal or highly ambitious standards of explanatory
explicitness, nor do we want to countenance a drastically different and lower standard
than the scientific one for our ordinary explanations. We might, if we're thoroughly persuaded by
Basavad Frasen's deflationary account, according to which nobody really explains anything,
we just answer one another's why questions. That's a contender, but assuming that one
takes the explanatory enterprise seriously somewhere, we don't want to draw too stark
a distinction between a successful scientific explanation and a successful non-scientific
explanation. Because science, broadly speaking, is supposed to represent us at our epistemic
best. It's not something deeply different than what we're doing in our everyday projects
of trying to understand the world.
So science had better be different from our everyday explanatory and predictive practices,
but it had better not be too different from them. And likewise, it had better be different,
but not too different from philosophy. Frought, though the process is, and as hard a time
as we have had over and over, characterizing the way in which observation and evidence
distinctively bears on science, science does find a distinctive way of putting questions
to nature and getting at least tentative answers from nature. Philosophy works differently.
There's a difference that makes a difference between what philosophers do and what scientists
do.
On the other hand, the search for a demarcation criterion or a useful bundle of demarcation
criteria did not work well. And it does not look promising. So philosophy and science,
philosophy, sorry, science and metaphysics don't look radically distinct from one another.
There seems to be at least that much truth in philosophical naturalism. In particular,
science probably cannot be done without some kind of metaphysical picture or conception
lurking in the background.
Desperate attempts to avoid metaphysics, of the sort we've seen in logical positivism
most prominently, run the risk of leading to bad metaphysics and to bad faith about
metaphysics, by which I mean a refusal to admit that you are perpetrating metaphysics
when in fact you are. It's very hard to come up with a way of doing science that involves
no metaphysics. The positivists had views about what's really real. It's very, very
closely tied to observation, for instance, but they had a hard time admitting that because
they didn't want to make metaphysical statements.
The inescapability of metaphysics emerges most clearly in the notions of categories,
minds, possibilities, groups. These are inescapable in scientific and in everyday explanatory
practices.
In any given context, what counts as two things being similar? Two emeralds having the same
color, is that grew or green? Two organisms belonging to the same species, does that depend
on our purposes or is that settled by the world? What counts as being rationally and
properly indifferent between somehow similar possible states of affairs? In our situation
of ignorance, how are we to represent different ways the world might be? We categorize, we
impose our language, our culture, our biological nature, our history, dispose us to clump things
together. We cannot do without these categories, wherever they come from, but for the very
reason that we can't do science without them, it's hard to give them an independent scientific
vindication.
Our commitment to these categories gives us a kind of inner realist in our intellectual
personality, someone who takes these kinds and categories seriously, who uses them to
explain and to understand, who is not distanced or alienated from, what the theory seems to
commit us to saying about the way the world is. That's a genuine and valuable part of
one's intellectual or scientific personality, but it needs to be balanced by an inner anti-realist
who explains these kinds as ours, as arising contingently from aspects of our nature that
might be misleading. Even our biological nature, for instance, might predispose us towards
misguided psychological assumptions or assumptions in physics, like, for instance, the Euclidean
Geometry of Space. So even if a category seems deeply natural and all but inescapable
to us, our inner anti-realist wants to raise questions about whether we should try to do
without it.
There's no general answer, in my view, to the tension between realism and anti-realism.
The relevant virtue is not maintaining a consistent realistic attitude or consistent anti-realistic
attitude. It's transparency and honesty. We want to be aware of the correlative dangers
of dogmatizing and of deflating.
How are these tensions between the distinctiveness of science and the continuity between science
and other enterprises to be, if not resolved, at least softened? Well first, we should realize
that our metaphysical views, our categories that we bring to the table in doing science,
are not very directly testable, and therefore we should pursue modesty and flexibility with
respect to these categories, with respect to our sense of what's possible, of what's
a real kind, of ways in which two things are similar.
And we should recognize that science differs from other pursuits, not in being free of
prejudices, not in the way the world imposes itself directly on the scientist's mind, but
rather in a lot of medium-sized ways, rather than in one or two big ways. This is how we
can maintain some genuine distinctiveness for science without claiming to solve the problem
of demarcation, with which we spent so much time early in this course.
Science does involve a distinctive combination of observation, of education, of the Kunian
indoctrination sort, among others. It has a distinctive kind of social structure.
What's special about science is the way that it manages to balance paparian criticism, subjecting
one's views to criticism from other people and, speaking metaphorically but importantly,
from the world, with a kind of Kunian confidence and assurance that allows science to build,
to assume that it's gotten parts of the world figured out and to do something using these
cognitive resources. It is a delicately maintained balance, and it's an imperfectly maintained
balance. Science probably should not be credited with having gotten this right remotely once
and for all. It's something that needs to be rethought, and the history of science helps
show us ways in which it's been importantly rethought.
Reflecting this continuity between science and other worthwhile enterprises, most of
the best philosophy of science these days is both informed by and driven by empirical
concerns. I hope you got a sense in the last three lectures before this one that the richer,
more scientifically informed approach to the general philosophy of science topics is rewarding.
The topics raise new and interesting questions and inform more abstract issues about, say,
what it takes to think of a kind as real that allows philosophers to offer things to scientists.
Scientists are starting to take philosophical work a bit more seriously than they had because
philosophical work is more scientifically informed than it had been.
General philosophy of science, of the sort we spent most of the course doing, does not
kick in very directly in laboratory work, but I think it can in a bunch of ways that
will emerge in the course of this lecture help scientists do their day jobs. It helps
them be articulate about the advantages and dangers of different approaches to their discipline.
That's different from the work that is very informed about what a species might be or
how thermodynamics impacts views about the direction of time.
The holism and naturalism of somebody like Quine helps us see that philosophers and scientists
can sometimes be working on the same parts of the web of belief, but approaching them
from different angles. So we can recognize that philosophy and science are not identical
undertakings, but that they could be part of what is genuinely, in some sense, one enterprise.
This very holism, however, points to another tension, which is the difficulty of figuring
out the right way of assigning praise and blame across the web of belief. We don't want
to be pure relativists about this and just say anything that's not forbidden by the laws
of deductive logic is perfectly fine, but nor did we have much luck coming up with, say,
an inductive logic that tells us the right way to apportion praise and blame. At best,
if we're relying just on what the world can do, the world will tell us that something
has gone wrong somewhere, and it's up to us to be bold, honest, and careful in trying
to figure out how to modify our web of belief in the light of experience. We have to realize
when we are perhaps excessively attached to some pet theory and that we should consider
letting that be the part that gets falsified by what experience seems to kick up. The world
won't settle these sorts of questions for us, but that does not mean, as Quine and some
of his constructivist followers sometimes seem to suggest, that the world gets no say
that this is a free decision on our part. It's a constrained decision, but it is as
it were a freely constrained decision. If we do science properly, we let the world tell
us what to do, and that's the kind of freedom we want in doing science. We don't want
license. We don't want to be able to do whatever we want. We want to have some control in how
we let our beliefs be informed by experience. Turning to another tension in science, empiricism,
both about meaning and about evidence, is an attractive idea. It dominated the first
part of our course, but it's difficult to keep empiricism in check, and empiricism sits
rather poorly with scientific realism, which is another attractive idea that tended to
dominate the latter part of our course. Empiricism about meaning, the idea that what we mean by
our terms cannot be allowed to outrun observational checks on meaning, is particularly unfashionable
with philosophers these days. And for good reason, we've seen that it hamstrings our
ability to talk about anything that's not fairly directly presented in experience. And
that dooms important parts of the scientific enterprise and maybe of everyday explanatory
enterprises. But let's not lose sight of the lesson of Einstein and special relativity.
Once we start appealing to models, to analogies, to other ways of letting our terms get meaning,
our semantic reach starts to outrun our epistemic grasp. We lose some valuable constraints that
inform as well as constrain what we're saying. We don't want to start thinking that we understand
what absolute simultaneity might mean. And so if we stop construing the positivist doctrines
about meaning as rules that one must follow in order to do science, and start thinking
of them as reminders about some important scientific values, empiricism about meaning
can be rehabilitated and is a valuable scientific doctrine. Because we don't want to let our
meanings get muddled, and constraining our meaning in observational terms is a nice way
of avoiding muddle. And who knows better the dangers of conceptual muddling than philosophers?
A crucial part of our valuable function is to help scientists stay clear about what they're saying.
And so empiricism about meaning is, I think, more valuable than a lot of my colleagues find
it. Nevertheless, I incline towards scientific realism, which requires rejecting a strict
empiricism about meaning. It also goes beyond empiricist strictures on the use of evidence.
So for instance, I'm willing to use, in many contexts, inference to the best explanation
as evidence for the truth of what a theory says about unobservable reality. So that's
almost sufficient anyway for making me a scientific realist. But we realists need to stay in touch
with our inner empiricists, another part of our intellectual personality, and especially
our inner empiricist about evidence, rather than about meaning. Because inference to the
best explanation is fragile, even under favorable conditions. Even if we help ourselves to the
idea that without some argument, we can nevertheless trust inductive inference. We never answered
Hume's skepticism about induction. Inference to the best explanation is inference that
goes not just beyond observation, but beyond the observable. And we should, especially
if we're realists, remain perpetually uncomfortable with that. We should squarely face the limitations
of our evidential situation. And here, Cooney and talk of values, rather than positivistic
talk about rules or methods, is helpful. When we go boldly beyond experience, as we must,
if we are to pronounce something a law in the intuitive sense, if we want to say that
being made of copper makes something conduct electricity, if we want to say that's not
just the sort of thing that happens, but it's the sort of thing that must happen. If we
want to say that unobservable reality is a certain way, even though we can't directly
detect that it's that way. If we want to evaluate counterfactual conditionals, if we want to
claim to know how the world would behave if things were somewhat different than they
are, these are all valuable things to claim oneself able to do. We should be clear exactly
what benefit we're getting from these leaps beyond the evidence. There's something intrinsically,
epistemically presumptuous about realism. Being presumptuous is not always and automatically
a bad thing to do, but we should try to explain to ourselves why we think we're entitled
to the presumption. Do we think, literally and straight-facedly, that the world will
answer to our explanatory ambitions? That the fact that something unifies our conception
of the world is evidence that it's true? If we don't think that, do we have a different
story about why it's okay to perform such inferences? Do we have a somewhat anti-realist
story, for instance, according to which all we're trying to do is come up with a unified
theory about the world, and we're not worrying about truth in some robust correspondence
sense to the world? On the other hand, if we're going to do without laws, if we're going to
do without deep explanations, if we're going to do without claiming that there's some
necessity out in the world that we can detect, we have to admit it and actually do without
them, not just sanitize them into a pretend empiricist version of them, but then appeal
to them in our everyday, unreflective lives. So if we're going to go beyond the evidence,
we have to admit the epistemic costs. If we're going to constrain ourselves tightly within
the evidence, we have to admit the costs to our explanatory ambitions. And so, a great
deal of the philosophy of science is about a kind of general ethics of epistemic resource
management. That's a sort of dull, ponderous phrase that makes it sound like a business
course. But my point, I think, is an important one. Science and philosophy can work wonders,
but neither can work magic. What we're able to get out of these disciplines will depend
significantly on what we help ourselves to at the outset. And we should try to figure
out what we think we're entitled to claim for ourselves at the outset.
Do we want to emphasize the intellectual virtues that cluster around evidential security?
If so, empiricism is a good way to do this. We should stick pretty closely to what's
presented in experience, and we shouldn't presume that too much is presented in experience.
If we do this, we're highly likely to avoid certain mistakes. So skepticism about induction
of the sort that Karl Popper and David Hume put forward and defend, and a resistance to
Bayesian subjective probabilities, a resistance to the idea that we should think the world
takes our biases, our categories, our conception seriously, is a good way to avoid error. We
should admit, however, that this increased security comes at the cost of significantly
diminished resources. We've seen thinkers from a number of approaches claim that science
doesn't need any more than they're willing to permit. The positivists think that science
doesn't need to talk seriously about unobservable reality, for instance. Maybe, but most of
us think in our heart of hearts that there is an unobservable reality, and it costs something
to remain silent and skeptical about the nature of that unobservable reality. It prevents
us from saying things we might unreflectively have thought we were entitled to say about
copper needing to conduct electricity, not merely happening to conduct electricity, for
instance. So on the other hand, you can pursue your explanatory ambitions. You can take
your models seriously and think that they can describe a world you can't see. You can
take your subjective probability assignments seriously and think that you can update them
in a way so that they deserve respectful consideration. And you can then set out to maximize confidence
and understanding. But the risks here are muddled headedness about what you mean and
mistakes about what you believe. So these are the vices and virtues not just of science,
but of everyday life as well. Depth and breadth in our understanding of the world is an inherently
risky enterprise. It has costs in terms of how clearly we understand the claims we make
as we go beyond the evidence, and how strongly we can support the claims we make when we
go beyond the evidence. Another difficult tension that has arisen within this course,
Kunian fidelity to actual science is an attractive idea. But the is-ought distinction is an
attractive idea, and these two sit somewhat awkwardly together. We should talk about the
extent to which they can be reconciled. The smart money, I think if you have to bet, is
on scientific practice over philosophical advice about scientific practice. They've
done pretty well. We haven't done quite so well. But what scientists say they're doing
doesn't always reflect what in fact they're doing. Scientists tend to commit philosophy
when they describe what they do. We've seen that many of them think, for instance, that
they're Poparians when they probably are not. Scientists don't like to admit that they've
got philosophical views, but they virtually always do. And so to some extent they're
on our turf. And anyway, in order to describe what scientists are doing in the first place,
we have to bring some conception of what it is to do science to the table. We don't
mimic scientists when they're going to lunch. We have some conception of which part of what
they're doing counts as the part we care about, counts as doing science. And in any case,
the smart money doesn't always win in any particular case. Even though by and large
you should bet on science, sometimes there is room for informed criticism of actual scientific
practice. I suggested a couple of lectures ago that at least sometimes the ways parts
of science use statistical significance tests seems to me a little bit flat footed. And I
don't feel obligated to defer to the people in the white lab coats merely because they've
got the white lab coats. Talk about objectivity in science tends to bring out the worst in
everybody. I have helped myself to this notion with some misgivings in this course because
it's just hard to do without. But it's an intrinsically dangerous notion, I think. It
tends to lead to exaggerating the virtues and or exaggerate exaggerating the vices
of science and scientists. So people sympathetic to views like social constructivism or postmodernism
hear a term like objectivity and they picture scientists claiming to view nature from nowhere
to step out of their skins to step out of language to step out of history and to carve
nature at its joints via some purely passive cognitive process. They rightly regard most
of this as pretty naive, but that stems from a ridiculously demanding notion of objectivity
being deployed. The reason many of these people want to deflate science stems from I think
an admirable desire to tolerate disagreement. They don't want to say that other views are
wrong. It seems disrespectful to go around pronouncing that other epistemic practices
are misguided. I think this embodies a serious confusion that is somewhat rampant in our
culture. It is important not to confuse toleration with a lowering of epistemic standards. A
quick story from the Counter-Reformation will I think bring out the point nicely. There's
an English philosopher of the time who made a stunning realization that he reported in
a letter to his friend. Now the Catholics were claiming that the Protestants were all
going to hell and the Protestants were claiming that the Catholics were all going to hell.
And this guy realized, he was a Protestant of course, being English at the time, that
the Catholic arguments from the Catholic standpoint looked every bit as good as the Protestant
arguments looked from the Protestant standpoint. He realized these were not crazy people, they
were perfectly rationally reasoning from their own premises. Does that lead to a stunning
display of tolerance? No, what the guy realized is, since their arguments look reasonable
to them, we can't reason with these people, we have to kill them. There's a big difference
between being tolerant and deciding that there's no fact of the matter about who's right. This
guy decided that there was no way rationally to convince the other side that they were
wrong. That doesn't automatically lead to tolerance. Nor does thinking that people who
disagree with you, when you've got say a well-tested scientific theory, are wrong. That doesn't
mean you have to be intolerant or a jerk to them. This way of trying to defend toleration
leads to relativism, to the view that, to a first approximation, it's objectively true
that nothing's objectively true, and that's a problem. We want to defend our toleration
on its own terms without muddying the epistemic waters by trying to say that there's no way
that science can be better than any other intellectual enterprise. The vices on the
other side are just about equally dangerous. People sympathetic to realism or to empiricism
hear other people scoffing at the idea of objectivity, and they get worked up because
they think science is being reduced to rhetoric or literature or something like that, and
they then want to valorize science, so they dismiss legitimate questions about whether
science is itself informed by values, whether there are any limits to what science can show
us. This leads to equally soft-headed thinking, the very kind of soft-headed thinking that
these supposedly hard-nosed thinkers were accusing the postmodernists and constructivists
of making. They start thinking that the problem of demarcation is no problem at all, and that
they know what a real science is, and real science clearly gets the world right in an
unproblematic way, and so they stop worrying about, say, the underdetermination of theory
by data, they stop worrying about the problem of induction, and that's just about equally
naive. As this dialectical process continues, each side tends to move towards more of a
caricature of itself, and this is what happened in the science wars of the 90s. This was the
most publicized, but also the ugliest display of thinking about science in recent decades.
This is an important tension to resolve. There are many notions worth calling objectivity
between these caricatures. Science does not just have the world imprinted on its, as it
were, collective mind, but nor is it just a literary genre.
Hopefully some of these intermediate conceptions of objectivity have come out in the abstract
as we started looking at various theories of evidence. The ways in which Coonian normal
science is constructed brings with it a certain kind of objectivity that gets built out of
some of these subjectivities and idiosyncrasies of individual scientists. Our thinking about
probability in statistics allows for reasonably refined views about what constitutes objectively
versus subjectively, scare quotes here, settling such questions. And also, as we've used some
examples from particular sciences, hopefully we have exemplars in the Coonian sense of
how questions can get settled in a way that's not dogmatic or naive about science having
direct access to reality, but nor is it excessively cynical and thinking that we've just
constructed thermodynamics or quantum mechanics to answer to political or other idiosyncratic
needs. It's highly important, I think, for us to have a realistic sense of the place
of science in our culture. Science deserves our respect. It should not be leveled down
to just another text or just an interpretation or just an expression of the interests of
those who have certain powers. But it does not deserve automatic deference. Philosophy
in general is supposed to provide a kind of manual for intellectual self-defense. And
so philosophy of science should help us look at claims made within science and claims made
about science, and can help us make informed judgments about how and what we're to think
about each case. As I said at the outset of this lecture, philosophy is hard. Science
is hard. Philosophy of science is doubly hard, which is part of why those of you who have
made it this far honestly, genuinely have my admiration. What do we get to show for
all of this hard work? Well, I haven't tried to answer many of these questions. I hope
we've come away more with clarity than with knowledge. We've come away knowing that there's
a balance of virtues to be struck, which is frustrating because we don't know exactly
how to strike it. But clarity is liberating. We become able to see things and to say things
that we couldn't have seen and couldn't have said. There's this emotional picture about
logic and rigor, according to which it's supposed to weigh us down. It's supposed to be a sort
of burden, a standard we struggle to meet as it were for its own sake. But Bertrand Russell,
I think, had it right when he suggests that drawing clear distinctions, logical rigor
is freeing because it shows us possibilities that have been there all along but that muddle
headedness prevents us from seeing. So what I hope you'll take from this course is an
ability to see and to think for yourself about the intellectual accomplishments of science
and the intellectual virtues of science so that you can appreciate what science offers
to us and deploy these intellectual virtues in your own life. So I'd like to thank anyone
who has made it through this, I think, difficult and demanding course and the people here at
the teaching company who have helped me deliver it.
We genuinely hope you've enjoyed these lectures from our great courses series. Our courses
are available to order online. Visit our website at www.teach12.com or call our customer care
representatives at 1-800-TEACH-12. That's 1-800-TEACH-12. Thank you very much.
