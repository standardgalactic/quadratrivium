We've seen over and over in this series that one, there is a lot of data to analyze and
two, a lot of insight can be gained from analyzing it.
Now it's time to talk about data privacy and security.
For example, online cookies can be placed on your computer to keep track of you.
A store might access your smartphone to track where you walk and what you buy.
Predictive analytics might determine what you are allowed to buy or at what price.
Risk factors from your medical data might be cross-referenced with other databases.
Medical cameras and stores in public places might study your every move.
In short, what data is being analyzed?
How difficult is it to keep data secure and what can be done to improve security?
These are our topics for this lecture.
Recently, I was grocery shopping in my hometown of Davidson, North Carolina.
I was carefully loading eggs and other groceries in my car when I got a text from a friend.
The text message said, I hope your grocery shopping went well.
I hope you didn't break those eggs.
I literally stopped cold in my tracks.
What?
Wait a minute.
The parking lot was almost empty and my friend was nowhere to be seen.
He knew I wouldn't see him.
First to the grocery store is a strip of offices.
He was on the second floor.
Honestly, I always forget that there even is a second floor to that building.
So I definitely wasn't looking there.
I was surprised because I thought I was quietly doing my own thing unnoticed by anyone.
I was surprised because I wasn't aware of other ways I could be watched.
I was surprised because I didn't know how closely I was being watched and I was surprised
because I didn't know that a digital message was being created about what I was doing.
As you may have guessed, this story motivates lessons for this lecture on security.
What if someone had been blogging about my shopping trip or posting a video about it?
So how secure is our privacy?
With so much data, we often have less privacy than we assume.
How much can really be gleaned and known?
Often quite a lot.
Major companies and governments are now very good at this.
Sometimes companies and government work together.
In 2014, familiar smartphone apps, including Google Maps, Facebook, and Angry Birds were
shown to reveal personal information in unexpected ways.
Not just to the companies, to the U.S. National Security Agency, as well as to the government
communication headquarters in Britain.
Let's see an example where a large organization wanted to assure that customers' personal
data remained private.
We've discussed the Netflix Prize in the lecture on recommendations.
Again, it was the million-dollar contest that challenged experts in data analysis to use
Netflix data to produce better recommendation than Netflix did.
Pretty big challenge.
But there was also a personal security angle to this.
Now, Netflix knew they were supplying personal data, so they made an effort to remove identity
and identifying information.
For the first Netflix Prize, they were successful.
A Netflix Prize was awarded, and for researchers like me, the competition was a wonderful push
forward academically.
A lot of new ideas were discussed and tested.
My own research team worked with the data.
It was a big, enriched data set, covering about 480,000 customers.
But when a second challenge was announced, Netflix got sued.
The lawsuit claimed that Netflix indirectly exposed the movie preferences by its users
by publishing user data, even though efforts had been made to remove identifying information
and make the users anonymous.
The initial data was out there, so it had already been analyzed by academics.
In the end, 50,000 contestants wound up participating.
It was the fact that so many people were pouring over the data that made privacy advocates
more worried.
Plain if, Paul Navarro and others sought an injunction to prevent Netflix from offering
that follow-up challenge.
Netflix wanted to take the recommendation challenge another step.
They promised to include even more personal data, such as genders and zip codes.
This could answer some fundamental questions.
Are there movies preferred by women, sometimes called chick flicks?
Maybe or maybe, as with other things we've learned in this series, that's simply folklore.
Maybe Netflix could get better at recommending a date movie, and maybe that depends on where
you live in the country.
Answers to these types of questions can be very powerful.
Just think about movies and people that you know.
There might be lots of interesting questions you could ask, and with enough data, interesting
answers could be possible.
That lawsuit was settled, and the sequel competition was canceled.
As a researcher, this is like seeing the trailer for a sequel to a movie that actually looks
better than the original movie, and then being told later that the sequel collapsed and won't
be shown.
It's like a cliffhanger with no resolution, ever.
It's relevant to note that Netflix was dealing with several interested parties.
The company's blog posted that Netflix also settled a negotiation with the Federal Trade
Commission.
Remember, Netflix released data having already thought about security.
They didn't propose to release additional data without any forethought about the issue.
So how could one possibly figure out someone's identity in the ratings data when Netflix believed
such information had been removed?
One way is with other data.
For example, two privacy researchers showed comments on another site, such as the popular
Internet Movie Database, could help triangulate the identity of an anonymous Netflix customer.
The dates for posting on both sites were often virtually the same.
This made it easy to match identities from one database with the other.
Now, there are ways people propose that the data could have been masked.
The technique called data masking can randomize the data, making it even harder to trace an
identity back to any specific person.
Such additional precautions might have been allowed in that second Netflix challenge to
go forward.
But the fundamental issue remains.
How secure is secure?
And when do you know?
And when does your privacy or security actually change without you knowing?
For that, let's see another example from another Internet giant, Facebook.
Now clearly, it is in Facebook's interest to keep information secure, but it is also
in Facebook's interest for users to share as much information as possible.
In 2007, Facebook released a new feature called Beacon.
It was created to enhance how people share information with their friends about things
they do on the web.
Facebook benefits when users share more information with potential monetary value.
So Facebook was very excited with this new feature.
But problems were discovered.
A security researcher sounded an alarm, indicating that the online ad system went much further
than anyone had imagined in tracking people's web activities outside the popular social
networking site.
Beacon reported back to Facebook on members' activities on third-party sites that participated
in Beacon, even if the users were logged off from Facebook and even if they declined having
their activities broadcast to their Facebook friends.
In fact, users wouldn't even know this was happening or be given the option to block
it.
Beacon tracked certain activities of Facebook users on more than 40 participating websites,
such as Blockbuster and Fandango.
Then that user's Facebook friends were notified.
For instance, you might know I bought something, kind of like my friend seeing me with the
eggs.
But now lots of people could see it on Facebook, not just one person seeing me in a parking
lot, just because he happened to be nearby.
There was much negative buzz about this emerging news.
In an online posting, Mark Zuckerberg, founder of Facebook, wrote later in 2007, quote, about
a month ago we released a new feature called Beacon to try to help people share information
with friends.
Less than two years later, Beacon became defunct.
This time Zuckerberg wrote, quote, we were excited about Beacon because we believe a
lot of information people want to share isn't on Facebook.
And if we found the right balance, Beacon would give people an easy and controlled way
to share more of that information with their friends.
But we missed the right balance.
In the end, there was a $9.5 million settlement in a class action lawsuit against Facebook.
The money?
It set up a not-for-profit group that addresses online privacy rights.
So here we see two very, very costly mistakes in privacy.
Both Netflix and Facebook would have been aware of privacy concerns about these projects.
But their projects did not have privacy as a primary objective.
And they did end up having trouble, in both cases, costing them millions.
There is another lesson.
Notice how an outside researcher blew the whistle and shared what was happening.
Without that, we wouldn't necessarily have known.
And in both cases, the U.S. Federal Trade Commission also got involved in an effort to
establish clearer rules about privacy online.
Facebook actually faced formal complaints on eight counts, one of which was the Beacon
Project.
And the day those complaints were settled in November 2011 was the same day that Facebook
CEO Mark Zuckerberg went online to write that the company had made, quote, high-profile
mistakes.
Not only with Beacon in 2007, but also in December 2009.
That was when Facebook temporarily dropped some privacy controls from its website.
Certain information that users designated as private, such as the friends list, was
suddenly made public without approval from users, or even a warning.
And these aren't the only such cases.
Google reached a 2010 settlement over a neglect of privacy by its defunct social service,
Google Buzz.
That settlement included agreeing to transfer 8.5 million to privacy groups.
There are other issues, too.
For example, the privacy of children is becoming more complicated.
I have a friend who never posts pictures of his children, even on Facebook.
That worked for a while, but now his kids are in elementary school.
They go on trips with friends and go to birthday parties.
Now his kids appear in other people's Facebook feeds.
So it is also getting harder to conceal a romantic relationship.
Consider the recent research by Facebook social scientist Lars Backstrom and Cornell University
professor John Kleinberg.
They found that your partner or spouse can be revealed simply based on your network of
Facebook friends.
If you've been married a long time, this may or may not seem surprising.
You might guess this has to do with the number of friends a couple share in common.
But that approach won't necessarily find your partner or spouse.
It may be that you share the most friends with a college buddy.
In their study, only about 25% of relationships could be identified based on mutual friends.
Instead, partners are more likely to overlap across many more separate groups.
Think of a huge birthday party.
When you turn 40, 50, or 60, one of your closest friends may not know your work friends, college
friends, neighbors, and so forth.
Your spouse is much more likely to know those friends, and in the case of Facebook, be connected
to them too.
Why is Facebook so eager to know so much about you?
The more Facebook knows, the more it can produce better, more relevant results for you.
It can show you information about those it deems are most important to you, simply by
knowing who is connected to whom.
Facebook and other companies are likely to know more about you than you intended.
In December 2013, Amazon obtained a patent for anticipatory shipping.
This means Amazon can analyze what you are likely to buy and hold those predicted orders
at a shipping hub or on trucks until you actually place the order.
But incursions by large companies, actual or potential, can seem small or harmless when
compared with the vast and unexpected reach of the U.S. National Security Agency.
Revelations during 2013 by a former technical contractor for the NSA, Edward Snowden, leaked
sensitive documents.
A vast system of government monitoring and archiving from phone lines and online services
was unveiled.
Snowden made it harder for the U.S. government to spy on U.S. citizens and other law-abiding
people.
This led some to say he should be protected like a corporate whistleblower.
To others, he was a villain.
He broke the law.
He made it harder to block cyber attacks from other countries.
He made it harder to catch terrorists.
There are two security issues here.
First, the security of the U.S. government information was breached by those leaked documents.
Second, the revelations showed how readily the security and privacy of information about
individual U.S. citizens could be breached.
Calls by U.S. citizens were revealed to have been recorded and stored in a vast database.
The U.S. government defended the program as court supervised in a powerful tool that
thwarted terrorist attacks in protected citizens.
Let's look at this from a government perspective.
My own experience with the government security has been at Los Alamos National Lab in Lawrence
Livermore National Lab.
I had security clearance to work at those labs.
But my security clearance was at a lower level.
I attended meetings where a portion of the meeting was determined, was spent determining
if I could be in the rest of the meeting.
In high security settings, you can be trusted and at the same time, not trusted.
The same approach applies to allied countries.
Disclosures have revealed how numerous high-profile G20 countries were assisting the U.S. government
in its intelligence-gathering efforts.
At the same time, those same countries also saw that their own leaders and citizens had
fallen under the same surveillance techniques.
Part of what has made the new surveillance techniques so powerful was the ability to
analyze previously neglected data in new ways.
Some of the basic advances have been published in scientific journals.
In a 2012 study published in Nature, it's reported that just four data points about
the location and time of mobile phone calls were needed to identify a specific caller
95 percent of the time.
Only four pieces of information about where you are and when you were there become sufficient
to identify who you are.
These debates underscore two very different opinions people have about security, how it
is implemented, and what makes sense.
On one hand, the security of government information can be essential to the defense of the nation.
On the other hand, the security of personal information against unreasonable search can
be an initial value, an essential value of the nation.
Then Obama said, quote, what's really at stake is how we remain true to who we are in a world
that is remaking itself at dizzying speed.
We can expect to see at least three big practical consequences from these disclosures.
First, organizations are rethinking how to effectively encrypt their most sensitive data.
Second, international organizations consider doing less business with U.S. companies, since
the NSA has methods and even agreements to see the data of U.S. companies.
Also, at least until this time, much of the world internet traffic has been routed through
the United States because the infrastructure has been both cheaper and more abundant.
Third, many organizations are more hesitant to put their data on what was the fast-moving
field of cloud computing.
We can also expect further disclosures.
NSA and other organizations can sometimes install and use covert radio wave technology
to spy on computers that are not on the internet.
Companies with wireless technology can be secretly accessed from increasingly remote
distances.
So, be careful if it seems like security is only a national issue or is only related
to how businesses like Netflix or Facebook implement or share their data.
Security is an issue for everyone.
Let's consider passwords.
What online programs or software or websites do you use that require a password?
Twitter and Facebook accounts have passwords, banks and insurance sites have passwords.
You probably enter a password word to log into a computer and access email.
Your password is a place to think security.
It is the gateway to many forms of information about you.
And with data, as we've seen again and again, comes power in possible predictive abilities.
So, how many passwords are there?
Well, let's assume a password must be 7 characters long, is case sensitive and can be any letter
or digit.
Then for each space you have 62 choices, 26 lower case letters, 26 uppercase letters
and 10 digits.
If you assume you must have a letter to begin and then can pick any of the other options,
you have close to 3 trillion options.
That's a lot of options.
Things grow a lot if you keep adding to the length of that password.
So really, that's pretty secure.
At least until you come to the passwords a lot of people choose.
IT security consultant Mark Burnett collected and analyzed over 6 million passwords.
Listen to his hit list of top 5 passwords.
Number 1, password, number 2, 1, 2, 3, 4, 5, 6, number 3, 1, 2, 3, 4, 5, 6, 7, 8, number
4, 1, 2, 3, 4, number 5, QWERTY.
OK, but how frequent is frequent here?
Is the most found password really all that prevalent?
Burnett found almost 5% of users had password as their password.
8.5% had password or 1, 2, 3, 4, 5, 6.
10% of the top had the top 3.
Password or 1, 2, 3, 4, 5, 6, or 1, 2, 3, 4, 5, 6, 7, 8.
14% had one of the top 10 passwords.
40% had one of the top 100 passwords.
79% had one of the top 500 passwords.
And 91% had a password from the top 1,000 passwords.
So think about this.
Out of 6 million collected passwords, over 91% of them
were from a list of just 1,000.
Now, does that sound very secure?
Animals, sports, personal names, and even expletives
are among the most common.
The phrase, let me in, was number 11 on the list.
Changing passwords frequently doesn't
help much, at least not if the password is short or common.
Better is to have a long password, the longer the better.
Experts like Burnett often advise
the use of non-standard spellings, including capital letters
in non-standard ways, also non-letters.
But even a long password does no good if given away.
That's why phishing for passwords is so common.
Spies from China and around the world
create increasingly elaborate deceptions
to try to gain access to passwords.
This more targeted form of phishing
is sometimes called spear phishing.
Similarly, malware goes hunting for passwords
once it gets installed.
So of course, it's a really bad idea
to use the same password across more than one account.
Not all organizations have equally good security.
If your one and only password gets compromised anywhere,
then you've just allowed it to be compromised everywhere.
Passwords are often like keys to the kingdom.
Edward Snowden needed password access,
without which none of his NSA disclosures
would have been possible.
Conversely, Snowden himself reportedly
used, quote, a large red hood over his head in laptop
when entering his passwords to prevent any hidden cameras
from detecting them.
Passwords employ a much more general approach toward data.
At many levels, we want data available.
We've seen surprising results.
And in the end, learn something new thanks to a data analysis
that saw something that we otherwise could not.
We want a rich set of ingredients
available for our computational laboratory.
But again, that data is often about us, our society,
our companies, our families, even our most personal details.
So we want it to also be secure.
Let's look at how companies, and especially the government,
make their data more secure.
First, keep outsiders out.
For example, when I worked at the national labs,
I couldn't play streamed music.
At least at the time, this could open the lab up for an attack.
I could play music from my laptop,
but not over an internet radio station.
Also, smartphones are more vulnerable than commonly
believed.
As President Obama once said, quote,
there is a reason why blackberries and iPhones
are not allowed in the White House situation room.
Those devices are not secure, and the US government knows it.
Second, keep inside things inside.
All the codes I developed at the national labs
stayed on their computers.
What I wrote at the national labs stayed at the national labs.
But they did want me to continue to develop them remotely.
So I could log on.
But they need to be sure the login is secure.
So I used a virtual private network or VPN connection.
VPN extends a private network across a public network,
such as the internet.
Using VPN, you can send and receive data
across shared or public networks as if it
were directly connected to the private network.
If you log in to work from home or while traveling,
you are probably using a VPN connection.
Businesses use VPNs to connect to remote data centers.
People who are very concerned about privacy
sometimes use a VPN to connect to a proxy server,
often in another country, so their presence on the web
can be anonymous.
Most laptops and smartphones have the ability
to run their own VPN.
And this is something far more people
could have taken advantage of.
A VPN might be especially good to set up, for example,
if you often log in at coffee shops
in other insecure hot spots.
Places like the national labs, in any case,
want and need connections even more secure
than an ordinary VPN.
So in addition to the normal VPN remote login,
there was also one more step when I worked there.
I had a little device called a token
that created a one-time password.
So when I logged on, I input my password
and then appended onto the end another six digits
that I saw on my token.
The security token changed every minute or so
with a new six digits.
The random numbers on my token were changing
at the same rate as the one at the lab.
So the lab knew at any moment what numbers
I was seeing on my token.
And that kept my password especially secure.
There is a lot of interest in how to increase
the privacy and security of specific databases.
One approach is more use of cryptography.
What works for passwords can be extended to databases
even to the creation of encrypted data.
The technology of HTTPS,
which is used to make commercial websites secure,
can be extended to many other kinds of websites.
Another approach is called differential privacy.
This can be thought of as aiming to solve
the Netflix prize problem
by adding increments of noise to a database.
Work on this has been supported partly by Microsoft.
The idea here is not so much to hide
the information entirely.
Instead, the idea is to mask just enough
so that a data set can be used freely
without revealing sensitive data.
Should the government have more data available
to help fight crime, espionage, or terrorism?
How much data should businesses share
with each other or the government?
How much should business or government
share with the rest of us?
In 2014, President Obama announced a comprehensive review
of big data and privacy.
Announced changes in government policy were to include,
find an alternative to storing bulk data
about citizen phone calls and emails.
Look for terrorists using two degrees of separation
from a member of a terrorist network
instead of three degrees.
Extend to citizens in other countries,
some of the protections previously offered
only to US citizens.
Remember though, even if we make up our minds about this,
even if we know what we want,
we can be going along thinking the data is secure,
but it may not be.
We will continue to see disclosures in the news,
stories revealing data that was suddenly found
to be insecure.
This can be like my trip to the grocery store.
Be careful thinking you are doing things
that won't be noticed.
If you are sharing digital data, it might be visible.
In fact, somewhere your digital data almost certainly
is visible, at least potentially.
So we live in a digital world and it is hard
and maybe impossible at times to live
without any digital footprint.
In fact, most of this course focuses on the advantage
of having a digital footprint.
Still, there are limits on what should be seen
and who should see it.
So these are all not easy issues.
These days, who you are in a new and important sense
is partly defined by where you stand on privacy.
