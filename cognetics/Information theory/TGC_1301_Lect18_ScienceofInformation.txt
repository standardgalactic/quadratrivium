John Kelly, like so many pioneers of the science of information, was an engineer at Bell Labs.
In the 1950s he had the reputation of being the second most brilliant person there after
Claude Shannon himself.
The two knew each other, though they worked in different divisions.
They weren't much alike.
Shannon was a quiet midwesterner who loved to think and tinker on his own.
Kelly was an outgoing Texan, a bridge player and a gun enthusiast.
So perhaps it's fitting that it was John Kelly who taught us to look at information
theory in a new and entirely different way.
For Shannon information theory was about codes and messages, for Kelly it's all about gambling.
The relation he found between Shannon's theory and making bets opens one of the most controversial
chapters in the science of information.
As we will see, the same concepts developed to describe communication, concepts we have
used to explore cryptography, biology and thermodynamics, also have a financial side
with applications from Vegas to Wall Street.
So let's start with a horse race.
And in the spirit of information theory it's a binary horse race.
Two horses, X and Y, are at the starting gate.
We want to put a little money on the outcome of the race.
But first we need to know the odds.
Odds can be confusing.
They are used for different things and expressed in different ways.
What are the odds for horse X to win?
That question might mean two different things.
It might be asking the likelihood that horse X will win.
Those are statistical or probability odds.
We won't talk much about those.
We already have a way of describing probability.
Probability.
We can just say that the probability that horse X wins is one-fifth or .2 or 20%.
Where do we get this probability?
We make our own judgment based on our own knowledge, our information.
Someone with different information might assign different probabilities.
The second meaning of odds relates to how much money a bet on horse X would pay out
if X wins.
These are betting odds.
They are the ones we need.
Betting odds are set by the bookmaker, whoever is offering the bet.
And they are quoted in a couple of different ways.
Most people are familiar with the old British system.
Using this we say that horse X has four to one odds.
This means that on a $1 bet, if X wins, then we are paid $4, but if X loses, we must pay
$1.
A somewhat more modern system widely used in Europe employs decimal odds.
The same odds on horse X would be quoted as odds of five, or 5.0.
The idea is that we first buy a bet for $1.
If we win, we are paid $5, which we can think of as our original $1 plus $4 more.
Decimal odds are better for our purposes, so we'll use them.
We'll call the decimal odds for horse X O of X.
If we make a $1 bet on horse X and we win, then we get paid O of X dollars.
Betting odds do have a connection to probability, of course.
If O of X equals $100, the bookmaker must estimate that horse X is unlikely to win.
It's a long shot.
If the odds are short, O of X not much more than one, the bookmaker must think horse X
is very likely to be the winner.
The bookmaker's odds are an expression of his probabilities based on his information.
There is an ideal mathematical relationship here.
If Q of X is the bookmaker's probability that horse X wins, the ideal decimal odds
for X is just the reciprocal of Q of X. O of X equals one over Q of X. I should add
that you will never get odds this good at a real bookmaker.
He will quote lower odds offering a lower payoff because he wants to make a profit.
For now, we'll assume ideal odds.
To keep things simple, we will suppose that the odds are even in our binary horse race.
The bookmaker thinks each horse is equally likely to win.
Q of X and Q of Y are both one-half and each has decimal odds of two.
A $1 bet on either horse, if successful, yields $2.
We might not agree with the bookmaker's probabilities.
We might possess information that he lacks, that's called side information.
In plain terms, we might have received a tip.
Based on the tip, perhaps we think that horse X is more likely to win.
So how much information is actually in a tip?
It's a question we can answer based on Shannon's theory.
For the bookmaker without the tip, each of the two horses is equally likely to win.
His entropy, the information he lacks about the race, is one bit.
That's his average surprise about the winner.
But we do have the tip, and it causes us to modify our probabilities.
We now assign P of X to horse X, and P of Y to horse Y.
If the tip actually tells us for sure which horse will win, then it carries one bit of
information.
But the tip might not be quite so informative.
After we receive the tip, the information we lack is the entropy H, the average surprise
based on our new probabilities.
So initially, like the bookmaker, we lack one bit of information, and after the tip,
we lack H bits of information.
Therefore the tip has conveyed one minus H bits of information.
In the language of Lecture 7, the tip is like a noisy communication channel.
Our residual uncertainty about the race is the noise.
If R is the race result, and T is the tip, then H of R is the original entropy, one bit.
H of R given T is the conditional entropy of the result given the tip.
That's H. I of R and T, or just I, the mutual information, is the amount of information
the tip gives us about the race results, and that equals the difference between the two
entropies, or one minus H.
Before we move on, I want to remind you of one more fact.
From the bookmaker's probabilities, Q of X and Q of Y, we can calculate the bookmaker's
surprise for each of the horses.
Surprise of course is log 2 of the reciprocal of the probability, or log 2 of 1 over Q of
X, and log 2 of 1 over Q of Y.
We know more than the bookmaker.
We have the right probabilities, P of X and P of Y.
So the bookmaker is more surprised on average than we are.
Mathematically, H is less than or equal to the sum of the P's times the logs of the
reciprocals of the Q's.
We call this fact the information inequality, and we'll need it in about 10 minutes.
The inequality becomes an equation only when the Q's are exactly the same as the P's.
So back to horse racing.
John Kelly imagined a series of identical races, one after the other.
In each, the bookmaker's decimal odds are two on each horse.
For each race, we get a tip that leads us to adjust our probabilities.
Without the tips, we would not expect to win any money in the long run.
We'd win about as often as we lost, but since each win pays $2 on a $1 bet, we'd come
out even.
With the tip information, we can hope to win more often than we lose, thus we can hope
to come out ahead.
So Kelly asked two fundamental questions.
First, what is the best betting strategy in the long run?
Second, what payoff can we expect in the long run from that strategy?
We could just make a series of $1 bets, that would pay a reasonably steady income with
some ups and downs.
Roughly speaking, our wealth would increase linearly at a constant rate.
But once we have accumulated some wealth, those tiny $1 bets don't make sense.
Why play for such small stakes?
We should increase our bets, and therefore increase our returns as our own wealth grows.
And if we do that, the long term growth of our wealth should be exponential.
There's an old story that Albert Einstein was asked to name the most powerful force
in the universe, and he replied, compound interest.
Anyone who has watched an investment or a debt grow over a period of years will appreciate
the remark, and that's the force that Kelly sought to harness.
So consider the mathematics of compound interest.
We start by investing a certain amount of money, A. Over a period of time, a year, say,
the value of the investment increases by a growth factor, G. A becomes G times A. We
often express this as a percentage, like 25% growth.
That means G equals 1.25.
Now a growth factor less than 1 means we lose money.
That is, of course, quite possible.
After another year, we multiply by another factor of G. Now we have G times G times A,
or G squared times A. Year by year, our money grows by a factor of G. A, G A, G squared
A, G cubed A, and so on.
So if we start with $100 and have an annual growth factor of 1.25, that gives us $100,
$125, $156, $195, $244, and so on.
The key point about compound interest is that the growth factors multiply together.
The overall factor for four years is G to the fourth power.
The number of years that have passed appears in the exponent of G. That's why mathematicians
call this exponential growth.
And now we can answer questions like this, which would be better in the long run, an
investment of $10 that grows at 10% per year, or an investment of $1 that grows at 20%
per year.
The growth factors in the two cases are 1.10 and 1.20.
We can use those to calculate the overall growth factors for years into the future.
When we find that after 30 years, the 20% growth factor is more in absolute terms, even
though it started out much smaller.
In the long run, the larger growth rate always wins, no matter how things start out.
But that is a statement about the long run.
Practically speaking, of course, 30 years might be too long to wait.
Kelly's repeated horse race is like that.
He wants to maximize the growth factor of his horse race investment.
But the growth factor varies because the same horses don't always win the race.
That's like an investment in which we get G1 the first year, G2 the second year, and
so on.
A becomes G1 times A, then G2 times G1 times A, etc.
The G's aren't all the same.
Some of them are probably less than one.
So let's take an easy example.
In year one, our growth rate is minus 50%.
We lost half our money.
The growth factor G1 is 0.5.
But in year two, our growth rate is 100%.
Our money doubled.
The growth factor G2 is 2.0.
Overall then, we broke even.
G2 times G1 equals 1.0.
So here's a question.
What is the equivalent annual growth rate?
What steady growth factor G for two years would yield the same net return?
The answer is obvious.
But it is not the average of the G's.
If we average 0.5 and 2.0, we get 1.25, which is wrong.
That's too big.
What we really need is what mathematicians call the geometric mean.
For two numbers, that's the square root of their product.
In our example, that formula gives 1.0, which is the correct annual growth factor.
If we do this for a series of in-years, or in-horse races, then the geometric mean is
the product of all the G's raised to the 1 over in power.
That's the steady growth rate that gives the same overall return.
Now the same equation looks quite different if we take its logarithm.
We need to call to mind two logarithm facts.
First, if we multiply numbers together, their logarithms add up.
Log 2 of x times y equals log 2 of x plus log 2 of y.
That product of growth factors turns into the sum of their logarithms.
Second, if we raise a number to a power, that just multiplies the logarithm by that power.
Log 2 of x to the p equals p times log 2 of x.
Putting it all together, we get a formula for the logarithm of the equivalent steady growth rate.
Now the log of G is the ordinary average of the logs of the growth rates.
That's really what the geometric mean, means, written in logarithm language.
So Kelly says we should choose our betting strategy to maximize log 2 of G.
That will give us the best long term growth rate for our money.
So how do we do it?
Well, even if we think that horse x is more likely to win, we must not bet all our money
on x.
That's because horse x might lose.
In the long run, horse x is sure to lose eventually.
When that happens, the growth factor for that race is zero.
We go broke.
We can't make any more bets.
So the overall growth factor, the product of the factors for all the races, is also zero.
That's called the gambler's ruin, and we need to avoid it.
We could do that in two different ways.
One way would be not to bet some money, keep it in our pockets, just to be safe.
The other way is to hedge our bets.
That means we bet some money on each horse.
One of them is sure to win so we can never get completely wiped out.
And it turns out that since our ideal bookmaker is offering ideal odds, those two different
ways are exactly equivalent.
There is no real difference.
So we will assume that we always bet all of our money.
We just divide it somehow among the horses.
We bet a fraction B of x of our wealth on horse x and a fraction B of y on horse y.
The two fractions add up to one, like a probability.
Our job is to figure out how to choose B of x and B of y to make log 2 of g biggest.
So suppose horse x wins.
We bet a fraction B of x on that horse and won back $2 for every dollar we bet.
The money we bet on horse y is lost.
Therefore our growth factor when x wins is 2 times B of x, and when y wins the growth
factor is 2 times B of y.
Now after many many horse races, any of them, the two horses have each one sum.
X has one about n times P of x races, and y has one about n times P of y races.
Remember our equation for log 2 of g.
In that sum, a certain number of the terms n times P of x of them will be races that
x wins.
The rest will be races that y wins.
And that simplifies things.
That number n, the number of races divides out.
It's gone.
Also, we can separate each logarithm into the sum of two logarithms.
Log 2 of 2 equals 1, and P of x plus P of y is also 1.
Therefore log 2 of g is just 1 plus the sum of the P's times the logs of the B's.
Now we can rewrite this in a clever way, remembering that log 2B is just minus log 2 of 1 over
B.
Now finally we get to the punchline.
The subtracted off part in parentheses is like an average surprise.
But it is the average surprise of someone who believes that our betting fractions B
of x and B of y are actually the probabilities for the horses to win.
Their average surprise is always greater than h, the entropy of the actual probabilities
of P's.
That, you'll remember, is the information inequality.
We want to make the subtracted part as small as possible to make log 2 of g big, and that
average surprise could be made as small as h, if the B's equal the P's.
So now we have the answer to Kelly's two questions.
First, how should we bet?
To make log 2 of g as large as possible, we should choose betting fractions B equal to
the probabilities P for the horse.
So Kelly tells us that if horse x has a 75% chance to win, then we should bet 75% of our
money on x, and hedge our bet by putting the other 25% on y.
That's the best strategy in the long run.
Second, what payoff can we expect?
That's determined by g, the growth factor for our wealth, per horse race.
When we choose the best strategy, the log of the growth factor is just 1 minus h.
But 1 minus h is exactly the amount of information in the race tip.
We call that i, the mutual information.
Log 2 of g equals i, or in exponential form, g equals 2 to the i-th power.
Kelly's relation between log 2 of g and the information i is astounding.
It gives us an entirely new way to think about information.
At the beginning of this course, we defined information as the ability to distinguish
between possible alternatives.
For Kelly, information is the advantage we have in betting on possible alternatives.
Every additional bit of information doubles our long-term advantage.
So let's see how it works in a couple of easy cases.
Suppose the tip gives us no information, then i equals 0.
After the tip, we still have an entropy h of 1 bit.
We are as uncertain about the winner as we were before.
The best we can do is divide our bets equally between the horses.
Since we always win one of the bets, we get our money back, but no more than that.
The growth factor g equals 1, so log 2 of g is 0, just as Kelly's formula tells us.
If the tip tells us everything about which horse will win, i equals 1 bit, h is 0.
We should therefore bet everything on the sure winner.
We will double our money each time, so g is equal to 2, which means log 2 of g is 1, and
that also agrees with Kelly's formula.
So now suppose that our tip only tells us all little.
After we get it, we estimate that one horse has 75% chance of winning and the other 25%.
That's how we'll allocate our bets.
The new probabilities yield an entropy h equal to 0.81 bits, which means that the tip only
gave us 0.19 bits of side information, doesn't sound like much.
According to Kelly, we can make this equal to log 2 of g.
So the gain factor g is 2 to the 0.19 or 1.14, which means in the long run we expect to increase
our wealth about 14% per horse race, even a pretty poor tip can help.
We've explained Kelly's discovery using a simple example, but his 1956 paper analyzed
other situations as well.
For instance, suppose the bookmakers odds are different.
If the bookmakers probabilities favor horse x over horse y, then horse x will be given
lower odds, even in the ideal case.
How should we take these new betting odds into account in placing our bets?
Kelly's answer is startling.
We should ignore the odds.
The fraction of our wealth that we should bet on x is p of x, our probability, whatever
the odds.
We always bet, according to our information, about the result.
The change in the bookmakers odds does affect the payoff, but Kelly's relation between
information and growth remains.
Every additional bit of information we obtain doubles our long term gain.
Kelly also considered the situation where the bookmaker does not offer ideal odds.
He reduces them a little to give himself an edge so that he can make a profit.
Our strategy is now more complicated.
It might be that some part of our money should be kept in cash rather than wagered.
Although we may not wish to bet on every horse, and if the odds are bad enough, it
may even be better not to bet at all.
In any case, Kelly's information theoretic analysis tells us how we should bet to maximize
log 2 of g.
It also tells us how much each bit of side information is worth.
Kelly's idea of maximizing the log 2 of g is called a log optimal strategy.
It's the one that ensures the greatest growth in the long run, and it's the one that is
connected to Shannon's information.
If you follow a Kelly log optimal strategy, you will never go broke because you never
bet everything on any horse that can lose, but you may be in for a wild ride.
A string of good luck can increase your wealth by a huge factor.
That's exciting.
A string of bad luck can also decrease your wealth by a huge factor.
That's alarming.
Not everyone has the nerve to play a log optimal strategy consistently.
Many gamblers use a half Kelly approach instead, which only bets half as much as Kelly advises.
In our horse race example, you'd keep half your wealth in cash each time and bet the
rest.
The gain factor G is less, but the ups and downs are much reduced.
Furthermore, the whole strategy depends on having some side information, that is, on
knowing something that the bookmaker does not.
We've assumed the long term statistics are more like our predictions than his.
In a lot of gambling, the betting odds are set by a paramutual system.
The odds on a horse are set by the total amount of money that people are willing to bet on
that horse.
And that means that paramutual odds represent a pooling of information from a lot of people,
including some people who are very well informed, that makes paramutual odds hard to beat.
Even after Kelly's 1956 paper, Claude Shannon moved to MIT.
And there, though he never published any papers on the subject, he quietly pondered Kelly's
ideas.
Experiments in his own workshop convinced him that roulette wheels had subtle biases.
Careful timing could provide enough side information to make the game profitable, that is, to make
log 2 of G positive.
So with his friend Ed Thorpe, he built a wearable computer that they could sneak into
a casino under their clothing.
They could feed timing data into the computer by tapping a button, and calculations were
reported in an earpiece.
But the technology was finicky, and the Las Vegas field test was only a limited success.
Shannon then began to think about the stock market.
He had never cared much about great wealth, but he found it an interesting problem.
And in 1966 he gave a seminar talk about his ideas at MIT.
It was an occasion still remembered today.
Hundreds of people came.
They had to move the talk to a larger auditorium.
What Shannon was doing was following Kelly's lead, devising a log-optimal investment strategy
using the mathematical tools of information theory.
Of course, the stock market is not quite like a horse race.
In the stock market, stocks go up and down in value, usually by a few percentage points.
In a horse race, one horse pays off big, bets on the others are dead losses.
Thomas Kovar, an information theorist at Stanford, used to say that a horse race is the worst
possible kind of stock market.
Today, you have shares of IBM, Apple, Google, Coca-Cola, tomorrow, all but one of them will
be worthless.
Nevertheless, a lot of the basic ideas do carry over.
Shannon himself did quite well with his personal stock portfolio in the 60s, 70s and 80s.
His effective annual gain factor, G, was better than 1.2.
And over time, the log-optimal Kelly strategy has gained a number of passionate adherents.
But it has also gained some bitter critics.
The most eminent of these was Paul Samuelson of MIT, probably the most accomplished and
influential mathematical economist of his day.
He was the first American to win the Nobel Memorial Prize in Economic Theory in 1970.
Now, Samuelson had been friends with Shannon in the late 1950s, but that did not keep him
from writing truly scorching critiques of the log-optimal idea.
He called it a fallacy and regarded its proponents as little better than crackpots.
Even in the long run, he said, the Kelly strategy made no sense.
He wrote letters and technical papers against it.
And finally, Samuelson wrote an article for the Journal of Banking and Finance explaining
exactly what was wrong in words of one syllable.
The paper is called Why We Should Not Make Mean Log of Wealth Big, Though Years to Act
Are Long.
Samuelson did not disagree with Kelly's mathematics.
He just disagreed that the math expressed a realistic view of the relationship between
people and money.
First, Kelly's strategy is only optimal in the long run, but the long run might be
very long indeed.
For any given finite amount of time, the log-optimal strategy exposes the investor to the possibility
of very big losses.
It is what they call an aggressive strategy.
To maximize the gain factor, the strategy accepts a lot of risk.
You can't actually go broke, but you can get hit pretty hard.
As Samuelson put it in his one syllable paper, when you lose, and you sure can lose, within
large, you lose real big.
The point about risk brings up an even more basic point.
Samuelson said that the log-optimal strategy ignored the way that people actually value
money.
If I have $100, then $10 extra seems like a lot.
If I have $100,000, that same $10 is not such a big deal.
So the relation between money and value can be complicated.
What we really seek to increase in our lives is value, the things that we value, following
our own idiosyncratic concept of value.
According to Samuelson, the problem with theories based on quote, information of the Shannon
type, unquote, is that they make an implicit assumption about the way money is to be valued.
That assumption, however, does not match the way that people actually behave.
Most people are very willing to trade future money, long-term gain, for security.
They are happy to avoid big financial risks.
And it's no good saying that people are wrong to avoid those risks.
After all, money has no value, except the value that people actually place on it.
So Samuelson's critique was in fact pretty devastating, particularly among economists.
Not many of them take the log-optimal strategy very seriously.
Nevertheless, the Kelly idea has never gone away.
It is still a popular theory among information theorists and mathematicians.
It is a very cool idea, and it does lead to some startling insights.
Tom Kovar of Stanford, for instance, used information theory to study the problem of
the optimum stock portfolio.
How should we use the information we have to apportion our wealth among different investments?
And how should we use new information to adjust the portfolio over time?
Never found that this problem was related to the problem of data compression, which
we described back in lecture five.
Mathematical tools for one problem may be applied to the other.
A number of Wall Street firms and individuals use Kelly's ideas in their own strategies.
The famous investor Warren Buffett, CEO of Berkshire Hathaway, is reported to be one
of them.
And these days there are a lot of information theorists and mathematicians making interesting
new careers in the financial industry.
I do not recommend John Kelly's logoptimal strategy, either for your gambling or for
your investments.
Paul Samuelson, after all, has a point.
On the other hand, the work of Kelly and his successors has really illuminated information
theory in a new way.
Mathematically, Shannon's information is all about logarithms.
But logarithms are exponents, like the exponents in compound interest.
By taking the exponential view of Shannon's theory, Kelly has given us yet another example
of the surprising scope of the science of information.
