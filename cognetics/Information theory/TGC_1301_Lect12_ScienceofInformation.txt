In 1943, during World War II, Claude Shannon was called upon to evaluate the security of
the encrypted telephone link that allowed Franklin Roosevelt and Winston Churchill to
confer in secret across the Atlantic Ocean.
That system, codenamed SIG Sally, was the first ever designed to protect the privacy
of that kind of electronic communication.
You can see a display of the SIG Sally apparatus, actually about one third of the whole thing,
which was enormous, at the National Cryptologic Museum outside of Washington.
It was an amazing technological achievement for its day.
There is how it worked.
To begin with, SIG Sally was the first telephone system to convert analog voice signals into
digital information using a technique called pulse code modulation.
The digital signal amounted to a highly compressed version of the original voice data.
That was important for two reasons.
First, it required less bandwidth to transmit the compressed data.
Second, and more importantly, the compressed voice data had much less redundancy than the
original voice data.
As we've seen, cryptanalysis relies on that redundancy, so reducing it makes the eavesdropper's
job harder.
The real secrecy of SIG Sally came from the cryptographic key.
The key was a pair of identical phonograph records, one at the transmitting station and
one at the receiving station.
Each record contained random electronic noise, the exact same noise on each.
Before the SIG Sally voice data was transmitted, it was added to the random noise from the
record.
At the other end, the same noise was subtracted from the received signal, yielding the original.
That in turn was decompressed and turned into a recognizable, understandable telephone voice.
The two key records, thousands of miles apart, had to be synchronized to within a few milliseconds
so that the same noise was added and subtracted.
Also, each record contained only enough key noise for about 12 minutes of conversation,
so a second pair of records had to be ready to start up on different turntables in case
the call went longer.
Shannon concluded that the SIG Sally system was indeed secure.
Here is his analysis in a nutshell.
The enemy can intercept only what is actually transmitted.
The combined signal, voice data plus random noise, that's the ciphertext.
But the enemy knows nothing about the contents of the noise record, the key.
Therefore any voice transmission whatsoever is consistent with what the enemy learns.
The phone conversation might contain military plans, chit chat about the weather, baseball
results, anything.
For any plain text voice data, there exists a possible key, a possible pair of noise records
that would make it look just like the received ciphertext signals.
Therefore the eavesdropping enemy learns nothing.
The system is secure.
Indeed during the war, German technicians at listening posts recorded many of the SIG
Sally transmissions, but they were not able to decrypt them.
Indeed, they did not even recognize them as encrypted telephone communication.
So how could it be that this cryptographic system could defeat every possible type of
cryptanalysis?
According to Shannon's description of cryptanalysis, secrecy comes from the gap between the secret
information and the information available to the enemy.
That gap starts out with the entropy of the key, h of k, but because of the redundancy
d in the plain text message, the gap narrows over time.
When the gap closes to zero, the enemy has enough information to read the message, at
least in principle.
The unicity distance L equals entropy of the key divided by d tells us how long a message
is required to be before the code can be broken.
Notice the assumption in that analysis.
The secret key has a fixed entropy, h of k.
Therefore the secrecy gap starts out at a fixed size and gets narrower over time.
That's how the enemy catches up.
But in SIG Sally, the key information grows along with the message, more and more noise
is from the record, and each conversation uses a new pair of records with new random
noise.
The secrecy gap grows wider and wider.
The unicity distance is infinite.
This general approach to cryptography was known in Shannon's time as a one-time pad.
So picture Alice and Bob, each with an identical pad of secret keys, a new key on each page
in the pad.
When Alice sends a message, she uses the top sheet of the pad, using as many key symbols
as there are symbols in her message.
Once a key sheet is used, one time it is torn off and destroyed.
Shannon showed that the one-time pad is perfectly secure.
It is a code that cannot be broken by crypt analysis.
And since SIG Sally is a system of that type, it is secure as well.
Now that we started to talk about cryptography in digital communication, let's describe
a binary version of the one-time pad concept.
Alice's plain text is a string of bits.
It might be teletype code, or digitized sound, or whatever, doesn't matter.
The key is a second, randomly generated string of bits, secret, but shared by Alice and Bob.
To generate the ciphertext, Alice combines plain text and key bits using the XOR operation.
You may recall that from our discussion of Boolean logic, 0, XOR 0, and 1, XOR 1 both
yield 0, while 0, XOR 1, and 1, XOR 0 yield 1.
Since the key could be anything, any particular ciphertext string, which Eve might intercept,
is consistent with every possible plain text message of the same length.
At his end, Bob receives the ciphertext, and to recover the plain text he just applies
the XOR operation again, using the key string that he has also.
That gives him ciphertext, XOR key, which is plain text, XOR key, XOR key, and since
anything XOR itself is 0, that just yields the plain text again.
After they use the key string, Alice and Bob destroy it, and use a new one next time.
That's the binary version of the one-time pad.
Now if Alice and Bob tried to reuse the key, the system would no longer be perfectly secure.
This is not just a theoretical issue.
It was the basis for one of the most remarkable episodes in the whole history of cryptanalysis.
During the 1930s and 40s, the Soviet Secret Intelligence Service, the NKVD, communicated
with its stations in Soviet embassies around the world using ordinary commercial cable
messages.
These messages were extremely sensitive because they contained details about Soviet spies
in the US, Europe, and elsewhere, so the Soviets adopted a one-time pad system for these messages.
Or rather, that is what they did in theory, for reasons that are not entirely clear, laziness
or carelessness, identical code key sheets were sometimes used in many different pads.
Now these pads might be issued to different stations, one to Turkey, another to Canada,
but the overall result was that sometimes the same key would be used more than once.
So the encrypted cables were intercepted and recorded by the US, Great Britain, and their
allies, but for a long time nobody could read them.
Then in the 1940s, the US Army Signal Intelligence Service at Arlington Hall began to realize
that the same key pages were being reused in different locations.
They started a project to exploit this mistake to decrypt some of the cables that had been
intercepted.
It was called the Venona Project.
Even though the Soviets had been tipped off to the project and switched to new codes in
1945, Venona went on for decades, and ultimately about 3,000 messages were decrypted, many
of them decades after they were sent.
That might seem pointless.
Why work so hard to unlock secrets from 30 years ago?
Remember some of the messages contain clues to the identities of Soviet spies.
That kind of information can remain valuable for a very long time.
Today, the Cold War between the Soviet Union and the United States is long past.
You can freely read the decrypted Venona messages online.
They are a fascinating window into the secret side of history.
They are also eloquent testimony to the fundamental fact about cryptography.
The security of the one-time pad depends on a continual supply of new, secret key data,
otherwise it is as vulnerable as any other system.
So the problem with the one-time pad is new key distribution.
It cannot be done with the cryptographic system itself, since that uses up as much
key data as it would transmit.
Some other means must be used, trusted couriers perhaps.
That's a lot of trouble, and as a practical matter, it is a point of vulnerability.
Who's to say that the enemy might not get a look at the new key as it's being delivered?
If Eve has her own copy of the key, she can decrypt messages as easily as Bob can.
This brings up another vulnerability common to any cryptographic system, which is any
system is operated by people.
The people are vulnerable to bribery, blackmail, and worse.
This is sometimes called rubber hose cryptanalysis.
The one-time pad is reminiscent of a very familiar piece of technology, the remote key.
I have various remote controls that open doors.
I have one for my car and another for my garage door.
When I press a button on the remote unit, it sends a coded radio signal, a string of
a few dozen bits.
That signal is the key.
The receiver recognizes the key signal and unlocks the door.
But here's the problem.
What if somebody nearby intercepts my transmission?
They can simply record the key signal that my remote unit produces.
Couldn't they retransmit the same key later and unlock the door on their own?
Thirty or forty years ago, remote key units did use the same key code over and over.
But modern systems are more clever.
They use something called a rolling code.
Each time you use the unit, it emits a new key code, a new string of bits.
No key code can open the door more than once.
It's like having a physical key that changes shape, and a lock that requires a new key
shape each time it's used.
Now of course, the key and the lock have to stay in sync.
You might press the button on your remote unit accidentally when you aren't near the
door.
So the receiver unit is programmed to accept any one of the next 256 possible keys.
Hitting the button by mistake a few times, or a few dozen times, is no problem.
And each time the key does open the door, the system gets back in sync.
That sounds something like a one-time pad system.
Old keys are discarded.
No key is used more than once.
But it isn't the same.
The reason why not is in the way that the new keys are generated.
Both the remote unit and the receiver have an effect, simple computers, that are programmed
to produce a sequence of key codes.
This is a strict mathematical sequence, not really random at all, based on an internal,
secret key generating code that both units share.
So there is no key distribution.
The new keys are not really new information.
If someone recorded a few of the successive key signals, it would be possible for them,
at least in theory, to deduce the key generating code and therefore predict the next key.
But that would be a very difficult mathematical problem to solve.
And that difficulty is what makes the system secure.
You see, Shannon's theory of cryptanalysis, based only on information, leaves something
out.
According to that theory, once the eavesdropper intercepts enough message data, a length given
by the unicity distance, then there is only one plain text consistent with the ciphertext
data.
Once a word would be intruder catches a few key codes from my remote, there is only one
secret key generating code that could produce them.
Therefore it is possible to break the code.
Possible in principle.
If that says nothing about how difficult the code breaking process will be, that's
the aspect of the problem that information theory ignores.
Most modern cryptographic systems, the ones used by remote keys, and also by computers,
phones and so on, are based on a completely different approach.
They rely on what computer scientists call computational complexity.
Now, that's the subject that studies how difficult different mathematical problems
are.
Any calculation is made up of a series of basic steps.
Some require many more steps than others.
Some require so many steps that no imaginable computer could finish them in a million years.
Those problems are solvable in principle, but not in actual practice.
So let me give you an example from arithmetic.
You probably remember that a prime number is a whole number that is divisible only by
itself and one.
An example would be 17.
There are prime numbers as big as you like.
Whole numbers that are not prime are called composite numbers.
But any number, prime or composite, can be written as a product of one or more primes.
For instance, 35 is 5 times 7.
36 is 2 times 2 times 3 times 3.
37, being prime, is just 37.
So suppose someone gives you two prime numbers, 2273 and 4057 for instance.
Your job is to multiply them together.
That's easy.
Even with pencil and paper, you can probably do it in a minute or two.
The answer is 9,221,561.
I did an experiment on my computer.
I wrote a program to find out how long it takes my computer to do that multiplication.
And frankly, it is hard to measure a time that short, but I found that it took less
than four nanoseconds.
Modern computers are very fast, that's a truly tiny interval of time in four nanoseconds
Light itself, moving at the speed of light, only goes about this far.
But suppose you are given the opposite problem.
You have the number 9,221,561 and are told this is the product of two primes.
Find them.
That's called the factoring problem, factoring the number, and it takes a lot more work.
Essentially, you have to try dividing the big number by many different possible factors
and check each time to see if the division comes out evenly.
By hand, you would be lucky to finish in a whole day.
My computer managed to factor that number in about 14,000 nanoseconds, that's still
blazingly fast by human standards, only a few millions of a second, but notice that
factoring took thousands of times longer than the multiplication.
I tried the same experiment again with two bigger prime numbers, 970,747 and 1,289,557.
Their product has 13 digits.
On my computer, the multiplication still took about four nanoseconds.
Easy.
But the factoring, starting with a big number and working backward, took 16 million nanoseconds.
The moral?
Factoring is just plain harder than multiplication, and the bigger the numbers involved, the more
dramatic the difference.
So suppose my two prime numbers had 70 digits instead of 7.
Their product would have around 140 digits.
On my computer, multiplying those numbers might take longer, perhaps a few hundred nanoseconds.
It would still be fast, less than a millionth of one second.
Factoring that 140-digit number would take my computer not minutes or hours or weeks,
but longer than the lifetime of the universe.
What's the record?
On 2009, using a more efficient program than mine, a 232-digit number was factored.
It took hundreds of computers working together for about two years.
This is what computer scientists call a trapdoor function.
There's an input, two primes, and an output, their product.
Given the input, it is easy to compute the output.
Given the output, it is also possible, in principle, to compute the input.
So from the point of view of information theory, the input and the output contain exactly the
same information.
But in the trapdoor function, going backwards from output to input is vastly more difficult.
It requires many, many more basic steps, far more time.
It might, for all practical purposes, be impossible.
Once you pass through the trapdoor in one direction, it is really, really hard to go back.
It is just barely possible that there is a clever, quick method of factoring numbers
that no one has yet discovered.
True, mathematicians have been thinking about factoring for a couple of thousand years, but
maybe they have missed something.
The fact is, no one has ever proved that a true trapdoor function exists.
That may be the most famous unsolved problem in mathematics.
And computational complexity in P stands for computational problems that are easy in at
least one direction.
There is a technical mathematical definition here of easy that we are skipping.
P stands for computational problems that are easy in both directions.
All of the problems of type P are obviously also of type NP.
But are there NP problems that are not P?
That's what you would need for a trapdoor function.
Now we do know a great many computational problems that seem to fit the bill.
After decades of research into mathematics and computer algorithms, these problems seem
to be easy in only one direction.
They seem to be problems of type P, but not of type, or problems of type NP, but not of
type P.
Nevertheless, no one has ever quite proven that NP is not the same as P. This is one
of the so-called Millennium Prize Problems in Mathematics.
It's famous.
If you solve it, you will become very famous too, and the Clay Mathematics Institute will
happily award you a million dollars.
Meanwhile, pretty much everyone is prepared to assume that P and NP are different.
Trapdoor functions do exist, and the factoring problem is one of them.
And that mathematical hypothesis leads to an astounding new form of cryptography.
This new form was actually discovered twice.
Now that's not as weird as it sounds.
After all, cryptography is the science of secrets, and a lot of cryptographic research
is done in secret and remains secret.
In the early 1970s, the new methods were invented by three British cryptographers, James Ellis,
Clifford Cox, and Malcolm Williamson.
They worked at the Government Communications Headquarters, GCHQ, which is the successor
to Bletchley Park, and is the British equivalent of the U.S. National Security Agency.
Their work was classified top secret.
Also, it was not yet very practical, because powerful computers were not yet common.
Several years later, a bunch of academic computer scientists and cryptographers in the U.S. followed
the same path.
Ralph Merkle, Whitfield Diffie, and Martin Hellman at Stanford established the basic
theory.
Then Ron Rivest, Eddie Shamir, and Leonard Edelman of MIT created the most popular and
unusable version of the system, christened RSA, after their initials.
What they all discovered came to be called public key cryptography, and it caused a cryptographic
revolution.
It completely solved the problem of key distribution.
It allows phones and web browsers and email systems to communicate privately over public
network.
That privacy is not the absolute privacy, Shannon's information theoretic privacy,
of the one-time pad.
Instead, the privacy of public key cryptography comes from a trapdoor function.
The essential idea of public key cryptography is to separate the processes of encryption
and decryption.
The mathematical process of encryption, turning plain text into ciphertext, uses a number
that is the product of two prime numbers.
That product is the encryption key.
However, the process of decryption requires the prime number factors themselves.
They make up the decryption key.
In principle, anyone that has the encryption key can work out the decryption key.
You can always factor a number.
However, if that number is very large, it might be impossible in practice to do so.
So let's see how it works.
Suppose Alice wants to send a secret message to Bob.
Once Bob generates two very large prime numbers and multiplies them together.
That's not too hard.
He sends the product the encryption key to Alice.
He does not have to do this secretly, it's a public key, he can publish it in the newspaper
or post it on the internet if he wishes.
Once she receives the key, Alice uses it to encrypt her message.
She sends it to Bob.
Bob, who has the original two prime factors, can then easily decrypt the message.
So what about Eve?
She knows the public key, the encryption key.
She knows the ciphertext that Alice sends to Bob.
She has all the information she needs.
All she needs to do is factor the encryption key to get the decryption key, and then decode
the message.
But factoring is very difficult.
If the key is long enough, no computer available to Eve could do the job, and therefore the
message remains secret.
Now, for this to work, Bob has to generate two really big prime numbers, dozens of digits
long in order to create the key, and that's a little tricky.
Proving that a particular number is prime, that it has no smaller factors, is actually
the same thing as factoring it.
But that isn't quite what Bob needs to do.
What Bob does is randomly generate a few hundred large numbers.
To each one he applies some simple mathematical tests for being prime.
He checks to see if any of the numbers are divisible by two, or three, or five, or any
of the smallest thousand prime factors.
And there are some other, more subtle tests, none of them very difficult.
Most of Bob's random numbers are rejected by the tests, they are composites, not prime.
But some remain.
Now they might be prime, or they might be composite numbers that happen to pass all
the tests so far.
Mathematicians call these imposters.
They look like primes, but they aren't.
However, imposter numbers are very rare.
So if Bob applies enough tests to his random numbers, he can be 99.999% sure that any remaining
number in his list is a real prime.
And with a few more tests, he can add a few more nines to that likelihood.
The probability that Bob is fooled by an imposter, an imposter number, becomes entirely negligible.
That's how he can generate the prime numbers that he needs.
Using large numbers is only one possible basis for public key encryption, though it is the
one used in RSA and most other systems.
In all of them, there is a public encryption key and a private decryption key.
A public key system is used for text messages on my Apple iPhone.
My wife also has an iPhone.
When she first set up her phone, the phone itself, which is a pretty good computer, generated
its own public encryption key and private decryption key.
It transmitted the encryption key to a public server run by Apple.
The first time I addressed a text message to my wife, my phone downloaded her public
encryption key from the server.
My message was encrypted by my phone before it was sent.
Since her phone has the decryption key, she can read the message.
Of course, anyone who knows my wife's phone number can download her encryption key.
And folks at Apple, who run the public key server, already have it.
And in theory, it should be possible to work out the decryption key from that information.
But in practice, doing so is an unreasonably difficult computation.
Even if someone hacks the Apple server or intercepts the signals being transmitted by
our cell phones, our messages remain private.
Public key cryptography has applications beyond keeping secrets.
For instance, how can I prove to you that I am who I say I am?
One way would be my signature.
It's hard to imitate handwriting well.
If I sign a paper, then that signature can be compared to my signature in some official
file.
Or I might use my thumbprint.
Human thumbprints are unique.
If I give you my thumbprint, you can compare that to my thumbprint on file.
Or we might use the retinal patterns in my eye or my DNA sequences.
All of these methods require me to be physically present somewhere, to sign the paper or give
my thumbprint, etc.
But you and I might wish to transact business without ever meeting each other, over the
phone or over the internet.
How could I prove my identity at a distance?
Public key encryption and its cryptographic cousins provide some ways to do that.
Let's take a simple one.
Suppose I generate a public encryption key and a private decryption key.
I post the public key in an official place, but keep the private key to myself.
If you want me to prove my identity, you could use the public key to encrypt a plain text
and send the ciphertext to me.
Then I could decrypt the ciphertext and send the plain text back to you.
That would prove that I am the person in possession of my decryption key.
We can actually do this more directly.
The idea is to switch the roles of the encryption and decryption keys.
In other words, the encryption key is secret, but the decryption key is public.
Working out the encryption key from the decryption key is possible in theory, but not practically
possible with an existing computer.
This is called a digital signature.
I can prove that I am who I am by providing both the plain text and the ciphertext myself.
You can use the public decryption key to verify that I have done the encryption correctly,
and so I must be the person in possession of the right key.
This can do more than just verify my identity.
Suppose we want to make a contract with one another.
What prevents me from later repudiating it?
Of course, you might then threaten to sue me in court if I do, but if you do take me
to court, what would prevent me from denying that I ever made the agreement?
And no offense, but I may have the same concerns about you.
How do we keep each other honest?
Digital signatures allow us to do this.
For instance, each of us might provide to the other an encrypted copy of our agreement
using our private encryption keys.
Anyone can verify that my ciphertext version matches the plain text version, but you could
not have created that ciphertext on your own.
It is cryptographic evidence that I myself did commit to the agreement.
The cryptographic problems I've been describing are examples of what is sometimes called post-Cold
War cryptography.
In the old days, cryptography assumed a kind of bipolar world.
There were good guys and bad guys, us and them.
The job of cryptography was to keep our messages secret from our adversaries who might be listening
in.
And that kind of cryptography is still important.
However, today most applications of cryptography apply to a complicated, multi-polar world.
It's a world of people and organizations that mostly want to cooperate, but they don't
fully trust one another.
Not only do people need to protect their own information and communicate privately, but
they also need to confirm each other's identities and verify their commitments.
And that is a remarkable conclusion.
Cryptography has moved beyond Shannon.
The cryptographic systems we use every day are built on principles of computation rather
than information theory.
And Shannon himself foresaw this.
He wrote, the problem of good cipher design is essentially one of finding difficult problems.
The practical security of the cipher rests on the difficulty of the problem.
And that's what makes public key cryptography and digital signatures possible.
Those things are technologies no less important than fiber optic cables and microprocessors
for linking together our society in this age of information.
Cryptography is not, or not only, about espionage and warfare.
The tools we invent to conceal information can also be used to establish truth, the science
of secrets, and also help us trust one another.
