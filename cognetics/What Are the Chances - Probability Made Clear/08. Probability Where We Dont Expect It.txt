Welcome back. In the previous lectures, what we've heard about are instances in which probability
and randomness seem pretty clearly to apply. We've talked about gambling, where obviously
randomness and probability come into play. In the case of physics, we can easily imagine
that all these molecules moving around randomly have a random component and probabilistic component
to them. We talked about the genetic drift and randomness was involved in genetic inheritance.
So these are clearly examples where randomness plays a role. In the last lecture, we talked
about the world of finance where stock prices, of course, will have random component to them.
But all of those are places where we sort of expect probability to play a role. Well,
in today's lecture, we're going to talk about finding probability in unexpected places.
Places where you wouldn't expect probability to play a role at all. And we're going to
start with an instance that, in my world at least, I think of as maybe the place where
you would really not expect any probability to play a role. Namely, suppose that I write
down a specific number, just the digits of a number, and I ask the question, is that
number prime or not? Now, surely no probability could be involved with such a question. Either
it's prime or it's not prime. There's no issue here. But it turns out that there are
strategies for determining the primality of huge numbers and deciding whether they're
prime that involve probability. So let's begin, though, by reminding ourselves what
a prime is and how we would naturally try to find out whether a number is prime. So
let's take a specific example. First of all, let me remind you what a prime is. So a prime
is a positive whole number, a natural number, that cannot be written as the product of smaller
numbers than itself. So it's some number two or higher that is not written as the product
of smaller numbers. So, for example, the number five can't be written as smaller numbers,
so it's prime. Seven cannot be written as smaller numbers, so it's prime. Six is not
prime because it's two times three. Okay, so that's what a prime is. Now, how would
we determine whether something is prime or not? Well, suppose we just take a number and
I'll take the number 91 and let's try to decide whether or not the number 91 is or is not
a prime. Well, since the definition of being prime has to do with its divisibility by smaller
numbers, let's just try to divide it and see whether or not we get a remainder. And by
the way, the reason that I choose 91 as an example is because some people view 91 to be
the smallest number that looks prime but isn't. So I don't know if you think that way. It
looks sort of prime to me, but it's not. Okay, so here's how you would go ahead to find out
whether 91 is prime. You try dividing. Divide by two, you get a remainder of one. Divide
by three, you get a remainder of one. Divide by four, four goes into 88 evenly, so it has
a remainder of three. Divide by five, you get a remainder of one. Divide by six, you
get a remainder of one. Then you get to seven and it goes in evenly and 91 is equal to seven
times 13. So that's a wonderful strategy for determining that 91 is not prime. Okay, now
I want you to try it with this number. Okay, is this number prime? Well, this number has
300 digits to it, 300 digits. How in the world would you determine whether that's prime?
You might consider trying the same method. That is just start dividing by two, see if
there's a remainder, three, see if there's a remainder and so on. The trouble is that
if you tried that strategy and even if you could attempt divisions at the rate of say,
oh, a trillion divisions per second, it would take you, if you started at the time of the
Big Bang 13.6 billion years ago and you did a trillion divisions per second, you would
not even be close to doing all the divisions that you would need to determine whether this
number is prime, not even close. So you don't have, unless you have much longer than the
history of the universe, that method will not work. So we have to think of something else
and it turns out that one of the ways to look at it is to use a theorem that was proved
by Fermat. Now you remember Fermat, I mentioned Fermat as being one of the originators of
the concept of probability, but this is not a probabilistic theorem. And you also remember
Fermat from the famous Fermat's Last Theorem, which was proved recently after 350 years.
But this is a theorem that Fermat proved called Fermat's Little Theorem and it has,
it's the following statement. It says that if you take any number that actually is prime
and you take any number less than it, a whole number, we're just talking about integers,
so you take any integer less than that prime, positive integer, and you raise it to the power
of one less than that prime, multiply it by itself that many times, divide by the prime,
you get a remainder of one. Now I said that sort of fast, so we'll just do some examples so you'll
see what it means. This says that if, for example, you take the number of five, five is a prime,
if you take any number less than five, like let's say two, you raise it to the fourth power and
divide by five, you'll get, after dividing, you'll get a remainder of one. In this case, two to the
fourth is 16 divided by five goes three times with a remainder of one. Same thing if you take
three and raise it to the fourth power, you get 81 divided by five, you get 16 with a remainder of
one. Take the number four, you take four to the fourth power, you get 256 divided by five,
it goes in 51 times with a remainder of one. And so this is, these are just examples of
Fermat's Little Theorem. Let's take the prime seven, two to the sixth power divided by seven,
you divide in and you get a remainder of one. Three to the sixth power divided by seven,
divide in, you get a remainder of one, and so on. And it's true for every single prime and,
and I could prove it if we took half an hour, we could prove that, that theorem. It's not a hard
theorem to prove, but it is an interesting theorem and it's true for all primes. Well,
the truth of Fermat's Little Theorem gives us a method for determining whether a number is
not prime. And the way it can determine whether a number is not prime is this, that you just take
any number, so let's prove, let's be specific and prove that the number nine is not prime,
you know, nine is three times three, but let's suppose we didn't notice that, and instead we
wanted to use Fermat's Little Theorem to prove that nine is not prime. What we would do is we would
take two to the eighth power divided by nine and see what the remainder was. Now, Fermat's Theorem
would say that if nine were prime, which is not, of course, but if it were prime, then two to the
eighth power divided by nine would have a remainder of one. Well, when we actually do it, two to the
eighth power divided by nine is 256 divided by nine has a remainder of four, not one. And since
it's not one, we know that nine could not be prime. Okay. And by the way, there's a
technical point I want to just say quickly here that we're trying to take two to the eighth power.
Well, two to the eighth power is two to the fourth power times two to the fourth power,
which is 16 times 16. Now, it turns out that if you wanted to, you could just use the
remainders of these instead of multiplying 16 together, you could just take the remainder upon
division by nine, seven, seven times seven divided by nine will have the same remainder as 16 times
16 divided by nine. So it's a simplification. So you don't have to multiply the bigger number 16,
you could just multiply the remainders together and you and and get the same remainder. But that's
a technical point. Okay. Now, so here is the here is the point. If we had this huge 300 digit number
and we're trying to try to figure out whether or not it's prime, let's just take the number two,
raise it to the power of one less than this huge number, divide by the huge number, and see if
we get a remainder of one. If we get any remainder other than one, we know it's not prime. Now,
you might say, well, how in the world are you going to take two to the power of a 300 digit
number? You'd be multiplying if I said that it took, you know, more than the history of the
universe time to divide, it would take more than that history of time to multiply. Well, the answer
is that you do it cleverly. You just first divide, you take two times two, then that's two squared,
and then two squared times two squared is two to the fourth power to the fourth power times two to
the fourth power is two to the eighth power to the eighth power times two to the eighth powers,
two to the sixteenth power. So you you quickly have those exponents growing, they're doubling each
time there's a multiplication. So in that fashion, you can actually raise a number even to this 300
digit number, number that you want, with only about 1000 such doublings. And so that's well
within the the scope of just a little computer. And so you can quickly determine what that remainder
is. So the answer is that this huge number is in fact a prime. But it's a probabilistic test
because there are some numbers that fool this test. For example, the number 341. The number 341
is 11 times 31. And yet, if you take the number two, and you raise it to the 340th power,
and divide by 341, you do get a remainder of one. So it would fool this test. But the test being
just to take the number two, raising it to the one less than this number power,
dividing by the number and finding the remainder. Well, it turns out that the test though,
although it failed for 341, it turns out to be a very good test in the sense that the probability
of being fooled by the test gets more and more remote as you get bigger numbers. And that the
probability is pretty darn good. For example, among 13 digit numbers, if you randomly choose
the 13 digit number and you do the test of raising the number two to the power of one less than the
number, dividing by the number and seeing whether you get a remainder of one, you can get a remainder
of one even for some non primes. But your probability of doing so is extremely remote.
The probability of such a number actually being a prime is 99.9999985. That would be your chance of
actually having it be a prime if you just did that one test. It turns out there are 308,457,624,821,13
digit primes. And of those, only 132,640 will fool this test of two raised to that power. Now,
how do people know these numbers? Well, that's what number theorists are for. They figure out these
things. Okay, so this is an example where probability comes into play to figure out the
primality of a number. That seems like a strange place for probability to play a role.
Well, let's find another situation. We're going to just do several different situations where
probability comes into play in unexpected ways. This next one involves game theory. So game theory
is a mathematical model of situations like games where the players use different strategies to
maximize their return. And so what we're going to do is to see that probability arises, I think,
rather unexpectedly in game theory. By the way, game theory, it's used in economics and in business.
It's certainly used in games, of course, but it's also used in sports, in war, modeling, war
situations, lots of areas, wherever strategic decisions are made. And it uses the concept
of a payoff matrix where you look at the options of one player and you correspond them to the
options of the other player and see what the payoff is under those circumstances. Now, we're
going to be investigating an example of such a payoff matrix in the world of football. So here
we are. We're going to play a football game and we're imagining that we have the ball and it's
third down with long yards to go. And we're the offense. And we're saying to ourselves, I have
a choice. I could either do a pass play or a run play. Now, by the way, you don't have to know much
about football for this. We're really talking about the math. So you can either pass or run.
Now, the defense can either defend against the pass or defend against the run. And we could write
down a matrix then that captured the expected number of yards that the offense would gain on
average given the four different possible alignments of pass run on the offense, defend against pass,
defend against run on the defense. So this chart says that if the offense passes and the defense
defends against the pass, on average, the offense will make five yards. On the other hand, if the
offense passes and the defense is aligned against the run, the offense will make seven yards. Here,
this square corresponds to the offense running while the defense is aligned against the pass.
The offense in that case makes six yards. But if the offense runs and the defense defends against
the run, the offense makes only one yard on average. So this is a payoff matrix for this
decision about whether to pass or run or defend against the pass or run. Now,
in trying to decide how to use this matrix to make a decision about whether to pass or run,
let's imagine that we're the offense. We say to ourselves, well, if I always pass
and the defense always defends against the pass, then on average, I'll make five yards. But if the
defense is defending against the pass, what I'll do is occasionally run. I'll fool them, you see,
because they're defending against the pass. And so then my expectation would be to make six yards
instead of five if I run when they're aligned against the pass. But of course, knowing that,
the defense then won't always defend just against the pass, because if it always said, I'll defend
against the pass, then the offense could choose to run, you see. So it's this kind of thinking process
that leads to the idea that instead of choosing one strategy of always passing or always running,
the best strategy for the offense is to choose to pass with a certain probability. In other words,
sometimes you're going to pass, sometimes you're going to run, and you're going to
randomly choose which to do according to some weighted probability. So the question to ask
is the following. Suppose we ask ourselves the question, what are the expected number of yards
that the offense would be expected to gain if it passes with probability P and the defense
is aligned against the pass? Okay, suppose the defense is aligned against the pass,
and for every probability P, we can ask ourselves the question, what is the expected number of
yards that the offense will gain? Well, looking at this chart, we see that if with probability P we
pass, then if the and with probability P we pass, that means with probability one minus P we will
run. So the expected value for a particular probability P, the expected number of yards
gained, is P the probability of a pass times five, the number of yards we expect to gain if we pass,
and if the defense is defending against the pass, plus one minus P, which is the probability of
running, times six, which is the expected number of yards that we will gain if the defense is
aligned against the pass. Okay, so this gives an equation that tells us the expected number of
yards we will gain in the offense for every choice of probability P between zero and one
if the defense is aligned against the pass. In the same manner, if the defense is aligned
against the run, we get a similar equation, but here every time we pass and they're they're
defending against the run, the chart tells us that if we pass and they're defending against the run,
we will make seven yards on average. So that means that the expected number of yards that we will
make if the defense is defending against the run is P times seven plus one minus P, the probability
of running times one, because if they're defending against the run, we'll only make one yard on
average. Now let's let's look here. So we're the offense and we're thinking about what to do.
So this is the offense's perspective of the of the problem. Namely, for each probability P,
we get a number of the expected yards we would gain if the defense is defending against the run,
that's this blue line, or if the defense is defending against the pass, that's this red line.
So I claim that the percentage of the probability with which the offense should pass
is exactly at this point right here. And the reason that this is the percentage, you see,
the percentage is between zero and one, it's the probability of passing. That's that's the
decision the offense is making with what probability should I pass. The reason that that the offense
should choose this probability of passing is the following. Suppose instead the offense chose to pass
50% of the time down here, then if the defense always defended against the run, namely on this
blue line, the expected number of yards would be down here, it would be a lower value than the
expected number of yards here. So in other words, if the offense only passes 50% of the time,
the defense could do something, namely always defend against the run that would lower the
expected yards that the offense is expected to make. Likewise, suppose the offense chose
to say pass every time, you see, if it chose to pass every time pass with probability one,
well then the defense can always defend against the pass and the expected number of yards would
once again be lower, you see this line is going downward. So the expected number of yards gained
for the offense would be less. So it's only at the place where the the offense and the defenses
against the pass, I mean the defense against the pass and the defense against the run cross,
that's the place where we should as the offense choose as our probability of passing. Because
that maximizes the minimum gain that we're expected to make. It's a max min strategy.
Well, first of all, how do we actually compute that value? Well, it's easy. We say it's the
place where the expected value of the number of yards gained if the defense is defending against
the pass is equal to the expected gain that the offense makes if the defense is defending against
the run. Those are the two equations that we previously computed as our expected value for
any given probability p of yards gained. And if we then just do the algebra, we set those two
things equal and and then solve for p. We see that p is exactly five sevens, which is point seven one
four and so on. So we're just, that means that the offense's best strategy is to pass with probability
71%. So isn't that interesting? It's a place where probability comes in as the method for
of finding out how to maximize the expected number of yards gained by the offense. Oh, and by the way,
I should say that if the offense does pass with a frequency with a probability of 71%,
then it maximizes the expected gain. And it's exactly the same whether the defense is aligned
against the run or aligned against the pass. It's 5.3 yards on average is the amount that you would
gain. And if you tried any other strategy, if the offense did any other percent strategy,
then the defense could do something that would lower that average gain. So this is a max min
strategy. Now, what happens? Well, the the defense does exactly the same kind of computation,
exactly the kind it it computes its expected value for for being aligned against the the
for picking a probability of defending against the pass. So it's making the same kind of
conceptual decision. And it does the same kind of computation. And it discovers that it should
it should align itself against the pass with a probability of 86%. So interestingly, both the
offense and the defense have a percent that they should randomly choose to on the offense's side
to pass and on the defense's side to defend against the pass with the probabilities respectively
of 71% for the offense is the is the percentage of time the offense should pass rather than run.
And the defense should randomly defend against the pass 86% of the time. And so so it's interesting
because what this means is that first of all, this is a mixed strategy in the sense mixed meaning
that it's a probabilistic strategy. It's not just always pass or always run or always defend
against the pass or always defend against the run. It's a mixed strategy, a probabilistic strategy.
And so it has the has the property that that both the offense and the defense might
from time to time be misaligned. And that that's what sort of makes it fun. So it and and in
ordinary jargon about actually watching football games, you can say you say things like this,
oh, the offense ran in order to keep them honest. And and that's that's approximately true. And
the defense has to do the same thing, occasionally defending against the run, even though there's
a high chance that the people will be passing. And then of course, it gives commentators a great
opportunity to say how dumb the coaches were to make these decisions if they happen to be misaligned.
But these probabilities are an example of what's called a Nash equilibrium.
A Nash equilibrium is a a strategy with the property that no player can get an advantage
by unilaterally changing his or her strategy. You see, in other words, the the offense can't
change the strategy and gain an advantage and neither can the defense. And and Nash was a
mathematician who won the Nobel Prize in economics for his work on game theory. Like and like and
this this existence of such a Nash equilibrium, such as we've just seen in this example, is is the
kind of thing that he won his Nobel Prize for. And he became famous for this work because of the
book A Beautiful Mind and the movie A Beautiful Mind. So anyway, I thought this was this the idea
that in in making strategies of games that we use randomness instead of just a direct strategy,
I thought that was an interesting unexpected place for randomness and probability to occur.
Well, let's turn our attention from from game theory to risk management in in business and and
in in managing large projects. It turns out that NASA, NASA makes these, you know, these very big
projects that send send space exploration going to Mars and other places. And these are very big
projects. And they involve all sorts of aspects that where there's uncertainty, people don't
know what's going to come up because they're doing things that have never been done before.
And so you have a large number of features of the project that have risks to them and unknowns.
Well, in in deciding how to how to describe their budget, this is what NASA actually does.
What it does is that the project lists all the risks that it can think of that would incur some
sort of cost. And then it estimates two things about those risks. It estimates the possible cost
of of that of overcoming that that problem. And then it also estimates the probability
of the occurrence of that risk. So when then then you have the opportunity to take an expected value,
you see, because you have probability of a risk occurring times the cost that will be incurred
when it when its risk if that happens. So in other words, if, for example, a particular risk
will cost an extra $100 million, but it has only a 30% probability of happening, then that would
be evaluated as a $30 million risk as expected value. It may cost $100 million, or it may cost
nothing. But on average, it's that $30 million. And by breaking up the project into small pieces,
you can have a whole collection of risks with their expected costs. And then and then that
as the project continues, some of the risks are retired, meaning that you've gone beyond the
point where that risk happened and didn't happen. So then you can retire that risk from the list
and reevaluate your expected extra money that you need in reserve. And so this is a way for the,
for a big project to manage how much money it should have in reserves for for the project.
So that's an interesting place, I think, where probability plays a role in managing,
in management, because the unexpected does happen. And so how do we deal with the fact that
unexpected things do happen? It's not good enough just to say, oh, I'll stick to your budget
when you're doing something where you don't know what's going to happen.
Well, another example where where randomness comes in is in the area of psychology.
You all know about Pavlov's dogs and the and the conditioning, operant conditioning.
Well, one question is, how should you condition an animal so that their learning becomes the most
last the longest? In other words, that they will learn something and will not lose that learning
over the longest period of time. What's the strategy of rewards? Well, so let's imagine,
say, a pigeon that's being trained to peck at a little dot. And when it pecks at the dot,
a a particle of food comes out, a piece of food comes out, and the pigeon eats it and is happy,
it likes it likes the food. So the question is, with what frequency are you best off giving the
pigeon the reward in order to have the pigeon learn that process and keep knowing it for the
longest? In other words, keep pecking at that dot? Well, you might think that giving a reward every
single time would be the way to do it because then the pigeon is reinforced most often. But the
problem with that is then when you quit, when you cut off the rewards, the pigeon has the expectation
of getting a reward every time. And when it quits getting rewards, then its concept that I got a
reward every time I did this is it fails and so it quits, quits rather soon. Now you might think,
well, okay, if you did it every third time or every fifth time or every seventh time, that would work.
It turns out that the best strategy is to randomly reinforce the pecking to give
give reinforcements randomly. And in that way, the pigeon doesn't know whether it when it's it
keeps pecking, it might just be in one of these long sequences where there don't happen to be any
pellets coming, you see, just because randomness has that feature and the the pigeon learns that.
But it turned out that that in actual experiments, they did some random reinforcing of pecking at a
dot for a pigeon. And they did this for just one minute, for one minute, they randomly gave him,
I guess they must peck pretty fast to only do this for one minute. But they this poor pigeon
pecked away and got randomly reinforced. And it took 3.5 hours before the pigeon gradually stopped
pecking at that dot, because it didn't know whether you know, when is the next reward going to come.
And it turns out, by the way, that I think that this is part of the explanation for the very
recalcitrant addiction to gambling. Because you know, gamblers are are randomly being rewarded.
And their random rewards are sometimes big. So they're getting these bigger rewards at random
intervals. And so they they're induced to continue on and try yet once again to try to gamble. So I
think that that may account for for examples of gambling addiction and other human examples of
things to where we get inclined to do do things over and over again. Well, so in this lecture,
we have seen probability in unexpected places. And then in the next lecture, we're going to look
at some of the really most famous examples of probability, the birthday problem, and the
Monty Hall game show. Let's make a deal. I'll look forward to seeing you then.
