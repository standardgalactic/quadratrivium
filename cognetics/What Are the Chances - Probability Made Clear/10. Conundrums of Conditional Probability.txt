Welcome back. In this lecture, we're going to introduce a very basic concept of probability
that's associated with what happens when we're asked a probabilistic question, but then we're
given more information. It changes the probability because we put ourselves in a more restricted
arena of possibilities. And so let me explain this concept. So the concept that we're going
to aim for is called conditional probability. I'll explain it by first looking at a very
specific example. Suppose that we have a collection of cards and here we see a collection of cards.
There are a total of 27 cards in this collection and suppose that these are randomly mixed up
and we're asking the question of what's the probability of choosing a card of a certain type?
Well, we're familiar with this. We know exactly what to do if it's equally likely that we choose
any card. We can answer such questions as what is the probability of choosing a face card? And
the answer is, well, we just count up how many face cards there are. There are a total of 12,
3 plus 3 plus 3 plus 3, that's a total of 12 face cards out of the total of 27 cards. So the
probability of randomly selecting a face card is going to be 12 out of 27. No problem. Likewise,
the probability of choosing a red card is the total number of reds that there are, 6, out of the
total number of cards that there are, 27. So that's the probability of choosing a red card.
Well, conditional probability comes in when we're told some feature of what it is that we get. For
example, suppose that we're asking the question, what is the probability of choosing a red card
given that we have chosen a face card? You see? So in others, we have these cards, we randomly
choose one, and then, and maybe somebody else is looking at it and says, oh, it's a face card. And
then you ask the question, what's the probability that it's red? Well, all that does is it puts us
into this collection of cards instead of the whole group of cards. We say, what's the probability of
having a red card if we know we have a face card? Well, there are three red cards out of the total
of 12 face cards. So the conditional probability of having a red card given that you have a face
card is 3 out of 12. So that's conditional probability. And there's a notation for it. So the
notation is the probability of getting a red card and then a vertical bar says, given that you
are, that you have a face card. So this is the basic concept of conditional probability. And it
turns out to come up in all sorts of arenas. So let me point out some facts about this conditional
probability, namely the following. Suppose that you are told that you are, you're asking the
question, what's the probability that you get a face card that is red? So among that same group of
27 cards, what's the probability that you get a face card that's red? Well, the answer is that
that probability is the probability of first choosing a face card. And then among those face
cards, choosing a red one. So it's the product of two probabilities, the probability of choosing
a face card from among the whole group of 27 cards times the conditional probability of choosing a
red card, given that we have a face card. Now, now let's just look at this, at this picture,
and to see what, what we mean by this. So the probability of getting a face card is 12 out of
27. And I'm assuming that we're just picking one card randomly from this group of 27 cards,
this specific group of 27 cards. Well, the probability of getting a face card is 12 out
of 27, since there are 12 face cards. Then the probability of getting a red card, given that
we're in this group of 12 face cards, is three out of 12. So that's the conditional probability
of getting a red card, given that we have a face card is three out of 12. So that means that the
probability of getting a face card that is red, that is we choose a card at random from the whole
group, the probability that it's both a face card and is red is the probability that we get a face
card 12 out of 27 times the probability that we have a red card, given that we have a face card.
And that product is one out of nine or three out of 27. And you see it is the correct answer.
The probability of picking a red face card is the probability of picking one of these three
cards, which are the three red face cards from the total of 27 cards.
Well, of course, we can look at the, that the same situation backwards. In other words, we can say,
once again, asking the question, what's the probability of getting a face card that's red?
Well, we can say that that's also the same as what's the probability of choosing a red card
from the whole group. And then within it, what's the probability of having a face card if we already
know that the card we've selected is red. So this is illustrated in this diagram. The probability
of choosing a red card is six, there's six red cards out of the total 27 cards. So the probability
of choosing a red card from the whole group is six out of 27. Once we know we're in the group
of red cards, the probability of getting a face card is three out of the six red cards.
So the probability of getting a face card, given that we already know it's red, is three out of
six. So another computation for getting a red face card is six 27th, that's the probability
of choosing a red card times the conditional probability of choosing a face card, given
that we have a red card, three out of six. And once again, of course, we get the same answer
of one ninth. Now a principal tool that is used in dealing with conditional probability is called
Bayes theorem. And what it does is it relates two different conditional probabilities, such as the
two conditional probabilities that we've been talking about. We talked about two different
conditional probabilities, namely, the conditional probability of choosing a red card, given that
it's a face card, and the opposite, the conditional probability of choosing a face card, given that
it's a red card. And we saw that there was a relationship between the two. And let's go ahead
and summarize it in Bayes theorem. That's what Bayes theorem summarizes. It says the following.
Suppose that you have two different characteristics, A and B, in some group of things. And by the way,
when you're thinking about Bayes theorem, simply think that A means red card and B means face card.
And then what Bayes theorem says is that the probability of condition B times the probability
of A given B, the conditional probability of A given B, is equal to the probability of A times
the probability of B given A. Now, by the way, when I read that, it just sort of words. But if you
think of it as to say, okay, red and face card, and you realize that what you're trying to compute
is the probability that you get a card that's both red and a face card,
then you can make sense of both sides of this equation and see that they're the same.
Because you see, what this says is that the probability of getting a face card, so being
among the face cards, that was those 12 face cards, that has a probability, 12 out of 27,
in our example, times the conditional probability of getting a red card given that it's a face card,
that product is giving the answer of the probability of selecting a red face card.
But likewise, it's of course the same answer as first seeing what the probability of getting a
red card is, times the probability among the red cards of having a face card, which is the
conditional probability of having a face card given that it's already red.
So this is Bayes' theorem, a very famous theorem in conditional probability, and it can be expressed
by simply dividing through by the probability of B. This is the form that it's often phrased in,
because it puts the conditional probability of A given B in terms of the other three probabilities.
Okay, so this is an example of a Bayes' theorem that talks about conditional probability,
but I want to give you some examples that illustrate this concept.
So let's start with a scenario that I refer to as the reunion scenario, because it can be viewed
as the following thing. Suppose you go to your college reunion, your 25th college reunion.
So you meet this person at the reunion, and you say, I understand you have two children,
and they say, yes, I have two children. And then you say, I understand that your older child is a boy,
and they say yes. What is the probability that both children are boys, that that person has two boys,
given the information that the first one is a boy, and the older one is a boy, the older one is a boy?
Well, here's the way you think about it. As soon as you said that this person has two children,
there were four equally likely possibilities for those children. Either the older one was a boy,
and the younger one was a boy, or the older one was a boy, and the younger was a girl, or the older
was a girl, the younger was a boy, or they were both girls. Those are equally likely scenarios
for the four children, if you had no further information, other than that they had two children.
Now we add other information, namely that the older child is a boy. Well, that eliminates the last
two possibilities, and we have only two of these equally likely possibilities remaining. One of
them is that that the person has two boys, and so the probability that the person has two boys is
one half. Great. Nothing surprising there. Let's do the same situation with a slight variation.
The slight variation is the following. You go up to this person, you say, I understand you have two
children. They say, yes, I do. And then you say, I understand that one of your children is a boy,
but you don't know which. You don't know whether it's the older or the younger. One of them is a boy.
Now you ask the question, what's the probability that they have two boys?
Well, in this circumstance, it is a little bit different. You see, the difference is you didn't
say that the older one was a boy. You just said that you have at least one boy. Well, look at what
happens. Among the four possibilities that you began with when you knew that they had just two
children, but had no further information, only one of those is eliminated by the knowledge that
at least one of the children is a boy. Therefore, there are three equally likely possibilities
remaining, of which only one is that both children are boys. So the probability of having two sons,
given that the information that at least one is a boy, is only one out of three.
Now, this is often surprising to people. It's very counterintuitive because you'd think, well,
knowing that they have one boy, well, the other one is either a boy or girl. So why shouldn't it be
50-50? But you see, this analysis shows us that the probability is actually just one out of three.
Well, it turns out that this particular probability paradox is actually quite subtle. And in fact,
it's confusing to a lot of people. And the reason that it's confusing is because some of the subtleties
are things arise that make it more challenging that you would think. And I personally made a mistake
about this particular problem when I tried to phrase it in a slightly different way. And it
turned out to change the probability in a subtle way that I didn't notice at first. And somebody
pointed out to me, so I got tripped up on it myself. So this is really rather subtle. And I'm
going to show you how subtle it is by doing a variation of this problem that I think you'll
find it really rather astounding. And at least I found it so. Suppose we make the following just
small variation on the problem. You come up to this person and they say, okay, and you say to
them, okay, you have two children. You've learned this someplace that they have two children. And
they say, yes, I have two children. And then you say, I understand that one of your children
is a boy who was born on Tuesday. Born on a Tuesday. And the person says, yes, that's correct. One of
my children was a boy who was born on a Tuesday. And now you ask the question, what is the probability
that that person has two boys? Now, of all the irrelevant things that I can think of, having
the child born on a Tuesday appears to be among the most irrelevant. Why would that have anything
to do with this probability scenario? Well, it turns out that it alters the probability
significantly. And here is the analysis. And this, I just find this mind boggling. So here we go.
Our strategy for computing the probability, as always, is to try to write down equally likely
scenarios, the equally likely possibilities of these two children that are relevant to the
information that we have. In this case, there are actually 196 equally likely possibilities when we
think about day of the week being born and male and female-ness of each of the two children.
In the following sense, there are 49 equally likely possibilities for the person having
two boys. Because the older boy could have been born on any day of the week, Sunday, Monday,
Tuesday, Wednesday, Thursday, Friday, Saturday. Likewise, the younger one could have been born
on any one of those seven days of the week for a total of 49 different combinations of older boy
and date of birth and day of birth and younger one and day of birth. Oh, and by the way, let me
point out something that I'm assuming, which is that the day of the birth is random, that is equally
likely to be born on any of the seven days. Now, incidentally, that's not true because hospitals
try to get people to be born during the weekdays, so my guess is it's actually more probable to
be born on the weekday than the weekend, but we're forgetting that for now. We're assuming that it's
equally likely. So here we go. We have 49 boy-boy possibilities. That is, the first square in each
case indicates the day of the week on which the older boy was born and the second square indicates
the day of the week on which the second boy was born. So we have these 49 possibilities. Likewise,
for the possibility of the older one being a boy and the younger a girl, we again have 49
possibilities. The older boy could be born on any of the seven days of the week and for each
such day of the week, the younger girl could be born on any one of those seven days. Likewise,
we have 49 possibilities for the older girl younger boy possibility and then 49 for the girl
girl possibility. Now, what we need to do is to understand when we learn that at least one boy
is a boy, at least one child is a boy born on a Tuesday, we need to look among all of those 196
equally likely things and find those on which there's included a boy who is born on a Tuesday.
Well, let's go ahead and do that. It's not, it's not hard. What we do is in the boy-boy scenario,
there are 13 of these pairs which include at least one boy born on a Tuesday. Namely, the first
boy could be born on a Tuesday, so that's seven and then the second boy could be born on a Tuesday.
That would be seven more except for the fact there's an overlap on the Tuesday-Tuesday
possibility. So that's a total of 13 boy-boy possibilities that include at least one born
on a Tuesday. Now, for the boy-girl possibility, older boy younger girl, there are seven additional
cases where there is a boy that includes a boy born on a Tuesday and for the older girl younger
boy possibility, there are seven more instances where there is a boy born on a Tuesday. Of course,
none in the girl-girl section. So just adding those up, we have a total of 13 plus 7 plus 7,
which is total of 27 possibilities that include a boy born on a Tuesday, of which 13 are in the
boy-boy category. So the probability of having two boys given that that one of the boys is born
on a Tuesday is 13 out of 27. It's neither a half nor a third. It's something in between. Isn't that
amazing? So anyway, I find this to be a really remarkable example. Well, I'm going to now shift
gears and go on and talk about another probabilistic scenario which involves earns. And this is very
important to always do something that involves earns because in any discussion or probability,
earns have to play a role and particularly reaching in and picking a ball from an earn. That's got
to be part of it. So here I have two indistinguishable earns. They look exactly the same. You see,
and first of all, you have to recognize them as earns and you have these two earns. They look
exactly the same and each one contains a certain number of balls and I'll show you what they contain.
They each contain 10 balls and this one contains seven blue and three red. You see? Seven blue and
three red and this one contains the opposite. This one contains seven red and three blue. Okay? Now,
okay. Now, I have these two earns and here's the experiment that we're going to undertake.
I'm going to take these two earns and just scramble them around without looking and then
I'm going to reach into one of the earns. Okay, so here's what I do. Okay? Now, I've scrambled them
around so that now I don't know which one is the one that has the red dominant red heavy earn and
which is the blue heavy one. Blue heavy, I mean red heavy means that they're the seven reds and
that's what I mean by the red heavy earn. So, I'm trying to get some evidence about which is which.
Pretend I can't look into these, by the way. Okay, but here's the evidence that I'm going to get.
I'm going to gather evidence by just reaching in and randomly choosing a ball from the earn
and picking it out and looking and seeing what color it is. Okay? And then that's going to be
evidence and we're going to evaluate how strong that evidence is for the question of whether I
reaching into the red heavy earn or the blue heavy earn. See, I don't know which I'm reaching into.
Okay, so here's what I do. I reach into this earn which I've selected randomly between the two
earns. I reach in and I get a red ball. Okay? Well, okay, that's something. Now, I put it back in
and I scramble up. I scramble up the the balls in the earn and I keep to the same earn now again
and I again reach in and I pick out once again a red. Okay? And then I put it back in and I scramble
it up in the same earn again. I'm always just focusing on this one earn because I'm getting
evidence about this one earn. I'm trying to decide what's the probability that it's the red heavy
one or the blue heavy. So, I reach in for a third time, get red, put it back in, scramble them up,
shake it up, reach in again, pick them out at random. Four times in a row, I get red. Now,
question. What's the probability that I have been reaching in to the red heavy earn?
You see, it's possible that I was reaching into the blue heavy earn. I mean, because there still
are three reds in the blue heavy earn and I had some probability of choosing the four balls
that were all red from the one that only had three. But it's more likely that I would choose four reds
if I'm in the one that has seven reds and three blues. Well, how am I going to think through
what the actual probability is of these two things? So, the first thing I want you to do
is to ask yourself, how strong do you think this evidence is? In other words, do you think that
there's a very high probability that I must be reaching into the red heavy earn with this evidence
when I got four reds? Or do you think that it's some evidence that it's probably red heavy, but
it's not that strong? So, I want you to think about that question here. Now, how can we think
about trying to be specific about how strong this evidence is? Well, here's a strategy that's
the kind of thing that we've been doing throughout this course, which is to say,
let's imagine doing the experiment many, many times and seeing what we would expect. So, for
example, suppose we had 20,000 people do this experiment, the experiment being to randomly
choose one of the two earns and then to reach in and four times in a row, pick out a ball and
then put it back in a row again and then randomly pick out another and put it in and so on.
What would we expect to happen if we did this 20,000 times with 20,000 people? Well,
let's just think it through. On average, 10,000 people would be reaching into the earn that has
seven reds and three blues and 10,000 people would be reaching into the other one, the one that has
seven blues and three reds, the opposite. How many people who reach into the earn that has
seven reds out of 10,000 people, how many of those would we expect to choose all four reds,
four times in a row to choose red? Well, we can figure this out. We can figure this out.
The answer is that the answer is that every time we choose a ball from the red heavy earn,
we have a 70% chance of choosing a red ball. Now, if we do this four times, the probability
of choosing a red ball all four times is 0.7 times 0.7 times 0.7 times 0.7, which is 0.2401.
So, if we conduct this experiment 10,000 times, we would expect that 2,401 of those people would
have chosen four reds if they're reaching into the red heavy earn. Well, we can do the same kind
of analysis for the blue heavy earn. Suppose that we're reaching into the blue heavy earn,
it's certainly possible that we could choose a red each of four times, but its probability is much
less, since the probability of choosing a red ball is only 0.3 for each individual instance.
So, the probability of choosing four in a row is 0.3 times 0.3 times 0.3 times 0.3,
which is only 81 out of 10,000. So, now if we return to our scenario of having 10,000 people
reach into this earn that's red heavy, and 10,000 reaching into the earn that's blue heavy,
we expect that 2,401 will draw four red balls from the red heavy one, and only 81 will draw
four red ones from the blue heavy one out of the 10,000. That's what the probability would dictate.
So, that means that in total, among this whole 20,000 people, 10,000 of whom picked from this
earn, 10,000 from this earn, a total of 2,482 people will draw four red balls. Of those,
2,401 are dealing with the earn that is red heavy, that has the seven reds in it,
and only 81 are dealing with the earn that is blue heavy. So, in order to compute the probability,
it's just 2,401 divided by 2,482. It's 97%. So, the evidence is very strong if you get four
reds that you're in the red heavy earn. Well, that may or may not be surprising to you,
but what I would like to do is pose a slight variation on the question, and see if I can
successfully surprise you. So, here is a slight variation on it. We have the same situation.
We have these two urns, one has seven red three blues, one has seven blues three reds. We scramble
them up randomly, and reach into one of the urns and start choosing balls. Sometimes we get red
ones, sometimes we get blue ones. But this time, instead of just reaching in four times, suppose
we reach in 50 times. Each time we pick out a ball, put it back in, scramble them up, reach them.
And among those 50 times, 27 times we get red, and 23 times we get blue.
So, here's a question, and I pose this as you as a thought question.
What do you think that tells us about the probability that we're in the red heavy earn?
If we got 27 reds and 23 blues, how strongly do you think that tells you that you're in the red
heavy earn? In other words, do you think, well, yeah, it's more likely to be red heavy, but just a
little bit. Most people I've talked to, their intuition tells them that there's just a little
bit of a chance higher that you're in the red heavy earn, because those two numbers are so close,
27 to 23, 27 reds to 23 blues. So it seems like the evidence is, for example, not as strong as the
evidence of just picking four in a row that we're all red. Well, the possibly surprising answer
is that in fact, the probability is exactly the same that you are in the red heavy earn.
The probability of choosing, if you choose 27 reds and 23 blues, that evidence is exactly the
same as just choosing four and having them all be red. And you can compute this probability
in a similar way that justifies it by looking at the probability of being in the red heavy earn
and choosing 27 reds and 23 blues. And this denominator is the total number of the probability
of choosing 27 reds and 23 blues from either of the urns. And computing that, it turns out,
everything cancels and you end up with just the exactly the same probability formula that we would
have written down for the case of just picking four. So I hope that you are at least a little
bit surprised by these examples of unusual probability and particular conditional probability.
In the next lecture, we're going to talk about the very interesting concept of probability as a
measure of belief. I look forward to seeing you then.
