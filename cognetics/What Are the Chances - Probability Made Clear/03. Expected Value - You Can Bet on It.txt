Welcome back. Many life decisions that we make every day involve randomness and outcomes
that we just really cannot predict. For example, if we buy a stock, we don't know whether
the price will go up or go down. If we decide whether or not to get eye surgery that will
correct our vision, well, several things could happen. One is that everything could work
out great and we'd have perfect vision or things could not go so well. So there are
consequences to different alternatives of the future and we have to sort of weigh them.
If I teach in the university and students constantly make the decision of whether they
should study for a test or just rely on knowing those three things that will be asked on
the test. You see, this is a trade-off they have to make. Or when we buy insurance, we
buy insurance with the idea that something might happen, in which case the insurance
will pay off or maybe we're paying for insurance that's never used. Well, how do we go about
making these kinds of decisions? One strategy, a basic kind of strategy that we use in everyday
life is that we consider hypotheticals. We say, well, okay, it might happen that a hurricane
comes and we have a disaster in our house or our house burns down and therefore it would
be good to have insurance to pay for it. And if the house burns down, it would cost this
amount of money and it would be this much trouble and therefore we say, well, it might
be worth it to buy so much insurance. But it's sort of a sliding scale and we have to give
a sort of a cost-benefit analysis for each possible outcome. And we don't know which
outcome is going to happen and that's why there's a decision that involves something
that's random. We don't know what's going to happen. Well, one of the main strategies
by which mathematics comes up with new ideas and develops things is to take ordinary thinking
and abstract it and generalize it and sort of clarify what that thinking is really involved
with. And in fact, Albert Einstein has a great quote on this that I think is completely correct.
He said, the whole of mathematics is nothing more than a refinement of everyday thinking.
And certainly in today's lecture, that's what we're going to be doing. We're going to take
everyday thinking and try to refine it to develop a concept. What the concept is is that
we're imagining that we have something that has several possible outcomes and each outcome
has a possibility to it, a probability to it. And then each outcome has a value associated
with it. And so what we need to do is balance the likelihood of the various outcomes with
the costs or the benefits of each of those outcomes. And so what we're really trying
to pin down is this intuitive and natural thing that we frequently do, which is that
we give more weight to things that are more likely. If something is very likely to happen,
then we say, okay, I better consider that to be much more serious possibility than if
there's something that's extremely rare. We say, boy, I sure wouldn't want that to happen,
but it's so rare I can more or less ignore it. Well, this concept of trying to pin down
the idea of balancing the expectation, the likelihood of an outcome with the cost or
the benefit of that outcome leads to the concept of expected value. And that is the concept
that we will define and discuss during this lecture. So here is the idea that we imagine
having various outcomes. And as is often the case in the realm of probability, the best
examples to illustrate a point are to start in the realm of gambling. So in this case,
what we're going to do is use the gambling game of roulette to explain the concept of
expected value, to illustrate this concept. So here we go. A roulette board, roulette
table here consists of the following game, that there's a roulette wheel that rolls around
a ball rolls around and lands in a slot. And the the it lands in a slot that has a number
and the number is any one of the numbers one, two, three up to 36, or there's also a zero
and a double zero. So the probability of any one of the numbers from one to 36 to plus
zero and double zero for a total of 38 possible outcomes are equally likely when you roll
the ball in an honor roulette wheel. They're supposed to be equally likely. So what happens
is the way that the the the payoffs are are are done in roulette is the following that
if you make a bet, you put a certain dollar bet on a particular number. So let's suppose
this chip represents a $10 bet. And if you put the $10 bet on number 13, then the wheel
rolls around. And if the number 13 comes up on the wheel, then the payoff is $360. In
other words, you get a total of $360 back. Well, the probability of getting a 13, the
13 coming up is one out of 38, because there are 38 equally likely numbers to come up and
the number 13 is just one of them. So your probability of winning is one out of 38. But
when you do win, you win $360. That is, you take back $360, which is $350 more than you
invested. So if invest is the correct term. So so the concept of expected value is to
consider what the average winnings or losings would be if you repeated the experiment many,
many, many times. So an expected value is an average winning or losing of the particular
trial that you're you're or experiment that you're conducting. In the case of the
case of betting $10 on the number 13, let's just see what what it would mean to say what
is the average winning or losing that you would expect from undertaking undertaking the bet
of betting $10 on number 13. Well, here's what we'll do. Let's imagine that we conducted
this experiment many, many times. And for convenience, let's imagine that we do it 38,000 times.
And the reason we do it 38,000 times is because there are 38 equally likely numbers to come
up. So that means that on average, we would expect 1000 of the bets to come up 13. If
we did 38,000 times, we'd expect to win 1000 times. Of course, it wouldn't be exactly 1000
times. But on average, it would be 1000 times. And we would expect to lose, by the way, 37,000
times of this 38,000 times that we bet on number 13. So what in in making those 38,000
bets, if we win 1000 times, the total payoff, the total amount of money that we take in
is the $360 that we get whenever we win times the 1000 times that we win for a total of
$360,000 that we take in. But we pay in order to have played 38,000 times, we paid $10 per
time. So that's a total of $380,000 that we paid out. Well, the difference is that the
difference between 360,000 that we brought in and 380,000 that we took out, of course,
we lost $20,000. So that means that per bet, the expected value of that bet is just the
fraction of the $20,000 loss divided by the 38,000 bets that we made. In other words,
it's the average over all of the bets that we made. It's the average winning or losing.
In this case, the average is negative 53 cents. In other words, our on average, we expect to
lose 53 cents for every $10 bet. Well, so the expected value of making a $10 bet is
negative 53 cents. Now, so the first principle to note about expected value is that it's an
average. In no case is it exactly the amount that you're going to win or lose. There's
no way that you can bet $10 on number 13 and have them lose exactly 53 cents. That doesn't
happen. But on average, if you did it many, many times, 53 cents on average would be the
amount that you lose. Now, by the way, another way to look at how this probability is computed
is that it's equivalent to saying that one out of 38 times, that's the probability that
you're going to win this bet when you put it on number 13. It's one out of 38. And with
that probability, you will win $350. That is to say you will be ahead by $350. Whereas
the 37 out of 38 times, that's the probability of some other number than 13 coming up, you
will lose $10. And if we do this computation, we get the same answer, negative 53 cents.
So that is the definition then of expected value. It is that the following is the formal
definition that if we have a collection of outcomes, in the case of the roulette wheel,
that there were two outcomes that we considered. One was it comes up number 13, which we bet
on. And the other outcome was that it comes up some other number. They don't have to be
outcomes that have an equal likelihood of coming up. In the case of the roulette wheel,
there was only a one out of 38 chance that it would come up 13. Whereas there's a 37
out of 38 probability that it comes up some other number. So we list the potential outcomes
of the experiment or trial. And for each one, we have a probability of that outcome
occurring. For every one of those outcomes, we also have a value associated with it. In
other words, if that outcome happens, like coming up with a 13, there's a certain value
associated with it. In this case, it's plus $350. You're $350 ahead. The value of the other
possibility, some number other than 13, was that you come out behind by $10. So the
computation of expected value is the sum of a product. It is the probability of an outcome
times its value, plus the probability of the second outcome times its value, plus the
probability of the third outcome times its value, and so on throughout however many
outcomes there happen to be in the experiment you're undertaking. Let's do a modified
experiment, another roulette experiment to just demonstrate this concept of expected
value. We're going to do a couple of these so that you really understand the concept of
expected value and how you compute it. Another kind of bet you can make on roulette is a
bet on red, and this is what this red segment here illustrates. If you bet your $10 on red,
what that means is that you're going to win if any of the red numbers that you see on the
board comes up. Now, there are of the 36 numbers from 1 to 36, 18 of them are red and 18 of
them are black. The two numbers zero and double zero are not either red or black. So your
probability of coming up with a red number is 18 out of 38 possible numbers. So you will
win with a probability of 18 out of 38, and you will lose with a probability of 20 out
of 38. Now, the payout for this $10 bet is $20. In other words, you gain $10. If you bet on red
and you get a red, then you get paid $20, you've invested $10, so your net gain is $10. Well,
we can compute then the expected value of this $10 bet on red. Namely, it's the probability
18 out of 38 of getting a red, of a red's coming up, times the amount that you gain, namely
$10, plus the probability 20 out of 38 that some other number that's not red, a non-red
number comes up, 20 out of 38 are non-red, and in those cases you lose $10. If you just
multiply these values out, you see that once again, you get, you have the exactly the same
expected value of that $10 bet, negative 53 cents. So in both cases, the expected value
of a $10 bet on red is exactly the same as the expected value of a $10 bet on an individual
number. And by the way, what does that mean? Well, that means that if you actually did
repeated the bets millions of times, on average in each case, you would lose 53 cents per bet,
regardless of whether you bet on 13 or you bet on red. The expected value over the long
term is exactly the same. Remember that the law of large numbers tells us that if we do
a lot of trials of something that has a certain probability that we can compute, then the number
of trials divided, the number of times that the outcome is what is being predicted divided
by the number of trials is going to converge to the probability. And so in the case of
roulette, this is exactly what it is that the casinos count on. You see, and we actually did
some simulations to illustrate this. So here's what we did. We simulated the idea of making
a $10 bet on red in roulette and we did it 10,000 times. So we made 10,000 bets on red
and we calculated the average gain, which of course was actually a loss, the average loss,
and we did that whole simulation 10 times. So 10,000 times we bet on red and we just saw
what the average gain or loss was. And then we tried the same thing. We bet $10 on red
a million times. We repeated that 10 times. So this is what we did. This is what computers
are great at, of course, that they can just, they're perfectly happy as a pig in a sty
to just be sitting there and just simulating a million times of betting on red. And look
what we see. After betting 10,000 times on red, the average bets you see in this column,
the average loss varied from, I guess the low here was 41 cents and the high was a remarkable
70 cents. And that was, but you see that the average looks to be very close to the 53 cent
average loss that we had computed from our expected value analysis. And look what happens
when we did it a million times. We bet on red a million times by simulation. Look at those
numbers. Look how close they are to 53 cents, average loss after we get a million times.
Once again, illustrating the concept of the law of large numbers, that when you repeat
something many, many times, the computation of what the probability is and what the expected
value is comes out to be what you actually observe. Now, why is this important for casinos?
Well, casinos are very happy to do this kind of calculation because they are in fact experiencing
this repeated process of making bets on numbers, namely all the people who come in and play
roulette, they're all betting these numbers and the casino is sitting there happily saying,
you know what, some people are going to win, some people are going to lose, but on average
over a lot of bets, and I know a lot of people are in their betting, on average I can be
pretty confident that I'm going to earn, I being the casino, I'm going to earn 53 cents
per $10 bet on average over the life of playing this game. And so this is a terrific thing
for the casinos and they can be very clear on their prediction of how much money they're
going to make given how much money is invested in gambling. And so this is the way casinos
operate. Now, I want to show you a couple of sort of surprising things about expected
value, sort of a little bit unexpected instances of unexpected, expected value. So here's an
example. Suppose that you have this roulette wheel and a roulette game and instead of playing
it just once, you play 35 times. In other words, you make a bet and you see what happens
and then you bet 10 more dollars and you see what happens and you do this and you do it
35 times. You play 35 times. Well, we know what the expected value of playing 35 times
is. We know that on average we lose 53 cents per bet. There are 35 rounds. We can just do
this computation here and see that our expected loss is going to be $18.42. That's the expected
loss over this 35 rounds of betting. On average, we'll lose $18.42. But here's what's
surprising. What's surprising is that if you had a bunch of people making these 35 bets,
in fact, 61% of those people will be ahead after 35 rounds. 61%, more than half of the
people will actually be ahead. In other words, if thousands of people, suppose you had a
thousand people, each one did it 35 times, 61% of those people, over 600 people would
actually be ahead after 35 rounds. Now, this seems to be a contradiction because we just
computed that the average loss was $18 and something. How could it be that 61% of the
people, more than half, were actually ahead? Well, the answer is that the people who are
ahead on average just won one time. Most of the people who are ahead, they're just slightly
ahead because you see they won just one time. But the people who are behind have actually
lost $350. Now, of course, some people won more than once. That could happen, but most
people who win just win once. The balance is that the losers are losing more money to
compensate for the winners winning a little bit of money. By the way, in order to make this
computation of the 61%, it's a simple computation, namely this. We just say, what is the probability
of losing every single time in making 35 bets? Well, the probability of losing any one time
is 37 out of 38. That's the probability. If you bet on a single number, your probability of
losing is 37 out of 38. If you then bet again, the probability of losing again is 37 out of
38 times 37 out of 38 because you had to lose of the times you lost the first time, then
you have to lose again the second time. Then the third time, 37 out of 38. If you wanted
to lose 35 times, you don't want to lose, but to lose 35 times in a row, the probability
is just 37 over 38 multiplied by itself 35 times. That's the probability. This part right
here is the probability of losing all 35 times. The probability of winning at least once is
1 minus that. Consequently, if you actually just put it in a calculator and do it, you see that
1 minus 37 over 38 to the 35th power is equal to about 61%. Let's do one or two more examples
to see the concept of expected value so we really pin down this concept. In this example,
suppose that you are a person who owns a pub or a bar and you're deciding to have a dart game
in the pub and you want to have the following payoff for the dart game. You have this target
here and $4 will be the payoff for getting in the middle, $3 for the next ring out, $2
for the next ring out, and $1 for the outer ring. Suppose that you assume, maybe by putting
the dart board far away, suppose you assume that anybody who throws the dart has an equal
likelihood of landing anywhere on the board. Then if they miss the board, you let them
try again. They definitely hit somewhere on the board, but it's equally likely to hit
anywhere. Then we can look at the probability of their hitting in the different rings by
computing the percentage of area that are in the different rings. Here we've done so.
44% of the area is in the outer ring, 31%, 19%, 6% for the four different rings in percentage
area. To compute the probability of landing someplace, you'd say there's a 44% landing
in the outer ring, a 31% in that next to the outer ring, and a 6% chance of landing in the
middle area. It's just by area because we're assuming it's just random, so aiming doesn't
have anything to do with this computation. What is the expected payoff of this game if
we pay out $4, $3, $2, and $1 respectively for the different rings? Well, remember the
definition of expected value is the probability times the payoff, probability times the payoff,
plus the probability times the payoff. So in this case, there was a 6% chance of getting
a payoff of $4. There was a 19% chance, the yellow ring, 19% chance of having a payoff
of $3, a 31% chance, .31, of getting a payoff of $2, and a 44% chance of getting a payoff
of $1. Just multiplying those together gives the expected value, which is $1.87, meaning
that if you had thousands of people randomly throwing darts at this thing and getting that
payout, you would on average pay out $1.87 per customer. That is per dart thrown. So if
you were the bar owner and you wanted to decide what would make the game completely fair so
that you would expect to come out even, you wouldn't either pay out more money than you
brought in or vice versa, having the people pay more than they paid, you would charge $1.87
in order to have this be a completely fair game. So in other words, a fair game is the
definition of a fair game is one where the expected value is exactly zero. In other words,
a person pays an amount so that the payout on average is expected to be exactly the amount
that they pay. So if you charge $1.87 for the start game, on average you would all come out
even everybody would be happy. Now roulette is not a fair game, as we saw because the expected
value is a negative number. And of course casinos would never have a fair game because
then they wouldn't have the expectation of winning money. So I'd like to finish this lecture
by looking at an example of unexpected example of expected value, the unexpected and expected
value. So here's what we're going to do. We're simply going to take a die and roll it many,
many times and we're going to look for fives. So the way we're going to do this is to
simulate it of course, and here's a simulation where we roll the die 6,000 times. So of course
we expect 1,000 of those to be fives, roughly. And here on this left hand column is the sequence
of numbers simulating, rolling the die 6,000 times. And at the top we record how many fives
we have. And we repeat the simulation, this time 997 and so on, number of fives always
close to 1,000 number of fives whenever we repeat the simulation. Now what we'd like
to do is to ask ourselves the question, what is the average gap between fives in that long
list of 6,000 numbers? Well the answer is simple, because since there are about 1,000 fives
and they occur every sixth time on average, the average should be about 6 as the average
distance between fives, and indeed it is. We see in this simulations that we always get
some number very close to 6. So let me ask you then a slightly different question, and
that is the following. Suppose that we take this long list of all of these numbers, 6,000
repetitions of rolling a number, and then just choose any point on that list between two
numbers, and ask ourselves how long is the gap between fives. So for example if we pick
this spot between these numbers, the gap is, well let's see, the 5 is the second number
to the right, the 5 is the seventh number to the left, so the gap has 8 units between the
fives where we find it. Now here's my question for you. If you randomly choose a gap between
this long list of fives, what would you guess to be the average length of that gap? Well
you probably think that we've already answered the question, that the average length of the
gap should be 6. Surprise, the expected value for the length of the gap should be, and is,
11. Not 6, it's 11. Okay, let's see why. If you choose a number at random between, and
what we've done here in this simulation is that this column shows us what the average
of the gaps is if we randomly choose a point between values. So if we, if we look here
for example, what this number represents is if we chose this gap between this 5 and this
3, then the total length of this gap is 5. Well likewise if we choose the gap between the
3 and the 4, the length is 5 again, 5 again, 5 again. Well why would the average of those
things be, be 11 rather than 6? Well the way to see this is by thinking in a, in a different
way. Namely suppose that we imagine putting down all of these long list of 6000 numbers
and taking a piece of string, this is red string, and we cut it to the lengths between the
consecutive fives. And then we put all of these in an urn here, it has to be an urn of course
in order to be in probability class. You put it in urn and then randomly choose a gap from,
from the urn. Well why are you more apt to choose a long string than a short string
if you make such a choice? The answer is because the long strings are more apt to be
selected. For example suppose you just had two strings in there, one had a length 11
and one had length 1. Then if you reached into the, to the urn and you chose any inch at equal
probability, you would choose the 11 inch one 11 times to every, every time you chose the 1 inch
one. So the average length of those strings would be closer to 11 than to 6, which is the
average of the length of those two strings, 11 plus 1 divided by 2 is 6. So, so that's the reason
that you're more apt to choose a long gap. If we look at this list of the gaps in our, in our
simulation, notice that whenever you have a gap like this gap has length 9, there are 9 9s that
appear because all of those 9 gaps, each of them has, has a gap of 9. And so if we get to a long
gap, here's one of 11, here's one of 16, and we're going to have 16 16s in a row. So we're more
apt to pick the long gap than the short gap. Another example of this would occur if you think about
waiting for a bus. Suppose that you're in a city where the, the concept of the bus line number 5 is
that it just appears one-sixth of the time, but just at random times. They don't go evenly spaced.
On average, it's every six minutes, but it doesn't, it just appears on a random minute. Well, then
if you go up to the bus stop and you ask somebody there, when was the last time that a number 5 bus
came? And that's a certain number of minutes. And then you wait to see when the next number 5 bus comes
and you say, well, that's the gap in the, in the length of time between buses. The expected value of that
gap is 11, not 6, even though the bus comes every six minutes on average. So I think this is a really
unexpected example of expected value. In the next lecture, we're going to be talking about random fluctuations
by taking a random walk. I'll see you then.
