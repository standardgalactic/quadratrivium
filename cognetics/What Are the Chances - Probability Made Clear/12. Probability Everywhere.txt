Welcome back. In this lecture, we're going to follow a road that often leads to interesting
ideas and that is the road of trying to understand what appears to be a paradoxical kind of
situation. And then in thinking it through, we develop an idea. In this case, our paradoxical
situation consists of imagining the following hypothetical kind of a challenge. Namely, suppose
that you were given the following game to play. You have two envelopes and you were
given these two envelopes and you shuffle them and choose one at random. And what you're
told about these two envelopes is that one of the envelopes contains a certain amount
of money and the other envelope contains twice as much money. But you don't know, and exactly
twice as much money, but you don't know which envelope contains which, of course. That makes
it fun.
So here you have the random envelopes and you just randomly close your eyes and you're
given an envelope and you open it up and you see how much money is in there. And here
we have D dollars. D dollars are in the envelope. Well, so you say, well, that's a great idea.
That's wonderful to have D dollars. But I'm told now that you have, so somebody gives
you the option of doing one of two things. Either you can keep the D dollars that you
are given in that envelope or if you would prefer, you could switch to the other envelope.
Now, of course, if you hadn't been watching this course, you would say to yourself, what
possible difference does it make? Because I don't know how much is in either envelope
and so it doesn't matter if I keep the one I have or change. But let's see if we can
think it through and we'll discover that we run into a sort of a paradoxical kind of analysis.
So having been in this course, you understand that one way to think it through is to imagine
an expected value analysis of what would happen if you switched. In other words, you
could say, if I switched, what would be the expected gain, the expected number of dollars
I would take home? Let's just go ahead and do this expected analysis and see what happens.
So here's the expected analysis. Now, the envelope that we opened had D dollars. The
other envelope has either two times D dollars or it has D over two dollars, half as much
money. So what we can do is do an expected value analysis. And here's the way we do
expected value. We've done it before. What we do is we say, well, since there's an equally
likely chance that it has either two, the other envelope has two dollars or that it
has D over two dollars, the expected value of switching is one half times 2D plus one
half times D over two. So let me review this and make sure you understand what this means.
This says that half the time you switch, you'll get the envelope with the larger amount of
money, 2D dollars, and half the time you switch, you'll get the amount of money with the lesser
amount D over two dollars. Well, let's just do the arithmetic. One half times 2D dollars
is D. One half times D over two is D over four. D plus D over four is five fourths D.
Now let's make sure that we let this sink in. What this suggests is that on average,
if you switch, you will make more money than if you stick with the original envelope that
you have. Now, I hope that I haven't found a way to have you completely abandon your
common sense. Your common sense tells you that this is ridiculous. It's ridiculous to
think that getting, you know, getting an envelope with D dollars, that it's always better to
switch because the reason it's ridiculous is because suppose you switched, then you could
imagine that that would have been the first envelope you took and then the same analysis
would have told you it would have been better to switch. So this is a paradox. This is a paradox.
What's wrong? There is something wrong. What is wrong with this kind of analysis? Well, so how
are we going to deal with it? The problem that's wrong is that we have an infinite number of possible
amounts of money in these two envelopes. That's what we're imagining.
And we're imagining that the probability of any of those amounts of money is the same.
You see, when we did the expected value computation, you remember how we did it? We said, well,
there's a 50% chance that the amount of money in the envelope is 2D and a 50% chance that the
amount of money in the envelope is D over 2. But the question is, is it really possible that every
amount of money is equally possible for the two envelopes? Well, so let's think it through.
The answer is no. It is impossible to imagine that the probability of any given amount of money in
the envelope is exactly the same as the probability of any other amount of money. And we can think
about it in a very practical way. Let's think about this as a real-life situation. Suppose somebody
literally gave you this envelope and asked you to undertake this experiment. I mean, literally,
a person that you know, that is to say, suppose that your neighbor comes over and you discuss this
thing and your neighbor says, well, let's just try it. And I'll put real money or a real check
that will actually be paid into the envelope. Well, the first thing you realize that it's not
going to be the case that that check will be for, say, $10 million. You have an expectation
for how much money will actually be in the envelope before you even open any of the envelopes.
You see? So the theoretical question of saying, well, there's any amount of money in the envelope
is possible is really not a practical question. Because in reality, you do, in fact, approach
this whole situation with an a priori bias about how much money is possible to be in the envelope.
So, for example, so what we can do is to, is to try to pin down what our bias is. So what we're
doing is we're harkening back to the Bayesian strategy of having an a priori distribution
about our sense of the belief of what's happening in the world. We don't believe that every single
possible dollar amount is equally likely. That's not what we really bring to the table.
Although at first when we first were confronted with this envelope problem,
we didn't think about saying, well, geez, I wonder how much is actually going to be in there. That
didn't come to our minds. But now that we see the paradox, it's forced us to confront the fact
that we must have inherited in us an a priori distribution of what we believe the possible
values in the envelope might be. So for example, suppose that we have this as our distribution
of probabilities of how much money is in the envelope. In other words, if we have, for example,
let's suppose that we open the envelope and there were $64 in the envelope. And the height
above that is indicating what the likelihood is that we assume a priori is the value that's likely
to be in the envelope, given the circumstances, who's paying the money, how rich they are,
and other circumstances like that. So we do have this a priori sense of how much could be in the
envelope. And the effect of having that sense is that the two probabilities associated with the
probability of the other envelope having twice as much money versus the probability of it's having
half as much money, is that those probabilities are not necessarily equal. And it, depending on
our a priori sense of what's happening, then we don't run into this expected value paradox.
Because in fact, by looking at the actual probability, given our a priori sense of the
likelihood of the twice as much money being in the envelope, then that will tell us whether or not
the expected value indicates that it's a good idea to switch. In this case, for example, where
there's $64, since the $128 has a smaller probability than the $32, then in this case, we might say,
no, it's more likely that the $32 is what's in the other envelope. And consequently, I should stick
with the amount of money I have. But it's based on using the expected value analysis,
which is completely correct, except using not the probability of one half, one half,
but of using the different probabilities according to our a priori distribution.
Now, by the way, there's another very basic point that's brought up by this issue of having
infinitely many possible values. In other words, even suppose we were just doing an abstract
mathematical issue of having a number in the envelope, it's impossible to have a nonzero
probability that is equal for infinitely many different things. Because if you add up the
probabilities of each possible outcome, like the probability of having between $1 and $2,
and the probability of having between $1 and $2 and $3, and between $3 and $4 and $4 and $5,
and so on, the sum of those probabilities has to add up to one. But if they're all the same,
you can't have an infinite set of numbers that are all the same and all above zero
that just add up to one, they would add up to infinity. So any probability distribution of
the number of the values in the envelopes has to actually taper off somewhere. Okay, so this was
the two envelopes paradox. I want to tell you another paradox that is involved with gambling,
that is a famous paradox that came in the early days of the discussion of probability,
and that is the paradox called the St. Petersburg Paradox. So this is a game that is played at a
casino, and it was imagined to be in St. Petersburg when it was originally proposed,
and the game was the following game. You just flip a coin, and here you flip a coin,
and if the coin comes up heads, you're paid $2. If the coin comes up tails, and then you flip
again and get a heads, that is the first heads is on the second flip, then you get $4. If you shake
tails, tails, and then heads, you get $8. Three tails, then a heads, $16, and so on. You see?
Now, the question comes, what is the value of playing this game? In other words, if somebody
were going to give you that payoff, you always make money, how much would you be willing to give
them in order to play the game? Well, the way that we have analyzed this before is to do an
expected value analysis. If we do it, here's what we find, that with 50% of the time, you'll get heads
the first time and get $2 as your payoff. A quarter of the time, you'll first get a tails,
then a heads, and you get a $4 payoff. An eighth of the time, you'll get tails, tails, heads,
and get an $8 payoff. And so on. Each of these is contributing a dollar. Therefore, the expected
payout is infinity. So, from the expected value analysis, it would appear as though you should
pay any amount of money to play this game, that it's a great thing. The paradox is that, of course,
it would be ridiculous to pay that kind of money. Because if you do, you'll find that you lose a lot
of money. A rational person would not pay very much money to play this game. And in order to
demonstrate that, we did some simulations. And so here's how the simulations go. We just played
the St. Petersburg game that is flipping a coin by simulation a thousand times. And we calculated
the average of the payouts per game over those thousand times. You follow me? So in other words,
sometimes we got $2, sometimes $4, sometimes $16, and so on. And we took the average of all those
different times we played, and we did it a thousand times, and took the average. We did that 10 times.
Then we did the same thing for 10,000 trials, and then 100,000 trials. So here are the results of
our simulations. The results are, when we played the game a thousand times, these are the average
payoffs that we got. There was one rather high one, $43, but the other ones were the most 20.
When we played the game 10,000 times, here are the average payoffs. No number was above $22.
Now remember, the expected value that we just computed was infinite. And yet here in reality,
we're getting average payouts of very small amounts. Here we go. Here's where we played the game 100,000
times simulated. And we simulated 100,000 repetitions, and we did those simulations 10 times.
You follow me? 10 times we did 100,000 sequences of flips of the coins until we got a heads.
Look at the payoffs of playing all of these times. Every number here, except for one, number two,
is $22 or less. Number two, by the way, had a single payoff of $2,097,152. So that was a case
where you flipped 20 tails in a row before you got a heads and paid off that amount of money.
Of course, you've got 100,000 attempts, and so these kinds of things will happen. 100,000
attempts repeated 10 times. So the St. Petersburg paradox is that although the expected value
is enormous, in practice, the amount that you would want to pay to play this game is actually
rather minimal. One resolution of the paradox is that if there's a maximum amount that the
casino has and will ever pay, even if you've shook many, many tails in a row, if there's a
maximum, then, in fact, you can compute an expected value that is very modest. For example,
if the casino will never pay more than $1,000,000, the expected payout is $21. If it'll never pay
out more than $1,000,000, the expected payout is $31. And if it's something approaching the
gross national product of the United States, not quite, then you would get an expected payoff
of about $44 million. So even though the expected value is enormous, in practice, you wouldn't want
to pay very much to play this game. Well, I wanted to now turn to the whole course in general and
say some things in summary about the whole course. And the first thing is about statistics. One thing
that this course has not done is to really talk about the major application area of probability,
and that is statistics, or maybe not the major one, but one of the most commonly
places where probability is applied is in statistics. Because probability is the central
driving force for making statistical deductions, doing statistical inference. And the reason is that
in statistics, the way that statistical inference works is that you see what would be expected
from probability, and then you compare it to the data that you actually collect. And if what you
get from probability is if your expectation that you deduce from a probabilistic analysis
differs greatly from what you actually see in the data, then you can make the deduction
that the concept that you had about how the data were being produced must be wrong. That's the basic
concept of statistical inference. However, we didn't spend time on that because we have another
course, the statistics course, that delves into that aspect of the application of probability a
great deal. So we just didn't want to repeat it in this course. But I didn't want to neglect,
I didn't want you to feel that that statistics is not an important application of probability.
So let me then conclude the course by making some general remarks. And that is that
probability is a fascinating field. And I think we'll all agree that it's fascinating,
and that it plays a fundamental role in how we understand our entire world. From games to science
to finance, we've seen probability apply in all these areas. And so in these last few minutes,
I want to look back on the whole course and somehow point out some of what I see as the overall effect
of what we've seen. And to me, the bottom line is that randomness and uncertainty are fundamental
parts of our experience of life. And the role of probability plays is to describe in quantitative
detail what we can expect from that randomness and that uncertainty. Well, one of the recurring themes
that we saw throughout the course, in fact, even including in today's lecture about the two envelopes
in the St. Petersburg paradox, one of the recurring themes was that randomness and probability
often confront us with situations that are very counterintuitive. For example, we saw that in
97% of the cases, there's a 97% probability that if you're in a room with 50 random people,
then at least two of them will share the same birthday.
We saw that it was better to switch. If we ever get on a revival of the let's make a deal show,
let's make sure that we switch. And we saw these really bizarre things like the bizarre influence
on the probability of having two boys. If you know that if a stranger comes up and has two children
and you say, oh, well, one of them was a boy born on a Tuesday, that somehow knowing that
it was born on a Tuesday changed the probability that that person has two boys as their children.
That was bizarre. And these probably all of those examples probably all seem simply wrong at first.
But then the question that I want to bring up now is, what should we make of these kinds of
examples? And the answer is this, that when our intuition doesn't accord with reality,
then one of those two things our intuition or reality has to give. And what has to give
is our intuition. You see, in all of these cases, the probabilistic analyses that we did
were correct. And they really do predict what actually would happen in the scenarios that
we described. So when we are confronted with a situation where our intuition is jarred,
it's because our intuition needs to be retrained. And that's the purpose of these really, what I
view as wonderfully thought provoking conundrums. They challenge us. They challenge us to rethink
the things that are actually mistaken biases. Our intuition is mistaken. But when we come to
understand the correct descriptions of the results, and we really understand the analysis,
then what we should do is to act according to this more accurate view of the world.
So after we've adjusted our understanding to see the truth of even these things that originally
have appeared to be completely counterintuitive, these examples that are so counterintuitive,
but after we come to understand them, then the probability results are ones that we can actually
make reliable decisions on. I mean, it literally is really true that if you are in a room
with 50 random people, it's almost certain that at least two of them will have the same
birthday. And you can make bets on it and win bets. So it really is descriptive of the way
the world actually operates. Well, probability gives us a practical and a logically sound way
of quantifying uncertainty. And it's up to us to understand and to accept its results,
and to realize that these probabilistic descriptions of reality really do meaningfully
give us guidance about what to expect. Many of the ideas that we introduced about probability
were illustrated in the realm of gambling. And that's because gambling games are fundamentally
based on probability. Casinos count on probability to ensure their success. And casinos can reliably
count on profits based on expected outcomes of random trials. They're conspicuous examples of
the confidence that we can place on the fact that random events are not, even though they're
not determined individually, but in the aggregate, random events, if they're repeated many, many
times, will display a regularity that can be completely relied upon. In other words, casinos
are the modern world's testament to the law of large numbers. You'll recall the law of large
numbers states that if you repeat a trial that has a random outcome many, many times, the experiments
will exhibit the predictions of probability with ever increasing accuracy. But the fact that random
behavior results in regularity in the aggregate isn't just a central feature of games of chance
and gambling and casinos, but it really is the center feature of our serious scientific understanding
and our descriptions of nature. The scientific view is that we view every breath of air we take
as being composed of countless molecules moving about in ways that we couldn't hope to describe
molecule by molecule. If we think about the second law of thermodynamics, we imagine a box
that has hot molecules on one side and cold ones on the other, and the hot ones are faster moving
and the cold ones are slower moving on average, and then we remove the partition and we're trying
to describe what happens. Well, we don't describe it molecule by molecule. The directions and the
speeds of the molecules are far too numerous to count and describe. We couldn't hope to do it that
way. Instead, we just abandon that idea of describing what happens as a deterministic system determined
by the speeds and directions of each individual molecule, even though that's actually what's
happening. But instead, we describe the interactions as what will be expected by as a result of a
probabilistic description of random motion and where, of course, we put the appropriate constraints
that describe the molecular behavior, you know, on what the distribution of fast molecules and
slow molecules are. Now, there is a different branch of chemistry and physics that actually
describes how single molecules interact with other single molecules. But if we want to know what
happens if we stir a liquid into another liquid, the result is described by probabilities.
Well, in no scientific arena is the role of probability more central than in the science
of genetics. And that's because the whole premise of the subject is that parts of the genetic material
from each parent are randomly donated to the offspring. So the challenge of genetics is to
understand what actually to what we can expect from random combinations of that sort. Well,
the results are challenging. They're challenging to understand because although they have probabilistic
regularity, such as, for example, we saw expressed in the Hardy-Weinberg equilibrium theorem,
it tells us that we can expect a certain kind of stability on average. And yet the random walk of
genetic drift tells us that we have to expect deviation from that stability by randomness alone.
But when we learn that, we shouldn't throw up our hands and say, oh, so randomness and
probability tell us nothing because anything might happen. No, that's just not true. On the contrary,
our knowledge of probability lets us understand and put into perspective the challenging blend
of probabilistic regularity along with a deviation from that regularity. And that
deviation occurs at an expected frequency and at an expected rate. And so just like we can't
know when we throw a die whether it'll come up a three or not. But there's a specific meaning to
say that there's only a one sixth probability of it's coming up a three and a five sixth probability
of it's not coming up a three. And that insight is something that we can rely upon. Probability
gives us definite insights. It gives us insights into what will happen over generations to populations,
characteristics, and probability can be used by the way to model all sorts of other things in the
biological realm, such as, for example, the spread of diseases is an example.
Well, of course, it's expected that probability would play a central role in descriptions of our
financial world and investments, because investments are viewed as having a probability
of rising or a probability of falling. So devising an optimal portfolio, advising what it really
involves is to optimize some measure of the probability of its being successful. But unfortunately,
that entails the uncomfortable reality that truly excellent decisions may, by chance alone,
have unfortunate outcomes. And so recognizing the role of randomness and probability in our
everyday lives puts a really challenging perspective on how we might react to successes and failures
that entail a probabilistic component. You know, good decisions can have bad outcomes
by chance alone. And that's one, I think, of the difficult parts of the nature of probability.
It's one of its greatest challenges philosophically. Well, one of the most fundamental sources of our
uncertainty about the world is that often we don't know what's really true among several
possibilities. For example, if we sit on a jury, we don't know whether the criminal in front of us
is innocent or guilty. But instead, we have a sense that there's some likelihood that the person is
guilty and some likelihood the person is innocent. And as evidence is adduced at the trial, our
relative confidence in the guilt or innocence of that person shifts. And the strategy that
Bayesian probability describes is that it looks at the relative strengths of our beliefs,
and it sees how those strengths are altered by evidence. It models a basic experience of life,
namely what uncertainty really is. It talks about what that is, namely you're giving a probability
to different possible states of the world, and it shows how our beliefs change when we get more
evidence. To me, the cumulative effect of the whole course is to underscore the reality that
randomness and uncertainty are fundamental parts of reality. Probability describes what we should
expect from randomness. And consequently, probability is a basic tool for making sense of
and coping with the reality of randomness and uncertainty. By its nature, probability forces us
to confront directly two very different fundamental views of the world. And so I want to show you two
quotes, thinking that there's a good probability, a good chance that you'll like one of them. And
both of them are from ancient Greece. So in fact, neither of the speakers reflects the modern
centrality of probabilistic thinking in the descriptions of our world, but they do capture
a philosophical dichotomy about the nature of reality. So here are the two quotes.
Lucipus said, nothing occurs at random, but everything for a reason and by necessity.
Democrates, everything existing in the universe is the fruit of chance.
So to end this course, I think we should once more put probability to the test and see if it works.
So let's once again take our 60 dice, roll them and see if we can have probability randomly
show us some regularity. Here we go.
Thanks for watching. Bye for now.
