In this lecture, we branch off to describe a special kind of graph.
These graphs are called trees, and they arise in many real-world problems, from finding
the best paths in a network to the efficient storage of data.
Here is the definition of the day.
A tree is a connected graph with no cycles.
So here is an example of a tree.
It's obviously connected.
It obviously has no cycles.
Here's a non-example.
This graph G is not a tree, but it does have connected components, I'm defining that word
right here, that are trees.
So this graph here has four connected components.
By the way, a graph that has no cycles, whose connected components are trees, we call that
naturally enough a forest.
There are some textbooks out there, by the way, that first define a forest as a graph
that doesn't have any cycles, and then they define a tree as a connected forest.
Though I think that's backwards.
I think the tree has to come before the forest.
Okay, before we get into theorems about trees, I want to count them, alright?
I like combinatorics.
How many trees are there that have exactly N vertices, and will label those vertices
one through N?
Let's call the answer to that combinatorics question, T sub N.
Now before we answer that, I have to clarify, what do we mean when we say that two graphs
are equal?
Officially, two graphs are equal if they have the same vertex and edge set.
So for example, these first two trees, both labeled one, two, three, and four, they have
the same vertex set.
Now are they the same tree?
They look different, right?
At the bottom, the three and four goes left to right, and then on the other one it goes
right to left, but they have the same edge set.
Both of those have the edges one, two, two, three, and two, four.
Similarly, the third tree on our list also has edges one, two, two, three, and two, four.
But the fourth tree on our list is not the same tree because it has an edge like one,
four, which was not an edge in the earlier trees.
So those last two graphs are not equal, but they obviously have the same shape, and we
use a mathematical term to describe that.
They're called isomorphic.
For all intents and purposes, they're the same, but they're not formally exactly the
same.
So let's answer our question.
How many trees have exactly n vertices labeled one through n?
So t1, the number of trees on one vertex, that's one.
T2 is also one, right?
You have an edge that goes from one to two.
T3 is three because every tree on three vertices looks like a simple path, right?
That's the only way you can draw a tree, but those three trees will be different according
to what the middle vertex is.
Is it one or is it two or is it three?
There are three trees.
Another way you can get three trees, by the way, is you could say, well, if order mattered
as I went from left to right, how many ways could you label that path?
Three factorial, right?
Three choices for the first vertex, two for the second, one for the last.
But every tree is the same as the tree that you get when you flip the tree around.
It still has the same set of edges, but whether I look at the tree that goes one, two, three,
or the tree that goes three, two, one, those are the same tree.
So you could quickly say we have three factorial over two, that is three trees on three vertices.
How many trees are there on four vertices?
Well, let's see.
Key four, when we have four vertices, we have the path graph, right?
And how many ways can I label a path graph on four vertices?
Four factorial over two, which is 12.
Okay, and what other kind of tree structure can I have with four vertices?
I can have something that looks kind of like a star, right?
With a one point in the middle that's adjacent to the three other points.
And how many different trees are there?
Well, that's all going to depend on what vertex goes in the middle.
So either it's vertex one that's adjacent to everything else, or two that's adjacent
to everything else, or three, or four, so there are four trees like that.
So therefore, and are there any other shapes of trees that we can create?
Either it looks like a path, or it looks like a star, and that's it.
I don't know of any others.
So the total number of labeled trees is 12 plus four, which is 16.
Okay, what happens when we have five vertices?
Then what kinds of shapes can we have?
Now there are three different kinds of shapes.
It can either be a path graph on five vertices.
It could be a star with a vertex in the middle, or it could be this kind of T-shaped graph.
How many paths are there on five vertices?
By our earlier logic, five factorial divided by two, which is 60.
How many star graphs?
There are five choices for what vertex goes in the middle, and then one way to finish
everything else off, so there are five star graphs.
And how many T-graphs are there?
Well we've got five choices for that vertex with degree three, and then it's got three
neighbors, one of which has degree two, so there are four choices for what that neighbor
is going to be, and then there's another neighbor that's adjacent to that one.
There are three choices for what goes there, and then we're essentially done, because it
doesn't matter how I label the other two, they're going to be the same tree.
And so there are five times four times three, 60 ways to 60 trees on five vertices that
look like a T, all together there are going to be 60 plus five plus 60, 125 different trees
on five vertices.
So question, how many trees are there with N vertices?
Let's look at the pattern.
When the number of vertices went from one to five, my answers were one, one, three, 16,
and 125.
Do those numbers look at all suspicious?
When I see 125, I can't help but think five cubed, five to the third power, and then I
notice the number behind it is 16, which is four to the second power, and behind that
is three to the first power, two to the zero power, we even have one to the negative one
power.
Putting this all together, we're inclined to believe Cayley's theorem that says that
the number of trees on N vertices is N to the N minus two power.
The proof is pretty tricky, so we're not going to do it in this course.
The next definition I want to give you is, in a tree, a vertex of degree one, a vertex
that's only adjacent to one other part of a tree, is called, naturally enough, what would
you guess, in a tree, a leaf, right?
A leaf is a vertex of degree one.
So does every tree have a leaf?
You betcha.
In fact, that's what the next theorem says.
Any tree with at least two vertices has at least one leaf.
All right, here's the proof.
Suppose not.
The tree is connected, right, so it can't have any vertices of degree zero, and if it
doesn't have any leaves, then it can't have any vertex of degree one.
Well, that would mean that every vertex would have a degree at least two.
But then, if every vertex has degree at least two, as we saw in our proof of the Eulerian
graph theorem, there would have to be a cycle in your tree.
But trees are not allowed to have cycles.
Therefore, there has to be a vertex of degree one.
There must be a leaf.
That's a theorem so nice, I'll prove it twice.
Here's another way to prove the theorem.
It's using what we call an extremal argument.
So in fact, I'm going to prove something twice as strong.
I'm going to prove that every tree has at least two leaves.
Now there's another quick proof of that.
You could take the one leaf that you found in the last proof and just keep on walking
until you reach a dead end, and that would be the other leaf.
But here's a proof using an extremal argument.
Here in your tree, a longest path in T. That is, just find the longest path that you can
in the tree.
There might be several.
There might be a tie for such honors.
Just pick any path that has the longest length.
Okay, let's say it has length k.
Let's say it uses vertices v1, v2, up to vk.
Then I claim that the vertex v1, and by the same reasoning, the vertex vk, must be leaves
of the tree T. Why?
Well, we know that v1 is adjacent to v2.
I claim it can't be adjacent to anything else.
For instance, it can't be adjacent to v3 or v4 or vk, because then, if it was, we would
clearly have a cycle.
On the other hand, v1 can't be adjacent to a vertex that's not on the path, because
if it was, let's say it was adjacent to some vertex v0, say then v0, v1, v2, up to vk,
that would be a longer path, contradicting the assumption that you started with a longest
path.
Therefore, v1 is only adjacent to v2.
Therefore, v1 is a leaf, and by the same logic, vk is a leaf.
Here's a useful observation that we will exploit, namely, if you have a tree and you
remove any leaf from the tree, and the one edge that it has, then the resulting graph
is still a tree.
Here's a tree, there's a leaf, remove the leaf, and you still have a tree.
Next I claim that every tree with n vertices has exactly n minus 1 edges.
I'm going to prove this by induction on n.
You might say I'm using the technique of leaf extraction to prove this.
Every tree with n vertices has n minus 1 edges.
Clearly it's true when n is 1 or 2, so we can see that clearly.
Next we state our induction hypothesis, assume that a tree with k vertices has k minus 1 edges.
Now consider a tree that has k plus 1 vertices.
Remove a leaf v and its one edge.
The resulting graph, which I'll call t minus v, is still a tree, but now it has k vertices.
And by the induction hypothesis, a tree with k vertices has k minus 1 edges, therefore
the original tree had to have k minus 1 plus 1 edges, which is k edges, and that concludes
our proof.
Trees are often used as efficient data structures where information is stored at the vertices.
Sometimes raw data is only stored at the leaves.
For example, when you call someone on your cell phone, you're actually a leaf in a giant
tree.
Your number is picked up by a tower that communicates your number to another tower and another and
another until it reaches the top of a tree, called the root, and then it finds the person
you are trying to reach who is another leaf on the tree.
Trees make excellent data structures for storing words in a dictionary.
Trees you wanted to create a glossary of key words from this course, the discrete mathematics
course.
Such a list might look like this.
Here are several words that I hope you've learned to appreciate in the discrete math
course.
Now if you listed them out this way, you'd see there are 15 words on this list, and
if you or your computer search the list to find a given word, it could take anywhere
from one step to 15 steps with an average of eight steps.
On the other hand, it's more efficient to organize your data in the form of a binary
tree like this one.
I have the same 15 words organized in this tree, and you'll notice that to find, so if
you take a look at this tree, you'll notice that say at the top of the tree we have the
word graph, and every word to the left of graph is smaller, comes before it alphabetically,
and every word to the right of graph is greater than it alphabetically, and that's true of
every vertex.
When you look to the left, your words come before it in the alphabet, when you go to
the right, they come after it in the alphabet.
So to find a word, you would start at the top of the tree, and if your word comes before
the current word alphabetically, then head down to the left.
If it comes after the word, then go down to the right.
Once you find your word, then stop.
For example, if I'm searching for the word Fibonacci, I compare it with the word graph,
okay, Fibonacci comes before graph, so I go to the left.
Then I compare it with discrete.
So Fibonacci comes after discrete alphabetically, so I move to the right.
That puts me at Fermat, alright, so Fibonacci comes after Fermat, so I move to the right.
Then I find myself at Fibonacci, and I'm happy.
This is, by the way, a lot like the way that you would actually search for a word in a
large dictionary.
You wouldn't go one page at a time from left to right, instead you'd start near the middle,
then you'd flip pages back and forth, back and forth, until you found the right page
of the dictionary.
Notice that it only took four steps to find Fibonacci, and that's the worst case.
You might have, you know, that you'll never take more than four steps in that tree.
As opposed to the list data structure, which took an average of eight steps.
So for large amounts of data, the comparison is even better.
With about two to the end data points, the binary search takes about n steps compared
to the list, which can take about, on average, two to the n minus one steps.
The following theorem is useful for communicating between vertices.
If T is a tree, then I claim that any two vertices on the tree, we know they're connected,
not necessarily by a single edge, but by a path, where we know that there's a way of
walking from X to Y, I claim there's a unique path that takes us from X to Y.
Here's the proof.
Let X and Y be vertices of the tree.
Since T is connected, we know that a path P exists from X to Y.
Okay, here's an abstract sort of path.
Now can there be another path, let's say Q, that goes from X to Y?
Like this.
Well, no, because if there was, that would create a cycle in T. You could see one giant
cycle.
Now in this picture, P and Q have no points in common except for X and Y. So the cycle
there was easy to see.
If they did have points in common, you'd still have a cycle, but it would be a smaller one.
Given a graph G, any tree inside of G that uses all the vertices of G is called a spanning
tree.
So for example, the graph shown here has several spanning trees, and I've shown them below.
Next, we want to consider a very important and practical problem called the minimum spanning
tree problem.
Consider a weighted graph like the one we have shown here.
This could be a network of roads or computers, and the weight of an edge could represent
the cost of traveling from one city to another, or paving a road between houses, or maybe
the cost of getting two computers to communicate.
We'd like all of our points to be able to communicate with each other, but we want to
be as efficient as possible.
So we don't need to include every single edge, and for maximum efficiency, we wouldn't want
to have any cycles because an edge from a cycle can be removed and everything would
stay connected.
The algorithm I'm going to show you to solve this problem was originally developed for
telephone networks at Bell Laboratories.
It's called the spanning tree problem.
Find a spanning tree, a tree that connects all the vertices of G that minimizes the
sum of the weights of the edges.
For example, let's find a spanning tree in the graph.
Here's a quick one.
One way would be to connect all the vertices like this using this Hamiltonian path.
It's kind of S-shaped, like that's a tree, it's a spanning tree, and if we add up the
weights on all the edges, we get 44.
Can we do better?
Here's another spanning tree.
It's not a Hamiltonian path, it kind of looks like a W there, and it's right, we're using
all nine vertices, there should be eight edges in that spanning tree, and when we sum up
the weights on this one, we get a total cost of 43.
Can we do better?
Let's try and be more systematic.
We know that a tree on nine vertices has to have exactly eight edges, our spanning tree
is going to have to have eight edges, so why don't we just choose the eight cheapest edges,
the edges with the smallest weights on them, the smallest costs, and be done with it.
Choose the eight cheapest edges.
There we go.
Unfortunately, if you do that, in this example, you don't get a tree.
You see, we've got at least one cycle in this graph.
I see an isolated vertex over there, so nice try, but no tree.
All right, here's a better idea.
Let's proceed by a greedy algorithm.
Let's still try to choose the eight cheapest edges.
We're going to go one at a time from cheapest to most expensive, and we're just going to
keep taking and taking and taking, except we won't take an edge if it creates a cycle.
We're just going to be greedy, except when we create a cycle, in which case we'll skip
over it and we'll try something else.
For example, in this graph, let's see, I'll take the cheapest edge.
I've got two edges with weight one, take either one, literally either one.
You picked one.
All right, now what's the next cheapest edge?
Oh, it's the other one.
Okay, we'll take that.
And then let's see, I'll take one of those twos.
I'll take another one of those twos, and now let's see, I've got a three, but can I take
the three?
I can't take the three because that would create a cycle with that one and two.
So I'll permanently ignore that one, and next I'll go to the four.
Okay, I can take that, that doesn't cause a cycle.
How about a five?
Well, if I take that five there, that would create a cycle with the one, two, four, so
I can't do that one.
If I take that five there, no, that would create a cycle with the two and the four, so I can't
take that one either.
Okay, next we go for the six.
I can take that, that doesn't create a cycle.
The seven, no, that creates a cycle.
How about the eight?
The eight, eight is great, I can take that, no problem.
How about the nine, no, I don't think so.
That nine creates a cycle, yeah, with the one and the eight.
And the 10, I can't choose this 10 because that would create a cycle, but I can take
that 10, that won't create a cycle.
Phew, I've chosen eight edges, and let's see how I've done, all right?
It's a tree, it's a spanning tree, there are no cycles in this graph, it's connected.
And the total weight of this one is 34.
Question, is our spanning tree optimal?
The answer is yes.
Will this approach always produce a minimum weight spanning tree?
Again, it may surprise you, but the answer is yes.
The greedy algorithm that we just went through, also known as Kreskel's algorithm, works every
time.
And if you don't believe me, here's the proof.
Now, in my proof, I'm gonna suppose that all the weights of the edges are different.
If any of the weights aren't different, we can tweak them by a tiny amount, and that
won't change the answer.
Okay, so here we go.
Suppose G has N vertices.
Then the greedy algorithm will create a tree, T, with edges E1, E2, and so on, where the
weight of the first edge will be strictly less than the weight of the second edge it
chooses, and so on up to the last edge that it chooses.
I claim that this, the greedy tree has minimum weight.
Proof by contradiction.
Suppose to the contrary, there is a tree, T, star, with smaller weight.
So the star means I'm the best, I'm the cheapest tree around.
I'm gonna prove that that is impossible.
Let's let EK be the first edge in T, the greedy tree, that's not in T star, okay?
So T star has edges E1 up through EK minus 1, but it doesn't have EK.
So now we insert EK into T star to create the graph T star plus EK.
This graph will have a unique cycle C.
Now there must be an edge E star on the cycle C that's not E1 or E2 or EK minus 1 or EK.
Why?
Because otherwise that cycle would be in T, and we know that T doesn't have any cycles.
Now by the greedy algorithm I claim that the weight of EK is less than the weight of E
star.
Why?
Because our greedy algorithm, after it chose E1 through EK minus 1, it could have then
chosen E star.
But it, I mean it could have, right?
Because it wouldn't have created a cycle because T star has E1 through EK minus 1 and E star.
So it could have chosen E star, but it didn't.
Instead it chose the edge EK.
Why did it do that?
Well because it's greedy it must have been because the weight of EK was less than the
weight of E star.
So now if we remove E star then the cycle C disappears and we have a new tree T double
star whose weight is the weight of T star plus the weight of EK minus the weight of E star.
And since the weight of EK is less than the weight of E star, then T double star has a
smaller total weight than T star, contradicting the assumption that T star, despite all its
bragging, was the minimum spanning tree.
And that's the proof.
A minimum spanning tree is found every time by the greedy algorithm.
Speaking of spanning trees, here's another combinatorial graph theory problem with a
beautiful answer.
Suppose we're given a graph G, like the one below, and we wish to know how many spanning
trees it has.
Now there's a beautiful answer that depends on the adjacency matrix of G and something
called the determinant.
The determinant of a matrix is a number that reveals a lot of information about a matrix,
most of which we won't go into here.
The determinant of a 2 by 2 matrix, ABCD, is very easy to compute.
It has determinant AD minus BC.
The determinant of a 3 by 3 matrix is trickier, but it's still not too bad, and we present
the formula here.
Now one way to remember it is if you put two copies of the matrix side by side, then the
determinant is the sum of these three products, AEI plus BFG plus CDH, minus the sum of these
three products, GEC, HFA, and IDB.
The formula for the n by n determinant is much more complicated.
It's the sum of n factorial over 2 products minus the sum of n factorial over 2 other
products.
Although when n is bigger than 3, there are quicker ways to compute the determinant without
using its formula.
Okay, it turns out that the number of spanning trees in a graph is just the determinant of
a particular matrix, and I'll tell you how to create that matrix.
Suppose that a graph G has adjacency matrix A, we've run into the adjacency matrix before.
Let D be the diagonal matrix where the i-th number on the diagonal is the degree of vertex
I, and everything else in the matrix is zero.
For example, the graph we saw earlier that had eight spanning trees has this diagonal
matrix and this adjacency matrix.
Now, here's the cool part.
Create the matrix D minus A. So in this example, here's our D matrix, there's our A matrix,
there's the matrix D minus A. Now, D minus A, the rows, every row is going to sum to
zero like we have here.
It turns out because of that, the determinant of D minus A will always be zero.
But if we remove the last row and the last column of D minus A, then believe it or not,
the determinant of that matrix is always equal to the number of spanning trees of G.
So here's our D minus A matrix.
We get rid of the last row and the last column, that gives us a three by three matrix and
adding up and subtracting our products, let's see, two times three times two is 12, plus
negative one times negative one times zero, that's a zero, plus I got another zero, minus
the sum of zero plus two plus two, and that gives us eight, which is the number of spanning
trees of G. There's our graph G, there are its eight spanning trees and it's counted
by that determinant.
The good news about trees is that they're very efficient.
The bad news is that they're very vulnerable.
If any of your edges break, the graph becomes disconnected.
Thus, when designing a network, it's generally a good idea to build in some redundancy so
that everything can stay connected while some items are being repaired.
For example, we might allow some cycles or allow more than one edge to connect two vertices,
but a minimum spanning tree provides an efficient foundation on which to build your network.
I'd like to end this lecture with a poem that I wrote just for this occasion.
I call it Trees.
I think that I shall never see a graph lovely as a tree, where every leaf stays on the
tree, although it's cold out one degree.
And if two points would like to speak, they always can, and it's unique.
Theorums are proved by fools like me, but only graphs can make a tree.
