Lecture 12 Instances and Consequences
The good news is that for now we get to stop banging our collective head against the old
and new riddles of induction.
The bad news is that we turn to a different and equally frustrating basic set of problems
concerning the positivist notion of an inductive logic.
We've been assuming that a sample of copper that seems large and varied to us, all of
which conducts electricity, counts as evidence for all copper conducts electricity.
And we've been having a surprisingly hard time explaining why that should be evidence
for that statement.
So let's back up to the notion of evidence itself and see whether we can use the tools
of logic to make any sense of this notion.
The positivists were looking for a logical relationship between an observation statement
and a hypothesis, typically the hypothesis will be of that standard all F's RG form
like all copper conducts electricity, such that the observation statement provides evidence,
maybe not much evidence, but at least some evidence for the hypothesis.
And Carl Hempel led the way for the positivists on this issue.
The most straightforward answer is provided by something called the instantial model.
It says that an F which is G counts as evidence for all F's RG.
So an observed black raven counts as a piece of evidence for all ravens are black.
What could be simpler?
This is as basic an approach to the notion of evidence as you're going to find.
As obvious as this theory seems to be, it runs into surprising trouble very quickly.
The paradox of the ravens due to Hempel seems to show that this model allows almost anything
to count as evidence that all ravens are black, and in fact it gets a little worse than that.
The first thing to realize is a point of logic.
All ravens are black and all non-black things are non-ravens, that's a mouthful, are logically
equivalent.
This means that as standardly rendered in logic, they are true under exactly the same conditions.
What both sentences do, as standardly interpreted, is forbid non-black ravens.
And that's all they do, so if one of them is true, the other is true.
This is not to say that they are equivalent or interchangeable for all purposes.
Not only is one of them a lot easier to say, it seems to have a different emphasis than
the other.
All ravens are black seems to be about ravens, while all non-black things are non-ravens
seems to be about non-black things.
But this sense of aboutness isn't part of what the sentences say, it's part of what
we do in saying them.
If you say something sarcastically like, what a great party.
What you're doing with the words might be quite different from what the words themselves
say.
So in our case, if you say all ravens are black, you are directing the listener's attention
first and foremost to ravens, while if you say all non-black things are non-ravens, you're
directing the listener's attention first and foremost to things that aren't black.
But both sentences, strictly speaking, are about everything in the universe, and both
of them say that everything in the universe is either black or is not a raven.
In that sense, they say the very same thing.
And since confirmation for Hempel and the other positivists is a logical relation that
holds among statements, it's concerned with what the statements say, not with what we
use them to do.
And so Hempel suggests that it seems to be a reasonable constraint on the notion of
evidence that if a piece of evidence confirms a hypothesis, it confirms any logically equivalent
hypothesis, any hypothesis that says the very same thing.
He calls this the equivalence condition.
And it seems natural enough, since the hypotheses are either true together or false together,
it seems that evidence for one is automatically evidence for the other.
You can't get evidence for either the Yankees or the Red Sox will win the division that
isn't at the same time evidence for either the Red Sox or the Yankees will win the division,
because those two statements say the same thing.
Evidence for one is automatically evidence for the other.
But this, combined with that very straightforward and intuitive, instantial model of confirmation,
seems like enough to get us into trouble.
Because by this equivalence condition, any non-black, non-raven is evidence for all ravens
are black.
Since those statements are equivalent, evidence for one is evidence for the other.
So a white swan is evidence for all ravens are black.
And so is a yellow pencil.
And so is a red shirt.
And any non-white, non-swan is also evidence for all swans are white.
So the yellow pencil and the red shirt are also evidence that all swans are white.
As Nelson Goodman quipped about this problem, it opens up wonderful prospects for indoor
ornithology.
And things get worse.
Since any non-orange, non-raven is evidence for all ravens are orange, we can get lots
of cheap evidence for that statement, too.
So by similar principles, we can confirm all ravens are purple, and for that matter all
philosophers are penguins, or just about whatever you'd like.
Now many of these statements we already know are going to be false, so getting evidence
for them won't make them seem well supported, but that's not the point.
The point is that this very straightforward and intuitive instantial model seems to permit
almost anything to confirm almost anything.
It seems much too weak, much too permissive.
Many responses to this paradox have been offered, and some of them actually are quite
promising.
This gives you more hope than wrestling with the grue problem.
Hemple's surprisingly direct approach is pretty much to accept all of the premises,
but to deny that there's a paradox here at all.
The way Hemple says it can make it sound a little crazy.
What he says is it's just a psychological illusion stemming from our mistaken sense
that all ravens are black is only about ravens that makes this seem paradoxical to us.
Once we see, Hemple says, that the hypothesis is really about all objects in the universe
will actually be able to accept this surprising sounding idea that a yellow pencil is evidence
that all ravens are black.
After all, says Hemple, if you could survey every non-black object in the universe and
could see that there are no ravens among them, then you'd have conclusive evidence
that all ravens, if there are any, are black, because you've checked every non-black object
in the universe and found no ravens among them.
So in that sense, you are piling up evidence that all ravens are black when you examine
a yellow pencil.
So Hemple says we're letting background information about how many ravens there are in the universe
compared to how many non-black things there are in the universe.
And that causes us to have intuitions according to which the yellow pencil isn't evidence
that all ravens are black.
But that background information isn't legitimately appealed to in a logic of confirmation, which
is supposed to be a formal relationship between the evidence, statements, and the conclusion.
So Hemple thinks this is not such a bad result at all.
It's easier to get on board with Hemple if one talks, as Hemple does not, about degree
of confirmation.
He only talks about whether a statement confirms another.
He doesn't talk about how much.
Maybe it's not so weird as it originally seemed, anyway, if we want to say that a yellow pencil
does provide a tiny, tiny bit of evidence for all ravens are black, but much less than
a black raven does, and keep in mind that finding one black raven does not provide very
much evidence that all ravens are black.
And by the way, all ravens are not black.
Just a traditional philosopher's example.
Even though Hemple does have an intuitively acceptable solution to the paradox of the
ravens within his own framework, many philosophers have drawn a different moral from the problem.
They think that the problem provides good reasons for rejecting Hemple's project, his
notion of a logic of confirmation.
One common such approach argues that whether a yellow pencil confirms all ravens are black,
and even whether a black raven confirms or provides evidence for all ravens are black,
depends on how the information gets collected.
If we first notice that an object is black and then discover that it's a raven, that
observation on this view does not actually confirm our hypothesis.
Why not?
Because a method of checking black things to see whether they are ravens could never
turn up a non-black raven.
You're only checking black things.
You'll never turn up a non-black raven if there are any.
So the idea is that evidence can't confirm or support your hypothesis, unless it's the
kind of evidence that has a chance of falsifying or disconfirming your hypothesis.
So this has loose affinities with a Popperian approach.
But we saw that Popper does not himself believe in the idea of confirmation at all, since
we can't solve the old Rital of Induction.
Similarly, if we first discover that an object is yellow and then notice that it's a pencil,
kind of a weird example, but if it's a pencil it can't be a raven, so that observation does
count in favor of our hypothesis.
Because had the yellow object been a raven, our hypothesis would have been disconfirmed
or maybe even falsified.
But if we first learn that an object is a pencil and then learn that it's yellow, that
observation has no bearing on our hypothesis at all.
If you approach confirmation and evidence this way, you're rejecting Hemple's conception
of evidence as a logical relationship that holds among statements.
The idea behind Hemple's project is that background information, the order in which
information gets received, these sorts of things don't matter to confirmation.
This can be illuminated by looking at the case of deductive logic.
It doesn't matter in what order or how you learn that Socrates is a man and that all
men are mortal.
Once you know those things, you have enough to know and to show that Socrates is mortal.
Hemple's looking for something like that in the domain of empirical confirmation.
Now maybe that's too ambitious, maybe nothing like that is in the cards.
But notice that Hemple does himself have a solution to the raven paradox that looks
like it might work pretty well.
So this is a maddening philosophical problem that actually maybe we can solve.
It threatened the instantial model with disaster, with letting anything confirm anything.
But maybe the raven paradox does not in fact show that the instantial model is too permissive.
Surprisingly though, the model suffers from being too restrictive.
Whether or not it lets in cases of confirmation that should be kept out, it seems to keep
out some cases that should be let in.
As written, the model does not allow for confirmation of hypotheses that have any logical form other
than that familiar, all FSRG.
Now we've granted in our discussion of Popper that statements of that form are the most
important ones for doing science, we'd like our theory to allow us to get evidence for
statements of different logical form, like there is at least one egg laying marsupial,
the platypus, and every metal dissolves in some acid.
These are statements that have a different basic logical form than the standard all FSRG,
and the instantial model only applied to the all FSRG statements.
Even more seriously, the instantial model only applies to statements that have observable
instances.
It is predicated on the idea that we can look and see whether we're dealing with an F that
is G or not.
This is a problem that is perhaps starting to sound familiar by now.
Many crucial scientific statements don't connect to observation as directly as that.
There's no way to look and see whether all top quarks have a mass equal to that of 189
protons or not.
We'd like to be able to get evidence for a statement like that.
But we can't just look and see whether it's true.
So this problem about logical form and more seriously about unobservable objects, not
the much flashier Raven paradox, is the main reason the instantial model has been rejected.
The hypothetical deductive model, say that five times fast, is a much more popular conception
of confirmation both with scientists and with philosophers.
According to this model, a hypothesis is confirmed by any evidence that the hypothesis
entails.
Hypotheses are confirmed when their consequences are established as true.
And this is a more general and flexible model than the instantial model.
So for instance, it lets me say that if my hypothesis says that the early bird gets the
worm, then evidence that birds that hunt early in the day way more than birds that don't
supports that hypothesis without having to be an instance of an early bird getting a
worm.
So it's more permissive than the instantial model.
And we've come near something like the hypothetical deductive confirmation, understanding of confirmation
a couple of times.
It's close to the verification principle applied to questions of meaningfulness that we saw
in AJ Air's work.
The positivists are interested here in a hypothesis having observational consequences
that support it as a theory of evidence, but we saw them use a very similar notion
as a demarcation criterion as a way of distinguishing scientific from unscientific statements.
Now as we saw back then and have seen with a vengeance in Quine, statements in general
don't have observational consequences of their own.
You need auxiliary hypotheses in order to generate observational consequences.
And we've seen that this can wreak havoc with a simple model of what a statement says
or how observation might support it.
But let's put that aside for right now.
Let's suppose that we have auxiliary hypotheses unproblematically in place.
We don't need to multiply our problems unnecessarily.
Notice that we're in the context of justification here, not the context of discovery.
We've said nothing about where the hypotheses come from.
We're only interested in testing the hypotheses.
So one strength of this model is that it's free of the restrictions that plagued the
instantial model.
It covers all of the cases that the instantial model had covered since all ravens are black
does imply that this raven is black.
So the instantial model is a special case of the hypothetical deductive model.
But we need to permit other cases.
We need to be able to say that the wave theory of light gets confirmed when you notice that
there's a bright spot in the middle of the shadow of a circular disk.
Note that this is not a case of someone observing this beam of light as a wave and using it
to support all light beams consist of waves.
This was a consequence of the wave theory of light, deduced by an opponent.
He made his prediction saying, you folks who defend the wave theory have a problem.
If you're right, there's going to be a bright spot in the middle of the shadow of a circular
solid object.
Then when that bright spot actually was discovered, when the prediction was borne out, that provides
significant evidence for the theory.
Why?
Because it's a logical consequence of your theory.
If the wave theory is true, you must get that bright spot.
And so on the hypothetical deductive model, it counts as evidence in support of the wave
theory.
Now, despite its popularity and intuitive appeal, the hypothetical deductive model is
going to run into difficulties very like those that vexed positivist conceptions of empirical
meaningfulness, like the verification principle we saw back in lecture six.
We saw there how hard it is to talk about the experiential content of a hypothesis,
the difference that hypothesis makes to our ability to make predictions.
We couldn't isolate which parts of observation the hypothesis gets on its own.
Similar problems are going to cause the hypothetical deductive model to allow a hypothesis to be
confirmed by totally irrelevant data.
And so we're going to run into the problem we thought we had with the Raven Paradox.
Just about anything can count as evidence for just about anything.
Let's see how that happens.
Let my hypothesis be 2,000 pound beagles once roamed the earth.
This hypothesis logically implies that either 2,000 pound beagles once roamed the earth,
or it's sunny today, or both.
Why does this implication hold?
Because if the if part of that sentence is true, then the then part must be true.
There's no way for A to be true without either A or B or both being true.
So this is just a trivial case of the idea behind scientific confirmation.
If the wave theory is true, then there must be a bright spot in the center of the shadow.
If 2,000 pound beagles once roamed the earth, then either 2,000 pound beagles once roamed
the earth, or it's sunny today, or both.
So we have a case of logical implication.
Well suppose it's sunny today.
That's enough to make the consequence of the previous statement, namely either 2,000 pound
beagles once roamed the earth, or it's sunny today, or both, true.
But since my original hypothesis implies a statement that observation has now shown
to be true, my original hypothesis received evidential support.
So now a sunny day can count as evidence that 2,000 pound beagles once roamed the earth.
And this can fairly be described as a problem.
We face, as we have seen a few times, the porridge problem.
Any attempt to exclude apparently inappropriate cases of evidential support ends up excluding
apparently appropriate cases.
And any attempt to make room for apparently sensible cases tends to make room for apparently
ridiculous cases.
We've seen that in the notion of meaning, we're seeing it now in the notion of evidence.
Since the idea of counting anything entailed by a hypothesis as evidence for it lets in
too much, it's natural to try to tighten up that relationship.
Our next model, the inference to the best explanation model, requires that the hypothesis
not merely entail the data, but explain it.
We saw this before.
Inference to the best explanation is sometimes called explanatory inference.
We introduced this a couple of lectures ago, but now we're going to pursue it in a little
bit of detail.
As we might expect by now, this is going to solve some problems while opening up others.
According to this model, a hypothesis is confirmed if the hypothesis would, assuming
it to be true, provide the best explanation for the observed data.
Sherlock Holmes uses this approach quite a lot, and Conan Doyle very misleadingly has
Holmes call it deduction.
It's not deduction.
Deduction would be a case in which the evidence entails the hypothesis.
Here we're talking about a special case of the hypothesis entailing the evidence.
There's a big difference.
If the evidence entails the hypothesis, the hypothesis is really proved on the basis
of the evidence.
You can't have the evidence without the hypothesis being true.
But no matter how good Holmes's evidence that the butler did it is, there are almost
always other possibilities.
And if there are any other possibilities, no matter how remote, then the evidence doesn't
entail the hypothesis, and you can't deductively get from the evidence to the hypothesis.
So it's really an explanatory inference, not a deductive one.
So having the hypothesis entail the evidence is too easy.
That allowed the sunny day to confirm the Beagle hypothesis, and it would allow Sherlock
Holmes's evidence to confirm the hypothesis that butler hating extraterrestrials framed
him for the crime.
On the other hand, having the evidence entail the hypothesis is too demanding.
It almost never happens.
So we're looking for something in between.
The idea is that when Sherlock infers that the butler did it, he does so because the
hypothesis doesn't just imply the facts.
It, along with suitable auxiliary hypotheses, of course, explains the facts.
If the butler did it, that would explain why his hair was found at the crime scene, why
the victim's blood was found on his shirt, etc.
Now we can't completely rule out other possibilities, but if one hypothesis fits the facts together,
that's a loose notion of explanation, enormously better than all the other hypotheses do,
then we can think that the hypothesis that unifies all of the evidence, that explains
it, brings it together, gets support by those bits of evidence that it explains.
That's our model.
Notice first that, like the hypothetical deductive model, and unlike the instantial model, the
first one we talked about today, inference to the best explanation allows hypotheses
about unobservables to receive evidential support.
So when a physicist sees a streak in a cloud chamber and says that's evidence for the
presence of an electron, that's an inference to the best explanation.
That's a Sherlock homestyle inference.
The physicist can be understood as saying, aha, the electron did it.
The electron is the culprit for the streak in the cloud chamber.
Now this is a pretty attractive approach to confirmation.
It allows, as seems to be the case in actual practice, for science to use explanatory inferences
as well as induction, assuming that somehow we solved these problems of induction from
the last couple of times.
We can use both explanatory inference and inductive inference as tools for confirmation.
But of course, we have to face a number of questions, the most obvious of which is what
is it for a hypothesis to explain some observations.
This is one of those big philosophers' questions, and it's a big enough one to occupy us for
a few lectures, I believe, numbers 18 through 20.
For now, we're just going to work with an intuitive sense of explanation, keeping in
mind that we don't always have to define a term in order to do some good thinking with
or about it.
The problems we can raise about inference to the best explanation do not require a detailed
account of what explanation is, though we will get one later in the course.
It's worth noting that inference to the best explanation needs not just an account of what
explanation is, but also an account of when an explanation is good enough.
You've all seen crime shows and stuff.
Sometimes the detective or the scientist will have a number of explanations to choose from,
but none of them is at least yet well enough supported by the evidence to be worth inferring
as a conclusion.
You have to get to the last 15 minutes of the show before there's any hypothesis that
gets put forward seriously as a conclusion.
So though it's a less catchy title, the name of the model really should be something like
inference to the best explanation when the best explanation is a good enough explanation.
The best of a bad lot isn't going to do it.
Now even without going deeply into the notion of explanation, we can see that the model
is going to need a story about what it is for one explanation to be better than another,
and there's going to be a major problem we're going to have to confront.
One notion of explanatory betterness would have us infer to the most plausible explanatory
hypothesis, the one that's most likely to be true.
Well, this sounds promising, and it is, it's just not very helpful.
Reminds me of the harshest book review I've ever seen which said something like, this
book says many true and interesting things, but the true things aren't interesting and
the interesting things aren't true.
So to say that we should infer to the most likely explanation in this sense is something
like saying we should predict that the team that scores the most points is going to win
the game.
We're trying to give an account of evidence of confirmation to say that we should infer
our way to the best supported hypothesis is not terribly helpful here because we're trying
to get a grip on the notion of evidential support in the first place.
So it's useful in the sense that it's true, but it's not useful as advice to be told
that we should infer to the likeliest explanation of the evidence.
The other main notion of explanatory betterness is, in the jargon of the day, loveliness in
an explanation rather than likelihood in an explanation.
We should infer to the hypothesis that best accounts for the data or the hypothesis that
would, if it were true, provide the greatest understanding of the data.
This is different from the hypothesis that is made most probable by the data.
That's the likeliest, which is great except we don't know what it means.
So a lovely explanation is not necessarily a likely explanation.
So we're trying to unpack the notion of explanatory loveliness here.
It probably doesn't, for instance, mean that we should infer to the hypothesis that makes
the evidence more likely to be true than any other hypothesis does.
The one that confers the highest probability on the evidence.
Because if we were to do that, if you draw a card from a deck and it's the Queen of Hearts,
the best explanation in this sense for that fact would be that the entire deck consists
of Queen of Hearts.
That would make it maximally probable that the card you draw is a Queen of Hearts.
But we don't think that's the best explanation, the loveliest explanation for this phenomenon.
So we have our work cut out for us, figuring out what it takes to render a set of data
understandable, to explain it, to contribute to our comprehension of this data.
Is this a matter of revealing causal connections, simplifying the way in which we describe the
data, or what?
And even if we can solve this problem, there's going to be a deep question lingering in this
neighborhood.
Do we have a good reason for thinking that the hypothesis that makes the deepest contribution
to our understanding is more likely to be true than hypotheses that make a smaller contribution?
Why, if at all, should lovely explanations be likely explanations?
Do we think the world is under some obligation to favor our explanatory enterprise?
Why not think that what contributes to our understanding needn't be true, it just contributes
to our understanding?
These are hard questions, so perhaps you'll be pleased to know that we're going to drop
the discussion of confirmation and its logic at this point.
We're going to move to a deeply different, much more historical approach to these questions,
as initiated by the epic making work of the historian of science, Thomas Kuhn.
