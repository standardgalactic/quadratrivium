Butcher 20, probability, pragmatics, and unification.
In our last two lectures we examined the strengths and weaknesses of the covering law and causal
models of explanation.
The covering law model tries to illuminate explanation in terms of nomic expectability.
It says that we have an explanation when we can say, given the laws of nature, this
is the sort of thing that always happens, while the causal model unsurprisingly appeals
to causation to illuminate explanation and to explain how explanation contributes to
understanding.
This contribution to understanding is one of the two main desiderata for a theory of explanation.
On the one hand, we need an illuminating answer to questions about why things are as they
are, and we need some standard of what counts as illumination, and some reason to think
a given notion of explanation counts as meeting a standard of illumination.
On the other hand, we don't want to pay too heavy a metaphysical or epistemological price
in order to attain such an understanding.
If we could help ourselves to a notion of the grand scheme of things, that would increase
our understanding quite a lot, but we'd be helping ourselves to a bunch of claims for
which we don't have clear observational support.
That's the overriding tension that dominates the literature on explanation.
The leading idea behind our third model of explanation, unificationism, is that scientific
explanation increases our understanding by reducing the number of independent explainers
that we need.
The fewer primitive principles, the fewer styles of argument that we need to take as
basic, the more unified, and the hence more explanatory, is our scientific theory.
Now the idea that unification contributes to understanding seems pretty intuitive.
If we take a sequence of numbers that has no discernible relationship holding among
them, we don't understand the sequence.
When somebody gives us an equation that shows the relationship that these numbers bear to
one another, we unify all of these instances as cases of a common pattern, and that contributes
to our understanding of what's going on with these numbers.
This is a nice start, but that's a very simple illustration.
The challenge for unificationism, as we saw with the causal model, is to give us a decent
explication of the central notion to which the theory appeals.
We saw that it's hard to get clear about what causation could believably be.
We're going to see to what extent we can get clear about what unification could believably
be.
Unfortunately, this part of the literature on explanation gets very technical very quickly,
so we're going to have to settle for our kind of modest gesture through this theory.
It's not enough for a hypothesis or theory to imply a bunch of statements.
Unification is going to have to be more stringent than that.
Why?
Take the following statement.
This is a conjunction.
Ice floats in water, copper conducts electricity, and bears are mammals.
It's a three-part conjunction.
That statement implies each of the smaller statements of which it is composed, and it,
in a literal sense, brings them together.
It's a conjunction of those three statements.
But it doesn't unify our understanding of those three statements, even though it implies
each of those three statements.
So if Newton's physics is going to unify our understanding of motion, it's going to
have to do so courtesy of something more ambitious than merely implying some claims about motion.
So one central idea has it that a theory unifies when it minimizes the number of independently
acceptable sentences that have to be taken as primitive.
So the contrast between the Newton case and the above spurious case of alleged unification
is that Newton shows us how, at the cost of adding a few independently acceptable statements
about laws and a modest number of independently acceptable initial conditions, we can then
derive, rather than having to posit or take as basic, countless other statements about
how objects move.
So the idea is you can start with the least and do the most, and if you successfully do
that, you've unified a domain.
The less you need to posit, the less you need to take as an unexplained explainer, the better
a job of explanation you have done.
We can thus see that, like the covering law model, this approach to explanation tries
to get logical relationships to do the work done by apparently metaphysical relationships
in the causal model.
It doesn't want to appeal to some explanatory relationship out in the world, it's a relationship
that holds among statements within our theories that makes some things explanatory of others,
rather than a kind of physical connection between the cause and the effect, which on
metaphysically ambitious versions of the causal theory is what constitutes explanation.
In ambitious versions of the unification theory, causation itself gets explained in
terms of unification.
We won't be able to see this in detail, but let me at least gesture at an illustration
of this.
Let's look at a related kind of unification.
We've looked at minimizing the number of independently acceptable statements.
We also want to minimize the number of independently acceptable argument patterns.
So let's ask why Jones' taking birth control pills fails to explain his non-pregnancy.
The notion of causation is not going to be what does the work if we're ambitious unificationists.
We're going to appeal to unification to explain causal connections.
So the main reason that taking birth control pills does not explain why Jones, a man,
failed to become pregnant is because we don't need arguments about birth control pills to
adequately explain his pregnancy.
We can have a simpler, more unified, and hence more explanatory theory by using arguments
of the form, males don't get pregnant, then we can, if we use arguments of the form, males
who take birth control pills don't get pregnant.
The former is a simpler, more unified explanatory theory.
Now it's not quite as simple as that, because we're still going to need arguments linking
birth control pills and non-pregnancy.
So what's the content of our claim that this is a simpler theory not appealing to males
and birth control pills to explain non-pregnancy?
The idea is that we systematize our arguments in such a way that we can get the most out
of them.
And an argument counts as an explanation if it figures in the best systematization of
our theories.
We're going to look at the notion of a deductive system in some detail in the lecture after
next, but the point is you're going to need arguments about birth control pills explaining
non-pregnancy.
You're going to need arguments about males explaining non-pregnancy.
You layer the kinds of arguments you need such that none of them is doing redundant
work so that each of them explains as much as possible.
And when you've got that kind of a systematic structure, you've got the best explanation
for the phenomena.
Now this is an attractive approach, at least at this level of detail, but we don't want
to minimize the extent to which it is giving hostages to fortune.
Others of a causal approach say part of the reason this seems attractive is you're helping
yourself to some confidence that at the grand level of systematizing our theories, you're
going to get the right direction for unification.
If it were possible that we could unify effects in terms of causes, if those arguments systematized
our knowledge as well as an appeal to causes instead of effects, then it wouldn't seem
like unification tracked explanation.
So we have to make out in more detail than we're going to be able to hear this idea of
a deductive system, the unificationists are counting on this idea that doing the most
with the least will bring in the asymmetry we need to account for explanation.
Because we think that the height of the flagpole explains the length of the shadow in the way
that the length of the shadow does not explain the height of the flagpole.
So the unificationists don't want to appeal to causation to explain this asymmetry.
They want to appeal to patterns within a deductive system.
And causal theorists are going to say you're assuming that those patterns are going to
track something like causation reasonably well, and it's not obvious that things will
turn out that way.
So this is the big debate currently in the philosophy of explanation.
But Basvan Frasen, a philosopher who has spent most of his career at Princeton, tries to
skirt this debate by coming up with a completely different account of explanation.
For him, an explanation is just an answer to a why question.
That's all an explanation is, and a good explanation is just a good answer to a why question.
Now which question is being asked, and what counts as a good answer to it, both depend
on the context.
So for this reason, Van Frasen's theory is often called the contextual theory of explanation.
It's sometimes also called the pragmatic theory or model of explanation.
That could be misleading.
It's not to suggest that it's more useful than other theories.
But it's because it locates explanation at the level of pragmatics.
We've intermittently seen there are three levels of language in which philosophers are
interested.
Syntax, which roughly amounts to grammar or logical form.
Semantics then concerns the meaning of sentences.
So for instance, the things that make them true or false, independently of context.
Pragmatics concerns how sentences are used in a given context.
So an instance of syntax would be a statement that has the structure X has property F.
Semantics would then add some content to that sentence.
Joshmo has the property of having lost the election.
A pragmatic analysis of that sentence would examine what's done with it.
It could function as a provider of new information, or as a reminder, or as an expression of disappointment.
So a pragmatic theory of explanation focuses on this level of what is done with statements.
Not what they mean, but what we do in using them.
Von Fressen begins by observing that Y questions typically assume an implicit contrast.
When someone asks why did X happen, that's usually a disguised version of why did X
rather than Y happen.
The poster child for this view is the bank robber Willie Sutton, who was asked by his
priest, why do you rob banks?
Sutton was puzzled by the question and answered, because that's where the money is.
The priest had meant to ask something like, why do you rob banks rather than have a normal
job?
Sutton took the question to mean, why do you rob banks rather than say churches?
So the contrast that is implicit in the Y question structures what counts as a good answer
to the Y question.
Sutton did not give a good explanation, because he didn't give a good answer to his questioner's
query.
Von Fressen's point is that there is nothing more to explanatory goodness than giving a
good answer to a Y question.
And a good answer to a Y question will take the interests, the abilities, and the informational
background of the audience or the questioner into account.
Slightly different whether you're answering the questioner's question alone or whether
you're answering it, say, to an audience.
So for instance, an entirely correct quantum-mechanical explanation of why a square peg won't fit
into a round hole is a bad explanation if offered to a five-year-old.
It's not that there's anything false about it, it's not that it fails to unify or present
causes, it fails to be a good answer to the Y question.
So causal or unifying or covering law or other kinds of explanation could all be appropriate
depending on the context.
And most importantly, for Von Fressen, there is no non-contextual standard of explanatory
goodness.
Everything is determined by the Y question.
This very starkly rejects Hemple's ambition in the covering law model, according to which
explanation is no more person-relative than mathematical proof.
It's certainly true that it doesn't make sense to give a child a complex mathematical
proof, but that doesn't affect the validity of the proof.
For Hemple, explanation was a logical relation.
For Von Fressen, it's a pragmatic relation between a question or questioner and the answer
given.
Von Fressen's view is a bit more radical than that, in fact.
Not only is there no distinctively scientific notion of or standard for explanation, explanation
for Von Fressen is itself no part of science.
And explanatory power is not a virtue of scientific theories.
It's not necessarily a virtue of Newton's laws of motion that they explain a whole
bunch of phenomena like the tides.
To call an explanation the tides and the motion of planets and things like that.
To call an explanation scientific for Von Fressen is just to say that it uses scientific
information to answer a Y question.
Explanation happens outside of science.
Science is used to give explanations, but we're not doing science when we explain.
In this respect, explanation is rather like technology.
You use science to make computers or airplanes, but you're not necessarily doing science
when you are applying it in this way.
Why does Von Fressen take such a radical view?
Well, his views are empiricist ones.
He thinks that if the demand for explanation is built into science, it will lead inevitably
to metaphysics.
He's a radical empiricist in the way that the positivists, for instance, were.
Science for Von Fressen aims only at empirically adequate descriptions of the world.
If we had to keep explaining why things are the case, we'd have to keep going beyond and
behind experience, and we'll posit things at too great a remove from observation.
We will see more about Von Fressen's distinctive approach to empiricism a little bit later in
the course.
But let me correct a possible misunderstanding.
Von Fressen is not a relativist or a subjectivist about explanation.
His view is not that your answer to my why question has to satisfy me in order to be
a good answer.
That's a relativist or subjectivist view.
There's no standard.
It's just pleasing whoever asks you the question.
He has a theory about what counts as a relevant answer, given the question being asked, and
the contrast built into that question.
And that's where he can run into some trouble.
It's difficult to specify what makes a given answer relevant to a given question.
It's difficult to give an objective theory of that, and there's a danger that the theory
will have the consequence that any answer can count as relevant to any question.
That's one of the problems Von Fressen is going to face.
Now no one, I think, should be reluctant to grant Von Fressen that we can do explanation
extra scientifically.
We can use science to explain things, say, to children, and that we're not doing science
when we do so.
But it's not clear that we want to give up too readily on the idea that answering why
questions is internal to science, that science has distinctive explanatory goals and standards
of explanatory adequacy.
Even if we agree with Von Fressen that explanation depends on context, we might want to say there
are distinctive scientific contexts in which why questions are asked and answered.
So Von Fressen, in the eyes of most philosophers of science, gives up rather too quickly on
the idea that explanation can have a legitimate place within science.
He says you just take science and answer people's questions with it, but you're not doing science
when you do so.
We turn now to statistical explanation, which raises its own set of problems and is of independent
importance.
Now, we might resort to statistical explanation in either of two quite different circumstances.
First of all, we might not have enough information about a situation to explain it deterministically.
We might be pretty sure there's a reason, or more than one reason, that a drug is effective
in 80% of patients and not effective in 20% of them, but we don't have any access to the
reason.
And so we settle for the statistical claim that the drug is 80% effective.
We don't know what the difference between the 80% for whom it works and the 20% for
whom it doesn't is.
We might assume there is a difference.
Alternatively, the situation might be irreducibly indeterministic.
According to the dominant interpretation of quantum mechanics, it is just a brute fact
about the universe that a uranium-238 nucleus, don't worry about what that is, has a certain
probability of decaying in a given time period.
There can be two identical ones, one atom will decay, the other one will not, and there
is no difference between them on the dominant interpretation of quantum mechanics.
This was the occasion of Einstein's dismissive comment, God Doesn't Play Dice, about quantum
mechanics.
The intuition that the world is deterministic, that the same causes will always issue in
the same effects, is very powerful and was thought to be a truth of reason by philosophers
for a long time.
But it now seems to many philosophers and physicists, like a metaphysical prejudice,
analogous to the assumption we saw back in lecture four, that there has to be a fact
about whether two events are simultaneous.
We won't be going into the details here, but you run into either conceptual or experimental
problems or both if you assume that there must be an underlying difference that makes
a difference between the case of the uranium atom that decomposes and the one that doesn't.
On the dominant interpretation of quantum mechanics, the most basic laws of the universe are irreducibly
probabilistic or chancy.
The reason you can't throw a baseball through a window is not because it's physically
impossible, it's just damn unlikely.
The covering law model, again, provides the classic account of statistical explanation.
In Hempel's account, statistical explanations use statistical, rather than deterministic
laws as we saw, and initial conditions, as we saw before, to confer a high probability
on the thing to be explained.
So this is as much like the original covering law model as possible, the difference is just
we have statistical laws being used, rather than deterministic laws, but that difference
makes a surprisingly large difference.
So our first issue is clarifying the probability statements involved in statistical laws.
The law refers to an objective probability, a fact about the world, 80% of patients given
this drug get better, something like that, that's an experimentally observed result.
But the probability that the explanation confers on the thing explained is different.
We don't have a sample of how probable the experiments make a certain conclusion.
The probability that the premises confer on the conclusion has either got to be a logical
statement about the amount of evidential support, a kind of inductive logic conferred by the
premises on the conclusion, or it's got to be a kind of guess, a personal probability,
an estimate of the degree of evidential support.
Why?
Because in really, really well-behaved cases, we'll have a single clear statistical law
saying that say 80% of applicants to a particular college are admitted, and then we can infer
of an applicant chosen, we think at random, that this person has a 0.8 probability of
getting admitted.
But very few cases are so well-behaved.
There could be a whole bunch of different laws.
Since test scores have a certain bearing, geographical region, intended major, and there
may not be any clear statistical laws summarizing all of these laws, we may not know how they
work together.
In that case, we have to have a different meaning for the probability statement, because
it's a statement about evidential support, not about a frequency out in the world.
This difference between probability in the sense of evidential support or inductive logic,
and probability in the sense of some observed frequency out in the world will loom large
towards the end of the course.
So right now, I'm just marking, there's a difference between saying by probability
you mean something that we've observed versus a kind of estimate of how likely something
is.
Those are two very different meanings of probability statements.
Now, despite the similarities to the deterministic version of the covering law model, the statistical
case turns out to work very differently.
Since the argument is inductive, additional information can make a difference to how much
probability the premises confer on the conclusion.
So if all we know is that Jones, we continue to pick on poor Jones in the explanation literature,
Jones has a particular kind of infection and has been given penicillin.
We might be able to cite a clear statistical law saying that a high percentage of people
with this infection who are given penicillin recover within 24 hours, so far so good.
Now let's add a new piece of information.
Jones is highly allergic to penicillin, it'll kill him, or Jones is 115 years old.
The relevant statistical laws about whether people like Jones will recover within 24 hours
change with the addition of new information.
So on the covering law model, explanation in the statistical case is relative to an information
situation.
Temple hated this and tried to minimize it.
He wanted a conception of explanation as closely modeled on the deductive case as possible.
And in the deductive case, new information makes no difference at all.
If you know that Socrates is a man, and all men are mortal, you can learn that Socrates
is Greek, you can learn that he was a philosopher, you can learn that he was in perfect health,
none of that bears.
The conclusion automatically follows from the premises.
But in the statistical case, new information can undermine the support the premises confer
on the conclusion.
And that raises questions about what we want to count as an explanation.
Do we want to say that we have a good explanation only when all of the relevant laws are included?
That's highly demanding.
We hardly ever know all the factors that bear on whether someone will recover from a disease
or get admitted to a certain school.
And if the feature is deterministic rather than quantum mechanical or irreducibly probabilistic,
the probability of recovery is going to have to be either zero or one.
Then we wouldn't need statistical explanation in the first place.
We'd have to know everything that bears on the question.
We could back away from that stringent requirement and instead say that we have a good explanation
if there are no known additional information statements that would change the probability
conferred on the conclusion by the premises.
But that looks a little relativistic.
How hard do you have to look before you count as saying, I don't know of any more information
that bears on the case?
How much effort needs to be put in?
We could back further away and say that we are going to count as a good statistical explanation
any case that uses true statistical laws to derive some probability for Jones' recovery.
But then I could have a good explanation that predicts that Jones will recover because he's
got an infection that is susceptible to penicillin and so most people recover.
And I've got a good explanation that Jones won't recover because he's 115 years old
and very few people who have this infection and who are 115 and get penicillin recover.
Can those both be good explanations?
One confers high probability on his recovery and one confers low probability on his recovery?
That seems peculiar.
And counterintuitively, the requirement that a good explanation must confer a high probability
on the thing to be explained is probably not right, as intuitively obvious as it seems.
The probability conferred on the thing explained might not have much to do with how well it's
been explained.
So take a roulette wheel that is biased.
I might know that it comes up on red 80% of the time.
And so if the ball lands on red, I can explain it by saying there's an 80% chance it's going
to land on red.
But now suppose it lands on black.
Can't I appeal to the very same law and say that's why it lands on black?
It looks like that's the relevant information.
So can we explain things that are unlikely using the relevant statistical laws?
If those are the relevant statistical laws, is that the explanation?
This has the consequence that we can offer the same explanation for incompatible outcomes.
We use the same law to explain it coming up on red and it coming up on black, which doesn't
seem so weird in the 50-50 probability case, but maybe it does in the 80-20.
This suggests that it's not obviously necessary for an explanation to make the thing that
it explains highly probable.
So suppose someone had a disease that is fatal if not treated.
The person undergoes a procedure.
The procedure only works in 30% of the cases.
But if it works in this case, the procedure is the explanation for the patient's survival,
even though the patient's survival is not highly probable on the basis of the procedure.
Similarly, there are no circumstances that make spontaneous combustion likely.
But it does happen, and when it happens, spontaneous combustion might well be the explanation for
the fire.
It didn't make the fire likely, but it could still be the explanation.
Sometimes that's all we have to go on, especially in some indeterministic cases.
That raises the question of whether it's an adequate scientific explanation to say
of an objectively improbable thing, of the sort of thing that just in the nature of the
world does not happen very often.
Do we explain it when we say, stuff happens.
That had a small chance of happening and it happened, and that's that.
Get over it.
That's what there is to explanation in these cases.
This is a big issue to which we will have to return.
Which things need to be explained, and what kinds of explanations do they need?
This allows us to appreciate Von Fressen's point.
If you insist on explaining things, you're going to need to look for something deep,
something beyond the idea that some uranium atoms decay and others don't, and he doesn't
think experience will show you that thing.
That's why he thinks explanation is not an intrinsic part of science.
A serious problem for the covering law model of probabilistic explanation comes from the
other side.
It's not enough for an explanation, which includes true statistical laws and initial
conditions, to confer a high probability on the explanandum.
Problems of irrelevance, analogous to those in the deterministic case arise.
So for instance, it could be entirely explanatorily empty to say, this patient took a lot of
vitamin C and got over a cold within seven days, and 90% of patients who take large doses
of vitamin C get over colds within seven days.
That may be no explanation at all, because it may be the case that 90% of people, whether
or not they take vitamin C, get over colds within seven days.
Probabilistic nomic expectability runs into the same problems that deterministic nomic
expectability did.
Being told that given the laws of nature, this sort of thing happens all the time, isn't
enough for explanation in the probabilistic case or in the deterministic case.
This was the intuition that made causal models of explanation seem tempting.
The covering law model makes explanation a matter of an argument that renders the explanandum,
the thing to be explained, highly probable.
A more causally inspired model would suggest that we explain when we raise the probability
of the thing to be explained, rather than making it high, right?
Because in the case of the procedure that saves the patient's life, it's not that it
confers a high probability on survival, it's that it raises the probability of survival
that makes it an explanation.
Anything that makes an event more likely than it would otherwise have been helps to explain
it.
And we could put this in causal language, anything that causes the probability to go
up.
A certain kind of cancer might be rare, even among heavy smokers, but if it's less rare
among heavy smokers than in the general populace, we might think that smoking helps explain
it.
And the causal theorist is going to say that's because smoking helps cause it.
We might, peculiarly, even have legitimate explanations that make the things they explain
less likely than they had been.
In the case of a patient who undergoes a treatment that is generally highly successful, but occasionally
goes wrong, if a patient undergoes a procedure that usually leads to recovery, but in this
case leads to death, then the procedure confers a low probability on the patient's death,
but might still explain the death.
And the causal theorist is going to say that's because it was the cause of death.
But notice, this is a case in which the statistical law that explains the outcome makes the outcome
unlikely and lower than it would have been had the law not been in place.
So the idea there is to explain is to provide information relevant to the probabilities
of the thing to be explained.
Needn't raise, needn't lower, it just has to bear on the probability of what's explained.
So surprisingly, statistical explanation is not a special case of deterministic explanation.
It works very differently and raises its own real set of problems, which given the pervasive
nature of probability in the sciences, raises its own whole host of issues.
We'll return to probability towards the very end of the course.
We've seen a variety of views about what explanation is and how it might work, whether
it's central to science, crucial for science, or unnecessary to science.
The tension between the temptation to use a robust notion of something like causation
for explanatory purposes or to constrain explanation within the bounds of experience is the kind
of tension that's going to keep cropping up in our course.
We will see that as we turn next time to laws of nature.
