Those who cannot remember the past are condemned to repeat it.
Those are the often quoted words of philosopher George Santayana.
Another way to look at this is that it is far better than learning from one's own mistakes
is to learn from the mistakes of others before you fall victim to them yourself.
In this lecture we are going to look at some of the greatest scientific blunders of the
past to see exactly what went wrong.
These cases demonstrate clearly why initial skepticism is the best response to any new
claims.
You will also see in these examples and the lessons we derive from them many of the principles,
the skills of critical thinking that I have reviewed up to this point in the course.
In each case the scientists involved made major cognitive blunders.
They were controlled by their own biases and blind spots or failed to question themselves.
I'm going to start with perhaps the most iconic example that I could think of and that is
N-rays.
This is I think a great example of a scientific blunder from the past.
Ren√© Prosper Blondlott, 1849-1930 was a French physicist who in 1903, shortly after discovery
of X-rays by Rentgen, claimed to have discovered another form of radiation he called N-rays
after his university and hometown of Nancy.
He believed they were emitted by most materials except green wood and metals that had been
treated with ether.
N-rays however were invisible.
They could only be detected by refracting the N-rays through an aluminum coated prism
which would then cause a thread coated with calcium sulfide to glow slightly.
Ultimately the detection of N-rays was dependent on the experimenter seeing this very subtle
glow in the thread.
Reports vary but about 30 research teams replicated Blondlott's experiments also seeing the glowing
in the thread.
There were about 300 papers total published about N-rays over a few year period involving
over 100 different researchers.
However, problems were evident from the very beginning.
Many prominent labs were unable to replicate the results.
N-rays appeared to have seemingly impossible characteristics.
The inability to see N-rays was often explained by those believers as the scientists not having
sensitive enough vision.
Alleged photographic evidence was also plagued with sources of error such as fluctuations
in exposure time.
Essentially the researchers were looking at subtle changes in the brightness of a filament
when the variability in things like just the exposure time of the film were far greater
than the effect that they were claiming to see.
In 1903 Johns Hopkins physician Robert W. Wood was sent by Nature magazine to do a first
hand investigation of Blondlott's labs and his results.
Wood also had experience investigating spiritualists and in criminal investigations.
In other words he had experience not only as a scientist but as a skeptic.
In the lab he witnessed several experiments but could not see the effects of N-rays that
were claimed.
He also attempted to replicate the results himself in what he called a morning gone to
waste.
In one experiment he used his hand to block the path of the N-rays but this could not
be detected by the experimenters.
In another he removed the prism needed to refract the N-rays and in yet another he replaced
the N-ray source with a similarly shaped inert piece of wood unknown to the experimenter
in each case.
Each time the change was not detected.
So what are the lessons that we could derive from Blondlott and the other N-ray researchers
who believed that they had detected N-rays?
In retrospect we know that N-rays do not exist that the researchers were engaged simply in
self deception.
They relied on subjective outcomes their ability to see something very subtle and also at the
very edge of human detection.
They also relied upon very highly error prone measurements where the effect size was smaller
than the noise that was being measured.
And they used these tricky measurements in order to establish an entirely new phenomenon.
They were insufficiently skeptical of their own results.
They used special pleading to dismiss the negative results of other researchers like
not being sensitive enough to the glow in the thread and they did not use proper blinding
to eliminate the effects of their own bias.
In effect wood blinded the experiment for them and when he did the effects completely
went away they vanished.
Always an indication that the phenomenon you're dealing with is likely not true.
Even after N-rays were scientifically dead Blondlott spent years of research pursuing what was
ultimately a hopeless cause.
Let me turn to another eerily similar example that of Jacques Ben-Veniste.
You might think that scientists learned the lesson of N-rays a long time ago to be properly
self skeptical but while many certainly have there are still those scientists who have
not learned these lessons and are doomed to repeat them.
Jacques Ben-Veniste in 1988 as a researcher thought he had discovered proof that homeopathic
dilutions extreme dilutions diluting a substance beyond the point where any active ingredient
remains in fact could still retain the chemical properties of what was diluted in the water
and he published these results in Nature magazine.
He was studying specifically the triggering of activity in basophils a type of immune
cell in response to an allergic trigger.
Ben-Veniste found that the basophils would react even to homeopathic dilutions of the
substance meaning that there was literally nothing left.
Studying that all of chemistry and biology says should be impossible.
The results were dependent upon observations of a variable biological system again a system
where there will tend to be a lot of noise and even subtle biases in the researchers
may therefore have a profound effect.
They could not be replicated in many labs although some labs did report replication again a very
similar history to that of N-rays.
When Ben-Veniste's claims were met with skepticism he claimed he was the victim of closed-mindedness
that he was being persecuted for challenging the scientific dogma of the day that he was
a modern Galileo.
Ben-Veniste also invented fanciful explanations for how the diluted solutions might work that
the antibodies communicated their effects to the basophils perhaps not through direct
chemical interaction but remotely through radio waves and that perhaps water could
act as a template and remember these radio waves and give them off later.
This even led him to believe that he could record these effects and transmit them over
the phone or over the internet.
However, he never tested or tried to demonstrate these assumptions.
They simply were hand-waving explanations for how the impossible might be possible.
He could have designed fairly objective experiments to test these basic ideas to show if these
radio waves existed but he chose instead to stick with a much more tricky, noisy, variable
biological system in order to support his claim.
In an episode remarkably similar to the N-ray episode Nature Magazine in response to criticism
from the research that they published sent a team of investigators into Jacques Ben-Veniste's
lab including a magician and noted skeptic James Randy.
They imposed rigorous blinding on the experimental protocol and just like with N-rays with proper
blinding the positive effects vanished.
They proved as illusory as N-rays themselves.
Let's move on to yet another example of a famous scientific blunder that of ponds and
Fleishman and their cold fusion claims.
In March of 1989 Stanley Ponds and Martin Fleishman called a press conference in which
they announced that they had experimentally produced cold fusion.
If true, the announcement could mean Nobel Prize for these researchers.
It could also mean a revolution in energy production, an end to dependence on fossil
fuels, a supply of endless, cheap, clean energy.
You probably don't remember all of that happening, so what went wrong with these claims?
For some background on cold fusion, existing nuclear power plants use the process of nuclear
fission to make heat, which they then use to turn a turbine and generate electricity.
Fission is the process of splitting apart heavy radioactive elements like uranium.
Fission is the process of combining light elements into slightly heavier elements such
as fusing hydrogen into helium.
However, tremendous temperatures and pressures are required to get atoms to fuse together.
This process happens in the middle of our sun, for example, but it's difficult to generate
those kinds of pressures and temperatures here on Earth outside of a large hydrogen bomb,
but difficult to use for fuel.
We can create these explosions, but we just can't control the reactions.
We cannot do it in such a controlled way that we can use it to generate heat and produce
electricity.
Cold fusion, as the name implies, is fusion of light elements into heavier elements at
low temperatures.
This of course would handle the problems of having to deal with extremely high temperatures.
This would be ideal for energy production, but we currently simply do not know how to
accomplish cold fusion.
Many researchers have tried to make cold fusion happen in their labs, but no experimental
design so far has been reproducible.
Often the claims are based upon measuring excess energy in an experimental setup, but
there are potentially many sources of unaccounted for energy.
So again, they are relying upon measuring things that are difficult to measure and that
are tiny effects that are smaller than the noise of the systems that they're dealing
with.
There are potentially many sources of energy that are not accounted for, but any tiny bit
of excess energy is taken in some cases to be evidence of cold fusion.
It has been suggested, for example, that Pons and Fleischman's setup, using electrolysis
to induce cold fusion in heavy water, was contaminated with tritium and that this contamination
could account for the spikes in energy production that they saw that they claimed were due to
cold fusion.
Pons and Fleischman, perhaps under pressure from their institution, the University of
Utah, held a press conference on March 23, 1989 to announce their cold fusion findings.
Prior to publishing their results in peer-reviewed journals and having their peers carefully review
their results, what followed has been referred to as the fusion confusion.
There were many claims coming from labs trying to replicate their findings mostly negative.
One of the positive findings, the initial positive findings, also panned out.
After initial excitement, by the end of April 1989, the press were announcing that cold
fusion was dead and that Pons and Fleischman's experiments were an example of pathological
science.
They had made the extreme scientific blunder of doing what is now called science by press
release.
They took exploratory preliminary findings in a very difficult system that is prone to
error and bias and they presented that as a Nobel-winning discovery.
This turned out to be a massive embarrassment for both researchers and for cold fusion itself.
Even believers in the promise of cold fusion have to admit that Pons and Fleischman single-handedly
destroyed any scientific credibility.
Research now exists on the fringes of science.
Proponents use terms like low-energy nuclear reactions to refer to their research to avoid
the stigma of cold fusion.
The lesson here is that Pons and Fleischman appear to have gotten carried away with the
excitement of their potential findings.
They are now the poster children for this effect, the science by press conference.
It is far better to allow the wheels of peer-reviewed to grind away, to weed out the false hopes
before they become a disastrous embarrassment.
Let's turn to yet another example.
I'm going to give you a quote referring to this next bit of research.
Some of the great scientists carefully ciphering the evidence furnished by geology have arrived
at the conviction that our world is prodigiously old and they may be right, but Lord Kelvin
is not of their opinion.
He takes the cautious conservative view in order to be on the safe side and feels sure
it is not so old as they think.
As Lord Kelvin is the highest authority in science now living, I think we must yield
to him and accept his views.
This quote is by Mark Twain.
What was Mark Twain talking about?
Well William Thompson, 1824 to 1907, who would later be known as Lord Kelvin of the Kelvin
temperature scale fame, was the most famous physicist of his time.
His specialty was thermodynamics, the study of heat.
Darwin and other contemporaries argued for a very ancient earth.
Lord Kelvin, who was not impressed by the quote unquote soft sciences of biology and
geology, set out to calculate the age of the earth using the reliable hard principles of
physics.
He figured that the earth was cooling.
So if it started as an initially molten state, one could calculate how long it would take
using thermodynamic principles to cool to its current temperature.
In 1862, he estimated the age of the earth using this technique as no greater than 100
million years, with a range of 20 million to 400 million years, given the uncertainty
in the measurements at the time.
He later refined his measurements and reduced his estimate to only 20 to 40 million years.
This did not leave enough time for the geological processes that geologists of the day were
saying were occurring to create the earth that we know today.
In fact, Lord Kelvin was highly critical of Charles Darwin and the geologists of his day,
including Sir Charles Lyle, not a lord mind you, just a lonely sir.
Lord Kelvin, while deservedly famous and respected, used his authority, in the view
of many, arrogantly, to push his calculations for the age of the earth.
He not only criticized geologists, he casually dismissed much of the contemporary geology,
which was simply incompatible with his calculations.
He was also hostile in the face of criticism of his calculations.
However, the deathblows to Lord Kelvin's calculations were eventually to come, and
they came in the guise of radioactivity.
At the time Lord Kelvin made his calculations, radioactivity had not yet been discovered.
When it was discovered, it was a triple threat to Lord Kelvin's position.
First, radioactive decay of elements in the earth's crust, like uranium and thorium, provide
extra heat to the earth.
Even using Kelvin's problematic equations, radioactive decay would extend the age of
the earth to 2.7 billion years old.
There are also other sources of heat that are not accounted for as well.
Also, radiometric dating allowed for a highly accurate method of dating the earth, actually
a collection of methods, with current results indicating that the earth is about 4.55 plus
or minus 0.02 billion years old.
This is consistent with the science of geology, which identifies many processes that would
take millions or billions of years to produce the effects, the geological features that
we see today.
It's also compatible with Charles Darwin's evolutionary theory, which also would require
hundreds of millions of years to unfold as it has.
Further, nuclear fusion also provided a heat source for the sun, allowing it to burn for
billions of years.
Prior to the discovery of nuclear fusion and nuclear processes, it was unknown how the
sun could have enough energy to exist and produce its light and heat for billions of
years.
There are several lessons to be learned from the history of Lord Kelvin.
The first is that scientific authority can never rest in one individual, no matter how
famous or successful their career.
This is something that is variable culturally within science and I think also over time.
Now we're more than a century later, the scientific establishment does not rest quite as much
authority in any individual.
And there's a good reason for this.
Any individual can be wrong, no matter how brilliant or how successful they have been.
Scientific authority is better to rest in the consensus of scientific opinion among
many scientists.
Further, Lord Kelvin was arrogant in dismissing the findings of a scientific discipline of
which he was not an expert.
He thought he could use physics to casually wipe away all of the carefully accumulated
arguments and evidence from geology.
This doesn't make him wrong, but it should have tempered his confidence in his conclusion.
This less lesson is more generally applicable.
Whenever a scientist or a researcher has a finding or a claim which seems to contradict
a very large body of established science, they shouldn't immediately assume that they
are correct and that a large body, even an entire discipline of science, is wrong.
That should, if anything, make them more skeptical of their own position.
And further, it would have been more reasonable to conclude from Lord Kelvin's calculations
that the inconsistency between the findings of thermodynamics and geology and also evolutionary
biology meant that there was a piece to the puzzle that was missing.
Rather, Lord Kelvin assumed that he was right and all of geology and evolutionary biology
was wrong.
It turns out that there was a piece to the puzzle missing and that piece was radioactivity.
This also is a further lesson about making arguments from ignorance, basing an argument
about based upon the current level of scientific knowledge or what we currently don't know.
Lord Kelvin really had no way of knowing that radioactivity was about to be discovered.
That was an entirely new phenomenon of nature.
He could therefore not account for it in his calculations, in his estimate of the age
of the earth.
What he really had was not evidence that all of geology was wrong, but an anomaly.
And if he recognized it as an anomaly, he would have seen it as an opportunity to discover
something new about how the world works.
And again, that something new was radioactivity.
In my final example, I'm going to discuss the research of John Edward Mack, a Harvard
psychiatrist who began in early 1990 to investigate patients who reported that they were abducted
by aliens.
At first, Mack thought they might be suffering from mental illness, but most of his patients
did not meet the criteria for a mental illness diagnosis.
They simply didn't have the signs or the symptoms that would warrant a diagnosis of schizophrenia
or any other specific mental illness.
He then, therefore, began to take their reports much more seriously.
In an interview, when asked if he took his patients' reports at, quote unquote, face
value, Mack responded, Face value, I wouldn't say.
I take them seriously.
I don't have a way to account for them.
Mack later believed that these alien encounters might be a spiritual or transcendental experience
in nature, perhaps related to the vision quests of the Native American cultures.
Mack seems to have fallen victim to his patients' own beliefs or delusions.
One mistake that he made was to commit the false dichotomy.
He concluded that, well, these patients aren't mentally ill, therefore there is something
incredible about their reports.
He ignored the fact that perfectly healthy individuals can, through flawed thinking and
other factors covered throughout this course, arrive at firmly held but false beliefs.
He ignored the fact that there was no corroborating evidence for the stories that they were telling.
And he engaged in special pleading and the argument from ignorance in order to justify
his conclusions.
Essentially, Mack was saying that his patients were reporting what they believed were encounters
with aliens, that they in fact were being abducted by aliens.
He was convinced by the fact that they were sincere.
They were not lying, in other words.
But sincerity is not a substitute for reliability.
People can be sincerely wrong.
And it's odd that as a psychiatrist, he did not consider all the many ways in which people
can delude themselves, even mentally healthy people, as we discussed in the lecture on delusions,
and can firmly hold to a belief, especially one that is encouraged by the culture, despite
evidence against their belief.
All of these factors conspired to lead Mack to believe that his patients were indeed being
abducted by aliens.
Or at the very least, something very interesting was going on.
And if it was not something physical, then it was something spiritual.
This of course led to a great deal of criticism of his conclusions, even an investigation
at his institution, Harvard University.
Although they ultimately concluded that Mack, what he was doing was academically reasonable
and that under the principle of academic freedom, he had the right to ask and pursue whatever
questions he wished.
We've spoken in this lecture about N-rays, homeopathy, cold fusion, Lord Calvin's calculations
for the age of the earth, and alien abductions.
There are many more scientific blunders that we can talk about as well.
But I think these are good examples to illustrate the lessons that we have talked about in this
course.
In each case, the researchers failed to be skeptical of their own conclusions.
They failed to learn the cautionary tales of scientists who came before them and committed
their own blunders.
They failed to adhere to principles of logic and to evaluate their evidence and their studies
in a properly skeptical way.
For example, by properly blinding studies in order to account for their evidence.
Or they too heavily relied upon their own expertise or their own stature and were not
sufficiently humble in the face of a genuine anomaly.
There's one more example that may or may not be a real blunder depending on your perspective.
But Albert Einstein himself called it the biggest blunder of his career, demonstrating
that even the great scientist himself can fall prey to these kinds of errors.
This is the incident of the cosmological constant.
Einstein published his general theory of relativity in 1916.
His prior special theory of relativity dealt with basically the speed of light.
In the general theory, he extended his concepts to deal with both gravity and mass.
It was more of a generalized relativistic theory.
Einstein believed, as many others did at the time, in a static universe.
But of the predictions of general relativity led to the conclusion that the universe must
be either expanding or collapsing.
Einstein, however, couldn't accept that.
He had fixed in his mind this concept that the universe, in order to be the billions
of years old that it is, or whatever was believed at the time, that it had to be self-sustaining.
It had to be static.
If the universe were either expanding or contracting, then how can it be as old as it is?
So he therefore introduced a fudge factor, the cosmological constant.
The cosmological constant is a repulsive force in the universe that he believed would exactly
balance the attractive force of gravity.
Therefore this made his equations of general relativity work in a static universe.
You have the gravity pulling everything in and this cosmological constant pushing everything
out to the exact same degree.
The two forces are therefore in balance and you have a perpetual static universe.
This accorded nicely with Einstein's preconceptions.
However, this was all blown apart when Edwin Hubble later observed the red shift of galaxies.
The light from distant galaxies were all shifted towards the red end of the spectrum because
they are moving away from us and that is what we call the Doppler effect or the Doppler shift.
This indicated that every galaxy that we could look at, except for those that are clustered
around us, are moving away from us.
The only way to really explain that observation is that the entire universe is expanding.
Edwin Hubble published his findings in 1929.
This means that Einstein was wrong and there is no need for a cosmological constant.
Einstein's blunder was in introducing this fudge factor to rig his equations, his results,
to comply with his preconceptions.
He had an opportunity, however, to see it for what it really was, an anomaly.
This anomaly was pointing to a new, stunning and dramatic fact about the universe.
This could have been a nice additional feather in Einstein's cap, not that he really needed
it.
His career was stellar, to say the least.
But he had an opportunity to say, hmm, my equations predict that the universe is not
static, that it is expanding or contracting, and make a prediction that could have later
been verified.
Instead, he robbed himself of that opportunity by introducing this fudge factor.
The cardiological constant, ironically, has recently been resurrected, although not in
the way that Einstein initially intended it.
In the 1990s, the observation was made that the universe is not only expanding, it's accelerating.
And this acceleration could not be explained by the Big Bang alone.
Cosmologists had to introduce something else.
There must be some repulsive force, some dark energy in the universe, which is causing it
to accelerate.
So in an ironic twist, Einstein's greatest blunder did happen to coincide, in a way,
with later scientific discoveries.
In this lecture, I gave you multiple examples of dramatic blunders in scientific history.
These researchers all made mistakes of critical thinking.
They put aside their critical thinking skills, and instead, they went for the biases of their
own beliefs and their own desires.
They didn't use good methods, they didn't properly blind their research, they didn't
try hard enough to prove their own ideas wrong.
The end result was history's examples, cautionary tales of scientific blunders that we should
try to avoid.
