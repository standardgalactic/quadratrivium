You
a
Your lecture is Dr. Steven Novella.
Dr. Novella is an academic neurologist at Yale School of Medicine
and is a leading force in medical education for patients,
the public, medical students, and medical professionals.
He earned his MD from Georgetown University
and completed his residency training at Yale School of Medicine.
Dr. Novella is the founder and senior editor of Science-Based Medicine,
a popular blog dedicated to promoting the highest standards of science in medical practice.
Do you believe that a technologically advanced alien civilization is visiting the Earth
at this time or any time in the past?
Are they abducting people from their bedrooms,
perhaps even right out of a heavily populated area like a large city?
Are they leaving us messages in geometric designs in wheat fields?
If this is true, does the government know about it?
And if so, are they engaged in a multi-generational cover-up of their knowledge of aliens?
And if so, why?
Is culture, perhaps even the human race, descended from alien visitors?
How can we claim to know the answer to these questions, or in fact, any question?
In this course, we will explore our current knowledge of the human brain as a tool for thinking.
The course is essentially a giant exercise in so-called metacognition,
or thinking about thinking itself.
It endeavors to give you the skills of what we call critical thinking.
Socrates said that the unexamined life is not worth living.
The motto for this course could be, the unexamined thought is not worth thinking.
What's at stake with all of this?
Well, science and belief permeate our lives.
They permeate our culture, our civilization.
We, for example, face environmental issues.
Is there global warming?
Is the planet warming up, for example?
And if so, are we causing it, and what can we do about it?
What future technologies should we invest our very limited resources into?
If we make the correct choices about where to invest, then there's a lot to gain.
If we make the wrong choices, we could squander billions on dead ends.
Also, we buy products every day that involve claims, either explicit or implicit.
And we need to be able to evaluate those claims in order to make good purchasing decisions.
For example, there is a company that will sell you a very expensive piece of exercise equipment,
and they claim that in four minutes of exercise, just a few times a week,
you can get all the exercise you need to be in perfect health,
that that's as good as a 30-minute exercise using a lesser piece of equipment.
Is this true?
Is it worth spending thousands of dollars on such a piece of equipment?
And how should we evaluate their claims?
Should we listen to anecdotal stories by other people who may be using the piece of equipment?
Or should we require objective scientific evidence to evaluate those claims?
We also use critical thinking in order to think about how we run our civilization.
Our population is rapidly approaching 7 billion people,
and we need to make that sustainable in some way.
I'm a physician. I see patients every day, and I know the difficulty they go through
often in making healthcare choices for themselves and for their family.
We have to purchase healthcare products, decide what foods to eat,
what lifestyles changes to make in order to stay healthy.
All of these claims are based upon evidence and logic,
and we need critical thinking in order to be able to evaluate them properly.
One of the premises of this course is that we are our brains.
We are that 3 pounds of grey jelly that floats inside of our skull.
The brain is comprised of about 100 billion neurons,
plus a lot of other cells that not only support those neurons,
but modify, modulate their function.
The brain is, in essence, an organ that can think.
It is an organ that is self-aware.
Not only the most complicated organ that we know about it,
it may, in fact, be the most complicated thing in the universe that we know about.
The brain can remember, it can feel, believe, calculate, extrapolate, infer, and deduce.
It does everything that we think of as thinking.
It is our universal tool and our greatest strength.
Most people believe that if there's one thing that separates us,
or that is our greatest advantage over all the other creatures on this planet,
it's our intelligence.
But the brain is also strangely deceptive.
It is also the root of many of our flaws and weaknesses.
This course will also be exploring what we might call human nature.
This may sound pessimistic, but it's true that humans possess logic,
but we are not inherently logical creatures.
We are not like the Vulcans of Star Trek mythology, right?
We have emotions.
So in addition to being logical, we are also highly emotional creatures.
What that means is that we tend to follow our evolved emotions and rationalizations.
Our thoughts follow what you might consider to be the pathway of least resistance,
not necessarily always the optimal pathway.
Logic and critical thinking are therefore learned skills.
While we have some inherent sense of logic, we are overwhelmingly emotional creatures.
We have the capacity for logic, but logic and critical thinking are skills.
We're not born as master critical thinkers.
For example, we are also not born with the ability to play the violin like a concert violinist,
or we are not born with the skills and the experience necessary to perform well as a football player in the NFL.
You should no more expect to be born a highly developed critical thinker
than you should expect someone to be born a violinist or somebody who can play in the NFL.
These are all skills and abilities that need to be developed over years
and practiced in order to be good at critical thinking.
Humans tend to make a lot of errors in thinking.
Our inherent tendency, again, this evolved pathways of least resistance,
include a lot of flaws in thinking.
Flaws in logic are one example.
We call these logical fallacies.
We tend to make logical connections that are not valid, that are not real.
Our thinking is also plagued with many false assumptions.
Our heads are filled with facts, things that we know to be true, but in fact are false.
Either they're just out and out wrong, or they're just assumptions that may or may not be true, but we really don't know.
Our memories are also massively flawed.
We tend to naively assume that our memories are an accurate passive recorder of what has happened,
when in fact our memories are plagued with numerous flaws that make them highly unreliable.
And there are things that psychologists call the churistics,
which are down and dirty rules of thumb or patterns of thinking.
They're mental shortcuts that we tend to take that may be right much of the time,
but they're wrong often enough that they lead us astray quite frequently.
How do we compensate for all of these flaws in our brains functioning?
Again, that's what this course is all about, that metacognition.
If I had to give a single term to encapsulate all of the skills in this course,
it would be scientific skepticism.
Skepticism includes systematic doubt,
essentially questioning everything that you think,
questioning the process of your thinking,
and questioning everything that you think you know.
The Scottish philosopher David Hume summed this up a little bit when he said,
a wise man proportions his belief to the evidence.
That's one component of critical thinking,
basing your beliefs on actual evidence as opposed to wishful thinking, for example.
The goal of all of this is to arrive at conclusions that are likely to be true,
as opposed to conclusions that are unreliable,
but also to have some kind of a sense of how reliable our conclusions are.
And this involves the scientific method as well.
This is scientific skepticism, not just doubt,
but a positive set of methods for examining reality.
Science essentially is a systematic way of comparing our ideas to external objective data.
Science, in short, the goal of science is to lead us to conclusions which are actually true,
as opposed to conclusions that we simply wish are true.
However, not all science is valid.
There is good science and bad science, or not so good science.
And some science is so flawed that we, in fact, call it pseudoscience.
It's not even real science anymore.
Science follows scientific methodology.
It is not a set of beliefs, but it is a set of methods.
And there are ways of defining that as well as distinguishing good science from bad science,
something that we will explore a lot throughout this course.
Here's one example.
There are many people and companies that claim that they have developed,
or they are developing an engine that can burn water as fuel.
Now, of course, the incentive for such a piece of technology is huge.
Imagine if we can replace all of the fossil fuels that are both expensive
and that are put in carbon dioxide and other pollutants into the air.
Imagine if we could replace that with something as simple as water.
Essentially, what the process is that they keep reinventing over and over again
is to electrolyse water, meaning separate water into its oxygen and hydrogen components,
the resulting mixed gas you might call oxyhydrogen,
and then burning that oxygen and the hydrogen back together again into water.
So the byproduct of the process is water.
They're burning the gas, the oxygen, the hydrogen, and getting energy out of it.
If this really were a legitimate method for running a car or running any engine,
how is it that the scientists and engineers of the world had missed this for so long?
That's the kind of question that a critical thinker would ask.
If, in fact, it is true that such an engine can work,
then perhaps the reason it has been quote-unquote missed for so long
is that there is a conspiracy of oil companies to suppress this scientific knowledge.
That's often the rationalization that those who claim to have such a piece of technology put forward.
But is such a conspiracy plausible?
Is it itself now just another claim that is just as fantastical as the claim that you can burn water?
We can also examine the plausibility of the claim itself by asking a very simple question.
If this is a process for generating energy, where is this energy ultimately coming from?
Even a very high school level of understanding and thermodynamics will tell you that
you're putting more energy into separating the water into oxygen and hydrogen
than you can possibly get out of it again by burning it back into water.
The process loses energy.
It is therefore not a source of energy.
The plausibility of such claims are beyond low.
They border on the impossible as much as we can say so in science.
So it's not very plausible.
It's hard to dismiss that plausibility simply with conspiracy theories.
And what evidence do they have that they can actually produce these engines that can run on water?
Well, it's always very thin.
It's always one step away.
They just need a little bit more money from investors in order to go that final step to make it finally work.
Their demonstrations always have major flaws, like they're running the engine along with a gasoline engine
that's burning gas for fuel to electrolyze the water.
They never give you what they claim.
So that certainly is a cause for questioning the validity of those claims.
This course will also explore the nature of knowledge itself.
What can it mean to know something?
What does that actually mean?
Well, the scientific method is based upon what we call methodological naturalism.
That's the philosophical term for it, which simply means that natural effects have natural causes.
And in trying to model and understand the world, you cannot invoke essentially magic.
You can't refer to supernatural or miraculous causes, causes that don't have any testable cause in the natural world.
It's not because we don't want there to be supernatural causes.
It's just that they're not amenable to the methods of scientific inquiry.
Therefore, from a scientific point of view, we could never really know about them.
And we'll get into this in more detail in a future lecture on the philosophy of science.
It also means that all conclusions in science are provisional.
There is no such thing as 100% metaphysical certitude.
There's no truth with a capital T.
All of our beliefs have error bars around them.
And as I said previously, not only do we have to assess what is likely to be true,
but how certain or how confident can we be about that belief knowing that we'll never quite ever get to 100% certitude.
This also means that all of our beliefs are open to revision.
That when new data comes in, or maybe just a better way of interpreting data or looking at the way things work,
we have to be open to revising what we thought we knew.
In addition to all of the flaws in thinking that I mentioned, human beings are also subject to delusions.
Sometimes our thinking goes so far awry that we can invent beliefs, invent our own reality,
or we can get swept up in the beliefs of others.
One common manifestation of this is a public panic.
Recently, psychics predicted that an earthquake was going to occur in Italy.
This caused many people to actually flee from cities.
The panic was so great.
There were similar predictions made in New Zealand.
These were based upon really the false claim that the phases of the moon and the position of the moon
controls or can provoke and therefore predict earthquakes.
Again, without there being any basis in scientific fact, this caused a panic in the populace.
Of course, there are earthquakes all the time.
There is the normal background frequency of earthquakes.
There's always an earthquake of some severity just around the corner,
especially in those parts of the world that are susceptible to earthquakes.
That can always be taken as confirmation about the prediction,
whether or not the prediction had any new information in it at all.
I also think it's helpful to consider thinking as a process
and to focus on the process rather than on any particular conclusion.
In fact, we should really invest ourselves in this process.
Once we invest in a conclusion, I mean emotionally invest in a conclusion,
then we start to twist facts and logic in order to fit that desired conclusion.
And humans are very good at doing just that, rationalizing or twisting facts and logic
to shoehorn them into a conclusion that we've already settled on.
The character Sherlock Holmes, perhaps the most iconic rational character in literature, said in one story,
it is a capital mistake to theorize before one has data.
And sensibly one begins to twist facts to suit theories instead of theories to suit facts.
And that captures the essence of what I am saying.
Invest in the process and be very flexible when it comes to any conclusions.
In addition, one might say that we are currently living not only in the age of information with the internet,
we're living in the age of misinformation.
We are subject all the time.
Every day I get spam in my email, email which are making very specific claims,
whether they're politically motivated, ideologically motivated or trying to sell me something
or perhaps even lure me into a scam.
There are many rumors that now spread not only like wildfire but faster.
They spread with the speed of electrons through the internet.
There are many urban myths that capture our imagination in some way
and again get spread credulously, so-called friend of a friend stories,
like the executive who checks into a hotel, gets picked up in the bar,
and then wakes up the next morning with his kidney missing while he's laying in a tub of ice.
How plausible is that story?
Should we believe it?
Can something like that actually happen?
But we are now awash in such stories, whether they're innocent and just fun
versus malicious and trying to either steal our money or lure us into a scam
or maybe just to influence our voting.
In a democracy we are constantly subject to people who are trying to influence our political thinking.
We also live in a capitalistic society which means that every day we're subject to marketing claims.
Marketing claims are highly motivated, in fact, to misrepresent the facts
or to at least give us a very specific perspective.
They're trying to influence our thoughts and our behavior,
so they engage in what you might call persuasive speech and maybe even deception.
Even when there are laws against outright fraud, marketers are paid a lot of money in order to flirt with that line.
How much can they twist or misrepresent the facts without crossing over that line into actual fraud?
And as consumers, every day we have to sort through all of these deliberately deceptive claims
to figure out which ones are reliable and which ones aren't.
Further, many companies will use pseudoscience or even anti-scientific claims
in order to back up their marketing, back up their products.
And that can seem very persuasive to somebody who isn't schooled or skilled
in telling real science from pseudoscience.
Let me give you one example of this.
In the last couple of years, a company has made literally millions of dollars selling so-called power bands.
These are little pieces of rubber, in fact about a dollar or two worth of rubber,
with a cheap plastic hologram embedded in it.
Now the company claims that this hologram gives off a vibrational energy,
which is balanced in order to resonate with the inherent vibrational energies of your own body.
And in so doing, it will improve your balance and your performance.
You'll have more energy, if you engage in sports, you will perform that sport even better.
In fact, they have many professional endorsements, recognizable sports professionals
who wear their product and say that it helps them shoot baskets better or play golf better.
So should we believe these claims?
Should we spend 30 to 40 or maybe 60 dollars in some cases in order to buy a piece of rubber
we wear around our wrist and improve our ability to play golf?
Well, the company further supports their claims with anecdotes,
as I said, like the not only professional endorsements, but just everyday people who use their products.
And we tend to be very compelled by stories.
When someone else is telling us a story, we are hardwired, if you will.
It is human nature to find those stories very compelling.
And they also give demonstrations.
They have you hold on to a power band and show how much improved your balance is.
It turns out that these demonstrations are very deceptive.
They are little more than parlor tricks that a magician, for example, might use in order to deceive you.
The American Council on Exercise actually did a blinded study of these bands, these rubber bands,
as if they really needed to do, given the plausibility.
But they went ahead and did it anyway and they find when you blind people to whether or not they are wearing one of these bands,
there is essentially no effect whatsoever.
Which means that any perceived effect was all in the minds of the people who were wearing the bands,
who believed that there was some effect.
This is not an isolated incident.
There are many similar products.
You can now buy a golf shirt that's woven with energy fibers that is essentially claimed to do the same thing as these power bands.
But there's literally no signs to support any of this.
This is a great example of marketing pseudoscience, using words like energy and vibrations,
in order to convince people that there is something to it.
When, in fact, if you have a fair degree of scientific literacy, you can see this for what it is.
Meaningless pseudoscientific jargon.
So thinking critically is, as I said, a process.
So what is this process like?
What do we mean when we say to think critically?
Well, there's a few components of it that are worth pointing out.
The first is to examine all of your premises, all of the facts that you are assuming or that you think are true.
Many of them may not be reliable, or they may be assumptions.
You may not know whether or not they're true, but they're just something that you're assuming is true.
You also need to examine your logic.
Is the logic you're using legitimate, or is it flawed in some way,
or perhaps it's just systematically biased in a certain direction?
You also should try to become aware of your motivations.
People are extremely good at rationalizing beliefs when they are motivated to,
because they have a desire to believe a certain conclusion.
Understanding your own motivations will help you deconstruct that process
and will give you the skills to, again, lead to conclusions that are more likely to be true
as opposed to the ones that you just wish to be true.
And critical thinking also means thinking through the implications of a belief
that different beliefs about the world should all be compatible with each other.
But we do have a tendency to compartmentalize,
to just have one belief walled off from all other beliefs,
and therefore we insulate it from refutation.
If you think, if this were true, what else has to be true?
And does that make sense?
And just continue that process, and that's a good way to tell how plausible
and how likely to be true a certain belief or claim is.
It's also a good idea to check with others,
because no matter how developed your critical thinking skills are,
there's still one person who's thinking is going to be quirky and individual.
You have a limited fund of knowledge and a limited perspective.
In fact, your knowledge and perspective may be limited in ways that you're not aware.
You don't know what you don't know.
So if you check your beliefs with others, it increases the probability
that any of these holes in your thinking will be covered up.
When a large consensus on a specific claim is achieved,
there's probably a greater chance that that consensus reflects reality
than the process of just an individual.
There's no guarantee of that.
A consensus may be systematically biased as well,
but at least you're stepping out of yourself and the own limitations of your knowledge.
It's also important to be humble, which means knowing your own limits.
We tend to get into trouble when we assume we have expertise or knowledge that we don't have,
or we don't question the real limits of our knowledge.
The world's a very complicated place.
Nobody could know everything.
So we always have to be on the lookout for where the limits of our own knowledge are.
And also, be comfortable with uncertainty.
There are some things we simply cannot know, or we just currently do not know.
There may be times when, after reviewing all the logic and all the evidence,
our only conclusion is we currently just don't know.
The level of uncertainty is fairly great.
Let's give an example from popular culture, which I will frequently do throughout this course.
There are those who claim that there is a large, hominid primate living in North America.
You may call it Bigfoot or use the Indian term Sasquatch.
Is this a credible belief or not?
How can we know whether or not Bigfoot is wandering through the forests of North America?
Well, what are the implications?
If there is one such creature, either he's the very last of his kind,
or if it's a sustainable population, there must be a breeding population around somewhere,
which means there's hundreds and probably thousands of these creatures around.
Where are they all?
What's the evidence for such a creature existing?
Has anyone ever captured a live specimen, found a dead specimen, found a skeleton?
Skeletal remains?
Any completely objective evidence that is not susceptible to misinterpretation?
The evidence that is usually presented is none of those things, no actual unambiguous specimens of Bigfoot.
All we have are what we sometimes call Blobsquatch, fuzzy photographs through trees at the very limits of resolution
and perhaps not well-in-focused pictures.
So anything that we can't clearly identify, that becomes quote-unquote evidence for Bigfoot.
Or there are things that are easily hoaxed, like just imprints of feet or footprints in the mud or in the ground.
But there's nothing that we would consider smoking-gun evidence.
There are eyewitness accounts.
There are people who claim that they have seen Bigfoot.
Well, then that leads to the question, how reliable are eyewitness accounts?
And we will explore that further too, but I will just quickly say now that they're very unreliable for many reasons that we will explore.
Well, if there is no smoking-gun evidence, then why do people persist or some people in believing in Bigfoot?
And that's where the errors in logic and the rationalizations kick in.
Many people engage in what we would call special pleading.
Perhaps Bigfoot can become invisible at will, and that's why we never can capture an unambiguous photograph of him.
Or capture him.
Well, is that really a valid way of excusing the absence of evidence?
And mixed in with all of this, there are just out-and-out hoaxes, like the Patterson-Gimlin film.
This is the iconic movie of what appears to be a Bigfoot walking through a campsite.
And this is still presented by some believers as the best evidence to date of Bigfoot.
However, the film is not incompatible with a simple hoax.
There is nothing in that film that can distinguish it from simply a person wearing a costume.
In 2008, to give a more clear-cut example, Matt Wittin and Rick Dyer claimed that they found a Bigfoot corpse
and that they had the frozen specimen in a freezer.
They even went as far as to call a press conference and to try to elicit the help of scientists to test the DNA of their Bigfoot specimen.
In the end, what they had was simply a stuffed Bigfoot costume, and they were exposed as deliberately concocting this hoax.
Why did they do it?
People do weird things for weird reasons, but they clearly did it.
So we always have to be on the lookout for hoaxes and deliberate deception,
not just innocent or perhaps flawed critical thinking deception in these types of claims.
Let's also go back to the UFO example I gave at the beginning of this lecture.
Those are really interesting questions, whether or not you think that they're very plausible that we could be being visited by aliens.
What I find more interesting than even that question is, why do people believe that we're being visited by aliens?
As human beings, we have the capacity for curiosity as well as reason,
but we are plagued by a host of cognitive flaws and pitfalls that may lead us to even fantastical beliefs that don't really hold up to the cold harsh light of scientific scrutiny.
But the good news is that critical thinking can be learned.
It is a skill that you can learn and that can be reinforced by habit.
The scientific approach to critical thinking is empirical.
It is a way of testing our beliefs systematically against the real world that is out there.
Once we develop our critical thinking skills and really begin to examine our beliefs systematically, it can be extremely empowering.
It's in fact a defense mechanism against all the machinations out there that are trying to deceive us,
whether for ideological, political, or just marketing reasons.
It's also very liberating.
It liberates us from being weighed down by all of those false beliefs and perhaps mutually incompatible beliefs that we tend to hold because of our emotional makeup.
So developing these critical thinking skills is both empowering, liberating, and a defense mechanism against the world that we currently live in.
