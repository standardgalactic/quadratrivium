In this last lecture, I'm going to give some final thoughts on how to apply critical thinking
to everyday life and the importance of scientific literacy and critical thinking in our modern
world.
Taking together this critical thinking and scientific approach to knowledge is known
as scientific skepticism, a term coined by Carl Sagan.
The modern use of the term skeptic does not mean cynic or naysayer or nihilist, rather
it refers to an appreciation for the limits and foibles of the human brain combined with
the power of the self-corrective approach of science.
It puts in place a rational filter through which all claims to truth must pass.
I've been talking about scientific skepticism for years and in response I've received
many letters and emails from people who have taken the basic rules of critical thinking
and applied them to their lives, saving themselves or their loved ones from being the target
of a scam or just making bad decisions about investments, healthcare or purchases, or just
not being taken in by a dubious claim.
To summarize what I've covered in this course so far, we have learned that the human brain,
although very powerful in its way, has many flaws and weaknesses.
We only perceive and attend to a small amount of the world around us.
That sensory input is highly filtered, processed and in fact ultimately constructed.
Immediately after we experience something, that highly altered sensory information becomes
a memory.
Our memories then start to alter further.
In fact every time we remember something we add change and fuse details.
We update the memory.
Further, humans are both rational and emotional creatures at the same time.
We come with a suite of emotional needs and biases.
Our default mode of operation is to make decisions for unconscious or only dimly seen emotional
reasons and then to rationalize them with motivated reasoning.
We then succumb to errors and biases in thinking, logical fallacies, insufficient information
and a poor grasp of math and statistics.
Psychologists have identified many more cognitive biases in fact almost anything they choose
to remember to study about our gut instincts tends to be at odds with reality and then
they assign a name to that error, a cognitive bias.
To give a few more examples, the forward looking bias or the forward bias, we tend to assume
that whatever is relevant or happening now will exist indefinitely into the future.
You may in fact read that if current trends continue then something horrible will happen.
We'll run out of energy for example.
Those all fall victim to the forward bias, they assume that the current variables are
going to remain forever relevant that we won't for example develop new technology that will
change the very nature of the game.
There is also the hindsight bias.
Once we know something to be true, we can then rationalize reasons to justify it as
if we knew it all along or we would have known it or figured that it was true even before
we knew it.
There is also the frequency illusion.
This is a very common one.
It's also known as the Bauder-Meinhof phenomenon.
Have you ever heard a new word for the first time and then in the next day or two you hear
that new word multiple times or the first time you become aware of something, you seem
to see it everywhere?
It seems to defy statistics, to defy random chance, but it's just an illusion based upon
something entering your awareness that previously you were not aware of.
All of these factors conspire together to lead us to make and firmly hold beliefs that
potentially have little or no relationship to reality.
What we believe in fact is a narrative, it's a story that we tell ourselves, stitched together
from flawed information, modified by our cognitive biases and emotional needs and desires.
This is an essential realization, one that separates critical thinkers from those who
think less critically.
Once we accept that we cannot trust what we think we remember, we become humble in the
face of our own experiences and our own knowledge.
Then we're open to the dire need for a systematic approach to knowledge, methods to compensate
for all the many flaws in our brain's function.
In a way, science and critical thinking are our fix for all the flaws in human reasoning.
That is why it has transformed our understanding of ourselves and the universe in which we
live.
And yet, even for those who have a working knowledge of critical thinking, it's difficult
to fully appreciate the potential for self-deception.
Every day I hear people say things such as, well, how can so many people be wrong?
Or do you think everyone who thinks that they were, for example, abducted by aliens, or
saw a ghost, or felt that they were healed by some treatment, et cetera, do you feel
that they're all either lying or crazy, as if those are the only options, that if somebody
comes to an erroneous belief, there must be something wrong with them or they're deliberately
deceiving us?
No, that's just the human condition.
We all come to dramatically erroneous beliefs all the time.
Our biases and flaws will lead us to those beliefs unless we put in the filters of critical
thinking.
There is a tendency overall to grossly underestimate the human potential for self-deception, even
among critical thinkers and skeptics.
We all want to view ourselves as rational beings, but that is just the greatest self-deception
of all.
If you think you are not biased and that you cannot rationalize a completely erroneous
belief, then that is just the greatest bias of all.
That's the master bias, the one that can undo all of your critical thinking skills.
We spoke previously about the fallacy of experts who begin to think that their expertise makes
them infallible.
Often times scientists and great intellectuals may become more susceptible to self-deception
because they lose their intellectual humility.
And that is the ultimate lesson of our understanding from neuroscience and psychology, humility
in the face of our own knowledge and beliefs.
So yes, millions, even billions of people, can be profoundly wrong about a belief for
hundreds or even thousands of years.
For example, it was widely believed and accepted as true in Western culture for thousands
of years that bloodletting was an effective treatment.
This wasn't questioned, everyone just knew it to be true.
Entire cultures may endorse a belief system which is strongly then reinforced by confirmation
bias.
Eventually, the apparent examples of support seem overwhelming.
Confirmation bias can be that powerful and deceptive.
There is also extreme social pressure to conform.
Our in-group identity is tied to specific belief systems which are common in that group.
If you are listening to this course, then you probably want to be a better critical
thinker yourself.
First, it is important to apply the rules of critical thinking to yourself most of all.
The famous physicist Richard Feynman famously said, the first principle is that you must
not fool yourself, and you are the easiest person to fool.
But there are barriers to being more critical thinking ourselves.
Once you invest, for example, your ego into a conclusion, then motivated reasoning will
kick in and distort and bias your critical thinking into that direction.
In the end, your education, your knowledge, and your critical thinking skills will still
lead you to the wrong answer.
You will just be much more confident in your error because you have rationalized it in
a much more sophisticated way, unless of course you really apply that critical thinking to
your own beliefs.
If on the other hand, you invest your ego in the process of critical thinking and not
in any particular conclusion, then you will be more free to follow the logic and evidence
wherever it leads.
You will in fact take pride in your ability to change your opinion as new information
becomes available.
Being called on using erroneous logic or biased thinking or incomplete data, that will be
what you will fear.
And in order to seem consistent and in order to meet the emotional needs of your ego, you
will focus on getting the process correct, not on being correct in any conclusion that
you have set your stakes into.
I mentioned that we cannot change human nature in that our personalities seem to be highly
resistant to change by therapy or by other means.
However, recent neuroscience is finding that the brain can actually change its wiring in
response to use.
This is called brain plasticity.
Sometimes this is simply learning.
The brain can learn and remember and with our increasingly sophisticated technologies,
we can see that process occurring in the brain.
And habits of thought can also become more ingrained.
However, you simply cannot change your basic personality profile.
Personality has proven to be remarkably resistant to change.
What you can change, however, is how you deal with your basic emotional makeup.
This begins with what some psychologists call emotional intelligence, insight into your
own emotional makeup.
And this is why knowledge of psychological needs and cognitive biases, all the things
that we covered in this course, are so important.
So we cannot change what we evolved in terms of our basic emotional needs and how we react
to things and the biases that tend to be shared or common among people.
But we can change how we respond to those emotions.
We can engage our frontal lobes, our executive function, and develop adaptive responses.
These responses can be learned and ingrained through habit and effort.
Throughout this course, I have advocated the application of rational thought, scientific
methods, and skeptical thinking.
This frequently prompts some to ask if this critical thinking approach of life denies
human emotions.
I frequently hear, well, what about love, beauty, and art?
Critical thinking, however, is not at odds with these things.
The full emotional palette is part of the human condition, and it is healthy, even rational,
to embrace it.
This is part of my point.
I'm not advocating that you deny your humanity, that you deny human emotions.
Simply that you understand them, that you understand the influence they have over your
thinking, and that you put in place systematic processes that will lead you to conclusions
that are more reliable.
When it comes to beauty and art, I would also agree with what Richard Dawkins wrote.
He was expressing the view that many scientists have had.
He wrote a book called Unweaving the Rainbow.
In this book, he argued that understanding the science that underlies the world, such
as the beauty of a rainbow, does not diminish that beauty at all.
If anything, it enhances it.
We live in a beautiful, subtle, elegant, and complex world.
Understanding something about how it works has a profound beauty of its own.
I'd also point out that the science that results from this scientific view of the world gives
us the ability to see things such as the rings of Saturn close up.
We have more beauty that we can see because of the fruits of the scientific world view.
In line with this view is the realization that, as far as theories and facts are concerned,
there is no absolute right and wrong.
There are only degrees of confidence.
Further, all conclusions are tentative because our information is always incomplete.
In other words, what Emerson said about life applies here as well.
Empirical knowledge is a journey, not a destination.
You need to be comfortable with uncertainty.
If, however, you think you have arrived at absolute truth at the final answer, then your
journey is over.
That journey is the process of science and critical thinking.
Again, this gets back to focusing on the process rather than any specific conclusions that
you hold to be an absolute or final outcome.
It's actually a very empowering perspective on the world.
To be a critical thinker is to be comfortable with uncertainty, comfortable with the limits
of human knowledge, and aware of all the many flaws and limitations of human intelligence,
and therefore not married to any one conclusion.
To be flexible in the face of new ideas and new information, but at the same time, not
afraid to acknowledge that some ideas are objectively better than others.
We do know stuff.
Reliable scientific knowledge is possible.
Logic can be valid or not valid.
Some data is more reliable than other data.
Being flexible does not mean being gullible in the face of any claim.
It means critically analyzing all claims and judging them fairly on their own merits.
Another question I frequently receive from those trying to be better critical thinkers
is how to deal with family and friends.
What do you do when someone states a belief or claim that you believe to be wrong or invalid?
Well, there really isn't any one answer.
A lot of this will depend upon your relationship with that other person.
But there are some ideas to keep in mind which you may find helpful.
So first, you have to recognize that no one likes being told that they are wrong or having
a valued belief taken away from them.
At some point, at the same time, you don't want to appear to be accepting an illogical
or false belief.
So there could be a delicate balance.
And there may be important decisions at stake, such as whether or not to seek an unconventional
treatment for a serious illness.
So you don't just want to stand by passively while somebody makes what you understand to
be a very bad decision.
One approach that is helpful is to simply ask questions.
Engage the other person's natural tendency to be curious and to ask questions themselves.
Engage their critical thinking and their skepticism.
If, on the other hand, you take a full frontal assault at their beliefs, you will be encouraging
them to engage their defense mechanisms, their rationalization.
So turn it around.
Just ask them questions about, well, how do you think that works?
Why do we know that?
How could we know that?
Do you think that this other possibility may also be true?
Also, we recognize that this is extremely rare for someone to simply abandon a valued
or strongly held belief system when confronted with disconfirming information.
In fact, recent psychological research shows that when this happens, when people who have
a firmly held belief are confronted with facts that disconfirm that belief, people tend to
dig in their heels and hold the erroneous belief even more strongly because they are
being encouraged to defend the belief, to think of and recall reasons that their belief
is true or that the alternatives are not true.
That in the end has the result of reinforcing the belief rather than getting them to think
more critically or skeptically about the belief.
Another approach is to give analogies, to talk around the problem a little bit or examples
that would encourage them to question certain aspects of their belief.
Get a seed of critical thinking and doubt, then encourage it over time and see what develops.
For example, if someone relates a story that they were abducted out of their bed in the
early morning by aliens, instead of just telling them that your experience is incorrect or
your interpretation of the experience is incorrect that didn't happen to you, encouraging them
to get defensive and dig in, you might simply relate the fact that, well, I have read elsewhere
that there are people who have had similar experiences, experiences that seem the same
as what you're describing to me.
And some of them were found to have had a neurological event known as a waking dream.
You can then provide them with links or articles with more information.
It's interesting to view this struggle between critical thinking and our cognitive and emotional
biases as a discussion, perhaps even a conflict that happens inside of our brains, between
our various brain regions and networks.
There are parts of your brain telling you to think or believe one thing while other
parts are filtering it through reality testing or other processes.
Critical thinking is the process of engaging your higher cortical function as a filter and
control on the more primitive parts of your brain.
Not only can we all strive to be more critically thinking ourselves, but we can also strive
to make those around us more critical thinkers.
And further, if our goal is to make society overall more scientifically literate and
critically thinking, then we can also change our educational system.
Our culture can also change, especially the way science and information is presented in
the media.
As we saw in a previous lecture, our society generally does a poor job of teaching critical
thinking skills and scientific literacy.
As a society, we can learn to approach science and education as a process, as I was recently
describing, rather than a set of answers or beliefs that never change.
Science news items, for example, should be framed as part of an ongoing process of scientific
discovery, not always as a definitive breakthrough that finally gives us the answer to this scientific
mystery.
Education can also focus on teaching children the process of science, not giving them authoritative
answers to memorize.
And we need to think of education as more than what happens in the classroom.
As evidence shows, in fact, most of your learning will take place outside of the context of
a classroom.
I find it very encouraging that scientists are increasingly engaging with the public,
trying to make their discipline, their science, more accessible, and engaging in ongoing education
themselves through blogs, podcasts, and other social media and the new media.
This is a great new tool that our civilization has to disseminate information, to close that
gap, make a connection between actual working scientists who are truly experts in the field
and who have also found the passion to teach their science to the public.
And there are those who think that this is largely responsible for a positive trend in
the public becoming more scientifically literate.
The numbers are still low, but they are getting better.
Further, it is a process, it's critical thinking, of questioning and constantly updating our
knowledge.
We're never content to just sit on a fact as if it is final, though there is the emotional
desire to do just that, to seize on an answer, and then to freeze our beliefs in place, check
that box and not worry about it anymore.
In statistical analysis, this method of constantly updating as new information comes in is called
a Bayesian approach.
A Bayesian analysis starts with what is called a prior probability, the probability that
some phenomenon is real or some claim is true, some hypothesis is true, based upon everything
we already know, all of the science that we have accumulated up to this point.
It then looks at any new information and updates that prior probability with the new information,
a Bayesian analysis that then gives us the post-probability.
What's now, what's the new probability that this claim is true, given the new data?
This is a process that we generally do in our everyday lives, as we learn new things,
we update what we think about the world around us.
We acknowledge all the limitations and uncertainties in the data and in our conclusions, and then
we constantly update our tentative conclusions as new data comes in.
All conclusions are tentative, but we also acknowledge that there is a range of confidence.
Some conclusions may be so highly confident that we treat them as approaching 100%, although
we never quite get there, we're always open to new revision.
It also needs to be pointed out that we live in a highly complex civilization, an increasingly
complicated civilization.
There has been and continues to be a geometric increase in scientific knowledge, meaning
that our scientific knowledge is not just growing, it's accelerating.
You can contrast this to what psychologists call our evolutionary milieu, the environment
in which humans evolved.
Certainly it was complex in its own way, many plants and animals to learn about, for example,
but nothing compared to the complexity of our current civilization, and again, of course,
the problem is getting much worse.
The evolved adaptive cognitive tools that may have been well suited to the plains of
Africa, but they simply are not up to the task of mastering all the complexities of
our modern world.
Science, skepticism, and critical thinking, including formal logic, you can think of as
rigorous processes that we use to handle the complexity of our world, because our flawed
brains are simply not up to the task by themselves.
There is another process to handle this complexity that has been specifically proposed.
In the book The Checklist Manifesto, author Atul Gawande makes the same points that I
just made that in our increasingly technological and complex world, we are getting to the point
where we're overwhelming our brains, we're overwhelming our cognitive ability to deal
with all of the details that are necessary.
In some professions, in some practices, there is a high degree of complexity, and there
is also a very unforgiving environment where the tiniest error can have catastrophic outcomes.
He points to examples such as flying a B-52 bomber or any modern commercial jet.
A small error may lead to a crashed airplane and many deaths, or to modern surgery, where
a small error, a small cognitive error, may lead to, for example, operating on the wrong
side of the body or the wrong limb.
Those are catastrophic outcomes resulting from tiny errors.
He recommends as one external mechanism, one fix, what he calls the checklist.
This checklist is simply a systematic list of things that you go through on takeoff or
before entering surgery, for example, so that you don't forget any little thing that
you need to do, and so that everybody has a moment to pause, to get on the same page,
and to go through the process systematically.
It's systematically rigorous, an external mechanism, just like science and critical thinking, rather
than relying heavily on our own memory and experience, which even when profound is just
not enough when the tasks are complicated enough.
Also I would argue that it's this process, this Bayesian approach of updating our beliefs
as new information comes in, this constant updating approach to knowledge that should
be reflected more in the classroom and in the media.
I feel that oftentimes the media treats scientific inquiry as if it were a black box.
Nobody really knows what goes on inside that black box.
Science is treated as some kind of arcane ritual, only understood by scientists who
are treated almost as a priesthood within a given field that spit out authoritative answers,
and all we have to do is just listen to what the scientists tell us.
Rather science should be presented as an understandable and accessible process, a transparent process.
We can't all be experts, but we can all understand it to some degree, enough to at least get
a feel for how it works and when it tends to be legitimate.
The critical thinking approach to knowledge and life is also very empowering.
Its power comes from its acceptance of reality.
As Carl Sagan said, for me it is far better to grasp the universe as it really is, rather
than to persist in delusion, however satisfying and reassuring.
That I've always felt is a very good way to encapsulate the skeptical approach to knowledge
and belief.
Scientific skepticism is also a mature view of the human condition and knowledge.
It is not scandalized, for example, by the flaws in human efforts of science, nor, however,
is it naive about the existence of those flaws and the limitations of the human brain.
We accept the flaws, we accept those limitations, and we understand the messiness of science,
and yet we see it as a process that slowly grinds forward and improves the reliability
of our knowledge.
The critical thinking approach is to do the best that we can with full knowledge and appreciation
for those weaknesses and limitations.
Putting all the pieces together then, the goal of this course is to understand all of
the cognitive and other biases that rule our thinking.
This is what I call the monkey brain level of thinking.
Without understanding all of these biases, we are destined to simply be carried along
by our monkey brain inclinations.
We're along for the ride, as opposed to being in the driver's seat.
Engaging our executive function frontal lobe critical thinking puts us in the driver's seat
of our own beliefs.
With a thorough understanding of logic and cognitive biases, we have the opportunity
to engage in what is called metacognitive reasoning, thinking about thinking.
We can consciously put into place a metacognitive self-check or filter on our own reasoning.
We literally engage the frontal lobe part of our brain, which hierarchically can override
the more primitive parts of our brain.
It's a filter that can inhibit, literally neurologically inhibit, those primitive impulses.
We can try to transcend our biases by being aware of them and asking, does this belief
really make sense?
And even if it makes sense, is it actually true?
How do we know it's true?
How can we separate it from other ideas, other hypotheses that may also fit the data, that
may also be true, by systematically doubting knowledge and ourselves, but in a positive
constructive way that leads to more inquiry and exploration?
Along with the understanding of metacognition, when logic and evidence leads us to uncomfortable
conclusions, this creates cognitive dissonance, which I've discussed previously.
Recognizing that dissonance and how it will motivate you and powers you to engage in metacognition,
to choose an adaptive, more rational resolution, rather than following the neurological pathway
of least resistance, in other words, rationalizing a convenient answer.
This is when we will tend to use our logic and our highest cognitive ability to rationalize
rather than reason, to have our cake and eat it too by convincing ourselves that we are
both logical and can still hold our emotionally appealing beliefs.
It is not easy, and it takes practice, knowledge and dedication to stay in the metacognitive
realm to allow the facts and logic rather than our biases and emotions to rule our thinking.
The ultimate irony of this course is that in taking the metacognitive critical thinking
approach, thinking about thinking and the nature of knowledge, one comes to the unavoidable
conclusion that you should not trust me as any kind of definitive authority.
You should question everything that I've said in this course, check my sources, verify my
facts and reason things out for yourselves, because after all, I am just one person trying
to make sense of a horrifically complex topic.
And in the end, I may be wrong about some things.
By listening to this course, you have already demonstrated that you are someone who enjoys
the intellectual journey of learning and thinking, as do I.
It is, I think, an ennobling journey, engaging the better part of our nature.
Thanks for letting me take this small part of that journey with you.
Thank you.
Bye.
