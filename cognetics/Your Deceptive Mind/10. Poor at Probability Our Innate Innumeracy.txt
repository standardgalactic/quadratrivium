How many times have you heard or said, what are the odds?
As a reaction to a seemingly unlikely event.
We then search for an explanation, some meaning to those events, because randomness or just
dumb luck doesn't seem to cut it.
This may even lead to a belief that numbers themselves hold some mystical meaning, a belief
called numerology.
The fact is that humans are terrible at probability.
Our brains are very good at certain tasks like pattern recognition and many other things,
but we have a horrible sense, innate sense of probability.
We especially have difficulty dealing with large numbers.
We appear to have evolved an intuitive sense of small numbers, up to four, five or six
or so, but can only deal with large numbers in the abstract language of mathematics.
This enumeracy, as it has been called, leads to a number of probability-based cognitive
biases.
For example, the sense of coincidence.
When two events seem to coincide with each other, we tend to notice this.
That is part of confirmation bias, another bias I discussed in a previous lecture.
We see this coincidence as highly improbable.
This has led some people to speculate that there are no coincidences, that everything
happens for a reason.
This is part of another cognitive bias, the meaning bias, the need for the world to make
sense or have some meaning.
This naive assessment, however, ignores all the misses, all the many events that happen
in our lives that do not line up.
We experience, hear, see, dream, thousands of things every day.
By random chance alone, events should appear to line up occasionally.
You dream of a friend you haven't seen in ten years and they call the next day.
In isolation, it seems amazing, but if there were never any such coincidences, that would
be unusual and that would demand some explanation.
The law of large numbers makes coincidences like that inevitable.
Also, that belief in coincidences neglects the fact that there are many people in the
world.
For example, in a city with one million people, a million to one coincidence should happen
to someone every day.
Such stories are likely to propagate as they are compelling.
They seem to hint at a deeper meaning to reality.
So they spread and you're likely to hear stories of really improbable coincidences
occurring.
This is also an example of what we call the lottery fallacy, which I mentioned in a previous
lecture.
We tend to ask the wrong questions.
What are the odds of John Smith winning the lottery?
Well, it's hundreds of millions to one against.
So when John Smith wins, we might think that it couldn't have happened by chance alone.
However, the real question is, what are the odds of anyone winning the lottery?
Well, it turns out it's pretty good.
Someone wins a particular lottery every few weeks.
It's a statistical certainty that eventually someone will win.
This also relates to the law of large numbers.
We are bad at intuitively understanding the probability of very large numbers.
What are the odds of someone winning the lottery twice?
This seems vanishingly small.
It's hundreds of millions to one against squared.
But when we consider all people playing all lotteries, the probability is actually quite
good.
And this, in fact, happens on a regular basis.
For example, Valerie Wilson, who works at a Long Island deli or used to, said she won
another $1 million on a lottery scratch-off game just recently.
The first time, I couldn't believe it, she told Newsday.
This time, she said, God's on my side.
She felt compelled to look for a deeper meaning to the fact that she personally won the lottery
twice.
And it was difficult for her to intuitively understand that this is something that can
happen by chance alone.
In fact, statisticians Stephen Samuels and George McCabe of Purdue University calculated
the odds of anyone winning any US lottery twice to be something like 1 in 30 for just
a four-month period and better than even odds over a seven-year period.
And this matches the number of times that it, in fact, happens that someone wins the
lottery twice or more than once.
This comes up in other contexts as well.
This is more than just about playing the lottery.
For example, what are the odds of a patient having two rare diseases?
A resident I was instructing recently expressed disbelief that a patient that we were treating
together could have two very rare diseases.
He calculated the odds of a specific patient having those two specific rare diseases as
very low, millions to one against based upon the incidence of those two diseases.
But he was asking the wrong question.
He was committing the lottery fallacy.
He should have been asking, what's the probability of any individual having any two rare diseases?
It is, of course, much higher.
It's so much higher that it should happen on a regular basis.
And of course, those patients will likely present to physicians for treatment having
two diseases.
And therefore, doctors should see on a regular basis patients who individually may have an
extremely rare condition or set of conditions.
This all plays into confirmation bias.
Again, as I said previously, confirmation bias, which will come up again and again in
this course, is a powerful influence on our thinking.
Because we can think of, or perhaps we have personally experienced, events that support
our beliefs, we take that as confirmation that those beliefs are correct.
But that's because we are mining a vast set of personal experiences, a vast set of data
for just those bits of data that appear to confirm beliefs that we have.
This is also part of what I have described as the availability heuristic, because examples
of something are easily available to us, we assume we feel as if that phenomenon must
therefore be commonplace or representative, when in fact it could just be the quirkiness
of our own individual experience.
We therefore underestimate the probability of events occurring at random.
Let me give you a common example that comes up frequently, especially with things like
alleged psychics.
Magicians understand that cold reading is a technique.
It's a technique that you can use, you can learn.
It can even be used unconsciously.
Regardless of the mechanism that a psychic and alleged psychic uses, whether it's tarot
card reading or an astrological reading or palmistry, the underlying technique that they're
using is called cold reading, or at least it's indistinguishable from a cold reading.
This also counts heavily on confirmation bias.
The psychic will throw out a lot of statements and they count on the subject remembering
all the apparent hits and then forgetting all of the misses, but also the subject or
the client will search for connections that seem to confirm the psychic's guesses, and
then they will take that as confirmation.
All the hard work in a cold reading is really being done by the subject.
They're the ones who are searching their vast memories of all the things that involve their
lives and looking for connections to what the alleged psychic is saying.
The person doing the reading is actually not doing the hard work.
Of course, we can test this hypothesis by systematically evaluating the statements made
by alleged psychics to see if they do have quote-unquote hits more often than we would
expect from just educated guessing.
When you do that, it turns out that they have many, many more misses and far more misses
than the subjects remember.
After a reading, the subjects do tend to remember the hits and vastly overestimate the accuracy
of the reading, but when it's recorded and counted, there are many more misses than
hits.
Further, we underestimate how high probability some guesses are.
This gets back to the forer effect I also described in a previous lecture where we tend
to take vague statements and then apply them in detail or directly to something about our
lives or our connections.
How many people know a woman whose first name begins with the letter M?
This may sound like a specific statement, but it's actually a very high probability guess
or a date that has the number three in it.
Sometimes a psychic, while doing a cold reading, will throw out the number three.
If they don't initially get a hit, they'll say it could be the day of the month or it
could be a number in the month.
They will expand it until some connection is made.
This is a technique identical to the one used by mentalists or stage magicians who do the
same thing for entertainment.
Or they might throw, as another example, the statement out that there is something to
do with water or I see a red door or a person in uniform.
Again, it seems specific, a person in uniform, but actually if you think of all the number
of different kinds of uniforms, everyone is likely to know somebody who has a connection
to some kind of uniform.
Let me talk also now about anecdotes.
These are essentially uncontrolled observations and scientists use the term anecdote in a
deliberately pejorative way to mean that, well, this is very dubious form of evidence
because the variables are not controlled and the observations are not systematic in any
way.
The reason why that is a problem is because anecdotes are a way of subconscious data mining,
again, subject to confirmation bias and memory effects and other cognitive biases as well.
We are not aware of the fact, like with coincidences, that we are mentally searching through large
amounts of data from our everyday lives looking for patterns.
Therefore, seeing a pattern should not be surprising.
We should expect, in fact, to see patterns all the time.
Humans are excessively good at doing just that.
So our anecdotes are a way of remembering hits and forgetting misses and seeing patterns
in a vast, perhaps, unappreciated set of data.
Sometimes bad research will use data mining techniques deliberately.
They make a what are the odds lottery type fallacy.
For example, what are the odds of this connection, not what are the odds of any connection?
This may crop up innocently, a doctor seeing patients who happen to have a similar pattern
of exposure and ailments, for example, may think that he has hit upon some risk in the
environment.
Hey, I've seen three patients in the last month who have this disease and all who had
a similar exposure.
They then ask the question, what are the odds of that happening by coincidence alone?
Rather than asking the question, what are the odds of me seeing any cluster of symptoms
at some point in time by chance alone?
Apparent patterns seen with data mining need to be confirmed with independent data sets.
So that doctor seeing that cluster of patients with the same ailments shouldn't ignore that
anecdotal evidence, but he should use it only as a method of generating a hypothesis.
Perhaps this is a real pattern.
All he could really say is that there is an apparent pattern here and recognize that
apparent patterns are going to crop up all the time by random clustering alone.
Then he then has to ask, well, if this is a real pattern, we should see it in an independent
data set.
The hypothesis then needs to be tested in a more rigorous or systematic way.
A fun example of this pattern searching through large sets of data or a data mining exercise
is a book that was published called The Bible Code.
What the authors did was look for hidden codes in the Bible, although you could do this with
any large book, any book really, by stringing together disconnected letters.
They used a computer algorithm to look for patterns of letters spaced out in the Bible.
And then they were amazed to find phrases appear that these disconnected letters could
be put together in a pattern, a pattern of words and phrases that they then further pattern
matched to events in world history.
Now this practice underestimates the probability that some pattern would be found by random
chance alone.
It also grossly underestimates the human ability to find meaningful patterns in randomness.
For example, these random phrases were then matched to all of world history, and of course
you can find something that will seem to fit.
But again, our intuition is once we seem to see the fit, it seems very compelling to us.
Here's a funny example of just this.
Some 46th of the King James Bible published in the 46th year of William Shakespeare's
life.
The 46th word is shake, and the 46th word from the end is spear.
What are the odds of that occurring?
Well, of course, it's vanishingly small.
But we really have to ask what are the odds of some weird coincidence happening?
And since there are so many potential coincidences that could happen, the answer is, over time
it is certain that very low probability coincidence, like the Shakespeare one I just described,
will happen on a regular basis.
Early Psi research, or extra-century perception research, also fell prey to inadvertent data
mining.
And this kind of thing can crop up even in very legitimate and well-meaning research.
It is something that researchers need to learn how to specifically avoid.
There was a practice called optional starting and stopping.
Again, this was a naive method of data mining.
It occurred because ESP researchers who were testing subjects to see if they could predict
what a target subject was looking at, typically these used the Zener cards, remember the
cards with, for example, a star, wavy lines, a square circle, et cetera, on it.
And then a target subject would look at a card and concentrate while the subject who
was being studied for their psychic ability would try to guess that card.
When the researchers looked through the data, they found that there were strings of excess
hits where the subject guessed greater than chance the card that the target was looking
at.
Now they hypothesized that, well, maybe psychic ability needs a warm-up period.
And then maybe further, the psychic ability will tire out.
So after a while, the researcher, the alleged psychic who was being tested, their ability
would wear off or would turn off.
So this is what led to optional starting and stopping.
They would look for a string of hits in the series of data.
They would discard everything before that as the warm-up period.
They would discard the data after that as the ability wearing off.
And they would just count the string of excess positives.
But this was a way of mining a larger data set for a random cluster of hits.
If you look at the entire data set, there is no excess of hits.
If there really were a string of psychic guesses in the middle of random guessing, there would
still be an excess of hits to misses greater than probability alone.
But there wasn't.
And that pretty much killed the hypothesis of optional starting and stopping.
Again, it is a very telling historical example of using data mining in bad research.
Notre-Dame is another classic example of retrofitting, of looking after the fact for some kind of
pattern recognition as a way of mining inadvertently a large data set.
Nostradamus was famous for his quatrains, most of which are vague poetic predictions.
These have come from the first century.
Here is an example of one.
A coffin is put into the vault of iron, where seven children of the king are held.
The ancestors and forebears will come forth from the depths of hell, lamenting to see
thus dead the fruit of their line.
Now that sounds very poetic.
It may sound very profound.
And if you search through all human history to look for a connection, you may be able
to find matches to some of the phrases that are said.
But the problem with Nostradamus' predictions is that they predict too much.
You could look at any segment of world history and find some events that seemed to match
what he was saying.
However Nostradamus made his predictions specific by mentioning specific names, locations,
or dates, his predictions failed miserably.
People can only find matches after the fact, so-called retro-dicting.
And as we will see in science in general, being able to explain things after the fact
is not a good predictor of a correct theory.
You have to be able to predict things in the future, and that's something that no
one has been able to do with Nostradamus' predictions.
Let me turn now to the topic of randomness, which I've brought up already in this talk.
So quick, think of a random string of 10 digits from 0 to 9.
Got it?
Chances are the string is not random.
We have such a poor intuitive sense of randomness that we are incapable of even generating
a mathematically random set of numbers.
We tend, for example, to alternate numbers more often than a random string would.
We avoid lumping or clustering numbers together because clusters of numbers don't look random
to us.
Again, our naive intuition about randomness is different than true mathematical randomness.
Let's take the night sky, for example.
The stars in the night sky are fairly randomly distributed.
They're not evenly distributed, and even distribution of stars would make it look like a grid pattern.
And we probably would recognize that as not being truly random.
The point is that the stars in the sky tend to cluster.
They cluster in a way that a random pattern does.
Further, we recognize patterns in that those random clustering of stars.
We call them constellations.
Every culture has recognized constellations in the night sky and assigned patterns meaningful
to their culture, to their time in history, to those patterns.
This is what mathematicians call the clustering illusion.
We have a poor naive sense of the degree to which randomness clusters.
To give another example, diseases tend to cluster.
They're not evenly distributed throughout society.
They're randomly distributed.
The Center for Disease Control and other organizations whose job it is to track diseases like cancer,
for example, will find that there are clusters that crop up from time to time.
After investigation, they determine that most such reported clusters are statistical
flukes, not a real effect.
It is simply the clustering effect of randomness.
But people who experience the cluster have a strong belief, a powerful belief that they
must be real.
If you have an uncommon disease and your next door neighbor gets the same uncommon disease,
like leukemia, for example, it's very difficult to shake the sense that that can't be a coincidence.
Something must be going on.
That is, we are hardwired to feel that, that that must be the case.
But only objective, thorough, rigorous, systematic analysis can really tell you if this is just
a random cluster or a real effect out there in the world.
Let me give you a more common example that from sports.
Many people watch sports or play sports, and we develop a lot of statistically based biases
and false assumptions based upon that.
There is, for example, a belief in the hot hands effect.
In basketball, for example, we believe that when a shooter, a basketball shooter is doing
well, he's made a few baskets, that he's on a streak.
He is more likely to make more baskets.
However, when statistically analyzed, there's a clear answer to this, and that answer is
no.
There is no real effect of hot hands.
Shooting streaks in professional basketball tend to follow a random pattern.
If players had hot and cold streaks, real hot and cold streaks, and effect other than
randomness, there would be more and longer streaks than is predicted by randomness alone.
But when large sets of data are looked at rigorously, we find that there just isn't
these longer streaks.
The amount of streakiness that we see in making and missing baskets is exactly what we would
predict by randomness alone.
Yet the belief in the hot hands effect among players and fans is very hard to shake.
I've had this experience myself, where I've tried very emphatically to explain to a basketball
fan that there is no hot hands effect.
Even when they eventually understand the statistics, they cannot bring themselves to believe that
there is no effect there.
Something must be going on, and they also fall prey to the availability heuristic and
that they can easily reach for explanations for the effect.
Players are confident, and that confidence makes them perform better.
Of course, when they miss, that's because they were overconfident.
When they're missing, then they get shaken.
They are now, their confidence is down, and therefore they're more likely to make a mistake.
However, you can use the opposite reasoning.
When they've missed a few baskets in a row, you might say, well, they're due.
They're due to make a basket.
Or when they've made a few baskets in a row, they're due to miss one.
We can use this contradictory reasoning to explain anything that happens, but our intuition
is to apply some meaning to what is statistically proven to be a random sequence of events.
This crops up frequently in gambling as well.
Gambling is, in fact, a giant exercise in probability.
Those count on the fact that people are terrible at probability.
There is, in fact, a fallacy called the gambler's fallacy.
If you just flipped a fair coin heads 10 times in a row, what is the chance of flipping heads
on the next toss?
Our intuition often tells us, well, it's probably less than 50-50.
If you just flipped heads 10 times in a row, then tails is due.
Or you may ultimately think that, well, you're on a streak of heads, so the chances increased.
Again, you could easily use mutually contradictory reasoning to explain any outcome.
However, the answer is 50%.
If it's a fair coin, there's a 50% chance of heads and a 50% chance of tails on any flip.
The gambler's fallacy is in not recognizing the fact that each coin flip is a completely
independent event.
What has happened previously therefore does not have any influence on the future events.
In fact, again, assuming the premise that it's a fair coin and a fair flip, thinking
that what has occurred previously affects future flips is akin to magical thinking.
But gamblers, just like sports fans and players, engage in a lot of superstitious magical thinking
in order to gain some sense of control over the randomness of events.
We tend to think that we are on a streak of heads.
Again, this streak is a consequence of assuming that events are connected.
Or we may think, again, that tails are due.
These are mutually exclusive or contradictory.
But it gives us the ability to assign an explanation to any possible outcome.
Another statistical effect that, when we're not aware of it, can bias our thinking or
cause us to invent an explanation for an event that is a statistical event is called regression
to the mean.
What this means is that in what we call the drunken walk of randomness, a random walk
like a drunkard will lurch at random to the left or to the right, they may go to the left
for a while, but then will tend to come back to an average outcome.
Or if you think of the bell curve, a distribution curve of probable events where most average
events cluster in the middle and then to either side, there are progressively less likely
and less frequent events.
We can, for example, use the performance of a professional sports star.
Let's say, for example, a baseball star and their ability to get hits.
They may have an exceptional season.
They may, just at random alone, perform to one side of the bell curve.
Whenever that happens, whenever we have a statistical effect that deviates from a statistically
average effect, it is likely that that will be followed by a more average effect.
It will regress to the mean.
This is just random chance alone.
That's because two statistically unlikely events are unlikely to occur in a row.
Therefore players doing statistically above their average are likely to regress to their
average performance.
However, this doesn't feel like the answer to us.
So we invent all kinds of magical thinking to explain this illusory effect of just randomness.
For example, there is something called the sports illustrated curse.
After a player gets on the cover of sports illustrated for having an above average performance
year, they will then falter.
They will then have a bad year following the year they had that got them on the cover.
But regression to the mean alone explains that occurrence.
We don't need to hypothesize that the player got cocky or sloppy, or perhaps they were
distracted by all the media attention.
Having an above average year, you're almost guaranteed by regression to the mean in order
to have a more average year following that.
Knowledge of mathematics and probability are critical for making sense of the world.
In many ways, we live in a mathematical universe.
It is the language of explaining how things work.
But we have to simultaneously recognize how terrible we are at doing so naively.
We did not evolve to have a really highly developed sense of mathematics.
The solution to this weakness, however, is two-fold.
The first is metacognition, understanding the flaws in our natural cognitive tendencies
and then substituting formal mathematical analysis for our naive senses.
We will see this pattern again and again in this critical thinking course.
We see and recognize the cognitive flaws in our naive brain processes, and then we substitute
a formal process of logic or analysis in its place, liberating us from those very flaws.
