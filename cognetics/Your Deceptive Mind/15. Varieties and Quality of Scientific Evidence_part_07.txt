evidence that Andrew Wakefield looked for were replicated in detail, and it was found
that his results were erroneous.
They did not pan out in replication.
And other types of data being brought to bear found also that there was no evidence for
any association or correlation between risk of autism and the MMR vaccine.
But the damage was done.
The single preliminary study was reported, and that created fears which had spread to
other nations and still reverberate today.
So when looking at any research question, does a toxin present a risk factor for a disease,
or does a treatment work, and is it safe, for example, you have to look at all of the
literature and put it into context, not just individual studies.
There are other features to the literature that you need to take into consideration.
One is called publication bias.
In an ideal world, every single study that is performed would be published and would
be part of any systematic review of the literature in order to answer a question.
This is another way of counting all the data.
You can count all the data in an individual study, but you have to also count all of the
studies in order to capture all of the data.
Statisticians do what is known as a funnel plot, which shows the scatter of results from
different studies on the same question.
Statistics predicts that they should vary around the true effect size.
Every study won't have the exact same results.
There will be kind of a bell curve, a scatter of results, with some being more positive
and some being more negative, and then as studies get better and better quality, larger
size, more rigorous, better controls, then the variability in the outcome of those studies
should decrease, that should narrow, that the pyramid should come to a point at the most
definitive studies, which show the true effect that is being looked for.
The question then becomes is, when the best studies get done, does the funnel plot show
that the results zero in on no effect at all or a real phenomenon or a real effect?
However, sometimes what the funnel plots show is that the negative end of that pyramid is
missing.
The negative studies or the less positive studies are simply missing from the literature.
This reflects publication bias.
The tendency for researchers to make more of an effort to publish their study results
when the results are interesting and positive and good for their career and reputation,
and for journal editors to also have a bias towards publishing positive studies, the kind
that will get good press releases and draw attention to their journal as opposed to negative
results which are less interesting.
When researchers look at the literature, the arc of the research on any specific question,
we also find that effect sizes tend to shrink over time as better and better studies are
done.
So, not only does the evidence tend to zero in on the true effect size, but the effect
