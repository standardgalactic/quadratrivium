In the first section of this course, I described how massively flawed our brains are as a tool
for understanding the universe.
But I also concluded on a positive note that we have our highly evolved frontal lobes,
the ability to abstract and to reason.
In this next section of the course, I'm going to go over some tools for how to use that reasoning
ability to override the flaws in our neurological function.
I'm going to start with the discussion of logic and arguments.
Now we use the term argument in a slightly different way than you may use it as a day-to-day
basis.
You probably argue every day.
By that I do not mean that you have a verbal fight with someone else, although you may
also do that.
What I mean is that you construct a logical argument in order to justify or reach a conclusion.
The purpose of an argument is often, we think, to convince others of your position.
But in reality, it's more than just that.
More broadly, it is to construct a statement that can be used to support a position or
a conclusion.
This is a primary tool that we have in exchanging thoughts and ideas with others, and also for
constructing our own beliefs about the world.
Yet many people do not know how to use this very important tool.
Despite the common usage, as I said, the purpose of an argument for a critical thinker is
not to win.
The goal is not to win the argument, although that is often the default mode of how we behave.
We pick a side and then defend that side at all costs, marshalling whatever arguments
we think can defend that position.
But the better approach, the critical thinking approach, is to value the process of developing
your arguments and reaching those conclusions.
A critical thinker should be willing to change any conclusion when new information or a better
argument is presented.
So the purpose of an argument is to discover which conclusions are most sound, are most
likely to be true, that are best supported by logic and the evidence.
It is primarily to improve our own beliefs and our own conclusions, not just a way of
defending them.
This gets to the difference between reasoning and rationalizing.
Rationalizing is a process of starting with the conclusion and then figuring out which
arguments can be marshaled in order to defend that conclusion.
Where reasoning focuses on the process going forward, where the conclusion flows from the
logic and not the other way around.
When we use the rationalizing process, which can seem very superficially like reason, that
in fact is the point of rationalizing to make it seem as if your conclusions are reasonable.
We use that to rationalize decisions that we've already made or conclusions that we've
already arrived at.
When we have a conclusion that is discordant, that is not in line with the facts or is challenged
by a new argument or a new piece of information.
Our tendency is to rationalize away that new information in order to resolve the cognitive
dissonance that results and then our brains reward us for doing just that.
To avoid cognitive dissonance, we should focus rather on the process.
So in other words, if you don't tie yourself firmly to a conclusion, then you won't feel
any emotional dissonance when new data comes to light that shows that the conclusion is
wrong.
As long as your process is valid all the way through, it's okay to change your conclusion
when new data or arguments arise.
Specifically, in logic, the term argument is a set of statements used to support a conclusion.
An explanation is not an argument.
An assertion, simply asserting that something is true, is not an argument.
An argument must take the form of starting with specific premises and then logically
deriving a conclusion from those premises.
A premise is a starting point, a fact or assumption that we take as a given at the beginning of
an argument.
If a premise is false, then any argument that is based upon that premise is not sound.
This means that it's very important to examine all of the premises and to recognize what
the premises of an argument actually are.
Often that is a missing step in an argument.
It's easy to focus on the logic and to forget that that logic has to act on certain premises.
The hidden premise is perhaps the most pernicious aspect of an unsound argument.
If we don't even know that a fact or an assumption is a premise of an argument that we're making,
then we can't examine it.
Oftentimes, when two people disagree, they are not aware of the fact that they're starting
from different premises that they're just taking for granted.
There is no possibility of resolving their different conclusions until they drill down
to all the premises that go into the arguments that they're using to defend their conclusions.
Assumptions can be used as premises.
Some premises are assumptions, and we need to recognize when that is the case.
When you are starting with a statement that is not an established fact, it is not known
to be wrong, it is not a wrong or a false premise, it simply is an assumption.
It is not known whether or not it is true.
It may also not be wrong or it may be right to a degree, but it may be incomplete.
You may have an incomplete premise that does not fully capture the entire situation.
Assumptions or incomplete premises weaken an argument.
They don't make them wrong, but they weaken it because the argument is only as good as
the premises on which they are based.
Having said all that, when two or more people disagree over a factual statement, what that
means is that one side or both sides must be wrong in some way.
Obviously, two mutually exclusive conclusions, by definition, can't both be correct at the
same time.
So immediately, when you and another person disagree over a factual statement, immediately
you know that one or both of you is wrong.
The goal should therefore be not to, again, marshal whatever arguments you can to defend
your side, but to examine both of your arguments to find out where the assumptions are in the
premises, where the false premises are, or where the errors in logic are.
You know that there has to be one or more of those somewhere.
If the two of you can work together in order to discover the errors in assumptions or logic,
then you should be able to resolve your differences and come to a better conclusion.
That is a much more practical approach to a disagreement than simply defending whatever
side you happen to take at the beginning, regardless of the validity of logic or the
correctness of the premises.
I'm going to cover a little bit of jargon that I have been using and will continue to
use in this and the next lecture specifically.
The term true means that a claim is factually correct.
It is in line with reality.
Arguments themselves are not true or false.
Their conclusions are true or false.
I'll also note that in most cases we do not have access to truth with a capital T with
metaphysical certitude.
What we're really talking about is something that is established to a sufficient degree
that we can treat it as if it were a fact, although we know that all true statements
are tentative in some way because they are dependent upon our incomplete current level
of knowledge.
The term valid refers specifically to logic.
One or more premises may still be wrong or unjustified, but an argument is valid when
it is impossible for the conclusion to be false if the premises are true.
The term valid only refers to the logic, meaning that the logic works.
The term sound refers to the entire argument.
Argument is sound when all of the premises are true and the logic is valid.
The conclusion of a sound argument therefore must be true.
By definition, the argument is not sound otherwise.
The logic that is employed means that if the premises are true, the conclusion must also
be true.
The conclusion of an unsound or invalid argument, however, may or may not be true.
Demonstrating that an argument is unsound or invalid does not prove the conclusion false.
It just removes that argument as justification for the conclusion.
For example, I might state that the sky is blue because the sun rises in the east.
The premise is correct, the sun metaphorically rises in the east.
The conclusion is true, the sky appears to be blue, but there is no logical connection
between those two statements, it's a non-sequitur, so therefore the argument is unsound despite
the fact that the conclusion is true.
The type of logic that I'm talking about in this lecture is deductive logic.
Deductive logic uses a premises to connect to a conclusion.
One goes from the general, therefore, to the specific.
You start with some general statements and then you deduce a specific instance that must
be true if those general premises, those general statements, are themselves true.
For example, this is like a classic textbook example, if we take as premise one, all men
are mortal and as premise number two, Socrates is a man, then we can arrive at the conclusion
that Socrates is therefore mortal.
The conclusion must be true if premise one and two are both true.
Conclusions of deductive logic are positive assertions, they are truth statements.
It's important to recognize that they are not valued judgments.
This is another way in which two or more people may disagree over a conclusion.
Some of the things that we hold that we believe are value judgments, they are aesthetic judgments.
They are not pure statements of fact or logic alone.
For example, there is no way to prove that Beethoven is better than Mozart, that Beethoven's
music is more enjoyable to listen to than Mozart.
There is a subjective artistic judgment involved there.
It's very useful to recognize this because oftentimes people have an argument where there
is one or more value judgments in the premises and when you identify that, then you can at
least agree to disagree.
You've at least identified the source of your disagreement and you realize that it's not
purely resolvable by facts alone and that it is your differing value systems or value
judgments that is leading to the different conclusions that you're arriving at.
For contrast to deductive logic, inductive logic goes from a specific observation to
general principles, so it goes in the opposite direction of deductive logic.
It's more of a statement of probability also than certainty, whereas the deductive conclusion
must be true, inductive logic is used to decide what is probably true based upon observations.
This is largely based on this mode of inductive logic or inductive reasoning.
As an example, if we take as a premise that every swan that has ever been observed is
white, we may come to the inductive conclusion that therefore all swans are white.
However, this statement is falsifiable.
The observation of a single black swan will render the statement untrue.
Then the statement might have to be modified to most swans are white or perhaps all swans
except for the species of black swans are white.
In order to be valid, deductive logic means that the conclusion must flow from the premises.
If the premises are true, then the conclusion must also be true.
If not, then the logic is invalid.
In other words, even if the conclusion may still be true, that does not make the deductive
logic valid.
The conclusion absolutely has to be true in order for the logic itself to be valid.
As an example, an argument may take the form that all A are B, C is A, therefore C is B,
stating it in more of a mathematical term.
In other words, if A is contained within the set of B, anything that is a member of set
A must therefore also be a member of set B. This is a statement that absolutely has to
be true.
It's like a mathematical truth.
Logical fallacies are arguments in which the conclusion does not have to be true if the
premises are true.
The generic term for this type of invalid logic is the non-sequitur, which literally
means it does not follow.
The conclusion does not follow from the premises.
There are many specific types of non-sequiturs of logical fallacies, and in the rest of this
talk I'm going to review some of the more common types of these logical fallacies.
The first type is the argument from authority.
This usually takes the form of a conclusion is correct because an authority figure asserts
that it is correct, that it is true.
Dr. X says it's true, therefore it's true.
The more general form of this logical fallacy could be that a conclusion is correct because
a person or a group making the claim have some positive or admirable attribute.
John says it's true and he's a nice and kind man, therefore his conclusion must be correct.
This links to the tendency to surrender the will to a charismatic authority figure that
I mentioned in a previous lecture.
We have this evolved desire to get along with the social group and to follow a leader of
some sort.
Therefore we have this tendency to respect celebrities or officials or experts or professionals,
somebody who has some claim to authority.
That brings up the idea that logical fallacies derive from different things.
The argument from authority derives from this evolved tendency to surrender our will to
authority figures.
Other logical fallacies, however, give us the ability to rationalize.
When we are defending a conclusion that isn't true, we can't use valid logic and premises
in order to support it.
We have to either use assumptions or false premises or we need to use invalid logic in
order to construct an argument to defend an incorrect conclusion.
That's what logical fallacies are.
They're essentially our mechanisms for rationalizing our own conclusions.
But getting back to the argument from authority, this logical fallacy can also be over applied,
meaning that we can dismiss legitimate arguments by the claim that they are the argument from
authority.
In other words, because the argument from authority is a logical fallacy, that doesn't
mean that we should be dismissive of the value of the consensus of expert opinion, for example.
That consensus does not have to be correct, but that doesn't mean that we shouldn't take
it seriously.
If a consensus derives from a robust program of research, of discussion, of a group of
experts going over a lot of evidence, hammering out their differences, hammering out their
objections, and finally arriving at a hard one consensus, that process of arriving at
that consensus of experts should be given some consideration.
It's at least a reasonable starting point, or at the very least you should have a good
reason for rejecting the consensus before doing so.
That doesn't mean that you're making an argument from authority, that a claim must be true
simply because an authority figure says so.
A different logical fallacy is the argument from final consequences.
The form that this fallacy typically takes is, well, some claim cannot be true if it
results in consequences that I don't like or that I find abhorrent, or the opposite
is something is true because it serves a positive purpose.
For example, those who deny the scientific conclusion that life on Earth arrived through
a process of organic evolution, so-called evolution deniers, will frequently make the
argument that, well, evolution can't be true because if it were, then we evolved from quote
unquote lower animals, then there would be no basis for morality.
Now I disagree with that premise that there would be no basis for morality, but even if
you did agree with that premise, it still doesn't mean that evolution isn't true.
The truth can sometimes have unwanted or bad consequences.
This form of argument is what's called a teleological argument because it reverses cause and effect.
In other words, it starts with the effect, the absence of morality, and says that that
somehow prevents or causes evolution to not be true.
Another more direct example of this teleological argument is the strong anthropic principle.
It is true, it is a true premise that the universe has all the physical attributes necessary
for life to exist.
It must because we exist.
The soft anthropic principle says just that.
Of course the universe has to have all of the physical attributes for there to be life
because we know that life exists in the universe.
The strong anthropic principle says that the universe has those physical attributes so
that life can exist, that the ultimate outcome of life caused the universe to have the attributes
that it does, or that the universe was designed to have those attributes so that life could
exist.
We often see this argument in conspiracy theories, for example.
Now I'll cover conspiracy thinking more thoroughly in a later lecture, but quickly the logic
that often goes into conspiracy theories is the principle of quibono, or who benefits.
If an event occurs, the conspiracy theorist might ask, well, who benefited from this event?
And then they would argue that therefore that person must have engineered or caused the
event through some hidden conspiracy.
For example, LBJ became president after JFK was assassinated, therefore he must have had
a hand in that assassination.
Or George W. Bush was able to justify a war in Iraq and a war in Afghanistan with the
events of 9-11, therefore he must have caused the events of 9-11, he must have had a hand
in it.
This ignores the fact that with any big event, any big world historical event, there are
going to be winners and losers.
There are going to be people who benefit from that event, even if it's a horrible or negative
occurrence, and there are going to be those who lose, and it doesn't always mean that
the winners were responsible for the event itself.
But I will say that that may be a reasonable basis for generating a hypothesis, maybe the
person who benefited from it was involved, because at least they have a motive.
But it can't be used to conclude that they were responsible for the event, that's the
logical fallacy.
A very common logical fallacy is the post hoc, ergo, proctor hoc fallacy.
Do this therefore because of this.
We tend to assume that if B follows A, that therefore A must have caused B. This logical
fallacy derives from innumeracy, a naivete about statistics and probability.
We are impressed with the pattern that B followed A, and we intuitively or instinctively don't
like the explanation that that was a statistical fluke or just random chance.
So we like to impose meaning on the patterns that we see.
One meaning is that, well, A must have caused B. For example, this very commonly comes up
in my own field of medicine.
If patients present with symptoms, with an illness, and then they take a treatment for
that illness, and then they get better, they often credit the treatment for making them
better.
That may be true, but it's not necessarily true.
They may have gotten better all on their own.
As the old saying goes, if you don't treat a cold, it'll last for a week.
If you treat a cold, it'll last for only seven days.
Very similar to this is confusing correlation with causation.
Here, the former of the argument is not just that B follows A, but B correlates with A
in some way.
Where we see B, we see A. The assumption, therefore, is that, well, A must cause B.
That's why they occur together.
However, this is not logically the case.
It's possible that B causes A. It's also possible that some other factors, C or D, cause both
B and A. Those would all be explanations for why there is a correlation between A and B.
This is even assuming that the correlation is real and not itself a coincidence.
Random distributions tend to be clumpy, so there are a lot of false correlations, correlations
that are due to statistical flukes alone.
Even if the correlation is real, at the very least then, we have three hypotheses.
A causes B, B causes A, where both A and B are caused by some other factor.
Like with the argument from authority, the logical fallacy of confusing correlation with
causation or assuming causation from correlation can be over-applied to dismiss the very legitimate
significance of a correlation.
Once we establish that a correlation is real, that doesn't mean that there's no causal relationship
between the two things.
It means that there's a number of possible causal relationships, one of which may be
the simplest one that A causes B. For example, it was noted that cigarette smoking correlates
with certain types of lung cancer.
The assumption was that smoking probably is causing cancer to occur.
Smoking contains a lot of harmful chemicals.
We've demonstrated that some of those chemicals could be a carcinogen, so it makes sense.
It's the simplest explanation.
But the tobacco industry actually employed the correlation does not equal causation logical
fallacy argument to say that, well, we cannot assume that smoking causes cancer just because
the two are correlated.
At various times, they argued that this factor X, this mysterious third factor, causes people
to both smoke and get cancer.
Even for a while, they floated the idea that cancer causes smoking, that cancer causes
irritation in the lungs and anxiety, which is relieved by smoking, and therefore cancer
motivates people to take up smoking.
Those could be considered less plausible hypotheses to explain the correlation.
But further, we can use other correlations to test the various hypotheses.
If smoking causes cancer, then we would expect that the more you smoke, the greater your
risk of cancer, that inhaling would cause more cancer than not inhaling, that smoking
unfiltered cigarettes would cause more cancer than filtered cigarettes, and that after quitting
smoking, your risk of getting cancer would then subsequently decrease.
All of those correlations turn out to be true also, and therefore we can use multiple correlations
to triangulate to the most likely causal hypothesis, smoking causes cancer.
But all of this evidence should not be dismissed as a logical fallacy.
It's only a fallacy if we assume one particular cause and effect from the mere correlation
itself.
Logical fallacy is special pleading.
This can also be called ad hoc or post hoc reasoning, meaning we're inventing reasons
as needed in order to explain certain aspects of the evidence or to jerry-rig problems with
an argument.
This logic is not formally invalid.
In other words, the arguments that are put forward may in fact be legitimate as far as
they go.
The fallacy comes in the process of just invoking these arguments after we know that they're
needed in order to jerry-rig a problematic conclusion.
For example, proponents of extrasensory perception, or ESP, may argue that the reason why well-controlled
studies of ESP fail to show any ESP effect is because of the presence of skeptics, that
a skeptical mind somehow prevents ESP from working.
They've actually generated hypotheses that believers in ESP allow the effect to occur,
and those with a skeptical worldview prevent ESP from happening, and that's why the researcher
researcher effect, where the attitude of the researcher affects the outcome of the study.
That may be true for other reasons in terms of biases and how well the researcher's conducted,
but the notion that just the mere presence of a skeptic keeps ESP from working was invented
ad hoc as needed to explain away the negative results of well-controlled studies.
There is no a priori or reason before such an explanation was needed in order to invoke
that concept.
Once again, what we see is with this kind of logic that this may be a way of generating
a hypothesis, but can't be used as a premise or as a conclusion in order to explain away
inconvenient evidence or the absence of evidence that should be there.
The special pleading fallacy is related to the fallacy of limited scope, introducing
a new element that is not a broadly applicable principle.
It narrowly addresses a single flaw in evidence or argument.
The perhaps most famous example of this is one that was given by Carl Sagan in his book
The Demon Haunted World.
He invited the reader to imagine someone claiming that they have a dragon living in their garage,
and when you ask them to see their dragon, they say, well, the dragon is invisible so
you can't see him.
Well, perhaps we can spread something on the ground and look at his footprints.
Well, the dragon floats and wouldn't leave any footprints.
Well, maybe we can measure the heat of his fiery breath.
Well, this dragon breathes a heatless fire.
Well, can I touch the dragon?
Well, he's also insubstantial.
So, for every experiment that you can devise to test for the presence of the dragon, a
special, very narrow reason is invented that would explain away the absence of that evidence.
This type of argument has been invoked frequently to explain why there is no smoking gun evidence
for the existence of Bigfoot or Sasquatch.
Some have argued that, well, perhaps he can turn invisible at will, and that's why you
can never capture him on a photograph, or perhaps he can travel through other dimensions.
He can disappear when needed to, and that's why you could never trap him.
Other forms of special pleading include the notion that aliens don't want us to know that
they are here.
They therefore will give us ambiguous little bits of evidence, but not smoking gun definitive
evidence.
Billy Meyer, who was a Swiss farmer who has been claiming for decades that he has been
in constant contact with aliens, for example, uses this type of argument to explain why
his evidence looks as if it's been hoaxed.
For example, he presents a photograph of a pretty typical flying saucer, which appears
to be attached to a tree for support, and he argues that, well, for whatever reason,
the aliens chose to fly around that tree.
When the area of the photograph was later investigated, it was found that the tree was
not there, which is what you would expect if the tree were a model he used only for
that photograph, to which Billy Meyer explained, well, the alien had the tree removed for some
unknowable reason.
These are all just special pleading arguments in order to explain away why the evidence
makes it seem like he has been engaged in a hoax.
Arguments are an opportunity to resolve differences of opinion.
Discovering hidden premises, factual errors, and flaws in logic should be the goal.
But remember, it's important to use these tools to improve one's own beliefs, not just
to prove why other people are wrong.
In the next lecture, we will cover more of these logical fallacies.
