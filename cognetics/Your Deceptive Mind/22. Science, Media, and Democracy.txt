Every day, I read science and other news stories that make incredible claims.
Some of them turn out to be reliable, while others, not so much.
For example, have scientists discovered a treatment that can regrow the end of a finger
and therefore perhaps more extensive injuries?
Has a lone researcher unexpectedly found the cure for multiple sclerosis?
Have astronomers found an Earth-like planet around a nearby star?
The broader question is, how does one find reliable information?
It's one thing to have basic critical thinking skills, but without accurate facts and a good
understanding of specific topics, those skills have nothing to work with.
Before we get into some specific examples, here are some rules that will help.
First, no one source is definitive.
Before accepting any piece of information as probably true, make some attempt to verify
it.
Do not trust any one source as definitive.
If possible, see what multiple independent sources have to say.
That is becoming more challenging on the internet because often single sources are repeated
endlessly on many sites.
A very useful strategy is to specifically look for disconfirming information or a contrary
opinion.
Try to find out what the people on the other side are saying.
Searching for the topic of interest, for example, with the keywords scam, skeptics, skeptical
or fraud can often be very helpful in getting you to those other points of view.
But see what all sides are saying about an issue before deciding who has the strongest
case.
It's easy to make what seems like a convincing case when you are only being presented with
one side.
And of course, it's important to consider the quality of each source.
There have been many reviews, for example, of online information quality.
One 2010 survey by Starman et al. of health information found that accuracy ranged from
46 to 61 percent.
So even the best sites still had significant problems.
Also, academic and non-profit sites generally had better information than commercial or
individual sites.
In general, don't trust sites that are trying to sell you something or have an apparent
political or ideological agenda.
Also, the more controversial a topic, the greater the chance that information will be
skewed or biased in some specific way.
In such cases, it is especially important to survey a number of sources to get the
broadest perspective possible.
Some topics are genuinely controversial, even among experts.
For example, are biofuels a useful strategy for achieving energy independence and limiting
greenhouse gases?
At present, for ethanol specifically, whether or not more energy comes out of the process
than is put into it depends on exactly how you make the calculations.
So experts disagree on this question.
In addition, there are many so-called manufacturers or questions that are not controversial among
scientists or experts but are made to seem controversial by ideological groups.
Examples include the safety and effectiveness of vaccines.
Experts largely agree that vaccines are both safe and effective, but there is a vocal group
of anti-vaccine activists who create a tremendous amount of information online arguing the opposite.
Is the planet warming?
And are man-made causes like CO2 emissions contributing significantly to this warming?
The scientific community largely says yes, but this balance is not reflected in the public
debate on this topic.
Many people get the majority of their science news from the mainstream media, whether online
or from more traditional venues like television or newspapers.
Therefore, it is critical to have a working understanding of the strengths and weaknesses
of how the media presents science.
The quality of information is highly variable, as is the background knowledge and skills
of journalists and editors.
Also, not all scientists know how to interface with the media, and they may unwittingly contribute
to misinformation.
I'm going to give you examples of bad science news reporting and use them to discuss the
various pitfalls of science journalism.
The first starts with this headline from the Telegraph, Pixie Dust Helps Man Grow New Finger.
Just about every major news outlet ran a version of that headline.
The story told is of Lee Spivak, who reportedly cut the end of his finger off.
However, his brother happens to own a company that is researching a tissue regeneration powder
made from pig bladders, whimsically called Pixie Dust.
Allegedly, this powder helped Spivak regrow his lost finger.
This is what we call science by press release.
With decreasing revenues going to traditional journalism, news sites have had to cut back.
Many have reduced or eliminated their science reporting divisions, and now generalist journalists
and editors are covering the science beat.
What distressingly many outlets do is reprint, sometimes with little or no alteration, science
press releases.
Now, of course, the best outlets, like the New York Times, for example, specifically
will not reprint press releases as news stories, but many outlets do.
They often do no independent fact checking and just accept the press release at face
value.
There are many problems with this.
Even respectable universities have a press office that may try to sensationalize a news
story to get their institution in the news.
Often the researchers have little or no input into the copy of the press release.
And worse, private companies can use the science press release, essentially, to advertise
their products or drum up interest in their company, perhaps to attract investors.
In this case, the story was generated by Spivak's brother, who was apparently trying to increase
interest in his company and in its new product.
The story itself is almost entirely bogus.
Spivak did indeed injure his finger, but not a single joint was missing.
All that happened was typical wound healing.
Sometimes the very ends of fingers can regrow with such healing, but this is very different
than the impression given by the press that Spivak had regrown a lost finger.
Essentially, the press was duped by a self-serving marketing campaign.
Or perhaps many outlets didn't really care how accurate the story was.
They had a source, they were reprinting the source.
As long as they got their sensational headlines, which they certainly did.
The next story is also about a claim that itself should immediately raise skeptical red
flags.
Dr. Paolo Zamboni, an Italian vascular surgeon, claims he has found the cause and a cure for
multiple sclerosis.
Multiple sclerosis is a serious autoimmune or inflammatory neurological disease where
the immune system attacks the brain and the spinal cord, causing any number of neurological
deficits.
He claims MS is due to a condition known as chronic cerebrospinal venous insufficiency,
CCSVI for short.
Essentially partial blockage in the veins that drain blood from the brain.
Further, he claims that he can cure MS by opening up this blockage with venous angioplasty
and stenting.
Essentially snaking little balloons into the veins, opening them up in order to relieve
the blockage.
This understandably has excited the MS community and the media around the world breathlessly
reporting how this lone maverick has challenged decades of MS dogma.
There are multiple problems with how this story is often being reported.
The reporters make the mistake of confusing the authority of an individual with the authority
of the scientific community.
However, no matter how many letters someone has after their name, their opinions are still
the quirky opinions of just one individual.
Reporters however often defer to such authority.
They have an expert, somebody who should know the answer to whatever question they're reporting
on and they're reporting the opinions of that expert.
This is often how they source non-science stories so it fits in with their process.
Often it seems like simply justification for making sensational claims however, you can
find an expert to say something then that's fair game.
However, you can find an expert to say almost anything.
It doesn't mean that it represents the consensus of opinion in the scientific community.
A good journalist would put the opinions of any individual into their proper context.
Further, the press love stories about the lone maverick taking on traditional beliefs.
It's a narrative that resonates especially within our individualist culture.
Sometimes those mavericks turn out to be correct but far more often their speculations do
not hold up under further research.
That's the nature of scientific research in general.
This represents another common error, confusing speculative research with confirmatory research.
Most speculative research turns out to be wrong in the long run but the public is often
treated to an endless sequence of scientific research and then never hear the follow-up
that the preliminary findings turned out to be wrong.
A lot of science news reporting is just premature.
For example, we may hear that a certain food or nutrient is good for you and then a year
later we hear that it's bad for you.
Wine daily is prevents heart attacks, wine daily is a risk factor.
It seems to go back and forth with each story is being reported totally in isolation without
being put into the proper context of this is a preliminary report.
We can't rely upon this.
We have to look at this in the context of the other hundred studies that have already
been done which says that this is probably not true.
That's the kind of real science journalism that we need.
When it's not provided then we're simply being given little bits of information that
often seem contradictory and generally don't pan out.
In the case of Zamboni, his claims have now been replicated many times.
Most of the follow-up studies have not found what he did.
No one has found the amount of correlation that he did between the venous blockage and
MS.
Some studies found a lesser degree of correlation.
Some found essentially no correlation that there was just as much venous blockage in
patients with other neurological disease or in even healthy controls.
Many patients with MS do not have venous blockage.
Inferring a causal effect between these venous blockages and multiple sclerosis seems very
tenuous.
The research so far is moving in the direction away from Zamboni's claims.
Further, the evidence continues to pile up that MS, multiple sclerosis, is an inflammatory
disease with a genetic predisposition.
In fact, there is decades of research showing that MS is an autoimmune disease.
And of course, was the cause of the initial skepticism among the neurological community
that if Zamboni were correct, we have decades of research which has been misleading or incorrect.
So Zamboni's one preliminary study was flying in the face of mountains of data leading to
a very different picture about multiple sclerosis.
Unfortunately, this particular genie is now out of the bottle, as it were.
The promise of a potential cure for multiple sclerosis has caused some in the MS community
to rally behind Zamboni despite the negative evidence coming in.
Some are calling for clinical trials, which seems premature given the negative evidence
so far.
Some even claim that there is now a conspiracy against Zamboni, a conspiracy of neurologists
or MS experts who don't want to be told by this upstart outsider, this vascular surgeon
what the true causes of MS are.
As we discussed in the conspiracy lecture when the evidence is not going your way, you
can always invoke a conspiracy to explain away the evidence.
In the end, a lot of time and resources will be wasted on what is likely to turn out to
be a dead end.
This situation was greatly exacerbated by the premature press reporting.
This is part of the double-edged sword of free access to information.
Traditionally, these scientific controversies would be worked out in the scientific literature
and at professional meetings, long before the public was made aware of them.
Now the public essentially has a ringside seat.
They get to see how the sausage is made.
They see the scientific debate as it's occurring.
You might argue that this is a good thing.
It is good for transparency and it will help the public understanding of the process of
science and I agree with that.
But at the same time, it causes a significant risk because the public may not be prepared
to understand how that process of science works.
If they are being misled by a press, a media looking for sensational headlines and not doing
the proper background work to put the story into context, then again they may be misinformed
into thinking that we have a potentially viable treatment for MS and a conspiracy of silence
and repression rather than what is much more likely to be true is this is just one more
preliminary claim.
These kinds of claims of a new dramatic treatment or cause for MS are actually nothing new.
It seems that every few years, every decade there is another such claim and they never
pan out, at least not so far.
The evidence is pointing increasingly strong in the favor of a genetically predisposed
autoimmune disease as the cause for MS.
So in the end, more harm may be caused than good by inappropriate reporting of this unfolding
controversy within the scientific community.
This I think is good in the long run but the public now has to be educated more about the
messy process of science and specifically about the nature of speculative research.
In other words, it is essential to remain skeptical of new ideas until they have had
time to go through the meek grinder of scientific research, peer review and replication.
Most new ideas in science fail.
They turn out to be incorrect in the long run.
Very few ideas stand the test of time.
So the public needs to learn patience and healthy skepticism when it comes to new ideas
in science.
Despite the frenetic pace and short attention span of the news cycle, it can often take
10, 15 or 20 years for a new idea in something like medicine, medical science, to go through
the long tedious process of research before we really know what the potential of a new
idea is.
Some ideas will die after a short time.
They simply don't pan out as soon as they try to be replicated.
But if the reporting is premature and preliminary and without this proper context, people are
simply left with the idea that, hey, wasn't there some new treatment for MS, something
about opening up the veins?
The sensational headlines get much more attention than the follow-up, which is not as interesting
and not as sensational to the public, although the scientific community certainly finds
it so because that's where the real interest is.
Reporters also may fall into a trap known as false balance.
This is another chronic problem with many science news stories, especially about controversial
topics.
The standard journalistic practice is to cover both or all sides of any controversial issue
equally.
This makes sense when it comes to politics or areas where opinion is dominant.
You're not going to cover a political story, for example, unless you equally cover both
sides of the political spectrum.
But this approach does not work well for science news.
Just because science news stories, even genuine controversies are often what we call asymmetrical.
You may have 95 percent of the scientific community coming down on one side of a controversy
and 5 percent coming down on the other side of a controversy.
A journalist, however, wishing to report balance of the story may present both sides as if
they are equal.
It even gets much worse in some instances.
For example, a reporter may report on the very unconventional claims of a lone researcher
or scientist or maybe even sometimes not a scientist, just somebody who has a very interesting
but certainly very likely to be untrue claim to make.
Then they balance that lone individual with their unconventional claims against the entire
scientific community that may hold a different view as if that's balance.
Sometimes in fact, the scientific view is given only a token approach.
You have what's called token skepticism in the reporting where the news story is almost
entirely about the lone individual making the speculative and unconventional claim.
And then the fact that the scientific community completely disagrees with that and has a mountain
of evidence to back themselves up is given just a token mention at the end for balance.
Science is about verifiable and testable factual claims.
There is often a huge asymmetry, as I said, in science controversies.
For example, let's take the notion that the earth is growing.
There is a small minority of believers on the fringe who believe that the earth is gaining
matter and growing significantly over historical time.
Further, that the reason the continents seem to fit together like a puzzle is not because
of plate tectonics, but because at one time the earth was only as big as the continents
and they broke up when the earth grew.
When subjects like this get covered, however, reporters at best will feel obliged to give
the issue balance.
So they have one expert present the growing earth theory and then a regular scientist
explains what the other 99.9% of scientific community think.
But just presenting the two views as equivalent gives a very false impression to the public.
It elevates the fringe idea and makes it seem as if it's a legitimate scientific idea.
So in the very framing or formatting of the story, the reader or the consumer of the news
is being given misinformation and a false impression about the status of the science.
One more example of this from recent science news.
It was reported that researchers from the opera experiment, the Oscillation Project
with Emulsion Tracking Apparatus, situated 1400 meters underground in the Grand Sasso
National Laboratory in Italy, that they measured the speed of neutrinos.
Neutrinos are a particular type of primary particle with very little mass that interacts
only extremely weakly with matter.
That they reported that neutrinos were traveling faster than the speed of light.
This violates Einstein's theory of special relativity.
Of course, if you want to get a sensational news headline, you can't do better than proving
Einstein wrong.
And this would be legitimate, although sensational, science news if true.
However, the results are preliminary and they're almost certainly in error.
Even the researchers who came up with these results themselves acknowledged that their
results are probably an error of some type.
The neutrinos were faster than the speed of light by only 60 nanoseconds, 60 billionths
of a second.
That's an incredibly small amount of time to measure.
Already, there are several proposed causes for this error.
In the first months following this story, there was no definitive answer.
It is a genuine scientific puzzle.
But it is likely that the media will not present the prosaic answer with as much enthusiasm
or high a profile as the initial and almost certainly incorrect findings.
Another example of a story that is frequently presented preliminarily in the media is the
discovery of an Earth-like planet.
I seem to read this headline almost every couple of months.
The new exoplanets or planets around other stars are being discovered all the time.
Many of them have new and interesting properties that have not been discovered before.
But the holy grail of an exoplanet is one that is Earth-like, another Earth potentially
because it may therefore have life, complex life like us.
However, so far, all of the reports of an Earth-like planet have been premature.
They are Earth-like in some way.
They are closer to our size and mass than previous exoplanets.
They may be in the so-called Goldilocks zone where liquid water can exist on the surface.
But all of them have had significant departures from being Earth-like.
For example, they may be very close to their star or they may be tidally locked.
So one side of the planet faces the sun at all times.
Some of them have been shown to have water on the surface, an atmosphere like Earth,
similar gravity, truly Earth-like.
We will get there eventually, probably, but so far reporting on this story has been premature
and in a very sensational direction.
Critical thinking, however, is not just about science.
In fact, the more political and emotional an issue, the more critical thinking is necessary.
This raises the important question, what is the relationship between science and politics,
ethics, and other value systems?
There is a range of opinions on this question as well.
Sam Harris, for example, has written about this issue and argues that ultimately you
can have a system of ethics that is entirely science-based.
I and others have disagreed to some degree.
This is ultimately a philosophical question, not a science question.
The position I think that has the most merit is this, that science can certainly inform
ethical and political questions and thinking, but there is always some subjective value
judgment in the mix.
So while science can inform us about how to think about these questions, how to approach
these questions, and the implications of our ethical system, it can't make these ethical
judgments for us.
Science education is also another issue that is important to any democratic society.
In democratic industrialized nations, it is important for citizens to have a working
knowledge of science.
Researcher John Miller has termed this civic scientific literacy.
This can be viewed as the ability to understand the science section of the New York Times,
for example, or to follow along with science documentaries such as NOVA.
It is also the ability to have a basic understanding of the important science-related issues of
the day.
Miller has found in his most recent survey that only 28 percent of Americans meet the
minimal criteria for civic scientific literacy.
The good news is that this figure, 28 percent, is up from 10 percent in the 1980s.
Miller has been doing the same survey now over many years, over several decades, and
this is good because it gives us the ability to make direct comparisons over time.
So the number is still low, about one in four only of Americans are scientifically literate
about basic issues, but that's up from 10 percent in the 1980s.
The numbers are also slightly higher in the United States than they are in Europe and
Japan.
This means that the vast majority of people living in industrialized nations do not have
the minimal scientific knowledge to participate in important scientific issues of the day.
And it should be noted that Miller's estimates are higher than many other surveys which ask
the same basic question, what is the level of scientific literacy in society?
Of course the number you come up with depends on where you draw the dividing line, but for
most surveys about basic scientific literacy, numbers come up that are in the five to ten
percent range.
Most people who aren't working scientists don't meet the criteria for scientific literacy.
Experts propose a number of possible causes and fixes to this problem of scientific illiteracy.
Basically the quality of science education needs to improve at all levels.
Science textbooks are also frequently criticized for their poor quality.
One study shows that requiring science classes for non-science majors at the college level
has a significant impact on scientific literacy.
And I think this point should be emphasized.
If high quality science education is reserved only for science majors, then we will continue
in the situation that we have now where only people who go into a science-based field have
a basic level of scientific literacy.
I would also argue that improving the overall quality of science reporting and science in
mainstream media is also highly important.
As I covered in this lecture so far, most people learn most of their science from the
mainstream media after they're outside of the classroom by reading articles, reading
magazines, and now reading entries on the Internet.
So it's important to raise the overall quality of science news reporting.
That's where most people are going to get most of their information.
We live in a world increasingly dominated by science, yet most people are without the
basic critical thinking skills and scientific knowledge to deal with the relevant science.
Both of these are required to deal with the flood of complex scientific information.
Critical thinking skills end by basic scientific knowledge.
One does not substitute for the other.
If you have critical thinking skills but no basic scientific knowledge, you have nothing
to apply those skills to.
And even a working scientist with detailed knowledge, even expertise in a field who
lacks critical thinking skills may fall prey to a lot of the foibles that I've discussed
in this course.
In the next lecture, we will explore this idea even further by discussing the nature
of expertise itself and the scientific consensus.
