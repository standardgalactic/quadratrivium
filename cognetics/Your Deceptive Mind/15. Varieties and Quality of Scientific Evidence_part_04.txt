You also need to consider, was the data collection systematic and continuous?
This is often a subtle problem with studies that can be difficult to detect unless you
know the very specific kinds of questions you have to ask.
For example, if people are being surveyed, did everyone answer the survey?
Surveys are actually usually considered to not even be legitimate scientific studies.
They're considered to be unscientific because depending on the methods, they're often not
rigorous in their design.
For example, if you send out 1,000 surveys and 100 people send back their surveys, you
really don't have any idea about the likes and dislikes or the features that you were
surveying in that 1,000 people.
You only know about the 100 people who chose to respond to the survey.
That introduces a massive systematic bias in the data.
You can also, in other words, the people can be self-selective and you can't know what
bias has led to that self-selective data.
In a study of patients, you might also ask, was every patient or sequential patients included?
For example, a researcher might say that patients with a certain symptom who presented to their
clinic were tested with a drug versus a placebo or maybe even without a placebo, just a new
treatment to see what their experience were.
But was every patient counted?
Did the patients who had a good response come back while patients who did not have a good
response not come back for follow-up?
Were patients who refused the new treatment different than the patients who accepted the
treatment and what was the dropout rate or the dropout percentage of the study?
This potentially introduces a further bias into the result.
You may, when reading a study, find that, for example, 1,000 people were enrolled into
the study, but then there's data only for 600 people out of that 1,000.
Well, what happened to the other 400?
Those are called dropouts.
It's possible that the subjects simply did not follow up with the study, they were lost
to follow-up, or maybe they decided not to complete the study because they were having
side effects from the treatment or perhaps they were getting worse and figured that they
may be they're only getting the placebo and wanted to pursue a different treatment.
There are many reasons that introduce, again, significant bias into the results.
Generally speaking, a dropout rate of greater than 10 to 20% seriously reduces the reliability
of a study and calls the results into question.
In other words, is all the data being counted?
It's easy to create false results if only a subset of the data is counted for whatever
reason.
Skipping, dropping, or selecting data can be system, can systematically bias results,
making the outcomes misleading, all but worthless.
You can also ask about a study, was it prospective or retrospective?
A prospective study chooses subjects or objects to be observed and then observes their behavior
