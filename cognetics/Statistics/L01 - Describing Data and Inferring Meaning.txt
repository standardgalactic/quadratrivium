Welcome to Meaning From Data, Statistics Made Clear.
Statistics is the study of data.
Statistics is a mode of reasoning that is used absolutely everywhere.
And in fact, when I was preparing these lectures, one of the things that I did was to just take
a newspaper and look through it and see examples of where statistics was used.
And I thought, well, maybe I'd have to wait, you know, and look every day for a week or
something to find good things.
Now, it turns out, of course, every single day, statistics is found in all sorts of places.
You look at articles about politics, elections, world conflict, certainly economics, business,
all of these, centrally involved data and interpretation of data.
And education, think of education, that the emphasis on assessment and the no child left
behind legislation, assessment is at the core of that enterprise.
Statistics intentionally playing an even more important role as time goes on.
In the social sciences, just think of the kinds of things you read about, recidivism
rates of prisoners.
You can read articles about happiness and its relationship to wealth and the fact that people
seem to be just as happy regardless of how wealthy they are.
The number of hours we watch TV, all these kinds of things are in the paper every day.
And then sports.
Well, of course, we all know that sports, how much fun would it be to just watch sports?
Oh, no, you've got to have the statistics of sports.
That's what really makes it fun.
You look at world records, you look at measures of the performances of people, you talk about
the streaks that some player is on.
And even in the arts, what do you discuss about arts?
Well, you can discuss things like how much works of art are sold for.
How much are the actors paid or how many people went to the latest blockbuster movie?
And then medicines.
Medicines.
Well, you take medicines and how is it that you decide whether or not to take a medicine
that could have a big effect on your life?
What do you do?
You rely on some sort of statistical study that has evaluated whether or not the medicine
actually works.
Statistics is central to everything.
Every area of science.
What do they do?
They do experiments in science to try to determine what actually has what effect in the world.
All of these things, and these come up, of course, every day in the newspaper.
Actually, there was one thing I forgot to do.
I know I should have done this earlier here.
I wanted to find one thing in the newspaper.
I'm sorry.
Geez, I should have done this.
There's the weather.
The arts.
Look at that.
Yeah.
The Louvre gets a $20 million thing now.
Let's see.
I knew there was something I was looking for.
Well, I guess I'm not going to find it.
I was looking for some significant area in which statistics does not play a significant
role.
It's really harder to find something where statistics isn't important than to find the
places where it is.
In fact, I guess it's not hard to make the case that statistics is everywhere and it's
important.
At the university, think of where statistics is taught at the University of Texas at Austin,
where I am.
Statistics is taught at every corner of the university.
It's taught in all the different colleges, such as architecture, teaches a statistics
course, in business, that teach statistics, in public affairs, in psychology, in government.
There are statistics courses in all of these places, and for good reason.
The reason is that it's statistics that is the mode of reasoning that is so prevalent
that when we make an argument in these subjects and try to persuade somebody of some opinion,
we'd better back it up with data and we'd better back it up with a statistical analysis.
But the trouble with data is that data are really meaningless or, in fact, misleading
if we just have data.
Let me give you an example here.
Here is a list of numbers.
It's a long list of numbers.
Now, I want you to look at this list, but not very long.
I'm not going to let you look at that list very long.
In fact, I'm going to take it away right now.
The reason is that most times, if people look at a long list of numbers, something happens,
and that is that their eyelids start to droop and they drop into a deep sleep.
Numbers in that form, just a long list of numbers.
I was going to make the point that they are meaningless.
They're useless in that form, just a long list of numbers.
But actually, I think they are of great value.
I came to think that they are of great value because a lot of people have trouble sleeping.
This is a great use of statistics.
I don't think people have thought of it.
You just give them long lists of numbers to look at, and pretty soon they're asleep.
Certainly happens in my classes, so it should work everywhere.
Anyway, the point is that actually that's the correct reaction to a long list of data,
or a long list of numbers.
The reason that it's correct is because the data, when they're just in a tabular form
like that, do not have meaning.
In order to get meaning from the data, it requires an additional step.
We think often of ourselves as a data-driven society.
But in fact, we're not a data-driven society.
We're an interpretation of data society.
Remember the character Data on Star Trek?
Remember Data on Star Trek?
He was a character on this TV show who was a computer.
He was a robot.
His name was Data, which represented the fact that he didn't quite get it.
He would be able to be completely logical and just have the numbers, but he just didn't
seem to catch on to the human meaning.
That really captures the correct idea that data don't have meaning by themselves.
Let me give you an example of some data.
This is a chart that takes a document and lists the number of times that various words
are used in the document, like the word the is used 1101 times and is used 878 times.
22 is used 726 times and so on.
Let's see.
Lord is used 218 times.
This list of numbers of words in a document is, of course, not telling the story.
In fact, these words do tell a story.
These are the words that are in Hamlet, and they tell the number of times each word is
used in Hamlet.
Actually, I was thinking of doing this, and I thought, well, maybe this is a little hokey
to say that data do not tell a story unless they're interpreted, but I thought it was
sort of nice that the story that these words tell are Hamlet, but they have to be put in
the correct form.
It's interesting.
You may say that it was a little, as I say, a little hokey to use Hamlet this way and
say that it doesn't tell the story of the data in this form.
But as a matter of fact, we'll find that looking at documents in that form, where we just look
at the number of words used, how often they were used, actually was used in an important
issue, namely an issue associated with Federalist papers.
Remember that the Federalist papers were written, they were essays written and published
anonymously for the purpose of promoting the Constitution of the United States before
it was ratified.
And these were written anonymously.
Most of them came to be known who had written the papers.
Alexander Hamilton wrote most of them, and James Madison, those two wrote most of them.
But there was a group of these papers, a dozen or so, where the authorship was unknown.
And one good way of arguing for the authorship of these documents would be to look at the
word usage and compare how frequently various words are used compared to documents that
were known to be written by Hamilton and Madison, and try to make an assessment of whether or
not the unknown document was authored by one or the other.
And in fact, we will discuss that issue in lecture 24, the very last lecture.
So the point is that data do not come with meaning.
And one method by which we frequently take a collection of data and try to give those
data meaning is that we try to summarize the data, often by taking average.
And so let me give you an example of this.
So here is a statistical fact, and it's a little embarrassing to say, but in the name
of statistics we have to say these things.
The average American has one testicle and one ovary.
That's a correct statistic.
You see, that's correct.
The point is that if we describe the data completely correctly, that is a completely
correct thing, you see, but somehow we know something about males and females so that
the knowledge of the statement, though true, that average statement is true, we know that
somehow it's not capturing the actual situation that is the meaningful part of the world
that that data is associated with.
We know that the average, although correct, we need to know things about the distribution
of males and females are about as many men and women in the world.
So that's an example of a misleading summary of data.
And unfortunately, the ability of statistics to mislead people is a very well-known phenomenon.
And in fact, I personally consider it rather sad that the most famous quotation about statistics
is a quotation that came from Mark Twain in his writings.
He ascribed it, by the way, to Benjamin Disraeli, and the quotation you've probably heard said
the following.
He said, there are three kinds of lies, lies, damned lies, and statistics.
And unfortunately, it's true that this quotation captures the common experience that statistical
information can quite easily be misleading.
They summarize things or display things that obscure the truth or distort the reality in
ways that can really support anything that you want to support.
But fortunately, there's an apt rejoinder to Twain's quote that I really like, namely,
it's easy to lie with statistics, but it's easier to lie without them.
And this quote really points out that statistics not only allow us to understand our world in
a more detailed and nuanced way, but it also forces a person who's using statistics at
least to try to garner actual data from the course, from the world in inducing arguments.
So in this course, our challenge is to extract from the raw information of the world and
the raw lists of data and facts to extract the appropriate conclusions, meaning from
data, that's the challenge, and to gather data that actually has meaning.
The two most fundamental words used in this subject are statistics and data.
And I wanted to just take a moment to point out that both of these words share a common
grammatical issue.
And the grammatical issue is that you have to ask, are these words singular words or
plural words?
Do you say statistics is or statistics are?
Data is or data are?
So let me just talk about this for a minute.
The word data, which by the way can be pronounced either data or data, some do one, some do
the other, is the plural of the word datum, which is just a single piece of information.
So data really is a plural word and a lot of academics are very strict about always
using data as a plural word.
And I will use it most of the time that way.
But it's also true that really data, the word is referring to a collection of information
and it's really the collection that contains the meaning, not the individual datum, one
individual datum or another individual datum, it's the whole collection.
And so to me it's not that bad to use data as a singular word and it doesn't bother me
when I hear the data is.
So for example, if you say data about the homeless paints a bleak picture of their existence,
to me that seems fine, you're talking about the collective information about data.
The word statistics itself also has this plural singular issue.
If it's referring to the study, statistics is the study of data, we'll use of course
the singular because it's talking about the subject itself.
On the other hand, statistics actually are bits of information.
A statistic is a number computed from a collection that you've taken from a population.
For example, if you say that 49% of the people of this group of 100 I asked were for candidate
A in an election poll, that is a statistic.
And if you asked two different such numbers then those would be two different statistics.
And we'll define the technical meaning of statistic which is basically what I just said,
but we'll define it in lecture nine and make clear what it is.
So a statistic is an individual thing and so statistics can appropriately be used as
a plural word when it's referring to more than one of such things.
Well any collection of numbers, any collection of data is susceptible to statistical analysis.
And the problem is that this is such a broad scope of things that statistics is being asked
to do that the challenge for statistics is similar to the challenge of describing all
shapes, you know, describing every cloud.
What does it look like?
And we cannot expect to get perfect descriptions that can be summarized in one or two words.
That's not going to happen because it's not accurate.
So instead we need to develop a collection of concepts and a vocabulary for describing
these complicated collections of information with the sort of balancing act of not losing
too much detail and yet somehow being able to summarize complex collections of information
in ways that are sufficiently simple and clear that they actually convey meaning to us.
That's the challenge.
Well in this course we're going to think of statistics as having two basic parts.
The first part is how can we describe and extract meaning from a collection of data
if we know all of the data in the population that we're concerned about.
For example, suppose we know the income of every single person in a particular city and
we want to understand that collection of data and see if we can get meaning from it.
The second part of our strategy for looking at statistics is to think about the situation
where we do not know all the data about every single individual in the population.
We know the data about some members of the population and then our goal is to make a
good guess about what we expect to be the truth of the entire population.
So we've got two sides here.
One, how do we organize, describe, and summarize a collection of data when we know all the
data and two, how do we infer information about the whole population when we have data
only about some members of the population?
Let me tell you now the structure of the course itself, the 24 lectures of this course.
The course is divided into two parts, the first 12 lectures and the last 12 lectures.
So the first part, lectures one through 12, is organized to present a logical and conceptual
development of the study of statistics itself.
And the second part, lectures 13 to 24, I guess I shouldn't say the second part is an
illogical presentation.
That's not true.
The second part instead is focused on application areas, where we take an individual application
area and in that present examples of the use of statistics in those different areas.
So of course, even in the first part of the course, by the way, we'll use many examples
of applications to make the individual concepts understandable and hopefully interesting.
But in the second part of the course, we'll take, so in the first part of the course,
the first part of the course, we'll take each statistical idea and demonstrate it and
develop it using several different application areas.
Whereas in the second part of the course, conversely, we take one application area and
present several different statistical themes that all come up in that one area.
So I'm going to go through the lectures and just give you sort of a roadmap for what is
in store for the course.
So lectures two and three together form an introduction to the whole analysis of statistics.
It's a broad overview.
In lecture two, we'll describe the basic themes for how we organize, describe, and summarize
a collection of data when we know all the data.
And then in lecture three, we give the same analogous thing, an outline of the conceptual
strategy involved in making statistical inferences, that is, inferring from data about some members
of a population a likely description of the reality for the whole population.
Then we return in lectures four through seven to present basic conceptual tools for organizing
and describing data.
So we introduce various categories of collections of data that help us to take a complex collection
of data and describe it in some canonical kind of ways.
And we'll introduce the basic concept of the distribution of data, which refers to how
we look at a whole collection of data and how those data are arrayed.
And we introduce various shapes that model common data sets.
And a famous example, by the way, that you probably know is the famous bell shaped curve.
And we'll talk about the fact that it has a specific mathematical properties and it
has significance, both the mathematics has significance and the shape of it comes up
in natural ways and we'll say why it comes up in natural ways and why it's so useful
to understand that particular shape.
But there are several such classes of curves that give us sort of a geometric vocabulary
for organizing and categorizing collections of data.
Another feature about data when we know all the data are relationships between different
features of the same people or things.
For example, you have SAT scores of seniors in high school.
They take this college board examination in high school and then they go to college and
do either well or poorly.
And one thing that we can ask is how closely are those two measures related to each other?
And so we have two pieces of data for each individual student and we want to know how
do they correspond?
How closely do they correspond to each other?
How predictive is the SAT score for future success in college?
So this is an idea that is very closely related to understanding cause and effect, one of
the basic ways by which we try to understand our world.
So those were lectures four through seven.
Then in lectures eight through 12, we begin talking about statistical inference.
In lecture eight, we present the concept of probability for inference, the probability
that's used in statistical inference.
And it turns out that probability is the glue that connects the methods of describing sets
of data that we've already talked about with the idea of statistical inference.
So eight through 12 then are developing the concepts and the logic of statistical inference.
Probability itself is the study of measuring random behavior.
We can give a number to how often something will occur, even though we don't know for
sure that it'll happen in any individual instance.
And that concept of probability, and you know, very simple, once you roll a die, what's
the, how often will it come up before?
Well, it'll come up about a six at the time.
That basic concept of probability then later goes on to be one of the, of the central ideas
in, in statistics, in, and statistical inference.
Because the, the concept of statistical inference, of probability allows us to develop expectations,
quantified expectations from what we would expect to happen from randomness.
And then statistical inference really is going to compare what the data we actually get in
a situation, compare it to what we expect from randomness.
And that really is the basic underlying core idea of statistical inference.
And of course, that's what we'll explain much more detail.
It's a very, it's sort of a tricky idea in, in these later lectures.
In lecture nine, we introduce the concept of a sample.
A sample means just choosing some members of a population.
And it turns out that, that when we take a, a sample, our goal is to look at the sample
and hope that the data in our sample somehow mirrors, reflects the data from the entire
population.
And, and you all are familiar with this kind of thing.
And a typical case is a poll before an election, where the pollster will ask perhaps 1200 people
how they're going to vote.
And so those 1200 people constitute a sample of the whole voting population, which may
be 100 million people.
And the, the goal is to get a sample that is representative of the whole population.
And we'll talk about that.
There are lots of pitfalls associated with, with samples that need to be avoided in order
to get a, a collection of a, a sample that is going to tell us something accurate about
the whole population.
So in lecture 10 then, we introduce a really fundamental strategy of statistical inference
that's called hypothesis testing.
And the, the strategy of hypothesis testing is that we, we do some, some experiment or
gather some data in order to determine whether or not a view of the world is actually accurate.
And the, the logic of hypothesis, hypothesis testing is a little bit tricky.
But it's worth understanding well because it really is at the heart of almost all statistical
inferences that we read about.
For example, if a, if a drug is tested, what they do is they'll take this drug and see
whether or not it is more efficacious than a placebo.
And comparing the data is a, an example of hypothesis testing.
And in election, in lecture 11, we talk about the concept of a confidence interval.
When we see in a newspaper, candidate A will receive 40%, 46% of the vote with a margin
of error of plus or minus 3%.
Well, we'll see what this phrase really means.
It's actually incomplete as written because if we want to understand confidence intervals,
we need to understand what's missing from that statement, namely how confident are we
that the popular, that the actual voting population is in that range.
Lecture 12 talks about the design of experiments.
If you're going to gather data from which deductions can be drawn appropriately, it's
very important that we think ahead about getting data in such a way that we can make the kinds
of logical statistical inferences that we want to.
Poorly designed experiments can produce a great amount of data, but really data from
which we can learn almost nothing.
Things like keeping most features of whatever the situation is fixed so that we can focus
on just one varying quantity.
That's one of the concepts that we'll use in the design of experiments to make them efficacious.
Okay, now we turn to part two of the course.
And remember, part two of the course is that we take application areas and look for interesting
examples within those application areas.
So we start off in lecture 13 with applications to the law.
And the law was the place that I wanted to start because in these settings you will be
the jury and we'll look at some cases, you're the jury and you make the decision about what
is right and what's wrong.
The reason I wanted to start there is because in a way that is the heart of statistics.
The idea that statistics is a mode of presenting evidence and it's up to us to evaluate that
evidence and see how valuable it is.
Lectures 14 and 15 concern voting.
And voting in a way, if you think about it, is a statistical issue.
You simply, in a vote, are finding out what the opinions are of all the people and then
you want to summarize that by electing somebody.
See, that's in a way a summary of a lot of data.
And it turns out that this is a very interesting feature.
It has paradoxes in it that you'll find fascinating.
It's not as simple as you might think.
Number 16, lecture 16 is about sports.
And sports, of course, analyzing statistical data in sports is a sport of its own.
And we'll consider a couple of questions.
Who is the best hitter in baseball history?
What a great question.
And it brings up all sorts of statistical issues.
And what are streaks and are they real?
In lecture 17, we talk about risk, both in war and in insurance.
In lecture 18, we talk about the real estate as an example where we have many different
varying qualities of, say, a house that all influence its price.
So it's actually going to introduce ideas of multiple regression, which sounds really complicated.
And then we have further lectures.
In 19, we talk about misleading and lying with statistics.
In lecture 20, we talk about the applications of statistics to social sciences, in particular,
the Myers-Briggs personality inventory.
In lecture 21, we talk about the health issues, such as how medicines are evaluated for whether
or not they are efficacious.
And so we talk about pain and weight in lecture 21.
In lecture 22, we talk about economics, including a way for detecting whether there's fraud
in a set of data by an interesting fact that more ones appear as the first digit in the
collections of data than you'd expect.
In lecture 23, we talk about science.
And in lecture 24, we'll sum up the course with the basic summary idea that statistics
is extremely prominent.
That's obvious.
But it's not only prominent now, but its importance and its influence can only be expected to
increase in the coming years.
And the reason for its increase is the ability of computers to deal with much larger sets
of data.
I look forward to introducing you to the concepts of statistics during the next 23 lectures.
