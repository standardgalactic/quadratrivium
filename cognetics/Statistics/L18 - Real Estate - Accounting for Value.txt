The previous lecture concerned war, so it seems only fitting that this lecture should
concern taxes.
In this lecture, we're going to confront a real-life problem and see what statistical
techniques are involved in solving it, and the problem that we're going to think about
is producing assessments of the market values of houses in a city.
So for example, if you're the tax assessor, you need to give a value to every house in
the city.
Well, some houses were sold during the preceding year, and so for those houses, we know the
data of interest about those houses.
We know their square footage, we know the number of bedrooms, and we also know the
sales price.
But for the other houses, we know the data about the houses, such as their square footage
and lot size, but we do not know the sales price.
So our challenge is to give an effective prediction of the sales price of the houses
that were not actually sold.
In most of our lectures so far, we've dealt with one or sometimes two varying quantities.
But in real life, usually there are many more variables involved.
And if we think about what makes a house sell for a certain price, there are many features
involved including the square footage of the house, the location, the lot size, the quality,
the building materials, many different features.
So these real estate features are examples of variables associated with each house in
the population.
Now in this case, the population is the population of all the houses in the city or the tax district.
The same basic principles that are used when dealing with one variable are used to deal
with more than one variable.
But everything becomes a little bit more complicated, and so that's what we're going to try to
deal with today.
As usual, our goals are to organize, describe, and summarize data.
In this lecture, we're going to describe methods for modeling data that have multiple variables,
and we're going to do this, we're going to accomplish this by doing a specific example.
So two basic questions of interest arise when there are more variables than one present,
and that is what quantities affect or explain or are related to what other quantities.
So in other words, you know things like the square footage, the lot size, the number of
bedrooms, the number of bathrooms, the distance from the city center.
You know that all of these things influence the market value of a house, but some of these
variables might be related to each other.
For example, we would expect that the square footage of the house and the number of bedrooms
or the number of bathrooms, all of those will probably increase together on average.
So the question is how can we summarize all these relationships?
In particular, sometimes can we eliminate some of the variables as being not important
in developing our model or predictive model for how much to assess a given house at?
But can we throw out some of those variables and still get a model that explains most of
the price of the house?
It captures most of what's going on.
Well, okay, so let's begin by taking our list of houses.
We're imagining we have houses in the city, and we're going to take the variable that
we expect to have the most influence on the value of a house, and we'll start there.
Well, so what variable would it seems likely to have the most influence?
It seems like the square footage.
Seems like a likely candidate for the most influential single variable in predicting
the price of a house.
So to ground our discussion, let's look at a collection of data that consists of having
the square footages and the selling prices and other information about a collection of
113 houses that were sold the last year in our example city.
What we see here on this list is an excerpt from the total list, but this is a list of
houses that were the houses that were sold.
You see, we're going to create a model using the houses that were sold and then develop
a model that we can then apply to the ones that were not sold.
So this is just an excerpt of a few of the 113 houses that were sold, and you can see
for each one we have a sales price, we have the number of bedrooms, bathrooms, home square
footage, lot, acreage, the age of the house, and the distance from the city center.
So we have all of that information for every single house.
We decided to focus on the relationship between square footage as an explanatory variable
to the selling price, which is then called the response variable.
So we have the explanatory variable, square footage, the response variable, the selling
price.
Well, naturally, we expect larger houses to sell for more, but we don't expect there
to be a perfect correspondence between the selling price and the square footage.
So our statistical challenge is to describe how these two varying quantities are related
and how closely they're related to one another.
Well, the first thing that we want to do is to look at these variables independently.
So specifically, let's just draw and look at a histogram of each one.
This is a histogram of the square footages of the houses in our 113 houses.
And you can see that it has this shape where it's skewed to the right.
So this is the histogram of the square footages of the collection of houses.
And this is a histogram of the house prices.
So we can look independently at the histograms of house prices and the histogram of the square
footages and notice that the two histograms are somewhat similar to each other.
They're both skewed to the right, as expected from the idea that these two quantities are
related to each other, square footage and selling price.
We can visualize the relationship between these two variables by making a scatter plot
of the two variables.
And as you see, the scatter plot is for every house, we put a dot, namely, we see what its
square footage is, and then we put it at that location horizontally, and then we rise up
to what its selling price was, and then that's where we locate the dot for that house.
In this case, you can see that the scatter plot of these 113 points is a cloud of points
that looks roughly linear and goes up to the right as expected, meaning higher square footages
correspond to higher selling prices.
And we can approximate that scatter plot by a straight line that is the straight line
that we actually met before in lecture number seven, which is called the least squares regression
line.
The least squares regression line is a summary of the data in the same sense that the mean
is a summary of just a collection of numbers.
It's sort of a central summary around which the data are spread either more or less.
Well, just looking at this least squares regression line, we can notice that it fits the data fairly
well.
And by the way, let me remind you of what the least squares regression line means.
It means that for every dot, for every house in our collection, we see what the vertical
distance is between the dot and our regression line.
We square that difference and add up the squares of those differences.
So that sums of squares is a number, and we choose the straight line which minimizes that
total sum of squared difference.
That's the least squares regression line.
Well, so these two quantities, square footage and price, are related, but larger houses
seem to have values that are above the line, meaning that maybe we need to think a little
more carefully about those houses separately, but nevertheless, this is still a pretty good
fit.
Well, after drawing this line, we can compute a number that captures the extent to which
the data are spread out from the line.
And specifically, after having chosen our least squares regression line, we can actually
write a formula for it.
And the formula for it is, in this case, exactly this, that the price is equal to $161 times
the square footage minus $63,600.
Now there's actually a formula for, there's a computer programs that will allow you to
just automatically get this formula for the regression line from the data.
And if you look at an Excel program or any statistics program, it just will spit out
this least squares regression line.
So in our example then, we notice that the slope of this line is $161.
In other words, the coefficient of the square footage is $161.
What that means is that we expect that when we increase the square footage by one, then
this price increases by $161.
So you see that it makes sense that in this neighborhood, roughly what this is saying
is that as a first approximation, when you add a square foot to your house, you would
expect the price to increase by $161.
Now when we look at this total picture of the houses in the scatter plot, we can think
of each house as, in the following way.
We can think of each one as being that the data, the actual value of the selling price
of the house, is equal to what its model tells it it should be, plus this vertical distance
which is called the residual.
So the vertical distance is the amount by which the actual square footage differs from
the model that we're creating.
So let's give a particular example.
If we look at this house whose value is $649,000, if we compute its predicted value given its
square footage, you see its square footage is $3,793, it's a big house, that we can put
in $3,793 into our predictive formula and do the computation and get that the predicted
value is $547,000.
Now in this case, we know that the actual selling price here was $649,000.
So the residual is the difference between the actual selling price and the predicted
selling price, so it's $102,000.
And we can see this visually on our graph that the length of this vertical line corresponds
to a difference of $102,000.
Our goal of course is to try to get a predictive model that predicts the values as closely
as possible.
So this one was off in this particular case by $102,000.
If we look at these histograms of the predicted house prices versus the actual house prices,
we can see visually the extent to which they seem to be similar.
We're trying to get a predictive model that looks exactly like the actual house prices
and you can see that it looks similar but not quite the same.
If we graph the scatter plot of the residuals, that is to say we say for each residual, remember
that's how far off the model was from being correct, we get a scatter plot and we hope
that this scatter plot is a rather random looking collection because we're hoping that
there's no bias to having the residuals in one area being always higher or one area
always being lower and it does look rather random.
Our goal is to make the residuals as small as possible.
So our concept again is that data equals model plus residuals.
When we've made a summary of data, our next step is to ask the question, how well does
our summary actually correspond to the data, whether it's taking just a mean or in this
case drawing a regression line.
So what we are trying to do is to see the extent to which our model explains the actual
selling price of the house.
So here's what we're going to mean by this very specifically.
The original houses had a certain variance to them, meaning remember what the variance
is.
The variance is the square of the standard deviation.
The variance is just the average squared distance from the mean to each individual data point.
So the variance of the sales prices of these 13 houses is just the mean squared distance
from the mean to the each value of the house.
So it's a measure of how spread out the sales prices of the original sales prices of houses
were from the mean of the sales prices of the houses.
The model of the predicted prices gave different values for every one of the houses.
You follow me for every single house, it had a square footage and that put the predicted
value on the line, a slightly different place from its actual value.
So we could look at the variance associated with the predicted values of each of those
houses.
So in this case, the variance of the predicted values is this number and the variance of
the actual prices is this number.
The ratio of these two, this to this, is 0.697, which means, and the way this is described,
is to say that 69.7% of the variation of the house prices is explained by the square footage.
You may have heard this term, how much of some varying quantity is explained by some
other quantity?
How much of intelligence is explained by upbringing?
How much of it is explained by genetics?
The actual meaning of that term is that we take a model, and in this case a least squares
regression line, and we compare the values of the model to the actual values of the
selling price, and we compare the variance of the original, how spread out the original
selling prices were, we compare it to the variance of the predicted ones, and making
that comparison shows us what fraction of the model is explained.
Or another way to look at it, an equivalent way to look at it, is that we could look at
the variance of the residuals.
Remember the residuals are the differences between the model predicted prices and the
actual prices, we're trying to make them small.
What this says is that the variance of the residuals, the leftover parts, is only 30.3%
of the variance that you started with.
So this model, just using square footage, has explained 69.7% of the variation of the
price.
Now by the way, this number, 0.697, is actually the square of the correlation, that was the
number, the correlation or correlation coefficient that we discussed back in lecture 7.
It remember had a formula, but the point is that value of correlation, which was measuring
the extent to which our scatter plot was lying close to a straight line, the square
of that is actually telling us the proportion of the variation of the price that's explained
by the square footage.
We now turn our attention to what we would do when we're using more variables than just
that one variable in trying to explain the selling price.
In other words, conceptually we know that for all the houses in the city, we know lots
of things about them, not just the square footage.
We know the age of the house in years, we know the bedrooms, we know the number of bathrooms,
we know the distance from the city center, we know the number of garage parking places,
the size of the lot on which they sit, the number of floors, we know lots of these, acreage
of the lot.
We know all of these things about each house and so our goal is to get the predicted value,
the one response variable is the selling price of the house and we want to use this other
information to help us get a better model, a better explanation for what the actual selling
price of the house is.
So for each house we actually have these explanatory variables, one response variable, the selling
price and how can we make use of, how can we deal with this more complicated situation,
how can we make use of this other information?
Well the answer is that we do something that's called a multiple linear regression.
A linear regression just gave us a single straight line summary of the predictive model
based on just one variable like square footage.
Multiple linear regression is a technique that we can use to approximate or summarize
the situation where we have several explanatory variables for just one dependent variable
and the idea though is to use the same concepts that we've developed for the case of just
a single variable such as square footage and price and try to follow the pattern of analysis
but apply it to this more complicated situation with many variables.
So first of all, to begin with we feel that the explanatory variables like square footage,
area of lot, distance center, that these things actually do have an effect on the house price.
That's the first thing.
There's a sense that there is some significance there but if we were starting from scratch
in some other setting, just I'm telling you things about the general strategy of doing
multiple regression, if we didn't know whether these variables were having an effect on the
actual outcome then what we would do is something called an analysis of variance, ANAVA and
this basically tests the null hypothesis that none of the variables is a predictor
of the response variable.
So that's what the ANAVA test says that at least one of the independent variables is
associated with the answer and we would see that if we have a p-value that's smaller than
.05 which is typical for taking this null hypothesis threshold of significance, we would
say that the result of this ANAVA test would say that it would be a rare occurrence by
accident to have the data we do if none of these variables were actually explanatory,
had something to do with explaining it.
So it doesn't necessarily mean by the way just getting a small p-value wouldn't mean
that the model necessarily explains a lot of the variance that we're talking about but
at least it says that it would explain some.
But in our case this step would just confirm something we already know that namely that
we have some variable that actually does make a significant contribution to predicting the
house price because we already have seen that the square footage is correlated to the house
price in a rather significant way.
But the idea of multiple regression is that we're going to find coefficients for each
of the dependent variables.
Just like we found this coefficient $161 for the square footage, we're going to find coefficients
for each of the dependent variables so that when we combine them they will predict the
house price and hopefully better than would happen with just one variable alone.
So that's the goal.
So when we run this multiple regression program what it gives us is a least squares, it gives
us least squares coefficients for the variables.
So if we take each house we could combine the values of the explanatory variables using
the coefficients that are produced by the multiple regression and we get a prediction
of the house price.
So as before the residual is just the difference between the actual selling price and the price
that's predicted.
So let's go and actually see what happens if we run a multiple regression on our collection
of houses.
Here's what it produces.
It produces an equation here.
The equation is the model whose answer is the predicted price, by the way this line and
this are exactly the same thing.
This is written out in words and this is just in a more abbreviated form.
So these are exactly the same.
What it says is that the predicted price for our model is a certain coefficient times
the square footage.
Now notice that when we use the multiple regression model and we have more variables involved
that the coefficient of the first variable, square footage, has changed.
Previously it was $161 and now it's $190 per square foot.
Then we have a coefficient $49,200 that is the lot size in acres.
So this tells us that $49,200, roughly speaking the way to think about this is that an additional
acre will add $49,200 to the predicted value of the house.
This coefficient is negative, negative $12,300 times D. What's D?
D is the distance from the city center.
So this makes sense.
It makes sense because what this says is that, and it's in miles by the way, so this says
that for every mile further away from the city center you go, you subtract $12,300 from
the house.
So we're interpreting the coefficients of these explanatory variables in terms of a
unit change in the explanatory variable has what effect on our predicted value in the
model.
Now here is an interesting one, negative $24,400 times B, which is the number of bedrooms.
Well this one, when we see this we have to say, whoa, what is going on here?
Why would having an extra bedroom decrease the price of the house by $24,400 per bedroom?
When we see a statistical anomaly like this, we see something that sort of hits us and
says, well this doesn't seem right, it gives us pause to try to think about it.
Does it make sense or doesn't it make sense?
Well, the answer is it does make sense.
What this is saying is that if you have a house of the same square footage and you have
more bedrooms, then that house is more apt to be a less luxurious house.
The quality of the house is less because that means that the rooms are smaller.
So adding, in the computation, it manifests itself by having a negative coefficient for
the number of bedrooms, but that's a rather interesting wrinkle to this thing.
We can actually look at our example, looking at the same house.
You see this is the general equation, and if we plug in the values for the exact same
house that we looked at before, we see that now the predicted value is $628,000.
Its actual price was $649,000, so in this case the residual has been reduced to $21,000.
So you see it's a better fit.
Once again, we can plot the residuals in this way to see that they're random, and of
course we're hoping that they get smaller.
In this case, in fact, they do get smaller because we can measure the variance of the
residuals and see how small they are, or alternatively, we can measure the variance of the predictor
house prices and compare it to the variance of the actual selling prices of the houses
in order to see what fraction of the variance in the original sales price of the house has
been explained by our model.
In this case, and it's traditionally called R squared, it's defined to be 1 minus the
variance of the residuals divided by the variance of the actual prices, and in this case it
has explained 77.7% of the variation in price.
That is to say, 77.7% of the variation in price is explained by the qualities that we used
in our model, square footage, lot size, distance from city center, and bedrooms, and finding
the least squares multiple regression model explains 77.7% of the selling price.
So this was an example to show how one can use multiple variables to try to explain one
variable, multiple explanatory variables to explain one variable.
Then what would happen is once we have a good model, we would apply it to all the houses
in the city to give the assessments that would be used for tax purposes.
Thank you.
