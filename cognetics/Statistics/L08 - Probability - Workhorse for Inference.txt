Welcome back.
With this lecture, we begin a series of lectures concerning statistical inference.
Probability is the bridge between the two ideas of one, describing data when we know
all the data, and two, inferring characteristics of a whole population from a sample.
Probability is a study of randomness, and it accomplishes what seems impossible, namely
putting a useful numerical value on the likelihood of events that are random, where you know
you don't know what they're going to come out.
The foundation of statistical inference is comparing the results that we find from actual
data that we collect with what we should expect from random processes.
But our intuition about what we are supposed to expect from a random process is often far
from accurate, and so for purposes of applications of statistics, it's vital that we know with
quantitative accuracy what probabilities we should expect from random occurrences.
Because the basis of making inferences about statistical data is usually comparing two
sets of data, one, what we would expect to get from some random situation versus the
data that we actually measure.
So we need a way to develop methods to accurately assess what is surprising and what isn't
in the world of chance.
So in this lecture, we're going to introduce the concept of random processes and probability,
especially the probability that's used for statistical inference.
We'll begin historically.
Somebody was introduced in the 17th century.
In 1654, the French gambler, Antoine Gambeau, the chivalier de Mer, posed a question about
gambling by writing a letter to Blaise Pascal, who in turn corresponded to Pierre Fermat,
Fermat famous for Fermat's Last Theorem and Pascal famous for Pascal's Triangle.
Well anyway, in responding to Gambeau's question, they introduced, that is Pascal and Fermat,
the basic concepts of probability.
And the basics of probability are really quite straightforward, until we think about it a
little more at least, they're straightforward because let's take a very simple example.
If you know every possible outcome of some sort of an experiment, and they're equally
likely, each outcome is equally likely, it's easy to calculate the probability of the outcome.
So for example, let's suppose we take a coin, here's a penny, if it's a fair coin and we
flip the penny and we look at it, we say it has a 50% chance, one half chance of coming
up heads.
So that's the measure of the idea that it's equally likely to come up heads or tails.
And so we give it a numerical value.
It's always going to be a value between zero and one, and in this case it's one half, it's
halfway between because it's equally likely to come up heads or tails.
Well so this is a basic example, there's another example with a die, since Gambeau actually
has a question involved dice, so it's reasonable to talk about dice.
So when you roll a die, there's an equally likely chance that it will come up any one
of the six sides of the die.
So you say that the probability, for example, of rolling a four is one sixth.
If you do roulette, you know you have a wheel on roulette and you have the little places
where the ball can land, then it's equally likely to land in each of those places, and
so you can assess the probability of landing in any one place, which is usually one out
of 38, where there are 36 numbers and then a zero and a double zero.
But where cases occur where they're not equally likely outcomes, unlike the dice or the pennies
or the roulette wheel, when they're not equally likely, then we have to think about a different
concept of what probability is meaning and what it's trying to capture.
So to illustrate this, let's think about a thumbtack.
So here's a thumbtack, so I don't know if you can see this or not, but I'll try to hold
it up.
So this is a thumbtack, and if we take the thumbtack and just throw it on the ground,
it might land as this one did, which is point down, the point touching the table.
That's the way this landed.
Or if you throw a thumbtack, it might land as this one did, point up, where the pointy
part is sticking straight up.
Well, you could ask the question, what is the probability when you just randomly throw
a thumbtack on the table, what's the probability that it lands point up?
Well, that's not something where there are equally likely occurrences.
It's not equally likely to end up point up as point down.
The only way to really assess such a thing would be to take the thumbtack and just throw
it a bunch of times.
You just throw it thousands and thousands and thousands of times, and you see what proportion
of the time the thumbtack landed point down or point up.
And then you would say that that fraction of the time is the probability of coming up
with the point up.
So that's the concept of probability in cases where it's not a clear cut example where there
are equally likely outcomes.
But randomness and probability, as I say, they become less clear the more we think about
them and more interesting, by the way.
I think it's fascinating.
So let's go back to our penny example and just think about it a little bit because there's
some subtleties.
When we flip a penny, to what extent is that really a random event?
You see, when we flip a penny and it lands, to what extent is that a random event?
Well, it certainly seems random in the sense that when we flip it, we don't know how it's
going to come out.
But really, the truth of the matter is that it actually isn't so random in real, if we
look at it in great detail.
And this was actually demonstrated.
There is a statistician, Percy Diaconis, a very prominent statistician, who had his
physics department produce a coin flipper.
And it would take a coin, I think it was a half dollar, and it would flip the coin.
Coin flies up in the air and lands in a little cup and 100 out of 100 times, that is every
single time, if it starts, heads up, it lands, heads up, in the little cup.
And so just demonstrating what may be obvious, but the physical demonstration of it is powerful,
namely demonstrating that actually randomness is not involved after the coin is in the air.
It's determined how it's going to land.
So when you flip a coin and you let it land on the table, is it really true when the coin
is up in the air that when you say the probability is 50% that it's heads?
It's sort of a subtle point.
Let me give you another way to look at it.
In some aspects of our understanding of the world, probability is actually an inherent
part of it.
In the basic model of quantum mechanics, the concept of probability is a basic concept
of reality, that it's not the case that an electron is right here, it's that it's a probability
distribution of where it is.
This is very weird stuff, and I'm certainly no expert on quantum mechanics, but the point
is that probability in that field is an absolutely fundamental idea, and it's not just a question
of luck.
But let me bring up something that different people have different points of view about
concerning probability, and that is the following.
Suppose that I flip this coin and I cover it up, and now I ask you the question, what's
the probability that this coin is heads?
Now some people will say, well, that's not a sensible question, because it either is
heads or it's not heads.
It's not susceptible to probability because it's not a repeatable experiment.
See, probability of a coin landing heads before you flipped it is you're saying, well, I'm
going to do something later that may come out heads or it may come out tails, but now
it's either heads or tails, it's just that we don't know.
So from the point of view of viewing probability as a measure of the proportion of the outcomes
if the experiment is repeated a certain number of times, the frequency with which it comes
out heads, this situation is not amenable to that kind of discussion.
On the other hand, you might view probability as a question of our belief.
In other words, if you were a betting person and I ask you, OK, how much are you going
to bet that this is heads, you would bet as though the answer was 50-50.
That would be the rational way to make the bet.
So these are different philosophical points about probability that really actually have
an influence on statistical practice, surprisingly enough, and we'll actually talk about them
in lecture 20 when we see some of the consequences of this somewhat different philosophical view
of what the meaning of probability actually is.
One interesting thing about probability is that human beings have a very poor intuition
about what is random.
And I'm going to illustrate this right now.
This is interesting to see.
I hope you find it interesting.
I'm going to show you two collections of dots on a page.
Here's one collection of dots and here's another collection of dots.
Now when you look at these two collections of dots, which one do you view as random?
Would you think this is random or would you think this is more random?
Well many people, if you just draw those dots, will view this configuration of the dots as
more random than this one.
Now maybe you can't tell too much of the difference, but the point is, often when people try to
assemble something that they view as random, what they really do is try to spread them
evenly out.
And in fact this came up, those of you who happen to watch the TV show Numbers, it actually
came up in one of the episodes of Numbers, maybe the very first episode of Numbers.
They asked people to assemble themselves in a random way and instead they sort of stayed
equally distant from each other.
And they starved the show, who was of course a mathematician, which is a great, you know,
this idea of murder and mathematics, what could be more better than this?
Anyway, the star of the show was able to point out that this was not random, that this was
a more uniform distribution.
So our intuition about what is actually random, it makes a real difference.
And also the concept of probability is a very, our guesses about probabilistic issues are
very poorly developed.
Let me give you a famous example, some of you may have heard this one and others not,
but if you haven't heard it, it's certainly worth hearing.
And that is the following.
Suppose that you go into a room and there are 50 people in the room.
And you ask the question, what is the probability that two of the people have the same birthday?
Celebrate the birthday on the same day.
So in other words, they weren't born the same day because they could have been born in different
years.
But what's the probability that two of them have the same birthday, meaning January 1st,
January 2nd, February 29th, March 3rd, and so on, that two of them have the same?
Well, a lot of people, when asked this question, feel that it's probably pretty rare because
you've got 366 days to choose from and you only have 50 people.
And so it would happen some of the time, but it's probably a pretty rare event.
It turns out that it is not a rare event at all.
In fact, what's rare is that in this random group of 50 people that you would not have
two people the same.
The chance is 97% probability that two or more people will have the same birthdays if
you have 50 people at random.
And by the way, you can look into this.
The point is that our intuition about probability is often very bad, particularly about rare
events or events that involve large numbers.
And I have a joke that's somewhat pertinent to this.
And I have to tell you that it's a joke because, well, maybe it's not that funny.
And so you wouldn't notice that it was a joke unless I tell you in advance.
So I'll tell you in advance.
So this happened at an astronomy lecture.
And the speaker said, the sun is going to explode in five billion years.
And a lady in the audience faints dead away, faints dead away.
So the people come around, you know, hover around and revive her, and then she comes
to life and they said, well, why did you faint when the speaker said that the sun was going
to explode in five billion years?
And she said, oh, I thought he said five million years.
So anyway, people, the distinctions between large numbers are difficult to intuit, and
yet that's what's involved when we deal with probabilities associated with rare events.
As I said before, it's absolutely crucial.
It's a crucial part of the foundation of statistical inference that we be able to actually assess
probabilities clearly enough, the probability of random occurrences, in order that we can
compare data that we actually obtain from what we expect from random events.
So this is where we need to make sure that our intuition doesn't lead us astray.
Of course, we'll discuss later the role that probability actually plays in statistical
inference in later lectures.
But let's talk a little more about the birthday problem just to make sure everybody follows
it and you enjoy it.
So we talked about having 50 people in a room and trying to see what the probability is
that at least two of them share the same birthday.
And one way to get a sense of this is just to do it, by the way.
If you're in a room with 50 people, just ask them.
Now, by the way, I do this every time I'm teaching a class, I often teach classes of
about 50, and I will go into the room and I'll say, usually the first day of class,
when they're naive, you see, I'll say, well, I will bet you even money that two of you
have the same birthday.
And I'll explain, there are only 50 of you, 366 days, and there's always somebody who
will bet me a dollar, and then I always win, and later in the semester they don't fall
for it quite as much when I make bets, but I do win a few dollars in the early part of
the semester.
Well, anyway, so you can take various groups of 50 people.
You can take, for example, the senators of the United States and look at a list of their
birthdays.
The presidents of the United States aren't 50, but there are several pairs that have
the same birthdays.
Or you could use a computer program.
You could take Excel and get 50 random numbers between 1 and 366, and you'll see if you do
it over and over again, 97% of the time, two of them will be the same.
So we can look at examples, but we can also actually prove that there are, that the chances
is 97%.
And the way that we approach a problem like this, and this is a very important, regardless
of statistics or anything else.
When you're faced with a difficult problem, what you should do is do something else.
You know, just don't do a difficult problem.
Do an easy problem, because then when you do an easy problem, you might teach yourself
something about the harder problem.
So let's consider the following case.
An easier problem would be, what is the probability that if you roll three dice, you take three
dice and you roll them, here they are, three dice, you roll three dice, what's the probability
that they're all different from each other?
Well, the first die is going to be something.
The second die has a five-sixth chance of being something else, because it's got to
be one of the five-sixths that aren't the same as that, the five out of six that are
not the same as the first die's value.
And then the third one has to be different from both of those two.
So these two are going to be different five-sixths of the time, and of those times, this one
will be different two-thirds of the time, four-sixths of the time.
So it's four-sixths of five-sixths.
We multiply the probabilities together to see that there's a five-ninths chance that the
three dice will all be different.
Well, to say that they're all different, the opposite of being different is that at least
two of them are the same.
So the probability that two are the same is just one minus five-ninths or four-ninths.
Once we see that pattern, we can accomplish it to do the birthday problem.
Here's the way the birthday problem.
The probability that 50 birthdays are all different, you line up the people, the first
person, the second person, the third person.
What's the probability that the second person has a birthday different from the first person?
Well, there are 365 days out of the 366 possible dates for that person to have, which will
make that person different.
So then we multiply it by the third person has only 364 target birthdays to choose from.
So we multiply those together, 363, and when we multiply all 49 other birthdays together,
it's 317 over 366 is the last one to be multiplied, and if you just take your calculator out and
multiply it, you get 0.03, a very small number.
So this is the probability that the 50 birthdays are different, all different.
There's only a 3% chance that they're all different, so the probability that two, at
least two are the same is one minus 0.03, which is the 97% that I previously told you
about.
Now let's return to dice.
If we have a black and a red die, so we have a black, you have two dice, one of them is
black and one of them is red.
If we throw the dice, there are 36 equally likely outcomes for these dice, and here it
is on this table.
These are the 36 equally likely ways that the red and the black dice could come up.
If we wanted to make a histogram of the sum, the sums that could come up, the sums are
not equally likely to come up.
You're much more likely, when throwing two dice, to have the sum be a 7 than you are
to have it be a 2, because the only way to get a 2 is a 1 and a 1, whereas there are
many different ways to get a 7.
You could get a 1 and a 6 or a 2 and a 5 or a 3 and a 4 and so on.
If you draw a histogram of the possible values that the sum of two dice could be, you would
see that the histogram is peaked in the middle and comes down.
There's just one way to get a 2.
There are two ways to get a 3.
You see this is 3, two ways to get a 3, and so on.
In the middle there's six ways to get a 7.
This is a histogram of the sum of two dice.
Suppose that we add another die, and we have three dice, and we shake them and we see what
are, we know that there are now 6 times 6 times 6 equally likely ways that these could
come out, and we could say how many of those ways produce a 3, that is, there's only one
way, 1, 1, and 1.
All three of them would have to be a 1.
But there are different ways that you could get a number in between, so the maximum number
you could get would be a 6, 6, and 6, 18, and getting numbers in the middle, like a
9 or a 10, there are many different ways that the three dice could come up in order to get
a 10.
This is a histogram of the number of ways you can get a 10 is up here, something 27 different
ways to get a 10, fewer ways to get a 3, and so on.
This is a histogram of the sum of three dice.
Now here's a histogram of the sum of four dice, and you notice the pattern as we take
the histograms of the sums of more increasing numbers of dice.
Look what happens.
Here's five dice.
When we get up to five dice, you can see that the pattern is more steeply peaked.
The trouble with looking at these graphs of the sums of the dice are that you notice
that this axis here is how many different possible combinations there are of taking five dice,
how many different ways could they come up.
The trouble is that these numbers change, of course.
There are many, many ways that five dice can come up and create these values, whereas when
you only had two dice here, then there were many fewer ways.
So the axis here was something that you couldn't really compare too well.
And when we're trying to deal with statistical issues, it's useful to have a method by which
we can compare the situations in a more meaningful way.
The way that we do this is instead of taking the sum of dice, let's just take the average.
I had this idea of explaining this in the following way.
I come up with these brilliant ideas, and I never know why people don't just accept them,
because they're really great ideas.
So this was an idea about pricing.
You see, pricing things.
When you go into a gas station, it's sort of boring because it tells you what the price
is of the gas, and then you just pay that and you leave.
But wouldn't it be more fun?
Wouldn't it really be a lot more fun?
If you went into the gas station and they gave you a die, you see, and you rolled the
die and whatever it came up, that's how much you would pay per gallon.
Now that would be sort of a nice thing.
The average price that they would collect from the customers would be three and a half dollars.
That's halfway between the one and the six, you see, three and a half.
But sometimes you could go into that gas station and get gas for a dollar.
But sometimes you'd have to pay six dollars per gallon, so that'd be a little...
And of course, by the way, to make this work, you'd have to have the person say how many
gallons they were going to buy before they rolled the dice, otherwise it wasn't going
to work.
I think this is a good way to price things, don't you think this is a good way?
No, no, but then you could have a gas station across the street, a competing gas station,
that does things a little different.
They give you two dice, and then you roll the two dice, and you take the average value
of the two.
See, that makes sense, because it wouldn't be fair to add up the dice, because then you'd
get increasingly higher amounts depending on how many.
But if you just took the average, the average you see would be the same.
In each case, it would still be three and a half dollars would be the average price
for a gallon of gas.
But once again, you might pay only a dollar.
If you threw two ones, you'd pay only a dollar.
Or if you threw two sixes, you'd pay six dollars.
But you might pay a, you know, there's a variety of how much you would pay.
Well, this is a histogram that tells us what the gas prices are likely to be.
In other words, the fact is that since it's peaked in the middle, you're more apt to
pay three and a half dollars for a gallon of gas than you are to pay only one dollar
for a gallon of gas, because the number of times, the fraction of times that you're going
to throw, get an average of three and a half is higher than it is for just getting something
whose average is one.
Now you can guess the pattern here that you, across the street, there's yet another gas
station.
It has three dice.
You throw three dice and you see what's the probability that those three dice come out
to be, whatever they come out, that's how much you pay per gallon.
And you can see from these graphs that they become more peaked as you have more dice that
you throw.
In other words, as you have more dice, here's four, it's becoming thinner, you see, it's
becoming thinner and taller, meaning that more of the ways to throw four dice have an
average that's closer to three and a half dollars.
Here are five dice.
So the gas station, you see, when you go into a gas station and you throw five dice, then
most of the time you're going to pay somewhere between two and a half dollars and four and
a half dollars.
You see, most of the thing is between those two values, most of this area here.
And you can see the difference by superimposing the two different histograms.
You can see that these two histograms are related to each other in that the taller one,
the more dice is more closely centered and taller.
And by the way, the way these graphs are formed, they're formed in such a way that the total
area underneath the curve is one, so as a way to normalize the curve.
So for example, here's what happens if you have a hundred dice, you see, it's a very
tall peak in the middle.
So you're almost certain to pay between three and four dollars for gas.
If you take a hundred dice and you roll them and you take the average, almost certain to
pay between three and four, but you still have that small chance that you could get
away with a dollar a gallon.
You see, so this gives hope, hope, whereas, whereas this, this one down here is the five,
the five dice curve.
You see, there's more variation.
Now we've already discussed the concept of these, of the variation of these, of the dice.
And what's really changing is the standard deviation.
The standard deviation of the gas price is declining.
And the way it declines is by the square root of the number of dice that you throw.
In other words, as you have more dice, it becomes like the square root of those terms.
This is the same as what we saw in the binomial distribution.
When we choose larger samples and we take the means of those samples, we saw that we get
a curve that is more peaked and has a standard deviation that's declining at a predictable
rate.
And it's knowing that how thin it's becoming at that predictable rate, depending on how
many times we throw it or how big a sample we take, how many dice we throw, that is the
foundation for statistical inference.
It's what allows us to know that when we start with any distribution, even for example this
Poisson distribution, just view it as just any old distribution, when we take samples
of size two and take their average, it gets more peaked.
Samples of size three, more peaked.
Samples of size ten, more peaked.
You can see that with higher collections of samples from a distribution taking their
mean, you get distributions that become more peaked and with the same mean as the original
distribution.
That's the content of the central limit theorem and that's what's going to allow us to specify
the extent to which we can be confident that an answer that we get is actually a statistical
inference is meaningful.
In summary, our dice examples explored what happens when we start with a large population
starting even with a uniform distribution and we consider the distribution of sample
means.
And the histogram becomes more peaked and with a smaller standard deviation.
That really is one of the workhorses for statistical inference.
So in this lecture then we're discussing the concept of probability and particularly
emphasizing probabilities associated with an application to statistical inference.
So in the next coming lectures we'll continue our discussion of the rationale for statistical
inference and how to know how close we are and how confident we are of being close when
we make a statistical inference.
I look forward to seeing you then.
