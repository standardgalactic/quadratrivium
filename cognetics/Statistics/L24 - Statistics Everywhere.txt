Welcome back to Meaning From Data, Statistics Made Clear.
Statistics provides conceptual tools with a very wide range of applicability, as we've seen.
And often statistical reasoning can contribute to decisive arguments
in matters that seem very difficult to resolve and even issues that don't appear to have any statistical component to them at all.
And we'll start this lecture with such an example.
In 1787 and 1788, Alexander Hamilton, James Madison, and John Jay wrote a series of essays about the Constitution advocating that the Constitution be accepted by the people of New York.
These were the Federalist Papers.
The goal of these papers was to convince people to vote for the Constitution, and they wrote a total of 85 essays.
They didn't sign the papers with their names. They were all published under the pseudonym Publius.
But of these 85 essays, the authorship was clearly known in all cases except for about a dozen.
And Hamilton was known to have written 51 of these 85 essays.
John Jay was known to have written five.
James Madison was known to have written 14, and Madison with Hamilton wrote three, leaving 12 disputed Federalist Papers.
And people had disputed the authorship of these essays for many, many years.
And some contended that Hamilton was the sole author, and others asserted that Madison was the author, and no one thought Jay was.
So it was between Hamilton and Madison.
And arguments were presented based on all sorts of things as you'd expect.
Namely, what positions were presented in the paper, in the disputed articles, and issues about their style of writing, and so on.
But none of these arguments were powerful enough to settle the dispute.
In 1964, statisticians Frederick Mosteller and David Wallace published a book called Inference and Disputed Authorship, The Federalist.
In which they approached the question from a statistical point of view.
They recognized that different individuals develop habits of word usage that are rather distinctive from person to person.
And in the case of Hamilton and Madison, there were many examples known of writing by each of the two.
So that they had methods for counting the frequency of the use of different words.
This was a very possible thing to do because they had these sources.
And in particular, Mosteller and Wallace viewed the use of unimportant words as particularly significant.
With the idea that the unimportant words were words that more or less just arise independently of the content being conveyed.
By the way, this method of analysis is called discriminant analysis, trying to discriminate between, in this case, the word usage of Hamilton versus the word usage of Madison.
Well, one example where they, and they used many, many words, but one specific word to ground our discussion was the word upon.
Hamilton was fonder of the word upon than was Madison.
And so in Hamilton's extent writing, he used upon at the rate of about 6 words per thousand.
That is six occurrences of the word upon per thousand words in his writing, on average.
Well, Madison used the word upon less than once per thousand overall.
So by looking at the actual Federalist papers in question, the ones that have disputed authorship, several such words were analyzed.
And the relative frequency of the use of those words by Hamilton versus Madison in the previous known writing versus the unknown writing,
that kind of analysis was used to try to distinguish the authors.
And the evidence and the reasoning from it are rather persuasive.
But I wanted to demonstrate how this was done by actually looking at the Federalist papers.
So these two volumes here comprise the Federalist papers and some others.
And I wanted to just read you some excerpts from some of this writing.
So this first excerpt will be from Federalist essay number 23, which is definitely by Alexander Hamilton.
And on this page, there are three occurrences of the word upon, and I'll just read some of these sentences.
It says, it rests upon axioms as simple as they are universal, the means ought to be proportioned to the end, and so on.
Later on the page, he says, as their requisitions are made constitutionally binding upon the states, who are in fact under the solemn obligations to furnish the supplies, and so on.
And finally, here at the end, a third instance, that if we are in earnest about giving the Union energy and duration,
we must abandon the vain project of legislating upon the states in their collective capacities.
So he used the word upon several times, and if you notice in the use of this word, in many instances he might have chosen to use the word just on.
For example here, as their requisitions are made constitutionally binding upon the states, you could have said on the states.
But Hamilton used the word upon.
Now let's look at an example that is known to have been written by James Madison.
So this is number 39, Federalist Paper number 39, and in it he has the following part of sentence.
We may define a republic to be or at least may bestow that name on a government which derives all its powers directly or indirectly from the great body of the people.
Now you notice that if you chose to use the word upon in that sentence, it would sound quite reasonable.
We may define a republic to be or at least may bestow that name upon a government which derives and so on.
So perhaps Hamilton who preferred the upon might have used upon in that instance.
Of course in any individual case it's completely inconclusive.
Now we'll turn to one of the disputed essays which is number 52.
So this is one of the disputed essays and here are a couple of sentences in which the word on is used where upon might be used instead.
So it says under the federal system cannot possibly be dangerous to the requisite dependence of the House of Representatives on their constituents.
You might have said, the author might have said requisite dependence of the House of Representatives upon their constituents.
It reads rather well or here's another example.
The advantage of biennial elections would secure to them every degree of liberty which might depend on a due connection between their representatives and themselves.
And that might have been written every degree of liberty which might depend upon a due connection between their representatives and themselves.
So we see that in these examples there are choices being made that the author makes in each instance of whether to use the word on or upon.
And Hamilton more frequently used the word upon than Madison did.
In this particular dispute it was discovered that in fact the authorship of these papers, that is to say the word usage of meaningless words,
corresponded much more strongly with Madison than with Hamilton.
So this was strong evidence from which it was rather persuasively concluded that in fact that the disputed Federalist papers, all of them were written by Madison.
So this is an example in which we have an arena in which it's not clear that statistical evidence would be pertinent whatsoever.
Well here's another example of the kind of analysis about authorship.
This is a paper entitled did Shakespeare write a newly discovered poem by two statisticians?
Well you might expect that it would be written by two English professors but no this is written by two statisticians.
And in this paper there's a different strategy by which these statisticians try to decide whether or not a poem was written by Shakespeare.
And the method that they use in this case is the method of looking for unusual words.
So the previous strategy was to look for usual words and how frequently usual words were used.
This strategy is another statistical variant in which they look for unusual words.
The kind of statistics that they presented were ones where they tried to claim that among the words that Shakespeare used, very frequently he used words very few times.
In other words his vocabulary included 31,534 distinct words that appear in the Shakespeare canon in the 884,640 total words in the Shakespearean canon.
It's interesting that all these things are so precise.
But the concept here was to look at the words in this newly discovered poem.
So a poem was discovered by Gary Taylor on November 14, 1985.
And the question was whether this Taylor poem, as it's come to be known, was or was not written by Shakespeare.
And it had 429 total words and the issue was how to distinguish whether or not this could be ruled out as a Shakespeare poem.
This is more ruling out than asserting that it was in fact written by Shakespeare.
This is the basis on which this analysis is done.
They discovered that unusual words are very common for Shakespeare.
Two-thirds of the 31,534 distinct words occur three or fewer times in the entire Shakespearean canon.
The effect of this is that you expect, even in relatively small samples of works from Shakespeare, you expect words that do not appear in the rest of the canon.
So in this poem of 429 words, there's an expectation, and these statisticians develop a model,
where there's an expectation of how many words that they would expect to be new, words that did not appear elsewhere in the canon.
And in fact, there were nine new words that appeared in this poem.
And they are admirations, besots, exiles, inflection, joying, scanty, speck, tormentor, and explain.
Those words occurred nowhere else in the canon, sort of surprising.
Now by the way, a variation on a word counts as a different word in this counting.
So for example, admirations counts, although the word admiration appears 14 times in the rest of the canon.
And besots counts as a new word, although besotted did appear elsewhere in the canon.
So using this strategy and data analysis, these statisticians were able to induce evidence that in fact this poem was certainly possibly written by Shakespeare.
One thing that is sort of troubling about this, I'm sure to a lot of people who are in the subjects of literature or history,
is that it seems somehow wrong that decisive evidence in favor of one theory or another would not be based on expertise in the area in which this evidence is being induced.
So I wonder whether how experts feel about these kinds of arguments.
But the evidence is very difficult to refute without further kinds of evidence.
I wanted to say one word about the distinction between the evidence, the way that it is evaluated by Bayesian statisticians versus frequentist statisticians, which are other variety.
Namely, a Bayesian would be willing to say that given the word usage in the Federalist papers that there is a 99.9% chance that it's written by Madison.
Whereas the frequentist would say that makes no sense, either the paper was written by Madison or it was not written by Madison,
we should not ascribe a probability to the concept of something that is either true or it's not true.
Instead we could make assertions like this, that randomly selecting a collection of a thousand words from a person's writing who generally has six appons per thousand would have a probability of such and such
occurring by chance alone to have a document that has no use of the words upon.
That kind of reasoning would be agreed to by both camps.
Well, using data and statistical analysis is obviously a central part of our world today, but I will argue that it will become even more prominent a part of our world in the future.
And the main reason is the computer, the continuing development of computer technology.
With the computer, it's now possible to deal with large databases and we can use techniques that were previously computationally impossible.
Some techniques, for example, involve simulation as a means to understand a collection of data where you simulate things and see what happens.
And often these methods are computationally intensive and consequently as we become increasingly able to have more computer power applied to them, then these methods become concomitantly increasingly valuable.
So in these lectures, by the way, we've shown several times examples where we've simulated data to demonstrate the efficacy of, for example, an estimator.
Remember in the German tank example, we said, how are we going to estimate how many German tanks there were?
And we simulated using the style that what we proposed as a method of estimation in order to get examples of, to get a sense of how effective that estimator really was.
There are methods called the Monte Carlo method, which involves Monte Carlo referring to the gambling place of using random processes by a computer to determine very specific things.
For example, you can randomly think about simulating throwing a needle on a floor in a method doing millions of times in order to determine the value of the constant pi.
It's a very strange thing, and I won't explain it here, but that's an example of a Monte Carlo kind of method where randomness and computer simulation can lead to a definite result.
And at home, you can now do amazing statistical analyses completely, essentially instantly.
You can perform things on your desktop, statistical experiments that would make any early 20th century statistician like Fisher just drool.
They had to do these elaborate computations, and early textbooks on statistics would emphasize methods for reducing computation, because that was one of the obstacles to applying the logic of statistics to real situations.
Now, of course, those kinds of techniques are not so important, but in this final lecture, I'd like to make some observations about the statistical enterprise altogether.
So first, there's often a difference between statistical knowledge and understanding based on deeper principles.
So we saw this example when we discussed the difference between Kepler and Newton in their relationship to the elliptical orbit of planets.
Kepler was doing a statistical model fitting technique, that is, he had data and found that an ellipse fit the data quite well.
Newton, on the other hand, had a theoretical concept about a law of physics from which elliptical orbits followed as a required consequence.
But I wanted to give a more down-to-earth example that occurred when I was serving on a committee where the committee had to do with trying to prepare teachers, future mathematics teachers.
And one of the members of this committee came into one of the meetings and said, well, I went to a sixth grade mathematics class where they were preparing students to take one of these assessment tests that you know are so prevalent now, these high-stakes assessment tests, which they take very seriously, the preparation for these tests.
And the woman on the committee explained what the teacher had done.
She said, the teacher was telling the students how to do well on these multiple-choice tests, and this is what they explained.
She said, she told the students to read the question, if it's a word problem, to read the word problem, and to look for the numerals, the numbers, and then look at the word that's right after each of the numbers.
And if the word after each number is the same word, then you add or subtract the numbers and look in the multiple-choice answers to see if any of them occurs.
Whereas if the word following the numbers is a different word, then you multiply or divide the numbers and then see if in the multiple-choice answers is the answer.
So this was what was being taught as a way to succeed.
And think about it.
And I thought, this is crazy.
Well, actually, it works because look at the following kinds of word problems.
If you have seven books on a shelf and eight books on another shelf, then you add them up to see how many books you have all together.
Whereas if it says you have seven books on a shelf and you have five shelves, then you multiply them to get the right answer, 35 bucks.
So it's a heuristic.
It's a statistical method by which to come to the conclusion of passing the test.
But this is such a clear example of a misuse of statistical methods.
Obviously, the goal of the test is to ascertain some quality that is now being perverted by teaching people how to, so to speak, get around the actual goal of this test.
Well, okay.
So another common misuse of statistics involves the blind application of statistical tests.
I think it's fair to say that statistics is used more than it's understood.
Statistics provides a whole collection of methods to analyze data and methods to induce evidence for various possible inferences from data.
But we need to understand the mathematical and the probabilistic logic behind the statistical techniques.
If we do, we can be very clear about what the particular statistical test or statistical statement means and also what it does not mean.
If we attempt to reduce the discussion to some sort of formulaic adherence to following tests, it's extremely likely that we're going to get misleading results or often nonsensical arguments.
And we saw that taking the, for example, if we just thought about taking averages, if we took the mean of the wealth of all the graduates of Lakeside School,
it gave us a very dubious picture of when every person got millions of dollars.
That kind of thing is just a blind application of something.
I ask a friend of mine who is a professor of microbiology, how is statistics actually used in your laboratory?
And she said, well, I'll tell you how my graduate students use statistics.
They gather data, they enter it into Excel, and then they apply every statistics test in Excel.
And if any of them comes out with a p-value less than .05, they declare that to be victory and report the result.
We've seen over and over again, statistical reasoning is sufficiently subtle and sufficiently prone to these counter-intuitive examples.
We've seen them throughout this course, that actually understanding the underlying logic is absolutely necessary in order to have confidence in the result.
And we've seen this example, choosing a good hospital.
We saw that you had to think more deeply than just the first statistics or we saw in the law lecture, evaluating the evidence against this cabbie who may have been driving a blue or a green cab.
Remember that we had to look more deeply in order to see what the implications of the evidence really were.
So one of the basic strategies of statistical inference, you recall, is the logic of hypothesis testing.
And remember, this is familiar to us, since it's really like our judicial system.
We're to assume the person is innocent until the evidence tells us otherwise.
That is, in hypothesis testing, we suppose hypothetically that the world is such and such a way, and then we determine whether it would be a rare event to find the data that we actually find.
Remember, that was the strategy of hypothesis testing.
But hypothesis testing has issues of its own.
For example, the arbitrariness of the level of rarity that we deem statistically significant.
How rare is rare?
So this, and there are other issues that are real issues, they have to be understood in the context of each application that we try.
Anybody who blindly asserts that if you get a p-value of .049, which is less than the threshold of .05, that means it's a better result.
If you say, OK, you get a p-value of .049, and that implies that the evidence is statistically significant, and therefore the null hypothesis is false.
Whereas if the outcome gives a p-value of .051, the person tells us that the null hypothesis is true, that person just doesn't understand the reasoning behind the hypothesis test and the probabilistic nature of the appropriate conclusions from statistical inferences.
The Bayesian strategy of updating an a priori concept or probability of the world, or viewing the world as something that we don't know, and that each part of it has a probability that needs to be updated as we gather more evidence.
This in some sense gives a more continuous way of interpreting data, and some people find it very persuasive.
Well, the persuasive strength of a statistical argument requires a clear understanding of the statistical reasoning, the context of the situation, and the details about the study or the data that all allow us to interpret the meaning of the statistical data and arguments with conviction.
Unless we really have a high confidence that a survey, for example, was conducted appropriately, that the questions weren't slanted, that the sample wasn't biased, that the interpretation of the answers actually did capture the issue that we were truly interested in,
then the statistical result, it's a piece of evidence, all right, but it may not be as strong as reported. And we saw this example in the literary digest poll for the presidency of 1936, and maybe even more startlingly in the Anne Landers example.
Those were cases where completely inappropriate conclusions seemed to come from a kind of a survey. So good statistical results and inferences are far superior to anecdotal evidence on an issue. That's true, but we need to be critical consumers of statistical evidence.
So in a fundamental sense, statistical knowledge is by its very nature an admission of ignorance. If we knew all the factors that create happiness, we wouldn't have statistical studies that assert that 50% of people with this characteristic have this result.
In such a statement, what it means is that we don't have the whole story yet. We're not able to say that if we do this and we do that and we do the other thing, then the economy will definitely get better.
Instead, we assert that the probability of its becoming better will increase. Statistics, it's an admission of ignorance, and it's extremely useful in dealing with that basic reality of our ignorance.
But expecting surety from statistical results just is a misunderstanding of the fundamental nature of the probabilistic processes with which statistical methods are all involved.
Often when we know something statistically, that knowledge actually gives us two pieces of information.
One is the indication of reality given by the statistics, and the second is an indication of what questions we need to ask to gain a deeper understanding of what's going on.
For example, if we learn that a higher percentage of people who have high cholesterol develop heart trouble than those with lower cholesterol, then we're led to investigate the mechanism by which high cholesterol causes heart problems.
So in some cases, the underlying reason for the correlation may not be known, and in those cases, if you're talking about medicines, it's a question about whether to treat the symptom or not.
Well, in a very fundamental way, much of the human experience seems to me is centered on the quest to derive meaning from the information we receive about the world.
And in all realms, there are challenges, but when the information comes in the form of data, particularly numerical data, we meet special challenges.
So statistics is a collection of profoundly powerful methods for understanding our world with more detail and more meaning.
We've seen statistics as having two parts. There's first, organizing, describing, and summarizing a collection of data when we know all the data.
And second, inferring information about the whole population when we have data only about a sample of the population.
So the guiding themes of describing all the data on the one hand and making statistical inferences on the other give us the framework on which the whole of statistics is built.
Statistical methods help us to put structure on complex collections of information, and we've seen how to think about the whole distribution of data rather than being content with one number summaries like the mean.
And we've developed strategies by which we can reasonably infer consequences from statistical and probabilistic situations.
The goal here is to answer the questions, how close and how confident? How close is our estimate of an unknown feature of the population, and how confident are we that that estimate is in fact close?
Statistics is really a powerful tool to help us understand the world. In fact, it's so powerful that I think we should end the course with a statistic about statistics itself.
And that is that among people who learn something about statistics, 100% appreciate our world with more clarity.
It's been my privilege and my pleasure to deliver these lectures. I feel honored that you've listened. Thank you. Bye for now.
