Well, now let's turn to his early mathematical interests, and I want to place his work in
context, and so I want to first paint for you the mathematical scene of that period.
In the mid-1800s, there was much interest in subtle questions involving numbers and
functions.
Now for our purposes here, let's just think of a function as a formula.
In fact, one of the individuals interested in this study was the very influential mathematician
Bernhard Riemann, who we mentioned in lecture 7.
The question of interest was how to express certain exotic functions as sums of more familiar
trigonometric functions, such as the sinusoidal sine and cosine function that we saw sometime
back in our school days.
So these functions that we were trying to look at were more complicated wavy functions.
You can imagine, for example, visualizing a sound wave, very wiggly functions, and we
want to write these wiggly functions in terms of sums of these nice sines and cosines.
This theory later became known as Fourier analysis, named after Joseph Fourier, the
great 19th century French physicist.
Well, by 1870, it was known that the functions that were of interest to mathematicians of
the day, those wiggly functions, could indeed be expressed as a sum, a potentially an endless
sum, of sine and cosine functions.
However, the big question was, is such an expression unique?
In other words, is there only one way to write these wiggly functions as sums of trigonometric
functions?
That was the question.
Well, in 1868, Cantor accepted a position at the University of Hull, outside of Berlin.
Two years later, one of his senior colleagues there, Edward Heiney, published a paper in
which he mentioned this question of uniqueness.
In particular, he actually noted that many great minds, including Riemann, have been unable
to answer this important question.
Well, this challenge captured the imagination of Cantor, and he set off to tackle the question
that the great minds of the day could not themselves answer.
And well, just within one year, one year later in 1871, Cantor published a solution to this
famous, famous uniqueness problem.
He actually proved that if the functions were reasonably nice and well-behaved, as most
functions of interest of the day were, then there's only one way to express them as a
sum of trigonometric functions.
Well, Cantor wondered if the results still held for functions that were strange and not
so well-behaved.
He soon proved that, in fact, functions could be, in some sense, bad, as long as they were
only bad at finitely many numbers.
Well, what do I mean for a function to be bad at a number?
I mean that if we were to put that number into the formula, it would be like dividing
