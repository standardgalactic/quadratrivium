Welcome back one more time, today we're going to go through our 11th lecture in the series
on how to think like an economist.
Today we're going to do something just a little bit different.
We're going to venture a little deeper into that somewhat new field of behavioral economics,
a field that sort of crosses the boundary between economic thinking and experimental
psychological research, and I think we're going to find some really strange things there.
In Rodgers and Hammerstein's famous classic Broadway story, The King and I, the Thai monarch
has hired a British nanny to come and teach his children, but he finds himself utterly
confused by her strange thinking and her strange behavior.
So at two times during this musical, he stops and breaks into a plaintiff's song that's
called It's a Puzzlement.
And in this new field of behavioral economics, we're going to find that the actual behavior
of real human beings in both experimental situations and in some real life situations
is also very puzzling.
We're going to find some real puzzlements.
The foundation principles and the core concepts that we've used so far see a world that's
made up of individuals who are always maximizing.
They're calculating their options.
They're thinking carefully about how to maximize their self-defined welfare.
People in that world are supposed to be always and everywhere rational in pursuit of that
goal, yet when actual human behavior is observed in many different contexts, in many sort of
different ways, people seem to make decisions that just don't fit that vision.
So today, there's some puzzles that we're going to look at and we're going to see if
we can solve these puzzles, if we can explain the behavior using our regular economic way
of thinking or whether they're a challenge to some of these foundation principles, core
concepts or our central conclusion.
That's the topic for today.
A lot of the evidence in behavioral economics comes from carefully controlled experiments
run in laboratories where the experimenters will set up structured tasks or games.
And one of the most famous of these is something called the ultimatum game.
And here's how it works.
Suppose I come to you and I say, would you like $5, no strings attached?
The odds are almost all of us would take it.
The options are $5, no dollars.
As the kids say, that's a no-brainer.
But let me modify that a little bit.
Instead of just giving you the money, what I'd like to do is to take all of you and divide
you into two groups.
One half stays here, the other half goes into another room.
I'll pair you so you each have a partner, but you don't know who that partner is and
I'm going to link you by computer.
You cannot communicate except under very strict circumstances.
Now what I'm going to do is I'm going to offer $100 to you as a pair, but there's a catch.
You have to agree on how you're going to divide that $100 and you're going to have to do it
through a specific process.
I'm going to give your partner the power to deliver an ultimatum.
He or she will put on your computer screen a take it or leave it split.
If you accept that proposal, then each of you gets the money, but if you reject it,
neither of you receives anything.
Now when you first look at it, that seems to be a regular simple game theory puzzle
and the outcome should be predicted by allowing each of our players to think in economic terms.
If you're the one with ultimatum power, your options are to say that I can offer very little
to my opponent or I can offer very much.
And of course anything I offer is greater than zero.
He should accept any offer.
And his payoff matrix says that he should do that.
After all, if I offer an ultimatum of $95 for me and $5 for him, that looks easy, doesn't
it?
Just as it was a moment ago, his options are $5 or no dollars.
Remember?
That was a no brainer.
Of course $5 is better than nothing.
He might be angry, but he'd be unambiguously wealthier.
Do you think he'll accept?
When the ultimatum game is actually played in an experimental situation, it's astonishing
that with a high degree of consistency, the person receiving an unfair ultimatum usually
will reject it.
Apparently the dissatisfaction of letting somebody else benefit from being unfair is so high
that people think they're better off foregoing a gain for themselves than for letting someone
else become unjustly enriched.
That's really interesting.
Does that challenge the way that economists think?
Compared to a payoff of zero, which is what I offered you the first time, either $5 makes
you better off or it doesn't make you better off.
If you chose $5 in the first instance, doesn't rationality dictate you should choose it in
the second?
Well, not necessarily.
You remember as far back as lecture two where we first introduced the concept of rationality?
In our thinking, rationality refers to the process of reaching decisions, not the objectives
and the motivations.
If you get great pleasure or displeasure from ice fishing, from attending the opera, from
sleeping in your hammock or running an ultramarathon, that's up to you.
What you like and appreciate is something that no economist can tell you.
And what the evidence here is showing us is that there are people, perhaps lots of people,
who literally put your money where your mouth is value on social contexts, on equity and
on fairness.
If those things matter to you, like ice fishing matters to you, then rationality, as we've
been using, requires that your behavior respond to that.
And I guess the evidence from repeated plays of the ultimatum game is that for many, many
people, fairness has a real value, unfairness has a real cost.
The world's probably a better place because of that.
The ultimatum game requires that we extend the boundaries of our analysis to pay attention
to the social context in which we interact.
But it doesn't really undermine the basic tools of our economic thinking.
A second kind of puzzling behavior that comes from behavioral economics is something that
has to do with anchor points.
Anchor points are a heuristic, a shortcut that people use apparently subconsciously when
we find ourselves faced with unfamiliar decisions.
In the town where I live, we have lots of good and successful restaurants.
Saturday night is very busy on Main Street.
A couple of years ago, a restaurateur from New York came and he put a new entry into
the dining-out sweepstakes, but he didn't last very long.
And once he closed down, he complained to the local newspaper that apparently people
in our town just don't appreciate fine dining and were not willing to pay for it.
What had happened to him was he'd collided with an anchor point.
Before we go into transactions, apparently we have in our mind conceptions and anchor
points, something that gives us a benchmark to define what's an appropriate price to pay.
In the early 2000s, when the housing bubble was rising so substantially and the San Francisco
Bay Area was the most expensive housing market in the country, people didn't blink when someone
asked a million dollars or more for a modest ranch house.
Trust me, anyone who moved there from Syracuse, New York, where the median home price was
about $75,000, anyone who'd done that would have had a coronary at the mere mention of
such a sum.
People live in communities where they develop psychological anchor prices set by the context
in which they live.
Dan Ariely, one of this new breed of behavioral economists, has done a study and he said that
the transplants who move from a community like Syracuse to San Francisco take at least
a year to adjust their anchor points to the new communities.
They will undoubtedly have to rent for at least 12 months before they can make the psychological
adjustment to realize what's, quote, an appropriate price in the new market.
That failed restaurateur back in Northampton, Massachusetts hadn't recognized that the anchor
price for fine dining in a New England college town is going to be a whole lot less than
the anchor price in New York City.
I think we do appreciate fine dining in our town.
We just have a very different definition of what's a reasonable price.
An anchor point can be an efficient and rational response when we're faced with the ignorance
that we've talked about before as being inevitable.
When information is expensive, we're always going to go into unfamiliar transactions without
all the information we'd like.
So an anchor point gives us an estimate of what something should cost.
But we also need to recognize, if we're realizing how strategic behavior works, that use of
anchor points creates strategic opportunities so other people can use them to influence
our decisions.
Here's an interesting example.
Restaurant consultants will often suggest that a restaurant add new, very high priced
entrees and high priced wines to its menu if it wants to increase the average bill that
its diners undertake.
And why do they do that?
It's not because a lot of people are going to select the new high price options.
In fact, the evidence is that the bill rises because it creates a higher anchor point in
consumers' minds because they have something expensive to compare it to.
And what happens is, it makes the second highest priced option seem more reasonable.
Dan Ariely tells another really fascinating tale about anchor points, and in this case
he was talking about home bread making machines.
Now when they came on the market a few years ago, that was an absolutely new appliance.
No one had experience with them, no one knew how useful they were, no one knew what a reasonable
price would be.
So the manufacturer built the first models and offered them for sale at a price of $275
and they sold like, well actually they didn't really sell much at all.
So they went back to the drawing board and what they did was they designed a larger fancier
model, produced it and priced it at half again as much as the original.
They were establishing a high anchor point, a point of comparison.
And the result, according to Ariely is, that there was significant increase in sales as
a result, not of the deluxe model, but of the base one.
That new anchor that was set by the expensive option now made the original machine look
like a much better buy.
But without experience, without a point of reference, who could possibly tell?
I suppose the lesson in all this is that if you want to sell more of an expensive item
maybe you should offer a still more expensive item.
Others try to set anchor points for us in lots of different contexts and it's probably wise
of us to recognize when they're doing that.
I like to think that my wife and I are very generous supporters of lots of good causes.
I think the fundraisers think we should be even better supporters because we get any
number of letters each year, often with a little personal note at the bottom, saying
we'd like to have a suggested donation of $1,000.
At that point I usually joke, gag, turn to my wife and say, who do they think we are?
We don't have that kind of money.
And then I think a little bit more about what's happening and I know they don't really expect
us to give $1,000.
Well, they'd like it, but they don't expect it.
The purpose of putting the $1,000 suggestion there is to raise our anchor point.
And if it makes us decide to give $200, rather than the $100 we were originally considering,
the letter served its purpose.
It's just like the very high priced wine on the menu.
It raised the expectation of what was appropriate.
People can set anchor points strategically for us when we're doing some kind of a guided
search.
A few years back, my older son and his wife were looking for their first home to buy and
of course they asked dad to come along as a consultant.
And we noticed that whenever a real estate agent set up a series of houses for us to
examine in a day, the first one we went to was always the worst one.
It would be in bad shape, it would need lots of repairs, it would be full of clutter and
it would be overpriced.
And after this had happened two or three times, we realized they never expected us to be seriously
interested in that house at all.
The purpose of starting there was to set a standard to make all of the others look that
much better.
The dump was on the itinerary to provide an anchor point.
I guess that's done commonly.
A few years later when my younger son and his wife started the same kind of a search,
I went along with them as well.
And I remember the first house we went to was an absolute disaster.
The wiring was so bad it couldn't get insured, the roof was about to fall off and the house
was being sold by somebody called Bob.
And after that, the semi-serious response that the kids had with every house they looked
at was, well at least it's better than Bob's.
That phrase sticks with them even to this day.
Anchors can be very useful tools in understanding situations when we have limited information
and limited experience.
In that sense, their use can be very rational.
But we also know there's a potential for that process to be used strategically by others
and we need to be conscious of that as we make our decisions.
There's another puzzle in behavioral economics.
This one's a bit harder to reconcile with our basic toolkit.
It's what's called the endowment effect.
In the normal economic view, an item's value, of course, we've said many times, is its value
for me.
There's nothing intrinsic about it.
It measures the contribution to my self-defined welfare on the margin.
Remember that desert traveler stricken with thirst?
The question how much water was worth depends on how much he actually had.
And so if I'm in a position where right now a glass of water would be worth 50 cents to
me at the moment you begin handing it to me, it should still be worth 50 cents to me when
it reaches my hand.
There's no obvious reason why changing possession should alter my valuation.
The behavioral economics seems to find that it does.
It's the opposite of the grass is always greener effect.
The endowment effect is that once the grass is mine, it gets greener.
It's hard to think of an economic reason why that should be so, but apparently it is.
Here's a hypothetical.
Suppose I had an infallible lie detector and I hooked you up to that and I offered you
a bottle of wine and you said to me, I'll pay $100 for that and not a penny more.
With my economic thinking, I would conclude, aha, your marginal value for that bottle
of wine is $100.
And if immediately after you bought it, someone came up to you and said, I'd like to buy
that bottle of wine for $110, normal economic thinking says, well, of course you'd sell
because you have $100 value you just revealed to us.
Now you're offered $110 for it.
It's only logical to sell, seemingly rational, but people don't always behave that way.
Apparently, a bird in the hand is worth much more than a bird in the bush or even a bird
in somebody else's hand, maybe quite a bit more.
Danny Ariely, again, and one of his colleagues, Ziv Karman, ran a natural experiment to determine
just how strong this endowment effect can be.
It's a fascinating outcome.
They both teach at Duke University and Duke periodically finds itself in crucial playoff
basketball games that are the highlight of the campus season.
The number of students that can be accommodated in the basketball arena is much fewer than
the number of students on campus, so the competition for tickets is intense.
Students camp out, in line, sometimes for days on end, putting their whole lives on
hold, not to get game tickets, but to qualify for a lottery number that will let them possibly
get game tickets.
The actual tickets go to the lottery winners.
So the lottery winners and the lottery losers all paid the same price, they all camped out
for a long period of time, and so it would seem that the difference between the winners
and the losers is pure chance.
So with the logic we were just talking about with the bottle of wine, it would seem like
the students who win the lottery tickets, the price for which they would be willing
to sell, the absolute minimum price they'd be willing to sell, should be pretty close
to the maximum price a loser would be willing to pay.
So shouldn't those prices turn out to be the same?
Logically you think it would, but it turns out that in fact they are.
So here's what Ariely and Carmen did.
They called up all of the losers of the lottery tickets and they said, I might be able to
find you a ticket, but I need to know what's the absolute maximum price you could pay.
You would not go any higher.
And then they were told, well, we'll put you on the list and call back if we can find
a seller to meet that bid price.
Now it's important that the losers can't understate how much they will pay because
if they do, they lose any real chance at those very scarce and highly coveted tickets.
Then they called the winners and said, we might have some buyers for your tickets.
And so they pushed and pushed and pushed and said, what's the absolute lowest selling price
for which you would sell your tickets and I'll call you back if I can find a buyer.
But again, the holders of tickets knew that if they overstated their price, what economists
call their reservation price, they wouldn't be able to cash in.
So what do you think the results were?
This is very interesting.
The losers said they would pay an average maximum price to buy one of those tickets of $170
each.
And the sellers or the winners said the average minimum price they would take to sell one
of their tickets was not $170, wasn't even $175, was $2,400, a huge difference in value
that can't be explained because the two groups came from different socioeconomic classes,
one was wealthy, one was poor, or different intensity as basketball fans.
They'd all camped out for days on end putting their lives at hold.
They were all undergraduate students at the same institution.
The only thing that separated those two groups of people was chance in a lottery.
And the only clear difference is some had won tickets and held them in their hands and
some did not.
And that alone somehow made the value nearly 11 times higher for the lucky ones.
For reasons largely inexplicable by our traditional reasoning, there was a very significant endowment
effect.
Even if traditional theory can't really explain it, it behooves us to recognize it.
And as the king of Thailand saying in this show, it is a puzzlement.
Another puzzle in behavioral economics is something called loss aversion.
There's no real reason why the value we place on winning $1 or losing $1 should be much
different.
It's a dollar in versus a dollar out, the same general thing.
But experimentally I guess we find that a loss hurts about twice as much as a gain helps.
So $100 loss is the negative equivalent in self-defined welfare of a $200 gain.
That's found from experimental data.
If you don't believe it, visualize the following.
Suppose you're on one of these game shows, you've been answering questions correctly
and pushing your winnings up and you're up to $50,000.
Here comes the final double or nothing question.
And you risk it all and you lose.
You gained $50,000, a few minutes later you lost $50,000, you are right back where you
started.
Everything canceled out.
But are you going to feel worse on the way home than you did on the way to the studio?
I'm betting you will.
You might not sleep for days.
The loss hurt worse than the gain helped.
Mathematically, nothing changed.
You had exactly as much when you went home as you had when you came, but psychologically
everything changed.
This tendency, known as loss aversion, sometimes makes us bypass rational choices that have
real expected value gains.
We forgo chances of substantial benefits because there's a chance of a relatively small loss.
One last behavioral trait today, and that's called the status quo effect.
My daughter drives a 10-year-old automobile, wasn't a fancy car to begin with, it's got
well over 100,000 miles on it, and we looked up the Blue Book value not long ago and it
was about $1,000, maybe $1,100.
The comprehensive insurance on that car, in case of collision, even with a deductible
is a little bit over $300 a year.
With all the things we've talked about, if you look at that rationally, you've got two
options and it should be easier to pick.
You can take a risk, a chance of totaling the car and losing as much as $1,100, or you
can absolutely for certain lose $300 each and every year paying that premium.
The expected value, we talked about that, the expected value for the comprehensive coverage
only makes sense if the probability of her totaling that car is greater than about 40%.
She's a safe driver and simple, expected value analysis says, no, that makes no sense.
But of course, when she first bought that car, the calculus was different.
It was a newer car, it had lower mileage, the value was greater, and the expected value
of a loss would have been greater.
So at that moment, it probably made sense to cover her.
But the car aged, the miles piled up, the value declined.
And clearly there came a point where the falling value of the car made the expected value of
the loss so low that the insurance made no sense.
But for years, she did what we all do.
She got a renewal form in the mail, she checked yes, renew, and gave it not a moment's thought.
We tend not to revisit decisions once made or consider whether they still make sense.
We experience status quo bias.
It was really only a move to a new state last summer that forced her to think seriously
about that decision when she had to shop for new insurance between multiple companies.
The consequences of this bias affect lots more than just too much clunker insurance.
When I finished my PhD, it was going to be my first salary job ever.
I was going to be an assistant professor of economics, I was 26 years old, I'd been
in school my entire life, I'd never had a steady income.
And retirement, that was the farthest thing from my mind, I didn't give it a moment's
thought.
But when I arrived on campus to take that job, I had to fill out lots of forms, and one
of them was choose an allocation for your contributions to your retirement plan.
And I did what most people do, I took the contributions and I split them equally among
the alternatives, that seemed like the easy solution, and I forgot completely about it
for years.
It's now many years later, and I'm getting a little bit closer to retirement.
And today I realize that there were much better strategies, I should have been more diligent,
I should have reallocated my contributions.
That first useful choice I made became the status quo and I stuck with it for years.
You'd think that a PhD in economics of all people would apply the tools of rational analysis
and make better decisions than that.
That would have been the rational thing to do, but the key phrase in that was, an economist
of all people.
And despite my formal training, I made a choice just like everyone else does and got caught
by status quo bias.
And today I know that that has cost me literally tens of thousands of dollars by not making
the best decisions.
I'm not alone in that.
A study done by TIA-CREF, which is the organization that organizes pensions for college professors.
Remember college professors are very educated people.
They've found that half of all college professors never, never, ever change the allocation
of their contributions even once.
Whatever they picked on that first day, they stuck with for their whole career.
Marketers know this about us.
Cable companies and phone companies offer low introductory rates, $19.95 a month for
the first six months, because they know that at the end of six months, we're probably just
going to continue even at the higher rate.
Main publishers know this.
They try to get us to subscribe just once so that they know that we're likely to keep
renewing automatically even if we never even read the magazine.
Manufacturers prefer rebates to price reductions.
Do you know why?
Because most of us don't even send in the forms to claim the rebates that enticed us
to go in and make the purchase in the first place.
So what are the conclusions?
When I was young, there was a very famous comic strip named Pogo Possum, and one of
the most famous quotes out of that was one day when the title character said, we have
met the enemy and he is us.
The strange findings of behavioral economists make that observation applicable here.
The evidence is pretty clear.
The thing that most prevents us from making rational decisions, the ones described by
our economic thinking, is often us.
That's the real takeaway point from this lecture.
If we really want to make rational decisions, we need to be aware of and consciously take
action to overcome our own intrinsic tendencies toward irrationality.
We're susceptible to being influenced by anchor points that others can set strategically.
We treat equal losses and gains as if somehow they're very different.
Our inertia lets unwise decisions persist.
We leave free money on the table.
And on one level, the ubiquity of these very strange behaviors muddies up the waters.
It makes the economist's predictions of rational behavior seem just a bit out of focus.
But on another level, when we become conscious of these phenomena, it gives us an opportunity
to do some things to overcome our own irrationality.
We now know what an anchor point is.
And if we recognize when someone is doing something to set one for you, you can resist
being unduly influenced.
When you go into a restaurant, be careful not to compare the entree price and the wine
price with the highest items, compare them with the lowest.
When the real estate agent says, let's start out with this dump as a starting point, skip
that house because it's just trying to set an anchor point.
You can even make status quo bias work for you.
Here's a suggestion.
When you sign up for that new cable service with six months low rate, that same day, write
a letter canceling the new cable service, give it to a friend, give that friend $5 and
say mail this in six months unless I explicitly ask you not to.
You can even do something like this.
Suppose you make an agreement with a close friend that each year you'll get together
to celebrate your birthday.
And you promise you'll pay for any bottle of wine on the menu that your friend chooses
if you have not in the past month met with your financial advisor to consider your retirement
allocations.
To economists, Rich Thaler and Cass Sunstein, call these things nudges, conscious changes
that we make to our own choice architecture, that we can create new incentives for ourselves
to make us make more rational decisions.
Well, we're almost to the end, my friends.
The next time, we're going to take a multi-part final exam.
We'll take a look at a few other nudges that have come along as a final way to see how
we can think like economists.
We'll take out our tools and our concepts.
We'll take one last look at them.
We'll examine them.
And then we'll use them to look at a couple of large policy issues and a couple of small
personal decisions to see how effectively we've learned to think like economists.
