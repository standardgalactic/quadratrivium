Hello, I want to welcome you back to the third lecture in our series on how to think
like an economist.
Today what I want to do is broaden our focus just a little bit.
So far we've been paying the closest attention to the strategic decision making that rational
individuals will undertake in a world of scarcity.
What would or should a rational individual do in different circumstances?
That's a question we ask ourselves as participants in the economy.
But as economists we're also concerned with a broader related question and that is what
happens when lots of rational individuals make decisions that are optimal for themselves,
does that always come out to be best for everyone?
Sometimes, often, always, never.
That's really the question that economists as professionals are most often addressing.
How does a society fare when it's made up of rational individual decision makers?
That's going to bring us to one final concept today, the concept of economic efficiency.
Efficiency is related to rationality but it's a little bit different.
Efficiency is looking at the process by which individuals reach their decisions.
Efficiency is measuring the consequences of all those many choices.
So what we're going to do first today, we're going to define efficiency the way economists
do and then we're going to try to develop our ability to use that in context.
And the second thing we'll do is take a first cut at trying to figure out the conditions
that have to be fulfilled if rational individual choices are going to result in efficient social
outcomes.
And then finally, we'll take a look at this one classic situation that's called the
prisoner's dilemma.
It's a case where rational individual decisions lead to an inefficient outcome.
What people choose to do rationally turns out to be less than the best for themselves
and less than the best for society.
People revisit that kind of problem later in other lectures.
I just want to emphasize that those are the situations where thinking like an economist
is going to be the most valuable.
There's not much urgency in rushing to the doctor for advice when you're completely
healthy.
And similarly, there's not that much need of thinking like an economist when everything
is running perfectly smoothly.
When we're faced with imperfections and obstacles, when there are problems in the way that economic
thinking becomes the most valuable.
So let's start.
Let's start talking about what is the definition of efficiency for an economist.
Efficiency like rationality means different things in different contexts.
If you ask an engineer what's efficient, she'll tell you it's achieving a given amount of
work with a minimum amount of energy.
If you ask an economist what's efficiency, the economist can say it's defined in terms
of making people as well off as they can be given the resources available.
Now who determines when you're well off?
Who determines when you're better off?
An economist doesn't.
You do.
Just as rationality makes no judgments about the wisdom of the objectives, efficiency is
not about whether you should feel better off.
It really is going to ask only if you do.
If you honestly consider yourself better off sitting out on the ice for an hour looking
at that hole hoping a fish will bite, then ice fishing does make you better off.
It's a rational choice to do it.
It's an efficient outcome having done it no matter what my wife thinks about the process.
I get to decide what's best for me.
You get to decide what's best for you.
And then if we're both rational, we each will have picked our own best option.
That's settled.
There's a harder question though.
When are things best for us?
When is a society made better off when there are lots of people involved?
How do you judge that?
When is a change a clear social as opposed to just an individual or personal gain?
Economists have struggled with that question for decades trying to figure out when one
social outcome is better than another social outcome.
By the time they got to the mid-20th century, they resolved the conflict by frankly just
giving up.
They decided that they could never find a strong, objective measure of social welfare.
So we settled for a pretty weak one instead.
Economic efficiency is based on a principle first proposed by a sociologist named Vilfredo
Pareto.
And he argued that the only unambiguous standard for saying this is a better outcome than that
is that if it makes at least one person better off by their own judgment without making anyone
else worse off, then we can say that's an unambiguous social improvement.
A Pareto optimum then is when we've reached a place where no one can be made any better
off without making someone else worse off.
And for an economist, when you reach Pareto optimum, that's efficient.
No unambiguous gains remain to be satisfied.
Doesn't mean it's just.
It doesn't mean it's fair.
It doesn't mean it's philosophically ideal.
It just means it's efficient.
Now, failure to take advantage of a Pareto improvement, that also would be inefficient.
Rationality and efficiency are pretty closely linked, and the distinction between them is
subtle, but it's important if you're going to understand how to think like an economist.
Rationality describes the process of making wise individual choices.
Efficiency is evaluating the social consequences.
When do rational individual decisions made of here lead to efficient results over here?
If you think about our foundation principles, it sounds like they're a prescription for
perpetual and bitter conflict.
This is a world of scarcity.
There is always a cost, at least in opportunity terms.
Doesn't that mean that there has to be a constant competition for resources?
Doesn't it mean that the resources that one person used cannot be used by another?
Doesn't that mean that one person's gain is always going to come at another person's
expense?
And doesn't that mean all interactions violate Pareto's standard?
After all, they're always counterparties.
They're always counterparties.
Every sale is a purchase.
Every loan is a debt due.
And the consequence of all that feels like it could be what Thomas Hobbes characterized
as war of one against all where life is nasty, brutish and short.
There are some failed states where Hobbes' vision seems to hold true, but most of the
world, most of the time, we seem to have a significant degree of cooperation and stability.
How can that be?
Thinking like an economist, I think, is going to provide an answer.
I once came across two friends who were having a fairly heated argument, and one of them
was arguing that in any transaction, one party is always taking advantage of the other.
They can't both win because they're trading the same thing.
Shopping, she argued, was like hunting.
One must be predator.
One must be prey.
Either the buyer tricks the seller into accepting less than true value, or the seller has to
trick the buyer into paying more than true value.
But thinking like an economist, you see the transaction differently.
Remember when we talked last time about the diamond water paradox?
The economist argues that nothing has a real, intrinsic, timeless true value.
The value to anybody is the marginal contribution it's going to make to that person's welfare.
And the contribution can be quite different in different circumstances.
The value of a glass of water when I'm sitting at home next to a free flowing tap is very
different than the value of that same glass of water if I'm crawling across a parts desert.
So if rationality holds, then no one is going to willingly pay more for an item than it
is worth to them or sell it for less than it is worth to them so that in any well informed
voluntary exchange, both parties can win because they are literally trading one thing
that has two different values.
Here's an example.
Suppose that somehow I came into possession of a ticket to a concert by the latest teenage
heartthrob band.
Now I can assure you I'm probably better off by trading that ticket for virtually anything.
Anything trivial, a bagel, because attending that concert for two hours would be pure vexation
to me, but it could be as dear as life to a young friend of mine.
So if we were to trade, both of us would be made better off by that transaction.
I could sit happy at home with my bagel, and she could be thrilled beyond words to be attending
the concert of her dreams.
No predator, no prey, a contented well fed economist, and an ecstatic teen.
That's a win-win situation that's a whole lot better than my spending the evening at
the concert with my fingers in my ears while she sits at home crying tears on the unwanted
bagel.
Value in transactions has to be judged on the margin from the perspectives of the potential
participants.
In a voluntary exchange, both parties can and do benefit.
It's true for bagels and boy bands, and it's true for travelers and profit maximizing airlines
as well.
Every week I get emails at the last minute.
I got one not long ago from an airline that said, quote, fly to Las Vegas tomorrow, be
back for work on Monday, only $49 each way, $49.
That's not even going to begin to cover the cost per seat of flying that big jet all the
way across the country.
Clearly, the airline is losing something here.
The airline must be the prey, but you know that's not true.
There really aren't losers in that deal if you think like an economist about it, and
you focus on the margin, you focus on the impact of a series of small changes.
Come Friday afternoon, that seat is going to fly across the country.
The question the airline faces is, will there be a paying passenger sitting in it?
By Thursday night, everyone for whom the value of the trip that Friday is worth at least
the normal fee, say $456, they've already purchased a non-refundable ticket.
That was a voluntary transaction, and the voluntary transaction meant that the passenger
put cash on the barrel head, which was a clear revelation that that trip at that price was
making them better off.
And then the question is, is there another transaction that can make anyone better off
and no one worse off?
The plane's going.
The marginal cost of putting another passenger into that plane is virtually zero.
So any increase in revenue, even the skimpy $49 is greater than the marginal cost of flying
that passenger.
The airline's better off than flying empty seats.
The bargain passengers are better off than staying home, and even the full fare passengers
are better off than they would have been had they stayed home.
I suppose the full fare passengers might wish that they'd waited for last minute bargain
tickets, and they could have won even more, but that's not the same thing as saying that
they were actually losing.
Rational individuals would and presumably will voluntarily enter into any transaction
that makes them better off.
And if all the participants are made better off, it's a Pareto improvement.
It increases efficiency.
That's really the basis for Adam Smith's famous observation in his book Wealth of Nations
that he published in 1776.
In that book he argued that the most selfish person who engages in a voluntary exchange
is guided, quote, by an invisible hand to promote an end that was no part of his intention,
close quote.
That central conclusion that in any freely entered into transactions, all parties get
made better off, is really why economists have such efficiency for markets.
They like markets because markets promote efficiency.
That's really why, given our foundation principle that no one is in control, things really work
out.
I'm always astonished when I walk in with supermarket and the shelves are covered with
food.
Some farmers somewhere in Kansas put forth extraordinary effort to grow wheat and deliver
it to a flour mill.
Some miller put forth great effort to grind it up and turn it into flour.
Some baker baked it, turned it into bread, and the teamster drove across country to deliver
it to me.
None of them know me.
None of them care much about me.
While it seems as if they were doing all of this for me, in truth they did it all for
themselves.
It was pursuit of their gain that motivated them to meet my need.
I am fed, they are paid, all of us are better off.
Rational choices increased social efficiency.
Well, if it works once, why not time and again?
Wouldn't it be rational to just keep searching out more and more and more gains until there's
absolutely no potential gain left?
Do you remember when we started this course?
And I said, if you adopt an economist's paradigm, it's going to shape everything you see for
the rest of your life.
One night, last week, late in the evening, I was having trouble sleeping, so I got up
and turned on the TV.
And I happened to come upon a nature documentary on something called a star-nosed mole.
This is an extraordinary creature.
It's got 22 tentacle-like projections that come right out of the end of its nose.
And as it burrows underground, those tentacles are constantly sampling and seeking everything
that it comes in contact with, looking for any opportunity for a gain.
It takes immediate advantage of that and moves on to the next.
And do you know what my distorted response was to this?
My first thought was, metaphorically, that is the truly rational decision maker, constantly
seeking out any improvement in position, taking full advantage of it until all potential
gains are realized and captured.
Rational deciders won't consent to their own harm.
They won't refuse a clear gain.
Rational individuals won't walk away and leave, quote, money on the table.
It's the basis of an old joke about an economist and a political scientist.
It goes like this.
So an economist and a political scientist are walking down the street.
Political scientist says, look, there's a $20 bill on the ground.
And the economist responds, there can't be.
If there were, someone would have picked it up already.
Now, you're not laughing.
It doesn't seem that funny.
But if you tell that joke to a bunch of economists, they'll be giggling uncontrollably.
It's a strange phenomenon, but it captures how economists see the world.
So let me take a moment and summarize and emphasize.
At the participant level, thinking like an economist means focusing your attention on
the rationality of individual choices.
On the professional level, thinking like an economist means focusing your attention on
the efficiency of results.
When all the potential unambiguous increases in self-defined welfare have been captured,
then we are efficient.
When some remain or when harms result, we're inefficient.
Economist's professional concern is with efficiency.
So our second question today is, what's necessary to make rational individual choices result
in socially efficient outcome?
In a nutshell, it's just this.
The actual incentives that they face must be true, complete, and accurate.
Every single harm incurred must be compensated for.
Every gain experienced must be appropriately priced.
The rights that people have have to be clearly defined.
The information upon which we base our decisions must be complete and true.
The bargained promises we make must be kept.
And if we do all that, there's probably not much need to think like an economist because
the invisible hand seems to be working fine.
But what if?
What if there's some distortion, some inaccuracy, some failing so that the incentives that are
guiding our choices are somehow wrong?
The decisions we make then can be harmful to ourselves.
We can voluntarily choose outcomes that in fact make us or someone else worse off.
If the incentives that guide our choices are not comprehensive and accurate, then this link
between rational decisions and efficient outcomes is broken.
Rationality and efficiency fail as perfect mirror images of each other.
And here's where thinking like an economist is the most valuable.
If we can understand what's causing the difficulties, if we can figure out ways to address the consequences
of them, then we can adopt strategies to overcome or correct them, and we can again make rationality
result in efficiency.
Most of the rest of the course we're going to spend doing just that.
Today what I want to do for the rest of this lecture is talk about one such case and it's
kind of an esoteric problem, but we're going to encounter it in lots of different contexts.
And it has implications for our decisions as individuals and perhaps even for our survival
as a species, but more on that later.
What I want you to do now is imagine a scene, it's one you've seen countless times on police
dramas on TV.
Two suspects have been arrested and the police have put them in separate interview rooms.
The detective goes into each room and offers each of them a choice.
The choice is going to affect them both, but they're not allowed to communicate with each
other.
So here's the situation.
They're arrested while driving in a stolen car and the prosecutor is planning to take
a two-year sentence for possession of a stolen car and they have ample evidence in order
to convict on that.
But the police also believe that the two suspects were involved in a drive by shooting earlier
that night, but they don't have enough evidence, so they need a confession and perhaps even
the testimony of one to convict the other of the serious assault with a deadly weapon
charge.
So they go in and they offer a deal.
Testify against the other man and I'll offer you a one-year sentence for the auto theft
and a walk on the shooting.
He'll take the fall, a hard eight years for the combined crimes, help yourself out.
Now's the time, confess.
Now, of course, the other suspect is being offered exactly the same deal.
And so you're suspicious that if he flips first, you're the one who's going to do the
full eight years.
And it turns out that if both of you confess right away, prosecutors don't need either
of you, so they don't need somebody to testify, but they don't want to pay for two trials.
So if both confess, they'll settle for a plea bargain sentence of four years each.
If you both hold the line, if you both stonewall, they've only got enough evidence to convict
on the stolen car charge and each does two years.
So the question is, what's the individually rational decision for each of these suspects?
If you're going to think like an economist about this, you're going to find yourself
deep into something called game theory.
Game theorists try to look at situations where players have independent strategic decisions
and they're going to put the effects of that into something called a payoff matrix.
And looking at the other player's possible moves and anticipating the consequences for
yourself, each player is supposed to determine an optimal strategy if they possibly can.
So here's how we would structure this.
What we'd do is we'd have a table with four cells in it and we'd put the possibilities
for my opponent on top and so we'd say if the opponent confesses or the opponent does
not confess and then down the side we'll put my options.
I confess, I do not confess and then in each of the boxes, we'll have the consequences
for me.
So let's look at it.
If he confesses and I confess, we'll both do four years time.
If he confesses and I do not confess, my sentence is going to be eight years.
So if he's down the hall confessing, I minimize my sentence by confessing as well.
If on the other hand he's down the hall holding the line, refusing to confess and I do confess,
I'm only going to have a sentence of one year.
If he holds the line and I hold the line, I'll do two years.
So if he's down the hall holding the line, stonewalling, refusing to confess, I minimize
my sentence by confessing.
So what's the conclusion?
If he confesses, I should also.
If he does not confess, my best strategy is to confess.
So regardless of his strategy, my best choice, the individually rational choice for me is
to go ahead and confess.
Of course, he faces the same payoff matrix, he's doing the same thing and so as a consequence
what we're going to find is that both of us confess, both of us end up doing four years.
That was the rational decision for each of us individually.
But had we stonewalled, we each would have done two.
We made rational, individual choices that combined into an outcome that was less than
best for both of us.
Why?
Mostly because we could not communicate.
We dared not trust.
We could not form an enforceable agreement.
Now who was thinking like an economist in this particular situation?
The answer, of course, is the police.
They purposefully shaped the incentives to make sure that the rational decisions made
by the suspects would benefit the police's position.
They laid a rationality trap.
Neither suspect had much incentive to consider the costs his decision imposed on the other.
He didn't have to pay compensation for harm.
He didn't get paid for a benefit he conferred.
He didn't have to get the consent of his confederate and the whole thing.
They couldn't negotiate, communicate or have an enforceable agreement.
The police created incentives for the suspects so that they would both make individually
rational decisions to their collective detriment.
We're going to encounter prisoners' dilemmas in several different contexts.
Whenever our decisions are independent but are made individually, when we don't have
enforceable agreements, we can't require compensation.
Rational choices can lead to collectively harmful results.
Here's an example close to home.
My youngest son wrestled all through high school and college, and each week he was faced with
a difficult choice.
In order to wrestle, you must make weight.
And often wrestlers trying to seek an advantage will go to great lengths to cut weight, starving
themselves, putting on rubber suits and running around so they sweat off all kinds of water.
Some have even been known to have some of their blood withdrawn get weighed and have
the blood put back in just to get those last few ounces.
That can be damaging to their health.
And there have even been examples of wrestlers who died trying to cut weight with extreme
efforts for dehydration and other health difficulties, just so you can be bigger and stronger than
your opponent.
That's a smart strategy, perhaps, unless your opponent's doing the same thing.
And if he is, at match time, two 170-pound wrestlers, both of whom risked their health,
temporarily reduced their weight below 160, and they end up wrestling each other anyway.
If both of them could be sure that their opponent was not cutting weight, they could wrestle
each other without the risk to their health.
And neither one of them, making a rational individual choice, dared not to cut weight,
because they might end up then wrestling a 185-pounder who was able to squeeze his weight
down to 170.
They were caught in a difficult prisoner's dilemma.
And there's no easy solution to that.
Individually rational decisions were making both wrestlers worse off.
The only way this was ever solved was to change the underlying payoffs that came from cutting
weight.
And the wrestlers alone, like the suspects locked up in the police station, really had
no ability to do that themselves.
How that was finally solved was that following a series of deaths from cutting weight, the
governing sports organization came in and brought in some external authority and changed
the payoffs.
At the beginning of each season, they do a physical exam on wrestlers and give them
a minimum certified weight that said they may not legally wrestle below that weight.
There's no advantage to be gained by cutting below the minimum.
And only then were rational individual choices made consistent with mutually beneficial results.
Sometimes it takes a third party to make rational choices become efficient.
It's not just robbers and wrestlers who get trapped by this.
Not long ago, two of the major producers of canned soup got into an advertising war.
Each one was arguing about the healthful, good, natural qualities of its own ingredients
and making allegations about unhealthful, unorganic, perhaps dangerous additives in the
other's soup.
Well, once they'd begun down that path, they were both trapped.
They were in a prisoner's dilemma.
Because if one company voluntarily quit, the competitor's best option would be continue
the negative advertising and push it as far as they possibly could.
If the other company continues, the competitor has no choice but to continue as well in an
arms race of advertising charges.
So can you predict the outcome?
Both of them did continue.
The negative comparisons continued to be part of the ads.
And the net result?
The sales of all canned soup declined.
Businesses apparently came to distrust the whole product line.
And had those companies never started down the path, they would have had higher sales
and lower advertising budgets.
But once they were in, there was no clear way out.
They could not meet, perhaps, and agree to stop doing it without running a file of antitrust
laws.
And they did that.
There'd be a different kind of prison dilemma they might have to find.
They had trapped themselves.
So what can we learn from all of this?
Part of the takeaway points.
First and foremost, rational choices can lead all involved to better, more socially efficient
outcomes, but they don't have to.
And the failing comes most often when our decisions and the strategies we use are interdependent,
when my best strategy depends on your choice and your best strategy depends on mine.
But we do not need each other's consent before we make our choices.
If we cannot or do not communicate and negotiate, if enforceable agreements are not possible,
we may sometimes rationally choose paths that are going to harm us both.
Prisoners' dilemmas are everywhere.
We're going to encounter them again.
Fortunately, economic thinking, I think, may provide a way out of this.
In the next lecture, what we're going to do is we're going to take our analysis of the
prisoner's dilemma out onto the high seas.
And we're going to take a look at one of a very serious number of pressing environmental
problems of our time.
And we're going to see how it's economists who devised a solution to free some of these
prisoners.
And we'll take an opportunity to see how that solution is working out.
