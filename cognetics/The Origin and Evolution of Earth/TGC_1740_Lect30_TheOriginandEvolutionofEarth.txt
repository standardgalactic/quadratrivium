Oxygen is the most abundant element in Earth's crust and mantle, almost two of every three
atoms are oxygen, but it took life and the emergence of the amazing process of photosynthesis
to isolate oxygen into the molecule that we breathe.
As a direct consequence of photosynthesis, more than two billion years ago, Earth's solid
surface changed from a dull gray to brick red in a geological afternoon.
We are learning about this critical transformation in Earth and in life from fossils of many
kinds, impressions in rock, molecular remains, and isotopes.
Oxygen producing photosynthesis points to the growing influence of new kinds of algae
and the consequent rapid rise of an oxygen-rich atmosphere.
Many details of this epic transition called the Great Oxidation Event are uncertain and
still matters of intense debate.
Our best guesses regarding the timing of the Great Oxidation Event come from subtle changes
in the rock record, which reveal a rise in atmospheric oxygen shortly after Earth's two
billionth birthday, perhaps 2.45 billion years ago, and by 2.2 billion years, atmospheric
oxygen had for the first time risen to more than one percent of its modern level.
Today, oxygen makes up about one in five molecules of the air we breathe, about 20 percent.
So 2.2 billion years ago, there were perhaps two-tenths of a percent of oxygen, and that
was enough to forever change Earth's surface.
This fascinating story of how Earth became a planet with an oxygen-rich atmosphere has
only recently come into focus, and there's still a lot we don't know, but there is a
scientific consensus about many important aspects as more and more new lines of evidence
have emerged and new research directions have been tackled.
It hasn't been an easy road.
For the past 50 years of research in paleo atmospheres, it's seen a lot of competing
ideas, many times with scientists, coming to diametrically opposed conclusions.
It's not an easy topic, since the atmosphere is so ephemeral.
How do you tease out the composition of gas from billions of years ago?
But ultimately, the scientific method has a way of winnowing out the unsupportable theory
and the false assumption.
Of course, as with every aspect for early Earth, we don't have the whole story.
And we'll always have some uncertainty, but we're getting a lot closer to a well-supported
picture.
We might say that the emerging story is quite literally breathtaking.
All the evidence for the Great Oxidation Event is locked in old rocks and minerals
from around the globe.
Most critically, there's a growing catalog of observations that span a vast interval
of Earth's history from about 3.5 to 2 billion years ago.
We find, on the one hand, that many rocks older than 2.5 billion years contain distinctive
minerals that rapidly weather away in the modern environment, because of the corrosive
effects of oxygen.
Geologists find pristine, unweathered, and rounded pebbles of pyrite.
That's the common iron sulfide mineral, also known as fool's gold.
And there are also streambed pebbles of uranium dioxide, which is the commonest uranium mineral.
But one that doesn't survive long in modern streams.
These findings suggest there was an oxygen-free environment.
And those streams flowed 3 billion years ago.
Similar evidence comes from rocks that represent ancient soil layers.
These old surface deposits are preserved as sediments of silt.
And when they date from before 2.5 billion years, they often have telltale chemistry.
Now compared to modern soils, they're unusually concentrated in some elements like the rare
Earth element cerium, that's element 58.
In ancient soils, cerium has abundances comparable to other rare Earth elements.
But in modern-day soils, cerium can be anomalously abundant or absent, either way, due to the
presence of oxygen interacting with other factors.
Ancient soils are also strikingly deficient in other elements, most notably iron, but
also molybdenum, compared to today's soils.
These chemical differences affect a variety of elements that are sensitive to oxidation
reduction reactions, so they point to an atmosphere completely lacking in oxygen.
Rocks deposited at or near Earth's surface after about 2.5 billion years show a very
different chemical pattern that appears to point unambiguously to oxygen.
Most notable are the massive layer deposits of iron minerals called banded iron formations
or biffs.
You can recognize these dense rocks by their distinctive alternating black and rusty red
layers.
Those are versions of biffs roughly contemporary with the origins of life, but these new reddish
layerings were deposited in absolutely staggering abundance between about 2.5 and 1.8 billion
years ago.
In fact, biffs hold 90% of all the world's known iron ore reserves and their mind in
gigantic open pits in several countries.
They're also immense deposits of manganese oxides at about that same time.
Biffs suddenly appear in the geological record as thick layers of sediments that supply most
of the world's manganese ores, and we'll soon see that many hundreds of other new minerals
appeared for the first time after the atmosphere became oxygen rich.
Their colorful minerals of copper, nickel, molybdenum, cobalt, mercury, uranium, many
other elements also appear for the very, very first time in Earth's history after the Great
Oxidation Event.
That diversification of the mineral kingdom was just one more manifestation of the Great
Oxidation Event.
Of course, all these signs are subtle.
You can't just look at a rock and see that it's older or younger than 2.5 billion years.
You can't see the trace elements or the isotopes.
What's more, the rock record is incomplete, and it can become altered in ways that are
confusing and misleading.
Nevertheless, new evidence kept building for a major transition in Earth's atmosphere
more than 2 billion years ago.
What many of us see is the smoking gun for the Great Oxidation Event came early in this
century from isotopes.
In fact, it was an unexpected source that's deeply buried in data on the isotopes of the
very common element, sulfur.
Let me set the stage for this important discovery.
Mass spectrometers are the essential analytical instruments for measuring isotopes.
The 1990s saw significant improvements in the resolving power and the detection limits
of mass spectrometers that could handle ever smaller samples.
That was when it became possible to measure isotopes in individual zircon grains, or even
in individual living cells.
These new mass spectrometers could be tuned to any chemical element of the periodic table
from hydrogen all the way to uranium.
Sulfur is one of a handful of life's essential elements, and it proved to be a particularly
interesting research priority.
It turns out that there are four different stable isotopes of sulfur in nature.
Sulfur 32, 33, 34, and 36.
All of these isotopes have 16 protons in their nucleus.
That's the definition of sulfur, and atom with 16 protons.
But the number of neutrons in these four isotopes varies from 16 in sulfur 32 to 20 neutrons
in sulfur 36.
Like all the elements, the distribution of sulfur isotopes is for the most part predictable
based on the relative masses of the isotopes.
The less massive isotopes vibrate more because of Newton's second law of motion.
Force equals mass times acceleration.
Sulfur energy applies a more or less equivalent force to all the sulfur atoms in a system,
so more massive sulfur isotopes vibrate less.
That means that in any chemical reaction, the less massive isotopes are more likely
to move than the more massive ones.
The result is that the reactants typically wind up with a ratio of sulfur isotopes that's
different from the products.
This process of refining the ratios of isotopes is called isotope fractionation, and it occurs
any time sulfur atoms undergo a chemical reaction.
And that's true whether the sulfur is in a rock or in a living cell.
The case of sulfur isotopes is typical.
Less massive sulfur 32 typically fractionates more than more massive sulfur 34, which fractionates
more than sulfur 36, and ratios of these fractionation effects are usually directly proportional
to the mass ratios of the isotopes.
That means the fractionation of sulfur 36 and sulfur 32, which differ by four atomic mass units,
is almost always twice the fractionation of sulfur 34 and sulfur 32, which differ by
only two mass units.
This is the basic physics that follows from Newton's second law.
Smaller mass means a bigger acceleration.
So under a given force, the sulfur 32 isotope vibrates more than sulfur 34, which vibrates
more than sulfur 36.
But there's something else going on with sulfur isotopes.
That was a discovery made in the late 1990s by geochemist James Farquhar.
Farquhar is now at the University of Maryland, but at the time he was working at the Scenic
Oceanside campus at the University of California at San Diego.
What he found was a profound and unexpected change in the fractionation of sulfur isotopes
that occurred about 2.4 billion years ago.
It turns out that virtually all rocks and minerals younger than 2.4 billion years display
almost precisely the mass-dependent trend that we all would have expected.
The ratios of sulfur isotopes 32, 33, 34, and 36 depend almost exclusively on the ratios
of their masses.
But Farquhar and colleagues found a very different fractionation pattern for sulfur isotopes
in many minerals and rocks that are older than 2.4 billion years.
In some samples, there are wild deviations of several tenths of a percent, and that's
a lot for isotopes.
These samples seem to violate Newton's law.
So Farquhar and his co-workers asked, what could cause this mass-independent deviation?
Well, the answer lies in quantum mechanics.
Theoretical models and clever experiments show that isotope behaviors can deviate from
Newtonian behavior when molecules are exposed to ultraviolet radiation.
Turns out that isotopes with odd mass numbers, like sulfur 33, can be selectively altered
by ultraviolet radiation.
So if a molecule of sulfur dioxide or hydrogen sulfide happens to hold a sulfur 33 isotope,
then if that molecule is in the atmosphere where it absorbs an ultraviolet ray, then
it reacts more readily.
That process selectively changes the isotope ratios.
Sulfur 33 experiences a mass-independent fractionation, and that fractionation skews the isotope ratios.
Farquhar was able to explain why there's a mass-independent isotope effect.
But what was the sudden change on Earth 2.4 billion years ago that turned off this effect?
The answer is a change in that ultraviolet radiation that affected the atmosphere.
The rise of oxygen led to the production of a new atmospheric molecule called ozone, which
is a molecule made of three oxygen atoms.
Ozone has been in the news a lot in the past few decades because it effectively absorbs
ultraviolet radiation.
This is Earth's natural sunblock.
Today a trace amount of ozone high in the atmosphere provides an essential barrier to
the sun's potentially lethal ultraviolet rays.
Basically, the way it works is high in the stratosphere, UV rays break up O2 molecules
into two single atoms of oxygen.
The single atoms bond with other O2 molecules to form O3, which is ozone.
Ozone then absorbs ultraviolet rays and breaks back down into O2 and an atom of oxygen.
It's kind of a cycle.
Careful measurements taken over the past 25 years or so reveal that this so-called ozone
layer has been significantly depleted, most likely because human-produced chemicals called
chlorofluorocarbons or CFCs and other chemicals such as carbon tetrachloride that can attack
ozone and for decades after they're released.
Massive ozone could lead to a rise in skin cancers among humans and a variety of ecological
stresses around the world.
It's good news that a worldwide ban on CFC production has apparently led to a reversal
of the previous trend and some restoration of the ozone layer, which was first created
2.4 billion years ago before the rise of photosynthesis and atmospheric oxygen.
All those sulfur compounds high in the atmosphere were subjected to intense ultraviolet radiation.
Compounds with sulfur-33 underwent mass-independent fractionation, and that process is reflected
in rocks and minerals of the Archean eon.
But after the great oxidation event, a protective ozone layer formed and that layer acted to
absorb the sun's UV radiation.
That's why the odd isotope effect was effectively shut down after 2.4 billion years ago.
There had been a lot of geological and geochemical evidence pointing to the great oxidation event
before James Farquhar's findings.
But as many labs around the world confirmed and expanded on Farquhar's discovery, the
great majority of earth scientists rather quickly accepted the reality of the great oxidation
event.
And this rapid change in thinking exemplifies the way scientific ideas often reach a tipping
point when one or more set of compelling data swings the majority to a new point of view.
And unless scientists come up with some way other than ozone to block the sun's ultraviolet
rays, the sulfur isotope data have established the beginning of the great oxidation event
at about 2.4 billion years.
There's now ample evidence that earth's atmosphere contained a small but significant amount of
molecular oxygen by 2.4 billion years ago.
But where exactly did that oxygen come from?
It's now common knowledge that plants and other organisms make oxygen by the remarkable
process of photosynthesis.
Photosynthetic cells combine water, carbon dioxide, and sunlight to make the energy-rich
molecule glucose, from which serves both to form plant tissues and to power other biochemical
processes.
This chemical reaction is easy to write.
You take six molecules of carbon dioxide, six molecules of water, and add energy, sunlight.
You make a molecule of glucose and a byproduct of six molecules of oxygen.
One consequence of this reaction is therefore the production of oxygen in the atmosphere.
So familiar is this chemical reaction that we now just take it for granted that plants
play a central role in making our world a habitable place.
The photosynthesis is not an obvious process.
And the discovery of how photosynthesis works was one of the greatest advances in the history
of science.
And this history, like so many of science's key advances, was made sequentially in piecemeal
fashion.
The first breakthrough was the discovery of water's critical role in the 17th century.
It had long been assumed that the woody tissues of plants must come from mineral-rich soil.
So it was thought that soils must be consumed as plants grow.
This assumption was tested in a simple experiment by Flemish physician John Baptiste Van Helmont,
who lived from 1577 to 1644.
Using 200 pounds of earth that had been dried in a furnace, he planted a five-pound willow
tree.
Now, five years later, after regular watering, his tree weighed 169 pounds.
While the soil, suitably dried, weighed only two ounces less than when he started.
This conclusion, therefore, 164 pounds of wood, barks, and roots arose out of water only.
So Van Helmont realized that soil is not consumed in any great quantity as plants grow.
This discovery was a major advance.
The water is not the entire story in photosynthesis.
Fast forward 100 years when English clergyman and naturalist Stephen Hales proposed that
plants must rely on some component of the atmosphere as well as water.
We now know that that component is the trace gas carbon dioxide, which combines with water
to make the sugar glucose.
And it's ironic that it was Van Helmont himself a century before who had discovered carbon
dioxide gas in combustion and fermentation.
But he didn't recognize CO2's central role in plant growth.
By the mid-18th century, scientists knew that water and carbon dioxide were the raw materials
of plants.
Yet the critical role of sunlight in the process remained uncertain.
Indeed, it took another 200 years for all the details of photosynthesis to emerge.
And surprisingly, it was advances in nuclear physics that paved the way.
A new kind of particle accelerator called a cyclotron was used to produce the first reliable
supply of the highly radioactive isotope carbon-11, which provided a very effective probe of biological
reactions.
It was in the turbulent late 1930s that Berkeley scientists Samuel Rubin and Martin Cayman
fed plants with carbon dioxide that had been spiked with radioactive carbon-11.
Rubin and Cayman used the radioactivity to trace carbon dioxide as an entered plant tissue.
Now, carbon-11 has a half-life of only 21 minutes.
So these experiments had to be done quickly and they weren't easy.
But a real breakthrough came with Rubin and Cayman's discovery in 1940 of a way to make
carbon-14, which is the famous radioactive isotope with a much longer half-life of 5,730
years.
Creation of carbon-14 in the lab helped to revolutionize biophysics because researchers
could follow the paths of radioactive carbon atoms, molecule by molecule, as plants made
their tissues.
For the first time, biologists could understand how plants use water, carbon dioxide, and
sunlight to make sugar.
At its most basic level, the photosynthesis reaction that algae have been engaged in for
almost 3 billion years begins with the consumption of 6 carbon dioxide molecules plus 6 carbon-11
water molecules to make one glucose-sugar molecule.
Six oxygen molecules are also produced as a byproduct.
Here we see yet another example of a redox reaction, analogous to a burning fire or
rusting iron.
Here electrons are transferred to carbon atoms in carbon dioxide.
Those atoms are thus reduced.
At the same time, oxygen atoms in water and carbon dioxide donate electrons, so oxygen
atoms are oxidized.
The energy for this electron shuffle comes from sunlight.
In its bare bones form, this chemical reaction is very straightforward, carbon dioxide plus
water combined to make sugar.
Yet the details of photosynthesis turn out to be extremely complex, and some of the steps
are still being studied.
For instance, photosynthesis relies on a very ancient, but complicated protein nicknamed
rubisco that plays the central role in concentrating the raw materials, carbon dioxide, and water,
and absorbing the sun's energy.
It also turns out that there are quite a few variants of photosynthesis.
Different microbes harvest sunlight using slightly different chemical pathways.
We're most familiar with oxygen-producing plants and algae, which typically use the
bright green pigment chlorophyll.
Chlorophyll looks green because red and violent wavelengths of light are absorbed.
Plants have to be black to absorb all the different wavelengths of light.
Other kinds of cells use different light wavelengths, and several variants of photosynthesis produce
no oxygen at all.
There are alternate light-absorbing pigments that result in distinctive red and brown algae,
as well as purple bacteria, and strikingly colored diatoms that produce no oxygen at
all.
Light-absorbing pigments that result in distinctive red and brown algae, as well as purple bacteria,
and strikingly colored diatoms and lichens in a wide range of colors.
There are even some microbes that use infrared radiation in their photosynthetic reactions.
Those are wavelengths longer than visible light spectrum, so they're invisible to our
eyes, but our skin can sense infrared radiation as heat energy.
In any scientist study, the nature and origins of photosynthesis, I've been especially impressed
with the pioneering studies of Robert Blankenship, who is a biochemist at Washington University
in St. Louis, and who also has a team of collaborators at Arizona State University.
In fact, his work is so interdisciplinary that he is a member of both the chemistry
and the biology departments at Washington University.
Blankenship's research involves looking in detail at different photosynthetic pathways
for several different kinds of photosynthetic microbes, including groups that are colored
purple, brown, yellow, and green.
What he finds is that all of these organisms share some characteristics, but they also
display important differences.
The photosynthetic apparatus is intricate and consists of several components.
For example, photosynthetic cells feature varied colored pigments that absorb light energy,
and there are varied molecular sequences for the protein reaction centers where electrons
shift from one molecule to another.
There are even a host of different antenna systems, because cells have evolved clusters
of elongated molecules that behave just like tiny light-collecting antennas.
What Blankenship finds is that life exploits a variety of photosynthetic strategies.
It's clear now that photosynthesis didn't just evolve once, but at least five different
times going back billions of years into Earth history.
Historical details are murky, but Blankenship's best estimate is that the most ancient and
primitive light-collecting chemical reactions probably date back more than three and a half
billion years.
Those earliest forms of photosynthesis didn't produce oxygen at all.
Some ancestors of those early kinds of cells still survive today, and they reveal that
these most deeply rooted photosynthetic microbes live without oxygen.
Indeed, most of these primitive microbes don't even tolerate oxygen.
Perhaps the most important discovery is the tendency of microbes to shuffle and swap their
light-collecting genes.
For microbes, this form of lateral or horizontal gene transfer turns out to be an important
mechanism of adaptation and evolution.
In the distant past, some single-celled organisms borrowed photosynthetic pathways from other
cells in this way.
Today, the oxygen-producing kind of photosynthesis that's used by almost all plants appears to
be a coupling of two primitive chemical reaction pathways identified in the early 1960s and
called Photosystem 1 and Photosystem 2.
The two systems differ in many details, but each houses a few dozen chlorophyll molecules
bound to proteins in a core complex, plus pigments in the so-called reaction complex.
In most plants, the combination of these two pathways provides an extra energy boost.
That's how today's plants exploit sunlight far more efficiently than did those earlier
forms of photosynthesis.
Even before photosynthesis, and even if photosynthesis had never gotten started on our planet, there
were still non-biological ways by which Earth's surface would have inevitably produced a very
modest amount of atmospheric oxygen.
Here's how that works.
High up in the atmosphere, molecules of water are subjected to breakdown by the destructive
power of ultraviolet radiation and cosmic rays.
Individual water molecules are split apart into fragments that ultimately make hydrogen
and oxygen atoms.
The hydrogen molecules are such low mass, they're so light, and they move so fast that
some of them simply evaporate into space.
They just fly off and leave Earth.
Oxygen, both in the usual molecule O2 that we breathe and in ozone, which is the molecule
with three oxygen atoms, are a lot more massive, so oxygen can't easily escape Earth's gravity.
That means that over long time periods, as hydrogen escapes, oxygen builds up slightly
in the atmosphere.
This process of hydrogen loss continues today.
It's estimated that an amount of hydrogen equivalent to all the hydrogen atoms in a
few Olympic-sized swimming pools escapes to space every year.
The exact same process occurs on the much smaller planet, Mars, with a lot less gravity
to retain hydrogen.
Mars had lost much of its water a long time ago, and as Mars' hydrogen escaped to space
over 4.5 billion years, iron minerals near the surface oxidized to the familiar rusty
red color.
And that's a key point.
Almost as fast as oxygen was produced and released to the Martian atmosphere, it was
locked away into near-surface rocks.
This process of oxygen production through hydrogen loss can't have had much of an effect
on Earth's environment before the rise of life.
Even if we take the most extreme estimates, there's probably less than one atmospheric
oxygen molecule in a trillion prior to the Great Oxidation Event.
By contrast today, it's one in five molecules of the atmosphere.
And that minute quantity of archaean oxygen was consumed just as fast as it was generated
at Earth's surface by immense quantities of iron atoms in the soils and in the oceans.
Those atoms were available to donate electrons, to transfer them to make iron oxides.
So it seems likely that even if photosynthesis never had evolved, Earth would eventually
have looked like Mars with a reddish weathered surface on all the older continents.
But that reddish coating was just an external feature.
It only affected the outer soil and rock layers.
Even a fraction of an inch below Earth's solid surface, there wasn't a trace of molecular
oxygen.
And it's very likely that life itself contributed a small amount of oxygen even before the evolution
of photosynthesis.
It turns out that living cells have learned at least four different ways to make oxygen
from their surroundings, in addition to photosynthesis.
Of course, oxygen and photosynthesis is the huge process they are dwarfs all of the ways
to make oxygen.
But these other biochemical pathways may very well have resulted in oxygen production for
the past three plus billion years.
It's a recurrent theme in biology.
Life is remarkable in its ability to scavenge energy from its environment any way it can.
Life uses heat energy from volcanoes.
It uses chemical energy of rocks.
It uses sunlight.
It even uses radioactivity in some special deep subsurface ecosystems.
By far the easiest way to obtain energy while liberating oxygen is to start with a reactive
molecule that's already oxygen rich.
So microbes have learned to exploit hydrogen peroxide, or H2O2, which is produced in small
quantities high in the atmosphere.
It's certainly true.
There wouldn't have been much hydrogen peroxide before the rise of atmospheric oxygen.
It's a trace chemical in any conceivable Earth scenario.
And consequently, nonphotosynthetic microbes can't have played any significant role in
modifying Earth's early environment.
And there are other chemical approaches to making oxygen as well.
A team of Dutch microbiologists recently reported what was perhaps a more significant oxygen
producing scenario through most of Earth's history.
They reported on some microbes that obtained energy by decomposing the oxides of nitrogen,
which can be produced by lightning and by burning fossil fuels with small amounts of nitrogen.
Early in Earth's history, these so-called NOx or NOx chemicals were produced in small
amounts through reactions with nitrogen gas with minerals.
Today even more NOx compounds are generated because of the widespread use of nitrogen-rich
fertilizers that run off into lakes, rivers, and estuaries.
Large microbial blooms include contributions from cells that are able to decompose nitrogen
oxides into nitrogen plus oxygen.
Then those clever cells use the newly formed oxygen in reactions with methane, which is
also available in the environment.
And those oxidation reactions provide life's energy source.
Of course, all of these investigations of modern living cells and their biochemical processes
must be supplemented by studies of ancient fossil organisms, including fossils of the
earliest oxygen-producing life.
And those studies represent some of the most revealing and at times dangerous research
in our quest to understand the story of Earth.
