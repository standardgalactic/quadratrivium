This course is all about history, and embedded in any historical discussion is the dimension
of time.
In the first few lectures, we've touched on the origins of the universe approximately 13.7
billion years ago, and some of the events that occurred in the subsequent billions of years.
In the upcoming lectures, we'll explore the richly layered lines of evidence for how the sun,
earth, and the rest of our solar system were born more than four and a half billion years ago.
Such chronologies are nothing new. Americans love to quote the dates of famous events in human
history. We celebrate great accomplishments and discoveries, such as the Wright Brothers'
first flight on December 17, 1903, and the first manned moon landing on July 20, 1969.
And we remember birthdays, July 4, 1776, and of course February 12,
1809, the coincident birthdays of Charles Darwin and Abraham Lincoln.
We trust the validity of these historic moments because of the unbroken, written,
and oral record that links us to the not so distant past.
Well, geologists also love to quote historic dates, at least informed estimates of historic
events. They tell of times about 12,500 years ago, when the last great glaciation ended and humans
began to settle North America. 65 and a half million years ago, when the dinosaurs and many
other creatures became extinct, and a much more catastrophic extinction about 251 million years
ago. We talk about the Cambrian boundary at 542 million years ago, when diverse animals with
hard shells suddenly appeared, and 4.567 billion years ago, when the sun and earth began to form
from a vast cloud of dust and gas. But how can we be sure of those age estimates? There's no
written record past a few thousand years, nor is there any oral tradition that can inform estimates
of Earth's ancient chronology. One difficulty in comprehending geologic history is the immense
time spans involved. Four and a half billion of anything is a lot. It's difficult for anyone
to conceive of such an immense time span as 4.5 billion years. The oldest humans, the current
record, according to Guinness, is held by a French woman who lived to celebrate her 122nd
birthday, but that falls far short of living even 4.5 billion seconds, which is a span of about 144
years. All of recorded human history is much less than 4.5 billion minutes long, and yet
geologists claim that Earth has been around for more than four and a half billion years. That's
half a million times longer than us humans. There's simply no easy way to comprehend deep time.
But I sometimes try by taking long walks. A few minutes south of Annapolis, Maryland,
the western shore of the Chesapeake Bay is flanked by 20 miles of undulating fossil packed cliffs.
Walking along the narrow strip of sand between land and water, one can find an abundance of
extinct striated clams and ornately spiral shells. You find branching corals,
symmetrical sand dollars, and once in a while on a very lucky day, you might find a six inch
serrated shark's tooth or maybe a six foot streamlined whale skull. These are prized relics,
and they tell of a time 15 million years ago when the region was warmer, more tropical,
like today's Maui where majestic whales came to cav and monsters 60 foot sharks feasted on the week.
The 300 vertical feet of sediments, they were laid down over a three million year
period of Earth history, and they form the cliffs. There are two dozen distinctive layers of sand
in Marl, and they dip ever so gently to the south. So walking along the beach is like a stroll through
time. Each stride to the north exposes slightly older layers.
To get a sense of the scale of Earth history, imagine walking back in time 100 years per step
every pace a time span equal to more than three human generations. A mile, it takes you 175,000
years into the past. The 20 miles of Chesapeake cliffs, and that's a hard day's walk to be sure,
it corresponds to more than three million years. But to make even a small dent in Earth history,
you must keep walking at that rate for many, many weeks.
20 days of effort, 400 miles or 20 miles a day at 100 years per step, that takes you back
70 million years, just before the mass death of the dinosaurs.
Five months of 20 mile walks corresponds to almost 540 million years,
the time of the Cambrian explosion, that's the near simultaneous emergence of myriad hard
shells amateurs, animals. But at 100 years per footstep, you'd have to walk for almost
three years to reach the dawn of life, and almost four years to arrive at Earth's beginning.
So at one level, numbers like millions and billions are extremely difficult to comprehend.
Nevertheless, Earth scientists have developed numerous independent yet consistent lines of
evidence that point to an incredibly old Earth, because rocks reveal their ages of formation in
several ways. Rocks and minerals provide Earth scientists with their most reliable clocks.
I want to spend some time describing just three of these many approaches.
First, annual layerings can give very accurate age measurements up to perhaps a million years.
Then estimates of much longer time spans based on the rates of ongoing geological processes,
and finally, our most accurate and reliable method for determining the timing events,
all the way back to four and a half billion years, that's isotopic age determinations or
radiometric dating. When properly applied, all three of these approaches yield identical estimates
of geological events. Now, the most straightforward and unambiguous geological
timekeepers are rock formations with annual layers. Annual tree rings provide a familiar analog.
I'm sure you've seen a cut tree stump and counted up the rings and cross section.
Each year, a tree's life is marked by a distinctive ring with lighter and darker zones.
These color changes result as growth increases in spring and slows the following winter.
Based on counting tree rings, the oldest trees on Earth are a few thousand years old,
but tree ring dating, or dendrochronology, has been pushed back 26,000 years by comparing living
trees with buried logs of increasing age. Sedimentary rocks, too, can display annual
layerings or varves that result from seasonal differences in sediment deposition.
The most dramatic varve deposits, such as a meticulously documented 13,527-year sequence
in Glacier Lakes in Sweden, those occur as thin alternating light and dark layers,
representing coarser grain spring sediments and finer winter sediments, respectively.
Ancient varve deposits sometimes reserve much longer time spans. The finely laminated
Green River shale in Wyoming features continuous vertical sections half a mile in thickness with
six million such layers. That implies that deposition continued for six million years in
the shallow lakes that hosted the Green River sediments. Some of the oldest continuous annual
layerings are extracted from ice cores, where laminate arrives from seasonal variations in
snowfall. One 2,000-meter-long ice core from east Antarctica reveals 160,000 annual layers of
accumulation, year by year, snow layer by snow layer. And those annual layers rest atop another
2,000 meters of ice, which in turn sits on vastly older rocks. Similar ages of ice cores
comprise Greenland's thick glacial deposits. The obvious conclusion is that at least a million
years is needed to account for many surficial deposits of sediments and ice. So Earth must
be much older. But how old? Slow inexorable changes of Earth's dynamic surface provide
a vivid, if rather approximate, measure of deep time. So let's consider three simple
back-of-the-envelope calculations. First, how old is the big island of Hawaii?
The massive Hawaiian islands rose from the Pacific as volcanoes periodically added layer
upon layer of lava. And for modern-day eruptions, we know that the most active Hawaiian volcanoes
grow by perhaps one meter every century. The highest point on the big island of Hawaii is
Manakea at 4,205 meters above sea level. However, the volcano rises approximately 10,200 meters
above the ocean floor. And that's a closer estimate of the true height. So we can do a
rough calculation to estimate its age. All we need to do is multiply the rate of growth
in years per meter. That's about 100 years per meter times the total height in meters,
which is about 10,200 meters. The result is roughly 1.02 million years. And that figure
makes a lot of sense. This is a rough estimate to be sure, but it jives well with other methods
that date the big island of Hawaii as about a million years old. The other islands that string
out to the northwest, each with now dormant volcanoes, are progressively older. And a new
island dubbed Loihi is already forming as volcanoes erupt on the ocean floor southeast of the big
island. Now you can do a similar calculation to date the age of the Atlantic Ocean, which is about
3,700 kilometers wide and grows wider every year. The near perfect fit of the east coast of South
America, where the west coast of Africa provide key evidence for plate tectonics, which is the
revolutionary idea that Earth's crust is broken into about a dozen thin brittle plates. These
plates shift positions in response to convection and Earth's deep interior. Now according to current
thinking, the continents of Africa and South America were once joined into the supercontinent
Pangea. The Atlantic Ocean formed when Pangea split down the middle and formed a divergent
plate boundary, what is now marked by the mid-Atlantic ridge. New crust forms along the
ridge as Europe and Africa move away from the Americas. So according to this model, the Atlantic
Ocean is still getting wider. Indeed, exacting satellite measurements that use laser distance
measurements have been conducted over the past two decades, and they reveal an average spreading
rate of about 2.5 centimeters per year. If you assume that the spreading rate of the Atlantic
has been more or less constant over its history, we can do a rough estimation of the age of the
Atlantic. Here, we need to divide the entire width of the Atlantic Ocean, that's about 3,700
kilometers or 370 million centimeters by that annual spreading rate of 2.5 centimeters per year.
That gives an age for the Atlantic Ocean of about 150 million years, and this rough estimate is
rather close to other measurements of the age of the Atlantic based on much more exacting methods.
Now, 150 million years is admittedly a pretty long time, but it's absolutely trivial
in the context of Earth's history. It's only about 3% of Earth's 4.5 billion year lifetime.
It's remarkable to imagine that a great ocean, a seemingly permanent feature of our home planet,
is so transient in the context of Earth's history. And here's a third simple calculation. It reveals
even longer time spans. The Appalachian Mountains are now gently rounded and relatively low,
mostly below 3,000 meters high. But geological evidence reveals that they were once the grandest
mountain chain on Earth, rivaling the Himalayas in ruggedness and height with some peaks approaching
10,000 meters. Ever so gradually, erosion has worn the Appalachians down to their present state.
But how long might that process take? For the sake of a very rough estimate, consider a mountain as
a rectangular block about 5 kilometers high, 4 kilometers long, 4 kilometers wide. That's about
2.5 miles on the side. And I realize that's a pretty wild way to describe a mountain, but
it's adequate for our crude estimation. The volume of this impressive mountain is
thus the product of the length, time the width, time the height, or 5 times 4 times 4 kilometers.
That's 80 cubic kilometers. And you can easily convert cubic kilometers into cubic meters,
because 1 cubic kilometer is about a billion cubic meters. So to erode away a typical mountain,
you have to remove about 80 billion cubic meters of rock. Now imagine a stream that flows down the
side of this mountain. Mountain streams carry silt and sand downward, a key factor in erosion.
You probably also find coarse gravel and even a few boulders in this stream,
the results of occasional flash floods that follow heavy rains.
All of these sediments came from higher up the mountain, which is constantly being eroded away.
To estimate how long a mountain might survive against erosion, consider a mountain with six
principal streams. A typical stream might carry an average of one tenth of a cubic meter of rock
in soil. That's a few shovels full every day off the mountain, though that actual amount would
vary considerably from day to day. Over a period of a year, the six streams might thus remove a
quantity equal to six streams times a tenth of a cubic meter per day times 365 days per year.
And you multiply that out, you get an estimated erosion rate, a very rough erosion rate to be
sure, on the order of 220 cubic meters of material per year. That translates to about 20 dump trucks
full of rock and soil that might be removed from a mountain by normal stream erosion every year.
If the mountain streams remove about 220 cubic meters per year, then the lifetime in the mountain
can be estimated as the total volume of the mountain, that's 80 billion cubic meters,
divided by the volume lost each year, 220 cubic meters per year. And the answer is 364 million years.
Okay, I admit it, this estimate is very rough. It involves a lot of what I hope are reasonable
assumptions, but it's not directly applicable to any specific mountain. Nevertheless,
the lesson is clear, even the grandest mountains can't last more than a few hundred million years.
So we've seen from back in the envelope calculations that great geological processes like
growing volcanoes, opening oceans, eroding mountains can take up to several hundred million years.
Nevertheless, a few hundred million years is but a small fraction of a few billion years.
How can we possibly say that Earth is 4.56 billion years old?
It's the physical process of radioactive decay that's provided earth scientists with their most
important method for determining the absolute age of rocks and minerals. This remarkable
technique, which depends on measurements of the distinctive properties of radioactive materials,
is called radioisotope geochronology, or simply radiometric dating.
Trace amounts of isotopes of radioactive elements including carbon-14, uranium-238,
and dozens of others are all around us. They're in rocks, they're in water, they're in the air.
These isotopes are unstable, so they gradually break apart or decay.
Radiometric dating works because radioactive elements decay in a predictable fashion like
the regular ticking of a clock, and here's how it works. If you have a collection of one million
atoms of a radioactive isotope, half of them will decay over a span of time called the half-life.
Uranium-238, for example, has a half-life of 4.468 billion years, so if you start with a million
atoms and come back in 4.468 billion years, you'll find only about 500,000 atoms of uranium-238
remaining. The rest of the uranium will have decayed to 500,000 atoms of other elements,
ultimately to stable, that is, non-radioactive atoms of lead 206. If you weighed another 4.468
billion years, you only have a quarter of a million atoms of uranium that are going to remain.
Radioactive isotopes come with a wide range of half-lives, from a tiny fraction of a second
to many billions of years. Isotopes with very short half-lives aren't very useful in dating rocks,
but they can make the nightly news, of course. Radon-222, with a half-life of 3.8 days,
is a good example because it can concentrate in the basement of houses and cause health concerns.
You may have had a radon test conducted if you ever bought or sold a home.
Now, the best-known radiometric dating method involves the isotope carbon-14,
with a half-life of 5,730 years. Every living organism takes in carbon during its lifetime.
At this moment, your body is taking the carbon in your food and converting it to tissue,
and the same is true of all other animals. And plants, they're taking in carbon dioxide from
the air and turning it into roots and stems and leaves. Most of this carbon, about 99%,
is in the form of stable, non-radioactive carbon-12. And about 1% is the slightly heavier,
stable carbon-13. But a certain small percentage of the carbon in your body and every other living
thing, no more than about one carbon atom in every trillion, is in the form of radioactive carbon-14.
That's because carbon-14 is constantly being produced high in the atmosphere,
when cosmic rays interact with the common nitrogen-14. Those nuclear interactions convert
a tiny fraction of nitrogen-14 to carbon-14, which then starts to decay back to nitrogen-14.
Now, as long as an organism is alive, the carbon-14 in its tissues is constantly renewed
in the same small part per trillion proportion that's found in the general environment.
All the isotopes of carbon behave the same way chemically,
so the proportions of carbon isotopes in the living tissue will be nearly the same everywhere
for all living things. When an organism dies, however, it stops taking in any carbon of any form.
From the time of death, therefore, the carbon-14 in the tissues is no longer replenished.
And here we have the secret. Like a ticking clock, carbon-14 atoms transmute by radioactive decay
to nitrogen-14 atom by atom to form an ever smaller percentage of the total carbon.
Scientists can thus determine the approximate age of a piece of wood or hair or bone or other
object by carefully measuring the fraction of carbon-14 that remains and comparing it to the
amount of carbon-14 that we assume was in that material when it was alive.
If the material happens to be a piece of wood taken out of an Egyptian tomb, for example,
we have a pretty good estimate of how old the artifact is and, by inference,
when that tomb was built. What's more, scientists have conducted meticulous year-by-year comparisons
of carbon-14 dates with those of tree ring chronologies. And the result, those two independent
techniques yield exactly the same dates for ancient fossil wood.
Carbon-14 dating often appears in the news in reports of ancient human artifacts.
And I remember a highly publicized discovery in 1991. There was an ancient hunter was found in
frozen ice in the Italian Alps. Otsi the Iceman, as he was called, was shown by carbon-14 techniques
to date from about 5,300 years ago. The technique provided similar age determinations for tissues
of the Iceman, his clothing, his implements, and carbon-14 has been absolutely fundamental,
instrumental in mapping human history over the last several tens of thousands of years.
But there is a catch. When an object is more than about 50,000 years old, the amount of carbon-14
left in it is so small that this dating method can't be used. To date, rocks and minerals that
are millions of years or billions of years old, scientists have to rely on similar techniques
that use radioactive isotopes of much greater half-life. Among the most widely used radiometric
clocks in geology are those based on the decay of potassium-40, the half-life of 1.248 billion years,
and then there's uranium-238 with a half-life of 4.468 billion years, and rubidium-87
with a half-life of about 48 billion years. In these cases, geologists measure the total
number of atoms of the radioactive parent, and the stable daughter elements to determine how
many radioactive nuclei were present at the beginning. Thus, for example, if a rock originally
formed a long time ago with a small amount of uranium atoms, but no lead atoms, then the
ratio of uranium to lead atoms today can provide an accurate geologic stopwatch.
When you see geologic age estimates reported in scientific publications or in the news,
the chances are those values are derived from radiometric dating techniques. In the case of
the early settlement of North America, for example, carbon-rich camfire remains in associated
artifacts point to a human presence by about 13,000 years ago. Much older events in the history
of life, some stretching back billions of years, are often based on potassium-40 dating. This
technique works well because fossils are almost always preserved in layers of sediment, which
also record periodic volcanic ash falls as thin horizons of tiny glass shards and other distinctive
particles. Volcanic ash is rich in potassium-bearing minerals, so each ash fall provides a unique
time marker in the sedimentary sequence. So, the rise of humans about 2.5 million years ago,
the extinction of the dinosaurs at 65.5 million years ago, the appearance of animals with hard
shells starting about 540 million years ago, and other key transitions in life on earth are usually
dated in this way. The oldest known rocks, including basalt and other igneous formations, solidified
from incandescent red hot melts. These durable samples from the moon and from meteorites are
typically poor in potassium, but fortunately they incorporate small amounts of uranium-238 and
other radioactive isotopes. As soon as these molten rocks cool and harden, their radioactive elements
are locked into place and begin to decay. The most ancient of these samples are several types
of meteorites, in which slightly more than half of the original uranium has decayed to lead.
These primordial space rocks, the leftovers from the formation of earth and other planets,
yield a maximum age of about 4.567 billion years for the nascent solar system.
The oldest known moon rocks at about 4.46 billion years also record these earliest
formative events. Earth must have formed at about the same time, but our restless
planet's surface has now eroded away. Only a few uranium-rich, sand-sized grains of the
hardy mineral Zircon, some as old as 4.4 billion years, survive. Nevertheless,
uranium-bearing rocks on every continent provide a detailed chronology of the early earth.
The oldest earth rocks at about 4 billion years point to the early origins of continents.
Rocks from almost 3.5 billion years ago host the oldest unambiguous fossils, primitive microbes
and dome-like structures called stromatolites, which form their rocky homes. Distinctive uranium-rich
sedimentary formations and layered deposits of iron oxides from about 2.5 to 2 billion years
document the gradual rise of atmosphere and oxygen through photosynthesis. Indeed,
every stage of earth's history has been dated with exquisite accuracy and precision thanks
to radiometric techniques. Many lines of observational evidence point to the immense
antiquity of earth. We've seen how geologists employ annual layerings of rocks, gradual changes of
earth surface, and the inexorable decay of radioactive elements to confirm the vastness
of geologic time. And more than a dozen other techniques also provide reliable age determinations.
For example, there's fission track dating, which is another radiometric technique that's based on
gradual accumulation of radiation damage from the decay of uranium-238. In many minerals,
these radioactive decay events can be preserved as tiny streaks of damage. They look like little
rays of light spreading out in mineral grains that concentrate uranium, and these streaks
accumulate. You can determine the track density by polishing the mineral grains,
and that density is a measure of age. The trick is that the damage is often healed at higher
temperatures, so fission track methods can reveal the time it took for a rock to cool,
or whether it ever experienced episodes of heating, for example during mountain building.
In this way, fission track dating provides a kind of historical thermometer for rocks in minerals.
Other dating methods rely on surface weathering rates, or the slow diffusion of atoms through
mineral crystals, or even on the slow growth of lichens. These and other measurements of deep
time are independent, that they all yield the same results, and the geologic data are complemented by
insights from biology and cosmology. Darwin's theory of evolution by natural selection relies
on hundreds of millions of years of accumulated genetic changes, and recall that Edwin Hubble
and other cosmologists who studied the red shifts of the most distant galaxies found that the universe
is almost 14 billion years old. The lessons of the rocks and minerals of stars and galaxies
and of life are equally clear. If you would choose to understand Earth, then you must somehow look
far beyond the inconsequential temporal or spatial scale of a human life. We live on a single tiny
world in a cosmos of a hundred billion galaxies, each with a hundred billion stars. Similarly,
we live day by day in a cosmos aged hundreds of billions of days, and this vast cosmic context
is hard to argue that we humans enjoy some privileged status in space or time. Rather,
from the perspective of deep time, we see a cosmos bounded by natural laws that lead,
perhaps inevitably, to a universe that is learning to know itself.
