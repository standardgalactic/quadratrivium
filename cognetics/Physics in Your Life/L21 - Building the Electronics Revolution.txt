Lecture 21, Building the Electronics Revolution.
So now we have the transistor, and in the previous lecture we probably saw more detailed
physics than anywhere else in this entire course.
This lecture is going to be more or less the opposite.
We're going to talk about manufacturing.
We're going to talk even a little bit about economics.
We're going to talk about a whole industry and how it operates and how it's come to
permeate our whole world, but it's an industry that's ultimately based in the physics of
semiconductor electronics.
So in the transistor we have this single control element that can either amplify a signal,
we put in a small electrical signal, it changes slightly, a bigger signal changes in proportion,
and that's how we get amplification.
But more important for our purposes in heading from atom to computer, we're going to talk
about using transistors as switches that can be either on or off, and again we use that
voltage on the gate to decide whether the transistor is going to be allowed to conduct
electricity by having its channel all one kind of semiconductor or whether it will block
the flow of electric current.
So it's an on-off decision we're going to be making.
Individual transistors are not enough.
What has really propelled the electronics revolution is the ability to put lots of transistors
automatically on the same single piece of silicon.
I remember several stages in the process to getting there, and some of you may remember
these historically also.
In the old days one wired by hand individual pieces of individual electronic components,
one to the other, and one built them on complicated looking, usually metal chassis in which you
had little pieces of insulating material with metal tags on them and you could attach wires
there and you'd solder them together.
What a complicated job.
A little while later we developed printed circuits, which was a flat piece of material,
insulating material on which copper was coated and then the copper was etched off to leave
a pattern of interconnections and individual electronic devices, resistors, transistors,
whatever were dropped into the holes and soldered together.
Printed circuit boards still exist, but now they don't contain very many individual transistors
and resistors and so on as I'll get to in a moment.
Some of you may date yourselves by having built electronic circuits yourself.
There were a number of manufacturers that made electronic kits.
I remember when I was in college earning spare change by people who wanted new stereo systems
and they could buy the stereo amplifier completely built or for about half the price they could
buy it in kit form and put it together, but they didn't want to put it together so I would
put it together and I would charge half the difference between the two.
Wiring electronic circuits was something a lot of people, particularly electronics hobbyists,
used to do a lot.
The electronics revolution has in some ways, unfortunately, obviated the need to do that.
These electronics is pre-wired largely because we've managed to put thousands, hundreds
of thousands, millions, hundreds of millions and by the middle years of the first decade
of the 21st century, billions of electronic components, particularly transistors on a
single chip of silicon.
Today's lecture is about how we do that and what some of the economics of that are that
have powered this remarkable revolution in which we now have smart devices in our cameras,
in our refrigerators, we now have refrigerators or we're about to have refrigerators that
know how much milk is left and tell you when to buy more milk.
And that's all powered by the ability to put thousands, millions and increasingly billions
of transistors on a single chip of silicon.
Now I emphasize last time that the role of the transistor is to be a control element.
It lets one electronic circuit control another.
Transistors are not the first such devices to do so and I want to take you on a little
historical tour of some of the other devices we've had that have served the same function
and in principle, but no way in practice, we could build all of today's devices, today's
electronics out of these other things I'm describing.
Let me begin with a simple device which is still in use for certain applications.
That's the so-called electromechanical relay.
I have one here and all this relay has is a coil of wire and you can kind of see this
golden part.
That's the coil.
There's a coil of wire and that coil of wire makes a little electromagnet and that coil
of wire is in the vicinity of a metal flapper and that metal flapper is just the switch
that can either close or open an electric circuit.
So the electromechanical relay works by passing current through the coil.
It becomes an electromagnet and that closes the switch.
By the way, I described such a device earlier that was basically how a circuit breaker works.
Only a circuit breaker controls its own circuit, whereas this electromechanical relay is typically
used to control another circuit.
And there are many examples of relays.
When you turn on the ignition switch in your car, that switch doesn't directly control
the flow of 100 or more amperes of current from the battery to the starter motor.
That switch couldn't handle that kind of current.
It would overheat.
You wouldn't want to run wires that long.
So what that switch does is closes a relay that ultimately connects the battery to the
starter motor and starts the car, increasingly other parts of cars.
For instance, when you turn on the headlights, you're probably ultimately turning on a relay.
Electromechanical relays are still in use.
They're cheap.
They're rugged.
They're not very sophisticated and particularly they aren't very fast.
It takes a fraction of a second to close the switch on an electromechanical relay.
But in principle, because an electromechanical relay is an on-off device, we could in principle
build an entire computer from billions of these.
We wouldn't want to, but we could.
So electromechanical relays were among the earliest of such devices.
By the way, the early telegraph system, dot dash, dot dash, and the sounds you hear, they
were basically operated by a device like a relay, again a coil of wire that simply pulled
down something else, some metal piece, and made that noise that you heard the dot dash
kind of noise.
Around the turn of the 20th century, out of experiments involving the experiments that
led, for instance, to the discovery of the electron, which involved trying to pass electric
currents between different electrodes in a vacuum by means of electrons that would
flow through the vacuum from one electron to another, out of that came the electronic
vacuum tube.
And the vacuum tube dominated electronics for the first half of the 20th century or a little
bit more, well into the 50s, into the 60s.
Vacuum tubes are still used in some applications, and I want to talk a little bit about vacuum
tubes, give you some history of them, and give you a sense of how they work.
A vacuum tube is actually easier to understand in some ways than a transistor.
I have some examples of vacuum tubes here.
Early vacuum tube, probably from around the 1920s, quite a large, ungainly looking structure.
As vacuum tubes evolved, they got a little smaller.
The final vacuum tubes, before they went out of popularity, looked like, most of them looked
like this very small one, but they all share a common feature.
They have a glass envelope, air has been evacuated from the envelope, and there are
metallic electrodes inside.
So vacuum tubes are kind of bulky.
As we'll see in a minute, they also get hot.
They're fragile.
They burn out frequently, as we'll see in a moment, have to be replaced.
Therefore, they have to plug into particular sockets.
They're not something that you leave in for the lifetime of the device.
So they're large, they're bulky, they're fragile, they consume a lot of power.
But they work on a very simple principle, which I'll just take a minute to show you.
Before we do, I want to give you a quote that's going to sort of start us on this history
from vacuum tubes to semiconductors, ultimately to putting lots of semiconductors on a single
chip.
This is Richard Feynman, and he's speaking in 1959 at about the time vacuum tubes are
going out, and transistors are coming in, but transistors are still individual devices
that we have to wire together.
Feynman knows about computers, and he's talking about computing systems, and he says, I know
that computing machines are very large.
They fill rooms.
Now he's talking about some of the first computers that were built in the 1940s and 1950s.
One of the first was ENIAC, Electronic Numerical Integrator and Computer.
ENIAC had something like 19,000 vacuum tubes, more or less of this size.
It had 1,000 electromechanical relays.
It filled an entire room, as Feynman is saying, and it consumed power at the rate of 200,000
watts.
It was very slow to make calculations.
It was always breaking down.
Some of those 19,000 tubes are always burning out, so it was very unreliable.
And it was far less powerful than this G4-based laptop computer I've got sitting here, which
although only two years old is already not the current technology.
That's how bad computers were in the 1950s, and so Feynman says, they're very big.
They fill rooms.
Why can't we make them very small?
Make them of little wires, little elements, and by little, I mean little.
For example, the wire should be only 10 or 100 atoms in diameter, and the circuit should
be a few thousand angstroms across.
Now an angstrom is one over one with 10 zeros of a meter, and it's a tiny, tiny distance.
An angstrom is about the size of an atom.
So he says the circuit should be about a thousand angstroms across.
A thousand angstroms is 100 nanometers, which is the more modern term we use for very small
scale things, nanotechnology.
And ironically today, or not ironically, but presciently, today's integrated circuits,
the current technology in actual manufacturing, uses 90 nanometer technology.
That's 10 percent smaller than what Feynman is suggesting if you interpret his a few thousand
to mean 1,000.
We're smaller than that, quite a bit smaller than that if it really means a few thousand.
So he says they should be a few thousand angstroms across.
Everybody who has analyzed the logical theory of computers has come to conclusion that the
possibilities are very interesting if they could be made to be more complicated by several
orders of magnitude.
Instead of 19,000 vacuum tubes, if you could have 190,000 vacuum tubes, or 200,000, or
2 million, wow, that would be complicated.
Well now we're at a billion vacuum tube equivalents in our computer circuit, so we've gone way
past Feynman.
If they had millions of times as many elements, well let's see, a million times 10,000 is
a 10 billion we're getting there, we're not quite there yet, then they could make judgments.
And already some of our computer chips are as complicated as the brains of simple insects.
So Feynman was very prescient, but he didn't quite see how to do it, but he thought we
ought to be getting there.
So vacuum tubes have evolved into the 1950s and 60s to these relatively small vacuum tubes,
but then the transistor basically superseded them.
There are a few cases where vacuum tubes are still used.
I've mentioned the magnetron before, a special vacuum tube that generates the microwaves
and a microwave oven.
Some high-powered radio transmitters still use vacuum tubes.
And there are audio files who claim, and I do not wish to get into this controversy
because I'm a bit of a skeptic, who claim that there's something more mellow about
the sound of audio produced by vacuum tubes.
Now in my purest sense, I think if you're going to have an audio amplifier, it ought
to reproduce faithfully whatever signal you put into it.
But given that that doesn't happen perfectly, maybe there's some truth to the fact that
vacuum tubes might make things sound a little better, but I don't want to go there.
So there are people who still use vacuum tubes.
Another place vacuum tubes are still in use is in traditional televisions and computer
monitors where the so-called cathode ray tube or picture tube is a special vacuum tube
that accelerates electrons.
They bombard a phosphorescent screen at the front of the tube, and that's what makes the
picture you see.
But those, as I've indicated before, are rapidly on the way out and replaced by LCD and plasma
displays and other devices.
So in the previous lecture, I introduced transistors and how they work.
And they are an enormous improvement over vacuum tubes, but they work by a more complicated
physics.
I'm going to take a quick look at the physics of the vacuum tube, then we'll move on to
transistors.
So here's a vacuum tube, typical vacuum tube, very simple vacuum tube.
That circle represents the closed envelope that I talked about.
At the bottom, that sort of triangular looking thing is a filament, and you run electric
current through that filament like the filament or the light bulb, and you heat it up.
And electrons boil off.
And then if you connect a battery, so the positive end is that uppermost electrode in
the vacuum tube, so that becomes positive, you connect the other end to the filament
so it becomes negative.
Electrons boiling off the filament will be attracted through the tube and they will hit
the plate and electric current will flow.
That's how a vacuum tube works.
And by the way, that alone makes the vacuum tube a diode that serves the same function
as our semiconductor diode, passes current in one direction but not another.
But here's a third electrode in the middle.
It's called a grid, and I've indicated it by a dashed line because it's actually a
grid work that lets electrons go through it.
If I place a negative charge on that grid, then with a battery with negative terminals
connected there, then the grid will repel electrons coming off the filament and they
won't be allowed to get to the plate and the thing will block the flow of electric current.
So I can turn the current on or off with this grid, just like I could turn the transistor's
current on or off with the gate, or I can adjust the current by adjusting the voltage
on the grid.
So that's how a vacuum tube works.
Conceptually, it's basically like a transistor.
It's a device that controls the flow of one circuit with another.
But it's big, bulky, that filament burns out, that filament consumes a lot of power.
It gets very hot.
It needs to be cooled.
It burns out.
It's fragile.
It's expensive.
It's complicated to build.
It has to be hooked in, almost wired in by hand, plugs into a socket, complicated device.
We don't want to go there.
We have transistors now instead, and we've had transistors since the 1950s and 60s.
And here are a host of transistors.
I showed you them in the previous lecture.
We know how they work.
And they are tiny compared to vacuum tubes.
Look at the smallest vacuum tube alongside a typical transistor.
And the transistor probably has a hundredth the volume of the vacuum tube.
And where the vacuum tube has a lot of pins coming out the bottom because it needs connections
to its filament and so on, the transistor has only three.
One for the control, and the other two for the controlled.
So these two things, the vacuum tube and transistor are conceptually similar, but practically
they're very different.
But still, if I were to build a circuit out of either vacuum tubes or transistors, I'd
have to connect them all together, connect lots of transistors together.
And the key to the electronics revolution is our ability to connect lots of transistors
together on a single chip of silicon so we don't actually wire a circuit anymore.
We build a chip which, as I said, contains many, many transistors.
And circuit design of integrated circuits, as these things are called, is clearly the
province of engineers.
This is not physics anymore, although we'll see there are some physics principles that
push when we get to the limits of how small we can make these things.
But I should point out that it is also the province of physics.
Jack Kilby of Texas Instruments, for example, shared the 2000 Nobel Prize in Physics for
his contributions in the late 1950s to the development of integrated circuits.
I have here a few integrated circuits.
Here is a simple logic circuit.
This is actually still in use.
There's the size of the device.
This is a circuit that was probably commercially available first in the mid to late 1970s.
It probably contains several dozen transistors.
Here's a bigger integrated circuit from about the same era.
Probably contains a few thousand transistors.
These are actually tiny circuit boards, two of them, with several different integrated
circuits mounted on each.
They're actually memory modules.
The one on the left is from an earlier era, and each one has about a few hundred thousand
transistors.
The one on the right is from a later era, and each integrated circuit on there has probably
a few hundred, not a hundred, but a few tens of millions of transistors in it.
And finally, I have a complete motherboard, as it's called, the main processing board
out of a laptop, but a personal computer.
You can see the Pentium chip here.
This is not a most current version, but this one probably has tens to a hundred million
transistors in this Pentium chip.
Each of those transistors serves the same function as one of these vacuum tubes.
So with this, we've realized Feynman's dream.
We have really the complexity that he thought we ought to get to if we were to make computers
really special.
Now in 1965, an engineer named Gordon Moore noticed even that early that integrated circuits
had been getting better and better and better, and he proposed that the engineering of integrated
circuits was going to improve to the point that every roughly one to two years, and it's
about every 18 months, it turns out, the number of transistors we could fit on a single integrated
circuit would roughly double.
And here's a graph of Moore's law from about 1970 on to about 2005.
The individual triangles are individual actual chips that were manufactured, put into production.
The line is sort of a trend.
When you see a straight line on a logarithmic graph, and if you look at the left-hand axis
of this graph, it goes from 1,000 at the bottom, the next tick mark is 10,000, the next is
100,000, then a million, a hundred, 10 million, a hundred million, a billion, each tick mark
goes up by a factor of 10.
That's a logarithmic scale, and when you see a straight line on a logarithmic scale, that
implies exponential growth.
So the number of transistors that we can fit onto chip is growing exponentially.
It's doubling roughly every one and a half years.
That, by the way, is why your new powerful computer you just bought is obsolete almost
as soon as you buy it, because next year or next month, there's going to be one that's
twice as powerful or much more powerful anyway, and it's going to cost either the same or
a little bit less, because even as the number of transistors we could fit on a chip increased,
the cost for each transistor dropped lower and lower and lower and lower, starting out
at over 10 cents a transistor, between 10 cents and a hundred cents, almost a dollar
a transistor, by 2005, we're down to about one millionth of a cent, which is 10 billionths
of a dollar, 10 nano dollars, if you'd like, in today's nano language.
So the cost for transistor has been dropping dramatically, and these integrated circuits
today are ubiquitous.
There are specialized integrated circuits in your cell phone, specialized integrated circuits
that are the receiver circuit of your FM radio, your DVD players have specialized integrated
circuits that decode the stream of bits coming off the DVD, and other ones that do the,
business I mentioned before, about focusing the lens and keeping up all kinds of customized
integrated circuits, our washing machines, our robotic vacuum cleaners, our thermostats,
our home energy control system, all these things now are smart, because they contain
specialized integrated circuits.
Your heart pacemaker, your pet may have a chip in it that tells you if your pet's gotten
lost, soon individual products in the store will have little integrated circuits, which
will emit radio signals, which will tell you what that product is, and will also serve
security needs.
Okay, so this is wonderful stuff, and we're all involved with it because we all use computers
and cell phones and televisions and all these other things that now have increasingly smarter
and more complex integrated circuits in them.
How do we build these integrated circuits?
Well, that's one of the most high tech things we do.
Here's an example of a clean factory, and I've got to emphasize clean, because remember
how pure that silicon has to be, so that we can then dope it exactly, right, at the level
of one dopant atom in 10 million silicon atoms, we have to keep things really pure.
So these semiconductors are manufactured in these wonderfully clean facilities here.
You see the workers dressed up in these moonsuit-like things to keep from contaminating anything
with stuff that comes off their own body, a remarkable process.
And the process begins with the preparation of pure silicon crystals.
We get pure silicon ultimately derived from sand, again, that very common place material.
So we make pure elemental silicon, we melt down, we melt down metalized silicon, and
then in a process that involves rotating, putting a seed crystal down on a block and
dropping on a rod and dropping it into the molten silicon, we slowly draw out the molten
silicon all the while rotating it, cooling it at just the rate, rate that we get a cylindrical
ingot of pure crystalline silicon, and it's got to be pure, and it's got to be crystalline,
and in most applications it has to be single crystal.
Even though silicon is the second most abundant element on earth, pure semiconductor grade
silicon is very expensive simply because of the process of making this pure silicon has
to be really pure, because we know what contaminants do, later we want to contaminate it, but we
don't want it contaminated to start with.
The fact that it has to be crystal, and all the atoms have to be sharing the same common
crystal arrangement, if we have gaps in the crystal structure we have problems with the
electronics of the semiconductor.
What happens once we get one of these ingots of silicon out?
Well we slice it up with specialized saws into these thin wafers, an awful lot of it
is lost in that sawing process, and people are working very hard to develop ways of growing
thin film silicon.
In some cases we've succeeded in doing that for some applications, for example my solar
panel over here, as I mentioned when I showed it to you outdoors, is in fact polycrystalline
silicon, and you can see that because of the model appearance of it, and that reduces the
efficiency of the photovoltaic device, but it makes it far cheaper to build.
But for semiconductor electronics we slice this silicon ingot into these very thin wafers,
about a millimeter thick, and we then process those wafers, and I'm going to show you briefly
the process we use to go from there to making individual transistors.
It's a process called photolithography.
So here's a wafer, typically these wafers are 8 or 10 or 12 inches in diameter, the size
has been growing as the semiconductor revolution has advanced.
In my own state of Vermont we had the state of the art, probably the world state of the
art facility for making 8 inch semiconductor wafers at the IBM facility there.
That's now been superseded by a facility in New York that makes larger wafers.
So we're trying to get more of these chips on a wafer, and this picture shows you a grid-like
pattern of rectangles, those are to be individual integrated circuit chips, each of which will
be identical to each other one, and they'll serve a certain function.
They might be a computer processor, they might be a memory chip or whatever, and typically
there's more like 100 of them on a single wafer, not just a few like I've shown here,
I guess I've shown 16.
So what happens?
So we've got this wafer, we expose it to oxygen and then grow a thin layer of silicon dioxide
on it, and that silicon dioxide layer is coated with a photoresistive material that responds
to light and is like camera film and can be developed when you shine light on it.
And then we develop a mask, and the mask, actually there's several masks in a complicated
manufacturing process, but the masks reflect what we want to put on this ultimately silicon
substrate.
We actually grow some more really pure silicon on first, even purer than the silicon that
came out of the oven.
So here's the mask, and we're going to shine light through the mask.
And I've marked this as UV light from a UV laser, although there may be other sources.
Used to be this could be visible light, but as I mentioned in the first module, you can't
image or make shadows or anything else like that with light, you can't make shadows of
objects that are comparable to or smaller than the wavelength of light.
And by now we're working with 90 nanometer basic device sizes, basic transistors, or
only 90 nanometers across.
The wavelength of visible light, as I showed you in the last lecture in the previous module,
is somewhere between 700 and 300 or so nanometers, 4 to 7 to 8, 10 times as big as the devices
we're now making.
So we can't use visible light anymore.
We have to use ultraviolet light, which has a much shorter wavelength.
So that diffraction limit that I talked about in an early module, the first module, is coming
to haunt us again here.
And as we make these things smaller and smaller, we have to use higher and higher frequency
shorter and shorter wavelength light.
So we expose the mask, and that puts onto this wafer a pattern.
And the mask is typically much bigger than the ultimate size of the integrated circuit,
so the focusing process of the light reduces the size to what we actually want on the chip.
So when the photoresist is developed, then there's a layer over those regions that were
exposed to light, and then we begin the process of fabricating the individual parts that make
the layers of an individual, of all the many individual transistors.
And I'm just going to give you the briefest hint of how this happens, but you can imagine
how the whole process looks gone over and over again as we build up a more and more
complicated structure on what is ultimately this wafer of silicon.
So here's how we might build a transistor.
So we want to build one of those MOSFET transistors, like I described in the last lecture.
So here's a slab of material that we've already exposed to something that's made at p-type.
So already that silicon has been exposed to maybe an arsene gas, for example, which contains
arsenic, and arsenic has diffused into there, and that's what gives us the p-type material.
OK, now we have this photoresist oxide, the oxide layer and the photoresist, and we've
put the mask on, we've developed the photoresist, and you see those two gaps where the photoresist
is gone, and the photoresist is resistant.
It's not only photosensitive to light, but it resists acids.
So now we etch away, typically with acids or other means, we etch away where the photoresist
is not there, and that takes away that oxide layer down to the p-type material underneath.
And then, by means, again, of a variety of techniques, increasingly high energy beams
of material, but more commonly, simply exposure to a gas that might contain the right material.
Here's a gas containing the dopant.
So this is a vapor, or maybe it's a beam of dopant atoms.
The material is exposed.
Where that oxide layer is present, the photoresist has now been removed, but where that oxide
layer is present, the material, this new material, is not allowed to get into the semiconductor
substrate, the p-type material, but through those two little gaps it is.
Diffusion again occurs because we have a high concentration of this dopant material right
at the surface of the p-type block, and so that dopant, which is an n-type material, now
diffuses in.
Did I say arsenic before for the p-type?
I think I meant the other way around.
This might have been arsine gas, and the arsenic diffuses to make these n-type regions.
And by controlling the concentration of the gas and how long we expose it, we control
how deep in those n-type blocks go and the level of concentration.
So there we are with those exquisite controls on the electrical properties of these materials.
Then what?
Well, then we plate again with some kind of photoresistive material.
So it only happens here that metal layer on, which is going to become the gate.
So now we have almost the complete transistor that I described in the previous lecture,
but we've got to make contact to it.
So we coat some more metallic layers on that make the contacts to the n-type material, and
then we probably coat some on some more oxide layers on that serve as insulators that separate
the now metallic contact to the gate.
But while this is going on, another 999 million or however many transistors there are in this
chip are all having the same thing happen at the same time.
And in addition, these things that show up here as gold or yellow are the interconnections,
and they're being made to interconnect the individual transistors in ways I'll describe
in the next lecture to make the final circuit that does exactly what we want it to do.
And eventually we reach the complete wafer.
It looks like that.
It's got this pattern of rectangles on it that wafer might be 8 inches across, and each
of these little rectangles is one of these chips.
The chips are cut apart.
There's a micro photograph of what's on an individual chip.
Those patterns on there, you don't see individual transistors at this scale, but you do see
a kind of patterning, which represents the way the transistors are arranged.
And the chip is ultimately packaged in a covering package to protect it, and the external wires
and connections to the external circuitry are ultimately connected.
And there we go.
So ultimately we have this single chip.
Now before I end with my final slide that shows how we got from Adam to here, let me
just say a few other things.
Although Moore's law has held now for a number of decades from the mid-1960s to now, ultimately
we will run into quantum mechanical uncertainty principle limitations on how small we can
make these things.
We aren't quite there yet, but we will be there probably in a matter of a decade or
so.
People are also experimenting with circuits made with DNA, for example, and already it's
been demonstrated that DNA can do actual computations, solve simple computational problems.
So we may ultimately get molecular-scale computers that are based in the principles
that govern life.
There are a number of other processes, superconducting computers that involve something called Joseph's
injunctions and quantum tunneling, and there are quantum computers that I'm not even going
to window that have crazy logic due to the multiple states of quantum physics.
So there will eventually be some replacement for this silicon-based technology, but we're
not there yet.
We're still into silicon, and we'll be there for a number of years to come, and probably
a decade or so.
Let's pause and consolidate here.
We're on this hierarchical journey from atom all the way to computer, and now we're about
halfway there in some sense.
We started with the structure of the silicon crystal, and the atom and the silicon crystal.
We built up to P and N-type semiconductors, and now we've got these things formed into
transistors on these chips.
So our whole picture looks like this.
Here's where we were at the end of the previous lecture.
In silicon-atom, silicon-crystal, we make P and N-type, we make PN-junctions, we make
transistors out of that.
Here we've learned how to put lots of transistors onto a single chip, and there's the chip,
and that chip can do useful things.
How does that work?
That's the topic of the next lecture.
