We've seen how perceiving the pitch and timbre of individual sounds involves complex mental processing.
Now we'll look at how combinations of pitches are perceived.
When two pitches are played at the same time, the resulting combination can sound very rough and dissonant like this.
Or very smooth and consonant like this.
These differences aren't just perceptual, they also have psychological qualities.
When I ask my students to describe the combinations I played you, I get very different responses with words like tense and ominous for the first and simple and regal for the second.
This is a great example of how even simple musical sounds are full of meaning for human listeners.
What we just heard was acoustic or sensory consonants or dissonants, which can be perceived when pitch combinations are heard in isolation without a context.
There's another type of consonants and dissonants that depends entirely on context, which we'll deal with in the next lecture.
Acoustic consonants and dissonants play a big role in music. They're both important.
They help structure the ebb and flow of tension and resolution, and they help give music an expressive, living quality.
In the first part of the lecture, we'll consider why pitch combinations differ in how consonant or dissonant they sound.
In the second part, we'll look at the structure of musical scales, which are collections of pitches used to make music, like the C major scale.
I'll argue that there are some surprising connections between consonants, dissonants, scale structure, and the way we process spoken language.
The connection is surprising because consonants, dissonants, and scales aren't features of human speech.
When I speak, my voice pitch glides up and down, but it doesn't produce multiple distinct pitches at once, which is how consonants and dissonants are created,
and it doesn't jump between a small number of distinct level pitches, which is the hallmark of musical scale structure.
We'll focus on scales in the second part of the lecture, but I'll say a few words about them now to give us some vocabulary for talking about consonants and dissonants.
Remember from our last lecture that two pitches separated by an octave or a doubling in frequency sound very similar to us.
We give them the same note name. Let's listen to two pitches separated by an octave that are both named C in western music.
The first has a fundamental frequency of 130.8 Hz, and the second of 261.6 Hz, exactly twice the frequency of the first.
Here they are played one after another.
And here they are played at the same time.
They blend perfectly. All cultures recognize the similarity of pitches separated by an octave. It's a basic component of human musicality.
When men and women sing the same note, they are often singing pitches that are an octave apart.
In western music, each octave contains 12 pitches, which are given letter names.
If we start on C, we have C sharp, D, D sharp, E, F, F sharp, G, G sharp, A, A sharp, B, and then we return to C.
This is called the chromatic scale, and it sounds like this.
These 12 notes are the basic pitch material for making intervals and for constructing the scales of western music, like the C major scale, which we heard a moment ago.
Right now we'll focus on intervals between two tones.
The interval between any two neighboring pitches on the chromatic scale, like C and C sharp or E and F, is called a semitone.
It's about a 6% difference in pitch.
Every pitch interval in western music can be measured in semitones.
For example, the first interval you heard in this lecture was made from the pitches C and C sharp.
This is an interval of one semitone, which is called a minor second in music theory. It's a very dissonant interval.
The next interval you heard was made from the pitches C and G. That's an interval of seven semitones, which is called a perfect fifth in music theory. It's a very consonant interval.
A key fact about intervals is that they are transposable or movable, up or down in pitch.
You can make a minor second from a C and a C sharp, but you can also make it by playing any two adjacent notes in the chromatic scale, because these notes are always one semitone apart.
Similarly, you can make a perfect fifth by taking any pitch and playing it with a pitch that's seven semitones above it, like an F combined with a C or a D sharp with an A sharp.
Let's listen to a few different minor seconds and perfect fifths to make this idea clear.
Pitch intervals are interesting, because they have perceptual properties that aren't present when their individual pitches are played alone.
Any single musical pitch, like the piano note C or C sharp, doesn't sound rough or smooth by itself, but when you take two pitches and make a minor second or perfect fifth, you get a new perceptual property, dissonance or consonance.
It's been known for thousands of years that different combinations of pitches vary in how consonant they sound, but the reason for this has long been debated.
The ancient Greek Pythagoras had a numerical theory of consonance and dissonance based on his measurements of the lengths of the strings that produced the pitches of a musical interval.
These measurements fueled his belief in the powerful role that certain ratios and proportions played in nature.
As people learn more about how hearing works, biological theories of consonance and dissonance began to emerge.
These theories try to explain people's perception of consonance and dissonance across a wide range of different pitch intervals, not just the minor second and the perfect fifth.
A study by Josh McDermott and colleagues in 2010 measured the average rating of the pleasantness or consonance of all pitch intervals between one semitone and eleven semitones, when each interval was heard in isolation, outside of any musical context.
There were actually four sets of ratings because the ratings were made with four different kinds of sounds, saxophone sounds, synthetic tones, sung vowels and synthetic vowels.
A similar pattern emerged in each case.
A graph of the results has an interesting M shape.
The very small and very large intervals like one, two or ten or eleven semitones get low ratings, meaning they are perceived as more dissonant.
The middle intervals, except for the interval of six semitones, get much higher ratings, meaning they are heard as more consonant.
Let's listen to all of the intervals that they studied, starting with an interval of one semitone, then going up to two semitones and three semitones and so on, up to eleven semitones.
You'll hear the minor second as the first interval and the perfect fifth when the interval size reaches seven semitones.
E
E
E
E
E
E
E
E
E
In the middle of that series of intervals, just before the perfect fifth, you heard a dissonant interval of six semitones.
This is known as the tritone.
When I asked my students to describe how this interval sounds, I've gotten words like unstable, suspicious and incomplete.
Their answers show how consistent some aspects of music perception can be over the centuries.
In the early 1700s, this interval was sometimes called the Diabolus in Musica, or the Devil in Music.
What is happening in the brain that leads people to hear certain intervals as more consonant and others as more dissonant?
There's a long history of debate about this.
The 19th century German scientist Hermann von Helmholtz suggested that we can understand this pattern if we look at the acoustic structure of the two sounds that go into making the interval.
Remember from our last lecture that musical tones are often complex harmonic tones.
A complex harmonic tone has a set of frequencies consisting of a fundamental and several upper harmonics, which are integer multiples of the fundamental.
For example, if the fundamental frequency is 110 Hz, then the harmonics are at 220, 330, 440 Hz and so on.
If two complex harmonic tones are played at the same time, then the brain receives both sets of frequencies at once, creating a composite sound with all the frequencies from both tones.
Helmholtz said that if there are frequencies in this composite that are very close to each other, they create a phenomenon called beating, a kind of warbling quality.
We can hear this clearly if we play two frequencies that are close together in pitch, like this combination of 200 Hz and 210 Hz pure tones.
It might be difficult to hear this as two frequencies, so I'll play it again, but this time I'll begin with the 200 Hz tone by itself and then fade in the 210 Hz tone and then fade it back out again.
When we hear it like this, we can clearly hear that the beating is caused by the two frequencies in conjunction.
The rate of beating depends on the frequency distance between the two tones.
If we play this example again, but this time fade in a 205 Hz tone against the 200 Hz tone, we'll hear that although the beating is still present, it's at a slower rate.
Helmholtz argued that the more pairs of nearby frequencies a composite sound had, the greater the overall roughness of the sound due to beating between nearby frequencies.
Until recently, this was the most favored theory of why we perceive different degrees of consonance and dissonance in different pitch intervals, but McDermott and colleagues ended up supporting a different theory in their 2010 study.
I'll need a few minutes to explain their study and the theory behind it, but at the end, we'll see how their results suggest a deep connection between the perception of consonance and dissonance and the acoustic structure of the human voice.
The theory, like the one we discussed earlier, also has 19th century roots in the work of a German researcher, Karl Stumpf.
Stumpf was a psychologist, an early comparative musicologist who was deeply interested in the origins of music, and in the music of non-Western cultures.
He felt consonance and dissonance reflected the degree to which the two tones of an interval fused into a single composite tone in our perception.
The modern version of this theory looks at the frequencies of the composite sound made up by the two tones and asks, how much does it resemble the spectrum of a single complex harmonic tone?
Let's look at two examples to help make this clear.
This spectrum shows the frequencies that make up the note C and this spectrum shows the frequencies that make up the note G.
If we put them together, we get the composite spectrum of the resulting perfect fifth.
The colors of the frequencies tell you which note each frequency originally came from.
Now notice how this composite set of frequencies is a pretty good match for the frequencies of a complex harmonic tone with harmonic spaced at equal frequency distances,
though not every harmonic of that imaginary complex harmonic tone is present.
This composite has a high degree of harmonicity.
Now, let's do the same kind of analysis with a minor second.
Here is the C spectrum again, and here is the spectrum of a C sharp.
If we put them together, we get the composite spectrum of a minor second.
Again, the colors of the frequencies tell you which note each frequency originally came from.
Notice how this composite set of frequencies does not produce a frequency pattern that nicely fits a complex harmonic tone with evenly spaced harmonics.
This composite has a low degree of harmonicity, or we could say it has a high degree of inharmonicity.
For many years, no one could decide between this harmonicity theory of musical consonants and Helmholtz's roughness theory because the two theories made similar predictions.
Composite tones with nearby frequencies that beat together are also less like a single complex harmonic tone in their frequency structure.
But in their 2010 paper, McDermott and colleagues found a way to disentangle these theories.
They took advantage of individual differences among people in how much they liked consonant intervals or disliked dissonant intervals.
Then, using some clever acoustic techniques in the lab, they made specially constructed sounds that varied in their amount of beating but didn't vary in their harmonicity and vice versa.
These sounds were much simpler than real musical sounds, but they allowed the researchers to measure people's aversion to beating and to inharmonicity independently.
After doing these measurements, the researchers measured if people's degree of aversion to dissonant pitch intervals was better predicted by their aversion to inharmonicity or their aversion to beating.
The results were surprisingly clear. It was aversion to inharmonicity, not aversion to beating that predicted people's musical consonants and dissonants ratings.
But why does that matter?
Well, it means that when judging the consonants or dissonants of a pitch interval, people seem to be implicitly comparing the composite frequency structure of the sound to the frequency structure of a complex harmonic tone.
What's the most common complex harmonic tone in our environment? It's the human voice.
As we discussed in the last lecture, whenever we hear a vowel, we're hearing a complex harmonic tone, a fundamental frequency and a series of harmonics which are integer multiples of that fundamental.
Our brains are deeply attuned to the sounds of human voices.
This makes sense because the voice is such an important carrier of information for our species.
It conveys words and the emotions with which we say those words.
In an earlier lecture, I showed how there were some overlap in brain regions that respond to the sounds of musical instruments and the sounds of human voices.
It may be that our perception of acoustic consonants and dissonants in musical pitch intervals reflects how well or poorly the resulting sound matches the acoustic structure of a human voice.
The research I've described so far is based on the fact that western listeners showed general agreement on how they perceive the acoustic consonants and dissonants of pitch intervals.
But is this perception universal?
Does the minor second sound dissonant and the perfect fifth consonant to someone who grew up in a very different musical culture?
This is an important question if we're interested in the biology of music.
To answer this question definitively, we would need to test people's perception of pitch intervals in a wide range of different cultures and this hasn't been done yet.
I think such work would show there is a universal element in how people perceive acoustic consonants and dissonants.
But to get at that element, we would need to make a conceptual distinction between perception and preference.
In other words, I think people from different cultures would agree that a minor second sounds more dissonant than a perfect fifth because of the shared biology of hearing.
They would have similar perceptions.
However, people may differ strongly in how much they like acoustic dissonants, reflecting the culture they were brought up in.
They may have different preferences.
Western baroque and classical music often emphasize consonant pitch intervals.
But Bulgarian women singing often emphasizes dissonant pitch intervals, which are perceived as very expressive in that tradition.
In other words, a minor second sounds more dissonant than a perfect fifth.
In other words, while the perception of acoustic consonants and dissonants is probably an inborn aspect of human musicality, preference for consonants or dissonants is probably strongly shaped by culture.
One line of evidence that is consistent with this idea comes from research with other primates.
If a preference for consonant sounds is deeply ingrained in the biology of hearing, then other primates should show this preference too,
because basic auditory, neuroanatomy and physiology is quite similar in humans and other primates.
McDermott and Hauser used the V-Maze that we discussed in the last lecture to test if cotton-topped tamarin monkeys had a preference for consonant over dissonant intervals.
The researchers found that the monkeys didn't show a preference.
They were just as happy to sit on either side of the maze and listen to consonant or dissonant intervals.
This finding was important because earlier work by other researchers had shown that monkeys can discriminate between consonant and dissonant intervals.
This experiment showed that even though the monkeys can perceive the difference, they don't seem to care about it.
This finding was later replicated with another monkey species that is a little closer to humans genetically, the Campbell's monkey from West Africa.
If humans do have an ancient and inborn preference for consonant sounds, we might expect to see these preferences expressed in infants.
Do human infants prefer consonant to dissonant musical intervals?
In 1996, two independent studies were published which suggested that four to six month old infants did prefer consonant sounds.
For example, in one study by Traynor and Heinemuller, the infants looked longer at a speaker when it played a consonant version of a simplified Mozart minuet than a dissonant version.
The consonant version sounded like this.
The dissonant version was made by changing the pitch intervals between the two melodic lines so that it sounded like this.
Infants looked longer at the consonant version, which suggested that they preferred it.
However, a study in 2013 by Plantinga and Tree Hub didn't replicate this result.
The researchers who did the newer study pointed out that their infants came from more ethnically and culturally diverse households than the infants in the 1996 study.
That means they likely heard a greater diversity of music and other sounds than the infants in the earlier study.
This could have shaped their auditory preferences.
This suggests that even if infants are born with a predisposition for acoustic consonants, it's easily changed by experience.
This is worth knowing because of what it means for our own musical traditions.
One reason that 20th century art music, like the music of Arnold Schoenberg, is so often challenging for listeners is that it uses a lot more acoustic dissonance than we usually hear in traditional western classical or popular music.
If you're like me, it takes time and repeated listening to understand contemporary music and to appreciate its structure and expressive power.
Knowing that our preferences for consonants and dissonance are largely shaped by experience and are probably not innately determined can help motivate us to take on the challenge of learning about contemporary art music.
And if we do, we can reap the rewards of new aesthetic experiences and of hearing new soundscapes that we would otherwise miss.
Let's turn back now to musical scales.
Even if you've never studied music theory, you know more about musical scales than you think.
This is because scales aren't just constructs from music theory.
Through our exposure to music, scales become mental constructs that influence how we perceive music.
For example, listen to this music. What culture does it remind you of?
Now let's change the scale that the melody is built from and the instrument, but keep the overall rhythm and melodic pattern the same.
Notice how the cultural connotation of the melody changes.
As you can see, scales can evoke cultural associations for us, and we don't have to go outside of western culture to realize this.
In the US, a blues scale is part of what gives the blues its characteristic sound.
In western tonal music, the most common scale is the diatonic major scale, which has seven distinct pitches.
If we start on C, these are called C, D, E, F, G, A, and B, with the next C being the eighth note or an octave above the lower C.
If we compare the C major scale with the chromatic scale, we can see that the major scale is formed by taking the starting note C
and then choosing notes according to a certain pattern of intervals.
Two semitones up to D, two more to E, one more to F, two more to G, two more to A, two more to B, and then one more to get back to C.
This pattern of intervals, two, two, one, two, two, two, one, is what defines the major scale.
We can make a major scale on any starting note of the chromatic scale by choosing notes based on this pattern of intervals.
Melodies based on a major scale move between the pitches of that scale, creating melodic intervals.
For example, in a C major scale, the interval between C and G is a perfect fifth.
It comes from jumping between the first and fifth note of the scale.
This is the interval that opens the song Twinkle, Twinkle, Little Star, and the theme from Star Wars.
The distance between C and F is a perfect fourth, which is the interval that opens the song Amazing Grace and Fogner's Bridal March,
aka Here Comes the Bride.
The perfect fifth and perfect fourth are just two of the melodic intervals you can make in a major scale.
As I said before, even if you've never studied music theory, you know more about scales than you realize,
because familiar scales become mental constructs.
One of the most powerful demonstrations of this comes from the research of Diana Deutsch,
a music psychologist who has discovered many striking auditory illusions.
In 2008, Deutsch discovered a phenomenon she called the Speech to Song Illusion,
in which a spoken phrase that's looped over and over starts to sound like it's sung.
We can listen to the original recording that launched this research,
which can be found on Deutsch's 2003 CD Phantom Words and Other Curiosities.
First, let's hear a spoken passage. This is Deutsch herself speaking, and everything in the passage sounds like speech.
The sounds as they appear to you are not only different from those that are really present,
but they sometimes behave so strangely as to seem quite impossible.
Now let's hear one phrase from this passage played repeatedly.
After a few repetitions, many people began to hear this phrase as sung, not spoken.
Sometimes behave so strangely.
If you heard the phrase transform to song, then when you hear it again in its original context,
it pops out as sounding like a sung phrase in the middle of an otherwise spoken passage.
Let's listen to the phrase in its original context again.
The sounds as they appear to you are not only different from those that are really present,
but they sometimes behave so strangely as to seem quite impossible.
Deutsch and colleagues published a scientific paper about this illusion in 2011.
The song illusion has now been demonstrated repeatedly by other research groups with this and other phrases.
One thing that makes the illusion so interesting is that not all phrases transform to sounding like song when they're repeated.
There's something about certain phrases that make them more likely to transform.
We're not yet sure what that something is, but it seems to concern the particular pitch and rhythm pattern of the syllables.
Exactly what it is about that pattern that makes a phrase transform as a topic of current research.
What we do know is that once a phrase transforms, a listener begins to hear those syllables
as if they're drawn from the pitches of a musical scale.
But since the speech hasn't changed acoustically, we know that the scale isn't just a physical fact about the sounds themselves.
It's a psychological framework in the mind of the listener, which is used to interpret the sounds that are heard.
All human cultures have music based on some sort of scale.
Does musical scale structure have any cross-cultural consistency?
If so, this could give us some clues about the mental foundations of music perception.
One striking thing about musical scales from around the world is that most have five to seven notes per octave.
Given that we can distinguish over a hundred pitches within an octave,
the tendency to use just five to seven doesn't reflect sensory limits on auditory perception.
It reflects cognitive limits on how many different pitches and intervals we can keep track of as we process a melody.
In Western music psychology, there has been a long history of searching for a universal scale structure
based on the laws of acoustics and the biology of hearing.
All musical scales use the octave and most use the perfect fifth,
which suggests that there is something about the biology of human hearing that leads us to these intervals.
Beyond that, though, the intervals used in musical scales show a lot of cultural variation.
For example, the intervals of Javanese gamelan scales are quite different from our familiar western musical scales.
Not only that, but the precise size of the intervals that make up the same Javanese gamelan scale
can differ substantially from one town to the next in Indonesia,
as shown in quantitative research by the ethnomusicologist Mark Perlman.
Apart from the octave and the perfect fifth,
the intervals that make up human musical scales may not be strongly biologically determined.
But even though scale structure varies a lot across cultures,
we shouldn't lose sight of the fact that all human cultures use musical scales.
People everywhere create melodies using a small set of pitches and pitch intervals
made by dividing up the octave into discrete steps.
As the music psychologist Andre Rakowski has pointed out,
there is an analogy here to how all human languages make sentences from a small set of distinct speech sounds or phonemes.
Just as different cultures make melodies from different sets of pitch intervals,
different languages make sentences from different sets of phonemes.
This tendency to make an infinite variety of sound sequences from a limited set of basic sound categories
is a human universal, seen in both language and music.
The analogy between phonemes and pitch intervals goes even deeper,
because the precise acoustic structure of any given phoneme or any given melodic pitch interval depends on context.
In language, the acoustic details of a phoneme, like the vowel ah in English,
depends on the other phonemes around it and on the emotional state of the speaker.
In music, made with instruments with flexible intonation like the violin and the voice,
the precise acoustic realization of a melodic interval, like a perfect fifth,
also depends on the notes around it and on the emotional expression with which the music is played.
Here again, we see hints that language and music might have some deep connections
in terms of cognitive processing, even though ordinary speech and instrumental music sound completely different.
In our next lecture on melody and harmony,
we'll go deeper into evidence that suggests that music and language really are cognitive cousins.
