This lecture is about disorders of music cognition.
I want to start with two anecdotes, one from my own experience and one from the writings
of the neurologist Oliver Sacks.
Some years ago I was walking down a sidewalk on a beach in California.
It was early and misty.
Very few people were out.
I gradually began to hear something that sounded like yelling, except that it kept going and
going.
As I drew closer I saw a man's shape emerge.
He seemed to be yelling while repeatedly hitting some kind of box that he was holding
in front of him.
I was in a town in Southern California where eccentric behavior on the beach is not uncommon.
So I continued to walk past.
But as I got close I realized the man was playing guitar.
The yelling started to sound like singing and I could make out the guitar chords and
how they fit with the singing.
By the time I passed the man I was really enjoying the music he was making.
The memory sticks in my mind because I went from hearing music as yelling and noise to
hearing it as music.
I don't know what it was about the acoustics of the beach that morning that caused this
transformation but it was dramatic.
It gave me a glimpse of what it might be like to have a music perception disorder.
From this perspective the normal human attraction to music seems strange.
It's like seeing and hearing music from a perspective of a visitor from another planet.
A planet that doesn't have music.
In his book Musicophilia Oliver Sacks gives us vivid portraits of a variety of people
whose neurological conditions have an interesting relationship to music.
Some have music perception disorders.
Others have non-musical problems like Parkinson's disease or dementia and are helped by music.
One of the people he describes is a woman who finds listening to music painful.
When Sacks asks her to describe what music sounds like she says it sounds like someone
going into her kitchen and throwing her pots and pans on the floor.
Imagine if that's what music sounded like to you.
Instead of music sounding like this.
It sounded like this.
In 2007 the neurologist Tim Griffiths reported a study of a patient like this who acquired
a distorted perception of music after a stroke that damaged higher order auditory cortex
regions on the right side of his brain.
The man could still perceive the pitch and loudness of individual notes fairly accurately
but the timbre of musical sounds was distorted.
Griffiths and his colleagues named this syndrome Dystambria.
Dystambria is a rare condition.
It's one of many different types of music perception disorders.
Research on these disorders has taught us that there are many different ways in which
music cognition can break down.
This makes sense if we think of musicality as having multiple distinct components.
By studying different ways in which music cognition can go wrong we can gain insights
into how these components are organized in a normal brain.
In this lecture I'll discuss a few music cognition disorders which have taught us interesting
things about the musical mind.
I'll start with one that's just recently been described.
It's very different from Dystambria.
In this disorder music doesn't sound distorted.
The problem is not with perception, it's with pleasure.
Musical Anhedonia was first scientifically described in a 2014 paper by Mas Herrero and
colleagues.
They studied individuals who reported getting no pleasure from music.
When they tested their basic pitch, melody and rhythm perception these individuals seemed
fine.
They could also recognize basic emotions expressed by music like happiness, sadness or peacefulness.
Also, these individuals weren't depressed.
They had a normal enjoyment of biologically important things like food and romance.
To see if these people really didn't get pleasure out of music, the researchers asked
these musical anhedonics to listen to music that had been judged as very pleasurable by
other members of their culture.
As they listened they were supposed to rate the pleasure they felt by pressing buttons
numbered one to four, where one was neutral and four was intense pleasure.
These people did press different buttons, but there was something strange about their
data.
During this experiment the researchers had also collected skin conductance and heart
rate responses.
These reflect the activity of the autonomic nervous system, a part of the nervous system
that operates largely outside of voluntary control.
When the researchers did the pleasure rating experiment with normal listeners they found
that the higher the number rating, the higher their skin conductance and heart rate.
Their pleasure was reflected in their physiology.
With the anhedonic listeners there was no relationship between rated pleasure and physiology.
No matter how they rated the music, skin conductance and heart rate stayed at the same low level.
The researchers suspected that the anhedonics just pressed different buttons because they
figured that's what the experimenters wanted them to do.
They weren't really feeling any pleasure in music.
Perhaps these are people who don't get pleasure out of things that are abstract, things that
are not connected to ancient biological functions.
This could explain why they still enjoy eating and reproducing, but not music.
To test this the researchers had the anhedonics do a monetary task where they could win or
lose money based on how quickly they responded to visual targets.
In this task the anhedonics performed very similarly to normal people including having
skin conductance responses which were high when there was a lot of money on the line.
For these musical anhedonics money, which is an abstract cultural construct, was still
very rewarding.
Research on musical anhedonia has just begun and we have yet to understand what it is about
the brains of some people that lead them to get no pleasure out of music.
Is there an anatomical disconnection between areas of their brain that analyze musical sound
and more ancient reward areas of the brain?
Hopefully brain imaging research will answer these questions in the near future.
For now musical anhedonia can serve to remind us that pleasure we feel in music is not an
automatic consequence of having a human brain.
Next time you enjoy music, thank your brain for having the kind of structure that makes
this possible.
I want to turn now to a different music cognition disorder which has been much more extensively
studied.
This is congenital amusia which is sometimes referred to as musical tone deafness.
Researchers prefer the term congenital amusia because tone deafness is used informally to
mean different things to different people.
In 2005 Lola Cuddy and colleagues reported that about 16% of the undergraduates they
surveyed self-identified as tone deaf but when they brought them into the lab and tested
their basic music perception abilities only about 4% had problems with music perception.
True congenital amusics have serious problems with music perception.
They may not be able to tell if two short melodies are the same or different.
They can't tell when their own singing is way out of tune.
They often can't recognize what should be very familiar tunes in their home culture
unless the tunes have words.
This could include a failure to recognize their own national anthem.
The Civil War General Ulysses Grant seems to have had congenital amusia.
He once remarked, I know two tunes, one is Yankee Doodle and the other isn't.
The example of Ulysses Grant shows that people with congenital amusia can be very accomplished
in other ways.
The Nobel Prize Economist Milton Friedman and the novelist Vladimir Nabokov are other
examples of famous people who probably had congenital amusia.
In his autobiography, Nabokov wrote that music, I regret to say, affects me merely
as an arbitrary succession of more or less irritating sounds.
Reports of true musical tone deafness date back to the 1800s, but the modern cognitive
study of congenital amusia began with the work of Isabel Peretz in the early 2000s.
Peretz had already done many pioneering studies of patients with acquired amusia in the 1990s.
These people had experienced dramatic changes in their music perception following brain
damage.
We discussed one of these people earlier in this course when we discussed the concept
of a musical key.
Patient G.L. lost his sensitivity to musical key relationships after strokes in his left
and right temporal lobes.
Peretz showed that his basic pitch perception and short-term memory for pitch patterns was
intact, but that he no longer heard note relationships based on musical key.
Let's listen again to an example to illustrate this.
You'll hear one melody that has all-in-key notes, and then a second melody where the notes
don't come from a coherent key.
In both cases, each individual note is perfectly well-tuned.
It's how they are related in terms of key that differs.
For most of us, the first melody seems like it would be much easier to learn and remember
accurately.
Here's the first melody.
And here's the second melody.
Imagine if those two melodies sounded equally challenging to learn, equally unstructured.
That's what G.L.'s perception was like.
By studying cases of acquired amusia using methods from cognitive science, Peretz and
other researchers helped analyze the different mental subcomponents of music cognition.
They showed that when music cognition broke down after brain damage, it didn't just break
down as a whole.
Different patients could have different problems, depending on the sight of their brain damage.
Some might have problems with aspects of melody processing, others with aspects of rhythm,
others with emotion recognition, others with memory from music, and so on.
In the 2000s, Peretz and colleagues published the first modern studies of congenital amusia.
These were people who had severe music perception problems in the absence of any obvious neurological
damage or intellectual impairments.
This line of research immediately took off because Peretz and her colleagues also created
a battery of music perception tests that could be used to identify people with congenital
amusia.
This Montreal battery for the evaluation of amusia, or MBEA, is now used by many labs.
It mostly consists of tests where people listen to pairs of short novel melodies and judge
if they are the same or different, though there are a couple of rhythm discrimination
tests too.
Congenital amusics are defined as people who score below a certain threshold on the overall
MBEA test.
It turns out that problems with pitch and melody are quite consistent in congenital amusia.
Problems with rhythm are much more variable.
One of the subtests of the MBEA that can sometimes completely separate people with amusia from
people without amusia is the ability to judge if two short melodies are the same or different
when they differ by just one out of key note.
Let's listen to a melody pair like this.
This pair isn't from the test, but it gives you the idea of what this particular subtest
of the MBEA is like.
Imagine you're taking the test and you hear these two short melodies.
For most of us, those two melodies are clearly different.
That out of key note pops out because of our implicit knowledge of music, but a congenital
amusic might not hear the difference at all.
They don't seem to apply the mental framework of musical key that most Western adults use
when they listen to music.
This is a subtler deficit than the musical distambria disorder we discussed earlier.
Congenital amusics don't usually say that music sounds like the banging of pots and
pans, but their problems perceiving musical key or tonality make it difficult for them
to enjoy melodies and to sing them accurately.
When they do sing, they usually can't tell when they themselves are producing out of
key notes.
It's not uncommon for them to first discover their problems when others tell them about
it.
In recent years, there's been some research on people who are not amusic but have serious
problems singing accurately.
These poor pitch singers are very inaccurate when compared to other people with equal amounts
of musical training.
Unlike congenital amusics, their melody perception is okay.
These people are being studied by psychologists like Peter Fordrescher and Simone Dallabella
to try and understand this mismatch between perception and action.
It's an interesting topic, but in this lecture I won't discuss it any further since we're
focusing on music perception disorders.
Back to congenital amusia.
Since many congenital amusics are otherwise normal, they are much easier to find and study
than people with music perception problems following brain damage.
Also the fact that their problems seem specific to music is fascinating from the standpoint
of cognitive neuroscience.
Research by Dennis Draena, Isabel Peretz and others has shown that congenital amusia,
or amusia for short, has a strong genetic component.
It runs in families.
So now we have a neurogenetic disorder that seems largely specific to music cognition,
which makes it even more interesting to cognitive neuroscience.
Amusia gives us a rare chance to study how genetic differences between individuals can
end up severely affecting one mental faculty while leaving other faculties largely intact.
Since 2-4% of the population is estimated to be amusic, there are plenty of people to
study, including around college campuses where research psychologists tend to do their
work.
For many researchers, including myself, another reason amusia is so interesting is that it
gives us a chance to study the relationship between music processing and language processing.
One of the most striking things about amusia is how differently amusics seem to process
music compared to other people, while their language processing seems largely intact.
As we'll soon see, however, when you test amusics in the lab, they do have some subtle
deficits in language processing.
But first let me give you an example of how different their music processing is from most
people.
In 2002, Ayat Peretz and colleagues published the first modern group study of amusia.
One of the tests they used was a test of sensitivity to sensory dissonance in music.
We discussed sensory dissonance and consonance in an earlier lecture in this course.
In this test, listeners heard a series of musical excerpts in two different versions.
In one version, there was a melody and an accompaniment that had a lot of sensory consonance,
like this.
In the other version, the music was modified by shifting all the notes in the melody up
or down by one semitone.
In this next example, they have all been shifted up by one semitone.
When non-amusic listeners were asked to rate these types of passages on a scale of pleasant
to unpleasant, they rated the consonant versions as quite pleasant, and the dissonant versions
as quite unpleasant.
In contrast, the amusics rated both versions as mildly pleasant.
In more recent work, Peretz and colleagues have shown that this indifference is not just
a lack of preference, it's a problem in hearing a difference between sensory consonance and
sensory dissonance at all.
This is strikingly different from how non-amusic people hear the musical world.
Recently, Peretz has collaborated with experts in the mechanisms of auditory pitch perception,
like Andrew Oxenham.
In 2015, they published a paper that used experiments with amusics to test different
theories of how the normal auditory system constructs the perceptive pitch.
This is a good example of how research on music cognition disorders is contributing to
auditory cognitive science more generally.
Another way in which amusia has contributed to cognitive science is through the investigation
of language processing in amusic people.
The way amusic people process speech can tell us about the mental architecture of cognition.
Are different mental faculties, like music and language, largely separate systems in
terms of underlying cognitive mechanisms, or are there important connections?
Speech perception in amusia is an issue that I've worked on in several studies.
In fact, one of my first studies of music in the brain was a collaboration with Peretz,
in which we studied an individual with acquired amusia after strokes on both sides of her
brain.
We showed that this patient had problems in both musical melody perception and speech
melody perception, that is discriminating between two sentences on the basis of their
spoken pitch patterns.
In later work that I did with Leo, Stuart, and Forsen, we looked at the ability of congenital
amusics to distinguish between sentences on the basis of their pitch patterns.
In a 2010 paper, we focused on the ability to discriminate statements from questions.
We looked at short sentences like, she changed her name, spoken as a statement, she changed
her name, or a question.
She changed her name.
The sentences differed in the direction of the pitch movement on the final word.
It went down for a statement, and it went up for a question.
The size of these pitch movements was fairly subtle for speech, but still in the natural
range, about four or five semitones, which is less than half an octave.
Amusics had difficulty discriminating statements from questions on the basis of these different
pitch contours.
This showed that their problems weren't specific to musical melody, but also influenced
speech melody perception.
They also had problems just listening to one sentence at a time and deciding if it was
a statement or a question, something that the non-amusic subjects in our study found
quite easy.
This was interesting because in an earlier 2008 study of statement question discrimination
I had done with Peretz, only about 30% of the amusics had problems.
The difference between the two studies was in the size of the pitch movement that distinguished
statements and questions.
In that earlier study, the upward and downward pitch movements at the ends of sentences had
been much larger, closer to an octave in size.
Comparing these two studies can help us understand why amusics don't often show problems in
ordinary speech perception.
Their problems with speech melody aren't all or none.
They depend on the size of linguistic pitch movements.
When these are big pitch movements, which often happens in real speech, they can hear
contrasts between spoken pitch patterns.
When pitch movements are small, which is less common in speech, then they have trouble.
This trouble with detecting small pitch changes seems to be a basic problem in amusia.
Research by Peretz, Griffiths and others has shown that if you test amusics with simple
pitch discrimination tasks, they need much bigger changes than other people before they
report hearing a pitch change.
They also have trouble discriminating between small upward and downward pitch movements even
when they do hear the pitch change.
Musical melodies are dominated by small pitch movements.
The most common pitch interval between notes in a melody in western music is two semitones.
If amusics can't detect this change or the direction of this change, then they won't
develop normal mental representations of musical melodies.
On the other hand, their speech melody perception will mostly be fine, because important pitch
movements in speech are usually significantly larger than just two semitones.
This could be one reason why amusic speakers of tone languages like Mandarin, where pitch
patterns can completely change the word's meaning, usually do fine in understanding
everyday language.
Another reason why amusia may impact music more strongly than speech concerns a short
term memory deficit for pitch sequence.
In 2010, Vicky Williamson and Lauren Stewart used standard methods for testing short term
memory capacity.
They showed that amusics had a much lower capacity than non-amusics for tone sequences,
even when they can hear the differences between each tone.
In contrast, they had similar capacities for remembering sequences of verbal digits.
In musical melody perception, you need to hold sequences of pitches in short term memory
in order to process their structure.
In speech perception, you usually just need to hold the pitches around the current syllable
in memory in order to hear if the current syllable is higher or lower in pitch, or as
part of a local pitch rise or fall.
In recent years, there has been increasing evidence that amusia impacts speech perception
in a variety of subtle ways.
William Ford Thompson and colleagues have shown that amusics have deficits in discriminating
between different emotions in spoken sentences.
Dennis Draina and colleagues have shown that on average, amusics do worse than non-amusics
in tests of phonological processing, processing the speech sounds of language.
In a 2015 paper with Fang Liu and others, I showed that amusics have subtle deficits
in understanding speech in noise.
So laboratory research shows that amusia provides evidence for connections between music and
language processing in the brain, even though in everyday life, amusics don't show obvious
problems with language.
In the real world, there are often redundant cues that can help overcome subtle perceptual
problems with speech.
For example, if you're not great at reading emotion and voices, you can use facial expressions
to help you gauge how people are feeling.
Even though amusics do show subtle language problems in the lab, it's striking how selective
their musical deficit is in everyday life.
This makes it interesting to look at their brains.
Are there obvious differences in the structure of amusic brains?
A 2007 brain imaging study of amusia by Hyde, Griffiths, Peretz and colleagues used MRI
to measure the thickness of the cerebral cortex in amusic and non-amusic brains.
The researchers found a few specific regions where the cortex was thicker in amusics.
It might seem like thicker cortex would be a good thing, but in brain development, overly
thick cortex can indicate abnormal development, for example, abnormal patterns of neuronal
migration during the formation of the cortex early in life.
In amusics, the thicker areas included regions in the right inferior frontal gyrus and in
the right auditory cortex.
Interestingly, the cortical regions that were abnormally thick in amusics had been shown
to be important for melody perception in normal individuals in earlier fMRI work by
Zatorre and colleagues.
So it seems likely that abnormal brain structure in these regions may be part of what causes
amusia.
In 2013, Barbara Tillman and colleagues published a paper that used magnetoencephalography or
MEG to measure brain waves in amusics or non-amusics during melody perception.
They showed that amusics had less effective neural communication between the right inferior
frontal regions and auditory regions.
This means that amusic brains don't just have disruptions to specific brain areas,
they have disrupted communication between certain brain areas.
Amusia may thus give us a way to study how normal music perception depends on the dynamic
interactions of different brain regions.
Recent years have seen other interesting discoveries about amusia based on methods from brain science.
Amusics that measure brain waves like MEG and EEG have been especially informative.
As we discussed before, these methods have excellent time resolution.
They can register cortical responses to individual tones with millisecond accuracy.
Studies of amusia using these methods have shown that even when amusics can't consciously
detect out of key notes, certain parts of their brain do respond to these notes.
For example, in 2015, Zendelle Peretz and colleagues published a paper using EEG to
examine brain wave responses to out of key notes in melodies.
In one condition, the task was to detect occasional clicks that had been inserted into the melodies.
In that condition, the out of key notes were not the focus of attention.
In another condition, the task was to detect the out of key notes, so they were the focus
of attention.
Both tasks required attention to the melodies, but the direction of attention was different.
The researchers measured brain responses to the out of key notes in A-musics and non-A-musics
in the two conditions.
When the task was to listen for clicks, both groups showed a similar brain response to
the out of key notes.
This was an early right anterior negativity, or E-R-A-N, Iran.
Extensive previous work by the music neuroscientist Stefan Kolsch and his colleagues had shown
that the E-R-A-N is a brain wave response associated with the processing of musical
key.
The brain response of A-musics to out of key notes seems paradoxical.
We know A-musics usually can't consciously process musical key relationships.
Yet in this study, their brains are showing a response that's typically associated with
the processing of musical key.
The interesting new discovery in the 2015 paper came in the task which involved trying
to detect the out of key notes.
When the controls did this task, they still showed the Iran brain response.
When the A-musics did this task, their Iran disappeared.
Something about focusing attention on the music eliminated their brain response to the
out of key notes.
This is remarkable.
It shows that A-musia does not involve an absence of implicit knowledge about musical
key.
Some implicit knowledge appears to be present in their brains.
The problem involves conscious access to that knowledge during music perception.
A-musics lack of sensitivity to musical key relationships may be because they can't bring
their implicit knowledge into consciousness when they focus on music.
This may be due to impaired connectivity between different brain regions, especially auditory
regions in the temporal lobes and regions in the frontal lobes that process musical structure.
Research on A-musia continues to grow, and in the next decade we will doubtless learn
further surprising and interesting things about it.
But A-musia is not the only disorder of music cognition that can teach us about the musical
mind.
I want to end this lecture by telling you about altered music perception in a very different
disorder called frontal temporal dementia, which has been examined by Jason Warren and
his colleagues.
This disorder involves atrophy in the frontal and temporal lobes and is often associated
with serious changes in social cognition.
These patients often have trouble interpreting the behavior of others in terms of underlying
mental states.
A very characteristic feature of human cognition is that we often think about what's behind
the actions people produce.
We think about what others are thinking.
This is often called theory of mind.
It's considered a foundational developmental milestone in young children.
In a 2013 paper, Warren and colleagues asked patients with frontal temporal dementia to
listen to musical excerpts and classify them in one of two ways.
In one condition, they tried to match them with labels that had to do with mental states
like dreamy or adventurous.
In the other condition, they tried to match them with labels that had to do with objects
or events that the music seemed to represent like raindrops or bird calls.
They found that the patients had significant problems in the task that involve matching
music to mental states.
This finding meshed very well with a fascinating 2009 FMRI study of normal people by Steinbeis
and Kolsch.
In this study, healthy people listened to a piece of contemporary music by Arnold Schoenberg.
These listeners didn't know Schoenberg's music.
The researchers took advantage of this to study how people's beliefs about a piece of
music influenced the way they process it.
The researchers told some of the listeners that the music had been composed by a computer
and told others that it had been composed by a human.
They found that just telling people this one piece of information strongly affected their
brain responses to the music.
In particular, the group that had been told the piece was composed by a human showed activity
in multiple brain regions associated with theory of mind.
To them, the music was a gateway into the thoughts of another person.
For the other group, the group that was told the music had been composed by a computer,
the music didn't lead to this kind of processing.
They probably just thought it was a quasi-random series of sounds.
The brain regions activated in the first group included areas in the medial frontal lobe
and the anterior temporal lobe.
Those regions are known to be involved in theory of mind tasks.
They were among the areas that were degenerating in the study of Warren and colleagues of music
perception in frontal temporal dementia.
I wanted to end with these studies because they powerfully remind us that music cognition
isn't just about processing sounds.
It's about using sounds to understand the thoughts and feelings of others.
