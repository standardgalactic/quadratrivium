One of the most distinctive things about music is its strong connection to emotion, so it
might surprise you to learn that until recently, emotion was not a major focus of research
in the psychology of music.
One reason for this is that emotions can be hard to measure.
Let's say I'm at a concert of classical music and I glance over at my neighbor and I see
that his eyes are closed and he has a look of intense concentration on his face.
I have no idea what kind of emotional experience he's having.
But what if I invite him to the lab and play him a recording of that same piece of music
and ask him to tell me about his emotional response?
Will his response be like anyone else's?
Or would he and every other person have a different response to the same piece of music?
We know that people can vary in how they respond to the same piece of music, and that even
the same person can have a different response at different times.
The challenges of measuring emotion and the variability in emotional response to music
are two things that steered early music cognition research away from the study of emotion and
led it to focus on phenomena that were easier to measure and consistent between people,
such as how we perceive structure and melodic patterns.
But if we're going to understand the musical mind, we have to study music's relationship
to emotion.
Unfortunately, recent years have seen a surge of empirical research on this topic.
One thing that has helped push this research forward is a clear conceptual distinction
between the study of emotions expressed by music versus emotions induced by music.
Emotions expressed by music are those emotional qualities that listeners perceive in a musical
piece, whether or not they themselves have an emotional response.
I'm going to play two short musical passages for piano and clarinet, and you try to decide
which expresses sadness and which expresses joy.
Here's the first passage.
And here's the second passage.
It's likely that you felt the first passage expressed sadness, and the second joy, and
not vice versa.
These passages were composed for this course, so I can be sure you weren't basing your
judgment on associations you had with these particular pieces of music.
In research studies that use music like this, most people judge the first type of music
as expressing sadness, and the second type as expressing joy.
And the important point is that they can make these judgments independently of how the music
makes them feel.
One person might be moved to sadness by hearing sad-sounding music, but another might not.
But these individual differences in the emotions induced by music don't need to stop us from
researching how music expresses emotion.
There is enough consistency in people's judgments about the emotions expressed by music to justify
scientific research.
Of course, if you think about it, this consistency is not all that surprising.
An entire industry depends on it.
Composers of film music count on audience consistency in understanding the emotions expressed by
music.
If a film composer writes a piece of music for a suspenseful scene, and wants the music
to express anxiety, they're going to be sunk if some people perceive it as joyful, and others
perceive it as sad, and others perceive it as humorous.
A film composer is essentially doing applied music psychology, using music to express emotion
in a way that complements the images on the screen.
Of course, emotion isn't the only thing music expresses.
Music can express other things, like character.
Think of the themes that accompany movie heroes or villains.
Those themes express something about the character of those people, adventuresome and brave,
or ominous and unstoppable.
Purely, instrumental music can express other things besides emotion.
Lush violins can express beauty, organ music can express religious faith, the sound of
a banjo can express American country life, and so on.
Our focus in this lecture, though, will be on emotions expressed by music.
And the main question we'll examine is how does music express different emotions?
For example, what makes a piece of music sound sad, or joyful, or angry?
The study of how music expresses emotion will bring us into contact with two themes that
will come up repeatedly in this course.
The first is the concept of multiple simultaneous mechanisms.
Much of the psychological richness of music comes from the fact that it simultaneously
activates multiple distinct processing mechanisms, some of which rely on brain regions well outside
of traditional auditory processing areas.
We've already seen this once when we discussed how people recognize a transposed version
of a melody as similar to the original version.
This involves not just auditory regions but also a region of the parietal cortex, which
also plays a role in visuospatial processing.
This could help explain why listening to music so often is associated with a subjective
sense of movement.
The perception of emotions expressed by music is another good example of multiple simultaneous
mechanisms.
As we'll see, perceiving the emotions expressed by music relies on at least three distinct
kinds of processes.
The second theme that will come up repeatedly is connections between music processing and
language processing.
I'm speaking now about relations between the processing of purely instrumental music,
music without words like the sound examples I played earlier, and the processing of ordinary,
day-to-day spoken language.
The idea that music and language share important cognitive operations is one that I've explored
a lot in my own research and writing.
A metaphor that helps illustrate the idea is a Venn diagram in which the two circles
represent the cognitive operations underlying music processing and language processing.
The overlap between the sets represents the subset of processes shared by the two domains.
Now, it's obvious there must be some sharing of brain processes by music and spoken language.
They both use the auditory channel for communication.
The real question is how much overlap there is in the mental foundations of these two
abilities.
One view is that the sharing is minimal, and just reflects the fact that they share a common
subcortical pathway for basic sound analysis.
That's the set of auditory processing structures between the ear and the cerebral cortex.
We know that the brain uses the same circuits in these brainstem and midbrain areas to analyze
basic acoustic features of speech, music, and any other type of sound, such as environmental
sounds.
But it's possible that in the cerebral cortex, where more complex cognitive processing takes
place, there could be minimal overlap in the circuits that process music and language.
This is perfectly reasonable.
Music and language are obviously different in many important ways.
Their sound patterns are different.
No listener would ever confuse instrumental music with spoken language.
Music and language are also very different ways of communicating human thoughts.
Language can refer to specific things in the world or to very specific concepts and
make propositions about them, like, I like the way that pomegranate sauce tasted with
the roasted chicken.
Instrumental music can't do that, but it can do other things that ordinary language
can't do.
Victor Hugo once remarked that music expresses that which cannot be put into words and that
which cannot remain silent.
Music can capture the complexities and dynamics of our inner emotional worlds in ways that
language simply cannot.
Going back to our Venn diagram, the idea of a minimal cognitive overlap between music
and language would be represented by minimal overlap between the circles of the Venn diagram.
This is plausible, but based on my own research and that of many of my colleagues, I believe
that this isn't the right picture.
I think there is significant overlap between the cognitive mechanisms of music and language
processing in the cerebral cortex.
Now why would that matter?
Well, two reasons.
First, if there are important shared cognitive mechanisms, then these mechanisms are likely
to be fundamental to how humans communicate with each other, and we have two pathways
for exploring them, a path through music and a path through language.
Second, if music and language have significant cognitive overlap, this means we may be able
to use music training to impact language processing.
A topic we'll take up later in this course.
Let's explore the idea that music and language processing have significant overlap in the
mind by focusing on how music expresses emotion.
How might this topic be connected to language processing?
Well, like music, speech is another sound pattern that can be used to express emotions.
When we speak, we don't just convey words and phrases, we convey attitudes and emotions
by the way we say those words and phrases, the pace and loudness of our voice, the way
pitch moves up and down, the rhythm of our syllables, and the way we articulate our speech
sounds all work together to express an emotional tone.
These elements of language are called speech prosody.
As listeners, we're sensitive to the emotions expressed by speech prosody.
We know when someone sounds happy or angry from the way that they talk, not just from
the words that they say.
If we can see the person, we also get cues to emotion from their facial expressions and
their gestures, but we can perceive emotions from just speech prosody, like when we're
talking to a friend on the phone.
And of course, we can perceive emotions in non-speech vocal sounds like laughter or crying.
The kinds of emotions that are most clearly expressed by speech prosody are what psychologists
call primary emotions or basic emotions.
These are thought to be ancient and universal emotions like happiness, sadness, anger, and
fear, which have a strong biological basis and have analogues in the emotions of other
animals.
These basic emotions can be contrasted with secondary or more complex emotions that depend
more on culture and learning, emotions like jealousy or guilt.
It's harder to express these secondary emotions by the way you say something, conveying them
depends more on the actual words you say or the actions that you make.
We believe that the basic emotions have a long evolutionary history.
Darwin wrote an entire book arguing that we share basic emotions with other species, the
expression of emotion in men and animals, published in 1872.
He was primarily looking at things like body postures and facial expressions associated
with different emotions in humans and other species.
Recent biologists like Yac Panksep and Joseph Ladoe have supported this idea with research
that looks at similarities in the neuroanatomy and neurochemistry of basic emotions in different
mammalian species.
So when we express basic emotions with speech, we're likely tapping into ancient emotional
circuitry with our evolutionarily modern language system.
One line of evidence that supports this idea is that the way basic emotions are expressed
through speech is much more consistent across languages than many other aspects of language.
If you go to a foreign country and overhear a conversation, you may not understand a single
word but you may have a good guess about the emotions being expressed by the speakers because
the way they use prosody to express emotion is not that different from the way speakers
of English or any language use prosody to express emotion.
In the language sciences there's been a lot of interest in how different emotions are
expressed through speech.
Researchers have done detailed sound analyses of voices expressing different basic emotions
like happiness or sadness and have found some consistent acoustic cues that distinguish
different emotions.
Happy sounding speech tends to be relatively fast with medium to high loudness, have a
high average pitch and wide pitch range and a brighter sound and a crisp articulation and
emphasizes upward pitch movements.
Sad sounding speech is slower and quieter, lower in average pitch with a narrow pitch
range and a darker sound quality and duller articulation and emphasizes downward pitch
movements.
In 2003 Patrick Yuslin and Petri Lauka published a landmark study which provided strong support
for the idea that speech and music communicate emotion in similar ways.
They reviewed many acoustic studies of emotion expression in speech and music and found a
remarkable degree of correspondence in the acoustic cues to basic emotions in the two
domains.
For example those same cues I listed a moment ago as characteristics of happy and sad sounding
speech are also seen in music that listeners judge as sounding happy or sad.
Let's listen again to the clips of joyful versus sad sounding music that I played earlier
in the lecture and this time think how these sounds which no one would ever confuse with
speech share some of the acoustic characteristics of happy and sad sounding speech.
Here's the joyful sounding music.
And here's the sad sounding music.
Now let's play two more sound examples which have also been composed for this course.
We've heard examples of music that expresses joy and sadness.
Let's consider two other basic emotions, anger and fear.
Which one do you think this might represent?
How about this one?
The first example was meant to express anger and it had some of the same acoustic features
that make a human voice sound angry.
Fast tempo, high intensity and great energy, high and varied pitch and fast attack times.
The second was meant to express fear and again it had some of the characteristics that make
a voice sound afraid like fast tempo, soft dynamics with much dynamic variability, little
pitch variability and rising pitch contours.
These examples were composed with basic emotions in mind to help clearly illustrate how music
can express emotions.
In real music basic emotions are often expressed in ways that aren't so basic.
Music can express different shades of a basic emotion like sadness just as a painter can
use different shades of a basic color like blue.
Music can also express different intensities of basic emotions like joy just as a painter
can choose the intensity of a particular hue.
And music can blend cues to different basic emotions which allows for more complex emotional
expressions than just the basic emotions.
By varying the shading, intensity and blending of basic emotions, music can express emotions
that are rich and nuanced and not simply captured by basic labels like happiness or sadness.
Let's listen to a full minute from a real piece of music now and try to think about
the emotions it expresses.
Music
Music
That was a piece of music composed by our course composer, Jason Carl Rosenberg, which
he wrote in 2002 for his sister's wedding.
When I ask my students what emotion this piece expresses, I don't get simple labels like
happiness or sadness.
I get complex labels which often blend different basic emotions to yield complex composite
emotions like nostalgia.
That's a nice example of how music goes beyond speech prosody in its ability to convey emotions
with sound.
Unlike speech prosody, music can simultaneously express a blend of different basic emotions
producing something closer to the complex inner feelings that we have but which we can't
express with speech prosody alone.
When Jocelyn and Lauka published their paper, they made an interesting suggestion.
They suggested that one distinct way that music uses those cues is that it makes them
stronger than emotional cues that occur in ordinary speech.
For example, happy speech has limits on its tempo and volume and pitch range because of
physical limits on the human voice.
Musical instruments can go beyond those limits.
They can take some of the same cues that make a voice sound joyful and make them stronger.
Jocelyn and Lauka suggested this make instrumental music a kind of super expressive voice from
the standpoint of brain processing.
That is, even though a listener consciously knows a piece of instrumental music is not
a human voice, at some level of brain processing the sound is being analyzed as a voice, but
a voice with powers of emotional expression that far outstrip anything a human voice could
do.
I think this is a neat idea.
It could help explain why we're so attracted to the sounds of musical instruments.
This attraction could be based on an inborn attraction to the sounds of human voices,
and our natural tendency to be sensitive to the emotional qualities of those voices.
But apart from the intuitive appeal of the idea, is there any real evidence that we perceive
emotions in music and in voices using similar brain mechanisms?
Well, one interesting line of research that is consistent with the idea comes from cross-cultural
studies of the perception of emotion in music.
We know that musical traditions vary enormously around the world, and if the way emotion was
expressed also varied enormously, then you would expect that people from one culture
would not be able to perceive accurately emotions expressed in the music of another culture.
Can people accurately perceive emotion in culturally unfamiliar music?
In 1999, Lorelie Bulkwell and William Ford Thompson published a study in which Western
listeners were presented with excerpts of North Indian classical music.
In this tradition, different melodic forms, or ragas, are said to express different emotions.
Listeners heard ragas meant to express joy, sadness, anger, or peace.
Even though they didn't know anything about Indian music, they were able to guess which
ragas were associated with joy, sadness, and anger, although they often confused peace
with sadness.
The key musical features that listeners seemed to be using in their judgments were features
related to how speech prosody conveys emotion, such as fast tempo and rising pitches for
joy and slow tempo and falling pitches for sadness.
This research is now one of several studies which show that people can guess the basic
emotion conveyed by culturally unfamiliar music, though they are not as good as cultural
insiders.
In each case, cues that can be related to speech prosody seem to play a role, which
makes sense, since voices convey emotions in similar ways across cultures.
The most direct evidence for overlap in the brain pathways that perceive emotion in music
and voices comes from brain imaging.
In an FMRI study published by a group in Montreal, Jorge Armini and colleagues found
that when people listened to either music or voices that expressed the emotion of fear,
a similar cluster of brain regions is activated, which includes the left amygdala, a deep brain
structure that's known to be involved in processing threat-related stimuli.
One thing that made these results so compelling is that individuals showed a correlation in
how strongly their amygdala responded to expressions of fear in music and in the voice.
I don't think any of these listeners would ever consciously confuse the sound of music
with the sound of a human voice, but parts of their brain are subconsciously confusing
the two sounds when it comes to analyzing their emotional qualities.
My favorite piece of evidence for a link between perceiving emotion in music and voices comes
from a study of six-year-old children.
If music and speech prosody convey emotion in similar ways, then it's possible that
musical training would enhance sensitivity to emotion and speech.
A team led by William Ford Thompson explored this idea by doing an experiment in which
children were randomly assigned to weekly training in piano, weekly training in drama,
or to no special training for a year.
Choosing drama training as one experimental condition was smart because drama training
explicitly trains children to use their voices to convey emotion.
After a year of training, they found that children who had studied piano were as good
at perceiving emotions in spoken voices as children who had studied drama, and both were
better than children who had no special training.
Music training enhanced an aspect of language processing that hadn't been directly trained.
We'll come back to this point later in the course when we focus specifically on some
of the cognitive benefits of studying music.
We've seen that cross-cultural studies, brain imaging studies, and experiments on musical
training in children all support the idea that one of the ways instrumental music expresses
emotion is by using acoustic cues shared with emotional voices.
But this isn't the only way music can express emotion.
Going back to our theme of multiple simultaneous mechanisms, I want to turn down the three
other ways that music expresses emotion.
The first of these was suggested independently by two philosophers, Stephen Davies and Peter
Kivi in 1980.
They suggested that music's emotional expressiveness is based on a perceived resemblance between
how music moves and human, nonverbal, expressive behavior.
Think of how a happy, cheerful, confident person walks.
Steps are quick or bouncy, eyes are bright, and the face has a smile.
A sad person moves much more slowly, eyes are dark and downcast, and the facial expression
droops or sags.
Now think back to our musical examples expressing joy versus sadness.
And listen to these one last time.
I think you'll find easy to sense a resemblance between the musical expression of emotion
and these human expressive behaviors.
Here's the joyful example.
And the sad example.
One neat thing about this theory, which is called the contour theory of musical expressiveness,
is that it emphasizes how we tend to perceive emotion in things that resemble nonverbal human
expressive behavior, even if those things are inanimate.
For example, if I ask you, what emotional state does this tree express?
Happiness or sadness?
I think you'll be likely to choose sadness.
We even call this tree a weeping willow.
We name it as if it were expressing emotion.
We perceive an emotion in this tree's structure because the tree's shape resembles some aspects
of human expressive behavior, like the sagging, drooping look of sadness.
Stephen Davies suggests that it's our strong human interest in the emotions of others that
leads us to read expressiveness in a willow tree and in other inanimate objects that
just happen to resemble the way human bodies express emotions.
So now we have two different ways that music can express emotions, with acoustic cues that
resemble speech prosody and via resemblances to human nonverbal expressive behavior.
These two ways are the most likely to cut across cultural boundaries because the way
voices and bodies express emotion has a deep biological basis that cuts across cultures.
But of course there are culture-specific aspects to how music expresses emotion, which aren't
obvious to cultural outsiders.
We'll discuss two.
Music can express emotion through the ebb and flow of tension in music.
All over the world, music is structured in ways that, at certain points, listeners perceive
a sense of tension, a sense that the music must continue before coming to a resting point.
Listen to this opening ten seconds of Franz Liszt's Hungarian Rhapsody No. 2 and notice
how in the middle there's a strong sense of tension which is finally resolved at the
end.
The ebb and flow of tension is central to music all over the world.
We can think of it as a kind of emotional expression that's very dynamic.
It unfolds in time, giving music a kind of emotional narrative that can reflect the way
our own emotions unfold over the course of a day, though music can make this happen over
just a few minutes.
Different musical traditions create tension in different ways.
In Western European music, harmony plays a big role.
But not all musical traditions have harmonic structure.
New traditions might use greater or less degrees of acoustic consonants or dissonance,
or melodic complexity, or other features to create tension and resolution.
This means that a cultural outsider is much less likely to pick up on these cues to emotion
because they are more culture-specific.
Finally, there are conventional associations between aspects of musical structure and expressions
of emotion.
For example, the philosopher Peter Kibbe has suggested that in Western music we have come
to perceive minor keys as expressing darker moods, like sadness or seriousness, purely
by conventional associations, not because those keys intrinsically reflect dark moods.
Conventional associations can be psychologically powerful and shared by many listeners.
Early pioneering work on how music expresses emotions in the 1930s by the psychologist
Kate Hevner included experiments in which the same piece was played in a major or minor
key, while everything else about the piece was kept constant.
When people rated the emotions expressed by the different versions, there was a lot of
consistency in rating the minor key version as more somber.
Let's listen to this kind of manipulation, and you can judge for yourself if you get
this kind of impression too.
Many would judge the minor key version as sounding sadder than the major key version,
and most are able to make this judgment without any feeling of conscious effort.
You perceive the emotional quality automatically and quickly.
This could lead to the sense that this is an unlearned instinctive response.
But that's an illusion.
If you're a native speaker of English, you're understanding my words right now without any
conscious effort, but you had to learn English.
Similarly, children seem to learn the minor key expresses sadness.
This has now been shown in several studies, including one published in 2001 by Simone
D'Alebella and colleagues.
They asked children from ages three to eight to judge if a musical piece sounded happy
or sad.
The children listened to a musical excerpt and then pointed to a happy or sad face to
indicate the emotion the music expressed.
Researchers manipulated the musical key of a piece and kept other things constant.
Six to eight-year-olds classified minor key versions of a piece as sounding sadder than
major key versions.
But the five-year-olds didn't show this pattern.
The five-year-olds classified slow tempo versions of pieces as sounding sadder than
fast tempo versions.
But as you'll remember, tempo is a cue to emotion that is shared by music and speech,
whereas the use of major and minor musical keys is unique to music.
Taking a step back, we've looked now at four ways that purely instrumental music can express
emotion.
Through acoustic cues that resemble emotional voices, by resemblances to nonverbal human
expressive behavior via patterns of tension and resolution and via conventional associations.
The first two of these, acoustic cues and nonverbal human behavior, are more cross-culturally
consistent than the third and fourth patterns of tension and resolution and conventional
associations because they're more deeply rooted in our shared biology.
We can now see why the old saying that music is the universal language of emotion is really
only half true.
Some of the ways music expresses emotion do cut across cultures, and some don't.
This is one of the insights we can get by thinking of music not as a single mental phenomenon,
but as a way of communicating that uses multiple simultaneous mechanisms to connect human minds
in rich and intricate ways without using language.
