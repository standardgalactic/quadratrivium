Economists, sociologists and other social scientists have uncovered a variety of situations in which people face a choice where the outcomes are objectively the same,
but people react in different ways depending on how the choice is described or framed.
Here's an example. Ever been buying gas or maybe at a store and you see a sign that says something like 2% off if you pay with cash, not a credit card?
Now here's a question, how did you feel about that? Maybe you decided to use cash, maybe you just paid with a credit card, it didn't bother you much.
But now imagine you were at a gas station or a store and I bet you've never been in a place where it actually said this, here's the price, if you pay with a credit card, add 2% more.
Why the difference?
There's actually some history here. When you pay with a credit card, the card company gets a little slice of the price in exchange for handling the transaction.
Back in the 1970s, when credit cards got popular, stores started wanting to say you had to pay extra for using the credit card because of the money that went to the credit card company.
Credit card companies reacted by saying if the store wanted to use their card, the store had to offer an identical price.
This issue eventually made its way up to Congress and eventually was resolved. The named price needs to be the same for everyone, but you can have a discount for cash.
What that solution recognizes is that people find it okay to say money off for cash, even if they don't actually use that option, but they'll be quite peeved if it says additional cost for credit cards, even though those two things mean the same thing.
Here's another example of how framing a situation alters how one thinks about it.
Say you're really sick and you go to the doctor and the doctor says, well, you are really sick, but there's a potential therapy.
I can tell you that out of every 100 people who try this therapy, 90 are still living after 5 years.
So how do you feel about that doctor's answer? Mull that over for a second.
Now, alternative way of phrasing the situation.
Say you're really sick and you go to the doctor and the doctor says, well, yes, you are really sick, but there's a potential therapy.
And I can tell you that out of every 100 people who try this therapy, 10 are dead after 5 years.
How do you feel about that answer?
Now, of course, saying 90 out of every 100 are alive after 5 years is the same thing as saying that 10 out of every 100 are dead after 5 years.
It's exactly the same information just framed differently.
But patients who get information which emphasizes that the cup is 9 tenths full are a lot more likely to go ahead than patients who get information that the cup is 1 tenth empty.
And in fact, this same bias shows up when surveys along these lines are given to health care providers, even though you would think they would recognize the equivalence of these two kinds of statements.
Here's another example involving taking a risk.
One group is asked, in addition to whatever you own, you've been given $1,000.
And now you have a choice.
The choice is between choice A, which is a 50-50 gamble.
Keep the original 1,000, don't get anything else, or add an additional 1,000, that's choice A, or choice B is receive an additional $500 with certainty.
Do you choose the safe gain or the 50-50 gamble?
When a study based on this question was published, only 16% chose A.
That is, an overwhelming majority chose getting the extra $500 with certainty, not the 50-50 gamble of maybe ending up with 1,000 or maybe ending up with 2,000.
Now, a different group is asked.
In addition to whatever you own, you are given $2,000.
And you are now asked to choose between two choices.
Choice A is a 50-50 chance of losing 1,000 or losing zero.
And choice B is losing $500 with certainty.
Which do you choose?
Well, when this study was done, 69% chose the 50-50 gamble of potentially losing $1,000.
Only a minority less than a third chose the sure loss of 500.
Now, here's the kicker if you haven't already perceived it.
In the first situation, remember you started with $1,000.
Choice A had a 50% chance of ending with 1,000 and a 50% chance of ending with 2,000.
Choice B, the $500 additional gain for sure, gets you 1,500 with certainty.
The second situation, you started with 2,000.
Choice A had a 50% chance of ending with 1,000 and a 50% chance of ending with 2,000.
And choice B, the 500 loss for sure, got you $1,500 with certainty.
In other words, the outcomes of all these choices are identical.
But when you phrase the choice as starting from 1,000 and having a sure gain of $500, people go for it.
When you phrase the choices starting from 2,000 and facing a sure loss of $500, then people would rather gamble.
These three examples I just gave, that is discounts for cash instead of credit, do 90 live or 10 die,
whether people choose the sure thing or the gamble, they all have a common factor.
They all involve a choice between whether something is phrased as a positive or as a negative,
as a gain or a loss, as the glass being half full or half empty.
The last two examples in particular draw on the work of two authors,
Daniel Kahneman, who spent the later part of his career at Princeton University,
and Amos Tversky, who was at Stanford University when he died in 1996.
Kahneman and Tversky started writing about these topics back in the 1970s and developed what is called prospect theory.
I can describe this approach in several ways, but let me emphasize just two key components here.
The first component is called loss aversion.
And that's the argument that people dislike losses more than they like gains of equivalent size.
The second component is called reference dependence.
And the idea of reference dependence is that preferences are related not just to how much you end up with,
but to looking at some reference point and comparing where you end up with to that reference point.
Often the status quo might be a reference point.
Now you can consider these two separately, but to some extent they go together.
The starting point, which uses a reference point, could determine whether you see the outcome as a gain or a loss.
If your reference point is an empty glass, a half full glass looks good.
If your starting point is a full glass, then a half full glass looks bad.
One is a gain, one is a loss, but the final outcome is a half full glass either way.
If we want to explain why people react when an identical situation is framed in different ways,
prospect theory argues that loss aversion and reference points help to give an explanation of why this matters.
Famous paper with this argument was published in 1979 by Kahneman and Tversky,
and it's one of the most highly cited papers in economics over the last 40 years,
maybe one of the most highly cited papers in all of the social sciences.
Kahneman won the Nobel Prize in Economics in 2002, even though he's actually trained in psychology rather than in economics.
His Nobel Citation said to Daniel Kahneman,
for having integrated insights from psychological research into economic science,
especially concerning human judgment and decision making under uncertainty.
Tversky would quite likely have shared the prize, but he died in 1996,
and one of the rules of the Nobel Prize is it only goes to living people.
But after Kahneman won the Nobel Prize, he made one of the nicest comments about a colleague and a co-author I've ever heard.
Kahneman said,
Amos and I shared the wonder of together owning a goose that could lay golden eggs,
a joint mind that was better than our separate minds.
If you're wondering or doubting whether this kind of thinking about human decision making
isn't really what economists do or isn't really about economics,
when this kind of work is well established enough to win Nobel Prizes,
it's obviously pretty close to the central knowledge of the field.
Let's talk about some of the ways in which framing issues that involve loss aversion and reference points
manifest themselves in economic decision making.
Let's start off with loss aversion.
Again, loss aversion is the principle that many people have preferences
such that if they face a possible gain and a possible loss of equal size,
their pleasure in the possible gain is less than their displeasure at the possible loss.
One way this comes up is in situations where you consider selling something
and taking a loss on your investment.
With stocks, this is sometimes called the disposition effect.
It's a lot easier for investors to sell stocks that have gained in value
compared to those that have lost in value.
There's sort of a weird belief that if you don't sell the losers,
then you haven't really lost yet.
You could still make it back in the future.
Now, this doesn't make any sense as an investment strategy.
You need to come to your investments with a fresh eye each day,
not stuck in what's happened in the past.
A cold-blooded look at reality says if the price went down of your stocks,
you've taken a loss.
Now think about what's going to happen in the future.
It's also a little bit odd because if you sell the losers and take a loss,
this would let you offset some gains on your income tax.
If you only sell gainers, you end up paying more in tax
than if you also sold some offsetting losers.
There's also some interesting evidence that when stocks are rising,
people are much more likely to track their portfolio on the Internet.
When stocks are falling, people don't look.
Again, a rational person would presumably pay roughly equal attention
because every day is a new day.
Another example of loss aversion that's sadly relevant to so many Americans
in the last few years involves selling a house at a loss.
With loss aversion, when you're selling a house,
you just want to avoid taking a loss.
You tend to think about that price you're asking relative to the price you paid.
It's mentally very difficult to ask for less.
For evidence on this point, you can look at houses on the market
and look at what they're asking for the house compared to what people bought the house for.
You can do statistical adjustments for the size of the house,
the number of bedrooms and bathrooms, the neighborhood, the lot size,
all those kinds of things.
When you do that kind of study, what you find is those who paid more for the house
and those are often people who bought the house more recently
also tend to ask more for their houses.
When prices fall, it's just much harder for people to sell at that lower price.
Another example of loss aversion arises when people buy insurance against small risks.
The economic purpose of insurance is to be protected against large but only occasional expenses.
It makes sense to have insurance against big events that happen rarely.
It doesn't make sense to have insurance against, say, needing to cut my grass
or needing to buy a new pair of pants.
Those are just regular expenses that are part of life.
However, loss averse people can be enticed to buy insurance against very small risks,
which are actually quite similar to the regular expenses that are just part of life.
And selling that kind of insurance tends to be a solidly profitable product
for those who can sell it.
An example is with homeowners insurance.
When you choose a deductible for your homeowners insurance policy, you have a choice.
A higher deductible means lower insurance premiums every year,
or a lower deductible means higher premiums each year.
A loss averse person will tend to choose the lower deductible and higher premiums
so they won't have to worry about that extra loss they might be facing.
A study a few years ago looked at the patterns that resulted.
The study found that 83% of home insurance customers choose home insurance deductibles
below $1,000. The typical homeowner chooses a $500 deductible.
Now, if you were to choose a $1,000 deductible instead of a $500 deductible,
you actually can end up saving $100 a year of additional insurance premiums each year.
About 5% of homeowners make a claim above the deductible amount each year.
So, if you think this through, in a year, having a $500 deductible instead of a $1,000 deductible
gains you about $25 a year on average.
That is, you have a 5% chance of paying $500 less and 5% of $500 is $25.
So, on average, you're paying an extra $100 a year for the lower deductible
and on average, you're getting back about $25 a year.
This is not a good deal unless you are an exceptionally loss averse person.
This same pattern of looking for insurance for low expenditures
applies to a lot of the warranties you can buy for consumer electronics and appliances.
Or the insurance you can buy when you buy a home that if something goes wrong,
they'll fix it for you.
The extra insurance you can get when you rent a car and so on and so on.
These are good products for loss averse people,
but they're products that make a lot of money for those who sell them.
Now I want to shift over to the other big part of prospect theory,
thinking about reference points.
And again, a reference point refers to the fact that many people make comparisons
with an implicit starting point.
As one example of how reference points work,
think about workers who have some flexibility over their hours and effort.
A common example is taxi drivers.
And how much those people will work in a day.
Think about the job of taxi driver for a moment.
There are going to be some days, some times,
when there are lots and lots of customers.
Maybe there's a big convention or event in town,
maybe there's bad weather.
There's other times when business is slow.
And you would think that if you were a taxi driver,
it would make sense to work a lot extra on the days with lots of customers
and take some time off on the slow days.
Instead, taxi drivers in studies in New York City at least,
seem to have a sense of how much they expect to make in a day.
That's their reference point.
If they make that amount pretty quickly on a good day,
they stop or they slow down.
If they earn that amount only slowly,
they keep going until they get it.
They adjust to their reference value of what they expect to earn,
not to the level of demand for taxi cab services in that day.
There is another study done on bike messengers in Zurich,
which found similar results.
The interesting thing to me is that we really all have a bit of this in us.
Some days you can imagine you're getting just a ton done.
Things are going really, really well.
Are those the days you stay late because you're really on a roll
and you really want to work extra?
Other days, things might be going really badly.
Is that the day you knock off and head for the beach
or the health club or the sofa?
Or do you sort of aim in some mental sense
to get about the same amount done each day,
and internal quota some reference point of what is enough
and just adjust to that level?
Status quo bias refers to a situation
where the reference point is the current situation.
Some examples from, say, questionnaire studies
help to illustrate the point.
Say you face a hypothetical situation.
You've inherited X million dollars from an uncle.
How would you invest it in stocks, bonds, cash, real estate, and other choices?
Now, you give the people another group a similar survey,
but this time it says you've inherited X million from an uncle
and it's currently invested in stocks.
Now, how would you invest it?
Or you've inherited X million from an uncle
and it's currently invested in real estate.
How would you invest it?
It turns out that how you received it,
if you say how the uncle had it invested,
has a strong effect on how you would invest it.
Well, why should that be?
I mean, why should your preferences be the same as your uncle's?
Why shouldn't you choose what you want?
Because we're adjusting to a reference point.
In this case, there's bias toward the status quo.
There's a study in California which offered consumers
different mixtures for the reliability of their electrical service
and the rates that they paid.
They found out that in the offered a questionnaire of choices,
if they designated any one of the choices as the status quo,
then all of a sudden that particular choice became much more popular.
And one other interesting example happens
with the American Economic Association,
which publishes the economics journal that I edit.
In the past, it used to be that if you were a member of the association,
you got my journal as part of your membership.
Now, the economic association has seven journals
and the new rule is you can become a member of the association
and not get any of the journals.
If you want any of the journals,
you have to check them off and pay extra.
Of course, you can access them online if you want.
You can imagine an alternative here.
Maybe getting all seven journals is the default option,
but you could opt out and get a refund.
Should it make a difference if the status quo is to get them all,
but you can opt out, or the status quo is to get none,
but can opt in?
It probably will make some difference,
but economists are actually pretty attuned
to thinking about these kinds of framing issues.
A standard finding in looking at marriage
is that those who live together before marriage
are more likely to get divorced sooner.
There's been a lot of controversy over how to interpret this fact.
It could be, for example, that those who live together before marriage
are, for some reason, less committed to marriage
as an institution in the first place,
which is why they end up more likely to divorce.
But I suspect a stronger reason
is that those living together before marriage
are more likely to marry
than if they had lived apart because of status quo bias.
If they continued to live apart,
some would have broken up without marriage.
But when living together, status quo is living together,
and a greater share of them will tend to marry
and then end up later getting divorced.
A reference point can also be,
as we were talking about a moment ago,
what arises as a default option.
That is, a default option is what happens
if you don't take any further action.
There's some intriguing evidence here from employers
who offer different kinds of savings plans to employees,
which suggests the power of default options.
Whether the default choice is to be in the savings plan
or the default choice is to be out of the savings plan,
turns out to make a big difference,
even if it only takes a phone call to switch between the two.
A group of economists studied a company
that ran the following experiment.
They had a 401k retirement plan for their employees,
and in this company, the employer offered a 50% match
up to 6% of the income contributed by an employee.
You could switch to participating
or not participating at any time
just by making a phone call.
Now, they split up the employees
and did this at random, actually.
One bunch of employees had the situation
where if they don't do anything,
they're not enrolled in this retirement plan.
And after a year, 49% of them were enrolled.
They'd made the phone call and changed.
The second group was the default was
if you don't do anything,
you're automatically enrolled in the program.
And a year later, 86% of those employees
were enrolled in the savings program.
Only 14% had made the call not to be enrolled.
Now, remember, it only took a phone call to switch.
Whether you participate in your employer's savings plan
is a huge life decision.
If you don't do it, it's possible
that you can mess up and not save much
in a way that will affect your entire retirement
and your working life.
A lot of the time, this is not the choice people want.
But remember, only about half signed up
if it wasn't the default option,
and 86% were signed up
if being in the program was the default option.
The default option, what is viewed
as the status quo choice,
can make just an enormous difference
in people's actions.
The existence of framing through loss aversion
and reference points
and other frames that have been discovered and discussed
makes a big difference.
Some of the other frames might relate to things
like limited attention or how people think
when risk and probability are involved.
All of these are examples of the idea of behavioral economics,
a term that was introduced in an earlier lecture,
which basically means bringing insights from psychology
over to the economics literature.
Framing poses a problem for the basic approach of economics.
Remember, the basic approach of economics
is people look at the trade-offs they face
and they try to make the choice they prefer.
But framing suggests that people don't see
the choices in front of them very clearly.
Instead, they're reacting to unimportant
or non-essential parts of how the choices are phrased.
In some cases, if they had the frame explained to them,
they'd feel as if they'd been tricked
or had made the wrong choice.
They wished they'd faced the question framed in a different way.
If people are going to make choices
based on how a question is framed,
then an obvious question becomes,
who determines the frame?
Will some frames end up making people happier than others?
There's no way of avoiding, for example,
that in many situations,
something is going to be the status quo,
something is going to be the default option,
something is going to be the reference point.
You just can't avoid that.
The only question is,
how will those defaults or reference points be determined?
So, this raises the possibility of public policy
that influences the frame you face.
Two economists from the University of Chicago,
Richard Thaler and Cass Sunstein,
wrote a book about these kinds of policies in 2008.
The book was called Nudge.
It's a nice word, nudge.
It sort of captures the idea
that you aren't really giving people a special incentive
to do something like a tax break,
and you aren't passing a law that has an absolute requirement.
You're just setting up the situation,
so there's a nudge to a certain kind of desired behavior.
In fact, one of these authors, Cass Sunstein,
took a leave to be an appointee of President Obama
and head the White House Office of Information and Regulation Affairs,
like the title says.
That's an office that helps develop policies
about what information is collected
and what regulations are passed for the whole U.S. government.
Perhaps the most powerful example of a nudge policy
is the one I mentioned already.
Whether you default into a rule
that companies need to offer a savings program,
unless the employee opts out,
employees could also say default into savings accounts,
and you can imagine a series of related policies
that might spell out the default options further.
For example, you might default into having, say,
half of your future raises go into your savings account,
so you gradually save more over time
and don't notice it too much.
You could default into investing the money
in a big stock market index fund when you're young,
and then, over life, have that slowly default
into a gradual transition
to a safer kind of investment like bonds
as you get to middle age and approach retirement.
You could default into having, say,
half your retirement savings at the time of retirement
turned into an annuity, adjusted for inflation,
to make sure you had something that would last the rest of your life.
The point is that any of these are just default choices.
You would be allowed to change any of them
with a phone, call, or an email.
If you hate these options or you have special circumstances,
go ahead and change it.
But for the average person,
this might be a reasonable set of default choices
that they could face and would need any people
would just follow.
Also, if you do opt out, you choose not to participate
or take other risks with your investments,
or at retirement, you take all your money
in one big lump sum, no annuity, and you spend it all,
that's clearly your personal choice.
You would have had to go out of your way
to make that decision.
And so the policy response to those who opted out
might be a little less sympathetic.
You can start thinking about other options,
nudge options along these lines as well.
For example, what if the default choice is
your organs are available for transplantation
when you die unless you opt out?
That's instead of the usual,
you need to sign a donor card and opt in.
Or you can imagine a nudge policy which says
that filling out one college application
is a high school graduation requirement.
You don't have to send it in, you just have to fill it out.
You could also think about nudge policies
which try to change the reference points that people face.
For example, you could post statistics on college campuses
about how the majority of students
don't actually drink too much,
which could reduce the peer pressure
feeling that everybody does it,
which isn't actually true.
You could tell everyone the average energy use
of other homes in their area,
and that would help people figure out
if they were out of line in their energy use
to try to beat the average.
You could position food in a school cafeteria
to encourage healthier choices.
You could require every mortgage offer
to give the annual percentage rate
so it would be easier to compare
across all the different mortgages.
You could let medical patients sign a waiver
saying they won't sue for malpractice
and maybe hope to avoid some unnecessary treatments
and get more honest answers from healthcare providers.
These kinds of proposals are sometimes
called libertarian paternalism.
It's paternalism because government
or a big institution is making choices
about the default or the reference point.
They're libertarian because if you don't like
the default option or the reference point,
it's easy to do something different.
And this idea of liberal paternalism
is a hot new area for thinking about
what public policy can and should do.
We all react to how situations are framed.
In fact, our brains are probably hardwired to do so.
But when you know you're susceptible
to being manipulated by a frame,
an obvious step is to beware.
For example, framing is really common in politics.
A classic example is whether you think of the abortion debate
in terms of being pro-choice or pro-life.
Another example is if you label something as a right,
that has a lot of clout in American political terms.
Even though philosophers and economists
both will tell you that they say
right to freedom of thought
is a different concept from a right
to get a cost of living raise every year.
Another common phrase sometimes is
you don't care about X or you don't care about Y.
You don't care about the unemployed or the poor.
You don't care about high taxes.
You don't care about the budget deficit.
Of course, the truth is very rarely
that someone doesn't care about those things.
Instead in thinking about the costs
and benefits of different trade-offs,
their beliefs led to different priorities.
But that line, you don't care about X.
It's a frame that has a special sting to it.
A lot of politics, a lot of marketing,
is really about trying to frame debates in a certain way.
I just find that deeply interesting.
I sometimes think that in this post-modern era
in which we live, we're all more cynical
about being manipulated in these subtle ways.
And we're more on our guard, perhaps,
than people would have been 50 years ago
or 100 years ago against those sort of tactics.
But there's so many examples of using these kinds of labels.
Clearly, we aren't as mentally liberated
from framing effects as we might like to think.
So beware.
