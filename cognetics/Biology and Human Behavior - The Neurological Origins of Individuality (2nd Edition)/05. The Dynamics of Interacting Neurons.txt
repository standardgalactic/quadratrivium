Butcher 5 â€“ The Dynamics of Interacting Neurons
We are back and ready for more riveting edge of your seat neuroscience because we are leaving
the limited pedestrian world of two neurons behind us and moving up to three today.
Maybe even more than that, we are now accomplishing this ever expanding view of how the nervous
system works, now having moved from one neuron getting excited, two neurons talking to each
other, two neurons changing their talking to each other over time, potentiating a synapse,
now expanding to begin to see how networks of neurons work.
Essentially the reason why we have to do that is we've been dealing with a very simplistic
picture so far.
What we have on the top of this diagram is one neuron sending all of its projections
to the next neuron in line and that neuron in turn sending all of its projections all
10,000 axon terminals to all 10,000 dendritic spines of the next neuron just a straight line,
a straight cable.
This is boring.
This is incredibly limited.
This is what goes on in your spinal cord and this is the reason why your spinal cord can't
lecture for you.
This is a very simple aspect of wiring.
Once you get into the brain, once you get into an area where much more complicated things
are happening, you don't have this network pattern of single neurons in line.
Instead, you've got neurons sending projections, sending axons to a bunch of other neurons
which send to a bunch of others and back to itself and you begin to get networks.
And out of these networks, you can get very, very complex processes.
And what we'll see in this lecture is how some aspects of wiring, how some of these
networks are put together, how you can begin to get function coming out the other side.
Okay, we start with the first example and we go back to our limited world of the past
back to two neurons but we introduce a new element into this which is a new thing that
the axons can do.
You'll note here we've got our typical old neuron sending its axon to the next neuron
in line, that old world of ours, but you will notice something different with this axon
of the first neuron which is it branches off.
It branches off and sends a big projection coursing backwards to, of all places, itself.
It sends a projection back onto itself, the neurotransmitter it's releasing onto the receptors
of the next neuron, the postsynaptic one.
The neurotransmitters there are excitatory, this projection back onto itself is inhibitory.
And this is what would be termed a recurrent collateral, a collateral of branching off of
the axon sending a projection back onto itself.
Why on earth would a neuron that's excited want to send a signal back to itself that's
inhibitory that turns itself off?
And what you have here essentially is a mechanism, a feedback loop, a mechanism to sharpen the
signal.
What do I mean by this?
Here we see on the right of the diagram showing when that neuron has action potentials.
And what you'll see is in the absence of any sort of external stimulus, every now and
then the neuron has a hiccup, has an action potential, that's something very different
than what I was telling you before.
Oh, neuron spent a fortune having this very restful resting state and being absolutely
silent.
It doesn't work perfectly.
Every now and then there's these spontaneous little action potentials.
But along comes the arrow here, some major stimulus on the system, and the neuron starts
firing like crazy.
And what you see is after a delay, finally that recurrent collateral kicks in and inhibits
that neuron.
What happens is after that burst of action potentials, you get a period of dramatic silence.
And what have you done?
This is the same principle we heard a few lectures ago, enhancing the contrast between
neuron being silent and a neuron being excited.
What you impose here is the silent period afterward.
That neuron has just told the world, I am done with this period of hyper excitation.
It's a way of sharpening the signal over time.
It's a way of getting more certainty that you're done with your signal.
Now this property turns out to be one that occurs all over the nervous system.
Neurons sending recurrent collateral back on themselves.
What you then see is an elaboration on this so that you can sharpen a signal not only
over time, but over space.
And here we have in this diagram a version of it.
These neurons, we've got a line of these, A, B, C, D, E. These five neurons which then
send their axons in parallel, these are all some sort of sensory neurons.
These are five photoreceptors in the eye sitting next to each other.
Or these are five neurons in your cochlea, hair receptive cells responsive to sound.
Or these are five neurons that respond to tactile information right next to each other.
So what happens?
You stimulate one of them.
You stimulate the middle one, neuron C, right in the middle of the stretch, somewhere in
the eye, whichever sensory system, you stimulate that neuron C.
It gets excited.
It starts getting its action potentials.
We've already seen what it does to itself.
It's got a recurrent collateral back onto itself, which means, as we saw before, it gets this
period of screaming its head off and then imposes that negative feedback loop, that period
of silence, you know exactly when that neuron has stopped its excitation.
But meanwhile, we have an additional piece of wiring.
And what we see here is, it also sends collaterals off to the neighbors on either side.
Neurons C inhibiting neurons B and D. Inhibitory neurotransmitter, what is it doing there?
It's turning off the neighbors.
The folks immediately to the side of it, the term given for this is lateral inhibition
What are you doing?
You are sharpening the signal in space.
Neurons C, by shutting down B and D, makes it absolutely clear it's this spot not one
a little bit over.
It's this spot of light not one a little bit over.
As we record from neurons A through E, you see the little bit of spontaneous action potentials
now and then.
Neurons C suddenly gets very excited.
And by shutting off B and D, you are sharpening the signal.
You are making clear where the local signal is coming through.
It's a way to sharpen over space and time.
So here we have no mistaking the fact that it's neuron C, not B or D, that's getting
excited.
And no mistaking the fact that neuron C has ended its message.
Self inhibition and lateral inhibition, both of these fabulous ways of sharpening a signal.
Okay, so that's one general property of all sorts of networks.
This business of sharpening signals.
We move now to another version of networks.
And this, as you'll see, is a far more complicated one.
This is, in lots of ways, the most exciting piece of neuroscience that was done in the
third quarter of the 20th century.
Amazing work.
It is canonical.
It is in every neuroscience textbook.
All of us neuroscientists love this work.
We worship the people who came up with it.
This was a fabulous piece of work showing how does your cortex process sensory information.
And this was work done by a pair of neuroscientists at Harvard at the time named Hubel and Wiesel.
And you cannot disconnect those names.
They're like peanut butter and jelly, Hubel and Wiesel, Hubel and Wiesel.
And this is just this amazing piece of work that goes together with these two names.
And these guys figured out how the cortex processes sensory information, or at least
everybody thought they did.
Here's what they showed.
Okay, we start off on the top of this diagram with a grid of neurons.
It just happens this grid is in the retina.
These are photoreceptors.
These are cells in the retina that respond to light.
And the way it works is in this grid, you can stimulate this neuron that will see this
dot of light, or stimulate the next one over, which sees the next dot of light.
You can do this, as Hubel and Wiesel did, with a very controlled pinpoint of light and
stimulate one single photoreceptor.
And what they found up in the cortex was the very first layer of the visual cortex that
got information from the eye.
Information from the eye.
We know what that means by now, which is the eye sends its projections, its photoreceptors
have its axons projecting up a couple of synapses away and gets into this first layer of the
cortex.
And what Hubel and Wiesel saw was something marvelous.
They would stimulate one photoreceptor, and as shown here, this one up in the left corner,
and one single neuron in that first layer of the visual cortex would get excited.
A point for point connection.
They would then shift the light over a little bit and stimulate the next photoreceptor over,
the next layer one neuron would get excited, move over, move over, point for point parallelism.
What is it that neurons in this layer one know about for a living?
They know how to recognize dots of light, and they are organized in these columns so
that these neurons respond to this moving line, and the next column over the next moving
line, these neurons are specialized to recognize little points of light.
Great.
Hubel and Wiesel take the weekend off, Monday morning they come in, and now they start stimulating
from layer two in the visual cortex.
In other words, layer one sends all of its axons into layer two, what's going on up
there?
And here it's something very different.
Back to the retina, they stimulate one single photoreceptor and one single neuron in the
first layer gets excited, nothing's happening in the second layer.
Now they shift over, they shift down to the next one, and the next layer one neuron gets
excited, nothing's happening in the second layer.
Next one, next one, down, down, down, and only when they've done a whole bunch of these
and a whole bunch of layer one neurons in succession, suddenly one of the layer two
neurons gets excited.
What do layer two neurons know about for a living?
They know about straight lines.
And what you would see is this neuron that is tuned to respond to a perfectly vertical
line, and next to it is a neuron that responds to a slightly less vertical one, slightly
less, slightly less, the next one over, over, over, until one that responds to a horizontal
line.
And what you see here is there's this hierarchy of extracting information, layer one knows
about dots, a whole bunch of them all together, gives information about a line.
Okay, so that took Hubel and Wiesel a bunch of years, and then they move over to the next
layer.
And the same exact logic, this one extracts information from layer two, this one gets
axonal projections from layer two, and you can begin to imagine how the wiring works.
What does this layer know about?
It knows about moving straight lines, moving straight lines at different angles.
What happens if you put a whole bunch of these together, you begin to get curves?
This was amazing, people love this stuff, Hubel and Wiesel were celebrated, they got
their Nobel Prize soon after this, and what everybody knew at that point is exactly what
happens next, which is you should be able to get to layer four, and layer four would
see a bunch of curves, and layer five would make them three dimensional, and you would
go 11 D layers up until you got to this super duper layer all the way up on top, until finally
you get a neuron that knows one thing and one thing only, had a response to the face
of your grandmother with her head at a particular angle.
And next to that, the next neuron responds to the same grandmother's face, the head at
a slightly different angle, next neuron over a slightly different angle, and finally a
whole column next to that that recognizes the face of your grandfather at different angles.
And this is what everybody expected, you go all the way up and you would find these super
specialized neurons that knew one thing, that responded to one thing and one thing only.
And literally what these neurons were called were gram other neurons.
The notion that these would be neurons, so many layers up in this abstraction of information
that you would get single neurons that were highly, highly specialized for recognizing
things.
Now fortunately for Hubel and Wiesel, they didn't go and look for these super duper gram
other neurons, they moved on to another area of research that was at least as interesting,
but everybody else went looking for them, and to this day, basically they haven't found
them.
And if you think about it, this actually makes sense.
Do some math here.
What you wind up seeing is a certain numerical constraint.
How many photoreceptors do you have in your retina, you got some large number of them.
How many neurons do you need in layer one?
You need one neuron there for every photoreceptor in the eye, one for one correspondence.
So you ask how many layer two neurons do you need?
Well you need one for a perfectly vertical line of a certain length and a perfectly vertical
line of a slightly shorter or slightly longer, and then one for a slightly less vertical
line of this or that length and a slightly less vertical.
You need like a hundred times as many layer two neurons as layer one.
And then up to layer three, how many layer three neurons do you need?
Well you need one that responds to a certain set of curved angles and one that responds
to a slightly different set of angles and slightly different and more this way and more
that way.
And once again, you need like a hundred times as many layer three neurons.
So wonder you don't have a layer four, you don't have enough neurons in your cortex.
And the whole field ran into a wall at this point because what became clear is, if you
think about single neurons knowing one fact and one fact only, all the way up in the cortex,
it can't work that way because you don't have enough neurons.
The whole field fell apart at this point, people were highly despairing, this notion
of single neurons specializing went down the drain and what became clear in retrospect
is the first two or three layers of the visual cortex worked like this.
The first two or three layers of the auditory cortex, layer one would recognize a single
note, layer two would recognize an interval of two notes, layer three would recognize
a chord, that's it.
And then it got into the great unwashed, undifferentiated cortex where it worked differently.
And what you had now entered was 90% of the cortex, which is called associational cortex,
which is a fancy way of saying we have no idea what it does.
But what you've got there is this whole point for point, one neuron knows one thing and one
thing only, went down the drain at that point.
And what this has ushered in instead is an entirely new field in neuroscience for looking
at how this stuff works, what are now called neural networks.
And a lot of this comes from the realm of computational neuroscience, computer models,
neural networks, essentially the way that this all works, or the basic notion is information
is not contained in a single neuron, information is not contained in a single synapse, potentiated
or otherwise, information is contained in patterns of excitation, in networks of excitation
where the same neurons can overlap in different networks and be used in different settings.
And it turns out this explains an enormous amount about how the nervous system works
and it has proved an enormously difficult thing to get after because it is very, very
complicated.
Let me give you an example of a wildly impossibly simplified neural network.
And here we have one, and you can trust me that none actually exists like this, but this
will give the idea.
We've got a neural network here consisting of two layers.
First layer has three neurons, second layer has five neurons, neurons A through E. And
what we've got is overlapping projections.
The first neuron down here in the lower layer sends its projections to A, B and C in the
second layer.
The second neuron in that first layer sends its projections to B, C and D. The third neuron
to C, D and E. What you can see here is there's partial overlap in each of these cases.
Okay, so what are these neurons about?
Layer one is an imaginary network layer, and this one has neurons that are Hubel and
Viesel-esque.
These are neurons that know one fact and one fact only.
They don't really work this way.
But suppose the first one is a neuron that responds to Gogam paintings, the second is
a neuron that responds to Van Gogh, and the third one is the one that responds to Monet.
So what's going on in the second layer?
What does neuron A know about?
In the second layer, who does it get information from?
Only the Gogan neuron.
It knows how to recognize Gogan paintings.
Meanwhile, neuron E only gets its inputs from Monet and knows how to recognize Monet paintings.
They're highly specialized.
What about neuron C?
Neuron C sitting there at the intersection of projections from all three of those neurons.
What does neuron C know about?
Neuron C is the one that knows how to recognize an impressionist painting.
Neuron C is the one sitting there saying, don't ask me the name of the painter.
Certainly don't ask me the name of the painting, but it's one of those impressionists.
It's not a Cubist.
It's not a Dutch master.
Neuron C knows information that it could only extract out of the individual cases.
Neuron C is at the center of the network where it gets that convergence.
And you look at neurons B and D, and they're both recognizing impressionist painting neurons
as well.
They're simply not as good as neuron C. They don't have as many examples to draw apart.
And in a very artificial way, that's how these networks work.
Let's give an example showing how we exploit these networks, showing that we're perfectly
conscious of this.
Now, this diagram shows an even more schematic version of a network, and it's the network
which has as its center a neuron that responds to the name of what's his name.
What was that guy?
I'm trying to remember that guy's name.
He was a painter.
He was a painter.
He was one of those impressionist painters.
He was always painting those Parisian women on the bars.
He wasn't Degas.
He was that short guy with the beard.
What was his name?
Oh, I had this junior high school art appreciation teacher who was always going on about him.
If I could remember her name, I would remember his name.
Oh, there was that time I was in the museum, and there was this really cute person.
And they liked this guy's paintings.
I had to pretend I did too.
Never got the person's phone number.
What was the...
There's this stupid pun about the tracks being too loose, too loose to the track.
And suddenly it comes popping out there, and this too loose to the track neuron, again,
which is hypothetical, this too loose to the track neuron is sitting there at the intersection
of your network of short guys, or your network of guys with beards, your network of stupid
puns, or your network, and sitting there at the intersection of them is that output.
And what are you doing there?
And you're sitting there saying, wait, wait, it was a lot of syllables.
It started with a tu sound.
There was this pun.
He was this short guy.
You're tapping into all these different networks.
What are you taking advantage of there?
Back to lecture number two, no single input is enough to pull out the guy's name.
You're trying to get summation, integration of all those inputs, and sitting there at
the intersection of those is the information popping out.
And what we've got here is a network in this dimension on this chart, and these same neurons
are part of another network that goes perpendicular to that and another at the intersection of
all of these.
This is how we pull memories out there.
We don't have a fact.
We have a fact embedded in context, and we are often trying to tap into enough pathways
to get that to pop out.
We all use that in everyday sense.
That's the tip of the tongue phenomenon.
What was that called?
You sense the number of syllables.
You sense where you were when you're trying to tap into these networks.
And one of the greatest ways of proving that this is how this works is to look at people
with early stage Alzheimer's disease.
Now, what's one of the cliches of Alzheimer's?
You lose some neuron.
Last night was the night that some neuron died that remembers the name of your first
grade teacher.
Never again will you find that name available.
That's not how it works.
What you see instead early on is the memory is still there.
It just takes more work to pull it out.
And thus, you are trying to get the person oriented in space and time.
You're giving them, do you know what year it is?
Do you know where you are?
What continent you are?
Why you were here?
And then you ask them a question, who's the president right now?
And suppose it's the 43rd president.
The person can't remember the guy's name.
So you start tapping into some of their networks.
You say, let me give you a clue.
Let me give you a clue.
It's a one-syllable name.
Still flailing.
They can't get it.
So you tap into another network.
It's a word for something you might encounter in a park.
Still not there.
So you give even more strong priming cues there.
You give them a forced choice.
You say, OK, is it president tree, president shrub, president bench, president rock, president
bush, president bush, yeah, he's the kid of the other president there.
It's still in there.
It just takes more work to pull it out.
And that's what dementia looks like in its early stages.
That's proof that you don't have one neuron that knows one fact only.
Instead, you have these networks where you have to tap into them.
And what's been happening in early-stage Alzheimer's is one of these neurons dies and
one of these and one of these in this network that I'm showing here in the diagram.
You lose a neuron here and there.
Do you lose the capacity to pull out that name?
No, it just takes more work.
The remaining pieces of the network have to be stimulated more strongly.
And I saw a wonderful example of what proves there are neural nets a couple of years back
with my daughter, who was about three years old at the time.
And we met some guy who we interacted with for the afternoon and his name happened to
be Barney.
And clearly showing what sort of network she had formed in her brain, she spent the entire
afternoon instead calling him Elmo.
And we could not get that out of her head and clearly she's got some sort of network
of childhood cartoon characters or purple dinosaur puppets or whatever the common.
And just calling this guy Barney Elmo all afternoon, that's where we begin to have the
intersection of facts.
These are networks.
And this seems to be much how the brain works once you get into the complex areas.
Let me show you another bit of circuitry.
And this is one, back down to that boring party or nervous system, down to your spinal
cord but an aspect of it that is far from boring.
How do we feel pain?
And what we've got here are two types of inputs in pain pathways in the spine.
Sitting here in this diagram is a neuron, which when stimulated shoots a message up
your spine telling you that something is painful.
But it turns out pain comes in a number of different varieties.
You can have a certain type of sharp pain, what may be obvious here is that we're just
on a set and this is artificial and I am fact I'm just a hologram.
But were this a real window and I put my hand through it instead of it being fake here,
I would be feeling very sharp pain as it goes through the glass.
Technical term, epichritic pain, what's a characteristic of that sharp pain?
It is suddenly very, very intense and then goes away somewhat.
We have here a pathway that explains it.
Here we have an input, a pathway from a pain receptor which carries rapid sharp information,
sends its axon to stimulate this neuron that we discussed before, excites it, this neuron
has its action potential and you feel pain.
The information shoots up your spine.
Notice however this same pain receptive neuron sends a collateral off to the second neuron.
The second neuron inhibits the pain messenger neuron.
This collateral stimulates that neuron.
What is that about?
This is a case of a feedback signal.
This neuron stimulates this one in order to feel pain.
This incoming fast projection stimulates this pain neuron and then a second later by stimulating
this feedback loop it turns it off.
A brief burst of excitation in that pain neuron and then it's turned off.
What is that?
That's the pin prick, the very painful instant and then it disappears.
Meanwhile, something very different on this side, we've got pain coming in and here it
stimulates that neuron to fire, to tell your spine that something is painful and it sends
its collateral off to that local inhibitory neuron but in this case it inhibits the inhibitory
neuron.
It blocks the ability of that inhibitory neuron to turn off that pain neuron.
What's that about?
You stimulate this pathway and it keeps going and it keeps going, that's throbbing pain.
That's a pulled muscle, that's a burn, that's a very different version of pain and here
we've got these two inputs, one of which gets a sharp pain pathway, the other which gets
a slow throbbing chronic one.
This turns out to explain all sorts of aspects of pain perception.
For example, you've got a disease that damages these fast fibers, the ones that produce the
sharp pain and these fall out of action.
What happens is you get stimulation in this pathway and it just keeps going on and on
and on, that's a certain type of pain perception people get with diabetes, something called
a diabetic neuropathy.
Things just keep throbbing for complex reasons, you've killed these neurons and these guys
just stimulate this pain neuron and it just keeps going and going.
This also explains a very important thing that most of us master early on in life when
we get our first horrible itchy painful mosquito bite and our mothers yell at us and say don't
scratch it or we'll get infected and what do we figure out to do instead?
We scratch on either side of it.
What's that about?
We've got this throbbing pain here going through the slow chronic pathway and by scratching
on either side, we're stimulating this fast pathway.
It adds a burst of pain and then a second later it turns off the pathway.
A sudden sharp pain inhibits throbbing pain and that's why if something really hurts
you squeeze another, that's why we pay to have our fast pain pathways pummeled by somebody,
that's why a massage feels good.
You've got some sore muscles that are throbbing in a chronic unabated pain and somebody comes
in and mauls you and pushes the muscles around and by stimulating these fast pathways you
get a burst of pain and then it turns off the system for a while after and here we see
the interactions of the two.
What is very striking back to our final two themes, first off at looking at plasticity,
all of these networks change their function over time.
Obviously, your Toulouse-Lautrec network gets potentiated by learning about it.
Obviously, all of these pathways can change their functioning.
In this pain pathway, for example, prior experience, projections starting up in your brain can
come down and change the excitability of this key neuron here.
What's that about?
This neurons and plasticity that, for example, puts you in a complete panic when you get
into the dentist chair if that happens to be your makeup and you sit there and the second
the music comes on, your teeth already hurt, you've sensitized that pathway thanks to experience.
That's all sorts of settings where if you were sufficiently excited and distracted,
you twist your ankle in the middle of battle and you don't even notice it, experience
can very dramatically change how this pathway works.
This issue as always of plasticity.
Then back to individual differences, how do networks differ in one of us versus the other?
In lots of ways, one of the most intriguing is to ask, what's creativity?
What we see here are networks by which a neuron that has something to do with short guys or
guys with beards or whatever can eventually overlap and out comes the knowledge of the
name of this painter.
On a certain very crude simplistic level, what creativity is about is having broader
networks than most people, making connections that most individuals don't.
Whereas most of us out there have networks of what encompasses a face that involves
two eyes on either side of a nose and some ears sticking out and all of that, every now
and then you get someone with networks that are broader than everybody else's as to what
constitutes a face and you've just invented Picasso.
On a certain crude level, what individual differences are about in creativity are making
associations that never occur to anybody else, put a whole bunch of cords together that would
have been thought discordant and you've just invented the right of spring and all these
cases what creativity is about is, no doubt, networks in places that most brains don't
have.
So this now has given us a sense of how we've moved from the level of two neurons to how
to extract information to compute things, to process things on a much larger level.
What this sets us up for now is to look at whole areas of your nervous system by way
of networks, now hundreds, thousands of neurons and how they affect events throughout your
entire body.
