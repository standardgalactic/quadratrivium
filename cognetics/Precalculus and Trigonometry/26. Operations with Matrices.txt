Hello again, and welcome to our second lecture on solving systems of linear equations and
matrices.
Last time we saw how to solve linear systems using that arithmetically complicated Gaussian
elimination, and then we showed how to represent a linear system using matrices.
Well, in this lecture I'd like to play with these matrices some more and show that they
have a life of their own.
We'll see later on that the matrices have lots and lots of applications in engineering
and science.
They're very good at representing data and of representing linear systems, etc.
So first of all, what is the technical definition of a matrix?
You could say it's a rectangular array of numbers, and you can either use parentheses
or brackets around that array.
And here I've written the array using a double subscript notation.
So the first row of this array is a string of numbers, a sub one one, a sub one two down
to a sub one n.
That first subscript, the one, refers to the fact that that's the first row, and the second
subscript indicates what column you're in.
So a one two is in the first row, second column.
And you go on down in that array until the bottom right hand number, a sub m n, m n,
that's the entry in the nth row and the nth column.
I have a lot of trouble saying m and n in the classroom, let alone writing those on the
blackboard, but I'll try to be careful.
A sub m n is the entry in the bottom of the matrix there on the bottom right.
Now matrices are often denoted by capital letters like a, or sometimes you'll indicate
that the entries are a sub i j with brackets around it.
There are lots and lots of notations in textbooks here.
We say that two matrices are equal if they have the same size, the same order, meaning
they have the same number of rows and columns as each other.
And if the corresponding entries are all the same, that's pretty simple to say two matrices
are equal.
They have the same size and the entries are the same.
You can also add matrices.
So let's do an example of that.
I'm going to add two matrices.
They have to be of the same size, the same order.
So I'm going to pick two matrices, each having two rows and two columns.
We often call that a two by two matrix.
And the first one I'll call a, and it's the matrix one, two, three, four, meaning one,
two is the first row, three, four the second row.
And for b, it's the matrix minus one, zero, two, four.
So I can add these because they're the same size.
And the result is the matrix a plus b, and you just add the corresponding entries.
This is fairly simple.
So it's one minus one, that will be in the upper left corner, then two plus zero, three
plus two, and four plus four, yielding the sum zero, two, five, eight.
Okay, so that's how you add two matrices.
Pretty simple operation.
Well, you can also multiply a matrix by a constant, by a real number.
In fact, we've often used the term scalar here.
You can multiply a matrix by a scalar.
Let me show you an example.
Let's take a to be our old friend, one, two, three, four, the two by two matrix.
What would three times a be?
Well, all you do is multiply each entry of a by three.
And so you'll get three times one, three times two, three times three, three times four,
and that yields three, six, nine, twelve.
Now this might ring a bell.
Some memory cells might say, oh, didn't we do this earlier?
Yeah.
Remember how we added vectors and multiplied vectors by scalars?
Scalar multiplication.
Well, the same thing's kind of going on here, isn't it?
Adding matrices, multiplying matrices by scalars.
Now some matrices are pretty special.
A matrix, all of whose entries are the numbers zero is called a zero matrix.
For example, the three by two zero matrix would have three rows, two columns, and it
would, all the entries would be the number zero, not a very interesting matrix, zero,
zero, zero, zero, zero.
But the zero matrix has some nice properties.
If you add any matrix to the zero matrix, now you have to add a matrix of the same size,
of course, you'll get back that matrix, a plus zero equals a, is a matrix equation.
And it says the following, for a matrix a, if you add the corresponding zero matrix
of the same size, then you'll get back that matrix a.
And that's obvious because all the entries are zero when you add them up.
The zero matrix doesn't affect the sum.
Now here's a more complicated equation.
What does it mean to say zero times a equals zero?
I find this equation kind of curious because zero seems to appear two times in this equation.
First of all, a is a matrix.
Think of a as being, say, a big fat matrix.
Who's that zero on the left of a?
Well, that's the scalar zero, the real number zero.
And who's that zero on the right of the equality sign?
That's the zero matrix, which is the same size as the matrix a.
Let me show you an example.
Suppose a is one, two, three, minus one, minus two, zero.
Multiply that matrix by the scalar, the real number, zero.
And that means zero gets multiplied by each entry and you end up with the zero matrix.
So you see, it's kind of a, you know, that equation looks really simple.
Zero a equals zero, but there's some depth to that.
The zeros are different, aren't they?
Okay, we come now to my favorite operation and the most interesting operation.
You know what's coming, don't you?
It's going to be a little more complicated.
It's called matrix multiplication.
And let me show you how this works with a simple example.
It requires some, you know, paying attention here to some of the details.
Let's multiply the following two matrices.
The first one will be a three by two matrix, three rows, two columns.
The entries are minus one, three, four, minus two, five, zero.
And I'm going to multiply it by the matrix minus three, two, minus four, one, a two by two matrix.
In a minute, I'll talk about whether or not you're even allowed to multiply these matrices.
Trust me, you can in this case.
And the answer is going to be a three by two matrix.
Here's how you get that answer, the product of these two matrices.
Well, the upper left-hand entry in the answer, that's the first row and first column of the answer,
that is obtained by multiplying the first row of the left-hand matrix times the first column of the right-hand matrix
in the following way.
Watch how it goes.
It's minus one times minus three plus three times minus four.
You see how that works?
I go across the first row and down the first column.
Minus one times minus three plus three times minus four.
And then you figure out what that number is and that's the upper left-hand entry.
Now, let's see what the entry in the first row second column is of the answer.
Okay, that'll be the first row of the left-hand matrix times the second column of the right-hand matrix.
Here we go.
Minus one times two plus three times one.
You see how we multiply that?
Bing-bing and then bing-bing like this.
So we multiply across the row times the corresponding column.
Let's try one more.
Second row first column of the answer.
That would be the second row of the left-hand matrix times the first column of the right-hand matrix.
Four times minus three plus minus two times minus four.
And you continue in this way.
Here I filled out the other entries.
Four times two plus minus two times one.
And the third row is five times minus three plus zero times minus four.
And then the bottom entry is five times two plus zero times one.
And doing that arithmetic, you end up with the answer of three by two matrix minus nine one minus four six minus fifteen ten.
So that's matrix multiplication.
I find when I'm teaching this skill to my class, they pick up pretty quickly on the algorithm for multiplying.
And then when they see the formal definition of matrix multiplication, they kind of step back and go, whoa, I thought I understood it,
but that definition looks really complicated.
So let's hope that doesn't happen here.
Here's the formal definition of matrix multiplication.
And if you're comfortable with what we just did, don't worry too much about this.
But here's how it goes.
You've got two matrices.
A is m by n, m rows, n columns.
B is another matrix, n by p.
Notice that the n's have to be the same here.
Then the product is m by p.
So the product of A, B is a new matrix.
And its entry, it's a typical entry is of the following form, the ijth entry.
Remember what that means?
That's the ith row and the jth column is a certain sum of products.
And it's precisely what we did in the previous example.
And I'll read it off to you, but again, this definition is kind of too complicated to fully be usable.
I think it's better to do it through examples.
It's a i 1 b 1 j plus, and you keep going to a i n plus b n j.
All right, pretty complicated, but it's basically that summation process we just did.
Some comments about matrix multiplication.
You must have the correct sizes to line things up.
And the bottom line is the inner numbers must match and the outer numbers give the size of the answer.
For instance, in that problem we just did, A was 3 by 2, 3 rows, 2 columns.
B was 2 by 2.
The middle numbers match, 2, 2.
And the outside numbers, 3 and 2, yield the size of the answer.
In general, if A is m by n, m rows, n columns, and B is n by p, the n's are matching the middle numbers,
and the outside m and p determine the size of the product.
For instance, if you took that example we just did and reversed the two matrices, B times A, B is 2 by 2.
A is 3 by 2.
The middle numbers don't match, do they?
So that product is not defined.
And if you try to do that product, you'll see that it won't work because as you're going along the row and going down the column,
the numbers don't match, you don't have enough.
So if you could actually try to multiply them and you'll see that it won't work.
All right, so what can we say about matrix multiplication?
We'll see a couple more examples of this lecture,
but I highly recommend you also spend some time doing some of the workbook exercises on matrix multiplication.
Here's some good news.
This is all built into calculators.
A lot of the fun of mathematics has been taken away by these calculators, hasn't it?
But you can feed in two matrices of the appropriate sizes and your calculator will multiply them instantaneously.
All right, I promised another example.
Here's one, and it has an interesting answer.
So let's take the matrix 1, 2, 1, 1, and another 2 by 2 matrix, minus 1, 2, 1, minus 1.
Each of these is 2 by 2, so it's no problem multiplying them, the middle numbers match, and the answer is also going to be 2 by 2.
So can you tell me what the upper left-hand number is?
How do you get it?
Well, you multiply 1 times minus 1 plus 2 times 1, and that yields 1 in the upper left corner.
Let's try the upper right corner.
1 times 2 plus 2 times minus 1.
I'm going across the row and down the column of the second matrix, and that yields 0.
How about the bottom left?
1 times minus 1 plus 1 times 1.
Second row of the left-hand matrix times the first column of the right-hand matrix, that yields a 0.
And finally, the entry in the second row, second column, is 1 times 2 plus 1 times minus 1, which is 1.
Now that's an interesting matrix.
1, 0, 0, 1.
We'll come back to that kind of matrix shortly.
Let's do some more multiplications.
I have a couple of examples here that are kind of weird-looking.
You'll be kind of, whoa, that's kind of strange.
I'm going to multiply a matrix that's a row matrix.
In other words, it's one row, three columns, and the entries will be 1, 3, 5 times what we like to call a column matrix.
It's three rows, one column, and its entries are 2, 1, 0.
Now, are we allowed to multiply these two?
Well, the first one is 1 by 3, and the second one is 3 by 1.
The middle numbers match, 3.
And how big is the answer?
Well, those are the outside numbers.
The answer is going to be 1 by 1, a tiny matrix, isn't it?
A matrix of one row, one column.
What is that matrix?
Well, you multiply the rows, tie in that column, and here you get 1 times 2 plus 3 times 1 plus 5 times 0.
Add those up.
The matrix, the 1 by 1 matrix, is the number 5.
Okay, kind of weird, wasn't it?
But now I'm going to really do something strange.
I'm going to reverse the two matrices.
Now we'll put the column on the left and the row on the right.
So it's 2, 1, 0 times 1, 3, 5.
Are we allowed to multiply?
Well, the first one is 3 by 1, 3 rows, one column.
The second one is 1 by 3.
Yeah, the middle numbers match.
They're both equal to 1.
How big is the answer?
The outside numbers give the answer, 3 by 3.
So these two skinny little matrices produce this fat matrix that's 3 by 3.
Let's do some of the entries.
How would you get the upper left-hand entry?
2 times 1, and then 2 times 3, and then 2 times 5.
So the first row is 2, 6, 10.
The middle row is 1 times 1, 1 times 3, 1 times 5, so it's just 1, 3, 5.
And the third row is really nice.
0 times each entry, 0, 0, 0.
So I'll ask you a general question.
Is matrix multiplication commutative?
Is A times B the same always as B times A?
Well, I hope you immediately say no way.
Look at the previous examples.
We have the same matrices.
When I wrote them one way, the answer was a 1 by 1 matrix.
The other way, the answer was a 3 by 3 matrix.
Those answers are not the same.
So in general, matrix multiplication is not commutative.
It's very rare that AB equals BA, extremely rare.
You might know other operations that aren't commutative.
Subtraction, 7 minus 2 is not the same as 2 minus 7, or division the same way.
Commutativity is lots of operations in mathematics are not commutative.
But they are, for the most part, the important operations of mathematics.
They're what's called associative, and that's a big word.
Associative refers to multiplying or adding three things in a row.
And matrix multiplication is associative.
And by that, I mean the following.
If you have three matrices, A, B, C of appropriate sizes,
so you're allowed to multiply them, the middle numbers match.
A, B, C, you could form that double product two ways.
You could first multiply A times B, and then that gets multiplied by C.
Or you could do B times C, and then multiply by A.
So you could move the parentheses.
The parentheses around A, B can be moved around B, C.
Notice I haven't changed the order. It's still A, B, C.
But the order of the multiplication can be done differently.
Okay.
I talked about that interesting answer we had on a previous problem,
that matrix that was 1, 0, 0, 1.
That's called an identity matrix, the multiplicative identity.
But here's why. Let's take that 2 by 2 matrix and multiply it by an arbitrary 2 by 2 matrix.
Say 1, 2, 3, 4. What do we get?
I'll do it in your head.
When you do that multiplication, out comes 1, 2, 3, 4.
The same matrix.
In other words, this matrix 1, 0, 0, 1 kind of plays the role of the number 1 in the real numbers.
If you take a real number and multiply it by 1, you get back that real number.
Well, here are the same things happening.
If you take a matrix and multiply it by this 1, 0, 0, 1 matrix, out comes that original matrix.
Now, of course, the sizes have to match up.
And there's an identity matrix, which is 2 by 2 in this case, or it could be 3 by 3.
And you can imagine what it looks like. It has 1s down the diagonal and 0s everywhere else.
So for every square matrix, there's an identity matrix associated with it.
Okay.
I've always liked to play this game with my students, ask them a question, and they come up with an answer.
So let me ask the following question of my students.
Do you think the cancellation law is valid for matrices?
Remember for real numbers, if you have, say, A, B equal to A, C, and A is not 0, you can cancel the A.
You can cancel common factors on both sides of an equality, as long as you aren't canceling a 0.
Is that true with matrices? Let me be more specific.
Suppose you have the product A, C of two matrices, again appropriate sizes, so you're allowed to multiply.
Suppose A, C equals B, C. So two products are the same, and C is not 0.
Assume it's not the 0 matrix. Is it then true that A equals B?
Can you cancel that matrix C on both sides?
Well, the answer turns out to be no.
And to show it's no, you have to come up with a counter example, don't you?
So let me show you a quick counter example that would illustrate that this property in general is not true.
Let A be 0, 1, 0, 1, and B the matrix 1, 0, 1, 0, and C the matrix 2, 3, 2, 3.
There are lots of counter examples, but here's the one I came up with.
Now, with those choices, I'll let you verify the following.
A times C equals 2, 3, 2, 3, and B times C also equals 2, 3, 2, 3.
So A, C, and B, C are equal to each other.
But notice that A and B are not the same matrix.
So that's kind of a quick example to show that that cancellation problem or property, unfortunately, is not true with matrices.
All right, let's use these matrices as a tool in expressing linear systems,
writing linear systems in a more convenient way.
And again, I'll show you an example, but it illustrates the idea.
Here's a system of two equations, three unknowns.
x minus 2y plus z equals 2, 2x minus y minus z equals 1.
So here's another way of writing that system.
Let's let the matrix A be the coefficient matrix.
So it'll be a matrix of that's two rows, three columns.
The first row is 1 minus 2, 1.
That corresponds to the coefficients of the first equation.
And the second row is 2 minus 1 minus 1 corresponding to the second equation, the coefficients of that second equation.
Now let B be the matrix of the right-hand side.
The right-hand side is 2, 1.
So I'm going to write B as a column matrix, 2, 1.
And then we have these unknowns, x, y, and z.
So I'm going to call that column matrix x, y, z equal to say capital X.
That's kind of like the matrix of the unknowns, because we're trying to find x, y, and z, aren't we?
So now we're going to express this linear system using this fancy matrix multiplication.
Watch how it works.
I'm going to put matrix A down, and to the right of it, put the column x, y, z.
And that equals, well, I claim it equals 2, 1, the B matrix.
Let's check that.
Let's multiply the matrix A times x, y, z.
Okay.
Can we multiply them?
Well, the matrix A is 2 by 3.
The matrix capital X is 3 by 1.
I'm allowed to multiply 3 equals 3, and the answer is 2 by 1, the outside numbers.
What's the top entry?
Here we go.
1 times x minus 2 times y plus z.
Oh, that's the first equation of the linear system.
Now do the second multiplication.
2x minus y minus z.
Wow, that's the second equation.
In other words, this matrix product expresses that linear system in a different way.
We're using matrix multiplication to express the linear system.
Now here's what textbooks do.
They'll compactify this and write it as Ax equals B.
So you'll see textbooks that say the following.
Let Ax equal B represent a linear system.
And they're saving a lot of space, aren't they?
They're writing that it's a tiny little phrase, Ax equals B.
But it means a whole lot.
A is probably some big matrix.
And X is a column matrix consisting of the unknowns of that linear system,
and B is the right-hand side of that linear system.
So there's a lot embedded in that very simple phrase.
Let me show you application of this, of this notation,
and get us back to some of our roots of solving equations.
Here's the application.
I'd like to fit a parabola to three points in the plane.
This is a very common skill, by the way, in mathematics and in statistics,
fitting a curve to data.
We're doing a very simple example here.
So the points will be 2, 0, 3 minus 1, and 4, 0.
There are three points in the plane.
I want to find a parabola that passes through those three points if I can.
So here's how you do it.
First, consider the point 2, 0.
That should be on the parabola.
And if I call the parabola Ax squared plus Bx plus C,
where A, B, and C are the unknown coefficients of my parabola,
I plug in X equal 2 and Y equals 0,
and I get 0 equals A times 2 squared plus B times 2 plus C.
I'm just saying 2, 0 satisfies the equation of the parabola.
Well, then I plug in 3 minus 1, and that yields a new equation.
Minus 1 equals A times 3 squared plus B times 3 plus C,
and plug in 4, 0, and you get the third equation.
0 equals A times 4 squared B times 4 plus C.
Now multiply out those squares,
and this gives rise to a system of linear equations.
There's one adage in mathematics or in applied mathematics.
Almost everything gives rise to a linear system
that you then have to solve with Gaussian elimination.
Here's our system. 4A plus 2B plus C equals 0,
9A plus 3B plus C equals minus 1,
and 16A plus 4B plus C equals 0.
Find A, B, and C.
Well, I'm not going to do it.
We know how to do Gaussian elimination.
This one would be pretty unpleasant by hand,
mainly because you've got some ugly fractions there,
probably when you start to eliminate the variables.
But notice that before you even solve it,
you can express the system in this matrix multiplication notation.
The coefficient matrix is 421, 931, 1641.
Those are the coefficients,
and then A, B, C represents the matrix of unknowns,
and the right-hand side was 0 minus 1, 0.
So the system would be AX equals B.
And by the way, this is a way a lot of graphing calculators
would accept the system.
You then solve it by Gaussian elimination.
Again, I said I'm not going to go through the steps,
but when you do all the steps of Gaussian elimination,
often called row reduction,
here's the answer you get.
You get a matrix,
and I'm going to write the matrix together with the right-hand side,
and it's 1, 0, 0, 1, 0, 1, 0, minus 6, 0, 0, 1, 8.
Now remember how you read these in the previous lecture.
The fourth column of that matrix are the constants,
and the first row means A equals 1,
and the second row means B equals minus 6,
and the third row is C equals 8.
So that's the solution.
It's a unique solution in this case.
A is 1, B is minus 6, C is 8.
So our parabola is x squared minus 6x plus 8.
Here's a picture of that parabola together with the three points
that gave that the parabola passes through.
So we have done some curve fitting.
For some data, we've fit a parabola through that data.
Okay.
What have we done today?
Let's sort of step back.
We've taken the linear system world
and sort of talked about these matrices.
Not only do they represent the linear system,
but they kind of have a life of their own.
We were adding them, multiplying them by scalars,
and then we multiplied matrices together.
We did a complicated operation,
and we discovered some interesting properties
like there's an identity matrix
and a zero matrix that play kind of a big role.
Well, next time we'll play more with matrices.
We'll talk about inverses of matrices,
and then a concept that you've probably heard of, maybe,
called determinants of matrices.
We'll look forward to next lecture
when we focus on inverses and determinants.
Thank you.
