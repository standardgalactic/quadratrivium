Let's start with a test.
Consider a bilingual person, native in one language and fluent in a second.
Suppose this person suffers a trauma to the head and develops aphasia.
I'm going to list five possible features of this aphasia,
and I want you to try to figure out which ones are the real symptoms and which ones I made up.
Ready?
Could it cause A, word-finding problems in both languages?
B, more mispronunciations in the first language?
C, more syntactic errors in the second language?
D, mixing words from both languages within a sentence?
Or E, alternating between languages across sentences?
You can pause to think of your answer.
Okay, well, it turns out that the answer is all of the above.
All five are potential symptoms of aphasia in a bilingual.
I ask this to illustrate the complexity of the multilingual brain.
As you know, language mechanisms involve an intricate neural network,
so when you bring additional languages to the mix, the system gets that much more complicated.
That's why damage to multilingual brains produces such unpredictable outcomes.
In this lecture, I'll talk more about this variability,
and more generally about the complexity of language in its multilingual form.
Along the way, I hope to dispel some myths about the multilingual mind.
Before we jump in, let me define some basic terms.
By multilingual, I mean living with more than one language and regularly using them in daily life, fluently.
And by fluent, I mean it in the original sense.
In Latin, fluentum means flowing.
So, to be fluent means to speak or sign in a flowing manner.
And this counts even if a multilingual has a non-native accent or produces some grammatical errors.
It's simply a myth that unless someone speaks language flawlessly, that person is not fluent.
By that measure, think of how many monolinguals would miss the cut.
Lastly, I need to define monolingual.
By this, I mean being fluent in only one language.
So, even though I can get by in France and Japan with my spotty French and Japanese,
I am most certainly a monolingual English speaker.
Traditional approaches to understanding language have focused primarily on people like me as the model language user.
In fact, even to this day, many scientific studies on language,
including from my own lab at Colgate, explicitly exclude multilinguals.
The idea is that they introduce too much unwanted variability to the data,
and this makes it harder to answer basic research questions about language more generally.
Fair enough.
But if you consider the actual number of multilinguals on the planet,
you might ask why we would run away from this variability rather than embrace it.
After all, the linguist Francois Gaujean estimates that over half of the world's population
regularly uses more than one language.
And even in countries with many monolinguals, like the U.S.,
multilingualism is not some fringe phenomenon.
In fact, recent estimates suggest that about 50 million bilinguals live in the United States today.
So there goes another myth.
Around the world, multilingualism is not the exception.
It's actually the rule.
Given its prevalence, it's surprising that systematic research on multilingualism is so young.
Linguists have long made comparisons across languages,
but not until the 1950s where there are large-scale theoretical attempts
to systematically investigate how people learn multiple languages.
Looking back, most scholars now point to a classic book published in 1957
by the American linguist Robert Ledeau as the start of multilingualism as a field of study.
The book, Linguistics Across Cultures, presented a theoretical framework to explain
how one's native language can make it easier or harder to learn various second languages.
For example, Ledeau's theory predicted that it should be easier to learn Spanish
if you already know Italian because the two share so many linguistic features.
But learning Italian should be much harder if your native language is Cantonese
because it's so radically different in almost every way.
Now, this theory has since been challenged by some more recent empirical studies.
In fact, there's evidence that in some cases,
it's actually easier to learn certain aspects of a language
that are very different from your native language.
Still, Ledeau's legacy lives on.
His work has been extremely influential
because it officially put multilingualism on the map for empirical study.
Another myth, or at least a misconception,
is that multilingualism is a single categorical thing.
To appreciate what I mean, consider monolingualism as a category.
I don't mean this in a bad way, but being monolingual is pretty homogenous.
Barring genetic disorders, physical constraints, or extreme neglect,
all monolinguals become fluent in pretty much the same way.
In contrast, multilingualism is much less uniform,
and this is due to the myriad of idiosyncratic contexts
of learning more than one language.
Think about it.
Monolinguals share remarkably similar learning contexts.
For spoken language, almost everyone is the same age
when they're exposed to speech,
and their spoken exposure comes from every possible angle,
from the home, classroom, broader society, you name it.
Not only that, but monolingual speakers
almost always learn language from other monolinguals.
Things are different for multilinguals in every way.
For starters, the age range of when they learn a second language is extremely wide.
It could be right after birth, or it could be decades later.
Not only that, but exposure to different languages comes from so many different sources.
In some cases, one parent speaks one language,
and the other parent speaks another language.
Other times, both parents switch back and forth between languages.
In still other cases, both parents speak the same language in the home,
but people outside the home speak a different language.
And finally, multilinguals learn language from models who have a wide range of fluency.
Some are fully fluent, and some are far from fluent,
and there's everything in between.
Consider an example.
I had a student who was born in L.A. to a father from France and a mother from Colombia.
Growing up, both their parents were fluent in English, but not at a native level.
At home, the family mostly spoke English,
but the parents also spoke their native language to their daughter,
but rarely to one another.
And to complicate matters even further,
almost every summer, the daughter would travel to France to be with her father's family,
where she would speak exclusively in French.
Compare this to my situation.
When I was born in a small town far outside of Chicago,
I came home to a family that spoke English all the time.
And then I went to an all-English-speaking school
and made friends who spoke to me only in English.
Also, practically everything I heard on the radio and saw on the TV was in English.
It probably wasn't until I took high school French
that I heard more than a few minutes of something other than my native language.
Now, times have changed,
and technology has made the world a more connected place.
But still, I bet my situation is pretty familiar
to many people who consider themselves monolingual.
So this brings us to another myth.
A bilingual brain is basically two monolingual brains rolled into one.
Wrong.
Although there are many similarities,
bilingual and monolingual brains are different in some important ways.
Here's a big one.
As you might expect from the diverse ways they learn language,
multilingual neural mechanisms are much more complex and variable than monolingual ones.
This variability is caused by a number of factors,
like how many languages a person speaks,
the similarity among those languages,
whether they are learned at home or in the classroom,
and the amount of use each one gets.
These are all important factors,
but the biggest may be age of acquisition.
We've already talked about sensitive periods and language development,
and you know that age of exposure strongly predicts phonetic ability in a language.
But after infancy, the effects of age extend far beyond phonetics.
For example, Alyssa Newport and colleagues have argued that many linguistic components are very fragile,
and mastering them requires exposure to a language within the first 12 years of life.
So in addition to accent,
there are sensitive things like complex syntax and inflectional morphology,
like markers for past tense and plurals.
However, Newport observes that other linguistic aspects,
like vocabulary, simple syntax, and basic pragmatics,
these things are much more resilient and relatively easy to learn even late into adulthood.
That said, there's still a lot of variability in what late learners can handle.
Newport has some very nice data showing that age of exposure and competence
in the fragile properties of language
have a strong negative correlation over the first 12 years of life.
But after puberty, the correlation goes to zero.
A correlation of zero indicates that age no longer predicts variability in language competence,
which means that variation after puberty is driven by individual differences,
like genetic predisposition, educational opportunities, and life circumstances.
Given these differences, what do the brains of these late and early learners look like?
In 1997, Carl Kim, Joy Hirsch, and their team at the Sloan-Kettering Cancer Center in New York
published a landmark study investigating how age of second language acquisition
affects the language network in bilingual brains.
The study used fMRI to compare differences in Broca's and Wernicke's areas of people who learned second languages as infants or as adults.
Participants were put in a scanner and asked to internally generate silent sentences
to activate neural networks of one language and then the other language.
The main finding was that while Wernicke's areas showed no differences across languages
for both early and late learners, Broca's area did show a difference.
For late learners, the two languages activated two separate sub-regions of Broca's area,
but for early learners, both languages activated an overlapping area.
This pattern in Broca's area makes sense given what we know about the dorsal stream of language processing.
If you recall, this part of the language network is where phonological forms of words are activated and executed.
Think back to Kuhl's theory of native language neural commitment.
Because the brain commits to phonemes of a language, or languages, early in life,
it can use prime real estate in Broca's area for the job.
However, if a second language is learned after this neural commitment,
it must rely on a different part of Broca's area that is not as optimally suited for phonological production.
Actually, an analogy may be useful here.
You know how a tennis racket has a sweet spot where hitting the ball has the most power and accuracy?
If you think of the racket as Broca's area,
that sweet spot is used for phonological forms of languages learned early in life.
But if a second language is learned later in life,
it must use the area surrounding that sweet spot.
And this lowers the power and accuracy.
Sure, you can still hit the ball in both places,
but the center is designed to strike it much better.
Since Kim and Hirsch's landmark experiment,
subsequent neuroimaging studies have mostly confirmed these differences
using a variety of languages and ages.
Not only that, but a recent meta-analysis shows that
the later in life someone learns a second language,
the more space is required in Broca's area.
Why would that be?
Let's try another analogy.
This one's from the sociolinguist Rosina Lippe-Green.
Think about language or languages learned early in life as a new house.
A house built on prime real estate using the best materials
and constructed by expert architects and builders.
Under these ideal conditions,
it's possible to build a modest-sized house
that can efficiently handle many languages.
Now think of a language learned later in life
as building an addition to this original house.
Consider the suboptimal conditions that may plague this late add-on.
For example, the new construction is constrained
by the structure of the original house
and the proximity to the neighbor's houses.
And perhaps there's a shortage of high-quality building materials,
and it's possible that you've lost the blueprints
and can no longer afford expert builders.
In addition to making a much larger and much less efficient house,
this variability makes it likely that the new addition
will not be as good as the original.
So to sum up, not all multilingual brains are created equal.
There's incredible variability.
But despite this variation,
multilingual brains are still much more similar to one another
than they are to monolingual brains.
One of the biggest differences between monolinguals and multilinguals
is that multilinguals must build mechanisms for keeping track of their separate languages.
Think back to my trilingual student.
Every time she speaks English, she has to suppress French and Spanish.
And when she switches to one of those, she has to suppress the other two.
How in the world does she do this without constantly mixing up her languages?
Well, the answer comes back to a familiar brain region,
the frontal lobe, or more precisely, the prefrontal cortex in the frontal lobe.
The prefrontal cortex, or PFC for short, is constantly at work when we use language.
It has to keep track of what was just said,
and it must monitor what to say next.
And on top of that, it also has to suppress information that's distracting to the task at hand.
This suppression is hard enough for monolinguals,
but multilinguals must work extra hard,
because when they're speaking one language,
their other language, or languages, must not get in the way.
Evidence for language co-activation and suppression in multilinguals
comes from many different lines of research.
Let's go through four of them.
For starters, let's take our case of bilingual aphasia.
One distinctive, but not uncommon problem of bilingual aphasics
is pathological mixing of languages within an utterance.
It's called pathological mixing to set it apart from voluntary mixing.
Voluntary mixing is perfectly natural.
The best known example in the U.S. is Spanglish,
but there are many other mixes, too.
For example, there's also franglais, a mix between French and English.
And here's one you might not know.
Svorsk, a mixture between Swedish, Svenska, and Norwegian, Norsk.
Pathological mixing is where an aphasic can't control swapping L1 and L2 words within a sentence.
And sometimes they're not even aware of doing it.
That's interesting, but here's an even more peculiar symptom.
In some rare cases, there's pathological switching of languages across sentences.
Again, when this is voluntary, it's quite natural.
It's even got a name.
Linguists call it code switching.
But for some bilingual aphasics, they can't help themselves.
So an aphasic from Switzerland, for example,
might alternate between fully grammatical and complete sentences in French, German, and Italian
over the course of an entire conversation.
By the way, this phenomenon connects back to something we've discussed before.
Remember spoonerisms?
You know, saying a half-warmed fish instead of a half-formed wish?
Spoonerisms provide support for language models stating that utterances are conceptualized and packaged before we utter them.
Well, I want you to think about pathological code switching as further evidence of that.
Okay, so what's going on in the brain to produce this type of uncontrollable switching?
In 2000, Franco Favro and his Italian team of neurolinguists published a landmark case study
of a patient who demonstrated pathological switching of his two languages, Italian and Friulin.
Friulin is a Romance language spoken in northeastern Italy.
The patient frequently alternated entire sentences between Italian and Friulin,
even when speaking to people who didn't understand one of the languages.
In this particular case, the patient was aware that he was making these switches and it caused him great distress.
After his symptoms got even worse and he started having difficulty walking and driving,
he went to the doctor who suggested an MRI to look for structural abnormalities in his brain.
The results showed that he had a large tumor growing in the left inferior frontal gyrus.
The damage was not quite in Broca's area, which explained why he could still speak fluently in both languages.
So where was his damage?
It was an area just anterior to Broca's area located in the PFC's executive control network,
which is important for neural inhibition.
In this patient's case, damage to the left PFC not only made it impossible to stop alternating between languages,
but it also produced more general deficits in social inhibition.
For example, one clinical observation was that the patient grew very fond of telling dirty jokes,
even in quite inappropriate situations.
Since this study, there have been other cases of structural damage to the left PFC and pathological code switching.
And just as with Fabro's case study,
these patients also demonstrated more general deficits in social inhibition.
This has led many researchers to conclude that this is not a problem specific to language,
but rather a more domain-general problem of executive control.
We'll come back to this later.
A second line of evidence for the co-activation of multiple languages
comes from research on neurotypical bilingual brains.
In one simple but creative approach,
the Spanish psycholinguist Albert Costa exploited the fact that some bilinguals
have many shared vocabulary items across their two languages.
These overlaps are called cognates in linguistics.
For example, take Spanish-Catalan bilinguals who have an unusually high number of cognates.
In Catalan, the word for cat is gat,
and in Spanish, it's gato.
Costa had fluent Spanish-Catalan bilinguals.
Look at pictures of things that either had cognates in the two languages,
like a picture of a cat, or didn't have them,
like a picture of a table,
which is taula in Catalan and mesa in Spanish.
The task was to name the objects in either Catalan or Spanish as quickly as possible.
The prediction was that if the mental lexicons of Catalan in Spanish
were both active when trying to name a picture,
bilinguals should be slower to name objects that had no cognates, like table,
than ones that did, like cat.
And that's exactly what Costa found.
He interpreted this finding to mean that when bilinguals are searching for lexical items
for a particular meaning, both languages are simultaneously active.
And this activation can facilitate or interfere with naming,
depending on whether the phonological forms are similar or different.
The third line of evidence for multi-language co-activation
considers the flip side of cognates.
For all bilinguals, there are some words that randomly sound similar across their languages,
but have completely different meanings.
For example, the Russian word marka means stamp,
while the English word marker means, well, marker.
What happens when a Russian-English bilingual hears the first few syllables of those two words?
Do they activate both meanings in their heads momentarily?
That was precisely the question asked by the psycholinguists
Viorika Marianne and Michael Spivey in a 2003 eye-tracking study.
Remember eye-tracking?
That's where eye gaze is recorded by a mini-camera,
which captures the moment-to-moment timing of what people are thinking.
The experiment studied Russian-English bilinguals
as they listened to a Russian speaker referring to different objects in Russian.
So picture a computer screen that has an image of a stamp on the left side
and a dry erase marker on the right side.
When subjects heard the Russian word for stamp, marka,
their task was to press the side of the screen where the object was located,
in this case, the left side.
On the surface, this should be a pretty straightforward task, right?
But the eye gaze pattern suggests something more nuanced.
When the stamp was paired with a marker,
bilinguals looked at the marker a third of the time.
This means that there was competition between the phonological forms of the two words,
marka and marker.
In contrast, when the stamp was paired with a competing image
that had a totally different-sounding English translation, like a candle,
the bilinguals were three times less likely to look at the competitor.
It's worth emphasizing that the experiment was done entirely in Russian,
so there's no reason for English to be active in the first place.
Despite this, it wasn't possible for the bilingual subject
to totally tune out the irrelevant language, even when it was disruptive.
This is a great finding from the lab,
but it's always nice to see results generalized to the real world.
So let me share a little anecdote from home.
Occasionally, when my bilingual wife uses numbers in English,
she says seven when she means to say nine.
Why would she do that?
Well, in Japanese, the word for seven is nana,
and that sounds kind of like nine.
The fact that she does this, usually after a long day of work,
suggests that both of her languages are always active
and that it's not easy to keep them apart.
Okay, before we turn to the final piece of evidence,
I want to share another interesting example
of this co-activation of languages.
Most bilinguals are what we call unimodal bilinguals,
meaning that both languages are in the same modality,
like Japanese and English.
But the sign language researcher Karen Emery
has studied a different type of bilingual,
bilingual, a bimodal bilingual.
These people not only use two different languages,
but two different modalities,
like someone who's bilingual in English and ASL.
For these bimodal bilinguals,
there's a fascinating and surprisingly common phenomenon
called simultaneous code blending.
That's when a person speaks in one language, like English,
but simultaneously signs in another, like ASL.
And remarkably, this happens even when bimodal bilinguals
are speaking English to monolingual English speakers.
Now, remember what you learned,
that ASL is not just a pantomime version of English.
Far from it.
It's its own distinct language.
So this is some of the most direct and compelling evidence
that bilinguals simultaneously activate multiple languages
when they communicate.
So we've considered evidence for language coactivation
from bilingual aphasics
and also experiments on regular old multilinguals.
The final line of evidence comes from neuroimaging studies
exploring how languages are activated
and deactivated in neurotypical brains.
The neural mechanism for this process
has been dubbed by the neurolinguists David Green
and Jubin Abutalebi
as the Bilingual Language Control Network.
In addition to the left PFC,
which we've already discussed,
the network involves other areas
outside of traditional language network,
like the inferior parietal lobe,
cerebellum, and the thalamus.
But the one I want to focus on
is the anterior cingulate cortex, or ACC.
The ACC is a subcortical brain structure
involved in error detection and conflict monitoring.
Neuroimaging studies have shown
that the ACC is heavily used in bilingualism
or bilinguals when monitoring
which language is most appropriate
for a given communicative context.
Interestingly, this region is most active
for low-proficiency multilinguals,
presumably because they are the ones
who are most likely to make errors.
The ACC and left PFC combine
to perform two critical functions
for multilinguals.
They determine when to engage
and when to disengage different languages.
Both functions are important,
but it turns out that one of them
requires much more brain power
than the other.
In a clever neuroimaging study in 2018,
Karen Emery and colleagues
investigated the control network
of bimodal bilinguals
who use ASL and English.
Using MEG,
they found that when these bilinguals
shifted from speaking only English
to simultaneously speaking English
and signing ASL,
there was minimal activation
of the control network,
suggesting the switch was pretty easy.
However, things were different
in the other direction.
When participants had to disengage
from simultaneously using both languages
to using just English alone,
that's when the control network
really kicked in.
So turning off a second language
requires much more effort
than turning it on.
We can apply this to the more common case
of unimodal bilinguals.
When only one language
can be spoken at a time,
these findings suggest
that it's easier to activate
than inhibit that language.
Here's a concrete way
to think about it.
Imagine swinging a bat.
Now imagine swinging a bat
and stopping midway through.
Stopping is much harder
than starting, right?
Well, it's the same
with bilingual control.
All right, let me wrap up
by taking down one final myth.
Once you've mastered a language,
language, it's mastered for life.
Not true.
Without activity, all languages decay.
And this applies to your first language, too.
When that happens,
linguists call it language attrition,
and it affects everything,
even your native accent to some extent.
To appreciate this,
think back to Lippy Green's house analogy.
If you've built a multilingual home
and you haven't been taking care
of all of it,
things will stop working.
They'll fall apart.
Not only that,
but if you've spent years
actively neglecting certain rooms
through neural inhibition
and suppression,
you won't even know
how much damage you've done.
So how does this happen?
Well, it goes back
to the basic brain principle
of neural plasticity.
Remember Hebbian learning?
You know, use it or lose it?
That's what's going on here.
Plasticity is what builds a language up,
and it's also what tears one down.
In our final set of lectures,
we'll explore the power
of this neural plasticity
in a new way.
So far, you've seen
how this basic property of the brain
contributes to language.
But next, we'll ask
how language itself uses plasticity
to contribute to other big aspects
of the mind,
like emotion, personality, and thought.
In short,
we'll ponder the profound question,
how does language make us human?
