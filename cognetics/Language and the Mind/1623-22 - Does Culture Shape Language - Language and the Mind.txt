To pick up where we left off last time, let's start with a provocative passage from John
McWhorter's book, The Language Hoax.
Here it is.
If you want to learn about how humans differ, study culture.
However, if you want insight as to what makes all humans worldwide the same, beyond genetics,
there are few better places to start than how language works.
This quote hits on some of the biggest themes we've covered so far, so pause and take a
moment to reflect on it.
The idea is this.
All languages share some fundamental universals, like having grammatical categories and rules,
possessing some degree of arbitrariness, being generative, and so on.
Remember those?
They're Hockett's design features of language.
These shared properties reflect human similarities and serve to unite all of us across the globe.
In contrast, according to McWhorter, culture precedes language and merely uses it to produce
the diverse ways of experiencing and living in the world.
In other words, culture is the agent for creating differences, and language is just a tool.
In the spirit of debate, I'd like you to consider three reactions to McWhorter's bold position.
First, might culture also unite people worldwide?
Like language, culture is also shaped by the brain.
So that means that every culture shares some basic properties.
For example, they all determine social status, they all regulate the family, they all establish
rules, and every culture transmits cultural knowledge among its members.
Don't these universals connect all cultures?
The second reaction is that just because language is a tool for culture doesn't mean the tool is trivial.
Sort of reminds me of the old gun rights slogan.
Guns don't kill people, people kill people.
True, but guns make it a lot easier, don't they?
So even if culture is what ultimately creates diversity, we shouldn't dismiss the unique
role of language as a powerful way of enacting it.
And the third reaction is this.
Is it really the case that language exerts itself only as a vehicle for culture?
Is it ever possible for language to be an independent influence?
That's the question that we'll take up in this lecture.
It's hard to separate the effects of language from culture, but that's what scientific experiments
are designed to do.
They isolate one variable from others to determine the effects of just that one thing.
It's not perfect, but this element of control definitely helps to parse the causal relationship
between language, culture, and thought.
Let's return to our color example.
Let's talk about my color blue versus other people's blues.
As an English speaker, I can capture about 15% of the visible color spectrum within the
word blue.
This range includes very light hues, like powder blue, to very dark ones, like royal blue.
However, speaking of the blues in Russian is different.
There are two categories of blue that correspond roughly to light and dark.
They are gulliboy and signi.
What's interesting is that unlike English, where it's optional to make the distinction within
the general category of blue, the distinction between gulliboy and signi is categorical and
obligatory.
They're actually separate colors, like purple and red in English.
For whatever reason, Russian just linguistically carves up the color spectrum differently than
English.
What's interesting about this linguistic difference is that there doesn't seem to be an obvious
cultural reason for it.
Unlike the example of cultural differences between Japanese and American social hierarchies,
it's hard to make the case that there are major cultural differences with respect to the
color blue between Russians and Americans.
So this is a great opportunity to see if linguistic relativity can operate outside of the influence
of culture.
In one well-known experiment, a team led by Jonathan Winnowar from MIT measured Russian speakers'
speed at differentiating colors within and across these categorical boundaries.
Here's how they did it.
They presented Russian speakers with a triad of color squares on a computer screen.
The top color matched one of the bottom two colors, the target, but not the other color,
the competitor.
The task was to ignore the competitor and find the target color as quickly as possible.
The main finding was that Russian speakers were 124 milliseconds faster at matching the top
color to the bottom target when the competitor was from a different color category.
So if the top color was a shade of Gullaboy, it was easier to match it to the Gullaboy target
on the bottom only if the competitor crossed over to the boundary of C and E.
However, if the competitor was a different shade of Gullaboy, the task took longer.
The idea is this.
When differentiating between target and competitor colors, it's easier when they cross color category
boundaries than when they're within the same category.
Sound familiar?
This is similar to categorical perception of phonemes.
For example, it's easier for an English speaker to distinguish between Ra and La than to distinguish
between the two variations of Ra or two different variations of La.
Now, here's the interesting thing.
This 124 millisecond advantage was not present for English speakers who did the same task.
Why would that be?
Well, for English speakers, there's only one general category of blue, not two.
This is like what happens with Japanese speakers trying to differentiate Ra and La.
It's hard because both of the phonemes are subsumed under a single category.
However, note that these findings go beyond speech sounds in an important way.
The Ra-La distinction is caused directly by phonetic exposure, whereas this difference
in color perception is caused indirectly by vocabulary usage.
For Russian speakers, obligatorily distinguishing colors in speech actually helps them to visually
distinguish them in perception.
Oh, and here's one last wrinkle.
Neuroimaging studies have shown that the language areas in the left hemisphere ventral stream
are engaged when subjects make perceptual categorizations of colors.
This suggests that the Russian speakers in the Winterworth study may have been relying on language
mechanisms to perform this color categorization task, even though language is not required for the task.
Taken together, it seems unlikely that these findings are the product of cultural mechanisms.
For one, English and Russian speakers both use the same full spectrum of colors in everyday life.
And to my knowledge, the distinction between light and dark blue does not have any special
significance in Russian culture.
And two, the fact that language areas in the brain are active during color processing
suggests a likely linguistic mechanism.
Before we move on, let me address something that might be on your mind.
Is 124 milliseconds really that big a deal?
I mean, that's the blink of an eye.
On one hand, it might not matter most of the time.
It's unlikely this color distinction, or lack thereof, is going to make much of an impact
on the everyday lives of Russian and English speakers.
But on the other hand, it might be a big deal, at least on occasion.
Recall that from the perspective of the brain, 124 milliseconds is a long time.
Consider a split-second decision.
What would it mean to have an extra fraction of a second in some extreme situations, like
avoiding an oncoming car, or recognizing a fleeting face, or telling the difference between a gun
versus a wallet?
Sure, these are rare situations, but they make clear that every once in a while, even a small
difference in timing can make a big difference in outcome.
Let's stay with color perception a bit longer.
I want to share a pair of studies that further remove culture from the Worfian equation, and
also start to tell a more complete story about the relationship between small-l language and
the mind.
In 2011, Veronica Kwok and Lee Hai Tan at the University of Hong Kong led a study that
investigated how exposing Mandarin speakers to new words for colors might induce plasticity
in visual areas of the brain.
In the experiment, participants were presented with two shades of green, and they were taught
two made-up labels.
These are made-up words for these two shades.
Ang for light green, and song for slightly darker green.
The same thing was done for two shades of blue with different made-up words.
The training spanned three days and lasted about 40 minutes a day for a total of just under
two hours.
During this instruction phase, participants first listened to the word-color pairings and
then had to actively, they tried to match the newly learned names to the colors in a series
of tests.
They were given feedback until they mastered all four color words.
After training, participants were placed in an MRI scanner to measure how much the training
produced structural changes in the visual areas of the brain.
Even after just three days, there was an enlarged cluster of gray matter in the V2-V3 region
of the visual cortex, which is an area specialized for color.
Now, it's not clear what actually caused this area to get bigger.
It could have been the language training or just the practice of differentiating light and
dark shades of green and blue.
Or it could have been both.
It's really impossible to tell.
However, regardless of what actually caused V2-V3 to enlarge, the findings show that the
brain's inherent plasticity allows for structural modifications even after short bouts of practice.
And given that the effects of practice with linguistic relativity span a much longer time,
years, not days, this finding serves as an existence proof that language can change the
brain independently of culture.
Now, let's switch gears.
I want to share a study that, on the surface, appears to conflict with these findings.
But as you'll eventually see, this apparent contradiction disappears when we use the 3D framework to
consider mechanisms on different levels of analysis across multiple time frames.
The experiment, published in 2017, was led by Anna Franklin and Alicia Skelton from the University of Sussex.
Unlike all the previous studies we've discussed so far on linguistic relativity, the subjects of this study were
four-month-olds.
Here was the question.
Before being fully immersed in language and culture, do pre-verbal infants have an innate bias in how they
process color?
To answer this, the experimenters had babies distinguish between different hues of color.
As with research on infant phoneme perception, the experiment used a habituation paradigm.
You remember that?
That's where babies are repeatedly presented with one thing, in this case a color, and once they get bored,
they're shown something new, in this case the same color paired with a new one.
A dependent variable is to measure infants' looking time to the new stimulus.
If there were longer looking times for the new hue, that would mean that the baby could tell the difference
between the two colors.
In this way, the infants could let the experimenter know how many different color categories they could
distinguish.
It's actually pretty clever, isn't it?
There were two interesting findings.
The first was that infants made color distinctions that aligned remarkably well with color categories
commonly seen in the world's different color lexicons.
This is notable because color categorization in this experiment occurred long before children acquire words for color.
So language and culture aren't part of the picture.
The second interesting thing is infants' color distinctions nicely corresponded to two neural subsystems in the brain's processing of color.
The primary visual cortex, or V1, is organized in a highly structured fashion.
You already know that.
And so you know that there are different dimensions of color requiring specialized computational mechanisms.
These mechanisms appear to act like biological fault lines, and infants seem to use them to make categorical distinctions between hues.
Here's the author's takeaway message in their own words.
These findings suggest that color categorization is partly organized and constrained by the biological mechanisms of color vision and not arbitrarily constructed by language.
But wait, doesn't this contrast with what we just learned from the study by Kwok and her colleagues?
I mean, Kwok used a made-up language, and it doesn't get any more arbitrary than that, right?
But the 3D framework offers a resolution.
The research on infants by Skelton and her colleagues gives us insights into the evolutionary mechanisms of color vision.
These foundations are ancient, so much older than language.
This suggests that the brain's architectural and computational constraints for vision were the impetus to the world's color vocabularies in the first place.
In other words, because our eyes naturally differentiate certain colors, our language systems evolved to name them.
Now, let's link this to the language training study done by Kwok and her colleagues.
In combination with these basic evolutionary fault lines for color differentiation,
experience with language overdevelopment often accentuates these breaks, but sometimes it can alter them.
And that's exactly what we saw with the variation of color terms across Herero, Russian, and English speakers.
By now, the story should be familiar.
There are always multiple mechanisms at play.
Evolution gives humans a genetic head start in color processing.
These combine with the brain's inherent plasticity, which allows social mechanisms over development
to either deepen those pathways or forge new ones based on unique experience.
This hybrid way of thinking about linguistic relativity is gaining more and more support from cognitive scientists.
One compelling account has come from my grad school professor, Terry Regeer, who's now at UC Berkeley.
In 2017, Regeer proposed a helpful way of reconciling how universal foundations for cognition,
like innate color biases, can coexist with the Sapir-Whorf hypothesis.
Regeer's solution was to cast linguistic relativity as a type of Bayesian probabilistic inference,
which in lay terms basically means an educated guess.
The idea is that when we are sure of something, we don't need the help of language.
But as uncertainty grows, so does our reliance on linguistic categorization.
Regeer uses color as an example.
Suppose I gave you a paint chip that was green, but not a perfect green.
There was a noticeable tint of blue to it.
Next, suppose that I held up two more paint chips, one the exact same color as the one you're holding,
and the other a more traditional shade of green, what most English speakers would call pure green.
Under these circumstances, if I asked you to choose the chip that was closest to the one you were holding,
which one would you pick?
This isn't a trick question.
Clearly, you'd pick the correct one, the bluish-green one.
But consider this scenario.
What if instead of holding the original color in your hand, you had to recall it from memory?
Let's say five minutes later, if I held both colors up again, which one would you pick in this case?
Regeer would say that the odds have now shifted a bit and that you'd be more likely to make a mistake.
You'd sometimes pick the pure green one, not the blended one.
What if instead of five minutes later, it was a day later?
Regeer would expect even more bias towards the pure green one.
And how about a week later?
Well, I think you get the picture.
So, what's going on here?
The idea is this.
As the actual perception of the color gets further away, it becomes fuzzier and fuzzier in your memory.
As this happens, you increasingly fall back on linguistic color categories to help you.
Because the original color was much more green than blue, you think to yourself,
Huh, I know it was green, but I just don't know what shade.
According to Regeer, the activation of the linguistic category of green becomes a cue in your memory that nudges you towards picking the one that most people would say is pure green.
Regeer has a catchy name for this mental process.
He calls it the cognitive control knob.
When basic perceptual information is sufficient, like when you can actually see the original color, you don't need to turn the knob.
But as perceptual certainty goes down, you turn up your language to give you an extra boost.
By the way, Regeer's idea has an added attraction.
Not only can it reconcile evolutionary mechanisms with developmental ones,
It also helps to explain why linguistic relativity is so fickle in scientific experiments.
Not all Worfian effects are reliable, and Regeer's cognitive control knob offers a reason why.
Perhaps the effects of language kick in only when uncertainty is high in an experiment,
but when perceptual certainty is crystal clear, there's no need to turn up the language knob for help.
Let's finish up by viewing this cognitive control knob from an even broader perspective.
Regeer's idea is a classic domain general approach to understanding the mind.
At its core, the mechanism is basically a Bayesian probability analysis.
When you're uncertain of something, how do you weigh different information or cues to constrain your decision?
This is an extremely general process.
It applies not just to language cues, but all possible constraints on decision-making.
For example, connecting back to McWhorter, why can't we think of culture as a constraint, too?
In fact, this is exactly how my colleague down at Cornell, Daniel Casasanto, views it.
Casasanto likes to relate linguistic relativity to what he calls cultural relativity.
What he means by cultural relativity is something similar to Worf's linguistic relativity.
In Casasanto's words, certain aspects of people's thinking vary relative to the cultural practices they engage in.
In one of his favorite examples, he talks about metaphors for space being used to conceptualize the passage of time
and how different cultural practices lead to different metaphors.
First, he sets this up by pointing out that people across all cultures use spatial metaphors to talk about time.
For example, in English, the past is behind us and the future is in front of us.
These metaphors are so natural that they make great fodder for marketing and political campaigns.
Consider Joe Biden's 2020 slogan for U.S. president.
Our best days still lie ahead.
Actually, there's a couple of metaphors in there.
Where do these spatial metaphors come from?
Going back to a paper from 1973, the Stanford linguist Herb Clark hypothesized
that it's the result of the way the human body naturally moves through space.
Because our heads, hands, and feet are biologically pointed to the front,
that means that most of the time we move forward through space.
And because it takes time to travel through space,
we unconsciously learn to map the future to what's ahead of us and the past to where we came from.
Makes sense, right?
Now, why humans are inclined to think metaphorically in the first place is a separate and fascinating question.
And we'll talk about that in the final lecture.
Casasanto makes an interesting observation.
The sagittal axis, front and behind, is nearly universal for spatial metaphors for time.
But no known language has ever verbally referred to time on the lateral axis, left and right.
So in English, you'd expect to hear Monday comes before Tuesday, but not Monday is to the left of Tuesday.
Now, even though we don't explicitly say such things, what's interesting is that speakers of English implicitly think like that.
I'm going to tell you about a seminal experiment that demonstrated this,
and I want you to try to explain the pattern of results on your own.
Back in 1991, the Stanford cognitive scientist Barbara Tversky had over a thousand English-speaking and Arabic-speaking children and adults
place stickers labeled breakfast and dinner relative to a sticker named lunch on the middle of a table.
Here's what she found.
The English-speaking subjects were much more likely to place the breakfast sticker to the left of lunch and the dinner sticker to the right of it.
The Arabic speakers did the opposite.
Breakfast was placed to the right and dinner was placed to the left.
Can you think of an explanation for this?
I'll give you a hint.
Hebrew speakers arrange things like Arabic speakers, not like English speakers.
What's culturally common between Arabic and Hebrew?
They both are read and written from right to left, not left to right like English.
So it appears that the cultural convention of reading and writing has caused the two groups to conceive of the arrow of time differently.
By the way, this can also be seen in the hand gestures that accompany speech.
To refer to the past, Americans gesture to the left, but Arabic speakers gesture to the right.
But a problem remains.
Correlation does not equal causation.
How can we know for sure that the cultural convention of reading and writing is actually causing all these interesting patterns?
To pin down causality, Casasanto and his colleague, Roberto Bottini, devised a clever little experiment with Dutch speakers.
Like English, the Dutch read and write from left to right.
In the experiment, subjects were asked to read phrases that had a common spatial metaphor for time, like a year earlier.
The task was to press a red button if the phrase was about the future, and a blue button if it was about the past.
Now, here's the key manipulation.
The red button was situated on the right side of the screen, and the blue button was situated on the left.
There were also trials that counterbalanced the colors to rule out color as a cause.
Importantly, the experimenters never mentioned the location of the buttons, only the colors.
This was to ensure that subjects didn't figure out that the location of the buttons were relevant to the experiment.
The main finding was that subjects were faster to press the buttons when they spatially matched the flow of time.
So when they read a year earlier, they would press the button when it was on the left faster than when it was on the right.
This was flipped with sentences about the future, like a year later.
Now, here's the most interesting thing.
Some subjects were asked to read sentences that were mirror-reversed, which meant that they had to go from right to left, not left to right.
This is initially hard to do, but really, with just a little bit of practice, people can learn to do this very easily.
What's remarkable is that even after just five minutes of this practice, the spatial effects completely reversed.
Now, people were fastest when pressing the left button for the future and the right button for the past.
This is a nice example of the usefulness of the experimental approach.
Because the same subject showed two different patterns, we can rule out that language or other cultural factors were at play.
Those things were held constant, and the only thing that differed across conditions was the reading direction.
Maybe you're not convinced that reading direction is a meaningful cultural convention, so let's finish up with a much more canonical one.
I want to share a classic study done back in 2001 by Takahiko Masuda of the University of Alberta and Richard Nisbitt of the University of Michigan.
They explored a well-known cultural difference between Japanese and American people.
Japanese culture focuses more on how individuals collectively fit into a social context, whereas American culture focuses more on individual autonomy.
Might these different cultural values shape basic cognitive processes of the mind?
The experiment asked participants from both countries to watch a short video of an aquarium scene.
In the foreground, there was a large central fish flanked by some small fish swimming past seaweed.
There were also some other peripheral details like shells and crabs and bubbles in the background.
After watching the video twice, both groups were asked to verbally recall everything they saw in the video from memory.
The main finding was that Japanese speakers excelled at holistically remembering the scene,
for example, recalling details about stationary objects and smaller critters in the background much better than Americans.
However, there were no differences in how both groups remembered the large focal fish or other moving objects that were more prominent.
These findings were taken as evidence that basic cognitive processes, like attention and memory,
are influenced by cultural values regarding the holistic analysis of a situation.
Japanese culture values how an individual's behavior fits into a larger context, American culture much less so,
so that's what the Japanese subjects notice and remember from viewing a scene.
These cultural effects can even be seen within the same individual.
Ying Yi Hong of the Chinese University of Hong Kong has studied bilingual Chinese and English speakers
who identify as biculturally with America and China.
In one study, language was held constant, but different cultural mindsets were primed through different cultural images,
like an image of Abraham Lincoln versus Confucius.
Following these primes, subjects had to describe an ambiguous scene involving a fish swimming in front of several other fish.
The most interesting finding was that when subjects were primed with an American image,
they described the fish from an individualistic perspective.
The fish was leading the group.
But when primed with a Chinese image, they described the fish from a more collectivist perspective.
The group was chasing the fish.
This shows that cultural mindsets are extremely dynamic and flexible,
and it suggests that even when you hold language constant,
the same person can entertain multiple frames in any given moment.
If you think back to Regeer, this fits nicely with his cognitive control mechanism.
When there is an ambiguous situation and a cultural frame is prominent,
you turn up the control knob to allow cultural information to interpret the situation.
It works with language, so why not culture, too?
So where are we with linguistic relativity?
I think the results from the experiments I presented in these lectures most safely lead to the following conclusion.
Language and culture both influence thought.
Sometimes they operate in isolation, but often they work in tandem.
In fact, they work together so naturally that the debate on linguistic relativity may benefit not from pitting one against the other,
but rather embracing and better understanding how they enable and enhance one another.
In the next two lectures, we'll move on from these small L effects of language
and consider the broader question of how having any language or languages affects the human mind.
