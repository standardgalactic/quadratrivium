Hi. Welcome back. In this lecture, we're going to talk about something new. It's called crowdsourcing.
And crowdsourcing taps into the power of information technology to get large numbers of diverse people to work on a problem.
So in a sense, what we're going to do is we're going to combine the amazing story of the Netflix prize competition, which involves prediction,
with the lessons that we've just learned about diversity and problem solving.
So these two core lessons are going to help us understand how crowdsourcing, which is basically this idea of getting a large community of people to perform some task, really works.
Now crowdsourcing has a large number of passionate advocates. It also has some critics, and I'm going to introduce you to both.
And many of these people have some larger-than-life personalities, so it should be some fun.
I'm going to conclude by talking about what we've learned from crowdsourcing and applying it to some broader questions, like how big should our group be
and how much diversity should we really have on a particular problem.
First, though, I want to make a personal aside and a confession.
When I was an undergraduate at the University of Michigan, I was fortunate to have a handful of professors who took a real interest in me and who shaped how I think.
One in particular was a man named Bert Hornbach, who taught an English class, and then he taught a class on Dickens.
And I remember him telling us in the Dickens class how later in Dickens' life when he was contemplating all the characters that he created,
so the nefarious Uriah Heap, the wave-like Pip, Mr. Barnacle, the famous Office of Circumlocution.
Dickens basically said, look, like many fond parents, I have in my heart of hearts a favorite child, and his name is David Copperfield.
So Dickens was coming clean. He said, look, Copperfield is my favorite character.
Well, I'm going to say the same thing about this lecture. I've loved writing and presenting all these lectures, but in my heart of hearts, this one's my favorite.
In the past five lectures, we've talked about how diverse perspectives in heuristics can help us solve problems.
We've seen how diversity can trump ability. We've learned how ideas and heuristics recombine to drive innovation and economic growth.
Remember we had bacon ice cream? These ideas and heuristics are contingent, though. We learned that, right?
No one heuristic or tool works on all problems. There's no free lunch. Sometimes it's big rocks first, sometimes it's big rocks second.
So one conclusion that one can't help but draw from what we've learned is that maybe there's going to be cases where we've had lots of people, lots of diverse people working on problems.
And that's absolutely true. It's a great insight. And it's the same logic, by the way, that underpins the success of pluralistic market economies.
What do I mean by pluralistic? I mean that a free market allows everyone to contribute. No one is politically excluded from participating in the market.
That means that in theory anyone can work on any problem in the marketplace.
And the fact that problems have market values associated with them means that people tend to work on problems that produce more economic rents that have more social value.
So that means more people spend time developing cancer curing drugs than spend time designing staplers.
Because the reason is the staple market just isn't of sufficient size to draw lots of diverse minds and the problem isn't that hard so you don't need lots of people working on it.
Whereas cancer is exactly the opposite. It's a really hard problem and it's incredibly important.
Now there's some caveats here, right? Because markets do create distortions.
More energy spent thinking about how to satisfy the desires of rich people than poor people.
But if we look at the problem from 10,000 feet, I don't think it's at all inaccurate to say that market incentives bias effort toward more important problems.
And most of that problem solving, I can't put a number on it, occurs in secret.
That's what's sort of interesting. It's in a lock box, right? It's done by private firms that don't have incentives to share it.
Or it's sometimes done by government agencies who want to keep what they do private.
Now you might say that, wait Scott, isn't a lot of R&D done in universities?
And all of that is put out in the open. It's on web pages, it's on journals, people can read it.
That's true, but if you actually look at the numbers, only about 10% of R&D is done in universities.
Let me try and put some real numbers on this. So I teach at the University of Michigan and U of M spends over a billion dollars a year on research.
That's a lot of money. Now historically, University of Michigan's and Johns Hopkins have been the two universities that spend the most on R&D.
It's over a 10-year period, you're always going to see them ranked number one or number two.
Now you can read about all the research that they do at these universities on the web.
And you can also attend a lot of the seminars and even contribute yourself to the production of this knowledge.
However, if you compare the University of Michigan or Johns Hopkins to a big pharmaceutical company like Pfizer,
or a big computer company like Microsoft, we don't look so big.
Microsoft spends a lot of money on R&D.
How much? 8 to 10 times as much as the University of Michigan.
How about IBM or Cisco? 5 times as much.
What about Google? 3 times as much, but they're growing.
And here's the thing to think about.
Places like Michigan, Harvard, Johns Hopkins, Berkeley, they're covering a ton of fields.
These companies aren't spanning all of research. They're studying one thing.
So a university does research on the brain, on drugs, on computers, on social science,
battery technology, artificial intelligence, prosthetics.
So we're small potatoes in some respects compared to these big companies.
Well, here's the rub. Take a company like Microsoft or Pfizer.
They're not going to share what they learn.
That's because they're trying to take what they learn and turn it into some better product,
get larger market share, and make more money.
Now, one of the costs of not sharing, it means that fewer people can provide input to their problems
and fewer people can take what they learn and apply it to other problems.
So this means that these companies aren't getting the best solutions they could get,
because not everybody's involved.
And it also means we're not getting the best products and ideas we could get.
So then you might think, hey, wait a minute, why don't firms open up their problems to more people
and then they can get better solutions?
Well, think about it. That's where the Netflix prize enters.
That's exactly what Netflix did.
They opened up their problem to the world and they got a better solution.
So firms are figuring this out.
They're learning, hey, if we open up a bit and we allow more people to work on our problems,
then we can get better solution.
This is what crowdsourcing is.
So what exactly is crowdsourcing?
Crowdsourcing is opening up a problem to a population or community,
oftentimes with a minimum of coordination.
Now the term is originally coined by Jeff Howe,
and crowdsourcing leverages the capabilities of populations
that have diverse ways of looking for solutions.
So it's basically the idea of sourcing a problem out to a huge crowd of people.
Now it's proven really successful in things like writing open source code,
in things like producing consumer goods and medical devices,
and it's even had some success in things like vehicle and building design.
Now if you want to try and unpack the successes, what causes them to work,
we're going to see a mixture of causes.
So one thing is that crowdsource competitions attract problem solvers
with diverse perspectives and heuristics.
That's the thing we've talked about.
That's sort of in general why it works.
And I've also talked about the Netflix Prize, right,
which is this example of crowdsourcing and we tapped into all these different ideas.
But there's other examples.
So one, one of the most famous ones really involves looking for gold.
So let me give you the history of this.
There's a Canadian mining company called Gold Corp.
They had this mine, the Red Lake mine that was in Ontario.
Now this mine wasn't producing as much gold as they thought it should.
So what they did is they had a competition and they said,
look, here's all of our maps and we'd like people to help us find the gold.
Now if you don't give people any information about the mine,
the crowd can't help, right?
If you just said find me gold in Canada, I'm not going to be able to use.
So what Gold Corp did is they posted every bit of information they had about the mine on the web.
They just put it all out there.
And then they said, look, we're going to give prizes to people or teams
who can identify the most gold.
What happened?
Well, there was a diverse group of people, really smart people, who participated.
And they identified over 100 places for Gold Corp to look for new gold.
Over half of those places were new.
There were places where Gold Corp had not looked before.
Now when the contest began, the mine was producing approximately 53,000 ounces of gold per year.
When it ended, 504,000 ounces.
That's a tenfold increase.
But not only that, these were better sources.
And the cost of getting the gold fell from 369 an ounce to $59 an ounce.
What happens to the value of the mine?
Well, it made a big jump as well.
It was worth 100 million before the contest, 9 billion after the contest.
That's 90 times the value.
Oh, by the way, who won?
Who was one of the people that found the most gold?
Well, it wasn't a person.
It was a team.
It was a team of people from Australia.
Think about it.
Australia is a long way from Canada.
These people haven't even been to Canada, yet they found the most gold.
That's the power of crowdsourcing.
So if you think about the Netflix Prize, the Gold Corp Challenge, these are amazing, right?
And they're written up in a whole bunch of different books.
But it's sort of a one-off demonstration.
There's more of them.
Here's another one.
Which was a government-sponsored program in which people earned points by folding proteins on a computer screen.
Now, protein folding problems are sort of like three-dimensional puzzles.
And they're really difficult.
So computer algorithms can't do it, but people can.
And that's because they're sort of visual problems.
Now, protein folding isn't just like a fun thing to do.
It's crucial in the development of new molecules.
So the pharmaceutical industry is really interested in how do we fold these proteins?
Well, that folded has been this amazing success.
And in being a success, it's driven home the value of diversity.
Because who are the best folded players?
Well, as you'd expect, a lot of professional scientists are really good at it.
Well, guess who else is?
Teenagers.
Gamers.
People who spend a lot of time on the web.
So you've got these professional scientists on the one hand and teenagers on the other.
Go figure, right?
There's a lot of really interesting toolboxes of skills out there, and they can all help on hard problems.
But again, these are one-off examples.
They're captivating, but there's this bigger question.
Can crowdsourcing be made systematic?
How does it work and when does it work?
Well, one of the first people to think about how do we leverage crowdsourcing systematically?
It was a guy named Elf Bingham.
Elf's just a wonderful guy, and he worked at Eli Lilly.
And he set up this company called Innocentive.
So Innocentive, here's the business model.
They basically say, okay, you have a problem?
Post it.
Just send it to us and post it and give us a reward.
Tell us how much you're going to pay for a solution.
Now, originally Innocentive, because it started in the pharmaceutical industry,
concentrated on problems in pharma, but now they've branched out.
So suppose, for example, you want to find a harmless chemical solution, some sort of solution,
that's going to turn blue whenever it comes into contact with ammonia.
Well, suppose you can't figure it out.
What you do is you just post it on Innocentive, and they're going to send it out to their community.
So let's call that community the solver community.
It turns out already they've got over 100,000 people in it.
So these are all people out there looking for problems that they might be able to solve.
Now, this is a totally cool idea, right?
Just you're sort of like, it's like the Wild West.
You're putting up wanted posters and hoping somebody could find the solution.
But has it worked?
Yes, it's totally worked.
Innocentive solves around 40% of the problems that get posted.
40%, that's pretty good.
In fact, it's incredible.
Because these are problems that couldn't be solved beforehand.
So you've got a company like Pfizer, right, that spends more money than major universities on research.
They can't solve a problem.
They post it, and Innocentive can.
So this 40% is just amazing.
Why?
How does that happen?
Well, we know the answer when studying it.
It's diversity.
Innocentive isn't tapping into smarter people.
It's tapping into a broader collection of scientists.
Now, you might say, OK, Scott, that's just speculation.
How do you back that up?
Well, here's how you back it up.
Cream Lacani is a friend of mine who teaches at Harvard Business School.
And one of his co-authors, Lars Bo Jepsen of Copenhagen Business School,
have looked at Innocentive's success in great detail.
So what they did is they looked through all these contests,
and they said, OK, which ones does it solve, and which ones doesn't it solve?
Well, here's what they find.
Problems that get posed with greater generality
that attract a more diverse set of problem solvers
turn out to be more likely to be solved.
So for example, recently posted problems say something like,
here's our problem.
We want to understand the flowability of powder blends.
Now, this was posted by a manufacturer who uses blends of powders, right?
And he wants them to flow.
And he doesn't understand why some powders flow through pipes really smoothly,
and others do not.
So this challenge wasn't posed as a mathematics problem.
It wasn't posed as a physics problem.
It wasn't posed as a chemistry problem.
Or as a material science problem.
It was just posed as a problem, flowability of powders.
So as a result, what's going to happen
is it's going to attract a diverse set of problem solvers.
And if one of them can solve it, she's going to get $20,000.
Or if she is part of a team can solve it,
they'll split the $20,000.
So what's another problem?
So one problem that was asked recently is,
how do we prevent apple juice from browning in the bottle?
OK, again, a totally open-ended question.
I didn't say it's a chemistry problem, right?
It's totally open-ended.
Now Lacanian Jefferson found that these problems,
these open-ended problems, attract what they call marginal problem solvers,
people who normally wouldn't look at the problem.
And they're more likely to find solutions.
And this is in some sense the brilliance of Innocentive,
because it's bringing in people with different toolboxes to solve problems
and sometimes those different tools work.
Now Innocentive isn't the only crowdsourcing platform.
These things are sprouting up all over the place.
So recently a consortium called CERMO
arose in England to crowdsource medical problems.
DARPA, which is the research arm of our Defense Department,
has crowdsourced things like the design of vehicles.
I actually worked with DARPA on some crowdsourcing data with vehicle design.
It was really interesting to see all the diverse opinions and proposals
that people had for how to design a Jeep.
Now there's a company called Threadless that was started in Chicago
by a guy named Jake and a guy named Jacob,
and they crowdsource T-shirts.
So you can do anything.
You can do military vehicles. You can do T-shirts.
Now crowdsourcing can consist of having groups of people collectively working on a task.
So that's what occurs in open source coding and stuff like that.
It can also consist, though, of decomposing a big problem into small problems.
So this occurs in things like crowdsourced air checking,
or you can even think of Wikipedia, the online encyclopedia,
as an example of crowdsourcing.
And last crowdsourcing can even be just open competitions,
like the Netflix Prize.
Now this idea of open competitions isn't a new thing.
In fact, it goes back, you know, 700 years.
For example, in August of 1418, Florence held a competition
to build the cupola for the Santa Maria di Fiori.
So the winner, who's Brunelleschi, right,
he won actually by borrowing ideas from the Pantheon.
So we see this again, this recombining.
He went and visited the Pantheon and said,
hey, I think we can do the same thing over here.
Now the interesting thing, this wasn't the first competition, though.
It actually even wasn't the most famous one in which Brunelleschi took part.
He'd previously lost a competition to cast the bronze doors
of the Baptistry of San Giovanni.
And so that's probably why he went to visit the Pantheon,
to get some new ideas to do better.
Okay, so this crowdsourcing gets a ton of buzz.
It's really cool.
We're using information technology, tapping into diverse minds.
Fabulous, right?
And there's a lot of books written about it, interesting web pages as well.
But you know what?
Like anything else, it's not a panacea.
So I want to describe three problems with crowdsourcing.
And I'm going to group these under the headings of the problem of sharing,
the genius or gadget problem,
and then the issue of pay to play.
Let's take these in turn.
So the problem of sharing.
Remember, early in this lecture, I spoke about how most research is done in firms
that don't always want to share what they know.
The reason they do the research is to make these cool new products
and offer new services,
but they don't have incentives to share that with everybody else
because then they wouldn't make money.
So let's look closely again at this Netflix prize,
because Netflix is releasing a lot of data about movie rentals and about people.
But here's the thing.
That information couldn't be used by anyone else.
The reason why, the users' names were kept private.
So even if somebody else did use it,
Netflix didn't see how some competitor could use it to cut into Netflix's market share
because they didn't know who the people were.
But let's suppose, you know, Ford Motor Company said,
hey, boy, that Netflix prize was great.
We're going to release all sorts of data on who buys which cars at which price.
Well, that would be a mistake
because competitors could probably swoop in and figure out
how to offer price incentives to lure away Ford's customers.
So Netflix was safe, but Ford might not be.
What about Gold Corp?
I mean, they put a ton of information about their mind on the web.
I mean, everything they knew.
But here's the catch.
They own the mind.
They own it.
So that information was only valuable to the person who owns the mind.
So therefore, there was no cost, zero for them, of putting that on the web.
What about an incentive?
Well, the problems are posted anonymously.
So you don't even know who's posting it.
So Procter & Gamble could be one chemical process away from a creating a shampoo
that straightens out cruelly here.
And they may be able to post the problem that if that gets solved,
they'll complete the chemical process.
And their competitors might not have any idea what they're up to.
So there's a way to sort of hide what you're doing.
Also, keep in mind this.
Nobody goes to an incentive unless they can't solve it themselves.
They might as well try and get the solution some way.
One last point on the sharing problem.
This is why government-funded research is a good thing.
Because the solutions get shared, the problem gets shared,
and it's just more likely we're going to solve them.
Okay, now this gadget issue, this geniuser gadget.
The most vocal critics of crowdsourcing don't point to the sharing problem.
They acknowledge it.
But what they argue is, look, crowds don't produce anything of genius.
They're more like gadgets.
Mozart wasn't a crowd.
Einstein wasn't a crowd.
Michelangelo wasn't a crowd.
Quick, name a great piece of literature written by a crowd.
Okay, it's a fair criticism.
But remember this.
Edison was a team.
He worked with a team of scientists.
And the Edison models become the norm.
Science has become team-based.
Remember I showed all that data.
Teams drove innovation at Bell Labs.
They drive innovations at Apple, at Google, at Oracle, at Microsoft, at Genentech.
I mentioned early in this course, teams of scientists are producing most great breakthroughs.
And for those great books, hold on to that thought for a second.
Give me a couple of minutes.
I'm going to be among the first people to say that there's a limit to what crowds can do,
and there's limits to crowdsourcing.
It hasn't been able to produce the sort of sublime things that we like to see.
Now this idea that crowds can't be genius gets its most coherent voice in a very engaging book
by Jaron Lanier, which is called You Are Not a Gadget, a manifesto.
It's a brilliant book.
Lanier is really just a muse of the tech community.
And he makes two points that are relevant to this course.
First, he argues that anyone commenting on everything has led to lots of raw opinion.
So you've got all these people commenting on everything.
It's just too much raw opinion.
And the result is we end up with just a bunch of group thing,
which locks us into inefficient platforms and paradigms.
I totally agree.
Group thinks bad.
And we're going to talk about that in a few lectures.
But group think results not from diversity, but from a lack of it.
Second, Lanier argues that nothing transcendent or beautiful comes from lots of people
kibitzing on problems.
I agree there as well, but only partially.
Transcendent ideas do tend to come from individuals.
But those individuals tend to be in diverse, vibrant communities.
And the Renaissance occurred in a particular place in time, Florence in the 15th century,
and did so for some very particular reasons.
Moreover, even transcendence gets refined.
Even poets have editors.
And in more pragmatic pursuits, kibitzing appears to add substantial value.
So the auto industry has this established practice of showing prototypes that auto shows.
They do this because vehicle design is improved when you have consumers looking at products.
They can add value to design.
So notice that Lanier is bumping up against a very deep question here.
How many people should work on a problem?
Should it be one? Should it be a team?
Should it be a huge crowd over the internet?
Well, people who study problem solving have thought a lot about that.
And one way to begin to get a handle on it is to distinguish between conjunctive and disjunctive tasks.
So on a conjunctive task, everything is connected to everything else.
So writing a novel is conjunctive.
So is writing an opera.
That's why they're better written by one person.
In contrast, a disjunctive task can be separated and the parts can be solved in isolation.
So if I'm writing a computer program that scrubs the web for blog posts about Luxembourg,
then I can sort of break this code down into different tasks.
Scrubbing, organizing, and analyzing.
And these can be written in isolation once I make a few decisions about the form of the data structures.
So I can decompose it.
The Netflix Prize, the Gold Corp Challenge, and the types of problems innovation in Ascentive Post
aren't conjunctive. They're disjunctive.
That's why we can open them up to crowds.
So we aren't a gadget, right?
We're capable of doing sort of amazing things with the tools that we have.
Okay, now I'm not saying that we're not getting better, though,
at having teams and large groups take on problems, even crowds.
We're getting better at conjunctive tasks.
It's only partly true that great books are not written by teams.
So read the acknowledgments of any biography.
So, for example, take Walter Isaacson's award-winning life of Einstein.
Notice all the people he thanks for helping him with the research and the writing.
It's an incredibly long list, and it includes some pretty famous physicists.
So think about it. Let me push this a little bit further.
Movie screenplays are a lot like books, and there are very few screenplays written by one person.
There's even a job classification of script doctor.
Why is that?
Well, I think it's because the cost of releasing a book is less than $10,000,
and the cost of releasing a movie is 1,000 or even 10,000 times that much.
And so because it costs so much more and it's so much more valuable,
we don't leave it to a person. We have a team do it.
Now, could it also be maybe that crowds are better at writing than individuals
and that if it did cost $100 million to release a book,
then books would be written by teams and not individuals?
Well, I can't say for sure, but I guess I would guess yes.
I think they probably would be.
Now, that doesn't mean we're going to crowdsource literature,
but I think we're going to go part of the way there.
Now, here's a really helpful way to think about crowdsourcing,
and it comes from our previous lecture.
Think of it as a heuristic. It's one way to solve problems.
And what did we learn about heuristics?
We learned that they're contingent.
So just like there's big rocks first and little rocks first,
crowdsourcing will sometimes work and sometimes it won't.
So the goal is to figure out when it will work.
More on that in just a second.
So the final concern I have turns on this cost and benefits.
This is what I call pay to play.
Most of the crowdsourcing examples, most of these examples,
they don't seem to make economic sense if you scaled up.
So for example, Threadless, the t-shirt company,
pays out about $10 per design.
DARPA had this thing called the Red Balloon Challenge,
which people tried to find 10 weather balloons hidden
in plain sight across the United States.
It paid out only about $10 per team.
These were teams of scientists working for hours,
and they only paid out $10 total per team.
You know, Senev, in its first decade of history,
paid out only about $40 for contributor.
Now, the Gold Corp Challenge,
which had a huge amount of money, relatively speaking,
only paid out $500 per team.
And the Netflix prize, if you take the total amount of money
they gave out, was only $50 per team.
Now, remember, people spent three years on this project.
So that's just not enough money.
That's far below what we consider to be a reasonable wage
given the skills that these people had.
These were really smart participants.
So given the negligible monetary incentives,
crowdsource design must rely on other motivations.
People must implicitly pay to play.
The incentives to contribute have to exist
from something other than money.
Now, they can include the novelty of participating,
opportunities to build human capital,
possibly to compare one skill against somebody else.
That was true in the Netflix prize.
Or it can just be a deep concern or stake in the ultimate design.
So this holds for things like crowdsource,
prosthetic designs. People really care.
Or it can just be to build reputations.
So John Malone, who we talked about before,
we talked about group IQ,
he talks about these non-monetarian motivations
as falling into two categories,
love and glory.
It gets a nice way to think about it.
Any effective crowdsourcing effort
probably has to leverage one of those two things,
either love or glory,
because the pay won't be enough.
Crowdsourcing, right, by definition,
takes up time and effort from a lot of people,
whether these people are paid or not.
So one thing we can say right away
is that the only crowdsource,
or for that matter, sign a problem to a teen,
if it's really important.
One of my favorite commercials ever,
shows two people in the produce section of a grocery store,
shaking, smelling, and rolling cantaloupes in their hands,
trying to find just the right one.
All the while, other people are walking by,
grabbing cantaloupes and looking at them
like they're just really strange people.
Now the tagline for the ad is,
are you spending time on the right decisions?
So the point is this,
there's a meaningless problem.
The harder and more important the problem,
the more you need to figure it out,
and the more you need to think about
how should we tap into diversity.
So you don't need to enlarge the pool and crowdsource.
If you're trying to figure out which shampoo
should I use this morning.
Second, let's think about what we know about diverse groups.
What have we learned so far?
We've learned that the more people,
and the more diverse those people think,
the more perspectives you have,
the more heuristics you have,
and the more solutions.
As far as empirical facts go in social science,
this one's pretty indisputable.
We've got decades of research and problem solving
showing you've got more people and more diverse people
in larger groups, you're just going to get more solutions.
But here's the thing,
by tossing a design problem out
to an enormous diverse group,
that can create problems
because you've got too many solutions.
Here's why.
Well there's also abundant social science research
showing that when you've got lots and lots of ideas,
they're going to be very good.
And we also know that when you confronted
with thousands of possibilities,
groups can become cognitively overloaded
and you can make bad choices.
You can have what some people call the paradox of choice.
So if you have a million solutions,
you need some way to accurately,
quickly, and cheaply evaluate them.
I'm going to call this an oracle.
Crowdsource problems work best
when there's an oracle,
like literally like a Delphi,
we can go with the answer right away.
People can just put their model in,
test it against this testing set
and find out right away, perfectly,
how well it worked.
Now Goldcorp had a nearly perfect oracle.
They could just go to the mind and look for the gold.
So it cost a little bit of money, but not that much.
So Netflix could handle
literally millions of researchers.
Now Goldcorp could probably handle only a few hundred,
but that's still a big number.
Problems that don't have oracles
are going to be hard to crowdsource.
That's why we can't just open a website
to crowdsource solutions
to things like improving education
or ending poverty.
Why not? Well, think about it.
Let's think about education.
So I suppose you wanted to determine
if some type of schooling was going to succeed.
Well, that's going to take years,
maybe even decades to see the results.
Or if you wanted to see, like,
well, this curriculum reform
improves student performance.
Well, student performance depends on a mixture
of individual characteristics, motivation, health,
and what you're going to know if it works.
And so therefore, if you have too many ideas,
we can't figure out which one's best.
Now, something doesn't have to be complex
to lack an oracle.
It could be low-dimensional and not at all complex.
Consider designing a coffee table, no oracle.
But that's going to be hard to crowdsource.
But this is funny.
It's not true of things like improving the aerodynamics
of a car that's easily crowdsourced
because there's computer models
that calculate aerodynamics.
But then, what about writing popular music?
Well, no oracle.
But there are computer programs that can predict
with some accuracy what we'll sell and what won't.
So maybe someday we'll have an oracle.
In the meantime, we somehow need to get Quincy Jones
to sit back and listen to a few tracks.
Unfortunately, there's not hours in the day
to have Quincy listen to all the music.
Now, wait a minute.
You might say, what about threadless?
Didn't I mention a t-shirt company?
There can't be a t-shirt oracle.
So that's right, there isn't.
So how does threadless do it?
They use a t-shirt each week.
They must have some sort of algorithm, don't they?
They must have some way of doing it.
Well, guess what they do?
They use a crowd.
And here's where the future lies.
To use diverse crowds as oracles.
To use diversity twice.
So first, you use the power of diverse perspectives
and solutions to come up with solutions.
That's the diversity-trumps-ability idea.
Then you use diverse predictive models
to decide which one's best.
This is what threadless does with t-shirts.
So this approach that combines
idea generation and evaluation
underpins a host of new endeavors.
It's just a brilliant idea.
We can call it double crowd sourcing.
And it may well change a lot of how we live and work.
But that's only really the start
because eventually the crowds will be more diverse
because they'll include both people
and computers in both phases.
Both in the problem-solving stage
and in the determining what's a value stage.
So in the meantime, we sort of look at
what's going to happen in the future.
So in the meantime, we sort of sit back and wait
and think about all the exciting ways
in which diversity is going to give us
new products, new ideas,
new cures for diseases,
and just a more interesting life.
Thank you.
