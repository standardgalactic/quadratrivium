Hi, welcome back. Throughout the course, we've been talking about the benefits of diversity,
about how cognitive diversity, both within a person and within a team, can improve performance
on predictive tasks, how it leads to more potential solutions and therefore can improve
problem-solving. We've even seen how diverse ideas can be recombined and how different
ways of thinking can prevent large-scale failure and collapse. We also saw the almost inescapable
benefits of diversity, how diverse collections do better, provided that we just make sort
of the standard assumption of diminishing returns to type. But we've been careful. We've
been careful not to naively say, more diversity is always better. Remember how we talked about
diverse perspectives leading to miscommunication and the Mars orbiter becoming the Mars crash
lander? We've also talked about how most perspectives actually won't help us find better
solutions because they're just going to create random landscapes where we really can't really
climb them very easily. And finally, we've talked about how for irreversible processes,
like cooking, we actually don't want diversity because experimentation is just too costly.
Hence it really is the case that too many cooks spoiled abroad. Now in the previous lecture,
we discussed the reason why organizations and individuals need to promote diversity,
and that is to avoid groupthink. Because we talked about four causes of groupthink, conformity,
drift, homophily, which is the tendency to hang out with people who sort of look and
act like us, and then even incentives. So to avoid groupthink, we need to somehow push
in the other direction because groupthink, I mean, we don't get the diversity we need
in order to make those good predictions, in order to solve our problems. So we have to
think about how do we structure our organizations or institutions to push against groupthink
and create diversity. Now remember early on in this course, I said we want to avoid those
blanket statements, like diversity is good, and instead we want to unpack logically what
types of diversity produce benefits, and even talk through the mechanisms through which
they operate. Now correspondingly, we also want to learn which types of diversity create
problems, and learn about the mechanisms through which those operate. And that's actually
going to be the focus of this lecture. We're going to focus on a type of diversity that
creates some rather large problems, and this is preference diversity. What we're going
to see is that preference diversity can just be, well, a pretty bad thing. It can undermine
many of the benefits that we get from other types of diversity, particularly diversity
and problem solving and prediction. Now to get us started, I want to make a distinction
and then a logical point. So first the distinction. Preference diversity means wanting different
outcomes, wanting different things. That's different from cognitive diversity, which
is possessing different ways of thinking about the world, different tools. Now the logical
point. Cognitive diversity solves problems. Preference diversity, well, it creates them.
So let's take these one at a time. What are preferences? Preferences describe what we
want. So some people like peanut butter and jelly sandwiches, and there's even a few people
who like peanut butter and banana sandwiches. What social scientists, what we do is we represent
preferences in two ways. So when we're talking about preferences for a particular quantity
or an amount, what we try and do is write down a functional form. Let me show you how
that works. So I like to swim. In the summertime, one of my favorite things to do is go out
in Michigan's beautiful lakes and just swim in the open water. Now suppose we wanted to
write down my preferences for the amount of time that I spend swimming per day. So we
would have some variable down here that we would call time, and we could graph my happiness,
which is on this axis, as a function of time. So if t equals 0, if I'm not swimming at all,
I'm not happy. Well, if I swim for 15 minutes or a half hour, I get happier and happier.
And maybe if we draw this graph and we get up to maybe like an hour and a half, I reach
a peak. You know, if I'm swimming like maybe just a little over an hour, I reach a peak,
and then it starts going down. Now if I swim three hours, once we get time equals 3, I'm
actually no happier than I were if I wasn't swimming at all, because I'm just exhausted.
And if I had to swim more than three hours, I'd be less happy. I'd see this as just work.
So what we do in this graph is we're sort of running my happiness as a function. Now
here's the point. Different people have different preferences, and therefore we have different
graphs. So let me show you how this would work. Let's take someone like Diana Nyat, who's
the famous long-distance swimmer, who swam across Lake Ontario, around Manhattan Island,
and tried to swim from Cuba to the United States. Her swimming happiness curve probably
doesn't top off in an hour like mine. It probably tops off way out maybe four hours.
So let me draw her graph. I'll draw this in a different color. So her graph, it's probably
going to sweep up and maybe not reach a peak until about four hours and then go down. So
what we've got is Diana's graph looks like this, whereas my graph looks like this. So
we have two people with two different preferences, and we can represent them with these functional
forms. Okay, so this functional form approach works great when we're considering only one
or two dimensions or quantities. So things like the time spent swimming, the percentage
of income we spend on housing, or maybe even hours of leisure. This is something that economists
think about a lot. Now, this functional form approach doesn't work well if we're considering
sort of discrete multi-dimensional things like houses, advertising plans, retirement
plans, that sort of stuff. So in those cases, we, and by we here, I mean social scientists
like myself, we rely on a technique that's called preference orderings. So it sounds
complicated, but it's not. Preference orderings are just a listing of the possibilities in
how much, sort of in order of how much we like them. So they're an ordering of our preferences.
Let's suppose, for example, we're considering a new advertising plan for a stainless steel
counter-depth refrigerator, and this fridge has a, you know, touch screen video panel
on the side. And so we hire three firms, and they develop three different print ads. The
first one shows a child of about 10 years old coming up to, you know, touch the screen,
and he sees a message that says, here is a list of acceptable after-school snacks, and
it shows an apple that he could pull out of the fridge. Now, the second ad shows a father
touching the screen, and a message says, buy milk. Now, the third ad shows a blinking message
that says cottage cheese about to go bad with little warning signs around it, and a woman
standing in front of the fridge just in abject horror, right? So we could label these ads
A for apple, B for buy milk, and C for cottage cheese. Now, if I were part of the team deciding
which ad to use, it could be that I prefer A to B and B to C. And if so, then what we
can do is we can write my preference orderings as follows. A is preferred to B, which is
preferred to C. Now, if someone else prefers B to C to A, then we write that down as sort
of like B greater than C greater than A. So if people have different preference orderings,
we just write those letters in different orders. Now, different preferences don't matter if
we're making individual choices. This is an important point. So my wife and children,
when I go out to the gelato store, it's totally great that we each have our own favorite flavors.
No big deal. But when groups of people must make collective decisions, or if we have to
solve a problem, then it can be the case that preference diversity creates problems, an enormous
problems.
Show you why I'm going to begin with a problem that arises when trying to aggregate diverse
preferences. I'm going to show what can happen. Now, this problem has been known for hundreds
of years, but the general nature of it was only recently solved well about 60 years ago
by Ken Aro. So hence, it's formally known as Aro's impossibility theorem. Here's what
it says. In essence, it says that if we've got diverse preferences, then there's no way,
no way for us to aggregate them in all cases in a general sort of collective ordering.
Well, what do I mean by that? It means there's no way to go from individual preferences to
collective preferences. Let's start with an example. And we're going to use the preference
ordering convention throughout this. So let's suppose I'm heading out to dinner with two
fellow great courses professors, Patrick Grimm and Steve Strogetz. And we're trying to decide,
hey, where should we go out to dinner? And we've got three possible restaurants, an Italian
restaurant, a Mexican restaurant, and a Chinese restaurant. I'm going to show you how we write
this down and how we run into problems. So let's suppose that I like Italian best and
then Chinese and then Mexican. So what we can write is we can write Italian, Chinese,
and then Mexican, just like that. Patrick, who's a philosopher, he likes Chinese best,
then Mexican, and he's not a fan of Italian at all. And finally, Steve, who taught the
great courses course on chaos, he likes Mexican best. And then he likes Italian. And finally,
I mean, if under duress, he'll eat Chinese, but he's not a big fan of it. Okay, so what
I've got is I've got these three preference orderings. I like Italian, Chinese, Mexican.
Patrick likes Chinese, Mexican, and Italian. And Steven likes Mexican, Italian, and Chinese.
That's how we write this down. Now notice that each of us has what we call rational preferences.
By that, I mean, we can order the alternatives. What would irrational preferences be? Well,
that would mean that I like, say, Italian more than Chinese, Chinese more than Mexican,
but then I like Mexican more than Italian. So that would be crazy. And that's what social
scientists call irrational. Now, this example, what it's going to turn out is though, even
though each one of us is rational, as a collective, we're irrational. Let me show you why. So
let's suppose we have a vote. We're going to vote first for Italian versus Mexican. Well,
what happens? Well, you'll notice that both Patrick and Steven prefer Mexican to Italian.
So Mexican's going to win. Well, now let's vote on Chinese versus Mexican, right? And
what we're going to see is that Chinese beats Mexican because Patrick and I both like Chinese
more than Mexican. So what I've got is Mexicans better than Italian. Chinese is better than
Mexican. So therefore it must be the case that Chinese is better than Italian. But in fact,
if I look, I like Italian more than Chinese. And Steve likes Italian more than Chinese.
So what we've got is this. Mexican is preferred to Italian. Italian is preferred to Chinese.
And Chinese is preferred to Mexican. So we like Mexican more than Italian. Italian more
than Chinese. And Chinese is more than Mexican. That doesn't make any sense. We're irrational.
Collectively, even though individually, we're all perfectly rational people. So are we collectively
crazy? Well, in a way, yes, we have what we call a preference cycle. A cycle exists when
A beats B, B beats C, but then C in turn beats A. So it's sort of like rock, paper, scissors.
Rock beats scissors. Scissors cut paper. And paper covers rock. That's a cycle.
So here's what this tells us. If people have diverse preferences, feel the same preferences
would be fine. But if we have diverse preferences, then we're going to have some trouble using
voting to come up with the best alternative. It often just won't work. Now, Eros and Possibility
Theorem says something even deeper. It says that nothing will work. So here I used a majority
voting, but Eros Theorem says no voting systems going to work, other than a dictator. So by
that I mean if we use any sort of procedure for coming up with a collective ranking, we're
always going to get these cycles. Unless, of course, we just appoint Strogat's dictator,
then we're fine. Now, again, this always is going to hold. Now, in the formal mathematical
version, Eros Theorem requires some assumptions, but they're actually pretty mild assumptions.
For example, if we add in some new possibility and the rankings of two other alternatives
don't change, then the theorem's going to require that the final ranking of those two
alternatives is unaffected by introducing this new option. Well, here's where Eros Theorem
is relevant for what we're talking about in this course. If people have different preferences,
then it's going to be really difficult to come up with a ranking of the alternatives and
difficult to make a choice. To put it another way, each member of our group can have rational
preferences, but if the individuals are diverse, then the group may be irrational. And we've
been talking a lot about teams and groups solving problems, while the rational groups
aren't going to be very good at solving problems. Now, Eros Theorem hints at a second result.
That is this. If we've got these cycles, it might make sense to be strategic. So if what
happens through some voting process is going to be somewhat arbitrary, perhaps I can manipulate
the process, and then I can get what I want. If not what I want, at least something better.
Let's see how that can happen. Let's go back to Patrick, Stephen, and I, choosing where
to go to dinner. So suppose we're going to first decide, like I have a vote between Chinese
and Italian, and have the winner run off against Mexican. So if we vote truthfully, then Italian
is going to win the first round, because Stephen and I will vote for it. But let's see if maybe
I'm better off by being strategic. And I've written down all of our preferences here,
and then I'm going to talk about how we'd vote. So let's suppose we're going to have
a first round vote of Chinese versus Italian. Well, what would happen? What we'd see is
is that I'm going to vote for Italian versus Chinese, and Steve's going to vote for Italian
versus Chinese, so Italian's going to win. And then we're going to have the winner face
off against Mexican. We'll have the winner face off against Mexican. What we see is Patrick
and Stephen are both going to vote for Mexican versus Italian. So Mexican's going to win
the second round. Now let's look at me for a second. Here I am up here. What's my least
favorite choice? It's Mexican. So I'm not going to be happy about the final outcome.
So what could I do? Well, in the second vote, when it's basically going to be Italian versus
Mexican, there's nothing I can do. Mexican's going to win. But what I could do in the first
round is I could lie. I could misrepresent my preferences. I could say, you know what,
I don't like Italian more than Chinese. I could say, no, in fact, I like Chinese more
than Italian. And if I say like Chinese more than Italian, Chinese is going to win the
first round. And if Chinese wins the first round, then I'm going to vote for it against
Mexican, and so will Patrick, and so will win both rounds. And so what I can do by misrepresenting
my preferences is I can't get my first choice, but I can get my second choice. And that's
good because if I didn't misrepresent my preferences, I'd be stuck with Mexican food.
Okay, now you might call this lying, but I was trained as a game theorist and game thought
theorist called this strategic voting. Alan Gibbon, one of my colleagues at Michigan,
and Mark Satterthwaite, who actually was a member of my dissertation committee in the
1970s, proved a theorem that said any voting system that isn't a dictator can be manipulated
by strategic voting. That's not good news. We've got like a double whammy here. So arrow
shows that we've got no good way to aggregate diverse preferences. Gibbon and Satterthwaite
show that no matter what method we do choose to use, which, again, by arrow is going to
be flawed, is going to be subject to manipulation. People can do better by misrepresenting their
preferences. So notice what these two theorems imply. They imply that the members of a group
have diverse preferences. The group's preferences will be ill-defined, and people have incentives
to lie. This means if you take a group like, oh, I don't know, say Congress, in which the
members represent the preferences of diverse communities and the ideologies of diverse
parties, we might find that all that diversity creates problems in terms of making choices.
Sound familiar? So we've got a case where diversity is perhaps not so good. I mean, by diversity
and near preference diversities, not so good. Now let's look at how preference diversity
affects problem solving. See, I've just talked about making choices. Let's see how it works
in problem solving. Does it cause problems there? And, again, the answer is going to
be yes. Now to see why, we have to go back to our landscape model. Now let's suppose
we all agree on the goal. And if we're a team, then we agree on the value of the solution.
If somebody finds a higher point, that's great. We're all going to move there. But let's
suppose in our team, we've got diverse preferences. So in the work context, these could be different
goals or objectives. And if you have different objectives, then an improvement for one person
need not be an improvement for other people. And if that's the case, we're going to need
some procedure for deciding whether to accept a new solution is better. And as we're about
to see, because of the logic of arrow, that can cause trouble. Now to see this in more
detail, let me describe a situation so we can see how this problem of people having
different preferences manifests itself in the context of problem solving. So let's suppose
the following. Suppose you have a company that designs tablet computers. And to keep
this simple, let's suppose a tablet has three relevant attributes, pixels, speed, and memory.
So the more pixels the better, the more speed better, and more memories better. Now let's
suppose we have three people working on design teams, and they want to come up with a new
version of our computer. We'll call these people Andrea, Brian, and Carlos. Now Andrea
cares about pixels and speed, she doesn't care at all about memory. Brian cares about
memory and speed, but doesn't think that the number of pixels matters very much. And
finally, to keep make preferences diverse, let's suppose Carlos cares about memory and
pixels, doesn't really care at all about the speed component. So hence we've got three
designers and all have different preferences here about the tablets, but they're all trying
to work together to create a good tablet. So let's suppose that Andrea introduces a tablet
called the alpha, and it has 60 pixels per square centimeter, that's really high resolution,
a processing speed of 50 megahertz, and a memory of 32 gigabytes. Now to make this example
easy to follow, I'm going to assume that each person gives a score to each tablet using
a fixed set of rules. Let me write those down to show you how it works. So what we're going
to assume is that Andrea just sort of counts up the pixels per square centimeter plus the
speed in megahertz. So in this case, she's going to look at this alpha computer and give
it a score of 110. Brian cares only about memory and speed, and so he's going to give
this a score of 82. And Carlos cares about memory and pixels, so he's going to give it
a score of 92. So this is sort of how they think about this particular computer. Now
notice that Brian's not that happy, because this only has a score of 82, and he cares
a lot about memory and speed. So what's he going to do? Well, let's think about what
we learned about problem solving. He's probably going to sit down and think about it. He's
going to apply some heuristics, some new perspectives on it, try and figure out how
do I get more memory and speed out of this tablet. So let's suppose he puts in a bunch
of time, and he proposes a new design, and we're going to call this new design the beta.
Here's what the beta looks like. The beta has 50 pixels, 70 megahertz, and a memory
though of only 24 gigabytes. Now Andrea cares about pixels and speed, so she's going to
give this a score of 120 for 50 plus 70. Now Brian cares about memory and speed, so he's
going to give this a score of 94. Now Carlos cares about memory and pixels, and this is
only going to get a score of 74 for him. Well, suppose we take a vote, and we compare this
to the earlier one. Well, this new tablet, the beta is going to win by a score of two
to one, because both Andrea and Brian are better off. If you think back to their scores,
Andrea and Brian give this one a higher score. But Carlos isn't happy. How come? Well, he
doesn't like this new design. It doesn't have sufficient pixels, and it's got low memory.
So what's he going to do? Well, he's going to work. He's going to try and find a better
solution. How's he going to do it? Well, he's going to apply his diverse tool set, try and
find a better answer. So he does this, and he introduces a third tablet. Let's call
this the Gamma. The Gamma has 48 gigabytes, so it's got more memory, but it's sacrificing
a bit in pixels. It's only got 40 pixels. It's also got 60 megahertz, which is okay
speed, but not great. So let's think about how this works. Andrea cares about pixels
plus speed, so she gives it a score of 100. Brian cares about memory and speed, so he
gives it a score of 108. Now, Carlos, because he cares a lot about memory, gives us a score
of 88, because it's got 48 gigabytes of memory and only 40 pixels. So if we look at this
computer and we vote, what we're going to see is that both Brian and Carlos are happier,
and so they're going to say, hey, why don't we do the Gamma? It's better than the beta,
and it's going to win by a vote of two to one. But who's not happy here? Well, Andrea's
not happy here, right? Andrea's not happy here because of the fact that this one has a pixels
plus speed of only 100. So she hates this computer. It's her least favorite of the three.
So what's she going to do? Well, one thing she could do is she could sit down and try
and design a new tablet. But that's going to take a lot of work. But instead, she might
say, you know what? I like the original tablet better, so let's vote on the alpha against
the Gamma. Well, if they do that, what's going to happen? What's going to happen is Andrea's
going to prefer it, because she got a score of 110. And so is Carlos, because it turned
out he had a score of 92 on the first tablet. So notice that we have a cycle. The beta defeated
the alpha, the Gamma defeats the beta, but the alpha defeats the Gamma. So once again,
we've got a game of rock, paper, scissors. Rock smashes scissors, scissors cut paper,
and paper covers rock. We have the same thing we had with Patrick, Stephen and I choosing
a restaurant. We've got a cycle. Okay, so in the case of Patrick, Stephen and I picking
a restaurant, I talked about how these cycles created problems because the group just isn't
rational. And then we talked about how there might be incentives for people, particularly
me, to misrepresent what I want. Here I'm making a different point. I'm talking about
problem solving. And in this context, the cycles are rising, not because we have a fixed
set of alternatives, but it's arising from people who've actually created new solutions
that they hope are better. And what happens is the result is not continuous improvement.
So before when people applied diverse heuristics and perspectives of problems, we climbed up
the landscape. But here, what's happening? We're running around in circles. Literally,
we're going from one tablet to the next, but we're not climbing up a landscape. We're
on an Escher staircase. We're just going around in circles. So the logic here should be clear.
If people disagree on which direction is up, you can have a lot of misplaced effort. So
what's climbing up a landscape for one person can be going down for another. And as a result,
an enormous effort can be spent going nowhere. In our example, Brian and Carlos did a lot
of work, but it had no positive effect. So what we see here is that preference diversity
causes problems in the context of trying to find new solutions. So let's pull this back
and think again about Congress. These observations about diverse preferences can partly explain
my government's aren't as productive as we might hope. So the members of Congress have
talent. They've also got a high level of diversity, lots of perspectives and heuristics. I mean,
they're truly a talented bunch. But they have different preferences. They want different things,
and they represent people from different states and districts who also want different things.
Now, in the context of government, the problems can be even worse than cycles. And here's why.
We've got two parties who often share power. So one party can hold the White House,
and another party can hold one or both houses of Congress. This, in effect, gives both parties
veto power, implying that only bills that both parties believe to be improvements will become
policy. Now, this problem of veto players has been studied in depth, in particular by a scholar
named George Cibeles, who used to be at UCLA, but it's now one of my colleagues at Michigan. He's
a political scientist. And George has shown why multiple veto players who have different preferences
cause a whole bunch of problems. Here's why. Let's suppose a policy has two dimensions,
an efficiency dimension, and an equity dimension. So sort of how efficient it is, and how fair it is.
Now, for the purposes of this example, let's suppose Republicans care only about efficiency,
and Democrats care only about equity, and that the average voter lies somewhere in between,
that they care equally about the two dimensions of a policy. Now, let's suppose we've got a current
status quo policy that has an efficiency score of, let's say, five, and an equity score of four.
And what we can see is how much is lost by having multiple veto players. I can show you
the picture, probably better than words. So this graph represents the efficiency and equity of a
policy. So on this axis down here, this x-axis, I've got efficiency, and on the y-axis, I've got
equity. So this policy right here has an efficiency of five and an equity of four. Now, the average
voter cares about efficiency and equity equally. So what I could do is I could draw a line here
that has slope negative one, and anything up here will be better for the voter, and anything down here
will be worse for the voter, because they just want any policy where equity plus efficiency
sums to more than nine. Now, this represents average voter preferences. Now, let's think about
if we have a candidate or if we have parties that have veto power. Now, let's think about the party
that cares only about efficiency, the Republican Party. So what they're going to do, and I'll draw
them in green, they're going to say we only accept policies that lie to the right of this line.
Anything over here, they're going to say no. They're going to veto. Well, now let's think about
the Democratic Party. The Democratic Party cares only about equity. So we can draw a
line for them, and let's draw that in blue. They're going to say we only vote for policies
that lie above this line. So what we see is the two parties are only going to vote for
policies that lie in this region right here, where it's both higher on the efficiency dimension
and higher on the equity dimension. But what we're missing is policies in this region,
which would make the voter happier, but won't make one of the two parties happier. And so what we
get is a bias towards the status quo because of this veto, because we have multiple veto players.
So this is a problem, and it has two implications. First, someone could propose a policy that the
average voter likes more than the status quo, but it could fail to pass. So someone from the
Democratic Party could propose a new policy with an efficiency of seven and an equity of three.
The average voter would prefer it, given that the sum of the efficiency and equity would rise from
nine to ten, but the other party is not going to like the bill, and they're going to stop it from
passing, because it's going to mean a decrease in efficiency, so it's not going to pass. Now second,
because policies are less likely to pass, members have a reduced incentive to spend time trying to
come up with new policies, and this is going to magnify the first effect. So this is frustrating,
but as Winston Churchill so aptly said, democracy is the worst form of government,
except for all the others. So I could sum this up in a few words. I'd put it this way. Diverse
preferences create problems. They're not so good. Okay, hopefully this course should all be starting
to make some sense. You should feel the tumblers clicking into place as you unlock new ways of
thinking about the world. Now one way to test for yourself that that's happening is to reflect for
a moment on this lecture and see if you feel a slow comforting flow of humility as you start to
understand the subtleties in how preference diversity interacts with other types of diversity
and affecting outcomes. Now humility isn't easy to come by, but it's an inescapable feeling that
you should get from this lecture and probably from the course more generally, because up until this
lecture we've talked about how diversity improves things like prediction, problem solving, robustness,
but in this lecture we confront the inconvenient fact that a different type of diversity,
preference diversity, creates problems, and if we think about it these two things are probably
linked. But let's think about the ways in which we've seen preference diversity causing those
problems. So what have we seen? First, we've got these cycles, the rock, paper, scissors effect.
So even though each person can be rational, a collection can be irrational. It's not only
paradoxical, it's lousy. Second, we saw that the presence of cycles means that people have incentives
to misrepresent their two preferences. Now we can view this really negatively, we can call it lying,
or we can put a more positive spin on it and see it as strategic behavior
that helps us get more moderate outcomes. Now either way it's a cause for concern.
Third, we saw in the context of problem solving we've got an even bigger problem because people
expend a lot of effort trying to come up with better solutions and then we can end up running
around in circles. So if we add this preference diversity to problem solving, we can wipe out
some of the benefits of diversity from problem solving. So yeah we're getting solutions from
the diverse perspectives and heuristics of these people, but they're not better. They're just getting
us to run around in circles. And then finally, as we just saw, if different actors with diverse
preferences can be gatekeepers or what George Sobellis calls veto players, then policy improvements
can be thwarted and there's less incentive to even come up with those solutions in the first place.
So what is to be done? How do we cope with diverse preferences, particularly if they go hand in hand
with cognitive diversity? Well that's a deep question. Fortunately we've got one lecture left
and in that lecture we'll try and make sense of how we do it. Thank you.
