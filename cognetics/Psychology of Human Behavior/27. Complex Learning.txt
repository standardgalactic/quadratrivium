Lecture 27 Complex Learning
This is our third lecture on the topic of learning.
If you recall in the first lecture we talked about a simple form of learning,
that is classical conditioning,
and the conditions under which classical conditioning occurs.
In our second lecture we talked about operant conditioning
and talked about reinforcements and schedules of reinforcements.
Both of those are usually considered fairly simple forms of learning.
In today's lecture we're going to talk about complex learning,
more complicated learning than what we've been talking about so far.
And earlier I asked you to consider the question whether complex learning
can be considered simply a function of the building blocks of simple learning.
And so today we're going to consider several kinds of learning.
I want you to ask yourself that question as we go through it,
whether or not classical conditioning and operant conditioning
can be used to explain these complex learning situations.
So today we'll start out with complex learning,
talking about avoidance learning,
which is a particular experimental paradigm,
and talk about avoidance learning and how it works also in a practical sense.
Then we'll talk about a couple of other forms of complex learning,
and I don't want to identify those for you at this point,
because I'm going to give you a demonstration
and I don't want to give away what the demonstration is about at this point.
And finally we'll talk some about language learning
and whether language can be explained as just a more elaborate combination
of simple learning kinds of procedures.
So that's what we're going to do today.
Let's start out then and talk about a particular kind of learning
called avoidance learning.
Now you'll notice I'm talking about learning rather than conditioning,
and that's sort of the way we do it in psychology.
When we're talking about simple learning,
we often use the term conditioning.
I don't want you to infer anything insidious into that term.
We're not talking about unconscious kinds of things
versus conscious kinds of things.
It's simply the way psychologists refer to simple learning situations as conditioning.
But from here on out, I will for the most part be talking about learning instead.
Imagine this as an experimental situation.
We have a shoebox-like apparatus, again with plexiglass sides
so that we can see inside.
And in the shoebox apparatus we have our usual white rat.
And in the middle of the box, by secting the box,
we have a little wall that wall doesn't go all the way to the top of the box,
so it's possible for the rat to climb up over the wall.
And in the wall we have a light that can be seen from both halves of the box
that can be turned on.
Now in the floor of the box we have an electrified grid.
And we can turn on one side or the other of this electrified grid.
And the rat doesn't like that very much.
It's nothing that will harm the rat, but it's uncomfortable on the rat's feet.
He doesn't like it.
And we'll dance around when you turn on this grid.
Now what we're going to do in this situation is we're going to turn on the light
and a half second or so later we will electrify the grid
that the rat on the side of the box where the rat is standing.
And if we do that, the rat will start trying to avoid standing on the grid,
will eventually climb up over the wall and get to the other side which is not electrified.
And very quickly the rat will learn every time that light comes on
to crawl over to the other side.
And then it's standing on the other side and we will turn the light back on,
electrify the grid on that side and it crawls back over to the other side of the box.
Now this is called avoidance learning for obvious reasons.
The rat has learned to avoid getting the shock by crawling over the wall.
And the rat learns that very quickly.
Now there are a number of interesting things about avoidance learning.
For one thing, it resembles classical conditioning, doesn't it?
If you have the light paired up with a shock,
that sounds very much like some of the conditions we were talking about
with classical conditioning like pairing a tone with a shock.
And certainly it's the case that the rat comes to associate the light
with the electrification of the grid on that side of the box.
And if we didn't let the rat climb over and we hooked up the rat to say an apparatus
that would measure how upset the rat is,
we would discover that in the future we could turn on the right light without electrifying the grid
and the rat would become upset.
So in that respect it resembles classical conditioning.
But it also resembles operant conditioning.
Because the rat climbs over the wall, does a voluntary response like that,
and by climbing over the wall it avoids the shock,
which is reinforcing by not being shocked.
And so this condition at least, this complex kind of learning,
does seem to be built up out of kind of the building blocks of classical conditioning,
the association of the light with the shock,
and operant conditioning, the crawling over the wall to avoid the shock and thereby be reinforced.
So that seems to be kind of interesting.
A second interesting factor with operant conditioning
is that it is highly resistant to extinction.
In the last lecture I said that variable ratio schedules are highly resistant to extinction,
but they're nowhere near as resistant to extinction
as avoidance learning is.
And you can perhaps figure out why that is.
The light comes on, the rat climbs over the wall, and doesn't get shocked.
Now, once it's learned that task, we turn off the shock.
That would be one way of trying to figure out how many trials we'll get before extinction takes place.
But the rat doesn't know we turned off the shock,
the light comes on, scurries over,
I avoided it again,
light comes on, scurries over,
oh, I was reinforced again, I didn't get shocked.
The rat doesn't know we turned off the shock.
It's kind of like there's self-reinforcement going on here,
where the rat self-reinforces every time he climbs over the wall.
And so it's highly resistant to extinction.
That rat may go 100 trials, may go 300 trials, may go 600 trials,
never knowing that we turned off the shock.
Highly resistant to extinction.
And that brings up the third point,
and that is that we can explain phobias to some extent by avoidance learning.
Now, we've in the past in this course talked about phobias being established by classical conditioning.
You've paired up a particular conditioned and unconditioned stimulus to bring the phobia about.
So you have the large dog who scared the little kid who's now afraid of dogs.
Well, that's true.
But then what happens?
Now the kid avoids the dogs.
So every time he sees a dog, he runs away, he avoids it,
he goes to school a different way so he doesn't have to pass the dogs.
And now he's avoiding it.
And every time he avoids it, much like the rat climbing over the wall,
he goes, phew, I avoided getting confronted by a dog again, and that's reinforcing.
So by avoiding it, and this is true of all kinds of phobias,
people are afraid of heights, avoid ladders,
people are afraid of water, avoid getting around water, and so forth.
And every time you avoid it, it's kind of self-reinforcing.
So while phobias may be established by classical conditioning,
they are probably maintained by avoidance learning.
And it's for that reason when you do behavior therapies
that you have to break that sort of vicious cycle of avoidance.
And what we're doing with behavior therapy is forcing the person
to get back in the situation so that they can learn a new response
and be classically conditioned in a new way,
but we have to break the avoidance cycle in order to get them to do that.
And that's part of the goals of behavior therapies
that we have talked about previously in this class.
So avoidance conditioning does seem to have characteristics
of both classical and operant conditioning.
But let's move on to a different case where we may not be able to find that.
I'm going to give you a little demonstration here
before I even identify what kind of learning we're doing.
And what I would like for you to do is if you're in a place
where you have a piece of paper handy,
I would like for you to predict what is going to come up next.
If you're in a place where you don't have a paper,
maybe you can say out loud what you think is going to come up next.
I do this demonstration in my typical class
and have the students write down what's going to happen next.
And what I'm going to do is read you a list of L's and R's,
the letter L and the letter R.
And I want you to predict what's going to come up next.
It's a little boring, but it'll only take a couple of minutes to do this.
So if you're in a place where you can write this down,
the first letter in the list is L.
I want you to predict what's going to come up next.
What came up next is a letter R.
Next, it was R.
Next, it was R.
Next, it was R.
Next, it's L.
Next, it's the letter R.
Next, R.
Next, R.
Next, R.
Next, L.
Next, R.
Next, R.
Next, R.
Next, R.
Next, L.
Next, R.
Next, R.
Next, R.
Next, R. Next, L. Next, R. Next, R. Next, L. Next, R. Next, R. Next, R. Next, L.
Next, R. Next, R. Next, R. Next, L. Next, R. Next, R. Next, R. Next, R.
Okay, I'm going to stop there. I sometimes go a little bit longer when I'm in my class, but it does get a bit tedious to do that.
Now, if you did write it down, what I'd like for you to do is now look at your last 10 guesses and figure out how many times you predicted it would be better.
Now, how many times you predicted it would be R and how many times you predicted it would be L out of your last 10 guesses as to what the next letter would be.
Now, if you do what my students do and you count the number of R's and L's, what I typically do at this point is then say, well, how many had 10 R's?
They pulled up their hands. How many had 9, 8, 7, 6, and so forth? And then I take sort of an average number.
And what I find the most frequently occurring response is that they predicted 7 R's out of the last 10.
And in some respects, that's good, because what we're doing here is a probability learning experiment.
I think people try to learn the probabilistic structure of the world.
And the world in this case is a hat I had, and I had 10 slips of paper, 7 of which had R's on them, and 3 of which had L's on them.
And I stuck these in the hat and shook it up and drew one out and wrote down what it was, an L or an R, and put it back into the hat.
I placed it and shook it up again and pulled it out.
So I had a random probability generator that was operating under a rule of 0.7 with a probability of 0.7 or 70% of the time it would come up an R,
and 30% of the time it would come up an L.
And that was the probabilistic structure of the world.
Now, when you started doing this, you were probably trying to look for a pattern of some sort.
There are 5 R's followed by an L and then 4 R's followed by 2 L's or something like that,
but you probably got bored with that by the end of it and just started predicting.
And what people predicted, the behavior they showed us is usually called probability matching.
They matched their probabilities to the probabilistic structure of the world.
And they predicted about 7 and that's good because I had 7 R's and 3 L's in the hat.
And so they were probably pretty good at picking up the probabilities in the world.
Now, before we pat ourselves in the back too much and say how great we are at assessing probabilities,
I might point out that that's not an optimal strategy.
The matching strategy is not.
If you wanted to be right most often, the strategy you ought to employ is to,
as soon as you know there's a preponderance of R's, predict R every time.
Because if you did that, you'd be right 70% of the time on average.
Any other strategy, you would not be right as much as 70% of the time.
So to be optimal, what you should have done as soon as you said,
well, there are more R's than L's, I think it's R and write down R every time after that.
Now, that's assuming optimality based upon being rewarded for being correct.
And that's probably not what people are rewarded for.
As you were doing this, people like to predict the underdog.
And so they go along R, yeah, okay, obviously.
R, R, R, I wrote down L, oh, I got it right.
I was rewarded for that.
It was of higher value to predict the underdog in that case
than to predict a very frequently occurring event.
And so most of us feel like we're rewarded more and this is kind of a boring task
so we might as well play little games with ourselves.
I could have made my students optimal and made you optimal.
If I said at the end of this task, I want you to send me your list
and I'm going to pay you a dollar for every one you get correct.
And if I did that, I would discover very quickly after 10 or 12 trials here
of reading L's and R's that you would be predicting R every time.
The fact I'm giving you a fairly large monetary reward
overrides any other value system like predicting the underdog
and probably would make you do an optimal strategy
instead of a probability matching strategy.
The point is here, however, is that we do learn probabilities in the world.
And we do this in everyday life as well.
As you come out in the morning, you perhaps listen to the weather forecast
or look up in the sky and try to decide how likely it is that it's going to rain
and whether I should carry an umbrella.
As you're doing a report for your boss, perhaps,
you try to figure out how likely it is that your boss is going to like it
if you put this in the report and not that in the report.
And so we throughout our lives do probability kinds of strategies
and try to figure out what the probabilities are of responding
in certain ways in our life.
And we could be wrong.
We look both ways as we're crossing the road.
We may get run down by a car, but it's an unlikely event.
So we have to assess the probabilities.
Does this sound like classical conditioning or operant conditioning?
Perhaps it sounds a little like operant conditioning.
Perhaps BF Skinner could say,
all right, I think I can explain that by reinforcement.
Every time you said an R, you were reinforced.
And if you said an L, you were reinforced or not reinforced.
And maybe I could predict that kind of behavior.
But I think we're starting to get away from that a little bit.
The next demonstration, I think, will show you an even more powerful case
that we're getting away from the simple forms of learning.
Now, what I want you to do is I'm going to present you with some shapes.
And I will describe these shapes for those just listening to it.
And these shapes vary in size.
Some of them are large.
Some of them are small.
They vary in color.
Some of them are blue.
Some of them are red.
And they vary in shape.
Some of them are circles, and some of them are squares.
Now, I want you to learn what a dag is.
What a dag is.
That's just a nonsense word.
And I'm going to have you learn this by telling you whether or not
the shape I'm going to show you is a dag.
All right.
And so your task is to figure out what a dag is.
Here's one of them.
And the question is whether or not that's a dag.
The answer is that's not a dag.
And that first one was a large blue square.
The next one is a large red circle.
And I would ask you if that's a dag.
And the answer is no, it's not a dag.
The next one is a small blue circle.
Is that a dag?
And the answer is yes, that is a dag.
The next one is a small red square.
Is that a dag?
And the answer is no, that's not a dag.
The next one is a small blue square.
Is that a dag?
And the answer is no, that's not a dag.
The next one is a large blue circle.
Is that a dag?
And the answer is yes, that is a dag.
The next one is a small red circle.
Is that a dag?
The answer is no, that's not a dag.
The next one is a large red square.
Is that a dag?
The answer is no, that's not a dag.
The next one is a small blue square.
Is that a dag?
That's not a dag, no.
The next one is a large red circle.
Is that a dag?
The answer is no.
The next one is a large blue circle.
Is that a dag?
The answer is yes, that is a dag.
The next one is a small blue circle.
Is that a dag?
The answer is yes, that is a dag.
And this will be the last one.
This is a small red circle.
Is that a dag?
And the answer is no, that's not a dag.
Okay, at this point you probably know what a dag is.
It may not have even taken that many trials.
And what a dag is in this case is a blue circle,
regardless of whether it's large or small.
So it has to have two dimensions that define a dag.
In this case it has to be blue,
and it has to be a circle,
and we can ignore the third dimension in this case.
Now this is called concept formation,
because people are forming concepts.
What is the concept of dag?
What does dag mean?
And you learn this concept by experiencing the world.
And people are pretty good at this.
They're not quite as fast-added,
as logic might predict if you did it perfectly
from a logical point of view.
But people do pick up on this fairly quickly.
And I could have made it a lot tougher, of course.
This was a relatively easy task.
When I do this in my classes,
I usually start out and use one dimension.
So I could have defined it by anything blue would be a dag,
instead of defining it by two dimensions.
And then what I typically do is include two dimensions in it,
although the particular thing I use in my class,
those dimensions are fairly far apart.
And so it takes them a while to do this,
maybe 20 to 25 trials in order to learn what a grack is,
which is a different object defined by different dimensions here.
And I could have made it more difficult for you as well.
I could have, for example, said a grack is a large blue square,
or a small red square.
And then you would have taken considerably longer,
and I would have had to stand up here and spend most of our half-hour
showing you these pictures in order for you to learn that concept.
And psychologists claim that most of this kind of learning
is what goes on with learning a verbal vocabulary.
You have a little Susie who's out there in the yard with Mom,
and Susie goes along and Mom says,
Susie, you see this? That's called a rose.
Susie looks at it and says, OK, a rose.
And then she goes along and sees a little red ball in the yard.
Rose, rose! No, Susie, that's a ball.
This is a rose over here. That's a ball.
Susie says, OK, that's not a rose. That's a ball.
And she goes along a little further. She sees a red petunia, perhaps.
Rose, rose! Well, that's close, Susie.
That's a flower. That's true, but it's not a rose. It's a petunia.
And so Susie, with these varying experiences,
much like we said, yes, that's a dag, no, this isn't a dag,
is learning what a rose is.
And psychologists would contend that that's the way we learn
most of our concepts and most of our vocabulary.
If I asked you to define what a rose is,
I don't think you could give me a very good definition.
I certainly couldn't. I'd say something like,
well, rose is a flower.
And most roses are red, but not all of them are red.
And they have to have sort of serrated leaves.
And most of them have a little prickly thorns
or something like that on them.
And that, I guess, is what a rose is.
And unless you're an expert,
that's probably the way you would do it, too.
I've never looked up rose in the dictionary.
You probably haven't either.
I haven't looked up most words I use in the dictionary.
I've learned them by learning concepts,
by having people say, yes, that is,
that isn't one of those things.
And so concept formation is probably the way
we learn much of our language.
And sometimes we get fairly complex concepts.
I remember when I was in middle school,
all the boys, what we were trying to do
was learn what a ford is and what a chevrolet is
and learn the makes of cars.
And that was not easy because you had little fords
and little chevroletes and big fords and big chevroletes.
And they're all different colors.
What defines a ford and what defines a chevrolet?
Or if you want it even more complex,
try to define what a strike is in baseball.
If you have a British friend who's visiting you or something
and watching the game, well, what's a strike?
Oh, well, a strike is if the pitcher throws the ball
in a particular circumscribed area, the strike zone,
and the batter stands there, that's a strike.
Or the pitcher throws the ball anywhere
and the batter hits the ball,
but in another circumscribed area,
that is the foul area, that's a strike.
Or the pitcher throws the ball anywhere
and the batter hits it and it goes into that other zone,
but not if it's a third one of those.
Then it's not a strike.
Well, if I had thrown that at you today,
learning that by concept formation would be quite complex.
And so we do these kinds of tasks
and we do it in an amazing kind of way.
So concept formation, I think, is a case of more complex learning
and I think you would find it difficult
to explain concept formation
simply by operant conditioning or classical conditioning.
Subjectively, I'm sure what you were doing as you were doing this
is carrying around certain mental hypotheses about what a dag is
and sort of checking those off as I gave you examples of it.
So you were going through cognitive activity
that was far more than, well, I was reinforced for that.
So I think you would have a difficult case to make
that concept formation is simply a combination
of classical and operant conditioning.
Now, B.F. Skinner and a fellow named Noam Chomsky,
who's a linguist,
had a great debate about language in particular
and whether language and the learning of language,
which is a very complex learning that goes on
more than just vocabulary that we were just talking about,
but learning language involves sentence structure
and parts of speech and how all of these things fit together
and present tenses and past tenses
and all of that kind of thing that goes into language,
whether or not that could be explained by simple learning
and Skinner contended that it could,
that he thought he could explain language simply by reinforcement.
He would say, for instance, that a child,
when he's learning language, he might misspeak and say they is,
for example, rather than they are,
and his parent might come up and say,
no, no, that's not what you say.
They is, they is plural and is is a singular verb
and you have to match the verb tense so you have to say they are.
Now, you got that?
And then the kid the next time would be more likely to say it right
because he would then be reinforced for it.
Well, Chomsky said that that's silly,
that there's no way we could learn language that way,
that in fact kids learn it far too easily
and pick it up far too quickly to do this.
If you waited a week or two even if you didn't correct the kid,
the kid would start using it properly.
That it wasn't the reinforcement that caused the change.
And also Chomsky told Skinner,
you can't explain possibly the learning of language
by operant conditioning
or else you couldn't explain how we could make up unique sentences.
Now, we make up unique sentences all the time.
The one I'm saying right now is probably unique to me.
Even though I've given this lecture a number of times,
I doubt that I've ever used the words in exactly the same order
I'm using them now in the sentence I'm speaking.
So this is a unique sentence and we do this all the time.
And if operant conditioning is right,
what that would say is that I would have had to have used this sentence,
had it reinforced or not reinforced multiple times
until I learned it was proper to use the sentence this way.
And Chomsky says that's ridiculous.
That's not the way it happens.
So what Chomsky argued that we have built-in modules,
language modules that control our use of language
and if you look at languages across cultures,
you will find that universally the parts of speech are the same
and the relationship of the parts of speech to each other.
And so these probably form a built-in language module
that allows us to speak language
and that we don't start out as a blank slate
and learn language simply through reinforcement.
And Chomsky's argument certainly held sway in the scientific community
and Skinner is no longer considered to be any kind of the father.
He may be the father of operant conditioning,
but he's not the father of language theory
because we no longer think that language is learned that way.
So what we've done today is talk about complex learning
and we considered whether or not complex learning
could be built up out of simple learning
like classical conditioning and operant conditioning.
We looked at several forms of complex learning
such as avoidance learning
and showed how powerful that was
and how it may help us understand phobias.
We looked at probability learning
and discovered people were pretty good at learning probabilities,
the probabilistic structure of life.
And we looked at concept formation
and discovered that people were pretty good at learning concepts
and that may explain how people learn vocabulary.
And finally, we looked at the debate between Chomsky and Skinner
about whether language could be explained
through simple learning principles
and discovered that it probably could not.
Thank you.
