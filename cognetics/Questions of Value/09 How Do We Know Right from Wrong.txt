Lecture 9 How do we know right from wrong
In the previous lecture, I talked about the value of human life, and in doing so, I relied
on something we know that human life has a very important value. In this lecture, I
want to talk about that kind of knowledge. How do we know things about values? Epistemology
is the name for that branch of philosophy that's concerned with knowledge, all kinds
of knowledge. And the question I want to approach in this lecture is a question in the epistemology
of ethics. The question is how we know things about value. How do we know that anything
really has value? When we think something has a certain value, that human life has an
extremely important value, for example, how do we know that? When we know that it would
be ethically wrong to do one thing, or ethically right to do another, how do we know that?
How do we know right from wrong? This is, I think, a very difficult question. Epistemological
questions are often difficult. I think epistemological questions about ethics, epistemological questions
regarding ethics, are particularly hard. My attempt will be to guide you through some
of the theories of the epistemology of ethics. I think these theories are initially tempting,
but don't ultimately seem defensible. Then I'll take a few steps, though only a few
steps, toward figuring out what a better theory of ethical knowledge might look like.
Let me start, however, by outlining the game as I see it. I think we do know things about
ethics. We know that human life is important and valuable. We know that people have rights,
rights to choose their own ways in life, rights to take their own paths in life. We know it's
ethically wrong to violate those rights. We know we have obligations to our family, to
our friends. We know we have obligations to humanity at large. I take that to be an important
kind of knowledge, but a normal kind of knowledge. The question, as I see it, isn't whether
we have that kind of knowledge. The question is a reflective question about what kind of
knowledge that is. In saying this, I'm saying that there is a particular kind of philosophical
game that I'm not going to play here. I'm not going to try to refute some extreme skepticism
regarding all ethical knowledge. It is possible to make a skeptical move here, just as it's
possible to make a skeptical move regarding any kind of knowledge, a skepticism regarding
mathematical knowledge, for example, or regarding scientific knowledge. The standard skeptical
move is to raise some possibility that you might be wrong, however far-fetched that possibility
might be. The skeptic raises the possibility that all the people that you know are really
robots or clever cardboard cutouts that are set up to fool you. Once he's raised that
possibility, that far-fetched possibility, he then leans on the word no and says, so
you don't really know that other people exist, do you? That's more a rhetorical flourish
than a real philosophical argument. If it's converted out of the rhetoric and into a real
argument, what the skeptic would have to maintain in giving an argument like that, what the
skeptic would have to maintain is something like this, that if there's any possibility
of being wrong about something, then we can't claim to know it. So the core of the skeptical
argument, if it's made as an argument and not just a rhetorical flourish is, if there's
any possibility of being wrong about something, we can't claim to know it. The problem with
that is that it just isn't true. If it were true, all knowledge would have to be infallible.
In fact, none of our knowledge is like that. Not even the best of scientific knowledge
is like that. All of our scientific knowledge is fallible, but that doesn't mean it isn't
real knowledge. What knowledge demands is that we've hit on the truth and that we have
reasons. We have justification to think we've hit on the truth. That's all that knowledge
in the normal sense demands. I think we have that normal kind of knowledge about scientific
facts. We have that kind of normal knowledge about mathematical results. I think we've
got that kind of normal knowledge about aspects of ethics. Even so, ethical knowledge does
seem different in some important ways. What I want to know is what kind of knowledge that
ethical knowledge is. There's a second position, beyond skepticism, that would also deny the
existence of ethical knowledge. That position is called emotivism, and it was developed
early in the 20th century by the philosopher A.J. Ayer. Ayer's position is emotivism in
its starkest form. Later ethical thinkers in the 20th century made something a bit more
sophisticated out of emotivism. But the basic idea remains the same, and the basic problems
remain as well. Here's Ayer's theory. Ayer's theory is that ethical language is merely
emotive. Ethical terms are used to express certain feelings. So when I say it's wrong
to make a promise that you intend to break, that may look like a statement. It may look
like I'm saying that a particular action, making a promise that you intend to break,
has a particular property. It may look like saying of that action that it has the property
of wrongness, that it's wrong. But according to Ayer, it's not a genuine statement. It's
wrong to make a promise you intend to break, according to Ayer, is more like this. Making
a promise you intend to break, yuck, ick, bleh. In the emotivist theory, that's wrong,
or the statement that's wrong, or the phrase that's wrong is a lot like ouch. That's right
is a lot like yippee. There aren't any real ethical statements at all. In the emotivist
theory, ethical language is ultimately just emotive hoots and hollers and grunts and groans.
Here's a quote from Ayer. Ayer says, if I say to someone, you acted wrongly in stealing
that money, I'm not stating anything more than if I'd simply said you stole that money.
In adding that this action is wrong, I'm not making any further statement about it. I'm
simply evincing my moral disapproval of it. It is as if I had said you stole that money
in a peculiar tone of horror or written it with the addition of some special exclamation
marks. So Ayer says that when I use ethical language, I'm not really making any ethical
claims. That would demand some kind of statement. No, ethical language is something different.
In the emotivist theory, I'm just grunting and groaning. Okay, now what on that theory?
What on an emotivist theory becomes of the idea of ethical knowledge? On such a view,
there's no such thing as ethical truth to begin with. Here's Ayer again. If a sentence
makes no statement at all, there's obviously no sense in asking whether what it says is
true or false. And we've seen that sentences which simply express moral judgments don't
say anything. They are pure expressions of feeling and as such do not come under the
category of truth and falsehood. So the idea is that hoots and hollers and grunts and groans
aren't true or false. They're just hoots and hollers and grunts and groans. Truth and
falsehood don't apply. But knowledge is defined in terms of truth. If there's no truth, there
will be no knowledge. Now in a way, this gives us a conclusion that's stronger than a skeptical
conclusion. The skeptic at least thinks there's some truth we may not be able to know. Ayer's
conclusion is that what look like ethical statements aren't statements at all. In ethics, we have
just grunts and groans. There's nothing either to know or to fail to know. That's the emotivist
theory. Now there's a fundamental problem with any theory like this. The theory is ultimately
a theory about ethical language. If it's a good theory, it has to fit the linguistic
facts. And those are facts about how ethical language is actually used. So if emotivism
is right, it's got to be right about our ethical language. And the problem is that emotivism
simply doesn't fit the facts of our ethical language. The fact is that we use ethical
language to make claims. So you claim that abortion is always wrong, perhaps. I claim
it isn't. If so, you've made a general statement about the wrongness of abortion. My claim,
my contrary claim contradicts yours. Both claims can't be true. We both see that one
of us has to be wrong. You and claiming that abortion is always wrong, me and claiming
that's not true. One of us must be wrong about the ethical status of abortion. Now none
of that could be right if ethical language were just grunts and groans. Grunts and groans
aren't claims. Grunts and groans aren't statements. And grunts and groans don't contradict each
other. If I grunt and you groan, my grunt doesn't indicate that your groan is wrong or mistaken.
Mistaken about what? It was just a groan. We also give ethical arguments. We start from
ethical premises and see that they entail certain ethical conclusions. But Hoots and
Haulers and Grunts and groans just don't have the kind of logical structure that's required
for arguments. So the fact is that we use ethical language to make claims, to construct
ethical arguments, sometimes to contradict other people's ethical claims, and to express
real ethical disagreement. If emotivism were true, we'd have only emotive Hoots and Haulers
and Grunts and groans. And those could do almost none of the work we use ethical language
for. So in the end then, emotivism just isn't a very good theory about ethical language.
I think neither skepticism nor emotivism succeed in impugning the possibility of ethical
knowledge. But if we do have ethical knowledge, as we seem to have ethical knowledge, just
what kind of knowledge is that? One approach is to see ethical knowledge as somehow analogous
to empirical knowledge, or scientific knowledge. The way that we know many things about the
world, that the sea is salty, say, that acid burns, ultimately that the earth revolves
around the sun, is by way of perception. In some cases we can just look and see that
something's the case. In other cases we build theories, but those theories are ultimately
tested in terms of what we can look and see. So might ethical knowledge be like that? In
any kind of normal look and see, ethical knowledge looks like a bad candidate for that kind of
empirical knowledge. If you witness an assault, you don't see its wrongness as one of its
observable features. If someone examines someone else very closely in order to try to see their
rights, then they don't know what rights are. Wrongness isn't just something you can see
that way, rights aren't something you can just see that way. There is an approach that
sees ethical knowledge not as ordinary empirical knowledge, but as extraordinary empirical knowledge.
This goes together with a particular view of mathematics. As it happens in this view,
both mathematics and ethics involve a kind of extraordinary perception. Plato thought
of mathematical knowledge in terms of geometry. Over the entrance to the academy, his school
of philosophy, was the slogan, let no one ignorant of geometry enter here. And what's
geometry about? Well, geometry is about things like perfect triangles. Your high school geometry
teacher may well have been a Platonist in this way. He or she may have said, here, let
me draw a triangle on the board. Of course, this isn't a real triangle. It has lines that
have thickness as I've drawn it on the board. I haven't drawn them perfectly straight. What
we're talking about is the ideal triangle that this drawing on the board represents.
But how do we know about that perfect triangle, that ideal triangle if we can't draw one,
if indeed perfect triangles exist nowhere on this grubby earth? Simply put, Plato's theory
was that we see those perfect triangles with our mind's eye.
Ethical knowledge in such an approach is a glimpse of a realm of pure forms in which
the pure triangle exists. And according to Plato, ethical knowledge is similar. It comes
not from looking at the physical world around us, but by glimpsing the form of the good
in this other abstract realm. There's a more common view that's not too far from that.
It's the idea that we know the ethical value of right and wrong by listening to our conscience.
That still small voice inside is what tells us whether something is right or wrong.
Now, the problem with Plato's theory is that it postulates a form of perception, perception
of a realm of being, the realm of the perfect forms, for which we have no evidence at all.
No one has found a mind's eye buried deep in the brain, and it's unclear what it would
be looking at even if they did find it. This doesn't look like an ordinary explanation
for an ordinary kind of knowledge. It looks like a mythical explanation invoking some
mythical type of perception. Theories that we know right from wrong by listening to our
conscience are troublesome as well. The problem isn't psychological in reality as it is in
the Platonic case. Indeed, the notion of a still small voice inside does seem to have
some kind of psychological reality. The problem is in trying to believe that it's some kind
of infallible guide. Where would one's conscience get its information
on what's right and wrong? And how do we know that the still small voice is telling us the
truth about right and wrong? Mark Twain makes the point brilliantly in
the adventures of Huckleberry Finn. Huckleberry's conscience tells him that he should turn Jim
in. After all, Jim's a slave. He therefore belongs to someone else. Huckleberry berates
himself because he helped him go free. His conscience tells him that that was wrong by
helping Jim go free. He's deprived Miss Watson of her property. Not only that, but Jim talks
about trying to free his own children. Huck's conscience really bothers him about that.
After all, Huck says, those are children that belong to a man he doesn't even know.
Now, what we know, what Mark Twain relies on us knowing, is that Huckleberry's conscience
is not innate and is not infallible. That small voice inside is merely an echo of his
acculturation, complete with an approval of slavery, typical of that time and place.
In the end, Huckleberry Finn defies his conscience and decides not to turn Jim in.
Alright, then he says, I'll go to hell. There's another view of ethical knowledge
tied to a different view of mathematics. Euclid's axiomatization of geometry, written in 300
B.C., about 50 years after Plato, became a model for what knowledge should be like for
almost 2,000 years. But in Euclid, you don't answer every mathematical question by casting
your mind inward looking for the forms as Plato would have you do. In Euclid, you start with
a few basic axioms, which are taken to be self-evident. You deduce other things from
those axioms by small steps where the validity of each step is self-evident. You can find
out surprising things that way. Indeed, you can find out all the surprising truths of geometry
that way. The results may be surprising, but they follow by these self-evident steps from
your self-evident axiom. Is ethical knowledge like that? Some people have seemed to think
it was, including Thomas Jefferson. That image of ethical knowledge appears in the Declaration
of Independence. It says, we take these truths to be self-evident that all men are created
equal, endowed by their creator with certain inalienable rights, that among these are life,
liberty, and the pursuit of happiness. Jefferson formulates the Declaration of Independence
as if he's going to put down some self-evident axioms and deduce from them that the colonies
have a right to be free and independent. Even here, of course, one is supposed to see that
the basic axioms are true. To that extent, it's still a perceptual view of ethics, demanding
some kind of inner eye attuned to the ethical universe. Unfortunately, different people may
claim very different truths are self-evident. George III certainly didn't think it followed
from self-evident truths that the colonies should be free of English control. His self-evident
truths were something different. They were things like the divine right of kings. Different
people seem to take very different things to be self-evident, and that again makes you
doubt that the self-evidence of ethics is some infallible mode of inner perception.
So if ethical knowledge isn't some kind of empirical perception in the world analogous
to scientific knowledge, and if it does involve some kind of inner perception on the model
of mathematics, on either of these models of mathematics, just what kind of knowledge
is ethical knowledge? What I want to propose is that a large part of the setup of this
question is wrong. Neither scientific knowledge nor mathematical knowledge are really as we
tend to portray them, and when we have a better appreciation for what other kinds of knowledge
are like, I think ethical knowledge starts to look like those other kinds of knowledge.
Ethical knowledge starts to look much less different and much less strange. So take mathematical
knowledge first. The notion that mathematical knowledge involved some kind of infallible
insight into some abstract realm, that idea took a number of strong blows in the 20th century.
One blow was the development of non-Euclidean geometries. These are sets of axioms alternative
to Euclids. They're equally consistent and equally interesting, but they give radically
different results. In the face of non-Euclidean geometries, it's hard to maintain that there's
just one realm of mathematical truth of the sort Plato postulated. A second blow to that
kind of view of mathematics was the history of set theory, which was carefully built up
from self-evident axioms in the tried and tested Euclidean fashion. Here Gottlob Frege
was a major figure. The problem in the development of set theory was that Frege's self-evident
axioms led directly to contradiction. So the history of mathematics has taught us that
apparent self-evidence is no guarantee of truth. So a more contemporary view of mathematics
is that we start with some set of postulates, or patterns, or conceptions, and we work out
what will follow from those whatever may follow. The question of what that mathematics might
apply to, what it might be true of, that's taken to be a question separate from the logic
of mathematics itself. Mathematics itself just works from a set of postulates, whatever
they are, deducing from them whatever follows. According to this view, mathematics works
out patterns of consistency, but it doesn't tap into some separate platonic reality.
So that view of mathematics is different than the one we've been working with here. Now
consider the notion of empirical knowledge that's run through the lecture. If you want
to know something empirical, the standard view, if you want to know something about the world,
you just look and see if it's true. If you want to know something about amoebas, you
want to know whether they always divide into two, or are there cases where amoebas divide
spontaneously into three? If you want to find out something like that about the world, you
look through a microscope to find out. But even here in this case of scientific knowledge,
things aren't really that simple. When you look through a microscope in order to find
out about amoebas, there are a lot of background assumptions that you're holding steady. You're
assuming that the microscope is in fact enlarging something real, rather than just creating optical
artifacts. Christian Huygens, who invented an early microscope in the mid-1600s, worried
about precisely that kind of thing. And people who work with optical microscopes now still
worry about what they call false color. The question is whether the color they are seeing
through the microscope is real, or whether it's just an artifact of the viewing system.
So when you look through the microscope in order to just look and see, you're in fact
relying on a whole range of background assumptions, assumptions about optics, about light, assumptions
about the visible world. It's now accepted as a commonplace in philosophy of science that
all observation is like that. Even when you observe things with a naked eye, you're acting
on the basis of certain assumptions about the reliability of your eyes. In philosophy
of science, this is called the Quine-Duhem thesis, after Willard Van Arman-Quine and
Pierre-Duhem. You learn something from any experiment, or any experience, only because
you have some background theories that are already in place, at a minimum, the theory
that your eyes are working properly, the theory that you're not hallucinating. So you're
always working with those background assumptions. And what grounds those background assumptions?
Other assumptions. And other assumptions behind those. The idea is that any of those assumptions,
any of those claims can be tested. Anything can be put to the empirical test. But every
test has to hold other things constant in order to perform the test. So anything can be put
to the test, but only by holding other things constant.
Now the contemporary picture of our knowledge then, in both science and mathematics, tends
to be this more pragmatic picture. In both science and mathematics, the idea is that
we're working with some initial set of assumptions. We start with our current assumptions. Why?
Because we have to start somewhere. There's nowhere else to start but with our current
assumptions. Our pursuit of knowledge involves exploring the consequences of our initial assumptions,
both our conceptual assumptions and our empirical ones. In the conceptual case, in mathematics,
for example, we may see what follows from those assumptions. We may reject some on the basis
of conceptual inconsistency. In the empirical case, in science, for example, we hold some
assumptions steady and we test others against the world. When our theories fail, we try
new ones. What we're working toward is that set of theories that's going to stand up
best in the face of repeated empirical tests. And the idea is that's what finding scientific
truth is really all about. In both cases, what's at issue is rebuilding our ship, plank
by plank, while still at sea. In neither case, is there some royal root of insight or perception.
In neither mathematical nor scientific knowledge, is there some royal road of insight or perception.
Well, if that's what mathematical and scientific knowledge are like, in the end, I think ethical
knowledge may be very much like that. We start with a set of ethical convictions, the ones
we've learned from our parents, or our communities, perhaps. Why? Because we have to start somewhere.
And that's where conscience does play a role. But if we really want ethical knowledge,
we can't rely on conscience to be an infallible guide. Ethics, after all, is a matter of evaluation.
It's an evaluation of decisions, of actions, an evaluation of people and their characters.
And on this line of reasoning, we work toward ethical knowledge by progressively evaluating
something else, by evaluating and changing and reevaluating our modes of evaluation themselves.
So we test our modes of evaluation in terms, among other things, in terms of consistency.
In this respect, our ethical knowledge is like mathematical knowledge, but broader than
mathematical knowledge, because we're after consistent, in ethics, we're after consistency
in a wider sense. If we find a strict contradiction in our ethical principles, we know something
has to go. But in working toward ethical knowledge, we may also revise and refine our principles
using a broader sense of consistency. In mathematics, we're working with a single set of axioms.
In ethics, we're often working with a much less formal plurality of principles. And sometimes
we apply one of our principles, a principle concerning promises, perhaps, only to find
that the result is one that doesn't accord very well with our intuitions regarding justice
and fairness. That kind of tension between our different principles can tell us that
we don't have things quite right yet, and it can lead us to revise our ethical views.
I think we also test our modes of evaluation in terms of experience, but this too is in
a wider sense of experience than is common in science. Our ethical principles have to
be livable. When we see our principles in action, our own experiences can lead us to
change our minds. There's nothing simple about this process, but I don't think there's
anything mysterious about it either. I know people who have come back from war with new
moral views based in new moral experience. They come back knowing ethical truths they
didn't know before. The 20th century philosopher John Rawls
talks about reflective equilibrium as something one looks for in both science and ethics. Sometimes
we evaluate specific cases in terms of general theories. Sometimes we evaluate general theories
in terms of specific cases and particular experiences. So the point so far is that ethical
knowledge may not be something totally different. It does share features with both mathematical
and scientific knowledge as currently understood. But I think there's also a source of ethical
knowledge that is distinct. In ethics, unlike in mathematics and science, a primary focus
of evaluation is people's actions and people themselves. And one way that we evaluate forms
of ethical evaluation is by putting ourselves in other people's place and seeing how the
shoe fits. This is different than mathematics and science. In mathematics, we don't put
ourselves in the numbers place. In science, we don't put ourselves in the electrons place.
But in reflecting on ethics, we do put ourselves in other people's places.
This theory too has some philosophical precedence. The theory of this type appears in Hume, but
even more so in the early work of his friend Adam Smith, a philosopher as well as a founding
father of the science of economics. The theory is that our capacity for identification with
other people, our capacity for sympathy, our capacity for empathy are also a major source
of our ethical knowledge. Skepticism, which we mentioned at the beginning
of the lecture, is one kind of challenged ethics. Another challenge is the fact that
different cultures seem to embody very different ethical beliefs. Cultural relativism is the
topic of the next two lectures.
