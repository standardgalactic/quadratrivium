The
life form known as a human being has been a source of inspiration for roboticists since
Leonardo da Vinci designed what is arguably the first humanoid robot in the 16th century.
In spite of the great design, Leonardo doesn't appear to have built a working robot. He would
have been hindered by the lack of electricity, electronic sensors and motors, and a digital
electronic computer. All of these missing elements first came together in a mobile robot
named Shaky. Shaky was a mobile robot built by researchers
at the Stanford Research Institute from 1966 to 1972. This is the robot that Life magazine
in 1970 heralded as the first electronic person. Now, Shaky doesn't look like Leonardo's
humanoid or any humanoid for that matter. Why the comparison then to humans? Well, Shaky
had the ability to reason and plan with what was considered a brain-like machine, a digital
electronic computer. In the controlled but real-world conditions
of a laboratory, Shaky could successfully navigate, move through this world from one
place to another, avoid objects and, most impressively, adjust the changes in the world
that it hadn't known about. Shaky could learn and update its plans.
Key to this kind of thoughtful, deliberative navigation is a computer reasoning construct
for our robotic controller that we call an internal world model.
Model-based architectures are inspired by humans and our ability to visualize, plan,
and simulate our actions before we undertake them.
Some of the most important actions that we and our robots take are the goal-directed
movements that we call navigation. If you use a world model to navigate, we call that
model a map. In robotics, navigation is the most important
problem that you must get your mobile robots to solve. How do you safely and efficiently
get from point A to point B? Navigation is a fundamental example of movement
with a purpose, and purposeful movement is at the heart of self-control and autonomy
in mobile robots. There are different solutions to navigating,
depending on the workplace and the task of your robot.
Shaky shows us that maps can be useful indoors, and modern robots working indoors often use
maps too. Maps of floor plans, for example, and maps are also extremely helpful for sustained
and long-distance navigation outside. Over the past 2,000 years, we humans have
developed a whole set of formal rules for navigation, and navigation is not a trivial
problem, even though we take it for granted thanks to computers and GPS systems that do
the heavy lifting for us these days. Navigation begins with a seemingly simple
question. Where am I? Well, the trivial and not very useful answer
to that is, I'm right here. No matter where you go, there you are.
Now you need to know where you are relative to some reference position or landmark so
that you can set a course to go where you want to go.
In robotics, you can have your robot know where it is without using a map at all, provided
that the workplace is structured, predictable, and confined.
And here's how. You can set up a beacon so the robot can always return home, and this
process is called homing. Homing is the ability to go out and get back
where you started. And once you are back where you started, then you know where you are.
For robots, homing is important for returning from a mission or recharging your batteries.
Let's watch Roomba home. I'm going to hit the cleaning button here.
Roomba is going to get going here. Oop, come on Roomba.
Let's start cleaning. And normally Roomba would move around
the room doing what it's doing here. I'm going to actually hit the dock button.
Now its docking station is over here, and what's going to happen is Roomba is going
to move around and look for that docking station.
And it's detected the IR signal that's on our dock, and now it's going to maneuver
into place. And it may take a little while here.
So Roomba is able to navigate without a map because it can sense the signal from that
IR beacon that's on the dock. And using a beacon is an example of what
we call landmark navigation. A beacon is one type of landmark that actively emits a signal,
perfect. The classic navigational beacon is a lighthouse.
For Roomba, operating without an internal world model, all we need its computer code
to do is read the intensity of the beacon's IR signal with its IR sensor and make adjustments
to minimize the difference between the maximum value measured and the values that have just
been measured. So this is an example of negative feedback control, where you minimize the error
between a desired and an actual state in order to regulate your movements.
Let's think about how we could use negative feedback control to make an algorithm to allow
Roomba to navigate to its home beacon station with just a single IR sensor.
Now I always find it helps to work through these kinds of instructions by pretending
to be the robot. So let's be the robot. I'm going to pretend that my fist here is the
IR sensor and that the home beacon is over there. So far so good.
Now let's say that I measure the strength of the IR signal as 10 right at this minute.
I move forward a little bit and to the right and then I'm going to take another measurement.
Now the signal strength is 8. If we take the difference between the two, between 10 and
8, and 10 is the maximum value I've taken so far, the difference is 2 obviously and
we call this the error term in control theory. But with only a single sensor, I don't yet
know what that error tells me. Am I going too far to the right or too far to the left?
Now we can see that I'm actually turning away if I kept going from the beacon to the right.
But as a robot, I don't know that. John the robot needs more information. One way that
robots, including shaky, get more information is to move and see or really sense what happens.
And this is called active perception, using your motion. So let me do that. I'll take
one more step forward as I turn to the right. Now all that I know is that I've just moved
to the right again and now I measure an IR value here of 6. So the difference with the
maximum value which I measured over here is 4, right? 10 minus 6. We're getting somewhere
literally and figuratively. I can compare the two errors that I just measured and I
calculate that the most recent error 4 is actually greater than the earlier error 2.
So what's happening is the error is increasing. What else do I know? Well because I kept track
of how I was turning, I know that I was turning to the right and that that movement turning
to the right increased the error. So if the goal of negative feedback is to decrease the
error then I need to turn in the opposite direction. Now I turn to the left as I move
forward and I measure 8 on my sensor. I've got a difference of 2. I compare this with
the most recent error of 4 and find that turning to the left I'm decreasing it. Perfect. I'm
heading back towards the beacon. Look Ma, I'm navigating. We've just created an algorithm,
a set of instructions for navigating towards a beacon using just a single sensor. By the
way, breaking down a task like this into the smallest steps possible and writing those
steps down is a great way to begin the process of creating algorithms and programming your
robot. One of the most important tricks of this simple homing algorithm is that we had
to know something about how we were moving. In this case we were keeping track of which
direction we were turning. This algorithm for homing is very similar to an algorithm
for holding a compass heading. Obviously we're using a compass as our navigational sensor
here and I have a compass right here. Like homing or docking, holding a compass heading
is a very basic behavior in robot navigation. I'm going to be the robot again and I'll
hold this compass rigid to my body. I'm going to head, let's say, east here on my compass
and I'm going to close my eyes and take a step in what I think is the correct direction.
One giant step for robotics, one small step for John, and what happens here? I'm still
pointed in the right direction. Oops. Nope. I'm now heading at southeast here. So again
I can calculate an error. The difference between the desired heading, which was in degrees,
45 degrees, and the actual heading, which was 55. So we have the same problem as before.
What does the error mean? How do we convert that error into instructions for how I should
move next? For starters, let's say that if the error is negative, then we should turn
to the left. That means if the error is positive, then we should turn to the right. Let's see
if this works. So I turn to the left and I take a step forward, 35 degrees. Calculate
the error, 45 minus 35 equals 10. Positive error means turn to the right. Okay, perfect.
You can see what happens here. I wiggle my way forward along the correct course. We've
just created another navigational algorithm. This one was using a compass. Now let's see
this in action in a robot. A digital compass is a common sensor to put on a robot. The Arduino
robot has a digital sensor built in. It's a Honeywell model HMC 6352 and it's a two-axis
magneto-resistive sensor. These sensors change their electrical resistance in response to
changes in the magnetic field. Magneto resistance was discovered by Lord Kelvin in 1851. One
of the great advantages of a compass over a system like an IR beacon is that it works
at any distance and in any condition, snow, rain or with obscured vision. At the same time,
one great disadvantage of a compass is that it's sensitive to local magnetic sources. So
you need to keep that in mind if you get strange results or operate around a lot of machinery.
In the computer code for the Arduino robot, we've programmed the robot to move along a
course set by its internal compass, just as I was trying to do with the real compass here.
So we calculate the error term as the difference between the desired and the actual compass heading.
I'm going to get my Arduino robot turned on here so it can warm up. So when we turn on
the Arduino robot, the first thing I want you to notice is that I'm actually going to
have it heading back here and it's going to want to turn and it's going to head along
a straight course here. See how far it goes? Put it down. I'll have it going this way.
It's heading towards the back of the head. It's getting attracted to the metal here.
Let me pull it out here and see what's actually going on. So I can see I'm actually outputting
the compass heading and so in fact the compass wants to go directly behind me. So let me
point it forward in this direction and see what happens. Okay, Arduino robot. So it's
not turning around in part because here in the laboratory we have a whole lot of metal
going on here but you could see as it was snaking off in this direction it was actually
wiggling on a compass course. It was holding a compass heading in its mind anyway. It thought
it had here. Now holding a compass heading is perhaps the most basic behavior of navigation.
Put it this way. If you can't move steadily on a given compass heading you'll not be very
efficient when it comes to navigating using a map. So one of the great advantages of using
a compass is that you don't need to use a beacon or a landmark. Sailors learn to steer
by the compass and can sail in the dark. But holding your compass heading only gets you
so far navigationally speaking. With a compass alone you don't know where you are but only
in what direction you are headed. Even if you don't know where you are a compass can
be useful to know where you just were which is how we can build up to homing from hold
your compass heading. So homing with a compass is handy for example if you are lost in a
snowstorm you head out in one direction looking for people right. To keep track of where you've
searched or how to get back you need to track your motion relative to where you started.
For navigation with a compass in addition to knowing your direction you need to know where
you are on a map as you travel. So you need something to figure out the distance you've
traveled from a known starting position. Now here's a trick. If you're on foot you can
count your steps. If you know the length of each step then you can multiply the number
of steps and the total length to estimate the total distance you've traveled. You can
solve this problem on a wheeled robot by counting the number of rotations of your wheels.
Mechanical odometers were known to hero of ancient Greece and to Leonardo da Vinci. Electronic
sensors can count rotations too such as a sensor called a shaft encoder. Now a shaft
encoder is often a magnet or an IR emitter detector that counts high contrast lines on
the wheel. But with a stepper motor you can simply tell the motors how much to rotate.
If you know the size of your wheel and the rate at which it's rotating you can build
a speedometer. And if you have a clock to keep track of how long you've been doing going
in that direction and at that speed then you can calculate the distance you've traveled.
Your current position relative to where you started and now you know how to get back home.
The distance traveled is the product of your speed and the time you've been moving at that
speed. With distance and direction you've traveled from your starting point and you
know where you are relative to where you were. Using our snowstorm example this can be life
saving if you need to get back to your car let's say to stay warm. You reverse your
direction 180 degrees and travel back to where you started. So we've got compass, odometer,
speedometer, clock. That's what's important in navigation. And in robots very cool we
get all these multiple sensors involved in navigation. And coordination of multiple sensors
sounds like a job for a robotic controller. So in practice going straight out and then
straight back is actually rarely very useful in what we want robots to do. We often want
our robots to explore or to carry passengers for hours along a course on the road or the
sea that may involve avoiding land, bodies of water or known obstacles. Now let's try
something different with our robot Sparky. Sparky is a robot built by ArcBotics and we're
going to use Sparky because it has stepper motors that control the position of its wheels.
So let's imagine a real world situation here. We want Sparky to patrol the perimeter of
let's say our laboratory here. And imagine that we want Sparky to carry a webcam around
and perform surveillance for us. Imagine that through the webcam we can get a view of what's
going on even though we might be elsewhere. I'm going to turn Sparky on here just a second.
And let's make the path of that Sparky is taking square. So it's going to patrol around
the laboratory here. Now as I mentioned Sparky's wheels have motors that are a special kind
of motor called a stepper motor that offer very precise movement with the trade off of
not rotating very very quickly. So we can literally count our steps with Sparky, estimate
the distance traveled by keeping track of the number of rotations and then multiplying
that number by the circumference of the wheels here. So the code for Sparky is written in
a architecture called Sparkyduino because of its Arduino type microcontroller that it
has. And it contains commands like Sparky move forward into which you can place a specific
value for how many centimeters you want Sparky to move or how many degrees you want Sparky
to turn. So this makes it easy to program a square patrol path. Now what should happen
is that Sparky patrols this circuit that we've got for it and then it should come right back
to where it started. So I'm going to turn Sparky on here and it's going to begin to
initialize. So this kind of navigation is called dead reckoning by Mariners. So here
goes Sparky and this is not really fair yet since I didn't have Sparky on the ground here.
What I want to do actually is put a little piece of tape on the ground and Sparky has
a hole in it which you can actually stick a pen by the way which is pretty cool so you
can draw with Sparky. So I'm going to use that hole to align that little piece of yellow
tape and so then we know exactly where Sparky started. We have Sparky to head out. We're
going to do a very small square here. So there goes Sparky. So dead reckoning involves knowing
where you are for starters and then heading out and moving along your intended course.
So there's Sparky taking a turn and after you've traveled a given distance and heading
is calculated by your compass clock and speedometer then you know where you are and you can mark
it on the map. So we're watching Sparky in action here. It's made another turn. So I've
marked that starting point as you can see and I don't know if you can tell Sparky is
supposed to be taking 90 degree turns and it's almost making 90 degree turns but it's
not quite coming back to where it started here. So what's happening is there are tiny
little errors in every little movement that Sparky makes. These add up and they're called
in navigational terms drift. Drift is caused by little things like the slippage of a wheel
or one motor being a little weaker than the other. For a shipper or a robot at sea winds
and tide cause huge amounts of drift. As you can imagine each time around the block here
Sparky's drift will accumulate such that the robot will get farther and farther away
from where it's supposed to end up. So let's let it come right back here. One more time
let's see how close you are Sparky and I'll stop it and we can see. So this is the problem
with dead reckoning. So we're back to the first question of navigation. Where am I?
Okay Sparky we're going to stop you right there and if I look down that hole on Sparky
is off from where we started by about three inches it looks like. So if we were to ask
after a couple of circuits around that perimeter Sparky where are you? Sparky would think well
I'm right there at that yellow spot but Sparky's actually off so that's drift. Now one way
to know where you are instead of doing dead reckoning is to have your robot use GPS the
global positioning system. One of the exciting breakthroughs in consumer robotics is that
our robots are now fully capable of navigating for themselves outside with GPS. GPS is actually
a fleet of navigational beacons mounted on satellites in orbit that provide us and our
robots with what we call a navigational fix. Now one warning GPS only works outside or
only works well outside and in the air. Inside or underwater you need to find other ways
to get a navigational fix. A fix refers to fixing your location or your position on a
map. To do this with GPS the robot needs a GPS receiver that reads the signal from GPS
satellites. The satellites know exactly where they are even though their position is changing
as they orbit. By knowing where the satellites are and the distance to them you can triangulate
your own position. So this is done with a GPS module some trigonometry and it's done
with a little computer on board the GPS module. There are also minor adjustments for special
and general relativity. The satellites are traveling very fast and they experience less
gravity than we do on earth. For us the take home message is that the GPS module is a very
fancy sensor that gives the robot its position in latitude and longitude. So with GPS we
can get around the problems of dead reckoning by using waypoints. We can tell the robot
to go to a particular spot and that's called a waypoint. If the robot senses that it's
not in the right position it can make adjustments. Those adjustments are done by good old negative
feedback control. Knowing what we know about navigation how did shaky manage the task under
the much simpler conditions of an indoor world? For accurate navigation we now know that sensors
are needed. So let's start there. Shaky's principal sensor was the TV camera on its
head. This camera could pan up and down and it provided the raw data for the computer
to calculate where objects were, what the objects were and just as importantly where
shaky was. Shaky also had bump sensors and an optical range finder to help locate and
identify objects. Two stepper motors moved shaky around with care and reasonable accuracy.
So like our friend Sparky, shaky had stepper motors. While shaky had a small computer on
board to help with communications and motor control, one big, literally big challenge
for the SRI team was to give shaky a computer that was powerful enough to hold in its memory
a world model. The computer also had to take in data from the camera, perform calculations
in order to update the world model and then use the reason-based algorithms it had to
plan shaky's next set of movements. So where was shaky's main controller? Well at the
time in the late 1960s powerful digital computers were large and heavy, the size of a bank of
industrial refrigerators filling a good-sized room. The final version of shaky used a digital
equipment corporation, PDP 10 slash PDP 15 mainframe. Because this mainframe was too
big to carry around, to serve as the controller of shaky on board, the two, the robot and
the computer had been constant radio communication. Shaky collected information about its position
in the world and then sent that information to the mainframe via the radio link. Acting
as the controller in the sensor actuator loop, the mainframe's job was then to update the
world model, create a new plan of action to achieve its navigational goal and finally
send the instructions back to shaky for how to rotate those stepper motors driving the
wheels and ultimately how to move shaky. So because it took time to collect information,
send it to the mainframe, perform the calculations and then send the instructions back, shaky
moved in a series of short choppy steps and each time it stopped its camera headed tower
shook hence its name. First things first, shaky clearly navigates successfully around
an object. So far, so good. But one of the big challenges if you are a navigate using
a map is if that map has to be accurate. So what do you do if the world changes and
those changes aren't on your map? Well, you're in trouble, right? And your mission is likely
to fail. This is where shaky's sensors came into play. What the researchers at SRI imagined,
just as an experiment here, was that a gremlin who was really a graduate student in a cape
could swoop into the room while shaky was busy pushing a block out of the way. Now,
shaky can't detect the gremlin because shaky is visually blind to the world as it moves.
So the gremlin, a sort of cosmic trickster if you will, whose job is to change the world,
pushes the block a little bit trying to disrupt shaky's attempt to push the block forward.
When shaky stops, its optical range sensors indicate a change in the world, that the box
has slipped off the bar it was pushing. So its catwhisker touch sensors tell which side
of shaky the box has moved to and shaky can adjust its movements to reengage with the box.
Now after shaky circles around and picks up the block, again, it has a problem. Shaky
needs to make sure that it knows where it is in the world and on the map. Shaky keeps
track of its own position by counting its wheel revolutions. Good old dead reckoning,
right? So the stepper motors are helpful here because like servo motors, their rotations
are carefully controlled, but as we've talked about, this kind of navigation can't be blind.
You've got to update where you are on your map all the time.
Shaky updated its map by taking a picture of a corner of the room for example and then
calculating its position relative to that corner. When shaky knows where it is, it can
then calculate a plan to achieve its goal successfully and shaky's goal is programmed
as instructions to take a certain course in the world. When shaky gets into its final
room in the experiment we're talking about here, what we can see on this video clip is
that shaky's actually able to push a block to the door and push it away. So shaky uses
its camera to make sure that the path is clear heading into the next room. Note that the stop
and look behavior of shaky is pre-programmed into the robot. Check the floor of the new
room that I enter for objects. If clear, then proceed. In that next room, shaky looks ahead
to see if any objects not on the map appear. Aha, an object! Warning, the map needs to
be updated. Take pictures, analyze the position of the object. Shaky then updates the world
model, the map. It then calculates a new path around the newly discovered object. See how
that works? Sense, model, plan, and act. In terms of a sensor actuator system, the information
of the sensors is sent to the computer controller. The controller updates the model, then creates
a new plan for how to best achieve its navigational goals. Then it sends the plan back to the
robot which moves the actuators accordingly. So here's a cool way to think of this process.
When shaky acts, moves, its movements are a test of that new plan. In this case, the
new plan works. Shaky makes it into the room in which it is going in order to push a block.
So in spite of the fun that some modern roboticists have poked at shaky, it's really worth appreciating
what the team from SRI was trying to do at the time and it was revolutionary. Quote, it's
the objective of this program to develop concepts and techniques in artificial intelligence
enabling an automaton to function independently in realistic environments. We're talking
about autonomy here and this statement points to the fact that shaky was ahead of its time.
Looking back, we recognize that the project was an important watershed moment in robotics
for three reasons. First, shaky was the first robot to use a powerful digital computer for
its robotic controller. Second, because of that computing power, shaky was also the first
to use what we now think of as a model-based controller architecture. Third, the use of
rules of reasoning and deliberation in planning routines clearly links shaky to the early days
of the field that John McCarthy called artificial intelligence or AI, which he defined as the
science and engineering of making intelligent machines. So successful was AI that by 1970
Marvin Minsky was quoted in a life magazine saying, in from three to eight years we will
have a machine with the general intelligence of an average human being. That didn't happen
and it hasn't happened yet. Some argue that the cognitive computing systems like IBM's
Watson have exceeded human intelligence when it comes to what is called deep question and
answer. Watson beat the best humans, our champions, in the game show Jeopardy. Watson is just
one of various computer systems that have beaten humans at things we never thought a
machine could do. There was a time when many smart people thought that mathematics could
never be done by a machine, but your simple calculator beats most of us hands down.
Chess was thought to be an ultimate test of human intelligence until IBM's deep blue
computer beat chess grandmaster Gary Kasparov. Given these successes of AI, many roboticists
recognize Moravex paradox. What we originally thought were the hard problems of AI turned
out to be easy to solve and the easy problems turned out to be hard. The bottom line, it's
really hard to make mobile autonomous robots that are like humans in terms of their bodies
and their movements. Honda has spent millions of dollars on Asimov and in spite of its physical
abilities, which are really wonderful, it's still not a fully autonomous humanoid. Now
that takes us to the very impressive reasoning that Shaky was doing with its world model,
its interactive map of its laboratory. The criticism over the years with the world model
design of robots is that you need to have complete knowledge of your world. Everything,
especially the new and the unexpected, has to be detected, identified, and then mapped
in order to accurately update the model. In Shaky's world, the objects were all specially
shaped and painted. They were of a limited class of possible objects and all objects
had known properties that could be accounted for in planning Shaky's actions. All this
works fine inside a lab or even an office building where the world of possible objects
is limited. It's an approach that's really difficult out of doors, where who knows what
you'll run into. Of course, many new tools have been created since Shaky. For example,
one thing that Asimov, each of the Mars rovers and even a lot of industrial robots have in
common is that they all use real-time operating system called VXWorks, which was first released
in 1987, almost two decades later. But what Shaky did do was successfully tackle a whole
class of really tough problems in mobile robotics for real-world environments, slam algorithms,
slam stands for simultaneous localization and mapping. That's a fancy way of saying
figure out where you are as you're making a map of where you are.
This is very much how, like, humans do it. Now, we've come a long way since Shaky was
moving through the controlled conditions of a laboratory. Think of the Mars rovers stopping
to plan their next move on a planet where humans have never set foot. Still, there was
a period when roboticists were keenly aware of Shaky's limitations, and the next lecture
will see a very different approach to robotics, an approach inspired by the simple behavior
of animals.
