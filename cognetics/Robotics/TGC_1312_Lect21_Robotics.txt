How close to living can we make a robot?
Even if we disagree about what constitutes life, we can agree on one thing about life
forms.
Being alive means you can, you should, you must harvest energy.
And when you can't, you cease to function, you die, you are terminated.
Now robots need to harvest and use energy too.
The energy supply for robots is often a battery.
It's not really fair to say that robots harvest energy if we humans put batteries in, right?
We're not harvesting it, we're giving it to them.
But remember Roomba?
Roomba went back to its charger.
Other robots can do even more.
Since 2009, the PR2 testbed robot from Willow Garage has been able to open doors for itself.
Move on if a door is locked, find a standard wall outlet, plug itself in, and get energy.
Other robots cut the cord entirely.
The wave glider robot uses wave power to swim and solar power to charge its batteries.
But none of these methods of energy harvesting are similar to what animals do.
We animals eat food.
Our stomach, intestines, and digestive organs work to chemically break down the organic
matter that we ingest.
And then we extract at a molecular level chemical potential energy for later use by our cells.
One of the first attempts to digest food in a robot, well, okay, an automaton, comes
from 18th century France and an inventor named Jacques de Vecasson.
In 1739, Vecasson charged admission fees for people to see his mechanical duck.
It would eat and then, forgive me, defecate.
This was a very popular exhibit if you can believe it.
And if you were watching the duck, you would see the food going into the mouth and you
might guess that the gears were macerating grain internally and you're not sure about
the chemical digestion part.
And then, voila.
We have tubes coming out the rear end for our waste delivery, maired.
But really, this famous pooping duck was an elaborate hoax.
Grain fed into the duck's mouth went below the main platform and was exchanged there
for a moist poop, which was really premade out of breadcrumbs.
But the idea of genuinely organic energy autonomy is no joke.
There's a robot capable of ingesting organic matter for food and for fuel.
It's a wheeled ground robot called Eater, which stands for Energetically Autonomous
Tactical Robot.
Under development by Robot Technology Incorporated in partnership with DARPA, the basic idea
of Eater is simple and concept.
Replace the environment for organic material, collect it, and then convert it into a usable
energy source.
The guts of the operation, quite literally, is an external combustion engine.
Water in one chamber is heated by combustion of organic matter biomass in an adjacent but
separate chamber.
Once ingested, the biomass is burned to provide heat.
The heat from the food boils the water.
That heat is used in a heat exchanger to generate electrical power.
Eater is a great idea if you need your robot to operate in remote areas for long periods
of time.
Imagine being able to collect and burn your own fuel.
But good idea or not, Eater isn't digesting its food chemically.
Yet even real chemical digestion and energy creation are in fact possible.
At the University of West of England, Professor Chris Melhewesh and his colleagues have been
working on a biologically-based fuel cell that uses bacteria, microbes, to convert things
like rotting fruit into electrical energy.
Fuel cells convert chemical energy into electrical energy, and they are all the rage as energy
alternatives to internal combustion engines in our vehicles.
The standard fuel cell uses hydrogen or hydrocarbons as its chemical source, and a chemical reaction
of the hydrogen with another chemical, like oxygen, moves electrons around.
The trick of a fuel cell is to arrange electron donors and electron acceptors in such a way
as to organize and guide the movement of the electrons so that a useful electrical current
can be generated.
Now, what Melhewesh and his colleagues have done is to put living microorganisms into
the fuel cell.
These microbes take in chemicals from rotten fruit, like apples, and produce, as their
waste products, free electrons.
Those free electrons are collected and guided.
Their movement is used to create an electrical current.
Melhewesh has put the microbial fuel cells into a robot called EcoBot 2.
Eight of the fuel cells are arranged on the deck of a round-wheeled robot, and the fuel
cells work away and the electrical current they produce charges capacitors.
Capacitors are electronic devices built to store up and then quickly release electrical
charge.
The stored charge in EcoBot 2's capacitors is used to power either its wheels or its
communication system.
EcoBot 2 has a controller that works with photo detectors to head the robot towards
a light source powered by rotten apples.
EcoBot 2 is a very slow-going robot, but if you are patient, you can see in this video
clip it lurching forward now and then.
Why is it so slow?
Well, keep in mind that electrical power comes from biological cells in this robot.
These are living organisms inside the fuel cells.
EcoBot 2 is a type of gastrobot, a robot that gets all of its energy from the digestion
of food.
EcoBot 2 is on the road to true energy autonomy, and that's the goal of Melhewesh's research
project.
Now imagine that we could combine EcoBot's chemical digestion talent with Eater's ability
to search for and find appropriate food in the environment.
Then we would really be moving robots towards total energy autonomy and operating like life
forms.
Seek out new life forms and eat them.
Another thing that life forms do that robots don't is to build themselves.
It's a funny way to put it, but building yourself is what you did and may still be doing.
Be proud of what you've accomplished.
That's not the way we normally engineer robots or other devices.
We don't start with an engine, turn it on, connect a single wheel and then ask it to
drive down the highway while we search for parts to attach to it to make it into an adult
automobile.
Nope.
We assemble the whole darn thing.
One really nifty exception is the International Space Station, which has had to function while
we've been building it.
Much of life starts as an egg, but we don't think of eggs as doing much except hanging
out waiting for life to happen.
And really, eggs are alive and the creation of multiple cells is one of the first tasks
for an egg.
Make more of me.
So there's work to be done even there.
Most organisms develop in stages.
Mosquitoes develop through a life cycle, from egg to larva, from larva to pupa, then from
pupa to imigo.
Larvae start moving around in the world and doing what?
Can you guess?
Of course, feeding, harvesting energy.
The larvae grow into the larger pupa, whose job it is to build a new set of structures
that will make the winged air creature we know and love the mosquito, technically that
imigo stage of development.
What's helpful about looking at the life cycle of an insect is that we can think about
different stages in that life.
Caterpillars are a classic example of becoming butterflies and having a life cycle that's
divided up into discrete stages.
You can glean from mosquitoes some basic life lessons for building yourself.
Move around to gather energy.
Use that energy to make yourself bigger by building more of you.
And as you grow bigger, build new kinds of structures that allow you to move around in
different ways, collect energy in different ways, and, lest we forget, figure out how
to make offspring.
Can you imagine building a robot that builds itself?
How would you do that?
Sam Felton begins with a sheet of paper.
OK, well, maybe not just a piece of paper, but with a sheet of composite material that
includes paper, copper, polyamide, and pre-stretched polystyrene.
Polyamide is a plastic-like insulating film that's used in medical tubing.
Polystyrene is a plastic that you encounter in packing peanuts and yogurt containers.
So we have in Felton's laminate the following, paper, metal, and plastic.
When you heat this composite sheet of material, the polystyrene shrinks, and if you arrange
the paper and polystyrene in the right way, the heating will cause the layer to fold.
Add heat, the sheet folds, and the sheet builds itself.
This is like a simple kind of origami, but instead of a human doing the folding, the
paper is folding itself wicked, wicked cool, right?
And now what Felton and his team in Robert Wood's lab at Harvard have done is to program
the sheet to fold up in a particular pattern, to make legs, engage a motor, and walk away.
What's really impressive is to watch this action unfold, so to speak.
You can see in this clip that as the system is heated, from two dimensions, we get three.
Most impressive is when the thing, which a few minutes before was a strange-looking sheet,
has just folded itself up and then walked away.
What in the heck happened?
This machine just built itself, that's what.
Now what's really exciting about this process is that the instructions for building itself
were not written in computer code or DNA.
Instead the instructions were built into the laminate sheet.
This is what they mean when Felton and his team talk about programming matter.
Keep in mind that the catalyst that starts the self-assembly is a change in the environment,
heat in this case.
Now to think about Felton's self-assembled walker in terms of a life cycle, we can think
of that flat sheet as the egg stage, roughly, sitting around, ready to make something out
of itself.
The heat turns on, the egg begins to build itself, a larval stage involving growing up
literally and building the adult.
The adult stage is the final walker, which leaves home as soon as it can.
The different approach to life cycles in robots has been taken by Josh Bongard, a professor
at University of Vermont.
He and his team have focused on metamorphosis, the transition from one life cycle stage to
another.
Working in digital simulation and with embodied robots, they discovered that individuals programmed
to change their bodies over time found new, better behaviors more rapidly than robots
that held their bodies constant.
The robot starts by laying flat on the ground with a sprawled posture, legs out.
It has a controller program whose job is to figure out how to move those legs in order
to move the whole body.
Using an evolutionary program, which I'll tell you more about later, many different
and randomly created controller programs can be tried out.
The best one is the one that moves the robot the fastest across the ground.
Once a good controller is evolved that works well for the sprawled posture, that controller
can be used as the starting point for when the robot brings its legs underneath its body.
Now if the body changes in one fell swoop, then it turns out that it takes longer to
evolve a controller that works well, compared to allowing the change in the body's posture
to be part of the robot's gradual development.
During development, the legs slowly change their posture, and that helps bridge the original
controller to the final controller.
The result is that development speeds up evolution.
Now this metamorphosis is not a transformer kind of metamorphosis.
Optimus Prime, this robot is not.
But it shows the benefit of having a body that can change, and the benefit of having
a process that can search for new controllers that can make the best use of the ever-changing
body.
Think of that as a search process.
It's a search process within the life of an individual that can be thought of as a
compound process of learning and development, and this takes place by trial and error.
A related search process is evolution.
Now one of the differences between development and evolution is that while development describes
the changes taking place to an individual, evolution describes the changes that are
taking place from one generation to the next, from one group of individuals to another group
of related individuals, from parents to offspring.
Like development and learning, evolution works by trial and error, but on a different
scale.
Since evolution is definitely a feature of life forms, let me take a minute to explain
in broad strokes how it works.
Then I'll show you how we apply it to robots.
The basic idea is that you have a population, like a group of fish, let's say, that you
see in the tank here in the laboratory.
Each individual is slightly or dramatically different from others.
Now let's say a predator, another species of fish, is in the same tank as these fish,
and this predator really likes orange fish.
After a while, all that's left are the non-orange fish, let's say the yellowish ones.
We would say that the predator has selected certain individuals to die and certain individuals
to live.
The survivors in turn are very important, since they're the only individuals around to
become the parents of the next generation.
They reproduce, creating a new population.
If we compare the first generation to the second, the parents to the offspring, you
can see right away that the average color of the fish has changed, color has evolved.
Now how does this relate to trial and error?
Think of each individual in generation one as a separate experiment in fish color.
No one is sure which colors will be the best in any given year.
So the trick is to make sure that each year there are different colors out there.
Imagine if all the fish were orange, they'd all be eaten.
So variation is key here.
Give us options, and each variation is on trial.
In this particular example, the errors in a trial and error sense are the orange fish
since the predator eats all of them.
So the system changes by trial and error finding over many generations the best color
to be if you want to avoid being eaten.
Now the very cool thing about evolution is that it's another one of these processes
that is characteristic of life, and using the process of evolution we can evolve robots.
For roboticists, evolution is one way to design robots, but the design is not like the engineering
approaches that we've explored.
Design by evolution is also not like the hacking approach that we've used.
Standard engineering and hacking both involve humans making decisions about the design of
robots, not so with evolution.
We take the humans out of the design loop.
This should sound familiar.
It's like taking humans out of the control loop, allowing robots perform tasks autonomously.
With evolution, we are allowing robots to design themselves autonomously.
Let's take a moment to appreciate all this.
We can boil life down to autonomy.
Like dogfish sharks, all life forms do all of this on their own.
They eat, they behave, they develop, and they evolve.
And as we work from nature, like sharks, to create robots that have more properties of
life, we are extending the kinds of autonomy that they have.
Eating becomes energy harvesting.
Eating becomes performing tasks.
Development becomes self-assembly.
And evolution becomes automatic redesigning.
I want to talk more about this evolution, this auto-redesigning process.
And let me introduce you to another kind of robot called the Tadro robot.
Now, I've got some robots in here that are built on the Tadro design, which is this,
what is essentially a food container, servo motor, with a microcontroller inside.
There's some eye spots here, and look at this thing off the back.
This is a tail that has vertebrae in it.
So when we ran our evolutionary experiments, we called the robots that were the prey robots,
the ones that were going to be eaten by the predator, prey roe.
And prey roe is a model of a 400 million-year-old fish called drepanaspis.
Working with my colleagues at Vassar College, what we're trying to understand is what kinds
of selection pressures may have caused ancient fish like drepanaspis to evolve the bones
in their back that we humans have.
We call these bones vertebrae.
So the answer lets us understand how vertebrates got their vertebrae and got their start.
This is an example of a flexible rod to which we've added some vertebrae-like bones.
Give you a sense of what a backbone looks like.
Now our guess was that predators might be selecting for faster fish over slower ones.
Based on biomechanical tests that we've done with fish and swimming robots, we actually
predicted that faster fish would be the ones with more vertebrae in their back.
To test the evolutionary idea about the importance of vertebrae, we put different individuals
of prey roe, each with a backbone with different numbers of bones, into a tank with a robot
predator.
That predator was called tatiator.
So let me show you some examples of some biomimetic skeletons with different numbers
of vertebrae.
So here are two different kinds of prey roe.
This one here is just loaded up with vertebrae in the tail.
This one has just a few.
And I have a third tad roe over here, and this robot has none.
So these skeletons, these vertebral columns, are used by these robots as the primary axial
skeleton in the tail, the propulsive element of these robots.
Now what I would like to do for you here, everything is the same in these three robots
except the number of vertebrae in their tails.
I'd like to get them swimming and give you an example of what has happened when we evolved
robots in terms of evolving different kinds of functions.
So I can show you what happens to swimming performance and let you see here.
So I'm going to start turning these guys on, and I have to signal to them to get their
tail moving by putting them in darkness.
So I have a little dark chamber here, a little dark chamber.
There they go.
You can see their tails wiggling, come on.
All right, this one's not wanting to behave here, so we'll just set it aside.
Well this is perfect.
The two that are working we have with the fewest and the most vertebrae.
And let's just turn them around here and do a little race so we'll see how they swim
differently, if at all.
Maybe there's no functional difference.
All right, pre-row, go.
Here we go.
What do you see in here?
Now they're not swimming perfectly straight here in the water, and this one kind of is
off-kilter.
And what's really funny about this, but it's telling, right, is what's supposed to
happen is the one with more vertebrae is supposed to swim faster.
And I think it was clear that this one actually swam more slowly.
Now this is telling for a reason.
I set this up for you to try to show that evolution would select for higher numbers
of vertebrae.
But what actually happened when we ran our experimental tests is it was the intermediate
number of vertebrae.
Along these lines, one, two, three, four, actually about six was the best number.
So the robot where that tail didn't work was actually the best swimmer in our evolutionary
trials.
So this just shows that there's actually a problem when you make your tail too stiff.
There's a trade-off.
So it's actually, I didn't mean it to happen this way, but it's a perfect example of the
kinds of trade-offs that we see happen in evolutionary system.
Now let me tell you a little bit more about the evolutionary trials that we ran.
We had behaviorally autonomous robots, I'm not sure I said that, and of two different
types, right?
We had the prey rows and we had the tatiators.
So prey rows in any one generation, any particular prey row was one of six different individuals
or six different genotypes in that population.
And it was actually competing against those other prey rows to see who was selected by
the predator to be parents for the next generation.
And the top three performers were the ones who were allowed to breed to make that next
generation.
Each prey row was cloned so that we had three identical triplets to test against the predator.
So with six different genotypes, that made for 18 different prey row tails that we tested
every generation.
All any individual prey row wants to do is to eat and we use light as a substitute for
eating.
So in robotics terminology, prey row's behavioral goal is to swim up a gradient of light intensity.
The light is really a metaphor for food here.
One prey row is tested at a time in the tank and while it is trying to eat, tatiator, which
I don't have here for you, is on the loose and tatiator is single-minded.
All tatiator wants to do is eat the prey row.
So it heads towards prey row and prey row is its food, right?
And so in the video clip that I'm showing you, you can see that initially tatiator misses
prey row on the first pass and has to circle around.
It chases up from behind and comes and gets prey row, knocks it from its blind spot.
Prey row senses the tatiator too late and gets nailed.
I should tell you that prey row can detect the tatiator using IR proximity detectors
and the tatiator can sense the prey row based on that IR signal.
So we ran each individual multiple times and came up with a score of how well the genotypes
were doing.
This is kind of like evolutionary Olympics.
So in fact, what we were doing here, as I mentioned, is taking the top three prey rows
in each generation and sort of awarding a bronze, silver, and gold medal winners.
And those individuals could then pass their genes on to the next generation.
And we were coding in their genes how many vertebrae that they had.
Now one really important thing to emphasize here, when we evolve robots, we don't know
how events will turn out.
We have a guess, like more vertebrae will make for better feeding and fleeing, but we
aren't sure.
That's where that intermediate that came out here is so important.
We didn't know it was going to be an intermediate number of vertebrae.
We have to let evolution run the course.
What determines the outcome are random factors, like genetic mutations that make sure that
individuals are different and selection, in this case, from the predator.
So when we talk about evolution being an automatic design process, this is what we mean.
Humans don't predetermine the outcome.
But humans do play a role.
For our population of prey row, they depend on us humans to conduct a mating algorithm
on the computer.
In addition to that mating algorithm, we also use a genetic algorithm to add in small amounts
of mutation to the reproductive cycle.
When we produce the genomes for the next generation, those are actually plans for us to construct
by hand the offspring of those parents.
This brings up reproduction.
Can robots reproduce on their own?
Well, the idea of self-replicating machines has been a serious scholarly topic at least
since mathematician John von Neumann introduced the thought experiment of a self-reproducing
automaton in 1948.
Much more recently, NASA has funded research proposals into how robots might replicate themselves
since this could be a very efficient way to begin mining or other large-scale operations
on other planets.
A partial proof of concept came from Hodlipsen at Cornell University.
His team created a modular robot built of cubes that could replicate itself if given
other cubes.
Each module, called a mollicube, is its own autonomous robot, and they link with other
mollicubes via reversible magnetic interfaces.
Each mollicube has the plans for replication, and most importantly, each cube has an actuator
that allows it to rotate its faces about a single revolute axis.
This allows the cube to grab another cube and then rotate itself to lift that new cube
to a position above it.
In essence, a cube can stack itself.
Isn't that a crazy idea?
So with a column of multiple mollicubes, the modular robot can bend over then and construct
itself, replicate.
Mollicubes are available now commercially from Festo Corporation as an educational robotic
system.
A completely different approach has been taken by Professor Mark Kim, who runs the Modular
Robotics Lab at the University of Pennsylvania.
He and his colleagues have created and built Foombot, which is able to build other robots
of various designs.
The key here is that Foombot lives up to its name and actually sprays foam onto actuators.
That foam hardens, and then the new Foombot, which can be of any shape you might spray,
can pick itself up and walk away.
So the key to the Foombot idea is that there is one robot whose job it is to reproduce,
to make other robots.
Both mollicubes and Foombot show us that the idea of reproducing robots is feasible.
For robot reproduction to work, what we still need is the robot, or the group of specialized
robots, to be able to harvest energy in raw materials, use what they harvest to create
finished materials and components, and finally to assemble themselves.
Throughout this course, we've been paying close attention to the bodies and behaviors
of biologically inspired robots.
What we've seen in this lecture goes beyond body shapes, movement patterns, or sensory
processing.
It turns out that even core features of life are beginning to become possible for robots.
Robots can eat, obtaining and harvesting energy on their own.
This is metabolism.
Robots can build themselves.
This is growth.
Robots can evolve.
And finally, robots can replicate themselves and build other robots.
Sure as heck sounds like life to me, doesn't it?
