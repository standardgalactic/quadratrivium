Warning. The demonstrations performed in these lectures can be dangerous. Any attempt to
perform these demonstrations on your own is undertaken at your own risk.
Your lecture is Dr. John Long. Dr. Long is a professor of biology and a professor of
cognitive science at Vassar College. He received his PhD in zoology from Duke University.
Dr. Long is known internationally for his work in the burgeoning fields of
biorebotics and evolutionary robotics. He is the author of Darwin's Devices,
What Evolving Robots Can Teach Us About the History of Life and the Future of Technology.
Along with his students and collaborators, he also has published more than 50 papers in scientific
and engineering journals. Dr. Long and his robots have been featured on radio and television
news programs and in science documentaries, including Through the Wormhole with Morgan Freeman.
Robots. It's thrilling just to say the word robots. We've been dreaming about robots for almost as
long as we've had words to describe the idea of a mechanical human, an artificial animal,
an automaton, a machine that operates on its own to do the work we need it to do,
and the dream is now a reality. The planet Mars has robots exploring the surface on our behalf.
NASA's Curiosity, also known as the Mars Science Laboratory, took this robotic self-portrait
using its long arm holding a camera out at the end. This gives me goosebumps every time I see it.
Curiosity is 140 million miles away. Curiosity's job is to do work that we wish we could do ourselves,
explore Mars. With a generator powered by non-explosive plutonium-238, Curiosity uses its
camera plus lasers and abraders for pulverizing rocks, a grabber for taking samples, and it even
has a miniature onboard laboratory for analyzing samples. Curiosity is an explorer and a scientist
and if any signs of life are found on another planet, that discovery may come from a robot.
In our oceans, we also have robots at work. Those robots search for lost airliners, fix
leaking oil pipes, and discover long-lost shipwrecks. Just like our explorers on other planets,
underwater robots work in dangerous conditions for periods of time that humans cannot. For decades,
tens of thousands of robots have been added every year to manufacturing plants.
Multi-jointed manipulators move heavy car doors into place for assembly.
Robotic arms weld parts together, robotic sprayers paint the body,
and increasingly complicated teams of robots even assemble cars.
And robots are no longer working in just caged off areas. They now work side by side with humans.
And we call this field collaborative robotics.
In order for humans and robots to collaborate, we have to think safety first. No robot illustrates
this better than Baxter. Baxter is a collaborative robot built by Rethink Robotics. Let me introduce
you. Baxter, home audience, home audience, Baxter. And Baxter is built with two manipulators,
each of these arms. What we would naturally call arms, and the great thing about arms,
like the cuckoo robot, too, is that they reach, grab, and then move objects in the world.
If you pardon the pun, this is a pretty handy ability. The problem with arms is that moving them,
just like in humans, flailing your limbs around, you can strike the unintended in with harmful
consequences. Spaz attack, right? Be careful. So the classic way to avoid robots accidentally
hurting a human is to have them working in a separate space. No humans allowed, a safety zone.
But particularly as manufacturing becomes more nimble, smaller scale, or faster in turnover
rates, we really need to work alongside of our robots. We need to collaborate in time and in
space. And here's what makes Baxter special. First of all, you can program it by touching it.
Right? I just grab its arm and I tell it what I want it to do. I'm pretending there's stuff here
that I want it to do. Baxter will memorize all these motions and then when I ask it to do it again,
it'll do it. It's as simple as that. There's no coding on a program that I have to do to get
Baxter to work. Here's the other great thing. Once Baxter is moving, it's safe for me to be
around Baxter. Let me show you this in action. What I've programmed Baxter to do here is simply
pick up a blue block with one manipulator, move it to the middle of the table, and pick up the
blue block with the other manipulator. Okay? I'm hanging around. I'm not worried big industrial
robot. No big deal. Now, when the right arm returns the block here to the middle of the table and
the left arm picks it up, what I'm going to do just to let you know so you're not too worried
is I'm going to grab the arm. I stop it when it's moving back. And guess what? It says,
oh, I'll stop. See? Okay, but then when I'm not holding on, it can sense what I did and actually
go on and complete its task. I'm not hurt. There's no pain. Baxter, I think, doesn't feel any pain.
I know Baxter doesn't feel any pain. And Baxter's compliant joints are what gives this whole process
suppleness and makes it very safe. So in fact, Baxter is compliant and I can move in and out of the
way. Baxter is a perfect companion in the world of manufacturing. Other robots can drive themselves.
30% of curiosities driving on Mars during its first 18 months was self-controlled.
Using stereo vision from two cameras, Curiosity created a driveability map,
which is an estimate of the danger of the path ahead. And by navigating on its own,
Curiosity can cover more terrain than it would be possible if it had to rely entirely
on remote control by humans. Now, back here on planet Earth, we have driverless cars getting
licensed to carry passengers on ordinary roads. They navigate and drive themselves and the whole
car is the robot. Now, you won't find a humanoid at the wheel even if you see human passengers
inside. There are sensors on top, helping the robot navigate, and a computer on board makes
decisions about which way to steer, how fast to go, and how wide to go when passing another vehicle.
Robots are literally at home with us. Robots like Cuscovarnas Lawn Mowing Robot can guide
itself to cut your lawn. And there are robots available to wash windows, the wind bot, by Ecovax.
Robots also clean our floors and millions of homes have iRobots Roomba or other robot
vacuums on the job. Now, I want to show you Roomba just so you can get used to this character here.
It's a 500 series Roomba and I want to show you how it works. So normally we put it on the floor,
but we wind it up here on the table so it's easy to see what's doing and it does this glorious thing
which is to clean floors. It also does a wonderful thing of not going off the table top.
So I have to keep it here from hitting the motors, but it's got cliff sensors
so it can actually detect when it's about to go off the table. So it does a wonderful
job cleaning my lab bench here too. It's got a bump sensor as you see here. It's got an IR
sensor as well. It can detect when it's approaching objects. It's really quite a wonderful piece of
embodied intelligence. Now Roomba has instructions written in software
that runs on its onboard computer that tells it what to do. So I'm going to just put Roomba over
here on the floor where it belongs. It's got a charging station so we'll let Roomba take a nice
drink of electrical energy. So Roomba's job obviously is to search for dirt and clean floors
and because of its size it's able to go underneath furniture. Now one of the cool things about Roomba
is that it's a robot and it's sold as a robot. Yet a lot of us who have Roombas in our own lives
don't think of them as robots. Somehow they become companions. Come here my little Camembert I love
you. That's kind of cheesy I know, but come to Papa where you going. We really identify with our
robots. So in addition to the software and computer that make this possible Roomba is built with a
variety of sensors and actuators as you saw. So you all know what sensors are things like a bump
sensor that you saw on the front of Roomba. But I haven't talked about actuators yet actuators create
movement. So those actuators move Roomba around the motors and the wheels attached to them and
actuators are the rotating brushes underneath as well. Now robots perform other work in extreme
environments for example search and rescue after disaster strikes. Robot snakes can crawl through
tight spaces carrying cameras and sensors to show topside humans what's inside and to search for
survivors. Robots were our first eyes in the Fukushima nuclear plant after disaster struck.
The iRobot Packbot brought in a live video feed and took temperature and radiation measurements
and those smaller tracks on the front of the robot can rotate 360 degrees and make it possible for
the Packbot to climb up flights of stairs. Robots are also in hospitals helping medical personnel
treat patients more collaboration. Teamwork between surgeons and the robotic assistants
like Da Vinci's surgical robot allows surgeons to perform mentally invasive surgery.
Thanks to this robot it's almost like the surgeon can miniaturize himself or herself and get inside
the patient. In RoboSpeak the surgeon becomes telepresent inside the patient. Let's take a look
at a different kind of robot called Sparky. Sparky is built by ArcBotics here which is an
educational robotics company. One of the cool things about Sparky is that it has manipulators on it
and that's these little fingers up front with which you can actually grasp stuff here. You can
stop there Sparky like so and just like Baxter had those kind of fingers as well. Now Baxter and
Da Vinci robots are all about the arms and the fingers. Those are stationary robots so their
body remains still while their arms and fingers do the walking so to speak. Robots like Roomba and
the driverless cars are all about moving themselves around and those are mobile robots.
Now Sparky has wheels and manipulators here too so it looks like this robot is set up to do both
kinds of things so both are present but Sparky is obviously not a dedicated manipulator. Some
jobs like roaming around the table here and not falling off have nothing to do with manipulation
at all so let's think about Sparky sent on a mission thinking about disaster mission. So I
need to get a disaster cup here. Bear with me for a second. So I'm going to remote control Sparky
and Sparky is going to move forward and this is what it's going to do. Its job is to collect
this radioactive coffee cup. All right so here we go Sparky move forward hold on let's see if your
graspers will do the job. Can you collect the cup? It's going to be close can you hold on.
Now got to back up get the cup radioactive cup out of harm's way. Tada we've backed out of the
radioactive hole here with Sparky. Now what we see here with Sparky and with its manipulators is the
ability to bring together two of these basic features of robots that ability to grab stuff
and the ability to move itself around. Robots like Sparky are also taking education by storm
thanks to efforts from companies like Arcobotics, Arduino, Lego, RoboMatter and Vex Robotics.
Robotics clubs and competitions are everywhere at all ages from elementary schools to colleges to
million dollar challenge events attracting some of the best companies in the world. The DARPA Robotics
challenges of 2013 through 2015 used an international competition to drive work on humanoid robotics
to new heights demanding that robots be able to walk stairs work doorknobs and use tools engineered
for humans and human hands. Now while it's clear that robots are finally here and here to stay it
also seems like they've been a long time coming. After World War II ended in 1945 the technological
advances brought by that conflict had everyone looking for peaceful uses for weapons. Science
fiction took off as a new way to think about a new future to prototype a future. Isaac Asimov
led the charge coning the word robotics in 1941 and in 1942 publishing a short story called
Runaround where he introduced his now famous three laws of robotics which I can summarize
quickly as follows. First, don't injure humans. Second, obey humans whenever that command doesn't
injure humans. And three, protect yourself the robot as long as you obey and don't injure humans.
Science fiction helped us dream a world of fantastic robots. Robbie the Robot starred in the 1956 film
Forbidden Planet. As a good robot he was helping humans and of course Robbie the real Robbie was
a metal suit worn by a human. We didn't have real capable humanoid robots in 1956. Now why not? Where's
my flying car? Flying cars, personal helicopters and trips to the moon were all being promised.
In 1956 a group of computer scientists met to discuss how to make machines that were humanly
intelligent. Nine years later fueled by the advent of electronic computers future Nobel prize winner
Herbert Simon optimistically predicted that quote machines will be capable within 20 years
of doing any work a man can do end quote. The pursuit of this goal created the field that we now
know as artificial intelligence or AI. That was 1965 and here we are half a century later and what
Simon says was wrong at least in terms of delivery date for the promise. It's tempting to ask hey
buddy where's my flying car? But while personal aviation may have stalled around 1980 at least
in terms of the number of private pilots in the U.S. robots have been a very different story.
We really do now have humanoid robots like Honda's Asimo. It's only really in the 21st century that
we've seen case after case of robots working not just in the lab but also as reliable commercial
products like Roomba or like Baxter. We even have robot aircraft called drones which are used by
militaries of many countries and as fast as permits are issued by everyone from delivery
services to Hollywood movie makers. But why is this process of creating intelligent machines
taken so much longer than 20 years that Simon predicted? Well truth be told we shouldn't
be too hard on Simon. The gestation period for the working technology of robots has actually
been much longer than the memory of anyone living today. Mechanical figures we call automata
have been around since the Middle Ages in Europe and were known in China and ancient Greece before
that. And the first serious design for a human humanoid robot comes from Leonardo da Vinci working
in the late 1400s and early 1500s. Leonardo never had a chance to build this humanoid but from his
notebooks we can tell that Leonardo's robot had an exoskeleton of armor inside there were pulleys,
gears and cables that were connected to move hands, wrists, elbows and shoulders. Now these actuators
might have been able to connect with a mechanical cart making it possible to reprogram the figure.
Why the delay? What's missing from Leonardo's humanoid that we see in today's autonomous robots?
There are really three missing ingredients and let's talk about them. Key ingredient number one
Leonardo did not have electric sensors. Now Sparky actually has three light sensors
up front called phototransistors which you can see here, little t things here, here and here.
And it lets Sparky measure the intensity of light and the direction of light. Now Sparky also has
an IR proximity detector that sends out electromagnetic beam of radiation right here
and it receives it right back in here. Now ultrasonic ping sensors which Sparky has right here also
work in the same way but they use sound instead of light and here is a ping sensor right here,
isolated and not on a robot. Other isolated sensors that I've got here include a camera that goes on
robots. This is a line detection sensor and here is an IR emitter and detector.
ASMO actually has four sensors in its feet which help it keep its balance. Alright let's talk about
missing ingredient number two. Leonardo didn't have electric motors. Electric motors don't show up
in the world of engineering until the early 19th century. So I've got an electric motor right here
which is a DC motor and I'm going to electrify it so you can see it spin.
So that's a DC motor and it travels very fast. Now this is small and powerful for its size and it
can operate without getting tired, can be made small enough to pack many of them into a humanoid
frame. Can you imagine Leonardo? My kingdom for an electric motor. Moreover many robots benefit
from particular family of electric motors called servo motors right here. I'm going to get this one
started and a servo motor which you're going to see start just flapping around here actually has
a sensor in it and so a servo motor knows exactly where it is and with feedback from that sensor
it can make repeated and controlled motions. You can say with a servo motor flex your elbow joint
20 degrees then the servo keeps trying to do that flexing until it achieves it and knows when
it's hit that target because of the sensors that are on board. Let me unplug that here. Now instead
of the robot just doing whatever it's doing over and over again right or wrong, sensors tell the robot
how to adjust what it's doing, how to act and react. So here's key ingredient three that was
missing for Leonardo. He didn't have digital electronic computers and this brings us back
full circle to the origins of artificial intelligence after world war two. The computer
scientists were of course excited about these electronic computing devices like the famous
colossus that helped crack the Germans code during the war. Now what makes digital electronic
computers so darned useful are the logic switches that encode information in digital yes no bits.
Information about the world from your sensors can be used inside the computer to flip logic
switches, store information and make calculations. Those logic switches can be miniaturized. The more
switches per square millimeter, the more powerful is your computer. That's the hardware side. Now
let's see an example of what that hardware looks like. Go back to the servo motor here and this is a
piece of hardware called a computer. It's an Arduino microcontroller. Now it takes inputs
as sensor readings and outputs as you see here to motors. Let's look at an Arduino based controller
working in a robot. We're going to introduce you to Hexie by ArcBotics. Hexie is a robot that has
six legs. I'm going to plug in Hexie's battery here, get it powered up, move these things off
this mat here so Hexie can perform for us. I'm controlling Hexie initially with a computer
program here that I have to call up and it's made available by ArcBotics to run all these servo
motors in here. Okay, so we've got this plugged in. Hexie's starting to get powered up. Now Hexie
has ping sensors up here and we can take a look at the legs here. Each of the joints in the leg
has an individual servo motor. Okay, so that's what the hardware looks like. We've got all these
motors. We've got sensors here. And let me just show you what Hexie can do. Hexie, get us.
Excellent. Very good. So Hexie is standing up for us, which is really terrific. And now,
just to show you, once Hexie is up, we'll have Hexie do a little dance. Hexie, let's see you dance.
Cool. Hexie doing a little groove there. Now we've been talking about all this hardware and that's
very cool stuff, but anatomy isn't the whole picture. With this hardware comes software. And on the
software side, both in here and in here, which I haven't told you about, we have the ability to
program these motions to tell Hexie what to do by a series of step-by-step instructions.
Any set of instructions that can be run on a computer are known as an algorithm. And inside
any program, we find many sub-programs called routines and functions and library calls that are,
in fact, themselves algorithms. It's algorithms all the way down. And there are hundreds or
thousands operating to allow Hexie to stand up here and do the dance that you saw. Now,
the really cool thing about algorithms is that once you figure out the basic set of instructions
with a little adjustment to the particular computer on board and the software it runs,
you can use that algorithm on different robots. This ability to create and reuse algorithms
is incredibly important in robotics. You can think of an algorithm as a universal behavior module
that can be easily adjusted to work in almost any robot. So it doesn't matter what that particular
robot is. If it has a computer, then you can program in your algorithm, for example, seeking light.
And your algorithm for moving forward. And an algorithm for following a wall.
Since a bunch of algorithms may coexist in a single program, you can see how quickly we
can create robots with complex behavior. Robots able to perform tricky tasks like
Roomba cleaning a floor. So let's go over this. Electric motors plus electric sensors plus
electronic computers equals robotic complexity that we don't see in purely mechanical machines.
Now, in contrast, let me show you a nearly mechanical machine, a robot called TootBot.
I'm going to move Hexy out of the way. Let you see TootBot here.
Okay. And one of the cool things about TootBot is it has the ability to do one kind of function.
And I'll show you in just a second. What I want to point out, though, is there's no embedded
computer. There's no Arduino microcontroller. It has some electronics. So strictly speaking,
it's not a purely mechanical machine, but it's not an electronic computer. And an
electronic computer, you can reprogram. You can't hear. TootBot is all hardware. So to reprogram it,
you'd actually have to change out these electronic components and rearrange them,
readjust them, rewire them. All right. So let me show you TootBot in action. When you hit its
bump sensor, it backs up, turns, backs up, turns, and eventually doing this, it can work its way
around an object. You can see it's going to go around until it works its way free of an object.
So that's like the escape behavior that we saw in Roomba when I hit the front bumper.
Now, here's the deal. The great virtue of a digital electronic computer is that the
algorithms we put into the computer, we can reprogram quite easily. Now, those algorithms
take the place of these hardware circuits, which have to be rebuilt. That's why we get excited
about putting computers into robots. And this kind of potential to make machines more intelligent
is what Simon and other computer scientists got so excited about. And rightfully so,
but what caused Simon's timing to be over optimistic is that we knew less about humans
and human level intelligence than we thought. So the moment we started, for example, to try to
create machines that could see a field that we now call computer vision, that was the moment
that we realized that identifying an object in a visual field was extremely complicated.
What makes a chair a chair? Trivial for us, but not for a computer or a robot.
The robot named Shaky, a mobile robot from the late 1960s, was the first to have and use
object identification to move around a room. It was in Shaky that everything came together,
electric motors, electric sensors, and electronic computers. Shaky was a mobile robot that could
sense its world, reason about the state of the world and its place in the world, make plans
about how to move in the world, and then enact those plans. Shaky had a computer, sonar range
finders, video camera, and bump detectors. Shaky was built to navigate an internal space,
much like a simplified office building, was given a map of that space that included objects
like walls and blocks. And given the presence of walls and objects, Shaky calculated a path to
its destination and moved forward and around objects. Shaky was covered by the New York Times in 1968
and in 1970, Life Magazine called it the first electronic person. And here's what's fantastic
about Shaky. It was a robot that had intelligence as seen through its behavior. It used a map to
plan its movements. If objects moved, it could use sensors to update its map of the world.
It had goals and figured out ways to achieve those goals. Shaky's intelligent behavior
set the standard for modern mobile robots, and nearly every mobile robot today owes something
to Shaky. In addition to mobile robots like Shaky, the other great class of robots are called
stationary robots, and we also call them robotic manipulators. While manipulators like Baxter
don't move around to get their work done, they like to move their arms,
like this, to get their work done. Now robotic manipulators are usually planted on the ground,
and instead of moving their whole body, they move an appendage or two in the case of Baxter.
Now what adds complexity to a manipulator is the number of joints that it has. If each joint has
a single axis of rotation, like a hinge on the door, like this, that's a single axis of rotation,
or translation, like the fingers on Baxter right here, then we can talk about each point of rotation
or translation as a single degree of freedom. As we add joints, we add degrees of freedom,
and here's the punchline, we add complexity. So we increase the ability of the robotic
manipulator to manipulate the world as we make its body more complex. Now some robots can manipulate
and move. Curiosity, who's up on Mars, has a huge arm with five degrees of freedom,
camera, scrapers, and shovels. That arm is really a beautiful manipulator attached to a
mobile robot. Very cool. But there's more than one way to put a manipulator on a mobile robot,
that is there's more than one type of possible robot body for almost any given task. Now in fiction,
robots most often have bodies like humans. Humanoids are mobile and they have manipulators,
right? Now, I wish to goodness I could do the robot dance thing for, I can do that for you right now,
but I can't. In fact, the word robot itself was first used by the Czech playwright,
Carol Chappek, in a play where the robots were three very human looking figures.
They were grown out of organic material, according to the story, and were created to
perform specific tasks, working in the factory or working in the office. The play was called
RUR, which stands for Rossum's Universal Robots. It was published in 1920 and first
produced in English in New York in 1922. Now the play was very popular and it set off a
firestorm of interest in building robots and telling stories about robots. In the Czech language,
the word robata, which was around before the play, referred to forced labor done by humans.
The robots in RUR are humanoids. They look like humans with head, arms, legs, and bipedal locomotion.
But, and this was a huge discovery, sort of a secret, and I want to reveal it to you right
here in this first lecture. Robots do not have to be built to resemble humans,
and yet they can still take advantage of biology. Robots can be inspired by bodies of other animals.
The robot Big Dog, built by Boston Dynamics, is an example. It's a famous biomorph. It's a
non-humanoid and it's been modified to help combat troops transport huge loads of equipment over rough
terrain. And as the name says, it's built like a dog, with four legs that have the basic anatomy
of a dog leg. Now by contrast, robots with no biological inspiration can be called
mechanoids, a category that would include such wheeled vehicles as Sparky Here, Shaky, and the
Mars Rovers. One of my favorite mechanoids is based on that groovy human invention,
the surfboard. The surfboard is called Wave Glider, and it's built by Liquid Robotics. It
holds the record for the longest distance moved by a robot across the Earth's surface, 9,000 nautical
miles. Like a surfboard, it moves by harvesting energy from waves, but unlike a surfboard,
it gets that energy by dangling an underwater array. And while the upper float moves up and
down on the surface waves, the submerged array gets tugged, but it's angled like your hand as
you skull in the pool to convert that vertical movement into forward thrust. Still other robotic
devices can be worn by a person, stretched the outside of your body, leading to the expression
wearable robotics. For example, there's a walk assist device that can help people with muscle
weakness from disease. These devices were spin-offs from technology developed by Honda to build the
humanoid, Asimo. And it's a robot in the sense that it has sensors, a computer, and motors.
Some people like to call these wearable robots exoskeletons. Now, don't we all want an Iron Man
suit? Yes, please. In still other cases, robotics are being implanted in humans in a more permanent
way, like the Deca Arm. The Deca Arm is a neuroprosthetic, a smart one. It uses electrical
signals from a human to tell the robot to grasp, lift, and release. Now, what sets apart robotic
prostheses is that they have onboard intelligence coupled with sensors and motors. So it's a robot.
But beyond the diversity of robots we see, there's an even greater diversity
that we do not see. There's always more than one way to create a given robot, and there are often
lots of choices. In fact, here's another aspect of the huge discovery I alluded to earlier.
Some of the greatest advances in robotics during the past couple of decades
have come from learning to simplify robots, to simplify demands on their computers in particular,
making them much less like a human brain. The Roomba vacuum cleaner moves much faster than
shaky in part because Roomba does not try to figure out its environment before making a move.
It doesn't have an internal model of the world. Instead, Roomba gets right to work,
taking its inspiration from animals like insects, figuring out what to do next while already moving.
So Roomba is an example of so-called behavior-based robotics, and shaky is an example of model-based
robotics. These terms refer to different strategies that we take in the software that runs on the
controller, and they are not mutually exclusive strategies. Most modern robots, in fact,
have a combination of these two architectures. When we think about an intelligent robot like
Roomba or shaky, what impresses is the idea that it operates on its own. It's a closed loop.
Shaky has servo motors responding to feedback from sensors, operation on its own. We call this,
ready, behavioral autonomy. Compare behavioral autonomy to a robot that is completely remote
controlled with a human sensing the world and then determining the actions of the robot.
In this case, most or all of the intelligence of the robot is located in the human and not in the
robot. Let me go back to Sparky to demonstrate here. So what I'm going to do is, even though I
had to pick up the coffee cup, I was remote controlling. Now Sparky has something else on
board going on. He's actually got some processes that operate automatically. Now if I use my
remote control here, maybe you'll see what's happening. I'm going to tell Sparky to go forward
and he'll call, go forward and then look, he's deciding to turn. Now Sparky, why did you do
that? Let's try that again. And to prove to you that I'm not doing this, we'll get Sparky going,
I'm going to set down the remote controller. See what's happening here? Sparky is not letting me
drive it off the edge of the cliff, if you will. Now you don't know this, but I've actually programmed
into the controller some autonomy with a student in my lab, Peter Staten. So Sparky, following
Asimov's third law here, doesn't want to hurt itself. We call this the safe driver program,
by the way. The robot takes over and doesn't let me, the driver, hurt it. Now if I try to hurt
Sparky, which would be very mean of me of course, I'll be trying to drive it off the countertop.
So what happens is Sparky, because of the program, doesn't let that happen. He just
took control from me in order to preserve itself. I think that's pretty cool. And that's an example
of mixed autonomy, where we combine remote control and autonomy. So that explains to you and shows
to you really what we mean by behavioral autonomy versus remote control. Just to drive this home
one more time, a behaviorally autonomous robot, acting on its own, has its own intelligence.
It doesn't need a human in the control loop. Now of course, autonomy is really cool, and there are
lots of different kinds and degrees of autonomy. We'll spend most of this course figuring out how
autonomous robots work and understanding the science and engineering behind how they are designed and
built. Robots are here. And perhaps even better, the field of robotics offers an endlessly exciting
way of seeing our world. This does not mean people are becoming more robotic, or robots are taking
over from humans. What I mean is this, any machine, any electronics component, any animal, anything that
humans do, almost everything around you has potential implication for robotics. And that
has implications for you. You know, you can look at the remote control for your TV, look at your
smartphone, and start thinking about what else those buttons might be used to program or control.
And when you do, think about computer programs as ways to give more autonomy to a robot. Robotics
is a field where many disciplines come together, so the sources of potential inspiration are endless.
To infinity, to autonomy, and beyond.
