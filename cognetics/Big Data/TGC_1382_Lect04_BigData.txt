We organize information into patterns all the time.
For example, look at this.
What do you see?
It's a face, of course, but notice how different this is to a real face.
This is very, very abstract.
We only have three circles and a line segment, yet we can make the connection.
Here are other images by mathematical artist Robert Bosch of Oberlin College.
Recognize the person?
Well, it's a good resemblance.
It is made entirely of one continuous line.
Here is a close-up of Maryland's left eye.
What about this?
Recognize that smile?
That's made out of dominoes.
They are laid down and then an image is created.
Here is an image made from M&M's from my book, Math Bites.
Here we use fewer and fewer candies, making the image more and more abstract.
Each time our mind has a way of organizing the data.
This type of thinking is ever present in us, in a part of how we think.
In fact, we can also make up patterns, seeing things that are not there.
For example, when we look at clouds or ink blocks or other random shapes, psychologists
sometimes call this peridolia, our ability to turn a vague visual image into an image
that we find meaningful.
We do this with what we see, and we also do this in how we think about cause and effect.
All athletes, for example, often look for patterns, patterns of behavior that lead to
success.
They are under constant pressure to perform at a high level, so if a player finds something
that meets success, they repeat it.
Maybe it helps, maybe not, but this can be taken to an extreme.
Consider these examples.
In baseball, Kevin Romberg played just 41 games for the Cleveland Indians from 1982 to
1984.
That's all it took for him to become one of the big leagues' most superstitious players
ever.
For instance, he refused to make right turns on the field.
Why?
Base running involves turning left, and only turning left.
He was a good hitter, and his percentage of times getting on base was impressively high.
Okay, but Romberg also tried to follow his left turn rule, even when playing defense.
There might be a case where any other player would turn right on the field.
Romberg?
Yeah, he made a full circle turning left, of course.
In football, American style, Jacksonville Jaguar defensive tackle, John Henderson, expects
the team assistant trainer to slap him open handed across the face as hard as the trainer
possibly can.
This strategy seems to have worked.
Henderson made the Pro Bowl multiple times since the trainer started slapping him around.
In basketball, even Michael Jordan, who led the Chicago Bulls to six NBA championships,
had his rituals.
The five-time MVP wore his University of North Carolina shorts under his uniform in every
game.
Every game.
Jordan led UNC to the NCAA championships in 1982.
Really good outcome, so he kept wearing that lucky pair.
These players see a correlation between their success and some activity, so they repeat it.
We all look for connections.
We all look for correlations.
When is a pattern real and when is it merely spurious or imagined?
Here are a few quick ones to consider.
According to Osco Drug, if you buy diapers, you're more likely to buy beer.
Why might that be true?
Do you find yourself thinking of possible reasons?
Here's another research result.
Research from an airline found that vegetarians miss fewer flights.
Are vegetarians more reliable or does pre-ordering a meal signal or even cause someone who is
more committed to making a particular flight?
Here's a third one.
Increased ice cream sales correspond to increased shark attacks.
Well, correlation picks up that two things have a certain pattern of happening together.
More ice cream sales and more shark attacks.
But there is a well-known saying in statistics, correlation does not mean causation.
It could be that the connection is simply a random association in your data.
But if there is a connection, many other things may cause that connection.
The two factors may themselves not be particularly connected, but instead be connected to another
factor.
For example, maybe weather is warmer in a particular area at the time when sharks tend
to migrate to that area.
Maybe the warmer weather causes an increase in the presence of sharks and an increase
in people eating ice cream.
It isn't that people taste better to sharks or that people consume more ice cream when
they're worried about increased shark attacks.
Ice cream consumption in shark attacks just happen to be correlated.
But one does not cause the other.
Okay, let's try another example.
A published medical study reported that women who receive hormone replacement therapy were
less likely to have coronary heart disease.
Again, there's a correlation.
But questions remain.
What set of people were sampled?
How many?
Can the results be replicated?
Turns out the answer is no.
Later, a controlled experiment was run with better scientific controls.
Who was receiving the therapy and who was not?
Turns out that more affluent women had access to the hormones.
That same female population had better health habits and better access to all kinds of healthcare,
which was probably a much better indicator of less heart disease.
Much research results can have worldwide effects, seemingly positive at first, but actually
quite harmful.
In 2003, it was reported that two popular high blood pressure drugs were found to be
much better in combination than either alone.
Prescription habits changed around the world.
But then, six and a half years later, a prestigious medical journal retracted the paper due to
quote serious concerns, unquote.
By then, over 100,000 patients had been prescribed the drug combination.
What effect did the combination have?
It left patients more vulnerable to potentially life-threatening side effects.
To make matters worse, news of a big result could quickly spread, but if found wrong,
the impact of such news can be difficult to reverse.
This is most important as the Wall Street Journal reported in 2011 that retractions of
scientific studies were surging.
They found that since 2001, the number of papers published in research journals rose
44 percent, but retractions, they left more than 15 fold.
There were 22 retractions in 2001, 2006, 139, 2010, 339.
Again, this can put patients at risk.
Millions of dollars in private and government funding can go to waste.
Now, some research is retracted due to researchers on ethically fabricating results or for plagiarism.
But in other cases, people find connections that do not offer the level of insight touted.
And the increasingly powerful tools of data analysis and data visualization now make it
easier than ever to over-present the results of a study.
It is very important to keep in mind that our tendency to essentially over-explain and
over-predict what we find is ever present in us.
Indeed, scientists are finding this to be hardwired into the human brain.
Psychologists have long known that if rats and pigeons knew what their NASDAQ is, they
might be better investors than most humans are.
How?
In many ways, animals are better predictors than people when random events are involved.
People keep looking for higher-order patterns and thinking they see one.
Here's the sort of experiment that has been done.
Set up two lights and flash them in a random sequence.
People tend to try and predict which of the two lights will flash next.
It's random.
Randomness means you can't predict it.
But we keep trying.
In fact, you can even tell a person that the flashing lights are random.
But they still look for a pattern to predict the next flash.
Indeed, looking for patterns is something we keep doing and doing and doing, even if
they aren't there.
Even if somehow we know they aren't there.
Returning to our table of lights.
We want a random sequence.
So we roll a die.
Roll a one, flash the red light.
Any other number, flash the green light.
A series of flashes could be GGG-RGG or GGG-GGG or GGG-RRG.
Looking for a pattern?
There is one, 83% of the time green will flash.
But that doesn't mean, just as we saw, that every one out of six times it will flash red.
So what will flash next?
You don't know exactly.
You only know it's more likely to be green.
Rats and pigeons generally notice which color appears most.
The best strategy is to pick green.
And they do.
In 83% of the time, they get a reward of food.
What about humans?
Well, somehow we try to actually predict the next result.
In one experiment, scientists did this, but rather than rolling a die and flashing the
green light 83% of the time, they still had things randomized, but flashing the green
light 80% of the time.
So how did people do?
They got the right answer only 68% of the time.
We can think of this like a sport.
The rats and pigeons score 80% of the time and people score 68% of the time.
In the NBA, teams often have about 100 possessions in a game.
If this were basketball with these percentages, the rats and pigeons would win 80 to 68.
That's a pretty big win.
Indeed, attempts to use our higher intelligence leads people to lower scores than rats and
pigeons on this type of task.
Do you feel okay since you aren't going to be sitting at a desk across from someone
in a lab coat asking you to predict when red and green lights will flash?
But remember, financial markets are almost as random as those flashing lights.
Granted, it's only almost as random, but that can hurt us too.
We can yet again look too hard for patterns in the randomness.
A couple of accurate predictions on the market and an analyst can seem like an expert.
But how will the person do over the long run?
Again, we have a tendency to overlook randomness.
If I told you that I just flipped a fair coin and got heads 13 times in a row, what do you
think I would flip next?
To some part of you think it's more likely to be tails.
This type of thinking is common enough it has a name, the gambler's fallacy.
It's what can keep us at the tables in Las Vegas or pulling the slot machine levers.
But there could be a lot at stake in such thinking.
Interestingly, people don't always pick the option with the highest probability of success
over time.
Remember our pigeons?
They do.
Humans will move into that type of thinking when the outcomes really matter and the stakes
are high.
This can play into financial decisions.
If we are determined there is a pattern where there isn't one, we could be making the wrong
decision.
In such a way, we could actually make our worst financial decisions on small amounts
of money.
But before long, that can equate to a larger decision.
So one way to look at that type of thing is to convince yourself there is no small or
casual investment when it comes to finance.
But be careful thinking that there aren't patterns.
There are.
And if we find them, the consequence can be huge.
Having discussed a lot of cases where our pattern seeking goes wrong, let's see one
where a suspected pattern was refined and refined to give us genuine insight.
When you get sick, you may want to know what the symptoms indicate or what to do to feel
better.
Where do you go?
Maybe eventually to the doctor, but before that, a pretty quick reference is a search
engine.
Sick?
Search Google for more information.
This can give you more information about the flu and if there seems to be an outbreak
in your area.
In fact, the Centers for Disease Control and Prevention request that doctors inform them
of new flu cases.
In time, they'd see a pandemic emerging, but by then the news was outdated by a week
or two.
There was the delay in simply relaying the information and then the CDC had to crunch
the numbers and share the news if something was found.
Two weeks of flu is breaking out is a long, long time.
In fact, epidemics or seasonal influenza can cause a quarter of a million to half a million
deaths per year.
Early detection and response in this area is of great interest.
The next time you get the flu and turn to Google, you are helping detect flu.
How?
You've found that the relative frequency of certain queries is highly correlated with
the level of flu activity.
But there's more.
Google knows the region in which you're conducting your search so they can actually utilize search
queries to detect influenza epidemics in areas with a large population of web searchers.
With three billion searches a day, Google had a lot of data.
A lot.
So Google took the 50 million most common search engine terms that Americans type.
Then they looked at CDC data on the spread of influenza between 2003 and 2008.
Was there some pattern in what people searched on when flu was spreading?
Note, this had been attempted before.
Google did it.
They had the data, the knowledge of the data analysis to look at it in the right way and
the computing power to crunch through the data.
Let's see what they did.
What would you expect someone to search on?
Well, that's exactly what you need to be careful of in data analysis.
We may not know what pattern to expect and that unexpected pattern might just be the
key to understanding what we're looking for.
Google understood this and so they made a method that didn't know.
It only looked for correlations between frequencies and search queries and the spread of flu over
time and space.
They processed 450 million math models.
Take a moment and process the size of that number.
It underscores the processing power of this Internet giant.
450 million seconds is just over 14 years.
That's the age of Google itself as of 2012.
They evaluated the models on their performance predicting actual flu cases in 2007 and 2008.
Data that was excluded from all prior steps.
Among the millions of models, they had a breakthrough.
A combination of 45 search terms led to a strong predictive ability for the actual cases.
Like the CDC, they could pinpoint where flu was breaking out.
But Google could do it right now without any lag time.
This was published in Nature magazine in 2009 and then the H1N1 crisis hit and Google ended
up being more accurate than the CDC and so much faster.
Armed with their model and their combination of search terms, they could begin to see a
pattern before some search engine users walked into a doctor's office or got the results
of a mouth swab.
Google has since offered the tool online, which has been extended to more than two dozen
other countries.
It is called Google Flu Trends.
It will give you an estimate of current outbreak levels in the U.S.
It will break things down state to state or even try for specific cities.
You can also look at the trends over time.
It works well, but it's not invulnerable.
When a New York Times story disclosed one of the search terms used in the algorithm,
casual searches on that term spiked.
More serious, during the 2012-2013 flu season, Google Flu Trends sharply overestimated the
amount of flu, warning that nearly 11% of the population were infected.
When follow-up information from the CDC found no more than 6% had gotten the flu.
What went wrong?
Media reports about flu indicating the state of emergency declared in New York led to more
searches that year by people who weren't sick.
Google had already anticipated how media coverage of the flu could lead to spikes in searches
by healthy people for three to seven days.
But this time, flu season actually was worse than the previous year, and the searches actually
continued at a higher level throughout the season.
More media coverage and more flu meant that even healthy people did a lot more searching
for flu throughout that particular season.
Using all this, Google adjusted their algorithm, first by adjusting for spikes in searches after
media coverage.
They also refined how their linear regression throws out extreme values.
With these changes, their revised algorithm once again gave an accurate estimate of flu,
with 1% of what CDC data reported.
And this is always the potential.
Patterns do exist.
When we find them, we see how powerful they can be.
But the fact that there is correlation doesn't mean the correlation will predict, or will
continue to predict as well as before.
Again, correlation doesn't necessarily mean causation.
For example, a somewhat whimsical note published online by the New England Journal of Medicine
in 2012 reported an apparently strong correlation between chocolate consumption and a number
of Nobel laureates produced by the country.
Countries with higher chocolate consumption produced more Nobel laureates.
Did you start thinking about why this might be true?
The note suggested that chocolate has been shown to improve cognitive function.
And it went on to estimate that a rise of total consumption of 0.4 kilograms per person
per year might even correlate with an increase of one Nobel laureate winner per year.
But the author also playfully suggested considering reverse causality.
Maybe countries with better cognitive function are more likely to pursue the health benefits
of chocolate.
So maybe smart people are more likely to choose chocolate to stay smart.
True or not, we simply have a tendency to think in that way.
It's like it is hardwired into us.
Think about it.
It was to our advantage to see patterns.
The author of that note about chocolate and the Nobel laureates is himself a declared
chocolate lover who was born in Switzerland, the number one country for chocolate consumption
and per capita Nobel prizes.
If you see a bush shake and a tiger jumped out, then it might behoove you to keep that
in mind.
Even if for the next hundred times that shaking is the wind and not a tiger.
That hundredth time, that's an important connection to notice.
There is a correlation.
A tiger could rustle a bush before pouncing.
But remember, that doesn't mean that a bush's rustle is a tiger.
There is a name for this.
Apaphynia is the experience of seeing patterns or connections in random or meaningless data.
The name is attributed to Klaas Konrad and has come to represent our tendency to see
patterns in random information.
But Konrad was actually studying schizophrenia in the late 50s.
He used the term to characterize the onset of delusional thinking in psychosis.
In 2008, Michael Shermer coined the term patternicity, defining it as the tendency to find meaningful
patterns in meaningless noise.
There is another end of the spectrum, of course, and that's called randomania.
That's where events with pattern data are attributed to nothing more than chance probability.
This happens when we overlook patterns, instead saying it was just totally random.
But the most common reason we overlook pattern data is that we already have some other pattern
in our mind, whether a real connection exists or not.
In his book on the origins of stories, Brian Boyd explains why we tell stories and how
our minds are shaped to understand them.
He argues that art is a specifically human adaptation.
Boyd further connects art and storytelling to the evolutionary understanding of human
nature.
For Boyd, art offers tangible advantages for human survival, making pictures and telling
stories has sharpened our social cognition, encouraged cooperation, and fostered creativity.
How can this help us from an evolutionary point of view?
Humans depend not only on physical skills, but even more on mental power.
We dominate that cognitive niche and, as such, skills that enhance it can aid us.
Looking for patterns from that point of view aids us, and when we see patterns, we create
meaning and may even tell the story.
Whatever the case, we do have a tendency to look for patterns, and that can be a real
problem and a real strength in data analysis.
The important part is to realize and recognize that we may unearth a pattern in data analysis.
It may even be surprising, but even if we can offer a possible explanation, that still
doesn't mean we've found something meaningful.
Let's consider a few examples from the website Correlated.org, which is devoted to finding
weird correlations.
44% of people who regularly check horoscopes also floss regularly, and generally only
28% of people floss regularly.
19% of people who can roll their Rs regularly wear cologne or perfume, compared with 31%
of people in general.
75% of people who can't type without looking at the keyboard prefer thin crust pizza to
deep dish, compared to 59% of people in general.
Do you find yourself looking for why these may be connected?
Maybe they are, but again, maybe they're not.
It's in our nature to find the connection, real or not.
And this ability is what lets us take surprising correlations from data analysis and find those
impressive connections.
Beware of just rushing in where angels fear to tread.
Some of those connections are real, and because of that, we will continue to see them.
Stop athletes and investors and researchers will continue to look for patterns to improve
their performance.
What connections do you see?
They may be a pattern, and they may just be your nature hardwired into you to look for
such a pattern.
In data analysis, we look for patterns in data.
As people, we are good at it, but sometimes we are good at finding something that isn't
there.
It's an ever-present balance.
As we look and find correlated data, be careful.
First, look in both directions, and see if you can think of why one might cause the other.
Maybe causality is there, but it goes in the opposite direction from what you expected.
Second, like warm weather explaining shark attacks and ice cream consumption, check to
see whether something else offers a better explanation.
And lastly, always keep in mind that it might just be our hardwired ability that's leading
you to expect something that isn't there.
We all love an interesting pattern, especially if it comes from a plausible story.
The difference in good data analysis is we don't stop there.
Finding a pattern is a great start, but remember, as data analysts, it's just the beginning.
