We stand within a data explosion of sorts.
Organizations talk about drinking from a fire hose of information.
Commentators refer to a data deluge.
But there is no need to drown in data.
In this lecture, we will see how data analysts of many kinds think about their data, the
amount of data, the types of data, what constraints there may be on an analysis, and what data
is not needed.
In this way, we'll see how the deluge can be put to work answering questions we may
have by developing the mindset of a data analyst.
First, as we discussed in the opening lecture, there is a lot of data, and it can be hard
to wrap one's mind around the huge numbers, but it is possible.
As data analysts, this is what we do.
Let's turn to the amount of data being generated on Facebook.
In only 15 minutes, the number of photos uploaded to Facebook is greater than the number of
photos stored in the New York Public Library photo archives.
Again, that's every 15 minutes.
Remember, though, that Facebook archives all this data.
Yet even with so much data being added, you see a picture on your Facebook news feed within
seconds after it's posted.
Yes, it's a lot of data, but with data analysis, it can be managed in a way that's both timely
and useful.
Keep in mind that advances in storage play into this.
Consider 50 gigabytes, which is about the amount of storage on a Blu-ray disk.
This would hold the textual content of just about a quarter of a million books.
Just simply a disk you might have lying around your television.
Storage capacity of a high-end drive from companies like Seagate or Western Digital
can hold five terabytes or more.
A terabyte is 1,000 gigabytes.
With all this data, we begin to see why there began to be a lot of talk about big data.
But without analysis, the data is essentially a lot of 1s and 0s.
If you can't analyze it, it may not be helpful.
