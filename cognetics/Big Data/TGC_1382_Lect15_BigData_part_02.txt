average of 14 percent for the remainder of the year when a team from the original National
Football League, NFL, won the game.
However, when a team from the original American Football League, AFL won, it fell by almost
10 percent.
This economic indicator was correct 28 of 31 times over that 30 year period.
Statistical formulas can pop out the statistical significance of something, and this would
reveal that there is only about a one in almost five million possibility that this relationship
emerged from chance alone.
What an amazing find.
It's striking in its simplicity.
Forget the Super Bowl ads.
Just see who wins to determine whether to buy or sell.
Yes, that's true in 28 of those 31 years, but there isn't such a predictive connection.
The next few Super Bowls showed this.
As we have seen before, it is easy for us to see correlation in think causation.
Again, this variable, while correlated with past data, doesn't mean it will have predictive
value in the future.
However, if you allow this to enter your data analysis, it could end up looking like a highly
predictive variable.
Remember, how we often find patterns where they may not really be.
Well, if we threw such patterns into our model without thinking, the model may mistakenly
tell us it's actually happening.
Let's look at another example of throwing in an unrelated variable.
This one throws a sports variable in with elections and political data.
With so much attention and interest, especially in presidential elections, there is a lot
of curiosity about ways to explain the election through something totally unrelated.
Like what?
Well, how about football again?
Did you ever notice that if the Redskins won their last home game before the election,
the incumbent party would hold the White House?
This has been true in 16 of the past 18 elections.
2012 was an exception.
The Redskins lost to the Carolina Panthers on November 4th, but Barack Obama won the
election for his second term.
So one must be careful.
Too many variables can lead to great results on predicting past data, but poor performance
for future data.
Again, we are overfitting the past, said another way we are trying too hard to predict the
past when our real goal is to predict the future.
In the cases we saw before, we had variables that weren't predictive, but could be seen
