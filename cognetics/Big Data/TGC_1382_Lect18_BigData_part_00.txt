We are approaching a time when every book ever written is available in a digital form
that is both readable and searchable.
Not just one by one, but all at once.
That is, all the books ever written, perhaps 130 million and all, are becoming part of
a vast new data set humanity has never had before.
As if that weren't enough, we are now digitally creating, storing, and analyzing many, many
more words than appear in traditional publications.
People update Facebook statuses, write emails, text, tweet, and comment on articles posted
on the internet.
As we will see, there can be more words posted on Twitter about just one topic than are contained
in the average book.
All these words offer rich data sets to understand and predict phenomena in our world.
The challenge is that all this data is unstructured.
No one has filled out a questionnaire, responded to a carefully crafted poll question.
Have their behavior sorted into box scores or any of the other helpful things that have
made data analysis easier for us to this point?
So in this lecture, we discuss how to watch the words and gain insight from unstructured
data.
These are the realm of sentiment analysis and text mining, what we can call text analytics.
Now these techniques are often different from the sort of textual analysis you might
expect in a literature class.
To see this, let's look at how social media were used to predict the winner of American
Idol.
This was May 2010, in the ninth season, when the final show drew an American audience of
over 23 million.
Who would be the American Idol?
There were some data analysts at a group then called IdolStats.com that sat comfortably
awaiting their predicted winner's name to be called.
And yes, they did get it right, lead to wise one American Idol that year.
In the group at IdolStats.com saw the victory coming far in advance.
Many other people were surprised.
MTV.com reported the outcome with the headline American Idol finale, lead to wise, upsets,
crystal, bower socks.
How did the analysts know?
They didn't have polling data, so waiting polls like Nate Silver wasn't an option.
Instead, the group monitored millions of interactions on social websites.
Those interactions gave them the data they needed for their analysis.
But they didn't simply look for which topics or contestants attracted buzz.
They also looked at what was being said.
Were the comments positive or negative?
How much was being said about each contestant?
Using a variety of tools, the group summarized the buzz and evaluated the chatter from publicly
