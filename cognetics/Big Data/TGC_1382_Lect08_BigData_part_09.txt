One of the worst teams, almost unknown, was ranked first.
Honestly, I'd never seen the method do that poorly.
Trying to recover, I said, well, let's compare this to the method that's usually, that we
usually use, that does well.
I put in those parameters.
Again, that same weak team was at the top.
This analysis was garbage, but more importantly, in front of this audience, I didn't know why.
Later, I looked closely at the data.
It had changed because the source of the data had changed.
The spot that had previously been for scores were now indicating whether games were home
or away for the teams.
So I was now ranking teams where the home team always won by two points.
So the team on top, that was a team that had more home games than anyone else.
They were ranked highest.
Pretty soon, I was able to change my computer program.
I could have changed the data, but since I'd be downloading it in the future, I changed
the program that read the data instead.
But what if the data was much, much larger?
What if you weren't doing something where you could see the problem in the results?
What if you simply didn't know what to expect in the results?
There are many other issues that can cause inconsistencies, changes, missing values in
other problems in data, creating results that are truly garbage.
Remember the other problem.
We have to create results that work on even good, clean data.
But our goal is generally not to simply do well on existing data.
That can lead to a problem called overfitting, which we'll discuss in a later lecture.
We want to create a method that can use that data to perform well, but also offer insight
into data that is yet to come.
Data analytics takes data, but how it takes the data matters too.
Working with the data can be and often is a science in itself.
Just remember to prepare your data.
And after you prepare your data, do your analysis with a training set, just a portion
of the data, leaving the rest of the data to test and validate your conclusions.
I call this training for success.
