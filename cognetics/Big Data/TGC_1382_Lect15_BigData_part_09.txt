You can compute the probability that at least one of those 50 gets at least eight correct.
It equals 1 minus 0.9453 to the 50th power, which equals 0.9399.
In fact, broadening your search to 100 analysts makes it even worse.
You now have a 99.6 percent chance that someone will get at least eight correct just by flipping
coins.
Each analyst individually is unlikely to get at least eight correct.
But as a group, the probability that one person will do that becomes quite high.
To make matters worse, there is no guarantee that the selected person will continue to
be accurate.
Remember, the person was flipping a coin.
So once we zoom in on our apparent winner, that one person's chance of guessing correctly
collapses back to 5 percent.
Data analysts build models that take data to predict future outcomes or explain past
events.
In a sense, data analysts are storytellers.
We saw in our lecture on patterns that we as people have a great way of putting order
in our world through stories.
We can find some way to explain what we observe to date.
Remember that scientists reach farther.
It isn't enough to build a model that can describe all past earthquakes or produce the
path of all past hurricanes or perfectly predict the outcome of every past March Madness Tournament.
These results are impressive only if they enable us to better predict future earthquakes,
future hurricane patterns, and future March Madness Tournaments.
Can a model be extended into something we've not yet observed and make predictions?
This is the goal.
To do this, you usually have to be less predictive in the past.
Remember a certain amount of that past data has noise and randomness.
We don't need to predict the noise.
We need to find the trend within the noise and yet not overfit that trend.
If we can, if we can find that sweet spot between predicting the past and predicting
the future, then our data analysis is at its best.
It can improve our forecast and like the case with Hurricane Sandy, give us more time to
respond to the forecast.
