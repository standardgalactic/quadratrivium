together, he's ready to analyze. We will take it step by step. Step one, collect all the recent
polls that you can find from within a state. We'll label them P1, P2, P3, and so forth.
Gathering all this information from various sources and getting it into the form you need
is called data scraping. Keeping a steady supply of current data fed to your model
can be the most time-consuming step in the whole analysis. Step two, figure out the poll weights.
This is part of the secret sauce in many cases. We know generally how this is approached,
but not specifically. But the general factors that go into weightings can be agreed scientifically.
Old information is worth less than new information. Bigger polls deserve more weight
than smaller polls. The quality of the poll matters a lot, so we need a measure of that.
Otherwise, it's just garbage in, garbage out. So each poll gets a weight that is made up of
three different values. The recency of the poll, the sample size of the poll, and the
pollster rating for the company that did the poll. Silver said he modeled recency
with exponential decay. That's fast, as we know. But Silver was working for a news organization.
He wanted his model to be able to respond strongly to recent events, such as a presidential debate.
For example, if a poll from today was given a value of one and tomorrow given a value of one
half and the next day of one fourth, this would be an example of exponential decay.
My colleague Davidson, by contrast, has used a slower rate of decay. So his model doesn't try
as hard to capture, to capture real but momentary changes. Instead, it gives more weight to past
knowledge. Either way, the older a poll gets, the lower the recency number gets. The faster this
decays, the more influenced your poll is by recent results. Recency also depends on whether the same
polling company releases a newer poll. If so, then the recency score for the older poll goes down.
For sample size, larger sample sizes are weighted higher. Note, however, that poor methodology
doesn't mean large sample sizes increase accuracy. We saw this in the Literary Digest example versus
Gallup's polling. The pollster rating requires the use of that massive database of historic
polling data. So this is another important place where we do an aggregation of data from many sources
and then keep updating as new results come in. The result is we can calculate how accurate
each pollster is. Better pollsters get higher weights. Of course, how a polling organization
