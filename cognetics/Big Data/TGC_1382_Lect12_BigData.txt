Usually, we data analysts look at the data, analyze, and learn from it.
But in this lecture, we see how computers can be programmed to look at the data and
learn by themselves.
The computer, all on its own, looks at the data and figures out how to predict what is
happening.
How?
It's programmed to learn, like our brains, that can sound like science fiction.
It isn't, because it's being done today to create games, recognize what you write on
a piece of paper, and more.
To help set the stage for this, let's consider the game 20 Questions.
If you and I played right now, then you would think of anything at all.
I get to ask 20 questions that you must answer truthfully.
So I might ask, is it bigger than a bread box, or does it lay eggs?
If I guess your object in fewer than 20 questions I win, else you win.
This could seem impossible, there are trillions of things to choose from.
The key is to ask questions that essentially divide the options you currently have in half
with each guess.
We talked about this type of power in our earlier lecture on complexity.
If you start with a trillion options, then one question narrows things to half a billion,
and then after another question, you have narrowed things to a quarter of a billion.
In fact, if you could have everything with each guess, then if you choose one object
from a trillion, I could guess your object in 40 guesses.
Now, while there may be technically trillions of things from which to choose, it's unlikely
any of us are going to think of a trillion things.
Why?
Well, let's say you could think of a thousand things each second.
How many seconds would you need to think of a trillion things if you could continuously
think of a thousand things per second?
Just over 31 years.
Twenty questions has been played for over a hundred years.
It grew in popularity during the late 1940s when it became the format of a weekly radio
program.
It was transformed by data analytics when the computerized game 20Q was invented by
Robin Bergener in 1988.
Today you can play 20Q online or with the electronic handheld version.
My family got this to take on long car trips.
Again, think of anything at all.
Text appears on the website or on this little ball that asks questions.
Answer them and you are on your way to 20 questions.
When I played online, the first question was, is it classified as animal, vegetable, or mineral?
I could answer animal, vegetable, mineral, other, or unknown.
If the game fails to guess in 20 questions, it takes an additional five questions.
If it fails to guess even with the additional questions, you win.
If you play the game, you see that it can win whether you guess a zebra or a carburetor.
It can be a bit stunning, so much so that you might want to buy one or send it to a friend.
That's how my family got ours.
Someone bought it for us.
But initially, this was an internet game and it became a sensation.
The link was emailed from person to person.
With no promotion, the link to 20Q was sent around the world.
In fact, this viral success played an important role in why 20Q did so well at guessing.
So how does it work?
How can a computer possibly guess what you're thinking of?
How did anyone figure out how to get a computer to make those decisions?
The computer, in a sense, figured it out.
How can a computer possibly figure something out?
Quick answer, artificial intelligence.
How does that work?
In this case, lots and lots of practice.
It's possible that inventor Robin Bergener could have created a database containing attributes of common objects.
Instead, he taught it only one object, a cap.
In fact, according to 20Q's published history, the system didn't even know 20 questions.
It knew only one question.
So then what?
He also built into the program the ability to learn.
Play a game, it learned from the game.
So he began playing, and to help the program learn quicker, he put it on a floppy disk and shared it with friends.
So each of them played the game learned.
By playing again and again and again, the program learned more objects, more questions,
and what series of questions tended to correlate with an object.
Then Bergener shared his program with even more people by putting it on the internet,
which helped it get better even faster.
And as it got better, even more people wanted to try it.
That viral success meant it was being played many, many times and learning a lot.
In the end, 20Q had built a database of 15,000 objects.
According to the 20Q website, the game guesses correctly within 20 questions 76% of the time.
And 98% of the time, if you let it ask 25 questions.
It can eventually guess correctly, even if one or more of your answers does not agree with answers from most other people.
Even with a vast database, it continues to learn.
It's also interesting that the game could be converted into a handheld device that is not connected to the internet.
There would be a difference. Rather than that database of 15,000 objects, it would be brought down to 2,000.
The good news is that people think of those 2,000 objects 98% of the time.
This is a very important step in data analysis, so let's pause and look again.
Yes, the handheld game isn't as robust, but it still does an amazing job and essentially a good enough job.
I often tell my students, don't always try to find what would be perfect.
Try to figure out what is good enough.
That's not always easy to do, but as you learn to think that way, you'll be much better at data analysis.
So let's dig deeper into the computing and data analysis behind the 20Q game.
It uses an artificial neural network, which is a computational model inspired by the brain.
Just like 20Q, these so-called neural networks are capable of learning and pattern recognition.
They've been used not only for language, but also for computer vision and speech recognition.
Amazingly, the work originated in 1943, even before the digital computer.
Warren McCullough, a neuropsychologist at the University of Illinois, and Walter Pitts, a logician,
postulated a simple model to explain how biological neurons work.
They were working to understand the human brain.
In the end, it provided a foundation for computerized learning.
When the digital computer became available in the 1950s, the ideas of McCullough and Pitts were implemented as what were called perceptrons.
They could balance a broom standing upright on a moving cart by moving the cart back and forth.
Can you envision this?
Sometimes I use a broom.
Here, let me show you using a yardstick.
Again, how did the computer learn to do this?
Same way I did.
Practice.
Lots and lots of practice.
I learned, like I did, by seeing what did and didn't work as I learned.
Today, robots, which are a form of a computer, can easily balance a broom, which more precisely can be called an inverted pendulum.
But we have more advanced computing today.
Today, they can also balance an inverted pendulum that is articulated in the middle.
It does get even better.
The pendulum can be hanging straight down.
So the computer has to swing it back and forth until it's ready to balance.
If you see this in motion, it looks like almost nothing is happening, except maybe an experiment in chaos, until that magic moment when the pendulum stands still, as if hanging by a wire.
And no, I cannot do that.
I wish I could, but I can't.
Imagine that.
In the 1950s, a computer had learned to balance a broom.
I balance brooms, and that usually gets a lot of attention.
Did the field go crazy with activity after this?
No.
Overall, the results were disappointing.
As a general method for solving problems, part of this was due to the times.
Keep in mind, at the time, computers were less powerful than today's microwave oven.
Further, it wasn't until 1969 that two MIT professors showed that the concept needed to be a bit more complex.
But whether it's balancing an object or playing 20 questions or something more, there is one issue to address.
How does this work?
How do you get a computer to learn?
A neural network, natural or artificial, creates a complex behavior from simple units.
Get enough of them acting together, and you can create that behavior.
A neuron is a single cell that communicates with others.
A typical neuron in the human brain receives between 1,000 and 10,000 inputs from other neurons.
These signals are relayed to the cell body where they combine.
If the stimulation is high enough, the cell fires, sending an electric signal to its downstream neighbors.
The input layer of biological neurons receive their inputs from the environment.
In the retina, they are sensitive to light of various wavelengths.
In the tongue, they are sensitive to the presence of particular molecules.
The axons of neurons relay their signals to other neurons, and others are connected to other cells.
Like muscle cells.
This is how we learn.
A cat with its 300 million neuron network learns the sound of a can of cat food opening.
As people, we have a 100 billion neuron network and learn to write poetry, ice skate, and yes, possibly balance a broom.
So we are now ready to look at neural networks on a computer.
First, there is the input layer.
In the body, this interacts with the environment.
In data analysis, this interacts with the data and gets its input there.
The second layer is known as the hidden layer.
It contains the artificial neurons.
They receive multiple inputs from the input layer.
Sometimes there is more than one hidden layer.
Then, the artificial neurons summarize their inputs and pass the results to the output layer.
So, you give the network training inputs.
For 20 questions, this is many, many people playing the game.
You want it to generalize the results.
For 20 questions, what in general do you ask to get a watch as the object?
Keep in mind, the computer is learning.
So, it can be hard if a neural network doesn't work to fiddle with it.
Neural networks are good for prediction and estimation when the inputs are well understood.
You have a pretty good idea of what is important, but not how to combine them.
The output is well understood.
You know what you are trying to model.
Experience is available.
You have plenty of examples to train the data.
A black box model is okay.
You don't need to interpret or explain the model.
Why did it get what it got?
You may not need to know, but it will predict from what it learned.
Let's return to 20 questions.
After the online version of 20Q was played 1 million games,
the neural network had built up 10 million synaptic connections.
How did they fire and communicate when asking questions?
That's what you won't know, but clearly, if you've played the game, it does pretty well.
Now, there's a lot of connections.
Keep in mind, it's still connections in a computer program.
It isn't a biological neural network.
An ant has 10,000 neurons, not 10 million like the online 20Q game.
But an ant can do many things a computer isn't good at.
An ant with 1,000th of the neurons of that 20Q game
can find a dropped crumb and relay that location to other neural networks in other ants.
So what type of questions have neural networks tackled?
Have you been called as a juror, taken time off from work, showed up,
and then sat and sat waiting to see if you're needed or you're not?
In Norristown, Pennsylvania, a neural network was introduced early
to help dramatically reduce the number of jurors called for potential service by 25 to 40%.
Using over a year's worth of past information about the courthouse,
a neural network was trained.
For input, it took the data that included dates, judges, types of cases,
and the number of jurors needed at a particular courthouse.
Then, the neural network determines the number of jurors needed
for the next day at a specific courthouse.
The savings, $40,000 per year, even in the early 1990s.
In the last lecture, we discussed regression and learned that logistic regression
can be applied to handwriting.
Well, since 2009, a research group has won multiple international competitions
in connected handwriting recognition.
This is cursive handwriting.
In each case, they don't have any prior knowledge about the language.
They have to have a computer learn on the spot.
The languages have been French, Arab, and Farsi.
How has the team won?
You got it.
Neural networks throw a lot of Farsi characters at their program,
and it learns and does better than other programs and methods designed to read handwriting.
Remember, this is a competition specifically for handwriting,
so even a doctor's scribble wouldn't be overlooked.
Google is using neural networks in their X laboratory,
which is perhaps most known for inventing a self-driving car and augmented reality glasses.
But the X lab also created one of the largest neural networks.
It connects 16,000 computer processors.
What's its input?
The internet.
Their neural network was presented with 10 million digital images found in YouTube videos.
Remember, you need a clear goal.
What's its goal?
Find cats.
They never told it during the training what a cat is.
Amazingly, the neural network learns.
In the end, it performed far better than any previous method.
It roughly doubled the accuracy in recognizing objects from a challenging list of 20,000 distinct items.
In 2012, Google used a machine learning technique called Deep Neural Networks for its voice search.
Its error rate decreased by 20%.
Neural networks helped Microsoft with direct mailing.
Each year, the software giant sends out about 40 million pieces of direct mail to over 8 million registered customers.
The mailings often encourage people to upgrade software or buy other related products.
Everyone in the database generally receives the first mailing.
The key question, to whom should the second mailing be sent?
That is, who is most likely to respond to a second piece of mail?
A key in the neural networks is inputting variables that are important.
So Microsoft took time to eliminate unimportant variables, which were important.
Initially, the neural network trained with about 25 variables.
Let's look at a few.
Recency. The more recently you've bought something, the better the chance you're going to buy again.
The date an individual made their first purchase.
The longer you've been a customer, the better chance is that you're going to buy again.
The number of products bought and registered.
And the number of days between the time the product came out and when it was purchased.
So how did it go?
Before this work, an average mailing would get a response rate of 4.9%.
After the response rate increased to 8.2%.
Keep in mind, they weren't necessarily finding new customers.
They were doing less and more targeted mailing.
So they end up bringing in the same amount of revenue for 35% less cost.
Neural networks are part of the larger field of artificial intelligence and machine learning.
Speaking of artificial intelligence, it is easy to think robots.
So let's move to the larger field of AI and talk about robots.
And see how they can use ideas and methods very similar to those we've discussed.
You have defined inputs, a defined output, and then let the computer learn as it goes.
In particular, let's discuss the robots, which almost look like flying saucers on wheels.
They will vacuum your house.
We'll take the iRobot Roomba, which has sold millions of units.
So what do you do?
Put it in a room, press the clean button, and walk away.
Go see a movie, go to work, and when you return, your room is vacuumed.
How?
First, you press the clean button.
Roomba's first inputs are to calculate the size of the room through its sensors.
The bigger the room, the longer it is going to take to clean it.
Keep in mind, we're talking anyone's room, not just an empty room.
Second, the system adapts to new input up to 67 times per second.
Much faster than the quarter second, it takes us to blink.
That could be as many as 4,020 adaptations in one minute.
For instance, Roomba can avoid steps with four infrared sensors.
These cliff sensors constantly send out infrared signals.
If the robot is approaching a cliff, those signals get lost.
But then, don't keep going.
If it bumps into something, it backs up, rotates, and moves forward.
It keeps doing that until it finds a clear path.
There is another sensor.
It keeps track of walls so it could follow along them closely.
That sensor allows it to keep close to walls or furniture without touching them.
And finally, regardless of where you put the couch or move the couch for that matter,
the robot determines its own cleaning path that achieves complete floor coverage.
Roomba generally isn't as efficient as we would be.
It takes longer to vacuum.
But we aren't doing the vacuuming either.
Keep in mind, though, Roomba runs off its rechargeable battery.
What if you have a big room?
Our rechargeable robot will return and connect to the charger all by itself.
Roomba was introduced in 2002 and sold millions of units in its first decade.
Do you like vacuuming, but don't do windows?
There's now a robot for that, too.
There is another that will mop your floors.
What all these robots have in common is the ability to take continuous inputs from the
environment and develop an algorithm for cleaning that environment on the spot.
Does the Roomba learn from previous cleanings?
No, not so far.
In that way, a Roomba is like a handheld version of 20Q.
If Roombas did have internet connectivity,
then they could share information and learn from one another.
Do you want a vacuum that's connected to the internet?
Or are the routines inside a standalone version good enough?
These are design questions that come straight from data analytics.
Neural networks in artificial intelligence underscore how computers can learn from data.
Indeed, they can learn to guess what we're thinking, how to navigate a room,
or to predict phenomenon like the number of potential jurors.
Neural networks have also been used since the early 1990s to predict what stocks might rise or fall.
They were a huge hit in the mid-1990s.
Technical editor John Sweeney said in a 1995 issue of
Technical Analysis of Stocks and Commodities,
quote, you can skip developing complex rules,
just define the price series and indicators you want to use,
and the neural network does the rest.
This is true when they work, and a key to effective neural networks is training the data,
or having it learn on a rich set of data.
Said another way, a big decision is the choice of variables in data on which to learn.
One early experiment in 1994 was by Yoon and Swales.
They wanted to predict how the stock of a firm would perform on the market.
For the inputs, they had nine variables.
Confidence, economic factors outside the firm's control,
growth, strategic plans, new products, anticipated loss, anticipated gain,
long-term optimism, and short-term optimism.
These values came from studies in Fortune 500 and Business Week's top 1,000 firms.
The output was well-performing firm and poor-performing firm.
The network was able to correctly classify 77.5 percent of test cases.
Since the early 1990s, neural networks have been used extensively for a wide variety of applications
in stocks from selecting or diversifying a portfolio to rating the risk of fixed-income investments.
Early uses included using neural networks to time when to buy and sell stocks.
Banks developed neural networks to predict interest rates.
Companies with international operations developed neural networks to predict exchange rates.
These early predictions worked well to attract interest from other organizations.
As these innovations spread, the expression neural network somewhat fell out of use.
For many users, machine learning was becoming just another routine aspect of what computers do.
Clearly, it is wonderful when neural networks work.
Here also lies an important issue in machine learning.
We can't always open the hood and see the wiring.
What I mean is that you may not be able to know exactly what the computer learned, why, and how.
If you need to know that, a variety of machine learning techniques may not suffice.
But, if you simply need a predictive method, you have the data and the output you want to predict,
then using these techniques can be great.
All you need to get started with neural networks is software that performs neural networks, like Excel, Jump, Sass, or R.
Then, you take your data and think your inputs, the output, and then you will have to think about the layers that you want to predict.
So, you will have to think about the layers in a neural network and the number of neurons.
Depending on the software, you will break the data into three groups, training, validation, and test data sets.
The validation enables the software to know when it can stop learning and consider itself done.
It is then ready to be tested on the data it hasn't seen.
Well, there are still a variety of ways to improve them.
For example, ensemble methods use multiple models to better predict performance than could be attained from any single one.
You may not know exactly how to build your machine learning program, but you can use several versions to build a better one.
It is important to recognize machine learning algorithms can take tuning.
And sometimes, you simply have to try another approach, which is true in many parts of data analysis.
Remember that these techniques are focused on a defined task.
Our minds learn all sorts of things.
The 20-Q algorithm trained from many, many people playing the game and is now able to work through various possibilities.
Another program learned to perform path finding when you plop a robot in a room and press the clean button.
This helps underscore that data alone won't allow a computer to learn.
Just being shown a lot of calculus equations and problems,
even their solutions won't necessarily teach you that level of mathematics.
You need an effective way to be taught.
The same is true with this type of data analysis. The machine must be taught effectively.
But with the ever-present and growing amount of data,
there is a lot of interest in learning from the data and automating how we can learn and predict from our past.
Artificial intelligence is not just a technique in novels and movies.
It is used to explore and use many large data sets that we may not otherwise understand.
In the end, such methods can learn all on their own
and learn to predict our behavior for some task or come up with an intelligent alternative.
In time, the data analytics underlying artificial intelligence may help a car drive itself
or use what people are posting on websites, such as Twitter and Facebook,
to automatically write a news story, maybe even a story about machine learning in artificial intelligence.
