If you've ever seen the children's magazine, Highlights, you may remember a feature where
you are asked to figure out how one picture is different from another almost identical
picture.
Other publications play spot the difference with photographs.
There is an original, then there is a photograph with features that have been digitally added
or removed.
In this lecture we do the same thing with data.
Can we spot a difference in the data?
It's called anomaly detection.
The goal is to find objects that are different from most other objects or behavior described
by the data.
You may have run into this before.
You make a big purchase with your credit card and suddenly get a call from your credit
card company checking in.
Among the many, many purchases happening, how did they see yours and why did they call?
Criminal behavior can be detected with anomaly detection and so can health risks.
The technique for identifying risks to your health are quite similar.
The goal in either case is to find objects that are different from most other objects
or behavior described by the data, but different only in a relevant way.
In Highlights magazine we already know there are relevant differences to look for and sometimes
we know how many, so we can keep searching until we find them all.
In data analysis we often won't know in advance if and when the differences occur, so we don't
know if anomalies are there, but if so we want to find them or at least flag that something
might be happening.
At first this may not seem that hard to do.
Essentially you're looking for an outlier.
Here's one we've already seen.
We're looking once again at the number of home run hits by every player in the American
League in 1920.
Who's the anomaly?
This is like Sesame Street.
One of these bars is not like the other.
The anomaly here was Babe Ruth.
As I've said before, there was truly Babe and everyone else.
Pretty simple.
But it can be much harder to spot all the anomalies.
For one thing as data analysts we need to be careful thinking that anomalies rarely
occur.
In percentage terms that will be true, but just take Babe Ruth.
He is an outlier among about 250 numbers.
Let's say he was an anomaly that happens only once in a thousand times.
Still pretty easy to spot if you only have a thousand events.
But if your tracking happens billions of times, then an anomaly that's one time in a thousand
may end up happening millions of times.
We have to remember this when working with large data sets.
Statistically, an anomaly might be unlikely, but it still might occur a million times.
Anomalies are, by definition, not common.
In the natural world, many events and objects we notice and care about are common.
Yet anomalies are of considerable interest too, maybe even more.
One thing that is very helpful is to see a variety of forms anomalies come in.
If you and I were about to work together on a data set, we'd want to know what type of
anomaly we might be looking for.
You might not entirely know, but when you do, it can be quite helpful.
Here are some areas where anomalies are important.
First, fraud detection.
You may make a big purchase that garners that call from the credit card agency, or maybe
you've made a purchase far from home.
They aren't calling just to touch base with you.
They're calling because that unusual purchase is uncharacteristic of you and they want to
ensure the purchase was made by you.
The same idea of noticing a change in behavior, in this case in spending, can aid in detecting
fraud more quickly.
Next, intrusion detection on the Internet.
In 2011, security company Imperva monitored 10 million attacks targeting 30 different
enterprise and government web applications.
On average, there were 27 attacks per hour, or roughly one attack every two minutes.
The attacks appeared to mostly be probing for vulnerabilities on various sites.
If a vulnerability was exposed, Imperva found that the automated attacks could grow to upwards
of 25,000 per hour, or seven attacks per minute, per second.
From overwhelming or crashing a system to intruding in secretly gathering information,
attacks on computers happen or are being attempted every second of every day.
Third, ecosystem disturbances.
There can be atypical events that have significant impacts on humans, earthquakes, hurricanes,
floods, droughts, and heat waves.
Here, the goal is to predict such anomalies.
Fourth, public health.
These techniques can help with outbreaks.
For example, in 2003, Carnegie Mellon developed a system called What's Strange About Recent
Events, or WSARE.
It searched a database of emergency department cases for anomalies.
Sometimes anomalies just happen.
You can flip a coin 100 times, and sometimes, as improbable as it is, you'll flip 12 heads
in a row.
Not often, but it can indeed happen.
This can happen with other anomalies, too.
So the Carnegie Mellon system ran an algorithm to determine how likely some anomaly happened
by chance.
Suppose that normally 8% of cases with patients over 50 involve respiratory problems.
But today is 15%.
This system could figure out that the probability this happened by chance is 20%.
So not as unlikely as you might have expected.
So maybe this incidence of higher activity can be taken less seriously.
Finally, let's take an example from individual medicine.
When you go to the doctor, you may have tests done.
Generally, you don't want unusual test results.
Keep in mind, though, what constitutes an anomaly may depend in part on the age and
sex of the person.
Correctly identifying an anomaly relates to costs, too.
Unneeded tests can cost money.
If a condition isn't noticed, it can be harmful.
Anomalies in a data set can arise for different reasons.
In 2013, the New York Yankees and the New York Mets started their seasons on the same
day and the same hour.
That in itself was unusual as it was the first time ever this happened.
But there was an even bigger anomaly.
The average income per person at those two home-openers was half a million dollars.
Really?
It's true.
How?
Well, New York City's mayor, Michael Bloomberg, attended both games.
His aides estimated the length of each game and driving time.
So he took the number 4 train to Yankee Stadium, then left after the 4th inning and drove
to City Field to see the Mets.
He arrived in the 6th inning and stayed through the final out.
Actually, Bloomberg's attendance all by itself is the key to knowing that the average net
worth of anyone who attended the home opener for either team was so high.
According to Forbes, Bloomberg's net worth is an astounding 27 billion dollars.
Yankee Stadium holds just under 51,000 people.
City Field holds just around 42,000.
So on average, you can take Bloomberg's 27 billion and divide it by the capacity of
the field.
That's half a million.
Bloomberg is an anomaly in terms of net worth.
So he skews the average.
If you are working with data, finding this anomaly can be helpful.
But if you are looking for meaningful averages and statistics, such things can be an issue.
So sometimes anomaly detection is part of data pre-processing.
But as we have seen in our earlier example, detecting anomalies is important to detecting
fraud or illness.
The next thing we need to think about as data analysts are the causes of anomalies.
They aren't all the same, and this is important to keep in mind.
First, data may come from a different class or source.
If someone has stolen a credit card, they are of a different class than credit card
users.
Bloomberg might be thought of as a different class in an economic sense.
He's in the Billionaires Club, but in mathematical terms, he's also just an extreme value.
He's what in regression we already called an outlier.
It can help us to lean on statistician Douglas Hawkins' definition of an outlier.
An outlier is an observation that differs so much from other observations as to arouse
suspicion that it was generated by a different mechanism.
Second, there is natural variation in data.
I'm a professor and students sometimes ask if grades will follow the bell curve.
This is a normal distribution, and a large amount of data can follow this.
Height is an example.
I recently taught a forward on the men's basketball team at Davidson College.
He's 6'11".
His height is less likely among men, so his height is an extreme value of the normal distribution
for heights.
Another source of anomalies are errors in data collection or measurement.
I recently had this in my own research.
We were looking at collections of Twitter data.
In our particular stage of research, we wanted to know how many times a tweet was retweeted.
In our collection, we only found the tweets were retweeted once, three times, eight times,
and so forth, nothing in between.
Keep in mind, we had 10,000 tweets.
Tweets were retweeted once or three times, but never twice.
Could that really be the case?
Yes.
Is it unlikely?
It is unlikely, quite unlikely.
So we spent time looking at our data and ensuring it was correct.
Was this real?
Was this a real and unexpected occurrence?
Collecting the data costs money.
So it wasn't as easy as just collecting another set of 10,000 tweets.
So what did we do?
First, we contacted the supplier of the data, and at first we were told it was our coding
causing the problem.
We weren't downloading the data correctly.
Then we began looking at Twitter itself, tracking down individual tweets to see if they matched
the data.
This is possible, but a hassle to do with 10,000 tweets, which is why we use a data
collection service.
We found examples and emailed the data collection service again.
In the end, it was an issue on their end, which they fixed.
We were supplied corrected data.
Note, we were able to identify the problem because we had a reasonable idea about what
distribution to expect in our data.
We don't expect tweets to only be retweeted three, eight, and so forth times.
It was possible, but it was highly, highly unlikely.
The same type of thing is true with the forward on the men's basketball team.
Height tends to be normally distributed.
In a normal distribution, you can know where 68%, 98%, and even 99% of the data points lie.
When a data point comes that lies outside these ranges, you know they are rare.
But keep in mind they are rare according to a normal distribution.
Further, not everything has a normal distribution, and it depends in part on the setting.
When that player is on the court, he's tall because he's a forward, but he doesn't look
disproportionately tall.
But sometimes models are difficult to build.
For example, what if I don't have data in advance?
What if I don't know what it is going to look like?
That basketball player's height is different in relation to others in my class than on
the court.
If I don't know in advance what things are going to look like, then other techniques
may be needed.
Other methods look at other factors, like how close an object is to other objects, or
the density of objects in a region.
For example, is a credit card purchase wildly different from the value or frequency or location
of typical purchases?
Do you have one huge purchase?
Do you have a flurry of smaller purchases?
Sometimes these types of anomalies can be seen in a graph.
Here is a set of data that I graphed in two dimensions.
Here the outlier is easy to see.
It is an outlier due to its distance from the others.
Visually we see that one point is far away.
But we are seeing more than this by looking at three points in the picture in particular.
Now notice how far that outlier is from the two red points on the graph.
Notice it is about as far away from either red dot as they are from each other.
So it isn't just that it's far away, but it is far away from the group or cluster of
other objects.
This data has two components or dimensions.
Those account for the horizontal and vertical axes in the picture.
We could end up with data having four, five, or more dimensions.
That isn't as easily visualized.
We can turn to math to find the outlier.
One way to detect such an outlier in an example like this is to use the method of clustering
which will be a topic in a later lecture.
That dense glob of points is a cluster.
The other dot is a cluster of one element called a singleton.
This would quickly be identified.
If we wanted to measure the distance of points, we could measure the distance from points
to the center of the cluster called the centroid.
This would help us see that the singleton is much farther than anything in the dense
group of points.
We will learn that clustering finds a group of points in two, three, or more dimensions.
You don't need to graph it.
Now there are some very specialized statistical tests to calculate what counts as an outlier,
at least for specific types of data.
Clustering is an example from the area of data mining.
We might use machine learning techniques which are an area of artificial intelligence.
Other times you use statistical techniques which calculate, among other things, the probability
of something occurring.
It could say, for instance, how likely is it that I have a 611 male in my class?
There are other techniques from the areas such as information theory and spectral theory.
A lot of methods depends on assumptions about your data that may not be valid.
So you may need to try several methods, especially if you don't know what to expect.
Let's look at some examples and see how anomaly detection is helping us.
The popularity of online games has created its own new industry.
It's an industry well above $1 billion in the U.S. alone.
A lot of money can be gained and companies can springboard or fall off one game.
The key, how much that game makes.
That significant revenue can be lost by players who steal currency used in the game rather
than buying it.
This type of fraudulent gameplay has often been identified and solved on the back end.
IT security personnel play back every transaction.
This enables them to find the cheaters and figure out how they're manipulating the game.
Another way to find the fraud has developed.
Investors often customize to a player adapting to what you're doing.
The data that customizes can also be analyzed to identify and stop fraud at the time it is
happening.
Analytical methods can determine common paths through a game.
So if you play a game, the game knows how likely you will progress through it.
By determining such average play, you then know what isn't average.
If a player falls outside the range of what is acceptable, it is flagged.
With credit cards, you get a call to check in.
With an online game, they could check in or even freeze the account and check in.
But let's note that it isn't the only type of play that might be of interest and help
overall revenue.
The same tools that pinpoint someone who advances too quickly might also find someone who progresses
quite slowly through a game.
Once you find such players, promotions can be offered for faster play.
Keep in mind that advances in data analytics have a direct impact on how and when we can
find fraud.
There are data sources that were previously ignored because they changed too quickly.
Traditional techniques simply couldn't handle them.
The insurance industry is an example.
They can refresh fraud scoring in real time.
But then that entire data set changes.
Averint behavior can be analyzed in employees too with huge log files from claims or bill
processing systems.
Now here is another lesson in data analysis.
At one time, analysis of such data would take hours or days to run.
Now billions of rows of data can be analyzed in seconds.
This speed has profound impacts on data analysis.
Applications that once demanded a sample or subset of the data can be used now with the
entire data set.
There isn't a need to find a representative sample.
You simply run it on the entire data set to learn and explore it.
Further, given the speed of modern algorithms and technologies, models can be tested, retuned
and tested quickly.
If a model seems to be failing and reducing in its ability to detect today's fraud, then
a refined model can be tested quickly and analyzed.
If it's efficient, it can be deployed quickly.
At one time, refined models might have been deployed only once or twice a year.
So here is the larger lesson.
Whatever you might consider today that's beyond your computing resources should be logged
for tomorrow.
Frequently in my research, I find that in a year or two, something that was impossible
becomes possible.
It may be better to postpone ideas rather than write them off entirely.
They may in time be viable if you don't lose track of them.
Returning to an old hunch with fresh tools can be exciting and challenging.
So let's return to that call from the credit card company.
It can be a nuisance, but remember anomaly detection in this setting is looking for criminal
activity and the criminals are sophisticated in order to at least try to run under the
data analytics radar.
Those who aren't sophisticated have most likely been caught already.
In August 2011, Visa began running a new form of data analytics that used a larger and more
varied data set, but could also run calculations faster and cheaper than traditional databases
or analytic engines.
For example, the new analytic engine could study as many as 500 aspects of a transaction
at once.
In 2005, the previous analytic engine could study only 40.
This ability to handle bigger calculations more quickly has paid off.
Visa estimates that it has identified $2 billion in potential annual incremental fraud.
The key potential, by identifying potential fraud, the company can address the issue before
that money is lost.
Fraud detection isn't new for Visa.
Their authorization system went online in the mid-1990s.
Fraud has declined by two-thirds during less than two decades.
Still, six cents out of every $100 in transactions are believed to be fraudulent.
Here is a case where sampling can be costly.
At one time, they analyzed as little as 2% of transaction data.
Now, Visa works to analyze all of it.
Before, Visa created its security assumptions using only average fraud rates for general
categories like grocery stores.
Now, they can narrow it down to individual merchant terminals.
They've identified warning signs for fraud.
For example, in certain merchant categories for transactions of $200 or more, prepaid
cards were used in 85% of the cases involving fraud.
Another warning sign is when the billing and shipping addresses differ.
Keep in mind that fraud comes in many forms.
Fraud can appear on social networks.
I have a Facebook account and enjoy reading the posts from friends, some of which I haven't
seen in years.
When I'm fond of their posting, I press the like button.
There is another social network just for pictures called Instagram.
If I like a picture, someone posts.
I again indicate that I like it.
Simple enough.
Whether you use it or not, Instagram gets attention.
By 2013, Instagram had 150 million users.
Over 16 billion photos have been shared.
One billion likes were happening each day.
55 million photos uploaded on average each day.
Being liked can be quite nice.
In the world of business and social networks, being liked can be important, so it becomes
a target for fraud.
Search for techniques to create and then sell false endorsements like likes and followers.
Getting false followers and likes could seem a bit odd, but remember, making an internet
splash can have real effects in business.
The biggest successes on the internet are themselves anomalies.
We turn to July 15th, 2012.
That's the day the song Gangnam Style, recorded by Korean singer Psy, was released outside
Asia.
It was soon a sensation.
That's really putting it mildly.
Within a month, it ranked first on YouTube's most viewed videos monthly chart.
On August 21st, it was number one on the iTunes music video charts.
Celebrities like Katy Perry, Britney Spears, and Tom Cruise were tweeting about it.
On September 14th, Psy appeared on The Today Show on NBC.
The following day, he made a cameo appearance on Saturday Night Live.
Then, on October 23rd, he met the UN Secretary, General Ban Kim Moon, at the United Nations
headquarters.
Ban expressed his desire to work with Psy, remarking on the singer's quote, Unlimited
Global Reach.
Global reach he had by the end of December of that same year, his video, which is just
over four minutes in length, was viewed over one billion times.
That equates to over 8,000 years of viewing time.
Again, these are anomalies, the kind that attract lots of attention.
When something goes viral like this, they often appear on lists that are said to be
trending.
This too is based on anomaly detection.
How do you deduce that something is trending among the many things being searched on Google
or tweeted on Twitter?
Let's take Twitter.
Twitter trends are automatically generated by a computer program looking at the terms
mentioned in tweets.
Remember in March 2013, that was reported to be 400 million per day.
This was up from 95 million tweets per day back in December 2010.
But what is trending depends on what's an anomaly, and that depends on what you're
looking for.
In 2010, Twitter changed how it identified a trend.
In doing so, what was considered a trend also changed.
Rather than being the most talked about subjects, Twitter wanted a trending to indicate what
is, quote, most breathtaking, and, quote, immediately popular.
These may sound similar, and overall they probably are.
But before this change, Twitter's trending topics were dominated by consistently popular
items.
In particular, Justin Bieber was present on the list.
That popular list kept anything new and hot in the moment from appearing.
Here's how Twitter explained this.
The new algorithm identifies topics that are immediately popular rather than topics that
have been popular for a while or on a daily basis to help people discover the most breaking
news from across the world.
To do this, Twitter tracks the volume of terms mentioned on Twitter on an ongoing basis.
Topics are then trending when the volume of tweets about that topic at a given moment
dramatically increases.
Then, it is different, trending and anomaly.
Again, here we see a lesson.
First, note that Twitter changed its definition, what worked at one time might need to change
later.
In data analytics, you often need to keep track of whether your methods continue to work
as we are in an age of ever changing data.
Anomaly detection is like a huge where's Waldo search.
But rather than having Waldo hidden on the page of a book, it's like having him hidden
on a sheet of paper the size of Manhattan or New York state.
Today, we look for oddities in huge data sets and we don't always know what the anomaly
is.
So, it might even be like where's Waldo when we don't know what Waldo looks like or we
don't know what he's wearing.
And sometimes we think we see Waldo but we don't.
But in medical testing is called a false positive.
Anomalies by definition aren't easy to find.
They are the surprises, the exceptions, the counter trends and the peculiarities.
As time goes on, more data unfolds, leaving a longer trail for some types of anomalies.
And research continues to create a more robust toolbox of techniques to find these special
cases.
The good news, we find such anomalies every day, improving our lives and saving money.
