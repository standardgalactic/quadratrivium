cases.
It's called logistic regression.
Before learning this, let's review what we've done.
When we started, we had two variables, an x and a y.
X was the year of the Olympic Games, and y was the gold medal winning time from that
year in the men's 100-meter dash.
But we can also have more inputs.
Instead of just one variable x, the studies could have used 10, 20, 100, or even hundreds
of variables.
But still, all the x variables, however many, combine to produce just one y.
Now, in logistic regression, we still produce a y and have various input variables.
But with logistic regression, the x values take only zeros and ones.
They are on and off.
Intact family or not, male or female, just two values.
One application is digit recognition.
Can a computer recognize your handwriting?
Well, that depends on your handwriting, but regression can help.
We talked about this in the lecture about training data, and we used simple averages
to sort through all the pixels for a given number.
Now we can do the same thing, but we can bring in the power of Lee Square's regression.
That will help us do a better job bringing outliers into our model, and handwriting is
an area filled with outliers.
So, where's the regression?
Exactly.
That is what you as a data analyst would need to figure out.
So let's try it together.
Consider just determining if you wrote the letter B. You'll scan your handwritten B into
a computer and place it into a grid of dots.
The dots in the grid are filled or not, depending on whether your B passes through that grid
point.
A variable is 1 or 0, depending if the corresponding dot in the grid is filled or not.
Then I take lots and lots of handwritten B's.
I use logistic regression to say, when the dots are filled, it's a B.
In another case, when the dots were filled, it was again a B. But in another case, when
a group of dots were filled, it was not a B.
So I get your handwritten B. It isn't any of the ones I've seen.
I look at which dots are filled and not filled.
Regression gives me a formula.
