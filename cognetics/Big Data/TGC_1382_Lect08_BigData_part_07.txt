For example, not everyone has a middle name.
Regardless of why the data is missing, what will you do when it isn't present?
There are several options.
First, you can eliminate data objects that have missing elements.
But then, you are throwing out data, and if the data is missing from an important subset,
you might be removing most or all of that set.
You could also delete an attribute that has missing values.
For example, maybe you no longer include middle names or ages.
Again, this removes data and should be done with caution.
Sometimes you can estimate a value.
Suppose you're looking at precipitation measures.
What if one collection device doesn't report a value on a given day?
Rather than remove that entire location from the data, you might be able to estimate that
value given certain surrounding areas amounts and their general ratio in location with the
missing value.
Or sometimes you can simply ignore that value is missing.
This depends on the analysis and the type of method being derived.
Let's look at another common attribute.
We can have inconsistent values.
Reading an address, maybe someone has a zip code that isn't contained in the listed city.
It could be that the person transposed two digits.
Sometimes this is easy to check.
Heights can't be negative in adult ages, shouldn't be single digits.
A zip code in California should start with a 9, not a 0.
Other times possible mistakes are not easy to check and can affect the results.
To see how unexpected errors can be introduced by new technology, let's look at weather data.
Data was collected for sea surface temperatures.
Originally they were collected from ships and buoys.
Technology changed and the data began to be collected by satellites.
With long-term behavior is needed in a study, data from both sources must be collected.
The data is studied and they are found statistically to be different.
It doesn't mean that they can't use the data together, but one would need to realize that
ship and buoy data from 1965 should be treated differently than satellite data from 1990.
To aid in dealing with these issues, data is often pre-processed or made clean, or at
least clean enough.
Data pre-processing comes in two main forms.
One, selecting data objects and attributes for analysis, and two, creating or combining
attributes to create new attributes more suitable for analysis.
In selecting data objects, you might sample the population or look at only a subset of
