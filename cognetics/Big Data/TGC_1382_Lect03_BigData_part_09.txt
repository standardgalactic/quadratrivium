when a big play occurs.
To do this, you must be reading Twitter live and analyzing it.
Note that the moment you know that, you must be analyzing data read from live tweets.
This also changes what type of techniques are even possible.
Really robust methods in natural language processing may give a lot of information,
but if it takes minutes to run and you need that information in seconds, the robust method may not be possible,
or you simply may not be able to do them in real time.
Today, knowing where data is coming from, how much of it is coming,
and how quickly you are going to need to analyze it are all very real and very important questions.
Clearly, there are a number of things to consider. How do you keep them all in mind?
You remind yourself of them as you learn methods and look at problems.
That's exactly what we'll do in coming lectures.
You don't need to master everything before trying specific methods.
Try, reflect, try again, and learn.
As you learn a variety of tools, you'll also develop the mindset of a data analyst.
When you begin, having a lot of data can be overwhelming,
but before long, having a lot of rich data, not just sporadic pieces of data you happen to find,
becomes more like a huge toy store that lights up a child's eyes.
So yes, we are in a data deluge, and for a data analyst, this is truly exciting.
I see data analytics like this. Each data set offers its own puzzle,
but unlike a jigsaw puzzle, there are many answers.
It's like a maze with all kinds of paths and rewards emerging all the time.
Thank you.
