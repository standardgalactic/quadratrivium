To me, an important lesson from Moneyball is having the courage to follow the sound predictions and believe in the results.
In fact, analysts who get this point may not talk much about what they do.
Like quantitative analysts working for hedge fund companies on Wall Street,
their mathematical methods are essentially trade secrets.
These analysts are using analytics to find undervalued assets in arbitrage on the difference for as long as possible.
Data analytics in search for undervalued assets are spreading to many fields.
So, keep these fundamental principles in mind.
Let's predict the future of predictive analysis.
Let's imagine we are at a data analysis conference of the future.
What might we see?
I organize a sports analytics conference where each year the work falls into several categories.
First, tools evolve.
Google adapted its algorithm to stay current.
Sports teams look for the competitive edge with new algorithms that offer new insight,
from biomechanics to training to coaching strategies that range from draft picks to player lineups.
How bracketology has evolved in my own work is another example.
In 2014, I had national media covering my work in creating NCAA basketball brackets for March Madness.
I was on the CBS Evening News, Bloomberg TV, and covered by the New York Times, USA Today, and The Atlantic, among others.
They were struck with the success of methods I had validated in years prior, which you learned in our lecture on bracketology in March Madness.
The methods you learned were made publicly available, with people from over 25 countries running the codes.
But in the midst of the media frenzy, we were also trying new methods.
For instance, we tried aggregating the data in new ways that might remind you of Nate Silver's work in politics.
However, instead of aggregating polls, we were taking about a dozen statistics for each team and treated that as a vector,
which we can process using linear algebra.
We also took data points for all teams from the past several years, not just a single season.
We also used cluster analysis to put all the teams into groups, and we created brackets based on how one cluster tended to compete against another cluster.
A bracket we created with clusters as part of the ranking popped into the 100th percentile in the second round of the 2014 tournament.
That means no one got more correct predictions in a field with 11 million brackets.
Our normal methods were also doing well, very well, but the entire research team was naturally excited to see new ideas work so well.
So then, we turned to focus on what information each new method was capturing.
What might that method see that another method may not?
