this doesn't seem so insurmountable of a task.
Again, knowing how Google creates its web ranking
can be to one's advantage.
Of course, Google has filed patents
and taken other steps aimed at reducing
the impact of Google bombs, especially
in their 2012 Penguin update.
Speaking of updates, the history of changes
to the Google search engine offers more general lessons
of data analytics.
The core approach was very good, but Google
stayed on top by continuing to make the algorithm work better
and better.
Major updates have their own code names
and have included 2005 personalized search,
taking prior search history into account when giving results.
2007 universal search.
Results from text, news, video, and so on are all included.
Caffeine, 2010.
New indexing of the web gives 50% fresher results.
Panda, 2011.
Downgrading of sites with little content, mostly ads
or duplicates of other sites.
Penguin, 2012.
Pushback against Google bombs, keyword stuffing,
and other attempts to hijack the search results.
Hummingbird, 2013.
Conversational search became possible,
where complex questions and even follow-up questions
using pronouns became possible.
Google has stayed relevant from the time
when the internet had millions of web pages
to an era of trillions of web pages.
The reason the Google algorithm has continued
to work for more and more users is
because the algorithm itself adjusted to downgrade attempts
to hijack search results, while also finding more and even more
ways to deliver meaningful results.
Scalability is an important issue for any business or algorithm
that will work with data from the internet.
Google shows that scalability means far more than just
handling bigger quantities.
