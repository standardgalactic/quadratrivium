Sometimes we have too many possibilities to consider, and sometimes phenomena are simply
too difficult to capture in an equation.
For instance, before a nuclear bomb was created, scientists wanted to test their ideas without
exploding a bomb.
Today, someone might want to test the aerodynamics of a car, or a new surgical procedure.
How do you test a car without driving, or a surgical procedure without operating?
You can simulate it.
Simulation is a powerful idea.
It's one of my favorites, and I'm surprised it's not better known.
In many cases, rather than analyzing lots of data, you can produce a simulation and analyze
what that says about a physical phenomenon.
This tool of data analytics allows us to make better medicines, faster cars, and explore new
realms of scientific study, all with the speed and safety of a computer.
Simulation is used in many more areas, too.
To get a sense, let's visit the World Series of Poker in Las Vegas.
It's a tournament that begins with thousands of competitors, and narrows down to the final
two sitting at a table with hundreds of thousands of viewers tuned in to see the outcome.
The winner is considered the world champion of poker, and receives a multi-million dollar cash prize.
When the game is broadcast on ESPN, a card is dealt, and quickly the probability of each
player winning, given the current hand, is updated.
Let's turn to our data analytics and think about how this is done.
So could there be a big database of all possible combinations?
In that case, a card is dealt, and someone looks up the probabilities for that given state of the
game. Consider how big such a database would need to be, and consider how fast we want our answer.
Let's look at the simplest states of a game. We'll have two players using a fresh deck of 52 cards.
The cards are dealt, from the 52 cards, five are chosen for the first hand, and from the
remaining 47 cards, another five are dealt for the other hand. How many different ways
can this be done? There are almost two trillion different ways. So if you wanted to store the
probability of every one of these hands winning at this stage of the game, you store probabilities
for these two trillion states. Keep in mind that even if two players are holding the same cards,
the number of cards available in the deck changes as the game progresses.
This changes the corresponding probabilities. So we would need to store trillions and trillions
of probabilities. Talk about big data. So is that how it's done? This is the key to data analytics.
We possibly could do it that way, but do we need to? No. There is another simpler way. Use a computer
to simulate the game, to see how we turn to another card game and travel to Los Alamos, New Mexico,
in the 1940s. Stanislaus Ulam, while working on the Manhattan Project that developed a nuclear
bomb during World War II, pondered the probabilities of winning a card game of Solitaire. Ulam was
a noted researcher, so one could wonder why he didn't just sit down and compute the probabilities.
The reason is the same as for poker. Such computations are inherently complex. Ulam explored
another route. He would play the game a large number of times and see the percentage of times
that he won. In fact, Ulam could play the game via an early mainframe computer that he programmed
to simulate Solitaire. He ran hundreds of trials and computed the proportion of time that he won.
Ulam. Such an approach became known as Monte Carlo simulation, as the methods often depend on an
element of chance, such as what cards will be dealt. Today, an ordinary spreadsheet can
generate and insert random numbers for you, such a command as the RAND operator. Such methods
will be used to simulate more important real-world phenomena, too. Ulam not only got a better
understanding of Solitaire. At Los Alamos National Lab, Ulam and John Von Neumann also created the
methods to simulate nuclear reactions. Today, Monte Carlo simulation is used to study applications
in such areas as physics, mechanics, and economics. And poker. Let's turn to poker,
and specifically the game Texas Hold'em to see how simulation could save us from developing
that database of trillions and trillions of probabilities. The rules of the game are as
follows. Two cards are dealt face down to each player. Then five community cards are revealed
face up. Each player takes his best five card poker hand from his two down cards and the five
community cards, and the player with the best hand wins. During the process of dealing, there are
several rounds of betting, and much of the strategy of Texas Hold'em comes from betting.
Here's where a simulation can help you play the game. You won't know, unlike the TV broadcasters,
in the World Series of Poker, what hand everyone holds. So let's find the odds of winning from a
given two card starting hand, assuming that no players fold. In a real game, players do eventually
fold, but we want to see the state of the game early on, when everyone is still in the game.
These probabilities can be computed quickly on a modern computer with simulation. These days,
a spreadsheet can do this kind of simulation too. Like ULM, we put the current state of the game
into the computer. Then we let the computer play thousands or millions of random games
and count the fraction of wins, losses, and draws for each player.
Suppose you are playing Texas Hold'em and your initial hand consists of three of clubs and three
of hearts. How good of a hand do you have? If you are allowed to have a computing device,
you could simulate the game say 100,000 times and see the resulting probabilities.
Doing so indicates that your hand leads to a win, loss, and tie, 53, 45, and 2% of the time.
What if you were dealt two fives instead? Now the probability of winning increases to 60%.
Would such information change how you bet?
In fact, one may bet a large amount, even with a poor hand, in hopes of convincing other players
to fold. This is called bluffing. Integrating this would involve a more advanced computer program.
So what is the best hand? If you take every initial hand and run 100,000 games and view
the resulting probabilities, you can determine this. Two aces is best, not surprising, and we
find that results in an 85% chance of a win. While such computers for Monte Carlo simulation
explained to ULM how to conduct experiments for cards in nuclear physics, simulation is an idea
that has been around much longer. Let's try an experiment from 1777, described by Comp Day Buffon.
It's quite simple. First, grab a toothpick. Next, line a piece of paper where the distance
between the lines equals the length of your toothpick. Then, drop the toothpick onto the
piece of paper. It's best if you slightly spin the toothpick so that each time is a little different.
Then, keep track of how many times you drop and how many times some part of that toothpick
intersects any of those lines. Say I drop the toothpick 10 times and it crosses a line 6 times.
Granted, this can feel a bit silly and could make one wonder what Buffon was up to. What are you
doing? Is this a simulation? The key is to take 2 times the total number of drops divided by the
total number of crossings. So for us, that would be 2 times 10 divided by 6. What does that do?
Buffon showed that you are estimating pi, yes, 3.141592. Surprising? It is unless you know why.
That's the part Buffon helped uncover. Before we do this, however, you may give this a try
and see what you get. I'll spin a toothpick 15 times. I get 9 crossings. So my estimate for pi
is 2 times 15 divided by 9, which equals 3.3333. Not that great, but let me try again from the
beginning. I drop the toothpick another 15 times. This time I get 12 crossings. Now my estimate is
2 times 15 divided by 12 or 2.5. This doesn't appear to be working. Here lie a few lessons
about Monte Carlo simulation. It must be run many, many times. How many? Consider Buffon's needle.
Let's start again and drop the toothpick 100 times. We get 63 crossings for an estimate of pi
at 3.17. If we try another set of 100, we get 72 crossings and 2.77 as our estimate.
Let's combine these two trials, though. We now get 63 plus 72 or 135 out of 200 crossings.
Now we have an estimate of 2.96. I'll really ramp things up and drop the toothpick 1000 times.
Now my estimate is 3.257. If I drop a different set of 1000 times, I get an estimate of 3.140.
Dropping 10,000 times gives me 3.16 and 100,000 times gives me 3.149. Notice how I'm getting
closer and closer. Notice also how I need a lot of numbers, a lot of data to find what I'm looking
for. From the law of large numbers in mathematics, I know that as I run more and more tests,
I'll tend toward the expected value, which again Buffon showed to be the value of pi.
The issue, which isn't a huge one for computers, is that we need to run
hundreds of thousands of experiments. Then we begin to see the value that we want and expect to see.
In this case, we know the value of pi, but if we didn't, we'd want to be sure we're getting the
expected value, which again may not be known in advance. Note how we sense that we weren't
close even for a thousand trials, which could sound like a lot, especially if you're doing them by
hand. We did this by running the experiment twice a thousand times apiece. We looked at the values
they hadn't converged, so we ran more experiments. We'll keep our focus on simulation and not go into
the details of Buffon's needle experiment and how it derives pi. If you're interested, hunt around
the internet and you'll find it, it uses some trigonometry and a bit of calculus. For now, let's
see other examples of simulation. How can this help us understand our world? First, it can help
answer questions and probability that can be difficult to answer. This is what Ulam was doing
when he simulated Solitaire. Here's another example. It's called the Monty Hall problem.
It's based on the game show hosted by Monty Hall. Now, you are told that there is a hundred dollar
bill behind one of three doors and that there is nothing behind the other two. You choose one of
the doors. Then, you're told one of the other doors that does not contain the money. For example,
suppose the hundred dollars is behind door number one. If you guessed one, then you're told either
that it is not behind door number two or that it is not behind door number three. If you guessed two,
you are told it is not behind door number three. And if you guessed three, then you're told that
it's not behind door number two. You may now change your guess to the remaining door, the one that
you did not choose the first time and that you were not told did not contain the hundred dollars.
The question is, is it a better strategy to stick with your first choice or switch?
This question appeared in the Ask Maryland column of Parade Magazine in 1990. It caught
wide attention. The problem was stated as having goats and a car behind the doors. In her column,
Marilyn Voss Savant asserted that switching is the best strategy. She got thousands of letters
and 92% of them insisted she was wrong. So, how did she settle the argument? Simulation. She called
upon math classes all across the country to simulate the probabilities using pennies and paper cups.
She was right. And of course, the simulation backed it up.
I did the same thing with my students. We heard a claim that a certain card trick
based in part on chance worked over 70% of the time. We wondered if this was true. It was a bit
complicated to derive the probabilities with pencil and paper. But we are trained in data analysis.
So, we wrote a computer program that simulated a shuffled deck,
basically randomizing the numbers from 1 to 52. Then we had the program simulate picking cards
and the magic trick. We ran the computer program 10,000 times and saw it worked just under half the
time. You were more likely for the trick not to work than to work. The code took about 10 to 15
minutes to write, a few seconds to run, and boom, we had our answer. Then we wondered how that claim
came about. Searching through the internet, one of my students found that the person that did the
trick only did it about 100 times. And it happened to work just over 70 times. At one level, it's
understandable why he thought this. If you flipped a coin 100 times, then the chance of getting 70 or
more heads is just under 4,000th of a percent. But even so, sometimes the improbable can happen.
He did his trials 100 times and only once, and nobody else replicated his results. Here is an
example of needing more experiments to ensure the estimated probability matches the underlying one.
Simulation is easy and you can run it many times to check your results.
What else can simulation do? Have you been in a fast food drive-through and seen that they time
how long it takes to fill the order? Such information can be quite important and helpful.
This branch of simulation is called queuing theory. If we know the rate at which customers arrive
and the length of time it takes to fill the order, we can simulate queuing up or lining up
under different scenarios. When should you have the cashier take orders only and leave the filling
of orders to someone else? Simulation can help you determine the impact of such choices.
Similar concepts allow one to model emergency room intake to reduce waiting times. In traffic
studies you can model the difference between a roundabout and an intersection with a stoplight.
Simulation is a great tool when you might change parameters in the problem.
Suppose you want to test different densities of traffic. Maybe you'll even change the road
from one lane to two lanes. If you know you may be changing these parameters then if you can
you write your simulation code so these parameters can be changed easily. Sometimes you write computer
code so you literally change a variable from one representing one lane to two which would
represent two lanes. Simulation is ideal because you can quickly test ideas without having to do
all the mathematical analysis again. Sometimes you need an analytical solution computed directly
from the data but often a simulated number would do just as well. If so simulation can save a lot
of time and allow you to quickly test many more ideas. While it's only a model a simulation can
if carefully constructed have enough realistic behavior that it will uncover enough characteristic
behavior to offer insight. With that decisions can be made. Simulation in general requires
some computer programming but not much only a little more than we have time for in a broad
course covering all of data analytics. At Davidson College I teach a math modeling course that covers
simulation among other topics. Here's what's impressive. Students who are only six or less
weeks into the course can start working on projects aimed at an international competition
called the mathematical contest and modeling. Two months earlier most of these students didn't know
any simulation. Four to six weeks later they're creating math models on real world problems
and within sight of working at a world class level.
Here is a quick digest of what we learn in such a course. First learn to create random events.
Suppose you learn that there is a 40% chance of something happening. How do you produce that in
code? Well you pick a random number that is equally probable to be any number between zero and one.
If that number is less than 0.4 then the event happened. Else it didn't. Second learn to create
cues of people entering a line. For this all you need to know is the average number of people who
come per day and the average service time. Then you can create random cues. But these cues can grow
arbitrarily long. Some lines do. Lines to get seasoned football tickets can wrap all the way
around the football stadium. On the other hand sometimes even a short line is too long.
If there are five people to buy items at the airport you might skip that store and hope for
another. I mentioned examples like this to my students to help them think. What's the nature
of your line? Will people get in that line? How long of a line is too long? If there is some
length you can try including that in your computer code. Maybe not everyone would agree on what's
too long. But you can change that later. Then learn to code simulations. You might code a game of
chance and compute the probability. The game of crafts is easy for example. It only takes a dozen
lines of code to simulate. Students who have taken probability often comment on how simple the coding
is. My students actually code a dating game and see what the probability is that they could find
that perfect someone among the student's potential dates. We also code lines for a pharmacy and calculate
average overtime for an employee. We do this in a couple weeks and with that the students are ready
to leap into that modeling competition. That's part of the power of simulation. It can model
phenomenon in our world. How good is it? Well we pay to see it in the summer. Summer blockbusters
often contain stunning special effects particularly computer generated images or CGI.
Such images often rely heavily on simulation. This is very true in special effects. To see this
let's turn to the character of Yoda from the Star Wars saga. In the 1980 film The Empire Strikes Back
Yoda was a puppet controlled by Muppeteer Frank Oz. He's the Muppeteer behind Fawzi, The Bear,
Miss Piggy, and Grover. In episode two Attack of the Clones from 2002 Yoda was created using CGI,
computer generated imagery. Frank Oz was still the voice but he no longer controlled the movement
as he did when Yoda was a puppet. In order to operate Yoda in a computer as opposed to the hand
of a puppeteer animators created a digital wireframe of the character. Such a model can
contain over 50,000 vertices connected by lines. The number of vertices are needed to capture the
detail of Yoda as we see when he moves across the screen. To move and animate Yoda animators sometimes
simply decide on specific places for Yoda's arm to be in space and time. Then it is the
computer's job to figure out where that limb is in the intervening frames. Animating his hair is
even more complicated. Unlike the movement of the body the movement of his hair may not be specified
except in the first frame of the scene. Generally it's up for the computer to determine how his
hair would move given the movement of his body. Remember often the computer is also figuring
out the movement of his body too. How do you determine how his hair will move? Simulation.
A model is built. In particular animators model his hair as springs. You can determine how springy
hair is in the model too. Think of a bed where some springs are bouncier than others. Then
you let the computer determine this given the force acting on the hair. Why? This allows animators to
put digital doubles into scenes. Harry Potter can fly his broom in a Quidditch match in ways that
might be harder with real actors or not even feasible at all. Animators found that viewers
notice hair that doesn't move. So they animated it. By simulating the movement of hair it may not
be exact and perfect but it is close enough that we as an audience buy into it. Of course
Hollywood is different from science. In science a simulation is used to predict or explain behavior.
In the movies a simulation needs only to produce images that give the appearance of reality.
But simulations in entertainment and science are becoming closer too. We see some amazing
simulations of water in entertainment movies. Look at Pixar in Disney movies with simulated
water. It's amazing how real it looks. CGI simulations for scientific purposes
can make it easier to visualize large data sets in motion further blurring the line between
scientific simulation and entertainment quality CGI. Simulation not only visualizes imaginary
worlds for Hollywood it can help us understand our universe scientifically. The Bolshoi simulation
is a massive incredibly detailed model of the universe's 14 billion year history. The images
it is producing are amazing and being closely studied. This simulation shows how gas is distributed
in the universe's most massive cluster of galaxies. The simulations create frame after frame of video.
They simulate the evolution of the universe. They do this by first examining the data from NASA's
WMAP Explorer which maps out the cosmic microwave background radiation. That radiation is the light
that was left over from the Big Bang. You can think of it as the universe's ancient data.
That data can be used as the starting conditions for the universe and then a supercomputer can
simulate how the universe evolved. How do we trust any of this? While there are reaches of the universe
we have yet to explore there are many regions that we do know. So the supercomputers results are
compared to the parts of the universe we do know and they match up really really well.
A key in the simulation is its integration of dark matter. That's essential because dark matter
accounts for 25 percent of everything in the universe and about 80 percent of all matter.
The simulation covered a massive chunk of the universe. The simulation was also massive in scale.
If you think about it it would have to be to have such good results. It simulated the interactions
of 8.6 billion dark matter particles. It took a lot of computing time over 6 million CPU hours
to complete. But it was a supercomputer so things are done in massive parallel.
So even though 6 million hours is over 380 years it can be done. 380 years ago was pretty close
to when Isaac Newton was born. But supercomputers run simulations in parallel across many processors
and can solve otherwise intractable large-scale problems in an acceptable amount of time.
Simulation is a powerful tool in our world. It can help us model, understand and predict
behavior that could otherwise be dangerous or impossible to model. The key here is to emulate
an essential feature using a computer. If that's possible you might be able to simulate it and
then study your simulation. That is how certain predictions we see and hear all the time are
made. The weather forecast is a vast simulation. When you watch the news and they show how you
know the weather should unfold for the day, remember that's a simulation. Many dynamics go into this
and that's why sometimes it isn't right. But five-day forecasts are now as good as two-day
forecasts were two decades ago. So remember there is a lot of science and mathematics enabling us to
understand what's happening every single day. Simulations are everywhere. MAT and NFL use
simulation to correctly predict 8 of 11 super bowls between 2004 and 2014. Computers predict the
aerodynamics of a car so it can be altered and honed before it is ever built. And simulations
can represent outbreaks of fires to help predict where they might spread. So we don't always have
to study numbers from the actual physical phenomenon. And even when we begin with actual data we don't
have to stop there. Sometimes we learn more with a simulation.
