the available features of your data.
Other times, you might decide you need to add an attribute, some data you hadn't collected
before.
Other times, you combined data.
For example, in basketball, sports analysts often look at what percentage of your possessions
you have turnovers, rather than simply how many total turnovers you might have.
In his 2012 book, Best Practices in Data Cleaning, Jason W. Osborne stated that recent surveys
of top research journals in the social sciences reveal that many academic authors are not
suitably concerned about dirty data.
A prominent study of 17 educational and psychology journals by Kesselman and colleagues in 1998
found that often 10 percent or less of the authors were looking at issues of dealing
with dirty data.
A later study from 2008 showed, again, that authors were not indicating sensitivity to
issues in cleaning data.
For example, only 26 percent reported on the reliability of data being analyzed.
The main problem is that most statistical tests may not be robust or reliable with dirty
data, at least to the degree that researchers might hope.
It's the same confused thinking that Charles Babbage reported.
If you put into the machine wrong figures, will write answers come out?
No.
But even if you've done everything right initially, similar problems can pop up later.
To demonstrate how things can quickly and almost unexpectedly go astray, I'll close
with an example from my own work.
I've conducted research in sports ranking.
Given the scores of games, how should teams be ranked, in particular to predict the outcomes
of future games?
I've spoken to various audiences around the United States about this work.
One of my favorite things is to show an audience how to create their own ranking method.
They're learning how we do it, live, during the talk.
If I have enough time, I even download data right then, so we're using a ranking method
created right then by the group with data that is as current as possible.
I've done this many times.
It's fun for the audience and for me, so I was really looking forward to this when I
spoke to a group of New York City public school teachers.
There we were on a cold December Saturday morning.
We developed a method, decided on parameters that customized it for our personal ranking
system, and then I downloaded the data.
Now, we get to see how we've done, I said.
I pressed the rank button and the results were returned.
