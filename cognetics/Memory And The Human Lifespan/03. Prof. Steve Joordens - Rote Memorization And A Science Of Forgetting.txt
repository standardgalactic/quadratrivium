Lecture 3
Wrote Memorization and a Science of Forgetting
Applause
If you really want to remember a lecture, you could listen to it over and over.
Suppose you listen to a lecture ten times.
How much more likely do you think you would be to remember that?
How much longer do you think you would remember it?
Well, in the previous lecture, we looked at what's sometimes called the art of memory.
Essentially, pre-scientific ways to be smart about how to use your memory.
Pneumonic strategies such as the method of loci have been relied on, well, since the classical period.
They especially enhance episodic memory.
What all of these sort of art of memory techniques have in common is that you spend extra effort up front.
You need to use organization, association, and dual coding.
And that extra effort pays off by producing a deep and strong memory trace, even for random stimuli.
But when you are listening to a lecture, you want to acquire and remember general knowledge.
And for that, traditional and most basic memory technique is quite different.
Whether with a book or a lecture, the most basic way to remember general knowledge has been traditionally to repeat it over and over and over.
What is called rote learning or rote memorization.
Rote memorization is interesting for two reasons.
First, it has an interesting past and present.
And to some extent, it provides a fantastic basis for comparison with the art of memory.
Second, it also turns out that rote memorization played a key role in the science of memory.
In the sense that the very first experiments that were performed were actually performed in the context of rote memorization.
Thus, the subject of rote memorization is a great complement to what we've already learned,
and it makes a natural transition from pre-scientific approaches to the study of memory
to the scientific studies that we will be focusing on for the remainder of this course.
Rote memorization is very different from mnemonic strategies and from the art of memory.
Rote and mnemonics almost seem like opposites.
Mnemonic strategies require plenty of upfront effort, but thereafter, the memories are retained, well, almost effortlessly.
But by contrast, rote learning seems to require lots more ongoing effort, although the effort at any given time is less.
All that ongoing effort is why some parents and teachers like rote learning,
even apart from how well it works as a memory technique.
So anyway, rote is different, and that difference results in rote memorization being more strongly associated with semantic memory,
our general knowledge of the world, things like the number we get when we multiply 4 times 6,
or the knowledge that the panhandle state is named Florida.
So how did we come to know these things?
Well, mostly we learned them just from hearing these facts repeated over and over.
This repetition of facts often occurs in different contexts,
but it may even occur in a very specific context such as when a teacher drills us on the multiplication tables.
But usually it occurs because we have simply heard those facts repeated in many different contexts.
But perhaps we've heard a number of different people refer to Florida as the panhandle state.
Now, of course, if you hear some claim enough, you eventually believe it's true.
If you hear some claim enough, you eventually believe it's true.
Sorry, that felt like it bears repeating.
But of course, it is true.
When you hear something enough, it becomes committed to memory, semantic memory,
and it becomes part of our general storehouse of the knowledge of the world.
Over time, we often forget the specific context in which we heard it.
It just becomes a fact.
Now, this is why politicians, of course, like to repeat their so-called talking points
and why a given political party will often send a number of its members
to utter the same talking points across a variety of news formats.
This repetition across a variety of formats,
when it's combined with variation of the details of where we heard the message,
makes it seem even more like the truth.
So this relationship between repetition and memory has deep roots,
probably going back to human beings even before the invention of writing.
We do know that rote learning was very important once writing had been invented.
As you know, most religions have some book they consider sacred.
It's the Bible for Christians, the Torah for Jews, and the Quran for Muslims.
Prior to print, there were only limited copies of these texts in existence,
not enough for every religious scholar to have their own copy.
In addition, just reading the text aloud posed a challenge,
given that writing didn't yet include such conveniences as spaces to separate words,
or commas to separate phrases, periods to separate sentences,
or anything like paragraphs or sections.
The letters just went on and on.
Reading today is far easier than it was in ancient times.
So even for the purpose of just reading aloud,
having some familiarity with the text was a really big help,
and verbatim memorization, well, that was even better.
So traditional scholars would literally read passages over and over
in an effort to become more familiar with the text,
as well as to commit more and more of the precise wordings to memory.
In some cases, those who were able to memorize the entire religious text
were afforded some sort of special status.
For example, one who's memorized the entire Quran is known as Hafeez,
which literally means a guardian, a guardian of the word of Allah.
However, as printed books spread,
the premium placed on memorizing an entire book gradually declined.
On the other hand, a premium for learning specific facts begin to rise.
By the 19th century, there was an extraordinary passion for rote memorization of specific facts.
We can see that strong emphasis on rote memorization in many parts of the world, even today.
And rote memorization still remains part of our educational system, too.
For example, our multiplication tables in mathematics,
in the periodic tables in chemistry, they're still both often taught with rote memorization.
However, in North America, our education system has kind of moved away
from a heavy reliance on rote memorization,
and instead is emphasizing deep learning strategies a little bit more heavily.
We'll see reasons for that both within this lecture and elsewhere in the course.
But in the 19th century, rote memorization had a very special place
in the Victorian era on the European continent.
At that time, a keen ability at rote memorization was viewed as, well, essentially as a virtue.
One who was able to recite poetry from memory was highly regarded,
notion being that they had to put a lot of work into that,
and they must have a true strength of character to do that.
It's fair to say that if you lived in Europe during the Victorian era
and if you were interested in memory, you likely viewed rote learning
as a viable method for getting information into memory.
Now, this is an important point because it is within this context
that the very first scientific research of memory began.
This work was by a German psychologist named Hermann von Ebbinghaus.
Now, before we talk about the details of Ebbinghaus's work on memory,
let me situate it within the context of psychology as a science.
While a philosophical interest in the mind dates back to ancient civilizations,
the birth of psychology as an independent science did not really occur
until, well, the mid to late 1870s.
At that time, Wilhelm Wundt established the very first dedicated psychology lab in 1879.
It's less than 150 years ago.
Now, this late birth is primarily due to a resistance by humans
to view human behavior as determined by material processes,
processes open to understanding via scientific inquiry.
Given this resistance, nearly all of the early psychologists, Wundt included,
focused their research on the study of perception,
our ability to internally represent external events as they occurred.
In many ways, perception can be viewed as one of the very first steps
of a mind's interaction with the environment,
and one that's really not too far removed from the scientific study of external objects,
that is, physics.
In fact, many of these first psychologists refer to themselves as people studying psychophysics.
So, perception was really a cautious first step into the scientific study of mind.
In fact, virtually all of the earliest psychologists also studied perception.
However, the hero of our current lecture, Hermann von Ebbinghaus, was a bolder scientist.
Ebbinghaus was interested in memory.
Now, memory is a somewhat abstract concept,
and it was definitely quite far removed from the sorts of topics
that had been scientifically studied prior to Ebbinghaus' time.
There were some serious questions about whether one could even scientifically study memory at all,
and Ebbinghaus was determined to show that yes, one could,
and if one could study memory with empirical rigor,
well, then perhaps one can study any aspect of the mind.
Ebbinghaus was specifically interested in a few questions about memory.
How long does it take us to learn something?
How long does it then take to forget those things?
And when we seem to have forgotten something, have we really forgotten it?
Well, in 1885, at the age of just 35, he published his first scientific book,
and it's the very first scientific book on memory.
It was translated as memory, a contribution to experimental psychology.
Now, recall that Ebbinghaus lived in the Victorian era.
Again, this was a time when the conception of memory was heavily influenced
by the process of rote memorization.
Thus, it should not be surprising that the experiments he performed reflect this influence.
Ebbinghaus began his research the same year that Wundt had opened
the world's very first psychology lab over in Leipzig, Germany,
and Ebbinghaus was just as determined to approach memory in the same scientific way.
So to get a sense of this, one really only needs to consider the procedures that he used.
Now, Ebbinghaus didn't have a lab.
At the start of his research, he didn't even have a full-time university position.
So he kind of knew from the outset that if he wanted to study memory,
he was going to have to study his own memory.
So his plan was to see how long it took him to learn various materials,
then how long it took to forget what he had learned,
and then how long it took him to relearn what he had apparently forgotten.
But what sort of material would he memorize?
Well, for Ebbinghaus, words would not do.
He saw them as really possessing way too much baggage,
too many pre-existing associations with other words, with images, with our lives.
Now, of course, in the mnemonic strategies that I discussed earlier,
I emphasized how images and associations could be used to enhance one's memory,
but this is exactly the sort of thing that Ebbinghaus did not want to happen.
He viewed such things as complicating factors,
and he wanted to eliminate them in order to study a more pure form of the processes related to memory.
So instead of using words, he created nonsense syllables,
and these were composed of a consonant, a vowel, and a consonant.
So these were items like NIM, N-I-M, or COP, K-O-P, or LEF, L-E-F.
He saw these items as much more neutral,
and therefore more appropriate to use in the context of a scientific investigation of memory.
So he first created a very large set of these consonant, vowel, consonant strings,
essentially put them in a hat.
During a learning phase, he would then pull out syllables and write them down in a notebook,
perhaps creating a list of, let's say, well, 20 items or so,
and this would be his learning set.
He then read them aloud one at a time in a neutral voice to the beat of a metronome,
trying to remember them as he did so.
Now, to give you a sense of this, let's imagine Ebbinghaus learning a list as follows.
Here's our metronome, okay, and you would see Ebbinghaus doing something like this.
Gek, Pob, Nis, Vot, Rup, Tog, Beck, Chem, Lun, Hib. You get the idea.
Clearly, he was using rote memorization to encode the items.
He would then go through his list fully, and then he would attempt to recall the list.
He did this repeatedly over and over until he could correctly recall the list twice in a row,
and then he recorded how many repetitions it took to get to that point.
That was his measure of learning time.
Now, for his experiments on forgetting, he would learn the list well enough to recall it twice,
and then he would just put it away.
He would literally try very hard not to think about it in any way,
and then after some amount of time passed, he would attempt to retrieve that list from memory
and would score himself in terms of how many items he could recall.
He did this over and over with different lists and allowing different amounts of time to pass,
really anything from, well, 20 minutes to 31 days.
And by looking at his accuracy, then, he was able to examine how much information he forgot as a function of time.
By doing so, he ultimately produced the forgetting curve, a depiction of forgetting over time,
and one that he is now actually quite famous for.
What's more, he was also able to calculate the formula suggested by the forgetting curve,
a mathematical function that captures forgetting.
Now, this was really important because by kind of adding math to this,
he was providing very compelling evidence that memory processes could be quantified experimentally
and that they seemed to follow natural laws that conform to mathematical description.
So that was very important.
Many of the early psychologists were trying to show they could study psychology scientifically,
and here was Ebbinghaus doing exactly that in the context of memory.
So that was fantastic.
Now, one startling aspect of Ebbinghaus' forgetting curve was that he himself, at least,
tended to forget half of the information he had learned really just in a matter of days or weeks.
He forgot the rest more slowly, but still, memory was obviously decaying exponentially,
with most of the losses occurring almost right away.
So that said, Ebbinghaus also showed that part of the steepness of this curve,
or I should say the onset of the curve, was due to the fact that he had used these nonsense syllables,
these CVC strings.
When he instead tried it with words, he found that he could retain his original level a little longer,
but when memory started to drop, it still dropped precipitously.
So there was still roughly an exponential drop, it was just shifted a little later in time.
Now, keep in mind that even when Ebbinghaus used these meaningful stimuli,
he still encoded the information in a rote memorization fashion.
So, while the meaningfulness of the stimuli may have sort of spontaneously brought to mind images or associations,
Ebbinghaus certainly didn't try to strategically use this information in any way.
Definitely nothing like the way we described in the lecture in Pneumonics.
So, yes, the forgetting curves look pretty ominous,
but they depict relatively extreme cases of really pure rote memorization.
Memory for real-world experiences is likely not as dramatically affected
as we tend to process stimuli in a deeper, more meaningful way.
Now, that said, even in the context of much richer real-world stimuli,
we can still often feel like we forget things very quickly after we learn them.
For example, given that you're watching or listening to this course,
it's quite possible that you have experienced other examples of the great courses.
Have you ever had the feeling that while you were learning a lot at the time,
you seem to have forgotten virtually everything you learned within days after watching or listening?
Perhaps you've also had that feeling with books.
As you read them, you think, ah, that's an interesting part.
I want to remember that.
But then after you've read the book,
you don't feel like you can remember any of those interesting parts.
Why can we no longer remember information after learning it?
Is that information really gone?
Is memory really so fleeting?
Well, Ebbinghaus did not go into detail about why we forget
or at least why we fail to recall information.
But subsequent research has suggested a number of relevant possibilities.
One reason people fail to remember some experiences
is because they just didn't encode it well enough in the first place.
In fact, this is a very common reason.
For example, you may find that you need to listen to a lecture more than once
just to encode it properly.
But in the case of Ebbinghaus's experiments,
we know that he made sure he could first recall the list twice,
at least right after learning it.
So even though his approach to encoding might have been, well, not so rich,
pretty shallow at some level,
it was still rich enough to support memory just after learning.
Still, I mean, had he tested himself more than twice
or had he distributed his learning over time a little bit more,
he presumably would have come closer to the long-lasting results
we get from practicing something many times.
The kind of results we get, for example,
when we use rote memorization with multiplication tables.
Another concept, though, that's sometimes presented when thinking about forgetting
is the concept of decay over time.
So as we think about forgetting,
this is sort of the natural thing we sometimes want to say,
that memory just decays over time.
It's important to note, though, that time itself doesn't cause decay.
It really just provides a temporal space
in which other processes might occur.
So, for example, it's not really correct to say something like,
the pyramids are deteriorating over time.
The pyramids may be deteriorating because of sandstorms
and the friction from the sand, you know, slowly eroding them.
But that sort of process is one that unfolds under time,
and that's the true cause of the degradation, not time itself.
So when we get to memory, then, we want to do the same kind of thing.
What is it that's actually causing a decay in memory?
Well, there's really kind of two processes that people talk about
that hold promise for us getting a better understanding of forgetting.
The first process is called interference theory, the second one, retrieval theory.
Interference theory suggests that sometimes experiences that occur,
either before or after we have some experience,
can interfere with our abilities to remember.
So let me give you an example to make that clear.
Suppose you take a French course for the first time,
but then you switch to a Spanish course.
Having started on a similar language might help you in some ways,
but you may also feel that learning Spanish was a little bit more difficult
because some of the details you learned in the French course keep coming to mind.
This is called proactive interference,
and it's when a memory from the past messes with your ability to remember something subsequent.
Or suppose you learn French well, set it aside, and then you learn Spanish.
You might find that when you try to go back to French,
you have some Spanish words sometimes coming to mind instead.
This is called retroactive interference.
It's when a memory for a later event interferes with your ability to remember some earlier event.
Okay, so the point is that sometimes interference effects of this sort
can make it difficult to either remember or to separate similar sorts of experiences.
Now, while interference can explain how two similar experiences
can reduce the ability to kind of separate and possibly recall either one,
it doesn't explain why we sometimes have trouble remembering something
when we haven't subsequently encoded anything similar.
And that's where retrieval failure seems to hold the most promise as a general explanation.
Okay, here's how I explain retrieval failure to my students.
Imagine you're the sort of person who changes clothes several times a day,
and every time you change clothes, you just toss the dirty clothes on the floor after each change.
You do this day after day, and eventually what you have is a layer of clothes on your floor.
Okay, now one day you want a shirt, a shirt that you wore many days ago.
But when you look at your floor, all you can see is a mass of clothes
with the clothes that you wore most recently on the top.
Is that shirt you want gone?
Well, no, it's not gone, but it may seem to be gone.
It's there somewhere, but if you don't know where to look,
it might take you a really long time to find it.
It's not gone, it's just buried under the new clothes.
And the only way to get it is to search all the way through them.
Depending on how large your floor is and how many clothes you've tossed on
over the shirt that you want, the search could be very difficult.
Unless you know something about where it is, something that helps you look for it,
it could seem like you just can't find it.
It could seem to be gone.
Well, memory encoding never stops.
It keeps encoding and it keeps putting things into memory.
So it's kind of like the clothes being thrown on the floor.
If you encode some new experience but then don't think about it for a bit,
it also can eventually become buried under the new experiences that you encode afterwards.
As time progresses, these new experiences build up
and the older experience becomes more and more buried.
Before long, that experience may seem to be completely gone
unless you know where to look.
That is, unless you have a good retrieval cue to guide you in your memory search.
If you don't, you may not be able to retrieve it at all.
It may seem like the information is forgotten when, really,
it is just impossible to get to without the right cue.
Okay, Ebbinghaus didn't propose retrieval failure,
but he did perform additional experiments that really fit with the notion well.
Recall that when he had learned to list originally, he noted how long that took him.
Then he put it away for some period of time
and tested himself to see how much he could remember.
All that formed the basis of that forgetting function that I told you about earlier.
But here's the new twist.
Once he had put a list aside, brought it back, tried to recall it,
then he went about the task of relearning it.
That is, just like he had done originally,
he went through that list one at a time with a metronome
and counted how many repetitions he needed to relearn that entire list,
once again to the point where he could recall it twice in a row.
And what he showed was that he could relearn that list much faster,
much faster than it had originally taken to learn,
and he referred to that difference as savings.
Now, this finding was important for two reasons.
First, there were perhaps the first experimental results
that suggested a distinction between knowledge that is conscious
and knowledge that is not.
After all, after some period it was as if some learning episode was futile,
simply because you could not bring it to mind.
It felt like it was gone, but clearly it wasn't gone.
It was there.
It just could not be consciously retrieved.
So that was an important implication of his results.
Second, on a more practical level,
it means that even if you cannot remember some experience,
even if it seems to go away after just a few days or weeks,
that does not mean the experience was in vain.
The knowledge is potentially there.
In fact, it's probably there.
And should you ever need to, you could bring it back,
perhaps quite quickly with just a little bit of relearning.
In a sense, if you find that shirt you were looking for
and toss it back on top of the pile,
it will be easy to find, at least until you bury it again.
And that should come in some consolation at least.
Maybe you don't remember all of the details
of the courses you've watched or listened to,
but really that information is sitting there in your brain
and it's just waiting to be refreshed.
Okay.
So let's take a moment now to integrate what we learned
about mnemonics and the art of memory in the second lecture
and what we've learned here about rote memorization
and the early science of memory.
If we are willing to do some serious mental work
when we experience some new information,
we can encode it in a way that organizes the new information well,
associate it with things we already know,
and maybe even store multiple copies of it.
If we do all that work,
it will make it possible to remember that encoding experience.
And it does so in a way that gives us really strong access
to the new information,
even though we've only encoded it once.
That's the art of memory.
Now, in contrast, rote memorization relies on heavy repetition
of information to literally stamp that information
into our memories.
Because the repetitions occur over several distinct episodes,
we don't tend to recall the specific episode.
Instead, we just remember what we learned.
Often in a very precise or verbatim way,
that information becomes part of what we simply assume to be true,
and this sort of memory is called semantic memory.
Now, there are times when both forms of memory enhancement
can be useful, and we want to combine these, perhaps.
So let me give you an example of that.
Let's consider actors learning their parts for a play.
Now, the actors must learn very specific lines, of course,
but they also have to learn specific movements.
They have to be on certain points of the stage at certain times.
So maybe just like the ancient Romans,
they could use these places as loci.
Each location, then, could be used as a sort of trigger word.
If they're associated a word with each location,
then when they're at that location,
that trigger word could be used to cue them
about the gist of what they wanted to say.
However, just like the religious scholars of old,
they, of course, can't just give the gist.
They have to speak the precise lines.
So given this need for specificity,
rote learning might be the best way to memorize the necessary lines.
So they could use the method of loci as the cue
that begins a set of lines learned by rote,
and this is a beautiful orchestration
of different memory enhancement techniques.
Now, of course, this is true not just for actors,
but for remembering more generally.
And you can try this yourself.
Start looking for ways to combine
the memory enhancement techniques we've discussed so far.
First, look for episodic cues you create for yourself
and the more vivid the better.
For instance, if you're going to use flashcards
to do some rote learning,
start by trying to create vivid mnemonics for each flashcard.
Or suppose you want to remember a lecture better.
In that case, you could take the time to do some deeper encoding.
That is to organize the new information well,
associate it with things you already know,
and maybe even store multiple copies of the information if possible.
Then you could try to use vivid cues you've already created
even when you go back to the material.
That combination of vivid episodic cues,
together with additional episodes provided by rote learning,
will transfer an already durable episodic memory
into a semantic memory backed by multiple episodes.
But multiple episodes doesn't mean listening to the same lecture ten times.
Most of the episodes helping you remember can come from
thinking and talking about the material yourself.
So in general, the key to creating a very long-lasting memory
is to use more than one memory system.
So in the next lecture,
we'll begin the discussion of our memory systems in much more detail.
Yes, Ebbinghaus got the memory research ball rolling in the late 19th century,
but no researchers really followed his lead until much later.
Specifically, many continue to see memory as too vague a concept
to think about scientifically,
despite the data that Ebbinghaus provided.
Even Ebbinghaus himself switched his research to perception later in his career,
who turned instead to a study of color vision.
So the scientific approach to human memory that Ebbinghaus pioneered
really laid dormant for eight decades until the late 1950s.
That's when research on human memory suddenly began to flourish.
So let's hop in our time machines,
let's set the dials for the late 1950s,
the heyday when memory research really began to take off,
and let's see what they were doing then.
APPLAUSE
