There is nothing wrong with your television. Do not attempt to adjust the picture. We are
now in control of the transmission. We control the horizontal and the vertical. We can tell
you with a thousand channels or expand one single image to crystal clarity and beyond. We can shape
your vision to anything our imagination can conceive. For the next 30 minutes we will control
all that you see and hear. We are exploring the outer limits. Programming anyway. Beyond linear
programming. We're doing nonlinear programming. In the last lecture we developed our intuition
about nonlinear optimization problems and how to go about solving them. We used the conceit of a
physical landscape to guide our thinking. This lecture is the nuts and bolts side of nonlinear
programming. Examples of how you really do it and how our work from last time can help us select a
good approach. I've chosen two practical problem areas for today. Locating facilities and retail
pricing. We'll formulate a couple examples of each and discuss why a particular nonlinear technique
may or may not be the one for the problem. Our final pricing example will be looking at a system
similar to those used by warehouse clubs like Costco. In the process we'll gain some insights
into what makes Costco such a successful retailer. But our first set of problems deal with facilities
placement. Addressing the challenge of finding the best places from which to conduct your business.
And it's an idea that we'll start with with Delta Airlines because it let them move from a small
regional company to a major competitor in the US airline industry. You see if an airline serves
more than a few airports providing direct flights between every pair of airports that it serves
is unworkable. It's simply a matter of the numbers. Connecting three cities with direct flights takes
three flights in a triangle or six given that you have to fly both ways. No problem. But connect
30 cities with direct flights and you'll find you need 930 flights and that number grows rapidly as
the number of airports increases. The solution that seems so familiar now was a new one in 1955
when Delta Airlines first pioneered the hub and spoke model. Atlanta was the hub city. If you
wanted to go from A to B you went from A to Atlanta switched planes and then flew from Atlanta to B.
Flights from California, New England, Texas, Florida you name it. Flights from everywhere
routed through Atlanta and many still do today. Adopting this model made Delta a real competitor
with Eastern Airlines. Since that time all of the major airlines have adopted a similar system.
Since those early days Delta has also expanded to have additional hubs in Cincinnati, New York,
and Salt Lake City leading to a multi hub map that's much more complicated while extending
this same hub and spoke approach. The decision to where to place the hubs takes into account a
number of factors of course but important among them, very important, is the goal of minimizing
the total number of miles in the hub and spoke system. A slightly different goal would be given
the airports that are going to serve and the number of people flying from those airports,
what location of the hub airport would minimize the average number of miles
flown by a passenger in the system. I grant you there might not be an airport at this perfect
location but if we can figure out where we'd like to have our hub we can look and see what
existing airports might be close to that location. If this problem sounds somewhat familiar, good for
you. It has a lot in common with our retirement home example from two lectures ago. The problem
there was given the location of retirement homes in a city figure out where to build the treatment
center coming into the mall. And that problem distance between a home and a center was measured
in taxi cab distance, the shortest path from one place to another using a combination of only
horizontal and vertical segments. We did that because that's how the roads ran in the city.
That made the math more messy but at least our formulation was still linear so our earlier
techniques applied. But for the airport problem, things are different. Distances as the crow flies,
straight line distance from the regional airports to the hub. And the math that gives the straight
line distance between two points is essentially just a Pythagorean theorem. For example, if the hub
is at the coordinates x, y, and the regional airport is at 10, 20, then the distance from
the hub to the regional airport is x minus 10 squared plus y minus 20 squared, the square root
of all of that. Those squares in that square root make the expression decidedly nonlinear
and minimizing average distance is going to mean taking a weighted average of the distances from
the hub to each regional airport weighted by how many people are traveling from and to each
regional airport. So that's a nonlinear objective. The good news is that I have essentially no
constraints here, no limitations on where to build the hub. If possible, we'd like to anticipate
whether this problem is going to be tractable to a solution or a pain in the butt. Well, we saw last
time that in a real sense the line between sure to be fairly easy and maybe not so easy doesn't
really hinge on linearity so much as on convexity. In general, it can be a fair amount of work to
figure out whether a function is convex or not, but there are a few helpful rules that you can
keep in mind. They act kind of like a toolkit for building convex functions and be surprised
how often they apply. First, linear functions themselves are convex. Second, an even power
of a variable is convex like x squared, x to the fourth, and so on. And so is e to the x. Third,
if you replace a variable by a linear expression in a convex function, it's still convex. So 3x
plus 4y plus 2 squared is linear. I'm sorry, it's convex because x squared is fourth. If you take a
weighted sum of convex functions, it's still convex as long as none of the weights are negative.
So 0.3x squared plus 0.4y minus 6 squared is convex. And finally, Euclidean distance,
that is straight line distance, is convex. Our objective in the locate the hub problem
is to minimize a weighted average of the distance of the hub to each regional airport. Euclidean
distance we just said is convex. So the objective is a weighted sum of convex functions with each
weight being non-negative, namely the fraction of the travelers who hail from that city. By our
rules for convexity, that means our objective, while non-linear, turns out to be convex. So we have
a solid ball problem, and a gradient-based technique is guaranteed to find the global
minimum for this. And Excel, for example, the standard non-linear solver will do the trick.
And the model is actually pretty simple. Let's take a look. We start out with the data on the
cities served by our airline. I'm giving their location by specifying how far east and how far
north they each are from an arbitrary reference point. I'm using Houston, Texas, as that point.
The red cells below this are our destination, our decision variables,
specifying the location of the hub. Again, with Houston as the origin.
From this, we can find out how far each regional airport is from the proposed hub.
That's just the Pythagorean theorem. We record these in the distance to hub column.
Finally, the weighted average of these distances is computed at the bottom of the sheet,
using the populations of the cities, in millions, as proxies for the amount of air traffic in and
out of each city. This objective minimizes the total number of miles that customers have to fly,
rather than the total number of miles in the hub and spoke system. The logic behind this is that
a spoke with more traffic would need more planes per day. Alternatively, we could instead simply
minimize the sum of the numbers in the distance to hub column. The resulting location is still
in the same vicinity in this particular case. I told Solver where the variables are and where
the objective is, just as we did for linear programs. I didn't have to impose any constraints,
since we didn't have any. The hub's allowed to be built anywhere. The only thing new was that I
told Solver to use the GRG nonlinear solving method, rather than the simplex LP method.
This is a gradient technique like we talked about last time. In fact,
GRG stands for Generalized Reduced Gradient. The answer comes out very quickly, as we expect
with this kind of convex problem, and here it is. It says that the hub should be built
628 miles east and 221 miles north of Houston. The graph makes it a little clearer. That is,
we'd like our hub to be about 63 miles southwest of Atlanta. Just like Delta Airlines,
we like the idea of Atlanta as a hub. Okay, suppose we wanted to take this problem to the
next level. How would we do it? Well, clearly, the real-life problem involves many more airports,
but that's just a matter of scaling. Our work ignores the curvature of the Earth. For a more
accurate distance model, we'd need to use something like the Haverstein formula from
spherical geometry to compute the distances from the longitude and latitude. It's a messy formula,
but conceptually, it's no harder than what we did. We might decide to minimize the cost of
the number of miles flown per day by the airline subject to meeting all of the demands. That could
involve integer decision variables for how many flights were needed for each link. But there's
a more substantive change that would occur when Delta grew and established new hubs. The Atlanta hub,
we could imagine, would already be established, but now we'll be looking for the location of new
hubs. The distance calculations wouldn't be any harder than before, but there'd be more,
there'd just be more of them. But a new factor would appear. Namely, now our regional airport
would be assigned to some specific hub. Its distance from the other hubs wouldn't matter.
This would mean a 0-1 variable for each pair of regional airport and hub,
answering the yes-no question of whether that airport goes with that hub. 100 airports and
four hubs would mean 400 integer variables, and 100 constraints, one for each regional
airport, saying that it has to get assigned to some hub. You can see why it can be smart to
size up a problem before you get too committed to one approach. Do we have an alternative in this
case? Well, let's think about it. Linear programming is out, of course. The objective is nonlinear,
but since we have no constraints here to begin with, we might want to consider a genetic algorithm.
They hate all but the simplest constraints, upper and lower bounds on decision variables,
but other than that, they allow almost unlimited flexibility and formulation.
For example, we'd need only one integer variable for each regional airport,
giving the number of the hub to which it was assigned, like hub number two.
So let's expand the problem to include multiple hubs and approach it with a genetic algorithm.
They can be slow, but I wouldn't expect that to be a problem here. Let's say that we'll have up to
four hubs, and that each hub has to be at one of the cities that we serve.
This restriction is desirable from a practical standpoint. Its addition will actually make
the problem easier to solve, too. We don't need the coordinates of a hub now,
just the city where the hub is located. For this example, I've picked 29 large U.S.
cities for our airline to serve. Our system will have multiple hubs,
with each regional airport being a spoke attached to one of the hubs.
Our goal will be to minimize the total number of miles in the system.
And finally, I'm going to make what seems to me to be a reasonable assumption
that each hub has to have direct flights connecting it to each other hub.
If not, then passengers might have more than two transfers on a domestic flight,
and I don't want that. I'm also going to take a different approach to distance,
getting it from a table of distances from city to city.
Here's the beginning of my table, with distance given in miles. Atlanta's a little over 1,300
miles from Austin, and so on. The information is much easier to obtain
than the compass point mileage coordinates from Houston, that I used in the last example,
and that troublesome curvature of the Earth is no longer an issue.
It does mean, of course, that I'll have to find a way for the spreadsheet to find the distance
from A to B from a table, but Excel actually has lots of functions for this sort of thing,
like index, or the lookup. And since I'm using a genetic algorithm,
I can use any such functions I want. Okay, so we'll begin like this,
with a specification of our four hubs. Each city is identified in our table with an integer,
and I've temporarily put the hubs at cities 1, 2, 3, and 4, from my table Atlanta,
Austin, Baltimore, and Boston. To make it easier for a user to understand,
I also had the spreadsheet report the names of the hub cities as well.
If you're interested, I use the index function for this, a very useful function in picking out
values from the sheet. I also have a variable for each regional airport,
specifying to which hub it'll be assigned, like this. So for example, look over there at city
number five, Chicago. It's assigned to hub one, which for now at least is Atlanta,
and so on for the rest of the 29 cities. As always, the values that I put in the red cells
don't matter. Later, I'm going to tell Solver that their decision variables,
and that they have to be integers between one and four, because there are four hubs,
one through four, and that's going to do it. But because I'm using a genetic algorithm,
I would have to have another, I would have another choice here. Once the hubs are determined,
the problem is going to have the optimal solution if each city is assigned to its nearest hub.
That is, I could tell the spreadsheet to compare the distances from this regional airport to each
of the four hubs, and then to choose the hub that's closest. Insisting on such a nearest hub
assignment would reduce the problem, the variables that one needs in this problem, to only four,
the hub locations. The nearest hub calculation for a given regional airport would involve finding
the min of four numbers in the spreadsheet. Something could cause us problems in a gradient
descent approach, because that operation is not differentiable. But once again, genetic algorithms
don't care. Nevertheless, I'm not going to require an assignment to the nearest hub. I like the idea
that we could come back and modify this problem later if the need arose. Perhaps, for example,
we find that we're overloading one hub, and so we might want to occasionally assign a regional
airport to a more distant hub. So each regional airport has a variable specifying its assigned
hub, and the sheet reports the distance between that airport and its hub. This distance is looked
up with an index command in the spreadsheet, much like we looked up the city names. Okay, nearly done.
We have to compute our objective from this assignment. The total size of the flight system.
The total distance from the regional airport to their hubs is trivial. We found each distance for
each regional airport, and we'll just add them up. Surprisingly, a more annoying part to put in
the spreadsheet is the total distance of direct flights that connect each hub to all the others.
With four hubs, there are six different pairs of hub cities, and adding up those distances is
straightforward, but I want my spreadsheet to be a bit more flexible. After all, maybe it's better
to use fewer hubs. If the sheet chooses the same airport for hub one and hub two, then the distance
from hub one to hub four is the same as distance from hub two to hub four, and that distance should
only be counted once, not twice. It's actually a good problem to figure out how to efficiently
decide the total inter hub distance, but I'll leave that as an exercise for the interested
viewer and include at least one solution in the guidebook. So the size of the hub and spoke system
will look like this. Start with the total distance between regional airports and their hubs, the total
spoke distance. Add the flights among the hubs, the inter hub distance. That gives us the total
distance in the network, the total system length, and that's what we're trying to minimize. The values
shown are for the random values that I typed into the decision variable cells to begin with.
All that's left are for the solver details. I told solver that all of my variables for integers,
that the hubs had to be cities numbered between one and 29, and that all regional airports had to choose
a hub between one and four. Remember that genetic algorithms want simple numerical upper and lower
bounds on variables. Those are the only constraints, which is good, because genetic algorithms don't
like constraints. I don't expect this problem to be that hard for solver because of the fact that
once the hubs are selected, there's very little left to do. But I want to make sure to get a good
answer. So in solver, I hit the options button and entered large values in the solving limit boxes,
a population size of 500, up to 300 sub problems, and 300 feasible solutions, and so on. And then,
I turned solver loose. They came up with an answer in a minute or so using only two hubs,
Atlanta and Las Vegas. Everything from Denver to the west went to Las Vegas,
and the eastern part of the country all went to Atlanta. Total distance, 26,864 miles.
But I let the evolutionary solver keep running in case there'd be any further improvement,
and after a couple of minutes, it did find a better answer. This one. It uses three hubs,
Las Vegas, Memphis, and Baltimore. Each regional airport, of course, flies to the nearest hub,
as suggested by the shading on the map. This new configuration shaved 2,000 miles off the first
one, and the genetic algorithm suggested that the genetic algorithm suggested. That's an 8%
improvement. I can't swear there's not a better one, of course, one of the drawbacks of a genetic
algorithm. But it's the best that I found in several runs, and letting the algorithm run for about 10
minutes each time. I'll leave this example at this point, but you might want to think of some other
practical possibilities. The volume of traffic in a major city, for example, might make it worth
flying from there to more than one hub. We could add this to our program or use the program's answer
as a starting point. Optimization problems don't replace a human decision maker, but they can
help that decision maker do a better job. But let's move on to retail pricing and see what's
going on there. Start with the basics. Profit is revenue minus cost, and the revenue depends on
two things. How much you charge for an item and how much of you sell at that price. How much you
sell depends on your supply of that item and the demand for it. No problem so far. Take each price
per unit, multiply by the number of units sold, add them up, and you got the revenue. But in a
pricing problem, your prices are decision variables, and the number sold of them almost certainly depends
on its price. That means that to find the revenue for a given item, you have to multiply its price
by a function that depends on that price. And that makes it a nonlinear expression,
so linear programming isn't likely to be of use to us here. How about gradient descent? Well,
if your demand varies smoothly with a change in selling price, you should be okay. We talked about
gradient descent in terms of solving a min problem, and this is a max, but you can use our logic from
the last lecture. You just have to turn the landscape upside down before you get started.
Maximizing revenue is the same as minimizing the negative of the revenue. In fact, if your demand
is linear in price, so that each $1 increase in price loses you the same amount of demand,
then the negative of the revenue ends up being convex, so the gradient method will find a global
optimum with no problem at all. If the demand functions smooth but more complicated than that,
then gradient descent might get stuck in a local minimum, the old concern, but it's not likely.
Let's take this problem to the next level too, replacing the demand function by something that's
certainly not smooth. Let's look at the pricing scheme for a warehouse club like Costco or Sam's,
and see why it works. And boy does it. Costco Wholesale Corporation is the seventh largest
retailer in the world, the third or fourth largest retailer in the U.S., and the largest retailer
of wine in the world. This success is due to a lot of factors, but two of its pricing practices
are important contributors to it. One is selling most items only in bulk. The other is the two-part
tariff. Members pay an annual fee to be able to buy at Costco after which they have access
to the low per item price in the store. I'm going to explore these strategies with a simplified
Costco. It'll be selling only one thing, cheese, in one pound blocks, and its membership lasts only
a day. It's essentially a permit to buy on that day. Ridiculous, of course. The difference between
this Costco and the real Costco is actually only a matter of scale, though, and not of kind.
If you can do the simpler problem, you can do the full-blown one. It's just a lot more of the same.
So, back to cheese. Like anything else, people are generally going to experience diminishing returns
from buying additional cheese. That is, each additional pound of cheese is likely to be worth
a bit less to the consumer than the one before it. 100 pounds of cheese is not worth 100 times as much
to me as one pound is. But not all consumers of cheese value it equally. Not all of them have
the same drop-off rates in the value of an additional pound of cheese. To make things simple,
I'm going to assume that no one wants to buy more than 10 pounds of cheese on their visit. I'm also
going to assume, for my example, that I can break the market up into five segments. The people in
each segment will have the same evaluation of the worth of n pounds of cheese. So, we'll need to know
the marginal value of a pound of cheese to each of these five market segments. Segment one, for
example, shows diminishing returns. The first pound, as you can see, is worth nine bucks to these
customers, and the second one's worth almost as much, $8.50. Beyond that point, the value drops
rapidly. If the customer already has nine pounds of cheese, that tenth pound is worth only 20 cents
to them. The other segments show diminishing returns, too, except for segment two. Perhaps these
purchasers are themselves vendors, and so need a lot of cheese. They won't pay a lot, but every
pound is worth $4.40 to them. In our problem, the limit on purchase is 10 pounds, just because
that's the limit I set for the demonstration. Okay, let's begin by modeling. This is a regular
store. No membership fee, and customers can buy cheese in one pound increments. What's the best
price for us to set? I'll tell you that we buy cheese at our store for $1.10 per pound. Well,
for the moment, imagine that we decided to sell charge five bucks per pound. What happens? Let's
see. The people in segment one would buy one pound, since it's worth $9 to them, and then they'd buy
another pound, since the second pound's worth $8.50, but they won't buy a third. Since they'd be
paying $5 for something that to them is only worth $4.94. So each of the 5,000 people in the first
segment buy two pounds of cheese for a total sale of 10,000 pounds of cheese. The people in segment
two buy nothing, since a pound is only worth $4.40 to them, and we're charging five bucks. No sales
there. We can follow a similar logic for the other three segments. It turns out that we sell
54,000 pounds of cheese at $5 per pound. Since we had to pay $1.10 per pound for it, our profit is
five minus $1.10 times 54,000 or $210,600. Easy calculation. But it's also highly non-linear
in the price that we set. The price determines the demand in each segment, and the demand jumps as
we pass that segment's price point for an additional pound of cheese. That's a discontinuous change,
a cliff in our mathematical landscape. So a gradient-based approach is out. We'll use a genetic
algorithm again. Is that going to cause trouble? Well, we need to set an upper and lower bound
on the variables, which means here what we charge for cheese. That's no problem. We'll set $1 for
a minimum, since the cheese costs us $1.10, and $10 for the maximum, since no one will buy cheese
for more than $9. Evolutionary solvers don't like a bunch of constraints, but we'll put the
calculation of how much cheese in each segment buys into the spreadsheet itself,
so we won't need to include them as solver constraints. Evolutionary solvers fine with that.
Figuring how much each segment buys is easy to do. With diminishing returns, the amount bought
by a customer is just a number of times that a value larger than the selling price appears in
their column. So at the $5 cost, the big spenders are in segment 3. They buy four pounds of cheese
each. When we run the program, solver finds that the best price to charge for a pound of cheese is
$5.48. In this case, we sell exactly the same amount of cheese to each customer that we do at $5,
but we make an additional $0.48 per pound for a profit of about $236,500.
But can we do better? How about if we use the two-part tariff? Now a person who buys anything
must first buy a membership fee. While in modeling this, we're going to have two decision variables,
how much to charge for a pound of cheese, and how much to charge for a membership. Given these,
we have to figure out what each customer is going to do. So first we compute the value of a possible
purchase to a customer, then we would compute what it costs them to make that purchase. The difference
in these two is called the surplus value of that purchase to that customer. And the customer wants
the biggest surplus that he or she can get. So let's see how this works. For now, imagine that
the membership costs $4 and that we're selling cheese for $5 a pound. And let's just focus on
segment one. Let's look at each of their choices. First, of course, they could be fused to buy
anything. That leaves them where they started with a zero surplus. But if they buy one pound of cheese,
they're going to have to pay the $4 membership fee and also the $5 for the pound of cheese.
That's $9 for $9 worth of cheese. As far as that customer is concerned, they're no better off than
they were when they bought nothing at all. But how about buying two pounds of cheese? Since the first
pound is worth $9 and the second is worth $8.50 to this customer, the two pound purchase is worth
a total of $17.50. And what do we charge them for it? A $4 membership and two pounds at
$5 each. That's a total of $14. So the customer is spending $14 to get $17.50 worth of cheese.
To them, that's a surplus of $3.50. And that's more attractive than either of the other options
looked at so far. And of course, we just continue from there. For this customer,
three pounds of cheese is worth $9 plus $8.50 plus $4.94. $22.44. But it costs $4 plus
three times the $5 price per cheese, $19. That last pound added $5 to the cost,
but we turned only $4.94 in value. The surplus drops to $3.44. That's good,
but it's not as good as the $3.50 surplus from buying only two pounds. As I'm sure you can see,
every pound after the second adds less value than the five that it costs. So the customer
buys two pounds of cheese and maximizes his personal surplus. We can calculate the surplus for each
segment by adding up the total worth of n pounds of cheese for that segment and subtracting off
what the purchase would cost. I recorded those values in a new table, like this. At the bottom
of the table, I put this new information to work. Scan the column to find the maximum surplus for
that segment. Record how many pounds of cheese gave this maximum surplus. For those interested
in the spreadsheet particulars, I used the max function and the match, match function.
Two more very handy functions. I now know how many pounds each person in the market segment
buys, and I know the size of the segment. Taking the sum product of these two quantities,
pounds times segment size, add it over all the segments, tells me the total purchase of cheese.
Multiply this by the profit per pound of cheese. Voila. With the current pricing scheme,
you can see it's a bit over $278,000. But you got to remember, that's just with my arbitrarily
chosen $4 membership and $5 a pound per price, price per pound of cheese.
All of the spreadsheet's evolutionary solver find the best values. I specified that the cost per
pound was between $1 and $10 in the constraints, and that the membership fee was between $0 and $100.
Those were the only constraints. Then, I'll let it run for a while. The best answer found is to
charge $8.57 for membership fees, and to sell the cheese at $3.54 a pound. With these prices,
we sell 74,000 pounds of cheese, which is rather staggering. That's a 270% increase in cheese sales
over our no membership fee model. Our profit is almost $335,000, up 42% from the original model.
The introduction of the membership fee, coupled with a reduced price per pound of cheese,
drastically increased sales and profits. So, we've seen the value of one part of
Costco's pricing strategy, a membership fee. Now, let's look at the other piece,
selling only in bulk. I'm going to add one more decision variable to our Costco formulation,
how large a package we sell. Specifically, we're going to sell packages of n pounds of cheese only,
where n's a whole number. We'll have the spreadsheet compute how big n should be.
Now, I could rewrite my program entirely in light of this new rule, but there's an easier way.
My idea is equivalent to Costco's saying to a customer,
oh, what set of cheese in four pound blocks we are? You don't like that? You're up our different
amount. Oh, that's no problem, squire, but it's a special right for that. Oh, let's see, a hundred
bucks more than you think it's worth. I'll do it. That is, if the amount of cheese is not a multiple
of our package size, we make the price so terrible, a surplus of negative 100 of the customer, that
the customer never chooses that option, which of course is exactly the condition we want to enforce.
So the resulting new spreadsheet looks like this. In the lower left, I have a new decision
variable for the number of pounds of cheese in a bulk package. Here it's four pounds. I modified
my surplus table to say that unless the pounds were a multiple of the package size, the surplus is
negative 100. Again, for spreadsheet fans, the easiest way to do this is to use the if and mod
functions. Two more things, you wouldn't see in a gradient descent program. Anyway, as you can see,
if you keep on our earlier pricing plan of $8.57 for membership and 354 per pound of cheese,
then this bundling idea looks like a big mistake. Segments two and four now by nothing, and segments
one, three and five by four pounds each, profits dropped to about 238,000. But we'll run the program
one last time, telling the spreadsheet that it can choose any integer from one to 10 is package size
and see what happens. Here's the result. You know that a downside of genetic algorithms is that they
can be slow. This program ran for about five minutes on my fairly fast desktop computer before
reporting back its answer. The solution is right there on your screen. Sell cheese in three pound
packages, setting the membership fee to $11.76 and the cost per pound as $2.48. That results in
selling 99,000 pounds of cheese for a profit of over $348,000. That is the three pound packages
increase the profits by an additional 4% and increase sales by 15,000 pounds of cheese.
So there you have it. The approach of a two part tariff system and bulk sales,
given the right market can substantially increase both sales and profits. How? Memberships brought
down the cost of an additional unit of product, encouraging customers to buy more.
Bulk sales took advantage of the fact that the value of additional units of product can drop
quickly. It forces a customer to buy a lot or not at all. Making it work though requires getting the
right membership cost and the right price and package size for the products. The problem is
complex. The answer is not obvious, but the improvements from implementing the best answer
are enormous. And whether the problem is commercial, military, personal, whether the
program is linear, integer or nonlinear, improvement is what optimization is all about.
