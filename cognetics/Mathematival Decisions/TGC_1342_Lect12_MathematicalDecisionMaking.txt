Music
Universities often have breaks during the semester where the students can get out and clear their minds.
So let's send you on a little vacation.
Your destination is a resort spot out in the middle of the Nevada desert,
which the internet map program tells you is 250 miles away from your present location.
You have only 10 gallons of gas in your car according to your gas gauge,
but you get 30 miles per gallon, which gives you an effective 300 mile range.
You're eager to get to the resort, but with the unfamiliar roads,
you decide to drive at a constant and leisurely 50 miles per hour.
Well, 250 miles at 50 miles per hour means it's going to take five hours to complete the trip.
Piece of cake.
But how about if your gas gauge is a bit off and you actually only have nine gallons of gas, not 10?
No problem.
At 30 miles per gallon, your range is still 270 miles,
so you'll reach your destination of 250 miles in the desert in five hours, same as before.
It's a difference that effectively makes no difference.
But if the gauge is off a bit more, say if you only have eight gallons in your tank,
then your range is only 240 miles and you run out of gas with 10 miles of desert between you and your destination,
and your trip time is going to be longer.
Depending on the time of day and how much traffic is on this desolate wasteland road,
it may be much, much longer.
On the other hand, if I went back to the 10 gallons of gas,
but made the trip 260 miles long rather than 250,
the travel time would change, but not by much.
An extra 10 miles at 15 miles per hour would mean a fifth of an hour, 12 minutes.
That's true for every additional 10 miles of trip distance.
Up to we reach our 300 mile limit, 10 more miles, 12 more minutes, 10 fewer miles, 12 fewer minutes.
And that, of course, is a linear relationship between the travel distance and the travel time.
But it doesn't last forever.
If I make the trip more than 300 miles, this 12 minutes for 10 miles rule no longer works.
You're back to hiking the desert again and the linear relationship breaks.
And the break point in this case is the trip of 300 miles.
This simple analysis actually gives you a pretty good idea of what's meant by the term sensitivity analysis in operations research.
We take a problem for which we found the best answer and then ask how sensitive this best answer is to perturbations in the problem.
How much can we change a program parameter like the gas in the tank before we affect the best solution?
If changing a parameter does affect the optimal solution like changing our distance to our destination,
can we anticipate and characterize the nature of this change?
And if we can, like the rule 12 minutes for each added 10 miles, then when, if ever, does this rule break down?
Sensitivity analysis can be done with a variety of analytical techniques.
Anytime we want to know how sensitive our solution is to variations in the parameters that characterize the problem.
Today, we're going to look at these questions for linear programs.
It'll be easiest to see what's going on in the matrix representation of a linear program that we worked out last time.
So let me pull up one that's already familiar to you.
The Great Courses Railroad.
We're shipping freight cars from the sore cities of Atlanta and Baltimore through the trans-shipment cities of Chicago and Dallas
and on to the destination cities of Eugene, Fresno and Great Falls.
Each source has a limited number of cars available. That's the first two constraints.
Each destination has a demand for cars that has to be met. That's the last three constraints.
And the constraints for Chicago and Dallas say that for those two cities, in the middle, what goes in goes out.
If you look at this matrix representation, you'll see that all of the problem parameters, the numbers given in the problem,
appear in gray boxes.
The red boxes are the best values of the variables as found by the spreadsheet.
The black cell with the green writing is the objective.
The LHS column holds the left sides of the constraints computed by using the red decision cells and the gray cells beneath them.
So right here, we can see 250 cars leave Atlanta, and here, we can see that 100 cars come into Great Falls.
Sensitivity analysis asks what happens when we change one or more of the numbers in gray.
These might be changes resulting from deliberate choices, or they might be changes imposed on us by some random variation.
In the top gray row, changing a number would mean changing how much it costs to ship one car along a link from a city to a city.
In the right-hand column, it would mean changing how many cars are available in the city, or how many are needed,
or allowing cars to be added or removed in Chicago or Dallas.
Changing the numbers in the big gray rectangle in the lower left doesn't make good physical sense on this problem, so we'll come back to that later.
Well, we're doing math, and the power of math is generality.
In this problem, the objective is cost, and the constraints are talking about freight cars.
In a different problem, the numbers in the shaded regions might represent quantities that aren't even close to these.
But if it's a linear program, the kinds of effects that we see when we change the gray cells are always going to be the same.
Last time, we saw that changing the right-hand side, the constant term of a non-binding constraint like number of cars available in Atlanta,
doesn't impact the optimal solution at all.
At least it does in as long as the amount that you change the right-hand side isn't so much that you chew through the slack,
the cars that are currently left unused in Atlanta.
Take a look. In the optimal solution, after we ship 250 cars from Atlanta, 50 of Atlanta's 300 cars are left in the train yard.
That's the slack. If you lost some or all of those 50, or you got more cars in Atlanta, you wouldn't really care.
You'd just have more or less surplus, more or less slack.
If you lost more than 50, of course, you'd have eaten through your slack and the supply constraint would now be broken.
You'd need to change your shipping schedule, and it would probably cost you more money.
But let's try the same game with a constraint that's originally binding in our optimal solution.
I'm going to look at the bottom one, the demand for great falls.
It wants at least 100 cars, and it's getting exactly that. No slack.
Binding.
Now, what do you think will happen to optimal cost if we change the amount of cars required by great falls, either up or down?
You probably figured that if they need more cars, the cost will go up, and if they need fewer cars, the cost will go down.
Exactly right.
Here's a one car increase in the demand for great falls, 101 cars.
And yeah, you can see costs did go up by $210. The old cost was $90,800.
And here's decreasing the cost of great falls demand by one.
And again, the original cost changes by 210, but dropping this time.
There's nothing really mysterious about this figure of 210 in both cases.
Solver did look at all possible routings for the modified problem, but it found that it was best to continue to use the all of Baltimore's cars for Fresno.
So another car to great falls has to go from Atlanta to Chicago to great falls.
Atlanta to Chicago costs $72. Chicago to great falls.
Falls costs $138. Total, $210.
And it isn't just one car, of course. Every time we need another car in great falls, the answer is to ship it from Atlanta to Chicago to great falls and to pay the $210.
The key point here is that each time we change the right-hand side by one, we alter our original solution according to the same recipe.
If the demanding great falls increases by one car, we send one more from Atlanta to Chicago, one more from Chicago to great falls, and we pay $210.
If they want another, we do exactly the same thing. A nice, linear pattern.
But like in our Nevada resort example, it doesn't hold forever.
Eventually, we run out of cars to send from Atlanta. This happens when the great falls demand passes $150.
What we've done in this example isn't intended to be impressive. It's intended to be instructive.
Let me summarize what we said here, because what's important is what we've seen here always works.
When you change the right-hand side of a non-binding constraint, it doesn't affect your objective or your schedule.
Until you change the right-hand side so far as to make it become binding, you use it all up.
If you change the right-hand side of a binding constraint, it generally changes both the optimal schedule, what you're supposed to do, and your objective value, how well you do.
But it does so in a predictable, linear way, such as one more demanding great falls means one more car from Atlanta to Chicago to great falls and $210 increasing cost.
This nice, linear pattern holds for a while, but it may break down at some point.
So change the demanded great falls from 100 cars to a new value, and it'll change your total cost by $210 for every one car you add or subtract that demand.
This $210 is called the shadow price of the constraint, although it's also known as the dual price.
In general, the shadow price of a constraint tells you how much the optimal objective function value increases, or decreases, every time that you increase, or decrease, the right-hand side of the constraint by one unit, at least for a while.
I have to say at least for a while, because we saw that we can't play this game forever.
If the demanded great falls gets too high or too low, that $210 per car number is no longer applicable, because our ship a car from Atlanta to Chicago to great falls recipe breaks down.
But for a certain range of right-hand side values, the recipe works just great, and in that range, you can trust the shadow price.
This range where everything is behaving great is called the right-hand side range of the constraint, RHS range for short.
So using our new terminology, I could summarize our findings from the last few minutes by saying this. Ready?
The shadow price of the great falls constraint is $210 per car, and the right-hand side range is from zero to 150 cars.
Translation. As long as the number of cars great falls needs stays between zero and 150 cars, each increase or decrease in its demand increases or decreases total cost by $210.
I could also say that the shadow price of the Atlanta constraint is $0 per car, and that the right-hand side range is from 250 cars to infinity.
That is, as long as the supply of cars in Atlanta stays at at least 250 cars or above, increasing or decreasing Atlanta supply does not change total cost at all.
That's the zero shadow price. Getting it?
Okay. Our analysis so far has been something that you could almost certainly have done on your own.
Now let me try to convince you that all this is worthwhile by looking at a harder problem.
I'm going to take our problem from last time, the three months, pants and shirts, inventory and production problem in the same kind of matrix form and look at the same kinds of questions.
And here is the program. Well, yuck.
The first thing to notice is that this program looks a lot less comprehensible than my user-friendly representation from last time, huh?
Last time I had six variables for shirts and pants production in each of the three months.
But in the matrix approach, it was easier to create a bunch of additional auxiliaries for inventory of shirts and pants and cloth at the end of each month.
While I could do a sensitivity analysis with the program in the user-friendly form that we created last time, this matrix form will actually be easier for us to see what's going on today.
And don't let all those numbers put you off.
To do the work that we're going to be talking about, we only need to know a few things.
First, what the objective is, which here is minimizing the cost in dollars.
Second, what the right-hand side of the constraints are telling us.
These right-hand sides, the gray cells in the last column, record for each of the three months, the demand for pants and shirts, the amount of cloth that becomes available, and the production capacity available from labor.
We're going to change one of these right-hand side numbers and see what it does to the optimal solution.
This time, it isn't so easy to intuit the changes that will occur to our solution when we change the right-hand side of a binding constraint.
For example, suppose that we could get 10 additional units of production capacity in one of the three months.
Which would you choose?
It's far from simple to see how the optimal production schedule would change in response to this extra capacity.
But with the right tool, you can find this information out from the spreadsheet without re-running the program.
While CALC, an open office, doesn't have this feature at the present time, you can get such a report from Excel or from a free linear programming solver like WinQSB.
In Excel, you simply ask for the sensitivity report in the window that solver pops up after it's solved the linear program.
The report it generates covers most of the page, but I'm going to show you a portion of it here.
This part talks about right-hand side ranging, constraints numbers 10, 11 and 12.
These are the constraints that say that you can't use more production capacity from labor than what's available in any of the three months.
The next column is labeled Final Value, but really it just tells you the left-hand side value of each constraint.
Here, that means how much capacity you actually used in each of the months.
We'll skip the shadow price column for the second.
The constraint right-hand side column not surprisingly tells you the right-hand side of the constraints.
Here it says that 2400 units of production capacity were available in each of the three months.
So the top row says that production capacity is a non-binding constraint in month one.
It says that we're only using 1,780 units of capacity, but that there are 2400 units of capacity available.
But in the next two rows, you can see that capacity is binding in months two and three.
2400 used equals 2400 available.
Final value equals constraint right-hand side.
All this is old news. We could have read these values off of the matrix formulation.
But now comes the new part.
The report also shows the shadow price of each constraint from months one, two and three.
The shadow prices for production capacity are as given as being zero, minus three, and minus six, respectively.
Remember, shadow price tells you what happens to the objective here, cost.
When the right-hand side of the constraint increases by one.
So the zero tells us that an additional unit of capacity is useless in month one,
which makes sense since we already have unused capacity in month one.
But an additional unit of capacity in month two would reduce the cost by three.
That's the negative three shadow price.
While an additional unit of capacity in month three would reduce costs by six.
We can make similar statements about capacity decreases too.
If you're going to have people going on vacation, you don't want them doing it in month three.
Since each one unit decreasing capacity increases costs by six bucks.
A few moments ago, I asked if you had to get 10 more units of production capacity for just one month.
Which month do you want it in?
Well, now we can answer that.
Month three, where it should be worth ten times that negative six dollar shadow price,
negative sixty, a sixty dollar cost reduction.
Let's see if it's true by re-running the program with that ten additional units of capacity in month three.
You can see the change that I made in available capacity in the last row.
And look at the objective.
Sure enough, the cost dropped from 37,700 to 37,640,
exactly the sixty dollar drop that we predicted for the shadow price.
Of course, that's not very big savings.
How about if we could get not ten more units of capacity,
but four hundred more units of capacity in month three.
Now we're talking.
Since each additional unit of capacity is worth six bucks savings according to the shadow price,
we should save four hundred times six, twenty four hundred bucks.
We predict the cost will drop from 37,700 to 35,300.
Let's see if we're right by re-running the program.
Change the month three capacity from 2400 to 2800 and...
and...
it didn't work.
We predicted the savings of 2400 and we're only saving 2100.
We were $300 off.
The shadow price lied.
Well, actually, no, it didn't.
Remember that we said that shadow prices only apply over a limited range, the right-hand side range?
It's like a coupon from a store that lets you buy light bulbs for a dollar each.
Limit six.
You can get six light bulbs for six bucks,
but who knows what you're going to have to pay for the seventh one.
How big this range is for a given constraint is given in the sensitivity report, too,
under allowable decrease and allowable increase.
These columns tell you how much you can increase or decrease the right-hand side of a constraint
without getting into trouble like the shadow price is changing and the like.
Here, take a look at the bottom row of the report on the screen,
which talks about the capacity in month three.
You'll see that the allowable increase is only 300,
so the first 300 units of labor capacity that we add will each reduce the optimal cost by six bucks,
but after the first 300, it's anybody's guess.
We'd have to rerun the program with the new right-hand side to find out the new shadow price.
It turns out to be $3 per unit for each additional unit of capacity between 300 and 400, although you wouldn't know that.
It's the old diminishing returns idea from economics, though,
as the resource becomes more plentiful, a unit of it becomes less valuable.
Now, the changes I've been talking about so far involve changing only one right-hand side,
but you can use shadow prices even when changing more than one right-hand side.
As we said, that would generally mean changing either the amount of available of something or the amount required of something.
You have to be a little careful with what happens when you change more than one right-hand side at a time.
You have to use something called the 100% rule, which is a bit beyond our topic today,
but as long as the changes that you make in the right-hand sides are relatively small compared to what each of the ranges allows,
you can still trust the shadow prices to be accurate.
So with that in mind, how could a manager use this report?
I'm showing you more of the report this time.
The range information for all of the constraints.
You are the manager.
What constraints do you want to focus on?
Pants, shirts, cloth, labor?
Well, look at the shadow prices.
We can forget about cloth.
Constraints seven through nine show getting or losing a bit of cloth.
The cloth supply doesn't matter.
The shadow prices are all zero.
Okay.
How about the demand for pants and shirts?
Here, the shadow prices are all positive.
So increasing demand for any of things in these months is going to increase your costs.
But you can see that this is true for pants more than for shirts, higher shadow prices.
And the later we get in the production cycle, the more costly each additional garment becomes.
The top row shows that an additional pair of pants demanded in month one increases costs by six bucks,
while an additional pair in month three would bump costs by twice as much, 12 bucks.
Hmm.
Which means that if we could get a wholesaler to take early delivery on some of those pairs of pants,
we could shift demand from month three to month one and save money.
Let's try it.
The allowable decrease on constraint three is 300 pairs of pants.
We play it safe and use only 100.
So I'll reduce month three demand by 100 and simultaneously increase month one demand by 100.
Month one allows an increase of 572 demand.
So 100 isn't pushing the constraint very hard.
Our analysis says that we should save 12 times 100, 2400, 1200 bucks by reducing month three demand
and increase costs by six times 100, $600 by increasing month one demand.
The net effect should be that we save $600.
Does it actually work?
Let's rerun the program.
You can see and read the changes I made in the demands in the two months and checking the costs.
Costs are down from 37,700 to 37,100.
Sure enough, 600 savings.
And of course you could play similar games with other aspects of production.
For example, we see from the shadow prices that getting the wholesaler to accept pants or shirts earlier can reduce our costs.
Pretty handy stuff.
There's a second kind of ranging that we can do too that's equally useful.
So far we've been changing the right hand side of the constraint and these quantities generally represent either the quantity available of something
or the quantity required of something.
But how about the gray sales across the top of our matrix?
They're the objective function coefficients.
And our problem today, the objective has been cost, so they represented the cost per unit of each decision variable.
Changing these numbers always changes how much one unit of the variable's worth.
Here how much cost.
So suppose for example that the production cost of pants drops from its original six bucks.
Let's drop the pants all the way down to a little more than half price then.
$3.01 per pair.
Should I make more pants at this price?
A lot more?
A few more?
No more at all?
Let's see.
I'll change the cost of making pants from month one down to $3.01 and rerun the program.
And as you can see, and this was really amazing to me when I first saw it, you don't change production at all.
All of the decision variables in the red cells stay exactly the same.
We reduce costs because we're saving $2.99 on each of the 700 pairs of pants that we're already making in month one.
But we don't shift production to take advantage of this bargain.
We don't shift it at all.
Our optimal production schedule is preserved.
But something interesting happens if I can get this month one pants production cost just two more cents down to $2.99.
Take a look.
Whoa.
Look at this.
Production shifts dramatically.
We make lots more pants in month one with a corresponding reduction in pants in month two.
Of course, this requires making less shirts in month one and more in month two to make up for that deficit.
All the labor comes into play in month one and that is now free time in month two.
And these changes, of course, alter cloth reserves and storage costs.
But it's worth it because the costs do go down.
Take a second to think again about what just happened here because it's kind of startling.
As the cost of making pants in month one starts to drop, while there's no impact on the production schedule for a while,
this is actually true all the way down to a cost of $3 per pair.
But the instant we drop below this figure, wham, the solution changes dramatically.
This is typical of what happens when we change an objective function coefficient in any linear program.
It's called objective function coefficient ranging or OFCR.
If the change is small enough, you keep doing exactly what you were doing before.
If it's big enough, you see a fairly radical change in activity,
a change in which the constraints that are binding and nonbinding can shift.
And the sensitivity report shows you where this happens.
Let me show you a different part of the sensitivity report.
This is the objective function coefficient range information, the OFCR info.
The top row of the report says that we're currently making 700 pairs of pants in month one
and that the objective coefficient, that's the current cost, is $6 per pair.
The increase and decrease columns are applied to this figure of $6 per pair.
The decrease is $3, which drops the $6 per pair down to $3 per pair.
The report is telling you that beyond this point, production will probably change.
Before that point, it definitely won't.
That's what we just saw.
The increase column tells you something new.
It indicates that if month one pants production costs go above $7,
that's the $6 plus the $1 allowable increase,
then the production is probably going to change then too.
And you can guess how.
The only thing we changed was making month one pants more expensive.
So if we change production because of this, it's going to be to cut back on month one pants production.
The report says that $7 per pair is the price point that initiates this kind of change.
Let's test it.
If pants in month one cost $6.99,
there's no change in our production from our original optimal solution.
The red cells haven't changed, but if we go just above $7 price point,
yep, sure enough.
Pants one production in month one drops with month two picking up the slack
and all other aspects of the optimal production schedule shift around to accommodate it.
Know that these changes are quite complex and ripple through the entire factory,
but that we knew what price was going to be the breaking point by a quick glance at the sensitivity report.
As long as the cost of month one pairs of pants stay between $3 and $7,
we can't do better by changing schedules.
Outside that range, the old answer is probably no longer the best answer.
And what happens when the cost of a pair of pants in month one is exactly $3 or exactly $7?
Well, we get alternative optima.
As we crossed the end of the objective function coefficient range,
we moved from a place where the old solution was best to a place where the new solution was best.
Exactly at the break point, they're both equally good.
This always happens.
It's just like two trains leaving the same station traveling in the same direction along parallel tracks.
Imagine the slow train leaves a half an hour earlier.
For short trips to arrive at your destination as soon as possible,
you'll want to take this earlier but slower train.
But if you watch the two trains, you'll see the fast one leaves the station,
each through the lead that the slow train built up, and eventually overtakes the slow train.
For any longer trip than that, you'd want to be on the fast train.
But if your destination happened to be at the exact point where the fast train caught up with the slow train,
well, you wouldn't care which one you'd ridden.
You have alternative optima.
In the same way, if we're inside the objective function coefficient range,
what you do is not going to change.
Outside of the range, what you're going to do probably does change.
And at the end of the range, both the old and new solutions are going to be equally good.
And again, you can change multiple coefficients without changing the optimal schedule
as long as you don't change them too much.
But don't think that if the change stays inside each one of its own ranges,
you can count on the same schedule.
Think about this.
You and I sell the same product in a side-by-side booths at a market to 100 people.
Your price is $6 and mine is $7.50.
Obviously, they all want to buy from you.
And this would be the case even if you raised your prices by $1.
Similarly, if I lowered my prices by $1, they'd still all buy from you.
The optimal schedule wouldn't change.
But let us both make those changes, where your extra dollar puts you at $7
and my $1 discount puts me at $6.50.
And it's a whole new ball game.
Again, if you want to look at multiple objective coefficient changes,
keep them small compared to the allowable changes
or learn about the 100% rule for objective function coefficients.
Earlier in the lecture, I talked about changing the numbers in the gray boxes
in the matrix representation of a linear program.
And so far, I've only talked about changing them in the last column,
right-hand side ranging, and changing them in the first row,
objective function coefficient ranging.
What about the big gray box?
Those are the numbers that appear on the left-hand side of the constraints.
This would be, if you like, left-hand side ranging.
Well, the truth is left-hand side ranging is much trickier.
The reason, once again, is the issue of linearity.
When you change one or more right-hand side values in linear program,
the effect on the solution is a linear one, as long as you don't push it too far.
Changing one or more objective function coefficients has the same kind of effect
as long as you don't push it too far.
The linear impact is on shadow prices rather than on the optimal schedule,
but it's still a linear effect.
But changing a coefficient on the left-hand side of the binding constraint
generally produces a non-linear change in the optimal solution, much more complicated.
From a practical standpoint, it's often easiest to just re-run the program multiple times
with different values substituted for the left-hand side coefficient,
just to get an idea of the impact of varying it.
Well, earlier we talked about applying the idea of optimization
and how it has relevance beyond the formal mathematical models that we've discussed.
What are you trying to accomplish?
What do you control?
What rules do you have to obey?
Important questions in a lot of life situations.
And that's also true about some of the ideas we've developed here today.
Objective function coefficient ranging shows us that, in a linear program,
behavior doesn't change until the payoffs are moved beyond some tipping point,
the end of the objective function coefficient range.
It's interesting to apply this line of thought to public policy issues,
such as environmental policy.
If companies are engaging in behavior destructive to the environment,
legislatures often enact laws to penalize them, such as fines.
This was the case, for example, in West Virginia in 1939
when the state enacted penalties for failing to adequately reclaim land after strip mining.
If you've been to West Virginia, you may guess what happened.
It turned out to be cheaper to pay the fine than to reclaim the land,
so the land was left scarred and barren.
More recent pieces of legislation have substantially increased the penalties,
including loss of mining permits and behaviors changed.
A sufficiently large penalty should rarely, if ever, have to be assessed.
It may be cynical, but when I see a piece of legislation proposing fines to curb, say, pollution,
I'm always interested to see how the polluters respond to the legislation.
If the fine is large enough, outside the firm's objective function coefficient range,
they'll cut back on pollutants.
If not, the legislation does nothing to address our pollution problem,
but it may do a great job of raising government revenues from fines
and providing political cover for politicians.
Determining appropriate sanctions can be tricky,
but this part at least is pretty simple.
If you actually want to change behavior, you need a penalty that's severe enough
that the violator prefers making the change to paying the penalty.
Sensitivity analysis can help you find the tipping point.
