Remember the Pythagorean theorem from way back when?
The first time I heard something like it was when I was a kid, because in the Wizard
of Oz, the scarecrow recites a fairly mangled version of it to impress everyone that he
has a brain.
I didn't get all of it because I was cowering behind a couch at the time, hiding from the
flying monkeys.
What the scarecrow should have said was, for a right triangle with legs of length a and
b and a hypotenuse c, you always have a squared plus b squared equals c squared.
That's quite a workhorse in mathematics.
We use one version of it or another all the time, like we did when we defined Euclidean
distance in n-dimensional space in our data mining work.
But if I was surprised that the scarecrow didn't know the theorem after all, what surprised
me even more was when a friend of mine in grad school took a survey of how many math
grad students, or math faculty, could prove the Pythagorean theorem.
You found that almost none of us could, including me.
So in case you want to slam dunk a mathematician sometime, here's a cute little geometric proof.
Start with two squares side by side, like this.
The blue square is 12 by 12, and the red square is 5 by 5.
Glue them together, and then make a right angle cut, like this, to split off two congruent
triangles.
Since my original squares were 12 by 12 and 5 by 5, these lengths, the lengths for these
triangles have lengths of 5 and 12.
Now you just swing the triangles around, and it's easy to verify that what you get is a
square.
You see it has the same area as the original two squares.
So its total area has to be 5 squared plus 12 squared, which is 169.
And that means that each side of the square is 13 units long, since 13 squared is 169.
Actually, this proof works with any original squares of any size, so you get a squared
plus b squared equals c squared for any right triangle, which I think is really cute.
On the other hand, the fact that the resulting big square that you get is a whole number
of units long, that's something different.
If you pick an arbitrary pair of squares to start with, you're almost certain to get
a larger square whose side's an irrational number.
If you start with a 6 by 6 and a 10 by 10 square, for example, then when you pivot them,
you get a bigger square.
But each side is about 11.661904 units long.
Most people seem to know that 3, 4, and 5 will work.
The next smallest solution in whole numbers is 5, 12, and 13, like we just did here.
If you ask a high school student to use the Pythagorean theorem, they can generally do
it.
But if you restrict them to solutions where all three legs have to be whole numbers,
so-called Pythagorean triples, that's a much tougher challenge.
There's a point here that I don't want us to miss.
A lot of mathematical problems become much more challenging when you impose the seemingly
minor requirement that the variables in the solution have to be integers.
In the 3rd century BC, the Hellenistic mathematician Diophantus of Alexandria was looking for solutions
to such equations, which are actually now called Diophantine equations in his honor.
In 1900, many such questions were still open, and the brilliant mathematician David Hilbert
challenged his peers to determine whether there was any general algorithm that could
be determined in a finite amount of time, whether a given polynomial equation has an
integral solution.
The answer was found 77 years later.
It's no.
You can solve equations like a squared plus b squared equals c squared, but not you can't
solve them all in general algorithm.
In fact, even figuring out which problems you can solve can be nightmarishly difficult.
A 358 year long nightmare was started back in 1637 by the French mathematician Pierre
de Fermat.
It may not be easy to find Pythagorean triples, but there are an infinite number of them.
Fermat wanted to think about higher powers.
Can you find a solution to a cubed plus b cubed equals c cubed, or a to the fourth plus
b to the fourth equals c to the fourth, and so on.
Nice question.
Fermat wrote in the margins of one of his books that he had discovered a truly marvelous
proof that there aren't any positive integer solutions to a to the n plus b to the n equals
c to the n if n is bigger than 2, but that there wasn't room in the margin to write
it down.
This result is the famous Fermat's Last Theorem, which is actually a misnomer in a
couple of ways.
First, he died about 30 years later and he did a lot of good math in the intervening years.
And given how intractable later mathematicians found the problem to be, it's almost certain
that Fermat's proof had holes in it.
But it was only a conjecture, not a theorem.
But nobody published a proof or disproof of this simple sounding integer problem until
1995, 358 years later.
When the problem was finally solved, and Fermat was right, there aren't any other solutions,
it was heralded by mathematicians and the popular press alike.
It wasn't the moon landing.
It took much longer than that.
The point of all this is that, up to this point in the series, I've mostly been assuming
that variables could take on any values they please, subject to the constraints.
You want a fraction?
No problem.
And we've got some great solution procedures.
But in a linear program, add the harmless sounding additional requirement that your
answer involves only integers, and you can make an absolute train wreck out of an otherwise
terrific solution technique.
And in real life problems, we often don't have any use for fractional answers.
Use it.
No one will buy three quarters of a car for three quarters of the sticker price.
Programs where variables have to be integers are sensibly enough called integer programs.
Take a linear program and require that all the variables be integers, and you've got
an integer linear program.
If it's got both integers and real variables, it's called a mixed integer linear program.
To save breath, I'm just going to call them all integer programs, unless it becomes important
to distinguish among them.
So let's restrict ourselves to linear programs with integer variables.
How much trouble are we buying ourselves with the integer restriction?
The best way to give you an idea is to return to our graphical approach to a linear program.
So here's a linear program with the objective of 8x minus 3y, solved graphically.
The arrow on the dotted line, that's the objective function line, tells us that the
further one moves in the direction of that arrow, the larger the objective function value
is growing.
And that makes sense.
8x minus 3y.
If you're maximizing, big X's are good, and big Y's are bad.
And that's what the arrow is saying.
In the image, you can see that the optimal point is marked with a star.
What makes it optimal?
Well, when we talked about graphical solutions, we imagine the feasible region is being flat
but a tilted field that was gradually being flooded.
In this interpretation, the OL follow line here is marking the water's edge after some
degree of flooding.
The arrow points to the side of the floodline that's still above water.
And as we let more and more water in, the OFL line creeps to the lower right, keeping
the same slope as it covers more and more of the feasible region.
The last point above the water is the optimal point.
And that's right at the red star.
The simplex method would get there by a different technique, walking along the edges of the
feasible region and always going uphill, but the results are the same.
We've solved this linear program.
But what if it's an integer program?
For example, maybe x is the number of bulldozers that we sell and y is the number of fueling
stations that we buy.
Can't sell a third of a bulldozer or buy 0.77 fueling stations.
Such things have to be integer quantities.
And you can probably see from our graph that the optimal solution is a little to the right
of x equals three and a little below y equals two.
Its coordinates aren't integers.
To be an acceptable answer to this integer linear program, both coordinates have to be
whole numbers.
We can show that on a graph like this.
It looks like the Cartesian plane has come down with chickenpox.
All those red x's form a lattice, a regular array of points.
And these lattice points are the only points that are permissible answers to this integer
programming problem, because they're the only points where both coordinates are integers.
And you can see clearly that the optimal solution to our linear program isn't on a lattice point.
So what do we do?
Well, a natural guess is to pick a lattice point nearest the linear program's optimal
solution.
This essentially corresponds to rounding each decision variable in the program to its nearest
whole number.
For us, that's x equals three, y equals two.
But you can see the trouble with that immediately.
That points outside the feasible region, so you don't get a feasible solution.
Okay.
How about this?
And the nearest lattice point to the linear program's optimal point that's inside the
feasible region.
How's that do?
Well, mathematically, finding what point that is isn't quite as simple as you might think.
And when the number of variables gets high, it can be worse, but we can deal with that.
The real problem is that this doesn't necessarily give you the best answer.
The nearest integer solution that's feasible in our problem is there at x equals two, y
equals two, almost directly to the left of the linear program's optimal point.
Now you'll remember that the objective function for this problem was 8x minus 3y.
Maximize that.
That means that the point 2, 2 gives an objective of 8 times 2 minus 3 times 2, which is 10.
But the point x equals 2, y equals zero, which is much further away from the linear program's
optimal point, does better.
8 times 2 minus 3 times 0.
That's 16.
In fact, for this integer program, 2, 0 is the optimal point.
I've marked the optimal integer point with a green star on the graph.
Now in this particular problem, there really weren't that many feasible lattice points
to check.
You can see that there are only seven red crosses inside that blue region.
But for a more complicated problem, this number can quickly explode.
For example, suppose that my program has ten variables, each of which are allowed to take
on a value from one to ten integer values.
Then the feasible region contains ten to the tenth or ten billion lattice points, a lattice
point for every person on the planet with a few billion to spare.
An exhaustive search just isn't practical.
So integers can cause us problems, even when the underlying program is linear.
What do we do about it?
Well, we have a few options.
The first thing we can do is ignore the problem and hope that it goes away.
That's not as flippant a suggestion as it sounds.
Suppose I try to solve an integer programming problem by ignoring the fact that the variables
have to be integer.
This linear program is called the LP relaxation of the integer linear program.
And as you know, linear programs can be solved very, very quickly.
So maybe we'll get lucky.
Maybe the solution to the LP relaxation will have all integer values.
In some cases, that's not as unlikely as you might think.
There are whole families of problems, such as single product transportation problems,
where you can be sure that you'll always get integer optimal solutions.
The Great Courses Railway problem never had a chance of calling for 13.3 cars to travel
from Atlanta to Chicago.
That said, most linear integer programs have non-integral optimal solutions.
So when you aren't lucky, what's next?
Well, one possibility is to fake it.
By this, I mean adjust the answers given by the LP relaxation just a little bit.
You could poke around the feasible lattice points in the vicinity of the LP optimum and
choose the one that's best.
The problem with that is that, as we've seen, the integer optimum might not be in that neighborhood.
It might be quite far away.
In some practical cases, though, you might not care.
For example, suppose you solve the LP relaxation, and it says the minimum cost is $900,000.
And then by rounding off some of the numbers in this solution, you get a feasible integer
solution that costs you $903,000.
Well you're within $3,000 or about .3% of the LP optimum.
Maybe that's good enough for you.
But suppose that it isn't, and you insist on finding the best integer answer.
How are integer problems solved?
Well, a common technique is called branch and bound, and we can get an idea of how it
works by using our graphical example.
So you start with the LP relaxation of your problem.
Solving our graphical LP, we find that the optimal solution point is at about x equals
3.14, y equals 1.71, and the optimal objective value is 20.
Now if we're going to have an integer solution, x can't be 3.14.
It's either got to be 3 or less, or it's going to be 4 or more.
So we take our one original integer program and we place it with two, one with the new
requirement that x has to be 3 or less, and one with the new requirement that x has to
be 4 or more.
Graphically it looks like this.
We're breaking up the picture into two regions, the orange one where x is less than or equal
to 3, and the red one where x is greater than or equal to 4.
That's the branch part of branch and bound.
Whichever one of these two different programs gives the best integer answer will provide
the best integer answer to the original problem.
It's essentially a dividing conquer technique.
Okay, how do we solve these two branches?
Well you see that the red region doesn't have any feasible points in it at all, so
we can get rid of it and focus on the orange region.
We got lucky.
If not, we'd have to continue our work with both regions.
But in the orange region, x is less than or equal to 3, so we add that constraint to
the picture and solve the new LP relaxation.
You can see that throwing in this constraint cuts off the right tip of the feasible region,
which makes the old LP optimal solution slide down into the left.
This new solution is at x equals 3, y equals one and a half.
Obviously not an integer solution.
So now what?
Well, why can't be one and a half an integer solution?
Either it has to be one or less, or it has to be two or more.
So again, I create two regions like this.
Imposing the linear program's constraints on these two big regions gives us two regions
to search for the best answer.
We get an orange triangle where y is bigger than or equal to 2, and a red trapezoid where
y is less than or equal to 1.
Two new problems.
And then we solve these LP relaxations.
We find that the top one is the orange star at x equals 2.75, y equals 2, giving an objective
of 16.
The lower one is the red star at x equals 2 and 2 thirds, y equals 1, giving 18 and
the third for the objective.
Here they are.
And neither of these are integer solutions.
But they both have x between 2 and 3.
So for each one, either x is less than or equal to 2, or x is greater than or equal
to 3.
Divide each of these problems in two, playing the same kind of game that we've already played
twice.
And we luck out again.
We can see from the picture that x can no longer be three or more, so we know that x
is two or less.
This adds this one more constraint, x less than or equal to two, to our picture, and
shrinks the feasible region of each of the two ongoing problems.
For the orange problem, the new best answer moves to x equals 2, y equals 2, an integer
solution.
The objective here is 8 minus 2, x times 2, minus 3 times 2, which is 10.
For the red program, the new optimal solution is at x equals 2, y equals 0, yes, again an
integer solution.
And its objective is 8 times 2, minus 3 times 0, 16, which is better than 10.
So the red star wins.
It marks the optimal integer solution to the original problem.
And that's branch and bound.
By the way, the bound part of the branch and bound is a winnowing technique.
It just says if we found one integer solution, we don't need to consider derived problems
whose best answers have no chance of doing better than that one.
Kind of like saying if you're looking for the oldest person in town and you've found
a 90-year-old already, a year old already, you can skip the local school where you know
that everybody is 65 or younger.
What we just did was an easy and short example of branch and bound.
There's a mathematical term for a procedure like this.
It's called a pain.
Seriously, it's an absurd amount of work.
And that's what makes integer programs in general so much more difficult to handle than
linear programs.
And it's part of why some of the real-life integer examples we've been talking about
in the course so far, like that FAA flight routing problem, required so much ingenuity
to solve.
Because although we didn't have the language to discuss it at the time, a lot of those
programs were really integer or mixed integer programs.
The FAA could not send half of a plane north of the storm and the other half south.
Jan DeWitt couldn't plant part of a lily bulb.
In some instances, the LP relaxation and adjusting it a bit was good enough.
Other ones took insight and cleverness to handle the huge problem of this difficult
integer kind.
Inside of spite of this, for problems of reasonable scope, you're going to be perfectly capable
of handling integer and mixed integer programs in either calc or excel.
Given the amazing amount of work required to solve an integer program as compared to a
linear one, it's almost embarrassing how little is required from you to turn a linear program
into an integer program in excel.
Let's take a look at an example, stock cutting.
Plate metal is often stored on large rolls like roll up carpet.
The roll might be, say, 22 feet wide.
But the machines in my factory need rolls that aren't so wide.
For this week's work, I need 5 rolls that are 10 feet wide, 5 rolls that are 8 feet
wide, 4 rolls that are 6 feet wide, and 4 that are 4 feet wide.
To get usable rolls, we're going to cut the 22 foot roll like a loaf of French bread into
rolls of usable width.
Here's one that's been cut into a 10 foot roll, a 4 foot roll, and an 8 foot roll.
Now management doesn't want us wasting material through inefficient cutting.
So cutting two 10 foot pieces out of the 22 foot roll is forbidden, because we'd have
this 2 foot piece of useless scrap left.
Our goal is to figure out how to carry out the stock cutting so that we get all the cut
rolls that we need, and use up the fewest possible number of 22 foot rolls.
The trick in stock cutting problems is to begin by listing all the different patterns
that you could sensibly use in cutting a 22 foot roll into usable pieces.
How can we cut a 22 foot roll into pieces that are 4, 6, 8, and 10 feet wide?
We've just seen one way by a 10, an 8, and a 4.
But we can also do 3 6's and a 4 for 22, or 2 8's and a 6.
If you keep going, it turns out there are 7 possible, sensible cutting possibilities.
Our decision variables are going to be the number of rolls that are cut in each of these
7 patterns, so I have 7 variables.
Now, obviously these variables have to be integer values.
Either I cut up a roll, or I don't.
The goal is to minimize the sum of these 7 variables, since that's the total number
of 22 foot rolls that I'm cutting, and I have 4 constraints, namely that I get at least
as many as I need of each of the 4 roll sizes.
I'll show you in a spreadsheet.
Easy peasy.
It's really pretty simple when you look at it.
The red boxes across the top record how many 22 foot rolls we cut in each of the 7 patterns.
These values are just made up for now.
The objective counts the total number of the rolls cut, and we want to minimize that.
The constraints just keep track of how many rolls of each size we make, and ensures that
we get at least as many as demanded.
When I tell Solver to find the optimal solution to the linear program, we get this.
Yep.
Non-integral optimal solution.
I only need to cut about 5.9 rolls for it, but it's a nonsensical solution.
I can't cut fractional rolls.
How do I tell Calc, or Excel, that all of these variables have to be integers?
Very simply.
Here's the interfacing Calc.
As you can see, I just added a new constraint.
The cell reference column on the left just gives the locations of all of my decision
variables and the operator pull-down menu.
From that, I chose integer.
It works the same way in Excel.
That's it.
When we press solve, the spreadsheet starts from that branch in bound drug drudgery that
we talked about a minute ago, cranks through it, and a problem this size, well, it's not
too complex.
It takes less than a second, and we get the best answer solution, the best integer solution.
And here it is.
You can see that it's considerably worse than the LP relaxation.
If fractions were OK, we could get away with cutting a little under six rolls, but with
integers required, we're going to need to cut up seven, and in the process, we're going
to get extra unneeded rolls of the 8-foot, 6-foot, and 4-foot varieties.
The price that you'd pay for integer variables.
And by the way, don't try to generate and use the spreadsheet sensitivity report when
you're doing an integer program.
The fact that only lattice points can be solution for integer programs means that most of what
we interpreted from the sensitivity report in the last lecture, like shadow prices and
ranges, were right out the window.
They may be approximately right, but it's safer to investigate program changes by using
a tool that resolves the linear program for a variety of parameter values, like we discussed
when changing the coefficient on the left-hand side of a constraint.
But from the point of view of creating a program or putting it into a spreadsheet, you can see
that the integer variable requirement isn't really much of a bother.
It just corresponds to adding one constraint into your spreadsheet program.
From the point of view of the difficulty of finding the optimal solution, this is a quantum
leap in difficulty, though.
But let me talk about a different flavor of integer variables, one that at first blush
may sound extremely limited.
It's called by a number of names, binary variable, Boolean variable, or 0-1 variable,
and as the name suggests, it can only take on two values, 0 or 1.
That doesn't sound like much.
But remember that your computer works in binary, and that all that magic comes from shuffling
around a bunch of 0s and 1s.
One thing that makes binary variables so useful is that, having only two values, they lend
themselves to yes-no or true-false quantities.
For example, either a worker gets assigned to a shift, or she doesn't.
Binary variables are great for quantities in which there's no middle ground.
Either you assign this person to the shift, or you don't.
You can't kinda assign them.
In fact, we'll often define binary variables with just such a statement, and we understand
that the variable is 0 if the statement is false, and 1 if the statement is true.
And that coding is very useful, too, because 0 and 1 are about the friendliest numbers
you could hope for arithmetically, especially when it comes to multiplication.
One times anything leaves the number unchanged, and 0 times anything is 0.
Because of this, when I multiply a number by a 0, 1 variable, I think of that variable
as a light switch, turning the number on or off in the problem.
Let me show you what I mean.
My firm needs at least 80 employees under normal conditions, but if we accept this new
job from a major customer, we're gonna need 40 more.
So I'll let job be a 0, 1 variable.
It's 1 if we accept the job, and 0 if we don't.
We want to write the constraint that says we have enough employees for whatever we decide
to do.
That's going to be this, mp greater than or equal to 80 plus 40 job, where mp is the
number of employees.
Look at it.
When job is 0, we don't take the extra work, it just says that mp is greater than or equal
to 80.
That's our usual workforce.
But when job is equal to 1, we do have the extra work, it says mp is greater than or equal
to 80 plus 40, or 120.
That is, it says that when we have the extra work, we need 40 more people.
The job variable turned that 40 on and off.
You can get quite clever with this on-off trick.
You can even include constraints expressed in propositional logic, statements like if
we decide to build the annex, then we have to hire a contractor.
Mathematically this one becomes annex less than or equal to contractor, where annex and
contractor are 0, 1 variables.
If annex is equal to 1, we build the annex, then contractor has to be at least 1 to make
the relationship true.
And being a 0, 1 variable, that means it has to be 1, and hence true.
So annex implies contractor, like we wanted.
Binary variables are everywhere, which is a big part of why integer programming is so
important.
And happily, they're no more difficult to represent in Excel or Calc than integer variables are.
You add a new constraint the same way that we saw a few moments ago for integer variables,
but instead of selecting int from the pull-down menu, we choose bin for binary.
And that's it.
When binary variables appear in real life, they often appear in great quantity.
Let me give you a real-life example.
Number of years ago, I was consulting for a firm that delivered its products from its
warehouse to retail stores throughout its distribution region.
They had about 200 stores that they were delivering to at the time.
Trouble was, they were seeing substantial delays in delivery times.
Almost all the stores made a new order every two weeks, every 10 business days.
Orders would come in, be processed in a process that took two days, and then shipped out.
But there were some restrictions.
The warehouse couldn't handle shipping to more than 35 stores on any given day.
They were serviced by five different freight carriers, but they couldn't handle more than
two of those freight carriers to come to their warehouse on any given day.
And since each store was delivered to by a specific freight carrier, the carrier didn't
come, and if the carrier didn't come on a particular day, then the order didn't ship
on that day.
When I was called in on the problem, the average delay between ordering and delivery was about
seven business days.
And some stores have been experiencing delays of more than 10 days on the receipt of their
orders, which meant that they were actually making their new order before the last one
had come in.
Just to say that the retailers could have been happier.
So when I was called in, I asked some questions.
It turned out that each store had its own specific order day.
Store 116, for example, might order on the first and third Tuesdays of the month.
Looking at the tangle of order routings, I asked how these days were assigned.
The answer?
Randomly.
When a new store entered the system, they just picked a day.
I suggested that we change order days, making stores that serve the same geographic area
by the same freight companies order on the similar days.
I was told, and it was certainly true, that clearly I didn't work in with retailers.
They were used to the current schedule and they would not change it happily.
So no change there.
We talked about some policies of assigning days to new stores, but the problem at hand
was the current collection of 200 stores.
So I decided to solve it by writing an integer program.
Let's rough it out together.
Each store gets one delivery day out of the 10 work days in the cycle.
That's 10 binary variables for store.
For each store, do I ship on day one or not, on day two or not?
That's 10 times 200 or 2,000 binary variables.
Then there are the five shipping companies, which either come on a day or don't.
That's five companies times 10 days is 50 more variables, hardly worth talking about.
But call it 2,050 variables.
How about constraints?
Well, each store has to ship sometime.
That's one more constraint per store, or 200 constraints.
No store can ship on a day when a carrier isn't there.
That's 200 more constraints.
No day can have more than 35 stores.
That's 10 more constraints.
No day can have more than two carriers, 10 more.
And a requirement that every order took at least two days to ship I got for free from
the way that I defined my variables.
So 420 non-trivial constraints and about 2,000 non-negativity constraints.
And notice something, please.
Even though this problem is huge compared to our usual examples, conceptually, it's
no big deal.
We have two kinds of variables for stores and shippers, and we have five kinds of constraints.
That's why I've been using small examples in this course.
It's a difference of scale, not of kind.
Finding the answer to big problems is much more impressive, but the mental efforts often
not much more in terms of the heavy lifting.
Okay, anyway.
I threw this thing into a mainframe computer and ran it as a linear program, no integer
requirements.
It came back in less than three seconds with the answer.
It was a useless answer, of course, telling me to have three-eighths of a truck at the
loading dock and so on.
So I imposed the requirements that all the variables had to be binary and re-ran it.
It wasn't done in three seconds this time.
It wasn't done in three minutes.
It wasn't done in three hours.
Let me cut to the chase.
I had it running in the background on a mainframe, but I came back three days later, and it still
wasn't done.
When I said integer requirements make a program harder to solve, I wasn't blowing smoke at
you.
Although, even though it wasn't done, I had found an answer that took the original average
delay time of about seven days and got it down to two and a half, and no store had to
wait longer than five days for its order, considering that it was impossible for any
order to ship in less than two days.
That processing time, remember?
Two and a half days on average looked pretty good.
I terminated the program at that point.
I wrote a front-end interface that would make the company store information and turn it
into an integer program automatically, as well as a back-end interface that would take the
output of the program and convert it into a shipping schedule that the shipping department
could read and follow.
With that in hand, the situation changed, and when the situation did change, they could
just re-run the program to get a new answer.
I submitted my solution to the company, and it was met by a lot of happy faces.
One of them was an ex-student of mine who brought the problem to my attention to begin
with and do that a nice bonus as a result.
In part, that was because of something that happened a few months later.
The national organization of the company released a directive to all of its regional offices,
insisting that delay time is for deliveries had to be no more than five days on average
by the end of the next year.
My client could say, yeah, we're already on that.
We've got it done to two and a half days right now.
More happy faces.
It feels good to make things better, you know?
