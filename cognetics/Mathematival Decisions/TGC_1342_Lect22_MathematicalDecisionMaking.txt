Yes, thank you. My name is Scott Stevens. I only have a moment, but there's a problem
with my account and I was hoping, what? Yes, I'll hold. But I won't enjoy it. And I don't
think I'm alone in this. For something that, for the most part, consists of doing nothing,
waiting is surprisingly unpleasant. And we do a lot of it. Estimates suggest that the
average American spends between 20 minutes and an hour a day waiting. Even at the low
end, that's 37 billion hours of American time lost to waiting lines each year, somewhere
around nine months in the course of a lifetime. Trouble is, of course, we often can't just
decide not to wait. In a society where we rely on the services of others, waiting lines
are almost omnipresent. Stores, banks, restaurants, restrooms, traffic jams, amusement parks,
airports, and some places where too long a wait can be critical of not fatal, like hospitals
and disaster response. Then again, it's not just people who are doing the waiting. Every
time that you go into a fast food restaurant, your food is literally waiting to be served.
If it waits too long, it's no longer palatable. A longer wait on the food side results either
in an unsavory meal for you or the expense of throwing it away for the restaurant. There's
a cost when goods wait to be sold, even if it's just the cost of inventory, like cars
sitting in a dealership. When people have to wait in line, it's annoying and a waste
of time. When products wait in line, it's costly. Either way, it's undesirable. But
it turns out that the behavior of waiting lines, of queues, as they're called in the
UK, is subject to mathematical analysis. Queuing theory lets us characterize the behavior of
such queuing systems and provide some ideas about how to make them work better. I think
some of the results will surprise you. We're going to approach this field from the perspective
of Markov analysis, meaning that we'll ignore everything about the past except the current
state of things. Let's start with an example where the things in line aren't people. You
offer online computer services to customers, and doing so requires that you have two mainframe
computers online at all times. When both machines are online, you're literally in business,
and you generate a revenue of $6,000 a day. Computers will go down from time to time,
of course, but for the moment, let's say you're taking that risk. Your data shows that on
average, your computer breaks once every six and a half months or so, once every 200 days
on average. When one does break, your income stream stops with it. In fact, it's worse
than that. Your clients are making critical transactions, and if they can't rely on your
service, they leave. You estimate a loss of $28,000 for every day that your system is
down. For a big mainframe, it takes an average of four days to get a computer that fails
back online. Online or not, a mainframe computer costs you $1,000 a day, and if it's broken,
the repairs cost $1,000 per day on top of that, and the repair team can only work on
one down computer at a time. So your business is okay if it's not down too often. Let's
draw a Markov diagram of your situation. It has only three states, depending on how many
of your computers are up and running. In this diagram, each transition represents one day.
The number in the middle of a circle indicates how many computers are up and running on a
given day. The arrows show the possible transitions from state to state. The arrow with the one
fourth probabilities reflect the fact that it takes an average of four days to repair
a broken computer. If every day a broken computer has a one fourth chance of being repaired,
then on average it takes four days to repair it. Having the same chance to repair each
day leads statisticians to call the result the geometric distribution, and it's what
you get out of a kind of discrete Markov process like this. In the same way, the working computer
has a one two hundredth chance of breaking per day, reflecting that it breaks on average
once every two hundred days. When two computers are working, the chance of a computer breaking
doubles to two and two hundred. Yeah, technically here there are some small errors in this model
since both computers could possibly break on the same day, or one computer could break
on the same day that another returns to service. The chances of these events are very small
though, so I'm going to ignore those things for now and come back to them a bit later.
If nothing breaks or is repaired on a given day, the system loops back to the same state
it had at the beginning of that day. Sensibly enough, the total probability leaving each
state is one, which is how we found the looping probability. This indeed is a queuing model,
though it's probably not what you normally think of when you think about waiting lines.
Here the customers in line are machines waiting to be repaired, and the entire population
of potential customers consists of only two individuals. We can analyze this queuing system
using the work from our last lecture on Markov analysis. The system is ergodic. You can verify
that you can move from any state in the picture to any other one in exactly four transitions,
and that means that in the long run the system is characterized by its steady state vector.
Using the techniques from last time, we get the steady state vector as this, meaning that
your system is up with both computers online about 96% of the time, and at least one is
down about 4% of the time. We can then find the average profit per day in an expected value
calculation, probability times payoff added up over all the possibilities. Here 96% of
the time you make $4,000 a day, that's the $6,000 revenue minus the $2,000 in operating
expenses. The remaining 4% of the time you lose $30,000 a day since you're losing customers,
paying for machines, and making repairs. On average that works out to be about $2,667
a day. Not bad, but it's quite a bit less than the $4,000 a day you'd be making if your
machines never went down. The sizable difference reflects the fact that you have a customer
demand that's strongly affected by waiting. Not having two computers online really costs
you. So is it worthwhile to have a backup computer? The bad part of the idea is that
it's going to cost you an extra $1,000 a day. But the good part is that you can have one
computer fail and still not hurt your business. Is the increased reliability worth the cost
of providing it? Well, let's modify the last markup diagram
and add a new machine. It's easy. We had one more state for having three machines in operation
with one of them on standby. Either of the two active machines might fail one more in
this state, so there's a two and two hundredth chance of a failure on a given day. I'm assuming
the machine that's on standby can't fail. On the other hand, if a machine's broken there's
a 25% chance that it'll be repaired during a day, so we have those one-fourth transition
probabilities from two functioning machines up to three. The steady state vector for this
markup system is this. Now, like before, this customer incurs a dissatisfaction if fewer
than two machines are in operation, but now that only happens 0.16% of the time. Even
taking into account the cost of the backup machine, your average profits per day rise
to 2,947 as opposed to 2,667 without the backup. And that translates into an extra $100,000
per year for you and happier customers. A win-win situation. So, chewing theory says
get the backup. Before we go on, I do want to address one
weakness in that analysis. We've been assuming that each transition represents one day. That
is, we assume that each day at most one thing could happen. But of course, we could have
two machines breaking on the same day or a repair and a breakdown on the same day and
so on. Then again, every repair took a whole number of days. We never got the system back
online in, say, 16 hours, but in real life we could. It's easy to address these issues
by moving from a discrete markup process, like we've been using so far, to a continuous
markup process. In fact, most of chewing theory is done in this continuous process way. We
just make a transition represent what happens during a very brief interval of time of length
dt. Our original problem without a backup, for example, would look like this. There's
not really that much difference between this picture and the earlier one other than the
addition of those dt terms and what you see. The diagram really just carries forward the
argument that we made for daily transitions. What we said was that at the average time
for a computer repair is four days, then on a given day, there's a one chance in four
that the machine will be repaired, which is where the one fourth came from. But by this
same logic would have led to the idea that in a half day, we'd have a one eighth chance
of repair or a quarter day, one sixteenth chance of repair and so on. In general, during
any tiny fraction dt of a day, the repair chance would be one quarter times dt. In the
limit as dt approaches zero, this picture then describes a continuous process where transitions
can occur at any time. The continuous model gives the same steady state as the discrete
one does. And again, the markup model is assuming that the chance of transition out of a state
during an interval doesn't depend on how long it's already been in that state. That is,
the process is memoryless. We'll come back to this idea in a few minutes.
But whether we use the discrete or continuous model, this system is going to approach the
same steady state in the long run. But with the continuous model, we no longer have the
concern of two events occurring in the same time. With dt small enough, each transitions
a very brief span of time. The chance of a repair or a breakdown occurring during a
single transition, quite small. But the chance of more than one occurring during the same
interval is so small as to be negligible. Still, maybe this situation doesn't feel like
a waiting line to you. When you think about a waiting line, you probably imagine people
standing in line, perhaps a very large number of them. And the size of the calling population,
the people that could enter the queue, is much larger than the queue length that we generally
observe. The number of people checking out of a grocery store might be sizable, but it's
a far smaller quantity than the population of everyone who ever goes to that grocery
store. In such cases, mathematicians usually take the population as if it were actually
infinite. It makes the math easier. And the error introduced by doing so is generally
quite small. Generally, if no more than 5% of the relevant population is usually at
the queuing facility, you don't make much of an error by considering the population
to be infinite. And if the population has unlimited size, then in general, the length
of the queue could be anything too. Sometimes, like with a call waiting on a land line, the
system can become full and not accept any more arrivals. But the simplest model for a
queueing system is, if someone wants to get in line, let them get in line.
Let's look at this kind of queueing system, assuming that we only have one server. This
should be like a convenience store with only one cashier. Keeping with our Markov idea,
we're going to assume that there's an equal chance of a new arrival during any small time
interval, but that if a customer is already being served, that customer has a fixed chance
of completing service during each small time interval. This model is usually called the
MM1 model, which is short for Markov Markov 1. The first Markov talks about the pattern
of new arrivals, and the second Markov talks about the pattern of service times. And the
one, that means we only have one server. Here's the picture. The number inside each
circle is the number of customers in the system being served right now or waiting to be served.
The picture extends off to the right forever. Traditionally, we use lambda to represent
the arrival rate of customers per unit time, and mu, the next letter in the Greek alphabet,
to represent the average departure rate due to customers being served per unit time. dt is
some tiny fraction of one unit of time, and which in the limit goes to zero. When someone shows
up, the number of people in the system increases by one. When someone leaves, the number decreases
by one. I've suppressed the pop probabilities in the loops where nothing happened during
the short time interval dt, but they're easy to recover. Remember that all of the arrows
leaving a node have to always add up to the total probability of one. While a steady state
vector for this system is going to tell us how often, in the long run, the system will
be in each of these states, it's easiest to find the steady state vector if we forget about
probabilities for the moment, and think of the diagram as a rather elaborate water fountain.
Each state, each circle, is a basin containing a certain amount of water, and the arrows tell
you what fraction of that water will move along that arrow to a different basin during
one transition. Dump one gallon of water in this fountain wherever you want, and let it run
until things steady out, with the water level in each basin stabilized. The number of gallons
in each of the basins will give you the steady state vector of the system. In this stable
steady state configuration, there are P0 gallons of water in basin zero, P1 gallons in basin
one, P2 gallons in basin two, and so on. Obviously, if you add all these P's, you have to get
one, since we started out with one gallon. Ok, now focus just on the arrows joining basin zero
to basin one. In the steady state, there are P0 gallons of water in basin zero, and the fraction
that moved to basin one during the transition is lambda dt. So in one transition, P0 times
lambda dt gallons, move from basin zero to basin one. At the same time, there are P1 gallons
of water in basin one, and the fraction moving to basin zero during the transition is, according
to the arrow, mu dt. So P1 times mu dt gallons move from basin one to basin zero. If we're
talking steady state, the transition doesn't change the amount of water in any basin. This
means that what flowed from zero to one must be exactly the same as the number of gallons
that flowed from one to zero. That is P0 times lambda dt equals P1 times mu dt. Solve this
for P1, and you get P1 equals lambda over mu times P0. You can apply exactly the same
reason into each other pair of adjacent basins, and you get parallel results. So P2 equals
lambda over mu times P1, P3 equals lambda over mu times P2, and so on forever. In general,
P sub i plus one equals lambda over mu times P sub i. Now, remember that all these P sub
i are actually probabilities, and they have to add up to one. P0 plus P1 plus P2 and so
on equals one. The sum goes on forever. It just says that the chance of no customers
plus the chance of one customer plus the chance of two customers and so on forever has to
add up to 100%. And we can use this to find all the P sub i, like this. Start with our
equation and make a second copy of it, but multiply this second copy through by lambda
over mu, like this. Again, remember that these sums go on forever. Okay, now recall that
our Markov work said that when you multiply a P i times lambda over mu, you just get the
next P in the list, P sub i plus one. So let's rewrite that lower formula. Now subtract
the lower formula from the upper one. On the left side, everything cancels out, except
for P0. Remember, these sums go on forever, so there's no last term left over on the bottom
there. On the right, we get one minus lambda over mu. So P0 equals one minus lambda over
mu in this model, and each P sub i after that is lambda over mu times the P that came before
it. So if I tell you the arrival rate lambda and the service rate mu, you'll know all the
P sub i. And these numbers have a lot of practical significance. For example, P0 is the fraction
of the time that the system has no customers in it. No one's being served, no one's waiting
in line. From the point of view of the people providing this service, that is not a good
situation. They're paying to supply a server, but this server has nothing to do. From the
point of view of the service provider then, a small value of P sub zero is desirable. You
don't want to have your workers goofing off. But turn it around and look from the customer's
perspective. In a single server system, you like it when there's no one in the system
when you arrive in the line. That means you're served immediately. If the server's busy 90%
of the time, then 90% of the time you have to wait for the server to get to you. If the
customers are impatient, this kind of delay may be worse for business than having servers
that aren't that busy. That's why luxury hotels have more staff than budget motels.
Since the fraction of the time that the server is free in an MM1 model is one minus lambda
over mu, as we just found, then the fraction of the time that the server is busy is one
minus this, just lambda over mu. The arrival rate divided by the service rate. With a little
thought, you could probably have guessed this. If customers arrive at an average of four
per hour, and if the server can handle an average of five per hour, then on average,
the server is only busy four-fifths of the time. Since on average, one-fifth of the server's
capacity is going to be unused. And that means that P sub zero, the chance that there are
no customers in the system, is one-fifth. So one-fifth of the time, a newly arriving
customer gets served without waiting. But wait a second. If the server can handle customers
faster than they're coming in, why does anybody ever have to wait? Imagine an assembly line
where assemblies come down the line every five seconds, but it only takes four seconds
to add your part to the assembly. You work for four seconds, rest for one, work for four,
rest for one, and so on. And no assembly ever has to wait for your service. True. But remember
that we're assuming that arrivals follow a Markov process, with each tiny time interval
being equally likely to contain an arrival. What does this memoryless arrival process
look like? Think about popcorn popping. Not right when it starts or near the end, but
the part in the middle. You know what it sounds like? Like this. Pop, pop, pop, pop, pop,
pop, pop, pop, pop, pop. My friends, every Markov arrival process, which is also called
a Poisson process, is going to sound just like popcorn popping, except that it may either
be sped up or slowed down. It turns out to be a good model of a lot of different arrival
processes. Telephone calls at a switchboard, requests for documents on a web server, people
arriving at a grocery store, cars driving past a mile marker on the highway. And it's
an oddity of the mathematics that if each little time interval has the same independent chance
of containing an arrival, then the observed arrival pattern tends to include clusters
of arrivals and are sourced with relatively dead intervals, which solves the mystery of
why popcorn popping sounds the way that it does. It's not peer pressure. A colonel doesn't
say, oh, all of my friends are popping. I've got to. It's just the Poisson process at work.
Now let's look again at our waiting line where people arrive on an average of four per hour.
That means that there's a one 15th chance of an arrival during any minute. Think of
really slow popcorn. There are going to be some times with long gaps between one arrival
and the next. And the server is generally going to be standing around with nothing to
do. But sometimes we'll get clusters of several people arriving by closely separated times.
And then some of them are probably going to have to wait. And remember, we've got similar
uncertainty in service times. The server on average handles five customers per hour or
12 minutes per customer, but that's only an average. The actual time is spread out like
the time between consecutive pops of popcorn, sometimes very short, occasionally quite long.
We can use our equations for our P's to find out how much effect this variability adds
to our system. We said that if Lambda is four customers arriving per hour on average and
Mu is five customers per hour, the service rate on average, then the server's busy four
fifths at the time. So P zero is one fifth. But recall that for this simple model, each
P is the P before it multiplied by Lambda over Mu. And here that's four over five. So
we get this. Each bar is four fifths as tall as the one to its left. Tell you the truth,
I still find this kind of surprising. If the arrival rates only 80% of the service capacity,
I think that most of us would imagine that lines wouldn't generally be much of a problem.
But you can see here that a single server system with these kind of random arrivals and
service times is going to have a considerable line a lot of the time. Usually the system
will have three or more people in it. And more than 10% of the time, it'll have 10 or
more people in it. By the system, I mean the people waiting in line along with any people
currently being served. The average number of customers in this system in the long run
tends out turns out to be four. From my money, though, the single queuing statistic of greatest
importance is the average time that a customer spends in the system from the moment that
that customer joins the system, as well as the moment that his or her service is completed.
This is called W, which stands for the word wait, since it's the average waiting time.
You can use the values of the piece of I from the MM1 model to find the value of W, but
the work involves infinite series. When the smoke clears, though, it turns out that the
answer has a particularly simple form. W equals one over Mu minus Lambda, which I think is
just a lovely equation. Applying it to our current example where the customers arrive
at a rate of four per hour, and the server can handle five per hour, this means the
newly arriving customer will spend an average of one over five minus four, or one hour in
the system. Yeah, that's right, an hour. If customers arrived evenly spaced in time and
service times were constant, everyone would be served immediately, and everyone would
spend 12 minutes in the system. But the random nature of arrivals and service has increased
this by 400%. And that's only the average. Some customers spend much longer than an hour.
Now this is a very simple model, but it provides some pretty important insights into how queuing
systems behave in general. Random variations in arrival times and service times can considerably
degrade system performance. A system can be made much more efficient if, for example,
arrivals can be scheduled, such as making appointments. But in much of Western life,
we enjoy the flexibility of requesting service whenever the whim hits us. Arrivals then look
pretty much like a Markov process, and the problems that we're seeing here manifest.
And of course, you can't schedule arrivals in some situations like when computers break
down or people need emergency medical attention. Another important point, the problem only
gets worse if the system is pushed closer and closer to its capacity. In fiscally challenging
times, many organizations try to do more with less, so they may add to the load on the queuing
system without increasing its capacity. Let's get a feeling for the effect of this with
our current queuing example. Suppose we decide to increase the average load of our queuing
system by only 20% from 4 customers per hour to 4.8 customers per hour. People who have
never studied queues tend to expect this to degrade system performance by about 20%.
People may have to wait 20% longer for service, for example. Is it true? Well, let's use our
MMM1 equation for the average time in the system. W is 1 over mu minus lambda, which
is now 1 over 5 minus 4.8. That's 5 hours. This is staggering. A customer is actually
in service for only 12 minutes, but to get that service, the average time in the system
is now 5 hours. A 20% increase in load resulted in a 400% increase in the average time a customer
spends in the system. As the load on a queuing system approaches its capacity, the performance
of the queuing system degrades with mind-blowing speed, assuming that there's no limit on
how long the line is allowed to be. If you ever saw the I Love Lucy episode, maybe you
can recall this scene in a candy factory. Classic comedy. Two women wrapping candies
that are brought to them on a steadily moving conveyor belt. All is going wonderfully until
the spacing between the candy shrinks and shrinks and shrinks. Lambda, the arrival
rate is increasing, and mu, the service rate, is staying the same. You might not be able
to predict that Lucy ends up shoving the candies into her mouth, her clothes, her hat, but
you can certainly predict disaster. In most queuing systems, the problem is just as severe
if not so amusing. When the arrival rate grows bigger than the capacity of the service, the
overload work backs up further and further, and the system never reaches a steady state.
Our equation for W actually falls apart entirely in this case and gives a negative answer. Mathematically
it's because we passed the radius of convergence for the infinite series that describes this.
More simply, we've got a nonsense answer to a nonsense question. The system has no steady
state. So what do you do when you have too much work? The obvious answer is to add more
workers. On the candy conveyor line, we just saw that two servers was clearly wasn't enough,
or you can limit the jobs you accept. If I have traditional call waiting, for example,
I can be serving one person and having one person waiting to talk to me, but if another
person calls, they're not permitted to wait. They get a busy signal. There are a lot of
ways that you can modify a queuing system. You can introduce a priority discipline like
an emergency room, where more important calling units are taken first. The thing is, each
of these different choices changes the equations that describe the model. Most of them are
derived in a way similar to the way that we analyze the Markov diagram for the MM1, but
with more complicated math. There are tons of queuing theory models, and you can often
look up the equations to fix your situation, but some queuing systems are so complicated
that it's just easier to simulate the model of the system and work with that. We'll be
discussing simulation in our next lecture. Once you've got your model, though, what do
you do with it? Queuing theory isn't an optimization technique. It doesn't tell you the best thing
to do, but it does allow you to consider the consequences of your various possible choices,
and then you can see what options look most attractive. Suppose we're talking about a
tool crib and a factory. The people waiting are the workers who need the tools in the
crib. Suppose these are skilled workers who cost the company $20 an hour. The workers
in the crib are less skilled and cost $12 per hour. In a lot of queuing problems with people,
we have to worry about the fact that people are impatient. Their customers and losing
their goodwill and patronage is bad for business. In this problem, though, the people in line
are employees. We're not worried about their impatience. We're worried that we're paying
them $20 an hour to stand in line. Let's stick with our earlier MM1 model and assume
with an average of 4.8 workers per hour that want the tools and a server able to handle
5 workers per hour. We call the average time in the system for a worker was a whopping
5 hours. What is this costing us? Well, each skilled worker that joins the queue stays
an average of 5 hours and they cost us $20 an hour. That's $100 per worker that gets
in line. And on average, 4.8 get in line per hour. So on average, we're losing $480 worth
of skilled labor each hour. Add the $12 for the tool crib worker and that's $492 per hour.
That's obviously not acceptable. But we can work out the same kind of calculation for
two or more workers using somewhat more complicated equations. And here are the results. As you
can see, adding just one more server reduces the average waiting time from 5 hours to 15.5
minutes. And that includes the 12 minutes of actually being served. Hourly cost drops
to from $492 to just under $49. A 90% cost decrease. More than two quilt tool crib attendants
aren't worth it though. The additional reduction in waiting times doesn't pay for their cost.
So two tool crib workers is the way to go. Playing around with queuing models can reveal
a lot of non-intuitive solutions for practical problems. For example, imagine two secretaries
each with a boss and each with enough work to be busy three quarters of the time. It
turns out that if the two secretaries were reorganized into a pool, handling the work
of the two bosses on a first come first serve basis, the average time to complete a job
is cut almost in half, even though neither secretary is working harder than they were
before. The secretarial pool helps to address the clustering problem of Poisson arrivals.
I actually used this idea to help a telecommunications company give better customer service to clients
who called the customer's regional offices with questions. If a call wasn't region specific,
we could reroute it to an operator who was free in another regional office. Simple and
effective. The firm ended up using fewer operators but giving better service. But when the calling
units are people, the solution isn't always found in mathematics. Psychological factors
play an important role. The Houston airport was receiving complaints from customers about
long waits at baggage claim. They added more baggage handlers and got the average time
from a disembarkation to collecting bags to eight minutes, well within industry standards,
but they still got complaints. On closer examination, they realized that the passengers were spending
one minute walking from the plane to the baggage claim and seven minutes waiting at the baggage
claim for their bags. The airport moved the baggage claim further from the planes, so
it took passengers six minutes to walk there. Now they only waited two minutes for their
bags and the complaints ceased. Now I think about that every time I take that hike at
the airport. And waiting feels longer when you're unoccupied. That's why there are often
mirrors near elevators. That's why the Disney parks always give you something to look at
as you wait for a ride. In fact, the Disney parks are masters of the psychological aspects
of managing queues. The single file queues move at a brisk pace, making customers feel
like they're making good progress. The times posted, like 30 minutes from this point, always
overestimate the actual average time from that point. Having mentally committed to a
30 minute wait, guests feel they're ahead of the game when they're boarding the ride
after only 23 minutes. And there's a chance you might be able to get your picture taken
with Chip and Dale. Waiting in line is boring, but the study of waiting lines is anything
but. Understanding human psychology can make queues less painful to the people in them
and even better, understanding the mathematics of queues, can help us design systems to give
better traffic flow, better healthcare, faster emergency response, and more efficient production
and service. Yes, yes, yes.
