The chance that something is true changes as new and better information becomes available.
Simple idea, but it's the key to Bayesian analysis.
I want to start with an example, and I think that you'll see that the mathematics for it
deserves to be known and used far more widely than it is.
On June 1, 2009, Air France Flight 447 left Rio de Janeiro, Brazil on its way to Paris.
About four hours later, the plane, an Airbus A330203, was over the mid-Atlantic, having
just crossed the equator.
It was never heard from again.
The plane went down, killing all 216 passengers and 12 flight crew, making it the deadliest
accident in Air France's history, and the highest death toll on any A330203 crash anywhere
in the world.
Although a search was quickly launched, it was clear that there was no hope of survivors,
and indeed, it took five days before debris and bodies from the crash were located.
Nine days after the crash, a total of 50 bodies were recovered in two distinct groups, more
than 50 miles apart.
But finding the impact site itself was a matter of considerable importance.
Like other commercial airliners, the plane contained a flight data recorder and a cockpit
voice recorder, the black boxes that had been ruggedized to survive a crash landing.
Their contents would be invaluable in determining what happened to AF447 between its last known
location and the moment of the crash.
Even though the water in the area was deep and the seafloor mostly rugged, the recorders
were equipped with locator beacons, pingers, that are designed to activate in contact with
water.
They were designed to operate for at least 30 days.
So for about a month after the crash, two tugboats pulled a passive sonar arrays through
the rectangular area of about 50 by 60 nautical miles to the northeast of the last known location
of Flight 447, more or less along its intended flight path.
It was estimated that the arrays would have a 90% chance of detecting an active pinger,
but no signal was heard.
With the battery life of the pingers exhausted, a new phase of the search was initiated.
This one used side-looking sonar in a region just south and east of the plane's last known
position.
It, too, was given a 90% probability of spotting the wreck if it were there, but it, too, found
nothing.
So phase three of the search began, with ships from the U.S. Navy and the Woods Hole Oceanographic
Institute.
Day two used side-looking sonar and focused on the areas suggested by a group that had
research drift in the area, roughly a wide wedge extending to the northwest from the
last known position of AF-447, out to about 40 nautical miles.
Once again, the search was considered 90% likely to find the wreck if it were there.
Once again, failure.
In July of 2010, more than a year after the crash, the French Bureau of Enquiry and Analysis
for Civil Aviation Safety, BEA for short, decided a different approach.
That approach was Bayesian analysis, using the information already available to create
new maps, giving probability distributions for AF-447's final resting place.
They asked the U.S.-based consulting firm Metron to do the work.
It was a natural choice.
The chief scientist of Metron had previously helped to find the sunken nuclear submarine
USS Scorpion back in 1968, using just this technique.
Bayesian analysis is named after the Englishman Thomas Bayes, an 18th century mathematician
and Presbyterian minister, who proposed a special case of what's now called Bayes theorem.
It's a powerful tool, but the idea behind Bayesian analysis is really pretty simple.
The chance that something is true changes as new information becomes available.
Bayes theorem tells you how to compute the new probabilities.
Like this.
I have here three cards, two red ones, and one black one, Ace of Spades.
And I shuffle them up and deal them out on the table.
The one on the left is yours, and in a moment I'm going to reveal the card on the right.
The question of interest is, do you have the Ace of Spades?
Well, the Ace of Spades is equally likely to be in any of the three positions, with
a one-third chance of each.
That's called the prior probability distribution.
It's the distribution before any new information comes in.
So your chance of having the Ace of Spades is one-third.
But now, I follow through with my promise to reveal the rightmost card.
And whatever happens, you're going to learn something.
Like this.
A red card.
I don't have the Ace.
Which means it's one of those two.
The odds of you having the Ace of Spades has now gone from one in three to one in two.
And you got lucky.
That's basically what Bayesian probability does.
We begin with a prior probability distribution, a specification of the probability of each
possible outcome.
Then we get some new information.
Bayes theorem then allows us to compute the updated probability for each possible outcome,
the so-called posterior probabilities.
Our original information is combined with the new information to tell us how our original
probabilities figures should change.
So how does this apply to the Metron analysis of AF447?
Well, they needed a prior probability distribution, and that wasn't as simple as our randomly
shuffled three cards.
They looked at how much time elapsed between the transmission of the plane's last known
position and the time the next signal should have come in, and determined the plane could
not have flown more than 40 nautical miles in that time.
So they started with a uniform distribution on a 40 nautical mile circle.
A uniform distribution gives the same probability to every point in the region, so Metron was
assuming for starters that the wreck was equally likely to be anywhere in that 40 nautical
mile circle.
But the accidents certainly seem to involve a loss of control.
The aircraft and studies on similar crashes from similar heights show that they generally
occur within 20 nautical miles of where the emergency started.
So Metron combined the uniform distribution with a normal curve, a haystack in probability,
centered on the last known position.
The further you got from the last known position, in other words, the less likely the plane's
wreckage was to be found there.
They created a prior probability graph of concentric circles, like this one, with hot
colors indicating high probability, a heat map, like we discussed in our data mining
visualization lecture.
The outer circle of the map had a radius of 40 nautical miles.
Anything else?
Well, debris and bodies from the plane were found, and computer programs tried to model
the possible drift paths they might have followed, but this is unbelievably hard.
The simulation suggested that the bodies originated in a corridor through the last known position
of the plane and running from southwest to northeast.
Metron didn't weigh this heavily in creating its prior probability distribution, though.
The analysis just wasn't that reliable.
So when they got done, their prior distribution had a patchy corridor of hotter colors, whereas
some of the probabilities were given slightly higher probability.
Again, the central red region shows the area of highest probability, and the colors cool
as the probability drops.
This was Metron's best guess about where to look, ignoring the searches that had already
been done.
But of course, ignoring those searches was exactly what Metron didn't want to do.
They were like Sherlock Holmes in the story of the Silver Blaze.
There, Holmes solved the crime by noting an odd clue, the dog that didn't bark.
Peter and Metron wanted to redraw the map on where to look for AF447 by using the information
of where it wasn't found.
This isn't quite as simple as it was in our card game.
If I turned up my card and you saw that it wasn't the ace of spades, you could be sure,
noted about it, that the ace was one of the other two cards, with equal likelihood.
But the sonar scans for AF447 weren't perfect, only about 90% likely to find the ship.
This makes things trickier.
In fact, if you imagine a completely general search, it could be worse still, there could
be false positives.
The equivalent in our card game of there being a chance that I'd tell you I had the ace
of spades when I really had a red card.
To handle all of this, we need more machinery than we needed for our original card game.
We need the full power of Bayes' theorem.
To see how this works, I'm going to take the Air France search and simplify it just a bit.
Metron was dealing with thousands of possible distinct rec zones in their map, but we won't
lose any of the concepts involved if we simplify this down to six, like this.
Search one would look for the pingers in the rectangular region, including zones two, three
and four.
Stage two of the search looked in zone five.
Stage three searched the wedge, including zones one and two.
Zone six was never searched.
Now we begin with a certain chance that the wreck is in each of these zones, our prior
probability distribution.
Zones two, three and four are all in the hot part of our map, the areas of higher probability.
This is especially true for zone four, but it's also relatively small.
Zone six is quite large, but most of it would require the plane to turn around from its
last reported position, which is marked with an orange cross in the middle of the circle.
So let's start out with a prior probability distribution, just using our best initial
guesses, like this.
For example, zone three has the best chance being large and including an area near the
center of the search.
So let's say 25% chance of the wreck being there.
The large zone two is along the flight path and is second with 20% tied with the smaller
but more central zone four.
We'll give the smaller but nearly central zone five a 15% chance and zones one and
six bring up the rear at 10% each.
Although they're large areas, they require substantial flight path deviations to be the
crash site.
What we're going to need to do is to modify our probabilities in terms of the new information
that we get.
The first piece of new information was from the passive sonars towed by the tugboats,
a quite large sweep with a 90% chance of detecting the black box pingers.
In our model, the sweep would cover zones two, three and four.
This search revealed nothing.
Assuming that the pingers were working, that means that either the wreck was somewhere else
or the wreck was in zones two, three and four, but the sweep missed it.
Base theory and computes how likely a particular result is in terms of the information you
require.
Here that means given that you got this search result, how likely is that the wreck is actually
there?
You'll probably recognize this as a conditional probability, the chance of one thing given
another.
Here, we'd like to say given that the ship wasn't found in two, three or four, how likely
is it that nonetheless the ship was in zone two or three or any other particular zone.
And symbols would write this for the probability that the wreck is in zone two, given that
it was not found in zone two, three or four.
Okay, how do we find this?
Well, that's a good question.
If the search fails, how likely is it that the ship was actually there?
You know, it's kind of a shame that's what we want, because if you flip that conditional
around, it's really easy to answer.
Flipping it around would give, if the ship is in the searched area, how likely is it
that the search fails?
And we were told that.
That's, it's 90% likely to find the wreck if it's there.
So if the wreck's there, the search is 10% likely to fail.
Unfortunately, probability that the wreck is there, given search failed, which is what
we want, isn't at all the same as the reverse conditional probability search failed given
wreck is there.
These two conditional probabilities are quite different.
Look, given that two men are father and son, the chance they share a last name is quite
high.
But given that two men share the same last name, the odds that they are father and son
is very small indeed.
Happily, though, even when the conditionals are reversed and they're very different, they're
related in a way that's going to let us crack the Air France puzzle.
And the key is something we talked about a couple of lectures ago.
Remember this guy?
We used him as a mnemonic for joint probability, probability of A and B. He has to complete
the obstacle course by clearing both obstacles.
And we said to do both, first he has to complete one, and then given he succeeded in that,
he has to do the other.
The probability of finishing the course of both A and B being true is the product of
these two probabilities.
The probability of wreck in area times probability of search fails given wreck is in that area.
And we can do this calculation for any zone we want.
For example, zone two.
The chance of the wreck being in the area is 20% according to our prior probability distribution.
That's the first obstacle.
Now given that the wreck is in that zone, how likely is it for the search to fail?
Well, the search includes zone two, and if the wreck is there, it will spot it 90% of
the time.
So given that the wreck is in zone two, there's a 10% chance of a failed search.
So a 20% chance of a zone two wreck times a 10% chance of missing it if it's there gives
0.2 times 0.1 or 2%.
That is, there's only a 2% probability of both of those statements being true of the
wreck actually being in zone two, but our search is not finding it.
Unfortunately, this isn't quite what we wanted.
We wanted the reverse conditional.
We know how likely it is that we'd fail if the wreck were in zone two, but what we want
is how likely is that the wreck is in zone two given that we fail?
Well, if you want the reverse conditional, reverse the obstacle course, like this.
Now what does our runner face?
To complete the course, to do both A and B, first he has to accomplish B, and given that
he did, he has to accomplish A. That is first, the search has to fail.
And given that it fails, the wreck has to be in the area.
Now here's the key observation.
Our little friend, regardless of his orientation, has to run the same course, as far as probability
goes at least.
When he finishes the course, you get the probability that the wreck is in the area and the search
fails, which is the same as the search failing and the wreck being in the area.
Running left to right, we found this probability as 0.02.
So running right to left has to give the same answer.
And the second hurdle in running from right to left is exactly the probability that we
want.
The probability that the wreck is in zone two, given that the search failed.
But to find it, we have to find the probability of clearing the first hurdle.
That is, we need to find the chance that the search fails.
Getting this is a little trickier than you might think.
That's because there are actually six ways for the search to fail.
The wreck, of course, is in one and only one of the six zones.
That means that if the search fails, either it failed and the wreck was in zone one, or
it failed and the wreck was in zone two, or it failed and the wreck was in zone three,
and so on.
The total chance the search failed is the chance that any one of these six combinations happened.
Can we find the probability of each of these combinations?
Sure, easily.
Each combination is the chance that the search failed and that the wreck is in that particular
zone.
We already did this calculation, for zone two, at least, running left to right through
our course, and we got an answer of 0.02, or 2%, and in an exactly analogous manner,
we can do the similar calculation for every other zone.
Take a look.
First, each term on the right is the prior probabilities that we originally assigned
to each zone.
Let's put them in.
Okay, now how about the conditionals?
Well, look at the first one.
It says that if we know that the wreck is in location one, how likely is it that a search
in locations two, three, and four will fail?
Well, it's guaranteed, isn't it?
Unless the equipment got false positives, thinking that it found a wreck where none
existed, you can't find a ship if you're not looking where it is.
And that's true for locations five and six, by the same logic.
For the other three locations, we use the logic that we used for zone two.
If the wreck is in zone two, three, or four, the search is going to find it with a probability
of 0.9, so it has a 10% chance of failing, like this.
So, let's come up for air and see what we've got.
If the search fails, then exactly one of six different things had to happen.
The wreck could be in zone one, and the search fails, or it could be in zone two, and the
search fails, and so on.
We found the probabilities for each of these possibilities.
So if the search failed, exactly one of them had to happen, and that means you can add
up those six probabilities to find the chance of a failed search in zones two, three, and
four.
Just add them up.
There was a 41.5% chance that the initial sweep in locations two, three, and four would
fail.
So, we can finally calculate the posterior probability that started all of this.
Knowing that the sweep did fail, what's the probability that the wreck was in zone two?
From our runner, we had this.
Probability of wreck in zone two and search fails is probability that the search fails
times probability of wreck in zone two given search fails.
And we know everything in this equation with the last term, which is the one we want.
Plugging in the numbers, or for the other two quantities in solving, gives us this.
The probability that the wreck is in zone two, given that the search fails, is .048.
That is, the search gives a 41.5% chance of failing, and given that it did fail, the probability
of the wreck being in zone two just dropped from 20% down to 4.8%.
And that's what Bayesian probability is all about.
We can do exactly the same kind of calculation for each other location to get a new probability
of the wreck being in each of the six locations.
In fact, we can just take the six joint probabilities that we found, and divide each by the probability
of a failed search in zones two, three, and four, which was .415.
Here's what the result would look like.
As you can see in red, factoring in the fact that the first search was a failure, the most
likely resting place for the wreck is now zone five, with about a 36% chance of holding
the wreck.
In real life, the second search was conducted in zone five, using side-looking sonar.
This search failed as well.
So what we want to do is the same kind of work that we just completed, using Bayes theorem.
We use the red distribution as our prior, and compute the posterior probabilities for
each zone, given that we had a failed search in zone five.
Here's what we get.
Check out the green bars.
The failure of the second search makes zone one and six the most likely candidates for
the wreck, each with about a 36% chance of containing the wreck.
Zone six is huge, though.
In real life, the third search was in zones one and two.
Its failure allows us to apply Bayes theorem one more time, using the green distribution
as the prior, and resulting in this.
At this point, the wreck is about 83% likely to have already been found.
Since it hasn't, the best bet is the only zone not yet searched, zone six, with about
a 58% probability.
Metron's analysis was actually very much like our own, but with thousands of zones,
rather than six, and with a more careful creation of the prior distribution.
The map that they got after doing their analysis looked distinctly different from the one they
started with.
Areas where the failed search had been conducted showed dramatic cooling of the colors.
The probability of the wreck being in these regions was greatly reduced.
At the same time, the colors in the unsearched areas were notably hotter.
Their posterior probabilities, in light of the new information, were higher than the
original ones.
Just like our work, where zone six is now our best bet, except in our analysis the odds
were quite good that the plane wreck would have been spotted by now, about 83%, since
we're 90% likely to see a wreck if it's there, and we haven't seen it.
Maybe we were just unlucky, and Air France 447 went down in the huge, if fairly unlikely
zone six.
But Bayesian analysis showed that the odds were very good that the plane would have been
found by now.
If it really was in zone six, its size was going to make it for a very slow search.
But the people at Metron were beginning to think that perhaps that wasn't what happened
after all.
Before tackling zone six, they explored another idea.
What if, for some reason, the pingers malfunctioned?
What if the search of zones two, three, and four was unsuccessful?
Because there was no sonar ping to hear.
They redid their work under this assumption, more Bayesian analysis of the kind we just
did.
And the new heat map showed a strong concentration of probability within about 10 miles of the
plane's last reported position.
Metron advised another search of this area, and after one week of additional searching,
the wreckage was found in the location well within that high probability zone, about
10 miles north northeast of the last known location.
No one knows if the pingers failed to operate.
The BEA says that they're highly reliable.
The probability map suggests that something either kept them from working or kept them
from being detected.
It's not certain, but given the results of the Bayesian analysis, it seems a real possibility.
Understanding Bayesian probability is, I think, terrifically important because failing to do
so can lead to a lot of bad decision making, including racial prejudice, medical misdiagnosis,
and bad public policy.
The reason is that most untrained people fail to distinguish between a conditional and its
reverse.
By untrained, I don't mean bumpkins, only untrained in the language of mathematics and
probability.
Let me give you an example.
There's a medical condition called phenylketonuria, or PKU, that results from an error of phenylalanine
metabolism in infants.
It results in mental retardation, if not detected, but there's a screening that's 100% successful
in spotting kids with a defect, and there's a treatment for the condition.
Screening is mandatory in all 50 states, so if your kid has PKU, you're going to know
it.
Ah, but did you notice?
I didn't tell you everything.
Yes, there's a test that spots 100% of kids with PKU.
But what does it do with kids who don't have PKU?
After all, if we simply say, all babies have PKU, we have a test that spots 100% of the
kids with the condition.
We'll just be wrong about everybody else.
That test has no specificity at all.
So here's the missing information.
There are two common tests for PKU, and the better one is 98% likely to identify a PKU-free
child as being PKU-free.
98% sounds pretty good.
So how afraid should you be when your baby tests positive, with a test that's somewhere
between 98% and 100% accurate?
Well, the question you want is not how likely a sick kid is to test positive.
That's 100%.
The question we want is how likely is it a kid who tests positive is to be sick.
So let's use Bayes.
Somewhere around one child and 15,000 is born with PKU.
We can run the equations from Bayes' theorem as we did in the Air France example, but let
me do it more intuitively this time.
Imagine 15,000 children.
On average, one of that 15,000 is going to be unlucky enough to have PKU, and our test
is guaranteed to catch it.
But there are 14,999 kids who don't have PKU, and with a 98% reliable test, that means
that on average it'll get about 2% of them wrong until it's said that they have PKU.
That's about 300 kids.
So when the test that's over 98% reliable says that your child has PKU, the odds are
300 to 1 against your child having the condition.
And the rarer the disease, the more likely the positive test result is a false positive.
When I said that most people untrained in probability have trouble with reverse conditionals,
I meant it.
60 medical students and staff at the Harvard Medical School were asked a question like
our PKU scenario, except the test had a false positive rate of 5% rather than 2%.
And the condition occurred in one patient out of 1,000.
So what's the chance of the disease in that case?
5% false positives in 1,000 patients means 50 wrong for everyone that's correct, one
in 50 is 2%.
The chance of testing positive means that you actually have the disease.
But only 18% of the Harvard staff and students got the correct answer.
The most common answer was 95%.
The average of the answers was 56%.
The right answer, 2%.
So even doctors need some help understanding reverse conditionals.
Here's another one.
You've probably heard that more people get killed by beastings each year than by shark attacks.
And an appropriate reaction really is, so what?
Because we don't want the probability of shark given death, we want the probability
of death given shark.
Let me put it this way.
If you are a hip dip in the ocean and a bee is approaching you from the shore, as a shark
closes into you from the sea, run toward the bee.
Most accidents occur within 15 miles of home.
Of course they do.
Most driving occurs within 15 miles of home.
The value that we need is probability of accident given near home, not probability
of near home given accident.
It's important because numbers and probabilities have a cache.
They sound irrefutable.
But even when the numbers are correct, you have to make sure that you're looking at
the right numbers.
I saw a congressional testimony examining if marijuana is a gateway drug to cocaine
and heroin.
One argument presented was that the overwhelming majority of cocaine users started on marijuana
first.
The figures you see vary, but many of them put the fraction of cocaine users who previously
used marijuana at about 95%.
For many people, this is a strong argument for keeping marijuana use illegal.
But none of this makes the argument it purports to make.
It's not just a logical problem of post hoc, ergo, prompter hoc, nor even that an addictive
personality would probably be exposed to marijuana before cocaine.
It's that if this argument were sound, then an even stronger one could be made against
milk, which is more than 95% likely to be used by cocaine addicts, and usually they
started from a very early age.
What went wrong?
Again, the problem is the reversed conditional.
The question isn't what fraction of coke users started with marijuana.
The question is, what fraction of marijuana users go on to use cocaine?
For the statistics I've seen, that's about 25%.
No small number, but a far cry from 95%.
To tell you the truth, what amazes me about the 95% statistic is how small it is.
If correct, it means that 5% of coke users just vault over marijuana.
Well, the joint?
No thanks, I'm saving myself for cocaine.
A similar problem comes up with statistics about the fraction of highway fatalities that
involve drunk drivers.
The president of Mothers Against Drunk Driving quoted this statistic in her congressional
testimony.
According to the Department of Transportation, about 31% of traffic fatalities involve drunk
drivers.
Chilling.
But again, knowing nothing else, this statistic tells us very little.
After all, it means that over two-thirds of all fatal highway accidents involve only sober
people.
If anything, that seems to imply we should get liquor it up before we get behind the
wheel.
This reasoning is, of course, nonsense.
Again, we're looking at the reverse conditional.
We don't need to know the probability that a fatal traffic accident involves a drunk.
We need to know the probability that a drunk is involved in a fatal accident, as compared
to a sober driver.
Doing the Bayesian work leads to the conclusion that those above the legal limit for blood
alcohol are at least 13 times more likely to be involved in a fatal accident than a sober
driver.
And that is the statistic that's relevant to the drunk driver discussion.
Many kinds of bigotry and prejudice are fueled in effect by confusing the conditional and
its reverse.
For example, when people think of terrorist attacks in the U.S., 9-11 instantly springs
to mind.
And overwhelmingly, the people involved in that attack were young, male, Arab, and Muslim.
The hijackers themselves all fit this description, and were probably all in their 20s and 30s.
Which means, of course, that if you know that you're looking at a 9-11 hijacker, you've
got a pretty darn good idea what he looks like.
What the problem, of course, is that most of the time, people aren't looking at known
9-11 hijackers.
They may be looking at someone who is young, male, Arab, and Muslim, though.
And when you think about situations like these, you can realize how dangerous it is to confuse
A given B and B given A. Because the vast majority of young, male, Arab, Muslims are
not terrorists, and thinking that they are is cause for a terror of a whole different
kind.
Once you understand conditional probabilities, Bayesian probability is available to improve
all kinds of decisions.
For example, in our last lecture, we were building a decision tree for whether to mine
for minerals into adjacent properties.
What if we could test the property before making a purchase decision, and our test was
75% likely to find minerals if they were there, and 5% likely to find them if they were present
in less than economic quantities?
Well, we said that there was a 30% base chance of worthwhile deposits of minerals being present.
We can use Bayes theorem to figure out how this changes our test for our deposits or
not.
It works out that there's about a 26% chance of a positive test, and 86% of the time,
a positive test means that the minerals really are there.
A negative test means that there's a 90% chance of no good deposits.
Add this research option to our decision tree, and it works out that doing the test before
deciding what you'll buy will on average increase your profits by over $850,000, less
the cost of the test.
In the language of decision theory, the EVSI of the research is $850,000.
EVSI is expected value of sample information.
In more common language, the test is worth doing if you can do it for less than $850,000.
So ladies and gentlemen, we can say thanks to mathematician and Presbyterian minister
Thomas Bayes for giving us this lovely analytical trick.
If you've got a conditional probability and you need it to reverse, then Bayesian probability
really is the answer to a prayer.
