In my last lecture, we talked about sequential games. I do something, you respond, and so
on. In these next two lectures, I'm going to be focusing on simultaneous games. In the
simultaneous game, all the players make their decisions at essentially the same time. At
least, you don't know what anyone else has done at the time that you make your decision.
These games can get big and complicated, but that'll wait till next time. Today, I'm going
to start out small. Very small. In fact, in this lecture, I'm going to talk about games
that are literally as small as you can get. Games so tiny that they might seem irrelevant
in the real world. Useless. Don't you believe it? Forget about game theory for the moment.
Think about chemistry. Before 1700, chemistry was in pretty much of a mess. It's not a coincidence
that the words chemistry and alchemy sound so much alike. Both have the same root, probably
the Egyptian chem, meaning earth. In the first part of the 1700s, there wasn't much to distinguish
the two studies. Part of what changed that was a more quantitative approach to chemistry,
precise measurements. The other part was a new idea, the notion of the atom. Atoms are
tiny. So tiny that none of us will ever see one, yet every school child knows that everything
that we see is composed of atoms, swirling and interacting with one another. Atoms come
in different flavors, the elements. Though each atom of the same element is essentially
indistinguishable from the rest, chemists soon learned that it was possible to explain
a lot of the world that we see in terms of these microscopic, simple pieces.
You can see the analogy that I'm trying to draw. Today, I want to share with you some
games that are, in a sense, atomic. You can't break them down into smaller games. Because
of their tininess, though, they appear again and again at the heart of many other games.
And knowing them gives you a place to start in evaluating such games. One of them seems
absurdly simple, simpler than it really is. One of them is absolutely maddening. Tiny
as it is, it would be my nominee for the most important game theory game of all. Each of
these games appears, just like atoms do, in many different contexts. And, just like atoms,
each has a name by which it's commonly known. Did you know that oxygen means sourness producer?
It's true, but it's a long way from saying everything that's important about oxygen.
That's how it is with these games, too. Their traditional names are only an artifact of history,
but the significance of the games themselves goes much, much farther.
The four atomic games that I want to talk to you about today are the Coordination Game,
the Battle of the Sexes, Chicken, and the Prisoner's Dilemma. This isn't the entire periodic table
of games. There are other important small games, too, but these are among the most important.
OK, I said I wanted atomic games, games as small as you can get. How do I do this? Well,
start with the fewest number of players possible. Two. Then give each of these players the fewest
possible number of moves. Again, two. The result is what we call a two by two game. Two choices
for player one, two choices for player two. Since each player has only two choices, these
are finite games. And you'll remember from the last lecture that in such a game, the
exact size of the payoffs doesn't matter. All that matters is what outcome the player
likes best, then second best, and so on. What we call these was ordinal payoffs, you'll
recall. And the fact that we can use ordinal payoffs here makes these games even simpler
to analyze. Let's make this more concrete by looking at the first of our atomic games,
the Coordination Game. I'll frame it in the context of a dinner date. Your date is a charming
companion named Tammy. Or Tommy. Let's go with Taylor, shall we? Okay. So you and Taylor
have agreed to meet for supper at your favorite restaurant, a fancy place called l'amour. You
each have to decide what to wear. The restaurant's upscale, so you feel that dressing formally
is better than dressing casually. On the other hand, you also feel that the worst situation
would be for you and Taylor to be mismatched, one of you formal, one casual. What should
you do? Assuming that you haven't made arrangements in advance? Well, given only the information
we've given you so far, you might as well dress up. I've told you nothing about what
your date thinks, so you can't factor Taylor's feelings into your decisions. Without knowing
the payoffs to the other player, there's very little that game theory can generally say.
So let me add to this story. You and Taylor have been dating for a while. You know that
Taylor has the same feelings about these matters as you do. Formals best for this restaurant,
but matching each other is the most important thing. By the way, do you prefer business
or engineering to romance? No problem. Replace you and Taylor with YouCom and Taylor Electronics.
You're each designing a computer application for the same customer. There are two different
communication standards, Standard X and Standard Y. Both companies prefer using Standard X,
but the most important thing is that they both use the same standard so that they can communicate.
Like I said, atomic games appear all over the place. My main concern is to pick a clear
example, since if you understand one application, you'll understand them all. So let me get
back to your date. How can we represent the situation? Well, we're not going to use a
game tree. They're great for sequential games, but not for simultaneous games. No one's going
first. So instead, we're going to use a game matrix or a payoff matrix. We basically make
a rectangular table, a matrix, and we label the rows of the table with the choices of player 1.
I'm going to let you be player 1 because, well, because you're you, and Taylor isn't. But you
could have let Taylor be player 1 instead. The moves are simultaneous, so it really doesn't matter.
Okay, now we label the columns of this table with the choices of player 2. Like this. When each
player chooses a strategy, we cross index the row chosen by player 1 with the column chosen by
player 2. In that cell, we record the payoff to each player. Let's put them in now. Your least
favorite outcome is when one of you dresses casually and the other dresses formally. So let's give
these cells a zero payoff. For that matter, these combinations also give Taylor a zero payoff. We'll
put those in. I've color coded the payoffs so that the colors match the colors of the players. If you
don't have colors available, just remember that the first payoff always goes with the row player and
the second payoff with the column player. Okay, the casual casual choice is your next favorite and
Taylor's to as it turns out. I'll give these a payoff of one. It doesn't matter what number I use,
as long as it's bigger than zero. These are ordinal payoffs. Remember, all that matters is that
options that are better get bigger numbers. Okay, finally, fill in your favorite and Taylor's to.
Again, the choice of numbers, the number two is arbitrary. Any number larger than one is fine. In
fact, I could give you a payoff of two and Taylor a payoff of three, and it wouldn't change a thing.
It wouldn't even mean that Taylor likes dressing formally more than you do. Remember that in general,
we can't compare the payoffs of one player to the payoffs of another.
Well, you can see why this is called the coordination gain. You and Taylor have exactly the same
preferences. So you have exactly the same favorite outcome. Seems like pretty much of a no brainer,
doesn't it? Both of you dress formally and you both get your best payoff. Happy ending.
Hmm. Not so fast. I'm going to nitpick a little bit. I told you that you know the matrix,
but does your date? We're going to need to assume that this matrix is common knowledge.
Otherwise, Taylor might not know how you feel about formalware or might not know that you know
how you both feel. Without assuming common knowledge of a game, analysis becomes really
difficult. Fortunately, in practice, common knowledge seems pretty easy to establish.
If both you and Taylor looked at the game matrix and then made eye contact with each other,
I'd feel pretty confident in saying that there was common knowledge of the game between the two of you.
But this idea of levels of knowing isn't an empty one. I'm sure you've met someone who believes
that one race is superior to another one, but doesn't believe that he or she believes it.
But let's get back to your date. Let's say that you and Taylor have common knowledge of the game
and that, uh, well, you're basically both going to dress formally, aren't you?
Well, not necessarily. I'm going to nitpick a little more. You might be irrational.
That is, you could deliberately pick the option that you're less happy with or you could pick
without any consideration at all in terms of, in terms of what would make you happy.
This kind of behavior is what we're talking about when we say that someone's irrational.
In saying that you're irrational, I don't mean that I disagree with your preferences.
A rational player can have any preferences that they want and rank them in any way that they want.
That's fine. When I say you're irrational, what I mean is you don't respect your own preferences.
There's no necessary link between what you want and what you do.
And if that's the case, any interaction with you is going to be a crap shoot.
You can see why in general we assume that the players are rational and that this
rationality is common knowledge. Rational players will make choices that will lead to
their best expected payoff given their knowledge and beliefs about the game at the time.
Actually, assuming perfect rationality is a pretty high standard, maybe too high.
Later in the course, we're going to consider this assumption more carefully
and see how reasonable it really is. But for now, let's assume that both players in our game are
rational. So, both you and your date prefer formal to casual, you're both rational,
and all these facts are common knowledge. Given this, we'd certainly expect that you'd
both dress formally, right? Well, okay, right, we would. I'll stop nitpicking.
Except to say that if the two of you got it in your head somehow that the other person was going
to dress casually, then that's what you'd want to pick. The shared idea of both casual,
once it comes up, is self-reinforcing. It's an ash equilibrium, just like both formal is.
Yeah, but the both formal solution seems to be a perfectly sensible and achievable outcome.
I want to point out, though, that achieving this obvious happy ending took a lot more
assumptions than you might at first have realized. Still, let's make this game a little more interesting.
This time you're going to a mid-priced restaurant. Taylor still thinks that formal
wear is best for such a place, but you prefer casual clothes. Again, if you don't match,
both of you are very uncomfortable, and that's the worst situation.
Now the payoff matrix looks like this.
This game is traditionally called The Battle of the Sexes, since it's often presented with a story
similar to ours. The most important thing is being together, but one person has one preference,
and the other person has another. If you like the computer networking example better than the
romance one, you can now figure that your company prefers standard X, and Taylor's company prefers
standard Y. But I'll do the dating version. We'll assume, as usual, that the payoff matrix of
structure is common knowledge, and so is the rationality of the players. So you like casual,
and Taylor likes formal. The cooperation game is pretty easy. This one is actually a whole lot
more complicated. What are you going to do? And please, don't try to base your answer on an argument
such as, I care about Taylor so much that I am willing to sacrifice my own happiness.
It's not that I object to the noble sentiment. It's just that if you really do feel that way,
then you lied when you said that both casual was your favorite outcome.
Taking into account all of the factors that might matter to you, you're saying that you'd
rather have Taylor's favorite solution to yours, which means that Taylor's favorite is really
your favorite too, and we're back to the coordination game. So getting rid of that once again, what do
you do? Well, life would be easy, or easier, if you could get Taylor on the phone. You might be
able to turn this into a cooperative game, where binding agreements are possible.
On second thought, it might be even better if you can get Taylor's answering machine.
If you knew that your date was going to check the phone messages before coming,
you could just leave a message saying, I'm going casual tonight, bye-bye.
If you were believed, and why wouldn't you be, then Taylor would show up in casual clothes.
After all, if you are going casual, Taylor gets a payoff of one by doing so two,
and a payoff of zero by wearing formal. By using the answering machine, you changed a
simultaneous game into a sequential game, and then took the first move. And this game does
have a first mover advantage. What you've just done is a strategic move called a commitment.
Maybe not the kind of commitment that Taylor was looking for. We'll have a lot more to say about
commitments and the other strategic moves, promises, and threats in a later lecture.
But that is for later. Right now, we're looking at non-cooperative games with simultaneous moves.
And ironically, no matter how you try, there doesn't seem to be any good way to have you
two match clothes. Any line of reasoning that will lead to you to choose one style of clothes
will lead Taylor, the exact same one of reasoning, to choose the opposite.
It appears that the only hope that you have of getting a somewhat happy ending here,
besides luck, is what's called a focal point, or a shelling point. It's an idea that was
investigated by Tom Shelling, who we mentioned in the first lecture as the author of The Strategy of
Conflict. Sometimes there's one solution that for some reason seems obvious to all the players in
the game. If no arrangements have been made, they'll tend to select it. For example, imagine at
the last four times that you and Taylor ate at this particular restaurant, both of you dressed
formally. Then both dressing formally this time might be a shelling point. Humans are social
creatures, and you'd be surprised how good we are at finding shelling points. In 2006, ABC's
Primetime conducted a really interesting experiment. They took 12 volunteers, paired them up into six
groups of two, gave each $100, and dropped them off somewhere in New York City, scattered about.
Their task? Meet up with another one of the teams before the day was out. Problem?
They had no more information about those teams than you have right now. They were all strangers.
New York has over 8 million people. And remember, even if they thought of a way to be recognized,
they had to go to the same place at the same time. Go ahead and play. Take a second to think about
where you'd go in New York City and when. Let's see if you'd meet anyone, because here's what actually
happened. All of the teams started thinking about landmarks or transportation hubs. Grand Central
Station, Penn Station, Times Square. Two of the teams remembered the movie Sleepless in Seattle
when Tom Hanks met Meg Ryan at the Empire State Building, so they headed there. After about three
hours, everyone had reached their destination. Three teams wound up at the Empire State Building.
Two of those teams, coincidentally, bought materials to make a sign in the same store.
The three other teams wound up at Times Square. If you chose to hang out at the New York Public
Library during the morning or Grand Central Station, you would have met someone too. But the
places to be were the Empire State Building and Times Square. And the time? Well, the time was
noon. Virtually every group decided on this meeting time. Most of you probably did too.
Noon is a good time for a meeting because, well, because it seems to be a good time.
It's a shelling point. And this remarkable story in which all six teams converge to two places
at the same time in a city of 8 million people gives you an idea of how good humans can be
at finding shelling points. In the Battle of the Sexes, it might have been a little tougher.
So back to your love life. Let's suppose that you made the wrong choice with Taylor too many times.
You hadn't studied game theory yet. And your relationship has ended badly. Very badly.
It's now a month later, Valentine's Day, and you're going on a date with your new partner,
Cameron. You want to go to your old favorite restaurant, LeMore. The trouble is, you know
that your ex will want to go there too. If both of you go to the same intimate little restaurant,
it's going to be the night from hell. The game matrix between you and your ex now looks like this.
This game is called Chicken after a game that was played by way too many juvenile delinquents
in 1950s movies. Starting with James Dean in Rebel Without a Cause,
the most common version of the game is the easiest to understand.
Two drivers approach each other at high speed on a narrow road. The one who swerves away first
is the chicken and the other one wins. The best outcome is that I go straight and you swerve.
Second best is that we both swerve. Third best is that you go straight and I'm the chicken.
The worst option for both of us is that we're both very brave and very dead by plowing into
each other at 60 miles an hour. Our restaurant problem has consequences that are less dire than
this, I hope, but it has exactly the same payoff structure and that's what counts in analyzing
the game. Each player can either head straight ahead to LeMore or swerve to another restaurant.
First choice is to go to LeMore and not find your ex there. Second choice is for both of
you to go somewhere else. It's better at least to not feel like you were kicked out of your
restaurant by your ex. Third choice, they go to LeMore, you go somewhere else, some second class
eatery. Fourth choice, you both go to LeMore and spend the night glaring at each other.
What do you think happens in this game? If you're like a lot of people, you may think that the
best solution is for you and your ex to go to different restaurants. Certainly that seems to be
fair, but if it's fairness that's important to you, it should have been reflected in your payoffs.
Your payoffs say that your favorite outcome is for you to go to LeMore and your ex to go somewhere
else. So if you honestly believed or knew that Taylor was going somewhere else, you'd want to go
to LeMore. Unfortunately, Taylor could be reasoning in exactly the same way. It's in this game of
chicken, if you knew for sure that your ex was going one place, you'd go to the other. You might
not like it, but if you had to swerve away from LeMore to avoid the collision, you'd do it.
But again, in this simultaneous game, you don't know the other player's choice.
What I want you to notice here is how the fair solution of both staying away from LeMore isn't
a self-reinforcing solution. It isn't a Nash equilibrium. As soon as either of you knew that
the other person was not going to LeMore, you'd want to go there yourself. So to get a solution
that's at all satisfactory, we're going to need to find a shelling point. You might even be able
to create one. Does LeMore require reservations? Call up, see if Taylor's made any. Or maybe better
yet, go to LeMore an hour earlier and call Taylor from the restaurant. Remember that one reason
that we're studying games is to see if we should be playing a different one than the one that we're
in. All right, like all of our atomic games, chicken is a game that you can find everywhere.
Think of a threatened strike. At the last moment, management either makes that concession or not,
or labor does or not. If neither one does, there's a strike. And a strike is often the worst outcome
for both sides. It happens when nobody swerves. Even very, very small games can create a surprising
tangle when you analyze them. But now, I'm going to really kick it up a notch. Let's revisit the
last situation and change the payoffs just a bit by switching two of them. Suppose that the idea of
your ex going to your restaurant while you and your date are exiled to some inferior place
is the worst thing that could happen in the evening. You would rather spend the evening glaring at
each other than letting that happen. Well, if you put that situation in the matrix and look at it,
it now looks like this. Oh boy, the prisoner's dilemma. My nominee for the most important game
of game theory. Pay close attention to this one, folks. It comes up in life all the time,
and it may be the weirdest game that you ever see. Let's think it through from your point of view.
You and your ex are choosing simultaneously. It doesn't matter whether it's literally
simultaneous or not. You don't know what the other person's choice is. And because of that,
obviously, that means that you can't control what they're going to do. It's not going to
depend on what you decide. Taylor will go to the more or not, and nothing that you do will change
that. So suppose Taylor goes to the more. Then if you go, you get a payoff of one. If you don't,
you get a payoff of zero. One isn't much, but it's better than zero. So if they're going to the more,
you should do. Okay, now suppose that Taylor's not going to the more. Then by going to the more,
you get a payoff of three. If you go somewhere else, you get a payoff of two. And three is better
than two. So if they're not going to the more, you should go to the more. Get that? No matter what
they do, you go to the more. The trouble is Taylor will reason exactly the same way. And so as a
result, we get a situation arrived at by impeccable logic, which has both of you going to the more
and getting a payoff of one for the night. Well, if you both went somewhere else, you would have
got each gotten a payoff of two. That's the prisoner's dilemma, the most famous game theory game of
all. It was discovered by Melvin Drescher and Merrill Flood at the Rand Corporation in 1950,
a place where you could see John von Neumann and John Matt Nash walking down the halls.
It's called the prisoner's dilemma because of the story that usually goes along with it.
It was created by Albert Tucker, a Princeton. By the way, Albert Tucker had two PhD students. One
was John Nash. The other was a man named Tori Parsons. Tori Parsons was in turn my PhD advisor.
So in a real sense, Nash is my academic uncle. Not to brag. Well, anyway, the usual story for the
dilemma is this. Two criminals committed a crime together and they're being interrogated in separate
cells. If neither one confesses, they'll each get a year in prison. If one confesses, that one goes
free. But the other gets five years because of the information provided by the stool pigeon.
If they both confess because of the mutual implication, they both get three years.
The exact same logic used in the restaurant example applies here. Each prisoner is better
off confessing, regardless of the choice made by the other. At the conclusion, they both confess
and they both get three years. While by keeping their mouths shut, they could have each gotten out
in one. What makes the prisoner's dilemma so maddening is not that somebody ends up being
unhappy with the outcome. In a lot of games, at least one player is unhappy with the outcome.
The problem isn't that you could find a solution that makes somebody happier.
The problem is that you can find a solution that makes everybody happier. Both you and Taylor
would agree that you both getting a payoff of two is better than you both getting a payoff of one.
And yet, there doesn't seem to be any way to get there. An economist would say that both of you,
you and Taylor, going to Le Moore is inefficient. A game theorist would say it isn't Pareto optimal.
They mean the same thing. A solution is efficient or Pareto optimal if the only way that you can
give a better payoff to one player is to give a worse payoff to somebody else. To pay Paul Moore,
you have to rob Peter, at least a little bit. But that's not the case here. If both you and Taylor
go to Le Moore, you'll regret that you both didn't have the sense to go somewhere else.
But, and here's the heart of it. As soon as you thought that the other person really was going
to go somewhere else, you'd want to go to Le Moore. In a prisoner's dilemma, the activity that gives
you both the payoff of two is called cooperating. The one that gives you both the payoff of one
is called betraying or defecting. So for our restaurant example, cooperating means going
somewhere else and defecting means going to Le Moore. And what I'm saying is as soon as you
know that the other person's going to cooperate, you're going to want to defect.
We'll see the prisoner's dilemma over and over in this course and wrestle with ways
to make that cooperative outcome where both people do better, a viable alternative.
It is absurdly difficult to accomplish. You might hate the mutual defection solution
and recognize its stupidity, but as soon as you know the other guy is going to cooperate,
you suddenly find yourself with no reason for doing so yourself. We can end a war by
you giving up weapons and us giving up land. Fantastic. Both of it. It's worth for both of us.
But if you know that the other side is going to do what they say, why would you want to do your
part? And if you knew that they weren't going to do as they say, then you certainly wouldn't
want to follow through. So you don't want to follow through no matter what the other side does
and the work continues. Prisoner's dilemma. Is there any way out of this? Yes,
several ways. And we'll spend one or two of our future lectures looking at the matter in detail.
In a weird way, escaping the dilemma requires a sense of history.
The coordination game, the battle of the sexes, chicken, the prisoner's dilemma.
For such very tiny games, they display a lot of subtlety and complexity.
And they're everywhere. Two American drivers approach each other on a narrow road.
To which side do they move? That's a coordination game with a good shelling point. Go right.
If one of the drivers is English, it's a battle of the sexes. I'd prefer driving on the left if
it's all the same to you, but let's just agree on something, shall we? A market big enough to
support only one new entrant creates a game of chicken. One company wants to enter the market
if and only if the other company doesn't enter. If both enter, a financial crash.
And how about the prisoner's dilemma? Well, think about scheduling contracting work for payment.
Both the contractor and the customer would prefer prompt work and prompt payment to late work
and late payment. But no matter when the service is performed, it's nicer paying late.
And no matter when the payment comes in, it's nicer working late. And so everything ends up late.
A prisoner's dilemma. In future lectures, we're going to look at much more complicated games than
these. But recognizing these atomic games when they appear, as they do often, can help us better
understand the situations that we face, both personally and professionally, every day.
