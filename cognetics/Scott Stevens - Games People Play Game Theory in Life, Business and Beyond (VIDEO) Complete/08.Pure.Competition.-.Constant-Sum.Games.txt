Well, we finally made it. Welcome to 1928, the year in which John von Neumann published
the Minimax theorem, the year that really got game theory rolling. John von Neumann
was quoted as saying, as far as I can see, there could be no theory of games without
that theorem. I thought there was nothing worth publishing until the Minimax theorem
was proved. His points well taken. von Neumann's Minimax theorem talks about two player zero
sum games. It essentially says that there are optimal strategies for any such game.
There are sensible ways for both people to play the game. And there's a sensible way
to find out what those ways are. To prepare you for this, I want to go back to our fifth
lecture and the Battle of the Bismarck C. The matrix for that game was this. We looked
at this game in terms of Minimax strategies. We said at the time that these were essentially
pessimistic strategies, Murphy's law strategies. What would you do if you knew that your opponent
was going to make his best response against you? The worst that could happen to the Japanese
if they went north was two days of bombing. The worst that could happen if they went south
was three days. By sailing north, they gave themselves a security value of two. That is,
two days of bombing was the worst they would have to endure regardless of what the allies
did. In a similar way, the allies were guaranteed at least two days of bombing by searching
north. That was their security value. So the two sides had the same security value.
Two. For the allies, no matter what the Japanese did, two days of bombing. For the Japanese,
no matter what the allies did, at most two days of bombing. Because these two security
values are the same, no side can do better than playing their Minimax strategy. Why?
Well, consider a solution with less than two days of bombing. Then the allies are going
to want to switch to their Minimax strategy, which guarantees them at least two days. Consider
a solution with more than two days of bombing. Then the Japanese are going to want to switch
to their Minimax strategy with at most two days. If the other side is playing its Minimax,
deviating from your Minimax can't help you. And it could hurt you. All well and good.
But how about if the Matrix looked like this? This says that the allies, if they go north,
can't return to the southern waters. Minimax for the Japanese is still to sail north, and
the security value is still two days. Minimax for the allies is now to search south, with
a security level of one day. That is, if they go south, they're sure to get at least one
day of bombing. But if they go north, they might not get any. But we can't follow the
old logic through to the end, deciding that these are optimal. If both sides play these
strategies, Japan sails north, the allies search south, and the allies only get one
day of bombing. But by switching their choice unilaterally, the allies can do better. They'll
get two days of bombing. But then the Japanese, of course, would want to change their strategy,
and so on. The security values for the two sides weren't equal. And because of this,
it triggered the infinite second guessing game that we've seen so often in these lectures.
That's going to happen anytime the two sides have different security values. And this is
where the Minimax theorem comes in. It says, let the players choose mixed strategies. If
you do, you can always find strategies that give them the same security value. And once
you have this, you have a Nash equilibrium. Think about penalty kicks and soccer. The
kicker is trying to get the ball past the goalie. The kicker will virtually always kick
the ball toward one of the corners of the goal, since it's harder for the goalie to
reach it there. The goalie stands in the middle of the goal until the ball is struck, but
that ball travels fast. The goalie really has to decide in which direction to move before
the ball gets going. And the obvious question is, of course, how do players decide what
to do in this simultaneous game? Well, let's listen in on the goalie's thoughts.
All right, I know he's best kicking to me right, so he's probably going to kick there.
So I'll move right. But he knows that I know he's best at kicking right, so he'll probably
kick left. So I'll move left. Again, the same impasse we've seen over and over in this course,
round and round and round. Any decision that you make is suspect. If you'd followed your
line of reasoning one more step, you'd reverse your decision. But the minimax theorem provides
a way out. We're going to see what von Neumann's ghost would tell the soccer players. And we'll
see how it compares with their actual professional play. A man named Ignacio Pelesiosuerta of
Brown University decided to do just this kind of analysis. He collected data on penalty
kicks in professional soccer games in Europe from 1995 to 2000. It's a large data set,
over 1,400 attempts. Pelesiosuerta's article didn't include the raw data, but I've reconstructed
it based on his report. Any slight errors I've made won't substantively affect the analysis.
Here's the data in a couple of tables. The table on the left shows successful shots on
goal broken down by where the kicker kicked the ball and which way the goalie originally
moved. For example, the 132 in the upper left hand corner means that there were 132 successful
attempts where the kicker kicked to the left of the goalie and the goalie moved left. The
second table records the number of attempts on goal. The upper left hand cell here is
227. 227 attempts in which the kicker kicked to the left and the goalie moved to the left.
We can see then that if both players chose left, the chance of scoring a goal was 132
out of 227, or about 58%. In terms of expected value, the left-left combination gives an
average of .58 goals scored per attempt. 58% of the time you get one goal, 42% of the time
you get zero, the expected value is .58. I've done this same calculation for the other
combinations in this table. You can see in the upper right and lower left cells that when
the goalie guesses the wrong direction, he has almost no chance of blocking the shot. If the
shot is to the left, it scores 95% of the time. If it shots to the right, 93%. If the goalie
guesses correctly, he does better. A kick to his left scores 58% of the time, as we've seen. A
shot to his right scores 70%. By the way, I'm not being sexist with my pronouns here. All of the
players in the study were male. And since whatever is good for the kicker is bad for the goalie,
I've given the goalie the same payoffs as the kicker, but negative. One other little detail.
Most kickers kick right-footed. In this data set, when a kicker was left-footed,
the definitions of left and right were reversed. That is, kick right really means kick to your
strong side and so on. Okay, you're the goalie. What should you do? Well, it's clear you're going
to have to play a mixed strategy. If you move in the same direction every time, the kicker will
know that and shoot to the opposite side. They'll be fairly, fairly sure to score. So you're going
to move left some fraction of the time and move right the rest of the time. But what fraction?
Rather than just shotgunning guesses like we did last lecture, let's approach it algebraically.
Let's say that you decide that the goalie will move left with probability Q. Q can be any number
that you want between 0 and 1. Then you're going to be moving right with probability 1-Q. They
have to add up to 1 or 100%. If you move left with a probability of 0.7, 70%, you're going to move
right with probability 0.3, 30%. Okay? I've shown these probabilities on our payoff matrix. Now
we're going to do exactly what we did for the Steven and Maude problem in the last lecture. We'll
find the expected payoff of the kicker for each of his pure strategies. Remember how we did that?
Take each possible payoff, multiply it by the probability that occurs, and then add up the
results. Let's look at the top row where the kicker kicks left. The two possible payoffs for
the kicker in this row are 0.58, which happens with probability Q, and 0.95, which happens
with probability 1-Q. Multiply payoffs times probabilities and add them up. Don't let the
algebra fake you out. It just says you pick a probability Q from moving left, and I'll tell
you how often a kick to the left will score against you. If you never go left, then Q is 0,
and then you get stored on 95% of the time, 0.95 minus 0.37 times 0. If you always go left,
then Q is equal to 1, and you get scored on 58% of the time, 0.95 minus 0.37 times 1. In general,
the more you go left, the less you're scored upon. This makes sense. The kicker is kicking to your
left. Now let's do the same thing for the second row where the kicker kicks to the right. Same old
game, probability times payoff added up over all the cases. You'll notice that this time as Q
runs from 0 up to 1, the chance of a goal runs from 0.7 up to 0.93. This means that the bigger
the Q is, the more likely that you move left, the more likely it is that the kicker scores. This
just makes sense. He's kicking to your right. That means you're out of position more. If you have
a bigger Q, and therefore more likely that you'll be scored upon. Okay, we know the expected payoff
of the kicker kicks left, and if the kicker kicks right, which is he going to do? Well,
that depends, of course, on the value of Q. If Q is very small, like zero, then kicking to the
left is better. It gives the kicker a payoff of 0.95 goals instead of 0.7. If Q is very big,
like one, then kicking right is better. It gives the kicker a payoff of 0.93 goals as opposed to
0.58. Somewhere in between these two extremes is the value of Q where both kinds of kicks are
equally good. Let's find that Q. You can do this by solving those two equations simultaneously,
but I'll leave that for those of you who love algebra. There's another way to represent what
we've been saying pictorially. Here, the blue line shows how scoring depends on the value of Q
when the kicker is going to the left. You can see that it starts at 95% when Q is equal to zero,
which means that the goalie always goes right, and drops to 58% on the right side of the graph
when Q equals one, meaning that the goalie is always going to the left. The pink line shows
how scoring depends on Q when the kicker is kicking to the right. It starts at 70% when Q
equals zero, meaning that the goalie always goes right, and rises to 93% when Q is equal to one,
meaning that the goalie is always going left. You can see that the two lines do cross at a
point of Q, which is just about 0.4. If you do the algebra, it's actually more like Q equals 0.42.
So what should the kicker do? Well, as I said, it depends on the value of Q. Given Q,
the kicker will pick whichever option is better, whichever line is higher on our graph.
So, with a small Q, the kicker is going to kick left every time. With a large Q,
the kicker is going to kick right every time, again, whichever line is higher.
The kick right part is higher than the blue one on the right-hand side. The blue line is higher
than the pink one on the left. The two black lines I've drawn, making the V, show you what the
kicker will do if he makes his smartest choice for any value of Q. The goalie picks
Q, and then the kicker picks which line he likes better. But what if the goalie chooses Q equals
0.42? Then the kicker is at the bottom of his payoff valley. He scores about 80% of the time,
regardless of which way he kicks. And the important thing to note is, if the goalie chooses any other
value of Q, the kicker will score more often. And that's where the fact that we're dealing with a
zero-sum game becomes so important. We've just figured out the value of Q that the kicker would
like least, Q equals 0.42. But since the goalie and the kicker have diametrically opposed goals,
whatever the kicker likes least, the goalie likes most. So, by playing Q equals 0.42, the goalie
can limit the kicker to about 80% success, regardless of which direction the kicker kicks.
Both kicking directions to him are equally good when Q equals 0.42. For any other value of Q,
the kicker can capitalize on the choice of Q to do better than 0.8. So, we've seen an odd thing
in determining the goalie's optimal strategy. The goalie acted so as to make the kicker indifferent
between the two kicking directions. This result is actually quite general. We'll come back to it
in a bit. All right, we found the goalie's best strategy. Move left 42% of the time. We found it
by seeing how the kicker would respond to various options, various values of Q that the goalie
could pick. Now, I want to reverse the process and see what the kicker should do. We're going to do
exactly the same kind of work, but working in columns this time rather than rows. I'll assume
that the kicker kicks to the left with probability p, and therefore kicks to the right with probability
1 minus p. Notice how far we're getting with the single trick of computing expected values.
Okay, let's start with the first column where the goalie's moving left. What's the goalie's
expected payoff? It's the same old game, folks. Probability times payoff added up over all the
cases. If the kicker kicks left, the goalie lets an average of 0.58 goals score, which is a payoff
of negative 0.58 to him. This happens with probability p. If the kicker kicks right, the goalie lets
in an average of 0.93 goals, which is a payoff of negative 0.93 to him, and this happens with a
probability 1 minus p. Multiply probabilities times payoff, add up the results, and do a little
algebra. The plus 0.53 p that you see at the end of the calculation shows that as p gets bigger,
the kicker kicks left more often, and the goalie's payoff gets better. This isn't a surprise.
If the goalie is moving left, then the more often the kicker kicks left, the better the goalie likes
it. Now, look at the second column. We follow the same procedure to compute the expected
payoff. Multiply the red payoffs by the probabilities and add them up. The negative 0.25 p here shows
that as p increases, the goalie's payoff is getting worse. Again, this is no surprise. This is the
column where the goalie moves right. As p increases, the kicker is increasingly kicking to the left,
and so the goalie is more likely to miss. Remember, the value of p is how often the kicker
is kicking left. We graph these results exactly the same way that we did last time.
The payoffs to the goalie are negative because every goal counts against the goalie.
Remember, p on the horizontal axis is how often the kicker is kicking to the goalie's left.
The blue line shows how the goalie does if he moves left. The pink line shows how the goalie does
if he moves right. Again, these two lines cross, and this time they cross at p equals 0.39.
You can verify this with a little algebra. You can solve two equations simultaneously.
So, how would the goalie use this information? Look at the picture again.
By the way, if you wanted to make these graphs without doing any algebra, you could.
You'll note that the endpoints in each line just correspond to different payoffs in our payoff
matrix, 70%, 93%, and so on. I'll let you work out the details if you're interested. It's not hard.
Okay, the goalie is looking for the best payoff he can get. That means that given a value of p,
he's going to pick whichever option corresponds to the higher line. For small values of p,
on the left part of the graph, he's going to move right. The pink line moving right is higher
than the blue line moving left. For big values of p, on the right part of the graph,
then the blue line is above the pink line. This means that blue, moving left, is better than
pink, moving right, so he's going to move left. But at exactly p equals 0.39 where the lines cross
is indifferent between his options. Moving left or moving right do equally well. On average,
you'll be letting in about 0.8 goals. Okay, so we know how the goalie will respond to any
particular value of p. And again, this is where the fact that it's a zero sum game is important.
Because the kicker gets to decide how often he'll kick left or right. The kicker gets to decide the
value of p because it's a zero sum game. What the kicker likes best is what the goalie likes least.
You can see from the picture that the worst value of p, from the goalie's point of view,
is at the bottom of his payoff valley. If you like, it's a 0.39 of p. At that point,
the goals we scored about 80% of the time, and you can see his payoff's negative 0.8.
Since this is the worst that the goalie can do, it's the best that the kicker can do,
so the kicker will kick left 39% of the time and will kick right 61% of the time.
And I'm claiming I've just found the optimal way to play penalty kicks in professional soccer.
The kicker should kick left 39% of the time, and the goalie should move left 42% of the time.
Let me show you the result of our analysis in a slightly different way that might drive
this point home more clearly. Remember, p is the fraction of the time that the kicker kicks left,
and q is the fraction of the time that the goalie moves left. Let's imagine that the kicker told
the goalie his value of p, and that the goalie chose his best response, in response. I'll plot
the goalie's choices on a graph. You've seen that if p is less than 0.39, the goalie is always going
to move right. Saying this another way, if the kicker's value of p is less than 0.39,
the goalie is going to choose q equals 0, never move left. If the value of p is bigger than 0.39,
the goalie's best choice is always to move left. That is, for big values of p, the goalie is going
to choose q equals 1. If p is exactly 0.39, both options are equally good for the goalie.
We saw last lecture, this means the goalie can go left, can go right, or can play any mix of the
two. They all perform equally well. That is, if p is exactly 0.39, the goalie doesn't care
what q is. The vertical line at p equals 0.39 indicates that any value of q is as good as any
other for that value of p. Okay, now let's play the same game by seeing how the kicker responds.
Now we imagine the goalie telling the kicker his value of q, or how often the goalie moves left.
Well, for small values of q, when the goalie doesn't move left much,
then the kicker will want to always kick left, p equals 1. If there's not much chance that the
goalie will move left, the kicker always wants to kick left. For large values of q, that is,
on the high side of the graph, the kicker wants to choose p equals 0. If there's a high chance of
the goalie moving left, then the kicker never wants to kick left. He'll always kick right.
There is that one critical value of q equals 0.42, where kicking left and kicking right are equally
good. At that point, the kicker doesn't care what value of p he picks. That's the horizontal line
across the middle of the graph. These two lines cross at p equals 0.39, q equals 0.42.
Now, the goalie is only going to be happy with a strategy profile if it corresponds to a point
on the blue line. If it doesn't, he'll unilaterally change his play. The kicker is only going to
be happy with a strategy profile corresponding to a point on the pink line. If it doesn't,
he'll unilaterally change his play. So the only point in which no one benefits from unilaterally
changing play, in other words, the only Nash equilibrium of this game, is where the two lines
cross. The kicker kicks to the left 39% of the time, the goalie moves to the left 42% of the time,
and of course, these choices are made randomly without any pattern to them. That's the only
equilibrium. And equally important, this equilibrium gives both players the same security value of
letting in about 0.8 goals per shot. The fact that both sides have the same security value
means that these strategies are essentially bulletproof. 80% of the goals will score on average.
If someone does worse than this, it's because they deviated from their equilibrium strategy.
Well, this is very nice, but it may be a little hard to believe.
What do real soccer players do in real life? They certainly don't do these calculations
or generate random numbers to implement their mixed strategy.
Their choices are based on years of experience and mastery of the game.
How do the results compare to what von Neumann's ghost would say?
Well, let's go back to the data that I presented at the beginning of this lecture,
those six years of professional soccer penalty kicks. Here are the tables once again.
We'll only need the right hand one this time. Look at the last column.
Out of the 1,416 kicks that were recorded, 566 of them were kicks to the left.
That's 566 over 1416, or just under 40%. Our game theory analysis said that the
kicker should kick to the left 39% of the time. So actual players are playing within 1% of what
game theory says for the kicker. Maybe we just got lucky. How about for the goalie? Again,
look at the right table. This time bottom row of the 1,416 kicks recorded 599 of them
had the goalie moving left. That's 599 over 1416 or 42%. Our mixed strategy analysis said it was
best for the goalie to move to the left 42% of the time. In other words, real life soccer
professionals are playing the strategies that game theory identifies as being optimal within
1% of the time. This is a truly remarkable correspondence. When games are bigger than
two by two, the approach is very much like what we did here, except that it involves
more variables. Calculate the expected payoff for each pure strategy and require that all
the pure strategies that are going to be played give the same best expected payoff.
At an equilibrium, each player is going to be indifferent among all the different options
that he or she is playing. The math can be done using algebra or more quickly using the technique
called linear programming. A piece of software called Gambit can do it for you too. I've given
the URL for the Gambit website in the course booklet. But if a game is only two by two,
it turns out that there is a very useful, very easy way to find the optimal strategies.
And that's what I want to show you now. Remember the Stephen and Maude game from last lecture?
Each would shoot one, two, or three fingers, and the payoff was the total number of fingers shown.
If the total was even, Stephen won. If it was odd, Maude would win. And one person,
the loser, had to pay the winner, which made it a zero-sum game. If you analyze this game with
the techniques we developed today, you'll find out that each player should shoot a two, 50% of
the time, and shoot one or three, one quarter of the time each. If they do, the game is fair. On
average, no one can beat the other player, provided that each is playing their bulletproof strategy.
But to demonstrate our two by two technique, let me restrict the game to shooting only a one
or a two. Here's the matrix. Is this game still fair? Well, let's find the optimal strategies
and find out. First, make sure that neither player has a dominant strategy. If someone does, that
player plays the dominant strategy, and the other player chooses their best response to it.
Here, no one has a dominant strategy. Neither one or two is always the best for either player.
Okay, here we go. I'm going to subtract Stephen's two payoffs in the first column,
taking the smaller from the larger, to see how much they differ by. I'll write this result
above the second column. Then I'll find the difference in Stephen's payoffs in the second
column, and write the result above the first column. The two blue numbers in the second
column differ by seven. By the way, note that I'm using the blue payoffs, the ones for the
row player. Later, this is going to make a difference. Okay, now add up these two numbers,
seven plus five equals 12. Divide both of the numbers by this total. The resulting numbers,
amazingly, give the optimal strategy for mod. You should shoot one, seven twelfths of the time,
and two, five twelfths of the time. For Stephen, we do the same kind of work, but go row by row,
and this time we use mod's payoffs. The difference of the first row is recorded in the second row,
like this, and the difference in the second row is recorded in the first, like this. Again,
we add these two numbers, seven plus five is 12, and then we divide each by the total.
So, Stephen's best strategy is exactly the same as mod's. He should shoot one, seven twelfths of the
time, and two, five twelfths of the time. So, is the game fair? Well, we see that Stephen is playing
both of his rows, which means he must be indifferent between them. They must be equally good. Let's
see his expected payoff from playing row one. Here's the calculation, and as you can see,
it comes out to negative one-twelfth. So, the game isn't fair. Stephen loses, on average,
one-twelfth of a dollar per game, or about eight cents. His second row has to have the same
expected value. Here's the calculation, and you can see that it does, negative one-twelfth.
I'll let you verify on your own that each of mod's two columns give her a payoff of plus
one-twelfth of a dollar per game. Well, in this lecture, I've shown you how to do the math that's
necessary to find these mixed equilibria, and the last two lectures have been fairly computational.
In my next lecture, I want to back off a bit from doing the calculation. I want to focus instead
on what the implications are of what we've done. Is a mixed equilibrium really the right way to play
a game? And what do we even mean by the right way? We're dealing with games that have no pure
strategy equilibria. The best answer that we found deals with a glorified version of rolling dice.
Does this make sense? The logic that I used in finding these equilibria relied on the fact
that the game was zero-sum. What if some cooperative elements are introduced into the game,
making them a non-zero sum? How does this change affect things? We've worked today with games that
are two by two. What happens if the games are bigger? Or if they have more players?
The answers to these questions are not all simple and not always satisfactory. But then again,
it's no longer 1928. And as we'll see, John von Neumann isn't the only person who can have a really
good idea.
