In my last lecture, I introduced the idea of a strategy.
A player's strategy had to specify what that player would do in any situation in which they could find themselves.
You'll remember we illustrated this idea with a simple game.
I bought a vase for $8 and was deciding to sell it for either $10 or $20.
You were deciding whether to buy it.
I had only two strategies, sell it for $10 or sell it for $20.
Your situation was more complicated.
That was because you could find yourself in two different situations, depending on the price I set.
So one strategy for you had to specify how you'd respond to both of those situations.
Would you buy it for $10? Would you buy it for $20?
We found that you had four different strategies.
Could be worse.
If the vase came in brown or blue, that four strategies would jump to 16.
If additionally you could either buy with cash, buy with credit, or not buy at all, your strategy count would now jump to 81.
In fact, the number of strategies that you have could actually be infinite.
Our retail game would have been more realistic if I could have charged any amount for my vase, not just $10 or $20.
Then every different price I could charge would correspond to a different strategy for me.
You, on the other hand, would still only have one choice to make, buy or not.
But you'd have to specify which choice to make for every single price that I could offer you.
So you'd have an infinite number of strategies, too.
One of them would be, I'll pay any price up through $16.32, but nothing more.
But another one would be, I'll buy if the price has at least a one and a seven and at least two nines.
That second one sounds like a pretty silly strategy, and it is for the problem we're talking about, but it's still a strategy.
Silly or sensible, all of the strategies that we're talking about are pure strategies.
That means the strategy doesn't involve any element of randomness.
You're not going to flip a coin, for example, to decide what you're going to do.
A very useful way to imagine a pure strategy is as a book, an instruction book.
To make my meaning clear, let's look at one book I happen to bring for playing chess.
It's just one I pulled at random off of my library of chess strategy books.
Let's see what we've got.
Oh, it seems I picked book 34,282.
Good, this is one of my favorites.
Let's just thumb through a few pages at the start and see what we see.
Here's the first page.
As you can see, it shows the setup of the board at the beginning of the game, and at the bottom of the page, it tells me what to do.
E2, E4.
In chess shorthand, this tells me to move my king pawn two squares forward.
If you don't play chess, don't worry about it, it doesn't matter.
It's just one of the 20 possible first moves I could make.
If you went through all the books in the chess library, every single one of them would have the same picture on the first page.
And at the bottom of the page, each one would specify one of those 20 possible first moves.
After the first move, of course, the opponent gets a chance to make a play.
Turns out that he's also got 20 different possible moves.
So if you walk away from a chess board and then come back two moves later,
the board could now be in any of 20 times 20 or 400 different positions.
And every single one of those 400 different positions will get a page in this book.
Here's page two.
Pages two through 401 in our book will each have a picture of one of the 400 positions that the board can look like after two moves.
And at the bottom of each page, it will tell me the move to make.
Again, different books will tell you different moves, but every one of them are going to have those 400 pages with those 400 pictures.
Well, this book is not going to make the New York Times bestseller list.
We've only gotten to the second move of the game and we're already over 400 pages into the book.
How thick is this thing going to be?
Well, I could say pretty thick, but that would be shading the truth a bit.
It's going to have to have a page for every possible chess position on the board.
Let's put it this way.
If you could shrink every page in this book down to an atom, you'd need the mass of 100 earths to get enough atoms to write this one book.
And there are going to be more different books, more different strategies than there are subatomic particles in the universe.
A lot more.
All of this is part of the reason why no one has ever found the optimal strategy for playing chess.
But I don't want you to get too odd by the size of this book.
There's some other things about it I'd like you to notice that are also strange.
The first one's obvious.
Even an extremely long game of chess only usually runs a couple of hundred moves, so the vast majority of pages in this book will never be used.
Look, the book has 400 pages for what the board looks like after each of you have made one move.
You're only ever going to use one of those.
To some degree, that makes sense.
You have to be able to respond to whatever move your opponent makes.
But wait, only 20 of those 400 pages even correspond to the first move that you made on page one.
The other 380 pages correspond to starting with a different first move.
They have no chance of appearing in your game at all.
Now, there's a term that non-mathematicians use for pages like this.
The term is stupid.
Okay, I'll admit, it does seem a lot like wasted pages.
It turns out, though, that these roads not taken are really very important.
A lot of times, the decisions that we do make are based on the consequences of what would follow from decisions that we don't make.
Actually, this is pretty obvious once you think about it.
If you stopped going to work, you would be fired.
An unpleasant consequence.
Because of this, you go to work, and as a result, that unpleasant consequence never occurs.
So, in a real sense, the decision that you do make is because of the consequence that never occurred.
This is actually a general characteristic of rational decision-making.
To decide whether a strategy is any good, you have to know not just what happens.
You also have to know what decisions you would have made if things had worked out differently.
Some of you may be thinking, this is hopeless, that will never be able to handle so many possible strategies.
Don't lose heart.
In the upcoming lectures, I'm going to show you how to throw away a lot of the bad strategies
and just look at the good ones, or at least the potentially good ones.
A library may have an awesome number of books, but if you know the right system, like catalog numbers, you can usually find what you're looking for.
Let's move from the high-brow world of chess to something a little less intellectual.
Remember rock, paper, scissors?
Both players simultaneously refuel a choice of either rock or paper or scissors.
Rock beats scissors, scissors beat paper, and paper beats rock.
The strategy books for this game look a lot simpler.
Each one only has one page.
That's because when you play the game, you're always in the same situation, the start of the game.
There are only three of these books as well, because there are only three strategies.
Shoot rock, or paper, or scissors.
Short and sweet.
But, if you grab one of these books to play the game,
you'd better be sure that your opponent doesn't sneak a peek at which one you took.
If they do, they can always win.
If your competitor knows what prices you're going to set, she can set her prices a few cents below yours.
In games like this, you've got to mix it up, keep your opponent guessing.
Any pattern in your decision-making can be recognized by your opponent and thus exploited.
But random choices aren't the same thing as arbitrary choices.
Game theory has a lot to say about how to pick the best random strategy for your situation.
Any strategy that doesn't involve chance is called a pure strategy.
Anyone that does is called a mixed strategy.
We're going to need to develop a little machinery before we can deal effectively with mixed strategies in concrete terms.
But they'll play an important role in our later work.
Alright, we've talked a lot about strategies today.
But once the strategies interact and play themselves out, the game's over and everyone gets a payoff.
How does that work?
Well, the payoff to a player just represents how much that player likes the outcome of the game.
We'll follow the convention that the bigger the payoff, the bigger the number, the more the player likes the outcome.
So, whatever units you're using, a payoff of four is always better than a payoff of two.
Let me go back to the example of selling the vase.
I bought it for $8, but you think it's worth $18.
Let's imagine that we don't have time to haggle and that you make me a ticket to leave an offer, $11.
Then, if the deal doesn't go through, both of our payoffs are zero.
If it does go through, I make $3, I bought it for $8 and sell it for $11, and you make $7.
You buy it for $11 when you think it's worth $18, and those are our payoffs.
Pretty simple, right?
So far, yes, but there are four important points about payoffs that aren't so obvious.
First, the payoff to a player reflects what that player cares about, not what another player thinks they should care about.
Second, in general, the payoffs for different players can't be directly compared.
Third, for a class of games called finite games, all that matters about a player's payoffs
is the way in which they order them, which they rank them, not the specific size of the payoffs.
And fourth, in games that aren't finite, you have to be careful in what units you measure the payoffs.
Let's look at these ideas with our example of selling the vase.
You offered me $11 for an $8 vase that you bought value at $18.
If the deal goes through, I get $3, you get $8, and if it's $7, I'm sorry,
and if it doesn't go through, neither of us get anything.
It might seem clear that I should be willing to sell you the vase.
After all, gaining $3 is better than gaining nothing, and that's true if what I really care about is money.
But suppose that I have a rather simple idea of fairness, and in my way of thinking,
it's grossly unfair if you get more money out of our deal than I do.
If the agitation or frustration that I feel from you ripping me off in that way
causes me more than $3 worth of frustration, then I won't sell.
Why gain $3 from a sale that causes me more than $3 worth of agitation?
And my choice would be perfectly rational.
This is a big deal.
Why?
Because it's precisely this kind of behavior that a lot of people want to brand as illogical.
Irrational.
And it's not.
That's the key point.
It doesn't really matter how you feel about my final situation in the game.
It matters a great deal how I feel about my final situation.
My payoffs, my preferences.
Being rational doesn't mean that I make sense to you.
Being rational means that I make my decisions in a way that will lead to my best expected payoff,
given what I understand about the game and the other players at the time.
This is true in any game, but there are places where you can forget about it at your peril.
Consider, for example, the question of how best to deal with terrorism.
The payoff that a terrorist gets for blowing themselves up in a crowded street
is quite a bit different than the payoff that you would get.
In playing a game with a terrorist, you certainly don't have to agree with his priorities,
but you have to know what they are.
Without that, you can't craft a strategy that's best for you.
I'm saying it's not good enough to stand in somebody else's shoes.
If you want to play the game right, you have to be able to look out of the other person's eyes.
Okay, point one, and it's a biggie.
The payoffs have to reflect the actual preferences of the player,
not ones that we conveniently ascribe to them from the outside.
In fact, payoffs for different players might not even be measured on the same scale.
I could care about the time that I save, and you could care about how much money you make,
which is better.
I'm saving an hour, or you're making $10.
I don't know.
And it doesn't matter. That's really my second point.
In general, the payoffs to one player can't be directly compared to the payoffs to another.
But we can get sucked in when they're measured in the same units,
because that makes us want to compare the payoffs.
Here's a famous little game that can tell us a lot about what game theory can and can't do.
It's called the ultimatum game.
Here's how it goes.
There's $10 worth of money sitting on the table between us.
You propose to divide that money between us in some way.
Once you do, I look at your proposed division and either say yes or no.
If I say yes, we divide the money the way that you said.
If I say no, the deal falls through and no one gets anything.
Take a second.
This should sound familiar.
It's the same take it or leave it game that we played with the vase without the window dressing.
There's no haggling in the ultimatum game.
You make one offer of the division and I say yes or no end of game.
So what are you going to offer me?
And how should I respond?
Think about how you'd play this game.
Then state your offer out loud, please.
You propose a division and if I approve it, we follow through.
If I don't, neither of us get anything.
How much do you offer me?
Well, I'm sure I know your answer.
You kept $9.99 and offered me a penny which I took.
Now, what?
You didn't?
No, I'll bet you didn't.
Although that is the right choice.
At least if all that you and I care about is money and we both knew it.
After all, once you decided what the division was going to be, I have only two choices, take your offer or not.
And even if you offer me only a penny, I end up with more money than I would if I say no.
You knowing this and knowing that the more you give me, the less you get to keep will offer me one red cent.
Except that if you really had done that, I would have told you to take that penny and shunned your offer.
I would have rejected it.
So what the heck is going on here?
Are we both irrational?
No.
But our payoffs were wrong.
We're going to look at the ultimatum game and some of its relatives very carefully in a later, later on in the course, to watch how people really play.
But the heart of the matter is this.
Money really isn't all that people care about.
You can tell them to play a game to maximize their cash, but most people won't or can't do it.
The emotional modifiers to payoffs are strongly dependent on context.
The $10 division, for example, usually leaves both people feeling entitled to about half of the $10.
The game isn't symmetric.
The players are not in the same situation, but somehow it feels like they are.
But take away these extra factors and the behavior that you see matches pretty well with what game theory predicts.
Let me offer you an example.
You're making an offer on a house.
You'd be willing to pay up to $700,000 for it, but you know somehow that the owner will actually accept $600,000.
What do you want to offer?
Do you still want to split the difference?
Yeah, like I said, context makes a big difference.
Okay, in general, you can't compare the payoffs of two different players.
But how about the payoffs of a single player in two different situations?
Here, obviously, you have to be able to compare.
Well, I said we're following the convention that the bigger the payoff, the better the player likes it.
A payoff of 20 isn't as good as a payoff of 30, which in turn isn't as good as a payoff of 40.
A property that we like payoffs to have is that they're on an interval scale.
If they are, the gap between a payoff of 20 and 30 is the same as the size of a gap between 30 and 40.
Such payoffs are called cardinal payoffs.
For cardinal payoffs, you need to know more than simply the order of your preferences.
You can rate three flavors of ice cream as first, second, and third,
but the size of the gap between chocolate and vanilla is likely to be quite a bit smaller
than the gap between vanilla and, say, horseradish ripple.
It can be pretty tricky to figure out the right payoffs in some situations.
You may know that you'd prefer to go out with friends tonight than stay home, but how much?
And how does working overtime fall on that scale?
Well, the good news is that for a large number of games, it doesn't matter.
My third point about payoffs is this.
For finite games, order is all that counts.
You don't need to know the exact size.
It's good enough if you can tell me how the players rank their outcomes.
So for a finite game, knowing that chocolate's first, vanilla's second, and horseradish ripple is third
is good enough.
That's all we need to know.
Payoffs like these are called ordinal payoffs.
Think order to distinguish them from the cardinal ones that we were just talking about.
Ordinal payoffs are all that we need for any finite game.
So, what's a finite game?
Well, there are a few requirements.
First, the game has to be sure to end, eventually.
Second, there can never be an infinite number of choices available to any player at any one time.
That also implies that players aren't making other decisions based on random chance.
It's also true that the game has to have a finite number of players, but that's not really a problem.
We're going to see that a lot of games are finite games.
And again, the great news about finite games is that you don't need to worry about the exact size of the payoff.
All that matters is, here's my favorite, here's my second favorite, here's my third favorite, and so on.
We usually represent the payoffs in an ordinal game with numbers 0, 1, 2, 3, and so on,
where bigger numbers correspond to more preferred outcomes.
Again, the actual numbers that we use don't matter at all.
All that's necessary is that if I like outcome B better than outcome A,
then outcome B has to get a bigger number than outcome A.
Well, how about when games aren't finite?
Well, then we have to be careful about the payoffs that we use.
The ultimatum game showed us that with the problem involving money, the payoff that you receive might not just be the cash.
And even if money is all that you care about, dollar payoffs might still not be the right thing to use.
One dollar isn't always worth as much as another dollar.
Imagine this situation.
I offer you either one dollar, guaranteed, or a flip of a fair coin.
If it comes up heads, I give you ten dollars.
If it comes up tails, you get nothing.
One dollar or a fifty-fifty shot at ten dollars. What do you do?
Most people will take a chance on the coin flip, which on average is worth five dollars.
Certainly, if you could play this game many, many times, on average, you'd make more money by doing the coin flip.
But right now we're just talking about a single flip.
Most people would still do it.
The expected return is good enough to make it taking the chance worthwhile.
But imagine that I add some zeros to this problem.
It now works this way.
I offer you one million dollars or a chance to flip a coin.
If it comes up heads, you get ten million.
If it comes up tails, you don't get anything.
Now what would you do?
The only way I've changed this problem is by making it a million times bigger.
But now, most of us would take the million dollars for sure.
I know that I would.
Even though, on average, the coin flip is worth five million.
In a sense, ten million dollars just isn't ten times better than one million dollars.
The risk isn't worth it.
Unfortunately, for game theory to work correctly, the payoffs that we associate with outcomes have to obey this kind of calculus.
If I give you a choice between a guaranteed fifty payoff or a fifty-fifty chance at a hundred, you have to be able to say,
I don't care.
And as we've just seen, that's not going to necessarily be the case for dollar payoffs.
Economists have found a nice way of handling this problem using something called utility.
We take our original payoffs, for example, in dollars and change them into utils.
Utils are basically happiness points.
Going into the details of how we compute utility is going to be beyond the scope of this course,
but I'd like to give you an idea of how we go about it.
Let's look at dollar payoffs to keep the problem simple.
Suppose in a particular game theory problem, the biggest payoff you can get is a thousand dollars and the smallest you can get is zero.
Then I want you to imagine that you've got a lottery ticket.
This ticket is going to be worth either a thousand dollars if it's a winner or nothing if it's a loser.
I offer to buy you that ticket from you for a hundred dollars.
Do you sell?
Well, the answer to that depends on how likely the ticket is to be a winner.
If it has a ninety-nine percent chance of being worth a thousand dollars, you're not going to sell it for a hundred.
If it's got only a one percent chance of being worth a thousand, that hundred is looking pretty good.
Somewhere between those two points is a chance of it winning, which would exactly balance an offer of a hundred dollars guaranteed.
That point will be different for different people.
For me, it's about fifteen percent.
If I have a ticket with a fifteen percent chance of being worth a thousand, I'd sell it to you for a hundred, but I wouldn't be in a hurry to do so.
Okay, how about what would the probability be for two hundred, for three hundred, for four hundred?
After thinking about it, I'd want a thirty-one percent chance of winning to sell a ticket for two hundred dollars.
A ticket with a forty-seven percent chance of winning, I'd sell for three hundred and so on.
Again, these numbers are individual decisions.
The number of different answers after a bit of soul searching might be quite different from mine.
But all of these questions, once these questions are answered, we can put them together into a graph.
Here's mine.
Once I have this curve, I can rescale all of my payoffs in the problem, replacing each dollar number with the probability that goes with it.
So, for example, suppose you offer me either four hundred dollars for sure or a prize based on a coin flip.
On the coin flip, half the time I get a thousand and half the time I get a hundred.
Well, the average money I'll get from this coin flip is five hundred and fifty dollars, which is more than the four hundred you're offering.
But that doesn't factor my feelings of risk, love, or risk aversion into the problem.
Let's rescale my payoffs by using the probability numbers to get my utils as satisfaction.
When I do this, the four hundred dollars from my chart becomes point six three, the one thousand dollars becomes one point oh, and the one hundred dollars becomes point one five.
That means the fifty fifty coin flip now averages one and point one five, which gives me point five eight.
That's less than the point six three that I said four hundred dollars was worth.
So for me, taking the four hundred dollars for certain is better than the coin flip, which is a lower utility.
I'll be honest with you though.
Now that I've shown you how to find utility, I'm largely going to ignore it for the rest of the course.
It's not that it doesn't matter, although sometimes we don't need to pay attention to it.
My main reason for doing so is simply that different people have different utility functions.
Your utility isn't a matter of logic.
It's a matter of personal preference.
And the answers that we're going to get for utility are going to be different for different people.
Because of this, I'm going to do what most people do when they're teaching a course in game theory.
I'm going to analyze a lot of problems by using the most obvious payoffs possible, dollars and so on.
This would actually be the right thing to do if you were risk neutral.
For example, if a fifty fifty shot at a hundred dollars was just as good as fifty dollars to you.
When dealing with money adopting this risk neutral attitude makes sense if you get to play the game over and over again.
For a single shot, it might not be right for you.
There's real danger, however, in this approach of using the obvious payoffs.
If I knew your personal risk profile, your personal utility function, I could adjust the payoffs to reflect it.
More than that, if I knew your feelings about how much you cared for the feelings of others,
or personal morality, or a sense of fairness, I could factor these in too.
I'm not going to do that because people can differ so much in their feelings on these issues.
But in leaving these factors out, I can give you the idea that game theory assumes that the players are just money-grubbing, selfish, inconsiderate egotists.
And that's not true at all.
It's just that if you do care about how other players do, that has to be reflected in your payoffs.
Remember, your payoffs reflect what you care about.
So, when we're looking at a problem in this course and you feel that personal factors matter to you,
take a couple minutes to change the payoffs and the problems to the ones that you feel are appropriate for the way that you see the world,
and see what game theory has to say.
Alright.
Before we start playing around with games, we need to make one final, slightly weird assumption.
We usually assume that the rules of the game and the rationality of the players are common knowledge.
What does this mean?
Let's talk about the rules of the game being common knowledge.
You'd figure that would mean that everybody knows the rules of the game, and that's true, but it's not enough.
We both may know that I need your order by Thursday, but I could still be worried,
because I might not know that you know that I need your order on Thursday.
You can think of common knowledge of the rules in this way.
A player who knows the rules has common knowledge level one.
But to anticipate what other people are going to do, I have to know that they all have common knowledge level one.
If I know that, I have common knowledge level two.
But you see where this is going.
In order to rely on common knowledge level two, I need to know that everybody has it.
My knowledge that everyone has common knowledge level two is common knowledge level three, and on and on and on forever.
Common knowledge actually means all of these things, all the way down, and if this knowledge is possessed by all players.
It's actually an easy idea, but it's difficult to talk about.
In the comedy movie Mystery Men, the superhero, Captain Amazing, played by Greg Kinnear,
confronts his arch nemesis, Casanova Frankenstein.
Frankenstein's just been released from an insane asylum, and his first act is to blow it up, to lure Amazing into his clutches.
Sure enough, Amazing soon flies through the window of Casanova Frankenstein's library.
Frankenstein, who is sipping a Harvey Wallbanger while sitting in an overstuffed chair, says,
Captain Amazing, what a surprise.
Really? I'm not so sure about that.
You were first date out of freedom, and you blew up the asylum.
Interesting choice.
I knew you couldn't change.
I knew that you'd know that.
Oh, I know that.
And I knew you'd know I know you knew.
But I didn't.
I only knew that you'd know that I knew.
Did you know that?
No, of course.
Basically, Casanova Frankenstein is admitting here that he doesn't have common knowledge.
He's saying that he's got level three, but he doesn't have level four.
Okay, he's also having a lot of fun with Captain Amazing.
This idea of common knowledge can look like a hall of mirrors when we try to make a practical notion formal,
but for most purposes, your intuition about what common knowledge is is going to do just fine.
Fine, excuse me.
Okay, players, strategies, payoffs, rationality, common knowledge.
We're all set up.
Let's play some games.
