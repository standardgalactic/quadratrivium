in the timescales we'll be dealing with in this course.
I once did a workshop in which I got people to stand along a corridor
and I got someone to volunteer to be the Big Bang
and then someone else volunteered to be the first slimy creature that crawled out of the sea
and someone else to be the first multi-cell organism, the first dinosaur, and so on.
And I placed them along the corridor at appropriate points and I primed them.
And then I got other members of the workshop just to walk down the corridor.
And it was wonderful.
You could walk down the corridor and you could chat with the Big Bang,
or with the early Earth,
or with the first slimy amphibian to crawl out of the sea.
Now, what can these scales tell us?
At first sight, they may seem to deprive our planet and our history of any significance.
We seem so small, so short-lived.
This used to depress my students.
But we'll see in the next lecture that this is not quite the end of the story.
We may seem small and short-lived,
but by some criteria such as complexity, which is the theme of the next lecture,
we humans and our history are significant even on cosmological scales.
The French philosopher Pascal wrote,
For what is man in nature?
A nothingness in respect to infinity.
A whole in respect to nothingness.
A median between nothing and everything.
Thank you.
In the previous lecture, we discussed one unifying idea.
We discussed one unifying idea in this course.
As we've seen, this course covers so much territory
that it's very important to be clear about the ways in which we can construct
a coherent account across all these disciplines.
The idea we looked at in the last lecture was the idea that
to fully understand the past on the scales of big history,
we need to explore it at multiple scales.
And we saw that each scale can illuminate the others.
We also saw that each scale can affect how we understand other scales.
For example, I ended with the idea that I said depressed many of my students,
and indeed it did, which is that the colossal scales of big history
seem to make humans and human history utterly insignificant.
As we'll see in this lecture, that is really not the end of the story.
So now what I want to look at is a second unifying idea of big history.
Because we face another fundamental difficulty,
not just the difficulty of scales, but the problem of coherence.
What thematic coherence can you possibly find
across all these scales and all these disciplines?
If you tell a story that begins with cosmology,
includes geology, then biology, and human history,
isn't it bound to be just a rag bag of completely separate stories?
After all, in universities each of these stories is told in quite separate departments,
and most of the time very little attempt is made to link them to string them together.
Is there anything that all these scales and all these different disciplines share?
Well, what I want to argue in this lecture is that there is a central idea,
and that idea is the idea of increasing complexity.
And we've seen already that the idea of increasing complexity
provides a sort of structural framework for this course.
It's an idea that's emerging in the writings of a number of scholars
who are thinking about the implications of big history, of unified accounts of the past.
And what I'll do is that this idea links all the different parts of our story in very powerful ways.
Furthermore, I'll argue that it shows how each part of the story can illuminate
and deepen our understanding of the others.
Just as we saw that understanding different scales
can help us understand more familiar scales in new ways.
Okay, so our theme is complexity.
Let's begin by asking, what do we mean by complexity?
What is complexity?
Now, we all have an intuitive idea of the difference between simple and complex things,
and that intuitive sense of complexity will take us quite away.
There is an incredibly rich body of mathematical, sociological, and biological theory on complexity.
I'm really not going to go too far into the nuances, and we don't really need them.
Some fairly basic ideas about complexity will take us a long way for this course.
So here is an attempt to pin down some of the properties of complex things.
Here's the first thing.
Complex things like stars or planets or you and me
consist of diverse components bound into larger structures.
And I need to add that those structures are patterned in very precise ways.
So that's the first thing.
You take a lot of components and you put them together in a particular structure.
Now here's a second slightly less obvious feature of complex things.
These structures that bring together diverse components display distinctive emergent properties.
Now the phrase emergent properties I'm using in a slightly technical sense.
I mean features that are not present in the components from which they are constructed,
but appear only when those components are assembled in specific ways.
Now the idea of emergence is going to be immensely important in this course.
So I'm going to take a bit of time to try and clarify it.
Here's a very simple illustration.
You could study the properties of hydrogen and the properties of oxygen as long as you liked
without being able to predict properties of water,
which is what you get when you combine two hydrogen atoms and an oxygen atom in a very specific way.
The properties of water are emergent properties.
They exist not intrinsically in the components, but because of the way those components are arranged.
They arise from a particular arrangement of those atoms, rearrange them differently,
and you may get different properties.
The idea of emergence, it turns out, is actually a very old one.
And there's a lovely illustration of this in a Buddhist sutra, which is known as the Questions of Melinda.
And I want to go back about 2,200 years to the Questions of Melinda to explore the idea of emergence
and to try and capture the magical quality of emergence.
What's magical about emergence is properties appear that seem not to reside in anything in particular.
They just suddenly appear when you rearrange those things in a particular way.
They appear not to be present, then suddenly they appear.
They appear only in a particular arrangement.
OK, so the Questions of Melinda.
Melinda is the name in this Buddhist sutra for a Greco-Bactrian ruler
who ruled a kingdom and empire that stretched from Central Asia to Kashmir in about the 2nd century BCE.
He's debating with a Buddhist monk, Nagasena.
And what they're debating is the Buddhist idea of the self.
The Buddha famously argued that in some sense the self doesn't really exist.
We all have a very strong sense of the self.
But the Buddha argued in some sense it's illusory, and this is what they're debating.
The emperor, Mananda, Melinda, as he's described in the sutra, says to Nagasena that the self is real.
Nagasena says to the emperor, how did you come to this meeting?
Melinda says, in a chariot.
Nagasena asks, then please explain to me what a chariot is.
Is the pole the chariot?
No, reverent sir, says the emperor.
Is then the axle the chariot?
No, reverent sir.
Is it then the wheels or the framework or the flagstaff or the yoke or the reins or the gold stick?
No, reverent sir.
And with all the Buddhist sutras, this goes on and on and on for pages, to and fro.
Then, and I'll skip all of that.
Then eventually Nagasena says, then is this chariot outside the combination of pole, axle, wheels, framework, flagstaff, yoke, reins and gold?
No, reverent sir.
Then says Nagasena, ask as I may.
I can discover no chariot at all.
Just a mere sound is this chariot.
And at this point he claims victory.
And he says, it is just so with me.
In other words, with the self.
Independence on the 32 parts of the body and the five scanners, these are simply Buddhist technical terms for the components of the self.
There takes place this denomination, Nagasena, this designation, this conceptual term.
In short, what he's saying is that the self, like the chariot, doesn't exist in any of the bits and pieces from which it's made.
It exists, or rather it emerges as a property when you assemble those things in a certain way.
And this is characteristic of emergent properties in general.
When assembled into larger structures, new things appear.
The sociologist Durkheim, one of the founders of modern sociology, was also acutely aware of emergence.
And it was very important to establish the credentials of sociology as a discipline.
Because what Durkheim tried to establish was that in society there are properties that do not reside in individuals.
Society has emergent properties of its own.
And here's how Emile Durkheim described what I'm calling emergence.
Whenever any elements combine and, by the fact of their combination, produce new phenomena,
it is evident that these phenomena are not given in the elements, but in the totality formed by their union.
And then he goes on to talk about life as an emergent property.
The living cell he writes, and he's writing the 19th century, remember, contains nothing but mineral particles.
Just as society contains nothing but individuals.
It is obviously impossible, however, for the phenomena characteristic of life to exist in the atoms of hydrogen,
oxygen, carbon and nitrogen.
For how could the properties of life exist within inanimate elements?
Life is in the whole, not in the parts.
So I've spent some time with this property of emergence.
It's absolutely crucial, this magical appearance of new qualities when you get a new level of complexity.
So that's the second property of complex things, emergence.
Now the third property, this is much simpler.
Complex entities have a certain stability.
Now this is, in a sense, stating the obvious.
If they didn't have any stability, we simply wouldn't notice them.
They'd pop up, they'd vanish, we wouldn't see them.
So they have to be stable to a certain extent.
Atoms or stars survive for billions of years, butterflies survive for just a few days.
So they've survived long enough to be interesting.
But the stability is never absolute.
Eventually they all break down.
And in the case of living organisms, we call this breakdown death.
Now a fourth property that's less immediately obvious.
And this is that to maintain complex things, you need energy flows to bind simple components into more complex structures.
Without these flows, the structures simply break down.
If you want to try this experimentally, try not eating for a year.
Very simple, your structure depends on energy flows.
So we study complex things, partly because we are complex.
But there are also good biological reasons for this.
To survive, we must be extremely good at detecting complex things in our surroundings,
such as tigers or tax inspectors.
We need to be good at detecting complexity.
We need to be complexity detectors.
And that is why this course will focus more on complex things, such as stars,
than on the simple things, such as empty space to take up most of the universe.
After all, if I were to try and make this a sort of equal time course,
we'd spend most of our time talking about empty space.
And I don't think that would be very exciting.
Okay, now the next point about complexity.
Though one of my heroes, Stephen J. Gould, has disputed this claim,
there are powerful reasons for thinking that over 13 billion years,
the upper level of complexity in the universe has increased.
Now, how can we demonstrate this?
Well, intuitively, it seems pretty clear.
The early universe, we'll see, was very simple.
It consisted of hydrogen, helium, and energy, not much else.
Now, 13 billion years later, there are lots of complex things,
such as planets and pythons and people.
So that's the intuitive demonstration of what I mean.
But there may also be more rigorous ways of trying to say this.
The astronomer, Eric Jason, has been teaching an astronomer's version of big history
in Boston for at least 20 years.
And he has argued that if it takes energy to create and maintain complex things,
that ought to mean that it takes more energy to make more complex things.
Now, what this means, roughly speaking, is that if he's right,
we ought to be able to roughly measure levels of complexity by measuring energy flows.
And this is an experiment that Jason himself has attempted in a rough and ready way.
He's tried to estimate using what at the moment are little more than back-of-the-envelope calculations,
but as we'll see, they're quite powerful.
He's tried to estimate the amount of energy that flows through a given amount of mass
in grams in a given amount of time in seconds.
And he calls this the energy density.
This is a measure of energy flows.
And here are some of his results.
Now, his unit is ergs flowing through a gram in a given second.
But it's the numbers that really matter here.
So here are his units, stars.
You do the sum for stars, and you come up with the figure 2.
2 ergs per gram per second are flowing through stars.
Now, you do the same calculation for planets.
And the figure he comes up with is 75.
Note immediately, it's a lot more than two.
Now, you do it for animals, and the figure is 20,000.
And you do it for human society today, modern human society.
And the answer is about 500,000.
Now, the point is that even if these calculations are out quite significantly,
the differences are so striking that they suggest that there is something to this rough correlation
between energy density flows and complexity.
So, Chesson's results, if they're accurate,
suggest conclusions of fundamental importance for big history.
Most of the universe we've seen has remained very, very simple.
Imagine someone picks you up.
They plonk you randomly, somewhere in the universe, completely randomly,
and you reach out and you grab a handful of the universe.
What are you going to grab?
You're not going to grab a person.
You're not going to grab a planet or a star.
The odds are overwhelmingly that you will grab a piece of cold, empty vacuum.
So, most of the universe is extremely simple,
yet the upper level of complexity has increased.
And Chesson's calculations suggest that living organisms are more complex than stars,
and modern human societies may be amongst the most complex things we know.
This, I think, may be the answer to the student who's depressed,
by the sense that the scales of the modern accounts of creation of big history
make them seem small and insignificant.
Now, I have to say that Stephen Jay Gould disputed this sort of conclusion
in a famous book called Full House, which is full of baseball statistics.
But his real objection, I think, was not to the idea that I'm suggesting,
but to the idea that the average level of complexity has increased.
In fact, as I've said, the universe remains very simple.
It's simply that some very complex objects have appeared,
and those are the things we're going to be interested in.
It's not that the average level of complexity has increased.
Now, there's something else we can say about complex things.
More complex objects appear to be rarer and more fragile than simpler objects.
And that's why, even though they've appeared,
they may not have changed the average level of complexity of the universe as a whole.
Stars, for example, are more common and survive longer than butterflies.
And the simplest thing of all the vacuum is, of course, much more common than either.
So if you're complex, you're probably rare, you're probably also fairly fragile,
which is an idea that I think has quite a striking message for modern human society,
which is fantastically complex.
Okay, let me summarize these ideas.
Roughly speaking, it seems that complexity can be measured
by the density of the energy flows through different complex entities.
And these calculations suggest what intuition suggests as well,
which is that over time, the highest levels of complexity have increased.
More complex things have appeared in the course of the 13 billion years
that the universe has existed.
Now, it has to be said straight away that a physicist hearing this sort of argument
might be worried that there's something paradoxical about them.
For at first sight, it seems to contradict one of the most fundamental laws of physics,
and that's the second law of thermodynamics.
Now, to deal with this argument, I'm going to talk very briefly.
Remember, as a historian, not a physicist, about the laws of thermodynamics,
because we have to get this argument straight.
What are the laws of thermodynamics?
They describe the relationship between energy and work.
Work simply means the ability to make things happen, to cause change.
So it's a very fundamental concept in any understanding of the universe
and the nature of change.
The first law of thermodynamics, and I should say both of them were formulated in the 19th century,
says that the total amount of energy available in any closed system
that's any system closed off to other flows of energy,
and the universe itself is a closed system, is fixed.
The total amount of energy in a closed system is fixed.
That's the first law.
However, at any particular point in the universe or any particular time,
the form, the distribution, and the intensity of energy can vary.
And this matters, because work can be done only when energy is distributed unevenly.
If it's distributed unevenly, it can flow from one place to another,
