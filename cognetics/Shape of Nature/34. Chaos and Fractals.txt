Welcome back, and thanks for joining me again.
In all our lectures thus far, we have seen the world from the viewpoint of classical dimensions.
We have started with one-dimensional knots, two-dimensional surfaces,
three-dimensional manifolds, four-dimensional polytopes, and higher dimensions in terms of configuration spaces.
Now, are there objects in nature that do not fit so nicely in the framework that we've created?
But what about these objects like snowflakes, crystals, clouds, ferns, coastlines, cauliflower, and lightning?
For example, let's just take a look at lightning, the shape of lightning.
Notice that lightning is not one dimension, it's not a line.
But yet, it's not two-dimensional either.
It's stuck somewhere in between.
It doesn't cover up an entire plane of possibilities,
nor is it simply a description of a straight line that we can understand.
So today we study the mathematical framework that allows us to capture this notion of the in-between.
Our work in this world begins with the idea of chaos.
Chaos is the behavior of certain systems, for example, weather patterns, that are highly sensitive to the initial data.
Sometimes called the butterfly effect, it describes how small changes in weather systems today
can have drastic changes in weather a week from now.
And we start with simple tools in order to construct elegant, chaotic systems, to understand them and to see them behave.
And this leads to the idea of self-similarity, focusing on some of the extreme shapes found in nature, such as snowflakes, ferns, and lightning.
Indeed, if we look at lightning again, if you look at that crack of lightning and zoom in to a part of that lightning bolt strike,
you see another entire lightning in it. You see this idea of self-similarity.
It looks like the entire object if you look at a piece of it.
This is the same for all of these objects I described.
Each of these objects of the property, the part of its shape, looks like the whole.
Now we close this lecture with an understanding of dimension from a fresh perspective, from the world of fractal dimensions.
Now we begin with a historical viewpoint of dynamics, of motion.
Now both chaos and dynamics are very closely related to one another.
Dynamics is the study of motion and change.
Now from this motion comes chaotic behavior.
Probably the most famous example of a problem in dynamics is the n-body problem.
It's made famous by the work of Isaac Newton.
Here we are given a set of data which represent the positions, masses, and velocities of n-objects.
For Newton, these objects were planets and other heavenly bodies, and for us they can be particles in motion.
Now what do I mean? You're given the position, you're given the mass, and you're given the velocity,
how fast in the direction they're going to be traveling for all of these different objects.
Now that's what you're given as the starting position.
But given Newton's laws of motion and gravity, he tells us exactly what motion and gravity are about,
we have an equation which then describes the motion of these objects.
And if we can solve this equation, then we can predict where the objects will be at any given time.
We can look into the future.
For example, let's just take one object. Imagine I have a baseball in my hand.
And I know if I throw it and I release it right here, I know the position of the baseball,
I know the velocity in which it's going to travel, and the direction, the speed in which it's going to go,
and I know the mass of the baseball.
Well, if I know those things according to Newton's laws of motion and gravity,
we know exactly where the ball is going to be in time.
Unfortunately, it turns out we can only solve this equation, this super equation of future prediction
for one body, for example, like a baseball, or for two bodies.
Even for three bodies, it turns out that nobody knows how to do this today.
It is an open problem, and anything more than three is extremely difficult.
Now, the reason this is difficult is due to gravitational interactions.
Each object isn't going in its own way.
If I have three objects, they're not just doing their own thing.
They're actually interacting with one another.
There's a gravitational pull.
If each of these represents stars in the solar system,
then you see this gravitational pull from one to the other one.
Now, one feature of the end body problem is the appearance of chaos.
Now, to understand what chaos is about, we look at the story of Edward Lorenz.
Now, Lorenz was a math graduate student at Harvard who became a meteorologist at MIT in about the 1960s.
And at that time, he was running a very primitive computer program for weather prediction.
Here's what happened.
He wrote down, as his program was running, he wrote down an intermediate result at one point.
He wanted to stop the program and come back later and see what happened.
So he just wrote down an intermediate result.
He came back the next day, and he started his calculations again
using this intermediate result that he had written down.
And he noticed something very unusual.
Lorenz became completely different from using his intermediate result
than from letting the program keep running.
In other words, instead of stopping the program, writing the result,
and plugging it back into the program and letting it go,
if you had just let the program go, you would come up with completely different results.
One would give you an amazingly sunny day the next day,
and the other would give you an intensely rainy day.
Why?
They're both using the same value system.
One just stops and then starts the computer again as you plug in the intermediate result,
and the other keeps going. Why should there be a difference?
And it turns out rounding off air is the problem.
His writing down an intermediate result, he didn't write down the entire long number.
He actually rounded up just a little bit.
He made it a little shorter, and this small rounding off air caused an immense change in the weather.
He noticed that simple differential equations could have very sensitive dependence
to these initial conditions of where they start.
This is called the butterfly effect.
A small butterfly in Brazil flapping its wings today
could actually powerfully impact the weather system three weeks from now.
It could create a hurricane because of a small change.
But today, this is an immense field of study,
and I am actually doing a great disservice by condensing an entire field into one lecture.
But I wanted you to have a taste of this world from the perspective of shape.
Now, it is not only in weather patterns that chaotic behavior is observed.
It has been noted in mathematical biology, such as in population dynamics
and even in the beating of the human heart.
Even the motion of Pluto, formerly a planet, seems to exhibit this kind of chaotic behavior.
So, what does chaos mean from a mathematical viewpoint?
Well, let's consider a very simple and naive model of a weather system.
This is really a bad one, but it's simple enough for us to grasp.
Here's what it is.
I have a function f of x equals x plus 2,
which means if we give it our current temperature x,
this function, this machine f of x, will give us tomorrow's temperature.
So f of x equals x plus 2.
So if today's temperature is 3, I plug it into the machine tomorrow's temperature is 5.
Then tomorrow's temperature is 5, I plug it into the machine.
The temperature after that is 7.
See, this is how the machine works.
It's a machine that tells us the next day's temperature given the current temperature.
So what should we do to get the weather three days from now?
We take our weather today, we plug it in, and then we plug it in, and then we plug it in.
We keep plugging it in.
Iterating is the mathematical terminology.
We iterate this function over and over again to get future predictions.
Now, based on this, we get several important concepts.
The first is that the orbit of a point under a function is what happens to it as we continue to iterate.
For example, the orbit of the point 1 under our function is that 1 becomes, well, x plus 2 is our function.
f of x equals x plus 2.
1 becomes 3, which becomes 5, which becomes 7, which becomes 9, and that's the orbit.
You see where it's going doing the entire step.
Well, the most important type of orbit is a fixed point.
A fixed point is 1, which never changes under iteration.
Now, we've already seen fixed points with respect to wind flows on surfaces.
These are the places where there's no wind or no change.
Now, what about f of x equals x plus 2?
Is there a place that if we iterate, we actually get fixed points, and it turns out there are no fixed points.
No matter what value you plug in, this function always adds 2 to it.
So thus, it's always moving further and further, and there's never a place it stops.
But consider the following functions.
Here, we have y equals x squared.
And notice this function has 2 fixed points.
0 is a fixed point. Why?
If I plug in 0, and if I square it, 0 squared is 0.
Well, I take that answer, I plug it back in.
0 squared is 0, and it stays there.
No matter what happens, as I look at the orbit of what happens to 0, it doesn't move.
It's fixed.
Well, what about 1?
Well, 1 squared is 1.
1 squared is 1, and that's squared is 1.
And you see 1 is also another fixed point.
So this function f of x equals x squared has 2 fixed points.
Well, what about the function f of x equals x cubed?
Well, here we have 3 fixed points.
0 is a fixed point, 0 cubed is 0.
1 is a fixed point, 1 cubed is 1.
But now we have negative 1 is also a fixed point.
Negative 1 cubed is negative 1, and this cubed is negative 1.
And you see the orbit just stays around these points.
In fact, there is an elegant geometric viewpoint of iterations,
which we can do to understand fixed points.
Let's consider an example.
Let's look at the function f of x equals x plus 2 again.
Here we see this function.
And what we want to do is we want to graph our function f of x as shown here
and the line y equals x.
Now, this line is going to act as a mirror to what our function is going to do.
We're going to bounce off ideas of this y equals x line with our function
to understand what iterations and orbits are about.
So what we do is we start at the y equals x line over the point of interest.
Say we want to understand what happens when we started x equals 1.
Say that's the place that we're interested in.
Remember, x equals 1 represents today's weather.
In a simplified model like this, x equals 1 is what is happening now.
And we want to know, according to this weather prediction machine,
f of x equals x plus 2, what are the weather's going to look like?
But now I want to do this visually.
So I take my point x equals 1 and I put it at the y equals x line.
This is the point 1, 1.
Now, the next thing I do is I follow a vertical line from this point
until my function is reached.
And when I do this vertically, I get the point 1, 3.
Now, from this point, I follow a horizontal line until my y equals x line is reached.
This becomes 3, 3.
Now notice, my 1, 1 point went to 3, 3.
So basically my 1 went to 3.
Notice what happens.
This is the orbit starting.
And I can do this again.
I can go from 3, 3, 2, 3, 5 to 5, 5.
And I can keep repeating this up and across, up and across, iterating this thing.
And this forms a cobweb-like diagram
which shows the orbit visually from our starting point x equals 1.
Now, let's consider another function.
f of x equals x cubed.
Again, we graph our function f of x and our function y equals x, that line y equals x.
Now, notice this is three fixed points that we talked about earlier, 0, 1, and negative 1.
Indeed, these three fixed points appear as the places where my function intersects my y equals x line.
Notice, at those points, I cannot go up and across anymore.
I'm already there.
Both worlds meet, thus the fixed points.
Now, look at any points after x equals 1.
Anything after that fixed point x equals 1, say x equals 2.
Look what happens.
I start at the y equals x line.
I go up and across, up and across.
And look, I just go off to infinity.
It just flies away.
Similarly, all the points below x equals negative 1, less than x equals negative 1, from that fixed point,
if I look at any point at y equals x, I go down and across, down and across.
And notice, it goes off to infinity.
But the points between negative 1 and 1, all the points there, if I start at the y equals x line
and go vertically horizontally, vertically horizontally, they all collide towards 0.
Thus, we can visually understand these orbits.
And just like fixed points on wind flows, we see that the fixed points here come in different flavors,
come in different kinds.
For example, the x equals 1 and the x equals negative 1 fixed points, repel.
Notice, any points near there, just sometimes they go off to infinity,
and sometimes they go to 0, but they never come towards each other, towards these fixed points.
They're repelling fixed points.
On the other hand, x equals 0, you see, is an attracting fixed point.
Any particles near there, as we start iterating the function, just make the particles collide towards x equals 0.
Things seem to be going well for us, and it's beautiful.
It seems we have a strong grasp on what is going on.
Unfortunately, it turns out this is far from true.
Let's turn to a simple function yet again, and by doing so, we enter the world of chaos.
Now, consider the following example.
f of x equals x squared minus 3.
That's it. It's that simple.
f of x equals x squared minus 3.
Let's graph the function, and let's graph the y equals x line.
It's going to look something like this.
Notice this has two fixed points, both of which are repelling fixed points.
It's easy to check they repel.
Now, call them points p here and q here.
Now, here's the simple question I'm going to ask.
Can you find the set of starting points, the initial values we need to plug into the function,
which do not go to infinity, whose orbits do not go to infinity?
Consider the interval negative p to p.
Consider that interval, right?
p is one of your fixed points.
Go from p all the way to negative p and make this following box you see here.
Now, we can see that any starting value outside of this interval must go off to infinity.
For example, if I pick a value like 3, which is outside this box, look what happens.
I start at the y equals x line.
I go up and across, up and across, and it just flies off to infinity.
And similarly, if I look at the value negative 3, I start at the y equals x line.
Then I go up and then I go across and up and across, and again, it flies off to infinity.
Now, this is a great first step.
We've eliminated all the points outside this box because they all go to infinity.
I'm trying to find the places that don't go to infinity.
Well, these huge clusters of infinite number of points get thrown away because they're not what we're interested in.
So, there's another way we can look at this question.
Let's rephrase this question.
Let's find the set of starting points that do go to infinity.
I'm feeling kind of bad because I haven't found one yet.
So, if I change the question, I might make myself feel a little better.
So, now I found tons of points that go to infinity.
And now let's look over at what's left over to see if there's any points that actually don't go.
Let's try to find the points which actually go off to infinity.
Let's see what happens.
Now, consider this interval here that I've labeled I1.
Now, notice this is the interval formed by all the points down here from the function that lands outside of my box.
And notice what happens if I take any points on my interval as my starting position.
And if I do my vertical and then my horizontal, look what happens.
In my first iteration already, if I do my vertical and horizontal, I'm already out of the box.
And then if I keep doing vertical and horizontal over and over again, these particles go off to infinity.
All these points leave and they go to infinity quickly.
So, the entire interval I1 goes to infinity and all the points outside of my box goes to infinity.
So, does everything go to infinity?
Well, notice the end points of this interval, they don't go to infinity.
Look what happens.
If I look at this endpoint of this interval, I draw a vertical line and then I go horizontal and then I do vertical.
Remember, I'm trying to build my cobweb structure and then I do horizontal.
And look, I land at P. P is a fixed point.
So, the endpoint, this endpoint lands at P.
Let's look at the other endpoint.
This drops down and then I go across and then I go up and I go across and that lands at P also.
And once you're at P, once it's a fixed point, it's going to stay there.
Remember, P can't go anywhere.
It's a fixed value.
So thus, although the interior of the interval goes to infinity, the boundaries of the interval, those two points, stay fixed.
They don't go to infinity at all.
The orbits are finite.
So, what about the points which get sent to our interval I1?
Notice here, I have two intervals.
I'm going to label both of them as I2.
Any points on this interval, if I do a vertical and a horizontal as I build my cobweb, they get sent to I1.
But what do we do if we iterate again?
Well, I1 gets sent out and the out goes to infinity, which means all the points in I2 also go to infinity.
In one iteration they go to I1 and in another iteration they leave the box.
But notice the endpoints of I2 get sent to the endpoints of I1.
So this endpoint right here gets sent here, this one gets sent here, this one gets sent here, and this one gets sent here.
The endpoints go to the endpoints of I1, but the endpoints of I1 do not go to infinity.
So now we are starting to build a collection of points that actually stabilize, that don't go off to infinity.
We can keep doing this.
Now, a few things to consider.
Each time we do this, there are twice as many intervals as before.
And inside all these intervals, all the points go to infinity.
But the boundary of these intervals, the endpoints of these intervals all remain finite.
And this, my friends, is chaotic behavior.
Because if you are exactly on an endpoint of these intervals and life stabilizes,
because you know exactly where you're going and it becomes finite.
But if you just move a little bit on either side of that interval, things go to infinity.
A simple flap of a butterfly's wings is enough to push you over and you get into a chaotic behavior.
It doesn't smoothly transition from nice to chaotic.
It goes intensely from one point being finite, orbit stays to one touch over and you're blown away.
And you just go to infinity.
So our simple function, x squared minus three, well, that has chaotic behavior.
But I still haven't answered the question, what is the answer at the end of the day?
Well, the end of the day, which points do go and stay in a finite realm rather than go to infinity?
To understand this, we must enter the world of fractals.
And we start with the construction of the classic canter set.
Let's take a look.
The canter set starts with an interval, zero to one interval, and I remove the middle of that interval,
the middle third of that interval.
I take one third to two thirds out.
And then I have two separate intervals.
Now I do the same procedure again.
I iterate this magical visual way of thinking about it in terms of removals.
I remove the middle third of this one, the one ninth to two ninth interval,
and I remove the middle third of this one, the seven ninth to eight ninth.
And now I have four intervals, and I repeat this process over and over again,
keeping removing these middle parts of the interval.
At the end of the day, at the limit, when I do this forever, I get the canter set.
Note that each iteration, we have twice as many intervals as before.
In fact, this is exactly the procedure that's going on with the x squared minus three.
And indeed, the set of elements, which do not go to infinity for my x squared minus three,
look exactly like the canter set.
So what is the canter set?
What's left over at the end of the day?
Well, using analysis, not combinatorics, not algebra,
but analysis of branch of mathematics, we can prove the following theorem.
After all the iterations, the canter set contains no intervals at all.
You just have a collection of points, disjoint points.
But moreover, there turn out to be an uncountable number of these points.
In other words, mathematically, a huge number of points left over.
So we see chaos.
For a function as simple as x squared minus three, we see an intense chaotic behavior
for points that are stable and points that are unstable.
An uncountable number of them stabilize, and an uncountable number of them become unstable.
We also see fractals here, objects which have a high level of self-similarity.
For example, notice the fractal behavior with the canter set.
We have this entire set.
We remove the third.
We're removing it as we zoom into part of the canter set, as you can see here.
It looks like the entire set again.
As we zoom in, it looks like the whole thing.
We see fractals in nature, such as snowflakes, where we zoom in,
we see the whole snowflake parts again, ferns, cauliflower.
As we zoom into a part, we see a hole.
And for us to study fractals, we need to look at a little bit more examples.
Let's take a look.
Let's consider two more fractals which are extremely famous.
The first is the Serpinski triangle.
Here's what it looks like.
Similar to the canter set, this fractal can be built from infinite removals.
We start with an equilateral triangle.
We remove the middle third triangle right here, the upside down one.
Then we're left with three triangles.
We remove the middle pieces from here.
And we're left with one, two, three, four, five, six, seven, eight, nine triangles.
Now we remove the middle pieces from here.
By iterating this procedure, we get, at the end, in the limit, the Serpinski triangle.
Notice the fractal nature of this set.
As we zoom into one part, it looks like the whole.
Now the last example of a fractal to consider is Cauchy's snowflake.
Now, instead of removing elements, this time we focus on infinite additions.
We start with the perimeter of an equilateral triangle.
And now, remove the middle line segments from these.
But instead of just me removing them, I'm going to throw in two more line segments of equal length there.
So I'm going to remove the middle ones.
And I'm going to throw in two more to form this kind of six-sided star shape at my first iteration.
And then I have all of these small line segments there.
I do the same procedure.
I remove the middle third of those line segments.
And I insert two more of equal length.
And here's my next iteration.
And my next iteration.
If I keep doing this, I get Cauchy's snowflake.
Now, this snowflake has an amazing property.
It has finite area, but it has infinite perimeter.
It turns out, what does this mean for us?
It means that you can buy a carpet to cover the area of this snowflake.
But it will take an infinite amount of fencing to block off the perimeter.
What a beautiful property.
It's a snowflake that has finite area, but infinite perimeter.
And it turns out this is mathematically easy to prove.
Thus far, we have tasted a bit of the world of fractals, the idea of self-similarity.
But as mathematicians, we want to measure this level of self-similarity.
We just don't want to say it exists.
We want to quantify it.
But how?
Well, one notion we have used is the idea of dimension.
This is how we started these series of lectures.
Dimension gives us a way of quantifying objects to say,
this object, the circle, is one-dimensional, but the sphere is two-dimensional.
It helped us at least to distinguish these objects in a meta level, in a bigger picture setting.
So what is the dimension of these objects?
Let's think about the Cantor set.
Now, the Cantor set is clearly not one-dimensional.
You don't get an entire line.
In fact, you don't have any intervals at all.
You just have a collection of points.
But it also, at the same time, doesn't feel zero-dimensional.
It's not like you just have three points.
You have an uncountable number of points.
That's a lot.
So it's somewhere between zero and one.
Similarly, the Serpinski triangle does not feel two-dimensioned.
It's not a flat object on the plane that is entirely taking up area.
But it's also not one-dimensional.
It's made up of a triangle, a two-dimensional thing that you removed.
It feels somewhere between a line and a plane.
As we consider these radically new objects,
a radically new concept of dimension itself is needed.
Now, something we defined in the very first few lectures
now needs to be redefined as we come to the end of these lectures.
Now, to redefine dimension for fractals,
we need to think about the world of self-similarity again.
And there are two concepts in this world that are extremely important to us.
The first concept is the number of copies.
How many copies of self-similar sets does our fractal yield?
And the second one is magnification.
What is the magnification level of each such set?
So let's see how these concepts appear in our work.
So here, for a canter set, look what happens.
If we look at the canter set at the end, at the final limit,
notice that I can zoom into a part of the canter set.
And I get a magnification level of three.
I need to zoom in three times as much,
because one piece of it is three times as big as the entire canter set.
But how many copies do I have when I zoom in?
I have this copy on the left, and I have a copy on the right.
So if I magnify my canter set three times,
I get these two copies at the end of the day
that form the canter set with a magnification level of three.
Let's look at the Sierpinski triangle.
Here, you can see that there are three copies
of the smaller Sierpinski triangle,
which can be magnified as big as the original.
So the number of copies of a Sierpinski triangle is three,
and the magnification level is two.
Because if you take one of those copies,
if I magnify it double, if I make it twice as big,
I get the entire Sierpinski triangle.
Similarly, if I take one piece of the canter set,
and I make it three times as big,
I get the entire canter set.
Now, what about Cauchy's snowflake?
Here, notice, if I just look at one edge just for detail,
then you see that there are four copies in that one edge.
Remember, we broke that edge, took the middle third,
and replaced it with two other objects?
So there are four objects now.
So the number of copies is four,
but the magnification level is just three,
because it's just a third of the piece that I had before.
And this level of self-similarity
appears in classical geometric objects as well.
It doesn't have to be just for fractal-like objects
that are complex that we've seen.
Take a look.
Look at the line segment.
I could take a line segment, break it into three pieces.
The number of copies I get of the big original line segment
is three, and the magnification level I need to do is three.
So the copies are three, magnification is three.
And look at the square.
I can break it into nine pieces.
I get nine copies of the original square,
but I need to magnify each of those squares
three times to get the original thing.
Copy is nine, magnification three.
A cube similarly has copies,
27 if I shatter it this way,
and the magnification level again is three.
Indeed, I could have picked any magnification level
for these objects.
It doesn't have to be three.
I just chose it for a level of consistency.
Now, we use these notions to create something
called the fractal dimension.
Now, fractal dimension of a set is defined as follows.
The logarithm of the copy
divided by the logarithm of the magnification.
It's that simple.
So let's check to see if this is worthy of the word dimension.
Look at the dimension of a line segment.
It's the logarithm of three copies
divided by the logarithm of three magnifications.
Log three over log three is one.
So the dimension of a line segment is one.
That's exactly right.
What about the square?
The logarithm of the copy is, well, it's three squared.
It's nine divided by the logarithm
of the magnification, which is three.
But the property of the log is if you have something squared,
you can move it to the front.
This is a mathematical property.
So this becomes two times log three over log three.
Well, this is two.
Dimension of the square is two. Perfect.
And the cube, it's log of 27 copies
divided by magnification three.
But 27 is just three cubed.
And I can move the three out in the front.
This becomes three times log three over log three,
which is just three. Perfect.
Now let's apply this idea to our objects
that we've been struggling with.
For the Sierpinski triangle,
I have logarithm of three copies
divided by logarithm of two magnification,
which is a dimension of 1.584.
It's a fractal dimension, a fractional dimension
between these worlds, between dimension one and two.
Caught to snowflake gives us log four divided by log three,
a dimension of 1.261. Beautiful.
And what about the Cantor set?
We want this to be not zero-dimensional
and not one-dimensional somewhere there.
Well, we had two copies and three magnification.
That's log two divided by log three,
which is 0.6309. Beautiful.
Logarithm handles the concept of scale perfectly.
We have covered numerous ideas today
which appear in nature.
These ideas are hard to capture
with classical notions of shape.
We study the chaotic nature of iterating functions,
which model ideas such as weather patterns,
population dynamics, and even the motion of Pluto.
And we also consider the natural appearances
of fractals in iterations,
which appear in numerous places in nature,
such as crystal, plants, and coastlines.
But I believe, most importantly,
we pushed our classical understanding of dimension
into the realm of fractal dimension.
And as we come near the end of our lectures,
we turn next, not to the intersection of mathematics
with the natural sciences, but with the arts.
Stay tuned.
