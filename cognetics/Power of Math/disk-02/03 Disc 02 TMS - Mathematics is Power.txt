So let's talk a bit about Calculus and what Calculus is trying to get at.
And remember, we're still trying to answer the question of how do people come up with the numbers that they want?
How do they compute functions?
I'll give you the big picture now, actually.
The big picture is we're going to use polynomials to approximate other functions.
And to explain how that happens, we have to bring in Calculus.
And it's interesting to see how Calculus does the things it does.
Calculus is, amongst other things, how we take derivatives of functions.
Now, I'm going to just tell you a little bit in general what a derivative is without getting into the specifics.
If you want the specifics, take a Calculus course.
So taking a derivative is different than the modern version of balancing out different stock options and risk factors.
As interesting as that might be and as rich as you might get.
In Calculus, the idea of a derivative is it gives us the instantaneous rate of change.
Calculus is a formalized way of trying to understand how things change over time.
This was a tremendous leap forward from the kinds of static math that had preceded it.
In Calculus, suddenly it was possible to describe well different kinds of motion and velocity.
Galileo did a nice job trying to describe motion of some simple things like falling balls and balls rolling down slopes and so forth.
But with the ideas of Calculus and finding the instantaneous velocity, this is how Newton managed to unlock planetary orbits
and how the solar system and the whole universe, things, moved and were attracted.
So how does Calculus tie in with polynomials in this context?
The derivatives of polynomials, the instantaneous rate of change of them, turn out to be remarkably easy to find.
Just in the same way that polynomials are easy to compute numbers for, when we consider them as functions,
they are also easy to compute the rate of change.
Now that might be nice to know and it's certainly a fun initial part of Calculus, but what does that have to do?
The tremendous insight is this.
What if we could approximate a function, exponential, logarithm, the sign, by a polynomial?
How could we do it? How could we know we are close to the real value? How close do we need to be?
So if we could take polynomials and use those to approximate these much more complicated functions
that we don't have too much idea how to actually compute numbers for, then all of a sudden the problem has shifted.
The problem has shifted from, wow, it would be very useful for me to know the exponential of 7.322
to how do I find a polynomial that approximates the exponential?
Once I have that polynomial, then I can just pop in 7.322, multiply it by itself a few times, add, divide,
do a few things like that and suddenly I have the number that will solve my real world problem.
If I could only approximate functions by polynomials, I could do that.
The second part of that is how good is the approximation?
Usually, being within one one-thousandth of whatever the real answer is more than sufficient for the real world,
the more high-tech it is that we're exploring, then the more important it is that we're maybe within one-tenth-thousandth
or one-hundred-thousandth, but there are very few things in our world that need to be that precise.
So what we need is an error bound, and we talked about error bounds a little bit before in the introductory lecture.
As long as we know that the answer we're getting is within some pre-specified amount, then we're happy with that answer.
So we will use a polynomial to approximate a function.
This is how calculators and computers work, at least in terms of the math they do when they're asked to solve math problems.
