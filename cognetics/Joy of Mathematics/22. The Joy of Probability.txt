And now it's time for another random lecture, this one on the joy of probability.
Now when you think of random events, we think of what could be more random than say flipping
a coin, heads or tails.
You just don't, you have no control over that.
And yet we can, by the end of this lecture anyway, have some ability to take advantage
of things that are generated randomly.
The easiest objects to understand are those that have equally likely outcomes.
For instance, the flipping of a coin, there are two possibilities, heads or tails.
And for most of us anyway, when you flip, you are just as likely to end up with a head
as you are a tail.
So if I say what's the probability that you flip a heads, well there are two possible
outcomes, one of which is heads, so the probability of flipping heads is one over two.
Likewise the probability of flipping a tails is one over two.
We say it has probability a half.
Every number gets a probability, it's some number between zero and one, and the closer
you are to zero, the more impossible it is, and the closer you are to one, the more certain
it is.
Here's another simple example.
Say you roll a six-sided die, a fair six-sided die.
You have six possible outcomes, and if your die is perfectly balanced, then each of the
numbers one, two, three, four, five, and six has an equal probability of occurring.
So the probability that you roll a one, for instance, is one out of six.
The probability that you roll a two is one out of six.
The probability that you roll any specific number is one out of six.
You can then ask more interesting questions like, well then what's the probability that
you would roll an even number?
Well, there are three even numbers that you could roll, a two, a four, or a six, and therefore
the probability of rolling an even number would be three out of six.
If I said what's the probability that you rolled something that was five or larger, well
then there are two numbers that are five or larger, so the probability would be two out
of six or a third.
Here's a more interesting example.
Suppose you flip a coin now three times, okay?
What are the equally likely outcomes?
I'm not going to say that you're just as likely to get three heads as you are to get
two heads or one heads.
I'm not going to say that, but there are eight equally likely outcomes.
There are eight different ways that you can flip a coin three times.
You can either see head, head, head, or head, head, tail, tail, head, tail, tail, tail,
tail, tail, tail, tail, tail, tail.
I think that's a tongue twister.
Each of those sequences is just as likely as the other.
You're just as likely to see head, head, head as you are to see head, head, tail.
Once you've flipped your two heads, the chance that the third flip is a head or a tail is
still a half.
There are eight possible outcomes, all of which have the same probability, but now when
we ask the question, well, then what's the probability of seeing three heads?
Of those eight equally likely outcomes, only one of them was three headed, and so there's
a one in eight chance of seeing head, head, head.
On the other hand, if I asked what's the probability of seeing two heads, then you would say, well,
there are three ways that you can see two heads, right?
You can go head, head, tail, or head, tail, head, or tail, head, head.
Those are the three of the eight possible ways of flipping your coin three times.
Three of them resulted in two heads, and therefore the probability of getting two heads out of
three would be three out of eight.
Likewise, the probability of seeing one head, well, that's the same as the probability of
seeing two tails, is also equal to three eighths, and the probability of seeing no heads, that's
the probability of seeing all tails, tail, tail, tail, just one way of doing that out
of eight.
By the way, you've heard the expression that two heads are better than one, but here you
see they have the same probability.
In general, if you flip a coin n times, then how many equally likely events do we have?
Well there are two possibilities for the first, two equally likely possibilities for the second,
two equally likely possibilities for the third, and so on, two equally likely possibilities
for the nth one.
Therefore there are two to the n different ways of flipping your coin n times.
How many of those ways result in exactly, let's say, k heads?
Well, among those n coin flips, choose k of them to be head.
The other ones will have to be tail, and so the number of ways of doing that, the number
of ways of picking k heads is n choose k.
So the probability of k heads would be n choose k divided by two to the n.
Let's do something a little more fun and I think a little bit unintuitive for most people.
Let's say you walk into a room and it has n people.
What's the probability that nobody in the room has the same birthday?
Well actually let me ask a more positive question.
What's the probability that at least two people in the room do have the same birthday?
So that's a question we were wondering.
You've got a gathering of, let's say, 23 people.
Would you believe that with 23 people there is at least a 50% chance that two people in
the room, in fact, have the same birthday?
Let's see why that's true.
We answer that by first saying, well let's answer the negative question.
What's the probability that they're all different?
What are the equally likely events here?
If I write down a list of birthdays, let's say I've got n people in the room and let's
just keep things simple and assume there are 365 days in each year, then if I ask everybody
for their birthday and I'll write the first birthday down, then the second birthday down,
then the third birthday down, then the nth birthday down, how many possible lists could
I create possibly?
Well there could be 365 choices for the first, 365 choices for the second, 365 choices for
the third, 365 choices for the last.
The total number of lists that are possible is 365 raised to the nth power.
Now the question we're interested in is what are the chances that all of those birthdays
are different?
So we have to ask how many of those lists result in all birthdays being different?
Well how many ways can I create a list where all the birthdays are different?
There'd be 365 choices for the first birthday, 364 choices for the second, 363 choices for
the third, and so on down to 366 minus n choices for the last one.
And so the probability that all of those birthdays are different would be that product, 365 times
364 times 363 and so on, divided by 365 to the n.
That's the probability that they're all different, therefore the probability that there's at
least one match among those people is one minus that fraction.
We can rewrite that fraction by the way, so the answer is one minus, something that looks
kind of pretty, 365 factorial in the top divided by 365 to the n times 365 minus n factorial
on the bottom.
To give some actual numbers to this, what are the chances say when you have 10 people
in a room, it turns out that the probability that there's a match there is 12%.
That may not sound too surprising, but with 20 people in the room, there's already a better
than 40% chance that two people have the same birthday.
With 23 people in the room, that's the point where you go from being less likely to more
likely to having a birthday match.
That is, there's a 50.7% probability that there is a birthday match.
With 30 people in the room, you have about a 70% chance, maybe 70, 71% chance of there
being a match of birthdays.
With 50 people in the room, it's 97% chance that two people will have the same birthday.
With 100 people in the room, you're talking 99.99996% chance that there is a match, two
people in the room that have the same birthday.
Let's look at another important issue when talking about problems and probability.
This is the notion of independence.
We say that two events, A and B, are independent if the occurrence of A does not affect the
probability that B occurs.
For example, if I flip a coin and I roll a die, the outcome of the coin flip has no influence
on the outcome of the roll of the die.
Or if I'm flipping a coin several times, what I receive on the first coin flip should have
no influence on what I would receive on the second coin flip or any of the subsequent
coin flips.
For independent events, we have a very simple probability rule, which is the probability
that A and B happen is equal to the probability that A happens times the probability that
B happens.
In other words, the probability of A and B is the probability of A times the probability
of B. For example, let's say I ask, what's the probability that when I flipped my coin
and rolled my die that I flipped a head and I rolled a three?
Well the probability I flipped the head is a half.
The probability that I rolled a three is one-sixth.
So the probability that both of them happen is their product, which is one-twelve.
What about, say, here's another question, what's the probability that I roll five-threes
in a row?
Well, the probability of the first three is one out of six.
The probability of the second three is one out of six.
The third three, the fourth three, the fifth three, all of those have probability one out
of six.
So since those are independent events, the probability that you roll five-threes in
a row is one-sixth raised to the fifth power.
How about this?
What if I said, all right, what's the probability that I roll a three, followed by a one, followed
by a four, followed by a one, followed by a five?
These are my digits of pi, right?
So what's the probability of seeing that specific sequence?
Well that's also one-sixth to the fifth, right?
There's a one-sixth chance of rolling the three, followed by a one-sixth chance of rolling
a one, one-sixth for the next, one-sixth for the next, one-sixth for the next.
Even though it looks more random than the one, one, one, one, one sequence, in fact both
of them have the same probability.
Now that's a different, it's a different question if I say, what's the probability
that I roll a one, two, three, four, and five in any order, okay?
I mean, if you want the probability of rolling a one, two, three, four, five in exactly that
order, that's also one-sixth to the fifth.
But if I'm allowing any order like five, four, three, two, one, or two, four, one, five,
three, each of those has a probability of one-sixth to the fifth.
How many ways can I arrange the numbers one through five?
Five factorial ways, 120 ways, so the probability of rolling one, two, three, four, five in
any order would be one-sixth to the fifth times five factorial.
Here's another question.
Suppose I roll a six-sided die 10 times.
What's the probability that exactly two of those times I rolled a three?
Okay?
Well, I know the chance of rolling a three on the first roll, for instance, is a sixth.
What's the probability that when I've rolled it 10 times, that two of them are threes?
Well, one way of doing it is I could roll a three, then another three, and then the
next eight numbers are not threes.
What's the probability of that?
What's the probability of three, followed by three, followed by no three, no three, no
three, no, no, no, no?
Well, it's one-sixth for the first three, one-sixth for the second three, and then the
next three, the next number, which is not a three, has probability five-sixths, and
then five-sixths, five-sixths, five-sixths, eight times.
So the probability of seeing that specific outcome of a three, followed by a three, followed
by eight things that aren't threes, would be one-sixth squared times five-sixths to
the eighth power.
But is that the only way that we can see exactly two threes?
No, there are lots of ways.
Those two threes didn't have to come in the first two.
Why there were ten-choose two ways of deciding where those two threes were going to occur,
right?
So there are ten-choose two sequences that have a probability of one-sixth squared times
five-sixths to the eighths.
Therefore the answer to the original question is ten-choose two times one-sixth squared
times five-sixths to the eighth, okay?
This is an example of what's called a binomial probability problem, one of the most important
problems that appear in probability.
So I'll say one little bit more on that.
In general, if we perform an experiment n times, okay, like flipping a coin, n times,
each of those experiments, let's say, has a probability of p.
If x is the number of successes, like the number of heads that we get, then we say that x is
a binomial random variable, binomial, meaning has two possibilities, right?
And each of those outcomes has a success probability p.
Then the probability that x is equal to k is equal to n-choose k times p to the k times
one minus p to the n minus k, okay?
That's an important formula in probability.
Here's another question.
It's not a binomial question, but a slightly different one.
Because I rolled a six-sided die repeatedly until I saw a three.
What's the probability that the first three appears on the tenth roll?
Well, in order for that to happen, we had to have no three, no three, no three, no three
for the first nine rolls followed by a three on the tenth roll.
The probability of that is five-sixths to the ninth times one-sixth.
That's actually called a geometric probability question.
Let's switch our attention from independent problems to problems where we have some kind
of dependence.
And there's a formula that's very important to memorize.
Some would say it's defined this way, the conditional probability formula that says
the probability of a given b is the probability of a and b divided by the probability of b.
Let's make sense out of this with some examples.
Let's say I roll a six-sided die and the outcome of that roll is x.
Find the probability that x is equal to six given that x is greater than or equal to four,
okay?
So if I said before, I'm going to roll a die.
What's the probability that I get a six?
You'd say one and six, yes, okay.
But now I told you that the outcome was greater than or equal to four.
So now you'd say, oh, well, if I know it's greater than or equal to four, then there
were three equally likely outcomes, a four, five, or six.
I would say the probability is now one-third, and you'd be right.
And the formula gives us that same conclusion.
It says the probability that x equals six given that x is greater than or equal to four
is the probability that x equals six and x is greater or equal to four, divided by the
probability that x is greater than or equal to four.
Now, the numerator says x is equal to six and x is greater than or equal to four.
Well, that's redundant.
I'll say it again, that's redundant, right?
Because the numerator should just say the probability that x equals six.
So we'll just write it that way.
The denominator stays probability x greater than or equal to 4.
OK, so the numerator, what's the probability that x equals 6?
It's 1 sixth.
What's the probability that x is greater than or equal to 4?
That's 3 out of 6.
And therefore, the probability is 1 sixth over 3 sixth,
which is 1 third, which is what we anticipated.
How about the probability that x is even,
given that x is greater than or equal to 4?
By the same idea, that's the probability
that x is even and x is greater than or equal to 4,
divided by the probability that x is greater than or equal to 4.
That's the probability that x is equal to 4 or 6,
divided by the probability that x is greater than or equal to 4.
That's 2 sixths divided by 3 sixths, which is 2 thirds.
And that makes sense as well.
Notice, by the way, that if a and b are independent events,
then the conditional probability formula
tells us that the probability of a happening, given that b
happens, is the probability that a and b
happen divided by the probability of b, so far nothing new.
But since a and b are independent,
the probability of a and b happening
is the probability of a times the probability of b
divided by the probability of b.
Notice the probability of b's cancel, leaving us
with the probability of a.
It says the probability of a given b
is equal to the probability of a.
In other words, given b, it didn't change our ideas
about the probability of a at all.
It stayed unchanged, and that makes
sense because a and b are independent.
Another important concept in probability
is called expected value.
Let's get the definition right out on the table.
The expected value of a random variable x,
which we denote by e of x, is its average value.
It's a weighted average of all the possible values
that x can take on.
Specifically, the expected value of x
can be calculated as the sum over all possible values
that x could be.
Let's say x could take on a value k,
and it's the sum of all possible k's times the probability
that x equals k.
For example, suppose x could take on three values, 0, 1,
or 2, with respective probabilities, 1 1⁄2, 1⁄3,
and 1⁄6.
Then the expected value of x is a weighted average
of the numbers 0, 1, and 2, where those weights are
the probabilities.
So the expected value of x would be 0 times
1⁄2 plus 1 times 1⁄3 plus 2 times 1⁄6,
which equals 2⁄3.
Expected values have some very expected properties.
For instance, we say that the expected value of a times x,
if a is a constant, is equal to a times the expected value of x.
You can just pull out that constant.
The expected value of x plus y is the expected value of x
plus the expected value of y.
In fact, it's true even if you add up n random variables.
The expected value of x1 plus x2 up through xn
is the expected value of x1 plus the expected value of x2
all the way up to the expected value of xn.
In other words, the expected value of the sum
is the sum of the expected values.
And that's true for any random variables,
whether they're independent or not.
If x and y are independent, you also
have another nice property.
The expected value of the product
is the product of the expected values.
That is, if x and y are independent,
the expected value of xy is equal to the expected value of x
times the expected value of y.
Now here's one example of this.
Let's take our binomial NP problem.
That is, I'm flipping a coin n times each with heads
probability p, and x is going to be the number of heads
that I get.
Now, what is the expected number of heads
that you're going to see when you perform an experiment
with probability p n times?
Then your intuition might tell you that, I mean,
for instance, if p was a half and I flip my coin n times,
how many of them are going to be heads?
You'd say about half of them, about n over 2 of them.
If the probability of heads was 2 thirds,
then you'd say, probably 2 thirds n, and you'd be right.
The expected value of x is equal to n times p.
Now there are two ways of doing this.
There's a hard way by using lots of algebra,
and I'll skip that derivation.
Or we can do it an easier way by looking
at each individual coin flip.
xi is equal to 1 if it's a heads and 0 if it's a tails.
In other words, xi is 1 with probability p,
and it's 0 with probability 1 minus p.
And then the total number of heads
is going to be x1 plus x2 plus x3 all the way up to xn.
In other words, we're just counting the ones.
If you were heads, raise your hand.
We're counting the number of hands that are raised.
Now what's the expected value of x sub i?
Like x1, for instance, the first flip.
It's either a 1.
It's a heads with probability p.
Or it's a 0.
It's not heads with probability 1 minus p.
And so the expected value of xi here
is 1 times p plus 0 times 1 minus p, which is p.
So the expected value of x, which
is the expected value of x1 plus the expected value of x2
all the way up to the expected value of xn
because the expected value of the sum
is the sum of the expected values,
is equal to p plus p plus p plus p n times, which is n times p.
Another concept that goes hand in hand with expected value
is the notion of variance, which is it's
fine to know that on average, I'm going to flip this coin.
If I flip this coin 100 times, on average,
I'm going to see 50 heads.
But what does on average mean?
Does it mean that you're always going to see 50 heads?
Or most of the time, it's between 40 and 60,
or between 20 and 80.
Give me some handle on it.
And what gives you that handle is the notion of variance.
So the expected value measures the average value of x.
The variance measures the spread of x.
Here's the formal definition.
If the expected value of x is equal to mu,
as the common Greek letter for expected value,
is mu as in mean, that's another term that's
used for expected value, then the variance of x
is defined as the expected value of x minus mu squared.
It's the expected squared distance from the mean.
That's what measures the spread.
On average, how far are you away from the mean?
We square it so that things stay positive.
It's the expected squared distance from the mean.
If you want to get something in the same units
as the original problem, we calculate
the square root of that quantity called
the standard deviation of x.
Here are some handy formulas for variance and standard
deviation.
The variance of x, though we defined it one way,
you'll find that in practice, it's
often easier to calculate it as the expected value
of x squared minus the expected value of x squared.
It almost sounds like I'm saying 0, right?
It's e of x squared minus e of x, pause, pause, pause,
squared.
So for example, in the problem we saw before,
if the probability of x equals 0 is 1⁄2
and the probability that x equals 1 is 1⁄3
and the probability that x equals 2 is 1⁄6,
then the expected value of x squared
is a weighted average of all the possible values of x squared,
which is 1⁄2 squared plus 1⁄3 times 1 squared
plus 1⁄6 times 2 squared, and that ends up being equal to 1.
The expected value of x, on the other hand,
we saw earlier that's equal to 2⁄3.
So the variance of x, which is e of x squared minus e of x
squared, is equal to 1 minus 2⁄3 squared,
which equals 5⁄9.
Here are some other nice properties of variance
that are worth knowing.
I'll list them here, but the only one
I'll mention that we'll use later is the last one that
says that if x1 through xn are independent random variables,
then the variance of the sum is the sum of the variances.
So in the situation where everything's nice and independent,
the variance of the sum is the sum of the variances.
Now, if there's only two things I want you to remember
about mean and variance, it's this.
Most random variables, most normal random variables,
have the probability that you are within one standard deviation
away from the mean is about 68%.
2⁄3 is easy to remember.
And that there is a 95% chance that you're
within two standard deviations of the mean.
So for most random variables, have this very, very
practical property, which leads us to the final theorem,
maybe the most important theorem in probability,
called the central limit theorem, that
says if you have a bunch of random variables,
independent random variables, and you add all those variables
up, then what you get is guaranteed
to have this normal property with the appropriate mean
and variance.
Let's go back to that coin flip, right?
If a single coin flip has a head's probability of 1⁄2,
the expected value of the number of heads in a single flip
is 1⁄2, and the variance of a single flip is 1⁄4,
then the expected value after 100 flips
is we expect to see 50 heads, on average,
and a variance of about 25, or a standard deviation of 5.
What that tells us is even though we have no way
to predict the outcome of a single flip,
we've got tremendous predictability
of what's going to happen after 100 flips.
Namely, after 100 flips of the coin,
you are going to have, on average, 50 heads,
and about 68% of the time, you're
going to be within 5 heads of 50,
and about 95% of the time, you're
going to be within 10 heads of 50.
That is, you're going to see between 40 heads and 60 heads.
And in our next lecture on games and gambling,
we'll see other ways that you can take advantage
of your knowledge of probability.
