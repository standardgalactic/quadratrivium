Iran, and North Korea as an axis of evil, and his particular concern was that those countries were in danger of developing nuclear weapons
with the risk that they might share them with terrorists. Well let's see what the reasoning is that would be underlying that example.
It would be something like this. When more countries develop weapons of mass destruction, the balance of power is threatened.
Now notice something carefully. Despite what we might think, this argument doesn't say that more countries developing weapons of mass destruction
causes the balance of power to be threatened. It might or it might not. It might be that there's something else that leads to developing of the weapons
and that also leads to destabilizing the balance of power. All we know is that given that more countries are developing weapons of mass destruction,
we can predict that the balance of power is threatened. What's the form of this argument? Well it's saying X is a sign of Y.
That's the underlying warrant. One thing can be taken as the sign of another, then X occurs or changes, therefore we can predict Y occurs or will change.
The underlying warrant is that something can be predicted from the occurrence of something else, so one thing is a sign of the other.
Now this relationship, the sign relationship is sometimes also called a correlation, which is simply a way of saying there's a predictable relationship between these two things.
It doesn't account for it, it just says that it's there. We have no idea why. We don't know whether one causes the other or not, but given one, we can predict the existence of the other.
That's the sign warrant. Now what things are used as signs? Well in theory a sign can be anything that stands for something else.
But let's talk about some commonly used signs. One is a statistical index. We think about something like the gross domestic product.
We generally take the GDP, the gross domestic product, and changes in it as a sign of the health of the economy.
So if we say the gross domestic product grew at an annual rate of 2.5%, we say that's a sign of a robust economy and economic health.
On the other hand, if the GDP basically didn't grow at all, say it grew by 0.2%, we say that's a sign of a stagnant economy.
And if the gross domestic product declines for two quarters in a row, that's a sign of a recession. So we're taking a statistical index as standing in for this abstraction called economic health.
That by the way is why this inference pattern, this warrant, is called sign. One thing stands for something else.
Sometimes we use physical observation as a kind of sign relationship. So we observe for example that parking lots at the mall are typically crowded on a day when there is a sale.
We drive by the mall and we see that the parking lots are full and so we infer that there is a sale going on in the major stores in the mall.
Or we'll sometimes use institutional regularities, things that by convention happen in a predictable pattern as a kind of sign relationship.
To use a very simple example, we know that the major department stores send out their catalogs at the beginning of the holiday shopping season.
And so if I receive in my mailbox a whole batch of catalogs in mid-October, I infer that the holiday shopping season is about to start because mailing out the catalog is a sign of the beginning of the shopping season.
The two things happen in a predictable relationship, in a recurrent pattern.
Well, we use all kinds of things as signs. Those are just three very obvious examples of things that we can claim stand for something else.
Aristotle distinguished between fallible signs and infallible signs.
An infallible sign is one that invariably, without the possibility of exception, would always stand for something else, so that given the existence of the sign, we could be absolutely sure of the existence of what it stood for.
Now if we had such a thing as an infallible sign, then the sign relationship would be a deductive relationship. The conclusion would follow certainly, and it would contain no new information.
But I submit that there are few, if any, infallible signs. Even things that we might think of as regularities that never vary, say the sun comes up in the morning.
When we think about it just a bit, those aren't infallible signs. There are cloudy days. There are parts of the world where depending on where we are in the calendar, the sun never comes up until very late in the day and stays up for a very short time.
There's such a thing as a solar eclipse, so we can't say infallibly that the sun comes up in the morning.
And by the way, yes, I know that that's a metaphorical way of speaking and that the earth revolves around the sun and not the other way around.
But because there are few, if any, infallible signs, the sign inference depends on probability, and it follows only with some measure of probability, so that we could be mistaken in asserting the sign inference.
Making the inference, therefore, is dependent upon a warrant that says there is a predictable relationship between the variables.
This enables us to predict a conclusion, but not with certainty. We could be wrong, so our reasoning process is normally inductive.
The prototype case of a sign relationship is a surface characteristic or property that is regarded as a sign of some deeper underlying essence.
We see this very clearly in one of the most famous speeches of the 20th century, Dr. Martin Luther King's I Have a Dream speech delivered at the March on Washington in 1963.
There's one section of the speech in which Dr. King refers to people who were asking supporters of civil rights, when will you be satisfied?
The implication being that the movement has gone far enough or is pushing too fast for some of its goals.
And Dr. King answers that question by identifying a number of signs of racial injustice.
He identifies several surface manifestations of underlying racism.
He says we will not be satisfied as long as African Americans are victims of police brutality.
He says we won't be satisfied as long as blacks are excluded from hotels and motels.
He says we won't be satisfied as long as geographic mobility is limited from a small ghetto to a large ghetto being the only way to go.
He says we won't be satisfied as long as voting rights are denied in Mississippi and as long as blacks in New York feel that they've got nothing for which to vote.
And then he alludes to the scriptural injunction and says we are not satisfied and we will not be satisfied until justice rolls down like waters and righteousness like a mighty stream.
Now we can take that section of the speech and understand it as a sign argument.
Each one of the problems that Dr. King identifies, police brutality, exclusion from hotels and so on, is a sign of racial injustice and lack of righteousness.
These things all occur, therefore American society lacks righteousness and racial justice.
And as long as that's so, we will not be satisfied.
What he's done is he's taken surface characteristics that he identifies as signs of a deeper underlying problem and says as long as those surface characteristics are there, the problem is there.
So we've seen what sign arguments are and we've talked a little bit about what kinds of things can serve as signs.
Now let's focus for a while on the purposes for which we use sign arguments.
Why do we use this particular warrant and inference pattern?
And I'm going to suggest at least three basic uses.
First, they are used to infer the unknown from the known.
If we think about it, there are lots of constructs that are unknowable abstractions such as intelligence, economic health, happiness.
Every one of those things is unobservable.
There's no way to know it or to see it directly.
And so we use other things as signs of those abstractions.
For example, we use statistical indexes and other measurements.
We use IQ test scores as a sign of intelligence.
We use the Dow Jones industrial average as a sign of the health of the economy and so on.
Likewise, we might infer a person's personality from his or her outward manifestations, his or her actions.
You want to know what kind of a person so and so is?
Well, you know that personality is an abstraction.
You really can't know the essential character of the person,
but you infer it by how the person behaves in a variety of situations.
So the acts are the external property that's taken as the sign of the internal essence, the character or personality of the individual.
Or a group and its members.
You want to know what the members of this organization are like?
Well, look at some individuals.
They believe this.
They do this.
They act in certain ways.
That's a sign of their membership in this particular organization.
Or an era and its events.
How do we think of the 1920s, for example, or the 1980s or the Cold War?
We think of those periods of time by their signs, by the events that happened during those periods of time.
Whether it's the 1980s being seen as a decade of greed or the Cold War as a period of mutual suspicion or the 1920s as the roaring 20s.
We form a judgment about this essence, about the era from the events that we take to be its signs.
So a property, some external characteristic, is seen as a sign of a deeper internal essence.
And that's what a sign relationship is about.
So one of the uses of a sign argument is to infer the unknown from the known.
A second use is to predict outcomes when it's not necessary to explain reasons for the outcomes.
So for example, we notice that people who bundle up in the winter avoid colds and stay healthy.
And we conclude that bundling up is a sign of staying healthy during the winter and not getting a cold.
We obviously want to stay healthy and avoid colds, and so we decide we will bundle up.
Now very important, we weren't able to say that bundling up is what causes us to stay healthy.
It might be.
It might be that we avoid germs that way, it might be that we avoid extreme body temperatures,
but it might be that there are other factors that explain why we avoid colds,
the state of our emotional health or mental health or who we come in contact with.
Nevertheless, if we can predict that bundling up is a sign of staying healthy and avoiding colds,
it will behoove us to bundle up.
We can't be sure that the practice causes the outcome, nor do we care,
as long as the relationship between the two is predictable.
And by the way, that happens far more often than we would think.
When we remember that this is a complex world, the chain of causality often can't be isolated or determined with precision,
and so what we want to know is, is it likely that a given practice and a given outcome will coexist?
We just have to be careful not to confuse sign with cause.
So for example, knowing that teaching company customers ask intelligent questions and that's a sign that they're intelligent people,
I want to become an intelligent person, I buy a course from the teaching company, now I'm a customer, therefore now I'm intelligent,
that's not likely to work.
So we have signs used to infer the unknown from the known and to predict when we don't need to explain.
The third way in which we use sign arguments very frequently is to rely on the judgment of expert authorities.
The assumption that we're making is first of all that a person's credentials are a sign of his or her expertise,
and then second, that his or her expertise is a sign of accuracy in the statement that the person has made.
And we do this of course because we can't know everything and so we need to rely on other people's judgment.
And so we assume credentials are a sign of expertise and expertise is a sign of accuracy and therefore we trust the judgment.
So for example, if we know that a person holds advanced degrees, holds a prominent and prestigious position,
we don't know the person at all perhaps, but we'll take those credentials as a sign that the person is probably an expert.
Having the advanced degrees and the other credentials becomes the sign of expertise.
And then the fact that the person's an expert will take as a sign that he or she probably knows what he or she is talking about in the case at hand.
So we'll take credentials as a sign of expertise and then expertise as a sign of accuracy.
Of course, we must be sure that the expert is speaking in his or her field of expertise, has a basis for making the statement,
and is not reflecting obvious bias or vested interest.
But what we've done here is to illustrate some of the common ways that we use sign arguments.
And I hope it's clear from this discussion and from the examples that I've provided that like the other patterns of warrant and inference that we've been examining,
sign arguments are very frequently employed.
We use them all the time and we use them typically when we want to make a statement about something that we can't see or observe directly
or something that we can't control or something that we don't have access to.
There's something in each case kind of just beyond our understanding, just beyond our ability to access.
And we infer it from something else that's a manifestation of it, that's an outward indication of it.
And we let that outward indication stand for whatever it is and so we conclude that that outward manifestation is a sign of the underlying reality.
Now you remember a few minutes ago, I suggested that just about all signs are fallible,
that if there was such a thing as an infallible sign, I couldn't really think of it.
And to say that signs are fallible is to say that we could be wrong.
It might be that X is generally a sign of Y and yet in the particular case we may not be able accurately to predict Y from the existence of X.
And so whenever we encounter a sign relationship with a fallible sign,
we want to ask a series of questions to test the strength of that relationship,
to determine whether we've probably got a good sign relationship or whether we don't.
And here are some of the things we would want to know.
For instance, we would want to know do the sign and the thing that it stands for generally appear together.
Because if they're just as likely to appear apart as together,
then it's much less likely the case that one is the sign of the other.
Let's consider an example.
In periods of prosperity, tax revenues go up.
And so we could say prosperity is a sign of increasing tax revenues.
But if there are periods of prosperity without corresponding increases in tax revenues,
or if there are increases in tax revenues during times that are not prosperous,
then we're far less confident in the statement that prosperity is a sign of increasing tax revenues.
When we talk about statistical correlations, by the way,
there's a way to show how strong the sign relationship is.
Correlations are typically measured from plus one to minus one.
So a plus one correlation would tell us just about all the time that we have one thing, we have the other.
A minus one correlation would say just about none of the time when we have one thing, do we have the other.
And a correlation near zero would be almost random.
There's no way to predict one from the other.
And so when we're talking about measurable correlations,
we can answer this question pretty precisely how likely are the sign and the thing that it stands for to occur together.
That's the first question we would want to ask.
A second question is, are there counter signs?
Are there signs that point the other way that would mitigate the strength of the sign relationship that we think we have?
Let's say, for example, that we regard increases or decreases in the stock market as a sign of economic health or economic sickness.
But we also regard housing starts as a sign of economic health or economic sickness.
So if there's new housing construction at an increasing rate, that's typically taken as a sign of a healthy economy.
Because it's saying people are betting on the future, they're buying houses, they're taking on long term mortgages.
Now what if there's a declining stock market and an increase in housing starts at the same time?
We have counter signs.
We have signs arguing the opposite relationships.
And so we ought to be cautious in saying, well, the stock market is dropping, therefore it's a weak economy.
Or housing starts are increasing, therefore it's a strong economy.
Because we've got in the same landscape both a sign and a counter sign.
So a second test question we would ask ourselves is, are there counter signs?
Third question, can a sign actually signify two or more different things, perhaps even opposite things?
For instance, we've said that declines in the stock market could be taken as a sign of a weakening economy, a downturn in the economy.
But we also know that sometimes the price of stocks goes up artificially as a result of excess speculation.
That's what probably happened, for example, in what we regard as the dot com bubble of the late 1990s and early 2000s.
To use an inexact way of describing it, sometimes this speculative bubble bursts.
And stock prices go down to what the economists believe is a more appropriate reflection of value.
It's what the market analysts call a market correction, in which stock prices drop to levels that are seen as more accurately reflecting the values of the companies.
And hence their position in the economy.
So we could have a declining stock market as a sign of a downturn in the economy.
But we also could have a decline in the stock market as a sign of the market correcting itself following a speculative bubble.
And so simply from the presence of the sign, the drop in the stock market, we can't be sure what it is that the sign stands for.
And because that kind of situation can easily present itself, we ask ourselves as the third test question, can the sign actually signify two or more different things, perhaps even opposite things?
Then a fourth question to ask.
Do we have a basis for thinking that the relationship between the two things is anything other than mere coincidence?
Now granted, a sign relationship can't account for the relationship.
It can't account for what causes what.
But do we think there's something there that goes beyond mere circumstance?
Let me give you my favorite example of an argument that reflects this concern.
In the history of American presidential politics, there is a phenomenon that has been called the zero factor.
Beginning with William Henry Harrison in 1840, for a long time, every president elected in a year ending in zero died in office.
Harrison, who was elected in 1840, Lincoln, who was elected in 1860, Garfield, who was elected in 1880, William McKinley, who was elected in 1900,
Warren G. Harding, who was elected in 1920, Franklin D. Roosevelt, elected in 1940, and John F. Kennedy, elected in 1960.
Ronald Reagan, who was elected in 1980, survived his two terms in office, but Reagan was the victim of an attempted assassination.
So there's a close correlation between being elected in a year ending in zero and dying in office.
Now, should we conclude from that, that Al Gore and George W. Bush were both crazy to have run for president in the year 2000?
Well, hopefully not, because on the face of it, there's nothing other than simple coincidence that seems to explain that relationship,
and so we would be less likely to think of it as a very strong sign.
And the final test, have we mistakenly regarded a sign relationship as a causal relationship?
Remember, I started out the lecture saying we've got to be very clear about the difference between the two.
So for example, if we say, we're going to have an arms race, and you say, how do you know that?
And I say, we're developing a national missile defense.
It's not immediately clear whether I've asserted a sign relationship or a causal relationship,
whether I'm saying that national missile defense causes an arms race, or simply that national missile defense can enable us to predict the occurrence of an arms race.
If it were a sign relationship, and yet I treated it as a causal relationship, I could be in for big trouble.
Just as you could be, if you took the statement that the teaching company customers are intelligent, and say, buying a course will automatically make me intelligent.
We need to keep straight the difference between a sign inference that asserts a relationship but doesn't account for it, and a causal relationship which does both.
So what we've seen is that sign warrants assert a predictable relationship.
Signs include statistical indexes, physical observation, institutional regularities.
Most signs are fallible, so the conclusion is inductive.
We use them for a variety of purposes, and we test them for their appropriateness and strength.
In the next lecture, we'll talk about causal relationships.
Lecture 16 Moving from Cause to Effect
Lecture 16 Moving from Cause to Effect
Hello again, and welcome back.
In the last lecture, we talked about sign inferences, and I warned you a couple of times that they're often confused with the inference pattern that we'll be talking about now.
Remember that we said that sign inferences assert that there is a predictable relationship between things based on the warrant.
But they don't explain that relationship, they don't account for it.
Causal inferences and warrants, the topic of this lecture, are warrants which both predict and explain a relationship between variables.
And before we get into our analysis of these arguments, let me simply observe that discussion about public matters frequently involves causal inferences and warrants.
Let's take some obvious examples.
Many people argued that the failure of the democracies during the late 1930s to resist Hitler's early aggressive moves is what caused World War II.
Now, in making that argument, the people who believe that are saying, World War II did not happen by accident.
There was an influence that led to World War II coming about.
And what that influence was, was that the democracies of the West didn't stand up to Hitler when they could have.
Second example, during the 1960s, there were a number of political liberals who argued that frustration with despair in the inner cities caused race riots.
While conservatives argued that social permissiveness and an attitude of permissiveness is what caused the riots.
Now, here what we've got are competing attempts to explain a phenomenon, to explain what influenced it, what led to it, and obviously which one we pick of these competing explanations will make a difference to the policy we recommend as to what ought to be done about it.
Third example, during the 1980s, many conservatives argued that the U.S. defense buildup under President Reagan caused the collapse of the Soviet Union.
While many political liberals were more likely to credit Mikhail Gorbachev for facing up to the economic weakness of the communist system and saying that caused the collapse of the Soviet Union.
Again, we've got two competing accounts, but what each of them is trying to do is to identify a factor which not only enabled us to predict something else, but explain it by showing what influenced what, what produced what kind of effect on what.
And final example, President George W. Bush and many others have argued that the retirement of baby boomers will cause the collapse of the social security system unless the system is changed.
The argument here again is if the social security system falls apart, it won't be by accident, it won't be a random occurrence, it will be the result of a phenomenon, namely the retirement of the baby boomers.
Well now what's real clear I hope in all of these examples is that causal inferences both identify and explain relationships. The inference is that doing something will lead to something else.
And by the way, we could argue the relationship either way. We could start with the alleged cause and say it's going to produce this effect, or we could start with the alleged effect and explain it as the result of the alleged cause.
Now claims that employ causal warrants and inferences based on them would follow from the evidence certainly and the argument would be deductive if and only if all other possible influences could be controlled for and eliminated.
And that's about as likely to happen as we are to get an infallible sign, not very likely. Hence the causal argument relies on the warrant that one phenomenon has influence on another.
And influence cannot be observed but is only inferred and our inference could be wrong, which means that the conclusion goes beyond the evidence, the conclusion follows only with a certain degree of probability and it is therefore inductive.
So just as we've seen with example, with analogy and with sign, the typical use of an argument employing a causal warrant and inference is inductive in nature.
Now one of the difficulties that we experience when we talk about causality is that the very concept of causality is ambiguous. It's been used by different philosophers and theorists to mean different things.
And let me just give you a flavor of those differences by suggesting some of the meanings that are associated with causality. Some people have suggested that cause means sufficient condition.
You may remember when you studied mathematics a discussion of necessary conditions and sufficient conditions. A condition is sufficient if, given that condition, you're assured of the presence of the effect.
It's all you need for the effect to occur. So for instance, a meteorologist might say that the combination of a high pressure front and high humidity is a sufficient condition for rainstorms.
But if you get those two things together, you can be sure that you will have rainstorms following because those things are the sufficient conditions. It's all you need to have rain.
And so for some philosophers, causality means sufficient condition. Other philosophers say no, sufficient condition may be a strong sign, but it's really not what we're talking about when we talk about causality.
There are other philosophers who identify causality as meaning human action or intervention into the normal order of things.
For these philosophers, the recurrent processes of nature are not what we mean when we talk about cause and effect. We don't ask what causes rain, but we do ask what causes war, because war is something that's produced by human action, by our intervention into the natural world.
And this usage of cause implies that only things that reflect choices and hence only things that human beings can do are causes. So on this reading, cause means human action or intervention into the natural order.
Yet other philosophers, some of the philosophers of law have said causality refers only to things that are abnormal, things that are normal, regular, predictable, recurrent.
We don't talk about as being cause and effect. When we use causality, we're talking about abnormal events. And so to use the old cliche, when the dog bites the man, we don't talk about what caused it, but when the man bites the dog, we do, because one is a regular, predictable, normal occurrence, and the other is not.
Well, there are other meanings as well. And my point in mentioning this is not to try to resolve this dispute or to settle the question of what does causality mean, but simply to indicate that one of the difficulties that we encounter in talking about causal arguments is that philosophers don't even mean the same thing, necessarily, by the word cause.
Which meaning is most appropriate, in fact, may depend on the use to which the causal argument is put, although here again in some cases different meanings are equally serviceable.
But at any rate, let me take a few moments and talk about some of the ways that we use causal arguments, arguments based on causal warrants and inferences.
We use them sometimes to make what are called causal generalizations. These are sometimes called covering laws. So for example, we say that depletion of the ozone layer results in an increase in ultraviolet rays.
Well, there what we've suggested is a kind of natural law explanation. If the ozone layer thins, then more of the sun's ultraviolet rays get through, and that will produce an increased incidence of cancer.
It's a natural law kind of explanation for a general phenomenon that could take place, and that we're probably likely to rely on causality as sufficient condition.
Sometimes, however, we use causality for the purpose of explaining or predicting events. So we say mobilizing each political party's base will increase turnout in national elections, as it did in the election of 2004.
Well, now what we've done is we've said here is an explanation of what's taking place. If you mobilize the base, then you will increase the turnout.
We could say that's human intervention because it's human beings that mobilize the base, or we could say that's sufficient condition because we're identifying a phenomenon that if you do it will be enough to bring about the effect.
Or we might say guilt leads people to try to purge their guilt. And so if you make them feel guilty about various conditions in the world, they'll be likely to give more money to charity if the charity is dedicated to doing something about those world conditions.
It's another explanatory hypothesis that could be used both as a prediction or as a retrospective explanation. So those are a couple of the uses of causal arguments to form natural law, covering law, generalizations, and to have explanatory hypotheses.
Often we use causal arguments to relate means to ends. Something is a means to the achievement of some other end. So to keep warm during the winter, dress in layers.
Well, that's a very common use of causal arguments. If you want to do X, then you should do Y because Y is a means to accomplish X. And again, you could think of that as human action. You could think of it as sufficient condition.
There's a specific application of relating means to ends that is called the pragmatic argument. And what the pragmatic argument says is we choose between values or we choose between actions based on their consequences.
And if the consequences of one are better than the consequences of the other, then that's what we choose. So what we do is we almost set up a parallel structure where we say this value or action will lead to these consequences.
This other value or action will lead to different consequences. I prefer the first set of consequences over the second. Therefore, I'll take the first action rather than the second action.
So we use the pragmatic argument as a way to choose between values or to choose between actions based on the consequences that we think will follow from them. So each choice becomes a means to a different end.
We decide which end we like better, and then on that basis we make our choice of consequences. So for example, in early 2005, when the president of Harvard University made some speculative comments that were interpreted as demeaning to women, and there was a desire to repair the damage, one way to do it was to appoint a commission to investigate the higher end.
And that would have certain consequences. It would focus attention on the problems of women in the sciences and focus attention on the importance of hiring. And that is the choice that the president of Harvard University made, but a different choice might have taken some other action.
Might have been to stonewall the reporters or stonewall the faculty questioners, for example, and that would have certain consequences. It would prevent the president from needing to apologize or to appear weak, but it would also make the president seem further removed from his critics and from the problems.
And so he concluded one set of consequences was better than the other, and so he chose accordingly what action to take.
Sometimes we use causal arguments to explain paradoxes. So for example, our so-called paperless society, since the advent of computers, has actually served to produce more paper, as we see the need to print out more and more things from the computer.
How can it be that a paperless society generates more paper? Well, that's a paradox that needs to be explained, and when we explain paradoxes, we rely on the concept of cause as abnormality.
