Not every dilemma really considers all the alternatives.
Reasoning from hypothesis although it looks like a conditional syllogism in fact is something different.
And arguments that look like they're mathematical computations are valid if we don't forget that the assignment of numerical values is somewhat arbitrary and that we're essentially quantifying the unquantifiable.
So with respect to each of the inference patterns we've examined, accumulated experience with the pattern suggests the validity tests that we want to meet in order to avoid fallacious arguments.
We actually discussed these tests in detail when we considered the inference patterns and what I've done now is just quickly to review them.
But some fallacies are broader than individual patterns of inference.
So a second general category of fallacies, errors in informal reasoning includes those that are deficiencies of clarity.
Deficiencies of clarity result from the inexactness of language.
And of course that's a condition that's particular to informal reasoning.
With formal logic, language really doesn't matter.
Once we cast arguments into everyday ordinary language though, we can run into problems such as equivocation.
Equivocation is the use of the same word to convey different meanings within the same argument so that the meaning of the term shifts as the argument proceeds.
Consider this example.
Anyone who tries to violate a law should be punished even if the attempt fails.
People who fly are trying to violate the law of gravity.
Therefore, they should be punished.
Simple example.
And we can quickly see what's wrong.
The meaning of the word law changes during the course of the argument.
In the first case, it's used to refer to a legal statute.
In the second case, it's used to refer to a natural law, principle of the law of nature.
And so we don't accept the conclusion that people who fly ought to be punished.
In fact, we'd probably laugh at it.
That's equivocation.
Closely related, but not quite the same thing, is ambiguity.
Ambiguity is a situation where a word or phrase has more than one meaning.
And it's not so much that the meaning shifts in the argument as that we can't be sure which of the different meanings is the intended one for the argument.
Let's consider an example.
We shouldn't hire Peter because our company has a policy against hiring drug users and I saw Peter take aspirin.
Now, obviously, in this case, the word drug has more than one possible meaning.
It can be used in the context of prescription drugs, can be used in the context of over-the-counter drugs,
or it can be used in the context of illegal substances.
And it's not clear which meaning is intended.
Now, we could guess in such a simple example that the policy against hiring drug users is not intended to refer to prescription drugs or over-the-counter drugs,
but it's not always so obvious which meaning is intended.
Here's another example.
Smith and Jones have a conversation and Smith says,
the first thing you need to know if you want to become a musician is the scale.
Jones says, what's the scale?
And Smith answers, it all depends on the union.
In this town, it's about $8 an hour.
Now, when Smith first talks and says you've got to know the scale if you want to become a musician,
we might imagine that the term scale is used to refer to the musical scale.
But apparently not.
There's a different meaning intended, so the term scale is ambiguous.
In recent history, probably the most famous example of an ambiguous term,
which most of us probably didn't think was ambiguous,
occurred when President Clinton said it all depends on what the meaning of is is,
suggesting that even such a simple term as that can have multiple meanings,
and it's not always clear which one is meant.
Similar to ambiguity is a third clarity problem, amphibaly,
which results when we can't be sure which of a set of possible meanings of a phrase is the intended meaning.
So, ambiguity refers to terms amphibaly to phrases.
Consider the statement, the cardinals are in town.
Does this phrase refer to birds, to a baseball team,
or to officials of the Roman Catholic Church?
It's not clear.
Another problem with clarity is vagueness.
A term is vague if there is no way to pin down what is meant.
My favorite example of a vague term is the term middle age.
At one time, I thought this term meant anybody over the age of 30.
Amazingly, as I've become older, the term middle age has changed as far as what it means to me.
I now think of it as probably older than 80, 90, 95.
But the point is, it's a term that it's almost inherently impossible to render precise.
Now, there are two other clarity problems that are somewhat related.
And they are the problem of the heap and the problem of the slippery slope.
The problem of the heap can be illustrated by a simple example.
You have a little pile of sand.
You add another grain of sand to it, and you still have a little pile.
You add another grain, still have a little pile, and so on.
So the pile never changes into a big one.
Or to use another example, those of you who are watching on video can see the color of my beard.
You might be generous and say it's salt and pepper, or you might say it's gray or even white.
But I grew this beard over 30 years ago, and it was black.
One day I found a single gray hair, but I still said my beard was black.
Found another gray hair, still said my beard was black, and so on.
So my beard never changed from black to white.
That's the fallacy of the heap.
During the Vietnam War, the argument was that the addition of more American troops did not fundamentally change the war.
We'd put in 5,000 more and 10,000 more and 10,000 more, and our objectives would be basically the same.
Except somewhere along the way, we went from American advisors assisting the Vietnamese to an American war with half a million troops.
So the clarity problem with the heap is not knowing precisely when a difference in degree becomes a difference in kind.
The problem of the slippery slope is the reverse. Any difference becomes a difference in kind.
Once you get started on something, there's no stopping. You'll travel down a slippery slope.
So consider this example.
The United States should oppose military aggression wherever it happens, no matter how minor,
because letting any aggression go unpunished will just encourage even more and more horrible forms of aggression
and will eventually lead to war throughout the world.
You see what's being said. Any small case of aggression will set us on an unstoppable slippery slope that will lead to world war.
And of course, the fallacy in the slippery slope is the assumption that once something gets started,
there's no way to reverse course or no way to stop, so every difference in degree turns into a difference in kind.
So we have equivocation, ambiguity, amphiboly, vagueness, heaps, slippery slopes.
These are all deficiencies in argument that could render an argument fallacious or unreasonable because of clarity.
And in order to have a valid argument, these are fallacies we want to avoid.
So we've looked now at deficiencies particular to individual inferences and deficiencies of clarity.
A third category of fallacies are those that are the result of vacuity.
These result from the failure to provide necessary proofs, leaving holes or empty spaces in the argument.
Again, we can consider a number of examples of this kind of problem.
I want to talk first about circular reasoning. This is a great name for a fallacy because you can visualize exactly what's going on.
The reasoning proceeds in a circle. The claim, instead of following from the evidence, just restates the evidence in slightly different language.
And so you really haven't made any inference at all. You haven't moved beyond the statement that you started out with.
Consider this example. Freedom of speech is for the common good because the unrestrained expression of opinions is in the best interest of all concerned.
Now what does that argument really say?
It says freedom of speech is for the common good because freedom of speech is for the common good.
The claim simply restates the evidence. It reasons in a circle. The evidence proves the claim, the claim proves the evidence, and we don't really advance our understanding at all.
Or consider this case. When B applies for a job from A, A says, how can we know you are trustworthy?
And B says, Mr. Davidson will write me a recommendation. A says, why should we trust him? B, I assure you that he is honest.
Now here again we've got a clear case of reasoning in a circle. The point of the conversation is to establish that B is trustworthy.
But the conclusion when B says, I assure you that Davidson is honest depends upon the fact that B is trustworthy, the very thing that we're trying to prove.
It proceeds in a circle.
Or again one more example. This is a characteristic form of argument in some religious circles.
The Bible is the inerrant word of God because God speaks only the truth.
How do we know? Repeatedly in the Bible God tells us that the Bible consists of his words.
Now again, don't misunderstand me. I'm not commenting about whether or not the Bible is the literal word of God.
But this proof, this means of proving that the Bible is the literal word of God works in a circle.
Because it depends upon God saying that the Bible is God's own word. So it repeats what it begins with in the evidence.
So that's circular reasoning and that's a fairly common problem of vacuity.
Now somewhat related but slightly different is the problem of begging the question.
This occurs when a claim is really dependent on other claims that need to be established but aren't.
They're implicitly assumed when they shouldn't be assumed.
The classic case of begging the question is, have you stopped beating your wife?
Now there's no way you can answer that question.
If you answer yes, well you've just admitted that you used to beat your wife.
And if you answer no, you've admitted you're still doing it.
The question that is begged is that you ever were beating your wife in the first place.
That really needs to be proved.
Consider an example.
An opponent of capital punishment says, state-sponsored murder only doubles the evil of the original crime.
Now I have no doubt that the opponent of capital punishment believes that.
But what is begged in that statement is the assumption that capital punishment is state-sponsored murder.
That's something of course that the advocate ought to prove.
So we have circular reasoning, we have begging the question.
Another kind of problem that's associated with vacuity is ignoring the question.
This is the result of digression or focusing on a matter that's extraneous to the question at hand.
And when this kind of extraneous matter is introduced it's sometimes called a red herring.
This is a metaphor that goes back a couple hundred years from Fox Hunts in which a red herring would be drawn across the trail to lure the dogs away and have the dogs not smell the fox.
A red herring is introduced in a situation like this.
Imagine an argument in which you say, the growing federal budget deficit curtailes our ability to meet important priorities.
I respond, a tax cut gives people more control over their own money.
That's a red herring.
We're not talking about whether people ought to have more control over their own money.
The question at issue is, what's the effect of the increasing deficit on our ability to meet important priorities?
And to say, well a tax cut gives people more control over their own money is to introduce an irrelevant element that ignores the question at hand.
That's the key point of this problem, it ignores the question that's at hand.
Then there's what may seem like a catch-all fallacy, the non-sequiture, which means it does not follow.
On the face of it, there's no connection between the claim and the evidence.
So what's vacuous here is that there's no inference really going on.
Of course, X wouldn't be a good public servant.
He has a beard and can't carry a tune.
Hello?
On the face of it, there's no connection at all between whether or not X has a beard or can't carry a tune and his ability to be a good public servant.
Sometimes we talk about attacking a straw man.
I apologize for the masculine reference, but that's how the fallacy has been named.
This is another vacuity problem.
A straw man has been attacked when one's argument responds to a claim that has not been made and is not in dispute,
rather than to the claim that has been made that's the focus of the dispute.
So imagine on a proposal to outlaw the burning of the flag, someone says,
I oppose flag burning. I am a patriotic American.
And the response might be, the claim I'm a patriotic American is a straw man,
because nobody's ever questioned your patriotism.
So the straw man consists of answering what hasn't been attacked, rather than what has.
And then a final example of vacuity problems is the self-sealing argument that permits no possible testing,
because it can encompass opposite results.
During the Cold War, our country believed that we needed to be firm and strong.
And if things turned out for us, we said, great, that proves that being firm and strong works.
And if things didn't turn out for us, we said, that only proves we weren't firm and strong enough.
Whether foreign policy works for us or against us, it bears out the assumption that firmness works.
There's no way to challenge whether that's the right foreign policy.
These then are problems of vacuity that we want to avoid in order for our arguments to be valid or reasonable.
One more category of fallacies, deficiencies of relevance.
We'll begin there in the next lecture.
Lecture 20, Validity and Fallacies, Part 2
Welcome once again.
Last time we introduced the concepts of validity and fallacies,
explaining that in order to know whether an argument is good, we must know if it's valid.
We considered how validity translates from formal to informal argument,
and then we considered three categories of validity tests,
those related to specific warrant or inference patterns,
those involving deficiencies of clarity, and those involving vacuity.
There is one more category of validity tests to consider, deficiencies in relevance.
And these result from introducing into the discussion some factor that has nothing to do with the relationship between evidence and claim or inference and warrant.
And again, we can talk about several examples of these.
One of the most common has the name ad hominem against the person.
Ad hominem arguments are usually defined as those in which an attack on a person is substituted for a response to an argument.
So let's imagine that you and I are having a discussion about whether having a tax cut is a good idea.
And I say that I'm opposed to it, I don't think it's appropriate at this time to have a tax cut.
And you reply, look, the main opposition to tax cuts always comes from people like you who depend on government programs that are funded by taxes,
so we should pay no attention to what you have to say.
You see what this response has done?
Instead of responding to my claim that we ought not to have a tax cut, it has substituted a personal attack against me.
Well, you know we ought not to take seriously what you say because you depend on the government programs.
It's an error of relevance.
Whether I depend on the government programs or not on the face of it has nothing to do with whether a tax cut is a good idea.
That's the argument ad hominem.
Another kind of relevance problem is the appeal to authority.
Particularly if the authority is outside his or her area of expertise or has no basis for reaching the conclusions that he or she offers.
Remember we said that a valid use of authority comes when expertise is taken to be a sign of accuracy.
But when you have prominent entertainment figures, sports figures or politicians endorsing commercial products saying this product is good and you can take it on my say so,
we usually have fallacious arguments, usually incorrect appeals to authority.
The authority of the sports figure or the politician has nothing to do with his or her use of the product that's being endorsed or his or her ability to recommend that product to you.
Another kind of relevance problem is the appeal to popularity.
This is sometimes called the bandwagon effect.
Something or other is a good thing or a bad thing because everybody's doing it.
And so popularity is substituted for the rightness of the argument.
This is a very familiar argument pattern to anyone who is in a home with teenagers.
Once the teenager says, well all of my friends are allowed to go to the mall or everybody's allowed to stay out late, why can't I?
And of course the fact that everybody does it doesn't make it a good thing.
And so the response to this argument often takes the form of what I will label the dad's refutation.
And that is, if all of your friends were going to jump in the lake, would you go do it too?
This is a rhetorical question that serves to make the point that popularity by itself is not a warrant.
It doesn't make it right.
Yet another relevance problem is the appeal to tradition.
Now an appeal to tradition like any of these appeals is not always wrong,
but an appeal to tradition can be used to block consideration of change without engaging the argument.
So let's imagine a situation in which a new business practice is being proposed.
If a company changes its accounting method or the way it keeps its inventory or the way it does this or that,
it can maximize its profit or minimize its cost or improve employee productivity.
And the response is, but we've always done it this way, period.
End of discussion, we've always done it this way.
This is an appeal to tradition that's inappropriate because it's used not to recognize the culture of the business or the organization,
but to block further consideration.
It's irrelevant, really, to the question of whether this change in the business practice would produce the appeals that are claimed for it.
Appeals to ignorance are another kind of relevance problem.
Now this is not an accusation that somebody is ignorant.
Rather, it's the assumption that a claim must be true because it can't be shown to be false,
or it must be false because it can't be shown to be true.
Ignorance becomes the premise in the argument.
It's used as a reason to do or not to do something, to believe or not to believe something.
President Reagan, expressing his opposition to abortion, once said,
you know it's interesting that all the people who favor abortion have already been born.
And of course, what President Reagan is saying is because we don't know what the fetus would think about abortion,
we ought to conclude that abortion is wrong.
Or here's another example.
This one characterizes the discourse of some organizations on the political fringe.
We can't prove that there isn't a plot by the United Nations to take over the U.S. by putting chemicals in our drinking water.
Therefore, we ought to conclude that there is.
Because we can't disprove some sort of fanciful plot, we ought to conclude that it's a real and serious threat.
Yet another example of a relevance problem with argument is an argument that appeals to inappropriate emotion.
It can prevent a response because of expressions of anger or fear or something else that's just irrelevant to the discussion.
This is characterized stereotype, for example, in the line from the movie,
I'm mad as hell and I'm not going to take it anymore.
And one's anger becomes a way to stop further consideration of the argument.
Now let me be very clear.
I'm not suggesting that every appeal to emotion is inappropriate, far from it.
There are arguments that are quite legitimately intended to reason to a conclusion that we ought to be angry.
We ought to be upset.
We ought to be outraged.
We ought to be shameful or whatever.
These are perfectly legitimate arguments.
The fallacy in the argument comes about when the appeal is inappropriately to emotion in such a way that the emotion,
instead of furthering the discussion, blocks consideration of what it is that's being talked about.
And my final example in this category, threats.
Threats coerce the conclusion, not because of the power of the argument,
but in order to avoid force or other kinds of serious consequences.
Employers sometimes have been accused of saying to their workers,
if you don't contribute to candidate X, I will fire you.
A worker who then contributes to candidate X cannot be assumed to have done so on the basis of the strength of the argument,
but rather on the irrelevant factor to the argument, namely the threat.
So, all of these relevance problems, the ad hominem argument, the appeal to authority, appeal to popularity, appeal to tradition,
appeal to ignorance, appeal to inappropriate emotion, and the threat,
introduce into the discussion some factor that is really not relevant to the relationship between the evidence and the claim.
Not relevant to whether the inference is adequately warranted or not.
It deflects and distorts the argument.
Now, between the last lecture and the first part of this one, we have covered quite a few fallacies under these four general headings.
The important thing, however, is not simply to put labels on arguments and say,
here's a case of argument ad hominem, here's a case of appeal to tradition.
The important thing is the ability to explain how the argument goes astray and why it is not valid.
