Psychologists have been moving their work from the University Laboratory to the world
of advertising and political campaigns since the early 20th century.
If opinions could be manipulated and consent and aesthetic preference could be engineered,
then there was money to be made and power to be gained.
If the psychologist possessed not only an understanding of how the mind worked, but
tools that could shape its working in desirable fashions, then they could be remunerated handsomely
for it.
This may have struck some as unseemly, but surely it wasn't harmful.
In the first half of the 20th century, psychology had the luxury of debating whether a subconscious
mind existed and whether scientific methodology required limiting the field of study of stimulus
and response.
But after the horrors of World War II, psychology changed.
Suddenly there was a pressing question about human beings.
How could people have done this?
The specter of the Holocaust raised deep and troubling questions about the human mind in
its relation to authority.
The field of social psychology began in earnest to take these questions very seriously and
as a result altered our understanding of ourselves and our relation to the world.
The reaction to Nazi atrocities in the scientific world is shaped by what are perhaps the three
most famous psychological experiments.
Stanley Milgram's obedience study, Solomon Asch's groupthink study, and Philip Zimbardo's
Stanford prison study.
Taken together, they stand as a significant challenge to the enlightenment picture of
humans as rational beings and left us with serious concerns about ourselves.
The first of these occurred in 1951 when the Polish psychologist Solomon Asch, working
in Swarthmore College, tested the ability of people to act independently.
Asch's experiment followed a long line of work in the 20th century on conformity.
Going back to the early 1900s, researchers like Edward Thorndike, the president of the
American Psychological Association, noted that all one had to do is to inform people
that supposed experts, or most of the people, preferred something different from them to
get them to later change their opinion.
Solomon asked a first time by one assistant, test subjects would give opinions and preferences.
Later, after a second assistant, whom the subject did not know was being fed information
from the first interview, again asked about the same opinions and preferences, but this
time prefaced the question with false information that some important figure, or most of his
or her peers, preferred something different.
Many of the subjects reported different preferences to the second assistant, bringing their choice
in line with the purported authority or the majority.
Thorndike thought this meant that he was able to shape preferences, or could it be that
he was just able to shape behavior?
If you're in marketing, or if you're a behaviorist who doesn't buy into the concept of a mind,
then who cares?
You got what you wanted, predictable and controllable human action.
But Ash wondered what was really going on.
So he created a similar setup.
Test subjects would enter a room and be seated at a table with seven other supposed test
subjects.
Really they were actors playing the role of test subjects, while really being Confederates
working with the researcher.
A researcher walked in and informed everyone that he was studying perception, and asked
that each of the participants look at the two charts he had placed in the front of the
room.
One of the charts had a single line on it.
The second chart had three lines labeled one, two and three.
One of the lines on the second chart was the same height as the line on the first chart,
and it was the job of the test subjects to say which one it was.
Now it needs to be stressed, this was not Fechner's barely noticeable difference here.
It was plainly obvious what the correct answer was in all cases.
They would go around the table and the real test subject was seated so that he would be
the last person asked.
Now for the first three go rounds, the Confederates all gave the correct answer and the test subject
would follow.
But on the fourth, the Confederates would all give the same wrong answer.
And now the fun began.
There are 18 sets of lines and of those, the Confederates would get 6 correct and 12 wrong
by design.
The question is, how often the test subject would go along with the majority in saying
something he knew to be false?
The answer was that 75 percent, 3 out of 4 answered with the faulty majority at least
some of the time.
Asks showed that once people started conforming, they were much more likely to continue.
When people began by setting themselves out as independent, they too were more likely
to remain independent.
The test subjects were interviewed after the experiment and reported some interesting
reactions.
Of those who always answered correctly, some were simply confident in their ability to
complete this simplistic task.
But others thought they were factually wrong in their answers even though the right answer
was obvious.
Well, I mean if everyone sees it differently, then they must be right since this is so simple.
They gave what they thought to be the wrong answer out of concern for the researcher's
data.
They thought that science was important and their misperceiving might be important.
And it was, as Ash puts it, their obligation to call the play as they saw it.
Now of those who answered with the majority, right, who answered falsely, there were some
who, like this second group of correct answerers, became quickly convinced that they were wrong,
that the majority was right, and that it was important to be right, either because they
didn't want the data spoiled or because they just didn't want to stick out.
Of those who answered wrong, many believed the other people at the table were sheep just
following along because everyone else was following prey to some sort of optical illusion
type effect.
But when it came time for them to stand up, they too followed along.
And then there was the other group who answered incorrectly.
In Ash's words, more disquieting were the reactions of the subjects who construed their
differences from the majority as a sign of some general deficiency in themselves, which
at all costs they must hide.
From this basis, they desperately tried to merge with the majority, not realizing the
longer-range consequences to themselves.
Universally, everyone who participated in the test said that independence was preferable
to conformity, yet most conformed.
That is to say, they acted not only counter to what they knew to be false, but also counter
to their own values.
Additionally, all of the yielding subjects, that is the ones who went along with the wrong
answers, underestimated the frequency with which they conformed.
They not only went along when they knew they shouldn't have, but believed they did it less
than they really did.
Ash expanded the study to see what would happen.
He showed that the bigger the majority, the stronger the pool to conform.
Like that if even one person dissented before the test subject, that the test subject was
then more likely to also voice his different view.
Ash showed, empirically, that having someone else agree with you is a powerful tool in
making people willing to take a contrary position.
But, that person were deserted by his fellow dissenter?
He followed rapidly and continued even after the deserter left the group.
Notice the move we're beginning to see here.
The one we've traced in other places in the history of science.
We began with an atomistic conception where the elements of reality are things in themselves.
If we really want to understand reality, we approach it as a collection and all knowledge
of what is real has gotten from understanding the details of these things one at a time.
To each under the microscope and learn everything there is to know about it.
We then move to seeing that we can't gain knowledge by looking at things individually.
We must observe the relations between them.
There are interactions, relationships between objects that must be added to complete a description
of reality.
Finally, we move to a place where these relationships take over and the individuality of the objects
fade away.
That what's real is the whole and that what we thought were autonomous independent entities
are really just modes of a larger unified system.
In physics, we move from atoms and point masses to gravitational theories with forces acting
between objects, finally to field theories.
In biology, we started with organisms, moved to species, and finally ecosystems.
There we see the beginning of the same sort of movement.
Psychology began as an investigation of the mind of the individual.
We all had minds and we just needed to figure out how they worked.
But Freud moved us to relationships.
We could not understand why you do what you do by only examining you.
We also needed to understand your relationship with other people, your parents, and those
who affected you when you were developing.
Now with social psychology, we're beginning to locate the mind, in part, outside the individual
in the group.
We'll make this step a little later when we look at sociology, but note the move.
To understand the reality of the human mind, we must see it as part of a larger social
consciousness which affects decisions, beliefs, and actions.
This becomes more pressing in 1963 when we have two seemingly parallel intellectual projects
coming out of one historical event, the trial of Adolf Eichmann.
Eichmann was a lieutenant colonel in the SS and was in charge of logistics for getting
the millions of people from their places of arrest to the concentration camps and then
to the death camps.
He was never the man who pulled the trigger, never the person who faced the victim, but
he was the person who designed the system in which the deaths would occur.
He was, in Simon Wiesenthal's words, a desk murderer.
Captured after having fled to Argentina, he was tried in Israel for his crimes.
It led to the asking of the crucial question, how could someone have done what he did?
The easy answer was that he was not human, he was a monster, he was insane, he had been
brainwashed or allowed his ignorant hatred of others to warp his mind, making him neither
rationally nor morally competent.
But the trial disabused us of this easy path.
In his cage sat a small man, balding and blowing his nose.
There was not the seething anger and screaming vitriol, the speeches we've all seen in the
filmed clips of Hitler addressing the crowds.
Eichmann was calm, he was mild, multiple psychiatrists had come to assess him and all of them said
he was not only sane, he was normal, a pleasant fellow.
If you didn't know he was the architect of the final solution, you'd never know.
Observing the proceedings was the German-Jewish philosopher Hannah Arendt, who was shocked
by the lack of shock during the trial.
Eichmann was not a raving lunatic, he wasn't an ideological fiend, he was just a guy.
He was not very bright, but that too is normal, he was just doing his job.
He wanted to please his bosses and get a promotion.
He thought in terms of the corporate jargon they fed him.
He could have been working for any corporation, getting widgets from the factory to the retailers,
looking for a big bonus come Christmas time.
He was a hard working Joe, just doing his job.
It just happened, Eichmann argued, and his job was working for the Nazis during the Holocaust.
Not his choosing, but hey, it was just my job.
I was just following orders.
Arendt realized that in important ways, he was right.
This didn't mean that he was innocent, far from it, but the fact is that the greatest
evil can be carried out by people who see themselves as not inheriting any of the responsibility
because they're just doing what they're told by those people in authority.
Those people, they have the responsibility, me, I'm just doing my job.
Arendt famously coined the phrase, the banality of evil, to describe such situations in which
we create structures which shield people from the real effects of their actions.
The true horror of Eichmann is not that such a monster could be created, but that he was
completely unremarkable, that he was just a guy who could be monstrous without being
a monster.
Maybe Eichmann knew what he was really doing, and maybe he didn't.
But the important aspect in Arendt's work is that we can often use social structures
to shift responsibility away from ourselves for our own actions, actions we would never
envision ourselves taking.
Arendt's philosophical account is supported by an experiment conducted that same year
based on the same concern.
How could people be made to do such things?
American psychologist Stanley Milgram conducted his famous obedience studies in the shadow
of the Eichmann trial.
The setup involved three people.
One was the authority who presented himself as the person running the experiment on the
effects of negative reinforcement on memory.
The experiment played on the public's picture of psychologists as behaviorists, making plausible
the context that one of them, the test subject, would be the teacher, and the other one, who
also seemed like a test subject but was really a confederate working with the experimenter,
would be the learner.
All three walk into a room where the learner is strapped into what looks like an electric
chair.
Electrodes are attached at the wrists, and it's explained that the teacher will read
him pairs of words he will learn to associate.
After the words are read together, the teacher will give him the first word in the pair,
and the learner will provide the second.
If he correctly supplies the second word, they move on.
If he supplies the wrong word or no answer, he will receive an electrical shock, and then
the experiment continues with the shock's increasing in strength as it proceeds.
The teacher, that is the real test subject, is then taken to an adjoining room and seated
behind a paddle with 30 switches, each one clearly labeled with a voltage ranging in
order from 15 to 450 volts.
Beneath the numbers are range indicators, which read slight shock, moderate shock, strong
shock, very strong shock, intense shock, extreme intensity shock, danger, severe shock, and
finally the last switches are just marked XXX.
The teacher is instructed by the authority to begin, and the words are read.
When an incorrect answer is given, the authority instructs the teacher to administer the first
shock.
When the switch is thrown, there's a buzzing, a couple of clicks, a light flashes, and then
a dial flicks across the face of a voltmeter.
There's every indication that the learner is really being shocked, including a reaction
from the learner.
Of course in reality he isn't, but you would never know it.
Now at first there's little reaction, but eventually there are verbalizations of pain
from a slight ooh, to a stronger ow, to a protest of stop it, cut it out, leading eventually
to the learner speaking of a heart condition, howls of pain, followed eventually by silence.
When the test subject is led to believe that he or she might have actually killed the learner.
Each time the authority demands the teacher continue and apply the shock in a firm level
voice, the authority clearly tells the teacher what to do, reinforces that it is essential
they continue, and verbally accepts all responsibility for whatever happens.
The point is, simply to place in conflict, obedience to authority, and an obviously immoral
act to see which one's going to win out.
Before he started, Milgrim described the experiment to a bunch of people, other professors
at Yale, 19 year old sophomore students, friends outside the college, clinical psychologists.
Everyone thought the same thing.
Most people would stop when the learner asked to leave the experiment, and only a very small
number of sadistic psychopaths, 4% they thought, would go all the way up to the dangerous shocks.
That of course is not what happened.
In the first run, using Yale Undergrads' test subjects, 25 of 40 went all the way.
That means more than 62% of the people were willing to act in a way they thought was not
only horribly painful, but would kill another person just because someone with authority
was demanding they do it.
The objection was made, well, these are Yale students who are attending one of the most
prestigious universities in the world, precisely because they've learned to do exactly what
people in authority want them to do.
Real people wouldn't act like that.
But when other populations were tested, changing age, socioeconomic status, nationality, the
results not only held, but increased.
In Munich, a researcher found that 85% of his test subjects threw the final switches.
The numbers were absurdly high.
And it was not, as had been originally hypothesized, that those who would remain compliant throughout
were sadistically taking pleasure in the suffering of the learner.
Those who continued showed obvious signs of distress throughout the experiment, sweating,
trembling, nervously reaching for cigarettes, they had difficulty lighting.
These were people who did not want to do what they were doing, and yet did it anyway.
Authority was shown to be troublingly powerful.
In Milgram's words, stark authority was pitted against the subject's strongest moral imperatives,
against hurting others, and with the subject's ears ringing, with the screams of the victims,
authority won more often than not.
The extreme willingness of adults to go to almost any lengths on the command of an authority
constitutes the chief finding of the study and the fact most urgently demanding explanation.
In an interview conducted after the experiment, one of the subjects who obeyed the authority
reported that his wife said to him, you can call yourself Eichmann.
Indeed, Milgram contends that Arendt's conclusions are closer to true than he dared believe.
Again, in his words, this is perhaps the most fundamental lesson of our study.
Ordinary people simply doing their jobs and without any particular hostility on their part
can become agents in a terrible destructive process.
Moreover, even when the destructive effects of their own work become patently clear and
they're asked to carry out actions incompatible with fundamental standards of morality,
relatively few people have the resources needed to resist authority.
A decade later, in 1973, Stanford psychologist Philip Zimbardo demonstrated that this authority
does not even have to be real to be effective.
Zimbardo took a bunch of graduate students at Stanford and randomly assigned some to be prisoners
and others to be guards and a fake prison he built in the basement of the psychology building.
The participants were screened so that those who might have sadistic tendencies were weeded out.
Indeed, the subjects were all well educated, middle class and white.
The guards and the prisoners in this experiment were incredibly homogenous.
There were none of the standard markers of division present in American society here.
The experiment was to take two weeks, but was cut short ending after six days
because the effects were so shocking and potentially harmful.
Zimbardo went to Paines to recreate the elements of the criminal justice system.
Those selected to be prisoners were arrested, taken to local police stations where they were
fingerprinted and had mugshots taken, then escorted to the fake jail on campus.
They were given badly fitting smocks, which they had to wear and ankle chains.
They were given numbers, which would be used instead of their names.
The guards were given uniforms with mirrored sunglasses,
batons and instructions that they could do whatever they wanted in order to create discomfort for
the prisoners. Zimbardo would be the warden and if he did not object to the action, it was fine.
At first, the prisoners didn't take the experiment seriously, acting goofy in a way that showed a
lack of respect for the guards authority, but the guards soon asserted themselves in a way
that enforced their authority. And when this caused an open revolt amongst the prisoners,
the guards quashed it with the aggressive use of fire extinguishers.
The guards decided that they needed to constantly reinforce their authority with
demeaning and dehumanizing activities designed to make sure the prisoners were kept in a place of
subservience. Their loss of their former identity was reinforced when they were made to report
their prison numbers over and over again mindlessly for no other reason.
Treatment became increasingly brutal and punishments increasingly vicious.
It came to the point where the study had to be ended.
One prisoner had a breakdown. He was removed, but the study continued.
Indeed, the experiment should likely have ended sooner than it did.
Remember that these are not real guards and not real prisoners. These are graduate students playing
pretend. They're not real criminals. They've done nothing wrong. There was no sense of justice
being served here. Zimbardo was describing the effects to his girlfriend, who would later become
his wife, and she was astonished that he had allowed this behavior to continue. She demanded
that he end it for humanitarian reasons, something he admits had not even crossed his mind.
He too had gotten swept up in it. His own authority had clouded his judgment.
But he did end it. And the result was that the usual claims that prison mistreatment was a function
of a few sadistic guards with personality problems seemed false. It's not that there were a few
sadists out there, and when they ended up in positions of authority, bad things happened.
Rather, it was concluded that it was the structure itself, the establishment of the system,
where some had authority over others that created the conditions for inhumane treatment.
These three experiments, taken together, formed an empirical approach to a question that had
been around since at least the 17th century. Are human beings inherently good or inherently evil?
What is the real human nature? Are we blank slates? Or do we have a predilection towards
altruism or selfishness? Thomas Hobbes, an English philosopher, argued that we needed a
strong central government to keep us in check from our dark and nasty natural selves. He began
by thinking about humanity before there was any social structure, putting us in what he called
the state of nature. Here there were no rules. There was no social safety net or even basic
cooperation. Each was on his or her own, and the key was simply to survive. We would seek that,
which would help us survive, and try to eliminate that, which was a threat to our survival. Since
everything could be useful in some way or other, we were in constant conflict with everyone else
over literally everything. Similarly, everyone else was a potential mortal threat, and so we found
that the state of nature was a constant state of war, each against everyone else. Life in the state
of nature, he famously said, was solitary, nasty, brutish, and short. We would soon realize that we
would be more likely to survive if we ended the state of nature. And so we created the state
by entering into a social contract that took away our natural rights and gave them to a central
government, which we expected would keep order. Any oppression we experienced from a central
government would be preferable to the state of nature, and so we willingly allowed for the power
to be located outside of us in order to create the order which is needed for human survival and
flourishing. We are brutal, nasty animals underneath and all, and the glory of human culture needs a
strong authority to keep us in check, to force us to act civilly. The 18th century French thinker
Jean-Jacques Rousseau disagreed. He was a romantic. To him, the state of nature was idyllic. Without a
political structure keeping us down and restricting our natural freedom, we would blossom into the
wonderful creative beings we really are underneath. If we're nasty and brutal, it's in reaction to
the authority of the state. It's the existence of private property and keeping things for ourselves
that we fence off land and other people creating envy, jealousy, and greed that turns us into
the terrible, selfish, modern, atomistic creatures we've become. We did not cease to be savages
when we became civilized. Civilization turned us into savages. What these psychology experiments
contend is that it's not the structure of civilization itself that made us or corrupted us,
but rather it's the distribution of that power and authority that corrupts.
Artistically, we find this represented at the beginning of the 20th century,
in the Polish writer, Joseph Conrad's work, Heart of Darkness, and even more so in its film adaptation
by Francis Ford Coppola, Apocalypse Now. The character of Mr. Kurtz in the book leaves the
civilized world of Europe to the barbaric Africa looking for ivory, while Colonel Kurtz in the
film is sent from the civilized world of America into the dark jungles of Vietnam and then illegally
across the border into Cambodia. In both, the character Kurtz is sent into the land Westerners
consider to be controlled by the savage in order to secure something of value to those with power
in the civilized world. But Kurtz goes off the rails. Instead of subduing the savages for the
profit of those who sent him, he instead lives among them, learning from them, and establishing
himself as a deity to them. Through sheer brutality, he becomes the ultimate authority
over them. They become his people. Kurtz does not become one of them. He does not as contemporary
anthropologists say go native. He remains Western reciting poetry and writing philosophy, but in
adopting the position of ultimate authority, he also sheds the moral restraints that guide
our interpersonal relations. To the narrator of the book in the film, Kurtz explains how he's learned
from his so-called barbarians, how the facade of civilization has weakened us, and how in his
position of authority, he's achieved a sense of wisdom he could never have learned otherwise.
But that insight into human nature discloses the savage truth lying beneath the mask of
civilization. And as Kurtz dies, his last words echo the sentiments, we too may glean from the
findings of post-Holocaust social psychology. The horror. The horror. But surely human nature
isn't reducible to such horror. There's care. There's love. These are essential elements of our being.
