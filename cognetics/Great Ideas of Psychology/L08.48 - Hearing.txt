Lecture 8 Hearing
The subject of hearing is offered as a second example of sensory psychology and the scientific basis of contemporary psychology,
as with the visual process so too, audition has been subjected to quite extensive experimental inquiry and measurement,
as with vision we do have not as many and not as well developed, but certain basic laws of auditory function.
The sensory systems are the result of millions of years of evolutionary adaptation.
Each sensory system equips the organism to deal with one or another aspect of the impinging world,
one or another aspect that ties up with basic considerations of survival.
And of course, as one goes from species to species, the dominant characteristics of the sensory systems change very often quite dramatically.
In audition, for example, as is very, very well known, bats have their peak sensitivity to frequency, to pitch,
at very, very, very high frequencies, frequencies we can't hear at all.
In fact, dogs also operate at very, very high frequencies.
The same is the case in vision.
For example, the peak spectral sensitivity of the honeybee, the region of the electromagnetic spectrum,
where the honeybee sees most clearly, is the region we would call ultraviolet.
So the ultraviolet light that we don't see at all is what illuminates the world of the honeybee.
And the sounds that we don't hear at all constitute the world of sound, perhaps the world of sound and music,
to organisms like bats and dogs, hearing things that will forever be on the range of our capabilities.
Well, as in the case of vision, so in the case of audition, I'm going to stay with the human system, the human sensory system,
recognizing in advance that the characteristics do change as you move from species to species.
What is sound? Sound is produced by vibrational phenomena.
When it's carried in air, for example, sound is produced by compressing and rarefying the air,
by moving the molecules of air very, very close together, very, very far apart.
These undulations, these compressions and rarefactions occur a certain number of times per unit time,
and that's what we mean by the frequency of sound.
By the frequency of sound, we mean the vibrations per second.
Now, in human audition, our sensitivity ranges roughly from vibrations on the order of 20 or 30 or 40 vibrations per second
up to perhaps 15, 16, 18,000 cycles per second, do you say?
And at 15,000 cycles per second or after the 19th century scientist Hertz,
at 15,000 Hertz HZ or cycles per second, we're getting almost a tingly, itchy sensation in the ears.
The pitch is now so high as to take on an almost, I should say, an almost tactile property.
And of course, at the very, very low frequencies, 30, 40, 50 cycles per second,
these are vibrations that again have an almost body surface feel to them,
a very, very low hum almost like an industrial noise in the background.
As you go to the very, very low end of the frequencies and the very, very high end,
our sensitivity drops off very quickly so that it takes much more energy for us to hear an extremely low frequency of sound
or an extremely high frequency of sound than for us to hear the middle frequencies.
The range from approximately 7,800 cycles per second to 2,000 or 3,000 cycles per second
covers the range in which we are likely to have our most common auditory experiences.
Middle C on the piano is 512 cycles per second, so roughly from 300 to 1,000 Hertz
would be the range in which most of our musical experiences take place.
Now, can we equate the ear with the eye?
Shakespeare at one point has a character saying,
dark night, that does from the eye his function take, the ear the better sense does make.
Shakespeare here recording the fact that in absolute darkness our hearing seems to be more acute.
And of course, during the 1950s and 60s, any number of studies were conducted to show
that with reduced sensation in one system, you generally can increase the sensitivity of another system.
So we can say that Shakespeare got that right.
Well, the systems do work in concert, of course.
Vision and audition and touch and smell and taste are wonderfully integrated in our experiences,
but they can also be studied and have been studied as separate processes.
If the cornea is the region of the eye that sits out in the world
and is there to collect the electromagnetic energy in the world first,
then the same would be true of the ear, what we call the ear that hangs on one on each side of our head.
That's the outer ear, do you see?
Now, the outer ear is a kind of collector.
It's not nearly as good in us as it is in some animals with very, very large antenna type outer ears,
but ours are suitable for the purpose.
As you go in from the outer ear toward the head, as you move immediately,
you pass through a semi-curved little chamber called the external auditory meatus,
and that ends in, that culminates in the eardrum.
Now, the eardrum is a wonderful, thin diaphragm
that has what engineers call great carrying capacity.
That is, for a given frequency put in, the eardrum will vibrate resonantly with it
and great carrying or following capabilities.
It will, over the range of maximum sensitivity, match that input frequency with its own vibrations,
very, very well indeed.
And indeed, it will also respond to very, very low levels of intensity.
There's very little energy loss in getting the eardrum moving.
In fact, if you measure the impinging energy on one side of the eardrum
and the energy that can be collected on the other side, there is very, very little loss indeed.
The technical term for that is that the impedance match is a very, very good one.
You don't really lose much in translation.
This is where the eardrum is healthy and wholesome,
which is to say where it hasn't been blown out of one's head by loud, alleged music,
which we could have long debates as to whether it's music or not.
In fact, nature must have imagined that we were going to entertain ourselves with some of this music
because there's actually a little muscular arrangement that can have a dampening effect on the eardrum
where the intensity gets too high.
It's almost like a drummer putting his hands on top of the drum to stop the vibration.
If the intensity gets too high, there's a little stapedious muscle
that actually damps out the response of the system.
It takes this muscle time to get engaged and the like,
so where there are sudden, very, very loud sounds coming on much too quickly for that mechanism to operate,
one does run the risk of damaging the eardrum and indeed irreparably damaging the eardrum.
Constant exposure to very loud sounds can also make this wonderfully rigidly mounted eardrum
a little softer in its mountings so that it gets rather raffly and hissy
and doesn't perform the kind of exquisite responses that it must perform for normal hearing.
Now, when the eardrum starts to vibrate, connected to the eardrum,
is a series of bones collectively referred to as the ossicles,
these bones forming what is called the middle ear.
The outer ear ends at the eardrum and then the ossicles form the middle ear.
The ossicles are referred to respectively as the hammer, the anvil, and the sterip
because of their shape, the sterip is sometimes referred to as the stapes, S-T-A-P-E-S.
Now, as the eardrum vibrates, the hammer starts banging down on the anvil, so to speak,
hammer coming down on the anvil, and as the anvil is attached to the sterip or the stapes,
the little stalk of the sterip attached to the anvil,
well, the whole sterip is moved back and forth, back and forth, back and forth
as a result of the motion of the hammer and the anvil.
Now, the sterip brackets a little window, a little diaphragm,
and as the sterip moves back and forth, it pulls this little window, this little diaphragm back and forth.
That diaphragm is what separates the middle ear from the inner ear,
and in the inner ear, we have a chamber that is filled with fluids,
and as that window is pulled back and forth, it sets up vibrational activity in those fluids.
Now, the story starts to get very, very interesting indeed.
The inner ear's chamber, if you looked at it from the outside, is shaped like a snail shell.
It's called the cochlea, C-O-C-H-L-E-A,
and if you treat it as a snail shell, and imagine that you can unwind it, you can roll it out
so that it would be shaped more like a cigar, for example, which when rolled up looks like a snail shell.
A cigar that gets narrower the further out you go.
Well, inside that cigar, inside that cochlea, is a membrane called the basilar membrane.
Indeed, as the cochlea narrows, that membrane inside actually gets wider, wider.
That membrane functions the way the retina functions in that, along that membrane, are receptor cells.
They're called hair cells, and they have wonderful properties.
They line the basilar membrane. Now, here's the picture.
Sound comes in, the eardrum is set into motion, the ossicles begin to follow the frequency of the input,
the little window is pumped back and forth, vibrations are set up in the fluid medium that fills the cochlea duct,
and the basilar membrane, which is rigidly mounted at both ends of the cochlea, now starts undulating, up and down,
like a whip in the water, up and down.
It's lined with hair cells, and as that basilar membrane undulates, the hair cells undergo a degree of stress.
That is, as the basilar membrane moves, the hair cells are slightly stretched.
They're stretched most where the undulation is greatest.
The hair cells have this extremely interesting property.
Engineers who are listening to the lecture or watching it will know what I mean when I say they're very much like piezoelectric devices,
or piezoelectric crystals, which is to say, they respond with a voltage.
They respond electrically in a way that is proportional to the mechanical deformation that you impose on them,
that is, as you stretch them or deform them, they give out an electrical response.
In this way, very much like the rods and cones in the retina that give you a weak electrical DC response when they're stimulated,
and the hair cells give a weak electrical DC response when they are stimulated.
These hair cells finally make connection with bona fide neurons.
Remember when we talked about the retina, how the retinal ganglion cells receive inputs from the bipolar cells,
how the retinal ganglion cells have axons which are the fibers in the optic nerve,
well, so too the hair cells make connection with bona fide neurons whose axons are the fibers in the auditory nerve.
So you've got something that very much parallels the visual system and by and large the sensory systems in general.
You begin with a receptor element that takes a mechanical stimulus, in this case undulatory motion and deformation.
You're actually imposing mechanical stress on the hair cells and what response do you get?
You get an electrical response. So you have a mechanoelectrical transducer.
As in the visual system, you have a photoelectric.
In fact, you have first a photochemical transduction.
Light hits the cone cell and the pigment decomposes.
There's a photochemical event and with that decomposing of the visual pigments, an electrical signal is generated.
So you ultimately have a photoelectric transducer in vision.
You have a mechanoelectric transducer in audition.
As with the optic nerve fibers, so the fibers in the auditory nerve generate impulses.
And as the sound increases in frequency, you get a greater number of impulses.
Interestingly, however, as the sound increases in intensity, you also get an increase in the number of impulses.
So the question naturally arises, how do we ever tell the difference between a sound whose pitch is going up and a sound whose loudness is going up?
That is, if the electrical code is the same in both cases, we shouldn't be able to tell them apart.
Well, we do tell them apart. We tell them apart almost all the time, but not always.
In fact, in a certain region of sounds, if you increase the intensity, the pitch also seems to change.
And that's because the code is the same in both cases.
That is, over a certain range of frequencies, increasing intensity also alters pitch.
Because in that region, the coding mechanism for intensity, impulses per second, is also the coding for pitch, impulses per second.
Now, one of the ways we can tell this apart is as follows.
Here you've got to use your visual imagination.
Imagine this whip in water, so to speak. It's more like a whip and a kind of loose jello.
And it's a whip anchored at both ends.
So you've got these vibrations going on.
And this whip now, this membrane, is going to start beating up and down.
But it isn't going to beat up and down equally along its length.
Where the maximum displacement occurs depends upon the frequency of the sound itself.
Do you see? In fact, I told you that the basilar membrane gets wider as you go down its length.
The wider it gets, the more it responds to low frequencies.
Like piano wires, do you see? Wires, do you see?
The narrower it gets, the greater is its response to high frequencies.
So the point on the basilar membrane that is most affected by a sound depends on the frequency of the sound.
High frequency sounds causing the greatest displacement where the basilar membrane is thinnest or narrowest.
And lowest frequency sound causing the greatest basilar membrane displacement where the basilar membrane is widest.
So guess what we have?
We are now able to code or represent pitch with a particular location.
That is, the hair cells that are attached to the widest portion of the basilar membrane are the hair cells that will be most deformed by a low frequency sound.
The hair cells that are connected to the narrowest portion of the basilar membrane will be most deformed by a high frequency sound.
Now, those hair cells tie up with specific auditory nerve fibers.
So, pitch is going to be represented to some extent now, not entirely, but different frequencies of sound will be carried by different auditory nerve fibers.
Now, here's the qualification that has to be put on this.
It is the case that the region of the basilar membrane most activated depends upon the frequency of the sound that reaches the eardrum.
Nonetheless, almost any audible sound will activate the entirety of the basilar membrane.
What varies is the point of maximum displacement.
The whole membrane is driven into motion by sounds in the audible range.
What varies is the region of the membrane that is most displaced.
So, although it is the case that to some extent different frequencies are carried by different auditory nerve fibers, there's tremendous overlap here.
And you would never be able to account for pitch sensitivity by knowing only how the basilar membrane is behaving.
So, what more do we need then?
Well, an interesting story unfolds and it requires experiments of an extremely delicate nature.
I should say too that as with much of the research in all of sensory psychology, these experiments have very often been conducted with non-human animals.
And the procedures involved sometimes have been radical surgical procedures.
I don't think anyone any longer can lecture on subjects of this sort.
Without noting, and this is not the context for a sustained discussion of the issue, though the issue is widely discussed in philosophy and in science,
I don't think one can address these issues without acknowledging that there are very, very significant ethical implications that arise from using sentient creatures.
If they weren't sentient, you couldn't be studying sensory processes in them, do you see?
Sentient creatures, particularly such complex social creatures as dogs and cats and primates, in experiments in which the surgical intervention sometimes reached the almost incredible level.
I say I don't want to dilate on this subject, which has engaged the energies of philosophers, ethicists and scientists.
But if in the course of these lectures I seem to glide past this in reporting the findings without addressing this other matter, I shouldn't want anybody to think it's not because this matter is not recognized.
It is recognized and duly noted.
Now, what has been found in these studies is the following.
Suppose you present a sound of a thousand cycles per second, and you have a way of measuring the fraction of the basilar membrane that is thrown into motion by that sound.
Well, as I said, almost all of it is thrown into motion by that sound.
Now, under the same conditions, suppose you sample the percent of fibers in the auditory nerve that are responding when you present this sound.
Well, not all of them are responding.
Now, you keep traveling along with the auditory system as it makes its way through various portions of the nervous system.
Without making anatomists of any of you, I point out that the auditory nerve fibers terminate.
They come to a way station in a portion of the brain called the medulla, on the lateral portion of the medulla, in an area that is referred to as the cochlear nucleus.
Now, a nucleus in the central nervous system is any place where you have a large collection of cell bodies.
So these fibers are now terminating on a collection of cell bodies that will pick up the information and deliver them elsewhere.
If you now measure the total number or percentage of cochlear nucleus cells that are responding to that thousand cycle tone, well, that's fewer than the percentage of auditory nerve fibers.
Now, again, without making a long story long, but keeping a long story short, as you keep measuring the response of the auditory system at each station, the medial, geniculate nucleus, et cetera, et cetera, et cetera,
smaller and smaller regions, fewer functional units are responding to that sound.
When you finally get to the auditory cortex, when you get to that region of the cerebral cortex that responds principally to sound,
there you have a surprisingly limited area that will be responding to a given range of frequencies.
Now, the short script goes something like this. As you go higher and higher in the auditory nervous system, the tuning becomes sharper and sharper and sharper.
So you've got fairly broadband tuning at the level of the basilar membrane, fairly precise tuning at the level of the cerebral cortex.
This, I submit, can be studied without surgical intervention, particularly these days where we have methods of recording the electrical response of the nervous system with surface electrodes,
magnetic resonance imaging, CAT scans, PET scans, and the like.
So you actually could do a fairly substantial study of effects of this kind non-surgically.
Now, pitch, I say, and loudness follow a similar code over a certain range, but what range would you expect that to be?
Well, it would obviously have to be at the fairly low frequency end of things, and this, for the simple reason, that neurons have a maximum firing rate.
If we take the range of auditory sensitivity to run from something like 30 or 40 cycles per second to something like 15 or 18,000 cycles per second,
you can't generate 18,000 impulses per second in an axon.
Do you see? No neural cell can respond with a frequency like that.
So if the only way you could hear a 15,000 cycle per second sound was by having units that respond 15,000 times in a second, well, this would be simply out of the question.
Now, where is it in the audible range that the nervous system's apparatus can keep up with the input frequency?
Well, at the low end of frequencies.
So when you actually record from auditory nerve fibers, what you discover is this.
If you put in a 50 cycle per second sound, you might find units that are giving you 50 impulses per second, 70 impulses per second, 90 impulses per second.
How long does it take the typical neuron to recover after firing?
Well, it takes an amount of time such that you would not expect anything to respond at a rate higher than 1,000 impulses per second.
Do you see? You're getting to the far outer limits at this point.
So once the input frequency goes above 1,000 cycles per second, something other than impulses per second in a given auditory nerve fiber must be involved.
What do you think that might be?
Well, other fibers kick in.
And now frequency is coded not in the form of impulses per second in a single fiber, but in the form of volleys that are generated by a combination of fibers, some number of fibers.
Do you see?
As you increase loudness, you also increase impulses per second in a given fiber.
Where would you then expect the greatest confusion of changes in pitch and changes in loudness to be at those relatively low frequencies where a given fiber is giving you more impulses per second,
either because the frequency of the sound has increased or its loudness has increased.
Do you see?
Now once you get to the higher frequencies where a kind of volleys code is involved, you don't get those pitch loudness confusions.
Most of this has been worked out at the psychophysical level with normal subjects, usually the college sophomore who wants to earn a little bit of extra credit for experimental psychology and is willing to sit in a room for two or three hours saying yes, no, louder, softer, and the like.
I sometimes wonder the extent to which all we know about psychology is limited primarily to college sophomores.
I mean, it's going to be quite an eye-opener if it turns out that they are utterly atypical in some sense.
Now I did say on a couple of occasions, both in discussing the visual system and in discussing the auditory system, one has to be very careful about protecting these systems.
Now I don't want to be a scold by any means, but I should say that the world of high technology does constitute something of a threat to the integrity and the functional capacity of our sensory systems.
Our remote ancestors lived in a world in which they were guaranteed long periods of darkness, periods of darkness occasioned by the setting of the sun.
Periods of darkness interrupted only by the moon in its various phases, providing quite dim illumination.
The body systems governed as they were by various diurnal patterns found us sleeping regularly and resting these systems.
Well, of course, all that has been changed with electricity and high technology.
We are constantly in the light. Very often we're in very, very bright light.
We wear sunglasses. Sometimes they're cheap sunglasses. The net effect being this.
The amount of light reaching the eye is reduced, which means the pupil diameter increases, admitting more destructive radiation.
That is where you do not have the right kind of sunglasses to filter out the ultraviolet, but just some cheap intensity dimming device in front of the eye, you make matters worse.
Similarly with audition, it would have been very, very rare in our remote ancestry, except for volcanic eruptions and cloudbursts, for anyone to experience the kind of sound that the contemporary citizen is experiencing all day long.
Traffic noises, jet airplanes, music played at much too high an intensity. People working with industrial equipment.
One thing we know from the industrial experience is this. A person standing out in the road four and five and six hours a day operating a jackhammer is constantly bombarding the system in such a way that a given region of the basilar membrane is undulating at a day long clip in a particular location.
People exposed to high intensity, industrial sounds, sounds like that, repeated exposure, lifelong exposure, develop what are called tonal islands and tonal gaps.
That is they actually become deaf in that region of the spectrum to which they have been constantly exposed.
Now you can test these by plotting how intense a sound must be to be heard as a function of its frequency.
When you plot the intensity of a sound needed for somebody to hear it against its frequency, you've generated what's called an audiogram.
You can see sensitivity over the range of frequencies to which we are normally sensitive.
People who have been exposed to a small frequency range at very high intensities for prolonged periods of time can develop precipitous losses in sensitivity in just that region.
That is to say if you looked at their audiogram, it might be a relatively normal audiogram that all of a sudden has a gap in it.
A place where there isn't a sound you can make loud enough for them to hear it.
There's simply depth at that frequency.
All this by way of saying that the care of the sense organs, particularly the visual and auditory system, is not something that can be taken lightly.
The world we live in is assaultive.
There is very little by way of predictability in the kinds of sounds we're going to confront, in the intensities of light we're going to confront.
We now have generations of children who are spending seven, eight, nine, ten hours a day, if not in front of a television set, then in front of a computer screen.
And it remains to be seen whether this is going to produce certain long range effects, not only of a sensory nature, but of a more general perceptual and perceptual mode of nature.
Now, of course, it always sounds like alarmism until after the fact, and I don't mean to be alarming, but I would point out that the exquisite sensitivity of the visual and auditory systems already is showing signs of degradation in youngsters who have exposed themselves
at rock concerts and elsewhere to extremely high intensity sounds in a relatively broad range of frequencies.
It's something we must pay attention to.
