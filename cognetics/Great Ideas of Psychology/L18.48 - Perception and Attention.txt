Lecture 18, Perception and Attention
In this lecture, I shall stay with the relationship between perception and attention,
which is often attempting to focus on what might be called internal processes
or factors, variables and conditions that are not in the external world
but must be assumed to be somewhere within the recipient himself or herself.
And I might begin by talking about the filtering operations that take place
in our perceptual experiences, in our perceptual encounters with the external world.
The external world provides a veritable bath of stimulation on the organism,
on us, on all sentient creatures.
Electromagnetic radiation covering the entire spectrum, sound of every variety,
doors closing and lightening bolts and squeaky mattresses and squeaky shoes.
So we are constantly under a flood of stimulation
and indeed life would be a daily, blooming, buzzing mess
if there were not some systematic way of keeping out whatever is extraneous,
whatever does not bear in any consequential way on life and its requirements
and admitting and selectively admitting the sorts of events that really do match up
with our requirements as biological and psychological organisms.
The mechanisms of perception contain two different kinds of filter to handle this job,
this ever-present moment-to-moment job.
One I think is best described as a passive filter.
A passive filter in the sense that it behaves in the same way,
trial after trial after trial, event after event after event,
the filtering here achieved by what is essentially the physical characteristics of the filter itself.
For example, in vision, the retinal receptors, the rods and cones contain pigments.
The pigments must be acted on by quanta of light.
When quanta of light strike molecules of pigments, the pigments undergo a decomposition.
But of course the frequency of radiation that hits these pigments
determines whether or not there is going to be any response at all,
which is to say we do not see all electromagnetic radiation.
We only see that portion of the electromagnetic spectrum that falls within the range we call the visible range.
I identified that as a range of wavelengths roughly between 360 and 760 millimicrons.
Now that's fixed. That means that unlike the honey bee, we do not see ultraviolet light.
And the honey bee does see ultraviolet light. The honey bee sees most clearly in ultraviolet light.
Now there's an example of a fixed filter.
It says that no matter what the range of electromagnetic radiation might be,
no matter how my system, my body surface might be bathed in electromagnetic radiation,
there's only going to be a portion of that that is visible.
And anything containing wavelengths shorter or longer than what I've described as the visible band
simply will not be seen at all. There's a passive filter.
The auditory system also presents another passive filter,
not unlike what people assemble in their houses when they put together stereo systems
or very good high-fidelity playback systems.
What you want in a speaker, if you go out to find something that's going to play
the way you want to hear it or Schubert the way you want to hear Schubert,
you want something that's going to respond quite faithfully, quite accurately,
to just those frequencies that constitute that musical piece.
You want something that's going to respond faithfully within that band of frequencies
that the musical repertoire is found.
You don't want a system that's going to respond to all the buzzing, humming sounds,
what we call 60-cycle hum in an electrical circuit.
So you want to filter out those low frequencies.
You don't want very, very high frequencies, squeaky frequencies picked up.
So when you go to the shop, you go to the audio supply place,
if you're one of these sound buffs.
And if you go to one of these places, you'll see people talking to the sales force
from furrowed brows and what's the spectral response
and do you have the waveform characteristics of this, that, and the other.
Well, what is it they're looking for?
They're looking for a system that behaves as follows.
If the sound output of the orchestra is so many intensities of, let's say, loudness
throughout that particular musical piece,
a given intensity of sound at each of the component frequencies in the piece,
then you want the playback system more or less to duplicate that spectrum.
You want the playback system to give you back the same intensities at those frequencies
that they were played by the orchestra or sung by the tenor or the soprano and the like.
You want something that's non-distorting,
which means you don't want it to accentuate certain frequencies over other frequencies.
You want it to give you a reliable response.
Now, you can never get something that plays back perfectly what was initially recorded,
as I pointed out in an earlier lecture.
In any information system, there is always noise.
But you are looking for something that will behave itself properly, play things back reliably.
To do this, you buy speakers.
The speakers are rigidly mounted.
They are made of materials that respond in a certain way.
The mounting plus the materials are such that that speaker system will not respond to 12,000 cycle per second sounds.
It will not respond to two cycle per second sounds.
It will give you its maximum response and its most faithful response in the region of the spectrum in which all music is found.
Now, this is a fixed filter.
It will always behave the same way.
Whatever input you put into it, the output characteristics are determined by the design of the system,
the physical materials, the nature of the mounting, what the baffling technique is, and so forth.
So there is a fixed filter.
The human auditory system also has these fixed filtering capacities and properties.
For example, the human eardrum is rigidly mounted.
It responds to frequencies in what range?
In the audible range, the eardrum does not pick up frequencies higher than the audible range.
It's designed in such a way, mounted in such a way, and made of such a material that it cuts out beyond a certain frequency range.
What you wanted to do is give you a highly faithful, highly reliable response to those input frequencies and intensities that are, in fact, audible,
listen to, and containing the kind of information on which we can base our actions.
So those are characteristics of fixed filters.
All the human and animal perceptual systems have these fixed filter features.
So a significant part of the external world never gets into the system.
Most of it's thrown away from a biological and psychological and Darwinian perspective.
What's thrown away is not relevant to survival.
It doesn't bear directly on the adaptive requirements that organisms face.
But there is also active filtering.
Some of this was referred to in the previous lecture.
That is to say, we are able to filter things out quite selectively with a selectivity that depends in part on learning,
but also seems to depend to some extent on certain innate predispositions.
Now there are any number of examples of active filtering, some of them amusing, some of them daily.
There's the so-called cocktail party effect.
Everybody has experienced the cocktail party effect.
It goes something like this. You find yourself at a party.
You find yourself in a room just buzzing with conversations.
There are little dyads and triads and quartets located all over the room.
Some people are in their cups.
There might be a musical group or some sound system playing elevator music in the background.
You don't quite know why you're at this thing.
It's the office Christmas party.
You're counting the minutes off.
You wish it would end in a moment.
But anyway, you're engaged in conversation with someone you really do like to talk to.
And there you stand, gabbing away, back and forth.
The discourse is incessant.
Now, the plain fact is that that room is alive with sound.
Conversations are going on all around you, right next to you.
You're back to back with somebody who's jabbering away about whether or not the New York Yankees will win the World Series again.
And interestingly enough, you hear none of this, none of it at all.
You don't even know what's going on.
You're solely preoccupied with the conversation you are having,
not withstanding to the contrary the fact that your auditory system is perfectly able to pick up all these other sounds.
They are all super threshold.
It's not that they're too soft or low in intensity to be heard.
It's that you've shut them out.
And in fact, you haven't in any, as it were, intentional way shut them out.
That is, you haven't said to yourself,
oh well, there are conversations going on everywhere in this room
and I'm simply going to make it my business not to hear these conversations
because otherwise I'm not going to be able to hear the person I'm speaking to.
No, this is done quite automatically.
And in fact, you can see that it's done quite automatically under the following circumstances.
There you are, Jack and Jill, gabbing away, chins wagging all over the place.
All the rest of the world has disappeared and you hear only what each other is saying.
And then, all of a sudden, in a distant corner of the room, somebody mentions your name.
Let's say your name is Jerry.
So you're gabbing away and talking away and you don't hear anything going on
and then all of a sudden, you pick up but your interlocutor does not pick this up.
You're interlocutor, by the way, at this point doesn't know your name is Jerry.
You pick up, blah, blah, blah, blah, and Jerry said, and what do we find Jerry doing?
He stops in the middle of the conversation, turns around, looks over to the corner of the room
and might even go over and say, did I hear you mention my name?
Or am I the Jerry that you had in mind?
Now, here we have the combination of two things.
We have a highly selective filter, which is to say a filtering mechanism that keeps away
everything that is not central to the discourse.
But it also is a variable filter in that somewhat like an antenna scanning around,
if something in the ambient acoustic environment is meaningful, it will pick it up.
You might see it as a sort of radar operator or sonar operator where this thing goes around 360 degrees
at a certain rate and sees nothing and sees nothing and then there's a little blip on the screen
that means something and at that point the lights come on, the bells go off and a new game begins.
So here we have the powerful influence of mechanisms of attention determining what will be perceived.
The attentive process is now guiding the perceptual processes and this is a quite flexible system.
It benefits from learning but there is already in place, innately it would seem, the mechanisms needed to do this.
We know for example that the neonatal child, the child two and three days old,
given access to a variety of voices will turn its head in the direction of the mother's voice.
Now how does this come about? Well actually studies involving the measurement of sound
in the intrauterine environment show that as a pregnant woman speaks, the spectrum of her sounds
is very faithfully represented in the intrauterine environment, fluid being a very good conductor of sound.
So that throughout its late development, the late developing fetus is having regular access
as its own auditory system develops, regular access to the spectral qualities of the mother's voice
whereas there's great great distortion in any sound in the external environment finally getting represented
in the intrauterine space and what we see at birth is the capacity to distinguish the mother's voice
from all other voices. Now here you see evidence of learning of course, there are opportunities for learning here
but you already have during fetal development mechanisms designed to achieve a certain kind of bond
or recognition that indeed will be highly relevant to this little creature coming into a busy world
in which survival is otherwise ever in doubt.
Now studies have been done, not the studies of the cocktail party effect of course are abundant
but other studies have been done of a more basic psychophysical nature
and these concerned with the extent to which we actually can filter out certain sounds
and here only the things we're supposed to hear.
The classic sort of study, in fact I think one of the best studies ever done was done about 40 years ago by Colin Cherry
involves subjects being given earphones and you can play separate messages into each ear.
This kind of presentation is not a binaural presentation, that's where the same sound is coming into both ears.
It's a presentation that is called dykotic, D-I-C-H-O-T-I-C
and that is where what one ear is hearing, the other ear doesn't hear, they are getting different messages.
So you now can play one message into the left ear and an entirely different message into the right ear.
What's very interesting about this is if you equate the intensities of the sounds going into the two ears
so that the subjective experience of loudness per se is the same in both ears
you then say this to the subject, I'd like you to repeat back to me with as minimum a delay as you can achieve
whatever you hear being spoken into the left ear.
Now you might recite into the left ear, my country tis of these sweet land of liberty
or you might start reading a daily newspaper.
The subject's task is to track whatever he hears in his left ear and to track it as closely as possible.
The task itself is aptly referred to as a shadowing task.
You are in your utterances to shadow whatever it is you're hearing in your left ear.
You're to introduce as brief a phase lag as you possibly can.
So let's say I'm reading something like this into the left ear.
We are in Springfield, Virginia and as I say we are in, if you're shadowing correctly
the minute you hear we you'll say we are, we are, are in, in Springfield, Springfield and the like.
So you're trying to be an acoustic shadow of whatever it is you're hearing.
Now it turns out that people can shadow very very well in these regards.
So we read this message into the left ear and you shadow it very very accurately
and we can actually measure the accuracy of the shadowing by comparing the two tape recordings.
The tape recording of what went into your left ear, the tape recording of your utterances
and through the right kind of processing we can measure the, the average phase lag
and the number of pronunciation errors you make and so forth.
That's, that's the way these measurements are made.
Now while this is going on we start playing all sorts of things into your right ear.
We, we might in your right ear be saying one, two, three, four, five, six, seven, eight
throughout this shadowing task.
We might be reading a page from Dickens and in the middle of that we might switch to Dickens in French.
Well the task is over and we tell you that you've done a very very good job shadowing.
We then say by the way, did you hear anything else while this was going on?
Now the substantial fraction of recipients first of all will say, no I don't think so.
Well think about it again, do you, do you think anything else was happening while we were doing this?
Well I don't know, there may have been something coming in on the other side.
You then play them what was coming in on the other side, you ask them if they ever heard this before?
Oh no, absolutely not.
Now these are tasks I say in which what is coming in on the other side
might actually involve a change in language from English to French, French to German.
It might be bizarre text, it might be a very very funny joke.
It might be the sort of thing which one played alone would summon the attention
and even the deep concern of the recipient.
But the recipient now has been told to listen to what is coming in the left ear.
The recipient can't tell you how it is he or she shuts off everything coming into the other ear.
It's not an act of intention though one might say at some level it might be an act of will.
But it certainly illustrates quite remarkably our ability to direct our attention,
to focus our attention, to bring it to bear on something to such a great extent
that we are utterly oblivious to anything else going on in the world.
The attention almost can't be pulled away by anything else except the most sudden
and perhaps even portentous event or highly meaningful event.
Now you might be interested in what the brain is doing while this sort of activity is going on.
And studies here are quite interesting.
Suppose while you are doing a shadowing study you actually record brain events
from areas of the brain known to respond to sounds.
So if you put recording electrodes over the temporal cortex of the human brain
and then presented the subject with let's say repeated clicks or repeated tones,
something like...
It doesn't take many such presentations before you will see
in these amplified signals picked up by electrodes on the skull surface
the formation of a response to those repeated sounds.
These responses are distinguishable from the background EEG activity.
The brain is always electrically active and that ongoing activity of the brain
is what is picked up by an electroencephalogram.
But this is not the ongoing constant background activity that we are looking for.
Rather it is the activity that is evoked or evinced by a regular occurring stimulus.
So these brain responses are called average evoked responses.
Now after a number of presentations like this, 10, 15, 20 such presentations,
you begin to see a fairly sharp brain response,
an average response to this recurring acoustic event.
So we have this recurring acoustic event let's say in the right ear.
It might be a pure tone that's repeated 100 times, 200 times, 300 times.
Now while this is going on the subject is put in a shadowing task.
And in the left ear we start playing any number of things.
We might do try to stay with us now, it gets a bit thorny at places.
We might play in something that is so highly redundant with the subject's knowledge base
that he could recite it, it wouldn't even be tracking.
I gave you the example of my country, tis of thee, or I pledge allegiance to the flag.
Now if I just stopped at that point, you could repeat the balance of this.
It wouldn't even be shadowing.
This would be an extremely simple shadowing task in that the information that you are shadowing
is information so well known to you that you almost have to try to shadow rather than simply recite.
Or in that ear we could be reading a highly technical journal article
drawn from a subject area that the subject has that the recipient has never studied,
where the shadowing task would be extremely difficult.
Now suppose we systematically vary then what might be called the information loading
that the shadowing task requires.
Very very high information loading being material that the subject has no knowledge of at all.
Very very low information loading being material that is so redundant with past experience
that it's really a piece of cake for the subject to keep up with this.
Meanwhile we have these repetitive signals going in the other ear.
Well what do you discover?
First as the shadowing task becomes ever more difficult,
the subject's shadowing errors increase, there are more mispronunciations,
there are more words that are actually missed,
there are greater pauses which is to say the phase relationship between the message
and the shadowing response starts to break down.
While that's going on as the shadowing task becomes ever more difficult,
the subject's recognition or recall of anything played in the other ear
systematically drops and indeed with a difficult shadowing task drops to zero.
On the other hand, as the shadowing task becomes quite simple, errors drop to zero.
As the errors drop to zero, the subject's recall of what's being played in the other ear starts to pick up.
Now what are the brain responses doing during all this?
Well find a shadowing task so difficult that the subject is utterly oblivious
to anything played into the non-shadowed side and there's no brain response at all.
That is you can present hundreds of pure tones, each one of them well above the auditory threshold
and you get no average brain response, no cortical evoked response at all.
Find a task in which the subject's shadowing is very, very difficult, the error rate is very high,
this is really tough now and you find the subject not doing very well shadowing,
the subject has no recollection of anything coming in the other side, no brain response at all,
now the subject has a very easy shadowing task, it's my country to visit thee, sweet land of liberty,
never is an error made, do you see, and the brain responses to are sharp in place and what does the subject say?
If you ask the subject, let's say a run of 32 trials, did you hear anything else besides this message?
Yes, I heard a tone. How many times do you think that tone was presented?
Oh, 25, 30. Now you go to an intermediary shadowing task where the subject perhaps says,
yes, I heard something in the other side, what do you think it was? Well, I think it was a tone.
How many do you think were present? Or maybe two or three.
And the fact is these subjective responses match up with the actual amplitude of the brain response under these conditions.
So you have this happy coincidence of the subject's error rate telling you something about the difficulty of the shadowing task,
the difficulty of the shadowing task predicting whether or not the subject will recall anything being played into the non-shadowed side,
and, I say happily, the cortical response just tracking these measures,
just standing up very, very well with what you're getting at the level of psychophysics and what you're getting at the level of recall.
Now, what's particularly interesting about studies of this kind is that there's no doubt that we obviously were in no position to do this.
The research I described is research that Professor Stephen Sabat and I did at Georgetown a number of years ago.
Now, we were in no position to take recordings from the basilar membrane or the auditory nerve and the like,
but I can assure one and all that during a shadowing task, if you actually start presenting pure tones or highly audible signals into the right ear,
that eardrum is going to be responding. The bones in the middle ear, the ossicles, are going to start vibrating as they must and as they should.
I say the eardrum will vibrate, the ossicles will vibrate, the basilar membrane is going to start bouncing up and down,
and I am sure if we were recording from the auditory nerve, the auditory nerve would be showing fibers discharging all over the place and carrying the consequences of that sound.
No cortical response. What does that mean? It means somewhere within the auditory nervous system.
There must be a means by which the mechanisms of attention prevent signals from activating the cerebral cortex, which we would assume would be mediating the conscious experience of sound.
We would take that conscious experience to be something occurring at the cortical level rather than the subcortical level.
Without going into the details of the anatomy, there would be good reason to believe that maybe somewhere at the level of the thalamus,
the thalamus is the primary sensory relay station within the brain, all but two of our sense modalities have quite developed phylamic centers there.
The thalamus projects its influences anatomically and physiologically to the cortical surface.
And we would expect then that somewhere at the thalamic level, there must be a means by which the nervous system's mechanisms of attention and selective attention determine the extent to which external inputs will receive cortical representation.
And it seems to be in these shadowing tasks that through divided attention and focused attention, we can actually not only have subjects oblivious to events in the external world,
but we can see to it that the brain isn't even responding to those events, though they are otherwise reliable and super threshold.
Why would anyone design a system like this? Well, for the most obvious reasons.
As I said at the beginning of lecture, we are in a veritable bath of energy.
The sense organs are being stimulated almost 24 hours a day, sound is everywhere, light is everywhere.
The clothes on our back will press down on cutaneous cells picking up pressure and temperature and the like.
We couldn't get one foot in front of the other one if we were attentive to every one of these stimulus events.
99% of what's hitting us has to be just kept out of awareness so that we can keep in awareness just those things that must be dealt with if we are to succeed, if we are to achieve the sorts of things that complex organisms must achieve as a condition of survival.
Now, much of this, I say, is pre-wired. Some of it benefits greatly from practice and training.
Everyone knows the difference. One of the main differences between the professional dancer, the professional musician, the professional athlete is this tremendous power of focused attention.
Take a look at a professional batter in the batter's box. For goodness sake, not a muscle is moving except those that are regulating the line of sight, the fingers on the bat.
World War III could break out and Joe DiMaggio is going to see just that ball coming up to home plate.
One of the great baseball hitters of all times, Ted Williams says that when he was at bat, he could actually see the stitches on the ball as the pitch came to home plate.
This is something coming in at 100 miles an hour. Well, this of course is a good visual system, but it's a profoundly good system for attentive behavior.
Pre-wired, benefiting from practice, our mechanisms of attention come to determine what we perceive and this again points to events on the inside of the organism rather than events in the external world.
