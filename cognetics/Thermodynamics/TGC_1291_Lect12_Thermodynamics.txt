Hi, today we'll be talking more about heat.
I mean, our subject is, after all, the motion of heat.
So it's a pretty important topic.
Now we've already learned all about heat and how it is a fundamental part of the first
law, how it can be made into the state variable entropy by dividing by temperature, or the
state variable enthalpy by holding pressure constant.
But today we're going to discuss something else about heat, namely the nature of how
materials keep thermal energy inside of them.
This is called heat capacity, since it is literally the capacity of a material to absorb
heat.
Now remember, we would never say store heat, not students of this course anyway.
We can't say store since heat is not just energy, it's energy transfer.
But just how much energy can be transferred to or from a given material in the form of
heat?
Let's pop some balloons for our demo to help us see this heat capacity in action.
So the following is a pretty simple demo, but it's a great way to illustrate the concept
of heat capacity.
Here I have two different balloons, and for each one I'm going to try to pop them with
a flame.
So first let me make my flame, and I hope you notice the candle holder that I'm using.
I'm very excited about that one.
And then I'm going to take, once that flame gets going, I'm going to take this balloon
here.
This balloon is filled with air.
So what do you think is going to happen when I put this over the candle flame?
Well, let's take a look.
As you can see, it popped, and actually the popping put out the candle.
The reason it popped is because the fire damaged the polymer and the plastic sort of
polymers that make up the balloon material.
And the heat from the fire went straight into damaging that material, and a Hulk was
created and the air burst out.
But what if I take this second case?
Here I have a balloon that's filled with water instead of air.
Now I'm going to hold this one over the same flame.
OK, we'll get it nice and close.
By the way, did you know that a flame is around 1,400 degrees Celsius?
It's pretty hot, even a small one like this.
And you can see that smoke is coming, but even after 5, 10 seconds, and even if I kept
holding it here, this balloon will not pop.
You can see that what happened was it got dark, it got charred.
So it looks like maybe I am damaging the balloon.
But in fact, that char, that will just wipe off, that's just from the smoke of the candle.
So that same material that got damaged before didn't even get scratched this time.
Why is that?
Well, it has to do with heat capacity.
The heat capacity of the water is so much higher than the heat capacity of air.
That means that the water wants that thermal energy so badly, so badly in fact, that it
pulls it away from the candle and away from the liner of the balloon, the material of
the balloon, instantly and it grabs the heat and stores it inside of its internal degrees
of freedom.
The heat capacity of the water is so high that I could have held this over the flame
literally until the water started to boil and no damage would have happened to the balloon.
And in fact, I am so confident in the high heat capacity of water that I want to show
you one more thing.
It turns out that I happen to have the 50-50 mixture of ethanol and water from the last
demo.
Now, I am so confident in the laws of thermodynamics and the role of heat capacity that I am going
to take a hundred dollar bill.
And what I am going to do is I am going to dip it into this 50-50 mixture of water and
ethanol.
I am going to get it nice and soaking wet.
And now, I am going to take the bill and I am going to light it on fire.
Let's see what happens.
You can see that you get a nice blue flame and you can see that it is on fire but no
damage was done.
And the reason for that is that again, the heat capacity of the water is so high that
it pulls all of the fire's energy away from the material that makes up the bill before
it could cause any damage to that material.
So what is it that determines heat capacity?
Well, let's get back to the lecture to find out.
Let's dive into some thermo to understand this.
If we ask the question, what quantity would measure the ability of a material to store
energy transferred as heat, then we might think that it has to have something to do
with heat transfer or the variable we like to call squiggly DQ, as well as temperature
since a change in the temperature of the material could be related to its loss or gain of thermal
energy.
In fact, it is the ratio of heat transfer divided by temperature change that is the
quantity we seek.
In general, heat capacity of the material is equal to squiggly DQ divided by DT, or
the ratio of the differential heat to differential temperature.
Now physically, this means a higher heat capacity material can absorb a higher quantity
of heat without changing temperature very much, whereas a low heat capacity material
will take less heat absorbed before changing the same amount of temperature.
And as always, units are very important to know about.
Here you can see that since Q has units of joules and T has units of Kelvin, the heat
capacity units will be joules per Kelvin.
Now we've all felt heat capacities in real life in many different ways.
I know most of us don't go around trying to light water filled balloons on fire, but
beyond that, heat capacity is everywhere.
If you have two different outdoor chairs, one made of wood and one made of metal, and
you leave them out in the sun on a hot day, have you noticed that picking up the wood
chair is comfortable while picking up the metal one feels much hotter?
Or how about how long it takes to heat a cast iron pan over the same flame that much more
rapidly gets a copper pan hot?
Or how much longer it takes to heat your soup in the microwave than say a croissant?
Or how much hotter sand on the beach gets out in the sun compared to say a small pool
of water?
And last, my favorite, heat capacity is why we can burn ourselves on the cheese of a
piece of pizza, but not the crust.
They both came out of the oven at the same temperature, but the cheese stored a whole
lot more thermal energy than the crust.
The biggest and most important example of heat capacity is that of just plain old water.
It's got a very high heat capacity.
And trust me, it's a really good thing that it does.
Because the oceans of our great planet are what regulate its temperature more than anything
else.
Without the high heat capacity of water, the oceans would not be able to serve as the
ultimate moderator, preventing the planet's temperatures from going through wild oscillations
that would threaten life as we know it.
So we've got all these different materials, all with different heat, different capacities
for holding thermal energy.
Let's dig a bit into our thermo to understand what's going on under the hood in these materials.
What is heat capacity more fundamentally?
And what is it about a material that gives it a high or low heat capacity?
To answer this question, let's start by traveling all the way down to the scale of the atom.
The world is pretty awesome down here, where we can see that everything is in motion.
At room temperature, atoms and molecules are flying around at speeds nearing a kilometer
per second.
And this motion is the kinetic energy that gives rise to the temperature of a material.
And we notice that when there is more than one atom, such as in a molecule, then the
kinds of motion can be more than just translational.
For example, the molecule could rotate, and different atoms within it could also vibrate.
All of these different types of movements taken together give rise to the temperature
of the material.
So why am I all the way down here at this scale, looking at how atoms and molecules
move, twist and vibrate?
Well, it's because I'm in search of an answer to the following question.
When a material absorbs heat energy, where does that energy go?
Well, from our discussions and definition of temperature, you probably have a pretty
intuitive feeling already for this.
It goes right into these atomic scale motions.
But take a look at all these different kinds of motion.
Which ones in particular does the heat energy go into?
Does it just get spread evenly over all of them?
Or is there some preferential way in which energy populates atomic motion?
And how, in the end, does that relate to the thermodynamic variables we know and love,
like temperature, internal energy, or entropy?
You might be able to guess from looking at materials at this atomic scale that the more
complicated and the greater the number of degrees of freedom, the more complicated the
question of where heat flows becomes.
You can also probably guess that there would be a big difference between the different
phases of matter, gases, liquids, and solids.
What we're going to do is start with the simplest case and then build up our understanding
from there.
In terms of talking about heat and temperature, the very simplest material is a monatomic
ideal gas.
Remember from our discussion of the ideal gas in lecture 5 that the assumption here
is that the atoms are non-interacting.
So they can bump into one another and collide, but they don't have any inherent attraction
or repulsion between them.
This is a pretty good approximation in many cases, but the more non-interacting the atoms
are, the more accurate the ideal gas model will be.
As we discussed previously for noble gases like helium or neon, this is an excellent
model.
So let's start with some neon gas atoms.
Imagine that we have a container with atoms flying around inside with a given speed.
That would be very fast, and bumping into the container walls as well as one another.
Think of an ideal gas as being like a whole lot of ping-pong balls crashing into one another
at millions of miles per hour, but never getting damaged or dented.
Notice that in this simple material we have only one way in which the atoms can move,
namely by translating, since we just have single atoms.
The atom doesn't rotate or vibrate around itself.
So that means that if I add thermal energy to this material, the only place where it
can go is into the translational motion of its atoms.
Thermal energy in a monatomic ideal gas comprises only translational motions.
Now in order to get from this picture to an expression for the heat capacity, we turn
to the first law of thermodynamics.
Remember that the first law tells us that a change in the internal energy is equal to
the change in energy from heat plus the change in energy due to work.
With just a little bit of math, this allows us to derive two versions of the heat capacity.
One that holds for a constant volume process, and one that holds for a constant pressure
process.
The constant volume heat capacity is defined in terms of internal energy.
It's the partial derivative with respect to temperature.
And the constant pressure heat capacity is equal to the partial derivative of the enthalpy
with respect to temperature.
So this is a good thing.
From the first law, we obtain two different definitions for heat capacities in terms of
thermodynamic state functions, which remember are really handy since they are path-independent.
For the case of the monatomic ideal gas, we know that the internal energy is U equals
three-halves times the number of moles of the gas N times the ideal gas constant R times
the temperature of the gas.
For constant volume, the heat capacity is the partial derivative of U with respect
to temperature, which gives three-halves times the number of moles of the gas N times the
gas constant R.
Now an important observation I'd like to make is that you can see that heat capacity is
an extensive quantity.
If the system size increases, so does the heat capacity.
That makes sense if you think about it.
The more material there is in your system, the more heat you'll be able to put into it.
As is often the case, it's useful to use the intensive version of an extensive variable.
In this case, it could either be the molar heat capacity, where we'd divide by the number
of moles, or what is known as the specific heat capacity, or specific heat for short,
where we divide by the mass of the system.
OK, now the constant pressure heat capacity for an ideal gas can be obtained in a similar
manner.
I'll let you all at home have fun with the math steps involved.
It's just a few partial derivatives.
But here I'll skip right to the answer, which is that the heat capacity at constant pressure
equals heat capacity at constant volume plus N times R.
Written as molar heat capacities, we have that the constant pressure molar heat capacity
equals constant volume molar heat capacity plus the ideal gas constant R.
Note that the heat capacity at constant pressure is always greater than the heat capacity at
constant volume.
So the molar heat capacity for an ideal gas at either constant volume or constant pressure
is simply a constant.
So all ideal gases have the same exact heat capacity.
Well, at constant volume anyway, and that is 12.5 joules per mole Kelvin, regardless
of the gas and regardless of the temperature.
It seems kind of simple.
Could this possibly be right?
In fact, it's really quite a good description.
But let's now move up one degree of difficulty in terms of the system.
Let's go for a diatomic ideal gas.
So these are pairs of atoms, which sometimes also called dimers, which since it's still
an ideal gas, do not interact with one another.
But they have a very important difference from the single atom monatomic ideal case.
As they are translating around at those tremendous speeds, the molecules can now also rotate
as well as vibrate.
These rotational and vibrational motions of the molecules can be activated by collisions.
And so they're strongly tied in with the translational degrees of freedom of the molecules.
But the key point here is that all this energy that was getting bounced around in the form
of translational motion along different directions is now on average shared equally by each independent
degree of freedom.
This is known as the Equal Partition Theorem, which states that each degree of freedom contributes
one half times the Boltzmann constant Kb times the temperature T of energy per molecule.
For a diatomic gas molecule, by the way, that would be most of what we breathe since air
consists primarily of N2 and O2 diatomic molecules.
For these molecules, the shape looks kind of like a dumbbell.
If you take a look, you can see that in addition to being able to translate around the x, y,
or z axes, the molecule can also rotate about any of these axes.
But if the dumbbell is pointing along, say, the z axis, then we can neglect the rotation
about the z axis.
Because the molecules' moment of inertia and rotational energy about this axis are negligible
compared to the x and the y axes.
So not counting vibration for now, for diatomic molecules, there are five degrees of freedom
from translation and rotation.
Three associated with translational motion and two associated from the rotational motion.
From the Equal Partition Theorem, as I mentioned, each degree of freedom contributes on the
average one half KbT of energy per molecule, which means that the internal energy for this
case is equal to five halves nRT.
This gives us a value for the constant volume molar heat capacity of five halves times R,
or 20.8 joules per mole Kelvin.
By the way, you may have noticed that I'm going back and forth between using the Boltzmann
constant Kb and the ideal gas constant R. That's because they're very much related.
The number of moles in a system times the ideal gas constant is equal to the number of particles
in a system times the Boltzmann constant.
This means that the Boltzmann constant is exactly equal to the gas constant divided by Avogadro's
number, which is another constant, roughly equal to 6.022 times 10 to the 23rd.
Take a look at the experimentally measured values for the molar heat capacity of some
diatomic molecules at room temperature.
Notice that they are all very close to this value, so it seems that our model is working
well.
But, and you could probably sense that there was a but, there's a little problem here.
Remember how I just ignored vibrational energy?
Well, that's not correct.
In fact, it's a bit troubling how well the model agrees with the experiment, given that
these entire other degrees of freedom have been ignored.
And vibrational motion adds not just one more degree of freedom, but rather two more degrees
of freedom, one coming from the kinetic energy and the other from the potential energy associated
with vibrations.
You can think of this as two balls connected by a spring for a simple picture.
If you put energy into it, it could change the distance the balls are apart, which would
be a change in the potential energy, or it could change the speed at which the balls
are moving, which changes the kinetic energy.
Therefore, there are two additional degrees of freedom from this single vibration.
The Equal Partition Theorem should really include all three types of motion.
And if we add this vibrational part, we get an extra two half hour contributions, giving
a constant volume molar heat capacity of seven halves r, a whole extra r.
But that's not what we see in experiments.
Or is it?
I'm very excited about what I'm about to show you, because historically, it was truly
one of the most confusing failures of classical physics, and it helped lead to the development
of quantum mechanics.
Now, don't worry, this isn't a course on quantum, and I don't plan to go all quantum
on you here.
But in order to understand what's happening with these heat capacities, we have to look
at the behavior of heat capacity as a function of temperature.
Take a look at this plot, showing the heat capacity for the hydrogen dimer, the H2 molecule,
from 20 to 10,000 Kelvin.
Notice that it's not at all a constant, but rather appears to have three different plateaus.
And this is quite remarkable.
Each plateau occurs at exactly the values we've already predicted for different scenarios.
For the lowest temperature range, we get the value three halves r, same as for a monatomic
ideal gas.
As the temperature rises to room temperature, the molar heat capacity goes up to five halves
r.
The value we obtained for a diatomic ideal gas, including rotational energy, but without
vibrational energy.
And finally, at high enough temperatures, the measured heat capacity is consistent with
our model for a diatomic ideal gas, including all types of motion.
So the key to understanding what's going on here is that the model we derived based on
the ideal gas law and the equal partition theorem is purely classical in nature.
It predicts a value of the molar heat capacity for a diatomic gas that, according to the
figure I just showed you, only agrees with experimental measurements made at very high
temperatures.
In order to understand this, we have to go beyond classical physics and bring quantum
physics into the model.
However, I did promise that I won't go all quantum here and I plan to keep that promise.
But I do want to give you a good, intuitive feeling for what's happening.
Quantum mechanics tells us that the energies of atoms and molecules are, well, they're
quantized.
This means that they can only take on discrete, specific values, as opposed to any old values
they want.
And this means that the energies of those rotational and vibrational degrees of freedom,
they're quantized and can only have certain values.
And the vibrational energies that are allowed tend to be highest with rotational next and
translational lowest.
So at very low temperatures, molecules are colliding about, but the energy they can gain
from these collisions is generally not enough to raise it to the amount needed to occupy
either rotations or vibrations.
That's why, even though rotation and vibration are allowed according to classical physics,
they don't occur at low temperatures.
And that's why we get the same heat capacity as we did for a single monatomic ideal gas.
The pair of atoms behaves just like a single atom, because it cannot rotate or vibrate
at low temperatures.
It can only translate.
The number of degrees of freedom is back to only three.
But as the temperature is raised, the average energy of the molecules increases.
And now enough energy is present to reach the amount needed for the first allowed rotational
In which case, the rotational degrees of freedom become accessible to the system.
And as a result, rotation begins to contribute to the internal energy and the heat capacity
increases.
To be able to access those vibrational states, we need to go to much higher energies, again
because quantum mechanics tells us that only certain energies are allowed, as opposed to
any energy.
And in the case of vibrations, the first allowed energy happens to be quite high.
As you can see in the data for H2, these vibrational modes start getting occupied between 1,000
and 10,000 degrees Kelvin.
By 10,000 Kelvin, vibrations are fully contributing to the internal energy, and the heat capacity
has the value we predicted for this case, namely 7 halves r.
So in a way, where we've come to is pretty cool, since the Equal Partition theorem still
works very well.
It's after all what gives us those plateau values.
It's this that which degrees of freedom are allowed to be Equal Partitioned over is more
complicated, and that is dictated by quantum mechanics.
Now at this point, I'd like to take a step back for a moment to be sure that we're feeling
our oneness with all of this.
Remember that our original goal of this lecture was to understand how thermal energy is stored
in materials.
And we went from that goal to the definition of a new thermodynamic variable, the heat
capacity.
The variable gives a quantitative measure of the heat that can fit, in a sense, into
a material per change in the temperature of the material.
And then we talked about the fact that the word fit here means degrees of freedom at
the atomic scale.
How many different places are there for the heat energy to go?
And that brought us to the calculation of how many degrees of freedom there are in a
given system, starting from the simplest case of an ideal gas.
The Equal Partition theorem states that thermal energy will be spread evenly over all the
degrees of freedom.
But as we just saw, quantum mechanics can get in the way and freeze out some of them,
depending on the temperature.
So as you can see, the heat capacity of a material is indeed quite a complicated variable.
OK, so we've worked our way up the chain, all the way from a single atom to a two atom
molecule.
You might think we have a whole lot more to go, but actually there's only one more
case I want to discuss, namely that of solids.
In a solid, all of the atoms are arranged on a regular lattice, like the one shown here.
In the simplest picture, you could imagine all these atoms held together by a kind of
spring that bonds them together, just as in the case of a diatomic molecule.
And as you're looking at this lattice of atoms held together by springs, think about
which of the three degrees of freedom solids can have.
Is it translational, rotational, or vibrational?
Unlike atoms and molecules, you can see that in fact, solids can only have one single type
of freedom, and that would be vibrations.
The atoms in the solid don't translate, and they don't spin around, since they're pretty
much stuck in their crystalline position.
So when heat energy is transferred to a solid, it all goes into those vibrations of the atoms.
And we can decompose each atom in a solid into having some amount of vibration along
each axis, x, y, and z.
For each axis, we have the two degrees of freedom that a vibration gives.
Taken together, this means that in a solid, there are six degrees of freedom.
Each one brings an amount of one half r to the heat capacity.
So according to this analysis, the molar heat capacity will be three r for a solid.
And this is in fact exactly what happens for most solids, as long as the temperature is
high enough.
This result of three r for the constant volume molar heat capacity of solids is known as
the Doulon-Petit law.
However, just as in the case of the diatomic molecule, there is a very strong temperature
dependence for solids as well.
For some metals, the variation from three r occurs below room temperature.
But for many materials, it occurs at temperatures much higher, meaning that for quite a range
of temperatures, the behavior is much more complicated.
Now take a look at the temperature dependence of the molar heat capacity for these solids.
And to close today's discussion, I'd like to impress upon you why this is all so important,
why I wanted to be sure to have an entire lecture devoted just to heat capacity.
As I mentioned in other lectures, absolute values of thermodynamic functions, like internal
energy and entropy, are not as useful as measured changes in these quantities.
But how can the changes be measured easily?
It's the knowledge of heat capacities that allows us to calculate changes in internal
energy and entropy occurring in real processes from simple experimental measurements.
We already know that internal energy is directly related to heat capacity, and with a little
help from the second law, we can rewrite the heat capacity as TDS divided by DT, giving
us a simple way to measure changes in entropy for real processes.
Be sure not to confuse heat capacity with entropy.
Remember our physical notion of entropy as a measure of the degrees of freedom available
to the molecules in the material.
This implies the materials with more molecular degrees of freedom, that is the ability for
the molecules to translate, vibrate and rotate, have higher heat capacities.
But entropy can only go up with temperature, not so for heat capacity.
Here's a plot of the heat capacity of the chlorine dimer as a function of temperature,
going through each of its different phases from solid to liquid to gas.
Note that the heat capacity can either go up or down as temperature increases, due to
all of the things we've been discussing today, as well as the complexity inherent to the
material changing from one phase to another.
While the entropy of a gas would always be larger than the solid form of the same material,
the heat capacity is actually lower.
So in the end, heat capacity is an extremely important property, both because it tells
us how a material holds on to thermal energy, but also because it connects us through very
simple laboratory measurements with other thermodynamic variables.
Take any material, carefully add a controllable amount of heat while measuring the temperature,
and you've got the heat capacity.
