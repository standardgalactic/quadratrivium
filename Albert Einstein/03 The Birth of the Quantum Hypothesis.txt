Welcome to the third in our series of lectures on Einstein.
In the previous two lectures, we followed Einstein's development from his birth in
Ulm through his early years in Munich, his university studies in Zurich, and the start
of his career as a patent clerk in Bern, up to the threshold of his Miracle Year of
1905, the year in which, in an unrivaled burst of scientific creativity, he published a
suite of papers that completely changed the way we understand the physical universe.
In this, in the next two lectures, we turn our attention to the physics of Einstein's
Miracle Year.
We will focus especially on Einstein's 1905 paper on the quantum theory, his so-called
photon hypothesis paper, and, of course, on his world-famous first paper on relativity
theory.
But first, an interlude.
You'll recall our talking about the fact that Einstein also completed, in 1905, important
papers on molecular dimensions and the phenomenon known as Brownian motion, the seemingly random
movement of small particles, like pollen grains, suspended in a fluid.
We won't have time to talk in great detail about Einstein's paper on Brownian motion,
so let's pause right here before moving on to discuss the quantum theory to digress long
enough to highlight a couple of important points.
The phenomenon of Brownian motion had first been discovered in 1827 by the Scottish botanist
Robert Brown, after whom it is named.
From the start, it caused much puzzlement.
Since it was first noticed with organic entities, like pollen grains, some scientists thought
that it might be evidence for the existence in organic substances of what was once termed
a vital force, a kind of spirit that some people thought was the crucial difference between
organic substances, living things, and inorganic ones.
But then the same phenomenon was observed in non-organic substances, like dust particles.
Many sufficiently small suspended particles behaved in the same way.
What Einstein demonstrated theoretically in 1905 was that the random motions of the suspended
particles is what one should expect as the cumulative effect of the particle's collisions
with the invisible atoms and molecules that make up the suspending medium, like the H2O
molecules in water.
When Einstein's analysis was confirmed experimentally a couple of years later, it was seen as proof
of the reality of invisible molecules and atoms.
One might wonder why that would be so important, but the fact is that as late as the beginning
of the 20th century, many serious scientists, like Ernst Mach, had good reasons for being
skeptical about the reality of atoms.
It was not just that one couldn't see them.
Far more worrisome was the fact that simple atomic models of material substances gave
straightforward predictions for things like specific heats that did not agree with observation.
Remember from the previous lecture that Einstein's physics teacher at the Eta Ha, H. F. Weber,
was well known for his highly precise measurements of specific heats.
Other physicists were equally convinced that the atomic model of matter had to be basically
right, but everyone knew that at the very least, something wasn't right with the details
of the atomic model, and it was only Niels Bohr's introduction of the quantum model
of atomic structure in the early 1910s that finally began to point us toward a more accurate
picture.
In this context then, Einstein's 1905 Brownian motion paper was an achievement of major importance,
and it was quickly recognized as such.
It was important enough to have made the career of any ordinary physicist.
Much the same could have been said of Einstein's dissertation and later paper on molecular
dimensions.
The fact that we now almost forget this other work from 1905 is a measure of how truly extraordinary
were Einstein's papers on the quantum theory and relativity, to which we now turn.
By his own account, as we saw at the end of the previous lecture, Einstein's most revolutionary
idea of 1905 was the photon hypothesis, the notion that light and other forms of electromagnetic
radiation is not made up of continuously spreading electromagnetic waves, but of discrete chunks
of electromagnetic energy called light quanta or photons.
In effect, Einstein proposed that electromagnetic radiation, like light or radio waves, has
a granular or particulate structure, not at all unlike the atomic structure of material
substance.
In and of itself, such a corpuscular view of light and electromagnetism was not new.
Isaac Newton thought that light consisted of corpuscles.
But since the early 19th century, the so-called wave theory of light had prevailed, and for
good reason.
For example, one of the most noteworthy properties of light is what is called interference.
Combine two coherent light rays from different sources, say two pinholes in a screen, and
you commonly get a curious pattern of alternating bands of light and dark called interference
fringes.
This is easy to explain if light consists of waves.
One gets a bright band where the peaks and troughs of the two different rays coincide
and so reinforce one another.
This is called constructive interference.
One gets a dark band where the peaks and troughs fail to line up and so cancel each
other out.
This is called destructive interference.
If a light ray is just a sequence of pellet-like bits of light, then how can they interfere
with one another in such a way?
It's a great mystery.
So when Einstein revived a version of the corpuscular model of light, he was proposing
something rather shocking.
To understand why Einstein felt himself compelled to make such a bold proposal, we have to know
more about the background.
We have to know more about what was working and what wasn't working in the physicist's
efforts to explain light and other forms of electromagnetic radiation in 1905.
In the late 1890s, when Einstein was a student at the Polytechnic in Zurich, the physics
community was nearly unanimous in believing that we were on the verge of achieving a
complete understanding of the physical universe.
It was thought that all of the known fundamental forces, gravity, electricity and magnetism,
had been explained.
In 1687, Newton had explained how massive bodies from grains of sand to planets move
under the influence of forces like gravity.
In 1873, James Clerk Maxwell had explained electricity and magnetism and along the way
had shown that light was just a form of electromagnetic radiation.
Rudolph Clausius and Ludwig Boltzmann had taken the first big steps toward a mechanical
explanation of heat.
They showed that thermal phenomena, like the steady increase of entropy in isolated systems,
resulted from the average behavior of sub-microscopic atoms and molecules.
Moreover, everyone expected that mechanics, electrodynamics and the molecular kinetic
theory of heat, would soon be unified in one grand theory of everything.
This expectation was encouraged by Hermann von Helmholtz's having shown as early as 1847
that all classical physical phenomena respected the overarching law of the conservation of
energy.
This vision of an imminent unification of all physics into a single body of physical
theory that would explain all physical phenomena along essentially classical lines.
This was the vision of Einstein's teachers.
Some curious anomalies had recently been uncovered, however, such as Wilhelm Renkens'
discovery of x-rays in 1895, Henri Becquerel's discovery of radioactivity in 1896, and J.J.
Thomson's discovery of the electron in 1897.
While these discoveries hinted at the existence of deeper layers of structure in nature than
were known up to that time, nearly everyone assumed that incorporating x-rays, radioactivity
and electrons into a unified physical picture were minor problems, matters of detail that
would be accounted for with just a little bit of tinkering, just as they thought that
minor modifications in the atomic theory of matter would clear up the vexing problem of
anomalous specific heats.
Very few people suspected that such anomalies contained within them the seeds of the greatest
revolution in physics since the time of Newton over 200 years earlier.
Faith in an imminent unification of physics was strengthened by steady progress in both
theory and experiment.
But that faith was strengthened as well by the fact that mechanics, electrodynamics and
the molecular-kinetic theory of heat all agreed on three deep and important fundamental
principles.
One might have to fuss with the details to fit the newly discovered electron into the
world picture of classical physics, but the deep principles were thought to be absolutely
secure.
One of these deep principles, an essential assumption of all classical physics, was determinism,
which is the idea that the future course of physical events is fixed down to the smallest
detail by past causes.
In Newtonian mechanics, give me the positions and momenta of all the constituent parts of
a system, like the solar system, at some one moment in time, and I will compute for you
as precisely as you wish the exact future and past behavior of that system.
That's why one can predict the next lunar eclipse and why one can figure out that the
comet seen at the Battle of Hastings in 1066 and depicted on the biotapestry is the same
comet that was described by Newton's contemporary, Edmund Halley, in 1682.
It works the same way in Maxwellian electrodynamics.
Give me the instantaneous state of an electromagnetic field at one moment, which is to say the detailed
specification of all electric and magnetic field strengths, and I will compute the state
of the field at any future or past time.
In a universe governed by strictly deterministic physical laws, there is no chance, no randomness.
Every event is the product of a physical necessity from which there is no appeal.
In fact, things are a bit more complicated than this in classical physics.
In the mid 1890s, Henri Poincare had discovered what we now call classical chaos.
It's a curious feature of many, but not all, classical mechanical systems that they exhibit
a property called sensitive dependence on initial conditions.
What this means is that if the position or momentum of a system at some initial time
is changed by just the tiniest amount, its state at some later time can be changed dramatically.
Sometimes also called the butterfly effect.
The beating of a butterfly's wings in Africa can dramatically change the weather in North
America six months later.
This kind of dependence on initial conditions means that while the system is still perfectly
deterministic in principle, there might be limits on my ability to predict its future
behavior because of limits on my ability to determine precisely the initial state of the
system.
If my initial measurement is off by a small amount, my prediction can be way off.
We now know of many systems such as the global climate that behave in this way.
But in the 1890s, before the days of digital computers, the calculations were almost impossible
to perform, and so the significance of classical chaos was not appreciated.
A second equally fundamental principle of classical physics was the assumption that
all physical processes were continuous in the sense that all changes in nature, however
great, could be analyzed in terms of continuous sequences of ever smaller changes.
In classical physics, there are no gaps or jumps.
The eight ball follows a continuous path through space from where it is struck by the
cue ball to the corner pocket.
At each of the uncountable infinity of intervening instance, it is at some definite place on
the surface of the billiard table.
And when I heat a pot of water to a boil, transforming thermal energy into the mechanical
energy of the bubbling water and the expanding steam, the energy flows continuously from
the flame into the water, like a continuous rush of water over a dam, and not like the
dripping of a leaky faucet.
A third fundamental feature of classical physics, so fundamental that it was not really recognized
as such until after it was challenged by quantum mechanics, was the principle of separability.
This principle asserts that the physical state of any composite system, two or more things
cobbled together, that the physical state of any composite system is simply the aggregate
of the separate states of the individual components, and that the state of each of those individual
components is what it is independently of the states of the other components.
In other words, the analysis of a system into its parts is guaranteed to give a complete
description of the system, because there is no holism in classical physics.
In classical physics, everything is just the sum of its parts.
Classically, the solar system is nothing more than the sun, its planets, and the gravity
that holds them together.
Classically, a magnetic field is nothing but the magnetic force here and here and here
and there, think of the iron filings arranging themselves on a sheet of paper held above
a bar magnet, all of these taken together.
As we shall see, all of these deep assumptions of classical physics, determinism, continuity
and separability, would be overturned by the quantum revolution that Einstein in 1905 helped
to inaugurate.
The quantum revolution began in 1900, five years before Einstein's miracle year, when
Max Planck first introduced the idea of what is called energy quantization to explain the
energy spectrum of so-called black body radiation.
The problem, black body radiation, the problem is essentially that of describing and explaining
how the frequency, which is to say the color, of electromagnetic radiation inside a black
box changes as the box is heated.
The empirical law had been determined with great accuracy by careful experiments, but
attempts to explain that empirical law theoretically had failed dismally.
This is, by the way, another one of those places where high-flying theoretical physics
was helped by the interests of industry.
Precision measurements of the black body spectrum were not being made simply because theorists
told experimentalists that this was an important problem.
No.
As with the precision measurements of specific heats by Einstein's teacher Weber, it was
industrialists who really needed to know how materials behaved under a wide range of circumstances.
For example, knowing how, in detail, the color of the light emitted by a heated substance
changes with temperature, one has another way of determining the temperature of substances
in circumstances where ordinary tools, like thermometers, are of no help, such as when
one has to control precisely the temperature of an alloy in a smelter.
In lecture two, we talked about the fact that Van der Fond Siemens had funded Weber's Physics
Institute at the Athe Ha.
Such links between industry and science were an important, distinguishing feature of the
scientific landscape in German-speaking Europe in the latter 19th century.
This is one reason why so much fundamental progress was made in that part of Europe at
that time, and the comparative lack of such collaborations between science and industry
was one important reason why physics lagged behind a bit in other places like France,
England, and the United States.
Back to the problem that Planck was trying to solve.
A straightforward analysis of the black-body radiation spectrum based on the principles
of Maxwell's electrodynamics yielded a formula that fits well the low-frequency end of the
black-body spectrum.
An equally straightforward analysis based on the principles of mechanics and the kinetic
theory of heat yielded a formula that fits well the high-frequency end of the spectrum.
But no one could give a theoretical analysis yielding a curve that fit the whole spectrum
very well.
Black-body radiation is a phenomenon that involves the behavior of both matter, the
walls of the heated box, and radiation, the visible light and other frequencies of electromagnetic
radiation inside the box.
Matter was well described by mechanics and the kinetic theory.
Radiation was well described by Maxwell's electrodynamics.
The problems seemed to arise when one sought to combine the two descriptions.
Max Planck's great discovery of the quantum hypothesis in 1900 came about more or less
by accident.
First, by tinkering with the two theoretical formulas, he found a single formula, now called
the Planck formula, that fit the empirical spectrum perfectly and contained the two separate
formulas as respectively for low-frequency and high-frequency limits.
But at first, Planck could provide no explanation for why this hybrid formula worked.
Then he noticed a curious thing.
He noticed that he could derive the hybrid formula by abandoning one of the above-mentioned
crucial assumptions of classical physics, the principle of continuity.
More specifically, he assumed that when the molecules in the walls of the box emitted
or absorbed radiation, they did so not continuously, but in discrete units or quanta of energy.
None of this made any sense in classical physical terms.
Their mechanics nor electrodynamics allowed for the discontinuous exchange of energy.
But the Planck formula worked, so it was assumed that it had to be pointing physicists toward
some new, deep insight.
Along came the 26-year-old patent clerk, Einstein.
It was Einstein who, in 1905, would first begin to reveal the deep truth about the new quantum
realm, with his even more radical explanation of the photoelectric effect.
The young Einstein knew all about Planck's invention of the quantum hypothesis in 1900.
Remember, he wasn't taught this stuff in his Atheha physics classes.
That old stick-in-the-mud vapor wasn't even teaching his beginning students about Maxwell,
let alone Planck.
Remember that Einstein was devouring all of the cutting-edge new journal literature on
his own in the library, and romancing Malava with it.
But Einstein studied Planck's works very carefully, and however marginal his place in the professional
physics world at the time, he was one of the few physicists who rightly guessed that Planck
was onto something really important.
To borrow an expression from a dear friend of mine, Einstein knew where the bone was
buried.
The photoelectric effect was as puzzling as blackbody radiation.
It was known that light falling on a metallic conductor could create an electrical current
by knocking electrons out of the metal.
Classical electrodynamics predicted that the energy of those electrons would be proportional
to the intensity or brightness of the light.
But careful experiments proved that the electron's energy was proportional instead to the frequency
of the light, which is to say the number of waves per second, like the frequency indicated
on your radio dial in the case of radio waves.
In other words, the emitted electron's energy depended on the color of the light, not its
intensity.
The intensity of the light determined how many electrons were emitted from the metal,
but not their energy.
As with blackbody radiation, this made no sense from the point of view of classical physics.
Why should blue light produce more energetic electrons than red light?
We should pause to note that the photoelectric effect was yet another one of those phenomena
that had been well studied in the laboratory, in part because of its importance to industry.
It has many important applications today.
You might know it best in the form of laser security systems.
Remember Catherine Zeta-Jones acrobatically maneuvering her way through a tangle of laser
beams in the 1999 movie Entrapment?
Those security devices work on the basis of the photoelectric effect.
The laser beam strikes a metallic surface in the detector.
Electrons are emitted, creating an electrical current.
Break the laser beam, the current shuts off, and the alarm sounds.
Einstein approached the problem of the photoelectric effect with a kind of brilliant flank attack
that nicely illustrates his extraordinary originality.
He started by thinking not about the energy of the emitted electrons, or the frequency
or intensity of the light, but about the entropy of the light.
This was an unusual way of attacking such a problem, but one for which Einstein was actually
quite well prepared by the work he had earlier published in the Anaheim der Physik.
He had written three papers on the foundations of statistical physics between 1902 and 1904.
We needn't dally over their content.
Essentially, Einstein independently reinvented the approach to statistical physics pioneered
by the American chemist Josiah Willard Gibbs.
It was more than just good work, but what is most important is that it trained Einstein
as well as or better than any physicist in the world in thinking about how one employs
statistical methods to investigate such things as energy fluctuations, in gases or radiation,
and the entropy of such systems.
Ludwig Boltzmann, the other great pioneer of statistical physics, had shown that the
entropy, we symbolize it by S, entropy of a gas, which is after all just the degree
of disorder of its molecular constituents, Boltzmann had shown that the entropy S is
related to the probability W, that those molecules were in some specific configuration
by a now famous formula, S equals K log W. K is called the Boltzmann constant.
The entropy is the logarithm of the probability.
In 1905, Einstein calculated the entropy of high-frequency electromagnetic radiation
and found that it obeyed a formula of exactly the same kind.
He then made a bold conjecture.
If the entropy of a gas, as described by Boltzmann, and the entropy of high-frequency
radiation obey the same kind of formula, then just as a gas consists of lots of tiny, mutually
independent, billiard ball-like molecules, so too, high-frequency radiation must consist
of tiny, mutually independent bits or quanta of electromagnetic energy.
And having postulated the existence of such energy quanta, Einstein easily showed that
the energy E of each quantum was related to its frequency, nu, by another now famous formula,
E equals h nu, where h is the famous Planck's constant.
In 1900, Planck had already proposed that when matter admits or absorbs radiation, it
does so in discrete amounts.
Einstein was now proposing that high-frequency radiation always exists in the form of independent,
discrete quanta of energy, these particles of electromagnetic energy later being named
photons.
In effect, Einstein was suggesting that electromagnetic energy was exchanged with matter in quantized
bits, precisely because electromagnetic radiation consisted of such quantized bits of energy.
If light or other forms of electromagnetic energy live in the form of quanta whose energy
is related to the frequency of the radiation by the formula E equals h nu, then it's obvious
why the energy of the electrons emitted in the photoelectric effect is proportional to
the frequency of the radiation, not its intensity.
It is simply because quanta of higher frequency carry more energy.
Einstein was right to describe the idea of light quanta as revolutionary, because it
was quite literally impossible to fit it into the framework of classical physics.
If electromagnetic radiation really consisted of discrete quanta, then Maxwell's Electrodynamics,
which described electricity and magnetism in terms of continuous fields, was simply false
at the micro level.
A measure of how radical Einstein's light quantum or photon hypothesis was is that it
took more than 20 years for it to be accepted even by such famous champions of the quantum
theory as Niels Bohr, the inventor of the quantum model of the atom in 1913.
That Bohr model of the atom assumes that electrons revolve around a tiny central nucleus in discrete
orbits, each with a sharply defined energy.
The Bohr model also postulates that those electrons jump instantaneously from a higher
to a lower orbit when they admit a discrete amount of electromagnetic energy of a specific
frequency, or conversely that they jump from a lower to a higher orbit when they absorb
electromagnetic radiation with an energy corresponding to the energy difference between the two orbits.
The Bohr model actually completes Einstein's story about the photoelectric effect, because
it explains why sufficiently energetic incoming radiation can kick an electron entirely out
of the atom, and yet even such a revolutionary as Bohr couldn't accept the photon hypothesis
for a long time.
But Einstein too had doubts, doubts that he almost surely harbored from the very start,
doubts that he was expressing publicly within a few years.
Here's the problem.
Remember that Einstein had reasoned by analogy.
He had shown that the entropy of high frequency radiation obeyed a formula exactly like Boltzmann's
formula for the entropy of a material gas.
And so he reasoned, just as a material gas is made up of lots of discrete, mutually independent
atoms or molecules, high frequency radiation behaves as if it consisted of discrete, mutually
independent quanta of electromagnetic energy.
But Einstein realized that that argument works only for high frequency radiation.
More specifically, the Boltzmann-like formula for the entropy of the radiation was valid
only in the limit as the frequency goes to infinity.
Here things get just a bit complicated, so slow down and let's think this through carefully.
The corpuscular analogy works only in the limit of infinitely high frequencies.
In that limit it is as if, those are Einstein's words, as if, it is as if radiation had a
granular structure.
But in reality there is no radiation with an infinite frequency.
Therefore in reality, no radiation behaves exactly as if it had such a granular structure
and certainly not low frequency radiation.
Therefore it is not strictly speaking true that radiation consists of discrete, mutually
independent quanta of energy.
In fact, radiation of all frequencies has a sort of chameleon-like nature.
The higher the frequency, the more it behaves like a radiation gas made up of mutually independent
quanta, but the lower the frequency, the more it behaves as if its constituent bits were
not mutually independent.
Take a deep breath.
You've just had your first introduction to one of the deepest truths of the quantum realm,
one that we'll talk about more in a couple of later lectures.
You've just reasoned your way exactly as Einstein did to the idea that radiation has
a dual nature, both wave-like and particle-like.
In as much as its constituents are not mutually independent, radiation behaves like waves
that are capable, as we saw, of interfering with one another.
In as much as radiation's constituent bits are mutually independent, radiation behaves
like a classical Boltzmann gas.
You've also just reasoned your way exactly as Einstein did to the first hint of another
deep truth about the quantum realm, something that we now call entanglement.
As we now know, and as Einstein started to suspect in 1905, in as much as the different
bits of radiation are not mutually independent of one another, those bits lose their separate
realities.
Their realities become entangled with one another, and here we confront a violation
of the third of the three above-mentioned deep principles of classical physics, the principle
of separability.
Are you confused?
Good.
In 1905, Einstein was himself very confused about this, too.
As we will see, it took him 20 years just to figure out what this bizarre aspect of
nature that we now call entanglement really was, and to convince himself that it would
be an abiding feature of the quantum mechanical picture of nature.
And once he got clear about what it meant, it made him a really unhappy guy and led to
his becoming ironically the most famous critic of the quantum theory.
Because however much Einstein was a revolutionary, he was also very conservative in this one
respect, namely he actually could not let go of the principle of separability.
He was more attracted to it than he was even to the principle of determinism.
Why ironically Einstein couldn't let go of separability is something that we will talk
about in a couple of later lectures, but it has to wait, because it is something that
we cannot understand until after we also learn about relativity theory, which is the topic
to which we turn in the next two lectures.
