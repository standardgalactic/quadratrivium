In this lecture, we're going to look at developments in calculus in the early 19th century. Calculus,
as I explained earlier, really builds on the work of Leibniz. And Leibniz explained calculus
in terms of the language of infinitesimals, these itty-bitty pieces that are positive,
they're larger than zero, and yet they are smaller than any actual positive number. And
they're very difficult to work with, and to really get a handle on, and especially because
you don't just need infinitesimals, you need infinitesimals of infinitesimals, and infinitesimals
of infinitesimals of infinitesimals. Now throughout the 1700s, this really wasn't a problem. There
were enough people who had a good intuitive sense of what was going on that they were
able to work with this idea. And as I said, even modern physicists and engineers often
work with this idea of infinitesimals, even though they can't say exactly what it is. But
this always was a problematic point for mathematicians working with the calculus. And there's a very
famous essay that was written by Bishop George Barkley in 1734, in which he argues against
the claim that science is rational, and he attacks the rationality of science by actually
getting to the rationality of mathematics and of calculus itself, and pointing out that
that sits on an irrational foundation, this idea of the infinitesimal. And I'd like to
read a short piece from that essay. Now to conceive a quantity, or than any of the least
finite magnitude is, I confess, above my capacity. But to conceive a part of such infinitely
small quantity that shall be still infinitely less than it, and consequently though multiplied
infinitely shall never equal the minutest finite quantity is, I suspect, an infinite
difficulty to any man whatsoever. But how are we to make sense of calculus if we get
rid of these infinitesimals? What do we really mean by the derivative, the dy over dx, if
it isn't a ratio of infinitesimals? What do we really mean by the integral of a function
multiplied by dx if that dx isn't an infinitely narrow piece of the rectangle? Now as I said
in the 1700s, mathematicians worked with this idea of infinitesimals without worrying about
it too much, but it was a constant nagging problem. And in the early 1800s, there were
three events that happened that really forced the mathematical community to go back and
look at the very foundations of calculus in an entirely new light and try to get rid
of these infinitesimals. I should say that it actually is possible to define infinitesimals
precisely and rigorously and to build a calculus on them. In the early 1800s though, the three
problems that led mathematicians to go back and try to get rid of infinitesimals were
first of all that you didn't have just a small group of scientists who were using calculus.
You were starting to train a large cadre of engineers in order to do calculus. In particular
the Ecole Polytechnique, which had been founded in 1794, was established precisely to train
engineers. And part of the education of these engineers was to learn calculus. And if you
wanted to be able to explain these ideas not to sophisticated scientists, but to young
men who were going to go out and try to apply it, you had to be quite clear about what you
were explaining to them. Another reason for needing to know exactly what we mean by calculus,
by the foundations of the derivative and the integral, was the fact that people now in
the early 1800s were beginning to think about how to apply calculus to these complex valued
functions. They were now looking at functions not just of a real number, but functions of
a complex number. When we've got a function that has a real number as its input and a
real number as its output, we can graph a curve that represents that function and it's easy
to talk about the area underneath the curve or the slope of the curve. But when we take
a function that goes from a complex value to a complex value, now the domain sits in
two-dimensional space and the range sits in two-dimensional space. And in order to graph
it, we actually need to have four-dimensional space with the two-dimensional plane of the
input or orthogonal to both of the dimensions of the two-dimensional plane of the output.
And you can't visualize a four-dimensional space very easily. So what do we mean by the
integral in this case? What do we mean by the derivative in this case? But the third
reason I think was the most important in the early 1800s and that was the development of
Fourier series. And before I explain Fourier series, I want to talk a little bit about
Joseph Fourier because he's a fascinating character. He was born in 1768. His original
intention was to become a monk. He had entered the monastery when 1789 came and the French
Revolution broke out. And a young man such as Joseph Fourier was realized that life
would be much more exciting if he went to Paris. And so he did and he got himself attached
to the scientific community there and learned a great deal of science and mathematics from
the great people who were living in Paris at the time. In 1794, the École Normale
was established. As I said in an earlier lecture, this was established in order to train future
French teachers of science and mathematics. And Joseph Fourier got himself enrolled as
one of the first students at the École Normale. In his first year there it was realized that
he knew much more than the other students. In fact, he knew enough that in the second
year he was named a professor at the École Normale. And shortly after that he managed
to move up to a position teaching at the École Polytechnique. He eventually would become
a science advisor to Napoleon. And when Napoleon invaded Egypt, Joseph Fourier was one of the
scientists that he took along. Napoleon took scientists with him because he wanted people
who could identify those antiquities in Egypt that should be taken back to France. And in
fact, if you go to the Louvre today, you will see that some of the greatest of the Egyptian
antiquities now are housed in the Louvre as a result of this Napoleonic expedition and
precisely as a result of the work of Fourier and others who selected what should be shipped
back to France. Fourier actually was very interested in Egyptian archaeology. He wrote
a very important two-volume work in which he described the antiquities that he saw at
that time in Egypt. And this really marks the beginning of modern Egyptian archaeology.
And his work describing these antiquities is very important for Egyptian archaeologists
today because he described many things that in fact no longer exist or have been severely
damaged since Fourier was there. When Fourier came back to France, Napoleon
appointed him as precept of the Department of Isaire. That's the department in the French
Alps that has its capital at Grenoble. And Napoleon was setting up a French civil system
of government. It was Fourier's job to actually set up the government, create a governmental
structure from the ground up for the Department of Isaire. That certainly must have been an
enormous task and yet at the same time he was doing scientific work. And one of the great
scientific questions of this time was trying to model the flow of heat. How do we come
up with the equations and the mathematical models that show how heat will move through
a body? And one of the things that Fourier realized was that the flow of heat was actually
closely related to the kind of modeling that Euler and D'Alembert had done in the 18th
century looking at vibrating strings. That in fact the same kinds of differential equations
that are used to model vibrating strings can be modified slightly in order to model what
goes on as heat is flowing. Now one of the keys to modeling a vibrating string is to
use the trigonometric functions, the sine and the cosine. These are nice periodic functions,
they set up a wave which is what we expect to see when we're looking at a vibrating string.
And what Fourier realized was that it's exactly these trigonometric functions, the sine and
the cosine, that are essential in order to be able to model and describe the flow of
heat. And so he considered a thin bar with a uniform supply of heat along one edge and
he was interested in how the heat then would spread through this bar. And what he needed
to do was to describe this constant heat in terms of these oscillating functions, the
sine and the cosine. What he actually needed to do in purely mathematical terminology is
to take the constant function 1 and write it as a sum of cosine functions. And one of
the incredible results that Fourier realized was that you really could do that. 1 is equal
to 4 over pi times the sum of cosine functions. And that sum of cosine functions is the cosine
of pi x over 2 minus a third of the cosine of 3 pi x over 2 plus a fifth of the cosine
of 5 pi x over 2 minus a seventh of the cosine of 7 pi x over 2 and continue that arbitrarily
far out. If we just take the first cosine function, we see the nice clear oscillation.
But as we add more and more of these cosine functions together, we see that the oscillations
become smaller and tighter and the sum of the cosine functions begins to close in on the
constant function 1. So that if I go out and take a hundred of these terms, you now see
just a very little wiggling around this constant function 1 and you actually then get at the
limits that you're looking at. This is only valid for values of x between minus 1 and
plus 1. As you get out toward the edge, you get a little shoulder, a little hump, and
then the whole function jumps down and it wiggles around the values minus 1. And then
as you get out to minus 3 or plus 3, you get a little shoulder, what's called the Gibbs
phenomenon, and then you jump back up and you oscillate around plus 1. So you get this
function that's jumping between minus 1 and plus 1 with tighter and tighter oscillations
around these constant values. And as you take more and more terms, the oscillations become
progressively tighter until in the limit, as you take infinitely many of these terms,
you actually get a function that's the constant function 1 and then it jumps down to minus
1 on either side and then jumps back up to plus 1 on either side and so on out to infinity.
Now that's a very strange function because that's a discontinuous function. That's a
function that has jumps and we were building it out of these nice cosine functions. And
the mathematicians began to wonder what's going on is this whole procedure legitimate.
If you take a function, when can you represent it as this kind of sum of cosines or very
often what you need is not just a sum of cosines but a sum of cosines and a sum of
signs. This process of taking a function and decomposing it into a sum of signs and cosines
is what would come to be known as Fourier analysis. And actually one of the ways of
thinking about this is in terms of music, is in terms of the vibrating string, what's
really happening is that you're getting different frequencies on the different pieces and each
of the cosine functions is representing one of the harmonics, one of the overtones of
the base tone that is represented by the very first trigonometric function that you look
at. What you're really doing is taking some arbitrary expression and breaking it down
into a basic tone and the various overtones that are on top of it. Now it seems very strange
that this is what's really going on in heat but as people would discover throughout the
19th century and the 20th century almost every kind of physical phenomena actually can be
broken down in this way using a Fourier analysis. Now Fourier set out a method for discovering
what these trigonometric functions should be. The problem was do you really know that
this infinite sum of trigonometric functions really approaches the function that you're
interested in? This is the question of the convergence of the Fourier series. As you
take more terms, does it get you progressively closer to your target function that you want
to do the Fourier analysis on? And that would be a driving question not just of the early
1800s, that would be a driving question right through the middle of the 20th century. Augustin
Louis Cauchy was undoubtedly the greatest of the French mathematicians of the 1820s.
He was born in 1789. He taught at the École Polytechnique and in 1821 he started writing
his great book on calculus, what was called the Core d'Annalise. His intention was that
this would be a book that the students at the École Polytechnique would use to learn
calculus. In fact it was a total disaster as a textbook. The students at the École Polytechnique
protested against it and they actually stopped Cauchy's writing of it. It was used the first
year and then it was never used again. But the Core d'Annalise was the basis for Cauchy's
work on refounding the foundations of the calculus. And to see what's going on, let's
consider a problem of the differential calculus. Finding the slope of the function x cubed
at x equals 1. And what we can do, and this is certainly the way Leibniz or Newton thought
of this initially, is you approximate the slope by looking at the difference in the
function divided by the difference in the variable. So if my function is x cubed, I'm
looking say I look at it at 1 and I look at it at 1.1. So the change in the function is
1.1 cubed minus 1 cubed divided by the change in x, which is 1.1 minus 1, or that turns
out to be about 3.31. As I take smaller and smaller changes in x, what is happening is
that this ratio gets closer and closer to 3. What Leibniz argued is that if I take an
infinitesimal change in x, I now get a ratio that is exactly equal to 3. And this is what
Cauchy would not allow. What Cauchy actually did was to go right back to the way Eudoxus
and Euclid and Archimedes argued about numbers and these kinds of limiting processes that
they were doing in the integral calculus, which was to look at that ratio and say the
ratio cannot be larger than 3 because I can always take a change in x that is small enough
so that my ratio, whatever number I take bigger than 3, my ratio is less than that.
And I can also force this ratio to be larger than any number that is less than 3 just by
taking that change in x to be arbitrarily small. So I, given any number that is larger
than 3, I can force the ratio to be less than that. Given any number that is less than 3,
I can force the ratio to be larger than that. The ratio must be 3. And this is the basis
for Cauchy's view of the calculus really based on the ancient Greek idea of how do
you compare two irrational numbers. And that would be our modern basis for calculus. Today
we couch it in the language of epsilons and deltas, and actually Cauchy did use these
epsilons and deltas. But the idea that sits behind them is this idea that it can't be
a smaller number, it can't be a larger number, it must be exactly the 3. Now as Cauchy was
trying to explain the foundations of calculus, he had a lot of trouble doing this. And he
came up with things that weren't quite right. And a number of the young mathematicians in
Paris at the time of whom Niels-Henrik Abel was one, realized this, and there's a marvelous
quote from Abel. In 1826 he wrote back to his teacher in Norway and he wrote, Cauchy
is crazy, and there is no way of getting along with him, even though right now he is the
only one who knows how mathematics should be done. What he is doing is excellent, but
very confusing. An example of this confusion comes from the Cordon Alize of 1821 when
Cauchy actually proves that every sum of continuous functions is continuous. And Abel in one of
his papers that he published in 1826 wrote, it appears that this theorem suffers exceptions.
And of course it does. The Fourier series is a prime example of an exception. This is
an infinite sum of continuous functions, but as I said it gives us this discontinuous function,
which is jumping between plus 1 and minus 1. A number of people worked on this question
of the Fourier analysis, and when does it really work? When does this sum of sines and
cosines actually converge to the original function? Very important work was done by
another young mathematician of the 1820s, Gustav Lejeune de Riquet. He was born in 1805,
would die in 1859, and we're actually going to see him coming up again in a later lecture.
In 1829 he showed that Fourier analysis is valid as long as you've got any monotonic
function. A monotonic function is one that is always increasing or always decreasing,
and you can extend that idea so as long as the function changes direction a finite number
of times, the Fourier analysis is going to be valid. But there are functions that even
within a finite interval oscillate infinitely often, and Dirichlet's analysis simply
doesn't work for those functions. Throughout the 19th century a lot of people would be
looking at this question of convergence of functions, convergence of the Fourier series
for functions that oscillate infinitely often. And the final theorem would actually not be
done until 1966. It was a Swedish mathematician, Leonard Carlson, born in 1928. He would then
go on and teach at UCLA for much of his career. And in 1966 he was able to prove that if
the square of the function can be integrated, then not only does the Fourier series exist,
but it actually converges to the original function. Carlson did a lot of important work
in analysis throughout his career. He is still alive at this moment. And in the year 2006
he was awarded the Abel Prize. The Abel Prize is a prize awarded by the Norwegian government
quite appropriately because it is named for Abel. It is the exact equivalent of a Nobel
Prize. It is a fairly recent prize. It was only established in the year 2002. But it
goes to mathematicians who have done important work in their careers. And very appropriate
that Leonard Carlson should get this award named for Niels Henrik Abel.
I want to finish this lecture up by talking about another very important mathematician
who really understood what was going on in calculus and really set the stage for a lot
of what other people would do with calculus in the 19th and then on into the 20th century.
And that's Carl Weierstrass, born in 1815. He would die in 1897. He was someone who had
started out in university as a law student. He was not particularly interested in studying
law. We know that he got involved in all kinds of pranks and duels and basically wasted his
time at university and eventually was expelled. But what he really loved was mathematics.
And so he went back and he decided to become a high school teacher, actually in the German
system a gymnasium teacher. And so he went to the Munster Academy and he had the very
great luck that one of the mathematicians who was teaching at the Munster Academy at
that time was Gurderman. And Gurderman was one of the few mathematicians who had really
studied elliptic functions in detail. And Gurderman wanted to be able to teach a class
on elliptic functions. But most of the prospective gymnasium teachers were not at all interested
in learning about elliptic functions. But Weierstrass was. Gurderman taught a class to
one student who was Weierstrass. And Weierstrass was fascinated by what was going on with these
elliptic functions, or as he usually referred to them, abelian functions. Weierstrass would
go on to become a high school teacher. He taught a wide range of subjects. He taught 30 hours
a week in addition to the mathematics. He taught German language, botany, geography, history,
penmanship. He even taught gymnastics. But he was also working on these elliptic or abelian
functions that Abel had studied. And in 1854, he published a groundbreaking paper called On
the Theory of Abelian Functions, in which he laid out a new and comprehensive way of
looking at abelian functions. And it was a paper that really brought him to prominence
within the mathematical community. The following year, he was awarded an honorary doctorate
at the University of Königsberg. Shortly after that, he obtained an adjunct position at the
University of Berlin, and he would go on to hold a chair of mathematics at the University
of Berlin, taking over that chair in 1864. Over the period from the 1850s into the early
70s, while he was at the University of Berlin, he would lecture on analysis, on the calculus.
And he's the one who really explained the fundamental ideas, who clarified many of the
things that Koshy and Abel and Dirichlet had wrestled with in the 1820s and the 1830s.
Weierstrass really saw clearly through to what was going on. Weierstrass realized the
importance of understanding the real number line and the complexity of the real number
line, and he encouraged his students to think about it. One of his students was Georg Cantor,
who would go on to develop set theory and explore all of the complexities of the real
number line, and he was motivated by Weierstrass's lectures, in which Weierstrass had explained
the importance of understanding real numbers. Many of the results that Weierstrass came
up with, he did not publish. He simply expounded them in his lectures. His students then would
go on to build on those results and state them and get credit for them. Although much
later after Weierstrass died, many of his lectures were collected and published, and
it was discovered that his students were taking ideas that had originally come from Weierstrass.
In fact, Weierstrass was an outstanding teacher. He had 41 doctoral students. He really trained
the next generation of German mathematicians. If you take a look at his mathematical genealogy,
all of the people who can trace their mathematical doctorates back through their advisor to their
advisor's advisor to their advisor's advisor, there are a total of 12,508 mathematicians
who can trace this back to Weierstrass. Some of the other famous mathematicians who studied
with Weierstrass are Killing, Frobanius, and Schwartz. Schwartz in particular would be
someone who would lay the foundations for Einstein's work in geometry and general relativity.
I want to close by mentioning one of his students and bringing up another woman mathematician
of the 19th century, and that Sophia Kovalevskaya, she was usually known as Sonja Kovalevskaya.
Born in 1850, she would die in 1891. I talked about the difficulty in the early 19th century
of being Jewish and trying to pursue a career in mathematics. It was even more difficult for
women, even by the end of the 19th century. Sonja Kovalevskaya was able to go to university
as an undergraduate, but she could not find a university that would accept her for graduate work.
But what she did do was to go to the University of Berlin where Weierstrass was teaching
and arranged to take lessons with and sit in on the classes that Weierstrass was doing,
and Weierstrass became her advisor in an unofficial capacity. And in 1874, when she did
her doctoral thesis on elliptic or abelian functions, it was Weierstrass who tried to get
her an official doctorate. It turned out to be impossible to do it at the University of Berlin,
but he had good contacts at the University of Göttingen, and he managed to convince the people
at Göttingen to give a doctorate to Sonja Kovalevskaya. And Sonja Kovalevskaya would become the first
woman to hold the position of chair of mathematics in a European university. This is 1889 when she
would be appointed by the University of Stockholm. Unfortunately, two years after she joined the
faculty at the University of Stockholm, she contracted the flu, which was complicated by
pneumonia, and she died. In the next lecture, we are going to be looking at Gauss' most famous
student, someone who also studied with Weierstrass, although he did his undergraduate work with Weierstrass.
His graduate work would be done with Gauss, and that is Bernhard Riemann, someone who had no
students, no doctoral students, but who nevertheless had a profound influence on the development of
mathematics. He fundamentally changed the way we think about questions in complex analysis,
the calculus of complex numbers, how we think about geometry, and how we think about number theory.
