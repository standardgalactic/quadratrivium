Welcome back. Life, of course, is the source of most mathematical ideas. We look at things
that happen in the world, and then we try to abstract from those some principles that
become the mathematics that we're trying to develop. And this is certainly true in
the case of talking about probability and randomness. But in today's lecture, we're
going to be looking at some phenomena that we see in everyday life that involve random
fluctuations. For example, think about the stock market. We look at how the price of
a stock varies over time, and if we look particularly at short periods of time, minute by minute,
we see that the stock price varies in sort of a random up and down kind of a way. Consider
an election evening when we're counting ballots from a ballot box, and perhaps instead of
thinking of a national election where there are millions of ballots, suppose we just have
a small ballot box where we literally are taking out one piece of paper at a time, and
we count one ballot at a time. Well, then one candidate seems to be going ahead, and
then the other candidate gets a few votes, and it goes down and up, and that's sort of
a random kind of a process. Or we just flip a coin. We take a coin, we flip it, we get
a heads and a tails and a heads, and sometimes the heads get a head, sometimes tails get
a head, and that's sort of a random variation between heads and tails. In sciences, there
are lots of these examples. For example, in biology, we'll be talking in two lectures
from now about genetic drift, how the kinds of aspects of the traits of the population
can vary just randomly from time to time. And another example is Brownian motion. You
may have heard about this sort of grain of pollen is sitting on top of the surface of
water. It seems to move in a sort of a randomly fluctuating way. All of these are examples
that involve a process of just taking random kind of a motion, and so what we're going
to do, as mathematics is want to do, is to abstract all of those ideas into some simple
essential ingredient and then explore that. So what are we going to think as the simplest
model for this kind of random fluctuation? Well, we're going to call it, the name that
it goes by is a random walk. What we envision is the following, that we decide to go for
a walk, but we're in a particularly indecisive mood. So instead of having a particular destination,
what we do is we just go outside our door and we say, I'm going to flip a coin. And
if the coin turns out heads, then I'm going to go one block north. And then when I get
there, I will flip the coin again. And if it's heads, I'll go another block north. But
if it's tails, I'll go a block south. And so in this, in this fashion, every block,
I flip a coin and randomly decide to go one block north or another block north of its
heads or one block south, if it's tails. And in that way, we have something called a random
walk. Now I'll give you, I'll show you a graphic to illustrate this sort of random
perambulation. So here we start at the point zero in our random walk. And we just take
a step because we flipped the coin and it came out heads, we went one block to the north.
And then here we flipped heads again. So it went another block north, we flipped heads
again. So it went one block north again, heads again, one more block north. Oh, there we
flipped it finally tails and we went one block south, another block south because of another
tails that we flipped and so on. And this continues on and on. And we just zoom back
and forth, back and forth in our sort of a jittery kind of a way. Now it's hard to see
this description of a random walk. And consequently, we're instead going to look at it in a different,
with a different kind of a graphic that is easier to see. And the way that we'll, we'll
see this new graphic is that we're going to expand the time out to the right so that
as we take our random walk, the steps are going up and down just as they were before.
But we'll record them by also saying what time that is, what number of flip that we're
taking in order to, to be able to see better where we are at different times. So here we
are, it's the same random walk, but we can spread it out now over time. And, and here
we'll speed it up and you can see the random walk that we're taking, this is a, after a
hundred steps, we get right to here. So this is recording a hundred step random walk. And
so I hope that, that you follow me that at, at each one of the hundred flips of the coin,
we're recording where we are relative to our original position. So at, at this point here,
we've flipped, for example, in this case, six more heads than tails at, at that point
after we've flipped about 30 heads or tails. When we're here at the axis, that means we've
flipped exactly the same number of heads and tails at that point, because that, that's
what it means to be back to the original position where we started. So this is the way that
we're going to describe our, our random walk. Now, after we've, we've thought about this
random walk, it's a rather abstract kind of an idea. And so the, the first question that
we, we need to ask ourselves is, well, what kind of, of question should we be asking about
this kind of random behavior? What kind of issue comes up? Well, one kind of issue is,
is the question of where are we going to get to if we take this kind of a random pattern?
Do we expect that we're just going to hover around the, the origin? That is the place
that we started and we're just going to sort of go back and forth and stay in a sort of
bounded area? Or will we sometimes go way off into the distance? Of course, the answers
are all going to be probabilistic. Since what we're doing is, is taking a, a phenomenon
that involves chance, namely just flipping a coin, we know that there's some chance
we'll just go back and forth, back and forth, back and forth forever. But then there's
another chance that we'll go further out and we have to ask ourselves some, some questions
about what are the chances that we go a great distance or that we hover around zero? So
one basic question that we can ask is, well, what is the probability that at some point
in the future we return back to where we started? In the random walk that we saw demonstrated
before, we saw that we did return, in fact, several times in that, in that 100 steps.
But what is the probability that we return? Well, most of the time we just sort of head
off and never get back to where we started, or will most of the time we get back to the
beginning? So that will be our first question that we undertake. And what we're going to
do is a demonstration of what the probability is that when we take a random walk, we will
at some time in the future return back to where we started. So let's think about this.
Well, first of all, when we flip our coin, the first step is going to take us to a distance
one away from where we started. So if we think of our, our blocks as being numbered with
zero as where we start and then one is in the positive north direction and minus one
is the negative south direction, then after one step we're going to be at position one
or position minus one. So if we're trying to compute the probability of returning to
where we began, after that first step, it's the same question as what's the probability
starting at position one that we get back to position zero. You see, or minus one to
get back to zero, but since they're symmetric, it's the same probability. So let's assume
we get to, we start at position one and we're asking what's the probability of getting back
to position zero? Well, we can think about this in the following way. First of all, there's
a 50% chance that we immediately return right back to zero because if we shake a tails,
we go south and therefore we go from one back to zero. So the probability that we, starting
at one that we get to zero, that probability P is equal to one half, which is the probability
that we shake a tails, plus one half, which is the probability that we shake a heads,
times Q, where Q is another probability, it's the probability that starting at two a random
walk will eventually get to zero. You see, we made negative progress, that is, that is,
we went to two when we were trying to get to zero. So we went to two and now we're asking
what's the probability of starting at two getting to zero? Well, here's then what we
can think about. In order to get from two to zero, we first of course have to get back
to one. What's the probability that we'll get back to one starting at two? Well, that's
the same question that we were asking to begin with. What's the probability of going from
a position to one block lower down? So that probability is P. That's the unknown probability
P, which we're striving to understand. So in order to get down to, from two to zero,
we first have to get to one, which we do with probability P, but then we know that the probability
of getting from one back to zero is once again probability P. So that means that Q entails
doing something that has probability P, getting to one, and then again doing something that
has probability P, namely going from one to zero. So Q is equal to P squared. Therefore,
P is equal to one half plus one half Q, which is equal to one half plus one half P squared.
Now just a little tiny bit of arithmetic multiplying through by two, gathering terms, and remembering
how to factor this little equation, we see that in fact P is equal to one. What this
says is that with probability one, when we take our random walk, we will eventually return
back to zero. Now you can, this might bring up in your mind a question, namely the question
that you can say, well, wait a minute, suppose that every time I flipped heads every single
time and I just kept walking further and further away, I never returned to zero. I thought you
told me, you're asking yourself, that if something has probability one, then that means that
it'll happen every single time. And yet here I've demonstrated an example where it doesn't
happen that you return back to the origin. The wrinkle is that here we're talking about
a probability that involves infinitely many possibilities. That is to say there are infinitely
many random walks you can take if you just continue to flip forever. And although there
are some that do never return to zero, the fraction of those that never return to zero
is smaller than any positive number. And therefore we say that the probability is one that we
return to zero even though it is possible that we won't return to zero. So this is the
wrinkle about infinity that involves the probability being one even though it is possible that
you will never return. But in practice you will always return to zero. The next question
that we can ask is, well, what's the probability that in flipping a coin will go a certain
distance away, such as will we ever get as far as 100 blocks away from where we started
by just randomly flipping a coin? Well, the answer to that is something that we have actually
thought about before because now we realize with probability one, we will return back
to where we started. But we know that there is some non-zero chance that we'll flip 100
heads in a row. There's always a non-zero chance that we'll flip 100 heads in a row.
Remember the monkeys that we met last time? The monkeys that said that even very rare
probabilities will happen if we go on forever. And there is a non-zero probability, one over
two to the hundredth, that we will flip 100 heads in a row. Well, if with probability one
we return to zero, then that means that with probability one we'll return to zero again,
and return to zero again, and again and again. In fact, infinitely many times we'll return
to zero. And so we have infinitely many opportunities to flip our 100 heads in a row, and that's
with probability one, one of those times that will happen. So that means that we're
going to get to any distance, and by the way, of course, in fact, it's possible to get
to 100, much more likely to get to 100, not by starting at zero and flipping 100 heads
in a row. In fact, we would just sort of tend to oscillate and then get up to 100 by sort
of jiggly way. But the proof that it's definitely going to happen is by observing that you're
going to be back at zero infinitely many times, so you have infinitely many chances to do a
rare thing, like flipping 100 heads in a row. So what we've seen then so far is that you
will definitely, by just this random process, get to any distance away from the origin.
Now, an implication for this is something called the gambler's ruin. The gambler's ruin
is the following scenario. Suppose that you're a gambler and you go to a casino and you start
rather well with $2,000, and you're betting at this casino in each bet, let's say, is
a $200 bet. And let's suppose that this casino, which doesn't exist in the real world, just
gives completely fair odds. It's a fair game. And in fact, let's suppose that the game just
consists of flipping a coin, and if the coin comes up heads, then you win $200 more. You
get $200 additional money, you get your $200 back, and you gain $200. And if it's tails,
you lose $200. And you start playing this game, just flipping coins. Now, this is a
fair game, and so on average you don't win or lose, but you're taking a random walk in
the same amount of money that you have. Now, what have we just proved? Well, we've just
proved that with probability one, you will get back to where you started, and with probability
one, you will actually lose $2,000 at some point. So with probability one, you're going
to go broke, and that is called the gambler's ruin. And notice, by the way, this is a gambler's
ruin in a fair casino, which doesn't even exist. You're going to be ruined a lot faster
in a casino where the casino is getting a certain percentage of take on the money. In
other words, where the expected value is negative, which is the case in real casinos, in such
things as roulette. But what we want to do is to simulate this a few times. Suppose that
we start with a gambler who starts with $2,000, and we just simulated making these fair bets,
$200 a bet, and seeing how many bets it takes before our hapless gambler goes broke. In
this case, the gambler went broke after 187 steps. In this next simulation, however, the
gambler did not go broke. And even after 1,000 steps, the gambler did not go broke. In fact,
now this gambler has, oh, it looks like $6,000 or $7,000. So this was good. Now he'll go broke
eventually, but he hasn't gone broke yet. This one went broke after 65 steps, after 47 steps,
after 57 bets, after, oh, this one, this person didn't go broke. And then look at this. This
gambler is making more than $10,000 after 1,000 steps. So this is great. He'll go broke later.
Okay, this person will go broke after 159 steps, and so on, 151 steps. This one took 703 steps.
That is 703 bets before that gambler went broke. And so this is the sad story of the gambler's
ruin. Now, there's another example that we're going to talk about now, which it has to do with
counting ballots in a ballot box. So this is what I described before. Suppose you have a ballot
box. And in the ballot box, you have the ballots which are voting for either candidate A or
candidate B. And let's assume that candidate A actually wins 52 to 47. So that's the eventual
outcome. And our question is, how likely is it that during the counting of the ballots one at a
time, what's the probability that the eventual winner always stays ahead as you're tallying the
votes one after another? So let me make sure that you understand what we're doing. And I'll show
you an example of what could happen. Here's an example of where you start with counting the
ballots. There are no ballots counted at the beginning. And then after one ballot is counted,
that ballot went to candidate A, the eventual winner. The next ballot went to candidate A, the
eventual winner, went up for a while, then candidate B got some votes. And so what we're
recording here is the margin of A minus B, A's votes, minus B's votes, as you're counting the
ballots. So you can see that if it's above the zero line, that means that during the intermediate
counting of the ballots, for example, 20 ballots have been counted here, it says that there were
10 more ballots for the eventual winner candidate A than there were for candidate B. In other words,
votes for candidate B are counted as a negative one, and votes for candidate A are counted positively,
and we're taking the accumulated total as we're counting the ballots. So this is an example of a
graph that indicates the intermediate counts of a ballot in which the candidate A did in fact
stay ahead the entire time. Now, here's one in which candidate B got some votes appeared to be
ahead at the beginning of the count, and then later, of course, A always wins because we're
assuming that A got 52 votes and B got 47 votes. So these are all examples of, here's an example,
A started out ahead, but then B got a lot of votes, and so B did at some point appear to be
ahead, but then finally, of course, A wins. So the question is, what's the probability of counting
the votes and having A always be ahead during the entire voting? Well, it turns out that there's
a neat, very neat closed form answer to this question, and that is that if the candidate A
gets A votes, and candidate B gets little B votes, and A is the winner, so A is bigger than B,
then the probability that of counting the votes, that is to say among all possible ways of picking
out those ballots, the probability that A will always be ahead throughout the counting is A
minus B over A plus B. A plus B is the total number of votes cast, and A is the number of votes
that A, the winner gets, minus B, the number of votes the loser gets. And you can see why at
least this makes some sense, because suppose that A just won by a little tiny bit, and so A and B,
maybe they just differ by one vote, A just won by one vote, then you can see that A minus B would
be a very small number, like one, so it'd be one over the number of ballots cast, and that would
make sense, because if the voting is very close, you would not, it would be rather rare for the
winning candidate to always be ahead, because the other candidate got almost as many votes,
whereas suppose it were a slaughter, and A got almost all the votes, and maybe B got one vote,
then this number, A minus B, would be just very close to A plus B, and consequently we have a
fraction that's very close to one, so the probability would be almost one, that is almost
certain that the intermediate counts would always favor the eventual winner. So this is called the
Bertrand ballot theorem. Well, one of the reasons that I like to think about the Bertrand ballot
theorem is that it brings up this question of potential ties, and let me illustrate it in the
following way. Suppose that you are a person who's hiring two people for a job, and the two people
have been, have had some sort of a measurement of who is better day by day, for many days, in fact,
for every day for an entire year, and you have the record of who was, they did something, and
maybe they were tennis players, and they played tennis against each other, or they were,
taking some sort of an exam, and one was better than the other, and every day they competed,
and we, you had in front of you a record of who was ahead in their cumulative wins over the other
one for the most of the time, and suppose that in hiring, in looking at this record, you say,
oh look, this candidate A was ahead for the entire last half of the year, in other words,
they had won more times than the other candidate for the entire last half of the year. Boy, that
certainly seems to be a good recommendation for that candidate, or maybe this candidate was ahead
for the entire last nine months of the job, always the cumulative record of the wins of the
one candidate over the other candidate, that one candidate had won more times than the other for
the entire last nine months. It seems like it's a very strong evidence that that person is actually
better, but here's what we're going to do in order to test the value of that impression,
and that is to compare it against randomness. You see, if we know what to expect by just a random
kind of a contest, like flipping a coin every day, we can then compare the effect of what to expect
from randomness about ties and things, and one being ahead than the other, compared to what
actually we saw in the example of the people, and it might give us an impression about how to
interpret the value of the evidence that one was ahead, and I found this surprising, and I hope
that you find it surprising too. So here's what we're going to do. We're going to look at some
simulations of where the contest between these two candidates consists of flipping a coin. That is
to say, it is completely random at every time whether one person wins or the other person wins,
and we're going to investigate the question of overdoing this for 366 days. How many times of
doing it 366 days, where do we expect the last tie to occur? In other words, is it common for the last
tie to do they oscillate back and forth, and almost always the last tie is right near the end of the
year, or how often does it happen that just by luck alone, the last tie is near the beginning of the
year? Well, so we just did a bunch of simulations, and here they are. So here's the first simulation.
Now, what this means by simulation is that we just simulated flipping a coin 366 times
and keeping the running total of heads minus tails. So in other words, whenever we get a cumulative
answer of zero, that's a case for a tie. So in this case, the last tie occurred here at about
number 0290 something. This vertical bar indicates the location of the last tie, the last time the
heads and tails were exactly equal, and then it continues on here. All of these are more tails
than heads for the remaining part of the year. And then we record this, we're going to do this
simulation a thousand times, and so we just make a mark down here to indicate that where the last
tie was in this first walk. In the second walk, the last tie occurred much earlier in the year,
at about the hundred and oh what 30th day, and then over that the head's person was ahead the whole
time. And then we do the simulation, here it was somewhere in the middle of the year. This time
the last tie was essentially right at the end. Here the last tie was in the middle, here the last
tie was right at the beginning, and we're accumulating these where the last ties were over each of our
thousand simulations, and now we're just going by tens, and I'm going to run it rather fast,
so you can see growing up this histogram on the bottom is telling us after a thousand simulations
where the last tie occurred. And look at how surprising it is. First of all, the last ties
often occurred right at the beginning of the year. That's in fact the most common individual place was
that it just deviated right from the beginning and never tied again. And then it actually turns
out that it's a symmetrical curve. In other words, that the probabilities are that the last tie occurring
at the first day is exactly equal to the probability that they occur at the very last day, and that
it's symmetrical and it has sort of a u-shape to it. What that means is that on average, half of the
time that you just flip a coin where there's no bias at all, half of the time the last tie will
occur in the first half of the year, and in fact a third of the time the last tie will occur in the
first three months of the year. To me, the impact of this is that if you have, for example, two
children who are being evaluated against each other by some method, and you see one child being
ahead in this measurement for many, many times over the year, just by probability alone, a third
of the chance they might be exactly equal at the beginning. I think this has some sort of impact
to it in the way that we maybe measure the different qualities of people.
So I want to conclude this lecture by talking about a case where we're viewing fluctuations
not just in one dimension, but in two dimensions. That is to say, we're going to take a random
walk, but starting at the origin, we'll by randomness choose to go either north, south, east, or west
randomly. And so I can simulate this random walk by this arrow is taking this random process of at
each place on the grid, we go right, left, up, or down, and we just continue in this way, and this
draws out this is rather interesting random perambulation around the plane. And there it goes.
Now, this is an interesting thing. First of all, it's interesting to just watch this thing, but it
turns out that this kind of random walk in two dimensions has some very interesting properties
to it. One question that we can ask about a two dimensional random walk is exactly the question
we ask for one dimensional random walk, namely, what's the chance of returning to the origin?
Well, it turns out that the probability of returning is one. But the rate at which we return
is not always so quick. Here are some examples of random walks that 1000 steps of a random walk.
In this case, first of all, they draw these interesting figures 1000 step random walks.
Sometimes they hover around the origin, but look, sometimes they just seem to go off.
This one just seems to go off. And often they don't come back to the origin anytime soon.
So these are interesting random walks. These are 50 random walks. Some of them just go off
to the side. Now, now what what I'd like to ask is the question that although the probability
of coming back to the origin is one, how soon do you do so? Well, we did simulations of these two
dimensional random walks and ask what are the number of steps before we returned. And in these
30 simulations, which we we took up up to 100 million steps, notice that some of these like this
one required 8 million steps before it returned to the origin. This one required 36 million
steps before it returned to the origin. And these four over here, we stopped at 100 million steps
that still had not returned to the origin. In the case of a three dimensional random walk,
it becomes even more peculiar, namely that in a three dimensional random walk, the probability
of returning to where you started is not one. In fact, it's only 35%. Well, what we're going to do
is in the next lecture, we're going to see some applications of this concept of random walks
and other applications of probability in the physical world. I'll see you then.
