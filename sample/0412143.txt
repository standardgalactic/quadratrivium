5
0
0
2

b
e
F
5
1

2
v
3
4
1
2
1
4
0
/
h
p
-
t
n
a
u
q
:
v
i
X
r
a

Limits on Eﬃcient Computation in the Physical World

by

Scott Joel Aaronson

Bachelor of Science (Cornell University) 2000

A dissertation submitted in partial satisfaction of the
requirements for the degree of
Doctor of Philosophy

in

Computer Science

in the

GRADUATE DIVISION
of the
UNIVERSITY of CALIFORNIA, BERKELEY

Committee in charge:

Professor Umesh Vazirani, Chair
Professor Luca Trevisan
Professor K. Birgitta Whaley

Fall 2004

 
 
 
 
The dissertation of Scott Joel Aaronson is approved:

Chair

Date

Date

Date

University of California, Berkeley

Fall 2004

Limits on Eﬃcient Computation in the Physical World

Copyright 2004
by
Scott Joel Aaronson

Abstract

1

Limits on Eﬃcient Computation in the Physical World

by

Scott Joel Aaronson
Doctor of Philosophy in Computer Science

University of California, Berkeley

Professor Umesh Vazirani, Chair

More than a speculative technology, quantum computing seems to challenge our most basic
intuitions about how the physical world should behave.
In this thesis I show that, while
some intuitions from classical computer science must be jettisoned in the light of modern
physics, many others emerge nearly unscathed; and I use powerful tools from computational
complexity theory to help determine which are which.

In the ﬁrst part of the thesis, I attack the common belief that quantum computing
resembles classical exponential parallelism, by showing that quantum computers would face
serious limitations on a wider range of problems than was previously known.
In partic-
ular, any quantum algorithm that solves the collision problem—that of deciding whether
n1/5
a sequence of n integers is one-to-one or two-to-one—must query the sequence Ω
times. This resolves a question that was open for years; previously no lower bound better
(cid:1)
than constant was known. A corollary is that there is no “black-box” quantum algorithm
to break cryptographic hash functions or solve the Graph Isomorphism problem in poly-
I also show that relative to an oracle, quantum computers could not solve
nomial time.
NP-complete problems in polynomial time, even with the help of nonuniform “quantum
advice states”; and that any quantum algorithm needs Ω
queries to ﬁnd a local
minimum of a black-box function on the n-dimensional hypercube. Surprisingly, the latter
result also leads to new classical lower bounds for the local search problem. Finally, I give
new lower bounds on quantum one-way communication complexity, and on the quantum
query complexity of total Boolean functions and recursive Fourier sampling.

2n/4/n

(cid:0)

(cid:0)

(cid:1)

The second part of the thesis studies the relationship of the quantum computing
I ﬁrst examine the arguments of Leonid Levin, Stephen Wol-
model to physical reality.
fram, and others who believe quantum computing to be fundamentally impossible.
I ﬁnd
their arguments unconvincing without a “Sure/Shor separator”—a criterion that separates
the already-veriﬁed quantum states from those that appear in Shor’s factoring algorithm.
I argue that such a separator should be based on a complexity classiﬁcation of quantum
states, and go on to create such a classiﬁcation. Next I ask what happens to the quantum
computing model if we take into account that the speed of light is ﬁnite—and in particu-
lar, whether Grover’s algorithm still yields a quadratic speedup for searching a database.
Refuting a claim by Benioﬀ, I show that the surprising answer is yes. Finally, I analyze
hypothetical models of computation that go even beyond quantum computing. I show that

many such models would be as powerful as the complexity class PP, and use this fact to
give a simple, quantum computing based proof that PP is closed under intersection. On
the other hand, I also present one model—wherein we could sample the entire history of
a hidden variable—that appears to be more powerful than standard quantum computing,
but only slightly so.

2

Professor Umesh Vazirani
Dissertation Committee Chair

Contents

List of Figures

List of Tables

1 “Aren’t You Worried That Quantum Computing Won’t Pan Out?”

2 Overview

2.1 Limitations of Quantum Computers

. . . . . . . . . . . . . . . . . . . . . .
2.1.1 The Collision Problem . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.2 Local Search . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.3 Quantum Certiﬁcate Complexity . . . . . . . . . . . . . . . . . . . .
2.1.4 The Need to Uncompute . . . . . . . . . . . . . . . . . . . . . . . . .
2.1.5 Limitations of Quantum Advice . . . . . . . . . . . . . . . . . . . . .
2.2 Models and Reality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
Skepticism of Quantum Computing . . . . . . . . . . . . . . . . . . .
2.2.1
. . . . . . . . . . . . . . . .
2.2.2 Complexity Theory of Quantum States
2.2.3 Quantum Search of Spatial Regions
. . . . . . . . . . . . . . . . . .
2.2.4 Quantum Computing and Postselection . . . . . . . . . . . . . . . .
2.2.5 The Power of History . . . . . . . . . . . . . . . . . . . . . . . . . .

3 Complexity Theory Cheat Sheet

3.1 The Complexity Zoo Junior . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.2 Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3.3 Oracles

4 Quantum Computing Cheat Sheet
4.1 Quantum Computers: N Qubits
. . . . . . . . . . . . . . . . . . . . . . . .
4.2 Further Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

I Limitations of Quantum Computers

5 Introduction

5.1 The Quantum Black-Box Model . . . . . . . . . . . . . . . . . . . . . . . . .
5.2 Oracle Separations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

iii

vii

viii

1

6
7
8
9
10
11
11
13
13
13
14
15
16

18
19
20
21

23
24
27

29

30
31
32

6 The Collision Problem

6.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.1.1 Oracle Hardness Results . . . . . . . . . . . . . . . . . . . . . . . . .
Information Erasure . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.1.2
6.2 Preliminaries
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . .
6.3 Reduction to Bivariate Polynomial
6.4 Lower Bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.5 Set Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6.6 Open Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

7 Local Search

7.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.2 Preliminaries
7.3 Relational Adversary Method . . . . . . . . . . . . . . . . . . . . . . . . . .
7.4 Snakes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7.5 Speciﬁc Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . .
7.5.1 Boolean Hypercube
7.5.2 Constant-Dimensional Grid Graph . . . . . . . . . . . . . . . . . . .

8 Quantum Certiﬁcate Complexity

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8.1 Summary of Results
8.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8.3 Characterization of Quantum Certiﬁcate Complexity . . . . . . . . . . . . .
8.4 Quantum Lower Bound for Total Functions . . . . . . . . . . . . . . . . . .
8.5 Asymptotic Gaps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8.5.1 Local Separations . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . .
8.5.2
8.6 Open Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Symmetric Partial Functions

9 The Need to Uncompute

9.1 Preliminaries
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9.2 Quantum Lower Bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9.3 Open Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

10 Limitations of Quantum Advice

10.1 Preliminaries

10.2 Simulating Quantum Messages

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10.1.1 Quantum Advice . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10.1.2 The Almost As Good As New Lemma . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . .
10.3 A Direct Product Theorem for Quantum Search . . . . . . . . . . . . . . .
10.4 The Trace Distance Method . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10.5 Open Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

10.2.1 Simulating Quantum Advice

10.4.1 Applications

iv

34
36
36
36
37
38
41
43
46

47
49
51
52
57
60
60
64

67
68
70
70
72
74
76
77
78

79
81
82
87

88
91
92
93
93
96
99
103
106
110

11 Summary of Part I

II Models and Reality

12 Skepticism of Quantum Computing

12.1 Bell Inequalities and Long-Range Threads . . . . . . . . . . . . . . . . . . .

13 Complexity Theory of Quantum States

13.1 Sure/Shor Separators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13.2 Classifying Quantum States . . . . . . . . . . . . . . . . . . . . . . . . . . .
13.3 Basic Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13.4 Relations Among Quantum State Classes
. . . . . . . . . . . . . . . . . . .
13.5 Lower Bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13.5.1 Subgroup States
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13.5.2 Shor States . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13.5.3 Tree Size and Persistence of Entanglement . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . .
13.6 Manifestly Orthogonal Tree Size
13.7 Computing With Tree States
. . . . . . . . . . . . . . . . . . . . . . . . . .
13.8 The Experimental Situation . . . . . . . . . . . . . . . . . . . . . . . . . . .
13.9 Conclusion and Open Problems . . . . . . . . . . . . . . . . . . . . . . . . .

14 Quantum Search of Spatial Regions

14.1 Summary of Results
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14.2 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14.3 The Physics of Databases
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14.4 The Model
14.4.1 Locality Criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14.5 General Bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14.6 Search on Grids . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14.6.1 Amplitude Ampliﬁcation . . . . . . . . . . . . . . . . . . . . . . . .
14.6.2 Dimension At Least 3 . . . . . . . . . . . . . . . . . . . . . . . . . .
14.6.3 Dimension 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14.6.4 Multiple Marked Items . . . . . . . . . . . . . . . . . . . . . . . . . .
14.6.5 Unknown Number of Marked Items . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . .
14.7.1 Bits Scattered on a Graph . . . . . . . . . . . . . . . . . . . . . . . .
14.8 Application to Disjointness
. . . . . . . . . . . . . . . . . . . . . . . . . . .
14.9 Open Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

14.7 Search on Irregular Graphs

15 Quantum Computing and Postselection

15.1 The Class PostBQP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . .
15.2 Fantasy Quantum Mechanics
15.3 Open Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

v

112

114

116
119

126
127
130
135
138
141
142
146
148
149
154
157
160

162
162
164
165
167
168
169
173
174
175
180
181
184
185
189
190
191

192
193
196
198

16 The Power of History

16.1 The Complexity of Sampling Histories . . . . . . . . . . . . . . . . . . . . .
16.2 Outline of Chapter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.3 Hidden-Variable Theories
16.3.1 Comparison with Previous Work . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.3.2 Objections
16.4 Axioms for Hidden-Variable Theories . . . . . . . . . . . . . . . . . . . . . .
16.4.1 Comparing Theories . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.5 Impossibility Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.6 Speciﬁc Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.6.1 Flow Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.6.2 Schr¨odinger Theory . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.7 The Computational Model . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.7.1 Basic Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.8 The Juggle Subroutine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.9 Simulating SZK . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16.10Search in N 1/3 Queries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . .
16.11Conclusions and Open Problems

17 Summary of Part II

Bibliography

vi

199
200
201
203
205
206
206
207
208
211
211
215
218
219
220
221
224
226

228

229

List of Figures

1.1 Conway’s Game of Life . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.1 Known relations among 14 complexity classes . . . . . . . . . . . . . . . . .

4.1 Quantum states of one qubit

. . . . . . . . . . . . . . . . . . . . . . . . . .

7.1 A snake of vertices ﬂicks its tail . . . . . . . . . . . . . . . . . . . . . . . . .
7.2 The coordinate loop in 3 dimensions . . . . . . . . . . . . . . . . . . . . . .

13.1 Sure/Shor separators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13.2 Tree representing a quantum state . . . . . . . . . . . . . . . . . . . . . . .
13.3 Known relations among quantum state classes . . . . . . . . . . . . . . . . .

14.1 Quantum robot searching a 2D grid . . . . . . . . . . . . . . . . . . . . . .
14.2 The ‘starﬁsh’ graph . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14.3 Disjointness in O (√n) communication . . . . . . . . . . . . . . . . . . . . .

vii

2

21

25

58
64

128
129
131

163
171
191

15.1 Simulating PP using postselection . . . . . . . . . . . . . . . . . . . . . . . .

195

16.1 Flow network corresponding to a unitary matrix . . . . . . . . . . . . . . .

211

viii

List of Tables

8.1 Query complexity and certiﬁcate complexity measures . . . . . . . . . . . .

68

10.1 Expressions for px,ijkl

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

109

12.1 Four objections to quantum computing . . . . . . . . . . . . . . . . . . . . .

116

14.1 Summary of bounds for spatial search . . . . . . . . . . . . . . . . . . . . .
14.2 Divide-and-conquer versus quantum walks . . . . . . . . . . . . . . . . . . .

163
165

16.1 Four hidden-variable theories and the axioms they satisfy . . . . . . . . . .

208

ix

Acknowledgements

My adviser, Umesh Vazirani, once said that he admires the quantum adiabatic algorithm
because, like a great squash player, it achieves its goal while moving as little as it can get
away with. Throughout my four years at Berkeley, I saw Umesh inculcate by example his
“adiabatic” philosophy of life: a philosophy about which papers are worth reading, which
deadlines worth meeting, and which research problems worth a ﬁght to the ﬁnish. Above all,
the concept of “beyond hope” does not exist in this philosophy, except possibly in regard
to computational problems. My debt to Umesh for his expert scientiﬁc guidance, wise
professional counsel, and generous support is obvious and beyond my ability to embellish.
My hope is that I graduate from Berkeley a more adiabatic person than when I came.

Admittedly, if the push to ﬁnish this thesis could be called adiabatic, then the
spectral gap was exponentially small. As I struggled to make the deadline, I relied on the
help of David Molnar, who generously agreed to ﬁle the thesis in Berkeley while I remained in
Princeton; and my committee—consisting of Umesh, Luca Trevisan, and Birgitta Whaley—
which met procrastination with ﬂexibility.

Silly as it sounds, a principal reason I came to Berkeley was to breathe the same air
that led Andris Ambainis to write his epochal paper “Quantum lower bounds by quantum
arguments.” Whether or not the air in 587 Soda did me any good, Part I of the thesis is
essentially a 150-page tribute to Andris—a colleague whose unique combination of genius
and humility ﬁlls everyone who knows him with awe.

The direction of my research owes a great deal as well to Ronald de Wolf, who
periodically emerges from his hermit cave to challenge non-rigorous statements, eat dubbel
zout, or lament American ignorance. While I can see eye-to-eye with Ronald about (say)
the D (f ) versus bs (f )2 problem, I still feel that Andrei Tarkovsky’s Solaris would beneﬁt
immensely from a car chase.

For better or worse, my conception of what a thesis should be was inﬂuenced by
Dave Bacon, quantum computing’s elder clown, who entitled the ﬁrst chapter of his own
451-page behemoth “Philosonomicon.” I’m also indebted to Chris Fuchs and his samizdat,
for the idea that a document about quantum mechanics more than 400 pages long can be
worth reading most of the way through.

I began working on the best-known result in this thesis, the quantum lower bound
for the collision problem, during an unforgettable summer at Caltech.
Leonard Schul-
man and Ashwin Nayak listened patiently to one farfetched idea after another, while John
Preskill’s weekly group meetings helped to ensure that the mysteries of quantum mechanics,
which inspired me to tackle the problem in the ﬁrst place, were never far from my mind.
Besides Leonard, Ashwin, and John, I’m grateful to Ann Harvey for putting up with the
growing mess in my oﬃce. For the record, I never once slept in the oﬃce; the bedsheet
was strictly for doing math on the ﬂoor.

I created the infamous Complexity Zoo web site during a summer at CWI in
Amsterdam, a visit enlivened by the presence of Harry Buhrman, Hein R¨ohrig, Volker
Nannen, Hartmut Klauck, and Troy Lee. That summer I also had memorable conversations
with David Deutsch and Stephen Wolfram. Chapters 7, 13, and 16 partly came into being
during a semester at the Hebrew University in Jerusalem, a city where “Aaron’s sons” were
I thank Avi Wigderson, Dorit
already obsessing about cubits three thousand years ago.

x

Aharonov, Michael Ben-Or, Amnon Ta-Shma, and Michael Mallin for making that semester
I also thank Avi for pointing me to the then-unpublished
a fruitful and enjoyable one.
results of Ran Raz on which Chapter 13 is based, and Ran for sharing those results.

A signiﬁcant chunk of the thesis was written or revised over two summers at the
Perimeter Institute for Theoretical Physics in Waterloo.
I thank Daniel Gottesman, Lee
Smolin, and Ray Laﬂamme for welcoming a physics doofus to their institute, someone who
thinks the string theory versus loop quantum gravity debate should be resolved by looping
over all possible strings. From Marie Ericsson, Rob Spekkens, and Anthony Valentini
I learned that theoretical physicists have a better social life than theoretical computer
scientists, while from Dan Christensen I learned that complexity and quantum gravity had
better wait before going steady.

Several ideas were hatched or incubated during the yearly QIP conferences; work-
shops in Toronto, Banﬀ, and Leiden; and visits to MIT, Los Alamos, and IBM Almaden.
I’m grateful to Howard Barnum, Andrew Childs, Elham Kasheﬁ, Barbara Terhal, John
Watrous, and many others for productive exchanges on those occasions.

Back in Berkeley, people who enriched my grad-school experience include Neha
Dave, Julia Kempe, Simone Severini, Lawrence Ip, Allison Coates, David Molnar, Kris Hil-
drum, Miriam Walker, and Shelly Rosenfeld. Alex Fabrikant and Boriska Toth are forgiven
for the cruel caricature that they attached to my dissertation talk announcement, provided
they don’t try anything like that ever again. The results on one-way communication in
Chapter 10 beneﬁted greatly from conversations with Oded Regev and Iordanis Kerenidis,
while Andrej Bogdanov kindly supplied the explicit erasure code for Chapter 13.
I wrote
Chapter 7 to answer a question of Christos Papadimitriou.

I did take some actual . . . courses at Berkeley, and I’m grateful to John Kubiatow-
icz, Stuart Russell, Guido Bacciagaluppi, Richard Karp, and Satish Rao for not failing me
in theirs.
Ironically, the course that most directly inﬂuenced this thesis was Tom Farber’s
magniﬁcent short ﬁction workshop. A story I wrote for that workshop dealt with the prob-
lem of transtemporal identity, which got me thinking about hidden-variable interpretations
of quantum mechanics, which led eventually to the collision lower bound. No one seems to
believe me, but it’s true.

The students who took my “Physics, Philosophy, Pizza” course remain one of my
greatest inspirations. Though they were mainly undergraduates with liberal arts back-
grounds, they took nothing I said about special relativity or G¨odel’s Theorem on faith.
If
I have any conﬁdence today in my teaching abilities; if I think it possible for students to
show up to class, and to participate eagerly, without the usual carrot-and-stick of grades
and exams; or if I ﬁnd certain questions, such as how a superposition over exponentially
many ‘could-have-beens’ can collapse to an ‘is,’ too vertiginous to be pondered only by
nerds like me, then those pizza-eating students are the reason.

Now comes the part devoted to the mist-enshrouded pre-Berkeley years. My
initiation into the wild world of quantum computing research took place over three summer
internships at Bell Labs: the ﬁrst with Eric Grosse, the second with Lov Grover, and the
third with Rob Pike.
I thank all three of them for encouraging me to pursue my interests,
even if the payoﬀ was remote and, in Eric’s case, not even related to why I was hired.
Needless to say, I take no responsibility for the subsequent crash of Lucent’s stock.

xi

As an undergraduate at Cornell, I was younger than my classmates, invisible to
many of the researchers I admired, and profoundly unsure of whether I belonged there or
had any future in science. What made the diﬀerence was the unwavering support of one
professor, Bart Selman. Busy as he was, Bart listened to my harebrained ideas about
genetic algorithms for SAT or quantum chess-playing, invited me to give talks, guided me
to the right graduate programs, and generally treated me like a future colleague. As
a result, his conviction that I could succeed at research gradually became my conviction
too. Outside of research, Christine Chung, Fion Luo, and my Telluride roommate Jason
Stockmann helped to warm the Ithaca winters, Lydia Fakundiny taught me what an essay
is, and Jerry Abrams provided a much-needed boost.

Turning the clock back further, my earliest research foray was a paper on hypertext
organization, written when I was ﬁfteen and spending the year at Clarkson University’s
unique Clarkson School program. Christopher Lynch generously agreed to advise the
project, and oﬀered invaluable help as I clumsily learned how to write a C program, prove
a problem NP-hard, and conduct a user experiment (one skill I’ve never needed again!).
I
was elated to be trading ideas with a wise and experienced researcher, only months after I’d
escaped from the prison-house of high school. Later, the same week the rejection letters
were arriving from colleges, I learned that my ﬁrst paper had been accepted to SIGIR,
the main information retrieval conference.
I was ﬁlled with boundless gratitude toward
the entire scientiﬁc community—for struggling, against the warp of human nature, to judge
ideas rather than the personal backgrounds of their authors. Eight years later, my gratitude
and amazement are undiminished.

Above all, I thank Alex Halderman for a friendship that’s spanned twelve years
and thousands of miles, remaining as strong today as it was amidst the Intellectualis minimi
of Newtown Junior High School; my brother David for believing in me, and for making me
prouder than he realizes by doing all the things I didn’t; and my parents for twenty-three
years of harping, kvelling, chicken noodle soup, and never doubting for a Planck time that
I’d live up to my potential—even when I couldn’t, and can’t, share their certainty.

1

Chapter 1

“Aren’t You Worried That
Quantum Computing Won’t Pan
Out?”

For a century now, physicists have been telling us strange things: about twins
who age at diﬀerent rates, particles that look diﬀerent when rotated 360◦, a force that is
transmitted by gravitons but is also the curvature of spacetime, a negative-energy electron
sea that pervades empty space, and strangest of all, “probability waves” that produce fringes
on a screen when you don’t look and don’t when you do. Yet ever since I learned to program,
I suspected that such things were all “implementation details” in the source code of Nature,
their study only marginally relevant to forming an accurate picture of reality. Physicists,
I thought, would eventually realize that the state of the universe can be represented by
a ﬁnite string of bits. These bits would be the “pixels” of space, creating the illusion of
continuity on a large scale much as a computer screen does. As time passed, the bits
would be updated according to simple rules. The speciﬁc form of these rules was of no
great consequence—since according to the Extended Church-Turing Thesis, any suﬃciently
complicated rules could simulate any other rules with reasonable eﬃciency.1 So apart from
practical considerations, why worry about Maxwell’s equations, or Lorentz invariance, or
even mass and energy, if the most fundamental aspects of our universe already occur in
Conway’s Game of Life (see Figure 1.1)?

Then I heard about Shor’s algorithm [219] for factoring integers in polynomial time
on a quantum computer. Then as now, many people saw quantum computing as at best a
speculative diversion from the “real work” of computer science. Why devote one’s research
career to a type of computer that might never see application within one’s lifetime, that
faces daunting practical obstacles such as decoherence, and whose most publicized success
to date has been the conﬁrmation that, with high probability, 15 = 3
5 [234]? Ironically,
I might have agreed with this view, had I not taken the Extended Church-Turing Thesis
so seriously as a claim about reality. For Shor’s algorithm forces us to accept that, under

×

1Here “extended” refers to the eﬃciency requirement, which was not mentioned in the original Church-
Turing Thesis. Also, I am simply using the standard terminology, sidestepping the issue of whether Church
and Turing themselves intended to make a claim about physical reality.

2

Figure 1.1: In Conway’s Game of Life, each cell of a 2D square grid becomes ‘dead’ or
‘alive’ based on how many of its eight neighbors were alive in the previous time step. A
In what ways is
simple rule applied iteratively leads to complex, unpredictable behavior.
our physical world similar to Conway’s, and in what ways is it diﬀerent?

widely-believed assumptions, that Thesis conﬂicts with the experimentally-tested rules of
quantum mechanics as we currently understand them. Either the Extended Church-Turing
Thesis is false, or quantum mechanics must be modiﬁed, or the factoring problem is solvable
in classical polynomial time. All three possibilities seem like wild, crackpot speculations—
but at least one of them is true!

The above conundrum is what underlies my interest in quantum computing, far
more than any possible application. Part of the reason is that I am neither greedy, nefarious,
nor number-theoretically curious enough ever to have hungered for the factors of a 600-digit
integer.
I do think that quantum computers would have benign uses, the most important
one being the simulation of quantum physics and chemistry.2 Also, as transistors approach
the atomic scale, ideas from quantum computing are likely to become pertinent even for
classical computer design. But none of this quickens my pulse.

For me, quantum computing matters because it combines two of the great myster-
ies bequeathed to us by the twentieth century: the nature of quantum mechanics, and the
It would be astonishing if such an elemental connection
ultimate limits of computation.
between these mysteries shed no new light on either of them. And indeed, there is already
a growing list of examples [9, 22, 151]—we will see several of them in this thesis—in which
ideas from quantum computing have led to new results about classical computation. This
should not be surprising: after all, many celebrated results in computer science involve
only deterministic computation, yet it is hard to imagine how anyone could have proved
them had computer scientists not long ago “taken randomness aboard.”3 Likewise, taking
quantum mechanics aboard could lead to a new, more general perspective from which to
revisit the central questions of computational complexity theory.

The other direction, though, is the one that intrigues me even more.

In my view,

2Followed closely by Recursive Fourier Sampling, parity in n/2 queries, and eﬃciently deciding whether

a graph is a scorpion.

3A few examples are primality testing in P [17], undirected connectivity in L [202], and inapproximability

of 3-SAT unless P = NP [224].

3

quantum computing has brought us slightly closer to the elusive Beast that devours Bohmi-
ans for breakfast, Copenhagenists for lunch, and a linear combination of many-worlders
and consistent historians for dinner—the Beast that tramples popularizers, brushes oﬀ
arXiv preprints like ﬂeas, and snorts at the word “decoherence”—the Beast so fearsome
that physicists since Bohr and Heisenberg have tried to argue it away, as if semantics could
banish its unitary jaws and complex-valued tusks. But no, the Beast is there whenever you
aren’t paying attention, following all possible paths in superposition. Look, and suddenly
the Beast is gone. But what does it even mean to look? If you’re governed by the same
physical laws as everything else, then why don’t you evolve in superposition too, perhaps
until someone else looks at you and thereby ‘collapses’ you? But then who collapses whom
ﬁrst? Or if you never collapse, then what determines what you-you, rather than the su-
perposition of you’s, experience? Such is the riddle of the Beast,4 and it has ﬁlled many
with terror and awe.

The contribution of quantum computing, I think, has been to show that the real
nature of the Beast lies in its exponentiality. It is not just two, three, or a thousand states
held in ghostly superposition that quantum mechanics is talking about, but an astronomical
multitude, and these states could in principle reveal their presence to us by factoring a ﬁve-
thousand-digit number. Much more than even Schr¨odinger’s cat or the Bell inequalities,
this particular discovery ups the ante—forcing us either to swallow the full quantum brew,
or to stop saying that we believe in it. Of course, this is part of the reason why Richard
Feynman [108] and David Deutsch [90] introduced quantum computing in the ﬁrst place,
and why Deutsch, in his defense of the many-worlds interpretation, issues a famous challenge
to skeptics [92, p. 217]: if parallel universes are not physically real, then explain how Shor’s
algorithm works.

Unlike Deutsch, here I will not use quantum computing to defend the many-worlds
interpretation, or any of its competitors for that matter. Roughly speaking, I agree with
every interpretation of quantum mechanics to the extent that it acknowledges the Beast’s
I would adopt
existence, and disagree to the extent that it claims to have caged the Beast.
the same attitude in computer science, if instead of freely admitting (for example) that
P versus NP is an open problem, researchers had split into “equalist,” “unequalist,” and
“undecidabilist” schools of interpretation, with others arguing that the whole problem is
meaningless and should therefore be abandoned.

Instead, in this thesis I will show how adopting a computer science perspective
can lead us to ask better questions—nontrivial but answerable questions, which put old
Let me give an
mysteries in a new light even when they fall short of solving them.
example. One of the most contentious questions about quantum mechanics is whether the
individual components of a wavefunction should be thought of as “really there” or as “mere
potentialities.” When we don our computer scientist goggles, this question morphs into a
diﬀerent one: what resources are needed to make a particular component of the wavefunction
manifest? Arguably the two questions are related, since something “real” ought to take less
work to manifest than something “potential.” For example, this thesis gradually became

4Philosophers call the riddle of the Beast the “measurement problem,” which sounds less like something
that should cause insomnia and delirious raving in all who have understood it. Basically, the problem is to
reconcile a picture of the world in which “everything happens simultaneously” with the fact that you (or at
least I!) have a sequence of deﬁnite experiences.

more real as less of it remained to be written.

4

Concretely, suppose our wavefunction has 2n components, all with equal ampli-
tude. Suppose also that we have a procedure to recognize a particular component x (i.e.,
a function f such that f (x) = 1 and f (y) = 0 for all y
= x). Then how often must we
apply this procedure before we make x manifest; that is, observable with probability close
2n/2 applications are
to 1? Bennett, Bernstein, Brassard, and Vazirani [51] showed that
necessary, even if f can be applied to all 2n components in superposition. Later Grover
So if we imagine a spectrum
[139] showed that
2n applications)
with “really there” (1 application) on one end, and “mere potentiality” (
on the other, then we have landed somewhere in between: closer to the “real” end on an
absolute scale, but closer to the “potential” end on the polynomial versus exponential scale
that is more natural for computer science.

2n/2 applications are also suﬃcient.

∼

∼

∼

Of course, we should be wary of drawing grand conclusions from a single data
point. So in this thesis, I will imagine a hypothetical resident of Conway’s Game of Life,
who arrives in our physical universe on a computational complexity safari—wanting to
know exactly which intuitions to keep and which to discard regarding the limits of eﬃcient
computation. Many popular science writers would tell our visitor to throw all classical
intuitions out the window, while quantum computing skeptics would urge retaining them
all. These positions are actually two sides of the same coin, since the belief that a quantum
I will show,
computer would necessitate the ﬁrst is what generally leads to the second.
however, that neither position is justiﬁed. Based on what we know today, there really is a
Beast, but it usually conceals its exponential underbelly.

I’ll provide only one example from the thesis here; the rest are summarized in
Suppose we are given a procedure that computes a two-to-one function f ,
Chapter 2.
and want to ﬁnd distinct inputs x and y such that f (x) = f (y).
In this case, by simply
preparing a uniform superposition over all inputs to f , applying the procedure, and then
) /√2, for some x and y
measuring its result, we can produce a state of the form (
i
|
such that f (x) = f (y). The only problem is that if we measure this state, then we see
either x or y, but not both. The task, in other words, is no longer to ﬁnd a needle in
a haystack, but just to ﬁnd two needles in an otherwise empty barn! Nevertheless, the
collision lower bound in Chapter 6 will show that, if there are 2n inputs to f , then any
2n/5 times.
quantum algorithm for this problem must apply the procedure for f at least
Omitting technical details, this lower bound can be interpreted in at least seven ways:

x
i

y
|

+

∼

(1) Quantum computers need exponential time even to compute certain global properties
of a function, not just local properties such as whether there is an x with f (x) = 1.

(2) Simon’s algorithm [220], and the period-ﬁnding core of Shor’s algorithm [219], cannot

be generalized to functions with no periodicity or other special structure.

(3) Any “brute-force” quantum algorithm needs exponential time, not just for NP-complete
problems, but for many structured problems such as Graph Isomorphism, approxi-
mating the shortest vector in a lattice, and ﬁnding collisions in cryptographic hash
functions.

6
(4) It is unlikely that all problems having “statistical zero-knowledge proofs” can be

eﬃciently solved on a quantum computer.

5

+

(5) Within the setting of a collision algorithm, the components

in the state
) /√2 should be thought of as more “potentially” than “actually” there, it
(
x
i
i
|
being impossible to extract information about both of them in a reasonable amount
of time.

x
i

and

y
|

y

i

|

|

(6) The ability to map

x
i
|
more powerful than the ability to map

to

|

, “uncomputing” x in the process, can be exponentially
f (x)
i

|
(7) In hidden-variable interpretations of quantum mechanics, the ability to sample the en-
tire history of a hidden variable would yield even more power than standard quantum
computing.

i |

|

f (x)
i

.

to

x

x
i

Interpretations (5), (6), and (7) are examples of what I mean by putting old
mysteries in a new light. We are not brought face-to-face with the Beast, but at least we
have fresh footprints and droppings.

Well then. Am I worried that quantum computing won’t pan out? My usual
answer is that I’d be thrilled to know it will never pan out, since this would entail the
discovery of a lifetime, that quantum mechanics is false. But this is not what the questioner
has in mind. What if quantum mechanics holds up, but building a useful quantum computer
turns out to be so diﬃcult and expensive that the world ends before anyone succeeds? The
questioner is usually a classical theoretical computer scientist, someone who is not known to
worry excessively that the world will end before log log n exceeds 10. Still, it would be nice
to see nontrivial quantum computers in my lifetime, and while I’m cautiously optimistic,
I’ll admit to being slightly worried that I won’t. But when faced with the evidence that
one was born into a universe profoundly unlike Conway’s—indeed, that one is living one’s
life on the back of a mysterious, exponential Beast comprising everything that ever could
have happened—what is one to do? “Move right along. . . nothing to see here. . . ”

6

Chapter 2

Overview

“Let a computer smear—with the right kind of quantum randomness—and
you create, in eﬀect, a ‘parallel’ machine with an astronomical number of pro-
cessors . . . All you have to do is be sure that when you collapse the system,
you choose the version that happened to ﬁnd the needle in the mathematical
haystack.”

—From Quarantine [103], a 1992 science-ﬁction novel by Greg Egan

Many of the deepest discoveries of science are limitations:

for example, no su-
perluminal signalling, no perpetual-motion machines, and no complete axiomatization for
arithmetic. This thesis is broadly concerned with limitations on what can eﬃciently be
computed in the physical world. The word “quantum” is absent from the title, in order
to emphasize that the focus on quantum computing is not an arbitrary choice, but rather
an inevitable result of taking our current physical theories seriously. The technical con-
tributions of the thesis are divided into two parts, according to whether they accept the
quantum computing model as given and study its fundamental limitations; or question,
defend, or go beyond that model in some way. Before launching into a detailed overview
of the contributions, let me make some preliminary remarks.

Since the early twentieth century, two communities—physicists1 and computer
scientists—have been asking some of the deepest questions ever asked in almost total in-
tellectual isolation from each other. The great joy of quantum computing research is that
it brings these communities together. The trouble was initially that, although each com-
munity would nod politely during the other’s talks, eventually it would come out that the
physicists thought NP stood for “Non Polynomial,” and the computer scientists had no
idea what a Hamiltonian was. Thankfully, the situation has improved a lot—but my hope
is that it improves further still, to the point where computer scientists have internalized
the problems faced by physics and vice versa. For this reason, I have worked hard to
make the thesis as accessible as possible to both communities. Thus, Chapter 3 provides
a “complexity theory cheat sheet” that deﬁnes NP, P/poly, AM, and other computational
complexity classes that appear in the thesis; and that explains oracles and other important

1As in Saul Steinberg’s famous New Yorker world map, in which 9th Avenue and the Hudson River take
up more space than Japan and China, from my perspective chemists, engineers, and even mathematicians
who know what a gauge ﬁeld is are all “physicists.”

7

concepts. Then Chapter 4 presents the quantum model of computation with no reference
to the underlying physics, before moving on to fancier notions such as density matrices,
trace distance, and separability. Neither chapter is a rigorous introduction to its subject;
for that there are ﬁne textbooks—such as Papadimitriou’s Computational Complexity [188]
and Nielsen and Chuang’s Quantum Computation and Quantum Information [182]—as well
as course lecture notes available on the web. Depending on your background, you might
want to skip to Chapters 3 or 4 before continuing any further, or you might want to skip
past these chapters entirely.

Even the most irredeemably classical reader should take heart: of the 103 proofs
in the thesis, 66 do not contain a single ket symbol.2 Many of the proofs can be understood
by simply accepting certain facts about quantum computing on faith, such as Ambainis’s3
adversary theorem [27] or Beals et al.’s polynomial lemma [45]. On the other hand, one does
run the risk that after one understands the proofs, ket symbols will seem less frightening
than before.

The results in the thesis have all previously appeared in published papers or
preprints [1, 2, 4, 5, 7, 8, 9, 10, 11, 13], with the exception of the quantum computing
based proof that PP is closed under intersection in Chapter 15.
I thank Andris Ambainis
for allowing me to include our joint results from [13] on quantum search of spatial regions.
Results of mine that do not appear in the thesis include those on Boolean function query
properties [3], stabilizer circuits [14] (joint work with Daniel Gottesman), and agreement
complexity [6].

In writing the thesis, one of the toughest choices I faced was whether to refer to
myself as ‘I’ or ‘we.’ Sometimes a personal voice seemed more appropriate, and sometimes
the Voice of Scientiﬁc Truth, but I wanted to be consistent. Readers can decide whether I
chose humbly or arrogantly.

2.1 Limitations of Quantum Computers

Part I studies the fundamental limitations of quantum computers within the usual model
for them. With the exception of Chapter 10 on quantum advice, the contributions of Part
I all deal with black-box or query complexity, meaning that one counts only the number of
queries to an “oracle,” not the number of computational steps. Of course, the queries can
be made in quantum superposition. In Chapter 5, I explain the quantum black-box model,
then oﬀer a detailed justiﬁcation for its relevance to understanding the limits of quantum
computers. Some computer scientists say that black-box results should not be taken too
seriously; but I argue that, within quantum computing, they are not taken seriously enough.
What follows is a (relatively) nontechnical overview of Chapters 6 to 10, which
contain the results of Part I. Afterwards, Chapter 11 summarizes the conceptual lessons
that I believe can be drawn from those results.

2To be honest, a few of those do contain density matrices—or the theorem contains ket symbols, but not

the proof.

3Style manuals disagree about whether Ambainis’ or Ambainis’s is preferable, but one referee asked me to
follow the latter rule with the following deadpan remark: “Exceptions to the rule generally involve religiously
signiﬁcant individuals, e.g., ‘Jesus’ lower-bound method.’ ”

2.1.1 The Collision Problem

8

{

}

to

1, . . . , n

1, . . . , n
{

Chapter 6 presents my lower bound on the quantum query complexity of the collision
problem. Given a function X from
(where n is even), the collision
}
problem is to decide whether X is one-to-one or two-to-one, promised that one of these is
the case. Here the only way to learn about X is to call a procedure that computes X (i)
given i. Clearly, any deterministic classical algorithm needs to call the procedure n/2 + 1
times to solve the problem. On the other hand, a randomized algorithm can exploit the
“birthday paradox”: only 23 people have to enter a room before there’s a 50% chance that
two of them share the same birthday, since what matters is the number of pairs of people.
Similarly, if X is two-to-one, and an algorithm queries X at √n uniform random locations,
then with constant probability it will ﬁnd two locations i
= j such that X (i) = X (j),
thereby establishing that X is two-to-one. This bound is easily seen to be tight, meaning
that the bounded-error randomized query complexity of the collision problem is Θ (√n).

What about the quantum complexity? In 1997, Brassard, Høyer, and Tapp [68]
n1/3
gave a quantum algorithm that uses only O
queries. The algorithm is simple to
describe: in the ﬁrst phase, query X classically at n1/3 randomly chosen locations.
In the
(cid:0)
second phase, choose n2/3 random locations, and run Grover’s algorithm on those locations,
considering each location i as “marked” if X (i) = X (j) for some j that was queried in the
ﬁrst phase. Notice that both phases use order n1/3 = √n2/3 queries, and that the total
number of comparisons is n2/3n1/3 = n. So, like its randomized counterpart, the quantum
algorithm ﬁnds a collision with constant probability if X is two-to-one.

(cid:1)

What I show in Chapter 6 is that any quantum algorithm for the collision problem
n1/5
queries. Previously, no lower bound better than the trivial Ω (1) was known.
for the following set comparison problem: given oracle
,

1, . . . , 2n

1, . . . , 2n

and Y :

n1/7

needs Ω
I also show a lower bound of Ω
access to injective functions X :
(cid:0)
decide whether

(cid:1)

(cid:0)

1, . . . , n
(cid:1)

{

} → {

1, . . . , n
{

} → {

}

}

X (1) , . . . , X (n) , Y (1) , . . . , Y (n)
}

{

has at least 1.1n elements or exactly n elements, promised that one of these is the case. The
set comparison problem is similar to the collision problem, except that it lacks permutation
symmetry, making it harder to prove a lower bound. My results for these problems have
been improved, simpliﬁed, and generalized by Shi [218], Kutin [161], Ambainis [27], and
Midrijanis [176].

for ex-
The implications of these results were already discussed in Chapter 1:
ample, they demonstrate that a “brute-force” approach will never yield eﬃcient quantum
algorithms for the Graph Isomorphism, Approximate Shortest Vector, or Nonabelian Hid-
den Subgroup problems; suggest that there could be cryptographic hash functions secure
against quantum attack; and imply that there exists an oracle relative to which SZK
BQP,
where SZK is the class of problems having statistical zero-knowledge proof protocols, and
BQP is quantum polynomial time.

6⊂

Both the original lower bounds and the subsequent improvements are based on
the polynomial method, which was introduced by Nisan and Szegedy [184], and ﬁrst used to
prove quantum lower bounds by Beals, Buhrman, Cleve, Mosca, and de Wolf [45].
In that
method, given a quantum algorithm that makes T queries to an oracle X, we ﬁrst represent

6
9

the algorithm’s acceptance probability by a multilinear polynomial p (X) of degree at most
2T . We then use results from a well-developed area of mathematics called approximation
theory to show a lower bound on the degree of p. This in turn implies a lower bound on T .
In order to apply the polynomial method to the collision problem, ﬁrst I extend the
collision problem’s domain from one-to-one and two-to-one functions to g-to-one functions
for larger values of g. Next I replace the multivariate polynomial p (X) by a related
univariate polynomial q (g) whose degree is easier to lower-bound. The latter step is the
real “magic” of the proof; I still have no good intuitive explanation for why it works.

The polynomial method is one of two principal methods that we have for proving
lower bounds on quantum query complexity. The other is Ambainis’s quantum adversary
method [27], which can be seen as a far-reaching generalization of the “hybrid argument”
that Bennett, Bernstein, Brassard, and Vazirani [51] introduced in 1994 to show that a
quantum computer needs Ω (√n) queries to search an unordered database of size n for a
marked item.
In the adversary method, we consider a bipartite quantum state, in which
one part consists of a superposition over possible inputs, and the other part consists of
a quantum algorithm’s work space. We then upper-bound how much the entanglement
between the two parts can increase as the result of a single query. This in turn implies a
lower bound on the number of queries, since the two parts must be highly entangled by the
end. The adversary method is more intrinsically “quantum” than the polynomial method;
and as Ambainis [27] showed, it is also applicable to a wider range of problems, including
those (such as game-tree search) that lack permutation symmetry. Ambainis even gave
problems for which the adversary method provably yields a better lower bound than the
polynomial method [28].
It is ironic, then, that Ambainis’s original goal in developing the
adversary method was to prove a lower bound for the collision problem; and in this one
instance, the polynomial method succeeded while the adversary method failed.

2.1.2 Local Search

→

Z, ﬁnd a local minimum of f —that is, a vertex v such that f (v)

In Chapters 7, 8, and 9, however, the adversary method gets its revenge. Chapter 7 deals
with the local search problem: given an undirected graph G = (V, E) and a black-box
function f : V
f (w)
for all neighbors w of v. The graph G is known in advance, so the complexity measure is just
the number of queries to f . This problem is central for understanding the performance of
the quantum adiabatic algorithm, as well as classical algorithms such as simulated annealing.
n, then previously Llewellyn, Tovey, and Trick [169] had
If G is the Boolean hypercube
shown that any deterministic algorithm needs Ω (2n/√n) queries to ﬁnd a local minimum;
and Aldous [24] had shown that any randomized algorithm needs 2n/2
o(n) queries. What
I show is that any quantum algorithm needs Ω
queries. This is the ﬁrst nontrivial
quantum lower bound for any local search problem; and it implies that the complexity class
PLS (or “Polynomial Local Search”), deﬁned by Johnson, Papadimitriou, and Yannakakis
[149], is not in quantum polynomial time relative to an oracle.

0, 1
}
{

2n/4/n

≤

(cid:1)

(cid:0)

−

What will be more surprising to classical computer scientists is that my proof
technique, based on the quantum adversary method, also yields new classical lower bounds
for local search. In particular, I prove a classical analogue of Ambainis’s quantum adversary
theorem, and show that it implies randomized lower bounds up to quadratically better

10

n

{

→

0, 1
}

2n/2/n2

Z. Not only does this improve on Aldous’s 2n/2

I then apply my theorem to show that
than the corresponding quantum lower bounds.
queries to ﬁnd a local minimum of a function
any randomized algorithm needs Ω
o(n) lower bound, bringing us
f :
(cid:1)
2n/2√n
closer to the known upper bound of O
; but it does so in a simpler way that does
not depend on random walk analysis.
In addition, I show the ﬁrst randomized or quantum
(cid:0)
lower bounds for ﬁnding a local minimum on a cube of constant dimension 3 or greater.
Along with recent work by Bar-Yossef, Jayram, and Kerenidis [43] and by Aharonov and
Regev [22], these results provide one of the earliest examples of how quantum ideas can help
to resolve classical open problems. As I will discuss in Chapter 7, my results on local search
have subsequently been improved by Santha and Szegedy [211] and by Ambainis [25].

(cid:0)

(cid:1)

−

2.1.3 Quantum Certiﬁcate Complexity

n

→ {

if f :

0, 1
}

0, 1
}
{

is a total Boolean function, then D (f ) = O

Chapters 8 and 9 continue to explore the power of Ambainis’s lower bound method and the
limitations of quantum computers. Chapter 8 is inspired by the following theorem of Beals
,
et al. [45]:
where D (f ) is the deterministic classical query complexity of f , and Q2 (f ) is the bounded-
(cid:17)
error quantum query complexity.4
This theorem is noteworthy for two reasons: ﬁrst,
because it gives a case where quantum computers provide only a polynomial speedup, in
contrast to the exponential speedup of Shor’s algorithm; and second, because the exponent
of 6 seems so arbitrary. The largest separation we know of is quadratic, and is achieved
by the OR function on n bits: D (OR) = n, but Q2 (OR) = O (√n) because of Grover’s
It is a longstanding open question whether this separation is optimal.
search algorithm.
In particular I
In Chapter 8, I make the best progress so far toward showing that it is.
prove that

Q2 (f )6

(cid:16)

R2 (f ) = O

Q2 (f )2 Q0 (f ) log n
n

(cid:17)

(cid:16)
0, 1
}
{

0, 1
}

. Here R2 (f ) is the bounded-error
for all total Boolean functions f :
→ {
randomized query complexity of f , and Q0 (f ) is the zero-error quantum query complexity.
To prove this result, I introduce two new query complexity measures of independent interest:
the randomized certiﬁcate complexity RC (f ) and the quantum certiﬁcate complexity QC (f ).
Using Ambainis’s adversary method together with the minimax theorem, I relate these
. Then, using the
measures exactly to one another, showing that RC (f ) = Θ
polynomial method, I show that R2 (f ) = O (RC (f ) Q0 (f ) log n) for all total Boolean f ,
Q2 (f ). Chapter 8 contains several other
which implies the above result since QC (f )
≤
results of interest to researchers studying query complexity, such as a superquadratic gap
between QC (f ) and the “ordinary” certiﬁcate complexity C (f ). But the main message
is the unexpected versatility of our quantum lower bound methods: we see the ﬁrst use
of the adversary method to prove something about all total functions, not just a speciﬁc
function; the ﬁrst use of both the adversary and the polynomial methods at diﬀerent points
in a proof; and the ﬁrst combination of the adversary method with a linear programming
duality argument.

QC (f )2
(cid:16)

(cid:17)

4The subscript ‘2’ means that the error is two-sided.

11

2.1.4 The Need to Uncompute

Next, Chapter 9 illustrates how “the need to uncompute” imposes a fundamental limit on
eﬃcient quantum computation. Like a classical algorithm, a quantum algorithm can solve
a problem recursively by calling itself as a subroutine. When this is done, though, the
quantum algorithm typically needs to call itself twice for each subproblem to be solved.
The second call’s purpose is to “uncompute” garbage left over by the ﬁrst call, and thereby
enable interference between diﬀerent branches of the computation.
In a seminal paper,
Bennett [52] argued5 that uncomputation increases an algorithm’s running time by only a
factor of 2. Yet in the recursive setting, the increase is by a factor of 2d, where d is the
Is there any way to avoid this exponential blowup?
depth of recursion.

To make the question more concrete, Chapter 9 focuses on the recursive Fourier
sampling problem of Bernstein and Vazirani [55]. This is a problem that involves d levels
of recursion, and that takes a Boolean function g as a parameter. What Bernstein and
Vazirani showed is that for some choices of g, any classical randomized algorithm needs
nΩ(d) queries to solve the problem. By contrast, 2d queries always suﬃce for a quantum
algorithm. The question I ask is whether a quantum algorithm could get by with fewer
than 2Ω(d) queries, even while the classical complexity remains large.
I show that the
answer is no: for every g, either Ambainis’s adversary method yields a 2Ω(d) lower bound
on the quantum query complexity, or else the classical and quantum query complexities are
both 1. The lower bound proof introduces a new parameter of Boolean functions called
the “nonparity coeﬃcient,” which might be of independent interest.

2.1.5 Limitations of Quantum Advice

Chapter 10 broadens the scope of Part I, to include the limitations of quantum computers
equipped with “quantum advice states.” Ordinarily, we assume that a quantum computer
starts out in the standard “all-0” state,
. But it is perfectly sensible to drop that
· · ·
assumption, and consider the eﬀects of other initial states. Most of the work doing so has
concentrated on whether universal quantum computing is still possible with highly mixed
initial states (see [34, 214] for example). But an equally interesting question is whether
there are states that could take exponential time to prepare, but that would carry us far
beyond the complexity-theoretic conﬁnes of BQP were they given to us by a wizard. For
even if quantum mechanics is universally valid, we do not really know whether such states
exist in Nature!

0
i

0
|

Let BQP/qpoly be the class of problems solvable in quantum polynomial time, with
the help of a polynomial-size “quantum advice state”
that depends only on the input
length n but that can otherwise be arbitrary. Then the question is whether BQP/poly =
BQP/qpoly, where BQP/poly is the class of the problems solvable in quantum polynomial
time using a polynomial-size classical advice string.6 As usual, we could try to prove an
oracle separation. But why can’t we show that quantum advice is more powerful than

ψni
|

5Bennett’s paper dealt with classical reversible computation, but this comment applies equally well to

quantum computation.

6For clearly BQP/poly and BQP/qpoly both contain uncomputable problems not in BQP, such as whether

the nth Turing machine halts.

classical advice, with no oracle? Also, could quantum advice be used (for example) to
solve NP-complete problems in polynomial time?

12

The results in Chapter 10 place strong limitations on the power of quantum advice.
First, I show that BQP/qpoly is contained in a classical complexity class called PP/poly.
This means (roughly) that quantum advice can always be replaced by classical advice,
It also means that we
provided we’re willing to use exponentially more computation time.
could not prove BQP/poly
= BQP/qpoly without showing that PP does not have polynomial-
size circuits, which is believed to be an extraordinarily hard problem. To prove this result,
is sent to the BQP/qpoly machine by a benevolent
I imagine that the advice state
“advisor,” through a one-way quantum communication channel. I then give a novel protocol
for simulating that quantum channel using a classical channel.
Besides showing that
PP/poly, the simulation protocol also implies that for all Boolean functions
BQP/qpoly
n
2 (f ) log Q1
,
0, 1
0, 1
f :
2 (f )
}
}
{
where D1 (f ) is the deterministic one-way communication complexity of f , and Q1
2 (f ) is
(cid:1)
the bounded-error quantum one-way communication complexity. This can be considered
a generalization of the “dense quantum coding” lower bound due to Ambainis, Nayak,
Ta-Shma, and Vazirani [32].

(partial or total), we have D1 (f ) = O

⊆
× {

0, 1
}

ψni
|

m Q1

→ {

m

(cid:0)

6⊂

The second result in Chapter 10 is that there exists an oracle relative to which
BQP/qpoly. This extends the result of Bennett et al. [51] that there exists an
NP
BQP, to handle quantum advice.
oracle relative to which NP
Intuitively, even though
the quantum state
could in some sense encode the solutions to exponentially many
NP search problems, only a miniscule fraction of that information could be extracted by
measuring the advice, at least in the black-box setting that we understand today.

ψni
|

6⊂

The proof of the oracle separation relies on another result of independent interest:
a direct product theorem for quantum search. This theorem says that given an unordered
database with n items, k of which are marked, any quantum algorithm that makes o (√n)
queries7 has probability at most 2−
In other
words, there are no “magical” correlations by which success in ﬁnding one marked item
leads to success in ﬁnding the others. This might seem intuitively obvious, but it does not
follow from the √n lower bound for Grover search, or any other previous quantum lower
bound for that matter. Previously, Klauck [155] had given an incorrect proof of a direct
product theorem, based on Bennett et al.’s hybrid method.
I give the ﬁrst correct proof by
using the polynomial method, together with an inequality dealing with higher derivatives
of polynomials due to V. A. Markov, the younger brother of A. A. Markov.

Ω(k) of ﬁnding all k of the marked items.

The third result in Chapter 10 is a new trace distance method for proving lower
bounds on quantum one-way communication complexity. Using this method, I obtain
optimal quantum lower bounds for two problems of Ambainis, for which no nontrivial lower
bounds were previously known even for classical randomized protocols.

7Subsequently Klauck, ˇSpalek, and de Wolf [156] improved this to o

√nk

queries, which is tight.

(cid:16)

(cid:17)

6
13

2.2 Models and Reality

This thesis is concerned with the limits of eﬃcient computation in Nature.
It is not
obvious that these coincide with the limits of the quantum computing model. Thus, Part
II studies the relationship of the quantum computing model to physical reality. Of course,
I therefore
this is too grand a topic for any thesis, even a thesis as long as this one.
focus on three questions that particularly interest me. First, how should we understand
the arguments of “extreme” skeptics, that quantum computing is impossible not only in
practice but also in principle? Second, what are the implications for quantum computing
if we recognize that the speed of light is ﬁnite, and that according to widely-accepted
principles, a bounded region of space can store only a ﬁnite amount of information? And
third, are there reasonable changes to the quantum computing model that make it even
more powerful, and if so, how much more powerful do they make it? Chapters 12 to 16
address these questions from various angles; then Chapter 17 summarizes.

2.2.1 Skepticism of Quantum Computing

Chapter 12 examines the arguments of skeptics who think that large-scale quantum comput-
ing is impossible for a fundamental physical reason. I ﬁrst brieﬂy consider the arguments of
Leonid Levin and other computer scientists, that quantum computing is analogous to “ex-
travagant” models of computation such as unit-cost arithmetic, and should be rejected on
essentially the same grounds. My response emphasizes the need to grapple with the actual
evidence for quantum mechanics, and to propose an alternative picture of the world that is
compatible with that evidence but in which quantum computing is impossible. The bulk
of the chapter, though, deals with Stephen Wolfram’s A New Kind of Science [246], and
in particular with one of that book’s most surprising claims: that a deterministic cellular-
automaton picture of the world is compatible with the so-called Bell inequality violations
demonstrating the eﬀects of quantum entanglement. To achieve compatibility, Wolfram
posits “long-range threads” between spacelike-separated points.
I explain in detail why
this thread proposal violates Wolfram’s own desiderata of relativistic and causal invariance.
Nothing in Chapter 12 is very original technically, but it seems worthwhile to spell out what
a scientiﬁc argument against quantum computing would have to accomplish, and why the
existing arguments fail.

2.2.2 Complexity Theory of Quantum States

Chapter 13 continues the train of thought begun in Chapter 12, except that now the focus is
more technical. I search for a natural Sure/Shor separator : a set of quantum states that can
account for all experiments performed to date, but that does not contain the states arising
In my view, quantum computing skeptics would strengthen
in Shor’s factoring algorithm.
their case by proposing speciﬁc examples of Sure/Shor separators, since they could then
oﬀer testable hypotheses about where the assumptions of the quantum computing model
break down (if not how they break down). So why am I doing the skeptics’ work for them?
Several people have wrongly inferred from this that I too am a skeptic! My goal, rather,
is to illustrate what a scientiﬁc debate about the possibility of quantum computing might

look like.

14

|

0
i

1
i
|

ψni
|

Most of Chapter 13 deals with a candidate Sure/Shor separator that I call tree
can be represented by a tree, in which each leaf is
states. Any n-qubit pure state
, and each non-leaf vertex is labeled by either a linear combination or
labeled by
or
a tensor product of its subtrees. Then the tree size of
is just the minimum number
of vertices in such a tree, and a “tree state” is an inﬁnite family of states whose tree size is
bounded by a polynomial in n. The idea is to keep a central axiom of quantum mechanics—
that if
—but to limit oneself
ϕ
ψ
i
|
to polynomially many applications of the axiom.

are possible states, so are

ψni
|

and α

ϕ
i

ϕ
i

i ⊗ |

and

ψ
|

+ β

ψ

i

i

|

|

|

The main results are superpolynomial lower bounds on tree size for explicit families
of quantum states. Using a recent lower bound on multilinear formula size due to Raz
[195, 196], I show that many states arising in quantum error correction (for example, states
based on binary linear erasure codes) have tree size nΩ(log n). I show the same for the states
arising in Shor’s algorithm, assuming a number-theoretic conjecture. Therefore, I argue,
by demonstrating such states in the lab on a large number of qubits, experimentalists could
weaken8 the hypothesis that all states in Nature are tree states.

Unfortunately, while I conjecture that the actual tree sizes are exponential, Raz’s
method is currently only able to show lower bounds of the form nΩ(log n). On the other hand,
I do show exponential lower bounds under a restriction, called “manifest orthogonality,” on
the allowed linear combinations of states.

More broadly, Chapter 13 develops a complexity classiﬁcation of quantum states,
and—treating that classiﬁcation as a subject in its own right—proves many basic results
about it. To give a few examples: if a quantum computer is restricted to being in a tree
state at every time step, then it can be simulated in the third level of polynomial hierarchy
PH. A random state cannot even be approximated by a state with subexponential tree
size. Any “orthogonal tree state” can be prepared by a polynomial-size quantum circuit.
Collapses of quantum state classes would imply collapses of ordinary complexity classes,
and vice versa. Many of these results involve unexpected connections between quantum
computing and classical circuit complexity. For this reason, I think that the “complexity
theory of quantum states” has an intrinsic computer-science motivation, besides its possible
role in making debates about quantum mechanics’ range of validity less philosophical and
more scientiﬁc.

2.2.3 Quantum Search of Spatial Regions

A basic result in classical computer science says that Turing machines are polynomially
equivalent to random-access machines.
In other words, we can ignore the fact that the
speed of light is ﬁnite for complexity purposes, so long as we only care about polynomial
It is easy to see that the same is true for quantum computing. Yet one of the
equivalence.
two main quantum algorithms, Grover’s algorithm, provides only a polynomial speedup.9
So, does this speedup disappear if we consider relativity as well as quantum mechanics?

8Since tree size is an asymptotic notion (and for other reasons discussed in Chapter 13), strictly speaking

experimentalists could never refute the hypothesis—just push it beyond all bounds of plausibility.

9If Grover’s algorithm is applied to a combinatorial search space of size 2n, then the speedup is by a

factor of 2n/2—but in this case the speedup is only conjectured, not proven.

15

More concretely, suppose a “quantum robot” is searching a 2-D grid of size √n

√n
for a single marked item. The robot can enter a superposition of grid locations, but moving
from one location to an adjacent one takes one time step. How many steps are needed to
ﬁnd the marked item?
If Grover’s algorithm is implemented na¨ıvely, the answer is order
n—since each of the √n Grover iterations takes √n steps, just to move the robot across
the grid and back. This yields no improvement over classical search. Benioﬀ [50] noticed
this defect of Grover’s algorithm as applied to a physical database, but failed to raise the
question of whether or not a faster algorithm exists.

×

Sadly, I was unable to prove a lower bound showing that the na¨ıve algorithm is
optimal. But in joint work with Andris Ambainis, we did the next best thing: we proved
the impossibility of proving a lower bound, or to put it crudely, gave an algorithm.
In
√n grid for a unique marked vertex in
particular, Chapter 14 shows how to search a √n
It also
only O

steps, by using a carefully-optimized recursive Grover search.

√n log3/2 n

×

(cid:17)

(cid:16)

shows how to search a d-dimensional hypercube in O (√n) steps for d
3. The latter result
has an unexpected implication: namely, that the quantum communication complexity of
the disjointness function is O (√n). This matches a lower bound of Razborov [199], and
improves previous upper bounds due to Buhrman, Cleve, and Wigderson [76] and Høyer
and de Wolf [146].

≥

Chapter 14 also generalizes our search algorithm to handle multiple marked items,
as well as graphs that are not hypercubes but have suﬃciently good expansion properties.
More broadly, the chapter develops a new model of quantum query complexity on graphs,
and proves basic facts about that model, such as lower bounds for search on “starﬁsh”
graphs. Of particular interest to physicists will be Section 14.3, which relates our results
to fundamental limits on information processing imposed by the holographic principle. For
example, we can give an approximate answer to the following question: assuming a positive
cosmological constant Λ > 0, and assuming the only constraints (besides quantum mechan-
ics) are the speed of light and the holographic principle, how large a database could ever be
searched for a speciﬁc entry, before most of the database receded past one’s cosmological
horizon?

2.2.4 Quantum Computing and Postselection

There is at least one foolproof way to solve NP-complete problems in polynomial time: guess
a random solution, then kill yourself if the solution is incorrect. Conditioned on looking at
It’s a wonder that this approach
anything at all, you will be looking at a correct solution!
is not tried more often.

The general idea, of throwing out all runs of a computation except those that
yield a particular result, is called postselection. Chapter 15 explores the general power of
I deﬁne a new complexity class
postselection when combined with quantum computing.
called PostBQP: the class of problems solvable in polynomial time on a quantum computer,
given the ability to measure a qubit and assume the outcome will be
(or equivalently,
I then show that PostBQP coincides with the
discard all runs in which the outcome is
classical complexity class PP.

0
i
|

1
i
|

).

Surprisingly, this new characterization of PP yields an extremely simple, quantum

16

computing based proof that PP is closed under intersection. This had been an open
problem for two decades, and the previous proof, due to Beigel, Reingold, and Spielman
[47], used highly nontrivial ideas about rational approximations of the sign function.
I
also reestablish an extension of the Beigel-Reingold-Spielman result due to Fortnow and
Reingold [115], that PP is closed under polynomial-time truth-table reductions.
Indeed, I
show that PP is closed under BQP truth-table reductions, which seems to be a new result.
The rest of Chapter 15 studies the computational eﬀects of simple changes to the
In particular, what if we allow linear but nonunitary trans-
p (suitably normalized)
2 to
= 2? I show that the ﬁrst change would yield exactly the power of PostBQP,
, and some
}

axioms of quantum mechanics.
formations, or change the measurement probabilities from
for some p
and therefore of PP; while the second change would yield PP if p
class between PP and PSPACE otherwise.

4, 6, 8, . . .

α
|
|

α
|
|

∈ {

My results complement those of Abrams and Lloyd [15], who showed that nonlinear
quantum mechanics would let us solve NP- and even #P-complete problems in polynomial
time; and Brun [72] and Bacon [40], who showed the same for quantum computers involving
closed timelike curves. Taken together, these results lend credence to an observation of
Weinberg [241]: that quantum mechanics is a “brittle” theory, in the sense that even a tiny
change to it would have dramatic consequences.

2.2.5 The Power of History

Contrary to widespread belief, what makes quantum mechanics so hard to swallow is not
indeterminism about the future trajectory of a particle. That is no more bizarre than a
coin ﬂip in a randomized algorithm. The diﬃculty is that quantum mechanics also seems
to require indeterminism about a particle’s past trajectory. Or rather, the very notion
of a “trajectory” is undeﬁned—for until the particle is measured, there is just an evolving
wavefunction.

In spite of this, Schr¨odinger [213], Bohm [59], Bell [49], and others proposed hidden-
variable theories, in which a quantum state is supplemented by “actual” values of certain
observables. These actual values evolve in time by a dynamical rule, in such a way that
the predictions of quantum mechanics are recovered at any individual time. On the other
hand, it now makes sense to ask questions like the following: “Given that a particle was
at location x1 at time t1 (even though it was not measured at t1), what is the probability
of it being at location x2 at time t2?” The answers to such questions yield a probability
distribution over possible trajectories.

Chapter 16 initiates the study of hidden variables from the discrete, abstract per-
spective of quantum computing.
For me, a hidden-variable theory is simply a way to
convert a unitary matrix that maps one quantum state to another, into a stochastic matrix
I list
that maps the initial probability distribution to the ﬁnal one in some ﬁxed basis.
ﬁve axioms that we might want such a theory to satisfy, and investigate previous hidden-
variable theories of Dieks [97] and Schr¨odinger [213] in terms of these axioms. I also propose
a new hidden-variable theory based on network ﬂows, which are classic objects of study in
computer science, and prove that this theory satisﬁes two axioms called “indiﬀerence” and
“robustness.” A priori, it was not at all obvious that these two key axioms could be satisﬁed
simultaneously.

6
17

Next I turn to a new question: the computational complexity of simulating hidden-
I show that, if we could examine the entire history of a hidden variable,
variable theories.
then we could eﬃciently solve problems that are believed to be intractable even for quan-
tum computers.
In particular, under any hidden-variable theory satisfying the indiﬀerence
axiom, we could solve the Graph Isomorphism and Approximate Shortest Vector prob-
lems in polynomial time, and indeed could simulate the entire class SZK (Statistical Zero
Knowledge). Combining this result with the collision lower bound of Chapter 6, we get an
oracle relative to which BQP is strictly contained in DQP, where DQP (Dynamical Quantum
Polynomial-Time) is the class of problems eﬃciently solvable by sampling histories.

queries, as opposed to O

Using the histories model, I also show that one could search an N -item database
N 1/3
√N
with Grover’s algorithm. On the other
using O
hand, the N 1/3 bound is tight, meaning that one could probably not solve NP-complete
problems in polynomial time. We thus obtain the ﬁrst good example of a model of com-
putation that appears slightly more powerful than the quantum computing model.

(cid:16)

(cid:17)

(cid:0)

(cid:1)

In summary, Chapter 16 ties together many of the themes of this thesis: the
black-box limitations of quantum computers; the application of nontrivial computer science
techniques; the obsession with the computational resources needed to simulate our universe;
and ﬁnally, the use of quantum computing to shine light on the mysteries of quantum
mechanics itself.

18

Chapter 3

Complexity Theory Cheat Sheet

“If pigs can whistle, then donkeys can ﬂy.”

(Summary of complexity theory, attributed to Richard Karp)

To most people who are not theoretical computer scientists, the theory of compu-
tational complexity—one of the great intellectual achievements of the twentieth century—is
simply a meaningless jumble of capital letters. The goal of this chapter is to turn it into a
meaningful jumble.

In computer science, a problem is ordinarily an inﬁnite set of yes-or-no questions:
for example, “Given a graph, is it connected?” Each particular graph is an instance of the
general problem. An algorithm for the problem is polynomial-time if, given any instance as
input, it outputs the correct answer after at most knc steps, where k and c are constants,
and n is the length of the instance, or the number of bits needed to specify it. For example,
in the case of a directed graph, n is just the number of vertices squared. Then P is the class
of all problems for which there exists a deterministic classical polynomial-time algorithm.
Examples of problems in P include graph connectivity, and (as was discovered two years
ago [17]) deciding whether a positive integer written in binary is prime or composite.

Now, NP (Nondeterministic Polynomial-Time) is the class of problems for which, if
the answer to a given instance is ‘yes’, then an omniscient wizard could provide a polynomial-
size proof of that fact, which would enable us to verify it in deterministic polynomial time.
As an example, consider the Satisﬁability problem: “given a formula involving the Boolean
, q (and, or, not), is there an assignment
variables x1, . . . , xn and the logical connectives
to the variables that makes the formula true?” If there is such an assignment, then a
short, easily-veriﬁed proof is just the assignment itself. On the other hand, it might be
extremely diﬃcult to ﬁnd a satisfying assignment without the wizard’s help—or for that
matter, to verify the absence of a satisfying assignment, even given a purported proof of
its absence from the wizard. The question of whether there exist polynomial-size proofs
of unsatisﬁability that can be veriﬁed in polynomial time is called the NP versus coNP
question. Here coNP is the class containing the complement of every NP problem—for
example, “given a Boolean formula, is it not satisﬁable?”

∧

∨

,

The Satisﬁability problem turns out to be NP-complete, which means it is among
the “hardest” problems in NP: any instance of any NP problem can be eﬃciently converted

19

⊆

into an instance of Satisﬁability. The central question, of course, is whether NP-complete
problems are solvable in polynomial time, or equivalently whether P = NP (it being clear
NP). By deﬁnition, if any NP-complete problem is solvable in polynomial time,
that P
then all of them are. One thing we know is that if P
= NP, as is almost universally assumed,
then there are problems in NP that are neither in P nor NP-complete [162]. Candidates for
such “intermediate” problems include deciding whether or not two graphs are isomorphic,
and integer factoring (e.g. given integers N, M written in binary, does N have a prime factor
greater than M ?). The NP-intermediate problems have been a major focus of quantum
algorithms research.

3.1 The Complexity Zoo Junior

I now present a glossary of 12 complexity classes besides P and NP that appear in this
thesis; non-complexity-theorist readers might wish to refer back to it as needed. The
known relationships among these classes are diagrammed in Figure 3.1. These classes
represent a tiny sample of the more than 400 classes described on my Complexity Zoo web
page (www.complexityzoo.com).

PSPACE (Polynomial Space) is the class of problems solvable by a deterministic

classical algorithm that uses a polynomially-bounded amount of memory. Thus NP
PSPACE, since a PSPACE machine can loop through all possible proofs.

⊆

EXP.

EXP (Exponential-Time) is the class of problems solvable by a deterministic
Thus

classical algorithm that uses at most 2q(n) time steps, for some polynomial q.
PSPACE

⊆
BPP (Bounded-Error Probabilistic Polynomial-Time) is the class of prob-
lems solvable by a probabilistic classical polynomial-time algorithm, which given any in-
stance, must output the correct answer for that instance with probability at least 2/3.
It is widely conjectured that BPP = P [147], but not even
BPP
Thus P
⊆
known that BPP

PSPACE.
NP.

PP (Probabilistic Polynomial-Time) is the class of problems solvable by a
probabilistic classical polynomial-time algorithm, which given any instance, need only out-
put the correct answer for that instance with probability greater than 1/2. The following
problem is PP-complete: given a Boolean formula ϕ, decide whether at least half of the
possible truth assignments satisfy ϕ. We have NP

PSPACE and also BPP

PP.

PP

P#P (pronounced “P to the sharp-P”) is the class of problems solvable by
a P machine that can access a “counting oracle.” Given a Boolean formula ϕ, this oracle
returns the number of truth assignments that satisfy ϕ. We have PP

PSPACE.

P#P

⊆

⊆

⊆

BQP (Bounded-Error Quantum Polynomial-Time) is the class of problems
solvable by a quantum polynomial-time algorithm, which given any instance, must output
the correct answer for that instance with probability at least 2/3. More information is in
Chapter 4. We have BPP

PP [55, 16].

BQP

EQP (Exact Quantum Polynomial-Time) is similar to BQP, except that the
probability of correctness must be 1 instead of 2/3. This class is extremely artiﬁcial; it
is not even clear how to deﬁne it independently of the choice of gate set. But for any
reasonable choice, P

BQP.

EQP

⊆

⊆

⊆

⊆

⊆
⊆

⊆

⊆

6
20

⊆

P/poly (P with polynomial-size advice) is the class of problems solvable by a
P algorithm that, along with a problem instance of length n, is also given an “advice string”
zn of length bounded by a polynomial in n. The only constraint is that zn can depend
only on n, and not on any other information about the instance. Otherwise the zn’s can be
P/poly. Since
chosen arbitrarily to help the algorithm.
the zn’s can encode noncomputable problems (for example, does the nth Turing machine
halt?), P/poly is not contained in any uniform complexity class, where “uniform” means
that the same information is available to an algorithm regardless of n. We can also add
polynomial-size advice to other complexity classes, obtaining EXP/poly, PP/poly, and so
on.

It is not hard to show that BPP

PH (Polynomial-Time Hierarchy) is the union of NP, NPNP, NPNPNP

, etc.
Equivalently, PH is the class of problems that are polynomial-time reducible to the follow-
ing form: for all truth assignments x, does there exist an assignment y such that for all
assignments z, . . . , ϕ (x, y, z, . . .) is satisﬁed, where ϕ is a Boolean formula? Here the num-
ber of alternations between “for all” and “there exists” quantiﬁers is a constant independent
of n. Sipser [222] and Lautemann [163] showed that BPP
PH, while Toda [228] showed
that PH

⊆
MA (Merlin Arthur) is the class of problems for which, if the answer to a given
instance is ‘yes,’ then an omniscient wizard could provide a polynomial-size proof of that
fact, which would enable us to verify it in BPP (classical probabilistic polynomial-time, with
probability at most 1/3 of accepting an invalid proof or rejecting a valid one). We have
NP

⊆
AM (Arthur Merlin) is the class of problems for which, if the answer to a given
instance is ‘yes,’ then a BPP algorithm could become convinced of that fact after a constant
number of rounds of interaction with an omniscient wizard. We have MA
PH.
There is evidence that AM = MA = NP [157].

P#P.

PP.

MA

AM

⊆

⊆

⊆

⊆

SZK (Statistical Zero Knowledge) is the class of problems that possess “sta-
AM. Although SZK
tistical zero-knowledge proof protocols.” We have BPP
contains nontrivial problems such as graph isomorphism [130], there are strong indications
that it does not contain all of NP [63].

SZK

⊆

⊆

Other complexity classes, such as PLS, TFNP, BQP/qpoly, and BPPpath, will be

introduced throughout the thesis as they are needed.

3.2 Notation

In computer science, the following symbols are used to describe asymptotic growth rates:

•

•

•

F (n) = O (G (n)) means that F (n) is at most order G (n); that is, F (n)
for all n

0 and some nonnegative constants a, b.

≥

a + bG (n)

≤

F (n) = Ω (G (n)) means that F (n) is at least order G (n); that is, G (n) = O (F (n)).

F (n) = Θ (G (n)) means that F (n) is exactly order G (n); that is, F (n) = O (G (n))
and F (n) = Ω (G (n)).

21

EXP

PSPACE

P#P

PH

AM

MA

NP

P

PP

BQP

EQP

P/poly

SZK

BPP

Figure 3.1: Known relations among 14 complexity classes.

•

F (n) = o (G (n)) means that F (n) is less than order G (n); that is, F (n) = O (G (n))
but not F (n) = Ω (G (n)).

The set of all n-bit strings is denoted

n

0 {

≥

0, 1
}

n, is denoted

0, 1
}
{

∗.

n. The set of all binary strings,

0, 1
}
{

S
3.3 Oracles

One complexity-theoretic concept that will be needed again and again in this thesis is that
of an oracle. An oracle is a subroutine available to an algorithm, that is guaranteed to
compute some function even if we have no idea how. Oracles are denoted using superscripts.
For example, PNP is the class of problems solvable by a P algorithm that, given any instance
of an NP-complete problem such as Satisﬁability, can instantly ﬁnd the solution for that
instance by calling the NP oracle. The algorithm can make multiple calls to the oracle, and
these calls can be adaptive (that is, can depend on the outcomes of previous calls).
If a
quantum algorithm makes oracle calls, then unless otherwise speciﬁed we assume that the
calls can be made in superposition. Further details about the quantum oracle model are
provided in Chapter 5.

∗

We identify an oracle with the function that it computes, usually a Boolean func-
tion f :
. Often we think of f as deﬁning a problem instance, or rather
0, 1
}
{
an inﬁnite sequence of problem instances, one for each positive integer n. For example,
n such that f (x) = 1?” In these cases the oracle string,
“does there exist an x
n, can be thought of as an input that is 2n bits
which consists of f (x) for every x

0, 1
}

0, 1
}

→ {

∈ {

0, 1
}

∈ {

long instead of n bits. Of course, a classical algorithm running in polynomial time could
examine only a tiny fraction of such an input, but maybe a quantum algorithm could do
better. When discussing such questions, we need to be careful to distinguish between two
functions: f itself, and the function of the oracle string that an algorithm is trying is to
compute.

22

23

Chapter 4

Quantum Computing Cheat Sheet

“Somebody says . . . ‘You know those quantum mechanical amplitudes you told
me about, they’re so complicated and absurd, what makes you think those are
right? Maybe they aren’t right.’ Such remarks are obvious and are perfectly
It does not do any good to
clear to anybody who is working on this problem.
point this out.”

—Richard Feynman, The Character of Physical Law [109]

Non-physicists often have the mistaken idea that quantum mechanics is hard.
Unfortunately, many physicists have done nothing to correct that idea. But in newer
textbooks, courses, and survey articles [18, 114, 175, 182, 235], the truth is starting to come
out: if you wish to understand the central ‘paradoxes’ of quantum mechanics, together with
almost the entire body of research on quantum information and computing, then you do
not need to know anything about wave-particle duality, ultraviolet catastrophes, Planck’s
constant, atomic spectra, boson-fermion statistics, or even Schr¨odinger’s equation. All you
need to know is how to manipulate vectors whose entries are complex numbers.
If that is
too diﬃcult, then positive and negative real numbers turn out to suﬃce for most purposes
as well. After you have mastered these vectors, you will then have some context if you wish
to learn more about the underlying physics. But the historical order in which the ideas
were discovered is almost the reverse of the logical order in which they are easiest to learn!
What quantum mechanics says is that, if an object can be in either of two per-
, then it can also be in a linear
. Here α and β are complex numbers
are called

fectly distinguishable states, which we denote
“superposition” of those states, denoted α
0
i
|
2 = 1. The asymmetric brackets
2 +
called “amplitudes,” which satisfy
β
|
“Dirac ket notation”; one gets used to them with time.

0
and
|
i
1
+ β
i
|

α
|
|

1
i

| i

|

|

|

+β

0
i

with probability

If we measure the state α
α
|
|

in a standard way, then we see the “basis state”
1
i
|
2. Also, the state changes to whichever
2, and
with probability
0
|
|
i
and then measure again, nothing having happened in the
outcome we see—so if we see
2 sum to 1, as they ought
interim, we will still see
|
So far, we might as well have described the object using classical probabilities—for
to.
example, “this cat is alive with probability 1/2 and dead with probability 1/2; we simply
don’t know which.”

. The two probabilities

2 and
α
|

1
i
|
0
i
|

0
i
|

β
|

β

|

|

24

The diﬀerence between classical probabilities and quantum amplitudes arises in
how the object’s state changes when we perform an operation on it. Classically, we can
multiply a vector of probabilities by a stochastic matrix, which is a matrix of nonnegative
real numbers each of whose columns sums to 1. Quantum-mechanically, we multiply the
vector of amplitudes by a unitary matrix, which is a matrix of complex numbers that maps
any unit vector to another unit vector. (Equivalently, U is unitary if and only if its inverse
1 equals its conjugate transpose U ∗.) As an example, suppose we start with the state
U −
, which corresponds to the vector of amplitudes
0
i
|

We then left-multiply this vector by the unitary matrix

1
0

.

(cid:21)

(cid:20)

which maps the vector to

and therefore the state

to

0
i
|

U =

1
√2 −
1
√2

1
√2
1
√2 #

,

"

1
√2
1
√2 #

,

"

U

0
i
|

=

1
√2 |

0
i

+

1
1
√2 |
i

.

with probability 1/2.
If we now measured, we would see
The interesting part is what happens if we apply the same operation U a second time,
without measuring. We get

with probability 1/2 and

0
i
|

1
i
|

1
√2 −
1
√2

1
√2
1
√2 # "

1
√2
1
√2 #

"

0
1

=

(cid:20)

(cid:21)

1
i
|

which is
with certainty (see Figure 4.1). Applying a “randomizing” operation to a
“random” state produces a deterministic outcome! The reason is that, whereas probabilities
are always nonnegative, amplitudes can be positive, negative, or even complex, and can
therefore cancel each other out. This interference of amplitudes can be considered the
source of all “quantum weirdness.”

4.1 Quantum Computers: N Qubits

The above description applied to “qubits,” or objects with only two distinguishable states.
Indeed, in
But it generalizes to objects with a larger number of distinguishable states.
quantum computing we consider a system of N qubits, each of which can be
. We
or
0
i
|
then need to assign amplitudes to all 2N possible outcomes of measuring the qubits in order
from ﬁrst to last. So the computer’s state has the form

1
i
|

=

ψ
|

i

N

0,1
Xz
}
∈{

z

αz |

i

25

1

0

+

1

2

0

, with α and β real, can be represented
1
Figure 4.1: Quantum states of the form α
0
i
i
|
by unit vectors in the plane. Then the operation U corresponds to a 45◦ counterclockwise
rotation.

+ β

|

where

2 = 1.

αz|
|

N

0,1
Xz
}
∈{

What was just said is remarkable—for it suggests that Nature needs to keep track of 2N
complex numbers just to describe a state of N interacting particles.
If N = 300, then this
is already more complex numbers than there are particles in the known universe. The goal
of quantum computing is to exploit this strange sort of parallelism that is inherent in the
laws of physics as we currently understand them.

x
i
|

The diﬃculty is that, when the computer’s state is measured, we only see one of
, not the entire collection of amplitudes. However, for a few speciﬁc
the “basis states”
problems, we might be able to arrange things so that basis states corresponding to wrong
answers all have amplitudes close to 0, because of interference between positive and negative
contributions.
If we can do that, then basis states corresponding to right answers will be
measured with high probability.

More explicitly, a quantum computer applies a sequence of unitary matrices called
gates, each of which acts on only one or two of the N qubits (meaning that is a tensor
2 qubits, and the operation of interest on
product of the identity operation on N
the remaining qubits). As an example, the controlled-NOT or CNOT gate is a two-qubit
gate that ﬂips a “target” qubit if a “control” qubit is 1, and otherwise does nothing:

1 or N

−

−

i → |
The unitary matrix corresponding to the CNOT gate is

i → |

i → |

|

00
|

,

00
i

01

,

01
i

10
|

,

11
i

11
|

i → |

.

10
i

1 0 0 0
0 1 0 0
0 0 0 1
0 0 1 0









.





26

Adleman, DeMarrais, and Huang [16] showed that the CNOT gate, together with the one-
qubit gate

4
3
5
5 −
4
3
5 (cid:21)
5

,

(cid:20)

constitute a universal set of quantum gates, in that they can be used to approximate any
other gate to any desired accuracy.
Indeed, almost any set of one- and two-qubit gates is
universal in this sense [94].

A quantum circuit is just a sequence of gates drawn from a ﬁnite universal set.
Without loss of generality, we can take the circuit’s output to be the result of a single
N with probability
2.
measurement after all gates have been applied; that is, z
αz|
|
(If a binary output is needed, we simply throw away the last N
1 bits of z.) It is known
that allowing intermediate measurements does not yield any extra computational power
[55]. The circuit is polynomial-size if both N and the number of gates are upper-bounded
by a polynomial in the length n of the input.

0, 1
}
−

∈ {

We can now deﬁne the important complexity class BQP, or Bounded-Error Quan-
n, ﬁrst a polynomial-time classical algo-
tum Polynomial-Time. Given an input x
∈ {
rithm A prepares a polynomial-size quantum circuit Ux. (The requirement that the circuit
itself be eﬃciently preparable is called uniformity.) Then Ux is applied to the “all-0” initial
n is in BQP if there exists an A such that for all
state
x,

N . We say a language L

0, 1
}

0, 1
}

0
i
|

⊆ {

⊗

(i) If x

∈
(ii) If x /
∈

L then Ux outputs ‘1’ with probability at least 2/3.

L then Ux outputs ‘0’ with probability at least 2/3.

By running Ux multiple times and taking the majority answer, we can boost the

−

probability of success from 2/3 to 1

2−

p(n) for any polynomial p.

BQP was ﬁrst deﬁned in a 1993 paper by Bernstein and Vazirani [55].1 That paper
marked a turning point. Before, quantum computing had been an idea, explored in pio-
neering work by Deutsch [90], Feynman [108], and others. Afterward, quantum computing
was a full-ﬂedged model in the sense of computational complexity theory, which could be
meaningfully compared against other models. For example, Bernstein and Vazirani showed
P#P: informally, quantum computers are at least as powerful as classi-
that BPP
cal probabilistic computers, and at most exponentially more powerful.
(The containment
BQP

PP by Adleman, DeMarrais, and Huang [16].)

P#P was later improved to BQP

BQP

⊆

⊆

Bernstein and Vazirani also gave an oracle problem called Recursive Fourier Sam-
pling (RFS), and showed that it requires nΩ(log n) classical probabilistic queries but only n
quantum queries. This provided the ﬁrst evidence that quantum computers are strictly
= BQP. Soon after-
more powerful than classical probabilistic computers, i.e. that BPP
ward, Simon [220] widened the gap to polynomial versus exponential, by giving an ora-
classical probabilistic queries but only O (n) quantum
cle problem that requires Ω

2n/2

⊆

⊆

1As a historical note, Bernstein and Vazirani [55] deﬁned BQP in terms of “quantum Turing machines.”
However, Yao [248] showed that Bernstein and Vazirani’s deﬁnition is equivalent to the much simpler one
given here. Also, Berthiaume and Brassard [57] had implicitly deﬁned EQP (Exact Quantum Polynomial-
Time) a year earlier, and had shown that it lies outside P and even NP relative to an oracle.

(cid:0)

(cid:1)

6
queries. However, these results attracted limited attention because the problems seemed
artiﬁcial.

27

People ﬁnally paid attention when Shor [219] showed that quantum computers
could factor integers and compute discrete logarithms in polynomial time. The security
of almost all modern cryptography rests on the presumed intractability of those two prob-
It had long been known [177] that factoring is classically reducible to the following
lems.
problem: given oracle access to a periodic function f :
, where R is
exponentially large, ﬁnd the period of f . Shor gave an eﬃcient quantum algorithm for this
oracle problem, by exploiting the quantum Fourier transform, a tool that had earlier been
used by Simon.
(The algorithm for the discrete logarithm problem is more complicated
but conceptually similar.)

1, . . . , R

1, . . . , R

} → {

{

}

Other results in the “quantum canon,” such as Grover’s algorithm [139] and meth-
ods for quantum error-correction and fault-tolerance [20, 80, 132, 159, 225], will be discussed
in this thesis as the need arises.

4.2 Further Concepts

This section summarizes “fancier” quantum mechanics concepts, which are needed for Part
II and for Chapter 10 of Part I (which deals with quantum advice). They are not needed
for the other chapters in Part I.
If

and

product, denoted
i ⊗ |
other. For example, if

Tensor Product.
or
ψ
ψ
|
|
= α

ϕ
i
ψ
i
|

|

ϕ
i

ψ
i
|
, is just a state that consists of
ϕ
i
+ β

are two quantum states, then their tensor
next to each
ψ
i
|
, then
1
i

ϕ
i
|

1
i
|

0
i
|

ϕ
i

and

and

= γ

+ δ

|

|

i |
0
i
|

and

ϕ
i
|

where
∗
such as

If

ψ
h

ϕ
i
|

ψ
|

ϕ
i

i |

= (α

0
i
|

+ β

) (γ

1
i
|

0
i
|

+ δ

1
i
|

) = αγ

00
i

|

+ αδ

01
i
|

+ βγ

Inner Product. The inner product between two states
is deﬁned as
1
= β1 |
i

N
+ βN |

· · ·

+

i

ψ
|

i

ψ
h

ϕ
i
|

= α∗1β1 +

· · ·

+ α∗N βN

+ βδ

10
|
i
1
= α1 |
i

+

|

.

11
i
+αN |

· · ·

N

i

denotes complex conjugate. The inner product satisﬁes all the expected properties,
ψ
h

= 1 and

ψ
|

i

+

) =
φ
i
|

ϕ
i
|
are orthogonal.

ψ
h

+

ψ
h

φ
i
|

.

(

ψ
|

ψ
h
|
and

ϕ
|
i
ϕ
= 0 then we say
i
|
General Measurements.
ϕ1i
{|
ϕji

|h

i

, . . . ,

ϕN i}
|
ϕj i|
ψ
|

in which to measure a state

In principle, we can choose any orthogonal basis of
states
(Whether that measurement
i
can actually be performed eﬃciently is another matter.) Then the probability of obtaining
2. We can even measure in a non-orthogonal basis, a concept called
outcome
Positive Operator Valued Measurements (POVM’s) that I will not explain here. None of
these more general measurements increase the power of the quantum computing model,
since we can always produce the same eﬀect by ﬁrst applying a unitary matrix (possibly
using additional qubits called ancillas), and then measuring in a “standard” basis such as

ψ
|

is

.

|

1
i

{|

, . . . ,

.

N

|

i}

28

|

0
i

+ β

1
i
|

Mixed States. Superposition states, such as α

, are also called pure
states. This is to distinguish them from mixed states, which are the most general kind
of state in quantum mechanics. Mixed states are just classical probability distributions
over pure states. There is a catch, though: any mixed state can be decomposed into
a probability distribution over pure states in inﬁnitely many nonequivalent ways.
For
with probability 1/2, then
with probability 1/2 and
example, if we have a state that is
|
) /√2 with probability
no experiment could ever distinguish it from a state that is (
0
i
|
) /√2 with probability 1/2. For regardless of what orthogonal basis we
1/2 and (
|
measured in, the two possible outcomes of measuring would both occur with probability
1/2. Therefore, this state is called the one-qubit maximally mixed state.

1
0
i
i − |

1
i
+

0
i
|

1
i
|

Density Matrices. We can represent mixed states using a formalism called
with itself, denoted
+
1
= α1 |
i
N complex matrix whose (i, j) entry is αiα∗j . Now suppose we have a
with probability
p. We represent the state by a Hermitian positive deﬁnite matrix ρ with trace 1, as

density matrices. The outer product of
, is an N
ψ
ψ
|
|
state that is
ϕ
i
1
−
follows:

N
+ αN |
0
= γ
i
|

with probability p, and

×
= α

1
i
|

1
i
|

φ
i

+ β

0
i

+ δ

· · ·

i h

ψ

i

i

|

|

|

|

αα∗ αβ∗
βα∗ ββ∗ (cid:21)

ρ = p

ϕ
|

ϕ
|

+ (1

p)

φ
|

= p

φ
|

−

i h

i h

δδ∗ (cid:21)
1. When
When we apply a unitary operation U , the density matrix ρ changes to U ρU −
is the jth diagonal entry
we measure in the standard basis, the probability of outcome
of ρ. Proving that these rules are the correct ones, and that a density matrix really is a
unique description of a mixed state, are “exercises for the reader” (which as always means
the author was too lazy). Density matrices will mainly be used in Chapter 10.

j
|

−

(cid:20)

(cid:20)

i

+ (1

p)

.

γγ∗ γδ∗
δγ∗

Trace Distance. Suppose you are given a system that was prepared in state ρ
with probability 1/2, and σ with probability 1/2. After making a measurement, you must
guess which state the system was prepared in. What is the maximum probability that you
will be correct? The answer turns out to be

1 +

ρ
−
k
2

σ

ktr

σ.

−

where
σ
are the eigenvalues of ρ

ρ
k

−

ktr is the trace distance between ρ and σ, deﬁned as 1

2

λi|
i |

where λ1, . . . , λN

Entanglement. Suppose ρ is a joint state of two systems. If ρ can be written as
, then we say ρ is separable;

ψ

a probability distribution over pure states of the form
otherwise ρ is entangled.
Hamiltonians.

|

i ⊗ |

ϕ
i

Instead of discrete unitary operations, we can imagine that a
quantum state evolves in time by a continuous rotation called a Hamiltonian. A Hamil-
N Hermitian matrix H. To ﬁnd the unitary operation U (t) that is
tonian is an N
eﬀected by “leaving H on” for t time steps, the rule2 is U (t) = e−
iHt. The only place I
use Hamiltonians is in Chapter 14, and even there the use is incidental.

×

P

2Here Planck’s constant is set equal to 1 as always.

29

Part I

Limitations of Quantum
Computers

30

Chapter 5

Introduction

“A quantum possibility is less real than a classical reality, but more real than

a classical possibility.”

—Boris Tsirelson [229]

Notwithstanding accounts in the popular press, a decade of research has made it
clear that quantum computers would not be a panacea. In particular, we still do not have a
quantum algorithm to solve NP-complete problems in polynomial time. But can we prove
that no such algorithm exists, i.e. that NP
BQP? The diﬃculty is that we can’t even
6⊂
prove no classical algorithm exists; this is the P versus NP question. Of course, we could
ask whether NP
= NP—but unfortunately, even this conditional
question seems far beyond our ability to answer. So we need to reﬁne the question even
further: can quantum computers solve NP-complete problems in polynomial time, by brute
force?

BQP assuming that P

6⊂

What is meant by “brute force” is the following.

In Shor’s factoring algorithm

[219], we prepare a superposition of the form

1
√R

R

r=1
X

r
|

g (r)
i

i |

where g (r) = xr mod N for some x, N . But as far as the key step of the algorithm is
concerned, the function g is a “black box.” Given any superposition like the one above,
the algorithm will ﬁnd the period of g assuming g is periodic; it does not need further
information about how g was computed. So in the language of Section 3.3, we might as
well say that g is computed by an oracle.

Now suppose we are given a Boolean formula ϕ over n variables, and are asked to
decide whether ϕ is satisﬁable. One approach would be to exploit the internal structure
of ϕ: “let’s see, if I set variable x37 to TRUE, then this clause here is satisﬁed, but those
other clauses aren’t satisﬁed any longer . . . darn!” However, inspired by Shor’s factoring
algorithm, we might hope for a cruder quantum algorithm that treats ϕ merely as an oracle,
n to an output bit ϕ (x) that is 1 if and only if x satisﬁes
mapping an input string x
0, 1
}
n such that
ϕ. The algorithm would have to decide whether there exists an x

∈ {

0, 1
}

∈ {

6
ϕ (x) = 1, using as few calls to the ϕ oracle as possible, and not learning about ϕ in any
other way. This is what is meant by brute force.

31

A fundamental result of Bennett, Bernstein, Brassard, and Vazirani [51] says that
no brute-force quantum algorithm exists to solve NP-complete problems in polynomial time.
In particular, for some probability distribution over oracles, any quantum algorithm needs
2n/2
oracle calls to decide, with at least a 2/3 chance of being correct, whether there
Ω
n such that ϕ (x) = 1. On a classical computer, of course, Θ (2n) oracle
exists an x
calls are necessary and suﬃcient. But as it turns out, Bennett et al.’s quantum lower bound
is tight, since Grover’s quantum search algorithm [139] can ﬁnd a satisfying assignment (if
it exists) quadratically faster than any classical algorithm. Amusingly, Grover’s algorithm
was proven optimal before it was discovered to exist!

0, 1
}

∈ {

(cid:0)

(cid:1)

A recurring theme in this thesis is the pervasiveness of Bennett et al.’s ﬁnding.

I
will show that, even if a problem has considerably more structure than the basic Grover
search problem, even if “quantum advice states” are available, or even if we could examine
the entire history of a hidden variable, still any brute-force quantum algorithm would take
exponential time.

5.1 The Quantum Black-Box Model

The quantum black-box model formalizes the idea of a brute-force algorithm. For the time
being, suppose that a quantum algorithm’s goal is to evaluate f (X), where f :
0, 1
{
}
state at any time t has the form

→
is a Boolean function and X = x1 . . . xn is an n-bit string. Then the algorithm’s

0, 1
}
{

n

α(t)
i,z |

i, z

.

i

Xi,z

}

∈ {

1, . . . , N

Here i
is the index of an oracle bit xi to query, and z is an arbitrarily large
string of bits called the “workspace,” containing whatever information the algorithm wants
to store there. The state evolves in time via an alternating sequence of algorithm steps and
query steps. An algorithm step multiplies the vector of αi,z’s by an arbitrary unitary matrix
It does not matter how many quantum gates would be needed
that does not depend on X.
, eﬀecting
to
to implement this matrix. A query step maps each basis state
the transformation α(t+1)
xi is the string z, with xi exclusive-OR’ed
⊕
into a particular location in z called the “answer bit.” The reason exclusive-OR is used is
that the query step has to be reversible, or else it would not be unitary.

i,z = α(t)

. Here z

i, z
|

i, z
|

xii

⊕

i,z

xi

⊕

i

At the ﬁnal step T , the state is measured in the standard basis, and the output of

the algorithm is taken to be (say) z1, the ﬁrst bit of z. The algorithm succeeds if

2

α(T )
i,z

2
3

≥

Xi,z : z1=f (X) (cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

∈ {

0, 1
}

n. Here the constant 2/3 is arbitrary. Then the (bounded-error) quantum
for all X
query complexity of f , denoted Q2 (f ), is the minimum over all quantum algorithms A that
succeed at evaluating f , of the number of queries to f made by A. Here the ‘2’ represents
the fact that the error probability is two-sided. One can compare Q2 (f ) with Q0 (f ),

32

or zero-error quantum query complexity; R2 (f ), or bounded-error classical randomized
query complexity; and D (f ), or deterministic query complexity, among other complexity
measures. Chapter 8 will deﬁne many such measures and compare them in detail.

As a simple example of the black-box model, let OR (x1, . . . , xn) = x1 ∨ · · · ∨

xn.
Then Grover’s algorithm [139] implies that Q2 (OR) = O (√n), while the lower bound of
Bennett et al. [51] implies that Q2 (OR) = Ω (√n). By comparison, D (OR) = R2 (OR) =
Θ (n).

The quantum black-box model has some simple generalizations, which I will use
n

when appropriate. First, f can be a partial function, deﬁned only on a subset of
0, 1
}
{
(so we obtain what is called a promise problem). Second, the xi’s do not need to be bits;
in Chapters 6 and 7 they will take values from a larger range. Third, in Chapter 7 the
output will not be Boolean, and there will generally be more than one valid output (so we
obtain what is called a relation problem).

5.2 Oracle Separations

“I do believe it
Against an oracle.”
—Shakespeare, The Tempest

Several times in this thesis, I will use a lower bound on quantum query complexity
to show that a complexity class is not in BQP “relative to an oracle.” The method for turning
query complexity lower bounds into oracle separations was invented by Baker, Gill, and
= NPA. Basically,
Solovay [41] to show that there exists an oracle A relative to which PA
they encoded into A an inﬁnite sequence of exponentially hard search problems, one for
each input length n, such that (i) a nondeterministic machine can solve the nth problem
in time polynomial in n, but (ii) any deterministic machine would need time exponential
in n. They guaranteed (ii) by “diagonalizing” against all possible deterministic machines,
similarly to how Turing created an uncomputable real number by diagonalizing against all
possible computable reals.
Later, Bennett and Gill [54] showed that a simpler way to
guarantee (ii) is just to choose the search problems uniformly at random. Throughout the
thesis, I will cavalierly ignore such issues, proceeding immediately from a query complexity
lower bound to the statement of the corresponding oracle separation.

The point of an oracle separation is to rule out certain approaches to solving
For example, the Baker-Gill-Solovay theorem
an open problem in complexity theory.
implies that the standard techniques of computability theory, which relativize (that is, are
“oblivious” to the presence of an oracle), cannot be powerful enough to show that P = NP.
Similarly, the result of Bennett et al. [51] that Q2 (OR) = Ω (√n) implies that there exists
BQPA. While this does not show that NP
an oracle A relative to which NPA
BQP,
it does show that any proof of NP
BQP would have to use “non-relativizing” techniques
that are unlike anything we understand today.

6⊂
⊆

6⊂

However, many computer scientists are skeptical that anything can be learned
from oracles. The reason for their skepticism is that over the past 15 years, they have
seen several examples of non-relativizing results in classical complexity theory. The most

6
33

famous of these is Shamir’s Theorem [215, 171] that PSPACE
IP, where IP is the class of
problems that have interactive proof systems, meaning that if the answer for some instance
is “yes,” then a polynomial-time veriﬁer can become convinced of that fact to any desired
level of conﬁdence by exchanging a sequence of messages with an omniscient prover.1 By
contrast, oracles had been known relative to which not even coNP, let alone PSPACE, is
contained in IP [117]. So why should we ever listen to oracles again, if they got interactive
proofs so dramatically wrong?

⊆

My answer is threefold. First, essentially all quantum algorithms that we know
today—from Shor’s algorithm, as discussed previously, to Grover’s algorithm, to the quan-
tum adiabatic algorithm2 [106], to the algorithms of Hallgren [141] and van Dam, Hallgren,
and Ip [232]—are oracle algorithms at their core. We do not know of any non-relativizing
quantum algorithm technique analogous to the arithmetization technique that was used to
prove PSPACE
If such a technique is ever discovered, I will be one of the ﬁrst to
⊆
want to learn it.

IP.

The second response is that without oracle results, we do not have even the be-
ginnings of understanding. Once we know (for example) that SZK
BQP relative to an
oracle, we can then ask the far more diﬃcult unrelativized question, knowing something
about the hurdles that any proof of SZK

BQP would have to overcome.

6⊂

The third response is that “the proof of the pudding is in the proving.” In other
words, the real justiﬁcation for the quantum black-box model is not the a priori plausibility
of its assumptions, but the depth and nontriviality of what can be (and has been) proved
in it. For example, the result that coNP
IP relative to an oracle [117] does not tell us
much about interactive proof systems. For given an exponentially long oracle string X, it
is intuitively obvious that nothing a prover could say could convince a classical polynomial-
time veriﬁer that X is the all-0 string, even if the prover and veriﬁer could interact. The
only issue is how to formalize that obvious fact by diagonalizing against all possible proof
systems. By contrast, the quantum oracle separations that we have are not intuitively
obvious in the same way; or rather, the act of understanding them confers an intuition
where none was previously present.

6⊂

⊆

⊆

1Arora, Impagliazzo, and Vazirani [36] claim the Cook-Levin Theorem, that Satisﬁability is NP-complete,
as another non-relativizing result. But this hinges on what we mean by “non-relativizing,” far more than
the PSPACE

IP example.

2Given an assignment x to a 3SAT formula ϕ, the adiabatic algorithm actually queries an oracle that
returns the number of clauses of ϕ that x satisﬁes, not just whether x satisﬁes ϕ or not. Furthermore, van
Dam, Mosca, and Vazirani [233] have shown such an oracle is suﬃcient to reconstruct ϕ. On the other
hand, the adiabatic algorithm itself would be just as happy with a ﬁtness landscape that did not correspond
to any 3SAT instance, and that is what I mean by saying that it is an oracle algorithm at the core.

34

Chapter 6

The Collision Problem

The collision problem of size n, or Coln, is deﬁned as follows. Let X = x1 . . . xn
, with n even. We are guaranteed that

be a sequence of n integers drawn from
either

1, . . . , n
{

}

(1) X is one-to-one (that is, a permutation of

(2) X is two-to-one (that is, each element of

1, . . . , n
{
1, . . . , n
{

}

), or

}
appears in X twice or not at all).

The problem is to decide whether (1) or (2) holds.

(A variant asks us to ﬁnd a
collision in a given two-to-one function. Clearly a lower bound for the collision problem as
deﬁned above implies an equivalent lower bound for this variant.) Because of its simplicity,
the collision problem was widely considered a benchmark for our understanding of quantum
query complexity.

I will show that Q2 (Coln) = Ω

, where Q2 (f ) is the bounded-error quantum
query complexity of function f . The best known upper bound, due to Brassard, Høyer,
(cid:1)
and Tapp [68], is O
(see Section 2.1.1). Previously, though, no lower bound better
than the trivial Ω (1) bound was known. How great a speedup quantum computers yield
for the problem was apparently ﬁrst asked by Rains [193].

n1/3

(cid:0)

(cid:1)

(cid:0)

n1/5

Previous lower bound techniques failed for the problem because they depended on
a function’s being sensitive to many disjoint changes to the input. For example, Beals et al.
, where bs (f ) is the
[45] showed that for all total Boolean functions f , Q2 (f ) = Ω
block sensitivity, deﬁned by Nisan [183] to be, informally, the maximum number of disjoint
changes (to any particular input X) to which f is sensitive.
In the case of the collision
problem, though, every one-to-one input diﬀers from every two-to-one input in at least n/2
places, so the block sensitivity is O (1). Ambainis’s adversary method [27] faces a related
In that method we consider the algorithm and input as a bipartite quantum
obstacle.
state, and upper-bound how much the entanglement of the state can increase via a single
query. But under the simplest measures of entanglement, it turns out that the algorithm
and input can become almost maximally entangled after O (1) queries, again because every
one-to-one input is far from every two-to-one input.1

bs (f )

(cid:16)p

(cid:17)

1More formally, the adversary method cannot prove any lower bound on Q2 (f ) better than RC (f ),
where RC (f ) is the randomized certiﬁcate complexity of f (to be deﬁned in Chapter 8). But for the

My proof is an adaptation of the polynomial method, introduced to quantum com-
puting by Beals et al. [45]. Their idea was to reduce questions about quantum algorithms
to easier questions about multivariate polynomials.
In particular, if a quantum algorithm
makes T queries, then its acceptance probability is a polynomial over the input bits of
degree at most 2T . So by showing that any polynomial approximating the desired output
has high degree, one obtains a lower bound on T .

35

To lower-bound the degree of a multivariate polynomial, a key technical trick is to
construct a related univariate polynomial. Beals et al. [45], using a lemma due to Minsky
) (where
X
and Papert [178], replace a polynomial p (X) (where X is a bit string) by q (
|
X
|

denotes the Hamming weight of X), satisfying

|

|

q (k) = EX
=k

X
|

|

p (X)

deg (p).

and deg (q)

≤

Here I construct the univariate polynomial in a diﬀerent way. I consider a uniform
distribution over g-to-one inputs, where g might be greater than 2. Even though the
problem is to distinguish g = 1 from g = 2, the acceptance probability must lie in the
interval [0, 1] for all g, and that is a surprisingly strong constraint.
I show that the
acceptance probability is close to a univariate polynomial in g of degree at most 2T . I then
obtain a lower bound by generalizing a classical approximation theory result of Ehlich and
Zeller [104] and Rivlin and Cheney [204]. Much of the proof deals with the complication
that g does not divide n in general.

(cid:1)

(cid:0)

n1/3

Shortly after this work was completed, Shi [218] improved it to give a tight lower
bound of Ω
for the collision problem, when the xi range from 1 to 3n/2 rather than
from 1 to n. For a range of size n, his bound was Ω
. Subsequently Kutin [161]
for a range of size n as well. By a
and Ambainis [29] showed a lower bound of Ω
(cid:0)
for the element distinctness
simple reduction, these results imply a lower bound of Ω
(cid:0)
problem—that of deciding whether there exist i
= j such that xi = xj. The previous best
(cid:1)
known lower bound was Ω
, and at the time of Shi’s work, the best known upper
bound was O
, due to Buhrman et al. [77]. Recently, however, Ambainis [30] gave a
novel algorithm based on quantum walks that matches the n2/3 lower bound.

(cid:1)
n2/3

n1/4

n3/4

n1/2

n1/3

(cid:0)

(cid:1)

(cid:0)

(cid:1)

The chapter is organized as follows. Section 6.1 motivates the collision lower bound
within quantum computing, pointing out connections to collision-resistant hash functions,
the nonabelian hidden subgroup problem, statistical zero-knowledge, and information era-
sure. Section 6.2 gives technical preliminaries, Section 6.3 proves the crucial fact that the
acceptance probability is “almost” a univariate polynomial, and Section 6.4 completes the
lower bound argument.
In Section 6.5
n1/7
for the set comparison problem, a variant of the collision
I show a lower bound of Ω
problem needed for the application to information erasure.

I conclude in Section 6.6 with some open problems.

(cid:0)

(cid:1)

(cid:0)

(cid:1)

collision function, RC (Coln) = O (1).

6
36

6.1 Motivation

In Chapter 1 I listed seven implications of the collision lower bound; this section discusses a
few of those implications in more detail. The implication that motivated me personally—
concerning the computational power of so-called hidden-variable theories—is deferred to
Chapter 16.

6.1.1 Oracle Hardness Results

The original motivation for the collision problem was to model (strongly) collision-resistant
hash functions in cryptography. There is a large literature on collision-resistant hashing;
see [201, 42] for example. When building secure digital signature schemes, it is useful to
, such that ﬁnding a distinct (x, y) pair with Hi (x) =
have a family of hash functions
Hi (y) is computationally intractable. A quantum algorithm for ﬁnding collisions using
O (polylog (n)) queries would render all hash functions insecure against quantum attack
in this sense.
(Shor’s algorithm [219] already renders hash functions based on modular
arithmetic insecure.) My result indicates that collision-resistant hashing might still be
possible in a quantum setting.

Hi}
{

The collision problem also models the nonabelian hidden subgroup problem, of
G,
which graph isomorphism is a special case. Given a group G and subgroup H
G,
suppose we have oracle access to a function f : G
f (g1) = f (g2) if and only if g1 and g2 belong to the same coset of H.
Is there then an
eﬃcient quantum algorithm to determine H? If G is abelian, the work of Simon [220], Shor
[219], and Kitaev [152] implies an aﬃrmative answer.
If G is nonabelian, though, eﬃcient
quantum algorithms are known only for special cases [105, 138]. An O (polylog (n))-query
algorithm for the collision problem would yield a polynomial-time algorithm to distinguish
= 2, which does not exploit the group structure at all. My result implies
H
H
|
|
that no such algorithm exists.

≤
N such that for all g1, g2 ∈

= 1 from

→

|

|

6⊂

Finally, the collision lower bound implies that there exists an oracle relative to
which SZK
BQP, where SZK is the class of problems having statistical zero-knowledge
proof protocols. For suppose that a veriﬁer V and prover P both have oracle access to
a sequence X = x1 . . . x2n, which is either one-to-one or two-to-one. To verify with zero
knowledge that X is one-to-one, V can repeatedly choose an i
and send xi to
P , whereupon P must send i back to V . Thus, using standard diagonalization techniques,
one can produce an oracle A such that SZKA

1, . . . , 2n

BQPA.

∈R {

}

6⊂

6.1.2 Information Erasure
m with m

Let f :
kinds of quantum oracle for f :

0, 1
}
{

0, 1
}

→ {

n

≥

n be a one-to-one function. Then we can consider two

(A) a standard oracle, one that maps

x

z
i |

|

⊕

f (x)

, or
i

x
|

z
i |

i

to

(B) an erasing oracle (as proposed by Kasheﬁ et al. [150]), which maps

eﬀect “erasing”

.
x
i
|

to

x
i
|

|

f (x)

, in
i

37

i

to

y
|

f −

1 (y)

Intuitively erasing oracles seem at least as strong as standard ones, though it is
not clear how to simulate the latter with the former without also having access to an oracle
that maps
. The question that concerns us here is whether erasing oracles
are more useful than standard ones for some problems. One-way functions provide a clue:
(cid:12)
(cid:12)
can be computed eﬃciently, but if
if f is one-way, then (by assumption)
f (x)
f (x)
x
i
|
, and hence f could be
f (x)
then so could
x
could be computed eﬃciently given
i
i
inverted. But can we ﬁnd, for some problem, an exponential gap between query complexity
given a standard oracle and query complexity given an erasing oracle?

given

x
i
|

i |

(cid:11)

i

|

|

|

In Section 6.5 I extend the collision lower bound to show an aﬃrmative answer.
Deﬁne the set comparison problem of size n, or SetCompn, as follows. We are given as input
.
two sequences, X = x1 . . . xn and Y = y1 . . . yn, such that for each i, xi, yi ∈ {
}
, and produces as output
A query has the form (b, i), where b
0, 1
∈ {
}
(0, xi) if b = 0 and (1, yi) if b = 1. Sequences X and Y are both one-to-one; that is, xi 6
= xj
= j. We are furthermore guaranteed that either
and yi 6
(1) X and Y are equal as sets (that is,

= yj for all i

1, . . . , 2n

1, . . . , n

and i

) or

∈ {

=

}

x1, . . . , xn}

{

y1, . . . , yn}
{

(2) X and Y are far as sets (that is,

1.1n).

y1, . . . , yn}| ≥

x1, . . . , xn} ∪ {
|{
As before the problem is to decide whether (1) or (2) holds.
This problem can be solved with high probability in a constant number of queries
using an erasing oracle, by using a trick similar to that of Watrous [239] for verifying group
non-membership. First, using the oracle, we prepare the uniform superposition

1
√2n

1,...,n
Xi
∈{

}

xii
0
(
i |
|

+

) .
yii
1
i |
|

We then apply a Hadamard gate to the ﬁrst register, and ﬁnally we measure the ﬁrst register.
) pair
If X and Y are equal as sets, then interference occurs between every (
z
1
i
i |
z
with certainty. But if X and Y are far as sets, then basis states
and we observe
b
0
i
i |
i
|
1
have probability weight at least 1/10, and hence we observe
1
with no matching
i
|
|
with probability at least 1/20.

z
0
i |
|

z
i |

−

b

i

i

|

,

|

In Section 6.5 I sketch a proof that Q2 (SetCompn) = Ω

; that is, no eﬃcient
quantum algorithm using a standard oracle exists for this problem. Recently, Midrijanis
not merely for the set comparison problem,
[176] gave a lower bound of Ω
but for the set equality problem (where we are promised that X and Y are either equal or
(cid:17)
disjoint).

(n/ log n)1/5
(cid:16)

(cid:0)

(cid:1)

n1/7

6.2 Preliminaries

Let A be a quantum query algorithm as deﬁned in Section 5.1. A basis state of A is written
, where xi is exclusive-OR’ed into some
i, z
i, z
|
|
speciﬁed location of z. Between queries, the algorithm can perform any unitary operation

. Then a query replaces each

xii

i, z

by

⊕

i

i

|

6
38

Let α(t)

that does not depend on the input. Let T be the total number of queries. Also, assume
for simplicity that all amplitudes are real; this restriction is without loss of generality [55].
after t queries when the input
i,z (X) be the amplitude of basis state
= h. Let P (X) be the
is X. Also, let ∆ (xi, h) = 1 if xi = h, and ∆ (xi, h) = 0 if xi 6
probability that A returns “two-to-one” when the input is X. Then we obtain a simple
variant of a lemma due to Beals et al. [45].

i, z
|

i

Lemma 1 P (X) is a multilinear polynomial of degree at most 2T over the ∆ (xi, h).

Proof. We show, by induction on t, that for all basis states

, the amplitude
α(t)
i,z (X) is a multilinear polynomial of degree at most t over the ∆ (xi, h). Since P (X) is
a sum of squares of α(t)

i,z’s, the lemma follows.

i, z
|

i

The base case (t = 0) holds since, before making any queries, each α(t)
i,z is a degree-
0 polynomial over the ∆ (xi, h). A unitary transformation on the algorithm part replaces
each α(t)
i,z by a linear combination of α(t)
i,z’s, and hence cannot increase the degree. Suppose
the lemma holds prior to the tth query. Then

α(t+1)
i,z

(X) =

α(t)
i,z
⊕

h (X) ∆ (xi, h) ,

h
X1
≤
≤

n

and we are done.

6.3 Reduction to Bivariate Polynomial

Call the point (g, N )

∈ ℜ

2 an (n, T )-quasilattice point if and only if

(1) g and N are integers, with g dividing N ,

(2) 1

g

≤

≤

√n,

(3) n

N

n + n/ (10T ), and

≤

≤
(4) if g = 1 then N = n.

{

1, . . . , n

For quasilattice point (g, N ), deﬁne

Dn (g, N ) to be the uniform distribution over
and range a subset
}
Dn (g, N ), we ﬁrst choose a set S

. More precisely: to draw an X from
}
with
S
|
|
xN from

all size-n subfunctions of g-to-1 functions having domain
of
1, . . . , n
{
X =
i
1
≤
b
b
b
chosen from

}
x1 . . .
n.
Let P (g, N ) be the probability that algorithm A returns z = 2 when the input is

⊆
n uniformly at random. We then choose a g-to-1 function
xi for each

to S uniformly at random. Finally we let xi =

≤
1, . . . , N
{

1, . . . , N

= N/g

≤

b

}

{

Dn (g, N ):

P (g, N ) =

EX
n(g,N )

∈D

X

[P (X)] .

We then have the following surprising characterization:

39

Lemma 2 For all suﬃciently large n and if T
q (g, N ) of degree at most 2T such that if (g, N ) is a quasilattice point, then

√n/3, there exists a bivariate polynomial

≤

P (g, N )
|

−

q (g, N )

|

< 0.182

(where the constant 0.182 can be made arbitrarily small by adjusting parameters).

Proof. Let I be a product of ∆ (xi, h) variables, with degree r (I), and let I (X)

0, 1
}
{

be I evaluated on input X. Then deﬁne

∈

γ (I, g, N ) =

EX
n(g,N )

∈D

X

[I (X)]

to be the probability that monomial I evaluates to 1 when the input is drawn from
Then by Lemma 1, P (X) is a polynomial of degree at most 2T over X, so

Dn (g, N ).

P (g, N ) =

=

=

X

X

EX
n(g,N )

∈D

[P (X)]

EX
n(g,N ) 

∈D

βI I (X)





2t

XI:r(I)
≤
βI γ (I, g, N )



for some coeﬃcients βI .

XI:r(I)
≤

2T

We now calculate γ (I, g, N ). Assume without loss of generality that for all

∆ (xi, h1) , ∆ (xj, h2)

∈

I, either i

= j or h1 = h2, since otherwise γ (I, g, N ) = 0.
Deﬁne the “range” Z (I) of I to be the set of all h such that ∆ (xi, h)
Z (I)
|

; then we write Z (I) =
|

I. Let
. Clearly γ (I, g, N ) = 0 unless

∈

S, where S is the range of

z1, . . . , zw(I)
X. By assumption,

(cid:8)

(cid:9)

w (I) =
Z (I)

∈

N
b
g ≥

n
√n ≥

2T

≥

r (I)

n
N/g

(cid:18)

(cid:19)

and, of these, the number that contain Z is

so the number of possible S is

w (I)

n
−
N/g

.

w (I)
Then, conditioned on Z

(cid:19)

−

(cid:18)
S, what is the probability that γ (I, g, N ) = 1? The
total number of g-to-1 functions with domain size N is N !/ (g!)N/g , since we can permute
the N function values arbitrarily, but must not count permutations that act only within
the N/g constant-value blocks of size g.

∈

1

j

≤

≤

Among these functions, how many satisfy γ (I, g, N ) = 1? Suppose that, for each
w (I), there are rj (I) distinct i such that ∆ (xi, zj)

I. Clearly

∈
+ rw(I) (I) = r (I) .

r1 (I) +

· · ·

6
Then we can permute the (N
r (I))! function values outside of I arbitrarily, but must not
count permutations that act only within the N/g constant-value blocks, which have size
either g or g

ri (I) for some i. So the number of functions for which γ (I, g, N ) = 1 is

−

−

40

(N

(g!)N/g

−

w(I)

Putting it all together,

r (I))!
w(I)

−

(g

i=1

Y

.

ri (I))!

−

γ (I, g, N ) = (cid:18)

n
−
N/g

w (I)

w (I)

−
n
N/g

(N

=

−

(cid:18)

(cid:19)
r (I))! (n
−
N !n! (N/g

(cid:19)

·

(g!)N/g

r (I))! (g!)N/g
w(I)

(N
−
w(I) N !

−

(g

ri (I))!

Y

i=1

−
(g!)w(I)

w (I))! (N/g)!

w (I))!

·

w(I)

i=1

(g

−

(N

=

r (I))!

−
N !

(n

−

w (I))!
n!

·

=

(N
−
N ! (n

2T )!n!
2T )!

−

qn,T,I (g, N )

w(I)

−

1

Y
N
g −

Yi=0 (cid:18)

ri (I))!

−
w(I)

i
(cid:19)

Yi=1

g




ri(I)

−

1

Yj=1

(g

j)

−





where

e

qn,T,I (g, N ) =

(n

−

w (I))! (n
(n!)2

−

e

is a bivariate polynomial of total degree at most

2T )!

2T

1

−

·

Yi=r(I)

(N

i)

−

w(I)

−

1

Yi=0

(N

gi)

−

w(I)

ri(I)

−

Yi=1

Yj=1

1

(g

j)

−

(2T

−

r (I)) + w (I) + (r (I)

w (I)) = 2T.

−

(Note that in the case ri (I) > g for some i, this polynomial evaluates to 0, which is what
it ought to do.) Hence

where

Clearly

P (g, N ) =

βI γ (I, g, N )

XI:r(I)
≤
(N
−
N ! (n

2T
2T )!n!
2T )!

−

=

q (g, N )

q (g, N ) =

βI

qn,T,I (g, N ) .

XI:r(I)
≤

2T

e

(N
−
N ! (n

2T )!n!

2T )! ≤

−

1.

41

(cid:27)

Since N

≤

n + n/ (10T ) and T

√n/3, we also have

(N
−
N ! (n

≤
2T )!n!

2T )! ≥

−

≥

2T

(cid:19)

n

n
N

(cid:18)
exp

−
−

2T + 1
2T + 1
1
5

n

−

−

(cid:26)
0.818

P (g, N )

q (g, N )

|

≤

−

1,

≤
< 0.182

(2T + 1) /n

≥
for all suﬃciently large n. Thus, since 0

P (g, N )
|

and we are done.

6.4 Lower Bound

We have seen that, if a quantum algorithm for the collision problem makes few queries,
then its acceptance probability can be approximated by a low-degree bivariate polynomial.
This section completes the lower bound proof by showing that no such polynomial exists.
To do so, it generalizes an approximation theory result due to Rivlin and Cheney [204] and
(independently) Ehlich and Zeller [104]. That result was applied to query complexity by
Nisan and Szegedy [184] and later by Beals et al. [45].

Theorem 3 Q2 (Coln) = Ω

n1/5

.

(cid:1)
Proof. Let g have range 1
in the rectangular region R = [1, G]
from Lemma 2, deﬁne

(cid:0)

×

g

G. Then the quasilattice points (g, N ) all lie
≤
[n, n + n/ (10T )]. Recalling the polynomial q (g, N )

≤

Suppose without loss of generality that we require

d (q) = max
∈

(g,N )

R

max

(cid:18)

∂q
∂g

,

n
10T (G

1) ·

−

(cid:26)(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

∂q
∂N

(cid:12)
(cid:12)
(cid:12)
(cid:12)

.

(cid:12)
(cid:27)(cid:19)
(cid:12)
(cid:12)
(cid:12)

P (1, n)

1
10

≤

and P (2, n)

9
10

≥

(that is, algorithm A distinguishes 1-to-1 from 2-to-1 functions with error probability at
most 1/10). Then, since

P (g, N )
|
by elementary calculus we have

−

q (g, N )

|

< 0.182

d (q)

≥

max
2
g
1
≤
≤

∂q
∂g

> 0.8

−

2 (0.182) = 0.436.

An inequality due to Markov (see [82, 184]) states that, for a univariate polynomial p, if
b1 ≤

b2 for all a1 ≤

a2, then

p (x)

≤

≤

x

max
x
≤
≤

a[1]

a[2] (cid:12)
(cid:12)
(cid:12)
(cid:12)

b2 −
a2 −

b1
a1

≤

deg (p)2 .

dp (x)
dx

(cid:12)
(cid:12)
(cid:12)
(cid:12)

R, there exists a quasilattice point (g, N ) for which

42

Clearly for every point

g,

N

(cid:16)

b

b

∈

(cid:17)
g
|

g

−

| ≤

1 and

N

N

−

G.

≤

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

g

—or, in the special case

g = 1, take g = 2, since there is only one quasilattice
For take g =
point with g = 1. Furthermore, since P (g, N ) represents an acceptance probability at such
a point, we have

b

⌈

⌉

b

b

b

Observe that for all

g,

N

(cid:16)
10T G (G
b

n

(cid:17)
b
1)
−

0.182

−

−

(cid:18)

0.182 < q (g, N ) < 1.182.

−

R,

∈

+ 1

d (q) < q

g,

N

< 1.182 +

(cid:19)

(cid:16)

(cid:17)

b

b

10T G (G

n

(cid:18)

1)

−

+ 1

d (q) .

(cid:19)

, and note that the maximum-
1) d (q) /n in the N

For consider a quasilattice point close to

g,

N

magnitude derivative is at most d (q) in the g direction and 10T (G
direction.

(cid:16)

(cid:17)

b

b

−

Let (g∗, N ∗) be a point in R at which the weighted maximum-magnitude derivative
d (q) is attained. Suppose ﬁrst that the maximum is attained in the g direction. Then
q (g, N ∗) (with N ∗ constant) is a univariate polynomial with

for some 1

g

≤

≤

G. So

> 0.436

dq (g, N ∗)
dg

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

2T

≥

deg (q (g, N ∗))

d (q) (G

1)

−

≥ s

1.364 + 2d (q) (1 + 10T G (G

1) /n)

−

= Ω

min

√G,

(cid:18)

(cid:26)

r

n
T G

.

(cid:27)(cid:19)

Similarly, suppose the maximum d (q) is attained in the N direction.

Then

q (g∗, N ) (with g∗ constant) is a univariate polynomial with

for some n

N

≤

≤

n + n/ (10T ). So

dq (g∗, N )
dN

0.436T (G

n

1)

−

>

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

2T

≥ s

(10T (G

1) /n) d (q) n/ (10T )

1.364 + 2d (q) (1 + 10T G (G

−

1) /n)

−

≥

Ω

min

√G,

(cid:18)

(cid:26)

r

n
T G

.

(cid:27)(cid:19)

One can show that the lower bound on T is optimized when we take G = n2/5

√n. Then

43

≤

√n
√T n1/5

,

(cid:27)(cid:19)

T = Ω

min

n1/5,

T = Ω

(cid:18)
n1/5
(cid:16)

(cid:26)

(cid:17)

and we are done.

6.5 Set Comparison

Here I sketch a proof that Q2 (SetCompn) = Ω
son problem of size n as deﬁned in Section 6.1.2.
(cid:0)

(cid:1)

n1/7

, where SetCompn is the set compari-

The idea is the following. We need a distribution of inputs with a parameter g,
such that the inputs are one-to-one when g = 1 or g = 2—since otherwise the problem of
distinguishing g = 1 from g = 2 would be ill-deﬁned for erasing oracles. On the other
hand, the inputs must not be one-to-one for all g > 2—since otherwise the lower bound for
standard oracles would apply also to erasing oracles, and we would not obtain a separation
between the two. Finally, the acceptance probability must be close to a polynomial in g.

The solution is to consider κ (g)-to-one inputs, where

κ (g) = 4g2

12g + 9.

−

is a quadratic with κ (1) = κ (2) = 1. The total range of the inputs (on sequences X and
Y combined) has size roughly n/g; thus, we can tell the g = 1 inputs apart from the g = 2
inputs using an erasing oracle, even though κ (g) is the same for both. The disadvantage is
that, because κ (g) increases quadratically rather than linearly in g, the quasilattice points
to
become sparse more quickly. That is what weakens the lower bound from Ω
Ω
. Note that, using the ideas of Shi [218], one can improve my lower bound on
Q2 (SetCompn) to Ω

n1/7

n1/5

n1/6

(cid:1)

(cid:0)

.

3 an (n, T )-super-quasilattice point if and only if

(cid:0)

(cid:1)

Call (g, N, M )

(cid:0)

(1) g is an integer in

(cid:1)
∈ ℜ
1, n1/3

,

(cid:3)

(2) N and M are integers in [n, n (1 + 1/ (100T ))],

(cid:2)

(3) g divides N ,

(4) if g = 1 then N = n,

(5) κ (g) divides M , and

(6) if g = 2 then M = n.

from distribution
= 2N/g
S
|

For super-quasilattice point (g, N, M ), we draw input (X, Y ) = (x1 . . . xn, y1 . . . yn)
with
}
S with

1, . . . , 2n
2n uniformly at random. We then choose two sets SX, SY ⊆

Ln (g, N, M ) as follows. We ﬁrst choose a set S

⊆ {

≤

|

44

=

= M/κ (g)

SX|
SX|
|
|
κ (g)-1 functions
uniformly at random and independently. Finally we let xi =
1
b

, uniformly at random and independently. Next we choose
S
≤ |
|
SY
Y =
xN :
x1 . . .
} →
yi for each

{
xi and yi =

1, . . . , M

1, . . . , M

SX and

y1 . . .

yN :

X =

} →

b

b

b

b

{

i

≤

≤

b
n.
Deﬁne sets XS =
N = M = n; then by Chernoﬀ bounds,

x1, . . . , xn}

{

and YS =

y1, . . . , yn}

.
b

{

Suppose g = 1 and
b

(X,Y )

n(1,n,n)

Pr
∈L

XS ∪
[
|

YS|

< 1.1n]

≤

2e−

n/10.

Thus, if algorithm A can distinguish
YS|
XS ∪
at least 9/10, then it can distinguish (X, Y )
probability at least 9/10
equivalent lower bound for the former.

2e−

−

|

1.1n with probability
= n from
XS ∪
|
∈ Ln (2, n, n) with
∈ Ln (1, n, n) from (X, Y )
n/10. So a lower bound for the latter problem implies an

YS| ≥

Deﬁne P (X, Y ) to be the probability that the algorithm returns that X and Y

are far on input (X, Y ), and let

P (g, N, M ) =

We then have

(X,Y )

n(g,N,M )

EX
∈L

[P (X, Y )] .

Lemma 4 For all suﬃciently large n and if T
q (g, N, M ) of degree at most 8T such that if (g, N, M ) is a super-quasilattice point, then

n1/3/8, there exists a trivariate polynomial

≤

for some constant 0 < ε < 1/2.

P (g, N, M )
|

−

q (g, N, M )

< ε

|

Proof Sketch. By analogy to Lemma 1, P (X, Y ) is a multilinear polynomial
of degree at most 2T over variables of the form ∆ (xi, h) and ∆ (yi, h). Let I (X, Y ) =
IX (X) IY (Y ) where IX is a product of rX (I) distinct ∆ (xi, h) variables and IY is a product
of rY (I) distinct ∆ (yi, h) variables. Let r (I) = rX (I) + rY (I). Deﬁne

γ (I, g, N, M ) =

(X,Y )

n(g,N,M )

EX
∈L

[I (X, Y )] ;

then

P (g, N, M ) =

βI γ (I, g, N, M )

XI:r(I)
≤
for some coeﬃcients βI . We now calculate γ (I, g, N, M ). As before we assume there are
= h2. Let ZX (I) be the range of IX
no pairs of variables ∆ (xi, h1) , ∆ (xi, h2)
and let ZY (I) be the range of IY . Then let Z (I) = ZX (I)
,
ZX (I)
|
|
wY (I) =

I with h1 6
. By assumption
Z (I)
|

, and w (I) =
ZY (I)
|
|

ZY (I). Let wX (I) =

∪

∈

2T

|

N
g ≥

M
κ (g) ≥

1
4

n1/3

2T

≥

45

w (I)

so

Pr [Z (I)

S] = (cid:18)

⊆

2n
−
2N/g

w (I)

(cid:19)

.

−
2n
2N/g

(cid:18)

(cid:19)
S and ZY (I)

The probabilities that ZX (I)
be calculated similarly.

⊆

SX given Z (I)

⊆

SY given Z (I)

S can

⊆

⊆

so that

Then

Let rX,1 (I) , . . . , rX,w[X](I) (I) be the multiplicities of the range elements in ZX (I),

rX,1 (I) +

· · ·

+ rX,w[X](I) (I) = rX (I) .

Pr [IX (X)

ZX (I)

|

⊆

SX] =

(M

−

rX (I))!
M !

w[X](I)

r[X,i](I)

−

Yi=1

Yj=0

1

(κ (g)

j)

−

and similarly for Pr [IY (Y )

ZY (I)

SY ].

|

⊆

Putting it all together and manipulating, we obtain (analogously to Lemma 1)

that

where
Thus

γ (I, g, N, M )

qn,T,I (g, N, M )

≈

qn,T,I (g, N, M ) is a trivariate polynomial in (g, N, M ) of total degree at most 8T .

e

e

P (g, N, M )

q (g, N, M )

≈

where q (g, N, M ) is a polynomial of total degree at most 8T .
approximates P to within a constant is analogous to that of Lemma 2.

The argument that q

The remainder of the lower bound argument follows the lines of Theorem 3.

Theorem 5 Q2 (SetCompn) = Ω

n1/7

.

Proof Sketch. Let g

points (g, N, M ) all lie in R = [1, G]

(cid:0)
[1, G] for some G
∈

(cid:1)
[n, n + n/ (100T )]2. Deﬁne d(q) to be

n1/3. Then the super-quasilattice

≤

max
(g,N,M )
∈

R

max

×
∂q
∂g

,

n/100T
1)
(G

∂q
∂N

,

n/100T
1)
(G

∂q
∂M

.

Then d (q)

(cid:18)

(cid:26)(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
δ for some constant δ > 0, by Lemma 4.
(cid:12)
(cid:12)
M

(cid:12)
(cid:12)
(cid:12)
(cid:12)
R, there exists a super-quasilattice point (g, N, M )

(cid:12)
(cid:27)(cid:19)
(cid:12)
(cid:12)
(cid:12)

N ,

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

g,

−

−

For every point

≥

such that
g
−
−
b
deviate from [0, 1] by at most

| ≤

1,

g

|

(cid:16)
N

b

(cid:12)
(cid:12)
(cid:12)

N
b

b

(cid:17)
c
≤
(cid:12)
(cid:12)
(cid:12)

∈
G, and

T G3
n

O

(cid:18)(cid:18)

κ (G) . Hence, q

g,

N ,

M

can

(cid:16)

b

b

(cid:17)

c

M

−

(cid:12)
(cid:12)
(cid:12)

≤

M

(cid:12)
(cid:12)
c
(cid:12)

+ 1

d (q)

.

(cid:19)

(cid:19)

Let (g∗, N ∗, M ∗) be a point in R at which d (q) is attained.

Suppose d (q) is
attained in the g direction; the cases of the N and M directions are analogous. Then
q (g, N ∗, M ∗) is a univariate polynomial in g, and

46

8T

≥

deg (q (g, N ∗, M ∗))

= Ω

min

√G,

(cid:18)

(cid:26)

r

n
T G2

.

(cid:27)(cid:19)

One can show that the bound is optimized when we take G = n2/7

n1/3. Then

≤

√n
√T n2/7

,

(cid:27)(cid:19)

T = Ω

min

n1/7,

T = Ω

(cid:18)
n1/7
(cid:16)

(cid:26)
.

(cid:17)

6.6 Open Problems

(cid:0)

(cid:1)

n1/3

In my original paper on the collision problem, I listed four open problems: improving the
; showing any nontrivial quantum lower bound for the set
collision lower bound to Ω
equality problem; proving a time-space tradeoﬀ lower bound for the collision problem; and
deciding whether quantum query complexity and degree as a real polynomial are always
asymptotically equal. Happily, three of these problems have since been resolved [161, 176,
28], but the time-space tradeoﬀ remains wide open. We would like to say (for example)
that if a quantum computer is restricted to using O (log n) qubits, then it needs Θ (√n)
queries for the collision problem, ordinary Grover search being the best possible algorithm.
Currently, we cannot show such a result for any problem with Boolean output, only for
problems such as sorting with a large non-Boolean output [156].

Another problem is to give an oracle relative to which SZK

QMA, where QMA
6⊂
is Quantum Merlin Arthur as deﬁned in [239].
In other words, show that if a function is
one-to-one rather than two-to-one, then this fact cannot be veriﬁed using a small number
of quantum queries, even with the help of a succinct quantum proof.

Finally, is it the case that for all (partial or total) functions f that are invariant

under permutation symmetry, R2 (f ) and Q2 (f ) are polynomially related?

47

Chapter 7

Local Search

This chapter deals with the following problem.
Local Search. Given an undirected graph G = (V, E) and function f : V

N,
f (w) for all neighbors w

→

ﬁnd a local minimum of f —that is, a vertex v such that f (v)
of v.

≤

We will be interested in the number of queries that an algorithm needs to solve
this problem, where a query just returns f (v) given v. We will consider deterministic,
randomized, and quantum algorithms. Section 7.1 motivates the problem theoretically and
practically; this section explains the results.

First, though, we need some simple observations.

If G is the complete graph of
with
size N , then clearly Ω (N ) queries are needed to ﬁnd a local minimum (or Ω
a quantum computer). At the other extreme, if G is a line of length N , then even a
deterministic algorithm can ﬁnd a local minimum in O (log N ) queries, using binary search:
query the middle two vertices, v and w.
f (w), then search the line of length
2) /2 connected to v; otherwise search the line connected to w. Continue recursively
(N
in this manner until a local minimum is found.

If f (v)

√N

≤

−

(cid:16)

(cid:17)

{

0, 1
}

So the interesting case is when G is a graph of ‘intermediate’ connectedness: for
n, with two vertices adjacent if and only if they have
example, the Boolean hypercube
Hamming distance 1. For this graph, Llewellyn, Tovey, and Trick [169] showed a Ω (2n/√n)
lower bound on the number of queries needed by any deterministic algorithm, using a simple
adversary argument.
Intuitively, until the set of vertices queried so far comprises a vertex
cut (that is, splits the graph into two or more connected components), an adversary is free
to return a descending sequence of f -values: f (v1) = 2n for the ﬁrst vertex v1 queried by
the algorithm, f (v2) = 2n
1 for the second vertex queried, and so on. Moreover, once the
set of queried vertices does comprise a cut, the adversary can choose the largest connected
component of unqueried vertices, and restrict the problem recursively to that component.
So to lower-bound the deterministic query complexity, it suﬃces to lower-bound the size
of any cut that splits the graph into two reasonably large components.1 For the Boolean
hypercube, Llewellyn et al. showed that the best one can do is essentially to query all
Ω (2n/√n) vertices of Hamming weight n/2.

−

1Llewellyn et al. actually give a tight characterization of deterministic query complexity in terms of vertex

cuts.

48

n

D

D

D

D

→

0, 1
}

0, 1
}
{

. Taking

Llewellyn et al.’s argument fails completely in the case of randomized algorithms.
over functions
By Yao’s minimax principle, what we want here is a ﬁxed distribution
N, such that any deterministic algorithm needs many queries to ﬁnd a local
f :
minimum of f , with high probability if f is drawn from
to be uniform will
not do, since a local minimum of a uniform random function is easily found. However,
Aldous [24] had the idea of deﬁning
via a random walk, as follows. Choose a vertex
n uniformly at random; then perform an unbiased walk2 v0, v1, v2, . . . starting
v0 ∈ {
from v0. For each vertex v, set f (v) equal to the ﬁrst hitting time of the walk at v—
. Clearly any f produced in this way has a unique local
that is, f (v) = min
minimum at v0, since for all t > 0, if vertex vt is visited for the ﬁrst time at step t then
1). Using sophisticated random walk analysis, Aldous managed to show
f (vt) > f (vt
o(n) on the expected number of queries needed by any randomized
a lower bound of 2n/2
algorithm to ﬁnd v0.3
(As we will see in Section 7.2, this lower bound is close to tight.)
Intuitively, since a random walk on the hypercube mixes in O (n log n) steps, an algorithm
that has not queried a v with f (v) < 2n/2 has almost no useful information about where
the unique minimum v0 is, so its next query will just be a “stab in the dark.”

t : vt = v
{

However, Aldous’s result leaves several questions about Local Search unan-
swered. What if the graph G is a 3-D cube, on which a random walk does not mix very
rapidly? Can we still lower-bound the randomized query complexity of ﬁnding a local
minimum? More generally, what parameters of G make the problem hard or easy? Also,
what is the quantum query complexity of Local Search?

}

−

−

This chapter presents a new approach to Local Search, which I believe points the
way to a complete understanding of its complexity. The approach is based on Ambainis’s
quantum adversary method [27]. Surprisingly, the approach yields new and simpler lower
bounds for the problem’s classical randomized query complexity, in addition to quantum
lower bounds. Thus, along with recent work by Kerenidis and de Wolf [151] and by
Aharonov and Regev [22], the results of this chapter illustrate how quantum ideas can help
to resolve classical open problems.

The results are as follows. For the Boolean hypercube G =

n, I show that
queries to ﬁnd a local minimum on G, and any
any quantum algorithm needs Ω
o(n) lower bound of
queries (improving the 2n/2
randomized algorithm needs Ω
Aldous [24]). The proofs are elementary and do not require random walk analysis. By
comparison, the best known upper bounds are O
for a quantum algorithm and
O

If G is a d-dimensional grid of size N 1/d

for a randomized algorithm.

2n/4/n
2n/2/n2
(cid:0)

2n/3n1/6

2n/2√n

0, 1
}

(cid:1)
(cid:1)

{

(cid:0)

−

(cid:0)
· · · ×
Ω

N 1/d, where d
1/d/ log N
N 1/2

≥

×
3 is a constant, then I show that any quantum algorithm needs
queries to ﬁnd a local minimum on G, and any randomized algorithm

(cid:0)

(cid:1)

(cid:16)p
needs Ω
were previously known in this case.4

1/d/ log N

(cid:17)

−

queries. No nontrivial lower bounds (randomized or quantum)

(cid:0)
In a preprint discussing these results, I raised as my “most ambitious” conjecture
that the deterministic and quantum query complexities of local search are polynomially
related for every family of graphs. At the time, it was not even known whether deterministic

(cid:1)

2Actually, Aldous used a continuous-time random walk, so the functions would be from
3Independently and much later, Droste et al. [99] showed the weaker bound 2g(n) for any g (n) = o (n).
4A lower bound on deterministic query complexity was known for such graphs [168].

0, 1

n to R.

{

}

(cid:1)
−
N 1/2

49

and randomized query complexities were polynomially related, not even for simple examples
such as the 2-dimensional square grid. Subsequently Santha and Szegedy [211] spectacularly
resolved the conjecture, by showing that the quantum query complexity is always at least
the 19th root (!) of the deterministic complexity. On the other hand, in the speciﬁc case of
the hypercube, my lower bound is close to tight; Santha and Szegedy’s is not. Also, I give
randomized lower bounds that are quadratically better than my quantum lower bounds;
Santha and Szegedy give only quantum lower bounds.

In another recent development, Ambainis [25] has improved the Ω

quan-
tum lower bound for local search on the hypercube to 2n/3/nO(1), using a hybrid argument.
Note that Ambainis’s lower bound matches the upper bound up to a polynomial factor.

(cid:0)

(cid:1)

2n/4/n

The chapter is organized as follows. Section 7.1 motivates lower bounds on Local
Search, pointing out connections to simulated annealing, quantum adiabatic algorithms,
and the complexity class TFNP of total function problems. Section 7.2 deﬁnes notation and
reviews basic facts about Local Search, including upper bounds.
In Section 7.3 I give
an intuitive explanation of Ambainis’s quantum adversary method, then state and prove a
classical analogue of Ambainis’s main lower bound theorem. Section 7.4 introduces snakes,
a construction by which I apply the two adversary methods to Local Search.
I show
there that to prove lower bounds for any graph G, it suﬃces to upper-bound a combinatorial
parameter ε of a ‘snake distribution’ on G. Section 7.5 applies this framework to speciﬁc
examples of graphs: the Boolean hypercube in Section 7.5.1, and the d-dimensional grid in
Section 7.5.2.

7.1 Motivation

Local search is the most eﬀective weapon ever devised against hard optimization problems.
For many real applications, neither backtrack search, nor approximation algorithms, nor
even Grover’s algorithm can compare. Furthermore, along with quantum computing, local
search (broadly deﬁned) is one of the most interesting links between computer science and
Nature.
It is related to evolutionary biology via genetic algorithms, and to the physics of
materials via simulated annealing. Thus it is both practically and scientiﬁcally important
to understand its performance.

The conventional wisdom is that, although local search performs well in practice,
its central (indeed deﬁning) ﬂaw is a tendency to get stuck at local optima.
If this were
correct, one corollary would be that the reason local search performs so well is that the
It would thus be
problem it really solves—ﬁnding a local optimum—is intrinsically easy.
unnecessary to seek further explanations for its performance. Another corollary would be
that, for unimodal functions (which have no local optima besides the global optimum), the
global optimum would be easily found.

However, the conventional wisdom is false. The results of Llewellyn et al. [169]
and Aldous [24] show that even if f is unimodal, any classical algorithm that treats f as a
black box needs exponential time to ﬁnd the global minimum of f in general. My results
In my view, the practical upshot of these
extend this conclusion to quantum algorithms.
results is that they force us to confront the question: What is it about ‘real-world’ problems
that makes it easy to ﬁnd a local optimum? That is, why do exponentially long chains

50

of descending values, such as those used for lower bounds, almost never occur in practice,
even in functions with large range sizes? One possibility is that the functions that occur in
practice look “globally” like random functions, but I do not know whether that is true in
any meaningful sense.

The results of this chapter are also relevant for physics. Many physical sys-
tems, including folding proteins and networks of springs and pulleys, can be understood as
performing ‘local search’ through an energy landscape to reach a locally-minimal energy
conﬁguration. A key question is, how long will the system take to reach its ground state
(that is, a globally-minimal conﬁguration)? Of course, if there are local optima, the sys-
tem might never reach its ground state, just as a rock in a mountain crevice does not roll
to the bottom by going up ﬁrst. But what if the energy landscape is unimodal? And
moreover, what if the physical system is quantum? My results show that, for certain en-
ergy landscapes, even a quantum system would take exponential time to reach its ground
state, regardless of what external Hamiltonian is applied to “drive” it. So in particular,
the quantum adiabatic algorithm proposed by Farhi et al. [106], which can be seen as a
quantum analogue of simulated annealing, needs exponential time to ﬁnd a local minimum
in the worst case.

n

Finally, this chapter’s results have implications for so-called total function problems
in complexity theory. Megiddo and Papadimitriou [174] deﬁned a complexity class TFNP,
consisting (informally) of those NP search problems for which a solution always exists.
1 as a Boolean circuit,
For example, we might be given a function f :
and asked to ﬁnd any distinct x, y pair such that f (x) = f (y). This particular problem
belongs to a subclass of TFNP called PPP (Polynomial Pigeonhole Principle). Notice that
no promise is involved: the combinatorial nature of the problem itself forces a solution to
exist, even if we have no idea how to ﬁnd it.
In a recent talk, Papadimitriou [187] asked
broadly whether such ‘nonconstructive existence problems’ might be good candidates for
In the case of PPP problems like the one above, the collision
eﬃcient quantum algorithms.
lower bound of Chapter 6 implies a negative answer in the black-box setting. For other
subclasses of TFNP, such as PODN (Polynomial Odd-Degree Node), a quantum black-box
lower bound follows easily from the optimality of Grover’s search algorithm.

0, 1
}
{

0, 1
}

→ {

−

n

However, there is one important subclass of TFNP for which no quantum lower
bound was previously known. This is PLS (Polynomial Local Search), deﬁned by Johnson,
Papadimitriou, and Yannakakis [149] as a class of optimization problems whose cost function
f and neighborhood function η (that is, the set of neighbors of a given point) are both
computable in polynomial time.5 Given such a problem, the task is to output any local
η (v). The
minimum of the cost function: that is, a v such that f (v)
lower bound of Llewellyn et al. [169] yields an oracle A relative to which FPA
= PLSA,
by a standard diagonalization argument along the lines of Baker, Gill, and Solovay [41].
FBPP,
Likewise, the lower bound of Aldous [24] yields an oracle relative to which PLS
where FBPP is simply the function version of BPP. The results of this chapter yield the
ﬁrst oracle relative to which PLS
In light of this oracle separation, I raise an

f (w) for all w

FBQP.

6⊂

≤

∈

5Some authors require only the minimum neighbor of a given point to be computable in polynomial
time, which does not seem like the “right” idealization to me.
In any case, for lower bound purposes we
always assume the algorithm knows the whole neighborhood structure in advance, and does not need to
make queries to learn about it.

6⊂

6
admittedly vague question: is there a nontrivial “combinatorial” subclass of TFNP that we
can show is contained in FBQP?

7.2 Preliminaries

51

∈

≤

→
V such that f (v)

In the Local Search problem, we are given an undirected graph G = (V, E) with N =
,
|
N. The goal is to ﬁnd any local minimum of f ,
and oracle access to a function f : V
deﬁned as a vertex v
f (w) for all neighbors w of v. Clearly such a
local minimum exists. We want to ﬁnd one using as few queries as possible, where a query
returns f (v) given v. Queries can be adaptive; that is, can depend on the outcomes of
previous queries. We assume G is known in advance, so that only f needs to be queried.
Since we care only about query complexity, not computation time, there is no diﬃculty in
dealing with an inﬁnite range for f —though for lower bound purposes, it will turn out that
suﬃces. I do not know of any case where a range larger than this
a range of size O
|
makes the Local Search problem harder, but I also do not know of a general reduction
(cid:17)
from large to small range.

(cid:16)p

V
|

V

|

∞

The model of query algorithms is the standard one. Given a graph G, the
deterministic query complexity of Local Search on G, which we denote DLS (G), is
minΓ maxf T (Γ, f, G) where the minimum ranges over all deterministic algorithms Γ, the
maximum ranges over all f , and T (Γ, f, G) is the number of queries made to f by Γ before
it halts and outputs a local minimum of f (or
if Γ fails to do so). The randomized query
complexity RLS (G) is deﬁned similarly, except that now the algorithm has access to an
inﬁnite random string R, and must only output a local minimum with probability at least
2/3 over R. For simplicity, one can assume that the number of queries T is the same for
all R; clearly this assumption changes the complexity by at most a constant factor.
v,z,s αv,z,s |

,
i
where v is the label of a vertex in G, and z and s are strings representing the answer register
P
2 =
and workspace respectively. The αv,z,s’s are complex amplitudes satisfying
1. Starting from an arbitrary (ﬁxed) initial state, the algorithm proceeds by an alternating
sequence of queries and algorithm steps. A query maps each
,
i
i
⊕
denotes bitwise exclusive-OR. An algorithm step multiplies the vector of αv,z,s’s
where
Mf denote the set of
by an arbitrary unitary matrix that does not depend on f . Letting
2
3 . Then the
αv,z,s|
local minima of f , the algorithm succeeds if at the end
bounded-error quantum query complexity, or QLS (G), is deﬁned as the minimum number
of queries used by a quantum algorithm that succeeds on every f .

In the quantum model, an algorithm’s state has the form

αv,z,s|
f (v) , s

v, z, s
|

v,z,s |

∈Mf |

v, z, s

P
|

v,z,s : v

v, z

P

to

⊕

≥

2

It is immediate that QLS (G)

RLS (G)

DLS (G)

N . Also, letting δ be the

maximum degree of G, we have the following trivial lower bound.

≤

≤

≤

Proposition 6 RLS (G) = Ω (δ) and QLS (G) = Ω

√δ

.

Proof. Let v be a vertex of G with degree δ. Choose a neighbor w of v uniformly
Let f (v) = 2, and f (u) = 3 for all neighbors u of v
at random, and let f (w) = 1.
other than w. Let S be the neighbor set of v (including v itself); then for all x /
S,
∈
let f (x) = 3 + ∆ (x, S) where ∆ (x, S) is the minimum distance from x to a vertex in S.

(cid:16)

(cid:17)

Clearly f has a unique local minimum at w. However, ﬁnding y requires exhaustive search
√δ
among the δ neighbors of v, which takes Ω

quantum queries by Bennett et al. [51].

52

(cid:17)

(cid:16)

A corollary of Proposition 6 is that classically, zero-error randomized query com-
plexity is equivalent to bounded-error up to a constant factor. For given a candidate local
minimum v, one can check using O (δ) queries that v is indeed a local minimum. Since
Ω (δ) queries are needed anyway, this veriﬁcation step does not aﬀect the overall complexity.
As pointed out by Aldous [24], a classical randomized algorithm can ﬁnd a local
queries. The algorithm just queries √N δ
√N δ
minimum of f with high probability in O
vertices uniformly at random, and lets v0 be a queried vertex for which f (v) is minimal.
It then follows v0 to a local minimum by steepest descent. That is, for t = 0, 1, 2, . . ., it
queries all neighbors of vt, halts if vt is a local minimum, and otherwise sets vt+1 to be the
neighbor w of vt for which f (w) is minimal (breaking ties by lexicographic ordering). A
similar idea yields an improved quantum upper bound.

(cid:16)

(cid:17)

Proposition 7 For any G, QLS (G) = O

N 1/3δ1/6

.

(cid:0)

(cid:1)

Proof. The algorithm ﬁrst chooses N 2/3δ1/3 vertices of G uniformly at random,
then uses Grover search to ﬁnd a chosen vertex v0 for which f (v) is minimal. By a result of
D¨urr and Høyer [102], this can be done with high probability in O
queries. Next,
for t = 0, 1, 2, . . ., the algorithm performs Grover search over all neighbors of vt, looking
for a neighbor w such that f (w) < f (vt).
If it ﬁnds such a w, then it sets vt+1 := w and
continues to the next iteration. Otherwise, it repeats the Grover search log (N/δ) times
before ﬁnally giving up and returning vt as a claimed local minimum.

N 1/3δ1/6

(cid:0)

(cid:1)

The expected number of u such that f (u) < f (v0) is at most N/

=
(N/δ)1/3. Since f (vt+1) < f (vt) for all t, clearly the number of such u provides an upper
bound on t. Furthermore, assuming there exists a w such that f (w) < f (vt), the expected
number of repetitions of Grover’s algorithm until such a w is found is O (1). Since each
√δ
queries, by linearity of expectation the total expected number of
repetition takes O
queries used by the algorithm is therefore

(cid:0)

(cid:1)

N 2/3δ1/3

(cid:16)

(cid:17)

O

N 1/3δ1/6 + (N/δ)1/3 √δ + log (N/δ) √δ

(cid:16)

(cid:17)

N 1/3δ1/6

(cid:0)

or O
. To see that the algorithm ﬁnds a local minimum with high probability,
observe that for each t, the probability of not ﬁnding a w such that f (w) < f (vt), given
(cid:1)
that one exists, is at most c−
So by
the union bound, the probability that the algorithm returns a ‘false positive’ is at most
(N/δ)1/3

(δ/N )1/3 /10 for a suitable constant c.

(δ/N )1/3 /10 = 1/10.

log(N/δ)

≤

·

7.3 Relational Adversary Method

There are essentially two known methods for proving lower bounds on quantum query
complexity: the polynomial method of Beals et al. [45], and the quantum adversary method

of Ambainis [27].6 For a few problems, such as the collision problem [2, 218], the polynomial
method succeeded where the adversary method failed. However, for problems that lack
permutation symmetry (such as Local Search), the adversary method has proven more
eﬀective.7

53

How could a quantum lower bound method possibly be applied classically? When
proving randomized lower bounds, the tendency is to attack “bare-handed”: ﬁx a distri-
bution over inputs, and let x1, . . . , xt be the locations queried so far by the algorithm.
Show that for small t, the posterior distribution over inputs, conditioned on x1, . . . , xt, is
still ‘hard’ with high probability—so that the algorithm knows almost nothing even about
which location xt+1 to query next. This is essentially the approach taken by Aldous [24]
o(n) lower bound on RLS (
to prove a 2n/2
0, 1
}
{

n).
In the quantum case, however, it is unclear how to specify what an algorithm
‘knows’ after a given number of queries. So we are almost forced to step back, and identify
general combinatorial properties of input sets that make them hard to distinguish. Once
we have such properties, we can then try to exhibit them in functions of interest.

−

.

∈ A

B
∈ B

of 1-inputs, and an arbitrary real-valued relation function R (A, B)

We will see, somewhat surprisingly, that this “gloved” approach is useful for clas-
In the relational adversary method, we assume
sical lower bounds as well as quantum ones.
of 0-
there exists a T -query randomized algorithm for function F . We consider a set
0
inputs of F , a set
Intuitively, R (A, B) should be large if A and B diﬀer in only a few
and B
for A
locations. We then ﬁx a probability distribution
over inputs; by Yao’s minimax principle,
there exists a T -query deterministic algorithm Γ∗ that succeeds with high probability on
inputs drawn from
. Let WA be the set of 0-inputs and WB the set of 1-inputs on which
Γ∗ succeeds. Using the relation function R, we deﬁne a separation measure S between WA
and WB, and show that (1) initially S = 0, (2) by the end of the computation S must be
large, and (3) S increases by only a small amount as the result of each query.
It follows
that T must be large.

A

≥

D

D

The advantage of the relational method is that converts a “dynamic” opponent—
an algorithm that queries adaptively—into a relatively static one.
It thereby makes it
easier to focus on what is unique about a problem, aspects of query complexity that are
common to all problems having been handled automatically. Furthermore, one does not
need to know anything about quantum computing to understand and apply the method.
On the other hand, I have no idea how one would come up with it in the ﬁrst place, without
Ambainis’s quantum adversary method [27] and the reasoning about entanglement that led
to it.

The starting point is the “most general” adversary theorem in Ambainis’s original
paper (Theorem 6 in [27]), which he introduced to prove a quantum lower bound for the
problem of inverting a permutation. Here the input is a permutation σ (1) , . . . , σ (N ), and
N/2 and 1 otherwise. To lower-bound this problem’s
the task is to output 0 if σ−
query complexity, what we would like to say is this:

1 (1)

≤

Given any 0-input σ and any location x, if we choose a random 1-input τ that is

6I am thinking here of the hybrid method [51] as a cousin of the adversary method.
7Indeed, Ambainis [28] has given problems for which the adversary method provably yields a better lower

bound than the polynomial method.

‘related’ to σ, then the probability θ (σ, x) over τ that σ (x) does not equal τ (x) is small.
In other words, the algorithm is unlikely to distinguish σ from a random neighbor τ of σ
by querying x.

54

Unfortunately, the above claim is false. Letting x = σ−

=
τ (x) for every 1-input τ , and thus θ (σ, x) = 1. Ambainis resolves this diﬃculty by letting
us take the maximum, over all 0-inputs σ and 1-inputs τ that are related and diﬀer at x,
θ (σ, x) θ (τ, x). Even if θ (σ, x) = 1, the geometric mean is still
of the geometric mean
small provided that θ (τ, x) is small. More formally:

1 (1), we have that σ (x)

p

Theorem 8 (Ambainis) Let
F . Let R (A, B)
location x, let

≥

0 be a symmetric real-valued function, and for A

F −

1 (0) and

A ⊆

B ⊆

F −

1 (1) be sets of inputs to function
, and

, B

∈ A

∈ B

θ (A, x) =

B∗∈B

: A(x)

P

θ (B, x) =

A∗∈A
P

B∗∈B
: A∗(x)

=B∗(x) R (A, B∗)
R (A, B∗)
=B(x) R (A∗, B)
R (A∗, B)

,

,

A∗∈A
where the denominators are all nonzero. Then the number of quantum queries needed to
evaluate F with at least 9/10 probability is Ω (1/υgeom), where

P

P

υgeom =

A

, B

∈A

∈B

max

, x : R(A,B)>0, A(x)

=B(x)

θ (A, x) θ (B, x).

p

The best way to understand Theorem 8 is to see it used in an example.

Proposition 9 (Ambainis) The quantum query complexity of inverting a permutation is
Ω

√N

.

(cid:16)

(cid:17)

Proof. Let

A

the set of permutations τ such that τ −
if σ and τ diﬀer only at locations σ−
given σ, τ with R (σ, τ ) = 1, if x
θ (τ, x) = 2/N . So maxx : σ(x)

=τ (x)

= σ−

be the set of all permutations σ such that σ−

1 (1) > N/2. Given σ
1 (1) and τ −

1 (1)

be
≤
, let R (σ, τ ) = 1
∈ B
1 (1), and R (σ, τ ) = 0 otherwise. Then
1 (1) then

N/2, and

and τ

∈ A

= τ −

B

1 (1) then θ (σ, x) = 2/N , and if x

θ (σ, x) θ (τ, x) =

2/N .

The only diﬀerence between Theorem 8 and my relational adversary theorem is
that in the latter, we take the minimum of θ (A, x) and θ (B, x) instead of the geometric
mean. Taking the reciprocal then gives up to a quadratically better lower bound:
for
example, we obtain that the randomized query complexity of inverting a permutation is
Ω (N ). However, the proofs of the two theorems are quite diﬀerent.

p

p

Theorem 10 Let
needed to evaluate F with at least 9/10 probability is Ω (1/υmin), where

, R, θ be as in Theorem 8. Then the number of randomized queries

A

B

,

υmin =

A

, B

∈A

∈B

max

, x : R(A,B)>0, A(x)

=B(x)

min

θ (A, x) , θ (B, x)
}
{

.

6
6
6
6
6
6
6
6
Proof. Let Γ be a randomized algorithm that, given an input A, returns F (A)
,

with at least 9/10 probability. Let T be the number of queries made by Γ. For all A
B

, deﬁne

∈ A

∈ B

55

M (A) =

R (A, B∗) ,

XB∗∈B

M (B) =

R (A∗, B) ,

XA∗∈A

M =

M (A∗) =

M (B∗) .

XB∗∈B

XA∗∈A
DA be the distribution over A

∈ A

DB be the distribution over B

Now let
in which each A is chosen with probability
M (A) /M ; and let
in which each B is chosen with
probability M (B) /M . Let
DB. By Yao’s minimax
DA and
be an equal mixture of
principle, there exists a deterministic algorithm Γ∗ that makes T queries, and succeeds with
. Therefore Γ∗ succeeds with at least
at least 9/10 probability given an input drawn from
In other words,
4/5 probability given an input drawn from
letting WA be the set of A

D
DA alone, or from

on which Γ∗ succeeds, we have

and WB the set of B

DB alone.

∈ B

D

∈ A

∈ B

M (A)

4
5

M,

≥

WA
XA
∈

WB
XB
∈

M (B)

4
5

M.

≥

Deﬁne a predicate P (t) (A, B), which is true if Γ∗ has distinguished A
the tth query and false otherwise.
for which A (x)
function

by
(To distinguish A from B means to query an index x
, deﬁne a score

= B (x), given either A or B as input.) Also, for all A

from B

∈ A

∈ A

∈ B

S(t) (A) =

R (A, B∗) .

XB∗∈B

: P (t)(A,B∗)

This function measures how much “progress” has been made so far in separating A from

-inputs, where the

B

B

-inputs are weighted by R (A, B). Similarly, for all B

deﬁne

∈ B

It is clear that for all t,

S(t) (B) =

R (A∗, B) .

XA∗∈A

: P (t)(A∗,B)

S(t) (A) =

S(t) (B) .

So we can denote the above sum by S(t) and think of it as a global progress measure. The
proof relies on the following claims about S(t):

XA
∈A

XB
∈B

(i) S(0) = 0 initially.

3M/5 by the end.

(ii) S(T )

≥
(iii) ∆S(t)

≤

3υminM for all t, where ∆S(t) = S(t)

S(t

−

1) is the amount by which S(t)

−

increases as the result of a single query.

6
It follows from (i)-(iii) that

T

≥

3M/5
3υminM

=

1
5υmin

56

which establishes the theorem. Part (i) is obvious. For part (ii), observe that for every
WB, the algorithm Γ∗ must query an x such that
pair (A, B) with A
A (x)

= B (x). Thus

WA and B

∈

∈

S(T )

≥

≥

≥

WA, B
XA
∈

WB

∈
M (A)

XA
WA
∈
4
M
5

−

1
5

M.

R (A, B)

M (B)

−

WB
XB /
∈

It remains only to show part (iii). Suppose ∆S(t) > 3υminM for some t; we will obtain a
contradiction. Let

and let CA be the set of A

∈ A

∆S(t) (A) = S(t) (A)

S(t
−
for which ∆S(t) (A) > υminM (A). Since
∆S(t) (A) = ∆S(t) > 3υminM,

1) (A) ,

−

it follows by Markov’s inequality that

XA
∈A

CA
XA
∈
Similarly, if we let CB be the set of B

∆S(t) (A)

2
3

≥

∆S(t).

for which ∆S(t) (B) > υminM (B), we have

∈ B
∆S(t) (B)

2
3

≥

∆S(t).

CB
XB
∈

∈

CA, and at least 2/3 comes from (A, B) pairs such that B

In other words, at least 2/3 of the increase in S(t) comes from (A, B) pairs such that
A
CB. Hence, by a
CB with R (A, B) > 0 that are
‘pigeonhole’ argument, there exists an A
distinguished by the tth query.
= B (x), such
that the tth index queried by Γ∗ is x whether the input is A or B. Then since A
CA, we
have υminM (A) < ∆S(t) (A), and hence

In other words, there exists an x with A (x)

CA and B

∈

∈

∈

∈

υmin <

∆S(t) (A)
M (A)

B∗∈B

≤ P

: A(x)

B∗∈B

=B∗(x) R (A, B∗)
R (A, B∗)

Similarly υmin < θ (B, x) since B
P

CB. This contradicts the

∈

which equals θ (A, x).
deﬁnition

υmin =

A

, B

∈A

∈B

max

, x : R(A,B)>0, A(x)

min

θ (A, x) , θ (B, x)
}

{

,

=B(x)

and we are done.

6
6
6
6
7.4 Snakes

For the lower bounds, it will be convenient to generalize random walks to arbitrary distri-
butions over paths, which we call snakes.

57

Deﬁnition 11 Given a vertex h in G and a positive integer L, a snake distribution
Dh,L
(parameterized by h and L) is a probability distribution over paths (x0, . . . , xL
1) in G, such
that each xt is either equal or adjacent to xt+1, and xL
1 = h. Let Dh,L be the support of
Dh,L. Then an element of Dh,L is called a snake; the part near x0 is the tail and the part
near xL

1 = h is the head.

−

−

−

Given a snake X and integer t, we use X [t] as shorthand for

.
x0, . . . , xt}

{

Deﬁnition 12 We say a snake X
uniformly at random from
from

0, . . . , L
{
Dh,L conditioned on xt = yt for all t > j. Then

∈
−

Dh,L is ε-good if the following holds. Choose j
1) be a snake drawn
1
}

, and let Y = (y0, . . . , yL

−

(i) Letting SX,Y be the set of vertices v in X

we have

Y such that min

t : xt = v
{

}

= min

{

t : yt = v

,
}

∩

[X

Pr
j,Y

∩

Y = SX,Y ]

9/10.

≥

(ii) For all vertices v, Prj,Y [v

Y [j]]

ε.

≤

∈

The procedure above—wherein we choose a j uniformly at random, then draw a
Y from
Dh,L consistent with X on all steps later than j—will be important in what follows.
I call it the snake X ﬂicking its tail.
Intuitively, a snake is good if it is spread out fairly
evenly in G—so that when it ﬂicks its tail, (1) with high probability the old and new tails
do not intersect, and (2) any particular vertex is hit by the new tail with probability at
most ε.

(If X

I now explain the ‘snake method’ for proving lower bounds for Local Search.
Given a snake X, we deﬁne an input fX with a unique local minimum at x0, and f -values
Y = SX,Y ,
that decrease along X from head to tail. Then, given inputs fX and fY with X
we let the relation function R (fX, fY ) be proportional to the probability that snake Y is
= SX,Y we let R = 0.) Let fX and gY be inputs
obtained by X ﬂicking its tail.
with R (fX, gY ) > 0, and let v be a vertex such that fX (v)
= gY (v). Then if all snakes
were good, there would be two mutually exclusive cases: (1) v belongs to the tail of X, or
In case (1), v is hit with small probability when Y ﬂicks
(2) v belongs to the tail of Y .
In case (2), v is hit with small probability when X ﬂicks its
its tail, so θ (fY , v) is small.
θ (fX, v) θ (fY , v) and
tail, so θ (fX, v) is small.
minimum min
are small. So even though θ (fX, v) or θ (fY , v) could be
large individually, Theorems 8 and 10 yield a good lower bound, as in the case of inverting
a permutation (see Figure 7.1).

In either case, then, the geometric mean

θ (fX, v) , θ (fY , v)

p

∩

∩

Y

}

{

One diﬃculty is that not all snakes are good; at best, a large fraction of them are.
We could try deleting all inputs fX such that X is not good, but that might ruin some
So we would have to delete
remaining inputs, which would then have fewer neighbors.

6
6
58

xj+1=yj+1
6

1
x0

2

Large q (fX,v) 
but small q (fY,v)

3

5

4

3

2

1

y0

7

8

5

4
Large q (fY,v) 
but small q (fX,v)

9

10

11
11

xL-1=yL-1

Figure 7.1: For every vertex v such that fX (v)
= fY (v), either when snake X ﬂicks its
tail v is not hit with high probability, or when snake Y ﬂicks its tail v is not hit with high
probability.

those inputs as well, and so on ad inﬁnitum. What we need is basically a way to replace
“all inputs” by “most inputs” in Theorems 8 and 10.

Fortunately, a simple graph-theoretic lemma can accomplish this. The lemma (see
Diestel [98, p.6] for example) says that any graph with average degree at least k contains an
induced subgraph with minimum degree at least k/2. Below I prove a weighted analogue
of the lemma.

Lemma 13 Let p (1) , . . . , p (m) be positive reals summing to 1. Also let w (i, j) for i, j
1, . . . , m
{
there exists a nonempty subset U
rp (i) /2.

be nonnegative reals satisfying w (i, j) = w (j, i) and

such that for all i
P

i,j w (i, j)
U ,
j

≥
U w (i, j)
∈

1, . . . , m

⊆ {

∈
r. Then

≥

∈

}

}

P

Proof. If r = 0 then the lemma trivially holds, so assume r > 0. We construct
. Then for all t, if there exists an
1, . . . , m

U via an iterative procedure. Let U (0) =
i∗ ∈

U (t) for which

{

}

r
2

p (i∗) ,

w (i∗, j) <

U (t)
Xj
∈

then set U (t + 1) = U (t)
constructed is nonempty, observe that when we remove i∗, the sum
by p (i∗), while

. Otherwise halt and return U = U (t). To see that the U so
U (t) p (i) decreases
i
∈

i∗}

\{

U (t) w (i, j) decreases by at most
∈

P

i,j

P

w (i∗, j) +

w (j, i∗) < rp (i∗) .

U (t)
Xj
∈

U (t)
Xj
∈

So since
the procedure; hence U must be nonempty.

U (t) w (i, j) was positive to begin with, it must still be positive at the end of
∈

i,j

P
I can now prove the main result of the section.

6
Theorem 14 Suppose a snake drawn from
Then

RLS (G) = Ω (1/ε) ,

Dh,L is ε-good with probability at least 9/10.
QLS (G) = Ω
.

1/ε

59

(cid:16)p

(cid:17)

∈

∈

t : xt = v
{

; and for each v /
∈
}

Proof. Given a snake X
X, let fX (v) = min

Dh,L, we construct an input function fX as follows.
X, let fX (v) = ∆ (v, h) + L
For each v
where ∆ (v, h) is the distance from v to h in G. Clearly fX so deﬁned has a unique local
minimum at x0. To obtain a decision problem, we stipulate that querying x0 reveals an
answer bit (0 or 1) in addition to fX (x1); the algorithm’s goal is then to return the answer
bit. Obviously a lower bound for the decision problem implies a corresponding lower bound
for the search problem. Let us ﬁrst prove the theorem in the case that all snakes in Dh,L are
ε-good. Let p (X) be the probability of drawing snake X from
Dh,L. Also, given snakes
, let qj (X, Y ) be the probability that X ∗ = Y , if X ∗ is drawn
X, Y and j
from

Dh,L conditioned on agreeing with X on all steps later than j. Then deﬁne
p (X)
L

w (X, Y ) =

qj (X, Y ) .

0, . . . , L

1
}

∈ {

−

−

L

1

Xj=0

The ﬁrst claim is that w is symmetric; that is, w (X, Y ) = w (Y, X).
that

It suﬃces to show

p (X) qj (X, Y ) = p (Y ) qj (Y, X)

for all j. We can assume X agrees with Y on all steps later than j, since otherwise
Dh,L, let A denote the event that X ∗ agrees
qj (X, Y ) = qj (Y, X) = 0. Given an X ∗ ∈
with X (or equivalently Y ) on all steps later than j, and let BX (resp. BY ) denote the
event that X ∗ agrees with X (resp. Y ) on steps 1 to j. Then

p (X) qj (X, Y ) = Pr [A] Pr [BX|
A]
= p (Y ) qj (Y, X) .

Pr [BY |

A]

·

Now let E (X, Y ) denote the event that X
Y = SX,Y , where SX,Y is as in Deﬁnition
∩
12. Also, let fX be the input obtained from X that has answer bit 0, and gX be the
input that has answer bit 1. To apply Theorems 8 and 10, take
Dh,L}
. Then take R (fX, gY ) = w (X, Y ) if E (X, Y ) holds, and
Dh,L}
and
∈
with R (fX, gY ) > 0, and letting v
R (fX, gY ) = 0 otherwise. Given fX ∈ A
be a vertex such that fX (v)
Y . Suppose
X or v /
∈
the former case; then

and gY ∈ B
= gY (v), we must then have either v /
∈

gX : X
{

fX : X

A

=

=

∈

B

{

fX∗ ∈A

: fX∗
X

(v)

=gY (v)

R (fX∗, gY )

≤

fX∗ ∈A

: fX∗
X

(v)

=gY (v)

p (Y )
L

1

L

−

Xj=0

qj (Y, X ∗)

εp (Y ) ,

≤

since Y is ε-good. Thus θ (gY , v) equals

fX∗ ∈A

P

=gY (v) R (fX∗, gY )
R (fX∗, gY )

(v)

: fX∗
fX∗ ∈A

εp (Y )
9p (Y ) /10

.

≤

P

6
6
6
6
Similarly, if v /
∈

Y then θ (fX, v)

≤

10ε/9 by symmetry. Hence

υmin =

υgeom =

fX ∈A

, gY ∈B

fX ∈A

, gY ∈B

max

, v : R(fX ,gY )>0, fX (v)

=gY (v)

min

{

θ (fX, v) , θ (gY , v)

max

, v : R(fX ,gY )>0, fX (v)

θ (fX, v) θ (gY , v)

≤

=gY (v)

p

r

ε
9/10

} ≤
ε
9/10

,

60

,

the latter since θ (fX, v)

1 and θ (gY , v)

1 for all fX, gY and v.

In the general case, all we know is that a snake drawn from

≤

≤

probability at least 9/10.
: G (X)
fX ∈ A
{

and

B∗ =

}

Let G (X) denote the event that X is ε-good. Take
gY ∈ B

Dh,L is ε-good with
A∗ =
, and take R (fX, gY ) as before. Then since

: G (Y )
}

{

XX,Y : E(X,Y )

w (X, Y )

≥

XX

9
10

p (X)

9
10

,

≥

by the union bound we have

R (fX, gY )

XfX ∈A∗, gY ∈B∗

≥

≥

=

G(Y )
X
∧
1
10

1
10 −

X,Y : G(X)
9
10 −
7
10

.

w (X, Y )

p (X)

−

−

XX : qG(X)

XY : qG(Y )

p (Y )

E(X,Y )

∧

So by Lemma 13, there exist subsets
gY ∈

B

,

A ⊆ A∗ and
e

e

R (fX, gY ∗)

XgY ∗ ∈
B

e

R (fX∗, gY )

XfX∗ ∈
A

≥

≥

B ⊆ B∗ such that for all fX ∈
e
7p (X)
20

,

A

e

and

7p (Y )
20

.

So for all fX, gY with R (fX, gY ) > 0, and all v such that fX (v)
20ε/7 and υgeom ≤
20ε/7. Hence υmin ≤
20ε/7 or θ (gY , v)

≤

e

= gY (v), either θ (fX, v)
20ε/7.

≤

7.5 Speciﬁc Graphs

p

In this section I apply the ‘snake method’ developed in Section 7.4 to speciﬁc examples
of graphs: the Boolean hypercube in Section 7.5.1, and the d-dimensional cubic grid (for
d

3) in Section 7.5.2.

≥

7.5.1 Boolean Hypercube

n denote the n-dimensional Boolean hypercube—that is, the
Abusing notation, let
graph whose vertices are n-bit strings, with two vertices adjacent if and only if they have

0, 1
}

{

6
6
6
n, let v [0] , . . . , v [n
Hamming distance 1. Given a vertex v
bits of v, and let v(i) denote the neighbor obtained by ﬂipping bit v [i].
lower-bound RLS (

∈ {
n).

0, 1
}

0, 1
}
{
Fix a ‘snake head’ h

n) and QLS (
0, 1
{
}
n and take L = 2n/2/100.
0, 1
}

I deﬁne the snake distribu-
Dh,L via what I call a coordinate loop, as follows. Starting from x0 = h, for each t take
with 1/2 probability. The following is

tion
xt+1 = xt with 1/2 probability, and xt+1 = x(t mod n)
a basic fact about this distribution.

∈ {

t

−

61

1] denote the n
In this section I

Proposition 15 The coordinate loop mixes completely in n steps, in the sense that if t∗ ≥
t + n, then xt∗ is a uniform random vertex conditioned on xt.

One could also use the random walk distribution, following Aldous [24]. However,
not only is the coordinate loop distribution easier to work with (since it produces fewer
self-intersections), it also yields a better lower bound (since it mixes completely in n steps,
as opposed to approximately in n log n steps).

I ﬁrst upper-bound the probability, over X, j, and Y [j], that X

SX,Y is as in Deﬁnition 12).

Lemma 16 Suppose X is drawn from
Y [j] is drawn from

Dh,L, j is drawn uniformly from
Y = SX,Y ]

0.9999.

Dxj,j. Then PrX,j,Y [j] [X
Proof. Call a disagreement a vertex v such that

∩

≥

Y

= SX,Y (where

∩

0, . . . , L
{

, and
1
}

−

min

t : xt = v
{

= min

} 6

t∗ : yt∗ = v

.

}

{

If v is a disagreement, then by
Clearly if there are no disagreements then X
∩
the deﬁnition of
n. So by Proposition 15,
Dh,L we cannot have both t > j
−
either yt∗ is uniformly random conditioned on X, or xt is uniformly random conditioned on
Y [j]. Hence PrX,j,Y [j] [xt = yt∗ ] = 1/2n. So by the union bound,

n and t∗ > j

Y = SX,Y .

−

Pr
X,j,Y [j]

[X

∩

Y

= SX,Y ]

L2
2n = 0.0001.

≤

I now argue that, unless X spends a ‘pathological’ amount of time in one part of
the hypercube, the probability of any vertex v being hit when X ﬂicks its tail is small. To
prove this, I deﬁne a notion of sparseness, and then show that (1) almost all snakes drawn
from
Dh,L are sparse (Lemma 18), and (2) sparse snakes are unlikely to hit any given vertex
v (Lemma 19).

Deﬁnition 17 Given vertices v, w and i
steps needed to reach v from x by ﬁrst setting x [i] := v [i], then setting x [i
and so on.
exists a constant c such that for all v

(After we set x [0] we wrap around to x [n
−
n and all k,

, let ∆ (x, v, i) be the number of
1],
−
1].) Then X is sparse if there

1] := v [i

0, . . . , n

1
}

∈ {

−

−

0, 1
}

∈ {

t : ∆ (xt, v, t mod n) = k

|{

}| ≤

cn

n +

(cid:18)

L
2n

−

k

.

(cid:19)

6
6
Lemma 18 If X is drawn from

Proof. For each i

∈ {
i (mod n) is at most L/n. For such a t, let E(v,i,k)

Dh,L, then X is sparse with probability 1
0, . . . , L
, the number of t
0, . . . , n
be the event that ∆ (xt, v, i)

o (1).

1
}

1
}

∈ {

−

−

−

such that
k;

t

t
then E(v,i,k)
t

≡

holds if and only if

xt [i] = v [i] , . . . , xt [i

k + 1] = v [i

k + 1]

−

−

62

≤

(where we wrap around to xt [n
2k/2n over X. Furthermore, by Proposition 15, the E(v,i,k)
independent. So let

1] after reaching xt [0]). This occurs with probability
events for diﬀerent t’s are

−

t

µk =

L
n ·

2k
2n ;

then for ﬁxed v, i, k, the expected number of t’s for which E(v,i,k)
1 then
by a Chernoﬀ bound, if µk ≥

t

holds is at most µk. Thus

Pr
X

t : E(v,i,k)
t

> cn

µk

<

·

h(cid:12)
i
n
(cid:12)
for suﬃciently large c. Similarly, if µk < 1 then
(cid:12)

o(cid:12)
(cid:12)
(cid:12)

ecn
1
−
(cn)cn

(cid:18)

(cid:19)

µk

<

1
22n

Pr
X

h(cid:12)
n
(cid:12)
(cid:12)

t : E(v,i,k)
t

> cn

<

o(cid:12)
(cid:12)
(cid:12)

i

for suﬃciently large c. By the union bound, then,

1

ecn/µk−
(cn/µk)cn/µk !

µk

<

1
22n

t : E(v,i,k)
t
n

(cid:12)
(cid:12)
(cid:12)

cn

·

≤

(1 + µk)

= c

n +

(cid:18)

L
2n

−

k

(cid:19)

o(cid:12)
(cid:12)
(cid:12)

for every v, i, k triple simultaneously with probability at least 1
Summing over all i’s produces the additional factor of n.

−

n22n/22n = 1

o (1).

−

Lemma 19 If X is sparse, then for every v

∈ {

n,

0, 1
}
n2
L

(cid:18)

.

(cid:19)

[v

Pr
j,Y

∈

Y [j]] = O

Proof. By assumption, for every k

0, . . . , n

,
}

∈ {

[∆ (xj, v, j mod n) = k]

Pr
j

|{

t : ∆ (xt, v, t mod n) = k
L

}|

cn
L

n +

(cid:18)

L
2n

−

k

.

(cid:19)

≤

≤

 
Consider the probability that v

∈

Y [j] in the event that ∆ (xj, v, j mod n) = k. Clearly

[v

Pr
Y

yj

∈ {

n+1, . . . , yj}

−

] =

1
2k .

63

Also, Proposition 15 implies that for every t
So by the union bound,

j

−

≤

Then Prj,Y [v

∈

Y [j]] equals

[v

Pr
Y

∈ {

y0, . . . , yj

]
n}

−

≤

L
2n .

n, the probability that yt = v is 2−

n.

n

Xk=0 (cid:18)

Prj [∆ (xj, v, j mod n) = k]

∆ (xj, v, j mod n) = k]

·

PrY [v

Y [j]

∈

|

n +

L
2n

−

k

1
2k +

L
2n

(cid:19)

(cid:19) (cid:18)

n

≤

(cid:19)

Xk=0

= O

(cid:18)

cn
L

(cid:18)
cn2
L

(cid:19)

as can be veriﬁed by breaking the sum into cases and doing some manipulations.

The main result follows easily:

Theorem 20

RLS (

0, 1
}
{

n) = Ω

2n/2
n2

!

, QLS (
{

0, 1
}

n) = Ω

2n/4
n !

.

Proof. Take ε = n2/2n/2. Then by Theorem 14, it suﬃces to show that a snake

X drawn from

Dh,L is O (ε)-good with probability at least 9/10. First, since
Y = SX,Y ]

0.9999

[X

Pr
X,j,Y [j]

∩

≥

by Lemma 16, Markov’s inequality shows that

Pr
j,Y [j]

[X

∩

Pr
X

(cid:20)

Y = SX,Y ]

9
10

≥

≥

(cid:21)

19
20

.

Second, by Lemma 18, X is sparse with probability 1
sparse then

o (1), and by Lemma 19, if X is

−

[v

Pr
j,Y

∈

Y [j]] = O

(cid:18)

= O (ε)

(cid:19)

n2
L

for every v. So both requirements of Deﬁnition 12 hold simultaneously with probability at
least 9/10.

 
 
64

Dh,L moves a random distance left or
Figure 7.2: In d = 3 dimensions, a snake drawn from
right, then a random distance up or down, then a random distance inward or outward, etc.

7.5.2 Constant-Dimensional Grid Graph

In the Boolean hypercube case,
Dh,L was deﬁned by a ‘coordinate loop’ instead of the
usual random walk mainly for convenience. When we move to the d-dimensional grid,
though, the drawbacks of random walks become more serious: ﬁrst, the mixing time is
too long, and second, there are too many self-intersections, particularly if d
4. The
snake distribution will instead use straight lines of randomly chosen lengths attached at the
3. That is,
endpoints, as in Figure 7.2. Let Gd,N be a d-dimensional grid graph with d
1, . . . , N 1/d
1]), where each v [i] is in
Gd,N has N vertices of the form v = (v [0] , . . . , v [d
(assume for simplicity that N is a dth power). Vertices v and w are adjacent if and only
(cid:9)
if
= i (so Gd,N does
1
}
not wrap around at the boundaries).

, and v [j] = w [j] for all j

= 1 for some i

w [i]
|

0, . . . , d

v [i]
|

∈ {

≤

−

≥

−

−

(cid:8)

Take L = √N /100, and deﬁne the snake distribution

Dh,L as follows. Starting
from x0 = h, for each T take xN 1/d(T +1) identical to xN 1/dT , but with the (T mod d)th
coordinate xN 1/d(T +1) [T mod d] replaced by a uniform random value in
. Then
1 to lie along the shortest path from xN 1/dT to
take the vertices xN 1/dT +1, . . . , xN 1/dT +N 1/d
xN 1/d(T +1), ‘stalling’ at xN 1/d(T +1) once that vertex has been reached. Call

1, . . . , N 1/d

(cid:8)

(cid:9)

−

ΦT =

xN 1/dT , . . . , xN 1/dT +N 1/d

1

−

a line of vertices, whose direction is T mod d. As in the Boolean hypercube case, we have:

(cid:1)

(cid:0)

Proposition 21
then xN 1/dT ∗

Dh,L mixes completely in dN 1/d steps, in the sense that if T ∗ ≥

is a uniform random vertex conditioned on xN 1/dT .

T + d,

Lemma 16 in Section 7.5.1 goes through essentially without change.

Deﬁnition 22 Letting ∆ (x, v, i) be as before, we say X is sparse if there exists a constant
c (possibly dependent on d) such that for all vertices v and all k,

t : ∆

xt, v,

t/N 1/d

mod d

= k

(cid:16)

j

k

(cid:17)

(cid:12)
n
(cid:12)
(cid:12)

≤

o(cid:12)
(cid:12)
(cid:12)

(c log N )

N 1/d +

(cid:18)

L

N 1

−

k/d

.

(cid:19)

6
Lemma 23 If X is drawn from

Dh,L, then X is sparse with probability 1

−

o (1).

65

Proof. Similar to Lemma 18. Let ΦT be a line of vertices with direction i =
T mod d, and notice that ∆ (xt, v, i) is the same for every vertex xt in ΦT . Let E(v,i,k)
occurs with probability
denote the event that ∆ (xt, v, i)
N (k
are independent
events. So let

k for the xt’s in ΦT . Then E(v,i,k)

1)/d/N over X. Furthermore, if

T
and E(v,i,k)

d then E(v,i,k)

T
|

T ∗

−

≤

−

T

T

T ∗| ≥
N (k

µk = L

·

1)/d

;

−
N

then for ﬁxed v, i, k, the expected number of lines for which E(v,i,k)
Thus, by a Chernoﬀ bound, if µk ≥

1 then

T

Pr
X

T : E(v,i,k)
T

> c log N

1

ec log N
(c log N )c log N

−

·

µk

<

i

which is at most 1/N 2 for suﬃciently large c.
(c log N ) /µk,

o(cid:12)
(cid:12)
(cid:12)

holds is at most µk.

µk

!

Similarly, if µk < 1 then letting m =

T : E(v,i,k)
T

> c log N

<

h(cid:12)
n
(cid:12)
(cid:12)

o(cid:12)
(cid:12)
So with probability 1
(cid:12)

i
−

1

em
−
mm

µk

<

1
N 2

(cid:18)

(cid:19)

o (1) it holds that for all v, k, letting

h(cid:12)
n
(cid:12)
(cid:12)

Pr
X

for suﬃciently large c.
it =

t/N 1/d

mod d,

(cid:4)

(cid:5)

t : ∆ (xt, v, it) = k

|{

}| ≤

c log N

·
= (c log N )

(1 + µk)

·
N 1/d +

Lemma 24 If X is sparse, then for every v

(cid:18)

Gd,N ,

∈

N 1/d
L

N 1

−

k/d

.

(cid:19)

[v

Pr
j,Y

∈

Y [j]] = O

N 1/d log N
L

,

!

where the big-O hides a constant dependent on d.

Proof. As in Lemma 19, setting ij =

j/N 1/d

mod d we obtain that Prj,Y [v

Y [j]]

∈

equals

d

Xk=1

d

≤

Xk=1

= O

(cid:4)

Pr
j

[∆ (xj, v, ij ) = k] Pr
Y

[v

∈

Y [j]

(cid:5)

|

∆ (xj, v, ij ) = k]

L

1

N 1

−

k/d

(cid:19) (cid:18)

N (k

−

1)/d

+

L
N

(cid:19)

c log N
L

(cid:18)

N 1/d +

N 1/d log N
L

.

!

 
 
 
66

By the same proof as for Theorem 20, taking ε = (log N ) /N 1/2

−

1/d yields the

following:

Theorem 25 Neglecting a constant dependent on d, for all d

3

≥

RLS (Gd,N ) = Ω

QLS (Gd,N ) = Ω

N 1/2

1/d

−
log N !

,

N 1/2

1/d

−
log N 

.





s



 
67

Chapter 8

Quantum Certiﬁcate Complexity

S → {

0, 1
}

be a Boolean function with

This chapter studies the relationships between classical and quantum measures of
n, that takes
query complexity. Let f :
input Y = y1 . . . yn. Then the deterministic query complexity D (f ) is the minimum number
of queries to the yi’s needed to evaluate f , if Y is chosen adversarially and if queries can
be adaptive (that is, can depend on the outcomes of previous queries). Also, the bounded-
error randomized query complexity, R2 (f ), is the minimum expected number of queries
needed by a randomized algorithm that, for each Y , outputs f (Y ) with probability at least
2/3. Here the ‘2’ refers to two-sided error; if instead we require f (Y ) to be output with
probability 1 for every Y , we obtain R0 (f ), or zero-error randomized query complexity.

0, 1
}

S ⊆ {

Analogously, Q2 (f ) is the minimum number of queries needed by a quantum
0, 1
algorithm that outputs f (Y ) with probability at least 2/3 for all Y . Also, for k
}
let Qk
0 (f ) be the minimum number of queries needed by a quantum algorithm that outputs
= k.
f (Y ) with probability 1 if f (Y ) = k, and with probability at least 1/2 if f (Y )
Then let Q0 (f ) = max
If we require a single algorithm that succeeds
.
with probability 1 for all Y , we obtain QE (f ), or exact quantum query complexity. See
Buhrman and de Wolf [78] for a more detailed survey of these measures.

0 (f ) , Q1

0 (f )

∈ {

Q0

(cid:8)

(cid:9)

It is immediate that

Q 2 (f )

R 2 (f )

R 0 (f )

D (f )

n,

≤

≤

≤

≤

≤

D (f ). If f is partial (i.e.

R0 (f ), and that QE (f )

n), then Q2 (f )
that Q0 (f )
can be superpolynomially smaller than R2 (f ); this is what makes Shor’s period-ﬁnding
algorithm [219] possible. For total f , by contrast, the largest known gap even between
D (f ) and Q2 (f ) is quadratic, and is achieved by the OR function on n bits: D (OR) = n
(indeed R2 (OR) = Ω (n)), whereas Q2 (OR) = Θ (√n) because of Grover’s search algorithm
, while
[139]. Furthermore, for total f , Beals et al. [45] showed that D (f ) = O

0, 1
}
{

S 6

=

≤

de Wolf [244] showed that D (f ) = O

Q2 (f )2 Q0 (f )2

.

The result of Beals et al. [45] relies on two intermediate complexity measures, the

(cid:16)

(cid:17)

certiﬁcate complexity C (f ) and block sensitivity bs (f ), which are deﬁned as follows.

Deﬁnition 26 A certiﬁcate for an input X is a set S

1, . . . , n

⊆ {

}

such that for all inputs

Q2 (f )6
(cid:16)

(cid:17)

6
Deterministic Randomized Quantum

Query complexity
Certiﬁcate complexity

D (f )
C (f )

R2 (f )
RC (f )

Q2 (f )
QC (f )

Table 8.1: Query complexity measures and their certiﬁcate complexity analogues.

68

Y of f , if yi = xi for all i
certiﬁcate for X, and C (f ) is the maximum of CX (f ) over all X.

S then f (Y ) = f (X). Then CX (f ) is the minimum size of a

∈

=
Deﬁnition 27 A sensitive block on input X is a set B
}
B. Then bsX (f ) is the
f (X), where X (B) is obtained from X by ﬂipping xi for each i
maximum number of disjoint sensitive blocks on X, and bs (f ) is the maximum of bsX (f )
over all X.

such that f

1, . . . , n

⊆ {

∈

(cid:0)

(cid:1)

X (B)

Clearly bs (f )

C (f )

D (f ). For total f , these measures are all polynomially

related: Nisan [183] showed that C (f )
C (f ) bs (f ). Combining these results with bs (f ) = O

≤

≤

≤

bs (f )2, while Beals et al. [45] showed that D (f )

≤
(from the optimality of

Q2 (f )2

(cid:17)

Grover’s algorithm), one obtains D (f ) = O

Q2 (f )6
(cid:16)

(cid:16)

.

(cid:17)

8.1 Summary of Results

I investigate RC (f ) and QC (f ), the bounded-error randomized and quantum generaliza-
tions of the certiﬁcate complexity C (f ) (see Table 8.1). My motivation is that, just as
C (f ) was used to show a polynomial relation between D (f ) and Q2 (f ), so RC (f ) and
QC (f ) can lead to new relations among fundamental query complexity measures.

What the certiﬁcate complexity C (f ) measures is the number of queries used to
verify a certiﬁcate, not the number of bits used to communicate it. Thus, if we want
to generalize C (f ), we should assume the latter is unbounded. A consequence is that
without loss of generality, a certiﬁcate is just a claimed value X for the input Y 1—since
any additional information that a prover might provide, the veriﬁer can compute for itself.
The veriﬁer’s job is to check that f (Y ) = f (X). With this in mind I deﬁne RC (f ) as
follows.

Deﬁnition 28 A randomized veriﬁer for input X is a randomized algorithm that, on input
Y to f , (i) accepts with probability 1 if Y = X, and (ii) rejects with probability at least 1/2 if
f (Y )
= X but f (Y ) = f (X), the acceptance probability can be arbitrary.)
Then RCX (f ) is the minimum expected number of queries used by a randomized veriﬁer
for X, and RC (f ) is the maximum of RCX (f ) over all X.

= f (X). (If Y

I deﬁne QC (f ) analogously, with quantum instead of randomized algorithms. The
following justiﬁes the deﬁnition (the RC (f ) part was originally shown by Raz et al. [197]).

1Throughout this chapter, I use Y to denote the ‘actual’ input being queried, and X to denote the

‘claimed’ input.

6
6
6
Proposition 29 Making the error probability two-sided rather than one-sided changes RC (f )
and QC (f ) by at most a constant factor.

69

Proof. For RC (f ), let rY

V be the event that veriﬁer V rejects on input Y , and
let dY
V be the event that V encounters a disagreement with X on Y . We may assume
rY
rY
Pr
= 1. Suppose that Pr
=
V |
V
f (X). We wish to lower-bound Pr
= f (X). Observe that

ε0 if Y = X and Pr
≤
for all Y such that f (Y )
(cid:2)

ε1 if f (Y )

dY
V

≥

−

1

(cid:3)

(cid:2)

Pr

Hence for f (Y )

qdY

rY
V ∧
(cid:2)
= f (X),

V |

f (Y )

Pr

≤

rX
V ∧

qdX
V

= Pr

ε0.

≤

(cid:3)

(cid:2)

(cid:3)

(cid:2)

(cid:3)

rY
V
dY
V
(cid:2)
(cid:2)

(cid:3)
(cid:3)

= f (X)

(cid:3)
rX
V

Pr

dY
V

Pr

rY
V

≥

Pr

−

rY
V ∧

qdY
V

1

ε1 −

−

≥

ε0.

(cid:2)
Now let V ∗ be identical to V except that, whenever V rejects despite having found no
= f (X),
disagreement with X, V ∗ accepts. Clearly Pr

= 0. Also, in the case f (Y )

(cid:3)

(cid:3)

(cid:3)

(cid:2)

(cid:2)

rX
V ∗

Pr

rY
V ∗

= Pr

(cid:2)

dY
V

(cid:3)
1

≥

ε1 −

−

ε0.

The result follows since O (1) repetitions suﬃce to boost any constant error probability to
any other constant error probability.

(cid:2)

(cid:3)

(cid:2)

(cid:3)

For QC (f ), suppose the veriﬁer’s ﬁnal state given input Y is

αY

z
z |

i

βY
0
z |
i

+ γY

1
z |
i

z
X

(cid:0)
is the accept state, and

0
i

is the reject state,

where
|
also that AX
is the probability of accepting. Then the veriﬁer can make AX = 1 by performing the
(cid:12)
(cid:12)
conditional rotation

= 1 for all z. Suppose
2

ε1 whenever f (Y )
(cid:12)
(cid:12)

ε0 and that AY

z γY
αY
z

1
i
|

P

≤

≥

−

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

1

z

2

2

+

(cid:1)
βY
z
= f (X), where AY =
(cid:12)
(cid:12)

γY
z

on the second register prior to measurement.

AY =

2

αY
z

= f (X), this produces

γX
z −
βX
z

βX
z
γX
z (cid:19)
In the case f (Y )

(cid:18)

z βY
βX

z + γX

z γY
z

z
X
2

(cid:12)
(cid:12)

(cid:12)
(cid:12)
αY
z

(cid:12)
2
(cid:12)

βX
z

2

+

γY
z

z
X

(cid:12)
(cid:12)
2 (ε0 + ε1) .

(cid:12)
(cid:12)

(cid:16)(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:17)

(cid:12)
(cid:12)

2

(cid:12)
2
(cid:12)

≤

≤

It is immediate that QC (f )

C (f ), that QC (f ) = O (Q2 (f )), and
RC (f )
that RC (f ) = O (R2 (f )). We also have RC (f ) = Ω (bs (f )), since a randomized veriﬁer
for X must query each sensitive block on X with 1/2 probability. This suggests viewing
RC (f ) as an ‘alloy’ of block sensitivity and certiﬁcate complexity, an interpretation for
which Section 8.5 gives some justiﬁcation.

≤

≤

6
6
6
6
6
6
6
70

(cid:17)

(cid:16)p

RC (f )

The results of this chapter are as follows.

In Section 8.3 I show that QC (f ) =
for all f (partial or total), precisely characterizing quantum certiﬁcate com-
Θ
plexity in terms of randomized certiﬁcate complexity. To do this, I ﬁrst give a nonadaptive
characterization of RC (f ), and then apply the adversary method of Ambainis [27] to lower-
bound QC (f ) in terms of this characterization. Then, in Section 8.4, I extend results on
polynomials due to de Wolf [244] and to Nisan and Smolensky (as described by Buhrman
and de Wolf [78]), to show that R0 (f ) = O (RC (f ) ndeg (f ) log n) for all total f , where
ndeg (f ) is the minimum degree of a polynomial p such that p (X)
= 0 if and only if
= 0. Combining the results of Sections 8.3 and 8.4 leads to a new lower bound on
f (X)
Q2 (f )2 Q0 (f ) log n
quantum query complexity: that R0 (f ) = O
for all total f . To my
knowledge, this is the ﬁrst quantum lower bound to use both the adversary method and
(cid:16)
the polynomial method at diﬀerent points in the argument.

(cid:17)

Finally, in Section 8.5, I exhibit asymptotic gaps between RC (f ) and other query
, and a sym-
I conclude in Section

complexity measures, including a total f for which C (f ) = Θ
metric partial f for which QC (f ) = O (1) yet Q2 (f ) = Ω (n/ log n).
8.6 with some open problems.

QC (f )2.205
(cid:16)

(cid:17)

8.2 Related Work

Raz et al. [197] studied a query complexity measure they called ma (f ), for Merlin-Arthur.
In my notation, ma (f ) equals the maximum of RCX (f ) over all X with f (X) = 1. Raz
et al. observed that ma (f ) = ip (f ), where ip (f ) is the number of queries needed given
arbitrarily many rounds of interaction with a prover. They also used error-correcting codes
to construct a total f for which ma (f ) = O (1) but C (f ) = Ω (n). This has similarities to
the construction, in Section 8.5.2, of a symmetric partial f for which QC (f ) = O (1) but
Q2 (f ) = Ω (n/ log n). Aside from that and from Proposition 29, Raz et al.’s results do not
overlap with the results here.

Watrous [239] has investigated a diﬀerent notion of ‘quantum certiﬁcate complexity’—

whether certiﬁcates that are quantum states can be superpolynomially smaller than any
classical certiﬁcate. Also, de Wolf [245] has investigated ‘nondeterministic quantum query
complexity’ in the alternate sense of algorithms that accept with zero probability when
f (Y ) = 0, and with positive probability when f (Y ) = 1.

8.3 Characterization of Quantum Certiﬁcate Complexity

, precisely characterizing quantum certiﬁcate
We wish to show that QC (f ) = Θ
complexity in terms of randomized certiﬁcate complexity. The ﬁrst step is to give a simpler
(cid:17)
characterization of RC (f ).

RC (f )

(cid:16)p

Lemma 30 Call a randomized veriﬁer for X nonadaptive if, on input Y , it queries each
yi with independent probability λi, and rejects if and only if it encounters a disagreement
with X.
na (f )

(Thus, we identify such a veriﬁer with the vector (λ1, . . . , λn).) Let RCX

6
6
be the minimum of λ1 +
.
Θ

RCX (f )

· · ·

+ λn over all nonadaptive veriﬁers for X. Then RCX

na (f ) =

71

(cid:0)

(cid:1)

na (f ) = Ω

Proof. Clearly RCX

RCX (f )
. For the upper bound, we can assume
that a randomized veriﬁer rejects immediately on ﬁnding a disagreement with X, and
(cid:0)
. Let V be an optimal
=
accepts if it ﬁnds no disagreement. Let
randomized veriﬁer, and let pt (Y ) be the probability that V , when given input Y
, ﬁnds
a disagreement with X on the tth query. By Markov’s inequality, V must have found a
queries. So by the union
disagreement with probability at least 1/2 after T =
bound

= f (X)
}

2 RCX (f )

Y : f (Y )

∈ Y

Y

{

(cid:1)

p1 (Y ) +

(cid:6)
+ pT (Y )

1
2

≥

· · ·
1, . . . , T

(cid:7)

∈ Y

. Suppose we choose t

uniformly at random and simulate the
for each Y
∈ {
tth query, pretending that queries 1, . . . , t
1 have already been made and have returned
agreement with X. Then we must ﬁnd a disagreement with probability at least 1/2T .
By repeating this procedure 4T times, we can boost the probability to 1
−
, let λi be the probability that yi is queried at least once. Then λ1 +
1, . . . , n
{
}
whereas for each Y

2. For i
+λn ≤

∈
4T ,

· · ·

e−

−

}

,

∈ Y

λi ≥

1

−

e−

2.

=xi
Xi:yi6

It follows that, if each yi is queried with independent probability λi, then the probability
that at least one yi disagrees with X is at least

1

−

=xi
Yi:yi6

(1

λi)

1

≥

−

1

e−
−
n

1

−

2

n

(cid:19)

−

(cid:18)

> 0.57.

To obtain a lower bound on QC (f ), I will use the following simple reformulation

of Ambainis’s adversary method [27].

n, let β be
Theorem 31 (Ambainis) Given a function f :
0, 1
}
a function from
be a relation such that
R (X, Y ) = R (Y, X) for all X, Y and R (X, Y ) = 0 whenever f (X) = f (Y ). Let δ0, δ1 ∈
(0, 1] be such that for every X

to nonnegative reals, and let R :

0, 1
}
0, 1
}
→ {

S → {
S

1, . . . , n

S ⊆ {

and i

with

S

2

∈ S

∈ {

,
}

β (Y )

β (Y )

≥

≤

1,

δf (X).

XY : R(X,Y )=1

XY : R(X,Y )=1,xi6

=yi

Then Q2 (f ) = Ω

1
δ0δ1

.

(cid:16)q

(cid:17)

I now prove the main result of the section.

6
72

Theorem 32 For all f (partial or total) and all X,

QC X (f ) = Θ

RC X (f )

.

(cid:18)q

(cid:19)

Proof. Let (λ1, . . . , λn) be an optimal nonadaptive randomized veriﬁer for X, and

let

S = λ1 +

+ λn.

· · ·

First, QCX (f ) = O
tion of basis states querying index i is within a constant factor of λi/S.
(cid:16)
n2 basis states.) Let

. We can run a “weighted Grover search,” in which the propor-
(It suﬃces to use
iterations

= f (X)

(cid:17)
=

√S

√S

, O

Y

Y : f (Y )
{

; then for any Y
}

∈ Y

suﬃce to ﬁnd a disagreement with X with probability Ω (1). Second, QCX (f ) = Ω
Consider a matrix game in which Alice chooses an index i to query and Bob chooses Y
(cid:16)
Alice wins if and only if yi 6
bility O (1/S), since otherwise Alice’s strategy would yield a veriﬁer (λ′1, . . . , λ′n) with

.
;
(cid:17)
∈ Y
If both players are rational, then Alice wins with proba-

= xi.

√S

(cid:16)

(cid:17)

Hence by the minimax theorem, there exists a distribution µ over

such that for every i,

Y

λ′1 +

· · ·

+ λ′n = o (S) .

Pr
µ
Y
∈

[yi 6

= xi] = O

1
S

.

(cid:19)

(cid:18)

. Also, let R (Y, Z) = 1 if and only
Let β (X) = 1 and let β (Y ) = µ (Y ) for each Y
if Z = X for each Y
. Then we can take δf (Y ) = 1 and δf (X) = O (1/S)
in Theorem 31. So the quantum query complexity of distinguishing X from an arbitrary
Y

and Z /

is Ω

∈ Y

∈ Y

∈ Y

√S

.

∈ Y

(cid:16)

(cid:17)

8.4 Quantum Lower Bound for Total Functions

The goal of this section is to show that

R0 (f ) = O

Q2 (f )2 Q0 (f ) log n

(cid:16)

(cid:17)

for all total f . Say that a real multilinear polynomial p (x1, . . . , xn) nondeterministically
represents f if for all X
= 0. Let ndeg (f ) be the
∈ {
minimum degree of a nondeterministic polynomial for f . Also, given such a polynomial p,
p if M2 contains every variable in M1. A
say that a monomial M1 ∈
monomial M is called a maxonomial if it is not covered by any other monomial of p. The
following is a simple generalization of a lemma attributed in [78] to Nisan and Smolensky.

p is covered by M2 ∈

= 0 if and only if f (X)

n, p (X)

0, 1
}

Lemma 33 (Nisan-Smolensky) Let p nondeterministically represent f . Then for every
maxonomial M of p and X
=
f (X), where X (B) is obtained from X by ﬂipping the variables in B.

1 (0), there is a set B of variables in M such that f

X (B)

f −

∈

(cid:0)

(cid:1)

6
6
6
6
Proof. Obtain a restricted function g from f , and a restricted polynomial q from
p, by setting each variable outside of M to xi. Then g cannot be constant, since its
representing polynomial q contains M as a monomial. Thus there is a subset B of variables
X (B)
in M such that g

= 1, and hence f

X (B)

= 1.

73

Using Lemma 33, de Wolf [244] showed that D (f )

C (f ) ndeg (f ) for all total
(cid:0)
(cid:0)
C (f ) deg (f ) due to Buhrman and de Wolf [78].
f , slightly improving the result D (f )
In Theorem 35, I will give an analogue of this result for randomized query and certiﬁcate
complexities. However, I ﬁrst need a probabilistic lemma.

≤

≤

(cid:1)

(cid:1)

Lemma 34 Suppose we repeatedly apply the following procedure: ﬁrst identify the set B of
maxonomials of p, then ‘shrink’ each M
B with (not necessarily independent) probability
at least 1/2. Shrinking M means replacing it by an arbitrary monomial of degree deg (M )
−
1. Then with high probability p is a constant polynomial after O (deg (p) log n) iterations.

∈

Proof. For any set A of monomials, consider the weighting function

ω (A) =

deg (M )!

A
XM
∈
Initially ω (S)

Let S be the set of monomials of p.
ω (S) = 0. The claim is that at every iteration, ω (B)
covered by some M
∈
deg (M ∗) = ℓ. Hence

B, but a given M

≤

∈

1

ndeg(p) deg (p)!, and we are done when
B is
distinct M ∗ with

e ω (S). For every M ∗ ∈

≥

deg(M )
ℓ

S

\

B can cover at most

(cid:0)

(cid:1)

ω (S

B)

\

≤

B
XM
∈

≤

≤

B
XM
∈
(e
−

deg(M )

1

−

Xℓ=0
(cid:0)
deg (M )!

(cid:18)

1) ω (B) .

deg(M )
ℓ

ℓ!

(cid:1)
1
2!

+

1
1!

+

· · ·

(cid:19)

At every iteration, the contribution of each M

B to ω (A) has at least 1/2
1)! (or to 0 if deg (M ) = 1). When
probability of shrinking from deg (M )! to (deg (M )
this occurs, the contribution of M is at least halved. Hence ω (S) decreases by an expected
amount at least 1

−

∈

4e ω (S). Thus after

log4e/(4e

1)

−

2ndeg(p) deg (p)!
(cid:17)
(cid:16)

= O (deg (p) log n)

iterations, the expectation of ω (S) is less than 1/2, so S is empty with probability at least
1/2.

I can now prove the main result.2

Theorem 35 For total f ,

R0 (f ) = O (RC (f ) ndeg (f ) log n) .

2The proof of Theorem 35 that I gave previously [4] makes a claim that is both superﬂuous for proving
I am grateful to Gatis Midrijanis for pointing this out to me.

the theorem and false.

74

Proof. The algorithm is as follows.

Repeat

Choose a 0-input X compatible with all queries made so far3

Query a randomized 0-certificate for X

Until f has been restricted to a constant function

Let p be a polynomial that nondeterministically represents f . Then the key fact
is that for every 0-input X, when we query a randomized 0-certiﬁcate for X we “hit” each
maxonomial M of p with probability at least 1/2. Here hitting M means querying a
variable in M . This is because, by Lemma 33, it is possible to change f (X) from 0 to 1
just by ﬂipping variables in M . So a randomized certiﬁcate would be incorrect if it probed
those variables with probability less than 1/2.

Therefore, each iteration of the algorithm shrinks each maxonomial of p with
probability at least 1/2. It follows from Lemma 34 that the algorithm terminates after an
expected number of iterations O (deg (p) log n).

Buhrman et al. [45] showed that ndeg (f )

2 Q0 (f ). Combining this with Theo-

rems 32 and 35 yields a new relation between classical and quantum query complexity.

≤

Corollary 36 For all total f ,

R0 (f ) = O

Q2 (f )2 Q0 (f ) log n
(cid:16)

(cid:17)

.

The best previous relation of this kind was R0 (f ) = O

, due to
It is worth mentioning another corollary of Theorems 32 and 35, this one

Q2 (f )2 Q0 (f )2

(cid:16)

(cid:17)

de Wolf [244].
purely classical:

Corollary 37 For all total f ,

R0 (f ) = O (R2 (f ) ndeg (f ) log n)

Previously, no relation between R0 and R2 better than R0 (f ) = O

R2 (f )3

was

known (although no asymptotic gap between R0 and R2 is known either [210]).

(cid:16)

(cid:17)

8.5 Asymptotic Gaps

Having related RC (f ) and QC (f ) to other query complexity measures in Section 8.4, in
what follows I seek the largest possible asymptotic gaps among the measures. In particular,
C (f )0.907
, as
I give a total f for which RC (f ) = Θ
(cid:17)
(cid:16)
RC (f )0.922
(cid:16)

3Clearly, as long as f is not a constant function, there exists a 0-input X compatible with all queries

. Although these gaps are the largest

well as a total f for which bs (f ) = Θ

QC (f )2.205
(cid:16)

and hence C (f ) = Θ

(cid:17)

(cid:17)

made so far.

of which I know, Section 8.5.1 shows that no ‘local’ technique can improve the relations
RC (f )2
. Finally, Section 8.5.2 uses combinatorial
C (f ) = O
designs to construct a symmetric partial f for which RC (f ) and QC (f ) are O (1), yet
(cid:17)
(cid:16)
Q2 (f ) = Ω (n/ log n).

bs (f )2
(cid:16)

and RC (f ) = O

(cid:17)

75

Wegener and Z´adori [240] exhibited total Boolean functions with asymptotic gaps
between C (f ) and bs (f ).
with an asymp-
totic gap between C (gt) and RC (gt). Let g1 (x1, . . . , x29) equal 1 if and only if the Hamming
weight of its input is 13, 14, 15, or 16.
(The parameter 29 was found via computer search
to produce a maximal separation.) Then for t > 1, let

In similar fashion, I give a function family

gt}

{

where X1 is the ﬁrst 29t
−
let

gt (x1, . . . , x29t ) = g0 [gt

−

1 (X1) , . . . , gt

1 (X29)]

1 input bits, X2 is the second 29t
−

−
1, and so on. For k

0, 1
}

∈ {

,

bs k (f ) = max
f (X)=k
C k (f ) = max
f (X)=k

bs X (f ) ,

C X (f ) .

Then since bs0 (g1) = bs1 (g1) = 17, we have bs (gt) = 17t. On the other hand, C0 (g1) = 17
but C1 (g1) = 26, so

C 1 (gt) = 13 C 1 (gt
1) + 13 C 0 (gt
−
−
1) , C 0 (gt
C 1 (gt
C 0 (gt) = 17 max
−
−
(cid:8)
22.725t

1) ,
1)

.

(cid:9)

. We can now show a gap between C

Solving this recurrence yields C (gt) = Θ
and RC.

Proposition 38 RC (gt) = Θ

C (gt)0.907
(cid:16)

(cid:1)

(cid:0)

.

(cid:17)

−

(cid:17)

C (gt)0.907
(cid:16)

1 (Xi) = 1
}

1 (Xi). Let I0 =

Proof. Since bs (gt) = Ω

, it suﬃces to show that RC (gt) = O (bs (gt)).
Let X be
and I1 =
1 (Xi) = 0
}
I1 uniformly at random; other-

The randomized veriﬁer V chooses an input variable to query as follows.
29
the claimed input, and let K =
i=1 gt
−
i : gt
{
wise A chooses an i

. With probability pK, V chooses an i

I0 uniformly at random. Here pK is as follows.
[17, 29]
1

∈
K [0, 12]
pK
Once i is chosen, V repeats the procedure for Xi, and continues recursively in this
= gt (Y ), then
= yj with probability at

manner until reaching a variable yj to query. One can check that if gt (X)
gt
−
least 1/17t, and RC (gt) = O

1 (Yi) with probability at least 1/17. Hence xj 6

i : gt
{

1 (Xi)

14
7
12

13
13
17

15
5
12

16
4
17

= gt

17t

P

∈

0

−

−

.

By Theorem 32, it follows that C (gt) = Θ
(cid:0)

. This oﬀers a surpris-
ing contrast with the query complexity setting, where the best known gap between the
deterministic and quantum measures is quadratic (D (f ) = Θ

QC (gt)2.205
(cid:16)

(cid:17)
Q2 (f )2

).

(cid:1)

(cid:16)

(cid:17)

6
6
RC (f )2
(cid:16)

(cid:17)

76

{

gt}

The family

happens not to yield an asymptotic gap between bs (f ) and RC (f ).
The reason is that any input to g0 can be covered perfectly by sensitive blocks of minimum
size, with no variables left over. In general, though, one can have bs (f ) = o (RC (f )). As
reported by Bublitz et al. [74], M. Paterson found a total Boolean function h1 (x1, . . . , x6)
such that CX (h1) = 5 and bsX (h1) = 4 for all X. Composing h1 recursively yields
C (ht)0.861
, both of which are the largest such
bs (ht) = Θ
gaps of which I know.

RC (ht)0.922
(cid:16)

and bs (ht) = Θ

(cid:17)

(cid:17)

(cid:16)

8.5.1 Local Separations

It is a longstanding open question whether the relation C (f )
is tight. As a ﬁrst step, one can ask whether the relations C (f ) = O

bs (f )2 due to Nisan [183]
and

≤

RC (f ) = O

bs (f )2

are tight.

In this section I introduce a notion of local proof in query

complexity, and then show there is no local proof that C (f ) = o

(cid:16)

(cid:17)

RC (f )2

or that RC (f ) =

bs (f )2

(cid:17)

(cid:16)

. This implies that proving either result would require techniques unlike those
o
that are currently known. My inspiration comes from computational complexity, where
researchers ﬁrst formalized known methods of proof, including relativizable proofs [41] and
natural proofs [200], and then argued that these methods were not powerful enough to
resolve the ﬁeld’s outstanding problems.

(cid:16)

(cid:17)

Let G (f ) and H (f ) be query complexity measures obtained by maximizing over

all inputs—that is,

G (f ) = max

X

H (f ) = max

X

GX (f ) ,

H X (f ) .

}

⊆ {

a minimal block on X if B is sensitive on X (meaning f

=
Call B
1, . . . , n
f (X)), and no sub-block B′ ⊂
(X)
(cid:1)
consist of X together with X (B) for every minimal block B of X. Consider a proof that
I call the proof local if it proceeds by
G (f ) = O (t (H (f ))) for some nondecreasing t.
showing that for every input X,

B is sensitive on X. Also, let X’s neighborhood
(cid:0)

N

X (B)

GX (f ) = O

t

H Y (f )

.

max
∈N

(X)

Y

(cid:18)

(cid:19)
(cid:1)(cid:9)
bs (f )2 is local. For each X,
As a canonical example, Nisan’s proof [183] that C (f )
Nisan observes that (i) a maximal set of disjoint minimal blocks is a certiﬁcate for X, (ii)
such a set can contain at most bsX (f ) blocks, and (iii) each block can have size at most
(X) bsY (f ). Another example of a local proof is the proof in Section 8.3 that
maxY
RC (f ) = O

QC (f )2

∈N

≤

(cid:8)

(cid:0)

.

(cid:16)

(cid:17)

Proposition 39 There is no local proof showing that C (f ) = o

o

bs (f )2

for all total f .

(cid:16)

(cid:17)

RC (f )2
(cid:16)

(cid:17)

or that RC (f ) =

6
77

√n
⌉

(f ) = n

+ 1, but RC0n

Proof. The ﬁrst part is easy: let f (X) = 1 if

(0n). For the second part, arrange the input variables in a lattice of size √n

denotes the
Hamming weight of X), and f (X) = 0 otherwise. Consider the all-zero input 0n. We
have C0n
(f ) = O (√n), and indeed RCY (f ) = O (√n) for all
√n.
Y
Take m = Θ
, and let g (X) be the monotone Boolean function that outputs 1 if and
m. This is a square of 1’s that can wrap around
only if X contains a 1-square of size m
(cid:1)
the edges of the lattice; note that only the variables along the sides must be set to 1, not
those in the interior. An example input, with a 1-square of size 3

3, is shown below.

√n (where

n1/3

X
|

X
|

∈ N

| ≥

− ⌈

×

×

(cid:0)

|

×

0 0 0 0 0
0 0 0 0 0
1 0 0 1 1
1 0 0 1 0
1 0 0 1 1

n1/3
(g) = Θ
m. Also, bsY (g) = Θ

Clearly bs0n
, since there can be at most n/m2 disjoint 1-squares of size
n1/3
m
for any Y that is 0 except for a single 1-square. On the
other hand, if we choose uniformly at random among all such Y ’s, then at any lattice site
(g) = Ω
i, PrY [yi = 1] = Θ

(cid:1)
(cid:0)
(cid:1)
. Hence RC0n

n2/3

n−

2/3

×

(cid:0)

.

8.5.2 Symmetric Partial Functions

(cid:0)

(cid:1)

(cid:0)

(cid:1)

If f is partial, then QC (f ) can be much smaller than Q2 (f ). This is strikingly illustrated
by the collision problem:
let Col (Y ) = 0 if Y = y1 . . . yn is a one-to-one sequence and
Col (Y ) = 1 if Y is a two-to-one sequence, promised that one of these is the case. Then
RC (Col) = QC (Col) = O (1), since every one-to-one input diﬀers from every two-to-one
input on at least n/2 of the yi’s. On the other hand, Chapter 6 showed that Q2 (Col) =
Ω

n1/5

.

(cid:1)

(cid:0)

n1/3

From the example of the collision problem, it is tempting to conjecture that (say)
Q2 (f ) = O
whenever QC (f ) = O (1)—that is, ‘if every 0-input is far from every
1-input, then the quantum query complexity is sublinear.’ Here I disprove this conjecture,
, a function
even for the special case of symmetric functions such as Col. (Given a ﬁnite set
H
n is called symmetric if x1 . . . xn ∈ S
f :
implies xσ(1) . . . xσ(n) ∈ S
where
0, 1
}
and f (x1 . . . xn) = f
for every permutation σ.)
The proof uses the following lemma, which can be found in Nisan and Wigderson

S ⊆ H
xσ(1) . . . xσ(n)

S → {

(cid:0)

(cid:1)

[185] for example.

(cid:0)

(cid:1)

Lemma 40 (Nisan-Wigderson) For any γ > 1, there exists a family of sets

such that m = Ω

2n/γ

,

Ai|
|

A1, . . . , Am ⊆ {
= n for all i, and

1, . . . ,

Ai ∩
|

γn

⌈
⌉}
Aj| ≤

n/γ for all i

= j.

A lemma due to Ambainis [26] is also useful. Let f :

(cid:0)

(cid:1)

n be a partial Boolean function, and let p :
0, 1
0, 1
{
}
}
polynomial. We say that p approximates f if (i) p (X)
), and (ii)
(not merely those in

g (X)

{

n

∈

p (X)
|

−

| ≤

S

1/3 for every X

.

∈ S

0, 1
S ⊆
}
R be a real-valued multilinear
n

→
[0, 1] for every input X

S → {

where

0, 1
}

∈ {

6
78

Lemma 41 (Ambainis) At most 2O(∆(n,d)dn2) distinct Boolean functions (partial or total)
can be approximated by polynomials of degree d, where ∆ (n, d) =

.

d
i=0

n
i

The result is an easy consequence of Lemmas 40 and 41.

P

(cid:0)

(cid:1)

Theorem 42 There exists a symmetric partial f for which QC (f ) = O (1) and Q2 (f ) =
Ω (n/ log n).

}

where

S ⊆ {

S → {

0, 1
}

1, . . . , 3n

1, . . . , 3n

Proof. Let f :

be as in Lemma 40. We put x1, . . . , xn in

= Aj for some j. Clearly QC (f ) = O (1), since if i

.
if and only if
Let A1, . . . , Am ⊆ {
(cid:0)
(cid:1)
= j then every permutation
x1, . . . , xn}
{
of Ai diﬀers from every permutation of Aj on at least n/3 indices. The number of symmetric
as above is 2m = 2Ω(2n/3). We can convert any such f to a Boolean function
f with
g on O (n log n) variables. But Beals et al. [45] showed that, if Q2 (g) = T , then g is
approximated by a polynomial of degree at most 2T . So by Lemma 41, if Q2 (g)
T for
every g then

≤

S

S

}

n, and let m = Ω

2n/3

∆ (n log n, 2T )

2T

·

·

(n log n)2 = Ω

and we solve to obtain T = Ω (n/ log n).

2n/3
(cid:16)

(cid:17)

8.6 Open Problems

(cid:17)

g

(cid:16)p

RC (f )

, where

deg (f ) = Ω

Is
deg (f ) is the minimum degree of a polynomial approx-
imating f ? In other words, can one lower-bound QC (f ) using the polynomial method of
g
Beals et al. [45], rather than the adversary method of Ambainis [27]?
RC (f )2
(cid:16)
R2 (f )2
(cid:16)

If so we obtain the new relations R0 (f ) =

Q2 (f )4
(cid:16)

Also, is R0 (f ) = O

and R0 (f ) = O

O

(cid:17)

(cid:17)

(cid:17)

?

.

6
79

Chapter 9

The Need to Uncompute

Like a classical algorithm, a quantum algorithm can solve problems recursively by
calling itself as a subroutine. When this is done, though, the algorithm typically needs
to call itself twice for each subproblem to be solved. The second call’s purpose is to
uncompute ‘garbage’ left over by the ﬁrst call, and thereby enable interference between
diﬀerent branches of the computation. Of course, a factor of 2 increase in running time
hardly seems like a big deal, when set against the speedups promised by quantum computing.
The problem is that these factors of 2 multiply, with each level of recursion producing
an additional factor. Thus, one might wonder whether the uncomputing step is really
necessary, or whether a cleverly designed algorithm might avoid it. This chapter gives the
ﬁrst nontrivial example in which recursive uncomputation is provably necessary.

The example concerns a long-neglected problem called Recursive Fourier Sampling
(henceforth RFS), which was introduced by Bernstein and Vazirani [55] in 1993 to prove the
ﬁrst oracle separation between BPP and BQP. Many surveys on quantum computing pass
directly from the Deutsch-Jozsa algorithm [95] to the dramatic results of Simon [220] and
Shor [219], without even mentioning RFS. There are two likely reasons for this neglect.
First, the RFS problem seems artiﬁcial.
It was introduced for the sole purpose of proving
an oracle result, and is unlike all other problems for which a quantum speedup is known.
(I will deﬁne RFS in Section 9.1; but for now, it involves a tree of depth log n, where each
vertex is labeled with a function to be evaluated via a Fourier transform.) Second, the
speedup for RFS is only quasipolynomial (n versus nlog n), rather than exponential as for
the period-ﬁnding and hidden subgroup problems.

Nevertheless, I believe that RFS merits renewed attention—for it serves as an im-
portant link between quantum computing and the ideas of classical complexity theory. One
reason is that, although other problems in BQP—such as the factoring, discrete logarithm,
and ‘shifted Legendre symbol’ problems [232]—are thought to be classically intractable,
these problems are quite low-level by complexity-theoretic standards. They, or their as-
coNP.1 By contrast, Bernstein and Vazirani [55]
sociated decision problems, are in NP
showed that, as an oracle problem, RFS lies outside NP and even MA (the latter result is
unpublished, though not diﬃcult). Subsequently Watrous [239] gave an oracle A, based

∩

1For the shifted Legendre symbol problem, this is true assuming a number-theoretic conjecture of Boneh

and Lipton [61].

80

on an unrelated problem, for which BQPA
MAA.2 Also, Green and Pruim [135] gave an
oracle B for which BQPB
. However, Watrous’ problem was shown by Babai [38]
to be in AM, while Green and Pruim’s problem is in BPP. Thus, neither problem can be
used to place BQP outside higher levels of the polynomial hierarchy.

PNPB

6⊂

6⊂

On the other hand, Umesh Vazirani and others have conjectured that RFS is not in
PHA.
PH, from which it would follow that there exists an oracle A relative to which BQPA
Proving this is, in my view, one of the central open problems in quantum complexity theory.
Its solution seems likely to require novel techniques for constant-depth circuit lower bounds.3
In this chapter I examine the RFS problem from a diﬀerent angle. Could Bernstein
and Vazirani’s quantum algorithm for RFS be improved even further, to give an exponential
speedup over the classical algorithm? And could we use RFS, not merely to place BQP
outside of PH relative to an oracle, but to place it outside of PH with (say) a logarithmic
number of alternations?

6⊂

My answer to both questions is a strong ‘no.’
on RFS, and show that all of them fall into one of two classes:

I study a large class of variations

(1) a trivial class, for which there exists a classical algorithm making only one query, or

(2) a nontrivial class, for which any quantum algorithm needs 2Ω(h) queries, where h is the
height of the tree to be evaluated. (By comparison, the Bernstein-Vazirani algorithm
uses 2h queries, because of its need to uncompute garbage recursively at each level of
the tree.)

Since nh queries always suﬃce classically, this dichotomy theorem implies that the speedup
aﬀorded by quantum computers is at most quasipolynomial. It also implies that (nontrivial)
RFS is solvable in quantum polynomial time only when h = O (log n).

Intuitively, given a Boolean function g :

The plan is as follows. In Section 9.1 I deﬁne the RFS problem, and give Bernstein
and Vazirani’s quantum algorithm for solving it. In Section 9.2, I use the adversary method
of Ambainis [27] to prove a lower bound on the quantum query complexity of any RFS
variant. This bound, however, requires a parameter that I call the “nonparity coeﬃcient”
to be large.
, the nonparity
coeﬃcient measures how far g is from being the parity of some subset of its input bits—not
under the uniform distribution over inputs (the standard assumption in Fourier analysis),
but under an adversarial distribution. The crux of the argument is that either the nonparity
coeﬃcient is zero (meaning the RFS variant in question is trivial), or else it is bounded below
by a positive constant. This statement is proved in Section 9.2, and seems like it might be
of independent interest. Section 9.3 concludes with some open problems.

0, 1
}
{

0, 1
}

→ {

n

2Actually, to place BQP outside MA relative to an oracle, it suﬃces to consider the complement of Simon’s

problem (“Does f (x) = f (x

s) only when s = 0?”).

⊕

3For the RFS function can be represented by a low-degree real polynomial—this follows from the existence
of a polynomial-time quantum algorithm for RFS, together with the result of Beals et al. [45] relating
quantum algorithms to low-degree polynomials. As a result, the circuit lower bound technique of Razborov
[198] and Smolensky [223], which is based on the nonexistence of low-degree polynomials, seems unlikely to
work. Even the random restriction method of Furst et al. [120] can be related to low-degree polynomials,
as shown by Linial et al. [166].

9.1 Preliminaries

81

, and are promised that there exists a secret string s

In ordinary Fourier sampling, we are given oracle access to a Boolean function A :
0, 1
→
{
}
n such that A (x) =
0, 1
{
}
s
x (mod 2) for all x. The problem is to ﬁnd s—or rather, since we need a problem with
is some known
Boolean output, the problem is to return g (s), where g :
Boolean function. We can think of g (s) as the “hard-core bit” of s, and can assume that
g itself is eﬃciently computable, or else that we are given access to an oracle for g.

0, 1
}
{

0, 1
}

0, 1
}

→ {

∈ {

n

·

n

To obtain a height-2 recursive Fourier sampling tree, we simply compose this
problem. That is, we are no longer given direct access to A (x), but instead are promised
n is the secret string for another Fourier sampling
that A (x) = g (sx), where sx ∈ {
0, 1
}
y (mod 2).
problem. A query then takes the form (x, y), and produces as output Ax (y) = sx·
x (mod 2) for all x,
As before, we are promised that there exists an s such that A (x) = s
meaning that the sx strings must be chosen consistent with this promise. Again we must
return g (s).

·

Continuing, we can deﬁne height-h recursive Fourier sampling, or RFSh, recur-
sively as follows. We are given oracle access to a function A (x1, . . . , xh) for all x1, . . . , xh ∈
0, 1
}
{

n, and are promised that

(1) for each ﬁxed x∗1, A (x∗1, x2, . . . , xh) is an instance of RFSh
; and

answer bit b (x∗1)

0, 1
}

∈ {

1 on x2, . . . , xh, having

−

(2) there exists a secret string s

0, 1
}

∈ {

n such that b (x∗1) = s

·

x∗1 (mod 2) for each x∗1.

Again the answer bit to be returned is g (s). Note that g is assumed to be
the same everywhere in the tree—though using the techniques in this chapter, it would
be straightforward to generalize to the case of diﬀerent g’s. As an example that will be
used later, we could take g (s) = gmod 3 (s), where gmod 3 (s) = 0 if
0 (mod 3) and
denotes the Hamming weight of s. We do not want to take
gmod 3 (s) = 1 otherwise, and
g to be the parity of s, for if we did then g (s) could be evaluated using a single query. To
see this, observe that if x is the all-1’s string, then s

x (mod 2) is the parity of s.

| ≡

s
|

s
|

|

By an ‘input,’ I will mean a complete assignment for the RFS oracle (that is,
I will sometimes refer also to an ‘RFS tree,’ where each
A (x1, . . . , xh) for all x1, . . . , xh).
vertex at distance ℓ from the root has a label x1, . . . , xℓ.
If ℓ = h then the vertex is a leaf;
otherwise it has 2n children, each with a label x1, . . . , xℓ, xℓ+1 for some xℓ+1. The subtrees
of the tree just correspond to the sub-instances of RFS.

·

Bernstein and Vazirani [55] showed that RFSlog n, or RFS with height log n (all
I
0 be an oracle that, for each n, encodes an
.

logarithms are base 2), is solvable on a quantum computer in time polynomial in n.
include a proof for completeness. Let A = (An)n
instance of RFSlog n whose answer is Ψn. Then let LA be the unary language
Lemma 43 LA ∈

BQPA for any choice of A.

0n : Ψn = 1
}

EQPA

⊆

{

≥

Proof. RFS1 can be solved exactly in four queries, with no garbage bits left over.

The algorithm is as follows: ﬁrst prepare the state

n/2

2−

x

A (x)

,

i

i |

n |
}

0,1
Xx
∈{

using one query to A. Then apply a phase ﬂip conditioned on A (x) = 1, and uncompute
A (x) using a second query, obtaining

82

n/2

2−

1)A(x)

(
−

n

.

x
i

|

0,1
Xx
∈{

}

It can be checked that the
Then apply a Hadamard gate to each bit of the
using
resulting state is simply
two more queries to A, to obtain
. To solve RF Slog n (n), we simply apply the
g (s)
i
above algorithm recursively at each level of the tree. The total number of queries used is
4log n = n2.

. One can then compute
i

register.
s

and uncompute

g (s)
i

x
i
|

s
|

i |

s

i

|

|

|

One can further reduce the number of queries to 2log n = n by using the “one-call

kickback trick,” described by Cleve et al. [87]. Here one prepares the state

n/2

2−

x

i ⊗

n |
}

0,1
Xx
∈{

|

1
i − |
√2

0
i

and then exclusive-OR’s A (x) into the second register. This induces the desired phase
1)A(x) without the need to uncompute A (x). However, one still needs to uncompute
(
s
|
−
after computing

i

A remark on notation: to avoid confusion with subscripts, I denote the ith bit of

.
g (s)
i

|

string x by x [i].

9.2 Quantum Lower Bound

In this section I prove a lower bound on the quantum query complexity of RFS. Crucially,
the bound should hold for any nontrivial one-bit function of the secret strings, not just a
speciﬁc function such as gmod 3 (s) deﬁned in Section 9.1. Let RFSg
h be height-h recursive
Fourier sampling in which the problem at each vertex is to return g (s). The following
notion turns out to be essential.

(partial or total), the nonpar-
0, 1
Deﬁnition 44 Given a Boolean function g :
}
{
ity coeﬃcient µ (g) is the largest µ∗ for which there exist distributions D0 over the 0-inputs
of g, and D1 over the 1-inputs, such that for all z
s0, and all 1-inputs
s1, we have

n, all 0-inputs

0, 1
}

0, 1
}

→ {

∈ {

n

b

Pr
D0,s1

∈

s0

D1

∈

z

[s0 ·

s1 ·

≡

z (mod 2)

z

s1 ·

s0 ·

≡

∨

b
z (mod 2)]
≥

µ∗.

Loosely speaking, the nonparity coeﬃcient is high if there exist distributions over
0-inputs and 1-inputs that make g far from being a parity function of a subset of input bits.
The following proposition develops some intuition about µ (g).

b

b

Proposition 45

(i) µ (g)

≤

3/4 for all nonconstant g.

83

(ii) µ (g) = 0 if and only if g can be written as the parity (or the NOT of the parity) of a

subset B of input bits.

Proof.

(i) Given any s0 6

=

s1 and s1 6

=

s0, a uniform random z will satisfy

z

z (mod 2)
s1 ·
b

s0 ·
[s0 ·
Pr
b
z
s0 then this probability will be 1/2; otherwise it will be 1/4.) So
b

(If s0 ⊕
certainly there is a ﬁxed choice of z that works for random s0 and s1.

s1 = s1 ⊕

z (mod 2)]

s1 ·

6≡

≥

6≡

∧

b

z

.

1
4

b

b

(ii) For the ‘if’ direction, take z [i] = 1 if and only if i

s1 arbitrarily.
This ensures that µ∗ = 0. For the ‘only if’ direction, if µ (g) = 0, we can choose D0
to have support on all 0-inputs, and D1 to have support on all 1-inputs. Then there
b
z is constant
z is constant as we range over 0-inputs, and s1 ·
must be a z such that s0 ·
B if and only if z [i] = 1.
as we range over 1-inputs. Take i

B, and choose

s0 and

∈

b

∈

If µ (g) = 0, then RFSg
47 will show that for all g (partial or total),

h is easily solvable using a single classical query. Theorem

Q2

RFSg
h

= Ω

(cid:0)

(cid:1)

h/2

1
µ (g)

(cid:19)

,

!

1

 (cid:18)

−

where Q2 is bounded-error quantum query complexity as deﬁned in Section 5.1.
In other
words, any RFS problem with µ bounded away from 0 requires a number of queries expo-
nential in the tree height h.

However, there is an essential further part of the argument, which restricts the
values of µ (g) itself. Suppose there existed a family
of ‘pseudoparity’ functions: that
is, µ (gn) > 0 for all n, yet µ (gn) = O(1/ log n). Then the best bound obtainable from
might still be solvable
Theorem 47 would be Ω
in quantum polynomial time. On the other hand, it would be unclear a priori how to solve
RFSg
classically with a logarithmic number of alternations. Theorem 49 will rule out
this scenario by showing that pseudoparity functions do not exist: if µ (g) < 0.146 then g
is a parity function, and hence µ (g) = 0.

, suggesting that RFSg
(cid:17)

(1 + 1/ log n)h/2
(cid:16)

gn}
{

log2 n

log2 n

The theorem of Ambainis that we need is his “most general” lower bound from [27],
which he introduced to show that the quantum query complexity of inverting a permutation
is Ω (√n), and which we used already in Chapter 7. Let us restate the theorem in the present
context.

Theorem 46 (Ambainis) Let X
f . Let R (x, y)

⊆

f −

1 (0) and Y

0 be a symmetric real-valued relation function, and for x

⊆

f −

1 (1) be sets of inputs to function
Y ,

X, y

∈

∈

≥

and index i, let

θ (x, i) =

θ (y, i) =

Y : x[i]

y∗∈

y∗∈
P
X : x∗[i]

x∗∈

=y∗[i] R (x, y∗)
Y R (x, y∗)

=y[i] R (x∗, y)

Y R (x∗, y)

y∗∈

P

P

84

,

,

where the denominators are all nonzero. Then Q2 (f ) = O (1/υ) where

P

υ =

x

X, y

∈

∈

max

Y, i : R(x,y)>0, x[i]

=y[i]

θ (x, i) θ (y, i).

We are now ready to prove a lower bound for RFS.

p

Theorem 47 For all g (partial or total), Q2

RFSg
h

= Ω

(1

µ (g))−

h/2

.

−

(cid:1)

∈

(cid:17)
(cid:16)
Proof. Let X be the set of all 0-inputs to RFSg
(cid:0)
h, and let Y be the set of all 1-
inputs. We will weight the inputs using the distributions D0, D1 from the deﬁnition of the
nonparity coeﬃcient µ (g). For all x
X, let p (x) be the product, over all vertices v in the
RFS tree for x, of the probability of the secret string s at v, if s is drawn from Dg(s) (where
we condition on v’s output bit, g (s)). Next, say that x
Y diﬀer minimally if,
for all vertices v of the RFS tree, the subtrees rooted at v are identical in x and in y whenever
If x and y diﬀer minimally, then we
the answer bit g (s) at v is the same in x and in y.
will set R (x, y) = p (x) p (y); otherwise we will set R (x, y) = 0. Clearly R (x, y) = R (y, x)
µ (g))h for all x, y
for all x
−
that diﬀer minimally and all i such that x [i]
Y is chosen with
= y [i]. For suppose y∗ ∈
X is chosen with probability proportional to
probability proportional to R (x, y∗), and x∗ ∈
R (x∗, y). Then θ (x, i) θ (y, i) equals the probability that we would notice the switch from
x to y∗ by monitoring i, times the probability that we would notice the switch from y to
x∗.

Y . Furthermore, we claim that θ (x, i) θ (y, i)

X and y

X, y

(1

≤

∈

∈

∈

∈

−

∈ {

0, 1
}

1, . . . , h
}

. Also, let zj ∈ {

Let vj be the jth vertex along the path in the RFS tree from the root to the leaf
n be the label of the edge between
vertex i, for all j
1 and vj, and let sx,j and sy,j be the secret strings at vj in x and y respectively. Then
vj
= g (sy,j) for all j—for otherwise the
since x and y diﬀer minimally, we must have g (sx,j)
subtrees rooted at vj would be identical, which contradicts the assumption x [i]
= y [i].
So we can think of the process of choosing y∗ as ﬁrst choosing a random s′x,1 from D1
so that 1 = g
= g (sx,1) = 0, then choosing a random s′x,2 from D1
g(sx,2) so that
= g (sx,2), and so on. Choosing x∗ is analogous, except that whenever we used D0 in
g
choosing y∗ we use D1, and vice versa. Since the 2h secret strings sx,1, . . . , sx,h, sy,1, . . . , sy,h
to be updated are independent of one another, it follows that

s′x,1

s′x,2

(cid:1)

(cid:0)

(cid:0)

(cid:1)

−

Pr [y∗ [i]

= x [i]] Pr [x∗ [i]

= y [i]] =

h

Yj=1
h

Pr
D0
∈

s

[s

zj 6≡

sx,j ·

·

zj] Pr
D1
s
∈

[s

zj 6≡

sy,j ·

·

zj]

µ (g))

(1

−

µ (g))h

≤

Yj=1
= (1

−

6
6
6
6
6
6
6
6
6
6
85

by the deﬁnition of µ (g). Therefore

by Theorem 46.

Q2

RFSg
h

= Ω

(1

(cid:0)

(cid:1)

(cid:16)

µ (g))−

h/2

−

(cid:17)

Before continuing further, let me show that there is a natural, explicit choice of
g—the function gmod 3 (s) from Section 9.1—for which the nonparity coeﬃcient is almost
3/4. Thus, for g = gmod 3, the algorithm of Lemma 43 is essentially optimal.

Proposition 48 µ (gmod 3) = 3/4

O (1/n).

−

Proof. Let n

n/6
⌋
(so gmod 3 (s) = 0); likewise let D1 be the uniform distribution over s with
+ 2
(gmod 3 (s) = 1). We consider only the case of s drawn from D0; the D1 case is analogous.
We will show that for any z,

6. Let D0 be the uniform distribution over all s with

⌊
n/6
⌋

s
|
|
= 3

= 3

s
|

≥

⌊

|

Pr
D0
∈

[s

z

·

≡

0]

−

1
2

= O

1
n

(cid:19)

(cid:18)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

s
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Assume without loss of generality that 1

(all congruences are mod 2). The theorem then follows, since by the deﬁnition of the
nonparity coeﬃcient, given any z the choices of s0 ∈
D0 and s1 ∈
n/2 (if
z
| ≤
≤ |
= 1, then clearly
z
If
by its complement). We apply induction on
|
|
1
2 ±

D1 are independent.
z
|

> n/2, then replace z

n/6
⌋

0] = 3

/n =

Pr [s

1
n

.
|

≡

O

z

z

⌊

|

.

|

·

(cid:18)

(cid:19)

For
the other 1’s. Suppose the proposition holds for

2, let z = z1 ⊕

| ≥

z
|

z2, where z2 contains only the rightmost 1 of z and z1 contains all

Pr [s

z

·

≡

0] = Pr [s

Pr [s

z1 ≡
z1 ≡

·

·

0] Pr [s

1] Pr [s

·

·

z
|

| −

1. Then
z2 ≡
z2 ≡

s
0
|
s
1
|

·

·

z1 ≡
z1 ≡

0] +

1] ,

where

Pr [s

z1 ≡

·

0] =

α
for some
|
1’s in s outside of z1 is (n

|

= O (1/n). Furthermore, even conditioned on s

− |

) /2

z1|
Pr [s

±
z2 ≡

·

b

s
|

z1 ≡

·

b] =

1
2

+ βb

1
2

+ α, Pr [s

1
2 −
z1, the expected number of
O (1) and they are uniformly distributed. Therefore

z1 ≡

1] =

α

·

·

for some

β0|
|

,

β1|

|

= O (1/n). So

Pr [s

z

·

≡

0] =

=

+

1
2
1
2 ±

β1
2 −

αβ1

β0
2

O

+ αβ0 −
1
.
n

(cid:18)

(cid:19)

Finally it must be shown that pseudoparity functions do not exist. That is, if g
is too close to a parity function for the bound of Theorem 47 to apply, then g actually is a
parity function, from which it follows that RF Sg

h admits an eﬃcient classical algorithm.

Theorem 49 Suppose µ (g) < 0.146. Then g is a parity function (equivalently, µ (g) = 0).

86

Proof. By linear programming duality, there exists a joint distribution
n, 0-inputs
1 (1), such that for all s0 ∈
z
0, 1
}
∈ {
1 (1),
g−
and s1 ∈

1 (0), and 1-inputs

s1 ∈

s0 ∈

g−

g−

over
1 (0)

D
g−

Pr
s1)

(z,

s0,

∈D

b
[s0 ·

z

s1 ·

≡

z (mod 2)

∨

z

s0 ·

≡

z (mod 2)] < µ (g) .

b
s1 ·

b

b
z (mod 2), since otherwise we could violate the hypothesis by taking
n and

s1 ·
It follows that there exists a joint distribution
b

D′ over z

0, 1
}

∈ {

Furthermore
s0 =
b

z
s0 ·
b
b
s1.
s0 or s1 =
such that
0, 1
b
}
b

∈ {

b

6≡

for all s

∈

g−

1 (0), and

[s

Pr
(z,b)

∈D′

[s

Pr
(z,b)

∈D′

z

z

·

·

≡

6≡

b (mod 2)] > 1

b (mod 2)] > 1

µ (g)

µ (g)

−

−

g−

for all s
functions. More precisely, there exist probabilities pz, summing to 1, as well as bz ∈ {
such that for all s

1 (1). But this implies that g is a bounded-error threshold function of parity
0, 1
}

n,

∈

0, 1
}

∈ {

Ψ (s) =

pz ((s

z)

·

⊕

bz) is

(cid:26)

n

0,1
Xz
}
∈{

µ (g)

> 1
< µ (g)

−

if g (s) = 1
if g (s) = 0.

We will consider var (Ψ), the variance of the above quantity Ψ (s) if s is drawn uniformly
at random from
bz is a parity
0, 1
}
{
function and hence µ (g) = 0. So we can assume without loss of generality that pz < 1/2 for
bz2
all z. Then since s is uniform, for each z1 6
are pairwise independent

bz1 and (s
·
random variables, both with expectation 1/2. So

n. First, if pz ≥

1/2 for any z, then g (s) = (s

= z2 we know that (s

z2)

z1)

z)

⊕

⊕

⊕

·

·

0, 1
}

{

var (Ψ) =

1
4

zp2

z <

2

+

1
4  (cid:18)

1
2

(cid:19)

2

1
2

(cid:18)

(cid:19)

!

=

1
8

.

P
On the other hand, since Ψ (s) is always less than µ or greater than 1

µ,

−

Combining,

var (Ψ) >

1
2 −

µ

2

.

(cid:19)

(cid:18)

µ >

2

√2
−
4

> 0.146.

87

9.3 Open Problems

An intriguing open problem is whether Theorem 47 can be proved using the polynomial
method of Beals et al. [45], rather than the adversary method of Ambainis [27]. It is known
that one can lower-bound polynomial degree in terms of block sensitivity, or the maximum
number of disjoint changes to an input that change the output value. The trouble is that
the RFS function has block sensitivity 1—the “sensitive blocks” of each input tend to have
small intersection, but are not disjoint. For this reason, I implicitly used the quantum
certiﬁcate complexity of Chapter 8 rather than block sensitivity to prove a lower bound.

I believe the constant of Theorem 49 can be improved. The smallest nonzero µ (g)

value I know of is attained when n = 2 and g = OR (s [1] , s [2]):

Proposition 50 µ (OR) = 1/3.

z

6≡

≥

s0 ·

= 0 and the unique 0-input

z with probability at most 2/3. Second, µ (OR)

1/3, since D1 can choose s [1] s [2] to be 01, 10, or 11
s0 = 00, we have
1/3, since applying linear
s1) equal (01, 01), (10, 10), or (11, 10) each
1 always, and for any 1-input s1, we have

Proof. First, µ (OR)
each with probability 1/3; then for any z
s1 ·
programming duality, we can let the pair (z,
with probability 1/3. Then 0
z
s1 ·
s0 ·
s1 ·
6≡
Finally, I conjecture that uncomputation is unavoidable not just for RFS but for
many other recursive problems, such as game-tree evaluation. Formally, the conjecture is
that the quantum query complexity of evaluating a game tree increases exponentially with
depth as the number of leaves is held constant, even if there is at most one winning move
per vertex (so that the tree can be evaluated with zero probability of error).

z
z with probability 2/3.

s0 ·

b
1

≡
b

≡

6≡

≤

≡

b

b

b

z

6
88

Chapter 10

Limitations of Quantum Advice

How many classical bits can “really” be encoded into n qubits? Is it n, because
of Holevo’s Theorem [145]; 2n, because of dense quantum coding [78] and quantum telepor-
tation [53]; exponentially many, because of quantum ﬁngerprinting [75]; or inﬁnitely many,
because amplitudes are continuous? The best general answer to this question is probably
mu, the Zen word that “unasks” a question.1

To a computer scientist, however, it is natural to formalize the question in terms
of quantum one-way communication complexity [43, 75, 154, 250]. The setting is as follows:
Alice has an n-bit string x, Bob has an m-bit string y, and together they wish to evaluate
f (x, y) where f :
is a Boolean function. After examining her
0, 1
}
input x = x1 . . . xn, Alice can send a single quantum message ρx to Bob, whereupon Bob,
after examining his input y = y1 . . . ym, can choose some basis in which to measure ρx.
He must then output a claimed value for f (x, y). We are interested in how long Alice’s
message needs to be, for Bob to succeed with high probability on any x, y pair.
Ideally the
length will be much smaller than if Alice had to send a classical message.

0, 1
}
{

0, 1
}

→ {

× {

m

n

Communication complexity questions have been intensively studied in theoretical
computer science (see the book of Kushilevitz and Nisan [160] for example).
In both the
classical and quantum cases, though, most attention has focused on two-way communica-
I believe that
tion, meaning that Alice and Bob get to send messages back and forth.
the study of one-way quantum communication presents two main advantages. First, many
open problems about two-way communication look gruesomely diﬃcult—for example, are
the randomized and quantum communication complexities of every total Boolean function
polynomially related? We might gain insight into these problems by tackling their one-way
analogues ﬁrst. And second, because of its greater simplicity, the one-way model more
directly addresses our opening question: how much “useful stuﬀ” can be packed into a
quantum state? Thus, results on one-way communication fall into the quantum informa-
tion theory tradition initiated by Holevo [145] and others, as much as the communication
complexity tradition initiated by Yao [247].

Related to quantum one-way communication is the notion of quantum advice. As
pointed out by Nielsen and Chuang [182, p.203], there is no compelling physical reason to

1Another mu-worthy question is, “Where does the power of quantum computing come from? Superpo-

sition? Interference? The large size of Hilbert space?”

89

assume that the starting state of a quantum computer is a computational basis state:2

[W]e know that many systems in Nature ‘prefer’ to sit in highly entangled states
of many systems; might it be possible to exploit this preference to obtain extra
computational power? It might be that having access to certain states allows
particular computations to be done much more easily than if we are constrained
to start in the computational basis.

One way to interpret Nielsen and Chuang’s provocative question is as follows.
Suppose we could request the best possible starting state for a quantum computer, know-
ing the language to be decided and the input length n but not knowing the input itself.3
Denote the class of languages that we could then decide by BQP/qpoly—meaning quan-
tum polynomial time, given an arbitrarily-entangled but polynomial-size quantum advice
state.4 How powerful is this class? If BQP/qpoly contained (for example) the NP-complete
problems, then we would need to rethink our most basic assumptions about the power of
quantum computing. We will see later that quantum advice is closely related to quantum
one-way communication, since we can think of an advice state as a one-way message sent
to an algorithm by a benevolent “advisor.”

cation.

This chapter is about the limitations of quantum advice and one-way communi-
It presents three contributions which are basically independent of one another.
First, Section 10.2 shows that D1 (f ) = O

for any Boolean
function f , partial or total. Here D1 (f ) is deterministic one-way communication com-
plexity, Q1
2 (f ) is bounded-error one-way quantum communication complexity, and m is the
length of Bob’s input. Intuitively, whenever the set of Bob’s possible inputs is not too large,
Alice can send him a short classical message that lets him learn the outcome of any mea-
It is interesting that
surement he would have wanted to make on the quantum message ρx.
a slightly tighter bound for total functions—D1 (f ) = O
—follows easily from a
result of Klauck [154] together with a lemma of Sauer [212] about VC-dimension. However,
the proof of the latter bound is highly nonconstructive, and seems to fail for partial f .

2 (f ) log Q1

mQ1

mQ1

2 (f )

2 (f )

(cid:1)

(cid:1)

(cid:0)

(cid:0)

Using my communication complexity result, Section 10.2.1 shows that BQP/qpoly

⊆
PP/poly—in other words, BQP with polynomial-size quantum advice can be simulated in
PP with polynomial-size classical advice.5 This resolves a question of Harry Buhrman
(personal communication), who asked whether quantum advice can be simulated in any
classical complexity class with short classical advice. A corollary of this containment is
that we cannot hope to show an unrelativized separation between quantum and classical
= BQP/qpoly), without also showing that PP does not have
advice (that is, that BQP/poly
polynomial-size circuits.

2One might object that the starting state is itself the outcome of some computational process, which
began no earlier than the Big Bang. However, (1) for all we know highly entangled states were created in
the Big Bang, and (2) 14 billion years is a long time.

3If we knew the input, we would simply request a starting state that contains the right answer!
4BQP/qpoly might remind readers of a better-studied class called QMA (Quantum Merlin-Arthur). But
there are two key diﬀerences: ﬁrst, advice can be trusted while proofs cannot; second, proofs can be tailored
to a particular input while advice cannot.

5Given a complexity class C, the class C/poly consists of all languages decidable by a C machine, given
a polynomial-size classical advice string that depends only on the input length. See Chapter 3 for more
information about the complexity classes mentioned in this chapter.

6
90

What makes this result surprising is that, in the minds of many computer scien-
Indeed, this belief seems
tists, a quantum state is basically an exponentially long vector.
to fuel skepticism of quantum computing (see Goldreich [128] for example). But given an
exponentially long advice string, even a classical computer could decide any language what-
soever. So one might imagine na¨ıvely that quantum advice would let us solve problems
that are not even recursively enumerable given classical advice of a similar size! The failure
of this na¨ıve intuition supports the view that a quantum superposition over n-bit strings is
“more similar” to a probability distribution over n-bit strings than to a 2n-bit string.

(cid:16)

(cid:17)

√N

The second contribution of the chapter, in Section 10.3, is an oracle relative to
which NP is not contained in BQP/qpoly. Underlying this oracle separation is the ﬁrst
correct proof of a direct product theorem for quantum search. Given an N -item database
with K marked items, the direct product theorem says that if a quantum algorithm makes
queries, then the probability that the algorithm ﬁnds all K of the marked items
o
decreases exponentially in K. Notice that such a result does not follow from any existing
quantum lower bound. Earlier Klauck [155] had claimed a weaker direct product theorem,
based on the hybrid method of Bennett et al. [51], in a paper on quantum time-space
tradeoﬀs for sorting. Unfortunately, Klauck’s proof is incorrect. The proof uses the
polynomial method of Beals et al. [45], with the novel twist that we examine all higher
derivatives of a polynomial (not just the ﬁrst derivative). The proof has already been
improved by Klauck, ˇSpalek, and de Wolf [156], who were able to recover and even extend
Klauck’s original claims about quantum sorting.

∈ {

The ﬁnal contribution, in Section 10.4, is a new trace distance method for proving
lower bounds on quantum one-way communication complexity. Previously there was only
one basic lower bound technique: the VC-dimension method of Klauck [154], which relied
on lower bounds for quantum random access codes due to Ambainis et al. [32] and Nayak
[180]. Using VC-dimension one can show, for example, that Q1
2 (DISJ) = Ω (n), where the
is deﬁned by DISJ (x, y) = 1 if and
0, 1
disjointness function DISJ :
}
1, . . . , n
only if xiyi = 0 for all i

0, 1
}

0, 1
}

→ {

{

n

n

For some problems, however, the VC-dimension method yields no nontrivial quan-
tum lower bound. Seeking to make this point vividly, Ambainis posed the following prob-
lem. Alice is given two elements x, y of a ﬁnite ﬁeld Fp (where p is prime); Bob is given
Fp. Bob’s goal is to output 1 if y
another two elements a, b
ax + b (mod p) and 0 other-
wise. For this problem, the VC-dimension method yields no randomized or quantum lower
bound better than constant. On the other hand, the well-known ﬁngerprinting protocol
for the equality function [192] seems to fail for Ambainis’ problem, because of the interplay
between addition and multiplication. So it is natural to conjecture that the randomized
and even quantum one-way complexities are Θ (log p)—that is, that no nontrivial protocol
exists for this problem.

≡

∈

× {
.
}

, Bob is given y
}

Ambainis posed a second problem in the same spirit. Here Alice is given x
1, . . . , N

1, . . . , N
{
Bob’s goal is to decide whether x
is that if S is chosen uniformly at random with
the randomized and quantum one-way complexities are both Θ (log N ).

∈
.
, and both players know a subset S
}
}
S where subtraction is modulo N . The conjecture
∈
about √N , then with high probability

1, . . . , N

⊂ {

S
|

∈ {

−

y

|

Using the trace distance method, I am able to show optimal quantum lower bounds

91

for both of Ambainis’ problems. Previously, no nontrivial lower bounds were known even
for randomized protocols. The key idea is to consider two probability distributions over
Alice’s quantum message ρx. The ﬁrst distribution corresponds to x chosen uniformly at
random; the second corresponds to x chosen uniformly conditioned on f (x, y) = 1. These
distributions give rise to two mixed states ρ and ρy, which Bob must be able to distinguish
I then show an upper bound on
with non-negligible bias assuming he can evaluate f (x, y).
ρyktr, which implies that Bob cannot distinguish the distributions.
the trace distance
Theorem 65 gives a very general condition under which the trace distance method
works; Corollaries 66 and 67 then show that the condition is satisﬁed for Ambainis’ two
problems. Besides showing a signiﬁcant limitation of the VC-dimension method, I hope
the new method is a non-negligible step towards proving that R1
Q1
2 (f )
for all
total Boolean functions f , where R1
I conclude in
(cid:1)
Section 10.5 with some open problems.

2 (f ) = O
2 (f ) is randomized one-way complexity.
(cid:0)

−

ρ

k

10.1 Preliminaries

Following standard conventions, I denote by D1 (f ) the deterministic one-way complexity
of f , or the minimum number of bits that Alice must send if her message is a function of x.
Also, R1
2 (f ), the bounded-error randomized one-way complexity, is the minimum k such
Dx,
that for every x, y, if Alice sends Bob a k-bit message drawn from some distribution
then Bob can output a bit a such that a = f (x, y) with probability at least 2/3.
(The
subscript 2 means that the error is two-sided.) The zero-error randomized complexity
R1
0 (f ) is similar, except that Bob’s answer can never be wrong: he must output f (x, y)
with probability at least 1/2 and otherwise declare failure.

The bounded-error quantum one-way complexity Q1

2 (f ) is the minimum k such
that, if Alice sends Bob a mixed state ρx of k qubits, there exists a joint measurement of ρx
and y enabling Bob to output an a such that a = f (x, y) with probability at least 2/3. The
zero-error and exact complexities Q1
E (f ) are deﬁned analogously. Requiring
Alice’s message to be a pure state would increase these complexities by at most a factor of
2, since by Kraus’ Theorem, every k-qubit mixed state can be realized as half of a 2k-qubit
See Klauck [154]
pure state.
for more detailed deﬁnitions of quantum and classical one-way communication complexity
measures.

(Winter [243] has shown that this factor of 2 is tight.)

0 (f ) and Q1

(cid:1)

(cid:0)

≥

≥

R1

R1

Q1

0 (f )

0 (f )

2 (f )

2 (f ), that R1

It is immediate that D1 (f )

2 (f ), and that D1 (f )
D1 (f )

≥
E (f ) = D1 (f ) and that Q1

Q1
, while Klauck [154] showed that Q1

Q1
≥
E (f ). Also, for total f , Duriˇs et al. [101] showed that R1

0 (f )
≥
Q1
0 (f ) =
D1 (f )
Θ
.
In other words, randomized and quantum messages yield no improvement for total functions
(cid:1)
if one is unwilling to tolerate a bounded probability of error. This remains true even if
Alice and Bob share arbitrarily many EPR pairs [154]. As is often the case, the situation
is dramatically diﬀerent for partial functions: there it is easy to see that R1
0 (f ) can be
constant even though D1 (f ) = Ω (n):
n/4
+ xn/2yn/2 ≥
· · ·
+ xn/2yn/2 = 0 and
and xn/2+1yn/2+1 +
xn/2+1yn/2+1 +

+ xnyn = 0 and f (x, y) = 0 if x1y1 +

n/4, promised that one of these is the case.

let f (x, y) = 1 if x1y1 +

0 (f ) = Θ

· · ·

≥

(cid:0)

Moreover, Bar-Yossef, Jayram, and Kerenidis [43] have almost shown that Q1

E (f )

· · ·
+ xnyn ≥

· · ·

92

can be exponentially smaller than R1
In particular, they proved that separation
for a relation, meaning a problem for which Bob has many possible valid outputs. For a
partial function f based on their relation, they also showed that Q1
E (f ) = Θ (log n) whereas
R1
0 (f ) = Θ (√n); and they conjectured (but did not prove) that R1
2 (f ) = Θ (√n).

2 (f ).

10.1.1 Quantum Advice

Informally, BQP/qpoly is the class of languages decidable in polynomial time on a quantum
computer, given a polynomial-size quantum advice state that depends only on the input
length.

I now make the deﬁnition more formal.

Deﬁnition 51 A language L is in BQP/qpoly if there exists a polynomial-size quantum
1, such
circuit family
that for all x

1, and a polynomial-size family of quantum states
Cn}n
{
n,
≥
0, 1
}
∈ {

ψni}n

{|

≥

2/3, where q (x) is the probability that the ﬁrst qubit is measured

, after Cn is applied to the starting state

x
|

i ⊗ |

0

0
i ⊗ |

.
ψni

· · ·

L then q (x)
(i) If x
∈
1
to be
i
|
L then q (x)
(ii) If x /
∈

≥

1/3.6

≤

The central open question about BQP/qpoly is whether it equals BQP/poly, or
BQP with polynomial-size classical advice. We do have a candidate for an oracle problem
separating the two classes: the group membership problem of Watrous [239], which I will
describe for completeness. Let Gn be a black box group7 whose elements are uniquely
labeled by n-bit strings, and let Hn be a subgroup of Gn. Both Gn and Hn depend only on
the input length n, so we can assume that a nonuniform algorithm knows generating sets
for both of them. Given an element x
Gn as input, the problem is to decide whether
x

∈

Hn.

If Gn is “suﬃciently nonabelian” and Hn is exponentially large, we do not know
how to solve this problem in BQP or even BQP/poly. On the other hand, we can solve it
in BQP/qpoly as follows. Let the quantum advice state be an equal superposition over all
elements of Hn:

∈

1
Hn| Xy

∈

Hn

|

y

|

i

Hni
|

=

p

We can transform

Hni
|

into

xHni
|

|

|

i

=

Hn

xy

1
Hn| Xy
∈
p
1xy
x−
Hn. Our algorithm
0
=
xy
|
i |
|
i
∈
) /√2, then apply a Hadamard gate to the
xHni
1
+
(cid:11)
i |
|
for some

for each y

xy

=

i

y

to

xy
0
y
by mapping
to
y
i
i
i |
|
⊕
Hni
0
will ﬁrst prepare the state (
(cid:12)
|
i |
(cid:12)
0
0
· · ·

6If the starting state is

i ⊗ |

i |

|

required to lie in [0, 1/3]
Yamakami [186] call BQP/∗Qpoly. Also, it does not matter whether the circuit family
since we are giving it advice anyway.

, then the acceptance probability is not
x
|
i
[2/3, 1]. Therefore, what I call BQP/qpoly corresponds to what Nishimura and
1 is uniform,

ψn
|

i ⊗ |

ϕ
i

Cn

}n

i 6

∪

ϕ

{

≥

|

7In other words, we have a quantum oracle available that given x, y

xy into an answer register), and that given x

Gn outputs x−

1.

∈

Gn outputs xy (i.e. exclusive-OR’s

∈

93

h

=

and

xHni

xHni
|

Hn|
Hn, and the second occurs whenever x /
∈

ﬁrst qubit, and ﬁnally measure the ﬁrst qubit in the standard basis, in order to distinguish
= 0 with constant bias. The ﬁrst case occurs
Hni
the cases
|
whenever x
∈
Although the group membership problem provides intriguing evidence for the
power of quantum advice, we have no idea how to show that it is not also solvable us-
Indeed, apart from a result of Nishimura and Yamakami [186] that
ing classical advice.
EESPACE
BQP/qpoly, essentially nothing was known about the class BQP/qpoly before
6⊂
the work reported here.

Hn.

10.1.2 The Almost As Good As New Lemma

The following simple lemma, which was implicit in [32], is used three times in this chapter—
It says that, if the outcome of measuring a quantum state ρ
in Theorems 56, 57, and 64.
could be predicted with near-certainty given knowledge of ρ, then measuring ρ will damage
it only slightly. Recall that the trace distance
ktr between two mixed states ρ and σ
equals 1
2

, where λ1, . . . , λN are the eigenvalues of ρ

ρ
k

σ.

−

σ

−

Lemma 52 Suppose a 2-outcome measurement of a mixed state ρ yields outcome 0 with
probability 1
ρ
ktr ≤
√ε. This is true even if the measurement is a POVM (that is, involves arbitrarily many
ancilla qubits).

ε. Then after the measurement, we can recover a state

ρ such that

ρ
k

−

−

e

e

λi|

i |

P

ψ
|

Proof. Let

i
resent any measurement as a unitary U applied to
ϕ1i
Let
|
and U
ϕ0i
= α
|
measurement result as σ = (1

be a puriﬁcation of the entire system (ρ plus ancilla). We can rep-
, followed by a 1-qubit measurement.
= 0
ϕ0|
h
2 = ε. Writing the
|

be the two possible pure states after the measurement; then
+ β

2 = 1
, it is easy to show that

ϕ0i
|
ψ
|

ϕ1i

ϕ1i

ε and

and

+ ε

β
|

ε)

−

ψ

i

i

|

|

α
for some α, β such that
|
|
ϕ1|
ϕ1i h
ϕ0|
ϕ0i h
|
|
ε (1
ψ
ψ
tr =

U −

−

U

σ

1

−

|

i h

|

So applying U −

1 to σ,

(cid:13)
(cid:13)

U −

1σU

(cid:13)
(cid:13)
tr =

p

ε (1

ψ

ψ

− |

i h

|

ε).

−

ε).

−

ρ be the restriction of U −

1σU to the original qubits of ρ. Theorem 9.2 of Nielsen
Let
and Chuang [182] shows that tracing out a subsystem never increases trace distance, so
ρ
k

ρ
e
ktr ≤
−

√ε.

ε (1

p

(cid:13)
(cid:13)

(cid:13)
(cid:13)

ε)

≤

−

p

e
10.2 Simulating Quantum Messages

n

m

× {

→ {

0, 1
}

0, 1
}

0, 1
}
{

Let f :
existing results to obtain the relation D1 (f ) = O
using a new method that D1 (f ) = O

be a Boolean function.
mQ1
2 (f ) log Q1
2 (f )
(cid:0)
Deﬁne the communication matrix Mf to be a 2n
(cid:1)

(cid:1)
2m matrix with f (x, y) in the
xth row and yth column. Then letting rows (f ) be the number of distinct rows in Mf , the
following is immediate.

In this section I ﬁrst combine
for total f , and then prove

for all f (partial or total).

2 (f )

mQ1

×

(cid:0)

Proposition 53 For total f ,

94

D1 (f ) =
Q1

log2 rows (f )
⌉
2 (f ) = Ω (log log rows (f )) .

⌈

,

Also, let the VC-dimension VC (f ) equal the maximum k for which there exists a
k submatrix Mg of Mf with rows (g) = 2k. Then Klauck [154] observed the following,

2n
based on a lower bound for quantum random access codes due to Nayak [180].

×

Proposition 54 (Klauck) Q1

2 (f ) = Ω (VC (f )) for total f .

Now let cols (f ) be the number of distinct columns in Mf . Then Proposition 54

yields the following general lower bound:

Corollary 55 D1 (f ) = O

mQ1

2 (f )

for total f , where m is the size of Bob’s input.

Proof. It follows from a lemma of Sauer [212] that

(cid:0)

(cid:1)

rows (f )

≤

Hence VC (f )

logcols(f ) rows (f )

≥

Xi=0 (cid:18)
1, so

−

VC(f )

cols (f )
i

(cid:19)

Q1

2 (f ) = Ω (VC (f )) = Ω

= Ω

cols (f )VC(f )+1 .

log rows (f )
log cols (f )
D1 (f )
m

.

(cid:19)

(cid:19)

≤

(cid:18)

(cid:18)

In particular, D1 (f ) and Q1

2 (f ) are polynomially related for total f , whenever
Bob’s input is polynomially smaller than Alice’s, and Alice’s input is not “padded.” More
formally, D1 (f ) = O
whenever m = O (nc) for some c < 1 and rows (f ) = 2n
(i.e. all rows of Mf are distinct). For then D1 (f ) = n by Proposition 53, and Q1
Ω

(cid:17)
by Corollary 55.

2 (f )1/(1
−

D1 (f ) /nc

2 (f ) =

(cid:16)
n1

= Ω

Q1

c)

c

−

(cid:1)

(cid:0)

(cid:0)

(cid:1)

mQ1

I now give a new method for replacing quantum messages by classical ones when
Bob’s input is small. Although the best bound I know how to obtain with this method—
D1 (f ) = O
of
2 (f )
Corollary 55, our method works for partial Boolean functions as well as total ones.
It
(cid:1)
also yields a (relatively) eﬃcient procedure by which Bob can reconstruct Alice’s quantum
message, a fact I will exploit in Section 10.2.1 to show BQP/qpoly
PP/poly. By contrast,
⊆
the method based on Sauer’s Lemma seems to be nonconstructive.

—is slightly weaker than the D1 (f ) = O

2 (f ) log Q1

mQ1

2 (f )

(cid:1)

(cid:0)

(cid:0)

Theorem 56 D1 (f ) = O

mQ1

2 (f ) log Q1

2 (f )

for all f (partial or total).

(cid:0)

(cid:1)

Proof. Let f :

be a partial Boolean function with

m, and for all x

D → {
×
D ⊆ {
0, 1
0, 1
. Suppose Alice can
{
}
}
send Bob a quantum state with Q1
2 (f ) qubits, that enables him to compute f (x, y) for any
y
∈ Dx with error probability at most 1/3. Then she can also send him a boosted state ρ
qubits, such that for all y
with K = O

m : (x, y)

0, 1
}

∈ D}

∈ {

∈ {

Q1

{

y

2 (f ) log Q1

2 (f )

0, 1
}
n, let
Dx =

0, 1
}

∈ Dx,

95

n

(cid:0)

(cid:1)
Py (ρ)
|

−

f (x, y)

| ≤

1
2 (f )10 ,
Q1

Let

be any subset of

where Py (ρ) is the probability that some measurement Λ [y] yields a ‘1’ outcome when
applied to ρ. We can assume for simplicity that ρ is a pure state
; as discussed in
|
i h
Section 10.1, this increases the message length by at most a factor of 2.
2 (f )2. Then starting with ρ, Bob
Dx satisfying
Y
in lexicographic order, reusing the same message state
can measure Λ [y] for each y
again and again but uncomputing whatever garbage he generates while measuring. Let ρt
be the state after the tth measurement; thus ρ0 = ρ =
. Since the probability that
|
2 (f )10, Lemma 52
Bob outputs the wrong value of f (x, y) on any given y is at most 1/ Q1
implies that

|Y| ≤

∈ Y

ψ
|

ψ
|

Q1

i h

ψ

ψ

1ktr ≤ s
Since trace distance satisﬁes the triangle inequality, this in turn implies that

k

−

ρt −

ρt

1
2 (f )10 =
Q1

1
2 (f )5 .
Q1

ρt −

k

ρ
ktr ≤

t
2 (f )5 ≤

Q1

1
2 (f )3 .
Q1

Now imagine an “ideal scenario” in which ρt = ρ for every t; that is, the measurements do
not damage ρ at all. Then the maximum bias with which Bob could distinguish the actual
from the ideal scenario is

|Y|
2 (f )3 ≤
So by the union bound, Bob will output f (x, y) for every y
probability at least

ρ0 ⊗ · · · ⊗
(cid:13)
(cid:13)
(cid:13)

ρ⊗|Y|

1 −

tr ≤

Q1

(cid:13)
(cid:13)
(cid:13)

|Y|−

ρ

1
Q1
2 (f )

.

simultaneously with

∈ Y

1

−

|Y|
2 (f )10 −

Q1

1
Q1
2 (f ) ≥

0.9

for suﬃciently large Q1

2 (f ).

Now imagine that the communication channel is blocked, so Bob has to guess what
message Alice wants to send him. He does this by using the K-qubit maximally mixed
state I in place of ρ. We can write I as

I =

1
2K

2K

Xj=1

ψji h
|

ψj|

,

, . . . ,

ψ1i
|

ψ1i
where
|
procedure as above except with I instead of ρ, then for any
simultaneously with probability at least 0.9/2K .
will output f (x, y) for every y

=
i
Y ⊆ Dx with

. So if Bob uses the same
2 (f )2, he

are orthonormal vectors such that

|Y| ≤

ψ2K

ψ
|

Q1

i

|

∈ Y

96

(cid:1)

(cid:0)

≥

≤

mQ1

2 (f ) log Q1

The classical simulation of the quantum protocol is now as follows. Alice’s mes-
K inputs y1, . . . , yT ∈ Dx, together with f (x, y1) , . . . , f (x, yT ).8
sage to Bob consists of T
Thus the message length is mT + T = O
. Here are the semantics of
2 (f )
Alice’s message: “Bob, suppose you looped over all y
∈ Dx in lexicographic order; and for
each one, guessed that f (x, y) = round (Py (I)), where round (p) is 1 if p
1/2 and 0 if
In
p < 1/2. Then y1 is the ﬁrst y for which you would guess the wrong value of f (x, y).
general, let It be the state obtained by starting from I and then measuring Λ [y1] , . . . , Λ [yt]
in that order, given that the outcomes of the measurements are f (x, y1) , . . . , f (x, yt) re-
∈ Dx up to yt, only by
spectively. (Note that It is not changed by measurements of every y
measurements of y1, . . . , yt.) If you looped over all y
∈ Dx in lexicographic order beginning
= f (x, y).”
from yt, then yt+1 is the ﬁrst y you would encounter for which round (Py (It))
Given the sequence of yt’s as deﬁned above, it is obvious that Bob can compute
∈ Dx. First, if y = yt for some t, then he simply outputs f (x, yt).
f (x, y) for any y
Otherwise, let t∗ be the largest t for which yt < y lexicographically. Then Bob prepares
a classical description of the state It∗ —which he can do since he knows y1, . . . , yt∗ and
f (x, y1) , . . . , f (x, yt∗ )—and then outputs round (Py (It∗ )) as his claimed value of f (x, y).
Dx to prepare her message, Bob does not
Notice that, although Alice uses her knowledge of
need to know
Dx in order to interpret the message. That is why the simulation works for
partial as well as total functions.

≤

Q1

K?

= K + 1

But why can we assume that the sequence of yt’s stops at yT for some T

Suppose T > K; we will derive a contradiction. Let

≤
. Then
2 (f )2, so we know from previous reasoning that if Bob starts with I and
|Y|
then measures Λ [y1] , . . . , Λ [yK+1] in that order, he will observe f (x, y1) , . . . , f (x, yK+1)
simultaneously with probability at least 0.9/2K . But by the deﬁnition of yt, the probability
that Λ [yt] yields the correct outcome is at most 1/2, conditioned on Λ [y1] , . . . , Λ [yt
1]
having yielded the correct outcomes.
Therefore f (x, y1) , . . . , f (x, yK+1) are observed
simultaneously with probability at most 1/2K+1 < 0.9/2K , contradiction.

y1, . . . , yK+1}
{

=

Y

−

10.2.1 Simulating Quantum Advice

I now apply the new simulation method to upper-bound the power of quantum advice.

Theorem 57 BQP/qpoly

PP/poly.

⊆

Proof. For notational convenience, let Ln (x) = 1 if input x

n is in
language L, and Ln (x) = 0 otherwise. Suppose Ln is computed by a BQP machine using
quantum advice of length p (n). We will give a PP machine that computes Ln using
classical advice of length O (np (n) log p (n)). Because of the close connection between
advice and one-way communication, the simulation method will be essentially identical to
that of Theorem 56.

0, 1
}

∈ {

By using a boosted advice state on K = O (p (n) log p (n)) qubits, a polynomial-
time quantum algorithm A can compute Ln (x) with error probability at most 1/p (n)10.
n,
Now the classical advice to the PP machine consists of T
8Strictly speaking, Bob will be able to compute f (x, y1) , . . . , f (x, yT ) for himself given y1, . . . , yT ; he

K inputs x1, . . . , xT ∈ {

0, 1
}

≤

does not need Alice to tell him the f values.

6
97

together with Ln (x1) , . . . , Ln (xT ).
Let I be the maximally mixed state on K qubits.
Also, let Px (ρ) be the probability that A outputs ‘1’ on input x, given ρ as its advice
state. Then x1 is the lexicographically ﬁrst input x for which round (Px (I))
= Ln (x).
In general, let It be the state obtained by starting with I as the advice and then running
A on x1, . . . , xt in that order (uncomputing garbage along the way), if we postselect on A
correctly outputting Ln (x1) , . . . , Ln (xt). Then xt+1 is the lexicographically ﬁrst x > xt
for which round (Px (It))

= Ln (x).

Given the classical advice, we can compute Ln (x) as follows: if x

x1, . . . , xT }
then output Ln (xt). Otherwise let t∗ be the largest t for which xt < x lexicographically,
and output round (Px (It∗ )). The proof that this algorithm works is the same as in Theorem
56, and so is omitted for brevity. All that needs to be shown is that the algorithm can be
implemented in PP.

∈ {

⊆

Adleman, DeMarrais, and Huang [16] (see also Fortnow and Rogers [116]) showed
that BQP
PP, by using what physicists would call a “Feynman sum-over-histories.”
Speciﬁcally, let C be a polynomial-size quantum circuit that starts in the all-0 state, and
that consists solely of Toﬀoli and Hadamard gates (Shi [217] has shown that this gate set
after all gates in C have been
is universal). Also, let αz be the amplitude of basis state
applied. We can write αz as a sum of exponentially many contributions, a1 +
+ aN ,
where each ai is a rational real number computable in classical polynomial time. So by
evaluating the sum

z
|

· · ·

i

Xi,j=1
putting positive and negative terms on “opposite sides of the ledger,” a PP machine can
It follows that a PP machine can also
check whether
check whether

2 > β for any rational constant β.

αz|

|

N

aiaj,

2 =

αz|
|

2 >

αz|
|

2

αz|
|

Xz : S1(z)

Xz : S0(z)

(or equivalently, whether Pr [S1] > Pr [S0]) for any classical polynomial-time predicates S1
and S0.

Now suppose the circuit C does the following, in the case x /

It
ﬁrst prepares the K-qubit maximally mixed state I (as half of a 2K-qubit pure state),
and then runs A on x1, . . . , xt∗ , x in that order, using I as its advice state. The claimed
values of Ln (x1) , . . . , Ln (xt∗) , Ln (x) are written to output registers but not measured.
contains the output
For i
sequence Ln (x1) , . . . , Ln (xt∗ ) , i. Then it is not hard to see that

, let the predicate Si (z) hold if and only if basis state

.
x1, . . . , xT }

0, 1
}

∈ {

∈ {

z
|

i

Px (It∗) =

Pr [S1]
Pr [S1] + Pr [S0]

,

x1, . . . , xT }

∈ {

so Px (It∗ ) > 1/2 and hence Ln (x) = 1 if and only if Pr [S1] > Pr [S0].
x

is trivial, this shows that Ln (x) is computable in PP/poly.

Since the case

Let me make ﬁve remarks about Theorem 57. First, for the same reason that
Theorem 56 works for partial as well as total functions, one actually obtains the stronger

6
6
result that PromiseBQP/qpoly
the promise-problem versions of BQP and PP respectively.

⊆

PromisePP/poly, where PromiseBQP and PromisePP are

98

Second, as pointed out to me by Lance Fortnow, a corollary of Theorem 57 is that
we cannot hope to show an unrelativized separation between BQP/poly and BQP/qpoly,
without also showing that PP does not have polynomial-size circuits. For BQP/poly
=
= PP/poly. But the latter then implies that PP
BQP/qpoly clearly implies that P/poly
6⊂
P/poly we could also obtain polynomial-size circuits for a
P/poly, since assuming PP
PP, consisting of all (x, a) pairs
language L
such that the PP machine would accept x given advice string a. The reason this works is
that PP is a syntactically deﬁned class.

PP/poly by deﬁning a new language L′ ∈

⊂

∈

⊆

Third, initially I showed that BQP/qpoly

EXP/poly, by using a simulation in
which an EXP machine keeps track of a subspace H of the advice Hilbert space to which the
In that simulation, the classical advice speciﬁes inputs
‘true’ advice state must be close.
x1, . . . , xT for which dim (H) is at least halved; the observation that dim (H) must be at
least 1 by the end then implies that T
K = O (p (n) log p (n)), meaning that the advice
is of polynomial size. The huge improvement from EXP to PP came solely from working
with measurement outcomes and their probabilities instead of with subspaces and their
dimensions. We can compute the former using the same “Feynman sum-over-histories”
that Adleman et al. [16] used to show BQP
PP, but I could not see any way to compute
the latter without explicitly storing and diagonalizing exponentially large matrices.

⊆

≤

Fourth, assuming BQP/poly

= BQP/qpoly, Theorem 57 is almost the best result
of its kind that one could hope for, since the only classes known to lie between BQP and PP
and not known to equal either are obscure ones such as AWPP [116].
Initially the theorem
PostBQP/poly. Here
seemed to me to prove something stronger, namely that BQP/qpoly
PostBQP is the class of languages decidable by polynomial-size quantum circuits with post-
selection—meaning the ability to measure a qubit that has a nonzero probability of being
. Clearly PostBQP lies
1
|
i
somewhere between BQP and PP; one can think of it as a quantum analogue of the classical
complexity class BPPpath [142].
It turns out, however, that PostBQP = PP (see Chapter
15).

, and then assume that the measurement outcome will be

1
i
|

⊆

Fifth, it is clear that Adleman et al.’s BQP

PP result [16] can be extended
to show that PQP = PP. Here PQP is the quantum analogue of PP—that is, quantum
polynomial time but where the probability of a correct answer need only be bounded above
1/2, rather than above 2/3.
It has been asked whether Theorem 57 could similarly be
extended to show that PQP/qpoly = PP/poly. The answer is no—for indeed, PQP/qpoly
contains every language whatsoever! To see this, given any function Ln :
,
let the quantum advice state be

0, 1
}
{

0, 1
}

→ {

⊆

n

=

ψni
|

1
2n/2

x

Ln (x)

i |

.

i

n |
}

0,1
Xx
∈{

Then a PQP algorithm to compute Ln is as follows: given an input x
x
ψni
|
|
uniform random bit.

in the standard basis.

n, ﬁrst measure
is observed, output Ln (x); otherwise output a

0, 1
}

Ln (x)

∈ {

i |

If

i

6
6
6
10.3 A Direct Product Theorem for Quantum Search

99

Can quantum computers solve NP-complete problems in polynomial time? In the early
days of quantum computing, Bennett et al. [51] gave an oracle relative to which NP
BQP,
It is easy to extend
providing what is still the best evidence we have that the answer is no.
BQP/poly; that is, NP is
Bennett et al.’s result to give an oracle relative to which NP
hard even for nonuniform quantum algorithms. But when we try to show NP
BQP/qpoly
relative to an oracle, a new diﬃculty arises: even if the oracle encodes 2n exponentially
hard search problems for each input length n, the quantum advice, being an “exponentially
large object” itself, might somehow encode information about all 2n problems. We need
to argue that even if so, only a miniscule fraction of that information can be extracted by
measuring the advice.

6⊂

6⊂

6⊂

How does one prove such a statement? As it turns out, the task can be reduced
to proving a direct product theorem for quantum search. This is a theorem that in its
weakest form says the following: given N items, K of which are marked, if we lack enough
time to ﬁnd even one marked item, then the probability of ﬁnding all K items decreases
exponentially in K. For intuitively, suppose there were a quantum advice state that let us
eﬃciently ﬁnd any one of K marked items. Then by “guessing” the advice (i.e. replacing
it by a maximally mixed state), and then using the guessed advice multiple times, we could
eﬃciently ﬁnd all K of the items with a success probability that our direct product theorem
shows is impossible. This reduction is formalized in Theorem 64.

But what about the direct product theorem itself?

It seems like it should be
trivial to prove—for surely there are no devious correlations by which success in ﬁnding
one marked item leads to success in ﬁnding all the others! So it is surprising that even
a weak direct product theorem eluded proof for years.
In 2001, Klauck [155] gave an
attempted proof using the hybrid method of Bennett et al. [51]. His motivation was to
show a limitation of space-bounded quantum sorting algorithms. Unfortunately, Klauck’s
proof is fallacious.9

In this section I give the ﬁrst correct proof of a direct product theorem, based on
the polynomial method of Beals et al. [45]. Besides showing that NP
BQP/qpoly relative
6⊂
to an oracle, my result can be used to recover the conclusions in [155] about the hardness
of quantum sorting (see Klauck, ˇSpalek, and de Wolf [156] for details).
I expect the result
to have other applications as well.

I will need the following lemma of Beals et al. [45].

Lemma 58 (Beals et al.) Suppose a quantum algorithm makes T queries to an oracle
N , and accepts with probability A (X). Then there exists a real polynomial
string X
0, 1
}
p, of degree at most 2T , such that

∈ {

p (i) = EX
=i

X

|

|

[A (X)]

for all integers i

0, . . . , N

, where

denotes the Hamming weight of X.

∈ {

}

X
|

|

9Speciﬁcally, the last sentence in the proof of Lemma 5 in [155] (“Clearly this probability is at least

Qx (px

−

α)”) is not justiﬁed by what precedes it.

100

Lemma 58 implies that, to lower-bound the number of queries T made by a quan-
tum algorithm, it suﬃces to lower-bound deg (p), where p is a real polynomial representing
the algorithm’s expected acceptance probability. As an example, any quantum algorithm
that computes the OR function on N bits, with success probability at least 2/3, yields a
polynomial p such that p (0)
.
}
To lower-bound the degree of such a polynomial, one can use an inequality proved by A. A.
Markov in 1890 ([172]; see also [203]):

[2/3, 1] for all integers i

[0, 1/3] and p (i)

1, . . . , N

∈ {

∈

∈

Theorem 59 (A. A. Markov) Given a real polynomial p and constant N > 0, let r(0) =
maxx

and r(1) = maxx

[0,N ] |
∈

. Then
p′ (x)
|

[0,N ] |
∈

p (x)
|

deg (p)

N r(1)
2r(0)

.

≥ s

Theorem 59 deals with the entire range [0, N ], whereas in our setting p (x) is
. But as shown in [104, 184, 204],
0, . . . , N
2/3 imply that
1/3 and p (1)
≥
1/3. Furthermore, let x∗ be a
[0, 1] imply that

constrained only at the integer points x
this is not a problem. For by elementary calculus, p (0)
[0, 1], and therefore r(1)
p′ (x)
point in [0, N ] where
r(0)
r(1)

∈
= r(0). Then p (
)
x∗⌋
⌊

1/3 for some real x
p (x∗)

[0, 1] and p (

|
. Thus

x∗⌉
⌈

≤
≥

∈ {

≥

∈

∈

1

2

}

)

|

≥

−

(cid:0)

(cid:1)

deg (p)

N r(1)
2r(0) ≥ s

≥ s

N max

1/3, 2
2r(0)
(cid:0)

(cid:8)

r(0)

1

−

(cid:1)(cid:9)

= Ω

√N

.

(cid:17)

(cid:16)
√N

queries.

This is the proof of Beals et al. [45] that quantum search requires Ω

When proving a direct product theorem, one can no longer apply Theorem 59 so
straightforwardly. The reason is that the success probabilities in question are extremely
small, and therefore the maximum derivative r(1) could also be extremely small. For-
tunately, though, one can still prove a good lower bound on the degree of the relevant
polynomial p. The key is to look not just at the ﬁrst derivative of p, but at higher deriva-
tives.

(cid:17)

(cid:16)

To start, we need a lemma about the behavior of functions under repeated diﬀer-

entiation.

Lemma 60 Let f : R
positive integer K, we have f (i) = 0 for all i
let r(m) = maxx
(thus f (0) = f ). Then r(m)

R be an inﬁnitely diﬀerentiable function such that for some
and f (K) = δ > 0. Also,
1
}
, where f (m) (x) is the mth derivative of f evaluated at x
δ/m! for all m
(cid:12)
(cid:12)

f (m) (x)

0, . . . , K

0, . . . , K

∈ {

∈ {

.
}

[0,N ]

→

≥

−

(cid:12)
(cid:12)

∈

Proof. We claim, by induction on m, that there exist K
x(m)
i
(cid:16)

< x(m)
K
· · ·
−
If we deﬁne x(0)
(cid:17)
lemma. Suppose the claim is true for m; then by elementary calculus, for all i

≤
i = i, then the base case m = 0 is immediate from the conditions of the
2

K such that f (m)

x(m)
K
−
(cid:16)

m+1 points 0

1 and f (m)

= 0 for all i

m ≤

(cid:17)
K

m

m

K

−

≥

≤

−

−

m

x(m)
0 <
δ/m!.

≤

−

−

x(m+1)
there exists a point x(m+1)
such that f (m+1)
i
x(m+1)
i = i. So there is also a point x(m+1)
x(0)
(cid:16)
(cid:17)
i
m
−
that

x(m)
i ≥ · · · ≥

, x(m)
i+1

x(m)
i

1 ∈

≥

∈

(cid:16)

K

−

i

101

= 0. Notice that

x(m)
(cid:17)
K
−

1, x(m)

K

−

m

−

such

m

(cid:17)

(cid:16)

f (m+1)

x(m+1)
m
K
−
−
(cid:16)

1

(cid:17)

≥

≥

=

f (m)

x(m)
K
−

x(m)
K
−
(cid:16)
m
−

1

1

m

−

(cid:17)

f (m)

(cid:16)

−

x(m)
K
m
−
(cid:17)
x(m)
m −
K
−
δ/m!
0
−
m
(K

1)

−

K

−
δ
(m + 1)!

−
.

With the help of Lemma 60, one can sometimes lower-bound the degree of a real
polynomial even its ﬁrst derivative is small throughout the region of interest. To do so, I
will use the following generalization of A. A. Markov’s inequality (Theorem 59), which was
proved by A. A. Markov’s younger brother V. A. Markov in 1892 ([173]; see also [203]).

Theorem 61 (V. A. Markov) Given a real polynomial p of degree d and positive real
number N , let r(m) = maxx

. Then for all m

p(m) (x)

[0,N ]

,

1, . . . , d
}

∈ {

∈

r(m)

≤  

≤  

2r(0)
N !

2r(0)
N !

m

(cid:12)
(cid:12)
T (m)
d

(1)

(cid:12)
(cid:12)

m d2

d2

12

d2

−

(cid:0)

3

1
(cid:1) (cid:0)
·

−
5

·

22

d2

· · · · ·
(cid:16)
(2m
−

(cid:1)
· · · · ·

−
1)

1)2

(m

−

.

(cid:17)

Here Td (x) = cos (d arccos x) is the dth Chebyshev polynomial of the ﬁrst kind.

As demonstrated below, combining Theorem 61 with Lemma 60 yields a lower

bound on deg (p).

Lemma 62 Let p be a real polynomial such that

(i) p (x)

∈

[0, 1] at all integer points x

0, . . . , N

∈ {

, and

}

(ii) for some positive integer K
0, . . . , K

all i

.
1
}

−

∈ {

N and real δ > 0, we have p (K) = δ and p (i) = 0 for

≤

Then deg (p) = Ω

√N δ1/K
(cid:16)

(cid:17)

.

Proof. Let p(m) and r(m) be as in Theorem 61. Then for all m

Theorem 61 yields

r(m)

m

2r(0)
N !

≤  

deg (p)2m
(2m
5

· · · · ·

1)

−

3

1

·

·

1, . . . , deg (p)
}

,

∈ {

Rearranging,

N
2r(0)

deg (p)

1

3

5

(2m

1)

r(m)

·
(cid:0)
(cid:1)
1 (if m > deg (p) then r(m) = 0 so the bound is trivial).

≥ r

· · · · ·

−

·

·

≥
There are now two cases. First suppose r(0)

for all m

condition (i) implies that r(1)

2

r(0)

1

−

≥

, and hence that

≥

deg (p)

≥ s

(cid:1)

(cid:0)
N r(1)
2r(0) ≥ s

N

r(0)
r(0)

(cid:0)

1

= Ω

√N

−

by Theorem 59. Next suppose r(0) < 2. Then r(m)
So setting m = K yields

≥

102

1/m

2. Then as discussed previously,

(cid:1)

(cid:17)
(cid:16)
δ/m! for all m

K by Lemma 60.

≤

deg (p)

N
4

(cid:18)

≥ s

1

3

·

·

5

· · · · ·

(2K

1)

−

1/K

δ
K!

·

(cid:19)

= Ω

N δ1/K

.

(cid:16)p

(cid:17)

Either way we are done.

Strictly speaking, one does not need the full strength of Theorem 61 to prove a
lower bound on deg (p) that suﬃces for an oracle separation between NP and BQP/qpoly.
For one can show a “rough-and-ready” version of V. A. Markov’s inequality by applying A.
A. Markov’s inequality (Theorem 59) repeatedly, to p, p(1), p(2), and so on. This yields

r(m)

2
N

≤

deg (p)2 r(m
−

1)

2
N

≤

deg (p)2

m

r(0)

(cid:18)
If deg (p) is small, then this upper bound on r(m) contradicts the lower bound
for all m.
of Lemma 60. However, the lower bound on deg (p) that one gets from A. A. Markov’s
inequality is only Ω

from Lemma 62.10

, as opposed to Ω

N δ1/K /K

(cid:19)

Shortly after seeing my proof of a weak direct product theorem, Klauck, ˇSpalek,
and de Wolf [156] managed to improve the lower bound on deg (p) to the essentially tight
Ω
In particular, their bound implies that δ decreases exponentially in K

(cid:16)p

(cid:17)

(cid:17)

.

√N δ1/K
(cid:16)

. They obtained this improvement by factoring p instead of

√N Kδ1/K
(cid:16)

(cid:17)

whenever deg (p) = o
diﬀerentiating it as in Lemma 60.

√N K

(cid:16)

(cid:17)

In any case, a direct product theorem follows trivially from what has already been

said.

Theorem 63 (Direct Product Theorem) Suppose a quantum algorithm makes T queries
N . Let δ be the minimum probability, over all X with Ham-
to an oracle string X
K
ming weight
for some constant c.

= K, that the algorithm ﬁnds all K of the ‘1’ bits. Then δ

0, 1
}

cT 2/N

∈ {

X

≤

|

|

(cid:0)

(cid:1)

10An earlier version of this chapter claimed to prove deg (p) = Ω

√N K/ log3/2 (1/δ)

, by applying

Bernstein’s inequality [56] rather than A. A. Markov’s to all derivatives p(m).
in that argument.
superseded by the later results of Klauck et al. [156].

(cid:17)
I have since discovered a ﬂaw
In any case, the Bernstein lower bound is both unnecessary for an oracle separation, and

(cid:16)

Proof. Have the algorithm accept if it ﬁnds K or more ‘1’ bits and reject otherwise.
Let p (i) be the expected probability of acceptance if X is drawn uniformly at random subject
to

= i. Then we know the following about p:

X
|

|

103

(i) p (i)

[0, 1] at all integer points i

∈
(ii) p (i) = 0 for all i

0, . . . , K

∈ {

1
}

−

0, . . . , N

, since p (i) is a probability.

∈ {
, since there are not K marked items to be found.

}

(iii) p (K)

δ.

≥

Furthermore, Lemma 58 implies that p is a polynomial in i satisfying deg (p)
cT 2/N

, or rearranging, that δ

It follows from Lemma 62 that T = Ω

2T .

≤
K .

The desired oracle separation can now be proven using standard complexity theory
(cid:17)

√N δ1/K
(cid:16)

≤

(cid:0)

(cid:1)

tricks.

Theorem 64 There exists an oracle relative to which NP

BQP/qpoly.

6⊂

x

∈

≤

≤

Proof. Given an oracle A :

0, 1
∗
}
{
z lexicographically and there exists an x such that y

LA
0, 1
}
z and A (x) = 1.
if and only if y
≤
NPA for all A. We argue that for some A, no BQP/qpoly machine M with
Clearly LA ∈
oracle access to A can decide LA. Without loss of generality we assume M is ﬁxed, so that
1 depend on A. We also assume the advice is boosted, so
only the advice states

, deﬁne the language LA by (y, z)

ψni}n
{|
that M ’s error probability on any input (y, z) is 2−

→ {

⊂ {
∈

Choose a set S

n subject to

n, set
0, 1
}
S. We claim that by using M , an algorithm could ﬁnd all
A (x) = 1 if and only if x
2n/10 elements of S with high probability after only 2n/10 poly (n) queries to A. Here is
how: ﬁrst use binary search (repeatedly halving the distance between y and z) to ﬁnd the
is good
lexicographically ﬁrst element of S. By Lemma 52, the boosted advice state
for 2Ω(n2) uses, so this takes only poly (n) queries. Then use binary search to ﬁnd the
lexicographically second element, and so on until all elements have been found.

0, 1
}

ψni
|

∈ {

Ω(n2).
= 2n/10; then for all x

S

≥

|

|

Now replace

by the maximally mixed state as in Theorem 56. This yields an
algorithm that uses no advice, makes 2n/10 poly (n) queries, and ﬁnds all 2n/10 elements of
O(poly(n)), T = 2n/10 poly (n), N = 2n,
S with probability 2−
K , which violates the bound
and K = 2n/10, such an algorithm would satisfy δ
of Theorem 63.

ψni
|
O(poly(n)). But taking δ = 2−

cT 2/N

≫

BQP/qpoly relative a random oracle with proba-

(cid:0)

(cid:1)

Indeed one can show that NP

bility 1.11

6⊂

10.4 The Trace Distance Method

This section introduces a new method for proving lower bounds on quantum one-way com-
munication complexity. Unlike in Section 10.2, here I do not try to simulate quantum

11First group the oracle bits into polynomial-size blocks as Bennett and Gill [54] do, then use the techniques
of Chapter 6 to show that the acceptance probability is a low-degree univariate polynomial in the number
of all-0 blocks. The rest of the proof follows Theorem 64.

protocols using classical ones.
Instead I prove lower bounds for quantum protocols di-
rectly, by reasoning about the trace distance between two possible distributions over Alice’s
quantum message (that is, between two mixed states). The result is a method that works
even if Alice’s and Bob’s inputs are the same size.

104

I ﬁrst state the method as a general theorem; then, in Section 10.4.1, I apply the
denote the

theorem to prove lower bounds for two problems of Ambainis. Let
variation distance between probability distributions

kD − Ek

and

.

D

E

∈ {

m, let

Theorem 65 Let f :
0, 1
y
}
a distribution over y
ﬁrst choosing y
Prx

∈ B

1,y

∈D

∈B

n

0, 1
}

m

0, 1
}

{

× {
→ {
Ay be a distribution over x
0, 1
}

m, and let

Dk be the distribution over (
∈ {
and then choosing k samples independently from
2
D2 − D
1

δ. Then Q1

≤

0, 1
}
0, 1
}
∈ {

be a total Boolean function. For each
n such that f (x, y) = 1. Let
be
n)k formed by
0, 1
{
}
Ay. Suppose that

B

2 (f ) = Ω (log 1/δ).

[f (x, y) = 0] = Ω (1) and that

Proof. Suppose that if Alice’s input is x, then she sends Bob the ℓ-qubit mixed
m, Bob outputs f (x, y)
state ρx. Suppose also that for every x
with probability at least 2/3. Then by amplifying a constant number of times, Bob’s
success probability can be made 1
ε for any constant ε > 0. So with L = O (ℓ) qubits of
communication, Bob can distinguish the following two cases with constant bias:

0, 1
}

0, 1
}

∈ {

∈ {

−

(cid:13)
(cid:13)
n and y

(cid:13)
(cid:13)

Case I. y was drawn from
Case II. y was drawn from
For in Case I, we assumed that f (x, y) = 0 with constant probability, whereas in
Case II, f (x, y) = 1 always. An equivalent way to say this is that with constant probability
over y, Bob can distinguish the mixed states ρ = EXx
y [ρx] with
constant bias. Therefore

and x from
and x from

1 [ρx] and ρy = EXx

D1.
Ay.

B
B

∈A

∈D

We need an upper bound on the trace distance

(cid:3)

ρ

k

−

ρyktr

= Ω (1) .

EX
y
∈B

(cid:2)

to analysis. Let λ1, . . . , λ2L be the eigenvalues of ρ

−

ρ
ρy. Then

−

k

ρyktr that is more amenable

ρ
k

−

ρyktr =

1
2

2L

Xi=1

λi|
|

2L

2L

≤

1
2 v
u
u
t
= 2L/2
−

1

λ2
i

Xi=1

2L

v
u
u
t
where (ρ)ij is the (i, j) entry of ρ. Here the second line uses the Cauchy-Schwarz inequality,
and the third line uses the unitary invariance of the Frobenius norm.

(cid:12)
(cid:12)
(cid:12)

(ρ)ij −
Xi,j=1 (cid:12)
(cid:12)
(cid:12)

2

(ρy)ij

We claim that

EX
y
∈B

2L


Xi,j=1 (cid:12)
(cid:12)

(cid:12)

(ρ)ij −

(ρy)ij

2δ.

2

(cid:12)
(cid:12)
(cid:12)



≤



From this claim it follows that

2L

EX
y
∈B

(cid:2)

ρ
k

−

ρyktr

≤

(cid:3)

2L/2
−

1 EX
y
∈B





v
u
u
t

105

2

(cid:12)
(cid:12)
(cid:12)
2





(ρy)ij

(ρy)ij





(cid:12)
(cid:12)
(cid:12)

(ρ)ij −
Xi,j=1 (cid:12)
(cid:12)
(cid:12)
2L
(ρ)ij −
Xi,j=1 (cid:12)
(cid:12)
(cid:12)

2L/2
−

1

√2L
−

EX
v
u
y
∈B
u
u
t
1δ.





≤

≤

Therefore the message length L must be Ω (log 1/δ) to ensure that EXy
Ω (1).

∈B

Let us now prove the claim. We have

ρ

k

−

ρyktr

=

(cid:2)

(cid:3)

EX
y
∈B

2L





Xi,j=1 (cid:12)
(cid:12)
(cid:12)

(ρ)ij −

(ρy)ij

2





(cid:12)
(cid:12)
(cid:12)

=

=

2 Re

(ρ)∗ij EX
y

(ρy)ij

∈B h

(ρy)ij

i(cid:19)

+ EX
y

∈B (cid:20)(cid:12)
(cid:12)
(cid:12)

2

(cid:12)
(cid:12)
(cid:12)

(cid:21)(cid:19)

2L

2

(ρ)ij

Xi,j=1 (cid:18)(cid:12)
(cid:12)
2L
(cid:12)
EX
y
∈B (cid:20)(cid:12)
(cid:12)
(cid:12)

Xi,j=1 (cid:18)

−

(cid:12)
(cid:12)
(cid:12)
(ρy)ij

(cid:18)

2

−

(cid:21)

(cid:12)
(cid:12)
(cid:12)

(ρ)ij
(cid:12)
(cid:12)
(cid:12)

2

(cid:12)
(cid:12)
(cid:12)

,

(cid:19)

since EXy

∈B

h

(ρy)ij

= (ρ)ij. For a given (i, j) pair,

i
(ρy)ij

2

−

(cid:21)

(ρ)ij
(cid:12)
(cid:12)
(cid:12)

2

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

EX
y
∈B (cid:20)(cid:12)
(cid:12)
(cid:12)

= EX
y

EX
x
∈B "(cid:12)
y
∈A
(cid:12)
(cid:12)
EX
(cid:12)
,x,z

y
∈A

∈B

=

y

=

Pr
2
D

x,z  
X

h
[x, z]

2

(ρx)ij

2

(ρx)ij

# −

i(cid:12)
h
(cid:12)
(cid:12)
(ρx)∗ij (ρz)ij
(cid:12)

EX
x
1
(cid:12)
∈D
(cid:12)
(cid:12)
(cid:12)
−

x,z

h
EX
∈D

1

i
[x, z]

h
(ρx)∗ij (ρz)ij .

!

−

Pr
2
1
D

i(cid:12)
(cid:12)
(cid:12)
(ρx)∗ij (ρz)ij
(cid:12)

i

Now for all x, z,

Hence

2L

(cid:12)
(cid:12)
Xi,j=1
(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤

(ρx)∗ij (ρz)ij(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2L

2L

(ρx)ij

Xi,j=1 (cid:12)
(cid:12)
(cid:12)

1.

≤

2

(cid:12)
(cid:12)
(cid:12)

Pr
2
D

x,z  
X

[x, z]

[x, z]

−

Pr
2
1
D

!

Xi,j=1

(ρx)∗ij (ρz)ij ≤

Pr
2
D

[x, z]

−

Pr
2
1
D

[x, z]

!

x,z  
X

= 2

2
D2 − D
1

and we are done.

2δ,
(cid:13)
(cid:13)

≤

(cid:13)
(cid:13)

The diﬃculty in extending Theorem 65 to partial functions is that the distribution
D1 might not make sense, since it might assign a nonzero probability to some x for which
f (x, y) is undeﬁned.

10.4.1 Applications

106

In this subsection I apply Theorem 65 to prove lower bounds for two problems of Ambainis.
To facilitate further research and to investigate the scope of our method, I state the problems
in a more general way than Ambainis did. Given a group G, the coset problem Coset (G)
is deﬁned as follows. Alice is given a left coset C of a subgroup in G, and Bob is given
an element y
C and 0 otherwise. By restricting the
group G, we obtain many interesting and natural problems. For example, if p is prime
then Coset (Zp) is just the equality problem, so the protocol of Rabin and Yao [192] yields
Q1

G. Bob must output 1 if y

2 (Coset (Zp)) = Θ (log log p).

∈

∈

Theorem 66 Q1
2

Coset

Z2
p

= Θ (log p).

(cid:0)

(cid:0)

(cid:1)(cid:1)

Proof. The upper bound is obvious. For the lower bound, it suﬃces to consider
F2
p;

p and Bob is given

F2

a function fp deﬁned as follows. Alice is given
then

x, y
h

i ∈

a, b
h

i ∈

fp (x, y, a, b) =

(cid:26)

1 if y
0 otherwise.

≡

ax + b (mod p)

Let
over
F2

be the uniform distribution over
x, y
p; note that

such that y

B
h

i ∈
ax + b (mod p). Thus

a, b
h

≡

i

Aa,b be the uniform distribution
i ∈

F2
p, and let
D1 is the uniform distribution over
1
p

x, y

−

h

.

Pr
a,b
1,
h

x,y

h

i∈D

i∈B

[fp (x, y, a, b) = 0] = 1

But what about the distribution
drawing
Aa,b? Given a pair
and
are three cases regarding the probability of its being drawn from

D2, which is formed by ﬁrst drawing
x, y
h
D2:

independently from

z, w

x, y

h

i

h

i

(1)

x, y

=

i

h

h

z, w

i

(p2 pairs).

In this case

a, b
h
,
i

h

i ∈ B
z, w
i ∈

, and then
p, there

F2

Pr
2
D

[
h

x, y

,

z, w
h

i

i

] =

F2
p

a,b
Xh
i∈
1
p2 ·

(cid:18)

= p

Pr [
h

] Pr [
a, b
i

x, y
h

i

,

h

z, w

]
a, b
i

i | h

1
p2

(cid:19)

=

1
p3 .

(2) x

= z (p4

p3 pairs).
−
a∗x + b∗ (mod p) and w

In this case there exists a unique
a∗z + b∗ (mod p), so

a∗, b∗i

h

such that y

≡

≡

Pr
2
D

x, y
[
h

i

,

h

z, w

a∗, b∗
] = Pr [
h

i

=

1
p2 ·

1
p2 =

] Pr [
i
h
1
p4 .

x, y

,

i

h

z, w

a∗, b∗

i | h

]

i

(3) x = z but y

= w (p3

p2 pairs).

−

In this case Pr

D

x, y

2 [
h

,

i

h

z, w

i

] = 0.

6
6
Putting it all together,

107

2
D2 − D
1

=

(cid:13)
(cid:13)

=

(cid:13)
(cid:13)

p2

1
p3 −

1
2
1
p −

(cid:18)

(cid:12)
(cid:12)
1
(cid:12)
p2 .
(cid:12)

1
p4

(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

p4

p3

−

(cid:0)

(cid:1)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
p4 −

1
p4

+

p3

p2

−

(cid:0)

0
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:1)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1
p4

−

(cid:12)
(cid:19)
(cid:12)
(cid:12)
(cid:12)

So taking δ = 1/p
65.

1/p2, we have Q1
2

Coset

Z2
p

−

= Ω (log (1/δ)) = Ω (log p) by Theorem

(cid:1)(cid:1)
I now consider Ambainis’ second problem. Given a group G and nonempty set
/2, the subset problem Subset (G, S) is deﬁned as follows. Alice is

(cid:0)

(cid:0)

S
⊂
given x

G with

S
|

| ≤ |

G
|
G and Bob is given y
Let

∈

∈

be the distribution over st−

1

and independently from S. Then let ∆ =
over G.

M

G; then Bob must output 1 if xy

S and 0 otherwise.

∈
kM − D1k

G formed by drawing s and t uniformly
D1 is the uniform distribution

, where

∈

Proposition 67 For all G, S such that

S
|

/2,

G
|

| ≤ |
2 (Subset (G, S)) = Ω (log 1/∆) .

Q1

Proof. Let
distribution over x such that xy
that

B

be the uniform distribution over y

G, and let

S. Thus

∈

D1 is the uniform distribution over x

∈

Ay be the uniform
G; note
∈

Pr
1,y

∈D

x

∈B

[xy /
∈

S] = 1

1
2

.

≥

S
|
|
G
|
|

−

We have

2
D2 − D
1
(cid:13)
(cid:13)

(cid:13)
(cid:13)

=

=

=

=

=

}|

1

−

2

G
|
|

(cid:12)
(cid:12)
(cid:12)
(cid:12)

1

2
G
|

|

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

y
|{

∈

G, s, t

∈

S : xy = s, zy = t

1
2

s, t

(cid:12)
(cid:8)
(cid:12)
s, t

1
2

1
2

Xx,z
∈

G (cid:12)
(cid:12)
(cid:12)
(cid:12)
G (cid:12)
Xx,z
(cid:12)
∈
(cid:12)
(cid:12)
(cid:12)
G (cid:12)
(cid:12)
(cid:8)
Xx
(cid:12)
(cid:12)
∈
(cid:12)
(cid:12)
Pr
(cid:12)
G (cid:12)
M
Xx
(cid:12)
∈
(cid:12)
kM − D1k
(cid:12)

1
2

[x]

∈

|

S : xz−
2
S
|
S : x = st−
2
|

∈

−

S
|
1
G
|

| (cid:12)
(cid:12)
(cid:12)
(cid:12)

G
|

S

2
| |
|
1 = st−

1

1

−

(cid:9)(cid:12)
(cid:12)

(cid:9)(cid:12)
(cid:12)
1
G
|

−

| (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

= ∆.

Therefore log (1/δ) = Ω (log 1/∆).

Having lower-bounded Q1

2 (Subset (G, S)) in terms of 1/∆, it remains only to
upper-bound the variation distance ∆. The following proposition implies that for all
1/2+ε, then
constants ε > 0,
G
|
Q1

if S is chosen uniformly at random subject to
)) with constant probability over S.

S
|

=

|

|

G
2 (Subset (G, S)) = Ω (log (
|
|

Theorem 68 For all groups G and integers K
S
at random subject to
|

= K, then ∆ = O

|

∈ {
G
|
|

1, . . . ,
/K

, if S

G
|

|}

⊂

with Ω (1) probability over S.

Proof. We have

(cid:16)p

(cid:17)

108

G is chosen uniformly

∆ =

1
2

[x]

Pr
M

−

1
G
|

G (cid:12)
Xx
(cid:12)
∈
(cid:12)
(cid:12)
by the Cauchy-Schwarz inequality. We claim that

| (cid:12)
(cid:12)
(cid:12)
(cid:12)

≤ p

G
|
|
2 v
u
u
t

G (cid:18)

Xx
∈

[x]

Pr
M

−

|

2

1
G

| (cid:19)

EX
S "

[x]

Pr
M

−

1
G

2

c
K 2

# ≤

Xx
∈
for some constant c. From this it follows by Markov’s inequality that

|

G (cid:18)

| (cid:19)

Pr
S "

G (cid:18)

Xx
∈

[x]

Pr
M

−

2

1
G
|

| (cid:19)

2c
K 2

≥

# ≤

1
2

and hence

∆

G
|
|
2 r
≤ p

2c
K 2 = O

G
|
|
K !
  p

with probability at least 1/2.

Let us now prove the claim. We have

[x] = Pr
i,j

Pr
M

sis−

1
j = x
i

h

= Pr
i,j

[si = xsj] ,

where S =
So by linearity of expectation,

s1, . . . , sK}
{

and i, j are drawn uniformly and independently from

1, . . . , K
{

}

.

EX
S "

G (cid:18)

Xx
∈

[x]

Pr
M

−

2

1
G
|

| (cid:19)

= EX

S "

#

=

G
Xx
∈

where





2

[si = xsj]

Pr
i,j

G  (cid:18)
Xx
∈
K
1
K 4

Xi,j,k,l=1

(cid:19)

−

px,ijkl


2
G
|

|

Pr
i,j

−

[si = xsj] +

1
G
|
|

2

!#

2
G
|

| Xx
G
∈

K

Xi,j=1

1
K 2





px,ij


+

1
G
|
|

px,ij = Pr
S
px,ijkl = Pr
S

[si = xsj] ,

[si = xsj ∧

sk = xsl] .

First we analyze px,ij. Let ord (x) be the order of x in G. Of the K 2 possible
ordered pairs (i, j), there are K pairs with the “pattern” ii (meaning that i = j), and
If ord (x) = 1 (that is, x is the
K (K

1) pairs with the pattern ij (meaning that i

= j).

−

6
Pattern
iiii,iikk
ijij
ijji
iiil,iiki,ijii,ijjj
ijki,ijjk
iikl,ijkk,ijik,ijkj
ijkl

−
−

Number of such 4-tuples
K 2
K (K
K (K
4K (K
2K (K
4K (K
K (K

1)
1)
1)
−
1) (K
−
1) (K
−
1) (K

2)
−
2)
−
2) (K

ord (x) = 1
1
0
0
0
0
0
0

3)

−

−

−

109

ord (x) = 2
0
1

ord (x) > 2
0
1

1

1

|

|

|

G

|−
1

G
|−
0
0
0
1
1)(
|

(

G
|

(

G
|

3)

|−

|−

|−

(

G
|

|−

G

1

G
|−
0
0
1
1)(
|
0
1
1)(
|

G

G

2)

|−

3)

|−

Table 10.1: Expressions for px,ijkl

identity), then we have px,ij = PrS [si = sj], so px,ij = 1 under the pattern ii, and px,ij = 0
under the pattern ij. On the other hand, if ord (x) > 1, then px,ij = 0 under the pattern
ii, and px,ij = 1
G
|−
|

1 under the pattern ij. So

1
K 2

K

px,ij =

G
Xx
∈

Xi,j=1

1
K 2

(cid:18)

K + (
|

G

| −

1)

K (K
G
|

1)
−
1
| −

(cid:19)

= 1.

Though unnecessarily cumbersome, the above analysis was a warmup for the more
complicated case of px,ijkl. Table 10.1 lists the expressions for px,ijkl, given ord (x) and the
pattern of (i, j, k, l).

Let r be the number of x

G such that ord (x) = 2, and let r′ =

the number such that ord (x) > 2. Then

∈

G
|

| −

r

−

1 be

1
K 4

K

px,ijkl =

G
Xx
∈

Xi,j,k,l=1

1
K 4

1

K(K
K 2 + (2r + r′) K(K
1)
1 + 2r′
−
(
G
G
|−
|
2)(K
1)(K
+ (r + r′) K(K
−
−
3)
G
1)(
G
(
|
|

|−

|−

|

1)(K
−
G
1)(
|−
|
3)
−

2)
2)

−
|−

!

using the fact that K

G
|

≤ |

Putting it all together,

≤

G
|

| −

3

.

+ O

1
K 2

(cid:18)

(cid:19)

EX
S "

Xx
∈
and we are done.

G (cid:18)

[x]

Pr
M

−

|

2

1
G

| (cid:19)

1

# ≤

G
|

| −

3

+ O

1
K 2

(cid:18)

−

(cid:19)

2
G
|
|

+

1
G
|
|

= O

1
K 2

(cid:18)

(cid:19)

From ﬁngerprinting one also has the following upper bound. Let q be the period-

icity of S, deﬁned as the number of distinct sets gS =

gs : s

{

S

}

∈

where g

G.

∈

Proposition 69 R1

2 (Subset (G, S)) = O (log

+ log log q).

S

|

|

Proof. Assume for simplicity that q =

; otherwise we could reduce to a sub-
= q. The protocol is as follows: Alice draws a uniform random prime

G
|
|

group H

G with

H
|

|

≤

 
110

2 log2
|

S
|

p from the range
G
|
|
where x is interpreted as an integer. This takes O (log
1 if and only if there exists a z
protocol’s correctness, observe that if x

; she then sends Bob the pair (p, x mod p)
) bits. Bob outputs
G
|
|
z (mod p). To see the
primes p such that

S
|
S and x

G such that zy

G
|
i

+ log log

, 2

≡

∈

S

h

|

|

|

|

2 log2

0 (mod p), whereas the relevant range contains Ω
S, then by the union bound

(cid:16)

∈
G
= z, then there at most log
|
|
G
|
)
G
|

2 log2
S
|
|
|
log
S
log(
|
|

|

(cid:17)

primes. Therefore,

z
x
≡
−
if xy /
∈

z : zy

Pr
p

[
∃

∈

S, x

≡

z (mod p)] = O

log

S
|

|

G
|

|

(cid:18)

10.5 Open Problems

log
S
log (
|
|
2 log2
S
|
|

)

G
|
|
G
| (cid:19)
|

= o (1) .

2 (f ) and Q1

Are R1
2 (f ) polynomially related for every total Boolean function f ? Also, can
we exhibit any asymptotic separation between these measures? The best separation I know
of is a factor of 2: for the equality function we have R1
o (1)) log2 n, whereas
(1
Winter [243] has shown that Q1
(1/2 + o (1)) log2 n using a protocol involving mixed
states.12 This factor-2 savings is tight for equality: a simple counting argument shows that
Q1
o (1)) log2 n; and although the usual randomized protocol for equality
[192] uses (2 + o (1)) log2 n bits, there exist protocols based on error-correcting codes that
use only log2 (cn) = log2 n + O (1) bits. All of this holds for any constant error probability
0 < ε < 1/2.

2 (EQ)

2 (EQ)

2 (EQ)

(1/2

≥

−

−

≤

≥

Can we lower-bound Q1

2 (Coset (G)) for groups other than Z2

2 , or
2 (Subset (G, S)) for all sets S, closing the

p (such as Zn

nonabelian groups)? Also, can we characterize Q1
gap between the upper and lower bounds?

Is there an oracle relative to which BQP/poly
Can we give oracles relative to which NP

coNP and SZK are not contained in
BQP/qpoly? Even more ambitiously, can we prove a direct product theorem for quantum
query complexity that applies to any partial or total function (not just search)?

∩

For all f (partial or total), is R1

2 (f ) = O (√n) whenever Q1

2 (f ) = O (log n)? In

other words, is the separation of Bar-Yossef et al. [43] the best possible?

= BQP/qpoly?

Can the result D1 (f ) = O

mQ1

2 (f ) log Q1

2 (f )

for partial f be improved to

(cid:0)

D1 (f ) = O

mQ1

2 (f )

? I do not even know how to rule out D1 (f ) = O

m + Q1

2 (f )

.

(cid:0)

(cid:1)

In the Simultaneous Messages (SM) model, there is no direct communication be-
tween Alice and Bob; instead, Alice and Bob both send messages to a third party called the
referee, who then outputs the function value. The complexity measure is the sum of the two
message lengths. Let R||2 (f ) and Q||2 (f ) be the randomized and quantum bounded-error
(f ) be the randomized SM complexity if
SM complexities of f respectively, and let R||
2
Alice and Bob share an arbitrarily long random string. Building on work by Buhrman et
(f ) = O (1). He then
al. [75], Yao [250] showed that Q||2 (f ) = O (log n) whenever R||
2

,pub

,pub

(cid:0)

(cid:1)

(cid:1)

12If we restrict ourselves to pure states, then (1

previous version of this chapter claimed incorrectly that Q1

−

o (1)) log2 n qubits are needed. Based on that fact, a
o (1)) log2 n.

2 (EQ)

(1

≥

−

6
6
111

,pub

n1/2

ε

ε

−

−

(cid:1)

(cid:0)

,pub

n1

√n

(f ) = O

whenever
asked about the other direction: for some ε > 0, does R||
2
whenever Q||2 (f ) = O (log n)? In an earlier
Q||2 (f ) = O (log n), and does R||2 (f ) = O
(cid:0)
version of this chapter, I showed that R||2 (f ) = O
, which means
(f ) + log n
that a positive answer to Yao’s ﬁrst question would imply a positive answer to the second.
Later I learned that Yao independently proved the same result [249]. Here I ask a related
(f )? (Buhrman et al. [75]
question: can Q||2 (f ) ever be exponentially smaller than R||
2
showed that Q||2 (f ) can be exponentially smaller than R||2 (f ).)
Iordanis Kerenidis has
pointed out to me that, based on the hidden matching problem of Bar-Yossef et al. [43]
discussed in Section 10.1, one can deﬁne a relation for which Q||2 (f ) is exponentially smaller
than R||
2 (f ), it remains to extend that
2
result to functions.

(f ). However, as in the case of Q1

2 (f ) versus R1

R||
2

(cid:17)(cid:17)

,pub

,pub

(cid:16)

(cid:16)

(cid:1)

112

Chapter 11

Summary of Part I

From my unbiased perspective, quantum lower bounds are some of the deepest
results to have emerged from the study of quantum computing and information. These
results tell us that many problems we thought were intractable based on classical intuition,
really are intractable according to our best theory of the physical world. On the other hand,
the reasons for intractability are much more subtle than in the classical case. In some sense,
this has to be true—for otherwise the reasons would apply even to those problems for which
dramatic quantum speedups exist.

We currently have two methods for proving lower bounds on quantum query com-
plexity: the polynomial method of Beals et al. [45], and the adversary method of Ambainis
[27]. The preceding chapters have illustrated what, borrowing from Wigner [242], we might
call the “unreasonable eﬀectiveness” of these methods. Both continue to work far outside
of their original design specs—whether by proving classical lower bounds, lower bounds for
exponentially small success probabilities (as in the direct product theorem), or polynomial
lower bounds for quantities that have “no right” to be polynomials (as in the collision and
set comparison problems). Yet the two methods also have complementary limitations. The
adversary method is useless when the relevant probability gaps are small, or when every
0-input diﬀers from every 1-input in a constant fraction of locations. Likewise, the polyno-
mial method cannot be applied to problems that lack permutation symmetry, at least using
the techniques we currently know. Thus, perhaps the most important open problem in
quantum lower bounds is to develop a new method that overcomes the limitations of both
the polynomial and the adversary methods.1

In keeping with the theme of this thesis, I end Part I by listing some classical
intuitions about computing, that a hypothetical being from Conway’s Game of Life could
safely carry into the quantum universe.

•

The collision problem is not that much easier than unordered search. For despite
being extremely far from any one-to-one function, a random two-to-one function still
looks one-to-one unless we do an expensive search for collisions.

Finding a local minimum of a function is not that much easier than ﬁnding a global

•
1Along these lines, Barnum, Saks, and Szegedy [44] have given what in some sense is a provably optimal

method, but their method (based on semideﬁnite programming) seems too diﬃcult to apply directly.

113

minimum. This is because the paths leading to local minima could be exponentially
long.

•

•

•

•

If we want to distinguish an input X from the set of all Y such that f (Y )
= f (X),
then there is nothing much better to do than to query nonadaptively according to the
minimax strategy.

The diﬃculty of recursive Fourier sampling increases exponentially with the height of
the tree.

Given n unrelated instances of a problem, but only enough time to solve o (n) of them,
the probability of succeeding on all n instances decreases exponentially with n.

NP-complete problems are probably hard, even with the help of polynomial-size ad-
vice.

6
114

Part II

Models and Reality

115

LS: So you believe quantum mechanics?

Me: Of course I do!

LS: So a thousand years from now, people will still be doing quantum mechanics?

Me: Well. . . um. . . I guess so. . .

—Conversation between me and Lee Smolin

116

Chapter 12

Skepticism of Quantum Computing

“QC of the sort that factors long numbers seems ﬁrmly rooted in science ﬁction
. . . The present attitude would be analogous to, say, Maxwell selling the Daemon
of his famous thought experiment as a path to cheaper electricity from heat.”

—Leonid Levin [165]

Quantum computing presents a dilemma: is it reasonable to study a type of com-
puter that has never been built, and might never be built in one’s lifetime? Some researchers
strongly believe the answer is ‘no.’ Their objections generally fall into four categories:

(A) There is a fundamental physical reason why large quantum computers can never be

built.

(B) Even if (A) fails, large quantum computers will never be built in practice.

(C) Even if (A) and (B) fail, the speedup oﬀered by quantum computers is of limited

theoretical interest.

(D) Even if (A), (B), and (C) fail, the speedup is of limited practical value.1

The objections can be classiﬁed along two axes, as in Table 12.1.
This chapter focuses on objection (A), that quantum computing is impossible for
a fundamental physical reason. Among computer scientists, this objection is most closely

1Because of the ‘even if’ clauses, the objections seem to me logically independent, so that there are 16
possible positions regarding them (or 15 if one is against quantum computing).
I ignore the possibility that
no speedup exists, in other words that BPP = BQP. By ‘large quantum computer’ I mean any computer
much faster than its best classical simulation, as a result of asymptotic complexity rather than the speed of
elementary operations. Such a computer need not be universal; it might be specialized for (say) factoring.

Physical
Algorithmic

Theoretical Practical
(A)
(C)

(B)
(D)

Table 12.1: Four objections to quantum computing.

117

associated with Leonid Levin [165].2 The following passage captures much of the ﬂavor of
his critique:

The major problem [with quantum computing] is the requirement that basic
quantum equations hold to multi-hundredth if not millionth decimal positions
where the signiﬁcant digits of the relevant quantum amplitudes reside. We
have never seen a physical law valid to over a dozen decimals. Typically, every
few new decimal places require major rethinking of most basic concepts. Are
quantum amplitudes still complex numbers to such accuracies or do they become
quaternions, colored graphs, or sick-humored gremlins? [165]

Among other things, Levin argues that quantum computing is analogous to the
unit-cost arithmetic model, and should be rejected for essentially the same reasons; that
claims to the contrary rest on a confusion between metric and topological approximation;
that quantum fault-tolerance theorems depend on extravagant assumptions; and that even
if a quantum computer failed, we could not measure its state to prove a breakdown of
quantum mechanics, and thus would be unlikely to learn anything new.

A few responses to Levin’s arguments can be oﬀered immediately. First, even
1000.
classically, one can ﬂip a coin a thousand times to produce probabilities of order 2−
Should one dismiss such probabilities as unphysical? At the very least, it is not obvious
that amplitudes should behave diﬀerently than probabilities with respect to error—since
both evolve linearly, and neither is directly observable.

Second, if Levin believes that quantum mechanics will fail, but is agnostic about
what will replace it, then his argument can be turned around. How do we know that the
successor to quantum mechanics will limit us to BPP, rather than letting us solve (say)
PSPACE-complete problems? This is more than a logical point. Abrams and Lloyd [15]
argue that a wide class of nonlinear variants of the Schr¨odinger equation would allow NP-
complete and even #P-complete problems to be solved in polynomial time. And Penrose
[189], who proposed a model for ‘objective collapse’ of the wavefunction, believes that his
proposal takes us outside the set of computable functions entirely!

Third, to falsify quantum mechanics, it would suﬃce to show that a quantum
computer evolved to some state far from the state that quantum mechanics predicts. Mea-
suring the exact state is unnecessary. Nobel prizes have been awarded in the past ‘merely’
for falsifying a previously held theory, rather than replacing it by a new one. An example
is the physics Nobel awarded to Fitch [110] and Cronin [89] in 1980 for discovering CP
symmetry violation.

Perhaps the key to understanding Levin’s unease about quantum computing lies
in his remark that “we have never seen a physical law valid to over a dozen decimals.” Here
he touches on a serious epistemological question: How far should we extrapolate from today’s
experiments to where quantum mechanics has never been tested? I will try to address this
question by reviewing the evidence for quantum mechanics. For my purposes it will not

2More recently, Oded Goldreich [128] has also put forward an argument against quantum computing.
Compared to Levin’s arguments, Goldreich’s is easily understood: he believes that states arising in Shor’s
algorithm have exponential “non-degeneracy” and therefore take exponential time to prepare, and that there
is no burden on those who hold this view to suggest a deﬁnition of non-degeneracy.

118

suﬃce to declare the predictions of quantum mechanics “veriﬁed to one part in a trillion,”
interference,
because we have to distinguish at least three diﬀerent types of prediction:
entanglement, and Schr¨odinger cats. Let us consider these in turn.

(1) Interference.

If the diﬀerent paths that an electron could take in its orbit around a
nucleus did not interfere destructively, canceling each other out, then electrons would
not have quantized energy levels. So being accelerating electric charges, they would
lose energy and spiral into their respective nuclei, and all matter would disintegrate.
That this has not happened—together with the results of (for example) single-photon
double-slit experiments—is compelling evidence for the reality of quantum interfer-
ence.

(2) Entanglement. One might accept that a single particle’s position is described by a
wave in three-dimensional phase space, but deny that two particles are described by
a wave in six -dimensional phase space. However, the Bell inequality experiments of
Aspect et al. [37] and successors have convinced all but a few physicists that quantum
entanglement exists, can be maintained over large distances, and cannot be explained
by local hidden-variable theories.

(3) Schr¨odinger Cats. Accepting two- and three-particle entanglement is not the same
as accepting that whole molecules, cats, humans, and galaxies can be in coherent
superposition states. However, recently Arndt et al. [35] have performed the double-
slit interference experiment using C60 molecules (buckyballs) instead of photons; while
Friedman et al. [119] have found evidence that a superconducting current, consisting of
billions of electrons, can enter a coherent superposition of ﬂowing clockwise around a
coil and ﬂowing counterclockwise (see Leggett [164] for a survey of such experiments).
Though short of cats, these experiments at least allow us to say the following:
if
we could build a general-purpose quantum computer with as many components as
have already been placed into coherent superposition, then on certain problems, that
computer would outperform any computer in the world today.

Having reviewed some of the evidence for quantum mechanics, we must now ask
what alternatives have been proposed that might also explain the evidence. The simplest
alternatives are those in which quantum states “spontaneously collapse” with some proba-
bility, as in the GRW (Ghirardi-Rimini-Weber) theory [123].3 The drawbacks of the GRW
theory include violations of energy conservation, and parameters that must be ﬁne-tuned
to avoid conﬂicting with experiments. More relevant for us, though, is that the collapses
postulated by the theory are only in the position basis, so that quantum information stored
in internal degrees of freedom (such as spin) is unaﬀected. Furthermore, even if we ex-
tended the theory to collapse those internal degrees, large quantum computers could still
be built. For the theory predicts roughly one collapse per particle per 1015 seconds, with a
7-meter vicinity. So even in such a vicinity, one could
collapse aﬀecting everything in a 10−
perform a computation involving (say) 1010 particles for 105 seconds. Finally, as pointed

3Penrose [189] has proposed another such theory, but as mentioned earlier, his theory suggests that the

quantum computing model is too restrictive.

119

out to me by Rob Spekkens, standard quantum error-correction techniques might be used
to overcome even GRW-type decoherence.

A second class of alternatives includes those of ’t Hooft [227] and Wolfram [246],
in which something like a deterministic cellular automaton underlies quantum mechanics.
On the basis of his theory, ’t Hooft predicts that “[i]t will never be possible to construct a
‘quantum computer’ that can factor a large number faster, and within a smaller region of
space, than a classical machine would do, if the latter could be built out of parts at least
as large and as slow as the Planckian dimensions” [227]. Similarly, Wolfram states that
“[i]ndeed within the usual formalism [of quantum mechanics] one can construct quantum
computers that may be able to solve at least a few speciﬁc problems exponentially faster
than ordinary Turing machines. But particularly after my discoveries . . . I strongly suspect
that even if this is formally the case, it will still not turn out to be a true representation of
ultimate physical reality, but will instead just be found to reﬂect various idealizations made
in the models used so far” [246, p.771].

The obvious question then is how these theories account for Bell inequality viola-
tions.
I confess to being unable to understand ’t Hooft’s answer to this question, except
that he believes that the usual notions of causality and locality might no longer apply in
quantum gravity. As for Wolfram’s theory, which involves “long-range threads” to account
for Bell inequality violations, I will show in Section 12.1 below that it fails Wolfram’s own
desiderata of causal and relativistic invariance.

12.1 Bell Inequalities and Long-Range Threads

This section is excerpted from my review [1] of Stephen Wolfram’s A New Kind
of Science [246].

The most interesting chapter of A New Kind of Science is the ninth, on ‘Fun-
damental Physics.’ Here Wolfram confronts general relativity and quantum mechanics,
arguably the two most serious challenges to the deterministic, cellular-automaton-based
view of nature that he espouses. Wolfram conjectures that spacetime is discrete at the
43 seconds. This conjecture is not new, and
Planck scale, of about 10−
has received considerable attention recently in connection with the holographic principle
[65] from black hole thermodynamics, which Wolfram does not discuss. But are new ideas
oﬀered to substantiate the conjecture?

33 centimeters or 10−

For Wolfram, spacetime is a causal network, in which events are vertices and edges
specify the dependence relations between events. Pages 486–496 and 508–515 discuss in
detail how to generate such a network from a simple set of rules.
In particular, we could
start with a ﬁnite undirected ‘space graph’ G. We then posit a set of update rules, each of
which replaces a subgraph by another subgraph with the same number of outgoing edges.
The new subgraph must preserve any symmetries of the old one. Then each event in
the causal network corresponds to an application of an update rule.
If updating event B
becomes possible as a result of event A, then we draw an edge from A to B.

Properties of space are deﬁned in terms of G. For example, if the number of
vertices in G at distance at most n from any given vertex grows as nD, then space can be

120

said to have dimension D. (As for formalizing this deﬁnition, Wolfram says only that there
are “some subtleties. For example, to ﬁnd a deﬁnite volume growth rate one does still need
to take some kind of limit—and one needs to avoid sampling too many or too few” vertices
(p. 1030).) Similarly, Wolfram argues that the curvature information needed for general
relativity, in particular the Ricci tensor, can be read from the connectivity pattern of G.
Interestingly, to make the model as simple as possible, Wolfram does not associate a bit to
each vertex of G, representing (say) the presence or absence of a particle.
Instead particles
are localized structures, or ‘tangles,’ in G.

An immediate problem is that one might obtain many nonequivalent causal net-
works, depending on the order in which update rules are applied to G. Wolfram calls a set
of rules that allows such nondeterministic evolution a ‘multiway system.’ He recognizes,
but rejects, a possible connection to quantum mechanics:

The notion of ‘many-ﬁgured time’ has been discussed since the 1950s in the con-
text of the many-worlds interpretation of quantum mechanics. There are some
similarities to the multiway systems that I consider here. But an important
diﬀerence is that while in the many-worlds approach, branchings are associated
with possible observation or measurement events, what I suggest here is that
they could be an intrinsic feature of even the very lowest-level rules for the
universe (p. 1035-6).

It is unclear exactly what distinction is being drawn: is there any physical event
that is not associated with a possible observation or measurement? In any case, Wolfram
opts instead for rule sets that are ‘causal invariant’: that is, that yield the same causal
network regardless of the order in which rules are applied. As noted by Wolfram, a
suﬃcient (though not necessary) condition for causal invariance is that no ‘replaceable’
subgraph overlaps itself or any other replaceable subgraph.

Wolfram points out an immediate analogy to special relativity, wherein observers
do not in general agree on the order in which spacelike separated events occur, yet agree
on any ﬁnal outcome of the events. He is vague, though, about how (say) the Lorentz
transformations might be derived in a causal network model:

There are many subtleties here, and indeed to explain the details of what is
going on will no doubt require quite a few new and rather abstract concepts.
But the general picture that I believe will emerge is that when particles move
faster they will appear to have more nodes associated with them (p. 529).

Wolfram is “certainly aware that many physicists will want to know more details,”
he says in the endnotes, about how a discrete model of the sort he proposes can reproduce
known features of physics. But, although he chose to omit technical formalism from the
presentation, “[g]iven my own personal background in theoretical physics it will come as no
surprise that I have often used such formalism in the process of working out what I describe
in these sections” (p. 1043). The paradox is obvious:
if technical formalism would help
convince physicists of his ideas, then what could Wolfram lose by including it, say in the
endnotes? If, on the other hand, such formalism is irrelevant, then why does Wolfram even
mention having used it?

121

Physicists’ hunger for details will likely grow further when they read the section on
‘Quantum Phenomena’ (p. 537–545). Here Wolfram maintains that quantum mechanics
is only an approximation to an underlying classical (and most likely deterministic) theory.
Many physicists have sought such a theory, from Einstein to (in modern times) ’t Hooft
[227]. But a series of results, beginning in the 1960’s, has made it clear that such a theory
I will argue that, although Wolfram discusses these results, he has not
comes at a price.
understood what they actually entail.

To begin, Wolfram is not advocating a hidden-variable approach such as Bohmian
mechanics, in which the state vector is supplemented by an ‘actual’ eigenstate of a particular
observable.
Instead he thinks that, at the lowest level, the state vector is not needed at all;
it is merely a useful construct for describing some (though presumably not all) higher-level
phenomena.
Indeterminacy arises because of one’s inability to know the exact state of a
system:

[I]f one knew all of the underlying details of the network that makes up our
universe, it should always be possible to work out the result of any measurement.
I strongly believe that the initial conditions for the universe were quite simple.
But like many of the processes we have seen in this book, the evolution of the
universe no doubt intrinsically generates apparent randomness. And the result
is that most aspects of the network that represents the current state of our
universe will seem essentially random (p. 543).

Similarly, Wolfram explains as follows why an electron has wave properties: “. . . a
network which represents our whole universe must also include us as observers. And this
means that there is no way that we can look at the network from the outside and see the
electron as a deﬁnite object” (p. 538). An obvious question then is how Wolfram accounts
for the possibility of quantum computing, assuming BPP
= BQP. He gives an answer in
the ﬁnal chapter:

Indeed within the usual formalism [of quantum mechanics] one can construct
quantum computers that may be able to solve at least a few speciﬁc problems
exponentially faster than ordinary Turing machines. But particularly after my
discoveries in Chapter 9 [‘Fundamental Physics’], I strongly suspect that even
if this is formally the case, it will still not turn out to be a true representation
of ultimate physical reality, but will instead just be found to reﬂect various
idealizations made in the models used so far (p. 771).

In the endnotes, though, where he explains quantum computing in more detail,

Wolfram seems to hedge about which idealizations he has in mind:

It does appear that only modest precision is needed for the initial amplitudes.
And it seems that perturbations from the environment can be overcome using
versions of error-correcting codes. But it remains unclear just what might be
needed actually to perform for example the ﬁnal measurements required (p.
1148).

6
122

One might respond that, with or without quantum computing, Wolfram’s propos-
als can be ruled out on the simpler ground that they disallow Bell inequality violations.
However, Wolfram puts forward an imaginative hypothesis to account for bipartite entan-
glement. When two particles (or ‘tangles’ in the graph G) collide, long-range ‘threads’ may
form between them, which remain in place even if the particles are later separated:

The picture that emerges is then of a background containing a very large num-
ber of connections that maintain an approximation to three-dimensional space,
together with a few threads that in eﬀect go outside of that space to make direct
connections between particles (p. 544).

The threads can produce Bell correlations, but are somehow too small (i.e. contain

too few edges) to transmit information in a way that violates causality.

There are several objections one could raise against this thread hypothesis. What
I will show is that, if one accepts two of Wolfram’s own desiderata—determinism and causal
invariance—then the hypothesis fails. First, though, let me remark that Wolfram says little
about what, to me, is a more natural possibility than the thread hypothesis. This is an
explicitly quantum cellular automaton or causal network, with a unitary transition rule.
The reason seems to be that he does not want continuity anywhere in a model, not even
in probabilities or amplitudes.
In the notes, he describes an experiment with a quantum
cellular automaton as follows:

One might hope to be able to get an ordinary cellular automaton with a limited
set of possible values by choosing a suitable [phase rotation] θ [θ = π/4 and
θ = π/3 are given as examples in an illustration]. But in fact in non-trivial
cases most of the cells generated at each step end up having distinct values (p.
1060).

This observation is unsurprising, given the quantum computing results mentioned
in Chapter 4, to the eﬀect that almost any nontrivial gate set is universal (that is, can
approximate any unitary matrix to any desired precision, or any orthogonal matrix in case
Indeed, Shi [217] has shown that a Toﬀoli gate, plus any gate that
one is limited to reals).
does not preserve the computational basis, or a controlled-NOT gate plus any gate whose
square does not preserve the computational basis, are both universal gate sets.
In any
case, Wolfram does not address the fact that continuity in amplitudes seems more ‘benign’
than continuity in measurable quantities: the former, unlike the latter, does not enable an
inﬁnite amount of computation to be performed in a ﬁnite time. Also, as observed by
Bernstein and Vazirani [55], the linearity of quantum mechanics implies that tiny errors in
amplitudes will not be magniﬁed during a quantum computation.

I now proceed to the argument that Wolfram’s thread hypothesis is inconsistent
with causal invariance and relativity.
be a set of graph updating rules, which
might be probabilistic. Then consider the following four assertions (which, though not
mathematically precise, will be clariﬁed by subsequent discussion).

Let

R

(1)

satisﬁes causal invariance. That is, given any initial graph (and choice of random-
yields a unique causal network.

is probabilistic),

R
ness if

R

R

(2)

satisﬁes the relativity postulate. That is, assuming the causal network approx-
R
imates a ﬂat Minkowski spacetime at a large enough scale, there are no preferred
inertial frames.

(3)

R

permits Bell inequality violations.

123

(4) Any updating rule in

is always considered to act on a ﬁxed graph, not on a distri-
bution or superposition over graphs. This is true even if parts of the initial graph
are chosen at random, and even if

is probabilistic.

R

R

R

The goal is to show that, for any

, at least one of these assertions is false. Current
physical theory would suggest that (1)-(3) are true and that (4) is false. Wolfram, if I
understand him correctly, starts with (4) as a premise, and then introduces causal invariance
to satisfy (1) and (2), and long-range threads to satisfy (3). Of course, even to state the
two-party Bell inequalities requires some notion of randomness. And on pages 299–326,
Wolfram discusses three mechanisms for introducing randomness into a system: randomness
in initial conditions, randomness from the environment (i.e. probabilistic updating rules),
and intrinsic randomness (i.e. deterministic rules that produce pseudorandom output).
However, all of these mechanisms are compatible with (4), and so my argument will show
that they are inadequate assuming (1)-(3). The conclusion is that, in a model of the sort
Wolfram considers, randomness must play a more fundamental role than he allows.

(cid:1)

≈

0.802.

yB = xA ∧

In a standard Bell experiment, Alice and Bob are given input bits xA and xB
respectively, chosen uniformly and independently at random. Their goal is, without com-
xB. Under
municating, to output bits yA and yB respectively such that yA ⊕
any ‘local hidden variable’ theory, Alice and Bob can succeed with probability at most 3/4;
the optimal strategy is for them to ignore their inputs and output (say) yA = 0 and yB = 0.
However, suppose Alice has a qubit ρA and Bob a ρB, that are jointly in the Bell state
) /√2. Then there is a protocol4 by which they can succeed with probability
11
+
00
(
i
|
|
i
5 + √2
/8
To model this situation, let A and B, corresponding to Alice and Bob, be disjoint
(cid:0)
subgraphs of a graph G.
Suppose that, at a large scale, G approximates a Euclidean
space of some dimension; and that any causal network obtained by applying updates to
G approximates a Minkowski spacetime. One can think of G as containing long-range
threads from A to B, though the nature of the threads will not aﬀect the conclusions.
Encode Alice’s input xA by (say) placing an edge between two speciﬁc vertices in A if and
only if xA = 1. Encode xB similarly, and also supply Alice and Bob with arbitrarily
many correlated random bits. Finally, let us stipulate that at the end of the protocol,
there is an edge between two speciﬁc vertices in A if and only if yA = 1, and similarly for
yB. A technicality is that we need to be able to identify which vertices correspond to xA,
yA, and so on, even as G evolves over time. We could do this by stipulating that (say)
“the xA vertices are the ones that are roots of complete binary trees of depth 3,” and then
choosing the rule set to guarantee that, throughout the protocol, exactly two vertices have
this property.

4If xA = 1 then Alice applies a π/8 phase rotation to ρA, and if xB = 1 then Bob applies a
to ρB. Both parties then measure in the standard basis and output whatever they observe.

−

π/8 rotation

124

Call a variable ‘touched’ after an update has been applied to a subgraph containing
any of the variable’s vertices. Also, let Z be an assignment to all random variables: that
is, xA, xB, the correlated random bits, and the choice of randomness if
is probabilistic.
Then for all Z we need the following, based on what observers in diﬀerent inertial frames
could perceive:

R

(i) There exists a sequence of updates under which yA is output before any of Bob’s

variables are touched.

(ii) There exists another sequence under which yB is output before any of Alice’s variables

are touched.

Now it is easy to see that, if a Bell inequality violation occurs, then causal invari-
ance must be violated. Given Z, let y(1)
B (Z) be the values of yA, yB that are output
under rule sequence (i), and let y(2)
B (Z) be the values output under sequence (ii).
Then there must exist some Z for which either y(1)
B (Z)—for
It
if not, then the entire protocol could be simulated under a local hidden variable model.
follows that the outcome of the protocol can depend on the order in which updates are
applied.

A (Z) or y(1)

A (Z), y(2)

A (Z), y(1)

B (Z)

A (Z)

= y(2)

= y(2)

To obtain a Bell inequality violation, something like the following seems to be
needed. We can encode ‘hidden variables’ into G, representing the outcomes of the possible
measurements Bob could make on ρB.
(We can imagine, if we like, that the update rules
are such that observing any one of these variables destroys all the others. Also, we make no
assumption of contextuality.) Then, after Alice measures ρA, using the long-range threads
she updates Bob’s hidden variables conditioned on her measurement outcome. Similarly,
Bob updates Alice’s hidden variables conditioned on his outcome. Since at least one party
must access its hidden variables for there to be Bell inequality violations, causal invariance
is still violated. But a sort of probabilistic causal invariance holds, in the sense that if
we marginalize out A (the ‘Alice’ part of G), then the distribution of values for each of
Bob’s hidden variables is the same before and after Alice’s update. The lesson is that, if
we want both causal invariance and Bell inequality violations, then we need to introduce
probabilities at a fundamental level—not merely to represent Alice and Bob’s subjective
uncertainty about the state of G, but even to deﬁne whether a set of rules is or is not causal
invariant.

Note that I made no assumption about how the random bits were generated—i.e.
whether they were ‘truly random’ or were the pseudorandom output of some updating rule.
The conclusion is also unaﬀected if we consider a ‘deterministic’ variant of Bell’s theorem due
to Greenberger, Horne, and Zeilinger [136]. There three parties, Alice, Bob, and Charlie, are
xC = 0.
given input bits xA, xB, and xC respectively, satisfying the promise that xA ⊕
xC.
xB ∨
The goal is to output bits yA, yB, and yC such that yA ⊕
Under a local hidden variable model, there is no protocol that succeeds on all four possible
inputs; but if the parties share the GHZ state (
) /2, then such
+
a protocol exists. However, although the output is correct with certainty, assuming causal
invariance one cannot implement the protocol without introducing randomness into the
underlying rules, exactly as in the two-party case.

yC = xA ∨
000
i

yB ⊕
110
|

xB ⊕

101
i
|

011
i
|

i − |

+

6
6
125

After a version of the above argument was sent to Wolfram, Todd Rowland, an
employee of Wolfram, sent me email claiming that the argument fails for the following
reason.
I assumed that there exist two sequences of updating events, one in which Alice’s
measurement precedes Bob’s and one in which Bob’s precedes Alice’s. But I neglected
the possibility that a single update, call it E, is applied to a subgraph that straddles the
long-range threads. The event E would encompass both Alice and Bob’s measurements, so
that neither would precede the other in any sequence of updates. We could thereby obtain
a rule set

satisfying assertions (1), (3), and (4).

R
I argue that such an

R

would nevertheless fail to satisfy (2). For in eﬀect we start
with a ﬂat Minkowski spacetime, and then take two distinct events that are simultaneous
in a particular inertial frame, and identify them as being the same event E. This can be
visualized as ‘pinching together’ two horizontally separated points on a spacetime diagram.
(Actually a whole ‘V’ of points must be pinched together, since otherwise entanglement
could not have been created.) However, what happens in a diﬀerent inertial frame?
It
would seem that E, a single event, is perceived to occur at two separate times. That by
itself might be thought acceptable, but it implies that there exists a class of preferred inertial
frames: those in which E is perceived to occur only once. Of course, even in a ﬂat spacetime,
one could designate as ‘preferred’ those frames in which Alice and Bob’s measurements are
perceived to be simultaneous. A crucial distinction, though, is that there one only obtains
a class of preferred frames after deciding which event at Alice’s location, and which at Bob’s
location, should count as the ‘measurement.’ Under Rowland’s hypothesis, by contrast,
once one decides what counts as the measurement at Alice’s location, the decision at Bob’s
location is made automatically, because of the identiﬁcation of events that would otherwise
be far apart.

126

Chapter 13

Complexity Theory of Quantum
States

In my view, the central weakness in the arguments of quantum computing skeptics
is their failure to suggest any answer the following question: Exactly what property separates
the quantum states we are sure we can create, from the states that suﬃce for Shor’s factoring
algorithm?

⊗

⊗

1
i
|

0
i
|

n + β

n and (α

I call such a property a “Sure/Shor separator.” The purpose of this chapter is
to develop a mathematical theory of Sure/Shor separators, and thereby illustrate what I
think a scientiﬁc discussion about the possibility of quantum computing might look like.
n
In particular, I will introduce tree states, which informally are those states
expressible by a polynomial-size ‘tree’ of addition and tensor product gates. For example,
α
Section 13.1 provides the
philosophical motivation for thinking of tree states as a possible Sure/Shor separator; then
Section 13.2 formally deﬁnes tree states and many related classes of quantum states. Next,
Section 13.3 investigates basic properties of tree states. Among other results, it shows
that any tree state is representable by a tree of polynomial size and logarithmic depth; and
that most states do not even have large inner product with any tree state. Then Section
13.4 shows relationships among tree size, circuit size, bounded-depth tree size, Vidal’s χ
complexity [236], and several other measures. It also relates questions about quantum state
classes to more traditional questions about computational complexity classes.

n are both tree states.

i ∈ H

0
i
|

1
i
|

ψ
|

+ β

)⊗

⊗
2

≤

Zn

But the main results of the chapter, proved in Section 13.5, are lower bounds
on tree size for various natural families of quantum states.
In particular, Section 13.5.1
analyzes “subgroup states,” which are uniform superpositions
over all elements of a
subgroup S
2 . The importance of these states arises from their central role in sta-
bilizer codes, a type of quantum error-correcting code.
I ﬁrst show that if S is chosen
cannot be represented by any tree of
uniformly at random, then with high probability
size no(log n). This result has a corollary of independent complexity-theoretic interest: the
ﬁrst superpolynomial gap between the formula size and the multilinear formula size of a
R. I then present two improvements of the basic lower bound. First,
function f :
I show that a random subgroup state cannot even be approximated well in trace distance by
any tree of size no(log n). Second, I “derandomize” the lower bound, by using Reed-Solomon

0, 1
}

S
|

S
|

→

{

i

i

n

127

codes to construct an explicit subgroup state with tree size nΩ(log n).

Section 13.5.2 analyzes the states that arise in Shor’s factoring algorithm—for
example, a uniform superposition over all multiples of a ﬁxed positive integer p, written in
binary. Originally, I had hoped to show a superpolynomial tree size lower bound for these
states as well. However, I am only able to show such a bound assuming a number-theoretic
conjecture.

The lower bounds use a sophisticated recent technique of Raz [195, 196], which was
introduced to show that the permanent and determinant of a matrix require superpolynomial-
size multilinear formulas. Currently, Raz’s technique is only able to show lower bounds of
the form nΩ(log n), but I conjecture that 2Ω(n) lower bounds hold in all of the cases discussed
above.

One might wonder how superpolynomial tree size relates to more physical proper-
ties of a quantum state. Section 13.5.3 addresses this question, by pointing out how Raz’s
lower bound technique is connected to a notion that physicists call “persistence of entan-
glement” [71, 100]. On the other hand, I also give examples showing that the connection
is not exact.

Section 13.6 studies a weakening of tree size called “manifestly orthogonal tree
size,” and shows that this measure can sometimes be characterized exactly, enabling us to
prove exponential lower bounds. The techniques in Section 13.6 might be of independent
interest to complexity theorists—one reason being that they do not obviously “naturalize”
in the sense of Razborov and Rudich [200].

Section 13.7 addresses the following question.

If the state of a quantum computer
at every time step is a tree state, then can the computer be simulated classically?
In
other words, letting TreeBQP be the class of languages accepted by such a machine, does
TreeBQP = BPP? A positive answer would make tree states more attractive as a Sure/Shor
separator. For once we admit any states incompatible with the polynomial-time Church-
Turing thesis, it seems like we might as well go all the way, and admit all states preparable
by polynomial-size quantum circuits! Although I leave this question open, I do show that
ΠP
ΠP
3 is the third level of the polynomial hierarchy PH. By
TreeBQP
PH, though admittedly not on strong evidence.
contrast, it is conjectured that BQP

3 , where ΣP

3 ∩

3 ∩

ΣP

⊆

Section 13.8 discusses the implications of these results for experimental physics.
It advocates a dialectic between theory and experiment, in which theorists would propose
a class of quantum states that encompasses everything seen so far, and then experimenters
would try to prepare states not in that class.
It also asks whether states with superpolyno-
mial tree size have already been observed in condensed-matter systems; and more broadly,
what sort of evidence is needed to establish a state’s existence. Other issues addressed in
Section 13.8 include how to deal with mixed states and particle position and momentum
states, and the experimental relevance of asymptotic bounds.
I conclude in Section 13.9
with some open problems.

6⊂

13.1 Sure/Shor Separators

Given the discussion in Chapter 12, I believe that the challenge for quantum computing
Ideally, come up with an alternative to quantum mechanics—even an
skeptics is clear.

128

Shor States (suffice for 
nontrivial factoring)

Allowed by GRW theory

Sure States (already 
demonstrated)

Allowed by local hidden 
variable theories

Figure 13.1: A Sure/Shor separator must contain all Sure states but no Shor states. That
is why neither local hidden variables nor the GRW theory yields a Sure/Shor separator.

idealized toy theory—that can account for all present-day experiments, yet would not al-
low large-scale quantum computation. Failing that, at least say what you take quantum
mechanics’ domain of validity to be. One way to do this would be to propose a set S of
quantum states that you believe corresponds to possible physical states of aﬀairs.1 The
set S must contain all “Sure states” (informally, the states that have already been demon-
strated in the lab), but no “Shor states” (again informally, the states that can be shown to
suﬃce for factoring, say, 500-digit numbers).
If S satisﬁes both of these constraints, then
I call S a Sure/Shor separator (see Figure 13.1).

) is at most, say, n2, then I predict that

Of course, an alternative theory need not involve a sharp cutoﬀ between possible
and impossible states. So it is perfectly acceptable for a skeptic to deﬁne a “complexity
If
) for quantum states, and then say something like the following:
measure” C (
ψni
ψ
|
i
|
is a state of n spins, and C (
can be
ψni
ψni
|
|
will be governed by
prepared using only “polynomial eﬀort.” Also, once prepared,
standard quantum mechanics to extremely high precision. All states created to date have
) grows as, say, 2n, then I predict that
had small values of C (
ψni
). However, if C (
|
requires “exponential eﬀort” to prepare, or else is not even approximately governed by
ψni
|
quantum mechanics, or else does not even make sense in the context of an alternative theory.
). So
ψni
The states that arise in Shor’s factoring algorithm have exponential values of C (
|
as my Sure/Shor separator, I propose the set of all inﬁnite families of states
1,
ψni}n
{|
)
ψni
where

has n qubits, such that C (
ψni
|
|
To understand the importance of Sure/Shor separators,

it is helpful to think
through some examples. A major theme of Levin’s arguments was that exponentially
small amplitudes are somehow unphysical. However, clearly we cannot reject all states
10000 is
with tiny amplitudes—for would anyone dispute that the state 2−

p (n) for some polynomial p.

ψni
|

ψni
|

≤

≥

5000 (
0
i
|
S is acted on by a unitary U such that

)⊗
1
i

+

|

1A skeptic might also specify what happens if a state
ψ
|

S, but this will not be insisted upon.

/
∈

i

U

ψ

|

i ∈

+

1

1-

129

+

1
2

1
2

+

1
2

1
2

|1〉1

|1〉2

|0〉1

|1〉1

|0〉2

|1〉2

Figure 13.2: Expressing (
) /2 by a tree of linear combination and
i − |
|
tensor product gates, with scalar multiplication along edges. Subscripts denote the identity
of a qubit.

01
i
|

11
i

00
i

10
|

+

+

as Sure states, we are almost forced to accept

formed whenever 10, 000 photons are each polarized at 45◦? Indeed, once we accept
and
ine, if we like, that
|
a Shor state such as

ψ
i
|
as well—since we can imag-
ϕ
i
are prepared in two separate laboratories.2 So considering

ϕ
i
|

ϕ
i

i ⊗ |

and

ψ
|

ψ

i

|

=

Φ
|

i

1
2n/2

2n

1

−

r=0
X

r

|

xr mod N

i |

,

i

what property of this state could quantum computing skeptics latch onto as being physically
involves entanglement across hundreds or
Φ
extravagant? They might complain that
|
thousands of particles; but as mentioned in Chapter 12, there are other states with that
/√2, that should be regarded
same property, namely the “Schr¨odinger cats”
as Sure states. Alternatively, the skeptics might object to the combination of exponentially
small amplitudes with entanglement across hundreds of particles. However, simply viewing
a Schr¨odinger cat state in the Hadamard basis produces an equal superposition over all
strings of even parity, which has both properties. We seem to be on a slippery slope
leading to all of quantum mechanics!

Is there any defensible place to draw a line?

0
i
|
(cid:0)

1
⊗
i

n +

(cid:1)

⊗

i

n

|

i

+ β

ψ
|

and

ϕ
i

The dilemma above is what led me to propose tree states as a possible Sure/Shor
separator. The idea, which might seem more natural to logicians than to physicists, is this.
Once we accept the linear combination and tensor product rules of quantum mechanics—
S—
allowing α
one of our few remaining hopes for keeping S a proper subset of the set of all states is to
impose some restriction on how those two rules can be iteratively applied.
In particular,
under a polynomial number of linear combinations
we could let S be the closure of
1
i}
|
and tensor products. That is, S is the set of all inﬁnite families of states
1 with
can be expressed as a “tree” involving at most p (n) addition,
ψni ∈ H
|
gates for some polynomial p (see Figure 13.2).
tensor product,

into our set S of possible states whenever

ψni}n
{|

0
i
{|

ϕ
i

i ⊗ |

ϕ
|

i ∈

ψ

ψ

≥

i

n

,

|

,

|

|

ψni
2 , such that
⊗
|
1
, and
i
|

0
i
|

2It might be objected that in some theories, such as Chern-Simons theory, there is no clear tensor product
ϕ
i
|

decomposition. However, the relevant question is whether
are both Sure states that are well-described in tensor product Hilbert spaces.

is a Sure state, given that

i ⊗ |

ϕ
i

and

ψ
|

ψ

i

|

˜
˜
130

|

ψ

+ β

To be clear, I am not advocating that “all states in Nature are tree states” as a
Indeed, even if I believed ﬁrmly in a breakdown of quantum
serious physical hypothesis.
mechanics,3 there are other choices for the set S that seem equally reasonable. For example,
deﬁne orthogonal tree states similarly to tree states, except that we can only form the linear
combination α
= 0. Rather than choose among tree states, orthogonal
tree states, and the other candidate Sure/Shor separators that occurred to me, my approach
will be to prove everything I can about all of them.
If I devote more space to tree states
than to others, that is simply because tree states are the subject of the most interesting
is not a tree state,
results. On the other hand, if one shows (for example) that
{|
then one has also shown that
is not an orthogonal tree state. So many candidate
separators are related to each other; and indeed, their relationships will be a major theme
of the chapter.

ψni}
{|

ψni}

ϕ
i
|

ϕ
i
|

ψ
h

if

i

In summary, to debate whether quantum computing is fundamentally impossible,
we need at least one proposal for how it could be impossible. Since even skeptics admit that
quantum mechanics is valid within some “regime,” a key challenge for any such proposal is to
separate the regime of acknowledged validity from the quantum computing regime. Though
others will disagree, I do not see any choice but to identify those two regimes with classes
of quantum states. For gates and measurements that suﬃce for quantum computing have
already been demonstrated experimentally. Thus, if we tried to identify the two regimes
with classes of gates or measurements, then we could equally well talk about the class of
states on which all 1- and 2-qubit operations behave as expected. A similar argument
would apply if we identiﬁed the two regimes with classes of quantum circuits—since any
“memory” that a quantum system retains of the previous gates in a circuit, is part of the
system’s state by deﬁnition. So: states, gates, measurements, circuits—what else is there?
I should stress that none of the above depends on the interpretation of quantum
mechanics.
In particular, it is irrelevant whether we regard quantum states as “really out
there” or as representing subjective knowledge—since in either case, the question is whether
there can exist systems that we would describe by

based on their observed behavior.

Once we agree to seek a Sure/Shor separator, we quickly ﬁnd that the obvious
ideas—based on precision in amplitudes, or entanglement across of hundreds of particles—
are nonstarters. The only idea that seems plausible is to limit the class of allowed quantum
states to those with some kind of succinct representation. That still leaves numerous
possibilities; and for each one, it might be a diﬃcult problem to decide whether a given
is succinctly representable or not. Thus, constructing a useful theory of Sure/Shor
ψ
|
separators is a nontrivial task. This chapter represents a ﬁrst attempt.

i

ψ
|

i

13.2 Classifying Quantum States

In both quantum and classical complexity theory, the objects studied are usually sets of
languages or Boolean functions. However, a generic n-qubit quantum state requires ex-
ponentially many classical bits to describe, and this suggests looking at the complexity of
quantum states themselves. That is, which states have polynomial-size classical descrip-
tions of various kinds? This question has been studied from several angles by Aharonov

3which I don’t

131

Y P

OTree

MOTree

Circuit

Vidal

AmpP

Tree

TSH

¸

¸

¸

2

1

2

1

Strict containment
Containment
Non-containment

Classical

Figure 13.3: Known relations among quantum state classes.

n

n

≥

}

{|

{|

1.

: x

∈ {

∈ {

x
i

0, 1
}

0, 1
}

ψni}n

2 with the ﬁxed orthogonal basis
⊗

and Ta-Shma [23]; Janzing, Wocjan, and Beth [148]; Vidal [236]; and Green et al. [134].
Here I propose a general framework for the question. For simplicity, I limit myself to pure
states
. Also, by ‘states’ I
mean inﬁnite families of states

ψni ∈ H
|
Like complexity classes, pure quantum states can be organized into a hierarchy
for
x
(see Figure 13.3). At the bottom are the classical basis states, which have the form
i
|
n. We can generalize classical states in two directions: to the class
1 of
some x
⊗
); and to the
0
(αn |
1
+ βn |
1
+ β1 |
separable states, which have the form (α1 |
i
i
i
class Σ1, which consists of all states
that are superpositions of at most p (n) classical
states, where p is a polynomial. At the next level,
2 contains the states that can be
written as a tensor product of Σ1 states, with qubits permuted arbitrarily. Likewise, Σ2
contains the states that can be written as a linear combination of a polynomial number of
3, etc. Containing the whole ‘tensor-sum
⊗
k is the class Tree, of all states expressible by a polynomial-size tree
hierarchy’
of additions and tensor products nested arbitrarily. Formally, Tree consists of all states
) is
ψni
|
deﬁned as follows.

ψni
p (n) for some polynomial p, where the tree size TS (
|

⊗
ψni
such that TS (
|

1 states. We can continue indeﬁnitely to Σ3,

⊗ · · · ⊗

ψni
|

kΣk =

0
i

⊗

≤

⊗

∪

∪

)

)

k

Deﬁnition 70 A quantum state tree over
labeled with α
1
i
|
labeled with either + or
⊗
that

0
i
|

+ β

∈

for some α, β
. Each vertex v is also labeled with a set S (v)

is a rooted tree where each leaf vertex is
H
C, and each non-leaf vertex (called a gate) is
, such

1, . . . , n

⊗
2

⊆ {

}

n

(i) If v is a leaf then

S (v)
|

|

= 1,

(ii) If v is the root then S (v) =

1, . . . , n

,
}

{

˜
˜
S
S
¸
(iii) If v is a + gate and w is a child of v, then S (w) = S (v),

132

(iv) If v is a

gate and w1, . . . , wk are the children of v, then S (w1) , . . . , S (wk) are

pairwise disjoint and form a partition of S (v).

⊗

Finally, if v is a + gate, then the outgoing edges of v are labeled with complex
numbers. For each v, the subtree rooted at v represents a quantum state of the qubits in
S (v) in the obvious way. We require this state to be normalized for each v.4

We say a tree is orthogonal

if it satisﬁes the further condition that if v is a +
If the
with
ψ2i
gate, then any two children w1, w2 of v represent
|
,
x
condition
ψ1|
i
|
h
either
= 0, then we say the tree is manifestly orthogonal. Manifest
x
ψ1|
x
ψ2|
i
i
h
orthogonality is an extremely unphysical deﬁnition; I introduce it because it turns out to
be interesting from a lower bounds perspective.

ψ1i
|
= 0 can be replaced by the stronger condition that for all basis states

ψ2i
= 0 or

ψ2i

ψ1|

= 0.

h

h

,

For reasons of convenience, let us deﬁne the size

T
|
ψ
2 , the tree size TS (
⊗
i
|
ψ
. The orthogonal tree size OTS (
|

of a tree T to be the number
) is the minimum
ψ
) and manifestly
|
) are deﬁned similarly. Then OTree is the class of
ψni
|
i
p (n) for some polynomial p, and MOTree is the class such that

i ∈ H

ψ
|

i

i

n

|

of leaf vertices. Then given a state
size of a tree that represents
orthogonal tree size MOTS (
ψ
|
such that OTS (
)
ψni
|
≤
p (n) for some p.
ψni
MOTS (
|
It is easy to see that

≤

)

n

ψ
TS (
|

i
, and that the set of

≤

)

≤
ψ
|

)

i

ψ
OTS (
|
ψ
such that TS (
|

≤

for every
other important properties of TS and OTS are as follows:

ψ
|

i

i

i

MOTS (

)

ψ
|

i

≤

n2n

) < 2n has measure 0 in

n

2 . Two
⊗

H

Proposition 71

(i) TS and OTS are invariant under local5 basis changes, up to a constant factor of 2.

(ii) If

|

is obtained from
)

ψ
|
i
k4k OTS (
|

≤

φ
i
φ
and OTS (
i
|
Proof.

).
i

by applying a k-qubit unitary, then TS (
φ
i
|
ψ

)

≤

k4k TS (

)

ψ
|

i

(i) Simply replace each occurrence of

in the original tree by a tree for α

and each occurrence of

1
i
|

by a tree for γ

0
i
|

+ δ

1
i
|

, as appropriate.

0
i
|

0
i
|

+ β

,

1
i
|

(ii) Suppose without loss of generality that the gate is applied to the ﬁrst k qubits. Let
, and let Ty be the restriction of T obtained by setting
ψ
i
|
. Furthermore, we can express
0, 1
∈ {
|
}
k SyTy, where each Sy represents a k-qubit state and hence is

T
Ty| ≤ |

k. Clearly

T be a tree representing
the ﬁrst k qubits to y
φ
|
i
expressible by a tree of size k2k.
P

in the form

0,1

∈{

}

y

|

4Requiring only the whole tree to represent a normalized state clearly yields no further generality.
5Several people told me that a reasonable complexity measure must be invariant under all basis changes.

Alas, this would imply that all pure states have the same complexity!

133

ψ
One can also deﬁne the ε-approximate tree size TSε (
|

2

such that

ψ

ϕ
|

i|

|h

1

≥

−

i

) to be the minimum size
) and

ψ
ε, and deﬁne OTSε (
|

i

of a tree representing a state
MOTSε (
|

) similarly.

ψ

i

ϕ
i
|

Deﬁnition 72 An arithmetic formula (over the ring C and n variables) is a rooted bi-
nary tree where each leaf vertex is labeled with either a complex number or a variable in
. Such a tree represents
x1, . . . , xn}
{
a polynomial p (x1, . . . , xn) in the obvious way. We call a polynomial multilinear if no
variable appears raised to a higher power than 1, and an arithmetic formula multilinear if
the polynomials computed by each of its subtrees are multilinear.

, and each non-leaf vertex is labeled with either + or

×

The size

of a multilinear formula Φ is the number of leaf vertices. Given a
multilinear polynomial p, the multilinear formula size MFS (p) is the minimum size of a
multilinear formula that represents p. Then given a function f :

C, we deﬁne

Φ

n

|

|

0, 1
}
{

→

MFS (f ) =

min
p : p(x)=f (x)
∀

x

0,1

}

∈{

MFS (p) .

n

(Actually p turns out to be unique [184].) We can also deﬁne the ε-approximate multilinear
formula size of f ,

MFSε (f ) =

min
f
p

2
2≤
k

ε

p :

MFS (p)

2
2 =
k

−
f
(This metric is closely related to the inner
x p (x)∗ f (x), but is often more convenient to work with.) Now given a state
n to C deﬁned by fψ (x) =
0,1

2 , let fψ be the function from
⊗

f (x)
|

p (x)

2.

in

−

0,1

∈{

n

x

}

k

|

n

P
x
n αx |
i

}

H

0, 1
}
{

p

−

x
P
∈{

where
k
product
=
ψ
|
i
αx.

P

Theorem 73 For all

,

ψ
|

i

(i) MFS (fψ) = O (TS (

)).

ψ
|

i

ψ
(ii) TS (
|

i

) = O (MFS (fψ) + n).

(iii) MFSδ (fψ) = O (TSε (
|

ψ

)) where δ = 2
i

−

2√1

ε.

−

ψ
(iv) TS2ε (
|

i

) = O (MFSε (fψ) + n).

Proof.

(i) Given a tree representing
by

xi. Push all multiplications by constants at the edges down to

|
×

i

ψ
, every

, replace every unbounded fan-in gate by a collection of
ii vertex by a formula
0
gates at the

ii vertex by xi, and every
1
|

|

⊗

binary gates, every
for 1
−
leaves.

×

(ii) Given a multilinear formula Φ for fψ, let p (v) be the polynomial computed at vertex v
of Φ, and let S (v) be the set of variables that appears in p (v). First, call Φ syntactic
S (w) = ∅. A lemma of Raz [195]
if at every
states that we can always make Φ syntactic without increasing its size.

gate with children v and w, S (v)

×

∩

134

{
= 1 but

x1, . . . , xn}
S (w)
|

∪

S (w), by multiplying p (v) by xi + (1

Second, at every + gate u with children v and w, enlarge both S (v) and S (w) to
S (v)
S (v), and
multiplying p (w) by xi + (1
S (w). Doing this does
S (v)
xi) for every xi ∈
not invalidate any
gate that is an ancestor of u, since by the assumption that
Φ is syntactic, p (u) is never multiplied by any polynomial containing variables in
S (v)

xi) for every xi ∈
\

S (w). Similarly, enlarge S (r) to

where r is the root of Φ.

S (w)

−

−

×

\

∪

|

S (v)

Third, call v max-linear if
> 1 where w is the parent of v.
|
If v is max-linear and p (v) = a + bxi, then replace the tree rooted at v by a tree
computing a
ii. Also, replace all multiplications by constants higher in
1
|
Φ by multiplications at the edges. (Because of the second step, there are no additions
by constants higher in Φ.) Replacing every
then gives a tree representing
ψ

ii + (a + b)
0
|

×
+ n) .

Φ
, whose size is easily seen to be O (
|
i

|
(iii) Apply the reduction from part (i). Let the resulting multilinear formula compute

by

⊗

|

|

polynomial p; then

p (x)

n |

2 = 2
fψ (x)
|

−

−

2

0,1
Xx
∈{

}

n

0,1
Xx
∈{

}

p (x) fψ (x)

2

−

≤

2√1

−

ε = δ.

(iv) Apply the reduction from part (ii). Let (βx)x

since this vector might not be normalized, divide each βx by
Then

0,1

}

∈{

n be the resulting amplitude vector;
2 to produce β′x.
βx|

x |

P

2

β′xαx(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

n

0,1
Xx
∈{

}

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2

β′x −

αx

= 1

1
2

−

n

0,1
Xx
∈{

}

(cid:12)
(cid:12)

1
2 

1

1

−

−

≥

≥

1
2

n |
s Xx
0,1
∈{
}

2 = 1
2√ε

(cid:12)
(cid:12)
β′x −

2ε.

−

2 +

βx|

s Xx
0,1
∈{

}

βx −

n |

2

αx|

2





Besides Tree, OTree, and MOTree, four other classes of quantum states deserve

mention:

(cid:0)

(cid:1)

Circuit, a circuit analog of Tree, contains the states

ψni
such that for
|
all n, there exists a multilinear arithmetic circuit of size p (n) over the complex numbers
(Multilinear circuits are the
that outputs αx given x as input, for some polynomial p.
same as multilinear trees, except that they allow unbounded fanout—that is, polynomials
computed at intermediate points can be reused arbitrarily many times.)

x
x αx |
i

P

=

AmpP contains the states

such that for all n, b, there exists a
classical circuit of size p (n + b) that outputs αx to b bits of precision given x as input, for
P
some polynomial p.

x αx |

ψni
|

x
i

=

135

{

ψni
|

1, . . . , n

Vidal contains the states that are ‘polynomially entangled’ in the sense of Vidal
ψni
into A and B, let χA (
) be the minimum k
}
|
k
ϕA
ϕA
i=1 αi
and
are states of
i
i
⊗
) is known as the Schmidt rank ; see [182] for
ψni
(χA (
(cid:12)
(cid:12)
(cid:12)
(cid:11)
|
P
Vidal if and only if
(cid:12)
(cid:12)
(cid:12)
ψni ∈
ψni
) = maxA χA (
|
|

[236]. Given a partition of
can be written as
for which
qubits in A and B respectively.
more information.)
ψni
|
χ (
≤
|
ΨP contains the states

Let χ (
p (n) for some polynomial p.

such that for all n and ε > 0, there exists a quantum
circuit of size p (n + log (1/ε)) that maps the all-0 state to a state some part of which has
trace distance at most 1
, for some polynomial p. Because of the Solovay-Kitaev
Theorem [153, 182], ΨP is invariant under the choice of universal gate set.

ψni
|
ψni
|

(cid:11)
). Then

)
ψni

, where

ε from

ϕB
i

ϕB
i

−

(cid:12)
(cid:12)

(cid:11)

(cid:11)

13.3 Basic Results

Before studying the tree size of speciﬁc quantum states, it would be nice to know in general
how tree size behaves as a complexity measure.
In this section I prove three rather nice
properties of tree size.

Theorem 74 For all ε > 0, there exists a tree representing

of size O

ψ
|

i

depth O (log TS (
ψ
|
ψ
and depth O (log MOTS (
|

i

)).

i

)), as well as a manifestly orthogonal tree of size O

(cid:16)

(cid:16)

i

TS (

ψ
|
MOTS (
|

)1+ε

and

ψ

(cid:17)
)1+ε
i

(cid:17)

Proof. A classical theorem of Brent [70] says that given an arithmetic formula
c), where c is a
Φ, there exists an equivalent formula of depth O (log
|
constant. Bshouty, Cleve, and Eberly [73] (see also Bonet and Buss [62]) improved Brent’s
theorem to show that c can be taken to be 1 + ε for any ε > 0. So it suﬃces to show that,
for ‘division-free’ formulas, these theorems preserve multilinearity (and in the MOTS case,
preserve manifest orthogonality).

Φ
) and size O (
|
|

Φ
|

|

|

|

|

Φ

Φ
|

Φ
|

/3 and 2

Brent’s theorem is proven by induction on
Φ

. Here is a sketch: choose a sub-
|
formula I of Φ size between
/3 (which one can show always exists). Then
identifying a subformula with the polynomial computed at its root, Φ (x) can be written as
G (x) + H (x) I (x) for some formulas G and H. Furthermore, G and H are both obtainable
are both at
from Φ by removing I and then applying further restrictions. So
Φ be a formula equivalent to Φ that evaluates G, H, and I
most
by at most a
separately, and then returns G (x) + H (x) I (x). Then
constant factor, while by the induction hypothesis, we can assume the formulas for G, H,
and I have logarithmic depth. Since the number of induction steps is O (log
), the total
|
depth is logarithmic and the total blowup in formula size is polynomial in
. Bshouty,
|
Cleve, and Eberly’s improvement uses a more careful decomposition of Φ, but the basic
idea is the same.

+ O (1). Let

is larger than

I
| − |

Φ
|
Φ
|

G
|
|

(cid:12)
(cid:12)
(cid:12)b

H
|

and

(cid:12)
(cid:12)
(cid:12)

Φ

Φ

b

|

|

|

|

Now, if Φ is syntactic multilinear, then clearly G, H, and I are also syntactic
multilinear. Furthermore, H cannot share variables with I, since otherwise a subformula

136

of Φ containing I would have been multiplied by a subformula containing variables from I.
Thus multilinearity is preserved. To see that manifest orthogonality is preserved, suppose
we are evaluating G and H ‘bottom up,’ and let Gv and Hv be the polynomials computed
at vertex v of Φ. Let v0 = root (I), let v1 be the parent of v0, let v2 be the parent of v1, and
It is clear that, for every x, either Gv0 (x) = 0 or Hv0 (x) = 0.
so on until vk = root (Φ).
Furthermore, suppose that property holds for Gvi
1; then by induction it holds for
ϕ
Gvi, Hvi. If vi is a
are manifestly
i
|
orthogonal, then
If vi is a + gate,
i
then letting supp (p) be the set of x such that p (x)
or Hvi

and
are also manifestly orthogonal).

gate, then this follows from multilinearity (if

= 0, any polynomial p added to Gvi

×
0
i ⊗ |
|

1 must have

0
i ⊗ |
|

1 , Hvi

ϕ
i

and

ψ
|

ψ

i

−

−

−

1

−

supp (p)

supp

Gvi

−

1

∩

(cid:0)
and manifest orthogonality follows.

(cid:0)

supp

Hvi

−

1

=

,
∅

(cid:0)

(cid:1)(cid:1)

∪

(cid:1)

Theorem 75 Any
ΨP.
Thus OTree

⊆

ψ
|

i

can be prepared by a quantum circuit of size polynomial in OTS (

).

ψ
|

i

n

|

i

i

)

i

)

i

i

⊗

≤

ψ
|

ψ
|

ψ
|

ψ1i
|

), is that Γ (

ψ
i ∈ H
|
ψ
q (OTS (
i
|

Proof. Let Γ (
0
⊗
i
|

) be the minimum size of a circuit needed to prepare

n. The claim, by induction on Γ (

and
gate; then clearly Γ (

⊗
2
))
ψ
|
) = 1 is clear. Let T be an orthogonal
, and assume without loss of generality that every gate has fan-in 2 (this
ψ
|
by at most a constant factor). Let T1 and T2 be the subtrees of root (T ),
. First suppose

starting from
ψ
for some polynomial q. The base case OTS (
|
state tree for
increases
T
|
representing states
root (T ) is a

ψ2i
respectively; note that
T2|
|
ψ1i
) + Γ (
Γ (
|
Second, suppose root (T ) is a + gate, with
=
ψ2i
ψ
ψ2i
ψ1|
|
|
h
Let U be a quantum circuit that prepares
, and V be a circuit that prepares
ψ1i
0.
|
n is
1V
1V
. Then we can prepare α
0
0
0
U −
0
ψ2i
|
i
i |
i
|
i
|
|
n. So applying
n is orthogonal to
= U
ψ1i
orthogonal to
⊗
|
a NOT to the ﬁrst register, conditioned on the OR of the bits in the second register,
n + βU −
1V
yields
by applying U
+ n), with a possible
to the second register. The size of the circuit used is O (
constant-factor blowup arising from the need to condition on the ﬁrst register.
If we are
more careful, however, we can combine the ‘conditioning’ steps across multiple levels of the
recursion, producing a circuit of size
+ n). By symmetry, we can also reverse
U
+ O (
|
the roles of U and V to obtain a circuit of size

, from which we obtain α
U
|

n. Observe that U −
= V

T
=
|
|
).
ψ2i
|
= α
i

n + β
⊗
0
⊗
i
|

0
i
|
ψ2i

T1|
|
ψ1i

+ n). Therefore

ψ1i
|
V
+
|

n, since

0
i ⊗

ψ2i

0
i
|

0
i
|

1
i
|

and

+ β

+ β

0
i

≤

+

α

V

(cid:0)

(cid:1)

⊗

⊗

⊗

⊗

⊗

i

n

|

|

|

|

|

|

|

|

|

|

|
U
|

V
+ O (
|

|

|
ψ2i
|

) + cn

}

ψ1i
) + Γ (
|
ψ

ψ

Γ (
|

)
i

≤

min

Γ (
|
{

ψ1i

) + cΓ (

) + cn, cΓ (

ψ2i
|

for some constant c
).
OTS (
i
|

ψ

2.

≥

Solving this recurrence we ﬁnd that Γ (
|

) is polynomial in
i

Theorem 76 If
ψ
TS1/16 (
|

i

ψ
|

⊗
2

i ∈ H

) = 2Ω(n) with probability 1

o (1).

−

n

is chosen uniformly at random under the Haar measure, then

6
137

, we can choose

αx,
1, then let αx =
b

βx ∈
b

Proof. To generate a uniform random state

ψ

R for each x independently from a Gaussian distribution with mean 0 and variance

αx + i

βx

/√R where R =

x

0,1

n

}

∈{

(cid:16)

b

(cid:17)

b

P

x : (Re αx)2 <

Λψ =

(cid:26)
for which

=

x

0,1

∈{

x
n αx |
i

}

|

i

P
x +

α2

β2
x

. Let

(cid:17)

b

,

(cid:16)
1
b
2n

(cid:27)

4

·

be the set of

] =
o (1). First, EX [R] = 2n+1, so by a standard Hoeﬀding-type bound, Pr [R < 2n] is

and let
1
doubly-exponentially small in n. Second, assuming R

< 2n/5. The claim is that Pr
|

Λψ|

i ∈ G

ψ
|

−

ψ

G

i

ψ

|

|

[

i

2n, for each x

≥

Pr [x

Λψ]

∈

≤

Pr

α2

x <

(cid:20)

1
4

(cid:21)

= erf

1
4√2 (cid:19)

(cid:18)

< 0.198,

and the claim follows by a Chernoﬀ bound.
n

b
R, let Ag =

For g :

0, 1
}

{

→

1 otherwise. Then if

x : sgn (g (x))
, clearly

0 and

y

≥

−

{
i ∈ G

ψ
|

= sgn (Re αx)

, where sgn (y) is 1 if
}

g (x)

n |
}

0,1
Xx
∈{

2

fψ (x)
|

−

≥

|

Λψ|
Ag| − |
2n
4
·

where fψ (x) = Re αx, and thus

Ag| ≤

|

4
(cid:18)

g

k

fψk

−

2
2 +

2n.

1
5

(cid:19)

Therefore to show that MFS1/15 (fψ) = 2Ω(n) with probability 1
that for almost all Boolean functions f :
Φ of size 2o(n) such that

0, 1
}

1, 1
}

→ {−

{

n

o (1), we need only show
, there is no arithmetic formula

−

x : sgn (Φ (x))

|{

= f (x)

}| ≤

0.49

2n.

·

Here an arithmetic formula is real-valued, and can include addition, subtraction, and mul-
tiplication gates of fan-in 2 as well as constants. We do not need to assume multilinearity,
and it is easy to see that the assumption of bounded fan-in is without loss of generality. Let
W be the set of Boolean functions sign-represented by an arithmetic formula Φ of size 2o(n),
= 22o(n)
,
in the sense that sgn (Φ (x)) = f (x) for all x. Then it suﬃces to show that
since the number of functions sign-represented on an 0.51 fraction of inputs is at most
W
|

22nH(0.51). (Here H denotes the binary entropy function.)

Let Φ be an arithmetic formula that takes as input the binary string x = (x1, . . . , xn)
as well as constants c1, c2, . . .. Let Φc denote Φ under a particular assignment c to c1, c2, . . ..
Then a result of Gashkov [121] (see also Tur´an and Vatan [230]), which follows from War-
ren’s Theorem [237] in real algebraic geometry, shows that as we range over all c, Φc
is the size of Φ.
sign-represents at most
is
Furthermore, excluding constants, the number of distinct arithmetic formulas of size

| distinct Boolean functions, where

2n+4

W
|

Φ
|

Φ
|

Φ
|

| ·

Φ

|

|

(cid:0)

|
(cid:1)

|

|

6
6
138

Φ
|

3

= 2o(n), this gives
at most
fore MFS1/15 (fψ) = 2Ω(n); by Theorem 73, part (iii), this implies that TS1/16 (

|. When

2n+4

Φ

Φ

Φ

Φ

(cid:16)

(cid:17)

(cid:17)

(cid:16)

3

·

|

|

|

|

|

|

|

|

2
|

2
|

|
(cid:1)

(cid:0)

Φ

| = 22o(n)

. There-
) = 2Ω(n).

Φ

ψ
|

i

A corollary of Theorem 76 is the following ‘nonampliﬁcation’ property: there exist
states that can be approximated to within, say, 1% by trees of polynomial size, but that
require exponentially large trees to approximate to within a smaller margin (say 0.01%).

Corollary 77 For all δ
TSε (
|

) = 2Ω(n) where ε = δ/32
i

∈

ψ

δ2/4096.

−

(0, 1], there exists a state

ψ
|

i

such that TSδ (
|

ψ

) = n but
i

Proof. It is clear from Theorem 76 that there exists a state

) = 2Ω(n) and α0n = 0. Take

n

ψ

ϕ
such that TS1/16 (
i
|
2
δ, we have MOTSδ (
|
) = 2o(n) satisﬁes
φ
with TS (
i
|

= 1
−
x
n βx |
(cid:12)
i
}
(cid:12)

0
i
|
0,1
x

∈{

ψ

⊗

ψ
φ
|

2
i|

h
(cid:12)
(cid:12)
P

|h

2

ψ

|

i

= √1

δ

−

ϕ
i
|
0
⊗
i
|

=
0,1
x
∈{
n + √δ
ϕ
P
i
|

x
n αx |
i
}
. Since

) = n. On the other hand, suppose some
i

=

φ
i
|

1

ε. Then

≥

−

√δαx −

=0n (cid:16)
Xx

βx

≤

(cid:17)

2√1

2

−

ε.

−

)) where c =
φ
Thus, letting fϕ (x) = αx, we have MFSc (fϕ) = O (TS (
i
|
By Theorem 73, part (iv), this implies that TS2c (
) = O (TS (
ϕ
i
|
ε = δ/32

δ2/4096, contradiction.

/δ.
)). But 2c = 1/16 when
φ
i
|

−

−

2

ε

(cid:1)

(cid:0)

2√1

−

13.4 Relations Among Quantum State Classes

This section presents some results about the quantum state hierarchy introduced in Section
13.2. Theorem 78 shows simple inclusions and separations, while Theorem 79 shows that
separations higher in the hierarchy would imply major complexity class separations (and
vice versa).

Theorem 78

(i) Tree

Vidal

∪

⊆

Circuit

⊆

AmpP.

(ii) All states in Vidal have tree size nO(log n).

(iii) Σ2

Vidal but

Vidal.

2

⊗

6⊂

⊆

(iv)

⊗

2 ( MOTree.

(v) Σ1, Σ2, Σ3,

1,

⊗

⊗

2, and

⊗

3 are all distinct. Also,

= Σ4

3

4.

∩ ⊗

⊗

Proof.

6
6
139

(i) Tree

⊆

AmpP
Circuit since any multilinear tree is also a multilinear circuit. Circuit
since the circuit yields a polynomial-time algorithm for computing the amplitudes.
For Vidal
1, . . . , n

Circuit, we use an idea of Vidal [236]: given

⊆
we can express

Vidal, for all j

ψni ∈
|

as

⊆

∈

{

}

ψni
|

ψ

χ(
|

i

)

Xi=1

αij

φ[1...j]
i
(cid:12)
(cid:12)
(cid:12)

⊗

E

φ[j+1...n]
i
(cid:12)
(cid:12)
(cid:12)

E

ψni
where χ (
|
φ[1...j]
can be written as a linear combination of states of the form
i

) is polynomially bounded.

Furthermore, Vidal showed that each
0
i
⊗ |
states is the same, in-

−

1]

φ[1...j
i
(cid:12)
(cid:12)
(cid:12)

—the point being that the set of

φ[1...j
i
(cid:12)
. This immediately yields a polynomial-size multilinear circuit
(cid:12)
(cid:12)

E

E

−

1]

1]

−

φ[1...j
E
i

(cid:12)
and
(cid:12)
(cid:12)
(cid:12)
E
dependently of
(cid:12)
(cid:12)
.
ψni
for
(ii) Given

|

ψni ∈
|

1
⊗ |
i
φ[1...j]
i
(cid:12)
(cid:12)
(cid:12)

E

Vidal, we can decompose

ψni
|

as

ψ

χ(
|

i

)

αi

φ[1...n/2]
i
(cid:12)
(cid:12)
(cid:12)
) and χ

⊗

φ[n/2+1...n]
i
(cid:12)
E
(cid:12)
(cid:12)
φ[n/2+1...n]
i

φ[1...n/2]
i

Xi=1
ψni
Then χ
≤
|
recursively decompose these states in the same manner.
2χ (
ψ
|
nO(log n).

(cid:16)(cid:12)
(cid:12)
ψni
; solving this recurrence relation yields TS (
(cid:12)
|

(cid:16)(cid:12)
(cid:12)
) TS
(cid:12)

ψn/2

E(cid:17)

E(cid:17)

χ (

≤

.

E

i

) for all i, so we can

χ (
ψni
|
ψni
It follows that TS (
)
|
≤
))log n =
ψ
)
i
|

(2χ (

≤

(cid:0)(cid:12)
(cid:12)

(cid:11)(cid:1)

(iii) Σ2

Vidal follows since a sum of t separable states has χ
)⊗

from the example of n/2 Bell pairs: 2−

⊆

+

≤
n/2.

t, while

Vidal follows

2

⊗

6⊂

2

⊆

MOTree is obvious, while MOTree

, an
⊗
6⊂ ⊗
equal superposition over all n-bit strings of parity i. The following recursive formulas
imply that MOTS

4 MOTS

= O

P i

n2

(cid:12)
(cid:12)

(cid:11)

:

P i
n

n/2

n/4 (
|

11
i
|

00
i
2 follows from the example of

P i
n

≤

(cid:0)(cid:12)
(cid:12)

(cid:11)(cid:1)
P 0
n

=

(cid:11)

(cid:12)
(cid:12)

P 1
n

=

1
√2
1
√2

(cid:16)(cid:12)
(cid:12)
(cid:12)

P 0

n/2

E(cid:17)

P 0

n/2

E

n/2

n/2

(cid:16)(cid:12)
(cid:12)
P 0
(cid:12)
(cid:16)(cid:12)
(cid:12)
(cid:12)

E (cid:12)
(cid:12)
P 1
(cid:12)
E (cid:12)
(cid:12)
(cid:12)

+

+

(cid:0)
P 1
n/2
(cid:12)
(cid:12)
P 1
(cid:12)
(cid:12)
(cid:12)
/
(cid:12)
∈

n/2

(cid:1)

E (cid:12)
(cid:12)
(cid:12)
E (cid:12)
(cid:12)
(cid:12)

P 1

n/2

P 0

n/2

,

.

E(cid:17)

E(cid:17)

E
(cid:12)
(cid:11)
(cid:12)
On the other hand,
Pni
Pni
|
|
has no nontrivial tensor product decomposition.

2 follows from

/
∈ ⊗

Σ1 together with the fact that

Pni
|

Σ1 and Σ1

1 are obvious.

6⊂ ⊗

2 (and hence Σ1

2) follows from part
1
⊗
= Σ2) follows from part (iv), together with the fact

Σ2 (and hence

⊗

=

6⊂

⊗

2

6⊂ ⊗
has a Σ2 formula based on the Fourier transform:

1

⊗
6⊂
(iii). Σ2
Pni
that
|

=

Pni

|

1
√2  (cid:18)

0
+
1
i
|
|
i
√2 (cid:19)

n

⊗

+

1
0
i − |
i
|
√2 (cid:19)

(cid:18)

n

⊗

.

!

(iv)

(v)

6
6
= Σ3 follows from

Σ2
Σ2 and
together with the fact that we can easily construct states in Σ3
nontrivial tensor product decomposition—for example,

Σ3. Also, Σ3

6⊂ ⊗

⊗

6⊂

⊗

⊆

2

2

\

3 follows from Σ2

= Σ3,
Σ2 that have no

140

1
0
√2  |
i

n +

⊗

(cid:18)

+
01
i
|
|
√2

10
i

(cid:19)

n/2

⊗

2
⊗
Σ3

=

⊗
6⊂ ⊗

3 follows from Σ2
3 and Σ3

Σ4

2 and Σ2

3. Finally,

⊆ ⊗

6⊂ ⊗
4.

⊆

∩ ⊗

.

!

3

⊗

= Σ4

∩ ⊗

4 follows from

Theorem 79

(i) BQP = P#P implies AmpP

ΨP.

⊆
BQP/poly.

(ii) AmpP

ΨP implies NP

⊆
(iii) P = P#P implies ΨP

⊆
AmpP.

⊆

(iv) ΨP

⊆

AmpP implies BQP

P/poly.

⊆

Proof.

0,1

⊆

i ∈

ψ
|

with

(i) First, BQP = P#P implies BQP/poly = P#P/poly, since given a P#P/poly machine
M , the language consisting of all (x, a) such that M accepts on input x and advice
a is clearly in BQP. So assume BQP/poly = P#P/poly, and consider a state
=
AmpP. By the result of Bernstein and Vazirani [55] that
n αx |
x
x
i
}
∈{
P#P, for all b there exists a quantum circuit of size polynomial in n and b
BQP
P
2, or the probability that the ﬁrst qubit is
that approximates p0 =
α0y|
measured to be 0, to b bits of precision. So by uncomputing garbage, we can prepare
0
a state close to √p0 |
. Similarly, given a superposition over length-
i
k preﬁxes of x, we can prepare a superposition over length-(k + 1) preﬁxes of x by
approximating the conditional measurement probabilities. We thus obtain a state
close to
, apply that
x
i
phase, and uncompute to obtain a state close to

. The last step is to approximate the phase of each
x
αx| |
i

P
+ √1

p0 |

ψ
|

1
i

x |

−

0,1

∈{

i

−

}

y

|

|

n

1

x αx |

.
x
i

P

(ii) Given a SAT instance ϕ, ﬁrst use Valiant-Vazirani [231] to produce a formula ϕ′ that
(with non-negligible probability) has one satisfying assignment if ϕ is satisﬁable and
zero otherwise. Then let αx = 1 if x is a satisfying assignment for ϕ′ and αx = 0
ΨP, there
x αx |
otherwise; clearly
⊆
exists a polynomial-size quantum circuit that approximates
, and thereby ﬁnds the
i
unique satisfying assignment for ϕ′ if it exists.

is in AmpP. By the assumption AmpP

x
i

ψ
|

P

=

ψ

i

|

P

(iii) As in part (i), P = P#P implies P/poly = P#P/poly. The containment ΨP

AmpP
follows since we can approximate amplitudes to polynomially many bits of precision
in #P.

⊆

6
6
6
6
(iv) As is well known [55], any quantum computation can be made ‘clean’ in the sense
n) is measured. The

that it accepts if and only if a particular basis state (say
implication follows easily.

0
i
|

⊗

141

13.5 Lower Bounds

We want to show that certain quantum states of interest to us are not represented by trees
of polynomial size. At ﬁrst this seems like a hopeless task. Proving superpolynomial
formula-size lower bounds for ‘explicit’ functions is a notoriously hard open problem, as it
would imply complexity class separations such as NC1

= P.

Here, though, we are only concerned with multilinear formulas. Could this make
it easier to prove a lower bound? The answer is not obvious, but very recently, for reasons
unrelated to quantum computing, Raz [195, 196] showed the ﬁrst superpolynomial lower
In particular, he showed that multilinear formulas
bounds on multilinear formula size.
n matrix over any ﬁeld have size nΩ(log n).
computing the permanent or determinant of an n
×
Raz’s technique is a beautiful combination of the Furst-Saxe-Sipser method of ran-
dom restrictions [120], with matrix rank arguments as used in communication complexity.
C, let P be a partition of the
0, 1
I now outline the method. Given a function f :
→
}
{
input variables x1, . . . , xn into two collections y =
y1, . . . , yn/2
.
n/2
2n/2
C. Then let Mf
This yields a function fP (y, z) :
0, 1
(cid:0)
(cid:1)
}
→
|
n/2, and whose columns are labeled
matrix whose rows are labeled by assignments y
0, 1
∈ {
}
n/2. The (y, z) entry of Mf
by assignments z
P is fP (y, z). Let rank
0, 1
be
}
the rank of Mf
be the uniform distribution
over all partitions P .

P over the complex numbers. Finally, let

P be a 2n/2
(cid:0)

z1, . . . , zn/2

and z =

0, 1
}

∈ {

Mf

× {

n/2

×

P

{

(cid:1)

(cid:1)

(cid:0)

P

n

|

|

|

The following, Corollary 3.6 in [196], is one statement of Raz’s main theorem;

recall that MFS (f ) is the minimum size of a multilinear formula for f .

Theorem 80 ([196]) Suppose that

Pr
P
∈P h
Then MFS (f ) = nΩ(log n).

rank

Mf

P

|

≥

(cid:0)

(cid:1)

2n/2
−

(n/2)1/8/2

= n−

o(log n).

i

An immediate corollary yields lower bounds on approximate multilinear formula
ε rank (L) where

size. Given an N
×
N
2
2 =
i,j=1 |

L
k

M

N matrix M = (mij), let rankε (M ) = minL :
ℓij −

2.
mij|

2
2≤
k

−

M

k

−

L

k

P
Corollary 81 Suppose that

Pr
P
∈P h
Then MFSε (f ) = nΩ(log n).

rankε

Mf

P

|

(cid:0)

≥

(cid:1)

2n/2
−

(n/2)1/8/2

= n−

o(log n).

i

6
Proof. Suppose MFSε (f ) = no(log n). Then for all g such that

would have MFS (g) = no(log n), and therefore

f
k

−

g

2
2 ≤

k

ε, we

142

Pr
P
∈P h
by Theorem 80. But rankε

rank

Mg

P

|

≥

2n/2
−

(n/2)1/8/2

= n−

Ω(log n).

(cid:0)
Mf

|

P

(cid:1)
rank

≤

Mg

P

|

i
, and hence

Pr
P
∈P h

(cid:0)
rankε

(cid:1)
Mf

P

|

≥

(cid:0)

(cid:1)

(cid:0)
2n/2
−

(cid:1)

(n/2)1/8/2

= n−

Ω(log n),

i

contradiction.

Another simple corollary gives lower bounds in terms of restrictions of f . Let
Rℓ be the following distribution over restrictions R: choose 2ℓ variables of f uniformly at
random, and rename them y = (y1, . . . , yℓ) and z = (z1, . . . , zℓ). Set each of the remaining
n
2ℓ variables to 0 or 1 uniformly and independently at random. This yields a restricted
function fR (y, z). Let Mf

2ℓ matrix whose (y, z) entry is fR (y, z).

R be a 2ℓ

−

|

×

Corollary 82 Suppose that

Pr
∈Rℓ

R

where ℓ = nδ for some constant δ

∈

rank

Mf

R

|

≥

ℓ1/8/2

2ℓ

−

= n−

o(log n)

h

(cid:1)

(cid:0)
(0, 1]. Then MFS (f ) = nΩ(log n).

i

Proof. Under the hypothesis, clearly there exists a ﬁxed restriction g :

C of f , which leaves 2ℓ variables unrestricted, such that

2ℓ

0, 1
}

{

→

Pr
P
∈P h

Then by Theorem 80,

rank

Mg

P

|

≥

(cid:0)

(cid:1)

ℓ1/8/2

2ℓ

−

= n−

o(log n) = ℓ−

o(log ℓ).

i

MFS (f )

≥

MFS (g) = ℓΩ(log ℓ) = nΩ(log n).

The following sections apply Raz’s theorem to obtain nΩ(log n) tree size lower
bounds for two classes of quantum states: states arising in quantum error-correction in
Section 13.5.1, and (assuming a number-theoretic conjecture) states arising in Shor’s fac-
toring algorithm in Section 13.5.2.

13.5.1 Subgroup States

Let the elements of Zn
the subgroup state

S

2 be labeled by n-bit strings. Given a subgroup S
as follows:

|

i

Zn

2 , we deﬁne

≤

=

S
|

i

1

S
|

p

.

x
i
|

S
| Xx
∈

Coset states arise as codewords in the class of quantum error-correcting codes known as
stabilizer codes [80, 133, 225]. Our interest in these states, however, arises from their large
tree size rather than their error-correcting properties.

143

E

Let

be the following distribution over subgroups S. Choose an n/2

trix A by setting each entry to 0 or 1 uniformly and independently.
x
{
ear formula size of the function fS (x), which is 1 if x

n ma-
×
Then let S =
. By Theorem 73, part (i), it suﬃces to lower-bound the multilin-
}

S and 0 otherwise.

0 (mod 2)

Ax

≡

|

∈

Theorem 83 If S is drawn from
nΩ(log n)), with probability Ω (1) over S.

E

, then MFS (fS) = nΩ(log n) (and hence TS (

S
|

) =
i

(cid:1)

and z =

. Let MS

y1, . . . , yn/2

(cid:0)
|
Let Ay be the n/2

z1, . . . , zn/2
P (y, z); then we need to show that rank
(cid:0)
(cid:1)
n/2 submatrix of the n/2

Proof. Let P be a uniform random partition of the inputs x1, . . . , xn of fS into
2n/2 matrix
two sets y =
whose (y, z) entry is fS
is large with high
probability.
n matrix A consisting
of all rows that correspond to yi for some i
, and similarly let Az be the
∈ {
n/2 submatrix corresponding to z. Then it is easy to see that, so long as Ay and
n/2
Az are both invertible, for all 2n/2 settings of y there exists a unique setting of z for which
P is a permutation of the identity matrix, and
fS
MS
hence that rank
n/2 matrix
P
|
over Z2 is invertible is

= 2n/2. Now, the probability that a random n/2

P (y, z) = 1. This then implies that MS

P be the 2n/2
MS
P

1, . . . , n/2
}

(cid:0)
×

×

×

×

×

(cid:1)

|

|

|

|

(cid:0)

(cid:1)

1
2 ·

3
4 · · · · ·

2n/2

1

−

2n/2 > 0.288.

(cid:0)

(cid:1)

So the probability that Ay and Az are both invertible is at least 0.2882. By Markov’s
= 2n/2 for at least
inequality, it follows that for at least an 0.04 fraction of S’s, rank
an 0.04 fraction of P ’s. Theorem 80 then yields the desired result.

MS

P

|

Aaronson and Gottesman [14] showed how to prepare any n-qubit subgroup state

using a quantum circuit of size O
6⊂
Tree. Since fS clearly has a (non-multilinear) arithmetic formula of size O (nk), a second
(cid:1)
corollary is the following.

. So a corollary of Theorem 83 is that ΨP

(cid:0)

n2/ log n

Corollary 84 There exists a family of functions fn :
arithmetic formulas, but no polynomial-size multilinear formulas.

0, 1
}
{

→

n

R that has polynomial-size

The reason Corollary 84 does not follow from Raz’s results is that polynomial-size
formulas for the permanent and determinant are not known; the smallest known formulas
for the determinant have size nO(log n) (see [79]).

We have shown that not all subgroup states are tree states, but it is still conceivable
that all subgroup states are extremely well approximated by tree states. Let us now rule
out the latter possibility. We ﬁrst need a lemma about matrix rank, which follows from
the Hoﬀman-Wielandt inequality.

Lemma 85 Let M be an N
IN k
Then

2
2 ≥

M
k

N

−

−

×
rank (M ).

N complex matrix, and let IN be the N

N identity matrix.

×

Proof. The Hoﬀman-Wielandt inequality [144] (see also [33]) states that for any
N matrices M, P ,

two N

×

N

Xi=1

(σi (M )

σi (P ))2

M

≤ k

P

2
2 ,

k

−

−

144

where σi (M ) is the ith singular value of M (that is, σi (M ) =

λN (M )

≥
0 are the eigenvalues of M M ∗, and M ∗ is the conjugate transpose of M ).
· · · ≥
Clearly σi (IN ) = 1 for all i. On the other hand, M has only rank (M ) nonzero singular
values, so

p

≥

λi (M ), where λ1 (M )

N

Xi=1

(σi (M )

−

σi (IN ))2

N

≥

−

rank (M ) .

Let

fS (x) = fS (x) /

S

|

|

be fS (x) normalized to have

fS

= 1.

b

Theorem 86 For all constants ε
with probability Ω (1) over S.

p

[0, 1), if S is drawn from

E

∈

2

2
(cid:13)
(cid:13)
(cid:13)
, then MFSε

(cid:13)
(cid:13)
(cid:13) b

fS

= nΩ(log n)

(cid:17)

(cid:16)

b

Proof. As in Theorem 83, we look at the matrix MS

P induced by a random
partition P = (y, z). We already know that for at least an 0.04 fraction of S’s, the y and
z variables are in one-to-one correspondence for at least an 0.04 fraction of P ’s.
In that
= I/2n/4 where I is the
case
ε,
MS

= 2n/2, and therefore MS
It follows from Lemma 85 that for all matrices M such that

P is a permutation of I/

|
identity.

S
|

S
|

M

P

|

|

|

p

−

|

2
2 ≤

rank (M )

2n/2

−

≥

S

|

M

MS

P

|

−

|
p

(cid:13)
(cid:13)
(cid:13)

(cid:0)

ε) 2n/2. Hence

(cid:13)
(cid:13)
ε) 2n/2

(1

−

(cid:13)
(cid:13)

2

2 ≥

(cid:1)(cid:13)
(cid:13)
(cid:13)

and therefore rankε

MS

P

|

(1

−

≥

(cid:0)

(cid:1)
Pr
P
∈P h

rankε

Mf

P

|

≥

2n/2
−

(n/2)1/8/2

0.04,

≥

i

(cid:1)
and the result follows from Corollary 81.

(cid:0)

A corollary of Theorem 86 and of Theorem 73, part (iii), is that TSε (
|

nΩ(log n) with probability Ω (1) over S, for all ε < 1.

S

) =
i

Finally, let me show how to derandomize the lower bound for subgroup states,
In the proof of Theorem 83, all we
k submatrix has full rank with Ω (1)
log2 n, then

using ideas pointed out to me by Andrej Bogdanov.
needed about the matrix A was that a random k
probability, where k = n/2.
it is easy to construct explicit k

×
If we switch from the ﬁeld F2 to F2d for some d

n matrices with this same property. For example, let

≥

×

11
10
21
20
...
...
n0 n1

· · ·
· · ·

· · ·

V = 





1

1

−

−

1k
2k
...
nk

−








1

×

k Vandermonde matrix, where 1, . . . , n are labels of elements in F2d. Any k

k
be the n
submatrix of V has full rank, because the Reed-Solomon (RS) code that V represents is
a perfect erasure code.6 Hence, there exists an explicit state of n “qupits” with p = 2d
that has tree size nΩ(log n)—namely the uniform superposition over all elements of the set

×

145

V T x = 0

, where V T is the transpose of V .

x

|

(cid:9)

To replace qupits by qubits, we concatenate the RS and Hadamard codes to obtain
(cid:8)
a binary linear erasure code with parameters almost as good as those of the original RS
code. More explicitly, interpret F2d as the ﬁeld of polynomials over F2, modulo some
F2d to
irreducible of degree d. Then let m (a) be the d
×
F2d, where q and aq are encoded by their d
1 vectors of coeﬃcients. Let H map
aq
a length-d vector to its length-2d Hadamard encoding. Then Hm (a) is a 2d
d Boolean
kd
matrix that maps q
∈
“binary Vandermonde matrix” as follows:

F2d to the Hadamard encoding of aq. We can now deﬁne an n2d

d Boolean matrix that maps q

×

×

×

∈

∈

10
Hm
20
Hm
(cid:0)
(cid:1)
...
(cid:0)
(cid:1)
n0

Hm

11
21

Hm
Hm
(cid:0)
(cid:1)
...
(cid:0)
(cid:1)
n1

Hm

Hm
Hm

Hm

· · ·
· · ·

· · ·

1k
2k
(cid:0)
...
(cid:0)
nk

1

1

−

−

−

Vbin = 







.






(cid:1)
(cid:1)
1

(cid:1)

For the remainder of the section, ﬁx k = nδ for some δ < 1/2 and d = O (log n).

(cid:0)

(cid:1)

(cid:0)

(cid:1)

(cid:0)

Lemma 87 A (kd + c)
(that is, full rank) with probability at least 2/3, for c a suﬃciently large constant.

kd submatrix of Vbin chosen uniformly at random has rank kd

×

|

Vbinu

2 , where

Proof. The ﬁrst claim is that

(n
∈
represents the number of ‘1’ bits. To see this, observe that for all nonzero u,
k nonzero entries by the Fundamental
2d. Furthermore, the

Fkd
|
the “codeword vector” V u
Theorem of Algebra, where here u is interpreted as an element of Fk
Hadamard code maps any nonzero entry in V u to 2d
Now let W be a uniformly random (kd + c)

1 nonzero bits in Vbinu
kd submatrix of Vbin. By the above

Fn
2d must have at least n

1 for all nonzero vectors u

Fn2d
2

k) 2d

| ≥

−

−

∈

∈

−

−

|

.

claim, for any ﬁxed nonzero vector u

[W u = 0]

Pr
W

1

−

≤

(cid:18)

∈

(n

Fkd
2 ,

×

k) 2d
n2d

−

−

kd+c

1

(cid:19)

1
2

+

k
2n

=

(cid:18)

(cid:19)

kd+c

.

So by the union bound, W u is nonzero for all nonzero u (and hence W is full rank) with
probability at least

2kd

1

−

(cid:18)

1
2

+

k
2n

(cid:19)

kd+c

1 +

k
n

= 1

−

(cid:18)

kd

(cid:19)

(cid:18)

1
2

+

k
2n

c

.

(cid:19)

Ω(1) and d = O (log n), the above quantity is at least 2/3 for suﬃciently

Since k = n1/2
large c.

−

Given an n2d

otherwise. Then:

×

1 Boolean vector x, let f (x) = 1 if V T

binx = 0 and f (x) = 0

6In other words, because a degree-(k

−

1) polynomial is determined by its values at any k points.

Theorem 88 MFS (f ) = nΩ(log n).

146

Proof. Let Vy and Vz be two disjoint kd

bin chosen
uniformly at random. Then by Lemma 87 together with the union bound, Vy and Vz both
have full rank with probability at least 1/3. Letting ℓ = kd + c, it follows that

(kd + c) submatrices of V T

×

Pr
∈Rℓ

R

h

rank

Mf

c

2ℓ

−

R

|

≥

(cid:0)

(cid:1)

= n−

o(log n)

1
3

≥

i

by the same reasoning as in Theorem 83. Therefore MFS (f ) = nΩ(log n) by Corollary 82.

Let

S
|
of Theorem 88 is that TS (
S
can also show that TSε (
|

i

be a uniform superposition over all x such that f (x) = 1; then a corollary
) = nΩ(log n). Naturally, using the ideas of Theorem 86 one
i

S
|
) = nΩ(log n) for all ε < 1.
i

13.5.2 Shor States

Since the motivation for this work was to study possible Sure/Shor separators, an obvious
question is, do states arising in Shor’s algorithm have superpolynomial tree size? Unfortu-
nately, I am only able to answer this question assuming a number-theoretic conjecture. To
formalize the question, let

1
2n/2

2n

1

−

r=0
X

r
|

xr mod N

i |

i

be a Shor state.
the ﬁrst register has the form

It will be convenient to measure the second register, so that the state of

a + pZ
|

i

=

I

1
√I

a + pi
i

|

for some integers a < p and I =
−
n bits. Clearly a lower bound on TS (
|
the joint state of the two registers.

(2n
⌊

Xi=0
. Here a+pi is written out in binary using
⌋
) would imply an equivalent lower bound for
i

1) /p

a
−
a + pZ

To avoid some technicalities, assume p is prime (since the goal is to prove a lower
1 . . . x0,
) =
i

bound, this assumption is without loss of generality). Given an n-bit string x = xn
let fn,p,a (x) = 1 if x
Θ (MFS (fn,p,a)) by Theorem 73, so from now on we will focus attention on fn,p,a.

−
a + pZ
a (mod p) and fn,p,a (x) = 0 otherwise. Then TS (
|

≡

Proposition 89

(i) Let fn,p = fn,p,0. Then MFS (fn,p,a)

a = 0 without loss of generality.

≤

MFS (fn+log p,p), meaning that we can set

(ii) MFS (fn,p) = O (min

n2n/p, np

).
}

{

Proof.

147

(i) Take the formula for fn+log p,p, and restrict the most signiﬁcant log p bits to sum
2nx is an

a mod p (this is always possible since x

to a number congruent to
isomorphism of Zp).

−

→

(ii) For MFS (fn,p) = O (n2n/p), write out the x’s for which fn,p (x) = 1 explicitly. For
MFS (fn,p) = O (np), use the Fourier transform, similarly to Theorem 78, part (v):

fn,p (x) =

1
p

1

n

p

−

1

−

Xh=0

Yj=0

2πih
p

·

exp

(cid:18)

2jxj

.

(cid:19)

This immediately yields a sum-of-products formula of size O (np).

I now state the number-theoretic conjecture.

Conjecture 90 There exist constants γ, δ
following holds. Let the set A consist of nδ elements of
random. Let S consist of all 2nδ
Then

2nδ
(cid:16)
chosen uniformly at
.
sums of subsets of A, and let S mod p =
}

(0, 1) and a prime p = Ω

for which the

20, . . . , 2n

x mod p : x

∈

∈

S

(cid:17)

(cid:9)

(cid:8)

{

−

1

Pr
A

S mod p

|

| ≥

(1 + γ)

h

p
2

i

= n−

o(log n).

Theorem 91 Conjecture 90 implies that MFS (fn,p) = nΩ(log n) and hence TS (
nΩ(log n).

pZ
|

) =
i

Proof. Let f = fn,p and ℓ = nδ. Let R be a restriction of f that renames 2ℓ
2ℓ variables to 0 or 1. This
variables y1, . . . , yℓ, z1, . . . , zℓ, and sets each of the remaining n
−
0 (mod p) and 0 otherwise for
leads to a new function, fR (y, z), which is 1 if y + z + c
+ 2bℓ zℓ
some constant c. Here we are deﬁning y = 2a1y1 +
where a1, . . . , aℓ, b1, . . . , bℓ are the appropriate place values. Now suppose y mod p and
n.
z mod p both assume at least (1 + γ) p/2 distinct values as we range over all x
Then by the pigeonhole principle, for at least γp possible values of y mod p, there exists a
0 (mod p) and hence fR (y, z) = 1.
unique possible value of z mod p for which y + z + c
So rank
It
γp, where Mf
follows that assuming Conjecture 90,

2ℓ matrix whose (y, z) entry is fR (y, z).

+ 2aℓ yℓ and z = 2b1z1 +

R is the 2ℓ

0, 1
}

∈ {

Mf

· · ·

· · ·

≡

≡

×

≥

R

|

|

(cid:0)

(cid:1)

Pr
∈Rℓ

R

rank

Mf

R

|

≥

γp

= n−

o(log n).

(cid:2)

(cid:0)

(cid:1)

(cid:3)

ℓ1/8/2 for suﬃciently large n since p = Ω

Furthermore, γp
nΩ(log n) by Corollary 82.

≥

−

2ℓ

2nδ
(cid:16)

. Therefore MFS (f ) =

(cid:17)

Using the ideas of Theorem 86, one can show that under the same conjecture,
) = nΩ(log n) for all ε < 1—in other words, there exist
i

MFSε (fn,p) = nΩ(log n) and TSε (
pZ
|
Shor states that cannot be approximated by polynomial-size trees.

Originally, I had stated Conjecture 90 without any restriction on how the set S
is formed. The resulting conjecture was far more general than I needed, and indeed was
falsiﬁed by Carl Pomerance (personal communication).

13.5.3 Tree Size and Persistence of Entanglement

148

In this section I pursue a deeper understanding of the tree size lower bounds, by discussing
a physical property of quantum states that is related to error-correction as well as to super-
polynomial tree size. D¨ur and Briegel [100] call a quantum state “persistently entangled,”
if (roughly speaking) it remains highly entangled even after a limited amount of interaction
/√2 is
with its environment. As an illustration, the Schr¨odinger cat state
in some sense highly entangled, but it is not persistently entangled, since measuring a single
qubit in the standard basis destroys all entanglement.

0
i
|
(cid:0)

1
i
|

n +

(cid:1)

⊗

⊗

n

By contrast, consider the “cluster states” deﬁned by Briegel and Raussendorf
[71]. These states have attracted a great deal of attention because of their application
to quantum computing via 1-qubit measurements only [194]. For our purposes, a two-
√n array of
dimensional cluster state is an equal superposition over all settings of a √n
1)r, where r is the number of horizontally or
bits, with each basis state having a phase of (
−
vertically adjacent pairs of bits that are both ‘1’. D¨ur and Briegel [100] showed that such
states are persistently entangled in a precise sense: one can distill n-partite entanglement
from them even after each qubit has interacted with a heat bath for an amount of time
independent of n.

×

Persistence of entanglement seems related to how one shows tree size lower bounds
using Raz’s technique. For to apply Corollary 82, one basically “measures” most of a state’s
qubits, then partitions the unmeasured qubits into two subsystems of equal size, and argues
that with high probability those two subsystems are still almost maximally entangled. The
connection is not perfect, though. For one thing, setting most of the qubits to 0 or 1
uniformly at random is not the same as measuring them. For another, Theorem 80 yields
nΩ(log n) tree size lower bounds without the need to trace out a subset of qubits.
It suﬃces
for the original state to be almost maximally entangled, no matter how one partitions it
into two subsystems of equal size.

But what about 2-D cluster states—do they have tree size nΩ(log n)?

I strongly
conjecture that the answer is ‘yes.’ However, proving this conjecture will almost certainly
require going beyond Theorem 80. One will want to use random restrictions that respect
the 2-D neighborhood structure of cluster states—similar to the restrictions used by Raz
[195] to show that the permanent and determinant have multilinear formula size nΩ(log n).
I end this section by showing that there exist states that are persistently entangled
in the sense of D¨ur and Briegel [100], but that have polynomial tree size.
In particular,
D¨ur and Briegel showed that even one-dimensional cluster states are persistently entangled.
On the other hand:

Proposition 92 Let

=

ψ
|

i

1
2n/2

n

0,1
Xx
∈{

}

1)x1x2+x2x3+

(

−

+xn

···

−

1xn

.

x
i
|

Then TS (

ψ
|

i

) = O

n4

.

(cid:1)
Proof. Given bits i, j, k, let

(cid:0)

P ijk
n
(cid:12)
(cid:12)
(cid:12)

E

be an equal superposition over all n-bit strings

149

,

.









x1 . . . xn such that x1 = i, xn = k, and x1x2 +

+ xn

1xn ≡

−

· · ·

j (mod 2). Then

P i0k
n
(cid:12)
(cid:12)
(cid:12)
P i1k
n
(cid:12)
(cid:12)
(cid:12)

E

E

=

=

1
√8 



1
√8 

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

P i00
n/2
P i01
n/2

(cid:12)
P i00
(cid:12)
n/2
(cid:12)
P i01
n/2

P 00k
n/2
E
P 00k
n/2

E (cid:12)
(cid:12)
(cid:12)
E (cid:12)
P 01k
(cid:12)
n/2
(cid:12)
E
P 01k
n/2

E (cid:12)
(cid:12)
(cid:12)
E (cid:12)
(cid:12)
(cid:12)
16 TS

+

E
+

(cid:12)
+
(cid:12)
(cid:12)

(cid:12)
+
(cid:12)
(cid:12)

≤

E

(cid:12)
(cid:12)
P ijk
(cid:12)
n/2

+

E
+

P i10
n/2
P i11
n/2

(cid:12)
P i10
(cid:12)
n/2
(cid:12)
P i11
n/2

P 01k
n/2
E
P 01k
n/2

E (cid:12)
(cid:12)
(cid:12)
E (cid:12)
P 00k
(cid:12)
n/2
(cid:12)
E
P 00k
n/2

+

E
+

P 10k
n/2
E
P 11k
n/2

E (cid:12)
(cid:12)
(cid:12)
E (cid:12)
P 11k
(cid:12)
n/2
(cid:12)
E
P 10k
n/2

P i00
n/2
(cid:12)
P i01
+
(cid:12)
n/2
(cid:12)
(cid:12)
P i00
(cid:12)
n/2
(cid:12)
(cid:12)
P i01
+
(cid:12)
n/2
(cid:12)
(cid:12)
(cid:12)
(cid:12)

+

E
+

P 11k
n/2
E
P 10k
n/2

E (cid:12)
(cid:12)
(cid:12)
E (cid:12)
P 10k
(cid:12)
n/2
(cid:12)
E
P 11k
n/2

P i10
n/2
(cid:12)
P i11
+
(cid:12)
n/2
(cid:12)
(cid:12)
P i10
(cid:12)
n/2
(cid:12)
(cid:12)
P i11
+
(cid:12)
n/2
(cid:12)
(cid:12)
(cid:12)
(cid:12)

E (cid:12)
(cid:12)
(cid:12)
E (cid:12)
E
(cid:12)
(cid:12)
, and solving this recurrence relation yields

E (cid:12)
(cid:12)
(cid:12)
E (cid:12)
(cid:12)
(cid:12)

E (cid:12)
(cid:12)
(cid:12)
E (cid:12)
(cid:12)
(cid:12)

E

E

(cid:12)

(cid:12)
P ijk
(cid:12)
n

Therefore TS

E(cid:17)

(cid:16)(cid:12)
(cid:12)
(cid:12)

Finally observe that

(cid:16)(cid:12)
(cid:12)
(cid:12)
TS

E(cid:17)
P ijk
n

(cid:16)(cid:12)
(cid:12)
(cid:12)

= O

n4

.

E(cid:17)

(cid:0)

(cid:1)

|

1
+
0
i
|
i
√2

=

ψ
|

i

(cid:18)

n

⊗

P 010
n

+

P 011
n

(cid:19)

− (cid:12)
(cid:12)

(cid:11)

(cid:12)
(cid:12)

P 110
n

+
√2
(cid:12)
(cid:11)
(cid:12)

+

P 111
n

(cid:11)

(cid:12)
(cid:12)

.

(cid:11)

13.6 Manifestly Orthogonal Tree Size

This section studies the manifestly orthogonal tree size of coset states:7 states having the
form

=

C
|

i

1

C
|

C
| Xx
∈

x
i
|

|

b

}

≡

p

is a coset in Zn

Ax

C
|

2 . In particular, I present a tight characterization of
x
where C =
{
MOTS (
), which enables me to prove exponential lower bounds on it, in contrast to the
C
i
|
nΩ(log n) lower bounds for ordinary tree size. This characterization also yields a separation
between orthogonal and manifestly orthogonal tree size; and an algorithm for computing
) whose complexity is only singly exponential in n. My proof technique is
MOTS (
i
independent of Raz’s, and is highly tailored to take advantage of manifest orthogonality.
However, even if this technique ﬁnds no other application, it has two features that I hope will
make it of independent interest to complexity theorists. First, it yields tight lower bounds,
and second, it does not obviously “naturalize” in the sense of Razborov and Rudich [200].
Rather, it takes advantage of certain structural properties of coset states that do not seem
to hold for random states.

|

i

ψ

Given a state

minimum size of a tree representing
with “disjoint supports”—that is, either
T
x
i
|
|
7All results apply equally well to the subgroup states of Section 13.5.1; the greater generality of coset

, recall that the manifestly orthogonal tree size MOTS (
) is the
, in which all additions are of two states
ψ2i
= 0 for every basis state
x
ψ2|
i
h
of T is the number of leaf vertices. We can assume without loss

. Here the size

ψ
|
i
ψ1i
|

x
ψ1|
i

= 0 or

ψ
|

i

h

,

|

|

states is just for convenience.

of generality that every + or
vertex is a

⊗

vertex and vice versa. Also, given a set S

vertex has at least one child, and that every child of a +
0, 1
}

n, let

⊆ {

⊗

150

=

S

|

i

1

S
|

x
i
|

S
| Xx
∈

p

be a uniform superposition over the elements of S, and let M (S) := MOTS (

1, . . . , n

Let C =

x : Ax
{

2. Let
, and let (I, J) be a nontrivial partition of [n] (one where I and J are both
}
in the I subsystem, and

≡
[n] =
nonempty). Then clearly there exist distinct cosets C (1)
distinct cosets C (1)

∈
, . . . , C (H)

in the J subsystem, such that

2 , for some A

be a subgroup in Zn

Zk

}

{

×

b

I

I

Zk
2

n

J , . . . , C (H)

J

).
S
i
|
and b
∈

C =

[H]
[h
∈

C (h)

I ⊗

C (h)
J .

’s and C (h)

J ’s are unique up to ordering. Furthermore, the quantities

The C (h)
I
C (h)
I

,

C (h)
I
(cid:12)
(cid:12)
(cid:12)

,

C (h)
J
(cid:12)
(cid:12)
(cid:12)

(cid:16)

(cid:16)

C (h)
J

, and M

M
suppress the dependence on h when mentioning them.

remain unchanged as we range over h

(cid:17)
For various sets S, the strategy will be to analyze M (S) /

, the ratio of tree size
|
to cardinality. We can think of this ratio as the “price per pound” of S: the number of
vertices that we have to pay per basis state that we cover. The following lemma says that,
under that cost measure, a coset is “as good a deal” as any of its subsets:

(cid:12)
[H]. For this reason I
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

∈

S

(cid:17)

|

Lemma 93 For all cosets C,

where the minimum is over nonempty S

M (C)
C
|

|

M (S)
S
|

| (cid:19)

(cid:18)

= min

C.

⊆

Proof. By induction on n. The base case n = 1 is obvious, so assume the lemma
. Let T be a manifestly orthogonal
1. Choose S∗ ⊆
|
of minimum size, and let v be the root of T . We can assume without loss of
S∗
. Therefore for some nontrivial partition (I, J) of [n],

C to minimize M (S∗) /

child representing a set R

⊂

true for n
−
tree for
S∗i
|
generality that v is a
⊗
such that M (R) /
R
| ≤
|
I
0, 1
and some S∗I ⊆ {
|
}

S∗|
vertex, since otherwise v has some
S∗|
M (S∗) /
|
0, 1
| and S∗J ⊆ {
}
S∗
=
i
S∗

S∗I i ⊗ |
|
S∗J |
S∗I | |
|
M (S∗) = M (S∗I ) + M (S∗J ) ,

|, we have

S∗J i
,

J
|

⊗

=

|

|

,

|

where the last equality holds because if M (S∗) < M (S∗I ) + M (S∗J ), then T was not a
minimal tree for

. Then

S∗i
|
M (S∗)
S∗|

|

=

M (S∗I ) + M (S∗J )

S∗I

S∗J

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

= min

(cid:18)

M (SI) + M (SJ )
SI| |

SJ |

|

(cid:19)

I
where the minimum is over nonempty SI ⊆ {
0, 1
|
}
C (h)
C. Now there must be an h such that S∗I ⊆
I
x /
∈

| and SJ ⊆ {
and S∗J ⊆

C would be assigned nonzero amplitude. By the induction hypothesis,

151

J
0, 1
| such that SI ⊗
SJ ⊆
|
}
C (h)
J , since otherwise some

,

(cid:18)

= min

M (CI )
CI |
|

M (SI)
SI | (cid:19)
|

M (CJ )
CJ |
|
and SJ ⊆
/M (SI ). Then since setting SI := C (h)
SI |
SJ |·|
|
,
SJ |
,
SI |
|
|

respectively. Deﬁne β =
where the minima are over nonempty SI ⊆
and SJ := C (h)
SI |·|
J
|
maximizes the four quantities
/M (SJ ) simultaneously, this
choice also maximizes β and γ simultaneously. Therefore it maximizes their harmonic
mean,

M (SJ )
SJ | (cid:19)

/M (SJ ) and γ =

/M (SI), and

C (h)
J

C (h)
I

= min

SJ |

SJ |

SI|

(cid:18)

|

|

|

,

I

βγ
β + γ

=

|

SJ |

SI| |
M (SI) + M (SJ )
C (h)

= |

S
|
M (S)

.

We have proved that setting S := C (h)
imizes M (S) /
C (h)
C (h)
J
minimizes M (S) /

/M (S), or equivalently min-
. The one remaining observation is that taking the disjoint sum of
|
unchanged. So setting S := C also
S
|

S
|
over all h
S

[H] leaves the ratio M (S) /

J maximizes

I ⊗

I ⊗

S
|

|

|

∈
, and we are done.
|

|

I can now give a recursive characterization of M (C).

Theorem 94 If n

2, then

≥

M (C) =

min

C
|

|

M (CI ) + M (CJ )
CI | |
|

CJ |

(cid:19)

(cid:18)

where the minimum is over nontrivial partitions (I, J) of [n].

manifestly orthogonal tree for

Proof. The upper bound is obvious; let us prove the lower bound. Let T be a
of minimum size, and let v(1), . . . , v(L) be the topmost
of C such that the subtree

vertices in T . Then there exists a partition

S(1), . . . , S(L)

C
|

i

⊗
rooted at v(i) represents

S(i)

. We have

(cid:0)

(cid:1)

= M

S(1)

+

T
|

|

(cid:11)
+ M

S(L)

=

(cid:12)
(cid:12)
· · ·

M

S(1)

S(1)
(cid:0)

(cid:1)

+

· · ·

+

S(1)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

S(L)
(cid:12)
(cid:12)
(cid:12)

M

S(L)

S(L)
(cid:0)

.

(cid:1)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
R(1), . . . , R(H)
(cid:12)

(cid:12)
(cid:12)

(cid:16)

(cid:17)

Now let η = mini
C such that M
T
T ′| ≤ |
|
expresses

(cid:17)
S(i)
M
/
R(h)
R(h)
(cid:0)
(cid:1)
[L] such that M
. Choose j
(cid:12)
(cid:12)
(cid:1)
(cid:0)
|
∈
(cid:12)
(cid:12)
S(j)
SJ i
SI i ⊗ |
as
|

(cid:16)
S(i)
= η for all h
(cid:12)
(cid:12)

(cid:12)
(cid:1)
(cid:12)

/
(cid:0)

(cid:0)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

. We will construct a partition

of
[H], which will imply a new tree T ′ with
(cid:0)
= η, and suppose vertex v(j) of T
/

(cid:1)

∈
S(j)

S(j)
for some nontrivial partition (I, J). Then

(cid:12)
(cid:12)

(cid:11)

M

S(j)

=

η =

M (SI) + M (SJ )
SI | |
|
= M (SI) + M (SJ ) follows from the minimality of T . As in Lemma 93,
C (h)
J . But Lemma 93 then implies that

(cid:12)
(cid:12)
C (h)
I

S(j)
(cid:0)

SJ |

(cid:1)

and SJ ⊆

S(j)

(cid:12)
where M
(cid:12)
there must be an h such that SI ⊆

(cid:0)

(cid:1)

(cid:1)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

152

. Combining these

|

M (CI ) /
bounds with

CI | ≤
M (SI) /
CI | ≥ |
SI |
|
M (CI ⊗
CI ⊗
|
So setting R(h) := C (h)
by the minimality of T ,

I ⊗

and that M (CJ ) /
SI|
|
SJ |
CJ | ≥ |
and
|

CJ )
CJ |

M (CI ) + M (CJ )
CI | |
|

≤

C (h)
J

for all h

∈

CJ | ≤

|

M (SJ ) /

SJ |

|

, we obtain by a harmonic mean inequality that

M (S∗I ) + M (S∗J )

= η.

≤

CJ |
(cid:12)
[H] yields a new tree T ′ no larger than T . Hence
(cid:12)

S∗I
(cid:12)
(cid:12)

S∗J
(cid:12)
(cid:12)

(cid:12)
(cid:12)

M (C) =

T
|

|

=

T ′

= H

M (CI ⊗

·

(cid:12)
(cid:12)

(cid:12)
(cid:12)

C
CJ ) = |
|
CJ |
CI | |
|

·

(M (CI ) + M (CJ )) .

One can express Theorem 94 directly in terms of the matrix A as follows. Let
(the vector b is irrelevant, so long

x : Ax

b

M (A) = M (C) = MOTS (
C
|
b is solvable). Then
as Ax

) where C =
i

{

≡

}

≡

M (A) = min

2rank(AI )+rank(AJ )
(cid:16)

rank(A) (M (AI ) + M (AJ ))

−

(*)

(cid:17)

where the minimum is over all nontrivial partitions (AI , AJ ) of the columns of A. As a
base case, if A has only one column, then M (A) = 2 if A = 0 and M (A) = 1 otherwise.
This immediately implies the following.

Corollary 95 There exists a deterministic O (n3n)-time algorithm that computes M (A),
given A as input.

Proof. First compute rank (A∗) for all 2n

1 matrices A∗ that are formed by
choosing a subset of the columns of A. This takes time O
. Then compute M (A∗)
for all A∗ with one column, then for all A∗ with two columns, and so on, applying the
formula (*) recursively. This takes time

n32n

(cid:1)

(cid:0)

−

n

Xt=1 (cid:18)

n
t

(cid:19)

t2t = O (n3n) .

in NP.

Another easy consequence of Theorem 94 is that the language
I do not know whether this language is NP-complete but suspect it is.
As mentioned above, my characterization makes it possible to prove exponential

A : M (A)

≤

is

{

}

s

lower bounds on the manifestly orthogonal tree size of coset states.

Theorem 96 Suppose the entries of A

random, where k
over A.

∈

h

4 log2 n, 1
2

√n ln 2

i

n

Zk
2

×

∈

are drawn uniformly and independently at
Ω(k) with probability Ω (1)

n/k2

. Then M (A) =

(cid:0)

(cid:1)

Proof. Let us upper-bound the probability that certain “bad events” occur when
A is drawn. The ﬁrst bad event is that A contains an all-zero column. This occurs
d
with probability at most 2−

kn = o (1). The second bad event is that there exists a k

×

submatrix of A with d
o (1). For we claim that, if A∗ is drawn uniformly at random from Zk
2

12k that has rank at most 2k/3. This also occurs with probability

d

×

, then

≥

[rank (A∗)

Pr
AI

r]

≤

≤

(cid:18)

d
r

(cid:19) (cid:18)

r

d

−

.

2r
2k

(cid:19)

153

To see this, imagine choosing the columns of A∗ one by one. For rank (A∗) to be at most r,
there must be at least d
r columns that are linearly dependent on the previous columns.
But each column is dependent on the previous ones with probability at most 2r/2k. The
d submatrix of
claim then follows from the union bound. So the probability that any k
A has rank at most r is at most

×

−

(cid:18)
Set r = 2k/3 and d = 12k; then the above is at most

(cid:19) (cid:18)

(cid:19)(cid:18)

(cid:19)

n
d

d
r

r

d

−

2r
2k

nddr

≤

r

d

−

.

2r
2k

(cid:18)

(cid:19)

exp

12k log n +

(cid:26)

2k
3

log (12k)

12k

−

(cid:18)

2k
3

−

k
3

(cid:27)

(cid:19)

= o (1)

where we have used the fact that k

4 log n.

≥

A(0)
I

be a partition of the

, A(0)
Assume that neither bad event occurs, and let
J
columns of A that minimizes the expression (*). Let A(1) = A(0)
(cid:17)
I
A(1) = A(0)

J otherwise, where

A(0)
I
(cid:12)
A(0)
A(0)
respectively (so that
(cid:12)
J
I
(cid:12)
(cid:12)
(cid:12)
of the columns of A(1), and let A(2) = A(1)
(cid:16)
(cid:12)
(cid:12)
I
≥
(cid:12)
(cid:12)
Continue in this way until an A(t) is reached such that
consequence of (*) is that M (A)

(cid:12)
= n). Likewise, let
(cid:12)
(cid:12)
if

A(1)
I
(cid:12)
(cid:12)
(cid:12)
Z (t

(cid:12)
are the numbers of columns in A(0)
(cid:12)
I
(cid:12)
, A(1)
J
and A(2) = A(1)
J
= 1. Then an immediate

be an optimal partition

otherwise.

A(0)
and
J
(cid:12)
and A(0)
(cid:12)
J
(cid:12)

A(0)
I
(cid:12)
(cid:12)
(cid:12)

A(0)
J

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

Z (0)

and

+

≥

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:17)

(cid:16)

if

−

A(1)
I
A(1)
J
A(t)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
1) where
(cid:12)
(cid:12)
(cid:12)
(cid:12)
rank(A(ℓ))

−

≥
Z (ℓ) = 2

· · · · ·

rank

A(ℓ)
I

+rank

A(ℓ)
J

(cid:16)

(cid:17)

(cid:16)

(cid:17)

and A(0) = A.

A(ℓ)
I

A(ℓ)
J

Z (ℓ)

otherwise.

Call ℓ a “balanced cut” if min

If ℓ is a balanced cut, then rank

12k, and an “unbalanced cut”
≥
A(ℓ)
2k/3 and rank
J
A(ℓ)
(cid:16)
I
A(ℓ+1)
(cid:17)
(cid:16)
. There can be at most k freebies, since for each one, rank

=
A(ℓ)
(cid:17)
rank
by the assumption that all columns of A are nonzero. For the other unbalanced cuts,
(cid:1)
Z (ℓ)

2k/3. If ℓ is an unbalanced cut, then call ℓ a “freebie” if rank
A(ℓ)

2k/3, so
A(ℓ)
J

,
(cid:12)
(cid:12)
A(ℓ)
(cid:12)
(cid:12)
I
(cid:12)
(cid:12)
(cid:16)

≥
(cid:17)
+ rank

< rank

n(cid:12)
(cid:12)
(cid:12)

(cid:12)
o
(cid:12)
≥
(cid:12)

≥

2.

(cid:17)

(cid:16)

(cid:1)

(cid:0)

(cid:0)

(cid:1)

A(ℓ+1)

Assume

A(ℓ)
each unbalanced cut. Then if the goal is to minimize Z (0)
(cid:12)
(cid:12)
· · · · ·
(cid:12)
(cid:12)
strategy is to perform balanced cuts ﬁrst, then unbalanced cuts until
point we can use the k freebies. Let B be the number of balanced cuts; then

/2 for each balanced cut and

A(ℓ+1)
Z (t

=
12k for
−
1), clearly the best
−
(cid:12)
(cid:12)
(cid:12)
= 12k2, at which
A(ℓ)
(cid:12)
(cid:12)
(cid:12)

A(ℓ)

=

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:0)
≥

Z (0)

· · · · ·

Z (t
−

1) =

2k/3
(cid:16)

B

(cid:17)

2(n/2B

12k2)/12k.

−

(cid:12)
(cid:12)

(cid:12)
(cid:12)

This is minimized by taking B = log2

n ln 2
4k2

, in which case Z (0)

Z (t

−

1) =

n/k2

Ω(k).

· · · · ·

154

(cid:0)

(cid:1)

(cid:0)

(cid:1)

A ﬁnal application of my characterization is to separate orthogonal from manifestly

C
|

)
i

≤

orthogonal tree size.

Corollary 97 There exist states with polynomially-bounded orthogonal tree size, but man-
ifestly orthogonal tree size nΩ(log n). Thus OTree

= MOTree.

Proof. Set k = 4 log2 n, and let C =

random from Zk
2

×

n

. Then by Theorem 96,

x : Ax

{

0
}

≡

where A is drawn uniformly at

MOTS (

C
|

) =
i

Ω(k)

n/k2

= nΩ(log n)

with probability Ω (1) over A. On the other hand, if we view
in the Fourier basis (that
is, apply a Hadamard to every qubit), then the resulting state has only 2k = n16 basis states
with nonzero amplitude, and hence has orthogonal tree size at most n17. So by Proposition
71, part (i), OTS (

2n17 as well.

C
|

i

(cid:0)

(cid:1)

Indeed, the orthogonal tree states of Corollary 97 are superpositions over polyno-

mially many separable states, so it also follows that Σ2

MOTree.

6⊂

13.7 Computing With Tree States

Suppose a quantum computer is restricted to being in a tree state at all times.
(We can
imagine that if the tree size ever exceeds some polynomial bound, the quantum computer
explodes, destroying our laboratory.) Does the computer then have an eﬃcient classical
simulation? In other words, letting TreeBQP be the class of languages accepted by such a
machine, does TreeBQP = BPP? A positive answer would make tree states more attractive
as a Sure/Shor separator. For once we admit any states incompatible with the polynomial-
time Church-Turing thesis, it seems like we might as well go all the way, and admit all
states preparable by polynomial-size quantum circuits! The TreeBQP versus BPP problem is
closely related to the problem of ﬁnding an eﬃcient (classical) algorithm to learn multilinear
In light of Raz’s lower bound, and of the connection between lower bounds and
formulas.
learning noticed by Linial, Mansour, and Nisan [166], the latter problem might be less
In this section I show a weaker result: that TreeBQP is contained in
hopeless than it looks.
ΣP
3 , the third level of the polynomial hierarchy. Since BQP is not known to lie in PH,
this result could be taken as weak evidence that TreeBQP
= BQP. (On the other hand, we
do not yet have oracle evidence even for BQP

AM, though not for lack of trying [5].)

3 ∩

ΠP

6⊂

Deﬁnition 98 TreeBQP is the class of languages accepted by a BQP machine subject to
the constraint that at every time step t, the machine’s state
is exponentially close to
a tree state. More formally, the initial state is
(for an input
n and polynomial bound p), and a uniform classical polynomial-time algorithm
x
(cid:12)
generates a sequence of gates g(1), . . . , g(p(n)). Each g(t) can be either be selected from
(cid:12)
some ﬁnite universal basis of unitary gates (as will be shown in Theorem 99, part (i), the
choice of gate set does not matter), or can be a 1-qubit measurement. When we perform a

0, 1
}

(p(n)
(cid:11)

0
(cid:12)
i
|
(cid:12)

ψ(0)

ψ(t)

x
i

∈ {

⊗ |

=

n)

(cid:11)

−

⊗

6
6
155

measurement, the state evolves to one of two possible pure states, with the usual probabilities,
rather than to a mixed state. We require that the ﬁnal gate g(p(n)) is a measurement of
> p (n), then
the ﬁrst qubit.
the outcome of the ﬁnal measurement is chosen adversarially; otherwise it is given by the
(cid:0)(cid:12)
(cid:12)
usual Born probabilities. The measurement must return 1 with probability at least 2/3 if
the input is in the language, and with probability at most 1/3 otherwise.

If at least one intermediate state

had TS1/2Ω(n)

ψ(t)

ψ(t)

(cid:11)(cid:1)

(cid:12)
(cid:12)

(cid:11)

ψ(t)

Some comments on the deﬁnition: I allow

to deviate from a tree state by
an exponentially small amount, in order to make the model independent of the choice of
I allow intermediate measurements because otherwise it is unclear even how to
gate set.
simulate BPP.8 The rule for measurements follows the “Copenhagen interpretation,” in
the sense that if a qubit is measured to be 1, then subsequent computation is not aﬀected
by what would have happened were the qubit measured to be 0. In particular, if measuring
0 would have led to states of tree size greater than p (n), that does not invalidate the results
of the path where 1 is measured.

(cid:12)
(cid:12)

(cid:11)

The following theorem shows that TreeBQP has many of the properties one would

want it to have.

Theorem 99

(i) The deﬁnition of TreeBQP is invariant under the choice of gate set.

(ii) The probabilities (1/3, 2/3) can be replaced by any (p, 1

p) with 2−

2√log n

< p < 1/2.

−

(iii) BPP

TreeBQP

⊆
Proof.

BQP.

⊆

(i) The Solovay-Kitaev Theorem [153, 182] shows that given a universal gate set, one can
approximate any k-qubit unitary to accuracy 1/ε using k qubits and a circuit of size
O (polylog (1/ε)). So let
be a sequence of states, with
by applying a k-qubit unitary g(t) (where k = O (1)).
ψ(t
ψ(t)
(cid:11)
Then using a polynomial-size circuit, one can approximate each
to accuracy
(cid:12)
(cid:12)
(cid:12)
(cid:12)
1/2Ω(n), as in the deﬁnition of TreeBQP.
Furthermore, since the approximation
circuit for g(t) acts only on k qubits, any intermediate state
it produces satisﬁes
TS1/2Ω(n) (
by Proposition 71.

k4k TS1/2Ω(n)

produced from

ψ(0)
1)

ψ(p(n))

ϕ
i
|

, . . . ,

∈ H

ψ(t)

ψ(t

p(n)

−
(cid:12)
(cid:12)

⊗
2

(cid:12)
(cid:12)

(cid:12)
(cid:12)

1)

(cid:11)

(cid:11)

(cid:11)

(cid:11)

−

)

ϕ
i
|

≤

(cid:11)(cid:1)
(ii) To amplify to a constant probability, run k copies of the computation in tensor prod-
uct, then output the majority answer. By part (i), outputting the majority can
increase the tree size by a factor of at most 2k+1. To amplify to 2−
, observe
that the Boolean majority function on k bits has a multilinear formula of size kO(log k).
For let T h

h and 0 otherwise; then

k (x1, . . . , xk) equal 1 if x1 +

2√log n

(cid:0)(cid:12)
(cid:12)

+ xk ≥

· · ·

h

T h
k (x1, . . . , xk) = 1

−

1

T i
⌊

k/2
⌋

−

x1, . . . , x
⌊

k/2
⌋

T h
⌈

i
−
k/2
⌉

x
⌊

+1, . . . , xk
k/2
⌋

(cid:0)
8If we try to simulate BPP in the standard way, we might produce complicated entanglement between

(cid:0)

(cid:1)

the computation register and the register containing the random bits, and no longer have a tree state.

Yi=0 (cid:16)

,

(cid:1)(cid:17)

156

+ O (1), and solving this recurrence yields

so MFS

2h maxi MFS

T h
⌈

k/2
⌉

≤

T h
k
T k/2
(cid:0)
k
(cid:16)

(cid:17)

MFS
the tree size increases by at most a polynomial factor.

= kO(log k). Substituting k = 2√log n into kO(log k) yields nO(1), meaning
(cid:1)

(cid:16)

(cid:17)

(iii) To simulate BPP, just perform a classical reversible computation, applying a Hadamard
followed by a measurement to some qubit whenever we need a random bit. Since the
number of basis states with nonzero amplitude is at most 2, the simulation is clearly
in TreeBQP. The other containment is obvious.

Theorem 100 TreeBQP

ΣP

3 ∩

ΠP
3 .

⊆

⊆

ΠP

Proof. Since TreeBQP is closed under complement,

it suﬃces to show that
TreeBQP
3 . Our proof will combine approximate counting with a predicate to verify
the correctness of a TreeBQP computation. Let C be a uniformly-generated quantum cir-
be a sequence of binary measurement outcomes. We
cuit, and let M =
adopt the convention that after making a measurement, the state vector is not rescaled to
have norm 1. That way the probabilities across all ‘measurement branches’ continue to
be the sequence of unnormalized pure states under
sum to 1. Let

m(1), . . . , m(p(n))

, . . . ,

(cid:0)

(cid:1)

ψ(p(n))
M,x

(cid:12)
measurement outcome sequence M and input x, where
(cid:12)
(cid:12)

E

E

Also, let Λ (M, x) express that TS1/2Ω(n)

.
i
p (n) for every t. Then C accepts if

y,M,x |

p(n) α(t)
}

=

0,1

∈{

E

y

y

P

ψ(t)
M,x
(cid:12)
(cid:12)
(cid:12)

ψ(0)
M,x
(cid:12)
(cid:12)
(cid:12)

ψ(t)
M,x

≤

E(cid:17)

Wx =

(cid:16)(cid:12)
(cid:12)
(cid:12)

XM : Λ(M,x) Xy
}

0,1

∈{

p(n)

2

2
3

,

≥

α(p(n))
1y,M,x

−

1 (cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

1/3.

If we could compute each

while C rejects if Wx ≤
Λ (M, x)), we would then have a ΠP
2/3. This follows
since we can do approximate counting via hashing in AM
2 [131], and thereby verify
that an exponentially large sum of nonnegative terms is at least 2/3, rather than at most
1/3. The one further fact we need is that in our ΠP
) predicate, we can take the
existential quantiﬁer to range over tuples of ‘candidate solutions’—that is, (M, y) pairs
together with lower bounds β on

2 predicate expressing that Wx ≥

eﬃciently (as well as

α(p(n))
1y,M,x
(cid:12)
(cid:12)
(cid:12)
⊆

2 (

ΠP

∀∃

(cid:12)
(cid:12)
(cid:12)

.

α(p(n))
1y,M,x

(cid:12)
It remains only to show how we verify that Λ (M, x) holds and that
(cid:12)
(cid:12)

= β.
First, we extend the existential quantiﬁer so that it guesses not only M and y, but also a
sequence of trees T (0), . . . , T (p(n)), representing
respectively. Second,

α(p(n))
1y,M,x
(cid:12)
(cid:12)
(cid:12)

, . . . ,

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
p(n), we verify the following:

E

ψ(p(n))
M,x
(cid:12)
(cid:12)
(cid:12)

ψ(0)
M,x
(cid:12)
using the last universal quantiﬁer to range over
(cid:12)
(cid:12)
n)
b

(1) T (0) is a ﬁxed tree representing

(p(n)

y

−

⊗

0
i
|

E
0, 1
}
∈ {

.
x
i

⊗ |

equals its claimed value to Ω (n) bits of precision.

(2)

α(p(n))
1y,M,x

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

y

y,M,x =

(3) Let g(1), . . . , g(p(n)) be the gates applied by C. Then for all t and

y, if g(t) is unitary
then α(t)
to Ω (n) bits of precision. Here the right-hand side is a
sum of 2k terms (k being the number of qubits acted on by g(t)), each term eﬃciently
computable given T (t
1). Similarly, if g(t) is a measurement of the ith qubit, then
y,M,x = α(t
α(t)

ψ(t
−
M,x
(cid:12)
(cid:12)
(cid:12)
−
y,M,x if the ith bit of
−

y equals m(t), while α(t)

y,M,x = 0 otherwise.

g(t)

|·

E

b

b

1)

1)

h

b

157

b

b

b

b

In the proof of Theorem 100, the only fact about tree states I needed was that
AmpP; that is, there is a polynomial-time classical algorithm that computes the
. So if we deﬁne AmpP-BQP analogously to TreeBQP

Tree
amplitude αx of any basis state
except that any states in AmpP are allowed, then AmpP-BQP

x
i
|

⊆

ΣP

3 ∩

⊆

ΠP

3 as well.

13.8 The Experimental Situation

The results of this chapter suggest an obvious challenge for experimenters: prepare non-tree
states in the lab. For were this challenge met, it would rule out one way in which quantum
mechanics could fail, just as the Bell inequality experiments of Aspect et al. [37] did twenty
years ago. If they wished, quantum computing skeptics could then propose a new candidate
Sure/Shor separator, and experimenters could try to rule out that one, and so on. The
result would be to divide the question of whether quantum computing is possible into a
series of smaller questions about which states can be prepared.
In my view, this would aid
progress in two ways: by helping experimenters set clear goals, and by forcing theorists to
state clear conjectures.

However, my experimental challenge raises some immediate questions. In particu-
lar, what would it mean to prepare a non-tree state? How would we know if we succeeded?
Also, have non-tree states already been prepared (or observed)? The purpose of this section
is to set out my thoughts about these questions.

First of all, when discussing experiments, it goes without saying that we must
convert asymptotic statements into statements about speciﬁc values of n. The central
tenet of computational complexity theory is that this is possible. Thus, instead of asking
whether n-qubit states with tree size 2Ω(n) can be prepared, we ask whether 200-qubit states
with tree size at least (say) 280 can be prepared. Even though the second question does
not logically imply anything about the ﬁrst, the second is closer to what we ultimately
) = nΩ(log n) tells us little about
care about anyway. Admittedly, knowing that TS (
ψni
|
), especially since in Raz’s paper [195], the constant in the exponent
TS (
ψ200i
) or TS (
|
6 (though this can certainly be improved). Thus, proving tight
Ω (log n) is taken to be 10−
lower bounds for small n is one of the most important problems left open by this chapter.
In Section 13.6 I show how to solve this problem for the case of manifestly orthogonal tree
size.

ψ100i
|

A second objection is that my formalism applies only to pure states, but in reality
all states are mixed. However, there are several natural ways to extend the formalism to
mixed states. Given a mixed state ρ, we could minimize tree size over all puriﬁcations of
ρ, or minimize the expected tree size
), over
αi|
i |
all decompositions ρ =
.
ψi|

ψii
), or maximum maxi TS (
|

ψii h

i αi |

2 TS (

ψii
|

P

P

158

A third objection is a real quantum state might be a “soup” of free-wandering
fermions and bosons, with no localized subsystems corresponding to qubits. How can one
determine the tree size of such a state? The answer is that one cannot. Any complexity
measure for particle position and momentum states would have to be quite diﬀerent from the
measures considered in this chapter. On the other hand, the states of interest for quantum
Indeed, even if quantum information is
computing usually do involve localized qubits.
stored in particle positions, one might force each particle into two sites (corresponding to
In that case it again
0
|
i
becomes meaningful to discuss tree size.

), neither of which can be occupied by any other particle.

1
i
|

and

i

But how do we verify that a state with large tree size was prepared? Of course, if
is preparable by a polynomial-size quantum circuit, then assuming quantum mechanics
ψ
|
is valid (and assuming our gates behave as speciﬁed), we can always test whether a given
; then it suﬃces to test whether
state
ψ
or not. Let U map
i
|
n. However, in the experiments under discussion, the validity of
1
U −
quantum mechanics is the very point in question. And once we allow Nature to behave in
arbitrary ways, a skeptic could explain any experimental result without having to invoke
states with large tree size.

is close to
ϕ
i
is close to

ψ
i
|
0
⊗
i

|
ϕ
i

n to

0
i
|

⊗

|

|

The above fact has often been urged against me, but as it stands, it is no diﬀerent
from the fact that one could explain any astronomical observation without abandoning the
Ptolemaic system. The issue here is not one of proof, but of accumulating observations
that are consistent with the hypothesis of large tree size, and inconsistent with alternative
hypotheses if we disallow special pleading. So for example, to test whether the subgroup
state

=

S

|

i

1

S
|

x
i
|

|

i

(cid:11)

(cid:12)
(cid:12)

(cid:12)
(cid:12)

S

to

p

S
|

and

vT x

vT x

0
i
|

x
i
|

∈
should be

for some vector v

, or an equal mixture of

, then perform the same test for the subgroup dual to S.

| Xx
S
∈
Zn
2 .
was prepared, we might use CNOT gates to map
x
i
|
,
0
Based on our knowledge of S, we could then predict whether the qubit
(cid:11)
i
|
when measured. Or we could apply Hadamard gates
1
1
|
i
|
i
In saying
to all n qubits of
that a system is in state
, it is not clear if we mean anything more than that it responds
i
to all such tests in expected ways. Similar remarks apply to Shor states and cluster states.
In my view, tests of the sort described above are certainly suﬃcient, so the inter-
esting question is whether they are necessary, or whether weaker and more indirect tests
would also suﬃce. This question rears its head when we ask whether non-tree states have
already been observed. For as pointed out to me by Anthony Leggett, there exist systems
studied in condensed-matter physics that are strong candidates for having superpolynomial
tree size. An example is the magnetic salt LiHoxY1
xF4 studied by Ghosh et al. [124],
which, like the cluster states of Briegel and Raussendorf [71], basically consists of a lattice
of spins subject to pairwise nearest-neighbor Hamiltonians. The main diﬀerences are that
the salt lattice is 3-D instead of 2-D, is tetragonal instead of cubic, and is irregular in
that not every site is occupied by a spin. Also, there are weak interactions even between
spins that are not nearest neighbors. But none of these diﬀerences seem likely to change a
superpolynomial tree size into a polynomial one.

−

159

For me, the main issues are (1) how precisely can we characterize9 the quantum
state of the magnetic salt, and (2) how strong the evidence is that that is the state. What
Ghosh et al. [124] did was to calculate bulk properties of the salt, such as its magnetic
susceptibility and speciﬁc heat, with and without taking into account the quantum en-
tanglement generated by the nearest-neighbor Hamiltonians. They found that including
entanglement yielded a better ﬁt to the experimentally measured values. However, this is
clearly a far cry from preparing a system in a state of one’s choosing by applying a known
pulse sequence, and then applying any of a vast catalog of tests to verify that the state was
prepared. So it would be valuable to have more direct evidence that states qualitatively
like cluster states can exist in Nature.

In summary, the ideas of this chapter underscore the importance of current ex-
perimental work on large, persistently entangled quantum states; but they also suggest a
new motivation and perspective for this work. They suggest that we reexamine known
condensed-matter systems with a new goal in mind: understanding the complexity of their
associated quantum states. They also suggest that 2-D cluster states and random subgroup
states are interesting in a way that 1-D spin chains and Schr¨odinger cat states are not. Yet
when experimenters try to prepare states of the former type, they often see it as merely
a stepping stone towards demonstrating error-correction or another quantum computing
benchmark. Thus, Knill et al. [158] prepared10 the 5-qubit state

ψ
|

i

=

+

+

+



1
4

00000
|
i
01010
+
|
11101
− |
10001
− |

01001
10100
|
i
|
i
00110
11000
i − |
i
i − |
01111
11110
i
i − |
i − |
00101
+
10111
i
|
i
i − |
) = 40 from the decomposition

10010
|
i
11011
i − |
00011
i − |
01100
i − |







,





ψ
for which MOTS (
i
|
01
(
i
|
00
(
i
|

ψ
|

1
4

=

i

(cid:18)

−

111
i
110
i

)
10
+
i
|
11
+
i
|

)
10
010
(
i
|
i − |
⊗
11
+
011
(
)
|
i
i
⊗
) = 40 as well. However, the sole motivation of the
and for which I conjecture TS (
ψ
|
In my opinion,
experiment was to demonstrate a 5-qubit quantum error-correcting code.
whether states with large tree size can be prepared is a fundamental question in its own
right. Were that question studied directly, perhaps we could address it for larger numbers
of qubits.

001
(
|
i − |
+
000
(
i
|

01
) + (
|
00
) + (
|

)
100
i
101
i
|

i − |
i − |

⊗
)
⊗

(cid:19)

)

i

,

|

Let me end by stressing that, in the perspective I am advocating, there is nothing
sacrosanct about tree size as opposed to other complexity measures. This chapter concen-
trated on tree size because it is the subject of our main results, and because it is better to

9By “characterize,” I mean give an explicit formula for the amplitudes at a particular time t, in some
If a state is characterized as the ground state of a Hamiltonian, then we ﬁrst need to solve

standard basis.
for the amplitudes before we can prove tree size lower bounds using Raz’s method.

10Admittedly, what they really prepared is the ‘pseudo-pure’ state ρ = ε

ε) I, where I is the
5. Braunstein et al. [69] have shown that, if the number of qubits n is
maximally mixed state and ε
less than about 14, then such states cannot be entangled. That is, there exists a representation of ρ as a
mixture of pure states, each of which is separable and therefore has tree size O (n). This is a well-known
limitation of the liquid NMR technology used by Knill et al. Thus, a key challenge is to replicate the
successes of liquid NMR using colder qubits.

+ (1

10−

ψ
|

i h

−

≈

ψ

|

160

be speciﬁc than vague. On the other hand, Sections 13.3, 13.4, and 13.6 contain numerous
results about orthogonal tree size, manifestly orthogonal tree size, Vidal’s χ complexity,
and other measures. Readers dissatisﬁed with all of these measures are urged to propose
new ones, perhaps motivated directly by experiments.
I see nothing wrong with having
multiple ways to quantify the complexity of quantum states, and much wrong with having
no ways.

13.9 Conclusion and Open Problems

A crucial step in quantum computing was to separate the question of whether quantum
computers can be built from the question of what one could do with them. This separation
allowed computer scientists to make great advances on the latter question, despite know-
I have argued, however, that the tools of computational
ing nothing about the former.
complexity theory are relevant to both questions. The claim that large-scale quantum com-
puting is possible in principle is really a claim that certain states can exist—that quantum
mechanics will not break down if we try to prepare those states. Furthermore, what distin-
guishes these states from states we have seen must be more than precision in amplitudes, or
the number of qubits maintained coherently. The distinguishing property should instead
be some sort of complexity. That is, Sure states should have succinct representations of a
type that Shor states do not.

I have tried to show that, by adopting this viewpoint, we make the debate about
whether quantum computing is possible less ideological and more scientiﬁc. By studying
particular examples of Sure/Shor separators, quantum computing skeptics would strengthen
their case—for they would then have a plausible research program aimed at identifying what,
exactly, the barriers to quantum computation are.
I hope, however, that the ‘complexity
theory of quantum states’ initiated here will be taken up by quantum computing proponents
as well. This theory oﬀers a new perspective on the transition from classical to quantum
computing, and a new connection between quantum computing and the powerful circuit
lower bound techniques of classical complexity theory.

I end with some open problems.

(1) Can Raz’s technique be improved to show exponential tree size lower bounds?

(2) Can we prove Conjecture 90, implying an nΩ(log n) tree size lower bound for Shor

states?

(3) Let

ϕ
i
|

be a uniform superposition over all n-bit strings of Hamming weight n/2.

It
is easy to show by divide-and-conquer that TS (
Is this upper bound
tight? More generally, can we show a superpolynomial tree size lower bound for any
state with permutation symmetry?

) = nO(log n).

ϕ
i
|

(4) Is Tree = OTree? That is, are there tree states that are not orthogonal tree states?

(5) Is the tensor-sum hierarchy of Section 13.2 inﬁnite? That is, do we have Σk

= Σk+1

for all k?

6
(6) Is TreeBQP = BPP? That is, can a quantum computer that is always in a tree state
be simulated classically? The key question seems to be whether the concept class of
multilinear formulas is eﬃciently learnable.

(7) Is there a practical method to compute the tree size of, say, 10-qubit states? Such a

method would have great value in interpreting experimental results.

161

162

Chapter 14

Quantum Search of Spatial Regions

This chapter represents joint work with Andris Ambainis.

The goal of Grover’s quantum search algorithm [139] is to search an ‘unsorted
database’ of size n in a number of queries proportional to √n. Classically, of course, order
n queries are needed.
It is sometimes asserted that, although the speedup of Grover’s
algorithm is only quadratic, this speedup is provable, in contrast to the exponential speedup
of Shor’s factoring algorithm [219]. But is that really true? Grover’s algorithm is typically
imagined as speeding up combinatorial search—and we do not know whether every problem
in NP can be classically solved quadratically faster than the “obvious” way, any more than
we know whether factoring is in BPP.

But could Grover’s algorithm speed up search of a physical region? Here the basic
problem, it seems to us, is the time needed for signals to travel across the region. For if we
are interested in the fundamental limits imposed by physics, then we should acknowledge
that the speed of light is ﬁnite, and that a bounded region of space can store only a ﬁnite
amount of information, according to the holographic principle [65]. We discuss the latter
constraint in detail in Section 14.3; for now, we say only that it suggests a model in which
a ‘quantum robot’ occupies a superposition over ﬁnitely many locations, and moving the
In such a model, the time
robot from one location to an adjacent one takes unit time.
needed to search a region could depend critically on its spatial layout. For example, if the
n entries are arranged on a line, then even to move the robot from one end to the other
takes n
1 steps. But what if the entries are arranged on, say, a 2-dimensional square grid
(Figure 14.1)?

−

14.1 Summary of Results

This chapter gives the ﬁrst systematic treatment of quantum search of spatial regions,
with ‘regions’ modeled as connected graphs. Our main result is positive: we show that a
quantum robot can search a d-dimensional hypercube with n vertices for a unique marked
3. This matches (or in
vertex in time O

when d = 2, or O (√n) when d

the case of 2 dimensions, nearly matches) the Ω (√n) lower bound for quantum search, and
supports the view that Grover search of a physical region presents no problem of principle.

(cid:17)

√n log3/2 n
(cid:16)

≥

163

Robot
Robot

n
n

n
n

Marked item
Marked item

Figure 14.1: A quantum robot, in a superposition over locations, searching for a marked
item on a 2D grid of size √n

√n.

×

Hypercube, 1 marked item O

Hypercube, k or more marked items O

Arbitrary graph, k or more marked items √n2O(√log n)

d = 2
√n log3/2 n
(cid:16)
√n log5/2 n
(cid:16)

d > 2

Θ (√n)

(cid:17)

(cid:17)

Θ

(cid:16)

Θ

k1/2

1/d

√n

−
√n

k1/2

−

1/d

(cid:17)

(cid:17)

(cid:16)

Table 14.1: Upper and lower bounds for quantum search on a d-dimensional graph given in
this chapter. The symbol
Θ means that the upper bound includes a polylogarithmic term.
Note that, if d = 2, then Ω (√n) is always a lower bound, for any number of marked items.

e

e

Our basic technique is divide-and-conquer; indeed, once the idea is pointed out, an upper
bound of O
follows readily. However, to obtain the tighter bounds is more diﬃcult;
for that we use the amplitude-ampliﬁcation framework of Brassard et al. [67].

n1/2+ε

Section 14.6 presents the main results; Section 14.6.4 shows further that, when
when d = 2,

there are k or more marked vertices, the search time becomes O

√n log5/2 n

(cid:0)

(cid:1)

√n/k1/2

1/d

−

when d

or Θ
3. Also, Section 14.7 generalizes our algorithm to arbitrary
graphs that have ‘hypercube-like’ expansion properties. Here the best bounds we can
achieve are √n2O(√log n) when d = 2, or O (√n polylog n) when d > 2 (note that d need
not be an integer). Table 14.1 summarizes the results.

≥

(cid:0)

(cid:1)

(cid:17)

(cid:16)

(cid:0)

(cid:1)

Section 14.8 shows, as an unexpected application of our search algorithm, that
the quantum communication complexity of the well-known disjointness problem is O (√n).
upper bound of Høyer and de Wolf [146], and matches the
This improves an O
Ω (√n) lower bound of Razborov [199].

√nclog∗ n

The rest of the chapter is about the formal model that underlies our results.
Section 14.3 sets the stage for this model, by exploring the ultimate limits on information
storage imposed by properties of space and time. This discussion serves only to motivate
our results; thus, it can be safely skipped by readers unconcerned with the physical universe.
In Section 16.7 we deﬁne quantum query algorithms on graphs, a model similar to quantum
query algorithms as deﬁned in Section 5.1, but with the added requirement that unitary
In Section 14.4.1 we address the diﬃcult
operations be ‘local’ with respect to some graph.

164

question, which also arises in work on quantum random walks [19] and quantum cellular
automata [238], of what ‘local’ means. Section 14.5 proves general facts about our model,
including an upper bound of O
for the time needed to search any graph with diameter
δ, and a proof (using the hybrid argument of Bennett et al. [51]) that this upper bound is
tight for certain graphs. We conclude in Section 14.9 with some open problems.

√nδ

(cid:17)

(cid:16)

14.2 Related Work

In a paper on ‘Space searches with a quantum robot,’ Benioﬀ [50] asked whether Grover’s
algorithm can speed up search of a physical region, as opposed to a combinatorial search
√n, Grover’s algorithm
space. His answer was discouraging: for a 2-D grid of size √n
is no faster than classical search. The reason is that, during each of the Θ (√n) Grover
iterations, the algorithm must use order √n steps just to travel across the grid and return
to its starting point for the diﬀusion step. On the other hand, Benioﬀ noted, Grover’s
algorithm does yield some speedup for grids of dimension 3 or higher, since those grids have
diameter less than √n.

×

Our results show that Benioﬀ’s claim is mistaken: by using Grover’s algorithm
√n log3/2 n
more carefully, one can search a 2-D grid for a single marked vertex in O
time. To us this illustrates why one should not assume an algorithm is optimal on heuristic
(cid:17)
(cid:16)
grounds. Painful experience—for example, the “obviously optimal” O
matrix multi-
plication algorithm [226]—is what taught computer scientists to see the proving of lower
bounds as more than a formality.

n3

(cid:1)

(cid:0)

Our setting is related to that of quantum random walks on graphs [19, 83, 84, 216].
In an earlier version of this chapter, we asked whether quantum walks might yield an
alternative spatial search algorithm, possibly even one that outperforms our divide-and-
conquer algorithm. Motivated by this question, Childs and Goldstone [86] managed to show
that in the continuous-time setting, a quantum walk can search a d-dimensional hypercube
for a single marked vertex in time O (√n log n) when d = 4, or O (√n) when d
5. Our
algorithm was still faster in 3 or fewer dimensions (see Table 14.2). Subsequently, however,
Ambainis, Kempe, and Rivosh [31] gave an algorithm based on a discrete-time quantum
walk, which was as fast as ours in 3 or more dimensions, and faster in 2 dimensions.
In
particular, when d = 2 their algorithm used only O (√n log n) time to ﬁnd a unique marked
vertex. Childs and Goldstone [85] then gave a continuous-time quantum walk algorithm
with the same performance, and related this algorithm to properties of the Dirac equation.
It is still open whether O (√n) time is achievable in 2 dimensions.

≥

Currently, the main drawback of the quantum walk approach is that all analyses
have relied heavily on symmetries in the underlying graph.
If even minor ‘defects’ are
introduced, it is no longer known how to upper-bound the running time. By contrast,
the analysis of our divide-and-conquer algorithm is elementary, and does not depend on
eigenvalue bounds. We can therefore show that the algorithm works for any graphs with
suﬃciently good expansion properties.

Childs and Goldstone [86] argued that the quantum walk approach has the advan-
tage of requiring fewer auxiliary qubits than the divide-and-conquer approach. However,

This chapter O

[86]
[31, 85]

d = 3

d = 4

O (√n)

d = 2
√n log3/2 n
O (n)
(cid:16)
O (√n log n)

(cid:17)

O (√n)
n5/6
O
O (√n)
(cid:0)

(cid:1)

O (√n log n) O (√n)
O (√n)
O (√n)

165

d

5

≥
O (√n)

Table 14.2: Time needed to ﬁnd a unique marked item in a d-dimensional hypercube, using
the divide-and-conquer algorithms of this chapter, the original quantum walk algorithm of
Childs and Goldstone [86], and the improved walk algorithms of Ambainis, Kempe, and
Rivosh [31] and Childs and Goldstone [85].

the need for many qubits was an artifact of how we implemented the algorithm in a previous
version of the chapter. The current version uses only one qubit.

14.3 The Physics of Databases

Theoretical computer science generally deals with the limit as some resource (such as time or
memory) increases to inﬁnity. What is not always appreciated is that, as the resource bound
increases, physical constraints may come into play that were negligible at ‘sub-asymptotic’
scales. We believe theoretical computer scientists ought to know something about such
constraints, and to account for them when possible. For if the constraints are ignored on
the ground that they “never matter in practice,” then the obvious question arises: why use
asymptotic analysis in the ﬁrst place, rather than restricting attention to those instance
sizes that occur in practice?

A constraint of particular interest for us is the holographic principle [65], which
arose from black-hole thermodynamics. The principle states that the information content
of any spatial region is upper-bounded by its surface area (not volume), at a rate of one
Intuitively, if one tried to
bit per Planck area, or about 1.4
build a spherical hard disk with mass density υ, one could not keep expanding it forever.
3/ (8πυ) (in Planck
For as soon as the radius reached the Schwarzschild bound of r =
units, c = G = ~ = k = 1), the hard disk would collapse to form a black hole, and thus its
contents would be irretrievable.

1069 bits per square meter.

p

×

Actually the situation is worse than that: even a planar hard disk of constant
mass density would collapse to form a black hole once its radius became suﬃciently large,
(We assume here that the hard disk is disc-shaped. A linear or 1-D hard
r = Θ (1/υ).
disk could expand indeﬁnitely without collapse.)
It is possible, though, that a hard disk’s
information content could asymptotically exceed its mass. For example, a black hole’s
mass is proportional to the radius of its event horizon, but the entropy is proportional to
the square of the radius (that is, to the surface area). Admittedly, inherent diﬃculties with
storage and retrieval make a black hole horizon less than ideal as a hard disk. However,
even a weakly-gravitating system could store information at a rate asymptotically exceeding
its mass-energy. For instance, Bousso [65] shows that an enclosed ball of radiation with
bits, even though its energy grows only as r. Our results in
radius r can store n = Θ
Section 14.7.1 will imply that a quantum robot could (in principle!) search such a ‘radiation

r3/2

(cid:0)

(cid:1)

166

r5/4

n5/6

= O

disk’ for a marked item in time O
. This is some improvement over the
trivial O (n) upper bound for a 1-D hard disk, though it falls short of the desired O (√n).
In general, if n = rc bits are scattered throughout a 3-D ball of radius r (where
c
3 and the bits’ locations are known), we will show in Theorem 130 that the time
needed to search for a ‘1’ bit grows as n1/c+1/6 = r1+c/6 (omitting logarithmic factors).
In
(saturating the holographic bound), then the time grows as n2/3 or
particular, if n = Θ
r4/3. To achieve a search time of O (√n polylog n), the bits would need to be concentrated
on a 2-D surface.

r2

≤

(cid:0)

(cid:0)

(cid:1)

(cid:0)

(cid:1)

(cid:1)

Because of the holographic principle, we see that it is not only quantum mechanics
that yields a Ω (√n) lower bound on the number of steps needed for unordered search.
If
the items to be searched are laid out spatially, then general relativity in 3 + 1 dimensions
independently yields the same bound, Ω (√n), up to a constant factor.1
Interestingly, in
, which for d > 3 is weaker than
d + 1 dimensions the relativity bound would be Ω
the quantum mechanics bound. Given that our two fundamental theories yield the same
lower bound, it is natural to ask whether that bound is tight. The answer seems to be that
it is not tight, since (i) the entropy on a black hole horizon is not eﬃciently accessible2, and
(ii) weakly-gravitating systems are subject to the Bekenstein bound [48], an even stronger
entropy constraint than the holographic bound.

n1/(d

1)

(cid:0)

(cid:1)

−

Yet it is still of basic interest to know whether n bits in a radius-r ball can be
)—that is, whether it is possible to do anything better
searched in time o (min
}
than either brute-force quantum search (with the drawback pointed out by Benioﬀ [50]), or
classical search. Our results show that it is possible.

n, r√n

{

From a physical point of view, several questions naturally arise: (1) whether our
complexity measure is realistic; (2) how to account for time dilation; and (3) whether given
the number of bits we are imagining, cosmological bounds are also relevant. Let us address
these questions in turn.

(1) One could argue that to maintain a ‘quantum database’ of size n requires n
computing elements ([251], though see also [206]). So why not just exploit those elements
to search the database in parallel? Then it becomes trivial to show that the search time is
limited only by the radius of the database, so the algorithms of this chapter are unnecessary.
Our response is that, while there might be n ‘passive’ computing elements (capable of storing
data), there might be many fewer ‘active’ elements, which we consequently wish to place in
a superposition over locations. This assumption seems physically unobjectionable. For a
particle (and indeed any object) really does have an indeterminate location, not merely an
indeterminate internal state (such as spin) at some location. We leave as an open problem,
however, whether our assumption is valid for speciﬁc quantum computer architectures such
as ion traps.

(2) So long as we invoke general relativity, should we not also consider the eﬀects
of time dilation? Those eﬀects are indeed pronounced near a black hole horizon. Again,
though, for our upper bounds we will have in mind systems far from the Schwarzschild

1Admittedly, the holographic principle is part of quantum gravity and not general relativity per se.
All that matters for us, though, is that the principle seems logically independent of quantum-mechanical
linearity, which is what produces the “other” Ω (√n) bound.

2In the case of a black hole horizon, waiting for the bits to be emitted as Hawking radiation—as recent

evidence suggests that they are [209]—takes time proportional to r3, which is much too long.

167

limit, for which any time dilation is by at most a constant factor independent of n.

(3) How do cosmological considerations aﬀect our analysis? Bousso [64] argues
that, in a spacetime with positive cosmological constant Λ > 0, the total number of bits
accessible to any one experiment is at most 3π/ (Λ ln 2), or roughly 10122 given current
experimental bounds [208] on Λ.3 Intuitively, even if the universe is spatially inﬁnite, most
of it recedes too quickly from any one observer to be harnessed as computer memory.

One response to this result is to assume an idealization in which Λ vanishes,
although Planck’s constant ~ does not vanish. As justiﬁcation, one could argue that without
the idealization Λ = 0, all asymptotic bounds in computer science are basically ﬁctions.
But perhaps a better response is to accept the 3π/ (Λ ln 2) bound, and then ask how close
one can come to saturating it in diﬀerent scenarios. Classically, the maximum number
1061
of bits that can be searched is, in a crude model4, actually proportional to 1/√Λ
rather than 1/Λ. The reason is that if a region had much more than 1/√Λ bits, then
after 1/√Λ Planck times—that is, about 1010 years, or roughly the current age of the
universe—most of the region would have receded beyond one’s cosmological horizon. What
our results suggest is that, using a quantum robot, one could come closer to saturating the
cosmological bound—since, for example, a 2-D region of size 1/Λ can be searched in time
. How anyone could prepare (say) a database of size much greater than
O
1/√Λ remains unclear, but if such a database existed, it could be searched!

polylog 1
√Λ

1
√Λ

≈

(cid:16)

(cid:17)

14.4 The Model

As discussed in Part I, much of what is known about the power of quantum computing
comes from the black-box or query model—in which one counts only the number of queries
to an oracle, not the number of computational steps. We will take this model as the
starting point for a formal deﬁnition of quantum robots. Doing so will focus attention
on our main concern: how much harder is it to evaluate a function when its inputs are
spatially separated? As it turns out, all of our algorithms will be eﬃcient as measured by
the number of gates and auxiliary qubits needed to implement them.

{

→ {

0, 1
}

0, 1
}

For simplicity, we assume that a robot’s goal is to evaluate a Boolean function
n
, which could be partial or total. A ‘region of space’ is a connected
n
v1, . . . , vn}
{

f :
undirected graph G = (V, E) with vertices V =
0, 1
}
be an input to f ; then each bit xi is available only at vertex vi. We assume the robot
knows G and the vertex labels in advance, and so is ignorant only of the xi bits. We thus
sidestep a major diﬃculty for quantum walks [19], which is how to ensure that a process
on an unknown graph is unitary.

. Let X = x1 . . . xn ∈ {

3Also, Lloyd [170] argues that the total number of bits accessible up till now is at most the square of the
2 = 10122. Lloyd’s bound, unlike Bousso’s, does not
number of Planck times elapsed so far, or about
depend on Λ being positive. The numerical coincidence between the two bounds reﬂects the experimental
(cid:1)
ﬁnding [208, 207] that we live in a transitional era, when both Λ and “dust” contribute signiﬁcantly to the
universe’s net energy balance (ΩΛ
In earlier times dust (and before that radiation)
0.3).
In later times Λ will dominate, and Bousso’s bound will be
dominated, and Lloyd’s bound was tighter.
tighter. Why we should live in such a transitional era is unknown.

0.7, Ωdust

1061

≈

≈

(cid:0)

4Speciﬁcally, neglecting gravity and other forces that could counteract the eﬀect of Λ.

168

At any time, the robot’s state has the form

αi,z |

vi, z

.

i

V is a vertex, representing the robot’s location; and z is a bit string (which can
Here vi ∈
be arbitrarily long), representing the robot’s internal conﬁguration. The state evolves via
an alternating sequence of T algorithm steps and T oracle steps:

X

U (1)

O(1)

U (1)

→

→

U (T )

O(T ).

→ · · · →
to

→
xii

An oracle step O(t) maps each basis state
, where xi is exclusive-OR’ed
vi, z
into the ﬁrst bit of z. An algorithm step U (t) can be any unitary matrix that (1) does not
depend on X, and (2) acts ‘locally’ on G. How to make the second condition precise is the
subject of Section 14.4.1.

vi, z

⊕

i

|

|

The initial state of the algorithm is

i,z (X) be the amplitude of
immediately after the tth oracle step; then the algorithm succeeds with probability 1

v1, 0
i
|

. Let α(t)

vi, z
i
ε if

|
−

vi,z
X|
i
for all inputs X, where zOU T is a bit of z representing the output.

: zOU T =f (X) (cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

2

α(T )
i,z (X)

1

ε

≥

−

14.4.1 Locality Criteria

Classically, it is easy to decide whether a stochastic matrix acts locally with respect to a
In the quantum case,
graph G: it does if it moves probability only along the edges of G.
however, interference makes the question much more subtle.
In this section we propose
three criteria for whether a unitary matrix U is local. Our algorithms can be implemented
using the most restrictive of these criteria, whereas our lower bounds apply to all three of
them.

The ﬁrst criterion we call Z-locality (for zero): U is Z-local if, given any pair of
non-neighboring vertices v1, v2 in G, U “sends no amplitude” from v1 to v2; that is, the
corresponding entries in U are all 0. The second criterion, C-locality (for composability),
says that this is not enough: not only must U send amplitude only between neighboring
vertices, but it must be composed of a product of commuting unitaries, each of which acts
on a single edge. The third criterion is perhaps the most natural one to a physicist: U
is H-local (for Hamiltonian) if it can be obtained by applying a locally-acting, low-energy
Hamiltonian for some ﬁxed amount of time. More formally, let Ui,z
i∗,z∗ be the entry in
row of U .
the

column and

→

vi, z
|

i

vi∗, z∗i

|

Deﬁnition 101 U is Z-local if Ui,z
of G.

→

i∗,z∗ = 0 whenever i

= i∗ and (vi, vi∗ ) is not an edge

Deﬁnition 102 U is C-local if the basis states can be partitioned into subsets P1, . . . , Pq
such that

(i) Ui,z

→

i∗,z∗ = 0 whenever

vi, z
|

i

and

vi∗, z∗i

|

belong to distinct Pj’s, and

6
(ii) for each j, all basis states in Pj are either from the same vertex or from two adjacent

vertices.

169

Deﬁnition 103 U is H-local if U = eiH for some Hermitian H with eigenvalues of absolute
= i∗ and (vi, vi∗) is not an edge in E.
value at most π, such that Hi,z

i∗,z∗ = 0 whenever i

→

If a unitary matrix is C-local, then it is also Z-local and H-local. For the latter
implication, note that any unitary U can be written as eiH for some H with eigenvalues of
absolute value at most π. So we can write the unitary Uj acting on each Pj as eiHj ; then
since the Uj’s commute,

Uj = ei

Hj .

P

Y

Beyond that, though, how are the locality criteria related? Are they approximately equiva-
lent? If not, then does a problem’s complexity in our model ever depend on which criterion
is chosen? Let us emphasize that these questions are not answered by, for example, the
Solovay-Kitaev theorem (see [182]), that an n
n unitary matrix can be approximated using
×
a number of gates polynomial in n. For recall that the deﬁnition of C-locality requires the
edgewise operations to commute—indeed, without that requirement, one could produce any
unitary matrix at all. So the relevant question, which we leave open, is whether any Z-local
or H-local unitary can be approximated by a product of, say, O (log n) C-local unitaries.
(A product of O (n) such unitaries trivially suﬃces, but that is far too many.) Again, the
algorithms in this chapter will use C-local unitaries, whereas the lower bounds will apply
even to Z-local and H-local unitaries.

14.5 General Bounds

n

→ {

0, 1
}
{

Given a Boolean function f :
, the quantum query complexity Q (f ) is
0, 1
}
the minimum T for which there exists a T -query quantum algorithm that evaluates f
with probability at least 2/3 on all inputs. (We will always be interested in the two-sided,
bounded-error complexity, denoted Q2 (f ) elsewhere in this thesis.) Similarly, given a graph
G with n vertices labeled 1, . . . , n, we let Q (f, G) be the minimum T for which there exists
a T -query quantum robot on G that evaluates f with probability 2/3. Here the algorithm
steps must be C-local; we use QZ (f, G) and QH (f, G) to denote the corresponding measure
with Z-local and H-local steps respectively. Clearly Q (f, G)
QH (f, G); we do not know whether all three measures are asymptotically equivalent.

QZ (f, G) and Q (f, G)

≥

≥

Let δG be the diameter of G, and call f nondegenerate if it depends on all n input

bits.

Proposition 104 For all f, G,

(i) Q (f, G)

(ii) Q (f, G)

(iii) Q (f, G)

(iv) Q (f, G)

≤

≤

≥

≥

2n

3.

−

(2δG + 1) Q (f ).

Q (f ).

δG/2 if f is nondegenerate.

6
170

Proof.

(i) Starting from the root, a spanning tree for G can be traversed in 2 (n

(there is no need to return to the root).

1)

−

−

1 steps

(ii) We can simulate a query in 2δG steps, by fanning out from the start vertex v1 and

then returning. Applying a unitary at v1 takes 1 step.

(iii) Obvious.

(iv) There exists a vertex vi whose distance to v1 is at least δG/2, and f could depend on

xi.

We now show that the model is robust.

Proposition 105 For nondegenerate f , the following change Q (f, G) by at most a constant
factor.

(i) Replacing the initial state

v1, 0
i
|

by an arbitrary (known)

ψ

.
i

|

(ii) Requiring the ﬁnal state to be localized at some vertex vi with probability at least 1

for a constant ε > 0.

ε,

−

(iii) Allowing multiple algorithm steps between each oracle step (and measuring the com-

plexity by the number of algorithm steps).

Proof.

(i) We can transform

(and hence
by fanning out from v1 along the edges of a minimum-height spanning tree.

v1, 0
i
|

v1, 0
i
|

) in δG = O (Q (f, G)) steps,

ψ
|

to

to

ψ

i

i

|

(ii) Assume without loss of generality that zOU T is accessed only once, to write the output.
Then after zOU T is accessed, uncompute (that is, run the algorithm backwards) to
localize the ﬁnal state at v1. The state can then be localized at any vi in δG =
O (Q (f, G)) steps. We can succeed with any constant probability by repeating this
procedure a constant number of times.

(iii) The oracle step O is its own inverse, so we can implement a sequence U1, U2, . . . of

algorithm steps as follows (where I is the identity):

U1 →

O

I

O

U2 → · · ·

→

→

→

A function of particular interest is f = OR (x1, . . . , xn), which outputs 1 if and
only if xi = 1 for some i. We ﬁrst give a general upper bound on Q (OR, G) in terms of
the diameter of G.
(Throughout the chapter, we sometimes omit ﬂoor and ceiling signs if
they clearly have no eﬀect on the asymptotics.)

171

d /2
d /2d

Figure 14.2: The ‘starﬁsh’ graph G. The marked item is at one of the tip vertices.

Proposition 106

Q (OR, G) = O

nδG

.

(cid:16)p
Proof. Let τ be a minimum-height spanning tree for G, rooted at v1. A depth-
2 steps. Let S1 be the set of vertices visited by depth-ﬁrst search

ﬁrst search on τ uses 2n
in steps 1 to δG, S2 be those visited in steps δG + 1 to 2δG, and so on. Then

−

(cid:17)

S1 ∪ · · · ∪

S2n/δG = V .

Furthermore, for each Sj there is a classical algorithm Aj, using at most 3δG steps, that
Sj. Then we
starts at v1, ends at v1, and outputs ‘1’ if and only if xi = 1 for some vi ∈
simply perform Grover search at v1 over all Aj; since each iteration takes O (δG) steps and
there are O

iterations, the number of steps is O

.

√nδG

2n/δG

The bound of Proposition 106 is tight:

(cid:17)

(cid:16)p

(cid:0)

(cid:1)

Theorem 107 For all δ, there exists a graph G with diameter δG = δ such that

Indeed, QZ (f, G) and QH (f, G) are also Ω

(cid:16)
√nδ

.

(cid:17)

Q (OR, G) = Ω

√nδ

.

(cid:16)

(cid:17)
Proof. For simplicity, we ﬁrst consider the C-local and Z-local cases, and then
discuss what changes in the H-local case. Let G be a ‘starﬁsh’ with central vertex v1 and
M = 2 (n
1) /δ legs L1, . . . , LM , each of length δ/2 (see Figure 14.2). We use the hybrid
argument of Bennett et al. [51]. Suppose we run the algorithm on the all-zero input X0.
Then deﬁne the query magnitude Γ(t)
to be the probability of ﬁnding the robot in leg Lj
j
immediately after the tth query:

−

Γ(t)
j =

Xvi∈

z
Lj X

.

2

α(t)
i,z (X0)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

d
d
d
d
d
172

Let T be the total number of queries, and let w = T / (cδ) for some constant 0 < c < 1/2.
Clearly

1

M

w

−

q=0
X

Xj=1

qcδ)

Γ(T
j

−

≤

1 = w.

w

1

−

q=0
X

Hence there must exist a leg Lj∗ such that

w

1

−

Xq=0

qcδ)

Γ(T
j∗

−

w
M

≤

=

wδ

2 (n

−

.

1)

Let vi∗ be the tip vertex of Lj∗, and let Y be the input which is 1 at vi∗ and 0 elsewhere.
Then let Xq be a hybrid input, which is X0 during queries 1 to T
qcδ, but Y during
queries T

qcδ + 1 to T . Also, let

−

−

be the algorithm’s state after t queries when run on Xq, and let

ψ(t) (Xq)
(cid:12)
E
(cid:12)
(cid:12)

α(t)
i,z (Xq)

vi, z
|

i

=

Xi,z

D (q, r) =

=

(cid:12)
(cid:13)
(cid:12)
(cid:13)
(cid:12)
(cid:13)
Xvi∈

−

ψ(T ) (Xr)
ψ(T ) (Xq)
(cid:12)
E
α(T )
(cid:12)
i,z (Xq)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
1, q)
ψ(t) (Xq)

z
G X

qcδ)

−

−

E(cid:13)
α(T )
(cid:13)
i,z (Xr)
(cid:13)

2

.

2

2

(cid:12)
(cid:12)
(cid:12)

1, we claim that D (q
Then for all q
≥
1)
distance between
−
−
1) cδ. But no amplitude from outside Lj∗ can reach vi∗ during
qcδ + 1 through T
(cid:12)
(cid:11)
(cid:12)
that interval, since the distance is δ/2 and there are only cδ < δ/2 time steps. Therefore,
switching from Xq
1 to Xq can only aﬀect amplitude that is in Lj∗ immediately after query
T

4Γ(T
j∗
can only increase as a result of queries T

. For by unitarity, the Euclidean

ψ(t) (Xq
(q

qcδ:

and

−

−

≤

−

(cid:12)
(cid:12)

(cid:11)

−

−

D (q

1, q)

−

≤

Xvi∈

z
Lj∗ X

= 4

α(T
i,z
(cid:12)
(cid:12)
(cid:12)

qcδ)

−

(Xq)

−

−

qcδ)

α(T
i,z

−

(Xq)

2

α(T
i,z

qcδ)

−

(X0)

(cid:16)
2
= 4Γ(T
j∗

(cid:17)(cid:12)
(cid:12)
(cid:12)

qcδ)

.

−

It follows that

Xvi∈

z
Lj∗ X

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

D (0, w)

p

w

≤

Xq=1

p

D (q

1, q)

2

≤

−

w

qcδ)

Γ(T
j∗

−

Xq=1 q

2w

≤

s

δ
2 (n

−

=

1)

T
c s

2
δ (n

−

.

1)

Here the ﬁrst inequality uses the triangle inequality, and the third uses the Cauchy-Schwarz
inequality. Now assuming the algorithm is correct we need D (0, w) = Ω (1), which implies
that T = Ω

√nδ

.

(cid:16)

(cid:17)

173

In the H-local case, it is no longer true that no amplitude from outside Lj∗ can
reach vi∗ in cδ time steps. But if c is a small enough constant, then the amount of
amplitude that can reach vi∗ decreases exponentially in δ. To see this, assume without
loss of generality that all amplitude not in Lj∗ starts in the state
is some
superposition over auxiliary qubits. Let H be the local Hamiltonian that acts between the
tth and (t + 1)st queries, all of whose eigenvalues have absolute value at most π. Since H
1 where V is unitary and Λ is diagonal. So by
is Hermitian, we can decompose it as V ΛV −
Taylor series expansion,

, where

v0, ψ

ψ
|

i

i

|

eiH =

V ΛjV −

1.

ij
j!

Xj
0
≥
such that the distance from v0 to vb is ℓ, for
Now let S be the set of basis states
vb, zbi
vb, zbi ∈
some ℓ > 4π. Notice that for all j < ℓ and
|
vb, zb|
h

vb, zb|
h

S, we have

V ΛjV −

v0, ψ
|

v0, ψ
|

= 0

H j

=

i

i

1

|

by the locality of H. Therefore

S
vb,zbi∈
X|

h
(cid:12)
(cid:12)

eiH

vb, zb|

v0, ψ

|

2

=

i

(cid:12)
(cid:12)

ij
j! h

vb, zb|

V ΛjV −

1

|

v0, ψ

ij
j! h

vb, zb|

V ΛjV −

1

2

i(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
v0, ψ
|

2

2





i

(cid:12)
(cid:12)
(cid:12)
(cid:12)

S
vb,zbi∈
X|

(cid:12)
(cid:12)
ℓ
Xj
(cid:12)
≥
(cid:12)
(cid:12)
(cid:12)
ℓ v
u
u
t

≤ 



Xj
≥

≤ 

ℓ s

Xj
≥

4πℓ
ℓ!

.

≤

S (cid:12)
(cid:12)
(cid:12)
(cid:12)

vb,zbi∈
X|
2

πj
j! 



1 has
Here the second line uses the triangle inequality, the third line uses the fact that V ΛjV −
1 has maximum eigenvalue at
maximum eigenvalue at most πj (and therefore
most πj/j!), and the fourth line uses the fact that ℓ > 4π.
Intuitively, the probability that
H sends the robot a distance ℓ from v0 is at most 4πℓ/ℓ!, which decreases exponentially in
ℓ. One can now use a Chernoﬀ-Hoeﬀding bound to upper-bound the probability that cδ
It
local Hamiltonians, applied in succession, ever move the robot a distance δ/2 from v0.
is clear that the resulting upper bound is 2−

Ω(δ) for small enough c. Therefore

V ΛjV −

ij/j!

(cid:0)

(cid:1)

and the remainder of the proof goes through as before.

D (q

1, q)

−

≤

qcδ)

4Γ(T
j∗

−

Ω(δ)

+ 2−

14.6 Search on Grids

Ld (n) be a d-dimensional grid graph of size n1/d
1, . . . , n1/d

Let
is speciﬁed by d coordinates i1, . . . , id ∈

n1/d. That is, each vertex
× · · · ×
, and is connected to the at most 2d

(cid:8)

(cid:9)

174

(cid:1)
√n1/3
(cid:16)

·

L2) = O (√n polylog n) for d = 2.
Before proving these claims,

vertices obtainable by adding or subtracting 1 from a single coordinate (boundary vertices
In
have fewer than 2d neighbors). We write simply
3, and
this section we present our main positive results: that Q (OR,
Q (OR,

Ld when n is clear from context.

Ld) = Θ (√n) for d

≥

let us develop some intuition by showing weaker
n3/4
: we simply
L2) = O
bounds, taking the case d = 2 for illustration. Clearly Q (OR,
In 5√n steps, the robot can
L2 (n) into √n subsquares, each a copy of
partition
travel from the start vertex to any subsquare C, search C classically for a marked vertex,
and then return to the start vertex. Thus, by searching all √n of the C’s in superposition
5√n =
and applying Grover’s algorithm, the robot can search the grid in time O
O

L2 (√n).

(cid:0)
L2 (n) into n1/3 subsquares, each a
. Searching any one of these subsquares by the previous algorithm takes

Once we know that, we might as well partition
(cid:1)
L2

(cid:0)
copy of

time O
and back from the start vertex. So using Grover’s algorithm, the robot can search
time O

= O (√n), an amount of time that also suﬃces to travel to the subsquare
L2 (n) in
. We can continue recursively in this manner to make the

(cid:17)
√n

n2/3
(cid:0)

n3/4

n1/4

n2/3

n2/3

3/4
(cid:1)

= O

(cid:16)(cid:0)

×

(cid:0)

(cid:1)

(cid:1)

.

(cid:0)

(cid:1)

(cid:17)

running time approach O (√n). The trouble is that, with each additional layer of recursion,
the robot needs to repeat the search more often to upper-bound the error probability. Using
this approach, the best bounds we could obtain are roughly O (√n polylog n) for d
3, or
√n2O(√log n) for d = 2.
In what follows, we use the amplitude ampliﬁcation approach
of Brassard et al. [67] to improve these bounds, in the case of a single marked vertex, to
O (√n) for d
for d = 2 (Section 14.6.3). Section
14.6.4 generalizes these results to the case of multiple marked vertices.

3 (Section 14.6.2) and O

√n log3/2 n
(cid:16)

≥

≥

(cid:17)

Intuitively, the reason the case d = 2 is special is that there, the diameter of the
grid is Θ (√n), which matches exactly the time needed for Grover search. For d
3, by
contrast, the robot can travel across the grid in much less time than is needed to search it.

≥

14.6.1 Amplitude Ampliﬁcation

We start by describing amplitude ampliﬁcation [67], a generalization of Grover search. Let
A be a quantum algorithm that, with probability ǫ, outputs a correct answer together with
a witness that proves the answer correct. (For example, in the case of search, the algorithm
outputs a vertex label i such that xi = 1.) Ampliﬁcation generates a new algorithm that
calls A order 1/√ǫ times, and that produces both a correct answer and a witness with
probability Ω (1).
, and let m be a positive
i
integer. Then the ampliﬁcation procedure works as follows:

In particular, assume A starts in basis state

s
|

= A

(1) Set

ψ0i
|
(2) For i = 1 to m set

.
i

s

|

= ASA−

ψi+1i
|
W ﬂips the phase of basis state
correct witness, and

1W

ψii
|
y
|

i

, where

•

•

S ﬂips the phase of basis state

if and only if

y
|

i

=

y
|

i

s

.
i

|

if and only if

contains a description of a

y
|

i

We can decompose

Ψfaili
+ cos α
ψ0i
|
|
Ψfaili
sition over basis states containing a correct witness and
|
other basis states. Brassard et al. [67] showed the following:

Ψsucci

as sin α

|

, where

is a superpo-
is a superposition over all

Ψsucci

|

175

Lemma 108 ([67])

= sin [(2i + 1) α]

.
Ψfaili
|
gives a correct witness with probability ǫ, then

+ cos [(2i + 1) α]

Ψsucci
|

1/√ǫ.

If measuring

2 = ǫ and
sin α
|
|
α
1. For our algorithms,
|
though, the multiplicative constant under the big-O also matters. To upper-bound this
constant, we prove the following lemma.

So taking m = O(1/√ǫ) yields sin [(2m + 1) α]

| ≥

≈

ψii
|
ψ0i
|

Lemma 109 Suppose a quantum algorithm A outputs a correct answer and witness with
probability exactly ǫ. Then by using 2m + 1 calls to A or A−

1, where

m

π

≤

4 arcsin √ǫ −

1
2

,

we can output a correct answer and witness with probability at least

(2m + 1)2
3

ǫ

1

−

!

(2m + 1)2 ǫ.

Proof. We perform m steps of amplitude ampliﬁcation, which requires 2m + 1

calls A or A−

1. By Lemma 108, this yields the ﬁnal state

sin [(2m + 1) α]

Ψsucci
|

+ cos [(2m + 1) α]

Ψfaili
|

.

where α = arcsin √ǫ. Therefore the success probability is

sin2

(2m + 1) arcsin √ǫ

(cid:2)

≥

(cid:3)

sin2

(2m + 1) √ǫ

(cid:2)

(2m + 1) √ǫ

≥  

(2m + 1)2 ǫ

−

≥

2

ǫ3/2

!

(2m + 1)3
(cid:3)
6

−
(2m + 1)4
3

ǫ2.

Here the ﬁrst line uses the monotonicity of sin2 x in the interval [0, π/2], and the second
line uses the fact that sin x

0 by Taylor series expansion.

x3/6 for all x

≥
Note that there is no need to uncompute any garbage left by A, beyond the

−

≥

x

uncomputation that happens “automatically” within the ampliﬁcation procedure.

14.6.2 Dimension At Least 3

Our goal is the following:

Theorem 110 If d

3, then Q (OR,

Ld) = Θ (√n).

≥

 
In this section, we prove Theorem 110 for the special case of a unique marked
vertex; then, in Sections 14.6.4 and 14.6.5, we will generalize to multiple marked vertices.
Let OR(k) be the problem of deciding whether there are no marked vertices or exactly k of
them, given that one of these is true. Then:

176

Theorem 111 If d

≥

3, then Q

OR(1),

= Θ (√n).

Ld

(cid:16)

(cid:17)
(2/3, 1) and µ

.

1

−

−

l

m

∈

ℓ1/β
−
1
R
−

Choose constants β

. Also let nR = ℓd

(1/3, 1/2) such that βµ > 1/3 (for example,
∈
β = 4/5 and µ = 5/11 will work). Let ℓ0 be a large positive integer; then for all positive
R. Assume for simplicity that n = nR
integers R, let ℓR = ℓR
1
−
for some R; in other words, that the hypercube
Ld (nR) to be searched has sides of length
ℓR. Later we will remove this assumption.
Ld (n0)
If n = n0, then search
classically, returning 1 if a marked vertex is found and 0 otherwise. Otherwise partition
1). Take the algorithm that
1 subcubes, each one a copy of
Ld (nR) into nR/nR
recursively on
consists of picking a subcube C uniformly at random, and then running
C. Amplify this algorithm (nR/nR

Consider the following recursive algorithm

A
Ld (nR

1)µ times.

1 ≈

Ld (nR

We now provide a more explicit description of

nβ
The intuition behind the exponents is that nR
1)
R, so searching
R steps, which dominates the n1/d
R steps needed to travel across the
3. Also, at level R we want to amplify a number of times that
≥
1)1/2 by some polynomial amount, since full ampliﬁcation would be
−

should take about nβ/2
hypercube when d
is less than (nR/nR
ineﬃcient. The reason for the constraint βµ > 1/3 will appear in the analysis.
, which shows that

can be
implemented using C-local unitaries and only a single bit of workspace. At any time, the
Ld (nR)
quantum robot’s state will have the form
and z is a single bit that records whether or not a marked vertex has been found. Given a
P
subcube C, let v (C) be the “corner” vertex of C; that is, the vertex that is minimal in all d
coordinates. Then the initial state when searching C will be
. Beware, however,
that “initial state” in this context just means the state
from Section 14.6.1. Because
of the way amplitude ampliﬁcation works,
will often be invoked on C with other initial
states, and even run in reverse.

, where vi is a vertex of

v (C) , 0
i
|

i,z αi,z |

vi, z

s
|

A

A

A

A

−

−

−

i

i

Below we give pseudocode for

and S from Section 14.6.1 as subroutines. For convenience, we write
denote the level of recursion that is currently active.

A

. Our procedure calls the three unitaries A, W ,
AR, AR, WR, SR to

Algorithm 112 (
the result to have larger probability. Default initial state:

AR) Searches a subcube C of size nR for the marked vertex, and ampliﬁes

.

v (C) , 0
i

|

If R = 0 then:

(1) Use classical C-local operations to visit all n0 vertices of C in any order. At each

C, use a query transformation to map the state

vi ∈

vi, z
|

i

to

vi, z
|

.
xii

⊕

(2) Return to v (C).

If R

≥

1 then:

(1) Let mR be the smallest integer such that 2mR + 1

(nR/nR

−

≥

1)µ.

(2) Call AR.

(3) For i = 1 to mR, call WR, then A−

1
R , then SR, then AR.

177

Suppose

AR is run on the initial state

v (C) , 0
i

|

minimal subcubes in C—meaning those of size n0. Then the ﬁnal state after
should be

, and let C1, . . . , CnR/n0 be the
AR terminates

nR/n0

1
nR/n0

v (Ci) , 0
i

|

Xi=1
if C does not contain the marked vertex. Otherwise the ﬁnal state should have non-
p
negligible overlap with
, where Ci∗ is the minimal subcube in C that contains
if C
the marked vertex.
contains the marked vertex, and

In particular, if R = 0, then the ﬁnal state should be
otherwise.

v (Ci∗) , 1
|
i

v (C) , 1
i
|

The two phase-ﬂip subroutines, WR and SR, are both trivial to implement. To
. To apply SR, map each basis state
vi, z
|
otherwise.

1)z
if vi = v (C) for some subcube C of size nR, and to

vi, z

to (

−

i

i

|

apply WR, map each basis state
vi, z
|
i
Below we give pseudocode for AR.

vi, z

− |

to

i

vi, z
|

i

v (C) , 0
i
|

Algorithm 113 (AR) Searches a subcube C of size nR for the marked vertex. Default
initial state:

.

v (C) , 0
i
|

(1) Partition C into nR/nR

−

1 smaller subcubes C1, . . . , CnR/nR

1, each of size nR
−

1.

−

(2) For all j

1, . . . , d
}

∈ {

only in the ﬁrst j coordinates. Thus V0 =
j = 1 to d, let

be the state

v (C)
}

{

, let Vj be the set of corner vertices v (Ci) that diﬀer from v (C)
R. For

, and in general

= ℓj

Vj|
|

Vji
|

=

Vji
|

1
ℓj/2
R Xv(Ci)
∈

Vj

v (Ci) , 0
i

|

Apply a sequence of transformations U1, U2, . . ., Ud where Uj is a unitary that maps
by applying C-local unitaries that move amplitude only along the jth
Vji
Vj
1i
|
|
coordinate.

to

−

(3) Call

AR
−
results.

1 recursively, to search C1, . . . , CnR/nR

1 in superposition and amplify the

−

If AR is run on the initial state

|

, then the ﬁnal state should be

v (C) , 0
i
nR/n0

1
nR/nR

1

−

,

φii
|

is the correct ﬁnal state when

p
where
φii
|
. A key point is that there is no need for AR to call
v (Ci) , 0
|
i
and once to uncompute—for the uncomputation is already built in to
enable us to prove an upper bound of O (√n) instead of O

AR
−
√n2R

AR
−

Xi=1
1 is run on subcube Ci with initial state
1 twice, once to compute
. This is what will

A

= O (√n polylog n).

We now analyze the running time of

.

A

(cid:0)

(cid:1)

Lemma 114

AR uses O

nµ
R

steps.

Proof. Let T

A
respectively in searching

(cid:1)

(cid:0)
(R) and TA (R) be the total numbers of steps used by
Ld (nR). Then we have T

(0) = O (1), and

A

178

AR and AR

(R)

T

A

TA (R)

≤

≤

(2mR + 1) TA (R) + 2mR,
dn1/d

(R

1)

R + T
A

−

for all R
≥
dℓR = dn1/d
R steps to move the robot across the hypercube. Combining,

1. For WR and SR can both be implemented in a single step, while AR uses

(R)

T

A

≤

(2mR + 1)

dn1/d
(cid:16)
1)µ + 2)

−
(cid:17)
1)µ + 2) T
A

(cid:17)

1)

1)

(R

(cid:17)
(R

+ 2mR

+ (nR/nR

+ ((nR/nR

R + T
−
A
dn1/d
R + T
A
(cid:16)
1)µ n1/d
R
1)µ n1/d
R
1)µ n1/d
R + (nR/nR
−
n1/d
n1/d
R
1
−
nµ
nµ
0 !
R
+ n1/d
−
1

2
+ n1/d
−
2

−
1)µ T
A
−
2)µ n1/d
1 +
R
−

· · ·

(R

+

+

+

+

βµ

βµ

βµ

(cid:17)

−

1

1

· · ·

+ (nR/nR

1)µ + 1

−

(R

1)

−

1)

−

+ (nR/n0)µ n1/d

1

· · ·

(cid:17)

βµ

+

n1/d
−
R
(cid:16)

1/β

βµ

(cid:17)

+

· · ·

+

(cid:17)
n1/d
−
R
(cid:16)

1/βR

1

−

βµ

(cid:17)

(cid:19)

((nR/nR

−

≤
= O

(cid:16)

(cid:16)

= O

= O

(nR/nR

−

(nR/nR

−

(nR/nR

(cid:16)
= nµ

R ·

= nµ

R ·

= nµ

R ·

O

O

O

= O

nµ
R

−
n1/d
R
nµ
R
−
n1/d
−
R
(cid:16)

n1/d
−
R

(cid:18)
.

(cid:0)

(cid:1)

Here the second line follows because 2mR + 1
(nR/nR
asymptotics; the seventh because nµ

1)µ + 2, the fourth because the
≤
1)µ terms increase doubly exponentially, so adding 2 to each will not aﬀect the
β
nβ
R; and

, the eighth because nR

(nR/nR

i = Ω

−

−

the last because βµ > 1/3

1/d, hence n1/d
(cid:16)(cid:0)
−
1

(cid:17)
< 1.
(cid:1)

≥

Next we need to lower-bound the success probability. Say that

or A “succeeds”
, where Ci∗ is the minimal
if a measurement in the standard basis yields the result
subcube that contains the marked vertex. Of course, the marked vertex itself can then be
found in n0 = O (1) steps.

v (Ci∗) , 1
i
|

A

nµ
i+1
βµ

1 ≤

−

Lemma 115 Assuming there is a unique marked vertex,

AR succeeds with probability Ω

Proof. Let P

(R) and PA (R) be the success probabilities of

tively when searching

A

Ld (nR). Then clearly P

A

(0) = 1, and PA (R) = (nR

AR and AR respec-
1)
−

1/nR) P

(R

A

−

1/n1
−
R
(cid:16)

2µ

.

(cid:17)

 
for all R

≥

1. So by Lemma 109,

(cid:18)

(cid:18)

(cid:18)

1

1

1

1

−

−

−

−

1
3
1
3
1
3
1
3

(2mR + 1)2 PA (R)

(2mR + 1)2 PA (R)

(cid:19)

1

(2mR + 1)2 nR
−
nR
1)2µ nR
−
nR

(nR/nR

−

P

A

(R

−

1)

1

(R

P

A

−

1

P

(2mR + 1)2 nR
−
nR
1)2µ nR
−
nR

(nR/nR

−

A

(cid:19)
1)

1

(R

P

A

−

1)

(nR

1/nR)1
−

2µ

−

1/nR)1
−

(nR

−

(cid:19)
2µ P
A

(R

1)

−

179

(R

1)

−

(R)

P

A

≥

=

≥

≥

≥

≥

≥

(cid:18)
(n0/nR)1
−

(cid:19)
1
3

R

2µ

r=1 (cid:18)
Y
R

1

−

(nR

1/nR)1
−

2µ

(cid:19)

−

(n0/nR)1
−

2µ

(n0/nR)1
−

2µ

Yr=1  
1

−

1

−

3n(1
−
R

1
β)(1

−

2µ)

!

R

r=1
X

1
β)(1

−

2µ)

!

3N (1
−
R

= Ω

1/n1
−
R

2µ

.

(cid:16)

(cid:17)

1
3 x2 is
1; the sixth because
nβ
R; and the last because β < 1 and µ < 1/2, the nR’s increase doubly exponentially,

Here the third line follows because 2mR + 1
nondecreasing in the interval [0, 1]; the fourth because P
nR
and n0 is suﬃciently large.

1/nR and the function x

1 ≤

nR

(R

1)

≤

−

≥

−

A

−

−

.

(cid:16)

(cid:17)

= O

OR(1),

Ld (nR)
(cid:17)

O(n1/2
−
R
n1/2
O
R
(cid:16)

Finally, take
µ
) times. This yields an algorithm for searching

AR itself and amplify it to success probability Ω (1) by running it
Ld (nR) with overall running time
n1/2
R
(cid:16)

lution is simple: ﬁrst ﬁnd the largest R such that nR < n. Then set n′ = nR
embed

, which implies that Q
All that remains is to handle values of n that do not equal nR for any R. The so-
, and
Ld (n′)
(cid:17)

Ld (n′). Clearly Q
Ld (n) into the larger hypercube
n1/β
(cid:16)
= O
Also notice that n′ = O (n) and that n′ = O
R
into n′/nR subcubes, each a copy of
(cid:16)
level of recursion, which chooses a subcube of
that subcube, and then ampliﬁes the resulting procedure Θ
time is now

OR(1),
OR(1),
(cid:7)
n3/2
Ld (n′)
R
Ld (nR). The algorithm will now have one additional
(cid:17)
(cid:16)
AR on
Ld (n′) uniformly at random, runs
times. The total
n′/nR

Ld (n)
(cid:6)
≤
(cid:17)
. Next partition

n1/d/ℓR
Q

(cid:17)

(cid:16)

(cid:17)

d

(cid:16)p

(cid:17)

.

n′
nR

O

 r

(cid:16)(cid:0)

n′

1/d + n1/2
R

= O

!

(cid:17)

n′
nR

n1/2
R

!

 r

= O

√n

,

(cid:0)
while the success probability is Ω (1). This completes Theorem 111.

(cid:1)

(cid:1)

 
14.6.3 Dimension 2

In the d = 2 case, the best we can achieve is the following:

180

Theorem 116 Q (OR,

L2) = O

√n log5/2 n

.

(cid:16)

(cid:17)

Again, we start with the single marked vertex case and postpone the general case

to Sections 14.6.4 and 14.6.5.

Theorem 117 Q

OR(1),

= O

L2

√n log3/2 n
(cid:16)

.

(cid:17)

(cid:17)

≥

For d

(cid:16)
) proba-
3, we performed ampliﬁcation on large (greater than O
bilities only once, at the end. For d = 2, on the other hand, any algorithm that we construct
with any nonzero success probability will have running time Ω (√n), simply because that
If we want to keep the running time O (√n), then we can
is the diameter of the grid.
only perform O (1) ampliﬁcation steps at the end. Therefore we need to keep the success
probability relatively high throughout the recursion, meaning that we suﬀer an increase in
the running time, since ampliﬁcation to high probabilities is less eﬃcient.

1/n1

2µ

(cid:0)

(cid:1)

−

The procedures

AR, AR, WR, and SR are identical to those in Section 14.6.2; all
0 , for
that changes are the parameter settings. For all integers R
≥
AR and AR search the square grid
L2 (nR) of
some odd integer ℓ0 ≥
ℓR
size ℓR
AR applies m steps of amplitude ampliﬁcation
0 . Also, let m = (ℓ0 −
to AR.
We now prove the counterparts of Lemmas 114 and 115 for the two-dimensional

0, we now let nR = ℓ2R

3 to be set later. Thus,

1) /2; then

0 ×

case.

Lemma 118

RℓR+1
0

steps.

AR uses O
Proof. Let T
L2 (nR). Then T

A

A

searching

(cid:16)
(R) and TA (R) be the time used by

(cid:17)

AR and AR respectively in

+ 2m

(0) = 1, and for all R

1,

≥

T

(R)

A
TA (R)

(2m + 1) TA (R) + 2m,
2n1/2

1) .

(R

R + T
A

−

≤

≤

(2m + 1)

2n1/2
(cid:16)
0 + T

R + T
A
1)

(R

2ℓR

≤
= ℓ0

A

= O

(cid:0)

= O

(cid:16)

(cid:16)

ℓR+1
0 + ℓ0T

A

RℓR+1
0

.

(cid:17)

1)

(R

−
+ ℓ0 −
1)

(cid:17)
1

(cid:17)

−
(R

(cid:1)
−

Combining,

(R)

T

A

Lemma 119

AR succeeds with probability Ω (1/R).

Proof. Let P

tively when searching
109, and using the fact that 2m + 1 = ℓ0,

L2 (nR). Then PA (R) = P

A

−

A

(R) and PA (R) be the success probabilities of
0 for all R

1) /ℓ2

(R

181

AR and AR respec-
1. So by Lemma
≥

(R)

P

A

1
≥  

−

(2m + 1)2
3

PA (R)

(2m + 1)2 PA (R)

!
P

ℓ2
0

A

1)

(R
ℓ2
0

−

P

A

ℓ2
0
3

−

1)

−

=

1
(cid:18)
= P

(R

1)

−
A
= Ω (1/R) .

(R
ℓ2
0
1
3

−

(cid:19)
(R

P 2
A

1)

−

This is because Ω (R) iterations of the map xR := xR
(say) 2/R to 1/R, and x0 = P

1 −
(0) = 1 is greater than 2/R.

−

1
3 x2
R

−

A

1 are needed to drop from

We can amplify

AR to success probability Ω (1) by repeating it O
= O

L2 (nR) that uses O

(cid:16)
(cid:17)
R3/2ℓR+1
√nRR3/2ℓ0
This yields an algorithm for searching
0
steps in total. We can minimize this expression subject to ℓ2R
(cid:16)
0 = nR by taking ℓ0 to be
(cid:1)
(cid:0)
√nR log n3/2
OR(1),
If
constant and R to be Θ (log nR), which yields Q
L2 (nR)
R
0 , then we simply ﬁnd the smallest integer R such that n < ℓ2R
n is not of the form ℓ2R
(cid:17)
(cid:16)
(cid:17)
0 , and
. Since ℓ0 is a constant, this increases the running
embed
time by at most a constant factor. We have now proved Theorem 117.
(cid:0)

L2 (n) in the larger grid

ℓ2R
0

= O

L2

(cid:17)

(cid:16)

√R

times.

(cid:1)

.

14.6.4 Multiple Marked Items

What about the case in which there are multiple i’s with xi = 1?
If there are k marked
items (where k need not be known in advance), then Grover’s algorithm can ﬁnd a marked
item with high probability in O
In our
setting, however, this is too much to hope for—since even if there are many marked vertices,
they might all be in a faraway part of the hypercube. Then Ω
steps are needed,
Indeed, we can show a stronger lower bound. Recall that OR(k) is
even if
the problem of deciding whether there are no marked vertices or exactly k of them.

queries, as shown by Boyer et al.

n/k < n1/d.

n1/d

(cid:16)p

[66].

n/k

(cid:17)

(cid:0)

(cid:1)

p

Theorem 120 For all constants d

2,

≥

Q

OR(k),
(cid:16)

Ld

(cid:17)

= Ω

√n

k1/2

−

1/d

(cid:18)

.

(cid:19)

Proof. For simplicity, we assume that both k1/d and

n/3dk

1/d

are integers. (In

the general case, we can just replace k by

d

k1/d

and n by the largest number of the form
(cid:1)

(cid:0)

which is less than n. This only changes the lower bound by a lower order

(cid:6)

(cid:7)

(cid:7)(cid:1)
We use a hybrid argument almost identical to that of Theorem 107. Divide

Ld
into n/k subcubes, each having k vertices and side length k1/d. Let S be a regularly-spaced

d

k1/d

3m
term.)
(cid:0)
(cid:6)

3dk

set of M = n/
2k1/d from one another. Then choose a subcube Cj ∈
all k vertices in Cj. This enables us to consider each Cj ∈
of M in total), having distance at least 2k1/d to every other vertex.

of these subcubes, so that any two subcubes in S have distance at least
S uniformly at random and mark
S itself as a single vertex (out

(cid:0)

(cid:1)

182

More formally, given a subcube Cj ∈

1 subcubes surrounding it.

Cj and the 3d
−
Then the query magnitude of

S, let
(Thus,

Cj be the set of vertices consisting of
Cj is a subcube of side length 3k1/d.)
e
Cj after the tth query is
e
α(t)
i,z (X0)
(cid:12)
(cid:12)
(cid:12)

Γ(t)
e
j =

z
Cj X

(cid:12)
(cid:12)
(cid:12)

2

,

Xvi∈
e

where X0 is the all-zero input. Let T be the number of queries, and let w = T /
some constant c > 0. Then as in Theorem 107, there must exist a subcube

ck1/d
for
Cj∗ such that

(cid:0)

(cid:1)

qck1/d)

(T
j∗

Γ

−

w
M

≤

=

3dkw
n

.

w

1

−

q=0
X

e

Let Y be the input which is 1 in Cj∗ and 0 elsewhere; then let Xq be a hybrid input which
qck1/d + 1 to T . Next let
qck1/d, but Y during queries T
is X0 during queries 1 to T

−

D (q, r) =

Xvi∈

z
G X

α(T )
i,z (Xq)
(cid:12)
(cid:12)
(cid:12)

−

−

α(T )
i,z (Xr)

2

.

Then as in Theorem 107, for all c < 1 we have D (q

qck1/d + 1 through T

queries from T
(q
can travel a distance k1/d and thereby reach Cj∗. Therefore switching from Xq
can only aﬀect amplitude that is in

Cj∗ immediately after query T

qck1/d.

−

−

−

−

(cid:12)
(cid:12)
(cid:12)
(T
−
j∗
1) ck1/d, no amplitude originating outside

qck1/d)

1, q)

4Γ

≤

−

. For in the ck1/d
Cj∗
1 to Xq
It follows that

e

−

w

≤

q=1
X
p
√n/k1/2

−

D (0, w)

p

Hence T = Ω
D (0, w) = Ω (1).

(cid:0)

D (q

1, q)

−

e
≤

2

w

Γ

q=1 r
X

qck1/d)

(T
j∗

−

2w

≤

r

3dk
n

=

2√3dk1/2
−
c√n

1/dT

.

1/d

for constant d, since assuming the algorithm is correct we need

(cid:1)
≈

Notice that if k

n, then the bound of Theorem 120 becomes Ω

which is
1/d = 0 and the bound is simply Ω (√n)
just the diameter of
independent of k. The bound of Theorem 120 can be achieved (up to a constant factor that
depends on d) for d
3, and nearly achieved for d = 2. We ﬁrst construct an algorithm
for the case when k is known.

Ld. Also, if d = 2, then 1/2

≥

−

(cid:0)

(cid:1)

n1/d

Theorem 121

(i) For d

3,

≥

Q

OR(k),

(cid:16)

= O

Ld

(cid:17)

√n

k1/2

−

1/d

(cid:18)

.

(cid:19)

(ii) For d = 2,

183

Q

√n log3/2 n
(cid:16)
Ld (n) into n/γ subcubes, each of size
γ1/d (where γ will be ﬁxed later). Then in each subcube, we choose one vertex

To prove Theorem 121, we ﬁrst divide

OR(k),
(cid:16)

= O

L2

(cid:17)

(cid:17)

.

γ1/d
uniformly at random.

× · · · ×

Lemma 122 If γ
(k/γ)2.
least k/γ

−

≥

k, then the probability that exactly one marked vertex is chosen is at

Proof. Let x be a marked vertex. The probability that x is chosen is 1/γ. Given
that x is chosen, the probability that one of the other marked vertices, y, is chosen is 0 if x
and y belong to the same subcube, or 1/γ if they belong to diﬀerent subcubes. Therefore,
the probability that x alone is chosen is at least

1
γ

k

1

−
γ

1

−

1
γ

≥

k
γ

1

−

.

(cid:19)
Since the events “x alone is chosen” are mutually disjoint, we conclude that the probability
that exactly one marked vertex is chosen is at least k/γ

(k/γ)2.

(cid:19)

(cid:18)

(cid:18)

In particular, ﬁx γ so that γ/3 < k < 2γ/3; then Lemma 122 implies that the
probability of choosing exactly one marked vertex is at least 2/9. The algorithm is now as
follows. As in the lemma, subdivide
Ld (n) into n/γ subcubes and choose one location at
random from each. Then run the algorithm for the unique-solution case (Theorem 111 or
Ld (n/γ).
117) on the chosen locations only, as if they were vertices of
for d
n/γ
The running time in the unique case was O
≥

3 or

−

O

log3/2 (n/γ)

= O

n
γ

(cid:17)
log3/2 n

(cid:16)p
n
γ

(cid:18)r

(cid:18)r

(cid:19)
for d = 2. However, each local unitary in the original algorithm now becomes a unitary
aﬀecting two vertices v and w in neighboring subcubes Cv and Cw. When placed side by
side, Cv and Cw form a rectangular box of size 2γ1/d
γ1/d. Therefore the
distance between v and w is at most (d + 1) γ1/d.
It follows that each local unitary in the
original algorithm takes O
3, this results in an
overall running time of

time in the new algorithm. For d

× · · · ×

dγ1/d

γ1/d

×

≥

(cid:19)

O

(cid:18)r

For d = 2 we obtain

(cid:1)

(cid:0)
n
γ

dγ1/d

= O

d

(cid:19)

(cid:18)

√n

γ1/2

−

1/d

(cid:19)

= O

√n

k1/2

−

1/d

(cid:18)

.

(cid:19)

n
γ

O

(cid:18)r

γ1/2 log3/2 n

= O

(cid:19)

√n log3/2 n
(cid:16)

(cid:17)

.

14.6.5 Unknown Number of Marked Items

We now show how to deal with an unknown k. Let OR(
k) be the problem of deciding
whether there are no marked vertices or at least k of them, given that one of these is true.

≥

184

Theorem 123

(i) For d

3,

≥

(ii) For d = 2,

Q

OR(
≥
(cid:16)

k),

Ld

(cid:17)

= O

√n

k1/2

−

1/d

(cid:18)

.

(cid:19)

Q

OR(
≥
(cid:16)

k),

L2

(cid:17)

= O

√n log5/2 n
(cid:16)

(cid:17)

.

Proof. We use the straightforward ‘doubling’ approach of Boyer et al. [66]:

(1) For j = 0 to log2 (n/k)

Run the algorithm of Theorem 121 with subcubes of size γj = 2jk.
If a marked vertex is found, then output 1 and halt.

•

•

(2) Query a random vertex v, and output 1 if v is a marked vertex and 0 otherwise.

Let k∗ ≥

log2 (n/k) such that γj/3

k be the number of marked vertices.

n/3, then there exists a
2γj/3. So Lemma 122 implies that the jth iteration
j
≤
of step (1) ﬁnds a marked vertex with probability at least 2/9. On the other hand, if
3, the
k∗ ≥
time used in step (1) is at most

n/3, then step (2) ﬁnds a marked vertex with probability at least 1/3. For d

If k∗ ≤

k∗ ≤

≤

≥

log2(n/k)

Xj=0

√n

1/d

γ1/2
−
j

=

√n

k1/2

−

1/d 



log2(n/k)

Xj=0

1
2j(1/2

−

= O

1/d) 

√n

k1/2

−

1/d

(cid:18)

,

(cid:19)



the sum in brackets being a decreasing geometric series. For d = 2, the time is O

√n log5/2 n

,

since each iteration takes O

√n log3/2 n

neither case does step (2) aﬀect the bound, since k

(cid:17)

(cid:16)

time and there are at most log n iterations.
√n/k1/2
n implies that n1/d

(cid:16)

(cid:17)

In
1/d.

−

≤

≤

Taking k = 1 gives algorithms for unconstrained OR with running times O(√n)

3 and O(√n log5/2 n) for d = 2, thereby establishing Theorems 110 and 116.

for d

≥

14.7 Search on Irregular Graphs

185

In Section 14.2, we claimed that our divide-and-conquer approach has the advantage of
being robust:
it works not only for highly symmetric graphs such as hypercubes, but for
any graphs having comparable expansion properties. Let us now substantiate this claim.
is d-dimensional if there exists

Say a family of connected graphs

Gn = (Vn, En)
}
{

a κ > 0 such that for all n, ℓ and v

Vn,

∈

B (v, ℓ)
|

| ≥

min

κℓd, n

,

(cid:16)

(cid:17)

Intuitively,
where B (v, ℓ) is the set of vertices having distance at most ℓ from v in Gn.
2 an integer) if its expansion properties are at least as good
Gn is d-dimensional (for d
It is immediate that the diameter of Gn is at most
as those of the hypercube
(n/κ)1/d. Note, though, that Gn might not be an expander graph in the usual sense, since
we have not required that every suﬃciently small set of vertices has many neighbors.

≥
Ld (n).5

Our goal is to show the following.

Theorem 124 If G is d-dimensional, then

(i) For a constant d > 2,

(ii) For d = 2,

Q (OR, G) = O

√n polylog n

.

(cid:0)
Q (OR, G) = √n2O(√log n).

(cid:1)

In proving part (i), the intuition is simple: we want to decompose G recursively
into subgraphs (called clusters), which will serve the same role as subcubes did in the
hypercube case. The procedure is as follows. For some constant n1 > 1, ﬁrst choose
vertices uniformly at random to be designated as 1-pegs. Then form 1-clusters by
n/n1⌉
⌈
assigning each vertex in G to its closest 1-peg, as in a Voronoi diagram.
(Ties are broken
randomly.) Let v (C) be the peg of cluster C. Next, split up any 1-cluster C with more
arbitrarily-chosen 1-clusters, each with size at most n1 and
than n1 vertices into
with v (C) as its 1-peg. Observe that

/n1⌉

⌈|

C

|

n/n1

⌈

⌉

Xi=1 (cid:24)

Ci|
|
n1 (cid:25)

2

≤

,

n
n1 (cid:25)

(cid:24)

⌉

+

+

· · ·

C1|
|

where n =
number of clusters.

. Therefore, the splitting-up step can at most double the

C
n/n1
⌈
In the next iteration, set n2 = n1/β
(2/d, 1). Choose
vertices uniformly at random as 2-pegs. Then form 2-clusters by assigning each
C ′|
|
> n2/n1
arbitrarily-chosen 2-clusters, each with size at most n2/n1 and with

2
1-cluster C to the 2-peg that is closest to the 1-peg v (C). Given a 2-cluster C ′, let
be the number of 1-clusters in C ′. Then as before, split up any C ′ with
into

, for some constant β

n/n2⌉

/ (n2/n1)

C ′|

∈

(cid:12)
(cid:12)

(cid:12)
(cid:12)

⌈

1

|

C ′|

⌈|

⌉

5In general, it makes sense to consider non-integer d as well.

186

.

1

−

⌈

}

n/nR⌉
v

v (C ′) as its 2-peg. Continue recursively in this manner, setting nR = n1/β
1 and choosing
R
−
2R
n.
For technical convenience, set n0 = 1, and consider each vertex v to be the 0-peg of the
0-cluster

vertices as R-pegs for each R. Stop at the maximum R such that nR ≤

In more detail, basis states now have the form

{
At the end we have a tree of clusters, which can be searched recursively just as
in the hypercube case.
, where v is
a vertex, z is an answer bit, and C is the (label of the) cluster currently being searched.
(Unfortunately, because multiple R-clusters can have the same peg, a single auxiliary qubit
1)-clusters in R-cluster C; then
no longer suﬃces.) Also, let K ′ (C) be the number of (R
K ′ (C)
K ′ (C)
“dummy” (R

. If K ′ (C) < K (R), then place K (R)
1)-peg v (C).

1)-clusters in C, each of which has (R

K (R) where K (R) = 2

v, z, C
|

nR/nR

1⌉

−

−

≤

⌈

−

i

i

The algorithm

, where C is an R-cluster. If R = 0, then

v (C) , 0, C
the initial state
|
v (C) , 1, C
formation to prepare the state
|
otherwise. If R
1 and C is not a dummy cluster, then
ampliﬁcation on AR, where mR is the largest integer such that 2mR + 1
C is a dummy cluster, then
returns that no marked item was found.

AR from Section 14.6.2 now does the following, when invoked on
AR uses a query trans-
v (C) , 0, C
i
|
AR performs mR steps of amplitude
If
≤
AR does nothing for an appropriate number of steps, and then
v (C) , 0, C
|

We now describe the subroutine AR, for R
as its initial state, AR ﬁrst prepares a uniform superposition

if v (C) is the marked vertex and

1. When invoked with

nR/nR

1.6

p

≥

≥

−

i

i

−

−

1

K (R)

K(R)

Xi=1

v (Ci) , 0, Cii
|

.

1 recursively, to search C1, . . . , CK(R) in superposition and amplify the

p

It then calls
results.

AR
−

For R

1, deﬁne the radius of an R-cluster C to be the maximum, over all
1)-clusters C ′ in C, of the distance from v (C) to v (C ′). Also, call an R-cluster good

≥

(R
if it has radius at most ℓR, where ℓR =

−

2
κ nR ln n

1/d

.

Lemma 125 With probability 1

−

(cid:0)

(cid:1)

o (1) over the choice of clusters, all clusters are good.

Proof. Let v be the (R

κℓd,
1)-peg of an (R
where B (v, ℓ) is the ball of radius ℓ about v. So the probability that v has distance greater
than ℓR to the nearest R-peg is at most

1)-cluster. Then

B (v, ℓ)
|

| ≥

−

−

n/nR⌉

⌈

κℓd
R
n

1

−

1

−

≤

2 ln n
n/nR (cid:19)

n/nR

<

1
n2 .

(cid:18)

(cid:19)
Furthermore, the total number of pegs is easily seen to be O (n).
bound that every (R
with probability 1

It follows by the union
1)-peg for every R has distance at most ℓR to the nearest R-peg,

o (1) over the choice of clusters.

−
O (1/n) = 1

(cid:18)

We now analyze the running time and success probability of

−

−

6In the hypercube case, we performed fewer ampliﬁcations in order to lower the running time from

√n polylog n to √n. Here, though, the splitting-up step produces a polylog n factor anyway.

AR.

√nR log1/d n

steps, assuming that all clusters are good.

187

Lemma 126

AR uses O
Proof. Let T

A

searching an R-cluster. Then we have

(cid:16)
(R) and TA (R) be the time used by

(cid:17)

AR and AR respectively in

T
(R)
A
TA (R)

≤

≤

nR/nR

ℓR + T
p

A

1TA (R) ,
1)

−
(R

−

with the base case T

A

(0) = 1. Combining,

(R)

T

A

≤

nR/nR

−

1 (ℓR + T

(R

1))

−
A
nR/nR

p

nR/nR

≤
p
= √nR ·

O

−

1ℓR +
(nR ln n)1/d
p
√nR

1

−

+

= √nR

= √nR

ln1/d n
(cid:16)
ln1/d n
(cid:16)

(cid:17)

(cid:17)

·
√nR log1/d n
(cid:16)

= O

O

·

O

n1/d
−
R
(cid:16)

n1/d
−
1

(cid:18)
,

nR/n0ℓ1

2ℓR

−

· · ·

β/2

+

+

1 +
+
· · ·
−
(n1 ln n)1/d
p
√n0

+ n1/d
−
1

· · ·

!
β/2

β/2

+

β/2

n1/d
−
1
(cid:16)

(cid:17)

(cid:17)
1/β
+

+

· · ·

n1/d
−
1
(cid:16)

(1/β)R

−

1

β/2

(cid:17)

(cid:19)

(cid:17)
where the last line holds because β > 2/d and therefore n1/d
−

β/2

< 1.

1

Lemma 127
n = nR, assuming there is a unique marked vertex.

AR succeeds with probability Ω (1/ polylog nR) in searching a graph of size

Proof. For all R

and let P
searching CR. Then for all R

(R) and PA (R) be the success probabilities of
(R

0, let CR be the R-cluster that contains the marked vertex,
AR and AR respectively when
1) / (2K (R)), and therefore
−

1, we have PA (R) = P

≥

≥

A

A

(R)

P

A

1
≥  

−

(2mR + 1)2
3

PA (R)

!

(2mR + 1)2 PA (R)

=

1

(2mR + 1)2
3

·

−

= Ω (P
(R
= Ω (1/ polylog nR) .

1))

−

A

P

(R

1)

−
A
2K (R) !

(2mR + 1)2 P

1)

(R
−
A
2K (R)

Here the third line holds because (2mR + 1)2
because R = Θ (log log nR).
Finally, we repeat

1 ≈
AR itself O(polylog nR) times, to achieve success probability
steps in total. Again, if n is not equal to nR for any
Ω (1) using O
R, then we simply ﬁnd the largest R such that nR < n, and then add one more level of
recursion that searches a random R-cluster and ampliﬁes the result Θ
times. The

K (R) /2, and the last line

√nR polylog nR

nR/nR

≈

(cid:1)

(cid:0)

−

n/nR

(cid:16)p

(cid:17)

 
 
188

resulting algorithm uses O (√n polylog n) steps, thereby establishing part (i) of Theorem
124 for the case of a unique marked vertex. The generalization to multiple marked vertices
is straightforward.

Corollary 128 If G is d-dimensional for a constant d > 2, then

Q

OR(
≥
(cid:16)

k), G
(cid:17)

= O

(cid:18)

√n polylog n
k

k1/2

−

1/d

.

(cid:19)

(cid:0)

n1/d

In iteration j = 0, choose

steps. As in Theorem 123, we give an algorithm

Proof. Assume without loss of generality that k = o (n), since otherwise a marked
con-

item is trivially found in O
sisting of log2 (n/k) + 1 iterations.
n/k
(cid:1)
⌉
uniformly at random. Then run the algorithm for the unique marked vertex case, but
. On the other hand,
instead of taking all vertices in G as 0-pegs, take only w1, . . . , w
⌈
still choose the 1-pegs, 2-pegs, and so on uniformly at random from among all vertices in
G. For all R, the number of R-pegs should be
In general, in iteration j
.
(n/k) /nR⌉
⌈
uniformly at random, and then run the
of
algorithm for a unique marked vertex as if w1, . . . , w
were the only vertices in the
⌈
graph.

B
vertices w1, . . . , w
⌈

vertices w1, . . . , w
⌈

n/(2j k)
⌉

n/(2j k)
⌉

, choose

2jk

n/k

n/

(cid:1)(cid:7)

n/k

B

(cid:6)

(cid:0)

⌉

⌈

⌉

bility Ω (1) there exists an iteration j such that exactly one of w1, . . . , w
⌈
succeeds with probability Ω (1). It remains only to upper-bound
Hence
B
In iteration j, notice that Lemma 125 goes through if we use ℓ(j)
R :=

It is easy to see that, assuming there are k or more marked vertices, with proba-
is marked.
’s running time.
1/d
κ 2jknR ln n

n/(2j k)
⌉

B

k

2

instead of ℓR. That is, with probability 1
every R-cluster has radius at most ℓ(j)
an R-cluster, the recurrence in Lemma 126 becomes

R . So letting T
A

O (k/n) = 1

−

−
(R) be the running time of

o (1) over the choice of clusters,
(cid:1)
(cid:0)
AR on

which is

(R)

T

A

≤

nR/nR

−

p

1

ℓ(j)
R + T
A
(cid:16)

(R

−

1)

= O

√nR

2jk log (n/k)

1/d

(cid:17)

(cid:16)

(cid:0)

(cid:1)

,

(cid:17)

O

√n log1/d n
k
1/d !
(2jk)1/2
−

2jk

n/

. As usual, the case where there is no R such that nR = Θ

if nR = Θ
is
trivially handled by adding one more level of recursion. If we factor in the O (1/ polylog nR)
(cid:0)
AR needed to boost the success probability to Ω (1), then the total running
repetitions of
time of iteration j is

n/

(cid:1)(cid:1)

(cid:1)(cid:1)

(cid:0)

(cid:0)

(cid:0)

2jk

O

√n polylog n
k
1/d !
(2jk)1/2
−

.

Therefore

B

’s running time is

log2(n/k)

O





Xj=0

√n polylog n
(2jk)1/2
−

1/d 

= O

√n polylog n

k1/2

−

1/d

(cid:18)

.

(cid:19)



 
 
For the d = 2 case, the best upper bound we can show is √n2O(√log n). This
Instead of taking
1 = 2R√log n, so that the total number of
. Lemma 125 goes through without modiﬁcation, while the recurrence for

is obtained by simply modifying
nR = n1/µ
1 for some µ, we take nR = 2√log nnR
R
−
−
√log n
levels is
the running time becomes

AR to have a deeper recursion tree.

(cid:6)

(cid:7)

189

(R)

T

A

≤

nR/nR

−

1 (ℓR + T

(R

1))

−
A
nR/nR

p

≤
p
= O

−

nR/nR
1ℓR +
2√log n(R/2)√ln n +
(cid:16)

p

= √n2O(√log n).

nR/n0ℓ1

−

+

1 +

2ℓR
· · ·
−
+ 2√log n(R/2)√ln n
(cid:17)

p

· · ·

Also, since the success probability decreases by at most a constant factor at each level, we
O(√log n), and hence 2O(√log n) ampliﬁcation steps suﬃce to boost
have that P
the success probability to Ω (1). Handling multiple marked items adds an additional factor
of log n, which is absorbed into 2O(√log n). This completes Theorem 124.

(R) = 2−

A

14.7.1 Bits Scattered on a Graph

In Section 14.3, we discussed several ways to pack a given amount of entropy into a spatial
region of given dimensions. However, we said nothing about how the entropy is distributed
within the region.
It might be uniform, or concentrated on the boundary, or distributed in
some other way. So we need to answer the following: suppose that in some graph, h out
of the n vertices might be marked, and we know which h those are. Then how much time
is needed to determine whether any of the h is marked? If the graph is the hypercube
Ld
for d
2 or is d-dimensional for d > 2, then the results of the previous sections imply that
O (√n polylog n) steps suﬃce. However, we wish to use fewer steps, taking advantage of
the fact that h might be much smaller than n. Formally, suppose we are given a graph
G with n vertices, of which h are potentially marked. Let OR(h,
k) be the problem of
deciding whether G has no marked vertices or at least k of them, given that one of these is
the case.

≥

≥

Proposition 129 For all integer constants d
such that

≥

2, there exists a d-dimensional graph G

Q

OR(h,

k), G

≥

= Ω

n1/d

(cid:16)

(cid:17)

h
k

(cid:19)

(cid:18)

1/2

−

1/d

.

!

Proof. Let G be the d-dimensional hypercube

Ld (n). Create h/k subcubes
of potentially marked vertices, each having k vertices and side length k1/d. Space these
(nk/h)1/d
.
subcubes out in
Ld (n) so that the distance between any pair of them is Ω
Then choose a subcube C uniformly at random and mark all k vertices in C. This enables
(cid:17)
(cid:16)
to every other
us to consider each subcube as a single vertex, having distance Ω
vertex. The lower bound now follows by a hybrid argument essentially identical to that of
Theorem 120.

(nk/h)1/d
(cid:16)

(cid:17)

 
190

In particular, if d = 2 then Ω (√n) time is always needed, since the potentially
marked vertices might all be far from the start vertex. The lower bound of Proposition
129 can be achieved up to a polylogarithmic factor.

Proposition 130 If G is d-dimensional for a constant d > 2, then

Q

OR(h,

k), G

≥

= O

n1/d

(cid:16)

(cid:17)

h
k

(cid:18)

(cid:19)

1/2

−

1/d

polylog

h
k !

.

Proof. Assume without loss of generality that k = o (h), since otherwise a marked
from Corollary 128, with the following simple
uni-

item is trivially found. Use algorithm
2jk
change. In iteration j, choose
h/(2j k)
⌉
formly at random, and then run the algorithm for a unique marked vertex as if w1, . . . , w
(cid:6)
⌈
were the only vertices in the graph. That is, take w1, . . . , w
as 0-pegs; then for all
⌈
R
vertices of G uniformly at random as R-pegs. Lemma 125

B
potentially marked vertices w1, . . . , w
⌈

1, choose

h/(2j k)
⌉

h/

h/

(cid:1)(cid:7)

(cid:0)

h/(2j k)
⌉

≥

goes through if we use
(cid:0)
the running time of iteration j is now

(cid:6)

2
κ

n

h 2jknR ln h

k

instead of ℓR. So following Corollary 128,

1/d

(cid:1)

O

√nR

(cid:18)

if nR = Θ

h/

2jk

1/d

polylog

= O

n1/d

h
k

(cid:19)

h
2jk

1/2

−

1/d

polylog

h
k !

(cid:19)

(cid:18)

(cid:17)

(cid:16)
. Therefore the total running time is

2jknR
ℓ(j)
R :=
(cid:1)(cid:7)

(cid:0)

b
2jk

n
h

(cid:0)
(cid:0)
log2(h/k)

(cid:1)(cid:1)
n1/d

Xj=0

h
2jk

(cid:18)

(cid:19)

O





1/2

−

1/d

polylog

h
k 



= O

n1/d

h
k

(cid:19)

(cid:18)

1/2

−

1/d

polylog

h
k !

.

Intuitively, Proposition 130 says that the worst case for search occurs when the h

potential marked vertices are scattered evenly throughout the graph.

14.8 Application to Disjointness

n.

In this section we show how our results can be used to strengthen a seemingly unrelated
n, and
result in quantum computing. Suppose Alice has a string X = x1 . . . xn ∈ {
In the disjointness problem, Alice and Bob
0, 1
Bob has a string Y = y1 . . . yn ∈ {
}
must decide with high probability whether there exists an i such that xi = yi = 1, using
as few bits of communication as possible. Buhrman, Cleve, and Wigderson [76] observed
that in the quantum setting, Alice and Bob can solve this problem using only O (√n log n)
qubits of communication. This was subsequently improved by Høyer and de Wolf [146] to
O
, where c is a constant and log∗ n is the iterated logarithm function. Using
the search algorithm of Theorem 110, we can improve this to O (√n), which matches the
celebrated Ω (√n) lower bound of Razborov [199].

√nclog∗ n

0, 1
}

(cid:0)

(cid:1)

Theorem 131 The bounded-error quantum communication complexity of the disjointness
problem is O (√n).

 
 
 
191

A
A

B
B

Figure 14.3: Alice and Bob ‘synchronize’ locations on their respective cubes.

a 3-D cube
n2/3j + n1/3k + l + 1 and j, k, l
of the form

Proof. The protocol is as follows. Alice and Bob both store their inputs in
L3 (n) (Figure 14.3); that is, they let xjkl = xi and yjkl = yi, where i =
. Throughout, they maintain a joint state

0, . . . , n1/3

1

,

(cid:9)

∈

X

(14.1)

vjkl, zBi

(cid:8)
αj,k,l,zA,zB,c |

−
c
vjkl, zAi ⊗ |
i ⊗ |
where c is used for communication between the players, and zA and zB store the answers to
queries. Thus, whenever Alice is at location (j, k, l) of her cube, Bob is at location (j, k, l)
of his cube. To decide whether there exists a (j, k, l) with xjkl = yjkl = 1, Alice simply runs
our search algorithm for an unknown number of marked items, but with two changes. First,
after each query, Alice inverts her phase if and only if xjkl = yjkl = 1; this requires 2 qubits
of communication from Bob, to send yjkl to Alice and then to erase it.
Second, before
each movement step, Alice tells Bob in which of the six possible directions she is going to
move. That way, Bob can synchronize his location with Alice’s, and thereby maintain the
state in the form (14.1). This requires 6 qubits of communication from Alice, to send the
direction to Bob and then to erase it. Notice that no further communication is necessary,
since there are no auxiliary registers in our algorithm that need to be communicated. Since
the algorithm uses O (√n) steps, the number of qubits communicated in the disjointness
protocol is therefore also O (√n).

14.9 Open Problems

As discussed in Section 14.4.1, a salient open problem raised by this work is to prove
relationships among Z-local, C-local, and H-local unitary matrices.
In particular, can any
Z-local or H-local unitary be approximated by a product of a small number of C-local
unitaries? Also, is it true that Q (f, G) = Θ

QZ (f, G)
A second problem is to obtain interesting lower bounds in our model. For example,
√n grid, and suppose f (X) = 1 if and only if every row of G contains a
, and we conjecture that this is optimal.

let G be a √n
vertex vi with xi = 1. Clearly Q (f, G) = O
However, we were unable to show any lower bound better than Ω (√n).

(cid:1)
Finally, what is the complexity of ﬁnding a unique marked vertex on a 2-D square
grid? As mentioned in Section 14.2, Ambainis, Kempe, and Rivosh [31] showed that
Q

= O (√n log n). Can the remaining factor of log n be removed?

for all f, G?

QH (f, G)

OR(1),

n3/4

= Θ

×

(cid:1)

(cid:0)

(cid:0)

(cid:0)

(cid:1)

L2

(cid:17)

(cid:16)

192

Chapter 15

Quantum Computing and
Postselection

“Gill, in his seminal paper on probabilistic complexity classes, deﬁned the class
PP and asked whether the class was closed under intersection.
In 1990, Fenner
and Kurtz and later myself, decided to try a new approach to the question:
Consider a class deﬁned like PP but with additional restrictions, show that this
class is closed under intersection and then show the class was really the same as
PP.”

—Lance Fortnow, My Computational Complexity Web Log [113]

(the approach didn’t succeed, though as this chapter will show, all it was missing
was quantum mechanics)

Postselection is the power of discarding all runs of a computation in which a given
event does not occur. Clearly, such an ability would let us solve NP-complete problems in
polynomial time, since we could guess a random solution, and then postselect on its being
correct. But would postselection let us do more than NP? Using a classical computer, the
class of problems we could eﬃciently solve coincides with a class called BPPpath, which was
deﬁned by Han, Hemaspaandra, and Thierauf [142] and which sits somewhere between MA
and PP.

This chapter studies the power of postselection when combined with quantum
In Section 15.1, I deﬁne a new complexity class called PostBQP, which is
computing.
similar to BQP except that we can measure a qubit that has some nonzero probability of
. The main result is that PostBQP equals
being
1
i
|
the classical complexity class PP.

, and assume the outcome will be

1
i
|

My original motivation, which I explain in Section 15.2, was to analyze the com-
putational power of “fantasy” versions of quantum mechanics, and thereby gain insight into
why quantum mechanics is the way it is. For example, I show in Section 15.2 that if we
changed the measurement probability rule from
= 2, or allowed linear
but nonunitary gates, then we could simulate postselection, and hence solve PP-complete
problems in polynomial time.
I was also motivated by a concept that I call anthropic com-
puting: arranging things so that you’re more likely to exist if a computer produces a desired

p for some p

2 to

ψ
|

ψ
|

|

|

6
193

output than if it doesn’t. As a simple example, under the many-worlds interpretation of
quantum mechanics, you might kill yourself in all universes where a computer’s output is
incorrect. My result implies that, using this “technique,” the class of problems that you
could eﬃciently solve is exactly PP.

However, it recently dawned on me that the PostBQP = PP result is also in-
In particular, it yields an almost-trivial, quantum
teresting for purely classical reasons.
computing based proof that PP is closed under intersection. This proof does not use ra-
tional approximations, threshold polynomials, or any of the other techniques pioneered by
Beigel, Reingold, and Spielman [47] in their justly-celebrated original proof. Another im-
mediate corollary of my new characterization of PP is a result originally due to Fortnow and
Reingold [115]: that PP is closed under polynomial-time truth-table reductions.
Indeed, I
can show that PP is closed under BQP truth-table reductions, which is a new result as far
as I know.

I conclude in Section 15.3 with some open problems.

15.1 The Class PostBQP

I hereby deﬁne a complexity class:

Deﬁnition 132 PostBQP (Postselected Bounded-Error Quantum Polynomial-Time) is the
class of languages L for which there exists a uniform family of polynomial-size quantum
circuits such that for all inputs x,

(i) At the end of the computation, the ﬁrst qubit has a nonzero probability of being mea-

sured to be

.

1
i
|

(ii) If x

L, then conditioned on the ﬁrst qubit being

∈

probability at least 2/3.

(iii) If x /
∈

probability at most 1/3.

L, then conditioned on the ﬁrst qubit being

, the second qubit is

, the second qubit is

1
i
|

1
i
|

with

with

1
i

|

1
i

|

We can think of PostBQP as the “nondeterministic” version of BQP. Admittedly,
there are already three other contenders for that title: QMA, deﬁned by Watrous [239];
QCMA, deﬁned by Aharonov and Naveh [21]; and NQP, deﬁned by Adleman, DeMarrais,
and Huang [16] (which turns out to equal coC=P [107]). As we will see, PostBQP contains
all of these as subclasses.

It is immediate that NP

PostBQP
the same techniques used by Adleman, DeMarrais, and Huang [16] to show that BQP
but sum only over paths where the ﬁrst qubit is
Theorem 57 of Chapter 10.

PP. For the latter inclusion, we can use
PP,
at the end. This is made explicit in

1
i
|

⊆

⊆

⊆

How robust is PostBQP?

Just as Bernstein and Vazirani [55] showed that in-
termediate measurements don’t increase the power of ordinary quantum computers, so it’s
easy to show that intermediate postselection steps don’t increase the power of PostBQP.
, we simply CNOT that qubit into a
Whenever we want to postselect on a qubit being
fresh ancilla qubit that is initialized to
and that will never be written to again. Then,
at the end, we compute the AND of all the ancilla qubits, and swap the result into the

1
i
|

0
i

|

ﬁrst qubit.
times, and thereby amplify the probability gap from (1/3, 2/3) to
any polynomial p.

It follows that we can repeat a PostBQP computation a polynomial number of
for

p(n), 1

2−

2−

p(n)

−

A corollary of the above observations is that PostBQP has strong closure properties.

(cid:0)

(cid:1)

194

Proposition 133 PostBQP is closed under union, intersection, and complement.
Indeed,
it is closed under BQP truth table reductions, meaning that PostBQP = BQPPostBQP
, classical, where
k
BQPPostBQP
, classical is the class of problems solvable by a BQP machine that can make a polynomial
k
number of nonadaptive classical queries to a PostBQP oracle.

PostBQP. Then to decide whether x

Proof. Clearly PostBQP is closed under complement. To show closure under
L2, run ampliﬁed
L2,
It

intersection, let L1, L2 ∈
∈
computations (with error probability at most 1/6) to decide if x
∈
postselect on both computations succeeding, and accept if and only if both accept.
follows that PostBQP is closed under union as well.
In general, suppose a BQPPostBQP

, classical machine M submits queries q1, . . . , qp(n) to the
k
PostBQP oracle. Then run ampliﬁed computations (with error probability at most, say,
10p(n) ) to decide the answers to these queries, and postselect on all p (n) of them succeeding.
By the union bound, if M had error probability ε with a perfect PostBQP oracle, then its
new error probability is at most ε+1/10, which can easily be reduced through ampliﬁcation.

L1 ∩
∈

L1 and if x

1

One might wonder why Proposition 133 doesn’t go through with adaptive queries.
The reason is subtle: suppose we have two PostBQP computations, the second of which relies
on the output of the ﬁrst. Then even if the ﬁrst computation is ampliﬁed a polynomial
number of times, it still has an exponentially small probability of error. But since the
second computation uses postselection, any nonzero error probability could be magniﬁed
arbitrarily, and is therefore too large.
I now prove the main result.

Theorem 134 PostBQP = PP.

Proof. We have already observed that PostBQP

0, 1
}
{
. Then we need to decide in PostBQP whether s < 2n
x : f (x) = 1

rection, let f :
s =
(As a technicality, we can guarantee using padding that s > 0.)

For the other di-
⊆
be an eﬃciently computable Boolean function and let
1.

0, 1
}

1 or s

→ {

PP.

2n

}|

≥

|{

−

−

n

The algorithm is as follows: ﬁrst prepare the state 2−

.
f (x)
i
Then following Abrams and Lloyd [15], apply Hadamard gates to all n qubits in the ﬁrst
register and postselect1 on that register being

n, to obtain

where

i |

0,1

∈{

x

⊗

n

x

}

|

n

n/2

0
i
|

P
ψ
i
|

⊗

0
i
|
1
0
s)
i
i
|
|
s)2 + s2

+ s

.

−
(2n

−

(2n

=

ψ
|

i

q

1Postselection is actually overkill here, since the ﬁrst register has at least 1/4 probability of being

n.

⊗

0
i
|

195

1

+

0

Figure 15.1: If s and 2n
eventually get close to
1
+
i
|
|
is not positive (dotted line), then we never even get into the ﬁrst quadrant.

2s are both positive, then as we vary the ratio of β to α, we
2s
= (

) /√2 (dashed lines). On the other hand, if 2n

0
i
|

−
i

−

+

Next, for some positive real numbers α, β to be speciﬁed later, prepare α
where

ψ

0
i |
|

i

+ β

H

1
i
|

ψ
|

i

H

ψ
|

i

=

p

1/2 (2n)

1/2 (2n

2s)

1
i
|

−

+

0
i
|
(2n

q

s)2 + s2
p
−
ψ
|

i

is the result of applying a Hadamard gate to
. This yields the reduced state
being

1
i
|

. Then postselect on the second qubit

αs

ϕβ/α

=

0
i

+ β

1/2 (2n

−
|
α2s2 + (β2/2) (2n
p

2s)

1
|
i
2s)2

−

(cid:12)
(cid:12)

(cid:11)

q

in the ﬁrst qubit.

Suppose s < 2n

−

claim there exists an integer i
0
= (
the state
i
|

∈
) /√2:
1
i

+

+

i

|

|

[

−

1, so that s and

−
n, n] such that, if we set β/α = 2i, then

2s) are both at least 1. Then we
is close to

1/2 (2n

p

ϕ2i
|

i

+

|h

ϕ2i
|

i| ≥

1 + √2
√6

> 0.985.

1/2 (2n
2s) /s lies between 2−
−
ϕ2i+1
and
ϕ2i
p
|
|

For since
such that
i
15.1). So the worst case is that
+
h
+
0
ϕ2i+1
i
|
ϕ2i
|

1]
in the ﬁrst quadrant (see Figure
fall on opposite sides of
ϕ2i
+
=
2/3
+
0
h
i
|
1, so that
. On the other hand, suppose s
0
i
|
never lies in the ﬁrst or third quadrants, and therefore
p

n and 2n, there must be an integer i

, which occurs when
i

1/3
i
|
0. Then
2s)
p
1/√2 < 0.985.

ϕ2i+1
|

ϕ2i
|

=
2n

i
2/3

[
−

i
≥

n, n

and

−
p

=

−

+

≤

∈

i

i

i

|

|

1/3
0
i
|
1/2 (2n
p
ϕ2i
+
p
|
|h

−
i| ≤

196

It follows that, by repeating the whole algorithm n (2n + 1) times (as in Proposi-
1 or
[
−

n, n], we can learn whether s < 2n

tion 133), with n invocations for each integer i
s

1 with exponentially small probability of error.

2n

∈

−

Combining Proposition 133 with Theorem 134 immediately yields that PP is closed

−

≥

under intersection, as well as under BQP truth-table reductions.

15.2 Fantasy Quantum Mechanics

“It is striking that it has so far not been possible to ﬁnd a logically consis-
tent theory that is close to quantum mechanics, other than quantum mechanics
itself.”

—Steven Weinberg, Dreams of a Final Theory [241]

Is quantum mechanics an island in theoryspace? By “theoryspace,” I mean the
space of logically conceivable physical theories, with two theories close to each other if they
diﬀer in few respects. An “island” in theoryspace is then a natural and interesting theory,
whose neighbors are all somehow perverse or degenerate. The Standard Model is not an
island, because we do not know of any compelling (non-anthropic) reason why the masses
and coupling constants should have the values they do.
Likewise, general relativity is
probably not an island, because of alternatives such as the Brans-Dicke theory.

To many physicists, however, quantum mechanics does seem like an island: change
any one aspect, and the whole theory becomes inconsistent or nonsensical. There are many
mathematical results supporting this opinion: for example, Gleason’s Theorem [127] and
2 probability rule [93, 252]; arguments for why amplitudes have
other “derivations” of the
to be complex numbers, rather than real numbers or quaternions [81, 143]; and “absurd”
consequences of allowing nonlinear transformations between states [15, 126, 191]. The
point of these results is to provide some sort of explanation for why quantum mechanics
has the properties it does.

ψ
|

|

In 1998, Abrams and Lloyd [15] suggested that computational complexity could
also be pressed into such an explanatory role.
In particular, they showed that under
almost any nonlinear variant of quantum mechanics, one could build a “nonlinear quantum
computer” able to solve NP-complete and even #P-complete problems in polynomial time.2
One interpretation of their result is that we should look very hard for nonlinearities in
experiments! But a diﬀerent interpretation, the one I prefer, is that their result provides
independent evidence that quantum mechanics is linear.3

2A caveat is that it remains an open problem whether this can be done fault-tolerantly. The answer
might depend on the allowed types of nonlinear gate. On the other hand, if arbitrary 1-qubit nonlinear
gates can be implemented without error, then even PSPACE-complete problems can be solved in polynomial
time. This is tight, since nonlinear quantum computers can also be simulated in PSPACE.
I will give more
details in a forthcoming survey paper [12].

3Note that I would not advocate this interpretation if it was merely (say) graph isomorphism that
was eﬃciently solvable in nonlinear quantum mechanics, just as I do not take Shor’s factoring algorithm as
evidence for the falsehood of ordinary quantum mechanics. I will explain in [12] why I think this distinction,
between NP-complete problems and speciﬁc NP-intermediate problems, is a justiﬁed one.

197

In this section I build on Theorem 134 to oﬀer similar “evidence” that quantum

mechanics is unitary, and that the measurement rule is

Let BQPnu be the class of problems solvable by a uniform family of polynomial-size,
bounded-error quantum circuits, where the circuits can consist of arbitrary 1- and 2-qubit
Immediately
invertible linear transformations, rather than just unitary transformations.
2 to
αy|
before a measurement, the amplitude αx of each basis state
normalize it.

is divided by

x
i
|

y |

qP

2.

ψ
|

|

Proposition 135 BQPnu = PP.

Proof. The inclusion BQPnu

Huang’s proof that BQP
direction, by Theorem 134 it suﬃces to show that PostBQP
qubit being

, we simply apply the 1-qubit nonunitary operation

PP follows easily from Adleman, DeMarrais, and
PP [16], which does not depend on unitarity. For the other
BQPnu. To postselect on a

⊆

⊆

⊆

1
i
|

for some suﬃciently large polynomial q.

q(n) 0
2−
1
0

(cid:19)

(cid:18)

Next, for any nonnegative real number p, deﬁne BQPp similarly to BQP, except
p
αy|
2. Thus BQP2 = BQP. Assume that all gates are unitary and that there

that when we measure, the probability of obtaining a basis state
rather than
are no intermediate measurements, just a single standard-basis measurement at the end.

αx|
|

αx|
|

equals

x
i

p /

y |

P

|

Theorem 136 PP
4, 6, 8, . . .
p

∈ {

.
}

BQPp ⊆

⊆

PSPACE for all constants p

= 2, with BQPp = PP when

1

p
|

poly (n)

Proof. To simulate PP in BQPp, run the algorithm of Theorem 134, having
. Suppose the algorithm’s state at some
S, where S is a subset of
x
|
if p < 2, then for some suﬃciently large polynomial q, apply
S. The

initialized O
−
x
x αx |
point is
(cid:16)
i
basis states. Here is how:
Hadamard gates to c = 2q (n) / (2
result is to increase the “probability mass” of each

ancilla qubits to
2
|
, and we want to postselect on the event

p) fresh ancilla qubits conditioned on

S from

p to

0
i
|

x
|

i ∈

i ∈

P

−

(cid:17)

x
|
αx|
|

i ∈
p = 2q(n)

αx|
|
p ,
αx|

|

p

2−

c/2αx

= 2(2
−

p)c/2

2c

·

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
x
(cid:12)
i
|

q(n)

/
∈

αx|
|

2) fresh ancilla qubits conditioned on

while the probability mass of each
apply Hadamard gates to c = 2q (n) / (p
/
x
S. This decreases the probability mass of each
i
|
∈
p, while the probability mass of each
2−
x
i ∈
|
observation is that Theorem 134 still goes through if p
> 0.985 from
the case
error, using polynomially many copies of the state
since all

S remains unchanged. Similarly, if p > 2, then
/
∈
p to 2c
S from
=
S remains unchanged. The ﬁnal
= 2. For it suﬃces to distinguish
1/√2 with exponentially small probability of
. But we can do this for any p,
p).
αβ
|

ϕ2i
i| ≤
|
p rules behave well under tensor products (in the sense that

x
|
i
p
c/2αx

αx|
|

ϕ2i
|

ϕ2i
|

α
|
|

p =

ψ
|

β
|

2−

+

−

+

|h

|h

i|

(cid:12)
(cid:12)

(cid:12)
(cid:12)

i

p

|

|

·

|

6
6
198

x

S |
∈

stein and Vazirani [55] to show BQP
simply compute

The inclusion BQPp ⊆
p and

PSPACE follows easily from the techniques used by Bern-
PSPACE. Let S be the set of accepting states; then
αx|
αx|
To simulate BQPp in PP when p

, we generalize the technique of
}
∈ {
Adleman, DeMarrais, and Huang [16], which handled the case p = 2. As in Theorem 57 in
Chapter 10, assume that all gates are Hadamard or Toﬀoli gates; then we can write each
amplitude αx as a sum of exponentially many contributions, ax,1 +
+ ax,N , where each
ax,i is a rational real number computable in classical polynomial time. Then letting S be
the set of accepting states, it suﬃces to test whether

p and see which is greater.

⊆
S |
x /
∈

4, 6, 8, . . .

· · ·

P

P

p =

αx|
|

αp
x

S
Xx
∈

S
Xx
∈

=

=

S
Xx
∈





1,...,N

Xi
∈{

}

p

ax,i


ax,i

is greater than

S XB
Xx
,
1,...,N
∈
}
⊆{
p, which we can do in PP.

S |
x /
∈

αx|

B

B
=p Yi
∈

|

|

P
15.3 Open Problems

The new proof that PP is closed under intersection came as a total surprise to me. But on
reﬂection, it goes a long way toward convincing me of a thesis expressed in Chapter 1: that
quantum computing oﬀers a new perspective from which to revisit the central questions of
classical complexity theory. What other classical complexity classes can we characterize in
quantum terms, and what other questions can we answer by that means?

A ﬁrst step might be to prove even stronger closure properties for PP. Recall
from Proposition 133 that PostBQP is closed under polynomial-time truth-table reductions.
Presumably this can’t be generalized to closure under Turing reductions, since if it could
then we would have PP = PPP, which is considered unlikely.4 But can we show closure
under nonadaptive quantum reductions? More formally, let BQPPostBQP
be the class of
problems solvable by a BQP machine that can make a single quantum query, which consists
of a list of polynomially many questions for a PostBQP oracle. Then does BQPPostBQP
equal PostBQP? The diﬃculty in showing this seems to be uncomputing garbage after the
PostBQP oracle is simulated.

k

k

As for fantasy quantum mechanics, an interesting open question is whether BQPp =
= 2. An obvious idea for simulating BQPp in PP
p. Unfortunately,

PP for all nonnegative real numbers p
would be to use a Taylor series expansion for the probability masses
I have no idea how to get fast enough convergence.

αx|
|

4Indeed, Beigel [46] gave an oracle relative to which PNP

PP.

6⊂

6
199

Chapter 16

The Power of History

Quantum mechanics lets us calculate the probability that (say) an electron will
be found in an excited state if measured at a particular time. But it is silent about
multiple-time or transition probabilities: that is, what is the probability that the electron
will be in an excited state at time t1, given that it was in its ground state at an earlier
time t0? The usual response is that this question is meaningless, unless of course the
electron was measured (or otherwise known with probability 1) to be in its ground state
at t0. A diﬀerent response—pursued by Schr¨odinger [213], Bohm [59], Bell [49], Nelson
[181], Dieks [97], and others—treats the question as provisionally meaningful, and then
investigates how one might answer it mathematically.
Speciﬁc attempts at answers are
called “hidden-variable theories.”

The appeal of hidden-variable theories is that they provide one possible solution to
the measurement problem. For they allow us to apply unitary quantum mechanics to the
entire universe (including ourselves), yet still discuss the probability of a future observation
conditioned on our current observations. Furthermore, they let us do so without making
any assumptions about decoherence or the nature of observers. For example, even if an
observer were placed in coherent superposition, that observer would still have a sequence
of deﬁnite experiences, and the probability of any such sequence could be calculated.

This chapter initiates the study of hidden variables from a quantum computing
perspective.
I restrict attention to the simplest possible setting: that of discrete time,
a ﬁnite-dimensional Hilbert space, and a ﬁxed orthogonal basis. Within this setting, I
reformulate known hidden-variable theories due to Dieks [97] and Schr¨odinger [213], and also
introduce a new theory based on network ﬂows. However, a more important contribution
is the axiomatic approach that I use.
I propose ﬁve axioms for hidden-variable theories,
and then compare theories against each other based on which of the axioms they satisfy. A
central question in this approach is which subsets of axioms can be satisﬁed simultaneously.
In a second part of the chapter, I make the connection to quantum computing
explicit, by studying the computational complexity of simulating hidden-variable theories.
Below I describe the computational results.

200

16.1 The Complexity of Sampling Histories

It is often stressed that hidden-variable theories yield exactly the same predictions as ordi-
nary quantum mechanics. On the other hand, these theories describe a diﬀerent picture of
physical reality, with an additional layer of dynamics beyond that of a state vector evolving
I address a question that, to my knowledge, had never been raised before: what
unitarily.
is the computational complexity of simulating that additional dynamics?
In other words,
if we could examine a hidden variable’s entire history, then could we solve problems in
polynomial time that are intractable even for quantum computers?

I present strong evidence that the answer is yes. The Graph Isomorphism problem
Rn,
asks whether two graphs G and H are isomorphic; while given a basis for a lattice
L ∈
within a √n
the Approximate Shortest Vector problem asks for a nonzero vector in
I show that both problems are eﬃciently solvable by sampling a
factor of the shortest one.
hidden variable’s history, provided the hidden-variable theory satisﬁes a reasonable axiom.
By contrast, despite a decade of eﬀort, neither problem is known to lie in BQP. Thus,
if we let DQP (Dynamical Quantum Polynomial-Time) be the class of problems solvable
in the new model, then this already provides circumstantial evidence that BQP is strictly
contained in DQP.

L

However, the evidence is stronger than this. For I actually show that DQP contains
the entire class Statistical Zero Knowledge, or SZK. Furthermore, Chapter 6 showed that
DQP
relative to an oracle, SZK is not contained in BQP. Combining the result that SZK
with the oracle separation of Chapter 6, one obtains that BQP
= DQP relative to an oracle
as well.

⊆

Besides solving SZK problems, I also show that by sampling histories, one could
N 1/3

search an unordered database of N items for a single “marked item” using only O
N 1/2
database queries. By comparison, Grover’s quantum search algorithm [139] requires Θ
(cid:1)
(cid:0)
queries, while classical algorithms require Θ (N ) queries. On the other hand, I also show
that the N 1/3 upper bound is the best possible—so even in the histories model, one cannot
search an N -item database in (log N )c steps for some ﬁxed power c. This implies that
NP
DQP relative to an oracle, which in turn suggests that DQP is still not powerful
enough to solve NP-complete problems in polynomial time.

6⊂

(cid:0)

(cid:1)

At this point I should address a concern that many readers will have. Once we
extend quantum mechanics by positing the “unphysical” ability to sample histories, isn’t it
completely unsurprising if we can then solve problems that were previously intractable? I
believe the answer is no, for three reasons.

First, almost every change that makes the quantum computing model more pow-
erful, seems to make it so much more powerful that NP-complete and even harder problems
become solvable eﬃciently. To give some examples, NP-complete problems can be solved
in polynomial time using a nonlinear Schr¨odinger equation, as shown by Abrams and Lloyd
[15]; using closed timelike curves, as shown by Brun [72] and Bacon [40] (and conjectured
by Deutsch [91]); or using a measurement rule of the form
= 2, as shown in
It is also easy to see that we could solve NP-complete problems if, given a
Chapter 15.
, such as a list of ampli-
quantum state
i

, we could request a classical description of

p for any p
|

ψ

ψ

ψ

i

|

|

|

6
6
201

tudes or a preparation procedure.1 By contrast, the DQP model is the ﬁrst independently
motivated model I know of that seems more powerful than quantum computing, but only
slightly so.2 Moreover, the striking fact that unordered search takes about N 1/3 steps in
the DQP model, as compared to N steps classically and N 1/2 quantum-mechanically, sug-
gests that DQP somehow “continues a sequence” that begins with P and BQP.
It would
be interesting to ﬁnd a model in which search takes N 1/4 or N 1/5 steps.

The second reason the results are surprising is that, given a hidden variable, the
distribution over its possible values at any single time is governed by standard quantum
mechanics, and is therefore eﬃciently samplable on a quantum computer. So if examining
the variable’s history confers any extra computational power, then it can only be because
of correlations between the variable’s values at diﬀerent times.
The third reason is the criterion for success.

I am not saying merely that one
can solve Graph Isomorphism under some hidden-variable theory; or even that, under any
theory satisfying the indiﬀerence axiom, there exists an algorithm to solve it; but rather that
there exists a single algorithm that solves Graph Isomorphism under any theory satisfying
indiﬀerence. Thus, we must consider even theories that are speciﬁcally designed to thwart
such an algorithm.

But what is the motivation for these results? The ﬁrst motivation is that, within
the community of physicists who study hidden-variable theories such as Bohmian mechan-
ics, there is great interest in actually calculating the hidden-variable trajectories for speciﬁc
physical systems [190, 140]. My results show that, when many interacting particles are
involved, this task might be fundamentally intractable, even if a quantum computer were
available. The second motivation is that, in classical computer science, studying “unreal-
istic” models of computation has often led to new insights into realistic ones; and likewise I
expect that the DQP model could lead to new results about standard quantum computation.
Indeed, in a sense this has already happened—for the collision lower bound of Chapter 6
grew out of work on the BQP versus DQP question.

16.2 Outline of Chapter

Sections 16.3 through 16.6.2 develop the axiomatic approach to hidden variables; then
Sections 16.7 through 16.10 study the computational complexity of sampling hidden-variable
histories.

Section 16.3 formally deﬁnes hidden-variable theories in my sense; then Section
16.3.1 contrasts these theories with related ideas such as Bohmian mechanics and modal
interpretations. Section 16.3.2 addresses the most common objections to my approach: for
example, that the implicit dependence on a ﬁxed basis is unacceptable.

In Section 16.4, I introduce ﬁve possible axioms for hidden-variable theories. These
are indiﬀerence to the identity operation; robustness to small perturbations; commutativity

instance of interest to us has no solution, but

1For as Abrams and Lloyd [15] observed, we can so arrange things that

if an NP-complete
for some tiny ε if it has a solution.
2One can deﬁne other, less motivated, models with the same property by allowing “non-collapsing mea-
surements” of quantum states, but these models are very closely related to DQP.
Indeed, a key ingredient
in the results of this chapter will be to show that certain kinds of non-collapsing measurements can be
simulated using histories.

= √1

+ √ε

0
i
|

1
i
|

0
i
|

ψ
|

ψ
|

−

=

ε

i

i

202

with respect to spacelike-separated unitaries; commutativity for the special case of product
Ideally, a
states; and invariance under decomposition of mixed states into pure states.
theory would satisfy all of these axioms. However, I show in Section 16.5 that no theory
satisﬁes both indiﬀerence and commutativity; no theory satisﬁes both indiﬀerence and a
stronger version of robustness; no theory satisﬁes indiﬀerence, robustness, and decomposi-
tion invariance; and no theory satisﬁes a stronger version of decomposition invariance.

FT

In Section 16.6 I shift from negative to positive results. Section 16.6.1 presents a
hidden-variable theory called the ﬂow theory or
, which is based on the Max-Flow-Min-
Cut theorem from combinatorial optimization. The idea is to deﬁne a network of “pipes”
from basis states at an initial time to basis states at a ﬁnal time, and then route as much
probability mass as possible through these pipes. The capacity of each pipe depends on
the corresponding entry of the unitary acting from the initial to ﬁnal time. To ﬁnd the
, we then determine how
i
probability of transitioning from basis state
i
i
|
. The main results are
much of the ﬂow originating at
j
|
that
trivially
satisﬁes the indiﬀerence axiom, this implies that the indiﬀerence and robustness axioms can
be satisﬁed simultaneously, which was not at all obvious a priori.

is well-deﬁned and that it is robust to small perturbations. Since

j
|
is routed along the pipe to

to basis state

FT

FT

i
i

i

|

ST

Section 16.6.2 presents a second theory that I call the Schr¨odinger theory or

,
since it is based on a pair of integral equations introduced in a 1931 paper of Schr¨odinger
[213]. Schr¨odinger conjectured, but was unable to prove, the existence and uniqueness of a
solution to these equations; the problem was not settled until the work of Nagasawa [179]
in the 1980’s.
In the discrete setting the problem is simpler, and I give a self-contained
proof of existence using a matrix scaling technique due to Sinkhorn [221]. The idea is as
follows: we want to convert a unitary matrix that maps one quantum state to another, into
a nonnegative matrix whose ith column sums to the initial probability of basis state
, and
i
i
whose jth row sums to the ﬁnal probability of basis state
. To do so, we ﬁrst replace each
entry of the unitary matrix by its absolute value, then normalize each column to sum to the
desired initial probability, then normalize each row to sum to the desired ﬁnal probability.
But then the columns are no longer normalized correctly, so we normalize them again, then
I show that this iterative process converges, from
normalize the rows again, and so on.
satisﬁes the indiﬀerence
which it follows that
and product commutativity axioms, and violates the decomposition invariance axiom.
I
conjecture that
satisﬁes the robustness axiom; proving that conjecture is one of the
ST
main open problems of the chapter.

I also observe that

is well-deﬁned.

ST

ST

j
|

i

|

In Section 16.7 I shift attention to the complexity of sampling histories. I formally
deﬁne DQP as the class of problems solvable by a classical polynomial-time algorithm with
access to a “history oracle.” Given a sequence of quantum circuits as input, this oracle
returns a sample from a corresponding distribution over histories of a hidden variable,
“adversarially,”
according to some hidden-variable theory
subject to the constraint that
satisﬁes the indiﬀerence and robustness axioms. Thus,
a key result from Section 16.7 that I rely on is that there exists a hidden-variable theory
satisfying indiﬀerence and robustness.

. The oracle can choose

T

T

T

Section 16.7.1 establishes the most basic facts about DQP:
for example, that
DQP, and that DQP is independent of the choice of gate set. Then Section 16.8

BQP

⊆

presents the “juggle subroutine,” a crucial ingredient in both of the main hidden-variable
) /√2 or (
) /√2, the goal of this
+
a
algorithms. Given a state of the form (
b
a
i
i
|
i − |
|
i
subroutine is to “juggle” a hidden variable between
, so that when we inspect the
b
i
|
hidden variable’s history, both
are observed with high probability. The diﬃculty
and
is that this needs to work under any indiﬀerent hidden-variable theory.

a
i
|

and

a
i

b
|

b
|

i

|

203

Next, Section 16.9 combines the juggle subroutine with a technique of Valiant and
Vazirani [231] to prove that SZK
DQP, from which it follows in particular that Graph
Isomorphism and Approximate Shortest Vector are in DQP. Then Section 16.10 applies
queries, and also proves
the juggle subroutine to search an N -item database in O
that this N 1/3 bound is optimal.

N 1/3

⊆

I conclude in Section 16.11 with some directions for further research.

(cid:0)

(cid:1)

16.3 Hidden-Variable Theories

Suppose we have an N

×

N unitary matrix U , acting on a state

N
+ αN |
1
= α1 |
i
is a standard orthogonal basis. Let

ψ
|

· · ·

+

i

,

i

where

1
i
|

, . . . ,

N
|

i

Then can we construct a stochastic matrix S, which maps the vector of probabilities

U

ψ

|

i

1
= β1 |
i

+

· · ·

N
+ βN |

i

.

induced by measuring

, to the vector

ψ
|

i

|




2

|

α1|
...
αN |

2

2

β1|
|
...
βN |
|

2











−→p = 

−→q = 




? Trivially yes. The following matrix maps any vector of

induced by measuring U
ψ
i
|
probabilities to −→q , ignoring the input vector −→p entirely:
2
β1|
...
βN |
|

β1|
|
...
βN |
|

= 

· · ·

· · ·

PT

S

2

2

|

2




.






PT

Here
stands for product theory. The product theory corresponds to a strange picture
of physical reality, in which memories and records are completely unreliable, there being no
causal connection between states of aﬀairs at earlier and later times.

So we would like S to depend on U itself somehow, not just on

Indeed, ideally S would be a function only of U , and not of

ψ
|

i

.
ψ
i
|
. But this is impossible, as

and U

ψ
|

i

the following example shows. Let U be a π/4 rotation, and let
+
|

1
0
= (
i
i − |
|

) /√2. Then U

implies that

1
i

|−i

=

i

|

204

+
|

i

= (
|

0
i

+

1
i
|

) /√2 and

whereas U

=

0
i
|

|−i

implies that

+

S (
|

i

, U ) =

S (

|−i

, U ) =

0 0
1 1

1 1
0 0

,

.

(cid:21)

(cid:21)

(cid:20)

(cid:20)

On the other hand, it is easy to see that, if S can depend on

as well as U ,
ψ
i
then there are inﬁnitely many choices for the function S (
, U ). Every choice reproduces
ψ
|
the predictions of quantum mechanics perfectly when restricted to single-time probabilities.
So how can we possibly choose among them? My approach in Sections 16.4 and 16.6 will
be to write down axioms that we would like S to satisfy, and then investigate which of the
axioms can be satisﬁed simultaneously.

i

|

Formally, a hidden-variable theory is a family of functions

SN maps an N -dimensional mixed state ρ and an N
stochastic matrix SN (ρ, U ).
occasionally use subscripts such as
ρ =

1, where each
SN }N
{
N unitary matrix U onto a singly
I will often suppress the dependence on N , ρ, and U , and
to indicate the theory in question. Also, if
ψ

ψ
|
Let (M )ij denote the entry in the ith column and jth row of matrix M . Then (S)ij
after U is applied, conditioned
j
|
before U is applied. At a minimum, any theory must satisfy the

or
FT
ψ
is a pure state I may write S (
i
|

is the probability that the hidden variable takes value
i
on it taking value
i
|
following marginalization axiom: for all j

ψ
, U ) instead of S (
|

1, . . . , N

, U ).

ψ
|

PT

i h

i h

×

≥

i

,

|

∈ {

(S)ij (ρ)ii =

U ρU −

Xi

(cid:0)

}
1

jj .

(cid:1)

1

This says that after U is applied, the hidden variable takes value
U ρU −

jj, which is the usual Born probability.
Often it will be convenient to refer, not to S itself, but to the matrix P (ρ, U ) of
(cid:0)
(cid:1)
joint probabilities whose (i, j) entry is (P )ij = (S)ij (ρ)ii. The ith column of P must sum
1
to (ρ)ii, and the jth row must sum to
and
by ﬁrst specifying the matrix P , and then setting (S)ij := (P )ij / (ρ)ii. This approach
(cid:1)
ST
has the drawback that if (ρ)ii = 0, then the ith column of S is undeﬁned. To get around
this, I adopt the convention that

jj. Indeed, I will deﬁne the theories

with probability

U ρU −

FT

j
|

(cid:0)

i

S (ρ, U ) := lim
0+

ε

S (ρε, U )

→
N maximally mixed state. Technically, the

where ρε = (1
limits

−

ε) ρ + εI and I is the N

×
(P (ρε, U ))ij
(ρε)ii

lim
0+
ε
→
might not exist, but in the cases of interest it will be obvious that they do.

16.3.1 Comparison with Previous Work

205

Before going further, I should contrast my approach with previous approaches to hidden
variables, the most famous of which is Bohmian mechanics [59]. My main diﬃculty with
Bohmian mechanics is that it commits itself to a Hilbert space of particle positions and
momenta. Furthermore, it is crucial that the positions and momenta be continuous, in
be discrete
order for particles to evolve deterministically. To see this, let
) /√2 at
positions, and suppose a particle is in state
R
i
|
a later time t1. Then a hidden variable representing the position would have entropy 0
both with
R
at t1, since it is always
i
1/2 probability. Therefore the earlier value cannot determine the later one.3
It follows
that Bohmian mechanics is incompatible with the belief that all physical observables are
discrete. But in my view, there are strong reasons to hold that belief, which include black
33 cm); results
hole entropy bounds; the existence of a natural minimum length scale (10−
on area quantization in quantum gravity [205]; the fact that many physical quantities once
thought to be continuous have turned out to be discrete; the inﬁnities of quantum ﬁeld
theory; the implausibility of analog “hypercomputers”; and conceptual problems raised by
the independence of the continuum hypothesis.

and
L
at time t0, and state (
|

then; but entropy 1 at t1, since it is

R
i
+

L
|

L
|

or

|
i

L

L

i

i

i

i

|

|

|

Of course there exist stochastic analogues of Bohmian mechanics, among them
Nelsonian mechanics [181] and Bohm and Hiley’s “stochastic interpretation” [60]. But it is
not obvious why we should prefer these to other stochastic hidden-variable theories. From
a quantum-information perspective, it is much more natural to take an abstract approach—
one that allows arbitrary ﬁnite-dimensional Hilbert spaces, and that does not rule out any
transition rule a priori.

Stochastic hidden variables have also been considered in the context of modal
interpretations; see Dickson [96], Bacciagaluppi and Dickson [39], and Dieks [97] for example.
However, the central assumptions in that work are extremely diﬀerent from mine.
In
modal interpretations, a pure state evolving unitarily poses no problems at all: one simply
rotates the hidden-variable basis along with the state, so that the state always represents
a “possessed property” of the system in the current basis. Diﬃculties arise only for mixed
states; and there, the goal is to track a whole set of possessed properties. By contrast, my
approach is to ﬁx an orthogonal basis, then track a single hidden variable that is an element
of that basis. The issues raised by pure states and mixed states are essentially the same.
Finally I should mention the consistent-histories interpretation of Griﬃths [137]
and Gell-Mann and Hartle [122]. This interpretation assigns probabilities to various his-
tories through a quantum system, so long as the “interference” between those histories is
negligible. Loosely speaking, then, the situations where consistent histories make sense are
precisely the ones where the question of transition probabilities can be avoided.

3Put diﬀerently, Bohm’s conservation of probability result breaks down because the “wavefunctions” at
t0 and t1 are degenerate, with all amplitude concentrated on ﬁnitely many points. But in a discrete Hilbert
space, every wavefunction is degenerate in this sense!

206

16.3.2 Objections

Hidden-variable theories, as I deﬁne them, are open to several technical objections. For
example, I required transition probabilities for only one orthogonal observable. What
about other observables? The problem is that, according to the Kochen-Specker theorem,
we cannot assign consistent values to all observables at any single time, let alone give
transition probabilities for those values. This is an issue in any setting, not just mine. The
solution I prefer is to postulate a ﬁxed orthogonal basis of “distinguishable experiences,”
and to interpret a measurement in any other basis as a unitary followed by a measurement
in the ﬁxed basis. As mentioned in Section 16.3.1, modal interpretations opt for a diﬀerent
solution, which involves sets of bases that change over time with the state itself.

time t1 to basis state
between t1 and t2.

Another objection is that the probability of transitioning from basis state

at
at time t2 might depend on how ﬁnely we divide the time interval
and unitaries V, W , we might have

In other words, for some state

i
i
|

j
|

i

ψ
|

i

ψ
S (
|

i

, W V )

= S (V

ψ
|

i

ψ
, W ) S (
|

i

, V )

i

ψ
|

, there exist unitaries V, W such that U = W V and V

Indeed, this is true for any hidden-variable
(a similar point was made by Gillespie [125]).
. To see this, observe that for all unitaries U and
theory other than the product theory
states
. Then applying
ψ
V destroys all information in the hidden variable (that is, decreases its entropy to 0); so
if we then apply W , then the variable’s ﬁnal value must be uncorrelated with the initial
value.
, U ). It follows that to
any hidden-variable theory we must associate a time scale, or some other rule for deciding
when the transitions take place.

In other words, S (V

, V ) must equal S

, W ) S (
|

1
i
|

ψ
|

PT

=

PT

ψ

ψ

i

(

i

i

i

|

|

In response, it should be noted that exactly the same problem arises in continuous-
is governed by the Schr¨odinger
time stochastic hidden-variable theories. For if a state
i
, and a hidden variable’s probability distribution −→p is governed
equation d
by the stochastic equation d−→p /dτ = Aτ −→p , then there is still an arbitrary parameter dτ /dt
on which the dynamics depend.

ψ
/dt = iHt |

ψ
|

ψ
|

i

i

Finally, it will be objected that I have ignored special relativity.

In Section 16.4
I will deﬁne a commutativity axiom, which informally requires that the stochastic matrix
S not depend on the temporal order of spacelike separated events. Unfortunately, we will
see that when entangled states are involved, commutativity is irreconcilable with another
axiom that seems even more basic. The resulting nonlocality has the same character as the
nonlocality of Bohmian mechanics—that is, one cannot use it to send superluminal signals
in the usual sense, but it is unsettling nonetheless.

16.4 Axioms for Hidden-Variable Theories

I now state ﬁve axioms that we might like hidden-variable theories to satisfy.

Indiﬀerence. The indiﬀerence axiom says that if U is block-diagonal, then S
should also be block-diagonal with the same block structure or some reﬁnement thereof.
Formally, let a block be a subset B
B
B, j /
∈
B and
and i /
∈

1, . . . , N
B. Then for all blocks B, we should have (S)ij = 0 for all i

such that (U )ij = 0 for all i

∈
B, j /
∈

B, j

⊆ {

∈

∈

}

6
207

to

B.

B, j

jBi

jAi ⊗ |
|

i /
∈
space
iAi ⊗ |
|
well.

∈
HA ⊗ HB, and any unitary U that acts only on
where iB 6
iBi

In particular, indiﬀerence implies that given any state ρ in a tensor product
HA (that is, never maps a basis state
HA as
Robustness. A theory is robust if it is insensitive to small errors in a state or
U by perturbing
unitary (which, in particular, implies continuity). Suppose we obtain
ρ and U respectively. Then for all polynomials p, there should exist a polynomial q such
that for all N ,

= jB), the stochastic matrix S (ρ, U ) acts only on

ρ and

e

e

1
p (N )

≤

P

ρ,

U

P (ρ, U )

−

(cid:17)

(cid:16)

e
, whenever

e

∞

(cid:13)
(cid:13)
ρ
(cid:13)
k∞ ≤

(cid:13)
(cid:13)
(M )ij
(cid:13)
(cid:12)
(cid:12)
(cid:12)

k

M

k∞

= maxij

1/q (N ).
where
−
Robustness has an important advantage for quantum computing: if a hidden-variable theory
is robust then the set of gates used to deﬁne the unitaries U1, . . . , UT is irrelevant, since by
the Solovay-Kitaev Theorem (see [153, 182]), any universal quantum gate set can simulate
any other to a precision ε with O (logc 1/ε) overhead.

1/q (N ) and

(cid:13)
(cid:13)
(cid:13) e

ρ
k

(cid:13)
(cid:13)
(cid:13)

≤

−

(cid:12)
(cid:12)
(cid:12)

U

U

∞

e

Commutativity. Let ρAB be a bipartite state, and let UA and UB act only on
subsystems A and B respectively. Then commutativity means that the order in which UA
and UB are applied is irrelevant:

S

UAρABU −

1
A , UB

S (ρAB, UA) = S

UBρABU −

1
B , UA

S (ρAB, UB) .

(cid:0)

mutativity for all separable pure states

(cid:0)
Product Commutativity. A theory is product commutative if it satisﬁes com-
ψAi ⊗ |
|

=
Decomposition Invariance. A theory is decomposition invariant if

.
ψBi

ψ
|

(cid:1)

(cid:1)

i

for every decomposition

N

Xi=1

N

S (ρ, U ) =

ρ =

piS (

ψii h
|

ψi|

, U )

pi |

ψii h

ψi|

Xi=1

of ρ into pure states. Theorem 138, part (ii) will show that the analogous axiom for P (ρ, U )
is unsatisﬁable.

16.4.1 Comparing Theories

To ﬁx ideas, let us compare some hidden-variable theories with respect to the above axioms.
We have already seen the product theory
PT
satisﬁes robustness, commutativity, and decomposition invariance. However, I consider
unsatisfactory because it violates indiﬀerence: even if a unitary U acts only on the ﬁrst

It is easy to show that

in Section 16.3.

PT

PT
of two qubits, S

PT

(ρ, U ) will readily produce transitions involving the second qubit.

Recognizing this problem, Dieks [97] proposed an alternative theory that amounts
to the following.4 First partition the set of basis states into minimal blocks B1, . . . , Bm

4Dieks (personal communication) says he would no longer defend this theory.

PT
No
Indiﬀerence
Yes
Robustness
Yes
Commutativity
Product Commutativity
Yes
Decomposition Invariance Yes

(Product)

(Dieks)

DT
Yes
No
No
Yes
Yes

(Flow)

FT
Yes
Yes
No
No
No

ST
Yes
?
No
Yes
No

208

(Schr¨odinger)

Table 16.1: Four hidden-variable theories and the axioms they satisfy

between which U never sends amplitude. Then apply the product theory separately to
each block; that is, if i and j belong to the same block Bk then set

U ρU −

1

jj
(U ρU −

(cid:1)

,

1)

j

j

(S)ij =

j

(cid:0)
Bk
∈
Pb

and otherwise set (S)ij = 0. The resulting Dieks theory,
, satisﬁes indiﬀerence by
construction. However, it does not satisfy robustness (or even continuity), since the set of
blocks can change if we replace ‘0’ entries in U by arbitrarily small nonzero entries.

DT

b
b

FT

and the Schr¨odinger theory
If we could prove that

In Section 16.6 I will introduce two other hidden-variable theories, the ﬂow theory
. Table 16.1 lists which axioms the four theories satisfy.
satisﬁes robustness, then Table 1 together with the
impossibility results of Section 16.5 would completely characterize which of the axioms can
be satisﬁed simultaneously.

ST

ST

16.5

Impossibility Results

This section shows that certain sets of axioms cannot be satisﬁed by any hidden-variable
theory.
to satisfy commutativity is
DT
inherent, and not a ﬁxable technical problem.

I ﬁrst show that the failure of

, and

FT

ST

,

Theorem 137 No hidden-variable theory satisﬁes both indiﬀerence and commutativity.

Proof. Assume indiﬀerence holds, and let our initial state be

Suppose UA applies a π/8 rotation to the ﬁrst qubit, and UB applies a
the second qubit. Then

−

= |

11
.
ψ
i
|
π/8 rotation to

+
00
i
|
√2

i

ψ
UA |

i

ψ
= UB |

i

=

ψ
UAUB |

i

ψ
= UBUA |

i

cos

1
√2
(cid:16)
1
(
2
|

=

π
8 |

00

i −

sin

π
8 |

01
i

+ sin

π
8 |

10
i

+ cos

π
8 |

11
i

,

(cid:17)

00

01
i

+

10
i
|

+

) .

11
i

|

i − |

Let vt be the value of the hidden variable after t unitaries have been applied. Let E be the
event that v0 =
If UA is applied before UB, then
the unique ‘path’ from v0 to v2 consistent with indiﬀerence sets v1 =

initially, and v2 =

at the end.

00
i
|

10
i
|

. So

10
i
|

Pr [E]

Pr [v1 =

] =

10
i
|

≤

1
2

sin2 π
8

.

209

But if UB is applied before UA, then the probability that v0 =
2 sin2 π
1
since the only possibilities for v0 are

8 , by the same reasoning. Thus, since v2 must equal

and

|

,

and v2 =

is at most
10
11
i
|
i
|
with probability 1/4, and
10
i

00
i

|

11
|
i
sin2 π
8

Pr [E]

1
4 −

1
2

≥

>

1
2

sin2 π
8

.

We conclude that commutativity is violated.

Let me remark on the relationship between Theorem 137 and Bell’s Theorem.
Any hidden-variable theory that is “local” in Bell’s sense would immediately satisfy both
indiﬀerence and commutativity. However, the converse is not obvious, since there might
, which an indiﬀerent commutative
ψ
be nonlocal information in the states UA |
i
i
theory could exploit but a local one could not. Theorem 137 rules out this possibility, and
in that sense is a strengthening of Bell’s Theorem.

or UB |

ψ

The next result places limits on decomposition invariance.

Theorem 138

(i) No theory satisﬁes indiﬀerence, robustness, and decomposition invariance.

(ii) No theory has the property that

N

P (ρ, U ) =

for every decomposition

Xi=1
ψi|

N

i=1 pi |

ψii h

piP (
|

ψii h

ψi|

, U )

of ρ.

Proof.

P

(i) Suppose the contrary. Let

Rθ =

(cid:21)
1
i
Then for every θ not a multiple of π/2, we must have

(cid:20)
= cos θ

+ sin θ

ϕθi

0
i
|

|

|

cos θ
sin θ

sin θ
−
cos θ

,

.

ϕ
S (
|

−

θi

, Rθ) =

(cid:20)

S

ϕπ/2

−

, Rθ

=

θ

1 1
0 0

0 0
1 1

+

0
|

|

(cid:21)

,

.

(cid:21)
1
1
|
i h

) /2 denote the maximally

(cid:20)

(cid:1)
So by decomposition invariance, letting I = (
0
i h
|
mixed state,

(cid:11)

(cid:0)(cid:12)
(cid:12)

S (I, Rθ) = S

ϕ
|

−

ϕ
θi h

−

θ|

+

ϕπ/2
2

−

(cid:12)
(cid:12)

θ

ϕπ/2

−

θ

(cid:11) (cid:10)

, Rθ

=

!

(cid:20)

(cid:12)
(cid:12)

1
2
1
2

1
2
1
2 (cid:21)

 
and therefore

(ρ)11
2
(ρ)11
2
By robustness, this holds for θ = 0 as well.
indiﬀerence P (I, R0) must be half the identity.

P (I, Rθ) =

(ρ)00
2
(ρ)00
2

"

210

=

#

(cid:20)

1
4
1
4

1
4
1
4 (cid:21)

.

But this is a contradiction, since by

(ii) Suppose the contrary; then

P

I, Rπ/8

=

(cid:1)
So considering transitions from

(cid:0)

0
i
|

P

, Rπ/8

0
i
|

, Rπ/8

1
i
|

+ P
2

(cid:1)

(cid:0)

.

(cid:1)

(cid:0)
to

P

(cid:0)

,

1
i
|
0
i

|
(cid:0)

P

I, Rπ/8

01 =

(cid:0)

(cid:0)

(cid:1)(cid:1)

11 + 0

, Rπ/8
2

(cid:1)(cid:1)

=

1
2

sin2 π
8

.

But

P

I, Rπ/8

=

P

ϕπ/8

, Rπ/8

also. Since Rπ/8

(cid:0)
ϕπ/8

=

(cid:1)
ϕπ/4

(cid:11)

(cid:0)(cid:12)
(cid:12)
, we have

+ P
2

(cid:1)

ϕ5π/8

, Rπ/8

(cid:0)(cid:12)
(cid:12)

(cid:11)

(cid:1)

(cid:12)
(cid:12)

P

(cid:12)
(cid:11)
(cid:12)
I, Rπ/8

(cid:11)
01 ≥

(cid:0)

(cid:0)

(cid:1)(cid:1)

≥

≥

>

1
2
1
2
1
2
1
2

which is a contradiction.

P

ϕπ/8

, Rπ/8

01

(cid:11)

P

ϕπ/8

(cid:1)(cid:1)
, Rπ/8

(cid:11)

(cid:0)(cid:12)
(cid:0)
sin2 π
(cid:12)
8

(cid:19)

11

(cid:19)

(cid:1)(cid:1)

(cid:0)

(cid:18)

1
(cid:0)(cid:12)
(cid:12)
2 −
1
2 −
(cid:18)
sin2 π
8

Notice that all three conditions in Theorem 138, part (i) were essential—for

satisﬁes robustness and decomposition invariance,
tion invariance, and

satisﬁes indiﬀerence and robustness.

DT

FT

The last impossibility result says that no hidden-variable theory satisﬁes both
indiﬀerence and “strong continuity,” in the sense that for all ε > 0 there exists δ > 0 such
that

ε. To see this, let

δ implies

S (ρ, U )

ρ, U )

ρ

ρ
k

−

k ≤

S (
k

−

k ≤

PT
satisﬁes indiﬀerence and decomposi-

e

0
1
√2 −
1
√2

0
1
√2
1
√2

2δ2

2δ2

+ δ

+ δ

0
|
i
0
i
|

−

−

e
U = 




ρ =

1
0
0

1

ρ =

p
1

p

e

,



+ δ



1
|
i
1
i −
|

δ

,

.

2
|
i
2
i
|

211

t

2

b

1

2

b

N

1

⋮
j

⋮
N

1

⋮
i

⋮
N

(
U

)

11

(
U

)

NN

s

2

a

1

2

a

N

Figure 16.1: A network (weighted directed graph with source and sink) corresponding to
the unitary U and state

ψ

|

i

Then by indiﬀerence,

S (ρ, U ) =

1 0 0
0 0 0
0 1 1



,



S (

ρ, U ) =

1 0 0
0 1 1
0 0 0



.



This is the reason why I deﬁned robustness in terms of the joint probabilities matrix P rather
than the stochastic matrix S. On the other hand, note that by giving up indiﬀerence, one
can satisfy strong continuity, as is shown by

.





e





PT

16.6 Speciﬁc Theories

This section presents two nontrivial examples of hidden-variable theories: the ﬂow theory
in Section 16.6.1, and the Schr¨odinger theory in Section 16.6.2.

16.6.1 Flow Theory

The idea of the ﬂow theory is to convert a unitary matrix into a weighted directed graph,
and then route probability mass through that graph like oil through pipes. Given a unitary
U , let





where for the time being

β1
...
βN

= 









(U )11
...

· · ·

(U )1N · · ·

(U )N 1
...
(U )N N

α1
...
αN

,
















ψ
|
ψ
|

i

i

= α1 |
1
i
1
= β1 |
i

+

+

· · ·

· · ·

U

+ αN |
N
N
+ βN |

i

,

i

are pure states. Then consider the network G shown in Figure 16.1. We have a source vertex
.
s, a sink vertex t, and N input and N output vertices labeled by basis states

, . . . ,

1
i
|

N
|

i

Each edge of the form (s,

,
i
,
i
|
|
2. A natural question is how much probability mass
(cid:12)
and each edge (
(cid:12)
|
(cid:12)
can ﬂow from s to t without violating the capacity constraints. Rather surprisingly, I will
Interestingly, this result would be false
show that one unit of mass (that is, all of it) can.

) has capacity
βj|
|

i
i
|
, t) has capacity

(U )ij
(cid:12)
(cid:12)
(cid:12)

) has capacity

αi|

j

j

i

i

|

2, each edge (

212

2

1+ε

,

|

i

j

i
i

) had capacity

if edge (
I will also
|
show that there exists a mapping from networks to maximal ﬂows in those networks, that
is robust in the sense that a small change in edge capacities produces only a small change
in the amount of ﬂow through any edge.

(U )ij
(cid:12)
(cid:12)
(cid:12)

(U )ij
(cid:12)
(cid:12)
(cid:12)

) instead of

(or even

(U )ij

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

.

The proofs of these theorems use classical results from the theory of network ﬂows
(see [88] for an introduction). In particular, let a cut be a set of edges that separates s from
t; the value of a cut is the sum of the capacities of its edges. Then a fundamental result
called the Max-Flow-Min-Cut Theorem [111] says that the maximum possible amount of
ﬂow from s to t equals the minimum value of any cut. Using that result I can show the
following.

Theorem 139 One unit of ﬂow can be routed from s to t in G.

Proof. By the above, it suﬃces to show that any cut C in G has value at least 1.
Let A be the set of i
C, and let B be the set of j such that
B, and we
(
) such that i
|
can assume without loss of generality that C contains no other edges. So the value of C is

i
such that (s,
1, . . . , N
i
|
i
C. Then C must contain every edge (
i
|

) /
∈
j
,
|

, t) /
∈

A and j

∈ {

∈

∈

}

j

i

i

2 +

αi|
|

A
Xi /
∈

B
Xj /
∈

2 +

βj|

|

B (cid:12)
A, j
Xi
∈
∈
(cid:12)
(cid:12)

Therefore we need to prove the matrix inequality

1

−

A
Xi
∈

2

αi|
|

!

+

1

−





B
Xj
∈

or

2

βj|
|



+

1 +

(U )ij

B (cid:12)
A, j
Xi
∈
∈
(cid:12)
(cid:12)

≥

A
Xi
∈

(cid:12)
(cid:12)
(cid:12)

(U )ij

.

(cid:12)
(cid:12)
(cid:12)

(U )ij

B (cid:12)
A, j
Xi
∈
∈
(cid:12)
(cid:12)
βj|
|

2 +


αi|
|

2 .

B
Xj
∈

1,

≥

(cid:12)
(cid:12)
(cid:12)

(16.1)

Let U be ﬁxed, and consider the maximum of the right-hand side of equation (16.1) over
all

ψ

. Since
i

|

βj =

(U )ij αi,

Xi
this maximum is equal to the largest eigenvalue λ of the positive semideﬁnite matrix

where for each j,

i
i
|
i h
|

+

A
Xi
∈

B
Xj
∈

uji h
|

uj|

uji
|

1
= (U )1j |
i

+

· · ·

N
+ (U )N j |

i

.

 
Let HA be the subspace of states spanned by
B
uji
spanned by
: j
{|
HA, and let LB (
ψ
|
uji
and
|

. Also, let LA (
|
}

∈
) be the length of the projection of

i
i
{|

: i

ψ

i

∈

A
}

) be the length of the projection of
i

, and let HB be the subspace
onto
’s
i
i
|

i
onto HB. Then since the

ψ
|

ψ
|

i

’s form orthogonal bases for HA and HB respectively, we have

213

λ = max
i

ψ
|

= max
ψ
|

i (cid:16)





Xi
A
∈
LA (

2 +

ψ
i
|

|h

i|

Xj
B
∈
)2 + LB (
ψ
|

ψ
|

i

ψ
uj|

2
i|

|h





)2

i

.

(cid:17)

So letting θ be the angle between HA and HB,

λ = 2 cos2 θ
2
= 1 + cos θ

1 +

≤

|

a

i∈

max
b
i∈
|

HA,

HB |h

b
a
|

i|

= 1 +

γ1
δ1

|
|

2+
|
2+
|

1 +

≤

max
+
+

···
···

2=1
2=1

γN |
|
δN |
|
(U )ij

i
γi h
|! 


B
Xj
∈

A
Xi
∈

δj |

uji
(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

B (cid:12)
A, j
Xi
∈
∈
(cid:12)
(cid:12)
which completes the theorem.

(cid:12)
(cid:12)
(cid:12)

Observe that Theorem 139 still holds if U acts on a mixed state ρ, since we
ψ
|

can write ρ as a convex combination of pure states
, construct a ﬂow for each
|
separately, and then take a convex combination of the ﬂows.
Using Theorem 139, I now deﬁne the ﬂow theory

ψ
|

i h

ψ

i

. Let F (ρ, U ) be the set
N arrays of real numbers fij such that

FT

of maximal ﬂows for ρ, U —representable by N

for all i, j, and also

×

fij = (ρ)ii ,

fij =

U ρU −

1

jj .

(cid:0)

(cid:1)

∈

∈

Xj

F (ρ, U ). Then let f ∗12 be the maximum of f12 over all f

Xi
Clearly F (ρ, U ) is a convex polytope, which Theorem 139 asserts is nonempty. Form a
F (ρ, U ) as follows: ﬁrst let f ∗11 be the maximum of f11 over
maximal ﬂow f ∗ (ρ, U )
F (ρ, U ) such that
all f
f11 = f ∗11. Continue to loop through all i, j pairs in lexicographic order, setting each f ∗ij to
1 previous values. Finally,
its maximum possible value consistent with the (i
let (P )ij = f ∗ij for all i, j. As discussed in Section 16.3, given P we can easily obtain the
stochastic matrix S by dividing the ith column by (ρ)ii, or taking a limit in case (ρ)ii = 0.
It is easy to check that
so deﬁned satisﬁes the indiﬀerence axiom. Showing
satisﬁes robustness is harder. Our proof is based on the Ford-Fulkerson algorithm
that
[111], a classic algorithm for computing maximal ﬂows that works by ﬁnding a sequence of
“augmenting paths,” each of which increases the ﬂow from s to t by some positive amount.

1) N + j

FT

FT

−

−

∈

0

fij ≤

≤

(U )ij
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

 
∈ {
ε.

}

e

f ∗i −
(cid:12)
(cid:12)
(cid:12) e

f ∗i

≤

(cid:12)
(cid:12)
(cid:12)

Theorem 140

FT

satisﬁes robustness.

214

Proof. Let G be an arbitrary ﬂow network with source s, sink t, and directed
edges e1, . . . , em, where each ei has capacity ci and leads from vi to wi. It will be convenient
to introduce a ﬁctitious edge e0 from t to s with unlimited capacity; then maximizing the
ﬂow through G is equivalent to maximizing the ﬂow through e0. Suppose we produce a
new network
G by increasing a single capacity ci∗ by some ε > 0. Let f ∗ be the optimal
ﬂow for G, obtained by ﬁrst maximizing the ﬂow f0 through e0, then maximizing the ﬂow
f1 through e1 holding f0 ﬁxed, and so on up to fm. Let
G
produced in the same way. We claim that for all i

f ∗ be the maximal ﬂow for

0, . . . , m

e

,

e

To see that the theorem follows from this claim: ﬁrst, if f ∗ is robust under adding ε to
ci∗, then it must also be robust under subtracting ε from ci∗. Second, if we change ρ, U
1/q (N ), then we can imagine the
U
to
≤
N 2 + 2N edge capacities are changed one by one, so that

1/q (N ) and

U such that

ρ
k∞ ≤

ρ,

−

−

U

∞

ρ

k

e

e

e
U

f ∗

ρ,

(cid:13)
(cid:13)
(cid:13)

(cid:17)

(cid:16)

e

e

f ∗ (ρ, U )

−

≤

∞

(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13)

(cid:13)
(cid:13)
(cid:13) e
U

ij(cid:12)
(cid:17)
(cid:12)
(cid:12)
(cid:12)
Xj

−

(U )ij
(cid:12)
(cid:12)
(cid:12)
U

(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
1
(cid:12)
U −

ρ

(cid:12)
(cid:16)
(cid:12)
(cid:12)
(cid:12)

e

e

e

(cid:17)

+

Xi

jj −

(cid:0)

ρ)ii −
(
|

(ρ)ii|

e
U ρU −

1

jj

(cid:1)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:16)

(cid:12)
Xij (cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

e
+

4N 2
q (N )

.

≤

(Here we have made no attempt to optimize the bound.)

We now prove the claim. To do so we describe an iterative algorithm for computing
f ∗. First maximize the ﬂow f0 through e0, by using the Ford-Fulkerson algorithm to ﬁnd
a maximal ﬂow from s to t. Let f (0) be the resulting ﬂow, and let G(1) be the residual
network that corresponds to f (0). For each i, that is, G(1) has an edge ei = (vi, wi) of
capacity c(1)
, and an edge ei = (wi, vi) of capacity c(1)
i = ci −
. Next maximize
f1 subject to f0 by using the Ford-Fulkerson algorithm to ﬁnd “augmenting cycles” from
w1 to v1 and back to w1 in G(1)
. Continue in this manner until each of f1, . . . , fm
e0, e0}
has been maximized subject to the previous fi’s. Finally set f ∗ = f (m).

i = f (0)

f (0)
i

\ {

i

f ∗i

ε for all i

f0, then

Now, one way to compute

f ∗ is to start with f ∗, then repeatedly “correct” it
f1, and so on. Let εi =
by applying the same iterative algorithm to maximize
e
. The proof is by induction
f ∗i −
; then we need to show that εi ≤
ε, since increasing ci∗ by ε can increase the value of the minimum cut
on i. Clearly ε0 ≤
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12) e
f0, the value of the minimum cut
from s to t by at most ε. Likewise, after we maximize
(cid:12)
from w1 to v1 can increase by at most ε
ε0 + ε0 = ε. For of the at most ε new units of ﬂow
from w1 to v1 that increasing ci∗ made available, ε0 of them were “taken up” in maximizing
f0 could have again increased the minimum cut from w1
f0, but the process of maximizing
to v1 by up to ε0. Continuing in this way,
e

0, . . . , m

∈ {

−

e

e

e

}

e
ε

ε2 ≤

ε0 + ε0 −

−

ε1 + ε1 = ε,

and so on up to εm. This completes the proof.

215

FT

That

violates decomposition invariance now follows from Theorem 138, part
violates product commutativity, by considering the fol-
(i). One can also show that
π/4 and RB
lowing example: let
ϕ
π/4
−
be π/4 rotations applied to the ﬁrst and second qubits respectively. Then

be a 2-qubit initial state, and let RA

FT
⊗

ϕπ/4

π/8

=

ψ

i

|

S

RA

π/4 |

ψ

i

(cid:17)
We omit a proof for brevity.

(cid:16)

(cid:11)

(cid:12)
(cid:12)
, RB

π/4

(cid:11)

(cid:12)
(cid:12)
ψ
|

i

S

(cid:16)

, RA

π/4

= S

(cid:17)

RB
(cid:16)

π/4 |

ψ

i

, RA

π/4

S

(cid:17)

ψ
|
(cid:16)

i

, RB

π/4

.

(cid:17)

16.6.2 Schr¨odinger Theory

, is the most
The ﬁnal hidden-variable theory, which I call the Schr¨odinger theory or
interesting one mathematically. The idea—to make a matrix into a stochastic matrix via
row and column rescaling—is natural enough that we came upon it independently, only later
learning that it originated in a 1931 paper of Schr¨odinger [213]. The idea was subsequently
developed by Fortet [112], Beurling [58], Nagasawa [179], and others. My goal is to give
what (to my knowledge) is the ﬁrst self-contained, reasonably accessible presentation of the
main result in this area; and to interpret that result in what I think is the correct way: as
providing one example of a hidden-variable theory, whose strengths and weaknesses should
be directly compared to those of other theories.

ST

Most of the technical diﬃculties in [58, 112, 179, 213] arise because the stochastic
process being constructed involves continuous time and particle positions. Here I eliminate
those diﬃculties by restricting attention to discrete time and ﬁnite-dimensional Hilbert
I thereby obtain a generalized version5 of a problem that computer scientists know
spaces.
as (r, c)-scaling of matrices [221, 118, 167].

As in the case of the ﬂow theory, given a unitary U acting on a state ρ, the ﬁrst
step is to replace each entry of U by its absolute value, obtaining a nonnegative matrix
U (0) deﬁned by
(U )ij
. We then wish to ﬁnd nonnegative column multipliers
α1, . . . , αN and row multipliers β1, . . . , βN such that for all i, j,

U (0)

ij :=
(cid:1)

(cid:0)

(cid:12)
(cid:12)
(cid:12)
+

(cid:12)
(cid:12)
(cid:12)
U (0)
(cid:16)
U (0)
(cid:16)

i1

(cid:17)

1j

(cid:17)

αiβ1

α1βj

+ αiβN

· · ·

+

· · ·

+ αN βj

U (0)
(cid:16)
U (0)

(cid:16)

iN

(cid:17)

N j

(cid:17)

= (ρ)ii ,

=

U ρU −

1

jj .

(16.2)

(16.3)

(cid:0)

(cid:1)

If we like, we can interpret the αi’s and βj’s as dynamical variables that reach equilibrium
precisely when equations (16.2) and (16.3) are satisﬁed. Admittedly, it might be thought
physically implausible that such a complicated dynamical process should take place at every
instant of time. On the other hand, it is hard to imagine a more “benign” way to convert
U (0) into a joint probabilities matrix, than by simply rescaling its rows and columns.

of a dynamical process reaching equilibrium turns out to be key to the proof. For all t

I will show that multipliers satisfying (16.2) and (16.3) always exist. The intuition
0,

5In (r, c)-scaling, we are given an invertible real matrix, and the goal is to rescale all rows and columns
to sum to 1. The generalized version is to rescale the rows and columns to given values (not necessarily 1).

≥

6
216

,

let

U (2t+1)
(cid:16)
U (2t+2)
(cid:16)

ij

(cid:17)

ij

(cid:17)

=

=

(ρ)ii
U (2t)
k
ik (cid:16)
1
U ρU −
(cid:1)
(cid:0)
jj
U (2t+1)
(cid:1)

(cid:0)
k

P

U (2t)

ij

(cid:17)
U (2t+1)

P

(cid:0)

kj (cid:16)

(cid:1)

.

ij

(cid:17)

In words, we obtain U (2t+1) by normalizing each column i of U (2t) to sum to (ρ)ii; likewise
we obtain U (2t+2) by normalizing each row j of U (2t+1) to sum to
U ρU −
jj. The crucial
U (t). We can
fact is that the above process always converges to some P (ρ, U ) = limt
therefore take

(cid:1)
→∞

(cid:0)

1

αi =

βj =

∞

t=0
Y
∞

t=0
Y

,

ik

(ρ)ii
U (2t)

k
U ρU −
(cid:0)

P

(cid:0)
k

1
(cid:1)
jj
U (2t+1)
(cid:1)

P

(cid:0)

kj

(cid:1)

for all i, j. Although I will not prove it here, it turns out that this yields the unique solution
αic for all i and
to equations (16.2) and (16.3), up to a global rescaling of the form αi →
βj →
The convergence proof will reuse a result about network ﬂows from Section 16.6.1,
in order to deﬁne a nondecreasing “progress measure” based on Kullback-Leibler distance.

βj/c for all j [179].

Theorem 141 The limit P (ρ, U ) = limt

→∞

U (t) exists.

Proof. A consequence of Theorem 139 is that for every ρ, U , there exists an N

array of nonnegative real numbers fij such that

N

×

(1) fij = 0 whenever

= 0,

(2) fi1 +

(3) f1j +

· · ·

· · ·

+ fiN = (ρ)ii for all i, and

+ fN j =

U ρU −

1

jj for all j.

(U )ij
(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:1)
Given any such array, deﬁne a progress measure

(cid:0)

Z (t) =

U (t)

Yij (cid:16)

(cid:17)

fij

ij

,

where we adopt the convention 00 = 1. We claim that Z (t+1)
1. To
see this, assume without loss of generality that we are on an odd step 2t + 1, and let

Z (t) for all t

≥

≥

217

C (2t)

i =

U (2t)

j

P

(cid:0)

ij be the ith column sum before we normalize it. Then
(cid:1)

fij

Z (2t+1) =

U (2t+1)

Yij (cid:16)

(ρ)ii
C (2t)
i

=

Yij  

ij

(cid:17)

fij

U (2t)
(cid:16)

ij!

(cid:17)

U (2t)

=



Yij (cid:16)


= Z (2t)

·

Yi  

fij

ij 

(cid:17)


(ρ)ii
C (2t)
i !


Yi  

(ρ)ii

.

fi1+

+fiN

···

(ρ)ii
C (2t)
i !





As a result of the 2tth normalization step, we had
the maximum of

C (2t)
i

i C (2t)

i = 1. Subject to that constraint,

P
(ρ)ii

Yi (cid:16)

(cid:17)

’s occurs when C (2t)

over the C (2t)
from the nonnegativity of Kullback-Leibler distance. This implies that Z (2t+1)
Similarly, normalizing rows leads to Z (2t+2)

= (ρ)ii for all i—a simple calculus fact that follows
Z (2t).

Z (2t+1).

≥

i

i

It follows that the limit P (ρ, U ) = limt

≥

is bounded away from (ρ)ii, so there exists an ε > 0 such that Z (t+1)

C (t)
i
all even t. But this is a contradiction, since Z (0) > 0 and Z (t)

≥
1 for all t.

→∞

U (t) exists. For suppose not; then some
(1 + ε) Z (t) for

Besides showing that P (ρ, U ) is well-deﬁned, Theorem 141 also yields a procedure
It can be shown that this procedure
to calculate P (ρ, U ) (as well as the αi’s and βj’s).
converges to within entrywise error ε after a number steps polynomial in N and 1/ε. Also,
once we have P (ρ, U ), the stochastic matrix S (ρ, U ) is readily obtained by normalizing
each column of P (ρ, U ) to sum to 1. This completes the deﬁnition of the Schr¨odinger
theory

.

≤

ST

It is immediate that

satisﬁes indiﬀerence. Also:

ST

Proposition 142

ST

satisﬁes product commutativity.

Proof. Given a state

|
. Then we claim that

i

ψ
|

=

ψAi ⊗ |

ψBi

, let UA ⊗

I act only on

ψAi
|

and let I

UB

⊗

act only on

ψBi

|

S (

ψ
|

i

, UA ⊗

I) = S (

ψAi
|

, UA)

I.

⊗
ψAi
|

by a constant
, has no eﬀect on the scaling procedure

and UA |

ψAi

The reason is simply that multiplying all amplitudes in
factor αx, as we do for each basis state
, UA). Similarly
ψAi
that produces S (
|

ψBi
|

x
i
|

of

S (

ψ
|

i

, I

⊗

UB) = I

S (
|

ψBi

⊗

, UB) .

It follows that

S (
|

ψAi

, UA)

S (

ψBi
|

⊗

, UB) = S (UA |
= S (

ψAi ⊗ |
UB |

ψBi
ψBi

ψAi ⊗
|

218

, I
⊗
, UA ⊗

UB) S (
I) S (

ψ
|
ψ
|

i

i

, UA ⊗
, I
⊗

I)
UB) .

On the other hand, numerical simulations readily show that
position invariance, even when N = 2 (I omit a concrete example for brevity).

ST

violates decom-

16.7 The Computational Model

I now explain the histories model of computation, building up to the complexity class DQP.
From now on, the states ρ that we consider will always be pure states of ℓ = log2 N qubits.
That is, ρ =

where

ψ

ψ
|

i h

|

=

ψ

|

i

0,1
Xx
∈{

ℓ
}

x
αx |
i

.

The algorithms of this chapter will work under any hidden-variable theory that
satisﬁes the indiﬀerence axiom. On the other hand, if we take into account that even in
theory (let alone in practice), a generic unitary cannot be represented exactly with a ﬁnite
universal gate set, only approximated arbitrarily well, then we also need the robustness
axiom. Thus, it is reassuring that there exists a hidden-variable theory (namely
) that
satisﬁes both indiﬀerence and robustness.

FT

Let a quantum computer have the initial state

ℓ, and suppose we apply a
sequence
= (U1, . . . , UT ) of unitary operations, each of which is implemented by a
polynomial-size quantum circuit. Then a history of a hidden variable through the com-
putation is a sequence H = (v0, . . . , vT ) of basis states, where vt is the variable’s value
, we
immediately after Ut is applied (thus v0 =
0
⊗
T
i
|
can obtain a probability distribution Ω (
repeatedly,
) over histories by just applying
,
T
once for each Ut, to obtain the stochastic matrices

ℓ). Given any hidden-variable theory

0
i
|

U

U

T

⊗

ℓ , U1

⊗

, S

S

0
i
|

U1 |

0
⊗
i

ℓ , U2

,

. . . S

UT

1 · · ·

−

U1 |

0
⊗
i

ℓ , UT

.

,

−

T

(cid:17)

(cid:16)

(cid:17)

(cid:17)

U

U

(cid:16)
,

(cid:16)
) is a Markov distribution; that is, each vt is independent of the other vi’s
Note that Ω (
T
) could depend on the precise way in
1 and vt+1. Admittedly, Ω (
conditioned on vt
U1 is “sliced” into component circuits U1, . . . , UT . But
which the combined circuit UT · · ·
as noted in Section 16.3.2, such dependence on the granularity of unitaries is unavoidable
in any hidden-variable theory other than
.
, let
Given a hidden-variable theory

(
T
positive integer ℓ, and a sequence of quantum circuits
Here each Ut is speciﬁed by a sequence
universal gate set
history distribution Ω (
Turing machine that is given oracle access to
makes a single oracle query to

) be an oracle that takes as input a
= (U1, . . . , UT ) that act on ℓ qubits.
of gates chosen from some ﬁnite
) returns as output a sample (v0, . . . , vT ) from the
) deﬁned previously. Now let A be a deterministic classical
). The machine A receives an input x,
), then produces an output based on the response. We

gt,1, . . . , gt,m(t)

. The oracle

PT
T

(
T

O

O

O

U

U

G

T

T

(cid:1)

(cid:0)

(

(

,

O

T

219

∈

say a set of strings L is in DQP if there exists an A such that for all suﬃciently large n and
satisfying the indiﬀerence and robustness axioms, A
0, 1
inputs x
}
correctly decides whether x

L with probability at least 2/3, in time polynomial in n.

n, and all theories

∈ {

T

).

O

(
T

Let me make some remarks about the above deﬁnition. There is no real signiﬁ-
cance in the requirement that A be deterministic and classical, and that it be allowed only
I made this choice only because it suﬃces for the upper bounds; it
one query to
might be interesting to consider the eﬀects of other choices. However, other aspects of the
deﬁnition are not arbitrary. The order of quantiﬁers matters; we want a single A that works
for any hidden-variable theory satisfying indiﬀerence and robustness. Also, we require A
to succeed only for suﬃciently large n since by choosing a large enough polynomial q (N )
in the statement of the robustness axiom, an adversary might easily make A incorrect on a
ﬁnite number of instances.

16.7.1 Basic Results

Having deﬁned the complexity class DQP, in this subsection I establish its most basic
DQP; that is, sampling histories is at
properties. First of all, it is immediate that BQP
least as powerful as standard quantum computation. For v1, the ﬁrst hidden-variable value
), can be seen as simply the result of applying a polynomial-size quantum
returned by
(
T
O
ℓ and then measuring in the standard basis. A key further
circuit U1 to the initial state
observation is the following.

0
⊗
i

⊆

|

Theorem 143 Any universal gate set yields the same complexity class DQP. By universal,
we mean that any unitary matrix (real or complex) can be approximated, without the need
for ancilla qubits.

G

U

≥

and

Proof. Let

n, since otherwise we simply insert n

by another sequence of ℓ-qubit unitaries,

G′ be universal gate sets. Also, let

= (U1, . . . , UT ) be a
.
sequence of ℓ-qubit unitaries, each speciﬁed by a polynomial-size quantum circuit over
G
We have T, ℓ = O (poly (n)) where n is the input length. We can also assume without loss
of generality that ℓ
ℓ dummy qubits that are never
acted on (by the indiﬀerence axiom, this will not aﬀect the results). We want to approximate
U ′ = (U ′1, . . . , U ′T ), where each U ′t is speciﬁed
U
ℓ2T . By
2−
by a quantum circuit over
U ′t −
= poly (n)
the Solovay-Kitaev Theorem [153, 182], we can achieve this using poly
G′; moreover, the circuit for U ′t can be constructed in polynomial time given the
gates from
circuit for Ut.
Let
= U ′t · · ·
,
}

ℓ. Notice that for all t

In particular, for all t we want

Utk∞ ≤
n, ℓ2T

1, . . . , T
{

= Ut · · ·

0
U ′1 |
i

0
U1 |
i

ℓ and

ψti
|

ψ′ti
|

G′.

−

∈

k

(cid:0)

(cid:1)

⊗

⊗

ψ′t

− |

(cid:13)
(cid:12)
(cid:12)
(cid:13)

(cid:11)

ψti
∞ ≤
(cid:13)
(cid:13)

≤

2ℓ

(cid:16)(cid:13)
T 2ℓT
(cid:13)

ψ′t

1

−
2−

ℓ2T
(cid:11)

− |

ψt

−

1i
∞
(cid:13)
ℓ(ℓ
= T 2−
(cid:13)

ℓ2T

+ 2−

1)T ,

(cid:17)

−

(cid:12)
(cid:12)
(cid:16)

T

(cid:17)

since
two vectors in C2ℓ

ψ′0i − |
k|

ψ0ik∞

= 0. Here

. Also, given a theory

k k∞

denotes the maximum entrywise diﬀerence between
, let Pt and P ′t be the joint probabilities matrices

220

(cid:0)

(cid:1)

Ω(
(cid:12)
(cid:12)
(cid:12)
(cid:12)

corresponding to Ut and U ′t respectively. Then by the robustness axiom, there exists
2ℓ
,
a polynomial q such that if
and
then
P ′t k∞ ≤
(cid:0)
(cid:1)
3ℓ for all t
2ℓ
T 2−
1/q
(cid:1)
≤
and suﬃciently large n.

2ℓ
ψt
U ′t −
− |
k
−
ℓ2T
For all such polynomials q, we have 2−
(cid:0)
ℓ. Therefore

3ℓ.
for suﬃciently large n

∞ ≤
1/q
(cid:13)
≤
(cid:13)
2−
P ′t k∞ ≤

Pt −
k
ℓ(ℓ
−

(cid:11)
Pt −
k

Utk∞ ≤

1/q
2ℓ

ψ′t
−

and

1/q

2−

1i

(cid:13)
(cid:13)

1)T

≤

(cid:12)
(cid:12)

(cid:0)

(cid:1)

1

Now assume n is suﬃciently large, and consider the distributions Ω (
and x
) over classical histories H = (v0, . . . , vT ). For all t

1, . . . , T

,

U
T
∈ {

) and
ℓ,
0, 1
}

Ω (
U ′,
T
we have

∈ {

}

2ℓ

3ℓ

2−

= 2−

2ℓ.

(cid:16)
Ω (
k

(cid:17)
U ′,

T

)

−

Ω (

U

,

)
k

T

is at most

Pr
,
T
U

[vt =

)

]
x
i
|

−

Pr
U ′,
T

Ω(

)

[vt =

]
x
i
|

≤

It follows by the union bound that the variation distance

T 2ℓ

2ℓ

2−

=

(cid:12)
(cid:12)
(cid:12)
(cid:12)

T
2ℓ ≤

T
2n .
,

(cid:16)
) can be distinguished from Ω (

(cid:17)

T

T

T

U

∈

Ω (

) with bias at most T /2n, which
In other words, Ω (
U ′,
is exponentially small. So any classical postprocessing algorithm that succeeds with high
probability given H
).
,
U
This completes the theorem.

U ′,
Unfortunately, the best upper bound on DQP I have been able to show is DQP

), also succeeds with high probability given H

⊆
EXP; that is, any problem in DQP is solvable in deterministic exponential time. The proof
is trivial: let
. Then by using the Ford-Fulkerson algorithm, we can
clearly construct the requisite maximum ﬂows in time polynomial in 2ℓ (hence exponential
in n), and thereby calculate the probability of each possible history (v1, . . . , vT ) to suitable
precision.

be the ﬂow theory

FT

Ω (

∈

T

T

16.8 The Juggle Subroutine

i

b

+

b
|

a
i
|

a
i
|

This section presents a crucial subroutine that will be used in both main algorithms: the
algorithm for simulating statistical zero knowledge in Section 16.9, and the algorithm for
search in N 1/3 queries in Section 16.10. Given an ℓ-qubit state (
a
i
are unknown basis states, the goal of the juggle subroutine is to learn both a and
and
b. The name arises because the strategy will be to “juggle” a hidden variable, so that if
it starts out at
, and vice versa.
then with non-negligible probability it transitions to
Inspecting the entire history of the hidden variable will then reveal both a and b, as desired.
To produce this behavior, we will exploit a basic feature of quantum mechanics:
that observable information in one basis can become unobservable phase information in a
diﬀerent basis. We will apply a sequence of unitaries that hide all information about a and
.
b in phases, thereby forcing the hidden variable to “forget” whether it started at
i
) /√2, at which point the
We will then invert those unitaries to return the state to (
a
i
i
|
hidden variable, having “forgotten” its initial value, must be unequal to that value with
probability 1/2.

) /√2, where
i

a
i

b
|

b
|

b
|

or

+

i

|

|

|

) /√2 be the initial state. The
+
a
= (
I now give the subroutine. Let
i
|
ﬁrst unitary, U1, consists of Hadamard gates on ℓ
1 qubits chosen uniformly at random,
−
and the identity operation on the remaining qubit, i. Next U2 consists of a Hadamard gate

ψ
|

b
|

i

i

on qubit i. Finally U3 consists of Hadamard gates on all ℓ qubits. Let a = a1 . . . aℓ and
= bi with probability at least 1/ℓ. Assuming
b = b1 . . . bℓ. Then since a
that occurs, the state

= b, we have ai 6

221

z

1)b
·

−

bizi

(

−

z
|

i



1

ψ
U1 |

i

=

2ℓ/2 

z

1)a
·

−

aizi

(

−

+

z
|

i

ℓ : zi=bi
}

ℓ : zi=ai
}

·

·

i

i

b

−

z



z
|

0,1
Xz
∈{

1 basis states

, namely those for which a

= bi, I claim that v3 is independent of v0. So in particular, if v0 =

Xz
0,1
∈{
assigns nonzero amplitude to all 2ℓ basis states. Then U2U1 |
ψ
to 2ℓ

z (mod 2). Finally U3U2U1 |
then v3 =

assigns nonzero amplitude
.
i
≡
Let vt be the value of the hidden variable after Ut is applied. Then assuming
with
a
i
|
with 1/2 probability. To see this, observe
such that zi = ai,
must
1 basis states that agree with a on the ith bit, and similarly
−
. Then after U2 is applied, v2 can diﬀer from v1 only on the ith
must receive an equal
, and probability mass originating at
a
i
. Therefore v2 is independent of v0, from which it follows that v3 is independent of v0

ai 6
1/2 probability, and if v0 =
that when U1 is applied, there is no interference between basis states
and those such that zi = bi. So by the indiﬀerence axiom, the probability mass at
spread out evenly among all 2ℓ
for the probability mass at
ψ
bit, again by the indiﬀerence axiom. So each basis state of U2U1 |
contribution from probability mass originating at
b
|
as well.

then v3 =

a
i
|

ψ
|

a
i

z
|

b
|

b
|

=

ψ

b

i

i

i

i

i

i

i

|

|

|

and

Unfortunately, the juggle subroutine only works with probability 1/ (2ℓ)—for it
= bi, and even then, inspecting the history (v0, v1, . . .) only reveals both
requires that ai 6
with probability 1/2. Furthermore, the deﬁnition of DQP does not allow more
b
a
i
|
i
|
than one call to the history oracle. However, all we need to do is pack multiple subroutine
calls into a single oracle call. That is, choose U4 similarly to U1 (except with a diﬀerent
value of i), and set U5 = U2 and U6 = U3. Do the same with U7, U8, and U9, and so
, the eﬀect is that of multiple
on. Since U3, U6, U9, . . . all return the quantum state to
independent juggle attempts. With 2ℓ2 attempts, we can make the failure probability at
most (1

1/ (2ℓ))2ℓ2
−
As a ﬁnal remark, it is easy to see that the juggle subroutine works equally well

< e−

ψ
|

ℓ.

i

with states of the form

ψ
|

i

= (
|

a

b
i − |

i

) /√2. This will prove useful in Section 16.10.

16.9 Simulating SZK

⊆

This section shows that SZK
DQP. Here SZK, or Statistical Zero Knowledge, was
originally deﬁned as the class of problems that possess a certain kind of “zero-knowledge
proof protocol”—that is, a protocol between an omniscient prover and a veriﬁer, by which
the veriﬁer becomes convinced of the answer to a problem, yet without learning anything
else about the problem. However, for present purposes this cryptographic deﬁnition of
SZK is irrelevant. For Sahai and Vadhan [209] have given an alternate and much simpler
characterization: a problem is in SZK if and only if it can be reduced to a problem called
Statistical Diﬀerence, which involves deciding whether two probability distributions are
close or far.

6
More formally, let P0 and P1 be functions that map n-bit strings to q (n)-bit strings
for some polynomial q, and that are speciﬁed by classical polynomial-time algorithms. Let
n
Λ0 and Λ1 be the probability distributions over P0 (x) and P1 (x) respectively, if x
is chosen uniformly at random. Then the problem is to decide whether
Λ0 −
k
than 1/3 or greater than 2/3, given that one of these is the case. Here

0, 1
}
is less

∈ {
Λ1k

222

Λ0 −
k

Λ1k

=

1
2

0,1
Xy
}
∈{

x
q(n) (cid:12)
(cid:12)
(cid:12)
(cid:12)

Pr
0,1

[P0 (x) = y]

n

−

x

Pr
0,1

∈{

}

}

∈{

n

[P1 (x) = y]
(cid:12)
(cid:12)
(cid:12)
(cid:12)

is the variation distance between Λ0 and Λ1.

To illustrate, let us see why Graph Isomorphism is in SZK. Given two graphs
G0 and G1, take Λ0 to be the uniform distribution over all permutations of G0, and Λ1 to
be uniform over all permutations of G1. This way, if G0 and G1 are isomorphic, then Λ0
= 0. On the other hand, if G0 and G1 are non-
and Λ1 will be identical, so
Λ0 −
k
isomorphic, then Λ0 and Λ1 will be perfectly distinguishable, so
= 1. Since Λ0
and Λ1 are clearly samplable by polynomial-time algorithms, it follows that any instance
of Graph Isomorphism can be expressed as an instance of Statistical Diﬀerence. For a
proof that Approximate Shortest Vector is in SZK, the reader is referred to Goldreich and
Goldwasser [129] (see also Aharonov and Ta-Shma [23]).

Λ0 −
k

Λ1k

Λ1k

The proof will use the following “ampliﬁcation lemma” from [209]:6

Lemma 144 (Sahai and Vadhan) Given eﬃciently-samplable distributions Λ0 and Λ1,
we can construct new eﬃciently-samplable distributions Λ′0 and Λ′1, such that if
Λ1k ≤
Λ0 −
k
n.
1/3 then
Λ0 −
2−
k

Λ′0 −
k
In particular, Lemma 144 means we can assume without loss of generality that
Λ0 −
k
Having covered the necessary facts about SZK, we can now proceed to the main

for some constant c > 0.

n, while if

Λ1k ≥

Λ′1k ≥

Λ′1k ≤

Λ1k ≥

Λ1k ≤

2/3 then

Λ′0 −

Λ0 −

2−

2−

2−

or

−

−

nc

nc

k

k

1

1

either

result.

Theorem 145 SZK

DQP.

⊆

Proof. We show how to solve Statistical Diﬀerence by using a history oracle. For
simplicity, we start with the special case where P0 and P1 are both one-to-one functions.
In this case, the circuit sequence
it ﬁrst
prepares the state

given to the history oracle does the following:

U

1
2(n+1)/2

,x
0,1
Xb
∈{
}
∈{

0,1

b
n |
}

x

i |

i |

Pb (x)
i

.

registers, taking
It then applies the juggle subroutine to the joint state of the
ℓ = n + 1. Notice that by the indiﬀerence axiom, the hidden variable will never transition
from one value of Pb (x) to another—exactly as if we had measured the third register in the
of the ﬁrst two registers, which
standard basis. All that matters is the reduced state

x
i
|

and

ψ

b

i

|

6Note that in this lemma, the constants 1/3 and 2/3 are not arbitrary; it is important for technical

|

i

reasons that (2/3)2 > 1/3.

223

|

nc

+

i |

2−

b
|

x
i

Λ1k

= 0, and

Λ0 −
k

x1i
1
i |

) /√2 for some x0, x1 if

for some
x0i
has the form (
0
|
i |
= 1. We have already seen that the juggle subroutine can distinguish
Λ1k
Λ0 −
b, x if
k
these two cases: when the hidden-variable history is inspected, it will contain two values of
register in the former case, and only one value in the latter case. Also, clearly the
the
b
i
|
= 0 with respect to
case
Λ1k ≤
Λ0 −
k
= 1.
Λ0 −
the subroutine, and likewise
k
We now consider the general case, where P0 and P1 need not be one-to-one. Our
strategy is to reduce to the one-to-one case, by using a well-known hashing technique of
Valiant and Vazirani [231]. Let
Dn,k be the uniform distribution over all aﬃne functions
n to
2 and Fk
mapping
2
n such
respectively. What Valiant and Vazirani showed is that, for all subsets A
that 2k
0, 1
}

k, where we identify those sets with the ﬁnite ﬁelds Fn
0, 1
}

is statistically indistinguishable from
1

Λ0 −
is indistinguishable from

1, and all s

Λ1k ≥

Λ0 −
k

0, 1
}

0, 1
}

Λ1k

Λ1k

⊆ {

∈ {

| ≤

≤ |

2−

2k

k,

−

A

nc

{

{

k

−

−

2

(cid:2)(cid:12)
(cid:12)
As a corollary, the expectation over h

Pr
∈Dn,k

h

h−

1 (s)

= 1

A

∩

1
8

.

≥

(cid:12)
(cid:12)

(cid:3)

h−

1 (s)

= 1

∈ Dn,k of
k :
A

∩

(cid:12)
(cid:12)

s

0, 1
}

∈ {

(cid:12)
n
(cid:12)
(cid:12)

Pr
h,x

A

∩

h−

1 (h (x))

= 1

≥

(cid:12)
(cid:12)

o(cid:12)
(cid:12)
(cid:12)

2k/8
A
|

|

1
4

.

≥

is at least 2k/8.

It follows that, if x is drawn uniformly at random from A, then

(cid:12)
(cid:12)
This immediately suggests the following algorithm for the many-to-one case. Draw k
uniformly at random from
prepare the
state

; then draw h0, h1 ∈ Dn,k. Have

2, . . . , n + 1
}

(cid:2)(cid:12)
(cid:12)

U

{

(cid:3)

1
2(n+1)/2

,x
0,1
Xb
∈{
}
∈{

0,1

b
n |
}

x

i |

i |

Pb (x)

hb (x)
i

,

i |

and then apply the juggle subroutine to the joint state of the
the

Pb (x)
i
|

hb (x)
and
i
|
Λ0 −
Suppose
k
(Pi (x)) and Hi = h−
i

registers as before.
Λ1k
(hi (x)), and suppose 2k

= 0. Also, given x
2

−

1

1

P −
i

∈ {
≤ |

registers, ignoring

x
i

0, 1
}
1. Then

∈ {
2k
−

, let Ai =

Pr
s,h0,h1

[
|

A0 ∩

H0|

= 1

A1 ∩

∧ |

H1|

= 1]

|

H0|

= 1 and

A0 ∩

A1 ∩
|

H1|
since the events
on x. Assuming both events occur, as before the juggle subroutine will reveal both
and
x1i
1
|
i |
H1 respectively. By contrast, if
and A1 ∩
register will ever be observed. Again, replacing
Λ0 −
Λ1k
Λ0 −
k
k
distribution.

= 1 are independent of each other conditioned
0
x0i
i |
|
H0
with high probability, where x0 and x1 are the unique elements of A0 ∩
= 1 then only one value of the
b
i
|
, and
Λ0 −
Λ1k
k
, can have only a negligible eﬀect on the history

Λ1k
Λ0 −
k
Λ0 −
k

Λ1k ≥

Λ1k ≤

= 1 by

= 0 by

2−

2−

−

nc

nc

1

and

b
|
i
|
n and i
0, 1
}
A1| ≤
=
A0|
|
1
4

≥

2

,

(cid:18)

(cid:19)

224

H0
Of course, the probability that the correct value of k is chosen, and that A0 ∩
H1 both have a unique element, could be as low as 1/ (16n). To deal with this,
and A1 ∩
we simply increase the number of calls to the juggle subroutine by an O (n) factor, drawing
new values of k, h0, h1 for each call. We pack multiple subroutine calls into a single oracle
call as described in Section 16.8, except that now we uncompute the entire state (returning
) and then recompute it between subroutine calls. A ﬁnal remark: since the
it to
algorithm that calls the history oracle is deterministic, we “draw” new values of k, h0, h1 by
having
prepare a uniform superposition over all possible values. The indiﬀerence axiom
justiﬁes this procedure, by guaranteeing that within each call to the juggle subroutine, the
hidden-variable values of k, h0, and h1 remain constant.

0
i

0
|

· · ·

U

Recall from Chapter 6 that there exists an oracle A relative to which SZKA

BQPA. By contrast, since Theorem 145 is easily seen to relativize, we have SZKA
It follows that there exists an oracle A relative to which BQPA
for all oracles A.

6∈
DQPA
∈
= DQPA.

16.10 Search in N 1/3 Queries

Given a Boolean function f :
, the database search problem is simply to
0, 1
}
ﬁnd a string x such that f (x) = 1. We can assume without loss of generality that this
“marked item” x is unique.7 We want to ﬁnd it using as few queries to f as possible, where
a query returns f (y) given y.

0, 1
}

→ {

{

n

O

N 1/2

auxiliary computation steps (here the

By querying f in superposition, Grover’s algorithm [139] ﬁnds x using O
together with
(log N )c). Bennett et al. [51] showed that any quantum algorithm needs Ω

Let N = 2n. Then classically, of course, Θ (N ) queries are necessary and suﬃcient.
queries,
O hides a factor of the form
(cid:0)
queries.
e
In this section, I show how to ﬁnd the marked item by sampling histories, using
N 1/3
computation steps. Formally, the model is as follows.
only O
)
Each of the quantum circuits U1, . . . , UT that algorithm A gives to the history oracle
is now able to query f . Suppose Ut makes qt queries to f ; then the total number of queries
made by A is deﬁned to be Q = q1 +
+ qT . The total number of computation steps is
at least the number of steps required to write down U1, . . . , UT , but could be greater.

e
queries and

(cid:1)
N 1/2

N 1/3

N 1/2

(
T

· · ·

O

O

e

(cid:1)

(cid:1)

(cid:0)

(cid:0)

(cid:0)

(cid:0)

(cid:1)

(cid:1)

Theorem 146 In the DQP model, we can search a database of N items for a unique marked
item using O

computation steps.

queries and

N 1/3

N 1/3

O

Proof. Assume without loss of generality that N = 2n with n
(cid:1)

(cid:1)

(cid:0)

(cid:0)

e

database item is labeled by an n-bit string. Let x
marked item. Then the sequence of quantum circuits
O
β

, where

2n/3

n

∈ {
U

iterations of Grover’s algorithm, in order to produce the n-qubit state α

0, 1
}

3, and that each
|
n be the label of the unique
it ﬁrst runs
+

does the following:

x
i
|

y

0,1
(cid:1)

}

∈{

y
|

i

(cid:0)
P

α =

r
β = 2−

1
2n/3 + 2−
n/3+1 + 1
n/3α

,

7For if there are multiple marked items, then we can reduce to the unique marked item case by using the

Valiant-Vazirani hashing technique described in Theorem 145.

6
(one can check that this state is normalized). Next
n/3 qubits. This yields the state

U

applies Hadamard gates to the ﬁrst

2−

n/6α

n/3

0,1
Xy
}
∈{

1)xA·

y

(

−

y
|

xBi
i |

+ 2n/6β

n/3

0
⊗
i

|

,

z
|

i

2n/3

0,1
Xz
}
∈{

225

0
i
|

z
|

i

where xA consists of the ﬁrst n/3 bits of x, and xB consists of the remaining 2n/3 bits. Let
Y be the set of 2n/3 basis states of the form
, and Z be the set of 22n/3 basis states
y
|
.
of the form

xBi
i |

n/3

⊗

Notice that 2−

n/6α = 2n/6β. So with the sole exception of

(which
belongs to both Y and Z), the “marked” basis states in Y have the same amplitude as the
“unmarked” basis states in Z. This is what we wanted. Notice also that, if we manage to
Y , then we can ﬁnd x itself using 2n/3 further classical queries: simply
ﬁnd any
test all possible strings that end in xB. Thus, the goal of our algorithm will be to cause the
hidden variable to visit an element of Y , so that inspecting the variable’s history reveals
that element.

xBi ∈

xBi
|

0
i

y
|

i |

⊗

|

n/3

As in Theorem 145, the tools that we need are the juggle subroutine, and a way
n/3.
z
if the ﬁrst two registers
|
i
. Disregarding the basis
xBi

of reducing many basis states to two. Let s be drawn uniformly at random from
Then
U
have the form
0
state
i
|

s, y
⊗
|
for convenience, the result is

appends a third register to the state, and sets it equal to

if they have the form

0
|
i
xBi

0, 1
}
{

, or to

y
|

z
|

n/3

n/3

i |

⊗

i

i

|

2−

n/6α





n/3

0,1
Xy
}
∈{

1)xA·

y

(
−

y
|

xBi |
i |

s, y

i

+

2n/3

0,1
Xz
}
∈{

n/3

0
⊗
i

|

z
|

z
i |

i

.



U

Next
the hidden-variable value has the form
probability 2−
Then conditioned on the third register being
is

applies the juggle subroutine to the joint state of the ﬁrst two registers. Suppose
(that is, lies outside Y ). Then with
z
z
i
n/3 over s, the ﬁrst n/3 bits of z are equal to s. Suppose this event occurs.
z
, the reduced state of the ﬁrst two registers
|
i
xBi
√2

zBi |
|

1)xA·

(
−

0
i
|

0
i
|

z
|

n/3

n/3

i |

+

zB

⊗

⊗

i

|

,

⊗

to

n/3

z
|

xBi

zBi |
|

, and hence from Z to Y .

i
The algorithm calls the juggle subroutine Θ

where zB consists of the last n/3 bits of z.
So it follows from Section 16.8 that with
probability Ω (1/n), the juggle subroutine will cause the hidden variable to transition from
0
i
|

times, draw-
ing a new value of s and recomputing the third register after each call. Each call moves
; therefore with
the hidden variable from Z to Y with independent probability Ω
high probability some call does so. Note that this juggling phase does not involve any
database queries. Also, as in Theorem 145, “drawing” s really means preparing a uniform
superposition over all possible s. Finally, the probability that the hidden variable ever vis-
its the basis state
is exponentially small (by the union bound), which justiﬁes
xBi
|
our having disregarded it.

N 1/3 log N

n/3/n

2n/3n

0
⊗
i

= Θ

2−

n/3

(cid:1)

(cid:1)

(cid:0)

(cid:0)

(cid:0)

(cid:1)

|

226

A curious feature of Theorem 146 is the tradeoﬀ between queries and computation
steps. Suppose we had run Q iterations of Grover’s algorithm, or in other words made Q
√N , the marked state
would have occurred with
queries to f . Then provided Q
Q2/N
calls to the juggle subroutine would have
probability Ω
O
been suﬃcient to ﬁnd x. Of course, the choice of Q that minimizes max
is
e
Q = N 1/3. On the other hand, had we been willing to spend
O (N ) computation steps, we
could have found x with only a single query!8 Thus, one might wonder whether some other
algorithm could push the number of queries below N 1/3, without simultaneously increasing
the number of computation steps. The following theorem rules out that possibility.

, meaning that

Q, N/Q2

N/Q2

x
i

≤

(cid:9)

(cid:8)

e

(cid:0)

(cid:1)

(cid:0)

(cid:1)

|

Theorem 147 In the DQP model, Ω
computation steps are needed to search an N -
item database for a unique marked item. As a consequence, there exists an oracle relative
DQP; that is, NP-complete problems are not eﬃciently solvable by sampling
to which NP
histories.

6⊂

(cid:1)

(cid:0)

N 1/3

Proof. Let N = 2n and f :
= (U1, . . . , UT ) that query f , and assuming that x

. Given a sequence of quantum
n is the unique string
circuits
such that f (x) = 1, let
be the quantum state after Ut is applied but before Ut+1
is. Then the “hybrid argument” of Bennett et al. [51] implies that, by simply changing the
location of the marked item from x to x∗, we can ensure that

ψt (x)
i

0, 1
}
{

0, 1
}

0, 1
}

→ {

∈ {

U

|

n

ψt (x)

k|

ψt (x∗)

i − |

= O

ik

Q2
t
N

(cid:18)

(cid:19)

k k

represents trace distance, and Qt is the total number of queries made to f by
where
provides an upper bound on the probability of noticing
U1, . . . , Ut. Therefore O
the x
x∗ change by monitoring vt, the value of the hidden variable after Ut is applied. So
by the union bound, the probability of noticing the change by monitoring the entire history
(v1, . . . , vT ) is at most of order

t /N

Q2

→

(cid:0)

(cid:1)

T

Q2
t
N ≤

T Q2
T
N

.

t=1
X
N 1/3

or QT = Ω

N 1/3

, either of which implies an

This cannot be Ω (1) unless T = Ω
Ω

N 1/3

lower bound on the total number of steps.
To obtain an oracle relative to which NP

(cid:0)

(cid:1)

(cid:0)

(cid:1)

(cid:1)

(cid:0)

DQP, we can now use a standard and
well-known “diagonalization method” due to Baker, Gill, and Solovay [41] to construct an
inﬁnite sequence of exponentially hard search problems, such that any DQP machine fails
on at least one of the problems, whereas there exists an NP machine that succeeds on all of
them. Details are omitted.

6⊂

16.11 Conclusions and Open Problems

The idea that certain observables in quantum mechanics might have trajectories governed
by dynamical laws has reappeared many times: in Schr¨odinger’s 1931 stochastic approach

8One should not make too much of this fact; one way to interpret it is simply that the “number of queries”

should be redeﬁned as Q + T rather than Q.

227

[213], Bohmian mechanics [59], modal interpretations [39, 96, 97], and elsewhere. Yet
because all of these proposals yield the same predictions for single-time probabilities, if we
are to decide between them it must be on the basis of internal mathematical considerations.
One message of this chapter has been that such considerations can actually get us quite far.
To focus attention on the core issues, I restricted attention to the simplest possible
setting: discrete time, a ﬁnite-dimensional Hilbert space, and a single orthogonal basis.
Within this setting, I proposed what seem like reasonable axioms that any hidden-variable
theory should satisfy:
for example, indiﬀerence to the identity operation, robustness to
small perturbations, and independence of the temporal order of spacelike-separated events.
I then showed that not all of these axioms can be satisﬁed simultaneously. But perhaps more
surprisingly, I also showed that certain subsets of axioms can be satisﬁed for quite nontrivial
reasons.
In showing that the indiﬀerence and robustness axioms can be simultaneously
satisﬁed, Section 16.6 revealed an unexpected connection between unitary matrices and the
classical theory of network ﬂows.

As mentioned previously, an important open problem is to show that the Schr¨odinger

theory satisﬁes robustness. Currently, I can only show that the matrix P
(ρ, U ) is robust
to exponentially small perturbations, not polynomially small ones. The problem is that if
any row or column sum in the U (t) matrix is extremely small, then the (r, c)-scaling process
will magnify tiny errors in the entries.
Intuitively, though, this eﬀect should be washed out
by later scaling steps.

ST

A second open problem is whether there exists a theory that satisﬁes indiﬀerence,
as well as commutativity for all separable mixed states (not just separable pure states).
A third problem is to investigate other notions of robustness—for example, robustness to
small multiplicative rather than additive errors.

On the complexity side, perhaps the most interesting problem left open by this
chapter is the computational complexity of simulating Bohmian mechanics.
I strongly
conjecture that this problem, like the hidden-variable problems we have seen, is strictly
harder than simulating an ordinary quantum computer. The trouble is that Bohmian
mechanics does not quite ﬁt in the framework of this chapter: as discussed in Section
16.3.2, we cannot have deterministic hidden-variable trajectories for discrete degrees of
freedom such as qubits. Even worse, Bohmian mechanics violates the continuous analogue
of the indiﬀerence axiom. On the other hand, this means that by trying to implement
(say) the juggle subroutine with Bohmian trajectories, one might learn not only about
Bohmian mechanics and its relation to quantum computation, but also about how essential
the indiﬀerence axiom really is for our implementation.

⊆

. Can we improve this to (say) DQP

Another key open problem is to show better upper bounds on DQP. Recall that
EXP, by giving a classical exponential-time algorithm to
I was only able to show DQP
PSPACE? Clearly
simulate the ﬂow theory
it would suﬃce to give a PSPACE algorithm that computes the transition probabilities for
some theory
satisfying the indiﬀerence and robustness axioms. On the other hand, this
might not be necessary—that is, there might be an indirect simulation method that does
not work by computing (or even sampling from) the distribution over histories.
It would
also be nice to pin down the complexities of simulating speciﬁc hidden-variable theories,
such as

and

FT

⊆

T

.

FT

ST

228

Chapter 17

Summary of Part II

Recall our hypothetical visitor from Conway’s Game of Life, on a complexity safari
of the physical universe. Based on the results in Part II, the following are some intuitions
about eﬃcient computation that I would advise our visitor to toss in the garbage.

•

•

•

•

We can be fairly conﬁdent that the class of functions eﬃciently computable in the
physical world coincides with P (or BPP, which is presumably equal).

Although there are models of eﬃcient computation more powerful than P, involving
the manipulation of arbitrary real or complex numbers, these models will inevitably
blow up small errors in the numbers nonlinearly, and must be therefore be unphysical.

A robot, moving at unit speed, would need order n steps to search a spatial region of
size n for a marked item.

The ability to see one’s entire “history” in a single time step cannot yield any complexity-
theoretic advantage, since one could always just record the history as one went along,
at the cost of a polynomial increase in memory.

On the other hand, just as in Part I, we have seen that many of the intuitions in

our visitor’s suitcase are good to go. For example:

•

•

•

If the items in a database have distance d from one another, then the time needed to
search the database is about d times what it would be if the items had unit distance
from one another.

It is possible to choose a probability distribution over histories, in such a way that state
i is never followed in a history by state j if the corresponding transition probability
is zero, and such that a small change to the transition matrices produces only a small
change in the history distribution.

If, at the moment of your death, your entire life’s history ﬂashed before you in an
instant, then you could probably still not solve NP-complete problems in polynomial
time.

229

Bibliography

[1] S. Aaronson. Book review on A New Kind of Science. Quantum Information and

Computation, 2(5):410–423, 2002. quant-ph/0206089.

[2] S. Aaronson. Quantum lower bound for the collision problem. In Proc. ACM STOC,

pages 635–642, 2002. quant-ph/0111102.

[3] S. Aaronson. Algorithms for Boolean function query properties. SIAM J. Comput.,

32(5):1140–1157, 2003.

[4] S. Aaronson. Quantum certiﬁcate complexity. In Proc. IEEE Conference on Compu-
tational Complexity, pages 171–178, 2003. ECCC TR03-005, quant-ph/0210020.

[5] S. Aaronson. Quantum lower bound for recursive Fourier sampling. Quantum Infor-
mation and Computation, 3(2):165–174, 2003. ECCC TR02-072, quant-ph/0209060.

[6] S. Aaronson. The complexity of agreement. ECCC TR04-061, 2004.

[7] S. Aaronson. Is quantum mechanics an island in theoryspace?

In A. Khrennikov,
editor, Proceedings of the V¨axj¨o Conference “Quantum Theory: Reconsideration of
Foundations”, 2004. quant-ph/0401062.

[8] S. Aaronson. Limitations of quantum advice and one-way communication. Theory of
Computing, 2004. To appear. Conference version in Proc. IEEE Complexity 2004, pp.
320-332. quant-ph/0402095.

[9] S. Aaronson. Lower bounds for local search by quantum arguments. In Proc. ACM

STOC, pages 465–474, 2004. ECCC TR03-057, quant-ph/0307149.

[10] S. Aaronson. Multilinear formulas and skepticism of quantum computing. In Proc.

ACM STOC, pages 118–127, 2004. quant-ph/0311039.

[11] S. Aaronson. Quantum computing and hidden variables. Accepted to Phys. Rev. A.

quant-ph/0408035 and quant-ph/0408119, 2004.

[12] S. Aaronson. NP-complete problems and physical reality: a survey. In preparation;

invited for SIGACT News, 2005.

[13] S. Aaronson and A. Ambainis. Quantum search of spatial regions. Theory of Com-
puting, 2004. To appear. Conference version in Proc. IEEE FOCS 2003, pp. 200-209.
quant-ph/0303041.

230

[14] S. Aaronson and D. Gottesman. Improved simulation of stabilizer circuits. Phys. Rev.

Lett., 70(052328), 2004. quant-ph/0406196.

[15] D. S. Abrams and S. Lloyd. Nonlinear quantum mechanics implies polynomial-time
solution for NP-complete and #P problems. Phys. Rev. Lett., 81:3992–3995, 1998.
quant-ph/9801041.

[16] L. Adleman, J. DeMarrais, and M.-D. Huang. Quantum computability. SIAM J.

Comput., 26(5):1524–1540, 1997.

[17] M. Agrawal,

Saxena.
www.cse.iitk.ac.in/users/manindra/primality.ps, 2002.

N. Kayal,

and N.

PRIMES

is

in P.

[18] D. Aharonov. Quantum computation - a review. In Dietrich Stauﬀer, editor, Annual

Review of Computational Physics, volume VI. 1998. quant-ph/9812037.

[19] D. Aharonov, A. Ambainis, J. Kempe, and U. Vazirani. Quantum walks on graphs.

In Proc. ACM STOC, pages 50–59, 2001. quant-ph/0012090.

[20] D. Aharonov and M. Ben-Or. Fault-tolerant quantum computation with constant

error. In Proc. ACM STOC, pages 176–188, 1997. quant-ph/9906129.

[21] D. Aharonov and T. Naveh. Quantum NP - a survey. quant-ph/0210077, 2002.

[22] D. Aharonov and O. Regev. Lattice problems in NP intersect coNP. In Proc. IEEE

FOCS, pages 362–371, 2004.

[23] D. Aharonov and A. Ta-Shma. Adiabatic quantum state generation and statistical
zero knowledge. In Proc. ACM STOC, pages 20–29, 2003. quant-ph/0301023.

[24] D. Aldous. Minimization algorithms and random walk on the d-cube. Annals of

Probability, 11(2):403–413, 1983.

[25] A. Ambainis. In preparation.

[26] A. Ambainis. A note on quantum black-box complexity of almost all Boolean func-

tions. Inform. Proc. Lett., 71:5–7, 1999. quant-ph/9811080.

[27] A. Ambainis. Quantum lower bounds by quantum arguments. J. Comput. Sys. Sci.,

64:750–767, 2002. Earlier version in ACM STOC 2000. quant-ph/0002066.

[28] A. Ambainis. Polynomial degree vs. quantum query complexity. In Proc. IEEE FOCS,

pages 230–239, 2003. quant-ph/0305028.

[29] A. Ambainis. Quantum lower bounds for collision and element distinctness with small

range. quant-ph/0305179, 2003.

[30] A. Ambainis. Quantum walk algorithm for element distinctness. In Proc. IEEE FOCS,

2004. quant-ph/0311001.

231

[31] A. Ambainis, J. Kempe, and A. Rivosh. Coins make quantum walks faster.

In
Proc. ACM-SIAM Symp. on Discrete Algorithms (SODA), 2005. To appear. quant-
ph/0402107.

[32] A. Ambainis, A. Nayak, A. Ta-Shma, and U. V. Vazirani. Quantum dense coding and
quantum ﬁnite automata. J. ACM, 49:496–511, 2002. Earlier version in ACM STOC
1999. quant-ph/9804043.

[33] A. Ambainis, L. J. Schulman, A. Ta-Shma, U. V. Vazirani, and A. Wigderson. The
quantum communication complexity of sampling. SIAM J. Comput., 32:1570–1585,
2003.

[34] A. Ambainis, L. J. Schulman, and U. V. Vazirani. Computing with highly mixed states
(extended abstract). In Proc. ACM STOC, pages 697–704, 2000. quant-ph/0003136.

[35] M. Arndt, O. Nairz, J. Vos-Andreae, C. Keller, G. van der Zouw, and A. Zeilinger.

Wave-particle duality of C60 molecules. Nature, 401:680–682, 1999.

[36] S. Arora, R. Impagliazzo, and U. Vazirani. Relativizing versus nonrelativizing tech-

niques: the role of local checkability. Manuscript, 1992.

[37] A. Aspect, P. Grangier, and G. Roger. Experimental realization of Einstein-Podolsky-
Rosen-Bohm gedankenexperiment: a new violation of Bell’s inequalities. Phys. Rev.
Lett., 49:91–94, 1982.

[38] L. Babai. Bounded round interactive proofs in ﬁnite groups. SIAM J. Discrete Math,

5(1):88–111, 1992.

[39] G. Bacciagaluppi and M. Dickson. Dynamics for modal interpretations of quantum

theory. Found. Phys., 29:1165–1201, 1999. quant-ph/9711048.

[40] D. Bacon. Quantum computational complexity in the presence of closed timelike

curves. quant-ph/0309189, 2003.

[41] T. Baker, J. Gill, and R. Solovay. Relativizations of the P=?NP question. SIAM J.

Comput., 4:431–442, 1975.

[42] S. Bakhtiari, R. Safavi-Naini, and J. Pieprzyk. Cryptographic hash functions: a
survey. Technical Report 95-09, Department of Computer Science, University of Wol-
longong, July 1995.

[43] Z. Bar-Yossef, T. S. Jayram, and I. Kerenidis. Exponential separation of quantum and
classical one-way communication complexity. In Proc. ACM STOC, pages 128–137,
2004. ECCC TR04-036.

[44] H. Barnum, M. Saks, and M. Szegedy. Quantum query complexity and semi-deﬁnite
programming. In Proc. IEEE Conference on Computational Complexity, pages 179–
193, 2003.

232

[45] R. Beals, H. Buhrman, R. Cleve, M. Mosca, and R. de Wolf. Quantum lower bounds
by polynomials. J. ACM, 48(4):778–797, 2001. Earlier version in IEEE FOCS 1998.
quant-ph/9802049.

[46] R. Beigel. Perceptrons, PP, and the polynomial hierarchy. Computational Complexity,

4:339–349, 1994.

[47] R. Beigel, N. Reingold, and D. Spielman. PP is closed under intersection. J. Comput.

Sys. Sci., 50(2):191–202, 1995.

[48] J. D. Bekenstein. A universal upper bound on the entropy to energy ratio for bounded

systems. Phys. Rev. D, 23(2):287–298, 1981.

[49] J. S. Bell. Speakable and Unspeakable in Quantum Mechanics. Cambridge, 1987.

[50] P. Benioﬀ. Space searches with a quantum robot. In S. J. Lomonaco and H. E. Brandt,
editors, Quantum Computation and Information, Contemporary Mathematics Series.
AMS, 2002. quant-ph/0003006.

[51] C. Bennett, E. Bernstein, G. Brassard, and U. Vazirani. Strengths and weaknesses of
quantum computing. SIAM J. Comput., 26(5):1510–1523, 1997. quant-ph/9701001.

[52] C. H. Bennett. Logical reversibility of computation. IBM Journal of Research and

Development, 17:525–532, 1973.

[53] C. H. Bennett, G. Brassard, C. Cr´epeau, R. Jozsa, A. Peres, and W. Wootters.
Teleporting an unknown quantum state by dual classical and EPR channels. Phys.
Rev. Lett., 70:1895–1898, 1993.

[54] C. H. Bennett and J. Gill. Relative to a random oracle A, P A

= N P A

= coN P A with

probability 1. SIAM J. Comput., 10(1):96–113, 1981.

[55] E. Bernstein and U. Vazirani. Quantum complexity theory. SIAM J. Comput.,

26(5):1411–1473, 1997. First appeared in ACM STOC 1993.

[56] S. N. Bernstein. Sur l’ordre de la meilleure approximation des fonctions continues
par les polynˆomes de degr´e donn´e. Mem. Cl. Sci. Acad. Roy. Belg., 4:1–103, 1912.
French.

[57] A. Berthiaume and G. Brassard. Oracle quantum computing. In Proc. Workshop on

Physics of Computation: PhysComp’92, pages 195–199. IEEE, 1992.

[58] A. Beurling. An automorphism of direct product measures. Ann. Math., 72:189–200,

1960.

[59] D. Bohm. A suggested interpretation of the quantum theory in terms of “hidden”

variables. Phys. Rev., 85:166–193, 1952.

[60] D. Bohm and B. Hiley. The Undivided Universe. Routledge, 1993.

6
6
233

[61] D. Boneh and R. Lipton. Algorithms for black box ﬁelds and their application to
cryptography. In Proceedings of CRYPTO, volume 109, pages 283–297. Lecture Notes
in Computer Science, 1996.

[62] M. L. Bonet and S. R. Buss. Size-depth tradeoﬀ for Boolean formulae. Inform. Proc.

Lett., 11:151–155, 1994.

[63] R. B. Boppana, J. H˚astad, and S. Zachos. Does co-NP have short interactive proofs?

Inform. Proc. Lett., 25:127–132, 1987.

[64] R. Bousso. Positive vacuum energy and the N-bound. J. High Energy Physics,

0011(038), 2000. hep-th/0010252.

[65] R. Bousso. The holographic principle. Reviews of Modern Physics, 74(3), 2002. hep-

th/0203101.

[66] M. Boyer, G. Brassard, P. Høyer, and A. Tapp. Tight bounds on quantum searching.

Fortschritte Der Physik, 46(4-5):493–505, 1998. quant-ph/9605034.

[67] G. Brassard, P. Høyer, M. Mosca, and A. Tapp. Quantum amplitude ampliﬁcation
and estimation. In S. J. Lomonaco and H. E. Brandt, editors, Quantum Computation
and Information, Contemporary Mathematics Series. AMS, 2002. quant-ph/0005055.

[68] G. Brassard, P. Høyer, and A. Tapp. Quantum algorithm for the collision problem.

ACM SIGACT News, 28:14–19, 1997. quant-ph/9705002.

[69] S. L. Braunstein, C. M. Caves, N. Linden, S. Popescu, and R. Schack. Separability of
very noisy mixed states and implications for NMR quantum computing. Phys. Rev.
Lett., 83:1054–1057, 1999. quant-ph/9811018.

[70] R. P. Brent. The parallel evaluation of general arithmetic expressions. J. ACM,

21:201–206, 1974.

[71] H. J. Briegel and R. Raussendorf. Persistent entanglement in arrays of interacting

particles. Phys. Rev. Lett., 86:910–913, 2001. quant-ph/0004051.

[72] T. Brun. Computers with closed timelike curves can solve hard problems. Foundations

of Physics Letters, 16:245–253, 2003. gr-qc/0209061.

[73] N. H. Bshouty, R. Cleve, and W. Eberly. Size-depth tradeoﬀs for algebraic formulae.

SIAM J. Comput., 24(4):682–705, 1995.

[74] S. Bublitz, U. Sch¨urfeld, B. Voigt, and I. Wegener. Properties of complexity measures

for PRAMs and WRAMs. Theoretical Comput. Sci., 48:53–73, 1986.

[75] H. Buhrman, R. Cleve, J. Watrous, and R. de Wolf. Quantum ﬁngerprinting. Phys.

Rev. Lett., 87(16), 2001. quant-ph/0102001.

[76] H. Buhrman, R. Cleve, and A. Wigderson. Quantum vs. classical communication and

computation. In Proc. ACM STOC, pages 63–68, 1998. quant-ph/9702040.

234

[77] H. Buhrman, C. D¨urr, M. Heiligman, P. Høyer, F. Magniez, M. Santha, and R. de
Wolf. Quantum algorithms for element distinctness. In Proc. IEEE Conference on
Computational Complexity, pages 131–137, 2001. quant-ph/0007016.

[78] H. Buhrman and R. de Wolf. Complexity measures and decision tree complexity: a

survey. Theoretical Comput. Sci., 288:21–43, 2002.

[79] P. B¨urgisser, M. Clausen, and M. A. Shokrollahi. Algebraic Complexity Theory.

Springer-Verlag, 1997.

[80] A. R. Calderbank and P. W. Shor. Good quantum error-correcting codes exist. Phys.

Rev. A, 54:1098–1105, 1996. quant-ph/9512032.

[81] C. M. Caves, C. A. Fuchs, and R. Schack. Unknown quantum states: the quantum
de Finetti representation. J. Math. Phys., 45(9):4537–4559, 2002. quant-ph/0104088.

[82] E. W. Cheney. Introduction to Approximation Theory. McGraw-Hill, 1966.

[83] A. M. Childs, R. Cleve, E. Deotto, E. Farhi, S. Gutmann, and D. A. Spielman.
In Proc. ACM STOC, pages

Exponential algorithmic speedup by quantum walk.
59–68, 2003. quant-ph/0209131.

[84] A. M. Childs, E. Farhi, and S. Gutmann. An example of the diﬀerence between
quantum and classical random walks. Quantum Information and Computation, 1(1-
2):35–43, 2002. quant-ph/0103020.

[85] A. M. Childs and J. Goldstone. Spatial search and the Dirac equation. Phys. Rev. A,

70(042312), 2004. quant-ph/0405120.

[86] A. M. Childs and J. Goldstone. Spatial search by quantum walk. Phys. Rev. A,

70(022314), 2004. quant-ph/0306054.

[87] R. Cleve, A. Ekert, C. Macchiavello, and M. Mosca. Quantum algorithms revisited.

Proc. Roy. Soc. London, A454:339–354, 1998. quant-ph/9708016.

[88] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein. Introduction to Algorithms

(2nd edition). MIT Press, 2001.

[89] J. Cronin. CP symmetry violation - the search for its origin. Nobel Lecture, December

8, 1980.

[90] D. Deutsch. Quantum theory, the Church-Turing principle and the universal quantum

computer. Proc. Roy. Soc. London, A400:97–117, 1985.

[91] D. Deutsch. Quantum mechanics near closed timelike lines. Phys. Rev. D, 44:3197–

3217, 1991.

[92] D. Deutsch. The Fabric of Reality. Penguin, 1998.

[93] D. Deutsch. Quantum theory of probability and decisions. Proc. Roy. Soc. London,

A455:3129–3137, 1999. quant-ph/9906015.

235

[94] D. Deutsch, A. Barenco, and A. Ekert. Universality in quantum computation. Proc.

Roy. Soc. London, A449:669–677, 1995. quant-ph/9505018.

[95] D. Deutsch and R. Jozsa. Rapid solution of problems by quantum computation. Proc.

Roy. Soc. London, A439:553–558, 1992.

[96] M. Dickson. Modal interpretations of quantum mechanics. In Stanford Encyclopedia
of Philosophy. Stanford University, 2002. At http://plato.stanford.edu/entries/qm-
modal/.

[97] D. Dieks. Modal interpretation of quantum mechanics, measurements, and macro-

scopic behaviour. Phys. Rev. A, 49:2290–2300, 1994.

[98] R. Diestel. Graph Theory (2nd edition). Springer-Verlag, 2000.

[99] S. Droste, T. Jansen, and I. Wegener. Upper and lower bounds for randomized search

heuristics in black-box optimization. ECCC TR03-048, 2003.

[100] W. D¨ur and H. J. Briegel. Stability of macroscopic entanglement under decoherence.

Phys. Rev. Lett., 92, 2004. quant-ph/0307180.

[101] P. Duriˇs, J. Hromkoviˇc, J. D. P. Rolim, and G. Schnitger. Las Vegas versus de-
terminism for one-way communication complexity, ﬁnite automata, and polynomial-
time computations. In Proc. Intl. Symp. on Theoretical Aspects of Computer Science
(STACS), pages 117–128, 1997.

[102] C. D¨urr and P. Høyer. A quantum algorithm for ﬁnding the minimum. quant-

ph/9607014, 1996.

[103] G. Egan. Quarantine: A Novel of Quantum Catastrophe. Eos, 1995. First printing

1992.

[104] H. Ehlich and K. Zeller. Schwankung von Polynomen zwischen Gitterpunkten. Math-

ematische Zeitschrift, 86:41–44, 1964.

[105] M. Ettinger and P. Høyer. On quantum algorithms for noncommutative hidden sub-

groups. Advances in Applied Mathematics, 25(3):239–251, 2000. quant-ph/9807029.

[106] E. Farhi, J. Goldstone, S. Gutmann, J. Lapan, A. Lundgren, and D. Preda. A quan-
tum adiabatic evolution algorithm applied to random instances of an NP-complete
problem. Science, 292:472–476, 2001. quant-ph/0104129.

[107] S. Fenner, F. Green, S. Homer, and R. Pruim. Determining acceptance possibility
for a quantum computation is hard for the polynomial hierarchy. Proc. Roy. Soc.
London, A455:3953–3966, 1999. quant-ph/9812056.

[108] R. P. Feynman. Simulating physics with computers.

Int. J. Theoretical Physics,

21(6-7):467–488, 1982.

236

[109] R. P. Feynman. The Character of Physical Law. MIT Press, 1998. Originally published

1965.

[110] V. Fitch. The discovery of charge-conjugation parity asymmetry. Nobel Lecture,

December 8, 1980.

[111] L. R. Ford and D. R. Fulkerson. Flows in Networks. Princeton, 1962.

[112] R. Fortet. R´esolution d’un syst`eme d’´equations de M. Schr¨odinger. J. Math Pures et.

Appl., 9:83–105, 1940.

[113] L. Fortnow. My Computational Complexity Web Log. Wednesday, October 30, 2002

entry. fortnow.com/lance/complog.

[114] L. Fortnow. One complexity theorist’s view of quantum computing. Theoretical

Comput. Sci., 292(3):597–610, 2003.

[115] L. Fortnow and N. Reingold. PP is closed under truth-table reductions. Information

and Computation, 124(1):1–6, 1996.

[116] L. Fortnow and J. Rogers. Complexity limitations on quantum computation. J.

Comput. Sys. Sci., 59(2):240–252, 1999. cs.CC/9811023.

[117] L. Fortnow and M. Sipser. Are there interactive protocols for co-NP languages?

Inform. Proc. Lett., 28:249–251, 1988.

[118] J. Franklin and J. Lorenz. On the scaling of multidimensional matrices. Linear Algebra

Appl., 114/115:717–735, 1989.

[119] J. R. Friedman, V. Patel, W. Chen, S. K. Tolpygo, and J. E. Lukens. Quantum

superposition of distinct macroscopic states. Nature, 406:43–46, 2000.

[120] M. Furst, J. B. Saxe, and M. Sipser. Parity, circuits, and the polynomial time hierar-

chy. Math. Systems Theory, 17:13–27, 1984.

[121] S. B. Gashkov. The complexity of the realization of Boolean functions by networks
of functional elements and by formulas in bases whose elements realize continuous
functions. Prob. Kibernetiki, 37:52–118, 1980.

[122] M. Gell-Mann and J. Hartle. Quantum mechanics in the light of quantum cosmol-
ogy. In W. H. Zurek, editor, Complexity, Entropy, and the Physics of Information.
Addison-Wesley, 1990.

[123] G. C. Ghirardi, A. Rimini, and T. Weber. Uniﬁed dynamics for microscopic and

macroscopic systems. Phys. Rev. D, 34:470–491, 1986.

[124] S. Ghosh, T. F. Rosenbaum, G. Aeppli, and S. N. Coppersmith. Entangled quantum

state of magnetic dipoles. Nature, 425:48–51, 2003. cond-mat/0402456.

[125] D. T. Gillespie. Why quantum mechanics cannot be formulated as a Markov process.

Phys. Rev. A, 49:1607, 1994.

237

[126] N. Gisin. Weinberg’s non-linear quantum mechanics and superluminal communica-

tions. Phys. Lett. A, 143:1–2, 1990.

[127] A. M. Gleason. Measures on the closed subspaces of a Hilbert space. J. Math. Mech.,

6:885–893, 1957.

[128] O. Goldreich. On quantum computing. www.wisdom.weizmann.ac.il/˜oded/on-

qc.html, 2004.

[129] O. Goldreich and S. Goldwasser. On the limits of non-approximability of lattice

problems. In Proc. ACM STOC, pages 1–9, 1998.

[130] O. Goldreich, S. Micali, and A. Wigderson. Proofs that yield nothing but their validity
or all languages in NP have zero-knowledge proof systems. J. ACM, 38(1):691–729,
1991.

[131] S. Goldwasser and M. Sipser. Private coins versus public coins in interactive proof
In Randomness and Computation, volume 5 of Advances in Computing

systems.
Research. JAI Press, 1989.

[132] D. Gottesman. Class of quantum error-correcting codes saturating the quantum Ham-

ming bound. Phys. Rev. A, 54:1862–1868, 1996. quant-ph/9604038.

[133] D. Gottesman. The Heisenberg representation of quantum computers. Talk at Int.

Conf. on Group Theoretic Methods in Physics. quant-ph/9807006, 1998.

[134] F. Green, S. Homer, C. Moore, and C. Pollett. Counting, fanout, and the complexity
of quantum ACC. Quantum Information and Computation, 2(1):35–65, 2002. quant-
ph/0106017.

[135] F. Green and R. Pruim. Relativized separation of EQP from P N P . Inform. Proc.

Lett., 80(5):257–260, 2001.

[136] D. M. Greenberger, M. A. Horne, and A. Zeilinger. Bell’s theorem without inequalities.
In A. I. Miller, editor, Sixty-Two Years of Uncertainty: Historical, Philosophical, and
Physical Inquiries into the Foundations of Quantum Mechanics. Plenum, 1990.

[137] R. B. Griﬃths. Choice of consistent family, and quantum incompatibility. Phys. Rev.

A, 57:1604, 1998. quant-ph/9708028.

[138] M. Grigni, L. Schulman, M. Vazirani, and U. Vazirani. Quantum mechanical algo-
In Proc. ACM STOC, pages

rithms for the nonabelian hidden subgroup problem.
68–74, 2001.

[139] L. K. Grover. A fast quantum mechanical algorithm for database search. In Proc.

ACM STOC, pages 212–219, 1996. quant-ph/9605043.

[140] E. Guay and L. Marchildon. Two-particle interference in standard and Bohmian quan-

tum mechanics. J. Phys. A.: Math. Gen., 36:5617–5624, 2003. quant-ph/0302085.

238

[141] S. Hallgren. Polynomial-time quantum algorithms for Pell’s equation and the principal

ideal problem. In Proc. ACM STOC, pages 653–658, 2002.

[142] Y. Han, L. Hemaspaandra, and T. Thierauf. Threshold computation and crypto-

graphic security. SIAM J. Comput., 26(1):59–78, 1997.

[143] L. Hardy. Quantum theory from ﬁve reasonable axioms. quant-ph/0101012, 2003.

[144] A. J. Hoﬀman and H. W. Wielandt. The variation of the spectrum of a normal matrix.

Duke J. Math, 20:37–39, 1953.

[145] A. S. Holevo. Some estimates of the information transmitted by quantum commu-
nication channels. Problems of Information Transmission, 9:177–183, 1973. English
translation.

[146] P. Høyer and R. de Wolf. Improved quantum communication complexity bounds for
disjointness and equality. In Proc. Intl. Symp. on Theoretical Aspects of Computer
Science (STACS), pages 299–310, 2002. quant-ph/0109068.

[147] R. Impagliazzo and A. Wigderson. P=BPP unless E has subexponential circuits:
derandomizing the XOR Lemma. In Proc. ACM STOC, pages 220–229, 1997.

[148] D. Janzing, P. Wocjan, and T. Beth. Cooling and low energy state preparation for

3-local Hamiltonians are FQMA-complete. quant-ph/0303186, 2003.

[149] D. S. Johnson, C. H. Papadimitriou, and M. Yannakakis. How easy is local search?

J. Comput. Sys. Sci., 37:79–100, 1988.

[150] E. Kasheﬁ, A. Kent, V. Vedral, and K. Banaszek. A comparison of quantum oracles.

Phys. Rev. A, 65, 2002. quant-ph/0109104.

[151] I. Kerenidis and R. de Wolf. Exponential lower bound for 2-query locally decodable
codes via a quantum argument. In Proc. ACM STOC, pages 106–115, 2003. quant-
ph/0208062.

[152] A. Kitaev. Quantum measurements and the abelian stabilizer problem. ECCC TR96-

003, quant-ph/9511026, 1996.

[153] A. Kitaev. Quantum computation: algorithms and error correction. Russian Math.

Surveys, 52(6):1191–1249, 1997.

[154] H. Klauck. Quantum communication complexity.

In Proc. Intl. Colloquium on
Automata, Languages, and Programming (ICALP), pages 241–252, 2000. quant-
ph/0005032.

[155] H. Klauck. Quantum time-space tradeoﬀs for sorting. In Proc. ACM STOC, pages

69–76, 2003. quant-ph/0211174.

[156] H. Klauck, R. ˇSpalek, and R. de Wolf. Quantum and classical strong direct product
In Proc. IEEE FOCS, 2004. quant-

theorems and optimal time-space tradeoﬀs.
ph/0402123.

239

[157] A. Klivans and D. van Melkebeek. Graph nonisomorphism has subexponential size
proofs unless the polynomial-time hierarchy collapses. SIAM J. Comput., 31:1501–
1526, 2002. Earlier version in ACM STOC 1999.

[158] E. Knill, R. Laﬂamme, R. Martinez, and C. Negrevergne.

Implementation of the
ﬁve qubit error correction benchmark. Phys. Rev. Lett., 86:5811–5814, 2001. quant-
ph/0101034.

[159] E. Knill, R. Laﬂamme, and W. Zurek. Resilient quantum computation. Science,

279:342–345, 1998. quant-ph/9702058.

[160] E. Kushilevitz and N. Nisan. Communication Complexity. Cambridge, 1997.

[161] S. Kutin. A quantum lower bound for the collision problem. quant-ph/0304162, 2003.

[162] R. E. Ladner. On the structure of polynomial time reducibility. J. ACM, 22:155–171,

1975.

[163] C. Lautemann. BPP and the polynomial hierarchy. Inform. Proc. Lett., 17:215–217,

1983.

[164] A. J. Leggett. Testing the limits of quantum mechanics: motivation, state of play,

prospects. J. Phys. Condensed Matter, 14:R415–451, 2002.

[165] L. Levin. Polynomial time and extravagant models, in The tale of one-way functions.

Problems of Information Transmission, 39(1):92–103, 2003. cs.CR/0012023.

[166] N. Linial, Y. Mansour, and N. Nisan. Constant depth circuits, Fourier transform, and

learnability. J. ACM, 40(3):607–620, 1993.

[167] N. Linial, A. Samorodnitsky, and A. Wigderson. A deterministic strongly polynomial
algorithm for matrix scaling and approximate permanents. Combinatorica, 20(4):545–
568, 2000.

[168] D. C. Llewellyn and C. Tovey. Dividing and conquering the square. Discrete Appl.

Math, 43:131–153, 1993.

[169] D. C. Llewellyn, C. Tovey, and M. Trick. Local optimization on graphs. Discrete

Appl. Math, 23:157–178, 1989. Erratum: 46:93–94, 1993.

[170] S. Lloyd. Computational capacity of the universe. Phys. Rev. Lett., 88, 2002. quant-

ph/0110141.

[171] C. Lund, L. Fortnow, H. Karloﬀ, and N. Nisan. Algebraic methods for interactive

proof systems. J. ACM, 39:859–868, 1992.

[172] A. A. Markov.

On a question by D.
torskoi Akademii Nauk, SP6(62):1–24, 1890.
www.math.technion.ac.il/hat/fpapers/markov4.pdf.

I. Mendeleev.

Impera-
Russian. English translation at

Zapiski

240

[173] V. A. Markov. ¨Uber Polynome, die in einem gegebenen Intervalle m¨oglichst wenig
von Null abweichen. Math. Ann., 77:213–258, 1916. German. Originally written in
1892.

[174] N. Megiddo and C. H. Papadimitriou. On total functions, existence theorems, and

computational complexity. Theoretical Comput. Sci., 81:317–324, 1991.

[175] N. D. Mermin. From cbits to qbits: teaching computer scientists quantum mechanics.

American J. Phys., 71(1):23–30, 2003. quant-ph/0207118.

[176] G. Midrijanis. A polynomial quantum query lower bound for the set equality problem.
In Proc. Intl. Colloquium on Automata, Languages, and Programming (ICALP), pages
996–1005, 2004. quant-ph/0401073.

[177] G. L. Miller. Riemann’s hypothesis and tests for primality. J. Comput. Sys. Sci.,

13:300–317, 1976.

[178] M. Minsky and S. Papert. Perceptrons (2nd edition). MIT Press, 1988. First appeared

in 1968.

[179] M. Nagasawa. Transformations of diﬀusions and Schr¨odinger processes. Prob. Theory

and Related Fields, 82:109–136, 1989.

[180] A. Nayak. Optimal lower bounds for quantum automata and random access codes.

In Proc. IEEE FOCS, pages 369–377, 1999. quant-ph/9904093.

[181] E. Nelson. Quantum Fluctuations. Princeton, 1985.

[182] M. Nielsen and I. Chuang. Quantum Computation and Quantum Information. Cam-

bridge, 2000.

[183] N. Nisan. CREW PRAMs and decision trees. SIAM J. Comput., 20(6):999–1007,

1991.

[184] N. Nisan and M. Szegedy. On the degree of Boolean functions as real polynomials.

Computational Complexity, 4(4):301–313, 1994.

[185] N. Nisan and A. Wigderson. Hardness vs. randomness.

J. Comput. Sys. Sci.,

49(2):149–167, 1994.

[186] H. Nishimura and T. Yamakami. Polynomial time quantum computation with advice.

Inform. Proc. Lett., 90:195–204, 2003. ECCC TR03-059, quant-ph/0305100.

[187] C. H. Papadimitriou. Talk at UC Berkeley, February 6, 2003.

[188] C. H. Papadimitriou. Computational Complexity. Addison-Wesley, 1994.

[189] R. Penrose. The Emperor’s New Mind. Oxford, 1989.

[190] C. Philippidis, C. Dewdney, and B. J. Hiley. Quantum interference and the quantum

potential. Nuovo Cimento, 52B:15–28, 1979.

241

[191] J. Polchinski. Weinberg’s nonlinear quantum mechanics and the Einstein-Podolsky-

Rosen paradox. Phys. Rev. Lett., 66:397–400, 1991.

[192] M. Rabin and A. C-C. Yao. Manuscript, 1979.

[193] E. Rains. Talk given at AT&T, Murray Hill, New Jersey, on March 12, 1997.

[194] R. Raussendorf, D. E. Browne, and H. J. Briegel. Measurement-based quantum com-

putation on cluster states. Phys. Rev. A, 68, 2003. quant-ph/0301052.

[195] R. Raz. Multi-linear formulas for permanent and determinant are of super-polynomial

size. In Proc. ACM STOC, pages 633–641, 2004. ECCC TR03-067.

[196] R. Raz. Multilinear-N C1 6
2004. ECCC TR04-042.

= multilinear-N C2. In Proc. IEEE FOCS, pages 344–351,

[197] R. Raz, G. Tardos, O. Verbitsky, and N. Vereshchagin. Arthur-Merlin games in

Boolean decision trees. J. Comput. Sys. Sci., 59(2):346–372, 1999.

[198] A. A. Razborov. Lower bounds for the size of circuits of bounded depth with basis
. Mathematicheskie Zametki, 41(4):598–607, 1987. English translation in Math.

&,

{
Notes. Acad. Sci. USSR 41(4):333–338, 1987.

⊕}

[199] A. A. Razborov. Quantum communication complexity of symmetric predicates.

Izvestiya Math. (English version), 67(1):145–159, 2003. quant-ph/0204025.

[200] A. A. Razborov and S. Rudich. Natural proofs. J. Comput. Sys. Sci., 55(1):24–35,

1997.

[201] I. B. Damg˚ard. Collision free hash functions and public key signature schemes. In Pro-
ceedings of Eurocrypt’87, volume 304 of Lecture Notes in Computer Science. Springer-
Verlag, 1988.

[202] O. Reingold. Undirected ST-connectivity in log-space. 2004.

[203] T. J. Rivlin. Chebyshev Polynomials: From Approximation Theory to Algebra and

Number Theory. Wiley, 1990.

[204] T. J. Rivlin and E. W. Cheney. A comparison of uniform approximations on an
interval and a ﬁnite subset thereof. SIAM J. Numerical Analysis, 3(2):311–320, 1966.

[205] C. Rovelli and L. Smolin. Discreteness of area and volume in quantum gravity. Nuclear

Physics, B442:593–622, 1995. Erratum in Vol. B456, p. 753. gr-qc/9411005.

[206] T. Rudolph and L. Grover. Quantum searching a classical database (or how we learned

to stop worrying and love the bomb). quant-ph/0206066, 2002.

[207] B. S. Ryden. Introduction to Cosmology. Addison-Wesley, 2002.

242

[208] S. Perlmutter and 32 others (Supernova Cosmology Project). Measurements of Ω and
Λ from 42 high-redshift supernovae. Astrophysical Journal, 517(2):565–586, 1999.
astro-ph/9812133.

[209] A. Sahai and S. Vadhan. A complete promise problem for statistical zero-knowledge.
J. ACM, 50(2):196–249, 2003. ECCC TR00-084. Earlier version in IEEE FOCS 1997.

[210] M. Santha. On the Monte-Carlo decision tree complexity of read-once formulae.

Random Structures and Algorithms, 6(1):75–87, 1995.

[211] M. Santha and M. Szegedy. Quantum and classical query complexities of local search

are polynomially related. In Proc. ACM STOC, pages 494–501, 2004.

[212] N. Sauer. On the density of families of sets. J. Combinatorial Theory Series A,

13:145–147, 1972.

[213] E. Schr¨odinger. ¨Uber die Umkehrung der Naturgesetze. Sitzungsber. Preuss. Akad.

Wissen. Phys. Math. Kl., pages 144–153, 1931.

[214] L. J. Schulman and U. V. Vazirani. Molecular scale heat engines and scalable quantum

computation. In Proc. ACM STOC, pages 322–329, 1999.

[215] A. Shamir. IP=PSPACE. J. ACM, 39(4):869–877, 1992.

[216] N. Shenvi, J. Kempe, and K. B. Whaley. A quantum random walk search algorithm.

Phys. Rev. A, 67(5), 2003. quant-ph/0210064.

[217] Y. Shi. Both Toﬀoli and controlled-NOT need little help to do universal quantum
computation. Quantum Information and Computation, 3(1):84–92, 2002. quant-
ph/0205115.

[218] Y. Shi. Quantum lower bounds for the collision and the element distinctness problems.

In Proc. IEEE FOCS, pages 513–519, 2002. quant-ph/0112086.

[219] P. Shor. Polynomial-time algorithms for prime factorization and discrete logarithms
on a quantum computer. SIAM J. Comput., 26(5):1484–1509, 1997. Earlier version
in IEEE FOCS 1994. quant-ph/9508027.

[220] D. Simon. On the power of quantum computation.

In Proc. IEEE FOCS, pages

116–123, 1994.

[221] R. Sinkhorn. A relationship between arbitrary positive matrices and doubly stochastic

matrices. Ann. Math. Statist., 35:876–879, 1964.

[222] M. Sipser. A complexity theoretic approach to randomness. In Proc. ACM STOC,

pages 330–335, 1983.

[223] R. Smolensky. Algebraic methods in the theory of lower bounds for Boolean circuit

complexity. In Proc. ACM STOC, pages 77–82, 1987.

243

[224] J. H˚astad. Some optimal inapproximability results. J. ACM, 48:798–859, 2001.

[225] A. Steane. Multiple particle interference and quantum error correction. Proc. Roy.

Soc. London, A452:2551–2577, 1996. quant-ph/9601029.

[226] V. Strassen. Gaussian elimination is not optimal. Numerische Mathematik,

14(13):354–356, 1969.

[227] G. ’t Hooft. Quantum gravity as a dissipative deterministic system. Classical and

Quantum Gravity, 16:3263–3279, 1999. gr-qc/9903084.

[228] S. Toda. PP is as hard as the polynomial-time hierarchy. SIAM J. Comput., 20(5):865–

877, 1991.

[229] B. Tsirelson.

Quantum information

processing

lecture

notes,

1997.

www.math.tau.ac.il/˜tsirel/Courses/QuantInf/lect7.ps.

[230] G. Tur´an and F. Vatan. On the computation of Boolean functions by analog circuits

of bounded fan-in (extended abstract). In Proc. IEEE FOCS, pages 553–564, 1994.

[231] L. G. Valiant and V. V. Vazirani. NP is as easy as detecting unique solutions. Theo-

retical Comput. Sci., 47(3):85–93, 1986.

[232] W. van Dam, S. Hallgren, and L. Ip. Algorithms for some hidden shift problems.
In Proc. ACM-SIAM Symp. on Discrete Algorithms (SODA), pages 489–498, 2003.
quant-ph/0211140.

[233] W. van Dam, M. Mosca, and U. Vazirani. How powerful is adiabatic quantum com-

putation? In Proc. IEEE FOCS, pages 279–287, 2001. quant-ph/0206003.

[234] L. Vandersypen, M. Steﬀen, G. Breyta, C. S. Yannoni, M. H. Sherwood, and I. L.
Chuang. Experimental realization of Shor’s quantum factoring algorithm using nuclear
magnetic resonance. Nature, 414:883–887, 2001. quant-ph/0112176.

[235] U. Vazirani. UC Berkeley Quantum computation course lecture notes, 2004. At

www.cs.berkeley.edu/˜vazirani/quantum.html.

[236] G. Vidal. Eﬃcient classical simulation of slightly entangled quantum computations.

Phys. Rev. Lett., 91, 2003. quant-ph/0301063.

[237] H. E. Warren. Lower bounds for approximation by non-linear manifolds. Trans. Amer.

Math. Soc., 133:167–178, 1968.

[238] J. Watrous. On one-dimensional quantum cellular automata. In Proc. IEEE FOCS,

pages 528–537, 1995.

[239] J. Watrous. Succinct quantum proofs for properties of ﬁnite groups. In Proc. IEEE

FOCS, pages 537–546, 2000. cs.CC/0009002.

244

[240] I. Wegener and L. Z´adori. A note on the relations between critical and sensitive
complexity. EIK: Journal of Information Processing and Cybernetics, 25:417–421,
1989.

[241] S. Weinberg. Dreams of a Final Theory. Vintage, 1994.

[242] E. Wigner. The unreasonable eﬀectiveness of mathematics in the natural sciences.

Communications in Pure and Applied Mathematics, 13(1), 1960.

[243] A. Winter. Quantum and classical message identiﬁcation via quantum channels. In

A. S. Holevo Festschrift. Rinton, 2004. To appear. quant-ph/0401060.

[244] R. de Wolf. Quantum Computing and Communication Complexity. PhD thesis, Uni-

versity of Amsterdam, 2001.

[245] R. de Wolf. Characeterization of non-deterministic quantum query and quantum
communication complexity. SIAM J. Comput., 32(3):681–699, 2003. Earlier version
in Proc. IEEE Complexity 2000. cs.CC/0001014.

[246] S. Wolfram. A New Kind of Science. Wolfram Media, 2002.

[247] A. C-C. Yao. Some complexity questions related to distributive computing. In Proc.

ACM STOC, pages 209–213, 1979.

[248] A. C-C. Yao. Quantum circuit complexity.

In Proc. IEEE FOCS, pages 352–361,

1993.

[249] A. C-C. Yao.

Princeton University

course

assignment,

2001.

At

www.cs.princeton.edu/courses/archive/spr01/cs598a/assignments/hw3.ps.

[250] A. C-C. Yao. On the power of quantum ﬁngerprinting. In Proc. ACM STOC, pages

77–81, 2003.

[251] Ch. Zalka. Could Grover’s algorithm help in searching an actual database? quant-

ph/9901068, 1999.

[252] W. H. Zurek. Environment-assisted invariance, causality, and probabilities in quantum

physics. Phys. Rev. Lett., 90, 2003. quant-ph/0211037.

