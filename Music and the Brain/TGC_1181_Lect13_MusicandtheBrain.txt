So far in this course we've focused on music cognition in adults.
In this lecture we'll turn to research on the development of music cognition in infants
and children.
This is a very important topic for the study of music in the brain because tracing how
music cognition develops can tell us about the different components of musicality.
Not all components of musicality mature at the same rate.
Some components develop more quickly than others.
And this gives us a way to parse the musical mind into different components.
Also developmental studies can teach us about the interaction between inborn predispositions
and experience in shaping the musical mind.
Let me give you an example from a classic experiment by Laurel, Traynor, and Sandra
Treehub.
In 1992 they conducted a study designed to test whether infants were sensitive to musical
key.
We've talked about musical key earlier in this course.
Even if you've never studied music theory, you implicitly know something about musical
key.
One way we know this is by people's sensitivity to out of key notes.
Let's listen to a short sound example.
See if you can hear the out of key note in this melody.
In that melody, one note was out of key, and it tends to pop out perceptually.
That note was a perfectly well tuned note.
It popped out because it's not part of the key of the melody.
As we discussed in an earlier lecture, when out of key notes are used artfully, they add
energy and expression to musical melodies.
For example, the melodies of art songs by Schubert often use out of key notes.
How early does our sensitivity to key membership develop?
In their study, Traynor and Treehub tested 8 month old infants for their sensitivity to
musical key.
You can't ask an 8 month old to tell you if she hears an out of key note, so the researchers
used a method that has often been used to test infant music perception.
This method relies on infant's tendency to habituate to a repeating stimulus.
If a sound repeats over and over, infants get bored with it.
When they notice a change, they react, for example turning towards the speaker that played
the novel sound.
In this study, a melody was repeated in the background over and over.
This was a simple 10 note melody in the key of C major.
In the experiment, the melody was transposed to different keys from one repetition to the
next in order to focus the infant's attention on the pattern of relative pitch between notes
rather than the absolute pitch of the notes.
Infants did grow bored with this repeating melody, that is they habituated to the repeating
stimulus.
The question was, how easily would the infant's detected change in the melody?
In one condition, the sixth note of the melody was changed to another in key note.
Let's hear that background melody followed by this kind of change.
First the background melody.
Now the melody with the in key change.
You may have noticed that this change is pretty subtle to our ears, even though the sixth
note was four semitones higher than the same note in the original melody.
In another condition, the background melody changed so that the sixth note became an out
of key note.
Let's hear the background melody again.
And now the melody with the out of key change.
In the melody with the out of key note, the changed note was just one semitone higher
than the same note in the original melody.
It's a smaller physical change than the in key change, but for adults it's a large perceptual
change because of our implicit knowledge of musical key.
The interesting finding of this study was that the infants detected the in key and out
of key changes equally well.
When adults were tested using these same melodies, they detected the out of key change much better
than the in key change.
This suggests that at eight months, infants have not yet developed implicit knowledge
about musical key.
This makes sense because key is a fairly abstract aspect of music.
It's not about how individual notes sound, it's about how notes are combined according
to certain culture specific principles.
Later research showed that by four or five years of age, children in western culture
do more easily detect out of key changes to melodies than in key changes.
By then, they have implicitly learned some of the principles of their culture's music
just by being exposed to the music.
This process is called musical enculturation.
These results are important because they teach us that infants don't perceive music
the same way we do.
We know that infants can enjoy music so it's natural to assume that they hear music in
the same way adults do, but that's not the case.
Their cognitive processes of music perception are not the same as ours.
Many aspects of ordinary music cognition take time to develop.
If we find that an aspect of music cognition like sensitivity to musical key takes time
to develop, one question that immediately comes to mind is whether experience can influence
the time course of development.
There are certain aspects of human biology that have a pre-programmed timing.
For example, a boy's voice gets lower when he goes through puberty due to the influence
of hormones on the size and mass of the vocal folds.
The different aspects of musicality develop on biologically determined schedules or can
experience significantly impact the time course of their development.
In 2012, Laurel Trainor and her colleagues David Gehry and Andrea Unrow published a paper
showing that experience can have a powerful role in the development of music cognition.
They looked at six-month-old infants who took weekly hour-long music classes.
These were kinder music classes that the infants attended weekly with a parent.
Infants were randomly assigned to one of two groups.
One group was the active group in which teachers encouraged infants to play percussion instruments
and sing and to actively engage with the music.
The other group was the passive group.
This group listened to a selection of CDs of classical music while teachers encouraged
them to play with non-musical toys like balls and blocks or to do visual art.
After six months, Trainor and colleagues tested different aspects of cognitive and social
development in the two groups.
One test examined sensitivity to musical key.
This was done by testing whether infants preferred to listen to a piece of music that stayed
within a key versus a piece of music that alternated between two keys on every beat.
Preference was quantified by measuring how long an infant would look at a speaker playing
each version of the piece.
They made the two versions from a sonatina by Thomas Atwood, a composer who lived from
the late 1700s to the early 1800s.
The single key version was the original piece, and the dual key version was a modified version
of this piece.
The neat thing about this manipulation is that it didn't change the sensory consonants
or dissonance of individual chords.
In the two key version, they changed the chords on every other beat.
The changed chords were still intrinsically consonant, if heard on their own, but since
they came from another key, they destroyed any coherent sense of key in the piece.
Let's listen to the two versions of this piece.
Here's the original.
And here is the altered version.
The researchers found that the infants in the active group had a preference for the
original version, which stayed in one key.
The infants in the passive group had no preference.
This suggests that with six months of active engagement with music, one-year-olds can begin
to show sensitivity to musical key.
Experience can strongly influence the time course of cognitive development in music.
Before this study, it was generally believed that sensitivity to key didn't start to emerge
till around four years of age, based on passive exposure to music.
In a 2015 paper, trainer and her colleagues reported brain measurements of the infants
that had been in the two groups in their earlier study.
They wanted to know if there was evidence of faster brain development in the active group
in terms of responses to musical tones.
They used EEG to measure brain responses to one tone, the note C, when it was played
repeatedly.
This time there was no task.
The infants just listened, while the researchers measured EEG patterns using little arrays of
electrodes that looked like hairnets which had been gently placed on the infant's heads.
The researchers examined event-related potentials, or ERPs, in response to this tone.
We talked about ERPs in the last lecture.
They allow one to measure the electrical response of large populations of neurons with excellent
time resolution.
In this case, the ERP analysis focused on signals coming from the cerebral cortex.
At six months, there were no differences between the groups and their brain responses
to this tone.
But at 12 months, the brain signals from the infants who had been in the active group
were significantly larger.
Basic tone processing in their brains was more advanced than in the passive music group.
Because the babies had been randomly assigned to the two groups, we know this difference
is due to the active training and not just an innate difference.
The ability to record electrical brain responses from infants and young children is beginning
to play an important role in our study of the development of music cognition.
One advantage of these methods is that they don't require a behavioral response.
By measuring signals directly from the brain, these methods have given us new ways to study
learning and to quantify neuroplasticity.
How early can musical learning begin?
The study we just discussed showed that significant musical learning can happen in the first year
of life.
The research I want to tell you about next showed that musical learning can happen before
birth.
It's been known for a long time that the human fetus starts to hear in the third trimester
of pregnancy, around 27 weeks.
This means that hearing has a head start over vision in terms of development, since structured
visual stimulation doesn't start till after birth.
Multiple studies have shown that newborns recognize sounds they have heard in utero,
such as their mother's voice.
They don't understand the meanings of the words they've heard in utero, but they have
picked up on things about the sound pattern of the words.
For instance, newborns prefer to listen to their native language than to a foreign language,
even if both are spoken by an unfamiliar person.
Research shows that this preference seems to be related to a preference for the rhythm
of the native language, which they've heard in utero.
Can babies also learn about music in utero?
In the 1980s, research showed that newborns prefer hearing a story that their mother has
read repeatedly during the last six weeks of pregnancy, versus a novel story read by
their mother.
This means they can pick up on specific sound patterns they've heard repeatedly while in
utero.
So if the mother sings a song over and over during pregnancy, a newborn would probably
recognize it.
But this is still the mother's voice, which may get special treatment in a baby's brain
because it's heard so often.
Can a fetus learn about music in the environment which isn't produced by the mother?
In thinking about this question, one obvious question is how well the fetus can hear sounds
other than the mother's voice.
The fetus is in a liquid environment and is separated from the outside world by the uterus
and the abdominal wall.
The sounds that reach the fetal ear are filtered by these physical structures, and high-frequency
parts of sounds are especially strongly damped.
Also there are physiological sounds coming from the mother, including the blood being
pumped through the uterine artery, which can mask out many sounds from the outside world.
What does music sound like from inside a human uterus?
Is it clear enough so that a fetus could learn about musical structure?
In 1992, as part of her PhD thesis, the researcher Sheila Woodward answered this question.
She was able to insert a hydrophone, that's an underwater microphone, into the uterus
of a pregnant woman and make a recording.
She recorded herself singing nearby the pregnant woman.
You can hear those recordings in a 2004 documentary called The Music Instinct by Eleanor Mannis.
And you can also see a picture of the tiny hydrophone Woodward used.
The big surprise of this research was how audible the singing was.
Our course composer, Jason Rosenberg, has listened carefully to those recordings in
the documentary and has created a simulation which we'll hear now.
This simulation is meant to give us a feeling of what it's like to hear someone singing
from inside the human uterus.
In this case, the voice is a male voice, so this might be what father's singing sounds
like to a baby before birth.
The music does seem audible enough for fetuses to begin to learn about its structure.
But do they learn?
The answer isn't obvious.
The middle ear of a fetus is full of fluid, and this probably damps the vibrations of
the middle ear bones.
This means that what music sounds like to us in recordings made inside the uterus may
not be what music sounds like to the fetus.
Again, we have to be careful about assuming that babies hear the world the way we do.
One way to test if fetuses can learn about music that isn't produced by the mother is
to expose them to recorded music during gestation and then test them as newborns to see if they
recognize this music.
This was done in a 1991 study by Peter Hepper.
Hepper had one group of mothers listen to a particular tune once or twice a day throughout
their pregnancy and had another group of mothers not listen to this tune.
This was a tune from a popular TV show at the time.
At birth, Hepper tested newborns in the two groups.
The group that had heard the tune prenatally reacted to the tune via changes in heart rate,
movement and alertness.
The other group didn't show these reactions.
In follow-up studies, Hepper showed that newborns who heard a tune in utero didn't
react to a different tune or to the original tune played backwards.
This meant that the music exposure didn't just increase their responsiveness to music
generally, but actually resulted in their learning about a particular tune.
He went on to show that fetuses showed signs of recognizing a familiar tune before birth.
At around 37 weeks fetuses moved more in response to a familiar tune than to other tunes.
I find it remarkable that humans can start to learn about the melodies of their culture
before they are born, including melodies that aren't sung by the mother.
Through music, humans begin to experience the artistic traditions of their culture well
before they get their first glimpse of the outside world.
Even once they're born, musical patterns may be clearer to them than many visual patterns
in their environment.
Newborns are very near-sighted.
Things beyond about 15 inches away are very blurry.
But in normal newborns, hearing isn't blurry.
Auditory perception does develop over an extended period, but is shown by researchers like
Janet Worker, Patricia Kool, Jenny Saffron and others.
Babies quickly start to pick up on the details of auditory patterns and learn things about
them.
So far in this lecture I focused on how the processing of pitch patterns develop.
Now I want to turn to research that looks at the development of sensitivity to rhythm
patterns.
I'll start by focusing on one very widespread aspect of musical behavior, the tendency to
move in synchrony with a musical beat.
This is seen in every culture and is fundamental to dance all over the world.
As we discussed in a previous lecture, even though this ability seems simple to us, it
reflects complex brain processing and may not be possible for many animals, including
most other primates.
In Western culture, the ability to move in synchrony to a beat doesn't appear reliably
in children until about five years old.
I'm talking about clapping or bobbing or dancing in a way such that movements line up with
the beat the way they do in adults.
But until recently, no one had measured the movements of babies to see if they were really
already doing this in a simple way.
It seems like something that infants could potentially do, since it can be done with
simple movements like bobbing the head.
In 2010, Marcel Zentner and Tuomas Arola published a paper in which they measured babies' movements
to music.
They had parents bring their babies to the lab and sit in a chair with the baby on their
lap.
The researchers played the babies different kinds of sounds, including music with a steady
beat and speech aimed at infants and children.
The parents listened to a spoken text over headphones so that they couldn't hear what
the infants were hearing and potentially cue their babies and confound the study.
The researchers did quantitative measurements of the infant's rhythmic movements and found
that the infants did move rhythmically much more to music than to speech.
However, the movements were not synchronized to the beat.
It may be that the babies perceived the beat, but just couldn't coordinate their movements
with it.
We know that motor control takes time to develop in babies.
Maybe that's why it's not until four or five that children seem like they can really
move in synchrony with a beat.
One interesting 2009 study by Kirschner and Tomas Ello showed that in social situations,
children may be able to synchronize at a younger age.
If a child drums with a human social partner and not just with recorded drumming, they
can synchronize around two and a half years old.
Social context can modulate the musical abilities of children.
One reason I wanted to discuss this line of research is that it brings up an important
point about the difference between innate predispositions and the age of emergence of
behavior and development.
The fact that people in every culture move to the beat of music and that this ability
doesn't come easily to other animals suggests that something about human brains predisposes
us to engage in this behavior.
But having a biological predisposition for a behavior doesn't mean the behavior is
fully developed at birth.
Language is a good example.
Most neuroscientists believe that our brains have biological specializations for language
processing.
But we're not born speaking or understanding our native language.
We need experience with language for language abilities to develop normally.
Similarly, we need experience with music for most aspects of music cognition to develop
normally.
Social research can teach us about how experience interacts with innate predispositions to shape
adult cognition.
Often this experience serves to fine tune our cognitive processing for the sound patterns
in our culture.
One example of this in the domain of rhythm comes from interesting cross-cultural research
on rhythm perception.
In Western music, musical beats are typically spaced evenly in time, like a metronome.
In an earlier lecture we discussed how this is not a musical universal.
For example, in certain types of Balkan music, beats can be spaced at uneven intervals, with
a long interval being one and a half times the duration of a short interval.
Let's listen again to an example of this where the beat intervals are short, short,
short, long, short, short, short, long in a repeating cycle.
You'll hear a melody that has this rhythm.
After a few cycles, the beats will be marked by a percussive sound to help us hear where
a native listener would perceive the beats in this pattern.
In 2005, Aaron Hannon and Sandra Tree have published a study in which they compared infants
and adults in their ability to detect changes to beat patterns in musical passages.
Some passages had beats separated by equal time intervals, like most Western music.
Other passages had beats organized like Balkan music, where the intervals between beats weren't
all the same.
The question was how easy was it for infants and adults to detect changes to these beat
patterns?
To measure this, the researchers used two types of rhythmic changes.
One type changed the pattern of note durations in a melody, but didn't change the beat pattern.
The other type of change did change the beat pattern.
These kinds of manipulations were done both for Western-style music with evenly spaced
beats, and for Balkan-style music with unevenly spaced beats.
The researchers found that when Western adults listened to Western music, they more easily
detected changes that violated the steady beat pattern than changes that didn't violate
it.
For them, the steady beats provided a clear perceptual framework, so that changes in the
timing of beats were easily detected.
On the other hand, when Western listeners listened to Balkan music, the results were
quite different.
When asked to detect changes to the rhythm, they did not have an easier time with changes
that altered the underlying beat.
It was as if they had difficulty extracting the beat patterns from the Balkan rhythms
and using it as a framework to guide their perception.
Hannon and Trehub then showed that Balkan adults found it equally easy to detect changes
to the beat in Western and Balkan music.
This was because they had grown up hearing both kinds of music.
They were bi-musical to borrow a word from ethnomusicology.
What about the infants?
These were Western infants, so you might expect that they would perform like Western adults,
but that's not what happened.
They detected alterations to Western and Balkan beat patterns equally well.
This suggests that the problem Western adults have in preceding Balkan rhythms is not because
humans have an innate bias for evenly timed beats.
It's because experience has tuned the perceptual system to the patterns of the native culture.
Part of this tuning actually involves losing sensitivity to patterns that we don't normally
encounter.
This is familiar from speech perception.
As shown in classic work by Janet Worker and her colleagues, babies can sometimes distinguish
between foreign speech sounds better than adults.
Japanese adults have trouble hearing the difference between English L and R sounds, but Japanese
babies don't have this problem.
It's experience with their native language, which doesn't have this L-R contrast, which
tunes their perceptual system away from irrelevant contrasts and toward relevant ones.
The work of Hannon and Treehub suggests that similar things can happen in music.
In later work, Hannon and Treehub showed that by 12 months Western infants are biased towards
the evenly spaced beats of their culture.
Interestingly though, the researchers showed that this bias can be reversed if babies are
given exposure to Balkan music at that age.
Most of this lecture has been focused on how infants process musical structure.
In the last part of the lecture, I want to tell you about some interesting research on
infant responses to music.
We all intuitively know that music can capture infants' attention and influence their emotions.
Infants might smile or move rhythmically to music that they like, or frown or cry to music
that they don't like.
Also, many cultures use lullabies and play songs to soothe or arouse infants.
We also know infants are very interested in speech and can be soothed or aroused by it.
Adults often use a special form of speech when talking to infants, which researchers have
nicknamed motherese or parentese.
This infant-directed speech has exaggerated pitch contours and more regular rhythm compared
to adult-directed speech, and often involves exaggerated facial expressions too.
In research on language development, there are studies showing that infants prefer to
listen to speech than to acoustically similar non-speech sounds.
This is often taken as evidence that infants have an inborn predisposition to attend to
speech.
This makes sense, since speech is the primary communication channel for our species.
But what if music and speech are placed head-to-head and tested for their ability to interest infants
and for their ability to influence the emotions of infants?
In a recent study, Corbile, Tree Hub, and Perettes did an experiment that compared infants'
interest in music and speech.
The researchers tested six to nine-month-old infants and used singing and speech in a foreign
language so that they could be sure infant responses were based on sound patterns and
not on the meanings of the words.
Infants heard a Turkish play song sung acapella in a lively infant-directed way.
They also heard the words of the song produced as speech, both as infant-directed speech
and as adult-directed speech.
Infants heard these different versions while sitting on their parent's lap.
The researchers measured how long infants listened to each version before beginning
to fuss.
They found that when infants heard singing, they took almost nine minutes on average to
become fussy.
If they listened to infant or adult-directed speech, they began to fuss after about four
or five minutes.
In this study, the infants just heard sounds.
They didn't see any facial expressions or gestures.
If you want to use interest in a sound as evidence for an inborn predisposition to listen
to that sound, these data are very interesting, because singing seems a lot more interesting
to infants than speech.
In a follow-up study, the researchers found a similar pattern of results when the infants
heard singing and speech in their native language, so the effect doesn't just depend on hearing
a foreign language.
The last study I'll describe by Gazban and Tree Hub also compared infant responses to
singing and speech, but this time it looked at emotional reactions.
Mothers came into the lab and were asked to play with their 10-month-old infants.
They were told that after one minute of play, they should become silent and expressionless
for 15 seconds but look straight at their baby.
This still-face procedure is known to distress infants.
After this short period of no interaction, they were told to resume full interaction
but to either only sing or only speak.
The researchers measured skin conductance from infants, which is a measure of emotional
arousal.
Sure enough, skin conductance began to increase during the still-face procedure, showing that
the babies were getting agitated.
Up to 30 seconds after the still-face procedure ended, while the moms were either speaking
or singing, skin conductance was still increasing in both groups of infants.
But after 30 seconds, it began to decrease steadily in the singing group while still
going up in the speaking group, even though both groups were trying to soothe their infants.
Singing was more effective than speech in calming the infants.
Even though in the speech condition, researchers noticed that the mothers engaged in more playful
touching than the mothers in the singing condition.
In this study, music seemed to touch the emotions of infants more powerfully than physical touch.
As humans, we often think of speech as our defining trait.
All studies are teaching us that there are times when music can be more powerful than
speech, even for infants who have a tiny amount of musical experience compared to adults.
This is just one example of the many surprising things that we're learning about the human
mind by studying the development of music cognition.
