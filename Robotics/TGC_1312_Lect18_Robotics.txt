Believe it or not, the first modern robot was a weapon, the torpedo.
Delivered by its inventor Robert Whitehead to the Austrian military in 1866, the Whitehead
torpedo was a self-propelled underwater bomb that could maintain its depth using a mechanical
pressure sensor.
Even before Whitehead, back in the 19th century, Sir George Kaley, an engineer, had examined
the curved wings of birds and tapered shapes of dolphins and trout and seen in them the
designs animals had in nature in order to minimize mechanical resistance.
While Kaley invented the first glider to carry a human aloft in the 19th century, having
correctly identified the aerodynamic forces of lift, drag, weight and thrust, we also
note today that when we see a torpedo-shaped body in a robot, it is built that way on purpose,
on poipas for streamlining.
Torpedo-shaped bodies are built to go fast and straight, and by the turn of the 20th
century, the torpedo's inventor Whitehead had added a gyroscope to stabilize his mechanical
beast's headings.
Motions guided by sensors are at the heart of autonomous robotics, and the success of
the fully autonomous robot known as a torpedo has led to its widespread and lasting use.
To this day, military robots lead the pack in terms of innovations in robotics.
As both Kaley and Whitehead glimpsed, years ahead of their time, military robots have
to be customized to operate in the air, on and under the sea, and even in space.
That's partly because robots designed for war must operate in a staggering array of
workplaces and carry out a multitude of tasks.
A very brief list of robotic missions in the 21st century military would include the following.
Hazards investigation, route clearing, mine detection, vehicle inspections, explosive
ordnance and bomb disposal, emergency response, carrying supplies and people, patrol, search
and rescue, communications and electronic warfare, and defensive and offensive ops.
But military robots have to be customized for another reason, too.
Now let's recall science fiction author Isaac Asimov's famous Three Laws of Robotics.
They appeared in his 1950 book of short stories, I, Robot.
In one of those stories, run around, Asimov lays out his principles summarized here.
First, robots may not injure humans.
Two, robots must obey humans, except if doing so would harm a human.
And three, robots must protect themselves so long as they obey humans and avoid injuring
them.
But, from Whitehead's torpedo onward, many military robots had been what we would refer
to today as self-guided weapons.
They were designed to kill and destroy.
Women such as torpedoes and aerial bombs appeared designed to violate all of Asimov's laws.
So how do we exercise safety and control over these robots?
In this lecture, we'll examine some of the tensions between semi-autonomous military
robots and our need to oversee their safety and control.
There are trade-offs to consider between the speed of action and the complexity of the
plan, and the identification of friend or foe becomes far more important in military
situations than in any other area of robotics.
One way to maintain control, to make the robot obey you, is to maintain communications with
it and give it limited autonomy to act on its own.
Flying for the U.S. Air Force, the NQ-9 Reaper, an unmanned aerial vehicle produced by General
Atomics, is controlled by trained pilots on the ground.
Force pilots and their human commanders make the decision about when the Reaper can fire
and what the target will be.
While partial autonomy keeps control in the hands of the humans, it presents a security
problem.
Radio communications can be hacked, so one robotic solution to the changing situations
like being hacked is called adjustable autonomy.
For example, if a radio link is cut, many drones automatically fly themselves home.
They monitor communications and then adjust to the change in situation and become fully
autonomous.
A second concern about maintaining safety and control resides in how decisions are made.
In robotics, we have two main kinds of decision making systems, behavior-based control and
model-based control.
Behavior-based controllers are fast, reflexive systems like the escape response on a Roomba
vacuum cleaner.
What triggers a response is a sensor.
When it detects an object or a change in environmental conditions, that information
triggers the program software controller to send instructions to the motors of the wheels
to initiate a series of movements that we call an escape.
If multiple sensors are triggered, the controller allows one reflex to overrule the others,
a decision that makes based on a set of priorities that are programmed in its code by humans.
Model-based systems are relatively slow, deliberative systems that can weigh information
from multiple sensors, calculate high-level inferences, update maps, and make plans for
actions in the short and long term.
And at the heart of this kind of controller is a model of the world that includes the
current state of the world and the robot as part of that world.
As both change, the model has to be updated in order to remain accurate and useful.
With a model-based system, decisions are made based on the current state of the robot and
the desired future states of the robot that are required in order to achieve the explicit
goals programmed into it by the humans.
The tension between these two systems can be characterized as a trade-off between speed
of action and complexity of plan, speed versus complexity.
In military situations, we often need both.
Sometimes a soldier has no choice but to decide reflexively, fast, and that's where
his training comes into play.
An officer, removed from the front lines, can take time to gather information and slowly
create multiple plans before deciding which plan is likely to lead to the best chance
of achieving the desired goals.
Many robots combine fast and slow autonomous control architectures.
Even so, both types of control architectures rely on the quality and accuracy of the information
provided by sensors and by the models of the world.
But nothing is ever certain and the field of probabilistic robotics recognizes that explicitly.
Probabilistic robotics grapples with uncertainty in mathematical terms, building and updating
models of the world, and the robot that creates robust behavioral choices in the face of that
uncertainty.
The autonomous robot makes decisions based on what it knows and what it doesn't know
and its degree of uncertainty about both.
Probabilistic robotics have helped build the very successful and safe autonomous robots
we know as self-driving or driverless cars.
Google driverless cars have logged almost one million miles on the roadways in California
without having been the cause of a single accident, although one driverless car was
hit by a car driven by a human.
Compare that to the average accident rate for human-piloted motor vehicles in the U.S.,
including fender benders, and any incident you might report to your insurance company.
3.7 accidents per one million miles traveled.
Robots may be much safer drivers.
The point here is not only that we can make autonomous robots operate safely in dynamic
real-world situations, but we can, with sufficient investment, make them operate much more safely
than humans working under similar conditions.
Can we do the same in war?
In warfare, the equivalent of the rules of the road are international treaties, such
as the Geneva Conventions.
Protocol 1 is an amendment from 1977 outlawing, among other things, attacks on places of worship.
This rule could be written into the programming of an unmanned aerial vehicle.
Any place of worship is indicated on the robot's model of the world, its map, as an off-limits
area.
Even with this programming and a probabilistic controller that accounts for uncertainty, we
could never ever expect a robot to operate perfectly, and here's why.
The robot could accidentally bomb a place of worship if the information in its world
model was inaccurate.
Imagine that a community creates a new or temporary place for worship during the armed
conflict and it keeps it secret, or the map makers never identified this space correctly
in the first place.
We would also consider it an accident if a missile fired by the robot intended for another
target malfunctioned for reasons that had nothing to do with the programming of the
robot and hit the place of worship.
Also, there's nothing to keep an unauthorized human from reprogramming the unmanned aerial
vehicle.
But there's one thing we wouldn't have to worry about anytime soon, a robot with emergent
self-consciousness, free will, and a sudden desire to kill humans.
No one working in robotics, artificial intelligence, psychology, or neuroscience has ever created
a computer program or a machine that is conscious and self-aware in the way that most humans
think of those experiences.
Could it be done in the future?
Yes.
Given that we're still trying to model and understand the brains, bodies, and behaviors
of much simpler organisms such as worms, however, we're a long ways off from creating robots
with human-style consciousness.
That remains the stuff of science fiction.
The science fact is that while we can build robots with behavioral autonomy, their autonomy
is not of the same type that we humans possess.
And that difference in how robots and humans work is a great thing, practically speaking.
That's why robots are better drivers than humans.
They don't get tired, or distracted, or emotional.
And that's why, if programmed correctly, robots can be better soldiers.
But we have a long way to go.
One area in which robots are not yet capable of being better soldiers than humans is in
the identification of friend or foe in non-traditional battle situations.
Now, to be fair, this is a huge problem for humans.
An occupying army faces this problem continuously.
Is that pedestrian on the streets of the city a friend or a foe?
The general problem is called combat identification.
And the military has been working on a technological solution since World War II with transponders
that were coded for signals on vehicles or individuals that can be used to identify positively
a friend, as can careful tracking from known starting positions.
But confusion exists if a transponder is broken or tracking is interrupted.
In addition, the activation of a transponder can also alert the foe to the presence of
your own soldiers.
So the difficulty of automating combat identification and general concerns about maintaining safety
and control are two of the reasons that the most widely deployed military robot, the Predator
unmanned aerial vehicle and its descendants, is operated by a human pilot and given only
partial autonomy.
The original Predator unmanned aerial vehicle was of modest dimensions, sporting a fuselage
length of 27 feet and a wingspan of 48 feet.
It's an old-fashioned propeller-driven plane.
The Predator was first flown in 1994 and entered production in 1997.
The Predator and its weaponized descendants, the Reaper and the Avenger, have served the
U.S. Air Force, U.S. Navy, U.S. Government and a host of other countries.
Predators are technically considered to be part of an unmanned aerial system because
they are remotely operated with humans in the control loop.
The robot does all of the autopilot work, navigation, flight control.
The humans exercise high-level control of goals and decision-making.
Here you can see two members of the U.S. Air Force closing the control loop in a Predator
unmanned aerial system.
The year is 2007.
The place are racked.
The Predator has just taken off and they are performing a series of in-flight equipment
checks.
Captain Cole on the left is the pilot.
Airman Oilo on the right is the operator of the Predator sensors.
Their job is to work with the Predator while it's within a 25-mile radius of the base so
they can recall it if they detect any problems.
If the Predator checks out, then they'll do something that at first blush seems crazy.
If it checks out, they'll hand over the control to a different set of Air Force operators
who are sitting in Nevada.
So two things make this handoff possible.
First, communications to and from the Predator are handled indirectly via satellite.
Unlike regular radio control operations, control via satellite allows communications over the
horizon out of the line of sight.
Second, navigation anywhere in the air is made possible by the global positioning system,
which we know as GPS.
GPS was created by the U.S. military for aerial, water surface and ground vehicles, both manned
and unmanned.
In robotics, navigation is one of the most fundamental problems that any mobile robot
has to solve.
You have to know where you are and in order to get where you want to go.
GPS works as a system of navigational beacons that can be used to calculate your position.
The current GPS system is a network of 29 Earth-orbiting satellites.
The robot needs the ranges and locations of four of those satellites to calculate its
position using a process called trilateration.
Trilateration involves the simple geometry of overlapping circles in the two-dimensional
case or the slightly more complicated geometry of intersecting spheres in the three-dimensional
case.
What makes accurate navigation particularly important to unmanned military robots like
the Predator is that they can remain on remote station for over 24 hours.
With the unmanned aerial vehicle we're trying to navigate by dead reckoning, errors in estimating
position would increase with time and distance.
Navigation does not present a problem for other types of military robots as long as
they operate in sight, performing jobs in close proximity to the soldier in front of
them.
Backbot, created by and produced by iRobot, is a class of small, mobile, remote-controlled
robots with partial autonomy that have been customized for a variety of different tasks
in close proximity to the operator.
They are built to dispose of bombs, improvised explosives, provide situational awareness to
first responders, aid search and rescue, collect video and air samples, and hazard responses
and detect and localize snipers.
In each of these tasks, Backbot increases the standoff distance between a human soldier
and the potential threat.
As a stand-in for the soldier, Backbot allows operators to have virtual presence and virtual
agency.
Virtual presence is made possible primarily by the cameras and microphone that Backbot
can carry.
It can also be outfitted with other sensors depending on its particular task.
Virtual agency is made possible by the ability of the soldier to control the movements of
Backbot using a video game style controller.
Virtual presence lets the operator perceive the world from the robot's point of view.
Virtual agency lets the operator act in the world as the robot.
One fundamental principle of robotics is that perception and action depend on each other.
Is that object a brick or a case that might contain a bomb?
Move closer, maneuver the arm holding a camera to the side.
These are actions that create new perceptions.
Is the path clear straight ahead for movement?
This is a perception that is necessary for the desired action.
To get Backbot working for you in the field, it has to be deployed first.
Man portable and weighing only 24 pounds without the battery.
Backbot can be carried easily by a human and then deployed in two minutes.
It can be operated up to a range of 1,000 feet via two-way digital radio communications.
So a challenge of battlefield situations is terrestrial locomotion.
Rubble, uneven terrain, water, mud, and tight spaces often bar access to wheeled vehicles.
Tools that fall into cracks or get stuck in loose sediments can permit the chassis to
get hung up and stop the robot dead in its tracks.
To avoid that problem, Backbot uses tank tracks.
Because the chassis of Backbot is relatively small, just 7 inches in height, tracks alone
would not permit it to move upstairs.
Yet it climbs stairs easily thanks to an innovative set of actuators called flippers.
These flippers, which have motorized tracks, are mounted collinearily with the axles of
the front-most wheels.
Operated separately from the chassis's main track actuation system, the 8-inch flippers
can be rotated 360 degrees, adjusted into positions that allow the flipper to serve
as a motorized ramp, or rotated to help lever Backbot over obstacles.
The flippers can also be used to prop up the front of the robot to increase its height
for reaching and inspection.
As a highly maneuverable mobile robot, Backbot can take tools and sensors into dangerous situations.
To carry sensors and end-effectors, Backbot can be installed with a manipulator and armed
with eight independent degrees of freedom.
If you use Backbot to inspect the building for threats, two problems can undermine your
mission.
First, you may lose the ability to navigate effectively because you're disoriented in
the remote frame of reference of the robot.
Second, you may lose communications because of electrical noise, distance, or obstruction.
Both of these problems tend to arise when Backbot is no longer in your site.
Here's where the partial autonomy of Backbot becomes very important.
In any navigational task, being able to hold a heading is paramount, allowing you to make
progress towards a waypoint.
Backbot allows the operator to select a heading, and then Backbot will hold that heading for
you, even as it moves over uneven terrain.
So this allows the operator, who's looking through cameras that experience all the bumps
and jostling, to be certain of the robot's course.
Heading hold is made possible indoors by the use of a compass and an algorithm based on
negative feedback control.
The difference between the selected heading and the actual heading in negative feedback
control is constantly calculated by the software controller.
That difference is called the error, and the goal of the controller is to adjust the
heading to minimize the error, ideally maintaining the desired heading without error.
But what happens when the communication link is lost?
Is Backbot lost too?
Not necessarily.
Backbot first initiates retro traverse, which is a fancy name for retracing your steps
or tracks in this case.
Because the chassis contains a compass, GPS, and an accelerometer, it can keep track of
how far it has gone on any series of headings.
Then it can backtrack until the communications link is re-established.
Once recovered, Backbot can be quickly packed up and transported.
In addition to the 24 pounds of the robot itself, there's the operator control unit,
another 15 pounds that includes the hand controller, radio module antenna, and wall charger.
At a three-link manipulator arm to your kit, that's another 20 pounds for a total of over
60 pounds with the batteries.
While loads of this amount are standard for foot soldiers to bear on their backs, these
loads reduce the speed and increase the fatigue of soldiers.
Particularly challenging is terrain, like mountains or swamps where wheeled transports
can't go.
Here is where a different kind of military robot is being built to literally lighten
the load.
The Legged Squad Support System, LS3, is basically a robotic pack horse.
Built in conjunction with DARPA by Boston Dynamics, which was purchased by Google, LS3 is the
size of a horse.
This four-legged robot can carry 400 pounds and, most importantly, can do so over rough
terrain.
Because the design of LS3 is inspired by animals, we talk about it having a biomorphic body
plan.
If we had LS3 helping us at home to carry firewood, groceries, or dirty dishes, we'd
call it a personal service robot, right?
The concept of a service robot conveys the idea that LS3 works in and around its operators,
works with designated tasks, doesn't bear weapons, and is not intended to operate autonomously.
Now, what sets LS3 apart from personal service robots intended for the home is that it is
large, loud, bearing a gas engine, and extremely robust in the face of challenging outdoor
environments and perturbations like weather and loss of balance.
These are the kinds of features we have in mind when we talk about a robot being hardened
for military use.
LS3 is partially autonomous in addition to being hardened for military use.
It responds to basic voice commands such as engine on and stop.
When commanded to follow tight, LS3 will kick into autonomous mode and follow the human
in front of it.
What's really impressive about LS3 are its actuators for movements, its legs.
LS3 is the descendant of Big Dog, and Big Dog was a breakthrough in legged robots.
Until Big Dog, most legged robots were either upright humanoids with two legs or sprawling
six-legged insectoids.
With four legs, Big Dog is more stable than a humanoid and able to carry heavier loads.
With an upright mammalian posture, Big Dog has better clearance than an insect body form.
The problem with using a dog or any mammal for robot design is that they are unstable.
You can't stand up passively, fall asleep, standing up, and you fall down.
To solve this problem, engineers led by Martin Bueller had to create a robot with dynamic
stability.
You can see how dynamic stability works because Big Dog is almost always moving its legs,
even if it's standing still.
It's sort of ironic, isn't it?
But that's the trick.
If you are always moving, then you are actively keeping your center of mass balanced between
your legs.
Now, dynamic stability is costly in two ways.
First, it takes energy to always be moving your legs.
And second, it takes a lot of sensing to do that balancing act.
Fifty sensors are needed to track the acceleration and tilt of the body, the position and force
on the joints, and the velocity and attitude of the body.
In many ways, Big Dog and LS3 epitomize bio-inspired design in robotics.
Working from the anatomy and physiology of trotting mammals, engineers worked backwards
from nature, identified the key functional principles, and then built machines that worked
in the same way.
The design of a robot's body, then, depends on its task and its workplace in which it
is conducting that task.
For novel tasks, roboticists often look to nature for ideas, as they did with Big Dog.
When we think about inspiration from nature, there are some very surprising robots that
have been built based on those principles.
The streamlining that we see in dolphins and porpoises has affected a whole range of torpedo-shaped
things, not only torpedoes in the water, but, for example, long-range ballistic missiles.
The first long-range ballistic missile was the V-2 rocket.
The V-2 was created by the Germans in World War II and was used against the Allies, most
notably the civilian population in Southeast England.
Just like Whitehead's torpedo, the V-2 is a robot in the sense that it operates on the
principle of sensor-guided movements.
The German engineers built an automated controller for guidance based on a gyroscope and a pendulum,
the Mueller-Pengilis Integrating Accelerometer, or PIGA, thankfully, for short, gyroscopes,
what useful sensors they end up being.
Now recall that we first encountered gyroscopes as the main component of the autopilot created
by Elmer Sperry when he was building that aerial torpedo out of an airplane.
The difference between Sperry's airplane and the V-2 is the required speed and accuracy
of the gyroscopic response.
Because the V-2 was traveling at speeds faster than sound, it needed to react quickly and
accurately.
A PIGA takes advantage of the fact that the torque from a spinning gyroscope can counterbalance
torques that attempt to rotate the gyroscope in a different direction.
In the PIGA, the pendulum would tilt its top arm to the right if the gyroscope weren't
spinning.
In flight, this PIGA is mounted so that neither the axis of the pendulum nor the axis of the
gyroscope are aligned in the direction of motion.
So as the V-2 rocket accelerates forward, the pendulum tips downward, causing the electrical
contacts to close a sensor switch.
That switch turns on the torque motor up on top, which then rotates the whole system until
the gyroscope's procession is able to turn the switch, is able to switch the torque motor
off.
Now, what the PIGA senses is both the magnitude of the acceleration and the speed of the V-2
rocket in that direction.
If you know your acceleration and your speed and how long you are moving at that speed,
your angle of takeoff also, then you can calculate where you're going to land using the simple
physics of thrown balls and other objects called ballistics.
You can go ballistic.
Hence, a ballistic missile throws itself to hit a target.
From a range of 100 miles or more, the V-2 could hit within 600 meters of its target.
That's a measure of its functional accuracy.
After World War II, the U.S. and Soviet Union captured as much of this V-2 technology as
they could.
The V-2 jump-started our own ballistic missile programs and space programs.
The first rocket launched from Cape Canaveral, Florida, took place in 1950.
For its inertial guidance, America's modified V-2 rocket, called a Bumper-8, carried a set
of PIGAs that had improved accuracy.
The basic design of the PIGAs sensors worked so well, in fact, that many of the most famous
rockets carried them, including the Saturn rockets that took humans to the moon.
Because of their accuracy, PIGAs sensors allowed the V-2 rocket to be independent of human
control once the rocket was launched.
Simple mission, simple environment, and independence from humans thanks to an accurate controller.
Early autonomous robotic systems have also been developed for defensive actions, as well
as offensive ones.
And let me introduce you to a very important unmanned system used by the Navy since 1980.
The Phalanx, Mark 15, a close-in weapons system.
The task of Phalanx is more complex than that of a V-2.
It's not just to launch and land an explosive device.
Phalanx has to detect, evaluate, track, and then engage targets that are rapidly moving
and attempting to destroy the Phalanx's ship.
The task of the Phalanx is to be the last line of defense against anti-ship missiles
and high-speed aircraft.
This is a do-or-die situation in which both speed and accuracy are critical.
The environment of Phalanx is likewise much more complex than that of a V-2.
It's not just the air, but objects in the air and objects on the water.
And keep in mind that there are other ships in your own fleet here, too, so the environment
is mixed with friends and foes sometimes intermingled.
Now what about human independence?
In battle stations, the operator normally places the Phalanx in its autonomous mode,
so it is actively using its radar to detect incoming targets.
Because the Phalanx is built as a last line of defense, it has very little time to react.
For example, it detects targets at a range of three nautical miles, can acquire those
targets at 2.3 miles, and engages those targets at one nautical mile.
If the target is a cruise missile, a human operator wouldn't even have time to hit the
on switch.
Because of the need for speed, the Phalanx needs a high degree of autonomy from humans.
Under most battle conditions, the job of the human operator is to hit a hold fire button
if so ordered by the fire control command.
The primary sensor systems of Phalanx are two radars.
It has a wide view detection radar, a narrow scope radar, also, that focuses on the target
once it has been acquired.
Before Phalanx engages a target, it has to answer these questions.
Is the target approaching the ship?
And if the target is not directly approaching the ship, can it maneuver to hit the ship?
If it is approaching the ship, or can maneuver to hit the ship, is the target's velocity
within the range that Phalanx can operate?
These questions are answered by calculating the heading and the course of the target over
time.
Knowing the heading and speed of the ship, too, the computer controller of the Phalanx
can calculate if the two paths will intersect at the same time.
Changes in heading of the target indicate its ability to maneuver.
Finally, changes in position over time indicate the target velocity.
Once Phalanx fires on a target, it uses its focused radar to track its own projectiles
relative to the target.
And using good old negative feedback control, Phalanx then makes adjustments to narrow the
distance between the actual and desired trajectory of its projectiles as it continues to fire.
Phalanx can make these adjustments much more quickly and accurately than a human operator
can.
Even though Phalanx is automatically detecting, tracking and engaging its targets, it's worth
noting that it is not deciding who is friend and who is foe.
All detected targets approaching the ship are treated as foe.
This is one way around the difficult problem of combat identification, trying to categorize
your targets.
Now, admittedly, this is a very dangerous way to program a robot.
You can't have your Phalanx system on automatic when your vessel is getting supplies delivered,
or the crew is coming back from shore leave.
Now, with the success of robots, like the Predator and the Reaper, the defense agencies
of over 50 countries have active military robotics programs.
The race is on to build new kinds of robots for war.
So what's going to happen?
Well, based on what's available in robotics and missing from military robotics, my guess
is that we'll see the following technological advances.
First, I expect to see more operational autonomy, particularly as sensor systems get better at
identifying friends and foes.
Second, autonomous robots will need to be able to adjust rapidly to changing conditions
on the battlefield, so I expect to see machine learning in robots sent out on unmanned missions.
Third, because robots can be made of any size, I expect to see many more robots that are
small and small robots to operate in swarms.
One great advantage of swarms is that they can tolerate heavy losses and still carry
out their mission.
Now, those are my guesses, but what is certain, as Kayleigh's observations about birds and
dolphins envision, and Whitehead's experiments with unmanned torpedoes proved, is that robots
will play an ever greater role in our humans' wage war and defend themselves in the 21st
century.
