In this lecture, we're going to use mathematics to analyze games, one of my favorite subjects.
Let's start with the game of horse racing.
We'll begin with the problem of Harvey the horse.
Harvey the horse likes to run in the rain.
Now that makes Harvey a mutter.
You see horses that like to run in the rain are a mutter.
That's kind of an inside joke because the school that I teach at is Harvey Mudd College.
Just thought I'd get a plug in for my school.
Anyway, if it rains tomorrow, then Harvey has a 60% chance of winning the race.
But if it doesn't rain tomorrow, he has a 20% chance of winning the race.
The way we express that with our notation is we say the probability that he wins given
that it rains is 60% or 0.60 and the probability that he wins if it doesn't rain is 20%.
So here the question then is what's the probability that he wins the race?
Well that answer will depend on the actual probability that it rains, right?
Because if it rains, he's got a better chance than if it doesn't rain.
So let's suppose the probability of rain on the race day is 50%.
Then the probability that he wins is going to be the average of the probability that
he wins when it rains and the probability that he wins when it doesn't rain.
So we take 60% plus 20% take the average of that and we would get 40%.
Now we can only take the average of that because we were assuming that the probability of rain
is 50-50.
Literally what we were doing is we were taking a weighted average of 60% and 20%, but both
of those, both the 60% and the 20% were given the same weight of 0.50 because it was 50-50
whether it rained.
Let me clarify that with another example.
Suppose the probability that it rains is 70% and the probability that it doesn't rain
is 30%.
Then in this case, what are the chances that Harvey wins the race?
So now in this case, there's an even better chance that Harvey wins the race because
it's more likely to rain.
With a 70% chance of rain, Harvey has a better chance of winning the race.
So the probability that he wins, we now take not the average of 60% and 20%, but instead
we take the weighted average of 60% and 20%.
And how are the weights?
Well, the weights are 70% for rain, 30% for no rain.
So we take 60% times 70%, plus 20% times 30%, and that will give Harvey an overall
chance of winning of 48%, which is better than the 40% that he had before.
All right, now suppose we're really sure it's going to rain tomorrow.
Let's say the probability of rain on race day tomorrow is 99%.
And the probability that it doesn't rain is just therefore 1%.
Now what are the chances that Harvey wins the race?
Now they're pretty good.
In fact, they're going to be practically 60%, because if we knew it was going to rain,
then our data was saying that he has a 60% chance of winning.
So what do we do here?
We take a weighted average of 60% and 20%, just like we did before, except now we weight
the 60% with a 99%, we weight the 20% with a 1%, and the weighted average of those numbers
is 0.596.
So Harvey has a 59.6% chance of winning, which agrees with our intuition, right?
We were expecting the answer to be practically 60%.
In general, we can say that the probability that Harvey wins is the probability he wins
given it rains times the probability that it rains, plus the probability that he wins
given it doesn't rain times the probability that it doesn't rain.
This is called the law of total probability.
The law of total probability in general, not just talking about winning and raining, is
if an event B has two possible outcomes, let's say B1 or B2, just like it either rains or
it doesn't rain, okay?
B has two possible outcomes, and the law of total probability says that the probability
that anything happens, let's call that event A.
The probability that A happens is equal to the probability of A given B1 happens times
the probability of B1 happening, plus the probability that A happens given that B2 happens
times the probability that B2 happens.
Similarly, if B has three possible outcomes, let's say B1 or B2 or B3, now again, these
outcomes have to be non-overlapping, mutually exclusive is the word we use for them.
Then the probability that A happens is the probability of A given B1 times the probability
of B1 plus the probability of A given B2 times the probability of B2 plus the probability
of A given B3 times the probability of B3.
It sort of has a little poetic rhythm to it, doesn't it?
In general, the law of total probability says that if the event B has n possible outcomes,
B1 or B2 or B3 all the way up to Bn, then the probability of A occurring is the probability
of A given B1 times the probability of B1 plus the probability of A given B2 times the probability
of B2 all the way up to the probability of A given Bn times the probability of Bn.
Okay, now that we have this powerful formula at our disposal, let's use it to analyze
a game that is otherwise pretty tricky to analyze.
Let's look at the game of craps, okay?
I'll describe the game of craps for those of you who are not familiar with it.
You take two dice and you roll them, okay, and let's call the total of those two dice
the number B.
If the total of those two dice is a 7 or 11, that is if B is 7 or 11, then you win immediately.
If the total is 2 or 3 or 12, then you lose immediately.
If however, the total is a 4, 5, 6, 8, 9 or 10, those are the only other possible outcomes,
then you keep on rolling the dice until you get a sum of B, that original total, or a 7.
If a B shows up first, then you win, and if a 7 shows up first, you lose.
So let's do an example.
All right, so let's say I'm playing my game and I roll a 7, hey, I win, okay, I play roll
a dice, okay, I got a 2, a total of 2, snake eyes, I lose, okay, let's say I roll a total
of 9, okay.
Now I keep on rolling those dice until I see a 9 or a 7, all right, so if my next roll
is an 8, nothing happens, I roll again.
Next roll is a 3, nothing happens, I roll again.
Next roll is a 2, snake eyes, I don't lose, I just keep rolling until I see a 7 or a 9,
okay, hey, I roll an 11, doesn't do anything for me.
Finally I roll a 9, hey, I win, okay, because I saw a 9 before I saw a 7.
And the question of the day is, what is the probability of winning at craps?
Do these rules favor the player or do they favor the casino?
I'll bet you know the answer to that question already, but let's analyze it mathematically
so we know exactly what our chances are and how we're likely to perform if we play this
game over and over again.
Okay, so the law of total probability says the probability that you win, all right, so
winning is my A event, the probability of A is the probability of A given B1 times the
probability of B1, all the way up to the probability of A given BN times the probability
of BN.
So in this case, the B event that I'm looking at is the total of the dice, if I say what's
the chance of winning at craps, you'd say, well it's easier once you know what your original
number is.
If you were to tell me your original number, then I can tell you your probability of winning.
You know, if your original number is a 7, then I know you've won.
If your original number is a 12, I know you've lost.
If your original number is a 9, that's a little harder to figure out, but I think we can, okay?
So what the law of total probability allows you to do is to break this problem up into
lots and lots of much more manageable pieces.
So for instance, that we look at the probability that you win is the probability that you win
given that B is 2 times the probability that B is 2.
Plus, the probability that you win when B is 3, when your initial roll is 3 times the
probability that your initial roll is 3, all the way up to the probability that you
win given that B is 12 times the probability that B is 12.
We're gonna put all of this information in what I call my craps table.
This is not what a craps table looks like at a casino, but this is all the information
we're going to need where we're going to store our calculations, okay?
So let's figure out some of these probabilities, okay?
We'll start with the column of probabilities of seeing any particular number.
What's the probability of rolling a 2?
What's the probability of rolling a 3?
What's the probability of rolling a 4, et cetera, okay?
How would, first of all, how would we figure out that?
Well, these are, when we're rolling two dice, and let's imagine that one of my dice is
green and the other one of my dice is red, okay?
So I've got a green die and I have a red die.
Now how many different possible outcomes are there when you roll a green die and a red
die?
There are six choices for the green die, there are six choices for the red die, and therefore
there are six times six, 36 possibilities for the green-red combination.
Even though we're only interested in the total, the total is some number between 2 and 12,
and those are not equally likely.
The different outcomes of, you know, I'm just as likely to see a green 3 and a red 5 as
I am to see a green 6 and a red 2, or a green 6 and a red 6 for that matter, okay?
So all of those 36 outcomes have the same probability.
Notice by the way that there's one way to roll a double 1, right?
There's one way to roll a total of 2, right?
There are two ways to roll a total of 3.
You could get a green 2 and a red 1, or you could have a green 1 and a red 2, right?
So those are two different outcomes.
So there are two ways of rolling a 3.
You're twice as likely to roll a total of 3 than you are to roll a total of 2.
And in this, in this matrix here, we've listed all of the different possible sums that you
can get.
So for instance, if you want the probability that you roll a 2 as your first roll, and
there's only one way to do it out of those 36 possibilities, out of those 36 equally
likely possibilities, so therefore the probability that B is 2 is 1 out of 36.
The probability that B equals 4, the probability that your initial roll was a 4, is 3 out of
36, because you could have either rolled a 2 and a 2, a 3 and a 1, or a 1 and a 3, right?
A green 3 and a red 1 is different from a green 1 and a red 3, okay?
Finally, how about let's just do one more.
What's the probability of rolling a 7?
Well, let's look at our table.
We count the number of 7s.
We see that there are six of them in the table.
Therefore the probability of rolling a 7 is 6 out of 36, all right?
So we can put that information into our craps table.
We can now fill out the probability of getting a 1, a 2, a total of 2, 3, 4, 5, 6, 7, 8, 9,
10, 11, 12.
In fact, if you look at the numbers, you'll see that they increase 1, 2, 3, 4, 5, 6 out
of 36, and then they go down 5, 4, 3, 2, 1 out of 36.
So they have a nice symmetry, all right?
Now let's go to the column to the left of that one and analyze that.
Let's figure out what's the probability of winning when you know what the first roll
is, once you know what B is.
For instance, what's the probability of winning given that B is 2?
If you roll a snake eye, double ones, then you know you've lost immediately.
Your probability of winning is zero.
That's the probability of winning if you roll a 3.
That's also zero, or a 12.
That's also zero.
On the other hand, more positively, the probability of winning if your initial roll is a 7, well
then hooray, you've won.
That's a probability of 100% or 1.
The probability that you win given that B is 11, that's also 1.
So we can start to fill out more information in our table.
We know the probability of B.
We know the probability of winning given B for certain values of B.
And ultimately, we're going to be multiplying that second column and third column together
to create the fourth column.
So let's start multiplying those now.
And now we need to answer some of the trickier questions, okay?
For instance, what's the probability that you win given that B equals 4, okay?
Suppose the initial roll, the dice, is 4.
I want to figure out the probability of winning when the initial roll is 4.
Now there are two ways of answering that question, okay?
And we'll answer it both ways.
One is, okay, how can you win?
First of all, what has to happen if the initial roll is a 4, what has to then happen for you
to win?
And keep on rolling those dice until you either see another 4 or a 7, okay?
And if a 4 shows up before a 7, then you win.
If a 7 shows up before a 4, then you lose.
First of all, are you more likely to win or lose in this situation?
How many ways can you roll a 4?
Well, from our matrix, we see that there are three ways out of 36 to roll a 4.
How many ways can you roll a 7?
There are six ways out of 36 to roll a 7, okay?
So those are the two pieces of information that we're going to use.
So the chance of winning on the next roll after you've rolled that first 4, the chance
of winning immediately after that would be 3 out of 36.
But what are the chances that you win two rolls from then?
That means you didn't roll a 4 or a 7 on the first roll.
That has probability 27 out of 36.
Then you do roll a 4 on the next roll.
That has probability 3 out of 36.
Multiply those.
You've got 27 out of 36 times 3 out of 36.
Or you could win on the third roll.
That is no 7 or 4, no 7 or 4, followed by a 4.
That has probability 27 36 squared times 3 out of 36.
And so on and so on, you probably win on the third roll, the fourth roll, the fifth roll.
This is just an infinite series.
And we know how to sum this infinite series.
It's a geometric series.
Once you factor out the 3 out of 36, you have 1 plus 27 over 36 plus 27 over 36 squared.
It follows the series 1 plus x plus x squared plus x cubed.
We know that equals 1 over 1 minus x.
When you do the algebra and the dust settles, you get 1 third as your probability of rolling
a 4 before rolling a 7.
That's the long way to show that the probability of rolling a 4 before you roll a 7 is equal
to 1 third.
But I should tell you there's another way of answering that question that's a little
bit more intuitive.
Okay, and so I'll take a look at our table again.
How many ways could we roll a 4?
There are three ways that we can roll a 4.
How many ways can we roll a 7?
There are six ways that you can roll a 7.
So if there are three ways of rolling a 4 and six ways of rolling a 7, then there are
twice as many ways to roll a 7 as there is to roll a 4.
Therefore, it would make sense, by all that is sensible, you should be twice as likely
to roll a 7 before you roll a 4.
I mean, after all, if you look at that table, the only numbers that are relevant to your
winning are those nine numbers, the three 4s over there and the six 7s over there.
So you're going to randomly pick one of those.
One of those is going to be the first number that shows up as you do your dice rolling,
and three of them allow you to win, and six of them make you lose, and that's why the
probability that you win given B equals 4 is 3 ninths, which agrees with our previous
calculation.
Let's use this easier method to answer the next question.
What's the probability that you win given that B is equal to 5?
If your initial roll is a 5, then we see that there are four ways of rolling a 5 in our
table.
There are six ways of rolling a 7.
So what's the probability that the next number you see is a 5 before you see a 7?
Well, of those 10 numbers, four of them are good, six of them are bad, so it's a 4 out
of 10 chance.
By the way, what about the probability that you win given that your initial roll was a
6?
Well, now they've got a better chance of winning, because now there are five ways to win.
There are six ways to lose, so of the 11 total number of ways of getting this game finished,
five of them win, six of them lose, so your chance of winning is 5 over 11.
And so on.
The probability that you win given that B is 6 is the same as the probability that
you win given that B is equal to 8, because there are just as many ways to roll an 8 as
there are ways to roll a 6.
So that also has a probability of 5-11.
So using all this information, we can now fill out our craps table completely.
We now know the probability of winning for every possible initial roll of dice.
And we know the probability of getting each particular roll of the dice.
So the law of total probability says we should multiply column 2 and column 3 together.
When you do, the product goes in column 4.
That then gives you your total.
To get the total probability of winning, you just total up all of those products.
When you do, you get the fraction exactly 244 divided by 495.
That's about 0.492929 repeated.
We'll call that 49.3%.
49.3%.
Gosh, that almost sounds fair, doesn't it?
Your chance of winning is just slightly less than 50%.
So what that tells you is if you go to a craps table, then you have a 49.3% chance
of winning and a 50.7% chance of losing.
Now by the way, some of you out there probably have more experience playing the game of craps
than even I do.
I tend to stay away from the game because I don't like playing games where I've got
a 49.3% chance of winning.
And they say, wait, wait, aren't you allowed to bet against the shooter, can't you bet
against the person who's rolling the dice?
And if that's the case, why wouldn't you be a winner by betting against the shooter?
Well, if you know the rules of craps, when you bet against the shooter, every time the
shooter loses, you win with one exception.
If the shooter's initial roll was a double six, then rather than the shooter loses,
but you don't win, you don't lose, it's merely a push.
You could think of it as when that one out of 36 event happens of him rolling a double
six, then you flip a coin and heads you in, tails you lose.
So that adds to your losing probability by one over 36 times a half.
That's one in 72, but you know what one in 72 is?
That's 0.014.
That makes up for the difference in the 49.3% chance of losing and the 50.7% chance of winning.
So even when you bet against the shooter, your odds are practically the same either
way.
Okay, so putting these numbers together, we have that the expected value when you play
the game of craps is with 49.3% chance, you win, you win a dollar, you get positive one.
On the other hand, 50.7% of the time, you lose a dollar.
So your expected value is one times 0.493 plus negative one times 0.507, which is equal
to negative 0.014.
In other words, if you're betting a dollar, then your expected value is negative 1.4 cents.
On average, you lose 1.4 cents for every dollar that you bet.
You may ask how large is this edge?
That doesn't seem like much, right?
You could probably get a lot of entertainment for your dollar, but if you play this game
long enough, you are going to go broke.
Let me illustrate that.
We have that the expected value is negative 1.4 cents.
I'll tell you also that the variance of a single bet, remember the variance is E of
x squared minus E of x squared.
Well in this case, x squared is always 1 because you're either squaring the number positive
1 or you're squaring the number negative 1.
So E of x squared is 1 minus E of x squared, that negative 0.014 squared.
That's practically nothing.
So the variance of a single bet is one dollar.
If you make, let's say, 100 bets, if on average you lose 1.4 cents for every bet, then after
100 bets, you're going to be down about a dollar 40.
That's your expected profit, is negative 1 dollar and 40 cents.
The variance of the sum is equal to the sum of the variances, so the variance of after
100 bets is going to be 100, but the standard deviation, the quantity we most care about
is the square root of 100 is going to be 10 dollars.
So your expected loss is a dollar 40, but the standard deviation is 10 dollars.
So that gives, there's a reason, you're probably going to lose, but there's a reasonable chance
that you'll still be on the positive side after 100 bets.
After 10,000 bets, let's say you play this game every day, and maybe in a month or so
you've made 10,000 bets, and now you're expected to be down 10,000 times 1.4 cents, which is
140 dollars.
And the standard deviation, it grows with the square root of the number of bets.
So the standard deviation is going to be about 100 dollars.
Again, you're very probably going to be a loser here.
You have less than a 20 percent chance of being positive after 10,000 bets, maybe more
like 10 percent chance of being positive after 10,000 bets.
After a million bets, you have no hope.
You will be down 14,000 dollars with a standard deviation of 1,000.
What that means is, remember what we learned from probability, that you're going to be
within two standard deviations of your expected loss.
So you're going to be somewhere between down 16,000 and $12,000, virtually guaranteed, 95
percent chance.
99 percent chance you'll be within three standard deviations of that, okay?
You'll be somewhere between 11,000 and $17,000 down, virtually guaranteed.
Another game, an easier game to look at, is the game of roulette.
Let me just say a few words about roulette.
In American roulette, you've got 18 red numbers, 18 black numbers, and two green numbers,
the zero and the double zero.
If you bet on red, you're going to win a dollar with probability 18 over 38.
You're going to lose a dollar when you don't win, with probability 20 over 38.
So your expected loss here is 18 over 38 times 1, plus 20 over 38 times negative 1.
Your expected value is going to be negative 2 over 38.
You're going to be down this time about five and a quarter cents for every bet that you
do.
Incidentally, every bet on the roulette table, even the ones that are offering odds, are set
up in such a way that your expected loss on each bet is five and a quarter cents.
With roulette, the picture is much more dismal.
After 100 bets, you're going to be down about $5.26 with a standard deviation of $10.
You might be positive here, but I wouldn't bet on it.
With 10,000 bets, remember when we were playing craps, you had still some but a chance, 10-20%
chance that you were going to be positive, but here you're down $526 with a standard
deviation of $100.
If you're betting red each time, a $1 bet each time, your standard deviation is going
to be $100.
You're not going to be more than five standard deviations away from the mean.
And if you bet a million bets, well, you're really being silly.
Another way to describe your hopeless situation is something called the gambler's ruin problem.
Let's say with each bet, you win a dollar with probability P. And with each bet, you
lose a dollar with probability 1 minus P, which I'll call Q. Suppose you begin with
D dollars, and your goal is to reach N dollars.
Let's say D is 60 dollars, you've got 60 dollars in your pocket, and you want to turn
that into $100 because you need $100 or nothing.
You want to buy a present.
It's going to cost you $100, and unless you make it to 100, you may as well be broke.
Then the gambler's ruin theorem has a beautiful formula for figuring out your chance of reaching
N dollars without going broke.
It's this.
It's 1 minus Q over P to the D divided by 1 minus Q over P to the N, as long as Q over
P is not equal to 1.
When Q over P equals 1, which happens when P is a half, then the answer is D over N. And
let's see what the implications of that are for the games that we've looked at.
So let's say you walk into the casino with $60, you want to turn it into $100.
If you're playing a fair game, what are the chances that you go from $60 to $100 before
reaching zero dollars?
Turns out it's what you'd expect it to be.
It's 60%.
If the game is fair, then if you start 60% of the way towards your goal, you're going
to get to your goal with a probability of 60%.
In a game like Craps, where your probability is 49.3%, just that tiny little change.
It seems almost fair, but your chance of reaching your goal now is like 28%.
You go way down from 60% to 28%.
If we cut off that fraction so we make it a 49% chance, instead of 49.3%, now your chance
of reaching your goal is 19%.
And if you play a game like Roulette, where your chances of winning are 47.3% on any given
goal, on any given play of the game, now you only have a 1.3% chance of reaching your
goal without going broke.
On the other hand, if you know a little bit of gambling theory and you can play a game
to an advantage, like some people I know who can play Blackjack this way, with a 51% chance,
you can go from $60 to $100 with a probability of 93%.
Now I want to say, I'm not advocating that you all go out there and start gambling.
I am saying is that if you are going to gamble, you may as well be smart about it.
