Lecture 14 Probability, Expected Value and Uncertainty
Our lives as household and business decision makers are filled with situations that require
us to make decisions without knowing for sure the consequences of our actions.
For example, should a restaurant owner open the restaurant for lunch?
What sort of collision insurance should an auto owner buy?
Is it better to invest, financially invest, retirement funds in stocks, bonds,
or money market mutual fund shares?
Should an apartment renter purchase insurance to protect her furnishings?
Should we allow our children to drive as soon as the law says they can?
In each of these cases, decision making would be easy if we could see the future
and know how the relevant uncertainties resolve themselves.
If we could know how many diners would choose our restaurant at lunchtime,
we would know whether it made sense to open them.
If we knew in advance whether or not we would have an auto accident,
who would be at fault, and how expensive the auto repairs would be,
we would know exactly the right kind of collision insurance to buy.
If we knew in advance the price of stocks and bonds on the day we wish to convert our retirement
funds to annuities, and if we knew the consumer price index on that day,
we would know whether stocks, bonds, or something else was the best strategy for our retirement saving.
If we knew in advance whether we would experience a fire or a burglary,
we would know whether or not to buy renters insurance.
And if we knew whether our children would be involved in an accident
and whether or not they would drive responsibly, we would know whether or not to let them drive early.
Of course, we know none of these things, but still in each and every case we make a decision.
Keep in mind that we make a decision either actively or passively.
Ignoring the decision to purchase renters insurance is a decision.
A decision not to buy the insurance.
Also, and this is very important, please remember that it never, never makes sense to judge the
wisdom of a decision that involves uncertainty after the uncertainty is resolved.
For an auto owner to say after five years of accident-free driving that buying collision
insurance was a mistake is illogical. It's just downright silly.
One can only assess the wisdom of a choice before the fact. That is, before one knows what is going to happen.
In this lecture, we will begin an investigation of decision making in the face of uncertainty.
We're going to meet concepts of probability and expected value, and we will come to understand
how they can be used to guide decision making when outcomes are uncertain.
At the beginning of the lecture, we'll stick with simple examples of uncertainty that allow us to easily
introduce the concepts of probability and expected value. But as the lecture proceeds,
we will consider far more realistic examples. The concepts we encounter in this lecture
are important for several reasons. First, they help us think through many kinds of decisions
that we face in our lives. Second, they help us better understand the importance of financial
markets in our society. Third, they provide a background for investigating financial institutions
which, after all, routinely make decisions in the face of uncertainty when they decide whether
to lend funds or, for example, to underwrite an initial public offering of stock. We can better
understand several concepts used to introduce decision making in the face of uncertainty
with the help of a random outcome generator. Well, the role of a simple, fair die.
We all know what a die is. It's a cube with six sides, each of which is embossed with one number
between one and six. If the die is fair, it is manufactured in a way that makes each side of
the die equally likely to come out on top when the die is tossed onto a horizontal surface.
In some parlor and casino games, the die or dice, if there's more than one,
are placed in a cup and the cup is spilled onto the playing surface in order to ensure that the
role of the die or dice is fair. To keep things simple, we will begin by considering random events
with only six outcomes, the numbers one through six. If the die is fair,
then the probability of each outcome is one sixth.
Now, let's consider a decision involving uncertainty created by the role of this fair die.
Suppose you have the opportunity to play the game depicted in the following table.
If the role of the die comes up one, you'll lose five dollars. If the role of the die comes up two,
you'll lose only one dollar. If the role of the die comes up three, or if it comes up four,
you'll lose nothing. Aha, here comes the good news. If the role of the die comes up five,
you will win one dollar. And if the role of the die comes up six, you're a big winner. You will win
five dollars. Should you play the game? Some of you may think that it is immoral to gamble and
make the decision on those grounds. But keep in mind that the game I present is only a metaphor,
a metaphor for the uncertainty we face in life and the decisions that we must make before the
uncertainty is resolved. Before we answer the question, it is useful to introduce a statistical
tool and use that tool to characterize the game. The expected value of the game is the probability
weighted average of the game's payouts. So what is this expected value? Well, we're going to multiply
the five dollar loss by one sixth and add it to the one dollar loss
multiplied by one sixth. And add it to the zero loss multiplied by one third because two of the
six sides of the die imply no loss at all. And then we're going to add that total to one dollar
multiplied by one sixth. And finally, we're going to add in five dollars multiplied by one sixth.
So what have we done here? We've taken each of the possible prizes and losses associated with each
of the faces of the die. And we've multiplied each of those possibilities by its probability of one
sixth multiplied and added them all together. And what do we get when we do that? We get that the
expected value of the game is zero. Now please, keep in mind that the probability weighted average
is different than a simple average. In fact, the example is good for pointing that out. The zero
outcome got a weight of one third because that outcome happened with two faces of the die and is
thus twice as likely. So we simply would not get the right answer if we just average the various
prizes. Now, when the expected payout of a game is zero, the game is said to be a fair game.
Please be alert to the fact that I'm using the word fair in a second way now,
where we describe the game rather than the die. There can be fair games
and there can be fair die. And not every game involving a fair die is a fair game.
If the expected value were positive, we would call the game better than fair or a player advantage
game. If the expected value were negative, we would call the game a worse than fair game or,
in the common parlance, a house advantage game. The expected value of the game may be interpreted
as the average prize you could receive if you played the game many, many times. Well, should we play
the game? Whether or not we play, whether or not we decide to play, it should be clear to us
that we should not expect to make a profit by playing because the expected value is zero.
But it might be rational to play the game if you found playing it enjoyable. Indeed,
many friendly wages are undertaken by friends every day. For example, two friends might lunch
together every week and agree to flip a coin at the end of the meal to decide who will pay.
Over time, if the coin is fair, each friend can expect to pay the same amount and the same number of
times. Now, let's consider a more complicated decision. We will again use the role of a die
as a metaphor for the uncertainty faced by the decision maker. Here's the setup.
Imagine that you are the owner of a toy store and you have to decide in July on the kind and the
quantity of toys to order for the holiday shopping season.
This particular July, the decision is very difficult because there's a great amount of
uncertainty about consumer confidence. One consumer's fear that a recession may come
and unemployment may rise. They often spend less during the holiday season in order to
build up their cash reserves. Our toy shop owner, let's suppose, has two available strategies.
I'm keeping it simple now. Only two strategies. Strategy one is called an aggressive strategy.
On the aggressive strategy, the owner purchases a large quantity of toys, including a good supply
of the newest and most expensive toys. Strategy number two is conservative. On the conservative
strategy, the owner purchases a much smaller inventory of toys and sticks with tried and true
toys rather than the new expensive ones. Note that both strategies entail risk.
If consumer confidence turns out to be low and the owner pursues the aggressive strategy,
the owner will be stuck with inventory that can only be sold at a loss.
If consumer confidence turns out to be higher, however, but the owner pursued the conservative
strategy, the owner will miss the opportunity to make many profitable sales.
The table you are seeing provides the owner's assessment. Imagine your assessment of the costs
and the benefits of each strategy as it varies with consumer confidence. So let's take a look.
We see in this table consumer confidence ranging from six when it's very high down to one when it's
six possibilities. I'm assuming again that each of these outcomes, six, five, four, three, two,
and one is equally likely. So the probability of each outcome is one sixth. Notice that I have
two rows, the implications of the aggressive strategy and the implications of the conservative
strategy. When consumer confidence is high, the aggressive strategy works very well. And indeed,
the numbers that you see in the table are toy store profits in thousands of dollars. So an aggressive
strategy when consumer confidence is at its highest is worth $100,000 in profits all the way on the
other end of the table. An aggressive strategy when consumer confidence is at its lowest is a loss
of $50,000. You get the picture. Similarly, think about the conservative strategy.
Using the conservative strategy when consumer confidence is very high,
gives the shop owner a profit of $20,000. Indeed, half of the outcomes, six, five, and four,
all give the shop owner $20,000. But when consumer confidence is low, the conservative strategy
implies a loss, but a much smaller loss than the aggressive strategy. So you get to see now the
feeling of the difference between the implication of the conservative and aggressive strategy.
The conservative strategy only loses in the worst two states of the world,
the worst two rolls of the die, and when it loses, it loses relatively little. But the
conservative strategy tops out at a $20,000 profit and does not benefit from the high levels of
spending associated with a really good holiday shopping season. The aggressive strategy is
only profitable in half the states of the world. In the worst two states, losses are very, very high.
But in the best three states, the profits are very large relative to the other strategy.
Now, the expected profit of the true two strategy differs. The expected profit of the aggressive
strategy turns out to be $25,000. The expected profit of the conservative strategy is $9,167.
And you can verify that for yourself by applying the expected value formula that we
have seen already, probability weighted averages. What you want to know is what decision the toy
store owner should make. Now, some decision makers believe that the right thing to do is to always
choose the strategy with the higher expected return. In that case, the shop owner yourself would
choose the aggressive strategy. It clearly dominates because its expected value is higher.
But as we shall see by any reasonable measure, the aggressive strategy is riskier.
Okay, it's important to realize that the toy store decision, even though I modeled it with the role
of a die, is not like a game of chance that one could play with your friends or at a casino.
And it's not like that game of chance in two very important respects that we really should
understand. First, and this is quite important, it is generally not possible to play the toy
store game, if I may call it that, multiple times like you can a casino game.
To appreciate the importance of this point, we consider the modification of the first game
presented in the following table. So remember that we were rolling a die and if the outcome was one,
we would lose $5. If the outcome was two, we would lose $1. If the outcomes were three or four,
we would break even, losing nothing, but winning nothing. If the outcome was five, we would win $1.
And if the outcome was six, we would earn, we said $5 before, but now I want to change
that $5 to $6. I have changed only one feature of the game, the payout associated with the six.
It's now $6 rather than $5. The expected payout of the game is now $0.16. If one can play the game
without limit, one should do so because one's wealth will grow without bound.
As the game has played multiple times, the law of large numbers tells us that the average return
becomes a virtually certain return. What does that mean? That means as we play many, many, many, many
times, our average return converges to our expected return. Playing that game thousands of times
virtually guarantees that on average, every time we play, we will get $0.16. That's why I say our
wealth could grow without bounds. By the way, I have just explained the business model of a casino.
Casino games are invariably house games. So from the point of view of the house, they're better than
fair games. From the point of view of players like you and me, they are less than fair games.
For that reason, the number one rule in a casino is keep the players playing.
In contrast, however, our toy store scenario is not one that an entrepreneur can repeat without limit.
An entrepreneur who believed that he or she had a strategy with positive expected profit
might try to replicate the strategy in lots of different markets, with lots of different stores.
But that won't work. In our example, the law of large numbers would not work to the entrepreneur's
advantage because the source of risk variation in consumer confidence would not be determined
by events that were different at different locales of his stores. Consumer confidence
is an economy-wide phenomenon based on the overall prospects for the economy and it'd
be the same for him in every store. So he would bear risk.
Thus, it's simply not obvious that one of the two strategies is better. The aggressive strategy has
a higher expected profit, but as I will now point out, and as we will see in future lectures,
it's also riskier by any reasonable definition of risk.
There is a second very important difference between the toy store decision and the decision
to play a casino game. That difference centers on the source of our information of the relevant
probabilities of events. Remember that for simplicity, I generated the uncertainty of all the games we
have seen so far with a random number generator with well-understood properties, the role of a die.
But no such random number generator exists for generating different levels of consumer confidence
and those define the relevant states of the world for the toy store scenario.
In real-world decisions, decision makers must often define the relative states of the world,
not assume they're one, two, three, four, five, six, like the faces of a die, and they themselves
must estimate the probabilities of each of those relevant states of the world, each of those
relevant possible outcomes. Frequently, this is done by analyzing data on similar past events
with the assumption that the future will be like the past in the sense that the
frequencies of events in the past are good estimates of the probabilities of similar events in the future.
I know that's a lot to understand and I think a new example will help us understand the difference
between decision scenarios where probabilities are estimated and decision scenarios where the
probabilities are known on a priori grounds like the fact that a die is fair. I'm going to show
you one more table. It's a table containing the frequency distribution of annual real returns
on all the stocks traded on the New York Stock Exchange between 1945 and 2007.
And you'll see what I mean. I'll take this slowly.
Real returns are defined as the sum of percentage capital gains and dividends earned on the New
York Stock Exchange market portfolio minus the rate of inflation. Hold on a second. What does that mean?
If you hold all of the stocks in the New York Stock Exchange, if you simply bought a mutual fund that
had every single New York Exchange stock in it, you would receive every year dividends and capital gains.
That would define the percentage return in a nominal sense, but we understand that real
values matter and so from that we would subtract the CPI rate of inflation for that same year.
A positive return would mean that the person holding the whole New York Stock Exchange portfolio
would experience a gain in purchasing power. A negative return would mean that the person
holding the entire portfolio of stocks traded on the New York Stock Exchange would experience
a loss in purchasing power. Now intentionally, I have constructed the table to be similar to the
payout tables we've seen earlier in today's lecture by computing real return sex tiles.
Now what does that mean? That means I ranked the returns and I grouped the lowest six
one sixth together, the next one sixth together, the next one sixth together, and so forth.
For each of these sex tiles, the table reports the average of returns within the sex tiles.
So let's turn to the table. The worst case, the lowest sex tile, and again by definition that's
probability one sixth, had a payout of minus 18% in real terms. That's bad news, losing 18% of your
wealth. The next sex tile was also a loser, but a lesser loser, only minus 2%. The third sex tile
was a winner, happily 7%. The fourth, a bigger winner by construction, 13%. The real good news
comes in outcomes five and six, the top two sex tiles. The fifth sex tile is associated returns
of 19% and the sixth of returns of 28%. That's where we would hope to be, right? We'd love to be in that
last sex tile.
The stock market is characterized by this table is a better than fair game. Do the math. The
average real return between 1945 and 2007 is 8%. But does this mean that an investor should expect
an 8% return in the future? Well, if the future is like the past, that assumption is reasonable.
However, a cautionary note, in 2008, the real return on a portfolio of New York Stock Exchange
stocks was, hold on to your horses, minus 44%. Lower than any other return experienced over
the historical period. That's a source of risk that the table doesn't capture.
Real world decision making is different from the decision making in the casino,
because we may only be able to estimate the probabilities of the various outcomes.
As scholars began to grapple with the question of how a rational decision maker should make a
decision in the face of uncertainty, they came to the conclusion in the 18th century that expected
value was the key. A rule of thumb evolved. If a game or an investment opportunity had a
positive expected return, a rational agent should play rather than pass. If that rational
agent had to choose among games or investments, the agent should choose the one with the largest
expected return. In the next lecture, we will learn why and how this rule of thumb changed.
Thank you.
