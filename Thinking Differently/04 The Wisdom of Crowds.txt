Hi, welcome back. In this lecture, we're going to talk about prediction. We're going to see how diverse ways of thinking contribute to the ability of a collection of people to make accurate predictions and forecasts.
Now, this phenomenon is sometimes called the wisdom of crowds. It occurs when a crowd of people is more accurate than the people in it.
Now, in examining the wisdom of crowds, we're going to see that it depends on two things, talent, that is good predictors, and diversity.
And we're going to see that diversity plays an equal role with talent, so they matter just as much. So talent and diversity matter in equal parts.
I'm going to make this argument in a formal way using some pretty straightforward mathematics.
Now, before we get to that mathematics, I want to talk about cattle. Now, why cattle? Well, I like cattle, and I used to own some.
Nine cattle in fact, not ten, but nine. Now, cattle are large creatures, and you buy them by the pound.
So when I bought my cattle, I paid a price per pound, and then when I sold them a few months later after fattening them up on some Iowa pasture land, I auctioned them off again at a price per pound.
So if you're going to trade in cattle, you've got to be able to estimate their weight. You want to think about what do they weigh?
So it turns out, one of the most famous examples of the wisdom of crowds involves guessing the weight of cattle.
Now, this example is due to Sir Francis Colton. In the story opens Jim Surwicky's wonderful book, The Wisdom of Crowds.
So Surwicky tells us that this great scientist, Francis Colton, had collected some data from the 1906 West of England fat stock and poultry exhibition.
Catch the name, right? 787 people at this exhibition guessed the weight of a steer.
Now, their average guess of that weight was 1197 pounds. The actual weight of the steer? 1198 pounds. It's amazing, right? It's totally amazing.
That's why Surwicky's book is called The Wisdom of Crowds. This is sort of incredible.
But let's not get too excited, because Galton's cattle example, that contest, it's a one-shot case. It's a single example.
So by no means does that imply that in every case a crowd is going to be incredibly accurate like that.
And in fact, crowds often make big mistakes. They can be mad as well.
So just like individuals can make mistakes, so can crowds.
But the weight of the evidence, not just from cattle guessing or jelly bean jar contest and stuff like that,
but from the trenches, from business and policy worlds, is that though Galton's example has this big wow factor,
it has, pardon the pun here, a grain of truth. Groups tend to be more accurate predictors than individuals.
So they are more likely to be wise, at least in predictive context.
Now, this generally accepted fact that crowds have greater accuracy than individuals,
but they can sometimes be horribly wrong, resonates with my own experiences as well.
So for a decade, I've had students in my classes make predictions on everything from my weight that are almost always within a pound.
No, I don't weigh 1197 pounds, but to the number of floors in the tallest building in Rio.
Last year, they were off by fewer than two floors, or even the number of chairs in a coffee shop that was just opening.
They were off by only three. I also had them guess the height of the Saturn V rocket.
They were off by, well, a thousand feet the first time, and the number of pizza places in Ann Arbor.
And there, they were off by a factor of two. They were off by double the amount.
Later on, I taught them how to make better estimates, something that we're going to do in this course.
And they got within just a few percentage points on both of those questions.
They became a wise crowd.
So look, the facts are in here.
Crowds are able to make more accurate predictions most of the time, but sometimes they can be way off.
So what we want to do is we want to make sense of this.
We want to understand when can crowds predict, when are they wise, and when are they not.
And the key to this is going to be that diversity plays a big role.
So that's the point of this lecture, to explain how and why crowds can make accurate predictions
and to show the value of diversity.
So I'm going to present two main results, and they're both mathematical results.
The first is going to show that collective accuracy of a crowd depends in equal measure on the accuracy of its members.
That's talent, and on their diversity.
So more diversity is going to be better.
Now the second result is going to be a corollary of the first.
And that's going to say that a diverse crowd will always be more accurate than its average member.
Not sometimes, but always.
So the crowd is always more accurate than the people in it.
That's sort of cool.
As a way to introduce the formal statistical terminology that I'm going to need to state these mathematical results,
I'm going to present a fairly simple example.
I suppose we have three people, Amy Bell and Carlos,
and they're making predictions regarding the number of new clients that their firm is going to attract in the next year.
We're going to work through this example so we can build some understanding of how the statistics work.
So let's do an example.
Here's our three people, Amy Bell and Carlos.
Each one of them has made a prediction about the number of new clients.
Amy predicts 12, Bell predicts 6, and Carlos predicts 15.
What we want to do is we want to figure out the crowd's prediction.
Well, the crowd's prediction is just going to be an average of these three predictions.
If we sum these up, we get 33, so we're going to get the crowd's prediction is just equal to 11,
which is the average of the three people.
Now let's suppose that the actual number of new clients turns out to be 10.
So I'm setting this up so the crowd is pretty accurate.
It's only off by one, but they're not perfect.
So it's a smart crowd, but not an incredibly wise crowd.
What we want is we want some way of measuring the accuracy of these individuals as well as the accuracy of the crowd.
So how do we do it?
Well, this is a problem statisticians have thought about for a long time.
They typically do it by taking the difference between the actual prediction and the true value and squaring that amount.
And they call the result the squared error.
So in the case of Amy, we take 12 minus 10, which is the true amount,
and square that and get a total of four.
Now why do we square it?
Well, here's the simple reason.
Suppose one person had an error of plus five and another person had an error of minus five.
If we added those up, we'd get zero.
We'd get no error.
Think of it this way.
Suppose I'm shooting arrows and I shoot one high and then one low.
I can't average those and then say bullseye.
What I do is I want the distance from the center.
So what squaring does is gives us the distance.
So let's compute the errors for the other people as well.
Let's look at Bell.
Bell predicts six.
The actual value is 10.
So six minus 10 squared is just going to be 16.
What about Carlos?
Carlos predicted 15.
15 minus 10 is five.
And if we square that, we get 25.
So Amy's off by four, Bell's off by 16, and Carlos is off by 25.
So if we average these things up, we can average the squared errors.
We're going to get 41 plus four, which is 45.
We're going to get an average of 15.
The individual squared error in this case is 15.
What's the crowd squared error?
Well, this is easy.
Remember, the crowd gets 11.
So 11 minus 10 is one and one squared is just one.
So the crowd squared error is one.
So what we get is the crowd is more accurate than the individuals are on average.
And notice the crowd's also more accurate than anybody in the crowd.
Now, that's not always going to be true.
Sometimes someone in the crowd can be more accurate than the crowd,
but the former always will be.
The crowd will be more accurate than the average member in it.
I'm going to come back to that point later,
but what I'm going to focus on for the moment is this idea
that we've got individuals who make mistakes and the crowd who makes mistakes,
and the crowd is in some sense smarter than the individuals in it.
So next, here's what we need to do.
I need some way to think about why the crowd is smart,
what's making the crowd good.
So one thing I figured out is the accuracy of the people, their squared error.
I need some way of measuring the diversity of the crowd.
How different are those people?
Well, here again, we can go to statistics.
They've got a standard approach.
What we do is instead of computing the difference between people and the true value,
we look at the variation in the prediction.
So there is between the predictions and the crowd predictions.
Now, one quick aside, statisticians use this expression
to compute what they call the variance of a data-generating process.
So some process that generates numbers.
So by variance, what they typically mean is how much noise or error is produced by the process.
Here, we're using it to mean diversity.
So let's think about this variance thing for a second.
Suppose I've got a machine that's producing cookies that are supposed to weigh six ounces.
Some are going to weigh a little more, some are going to weigh a little bit less.
How much more or less is the variation?
Now, what causes that variation?
Well, the variation can be caused by vibrations in the machine
or clumping in the dough, all sorts of things.
Now, in our case, we're getting variations in these predictions.
But the cause of the variation is not the shaking in machines or lumping of cookie dough.
It's differences in how people think.
So when we think about this variation in the predictive context,
we're going to call it diversity of predictions, because that's what it is.
It's differences in how people predict.
So remember, in our case, people's average prediction was 11.
So what we can do is we can figure out what in some sense is the diversity of those predictions.
Well, let's, again, just do some simple math.
Amy's prediction was 12, and the crowd's prediction was 11.
So we can say Amy's contribution to diversity is 12 minus 11 squared.
So that's just 1.
Bell's contribution to diversity is 6 minus 11 squared.
So that's 5 squared, which is 25.
And Carlos' contribution to diversity is 15 minus 11 squared, which is 4 squared, which is 16.
So when I add that up, I get 42.
And when I divide that by 3, I get that, on average, people are off by 14.
So I'm going to call this 14 the diversity of the predictions,
because this is how different people are in the predictions that they make.
Now, let's look at these three numbers that we've calculated.
What have we calculated so far?
We've calculated the average individual squared error.
That's 15.
So that's, on average, how far off are people?
We've calculated the diversity of the predictions.
That's 14.
And then we've calculated the crowd squared error.
That's 1.
Can you notice anything?
Look, that's correct.
The crowd squared error equals the average individual squared error
minus the diversity of the predictions.
I'm going to call this the diversity prediction theorem.
Because this happens not only in this example, it's true in every example.
It's a mathematical identity.
It's like the Pythagorean theorem.
Remember?
Take any right triangle, the hypotenuse squared equals the sum of the squares
or the two sides.
This is the same thing.
The diversity prediction theorem is just like that.
It's just like the Pythagorean theorem.
It's always true.
So now this is a really important result, and it's counterintuitive.
Because what it tells us is the crowd's ability depends on equal measure
on ability, that's the average individual error, and on diversity.
So it's so important.
This is so central and also so counterintuitive.
I want to flesh this out in more detail.
So let's do this now in the general case.
So let's suppose we have some general thing that we're trying to figure out.
Some future viber trying to figure out.
Some x that's sitting out here.
And we have people make predictions.
Now this could be anything.
This could be the unemployment rate, the number of jelly beans in a jar,
even the weight of a steer.
So we've got this thing x that we're trying to figure out.
Now we've got a whole bunch of people.
Now instead of three, we're going to say we have n people who make predictions.
And I can label these people from verse 1 to 2 to 3 to 4 up to n.
And I can just index them by these x sub 1, x sub 2 to x sub n.
These are the people's predictions.
So what's the crowd's prediction?
Well, that's easy.
That's just the sum of all the individual predictions.
So x1 plus x2 plus x3 plus xn divided by the number of people.
So I can just write that just like this.
And this is what I get.
This is the crowd's prediction.
Now, I want to sort of make this a little bit fancier,
because this is a whole bunch of writing.
And I'm going to introduce some new notation.
This is called a summation sign.
So I can write this as the crowd's prediction is the sum from i equals 1 to n of the xi.
So this sigma term here in the center is just a way of saying I'm summing up all those numbers.
And that's going to make it easier for us to write down more complicated sets of expressions.
So it looks a little fancy, but the thing is,
it's going to help us make sense of some of the mathematics we're going to do.
So what we've got then is you've got this particular expression,
and we want to write down sort of how things work.
So let's unpack things a little bit.
Here's the crowd's error.
The crowd's error is just their prediction minus x squared.
And remember, x is the truth.
So this is how far off the crowd is.
And now I want to write down what is the average error of the individuals.
Well, the average error of the individuals is just each person's prediction.
That's xi minus the truth squared.
So remember with Amy, I had her prediction, which was 12, and the truth was 10.
So I just took 12 minus 10 and squared it.
Here what I do is I just take xi minus x, which is the truth and squared.
And I sum that up.
There's that summation sign again over all the people.
And then I just divide this one over n by the number of people.
So this is going to tell me the average squared error.
Now all I'm left is with figuring out somebody to write diversity.
So how do I write diversity?
Well, what I do here is I just ask, what is people's distance xi from the crowd's prediction?
So I take each xi and subtract off c, which is the crowd's prediction.
And again, I have this fancy summation sign.
So I sum over all the people.
And then again, I divide by one over n.
So what I've got now is I've got an expression for the crowd error, the average error, and the diversity.
And again, we see these summation signs everywhere.
And we can go forward.
Well, here's the cool thing.
Now I can write the following expression.
I can write that the crowd error equals the average error minus the diversity.
This is just always true.
So let me show this with mathematics.
This is what it looks like.
It looks a little bit frightening, right?
So the crowd error, that's the c minus x squared, equals the average error.
So this is just averaging up each of the individual's errors.
Minus the diversity of the predictions.
So what I've got is this formal mathematical expression that says crowd error equals average error minus diversity.
Let's think for a minute how unintuitive this is.
Because I said, what's going to make a crowd smart?
You might have said, well, it's having smart people.
And that's captured here in average error.
But it's also diversity.
We're going to see the diversity matters.
And the interesting thing here is diversity matters just as much as ability.
It matters just as much as average error.
So what we want to do here at this moment is I want to take some time and walk through this result.
Here's why.
This is going to be by far the most math we do in this course.
And it's going to look a little bit scary.
So let me just put that right out there.
But we're going to do this math for two really important reasons.
First is this.
A primary reason for this course, at least for me to teach this course,
is to speak math to metaphor.
When people talk about diversity, we often tell stories and speak in metaphors.
I want to nail down the logic.
I want to convince you why diversity is so important.
So I'm going to show you how it's done.
So a lot of the later results I show, I'm just going to ask you to take them on faith.
We're not going to do the math.
But for at least one case, I think it's important to do one.
Second, another reason is this, is that by working through the proof, by watching me do it,
you're going to see the logic of why it works.
So you're going to learn something from the exercise in terms of how we go about proving results like this.
So let's go at it.
This is going to be fun, but a little bit tricky.
All right, so here we go.
So here's what I've got.
Here's my expression.
I've got the crowds error equals average error minus diversity.
So the first thing I'm going to do is I'm going to multiply both sides, everything by n.
So I'm making this crowds error here and I multiply it by n.
And it allows me to get rid of the 1 over n that I had in front of the average error and the diversity.
The next thing I do is I just expand terms.
Well, this is pretty easy, right?
So if I have c minus x squared, that's going to be c squared minus 2cx plus x squared.
And the same's true for little xi minus x squared.
What I'm going to get is I'm going to get xi squared minus 2 little xi times big x plus x squared.
But notice again, I'm summing that over all the people.
And then I do the same thing for the diversity term.
So all these things sort of get multiplied out.
Well, then what I can do after I sort of multiply all these things out is I can think,
well, is there some way to simplify it?
Well, here's sort of an interesting trick.
Notice I've got this summation of minus 2xi's here.
Well, what is that?
If I'm summing up all the xi's, that's just the crowd's prediction.
So what's great is I can get rid of these 2xi think terms I've got and replace them with c's.
When I replace them with c's, then I end up with this sort of somewhat complicated equation that says
here's n times the crowd error plus these two other terms.
But I notice that, you know, look, I've got a minus 2c squared and a plus c squared
and that will just turn into 1c squared.
And if I add that to what I have over here, I see that now I've got an identity.
The two sides of the equation are equal.
So what this is saying is, is that these two expressions, even though they look very different,
so even though this expression looks quite different from this expression,
if we expand this expression all the way out, cancel some things out,
we see that in fact they're the exact same thing.
So what we've got, in this case then, is what we call an identity in mathematics.
The crowd error is literally the exact same thing as the average individual error minus the diversity.
It's just a theorem. It's always true.
Okay, enough math.
Don't worry if you didn't follow it.
You can go back and watch the proof again if you want.
The point of doing this exercise was to show you there's no great mystery to the proof.
It's really just a matter of multiplying things out in canceling terms.
But what's most important, now that you've seen the mathematics,
is to recognize that this is always true, always.
And that the wisdom of crowds, by that I mean the ability of crowds to make accurate collective predictions,
depends on equal measure on the crowd's ability, their average individual squared error,
and on the diversity of their predictions.
Now let me give you a really interesting corollary here.
And that's this.
The crowd error has to be less than the average individual error.
So let's look at this, right?
What did I have before? I had the crowd error equals average error minus diversity, right?
Well, if it equals average error minus diversity, if diversity is positive at all,
the crowd error has to be less than the average error.
So that means if there's any diversity in the room in any way,
then the crowd is going to be better than the average person in it,
because it's just a mathematical fact, okay?
So that's an interesting thing that follows from what we've found.
Now I'm going to call this, the formal way I'm going to call this,
is the crowd beats the average law.
And it's really easy to see why it's true.
Now before I move on, a quick corollary, and this is our second main result.
If the crowd squared error equals the average individual error
minus the diversity of the predictions, then the following also has to be true.
That if the crowd has any diversity at all, any diversity in its predictions,
then the crowd's error is strictly less than the average squared error of the people in the crowd.
So in other words, the crowd is better than the average person in it.
Now I call this, the crowd beats the average law.
And it's really easy to see why it's true, right?
The crowd's error is the average individual error minus the diversity.
So if the crowd's got positive diversity at all,
then the crowd's error has to be smaller than the average individual error.
That's pretty cool. Crowds really are better than the people in them.
Well, at least on average.
Now as the diversity prediction theorem is just a mathematical fact,
it's got to be true in every single case.
And it is. So it's got to be true in Galton's data.
So let's check.
No, I'm not worried about there's anything.
It's just fun to see the logic in action.
So if we take his data, we get that the crowd's squared error equals 0.6.
The average individual squared error in that case was 29.56.
Now wait a minute.
You say, whoa, that's huge.
The catalog would love 150 pounds.
How could the error be 29.56?
Remember this is squared error.
So if we take the square root of that number, we get 54.4, 55 pounds.
So that's not bad.
Cattle away about five times the size of people.
We can guess the weight of a person within about 10 pounds.
So 50 pounds isn't that far off.
So wait a minute.
If the crowd was off by 0.6 and people were off by 29.55,
then there must have been a lot of diversity.
And in fact, there was.
The diversity was 29.54.4.
So that's how crowd error can equal average error minus the diversity.
Now, if you want a wise crowd, this suggests we have two options.
We could find brilliant people who all know the answer.
So then the individual error would be 0.
Crowd error would be 0.
Diversity would be 0.
Or we can find a bunch of fairly smart people who have moderate errors
who happen to be diverse who also get moderate diversity.
So if you take an example from one of these books on wise crowds,
such as Sirwicky's books, you look at Jelly Bean guessing contest
or any one of the things that you might see on Cattleway guessing,
predicting the NFL draft, anything like that,
you're going to see that it's almost always the case that it looks like
Galton's data where you see a wise crowd
because you've got moderately accurate people who happen to be diverse.
So let's see why this works.
Here's another way to think of it, right?
We basically have this equation.
Crowd error equals average error minus diversity.
So how do we get small crowd error?
Well, let's think of it this way.
It always looks like small equals big minus big.
This is what we see in these books.
Well, why is that the case?
Well, let's think about it.
How does it make a book called The Wisdom of Crowds?
The only way it can make a book, The Wisdom of Crowds,
is if the crowd error is small, if people don't make mistakes.
So in order for it to make The Wisdom of Crowds,
you need a small crowd error.
Now, what also has to be true for it to make The Wisdom of Crowds?
Well, it has to be the case that the average error is pretty big
because if the average error wasn't big,
that would mean that everybody can get it right and it wouldn't be surprising
because we just basically say, this was an easy question.
So if you make a book like The Wisdom of Crowds,
you have to have a small crowd error.
You have to have a big average error.
So guess what?
It has to be the case that diversity is also big.
So the only examples that make the books about wise crowds look like this.
You've got high average individual error and high diversity.
So therefore, you've got The Wisdom of Crowds explained by diversity in most cases.
Okay, so let's think about this intuition for a second.
We've done a lot of math and we can see how each line follows from the next,
but that doesn't mean we necessarily intuitively understand
why this diversity prediction theorem works.
So what I want to do is I want to go back
and look at another example of why diversity matters so much.
Okay, so let's do it.
Let's suppose I've got 100 people guessing the weight of a steer.
And again, let's write down our theorem here.
And let's suppose that each person is off by exactly 20 pounds.
So if each person is off by exactly 20 pounds,
then what we're going to get is an average error of 400.
Now let's first suppose there's no predictive diversity,
so everybody guesses 20 pounds too high.
So that means the diversity is going to be zero,
which means the crowd error is going to be 400 as well.
So what we get is that we don't get a wise crowd.
The crowd is no better than the average people in it
because the diversity is effectively zero.
Well, let's suppose instead that people are off by an average 20,
but now we've got a lot of diversity.
So half the people are 22 high and half the people are 22 low.
Well, that's going to mean that the diversity is also 400.
So if the diversity is 400 and the average individual error is 400,
what we're going to get is we're going to get a crowd error of zero.
So we get zero equals 400 minus 400.
Here's what's interesting.
If we compare case one to case two,
we see that the people didn't get any smarter,
but the crowd got smarter.
How did the crowd get smarter?
It got smarter because it got more diverse.
So what we see in this simple example
is that collective wisdom comes from diversity.
Okay, now we've got the core intuition.
So let's drive it home.
Suppose you have a crowd that's not wise.
So now you've got a big crowd error.
In order to have a big crowd error,
that means you've got to have big average individual error.
People can't be getting it right.
It also means diversity has to be relatively small
because otherwise that diversity would cancel out the errors.
So remember at the beginning of the lecture,
I said sometimes crowds get things right,
sometimes they get things wrong, sometimes crowds are mad.
Well, for a crowd to be mad, what has to be true
is we have to have big equals big minus small
because if the diversity weren't small relative to the error,
the crowd couldn't possibly be mad.
So wise crowds come from diversity,
mad crowds come from a lack of diversity,
and a lack of talent.
So where does the diversity come from, right?
We've done all this mathematics.
We've seen the intuition for why diversity improves
the ability of a crowd to make predictions.
But we haven't explored at all
what causes this diversity of predictions.
Well, that's a really important question.
It's one that we're going to meet up with again
in four or five lectures.
But to get us started on this question,
I want to go back to some of the examples we've talked about
in terms of the crowds making predictions.
So the first was, remember I said I had my students
predict the height of the tallest building in Rio.
The tallest building in Rio was only 60 stories high.
Now the individual guesses for my students
went from around 30 to up to 90 stories.
So I went back to my students and I said,
okay, well how did you come up with these predictions?
And the students who predicted 90 floors,
they basically said, look, Rio is the second largest city in Brazil,
it's one of the largest cities in all of the Americas,
and it's beautiful, there's a lot of money there,
so it must be the case that they have, you know,
huge skyscrapers.
Why wouldn't there be a really tall building?
Now the people who guessed 30 floors,
they did something different.
They used different logic.
They said, look, Rio is a beach city,
you don't want huge skyscrapers in a beach city.
It's not even the capital of Brazil.
So the tallest building is probably going to be a hotel,
and beach hotels tend to be about 30 stories high.
There are other people who predicted short buildings,
and they said, look, you know,
there's that Christ the Redeemer statue
that sits on Crocovado Mountain, which is really huge,
and you don't want anything that detracts from that,
so probably nothing above 40 floors.
This is kind of funny because people made different predictions
based on having different models,
different understandings of what Rio was like.
They had different conceptual models of how the world works,
and those different models, one based on capital and wealth,
one on beach culture, and one based on aesthetics,
all led to different predictions.
Now in reality, all of these ideas probably contribute
to the tallest building really only being 60 floors.
Rio does have lots of money, and Rio is a major city,
but it's also a beach city, it's not a city of bankers,
so it argues against something being really, really tall.
Now as for the Crocovado Mountain argument,
well, it turns out that's 2,300 feet high,
and a 1,200 foot tower wouldn't block out the view.
So it remains true, right, that this Christ the Redeemer
serves as this iconic image of Rio,
and no one would want some glass tower to track from it,
but the fact is that probably doesn't restrict the heights.
So the truth, like the average prediction in this case,
lies sort of in between what people thought.
Well, let's go back to Galton's steer,
because this one's more problematic.
How in the heck do people look at a steer
in a whole bunch of different ways?
So here the explanation comes less from diversity of mental models,
than it comes from diversity of experiences.
So each of these people, this is the west of England, right,
each of these people, they probably had steer at home,
and they probably knew the weights of those steer.
So if I steer at home, it weighs 1,300 pounds,
and I look at this contest steer,
and it looks a little smaller,
then maybe I'll get a little bit less than 1,300 pounds.
If I have a steer at home that weighs 1,050 pounds,
and maybe a little smaller than the contest steer,
maybe I guess a little bit north of that 1050 amount.
So this tendency for people to base predictions on what they know
has a formal name in psychology.
It's called a base rate bias.
We're influenced by how we start thinking about a problem.
So in the case of Galton's steer, the crowd gets it right,
because the idiosyncratic errors of the individual sort of cancel out,
and they're equally likely to be high or low,
and so therefore they're diverse, and we get a wise crowd.
So we've got two primary reasons for these predictions to be diverse.
The first one is different models,
and the second is different idiosyncratic errors.
In the case of guessing the tallest building in Rio,
it's the different models that explains the wise crowd,
and in Galton's steer, it seems to me at least, you know,
that it's a classic case of errors cancelling
because they happen to be diverse because of a base rate bias.
I want to finish up with an observation
that I'm going to return to in greater depth
near the end of this course, about 16 or 17 lectures from now.
And this observation concerns disagreement.
Let's suppose you go to a meeting,
and you're asked to predict something,
like maybe to invest in some new business opportunity.
It could be something even as simple as the number of attendees
you're going to get some of them.
It could be the sales of a product,
it could be the price of a stock,
or like if you're sitting on the Federal Reserve's
Open Market Committee, right,
it could be how much unemployment is going to change in the next month,
or what you should do with the money supply.
Let me lay out two scenarios.
Scenario one, you go to this meeting and everybody agrees.
You all think the same thing.
You make the same predictions, you use some more logic.
Scenario two, your predictions differ
because people use different models
or they have different sort of sets of experiences.
So in scenario one, there's two possibilities.
Either we're all right or we're all wrong.
Now, if it's a hard problem,
it's probably not that likely that we're all right.
So the only way you should feel good about the outcomes
is if you feel that, boy, it was an easy task,
and it was an easy task,
then why did you have the meeting?
It was easy.
Everybody could have got it right on their own.
There was no reason for bringing the diverse group together.
Now, in scenario two, there's disagreement.
So some people might think sales are high,
others might think sales are going to be low,
and we know from our corollary
to the diversity prediction theorem,
the crowd beats averages law,
that the crowd is going to be more accurate
than its average member.
So when you leave this meeting, you should feel good.
You should feel like, wow, the crowd probably made a better prediction
than a random person, including me, would have made on my own.
So we did better.
So in other words, if you go to a meeting
and you're predicting something and people disagree,
that's good.
It's good because it means there's diversity in the room
and that diversity in the room improves performance.
This isn't a metaphor.
We just work through the math.
It's a mathematical fact.
So what's the key lesson?
The key lesson is this.
Within your organizations,
you should include multiple diverse models
when you're making a forecast.
Now, in your daily life, you should do the same thing.
You should open your mind to new and diverse ways
of looking at the world.
Not only is it going to be fun and enlarging,
it's going to be better.
It's going to make you better at predicting what lies ahead.
Thank you.
