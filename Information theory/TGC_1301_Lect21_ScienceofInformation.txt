In the last years of the 19th century, the German physicist Max Planck was worried about
entropy. The entropy formulas of Boltzmann and Gibbs work beautifully for the thermodynamics
of gases, solids and liquids, but when Planck tried to use the same ideas for radiation,
for light, his calculations went badly astray. What Planck eventually discovered in 1900
was something crazy and unexpected. The entropy formulas were okay. What was wrong was our
understanding of the microscopic world. Planck's discovery was the beginning of the greatest
revolution in the history of physics, the quantum revolution. Quantum theory can almost
seem like old news. After all, the basic framework of quantum mechanics has been around since
the 1920s. But the quantum revolution is still going on, and right now, some of the most
exciting events in that revolution are taking place within the science of information. That's
the story I want to tell.
Let's recall the distinction we made between digital and analog information. Digital information
refers to discrete alternatives, like the zero and one of a binary digit. Analog information
is about variables that have a continuous range of values, like the voltage in an electrical
signal. According to classical physics, the ideas of physics that prevailed before quantum
theory, like Newton's laws and so on, information in the physical world is all really analog
information. Every physical variable, the position of a particle or the frequency of
a wave, is continuous. Digital information is a convenient simplification, sometimes
useful, but it's all analog underneath. What Planck found is that the microscopic world
is far more digital than we imagined. A light wave does not have a continuous range of energies,
but only discrete values. It is quantized. That's the quantum part of quantum physics.
The individual and indivisible packets of energy are called photons. And this has practical
implications for communication. Suppose we want to send signals via electromagnetic
waves in an environment where there is essentially no noise. Well, without noise, we should be
able to send our message using almost no energy. The amplitudes of the waves will be extremely
low, but they will carry our information. What matters is the signal to noise ratio.
Quantum physics says not so fast. At such low wave amplitudes, the energy of the signal
will not reach the receiver as a smoothly varying function, but as a series of discrete
photons that arrive randomly. The photon randomness will introduce noise of its own, shot noise,
and that inescapable quantum noise will be what limits our capacity to communicate.
Well, physicists and engineers learned how to calculate the quantum noise level in specific
situations. But it wasn't until the 1970s that we gained a more comprehensive understanding
thanks to the brilliant work of the Russian mathematician Alexander Holovou. Holovou considered
the general problem. We prepare some particles in quantum states that encode our message.
We send them on to the receiver. The receiver makes some kind of measurement to extract
the information. How many bits can we send in this quantum communication channel? Holovou
derived an absolute upper bound on Shannon's mutual information for the channel. We can
never exceed Holovou's bound. Sometimes we can't even get up to Holovou's bound. We
might not be able to reach the ceiling, but there is definitely a ceiling. Now let me
tell you something that I discovered. In the early 1990s, my friend Bill Wooters of Williams
College and I were working on a research problem that involved staring at Holovou's ceiling.
Maybe with the right coding and decoding process it would be possible to get very close to
Holovou's bound. We can't go past the ceiling, but maybe we can always reach all the way
there. Then Holovou's upper bound would equal the Shannon information capacity of a quantum
channel. That would be a great thing to prove. We would know exactly how many bits that quantum
channel was worth.
But this problem was too hard for us. After a couple of years we set it aside. And as
we did so, we had a conversation. We said, maybe this is the wrong problem. Maybe for
a quantum situation we need a new quantum idea of information. And we could measure that
information in quantum bits, qubits.
The more I thought about that idea, the better it seemed. And a lot of other ideas that people
were working on at about the same time made sense as quantum information, quantum entanglement,
quantum cryptography, quantum computing. More about those later.
If we wanted to build a new quantum information theory, where should we start? We should start
by trying to find an equivalent to Shannon's first fundamental theorem, the data compression
theorem. That's the one that says that the Shannon entropy equals the number of binary
digits needed to carry a message. So that is what I set out to find. And to do that I
needed to find quantum versions of all the pieces of Shannon's theorem.
First what is a qubit? Well, a bit is any classical system which has two distinct states
which we can label zero and one. So a qubit is a quantum system with two distinct states.
For example, a photon can be horizontally polarized or vertically polarized so we can
label the horizontal state zero and the vertical state one. A photon polarization is an example
of a qubit. Because the qubit is a quantum system, there are also many other qubit states
called superposition states that are weird combinations of zero and one. So photon polarization
along some other axis is a superposition of horizontal and vertical. And many qubits can
be in a collective superposition called an entangled state. And all of these are built
out of the base of states zero and one, but there are a lot more possibilities for a qubit.
Next what is a quantum message? What would it mean to convey that message? A quantum message
is simply the state of some quantum system. So we imagine that different states are produced
with different probabilities. That's our quantum information source. And the idea is
that Alice wants to convey the quantum state she has to Bob by sending him some qubits.
If Alice's initial state is a superposition or an entangled state, all of that must be
faithfully carried by the qubits. But that brings us to a very interesting point. Previously
Bill Wutters and Wojtek Zurek had proved that it is impossible in general to make a perfect
duplicate of the quantum state of a system. That was called the quantum no cloning theorem.
In the new language we would say that quantum information cannot be copied. Any process
that can successfully copy the zero and one states will fail for superpositions of zero
and one. So our coding and decoding processes are going to be a little different. In Shannon's
theory when Alice sends Bob a message, she can retain a copy for herself. But if she
sends a quantum message, that process cannot leave any copy behind. The information is
transferred, not shared.
Finally, we need to think about entropy. The Shannon entropy is not the right measure
of quantum information. Suppose I have a photon with two possible polarizations, vertical
and ten degrees away from vertical. These are equally likely, so the Shannon entropy
is one bit. But those two states are so close to each other that they cannot be reliably
distinguished by any measurement. They are not as physically distinct as zero and one.
So the Shannon entropy is far too high. Luckily, John Von Neumann had already figured out
the quantum version of the Gibbs formula for thermodynamic entropy, and we can adapt it
as an information entropy. Von Neumann's formula gives just 0.006 bits for our photon
polarization example.
So here is what the quantum version of Shannon's first fundamental theorem ought to look like.
The Von Neumann entropy equals the number of qubits needed to transfer a quantum message.
And that is exactly right. That is the quantum data compression theorem.
If you pick up a textbook on quantum information, you will find in it a mixture of the familiar
and the strange. Some of the concepts seem to run parallel to Shannon's ideas. Bits
and qubits. Entropy. Data compression. But there are also some sharp differences, super
positions and entangled states. The quantum no-cloning theorem.
It isn't that Shannon's classical ideas of information have gone away, far from it.
They still describe the kind of communication and computing that we directly experience.
But now we know of another kind of information. Quantum information. And the two kinds are
related in interesting ways. And that brings us to a happy post-script to our story. The
mathematics of quantum data compression solves the very original problem about sending classical
messages over a quantum channel. So it turns out that Holovoe's information
ceiling is actually Holovoe's information capacity.
But what is it about the world that makes quantum information so different?
Well, to find the answer, I want to begin with the basics. The great quantum physicist
Richard Feynman once said that nobody understands quantum mechanics. But he also said that all
of the mysteries of quantum mechanics are to be found in the two-slit experiment.
The setup is like this. We have a source that sends out photons one by one. Each passes
through an opaque barrier with two small openings or slits. A bit farther on, the photon strikes
a screen. The screen is covered with a dense array of photon detectors, rather like the
array of detectors in a CCD chip inside a camera. The photon is recorded at just one
of those detectors. If we open up just slit one, then the photon might land anywhere in
a wide range of places on the screen. And the same is true if we only open up slit number
two.
If we open up both slits, though, the distribution of photon landing places has alternating bands
of high and low probability called interference fringes. That's because the photon is in
a quantum superposition state of passing through both slits. The interference fringes are produced
by that superposition.
Now, it's easy to think about this wrong. We naturally assume that the photon does go
through one slit or the other. There is an underlying fact of the matter. Which slit
is it? We may not know. We lack that information. But nature knows. The uncertainty is all in
our minds. That is not what is happening here. If we were to change the experiment to find
out which slit the photon passed, maybe by placing super-sensitive, non-absorbing photon
detectors beside the slits, then the interference fringes disappear. The superposition is undone.
The quantum information is destroyed.
The possibility of maintaining a quantum superposition relies on the fact that no measurement is
made. And by measurement I mean the formation of any physical record of any kind. The photon
must leave no footprints, no trace of the path it takes. It may pass through glass or bounce
off mirrors on the way, that's okay. But afterward if you examine the glass and the
mirrors, you won't find any evidence of its passing. The photon must be informationally
isolated from the rest of the world.
The ability of an informationally isolated system to maintain its superposition is called
quantum coherence. Quantum information only survives while there is quantum coherence.
And that coherence is very delicate. If even a single atom records the path of the photon,
it is lost. And by the way, this is not an all or nothing proposition. We could imagine
another experiment in which the super-sensitive photon detectors are not very efficient. They
give us less than one whole bit of slit information for each photon. And when we do that experiment
we find a diluted pattern of interference.
Quantum coherence has been lost, but some remains. And there is a mathematical trade-off
between the amount of slit information we gain and the amount of coherence that remains.
And roughly speaking, every bit of information we gain about the path represents the loss
of at least a qubit of quantum information.
Quantum coherence can be very important. For instance, we have recently learned that
coherence is essential in the process of photosynthesis in plants. So a photon strikes
a chromophore, which is a molecular unit such as chlorophyll. The energy is absorbed. But
then the energy must be transferred across a whole chain of molecules to another location
where it can be stored in metabolizable form. And that energy transfer depends crucially
on the quantum coherence of the molecular vibrations. The quantum information must be
preserved, not for long, just a billionth of a second. But without that tiny interval
of information isolation, the efficiency of photosynthesis would be dramatically reduced.
So quantum coherence is like a magic trick. So suppose I were to do a magic trick for
you. I have a box, I put an egg in the box and close it, I wave my wand and draw out
a rabbit. Now since this is stage magic, you know it's a trick. If the box were made
transparent, you could watch the trick work. You would be able to tell that there was a
secret compartment all along.
But the quantum magic box is different. If you make the sides of the box transparent
to observe the thing happening, the trick does not happen. The trick depends on the
physical fact that no one is watching. Quantum coherence relies on informational isolation.
And this is why we never see those effects for the macroscopic objects in our everyday
experience. Big things like billiard balls and electrical signals and wires are continually
reacting with other things. Gas molecules and photons bounce off the billiard ball.
Water atoms and a wire are agitated by the passing current. These things make records
of their passing. They cause extremely rapid decoherence. The whole universe is a vast
network of continual information exchange. But very small things like single particles
can sometimes separate themselves from that network for a while. That is when the quantum
coherence and quantum superpositions can do their magic.
So quantum information is the kind of information contained in an informationally isolated system.
And quantum information theory studies the properties and rules of that kind of information.
And it also studies the relationship between quantum and classical information. So we have
already seen a quantum version of data compression of Shannon's first fundamental theorem. What
about other landmarks of Shannon's information theory? Are there quantum versions of those?
For example, we should regard decoherence as a kind of noise. Can we defend against it
in the same way that we can defend against classical noise in Shannon's theory? Is there
quantum error correction? I confess, when quantum information theory was getting started
in the 1990s, I believed that quantum error correction had to be impossible. After all,
error correcting codes are based on copying information. Think about the simplest error
correcting bit code, the 2 out of 3 code. The code words are 0, 0, 0, and 1, 1, 1. Three
copies of the same bit of information. So even if one of the bits is changed by noise,
the majority still indicates the original bit. So if we cannot copy qubits, I believed,
surely we cannot make a code like that. I was wrong. In the mid-1990s, Peter Shor of
Bell Labs and Andrew Spien of Oxford University discovered the first quantum error correcting
codes. By using many qubits to encode the quantum information of one qubit, their codes made
that qubit of information more resistant to errors. The qubit state 0 might be represented
by the code word state 0, 0, 0 of 3 qubits. State 1 becomes the code word state 1, 1, 1.
A superposition of 0 and 1 becomes a superposition of 0, 0, 0 and 1, 1, 1. And that's not three
copies of the qubit state, it's an entangled state of 3 qubits. The quantum information
is not duplicated, it is shared by all three code word qubits. And that makes it resistant
to the error processes that would affect only one qubit. Put it this way. If the quantum
information is collectively held in the entanglement among many qubits, then a failure of information
isolation of only one qubit cannot quite reach that information. No single qubit has it.
The quantum code I've mentioned is a little too simple, but there are longer codes involving
five or more qubits that are entirely immune to single qubit errors. Any one qubit of the
code word could suffer decoherence or be damaged or destroyed and still the original quantum
information can be reconstructed by the receiver. So quantum error correction is possible. And
there is now a very sophisticated quantum error correction code theory to go with it.
So can we therefore find a quantum version of Shannon's second fundamental theorem?
That theorem tells us exactly how much error correction is possible, exactly how many bits
of information a noisy channel can convey without error. That's the information capacity
of the channel. The capacity of a quantum channel is how many qubits it can convey faithfully.
Unfortunately, we do not have the quantum version of the second fundamental theorem,
or at least we do not have it yet. It is an unsolved scientific problem. In fact, we've
been stuck on it for about 15 years. So what's the problem? We can define mathematically
the quantum information capacity. We just can't calculate it. So let me explain. In
Shannon's information theory, suppose we have two noisy information channels, each
with a capacity c. If we use them together, the overall capacity is just 2 times c. The
information capacity adds up. So if we use a single channel many times, or many copies
of the same channel in parallel, then we can just multiply c by the number of channels.
Many of us thought the same would be true for quantum channels, but we could not prove
it. And then in 2009, Matthew Hastings, now of Microsoft Research, found a mathematical
example that explained why we were having so much trouble. Our assumption wasn't true.
So consider two noisy quantum channels. We have an expression for the maximum quantum
information through one channel called that q. When we use the two channels together,
we actually can get more than 2 times q. The quantum information capacity adds up and then
some. And the reason is that the channels can be used in an entangled way. The extra
capacity in the Hastings example does seem to be very small, but no one has proven that
it always must be small. The Hastings example is telling us something subtle and important
about quantum channels and their relationship to entanglement. We just don't quite yet know
what that message is. And until we do, the long sought for second fundamental theorem
of quantum information will remain just beyond our grasp.
Probably the most amazing concept in quantum information is the quantum computer. So here's
the general idea. An ordinary computer stores its data as bits in its memory. It runs programs,
sets of instructions, which are also stored as bits. A quantum computer on the other hand
stores its data and programs as qubits. That means that its memory can be in superposition
states. It can execute superpositions of different programs, or the same program on superpositions
of different input data. It is almost as if the same computer can do many different computations
at the same time. Unfortunately, you cannot read out all the answers to all those different
computations, but in some cases you can combine the answers using a form of quantum interference
and obtain a single result that no single ordinary computation could have given you.
And that means that for certain mathematical problems, a quantum computer can arrive at
the answer in exponentially fewer basic steps than any ordinary classical computer. And
one such problem, as Peter Schor discovered, is the problem of factoring.
We saw in lecture 12 that it is a computationally hard problem to take apart a large integer
into prime number factors. A number with a few hundred digits could not be factored
in millions of years on any ordinary classical computer. Yet a quantum computer of a few
thousand qubits could solve that problem quickly.
How quickly? Let me give you some order of magnitude figures. Don't take them too seriously.
They are intended only for illustration. So let's assume that both computers can factor
a 10 digit number in one millisecond. A 20 digit number takes them each about 10 milliseconds.
A 50 digit number takes the classical computer 10 seconds, but the quantum computer uses
only one tenth of a second. A 100 digit number takes the classical computer 20 minutes, but
the quantum computer one second. A 200 digit number takes the classical computer 3 years.
The quantum computer clocks in at 10 seconds. A 500 digit number takes the classical computer
a billion years. The quantum computer manages it in 100 seconds.
Now let me be clear, a quantum computer is not really magic. It cannot calculate an
uncomputable function like Turing's halting function, or tell us the first thousand bits
of Chitin's omega. In that sense it is no more powerful than a Turing machine. But the
line between hard computational problems and easy computational problems is apparently
not the same for classical and quantum computers. Factoring is hard for one, but easy for the
other.
However, no one has yet built a quantum computer having more than a handful of qubits. The reason
is that in order to work, all of the computer's qubits must be informationally isolated from
the surroundings. On the other hand, they cannot be isolated from each other since they must
exchange quantum information to carry on their computation. That combination is difficult
to achieve. It's difficult for a few qubits. It might be a thousand times harder for a
few dozen. Even with serious quantum error correcting codes, decoherence is a fast process
that is hard to beat.
At the moment, all of the proposals for large quantum computers look like babbages analytical
engine, impressive in conception, but perhaps beyond the abilities of their inventors to
build. Real quantum computers may not arrive for a long time.
Still, experimental physicists are very clever. Who knows what they will dream up?
Now some years ago I made a wager with a physicist's friend of mine. The wager was
whether by 2019, exactly 20 years after we made the bet, a large quantum computer would
be built. Well, what's large? It has to factor a 500-bit number, about 130 digits. And the
value of the wager is one bottle of port from 1999. If you are sure that you will win the
bet, you can just wait. If you are less sure of your chances, perhaps you should buy a
bottle soon, just in case.
Now I took the optimistic side of the wager. I bet that a quantum computer would be built.
But I long ago bought my bottle of port. I hedged my bet. My friend tells me that he
has not bought his own bottle. Nevertheless, he is hedging his bet in a different way.
His name is Raymond LeFlam, and he is now the director of the Institute for Quantum
Computing at the University of Waterloo. And I don't know any group of people in the
world working harder to win my bet for me. And if they succeed, I'm sure Raymond will
only be too glad to send me a bottle.
One sign of hope for my side. Just last year, a group reported a quantum factorization of
the number 56,153, using a different technique called adiabatic quantum computing. The quantum
computer found that 53,153 is 241 times 233. That number, 53,153, is only 16 bits long.
It's a lot less than 500 bits. But it's something.
Whether or not a large quantum computer is built by 2019, or even 2119, the new science
of quantum information has already taught us profound new lessons. There are concepts
of information beyond Shannon. The laws of information are inextricably linked to the
laws of nature.
However, if a quantum computer is built, we will face a very serious problem. Almost all
public key cryptography today is based on factoring. If quantum computers ever make
that into an easy problem, every one of those cryptosystems will become insecure. We will
need to discover new ways to keep our secrets.
Luckily, quantum information, which poses the problem, may also provide the answer.
It's called quantum cryptography.
Where else should we look for absolute privacy than the physics that only works when no one
is looking?
