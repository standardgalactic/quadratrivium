Co-Opetition, the word used by Adam Brandenberger of Harvard and Barry Nelbuff of Yale is the
title for their book. Also, their name for a practical approach to applying game theory
to the world of business. Business as both war and peace, both cooperation and competition.
In short, business as a non-zero sum game. Last time, we saw that the Co-Opetition approach
looks at the game of business quite literally as a sum of its parts. Parts is an acronym
that identifies the five sources of leverage that you have in your business relationships,
namely players, added value, rules, tactics, and scope. We've already discussed players
and added values, along with several examples. Today, I want to round out the discussion
with the last three components, rules, tactics, and scope. The materials that I present are
only a sampler of what Brandenberger and Nelbuff comes up with in their book, so if you find
the discussion intriguing and want to learn more, I'd strongly encourage you to get a
copy of Co-Opetition. This lecture is the final one in the series, so when we do finish
with Co-Opetition, I want to take a brief look back at the course as a whole, where
we've been, what we've seen, and what I, at least, am taking away from the trip.
But first things first, let's add the third component to our parts list. R is for rules.
Every game has them, and every business deal does too. Brandenberger and Nelbuff point
out that the rules of business are often viewed as being set in stone. To some extent, that's
true. There are laws and customs that you violated your peril, but a number of apparently
minor rule changes, generally in the details of contracts, can have a powerful impact on
shaping your business relationships. Some of these effects are so subtle and counter-intuitive
that the other parties in your deals may not even be aware of them. Take, for example,
the Most Favored Customer Clause, or MFC. It also goes by the name of Most Favored
Nation or Best Price Provision. Whatever you call it, it's a clause in the contract with
a customer that says that you agree to charge that customer the best price that you give
anyone. This kind of clause is very common in business to business contracts, and it's
easy to see why customers like to have an MFC. As a customer with an MFC, what's not
to like? If somebody else gets a better deal from you, then so do I. This is particularly
good for me if you also supply my competitor. Why? Well, suppose I'm not a great negotiator.
With the Most Favored Customer Clause, I don't have to be. If my competitor drives a hard
bargain with you and gets a great price, then I get it too. I'm not going to end up at a
cost disadvantage relative to that competitor. The scene of explaining to the boss why the
competitor got a much better deal than the one that I got is a scene that most purchasing
agents would prefer to avoid, and with an MFC, you've got the protection to avoid it.
But Brandon Berger and Nailbuff point out that having an MFC clause in your contract
with your customers is good for you. How does that work? Simple. It goes back to threats
and credibility. Having MFCs with your customers allows you to make a credible threat that
you'd rather lose that customer's business than give them the price cut that they want.
Let's see how it works. To make it simple, let's say that you have 10 customers all the
same size. You make a product that you sell for $100 a unit. You make it for $100 a unit
and you sell it to your customers for $300 a unit. Let's say I'm one of your customers
and I actually value your product at $400 a unit. And let's further suppose that at
the moment, you have no MFCs. All right. You and I are negotiating for our contract
for the upcoming year. I'm pressing you for a lower price. I want you to drop your price
from $300 to $250. That way, the surplus generated by our transaction is shared evenly
between us. You tell me I can't afford to do that. I tell you, you can't afford not
to. If you don't give me a price break, I'll find another supplier. Well, maybe my threat
is real or maybe it's just posturing. Either way, it's something that you have to worry
about and I know it. In making my demand, I'm trying to get you to play an ultimatum game
with me. The price I'm proposing cuts your profits down from $200 to $150, but losing
my business cuts them to zero. I'm actually making a fair sounding ultimatum deal splitting
evenly the surplus of our transaction. So you might lose my business if you don't give
me a price break again. There's a lot of pressure for you to do so. But how about if
you have MFCs with all 10 of your customers? Let's run the same situation again. Lowering
my price by $50 means that you'll have to lower the price to all of your other customers
by $50 too. Cutting me this break on price costs you 10 times the benefit to me. Suppose
for example that each of your 10 customers bought 100 units of your product. Giving into
my demand will cost you $50 on every one of those 100 units or $50,000. Losing my business
entirely on the other hand loses you $200, but only on 100 units. That's $20,000 loss.
So when you tell me that you can't afford to give me the $50 cost break, you're telling
me the truth. Your statement that you won't give it to me isn't a threat. It's a warning.
Wishing you for a $50 break on price is a game that I'm not going to win. I'd have
to settle for something less. I might be able to squeeze you for $10 or $20, but in the
presence of the MFC, your hands are tied when it comes to the big cuts. It forces you to
hold the line on lowering your prices. At the same time that MFCs make you a tougher
negotiator, they make your customers less aggressive in negotiation. I've already hinted
this. I don't have to fight tooth and nail with you to get the best deal I can. Someone
else can do the fighting and I get the same deal that he does. The trouble is of course
the volunteer's dilemma. It's often the case that no one is willing to do the heavy lifting,
not when the benefits to the negotiator's competitors are as much as they are to the
negotiator herself. So dividing up the pie between you and your customers with MFCs,
you get a bigger piece. MFCs do have a downside for you. The fact that you can't afford to
give a particular customer a price break means it's harder for you to steal business from
your competitors and easier for them to steal business from you, unless you have a lower
variable cost than they do, of course. But this cost might not be as great as it first
appears. A customer that will go to a lower price once, once is likely to do so again.
So you have to ask yourself how much you really want to keep a disloyal low margin customer
anyway. Brandon Berger and Nelbuff talk about another condition you might want to consider
in your contracts with customers, the meet the competition clause or MCC. It's also
called meet or release or a last look provision. It simply says that before your customer switches
to another supplier, he or she has to give you a chance to match that supplier's price.
If you do, you keep the business. This type of provision often appears in commodity contracts
when the difference between what supplier's supply is essentially nothing. They're identical
goods. It's easy to see why your supplier would like to have an MCC as a supplier. You'd
like to have an MCC in your contract with me. If one of your rivals tries to steal my
business, you have a chance to keep my business, although with a smaller profit margin than
you had before. As your customer, I might feel agreeing to an MCC is an easy thing
for me to do. As long as you're giving me the best deal that I can get anywhere, I'm
willing to stay with you. But again, this overlooks the fact that the new rule changes
the optimal strategies for the players in the game in a couple of important ways. Let's
imagine that I come to you with the news that one of your competitors is offering me a better
price. It'd be bad business practice for me to make up such a story, but I could be lying
to you. U.S. law actually prevents you from calling up the supplier to verify my story.
Even if it's true, you don't know how much you'll have to cut prices to keep my business.
But now look at it with the MCC. The MCC means that I have to tell you exactly what the better
offer was. You can meet it exactly if you wish and keep my business. If you don't want
to keep my business at the lower price, you're free to let me go. The MCC has cost you nothing.
But there's a more subtle benefit conferred from the Meet the Competition Clause. Look
from your competitor's point of view. She's thinking of stealing a customer from you.
Making a bid as Brandenburger and Nailbuff point out isn't free. There are a lot of
hidden costs. Bidding takes time. It takes effort. It encourages retaliation, such as
price wars. It helps set a new lower price as a benchmark for her business. A benchmark
or other company customers are going to want to use. Now to all that, add the new cost
of the MCC effect. After all this work, she won't get me as a customer if you're willing
to make the same offer to me that she is. In short, the MCC gives her less incentive
to go after your current customers in the first place. Of course, she could make a lower bid
on one of your customers without any real desire to steal them. Her purpose would just
be to reduce your profit on that customer by forcing you to offer a lower price. Even
if this is the case, the MCC doesn't hurt you. You have exactly the same options as
you would have had without it. But now you know the specific information about what bid
you need to beat to keep my business. Brandenburger and Nailbuff point out that
analyzing your business game theoretically may allow you to find such details that increase
your power in such a game. The MFC and MCC are just two examples. Let me give you one
more, this one for retail business. The low price guarantee in the retail market. If a
customer finds the same product at a lower price in a local store, you'll refund the
difference in price and perhaps even a bit more. That sounds like good news for the customer,
but it actually allows you to charge higher prices. A customer who's insensitive to price
buys at your original higher price. Even a customer who's concerned about price need
not shop around at other stores, they can buy from you. And if they discover that they
have made a mistake, they'll get the lower price anyway. So you essentially get to engage
in differential pricing in different markets. And after they've bought from you, most customers
won't have much incentive to shop around for a better price on an item that they've already
bought anyway. Alright, that's players, added value and rules. Let's talk about tea for
tactics. This really just means shaping perceptions. Perceptions, beliefs, drive behavior. For
example, Brandenburger and Nailbuff report that a bitter price war shook the market for
electrical products. The cause? An industry trade journal erroneously reported that the
total market volume was 15% more than it really was. The four major players all thought they had
lost market share, so they all dropped their prices to regain what they had never lost.
We've talked about shaping perceptions a lot in this course already. We've discussed threats,
promises, commitments. You'll recall that each of these techniques in order to be effective had
to be credible. They had to be believable. We also discussed how signaling and screening can be used
to convey information among players. In addition to these topics, Brandenburger and Nailbuff talk
about one more, the fog of business. Negotiations usually take place in an environment where
some things are suspected to be so, but not known for sure. Depending on the situation,
you may wish to lift that fog, to preserve it, or even to stir it up a little. Lifting the fog
is what we do with signaling and screening. As a nice example, Brandenburger and Nailbuff say
that Federal Express should send a more credible signal of their reliability. If FedEx fails to
deliver your package on time, they give you a refund of the shipping price, hardly adequate
compensation. You pay more for FedEx than, say, Expressmail because you care about that increased
reliability, and FedEx is actually quite reliable. FedEx's low failure rate would allow it to pay a
sizable payment, say $200 for packages not delivered on time, and this is a payment that
its less reliable compliments could not afford to match. The existence of the program would be
a credible and visible signal to FedEx's customers of its reliability. As Brandenburger and Nailbuff
will put it, if you offer a first-class service, you can and should offer a first-class guarantee.
Preserving the fog may be desirable for a couple of reasons. You might not want to erode the
favorable impression that others currently have of you with some new bad news. The herd may be
wrong, but following it gives you no chance of standing out as a fool. Similarly, rejecting the
project, burying it, usually preserves the fog of the decision-maker's competence. When you
greenlight a project, you're on the hot seat of the project fails. If you reject a project,
who knows if it would have been successful? But this doesn't always work. Ambulan productions
wanted to use M&Ms in one of its movies. It went to Morris Incorporated, the maker of M&Ms,
but Morris refused the offer, so Ambulan used a different candy instead, Reese's Pieces.
The movie, of course, was E.T., and the sales of Reese's Pieces skyrocketed after the film's release.
Morris made a mistake by rejecting the project, and burying the project, in this case, didn't
preserve the fog. Preserving the fog is also a negotiation tactic. Many things once they're
said can't be unsaid. If I offer to sell you my car for $3,000 and you refuse,
well, we can continue to negotiate, but you know that my minimum price was $3,000,
or maybe less. You'll bargain accordingly. Knowing this, I'm more likely to make my original offer
at $6,000, not $3,000. It could take us a long time to reach an agreement.
One interesting solution to this problem is the idea of settlement escrows. In this arrangement,
we bring in a neutral third party. I name my selling price to the mediator, and you name
your buying price. If they cross, if my selling price was below your buying price,
then the transaction is completed at the average of those two prices. If the prices don't cross,
the mediator simply announces that the prices didn't cross. Each person knows that the other
didn't accept their current offer, but neither party knows what the other offer was. The fog
is preserved. Brandenberger and Nailbuff point out that threats, once made explicit,
can do a lot of harm to business relationships. A customer knows that a supplier asking for
a certain price may refuse to supply them at a lower price, but making that threat explicit
changes the tenor of the negotiations. If a customer is over a barrel, he'll accept the price,
then almost certainly move as quickly as possible to find a different supplier and maybe a backup
to that one. Mediators can be helpful in making sure that both sides of a negotiation appreciate
the possible consequences of their actions. We saw this before. Embarganing, patience,
is a necessary virtue. Sometimes the fog of disagreement is actually helpful.
Co-opetition offers an example of the sale of a company. The owner wanted $500 million for the
company based on the belief that the company would continue its recent 10% per year growth.
The buyers of the company expected growth to be flat. They offered $250 million.
How to remove the impasse? They struck a deal where the company was sold for a combination of
cash now and delayed payments based on the future growth of the company.
Each side got the price they wanted, if their beliefs were right.
To round out the parts list, let me say a few words about S for scope.
This last part is really more of a reminder than a new part, a reminder that everything
is really one big game. Scope tells us to look at the linkages among games, among the pieces of the
game. Creating, dissolving, or even recognizing such linkages can be crucial for business success.
Nintendo once again provides a nice example. Its stranglehold on the video game industry was
eventually broken, but not until another manufacturer, Sega, came out with a 16-bit machine,
the Sega Genesis, in 1988 and 89. Interestingly, Nintendo had been developing its own 16-bit
machine since the late 80s, but didn't come to market with it until two years after the
Genesis appeared. Why? Because Nintendo knew that two games were linked. In this case,
the 8-bit game market, which Nintendo had all to itself, and the 16-bit game market.
As it stood, Genesis was priced at about twice what the Nintendo system cost,
so the 8-bit market was still strong, and as we've seen, Nintendo owned that pie.
When Nintendo released its own 16-bit machine in the U.S., as eventually happened in 1991,
the results were predictable. There was fierce competition between Sega and Nintendo,
including price reductions, free software, and stripped down cheaper versions of both systems.
With better systems and cheaper prices on 16-bit machines, the added value from the
8-bit market was greatly reduced. 8-bit video game cartridges dropped to $20 each,
and less than half as many new 8-bit titles came out in that year as compared to previous years.
Nintendo had made a hard call. It gave Sega the 16-bit market for a while to avoid cannibalizing
its own 8-bit one. The lead developed by Sega in that market took about three years of catch-up
for Nintendo to erase. For Sega's part, it wisely let Nintendo keep the 8-bit market
by pricing its Genesis substantially higher. As Brandon Berger and Nailbuff point out,
it's often wise to let your competitor make profit too. If he lives in a glass house,
he's less likely to throw stones. The main point of the scope component is just this.
There's always a larger game. And that same thing, I suppose, could be said about game theory in
general. There's always a larger game, and there's always more to know about the games that make it up.
I hope that this series of lectures has given you a good layperson's feel for the world of game
theory. What it is, how it's done, how it can be used, and what we can learn from it.
We've opened up some doors on a new world. It's a big place, and in some cases, we've only walked
a few steps through that doorway, craning our necks to see what we could see from there.
That's enough. Your passport has been stamped. If you've caught glimpses of sites that interest
you, you can go and learn more. The suggested readings in this course booklet will give you
some ideas of places to start. You might remember that in my first lecture, I told you that the
games that we looked at would in some ways be parables. There were a lot of little lessons
along the way, but a few of them stand out in my mind as particularly important.
The first is simply this. To play games successfully, you must be allocentric.
You must be able to put yourself in the position of other players
and look at the world from that perspective. Abraham Lincoln said,
when I'm getting ready to reason with the man, I spend one third of my time
thinking about myself and what I'm going to say, and two thirds about him and what he is going to say.
And that's pretty close to the heart of allocentrism. It's not the golden rule,
and it's not merely putting yourself in the other person's shoes.
The issue isn't what you would care about if you were the other person or how you would
interpret the situation. The issue is what that person cares about, about how they interpret
the situation. Unless you have a dominant strategy, and usually you don't, then you simply
can't make your best decisions without being allocentric. Your actions are going to generate
reactions, which you yourself are going to respond to. If you can't or won't adopt an
allocentric perspective, you lose an important ability, the ability to encourage others into
the kind of behavior that you want to see. People make their choices based on the game
that they think that they're playing. Beliefs and perceptions play an important role.
Allocentrism requires you, to the extent that you can, to determine how the other person sees
the situation, including how they see you. This is a hard thing to do. It's like tickling yourself.
Since you know your worldview and your plans, it's very hard to step outside yourself and
see how the other player would see you from the outside. I'll be honest, game theory can't help
you with that much. But role-playing can. Discussion among the participants after a role-playing
exercise lets each see how things looked from the other side. This information can sharpen
the game theory models and can be used in playing the real game. Kirsten Green and J. Scott Armstrong
have shown that when forecasting the outcomes of geopolitical conflicts, analysis including
such role-playing, did significantly better than game theoretic analysis alone. The technique is
also commonly used in businesses. People often presuppose that others will have the same reactions
to a situation that they themselves would have. They may even be quick to brand other preferences
as irrational. But we deal every day with people who value things differently than we do and make
their choices based on that valuation. And that, as we've seen, is the hallmark of rational behavior.
We've seen from co-opetition that the differences in worldview may actually create opportunities
for deals. People can and will sensibly see things differently than you do, which is why
you must be allocentric. To do otherwise is just, well, irrational.
Of course, we've also seen that the assumption of rationality itself in many real-life situations
may go too far. The works of Thaler, of Selton, and others give a strong evidence that people
often engage in bounded rationality, especially when dealing with new situations. In particular,
we've seen that odd characteristic that people often take a chain of reasoning,
only two or three steps, and then stop. They reach a kind of mental event horizon.
If allocentrism means seeing the world from another player's eyes, then you have to take
into account such limitations when you make your plans. For example, our central precept for
sequential games was to look forward, you must reason backward. But you have to know if you can
count on the other players to do the same. It's possible that the event horizons of other players
may act to your advantage, in which case you may choose to preserve the fog and the metaphor of
Brandenburger and Nailbuff. But you could also choose to dispel the fog by helping other players
to clearly see that the course of action you're proposing is the best that any of you can reasonably
hope for. Your understanding of game theory can help you to do this. This is especially important
when using strategic moves. We've seen that for threats, promises, and commitments to be effective,
they must be known, and they must be credible. These moves put you in a better position by
an odd mechanism, forcing you to do something that you will not want to do in at least one
circumstance. Threats in particular set up a trigger that will result in an outcome which
is worse for you and for another player. It's essential when making a threat that the other
player understands its credibility and its consequences. On the flip side, when someone
threatens you, don't just think, what will happen to me if they do this. Also consider the question,
would they have reason to actually follow through? While on the subject of strategic moves,
another surprising result from game theory is this. Flexibility is not always a good thing.
At least there are many times when it's in your best interest to have other players believe
that your hands are tied. This was nicely summarized by Tom Schelling, remember? The
power to constrain an adversary depends upon the power to bind oneself. The lack of flexibility is
exactly what you need to make a strategic move credible. We saw this with NFCs earlier in this
lecture. I said that this result was very surprising, but perhaps it shouldn't be.
Children know that it is easier to get forgiveness than permission.
An act they have already performed can't be undone, so no punishment can prevent it.
Suppliers can take on new customers knowing that it's going to delay your deliveries,
but once the contracts are signed, what can they do? In fact, this sort of hand-tying comes up so
often that we should follow Sun Tzu and his golden bridge for his enemies to retreat across.
Look for ways to prevent other players from tying their own hands in order to pressure you.
It's never in your best interest to let someone threaten you.
One last topic, and one that feels most important to me personally.
The puzzle of cooperation. I want to start out by telling you a story
how the great man of game theory, John von Neumann, was horrifyingly wrong.
The Soviet Union exploded its atomic bomb in 1949. The prisoner's dilemma was discovered in 1950.
William Poundstone says that it was unlikely that von Neumann thought of the nuclear standoff
between the U.S. and the USSR as the prisoner's dilemma, but it's often been viewed that way since.
Given the antagonism between the Soviets and the West, all that's required for a prisoner's dilemma
is that the preferences go, best is we nuke them, then no one nukes anyone, then everyone nukes everyone,
then they nuke us. Better dead than red. If this is the order of preference,
the one equilibrium is nuclear war. Both sides launched the missiles.
In the years following 1950, many people, including von Neumann and Bertrand Russell,
thought nuclear war with the USSR was inevitable. That being the case, it was best done sooner
than later when the Soviets would be stronger. According to von Neumann's obituary in Life
magazine, he was remarking in 1950, if you say, why not bomb them tomorrow? I say, why not today?
If you say today at five o'clock, I say, why not one o'clock?
von Neumann was definitely not alone in advocating that we be aggressors for peace,
and he had personal reasons to hate the Russians from his childhood,
but as someone who grew up during the Cuban missile crisis, I find his advocacy chilling.
von Neumann was a consummate strategist, and in the nuclear game, if the other side strikes first,
you lose. I think that he advocated war for reasons similar to the traps that we've struggled with
so many times with the prisoner's dilemma. I don't think he saw a way to achieve the cooperative
solution of peace. And yet the war between the Soviets and the West never came to pass,
and the nuclear devastation of Europe that Russell thought was all but inevitable was avoided.
And it will be the work of a new generation of game theorists, behavioral game theorists, probably,
to tell us how. Because all of the math aside, there's something about cooperation that's operating
inside us. It's hardwired into the human animal. We can see it on brain scans. The work of Axelrod
and evolutionary game theorists show that in many contexts, cooperation is selected for. It's selected
for because it works. And that's what I want to leave you with. Axelrod's prescription for
eliciting cooperative behavior. You must be nice. Don't be the first to betray another.
You must be provokable. Be ready to punish those who betray you, and perhaps even those who betray
others. But you must be forgiving. Once you've punished a betrayal, you've got to be ready to
work together again. And finally, you must be straightforward. You have to let people know
how the actions that they take influence the ones that you will take. It's all one big game,
and it's definitely nonzero sum. I said in the first lecture that we study games not simply to
play them better, but to change them to better games. If we play the game right, the world of
game theory can make this world the one that we all share a lot nicer place to live. So thank you
and have fun.
