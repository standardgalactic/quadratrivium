We saw in my last lecture that game theory has its own problems in predicting human behavior.
One of these was a problem of which Nash himself was well aware, instantaneous equilibrium.
In real life, people usually don't gravitate so quickly to an equilibrium.
No more than a marble placed in a bowl instantly goes to its lowest point.
But repeated exposure to the same situation lets us try different strategies and see how
they work.
If everyone's doing this, we often slide toward the game theoretic equilibrium.
We're going to look at a place where that occurs today.
We'll be studying collective action games, games with lots of players.
This sliding toward equilibrium will be even more important in my next lecture when we
look at evolutionary game theory.
Game theory is both extensive and deep, and I can only mention some things in this series.
We're covering an amazing amount as it is.
We've looked at a lot of games with two players and a couple with three or four, but how much
are we leaving out by doing this?
Well, when you've got more than two players, you can be dealing with a fundamentally different
situation.
If you allow binding agreements, coalitions come into play.
Three business partners who use majority rule could have two of them vote to divide all
of the company's profits among just those two.
These games can become extremely complicated to analyze.
That's part of why I've been focusing on non-cooperative games, where binding agreements
aren't possible.
With non-cooperative games, most of the problems that arise from adding extra players are technical
ones.
They're just more work to solve and harder to visualize.
A simultaneous game with two players can be represented in a matrix, essentially a rectangle
of numbers.
For three players, you need three dimensions, both width and height and depth, essentially
a payoff cube.
One player picks the north-south position, one the east-west, and the third picks the
floor of the building that you're in.
For four players, the picture would have four dimensions.
It's not as bad as it sounds.
There are ways around it.
When you're drawing the blueprints for a three-story building, you can put each floor on its own
page.
And we use similar tricks in dealing with mathematics for the payoff matrices of more
than two players.
Still, technically, it's more complicated.
A bigger obstacle is that the problem can get very big, very fast.
Earlier we looked at a voting problem with three committee members.
Our decision tree had 27 leaves, 27 final payoffs.
If it were expanded to four players, that tree would have 256 leaves.
By the time you reach 17 to 19 players, you would have more leaves than there are grains
of sand on the earth.
That's a lot of payoffs to attach.
And as you realize, there are a lot of games that involve a lot more than 19 people.
So what do we do?
Well, we make simplifying assumptions.
Think of pouring water into a glass.
You really don't know what each drop is going to do, but you have a very good idea what
the water is going to look like in a couple of moments.
Even though the drops aren't identical, they share a lot of traits with the others.
In the same situation, they react in pretty much the same way.
People show a lot more variety than drops of water, of course, but the principle is
still useful.
We can approximate the real situation by having a bunch of agents, all of who basically face
the same decisions in the same kind of way.
We then watch how such a community of players evolves over time.
That's the approach that we're going to take in today's lecture.
In particular, what happens when you take the simplest of games, prisoner's dilemma,
chicken, the coordination game, and move them to their many player equivalents?
I think you'll be amazed at the answer.
These questions have a remarkable relevance to real-world situations and how they work
out.
So let's get started.
Ever hear of a free rider?
I'm sure you have.
Someone who lets the others do the work while they share the benefits.
The term comes up a lot in economics.
We pay for the highways, but they get to use them as much as we do.
We clean up the park, but they enjoy its pristine appearance along with everyone else.
There'll be plenty of food at the potluck supper, so they come in empty-handed and eat
with the rest.
They're all free riders.
Look, it's late at night, and you're alone in a subway station.
There's the turnstile.
You can pay with your $1 token to ride the train, but you can also just jump the turnstile
and ride for free.
You're sure you won't get caught or hurt yourself on the turnstile.
So what do you do?
Well, jumping the turnstile has a positive and a negative effect, no doubt.
You save yourself the cost of the trip.
You get to ride for free.
But the second effect is that you cost the subway system the price of the trip.
Well, from a practical perspective, how big a deal is that?
The train was going to run anyway, with you on it or not.
It really doesn't cost more to run with you on it, and the subway system is not going
to go bankrupt over the cost of your fare.
So the buck for the trip is a bigger deal to you than it is to the subway system.
All true.
Until a lot of other people think the same way.
Then revenues for the subway system fall eventually enough that the subway has to close.
Then you, and all the other free riders, and all the paying customers too, you're all worse
off than you would have been if you all paid.
This is an example of a social dilemma.
A social dilemma is just a game where the equilibrium isn't efficient.
It isn't Pareto optimal.
Every player could be better off if they played a non-equilibrium strategy.
That's hard to get in a two-player game.
It's even harder in a many-player game.
I'm going to need an effective way to model the many-player games I want to talk about.
I'm going to limit each player's choices to only two choices, like paying for the fare
or leaping the turnstile.
And while it's natural that people like to think in specifics, I've got to point out
that the power of both science and mathematics is in its ability to generalize, to show how
seemingly different things have the same underlying structure.
So I'm going to keep my terminology general to highlight the structure and add specifics
as we look at particular examples.
So each member of society, each player, is going to choose between two options.
I could call them A and B, but to make them memorable, I'll call them working and shirking.
Working sounds like you're doing your part, and shirking sounds like you're not.
And in a lot of examples, those names are going to be right.
But sometimes shirking might be a good thing.
We'll just have to see from the context of the game.
What's desirable will come out from the analysis.
Okay, let's start by considering air pollution.
Each player can either work by curbing their emissions or shirk by not curbing them.
The players could be countries, companies, individuals, whatever you like.
In the general situation, some people are going to work and some are going to shirk.
I'll call the fraction that are working P.
So in my picture, P is about a quarter.
That means that 25% of the players are working, curbing their emissions, and the other 75%
are shirking, not curbing them.
You'll see two lines in my picture.
That's going to be the case for every graph I draw today.
The red line will always show the shirker payoff, and the black line will always show
the worker payoff.
What do these lines mean?
Well, suppose P is the fraction of those who are working.
Draw a straight line up from P.
It'll cross the worker line and the shirker line.
In fact, I've marked these points with crosses.
The higher the point, the better the payoff.
At the value of P shown, the shirker gets more than the worker.
In fact, in this particular picture, the shirker always gets a better payoff for the worker,
for any P.
Hardly surprising.
After all, the problem caused by air pollution is the same for everybody.
But the worker has the extra expense and inconvenience of curbing his or her own emissions.
This gives the worker a lower payoff.
Okay, start the society off with any P that you want, any fraction of workers.
Assume that people want to maximize their individual payoffs.
The issues of fairness and looking out for the other guys seem to be much less strong
when there are many players.
Anonymity kicks in, along with the feeling that what you're doing has such a small effect
on others.
So focus on a particular player who's revisiting her choice.
What does she want to do?
Well, she can work or shirk.
And no matter what P currently is, the shirk payoff is higher than the work one.
So she decides to shirk.
In particular, a person who's working is now going to stop.
This jumps her from the black line to the red line.
That's better.
But it also makes the value of P tiny bit smaller, moving the vertical line a little
bit to the left.
Just a touch.
That's going to make the payoffs for both types of workers just a little less.
But not much.
Now in the new position, someone else can reconsider their decision.
They're going to go through the exact same reasoning and end up by making the same decision.
I'm better off shirking.
Over time, there are less and less workers.
So the value of P moves further and further to the left and doesn't stop until it reaches
P equals zero, all the way to the left of the graph.
No one is curbing emissions.
And here's the social dilemma.
If everyone is shirking, everyone gets the red payoff at the left-hand side of the graph.
If everyone works, P equals one, and everybody gets the black payoff at the right-hand side
of the graph.
And that's a better payoff.
That is, if everyone works to curb emissions, the improved quality of the environment, more
than compensates for the extra effort involved in the work.
Everyone's better off.
But because the red line is higher at any point, people are always going to want to
shirk regardless of the current emission level.
After all, their shirking makes no difference in the world, really, but a big difference
to them.
This is the many player equivalent of the prisoner's dilemma.
It's usually called the tragedy of the commons.
I want you to realize how little I needed in our graph for this reasoning to go through.
The tragedy of the commons is going to occur if just two conditions are met.
First, the shirk line has to be above the work line, always.
This means that individually it's better for people to let somebody else bear the burden.
That leads to the everyone shirk solution.
Second, the right end of the work line is above the left end of the shirk line.
That is, the small degradations caused by individual shirking add up to a major effect
when there are a lot of shirkers.
That's a pretty simple set of conditions.
And having those conditions met is all too, well, all too common.
By the way, the name, tragedy of the commons?
The commons refers to common pasture land.
Those were available in many English towns.
Anyone from the town could graze their animals on the common for free.
In 1832, William Forrester Lloyd, a political economist at Oxford, asked, why are the cattle
on the common so puny and stunted?
Why is the common itself so bare worn and cropped so differently from the adjoining enclosures?
Well, you can give the answer now, can't you?
Here I am, welcomed to Oxford, 1832.
I got the common to pasture me animals, so that's nice, eh?
Common's not looking so good these days, and I'll tell you why.
Too many damn animals, that's why.
So I'm buying another cow.
Yeah, yeah, yeah, I know.
My extra cow's not going to help the commons, any is it?
Not stupid, just poor.
Poor he is.
It's not going to hurt bloody much any, either is it?
All those other animals about.
And for me and mine, having one more cow, even if it is a puny little runt, well it's
better than nothing in it.
So everyone does this, until the commons are so overtaxed that each animal is almost starving.
If everyone had reduced their livestock to fewer animals, everybody's livestock value
would have been higher.
Garrett Hardin came up with the name, The Tragedy of the Commons, in his article in Science
Magazine in 1968.
People were aware of this dilemma before, but Hardin stated it clearly and reasoned about
it formally.
And it's a tragedy in the literal sense, not simply unfortunate, inevitable, given the
preferences of the people involved.
Think about commercial fishing.
My extra net or two won't mean a whole lot to the fish population, but it will mean a
whole lot to my family.
Trouble is, everyone's thinking this way.
And the same theory predicts that you'll end up with a situation where everybody is getting
smaller payoffs than if they had exercised more restraint.
And that's what's happened, all over the world.
Off the grand banks in the North Atlantic, cod stocks were so plentiful that reportedly
you could dip a hat into the water and come up with cod in it.
That was the 16th century.
Commercial fishing in the area went on for 500 years, but in the 20th century, fishing
rates rose above the fish's ability to repopulate.
Patch sizes dropped.
So fishermen cast more nets and worked more hours to meet their goals.
In 1989, the cod population off the grand banks abruptly collapsed, leaving thousands
of fishermen without jobs and a decimated cod population that probably won't bounce
back in our lifetimes, if ever.
The grand bank story is being replayed all over the world and not just with cod.
In the North Sea, stocks are at about 10% of their 1970s levels.
It's even happening in the formerly pristine South Atlantic and Indian oceans and around
Antarctica, the tragedy of the commons.
And how about traffic congestion?
Too many cars on the road?
Still, you can probably get where you're going faster by taking your own car than by
taking something like a bus.
But less traffic would mean better times for everyone, regardless of their mode of transportation.
Get enough people on public transport, and the time saved from the cleared roads would
more than make up for the time needed to carpool or take a bus.
But the tragedy of the commons strikes again, so we spend hours sitting in traffic jams,
instead wasting time, wasting fuel, fouling the air.
At my university, the students organized a don't drive to school day.
The reports I heard said that the actually more students drove to school, expecting it
to be easier to find parking.
You played the tragedy of the commons on the first day, remember?
The button pushing game?
Pushing your button helped you, even if it hurt everybody else a little bit.
If no one pushed, no one shirked, everyone got the best possible pay off.
But as we saw, a lot of people chose to shirk.
From the individual game theoretic perspective, it's the right choice.
It's the dominant strategy.
It's a rotten answer.
It's the tragedy of the commons.
The tragedy of the commons shows that there's a hole in Adam Smith's notion of the invisible
hand.
Self-interested behavior here doesn't maximize the social good.
And why not?
Because the costs of the shirk that the shirkers create had to be borne by others.
What do I mean by social good?
Well, we could measure it as the average pay off to each member of society.
And there's an easy way to see this quantity on our picture.
Given the value P of workers in the population, I want you to look at the worker and shirker
payoffs.
From the workers pay off, draw a line going to the left.
From the shirkers pay off, draw a line going to the right.
You can see the two lines I'm talking about on the graphic.
The total area in the blue, the two rectangles combined, represents the average pay off per
player.
The bigger that area is, the better the social good.
In this picture, you get the biggest area, the biggest possible social good, when everyone's
working and no one is shirking, like this.
Since everybody is working here, there's only one rectangle.
Let's all do our part.
Is that what I'm saying?
Well, not always.
Look at this tragedy picture.
You can see that it is a tragedy of the commons.
Shirk is always above work, and the upper end of work is higher than the lower end of shirk.
So we expect everyone to shirk, giving us an average payoff of four.
If everyone worked, then the average payoff would be five, which is better.
That is, this rectangle with everyone shirking has an area of four, and that's not as good
as this rectangle with everyone working, which has an area of five.
But neither of these is as good as these two together, where 55% of the population works
and the rest shirk.
This division has a total area of just over seven.
In this problem, shirking confers a very big benefit when a lot of people are working.
Because of this, the social good is maximized when 55% of the people work and 45% shirk.
If this were the graph for our traffic example, it would mean that the total amount of travel
time used by society would be minimized.
If 55% of the people carpooled or took a bus, and the other 45% drove their own cars.
This kind of result isn't rare, and it raises a question, who gets to be the 45%?
Sometimes rotation schemes can be used so that I drive this week, and I take the bus
next week.
Often though, this isn't the case.
A solution like this one might be enforced because there's a subset of the population
that can be coerced or forced to be workers, while the rest shirk.
In effect, in this society, the society as a whole does better with 55% of its citizens
being second class and getting payoffs of a little over three.
Because of their work, the remainder of the citizenry can receive payoffs of about 12.
Again, the average payoff here is about seven, and this is the highest average payoff that
the society can get.
It's just that not everyone gets the average.
A more equitable solution can arise when transfer payments are possible.
That is, when the shirkers can compensate the workers for their efforts.
If shirkers could transfer about four units of payoffs to a worker, the payoffs would
be balanced.
In my example, the drive-alones might pay a driving fee worth four units of payoff to
save their time, and the travel costs of those used in public transport could be subsidized
with this money.
In this system, the shirkers are paying for the inconvenience that they cause, and the
free market can determine the appropriate size of the fees.
Once you start playing with these pictures, you can analyze a lot of different situations.
It's kind of fun.
Let's consider the Neighborhood Watch Program, in which townsfolk spend their time keeping
an eye on the neighborhood, and so decreasing crime in the area.
The picture might look like this.
Okay, what's going on here?
Well, start on the left side of the graph, where there are no watchers.
If I become a watcher, I can keep an eye on the area near my home, which helps me quite
a bit.
Pay off four.
A shirkers puts in no effort, but gets almost no benefit.
So workers do better than shirkers.
The more watchers there are, the safer the neighborhood becomes, which helps everyone.
That's why the lines are going uphill from left to right.
But when you get a certain number of watchers, the entire neighborhood becomes safe enough
that extra watchers don't really help that much.
Shirkers gain the benefit without putting in the work.
So the shirkers line rises above the worker line.
Okay, now imagine this neighborhood starting with very few watchers.
Then workers will do better than shirkers.
So people will tend to switch from being shirkers to being workers.
They'll watch.
So that will move us rightward on the graph, since we have more workers.
On the other hand, let us start with a whole lot of watchers on the right-hand side of
the graph.
Then shirkers make more, so some of the workers are going to become shirkers and move the
fraction of workers to the left.
You can see that these processes of change stop when the two lines cross.
From my particular picture, that's at about 40% of the population watching, when both
shirkers and workers get a payoff of 4.8.
Without outside intervention, this is the condition you would expect to see.
It doesn't maximize social good.
The green lines on my graph show that happens with about 80% of the neighborhood watching.
When the watchers get a payoff of 5.6, and those that don't watch get 9.6.
The watchers do much worse than the shirkers do, but note that even the watchers are making
more than they get at the 4.8 equilibrium.
This picture actually corresponds to the many player version of chicken.
You want to help basically if other people aren't, and you don't want to help if most
other people are.
You're best off doing what other people aren't doing.
It's sometimes called the volunteer dilemma.
By the way, the same analysis will hold when one of the lines is downward sloping, like
this.
This might represent the decision of whether to keep your convenience store open all night.
If you other store is open, then you get a lot of business, so workers do much better
than shirkers.
But the more stores that are open, the less business you get, and hence the downward
sloping line.
If your store isn't open, the more stores that are open, the better for you.
It's convenient.
Again, the crossing point is the equilibrium.
Here about two-thirds of the stores would be open.
That's more than one for the maximum social good.
Let's have more fun with these graphs.
Suppose that we reverse the worker and shirkers lines in the last picture.
We get this.
What could this correspond to?
Well, the particular example I've got in mind is suggested by my axis label.
In America, we use a system of measurement usually called English units, although they
aren't used in England.
The proper name for our system is United States customary units.
But most of them have their roots in historical English units, so I'll use that term.
Much of the rest of the world, of course, has gone to the metric system.
The metric system is demonstrably superior for a number of reasons, notably easing, converting
from one unit to another, or even remembering what those conversion factors are.
Anyone who knows the metric system can instantly tell you that there are a million millimeters
in a kilometer.
How many inches are in a mile?
Which covers more?
A paint that covers 120 square feet per gallon, or one that covers two square yards per pint?
The metric system even makes it easier to find good deals in the grocery store.
By the way, if you like the English system, I encourage you to embrace it in its full
richness.
The mass of an object, not measured in pounds, it slugs.
Or if you prefer, stones.
And why limit yourself to inches and feet and yards when you can use furlongs and elves
and fathoms?
I heard once that a NASA report gave all the velocities in metric units, and that some
member of a congressional committee evidently thought it was un-American.
So the report was redrafted using English units.
All the velocities were expressed in furlongs per fortnight.
It's one of those stories that if it isn't true, it ought to be.
So if the metric system is really so great, why hasn't it caught on in the U.S.?
Well, let's look at our graph again.
For no special reason, I've made the metric system shirking and English units working.
So we're way to the right of this graph.
Almost everyone uses English.
So which system should a kid learn?
Well, in a world with English road signs, English tools, English labels, English packaging,
the payoff is bigger for learning the English system, a payoff of five, rather than one
in my picture.
But suppose the society were at the 50-50 point of users using each system.
Then the graph shows that the superior metric system gives the higher payoff.
So the fraction of English system users would drop and drop and drop.
This would continue until virtually everybody used the metric system, which has happened
in a lot of other countries.
This model has three equilibria, all metric, all English, and a point about 63% English
where the lines cross.
This gives, by the way, the worst social good, and it's not a stable equilibrium.
The population moves a little bit left or right.
It starts a cascade that moves almost everyone to a single endpoint.
The same model, by the way, explains why we use an inefficient keyboard layout on our
computers, and why Microsoft doesn't have to worry in spite of numerous claims that
Windows is not the best operating system for a PC.
It explains why VHS cassettes took over the market even though Betamax might have been
better.
More recently, it explains why Blu-ray has stomped HDDVD.
This is the many-player version of the coordination game.
We may have a preference among our options, but we do best when we follow the crowd.
To end this lecture, I'm going to return to the many-player chicken game, the Volunteers
Dilemma.
The name of the game comes from a situation which requires someone to act, but it doesn't
require a lot of people to act.
When the power goes out in the neighborhood, someone has to call the power company.
But who?
My example is a famous but grisly murder case.
Any viewers not wishing to hear about Kitty Genovese in 1964 can stop the video at this
point.
You'll miss less than three minutes.
I'm including this example because what happened is so outrageous that it cries for some explanation.
Our topics today will bear directly on it, so I think it's worth telling the tale.
OK.
At about 3.15 in the morning, Kitty Genovese, a 28-year-old woman, was attacked.
She was in the parking lot of her apartment complex in New York City.
A man ran up behind her and stabbed her in the back twice.
Genovese cried out, oh my god, he stabbed me, help me.
She was hurt by neighbors.
The original newspaper account claimed that at least 38 people watched the attack, but
the number was probably closer to a dozen.
A dozen.
None of them called the police.
One eventually shouted for the attacker to leave the girl alone and the attacker fled
the scene, only to return about 10 minutes later.
He systematically searched to find the hallway that Genovese had staggered into, barely conscious.
There, he stabbed her several more times.
The wounds suggest that she was trying to defend herself.
Then he sexually assaulted her.
All this took about a half an hour, and when it was over, the girl was dead.
And during all that time, no one called the police.
One neighbor up the stairs from the hallway opened the door to watch the last part of
the attack, but did nothing.
This is truly, truly a dreadful story, and many people at the time said that it showed
the heartlessness of New Yorkers.
But there's something else going on here, which psychologists usually call the diffusion
of responsibility.
If you knew that nobody called the cops, it's certainly worth calling to get involved, giving
your name, giving evidence, the girl's life at stake.
But if someone else has already called, then the second caller is incurring these costs
for nothing.
You can actually do a formal mathematical analysis of this kind of volunteer's dilemma,
and the result is startling.
It can be the case that the more people who witness an event, the less chance that anyone,
anyone, reports it.
It's a startling bit of mathematics, but the Genovese story is a sobering, troubling
demonstration of the principle.
Please, keep it in mind when you find yourself in one of those situations, and we all do,
where you know that someone needs to act, but you're sure that someone else is going
to do it.
This is a tragedy, but it's one we can avoid.
