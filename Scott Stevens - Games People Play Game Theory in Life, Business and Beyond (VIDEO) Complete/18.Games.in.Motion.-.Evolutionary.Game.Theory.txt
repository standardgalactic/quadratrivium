Two lectures ago, I identified some shortcomings of game theory. I focused on three in particular,
building with payoffs, spontaneous equilibria, and rationality. Since then, we've seen some
way that some of these shortcomings can be addressed. The problem of payoffs is a real
one, but the problem isn't with the idea of payoffs. It's figuring out what the correct
payoffs are. Psychology, sociology, and neurobiology are helping us to do that, to better understand
how factors like a sense of fairness can modify our perceived payoffs. In fact, there's
a whole new discipline, neuroeconomics, that's trying to replace the classical homoeconomicus
with something a little bit more like the real homo sapiens. Our discussions of collective
games suggested a way to address the spontaneous equilibrium problem. Players can periodically
revisit and revise their strategies. The equilibrium behavior can evolve over time as a result
of these choices. One can argue that this really means that the players are actually
playing an iterated game that's perhaps different from the one shot. Perhaps, but the choices
that our players made in the last lecture didn't rely on the history of the game, only
on the current state of society. Today, I'm going to take this evolution through time
idea one step further. My topic is evolutionary game theory. It borrows from biology in its
terminology and in its paradigm. This version of game theory rests on a different foundation
than the one that we've developed so far. We're going to be getting rid of the requirement
that the game become a knowledge. We're even going to be getting rid of the requirement
that the players be rational. And in spite of this, we're going to see that many of
the results that we've seen already are results that can be paralleled in the field of evolutionary
game theory. So, let's get started. I'm going to restrict my attention today to interactions
between two members of an individual species. That simply means that the two individuals
interacting will be drawn randomly from the same pool of contestants. But within this
species, this population, different individuals may display different behavior patterns.
The behavior patterns of a given individual is called its phenotype. This corresponds
to its strategy in the traditional game theory. The difference is the phenotype isn't something
that the individual can consciously choose. Phenotypes are hardwired. An individual can't
change its phenotype any more than you can change your height. But a population may consist
of entirely one phenotype or it may consist of a mix. If all of its members have the same
response patterns, they're all of the same phenotype. A population like this is called
monomorphic from the Greek meaning one form. Other populations may include two or more
phenotypes. Each individual is hardwired to play a certain way, but different individuals
might be wired differently. In a contest, one may be a hawk willing to fight for a
prize while the other may be a dove who's going to retreat from a fight. A population
with multiple phenotypes is called polymorphic, many forms. How's this going to work? Well,
imagine a population of 60% hawks and 40% doves. Pick one at random and watch its behavior.
60% of the time, it's ready to fight. 40% of the time, it's ready to run. Each individual
is hardwired to either always play hawk or always play dove, but in watching encounters
between members of the species, I see a species that acts like a hawk 60% of the time and
acts like a dove 40% of the time. That is, together, the individuals in this polymorphic
population behave like a person playing a mixed strategy. Actually, there's nothing
to stop a single phenotype from being hardwired to use a particular mixed strategy. We could
imagine a phenotype that when confronted with a situation acts as a dove 60% of the time
and as a hawk 40% of the time and what they act like is chosen randomly. You could then
have a monomorphic population, all the same phenotype, but still see mixed strategy behavior.
When we describe these things in terms of hawks and doves, we're seeing a mix. So, monomorphic
populations aren't the same thing as pure strategies. Okay, we've got our players, each
with its own phenotype. Now, they interact. Pick two at random and play out their encounter.
Each receives a payoff at the end. Sometimes the individual will have a good encounter.
Sometimes a bad one. But in evolutionary game theory, it's not the individual that we're
really interested in. It's the phenotype. When a member of this phenotype encounters
a member of that phenotype, on average, how do they do? In fact, we're really interested
in even a larger question. How do members of this phenotype do in the population as
a whole when compared to members of some other phenotype out there?
To make this clearer, let me stick to my hawk dove phenotypes. Let's say the population
is only 10% hawks and 90% doves. How would we expect these phenotypes to fare? I'm a
hawk. 90% of the people I meet are what you call doves. They back down, I get the prize.
Good. Eh, 10% of the time, hawks. So, bada-boom, we tangle. One of us gets the prize. One of
us gets a busted beak. That's life. But, like I said, there are many hawks around. So, life's
good. How about a dove? Well, most of the time, I meet other doves. You know, I mean, we don't
fight enough and okay. Usually we kind of put on a show, you know, try to get the other
guy to back down maybe. Sooner or later, somebody gets tired and leave and that's a lucky day
for the other dove. I guess I win my share. Of course, with a hawk now, forget it. Time
to scoot. I don't win no prize, but I don't get no broken bones, neither, you know what
I mean? So, in a population that's 90% hawk and 10% dove, hawks get everything and 90%
of their encounters at no cost. In 10%, they have a 50-50% chance of getting beaten up
a bit or getting the prize. They get the prize 95% of the time and get beaten up 5%. Doves
never get beaten up, but they get the prize only 45% of the time, half of 90, and they
had to put on a show to do it. As long as the damage from a fight isn't too severe, it looks
like the hawks have the better of the situation. And that means we'd expect hawks to grow at
the expensive doves in this population. How well a phenotype does on average is called
its fitness. It's the same idea as expected payoff in traditional game theory. Obviously,
fitness depends on the mix of phenotypes in the population. When one phenotype is more
fit than another, its proportion rises in the next generation of the population. In Darwin's
theory, this is natural selection. When we're talking about evolutionary game theory, we're
not necessarily talking about physical reproduction, though. Successful phenotypes aren't necessarily
based on genes. With humans, for example, successful strategies may be shared with friends
and colleagues, or those practicing unsuccessful strategies may change them to emulate those
who did better. Whatever the mechanism, the effect is the same. The population proportionately
ends up having more of whatever phenotypes were winners and less of whatever phenotypes
were losers. Evolutionary game theory looks at the long term results of what this will
be. There are two common ways of asking the question, but they usually come down to the
same thing. The first is dynamic. We start with a mix of phenotypes and let the population
evolve over time. What's the long term distribution of phenotypes going to be? The other approach
is static. Suppose you start with a distribution of phenotypes that's stable over time. Can
a small number of a different phenotype successfully invade that population? In all of my models,
I'm going to assume a large number of individuals in the original population. It simplifies
the math a bit, and it's usually realistic, too. So let's look at a simple example to
get started. My population has two phenotypes. I'll call them Scrooge and Grim. The game
that they're playing is a familiar one. It's a prisoner's dilemma. The Scrooge type always
betrays. The Grim type betrays until it is betrayed, and it'll betray, I'm sorry, it
cooperates until it's betrayed, and then it will betray from then on. It's playing a Grim
trigger strategy. Mathematicians are interested in the model and technique rather than the
particular example, and we're talking about a very general structure here. The players
could be female vampire bats deciding whether to feed the young of other female vampire
bats, or it could be about plants deciding whether to release toxins around their bases,
or any of a number of other applications. I'm going to cast it today as two employees
from a company put together for a one-day project. They can either cooperate, or each
can try to grab the credit. We're looking at a population where individuals meet, have
one encounter, and then separate. Either they're likely to never meet again, or when they do,
or histories don't make any difference. Maybe they don't remember, maybe they don't recognize
each other. What happens in an encounter? Well, when two Scrooge's meet, they both
betray, so they both get one. When two Grim's meet, they both cooperate, so they both get
two. A Scrooge will betray a Grim, so the Scrooge gets three, and the Grim gets zero.
Since they only ever have one interaction, the Grim can never retaliate. So, what happens
to this population of Scrooge's and Grim's over time? Well, that depends on the mix.
What fraction of the population is each phenotype? Let's call P the fraction of the population
consisting of Scrooge's. Then Grim's make up the remaining one minus P. So, when an
individual runs into another, the probability is P that that other guy is going to be a
Scrooge, and one minus P that he's going to be a Grim. Okay. Now, remember how we compute
expected payoff? Probability times payoff added up over all the cases. So, what does
all this tell us? Well, look at the average payoffs for the two types. The Scrooge, three
minus two P, is always bigger than the Grim's two minus two P, no matter what P is. That
is, Scrooge's are always more fit than Grim's. So, in the long run, Scrooge's are going to
wipe Grim's out of the population. Scrooge's read faster, if you like. Once the Grim's
are gone, what happens when a few Grim's from the next company over wander into this Scrooge
population? Well, they're in big trouble, that's what. P would be almost one, so the
Grim population would have a payoff of about zero, while the Scrooge payoff would be about
one. So, the Grim's would soon be wiped out again. That is, a population of all Scrooge's
can't be invaded by Grim's. Evolutionary biologists call a population that can't be invaded by
another phenotype an evolutionarily stable strategy, which they shorten to ESS. So, we've
just seen that an all Scrooge population is an EN at ESS. In fact, it's a monomorphic
ESS, since the ESS includes only one phenotype, Scrooge's. How about if we have an all Grim
population? Then everybody cooperates. Happy day. Yeah. Until a few Scrooge's show up,
either from migration or from mutation. In a society that's almost all Grim's, P is
close to zero. This means that a Scrooge has a fitness of about three, and a Grim has a
fitness of about two. Scrooge's prey on the gullible Grim's and eventually take over.
So a monomorphic Grim population can be invaded by a few Scrooge's. So, a monomorphic Grim
is not an ESS. I've written a little spreadsheet application to show how this happens over
time. This population started out on the left with one percent Scrooge's. You can see they
multiply at the expense of the Grim's. As the generations pass, their blue line goes
up and up, and the Grim's red line goes down and down. By generation 40, the Grim's are
a fairy tale. Sorry. By the way, the actual number of generations that pass depends on
the scaling factor in the model, but the shape of the curves is unavoidable. In fact, no
matter what mix of Scrooge's and Grim's you start with, as long as there are some Scrooge's,
you'll eventually approach an all Scrooge population.
Okay. Let's stay with the Scrooge's and Grim's, but imagine that they even count as which
last two steps, not one. You can imagine that we're talking about them being paired with
a co-worker for two days. On each day, each worker can cooperate or grab the credit. Again,
Scrooge's always betray. Grim's will cooperate until betrayed and then will betray after that.
The new payoff matrix now looks like this. A Scrooge's Scrooge pairing will betray on
both days, getting one point each day for a total of two. A Grim-Grim pairing will cooperate
on both days, each getting four. When a Scrooge and a Grim interact, on the first day, the
Scrooge gets three and nothing for the Grim, but then they both betray on the second day.
Okay. What happens to this population? I'd like you to notice that both Scrooge's and
Grim's do equally well against Grim's, four points. Scrooge's do better against other
Scrooge's than Grim's do, though. This means that if a society contains both phenotypes,
the Scrooge's will again outperform the Grim's and the Grim's will again die out.
Look at the expected payoff. Compare the two fitness functions. If there are any Scrooge's
at all, then P is bigger than zero. So Scrooge's are marginally fitter. They grow a bit and
then a bit more until eventually they trash the Grim's again. As before, Scrooge's are
a monomorphic ESS and Grim's are not. It may take a few Scrooge's a long time to wipe
out the Grim's, but it'll happen. With our data, it took about 300 generations for the
Scrooge's to get to 20%. As you can see on the graphic after that, the Scrooge's are
as you can see on the graphic after that, it went fast. How can you spot a one evolutionarily
stable strategy, a monomorphic ESS? With only two phenotypes, it's pretty easy. We're talking
about resisting invasion. If you're better at dealing with the population than the invader
is, you're an ESS. If you tie the invader, but you're better at dealing with the invader
than the invader is, then you're still an ESS. Otherwise, you can't repel an invasion
and you're not a monomorphic ESS. Okay, let's carry the coworker problem one more day to
a three day job. Then two Scrooge's will betray three times in a row for three points. Two
Grim's will cooperate for three days in a row for six points. When a Scrooge meets a Grim,
the first day it gets three to the Grim's none and then they both betray for two days.
Scrooge's score, Scrooge's five, Grim's two. Look at the fitness functions, the average
payoffs. Who's fitter? Well, it depends. If P is small, not many Scrooge's, then Grim's
are better. Their fitness is just below six and the Scrooge's is just below five. But
if P is large, lots of Scrooge's, then Scrooge's are better. Their payoff is a bit more than
three compared to the Grim's payoff of a bit more than two. If you set these two fitness
functions equal to one another, you find that they're the same when P equals one half. When
the present number of Scrooge's and Grim's is the same, they both have a fitness function
of four. So in this evolutionary game, whoever has the majority at the outset wins. If there
are more Scrooge's, Scrooge's take over and can't be invaded. If there are more Grim's,
Grim's take over and they can't be invaded. Here are some sample graphs. The first one
starts with 51% Scrooge's. The second one starts with 51% Grim's. And what happens when
exactly 50% of the population is Scrooge's? Then both sides are equally fit and so the
50-50 split persists. It's an equilibrium. But it's an unstable one. A tiny nudge from
the outside, one way or the other, a migrant, a mutant, will start a cascade to one of the
two monomorphic ESS's. So we don't call this 50-50 mix an ESS because it's not stable.
Could you ever have a polymorphic ESS, more than one form coexisting but in balance? To
look into this, I'm going to go back to our friends from the earlier lecture, the Hawks
and the Doves, earlier in the lecture, the Hawks and the Doves. I'll put some numbers
to this. To make it specific, suppose that two individuals are in a contest for a prize
worth 50 points. If they're both Hawks, they fight until one's hurt and the other's victorious.
Let's say the injury costs the loser 80 points. When a hawk meets a dove, nothing to talk
about. The hawk gets the 50 points and the dove gets nothing. When two Doves meet, each
puts on a display, trying to convince the other one to give up. Eventually one quits
and the other one wins the prize. Both Doves pay the same display cost, though, until the
show's over. Let's say the display cost is 10 points on the average. You could imagine,
for example, two job applicants at a reception, each waiting for the other one to leave so
that they could get the last word with the recruiter. Both pay the waiting cost until
the loser leaves. Okay, let's clean up the matrix to show the expected payoffs. Half
of the time the hawk gets 50 and half of the time it loses 80, so her average payoff against
a hawk is half of 50 plus a half of negative 80 or negative 15. When two Doves meet, half
the time the dove wins, getting 50, and half the time it loses, getting zero. That's 25
on average. But when or lose, the dove pays the display cost of 10. So the average payoff
to a dove in a dove-dove meeting is 15. And, of course, a hawk gets everything and
a dove nothing in a hawk-dove encounter. Okay, check the matrix. Who does best when
meeting a hawk? Doves do. A hawk, on average, loses 15. A dove gets nothing when it meets
a hawk, but that's better than negative 15. Who does better when meeting a dove? Hawks
do. Hawks get 50 points from meeting a dove, while doves, on average, only get 15. So what?
So when there are a lot of hawks around, it's best to be a dove. And when there are a lot
of doves around, it's best to be a hawk. Look at the fitness functions. Sure enough,
if P is small, not many hawks, then hawks are more fit. If P is big, lots of hawks, then
doves are more fit. Set these two equal, and you'll find out that they come out to be equal
when P is 0.7. If the population is 70 percent hawks, then both hawks and doves are equally
fit, a fitness of 4.5. You can see this borne out in the graphs. I've started with lots
of hawks, then lots of doves, then equal numbers of both. No matter how the population starts,
it quickly approaches the polymorphic ESS of 70 percent hawks and 30 percent doves.
Okay, let's stop for a second. I want to see how our new work compares with the work from
earlier in the course. Here's our matrix for the first game. We found today that the only
ESS for this game was monomorphic Scrooge, but suppose I had given you this matrix before
today. You'd say it's a two-player, non-zero sum, simultaneous game. How would you solve
it? Well, look for dominant strategies. For both players, the Scrooge strategy dominates
the Grim one. Each player is always better off playing Scrooge, so the only Nash equilibrium
in this game is Scrooge-Scrooge. That is, everyone's playing Scrooge all the time. And
that's exactly what we see when we say that the only ESS is monomorphic Scrooge. How about
the two-day game? Now, Scrooge weakly dominates Grim. There are two Nash equilibria, Scrooge-Scrooge
and Grim-Grim, but you'll recall in working with simultaneous games that we often restricted
ourselves to admissible equilibria, ones that weren't weakly dominated by anything
else. And there's only one such equilibrium, Scrooge-Scrooge, with everyone playing Scrooge
all the time. And that's also the only ESS of this game, monomorphic Scrooge. I think
you're getting the idea, but let's go on. Three-day matrix. This game has three equilibria.
Two are admissible and in pure strategies, Scrooge-Scrooge and Grim-Grim. You'll recall
that in this game Scrooge was a monomorphic ESS, and so was Grim. We can find the mixed
equilibrium in the traditional game by solving our usual equations or doing the usual tricks.
I'll leave that to you. If you do it, you'll find out that the equations that you're solving
are exactly the ones that we computed in finding average fitness. The mixed equilibrium strategy
has each player playing each choice half the time. In the evolutionary game, we saw an
equilibrium when the population was divided between Scrooge's and Grim's, but it was
unstable. In a tiny imbalance between the types set the population all in one ESS or
all in the other. Clearly, we're seeing a strong connection between equilibrium behavior
in traditional game theory, and evolutionarily stable strategies look a lot like optimal
strategies. Let's look at Hawks and Doves. To get our full complement of birds in this
lecture, I'll point out that the game that the Hawks and Doves are playing is really
chicken. Each player decides to choose the option not chosen by the other. This game
too has three equilibria. In pure strategies, Hawk Dove and Dove Hawk, and in a mixed strategy,
70% of the time Hawk and Dove the rest of the time. Average payoff for that one is four
and a half. How does this match up with the evolutionary approach? Well, row playing Hawk
while column plays Dove doesn't make sense in our evolutionary model, not all the time.
The two players are drawn from the same population, one species, remember? So the population can't
be all Hawk and all Dove. So the only physically meaningful equilibrium in this problem is the
one which has us playing Hawk 70% of the time and Dove 30%. And the only ESS for this game
is the polymorphic population of 70% Hawks and 30% Doves. It may seem to you that we're
just covering the same ground that we did much earlier in the course. If so, look again.
Yes, we are getting the same answers. We're seeing a strong correspondence between Nash
equilibria on the one hand and the ESSs of evolutionary games. But there are some important
differences. And here's the biggest. We never required the players to be rational. We didn't
even require them to know the payoff matrix. In the evolutionary model, a phenotype grows
because it works. No one consciously has to choose it. It's easy to show that any ESS
is a Nash equilibrium, but we arrive at it without requiring players to compute probabilities
or strategies. There aren't even any probabilities to compute. Remember, each of our individuals
is hardwired to their phenotype. They're not choosing anything. What we've been looking
at so far is dealt with symmetric games. The two players face exactly the same situation.
It's not necessary to have that for the evolutionary approach to work. If we draw the players from
two different species, then they can have different choices or they can have different
probabilities in the population. The battle of the sexes can be handled in this way, for
example. If you're curious, there are two ESSs in the battle of the sexes, one in which
men always do what they want and the women always go along and one in which the women
always do what they want and the men always go along. And if you think I'm going to make
any comments about that, you are out of your mind. You can handle as many different phenotypes
as you want, and this brings up a clarification I need to make. I told you that evolutionarily
stable strategies can't be invaded by another phenotype, and this is true. But only within
the context of the phenotypes possible, the options that exist within a game. In the three
days Scrooge-Grim game, both Scrooge and Grim were monomorphic ESSs. Once established, they
were both bulletproof from the other phenotype. But I could introduce a new phenotype in this
game. Let's call it a Sneak. A Sneak plays just like a Grim, but always betrays on day
three. This new type, it turns out, can invade an all Grim population. So in the universe
of Scrooge's Grims and Sneaks, Grims are no longer an ESS. Only Scrooge is. You can
get some pretty complicated behavior in such systems. Think about it. Scrooge can invade
Grim, but Sneak can, and it turns out that Scrooge's can invade Sneaks. So start out
with a population that's almost all Grims, but season it with a few Scrooge's and Sneaks.
The Sneaks will eat the Grims, and prosper, while the Grims dwindle. Then the Scrooge's
will eat the Sneaks. By the way, if you analyze the payoff matrix for this game, you'll find
that there's only one admissible equilibrium in the game. Scrooge. Like the rest of game
theory, evolutionary game theory gets quite deep. The mathematics behind it can get rather
sophisticated. I'm not going to develop the math for this last example I'm about to do.
It requires integral calculus, but I think you'll find the results interesting. The game
is commonly called the War of Attrition. There are lots of ways to think about this game.
As the name suggests, you're going to have a war for a prize going on in which both sides
are suffering losses until one side gives up. The problem, of course, is that one can end
up with a Pyrrhic victory. You pay more for the win than the value of the prize. We could
imagine a war of attrition in nature. Two animals could make an aggressive display without
actually fighting until one gives up. Think about the mating behavior of a lot of species.
See what I told you about the $100 auction when it went for $465 to the Wall Street financiers?
That's an example. The winner and the second place bidder both had to pay their bids. It
would be a war of attrition if they both had to pay the winning bid, but only the winner
got the $100. Something similar, but more complicated, goes on in the Olympics, assuming
that the gold medal is the only reason to train. Everyone pays the training cost, but
only one person gets the prize. To fix ideas today, I'm going to focus on
the example of a $100 bill auction. I'll conduct it a little differently. Both players are
given a buzzer. At the beginning of the auction, the clock starts counting from $0 upward.
When someone buzzes in, the clock stops. The person who pressed the buzzer loses. The other
player gets the $100, but both players must pay the money shown on the clock. If they
both buzz simultaneously, they both get half of the $100.
While there is a Nash equilibrium for this game, one player buzzes immediately and the
other wouldn't buzz until after a hundred. This equilibrium requires that the two players
coordinate and adopt different strategies, essentially decide who's going to be the
winner. They may have a tough time agreeing on this.
The evolutionary game theory analysis of this game is quite interesting. A phenotype is
specified by how long it's willing to compete before quitting, the dollar amount at which
it will push the buzzer. We're looking for evolutionarily stable states. Can there be
a monomorphic one, one that can't be invaded? Well, suppose that a monomorphic population
pushes the button at something less than a hundred. Nineties, say. Now imagine an invader
that waits just a little bit longer, say 91. Then the invader wins every contest against
a member of the population, because the population always pushes at 90. The invader's payoff
is therefore $10 against any member of the population. It gets a hundred and pays 90.
The average payoff to one 90 pusher against another is negative 40. They both pay 90,
but only get half of the 100, which is 50. So a monomorphic population that pushes before
a hundred can be invaded by someone who pushes just a little later.
Okay, how about a monomorphic population that pushes in sometime later? Let's say after
50. Ninety, for example. Well, imagine an invader who buzzes immediately. This player
gets a payoff of zero, which isn't that great. But a member of the population playing against
another member of the population does worse. Again, if I buzz in at 90 and you do two,
we both get 50. That puts us both 40 in the hole. That's worse than buzzing in immediately
getting zero. So this phenotype can be invaded by someone who presses immediately. A population
that waits more than 50 can be invaded by buzzing immediately. A population that buzzes
in before 100 can be invaded by one that waits a little longer. So there are no monomorphic
ESSs for the war of attrition. But there is a polymorphic one. You could think of the
optimal strategy as being essentially this. Each time that the dollar clock clicks, one
more dollar, give yourself about one chance in a hundred of buzzing in. The actual chance
should be .995%. For example, generate a random number from one to 100. And if it's 100,
buzz in. If not, wait until the next dollar and do the same thing. You'll note there's
a chance that you actually won't buzz in before 100. That's okay. You can show mathematically
that this strategy outperforms any monomorphic strategy, any fixed stopping point by at least
$19 on average. Wild, huh? Maybe we should tell Wall Street.
