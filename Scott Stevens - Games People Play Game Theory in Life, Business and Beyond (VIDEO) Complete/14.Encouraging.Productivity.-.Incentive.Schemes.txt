Why don't people do what you want them to?
For most people that ask that, the question is really more of a complaint than a question.
You already know why people don't do what you want them to.
It's because they're too busy doing what they want to.
So when you're considering a relationship with another person, professional or personal,
the first step is getting a sense of what they can do and what they want to do.
What are their abilities?
What are their motivations?
That's what screening was all about and signaling is telling another player about what you are.
People don't get to choose their types.
They just are.
If I got to choose my type, I can tell you I'd look a lot more like a young Peter O'Toole
and be more than moderately rich.
But suppose that the screening and signaling is done and you know the kind of person you're
dealing with.
They're still going to do what they want to do if they're rational.
They're going to factor in everything that they care about and then choose the option
that gives them the best overall satisfaction.
So if you want to get people to do what you want them to do, you're going to have to
create an alignment between their desires and yours.
That's today's topic, incentive schemes.
In almost all of my examples today, my incentives and payoffs are going to be monetary.
We've already talked about the dangers of this.
Payoffs have to be factors that factor in everything that a player cares about and they
should be measured in utils or happiness points.
Utils have nice mathematical properties, taking into account a player's feelings of
risk love and risk aversion and so on.
In particular, remember, they work well with expected value arguments.
If I give you a choice between a 50-50 shot at 100 utils or 50 utils for sure, you really
won't care which one you get.
50 for sure or a 50-50 shot at 100, don't care.
So in my examples, when I'm talking about payoffs in dollars, I'm really implying that
for the people involved, one dollar equals one util.
That is, all a player cares about is how much money on average they're getting.
To do this analysis more properly, I really should be factoring in extra considerations,
non-monetary considerations, attitudes of risk love or risk aversion, or non-monetary
considerations as well in general.
But this wouldn't change the essential arguments.
It would make them a lot harder to follow, more mathematically complicated.
I'm choosing not to do that, but please remember that with a little more care, such factors
can be included.
As a reminder of this, let's start with an example of an incentive scheme of a different
kind.
Western Electric had a large factory complex in Cicero, Illinois for most of the 20th century.
The Hawthorne works.
In the 1920s, they started doing a set of experiments to try to increase productivity
on the assembly line.
They raised the level of the lighting to see what happened, just a little bit.
The workers produced more.
So they raised the lights a little bit more.
The workers produced still more.
Well, it looked like increased lighting, increased the amount of productivity.
But the experimenters understood the idea of the scientific method.
They lowered the levels of light, slightly below the original level.
The workers produced more.
In fact, they kept on lowering the lights until it was almost impossible to see, and
the workers were still producing more.
The experimenters puzzled over what the heck was happening, while productivity levels gradually
slid back to the pre-experimental levels, and then it hit them.
It wasn't the lighting changes that were producing more outcome.
The workers were producing more because somebody was paying attention to them.
So you'll be seeing monetary payoffs in almost all of the examples for the rest of this lecture,
but keep in mind that nothing in game theory says that a player's payoffs have to be monetary
or selfish or driven by the desire for anything in particular.
The Hawthorne effect, as it's come to be known, is an interesting example to keep in mind.
Alright, let's look at an extremely common incentive problem, the principal agent problem.
I'm your employee.
You want me to work hard, because the firm will, or at least should, do better if I do.
But why should I?
The obvious answer is that you'll adequately compensate me for my extra effort.
As long as the expected game that the firm makes from my extra work is worth more than
what it costs me to give it, we should be able to strike a deal that's mutually satisfactory.
The trouble is, what if you can't monitor my efforts?
Look at me.
I'm a mathematician.
When I'm doing my best work, I look a lot like a guy who's just daydreaming.
The problem is, is that when I am daydreaming, I look just the same way.
You may be willing to reward me for my exceptional effort, but my effort isn't directly observable.
Information asymmetry, once again, causes problems.
I'm not going to do the hard work unless you pay me more.
You're willing to pay me more to have me do the hard work.
But if you can't tell whether I'm working hard or not, then why don't I just take the
money and goof off?
The difference between this idea and our topic from last lecture is that while I can't choose
my type, I can choose whether to work hard or slack.
So you can try to do more than determine my type.
You can try to change my behavior to what you want it to be.
That's an incentive scheme.
Let's look at a particular example and see how this works.
Your company is bidding on a job that's worth a quarter of a million dollars to the firm.
You assign the job of generating the bid proposal to Nathan, your most talented proposal writer.
If Nathan works hard on this project, there's an 80% chance that it will be accepted.
If he works normally, there's a 50% chance it will be accepted.
Nathan's willing to put in the usual amount of work for $30,000, but needs $60,000 to
work hard.
Let's start by ignoring the information asymmetry.
You can watch Nathan incorrectly determine whether he's working hard or not.
What do you do and what does he do?
Well, how much is Nathan's extra effort worth to you?
If he works hard, your expected payoff is 80% of the $250,000 or $200,000.
I got this by the same old expected value calculation we've been using throughout the course.
80% of the time you get $250,000, 20% of the time you get ZIP.
So the expected average is 80% of $250,000.
On the other hand, if Nathan works normally, you have only a 50% chance of getting the
job and half of $250,000 is $125,000.
So Nathan's extra effort takes you from $125,000 up to $200,000.
His extra work increases your expected payoffs by $75,000.
Okay.
Looks like you and Nathan can strike a deal.
Nathan needs an extra $30,000 to do the extra work.
You can afford to pay up to $75,000 for that extra work.
You can negotiate the difference or if you're in a position to make a take it or leave it
offer, you can offer him just a little bit more than $60,000 to work hard and nothing
for normal work.
Remember that you have perfect information in this version of the problem.
You can see how hard he's working.
So you can essentially compel Nathan to work hard for a little over $60,000.
And it's so you can pocket on average $200,000 minus the 60 plus or just under $140,000.
Nathan's payoff minus his pay of $60,000 for the work he's putting in is a minimal amount,
but it's positive.
If Nathan were in a position to make demands, he could ask for the lion's share of that
$75,000 surplus from his expected work and leave you with just a small surplus.
Or the two of you could negotiate to find some better split.
You can see why I raised the issue of dollar payoffs and utility earlier in the lecture.
The calculations I just did were based on the company's average payoffs.
But is the company really going to be indifferent between a guaranteed $200,000 and an 80% chance
at $250,000?
Probably not.
But if I change these payoffs into utils, we could do the same calculation in the same
way that would account for the risk-love or risk aversion of the company.
It's just uglier mathematically.
You may also be thinking that your current situation, giving Nathan only slightly more
than $60,000 or giving him quite a bit more, could influence your future relationships with
Nathan or maybe even other employees at your company.
That's a valid point, and we'll be taking a closer look at that in our very next lecture.
We will get there, honest.
But for now, let me set these finer points aside.
In that case, the perfect information problem was pretty easy.
But what if you can't directly observe Nathan's choice?
What can you do to get him to work hard?
The problem at first blush seems to be insurmountable.
After all, you're going to have to offer him the deal before he does the work, assuming
that he does take it.
Why would he want to work hard?
He'll get the same money by working normally.
Did somebody say commission?
That's the key idea.
Make Nathan's pay contingent on something that you can't observe, the success of the
project.
The project's success isn't perfectly correlated with his effort, but the project is more likely
to succeed when Nathan's working hard.
So here's the idea.
Nathan gets a base salary, and then you pay him a bonus if the project's successful.
Can this work?
Well, let's play a bit with the math and see.
Suppose you offer Nathan a base salary of S, and tell him that he gets a bonus of B
if the project's successful.
So you'll want to choose S and B so that they induce Nathan to work hard, but you don't
want to spend more than you have to.
What conditions do you have to satisfy?
There are three.
First, you have to make it worth his while to work hard.
So when he works hard, he has to make $60,000 or more.
Second, working hard has to look better than working normally.
And third, of course, the amount that the company makes from having Nathan work hard
has to be bigger than the profit it would make without the incentive pay.
It's foolish to induce Nathan to work hard if it's better for the company if he works
normally.
Okay, let's look at each of these.
First, we have to make it worthwhile for Nathan to work hard.
You'll recall that to work hard, he has to be paid at least $60,000.
So Nathan needs $60,000 at least.
Since his new salary is contingent upon a random event, the success of the project,
what we really mean is his average or expected salary has to be at least $60,000.
So what's his expected salary if he works hard?
Well, if he works hard, the project has an 80% chance of success and a 20% chance of
failure.
So 20% of the time, Nathan gets only his base salary, S. The other 80% of the time,
he gets the bonus too, S plus B.
You can see when the algebra clears, this is just S plus 0.8B.
We want to say that Nathan will do $60,000 of work for this salary so that we need S
plus 0.8B has to be at least $60,000.
This is generally called the participation constraint.
It says that doing hard work is better than not working.
Okay, our second requirement was that Nathan's better off working hard than he is by working
normally.
How much does he make by working normally?
Well, when he works normally, the project has a 50% chance of success, so half the time
he gets his base salary, S. Half the time he gets S plus B. And again, when you work
out the algebra, this comes out to be S plus 0.5B.
But it costs Nathan $30,000 to do his work.
So his surplus or gain from working normally is S plus 0.5B minus the $30,000.
While his gain from working hard is S plus 0.8B minus the $60,000.
It costs him to do it.
So Nathan is going to prefer to work hard if S plus 0.8B minus $60,000 is bigger than
S plus 0.5B minus $30,000.
His gain from hard work is better than his gain from normal work.
Now I'll do some easy algebra.
The S terms drop out of both sides, and when you rearrange, you get 0.3B is bigger than
$30,000, or B is bigger than $100,000.
This constraints usually called the incentive compatibility constraint.
It says that working hard is better than working normally.
Now the company doesn't want to pay Nathan more than it has to, so they'd like S and
B to be as small as they can get away with.
If you replace the greater than symbols in the two constraints with equal signs and solve,
it's pretty easy.
In the second equation, the bonus has clearly got to be $100,000.
Plugging that into the top equation, well it's this.
These values, solved by using the equal signs, made Nathan indifferent among his options.
To make working hard a little bit more attractive than working normally, or not at all, you
need to make B a tiny bit more than this, just over $100,000.
So you offer Nathan a bonus of just over $100,000 if the project is successful, and his base
salary is negative $20,000.
Negative $20,000, yeah.
I mean, if Nathan works hard, there's an 80% chance the project is a success.
So the bonus itself, on average, is worth $80,000, and that's $20,000 more than he needs to
work hard, so his base salary is negative $20,000 on average.
Well, some of you may have been willing to ride with me when I ask you to set aside issues
of risk love, and risk aversion, and fairness, and repeated games, and all of that stuff,
and I do thank you for it.
But this may be too much.
Who would take a job for a negative base salary for goodness sake?
Okay, I grant you your point.
Our relent.
But I will point out that such jobs do in fact happen.
People can buy into partnerships, for example.
In doing so, they provide a cash payment to the firm up front in anticipation of a fraction
of the firm's earnings later.
This negative $20,000 could be interpreted as a kind of commitment, a personal investment
of the project, against future projected earnings.
That said, I have to agree that it's unreasonable to imagine that, in most cases, Nathan would
accept this kind of a deal.
Negative S is a pretty hard thing to argue for.
So you as the firm make S as small as you can reasonably do, $0.
That is, Nathan's salary is straight bonus.
If the proposal is accepted, he gets $100,000.
If it isn't, zip.
That's not quite as bad as a negative base salary, but is it really believable?
Would anyone ever do this?
Well, Lincoln Electric Holdings in Cleveland has been doing it for more than 60 years.
Its 1800 production workers get no base salary.
They make welding and cutting products and have more than $1 billion a year in annual
sales.
Lincoln Electric won't lay off any of its employees, even during hard times, because
it pays them only on the basis of how many units each employee produces and a profit
sharing bonus.
If the market's bad enough, it shortens worker hours.
Admittedly, this approach is extreme, but linking employee pay to observables in company
success has found wide acceptance in business.
A survey by Towers Perrin showed that most firms use merit pay of some sort, merit pay
or incentive pay.
It appears that which system is used has a strong impact on its effectiveness.
Programs that tied rewards to overall company performance seem less effective than those
that tied rewards to team performance.
According to the self reports of companies, only 17% of those that tied the merit pay
to company performance saw significant impact on their productivity.
31% of those that tied it to team performance did.
Both of these numbers are actually relatively low, but some programs may be poorly designed.
According to William Abernathy, an incentive pay consultant, the key to successful incentive
programs is frequent feedback on how the goals are being achieved.
Annual evaluation, he says, is useless.
OK, let's get back to Nathan.
For the moment, let's assume that he's OK with receiving no base pay, like the employees
at Lincoln Electric.
He gets a bit more than $100,000 if the project succeeds, otherwise nothing.
The equations we've solved already guarantee that his best option is to work hard.
But does this work for the company?
Well, with Nathan working hard, 20% of the time they make or lose nothing.
80% of the time the project's successful.
Of the $250,000 coming in, $100,000 of that money goes to Nathan, and $150,000 go to the company.
Since this only happens 80% of the time, the company's average payoff is $120,000.
So that's how much they make.
Remember that the company made $140,000 on average when it could observe Nathan's work
directly.
Imperfect information always has a cost.
In this case, that cost is $20,000.
Sometimes the cost of this information is symmetry is simply too great.
We've been talking about a project that was worth $250,000.
Let's leave everything in the problem the same, but lower this to $150,000.
The incentives need to make Nathan work hard haven't changed a bit.
If you work on all the math, you still get the same thing.
But when you work out the profit for the company, you'll find out that they get 80% of $50,000
or $40,000 as their average return.
Disappointing.
But it's still a profit.
But remember that the company can get Nathan to work at normal level by paying him $30,000
and forgetting about the incentive system.
You still get the contract half the time.
So 50% of the time, you pay Nathan $30,000 and get nothing.
The other half of the time, you pay him $30,000 and get $150,000.
The expected payoff is 20% of negative $30,000 plus 20% of $150,000, which works out to $90,000.
So the incentive scheme with the smaller project gives you $40,000 on average.
But letting Nathan do his normal work and forgetting about the incentive scheme gives
you $90,000 on average.
In this case, the incentive scheme is possible, but it just doesn't worth it.
It's also possible, in fact, that it might not be worth it at all.
If the project were worth less than $60,000, don't bid it.
Look for a new job.
Incentive schemes can be and are used to modify behavior in many business environments.
But there can be many more areas in which they can be useful.
Sometimes an incentive may not just be a carrot, but also include a stick.
As with our first example with Nathan, the behavior encouraged or discouraged is directly
observable.
When it is, the topic of incentive schemes becomes closely entangled with promises,
threats and commitments.
How do you encourage your customers to pay their bills on time?
How do you get customers to return books or videos when they're done with them?
How do you encourage suppliers to deliver on time?
Being aware of the game theoretic issues that underlie this kind of interaction can give
you a considerable edge in finding a solution.
Let me give you one beautiful example.
It was presented in Brandenburg and Nailbuff's Co-Opetition.
Co-Opetition is all about finding practical applications to game theoretic ideas in real
life business.
I'll have a lot more to say about them toward the end of this lecture series, but here's
just one.
You have 10 different suppliers for a particular good, and your business needs to keep at least
eight of them.
The suppliers can either deliver on time, which makes them $2,000, or they can deliver
late, which makes them $5,000.
Because suppliers are interested in making as much money as they can, they tend to deliver
late as much as they can.
All of them tend to deliver late most of the time.
$2,000 is good.
$5,000 is much better.
So what can you do?
You can threaten to stop doing business with any supplier who's late again, but this isn't
a credible threat.
You need eight of the suppliers, you can't get rid of all of them, so they'll still deliver
late.
In fact, the suppliers could get together and have a little chat.
They could all decide to keep delivering late.
Sure, you might fire two of them, but even so, that means that the supplier has an 80%
chance of keeping your business.
And once again, we have an expected value calculation, 80% of $5,000 is $4,000.
So continuing to deliver late, even with the possibility of getting sacked, has an expected
payoff of $4,000.
That's still a lot better than the $2,000 for delivering on time.
So what can you do?
You could combine a threat, I'll can the first two people who don't deliver on time with
an incentive payment of over $2,000 to those who deliver on time, but we're talking serious
cash here.
And the problem with a promise is it doesn't go away, week after week.
So here's a brilliant solution.
Assign the 10 suppliers, numbers 1 through 10, assigned randomly.
Eh, change it from week to week, just for fun.
Make sure that every supplier knows his number though.
Now make this announcement.
I will stop doing business with the lowest numbered supplier who is late.
What happens?
You've changed the payoffs very nicely, assuming that the threat is credible.
Supplier number one now says, if I deliver on time, I get $2,000.
If I deliver late, I get nothing.
So I'm going to deliver on time, and he does.
But his logic is clear enough so that everybody else knows that's going to happen.
So think about supplier number two, two says, one's going to deliver on time, which means
that either I deliver on time, getting $2,000, or I get the ax.
So I'm going to deliver on time too.
And so the reasoning goes up through the 10th supplier.
In general, blanket threats and promises don't work as well as targeted ones.
But this is an example where the blanket threat has incredible potency, all because of the
removal of imperfect information.
By numbering the suppliers, you resolve the question of who was going to be fired for
late delivery.
And everyone knowing that meant that nobody delivered late.
Isn't that lovely?
Here's a cute example from the world of politics.
Warren Buffett, the Oracle of Omaha, with an estimated worth of about $62 billion, proposed
a brilliant way to reform campaign finance.
Get a bill introduced into Congress that will limit the contribution of political campaigns
to $5,000 per citizen.
The bill outlaws contributions from any other sources, including businesses and unions.
Such organizations can encourage their members to contribute, but do no more.
Which says Buffett is what it was like before 1978 anyway.
The motivation behind the bill, of course, would be to limit the power that such organizations
would have in buying votes, even though politicians frequently claim that their voting is not influenced
by the soft money in any way.
I think we can agree that this bill will have very little chance of getting through Congress.
Ah, but wait, here's where Buffett's brilliant idea comes in.
Imagine an eccentric billionaire puts up $1 billion.
This money goes, if the bill fails to pass, the billionaire will contribute $1 billion
to whichever political party had cast the most votes for its passage.
After all, soft money would make such a contribution possible.
Buffett anticipates that the bill would pass easily, since neither party would be willing
to let the other party get $1 billion, which, by the way, is a wonderful confirmation that
you can, in fact, buy votes.
And because it passes, the billionaire never has to pay a cent.
I love Buffett's idea, but I'd add one cortisol.
A clever Congress could broker a deal to have the same number of votes cast in favor by
both sides, but make that total just below what it takes to make the part of the bill
pass.
To avoid this, I'd add a rule that if there were a tie, the minority party gets the billion
dollars.
That ought to do it.
Once more, one more example, and a warning about the dangers of a poorly conceived incentive
scheme.
This one's from the world of sports, soccer.
Soccer isn't the most popular sport in America, but hang with me.
You're going to like this one.
The year is 1994, and the scene is the Shell Caribbean Cup.
It's the first round, and the game is between Barbados and Grenada.
In order to advance in the tournament, Barbados needs to win by two goals.
If they lose or win by only one goal, Grenada advances.
This is common enough in soccer matches.
But here's where things start to change.
This particular tournament had a well-intentioned but ill-conceived rule.
If the game was tied when it went into overtime, any score, goal that was scored in overtime
would count for two goals, not one.
That'd only be one such goal since overtime is sudden death.
The ideal was to reward close matches, and particularly the team that came through in
the clutch with an exciting victory in that finale after the game was tied.
Barbados and Grenada play their match.
With less than 10 minutes left in the game, the score is 2-0 in favor of Barbados.
This is just what Barbados needs to advance to the second round.
Consequently, they begin playing very defensively.
But in the 83rd minute of the match, Grenada breaks through and scores against Barbados.
Barbados' lead is now down to one point.
It's not good enough for them to advance.
Barbados tries desperately to score against Grenada for the next several minutes, but
the Grenada defense holds firm.
With only three minutes left in the game, Barbados decides on an odd tactic.
They score against their own goal.
The score is now 2-2.
Now if the game ends in a tie, it goes into sudden death.
If Barbados scores first in overtime, the new rule will give them two points.
They'll win by two points, allowing them to advance to the next round.
For a minute or so, the shocked Grenada team drives hard at the Barbados' goal, but soccer
is a low-scoring game.
It's unlikely that you can score against your opponent in so little time.
Then with only about two minutes to go, the Grenada team comes to its own realization.
If they score, they win and advance to the next round.
But if Barbados scores, Grenada loses by one.
And so Grenada still advances.
So I want you to imagine the last two minutes of regular play in this match.
Soccer fans were witness to one of the screwiest soccer games ever played.
Imagine the sight as Grenada tries desperately to score against either goal.
The Barbados team is split between the two ends of the field and are trying to guard
both goals simultaneously.
I'm not making this up.
The videos on YouTube, if you want to check it out.
Well, Barbados did in fact manage to hold Grenada at both ends of the field, and in
the ensuing sudden death that followed, they scored first and advanced to the next round.
Neither team was penalized for the bizarre play since each was genuinely trying to win.
Barbados was eliminated from the next round, and I trust the well-intentioned rule was
eliminated from all future soccer tournaments.
This hilarious example serves as an important reminder.
A poorly conceived incentive scheme may end up promoting the kind of behavior that's
quite different for which it's designed.
In 1999, a paper by two Baylor University economists looked at the performance of pro-basketball
teams and found significant evidence that teams lose more often when incentives to lose
are present.
What are the incentives to lose?
Well, the worse your team does this year, the better draft choices you get for next
year.
It's obvious, but still worth stating.
To be useful, incentives need to encourage the kind of behavior that you desire, and
discourage the kinds that you don't.
