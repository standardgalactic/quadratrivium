This time, we begin our exploration of the traditional heart of operations research,
the once top secret techniques that help win World War II.
These are practical techniques capable of handling thousands of variables, but the distinction
between what we've done so far and what's coming up isn't really the number of variables.
Instead, the big difference is in the models, both the type of models and the purpose of
those models.
Thinking about models doesn't come automatically.
I was surfing the internet the other day and I came across a plea for guidance from a troubled
soul on an answer's website.
Someone trying to help replied with the old adage that the first step in solving any problems
is admitting that a problem exists.
Sure, not certainly, but I was rather amused by the response of the troubled soul.
She said, yeah, I got that one, but what's the second step?
Talk to anyone who tackles problems professionally and I think you'll find there's a strong consensus
about what that second step should be to find the problem, determine where you stand now
and what it is precisely that you're trying to accomplish.
But then we get to the third step and there are a number of choices.
In a business environment, for example, it's common to conduct a SWOT analysis, short
for strengths, weaknesses, opportunities, threats.
But anyone tackling a problem from an analytics perspective is going to make a different choice
consistently.
The third step, adopt a model.
We've done this repeatedly in our lectures so far from regression models to time series
models to exploratory models and data mining.
And in not one of these cases have we captured every tiny detail of the real-world situation
that the model is being used to investigate.
In a real sense, we don't want to.
A map that tells you everything isn't a map.
It's the reason you wanted a map in the first place.
Any real-world situation viewed in its entirety is likely to be incredibly messy.
Our intent has been to extract from that tangle the qualities, quantities and relationships
that are at the heart of what's going on, and then to focus our efforts on those.
There are, of course, good models and bad models, and the test of a model is the extent to which
its predictions agree with observation.
If the agreement between the two is good, the model can be used in a better understanding
the reality and in predicting the consequences of our actions.
A good model doesn't necessarily even have to be right in an absolute sense, as long as
its results give an accurate enough fit to reality.
Newtonian mechanics and classical electromagnetic theory have been shown to be wrong and have
been superseded by relativity and quantum field theory, but the simpler, earlier models
are still used in guiding spaceships to other planets and in designing most electronic equipment.
That's because when moving from theoretical to applied perspectives, we want a model for
something different than maximal agreement with observation.
We want one that's simple enough to be readily applied in a practical context, yet accurate
enough to make quite useful forecasts as to how things will play out.
The mathematical models that we develop in this course aren't intended to capture every
nuance of reality.
If we do our job well, they'll meet two criteria, tractable enough to be solved, accurate enough
to be useful.
Those requirements still leave open a lot of possibilities, and we're exploring some
of the best of them in this course.
Up to this point, all of our models have included statements of an element of randomness, but
restricted to a particular context.
Everything we've done so far has been taken from a random sample from a population and
tried to find a connection among the quantities represented in that sample.
We address the randomness with a statistical analysis of error that tells us how much we
could trust the results when applied to new data.
Later in the course, we're going to lift the stochastic genie out of the bottle and look
at the impact of randomness on a much broader context.
Speculations where random events play a central role in the problem that you're trying to
analyze.
Machine failures, service times, public opinion, financial speculation, acts of God, or of
government.
I'm sure you can think of a lot of examples from your own experience.
But for this central section of the course, I want to go in the other direction because
there's a lot of life that's not driven by random fluctuations.
We manage to navigate the world because we can often rely on cause and effect relationships
among the events that play out in it.
And when we can quantify the nature of those relationships, we can build a structural model
of the situation that we face.
There's no randomness here.
We're talking deterministic systems where a particular set of inputs leads to a predictable
set of results.
And if you have any doubt about the power or usefulness of that kind of modeling, take
a look at any of the physical sciences or engineering.
Our technology, from a match to a supercomputer, hinges on this kind of predictability.
What we've been doing so far is like science, looking at data and trying to uncover relationships
that tie things together.
In science, you try to figure out how the pieces are connected to find rules that some
aspects of the universe obeys.
But our approach now, by contrast, is going to be more like engineering, in that I'm going
to assume that you already know about how the pieces are connected.
So our job is to figure out what to do with them.
Because you're going to try to accomplish something, and the question is, what action
should you take so that you accomplish that something as well as you possibly can?
And that's going to be our focus in this central part of the course, optimization.
All optimization problems have the same purpose, to find the best possible answer to the problem
at hand.
Think about that phrase for a moment.
The best possible answer.
Because it's really all that you need to know to get a clearer image of how we model an
optimization problem.
It's actually easier to start at the end of the best possible answer and work our way
back toward the beginning.
Start with answer.
What's an answer?
Well, you're analyzing the situation because you want to know what to do, right?
You're going to need to take some kind of action, and the question is, what kind?
The answer is the specification of the decisions that you'll make.
Those decisions might be simple to describe, such as, don't buy the car, or they could
be more subtle and complex.
If the Dow stays above $12,000, then we hold a market share of at least 30%, and then approve
the new construction project with a budget of 5% of the gross income from the last year.
Simple or complex though, your answer is your set of decisions, your course of action in
the upcoming situation.
But of course, you can't do whatever you want.
Virtually every real-world decision-making situation comes along with its own limitations
on what you can do.
It comes with its own set of constraints, and there really isn't much point in spending
a lot of time considering answers that are impossible to implement.
So we want to focus on answers that don't break any of the constraints on possible answers.
Okay.
So we've narrowed the field down to only possible answers to the situation.
In the end, we're going to have to select one course of action from among these candidates.
We want the best possible answer.
And that's not as straightforward as you might at first imagine.
Look, I've got a set of decisions over here, A, and another set of decisions over here,
B. Both are possible to implement.
Which one's better?
Well, I have to have a way of comparing any two such answers and choosing between them.
We'll generally do this by identifying our goal, our objective, and then seeing which
of the two solutions better achieves that goal.
So this idea of best possible answer leads pretty directly to three important factors
in analyzing a situation.
What are you trying to accomplish?
What do you have the power to decide?
And what rules do you have to obey along the way?
And these are the three questions that we ask for every optimization problem.
And it's been my experience that this set of three simple questions can be surprisingly
useful in getting a handle on problems both professional and personal, without any mathematics
at all.
So it's amazing to me how rarely people take the time to explicitly identify their options,
their restrictions, and what they're actually trying to accomplish.
One example.
In his book, The Goal, Elihu Goldrat has a protagonist who's a plant manager in a manufacturing
firm.
The manager is going to a conference on robotics, and he's very proud of the efficiency of
his robots in his factory.
In order to get these efficiencies though, the robots had to be used pretty much 24-7.
And since there wasn't enough demand for their output from the processing steps further down
the line, the robots ended up making parts that nobody really needed.
When quizzed about this by his old college professor doing operations research work,
the manager admitted that they were getting no more product to market, that they had not
reduced employees, and that they had actually built up a considerable and expensive inventory
of parts that they had no immediate use for.
But he had been proud, because his robots were so efficient.
Kind of reminds me of Rita Rudner's dieting solution.
At restaurants, she says, she orders dessert, but only eats half.
But if it's really good, she orders two.
Well, jokes aside, it's surprisingly easy to get stuck doing something that's suboptimal.
So how do we find the best option?
The purpose of having something concrete, for the purpose of having something concrete
to talk about, I'm going to tell you about an aviation company, Air New Zealand.
They knew what flights they wanted their jets to fly, but there are some obvious logistical
matters to be worked out.
You can fly a plane and a crew from A to B, always assuming that you have the plane A,
but then after the flight, you've got a crew and plane at B. If you're going to have a
repeatable schedule, that plane eventually has to get back to A again, as does the crew.
In the airline biz, the collection of flights and rest periods that make up a circuit are
called a tour of duty, and the schedule of a member of the crew that brings them back
to their crew base at the end is called a line of work.
So how do you figure out all that?
Let's see how we can approach this problem with a mathematical model.
We're going to begin by framing the problem, by identifying its decisions, its constraints,
and its objectives.
In order to apply mathematics to the result, we're going to need to express all of the
components of the model in terms of measurable quantities.
For this section of the course, we won't be looking at categorical data.
A measurable quantity is basically anything that you could sensibly assign a numerical
value to in this specific situation.
Although there are exceptions to every rule, you can think of a measurable quantity as pretty
much anything that you could specify with a phrase starting of number of this or number
of that.
The number of employees we hire, the number of days before an order arrives, the number
of dollars we spend on equipment, the number of fatalities in a car accident, the number
of pounds I put on over the winter holidays, that kind of data.
So how do we express the Air New Zealand problem in terms of measurable quantities?
Well, hold on a minute.
As I've described it, it might be more tractable to approach it as two problems rather than
one.
First, find what tours of duty you want to minimize the cost of your flights and layovers.
Then figure out how you can use the people that you have to crew those flights.
It might be better to solve these two problems together.
We might find some really clever ways to schedule crew if we had a particularly friendly tour
of duty schedule, but it's also a lot harder to solve.
So for the sake of tractability, an airline, the airline and the University of Auckland
who were collaborating on this project created these two separate problems.
Well, eight, actually.
Because the rules concerning pilots are different than for flight crews, and the rules for
international flights are different than from purely domestic ones, but to keep our discussion
from getting out of control, let's just talk about scheduling flight crews on international
flights.
Okay, the first part of the model is the objective, the goal.
Remember, we're going to represent the objective by a measurable quantity, like the number
of dollars a profit, or the number of people seeing my ad, or the number of minutes a
patient spends in an emergency room waiting area.
Notice that each of these starts with a phrase number of, which is how all of our measurable
quantities will be expressed.
For any particular proposed solution, the objective will be a number.
We'll judge the quality of the solution by the size of the number.
If Air New Zealand cares about profit, it's pretty clear they'd like to maximize it.
The bigger the better.
On the other hand, if their revenues are more or less fixed, they might prefer to analyze
the problem in terms of total cost.
This would be a minimization problem.
The goal is to minimize the expenditure.
While some problems have the goal of keeping a value within a certain range, most can be
expressed with the goal of either maximizing something or minimizing something.
This actually brings up an important point.
How about if you have more than one goal?
For example, the Air New Zealand management is primarily concerned about money, specifically
minimizing the cost of its operations.
The crew, on the other hand, is much more concerned about pleasant or unpleasant schedules for
them.
The management's calling the shots, but it's obviously good business practice to keep your
employees as happy as you can.
So Air New Zealand management actually has at least two goals.
We'll be looking at how to handle this kind of thing in detail when we discuss goal programming
and how to address more than one goal later in the course.
But in brief, if you've got more than one goal, you're in a bit of a jam, and there
are only a few ways out.
One way is to combine the goals in some ways.
For example, by taking the weighted average of them with appropriate weights.
In this case, your multiple goals become one goal.
Maximize or minimize this weighted average.
A second option is to prioritize your goals.
To say, for example, my first goal is to reduce cost to no more than this amount, and my second
goal is to maintain a crew satisfaction level that's as good as I can get.
The last option is to look at trade-offs, focusing on the question of how much of this
you're willing to give up for how much of that.
But if you do have more than one goal, the goals are usually going to conflict with one
another, so you have to make a decision about how to resolve those competing objectives.
It's interesting to listen to political speeches with this observation in mind.
You'll often hear politicians make statements such as, we're going to provide the best possible
health care at the lowest possible cost.
Well, the lowest possible cost is free, and the easiest route to that lowest cost is by
offering no health care at all.
This obviously is not the best possible health care.
What's really being said in a fuzzy way is we're going to provide the best balance of
health care, quality, and cost.
But what is that balance?
Who decides?
These are hard questions, but the phrasing of the original statement too often lets the
speaker avoid them entirely.
But back to Air New Zealand.
The objective is going to be essentially to minimize cost, although we include crew
dissatisfaction in the objective appropriately weighted as a cost.
What's next?
Well, the decisions we make.
Again, these are going to be represented by measurable quantities, number of this, number
of that.
There's generally one decision variable for each quantity over which you have direct
control.
I put that word direct in there, quite deliberately, and remembering it will help you avoid some
of the most common formulation errors and optimization problems.
When you go to the store, for example, you do control how much money you spend, but not
directly.
Your total bill depends on the money you spend on each type of item, and that in term depends
on how many of each type of item you buy, and what does that depend on?
Nothing.
You get to pick.
That's the hallmark of a decision variable.
If you repeatedly ask yourself, what does that depend on?
The answer finally comes back as, nothing, I get to decide that.
And then you're at the level of the decision variable.
For the airline, we might have decision variables such as the number of flight attendants that
were assigned to each tour or the like.
But here our job is to decide how to schedule the specific people that we have available
as flight attendants.
So our variables are both simpler and more subtle than the number assigned to each flight.
We already solved the tour of duty problem.
So Air New Zealand knows the tours that they're going to fly.
It knows the available staff.
The decisions we have to make are really at a grassroots level.
Here's a particular flight attendant, Alexis.
Here is a particular tour of duty, a six-day loop from Auckland to LA to Sydney and back
to Auckland with layovers.
What we decide is, does Alexis fly this tour or doesn't she?
It's a really simple variable, it doesn't even sound like a number.
But we can use one to mean that, yes, she does fly the tour, she flies it one time, and zero
to mean that she does not.
This kind of variable is called a binary, or boolean, or zero one variable, and we'll
look at them carefully in a later lecture on integer programming.
So I might have a variable called Alex O7, which is one if Alex flies tour number seven
and zero if she doesn't.
Are you starting to get scared yet?
The researchers on the project were, because these zero one problems can actually get pretty
time consuming to solve when they get big, and our problem is looking like it's going
to get big.
As an example, suppose that Air New Zealand has 100 tours of duty and 300 people available
as flight crew, then there's a zero one variable for every combination of person and tour, meaning
our problem has 30,000 variables, and that's just for the flight crew.
There might be several thousand more variables for the pilots.
Okay, that brings us to the constraints, the rules that were required to obey.
Again, if we're going to be solving problems quantitatively, our restrictions have to be
expressed in terms of measurable quantities.
In almost every case, our constraints are basically going to specify how the size of
this quantity compares to the size of that one.
Are they equal in size, or is the first less than or equal to the second, or greater than
or equal to it?
For example, I personally have a constraint that the money I spend has to be less than
or equal to the money that I have.
The government evidently doesn't have this particular constraint.
A line worker might have the constraint that the number of units that he or she assembles
in a shift must be greater than or equal to the prescribed shift quota.
A soccer league may have the constraint that the number of games played by team A during
the season is the same as the number of games played by team B.
We're going to have a lot more to say about constraints a little later on, but you get
the idea.
Constraints tell you what you may not do, or what you must do.
They're the rules you have to obey.
For Air New Zealand, what do we have to do, and what can't we do?
Well, our particular problem is only about flight attendants, so we have one set of rules
that says this.
A flight attendant can't be doing two different things at the same time.
Tours of duty are mutually exclusive, so if she's on tour 7 on Wednesday morning, she
can't also be on tour 16 at that time.
That's one constraint for each flight attendant for each time window.
Again, a lot of constraints.
What equally important is a second set of constraints, saying that the flights must
be crewed.
If a particular tour of duty needs three flight attendants, then there have to be at least
three people assigned to that particular tour.
That's going to be one constraint per tour.
If the first program, which was making up the tours to begin with, took into account
all the regulations concerning what tours are and aren't legal, and which ones break
labor agreements and so on, then these two kinds of constraints may pretty much be all
that we need in our current program.
And this is essentially what Air New Zealand ended up with.
Conceptually, simple, computationally, a little terrifying.
But with computer power and mathematical cleverness, it turns out that it's quite possible to
solve.
The solution, coupled with the solutions of the several other related problems that they
solved, is estimated to have saved Air New Zealand over $12 million dollars in U.S. dollars
a year, and to have provided better attention to the crew's preferences and scheduling.
Now, I'm not saying that every problem can naturally be described in this way with a
quantitative objective, a set of quantitative constraints, and a set of decision variables
representing measurable quantities.
For example, if your golden life is to be happy, or to maximize your overall happiness,
how do you measure it?
Well, before this lecture started, I was feeling a little down, about 30 happiness points.
But now my happiness rate has skyrocketed to 73.1.
I'll be honest, really.
I have no idea how to effectively measure my happiness numerically, nor how I could accurately
connect it to the decisions that I make.
Part of the problem is I can't effectively model my happiness because I don't understand
how the pieces fit together.
And understanding how the pieces fit together, creating a structural model, is essential
if we want to find an optimal solution, a best set of decisions, in the face of the
problem at hand.
Even when we can sensibly model a problem mathematically, we're going to want to look
carefully at our answer before implementing it, or we may be in for a surprise.
What we modeled might not be quite what we wanted.
One of the pioneers of mathematical optimization, George Danzig, found out the hard way.
Danzig was a mathematical scientist important to us because he developed a procedure, the
simplex method, for solving a class of optimization problems called linear programs.
Linear programs are going to be extremely important to us in this course.
And when we get into the details, I'm going to be letting you in on what was originally
top secret stuff.
Much of the early work in the field was classified until 1947.
The allies used linear programming to reduce the cost of World War II operations and increased
enemy casualties.
Important stuff.
Anyway, in 1947, Danzig used his simplex method, which in principle could solve any linear
program, to solve a linear program that had earlier been formulated by another researcher
in linear programming.
The decision variables were the number of units of various foods that you would feed
a person per day.
The constraints were the minimum daily adult requirements for various vitamins, minerals,
calories, and so on.
The goal was to meet these constraints at minimum possible cost.
Even though the program was formulated with only 77 foods and only nine requirements as
far as nutrition, computers weren't available at the time, so even with Danzig's lovely
simplex method, it had to be solved using desktop calculators.
120 man days of work later, Danzig's team came up with the answer.
It wasn't an exciting diet, but for people going hungry, excitement's not usually the
primary concern.
It consisted of only five foods, wheat flour, evaporated milk, dried navy beans, cabbage,
and spinach.
You could feed a man for only $39.69 per year, $39.69 in 1947 prices.
That's still well under $600 per year to feed a person in current dollars, under $2
a day.
Not bad.
Skip ahead a few years.
In the 1950s, computers were coming into their own, Danzig, like many of us, had put
on some extra pounds that his doctor thought he'd be better off without.
So, thinking of the success of his earlier diet program, Danzig wrote a linear program
to find his optimal diet.
The goal was to maximize the feeling of being full, which he estimated by the weight of
a serving of food minus its water weight.
He imposed nutritional constraints as well as a constraint that the total calories consumed
couldn't be more than 1500 calories a day.
He announced to his wife that whatever the computer generated as his optimal diet was
what he intended to eat, she was going to play along and prepare what the computer ordered.
The program was run and Danzig informed his wife of the suggested diet.
She said it was weird but doable.
Then Danzig told her that there was one more item on the menu, 500 gallons of vinegar.
Evidently, vinegar was considered a weak acid with virtually no water, so it looked great
in the objective function.
Danzig decided vinegar wasn't a food after all and re-ran the model the next day.
This time the solution was reasonable, except for including 200 beef bouillon cubes.
Still, Danzig gave it a whirl, starting breakfast the next morning with 4 bouillon cubes dissolved
in water.
He couldn't drink it, it was pure brine.
And just as well, you can imagine what his salt intake would have been.
No sane person wants to eat that much salt, so doctors weren't warning people against
this ridiculous level of salt intake at the time.
So new constraint.
No more than 3 bouillon cubes a day.
The computer found the optimal solution for the new problem.
It included two pounds of bran per day.
Imagine the effects of eating two pounds of bran.
He limited the amount of bran allowed in the solution, and the computer switched to two
pounds of blackstrap molasses.
At which point Mrs. Danzig said, George, I love you, but enough is enough.
She said she'd gotten some good ideas from the solutions of the programs that the program
had proposed, but that she was going to decide the meals.
She did.
Danzig lost 22 pounds.
The moral of the story?
A mathematical optimization finds the best answer to the problem as posed.
To the extent the question's not well posed, the answer's in doubt and may be nearly useless.
But even when mathematical solutions don't take into account some human detail, the suggestions
are rarely as surreal as Danzig's diet.
A small adjustment by a human decision maker can often result in an excellent solution.
Before we go on, I think I better take a minute and talk about programming and what it means
in this course.
For example, I told you that the Feed the Hungry Diet problem and Danzig's Less Successful
Personal Diet were examples of linear programs.
The Air New Zealand problem was discussed was an integer program, because it had lots of
ones and zeros.
There are other kinds of programming as well that will be coming across, nonlinear programming,
mixed integer programming, goal programming.
All of this programming makes it sound like we're going to be working with computers.
Well, that's true.
But the term programming in all these topics doesn't refer to computer programming.
A lot of early optimization problems were worked out involving scheduling and logistics
like figuring out what factory should be making during the war.
The term programming is meant in the sense that it has in the phrase television programming.
It just means scheduling.
That said, it's undeniable that today almost any real-world scheduling or optimization
problem is going to be solved by harnessing the power of computers, whether it's a PC
or a mainframe.
And for a lot of smaller problems, you don't need to be a computer programmer to take advantage
of the computer's power.
The Feed the Hungry problem that took George Danzig and his team 120 man days to solve
could be done on any desktop computer in a fraction of a second today, once it was set
up.
And setting it up would be a matter of minutes, not hours.
Spreadsheets were useful in our regression and data mining work, and they'll continue
to be useful in optimization.
Excel in the Microsoft Office Suite does a lovely job for most of our optimization work,
and most people already have it on their computers.
An alternative is Calc, a free alternative to Excel that's part of Open Office, downloadable
from the web.
I use Spreadsheets not only because they're accessible and familiar to a lot of people,
they're also transparent.
That means I'll be able to show you the details of what I'm doing, and you'll be able to
see the model as it evolves over time.
So, we've got the big picture.
Given a troublesome situation, we're going to identify its key factors.
What is it we're trying to accomplish?
What controls do we exert over the situation?
What rules are we compelled to obey?
And how do all of these pieces fit together?
A good model is going to strip away all of the extraneous window dressing and focus on
the heart of the problem.
And once we have that model, we will be in a position to apply some accessible and powerful
mathematical machinery, machinery that will provide us with the best possible answer to
the problem.
That's the skill set we'll be building in this central part of the course.
And the most important skill is the one that I mentioned in the first lecture, that act
of translating the problem from English that we use in everyday descriptions, to the Mathematies
that will allow us to bring our analytical tools to bear, formulating the optimization
problem.
And we're going to begin next lecture by looking at a set of models that's near the head of
the list of mathematical tools widely used in businesses big and small.
The very beautiful, remarkably applicable, perfectly solvable class of problems called
linear programs.
See you then.
