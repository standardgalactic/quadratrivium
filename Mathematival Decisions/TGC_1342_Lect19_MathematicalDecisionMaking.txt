Every decision that you make, whether for yourself or as part of an organization, has
the potential to affect your overall reputation and prospects into the future, and often your
control of that future is limited.
You'll exercise control over some aspects of the situation, but in many cases, some
things are just out of your hands.
Decision trees are an analytics tool for addressing just such scenarios, ones that unfold over
time, interleaving the choices that you make with the unpredictability of the rest of the
world.
Corporate image is incredibly important, and never more so than when you're marketing
a product for infants.
Take Gerber products incorporated.
They're probably most famous for the familiar Gerber baby logo that appears on their jars
of baby food.
Adorable.
Still, this is deliberate, purposeful.
Gerber has worked hard to cultivate its public image, but in 1986, chance intervened and
they committed what many people consider to be the textbook example of a PR disaster.
And 12 years later, as Christmas approached in 1998, Gerber was again on the hot seat.
It was the focus of governmental review and media scrutiny, with the issue being the last
thing that they wanted, baby safety.
Here's what happened.
In 1986, the Food and Drug Administration received about 140 reports of glass shards
in jars of Gerber baby food.
The FDA looked into it and confirmed 21 cases of product tampering.
These are probably the work of isolated individuals.
But a week before, Beechnut, Gerber's competitor, had faced a similar situation, and Beechnut
had promptly recalled its baby food from the store shelves.
Gerber didn't.
To many, Gerber seemed cavalier about the possible dangers.
And when the state of Maryland responded by banning Gerber peaches in light of the glass
shards scare, Gerber sued the state.
From the point of view of reputation, it was not a pretty story.
Gerber eventually recovered from the debacle, but it didn't forget it.
Then in 1998, Gerber faced a second PR crisis.
This one had its roots about 30 years earlier, polyvinyl chloride, or PVC, remarkably useful
plastic.
You probably know this stuff.
You've seen it around the house in plastic water pipes, food storage containers, toys,
lots of places.
It's also important in a lot of medical supplies.
And for some uses, it needs to be softened to be made more pliable.
And this is often done with a family of chemical plasticizers called phthalates.
Phthalates had been around in use for about 30 years, and no one seemed overly concerned
about their safety, but that was about to change.
Enter the environmental group Greenpeace.
Greenpeace had conducted research on phthalates, and it concluded that they were carcinogenic
in lab rats.
It also said that phthalates would leach out of the plastics over time.
Greenpeace was particularly concerned about products that children would chew or suck
on.
No stranger to the PR game, Greenpeace timed its press release to come out just before
the Christmas season in 1998.
The media picked up the story, 2020 did a segment on it, and with Gerber having about
75 different products containing phthalates, the company was feeling the pressure to respond.
It got worse.
Although phthalates had no known health issues, the U.S. Consumer Product Safety Commission,
the CPSC, felt compelled to release a new statement expressing new doubts.
As companies like Mattel and Disney began to pull back on products with phthalates,
the spotlight focused on Gerber.
About a month before Christmas, the CPSC told Gerber they were going to release a statement
advising parents on the potential dangers of phthalates, and that Gerber would be one
of the companies named in the statement.
And that's why Gerber was in the hot seat.
And in deciding how to handle it, one of the tools that they used was a relatively simple
approach to a complex problem, a decision tree.
In today's lecture, we're going to develop the same tool, apply it to the same problem,
and see what it has to say.
To me, a decision tree always feels like a choose-your-own-adventure book, and a kind
of fun.
You start on the first page and the story advances a bit, then comes a decision point, and the
book says something like, you're standing on the steps of a brownstone manner.
If you want to ring the doorbell, turn to page 16.
If you want to return home, turn to page 48.
If you want to see who comes by and wait, turn to page 11.
And then you turn to that page and the story continues, based on the choice that you made.
A low-tech hyperlink, I suppose.
Anyway, decision trees work like that, except that in addition to the kind of pages I just
described, there'd be others where you don't get to choose.
Chance does.
It's as if the book said, roll a die.
On a one through three, the weather stays fair.
Go to page 18.
On a four or five, it begins to rain.
Go to page 22.
On a six, it begins to snow.
Go to page six.
Obviously, in a book like this, there are a lot of pages that you'll never read.
And that's like a decision tree, too.
A decision tree has lots and lots of branches that in the final analysis will never come
to pass.
And actually, that's the power of the technique.
In generating all of the possible stories and then navigating your way through to the
best ones to see the best decisions you can make in light of the possibilities.
Let's see how this works for Gerber.
Given their situation, it has to decide whether to adopt a proactive or reactive stance to
the situation.
If it's proactive, it would aggressively address the issue by announcing that it would discontinue
the use of phthalates in its products before the CPSC report was released.
If reactive, then wait, see what the report said when it came out, and then decide how
to respond.
In either case, when the report was released, Gerber would know its contents.
They thought that either the report would be a recall on the phthalate-containing products
or else it would just be an advisory expressing concern.
But whatever the report said, all of this would result in an impact on Gerber's profits,
either for good or ill.
So how do we come to grips with this in a decision tree?
Like this.
Layed out like this, decision trees are surprisingly easy to understand.
Read from left to right.
The circles and squares that you see are nodes, but they're two different types.
Squares represent decision nodes, and where we're able, that means we're able to choose
which option we prefer.
In our tree, Gerber begins by deciding on a proactive or reactive stance.
Chances on the other hand, are chance nodes.
They represent matters where we don't have control.
In this particular tree, it's actually pretty simple, and once Gerber makes the original
decisions, things play out by chance without any more choices on its part.
The CSPC will do what it does, and then the consumer reaction will either be relatively
good or relatively bad.
The tree is also simple in that each node is a binary one, there are only two options
leaving each node.
Still, even though this tree is simple, we can use it to point out some properties that
are true about decision trees in general.
Trees start with a single node, the root.
It may be a decision, like in this problem, or it may be a chance event, like looking
out your window to see the weather before deciding how to dress for the day.
Second, starting from the root and moving rightward, we're tracing out a possible sequence
of events in the scenario.
If you stop anywhere along the path, from the root in the left to the twig on the right,
everything to the left of your current position is what you already know, and everything to
the right is what you don't know, yet.
If you like, the left is history, the right is mystery.
This is an important thing to keep in mind if you're building a tree.
For example, imagine that Gerber had a mole in the CPSC so that it knew what the report
was going to say before needing to make its decision about its stance.
Then our tree would begin with a chance node for the CPSC report followed by the Gerber
decision of its stance.
A better situation for Gerber, but not what happened.
Okay, we've got the structure of the tree, but before we can do anything useful with
it, we need two more kinds of information.
First, we need to know how good or bad things end up being in any of the eight possible ways
that this story can unfold.
Second, all the chance nodes are not created equal.
We need to know how likely each of the possible outcomes is for each of the chance nodes.
Not surprisingly, Gerber had to estimate these.
And here's what they came up with.
First possibility, Gerber announces removing phalates from all the products and the CPSC
report only expresses concern.
In this case, Gerber figured that it would probably gain revenue from a positive public
reaction to its proactive behavior, particularly when compared to slower reacting competitors.
So say, a million dollars in increased revenue.
Then again, it was some chance that the media attention could depress sales in spite of Gerber's
actions.
Let's say, a million dollar decrease in revenue.
Gerber estimated an 80% chance of the good public reaction in this case.
Let's put that on the tree too.
Of course, it was also possible that the CPSC would order recalls.
If they did, Gerber's proactive approach might let them keep their current sales about a
25% chance of that, but they thought it was more likely they'd lose revenue to the tune
of 1.25 million.
And if Gerber chose to respond reactively, the CPSC expressed only caution.
Gerber thought it was 25% likely they could maintain their current sales, but 75% likely
they'd lose 2 million.
And that leaves the worst case scenario, where Gerber responds reactively and the CSPC recalls
daylight-containing products.
Surprisingly, Gerber thought there was still a 20% chance that they could actually gain
a half a million dollars in this case, since they felt themselves more prepared for this
nasty outcome than their competitors.
Still they thought it much more likely they'd experience substantial losses, perhaps 5 million.
Let's put all of this information on the tree.
This is the tree that Gerber used.
But before going any further, I'd like to take a few minutes to address some concerns
you may have about our work so far.
First, perhaps it makes sense to say that Gerber is considering only two different stances.
It may also be reasonable to limit the CPSC reaction to either recall or concern, since
a recall may have serious impact on Gerber, while concern might only cause minor effects.
But surely the last node in the tree aren't realistic.
Surely there's a whole range of possible revenue, not just a pair for gain and loss
numbers.
You're right.
And in some work with decision trees, after a binary node with gain and loss, we might
see another node, a fan with a whole wide range of values.
Each spine in that fan would lead to a different payoff, and each would have its own probability.
Using this more formally, there'd be a probability distribution for all the possible different
revenues.
But the way that we're going to evaluate this decision tree is based on expected values.
We're going to be looking for the best course to follow on average.
So we could view our trees' upper payoff as saying, if we're proactive and the CPSC
is only concerned, we think there's an 80% chance that things will go relatively well.
If they go relatively well, on average we expect a gain of about a million.
That $1 million figure comes from a value in the fan of all possible revenues.
In fact, it may come from a decision tree where many different favorable customer reactions
scenarios are considered.
Okay, second concern.
The probabilities on this tree are obviously subjective probabilities.
We have to assume that the people at Gerber know their own business, but how much can
we trust these figures?
And at present, we don't even have Gerber's guess for how likely a negative CPSC report
is.
To get one, how much can we trust that subjective probability?
Well, that can be a difficult question to answer, but I can address a related question.
How much do we need to be able to trust them?
That is, how sensitive is our best decision to errors in these probabilities?
This is a question we'll return to after we complete our original analysis.
To get started though, let's just take what we have and further assume that Gerber thinks
it's about equally likely that the CPSC report will be recall or concern.
Then here's our completed tree.
Okay, we're ready to do the work to find our optimal strategy.
At present, we're defining optimal as the strategy that results in the highest expected
revenue for Gerber, whichever option gives the highest revenue on average.
That's the one we want.
Such an evaluation is called risk neutral.
The company is concerned only about the average result.
It neither shies away from risk, nor is attracted to it.
For a situation that's faced many times, this is actually a sensible attitude.
But there are lots of situations in which individuals or firms may face a situation
only one time, and there they may demonstrate risk aversion, or more rarely, risk love.
We'll talk about how to account for such attitudes in a few minutes, but for now let's
keep it simple and assume risk neutrality.
The key to analyzing any tree is to start the analysis in the right place.
In their book, Thinking Strategically, Avinash Dixit and Barry Nalbuff summed it up beautifully.
To look forward, you must reason backward.
Start at the right hand of the tree, because the rightmost nodes of the tree have almost
everything being their history.
Once you figure out what to do there, you can roll back your analysis to the earlier
nodes.
Let's see how this works.
Here's the top node of the tree, where Gerber is proactive and CPSC expresses only concern.
80% of the time they make a million, and 20% of the time they lose a million.
Our work from last lecture lets us easily figure out what the average revenue will be in this
situation.
Expected value, remember, is just probability times payoff, added up over all the cases.
So here we get 0.8 times a million, plus 0.2 times negative a million, which comes out
to be 600,000.
So in this scenario, Gerber's expected revenue is $600,000.
You can do exactly the same kind of calculation on all the other rightmost terminal nodes,
too.
And when we do, it looks like this.
As you can see, I've written the results of each expected payoff calculation over the
corresponding node.
For example, the bottom entry shows that if Gerber responds reactively and the CPSC orders
recalls, Gerber's average losses will be 3.9 million.
And now we just do the same thing again, this time for the CPSC nodes.
For example, if Gerber responds proactively, then there's a 50% chance that the CPSC expresses
concern and a 50% chance of a recall.
But they know that we know that if they're concerned, Gerber expects to make 600,000 in
additional revenue, while if it recalls, Gerber expects to lose 937,500.
Again, do an expected value calculation, probability times payoff, added up over all the possibilities.
We do the same kind of work on the lower node, half the time they lose 1.5 million and half
the time they lose 3.9 million, so on average they lose 2.7 million.
We'll put these values on the tree, too.
Okay, we've worked our way back to the first node in the tree.
Time for another averaging?
If you think about it for a moment, obviously not.
At chance nodes, the outcome is random.
That's why we had to take expected values.
But at decision nodes, obviously, you get to choose which path to take.
Here, if Gerber is proactive, it loses about $170,000 on average.
If it's reactive, its average losses are about 15 times as great.
If what it cares about is expected revenues, its choice is pretty obvious.
The company should be proactive, and that's what Gerber did in real life.
To finish the tree, we'll just barricade the rejected choices and put the payoff on the
selected choice over the decision node, like this.
A more complicated tree is handled in just the same way, begin at the end of the tree,
for a chance node, compute an expected value, for a decision node, choose the best option
and barricade the rest.
Keep going this way until you reach the root node.
When you're done, you'll have a selected option at each decision node.
If and when you ever reach that node, follow the open edge.
On average, you can't do better than this.
You can also use the resulting tree to get an idea of the risk that you face in terms
of possible outcomes and their probabilities.
Every leaf you can reach from the root node along an open path represents a possible outcome
to your situation, and you can find the probability of that outcome by multiplying together all
of the probabilities along that path.
The top path on our Gerber tree leads to the happy outcome of them gaining a million dollars.
The probability of this outcome is 0.5 times 0.8, or 40%.
The Gerber problem looks relatively simple, but the approach can be used to sort out much
more tangled situations.
For example, suppose I run a mining company.
I have my eyes on two adjacent parcels of land that may have valuable deposits of minerals.
Each deposit, if it's there, is actually worth $3.5 million, in fact.
The owner is asking $1.6 million for the pair, which is too rich for my blood.
After all, there's only a 30% chance that a parcel contains minerals.
But he agrees to sell me one of the parcels for $1 million.
And if he wants, if I want, he'll also sell me an option on the second parcel for $200,000.
The option is to let me buy the other parcel for an additional $400,000.
So if I eventually want both parcels, this lets me get them for the $1.6 million total.
If the first parcel's a dud, I can walk away losing the $1 million and the $200,000 for
the option.
But if the one parcel has minerals, the other one's 60% likely to have them too.
The owner, no fool, once it says that without the option, I'll have to pay $1.3 million
more if I want to buy the second parcel.
So what should I do?
This problem's considerably more complicated than Gerber's.
Let's take a look at it in a tree.
To begin with, we have three choices.
Buy the first parcel and the option.
Buy the first parcel without the option, or forget the whole thing.
Let's think about the top choice where we buy the parcel and the option.
We next find out whether the parcel contains minerals.
That's a chance node, with a 30% chance of success.
We said we'd walk away if the first property doesn't have minerals.
There's nothing more to do in that case but lose the $1.2 million.
But if the first parcel does contain minerals, we have another decision, whether to buy the
second parcel.
Since we bought the option, we can get the second parcel for only $400,000.
Assuming that we buy it, we find out if the second parcel contains minerals as well.
That's another chance node, with a 60% chance of success this time.
Remember that if the first parcel had minerals, there's a 60% chance that the second one
does too.
The payoff at the ends of the branch is just to add up all of the losses and gains experienced
as we move through the tree.
For example, see that $1.9 million on the third branch down?
What events occurred to get to that point?
We bought the initial parcel and the option, had a success with the first parcel, decided
to pick up the option, and found nothing in parcel too.
So we spent $1 million in the initial land, $200,000 on the option, and $400,000 for the
second parcel for a total outlay of $1.6 million, but we made $3.5 million on the first parcel.
The total profit, $3.5 minus $1.6, is $1.9 million, and all the other payoffs work in
the same way.
We can build the branch for buying the land without the option in exactly the same way.
In fact, when you're done, the whole tree looks like this.
Let's see what we get when we roll back the tree, finding its optimal strategy.
It's straightforward.
We work from the twigs on the right to the root of the left.
For the chance nodes, we find the expected values.
For the decisions, we choose the most profitable option.
And here's what we get.
What does it say?
Buy the original parcel and the option on the second parcel.
If the initial parcel contains minerals, then exercise the option on the second parcel.
On average, you'll profit by $360,000.
Not bad, given that your maximum outlay is $1.6 million, that's about a 22% return on
investment.
On the other hand, the enterprise is fairly risky.
The most common outcome, which happens 70% of the time, is that you lose $1.2 million.
Well, we mentioned the idea of risk before.
Decision trees, as we've been using them, have been assuming risk neutrality.
That is, given two options, the one that gives the better payoff, on average, is more desirable.
Now, when the same situations face many times, this attitude makes sense.
The law of large numbers and statistics says that we're very likely to see overall results
that are quite close to the expected value calculation when you repeat the situation
many, many times.
This is the principle that allows insurance companies to make money, even though they
have less of an idea about your individual health than you do.
Nevertheless, most of us aren't risk neutral most of the time.
Most of us are risk averse.
For example, suppose I offered you this opportunity.
I flip a coin and you call it in the air.
If you're right, I pay you $400,000.
If you're wrong, you pay me $200,000.
Honestly, would you take this wager?
Clearly it favors you.
On average, you'll win $100,000 on the flip, but half of the time you'll be losing $200,000.
And for most of us, that downside risk is too great.
If you refuse the wager, you're risk averse in this situation.
And the reason is actually fairly simple.
The $400,000 that you might gain isn't worth as much to you as the $200,000 that you might
lose.
To reflect these kinds of feelings in a decision tree, we need to replace each payoff in the
tree with its corresponding utility.
The idea is to define the utility of an outcome of a person in such a way that the expected
value calculations we've been doing make sense when applied to utilities.
John von Neumann and Oscar Morgenstern showed that under four pretty weak assumptions, one
could construct such a utility function for a decision maker.
The assumptions were things like transitivity, that if you like A better than B and B better
than C, then you like A better than C.
Another is continuity.
Suppose that you like A better than B and B better than C. I offer you a choice.
If you want, you can get B for sure.
Or you can enter a lottery.
Win the lottery and you get A, but lose the lottery and you get only C.
Continuity says that I can make you indifferent between B for sure and the lottery if I choose
the right probability, P, of winning the lottery.
If I give you 100% chance of winning, you'd take the lottery, since you'd get your first
choice A. If I gave you a 0% chance of winning the lottery, you'd take B, since the lottery
is sure to give you your least favorite choice, C. Somewhere in between is the probability
where you'd think B and the lottery were equally good.
Let me demonstrate the idea of utility by using the one originally suggested by Daniel
Bernoulli back in the 1700s.
If you end up with a wealth of W, Bernoulli suggested using LINW, the natural log of W,
as a measure of your utility.
There are some interesting theoretical arguments for this choice, but for now, we'll just
see how it works.
And let's not worry about taking natural logarithms by hand.
The LIN key on a calculator is happy to do this for you.
The important thing about log functions is that they keep on increasing as W increases,
but they do so more and more slowly.
A moment ago, we looked at a wager where half of the time you'd gain $400,000 from me and
the other half of the time you'd lose $200,000.
We said that if you risk neutral, you'd be a fool not to take this wager, since on average,
you make $100,000.
But let's say that right now, you have $400,000 to your name.
That's your current wealth.
Then I'm offering you a chance to either double your wealth or to cut it in half.
Using Bernoulli's log utility, we'll see what happens.
Your utility, if you keep your $400,000, would be LIN of $400,000, which comes out to be
about $12.9.
If you win the wager, you'd end up with $800,000, and LIN of $800,000 is $13.59.
On the other hand, if you lose, you end up with $200,000, and LIN of $200,000 is $12.21.
So looking at utilities, half of the time, you get a utility of $13.59, and half the
time, you get a utility of $12.21.
You expect a utility from the wager as the average of these two, which is $12.9.
And that was the utility you started with.
So with Bernoulli's utility, you'd be indifferent between taking the wager and keeping your
current money.
In fact, if you had more money already on hand, the bet would look better to you.
If you had a million dollars already on hand, the wager would leave you either with $800,000,
utility LIN of $800,000, $13.59, or with $1.4 million, utility LIN of $1.4 million is $14.15.
The average of these is $13.87, while keeping your original million gives you a utility
of LIN of $1 million, $13.81, $13.87 is better.
In logical terms, the more money in the bank, the less the pain of the possible $200,000
loss is.
Some have proposed other utility functions for risk aversion, but it's also possible
to build a personal utility function to mirror any rational decision maker.
Essentially, you make the lowest payoff on the tree, take the lowest payoff on the tree,
the highest payoff on the tree, and you offer the decision maker a lottery ticket that will
either pay this lowest amount or the highest amount.
Question?
What's the ticket worth?
Well, it obviously depends on the probability of getting the high payoff.
We call it P. A high P ticket is worth a lot more than a low P one.
To see how we use this lottery ticket idea to assign utilities, go back to the Gerber
problem.
The highest payoff was a million, the lowest was negative 5 million.
So we'd ask Gerber how high P has to be before they'd be indifferent between a lottery ticket
and a payoff on the tree.
The first payoff on the tree was 1 million.
Well, since the ticket either gives 1 million or a 5 million loss, Gerber would obviously
only take the ticket if P equals 1, if it always paid a million.
Similarly, the ticket would always be better than the guaranteed 5 million loss unless P
equals 0.
Any higher P gives at least some chance of dodging the 5 million loss and making a million
instead.
So the utility for 1 million dollars is 1, and the utility for negative 5 million dollars
is 0.
But the other payoffs depend on Gerber's risk aversion.
For example, if they're proactive, the CPSC only voices concern, and the public responds
badly, the payoff's negative 1 million.
To turn this into a utility, we ask Gerber this.
You either have to pay 1 million dollars or take this lottery ticket.
Sometimes the ticket makes you 1 million, sometimes it loses you 5 million.
How big a chance of winning does that ticket have to have before you don't care whether
you pay the sure 1 million debt or take your chances on the ticket?
This might take Gerber some time to decide.
Maybe they decide that a ticket with an 80% chance of winning would be just good enough
to tempt them.
One time in five, they pay 5 million, but four times in five, they make a million.
If so, the utility for this payoff is 0.8.
Someone who is risk-neutral will be willing to go to a P value of two-thirds, but Gerber's
more risk averse than that.
We'll ask Gerber this same question for each payoff in the tree, and we place each payoff
with the P value that they give us.
After this is done, we can roll the tree back just like we did earlier today, and the answer
would reflect how Gerber should behave in light of their own feelings about risk.
Clever, huh?
Well, to wrap things up today, I want to return to the other issue we raised earlier, the
matter of subjective probabilities or even the payoffs might be called into question.
I said that we'd look at the question of how much our decision hinges on the accuracy
of these values.
Let's look at it with the Gerber tree, where we assumed a 50% chance that the CSPC would
issue a recall.
How sensitive is Gerber's decision to this number?
There's a lot of software programs that will actually do such an analysis for you, but
it's easy to do by hand.
Let's look at the Gerber tree again.
Here I've stopped the rollback right before we evaluate the CPSC reaction.
If that 50% recall figure is wrong, let's replace it with a probability P.
Now we roll back to respond proactively branch, and also to respond reactively branch.
We do this in the way that we always do, payoff times probability, added up over all the cases.
On the top branch, this becomes 600,000 times 1 minus P plus negative 937,500 times P, and
so on.
For the bottom branch, you get this.
Responding proactively is going to be better if the top branch payoff is better than the
lower branch one.
Using the two payoffs that we just computed, this means that proactive is better if this
inequality holds, 600,000 minus 1 million 537,500 P greater than or equal to 1.5 million
minus 2.4 million P.
This is just a linear inequality, and it's easy to solve.
Like this, 2.1 million greater than or equal to negative 652,500 P, so we get that P has
to be at least negative 2.43.
Remember that probabilities are always between zero and one.
This negative 2.43 tells us that Gerber doesn't need to have a clue of the prediction of the
CPSC if the other figures are reliable.
Even with no chance of recall, Gerber still does better on average with a proactive stance.
This kind of analysis could be combined with a utility function model of Gerber's risk
profile to get a more complete picture of the situation.
But it's a decision for a proactive stance that's so far from a close call that it seems
likely that a more complete analysis wouldn't change it.
Oh, the actual history?
Gerber took a proactive stance, as I said.
The CPSC issued a statement saying, in part, one pacifier and two models of feeding bottle
nipples manufactured by the Gerber products company contained a related phthalate.
Gerber has stopped manufacturing these products and is removing phthalates from all future
production.
Gerber directed retailers to remove the phthalate-containing pacifier and nipples from store shelves.
Eventually the FDA and the CPSC and other organizations approved the continued use of
phthalates.
In the meantime, Gerber avoided another PR nightmare.
Decision theory lives in an interesting and important neighborhood of analytics.
They take on stochastic events straight on, not just random errors, but identifiable events.
At the same time, decision theory is an optimization technique.
Its job is to identify the best set of decisions.
This is the first time that we've taken a close look at such a combination, a stochastic
optimization technique, but it won't be the last.
You may be analyzing the situation that you face again and again from the perspective of
risk-neutrality.
You may be finding your way in an uncommon problem where your personal degree of risk
aversion needs to be considered.
Either way, decision trees offer a powerful way to reason forward by looking backward.
Turning to decision trees is one of the best decisions you can make.
