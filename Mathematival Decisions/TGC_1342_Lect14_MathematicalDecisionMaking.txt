I don't think I've ever heard of a company that wasn't interested in improving its efficiency.
Being more efficient means doing more with what you've got, or, equivalently, continuing
to do what you're doing now, but managing to do it with less.
You might not be able to say, this is the best way of doing things, but you'd certainly
like to be able to compare what your organization is doing to what others are doing in your
field.
If you find a weakness, you can go to school on the more efficient organizations, find
out what they've figured out that you haven't.
And it would be good to know if you are behind the curve, is it just a little bit or a lot?
It's even more important in the public and non-profit sectors where there isn't a clear
dollar bottom line to demonstrate success or inefficiency.
But how can you demonstrate inefficiency?
Well, the game is turning inputs into outputs.
Suppose that you start out with less of every input than I have, and end up making more
of every output than I do.
Well, then relative to you, I'm not efficient.
That's a no-brainer.
If there's only one input and one output from our production, things are also very easy.
Suppose that you turn 100 units of input into 250 units of output.
I turn 200 units of input into 400 units of output.
Then simple division gives our output input ratios.
You turn one unit of input into two and a half units of output.
I turn one unit of input into only two units of output.
I'm less efficient than you.
In fact, since my two is only 80% of your two and a half, we could say that I'm only
80% as efficient as you.
80% is my relative efficiency.
Now you can use this approach if you can reasonably assign dollar values to all of the inputs
and the outputs, since that effectively makes our problem a one-input-one-output problem
with money being the input and the output.
But how about when you have multiple inputs, multiple outputs, and no obvious way of pricing
them?
This often happens in the public and non-profit sectors.
For example, how do you compare the efficiencies of different universities?
Yes, they all value undergraduate programs, liberal education, research, and so on, but
different schools weigh the relative importance of these factors differently.
Or how do you compare police forces when each has its own resources and limits and its own
particular challenges?
One more example, program follow-through in the 1970s.
It was a federal program to help disadvantaged kids in the U.S. public schools and the government
what's now the U.S. Department of Education had collected the results for study.
They wanted to compare the approaches of different schools to find out what worked and what didn't.
But when the usual mathematical tools for an analysis like this were applied, none of
them seemed to be working very well.
Roughly those approaches worked like this.
You looked at it today from a lot of schools, then using tools like multiple regression,
you tried to find relations to say something like, if a school has this set of inputs,
then on average, it gives this quality of output.
When you find a school that does a lot better than this average, you figure that they must
be doing something right.
Well, the first problem with that is that it talks about output, not outputs.
We have multiple outputs in program follow-through.
Things like cognitive development, academic performance, self-esteem, and so on.
When you try to fit a problem with multiple outputs into a technique that can handle
only one, then you have to combine those outputs in some way to shoehorn them into that single
output slot.
And that means essentially that you have to decide, a priori, the relative importances
of the multiple outputs.
Besides, looking at deviations from average isn't really the right thing to do anyway.
It really doesn't matter how many average organizations you have when you're looking
for those few exceptional examples on the frontier.
The ones that might give you some insights into what constitute best practices.
Now, for program follow-through data, using the usual techniques, we're getting answers
that were unsatisfactory at best and absurd at worst.
So they came up with a new approach, one that ended up being useful for all the problems
I've mentioned so far.
They started with some previous research on efficiency and combined it with our old friend,
linear programming.
The result is what is now called data envelopment analysis, or DEA.
It was first published in its current form in 1978, but it's just as useful in the 21st
century.
Not only on problems like those we've already mentioned, but for tasks like benchmarking
hospitals, reading the performance of banks, evaluating maintenance activities on Air Force
bases, comparing performances of different university departments.
DEA was even used to help identify promising sites for the new capital of Japan, one far
away from Tokyo.
Tokyo is a lovely city, but it sits on the meeting point of three tectonic plates and
has earthquakes almost every week.
Bill McGuire, professor of Geohazards at University College London, has christened it the city
waiting to die.
So let's discover DEA for ourselves.
We'll start by comparing just two producers, in standard DEA terminology to be called DMUs,
or Decision Making Units, but producers is more familiar and captures the essence.
There are two different ways to think about their relative efficiency, one focusing on
inputs and one focusing on outputs.
The output perspective would say, you're more efficient than I if you can make more of every
output than I do without using more of any input than I do.
The input perspective would say, you're more efficient than I if you can use less of every
input than I do and still make as much of every output as I do.
I'm going to take this latter input perspective.
Greater efficiency means using less of everything to make at least as much of everything.
If you can squeak by and make what I make using only 60% as much of each input, then
my relative efficiency when compared to you is only 60%.
That's a decent start, but it leaves a lot of ground uncovered.
You might use less of everything than I, but make less of some things and more of others.
And then there are more than two producers in the world, it's you and me.
How does that change things?
Well, let's start by looking at a special case, one in which all of the producers have
the same supply of inputs.
Let's say I have nine teams of workers at a factory, and that each team is doing essentially
the same job, making units of the product and shipping them out.
Each team has the same inputs.
Now, those inputs might include a lot of things like raw materials and so on, but to keep
it simple, I'm going to focus only on personnel.
Each team has 54 people, 30 trained workers, 20 untrained workers, and four supervisors.
We'll also assume that they all face the same demand.
How about outputs?
Suppose we decide that there are two outputs that matter for a team, productivity and rush
responsiveness.
Productivity is the average number of units that the team produces per week.
Rush responsiveness?
The average number of rush orders that are delivered on time per week.
So for each team, I collect data on these two outputs.
Since there are only two outputs, we can show them on a scatter plot where the horizontal
position shows the productivity of the team, and the vertical axis gets responsiveness.
Just like in the graphical method for linear programs, looking at this easy-to-draw case
can teach us a lot more in a general context.
Ah, there we go.
So who's efficient?
Team 8 in the lower right has a great production of 1,000 units per week, but terrible responsiveness
with only about 30 rush order deliveries on time.
On the other hand, Team 2 and 5 both toward the top are great on responsiveness.
They leave the pack at 125 rush order deliveries on time, but they're not so great on quantity
produced.
If we're prepared to assign relative importances to responsiveness in production, then we might
be happy ranking one of these two above the others.
But without that kind of a priori decision, both Team 2 and Team 8 could be considered
efficient.
No one else can beat them in one output without being beaten by them in another.
This is a common definition of efficiency in economics, although it's also called Pareto
optimality.
Roughly a solution is Pareto optimal if there's no way to make one thing better than it already
is, without making something else that you care about worse.
But let's take this idea a bit further.
Look at Team 9.
Should I consider this team to be efficient?
After all, our notion of efficiency is kind of a best in class.
There are only three teams that make as many or more units as Team 9, namely Teams 1, 4
and 8, and none of them has as high a responsiveness score.
Well, true enough.
But look at it this way.
Suppose I took Teams 1 and 2 and blended them to make a hybrid team.
If you like, imagine I could each of them in half to make mini teams using only half
as much of each input and generating only half as much of each output.
I take these two Demi teams and stick them together, and we're still now consuming one
team's worth of inputs, 30 trained workers, 20 untrained ones, and four supervisors.
But how about outputs?
Well, this half and half hybrid will make 810 units, and here's how we get that.
Productivity of Team 1, one half of the productivity of Team 1, and one half of the productivity
of Team 2, is 0.5 times 900, plus 0.5 times 720, and that adds up to 810.
The productivity for Team 1 is 900, so half of Team 1 gives you 450 units.
Similarly, Team 2 has a productivity of 720, so half of Team 2 makes 360.
Put them together, and it's 810.
In the same way, the hybrid responsiveness is 100.
We get it the same way, but this time using the responsiveness scores of the two teams,
75 and 125, to get the answer.
Note that the multipliers were one half for each, since our hybrid is made up of one half
of each of the two teams used to create it.
Okay?
Let's recap.
We just created a virtual team, an imaginary blend of two real teams.
This hybrid uses the same resources as Team 9, but it makes 810 units per week, not 800,
and it delivers 100 rush orders on time, not 80.
So the hybrid uses the same resources as Team 9, but it outperforms it in both respects,
productivity, and responsiveness.
Conclusion?
Team 9 isn't efficient when compared to this mix of teams 1 and 2.
There's nothing that says that my hybrid team has to consist of a 50-50 blend of teams
1 and 2.
The hybrid that I really like is made from about 66% of Team 1, and 28% of Team 2.
Why?
Because if you work it out, you find out that this hybrid's outputs are exactly what Team
9's are, but it only uses about 95% of the input resources.
So Team 9's efficiency isn't 100%.
Compared with this hybrid, it's only about 95%, and that's the best you can do.
Makes sense?
For a problem like this one, identical inputs and only two outputs, there's an even easier
geometric way to think about what we're doing.
Taking a weighted average of two teams and having the weights add to one corresponds
graphically to identifying all of the points on the line segment that join those two teams
on the graph.
Combining more than two teams allows you to reach any point inside a region of which those
teams are the corners.
And what we're really looking for in DEA problems is the frontier.
What's the best you can do by creating virtual producers that are weighted averages of real
producers?
In our factory teams example, the frontier would look like this.
Both axes are outputs, okay, and more is better.
So higher is better, and further to the right is better.
Points on the straight line connecting two points are all hybrids.
Some producers made by blending the real-life producers that are the line's two endpoints.
You can start to see why this technique is called data-envelopment analysis.
We're building a convex envelope that forms the frontier of possible production.
How do we measure efficiency in this picture?
Well, if you're on the border, your efficiency is 100%.
So teams one and two are both efficient.
If you're not on the frontier, we draw a line from the origin, through your point, and onto
the frontier curve.
Look at how long the line is from the origin to the producer, and compare it to the line
from the origin to the frontier.
For team nine, for example, it looks like this.
If you measure carefully, you'll find out that team nine is 95% of the way from the
origin to the production horizon, shown in black.
That's what makes it 95% efficient as we computed just a minute ago.
But when you look at it, there's something a little wrong with this system.
I just said that anything on the frontier gets an efficiency of one of 100%, which means
that team five is efficient.
But compare team five and team two.
Both use the same resources.
All the teams do.
Both have 125 rush order deliveries on time.
But team two makes 200 more units per shift.
It's because of this that team five is called a weekly efficient producer.
It's not pro-80 optimal, since team two shows that you can do better on one output without
doing worse on the other.
On the other hand, you can't do what team five does with less of each input.
And that's why it gets 100% efficiency.
Well, I have more to say about such producers later.
So teams one, two, and eight are considered efficient.
And team five is weekly efficient.
And the remaining teams are inefficient to various degrees, depending on their distance
from the frontier.
You can probably imagine what the corresponding picture would look like in a problem with
three outputs.
The frontier would be a dome with flat paneled faces.
In higher dimensions, the math still works, even if the imagination fails.
But so far, we've been assuming that everyone has the same inputs.
And of course, that's often not the case.
Different police departments, for example, may have different funding, different staffing,
different numbers of cars, and so on.
How do we compare them?
Well, it turns out that we can use essentially the same idea on a slightly larger scale.
Let me sketch it out for you.
We're going to evaluate the efficiency of a specified real world producer, the target
producer.
We do this by comparing it to a virtual producer, a hybrid blend of real producers.
In our earlier example, we created a hybrid of just two teams, but you can use as many
as you want.
In order for this hybrid to have anything to say about the efficiency of the target
producer, it has to meet two conditions.
Condition one, the hybrid has to equal or exceed the performance of the target producer
on every single output.
Condition two, the hybrid has to use up no more of each input than the target producer
does.
Suppose that the hybrid meets these conditions.
In fact, suppose that for any input, the consumption of the hybrid never is greater than x percent
of the consumption of that input by the target producer.
Then we can conclude that the target producer is at most x percent efficient.
And the very best hybrid for comparison is the one that meets our two conditions and
uses as little of the inputs as possible.
That is, we want that hybrid that meets the conditions and makes that x percent as small
as we can.
We'll call that x percent the input fraction for now just to give it a name.
Okay, let me say the same thing in a slightly different way.
To make a hybrid, we decide how much of each real world producer goes into it.
These are called the weights for each of the real world producers.
A hybrid might consist of half of a producer one, a third of a producer two, and 2.5 producer
threes.
Weights can't be negative, but other than that, they can be whatever they want.
Of course, this hybrid isn't relevant to our assessment of the target producer unless
it satisfies our two conditions a moment ago.
Those are our constraints.
And our goal is to find the hybrid that meets these conditions and minimizes that input
fraction for that hybrid.
Goal, constraints, decision variables, we've got an optimization problem.
And since a hybrid is a linear combination of real world producers, it's a linear program.
Let's see what it looks like for the example of our worker teams when we're trying to
evaluate team 6's efficiency when compared to all of the other teams.
We start with a table listing the amount of each input that a real world producer uses,
shown in dark gray, as well as the amount of each output that it produces from those
inputs, that's shown in lighter gray.
To specify a hybrid, we have to give the weights for each of these real world producers.
Like this.
I've given them red borders because they're decision variables.
We get to pick them.
For demonstration purposes, I'm looking at a mix that's 90% team 2, combined with 5%
of team 5.
But it's going to be the spreadsheet's job to find their best values as usual.
Okay, next we have to figure out how this hybrid behaves.
How much of each resource does it use?
And how much of each output does it make?
We saw how to do this when we were creating the 50-50 blend of teams 1 and 2 earlier in
the lecture.
The gray box numbers in a given row are multiplied by the corresponding weights, which are in
the red boxes, and then the results are added to give the total for that row.
You might recall that's just the sum product operation that we used in our linear programming
formulations.
We record this value in a new column in the sheet to the right of our earlier example.
You can see, for example, that our hybrid uses only 19 untrained workers, and it produces
673 units per shift.
To make sure that you've got it, that 673 was computed like this.
Put the weights 0 times 900, plus 0.9 times 720, plus 0 times 300, and so on.
Add them up.
673.
OK.
So, how does this hybrid do?
Look at the last column.
The top three entries show that it uses less of each input than team 6, our target team,
and the last two entries show that it does better than team 6 on both productivity and
responsiveness.
The corresponding entries in the team 6 column, we've just shown that team 6 is inefficient.
But now, let's push our hybrid a little more, cutting down its inputs to only 97% of team
6.
Again, I've picked the number 97% out of the air for now.
Could our hybrid still function?
Hmm.
Well, what would it have available for inputs?
It's an easy computation.
The three inputs for team 6 are 20, 30, and 4, so we multiply each of those by 97% to
get 19.4, 29.1, and 3.88.
Again, can our hybrid function with these reduced inputs?
And we see that it certainly can.
Our hybrid needs are more than satisfied by 97% of team 6's inputs.
In fact, it would be satisfied with even a smaller fraction of the inputs.
95% is good enough for this hybrid.
But we want to find the hybrid that uses the smallest possible fraction of team 6's inputs
and still meets our performance conditions on inputs and outputs.
And since now we have all the pieces in place to do this, we just stick them all together
like this.
The hybrid column shows what our hybrid uses and produces.
Our inputs allowed, outputs required column gives us the conditions that our hybrid must
satisfy, use at most 8% of the target's inputs and still equal or exceed the team's performance.
Our goal is to minimize the input fraction that we're going to find, and we're going
to find the hybrid that does that.
And that, ladies and gentlemen, is the linear program.
When we let Solver Solve it, it gives this.
Which shows that a hybrid that's about 5% team 1 and 77% team 2 can make everything that
team 6 makes and do it with only about 82% of the resources.
That is, team 6 is only 82% efficient.
To evaluate a different team, we just replace the team 6's gray cells on the right with
the numbers from the team being evaluated.
Let's try it with team 5.
Here's what we get.
And this is the problem we were talking about earlier, weak efficiency.
Team 5 is on the frontier, so you can see it gets a 100% efficiency score.
But the linear program compares it to team 2.
And you can see that one of the constraints has non-zero slack, specifically the productivity
constraint, where 720 is strictly bigger than 500.
If the efficiency is 1, having any of your output constraints with a non-zero slack is
the hallmark of a weakly efficient producer.
Unfortunately, a weakly efficient producer can hide in the linear program.
How?
Well, another equally good solution to this linear program, an alternative optimum, is
to make the weight for team 5 equal to 1, and all the other weights equal to 0.
That comes down to comparing team 5 to the benchmark of itself.
And not surprisingly, then all the constraints have zero slack, because team 5 does exactly
as well with everything as itself.
This is one of the fiddly bits of doing data-envelopment analysis.
When there's more than one optimal solution, you always choose the one that maximizes the
sum of all of the slack in the output constraints.
Otherwise, a weakly efficient producer can go undetected.
Actually, a lot of the recent literature concerning DEA focuses on the fact that there are two
aspects to inefficiency.
The technical inefficiency, which is what we've been measuring so far, and the second
factor arising from weakly efficient producers who have slack and output constraints, which
frequently referred to as the matter of non-zero slacks.
Well, our example started with the assumption that all the teams had the same resources,
and this made it possible to create a frontier in an intuitive way on a scatter plot.
But the linear program that we just created doesn't require this assumption.
We've just built a machine that, with the obvious adjustments, can handle any number
of producers, any number of inputs or outputs, and doesn't require identical inputs for producers.
Let's look at an example.
Let's take a look at hospitals.
For our inputs, we'll take the number of beds, the number of doctors with admitting privileges,
and the annual number of dollars spent on capital equipment, averaged over the last
five years.
We'll also have three outputs, number of patients admitted, number of patients discharged, and
average number of beds in use.
Let's assume that we have five hospitals in the region of study, like this.
You know how to read this chart now.
Each column tells you about one hospital, so hospital one has 185 beds, 26 doctors, and
a bit over 2 million in equipment funding.
With this, it admits a bit over 9,000 patients, discharges 7,000, and has 130 beds in use.
The current run has us evaluating hospital five as the target.
The red cells show us that hospital five has been found to be inefficient, an efficiency
of about 81%.
If you run the program to evaluate each hospital in turn by changing the gray column on the
right-hand side, here's what you get.
Hospitals three and four are strongly efficient.
Hospital one, efficient, but only weakly so.
The virtual producer found in the chart, a blend of half of hospital three and point
two of hospital four, uses the same resources as hospital one, but discharges 25% more patients
and uses 25% more beds.
Still, there's no way to do better than hospital one in all three outputs using only its inputs,
so its efficiency is still 100%.
But there's obvious room for improvement.
Hospital two isn't far off the efficiency run mark with 97% efficiency, but hospital
five, the fairly small but decently staffed hospital and equipped, is less than 81% efficient.
If these hospitals are being supported by tax money, hospital five may have some explaining
to do.
The other hospitals in the study could accomplish what it does with only about four-fifths of
each resource.
In fact, we can see from the weights of hospital five that hospital three itself, scaled down
to about 28% of its size, would accomplish just about as much as hospital five all on
its own, but use only about 81% as much of the resources.
Which raises an issue, actually.
The DEA model we've been working with assumes constant returns to scale.
That is, it assumes that if you've got a company that can turn five units of input into ten
units of output, then you could scale that up and down to make a company that uses fifty
units of input for a hundred units of output, or one unit of input into two units of output.
This assumption isn't valid for a lot of markets, and for that reason, a lot of economists
didn't like DEA.
It turns out, though, that you can handle variable returns to scale by adding some constraints
to the weights.
So far, the only constraints that we have on the weights is that they can't be negative.
If a producer is strongly efficient in that model, the weights add up to one.
If the weights add up to less than one, the producer is operating under increasing returns
to scale.
While if the weights add up to more than one, the producer is operating under decreasing
returns to scale.
We can handle variable returns to scale directly by imposing an additional constraint on the
linear program, namely, all the weights have to add up to one.
It's not easy to visualize what this means in general, but I can give you an idea of
what it does by looking at an example with only a single input and a single output.
In this graph, it's different.
The horizontal axis is the amount of input the producer has, and the vertical axis is
the amount of output the producer makes from it.
In this picture, the requirement that the weights have to add to one restricts the hybrids
that you can use.
Specifically, the only hybrids that can be used as benchmarks are those within the envelope
that you get when you connect each point in the picture to every other point, like this.
It's called the convex hull of the producers, and those ones inside it, real or hybrid,
are the only ones that you can use in this model.
We're looking for the one in there that gives the best performance for the given amount
of output.
If you're on this red line, you're efficient.
Below it, and you're not.
Notice this is quite different from our original constant returns to scale model.
There A wouldn't have been efficient since it turns three units of input into three
units of output, a 1 to 1 ratio, while C turns nine units of input into 36 units of output,
an input-output ratio of 1 to 3, much better.
But variable returns to scale model says that C is benefiting from economies of scale.
Taking one-third of C is not a fair comparison to A. For that reason, even E is efficient
since no other producer has the burden of having so much input.
Maybe there's nothing to do once your supply exceeds demand except pay for extra inventory
and costs to store it.
In contrast to this, a constant returns to scale model would allow you to take the convex
hull that we just found and zoom it in and out from the origin, like this.
Anything inside that red cone is a valid hybrid to use as a benchmark.
And again, the top border of the valid benchmark is the efficient frontier.
You can see here that in this model, only C is efficient.
Not surprising since it had the highest conversion rate of inputs into outputs.
As we said at the beginning of the lecture, with one input and one output, that's all
she wrote.
Whether the constant returns to scale or variable returns to scale approaches the right one
depends on the producers that you're analyzing.
TEA is an attractive technique because it mathematically boils down into a linear program
and that means that we have all the tools that we need to analyze such programs and
that includes being able to solve them, but it also means we can look at sensitivity analysis.
Let's finish up with one quick example of how that can be useful.
For that, I'll go back to our analysis of Hospital 5, the one with the dreadful efficiency
of less than 81%.
Here's the right-hand side range report from the linear program.
Let's see what it tells us about the DEA program.
Very useful here are the shadow prices.
They allow you, among other things, to compute the marginal rates of substitution for the
inputs.
For example, take the shadow price of doctors and divide it by the shadow price of equipment
and you get negative 0.073 divided by negative 0.00068 or 106.4.
What does that mean?
It means that as far as efficiency goes, being able to reduce the staff by one doctor would
improve Hospital 5's efficiency as much as cutting equipment budgets by $106,400.
If the hospital is trying to increase efficiency by tightening its belt, this ratio could be
used to help it decide what kind of change might have less impact on the hospital's outputs.
Similarly, the shadow prices on outputs are reporting how much improvement in efficiency
would be obtained by managing just one more unit of that output.
From the report, we can see that the hybrid significantly outperforms Hospital 5 on check-ins
and check-outs, so even if Hospital 5 improves somewhat in these regards, it doesn't help
its relative efficiency.
Using on average one additional bed per week, though, would increase its efficiency rating
by about 2%, since the shadow price of this constraint is 0.02.
DEA has a lot going for it, especially the way that it doesn't require you to prioritize
the values of the differing outputs, but it's got its own problems, too.
One of the biggest, in my opinion, is that the results that you get can depend considerably
on what you consider to be the inputs and the outputs.
In our hospital example, we took patients admitted as an output based on the notion
that the hospital that admitted more people served a larger community or served the community
more thoroughly.
We also had discharges as an output, since a patient who was discharged presumably got
well enough to go home.
I confess that if a hospital quadrupled its admissions, while its discharges fell to zero
– I'd be concerned – sounds like a plague with no one getting well.
The worse your ability is to select meaningful inputs and outputs, the more nonsensical the
results may be.
There's also a problem when the number of inputs and outputs in quantities becomes
very large.
A virtual producer has to outperform the target producer in all respects in order to be identified
as inefficient.
And as the number of inputs and outputs becomes large, this is harder and harder to do.
More and more producers of the class is efficient in some ways, and they may be, but only in
a very narrow niche market.
DEA works well with multiple inputs and outputs, but not myriad inputs or outputs.
DEA has allowed us to consider and compare efficiency in a more comprehensive way.
But what if efficiency isn't your only goal?
Remember the factory manager who was so proud of his efficient robots?
How do you evaluate the quality of a solution based on more than a single objective?
Big problems are real and important, and not just when evaluating efficiency.
So I'm going to take our next lecture to explore how we can analyze such situations.
And not surprisingly, we're going to need to consider some things that so far we've
been able to ignore – trade-offs, priorities.
And when pretty good, it's good enough.
I'll see you then.
