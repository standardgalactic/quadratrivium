Hey, everybody.
So I want to talk today about simplicity and complexity and how they are not as different
from one another as we often think that they are.
But first, in the spirit of full disclosure, I want to tell everybody, I'm an economist.
And when most people hear that, they think that I'm the guy that is yelling in the stock
wave in papers, or I'm the guy that refinances the mortgage on your house, or I set the interest
rates on your bank loans.
Myself and most other economists do none of those things.
Instead, the job of the economist is to take data and build models that predict the way
the world works.
And usually, that's a human process, right?
And all economists start by learning about the same model.
This is called supply and demand curves, right?
And this is the first model that every economist learns on the first day of Econ 101.
Now, for some of you, this was the bane of your undergraduate existence, and you barely
made it through this class, right?
But for those of us that really liked it and enjoyed it, it was something really neat,
because it's an abstraction of the way the world works.
But yet, it's simple, and there's a power to it that helps you make high-level predictions
about a complex system.
Now, as you go on in your economics courses, you learn that underlying that first model,
there are a bunch of rules and assumptions that a bunch of really smart people have argued
over for the better part of the last century, and you're at the same time excited and disappointed.
Excited because you're learning something new, but disappointed because that first model
that you learned about is not as simple anymore.
It's further away from reality, and you find out there are variations to it.
Now, if you go on again and go to graduate school, you find out that that model that
you learned about first has brother and sister models, each of them with their own sets of
rules and assumptions, and each of them that other smart people have argued about for a
long time.
That picture becomes cloudier still, less simple, more complex.
Then you do some reading on your own, and you find out that overall people are generally
irrational and behave in highly unpredictable ways.
At one point in history, every assumption that underlies every one of the models that
you've learned thus far has been proved wrong by a thing that actually happened in real
life.
You get really frustrated at this point, and graduate, and then go become a banker and
never think about any of these things ever again.
In graduate school, I got frustrated with this cycle, this laundry machine where you
go and learn about a model and learn about how it's really neat and predicts a complex
system, and then learn about all the things that make it wrong and not actually representative
of reality.
Moreover, I started my education as an engineer.
Engineers are really good at taking a complex system full of little parts, assembling it
together into a whole, and predicting how that system is going to work, not just five
minutes after you turn it on, but five years after you turn it on.
Why can't we do the same thing in economics?
We have a lot of data, we've got a lot of smart people, we've got a lot of history
there.
Why can't we do the same thing for systems of people to make better predictions?
The nice thing about economics is that there are lots of examples of complexity for you
to try and wrap your head around this issue.
This is one of them.
This is a graph of stock market activity across a number of different stock indices in the
year 2007.
What's special about this graph is that this is only activity carried out by automated
trading algorithms.
That is, algorithms that go out and search in the stock market for patterns.
When they see the right pattern, they execute a sale or they buy that stock without human
intervention.
You can see here, this is pretty much blank.
There's not a whole lot going on here.
This was a typical day last year.
Wow.
What happened there?
Did robots take over?
Before you go home and talk about the crazy guy at TEDx Columbus that told you robots
took over and then cash out all your 401K and hide that money under the mattress, don't
do that, please.
That's not quite what's going on here, but to me, that's actually not the most interesting
question that I think you can ask when you see this.
The difference from 2007 to 2012 represents a trend, a pattern.
In 10 years from now, say that trend continues, what will it mean to say that you've invested
money in that system?
How would you describe that to somebody that has no idea what the stock market is?
We have a hard time sometimes describing what we've invested in even today.
How would you describe that?
More importantly, what happens in 10 years when this system is confronted with an event
that is never experienced before?
Is it going to crash?
Is it going to be able to adapt?
We don't know right now.
These are questions that traditional economic modeling is not very good at answering.
Here's another example.
For those of you that have seen the movie, A Beautiful Mind, you should recognize this.
This is a famous game from a discipline in economics called game theory called the prisoner's
dilemma.
The way it works is like this.
You and your buddy go out and do a hypothetical crime, and you both get caught, and you both
get brought in, and you can get put in separate jail cells.
The police give each of you the same deal.
They say to you, if you rat on your buddy, you get to go free, but your buddy goes to
jail for life.
They say the same thing to buddy and the other.
If neither one of you talks, they'll put you in jail for lesser charges, and you'll
both go away for a little bit.
What they don't tell you, because they're devious, is that if you both confess, they're
going to put you both away for a long period of time, because they've got a confession.
They don't need anything else.
The way this plays out is as follows.
You have an incentive to improve your outcome by confessing on your buddy.
Your buddy has an incentive to prove his outcome by confessing on you, so you both always confess
on each other, and you both always go to jail for a long time.
Again, this is a neat abstraction.
It's a model of the way that the world works, and it makes sense, and it's a good model
of a reasonably complex system, which is the interaction between two people.
In real life, though, it's actually even more complex than this.
What really happens is, the police bring you in, and they bring your friend in.
Between the two of you, there's a relationship that probably plays out very similar to the
game that I just showed you.
However, then they bring in your friends and your buddy's friends, and there's connections
between them.
There's connections between you.
They probably know all each other, and they probably know your buddy, and some of them
probably know you.
Then they bring in friends, family, and witnesses, and attempt to get even more information about
the situation, and some of them may have connections with these aggressive people.
What you end up with is this network of people who are all simultaneously playing their own
version of the Prisoner's Dilemma game with every other person in the network, continually
as information is updating as they're being told different things by the police.
It's a lot less fun of a game to solve.
If you're the police, it's an important game to solve, because it's a time-sensitive issue,
and soon, both guys are going to be out on bail.
If you're the police, you want to know where's the point in this network where I can apply
pressure such that the right incentives will flow through the whole network, and you can
get a confession from one of the two suspects.
Again, traditional economic modeling not very good at solving these type of problems.
Now, at this point, you're probably saying, it's no wonder that our politicians and bankers
get this stuff wrong all the time, and in some sense, you're right, it is no wonder
they get it wrong all the time, but there is a way to start to understand these things
such that you don't have to be intimidated by the complexity, and instead, you can embrace
it and start to make meaningful predictions about it, and I'm going to talk about one
of those ways today.
What I want to talk about is a thing called emergence, and emergence is the idea that
you can take the small parts in a system and look at the interactions between them and
put them in a simulated environment and watch the complexity of that system emerge spontaneously
rather than building it in explicitly.
Now, that's a little bit abstract, and even though we're at TEDx, that's still a little
bit abstract, so I'm going to give you an example of something that's hopefully familiar
to everybody.
This is a flock of birds.
Hopefully, everybody's seen a big one of these, and when you see it, it moves very organically,
and it's a complex system.
It's made up of a lot of individual parts.
Now, if we're going to take a traditional modeling approach to making a prediction model
about how a flock of birds behaves, we would probably do something that involves making
an algorithm that says where each bird in the flock is supposed to be relative to every
other bird at any given point in time, and then we'd build in some additional algorithms
that talk about things like food, talk about avoiding predators and other behaviors.
But 9 times out of 10, if you build your model this way, it's going to eventually either
end up looking really robotic, not lifelike like we want it to look, or it's going to
be confronted by a scenario that's not programmed in there, and it's going to crash.
It's going to crash your model, crash your computer.
So, instead, what I propose is to build this complex system differently.
Build it instead based only on the interactions between the individual parts in the system
and let that complexity emerge.
What about, if I told you, I only want three rules for every individual bird in the flock,
right?
The first rule is going to be don't hit your friends.
That's not nice.
You'll get exiled from the bird flock if you do too much of that, right?
Second rule is fly the same direction as everybody that's kind of in your cone of vision, because
they all probably know where they're going.
Second rule is don't be the lone straggler in the closest group of guys waiting to get
picked off by a predator.
There's safety in numbers, okay?
If I put all of these together in a simulated flock, in a simulated environment, I get these.
The solution to that is the solution to a famous emergence problem from the 1970s, called
BOIDS, B-O-I-D-S, where there were a bunch of biological researchers struggling to learn
about complex biological systems.
Now, those three rules I just showed you are the basis for all swarm and insect logic that's
used today in every application from computers to the way that drones fly around for our
military, right?
And you might say that, hey, Joe, a flock of birds is one thing, right?
But humans are infinitely more complex.
And they are.
That's very true.
But we don't need to be intimidated by that.
That's actually a good thing for emergence, because it thrives off of the interactions
in a system.
And one thing I know is if you get a group of people, they're going to interact with
each other, even if it's not always in obvious ways, right?
So what you can do is take those same three rules that I just told you about, and start
to apply them to systems of humans, right?
You can start to look at things like traffic patterns and traffic congestion.
Start to look at spontaneous human organization into systems like governments, coalitions,
political parties, insurgencies.
Start to look at the movement of crowds and pedestrians, the way they flow, the movement
of riots.
Start to look at the dissemination of information on social networks on the Internet.
Look at the outbreak of disease and the way it spreads through a population.
You can look at the spontaneous growth and organization of cities, urban sprawl, and
the formation of slums.
You can bring it all the way back to the economic hurting behavior and irrationality that was
at the very core of the last financial meltdown that we just experienced.
These are simplifications of the rules that you use to actually try and simulate these
things, but you can begin to see the power in thinking this way.
It's a power in terms of adaptability of using small to become big and using a minimum
number of rules to do so.
This is a quotation that I really like, that I think sort of summarizes the direction that
this sort of thinking can take us.
It's very much a place of convergence, synthesis.
Using this type of thinking, a lot of disciplines are going to start to mesh and come together
with art, science, mathematics, physics, engineering, because you can begin to solve
the hard problems in every one of those disciplines using the same way of thinking about things
if you use emergent systems, but it's not going to be easy for us.
Our brains are hardwired instinctively to respond to complex systems in one of two ways.
We either dive deep when confronted with a complex system to the part that's most familiar
to us, the part that makes us feel at ease, that we feel we understand the best, and we
tend to ignore the rest of the system, which may actually have important elements in it
that help you understand that system.
Or the other way that we go is we try to take it all in at once, try to understand the whole
system at one time, but it's too much information, and we can't.
So we start to make up rules and assumptions and introduce bias into the way that we understand
the system.
Now, both of these things on their own can lead to bad predictions, but increasingly
the world is going to challenge us in new ways as well, because things are getting faster
and more complex at a rate that we've never seen before, right?
Data is getting bigger, information is flowing faster, people are getting more and more connected,
and these types of networks of complex systems of people spring up overnight and disappear
just as quickly.
How can you even begin to understand something like that unless you have a better way of
looking at it?
The real danger, especially for those of us that are technical folks, is that the solutions
that we come up with, the problems, are going to be obsolete by the time we are ready to
deploy them, right?
When we put that differently, it's not going to be enough in the future to just solve problems.
We're going to have to recreate the system that led to the problem in the first place
and understand it if we want our solution to have any chance of succeeding.
So really put in context where we're at today, I want you to imagine a dog, it's a dog you're
going to raise as a pet, right?
We generally have a pretty good understanding of the behavior that dogs have, right?
We know based on our observations of dogs throughout history, there are certain things
they're not going to do, right?
A dog is not going to talk, right?
And we use those observations and about the limitations of behavior of dogs when we interact
with them, when we try to train them and try to understand them.
Now I want you to imagine a child, right?
A child is significantly more complicated than a dog, right?
And the spectrum of behavior that a child can have is significantly wider than a dog,
right?
We think we generally know what kids are going to do, but any parent out here will tell you
every now and then kids will do something completely unexpected that we didn't think
that they were capable of, right?
So on the whole though, we still think we have a pretty good idea of how to raise children
while at the same time acknowledging that from time to time they're going to do things
that are completely outside the bounds of what we can imagine they're capable of, right?
Now I want you to imagine a hypothetical child, right?
This child is the same as any other child except that every 30 minutes this child takes
on the personality intelligence level of a random child somewhere in the world, right?
So for the first half hour, the child might be completely normal, right?
Second half hour, the child might have ADHD.
Third half hour, the child might have emotional problems.
Fourth half hour, the child may be completely unresponsive.
In the last half hour, the child might have a genius intellect, right?
How do you even begin to bound what kind of behavior you would expect from that child?
So the dog in this example is like the complex systems of the last century, right?
The ones we're used to, the stock market of the mid 1900s, for example.
We have a really good idea, even though there's uncertainty in there, of where that uncertainty
is bounded.
We think that the complex systems of today are like that middle child, but really they're
already becoming and will increasingly become much like that last child, right?
And how would you even begin to understand that last child with traditional child psychology
and traditional ways of raising that child, right?
I would contend that the only way that you can start to understand that child and start
to make predictions about what they're going to do is if you live in the moment, right?
If you understand the small scale behavior and the low level interactions between you
and that child without worrying about things like what their eventual career is going to
be or where they're going to go to college.
This is the way in which we can begin to understand the complex systems of our world.
This is the way we can begin to predict the things that are going to emerge from them.
Thank you.
