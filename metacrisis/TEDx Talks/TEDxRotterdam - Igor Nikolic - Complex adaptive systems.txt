I'm going to do a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little bit of a little
well.
Tonight, when you go home, you'll perform a very small, seemingly insignificant action
which will have dramatic global consequence.
When you walk into your room tonight you'll flip a switch and lights will go on.
You see here is what NASA sees from space when there's no clouds and the lights are
off.
The big light is off, obviously.
Now, let's just think about for a second what happens when you turn on a light.
The moment you flick that little switch, this global massive machine of cables, power plants
comes into action and delivers just a little bit more power, right?
Because every old power that is used has to be produced.
That moment, because of an agreement we had hundreds of years ago, this power plant starts
spinning producing 220 volts at 50 hertz.
That power flows then from that power plant, goes into several different markets where
it's traded, crosses a number of borders, and flows into your light bulb.
And there is light.
But that's not something that just happens like that.
And also, that's not something we always used to have.
So how come that these things are really here for you to perform this unconscious action
without thinking?
So what you see here, the red dots, are all the power plants, some 55,000 plus of them
on our world, that are feeding us this power.
Now what's interesting about these machines is that it's not just the physical things,
even though there is a tremendous amount of them, right?
There is this huge, huge power plants, I don't know if you've ever been in a power plant.
There is turbines bigger than me spinning at 30,000 rpm.
These are violent things that are connected with cables across borders.
They have all of these big physical components.
But also, they're social entities.
There's markets who trade power.
There's people or companies that own these power plants.
There's people that work there that have families that need to have laws to protect them from
people breaking into houses.
They have to have insurance for their health and when the heart attack hits them, all of
these things.
So how does such a socio-technical system, this big beast, come to be?
And what does it do?
Well, what you see in a second when the computer decides that it's time to evolve further,
you will see the minds that feed this massive machine.
These are some 300,000 minds as known by the United States Geological Survey that feed
this socio-technical beast and it eats copper, gold, oil, it has to be shipped all over the
place.
And it also poops, right?
There's CO2, there's dioxins, there's car tires, there's junk coming out in the end.
Now, this thing was not here always.
There was a time when there was no light on the planet other than small fires of hunter-gatherers
sitting some 60,000 years ago in Africa sharpening the stone tools, telling stories to each other.
And from this story telling, the sharpening of tools, a system has grown to be all-encompassing
global system producing useful things like this.
But that's not the only thing it does.
It has also evolved to be highly unsustainable and I think in a setting like this, there
is really no reason to elaborate on lack of sustainability.
Now there is one common property, ah, that's supposed to be spinning, I see, there we go,
you get a picture.
Anyway, so what is special about these systems is that they are so-called complex adaptive
systems.
Now, here is one, I don't think it needs much introduction, and the way we understand
complex adaptive systems is being things that consist of many, many different entities acting
and reacting to each other without any centralized control, having a so-called emergent behavior,
creating a pattern of behavior that looks like something you can recognize, like a city,
an industrial region.
Now there are two very important properties that complex adaptive systems have that most
people are not aware of that are of great interest to us if you try to understand how
these things evolve and how to shape them towards a more sustainable future.
One is that they are complex, and I will explain in a second what I mean by that, and the second
is that they evolve thus they are intractable, big word, and let me tell you what it means.
So complexity is understood by some scholars as the inability of single language or single
perspective to describe all the properties of a system we observe.
So we have to have these multiple languages, we have to have these different perspectives
just to understand the complex system.
And that has a very, very important consequence, just one second, and that is that nobody really
understands everything.
By necessity you don't understand everything, you also don't know anything.
Regardless of politicians, managers, conspiracy theories tell you nobody is in control.
We all are, but in very roundabout ways.
And the second property I alluded to is intractability.
Now intractability is something that evolving systems do.
What you're looking at now is a graphical depiction of this fairly complex idea.
The white line is us progressing through time, making decisions, events happening, and things
evolving over time.
All the red things are all the futures that did not happen but could have, right?
If I had driven my bicycle a little bit less careful this morning, I could have been hit
by a truck, I would not have been here, and maybe I would have not inspired somebody.
I hope I do.
And then the world would have looked differently.
And that's true for every single one of us doing actions every single day all over the
place at the same time.
And intractability also means that there is no faster way of predicting the future other
than just going there.
You cannot jump into the future, you have to go through the steps.
So what does this really mean?
Well, it means a couple of things.
If we are to have a sustainable world, we have to consciously shape it.
But nobody knows what's going on, nobody can control everything, and nobody can predict
everything.
Now what?
Well, I wouldn't be an engineer if I wouldn't say, well, it's here, it's real.
Now let's deal with it.
Let's do something about it.
So what we try to do at our group at UDELFT is to say, well, let's represent the real
world in all of its facets, all of its complexity, and try to grow possible futures.
We use sophisticated internet technology, semantic web, some of you might know it as
Web 3.0, to collect these multiple perspectives, these multiple ways of thinking, different
types of data, and bring them together into computer entities that we call agents.
Agents are things, in this case, their governments, their firms, their people, their consumers,
and they know things and they do things.
So an agent is a thing that does things to other things, people like to say.
So what we do is create these gardens of things, agents, we let them interact, they do things
to each other and with each other, and patterns of behavior emerge.
What you're looking at is an agent-based simulation of the Dutch electricity sector.
This is work done by a graduate student of ours, Emile Chappan, who has looked at what
happens to the Dutch electricity sector under different government conditions and under
different types of policies.
And since we cannot predict, what we do is the following.
We run thousands upon thousands upon thousands of experiments, gigabytes and gigabytes of
data.
Things run for a month on the biggest computer we own at Udelft.
And they generate many possible ways of how the world could look like.
Again, we are not predicting, as nobody can do that, we're just exploring where the things
could go.
And out of this pattern, out of this data, a pattern starts to emerge.
And one specific pattern that I can, oops, I'm sorry about that, one pattern that I can
tell you is that the current way how the EU has set up CO2 trading is not going to work.
Be prepared for very expensive electricity and very little reduction in CO2 because
what these patterns tell us that firms really like taxes, which sounds very paradoxical,
but taxes are predictable.
You know how much you will be taxed, and that also means that you can invest in these very
expensive, very large physical systems that you need to create in order to reduce CO2.
Okay, so this is a very specific type of insight for a specific model.
What I would like to share with you is four more fundamental insights that stem both from
complexity theory and theory of evolution, and from our experiences with working with
these things.
So how does one grow or evolve a sustainable social technical system, a sustainable society?
Well first, you have to start bottom up.
Decentralized is the key here.
Each and one of you might have that one idea that, if connected correctly to others, will
bloom into something.
Think about why, for example, people don't like what happened in Copenhagen for the climate
things.
There was no one centralized decision.
Well there never could be one, there never will be one.
We can never possibly agree what sustainability even is and let alone how to deal with it.
So we just have to act.
We heard this morning a fantastic example of greenhouses.
Just go out and build them, and things will come.
Second, we have to learn to fail gracefully.
This is a very weird thing, because when you think about it, evolution is all about trial
and error.
Not trial and success.
We like success because it's so special.
But what we really do a lot is make mistakes all the time.
Now the question is, how do we make mistakes in such a way that we can recover from them?
How do we do social experiments in a city like this?
There's no social problems that we have to try to solve.
So how do we do that without making a big mess?
How do we try different things in the environment without destroying it?
And how do we learn from things that went wrong?
So that's something we really have to address.
And we have to grow.
And what I mean by that is that it has to be a step-by-step thing, evolving, adapting,
learning.
You cannot jump into the future.
You have to go there.
And finally, maybe even most importantly, we have to do it together.
As I already said, complex adaptive systems consist of many, many distributed elements
or acting, interacting.
And it's only when people come together and connect in meaningful ways can we create big
things.
Places like this, for example, are our prime example.
Think about things like Wikipedia or Linux or Creative Commons.
Now what I would like to do is to show you an example of a real evolving social technical
system.
As we have been doing these things and applying these things to ourselves, in the middle of
words, eating our own dog food, we have been studying how our knowledge structures encoded
in a wiki have changed over time as our understanding of these systems grows.
So what you will be seeing here in a minute is the structure of a wiki at wikithew.nl
where each page means a different perspective, a different set of facts, a different set
of data interacting with each other.
So let's look at it.
And as time evolves, as people contribute, knowledge is structured.
You can see that, oh, I'm sorry, there goes my dramatic effect.
But again, recovery hopefully in a graceful manner.
I hope.
There we go.
So I hope you can see it.
There are yellow dots which are pages that are really important.
Knowledge that we find relevant, data that we are collecting.
There is red stuff, stuff that we abandon that's not interesting anymore.
But we have a history.
We have a way to recover from failure because there's things we've done in the past that
we will not repeat again.
It's there.
As you see, it's a very organic growth.
So social and technical systems co-evolve.
You can see vacations, people going on holidays, you can see weekends in here.
People are working, creating, structuring.
And some things are not connected, they fly off, never to be seen again.
And that's a part of evolution.
I would like to point your attention at February 2009.
So far, this thing is a small research project running under my desktop on a little computer.
And at one point, we decided to open it up to the wider community of university in Delft.
You will see this sudden burst of activity.
There's Google coming in, it's indexing us, people are adding more, there's more people
coming in, there's energy being created, stuff is growing, understanding is growing.
And in fact, what you're looking at is the social and technical process that led to me
standing here talking to you.
And with this, I would like to close.
I'll do it.
Thank you.
And I would like to invite you all to join us in this evolution and contribute your perspective,
your knowledge, your data, your questions, and how you can do these things.
Contacting us.
And these things are not easy to use, I must say that.
So if you give us a call, send us an email, Twitter us, whatever.
We are certainly doing our darn best to do so.
I think that's a good comment.
Igor Nikolich.
Thank you very much.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
