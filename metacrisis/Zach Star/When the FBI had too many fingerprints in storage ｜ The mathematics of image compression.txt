This video was sponsored by Curiosity Stream, home to over 2,500 documentaries and non-fiction
titles for curious minds. Since 1924, the FBI has been managing a huge collection of fingerprints
taken from people all around the nation. By the year 2000, they had a few hundred million sets
of fingerprints in storage. In the beginning, way before all the cool technology we have today,
they simply store these fingerprints in filing cabinets, thousands of them. And every day,
they would receive tens of thousands of requests to do fingerprint comparisons,
which as you can guess was no easy task manually. Finally, when computers and more advanced technology
came into the scene, they could start storing files electronically, but even by the 90s,
they were still having some problems. Each set of fingerprints took up about 10 megabytes of
storage, but it wasn't actually storing these that was the issue, but rather transmitting them to
computers around the nation. With all the requests coming in, occasionally from remote
locations where connections were extremely slow, they weren't able to transmit the digital images
fast enough, so they needed some way to reduce the file sizes. The algorithm developed by the FBI,
along with some government funded labs, became a standard in how fingerprint images were stored
and transferred. A deep look at the mathematics of this technique is way beyond a 15 minute
YouTube video, but we can get a very good idea for the general concept and how they managed
to reduce the necessary storage by a factor of 20. So let's see what they did. As I said in the
applications of matrices video, which I'll reference a few times here, a digital image when
you zoom in is just made up of a bunch of pixels, each of a specific color, and those colors are
represented by some numerical value. Now for this video, like that previous one, we will only be
worried about grayscale images, where we can have black, white, and a continuous spectrum of
different shades of gray. So pictures like these. Now to send a digital image, we could just send
the numerical value associated with every single pixel, which would then be reconstructed on the
other end. But that's a lot of information and we need something much better. To understand the
algorithm that was used, we first need to realize that we can make any image from this all the way
to this or the Mona Lisa or whatever using sine waves. If that seems super weird, don't worry,
it did to me too at first, because it doesn't even seem like images and these functions mix.
But here's how they do. First, I'm going to graph z equals cosine x, which will yield a 3d
plot that looks like this. All this is is a regular cosine curve extended in an extra dimension.
But we sort of don't really care about the 3d aspect, because what I'm going to do is color the top
of this black, the bottom will be white, and there'll be continuous fade in between. So a spectrum
of gray. And we're going to look at this from the top view only. What we have here is a two
dimensional cosine curve. It's an image that oscillates back and forth in one direction,
but in color rather than height. And you'll notice it's constant along the y axis.
If I instead graph z equals cosine of y, then we get the same thing,
but the colors are constant in the x direction and change in the y direction.
If I increase the frequency, then we get faster changes in color,
and lower frequencies correspond to slower changes.
Now, if I graph cosine of x plus y, then the colors stay constant along a 45 degree angle.
This is what we really care about. Cosine of some number u times x plus another number v times y.
When you and v are the same, we get what we see here. The colors are angled at 45 degrees,
or 135, depending on your reference. And as I increase u while decreasing v,
you'll notice that the angle changes, as well as the frequency in this case,
until we get to v equals zero, where the colors are oriented vertically like we saw before.
Now, if we take, let's say, cosine of x and cosine of 2y, then combine them,
we get a slightly more complex image whose equation is cosine x plus cosine 2y.
If we then add in something like cosine 0.5x plus 0.3y, we get this. It gets more chaotic.
And it turns out, if you kept doing this with just the right functions,
usually an infinite amount, you could create any grayscale image you wanted.
So yes, any picture you see can be thought of as a bunch of 2D sinusoid's added up.
There will be different coefficients associated with these that has to do with the magnitude of
each image, but I'm not as concerned with that here. Then if your image has, let's say, a cosine
of x in it, which I'll write as cosine of 1x plus 0y, so we can just see the coefficients,
we can represent this simply by using a u and v axis and a dot at 1 comma 0, 1 for the u,
and 0 for the v. So for any cosine of ux plus vy, we can just use points to say
which u's and v's are present in our image. This means for cosine of y, there'd be a point at 0 comma
1. And cosine of x plus y would yield a point at 1 comma 1. And you'll notice that scaling a point
on this graph or in what we call the frequency domain leads to a different frequency in the spatial
domain. And rotation in the frequency domain leads to rotation in the spatial domain.
By the way, just for a few upcoming parts, notice a point on the vertical axis here
corresponds to an image with horizontal edges, and the opposite would be true as well.
So now you know what an image will look like based on a single point located on the Fourier
transform graph. But like we saw before, real images are made up of usually infinitely many
of those sinusoid, therefore their frequency domain will consist of infinitely many points.
I know this probably looks like nonsense, and it is just a random 2D Fourier transform graph,
but just realize these are a bunch of really small dots that represent all the many many
sinusoids in some function. And the bright spot here means most sinusoids lie in this area,
in this case with the u and v fairly close to zero. So now what do you think this 2D Fourier
transform will look like for this image here? No, this is not the same as what we saw before.
The images before had a fade from black to white and vice versa, but this has distinct
edges. So if I use an online Fourier transform program I found, then we get this graph here.
Again this looks strange, but here the bright spot we care about is actually a horizontal line of
points. These are pretty much all the sinusoid that make up the image. Here might be like cosine
of 0.5x plus 0y, no y component because it's on the x axis, but then there's cosine of 0.51x,
0.52x and so on. We got to combine all these sinusoids to get the striped image on the left.
And this makes some sense because points along that horizontal line correspond to vertical edges
like I mentioned before. If I then replace the striped image with a more complex and very famous
one in the image processing community, we get a more hectic 2D Fourier transform, but there's
still visible info here. Like these slanted streaks in the frequency domain correspond to slanted
edges in the original image. Like these two here correspond to the legs of the tripod.
The program I'm using allows me to actually remove any part of the frequency domain,
and you'll see if I black out those regions, then reassemble the image without those sinusoids,
we get roughly the same thing with some distortion, but the legs have been smeared you could say,
and they're definitely not black like before.
Now I'm going to use a different image for this next part just because it works better,
but what I'm going to do is take the Fourier transform and apply a low pass filter.
This means I'm going to keep or pass all the sinusoids where u and v are close to 0,
but I'm going to remove everything else, aka the sinusoids with faster oscillations,
and then I'm going to reconstruct the image. Then I'll do the same thing,
but the opposite where I'll keep only the higher frequencies. So what do you think is going to
happen in each case? Well, I think it's easier to see this when you imagine a normal curve that's
made up of several cosines added up. Because if you remove some of those higher frequencies,
you lose the fine details in your signal, those little oscillations, but you keep the overall
picture, there's your hint, in that you can still see, hey, this looks similar to a square wave.
But if you instead remove the lower frequencies, then you kind of lose that big picture, but you
keep all the fine details or those faster oscillations. So back to our image, if we remove
the high frequencies, aka the fine detail, we get this. It's simply a blurred version of the original
picture. We can still interpret what this is like that previous curve, but when I say we lost the
but when I say we lost the little details, I mean the edges. That's what blurring really does.
It smooths out the quick changes in color, which is what an edge is.
In fact, in another video, I showed a different technique for blurring and I did it with the
number one. Here, the blurred image is outlined just to show the general shape is still there.
But the main takeaway was that the very defined edge from black to white that made the number
easy to read became smoothed out by the blurring, creating this fade from dark to light.
And for our technique, the same thing pretty much happened. High frequency sinusoids with
fast changes in color that create those defined edges were removed, leaving sinusoids with more
of a fade and slower transitions, giving us an overall blurred image. So a low pass filter is
really just a blur filter. Now, if we go back to our image and do the opposite, keep the high
frequencies, but remove the lower ones, we then only keep the fine details or those edges.
So we lost most of the picture, but the edges are still there, which is why a high pass filter
can be considered an edge detection filter. And decades ago, edge detection was used by law
enforcement to catch someone guilty of assault by analyzing an image of their arm to reveal a very
specific tattoo. So yeah, this does have important applications. Now we're pretty much there,
but we just need to acknowledge the fact that sinusoids actually don't handle edges and quick
changes very well, whether it be for an image or a signal, as you can see by these extra unwanted
spikes on the corner here. So to deal with functions or pictures that have very abrupt changes,
we want something more localized that doesn't oscillate forever, which is actually the main
issue with sinusoids. To help with this, we use something called a wavelet. These are like
sinusoidal pulses that decay to zero pretty quickly rather than oscillate forever.
Now, just like before, we can scale or shift these. And even though the equation is more
complicated, it leads to a simpler function representation in the end. I'll call the
general equation for a wavelet psi, because it turns out with just scaling and shifting,
we can sum up several to infinitely many wavelets to create the function we want,
whether it be a curve or an image, just like before. And if we take the coefficients associated
with those wavelets and transmit those rather than the pixel values of an image,
we have a main aspect of the wavelet scalar quantization algorithm, which is finally what
this video was about. It's quite complex with several components, but hopefully this gave you
a general idea of how image processing works in relation to sine waves, Fourier analysis,
and separating an image into its components with those coefficients, because these general concepts
extend to wavelet analysis and that compression algorithm, even though there are, of course,
differences. Sending those coefficients does lead to a smaller file size compared to other
compression methods, with very minimal loss of information, by the way. And when someone on
the receiving end wants the fingerprint to be displayed, a computer just uses those coefficients
to reconstruct the image. Again, any deeper analysis is really beyond a video like this,
but if you like these real-world stories centered around mathematics, you can continue your learning
over at CuriosityStream, the sponsor of this video. One documentary I really enjoyed is Codebreaker,
as this explores some of the mathematics used to break German encryption during World War II.
Most of you probably have heard of Alan Turing, but there were many more people involved in this,
and this film takes you through the story of how someone named Bill Tutt pulled off what some
describe as one of the greatest intellectual feats of World War II. CuriosityStream is a streaming
service that hosts thousands of other documentaries and non-fiction titles, spanning a range of topics,
from math to physics to history, technology, and more. The service is available on a variety of
platforms worldwide, including Roku, Android, Xbox One, Amazon Fire, Apple TV, and more,
and it only comes out to $2.99 per month. Plus, if you go to curiositystream.com slash Zach Star,
or click the link below and use the promo code Zach Star, you'll get your first month's membership
completely free, so no risk in just giving it a try. This gives you unlimited access to top
documentaries and non-fiction series that I know many of you will find very interesting,
so again, links are below, and with that, I'm going to end that video there.
Thanks as always to my supporters on Patreon, social media links are down below,
and I'll see you guys in the next video.
