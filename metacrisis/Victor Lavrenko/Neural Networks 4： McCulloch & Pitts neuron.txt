the neat thing is you can come up with a fairly simple mathematical model for what that thing
does. So the dendrites and the cell body, what it's basically doing is it's you have some input
around it. So think of the amount of chemicals around the three dendrites as being x1, x2,
and x3. Those amounts are fed in into some mechanism that somehow adds them all up, right?
It looks how much chemicals I have around me. So you have a basic summation. So it comes up
with some number, right? And then there's this firing behavior. So one way to model the firing
behavior is with a squashing function, right? So what a squashing function says is if I don't,
so on the x-axis I have sort of the amount of chemicals that were added up by this accumulator
unit. So if I don't have enough, then I don't fire. Now once the amount of chemicals, the sum,
reaches a certain critical value, I'm going to fire and for a while the strength of my firing
is actually going to be proportional to the amount of stimulation that I received. So neurons,
they're kind of like binary. They either fire or don't fire, but when they fire they can fire
with different amounts of sort of intensity. So now, but then there's a natural cap on how well,
how strongly they can fire. So basically what that means is up until a certain value of the sum,
I don't fire, and then I reach my threshold and I fire. So that's what your sigmoid function or
a squashing function could look like. And of course, remember the sigmoid function,
the squashing function, we can model it with a sigmoid. So it's just 1 over 1 plus e to the
minus z, where z would be the value of that sum. And that generates the value y. So that value y,
think of it as sort of the electric potential, the magnitude of the electrical signal that gets
sent down the exon and gets picked up by the next neuron in the chain. So overall, that y is just
the squashing function sigmoid of some weighted combination of inputs. Now where are those
weights coming from? Those weights are coming from the fact that these connections, the dendrite
connections, they could actually have different strengths. They're not all the same. So some
of them, when one neuron fires, it could influence some neuron more than some other neuron. They're
not equal. So I'm taking inputs, I'm multiplying them by the strength of connections. I'm adding
them all up, adding a bias germ. The bias germ is just my threshold. It's how much it takes for me
to fire. And then the squashing function determines the firing behavior. And then the result of that
goes into other neurons that do exactly the same thing as this neuron that I just said. Okay,
great. So that is a little chunk of an artificial neural network. And the reason it's called a
neural network is because we think it's a pretty good approximation of what's going on with actual
neurons. And the reason it's called artificial is because it's really not a very good approximation.
It's very, very crude.
