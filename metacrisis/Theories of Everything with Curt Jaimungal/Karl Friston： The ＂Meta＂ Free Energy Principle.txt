This is the longest interview I've ever done because they are such intriguing questions.
But yeah, the fact that I'm still here is desperate to the fact that I had a great time.
I don't want to talk to our next next exchange.
Carl Friston is considered by his peers to be the top neuroscientist that exists, probably
that ever existed. Now, obviously, he won't say that he'll rebuff that because he's a
humble British chap who doesn't like to draw undue attention to himself, but I give him
that accolade. He has a principle called the free energy principle, which is infamously inscrutable,
but we try to make it as simple as possible. Please keep in mind that while there is plenty of
technical jargon in this podcast, it's important that you stay with it. Once you're at the end,
you'll probably have a better understanding as to how to interpret what he said at the beginning.
This is one of the longest conversations, if not the longest conversation with Carl
Friston that exists, and not that size matters, but you can use the duration or the length of a
podcast as a proxy for the interviewee's interest. And that's great for me as an interviewer,
because hopefully the rapport comes across and influences whether or not you can absorb the
information or influences the rate at which you can absorb it and possibly even the comfortableness
that me and Carl have with one another aids your understanding, perhaps the integration of this
information so that you can assemble your own Veltan Shawoom, that is your own theory of everything.
These podcasts are extremely difficult to produce because they require quite a bit of
preparation. And if you're interested in supporting conversations like this or seeing more like this
or you have other ideas as to who I should interview and you'd like to support this channel in some
way, shape, or form, then please do consider going to patreon.com slash Kurt Gimungal. Literally
every dollar, every donation, every patron helps a tremendous amount, not only financially, but it
also helps with encouragement. It helps show me that this is something that people are people
like and are willing to support voluntarily. Thank you to all the existing patrons. And just so you
know, the best way to view this podcast in spite, like I said, it's inscrutable nature as to what
exactly the free energy principle is. The best way to view this podcast or listen to it is by
re listening to it. By the end of it, you'll have a better understanding as to what Carl
Friston means when he says certain terminology. And then when you rewatch or revisit certain
parts, you can look at the timestamps, revisit and hopefully gain a better understanding for those
listening and not watching. There is also a YouTube channel. And for those who are watching
and not listening, there is a iTunes, Spotify, Google Play, we're on pretty much every platform.
You can look at the description to get the links for that. Thank you so much and enjoy.
Very bubbly. I should say that I'm certainly not the greatest neuroscientist. I think that's more
a reflection of the fact they invented the H index a few years ago. So it gives me an unfair
advantage. The balance is very poor. So most of my life, I spend pursuing academic commitments.
In fact, in the past year, also commitments I've taken on in relation to the coronavirus
outbreak in terms of modelling. So on the other hand, I love what I do. So for me, life is a bit
of a holiday anyway. I think many people suffer from my family in terms of my improper work-life
balance. Does your family get upset that you're constantly thinking about work? Or are you distracted
when you're spending time with them? Because something else is on your mind? I think they've
got used to it. And I have to say that they also have their preoccupations and the things that
they invest in. So I think they are as guilty as I am in not paying proper attention to
the life side of the work-life balance. Do you have a daily ritual or do you meditate?
Do you eat a certain type of meal? Go to sleep at a specific time? Wake up at a specific time?
What's the structure? I am certainly a creature of habit. I guess we'll come back to why that is
possibly the case. I should be the case for most creatures. I don't meditate, but it's an interesting
question because my daily routine does involve a long period of thinking in the morning. And it's
alone. So I generally joke, and perhaps not joke, that I don't like talking to other human beings
before lunch, before 12 o'clock. So my day typically will start with at least an hour,
if not two hours, sitting and contemplating on the problem at hand, usually in my conservatory,
smoking my pipe, just drilling down without any aids, without a computer or without any
pen and pencil, just to boil down the simplicity of the problem at hand and try and see the
architecture of the solution. And then it's a question of buckling down to emails or then
doing coding or mathematical derivations or writing something up for the rest of the day,
and when I start talking to other people. You sit without a pen and a paper and you just think
with your eyes closed? Well, I actually enjoy looking at the garden whilst thinking, but I do
get distracted, yeah. And if you see me close my eyes, I'm often thinking deeply about what you're
saying. I don't want you to think I'm distracted or sleepy, just so you know. This just sounds
extremely British of you to have a pipe. And do you drink tea? Are you sitting with biscuits?
Do you have a breakfast? Well, no. In the morning, it's coffee and then tea would be for the afternoon
without biscuits, but certainly coffee in the morning, tea in the afternoon.
How do you choose which problems to tackle? Because I assume that maybe 80% of the reason
for your high H index is the problem selection. Yeah, absolutely. And I often have heard it said
that the mark of a great scientist is not the answers that they offer. It's really the questions
that they ask. And I have to say that most of the questions that I'm obliged to contend with
are those that are proffered either by colleagues internationally and most of the time by the
younger people that I work with or supervise. So it's really, I spend most of my time in response
mode just trying to formulate and resolve questions that my international usually younger team bring
to the table. So 90% of my work is just basically helping other people solve problems.
About 10% of it when I have time is sort of focusing on, you know, on my particular hobby,
which in latter years has become, you know, the free energy principle. But that's
somewhat rare opportunity. Most of the time, you're working on other slightly more practical
problems. How has learning mathematics, new mathematics, new physics, whatever it may be,
how has that changed in your later years compared to your younger years?
Well, practically, and on this answer to that question, it's much easier now
because of things like Wikipedia and the electronic age. I mean, certainly I
had the conviction, which I think is a proper conviction that to make any real formal difference,
you had to be able to articulate things mathematically. So, you know, made a particular point of
choosing an early career and education that covered physics and maths and probability theory and the
like, but probably not dissimilar to your early career structure. And then forgot it all until I
until I returned after a studying as a doctor with a psychiatrist to maths via data analysis
in imaging neuroscience. So, it was extremely useful having had that early physics sort of
degree level education. Although I'd forgotten everything, at least I had the confidence to
relearn those bits that you need to know to make something work. So it was very much one of the
situations of sort of see one do one teach one where very quickly you need to solve a problem.
And then you went to, you know, in latter days, at least you went to Wikipedia,
you got the right equations and you put them together, implemented it in code, and then
proceed, you know, to onto the next problem. So, you know, I have possibly an undue respect
or reverence for the utility of maths, not, you know, not just in relation to its unreasonable
efficacy, but also as a language for communication as a calculus that every like-minded academic
or indeed industrial partner will at some point subscribe to it and drill down on and understand.
So I think it is the ultimate language, which, you know, effectively are most of what I say
in words or write textually inherits from and is always guided by the underlying the underlying
mathematics. Before we get to the free energy principle, which I'm going to ask you to explain
as simply as you can, and then you can go as complex as you can later. But before we get to
that, I found that there were a few words that you use in the different interviews that I've seen
of you that I'm unsure as to what you mean precisely when you say them. So deflationary is one.
What do you mean when you say deflationary? I'm sure that will come up over and over here.
Right. Yes. You're right. That's one of my favourite words at the moment.
Just taking, if you want an honest answer, I use it in the sense of just taking the hot air out of
something. So I, in some instances, one sees what an overinterpretation of certain things.
So there is always a simpler explanation for various phenomena or behaviours or constructs.
So for me, a deflationary explanation is a better thing in the sense that it provides
a simpler, more parsimonious account of something than was on offer before that
simpler account came along. So philosophically, I think I'm using it in the sense of what my
friend Andy Clark, who's one of the world's more accomplished philosophers, refers to as a sort
quinion desert landscape. So this inherits from Quine, who conceived of a set of explanations
that was so simple, there was nothing left, hence the desert landscape. And a lot of the
aspirations of our theorising actually points in that direction. A little bit like natural
selection. I mean, natural selection is such a wonderful idea, probably the greatest biological
idea, certainly in the past few centuries. And yet it is inherently tautological.
It just almost goes away when you think about the essential tautology of natural selection.
So for me, it's a beautiful idea that is deflationary. It explains so much with hardly anything.
When you mean, when you're saying that natural selection is tautological,
do you mean to say that survival of the fittest, well, you're defining fitness by survival anyway?
That's exactly what I mean. Yep, that's exactly what I mean. Yep.
Okay. Okay, now self evidencing.
Self evidencing is a philosophical term, which I think has been around for some time,
but I was introduced to it by my other philosophy friend, Jacob Hoey, who's currently in Melbourne,
as a nice perspective on the one take on what we do or what the imperatives,
existential imperatives behind our behavior and dynamics, if you're a physicist,
which is to maximize the evidence for your models of the world. So in maximizing the evidence,
sometimes described perhaps poetically as acting to garner evidence for your own existence,
you can be said to be self evidencing. I just say it's a slight play on words from the point of view
of a mathematician because nearly every interesting formulation of self organizing systems has
self in. So you start off with self organizing systems of the sort you might see as a computational
chemistry through self assembly. Sometimes in the biological sciences, people refer to
auto poesis, which is again Greek for self creation. You start off just thinking about
the information theory that would underwrite that kind of self organization. The first thing
you come across is self information. Following that through, you can sort of spin off all sorts of
other selves in terms of self serving behaviors that you can write down in terms of information
theory. And for me, the simplest and most the prettiest is this notion of self evidencing.
What about equilibrium state versus a non equilibrium study state? So that one's not
idiosyncratic to you. Right, no, no, it happens now. And again, remember, I'm a bit of an amateur
physicist. I trained as a physicist as a young man, but haven't really been in that field
throughout my career. But my reading of physics as it applies to the kinds of systems that we
have to deal with can be read as sort of 20th century physics where you're dealing with
closed systems at equilibrium. And then the 21st century, people got much more interested in
the physics of open systems that are far from equilibrium or non equilibrium.
What can you do with these kinds of systems? Well, you can write down their dynamics,
their density dynamics, you can formalize the behavior of the probability distribution over
the various states of these systems and how they would unfold from any given initial condition
to some steady state distribution. For me, though, it is the steady state distribution,
which is interesting because that provides you with a well defined probability distribution.
And once you've got that, then you can go forward in terms of the information theory
and spin off everything that you might want to in terms of inference and the like.
So the non equilibrium path is absolutely crucial in the sense that it defines a set of questions
about systems that are in exchange with a world out there. So there is, you know, from the
thermodynamic point of view, an exchange of energy and entropy between the system in and of itself
and the rest of the universe. From a mathematical point of view, the non equilibrium aspect is
inherited from the prevalence of circular flows, solenoidal flows, the sort of flow which if you
were in machine learning would destroy detailed balance and that would have a lot of tentacle
implications. But what I'm talking about is sort of the fluctuations that you get
in classical mechanics like the orbits of heavenly bodies or the circular fluctuations
you get in predator-prey relationships or red queen dynamics. Wherever you look at sort of
interesting systems that persevere over time, you see this sort of solenoidal circular
oscillatory like behavior and it is that which characterizes real dynamical systems
that are, you know, I repeat, not isolated from the rest of the universe or are not carefully
enshrouded in a heat bath like an idealised gas, but they actually have to contend with
an exchange with the outside world. So that's what's encapsulated by a non equilibrium system.
The steady state means that if you leave it alone for long enough, it will self-organise
into some recognisable configuration that you can describe probabilistically with the
probability density function or in terms of some attracting set or pullback attractor,
whatever your preferred kind of calculus or mass would be. So steady state refers to it over time
being somewhat stable but then the non equilibrium means that it can ramify,
can go between here and then it may jump here and then it may jump here, but between three only
instead of one would be equilibrium. No, I think that's a very nice description. So yes, absolutely.
So the steady state just means that the system has settled down to some attracting set of states
but within that set of states there is exactly what you were referring to. There's an itinerancy,
there are different sort of regimes or sub manifolds of an attracting set which gives it
an itinerancy or a wandering. So it moves around from one part of the attracting set to another
part of the attracting set. So the example I like to use when trying to get this notion in play
is at every level of self-organisation in me, you see this phenomena whether it's very, very
fast fluctuations in electrophysiological potentials in one part of my dendrite of one cell in one
part of my brain, you know, fluctuating at say the gamma frequency or whether it's my heartbeat,
you know, unfolding during the cardiac cycle or whether it's me getting up in the morning,
having a cup of coffee, do my emails or whether it's the annual cycles that we all enjoy sort of
Christmas, Easter, summer holidays. Every one of these instances of an, you know, an open system
at some kind of non-equilibrium steady state has in common the fact you keep revisiting
certain states of being and it's that revisiting that defines this attracting set and the, you know,
the steady state aspect. So exactly as you were doing with your fingers, you are, you are moving
around from sort of one part of the manifold to another part of the manifold, you know, if you're
a physicist who did dynamical systems theory, you might think of this in like a
heteroclinic cycle where you're moving from one unstable point to the next unstable point,
but you're always ultimately coming back to the same attracting set of unstable points. So it's
that, you know, non-equilibrium, so we're not at a fixed point, we're not all aspiring, you know,
to be at thermodynamic equilibrium. There's an itinerancy and a complexity and a richness to
the behavior. But on the other hand, it's a behavior that evinces the same kinds of states,
the neighborhood of places in states based time and time and time again for the duration of the
existence of that particular system or particle or person in question.
Why did you call it the free energy principle? When I first heard, well, I heard about it quite a
few times, then I kept dismissing it because I thought it was referring to perpetual motion
or the extraction of energy from vacuum fluctuations.
Right, I understand that it has something to do with free energy in the physics term, but
what led you to calling it the free energy principle? And have you heard of other people?
Have you heard of the case of mistaken identity from other people? Is it just me?
No, no, I've certainly come across that, but not so nicely articulated or gently articulated.
So, yeah, for me in my world, the free energy was the most natural and obvious thing to call it,
because the kind of free energy that we're dealing with, or when I say we, people in either
base in statistics or latterly what we know now as machine learning, would always refer to this
quantity, this variational free energy as a computable objective function for any
inference or estimation problem. So whether you're doing sort of classification of machine
learning and you're using restrictive ultimate machine and you're using, let's make it more
current. So you're using high end deep learning, using a variational auto encoder to try and recognize
some sequence of images. Then the weights that you are optimizing in that deep learning setting,
in that particular variational auto encoder setting, are optimized with respect to a variational free
energy. So this variational free energy plays a central role and has done for more than half a
century now in optimization problems. Its origins actually really quite interesting. Historically,
again, this is not really my field, but from what I gather, there are two ways that the free energy
sort of came into play, the American route, and this starts with Richard Feynman, as with most
things. So he had the problem of basically wanting to, you know, express it simply, evaluate the
probability distribution over all the paths an electron say could take. And he realized that
was an intractable integration problem. He couldn't work out the sort of the normalization constant
to make sure that probability distribution summed to one. So he was faced with an intractable,
effectively, integration problem in quantum electrodynamics. So he solved it by converting
that integration problem into an optimization problem. And the way he did it was to introduce
a variational free energy that was always greater than the quantity that he wanted to minimize,
or was less than the quantity that he wanted to maximize, which in this instance is just
the marginal likelihood or the likelihood distribution of various paths, say a small
particle might take. So that's where I learned about free energy, essentially a Feynman-esque
free energy that was provided a bound approximation to something that you actually wanted to maximize
or optimize. And in my world, that thing you want to maximize is the model evidence or the
marginal likelihood, because back to self-evidencing, but also the marginal likelihood, sort of
indicating that this is a central notion in physics, in Bayesian statistics as well.
And that quantity, that variational free energy has been in play now for not quite a century,
but certainly many, many decades, currently known as an ELBO, ELBO, an evidence lower bound.
So that evidence lower bound underwrites all of high-end machine learning.
Certain simply reduced cases of it, I would actually suggest probably all of machine learning
at some point, refer to or can be seen as a special case of this. The other route
inherits more from the Russian side. And this is notions of algorithmic complexity,
underlying universal computation via Kolmogorov complexity and sort of induction. So the big
drive there is, again, formulating universal computation as basically communicating or
articulating or encoding some structure in the simplest way possible by introducing
a bound on the thing that you want to optimize or minimize or maximize.
So you can also find the free energy in the context of sort of a more Shannon-esque take
on communication and optimization. And David McCabe sort of originally brought that perspective
to the TABAR perspective that was well understood by people like Wallace in Melbourne,
who themselves had taken it from the Russian literature. I think he was an American but also
taking this algorithmic complexity. So it's a very long answer to actually say that the free energy
principle or the principle of minimizing free energy has underwritten universal computation,
practical approaches to quantum electrodynamics and machine learning since the 1950s.
So that's what the free energy means. It's not that the energy is costless. It's just
borrows from the formalism of the thermodynamic free energy, the Gibbs or Helmholtz free energy.
Okay, this sounds like a great time to explain what the free energy principle is. I know you
touched on it but for the people who aren't aware. Right, so we're asked to do this. I'll give you a
choice. You can either take the high road or the low road. So the high road would start with
a consideration of what it is to exist to be something and then unpack that in terms of
physics and then ultimately you get to a picture of things that exist as things that look as if
they are trying to minimize their free energy and you can interpret that in terms of action and
perception, sentient behavior, effectively a physics of sentience where everything entailed
by a particle that could be a sort of small particle or it could be a person or a plant,
anything that exists can be seen as or understood or characterized as trying to optimize or minimize
a free energy through changes in internal states or through action upon the world. That would be
the high road and we can take that if you choose that option. The low road would be sort of building
up a sense of there being just one imperative from the notions that probably can be found
in the students at Plato, throughout philosophy, through Kant, through Helmholtz, through modern
day psychology and subsequently machine learning would appeal to a story, a narrative about prediction
and inference and that we are all effectively prediction machines where in this setting the
existential imperative is basically to reduce prediction error. So by prediction error I simply
mean that we have in mind a model of the way that the world works and that we can leverage that model
to produce predictions about the sensory evidence at hand and the disparity or the difference between
our predictions and our actual sensory samples can be called prediction error and it turns out
mathematically that the sort of the high road and the low road converge because the prediction error
is just the gradient of the free energy that you're trying to try to minimize. So I'll come back
to you which would you prefer the high road or the low road? Okay first when you say sentient
do you mean the capacity to feel pleasure or pain or how are you using that word?
Yeah just a sense just to not so much the affect aspect not the sort of the pleasure and the pain
just being able to represent and infer so to have in mind a notion of what caused your sensations
so you know I'm using it in a deflationary way. So some systems may or may not have the kind of
sentience that you'd associate with say a person or a pet say you know there's a plant
there's a plant sentient let me ask you do you think a plant is sentient does it does it have
can it in an elemental way feel its way around the world or have some internal representation
of the world that it inhabits? I would say it's a scary thought to think of plants as extremely
sentient because you crush them constantly and even if you're a vegetarian so I'm unsure if I
think that they can feel pleasure or pain it does seem like it's clear that they respond to the
environment and that they take in sensory information and act on it. Yes I think that's
absolutely true and in fact interestingly they have the same sort of electrochemical
message passing that we have with our axons you know in the brain it unfolds at a much slower
time scale but the you know the physics of the message passing the internal states of a plant
to actually comply with very similar kinds of computational architectures that your brain
and mind desire I would say a plant is sentient but not to the extent that it has emotions or even
a sense of self you know there are lots of graded very you know sort of ladder there are lots of
steps on the ladder of sentience right through to self awareness and pleasure and pain but I'm
talking about a very elemental sort where there's something going on in the inside that is caused
by and causes stuff that's going on on the outside that you can read as a kind of representation
or an inference about the causes of sensations. Okay so when you ask this question as to which
explanation would I prefer the high road or the low road I imagine that as top down versus bottom
up and when I say that please let me know if I'm understanding it correctly when you say the bottom
up it's something like looking at what exists and seeing that it does act such that it minimizes
some quantity or it wants to minimize error in some way versus the top down which looks like
if I was to sit in an armchair with my eyes closed and think what exists okay what would
have to be the case if it were to exist what properties would it have to have so one is
is that correct am I in my obtuse no that's brilliant yeah okay
let's start with the top down let's just do the top down because I we have quite a few questions
so let's start from the armchair excuse me so okay I'll do the top down with a little nod to the
bottom up so we don't we don't miss out on anything so that you've just said what you know basically
the strategy you start off okay I want to explain anything a theory of everything yeah so what's a
thing well the first thing you have to contend with well how do I differentiate a thing from
no thing or nothing or something else so that immediately implies that you're splitting or
carving or partitioning the states of some universe into states that belong to the thing
and states that don't belong to the thing and when you think about what that means you have to
well you're compelled then to consider the statistical dependencies that demarcate
something from nothing and when one drills down on that you come across this notion of a
mark of boundary or mark of blanket which is effectively a set of states that separate or
insulate internal states on the inside from external states on the outside so you have this
picture of transactions mediated by standard dynamics by of the sort you'd see in physics with
a launch van formulation the kinds of equations of motions that everybody uses to you know to
build their favorite physics whether it's sort of quantum mechanics or classical mechanics
or thermo and statistical mechanics they all start with with the notion of there being some
dynamics out there and the special kind of dynamics that you the we're interested in in terms of
talking about anything is applies to systems that have this partition so as soon as you put this
partition into play which is basically a partition where internal states influence external states
this direction through the blanket states and then external states influence internal states
in the other direction and becareously through the mark of blanket you have this notion of a
sort of generalized action and perception that you know the inside influences the outside so
somehow the thing is acting up on the world but at the same time through the blanket states
the outside is acting upon the inside you know and we normally divide the blanket states into
sensory and active states so in this instance the outside external states impress themselves upon
the sensory states and then the sensory states influence the internal states and so there's a
sort of circular causality implied by this partition now all you do then is say well look
let's just look at the long-term behavior of any system that would that you can describe in terms
of the the dynamics or the rate of change of the probability distribution over states or density
of estates and note that because we are interested in systems that have attained a non-equilibrium
steady state the probability density density is not itself changing and when one does that
when one looks at the solution to the density dynamics in the context of the mark of blanket
you get a particular kind of mechanics and that mechanics is exactly the same as quantum mechanics
or statistical mechanics but with one key difference now it applies in the setting of a markoff blanket
I think that that's where the interpretation of things as the self-evidence in comes from because
you can always write down the flows that maintain this steady state as effectively trying to trying
to minimize their prediction error or minimize their self-information or minimize their what's
known as surprising information theory which mathematically is just the same thing as
what statisticians like to call Bayesian model evidence or the log of the probability of these
sensory states given my implicit model encoded by the internal states so what you end up with
is a description of anything defined stipulatively in terms of it possessing a markoff blanket
defined by its non-equilibrium steady state density whose dynamics or flows must have this
property that the internal states and the active part of the blanket states must be performing
a gradient flow on this self-information and then you make a further move and say well this
self-information can be written down as a free energy functional well the free energy if I
interpret the internal states as encoding belief Bayesian beliefs or probabilistic beliefs about
the external states so now you have a mathematical image or a picture of existential dynamics
that inherit from having a markoff blanket where you can say that the dynamics of the internal
states look as if they're trying to maximize their model evidence or trying to minimize
their free energy or prediction error and that's basically the story so a story that rests really
upon what physicists will understand as dynamics and average flow at non-equilibrium steady state
and in particular the gradient flows so perhaps it would demystify this to say that
I'm coming back to Helmholtz who was a key architect of these ideas on the low road to
describing so among the many things that Helmholtz brought to the table was you can always decompose
the flow for example let's take the flow of a fluid into two parts there's one that's flowing
up or down gradient say concentration gradients and then there's another circular flow
which flows around the iso probability contours or the iso gradient the iso contours of any
of any function so what we're talking about is the gradient flow part of it not the serenoidal
which is the other circular part of the flow that we were previously talking about in terms of
defining non-equilibrium as opposed to equilibrium systems and you know that gradient flow then
can be now read as a gradient flow on a variational free energy which is wonderful
from the point of view of people like me in neuroscience because now what you've got
is a description of neuronal dynamics so you've got now a first principal account of how neuronal
activity or states change as a function of their state over time and you can write that down now
as a gradient flow on this one quantity this variational free energy that endows that gradient
flow those that dynamics with an interpretation that they're trying to maximize the evidence for
their model internally of what's going on on the outside okay let's zoom out and we see
in your model most of the time when you're presenting with the powerpoint slides I see
nodes and then they have arrows and so the nodes are connected with different arrows
and then that's what affords a Markov blanket I have a couple questions the arrows represent
influence which to me is a synonym for causation so I'm wondering is causation necessary for
this model because some people argue that causation is an illusion so for example Sean Carroll may
say that and well first of all let's tackle that does your model presuppose causation
um yeah in a deflationary sense yes so deflationary yes so in in the sense
I'm not quite sure what Sean has said but I will I want to agree with it with what whatever you said
so this is a very trivial causation that that is implicit when you write down any random differential
equation or stochastic differential equation or launch van expression if you just write down
a universe in which there are states that change with time as a function of those states plus say
some random fluctuations to make it a random or a stochastic differential equation then what you
are saying is that the flow of those states the rate of change of those states is caused by those
states that's the only causality that is in play here so it's it's causality of a rather sort of
elemental and trivial sort that that I have to refer to oh sorry not me but people often refer to
as causality in a control theoretic sense that the system is causal in the sense that there is just
motion or dynamics that is caused by by a state so the causality here is inherits just from writing
down differential equations they're interestingly are only expressed in motion over time so there's
a deep link behind this trivial causality and time because you're just writing down a differential
equation after that there's no causality there's nothing else after that the the sort of the causal
inference that that that sort of that would be of the kind say that that people like Pearl
in his causal mechanics talk about I think that's much more a product of inference but you'd have
to actually work right up through the free energy principle you know to actually understand what it
means just to measure things you know let alone have ideas about did this a cause be you know
you first of all got to even you know work out how would you measure how would you infer the
existence of a out there and be out there so you know the free energy principle that starts
at a very very low level and then the baby steps works up to higher order notions of things like
causality does that answer your question about the other yeah does time always have to be the
parameter or can it be something else because then it presupposes time as well yeah yeah I mean in my
in in our work yeah it is always time but of course you can generalize that you know just
treat time as another another another coordinate if you wanted to I personally haven't found that
a very useful move I have all have an enormous respect for people who can think like that
you know and completely generalize this you know and get all you know
gate theoretic sort of understandings of the underlying geometry for me I have to say
you know I just start with a random differential equation and then everything else follows from
that and in particular you know you keep connected to
useful things of the sort that do rest upon dynamics you know if you if you so don't keep
if you don't treat time as a special if you like coordinate or aspect of some of some space
then you know it's less easy in a straightforward way to connect to things like entropy production or
even things like sort of information entropy and information length in dynamical systems
so I personally do you know time starts off with a privileged position in the formulation
in the sense that it underwrites the meaning of a differential equation
do you see that as then meaning that the free energy principle as it's currently formulated
is incomplete in some manner given special relativity let's say that or any relativity
says that time and space must be on some equal footing and if you're saying that time has some
privileged position then well position needs to have a equally privileged position
right yeah yeah that that question is above my pay grade I personally don't know you can easily
get dynamics or mechanics out of a long van formulation that has time baked into the very
core of it you know at the beginning but just right down the long run you can work the whole
way thing out the whole density to dynamics up and at non-equilibrium steady state you can write
down quite you know a simple potential function that describes general relativity so I don't think
was it I didn't know that okay because when I was looking at some of your notes I know you call it
the launch van equation I can never pronounce that so I always call it the Kolmogorov forward
equation for some reason that's easier for me but whatever the launch van is that correct launch van
yeah that's how I say it anyway yes okay let's just say it like that for now
right okay so the launch van equation it can it can imply Newtonian mechanics I saw that
you were showing that in one of your slides as well as quantum mechanics as well as some
aspect of thermodynamics and then I forget the fourth one but then I didn't see special
relativity or non-relativistic quantum mechanics you're saying that you can tweak some of the
parameters to derive general relativity yep and it all rests upon the way that you configure the
the the the gradient flows that have a dissipative the lender system a dissipative aspect
versus the solenoidal flows that characterize more conservative systems so when we're talking
about special sorry general relativity for example excuse me we're almost
considering the limiting case where the random fluctuations are attenuated by being averaged
away that we're talking about sort of massive bodies moving around so it's just a question of
looking at the various functional forms you would get out of the solution to the Kolmogorov forward
equation under the limit that gamma is is is very that sorry the amplitude the random
fluctuations is very very small so the gradient flows almost disappear
so then it's just a question look at the functional forms and with a few nonlinearities
here and there you can you can quite you can quite you can quite easily write down something that
general relativity will be quite comfortable with there are some interesting twists here but
you know if you start putting back the random fluctuations into the so general solution
to the the Fokker-Planck equation or the Kolmogorov forward equation and sorry just
for the people listening the Fokker-Planck equation and then the launch van equation
and the Kolmogorov forward equation are all synonyms yes well or the special cases of one
another yeah well the launch van equation is is just the the underlying equation that describes
the the flow of the system as a function of the states but if you if you know that and you know
the amplitude of any random fluctuations on that flow then you can do you can equivalently write
that down as a Fokker-Planck equation or a Kolmogorov forward equation I should also say
incidentally you can also write it down equivalently in terms of a path integral formulation
you know all of these could be thought of as different ways of just articulating the same thing
so but the density dynamics most transparently inherits from the you know from the the Fokker-Planck
or the Kolmogorov formulation which is explicitly about how the probabilities over the states
evolve over time so one example of that would be this time independent stroding away equation
you know which is you know one version of a of a Fokker-Planck equation what they have in common
is describing the dynamics of of systems in terms of the probability density over the states
or if you need quantum mechanics over the other sort of the say the wave function of states
so at steady state in fact you need to go to steady state but certainly once you've written down
the the Fokker-Planck equation and solved it for the flow and then used the Helmholtz decomposition
to split the contributions to flow into the solenoidal and gradient flow parts
then that provides a sort of a nice way of looking at limiting cases so the gradient flow
is realized by the random fluctuations so you know for people who are not physicists
I often use the following analogy that you know imagine that I placed a drop of ink in the cup
of water and the ink for dissipative systems or you know a dissipative ink would disperse itself
throughout the solvent as a random molecular fluctuations caused the ink molecules to diffuse
down concentration gradients until you had you know a maximum entropy dissipated and dissolved
sort of equilibrium within the sort of the heat bath or the boundary supplied by the glass
that's not the kind of system that we're interested in that's the 20th century
sort of equilibrium physics what we're interested in is special kinds of ink
that seem to gather themselves up again into a little globule and that gathering up
in the context of sir you stirring the stirring the glass of water
can always be written down in accord with the Helmholtz decomposition into two kinds of flow
one kind of flow is up concentration gradients so it's this is the gradient flow I was talking
about that so the molecules are gathering themselves together paradoxically if you like
looking as if they're flowing towards each other or to the highest concentration the highest
probabilities or longer probabilities and it's that gradient flow that is responsible for
this self assembly this sort of the emergence of this attracting set of a small number of
states and I keep I keep visiting and then the solenoidal flow is this sort of circular flow
around around the ice the constant you know in this instance the concentration
profile the isoconcentration lines whereas the gradient flow is going to the
you know the maximum concentration or the maximum probability density so that's non-equilibrium
steady state crucially that gradient flow is exactly balancing the dispersion due to the random
fluctuations so put that another way the gradient flow that keeps things glued together as it were
that keeps things pointing towards that attracting set that pullback attractor that states that have
a high non-equilibrium state density is exactly offsetting the dispersive dissipative effects
of the random fluctuations which means that the random fluctuations realize the gradient flow
so you have to have random fluctuations before you can have at non-equilibrium steady state
the gradient flow so what would happen if you took them away well what would happen is there
would be no gradient flows and things would just have solenoidal orbits and then we have
basically Lagrangian mechanics we have you know a mechanics app for describing large bodies
heavenly bodies moons and earths and the like all they can do is move around in circles so
they've just got solenoidal flow that's because there aren't all the random fluctuations are
averaged away so they're effectively zero so they can't realize the gradient flows so they don't
fall towards each other you know with you know with the suitable potential energy
that would define the you know the gradient flows or the form of that non-equilibrium density
on the other hand you could say well no I'm in monitoring systems that are hot and fast
really fast like so quantum fast and where the solenoidal bit can be ignored I'm just going to
focus in on the on the random fluctuations on the the impact of those on the density dynamics
and then you can ignore the solenoidal flow we return to systems our detailed balance and we can
you know write down certain you know all all our favorite thermodynamic laws you know and
derive all the integral fluctuation theorems that underwrite generalizations of the of the
of those laws so you know from that perspective classical mechanics where general relativity
might live for example lives at one end of the spectrum very large cold no random fluctuations
and then quantum mechanics lives at the other end where it's dominated by random fluctuations
very fast gradient flows and the middle is where we live where we've got both the so we're neither
committed to disorbiting for eternally some you know orbiting some you know some center
committed to you know a periodic orbit for the rest of our lives nor do we dissipate or behave
you know in a sort of you know in a quantum way but we're sort of halfway between where that that
right sort of scale where there's lots of solenoidal there's lots of oscillations that you know
that we we are exposed to impose from a larger scale such as tides that we generate ourselves
such as oscillations in our hearts and our physiology in our brains but at the same time
we do have to contend with the random fluctuations so you know we spend all of our time doing our
gradient flows gathering ourselves up planning homeostasis keeping ourselves in you know actively
keeping ourselves within certain bounds within within that within that attracting set and this
moving up the gradient flow is this analogous to what schrodinger talked about when he said that life
resists entropy in some way yeah I think that's absolutely right you're asking us if you didn't
know that's exactly right so you know in the presence of these
for at equilibrium you know certainly enclosed systems that don't have
sort of low-energy people back attractors then you will get the second law you know in the
usual way where all the random fluctuations eventually dissipate you hence you get dissipated
systems and dissipated dynamics and yet somehow we we in our existence we are in existence proof
that that's a violation of that kind of behavior and that's basically where the free energy principle
starts it just says there are things out there that have to be explained that seem to resist the
second law so um schrodinger framed it in terms of negative neg entropy uh that's right right
uh you know to frame it in terms of um of resisting those that entropic dissipation
by this gathering up behavior and is those gradient flows that are responsible when
you just write down the the dynamics in terms of the Helmholtz decomposition
for providing that balance between the dissipative effects of random fluctuations
and the self-organizing dynamics that exactly balance those those dissipative effects to give
you this this non-equilibrium steady state professor when I was first researching the
free energy principle I kept coming up to cautions about how
intellectually formidable it is and if one was to just go by the just the warning signs
one would think that it was more abstruse than particle physics or general relativity
and I'm curious why do you think it has this reputation here's an example when you search
general relativity or particle physics or quantum field theory stand or the standard model
or any gran unified theory I don't think I've ever read a single sentence except on quantum mechanics
that says this is a difficult theory to understand however on the wikipedia page for the free energy
principle it says this is notoriously difficult to understand yeah um so I'm just trying to think
of other examples that um I'm not saying that it's easy to understand in the least what I'm
wondering is why do you think it has this reputation oh I see yes um I think it's largely
because somebody's slipped in that wikipedia that centers in wikipedia to be quite so it becomes
a self-fulfilling prophecy absolutely it's entertaining um it's yeah and of course it it's
and I know it's not as hard as quantum physics and and thermodynamics because I used to do those
and I can tell you the free energy principle the maths is much simpler than than quantum physics
or general relativity um it is much simpler but it is mathematical but if you're you're in dialogue
with psychologists who don't do mathematics then there can be this sort of inflationary
reification of the ideas and then there's a mystery because you you don't see the simplicity
that is inherent in the in the mathematical formalism the functional forms that you're dealing with
but I I quite like that I think it's quite funny really keep that in the wikipedia page
okay so the free energy principle do you see it as being a potential theory of everything
first of all you have to decide what are the desiderata of a theory of everything but the way
that I one of the reasons I'm interested was from seeing that slide about the launch van
equation or the column or whatever that equation and seeing that it when you tweak the parameters
you can either generate Newtonian mechanics or general relativity at least you're saying that
now I haven't seen that and then quantum mechanics and so on so then that to me means it's a more
fundamental principle than those which makes it a candidate for a theory of everything but then I
just heard you say well there's the quantum mechanical world let's say high fluctuations
then there's low fluctuations of general we live in the middle so then is the free energy principle
simply a principle of the middle and not the one that generates all three or do you see it as being
a theory of everything itself so that's a very good question you're right which deserves two
completely different answers I think the thing that the free energy principle brings to the table
is is only licensed by the presence of a Markov blanket so basically the way I look at this is
this is applying box standard variational calculus of the kind that people have been using for centuries
not centuries but in certain it's two centuries with the most right you know to get at formal
formulations of classical mechanics and quantum mechanics and statistical mechanics or strictly
speaking stochastic mechanics thermodynamics and so you know it uses exactly the same maths the only
thing that's special about it is that it applies that math in the context of a Markov Markov blanket
or a particular partition into inside and outside and separated by blanket states that's the only
thing that it brings to the table and in in that sense if you allow me to interpret everything as
every space thing then thickness as defined stipulatively by a Markov blanket that allows you
to demarcate a thing from not thing is certainly a theory of everything by definition but in a very
deflationary way right right right now when you say deflationary see to me the way that you use it
is different than how you described it unless I'm misunderstanding it the way that I hear you
using the term is like there are concepts that we have a colloquial understanding as to its
connotations but you use it in such an abstract manner that it coincides with the colloquial
only seldomly and so we shouldn't take it too seriously for example when someone says surprise
it doesn't or belief it doesn't mean that that atom has a belief that's the way that I understand
deflation in my misunderstanding deflationary no well it well it not not at all no you're certainly
understanding my use of the word but it is quite likely that I'm using the word I'm abusing the
word or at least misusing it but that's exactly what I meant yes you know and so it is getting
under the hood and not reifying and not associating all the folk psychological interpretations so
you know I get that a lot I have to suddenly pause and say when I say a base in belief I of
course do not mean something you can talk about that you have a conviction about these these are
just conditional probability distributions so you always have to sort of say look we're talking
about something that's simpler here than you might think and I think that may in part be an
explanation as to why people think that the free energy principle is difficult to understand it's
not it's just that they think it is because they're they're reading it using folk psychological
or you know possibly from my point of view over rare find rare find rare find the mathematics
I see I see when I first started learning free energy principle when I first started learning it
what struck me was its connection to disparate fields of biology physics machine learning
and so on and it reminded me of in mathematics there's modular forms which keep coming up over
and over and there are problems which previously were intractable that when you recast them in
terms of modular forms they become easier to solve do you mind listing some of the applications
of the free energy principle that let's say reformulates previously convoluted complex problems
into something more simple and the different fields maybe I can even when I'm editing this maybe
I'll even list like physics and then here's how it helps physics here's how it helps biology
here's how it helps machine learning so do you mind going through a couple examples
you can go through this quickly because I'm sure you've done this many times and I'm mainly
interested in a list well that's a very interesting question I know I haven't so but you're absolutely
right so you know the theory of everythingness which is you know I use a rather cheeky way to
interpret everything and it's thinness which is the theory is also I think claimed by this
the free energy principle in the sense you're you're you're you're hinting at that it provides
an explanatory framework although albeit deflationary for many different disciplines
and you see that in terms of it really being the underlying maths behind all kinds of explanations
for behaviour of a purposeful or systematic sort so for example you can interpret the
this this quantity either cast as a variation free energy or the thing that it provides an
approximation to or a bound on which is the the log probability of being in attracting the states
you can interpret that in many different ways and you spin off different kinds of approaches
in the life sciences and the physical sciences that suddenly are seen as just different ways
of expressing the same underlying mechanics so a particular instance here would be
interpreting the the free energy as a value function a negative a loss function yeah
so then you can write down reinforcement learning you can write down expected utility
theory in economics you can write down optimal control theory in engineering so all of these
things have in common the notion that you want to have controlled dynamics that optimise some
loss function but if the loss function is is just the negative evidence or the free energy
you've now got an explanation as to why all of these takes on interesting behaviours of the kind
economists and behavioural psychologists and control theoreticians study have to they're looking at
exactly the right kind of dynamics because all of these systems have to possess this
fundamental property and then you can you're not only if you like provide a unifying framework
that you can now start to understand you know well where does the bellman optimality principle
come from well you can actually cast it as a limiting case of a principle of station reaction
Hamilton's principle of station reaction when applied to a Markov blanket which is just a free
energy principle so if you wanted me to say in one sentence what is the free energy principle
it is the application of Hamilton's principle of station reaction to a Markov blanket
that's interesting that's interesting so yeah where do you get the bellman optimality principle
from well if you take away lots of uncertainty or you know from from the probabilistic treatment
on offer from the free energy principle you end up with the bellman optimality principle
so that you know that provides a unifying take on things like Bayesian decision theory
when you put the uncertainty back in again you get something which is now a mixture of Bayesian
decision theory and optimal Bayesian design sometimes known as active learning in machine
learning so now you have a principle first principle account of the so-called exploration
exploitation trade-off which just dissolves in the free energy principle you know the free energy
has two bits to it I will go to the details but in the same way that a good statistician is always
trying to optimize the the evidence the marginal likelihood of or the the evidence for or the
variation of free energy associated with their model they're just trying to provide an accurate
account of the data at hand that is as simple or minimally complex as possible so we come back
to algorithmic complexity under the hood here so in the same way you've got this these dual
aspects to the good inference again complying with Occam's principle possibly even James's
principle of maximum entropy apply to belief structures or posterior beliefs or Bayesian
beliefs you you've got this sort of dual aspect to what is a good inference which has this sort of
accuracy on the one hand and the complexity on the other hand and when you apply this in an
inactive setting where you have to have to make moves and decisions and consider not just you know
me as a sentient organ absorbing sensory states but I actually also act and choose where to look
you get this dual aspect which is basically exploration exploitation I want to minimize
surprise or prediction errors by sampling those things that I predict I should sample
like being warm and happy and befriended but at the same time there's also another aspect which is
this epistemic aspect this resolving uncertainty so if surprise and specifically self-information
surprise or if expected self-information is entropy then expected surprise is uncertainty
so in minimizing surprise and minimizing prediction error in expectation on average under
particular decisions or choices I make I'm also compelled to minimize my uncertainty about the
world out there generating my sensations so there's this epistemic part that comes into play
which you know in the same way that the the accuracy and the complexity add together to give you
the model evidence or the free energy these two sort of exploration exploitation things just add
together to give you the expected free energy so that to my mind provides you know another example
of the unifying aspect where you can from a first principle account put together two seemingly
separate strands of Bayesian theorizing on the one hand Bayesian decision theory which is all
about making the right decisions under some priors or some loss function on the other hand
good experimental design that you know could be read as a sort of preparing approach to the
scientific process or possibly beyond but they're just two sides in the same coin so that's a nice
unification that I repeat dissolves things that I see as living in the 20th century like the
exploration exploitation dilemma there is no dilemma it's just how precise are your preferences
that drive that sort of that technically what is actually a risk so the the complexity
when you take the average complexity of the free energy under some expected outcomes before you've
actually made a move on the world that becomes a KL divergence between what you anticipate will
happen and what a priori you expect to happen so that's risk in economics and in engineering
sometimes there's KL control. What does KL stand for in the divergence? Sorry Colbacoliba
which so it's just it's just a particular well it is just a relative entropy it's just a measure
of it's not a measure that's good I should it's a way of quantifying the divergence between two
probability distributions or it's a measure in the deflationary sense
well actually no no that's that's very clever but technically wrong now the reason I caught myself
was that the KL divergence between A and B is not the same as between B and A so it's not a metric
measure which is why I can't use the word measure right so it's not a measure but it's like a
like a measure so that's why it's called a divergence so you know it's just a relative
entropy it's a way of quantifying how much you you know if you read a Bayesian belief as a state
of mind how much have you changed your mind and the key thing at the heart of if you like applications
the free energy principle to inference and active inference and Bayesian decision theory
and the like is the the the divergence between your beliefs before seeing some sensory evidence
and afterwards so if you're a Bayesian statistician this would be the KL divergence between the prior
and the posterior literally how much you've changed your mind or moved your beliefs in response to
assimilating some new data okay am I supposed to understand surprise as equivalent to a mismatch
between what you predict and what actually happens so error right that that's an excellent quote
is it more complex than that well it's you know if you want to get into the nitty gritty so surprise
read as surprising is a very simple concept concept it's just the self-information it's
the negative log probability of some outcome usually as you know a sensory state of your
Markov blanket so if something is highly improbable or if the outcome or your sensory state say your
physiological or sensed physiological state is highly unlikely given what you are so the usual
example here's a fish out of water for example that that has a lot of surprise it just means it's
just you know a euphemism for for self-information that scores the kinds of outcomes that would be
characteristic of this self-organizing system so it's just a way of writing down or scoring the
probability of being in this state if you're that kind of system or technically if you're
you have that that kind of pullback attractor there's another kind of surprise which is the
Bayesian surprise which is often confused with that which is I think closer to the notion that
we're just talking about which is the degree to which something causes me to change my mind
with the information gain which is fact the complexity so the complexity basically when you
if you're looking at this as a statistician you're given some data and you had some prior beliefs
about what caused those data before you saw the data and then you use Bayes rule to combine
the likelihood of those of those data given your beliefs about how they're caused with your prize
you can't be the posterior so posterior after seeing the data this is now your belief so you
start with your prior belief then you have your posterior belief and then there's a movement
and that movement is this KL divergence that we're talking about that scores the amount you've
changed your mind that just is the complexity it's the complexity cost that you have paid
for providing a more accurate account or an accurate account of the data
that you've explained that has moved your beliefs from priors to to postures so it is
the the cost of changing beliefs in order to do belief updating or Bayesian belief updating
I'm going on about that because it's quite interesting that because you have
via things like Landau's principle and the Josinski equality that degree of movement
costs thermodynamic energy so that tells you that a good artifact a good person or a good computer
from the point of view of existential goodness as scored by minimizing free energy or maximizing
marginal likelihood or model evidence is the kind of personal computer or artifact
that when confronted with some new information will actually process and assimilate that in a
really thermodynamically efficient way so they'll do it with a very cool brain they won't use very
much electricity or food and very little will change and what that basically means is that
their prior beliefs were already quite close to the posterior beliefs so they already had a good
idea of what's going on so they were not surprised so and in not being surprised they're trying to
minimize that complexity cost in terms of the price you have to pay for providing an accurate
account of some data you are you are also maximizing the efficiency of of your belief updating so
I think that's quite a nice thing because what it says is if you want to build good artifacts
artificial general intelligence what you're looking for is a really small thing that can
be powered with a battery that's the one that's the kind of thing that'll do the best kind of
belief updating that's really tailor made for the inference problem inference problem at hand
so that's a we wandered away from your question about what surprises but the other surprise is
just basically the impromptu implausibility of this happening to me basically well when you were
talking about what makes a good computer or a good person and you're using good in a different
manner I assume you're using it in terms of adaptive or effective or accurate or at least
not using too much energy to accomplish its tasks that to me sounds like
almost a restatement of Occam's razor that you want the minimal assumptions to account for the
most data is that similar no oh no it's exactly the same thing so that's excellent yeah no that
that's exactly so you know the the pressure to provide a simple account of the of the data
is exactly getting this paying the least complexity cost possible for the for the accurate on the
fitting and that is exactly Occam's principle and if you don't know that that's important and
that's probably more important than the accurate fitting then you'll end up with machine learning
artifacts and devices and schemes that overfit and if they overfit they don't try to minimize the
complexity of the the explanation at hand or you know that effectively their inference and then you
will get an inference and learning that does not generalize so inevitably if you allow for
overfitting then you overfit today's data and tomorrow's data are very difficult to explain
because you've overexplained today's data so just practically what this manifests as is a problem of
sharp minima and difficult to solve optimization problems in in machine learning you get stuck
in local minima that have a very very difficult and that's because you haven't you haven't
flattened the minima by building into your objective function this simplifying aspect this
complexity suppressing aspect and of course once you have an objective function which actually
entails that complexity minimizing imperative then the minima by definition the free energy
minima are always shallow so that you've got a lot of latitude to wander around your minima so
you're not committing to a particular sharp explanation of overexpaining the data so it's
a really practically really important you know observation there I should say that when I talk
about good I just mean minimizing free energy or maximizing evidence so that's the only good
for me which is fit for purpose in this world having a good model of this of this particular
world let me see if I can explain what I heard in another manner let's say you're playing roulette
what you want to do is you want to have a minimization of your mismatch of prediction versus
actuality but let's say you have a good reason to believe that 33 black is going to be hit
you don't put all your eggs in that one basket because you could be wrong so you need to have
some spread it's not a direct delta function it's not just that and then that spread is
equivalent to entropy is that correct because there's a trade-off between you wanting to be
completely accurate but then leaving one's options open yep no that that's absolutely right so that
well you use that wonderful phrase leaving one's option open having that latitude in play
in in play is a very important aspect of this expected complexity minimizing imperative that you
get from you know sort of trying to minimize the expected free energy for expected following
a particular choice or action so just in that particular instance you know if you would if you
were acting according to expected utility maximization and you thought that the black 33 was the most
likely outcome then you put all your money as a delta function on the outcome that's not what
KL control does that's not what with sensitive control it's not what the sort of the exploitative
part of minimizing expected free energy does it tries to match your anticipated outcomes with
your with your prior beliefs that incorporates exactly that kind of uncertainty and indeed
there may be situations where your behavior at the roulette table is doesn't look as if it's just
about trying to maximize the amount of money that you'll get following the bet you may be
that sometimes compelled to engage in epistemic behaviors that resolve uncertainty so say that
you have the hypothesis that the roulette wheel was rigged and it was rigged in a way that
depended upon the way that people placed bets then you might actually place a bet just to see
what would happen in terms of the what the person who's in charge of spinning the wheel
does so you know not every move is just about minimizing some or realizing some prior preferences
or minimizing some loss function a lot of a lot of our moves are actually to resolve uncertainty and
disclose things that we don't know and resolve our uncertainty about the other contingencies
under which we're operating so then you can get into some sorts of interesting paradoxes in terms
of deceit and regret and making moves just to reveal what's going on out there and particularly in
transactions with with other people so that's another you know just beyond the KL the engineer's
perspective on KL control the matching behavior which is in psychology this you know you try to
match the probability distributions on from which you sample your choices to the underlying
payoff structure at hand so that you know that would be one way of looking at the utility of a
KL control or risk sensitive kind of control but beyond that there's also explicit sort of uncertainty
resolving moves you can make such as checking which is a fair fair gambling house and a non-fair
one on google before you actually start your commit to going to gambling this house as opposed to that
house yeah speaking of gambling have you heard of newcoms paradox oh okay well look it up at some
point i'll say it here but the paradox is imagine you go to a circus tent and then someone says
here is a box it's clear and it has a thousand dollars in it that's box a then box b is sealed
can't see it but the fortune teller inside there says i think it's you can choose either the sealed
box or both boxes those are your only choices now what's in the sealed box is one million dollars
ah i'm messing it up you'll just have to look it up it's something please let me spasmodically
verbally vomit here for a second as i try and get it correct because it's actually it's an
interesting paradox and i wanted to know what your theory had to say about it now obviously you
can't answer that in real time because you might have to think about it but something like okay you
have a sealed box you have a million dollars a million dollars maybe in it or it's not i'm trying
to work through what the actual paradox is the fortune teller says i have predicted i'm 100
correct maybe there's a sensor you can say there's a sensor that analyzed your brain and it knows what
you're going to do and she either put one million dollars in it or didn't depending on if you
depending on if you choose ah right she says if you're going to choose this single box just the
box alone the sealed box then i've included a million dollars in it i've already predicted which
one you're going to do by the way but i'm just letting you know if you just pick the sealed box
you get a million dollars i put a million dollars in it if you choose both boxes because you're greedy
i put nothing inside the sealed box so then the question is what do you do now you have to make
many assumptions you have to assume she's telling the truth when she says that she's able to predict
you with 100 accuracy but even if it's 99 accuracy the paradox still holds the question is well what
do you do you may say okay now that i'm there she made that decision beforehand the million
dollars is either there or not i might as well take both boxes so that's one way of reasoning
through this problem but another one is to think okay all the people that just selected the sealed
box get one million because that's the way that she said it's worked she said also that hey i've
done this millions of times and i've always predicted correctly so then what do you do do you
risk taking both boxes or do you just take one and it it shows a difference in i forget what
it's called either causal decision theory and there's another type of decision theory one where you
maximize evidential based decision theory so usually those two imply the same solution but
here they don't anyway i wanted to know what the free energy principle says one should do because
it's a famous paradox let's forget about that then i'm gonna have to go and google that one it
it sounds even more complicated than the mon the monty hall paradox problem so it sounds intriguing
so yeah yeah um so the paradox is it's basically um the the paradox that is confronted by you in
the situation as opposed to a paradoxal behavior that people actually right right right you want
to maximize the amount of money so let's assume you're instrumentally rational that is you want
to maximize your your pleasure whatever it is what do you do okay so forget about that something
i was wondering about the free energy principle is how much of it do you see as a principle like a
law like a law of physics versus a compression mechanism so for example what i mean by that is
when you look at Maxwell's original paper for his four laws they're actually 26 different equations
or 24 it's two pages long because he didn't compress it down to the four that we now use
so these four aren't actually four equations they're just code and then i always wondered how much
of our Lagrangians are sorry the minimization of action is an actual principle of nature
versus this compression mechanism that says here you're complicated equations of motion
what you can do is you can package it into this simplified little Lagrangian that you then put
into the Euler Lagrange equations and you crank out the equations of motions so it's not actually
a principle in and of itself it's more like a zipping of something that's convoluted so do you
see the free energy principle as a law or do you see it as akin to what i made an analogy about with
Lagrangian mechanics and the Lagrangian that is it's just compressing could just be compressing
yeah i think that i see it as a law but i think that distinction is is very nicely articulated
i think it's really in play in in my world in a slightly different way so i repeat the the free
energy principle is just a variational principle of stationary action cast in terms of density dynamics
of things that have markoff blankets and by implication at steady state so it is as it plays
a role exactly the same role as Hamilton's principles of stationary or least action so it
either applies or it doesn't so it's not a it's not a theory and in many senses it's not very
useful you know it's just a way of writing down and zipping things up as you nicely put it
in an internally coherent way that speaks to sort of you know as all i think these
useful principles do some symmetry or some invariance property for me the variational
principles of stationary action are the simplest and most graceful way of expressing these symmetries
you can do gate theories or i'm sure there are other formulations but for me you know the best
way is just to to use that principle of least of least action or stationary action so that's
what the free energy principle does but as you say you know for the free energy principle
what does that actually mean in practice well it means that anything that exists can be understood
and simulated or built as a gradient flow on a free energy function a function of what well
the free energy is a function of the states the data the states of the markoff blanket
and the basian beliefs about the posterior beliefs about the causes of those data that are
encoded by the internal states so where does that where does the where do those beliefs come from
well they're defined or the free energy is defined if you think of this sort of prediction error
version or reading of free energy they're defined by a generative model that predicts
the sensations that you would get if that model was right so you have to have a generative model
so you know that there's going to be a universe of generative models you could plug into the
underlying gradient flows the Helmholtz decomposition that we talked about that
basically describes all dynamics you know for systems that can be cast along with markoff
blankets so the question is not so much now the free energy principle or the application of a
variation principle is action but really what is the generative model so at this point I think
then you move away from the principle and you start now to get into the world of process theories
and hypotheses so and you can ask that question or you can have those hypotheses at the number
different levels you could actually take a working system a person say if you're a psychiatrist
you know somebody who might have obsessive-compulsive disorder and you may say well I want to understand
them now as making decisions under some model of their lived world some generative model I know
their neural dynamics and I and I know the principles that underwrite their choices but
what I don't know is their generative model and their priorities so I'm going to now reverse
engineer on the basis of their behavior what are their priorities what what do they actually
believe is going on to best explain this behavior so that will be one application another application
might be building artificial intelligence machine artifacts you know where I now write down
the you know the prior preferences of a generative model the kinds of states that I want this system
to aspire to and I then just let it you know I just equip it with active states and actuators
and sensory states and sensors and I make a little robot and off it will go and it will go and
epistemically forage always with a mind to learning about its world but also under the
constraint of its prior preferences like keeping its battery charged so that will be another instance
but in both applications I've had to either reverse engineer or commit to a particular
generative model and that's where I think the you know you moved a long way away from principles
and if it's a question about does this person with obsessive or compulsive disorder have this
kind of generative model on that kind of generative model and that's no a hypothesis that we're
falsified with respect to the evidence if it's a question of building an artifact do I use a
discrete state space generative model or a continuous one which means I'm now committing
to different kinds of message passing if it's discrete it could be a variational message passing
on belief propagation it's continuous I'll be using things like linear quadratic control or
Kalman buce filters so again you're now in the mechanics of the processes that are
realizing these gradient flows and of course there are no principles or rules that tell you
you're right or wrong that these are all process theories that might work and that might not work
so you know I think the zipping that you talked about is from my point of view it's basically
unzipping the principle to realize that under the hood it is the generative model that supplies
the free energy gradients that drive the gradient flows that's the big open question and getting
the generative model right is in most instances scientifically or indeed in industry and possibly
even in medical translational practice translation of these ideas and medical practice it's all about
getting the right kind of generative model and your hypotheses about that generative model
you said a couple of statements that reminded me of Jordan Peterson now I'm not sure how much
you follow Jordan Peterson at all but he's a proponent of watching what someone does to
infer their beliefs so that is okay well you're not sure so you understand what that means and
then number two he also mentions order and chaos and the balance between them which is
Taoist that you don't want the elimination of one or the predominance of another you want
a special balance between them which reminds me of what you said about surprise and then I believe
it's KL divergence right okay you don't want one to dominate there's a delicate balance have you
heard Jordan Peterson speak on order and chaos and do you see any correspondence between the
free energy principle and what he says about chaos and order yes I think so I mean I would
I would put this I mean there are a number of different routes one could take to that kind of
issue you could ask yourself is there any first principle account for example of self-organized
criticality so you remember the edge of chaos notions from the Stuart Kaufman and self-organized
criticality that was the self I was trying to remember before but that's another one of these
branches of physics which starts off with self so SOC self-organized criticality so this is a notion
that it is inevitably the case that any self-organizing system will organize itself to a regime of
critical slowing and dynamical instability which you know Stuart Kaufman might have articulated
in terms of systems moving themselves towards the edge of chaos so towards separatrices towards
sort of bifurcation into regimes usually associated with multi-stability or metastability
you know depending on the nature of the dynamical system but there's tendency to
to put yourself in a state where you have a repertoire of dynamics available to you
simply because you are near disorder you're near chaos so but you never actually go chaotic
but you just it's a latitude of the repertoire of things you know of dynamics that might happen to
you and that from that perspective then there are sort of there are I think a number of interesting
things that the free energy formulation brings to the table the first we've actually already touched
on which was this building in to an optimization perspective shallow minima to preclude the
existence of sharp minima and just by having effectively Occam's principle baked into your
understanding of life or indeed any kind of self-organization as you know trying to
optimize this bound on evidence or marginal likelihood then you're necessarily saying
that you want to have these low curvature minima you want to occupy low curvature minima that if
if you now ask what would that look like in terms of you know coupling between internal
external states in the context that the the gradient flows are informed when went out free
energy minima by very shallow gradients what do you get well you get exactly this sort of this
latitude for excursions which have a long correlation then so you get this you know
the kind of critical slowing that is associated with self-organized criticality so often so
heavy tail distributions in terms of in terms of sort of covariance functions for example
so that I think there's a simple and mathematically and deflationary account of
the balance between order and chaos at least from a purely dynamical's perspective
that is on offer via the minimization of free energy with gradient flows
simply because you are dealing with minima that don't trap you they allow for that latitude
so you avoid I see I see a particular solution now sharp would be too much order absolutely yeah
so you just get locked in you get you literally get stuck in a rut you get locked into this
particular explanation and any slight movement away from a very sharp minima incurs an enormous
penalty and right so you just don't make that move but if you've got a very shallow
basin of attraction if you like and I repeat I think the beautiful thing about the sort of
the free energy functionals or this free energy functional is that it's built to be shallow
you it's a you know perhaps an analogy would help here that that if you think of a free energy
landscape that is paraded by a mountain landscape right from the high that the mountains mountains
in the Scottish Highlands right down to the estuaries at sea level then what you typically
tend to get is that very high terrains of any landscape have lots of high frequency ravines
and sharp valleys and sharp minima so there's a little stream at the top of a mountain will be
will be carving its way through very sharp trajectories and they're meeting slower and slower
and wider and wider streams as it comes down the mountain but also what happens is that as you come
down towards sea level as you get to lower and lower free energy levels the terrain itself
becomes smoother so all the minima now have smaller curvature so that you don't get those
sharp little landscape features that you saw high in the free energy or high in the mountains
anymore what you get are now much more a much more gentle landscape where everything because it's a
lower altitude or a lower free energy has to be smoother has to have a you know by Occam's principle
it has to be it has to have less of a curvature and what that affords is the latitude for the river
now to start meandering around like you know sometimes for the oxbow legs and features
that you that was kind of meandering that you see as a large river starts to
wander and oscillate as as it gets towards the estuary and gets towards the sea and it's that
sort of wandering around which is that if you like the sort of the the the permissive or the
reflection of what can happen with a low curvature free energy functional or objective function
which is in the cell in the sense that if the system is trying to minimize its free energy and
get to those estuaries so it can do its want slow wandering around you get this critical slowing
that you see dynamically that characterizes you know all kinds of interesting behaviors from sort of
avalanches in your own avalanches in the brain through to the markets in the old days this might
have been known as catastrophe theory but you know it's the same notion that when we're close to the
edge of instability which means we have the latitude to explore different states you're on
some objective function that we wouldn't have if we were stuck in a rut and committed to a particular
solution and we've overfitted the data for example or we've got trapped in a local minima so that's
that's one thing there is another aspect there which we haven't touched upon which
I think nicely follows on from this notion of you know getting the generative model right
so if you remember the free energy functional or the model evidence needs a model in order to have
so the model can have the evidence and of course you know most of the time you're dealing with models
that have unknown states such as models that underwrite things like Kalman filters unknown
parameters such as the generative models that might do weather forecasting but there's another level
which is the very structure of the model itself so you're even even if I knew all the states
the time varying unknowns in a generative by a particular model and even if I knew exactly all
the particular connection strengths and rate constants and every all the other parameters
and contingencies I you would need to know to to make this model predict the perfect data
perfect explanation for these for this observed world I may not know the structure of the model
so if I was doing say deep learning and I wanted to build a deep convolution network how many how
many layers do I use two four eight sixteen so these are really important architectural structural
problems that are attributes of the model but the model can always be scored given some data
in terms of its free energy or elbow evidence lower bound which means there's always an answer
if you can create a space of models to evaluate so this is known as incognitive neuroscience
by people like Josh Tenenbaum as structural learning and it's the problem of basically
exploring the right structure of models by you're adding things in taking things away
collapsing things together you talked about modularity before and that's a really important
architectural aspect of these models usually cast in terms of factorization it's exploiting conditional
dependencies to get simpler models that you can have a modular architecture in the journey model
so all of these structural the hierarchical depth the degree of lateral factorization or modularity
the number of parallel streams the number of nonlinearities all of these things need to be
optimized to get the good model the free energy minimizing model so how would you do that and
this point that you come back to disorder and chaos so one really efficient way of exploring a
space of models is to actually exploit the chaotic dynamics that you get or at least
stochastic dynamics that you get for example in natural selection that you could take arguments
from evolutionary theory and again coming back to Stuart Kaufman in terms of his formulation
of selection for selectability I don't know have you come across this second order selection
no actually the way that I encountered Stuart Kaufman was reading about his expansion of
Schrodinger's what is life and then Schrodinger posed three questions that is how whatever he
posed three questions and Stuart Kaufman answers the second two so two and three all right I didn't
read much about him afterward and I'll ask you about Stuart afterwards but do you have to tell
me what the questions were that sounds very interesting yeah sure sure I'm talking about his
work um on sort of um more sort of artificial life um that speaks to this edge of chaos and the
the necessary role of disorder or chaos in any evolving system that needs to explore different
ways of being so it's interesting because of course you can now the degree of chaos that you
bring to the table the degree of mutation for example there will be an optimum degree of mutation
that depends upon the volatility of the environment and the degree at which you exploit or leverage
chaos now becomes subject to selective pressure and just as an aside you can always recast
selective pressure as basically a pressure to minimize free energy if you read free energy as the
you know the adaptive fitness of any of any phenotype in a in a natural set of natural selection
so what he's saying is that there is an optimal degree of changeability and chaotic exploration
of any model space or any way way of being um that to my mind provides a very nice
perspective on this tendency for self-organized criticality that we actually move ourselves
to the edge of chaos just to position ourselves so we can explore and make sure there are no
better ways of doing things so I think that that that aspect of you know or the right
mixture of order versus disorder order versus chaos you know comes out at the level of the
structure learning itself from the sort of the repertoires of different alternative hypotheses
about you know modeling our world or making decisions in that world okay when we're modeling
this world most of the time what we do is we look at nature and then we see principles and then
sometimes we can infer about the brain so let's say we understand how atoms assemble then we
understand the molecules assemble then we understand cells and so on so obviously it's
not as simple as that but then you in one of your interviews posed another mechanism that is that we
can look at the brain structures and we can infer about the world so for example I believe you said
that the fact that an axon is long and reaches out is a reflection of spooky action at a distance
or action at a distance and then I was thinking well what about the hierarchical structures of
pyramidal neurons do they reflect that our world is hierarchical and first of all why would that
be the case why does it have to be mirrored second of all there's another structure that is the
bio hemispheric structure of the brain so one is I know there's a fair bit of myths about the brain
left brain versus right brain but there's also some truth to some parts of that now Ian McGillchrist
I'm sure you're aware of his work or his name sounds familiar he explored that as well so
my question is what can you infer well why does it have to be the case that your
internal structure of your brain would mirror reality in some manner and second what about
the bio hemispheric structure what does that say about our world okay well that's a really good
question which could take us in a number of different directions the the notion that the
if you are in the game of predicting minimizing surprise through the lens of minimizing prediction
error then you want to generate a model that can faithfully but simply reproduce the kind of sensory
data sensory impressions that the world is generating so the formal structure of the the
process that generates the sensory input has to be to a certain level recapitulated
on the inside in order to generate and afford those the right kind of predictions so that is
a statement really I think the good regulator theory which which arose towards the end of the
cybernetics movement by people like Mos Ashby sort of you know regard by so as a father of
self-organization this notion that every system that controls or regulates its environment must
in essence be a model of that environment so there's an isomorphism between the controller
and the controlled and that certainly is the case um is it an sorry to interrupt I'm so sorry
is it an isomorphism like is it exactly mirrored because I recall when I was speaking to Bernardo
Castro he said we can't model our reality exactly because if we did we would dissolve into an
entropic soup and then I said what do you mean and then he said the argument was it was too convoluted
for him to state at the time and I think he was referring to you so is it isomorphic or is it just
no you're absolutely certainly not isomorphic because as you say if you want I mean the best
model of the world is the world itself I mean that's that's a truism whichever everyone celebrates
so um no it's a it's a sufficiently good model or not only good model in the sense that it's the
simplest caricature of the system or parts of the system the subspace you're trying to control
so you know I still think it's useful to consider the good regulator theorem
but you're right it's not not isomorphic in any sense it's and even less so when you when you
consider that a lot of the time we actually build our own sensations when we move and certainly
in terms of sensing our own body you know we are in charge of basically creating that sensorium
um however let's just stick to the original question you know so no it's not it's not a
isomorphic but it certainly has the right architecture to be able to produce a simplified
summary or prediction of what's going on that is conserved every time around so you're only
interested in predicting things on average so that you're revisiting particular states
so you just need to get the gist of what's going on so it's a much simpler one but it still
must fundamentally have the same kind of causal architecture the same conditional dependencies
and you've highlighted a really important one which is the the symmetry between our two hemispheres
the you also mentioned this this which I've forgotten about which is you know the very
existence of neuronal processes long thin um connections um that our neurons are equipped
with which you won't find anywhere else in any other organ um you know the liver doesn't have them
the heart to a certain extent does have fibers but they're not they're not nice and long um
which which you know just reading the structure of the generative model is telling you something
about the kind of universe that's generating the data that this model is trying to predict
tells you immediately you've got action to distance um which is not necessarily a given
but it tells you that this creature must contend with a world where there's some kind of action to
distance it can see things in the distance for example so you know the contention would be
if you had a um a worm that could not um see things at a distance then it probably wouldn't
have very long axons um and it would be quite comfortable having lots of short range axons
that were quite sufficient for modeling a world where it's just immediate contact and
short range causality that's generating its sensations okay quick question so I'm speaking
to a camera right now and its sensor is fairly flat and yet it can pick up from far away it can
pick up a mountain now I understand that the camera isn't acting on the world are you saying that if
it was to have some embodied enactment then well it wouldn't use this sensor in the way that it's
formulated right now it would use axons in some way would use long wires in some way you'd um if
you actually well okay let's pursue that analogy then so um so you know let's pursue assume you're
going to be using um some kind of VGI um so you know computer graphics to generate um um
you know a visual scene that you could use in a movie so what that would necessitate is basically
a machine with lots of wires because it's all action at a distance so you couldn't do it on a
computer that didn't have big buses and the ability to move data around in a way that would
recapitulate the the action at a distance that is necessary for for VGI so particularly sort of
you know the ray tracing that's required um to to basically you know render a scene
you know that's massively computer intensive that requires a lot of if you like hardware
that you cannot do with just local computing you actually have to do lots of lots of message
passing it yeah and we're talking now about sort of the architectures that computer scientists
would you would use so it's just that there are certain computations you can do um without
sort of you know the kinds of architectures you'd find in computer science that just involve
local interactions but as soon as you have to actually generate virtual worlds or worlds um
that they entail action at a distance you've got a different kind of collectivity and a different
kind of structure so that's how I was really trying to intimate um intimate there um the my
favorite example is is um before we turn to the inter hemispheric one is the um a differentiation
between a dorsal stream and a ventral stream primarily concerned with what things are and
where they are um and this speaks to that modularity that we were talking about earlier on that um
somehow our brain has found a really simplifying device to create a modular architecture by
leveraging the conditional independence between whatness and awareness in objects in the kind
of universe we live in so put that simply that you're knowing that this is a cup doesn't tell
me where it is knowing something is over there doesn't tell me what it is so that means that
if I'm trying to generate predictions I only need I can have one part of my brain doing the
whatness and the other part of my brain doing the awareness and then I can bring them together
to actually explain the sensory input and that keeping things apart keeping these parallel
parallel streams apart means I don't have to have the complexity cost of all the connections
between them I don't have to represent every object in every position in the world I can just
represent um your what it is and where it is and then just bring them bring them together
as part of my genitive models so that that you know that tells you something quite fundamental
if I find a brain that has this segregation into what and where I know that they live in a world
of objects where they in their universe things don't read things are conserved when they move
ah uh-huh uh-huh interesting so um brings us to the delicate issue of why we've got symmetrical
brains I think quite simply because we've got symmetrical bodies um I think that you know
but then you may be asking why we've got symmetrical bodies but so I'm not gonna
answer that well I was actually referring to the asymmetry of the brains all right
that the left let's say Ian McGillchrist would say that the left is more concerned with
manipulation and pinpointing making definitive and the right is more concerned with exploratory
motion so even actually at nighttime when you're looking for your watch or your clock you actually
explore with your left hand because it's controlled by the right brain naturally you move you make more
exploratory movements with your left I'm not saying anything you probably don't know and then with
your right most people are right-handed and they like to well whatever so then I was wondering
is that a reflection of what the world is composed of or comprises in some manner and then also how
does one know when one is taking this too far so for example just because the brain has a morphological
structure of foldiness and gyrosis and sulky and so on it doesn't mean the world is full D
or my experience is is hilly how does one know when to apply it and when not to
so I was just thinking about all your challenging questions of one by one and I like the one about
me the world isn't folding that's very nice um and and this mystically one can make an
an analogy and say well the world is complex and fractal like and nothing is ever the same and
and you can look at it from multiple vantage points so it sounds to me more like one is playing a
linguistic game in that example that I just gave rather than actually giving a property
of the world that's reflected in the morphology of the brain yes yes um so I also just remembered
that I saw a presentation by colleagues of mine recently that actually interestingly made the
foldiness a possible reality but that's a distraction and a unique and very exciting
observation uh but you're right so when I'm talking about structure the only structure that
matters is the same kind of structure that underwrites a markoff blanket is conditional
dependencies so I'm talking about a connectivity architecture here I'm not talking about the
physical shape of the brain I'm just talking about what is connected and what is not connected
so you know you all I need is the graph if you like if you're a graph theoretician I just need
the adjacency matrix on the connectivity usually the directed connectivity matrix that's for me is
what what defines the structure so um you know the at that level um the kinds of structures
that can be defined purely in terms of the adjacency or the edges on a graph are things like
the number of hierarchies or the number of parallel streams or the number of modular
number of modules or clusters you know the degree of small world as if you if you like
of clustering indices I can't remember all the um the graphic terms for them but
crucially it's just that defined in terms of connectivity and I think um I think you can you
can um within that remit without going into the world isn't doesn't have cortical folds
which I agree with you is a brilliant sort of yeah sort of sanity check on taking this too far
but within the remit of um instantiating and biophysically realizing causal contingencies
and associations uh in terms of connections between um biological systems in particular
neuronal systems I think I think you can um I think you can actually play this game
and play it for quite a long time in terms of the hierarchical depth and in terms of this modularity
and this factorization that we're just talking about and in particular the hierarchical depth I think
is is a very important one because you know you're asking me well why should the world be
hierarchically structured um but it is necessarily hierarchically structured if one
just considers a you know a separation of temporal scales so you know the just has to exist
in terms of a coarse grading um applied to any dynamical system um a progression of slower stuff
that is has a you know more coarse grained aspect to it uh that you could add you know
you could elaborate recursively um you know in principle for you know for an infinite number
of levels so there does exist causal structure out there in any sparsely connected um in the
dynamical sense um uh world um that I think fully licenses an interpretation of the corresponding
architecture and in particular its hierarchical depth as somehow mirroring or reflecting that
hierarchical structure out there with the obvious example of course is is is um all of that machinery
that aspect of our brains that is devoted to providing an apt generative model for interpersonal
interactions so you know if one realizes that most of our lived world is uh or at least the
sensations generated by that world are generated by other creatures like me namely you uh you know
whether we're driving around in cars walking in parks talking on zoom reading books 99.9 percent
of our sensorium is generated by another human being that is like me so that actually says there
has to be a lot of the brain has to be devoted to modeling me and people like me and making
inferences about me and as soon as you start to get to this um think about what kinds of
generative models would be fit for purpose in in that uh context then the imperatives to resolve
uncertainty are basically the drives for me to understand you so this so epistemic part of the
the free energy minimization as a consequence of action translates into an imperative to understand
the world but the lived world now with is basically you in this instance I need to understand you
how do I do that we have to have a shared narrative what does that require language
it could be maths it could be could could be English um but that narrative has many many
different scales to it that has itself a deep temporal structure so there's the the concept
that we're conveying there's a temporal scale of the duration of this of this um exchange um there
are much recursively much finer temporal structures in terms of the structure of the sentence the
phrases that I'm using the words the phonemes all the way down to the millisecond by millisecond
activation of your sensory epithelia in your ears or my neuromuscular junctions
controlling my articular articulatory apparatus so we wouldn't be able to talk to each other
or comply with this imperative to resolve uncertainty to explore the world that I have to model
without language and without a deep generative model with a deep hierarchical structure there
can be no language there's a natural if you like not pressure but there's certainly an easy way to
understand why we have deep generative models in our brain we in fact we do I mean you know nine
nearly all the interesting connectivity all the interesting architectural aspects of brain
connectivity speak to a hierarchical organization at some level it's cortical sub-cortical the very
word sub means below below is only an attribute of hierarchy it can't be any other thing you know
the visual hierarchy being the sort of the the poster child for very well defined subsumption
hierarchies but you know beyond that wherever you look in the brain there is some hierarchical
organization where where slow stuff is in training fast stuff at the lower below and then all the way
down to the to the sensory inputs on the the actuators on the active active outputs which are
the fastest parts and the elemental parts okay so hierarchy is another way of saying difference
that can be compared so that again difference so hierarchy a difference that can be compared
so these two are different but there's no hierarchy between them if it's like
someone may say apples and oranges but if it's between apples and two apples then there's a
hierarchy there because there's a quantity that we can reduce down and put a comparison between
them I see yeah no absolutely so that the high the way I'm using hierarchy here is certainly
sort of so when people talk about say deep learning what they're talking about is inference
and classification under a under a hierarchical generative model that has a number of hidden layers
so the depth of the learning machine refers to how many layers you build and so what you do is you
set put the data in and then you try and explain it with one layer and then those explanations
are that you then try and explain it with a layer on top of that and then you keep on going until
ultimately you get to some very very coarse grained very abstract explanations that are predicting if
you like the layer below and then their impact to predict hierarchically right down to the level of
say pixel elements in a tv screen or sort of you know some image that's been grabbed so the deep
the hierarchical depth is basically how many subordinate layers do you have I see I see one
higher level providing getting information from the lower level but also providing
constraints I'm saying well if this hierarchy if this context is in play then I expect this kind
of thing to happen over here in that modality and that kind of thing to happen over there in that
modality so it brings a simplification and a a better way of modeling provided that you've got
this hierarchical structure what you were talking about I think it's more than modularity that's
sort of is this an apple or is this an orange I think that within the hierarchy within the depth
from sort of you know the lower level which are usually at the level of the sensors and the actuators
and the higher level is usually the top of a pyramid of course you know there isn't a pyramid
in the brain it's you can imagine it more like a circle and the center being being the deeper
parts of it so but there's another architectural structure which is not in the the depth of the
hierarchy from the bottom of the circle say to the the center but actually the the different
streams you were talking about the apples and oranges and it's that factorization that what
and when that's that I was you know hinting at before which is a lovely example of you know
things I know about oranges are not relevant things I know about apples I mean that's probably a
silly example because there are there are things that I concern but things I know about fruit
are not going to be terribly useful for things I know about tools so I can actually have my
generative model generating a cascade of abstract representations becoming more and more detail
committed right down to a picture of or a sound of or me moving this particular artifact but of
course this artifact can be either a tool or a face you know or an apple fruit and and because
you've got you know these conditional dependencies tools don't behave like fruit and I don't in
particular I don't actively engage with tools in the same way that I engage with fruit I eat fruit
but I use tools so it's likely that you get this the separation through this this factorization
or modular parallel architecture in the setting of a hierarchical composition
so they're really important sort of sort of architectural principles if you have to actually
build or understand the brain but also if you wanted to build a you know a conscious artifact
or an internal artifact you'd have to equip it with a with this you know with both a deep
generative model but also had this sort of these parallel streams to them which brings us back to
the right brain versus left brain I still I don't have a neat answer if you're afraid you're
right I mean your language lateralization is a classic a classic and conserved aspect of our
brains but I can't think of a first principle account as to why that might be the case you
mentioned the word narrative that we have to have a shared narrative now were you saying that we have
to have a shared narrative in order to have peace between us or in order to interact or in order to
understand one another and then also does that narrative have to be encapsulated in language
or can it be embodied because I assume that animals can get along and they don't have language at
least not the way we do and presumably we didn't have language prior to a million years ago yet
we got along yeah when I mentioned it exactly the same the sense that you you intimated there so
yeah it is just there if we have a shared narrative that I'm now using narrative to describe a
generative model that entails sequences of things that happen over time so it's a model of sequences
that usually has a deep temporal structure to it so if I want to understand you and I want to
communicate with you in order to understand you and to and to ask you questions to understand more
about your your intentional stance your knowledge then I'm going to need to infer what you're thinking
and I can do that if I know what I'm thinking but only in then under the assumption that you're
using the same kind of model as me so we're both using the same code or singing from the same hymn
sheet so you know when you start to model this you don't you well we have models of of of
linguistic exchange which are cast in terms of simple games of 20 questions so you know
one agent has to ask another agent through linguistic exchange but it does depend upon
them both committing to the same generative model of this linguistic exchange in the meaning
a simpler a simpler set of simulations
arises when you think about sort of just birds singing to each other so they can recognize
conspecifics so you know what that's quite that's much easier to simulate when you just have
two dynamical systems talking to each other and they both now become entrained to show
synchronization of chaos than we were talking about before in the different contexts but here
in the service of mutual predictability so another way of thinking about what's the best
way to minimize surprise surprise or self-information when exchanged with another is to make sure that
I only exchange with other people exactly like me because I can predict exactly what you're going
to do next because I know exactly what I'm going to do next and I'm doing it so you know we could
be singing or talking together clearly we take turns but there are situations where we could be
actually singing in the choir together but I can only sing with people that have a sufficiently
similar generative model to me that makes it that licenses the use of my model of how this kind of
creature interacts with the world licenses its use as a model of how you are interacting in the world
and interacting with interacting with me so that's what I meant by a shared narrative just
just a shared or a conserved generative model between creatures that typically act together
in terms of things like joint attention or familial bonds or sort of conspecifics in an
evolutionary context you know the generalizes in terms of you know cultural takes on niche
construction you know the existence of things like signs and traffic lights and elephant and
desire paths and these are all manifestations of you know living sharing a world with other
creatures like myself that after a while they become very efficient very simple ways of communicating
that possibly as you say don't involve spoken language and non-verbal communication is clearly
an incredibly important part of that but even beyond that just the fact that we have a shared
commitment to stopping when a traffic signal or light goes red you know that's a shared narrative
we have that enables us to drive around and occupy the same streets when some of us are
driving or some of us are walking or both of us are driving so that's what I meant by a shared
narrative is sort of you know a common a common generative model of how to live in this world
with things like me interesting interesting okay now it can't simply be just shared there has to
be some other criteria only because me and you can still share the same model that says that you're
an enemy and I'm supposed to kill you and I'm and you're supposed to kill me so then it's not
just shared that allows us to be peaceful cohabitants and I was wondering then do you think religion
is an attempt to make a hypothesis or or to generate possibilities as to generative models
that a large class of people could share and minimize the suffering of both the society and
then individuals at the same time yeah I haven't thought deeply about this but that's a very plausible
very plausible explanation for why religious narratives have emerged and that's so successful
in maintaining themselves so you know just in terms of a simple analysis of the minimizing
complexity arguments that we were rehearsing before you know if you want to find a really
simple explanation that accommodates a lot of difficult to explain stuff very accurately
then a a deity that can cause all this stuff is a really simple explanation and you know if it
accurately explains your sensorium in your world then it's a it's a beautiful example of a very
parsimonious hypothesis now it may not be sufficiently accurate for a scientist who
does not accept you know a religious explanation for this or that but if you are not if you are not
sampling that kind of sensory information or that kind of scientific data then that doesn't
matter because you know you only need to explain what you need to explain so just as just as a
broad comment upon religious beliefs and I think you can generalize that to
societal norms you know just ways of behaving the right way to behave you know these are just
simple hypotheses that explain a lot of my behavior a lot of your behavior in a really
parsimonious way and therefore they have big evidence although free energy because they provide
simple explanations so but you're bringing something else to the table which is which
is an interesting one which I haven't thought about which of course these kinds of hypotheses
are easy to share as well in virtue of their simplicity and there's always going to be
benefit in having a shared or a conserved or a common generative model provided as you say that
we're all cooperating we're all acting as cons specifics and it's interesting to and you know
so in answer to your question I am sure that if you simulated multiple agents all free energy
minimizing all trying to predict each other in the most efficient way possible and then one of
them had this simple hypothesis of a religious or a ideological or theological sort that made
sense of lots of things to which everybody could subscribe you'd suddenly see the consolidation
and the emergence of that of that aspect of the generative model absolutely and that would render
everybody mutually predictable so everybody would be reducing their surprise you know
and that would mathematically be expressed as you know a collective decrease in free energy
or an increase in the adaptive fitness in the sense of you know increasing the marginal likelihood
of finding that phenotype around if you simulated multiple generations but the well in that case
there would be trivially correct in saying that there's a deity because you're the simulator
yes well that's an interesting hypothesis which interestingly if you if you do philosophy of
course then you got the brain in the vat thought experiment which indeed it actually has that
exactly as an alternative hypothesis to confound the you know the philosophy of realism versus
skepticism but coming to your interesting point that you know what happens if my generative model
is that you know you're my enemy you're going to you're going to you know cause me surprises
I think that's an interesting one you know the level at which we simulate these things really
only addresses cooperation and systems that have different components and trying to find their place
with a shared narrative so you what one would predict is that if there were
there were other kinds of agents that were not like you then you would certainly be have to
represent them but in virtue of the fact that they're not like you you wouldn't be able to
communicate with them so you know my prediction would be that you know whether it's a theological
or a political or other kind of commitment if there's an in-group and an out-group for anyone
given individual it is highly unlikely that there will be a shared language or indeed
a big transaction of communication between these two groups so there will be a mark-off
blanket if you like between the between the in-group and the out-group the blues and the reds the
you know wherever you go and an interesting observation which is not mine but I've heard
a number of people make is that the the only stable non-equilibrium for that in-group out-group
is a 50-50 split so the you know in the language of theoretical biology the evolutionary stable
strategies for opponents is a 50-50 split which is born out you know time and time again in terms
what do you mean a 50-50 split of what population of the number of people that would identify with
one group versus another group so it's interesting yeah so Brexit versus non-Brexit in the in the
UK or Trump versus Biden in the most recent American elections you know wherever you get
something where where there is contention where you commit to one side or the other side the only
if you like contentions or dialectics which seem to survive is when there's a roughly
50-50 split between you so okay so in other words the fact that we stably defer
somewhat down the line on many important issues is adaptive yep for the collective as a whole
it's just maintaining a non-equilibrium steady state yeah I mean adaptive in the deflationary sense
that you know that is one way to maintain you know a an extended non-equilibrium
you know where now we're talking about Markov blankets and Markov blankets and sort of applying
blankets to you know to multiple agents yeah there's one quote that I love that I I try to
live by and it's only the shallowest of minds would think that in great controversy one side is
mere folly I'm sure you've heard that before I haven't heard that particular one but I've heard
something similar which which which is okay so do you believe in free will and if so how do you
define it so free will yeah I mean do I believe in it there's certainly space for free will
in the realization of a free energy principle in sentient artifacts at many levels you when you
actually come to write down and simulate or build little toy agents you very quickly realize
that the most interesting of that the only interesting behaviors that you can simulate
arise when you write down the generative models as containing
autonomous dynamics usually of a chaotic sort so the reason I use the word your autonomous
dynamics is that you know mathematically speaking there's a sort of free will in the
autonomy there's even in a deterministic setting there is you know an unpredictability given the
initial conditions that cannot be determined so in that sense there has to be a mathematical
kind of free will at play the the the other the other sort of take I guess on free will is
it comes back to what we were talking about before about you know making our own sensations
creating our own sensorium so if you remember that you know from the point of view of minimizing
prediction error as surprise there are two ways I can do that I can change my mind
so that my predictions are more like what I'm sensing and that would be a minimization of
prediction error through perception but there's another way of doing that minimizing the prediction
I actually just change what I'm sampling to make the sensations more like the predictions
so that's you know that's action in the service of minimizing surprise or prediction error but
what that means is that my actions are basically enslaved to where they can fulfill my predictions
so they are in the service of fulfilling prophecies so collectively action perception
is a self-fulfilling prophecy and in that sense I think you know you can find free will you know
if we are creating our own worlds and our own sensory inputs we're constructing our sensorium
who else is doing it you know so in that very simple I won't say deflationary but simple
account of free will then I can't see how it can be any other way really I had there's something
that I've been wanting to study for quite some time and I've been making extensive notes on which
is self-fulfilling prophecies I find that to be an extremely interesting area of research the fact
that you can have them it's like you have a model of the world and most of the time what you want
to do is make sure that your model comports with reality but then it's as if there are these blank
spots in reality where whatever you think if you think there's a chair there then a chair becomes
so I know that that's an extreme example but what I mean is that if you imagine that your wife loves
you then you're going to act in a manner that makes her love you more and if you mistrust and so on
so on so they're self-fulfilling so it's as if there's these lacunas in the world that whatever
you think is there becomes there and I wanted to know what your free energy principle had to say
about self-fulfilling prophecies I imagine quite a lot but I'm not sure if we have enough time
do you have any quick notes on? Well I mean the way that you just articulated that is it's
spot on from the point of view of the free energy principle so we we often use the phrase action
is there to realise and fulfil the prophecies supplied by the brain you know it is literally a
way of of of creating your own sensorium in virtue of self-realising and you know self-fulfilling
prophecies you know I think the question is can you keep on doing that in the face of a particular
environment that may allow you to do that or may not and in particular if you do it lots of other
people who are also trying to pursue and self-fulfill their their their prophecies. Like what are the
limitations of it? Yeah yeah so you know I think that's absolutely right and it also speaks to
you know seeing stuff which is not there starts to talk brings us into the world
of false inference and delusions and hallucinations and the kinds of fulfilling self
sorry self-fulfilling prophecies of a perceptual sort that people with things like autism or
schizophrenia might be subject to so as you know you can go too far but on the other hand you know
there are many people who now consider perception basically as sort of hallucinations that are
entrained by sensory input that you know what we actually see is sort of you know a product of
the hypotheses about what best explains what's going on and there are occasions when we can get
those hypotheses wrong and that we have we're then subject to illusions for example in psychophysics
or hallucinations and indeed delusions you know if we've taken some psychedelic drugs or that we
have conditions such as say schizophrenia. So then is schizophrenia a pathology of free will?
I don't think so no no I think it's a pathology of that can be understood as a
false inference but I don't think that there's any aspect of that would enable you to sort of
isolate free will as the as the locus of that false inference. There's certainly a lot of
lot of work suggesting that people with schizophrenia when they are acutely psychotic
may have difficulties inferring who did that so assignment of agency so in the sense that
you know who willed that was it you or me there may be a slight confusion so I if I say something
to myself I may for actually you said it you put that thought into my head so you know that's just
you know a false attribution of agency and so in that sense perhaps you could say that that is a
form of disorganized free will but certainly the people with schizophrenia that I have treated
or worked with in the past you know I think they would have a sense of self and you know a sense
of free will which which would be indistinguishable from from yours and mine. You know I know that
we have to wrap up at some point soon and I wanted to bring this up I didn't know how
but I'll just tell you quickly the a few months ago maybe I'll even take this out of the actual
clip but a few months ago January February I was I woke up in the middle of the night and then I
had a conversation with my wife who was minor neutral wasn't positive or negative and then
as I was going back to sleep she either said yes or okay or she could have not said it but I was in
this hypnagogic almost sleep like state and I've never had a panic attack in my life but for some
reason I wasn't sure if she said okay or yes or whatever it was or if it was in my own head
and then I thought am I am I psychotic am I getting schizophrenia I don't know why it's not like
that was a background anxiety of mine before maybe it was maybe it's latent but then I started to have
a panic attack because I didn't want to hear anything and I felt like I may be able to will
myself to hear something by telling myself don't hear then I'm like well what would it sound like
if I were to hear then it's no no don't go down there because you may hear a voice and I don't
want to go I don't want to be crazy I don't want to be psychotic a couple days later I had another
panic attack almost based on the worry that I'm going to be psychotic rather than I am at all
and and I'm I've been afraid to search about schizophrenia because I don't want to read that
I have the symptoms of it and there's nothing else other than that I may have heard my wife say
okay or yes in a state where I was about to sleep and that she actually may have in fact said it
or not I talked to my doctor about this on the phone because it's COVID and she said oh Kurt well
you can hear many things you can hear music when you're about to sleep you can your foot can feel
like you're about to fall off and you so don't worry about that and I found that when I talk about
it I feel much more at ease but ever since then for three months Carl for three months at night
time I've had such a difficult time falling asleep because I'm afraid of my own mind I can't let
myself be alone with my own thoughts because I'm afraid of what I might find and it's created such
anxiety in me that I well I can't rely on any benzodiazepine to sleep because that can just
put you in a that'll create way worse problems so I have to find some way of sleeping without any
medication besides maybe melatonin that's difficult and I'm just not sure what to do with that
issue I brought this up on one of my podcasts because I feel like there are plenty of people
who may be experiencing what I'm experiencing but but people don't talk about it in turns out when
I did talk about it many people in the comment section said I can't believe you've been going
through this that's I've been going through something similar when I study about consciousness and so
on for this for these types of interviews I feel like I don't know what reality is anymore because
there's so many different theories and so that is destabilizing me on top of what I've already
been feeling and I'm unsure what to do about it and I just want to know what what advice do you have
I know that that's extremely personal question but what what do you recommend that I do or not do
well if ironically you've just done it so now I'm responding as in my role as a psychiatrist
not as the author of the free energy principle although much of the free energy principle was
actually inspired by exactly the questions that you're contending with you know how do I maintain a
sense of self which is the most important part of my narratives you explain explain me and
what can go wrong but when you have psychosis I think the first thing to say is that there
there have been an enormous number of people around the world during lockdown and during the
coronavirus crisis with reduced social contacts and changing points of reference so your old
narratives your old models are just not fit for purpose and in a sense you've got to be able to
grieve for the things what that you know the way that things were and it's quite frightening to
actually relearn how to live even for a few months you're in a new COVID world and certainly if there's
been you know sort of changes in social distancing or the way that you interact with people and I
should say also when and if you have to unlock that will also be very you know anxiety-provoking
as well because of the uncertainty you've got to relearn how to do it so lots of my colleagues have
had psychotic breaks and talking to you I think it's highly unlikely that you have any form of
psychosis or indeed an acute psychotic episode just by your composure your theory of mind and
a lot of our non-verbal cues however I do have many colleagues who've actually had an acute psychotic
episode in response to this I haven't but you know a lot of my close colleagues have
and it's perfectly natural they usually last about sort of you know sort of a few weeks to a month or
two may respond to medication if the person is becoming sufficiently agitated or they're wearing
the close family you know it needs containment pharmacologically that's certainly viable if
it gets that far usually it doesn't but the important thing to know is this is perfectly
normal you know even if you haven't had a psychotic episode if you had had it's you know lots of
people are going through this which brings me to the answer to your question you can certainly
talk to your GP and talk to healthcare professionals and mental healthcare professionals and
there will be the option of medication either to help with sleep or to if you actually did have a
psychotic break to take the edge off that and enable everybody to cope with your with the
consequences that's always an option should you want to go for it and you shouldn't feel ashamed
of doing that or in any way hesitant I have to say that the nature of these episodes is such that
it won't be the person who has the psychotic episode who knows that they need containment and
looking after of a particular kind it's usually the next of kin their children their parents or
their wife or their husband who has to take the initiative to bring in support and help to get
that done and that help is there the very fact you're worrying about it
can't be psychotic because you've got insight so just by worrying about it I'm afraid takes you
off that list but it doesn't mean to say the anxiety doesn't go away but it doesn't mean you're not
actually psychotic and the other thing which which really helps is just what you've already said
it's basically sharing in the group so you know the angst that these things generate and the work
you know whether it's a psychotic break or not or worrying about it or not everybody's going through
this and and being able to share that in a group is can be enormously therapeutic for everybody in
in the group it did you know so if you can set up by sharing a safe environment within which
to share these experiences and anxieties and by safe I mean very clearly bounded so it starts at
a particular time and it finishes exactly one hour later so you've got this boundary so that
anything that comes out in that context can't spill over and affect and can be put back in the box
but you know there's going to be a box next week or tomorrow very very carefully time you know who's
going to be there or you know what kind of people are going to be there so boundaries are very very
important when it comes to group therapy that that in my in my experience that's the most effective
kind of talking therapy in this situation how do you get a group together you have to say well this
is a a thing um how do you do that you just have to declare you have to come out say I'm upset by
this I can't get to sleep because of this this you know you know if I told myself these worries
a year ago I thought I was stupid but these are real worries they're stopping me thinking I can't
you know just saying that out loud means that other people now are aware that this is a thing
and it's something that can be talked about so when I said you've just done it by just going public
in this kind of interview is the first move the next move is then to find you know a network
or a structure that will support either therapist-led or self-help groups usually small enough that you
actually have the the intimacy of a small group dynamic you know so not more than 12 people you
usually about so eight people with or without a therapist you don't need the therapist but it's
useful you know if somebody is just to get used to the importance of boundaries and your and group
dynamics but it's not necessary this is you know the important thing is you're getting together
in a bounded way um to you know to to share and um and to just in a um a completely open and non
judgmental way um tell other people how what they are saying makes you feel um and and just use them
to reflect literally like a mirror you know so you come back to the shared narrative again
you can you can get a long way with that so that's what I would recommend that you you know
I mean somebody in your position may well feel that perhaps you should start
an initiative along these lines or actually start you you should take the initiative and actually
set up a discussion group or a self-help group but if not then certainly look around on the web
I'm sure you'll find um you know that somebody over the past few months will have started this
and be mindful that you should tell your wife if you do go psychotic you just got to get the
doctors in to to get you medicated because that'll go away in about three weeks once you you know if
you just take take the right kind of medication it's not a big thing you know I repeat it's happened
to several of my colleagues and friends um and you know they're back in the saddle now um and it's
been a useful experience sometimes people get um they get more creative they got slightly manic
I don't know sense that in you um but um I do notice that when I was having my high anxiety
periods right after the initial episode that I saw many more connections almost like I imagine
when you're on lsd or psychedelic that everything is imbued with meaning that every other sentence
someone would say in in a movie I'm like oh that's so deep that it makes me want to cry almost now
that's not there I still do see connections but I tend to have always seen connections to some degree
anyway yeah so I mean that you know these episodes um will either just reveal innate sort of you know
ways of thinking and seeing and making sense of the world in a particular pro-social context
um but but certainly you know what I was going to say is that there can be some um if you keep a
record of these if you can if you just see associations and links and just keep a documentary
record of it it may actually be something quite useful either to go back to as a you know an essay
in the way that you saw the world in that particular state of that particular type
but sometimes you actually get some quite profound insights you know uh again a number of my
colleagues actually do suffer from manic depressive psychosis uh and of course if you look at the
history of your creative people in both you know the arts and the sciences you know you're on this
edge of chaos this is the instability that is associated with um with psychosis um so it's
not an unproductive um time um you know if you are if you did get close to the edge then
then make sure you keep a very um if you can keep a very clear document document what happened to
and everything you can this would be nice for you to go back to next year yeah I definitely
take notes on all my thoughts I've done so for years anyway I'm always constantly saying I can't
say now because it'll turn on but okay and then the name of my device and then I say make notes and
so on so on yeah okay well thank you so much doc I want to say doctor thank you so much professor
you are a doctor obviously professor thank you so much Carl there was a statement that you said
before many times actually it's that you are your own existence proof can you explain what that is
what that means it is one of those deflationary um summaries of the free energy principle that says
the very fact you exist tells you a lot about the mechanics and the things that you must do
or the properties that you must possess in order to exist um so you turn that on its head and the
fact that you exist is proof of your own existence again in this tautological sense um you could
also read it as one way of um encapsulating the notion of self-evidencing so if you read
self-organization as a system trying to minimize its free energy or maximize the
evidence for its models of the world then what you can say is that these kinds of systems
change in such a way to increase the evidence for their own existence um so it comes to
very close to the notion of this self-fulfilling prophecy that you know I expect it to exist
and I'm going to act on the world in a way that solicits or secures evidence for that
existence and if I have a good model of that world then I will be successful in soliciting that
evidence and in so doing I will persevere and I will simply exist and I look as if I'm self-evidencing
and of course evidence for what well evidence to prove that I exist so it's it's a rather sort of
cheeky way of celebrating the the tautology of existence in the in the sense that just
existing is really all you need to know and you can spin off everything else all the attributes of
artifacts particles people plants that exist just from their very existence what happens if you
start looking for evidence that you don't exist like let's say you're on the eastern end of the
philosophical spectrum and you say that the eye is illusory that maybe this is all a dream whatever
that may be what happens is that is there a system that can do that where you look for
evidence of your non-existence can you think yourself into non-existence I know that likely
not but please run with that idea oh well it's a wonderful question I mean yes I think you could
certainly um think yourself into non-existence I mean just you know a trivial thought experiment
would be somebody who's a very committed meditator who forgets to drink or eat
and dies through dehydration so no it is certainly possible it's a wonderful question
because it speaks to something in philosophy called the dark room problem so it is certainly
possible to simulate in silico in computers and agents that deliberately do not believe
that they exist and will avoid sampling data that would otherwise
provide evidence for their existence and what that translates into is essentially
an artifact or a creature that turns off the lights it deliberately avoids any
information from the world and sequesters itself from the world but in so doing of course
there are profound implications for its homeostasis and you know from a sensory point of view
hides away in dark corners and is now subject to the dark room problem
but at the same time it will not be able to maintain its mark of blanket and ultimately
will dissipate so if it doesn't comply with the existential principles that maintain
its structure and form and its organization technically if it doesn't comply with the
principles that underwrite the maintenance of mark of blanket then that mark of blanket will
cease to exist and so will you if you are that mark of blanket so you know it's practically a very
very interesting question because it all rests upon having a good generative model of the world
so you know there's a sort of dual dependency here that you know it looks as if creatures or
systems more generally that exist are seeking out evidence for their internal model of how the
world works and how the world generates its sensory samples and that's only an apt explanation
for self-organization if the generative model is a fair or a good enough explanation for the way
that those sensory samples are generated technically that's an idea which dates back to the inception
of cybernetics in the early half of the 20th century known as a good regulator theorem that in
order to regulate to control to survive in your environment you have to be effectively a model
of that environment so you're whether you're a thermostat or or a person you know your structure
and the way that you exchange with the environment under a model of that environment only works when
you are a good model of that environment when you say generative model what's the difference between
a generative model and just a model um well generally model is just a technical term it
you're strictly speaking it's just a specification of the probabilistic relationship between causes
and consequences so you literally you write down a probability density or a probability distribution
over causes and consequences and that allows you then to evaluate the evidence in some data
for that model so in this instance the causes are unobservable sometimes referred to as latent or
hidden states say of a world and the consequences are observable consequences say sensory samples
that we solicit with our sensory epithelia our eyes our ears or indeed our our our interception
so the generative model read like that is just a probabilistic specification of how
hidden or latent states hidden behind say I mark off blanket generate observable consequences
and if you've got that model then you can assess how likely those sensory samples as
sensations as sensory impressions were under your model and if they were very likely you're not
going to be surprised you know low free energy and you know that you've got a good model of the
world if you're constantly surprised unable to predict then you've got a bad model of the world
and remember that surprise can also be as prediction error so if you constantly subject
yourself actively to lots of prediction errors you're going to be constantly surprised in the
state of high free energy but think about what that means these are not just prediction errors
in fact they are not prediction errors of a sort of personal sort of you know a propositional thing
I could I could say oh I didn't expect that these are sort of fundamental deviations from your
expectations like your bodily temperature the amount of blood sugar that you your your circulation
is currently supplying so when these get out of physiological bounds you start to literally
disintegrate and die and your mark of blanket dissolves so it's important to keep these prediction
errors within bounds or in the language of the free energy principle to you know to keep on top
of your surprise self-information or free energy all words for essentially the same thing
okay what do you make of Donald Hoffman's ideas on consciousness another's broad
yeah I had a mentor once called Jerry Adelman there's a Nobel laureate
famed for understanding the evolutionary basis of our immune systems he used to call me an
intellectual thug because I didn't know anything outside my own sphere so if you tell me what
Donald Hoffman yeah so forget about that forget about because in order for me to say that it would
take too much time and I'm and I probably wouldn't do its service okay how about orchestrated objective
reduction from penrose roger penrose stort hammer off if you've heard of them yes yes yes certainly
so you know I certainly read roger penrose is emperor's new mind yes the emperor's new mind
so so what what what what sorry can you repeat what yeah what do you think what do you think
about it does it comport with your theory does it contradict it do you think it's
too unfalsifiable do you like it do you think it's creative like what are your broad thoughts about
it um I think it's entertaining um so I'm going to lump that in with um quantum theories of consciousness
or you know um which is entertaining um I don't see it as a serious contender that offers any
expiry power in terms of symptom behavior I should say of course that the you know my work
with the free energy principle and things like active infants these are not theories of consciousness
they can certainly be deployed to set some parameters on quite questions that arise in
consciousness research but in and of themselves that they're not theories or principles that
would underwrite consciousness um having said that you know they do tell you where the mechanics of
the basing mechanics the physics of sentience lie in the physical world and it is not at the
quantum level um so you know from the perspective of a theory of every space thing um the you know
there are there is a range um you can formalize mathematically under things like the renormalization
group of things you can have very very small things that have very large amplitude random
fluctuations very very fast things you can have very very big things very slow things very cool
things that where the you know the randomness averages away so you know one can envisage this
as a spectrum between quantum mechanics um at the very fast small end and classical mechanics at the
very very slow large end of the sort that would describe the you know the orbits of heavenly bodies
which means that you um you you ask well where do where do we fit and we being
um biotic systems that show a particular kind of self-organization that we would associate with
with life and and it's in that it's in that intermediate zone where both the um the you
know the random fluctuations and um what underwrites classical mechanics which is this
solenoidals um circular motion that doesn't actually change the surprise or or the marginal
likelihood that's where we live so we know it's not at the quantum level so we know that sentient
behavior and by implication sentience um cannot be found at the quantum level in the same sense
it cannot be found in the motion of the heavenly bodies simply because they're too cool they don't
have the right kind of itinrancy they're right um if you like an adaptation the challenges
the existential challenges that might um destroy their mark of blankets are simply not in play
and at the quantum level um um the uh that there is effectively no interesting itinrancy that is
that defines non-equilibrium steady state so if I was responding I know I'm not but if I was responding
to um a physicist asking asking that question what you what I would be saying would be that
if we consider life to be um self-organization to some form of non-equilibrium far from equilibrium
non non-organization then stipulatively I am saying that we have to account for this non-dissipative
these non-dissipative dynamics that are mathematically the solenoidal part if they are
dwarfed by random fluctuations that you find in quantum physics then the we're not talking about
any more um non-equilibrium we're talking about equilibria we're talking about solutions in the
scrolling wave equation so you know in conclusion you know quantum neurobiology is entertaining
it's interesting um but it's just not the right place to um to you create a mechanics of um of
sentient behavior and by that you know I would guess that that precludes it from being an apt
description of conscious artifacts. Is one to understand the free energy principle as giving
any indication as to what consciousness is so for example the self-evidencing is that consciousness
or is it when it's minimizing the free energy or is it the fact that it has a Markov blanket because
when I was looking at the nodes any point you can define a Markov blanket to so it doesn't
seem like the fact that there exists a Markov blanket means it's conscious so what are the
conclusions one is to take from reading your free energy principle that someone can draw for
consciousness? Yeah um yeah I I mean this is again an excellent question because it's one being
posed around the world as we speak you know so people like the John Templeton Foundation are
sort of earnestly looking at ways to sort of put out for example the free energy principle
against integrated information theory as formalisms that might speak to um speak to consciousness
research so it's a it's a great question um the the normal answer from people in my world
would start off by saying that consciousness is probably a vague notion and I mean vague in a
philosophical sense that you know at what point does a collection of sand grains become a pile
of sand so it admits the possibility that a thing may not be conscious yes it certainly would
by definition have to have a Markov blanket you know in our formalism but it that does not mean
it is conscious it will be self-evidencing in the sense of having gradient flows that
try to minimize the self-information but that's as far as it goes so then you ask yourself well
what kind of systems first of all look as if they are living and then as we move through this vague
landscape or vague dimension towards very sophisticated you know particles like like
yourself and myself um what would take us from living to um systems that had you know a minimal
selfhood and then even further what would take us to systems like philosophers that sort of puzzle
over the fact that they have minimal selfhood and I think the answer lies really in the genetic
model so if you remember um we were talking about a genetic model as being a probabilistic
specification of causes and consequences that underwrites the free energy or specifically the
free energy gradients that provide an explanation for our dynamics so it all boils down to the
genetic model so first of all what would it mean to be alive um and you know we have discussed this
in terms of just moving to you know to have an itinerancy to actually act upon the world
so you need to see a particle moving around and it would look as if it was moving around
in the service of sampling evidence for its own existence and maintaining itself in you know in
this in these characteristic ranges and showing us a generalized homeostasis you know the other
sort you might expect a worm or a single cell system some kinds of behavior a single cell system
might show is that does that have any sense of self or any sense of consciousness probably not
um so you then take it up to say insects and your and small mammals and at some point in this
vague continuum um you you come across the next milestone or marker on the way which is the kind
of genetic model that would um explain the consequences of action so put it very very simply
though there are some creatures that um or systems at least that will respond reflexively like say
microbes and indeed thermostats that will respond in a way that seems to keep themselves within a
particular range but crucially they don't plan so what would it mean in terms of planning in a
deliberative way basically selecting among a number of ways forward a number of courses of action
that will lead you to um reduce uncertainty minimize your free energy or minimize your
expected surprise as a consequence of that action well you would require a genetic model
of what would happen if i did that now because um what would happen is in the future that's a very
sophisticated genetic model so now you're actually equipping this genetic model with a temporal depth
it can reach into the future and if a creature or a system is endowed with a deep genetic model
that encompasses the consequences of action it's now in a position to choose those actions
that it things will either resolve uncertainty or supply the most evidence for its own existence or
put more simply um evince the characteristic sensory states that define it define what it is
so then we're moving on now to creatures that plan and if creatures that plan now have an extra
bit to their genetic models which recognize that they are planning that have this hypothesis that
hang on it may be the simplest explanation for all these multimodal um sensations is that I am a thing
and that I it is me that is prosecuting these reflexes or moving or it is me that is looking
over there and now you've got a very sophisticated genetic model where you can certainly
imagine that there is a minimal representation of self like self-modeling
so now we're moving closer to the notion of conscious artifacts would they be fully conscious
would they would they have qualitative experiences would they have qualia and then the next
what would license a qualitative experience you know you know what it would be like to see
red or any other attribute of the sensorium that usually the argument then is well that's
that would require the kind of genetic model that was able to essentially infer on its own
inference that would be able to enact a kind of mental or covert action in order to select in
the model itself in the message passing in the brain for example be able to select certain
sources of information in the service of this hierarchical self-evidence and well
from the hierarchy like layers of an onion and the deeper you get into the onion the higher
you are in this hierarchy you know recurrent message passing between each of the layers
but if the if the deeper the core of the onion was now able to act upon the intermediate
layers or levels of this hierarchical construct then you might now suppose that this is a kind
of mental action the licenses you to say now this is an agent it's an agent that plans
because it's acting psychologically this would be effectively attention so if you can plan what
to attend to or generate attentional selection of the the way that you go and secure evidence from
your world then you might now start to develop a theory of what it is like to actively perceive
something you know I could go on at length and probably not very usefully in terms of how you
might cast that in terms of phenomenal transparency and opacity in brief what we're saying is that
there are certain generative models there are certain creatures that can render their
perceps experienced by rendering them opaque by acting upon them by having this capacity
of attentional selection so now you've got to some very sophisticated generative model
that not only has temporal depth that enables the agent to plan it's also truly an agent that
may be self-aware or at least aware of what it is it is perceiving because it can now act upon
the the the perception the perceptual inference that's implicit in this self-evidencing
but we still haven't got to self-awareness yeah so these things might be apt to describe
say mice but we don't know whether mice are self-aware they could you know probably they can
attend to this or that and then you're under this if you like spectrum of vague and vague levels of
different kinds of consciousness you know they could be said to be conscious in the sense that
they are sentient and have qualitative experiences but are they self-aware and if you want to be
self-aware you've now got to by definition have part of your generative model literally part of
your brain that stands in and represents selfhood so just and then we come back to this notion that
highest forms of life on earth would probably have realized and learned and infer that they are
entities they are agents and that becomes me and it's me that's doing this overt action and this
covert action this attentional selection and the final step would be to go from this highest
form of life to become a philosopher when you start to have mental models of how it is that some
people are self-aware and so an ad infinitum in terms of the number is there an ad infinitum what's
the next step that after philosophers yeah as soon as I said that I realized I was stupid and you'd
stop me yet now it's not okay I think I think I think probably we've probably got as far as we can
in terms of levels of recursion and I say that because there's a lovely
notion which I'm sure you're aware of this is a notion of the meta hard problem and
no I never heard of that I should know you'll love this I think it's something that was introduced
just in a presentation I taught by Andy Clark in about 2001 and then seriously taken up by David
Chalmers you know about two to three years ago in 2018 so this this is not the hard problem of
finding an explanation for sentience you know what is it like to perceive red
it's more why do we find why do we find ourselves puzzling over it why do we think it's such an
interesting yeah so this is not the hard problem but what sits next to the hard problem which is
why is it that we find it so perplexing and difficult to explain why is the hard problem a
problem for us and you know that that's you know to my mind it's an extra level that you were
talking about sort of you know now now we're asking we're trying to explain the emergence of
philosophers so we're up to the next level and it's a very interesting and it tells you
immediately a number of a number of very interesting things that you know if I am puzzled about the
fact that I am seeing red or that I can see red that tells you immediately that your generative
model has to have a model of a counterfactual where I can see red but not experience it now
that's quite remarkable you know to actually have that kind of generative model where you can imagine
yourself you know in a structured in a very very different way so I use the word counterfactual
there you know so deliberately because you know it may be just because we are systems artifacts
sentient artifacts that have these very very deep generative models that entertain counterfactuals
anneal seth causes counterfactual depth now allow us I spoke to anneal seth for this program he's a
great guy well I hope he mentioned counterfactual depth and if he doesn't you'll have to get him
back and yeah yeah no I don't think he did or maybe I slipped up and don't remember okay so
continue sorry yeah so the you know this notion of counterfactual depth you know I think is very
important I mean it's absolutely quizz it for planning in the sense that you know planning is
just choosing the right course of action which means you've got a series of options all of which
have these counterfactual outcomes but of course if you've given that model you're given that kind
of model you're now in a position to hypothesize counterfactuals that could never occur such as
seeing red without seeing red such as you know seeing but looking but not seeing for example
such as the you know the thought experiments that philosophers like like you know philosophical
zombies you know the very fact that there is this meme of a philosophical zombie tells you
immediately that we are in discourse with creatures namely philosophers that have the capacity to
represent in their janitor models impossible scenarios and counterfactuals of the kind that
you would have to bring to the table to you know to conceive of a of a philosophical zombie so just
perhaps even more simply the fact that people can do these kinds of thought experiments tells
you a lot about the kinds of janitor models they used to explain their world and that that is possibly
a sufficient explanation for the meta-hard problem just because we can uh-huh okay i'm going to need
to think about that there's this lady named Annika Harris who's Sam Harris's wife and she has a book
on consciousness i believe it's just called consciousness and no offense to Annika Harris
but the book was the books the best part of the book to me was when she was talking about
philosophical zombies that is for the people who aren't listening how can there be robots that look
like us that aren't conscious and it produces an equivalent world and she said she said something
so interesting which is that the fact that we're talking about consciousness implies that we're
conscious is because in an equivalent zombie-like world it's hard to imagine why they would come
up with that question so that's what separates us from them yeah uh that that sounds exactly
that that sounds exactly like how Andy Clark would phrase it you know the big thing is why we
so puzzled about consciousness and sentience so that sounds very very close to to you know the core
question that underwrites the the meta-hard problem or the meta problem yeah Anna Lukomsky asks she
says that's lovely to hear when i told her that i was speaking to you she's fantastic news about
Carl Friston i'm curious to know if he's an idealist or a physicalist now i'm biased towards idealism
i'm speaking in terms of her she's a psychiatrist by the way or a psychologist and she says well
first of all are you an idealist or a physicalist um i'm very happy to vote for both sides depending
on who who i'm talking to okay so you're uncommitted right now um no i mean i'm happy to commit to
either so your i see this through the lens of the people i know in philosophy so on the one hand
my friend Andy Clark um would would be um um somebody who believes you know certainly would not
adopt a you know a radical idealist whereas Jacob Hoey you know would celebrate the mark
off blanket that separates you from the external world and therefore the external world can never
be known um it's only ever accessed vicariously via the mark off blanket and and he might he might then
take a more skeptical position um you know i think that the maths of the free energy principle
really forces you to to um um uh to back for both sides on the one hand it is absolutely true
that are um making sense of the world through the the sensory veil supplied by the mark off
blanket uh precludes any um anything out there that will be ever known um that is certainly true
so it's only consistent with brain and of that like thought experiments there there will be no way
that you could verify or not what's actually going on out there everything is this sort of delusion
or hallucination that is entrained and grounded by sensory evidence but you know you never know
the causes of that sensory evidence that's the whole premise of inference you know active inference
encapsulating or the um encapsulating the take on self-organization as a process of inference
so that's that that would be sort of you know the you know one side of the fence
the problem is when you um if you commit to that it's very difficult to actually simulate
um or engineer sentience because in order to do that you've actually got to generate the sensations
the sensory states of the mark off blanket on uh that the that the agent can infer and of course
when i talk about or refer to the good regulator theorem um i'm implicitly assuming that there
is a world out there to be regulated i'm assuming that you know the quality of a generative model
as measured by its free energy um is in relation to what is being modeled so i have to commit
to some realism uh in the sense that i'm saying there is a model so it's very difficult for me
to answer that because on the one hand um it's if it's a model of something then the something must
be real on the other hand it's always the other process of inference under a particular model
means i'll never know whether there's anything real or not so you know it it sort of accommodates
both points of view and it resolves neither i guess so that's the reason the psychological
reason you're saying sorry that there's not a psychological reason that you're saying you're
both a physicalist and a realist or neither it's it's not because you don't want to offend anyone
it's actually because your your model accounts for both well one is like ontological the other
is epistemic so one is like we can't have knowledge of it but the other one but at the same time
you're assuming that there exists a world that's independent yes i've got some beautiful way of
putting it but but also i also don't want to offend anybody as well but yes you're a lovely
chap you want to keep your charming nature okay so this person named Matthew Nahemi says does
referring to you does Karl Friston know Alfred Korzybski and what does he think about his theories
that doesn't evoke about but you're going to have to tell me forget it because i actually
don't know this person and i have been told that i need to learn more about this person
dr. JT Velikovsky of the University of Newcastle from australia who has published some work on
Holon-Parton theory structure of the meme some memes like Richard Dawkins memes he asks
do you expect like David Bohm suggested that the scale size of entities in the universe
e.g matter energy go infinitely smaller e.g smaller beyond quarks and also infinitely
larger e.g to multiple universes um yes i mean i think that would be that would be sort of
mathematical take um on um the application if we wanted to do that of of the the apparatus of
the renormalization group when trying to understand um the separation of temporal scales between
different levels of organization which is an important part of the free energy formalism when
it comes to thinking about um Markov blankets and Markov blankets say you know organs that comprise
cells where each cell comprises organelles that themselves comprise molecules that themselves
comprise out and so on and so forth and then the other way organs constituting phenotypes
phenotypes constituting populations of constituents constituting in groups and out groups constituting
species and and so on right up to um sort of a cosmological uh scale so you know i think
mathematically um that that's a very comfortable position to adopt um so that the other there is
no lower upper bound on the application of the renormalization or the apparatus of the
renormalization group when you move from one scale to the next um which you can do very gracefully
when it comes to um certainly modeling for example um you applying the free energy principle
to single cells in a network of neurons and then coarse graining that to try to model um
you know parts of the brain as um self-evidencing through you know physical motion through to
coarse graining that and then trying to model um populations talking to each other or interacting
through them are the Markov blankets that defines an organization or a family or a set of
conspecifics um defines it in relation to say the the the environment or the ekanish so these are
just examples of um lifting exactly the same dynamics the gradient flows that underwrite the
free energy principle from one scale to the next and in so doing working out what the states are
what the you know when you say the states of affairs or the or the sensory states or the
internal states yeah what are they and um when you sort of drill down on that what you can do is
use the um the renormalization group formalism um to in moving from one scale to the next you
basically take um mixtures of blanket states uh and then those mixtures of blanket states
technically the eigenfunctions of the blanket states now become the states of the next level
and then you look at the conditional dependencies of the states the next level
then you find the Markov blanket and you take the eigenfunctions of those states
and then they become states of the next level at each level of coarse graining
you get bigger and slower so before we were talking about sort of this um from quantum to classical
that inherits simply from this um the successive coarse graining but at each point exactly the same
free energy um um for like Lagrangian you know the way that you would write down the dynamics
and you know on one reading the energetics the functional forms are exactly preserved
you're just swapping out sort of um you know microscopic states um for mixtures of microscopic
states in particular repeat the eigenfunctions or mixtures of blanket states to get to the next level
noting that the blank you're throwing away the internal states remember the internal states
are independent of the external states given the Markov blanket and vice versa which means
there's nothing in the internal states or any particular particle that is not if you like
encoded in the blanket states if you wanted to move to the next level so at each level
you're throwing away the internal states um that can have very fast dynamics and you're picking out
the slower fluctuations of them on the Markov blanket on the blanket states themselves so the
states at the next level up now fluctuate much much more slowly and they encompass
they have a larger spatial scale as well so um you know once one has that um that that that sort of
recursive um you know not proof by induction but the same spirit as a proof by induction where you
move from from one level to the next level uh that um once I have one has that apparatus in play
there is no need to ask when does when does the process stop or where did it begin
and in the sense you dissolve those questions because you're only interested
in one particular scale and how it relates to the scale above and the scale below
I mean you can go um if you're like um astronomy uh or you know um you're interested in the physics
of the cosmos then you know you'll be going and say six scales uh you know towards towards
classical mechanics if you're interested in string theory and uh small particle accelerators
then you'll be going to say six scales down to very very small things you know towards the quantum
level um but we is six just a number for an example or are you specifying something in
particular um well yeah it is a number I pulled out of the hat but but it's probably about that
when one looks at um when one looks at the time constants um empirically associated with any
particular scale or any set of Markov blanks at different scales and then one goes to the next
scale using you know this is not this is not magic you know it has been applied for example to
brain imaging time series where you you look at every um um little cubic um patch of the
brains you know a few millimeters in size um then you say well that's the scale I'm going to start
with and I'll take the eigen modes or the eigen functions um um literally as the activity of
each of this little chunk of brain and then I've got say thousands of states and then I look at the
dependencies and I work at a Markov blanket and it could be a Markov blanket around the little
chunk of brain the size of your thumbnail um and then you can take the eigen functions of the Markov
blanket of that little chunk of brain um and then you put the chunks together and you find the Markov
blanket at that level and then you talk about lobes of the brain um and then you talk about the
entire brain and then you think about well lots of brains together at a scientific conference
there's so many whatever almost every four sentences that you speak three ideas occurred to me and I
just want to explore them all so here's an example we're not going to explore them I'll just say them
when you mention that the internal states are independent of the external vice versa that
means there's almost an arbitrariness as to which one you call internal and which means that you can
at least I'm surmising I'm gonna I'm pretty much asking but either way then that means that you can
imagine the environment models you in a sense and then I wonder well what's the connection between
that and the holographic principle in string theory which says that as the boundary it encodes
the information anyway okay that's just what occurs to me and also multiple dissociative
personality disorder I also want to know about that but it's not about me Joanna dong has a
question she says my question to Carl Friston how do you explain the meaning of life using the
free energy principle that's an easy question you can answer that in like 10 seconds
um well I've never been asked that before the meaning of life uh so no I'm just going to use
my favorite words uh tautology and deflation um you know the meaning is in the existence um the
shape of that existence defines the goals for the existential imperatives to keep yourself
in the in those existential domains so it's just in the existence it's just the shape of things
that exist that define their own meaning and you know in a sense you could look at self-evidencing
as finding meaning uh for your life or your finding finding um or understanding the um
the model for which you're trying to accrue evidence um and what that basically means is
if you're reading that as a as a psychiatrist or a philosopher you're basically trying to
understand yourself and your own generative models so if you understand your own purpose
for your purpose is just to aspire to this these attracting sets um that define you as the kind
of thing you are and then the meaning would I think rest upon this some kind of self model
where now you recognize you're you're this kind of person so you you can spin it off as a number
of different levels so it wasn't a very I'll think of a more succinct tax at your question
psychologically an attracting set would be what mathematically that's fine but
for someone who is just interested in how one lives their life is this just a recapitulation
of know thyself yeah so the things the things that the things that um you are attracted to
literally um the things that you see yourself being attracted to the things that you see yourself
aspiring and working towards um um so what you find interesting and admirable is that what you
mean yeah yeah that that was that at a very high level but remember you know this operates at all
scales of a deep generative model where remember the the the core is dealing with with sort of
more abstract things such as you know being likable being loved being rich but at the periphery
you know there are still um there's a model of basically body temperature body pose um
not being in pain so these are also things that make me happy in a sense yeah these are
these are attracting states it's attractive to be at a particular temperature so attractive not
to sense pain it's attractive um you know to be hydrated to a particular extent uh at some level
the model is also attractive you know if you have very deep generative models um that have this
counterfactual depth then there are certain counterfactual outcomes that you would find
very surprising will be unattractive and there'll be other outcomes which you would have learned
this is the kind of outcome that I aspire to this is the kind of generative model I am you know at
that point that I think it would be quite fair um to start thinking about this in terms of you know
I'm going to devote this reputation you know if I if I say this or if I donate this or I'm going to
I'm going to be this kind of person if I take these actions so there are certainly entailed
in the prior beliefs that constitute the generative model ways of behaving ways of being
outcomes that you a priori expect to happen and generally these are going to be things
that are consistent with your self image with the with your self model and interestingly also
require um an optimism bias so sort of you know because of this self-fulfilling prophecy of all
our actions and decisions and choices and behavior if they're all in the surface and realizing
our fantasy about the kind of thing that we are then we're always behaving and selecting
those information and ignoring other kinds of information in order to find evidence indeed
this is the kind of thing I am so I'm going to ignore any evidence that runs counter to my self
image you know that I'm not liked or not believed or that I'm very poor or very hungry unless I
can do something about it um so um so you know that's a I think it's a really interesting question
because it it it speaks to the both the self-fulfilling prophecy but and this sort of
optimism optimistic aspect of active inference which is not a fallacy it is it is absolutely
essential in keeping us on track and keeping us within these attractive attracting or attractive
states so if you're doing if you're a behavioral psychologist this would just be
some kind of reward if you're a control engineer it would be some kind of negative loss function
so you just score being in a given state in terms of the probability that you would find
me in that state and if it is unattractive and the kind of thing I would avoid that simply
is a statement that has a very low probability that means that the negative logarithm is very
very high it just means it's surprising so it's just another way of saying that the attracting
set of states or the attractive states are those that I am not surprised to be in that they are
comfortable they're familiar given I am who I am this is exactly the kind of state that I think
I should close and be occupied again almost all that you say there's so many thoughts that occur
I'll say some of them now not for you to explore but maybe for people in the comment section to
explore I was thinking when you were talking about different goals that one has and there's
different levels of abstraction so one is to regulate your body temperature at an extremely
low level than at a high level one might be to be a lovable person or to love someone else
then I was wondering well though you can go much much lower to parts that you don't have control
over so it's it's you want to have transcriptase in your cells so that you can have a replication
of DNA but you also want to have cell walls it's not like you can control that but that's at the
extremely low level and then at a high level what I'm wondering is is there a relationship between
the highest ideal and then God and then is there a relationship to being fragmented there and having
what's not monotheistic so that is polytheistic and then if you have what's polytheistic and
there's a contradiction between them is that one of the reasons why in monotheism they say you cannot
serve two gods and is that related to people who are well all of us are in some degree psychologically
not fully integrated but is there a relationship between monotheism and being fully integrated
as a person where you have one goal that you're working toward and they're not contradicted at
some higher step so you're living in a in a more congruent fashion you don't have to comment on that
you could probably say that's all foolishness but do I can't resist because when you say I have
lots of thoughts as well so that that that sort of can we act in order to make sure that our
messenger RNA is working properly um yes you can actually but maybe you'd have to use this sort of
sort of scale different scales of Markov blankets but also there's there there is actually
a formalism that allows you to look at the way that say the central nervous system
through neurodegrology and through sort of your neuroimmunological mechanisms does actually
have an effect on gene expression and this speaks to the sort of the you know the the
transactions both between Markov blankets but also if a Markov blanket at one scale
exists that necessarily implies existence at another scale so a cell can only exist at the
organ exists but in the same spirit and in in reverse the organ only exists in virtue of the
cells existing and all of this has to maintain a free energy minimizing dynamic in order to keep
both scales in play at the same time so you know it's a really I think that's a really interesting
example the god versus um or monotheistic versus monotheistic monotheistic models of the world
I think that that's that's you know a lovely description of um sort of you know sources of
cognitive dissonance but possibly of a theological or existential um sort of my underwrite or not
ontological security that you know if if I do have these counterfactuals about different things
the kind of person that I am or the the the data is that that I commit or subscribe to
and then that's just another example of the opportunity to resolve uncertainty but in that
sense there's also uncertainty there there's this puzzlement that underwrites the the metahar problem
that is it this kind of god or that kind of god is it the holy father or you know the holy son
um and by introducing that uncertainty you do you may well um express yourself to culture
dissonance and ambiguity and existential angst at that level which you will actively try to resolve
so that's this again this imperative to self-evidencing is acting in a way to minimize expected surprise
or uncertainty in the future so it may well be that certain um um clerics um certain sorry what
clerics uh clerics clerics yes or people people people you know with uh an ecclesiastical
leaning they may spend a lot of time trying to resolve that that kind of uncertainty that kind
of culture dissonance you know okay two quick questions that's it for us says in the context
of embodied cognition and by the way for us is someone who graduated from u of t right around
here in neuroscience and I forgot the other one so he's going to comment in the comment section
about what I forgot in the context of embodied cognition what is the relationship between perception
and mathematics and furthermore if the external world perceives our actions can we extrapolate
from that assertion the idea that our actions matter to the world as well
so that um that question you sort of hinted at before when you were when you were um the duality
between internal external exactly yeah that that that sort of um perfect symmetry um which I thought
was you know that that that was insightful and I think um that insight sort of speaks to the second
half of this question here um so you know it it is certainly the case that when you
simulate um agents conspecifics in a particular environment or eco niche um and you just integrate
these simu simulation or physics engines um using um the free energy principle you get the
the kind of um learning that um you would normally expect to see in the agents about the
environment but it that that is exactly mirrored by the environment learning about the denizens
that you know it plays host too so I'm sure you know this but you know um my favorite example
from colleagues who really you know some push these arguments as far as they they can go at
the present time my favorite um their favorite and my favorite example is a notion of a a desire
path or an elephant path which is the the phenomenon that say I'm going to get my coffee from the
cafe on the other side of a green or a park and I can either walk around on the pavement or I can
take a shortcut across the grass and if I so do um I will eventually me and all my conspecifics will
eventually wear a um a you know a dusty trail uh of grassless signs and queues uh from uh this
you know my office directly to the cafe so from the point of view of the environment this is basically
could the environment learning about the behavior of the kinds of agents that you know um that occupies
that um that um that environment so the environment is learning about the behavior
by being eroded by being changed so it's literally it is remembering in its structure
and its sub-personal structure it is learning about the uh the conspecifics that are good for
occupying that environment in fact even the conspecifics that are occupying that environment
what are the conspecifics oh a conspecific um you and I are conspecifics because we're from the same
species so it's sorry it's just a way of describing a an ensemble of or a collection of phenotypes
agents that have the you know come from the same species um and that the environment can learn
this is the kind of phenotype that operates well in my environment whilst at the same time
the phenotypes are trying to change to operate better in this environment so there's there's a
there's a you know a circular causality you know while while the while the the um the phenotypes
or the conspecifics are trying to adapt to the environment the environment is also adapting
to those conspecifics so it's a dance um that in fact can get quite high order in the sense now
that the that you and I will now see the path and realise oh that must this path needs to to
somewhere that it must be nice for things like me to go so I can just infer seeing a desire path
that it will lead to something I desire because I know that everybody else who has used that
are conspecifics they like the same kinds of things they have the same attracting sets
so now you know the environment has learned about the the phenotypes and has memorised
it in its structure and now the phenotypes are now using that to infer the kinds of things that I
should do so now you get like who's using the environment to to cooperate and to signal and
to change and to provide information for other things other creatures like me and you can take
that right through to the emergence of roads of traffic lights of language so you move these
arguments okay that's interesting I didn't think about that cultural domain and now you know so
language is that part of the environment or is it part of popper's third world or is it you know
is it part of your brain I don't think you tie it down like that because of this circular causality
that you you hinted at in fact more than hinted at when you're when you recognise that a Markov blanket
you know it's quite arbitrary what is internal external this depends upon which point of view
you're taking so I think it's a really interesting question which you can take in many many different
directions you know I I'm personally not not taking it in those directions because because I got
distracted by other things but I have lots of young colleagues around the world who are really
trying to try to understand this and relationship to evolutionary psychology evo divo the relationship
to niche construction the relationship to what Andy Clark would have promoted which is the the
designed environment so one of the one of the sort of you know key parts of the triple you know the
four E's you know so yes it is embodied but there's also you know an extension it's situated
so the environment not just the physical environment outside my body but my body as
environment as well starts to become you know an important part of this reciprocal loop and this
sort of joint free energy minimizing mechanics that rests upon a reciprocal exchange between
you know one side of a Markov blanket and the other side of the Markov blanket I'll just close with
with with the first part of the question which is does that mean the environment perceives
I would say possibly not it certainly would be the case mathematically speaking that the
environment is learning but we generally reserve the notion of perception to refer to to perceptual
inference or inference about states of the world as opposed to the parameters of a genetic model
which are more attributes of contingencies laws and the like so that we infer that the world is
in this state or that state at this point in time but we learn the contingencies and the lawful
mappings and likelihoods and the transition probabilities that underwrite the changes and
transitions in the state that you know the flux of states in the world so it's probably the case
that the environment the physical environment not the body environment but so you know things
like roads and paths and buildings trees they they learn that they probably don't infer and
perceive in the sense of having qualitative experience of qualia but they do learn you know
they may update their parameters in a way to model what's on the other side of their Markov
which is you and me thank you sir you've given you've been far too generous with your time
and I appreciate it immensely I think this conversation will be fruitful for quite a
few people especially more on the philosophical end there's not many most of the interviews with
you are more technical so I'm glad that we got a bit philosophical even though I love
some of the technical questions I have maybe 30 more that I didn't get to but we'll save that for
the next time well as last time it's been a real pleasure talking to you thank you I look forward
to our next our next exchange thank you man appreciate it honestly I do thank you so and
you've helped me psychologically as well because well just you telling me that other people are
going through what I'm going through but sometimes even worse and sometimes better but it's normal
that gave me at first some anxiety because I was thinking well if your colleagues are going through
psychotic breaks I'm not at a psychotic break but that means that it's possible and if Cantor
is studying infinity could go through psychotic breaks I wonder how much of what I'm doing is
self-imposed from my own study of consciousness and investigating the universe so it gives me a
bit of anxiety because okay well this is a path that may lead to that but at the same time it gives
me some calm because you're saying it's okay first of all if it gets serious it can be treated
don't worry about that and and it doesn't seem like I give off any signs of being schizophrenic
even though I'm concerned about it so I'm not a very factual concerned means you can't be
psychotic I did cross my mind when you're talking about the monotheism versus polytheism
and resolving that sort of cognitive dissonance and existential angst you get when you you know
you could be this way or that way I mean the very ability to entertain these counterfactuals
is very very close to psychosis you know the kind of the kind of angst you see a manic
depressive psychosis so it's a natural state for curious creatures so the anxiety you're going to
go over the edge it's just a price you pay for being a curious creature and as you say you'll
know when you're going too far and you either get your wife to call in the doctor or you'll just
sort of commit to one way of being on another way of being you know you will know that but it's you
know what I'm saying is don't you shouldn't be frightened that she should you should celebrate
this you know which is why I always encourage you to actually write down everything you trust me I
write down all right here's an extreme extreme sort of loss of ontological security what I don't do
is rewrite and that's my problem as well because plenty of the writing is in the rewriting and
plenty of retaining it is in the rewriting as well but anyway I got to work on that thank you sir
you're I gotta I feel like I've gotten along with you more than almost anyone that I've interviewed
and I've interviewed almost 50 or 50 plus people so I don't I don't know what to attribute to that
but it's probably your your demeanor and your there's a caringness that comes across in your
voice and I appreciate that and a humbleness as well thank you it was very great thank you very much
you
