I hope you can hear me.
I welcome everyone to this physics of life conference,
which is called physics of immersion behavior 3 from
origin of life to multicellularity.
My name is Robert Endrest and I'm one of the organizers and
along this to find Lee and Elaine de Malepard and Sarah Walker.
We wanted to welcome you to this event.
So there's been quite a tremendous interest in this
conference over 700, almost 800 people signed up and also
virtual. We hope that we can have it at an interactive
in an interactive way. We can run it so before we start, I
wanted to thank all the speakers for making time and you know,
say time zones were quite an issue in the beginning, but we
figured that out. I also wanted to thank the Imperial event team
for logistics and the support for running the workshop and
also Suhael Islam for setting up the registration website.
And then additionally, the Imperial College Network of
Excellence initiative, which we are part of as part of the
physics of life and IOPs Institute of physics for
support. Coming back to the science, so as the topic of
origin of life and multicellularity is really a
profound topic. I think quite a deep question and to make this
accessible to a broad audience. We gave the speakers a
provocative assignment to talk about the big open questions
and where the field might be heading and less so about the
technical details. Of course, one issue is that the origin of
life is not such a well defined problem. So a lot of people
from different backgrounds work on this. So to introduce this
topic a bit more, I prepared a couple of slides, which I'm
going to share now.
I hope you can see that. So this is just again the program.
You saw it already. We have these two days of exciting
events, so we have four sessions. We will talk about this in more
detail in a second. Some of you might also wonder why physics
of Emergence 3. So there were these two earlier conferences,
which dated a couple years back already. So always the issue
was we wanted to have big open questions to be addressed about
Collective Pavia originally and then later on we spent molecules
to planets, so it was even even bigger in terms of scales.
The conference originally was initiated by the Physics of
Life Network at Imperial College. Just here's briefly the
website. Besides some conferences, we also run a monthly
seminar series, which are recorded. So please check it out if
you like.
So how do you now introduce the origin of life to a broad
audience? And I'm sure not everyone thinks about this
problem all the time we included. So obviously this has been an
event a long time ago, 3.5 to 4 billion years ago. So here I
just wanted to show us this phylogenetic tree. The so called
tree of life is a different domains of life. And the point is
now if you would go back in time down the phylogenetic tree and
look what is conserved, you end up with a last universal
common ancestor, Luca. And of course the issue here is said
that this is already quite a modern biological organism
following Darwinian evolution. So and so we said high
complexity. We run into that classical chicken and egg
problem. So ever we can go further back in time and
ultimately we will end up with chemistry, maybe complex
chemistry and even ultimately physics and somewhere there at
this moment we had this transition from nonliving to living
matter, which we then call the origin of life.
Of course now how to introduce us in a couple of minutes is
very difficult. So I just wanted to say there's these two
potentially two branches how to think about it. I won't
call it. I want I called one of them the biochemical perspective.
I'm not going to read all these keywords, but some of these
might sound familiar to you and might pop back some memories
about what you know already for the audience. Certainly you
probably has heard about the RNA world and the famous Miller
and Eury experiment. And then there's the other
communities, the physics community would say, okay, physics
of life, origin of life is really a physics problem. And
of course there's one famous work by Evan Schr√∂dinger in the
lecture and book and in the more modern time we have this
stochastic thermodynamics which addresses this as well.
Yeah, I mean I come from a biologically physics background
and say a lot of physical principles now being
investigated. I would say they're also important for
understanding the origin of life, but this is a very personal
view. So I just wanted to briefly highlight a couple of
them again to so we can start thinking about this.
But other people might have a very different angle on this.
So one thing is certainly one important constraint is
certainly the second law of thermodynamics set in a closed
systems entropy will increase under equilibrium at zero.
And so that provides a severe constraint
on the origin of life if we create order. However, more
recently there are other ways to think about this entropy
increase so we can write it for a sequence of events or
paths. And so if there's a macroscopic event very
likely like the cup breaking, for instance, there's a large
increase in entropy and the other events a reversal event
would not happen. But however, when we go to smaller scales
we can have a spontaneous creation of order and
violation in certain instances.
Of course, biological systems also adapt over
evolutionary time scales, but we can also think of this
in terms of function of organisms.
So here's just an example from a paper of Pablo.
He's one of the speakers for my years from a few years back,
which is about bacterial chemotaxis and it's about
adaptation mechanism with some mesolation level of
receptors track some external like in concentration.
Don't worry about the details. The point is that equilibrium
everything goes down in energy. It doesn't really produce
anything so useful. However, when we drive the whole system
with energy consumption, we can be at the sweet spot where we
get precise and robust adaptation for free and even
engineering principles like integral feedback control.
Another thing, of course, is about accuracy and precision
and potentially error correction. So there's this
classic Hopfield kinetic proof reading model in
equilibrium separation of different discrimination
of different substrates is very difficult, determined
by Boltzmann distribution. However, when we run this
non-equilibrium where we have driven pathways, we can
become more accurate.
One last thing, if we think of biology, of course, we would
think in eventually said we will have
intelligence developing or evolving.
Of course, we could.
We could think about this in terms of complicated
neuroscience. Yeah, I just wanted to take on a perspective
of visiting gross from a few years back,
thinking about it in terms of physics.
So we could, as an alien race, look down on the earth
and see meteorites, asteroids hitting the earth.
Sorry.
We see asteroids hitting the earth.
But then billions years later, we might start
seeing that asteroids are being deflected.
And so we could infer that the planet has
evolved some awareness or intelligence.
And this wouldn't require necessarily any
biology to understand. So it's just a different
way of looking at this thing.
OK, just a last but not least, just a couple of
questions also to get people thinking about this
problem. And again, it's a personal choice, but
these are, I think, quite common questions.
The first one might be, you know, how complexity arises
in biology. We would not argue that this is
biologically organismal complex. It's the same time.
It's a higher level. We have also simplicity in order
to understand biology. So that seems like a paradox.
Second, we could ask
similar to adventuring, ask a new physical loss we might
be missing to explain the emergence of life.
Maybe not at a fundamental level, but at an emergent level.
Even if we would say no,
then we might still wonder about physical principles which
might be relevant to the origin of life.
And finally, in the tradition of theoretical physics,
we want to end up with a predictive quantitative theory.
Given certain conditions, can we predict
if life is evolving?
Essentially, a probability of life we could try to
calculate. In particular, in terms of Earth, we might
want to know was life inevitable or
is it a very rare event and very unlikely?
OK, so
it brings me now to the first session,
which is life in molecules and
there are three speakers.
I wanted to introduce them briefly all together.
So there's essentially a block of speakers and then
each speaker has 20 minutes, 15 plus five.
Five minutes for a quick question answer session.
But then we have the joint panel discussion of all the speakers
and the organizing committee to have a more
interactive thing.
The attendees can submit questions on the Q&A
and we can then also address some of these
and transfer them to the audience, to the speakers.
So, originally,
OK, the three speakers are Dieter Braun.
However, we don't start with Dieter now, we start with Schroeder
because of some technical issues. Neversales Dieter Braun
is from the Ludwig Maximilian University in Munich
and he uses experiments and simulation
for the onset of Darwinian evolution in a non-equilibrium environment.
Then we have Joanna from
she just started, Joanna Xavier
she just started University College London
and she will talk about
auto-colytic sets which are
self-contained networks
where all molecules are catalyzed
by other molecules and that will be very interesting.
It's more about the collective behavior
and then we have Sarah Walker, she's also one of the organizers
she's from Arizona State University
and she has a
theoretical physics background and works in astrobiology
and I think she has a very good overview of this field
and so that will be also very exciting to hear her opinion.
So now we start
and we make a small change that we start with
Joanna. So yeah, thank you for being here
and really looking forward to your talk.
Hi, can you hear me?
Yes. Great.
Well, good afternoon everyone.
I'd like to start by thanking the organizers very much.
This is a very exciting meeting. I'm very glad to be part
and in the spirits of
thanks, I will
move towards my acknowledgment slide
a bit heretic but let me do that
because I just started a new position
in UCL. I'm very happy about it so I want to thank
all my funders and the other institutions
and all my great collaborators but
in particular the Lane Origins Lab at UCL
and I want to mention as well
and thank you very much, Olin, the Origin of Life
Early Career Network, which
I'm an active part and
it keeps reminding me that the Origin of Life
is a question that is definitely not
a one person's task
only.
So I was very excited with this meeting
in particular because it talks about the emergence
which is
a different word than origins that we are more used to
hear but also I like this image
very much that was used because
when you look at it at first it could seem like a phylogenetic tree
or even a cross section of a brain but
in fact it is a colony
of bacteria that engage in social behavior
and form these complex structures
that emerge from
a single cell so
quite interesting for us here.
So emergence
is a very hot topic
it belongs more in the philosophy of science
but I think we should all be aware
that we study origins of the implications
of the philosophy of emergence
and biology loves emergence
mostly because we can model
and predict properties
biological properties without knowing all the very basal
quantum level properties of the atoms
that make biological systems
so there are other
possible suggestions towards strong emergence but I think
most of us right now agree that we can
emergence is real and useful
so
the emergence is about
the arising of unexpected
or non deducible properties in systems
and Kaufman sometimes talks about these as unperstateable
as well.
Another example of emergence is
the origin of
unicatalysis mechanisms in biochemistry
so I do not see a way that these could be
foreseen if they could it would be
in fact a holy grail for cheminformatics
which I'll see how the field
advances.
In terms of life many people talk about emergence
the interesting emergence of order and information
I hope the Natural History Museum does not mind
me sharing this photograph that I took there last week
here in London because I could not find
a better image of
the order the complex order that is
in a simple crystal so order
exists outside of life
and before life and you can see that in the Natural History Museum
so go there
and you can see the complex
structures at crystal conform that at first glance
they are very similar to protein structures even.
So origins of life
imply more than origins of order
in life you have
energy and matter metabolism self-replication
implated replication code
cells which at the beginning of life
were not probably fully fledged
were not for sure but some kind of proto
entity.
I think the big question here is how we can get
variation in selection before we have
the genetic code
and this complex interplay between geochemistry
and biochemistry is what I'm most interested
in is the emergence of these phenomena
so you can choose to focus on
different aspects of life
but none of these alone
make up what a living system is
and this transition here
I think it's the big black hole
and in part it's because
of the self-referentiality of the genetic code
and so this is where we are working right now.
So I said I would be talking
about universal biomolecules and I would like
to start by that so
if you look at what I just said
the processes that make up a cell are very complex
so as a bioengineer I thought I would be going
for the parts and try to decipher
their interactions
so I think it's good for anyone that studies
the origin of life to have a visual perspective
of what makes up life and what are the parts
and the PDB is a great source
for a scale view
of what makes up a cell.
There are many essential components
for all the simplest cells that we know
I gave them some funny names here
but I'm focusing more
in my work on very small things
much less complex than this but which are
implied in the arrangement of the system
and the way it functions and hopefully
I believe it's emergence.
So one of the things I did
some years ago was to integrate
a lot of metabolic data and simulation of metabolic models
to infer which of these molecules
very small molecules are essential
in the functioning of cells
so this is just a very broad schematic
of this work it was basically data integration
from different sources experimental sources
of essentiality and genome scale
metabolic models and literature which led me to infer
which organic factors should be
present in genome scale metabolic models.
So this is a list
which was integrated very recently
into community standards and
I'm very happy about that and this means that
for the actual
functioning of metabolic modeling
and to predict the behavior growth
and metabolism of a cell
you need to include these molecules
for the model to function. I usually focus on
periodic sulfide phosphate is one of my favorites
it's also called the Swiss Army Knife of Catalysis
but today I want to focus a bit more
and tell you more about NAD
because it has come up later in my work
from a very different approach
and NAD is super interesting because it's basically
as I've shown by paraphosphate
and it allows for a universal reaction
in all cells as we know them
it's a universal redock currency
but also in the structure of NAD you have
ADP embedded so this part of the molecule
and what gets reduced or oxidizes
just this part which you see here
so ATP is basically NAD
it's more phosphate and without the second ribose
which is quite interesting and tells you about
how the biochemistry
has constraints that are very specific
and very fundamental for all cells as we know them
and we'll see the relevance of this later
in autocatalysis work
so regarding autocatalysis
we all know that life is self-referential
and Pasteur took a big leap
when he told us that
life comes from life but we also know that at some point
life had to emerge in the universe
so in cells cells catalyze
their own reproduction
through the production of all the essential components
and also the maintenance of the energetic requirements
but in the simplest form
that we can conceive
self-referentiality in chemistry
is an autocatalytic reaction
where basically one compound
enhances the rate of its own production
and more or less around the same time
in the 70s and 80s
a lot of very smart people realize that this
property of chemistry has probably
strong implications for the emergence of complex systems
in more complex
autocatalytic networks
and recently together with Stuart Kaufman
one of those pioneers
I did work in inferring
autocatalytic networks
in metabolism of prokaryotes
that do not require in principle an interior
material to be produced
so we found a network that was very conserved
and somewhat complex at the intersection between
one acetogenic bacteria
and one methanogenic archaea
and the network produces some amino acids
nucleobases acetyl-CoA
which is a quite central metabolite
and I'm proposing now
the first universal common ancestors
before the origin of the code, we'll see about that
but for now
let's let it marinate in our heads
so more recently some work that I have done
with Mike Steele and Daniel Hudson
which is also where we introduced Kathleen Net
which is a tool where you can explore
autocatalysis with your own data set
and I recommend that you check it out
and one of the things that we found out
is that the expansion of these autocatalytic networks
is
extremely influenced by one single reaction
which is the reversible conversion of NAD and ATP
as I showed you before these molecules are very related
but this is not a reaction
that is commonly mentioned in biochemistry
and I thought well
maybe this doesn't really happen
but I was happy to find that the reaction
has been demonstrated experimentally
and it is a reaction that happens with an enzyme
in vitro so I'm looking forward to see
more work in the lab in terms of
what this interconversion might mean
for the emergence of metabolism
So to conclude I think I'm good with time
I would like to
highlight the necessity
at the emergence of cells so we all know that cells are extremely
complex and for them to have appeared
so fast after the origin of earth
for instance when you compare the origin of multicellularity
how long that took
there should be or an intuition
but the respectable intuition says
that there should be some necessity at the emergence of cells
and I think part of
that path implies the synthesis of new catalysts
and redox and energy currencies that are more powerful
and lead to variation that is selected
Of course these networks should be encapsulated
if we want to have units
some people propose this to be a mineral compartment
there are lipid membranes
there is a lot of work required
but we have this kind of image emerging
where from linear chemistry we go to
network chemistry that self sustains itself
and generates
more and more complexity eventually towards
Luca of course there is still a big gap here
and that is about the origin of
template based replication
which could also be autocatalytic
and so these are some of the questions that I'm interested in
and that require a lot of work
for instance the geochemical requirements as well
I personally am inclined to believe that the dynamic
environment of a hydrothermal vent
in terms of pH and temperature would be quite favorable
to the emergence of dynamic system as a cell
in fact when as a bioengineer you look at these
they look very much like bioreactors
so that should tell us something
nevertheless we should work on it
and there is a lot to be done
and that doesn't mean that other environments
wouldn't be interesting for other
processes that could be important at the origin of life
so there are many open questions
together with a group of early career researchers
we published this paper
that tries to highlight that these questions do not belong
in any specific discipline
I mean the big questions and
answering them really benefits
from the interaction of disciplines
so we advocate for
post-disciplinarity and
the dialogue, the open dialogue between scientists
so
please consider doing that
and that's it for my talk
do get connected on
Twitter if you're an early career researcher
check out Olin and thank you very much
for your attention
thank you very much Trina
for your fascinating talk
just looking at the Q&A
so there are no questions yet
but it doesn't matter if you have a joint discussion afterwards
maybe I'll just ask something very briefly
so essentially
what you're proposing or what you're working on
would you be able to classify
as a field of metabolism first
I haven't talked about I suppose there is a link
to da Vincian evolution in some sense
or how would a big relatively complicated
metabolic network evolve
it's a good question but I would not classify it
as metabolism first in fact
one of the bridges we asked for in this paper I mentioned
is
that metabolism first and RNA first don't make
much sense when you think about it because
of the complexity of what a protocell is
and metabolism is it means
it comes from Greek it means change or exchange so
it requires some kind of unity
some kind of membrane and perhaps to have that
you need already some kind of template
polymer so that could be a protein or RNA
so for the type of complex metabolism
that you're thinking about I am not certain
that you could achieve high complexity
without some kind of polymer and I'm more inclined
recently for the necessity of transporters
that would allow for the maintenance of the
self stability but we will see
very good
okay
I think that's a good time now to
move on to the next talk we will see Trina again
it's a panel discussion thank you very much
okay so the next speaker we move on now
to Sarah Walker introduced her already earlier
and then we have to see what we can do about
some difficulties joining
okay Sarah over to you great can you hear me
yes okay excellent I'm going to share my screen
it's just a little slow loading it
sorry
if say any other urgent questions
just speak up or write
him in the Q&A box
alright we're good now you can see
it's coming up
okay
yes excellent
great so thanks so much for having me
give this talk I know one of the organizers and I'm really thrilled to have
so many great people here and it's really fantastic
to have the discussion my talk is really going to be
about fundamental physics of life and if it exists
and why it might be
most apparent in molecules so I'm deeply interested
in the question what is life but I think looking
at highly organized systems like you and I is actually
quite hard to see the physics and so this idea
of seeing what's really there I think is important because
if you look at the history of the progress of physics
most of our physical theories have not conformed
to our intuition for how reality works they're
actually rather surprising and so one of the things I've been really
deeply interested in is whether the physics of life is going to be equally
interesting and I think that other people have also
thought similarly
about it I think my
computer is just being really slow and I'm sorry about that
so Schrodinger has this quote
which was already brought up in the introduction to this session
about the idea of other laws of physics
being important when we're talking about
physics of life and so
there's a lot of areas of physics that we study
and we know and love the laws of physics as they are
and I think I wouldn't challenge that any of those are right
for their domain of validity but I would
suggest that maybe there are entirely new principles at play
and we just haven't been able to see them yet because they are actually only
apparent in the phenomena that we call life because
there is an underlying physics there so this isn't covering all of the
physics that you might learn in undergrad education but these are sort of the major divisions
that we might talk about and so one of
the questions I'm always asking myself is whether
or not
we can actually transport physics as we know it over
to life and in what ways we can do that
and it seems to me to be the case that there's a lot of discussion
physics of life community about applying laws as we know it
to explain life but those
laws were actually really developed for entirely different questions
about the nature of physical reality so for example
thermodynamics was invented to talk about
the efficiency of heat engines and why that should apply to
life and be the foundational principle explaining life
to me is a bit perplexing but I think that will be something fun to discuss later
so what I wanted to kind of propose
is that maybe these kind of physics that we have come up
with so far are important for certain aspects
of reality but they don't cover all of it and
so I added down here this sort of the laws of what is possible
I call it different things usually I think about it in terms of physics
of information but
and that would be a universal physics in the same way that gravity is a
universal physics but gravity has a domain of validity like
at the largest scales in the universe it really matters but it doesn't matter inside an atomic
nucleus. The laws of what possible
or the physics of information or whatever you want to call it
is also a universal physics but it doesn't matter until
you get to the scale of the very complex
things like us and that's when it becomes a dominant physics
once you get into molecules and higher combinatorial
possibilities so there's a few theories
that I think are exploring this kind of idea in interesting ways the one I'm going to talk about
is the one I work on which is called assembly theory
there's also calls set theories which are theories for gravity
that treat events as independent and they're related to
some of Stuart Kaufman's ideas on the adjacent possible so I think
there's some connection there and also constructor theory which rejects
entirely the idea of dynamical laws at all
and initial states and treats reality in a really different
formalism so I think we need to be open minded to the possibility
of what these laws of life could look like
and that they might look radically different than laws of physics if they've been constructed
over the last 300 years because we were asking
really different questions before we got to life
and so part of this is just
trying to see where we are in the history of the progression of human thought
and so this list of unifications
is from a very nice paper by Frank Wilczek
projecting what physics will look like in the next 100 years
and in that paper Frank even mentions
that this dichotomy between initial conditions
and laws as being separate
might need to be resolved and that might be a way forward
the way I think about that from this perspective of thinking about the physics of living matter
is that we have these concepts of information
like computation which emerged in the last century
and we have ideas about matter and its properties
that emerged much earlier than that but we finally came up sort of with the standard model
and things that we have now also in the last century
so what are the next sets of unifications that we actually really need to think about
and one of the features of these unifications
is the physics that we came up with after we unified
these ideas never looked like what we anticipated before
so I think whatever theory is going to emerge
is not going to look like our current theories
and so sometimes
I talk about the original life as a problem of unification
we are not going to understand the transition to the original life
until we understand the physics that underlies life
and the physics that underlies life I think is this sort of
very new perspective that has to do
something with how information becomes a physical
feature of matter and
I like a lot of the ideas in different areas about approaching this
I'm going to talk about a few of them
I'm not going to explicitly talk about information
for the very reason that I think that we need not sort of a
Shannon sense of information but a physical kind of
information which has to do with the fact that you can copy
different attributes between material substrates and they retain
that feature and also that information can be causal
so those are the aspects of information that I think are important
and just to kind of hit home the dichotomy
between what we're talking about in biology when we're asking
for physics of life and what we've done in physics traditionally
I think Charles Darwin had maybe the
best quote that will
this planet has gone cycling on according to the fixed
law of gravity from so simple getting endless forms most beautiful
wonderful happen and are being evolved so I think we're all familiar with this quote
but I think what you know sort of a key point
of it is that in physics we
assume that the laws are immutable
and they exist autonomous to the system and in some sense there's a problem
of where the laws of physics come from in the first place
because they don't exist within the universe
but when you get to biology you have systems that are writing down
theories like us and those are changing
sort of the physical systems they're in but more generally we have
this idea that living systems are generative
and they don't have fixed rules over time
and this is actually the process that we call evolution
so somehow we need to try to figure out how these
kind of two very different descriptions of physical reality can exist in the same
universe and what
I'm going to talk about for this talk is actually just how we can
start to see some of these ideas in biochemistry
itself and I'm not going to into a lot of details
because we don't have a lot of time for this talk
but I do want to touch on this idea of universality in biochemistry
which is an important concept
that we have a single sample of life on earth and as
Joanna was just talking about in the last talk and was also
alluded to in the introduction we have common biochemical components
across all of that and that's one of the reasons that we have evidence
for our last universal common ancestor
and the idea of focusing on the specific components
of the features of life on earth is really embedded in this idea that life is chemistry
so the molecules that are involved in living systems
are essentially life and in astrobiology
this assumption is not often made
explicit but it's very implicit because we're always
conducting our search for life on other planets by looking
for molecules that life on earth uses and so
we have to ask ourselves is this really the best way of doing it and if we're
thinking about life as a universal phenomena phenomena
that can potentially arise anywhere in the universe because
the physics itself is universal then maybe we need to abstract
away from the specific details of the chemistry of life on earth
and so the first part
I'm going to talk about getting into some more technical content rather than
philosophical content is this idea of assembly
theory which is
a proposal of a sort of new theory
that would be explanatory of life
that originated in the lab of Lee Cronin but the
ideas are things that we've been working on together for years he's been doing
experimental and theory part and I've been working a lot on the theory and connecting it
to physics of information and the basic
conjecture of assembly theory is that physical
objects like molecules and tables and chairs
and people live in a space called an assembly
space and it's very easy to articulate when
an assembly space is for a molecule
an assembly space is very different than a physical space or some of the other spaces that we
talk about in physics currently but it is a very real
space potentially and it is observationally
accessible which I'll talk about in a minute
but what an assembly space is if you imagine a molecule
you can break it apart into all of its fragments and then you can build up
all the possible ways of assembling the molecule and that's what we call an assembly
space and in assembly theory
a molecule is not a molecule as we see it
we measure its properties in the lab it is an assembly space
for instance of a particular causal structure of all these pathways
of building an object so a molecule encodes all of the possible
histories in that assembly structure
and you can talk about the complexity of a molecule as the shortest path in that space
so just shown here is how we do that
in terms of assembling bonds to count up the number of possible
bonds to build up a molecule for ATP
now the important part of assembly spaces for me
and why I started really getting interested in this as a pathway
into getting into some of the deeper conceptual ideas about
what a fundamental physics of life might look like
is that it's observationally tractable so this idea
of fragmenting molecules and looking at their parts
is something that an instrument called a mass spec
does anyway and so Lee's lab has actually
mapped measurements in a mass spec
to the assembly index the shortest path in the space
of molecules and been able to
observationally verify
that there's a strong correlation there and then use that to show
that the only physical systems we know that make high complexity
molecules are living systems
and so this was published in a paper very recently
and the key point I want to make here is
we've been applying assembly theory to molecules but the idea
is you could fragment yourself and all of your possible histories
would also be encoded in that structure of you as a physical object
and then also you exist in space time so you might think of an assembly
of the space time coordinates and all of those kind of things
but that's to be developed. But the key
conjecture of assembly theory I think is important is that there's a threshold
which might be a constant of nature in the same sense that the plant
constant is constant in nature or the fine structure constant
in assembly spaces above which living
physics is necessary. What I mean by living physics
is physics of information has to exist in those systems in order to get
to that complexity threshold. The reason being that the probability
of seeing objects and where we see that
observationally experimentally is at an MA of 15
is so improbable you would never expect to find them in high abundance.
So it's not going against the laws of physics it's saying that they can
these things can spontaneously form with exceptionally low probability
but observationally you're never likely to observe them
and you're certainly not likely to observe say 10,000 copies necessary
to observe them in a mass spec.
So for me this is trying to really articulate
the possibility that there's actually a threshold
in physical reality above
which you require information in order for those
objects to exist. This is what assembly theory is trying to get at
so we're trying to formalize this concept of information and assemble theory now
and related to the causal histories necessary for the universe to undergo
to construct specific objects
and so that's sort of where the current state of that is
I am going to just kind of breeze through the next
part of my talk which is just to talk about the universality
beyond life on earth. So not just talking about the assembly theory part
but also how do we actually extrapolate beyond
in other ways molecules
properties of molecules. So there is
a sort of set of ideas
that my lab has been working on which we call planetary systems
biochemistry which is to look at biochemistry
all the molecules that life on earth uses and the cataloged
reactions that we know about that are catalyzed
by enzymes and try to look for scaling properties
to see if there's any law like behavior. So again this is trying
to move away from thinking about the specific molecules
on life on earth
and thinking about general properties. So assembly theory tells us
there's sort of a complexity threshold and life can only make things above
that threshold it doesn't matter what it is it doesn't have to be like molecules on earth.
Here we're looking at instead it's statistical
patterns in the properties of the molecules and reactions.
So it's kind of getting a window into a similar physics
and same properties but looking at it from a very different perspective.
To look at scaling behavior and statistics
we have to build ensembles just like we do in statistical mechanics
and thermodynamics and so we've built large ensembles
of biochemical networks across different scales of organization
and the particular results
I'm going to show you are related to coarse-graining of chemical reaction
space so if you look at the kind of biochemical reactions
life on earth uses there's actually
a way that they're cataloged called
enzyme commission numbers that hierarchically organizes them
by function and you can look at the broadest class
of enzyme function as sort of the highest
level of coarse-graining so the largest bins for functions that biochemistry uses
and those functions are listed here
I'm not going to go through them because we don't have a lot of time but you can see
our pre-print on bioarchive
and if you look at total enzymes
and the number of each kind of enzyme function
what we were looking for is whether or not there was particular scaling behavior
associated to that and in fact we do
find that enzyme functions exhibit universal scaling
laws and they fall into a few
different classes so some of the enzyme functions are super linear
some are linear, some are sub-linear but we see
universal behavior across the different domains of life and also
across scales of organizations so metagenomes are really looking at the ecosystem
level scale.
I don't have time to get into details but I just want to make the point
that these universality classes are different than
the biochemical notion of universality where you have shared component parts
because we've actually been able to show there's not a correlation between
the behavior of the scaling and the
universality of component parts of the biochemistry so whether enzymes are
shared across organisms or not does not matter for these
emergent patterns that we see in the scaling behavior.
What we're trying to do now
is use these scaling laws as a way
of looking at statistical properties
of biochemistry independent of the component parts to predict
both features of the earliest
life on Earth in terms of sort of in this case
distribution of different functions that the last universal common ancestor
might have had or you can imagine
growing biochemistry from geochemical conditions on other
planets and using these coarse grain constraints to actually predict
what kinds of biochemical systems could exist in different geochemical environments.
And so those are two things that we're doing
we are currently looking at the last universal common ancestor
consensus model given to us by our
colleague Aaron Goldman and demonstrating
that it's not consistent with the universality classes that we
observed for modern life which either means that there was
some phase transition probably in early life anyway to these
universality classes but whether it was at the time of Luca or not
is an interesting question. So just to
summarize this last part
when we're talking about universality and biochemistry traditionally it's been about molecules
the work we're trying to do is push it beyond
looking at molecules to look at statistical patterns and some of these patterns
that we're seeing emerge are independent of the details of the component chemistry
which is suggestive they might be more universal
organizing principles for life. And with that
I'm going to conclude on one of my favorite quotes about the dichotomy between
physics as we know it now which is we use to describe
objectively properties of the universe and then the physics
as I hope to understand it in life which has to do with
intelligent information processing systems actually interacting
with that physics and changing the possibilities or generating
possibilities in the universe and how we can actually get at that physics.
And with that I'm going to take my group and
collaborators in particular Lee Cronin, Chris Kempies and Michael Lachman
have been working together a lot
on the assembly theory ideas and where we're going with it and Erin Goldman
for the Luca models
and Paul Davies for being an awesome mentor and I work with
an awesome group of postdocs and grad students that I
am always thrilled to interact with. So thanks.
Thank you Sarah.
Thank you for your talk. So there have been a couple
of questions also some related to China but maybe we can
come back to this later in the panel discussion and
there are now a couple of questions for a few questions
for Sarah and if I can I don't know if I can summarize
them very quickly so it seems to be about the physics of information
and also the link to Shannon entropy
and a similar question I also had so Sarah
I think in the beginning you said you know you're not talking about Shannon entropy and then
you talk about this assembly theory which is another measure
of complexity and I guess one question might be
you know how they are linked and also
how it links to physics of information.
Yeah so I can try
to give a short answer to that which is the way I think about Shannon
theory is it's really capturing correlations between different physical
systems but it depends on sort of how you're observing them
because you have to actually label the states of the system and this is also something that
I find deeply intriguing about the way we do thermodynamics.
In assembly theory what we're saying is
the assembliness of an object is a physically
observable attribute and it is actually a feature of the physical
structure and in some ways
you should think about that as
sort of how much information that assembly index is
related to how much information is necessary to create
an object in the universe but I mean it in terms of number of events
or steps not in a Shannon sense of information
and I think where Shannon comes into it is if I start
looking at interactions between these objects and the statistics
of interactions some of Shannon's formalism is going to be
really relevant to talking about that but I want to
look at the underlying sort of evolutionary pathways
the universe takes and what objects are necessary
to actually catalyze new transformations so each step
in that assembly pathway requires potentially
a constructor or an object that has
the ability to mediate that transformation so what
we're saying is when you
get to the physics of life the laws become very local because they're
local to specific objects that are necessary to
mediate specific transformations to happen in the universe
that are consistent with the laws of physics but the laws of physics don't tell you
which transformations do happen they tell you what can happen
and the objects themselves tell you what does happen.
Yeah, very good.
I mean there are several questions I think you
address them in one way or another.
Just very briefly before we move on to the next speaker
I guess there's also the issue of the value of information
in information theory in biology.
I think there are some quite well known papers on that as well
and I know Bibi Alec was wondering about this as well. Would you say now
you somehow bypass this problem because
your steps in assembly they are certainly important
to get the thing to the molecule of interest
assembled and
I suppose these are critical steps anyway so
there's maybe no question even
of the value of information
or would you not think about this issue like that?
I think there will be a deep connection
but I think they're very far afield from what they're addressing
and what they're asking right now so I work in both information theory
and assembly theory and I just think about them in completely different
domains when I'm trying to apply them and think about them but I think
the properties that we associate
to the value of information
and its role in biology are an emergent
property the fact that life exists in assembly spaces.
That would be the cleanest way I can say it simply
but I think the problem
there's a lot of problems with information theory applied to life
that we talk about like the fact it doesn't cover semantic information
you have to label the states, you have to know what the properties of the channel
are ahead of time and all these other features
and I think what we're trying to do is dig a little deeper
and see if there's some other underlying feature that's more objective.
Okay, just one thing
I noticed here is the last question was about wolves from
hypergraphs in the new kind of science. I don't know does it tell you anything
Yeah, I think those ideas are also related
because Wolfram's talking about the causal structure
in terms of these hypergraphs. I think there's
a few subtle differences in the way we talk about
the physics and assembly theory and what Wolfram's
trying to do in the hypergraph. So one thing is Wolfram's
objective is to reconstruct known physics
not to discover new physics and I think what we're doing in assembly theory
is trying to discover the physics of life and have it be
observationally testable in the lab that we can actually
de novo evolve life from scratch in the lab.
The fact that those physical theories have similar
structure is deeply interesting and probably
is telling us something because assembly theory if you look at any theories of physics
is closest in relation to theories of quantum gravity in terms of
its structure which I find deeply intriguing.
But that's a whole separate can of worms and would be a very long conversation.
Thank you so much.
Now we can come back to these in the panel discussion.
So now we have Dieter Braun joining us.
I'm really glad it worked out and fantastic to see you.
I introduced Dieter before.
He said Ludwig Maximilian University in Munich and
I'm happy to hear your talk. Thank you.
Okay, yes. I hope you can hear me. Yes.
Can you hear me? You see the screen.
Perfect. Here we go. So I had to move for another computer.
So basically it's too heretic to ask Microsoft to write
software for Linux, I guess. So
yes, we try to approach
life from experiments bottom up
experiments. I want to share with you what we did the last years.
Basically the question is
the earth very violent early on
and then connect the dots to get somewhere
close to replicating system, molecular systems
there and the two movies who didn't make the move to the new
computer are movies on Iceland.
Volcanic Island, you have high
porous rock, a lot of warm
vapor flowing by and if you walk over
Iceland what was really peculiar and that's for all volcanic
systems and it has very porous rocks out there and
that's kind of the starting position where we try
to start doing experiments and
what we are doing in the lab is we make mimics
of what could happen these pores if they're exposed
to temperature differences and the latest
iteration of that is
where we look at pores which are only half
filled by water, the other end is by air
and there's an interesting evaporation precipitation dynamics
going on. Basically if you look inside
and you have oligonucleotides, RNA, DNA, shorter strands
and you label them presently, you can figure out
that this evaporation and condensation dynamics
already at these moderate temperatures give you
reasonably fast and strong accumulation.
I mean you get about 200 fold accumulation
within five minutes of these nucleotides at the interface
which make it a quite
interesting place to look at experimentally. So
basically there surface tension effects, there's evaporation
as coffee ring effect, this model which is behind
fitting these experimental findings
is basically mostly driven by the capillary
flow of the evaporation and the diffusion of the molecules
against that and therefore they accumulate at the interface.
But this accumulation was at this water
interface not the only point which
showed interesting dynamics here besides
that accumulation we've seen many important
reactions for prebiotic life at this interface
one of them is if you not only have
a large bubble but even a small bubble of air
you do find in the temperature difference
that molecules are in the
similar way as you see before evaporating
recondensing therefore concentrating at this interface
as they can't go with the water into the gas bubble
for the cold side and you actually find a crystallization
which is very peculiar very nice defined
for in this case a precursor molecule
for RNA synthesis. So if you think about
chirality this would be an issue where this
in special the case is a case where these crystals are
homochiral in their composition.
So beside that small molecules can be accumulated
actually also salts are accumulating
in the settings. The wet dry cycling at the interface
because the interface is moving up and down
gives you also potential for a dry wet cycle
where you can actually phosphorylate nucleotides
it's also an important part in the mixture
towards more complex RNA molecules.
But then if you have longer oligonucleotides
of RNA they can be catalytic here it's a catalysis
where it cleaves a substrate and therefore enhances the fluorescence
it's a hammerhead ribosome and it
doesn't do the make it more complex but actually destroying
it and what is interesting to see
that the accumulation of the salts and the molecules
at the interface is boosting the reaction tremendously
and ribosomes have a very nice
time at this interface to the point that they actually
produce so much material which comes down
into the whole liquid part.
But that's not all if you have RNA
which is self-sticky to the point that it can make large
aggregates almost like in a phase transition
they accumulate to the point to really make large
parts and they only do
so if they have complementary sequences so the accumulation
can trigger actually a large scale formation
which can be very stable because very stable against
hydrolysis in double-stranded state.
But also the same happens for lipids
on the left hand side you have a lipid fluorescence channel
right hand side a DNA fluorescence channel
and the combination of the accumulation of the DNA
at the interface and the accumulation of the lipids
at the interface actually leads to what you see here
as particles which both have lipids and DNA
and you can show if you go more detail
that these are protecting the DNA in the
center and also this marangoni flows which are very
strong leads to fission
events up here so that
brought us to the idea that we should push more
at these conditions because a lot of interesting effects come together
so we're pushing right now RNA polymerization that these phosphorylated
nucleotides will actually go for longer
polymers and you know that's kind of the
down the road hope that we can go bottom up
from nucleotides to lifelike systems
and if you go for replication we've shown that
with proteins in the past and we push
more now to do the same thing without proteins
so this is a don't go in detail here it's basically
length selective replication based on thermophoresis
to accumulate molecules and we managed last year
to figure out a way to make a RNA version
of that so here it has to be optimized
in a very localized heating that molecules
only go through this high temperature step
to separate the strands in a short time
because otherwise the RNA
which is actually driving the reaction is destroyed
so the degradation time becomes very short
and because they run this reaction at very high salt concentrations
this is a tricky situation to balance
replication and destruction at the same time
so this is not yet that the position to replicate these
100 bases long ribosomes at the same time
but we've seen interestingly enough that they form
aggregates also in this case under the native conditions
where Jerry Joyce with whom we collaborated here
is optimizing these conditions
and those again have an effect
based on thermophoresis movement of molecules in terms of
gradient to accumulate in a ring like pattern
and therefore gives us also protective environment
for these molecules so
in general we can replicate and we can try to push it
but one has to be a little bit aware of that
if we only replicate randomness
we might be trapped in a situation where
sequences not become long enough but become interesting
enough and to really make that
ribosome functions. Ribosomes are
200 mergers even tRNA 70 mergers large molecules
and the big question is what selection
comes in place
before we can hope that information
is replicated well enough and selected well enough
that we can think about RNA world scenarios or
self replicating scenarios so
one thing we observe and are quite intrigued by
that it's a symmetry breaking like dynamics
in sequence space paper
I won't talk about but something we published
now
where we just start from random sequences
and add a reaction
again we cheat a bit we have a protein doing it
but it's something you could think that a very simple
pre-built reaction could bring it about
which is doing a templated ligation
so the strands come together in the three body
of the ligation and are linked in the template
so the interesting thing is well
on the one hand side these strands tend to make
longer strands quite fast and quite long
that's something you would have expected a bit
there are a lot of interesting details if you go for real
modeling of these systems because you have to assume
that this is actually happening in the conformation
if you really go for equilibrium it would actually
counter part and would not have the overlap
so there's an interesting kinetic aspect to that
but if you look at this and you start with these
random distributions so they have a Gaussian distribution
of T we talk here about only two bases
because again interesting kinetic effect
if you start with four bases it doesn't work at all
because the strands don't have enough time to find themselves
but then if you look for the first strands
of 20 former they actually you find
a very distinct bimodal distribution
which you can assign to that these
strands are selected out if they can make these happen
so the strands rather have a lot of A
or have a lot of T bases but nothing in between
because that tends to run into a lot of happens
so even these very simple replication
systems apparently have a strong way to select themselves
and beside of that A type
and T type pattern you can see here in the between
that you get a zebra shaped pattern which is also quite peculiar
and the self amplification of the ligation site
in short if you look
a little bit further out we do
a liminar sequencing on these strands
which are capable of making the longer strands
you actually find two worlds of two networks of A type, T type
linking together almost being fully complementary
and then actually can make networks of replication
so if you start from randomness
what you get out of that such a system is not just a random along
strands you rather get networks
of strands which have a higher concentration therefore
find themselves faster in the mixture and are able to
make more template of their sequence and therefore
replicate themselves in a cooperative manner
and that is understood to the point that you can make those networks
and test them and yes they work as expected
but it shows actually that if you look at sequences
cooperative very simple reactions
working together leads to quite an interesting
evolutionary dynamics probably not yet you know
Darwinian evolution a little bit in between between the randomness
short strands and the long strands you want to have but it structures
the sequence in a very peculiar interesting way
that's a much interesting mechanisms to find
because the jump for ribosomes is a large one
so before I stop I
don't have enough time just want to mention a paper
where we work on tRNA sequences where replicators
only thermally self-assembling but as I said
that's not enough time but it might be interesting if you're
interested in translation origin translation the connection
to replication you might want to have a look at that
I like to end and
all the PhD mostly PhD students
doing the work and Christoph must the master of
microfluidics in the lab I'm happy to take questions
thank you so much Dieter
fantastic talk
yeah while we wait for questions
in the Q&A
I can ask something I can start
so I was thinking so
in your experiments or the experiments you
described you start with
you know it starts it's a it's a relatively
simple system I think you know
because you're trying to push down to the origin of life obviously
but then of course you still start with a high energy
nucleotides or in one case you had to
protein and in another case you had to complicated ribosome
so I guess
I guess the question is you know how far do you think
to get to the stage where you don't need these
inputs so I guess I'm thinking of some
middle urea experiment you know all you have is a bunch
of stuff in the soup and you you know
stimulate it somehow and so on and then
yes I mean the standard
RNA world assumes a triphosphate nucleotide
and that's something you know you have an
activated molecule it's already very complex compared to what you discuss here
and that's quite hard to get prebiologically
and at the same time it doesn't give you
much on the polymerization side but
you know it's work in progress but we see
polymerization from a very simple phosphorylation state of a nucleotide
which is prebiologically plausible
and you can think of that
if you've managed to get some way into the nucleotide
business
then phosphorylation is part of the deal and then
polymerization is likely also possible in these conditions in very mild
settings and then if the polymerization
goes and it you know takes away the nucleotides
and kind of you know removes those from the mixture
it also you know moves the whole
reaction from the low side but that's sad
because having just a sugar soup and just a base
soup is a very tough way to get to RNA
but let's see I mean I just see this quite
encouraging to push on
and let's see how far we can get
it's an experimental question has to be shown experimentally
Can I ask a similar sort of follow up, a related follow up question?
How concentration dependent
is this process in the sense that like if you know
you have these beautiful results at high concentrations of
you know polymer of nucleotide soup
if it was one one thousandth the concentration
does the sort of fundamental kinetics still favor polymerization
or is it is it is there a sort of a tipping point
of concentration required?
I mean one thing is always
how much is your mixture tolerant to other
molecules and that you can test but then on the other
hand side you know what I would need a little
bit more detail here how the wet tricycling is working
here that accumulates molecules a lot you have this
surface coffee ring effect
which accumulates 200-fold you and top can make this
at the bottom of a longer short you know
thermal gradient chamber which accumulates
million-folds by thermophoresis so
yes concentration is a problem but there are
physical means by you know we specialize a bit
on the temperature alone there might be other ways
but temperature alone is already giving you a cascade
where you can slowly feed this with low concentrations
and then at one position and you know
100 by 100 by 100 micrometers in your experiment
you can get those concentrations and
so we are very much aware
of that concentration dependence but you know we
have a lot and explored a lot methods to accumulate it
while you know not having running away
effects if you have really wet tricycles
which are not diffusively coupled as they are in here
they have a bit of tendency to a mass a lot of
salts have a shift of pH because
as you evaporate you remove water you can
actually not feed it again because if you bring in other molecules
you bring in more and more and more stuff and therefore shift your pH and
salt so in these conditions that wet tricycle
is very local and you can feed by diffusion the system
and therefore you know also remove and keep the pH
constant and keep so those are my
fluid experiments we can do now in the lab and you know
we see polymerizations in one day
you know can run that for a week or two and
with all the nice methodology of mass back
Illumina sequencing you know there's
many many ways to look at the system
and ask the question you know
will it be possible and I think you know
with what we see there's plenty of interesting things coming up
in the future on this
I still see a lot of momentum and doing this
and this non-equilibrium setting get very interesting results
I think
Good
Any more questions
just
let me just check one more time
wonderful talk
leader in your opinion what is missing in plan to experimentally
show Darwinian evolution through using
your system
I mean these systems here on the right hand side
they are already Darwinian in the sense that you're
replicating and the replication gives you longer strands
very often in Darwinian
pre-Davinian evolution you replicate things but then
you run the problem with the Spiegelman monster
that you get shorter shorter strands because shorter strands replicate
faster
but this is one case where the longer
ones replicating better with the use of protein
and we learned a lot on this
we have a problem
we can hopefully not too hard
transfer that also to a system where
things get longer and longer as you can see
in the ligation experiments this is done
in a simple test tube and we start to put this also
on these non-equilibrium settings
so when does it become Darwinian
the funny question is here all the time
what's your function you're selecting for and of course
you always want to have a protein or a special
self-helping reaction
well the first self-helping reaction is to
survive longer so to make
hydrolysis less for RNA
to have sequence space
which can ligate replicate fast
and I think that those rather physical
selection pressures which you probably not yet
associating fully with Darwinian evolution because
what you're used to in biology is already
almost Darwinian evolution
and I think you can go quite a long way
by first putting it on
physical means of selection
and probably get to 200 MERS or something
and then you will get to feedback cycles
where the replication is self-stabilizing
and self-helping
again we've been amazed here
you take random sequences you get longer ones
but actually it's not random anymore
so it's just a nice piece of non-equilibrium
biophysics to be fully explored
and after seeing it you understand yes of course
afterwards you say yes of course
obviously
so hopefully we'll also have some obviously
solution it's answered
so Dieter just
we should move on to the panel discussion but maybe one question
I don't know if you can answer it in one minute
or not in one minute even in one sentence
it says you mentioned briefly about random experiment
structuring the sequences in a particular way
do you see any signatures of these and viruses
if you know what this question means and if you can answer
if you have a genetic code that's already much
much evolved we are talking way below virus
so I think that's disconnected
okay so thank you again Dieter
and all your speakers and I invite you
to join with your camera on
so we can start this more broader
panel discussion how we call it
I think Dieter is here Sarah is here
are we missing anyone no good
fantastic
so the idea is now that we have
the speakers and the organisers
joining us and
so we can broaden up this discussion so there are still
some questions on the chat box maybe
because it was cut short initially
with journalist talk maybe let me ask you a quick question
before we start with a more general discussion
just one second
I guess okay nice talk
China do you think an underlying network of proteins
embeds the so-called template in terms of
organismic evolution in simpler terms the network
is the cause of the template
I'm not sure
I understand the question but let me try
so I think sorry if you talk about RNA being
the template for
itself and I guess the question is does the network
can it function as a similar level
well theoretically yes
just because the chemical
structure is maintained and
it's a template for itself so that's the basic
definition of a collectively autocatalytic set
in chemistry now experimentally
with small molecules there has been
little work so I'm hoping to see
more in the future and I'm not advocating that
networks we find will be
seen exactly like that in the lab
so definitely there has to be more work in the lab
to see how far they can go and they can
be self-sustained and self-maintained without
the aid of templates and polymers
I'm sorry but so theoretically yes
okay cool
yeah so thank you everyone for someone is still sharing
their screen sorry
just a note I think
it might be
it might be the producer of Sevent Aka so we can see each other
I don't know so maybe
let me just start something here so let's
open up this discussion so the idea is also that speakers
can ask each other questions so maybe
let me just start this whole thing with this one
question so we had these
very different talks which was fantastic so we had
metabolic networks then we had
I don't know RNA world from Dieter Braun
or this non-equilibrium setting
and then we had Sarah's assembly
theory and really cool theoretical ideas
so I guess you know if you talk
about the origin of life like a singular event
would it mean that at least two of you three are wrong
in terms of explaining it
or do you think it's
it can be all of the above
so to anyone
I would say all of the above
but I think just on the
experimental side there is something that we talk a lot about
in the context of assembly theory that I think is critically important
which is we never quantify how much information we're putting into
prebiotic experiments
so you have to think about the fact that when you design experiment you're manipulating
conditions and then you're actually
putting information in I think Dieter's experiments are trying
to minimize the amount of information in and that's one of the nice things about what he's doing
but I think trying to make that explicit might be more helpful
for seeing sort of the underlying physics from the way we talk about it
in assembly theory because you have to actually talk about the constraints
you're putting on the system before you can talk about what information is emerging
in the system and of course
the other feature I would say is that
we do have some of the theory work we're doing now
which indicates that copying or reproducing systems
are necessary to get to high assembly objects which is one of the reasons that I say
there's a deep connection between assembly theory
and the physics of information if you don't have copying events
physical system propagating information in the future you're never going to get to a high assembly object
and that's sort of one of the
conjectures that we have right now that we're trying to demonstrate
I mean all of these systems are
informing themselves you know that's why I think
it's important to look at all of them
and combine it you know
it would be interesting to be more explicit about information content
in the system and let's see
I mean we're quite open in what we do
but of course we have to get it going at some point
and then we can hopefully reduce
make it more realistic
optimise its
information as a massing or its probability
at the end of the day we have to talk about probabilities
of immersion of life if we manage to once make it convincingly
and then all these theories
are will be important
to me it was never
helpful to think who is right or wrong
I like to think in terms of explanations and their power
the power of the explanatory power of theory
and experiments
I do think that what Sarah brought up
about the information we put in is important
but also to mention that
whenever we build a model of any type
model in science we do put constraints
in and that's what makes a model work
so I do not see
how else we could
access what happened at the origin of life without
good models, good theories, good simulations
B, it's just the way that science works
and you are much faster experimentalist
if you listen to theoreticians
because they will tell you this is a good direction
and they will tell you this is a bad direction
I think, I fully agree
so for instance, Sarah and
China described, do you think that could be applied
to model your experiments or is it
not close enough?
That's the importance of modeling, sometimes you need
the model very close so we do a lot of COMSOL
finite element simulation that we really know the flow of
speeds and all the details that we are not doing
stupid experimental runs where nothing works
but then you have this overlaying theoretical levels
and all of them have the ability because
in COMSOL you can't simulate sequence space
or simply dynamics or information
in the way you know you can do these
theoretical models which are a little bit more
overarching, sometimes of course
we'd love to see it a little bit more applied to what
really is possible and link it but I see it
the trend is over the last years that gets
more and more, we're moving together
we're not moving further apart, that's what I see
Can I clarify the point I made just a little
bit in response to Joanna's comment because I think
the comment about we always have to have a model and an experiment
in theory is totally valid, I think my point was more
we have to understand how we're setting up the initial conditions relative
to what it is we hope to observe and so in any
experiment you need to control for your starting conditions
and my point was just that I think historically
because we haven't understood the question we're asking
we haven't necessarily been setting up experiments in the way
that we understand exactly what we're inputting as the boundary
condition for the experiment relative to what we want to get out
so one way I would articulate that is everything
that goes into the experiment is itself a product of evolution
or a chemist designing something and that means
that there was evolutionary information or intelligent
information put into the experiment and once we understand how to quantify
that we can control for those boundary conditions and then ask
how much information are we getting out of the experiment relative to
what we put in and that's something that you can actually
formalize in assembly theory and I think that's just
a really important point whether or not that's the right
theory for doing it is a different question but I think it's just something that
has been raised in an interesting way in the way we talk about it in assembly
theory that is relevant no matter what physics ends up
describing origins of life is we have to be aware of what we're putting in and what we're
getting out with respect to where we are in the evolutionary
history of objects in the universe that are life.
Every experiment we create is a product of life so we have to
know how much we're putting in.
I mean in physics we don't have a theory of non-equilibrium
thermodynamics of non-equilibrium events so
all that interaction of boundary conditions with the molecules
is just all or some new physics so it's
that's why we got funding early on
mostly from the physics side because they think oh we don't know
what we want to know so
but then the more close you get to the molecules I think
the better and better you can use assembly theories and do those
theories but we'll have to be a bit open
to how those boundary condition molecule interactions
what possibilities we are missing out
still right but that's a
adventurous pathway which is in front of us
I think.
I'm going to clarify this again so for your experiments
you don't need theory to constrain your
experiments so you don't need a prediction from theory to
implement your experiments is it sort of intuition
you have to set up these experiments or does most of them
most of them don't work and once in a while you get something
which works.
It's the stepwise things so some things we
do know before that it will work but then
it's always open to things where you say
okay this sounds interesting this is polymerizes ligating
are we really sure that we know already
so let's try out and it's a bit 50-50
it's not 50% you know already yeah that must go
in that direction but 50% is just blue sky
and I think the beauty of the field is that you can do both
and if you're lucky
both works well we
are just reporting on all those experiments which didn't work
so as usual.
That's already a good selection principle.
Okay just another quick comment since
no one else says anything so you said you know there's no
theory for non-equilibrium physics I mean I'm sure
the speakers of the next session would disagree
so you don't think that
the kind of theory can help make predictions for
experiments and make even theoretical
prediction about the origin of life?
Well they will to some degree but if you're
really really far from equilibrium and you easily
are far from equilibrium
I'm not sure
you know it's always good if theoreticians say look there's some interesting
coupling and there's something this you know you have
a feedback loop that's always something where as experimentalists
you say oh let's have a look you know
is there something and then
I just see a lot of interesting connections
back forth between molecules and boundary conditions
you know initially we thought temperature gradient
something boring right I mean and we've continuously
see interesting things coming up so
let's see I mean
it doesn't have to be thermal origin of life
that's fine but some non-equilibrium
it's always kind of fun to look at
So maybe I
answer questions to
data here so you emphasize
on the boundary condition where it seems to me all you
talking about is some kind of compartmentalization
it could be a 3D into a 2D
so there is a air water interface
or it could be a compartmentalization
it's still in 3D into small drops where
concentration is again increased
so do you see a distinction between boundary conditions
and just general compartmentalization due to potentially
phase separation?
I would be a bit stiff here because
compartments don't do anything you know compartments are
not
they're not accumulating they're not
well if you do phase separation you would have a
potentially higher concentration of material to do reaction with
Yeah but
well okay
that's a longer discussion but
if you know I think the important ingredients is actually
not boundary conditions and not
compartments or anything it's more
to keep your system out of equilibrium because that's what
living systems are about they can keep themselves out of
equilibrium nowadays and early on it was more
how could the environment keep it out of equilibrium
because I think only then you have a chance to replicate
things accumulate things work against the second law
thermodynamics and you know get evolution
going so whatever
you find out to keep your thing out of equilibrium
and it's getting interesting for regions of life and
often in chemistry it's the opposite you know you have two
pure materials completely out of equilibrium put it together
you mix it you know it will just decay into equilibrium
and die out so we have to kind of work against that
reflex normals that the chemist has
So compartmentalization of course
can also be stabilized by non-euclidean
effect I mean for example the lava lamp that
they have not seeing those blocks rising
you know the story of
the story of course awaits of you know
assembling things has always been
seen you can see it
optimistically or pessimistically and in many cases
they just form the course of it and then are less active
because it's just binding the molecules to a lot of other
molecules and therefore don't have the freedom
to actually do the reaction anymore so it's a you know it's a trade off
of accumulation
by binding to something and then it's not fully clear what
your advantage is at the end of the day
that's probably no pessimistic way but
there are nice potentials
on price of aid systems for sure
but
Yeah, thank you.
A commentary in the Q&A box
I might have misunderstood this but
Sarah Walker showed that Lucas enzymes
are in a different universality class in modern life
but China showed that you can reconstruct
some parts of Luca
biochemical network from modern life data are these two ideas at
odds
They're not actually at odds I think what we were trying
to show is there's different ways of constructing Luca
and some of them are phylogenetic and then there's
sort of the way that Joanna's been trying to do it also
reconstructing from modern reaction networks
and what we're suggesting is there's this third way
of trying to look at Luca by looking at the universality classes
and not those reconstructions don't match up yet
but specific phylogenetic reconstructions don't reproduce
the same exact Luca and I think Joanna made the good point
of hers being one example of Luca
and the way I think about Luca is not an individual model
but a class of models with certain properties
and I think what we're trying to do is constrain
properties of that class of models
using these statistical relationships
and something like Joanna's example
might be a particular member of that class or not
and whether Luca was in that sort of class that we predict
is something that we have to be able to figure out
using different approaches
and so what we're hoping to do is be able to construct
a class of models that are in the same universality classes
modern biochemistry and see if those Luca models
seem like they're consistent with
what we know of early life from other people's reconstructions
or how it can kind of co-constrain what was happening at that period
I'm sure Joanna has more to say from her side
Yeah, I agree. I think there is an important
distinction to make here which is
what is Luca and what is Fouca? Luca is the last
universal common ancestor, right? So
commonly in evolutionary biology that is
seen as the last thing that
had what we all shared so Luca in theory
in the common definition of evolutionary biology
has the genetic code already because we all share it
so perhaps it would be more appropriate
to talk about what me and Sarah are doing in terms of Fouca
I changed the concept for the slide today
so the first universal common ancestor
and what's before what we all share now
is much different
and a much bigger unknown
I tend to believe that it involved
some universal molecules that are already
that we share as well
probably not the code but I'm looking
forward to see more work in terms of different molecules
and different possible pathways is what Sarah and Lee are exploring
Yeah, and I think
some of our work can kind of
corroborate what you're saying Joanna because I didn't show this stuff
but we always see you have a higher universality
and compounds used across all modern life then you do reactions
then you do enzyme functions so there's sort of a hierarchy
of universality to which people don't usually talk about
and it also depends if you're talking about universality
across individual organisms or universality across ecosystems
and I personally tend to think of Luca as an ecosystem
level property not an individual
and a lot of other people have worked on that
and suggested that including Nigel that's going to talk tomorrow
has worked quite a lot on that set of ideas
so I think we just have to be very careful what we're talking about
and I think the way I think about it is much more similar to what Joanna was saying
it's the first sort of organized chemistry
we had that we could call life that has some
ancestry today in terms of what
biochemical reactions were happening
and that's what we're trying to reconstruct
Yeah, this hierarchy is very clear
even when you go from molecules to reactions
to genes in terms of genes when we started
sequencing more and more genomes we saw
wow it's almost nothing is conserved
like we have shared function
but what encodes for that
is very non-orthologous, non-universal
so that universality is
the hierarchy is very clear
Okay
Well I guess I was just
trying to emphasize that all speakers
are on the panel discussion so are there anyone
is there anyone who would like to chip in
from the speaker list?
So while speakers think of a question
I'm going back to the first question from the Q&A
and it's quite interesting it's a theoretical question
and it's related to I think
Goethe's work, Goethe's incompleteness theorem I suppose
and strong emergence, I'm not an expert now
but I guess it says something that you
can't calculate everything
it's a sort of axiomatic ingredient that you can't prove
so I guess if I understand this correctly
if it applied to the origin of life
we might encounter problems
that we have to take it as a given
we can't compute it essentially, we can't predict it
I don't know if I understood this question correctly
but if there's any other theorist
Joanna put that out
on her slide so I guess Joanna
may want to elaborate on that
Yeah I burned myself why did I do this
I'm not a mathematician or a philosopher but
yes this is an argument that is made
I don't think there is a clear proof
of strong emergence in Goethe's work
for many reasons but
Goethe's statement so the ones that
have to
have to be inserted in a theory
independently of its axioms
their existence means that the theory
is explanatory without external axioms
that will never be predictable
from within the theory so in a very
formal way I think there is
some kind of relation
but I'm not a philosopher or a mathematician so I would not
know if that is proof I hope someone can help me out here
I just a quick comment on it
just building out what Joanna was saying
a key feature is you have to describe the system
from outside itself to see any of the issues
if you have a Turing machine
you can't predict if a program is going to halt
but if you put that Turing machine in the program into another Turing machine
then you can talk about properties of that system together
but that Turing machine you put them in
you won't know if it will halt on that program
you can't tell the system completely from the outside
but you can't describe it internally because it doesn't have all the information
about itself
so I think there's a couple places where people talk about this being relevant to
physics of life because life looks like it's a self-referential system
and you might have state dependent dynamics
in the way that a Turing machine has state dependent dynamics
that the rules actually depend on the state of the machine and the state of the tape
and that's very different than the way we talk about dynamical systems and physics
and that doesn't depend on the state of the machine
it just depends on the law which you know is
well it kind of does but in a really trivial way
and Nigel would be you know I see he's turned his camera on
so he should be talking about this
but I think also some of these issues arise
because of the way that we write down the laws of physics as they exist now
and they're not consistent with talking about
self-referential features or state dependent dynamical laws
here have worked on those kind of features. I'm going to pass to Nigel because
I really want to hear what he's going to say.
Thanks for the really interesting session
I just wanted to jump in here because I heard the discussion was being in the direction
and I'll cover a little bit in my talk tomorrow but only
very quickly of course but
I don't think I agree with the idea of emergence as being
something surprising that
comes out of the system or unexpected because
first is a feature of your ignorance
you could start off with a magnet and say
oh wow I called it down and I went
from a paramagnetic phase to a ferromagnetic phase
who knew that would happen but in fact
if you write down the correct Hamiltonian
and you do the correct statistical mechanics you will indeed
be able to predict that there is no surprise
but it is certainly emergence because the emergent properties
are the emergent rigidity, the spin wave
stiffness and other properties that characterize the
collective order that arises from local interactions
so I would differ from the
characterisation of the emergence
as being something surprising and sort of not
cut into the theory. Now as I said
when we get to evolution
there's this notion of self-referentiality
and I don't know who was the first people to
talk about that certainly Carl
Rose and I wrote a lot about it
about 10 or more years ago but
the idea is that what distinguishes
physical and biological systems is that
the biological systems essentially can change
the rules by which they operate
and the rules by which they change those rules are themselves
subject to change because their biological laws are said
and so you get this infinite regress
and where the connection to Girdel's theorem comes in
is that if you know the state of a system now
you can't predict the state in the future, not because you can't predict it
but because you don't even know what the axes are
of the phase space because it is generating
new phase space, it is generating new emergent
degrees of freedom that then have their own axes
of space and so that's the reason why
I think you have this notion of
perhaps Girdel undecidable in the
dynamics of evolving systems so I think once you distinguish
physical and biological systems in the sense that the physical systems
are a subset of biological systems
biological systems are an example of systems
which self-program themselves
and physical systems are examples of systems
that self-programming is already done and nothing active happens
and I think that's what differentiates living systems
from purely physical, boring systems
that we study in physics departments
so I don't know if that helps the discussion but anyway
I thought I'd jump in and...
If I can follow up on it so
because the sequence space is so large and you have so many
different ways where to go
that's what you're saying that you have feedback possibilities
Actually it's not because I don't think secret space is
adequate to describe evolving systems
in other words the idea that if I just know the genotype
I know everything, I know the phenotype, that's completely wrong
because the emergence
comes from the interaction between the living system
in fact I'll show this in my talk tomorrow and when you try to understand
the structure of phylogenetic trees
you actually need to understand something about the ecosystem
dynamics and that sort of collective behaviour
so I think, I mean certainly
the emergence of biomolecules
is absolutely critical to think about sequence space
but if one is trying to think about the self-referentiality
and the open-ended growth of complexity, which is what I thought
we were discussing here, then I think sequence space is not
the right space to be using
but would you agree that it's just the sequence space of all the molecules
you know the cooperative sequence space
with the boundaries or
The whole point about emergence is that when you have
collective behaviour then you lose
the connection to the lower
line degrees of freedom except through
parameters that are at least
in simple systems come in as phenomenal constants
through ideas like renormalisation group
so I think
Jesus, what the heck
stop
throw it out the window
I will, thank you Timo
because I paid my phone bill
so I think
you could look at the microscopic configurations of a fair magnet
and look at the spin system
but that won't tell you very much about
how a spin wave is propagating through the system
and that's the point
the whole point about emergence is you have to talk about the level of description
of the objects that are created, the macroscopic objects
and then you basically lose the connection
to the microscopic degrees of freedom
in my example of say the fair magnet, all that happens is everything that's happening
between the spins and their configurations
and the way that they interact
through exchange interactions from quantum mechanics
all of that does get bundled in to the
coefficient in the spin wave stiffness
so
that's how you can get universal descriptions of systems
but the flip side of that is that you cut
the connection to the microscopic degrees of freedom so you don't see them anymore
except through certain renormalised parameters
but the mechanism of Girdel is a little bit the different thing
right?
That is a different thing
I agree with you
So we have two reasons why it's very hard to go down
to the origin of life to explain it
either Girdel or emergence which makes it really hard
to understand the lower levels I suppose
I don't know that Girdel helps us understand
the origin of life, I wouldn't say that at all
and I don't even know if it's true
but I think
and I'm not the only person who's thought about Girdel's there and there's other
people who have as well but I think
what I want to talk about the emergence of life as opposed to the origin of life
one is talking about what are the
generic universal processes
that the emergence of life on Earth is
an example of and that would presumably govern the emergence of life
on say in the global oceans of liquid water
underneath the ice caps of Enceladus or Europa for example
I also just can point out briefly
that most of these issues arise because of the way we write
laws of physics with an initial state and a fixed law
of motion and so some of these problems are just because
of the way we structure physical theories and if we have a different way
of building those theories they might not have the same problems
that physics has and why physics looks different than biology
because there's an underlying theory that doesn't have those constraints
on it.
Okay.
Hey, in interest of the time
I think we break here
and take a little bit over time
so we take maybe a very short break
and that's two, three minutes and then we continue with the next session
so I wanted to thank again all the speakers
and all the people contributing to the discussion
and we see you in a couple minutes.
Cool.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Thank you.
Sir, you are now on live.
Sir, you are now on live.
Sir, you are now on live.
Can you see the slide?
I can see it.
Okay, so
welcome back everyone after this short break.
We continue with the next session and
Sarah will introduce the speakers.
Yeah, Robert, are you able to pull up the slide
for the second set of speakers?
Am I sharing my slide?
Yeah, we have the slide introducing the speakers.
Sorry.
My computer is very slow so I could load it but it might take five minutes.
Yeah, I wanted to show the slide
to introduce the next session.
Yes.
So Sarah, do you want to quickly introduce the speakers?
Sure, I can do that.
I'll just see if I can share my slides because it's just very slow on my hand.
Sorry.
I'm showing the slide right now, Sarah.
No, Robert, you haven't shared the slide yet.
We don't have your slide yet. Robert, can you share it?
Yeah, please.
Well, while we're pulling up this slide,
just so we don't delay further, I can start introducing
our next set of speakers and that slide should appear in a moment.
So hi everyone, welcome to our second session
which is called Defying
the Second Law of Thermodynamics. So I suspect we'll
find a little bit about what that provocative title means
in a few minutes. We have three
excellent speakers lined up for the session that are going to give talks live
and also fourth speaker
that had a video sent out earlier today.
So I'll go through and introduce our speakers.
Our first speaker for this session is going to be
Suzanne, sorry,
Udo Seyfert
and you
who is a professor
of theoretical physics at the University of Stuttgart
and is really a leader in
the field of stochastic thermodynamics.
And then next up we have Jeremy England
who's going to be talking about self-organization of
life-like behaviors and their properties
and has really been leading a lot of efforts about trying to
understand from thermodynamic principles
the emergence of life-like properties.
And then we have Pablo Satari who
talks about stochastic thermodynamics and bio-energetics
and has some very exciting
things to say there. And then the talk that we have
recording for you is
Suzanne Still's talk. So please
keep an eye out for that and then we'll have the panel discussion afterwards.
So I'm going to pass over
up here so I finally came up
to our first speaker, Udo Seyfert
and
that should
So let's just take a second to switch over.
Udo, you should be able to share your slides now.
He might have left briefly
to rejoin. Oh, I see.
I see him on here. No access.
No access.
No access.
No access.
No access.
No access.
I see him on here. No access.
So
Udo doesn't seem to have access anymore.
Okay, he's coming back.
Hey, Udo. Glad you could join.
You're still muted.
Okay, we had a crush here.
So I missed the introduction.
Am I supposed to start?
Yes.
Okay, good. Oh, fine. You introduced
as well as here.
This one is here.
Good.
So can you see that, Robert? Yes.
Okay, perfect. So
thank you very much for inviting me, Robert, and
the other organizers as well and inviting me despite
the fact that I'm not working at the origin of life.
So I thought what I will do
today and you see it in the somewhat
cautiously formulated title that I would like
to highlight a few insights from stochastic
thermodynamics which may be relevant
hopefully to the origin of life
and the early stages of life.
So what is stochastic
thermodynamics about? It's basically
summarized here in this slide, the basic philosophy.
So we are trying to understand
and to explore whether and how the rules
have been developed to understand steam engines,
i.e. the different ways how to transform
energies into each other, whether and how
these laws can be applied to much more
smaller engines, molecular motors.
Here you see this F180Pase
where due to experimental progress over the last
20 years, one can observe single 120
degree steps when this gamma purple
subunit turns around.
So the question is whether the thermodynamic
laws which have been developed on the left
can be applied to systems on the right.
That's what we're basically trying to understand
in stochastic thermodynamics and
community has made quite some progress
and I want to highlight a few of this
progress and then perhaps we can discuss later
on to the theme of the conference today.
So my first point is
in aqueous solution and under non-equilibrium
conditions, temperature and chemical potential
of small molecules, let's say like ATP
or phosphate, are locally well defined
and these values
for temperature and chemical potential, they will enter
kinetic constraints.
So if you have an enzyme
like this green one which has different conformations
or different states and which interacts
with substrate molecules like ATP
or ATP or phosphate
with chemical reactions like this one here
and the point is that in each
of these different states of the enzyme
you can associate a free energy
and depending on the concentration of these molecules
you can associate a chemical
difference for instance for this type of
catalyzed reaction and then one
of the insights is that
there is kinetics, yes, but this kinetics is constrained
by the fact that the log ratio
of the rates typically has to obey
these kind of thermodynamic constraints.
And we have also learned that if we look at such a single reaction
in aqueous solution
that we can
identify a first law for such systems
in this case for instance
if the enzyme goes from N to M
the internal energy changes, the energy of the surrounding solution
changes and there is some contribution to it.
And we also have expressions for the
entropy production in such a situation so
when we look at the current of going from N to M
the total entropy production is the sum
over all these currents and using that constraint
and only by using that constraint you can show
that this entropy production
is positive.
And this holds not only for a single
reaction event or single enzyme, you can build
this kind of theory for whole biochemical
reaction networks and I guess it could be applied
to some of the systems we have seen in the previous talks.
Okay, so
certainly these are not equilibrium systems
because for instance the ATP
reaction is not in equilibrium
but there are constraints you cannot choose
anyways you want.
The second point is fluctuations in these small systems
are typically non Gaussian, even rare fluctuations
are thermodynamically constrained, the initial
distribution matters.
So an essential tool
is to consider entropy
total entropy production as a quantitative
measure of broken time reversal symmetry.
So if you have any trajectory X of t in some space
you look at the time reverse trajectory
and then the total entropy production along such
a trajectory is given by the log ratio of the probability
of observing this trajectory
compared to the probability of observing the time reverse
trajectory.
And with this definition once you have that it's easy to derive
fluctuation theorems like this one
which shows you that e to the minus total entropy production
averaged will be always one
and from this by Jensen you get a second law.
The key point is this is true for any initial distribution
you don't have to start in equilibrium or in a non equilibrium steady state
it's true for any duration of the experiment
however there's an important constraint which I want to
highlight, each microstate for that to be true
each microstate must have an initially
a non zero probability.
This is not the case you get different
laws or relations
and somewhat provocatively I have sketched here one
so at the left hand side
we have time equal to zero and I've partitioned
all microstates let's say in a test tube
or in some bigger aquarium or whatever
into the set of that
microstate and the potential set of living months
the initial time t equal to zero
all probability is in the dead space
and then there's a certain probability for the living
states to emerge after time t
and there's a probability for them to survive
after time
2t and the relation which you then get
is that e to the minus total entropy production
under the condition that this red
trajectory happen that emergence has
happened is for instance one minus the
survival probability to go from living at time
t to living at time 2t and then
by Jensen you get for instance that the total
entropy production along this red emergence
is will be larger than the log
one over one minus survival probability
so if the survival probability is very large
then the mean entropy production had to be
substantially positive stronger than the second log
and I guess we'll hear more on this
in Jeremy's talk later
these integral relations are typically
just one constraint on what can happen
and for certain situations like in a non-equilibrium
steady state there are stronger constraints
like the detailed fluctuation theorem
that trains the whole probability distribution
but the warning is and the important point is
again you have to start in the non-equilibrium
steady state otherwise you can't use a relation
like this for entropy production and just as a brief
illustration for the fact that fluctuations are
non Gaussian I mean this is not a living system but it's a small
driven system out of equilibrium particle
driven across the periodic potential and here you see
very much non Gaussian still they obey
this red box. A second insight
perhaps more important is
precision doesn't come perfectly. We had already
in Robert's talk the reminder
on a Hopfield and Minio theory
of copying with templates
and the fact that the equilibrium
discrimination wouldn't be quite enough
at the expense of a non-equilibrium reaction
you can get essentially the square
of this error rate. Now I want to
introduce you to not this type of
precision in copying
but on what you could call temporal precision.
So suppose you ask
the following question and I want to motivate it with
the present day situation not with the origin of life
suppose you want to run this watch
and you want to run it at finite temperature
so it's clear that there will be fluctuations and the watch will not be
infinitely precise. So the question is
does a more precise clock
need more energy from its battery
and the answer is yes and if you want to
get numbers for instance if you want to measure
the length of the day with a precision of one second
we now understand that the cost
of that measurement will be
at least 10 to the minus h rule
i.e. at room temperature i.e. 2 times
10 to the 10 kVt. So how do we get
this kind of result?
Well we built a simple clock
and the simplest one is the asymmetric random
so each step of the hand of such a clock
will involve the let's say hydrolysis
of ATP and then you just
apply the rules of the random walk
I don't have to go through this here in detail
what you then find is that
what we call the uncertainty which is defined as the variance
of let's say after one minute
typically 160 steps
but sometimes you've got 58, sometimes 62
which leads to this uncertainty
this uncertainty should be small
but there will be a cost associated with it
the cost is the entropy production times the time
and we know from stochastic thermodynamics that
the entropy production for a single step is the log ratio
of going to the right versus going to the left
and this log ratio again
is associated with the free energy difference associated
with the process that drives the system to the right
that drives the clock
and when you combine these relations you'll find that
the cost times the uncertainty squared
is larger than 2 kg. Now this would be
just a curiosity but
we saw in simulating much larger systems
different networks looking at limiting cases
that this relation is true for any process
which can be based on a stationary
Markov process and that was later proven by
Tothini which and Jeremy England are co-workers
so you could call this the inevitable universal
cost of any precise process
of temporal precision or more technically
for any current in such a network
and current is something which is odd under time reversal
and you can associate a weight with each link
you'll find this little red box
the total entropy production in the system
is larger than the current squared divided by the fluctuations
of the current. D.J. is the diffusion coefficient
which is the signature of the fluctuations
of such a current and that's
now known to be a universal relation
and this has a consequences
and I want to formulate this consequence
in the following way any molecular machine
is subject to a trade-off between three criteria
between efficiency
between power and reliability
i.e. small fluctuations
this is true under non-equilibrium steady state conditions
if you have external periodic driving
these constraints can be alleviated
and again I want to illustrate it
in a biological system
a molecular motor kinasein running
along this microtubule
and running against an externally imposed force
which is exerted by a laser trap
that acts on the bead which is attached to the molecule
now this here what you can measure then is the velocity
you can measure the fluctuations in the velocity
which is called the fusion coefficient
the ratio is typically quoted
and these are experimental data from Bloch School
from 20 years ago as a function of the load
at a certain activity concentration
now you take this data and you combine it
with the uncertainty relation and you find a really interesting
result on the efficiency
of such a machine
so the thermodynamic efficiency is given by the power output
by the input
power is velocity against the force
the input is not known, that's the key point
you do not know how many ATPs the motor needs
but we know that the input is the output
plus the dissipation
and for the dissipation we have the inequality
so you see that the efficiency of the motor is constrained
by a ratio
that is only experimentally measurable quantities
and taking the same data now and overlaying this curve
if you take this data point where the motor runs
against a two piconewton load
we find from our theory
that given this measured fluctuations
and the measured velocity the motor here
this is 45% line the orange line
the motor is at most 45% efficient
in transforming chemical energy
into mechanical motion
and that holds us without assuming
any specific model of the motor
just given the experimental conditions
and the tradeoff I was alluding to
is essentially the same relation formulated in a different way
the power of any such machine
is constrained by the distance the efficiency
has to the maximum value 1
these are all isothermal machines
the highest efficiency is 1
so as you approach this upper limit
the power typically vanishes but there is a pre-factor which are the fluctuations
now when you have additional
periodic driving from the external
agent like the sun
periodic driving 24 hours cycle for instance
in the external factory which is this green one
which can become quite small
and in this case for this external periodic driving
there is the option of
dissipation this precision so in that case
the external environment
pays for this precision
and the system itself doesn't have to
to pay so with this
I suppose and I guess the big question is
in which sense these relations
which are true in the framework I described
in which sense these relations are helpful
for understanding the key questions
this conference is about so
thanks so much happy to take questions
excellent thank you for the wonderful talk
that was really quite intriguing
I don't have any questions in the chat right now but I actually do have a question
since you're talking about efficiency
and time scales there's always this
critical question in origins of life about
how long the process takes
because the origins of life seem to happen very quickly
at least on geological time scales not necessarily chemical time scales
do you see any promise
for some of the things that you've been talking about in bounding
sort of how efficient the first
systems needed to be or what the time scales were
for the process or these kind of things
well I mean the theory is certainly so far
in a sense is made for specific
molecular machines like motors or perhaps
the ribostoms or whatever
so whether it can be applied
to that big system which
takes life at the first time I think that's
a different story so I see it
more immediate applicability
is perhaps looking at systems
data will explore at some point
I wouldn't
quite dare to
apply it to a process which runs over
a considerable long time
but those external conditions may also change
so most of what I said applies to steady state conditions
and I imagine for many processes
we are in fact in steady state conditions
right in ourselves we are non-equilibrium
but we have 37 degrees of temperature
we have typical delta mu
for the ATP hydrolysis of 20 kBt
so that was my first point I mean despite the fact that
non-equilibrium and perhaps slightly
disagreeing with what Dieter said
we do have a theory of physics
theory for non-equilibrium for a certain type of non-equilibrium
non-equilibrium in aqueous solution
certain concentrations of these small molecules
and then the big ones are subject
to these constraints
Excellent thank you
I mean Udo, can you hear me?
Yes I can hear you
Just to follow up a bit
what we find quite interesting is if you have
longer strands 12 more of RNA DNA all kind of sequences
if you make it
thermally oscillate between two points
they are having a hard time to be in equilibrium
they are always kinetically disassociate them
and try to find themselves and always
so I was wondering how much
defined temperature are all very well defined
how much of your theory could be applied to that
because it would be interesting to see which sequences
which classes can actually meet under these non-equilibrium
thermocycling in a very efficient way
because they will drive the evolution of this pool of
polymers
you cycle the temperature
and that's the next class in complexity
compared to steady states
but all of this is perfectly applicable
the key point is that then the rates become time dependent
as well in the periodic fashion
because the temperature cycles
The on-rates smallest
same off-rates change
and I was just wondering how much
complexity you could think of
if they start to like it
the funny story is
for those 12-mers if you have all the four bases
you can run that and if you don't give it enough time
at the cold temperatures they just don't find each other
so clearly they are not
equilibrated but if some sequences
can run the game and can find themselves
because they have whatever on-rate advantage
or they will completely exponentially
grow out of that system so even such a very
simple thing could show very interesting dynamics
yeah
would be worth exploring certainly
we have a few more questions in the chat
I'm just going to ask one really quick one before we move to our next speaker
we can get to the other questions in the panel discussion
this one should be very quick which is just which paper
if you can restate how the derivation relating entropy generation
of emergence to survival
I made this sketch
when I prepared the talk but Jeremy
certainly has a more sophisticated version of this and it's his paper
in jkemphis 1213
so this is a perfect segue then to our next talk
so with that I'm going to segue into introducing Jeremy
so
Udo I still see your slide on my screen so maybe if you can stop sharing
and then we'll get Jeremy up
and thanks again that was fantastic I'm looking forward to it
thank you
can you kill the sharing because
just kill the sharing
and Jeremy are you ready?
we can hear you
okay good
we can hear you
I clicked on what I thought was
unmuted and then it somehow minimized the window so I was trying to go back
and it also looked
well it was very tiny like it was still muted so I didn't realize I could be heard
I'm glad I didn't curse word loudly
I'm glad I did
I'm glad I didn't realize I could be heard I'm glad I didn't curse word loudly
so
now
I will try again to show you my screen right so
I want to do desktop
and now
I am sharing my desktop are you able to see
the slides yet
excellent
great
so
I'm going to
skip over this part to save on time a little bit
so let's start off with this idea
when we think about
the organization of living things and we say
that we think that they are well adapted to their environment
and that they are somehow architecturally impressive
and that they accomplish in relationship to their environment
it's easiest for us to think of that
in biological terms meaning
or let's say to be generous biochemical terms that there are things that need to happen
in order to help a living thing to survive and reproduce
and if they can't happen then things die
and so adaptation and selection and all of that good stuff
is coming from the question of whether the structure
of the living system is well suited to the state of the environment
in such a way that it can persist there and maybe make copies of itself
so if we have a bacterium for example
we could ask whether it is
able to metabolize sugars in its environment
it's going to break down these sugars and make the enzymatic wheels turn
and run things like
clocks like what I was referring to in the right direction
and do all the detail balance breaking that requires that fueling
and if you aren't able to break down the sugar
in the environment then it may as well be from your perspective
like there's no food there at all
and what's interesting I think in the biological example we readily appreciate
that of course if you mutate the genome of this bacterium
you might destroy its ability to metabolize some food
because the enzyme is going to be different and it's not going to work
and we think of that in terms of change in genotype and change in phenotype
but you could also just think of it as a change
in physical state or physical composition
I have a bunch of atoms that can put them together in different ways
and I could make one kind of bacterium out of it
or another kind of bacterium out of the same building blocks
and that's a much more radical kind of
reorganization of the matter than just changing something in the genome
but similarly
it's sort of obvious or trivial to say if I took the atoms of the living thing
and I randomly rearranged those constituent parts
then I wouldn't typically get something that was as good
as catalyzing the breakdown of a particular sugar
that's in the environment or whatever other
kind of interaction or relationship I'm interested in
and that points to I think something basic about our notion of
function and functional success
and the relationship between structure and function which is that
whenever we see something good at something we're implicitly comparing it
to a random rearrangement of its constituent parts
because if it weren't better at doing whatever
we're interested in than the random rearrangement
then it's hard to say that it has function or that it has form that
begets function because random things
are not distinguishable so that's
all very well and good for biological systems
and I think the point now is to try to think
what does it mean to generalize this
and this goes back to a point that I was struck by
hearing Joannis talk earlier that if you have just a bunch of chemicals
that have different concentrations and
you're not going to ask the question what is special about
the distribution in chemical space that I'm observing
you need some kind of
talisman in the environment to sort of compare
to the degree that you can talk about
a particular ability or a particular relationship to the environment
that that matter has now you can start saying
well now let me compare the state that I observe
to perhaps random mother arrangements or
an arrangement I would take from some null distribution
like thermal equilibrium and you start to be able to notice
the exceptionality of the particular arrangements
or ensemble of arrangements that you're able to observe
to me I think that's the essence of the starting point of saying
how do we understand the emergence of
life like this we should be thinking about what is life
good at with respect to its environment and it's a list of things
and given that it's good at those things what
can we now say about how matter might
end up becoming exceptionally organized
in that kind of relationship and I'll just mention
there are different kinds of things that living things are good at
they persist meaning they don't fall apart once they form
that sounds trivial but shouldn't be totally trivial
thermodynamically speaking because it's all from fluctuations
self-replicate, they harvest energy, they tell
time like Udo was discussing, they make predictions
about their surroundings and act out those predictions
so life is this big semantic bundle of different things
that can note the idea of life together
and on their own they maybe are more primitive
things that we can build physical models of so that's
the program that I would recommend is dividing and conquering
and saying let's think about the different things that living things are good at
and let's try to make physical theories of how they might get
good at them, how humps of naive matter might get good
at those things and then maybe we'll make some progress
in understanding how life like
emergence converges from different
factors of life likeness that maybe have
separate ways of getting going so
one of the things I've tried to argue for and how to approach
thinking about this is what we call
dissipative adaptation and this really is a very high level
argument just from an algebraic rearrangement
of an equation that also appeared
in Udo slides that is stochastic thermodynamics
we have this idea that entropy production in the surroundings
is what allows you to break time reversal symmetry
and so you get that from the Crookes relation and if you just do
a little bit of rearranging things you can write down
a generalization of the forward Boltzmann distribution
for a non-equilibrium process using that same kind of expression
so basically you still have a Boltzmann weight telling you
whether J or K is more likely and it has to do
with their relative energy but also there are other things
that are very non-equilibrium like kinetic factors
and this middle factor here is about kinetic accessibility
and the last factor on the right is about the extra
entropy production you're doing essentially the work
absorption from the surroundings on the way to
your destination and the point I try to make here is that
the fact that ice exists is something that we connect
very intuitively to the notion that lowering
your energy is going to make you more probable
in the Boltzmann distribution we could also ask
about other factors in this equation
and whether there are other kinds of organization that
the explanation for why they're possible comes
not from the lowering of energy but instead for example
from the work history from the idea that on the way to where you're going
you absorbed a lot of extra work from the environment
and I'll point out that just because ice exists
and can exist doesn't mean that lowering your energy is always
what you do you can't predict the outcome of any system
by just saying well the Boltzmann distribution says low energy is more probable
so you always are in some crystalline state that's not true
nonetheless the fact that that
weight is on the scale implies the existence of forms
of organization that end up extramising that factor
and I think what's really exciting is to now look at forms
of organization that might end up extramising the other factor
if I think about a collection of matter
the environment that it's in and the work
that that environment could do on it what is going to be
the argument for why I might end up in a state of organization
that reflects the work history aspect of this
overall term
governing the likelihood of outcomes when is it going to be
the case that the history of how much energy I absorbed
along my way to where I'm going is kind of the reason I'm there
and I think that the particularly important point here is
as we know you have
situations in which it's clear that the shape
or the state of the system is going to control
the access of the system to energy from
a fixed environment so I have a non-equilibrium drive
with a certain frequency and if I'm in a particular
shape then that shape
might resonate a lot and absorb a lot of energy
or if I take the same matter and reshape it
then I might resonate less and absorb less energy
and that could have very consequential
impacts on the eventual state of organization
of the system because I might shatter the glass in one case
and not shatter it in another case so this is the ultimate
feedback loop that we have to close when thinking about this
the flow of energy is both
non-equilibrium dynamics and also
it is something that's controlled by your shape
so if I have matter that's in some state
and the state that I'm in controls my access to external drives
and then also my access to those external drives impacts
the way that I change my state and then I keep on doing that
I close that loop and I iterate what I'm going to get is a
biased exploration of the space of possible configurations
and I see the potential then for
the particular ways the environment
is capable of pushing on the system to be
written into the eventual states towards which the system
gets biased so it's about the emergence
of a fine-tuned matching relationship between the state
of the system and the particular pattern of the environment
and so it's a sort of input-output
or a response property kind of evolution
that can be a generalized form of selection
and I look for even in cases where you don't have self-copying things
where that's the underlying mechanism for how
such a relationship could emerge so
sorry my slide is further than for a second
did I jump over one or sorry
there we go so I just want to briefly mention
two examples where you see this kind of behavior and I think that
what they point to is the broader potential
either in non-equilibrium many chemical
spaces or in active matter
for there to be new kinds of experiments we could do
if we take the right sort of
lessons from these simple examples they're both
examples of systems where you have multiple degrees of
freedom it's kind of a many-body system there's some quench disorder
and how different pieces interact there's non-linearity
so you have this kind of rugged landscape of something
to explore and then you're going to have a pattern
in the way the system is being driven maybe it's a frequency
maybe it's some other more complicated predictability
and how the system is being poked in this case this is a
mechanical network where you just have masses
in two dimensions with short bonds
or rather I should say bonds that either like to be
shorter long they're just by stable but they can't break
and which masses are bonded to which is quench disorder
and I take one of these masses and I just wiggle it with some chosen frequency
and amplitude and direction and what's interesting
is that at short times what the system does is it kind of
thermalizes the energy it absorbs so it's non-linear
it's many body there's a lot of chaotic things
that you could imagine start to happen as you start pushing on the system
enough to jump over barriers and so at short
times the system just looks like it's kind of heating up and absorbing the energy
and doing very random things and then at long times
the rate of work absorption settles down the drive hasn't changed
but the system stops absorbing as much work and it's kind of stuck
now in fact without thermal noise if you just
had Newtonian mechanics with drag this would be an absorbing
attractor a closed orbit in
phase space where the system is basically
finding a particular combination
of short and long bonds whose local response properties
are well matched to the drive so that the work
that is absorbed doesn't end up rearranging you further
so it's a highly exceptional state
and the way that you can tell that is if you just change the drive
then you get something new so here we're just switching between
oscillating the drive at fixed amplitude and frequency
and then instead oscillating the driven particle
at fixed positional amplitude and frequency
instead of forcing amplitude so you just go back and forth
and every time you change the drive the system jumps back
up and work absorption rearranges finds a new
table arrangement that has a sort of phenotype or
a collective behavior that's well matched to the pattern of driving
and then it settles down again and sort of stuck there
what's interesting is that
you're in one case reducing resonance because
when force amplitude is being fixed and you want to resonate less
and the other case you're coupling your slack
modes to the driven particle so that they're not as stiff
and less work gets done as you move the driven particle
back and forth so it's actually in terms of response properties
quite global rearrangements of what the system is doing
and the other thing I'll mention as he slides out
of order is that you really should think of it
as being kind of like the difference between genotypic and
phenotypic change because every time you do that
simulation you get a different state that is well adapted
or fine tuned to the drive and it's adapted
in the same way the work absorption has gone down
but the bonds are different in terms of which ones are short
and long a hamming distance of that whole ensemble
diverges over time and then sort of plateaus when they all
reach their different stable states so
you get to explore a high dimensional space of behavioral
possibility and there's lots of different microscopic
ways that you could choose to have the same phenotypic or
collective behavior that ends up being
adapted or matched to the environment and I like to show
you of this one because it's kind of a particularly fun example
it's a little bit cherry picked but it just gives you
a sense of what happened. I start wiggling the particle
I have this random network first the energy kind of thermalizes
and things randomly jumble around and then
eventually I end up at later times in this state that's much more stable
and can't be rearranged by this drive anymore
but what's interesting is actually on a longer time scale
it's doing this kind of motor duty cycle where the energy
that's being absorbed by the driven particle is pumping
some of the free degrees of freedom around in a circle that breaks
detail balance and so you didn't
select for that particular behavior deliberately
but just from the fact that you have a driven system
that's settling and reducing the flexibility
of many of its degrees of freedom some of the remaining free ones
end up getting pumped in these detail balance breaking ways
and so it's not actually so difficult to make a very primitive
accident.
So sorry these slides are transitioning
a little bit slowly so I'll skip over this
or maybe we could
come back to it if people have questions about it but there's a general
framework in which you can think about why you think models
like this should apply or behaviors like this should
pop up in a lot of different kinds of systems
and if people are curious we can return to it. I just want to mention
our most recent paper that came out in this topic area
was the first experimental test of these ideas
and the idea was to try to look at this in a swarm robotic setting
so what you do is you say
let me try to predict the relationship
or let me try to predict the steady state probability of a given configuration
of the system and the way that I do that is by looking at
how work being absorbed from drive is giving rise to random motion
and the idea being that the more that
you absorb causes randomizing motion the more you're going to kind of diffuse
away and try out a new state but if you find a state
that has a kind of fine tune matching of response properties to that drive
so that you stay in some orderly
subset of arrangements rather than getting
randomized and knocked around in chaos by the drive
then you're going to dwell there for longer and so at long
times you end up being able to look at this local response
property for how driving is transduced into motion
and you can predict the steady state behavior at long times
and excitingly
you can do this in an experimental setting with
robots that were developed in the law of Dan Goldman at Georgia Tech
that are called SMARTICLES. What's cool about them is that they only move
when they push on each other and so everything is very
collective and very dynamical in terms of what kinds of
self-organization you can see
and if you take these and put them in a ring
then they can do these very organized dances
in ways that are kind of surprising with these rare
chaotic flights in between the stable attractor dances
so this dance that it now got into
is pretty stable and it will do this for a while
and then let's see does it go into something else eventually
so it does it for a while and see now it found a different arrangement
but that one is going to be stable and it will hang out that way for a while
so the question is
can you predict the behavior in general from looking at the local dynamics
or the local response properties and indeed
you can so that the steady state probability
is predicted well by this idea of rattling
that's how the driving is producing
local randomizing motion both
in terms of the amplitude of that motion and how random it is
and you also can even use this as a selection principle
where you can say let me combine different patterns of drives
and actually pick out the states that have overlapping matching
to that drive so every drive you choose
it will be totally different states that are well matched to that drive
so if I combine new drives I can say let me pick out the states
that matches to both of them and I can actually select
for a very particular set of configurations
I think the ultimate point here is
and this is something we could study
systematically is that if your drive
is quite random then
you can't have emergent order respond to it
in the system but if your drive has some kind of pattern
to it some kind of structure some kind of lower entropy predictability
to it then it raises the possibility that there
could be an emergent responsive low entropy
in the steady state distribution and as a result
I think the argument we're making
for how you can do new experiments in
these species chemistry or inactive matter
is to think about can I create a
pattern in how I'm influencing the system that has enough
of a barcode so to speak that I will be able to
recognize the specialness and the fine tunedness
of what the system gives back to me in terms of its behavior
and I think that it might be the case that
in a broad variety of systems where they're kind of
quasi disordered and active and they have
different dynamical states they might occupy in principle
that if we go in looking where we're giving special attention
to the pattern that we've chosen and how we try to
drive the system and then look at the matching
in the response then we may get new opportunities to see
different kinds of organization emergent active matter
some of which may remind us of things that are on the path
towards more lifelike behaviors and so
with that I will just
close and thank great many
brilliant people and
collaborators who helped to make some of this work
possible and also sources of funding
and support and lastly I'll just mention
I wrote a book that came out for general audiences last year
but actually I think it
is in another sense a letter to my scientific colleagues
just trying to sort of in one place explain a bunch
of ideas that I think are interesting in connection with this topic so
if anyone's interested that these are
pieces of information that might help in chasing it down
thanks very much.
Yeah, thank you so much.
Sarah you're muted.
Yeah, I'm gonna take it.
Can I just jump in and ask a question?
So, Jeremy, you mentioned a picot machine
on one of your slides and
in the 70s as you know he talked about the
dissipative structures and you talk about the dissipative
adaptation. So how would you know
for the non experts in the audience
how would you say what is the difference
so I guess he talked about linear thermodynamics and far from equilibrium
and maybe mobile.
Yeah, it's a good point to call out because
so I'll say first what
commonality there is and then
I think there are some very
important things that are not in common that have to be underlined so
I think when you get structure
away from equilibrium it
can be the case that something
appears to be optimized
as a result of the formation of that structure
and in general you know optimization is a great way of seeing the emergence
of what you call structure because
structure kind of requires order and low entropy
and also usually is based on some notion of relationship
which might be the thing
you're optimizing in a sense. And so pre-regine
had this result of taking the on-site relations
and demonstrating that in linear regime
non-equilibrium thermodynamics that you have this
reduction of the total rate of entropy production as you relax to the steady state
and that may sound familiar
in connection with someone I was talking about because there was this kind of falling
rate of work absorption. I know of no
rigorous connection between these ideas though because
we're talking about systems that are definitely
in the very non-linear regime for which
you can't motivate the idea
of an overall fall in entropy production from
argument. Indeed, it's clearly the case that there are
non-equilibrium systems that are far from equilibrium
that are not governed by some kind of
principle of minimal entropy production
in its average rate at the steady state. However, what's true
is that there's a subclass
of far from equilibrium non-linear systems
where you still can argue
why it might be the case that the system is going to have a tendency to
maximize and even perhaps minimize its rate of work absorption
over time. And so the
commonality there is that the same way, when you take any many body
system and you say, let me do an optimum of some
property that is a global result of
the arrangement of all the pieces, I'll end up getting
something that might look structured in some way. These are structures
that emerge from a
process that you can describe as having to do with
work absorption and energy dissipation.
But we shouldn't call them distributive structures because it's
not trying to be in contact with the same formalism
and the same theoretical motivation.
Excellent. Thank you, Jeremy.
In the interest of time, we're going to move on to our next speaker. We do have a few
questions that we might return to for you in the panel discussion.
But I think that was a really, really great talk.
So next up, I think if Jeremy can stop
sharing his screen, our next speaker is Pablo Cittari.
And I just want to point out that Pablo was asked on
rather short notice to step in to get the talk today. And we're really
grateful for him to join us.
And also to remind our audience that Suzanne Still, that was originally slated
to speak in this slot, has provided
a recorded talk that we invite you all to watch
in your time outside of the main session
of the meeting. And that will also be additional
engaging material for us. So with that,
I'm going to pass over to Pablo. We're very excited
that he's been able to join us today.
We're ready. Thank you.
Just give me a second because the computer is extremely slow with this
teams. Yeah.
Can you see this?
Thanks.
Yeah.
It's coming up.
Okay.
Thank you very much. I just hope it doesn't crash again.
It already crashed three times.
So yeah, I was given short notice.
Yeah.
So yeah, I was given short notice.
And because of that, I won't be able to focus too much
on the origin of life that I would like to see a couple
of things about the cellular thermodynamics.
So this is a topic that I've worked on
in the past and I'm slowly getting back into
and
well, maybe the role that was advocated.
Let's see what you think.
One of the good places to start is by something that we all feel more
less comfortable with, which is the success of thermodynamics
and I would argue that there are two main successes
in thermodynamics. I'm not sure there are many, but two that I
like to highlight today. One of them is that it allows
a low dimensional phenomenology of matter.
So ideal gas law is a good example of this.
Simple models of phase transitions are another example.
And today we'd like to think about this
as a case of dimensional reduction.
We know it's an entropy and we tend to think of
these four-dimensional descriptions
using the statistical physics technology.
However, the history was very lengthy
to get to these simple descriptions.
It started at least in the 1600s with
works like one of Boyle and this was
so long ago that the same old point was
where it's actually you have to look at the exact fractions of the two columns
to compare them and even plotting data was not
customary because the caps have died not too long ago
so it's not very standard but if you plot today this
data you can get this plot on Wikipedia. It's pretty
astonishing how well the scaling behaves.
So I think this is very
with evidence that this low dimensional description
is one of the early successes.
Later on what happened
was that one of the things that happened is that this
simple models were used as inspiration to
quantify the limits of thermal processes and
this required a huge deal of abstraction that is
sometimes taken before granted today which is going from designs
entropy designs like this one from James Butler,
steam engine to the Carnot engine.
So the description that Carnot made that we still find on textbooks today
is how a thermal engine should work.
Carnot cycle after that in the same work
and soon after we could formulate it in a pretty good shape
the first and second law of thermodynamics.
On the one hand we have low dimensional descriptions
of finding the right variables for systems
and on the other hand we have actual
thermodynamics so quantifying limits of thermal processes
now how do we take this knowledge
inspiration from this knowledge and bring it back to biology
so I think one approach
is to take the spirit of thermodynamics
so more than looking at the variables of thermodynamics
or the identities of thermodynamics
just taking the spirit of low dimensional phenomenology
of different cell or subsystems so we will talk briefly
about an ATP synphase
it's one of the many instances of a protein assembly
so during my research
I've been investigating what would be a good phenomenological description
of biological self assembly
in the cell and when you do that
you will come up with strange variables
so things like the heterogeneity of assembly
or protein loading which are not as standard
as thermodynamic variables.
The other approach which I worked more in the past
is actually applying the laws of thermodynamics to cell or systems
so for instance you have an ATP synphase
and it's a rotary motor
and you can describe it as a discrete state space
and calculate something like the production rate
study it as a function of the
rates that you may be able to determine experimentally
and use a lot of thermodynamics to say something about it
so Olivia much more focused on the first approach
but today I will talk a little bit about
the second because I think it's more in line with
this session
but to not leave everything in a very abstract way
for physicists
let me give you an overview of cell or energetics
so I don't know
I presume there's a lot of people in the audience
but many of them may not have
a good training in sub-biology so I think it doesn't hurt
to go over this
and the idea is that if you think of a simple microbial cell
something like E. coli
the first layer with the environment you have is the receptors
that may respond to properties such as temperature,
PAH or chemical concentration of different ligands
and as these environmental factors change
they fluctuate, these receptors will respond
and they will affect internal proteins called response regulators
and typically will consume energy
in order to carry out their function
so this energy comes from the hydrolysis of molecules
that have already been described such as ATP
and at the end of this process of signal transduction
at one stage what happens often
is that one of these response regulators will bind to DNA
maybe a transcription factor, it may assemble before binding
and it will result in the expression of a gene
what is the amount of more primitive time per cell
that this process, the information process
involves and you have the number there, it may not tell you too much number
we'll compare it with other numbers
so after the protein has bound to the DNA
what tends to happen or one of the things that can happen
is that a certain gene is first transcribed
and then translated
so this process again consumes ATP
this is the process of information copying and amplification
and the amount of ATP that is consumed, particularly in the translation state
is much larger than that information processing
it's actually one of the main process of energy consumption within the cell
finally these different proteins can do a number of things
one of them could be attaching to flagella
or to the motor of flagella
and the consequence of this is that this flagella motor will move
thus exerting mechanical work in the surrounding fluid
which will be dissipated into heat
flagella motor is
driven also by energy of course
but not by ATP hydrolysis
but by a protomotive force
and the amount of energy that it actually consumes is significantly larger
than the amount of energy involved in the signal transaction
but still smaller than that of translation protein expression
and these are sort of very classical systems
for physicists to study
or for people working in statistical physics
in order to get thermodynamics
but another one that maybe we're less
used to work with is metabolism
metabolism has already been touched on several times
and it's a central process
to the cell which involves energy convert
transformations and also mass transformations
and it tends to end with the synthesis of ATP
whether that's one of its fundamental processes
and in fact it's a very dissipative process
it's a bit hard to estimate but it comes close to translation
so these are the
some fundamental processes of the cell and we see all of them consume energy
of course it's not surprising and they consume energy in different amounts
and the question then is what thermodynamics can tell us
about these different systems
so I'm just going to present a very simple argument
which is sort of epitomizes some work that I didn't pass
and others as well and then I'm going to play the role
of an evil referee and criticize it
so the premise that as physicists
we pretend to use is that dissipation is somehow a product of function
so in some sense it's a trivial statement
in another sense we expect it to be an informative statement
so let's see how we can go about that
imagine you have a certain system, a cellular system
you can parametrize it
create a model and parametrize it with a set of parameters
PR which can be kinetic rates, it can be
radians, energy landscapes, some stiffness
constant and you expect to be able to estimate from this
things like the dissipation of this model
of this system as well as function
so in biological function of interest this can be something
like the accuracy or the speed
of those ratios, something that you consider to be biologically
desirable
and so then typically you can perform
a parametric perturbation on the
ATP driving and what you will see is clearly the dissipation will go up
and
in a few cases it has been observed that the function improves
and in some sense the idea here is that
dissipation is somehow the cost
of cellular function and this should clarify
the role of dissipation in cells
however there can be several problems
with this line of thinking
one of the problems is that dissipation may be suboptimal
in some sense, so what I mean by this is that if you have a function
that looks something along these lines, it's monotonically increasing
you would expect that
the data should fall somewhere in this line
or you have a good knowledge to be able to predict
the value of its function as well as the amount of dissipation
but often
or in some instances it has been noticed that the data actually falls
in these flat regions
and what I mean by this is that you could change the amount of dissipation
by a big margin and the function wouldn't change
and in some sense this leaves out a large amount
of dissipation unexplained
so the cause of this is more or less understood
it's just because the ATP of hydrolysis
in cell it's around 25 kT
which is very large
so if you add a couple of kTs from there
the reactions will see effectively irreversible
and one place where this is found is this type of
flatness is in similar transactions
information processing of sensitive systems
the second problem is that the dissipation curve
is typically parameter sensitive
so I've been arguing that if you perturb the
ATP driving you will move along this curve
and you may even happen to find a tight bound
for this system however
often you can tweak all the parameters of your model
to shift the curve
and what happens then is that it stays unexplained
how come if dissipation is such a strong
evolutionary constraint
didn't the data fall on the line
and again you have this problem of some amount of dissipation
that remains unexplained
and the cause of this is essentially the idea that
the functional space is low dimensional
so we can imagine a low dimensional set
of you can call it phenotypic traits
but at the same time the parameter space
that you can use to perturb this
functional space is high dimensional
there's a lot of room for improvement
and often you will find that that's the case
so in some sense
what I'm trying to argue
as an evil referee is that
for normative processes at least there is not a very strong evidence
I would say that cell dissipation is being the minimal
needed to guarantee function so in some sense
this functional explanation
of the amount of dissipation in cells leaves
something open still
and there is a certain amount of non-metabolic cell dissipation
that remains unexplained
so I've tried to be very
explicit about using non-metabolism
aside because I think that's a much more complex matter
because it's not a small subsystem
that you can describe, it's a very large coupled subsystem
so what about metabolism, right?
I mean the problem with metabolism is very difficult to model
there's many approaches
but there's always a lot of unknown parameters
but one thing that you can do
is just try to define microscopic descriptions
of non-metabolism and that's something that I'm working at this stage
unfortunately and somehow surprising to me
there's not a lot of literature in this direction
but if you dig deep and old enough
you can estimate the metabolic efficiency just based on the consumption
rates of nutrients of different microbes
what you find is that the value of this
thermodynamic efficiency is intermediate
so it's very hard to assess whether metabolism is somehow
efficient or inefficient
by the way this is very much a work in progress on my app
also in the group Tomas and Quasito
and in addition if you
read a recent literature
in the field of metabolic research
particular papers by Matthias Heinemann which take into account
thermodynamics, one of the findings
is that if you use
analysis the efficiency may actually decrease with dissipation
so instead of things getting better the more you dissipate it may actually
get worse
so in some sense
there may be an excess of cellular dissipation
in the sense that I mean this is that
we do not have a good explanatory theory for it
and
I do not have an answer to this question
but it is very provocative that perhaps pose this question
and many people would feel very comfortable with it
other people may feel uncomfortable with it so one
some of the possible explanations are that dissipation is simply not something
that pollution has optimized significantly
it's just one of the wrong variables it's just
being abundant enough and it's not being optimized
another possibility is that it cannot be optimized
further without altering some major biological constraint
that are very ingrained in cellular systems
that is not straight to changing like the genetic code
that has been talked about today or like the usage of ATP
as a key energy carrier
another answer to this question
that people have been bringing about lately is that
perhaps this excess dissipation actually has a function
so perhaps one of these examples is that ATP
can act as a hydrogop
and leave it up to you so that's all I wanted to say
and happy to take questions
thank you fantastic
can I just
ask something very briefly
so you mentioned it's sitting
not at the optimum in terms of when you reach saturation
in terms of the function of interest the cellular function
so you're dissipating much more you have an excess
thing so of course the issue
you could say is an issue of robustness
even if you sit perfectly it's a cusp of this curve
there is some starvation
condition or some fluctuation and all of a sudden
you fall down in the basement on the left side of the curve
the function completely drops so it might be essentially a mechanism
of robustness and another comment I wanted to make
is that you know there could be
it's about let's say ATP concentrations
which is used for a lot of different things
and this threshold of optimality might be different for the different
roles ATP plays and so it has maybe to
be an excess of dissipation
to make sure that all the different functions work
reliably so I just wanted to make this comment and see how
you think about it
thank you for the question the first question was
as I understood concerning robustness
I think
of this is
you find that some data falls in a special point
you say it's being able to be optimal if you find it falls
nowhere then you say it's robustness
I guess the problem of robustness is it doesn't have units
certainly but
of chemical potentials of ATP
in which reactions can still happen
similar to the way they happen
robustness can be an explanation and that would be a bit in line with saying that perhaps
dissipation is just not significantly optimized
so I agree with that
I do find it difficult to talk about robustness in general
like with most interesting concepts in biology to be frank
the second question was about
if you talk about dissipation
in terms of fuel molecule like ADP
which will be used for many different processes
and so the optimum might be at very different places of ADP
concentration
so in that sense that's why I'm trying to look into
something like metabolism which is one of the main
players or translation
so I think the first
one important role would be to first look at one of the main players
in terms of ATP consumption and ribosom is
by far the winner so for that reason it's hard
to expect and one could expect
that others have several processes which can support
less ADP that have simply not been optimized
for it
thank you
so we don't have any questions coming up from the Q&A but we still have a few more
minutes of question time specifically for Pablo
so I also wanted to engage some of our other participants in the meeting
if anyone else has a question related to this
talk beyond Robert's question
I mean there are quite a lot of questions
on the Q&A but they are quite general
can I ask a quick question to Pablo
absolutely
thanks for the great talk it's very interesting
so if we look at efficiency from a sort of economics
point of view if we imagine in a society
where there's only one currency there's only one note
a 10 pound note and that's how
we have used that 10 pound note that's the ATP unit
that's only this amount of money
that you can use then it seems to me
when we talk about economic efficiency we have to
view it through this severe constraint
of a single amount of
coin that you can use
so do you think that that's how we should
view efficiency in this cellular context
we have to view it through the lens
that there's only ATP that's what
KBT and that
constraints everything how you spend money
to construct your machinery
in the cell
I guess what you're saying is
given that you're mostly just using one currency
how can you talk about optimizing processes
I mean one
answer to this
is similar to what I gave to Robert but you could imagine it
optimizing the process that most significantly uses that
which I think is the translation
protein synthesis but
the steps are
how popular is coming back
maybe we can start the panel discussion now
yeah can we take
Pablo's slides down
if he's connected
alright so we're going to move next
to our panel discussion with all of our speakers from this session
and I can also invite any of our speakers from the other sessions
if they want to join and turn on their cameras and participate
so I think
we have a lot of questions actually from the audience
in the chat
and I was going to just bring up a sort of a very general question
to start because I think it might help us dig into a lot of the concepts
that were brought up so this question
comes from one of our audience members and the question is
to what extent do you think the dissipative adaptation
theory explains the trend for complexity in modern Darwinian
evolution beyond the initial emergence of life
so how much of life can we explain
I guess by these thermodynamic principles
so any of our speakers can comment on that would be wonderful
I guess I'd be happy to
jump in to begin with and
say that I think that
on the one hand
it seems clear to me that what we think of
life as being good at is a list of different things
and they don't necessarily all have to have
the same kind of emergence mechanism
it also seems to me like a few different ones
that on the one hand seem definable as different behaviors
maybe are coming from common sources
like emergence of predictive ability
isn't the same thing necessarily as emergence of
ability to harvest energy
or
isn't necessarily the same thing
as
say the ability to persist
and not be beaten to pieces by the
sort of energy that's flowing through you
there's a few different things on that list where they start to look like different sides
at the same point like robustness to the fluctuations
of your environment kind of requires being able to predict
them and being good at absorbing energy
and the ways that you want to from your environment requires being able to perhaps predict
it but then there are other things like self-replication
where I wouldn't necessarily
say that I see that emerging from the same
source I think
in my view or my guess
if we call the complexity of life as a whole there may be different mechanisms
for different parts of it if we try to look for them to emerge separately
but it may also be that there's kind of a unification
if you look it in the right way I wouldn't say that I have
necessarily gotten that perspective yet
Jeremy can I ask a point of clarification on that
when you say mechanistically explaining them do you mean
some kind of explanation from non-equilibrium
stochastic thermodynamics or there might be other mechanistic explanations
and then they are like are you specifically keeping that as
thermodynamic explanations for everything individually but not a whole picture
or
I think the story always
actually is that there's always a way
you can talk about why something happens in a system
that doesn't have anything to do with thermodynamics right the thermodynamics is kind of
an alternate perspective on many of the same
processes where the same way that
you have a polymer and you want to know sort of why the ends are being
you know pushed apart or pulled together by
thermodynamic forces you can talk about it in terms of free energy
and entropy and all of that or you can think of it more
kinetically as being about collisions with molecules in a bath
and sort of what forces end up averaging out to
and I think in my experience
every time you could have anticipated
from making some kind of high altitude thermodynamic argument
that is possible or likely in the system
there's an alternate explanation that sounds more kind of down to earth
that focuses on the particular kinetic
rules and the particular kind of physical interactions
in that system so yeah I guess what I'm saying mechanism
what I mean more is that in
the least battling examples that I was presenting where
it's sort of a class of active matter systems that are trying
to optimize this
kind of new property for the system if you know
the system is trying to optimize
that then it becomes a kind of an explanation
for what happens the same way that trying to lower free energy
can be the explanation for something that happens in an equilibrium system
but you also always can resort to
saying well what are the real rules of this particular system
you know why would it end up getting in these states
and not in those states and you're always going to be able
to tell a different kind of story that's more wedded to those
particularities
maybe can I just
a related question I suppose is you know
what I mentioned is very beginning as I mentioned of
Evan Tr√∂dinger you know in this book he mentions
he raises a question is there
a physical theory missing still of the
of the emergence of life and
I guess sort of my question to the panel
is what Sharon Meach has said is
whether stochastic thermodynamics or
this theory of active matter and these kind of more modern views
are these missing links or
is it something more what Sharon Meach has said it's
you know this is not a relevant way of or maybe not a relevant
way to think about it.
Can I step in here? Certainly
I think thermodynamics doesn't
they'll never tell you everything I mean thermodynamics
gives you constraints and what
Sharon Meach just said is completely correct
so thermodynamics constraints the ratio
between a backward and a forward rate
between two events but then
there is still one event
or one rate is free so the ratio is
fixed by thermodynamics and thermodynamics will never
tell you the kinetics it just gives you
constraints overall constraints
on the kinetics so I don't think it's a question of
you know whether thermodynamics will explain or whether
kinetics will explain this is not the alternative
thermodynamics basically tells
you what's forbidden
but it doesn't necessarily
tell you what will happen
I wanted to ask a similar
question make a similar point to
Jeremy I mean I suppose
one question that people want to understand the answer to is
is emergence of life inevitable
and modulo some boundary
conditions obviously or several environmental
context so that seems to me
something that a thermodynamic understanding definitely
should be able to tell us
do you agree or
I think that
the way that I would first of all
I try to be careful about distinction between
emergence of different life like behaviors versus the
emergence of full-blown life because I do think
life is kind of this raft full of different things
and I don't think I can make
any claim about knowing when
and how and why they should all end up getting
wraps together like when and how self replicators
combined with you know
modularity combined with prediction combined with
robustness and all these different things and it has to come
together in one place it makes sense once it does that it stays that way
but so I think
that I would be the first distinction to make then
on top of that so I
I agree in large part with what
would have just said about thermodynamics setting constraints
for things but I also think
that what it kind of points to is that
in some ways what
thermodynamics is is a particular subclass
of statements you can make about dynamical
systems when you impose
certain kinds of rules on relationships
between different parts of the
rules governing those dynamical systems
and what that points to is that to some degree
what you're ultimately going to be able to say about emergence
is probably not going to be required
to be couched in thermodynamic terms
it just may help to think in those terms
because of where it grounds you it's I mean I find as a physicist it's just
helpful to me to think about things like conservation of energy
and it gets me oriented I think about
all rolling up and down hills and I have more
about that sometimes than I do about other things
but in the for example the least
rattling
arguments that we've been trying to make lately
it's really fundamentally a dynamical systems argument what it's
saying is that for an arbitrary random mark of
graph you could
apologize for the noise for an arbitrary random mark of
graph you could
in principle not have any ability to predict
the steady state behavior from a local property
in the graph however in a large
graph where the edges the jumping
rates on all the edges are taken independently from a random distribution
you can argue that there's a limiting
behavior in which the local steady state
probability is determined by the local exit rate which is not
generally true but it becomes true in this limit
now that limit I just described must
be far from thermal equilibrium because in order for the edge
jumping rates to be statistically independent you have to have local
breaking of detail balance so it's
a requirement that it be a non-equilibrium system
but it's not ultimately a
system so to speak of thermodynamics that you have to get
emergence it's more like
in a certain class of dynamical system you're going to get
this simplification that gives you predictive power
in the behavior of the system and that has to
happen far from equilibrium that's the way that I would pay
it
So there's a couple related questions
in the chat the second one came up
so I'm going to direct this to you first
for the panel
Sorry my mic was muted but could I follow up that
Is it directly related to what Jeremy was saying?
Yes
Just quickly
I want to follow that up Jeremy by asking
how does the open ended growth of complexity come into this
because one of the reasons that in the previous session we were talking
about things like girdle and the cider wall and stuff like that
one of the reasons I started worrying about self-referential
dynamics was because when I started making models
of evolving ecosystems and other people have done this
well before me what you always find
is that the system evolves to a point and then it stops
evolving and because it basically
maxes out whatever thermodynamic properties
are there and come to some non-equilibrium steady
states or something like this and so then
how do you then you never get
the open ended growth of complexity and so
we did some of the background noise
and we did some modelling of that
I'll talk briefly about tomorrow but I mean it seems that
that's not something that's easy to describe in a thermodynamic
or do you think one can do that?
Jeremy did you hear the question are you able to answer it?
or did we lose Jeremy?
Jeremy's muted.
Jeremy you're muted.
I'm sorry there's a delay so I click on mute
and then I start talking and it seems like it's
unmuted and I click it again and it gets muted
so I apologize but
I think that I would return to
the thing that Udo mentioned which is that
so if you're talking about
an arbitrary dynamical system
then in terms of
going from the kinetic rules to thermodynamic constraints
you at best can set sort of inequalities
on what the minimum thermodynamic
cost of operating a system like this might be and then
you could always spend more if you want but there's sort of an underlying minimum
so I think there are some systems
where you know the
qualities at the edge of those inequalities are being obeyed
if you're microscopic and chemical and when they're more complicated
and ecological the actual
kind of macroscopic kinetic
properties that you're looking at they will set bounds
on thermodynamics but they won't automatically
tell you about thermodynamics
so
I guess we have left Charmy?
No I'm here so I
it's only interesting someone in the meeting muted me so I
think you must have lost me at some point.
I apologize I don't know how much of
what I just said got missed but so I'll just say briefly
I think in anything ecological
the way I would look at it is it's a dynamical system
it might be a dynamical system
where you can argue from purely dynamical
arguments that there's some kind of attractor behavior
that
it might settle into and it may
indeed also be the case that you have enough information to connect
the dynamics in the system to thermodynamic fluxes that it will
appear that there's a thermodynamic principle underlying that
but I think that's not the same thing as knowing
from the kinetic description of the dynamics alone
what the thermodynamics must be because as you said before
if you start from the
kinetics you get inequality constraints on the minimum
thermodynamic costs of operating something with these dynamics
but for macroscopic systems those aren't necessarily going
to actually be as informative
because you're usually operating very far from the
thermodynamic limitations anyway.
Can I make a quick point on the note of open-ended
evolution related to this I think one of the biggest problems is that
none of our theories really account for the
I think Jeremy brought up some interesting ideas about work history and things like that
but I think in order to get to a proper picture of open-ended
dynamics it has to be something that's dependent on the history
which Nigel you know well from thinking about self-referential dynamics
but unless you're carrying that history with you you're not going to be able to
get a system that's open-ended
and there's a lot of reasons for that
so they're actually
I see your hand up now so I'm just getting the video back
so go ahead. Well I have a comment or question
for Nigel and Jeremy
isn't it that evolution has this tendency because
it explores sequence space
gets longer at best, longer sequences all the time
that at the end of the day it will never be able to really
get to that steady state in the boundary condition because
it can always continue to make longer and longer and explore
larger sequence space therefore it is a little bit difficult
to make that closed
theory where you hope for that steady state because you don't get there
or am I missing out
the argument? I mean we probably have tomorrow a better discussion
but yeah. Well I'll give you a quick answer
Jeremy can give here
I don't think there is a fixed point state
which is like a dynamical fixed point I think it's more like
a similarity solution of a differential equation
like a diffusion equation where the solution scales
as x over the square root of t it's always
the diffusion profile is always going out
you could say well eventually it will be flat
but actually what's happening is the intermediate asymptotics
is it's always going to be evolving and scaling in some way
so you can think of that as being a metaphor
a perfect one for open-ended growth
and just about sequence space yeah I agree with you
there's a work we did about
more than 10 years ago where we tried to make a model
of evolving
complex objects that
went and looked at what was the genome dynamics
that could give open-ended growth complexity and we found what it would be
in this model and I'll say something about it tomorrow
but the bottom line was
that what you end up with is not processes like
global processes like closings and gene duplication
now that conclusion happens to be
what you see in the biology but our conclusions were model specific
and in particular we were modelling the complexity
of the genome and the organism
in a way that is definitely biologically wrong just by the length of the
sequence so it relates to your
question back but that's the best statement you can make
thanks
yes actually
maybe I read off a question from the Q&A
what would you say is the
semi-dynamic cost of Maxwell's demon in biology
is this encompassed by the cost of
positions that Udo mentioned
so I guess Udo's
let's say answer the semi-dynamic answer relationship
how does it relate to Maxwell's demon
it's not about the Maxwell's demon
I mean the Maxwell's demon
typically is this
the LN2 like Landau
you get information, you have to store it
you erase it, the semi-dynamic and semi-relation
is something quite different
I mean it's a relation about processes in steady state
we now have time dependent variations
but I don't think it's directly
or reasonably related to the Maxwell's demon issue
I mean the Maxwell's demon from a semi-dynamic perspective
is that you do not start in
equilibrium but you have additional information
and that's where you get the work from
and then you have to pay at some other point in order to restore
the second law on a more global scale
I also want to take the opportunity
to comment briefly on what Dieter just said
Dieter, it's a
wrong impression that we need to have
steady states in order to do what I showed
or what Jeremy showed so it's just
we often use the steady state to illustrate these relations
and we have the strongest relations for steady states
but you can certainly have
thermodynamics or stochastic thermodynamics
and time dependent environment for instance
and you can start that was one of my points
you can start with a very special initial distribution
concentrated on something
and then you see and that ties to what Nitro said
and then you see how it develops
and perhaps spreads in distribution
so having a steady state
is not a necessary condition for these kind of
theories or ideas to apply
Sounds good
Yes, I would like to bring Pablo
into the discussion if I understood Jeremy correctly
he was suggesting that micro system
is operating so far from
stochastic thermodynamics
that is not even useful
Pablo seems to be saying at the cellular level
that it is not useful
am I pushing your talk too far
Pablo you are muted
you are still muted sorry Pablo
Pablo you have to unmute yourself
but ok
Am I muted now?
What I was saying is that I guess
there is a lack of experiments in this area
I think in general in stochastic thermodynamics
in particular it is application to biology
I don't find very strong compelling evidence
I mean it is self-evident to say that these are lower bounds
and sometimes they will be meaningful and sometimes they will be
not meaningful the question is
how many instances of them being meaningful
have we found and I think
there is a need to sell our energetics
that should be a focus
in what pertains to making models
abstract models of how evolution
may have emerged I mean it is true I agree with Jeremy
was saying that it is a nice
clutch you wish to think about probability models in some thermodynamic language
because it is useful to think about them
that way but at the same time
the comment from Sarah which probably
biology is different and then if you are too much attached
to theories that you know
you may not be able to formulate theories that are
truly novel and effective to describe the parts of biology
that are not just some variant
of the known physics which I think is probably the most
interesting of course I guess like her I cannot tell you what that theory was
well I mean she seems to have some ideas but I don't have
any ideas of what such a theory may be but
focusing on how we can formulate it
in very self-consistent and
queen-depth thermodynamic terms although it makes us feel
a bit more comfortable it may actually not be a productive
endeavor if you wish
May I just follow up very quickly as a quantitative
biophysicist it is much better
if you tell me at what length scale
stochastic thermodynamics is you can forget about it
so you say there is not much evidence
of worrying about stochastic
or energetic cost at the cellular level
how about the other two panel members
Jeremy do you agree with that because you mentioned macroscopic
I don't know what does it mean
I was going to jump in and say that
I didn't mean to give the impression before that I was saying that
I think it's not actually useful to think
in thermodynamic terms I think it's more that
there are systems where
the informative description of them is just
a dynamical system that isn't rooted in any underlying
notion of the thermodynamics and you still can make
progress there and some of these ideas
may still be applicable but I think when you do have
grounding in thermodynamics that comes from your understanding
of the system in question that can be more powerful
and more predictive and
help you to understand more about what is likely to go on
and what can go on and it seems like a natural thing to be wanting
to make use of especially when talking about what's going on with molecules
and I'd also say that
I'm not sure that so
perhaps it might be the case that stochastic
thermodynamics
specifically presumably
if we're thinking about it's thermal noise then yes
small things, nano things care more about thermal
noise but I think
the ideas that come out of this like
what Uda was describing for example that there are underlying
energetic costs for things like
the precise operation of a clock they
do end up having consequences
on the macro scale in
particular cases because I think there's still
more general reasons why thermodynamic
works and the physics that it's connected to that can still end up
mattering for some of these questions so for example
in the system I was talking about this mechanical network
that was jumping around and exploring its configuration
space that system
actually gives you the interesting
without any thermal noise at all
meaning that it is possible
it's a Newtonian system without you know if you don't put in some random noise
on top of the Newtonian equations
you write down for the dynamics so the fact that you have drag
but no noise means you're effectively at zero temperature
in a near zero temperature
thermal bath and it could be a macroscopic system
but then the fact that you're pumping energy into it with a drive
dominates its exploration of its configuration
space and now you can have sort of emergent fine tuning
properties so I think that the
physics that gives you thermodynamics
that undergirds the physics of a lot of other systems
can still matter in active matter settings where it might
not really be the case that you specifically
care about so to speak the fluctuations of a heat bath
and I think stochastic
can actually be thought of as one formalism
and a very powerful and general one but one formalism
among a variety of others which
capture the underlying physical principles like
time reversal symmetry or Newton's laws essentially
and connect as a result
certain kinds of events in a system to
what has to happen in a surrounding heat bath
and things like dissipation so I don't think
entirely can make the division of well when things are small
which matters and when they're not on some scale
it doesn't matter anymore I think that the physics
of emergent life like fine tuning
can apply at various scales and doesn't necessarily need
stochasticity.
Udo did you also want to comment on the current discussion?
I did but I think we'll do this talking first.
Yeah so I mean
I essentially agree with what Jeremy was saying
the strongest result
we certainly have on a level of small systems
and the one example I've shown you with this for this
molecular motor I mean I think that's really a strong result
that we can say 45% efficient at
most
and Pablo was pointing I think to an important
issue what we do not yet
have is let's say
good understanding of how for instance the thermodynamic
uncertainty relations scales with system size
I mean this is one of the things we're currently exploring in my group
because you certainly
want a tool
which scales with the system
so you know if you just look at one degree of freedom
or if you look at a cell and you just look at
you know for instance how its shape changes or so
and you try to infer the dissipation you typically get something
of the order of KBT
per second or so but you want something which scales
with the scale of the system with the size of the system
and we're not there yet
but on a more general level I'm kind of optimistic
because we know that thermodynamic tells us important
I mean about steam engines
and car engines and it tells us something
important about molecules so why shouldn't at some point
it tell us something important about cells and aggregates of
cells
and one more comment on this issue of efficiency
I mean if you have efficiency
one you typically have
you need infinite time
so if a process should
happen in a finite time it's clear that the
efficiency cannot be one and there has to be dissipation
so you know
if a system is only 50% efficient it may be
because it wants to get something done in finite time
Did I cover
the topics?
Yeah that was great
I was going to say we're running short on time so maybe
Nigel if you have the point that you wanted to make
our question and then we'll wrap up after that
Okay very quickly Jeremy in your dynamical system
model with the nodes and the networks flapping around
did you ever look at what happened if you make a rule
that says if there's locally a fluctuation in energy
that is above a certain threshold you add another node
to the system with some springs attached to it
and then watch how that system
and then do everything that you did before but with this
new system which is now guaranteed to
grow itself over time? Yeah that's quite interesting
we haven't done any simulations where we
allow the network structure
to kind of self edit
and it's related to a different
kind of question that one can ask about this
which is what if for example
you make the input to the system dependent on its behavior
in a more sort of computational
way or a programmed way so instead of an environment
that has a sort of fixed pattern to it
the environment could be operating a program that depending
on the system does it could poke it differently
so we I think both of those
are very interesting suggestions and I think they could be even more
interesting if you combine them because
it's sort of a on the one hand very
primitive mechanical system but if you just give it a little
bit of a nudge out the door in giving it the ability
to evolve itself I do wonder what kinds of response
properties could emerge but the short answer
I like the idea of combining
what you were saying with my suggestion because I think what we will
have then is a very primitive version of niche
construction which I'll talk about tomorrow.
Excellent great that's a perfect segue
for us to end and get excited about the conversations tomorrow
so I want to thank all of our speakers today
and everyone for participating in the discussion
and also our audience and we'll see everyone again
tomorrow for our first session on the emergence of order
thank you all.
Yes thank you thank you dozer speakers.
Thanks bye. Thanks bye.
you
you
