So, yeah, I mean, this talk is going to be primarily a kind of theoretical, you know,
in silico, active inference kind of talk.
I'll try to sprinkle in some empirical data here and there.
But so, yeah, one of my major interests is in more or less ways of understanding conscious
and unconscious emotional processes in the context of emotional disorders.
And specifically, I've been really interested in seeing if you can find ways to understand
these sorts of processes at a computational level of description.
And so, I'll tell you about one particular type of emotion-cognition interaction that
I've done a fair amount of work on and recently have tried to develop deep active inference
models of.
So, and the main kind of goal with this, and the specific type of emotion-cognition interaction
that I'll tell you about is related to an individual difference variable called trade
emotional awareness.
And the idea is to use it as just an example of a sort of a relevant trade psychological
difference that's sort of clinically relevant, where the idea is that hopefully, even though
you have this sort of single phenotype of low emotional awareness as just something clinically
relevant, that doesn't mean that there's a one-to-one mapping between that phenotype
and the underlying mechanisms that are causing it.
So, the hope is to use both neuroimaging measures and computational modeling to sort
of figure out, okay, what are all the different possible mechanisms that could be causing
this?
And then use that to figure out ways to identify which mechanisms are operating and which people,
and then use that to inform treatment selection on an individual basis and potentially to
treatment development.
So, that's the kind of general aim I have with using emotional awareness as an example.
So, first, I'll kind of give you some background context.
What is trade emotional awareness?
A little bit about its clinical relevance.
I'll then give you a crash course on what we've called the three-process model of emotional
episodes.
This is a very kind of broad way of dividing up different processes that contribute to
what happens when you have an emotional experience, that we have more or less come up with as
a way to kind of tease apart what the different places are in that process of having an emotional
experience where things can kind of be different between different people that could explain
differences in what happens in your body, what happens when you feel what happened in
your body, how you interpret it, how you use that to make decisions, things like that.
And then I'll tell you about the kind of active inference version of this that I put together
at UCL in that sense, and what, if anything, that might have to add in terms of understanding
possible mechanisms.
Okay, so first thing, emotional awareness.
The idea is that some people, it's just kind of this common clinical observation, that
some people understand their emotions or have trouble, some people have a lot more trouble
recognizing and understanding their emotions than other people do.
At a low level, this can lead to things like mistaking negative emotions for signs of sickness.
So this is the kind of thing like somatization or somatiform disorders.
Some people kind of divide up emotions based in a really coarse-grained way, like they
just kind of feel bad or good, but yeah, that's about it, which isn't all that action-guiding,
right?
If I know I'm sad, I have a much better sense of what the possible causes, what the likely
causes are, what I have to do to regulate my emotions, et cetera, so bad versus good
isn't all that informative or action-guiding.
It also, for the same reason, can lead to poor interpersonal problem-solving.
If I'm not good at recognizing my own emotions, probably also am I good at understanding other
people's, right?
So there's a lot of ways that this kind of plausibly has an influence socially and in
terms of emotion regulation for yourself, and so unsurprisingly, almost all psychotherapeutic
approaches aim to improve emotional awareness in one way or another.
So the main sort of instrument that we've used to measure emotional awareness is something
called the levels of emotional awareness scale.
It's technically performance-based, so it's based on self-report, but it's performance-based
in the sense that it's not based on what you believe in your self-report.
Basically what it does is it just asks you to describe how you'd feel in like 20 different
hypothetical situations, and then it just takes the sorts of terms you use and then
just scores them based on their kind of level of specificity more or less.
So like if you say you feel sick, that'd be like one point, it's like a fully somatic
kind of thing.
Maybe to say bad or good, that'd be two points.
Use a single emotion word like sadness or anger, that'd be three points, and if you
can talk about, say, feeling multiple things at once, that'd be four.
So that's the main way that people sort of objectively or performance-based kind of get
a sense of what cognitive, the wet way, what sort of concepts do you actually use to understand
your experience spontaneously when you're thinking about it.
And there's a pretty sort of large literature on this nowadays, so lower LAA scores have
been found in quite a large number of different emotional disorders as well as just systematical
disorders, and it's even a thing that gets such a hypertension or irritable bowel syndrome.
And higher LAA scores are associated with greater empathy, emotion recognition, openness
to experience, lower impulsivity.
It's a lot of things like this, and it's because of that reason and part, it is part of the
R-Doc matrix, so, largely by just motivating its importance.
So then, I mean, the idea is, like I mentioned before, it would be helpful if you want to
know what the cause of this is in different people to have some understanding of what
the underlying cognitive and neural processes are, and really the only way.
So our attempt to try to do that was to use this kind of broad, three-process model thing
that I'll tell you about.
So I can't really go through all of the kind of supportive evidence to back everything I'm
going to say up.
So, but we've published a number of a series of reviews kind of covering this and updating
it in various ways, but, oh, I'm sad, I was going to show you a fun video.
Imagine that you were watching a car really serenely going down the road, and then like
a zombie jumping up on the screen and screaming at you.
You should have all jumped.
At which point, I would have said, okay, what just happened, right?
And I would have used that to guide you through the three-process model of an emotion episode,
so you missed out, but, so this is, in the kind of boxology depiction, what the three-process
model is.
So more or less, you start out with some sort of event, it could be real, it could be remembered,
it could be imagined, but you're representing some event, right, in some way.
And then, once it's represented, then you both implicitly and explicitly evaluate it
along a bunch of different dimensions.
This can be really low level, like condition response kind of thing, but it can also be
higher level, like, you know, is this something controllable, is this congruent with my goals,
you know, things like that.
So that is what we call the initiator of affective response generation processes.
And the idea here is, based on that evaluation, you have some kind of allostatic prediction,
right, about what sorts of cognitive and metabolic resources you're going to have to bring to
the table in order to deal with it, and bring yourself sort of back to preferred states.
And that response, broadly, again, has two different kind of components to it, has a
cognitive component, or a central component, and then a peripheral physiological component.
So the cognitive component is going to be things like initiating attention biases, interpretation
biases, motivations to say approach avoid, things like that.
Whereas the involuntary bodily response, the peripheral component is going to be things
like automatic changes in facial expression, automatic changes in heart rate, muscle tension,
things like that.
And so once that all kind of gets going, and I should say this is all kind of going at every moment,
so it's all feeding back and influencing itself as well, but then you kind of have some update
in your model about what it is that just happened, right, what just changed in my body,
and how do I interpret it.
So, and I'll go into more detail in that, but this is where you say, okay, I feel an increase in heart rate,
I interpret that as indicating that I'm afraid, right, something like that.
And then finally, it's important to realize that, at least briefly, there's evidence to suggest that
all of these things can be briefly represented unconsciously without you being aware of it.
So there is this sort of further process that you need where these representations are selected
and sort of maintained active in some way, so you can kind of hold them in working memory and use them
to make some sort of deliberative decision.
We've just called that conscious access working memory, you know, access to working memory, something like that.
So, you know, as a fear example, had you seen the jump scare, you know, it would have been like,
event, scream, zombie, you know, the evaluation, unexpected, potential danger, you know,
some low level association between loud scream and danger, and then you would have had some change in your body
and you could sort of represent that way. This is actually data based on you.
I've had a bunch of people kind of draw how they feel on their body when they say they're feeling different emotions,
and there are these kind of like interesting, reliable perceived patterns.
So you have something like that, you're going to have the initiation of some kind of threat bias
and some avoidance motivation, you know, you'd feedback and you'd represent those bodily sensations,
you'd identify that as corresponding to your learned concept of fear, and then if that all gets accessible,
you'd be able to say, I just got scared because of the abrupt unexpected jump scare.
So that's kind of, so process one, generate the effective response, process two, represent it in this kind of hierarchical way,
and process three, gain access to it, hold in working memory to use it.
And I can do this for other things, right, so it could be you got denied a promotion,
that was goal and congruent, and you direct the blame at other people, say your boss, right.
You have this anger kind of like bodily feeling, right, fists really active, negativity bias,
but an approach motivation, right, you represent the flu and that you think you're angry,
and then that becomes accessible when you can say I'm really angry at my boss because he didn't give me the promotion,
I deserved it, right, so hopefully that gives you guys kind of the intuition.
And if you kind of zoom in on this internal state representation part,
because that's going to be a big chunk of the modeling,
then you can kind of think about it as, again, at the kind of low level,
you have this feedback from your body and you're representing something like a valenced, valenced intraceptive representation,
along with some matter motor stuff like facial expression changes, things like that,
but then you kind of have to map that in some way up to some high level interpretation
that's going to depend on what you've learned, right, like emotion concepts, for example, are different in different cultures.
So it's not like there's one kind of true answer about what of the bajillion different multi-dimensional body states you could be in
and some particular emotion concept, but you make sense of it in some way, you know, that you've learned,
and there can be differences in the granularity or specificity or action-guidingness, right, of the ways you've come to carve it up.
So this could again be you feel a body feeling like that, you map it onto sadness with priors that come from
the cognitive part like unexpectedness, loss, uncontrollable, etc.
And this is actually meant to be like fully sort of general and analogous to say like a visual case,
where you see say a visual image like that, you'd map it onto the concept shovel, right,
in the context of other aspects that you're representing, say like tools, shed, you know, familiar, controllable, etc.
And I should say that this is like a huge simplification, right, there's definitely not two levels of representation of body states,
if you're interested in this, we've published a paper a couple of years ago laying out based on a lot of kind of
just nitty-gritty about anatomical and physiological responses and characterizations that you can kind of lay out
and even this is oversimplified eight level kind of hierarchy for how you represent inter-acceptive states
and kind of integrate them with higher level information from other senses and memory.
But good enough for our purposes here.
And then the final process, so we've kind of based this largely on this work on what are called global works-based models of consciousness
or at least the empirical support for them, which broadly shows again that say if you play somebody a sound
but they don't hear it because it's say the intensity is too weak or they're distracted by something,
you get this kind of local representation in auditory cortex, but only when it's detected does it have this kind of global broad influence
on association cortices throughout the brain.
So the idea is consciousness requires accessibility of the information carried by that local representation
via this broad sort of causal influence.
It's updating a model more broadly, you could think about it that way.
So here the idea would be something like you could represent, you could have some representation of a body state like that,
you could have primed a concept like sadness and you could have primed things like unexpectedness, loss, etc.
But that may or may not become broadly accessible.
If it is, then you could say things like I'm sad because I just lost a friend and I don't have much energy right now.
But maybe only the body state becomes accessible.
Then you'd be able to say I feel really low energy but I don't know why, maybe I'm sick.
Or you could have access even to the interpretation but not to the underlying sort of causes.
And then you could say, and this happens fairly often, I feel where it's at but I'm not sure why.
In real life there's a kind of top down process in the sense that you're in a context
and there are norms and expectations from what you might feel in that context.
So those schemas are sort of available as high level priors.
Yeah and you could think about that as priors coming in part from this kind of cognitive appraisal dimension sorts of things.
But that could also act as priors on just what emotion concept you think best fits the bodily feeling you're having.
So that could probably come in a couple places.
I guess I'm thinking of it even as prior to having any bodily feeling and as to priming that in some ways.
And maybe even increasing the likelihood of having certain bodily feelings.
Or even selecting out a sort of white noise bodily feelings.
The possibility of labeling something that doesn't have a strong balance attached to it but assimilating it into that expectation.
Yeah I totally agree. There's questions about whether that's coming in at the response generation part or after.
Either you're not generating the response to begin with, in which case you're not going to have the bodily feeling because the body didn't do anything.
Or it could be the way you interpret it after the fact.
So it seems like this is where you can kind of disentangle a couple different things potentially.
I guess a short comment that your model has just gotten a reason for doing after scanning of spinal cords.
Because you just described pain gates which are operated very nicely in spinal cord and have a bound regulation.
So I don't think I fully understand.
I mean nothing I've been talking about I think is at the level low enough to be something like pain gating in the spinal cord.
Well that's an interesting thing about it.
Because how we experience pain is we're independent very much on social context.
Any rugby player on the rugby field will tell you that.
And where the gating occurs anatomically seems to be in the spinal cord.
So that can certainly happen via these sort of like descending saline.
So it would be quite nice because also all the intraceptive stuff for the gut goes in through, well some of it goes through the baby, some of it goes through spinal cord.
But it's a good case for doing a spinal cord after scanning.
I mean there is a lot of work on pain representation actually within the global workspace in a sort of approach to conscious processing.
And there I mean depending on the reason or the actual, basically there are circumstances in which the pain representation probably gets a lot higher up.
Like into the insula for example but you still don't become conscious of it anyway.
But the thought that people will actually continue without physical anything due to any kind of awareness is you get the sensation lower down.
Then the insula and the palimous really where the palimous in particular is where the unpleasantness gets assigned.
So you're...
But it doesn't have to be, but it wouldn't have to be conscious.
That representation can happen unconsciously.
I mean we probably have to talk about it normally.
But for good reasons.
So anyway, so I mean that's kind of just a brief kind of crash course.
And just to kind of frame a few of the kind of neuroimaging results that all kind of sprinkle in throughout the way.
We have kind of proposed and based in part on some of our research a kind of tentative kind of large scale model for the way to think about these processes in the brain.
Based mainly on work on the function of large scale brain networks.
The idea is that I mean you know there's still kind of up in the air exactly the right way to interpret these things.
But while you can't really say conditional on knowing the particular brain area activated, you can't really know that much about what psychological function was going on.
Looks like you can actually do this quite a bit better if you know what brain areas are talking to one another based on functional connectivity.
And so based on that kind of thing, you know people have kind of looked at a number of studies and proposed, for instance this paper by Lisa Feldman Barrett and Ajay Sopate.
Ways of understanding kind of broad domain general functions of these different networks.
And you know one for example this thing though in cream here the limbic network looks like it's pretty strongly involved in representing and regulating this for motor states.
And so it's kind of a prime target for generating these sorts of affective bodily responses in response to evaluations.
Whereas the somatic motor network here and salience network components especially sort of insulin and figure singulate look like some of that is also involved in the generation process.
But also looks like it's pretty important for representing interceptive and somatosensory states to be a lot of the kind of body state representation stuff.
The default mode network this guy in cream here is pretty strongly implicated in a lot of conceptualization related processes.
So multimodal integration, trying to make sense of things, the semantic level, launching these sort of large scale simulations over kind of like long temporal scales based on drawing from long term memory things like that.
And then the yellow thing, executive control network, largely implicated in things like working memory, executive function, cognitive control.
And it's a big chunk of what activates during the global workspace, conscious versus unconscious contrast.
So the kind of thing we have in mind is you have some perceptual representation, it either gets interpreted via default mode network processes or directly has some sort of conditioned association thing with limbic network processes.
That ends up generating a change in body state and some modulatory effects on cognition, likely based on influencing these sort of broad neural modulatory patterns from brainstem neural modulators.
That'd be kind of the tweaking precision here and there kind of the thing.
Body state information then feeds back in and updates your model.
So representing your body in a different state now, that then can feed back and further get interpreted and conceptualize as an emotion or as something else via the same sort of default network processes.
All that stuff can then compete for maintenance and working memory and then all of it can both consciously and unconsciously then influence action selection in some way.
So again, very, very broad. We do have some studies consistent with it, but I wouldn't say it's at all kind of take it to the bank.
It's just kind of something to guide hypotheses.
And so we thought, okay, well you could have individual differences in the response generation stuff, in the representation stuff or in accessibility.
And you could tweak each of those independently and produce a similar kind of phenotype.
So different things could be going on in different people and knowing what's going on and what person would be important potentially in terms of intervention.
Would you classify facial expression and display as part of a response?
Because there are big cultural differences and sort of training for the degree to which you display things.
Yeah, absolutely. And there can be some kind of top-down control stuff too, where you could have the automatic tendency to do one thing but then suppress it given some norm, right?
And so that also gets pretty complicated pretty fast.
Yes.
Just to pick up on what you were saying earlier, on the core is very general level without even getting into cultural differences.
To get a sense of the general picture, it seems to me maybe we need to talk about top-down processes where cognitive framing is always culturally framed.
So experiencing an emotion for humans has something to do with the attribution of meaning, finding like a narratively postulated cause.
And then say strongly to accept the surprise or probably top-up, go back up to like say, you know, activate system 2 resources, then you go and Google for symptoms, then you imagine a new cause and then that goes back down and affects how you feel.
Yeah, absolutely. No, yeah, I don't disagree at all.
So the really, really important domain of statistical regularity is this cultural narrative.
Oh, absolutely.
There's a patterning.
And I mean, you know, I'd like to pack some of that into, you know, the sort of, you know, like the hierarchically expanded version of this like evaluative appraisal sort of thing I'm talking about, right?
Where you can definitely have a lot of these top-down influences, even when they're not culturally specific, right?
Like the amygdala will respond pretty strongly to images of food when someone's hungry but not when they're full, for example, right?
So I'm going to sort of top-down an expectation about what's relevant, you know, in your situation to be very context-specific, right?
So I mean, there's definitely a lot of that.
And a lot of the way that you evaluate things in terms of, say, consistency with norms and values, consistency with your current goals, all of that is going to have very much a sort of top-down component
and influence the response you have to whatever you think is going on.
But it will also influence other things too, right, like the way you interpret what state you're in after the fact.
So yeah, I just totally agree.
Okay.
So like I mentioned, we've done sort of a number of studies over the last few years testing various aspects of this
and finding neuroimaging results both structural and functional that we at least think are consistent with it.
Like I said, I'll mention some of them along the way.
But all of this is primarily to motivate why it's worth trying to do a fancy active inference model version.
So since we haven't really talked about active inference at all, at least not the markup decision process formulation, it could probably be worth giving people kind of a quick walkthrough.
You know, if you've seen this kind of Bayes net depiction before, it can be kind of intimidating.
It has a billion variables.
It doesn't say anywhere what they mean.
So I'll try to give you kind of a step-by-step here real briefly.
So if you get rid of most of that, and you just have this O thing at the bottom, this connection up that we'll call A,
and then this S thing, which is the state that you believe you're in, and then D, which is essentially your prior expectations about states,
then this is just a pretty simple sort of depiction of kind of one-step Bayesian inference.
You have some prior expectation.
You get some observation.
You infer what that observation means based in part on what you expected ahead of time.
Right?
And so D is your priors.
The A matrix essentially just describes your beliefs about the relationships between states and observations.
Right?
Like something white and circular is more consistent with baseball than football.
Right?
I mean, that's basically all it amounts to.
Right?
So then if you're going to expand on that then, you know, we don't just observe things statically.
Right?
So you need a temporal component to this, and that's where this B matrix thing comes in.
So that's essentially your beliefs about how things, how states evolve over time.
So once you figure out what you believe about what you're in, about where you were or what state you were in at time one,
this B matrix gives you a prior and, okay, what state do I expect now to be in at time two?
And so then that becomes your prior.
You get an observation at the next time point, and then you infer a posterior over states at time two,
which can then also feedback and update your beliefs about what happened at time one.
But a central all you're doing is just making this thing temporarily extended.
So beliefs at one time point, half as priors for the next time point.
But this is still wholly perceptual.
So then to add an action model on top of it, you have to add these things.
So pi here is just your set of allowable policies.
So it's the choices you take yourself to have.
This G thing is the expected free energy of each policy, essentially encodes your,
something like the estimated value you assigned to each policy.
And that is evaluated with respect to the C vector thing, which encodes more or less what you want and what you don't want.
So inactive inference lingo is your prior preference distribution.
And then finally, so, okay, just to give you a sense.
So G, the expected free energy, that is one way of displaying the equation.
I won't go into it in detail, but the thing to understand more or less is it has a component
that involves minimizing the deviation between the outcomes that you think are going to happen
if you choose a certain policy and your preferred outcomes.
So technically you're minimizing the public labor divergence between the outcomes you think are going to happen
and the outcomes you want given each choice you could make.
And then the second component involves a way of also basically policies end up having higher value
if you think that them leading you to transition to certain states is going to be really informative.
It's going to minimize the uncertainty more about what states you're actually in.
Yeah, so I mean, all you should take this to mean is just that the value of policies,
so the posterior distribution over pi is going to be based on the expected free energy calculated with respect to C.
So more or less this just means policies have higher values if they're going to get you closest to what you want
and if they're also going to give you more information about what's actually the case.
Because a lot of times before you can know what you should do to get what you want,
you have to know enough about what the state of affairs actually is.
So then finally the last step is adding these additional things, which won't matter a ton for what I'll show you,
but more or less these additional kind of hyperparameters allow you to, allow the model to maintain estimates
of essentially its own confidence in its actual model itself.
So this sort of beta-gamma thing is more or less a way of having a prior and then updating this expected precision term,
which more or less reflects your confidence in how good your action model is.
And that ends up actually trading off influence with this E thing, which is essentially a fixed form prior over policies.
So it's sort of the policies you expect a priori to select over others.
The other thing we were kind of like, just like habits more or less.
And so the way this ends up working is that policy selection will be more driven by habits if gamma is low,
if you have very little evidence or very little confidence in your action model.
And having a prior for high beta is going to bias your initial gamma, so toward being lower,
which means you're going to favor acting based on habits.
So that's the way of interpreting this thing.
And yes?
I just have a question.
How do you normalize the pragmatic that's used if they make...
So that will happen kind of just on its own.
I mean, that just falls out of the expected free energy equation, right?
So you just have the epistemic component is that ladder component
and the pragmatic component is the earlier part of the side of the right side.
So for instance, it just will happen automatically that whatever value,
whichever policy has the lowest expected free energy will be a trade-off between those two.
There's nothing waiting then outside of just the equation.
Because it would be possible to have a kind of hyperparameter forces in people
to have more one or the other value, right?
So an empirical, so if you want to fit behavior empirically,
you know, I've tried to do this before where you can actually throw in an additional term
that will essentially weight the epistemic component versus the pragmatic component.
But in practice, what will happen is because the C vector,
because the magnitude of preferences can vary continuously,
then just the higher the magnitude is,
the greater the weight the pragmatic component will have.
So having a low-magnitude C just automatically makes it so you're more driven by this value.
Also, one more step would be that you could add a precision.
It's like you have now a reaction model, but then add it to C.
So maybe if you're hungry, then you start being more guided by your preferences for food.
So you can like temporarily unregulate and prioritize the pragmatic component epistemic.
But that would be even more harder.
Yeah, I was going to say, that's not built into the standard MDP formulation.
There's definitely fancier things you could do.
Casper has tried to do some of them, which I don't know.
Are you going to talk about that at some point?
Well, yeah, maybe during the tutorial.
Okay, okay.
Well, stay tuned.
So anyway, and just briefly, I mean, you can't really see this a lot well,
but the Active Inference Formulation I'm just showing you also has this kind of
proposed accompanying neural process theory that allows you to essentially simulate
plausible neural activation that you ought to see given the dynamics in the model.
It's not going to be that important for what I'll show you,
but more or less you just end up being able to derive these update equations
that just cast essentially the equations for updating free energy and for expected free energy
in terms of these two different sorts of prediction errors called state prediction errors
and outcome prediction errors.
And then those errors then feed into calculated error updating the free energy
and expected free energy estimates.
And then you can just do gradient descent on those.
And what ends up happening is that belief updates from moment to moment correspond
to changes in activation levels in different of these kind of simulated neurons,
whereas the actual matrix entries like the matrix entries in A and B and C
and D that indicate where you're kind of like more stable beliefs about relationships
between things, those end up corresponding to synaptic connection strengths,
which you can learn, but you update them more slowly across trials.
But like I said, it won't matter that much for what I'll show you.
So applying that then to understand emotional awareness is something that we've not tried to do.
And one thing, so you can just ignore this top part, basically all that adding the second level on means
is that you just tack the same thing on a top, what I just showed you.
So the state, your state inference at the end of each trial at the lower level
just ends up being the observation that feeds into the same exact structure at the level above.
So for instance, you'd run the lower level like three times
and then that would correspond to three observations over time by the higher level.
And so for the kind of task we put together to model emotional awareness
is this kind of emotion-focused working memory task more or less.
The idea is that the agent is presented with some kind of affective response at time one
and has to infer what emotion it's feeling.
And then some time goes by, it's presented with another affective response,
it has to infer what it's feeling now, and then there's kind of delay period
where it has to kind of hold on to that information and manipulate it,
at which point it's exposed to a third affective response and it has to say,
okay, is what I'm feeling now the same or different from some of the stuff I was feeling before.
So it's kind of a reflection on current versus past emotional experience.
This is actually, you know, a thing not too dissimilar from stuff that can happen in therapy, right?
And it's also, well, here I'll get to this.
So the idea ultimately with the model, as I'll show you,
is you end up having these two nested tasks.
So first, you have this affective response that kind of comes up from your body
and you represent it, which can have various dimensional components,
valence, arousal, motivation, your kind of interpretation of a situation, things like that.
And the first task is to infer which emotion concept that you currently have acquired
best accounts for that pattern for lower level representations.
But at the second level, you have to take that and map it into working memory.
Then you have to kind of do something with it in working memory
to be able to self-report it and use it in collaborative cognition.
So task one is just to figure out what you're feeling at a given moment,
and task two is kind of accumulate evidence for what different things you're feeling over time
and then use them to deliberate to make a choice.
And I should say this particular task is motivated by the fact
that we've actually done some empirical work on emotion-focused working memory
with just little tasks like this where you show people emotional images
and you either ask them to hold what emotion they felt in mind
or just hold the visual image in mind or hold like their bodily sensations in mind
or hold nothing in mind over some delay period.
Then they have to make some judgment afterwards about whatever they were holding in mind.
And what you can find is actually consistent with the three process model
I showed you, you get in the emotion condition relative to just holding visual images in mind,
you get a lot of this medial prefrontal and anterior insula kind of default mode network kind of stuff.
Whereas in both conditions, actually emotion greater than rest
and also in vision greater than rest, you get this dorsolateral frontoparietal thing
that you'd expect for any kind of working memory.
So it's kind of like the representation may be specific,
but what's holding in mind is general.
And so suppose on previous work showing that just when people pay attention to their emotions
and just recognize them, you also get this default mode network activation.
But it's okay.
So the first level in the model, formerly, so it has this kind of structure where
there are a bunch of different things that you can observe.
You can observe different valences, different arousal levels, different approach or avoidance motivations,
and three just general different kind of evaluated contexts that you could be in.
It's called like a neutral context, a social threat context or a physical threat context.
And again, this is very just kind of toy model to get across the general structure.
But the idea is that what it is to have acquired different emotion concepts
is to have learned particular mappings to different sorts of regularities that occur across
those different lower level representations.
So for instance, and you can encode, you encode that in, for instance, the A matrix here.
So this basically says that sadness corresponds to negative valence, low arousal, avoidance,
and social threat, right?
Whereas happy on the end corresponds to neutral weight.
I might have that wrong.
Oh, no, sorry, that's heart attack.
My bad.
So it's sadness, panic, sickness, and heart attack, right?
It's like happy is negative, high arousal, avoid, and physical threat, right?
So I mean, that's kind of what it looks like.
It's encoded in those connections more or less.
And for this particular model, we're just assuming that within a trial and emotion remain stable.
So the B matrix is an identity matrix.
And then, you really can't see it down here, but down here, this is showing that the actual
affective response generation component right here would amount to sort of like visceral policy selection process, right?
You'd interpret your situation a certain way and you'd select, say, the like increased heart rate policy, right?
Or something more high dimensional than that, obviously.
So we're not explicitly modeling that there, we're just assuming a particular response has been generated,
that it's consistent with your evaluation of the context, and that you're just being,
the agent's kind of being presented with the result of that response.
And so, which I'm just highlighting here is that we're kind of assuming that's the case,
but we're not actually modeling the response generation.
That even lower level policy selection first.
And then the second component of the first level is there is a kind of selective attention component built in.
And the idea here is to figure out what you're feeling, you have to kind of selectively attend and say,
okay, what valence am I feeling?
Okay, you know, what does my body state feel like?
Oh, what do I feel like?
Do I feel like I should run away or, you know, approach?
You know, what are my actual beliefs about the situation?
Things like that.
This is actually the exact sort of thing that often people do in like cognitive behavioral therapy,
for example, where you kind of track patterns, right?
And like what you're thinking, what you're feeling, what you did, you know, stuff like that to try to increase people's awareness.
So it's meant to kind of mimic that process.
And so the idea is that the agent has to kind of choose what to pay attention to across the trial to infer what emotion makes the most, you know, best fits the experience.
And so you can kind of, the way that gets implemented is that the actual probability distribution in the A matrix becomes higher dimensional.
Essentially it's a different conditional on what attentional state you're in.
So if you're in the attend to valence state, then the A matrix looks like that.
If it's a tend to arousal, it looks like that.
If it's a tend to motivation, it looks like that.
And if it's a tend to context, it looks like that.
Right, so that's the way it ends up being structured.
So for the first level, then you can use that all by itself without tacking on the second level at all to do this kind of single emotion recognition process, right?
The emotional state representation component of the three process model.
And this is what it looks like when the model performs successfully.
So here, the agent was presented with an effective response that was most consistent with sadness, according to the concept it had learned.
And so you can see what happened is it first chooses to pay attention to context, and then it chooses to pay attention to arousal.
And then at that point, it says, okay, I'm confident based on the social threat context and low arousal that sadness is the right thing.
And so it reports sadness.
And then you can just kind of see over here how the confidence kind of shifts slowly toward being confident, most confident in sadness by the third time point in the trial.
They're on the right.
And this stuff on the bottom is just kind of simulated, simulated like the center-related potentials that you would see, but don't worry about that.
So then the second level then, the working memory component, involves doing a sort of similar thing.
So basically, what you have here is now, once the agent's inferred what emotion, say, sad or panic, or what other bodily state is sick or heart attack.
However, it's categorizing its data at a given time.
Those provide evidence over time for different things that could be held in working memory.
So this could be just being sad, just feeling panic, feeling both sadness and panic, et cetera, et cetera, for different combinations.
And then you have another independent hidden state factor that corresponds to the comparison state.
So essentially what you find out at the end, the third emotion that you're feeling, you have to judge whether it's the same or different from one of the original two.
And so the A matrix for that one just looks like that, which I can go into if you want, but it just describes that mapping, it just described.
And then there are a couple of additional hidden state factors you have to build in here.
Like you have to build in beliefs about the task structure.
The agent has to know, for instance, that it's at time point one, you know, in the working memory task, time point two, whether it's in the delay period, et cetera.
And then it also has to choose to report at the end of the trial just two things, just same or different, you know.
It was what I'm feeling the same as before or not.
And that leads to observations where it gets some feedback, where either it was, you know, it gets it right or it gets it wrong.
And the C matrix here just basically says it wants to get it right and it doesn't want to get it wrong.
And so this part would be modeling the kind of conscious access process more, where once you have these representations, you map them in and hold them in mind and you can do something with them.
And so a successful trial with the model here looks like this.
So at the first time point, so this middle panel here corresponds to the single state inference at the lower level.
So first it infers nothing, so we just call that blank.
The second time point, it infers it was feeling sadness.
So the third time panic, then blank again because it's the delay period.
Then at the fourth time point, it thinks it felt neutral and then blank again.
That's just the structure of the trial and what it experienced at each moment.
And you can see at the second level what happens is it slowly builds up confidence over time that the sadness plus panic state is the right one, right?
And then it holds that information in mind over this delay period after it observes the second emotion and then uses that at the end to choose to say different, in which case it observes that it was correct.
Can you be sad and funny?
What did you say?
I'll be sad and funny.
So I mean the idea is these are beliefs.
So these are beliefs about how it feels changed over time, right?
I'll be sad and funny.
Well, I mean so for instance, say you had a panic, I mean this is not uncommon.
You have a panic attack and then you're really sad the rest of the day that you had a panic attack, right?
What happens?
So the potential usefulness of this kind of thing other than just showing fancy flash simulations is that it allows you to kind of interrogate what are the different ways that things can go wrong?
What are the different possible mechanisms by which things could break down where you could have different potential intervention targets?
So the first one and I'll just sort of mention this really briefly is just you can maybe you're just failing to generate responses at all.
In which case just means visceral policies aren't being selected in the first place.
There's nothing to explicitly simulate there, but I mention it because it's probably not unreasonable thing to think happens in some cases.
So for instance, in one study we did, we actually did find that the thinner visceral motor cortices were, the lower emotional awareness scores were.
So suggestive.
More interestingly, we've done some, we reported on these case studies, these extreme sort of rare cases where for instance this woman just reports she's never experienced an emotion in her whole life.
Just flat, just emotionless experience.
And she's really like paradoxically distressed by it because she ultimately committed suicide because she said her life felt meaningless without any emotion.
And when we did like skin conductance responses on her, totally flat. No responses to emotional images whatsoever.
But it was more just like they were kind of incoherent responses because she would be talking in a therapy session about like for instance her marriage failing.
And tears would well up in her eyes, but her face would be totally flat otherwise.
And like therapist would say, hey, it looks like you're like crying. She's like, yeah, you know, I don't control this. My eyes just do that sometimes.
And so point being, it's not inconsistent that this is the explanation in some cases.
And I mean, there is some actual developmental literature, you know, suggesting ways this could kind of happen to write.
So if you look at the sort of drawing version of how people's body feels when they're feeling different emotions.
Six year olds, like if you look at sadness, six year olds, it's pretty like nondescript, basically nothing, whereas in adults it's really highly specific, right?
So you could imagine ways in which the six year old version just persists under certain sorts of like unfortunate developmental circumstances or something like that, right?
So the next version, so just like all failure to infer.
And this corresponds to something we've talked about in the past called affective agnosia.
The idea being something a lot like a visual agnosia where, what just happened?
Okay, right. So the basic idea is kind of just like with like an associated visual agnosia where you could have like an experience, perceptual experience like that shovel, right?
A person could drop for you and everything, but you ask them what is it and they have no idea, right?
Or they misrecognize it as something else.
So there's a similar sort of thing that could happen, but in the sort of emotional realm, affective agnosia, where a person perceives and could describe the bodily feeling, but just doesn't recognize what it means.
And often what will happen in this case is that it'll be misrecognized as something else.
And so in the somatization case, you might say, think you're feeling, you know, have a bodily sensation consistent with fear or panic, but instead infer, oh, this is a heart attack, which often happens.
People with panic attacks often run to the ER, right?
So one way to make sense of this or potentially, right, would be if a person's just learned to have a really strong prior expectation for threatening somatic states.
One interesting example of this is people with high anxiety sensitivity scores, like actually characterizes just that.
And this is actually something in part that we've talked about in a recent paper where we're trying to kind of give explanations for why early adversity is actually associated with high oils and chronic pain.
I don't have time to get into it, but if you're interested.
And so here, I mean, it's interesting what actually happens.
If you give the thing higher prior expectations for sickness and heart attack, right, for the threatening somatic states, then what happens is basically the model that jumps to conclusions too quickly.
Like all it does is pay attention to its arousal level, sees high arousal, and it's like, oh, I already know.
You know, so it just says it's having a heart attack.
It doesn't, it's too confident, right?
So it doesn't pay attention to the context or anything else that would allow it to say, okay, no, I'm probably just having some anxiety.
Yes.
So I'm not going to finish it all if I don't take a power through here, but we can talk at the end.
And so, again, I should probably skip some of the empirical work here just given time.
But basically we have shown that if you look at people with different emotional awareness levels, the default mode network actually only activates more than somatic representation systems.
If you have high emotional awareness, so it looks like you don't really differentiate emotions from bodily sensations at the low end, which is kind of consistent with this idea.
So a third one, so could be that you just, you just haven't acquired emotion concepts, right?
So consider like a person who grows up in like an environment with a lot of like just early parental neglect.
You don't have the attunement, you don't have the, you know, social feedback signals to learn about these things.
And so you just don't acquire them.
And this is probably also something that contributes a lot to if you want to understand things like the relationship between social support and disease.
We've talked about in this sort of computational variant of the, trying to understand the biopsychosocial model in medicine.
We've talked about this a little bit there, but you, yeah, like if you don't have the early support and you're not going to learn the things that you're going to need to learn.
And that can lead to a bunch of things that can promote systemic disease later in life, short version.
But so here, really, all you have to do to mimic not having acquired emotion concepts is just to get rid or flatten out the, you know, connections between the emotion concepts and what they predict, right?
If those states don't predict anything specific, that's the same thing as saying you don't have those concepts.
And so if you do that, then, skip that, then what happens is unsurprisingly, the thing never really becomes very confident no matter what it experiences.
At the end of the day, it's like, okay, I have to report something, so it just reports that it feels bad.
It's not confident, it knows it's feeling an emotion, but it's not confident enough to pick a specific one and it doesn't want to be wrong.
So it just says bad.
And interestingly, this version predicts that you'd have much longer reaction times, right?
So in the first version, if somebody has a low emotional awareness score, they have a really fast reaction time because they jump to conclusions really quickly, right?
Whereas this person sits around for a while and they're like, I don't know what's going on, right?
So like you could actually test just based on reaction times, which one of these sorts of mechanisms was most plausible when you give an individual.
I think that's a very important distinction and finding because you could also make the argument that a distinction being good and bad is just a very crude, low level distinction that should be made very quickly.
Reptiles can decide whether they're bad.
But this is saying no, actually, it's really related to some kind of ambivalence and ambiguity that the individual's having trouble resolving.
Yeah, or it could be, at least in certain people, right?
Yeah, so it'd be cool to be able to say, you have fast reaction times, you have slow reaction times, therefore I treat you with treatment A, treat you with treatment B.
That would be kind of the hope.
And again, just briefly, we've done some work with resting state functional connectivity, showing that if you think about functional connections as reflecting, differentiated,
say like synaptic connection patterns of corresponded learning, then what we found is in both the default network and in salience network, body state representation regions, you have much lower functional connectivity at rest than people with low emotional awareness.
So at least something about the fidelity of that kind of processing is not as great.
This is just some of the data in correlations.
But I should just mention, we have another paper that's under review right now where we actually simulate the emotion concept learning process itself, with active inference and that also is kind of a cool story about when learning can go wrong, but not going to talk about that here.
So then a fourth possible mechanism is just having learned bias patterns of attention.
This is another thing that comes in a lot actually when thinking about chronic pain in the context of chronic negative effective states.
But we've talked about before.
But here, I mean, it's pretty simple.
You just use the e-matrix thing, the prior over policies, and you just say, this person has a really strong habit of only paying attention to context for an external attention bias, or this person has a really strong prior that they're going to attend only to the internal stuff.
As it's set up, you have to integrate context information with the body student information to be good at inferring what you're feeling or understanding it.
And so if you simulate these different sorts of attentional biases, you get low emotional awareness behavior, but they have different patterns.
You know, in one, if it's an external bias, if they're kind of like averse to paying attention to the other body altogether, right, then they just end up reporting, you know, pattern good.
Whereas if they ignore context and just have this hyper focus on their body, then they just tend to kind of report kind of like an emotion thing or a body thing kind of half and half, right, they're just kind of inconsistent.
The fifth one, again, I'm just kind of rushing through this quickly because we're short on time.
Something that's interesting in the context of borderline personality disorder is this idea about beliefs and emotional instability or high emotional volatility.
If you just believe that you could be sad in one moment, happy in the next, and right, if you don't think the emotion's absolutely minimal amount of stability, then it actually becomes really hard to learn about them or infer them if you have to selectively integrate information about them over time, right.
So in this case, you just flatten out the B matrix down here to say, look, like emotions are allowed to transition to other emotions or to somatic states within trial.
Then what you end up with something like this, where the thing's just not confident at every moment, it just rechecks the same thing it looked at before because then something could have changed.
And what you end up with is things like it starts out believing that it was feeling panic, but by the end itself reports that it's feeling having a heart attack.
So it might have started out as just panic, but now it's a heart attack.
So it's another thing that's kind of interesting.
And then the last two mechanisms are when you have to invoke kind of this higher level, right, the working memory level.
And here, I mean again, just review papers on stuff if you're interested in more detail, but the idea is how do you kind of model this presence or absence of this strong connect, strong causal influence that actually updates the higher level.
And this is also motivated by some work we've done, some graph theoretic analyses that we've done, showing that actually if you look at individual differences in emotional awareness, they actually correlate with lower network density and with longer average path lengths.
So those are just two measures of essentially a long range information integration.
So if you have higher emotional awareness, you're better at propagating the signals over long ranges, right, so kind of consistent with this general idea that this is a possible thing.
And here, it's a similar kind of trick, you just take these connections from the first level to the second level, and any of them that involve updating based on emotional information at the first level, you flatten out.
Which is essentially the same thing as saying the first level representation is no longer have causal influence on the higher level, right.
And if you do that, then what's really cool is you get something a lot like unconscious emotion priming, right.
So at the first level, it is representing sadness and then panic and then neutral, right, that's there.
But just in kind of this prime state that could have some kind of semantic priming effects, but it doesn't update the higher level at all.
So the thing can't hold the emotions in mind, work with them at all, and it gets it wrong when it needs to report something or think about, supposedly think about what it's feeling.
And then the final one, one that's kind of interesting in clinical context with some of the clinical clinicians that I've worked with in the past, has to do with this idea about sort of state differences and reflective capacity.
The idea here is that, again, the image doesn't show up that well, but there's this really like well-known result that cognitive performance, like the ability to kind of reflect on things, cognitive control, working memory, all that stuff.
Tends to be best at this kind of middle level of arousal. If you're like really highly anxious, then all of a sudden you can't reflect on anything at all and decision-making becomes a lot more impulsive and unreflective, typically not all that adaptive.
And one way to think about this is that in higher arousal states, the predictability or the precision assigned to the higher levels of processing, like that reflect these sort of long timescale regularities,
those just kind of get assigned low precision, because in threatening context, sort of historically, you act now or you're eating, right?
It doesn't make sense to assign high precision to those, to the high levels in those contexts.
And so you can kind of think about this as in a state-dependent way, decreasing the transition precision at the higher level,
which Thomas Parr and other people have previously already shown. This is a way to mimic lower working memory capacity, as well as essentially the same kind of idea.
So what happens in this case is, even say, if at time point two, it knew that it was feeling, it was feeling, in this case, panic, then that just kind of decays away over time.
So it can't actually, even though it knew it at one point in time, it can't hold it in mind and actually use it.
And so that's just yet another kind of mechanism. And again, I wish you could see it better on the image, because it really does kind of just decay away until the probability distribution becomes flat by the end.
But so anyway, so the idea is basically you can use this and you can show, look, there's at least these seven different independent mechanisms that could be messed up or working suboptimally,
that could lead to the same or very similar clinical phenotype, but they have different underlying causes and you would target them differently.
And we've actually, in our paper, we actually outlined, and you can't see it, but for each of the different mechanisms, there are different sort of clinical evaluations that are currently used,
different relevant measures that are currently used, that you could use to evaluate them, and different interventions that look like they target some more than others.
And there are also gaps where you can design things that would more effectively target one versus the other, but a lot of it is kind of out there somewhere.
It's just not framed in this way or selected. You know, treatments are selected based on this kind of thing.
And so the basic idea is, is that like I said, there's a bunch of these different possible mechanisms.
You could actually test them based either on different predicted normal response patterns or behavioral patterns like reaction time differences.
And, you know, if that ends up working, you have to do experimental work to actually test that, but in principle, you could use that to identify mechanisms that operate in single individuals and then use that for targeted intervention.
So with that, tons of people to acknowledge, but top of the list would be Carl Fursten, Thomas Parr, Richard Lane, Maxwell, Gasper, Paul Badcock, Scott Koldor, and a bunch of other people.
Thank you.
