that ability to plan I think is really important and what does that mean from the point of view
of the nature of the generative model well it simply means that to plan is to have a prediction
of the consequence of action in the future and simply saying in the future immediately says
you've got the kind of generative model that is freed from the moment so this is like
the present so you've got a generative model now that requires a temporal depth it has a horizon
in the future which is quite remarkable thermostat doesn't have that a virus won't have that you
could even i got small insects don't have that but things that plan things that choose to do this
or that must at some level this can be described as if they had a generative model that requires a
temporal depth and I think in that sense as soon as you're choosing between one plan and another
plan you are truly an agent and you have a you know some a biological autonomy which many things
don't have and that brings with it an interesting question which brings us back to this notion of
how do you choose the best plans if the imperative is to minimize surprise well the best plan would
be that which minimizes the surprise expected if you pursue that plan and again we come back
what does that mean it means i'm going to resolve uncertainty which simply means that anything that
can plan that exists must look at some level as if it is curious it will want to go and
technically maximize its expected information game which is the important part of this expected
free energy or expected surprise all so what you're saying now is that there may be another
bright line between things that move that are not curious and things that move that are curious
and I would say that to be a true agent you have to have that curiosity you have to move in a way
that resolves uncertainty about the state of affairs out there on the basis of your actively
sample sensations
Carl Friston genuinely needs known production if you spend any time around this channel
or are interested in neuroscience in the mind you probably already know who he is
he is one of the world's most eminent and impactful neuroscientists
having made countless contributions to neuroscience brain imaging and more
here we flush out the free energy principle and the development of the active inference
framework and look at a couple of related applications so we talk about cognition the
4e approaches particularly inactivism and affordances the idea of affordances
we talk a bit about consciousness and metacognition and more if you like these conversations
and would like them to continue please consider subscribing to the channel that really really
helps us out here is my conversation with Carl Friston could you tell us about the history of
predictive processing before the free energy principle I could it would take a long time
in the sense that the notion of predictive processing which I tend to regard as something
called active inference I think was probably born in the days of Plato was articulated in
philosophy by people like Kant and then taken up in a much more by physical sense by Helmholtz
in the 19th century and then has a sort of fluctuating history throughout the 20th century
suppressed to a certain extent by behaviorism and sort of a focus on the overt behavior of systems
things like reinforcement learning but underneath that there was there were notions of things like
analysis by synthesis perception as hypothesis testing perceptual control theory the cybernetics
movement things like the good regulator theorem all of these are probably quite obscure notions
nowadays but they do speak to a very rich and enduring legacy of this style of thinking
and this style of thinking is quite simply the sentient artifacts sentient creatures
brains you and me are in the game of predicting what would happen if I did that or what would
happen if I was right about the state of the world that's generating my sensations so it's
a construction or a view of sentient behavior which puts the brain very much in an active
and constructive mode that it's generating hypotheses explanations that are a best fit
to the sensory evidence supplied by the outside world so that's the emphasis on predictive
the processing information processing I would read that as inference or learning and depending
upon the time scale so you put the two together you get predictive predictive processing which is now
the term is interesting I think was probably due to Andy Clark who's you know one of the world's
most famous philosophers and certainly neuro philosophers and I think he brought it to the
table to provide a label for a more generic way of understanding sense making in the service of
inaction in a situated context in an inactive context in a way that distinguished it from
very particular instances of implementations such as predictive coding so predictive coding
was something that had been around for compressing sound files since the since the the 1950s
but suddenly was a focus of attention in the neurosciences as a plausible way of compressing
data by prediction in a really efficient way in the spirit of sense making and perception
so what Andy wanted to do I think was say well yes that's fine but predictive coding in and of
itself doesn't have this inactive situated embedded aspect to it so let's think about
sort of you know how you'd make how you'd make predictive coding work in an artifact that actually
had to go and gather its own data and exchange an act upon the world so that's that's my view of
predictive processing and the reason for the active inference is it emphasizes the active part
but under the hood all of these processes all of these ways of framing sense making
can be expressed as the process of inference and or learning at a longer time scale
so is the addition that you're making going from just looking at it as a sensation information
loop to adding active inference to it so adding actual movement to it that's absolutely right
yeah I mean something obviously which people have been acutely aware of you know you have the four
ease movement you know extended embedded and you know and so on you have notions of the action
perception cycle so in both of these sort of what we could almost say paradigm shifts at the
beginning of this century there's this realization that closing the circle between as you put it as
of the the information the sense making the feed the other the coupling from the environment into the
the sense making organ or the brain and closing the circle literally a perception action circle by
now saying well now the brain is in charge of setting the set points for its actuators its
reflexes so that he can act upon the world that then generates more data so you're closing the loop
so you've got sort of a bi-directional a circular causality in play which makes this much much
more interesting so you know sometimes I like to think of this in terms of you know pre active
inference and pre sort of predictive processing formulations of sentient behavior certainly in
the cognitive sciences and possibly even in machine learning that you're you were thinking about pure
sense making and how that could be articulated in terms of inference very much along the lines of
how a statistician would make sense of data how a machine learning person would do some classification
would recognize things but then you put on top of that okay what are you going to do about that
and of course one as soon as you put that into the game then you have to address the rather
vexed and intriguing question okay I've got these data and I've made sense of them but now I'm in
charge of gathering the data that I'm making sense of and now you have a model which is much more
apt for describing things like you and me and indeed scientists you know what do they do this
when half their time performing experiments they're acting on the world to generate some data then
they try to make sense of it they test the hypotheses so it's you know that sort of circular
causality that action perception cycle I think is quite fundamental to this account of self
organization right right it's it's a tricky history because I mean at some point we had a
break away from behaviorism and looking at the brain as input output to seeing the deep deep
nuances and complexities of the action perception cycle but it's it's never clear where that break
happened if it was a one-pointer or how it developed it seems like a long story to get to it
yeah yes you're probably in a better position to summarize that narrative you know from my
perspective it really has been a obviously yin yang from what I know of the history and of course
we were both too young to really know what actually was going on but certainly the rise of behaviorism
and then it's demise you know when you know you know with a greater focus on influence and
classification and hypothesis testing and then perhaps nowadays perhaps in this century the
two are seen to work hand in hand perhaps that dialectic is not quite so quite so evident
but you know it would be fascinating to read a book about you know all the different waves of
understanding different kinds of intelligence over the past two centuries now I would imagine
right right right yeah it's spread out through so many fields and disciplines and people that
it's very tricky to sort it all out yeah okay so moving on the free energy principle do you
mind just describing the free energy principle right not at all there are two ways of describing it
I can either describe it from the bottom up or from the top down so in a sense I think we've
already covered the the basic tenets of the free energy principle from a sort of low road bottom
up approach understood or read through the eyes of people trying to understand their own behavior
and the behavior of animals and other biological creatures biological biotic self-organization
and that story is basically what are the imperatives for good predictive processing well it's quite
simple you just basically want to minimize your surprise well what does that mean well it
basically means being able to predict reliably eridically then the sensations that you're
encountering both in the moment and as a consequence of of moving but in the moment
this is a sort of the predictive coding perspective in the moment if I've got some sensations and I
want an explanation that is most apt for describing those sensations then I have to have a model
that articulates and expresses my explanation of what produced what generated those those
sensations that's in my world called a generative model in machine learning it might be called a
world model an internal model irrespective of what you want to call it it's basically
a probabilistic specification of what I would see if this was the state of the world out there
and if I now want to minimize my surprise that is exactly the same as saying I want to render
my beliefs about what's going on out there such that these sensations these data are the least
surprising technically have the highest marginal likelihood given my model of the world so that
quantity underwrites nearly all imperatives and objective functions in statistics in the
machine learning and evolution wherever you look this fundamental quantity this sort of
I call it surprise you could also call it the log marginal likelihood you could also call it the
logarithm of the model evidence the evidence for a particular model of some data if you're
in theoretical biology and your evolution with theorists you might even call it adaptive fitness
it's just the the likelihood of a particular phenotype being a good fit wall or being a good
model of the its eco niche or its environment so wherever you look this this fundamental
quantity appears to be optimized in the sense and it will look as if you are basically just
positioning yourself or sampling the world in order to minimize surprise and when you take
this notion into the inactive domain clearly in choosing what to do next you don't have the
sensations that ensue before you've made the movement so now you have to appeal to well what
would I see if I did that and then you choose what to do on the basis of minimizing the expected
surprise the surprise expected following that particular plan relative to another plan technically
that's called entropy or uncertainty so all we're saying is that we act in a way to
to minimize the uncertainty about what the uncertainty about the causes of our of our
sensations so that link I think is it is also useful in our conversation because it says
you now have an opportunity to express this imperative in terms of information theory
so because this fundamental quality this model evidence or this marginal likelihood or adaptive
fitness can be written as self-information in information theory which is another
technical description of surprise or surprise whereas the average of the self-information
or surprise or is entropy so it all fits together very beautifully and license is now a description
of this characterization of self-organizing systems in terms of information theory and
that's where the free energy principle gets you know gets into the game and you may be asking well
why free energy and I can tell you I'm not sure how much depth to go into perhaps very briefly
it would be a simple and almost tautological problem if we just describe systems as minimizing
their self-information or minimizing their surprise or minimizing their surprise
however that would entail the the ability of any system to actually evaluate this marginal
likelihood or this fundamental quality the surprise mathematically you can't do that you
can't physically realize this so what you do or what one does is when you're faced with these
impossible integration inference marginalization problems is to create it into an optimization
problem by inducing a quantity that you can measure you can represent you can compute
that is always a bound in the sense it's always smaller than or bigger than the thing you want to
maximize or minimize so in machine learning that bound is known as an evidence lower bound
so if you recall surprise, the negative surprise is the logarithm of the evidence and model evidence
so the evidence lower bound now becomes this variational free energy which means that if you
keep on pushing it up you're guaranteed to actually maximize to within the bound approximation
the thing that you want to maximize or you think is maximized by sentient creatures or
things that exchange in a sort of Bayes optimal way you'll take reading reading this in terms of
inference in physics the signs change so in physics you want to minimize the free energy
so you have to multiply anything by my one this is very confusing for everybody
but it has to be said so what that means is that this bound approximation
that was invented on most readings of the history by Richard Feynman when he was converting
an impossible path integral literary in the path of formulation quantum electrodynamics
that integration problem was insoluble so he converted it into an optimization problem by
equipping academia with this variational free energy bound using variational calculus
and in that world you want to minimize a free energy and this in turn is exactly what people
like ET James were saying when they were talking about physics as measurement physics as a process
of inference and of course because free energy is equal to some expected energy minus the entropy
minimizing free energy now becomes a maximum entropy principle so the maximum entropy principle
just is the free energy principle qualified by the fact that of course we're talking about a
maximum entropy principle under constraints where the constraints come from when they come from that
that expected energy what is that energy it's just the expected surprise or the surprise or
it's the the accuracy if you like with which you can predict your current sensations given
given a particular hypothesis or measurement or inference about what generated those particular
those particular measurements so i've just given you a bit of the top down high road
explanation for the free energy principle but on the back of linking
predictive processing to the physics of sentience via the via information theory
there is actually one more part of the story that really is free energy principle and that's
the observation that any system that individuates itself from the rest of the universe that is
statistically separable in some in a certain sense from the rest of the universe and must have a
dynamics that looks as if it's doing a gradient flow on this exactly you exactly the same quantity
a gradient flow on the physicists free energy or you know if you if you take out the bound
this is just on the surprising which means that now you can understand neuronal dynamics the
dynamics of message passing and bleed propagation as something that is necessarily part of the
dynamics of any system that manages to maintain itself as individuated or separate from its
embedding space or its environmental or or e-cognition right so so then can we use that as as a benchmark
to as a criteria for life that any system that resists entropy and uses that principle
is a living system and then we can find a line from where there's no life and then there's life i
know that's a very touchy subject and probably probably generalizing far more than that's what's
allowed oh yeah i think i think it's a great subject and a great question um so and it's
something which is occupying um many of my colleagues who are um thinking about the
applications of the free energy principle i should just qualify as a free energy principle
in and of itself is not terribly useful um you know it's a little bit like um you know
Hamilton's principle of least action you know or the theory of natural selection you're knowing it
is very pleasing and you know it's a conceptually nice and pretty and round and it makes a lot of
sense but it doesn't actually do very much for you until you apply it and so you have to apply
the free energy principle to something and usually that something is a description of a
self-organizing system with a particular generative model so you know so i just just make that point
but a lot of people are now thinking about well what kinds of systems and what kinds of
generative models would license you to draw a bright line between systems that persist over time
that are non-living versus biotic systems and then within biotic systems um you know to what extent
can they be thought of as agents and having a degree of autonomy and then within those to what
extent can you ascribe them um uh sentence and to what and then within those to what extent can
you ascribe them self-awareness and consciousness and also there are you know i think it's a really
great question in answer to your question i would very simply say that um systems that look as if
they comply with the free energy principle um or actually by definition to exist as a system
means that you are separable from not system and therefore you must comply with the free energy
principle um but um you can comply with it in different ways and um one key thing i think
that does draw a bright line between living and non-living is the ability to move it's really
really simple um technically in my world that separation is mediated by something called a
Markov blanket so you've got this notion of um you're carving up all the states of a universe
into four parts the first are the states that are internal to the system say for example your
neural activity and connectivity um and then the second part are the external states everything in
the outside world that might include your body if your internal states for your brain states
and then crucially the thing that individuates or separates or distinguishes that keeps apart
statistically the inside from the outside and that's the Markov blanket and that can be carved into
two one is mediates the influences of the inside on the uh of the outside on the inside so one way
traffic and then the other one is the um the states that mediate the influence of the inside
on the on the outside again it's one way traffic to a certain extent and it's that one way traffic
that preserves its distinction um so that that that construct um then suggests that there's a very
simple taxonomy of things um that first of all do and do not possess active states so what does
that mean well it just means that they can't act upon their world so a stone doesn't you know if
you looked at a stone and you looked at a tortoise um you know forget about everything else the reason
you might think the tortoise was a living and the stone wasn't is simply because it moves
and that's just an expression of having active states to complete that sort of Markov blanket or
sometimes referred to as a particular partition the reason for particular partition is that
you know as a physicist you might regard the internal states and their blanket states as a
particle in a universe um so that would be the first thing so i'd say that living stuff is
are just things that um endure overtime in virtue of the fact that they are moving
so is this why the the low road in the high road distinction has been useful uh in implying the
free energy principle if you have a high road where you sort of just know what the what the
directive is what the what the objective function will look like then it's easier for people doing
that work because they just have that reference point rather than having the whole constructive
history yeah yes yeah i'm going to read your question as saying you know what's the utility
of having something like a free energy principle and if you meant it in that spirit then absolutely
it just provides a relatively simple account of the way that things are and the way that things
behave or must be must behave if they exist and then within that relatively straightforward
bit of physics and differential equations and density dynamics um then you can see the kinds
of behaviors that you are very much interested in if you are an economist or you are in machine
learning or you are in cognitive neuroscience um and you know you can see how all your favorite
schemes and ideas suddenly have to be right and have to be enacted and also how they relate to each
other and all the special cases you get and you've just identified a really special case which is
the non-living thing that exists and possibly is making lots of sense it's still probably doing
predictive coding so just think about the stone the internal states of the stone will
equilibrate thermodynamically with the temperature of the surface it's marco blanket so it's still
making sense and modeling its environment in the sense it's representing the temperature
of its local external milieu uh but of course it's not moving so you know so you're stuck in
the 20th century without worry you're stuck in the days of predictive coding because you haven't
thought about what your can the same imperatives and minimizing surprise or expected free energy
um in a physicist's sense uh can they also be applied to the way that we act and of course then
you start to think about well what would that look like well it would simply mean um acting or
changing acting upon the external states in a way to minimize surprise what would that be
it would be a thermostat it would be a homeostat it would just be the simplest description of the
simplest kind of biological self-organization named with the physiology of homeostasis keeping
things within bounds minimizing surprises about excursions from um um equilibrium or set points
that that characterize the creature the creature at hand and expressing like that immediately
takes you back to the 1940s and the the inception of cybernetics for example rosh ashbiz homeostat
and which is just about this you know this kind of just simple imperative is keeping things within
bounds and how do you sort of position yourself so that you can keep things within with in bounds
using this simple reflex like sort of circular causality between perception and action of a
very very elemental sort and so you know that's you know to my mind a nice illustration of how all
these things suddenly fit together under relatively simple um physics or mechanics um
afforded just by thinking about the fundamentals of um of how your water thing is and how it
maintains its separation from the rest of the world just by keeping certain states
sensed states within within bounds and using that kind of language you see immediately well
this is exactly what people um in biology were trying to articulate when they're talking about
autopoiesis you know self assembly self creation more like self maintenance from my perspective
but you know you you get the spirit if you're a chemist you're talking about self assembly
and then you can start talking about oh does this relate to curing pattern formation reaction
diffusion systems what are special about these kinds of things and then you say oh i see they're
just statements of steady state plan formation far from equilibrium so immediately now back to the
physics the information theoretic physics um of um non-equilibrium steady states which is where we
started with the free energy principle trying to work out the dynamics of something that is an
open exchange with its environment with its heat bath if you like uh via this permeable mark mark
off blanket so it all starts out to hang together i should just mention other things which people
get upset when we ignore or when when when i ignore things like perceptual control theory
um so you know the notion that all of our purposeful behavior is just in the service of keeping
our sensations our sensed world within uh viable viable bounds and you know that's you know a
sufficient explanation of any of any behavior i'm absolutely right it's just keeping that surprise down
right so okay going back to going back to the four e approaches or four e a i should say um do
how do you feel about like the strong version of the of the claim that that all perception is in
some sense influenced by the affordance that is related the affordance of how you could interact
with that perception right right yeah that's a subtle question because you've introduced the
notion of affordance there do we all will all listeners know what affordance means or do you
want to just unpack the importance of the concept yeah i mean i think you could do a far better
job than i but just simply the idea that um when you're in perception there's this bias
where you're constructing perceptual models based on how you can interact with with
whatever is being perceived uh in a very very elementary way but i'm sure you could do a far
better job than me no i can't improve upon that so uh so yeah um so your question is about um
radical inactivism and does that fit comfortably um with our with our theoretical thinking um
i have to confess it doesn't really but i'm i say that in a qualified way because i change
my story depending on who i'm talking to so i i'm quite happy batting for both sides
so it depends so i have friends in philosophy who are committed skeptics and committed realists and
um uh so i you know i will change my my nuancing or my interpretation of free energy principle
to suit who i'm talking to in a sense so i think the free energy principle um does dissolve some
of that dialectic um but it still leaves i think big open questions so radical inactivism
in and of itself is just a little bit too radical for my taste um and the reason is the whole point
of inference um or casting sentient behavior as a process of inference and learning is that you are
belief updating that you are if you define inference it's basically changing your mind
in order to better infer what's going on out there cast in terms of abductive reasoning as
opposed to inductive or deductive reasoning immediately are in the world of beliefs probability
and i i should qualify that when i talk about these things i don't mean sort of folk psychology
beliefs or propositional beliefs i'm talking about basing beliefs conditional probability
distributions whose sufficient statistics are physically embodied in your neural activity or
your connectivity but crucially they still have a mathematical description of beliefs
and if you your whole framework is predicated on effectively um a description of basing belief
updating articulated information theory it's rather difficult to deny the possibility of
representations simply because these are probabilistic representations and you know
all i would do if confronted with a radical inactivist is rush away and find a friend in
quantum physics because in quantum physics everything is a belief it's all about there's
nothing but probabilistic descriptions inferences and wave functions probability distributions
basing beliefs so that all of physics really is is sort of i think beyond the reach of radical
of radical inactivism so for me radical activism is a bit too radical because it denies representation
however that doesn't mean to say that you know you can still adopt a sort of you know either a
realist or anti-realist approach and and look at that approach or stands through the lens of the
free energy principle ask does it have any currency and i think both both approaches both
views i think do have some currency one the whole point or the the the foundation of the
basing mechanics that inherits from the free energy principle simply is this separation
of the particle or the thing from the rest of the the universe and in that separation what that
means is that the the basing mechanics the constrained maximum entropy principle as applied
to the internal states is forever secluded from the external states so you'll never know what's
going on out there there is no way of knowing if there was a way of knowing if there was a way of
establishing some direct contacts and direct causal influence influences from the outside to
the inside you would have breached your markoff blanket and you would cease to be the thing that
you were so by definition to be something means you can never know what everything else is
so that that fits comfortably with a skeptical position but the problem is that if you're
the other the realist position is of course if you're making influences about something that is
meant to be generating your sensations the sensory states of your markoff blanket
then there has to be something out there doing that so that takes you to a realist position
but i think you can argue for both sides if you really wanted to do you think do you think
evolutionary processes play play a role here donald hopman has argued from the evolutionary
standpoint that that although there is something out there all you have to do is look at look at
the rules the models that govern evolutionary behavior then you could ask the question whether
they would optimize for a system that has that preserves some's world homomorphism with what's
going on inside or not and then he argues that they don't there there's a zero probability that
they do um yeah what do you think about that um well i think and um i should say quite a number
of my international colleagues also think that there's a really profound and illuminating link
between um this formulation of um self-organization in terms of a Bayesian mechanics or a a sort of
belief updating description of how we optimize our beliefs and in generative models and evolution
itself um so that can be if you like um expressed at a number of different levels
you're an implicit against a really good question because he actually speaks a little bit to what
we're just talking about in terms of you know what's on the outside um so the first thing to say
is that i think it's now among the people i talk to so i i don't know if there are people out there
who like an argument who don't take this position but the people i talk to would certainly accept
that evolution just is um a um a surprise or model evidence um minimizing maximizing respectively
process um and the way that's normally articulated is um in the following sense that if you read
optimization of the model evidence or its free energy bound um as a model selection so say i've
got two models in play that i can bring to the table to explain all these sensory exchanges
say over a lifetime um and the two models are now scored in terms of their goodness how optimal
they are how fit they are or how fit the purpose they are in that environment generating those
sensory exchanges so we're talking about adaptive fitness basically where we're reading adaptive
fitness as the likelihood that this model would fit with this environment that it could predict
and explain all its environmental exchanges so if you read now um the selection or Bayesian model
selection that's simply the um the selection of the model with the highest evidence or the highest
adaptive fitness you now have a mathematical image of natural selection so it's i don't think
that evolution if you like um sets the scene for the emergence of the free energy principle
i certainly do not think that i think evolution is an example of the free energy principle
and it's an example of the surprise minimization the evidence maximization the adaptive fitness
maximization when you get a separation of scales and that's the big point i wanted to
get to which speaks to what we're talking about before so you know when you start to deploy or
apply the free energy principle um as many people are currently doing um at ensembles of things and
at different scales you now reach this really interesting um question well what would happen
if all of these particles were um maximizing them uh the model evidence sometimes people like Jacob
Howie another um well-renowned philosopher would refer to as self-evidencing as you know
a shorthand of this kind of Bayesian mechanics or self-organization if if you had a whole bunch of
things say cells or people who are all self-evidencing with their own little Markov blankets all
individuated nicely but exchanging with each other what would happen if now the whole ensemble
had its own Markov blankets so now you have a community of cells and then what would happen
if that community of communities had its own national boundary and you start now to think about
the this kind of Bayesian mechanics playing out at different scales both in space and in time
so I would regard evolution as simply a Bayesian model selection process that plays out very very
slowly on a sort of transgenerational level and what it's doing it's selecting for those
phenotypes or generative models that are on a much faster scale do all the sense making and the
predictive processing that we that we try and study and celebrate and say cognitive science or
machine learning but at both scales exactly the same mechanics is going on it's just a gradient
flow or can be read as an optimization process which is minimizing the physicist's free energy
which is an attribute of the beliefs entailed by a particular physical structure you know of the
of the internal states of the thing so I think that sort of putting or applying the free energy
principle in this in this in this hierarchical and scale invariant context is a really important
move because what it tells you is you can't look at any individual thing in isolation you always
have to think about you know the context of which is which it operates so you know one way of saying
that is that in order for my dendritic processes in a hippocampal neuron to oscillate at a gamma
frequency I have to have the right neural circuit the right brain region the right neural population
which has its own Markov blanket in order for that functionally specialised neural distributed
neural circuit to exist it has to exist in the context of a larger organ with the right functional
architectures the right Markov blankets and the right integration named in the brain in order for
that to exist it has to exist in a body in order for the body to exist it has to exist in a family
or a community in order for the community and you can go right up to Gaia and beyond and increasing
increasing spatial temple scales but the same principles are operating at every scale so every
scale if there is something there whether it's a species or an ecosystem it must have a Markov
boundary by definition in my world and therefore must there must be some aspect of its dynamics
that look as if it the state's internal to that thing that defined the Markov blanket that defines
the thing in question at the scaling question must be minimising a bound on the log model
evidence indeed the model evidence itself for that collective and that has to hold every scale
so that will be another way of dissolving the realist anti-realist argument that you know
it depends upon what scale you're operating so from the point of view of my brain I can have
an argument with a philosopher about being skeptical but from the point of view of
that cell in my hippocampus I can't have that kind of argument it really doesn't matter it's not on
the right it's not posed at the right on the right scale and of course you can't actually say you
kind of have countries arguing about that to a certain extent because they argue about other things
do you think just as I do you think that has implications for the idea of identity or or
self in that the scale at which you can identify the Markov blanket is is useful in in figuring out
what the self is what the system that you're looking at is so if the Markov blanket is at the
state is at the scale of a society then you're looking at a society if it's at the scale of
people in the market making rational decisions then you're looking at economy and so on so forth
yeah no absolutely again another very astute question there I mean I personally am not working
explicitly on this but there are many people who are earnestly and in quite an excited way
working on this ranging from people who are trying to induce a move away from behavioral
economics to cognitive economic so so to actually get uncertainty and confidence in the markets
into a formal calculus and a mechanics that you can actually simulate and predict and understand
how markets and and trainers and you know how institutions behave and respond and act upon
their external milieu which you know because it's composed of other institutions so you know these
to leverage or realize the the potential of the Fianchi principle in application
the first step is to identify those particular partitions you're absolutely right so identify
what is a thing once you identify what a thing is then your job is basically building or deciding
what kinds of internal architectures the structure of institution or the structure of your brain
or indeed the intracellular structure of a neuron what what kinds of structures computational
architectures usually sparse ones would be required to provide an explanation for all the
sensory information that's impinging upon that particular boundary so if you're a cell it'd be
presynaptic inputs if you were an organization it would be all the transactions all the data that
you had available say from the stock markets you know orders coming in at reception or on your
website so it's quite easy to identify the the sensory states of of anything the question the
deeper question then is what kind of genetic model would be apt for explaining how these
sensations were generated once you've done that you can then use basic model selection indeed you
can even use evolution using evolutionary algorithms if you wanted to to optimize that genetic model
and then once you once you've done that you can start to simulate and understand the mechanics
and start to you know do scenario modeling and understand self-organization and things like
niche construction could be cultural niche construction the emergence of language for
example so niche construction is a nice example of what you can do if you associate a phenotype
with one kind of Markov blanket and ask how does action of that phenotype on the environment
unfold while referring back to the energy principle which says that there's a beautiful
symmetry here in the sense that the Markov blanket that separates me from the rest of the
environment is exactly the same Markov blanket that separates the environment from me so as much as
I'm learning and inferring about my world my world is learning and inferring about me at some
elemental level we you know there's another bright line there but in principle the environment
simply in virtue of the existence of a Markov blanket which means that I am not part of my
environment it means the environment must be learning about me and you can read that basically
as the environment being sensitive to its sensations that are my actions and that basically means
I'm designing my environment I'm creating changes in my environment so from my point of view the
environment becomes more predictable so that I'm minimizing my surprise from the environment's
point of view it's learning about how its denizens its inhabitants behave and so it's making the
environment's making it easier for its inhabitants to predict so we get things like traffic signs and
roads and language and elephant paths and desire paths and you know so all of this is it so emerges
from thinking about the exchange between different blanketed systems it gets even more interesting
when you start to think about another thing that is very similar on the same spatial scale as me
now I think you're getting into the game of self versus other and self-awareness I think you know
it is I if I was living in a universe where there was just me and the rest of my environment and
there was nothing like me and there was nothing living in that environment then all the causes of
changes must be caused by me I wouldn't eat a sense of self because you know it would it wouldn't
it would provide no extra expoundry power but if that universe included other things like me
who are also acting in your in the efforts of niche construction I'm now faced with an
infants problem did you cause that or did I cause that at this point I now need to have a mental
generative model or internal world model that says things can be caused either by me or things
like me namely others and I think at that point you now have a sense of self so here's one of these
other bright lines that rests upon the situated context in which I'm trying to create a good
model and make good inferences about my world and of course for you and me 99.9 percent of all
sensations are caused by things like us so we're always in the game of did you did you do that or
did I mean that or you know and ultimately you know one nice and common theme and when you start
to simulate these processes is that if the ultimate imperative of all of us is to minimize our
surprise and minimize our uncertainty and in the moment then that means that we should all
start to share the same generative model because that means that I can predict what you will do
because it's what I would do and you get this notion of a shared narrative or a common ground
that sort of tumbles up you know in various parts of psychology or ethology
mathematically what that looks like is generalized synchronization
that you get the same dynamics in two systems that are mutually and reciprocally trying to
exchange and infer each other so inevitably you get this convergence to the same kind of dynamics
simply because or that can be read as a shared generative model or a shared worldview with a
shared language and a shared you know a shared yes language I think is probably the best description
of it you know it doesn't have to be a spoken language but you know a shared commitment and
understanding of your actions that become my sensations and vice versa and then that leads
to interesting questions well why do we have arguments why do we have trump versus biden
why do we have wars so we can talk about that if you want to too right so at each level like
the only knobs that you have to the only dials that you have to move are either the evidence or
the model right I mean I know it's more complicated than that but but at each level what constitutes
the evidence and what constitutes the model shifts so differently and you need such different
language and conceptual tools to understand it and I think that makes it very tricky to think
about it from the scale of a brain to the scale of an economy to a society yes but in a sense you
know that that that that is exactly the the problem or the aspiration that you describe
there are I mean if you can if you can define the particular partition what are sensory states
what are active states what are control variables in engineering what is my system what are internal
states to my system what's external I think you've got a long way to actually making that
conceptualization less tricky for anybody but I'm not saying that's easy I mean that's you know
that's that's the first hard part in in in the feel like hypothesizing a particular
model is it's basically working out what are the boundaries of the thing that I'm trying to model
to understand or to explain but I think the solution or the key to making it a useful
untricky business is identifying that partition that that that thing distinguishes the system
of interest from everything else and there's quite a lot of work in maths at the moment
and looking at sort of automated ways of trying to partition the world into lots of little
Markov blankets to understand at a particular scale and then to understand try to understand
and try to model you know what would happen if I if I then applied the free energy principle to
charity models there was another profound truth though in your question you were saying you know
the thing that the only thing that I need to describe how something will change
is this functional i.e. a function of a function of two things the data the sensory states
and the model and that's so true you know so you can either change the sensory states through
action or you can change the model by changing your mind and again we come back to this you know
this this sort of nice way of viewing a distinction between action and perception so there you know
at a very simple level whether I'm a cell or a brain or an institution
or you know I think that that that's very simple duality pervades in terms of this sort of
generalization of action and perception I can you know to make things less surprising I can
either say oh actually that's not surprising that's exactly what I would have predicted by changing
my mind about the way the world works or I can move to ignore that and sample something else
which is more predictable so I can choose which news channel to watch so you know if I'm watching
a news channel everything I find really surprising and so ego is historic I can I've got two ways of
responding I can say oh perhaps I was wrong perhaps my ideology needs to be nuanced in this
direction so that I'm not surprised by people saying this or people telling me that or I'm
going to watch the other channel because that's more more for people like me both of them are
perfectly viable solutions to minimizing your surprise on and in a sense that's that's what
we do all the time you know we're constantly changing our mind and then changing the evidence
upon which we make those inferences that enables us to change our mind okay so how would you just
for fun how would you do that for politics what does that language for a political system a political
markup blanket look like right so I'm not going to give you a very deep answer there
I suspect you probably could could have a more poetic answer than I could but it is interesting
that people are starting to try and simulate this kind of thing by simulating lots of little
artificial active inference agents all doing their predictive processing together in a minimal context
so I'm thinking here of friends of mine who simulated the emergence and prevalence of different
ideas by simulating tweets basically so what they've done in fact two groups of friends of mine
have been doing this they've asked well if everybody is in the game every art about every
particle every person every tweeter is in the game of trying to minimize their surprise and
they are broadcasting their messages and their means and what will happen if you put a thousand
or ten thousand or a hundred thousand of these agents together and what tends to happen is something
very interesting you basically get a partition into into two groups and it's usually 50 50
and then you ask yourself oh that's interesting and I can't remember but somebody told me that
there's a law which says that you know in voting dynamics or indeed in terms of population dynamics
isn't this is this is unsurprising there's a mathematical basis right but certainly using
numerical experiments this is an emergent property of of these kinds of simulations where
lots of sort of sentient little active inference particles are in exchange with each other
one argument is that of course it couldn't be any other way this is the only evolution
is stable state in the sense if one small group existed it would quickly get absorbed into the
other group by this process of shared narratives and generalized synchrony so the only stable
solution is to have a 50 50 split but then you ask well why don't they just merge and the answer to
that is still I think outstanding or perhaps somebody's got an answer but I I think it
the answer lies in the initial conditions and the heterogeneity that you know people
people bring to the table when they start their their exchanges but also something more subtle
on top of that which is something that comes when you start to think about agents that plan
now previously we were talking about sort of homeostats and
thermostats and reflexes and the like and all of these things are beautiful instantiations of
very simple basing mechanics and the very trivial generative models you're basically I believe
this room temperature should be 16.8 degrees and if in parts of that I'm surprised and I'm
going to act in a way to reduce my surprise and bring the temperature simply by turning on the
heater so very simple little circuits that can be interpreted through the lens of this basing
mechanics you know I'm not saying that this is how the thermostat is working but you know you can
describe its dynamics and its behavior using this kind of basing mechanics and you can simulate it
in silica if you wish to but notice that's got active states you could actually say that in some
sense it was living it certainly is a product of a living you know somebody built the thermostat
in the absence of life there wouldn't be any thermostats of that sort but it's not it's not
got the kind of biological aspect that you might you might aspire to when thinking about biological
agents there's no purposeness there there's no and there's no ability to plan and it's really
simple that ability to plan I think is really important and what does that mean from the
point of view of the nature of the generative model well it simply means that to plan is to have
a prediction of the consequence of action in the future and simply saying in the future immediately
says you've got the kind of generative model that is freed from the moment so this is like
Jerry Edelman's member present so you've got a generative model now that acquires a temporal
depth it has a horizon in the future which is quite remarkable thermostat doesn't have that a virus
won't have that you could even I would small insects don't have that but things that plan things
that choose to do this or that must at some level at least can be described as if they had a generative
model that acquires a temporal depth and I think in that sense as soon as you're choosing between
one plan and another plan you are truly an agent and you have a you know some a biological autonomy
which many things don't have and that that brings with it an interesting question which
brings us back to this notion of how do you choose the best plans if the imperative is to
minimize surprise well the best plan would be that which minimizes the surprise expected
if you pursue that plan and again we come back what does that mean it means I'm going to resolve
uncertainty which simply means that anything that can plan that exists must look at some level
as if it is curious it will want to go and technically maximize its expected information
game which is the important part of this expected free energy or expected surprise all
so what you're saying now is that there may be another bright line between things that move
that are not curious and things that move that are curious and I would say that to be a true agent
you have to have that curiosity you have to move in a way that resolves uncertainty about the
state of affairs out there on the basis of your actively sample sensations now if we bring that
back to the 5050 biden trump split or brexit versus no brexit or whatever you know it's right
down the middle and then what that means is that there is now an opportunity to be curious
so having somebody with a different mindset is rather interesting because it'd be interesting
to know what they thought if you ask them and of course you know when you formulate tweeting
and communication it's all about questions and answers very much like quantum information theory
it's just sort of you know posing questions to the universe and the universe supplying its answers
in the form of sensory input and of course that sensory input is now provided by the other group
from your point of view but it's still very attractive to do that because of course if you
can plan you can maximize your expected information gain minimize your uncertainty by listening to the
armed group so in our in agents or particles that can plan then this separation into big groups of
roughly equal size and makes perfect sense simply because it provides a form that looks as if
they are engaging in this epistemic behavior and in many in many of our writings we we talk about
that as an epistemic affordance so coming back to your clever and careful use of the word affordance
if I now read affordance basically as the current state my current sensations leading to a belief
about the current state in the world that then underwrites the evaluation of a series of plans
that I'm going to score in terms of my expected free energy then those that have the greatest
expected free energy will have the greatest affordance so those those cues that I have
that intimate that if I did that if I sat on that chair this is the kind of thing I do then the
plan to sit on that chair has the greatest affordance simply because that's the that I will resolve
the most uncertainty by committing to that plan because that's the kind of thing I do and this is
a particular kind of surprise which sometimes we call prior preferences or you know preferred
states of being so one way to minimize the expected surprise is to avoid surprising things
so you avoid uncertainty you avoid unfamiliar unfamiliar you avoid for example being having
temperatures that are too high or too low if you're sort of home your firm so you will avoid
being very cold either by shivering or by the erection or going inside and putting the radiators
on so all of these behaviors are just realizations of plans that are avoiding surprising states of
being where the surprise shapes your preferences so to be good to be a preferred state of being
is just to be in a familiar characteristic set of states that characterize you rich happy loved
warm well-fed and anything that takes you away from that is surprising so you plan to avoid that
so that's known in my world as the the the pragmatic affordance and that basically is another
part of the expected free energy which can be written down as an expected cost which is a
violation of preferences you know the expected surprise basically and you put the expected
cost together with the expected information gain and now you've got this same sort of construct
which gives you the expected free energy which is very very similar in mathematical form to the
free energy being your your energy minus your entropy you have to rearrange the terms a little
bit and take an expectation operator apply not an expectation operator but you know functionally
speaking there's a beautiful formal relationship between these two aspects of good plans that
inherits from the way of decomposing your surprise or your free energy bound into an
energy and an entropy sometimes you rearrange that into a sort of accuracy complexity and these
this this sort of decomposition survives in terms of a dual aspect imperative for plans which is
based summarized I think in terms of dual Bayesian optimality in the sense of maximizing
expected information gain which would be the the principle of optimal Bayesian design which is if
you have to design an experiment then there's a particular kind of data you will get which
resolves the most uncertainty so people literally use this in designing the good experiments as
scientists we use it all the time when we're deciding where to look next we look where we
think we're going to get the most information gain the most salience the most resolve the most
uncertainty about what causes flutter in the periphery of my vision but there's another part
to it which is this expected cost or negative expected value or expected utility which is
defined by our prior preferences so we call that pragmatic affordance to complement the
epistemic affordance so sitting in a chair I think would be more the pragmatic affordance
things like me like to sit in chairs you know I'm the kind of thing that sits in chair so if I see
a chair then from the point of view of the free energy principle this active inference application
of the energy principle what that basically means is a realization of the the pragmatic
affordance simply that I would find it less surprising to be sitting in a comfortable chair
than I would standing on my head beside the chair you know I find that more surprising given I am
the age 60 plus so you know I love the word affordance and you know distract knowledge with
slightly nuanced the pure Gibsonian notion of it but you know it survives as a really important
notion that underwrites I think all of our planning so bringing that back to the Biden
Trump thing having another group of people that is not like-minded affords epistemic
affordance for particular tweets or questions of course it exists for most of your time talking to
your family and friends in your in group but from time to time you're going to indulge a little bit
of curiosity and responding to those epistemic affordances of just listening to you know I was
going to say Fox News where I think that would be unfair or your news channel or your I don't know
I don't know what the the opposite would be in America ABC I don't know anyway you know looking
at two politically polarized takes on on the news cycle and your your commit most the time to
watching this one time to time you'll go out there and look at the other one and then I haven't thought
about this but you could get into all sorts of arguments about sort of fake news and the ability
of big tech to actually supply you with the kind of news that they think you will expect and whether
that you know is based optimal in and of itself just anecdotally that makes so much sense I mean
that there must be why all media platform or social media platforms especially are
are geared towards divisiveness like every time let's say for example when the when the right
price to build a platform that's insulated for itself it doesn't work for them because there's
no one to to have conflict with there is there is no there's no two things to interact it's just a
homogeneous group yeah I think that's absolutely right and and also right in a personal sense you
know if there was no uncertainty to resolve there's there's no opportunity to indulge in curious
behavior and my whole life as a scientist is just an expression of responding to
ecostemic affordances to test hypotheses because I am curious about that in the absence of any
uncertainty that would be I think a very very boring life and of course we aspire to that and
we call it things like novelty seeking you know it's why we are bungee jumping you know
a really younger great discourse to see who you might be a partner with that that evening you know
so all of these all of these you know I think sort of very fundamental and very true observations
about the nature of self-organized incentive behavior are fundamentally true in the sense
that they are statements that to be and to plan is to is just to be curious and of course you
can't be curious if there's no debate if nobody if everybody's always right or everybody's always
wrong there's nothing to be curious about on the other end of that how far do you think agency can
go from a planning perspective so I asked us because people people insist on sort of meta
meta planning perspectives where does the ability that we can plan afford at least the
the principal possibility that you can step out of the process that you're embedded in
kind of rise above it sorry I know it's a bit of a poetic question well no no I think it's exactly
where this conversation should go next and you know I'm just putting it framing it in
this narrative of where does one draw the bright lines between different kinds of things I like
calling them natural kinds but I've been told off by philosophers that's a bit too so I call
particular kinds and I think that's standing standard that metacognitive aspect that you're
speaking to that standing back and looking at yourself sense making and planning I think this
is the this is the characteristic of these now much deeper generative models that have very deep or
high hierarchical structures that can actually see what's going on below and as soon as you do that
I think you now have the opportunity to be aware of things and you could possibly even
argue self-aware so I think that that's the bright line the very thing that you brought to the table
by that question is structurally the bright line that distinguishes systems that have either a
minimal self-awareness or a minimal selfhood anyway and if they are aware of that or they can model
or infer that minimal selfhood then possibly full-blown self-awareness so I think that's a really
important aspect I would see it just in terms of the hierarchical depth of a generative model
and in a slightly deflationary way I would see this very much through the eyes of people like
you know James Lang theory of emotions or possibly Tony de Marzio's formulation of your
you know valence states of being and emotional states of being in this in the following very
simple sense that if I've got the capacity in or the structure of a generative model that includes
a hypothesis or a belief or a representation that I am something and that I can be in different
states that then enables me to contextualize or condition all my belief updating and my selection
of plans in a much more fine grained and functional way than if I didn't have that capacity to recognize
I am in this state so very simply for example if I am faced with a myriad of sensations from my body
interceptive sensations of a racing heart hyperventilation extra visually it's very dark
I'm you know I can't see what's you know what's around the corner I can't see what's in front of me
all of these this sort of profile this particular pattern of sensory evidence sensory impressions
and is evidence that I'm frightened now if I'm frightened I can now say I am the sort of creature
that is frightened and when I am frightened I expect my body to do these kinds of things
so flight and flight responses which means that I will now send down predictions that my heart
should beat faster and I should breathe I should breathe more quickly if I'm just about to run away
or converse if I just want to attend or freeze if I don't want to be noticed so but the point being
that you are now self-constructing the very signals through your body that are providing
evidence that you're in fear and you can get into a little vicious cycle which usually is quite
quite quite functional if you are actually alone in the dark alley you know you're frightened is
important that you maintain a degree of fear until you secure evidence that you don't need to be
frightened anymore apart from that evidence on my heart slowing down now oh it's just a panic
attack or it's hyperventilation so all of that very simple story which would justify the existence
of certain creatures with gerative models that have this very sophisticated very deep
representations of self in a different in different values or emotional states
I think is exactly the kind of kind of genetic model that you would require to at least have a
minimal selfhood and then you can imagine being on top of that seeing that oh yes it looks as if
I'm inferring that I am frightened therefore I must be frightened and I can tell myself I'm frightened
and then I can tell you I'm frightened and then you have self-awareness then of course there's this
question of how far does that go like is there an upper bound on how metacognitive you can become
yeah you know I think that's a secret of philosophy and philosophy of consciousness so
as a younger man I used to think that clearly there is and there's actually a mathematical
bound as well as a sort of common sense physical bound in the certain size of your brain you know
the best model the world of course is or map of the world is the world itself you know the best
map is the territory and of course you can't physically realise this which is another argument
against the moralical the radical in activism but mathematically there is also you know a stronger
more mathematically motivated bound and that's the inherits from an alternative
carving up or decomposition of the log evidence and not into in this instance
energy and entropy but just by switching a couple of terms around it now emerges in a functional
form that a statistician would recognise as accuracy and complexity so what that means is
as you're doing yourself evidencing it looks as if or implicitly you are generating very
accurate predictions of your world as simply as possible because you're minimising the complexity
bit like Occam's razor so just by being self-evident and if you recall from the point of view that
the entropy is just being means you have to self-evidence or at least it looks as if you are
self-evident that means you're trying to find the simplest explanation for all of your sensations
which means that you can be too hierarchically deep you can have if you're in machine learning
this would be a little bit like having an overly expressive over parameterised
deep network of convolutional network of variation autoencoder and that over parameterisation
needs to have a fitting which leads to affinity generalize and these are all symptoms of not
minimising the complexity and just focusing on the accuracy of the maximum likelihood part of
the equation as opposed to the maximum marginal likelihood which is the model evidence of the
self-eminising part so when you say is there any upper bound on the level of metanus in terms of
self-modelling yes I think there is at some point you will start to incur a complexity cost because
there are too many degrees of freedom that your your generative model that's meant to provide
the best explanations for all your sensations will hit and after which you will become more complex
and your pathogenical of your free energy or your surprise will start to fall and literally you
will have smaller adaptive fitness you just won't work in this world you won't you'll overfit
everything you'll overthink and I have friends in Portugal have written about this and you're
some psychopathologists can actually be a reflection of overthinking over mentalising
and having too many hierarchical levels and I think the best expression with Tam in cheek
of this pathology is a philosopher particularly a philosopher of consciousness so they spend their
time worrying about experience and quality of experience and nature of consciousness
so they they're really overfitting their world and having a lovely time indulging in their
epistemic affordances but there will probably be never no answer so I've always thought that
you know that this argument was not only explains consciousness but also explains the existence
of philosophers and or why or why there are so few of them or good ones anyway so so from that
point of view I think there is a really fundamental upper bound I should say that that view in my eyes
has been vindicated by recent moves in in philosophy this is not my field so this is just hearsay from
my friends in philosophy so people like David Chalmers and Andy Clark have been in exchange
on what has now become the new focus which is the next hierarchical level up which is the
meta problem so this is not the hard problem this is the meta problem why do we find the hard
problem so puzzling so this is so this is this is wonderfully metacognitive and that's now the
new question and I think I think that this this this story that I just told you and I think has
something to say about the meta problem you know as Andy Clark summarizes it you know why is it
that we are so puzzled by the by our qualitative experiences you know why do we spend our entire
lives with existential angst you know eluding any ontological security just by being being
philosophical about our own existence and it you know clear from the point of view of our
conversation that you know this is just an expression of responding to epistemic affordances
and in that you know a highly encultured context you know cultural niche construction which is
philosophy and communication and but from the point of view of you know the meta problem or the
meta hard problem being answerable I think I think that there is a beautiful answer that is
engendered or insight this is engendered just by asking that question by asking the meta the
meta hard question or the meta question and that's the very fact that we are aware of our
qualitative experiences is itself very revealing and it speaks exactly to this high level that we
were just talking about which is a system making influences having hypotheses about its sense-making
the consequences that in terms of overt and covert action the plans you commit to either by
cardiac acceleration or covert action by attending to this or attending to that
source of evidence so that tells you that you know there are only certain creatures or systems
that will ever be exposed or even ask the kind of questions that form the meta problem or the
meta hard problem and it's only those kinds of questions sorry it's only those kinds of systems
that have this capacity to actually realize that they are something and that they are something
that is doing inference or belief updating in different contexts so just knowing that I think
provides you know a nice solution to the meta problem at least if not the hard problem in
and of itself so I find this fascinating I repeat it's not my area of expertise you have to get
David Chalmers on to see what he thinks about it in the moment. Why do you think that is is it
just a matter of historical contingency that there are these creatures that happen to have
the right machinery the right substrate that that got them that got them to that scale?
Yeah again that's a great question I think there's a principle out of that question in
effect I've already given it remember that the only imperative for your gerative model is that
which maximizes the likelihood the marginal likelihood of all your sensations so now you ask
yourself why on earth would I have a gerative model that included a sense of self and indeed
a sense of sense of self or self-awareness why and I think the answer is very simple it's just that
we have to generate predictions of a universe in which there are other creatures who are doing
the same thing so as soon as you have a sense of self and other then I have to have one to
understand what you're doing to make sense of you all the sensations that you generate
and of course as soon as you start talking I'm now going to have to have you know a self-awareness
in order to do the turn taking that's necessary for us to actually communicate so I think it's
just a reflection of something we're talking about before that self-evidencing active inference
predictive processing of this inactive and situated sort has always to be seen in context
and if the context is I'm doing this in a universe that's populated by things like me
then there's going to be a natural tendency for increasing sophistication
depth of sophistication to disambiguate who's talking and to be able to talk in the first place
so what that says is that we wouldn't have these conversations and we wouldn't have these
hierarchically deeply and delicately crafted gerative models crafted by this evolutionary level
model selection in the absence of our conspecifics and our brothers and sisters who just wouldn't
be there so you're only going to find this level of or this depth of self-organization
and sentient behavior in populations basically so that you know I think that is a simple consequence
and a simple answer to your question why me why why we have these privileged really high level
things that may be only shared with things like dolphins I don't know and you know I think it's
just a reflection that we co-evolved and you know and the nature of that co-evolution
that itself is a free energy minimizing process means that there are lots of examples of me and
that we're all we're all coupled throughout through our action perception cycles what do
you think of extended cognition the idea that if cognition can be extended out with artifacts in
the world and that somehow increases the the possibility space or the depth that can be imagined
here well I like that notion very much but that's because I like Andy Clark's so you know and it's
so the notion of extended cognition I think is
which I'm taking here the kind of take on the ability for me to store all my phone numbers
on my smartphone is a way of basically extending my cognitive ability the other example I love
here is the ability to of very young Chinese children who have been trained on an abacus since
age of two and so they can so fluent and manually dexterous in a radically inactive sense that they
can do computations so fluently by externalizing acting in their world physically acting on their
world through their active states they can then internalize it and become wonderful arithmeticians
without the actual physical so they just rehearse so I think the extension sort of goes in two
directions that yes you can when you put action into the loop you suddenly now have a kind of
extension of self-organization that now has to accommodate the exchange of you with the body
and extra personal space and all the artifacts that we have and that we can build such as iPhones and
and or the electronic devices that augment our cognitive capacities but also you know competing
the circle a lot of that can be sort of you know absorbed back into the brain if we just imagine
you know a good musician for example I can I can I can I don't know because I can't do music but
I imagine a lot of the creativity is really a reflection of rehearsing and is either articulated
in song or physically articulated in terms of playing an instrument what would happen if I did
that in my head and then being able to create is by imagining creative creative acts so in a sense
this is extended but it's extended but you know it's come back inside into our simulation machine
where it is part of this generative model that is necessary for planning right yeah I mean there
are these examples of I'm sure you're aware of of machines that are just using cybernetic principles
and they don't have any any like they don't have a motor to them or they don't have a circuit to
them or anything like that and they seem self-organizing they seem and then one imagine is how far
that could be taken could you have a cognitive system on a totally different substrate that
that we don't even know of yeah I'm sure we can I think was as you point out we were seeing this
kind of thing emerge in silico in machine learning of the of a particular kind that commits to so
I have a friend Matt Brown who loves and spent years trying to stand up you know the original
documents and the derivations of Ross Ashby and spent years implementing this in you know
in silico and has lots of amazing results and you also see it you know I have another friend
Chantani in Japan who has so he comes in the field of neuro robotics and he could actually
argue developmental neuro robotics but you know simply by having a bank of having a
dynamical system encoded in a computer that plays a role of a very deep generative model
and then just exposing simulated or robot child to various things he can engender really
interesting behaviors actually choosing to you know throwing both pushing balls between
or choosing one ball versus another ball very very impressive sort of emerging behavior
just by having a self-organizing predictive predictive processing machine under the hood
that can actually move you also see it interestingly emerging now and in several guises
in the the ultimate in biomimetic computing which by which I mean in cell cultures so now
you're starting to see behaviors that are entirely compliant with this kind of
self-evidencing emerge spontaneously in cell cultures in vitro literally in glass on on a
glass dish and I would imagine next year in little organoids and in brain oids that have
been scuffled in the right way so these behaviors are now being recorded and observed and characterized
in terms of self-evidencing or predictive processing or active inference formally
and they're now appearing in the literature so I see that that is a very nice example of
what you just described that you know just just get the right kind of system that seems to self
organize in a way that it endures in a particular state for long enough and it will show some kind
of intelligent behavior I think absolutely okay final question so you seem to be really good at
managing both really complicated conceptual work and also applying it and being attention to the
empirical development are that do you have any any general principles or ideas to share about
how to manage that how to manage conceptual and empirical work that's a good question which I don't
have a preformed answer to um I've been in a sense the the application or the job or the process of
scientific inquiry and you know the way that I would describe my life and I would suspect to
associate your life as well in terms of your quintessentially curious and you know you're a
kind of scientist soliciting the right kind of evidence to resolve uncertainty about this belief
on this hypothesis versus that I think for both of us the whole process of scientific inquiry
that rests upon having the right kinds of ideas and hypotheses and then securing evidence for those
by committing to an empirical experiment just as a statement of this action perception cycle
we've been talking about so I don't really see it can be any other way you can certainly get
different kinds of scientists who just like you know the discovery part of it and don't have very
deep hypotheses or you can get pure theoreticians who rely upon their friends to do all the hard
active part and do the experiments but collectively you know you know very much like the the data and
the model dialect that you were talking about before I think that these are two sides of the
same coin and they both have to go into this fundamental imperative which is this surprise
or sort of free energy bound on the surprise in order to to self-organize and to self-evidence
so I don't have any advice other than other than practically make sure that you give yourself the
opportunity to indulge in curious behavior and that curiosity may be entirely covert
they may be just thinking a lot in the morning I normally do that with my pipe at least for two
hours but also it has to be an overt as well you actually have to go out there and get evidence
from this hypothesis and that hypothesis even if it's to sort of type your numerical analyses to
test whether this your internal conception of this dynamic on this functional form
mathematically was correct but making that opportunity if you're a young scientist
really depends upon the right career choices so keep your options open and just create space to be curious
