Вторая часть будет посвящена той статье, которую Антонович
присылал нам про Радофамин.
Но в процессе рассмотрения оказалось, что это далеко
не единственная статья, а Радофамин.
Более того, не лучшая.
Потому что, к сожалению, Радофамин, такие статьи у него
несколько, и, по крайней мере, еще одна, на которой
он ссылается в конце этой, не в начале, а в конце.
И там используется несколько иной математический аппарат.
И ситуация рассматривается более детально.
Какие-то вещи, какие-то вопросы, которые появлялись
в этой статье, я старался найти в той, но ту я целиком
не прочитал вторую.
Я пытался найти ответы, если вопрос, который появлялся
у меня здесь.
Но в том числе есть некоторые вещи здесь, например, пример,
который он не то, чтобы прямо очень объясняет, и при
этом именно, например, не ссылается никуда больше.
На свои другие работы он не ссылается.
Поэтому пример уж как будет.
Да, а все остальное давайте попробуем разобраться.
Вы скажете, что статьи, которыми мы видели, пора,
которые, серьезно говоря, они довольно сильно и
пересекаются.
Вот до повторения картинок.
Нет, нет, я говорю про дубую статью.
Их было три.
Не то, которое мы говорили.
Их было три.
Одну прислал Митяна Антонович, вторую статью я нашел, она
была расширением этой, она была чуть большее.
Я проверился там все точно тоже, и еще плюс что-то.
Я подумал, лучше ее прочитать.
И я читал вот эту, и ее и буду рассказывать, вот та,
которая вторая.
Но есть еще третья статья, вот в конце второй была ссылка
на третью про Дафамин, и там она была еще детальней,
еще больше, но там была совсем другая математика.
И кстати, в Фристон, в том смысле, что Фристон, он
к математике из-за того, что он пишет в общих каких-то
вещах, конкретные детали могут быть разными с точки
зрения математики.
И он поэтому и говорит, что есть какое-то отображение.
А как реализовывать это отображение?
Оно может быть в разных статьях реализовано, здесь
это дифференциальное уравнение, а здесь тут нет никакого
дифференциального уравнения, есть какие-то вероятностные
отображения.
То есть для него вот этот математический аппарат
не ключевой, он может быть разным.
Да, конечно.
То есть у него есть эта схема, в которую как блоки
он может вставлять разную математию.
Вот.
И вот в третьей статье был другой математический аппарат,
а в этой он эдакий.
Но в общем, рассказывайте я буду про эту.
На самом деле у меня не очень много слейдов, но
посмотрим, какова будет скорость движения.
Вначале я хотел бы рассказать про скрытые марковские
процессы, потому что они лежат в основе метода
вот в этой статье.
И просто из общих, в том, что мы потом, когда перейдем
к статье, мы покажем, что вот отсюда мы сразу
перескочили сюда.
А как перескочили?
Вот через использование скрытых марковских процессов
без деталей, просто понять, что было на входе и какая
задача решалась.
Вот.
А потом, вот, кратко о схеме работы модели, это в общем
частичное пересечение с тем, о чем говорила Людмила
Юрьевна, модель схемы у нее такая же, и затем уже
попытка фристаном привязать какие-то отдельные структурные
части моделей к мозгу.
То есть сказать, что вот это, это, наверное, вот этого
обусть.
Да?
Вот за это отвечает вот этого обусть.
Причем нужно сразу сказать, что он оговаривается, он
говорит, что это все несерьезно, не надо прям вот буквально
понимать, что я сказал, что именно это здесь происходит.
Он говорит, что это вроде как похоже, по функционалу
похоже.
Вот.
И в конце будет вот этот пример, о котором я уже сказал.
Ну, посмотрим.
Скрытые марковские процессы, это такая ситуация.
Это картинка не с фристаном, но тем не менее представим,
что у вас есть друг, с которым вы разговариваете по
скайпу, как мы знаем сейчас, каждый день.
Вы сидите дома, и у вас дома нет окон.
Вы не знаете, что происходит на улице, какая там погода.
Там может быть дождливо, а может быть солнечно.
Вы своего друга никогда не спрашиваете о погоде,
ну или он не может вам об этом сказать.
Но вы его спрашиваете, о чем ты сегодня занимался.
И вдруг может гулять на улице, ходить по магазинам
и сидеть дома убираться, строить такой день, когда
он дома наводит порядок.
И при этом каждый день вы его спрашиваете, и он вам
говорит, что он делает, то есть он либо гулял, либо
ходил по магазинам, либо сидел дома.
И при этом каждый, ну вот это вот то, что делает
друг, естественно, связано с тем, какая погода на самом
деле.
Получается, что если, например, дождливо, то он с большей
вероятностью пойдет гулять, ой, наоборот, да, большая
вероятность останется дома, погода плохая, да, он останется
дома.
Ну что-то я говорю, друзья.
Да, кто тоже дождь, особенно летом.
Вот, если солнечно, то он скорее всего пойдет гулять.
Ну и так и так далее, то есть каждая из реализации погоды
имеет некоторую от нее вероятность того, что будет
делать ваш друг.
При этом день идет за днем.
И есть некоторая процесс вероятностный, перехода
между состояниями, то есть между погодой.
То есть если, например, сегодня было дождливо, то с большой
вероятностью и завтра будет дождливо.
С не очень большой будет завтра солнечно.
Если сегодня солнечно, то чуть с меньшей вероятностью
и завтра будет солнечно.
Но с некоторой другой вероятностью будет дождливо
в следующий день.
И так день за днем этот процессходит между этими
двумя вершинами.
Дождливо, солнечно, дождливо, солнечно, и он каждый раз, и грубо говоря, подкидывает монетку в соответствии с этим распределением.
И это примерно реализуется на следующий день, на следующий день, а вы слушаете только друга.
Вы слышите, у вас есть другая последовательность, вы видите, что делает друг при этом.
При этом, да, вы конечно, есть некоторая стартовая вершина, то есть первый день, когда все началось,
и вы знаете, что в первый день с вероятностью 0,6 было дождливо, с вероятностью 0,4 было солнечно,
а дальше уже вероятности, да, в соответствии с этой схемой.
И задача получается такая, что у нас есть некоторая переменная скрытая, вот ровно про то,
про что говорила Людмила Юрьевна, скрытые переменные, которые, они меняются, что-то с ними происходит,
но мы их не видим, мы не знаем, какие они, мы видим какие-то другие переменные, которые зависят от скрытых.
И вот эти задачи, связанные с скрытыми маркерскими процессами, они как раз тут добавляются еще какие-то дополнительные условия.
В общем, это целая теория, которая занимается тем, чтобы определять вероятности значений х, в каждом момент времени,
не зная вероятности у, то есть именно это происходит по скрытым переменным, у нас есть наблюдаемые,
у это наблюдаемые переменные, по наблюдаемым переменным мы восстанавливаем скрытые переменные.
И мы будем считать, что эта задачка, вот она мы знаем, как ее решать, она решается,
и в нашем модели ровно это и будет происходить, то есть у нас будут наблюдаемые переменные,
а мы по ним будем строить те скрытые, которые как бы должны быть на самом деле.
Но здесь предполагается, что связь между у и х уже заранее известна,
или мы ее по каким-то образом устанавливаем в процессе сами?
Значит, связь между у и х, ну вот в данной ситуации получается, что связь, она действительно известна,
но она видите тоже вероятность, она не...
На самом деле, если это все действительно попробовать выписать на бумажки и решить,
это весьма нетривиально, чтобы понять, что было в тот или ноль день по этим вероятностям.
Это, как правило, предполагается...
Кстати, тоже вот эти вероятности, это в нетом смысле модели мира.
Например, мы знаем про другое, что вот в дождь он будет гулять с точно небольшой вероятностью.
А это частостные вероятности, обычные.
Бойзовские.
Ну, значит, смотрите, исходные вероятности нам были даны вот здесь,
вот которые здесь были они. Но вообще, все вероятности в том-то смысле частотны,
если мы начинаем говорить, откуда они взялись...
Да, понятно, классические.
А не байзовские.
Классические, не байзовские.
А, не классические, да.
Я просто здесь не очень понимаю, вот в этой модели, если мы говорим про солнечный день и про дождливый день и про выбор друга,
друг ведь в каком-то смысле не решает, он тоже подбрасывает монетку.
То есть у нас есть некоторая, резолвалась какая-то случайная личина, у нас сегодня дождлива и он подбрасывает монетку
и у него вот этот вот закон распределения, что если дождлива, то с вероятностью 0,5 он будет сидеть дома, с вероятностью 0,4 он пойдет по магазинам
и с вероятностью 0,1 он пойдет гулять, он таким может пойти гулять, если у него выпадет вот эта с вероятностью,
каждый десятый раз грубо говоря, он будет ходить гулять, он в соответствии с этим распределением реализует свое поведение,
то есть в этом смысле, как можно сказать, что оно субъективное, он подчиняется этому закону распределения,
я не очень понимаю, на самом деле, разделение субъективного и объективного, и вероятности.
Частотные вероятности.
Частотные вероятности.
Частотные вероятности.
Частотные вероятности.
Частотные вероятности.
Частотные вероятности.
Частотные вероятности.
Частотные вероятности.
Частотные вероятности.
Частотные вероятности.
Частотные вероятности.
Частотные вероятности.
Значит, про схему модели, она в общем целых чертах примерно такая же,
но нужно сказать, что, во-первых, в разных статьях немножко различаются обозначения,
не всегда одно и тоже обозначаются одними буквами,
но, тем не менее, вроде бы, сильно много нового не появляется,
то есть есть условный мир, условный агент, справа, слева мир, справа агент.
А вот так.
Да, вот они-то подписаны.
Значит, в мире реализуется какое-то состояние.
И агент знает об этом состоянии через наблюдение, обозервающие.
То есть с рецепторов, грубо говоря, что-то получает про это состояние.
Значит, вот эти, у агента есть предположения о том,
какие на самом деле состояния у мира.
То есть они не обязательно те, которые там имеют место быть,
но это его, он восстанавливает какое-то может быть состояние.
Вот он видит такие наблюдения, для него это скрытое переменное,
он восстанавливает какое-то может быть состояние.
И у него есть переменное, опять, скрытое переменное,
значит, которое определяется, то есть при этом он восстанавливает состояние,
он еще все время, как вот Людмил Юрьевна рассказывала про «Varational bias»,
то есть когда у нас есть какой-то ряд значений,
мы наблюдаем ряд значений, например, просто ряд чисел,
и нам нужно достать оттуда, так он ее называет,
достаточная статистика, то есть некоторые числа или какие-то величины,
которые было бы достаточно, чтобы этот ряд значений описать.
Или какой-то инфраунционный горбочек получается, да?
Да, в том-то смысле, вот например, так вот и примером может быть,
когда вам дают числа, вы знаете, что они по нормальному закону распределения все,
числа идут первая, вторая, третья, четвертая, вы их копите, вы их видите,
но при этом вы знаете, что по нормальному закону,
неизвестным от ожиданий, неизвестной дисперсии,
вот характеристики этих чисел случайно,
при этом вы знаете, что среднее, грубо, вокруг какого-то они колеблятся,
мало того, что это среднее может немножко меняться в течение времени,
вот пока вы числа их вам идут, да и еще дисперсия может меняться,
и вам хотелось бы понять, как примерно распределена вот эти другие статистики,
то есть уже не про эти числа, а что-то про из них извлечь какие-то другие,
которые бы могли описать их, и при необходимости,
вы могли бы эти числа как бы воспроизвести с помощью этих статистик,
вот в случае с вариационным рядом это может быть два числа,
матожидание дисперсии, если вы знаете закон распределения,
но вам их надо понять, и более того, они в течение времени могли немного меняться,
то есть это будут тоже случайные числа, вот эти вот случайные статистики,
которые вы извлекаете из данных, это в каком-то смысле,
насколько я понимаю, в том числе скрытые переменные,
которые у вас находятся внутри, в чем они реализованы биологически,
тут я ничего не могу сказать, то есть про это я не встретил пояснений,
вообще надо сказать, что пояснений, вот интерпретации каких-то отдельных вещей
биологические, крайне вкупы, и они еще бывают, что вот он в этой статье,
вот это рассказал, ну вот это, например, вот это,
кстати, я про другое что-то сказал, в итоге непонятно,
их можно все вместе соотнестись, что вот, например, в одной статей,
когда Юрина рассказывала, что, значит, например, О, то есть Observation,
это может быть показания с рецепторов, если мы говорим про клетку,
то, например, Action, в одном месте он так очень скользко, как ты сказал,
например, это движение жгутиков у одноклеточного, например,
и все, что такое Action, больше ни в одной статей не встретилось,
что может быть Action, какой-то Action, интерпретировать,
что такое может быть Action, ну, в общем, не просто,
на жгутиках и остаемся, вот, но важно то, что вот эти внутренние переменные,
У, он их называет Control States еще, они, как он тоже пишет,
они, после того, как про них что-то узнает агент,
то есть он их, как бы, восстанавливает, вычисляет в каждый момент времени,
они непосредственно реализуют этот Action, он говорит, что это чуть ли не Reflex.
Я же не понял, да, это некоторое принятие решения, да, как что, действие.
Тут, как бы, вот эту стрелку трудно себе интерпретировать,
то есть, я не могу сказать, например, что он делает,
как-то реализуется Action при этом, но вот все завязано
с переменных внутренних, как Control States, то есть, они здесь в модели ключевые,
вот эти переменные. Так, да, значит, вот это первый слайд,
где появляется много формул, но на самом деле, это уже,
дел в том, что он описывает вот все те отображения,
которые были на картинке Людмилы Юрьевны, ну, и вот здесь они просто
не обозначены в виде отображений, взаимосвязи переменных,
в этой статье он описывает бездифференциальных уравнений,
а с помощью вероятностных распределений, то есть,
вероятность того, того, того, при условии того, того, того.
Вот, затем вот она, вот одно из уравнений вверху,
но оно достаточно такое громоздкое от многих переменных,
причем в том числе отфективных переменных зависит,
это, может быть, не так важно. Вот, но после этого он,
допустив еще некоторые предположения,
он находит, видимо, с использованием variational bias,
то есть, это не раскрывается, как именно делать,
просто упоминается, дается ссылка на монографию,
где есть много алгоритмов, да, это диссертация людей,
которые занимаются скрытыми маркерскими процессами,
и в том числе восстановления одних переменных под другим,
и в том числе как это выбора некоторого оптимального решения.
Вот, то есть сам механизм он, вне этой истории,
он говорит, что вот мы, как бы используя их,
получаем вот такие, такие вещи, что, например,
значит, вот лучше на схеме это объяснить,
а потом я объясню, что где-то слева.
Значит, это уже результат обработки некоторых данных,
то есть у нас состояние меняют друг друга,
ST-1, ST-ST-1 на картинке справа,
и на каждой состоянии действуют предыдущие экшены,
то есть, что, как раньше отреагировала клетка,
это повлияло на состояние объективное,
вот, это в том числе должно повлиять на состояние субъективное,
которое прогнозируется.
Сама клетка получает только наблюдение,
observations, это вот внизу О.
С помощью этих методов мы получили матрицу,
значит, УАТ, это на самом деле, есть какой-то,
чисто математически это некоторый вектор возможных состояний,
тех, которые мы можем наблюдать,
и умножая этот вектор на матрицу,
а матрица А, которая получилась с помощью этого метода,
мы можем получить распределение вероятности
среди совершенно состояний предполагаемых,
которые есть у мира.
То есть А — это вот модель,
которая позволяет из наблюдения получить состояние предполагаемое,
Есть матрица b, которая тоже описывается как вероятностная
матрица, где e и gt с трочкой – это вероятность перехода
из, значит, если у нас было какое-то состояние, например,
2, то вероятность перехода в состоянии 3 в следующем
такте – оно такая.
Итак, для каждых пары состояний, эта матрица задается в виде
этих вероятностей перехода.
Она не задается, она получается из, с помощью этих алгоритмов
мы ее получаем.
И есть c, вот эта интересная вещь, она появляется именно
в этой статье, до этого ее не было, это цель.
То есть у организма есть цель.
Цель описывается в виде распределения вероятностей
по… вот есть конечное состояние в какой-то момент
t, там сотый.
И цель такова, что вот с такой вероятностью оказаться
в этом состоянии, с такой вероятностью, в этом, в
этом, в этом.
Она задана эту цель.
В этой статье она есть, но она встретилась только
в этой статье.
Она определяется как-то этим принципом свободной
энергии этой цели.
Скорее, наоборот, исходя из принципа свободной энергии
этой цели, мы потом, да, начинаем достигать этого
состояния.
А цель дана сразу.
Вот она дано видимо распределение, либо, скажем так, ну в общем,
непонятно, как она получается, я бы так сказал.
Я так понимаю, что она дана сразу, потому что в примере
она дана сразу.
Там написано вот такая вот такая вероятность.
Ну скажем, в общем, геологическая цель оставить потом
все.
Вот за чего родиться от гони?
Это уже цель.
Да, но тут еще...
Тут что-то более локальное цель.
Ну и что, да, но как ему надо идти маленькими шашками?
Ну да.
Ну вот помните, тот интеграл действия, которое я показывал.
Вот у нас есть то состояние, в котором мы сейчас находимся
и то, которое мы хотим достичь.
И вот свободная энергия, она как раз проявляется в том,
чтобы при наименьших потерьах, так сказать, энергии туда-добраться.
Когда же про дофамин будет?
А вот для дофамин и цель, видимо, нужно.
Цель, да, в случае, это некий предмет потребности.
Если приходит психологический термин, когда есть некая
потребность, то есть среда такова, что организму нужно
что-то делать, потому что, ну, проект проголодался.
Вот.
И появляется цель, там, добыть еды.
Вот.
В принципе, поэтому она сразу дана.
Ну да.
Если у нас нет биологических интерпретаций, то нет, то это
интересно, да.
Т.е. цель действительно может быть.
Вообще, в случае она определена в виде распределения
вероятности по состоянию.
Видимо, модель, могу предсказать, что дофамин появляется
как некий...
Мограда за...
Как да.
Да.
Мограда?
Да.
За стяжение цели, да.
Ну вот, оно так и должно быть.
Ну и у него тоже самое.
Вот.
Значит, ну, тут есть некоторые параметры,
параметры параметризуются вся эта история еще через
гамму.
И на самом деле этот параметр играет роль, насколько я
понимаю, вот этой некоторой тяжбы, связанной с
минимизацией свободной энергии, но напрямую алгоритм,
там, так как не раскрывается, я его не очень понимаю, но
понимаю, что как-то через него все это происходит,
т.е. подбор этого параметра.
И...
Так.
Да.
Значит, и в результате, когда он, значит, получил свои
вот эти...
Выписывает все свои распределения, он выражает из
своих решений непосредственно, как зависят, какие перемены
от каких.
Мы сейчас остановимся по очереди на каждом.
И да, и вот, значит, их три, эти переменные, и он их
картирует на мозге.
Он говорит, что примерно, с чем бы он связал.
Еще раз и говори, что не просит его не критиковать
сильно за это.
Значит, первое переменное, которое здесь указано
perception, ну, вроде как, да, можно непосредственно
восприятие ее перевести.
Вот если смотреть на математику, так как, ну, не на что
больше смотреть, да, то здесь, значит, это некоторое
распределение вероятности среди состояний, насколько
я понимаю, которые находятся сейчас.
То есть, это обработка информации и получение
распределения вероятности среди состояний, которые
сейчас имеют мир.
То есть, мы как систем, на основе показаний рецепторов,
хотим понять, в каком состоянии мир.
Вот это первая строчка.
На самом деле, вот первое слагаемое, это то, что
непосредственно выводится из рецепторов, то есть,
это вот как раз, ну, насматривается а, умножается на
показания observations, да.
Второе слагаемое, это то, что, согласно нашей, картине
мира должно было бы получиться, то есть, исходя из
предыдущего состояния нашей предыдущего действия.
Вот.
И есть некоторое третье слагаемое, про которое он говорит.
Значит, это слагаемое, на самом деле, значит, вот
если ку-пи, как его чисто математически можно
интерпретировать, пи однозначно задает последовательность
control states, то есть, состояние управления.
То есть, это некоторая стратегия действия, грубо говоря.
Или вот в некоторых смыслах она интерпрет...
То есть, написано так, что пи, это то, что однозначно
задает control states, но одновременно, чисто математически,
это в каком-то смысле ожидание, попадем мы в цель или нет.
Вот.
К чему мы пойдем?
Это набор политик.
Набор политик, да.
Полисис.
Они, к сожалению, вдруг появляются, не даются им определения,
но понятно становится, то есть, он говорит, что однозначно
выбор политики нас приводит к некоторому последовательность
control states, и это как бы нас естественно приведет
в какое-то состояние, конечное состояние.
Так как у нас есть распределение желаемости
на конечных состояниях, то мы можем понять, какое
состояние нам сейчас надо выбрать, ну, или некоторые
последовательности этих политик, да, стратегию, скажем
словом, таким теоретикой игровым, некоторую стратегию
поведения, чтобы прийти к той цели, которую мы хотим.
Вот.
Купи нам как раз даёт распределение среди стратегий,
которые нужно выбрать сейчас, соответственно,
и тех состояний, которые мы сейчас реализовались,
потому что это в некотором смысле, как бы,
купи переводит в состояние, которое сейчас имеет
место быть.
Это как бы некоторое такое желаемое, исходя из того,
чего мы хотим.
Вот.
То есть интерпретация того, что вот мы хотим этого,
а это вот того, что вот нам хочется увидеть,
потому что нам это нужно.
Вот.
Что мы видим это состояние.
То есть ST — это некоторый такой оптимизм,
этот последний ослагаемый, он его сам называет.
Это такой оптимистический параметр,
оптимистическая ослагаемая, которая в зависимости
от гамма, гамма может быть маленьким,
может быть большим.
Это вот как...
Это не вероятность, как бы, получения награды
или достижения цели.
Нет.
Это уже, как сказать, нет вероятности.
Это вот что.
Мало того, что мы имеем некоторые гипотезы свои,
мы еще, поскольку все приближенно, то мы еще должны
иметь уверенность в своей гипотезах.
И эти уверенности бывают разные.
Вот эта уверенность, она называет точно.
Присижение.
Присижение.
И когда уверенность велика...
Это гамма.
Да.
Когда уверенность велика, вот она порождает
оптимист.
Она может быть неверная, это уверенность.
Да, понятно.
И тогда можно ошибиться.
Поэтому у Кристон говорит о том,
что не всегда надо уверенность максимизировать.
Она должна быть, она зависит от контекста.
Это да.
А P тогда еще что?
А P — значит, дословно это,
как сказано у него, это набор политик,
которые предопределяют набор управляющих
состояний.
Но это, как сказано у него,
а если исходить из того, что заматрится Q,
и почему в итоге умножение Q на P дает состояние,
то P, получается, это распределение
среди конечных состояний.
Вот.
И получается, что...
Таких возможных состояний.
Да.
То есть мы обратно возвращаем, что если мы хотим через
10 тактов оказаться там, то сейчас надо вот-вот-вот
туда двигаться.
Вот.
А это P — это тоже самое, что action-selection.
Да.
Это он оттуда и берется.
Да.
Вот.
Значит, и вот тут он говорит,
что этот perception, ну, или это восприятие,
он предлагает связать с, так, сейчас,
с лобной корой, потому что там, значит,
так, прописывание этих обновлений,
лобной, приписывается этих обновлений в том
смысле, что ST, да?
То есть вот эти вот первые уравнения,
он связывает с лобной корой, потому что там вот
все время вычисляется текущее состояние мира,
где мы находимся, да, и вот сохранение
рабочей памяти, что вот мы находимся здесь.
Вот там происходит понимание по нему, да,
где мы находимся, что за состояние мира сейчас,
что происходит.
Вот.
Поэтому это уравнение он относит к нему.
Но в таком смысле, как программирование,
можно что-то назвать, в общем,
обычный соотноситель, лобной корой,
программирование.
Соответственно.
Потому что я хочу вот такую-то цель,
да, стичьи, поэтому я, собственно,
имею представление о том, как у меня.
Ну, это, так, с программированием,
я думаю, я бы сказал так, что из-за того,
что, видимо, это требует вот,
это формула, во-первых, она самая сложная,
в плане того, что она много чего учитывает,
в итоге, взвешивая что-то вот получается,
то есть некоторое,
относительно глобального параметра,
внешнего параметра,
это некоторые аналог мыслительной деятельности.
То есть, это, как бы, нужно продумать
и взвесив принять решение.
Вот, я так понимаю, почему буквально
соотносит это с лобной корой.
А с вниманием, это как бы...
Хороший вопрос.
Про внимание...
Дело в том, что слово «внимание»
не встречается вообще нигде,
поэтому я не знаю.
Ну, вообще, надо
к его биологическим интерпретациям
отнестись, как...
ну, же стверже.
Значит, вот второе уравнение,
которое называется action-selection,
значит, оно...
оно, фактически,
оно соотносится
с тратомом,
вот, и...
С треатом.
И, значит,
в этом уравнении
мы получаем некоторое
понимание того, что, находясь
в этом состоянии,
куда мы, в общем-то, придем.
То есть, какое будет распределение
вероятностей в конце,
то есть через фиксивное число шагов.
Так как число шагов
и модель определена в конкретный такт времени,
а это дискретная модель,
то есть, следующий шаг,
Q всегда нас переносит
из текущего момента,
вот, если то, что происходит сейчас,
что будет в конце, вот.
И в этом смысле в P
это вот некоторое образ будущего,
да, что будет в конце,
на основе того, что сейчас,
в какое состояние сейчас.
И Precision,
вот этот последний,
вот.
Precision это,
значит,
такое любопытный
параметр, который, во-первых, он входил
во все в оба предыдущих.
И в первом,
я напомню, что в первом он играл
роль такого оптимистического,
то есть, чем больше
гамма был,
тем
больше оптимизма, тем больше мы,
как бы, вот к объективной,
беспристрастной картине мира добавляли
нечто, что нам, по что нам хотелось верить.
Вот здесь он, кстати, первый раз и говорит
про дофамин, вот он последнее предложение,
он говорит, что оптимистичное смещение
вот это, в оценке ситуации,
осуществляется третьим слагаемым,
подобно дофамину пишет он.
Вот.
И второй раз, когда он про него говорит
про этот гамма.
Так, сейчас, значит,
во-первых, это
величина такая,
что вот тут
в знаменателе
альфа Б это некоторые константы,
а то, что вычитается,
это соответствие
вот именно ровно соответствия того,
чего мы хотим
и то, чего мы получаем
исходя из того, где мы находимся.
Вот. Оно может быть
нулевым, вообще не соответствует.
И тогда
вот этот показатель Precision,
то есть, что
это либо уверенность в том, что все правильно, да,
он становится минимальным.
Сейчас,
сейчас, наоборот,
значит, Precision,
если он нулевым,
это не соответствие, а
расстояние, как вы говорите, между ними, получается.
То есть, сейчас,
он нулевым.
Если там нуль, то это максимум,
а если он большой. А, да, все правильно, да.
Значит, если
они полностью соответствуют,
то
то максимальное значение
у Gamma, потому что это ровно нулево
слагаемое, и
очень высока роль того, что мы хотим,
нам кажется, что все так, как есть,
вот как мы хотим, все так идет.
Вот. А если он
максимальный, то Gamma становится очень
маленькой, и в итоге
как...
Да, демотивации. Вот он
здесь
говорит ровно
про это, сейчас секунду.
Это что такое?
А, сейчас, Beta,
это параметр
распределения Gamma, оно в начале
было, оно не интерпретируемо, это число.
Он, например, в примерах говорить,
пусть оно равно четырем.
Вот, но это параметр распределения
у Gamma, Gamma имеет Gamma распределения,
у нее там два параметра, а и б, альфа и б это.
Вот б это один из параметра.
Вторая вещь, которая связана с Precision,
если позволить, я прямо прочитаю,
потому что я не скажу так,
как он сказал, да.
Значит, если точность вот эта Precision,
Gamma, последний параметр, равна 0,
то восприятие Perception
будет беспристрастным. Но это
может привести к невозможности выбора
действий, так как шансы всех вариантов
были бы одинаковыми. Это вот как раз,
он говорит про первое уравнение, то есть,
если вот это занудить, последнее слагаемое,
то все беспристрастно
и может так случиться,
не может так случиться, а вот здесь
ровно так и случится, что
все варианты
они оказываются равновероятными
и выбор будет очень трудным между ними.
Можно ассоциировать это
с патофизиологическими болезнями.
Прокинсон
способствует потеря
дофамин энергических клеток
и приводит к проблемам
с выбором действий.
Он вот эту Gamma непосредственно ассоциирует
дофамином.
Он говорит, что Gamma связывает
с VTA
вот это
я пытался по-русски
написать, я к сожалению не очень
вот он
связывает ее с ней и значение
Gamma напрямую связывает с дофамином.
И вот вторая вещь, что наоборот,
если вот эта Gamma очень большая, то есть
слишком высока
точность вот эта, рассчитывая
то высоко, то
можно
то точный выбор действий
будет конечно сделан, но тогда
возможно предположенность к ложным
выводам, потому что
потому что вот в этом слагаемом
последнее станет почти решать
все. То есть что
говорит объективной реальностью, уже будет не так важно.
Вот. И он
говорит, что очень важно выбрать
оптимальное значение этого Gamma.
И дальше он говорит
сразу, что
оптимальное значение напрямую
связано с тем, насколько
достижимо то или иное
желаемое
состояние.
Вот, собственно, буквально
словами отделывается.
Так, Сереж, может небольшое вступление?
Да. Вот здесь, вот здесь, вот смотрите
на первое уравнение, видно,
что это уравнение метакорическое.
Ну действительно, ну что?
Если буквально понимаете, это уравнение
это вообще слева.
Стоит некоторое число, которое надо будет
распределение. Ну что, Perception, это что?
Это число
нет конечно. Есть ли число в каком
смысле? Олег Петрович.
Другой стороны, нельзя сказать,
что эти все уравнения
не бессмысленно. Почему?
Потому что они отражают некоторую структуру
связи. Вот это вот
с волной в левой части первого уравнения.
Оно стоит в других уравнениях.
Потом, мы можем говорить,
что если что-то растет, то растет
что-то другое и так далее. То есть
о каких-то связях эта система
уровня не говорит. Но буквально
как вообще некоторое вещество
их понимать не сделает.
Понятно, да.
Это понятно.
Вот, и второе
про большие значения
гамма. Он говорит, что
это
из большого оптимизма
приводит к тому, что
могут быть ложные выводы. Эта ситуация
может быть метафорой для симптомов шизофрении
предположительно связанных
с гиппердов, аминергическими
состояниями, видимо.
Про оптимальную
точность, он говорит, что
когда
желаемое состояние
достижимо,
она должна быть тщательно
проанализирована, чтобы не скатиться
в ту или в другую сторону
в этой системе. Если мы говорим
про гамму, да, что она
может, ее очень большое
значение, это плохо.
Маленькое значение, это плохо. Это всегда
некоторый такой баланс нахождения этого гамма.
Так, вот, на самом деле
дальше идет пример, который
нужно сказать прямо
связи
связи его
совсем сказанным, она
то есть, она такая
относительная. То есть, с одной стороны
здесь иллюстрация его модели,
но она совершенно
не биологическая, во-первых,
а во-вторых, каким образом
получается результат
даже на формулы ссылок нет, то есть
как-то получается результат.
Мы сразу потом будем говорить про результат.
Значит, это такая
игра. Когда
вам предлагают в последовательные
моменты времени, вам предлагают
некоторую сумму.
Руба, говоря, сумма в прозрачном
конверте, вы видите, сколько там. Вы знаете,
что могут предлагать мало, а могут много.
Предположим, рубля
могут 10 рублей.
И вам предлагают в каждый момент
времени, и вам в каждый момент времени надо
принять решение. Вы либо соглашаетесь и
берете деньги.
Вот, если вы берете деньги, вот
правая картинка соответствует тому, значит,
тут 5 состояний получается, и вот
в правой картинке соответствует тому, когда
вы берете деньги. Вам предложили мало
на правой картинке вот это
левое-верхнее состояние
со знаком вопроса.
Вы берете деньги, вы их получаете,
но после этого вам уже
как игра заканчивается, вам больше ничего не предлагают.
То есть постоянно кручитесь вот в этом
пустом состоянии, игра кончилась.
Значит,
вы можете подождать,
сразу не соглашаться. Тогда
с некоторой вероятностью вам могут в следующий
момент предложить опять мало.
Могут еще меньше вероятности
предложить много
и с какой-то вероятностью
игра закончится.
Сказать, ну все, больше не будем.
То есть получается, что
у вас выбор такой, что
вы не знаете, сколько раз вам будут предлагать.
Это всегда некоторый такой вероятный
момент, сколько раз это будет происходить.
Но если вы соглашаетесь на мало,
то все заканчивается.
Вот, если вы говорите
что я подожду, то вы рискуете.
В следующий раз может быть много, может быть мало,
может быть вообще ничего и никогда уже ничего.
В этой метафоре
значит,
управляющими переменами вы являются
как раз ваше решение,
вы либо соглашаетесь, либо вы говорите, что
вы подождете.
И скрытыми переменами являются
значит, вот все эти
пять состояний, которые здесь имеют
место быть.
Они предлагают мало, предлагают много,
уже ничего не предлагают
и вы взяли
то, что вы выбрали.
На основе
этой игры...
Скрытыми переменами, наверное, QE,
потому что он не знает,
какой вероятный у него предложат много.
Ну, как сказано в статье,
скрытыми переменами это вот именно
эти состояния.
Да, дальше он, на самом деле,
когда рассматривает этот пример,
так что с каждым следующим разом
все вероятнее, вероятнее
игра может закончиться.
И в результате
он предлагает
посмотреть, вот исходя из его модели,
как
меняются вероятности
вот этих вот
выбора то или иное управляющие
перемены. У нас
играть дальше
или брать деньги сейчас.
Значит, первая ситуация
отображена на этой картинке, значит,
вот слева
в верхнем
квадрате, по оси X-время,
первое, второе, третье, по тактам,
по оси Y это скрытые
состояния, первое, второе, третье, четвертое,
пятое. Значит,
первое состояние это, я напомню,
предлагать мало денег. Значит, какое-то время
предлагают мало денег, потом
вдруг предложили много денег
и потом игра закончилась.
Значит, для
разыгрывания этой состоянии, да, при этом
задается цель. Цель задается
в виде вектора, я ее здесь не привел, но
он фактически там просто задает
некоторое его ожидания. Он же, на самом деле,
у него очень хорошее ожидание в этой цели.
То есть, он
очень уверен, что он играет много,
в два раза менее уверен, что он возьмет
мало в результате этой игры и совсем
мало вероятности про остальные.
То есть, он такой оптимист.
Вот. И для этой
модели, для этой цели пересчитываются
в каждый момент времени,
в каждый, как бы, раз, когда ему
предлагают деньги, пересчитывается его
прогноз,
но это распределение вероятности
относительно того,
когда ему надо согласиться.
Вот. Оно здесь не очень хорошо
видимо. Вот, для этих
функций, вот, которые
зеленые, тут есть зеленые
функции справа,
вверху справа, это
это взять
деньги, вероятность того, что он
хочет взять деньги, а синяя
это, ну, наоборот, просто перевернет,
это вероятность того, что он будет играть дальше.
Вот.
И, значит,
потихоньку, с каждым тактом, у него
его оптимизм, ну, немножко так проседает.
То есть, но тем не менее, он не критичен.
То есть,
опять-таки, тут важный момент.
Это распределение вероятности в том смысле,
что
как бы, получается,
что наша стратегия это не
точно определенное значение, делай это.
А это распределение на множестве
действий. То есть, мы говорим,
что вот с такой вероятностью
в этой ситуации оптимальнее делать так, наверное,
а с такой вот так, а как делать, это уже, значит,
в соответствии с этими распределениями вероятности.
В этом смысле, как бы,
само решение становится
инструментом, вернее, оно получается
исходя из распределения вероятности.
Вот.
И, значит, в какой, в тот момент,
когда ему дают деньги,
он естественно соглашается,
потому что уже много ему предложили.
То есть, постепенно у него растет
его вот этот веро в то,
что будет ли этот момент,
когда ему предложат много.
И он все больше и больше, вроде как,
прогнозирует, что в следующий раз,
он еще подождет, но в следующий раз
он уже сдастся.
И в тот момент, когда ему предлагают много,
у него вспышка вот этого распределения,
то есть, последние зеленые,
когда ему предложили много,
он берет и игра заканчивается.
Значит,
и вот здесь слева,
слева внизу, это как раз значение
гаммы, то есть самые гаммы,
про которые мы говорили, это perception.
Значит, она
постепенно, то есть, вот эта, грубо говоря,
precision,
точность, да, прощание precision,
значит, то есть, она постепенно,
постепенно, постепенно падает,
ну, тут не очень заметно, но она чуть-чуть
да, и потом ему предлагают много денег,
и она взмывает до небеса, до конца она уже большая,
потому что он добился того, чего
он хотел, что он выиграет, он выиграл
эти деньги.
Да, что это случится, что в итоге игра
кончится тем, что он выиграет.
Вот, и вот как получается
вот эта картинка, значит,
он пишет дословно, что она
получается
значит,
там механизм фильтрации,
определенным образом, механизм фильтрации
вот эти
значения интерпретируют, он их
как дофамин,
получается они из переменных
его модели, каким образом, тут
нигде он про это раньше не говорил,
и формулу нигде не написал, каким-то
образом он интерпретирует
доставая свои переменных в свои модели,
переменную, которую
он интерпретирует как дофамин.
Он так ее называет,
simulated, дофамин,
responses, значит,
вот каждый раз
мы видим, что когда
предлагают
значит, какие-то значения
вернее, делают предложения
этому человеку, он все больше и больше
предвосхищает, что вот сейчас будет
выигрыш, или сейчас будет выигрыш.
И когда он получает выигрыш, происходит
максимальный всплеск, и потом уже
понятно, ничего не происходит, игра заканчивается.
Сейчас там получается, этот максимальный
всплеск, он определяет
его решение принять,
или он появляется именно
как наград.
Я понимаю, когда ему уже дают эти монеты.
На самом деле, по-моему,
вопрос-кварт, биологический.
Дело в том, что да, это
наград, то есть это
причинные лечебные,
яйцо и курицы.
Но получается оно
экспериментных, вопрос, как
оно получается экспериментным.
Так, Сереж, а сколько я понимаю,
вот эти вот маленькие
всплески
всех дефамина, мне кажется, они
означают вот что, что
каждый раз он слегка
опасается, что на священном шаге
не будет ничего. А когда он видит, что
опять чего-то есть, это небольшое
удовольствие. Значит, пока он прав.
Ну, возможно так.
И второй случай, когда
не случается эта схема, то есть
когда, значит,
опять картинка на самом деле
поменялась, то есть наверху слева
ему предлагают
мало денег, а потом вдруг игра
заканчивается.
Значит, то есть когда
у него те же самые цели,
он планировал выиграть много, а
на самом деле это все ничего...
Ничего это...
Ну, она у него, то есть он, как бы да,
он получается с той же целью
рассчитывать те же вероятности, те же
распределения. Вот, но момент,
что происходит много, не случается.
И здесь точно так же
меняются распределения со временем
от того, что он...
от уверенности того, что он должен играть
или нет. Они
не доходят до критических значений, чтобы он
все-таки взял, да, то есть раньше
это происходит. И в итоге
игра заканчивается, он не выигрывает ничего.
Мы видим, что
вот эта гамма, которая
говорит об точности,
она тоже сначала падала, как и на
в предыдущей картинке. На самом деле тут просто масштаб
поменялся. Она не больше, чем там была.
Просто там был всплеск, поэтому
она... А здесь она точно так же.
Она, значит, тоже падала.
А потом, когда оказалось, что
не предложили, игра закончилась, она упала совсем.
Вот.
И вот, значит,
продафамин здесь интересная картинка.
Значит,
интерпретация...
Тут, конечно, тоже
специфическая. В общем, насколько я понял,
что, то есть, он все происходит
та же самая картинка, пока не случился
проигрыш, да, то есть вот эти небольшие
колебания дафамина. Вот. А потом
опять-таки
какая-то расчетная
дафамина, то есть ненастоящая.
Вот. А потом
он говорит, что вот все-таки он начинает
колебаться больше, больше, больше. И
он говорит, что это
как-то связано с некоторыми
вот переменами модели, что вот он
все-таки
продолжает, как бы, они продолжают
там
как-то он так вывелся, что, значит, цель
не достигнута, там продолжается
какой-то пересчет, и
вот из-за этого этот дафамин
колеблется. Он пишет, что это интересно
и даёт ссылки на людей,
которые занимаются, ну, то есть на
другие статьи, где... не свои статьи,
где есть что-то сказано, что вот как-то,
как здесь прямо, вот что-то вот такое.
Но те статьи я не смотрел.
Я так понимаю, что это
идеологически какие-то вещи.
Вот, но это-то его расчётная
штука. А как ещё раз он и рассчитывает?
Он, наверное, говорит, как
он и рассчитывает, да? Нет, он говорит
это словами, да, он говорит
словами, и суть
математического принципа, ну, то есть
его можно сказать одним словом фильтрация,
а суть в том, что если, например, у
нас есть какие-то два временных
ряда значений, и
у нас мы их перемножаем в каждый
момент времени, вот, получается
третий временный ряд, так вот он говорит,
что, наблюдая третий временный ряд,
и, видя второй, мы по нему
можем восстановить первый, вот так
он получает этот
дофаминь, но какие
эти два временных ряда, он их не называет.
То есть, он называет
метод, метод говорит в том, что
из двух, когда две перемены,
ну, как бы говорят, две функции, они
в каждый момент времени перемножаются их значения,
и мы видим результат только,
мы не знаем, мы видим результат, но видим,
может быть видим, как одна из них
выглядит примерно, то мы по ней можем
восстановить вторую, как она бы
выглядела, вот, вот суть,
он это не говорит словами, он просто
говорит, что метод этот, вот этим методом
мы это делаем, а метод заключается
в ровном восстановлении одной
из функций по другой, вот,
а какая функция
не про одни из них, он не
называет, что он берет, даже в своих
переменных, что это,
может быть, он имеет виду гамма,
но мы не уверены.
Вот.
Забавно, но то есть не очень понятно, да?
Да.
Интересно, что будет, если сразу дать
много денег, прямо с первого подъявления
по ней, дофамина этот метод?
Наверное, то же самое, что было
в первом случае, только это случится
раньше, то есть. А может быть,
будет и мало. Дофамина мало?
Да. А то есть еще так хочется
Вчера войны что игра кончила?
Ну, это же цель меняться
не может.
Но здесь она одна и та же, то есть
она вот фиксирована целью.
Он хочет выиграть вот столько денег,
причем он почти уверен в этом, то есть
его уверенность задается
в виде того, что он в результате
этой игры выиграет.
Интересно, что он не
рассматривает, например, когда
цель была бы другой, например,
выиграть мало денег, но он уверен, что
он выиграет мало денег, но, наверное, он так-то
сразу и соглашается, скорее всего, да, так-то
если цель быстро прекратить игру,
а деньги все дают,
и дают.
Нет, тогда надо взять деньги, игра
кончится.
Ну да, всегда можно забрать?
Да, да, да.
А вот, в чистых таких моментах
мы смотрели внимание, о чем
здесь идет речь, вот здесь
ему предлагали.
Здесь как раз понятно.
Да, здесь вот в результате
он предложили много, а что вот это
заканчивается? Это заканчивается игра.
То есть, вот это состояние означает, что
он с деньгами там находится уже.
Деньги у него, игра закончилась.
А вот тогда вот на следующей картинке, вот что
следует? Следующее.
Почему такая широкая средняя полоска?
А вот тут, вот что здесь должно
произойти?
Ему каждый раз предлагают много
денег. Нет, нет, нет,
картинка именно такая.
Вот почему здесь нарисовано в конце
5.
Вот именно как будто оказался в этом
состоянии. Не знаю,
не могу проинтерпетировать. Я бы
проинтерпетировал что-то тут как-то это.
Потому что словами, это ровно, он говорит
о том, что игра закончилась и у него
денег нет.
Я бы проинтерпетировал что-то как-то
не ошибок. Там просто, видимо,
предполагается, что у них там, то есть
они специально выравнивают, чтобы,
скажем, что если он получил что-то раньше,
он по времени должен ждать.
Я не могу максимизировать,
если я хочу увеличение силопопыток.
Видимо, здесь просто предполагается,
что вот это время так пока он ждет.
Затружено вот таким прямоугольником.
С таким вопросом тогда, что вот они
здесь моделируют. То есть, как будто
он ждет, и они предполагают, что просто
пока он ждет, значит, происходит
как бы некоторые нарастания.
Ну и какие-то вот такие фазные
скачки, вот это вот
это вот.
Я на самом деле
не могу говорить.
Нет, я смотрю,
я читала эту поведенческую методику.
Она, в общем, такая довольно-таки
простая, там никакого права нет.
Там просто действительно выравниваются
по времени попытки, чтобы за счет
увеличения количества попыток,
он мог максимизировать свой, ну,
увеличивать свой выигрыш.
В том смысле, что они их рассматривают
всегда одно и то же число
моментов, да, то есть времени.
Ваши возможности, и возможности, что
все совсем не так.
Вот это самое
левое терпение.
Смотрите, по оси игр,
это просто номера состояний.
Ну да. Вот и стой,
картинки, да, поэтому вот это черное
там наверху, значит, значит, он пока
находится в первом состоянии, он ждет.
В третьем счету, да.
Потом он, значит,
вот где на шестом шаге,
он решил перейти вот в это состояние.
Вернее,
а ему не да, да.
А да, его оказался в третьем состоянии.
Да, а как он пришел в пятом?
А пятая
это, когда все уже, из него выхода нет.
Смотри, предыдущая,
вот тут диаграмма.
В пятой, это даже деньги,
это просто там ошибка.
Ну, кажется, что ошибка.
Если эту картинку посмотреть,
действительно, не из пятого,
не из пятого, значит, они
пронувированы первой, а второй,
а третьей, четвертой, пятой.
Не четвертая, не пятая, не третья,
нигде не выходит.
А, вот здесь, смотрите, из пятого
здесь есть выход, да, вот интересно.
Ну, из пятого в третьей, а не на пятой.
Да, да, в пятой никак не попасть.
Ну, ну, просто...
Это ошибка, это ошибка.
Вот еще вопрос такой.
Это предполагается, люди один раз
играют, один человек,
один раз играют, и это его
новый опыт.
Это уже обычный человек.
То есть, он играет не первый раз,
и он уже в эту игру играл.
То есть, у него же есть модель?
Да, у него есть уже модель.
Модель должна быть точно, да.
Ну, тогда вот эти всплески
дофамина в конце могут
связаны бы с его состояниями,
как он в прошлый раз выиграл.
И вот он сидит все эти, сколько там,
минут, десять, и вспоминает,
сколько в прошлый раз ему давит деньги.
Его дофамент по его воспоминаниям
в голове все-таки отъезды идти.
Ну, имеется в виду вот модель вот это.
Потому что она уже
имеет некую картину, некий опыт.
Хотя, конечно, было бы интереснее
с настоящими людьми это делать,
а не с его моделью.
С настоящими людьми?
А где?
Просто Наташ сказал, что их обучают.
Да, соответственно...
Не уверен, что я...
Нет, он есть со настоящими людьми.
И тоже Христом, да?
Да.
А, да, вот так вот.
Чуть-чуть на 10 картинках.
Я вот не разобралась,
потому что я в начале в самом перусе,
а он в перусе тут в эту матрицу,
и не поняла, что она это начает.
Но я вижу, что они картинки какие-то другие.
Нет, но вот это вот тут практически то же самое,
что я показываю.
Здесь, в процессе поиска ПУ,
оно зашит благородно,
когда он ПУ пересчитывал,
ПУ, которая...
Да, то есть мы тут его просто уже как...
А можно еще то же те, что технические вопросы
по этим картинкам?
Следующим?
Да, смотрю.
Вот то, что вы говорили на картинке с воздухом,
Присижен это как бы был
некий аналог фагоменного сигнала.
Как бы да.
Здесь все-таки этот Присижен что-то преобразуется.
Вот это как-то обосновывается.
Где там?
То есть Присижен даётся в чистом виде,
с самыми значениягамма, до слева.
А как получается картинка справа?
Нет, как получается понятно, что он как-то там
забланирован все это.
Да, я так понимаю, что это Присижен в том числе зависит.
И судя по всему...
Как это обосновывается вот это преобразование?
То есть в данном случае вроде бы полностью сигнал такой
поступает,
ожидаемая точность, да?
И собственно там вот эта стрелочка
есть как бы об ожидаемой точности.
Здесь они все-таки эту ожидаемую точность
каким-то образом преобразуют,
преобразованную виде она действительно туда поступает.
Преобразованную вы имеете ли справа?
Да-да-да.
Она не поступает, она
Присижен внутри модели,
остается гаммой своей,
вот этим значением слева.
А для нас, они её зачем-то вот оттуда
достают это в их понимании
дофамин, в их понимании.
Но я так понимаю, он в модели не играет роль.
Он как индикатор,
посмотреть, что внутри происходит в модели.
То есть они берут эту гамма и быть может
это в гаммере.
И каким-то образом получается этот дофамин.
Каким непонятно. Вот он вычислительный,
вычисленный дофамин.
И то, что они называют дофамин
в этой модели.
К сожалению, это самый такой неясный момент.
Ну, один из самых неясных.
Я не знаю.
Вот мне кажется, что на самом деле
есть биологические системы,
хорошо изучены,
где дофамин принимает участие
в принятии, механизмы принятия решения.
Вот Фрисон взял вот эту вычерну,
в общем,
где все приходится как бы спать,
соваться с участием дофамин.
Они проанализируют
математически
хорошо изученные системы.
А что за хорошо изученные системы,
где дофамин принимает участие?
Вот таких кучер.
Например, на клубе, на дворе.
То есть они прошли, но
ориентироваются на работу,
где дофамин это
есть.
Ну вот есть, например,
морской андон.
Вот наш объект.
У вас дофамин другой?
Довламин тот же?
Тот же дофамин,
и принятие решения
в пользу того,
о новодичной роли играет Сертонин.
Сертонин?
Нет, принятие решения
между разными
стратегиями поведения
определяется
соотношением балансом
Сертонин и дофамин.
Причем все это изучено
и на кветочном, и на поведенческом уровне.
Если ты такой умный,
принеси свою математику и проверишь,
как это работает или нет,
какие предсказания можно сделать.
Мне кажется, в данном случае
просто несколько другой подход.
В этом поле есть много моделей,
где моделируют каналы и прочее.
Ну хорошо, вот его модель
Фристон дает
какие-то предсказания
для этого поведения.
Проверяемые предсказания,
проверяемые в эксперименте.
Потому что, на самом деле,
на мой питающих, как раз очень много работ
с дофамином принять решение.
В том числе?
Да, кстати, что вы сказали,
дофамин выделяется
независимо от того,
цепь достигнут или нет.
Он заставляет принять решение.
Да, нет.
Зависимо.
Но, например,
если цель поесть,
то
увеличивается содержание
сертонина в определенных клетках.
Увеличивает секрет сертонина,
но после того, как поезд
падает,
с дофамин немножко не так
подробно изучен, но там цель
другая.
Ой, извините, я занят.
Я говорю, вот с дофамином,
когда больше
в пользу дофамина баланс,
там как бы цель
другая – отдохнуть.
Вот так ангел плавает, плавает,
плавает и есть захотелось,
начинается
повышение синтеза сертонина
в определенных клетках.
Они хорошо известны.
И это можно править не на ангел,
не на других животных,
но на пиявке, например.
То же самое. У голодной пиявки
растет содержание сертонина
в определенных клетках.
И как только она наелась,
это такой общий биологический механизм.
И баланс между сертонином
и дофамином – вот я рассказывал, например,
выбор локомоции
из диалюров.
Какой изалюров повидел мог
лучше обеспечивать
еще и достижение биологической цены?
И вот здесь вот
приложи математику, приложи формулы,
найди свободную ангел.
Все это можно проверять
непосредственно.
А у Фриснона вот эта модель
совершенно фантастическая.
Там все из пальцев высказывает.
Не совсем фантастическая.
Ну не совсем.
Просто другие объекты.
Это мишинная модель
с макремплейом.
Где-то она
получает удовольствие,
там-то пойми.
Для кого-то это гораздо
более естественная модель, чем
ангел.
Пожалуйста.
Нет, это все же эврюционные вещи.
Модель животное меняется,
а вещество остается те же самые.
Ну да, немножко функции меняется.
Чуть-чуть.
Нет, ну в принципе,
может быть какие-то, да, сохраняются
вообще по фестимодели.
Так я все-таки вопрос жалко.
Которое мы создаем.
Делать предсказания
из своих вот этих работ с дофамину.
Предсказания, которое можно проверить.
Фидиологически на эксперименте.
Я не нашел таких
щищных, что можно делать.
Теоретически можно померить
уровень дофамину мыши
в определенной области мозга,
в математически,
в конюль какой-то,
в определенной области мозга.
И посмотреть ей,
повторяются вот эти всплески
в велящей жизни.
Смотрите, что, наверное,
называть, проверить модель.
Вот в моем понимании,
я позволю себе интерпретировать эти слова.
У него есть некоторая модель,
например, вот этот последний пример,
который математически вообще,
можно сказать, никак не описан,
но есть, в результате
построения работы его модели,
некоторый выход, который
он интерпретирует как изменение
дофамина.
Будет ли, будет ли проверка
этой предсказательной...
Не он интерпретирует, он берет
из литератур, чтобы у партенционников
дофаминов снижено.
Нет.
А он сумасшедший.
Да, это да.
Но вот в последнем примере с игрой,
с настоящего человека,
и чтобы у него
была какая-то цель,
выиграть так или иначе,
и проигрывать с ним вот эти же ситуации
и смотреть, что у него происходит с дофамином,
а потом сравнить с тем, что даёт модель,
это непредсказательная,
её же можно проверить, так ли это происходит,
если в спец дофамина в этот момент,
или это с точки зрения биологии, и так понятно,
тут нечего проверять.
Я просто не знаю.
Я впечатляю, что ему это интересно.
Проделать.
Вот то, что вы сказали.
Мне кажется, есть обратная ситуация, нет?
Если действительно он использует
свой прийти к свободной энергии,
показывает, что он может
прийти к тому, что
есть определенные
законоверности выброса дофамина,
которые действительно совпадают,
как я понимаю, с тем, что получают экспериментики,
правильно?
Вот ситуация гораздо более запутанная,
в том-то и дело. Во-первых, экспериментики получают разные,
есть уже школы,
которые, в общем,
они не спорят, они как бы не пересекаются,
они друг друга не цитируют,
там очень частно понимают, и так далее.
Нет, у них не есть такая же работа.
Но очень популярная, да,
вот эта модель reinforcement learning
она и математическая, в том числе,
я понимаю, что это...
И, в частности, вот Христон спорит
в тем, что его модель отличается
от этой модели, он считает, что дофамина
делает не то, что о чем говорит
эта модель приход с нетлей.
И вот единственное, собственно,
экспериментальное, как вот идеи,
вот идеи вот здесь опущены,
это вот эта статья, которую я нашла,
которую я просто не смогла разобраться
для того, что у первого математического
какой-то аппарат.
Вот здесь, собственно, вот у них вот эти
столбики, вот серые, синий,
это реальные данные,
которые они получают с помощью
тому, что мы в МОРК,
и это данные, которые они, вот,
ну вот, может быть, сейчас что-то стало
мне понять, мне попробую
в этом разнообразовании.
Они похожи там на тебе синий, серый столбик?
Там есть некоторые разнообразия,
опять же, в этих
высотей, в столбиках.
Почти одно это.
Да, да, в общих и целых,
гораздо хуже бывает.
Вот, ну он, вроде бы,
с одной стороны, вкладывает какие-то, действительно,
представления у него в другой статье,
где, действительно, у него идет какая-то математика,
очень абстрактная, хоть я не математик, но видно,
что там как-то просто вот рассказывается
о том, что вот она так была.
А потом раз идет, а вот это похоже немножко
на дефамины, какое-то перечисление данных
по поводу дефамина.
То есть, с одной стороны, он хочет списаться
в некоторый набор экспериментальных данных,
огромным и питающим, очень противоречивым,
в общем-то. В другой стороны,
он предполагает свою некоторый взгляд,
за счет которого, он пытается
эти противоречия каким-то образом снять.
То есть, в общем-то, у него есть какая-то
своя идея, другое делать,
как это, в конце концов,
все получается.
Ну, учитывая огромные крючки,
вот эти, просто какие-то необозримые,
а причем они все, почти
в последние лет десять, наверное.
Да, даже меньше.
То есть, просто, ну, много из них
действительно повторяется,
прямо из-за того, что, кстати, ну, шавка
всегда повторяется, да, про эту систему.
Вот. И, видимо, там большое количество людей
с ним работает.
Чисто по внешней паре,
там, кажется, большое исследование.
У него нет, во-прежнему, уже давно
у него нет савторов-профинитет,
кто занимается фанильной системой.
А другие геологи там вообще
интересно есть, где савторов?
Да, есть, у меня есть такие статики,
где там еще и много шковорожных народов,
ну, вот и те,
которые занимаются так более не пристально.
И, опять же, те, кто пристально занимаются,
они, как правило, принадлежат вот
какими-то шковами.
И очень часто, что такие-то обзоры,
более-менее претендующие
на эту некую всеобъемную часть,
они как раз пишут и цены людьми,
которые, в общем-то, немножко
боком все отношения с исследованием
фанильной системой стоят.
Поэтому, вроде как, то есть, какой-то интерес есть,
желание, вот, проясните,
что там за какой-то рациональный
извиноз, что вот можно выйти
не функционалов, в конце концов,
а не фамины же, как все работают.
Потому что, в общем-то, во-первых, действительно стоит
вот, как бы, ребро, до фамины работают
или после. Все вот эти
репортивные вклёвки, это все, они
между людьми, что это работает после.
Но при этом это никак из-под пенсионизма
вообще не делается.
А до или после чего?
До действия.
До принятия решения, до того же,
да.
Наказание или мотивация,
там попуждение действия.
То есть это еще не
не установленный факт?
Нет, если вы почитаете некоторые статьи,
там идет, что, как бы,
да, все всем известны, что это так,
а вот, да.
Ну, есть такие статьи, например,
кто там последний скажет ревар,
пускай включает свет, там, что-то того, что
вот мы, да, у нас есть какое-то слово
ревар, мы с ним каждый понимает его
по-своему, и в результате,
собственно, что мы знаем и до фамилии,
как вот мы работаем. Но здесь, конечно,
упор на то, что это, собственно,
намлекопитающе.
Потому что, действительно,
это, конечно,
это, конечно,
это, конечно,
намлекопитающе. Потому что, действительно,
вот так, таким образом,
вот функционал он поменялся.
Вот в обзоре обзор, в принципе,
по этому поводу, когда там случился.
Кстати, это
совсем другая фамилия
на системе.
Это фамилия на системе,
не столько,
то, что очень непонятно для меня было,
почему он открывает на фамилию
на системе, потому что это
другие гяда.
Это не совсем так, потому что
смотришь, что, опять же, считать ревард системы,
то есть то, что они не создают инсэнтив,
вот некое побуждение,
то, что вначале, вот,
вы говорили, некого можно поднести
под общую шапку имблицительного научения.
То есть, научения, как бы, без нашего
специального обучения. То есть,
мы просто идем, почему-то, по ходу, делаем
учимся, ну, там, как на тайках кататься.
Там, в общем-то, это тоже, или, в общем-то,
ошибка, предсказания,
из награжения, что, вот, я поеду, а тут, раз,
он упал. То есть, это, в общем-то, в принципе,
работает, вот, это основоположник, вот,
этой идеи, о том, что это
ошибка предсказания, из награжения, шумец.
Он, собственно, вообще смотрел все.
Он не разбирал структуру, он смотрел
вот, в конце, нигра, или фута, и он
упал, по его мнению, то они там
одинаково работают.
Вот, в принципе, это очень всерединено.
Спасибо.
Я хотел еще, в конце,
сказать, что,
как сказать,
какие-то слова, вот, там, где
еще идет мне про математику,
а про какие-то его выводы,
какие-то его предложения.
Вот, я вполне
мог не понимать совсем,
или понимать их неправильно.
Поэтому, вот, содержание
статьи, там, где была математика,
моделирование, я могу в них
более-менее пытаться разобраться, но,
допустим, у него в конклужинах,
что я не упустил чего-то важного, чего он
делает потом без относительно модели.
В модели случилось, а вот он сам что-то
потом пишет, может, его свое мнение
высказывает. Я вполне мог пропустить,
потому что я про дофамин не знаю ничего,
и мне, когда я вижу, что это никак не связано
с моделью, он говорит, что это про дофамин.
Ну, я, я мог это упустить, поэтому
я хотел, то есть, я хочу
сказать, что это надо, вот,
конклужинс его в конце еще раз
посмотреть в пустом ключе, потому что
я вполне, вот, что-то просто вообще не
понять, что он утверждает, например.
Но, опять-таки, если он утверждает,
что он утверждает без связи с моделью, потому что
в модели ничего про это не говорит.
Ну, по крайней мере, нужно сделать
теперь после того, как
что-то будет. Да, какое-то
выигрывание, вот так вот
твои дела работают с
фото. Олег Петрович,
мне кажется, нам надо принять
стратегическое решение. А именно.
Потому что есть, наверное, много вещей,
которые можно было бы обсудить.
Не, не на беду.
Да. По поводу Фристо,
может быть, делать отдельным
семинаром, потому что сейчас
это
высказаться хочется,
но это как бы начался
новый
вид. В общем, да.
Да, что это и нам уплубляться
и даже в самого Фристо,
но там есть несколько направлений,
что надо было бы обладать.
Может, конкретно тем, дофамины
принятия решения.
У нас же есть
некоторое актуальное для нас
очень темно. У нас есть
принятие решения уликой
в неопределённой ситуации.
И к этой собственной нашей
поведенческой модели мы
всё время хотели посмотреть,
положиться ли на неё и как на неё
ложиться в теорию.
И хотите, вы, мы можем сделать
следующий магический семинар,
где мы просто расширились.
Да, мы же без дофамины.
Без дофамины, пожалуйста, пока.
И получается, как себя ведёт улитка,
когда мы снижаем, повышаем
в неопределённой снежной следы,
как она меняет своё поведение,
как она принимает решение,
о котором мы считаем рискованным.
А вы, да, и пока мы не забыли
всё, что мы услышали сегодня,
вы с этим разобрались,
может быть, да, видайте нам,
пожалуйста, презентацию,
потому что, может быть, мы что-то придумаем,
во-первых, и в плане интерпретации того,
что мы получили, и может быть,
в плане сотрудничества, и в плане,
в плане опытов,
потому что это, может быть,
интересно, мне кажется.
Так что здесь очень интуитивно чувствуется,
что много совпадений. Во-первых,
мы создаём ей высокую степень
определённости, это тот самый сюрприз,
когда мы буквально принимаем
любой из батареи, а не у них
позакварима, у неё есть цель,
и нужно найти воду. И мы меняем
степень определённости
внешне среды длини. То есть, мы создаём, скажем,
и в зависимости от этого, мы видим,
что её поведение меняется. То есть,
если мы создаём для неё совершенно
симметричную ситуацию, то
её выбор явно затрудняется,
и мы это видим по поведению.
Может быть, здесь можно что-то придумать,
такое, что будет интересно. Или хотя бы проверить,
как это ложится действительно на
фристонские идеи,
свободные идеи и так далее.
Ну, в теме распределения, например, об этом.
Да.
А, ну что ж.
Может быть, не очень длинный семинар.
То есть, так что
у нас покаливали...
Кстати, вы на этом, на своей модели
вы роль сертанины смотрели, а
роль дофанины не смотрели.
Или, может быть, смотрели, но я не знаю.
Нет, не смотрели, не смотрели.
Потому что там, я вот, хочу
такую подкинуть идею.
Здесь всё энергия, энергия,
свободная энергия.
Можно иметь значение,
что выбор в пользу сертанины
зависит от того, что один из них
окислитель, а другой
восстановитель.
Это взаимодействие
с энергией.
Ну,
стоили энергии театричные,
какой был аэцерист,
или с реальными
энергичными процессами.
Мне кажется, здесь сочувствовать можно.
Да.
Да, сочувствовать можно.
Сведение вероятности
мне кажется, что это более жирно.
Давайте, да. Вот хотя бы вот такие
слова, они были бы полезны
по приложению к тому, что мы реально делаем.
Потому что
вот просто интуитивно
чувствуется, что это
можно описывать в каким-то
более интересном языком, и возможно
проверять на
реальной поведенческой модели
в модели.
Хорошо.
Понимаешь.
Спасибо.
Ну, а какие воспечатления
от Фристона,
от рассказанного Фристона?
Я могу сказать,
что
мне трудно отделить background
от Фристона.
И я очень благодарна за то,
что я хотя бы услышала этот background.
И много
и практически все, по-моему,
сегодня говорилось. Интуитивно
Лео там воспринимается, мне кажется,
положительно, потому что
представление о том, что
да, есть некоторое
сформирование моделей,
которое может как
приближаться к объективной
реальности, так и удаляться от нее.
Все это, ну не знаю,
мне это понравилось. Мне это не вызывать протест.
Единственное, там был один
момент, который у меня вызвал
сомнения, но, может быть, мы в следующий
раз это обсудим, потому что иначе мы
уйдем опять куда-то в сторону,
что все-таки это все
слоится к тому, что как бы основная цель
это построение
лучшей-лучшей модели
внешней среды, то есть
получается. Но на самом деле
вот, как раз здесь
у биолога возникает вопрос, так ли?
На самом деле,
вот, то есть, ну это
уже почти мы уходим в философию,
да, то есть
вот здесь биологическая есть некоторая
противоречия, что на самом деле вряд ли
это цель для живого организма,
построение,
оптимальные модели внешней среды.
Нет, это не цель, конечно.
Это инструмент, а не цель.
А цели биологические, как я сказал,
выживание, создание потом,
что-то сказать.
Ну вот, да. Но как раз в мире это
инструмент съемок? Правильно, но
очень часто это вступает в противоречие,
то есть на самом деле надо для достижения
приходится отказаться
от объективного построения модели
и загрубить ее,
загрубить ее, или даже создать
ручку. Да.
Вот эти все бутылочные горошки,
они о том и говорят.
Да, но вот в третьем панкпункте
там просто... А, прессируют?
Да, по-моему. Вот там это было
в вашем докладе,
уже в приложении.
Ну посмотрим в следующий раз
потом, в результате.
Вот.
А в следующий семинар
тогда, как всегда, через две недели
или сделать еще быстрее?
Две недели.
Я вам скажу.
Вот у меня общее впечатление
подозрительное к Фрису.
Как было, так оно и
усугубилось.
Вот знаете, вот на чем
спорастал вот у него эта работа
с темной комнатой, да?
И там
что обсуждает его модель мозга?
Физик, философ
и теоретик
по теории
информации.
Если бы у Фрисы то
сломался унитаз,
канализация.
Вот представьте себе такой трил, пришло
обсуждать.
Сам техника надо позвать.
Они не догадались
пригласить биологов.
Хотя их объект
он ссылается
в предсове книги
20-го года, когда именно такая
была.
Там книга была. Время, пространство
и гравитация.
Совсем другая проблематика.
А тут он о мозге
биологическо
в объекте, имеющем совершенно свои
законы. Хочет обсуждать
на уровне сам техника.
Это никуда не гордится, мне кажется.
И это вы погубаете все время.
Это понятно почему?
Вы найдите такого биолога, с которым
можно это обсуждать.
Можно хотят спросить, что с собой
нервные клетки.
Они же приписывают.
Что это значит?
Нет, понимаете, если он живет в мире
в своем модели, это вполне нормально.
А почему тогда
какой интерес?
Почему, скажем, патологический интерес?
Не хватает фамилии.
Потому что он использует еще
многие, которые вообще не
может...
Нет, только уровня его привязания,
потому что он претендует на общей
теории мозга и так далее.
Только этим?
Нет.
Опять. Он претендует на общей теории мозга.
Потом берешь
другую статью на общей теории.
Та же самая теория.
Общая теория любых адаптивных систем.
Потом берешь третий тип.
Общая теория всего же в голову.
Как источник
единственных всех идей
это искусство интеллекта.
Совершенно искусственная инжемерная система.
Вот это все вызывает
какое-то подозрение,
что не все тут чисто.
Но механицизм
нельзя из науки совсем воскоренеть.
Я говорю
своем мнению.
Олег Петрович спросил о впечатлении.
Вот это общее впечатление.
Может быть, если разбираться под деталем,
как кажется хорошо приложимым
к реальным системам.
А может быть и нет.
Может быть и нет.
Примерно такое же ощущение у нас.
Другой идем.
Разбираясь с Фристоном
мы, тем не менее, узнали
что-то полезное.
Увидели новые направления и так далее.
То есть нам-то интересно
не сколько Фристона, а вот все,
что вокруг, все те проблемы,
которые он задевает.
Разговор, обоим его продолжать.
А мы, в общем,
не очень ожидаем, а потрачим.
Нет, замечательно.
Спасибо большое.
Обоим докладчиком.
На какое-то время уходим в сторону
от деталей.
Ничего, нормально.
В любой момент можем вернуться.
У меня уже есть рассказы.
Замечательно.
Нет, ну сначала
в следующем басе на оружие есть.
Прекрасно.
Спасибо.
Спасибо вам большое.
Большое дело.
Теперь вы не уходите пока.
Дмитрий, надо решить.
Дима, ты слышишь?
Да.
Подожди, вы слышите.
