The purpose of science is to examine data in order to improve our certainty of the world.
Bayesian belief update is a mechanism for achieving this. Next slide.
The prior probability tells us what we believe before we see the data.
Here we see an uncertain quantity, capital X, and the event that it takes on a particular value, little x.
We then ask what's the probability that the uncertain quantity assumes the value, little x.
By doing this for all possible values of that random variable or uncertain quantity,
we obtain a probability distribution in advance of having seen the data.
Next slide.
The likelihood function tells us how to work with the data.
It explains how well each hypothesis can explain the data.
Here on the right side of the conditional probability, we see a hypothesis that capital X takes on the value, little x.
And the data from our experiment is on the left side of the conditional.
With the data fixed on the left side of the conditional, we consider every possible event that could have occurred,
and we go through them and the likelihood tells us which explanations of the data are more probable than others.
Next slide.
The posterior probability is what we now believe after we've seen the data.
So the probability of each explanation that the random quantity X takes on the value, little x,
now has a new probability after we've seen the data.
This is the posterior probability, which is really what we want to know by having examined data
and changed our beliefs about the state of the world.
Next slide.
Bayes' theorem puts this all together for us.
The Reverend Bayes published a major paper posthumously in 1763 that tells us how we can find the probability of causes by examining effects.
Before this, as was known to the Greeks in ancient times, one could examine effects from causes,
but to go back the other way was a bit more complex.
What Bayes' theorem says is that our belief in a hypothesis after having seen data from an experiment
is proportional to how well that hypothesis explains the data, the likelihood, times our initial belief, the prior.
Now, in order to use Bayes' theorem, all hypotheses must be considered.
To do this properly, we need computers.
As I show in the top right, there's a complex network of beliefs that could involve hundreds, thousands, or millions of interacting variables,
and using modern statistical computation along with Bayes' theorem for representing our probabilities.
For the past 20 years, scientists have been able to solve thousands of different problems using this Bayesian probabilistic approach.
Next slide.
Here we see a mathematical expression of Bayesian update.
The posterior probability is proportional to the likelihood function times the prior probability.
Next slide.
In order to turn that proportionality into an actual number, into a probability distribution where those probabilities all adapt to one,
it's necessary to consider all possibilities and have a normalizing constant in the denominator.
That normalizing constant is nothing more than all the possible numerators added up.
That's what guarantees that considering everything will sum to one in probability.
Next slide.
Bayes' original example of parameter update had to do with simple events like tossing coins.
Suppose you had a coin, and your question was, what is the probability that that coin comes up heads?
To what extent is it a fair coin?
This is different than asking what would happen if I knew it was 50%.
Instead, it's asking, what is the underlying probability of that coin?
To do this, he began with a prior probability in his paper.
It was uniform, but it can be any prior probability.
And to express our belief about the probability of values between zero and one, a beta distribution is used.
We'll see this again later to represent mixture weights, where there's a number between zero and one.
On the next slide, we see the likelihood.
Suppose a coin is tossed n times, and k of the times, it comes up heads.
Well, that is represented in probability as a likelihood that's a binomial distribution.
Assuming we know what the probability of heads are, and how many times we've tossed the coin,
n, we can immediately deduce what the probability of observing k heads would be, k successes in n trials.
The third line is the posterior distribution.
It tells us what the probability of the event, of a particular value of the coin being 43% or 50% or 72%,
would be having seen the data of k heads occurring in n coin tosses.
The result of multiplying the likelihood times the prior is, again, as we see in the last line,
a beta distribution, which is reflecting our belief in what that parameter would be for the posterior value,
as a number between zero and one.
Next slide.
Let's take a look at what these priors, likelihoods, and posteriors look like visually to get some familiarity with them.
Here we see a beta distribution on the x-axis.
The parameter is some number between zero and one, which are the possible values for a beta variable.
And what we see is that all possible variables have equal probability.
It's a uniform distribution.
This is the sort of prior you might consider when you look at a variable like mixture weight,
when you don't know what the mixing proportion as a number between zero and one would be.
Next slide.
Here's a different prior.
Suppose we believe that the coin is not fair.
Maybe we believe that the probability of heads is around one-third,
but we don't know exactly to what extent it would be one-third.
It could be a tenth.
It could be 80%, but our belief is maybe it's around one-third.
Next slide.
Here's a strong prior value.
What if we believe that the coin is pretty much definite to be a coin that has a probability of one-quarter of coming up heads?
It's very biased.
We don't really believe it's likely that it's even 50-50 or certainly anything higher.
So those were examples of three different prior beliefs.
Uniform, a weak prior, a strong prior.
Next slide.
So let's take a look at the impact of observing data on our priors and to what extent that updates our beliefs.
Here is an experiment where we tossed a coin twice and heads came up one out of those two times.
What's the likelihood that the coin had a probability of heads of a quarter, a half, 75%?
Here it is.
It's a binomial likelihood and it's very broad.
It can accept almost any possibility, a little tendency towards 50%, but it's symmetric.
It's not leaning in any direction because with just two experiments, we really don't know.
Next slide.
However, if we tossed that coin ten times and observed seven heads, seven counts and ten trials,
then the likelihood as a relative number across all possibilities of what that probability of heads would be in the coin
is now heading towards a number more than 50%.
It's not completely definite, but there's far more evidence that that number is more than half than that it's less than half.
Next slide.
Now suppose we gather even more data.
We do 100 coin tosses and observe 65 heads.
So with 65 counts in 100 trials, the data from this likelihood function are now starting to focus the parameter around that number of 65%.
The data are strongly suggesting a particular parameter value in a much narrower band of certainty than we had before,
which is what we expect experimental data to do for us.
Next slide.
Let's go through an example now where we start off with a prior belief, and we update it with data,
and we look at what the posterior belief would be expressed as a probability distribution.
Suppose that our initial belief is a weak prior, that the coin head probability is around one-third.
Next slide.
Now we flip the coin twice.
We observe one count in two trials, and in green we see the effect of the likelihood.
To combine this, we now need to multiply these two curves together and renormalize.
Next slide.
And we obtain our final belief, the posterior probability.
And what we observe is that two experiments moved our beliefs somewhat away from having it centered at one-third, but not that much.
In order to get a stronger belief, we need more data.
Next slide.
We'll start with the same prior probability as a weak initial belief that the coin has a probability of one-third of coming up heads.
Next slide.
But now we flip the coin ten times, and we observe seven heads.
In green, we see the likelihood.
And what the likelihood has done is it's now gravitating a bit more to the right, centered somewhat around 70%.
It's still diffuse, but that likelihood now has more power to overcome the weak prior.
Next slide.
Using Bayes' theorem, we multiply the prior in brown times the likelihood in green and renormalize, and we obtain a new probability distribution.
This probability distribution is now beginning to gravitate toward where the data are indicating the true probability of this coin might be.
Next slide.
We'll do this one last time.
We begin with a weak prior probability of one-third as before.
Next slide.
But now we toss the coin a hundred times.
We observe 65 counts of heads in those hundred trials.
Now we have a strong likelihood, shown in green, that's far more concentrated, around 65%, with not much possibility of very low numbers or very high numbers.
Next slide.
With Bayes' theorem, we multiply the brown prior times the green likelihood to obtain the blue strong posterior probability distribution that is now largely dictated by the experimental data, the likelihood function that was shown in green,
that overwhelms the weak prior and brings us to our state of knowledge about the coin.
Next slide.
Having examined an example of continuous probability, like mixture weight, a number between zero and one, let's move on and look at an example of a discrete random variable, one that has a certain countable number of values.
An example might be the genotype, where there are a certain number of allele pairs.
Here, we'll take a look at the classic example of disease prevalence.
There's a very rare disease, maybe it occurs in one in a thousand people, and somebody gets a positive medical test result.
We want to know what is the chance of having this rare disease?
Well, based on the disease prevalence, we see our prior beliefs, our prior probabilities.
The probability that we're free of the disease is 99.9%, and the probability that we have got the disease is 0.1%.
Those two numbers add up to one, or 100%, covering all possibilities.
Next slide.
A medical test is an observation of data.
Therefore, it's a likelihood.
It comes into the likelihood function, and the data can either be a positive test result or a negative test result.
Let's look in the blue column, which called free of disease.
A positive test would give a false positive.
The individual is free of disease, but the test is coming up incorrectly.
What's the likelihood of observing the data of a positive test, given the hypothesis that we want to be learning about the person being free of disease?
Well, the false positive rate for this test, say, is 5%, 5 in 100 people, and so that is expressing the likelihood.
What about a negative test?
If a person is free of the disease, if there's a 5% chance of a false positive, then the probability of a negative test, given that they're free of disease, is 100% minus 5%, or 95% of observing a true negative.
In the red column of people who actually have the disease, again, there can be a positive test result, or the data can indicate a negative test result.
With a true positive, we see that the probability of observing that data, given the hypothesis that the person has got the disease, is 99%.
That's because, on the next line, the false negative rate of the test, the probability of observing a negative data test result, conditioned on a person actually having got the disease, is only 1 in 100, or 1%.
So our false positive rate and our false negative rate determine the conditional probabilities that are the likelihoods, the probability of observing particular data outcomes under varying hypotheses.
Next slide.
Using Bayes' theorem, we can now work out the probability of a disease.
We ask, with a positive test result, what is the probability of a person having got the disease?
So on the left side, we see the probability of a person having got the disease, the hypothesis of interest, given the data, a positive test result.
By Bayes' theorem, this is equal to the likelihood times the prior appropriately renormalized by all possibilities.
There we see the probability of a positive result having got the disease, as a hypothesis, is the likelihood, times the probability that a person has got the disease as a prior.
We divide that by all possible positive outcomes, and on the denominator, we see the same expression as in the numerator, when a person has the disease, and we add to that the likelihood times the prior when a person is free of the disease.
On the next line, we put in those numbers the likelihood of 99% times the prior of 0.1%, and divide by all of the possibilities that could have led to a positive result.
The condition that someone has got the disease, which we see as the first term, plus the 5% times 99.9%, that someone is free of the disease, and we observed a positive outcome.
Doing the math, that turns out to be 0.1% divided by 0.1% plus 5%.
In this case, the 5% is a very large number compared to the 0.1%.
It's there because the prior belief or prior knowledge about this disease is that it's very rare, and therefore the probability that someone is free of the disease is 99.9%,
which overwhelms much else of the probability values that we see.
Dividing 0.1% by around 5% gives 1 over 50 for a posterior probability of having the disease seeing a positive test result of only 2%.
The negative and false positive rates may have been 95%, 99% in terms of what our belief was going to be, and through the likelihood, however, the posterior probability is just 2% because of the rarity of the disease.
Next slide.
Let's look at this visually.
Here's the prior belief that we have a 99.9% probability of being disease free, and on the left, outcome number one of having got the disease is very small at only 0.1%.
Next slide.
Now we introduce the likelihood shown in green again.
For a positive test, there's a 99% true result shown on the bar graph on the left next to the first outcome, 99% true positive result, and on the right, we see a 5% false positive result that we would have obtained this test result.
Next slide.
Using Bayes' theorem, we multiply the likelihood in brown times the prior in green to obtain the posterior distribution in blue, which is then renormalized by all the events to give a true probability distribution.
And what we see is that there's a 2% chance that we have the disease and a 98% chance that we're disease free.
Next slide.
The odds of the disease is often a clearer way of seeing what's happening.
Odds can be used whenever there are only two states.
For example, having the disease got versus the alternative, not having the disease or being free.
Then we can express the odds as the probability of one event divided by the probability of its only alternative, the other event.
So we can ask, with a positive test, what are the odds of having the disease?
Well, the posterior odds are seen here as the probability of having got the disease given a positive test divided by the probability of being free of the disease given a positive test.
We can expand that with Bayes' theorem into a likelihood in prior, as we see at the top right expression, the probability of a positive test given that someone has got the disease, that's the likelihood, times the prior that they have got the disease.
In the denominator, we see the alternative condition with its likelihood and prior.
Going to the next line outlined in red, we have a term that depends only on the data.
Those are ratios of likelihoods, the probability of the test data, the positive outcome, in the numerator, conditioned on someone having the disease, and in the denominator, they're being free of it.
To the right of that is our prior belief, separated out.
The separation of likelihood on the left and prior on the right is an expression of Bayes' theorem, this time in the odds form.
On the next line, we see that we divide those likelihoods, we have 99% over 5%, which is 20, and the prior belief is 0.1% divided by 99.9%, which is 1 in a thousand.
That number of 20 is the likelihood ratio.
It's the probability of observing the data under two different hypotheses.
In one case, someone having got the disease, and in the alternative, they're being free of the disease.
The likelihood ratio, when multiplied by the prior odds, gives us the posterior odds.
Here, the prior odds are 1 in a thousand that somebody has got the disease.
That multiplication of the likelihood of 20 times the prior of 1 in a thousand gives us the posterior odds of 1 in 50 or 2%.
What this likelihood ratio illustrates is that the power of this test is only on the order of 20 to discriminate if you get a positive result.
The prior is on the order of a thousand, so even though there's a positive test result, when you consider the likelihood ratio for a positive outcome, you can only multiply your prior of 1 in a thousand by 20,
and so that update is not bringing you to anything near certainty, it's only bringing you to around 2%.
Next slide.
What the likelihood ratio does for us is that it appropriately focuses us on what the data results are.
The data results in this case were a positive test.
Everything that goes on from that point on must be conditioned.
All inferences, how we update our beliefs, must be conditioned on that positive test result.
The negative test is entirely irrelevant.
It's not what we observed in the data and therefore must be ignored.
What's left are the two hypotheses.
That a person is free of the disease or that they have got the disease.
In blue, we see that the likelihood of someone having a positive test result when they're free of the disease is the false positive rate of 5%.
The alternative hypothesis that they have got the disease expresses the likelihood of a true positive,
the probability of the observed data given the hypothesis that they've got the disease, which is 99%.
And it's the ratio of these two that 99% over 5% that expresses how informative the test is for this medical condition.
Thank you.
