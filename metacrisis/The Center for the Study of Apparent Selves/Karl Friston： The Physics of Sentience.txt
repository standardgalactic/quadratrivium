All right, so welcome everybody to the second day of this amazing meeting.
We are extremely fortunate to have two great speakers again this morning.
We're going to start with Carl Friston.
Probably doesn't need an introduction, but he's a neuroscientist in London, and also
the most cited neuroscientist, I believe, of all time.
I think that's still correct.
So just some some amazing work that we're extremely excited about.
So please, Carl, share your screen.
Go for it.
That's a great pleasure to be able to talk to you.
Thank you very much for inviting me.
And I'm going to basically tell the same story that Neil and Kevin told yesterday,
but using the language of physics in the first half and neuroscience in the second half.
And I should apologize for this because it's going to be my basic talk or starting from
first principles.
My hope is that many of the ideas that I heard you discussing yesterday are fully licensed
and endorsed by this rather elemental or basic approach as seen through the lens of a physicist.
Furthermore, the reason that I and my colleagues committed this kind of explanation is if you
understand the underlying mechanics and the physics of what's going on, it allows you
to simulate things.
So I'm justifying some of the technical details in this talk on the basis that if you can
actually write down the kinds of processes and phenomena of interest, then you're now
in a position to simulate and provide proof of approval.
My hope is that at some point, the agenda, the fascinating and challenging agenda that
your group is applying itself to may succumb to this kind of modeling and proof of principle.
But I think that's going to be for you to decide.
So this talk is going to be breathless because I have to complete it within 45 minutes.
And we're going to cover the statistics of life with a special focus on Markov blankets
and how they induce an interpretation of self-organization in terms of inference and a
very basal kind of belief updating, namely Bayesian belief updating.
And then we're going to move on to a rehearsal of exactly the same story, but from the point
of view of neurobiology in terms of predictive coding and how they play out on neuronal networks.
And then if we have time, I want to just speak to the core notion of selfhood and argue that
that may be intimately related to agency and then ask, well, where does agency emerge from
the formulation that I will have established in the first two bits of the talk.
So I'm going to start with a question posed by Schrodinger.
How can events in space and time, which take place within the spatial boundary of a living
organism, be accounted for by physics and chemistry? Clearly, I'm not going to address
that question, but what I want to do is just pick out this notion of a spatial boundary
and note that in order to talk about anything, a particle or a person or a priest,
you have to be able to distinguish or separate or individuate that thing from everything else
in virtue of it possessing a boundary. And Schrodinger would be the first to acknowledge
that that boundary is in itself a statistical object. And I'm going to read that boundary
as something called a Markov blanket. So for those of you who don't know what a Markov blanket is,
imagine some little universe. And these are the states of the universe. And these states influence
each other. And these influences are denoted by these areas or edges. And imagine we take some
states, say my states, my internal states, the Markov blanket is effectively a set of states
that constitute the or constituted by the parents, the children, and the parents of the children,
as defined by this causal coupling. And in brief, the role that the Markov blanket plays
is that it provides all the information that I would need about the universe
to predict how I am going to change or evolve next. Technically, conditioned upon these states
here, the blanket states here, the internal states are conditionally independent of the external
states. And I'm going to make a further move here. I'm going to divide these blanket states
into sensory states and active states, where the sensory states influence but are not influenced
by the internal states, active states influence but are not influenced by the external states.
And I motivate this particular partition in a moment. I use the word particular partition
deliberately, because in effect, we've just described a particle or something more generally,
with particular states that constitute or constituted by the blanket states,
known as sensory and active states, and the internal states. And this partition universal,
in the sense you can see it wherever you look. So here are two of our favorite things.
At the top, there's a brain and the bottom, a single cell. We can imagine the internal states,
the brain, everything I need to write down to identify the current state of my brain,
its activity, its connectivity, the internal states, the brain will influence my autonomic
system, my active states, my actuators, which in turn change the external states,
that then couple back to the sensory states, my sensory epithelia,
that then influence my internal states. And so the cycle continues. And exactly the same
partition or sparse coupling can be found, say, in a single cell with intracellular states
constituting the internal states, but influence, say, the active filaments that support the cell
surface, that is pushed into the external states and the external milieu reciprocates by
changing, say, cell surface receptors that change the intracellular states. And again,
establishing this circular causality that I read in terms of an action perception cycle
in relation to the brain. So that's the basic setup. What I want to do now is to do a very
brief course in physics and then ask what would happen if we put the Markov blanket back into
play. So I want to start with the basics of nearly all physics that we know, articulated here
classically as a Laungevan equation or a stochastic differential equation. I use the
description stochastic deliberately because yesterday I noticed in the chat, Dennis was
was asking about fluctuations, random fluctuations, a kind of itinerance
that is characteristic of biotic self-organization. And those fluctuations are central to this
argument that are denoted by omega here. And all we're doing here is just writing down a universe
in which the rate of change of any states of this universe is determined by some flow,
which is a function of where I am, plus these itinerant or random fluctuations. And I've just
sketched out two states here. So this could be an oscillation in one cell of my brain.
It could be my heartbeat or it could be me getting up in the morning, doing my emails,
having lunch, watching television and so on. At any temporal scale, the kind of systems that we
are interested in show this characteristic property that they have characteristic states,
which they keep on revisiting. You can describe this in terms of in random dynamical systems,
a pullback attractor. You can articulate this in terms of physics, in terms of non-equilibrium
steady state. The key thing is to be something is to have characteristic states that I return to
or at least the neighborhood of. And thought of like that, we can now read this object as the
probability that you'll find me in any particular state if you sample me at any random time.
And that's important. It's important because we know a lot about the maths of the relationship
between the dynamics, the flow, the amplitude of the random fluctuations and this description of
the state system in terms of its characteristic states or its pullback attractor. Don't worry
about the equations, I'll just pick out what we need to know. This is a very generic equation
known as the master equation in some contexts, the Schrodinger wave equation or the Fokker-Planck
equation, most simply just a description of how this probability density changes with time
as a function of the amplitude of the random fluctuations, gamma, and the flows here.
But we just said it doesn't change with time because I exist. So to use Kevin's notion of
persistence, I persist in time. So we know this probability density doesn't change in time.
Which affords this solution here, known as the Helmholtz decomposition.
May sound very arbitrary, but this is absolutely fundamental and I repeat underwrites most of
physics that we know from Pascal to quantum. The key thing I want to look at though is that it
describes what's known as a gradient flow on the log of this probability. In other words,
in order to counter the random fluctuations, I have to be flowing towards my characteristic states
in order to stop the probability density changing. And that's the key behaviour
that I want to pursue for the rest of the talk. So at this point, let's put the Markov-Planck
back in play and write down that gradient flow in terms of the amplitude of the random fluctuations,
these things denote circular or solenoidal flows that give this kind of itinerancy and life cycles
and oscillations. And what the Markov-Planck tells you is that it is subject to the same law
and it means that the internal states and the active states will look as if
they're trying to increase the log probability of, in this instance, the sensory part of the
Markov-Planckid. And I'm going to interpret that in terms of perception and action respectively
and just ask the question, how would I then interpret this quantity here? Well, we've just
said that the states that I'm most likely to occupy are those that are characteristic of me,
they are literally the states that constitute my attracting set to which I am attracting.
So they are valuable for me, they have meaning for me denoted by M here. So one could read this
log probability just as value, and one could spin off reinforcement learning if you're an
engineer, optimal control theory, if you're an economist, expected utility theory,
if you're a free energy theorist, the negative variational free energy is just a way of writing
down this valued function. If I just multiply this by minus one, we have a complementary
perspective that people in information theory will recognize. So this is now known as this
negative log probability that I'm now looking as if I'm trying to minimize is known as self
information, information theory, or more simply, surprise or surprise. It's just a measure of
the implausibility that I would sense this given I am me. And this is the quantity that is bounded
by the free energy leading to things like the informats principle, the principle of minimum
redundancy, and indeed the free energy principle. This is nice because the average of this thing
is known as entropy. So the expected free energy or self information is entropy. So it'll look as
if I'm trying to resist the second law by minimizing the dispersion or the entropy of my sensed states.
And of course, that's the holy grail of self organization and physics and synergetics of the
kind described by Herman Haken. And indeed, if I was a physiologist, it would just be a statement
of homeostasis. And I have to exist, I just have to keep my sensed physiological states within some
viable bounds that are existentially consistent and have meaning for me, because they are
characteristic states that I occupy. The final interpretation, which is the one I want to pursue,
is that which will be given by a statistician. A statistician would read this not as the
probability of some states given me, but me as a model of how my states were generated.
This is known as model evidence, also known as the marginal likelihood having marginalized out
all the external states that cause my sensations, and therefore perception and action will look as if
we have it is trying to accumulate or increase model evidence. And then we can read off things
like the Bayesian brain evidence accumulation and indeed predictive coding. So I just want to
illustrate now and try and demystify that last interpretation with a worked example,
just to work towards something which I think may be very, which may be a useful mathematical image
of a system that is sort of self caring. And I'll motivate this using the simulation in the
following way. What we've done here is simulate a lot of little macromolecules with strong repulsion
and weak electrochemical attraction. And their very existence in some metric space means that
their coupling is sparse and that each molecule cannot see molecules a long way away. So because
we've written down the dynamics here, we know the coupling, we can go into this synthetic soup
and identify some internal states on their Markov blanket. In essence, what we're doing is
we're asking the question, is there a little particle or thing living in this soup that is
identifiable as something in virtue of the fact that it has a Markov blanket? And indeed there is
in this synthetic soup. Here the internal states are coded in blue, surrounded by the active states,
say the active filaments, if this was a little viral cell like structure, that underlie the
sensory of the surface states that protrude into the external states in cyan here. So now we have
a simulation in silico little thing living non equilibrium steady state that we've identified
because it's got its Markov blanket. The question is, what does it mean for it to be self evidencing
in the sense that it has to on average increase its Bayesian model evidence or the evidence for
its models of what's causing its sensory inputs. The answer is subtle, simple, and I think very
interesting. Simply because of this conditional independence that exists between the internal
states and the external states, it means for any given internal state, there must exist a probability
distribution over the external states, given the sensory states or the blanket states more
generally. So what that means is there's a lawful relationship, a manifold or a function
relating my internal states to the probability distribution over my external states. And if
I read that conditional distribution as a Bayesian belief, what that means is these internal states
in some sense hold or represent beliefs about the external states. We can actually go in and
just look at the nature of these beliefs. And what I've done here is articulate them in terms of
something called a synchronization manifold, where all I've done is just plot the some mixture of
internal states along the x-axis and the probability distribution or beliefs about the
external states and the actual external states in terms of their mean on the y-axis to show this
synchronization manifold here, this lawful mapping that just has to exist because there is this mark
off blanket, the separation between the thing and everything else. And in this example, what we're
doing is asking the question, can we numerically demonstrate that the internal states hold Bayesian
beliefs about the fluctuations and the flow of patterns in the external states? And indeed they
do. Here are the estimated or the beliefs that are held, Bayesian beliefs that are held by the
internal states and the actual external states show that they lie within the 90% Bayesian credible
intervals. And these look very much like what you'd see in electrocosiology if you just look
at fluctuations of the internal states in response to certain events in the external states when
these molecules leave their little soup and they're pulled back in again here. The point I want to
make with this demonstration is not only that there always exists an interpretation of self-organized
or self-evidencing systems endowed with a mark off blanket in terms of elite or having a process
that looks as if they are tracking the states of the world generating their sensations. But more
generally, this is just a description which I'm sure a lot of you will be very familiar with
of self-organization that can be described in terms of generalized synchrony or synchronization of
chaos. Exactly the thought first noted by Huygens in terms of clocks that are suspended from the
same beam or wall will ultimately come to synchronize and oscillate in tandem in a synchronous
fashion. That's all that's happening here and indeed this little drawing by Huygens illustrates
that from the perspective of the particular partition into internal active sensory and external
states where the blanket states constitute the beam that's coupling the two penduli here. So from
our point of view all we're seeing here is an inside out to use Anil's phrase view of a completely
symmetrical synchronization of chaos or generalized synchrony between two sets of states. I've never
said this before but what I will say to you I was just wondering whether now if we replace the external
states with something else like me we now have a mathematical image of the synchrony between
that characterizes a dynamic interaction between two people and you can imagine that's being
many people on many cells an ensemble of similar kinds of things that are constituted
in their either Markov blankets but have some isomorphism in their form will in minimizing
their joint free energy necessarily show this kind of generalized synchrony in this harmony
that can always be read as one particle or person holding the right kind of beliefs about
another kind of person having a mutual understanding and implicitly a mutual predictability a shared
narrative in the sense that all of this can be described in terms of increasing the evidence
for my models my narrative my explanation of what's causing my sensations and of course 99% of the
time it is you that is causing my sensation and vice versa. So that's the physics part just to
briefly summarize that the existence of a particle implies a partition of systemic states as states
of any given system into internal blanket namely sensory and active and external states that are
hidden behind the Markov blanket from the point of view of the internal states and because active
states change but are not changed by external states they reduce or on average look as if they
are reducing the entropy of blanket states and effectively this means that action the active
states will appear to maintain the structural and functional integrity of the blanket a very
simple form or basal form of self-assembly and one could argue a very simple form of water peresis.
Internal states appear to infer the hidden causes of sensory states by increasing Bayesian model
evidence and actively influence those causes and in my world we refer to that as active influence
just to highlight the crucial role of actively engaging and establishing and selecting the
right kind of data that is necessary to establish this kind of shared dynamic or synchronization.
I'm going to end now by rehearsing exactly the same story but using language much more akin to what
the first half of Kevin's talk and the second half of Anil's talk yesterday. So this is the
perspective that a psychologist or a neurobiologist might bring to the table on exactly the same
phenomena and this usually starts with the notion of the brain as a fantastic organ
generating fantasies or hypotheses explanations on the inside that then are put to sensory impressions
to see whether they are apt to explain what's going on and if they match that's fine if they
don't then you get some kind of Bayesian belief updating. I find this very nicely demonstrated
by this 16th century oil painter fame for doing still lives that when viewed from a different
direction and give you a very different impression oops I got them the wrong way around so you're
meant to see the bowl of fruit first and then after that the face and if you do see a face now
the point being made here is that you made that face and it's something that you had on the inside
in your internal states that is a good explanation for the sensory impressions on your retina
or your epithelia and then this notion you can find throughout history and philosophy I'm not a
scholar but I find beautifully summarized by Helmholtz for example objects are always imagined
as being present in the field of vision as I have to be there in order to produce the same
impression on the nervous mechanism so again what he's saying is it has to be on the inside before
you can explain that sensory impression almost exactly the same ideas from people like Richard
Gregory the notion of perception as hypothesis testing ideas used to great effect by people
like Jeffrey Hinton and Peter Diane in machine learning who indeed built a Helmholtz machine
based upon the work of the Bayesian inference and the work of people like Richard Feynman
articulating that mathematically in terms of this minimization of free energy so from our
point of view though let's just come back to this notion of impressions on the nervous mechanism or
sensory impressions on our Markov blanket the sensory part of our Markov blanket so I've
cartooned that here in terms of some sensory shadows and our sensory veil and if this dynamics
if this Bayesian mechanics induced by Markov blanket is true then what that means is I will
look as if I am trying to find expressions for this sensory impression what caused this particular
shadow so what would that look like well we know exactly what it would look like it has to be written
down in this form from the physics so my internal states change in a way that look as if they are
trying to minimize this free energy form of this surprise or self-information here and it transpires
that the functional form of this can be universally interpreted as a prediction error so what does
that mean it means my internal states say my neural activity is changing as a function of my
current neural activity plus a prediction error and if you were an engineer you'd recognize these
as the equations behind predictive coding or Kalman filtering usually separated into a prediction
what I predict the world will do given its currents my expectations about its current state
and then an update that is informed by the sensory data that I sampled so what's this
free energy gradient here this prediction error well imagine that I had this sensory impression
here and I had an expectation a Bayesian belief that it was caused by a dog and if I had a
generative model that could generate what I would see if I was correct I can then
generate the prediction and compare it to the sensation to form a prediction error which is
simply the difference and all this fundamental gradient flow is saying this predictive coding
or Kalman filtering equation is saying is I'm going to change my mind in the sense of changing my
internal states in my neuronal states until the prediction error has been eliminated and I've
minimized my free energy and the gradients have been destroyed so is that plausible in fact it's
very plausible it speaks to a picture which we'll see in a second where we want to look at
I think both Kevin and Anil showed sort of cartoons of this one can look at
the brain as a hierarchical generative model generating predictions
evaluating the quality of those predictions by evaluating a prediction error the free energy
gradients and then revising beliefs doing Bayesian belief updating on the basis of the mismatch now
notice at no point well I ever know what's going on out there all I'm doing is finding a sufficiently
good explanation in terms of that which minimizes my prediction errors in this instance it was
actually a cat and but that's nice because what it means is to forget about all the physics and
just summarize the existential imperative that inherits from the physics in terms of minimizing
prediction error and there are two ways to do that we can either change our minds to make our
predictions more like sensations or we can act on the world to solicit some more sensations
that are closer to our predictions so we can just realize our predictions actively by changing
the configuration of our body for example or in our internal state we talk about interceptive
inference and autonomic reflexes or we can engage motor reflexes or I can look somewhere else until
I see what I expect to see and thereby minimizing my prediction errors I won't go through this this
is what I would take people through if they did neuroscience in terms of the hierarchical
organization this kind of scheme the basic message behind this architecture is that say for example
visual input comes in it's a receipt of top-down predictions from the visual part of the brain
it elaborates a prediction error that's then sent forward to revise my beliefs to provide
better elemental descriptions but crucially these expectations are themselves being predicted in
a hierarchical sense with these top-down descending predictions to produce a prediction error that
then drives the high level expectations more abstract representations to provide an account
of what's going on below this is exactly what Kevin was talking about yesterday in terms of
this layer or level of the hierarchy looking at informing and being informed by the level below
and so on to any hierarchal depth required the particular twist in this graphic though is that
it incorporates action so here there's another kind of prediction error that comes from the
muscles in my eye that I could predict and I could use a prediction error to infer where
my eye was currently pointing but there's a much simpler way that I can minimize these prediction
errors I can just change the stretch of my muscle to match the predictions of the stretch receptors
and what I'm describing here is a classical reflex arc in motor control if I was doing
interceptive inference this would be an autonomic reflex basically actively and reflexively
minimizing prediction errors in relation to deeply hierarchically informed predictions
that are generated by my model that I'm trying to maximize the evidence for
and so that's the basic story I just want to finish the story with saying well actually
not quite before I do that let me just illustrate the kind of active inference and the kind of
sort of engagement with the world and one way of establishing a very simple synchrony with the world
that inherits from the architecture I've just shown you and what we did here is basically
equip a synthetic subject with a generative model that had dynamics autonomy and this kind of
itinerancy that was implicitly referred to yesterday in the form of a central pattern
generator and then map this abstract dynamic to some point in extra personal space and we told
the synthetic subject or part of its generative model was that there was an invisible point that
was moving around and there was an invisible spring that was pulling her finger towards the
moving point so that means that this synthetic subject is now expecting to predicting to feel
her hand being moved around and see her hand being moved around but because she also has reflexes
then she's going to automatically fulfill the addictions of the hand movements and cause the
hand to move thereby fulfilling the visual predictions and with this very simple kind of
reflexive setup we can simulate quite realistic biological kinds of motion and also by simply
removing the proprioceptive or the movement sensing information we can simulate not just action
but what it would be like to observe something very similar performing the same action but
just visually without the proprioceptive input so that kind of simulation rests upon this sort of
overall architecture that we get some sensations and that they are used to do our basic belief
updating by minimizing this variation of free energy or what to do next and those predictions
are then used to generate action and this rests on the the markoff banquet that I showed right
at the beginning of the presentation what I'm going to do now is make one very very simple move
and take this sparse coupling that defines this thing from everything else make it slightly
sparser in a very simple but very important way I'm going to remove the influence of my active
states on my internal states and as soon as I do that then from the point of view of the internal
states my active states now become vicarious causes of my sensory states which means that
there now exists an interpretation of my internal state as modeling not just the external states
as causing or using a model of the external states to predict the sensory states but the
external states and the active states now become causes of my sensations so now I have a model
of the causes of my sensations that include my own actions and it's this particular move
that I'm suggesting or from the point of view of simulating these kinds of this kind of self
organization may be a necessary move to introduce agency in the sense that agents will have some
notion some or at least can be described as having some sense of their own agency the
consequences of their own action because the their own action is now not directly accessible
it can only be observed by the sensory consequences that therefore have to be modeled
and this takes us into a slightly different and I think richer world where you now have
the notion of a model that incorporates explicitly the consequences of the agent's action I'm not
saying at this stage there's any awareness or sentence of that agency but just it is there
that is then used to plan into the future to evaluate the different consequences of different
actions so that you are now implicitly introducing the notion of planning and the temporal depth
into the dynamics that then provide the predictions of what I'm actually going to do next I won't go
through this in any detail but just use it to make the point that the underlying maths is quite
simple and has a telonomy or at least an interpretation in terms of things that's
people's statistics machine learning and economics would recognize immediately in terms of things like
risk and ambiguity or accuracy and complexity and intrinsic and extrinsic value where it turns out
that all of these quantities that underwrite the planning that ensues from having to have a model
of the consequences of my action are well established in different kinds of literature so for example
the intrinsic value is just the quantity used in visual search known as Bayesian surprise
it's also exactly the same quantity underwrite something I mentioned earlier which is the principle
of maximum mutual information or the minimum redundancy principle and it is effectively
the thing that drives our curiosity it's the the thing that minimizes expected surprise by
maximizing information gain and I can sort of strip away various sources of uncertainty and
get back to expected utility but I really want to focus in the final slide on this epistemic
affordance that falls out and is a necessary consequence of just having a model of the consequences
of my actions in the future that I pete entail a degree of planning and if I'm say planning to
where am I going to look next I'm going to look to the I'm going to make the next eye movement
that resolves the greatest amount of uncertainty about the states of affairs out there because
that has the greatest intrinsic value it has the greatest intrinsic motivation it has the greatest
epistemic importance it is salient for me it has meaning for me in terms of what I don't know
in about the world beyond my sensorium and you cannot write this down with particular
examples and produce salience maps that do actually describe quite accurately the imperial
behavior of people choosing where to look next and indeed you can simulate this in terms of
a little agent this particular agent to a very simple universe she was either in universe that
where all her sensory input was being caused by an upright face a sideways face or an inverted
face and by carefully choosing where to look next noting that she could only sample a very small
part of the visual field with her fovea as indicated by these images here and this movie here
she can choose the best places to look to maximize this Bayesian surprise to maximize
or respond to these epistemic affordances and resolve her uncertainty what is she is looking at
and she's indeed correctly inferring she's looking at an upright face so all that can be much more
gracefully summarized by Helmholtz and as follows each element we make by which we alter the appearance
of objects should be thought of as an experiment designed to test whether we've understood correctly
the environment relations of the phenomena before us that is their existence in definite
spatial relations and with that it only remains for me to thank those people whose ideas I've
been talking about and of course to thank you for your attention thank you very much indeed
now it's on yeah thank you Carl amazing talk as always
I was wondering what does what does it look like or what what insights could we get from
um applying the this minimization of of uh well or this principle to let's say an intertwined
relationship between two entities um that would be sparsely or densely coupled
where you would have um one in one using the other as a tool in a positive way
uh perhaps or or neutral way or as a companion I'm sure yeah I'm sure you have applied that
but what does it tell us about selfhood um so yes indeed you know that has been applied
and it's something that I thought about you know not doing the the presentation that I've just done
and just jumping in exactly when you actually apply these principles to couple systems where
those two systems can be interpreted as two people so much of the sort of simulation work
that we've done has actually been based upon birth song um so building little birds who can actually
sing and hear each other and then bringing them closer until they can hear each other
and then evaluating the emergence of this generalized synchronization of chaos or synchrony
so that they start to recognize each other uh and engage in the same song it does involve some
turn taking but the basic insight from that kind of study is exactly as you'd say that um provided
two birds have this kind of symmetry and isomorphism so you and I share you know a common
generative model a shared narrative the same kind of language then it's very easy for us to suddenly
fall into this um this generalized synchrony which simply means that I can use my model of me
to make predictions about you and you likewise can use your model of you to make predictions about
me which means that now there is no model uh it's our model and we just share it by taking turns
in terms of singing and you know speaking and listening or in this instance singing and and
listening and you can just look at the emergence of this and ask the kinds of questions you know
from either a mathematical perspective um or from the point of view of um the temporal scheduling
of of the turn taking and the the emergence of this then what you do is just to speak to your second
question is you know well what what would happen if one bird was a baby bird and the other bird
was a very mature bird a teacher or a parent um who had very confident dynamics very very precise
dynamics in terms of the skilled performance of say a song or a language or uh articulating or
communicating certain beliefs um whereas the baby had a less mature model that was um imbued with
much less precision and more uncertainty and what tends to happen is that the the two birds sort of
converge on the same model just as they minimize their joint free energy put that more simply
as they minimize their mutual prediction errors as they become mutually more predictable of each
other um they they converge on the same generative model but if that one bird is much more precise
it'll pull the less precise the younger student bird towards it so that you do exactly get as
you were intimating this opportunity when you have this kind of asymmetry when there's a certain
wisdom at hand um for the wisdom which is basically precise knowledge that works and it's you know
an apt explanation for my world um to draw to it um less experienced um um uh less experienced
things or people or in this instance little birds um so they come to share again you know
share the same narrative um in terms of selfhood um like you know there is an answer which is
very anecdotal it's very common sensical um but um may or may not resonate with with your
perspective and you know if you didn't have this um dyadic and you know and generalize this to sort
of you know any cons specifics and sort of the notion of cultural niche construction for example
would you know would be one manifestation of this kind of um mechanics if you didn't have
those kinds of dyadic interactions and there was only one thing like me in the universe
then I would not need a sense of self in in in the following sense that um in order to do this um
dyadic interaction you have to um infer whose turn it is to talk or listen because you can't
talk and listen at the same time so although you may have the same generative model you still have
to infer whose turn it is to talk in order to do that you have to have a model of self versus other
but you only need that when you have to take turns so if I lived in a universe where I was the only
thing like me I probably wouldn't need a sense of self but as soon as you put me in a universe
where there are other things like me and I now have to resolve the uncertainty or test the hypothesis
did you do that do that or did I do that did I do that or did mum do that then I would need a sense
of self in order to to properly engage with and synchronize is that the kind of answer you were
looking for yeah that's that's amazing thank you uh you have more questions but I think people around
me also also have uh oh follow yeah okay so a follow-up to Olaf's question at the end of that
synchrony process is it possible then that the Markov blanket boundary would then shift so that
both agents were on the inside is it possible for that to for that to move or be flexible in some way
that's an excellent question uh yeah and sorry I should have pre-empted that question by saying
that um you know as soon as you start to think about dyads and triads and then ensembles you then
have a whole collection of Markov blankets so you sort of partition this system into lots of
little Markov blankets and they're all they're all sparsely coupled to each other but as soon as you
do that you've now got a sparse coupling between Markov blankets so now you have a Markov blanket
of Markov blankets and so on adding to an item so this notion of Markov blanket is scale free it's
not it's not tied to any particular level um so in answer to your question there would be no fusing
of the Markov blanket and that would um you know sort of um sorry I'm thinking about sort of uh I
saw Mark earlier on so he'll be smiling but I was thinking about some ego dissolution emerging of
of sort of ego boundaries that will happen mathematically no um you have to synchronize
across your Markov blankets but if there's enough of you doing it and there is an in-group then that
in-group will now itself have a Markov blanket that will be composed of those um
members of your in-group that separate you from the outside so say the institution this might be the
the receptionist or the the delivery person who is public facing facing the outside that the
internal members of that particular institution may never actually have to directly communicate
with so everything is conditioned upon the the interface you're a computer scientist this is
just the inputs and outputs basically hi um so great I I would love to get back to that point
because I think it's exactly on the sort of heart of what we're working on but if I could just back
up for a second um to Apophenia this idea of seeing patterns where none exist or our tendency to infer
patterns there are certainly accounts of those that are more structural um less reliant on this
idea of construction of a model for example and just the way we're physically built and I and I
think that extends obviously Paridolia Paridolia as well so I was interested to see that you used
faces sort of twice there and I wonder if that might end up being the kind of limit of practical
compute um to to sort of impose a model and again I think there are structural accounts for why we
have Paridolia but just sort of follow up on that and bring us back to where you were
I wonder if you're familiar with work like Andy Meltzoff's on the like me and how early
like me emerges in the psychology of very young humans again two two excellent questions um
so the first one um I think is actually quite fundamental it's probably just worth just you
know celebrating that question so um the the structure of the um the internal if you like
state space is seen as part of the model so the you're absolutely right that the kinds of things
that I can you know pseudo hallucinate hallucinose um um see um um are going to be fundamentally
constrained by the structure of my brain and the uh right through to the micro circuitry through to
sort of the other the visual hierarchy at a macroscopic level um and the all the dynamics
that are entailed so that structure has now been optimized in relation to variational free energy
in the following sense that it is basically um has been selected in the spirit of Bayesian model
selection which you can now read as you know a mathematical image of natural selection epigenetically
but also at a neurodevelopmental scale in terms of removing redundant parts of the model so this
kind of self-evidencing um fundamentally has to address and is manifest in terms of carving out the
right kinds of structures which as you were intimating that's fundamental constraints on the
kinds of things that I can perceive simply in virtue of having the right kind of structure
and just to link that to Anil's reference um um to the good regulator theorem this is very close
in spirit although I was devastated here that the good regulator theorem is no longer perceived
valid but um it's exactly the same cybernetic spirit that I have to have the right kind of
structure in order to synchronize with my world and this has to be probably learned at a much
slower timescale than the um the synaptic plus history that um um one would associate with
sensory learning and the the second I'm not familiar with that work at all no so so thank you
I am familiar with um sort of this the role in attachment theory um and the the importance of
things like affiliate attach and interceptive um inference in very very early developmental
not psychology but you know sort of perinatal kind of experiences um and um I would imagine that the
work you're referring to has something to say about things like you know different attachment
styles and the and the development of um your mother versus versus self am I am I correct or
perhaps you should just send me a link yeah the fellow's name is Andy Meltsov I'll be glad to
send it along thank you so much
Hi um is that aren't you hi Carl this is this is Kevin thanks very much for that talk um I have a
question that may be pretty broad um about the distinction in in just some of the phrase
phrase use of of having a model the system having a model which makes it sound like it's a resource
that the system has sort of somewhere in it that it can utilize versus the idea of it being a model
it just physically instantiating a model and it feels like there's a subtle distinction between
those two things and and there might even be a kind of a continuum where simple you know single
cell things just are a model of the world but eventually they may actually have a model that
is a distinct isolatable sort of resource right you've been talking to Max or Ramsted I can I can
see who what who worries about this a lot but that's absolutely right so if I said anything else
then I'm very sorry what what I should have been saying is you know at the level at which this
presentation was was posed which is about basically single cell organisms and and the like um that
you know it is a model you know it's a physical instantiation um of something that can be described
as a geratin model mathematically the geratin model is just a description of those attracting
states that I started off with the the characteristic states that I would experience that characterize
this particular phenotype or this this kind of thing um so you can't you you are exist you are
you are that model you don't possess a model in a sort of anthropomorphic sense but you
you're absolutely right also um I think when it comes to self-modeling um and um which I'm guessing
is where you where you're going when you suddenly um so now we're we're moving well beyond my
comfort zone and the kind of inference and belief updating that you know I was talking about um
but one can imagine that if my generative model now has um uh been obliged through a process of
maximizing model evidence at any temporal scale to have the hypothesis that it is me as opposed to
not be say mum or or other um or me in a different context or me in a different emotional state so
I've now um got some rather deep um um part of the model that now becomes a model of me the model
that that you're in being and I think you could you you would be licensed now to sort of refer to
that at least anecdotally as having a model of the model where I am the model and that leads to the
interesting notion that you know as soon as you've got a hypothesis a potential not per se perhaps
but perhaps concept um at hand to explain all your multimodal your interceptive your
ex receptive your proprioceptive and implicitly all those pro-social kinds of uh or cues that
are generated pro-socially all that evidence now can be explained in terms of well I am a person
or I am a body or I am a happy body or I'm a frightened body um then you've got now I think a
lot a lot of latitude to start to address some of the questions that were being addressed um
yesterday uh yesterday morning and in particular the kinds of questions that philosophers like
you know that you can now entertain well what would it like to be me if I didn't actually have any
sentience or I wasn't aware of being me what would it like to be a zombie because you have to have
that hypothesis that I am an agent um before you can entertain the null hypothesis or the
alternate hypothesis that it is possible to have um agency without having uh or is it possible to exist
which of course it probably is uh without a sense of agency is that what you were yes absolutely
know that that's great super interesting thanks thank you Carl this is Adam I have a question on
this temporal scale uh question how it ties into the discussion or the talk that we had yesterday
from Rinpoche so to take an example here suppose that you've got a caterpillar turning into a
butterfly or a stem cell turning into a muscle cell or any sort of kind of predictable biological
transition in which these different life stages have very unique state spaces that have almost
no correspondence to each other now we say that things persist if they persist they self evidence
but the idea of persistence particularly in the Buddhist tradition is a little tricky because
the idea is that nothing really persists there's just this illusion and that everything is constantly
undergoing change so you can use the caterpillar butterfly example as an extreme case but more
generally if you've got a continuous learning process then the generative model is never the
same moment to moment there's always some bit that's changing or often some bit that's changing
so my question would be in those situations if we just suppose that there is some continuously
continuous learning continuously changing model which is the model that is self evidencing
is it the model at this moment in time is it the average of the model over the lifetime is it
not really an appropriate question to ask because we have to assume that there is something that
persists how would you incorporate that into the framework again excellent question I think there are
two ways you would do this the first would be to say that the thinking of itself encompasses multiple
instances you know in terms of a sequence of metamorphoses or a species for example so you
come back to this notion of this a pullback attractor that you know I can't emphasize this enough
so we're not talking about the kind of fixed point attractors that characterize classical physics
we're talking about the the attractors that are characteristic of far from equilibrium systems
and usually biotic self-organization so they have an itinerancy they can still have very low
measure but they're very space occupying so you can imagine sort of a particular life cycle that
could indeed involve lots of metamorphic changes it doesn't have to you can just have a developmental
one as basically being one system where the persistence is not in the lifetime of any individual
but in the recurrences of this particular kind of form so that will be one way of doing it
if I was having if I had to simulate this though I'd actually use a much simpler device
which is a little bit like a sort of local linear approximation to to to any given curve
so I just chunk it into lots of little linear parts and say that for this little segment
you know for you know whilst I am a caterpillar for example or whilst I am at a particular growth
stage in my caterpillar life then at this particular stage this is the characteristic
states of being this particular kind of caterpillar that's my generative model and then once I've been
able to write down those characteristic states I could then simulate the development and the active
inference and the behavior of that particular caterpillar for the period of time that it was
that particular kind of caterpillar and then I have to change and then I have to write down
another generative model and simulate the next stage of the caterpillar's life and of course in
so doing you're introducing now another RRK level where which still has characteristic states you
know you're going from caterpillar to butterfly to caterpillar butterfly, caterpillar to butterfly,
caterpillar to butterfly but it's evolving you know if you like at a slower information rate
that's governing the transitions at the lower level so that it's a quite a complicated answer
it becomes very relevant when you want to try and model or simulate these things
you normally obliged to move to an explicit separation of temporal scales which is where
your question started to make sense of this kind of biotic self-organization that doesn't have any
unique scale and then you might ask well what kind of physics or maths is pertinent for that
the answer that I would give would be the renormalization group so you put very simply what
you're looking for is the same kind of laws that are evinced at every level but just at different
spatio-temporal scales as you move up the different levels and those laws are just the
the kind of self-organizing not organization that we were talking about the gradient flows
we're talking about thank you very much
