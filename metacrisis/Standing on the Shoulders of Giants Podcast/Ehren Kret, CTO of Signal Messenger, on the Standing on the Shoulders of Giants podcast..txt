Today on Standing on the Shoulders of Giants, we've got Aaron Carrette, the CTO of Signal.
Aaron and I worked together at AdMob, so I'm actually really, really excited to have him here on the podcast.
It's going to be awesome.
Good chat.
Huge fan of Signal as well, which we will definitely get into.
Aaron, give us a little bit more about your background.
I mean, you're not originally from Austin.
Not originally from Austin.
I'm originally from Texas, though.
I moved here, went to school here in Austin.
Then I moved out to the San Francisco Bay Area and worked for Google.
And then you and I met each other.
I left Google and joined a company called AdMob.
And that's where David and I first started working together.
And let's see.
Then from there, Google bought it.
So I kind of ended up back at Google.
Yeah, kind of knew that was coming.
Indeed.
Almost not, almost not, but it did.
Yeah.
And then I left Google to go to Facebook a few years after that.
Right.
I left Facebook, it did my own startup for about a year, then joined WhatsApp.
And then Facebook acquired WhatsApp.
So I ended up back at Facebook.
Yeah.
And about three years ago, I left WhatsApp to work on Signal.
Yeah, which is awesome.
You know, how?
I'm asking in the context of sort of this, you know, this Twitter stuff.
That's been happening lately.
But how exactly did you guys manage?
What was it?
Like almost a billion users.
Was it two billion?
It was a billion.
How did you guys manage that many users with what, 35 engineers?
I mean, the team, as I understand it, at acquisition and WhatsApp was notably small.
It was definitely small at the time, but it wasn't two billion users yet at the time either.
It was around about 300 million monthly active users at the acquisition time.
Okay.
And yes, the entire organization was about 55 people.
Of which probably a little bit more than half were engineering.
And the way that it was sort of managed, which was a small team is sort of through the leverage
you get from the app stores.
I mean, you can distribute an application to a lot of people that's written by a small
amount of people.
And also making sure that the applications we were developing, we could actually add features
to them and ship those features without having to maintain them with people.
And that was always one of the elements that you see a lot of companies fall into sort of
the trap of like a feature is shipped out and it functions partially.
But the way that you keep it working is by throwing people at the problem, essentially.
And at WhatsApp, there was always this focus on trying to minimize the cost of running the
application because it was such a small organization and the revenue model for WhatsApp
was never really figured out prior to the acquisition.
Right.
Right.
If I recall correctly, the app actually cost money at one point, but there wasn't a subscription.
It was just you had to pay for the app itself.
It was like 99 cents or a dollar or something of its nature, right?
And then and then eventually that even that got dropped, correct?
Yeah, that was only for iPhone.
And it was one point in time that that cost like a dollar to download the app.
That I don't remember exactly when that got dropped.
But yes, for a while, the application was just generally free.
And then we sort of experimented with a dollar a year revenue model in a number of countries.
So there were places that were actually paying a dollar per year per user.
And to be fair, that was Jan's pitch when I when I met with Jan to ask, you know,
you know, how do you actually plan to make money with this?
And he basically said, well, what if everyone in the world gave you a dollar?
And that was his business plan.
It was like, OK, I can see that that makes a lot of sense.
And like he managed to actually pretty close to pull that off
with two billion people using the product now.
Although these days, it doesn't charge anymore with Facebook acquisition
that sort of shifted over into a more of a business messaging product stream now
to try to make money.
Sure, sure.
So in that context, I guess the question sort of circles back to Twitter,
which is why do you think they had so many engineers over there?
Is it just engineers to have engineers?
I mean, they're hot commodity.
It's really hard to hire them, etc.
Or is it more along the lines of like, no one really knows,
you probably could have done this thing with maybe a hundred or 200 engineers,
or am I just way off base here?
I think to some extent, there there has definitely been periods of time in the past
in Silicon Valley where part of the hiring is because you might want to start some new project
and you need engineers in your company.
Right.
And it takes a long time to build up the hiring pipelines to go find and
hire them.
So to some extent, there is a little bit of that, for lack of a better term,
parking that goes on, which you're smiling at.
So I don't know if you have a story on that.
No, it's just, you know, it's, I like the term.
Okay, fair enough.
But I think that's sort of like only a background thinking.
It's not like an active thought that like that's what people are trying to do.
It's usually along the lines of a lot of feature development happens
where it sort of like partially gets completed or sort of the 80% of the product is done
and then it's shipped and it's good enough.
But the problem with that is your existing engineers, now you've taken something that
only works 80% of the time, or even if you did, you know, great job, 90, 95% of the time
and put it out in front of your users.
And with that out in front of your user base, now you've got a lot of bugs coming in,
a lot of issues coming into your issue tracker, whatever tool you use for that,
pretty much every software organization has one.
And that consumes a lot of your people's time.
And so when you go back to your team who just rolled out some major feature and say,
I want to work on the next one, okay, well, give me three more engineers.
And you sort of repeat this process.
And over years, you start to end up with teams that are hundreds of people,
large to do, you know, application development.
I, yeah, I've definitely seen that before.
There's no question that that definitely exists in sort of larger companies.
And there's something about having large teams almost for the sake of having large teams
and getting promoted in some of these sort of fang type of worlds.
Is that to your experience as well?
Well, it depends on the company.
So some of them do a better job of like navigating the impact of your team being the sort of
things that they incentivize.
Others in that space, they'll, yeah, sometimes they'll flat out measure their engineering
managers by how many reports that they have.
And that doesn't lead to a very good incentive for your engineering managers to have less reports,
right?
So naturally you tend to end up with more engineers when you have incentive systems that
work like that.
For sure.
I mean, I, yeah, it's, it's interesting that a lot of businesses haven't quite figured out that,
you know, incentive systems will be gamed by any way, like any way, shape or form.
You know, sales, sales teams seem to, seem to do this incredibly well.
I'm not sure that engineering and product have quite figured this, this incentivization out,
though.
Would you, would you tend to agree there?
Yeah, although it's a little bit harder.
Sales tends to be a very numerically driven part of the business.
That's where it's like, you can see like your sales print signed this amount of dollar amount
for contracts.
Now there's some hidden costs in there sometimes, as I'm sure you are well aware from our time
together at AdMob, sure.
But in engineering and product, it's the, the tricky part there has long been
measuring the success and health of your teams.
That problem is what has vexed, I think, doing software development as an industry
since the outset and will continue for this foreseeable future.
I haven't seen anyone come up with a great answer.
Sure.
What would you imagine the sort of measure to be over at Twitter for some definition of,
of measure right now in product and engineering?
Would it be, I don't know, would it be, would it be solid?
Would it be weak?
Would it be, I don't know, intrigued?
Again, given the new owner and sort of the, the, the stuff that's been going on,
how do you feel about that?
I'm more asking just because you've, you've had some, some interaction with, with a lot of
social, social type of products.
You said measure to, measure to be?
Just measure for, for some definition of whatever the measurement would be for those teams.
And I'm not sure what it would be.
If you solve that problem, you know, quit what you're doing and start that company, of course.
Measurement of product engineering is incredibly difficult, but what I'm more asking is, you
know, do you know some folks at Twitter or anything like that?
How's the, how's sort of the, the attitude going on over there?
I don't personally know anyone at Twitter currently.
So, I don't know, all I know is sort of the second hand, third hand stuff you see in the,
the general news is obviously there's been a shift over there.
And clearly there's a lot fewer employees now than there were before.
But other than that, I don't have any internal insight into what's going on.
That's fair.
So it seems to me anyway, and I hope this isn't super leading, but to me it seems like
Elon stepped in a bit of a quagmire here.
And he didn't quite realize what owning a social product means.
And as we have kind of spoken about before, it means content moderation for some definition
of what content moderation is.
And of course, the quagmire is, what is that definition?
What does that look like?
Right?
And so you've had some experience with this.
What's, I mean, and for that matter, you've also kind of gone out of your way to not have
experience with this, depending on how you look at it, right?
Yeah.
Um, specifically like, well, we don't know what people send in the signal application.
We don't know what people send in WhatsApp, et cetera.
And at the same time, there's been some other places where you've actually had some foot
in this.
Why is this so difficult?
What's hard about this?
Well, you're looking at agreement between groups of different groups of people for a
global product about what is the acceptable range of discourse.
You know, you hear it discussed as the Overton window, right?
Well, everyone's got it.
What's the Overton window?
The, it's essentially the definition of like, what is the acceptable range of topics to
discuss for a given group of people?
Hmm.
Okay.
Yeah.
That seems, that seems like a bit of a dilemma to say the least.
Yeah.
I mean, the problem, the fundamental problem on this is not a technology problem.
It's a people problem.
It's, it's fundamentally, if you get large enough group of humans together, they don't
agree on what topics people are allowed to talk about.
And then you get into these platforms that are pretty much trying to apply the same rules
globally.
And yeah, there's attempts to moderate them differently per region, per country,
take into account some degree of localization for that.
But they are based in the country they're based in.
You know, for example, Twitter, they're based in the United States and headquartered in San
Francisco.
That lends to a certain like set of people and, and, and experiences that are there at
that company that don't reflect everyone in the world.
And so what happens is you'll end up with people who disagree with the Overton window
that the people who are setting the content moderation policy have tried to define.
And that just leads to a place where there's just conflict over what you can say on that
platform.
That makes sense.
Is there not a tech way out of this problem?
Is this truly a human problem that's unsolvable?
I haven't seen a good tech way out of this problem because I think at the end of the
day what you're trying to do is decide who can speak and about what.
And that's not like, that's not a problem that like technology itself is going to be
able to jump in and solve for you.
That that's people working with other people to decide like, what are the topics that you
want to hear about?
What are the topics that you don't want to hear about?
And, and this comes up in more context than just content moderation.
One of the most common feature requests that we got at WhatsApp that's now actually in
the product, but we sort of resisted it for years when I was part of WhatsApp,
was the ability to silently leave a group.
I did not know that.
I'm guessing there's a little, there was a little message that says X person left the
group or whatever.
Yes.
And the idea was not to not to have that be the case.
Yeah.
So you'll find, and it's understandable from both sides, right?
You have people who get added to groups who are like, I don't want to leave this group,
which is a completely understandable feeling.
Cause like, maybe it's your family group or some group of people that you don't want to
like disassociate with, but also you don't want to hear what they're usually talking about.
And so you don't, you want to exit that group.
And on the other side, there's the people who think they're messaging you and they're
including you in the conversation.
And so there's, there's sort of a two way street here where one party is like, well,
I don't want them to know I'm not hearing them, but I don't want to hear them.
And the other party is like, but I want to send them a message.
And so how do you deal with the problem there of like who, who's desire is the one you serve?
Because they're both valid, you know, human interaction desires.
And part of what you experience as a technology product is the recipient kind of wants to,
in some ways, use your product to like ease the personal pain of like telling someone,
I don't want to hear from you.
Like they want your technology product to be like, oh, sorry, like it must have been a bug.
It like dropped me out of the group.
You know, people want to like blame the technology rather than like have the hard
conversation, which is a human and completely understandable point of view.
But it's very hard to like build a reliable technology product like that when you're,
you know, that then it looks like unreliable to the people who are sending messages.
And so you're sort of put in this hard position to resolve.
Right, right.
I see where you're going there.
That's a, that's a, that's a tough dilemma, especially on the, on the, on the product
and engineering side, I can see why there's pretty strong resistance to that.
Is there not an option there to just sort of, I don't know, maybe you're in the group,
but it's completely muted or something of this nature, like you don't get notifications.
It doesn't necessarily show up at the top, but you didn't necessarily leave the group either.
Yes.
So that option was there and that was actually implemented a long time and still people wanted
to like fully leave the group, seen the group like resort to the top or the, just the messages
come in at all was sort of like the behavior, even if you didn't notify, was still a, not,
not enough of an exit for a number of people who requested it.
Not to go down a crazy path here, but this start around 2016.
I'm just guessing.
I'm just guessing.
I could be wrong.
I could be wrong.
No, I think it, I think it predated that.
Okay, just checking.
I'm guessing 2016 may have boosted along a little, but okay.
Okay, sounds good.
What are some, I mean, what are, what are some of the tactics that people are taking these days
in the content moderation world?
Like, like, like you said, tech's not going to solve this problem all the way.
So clearly it's some sort of mix.
And as I actually on a, on a previous podcast, one of our, one of our topics was the combination
of human and AI is actually notably better than just humans or just AI.
Um, specifically because AI is unbelievably, I think, I believe we were talking about chess
and go and it was, um, that the AI makes perfect moves with chess.
Perfect.
But it doesn't understand strategy very well, but its tactics are better than any human.
And so when you sort of group this, um, group this together with humans who are thinking
on the strategic level along with the AI who's thinking on the tactical level,
you end up with effectively unbeatable systems.
Is there something like this?
Is that, is that sort of like, is that a tactic that could be used for content moderation
or is it being used?
Um, I haven't seen examples of that being used.
Like, uh, I'm sure there are, there are some attempts to use that, but they're probably
fairly early in development, fairly nascent, especially if you've seen, you know, over the
past couple of months, the rise of unpopularity of like chat GPT and things like that.
Oh yeah.
Love that.
Love chat GPT.
I'm, I'm, I'm feel for, or fearful for all my marketing friends who generate content.
And I'm like, you're either out of a job or your job just got instantaneously easy.
The problem with those is that they don't actually understand the content of what they're
spinning out.
They've got statistical models that say this looks like something I would have seen somewhere
on the internet.
But it doesn't necessarily mean it's factually accurate and it doesn't mean it understood
what it said.
And so you can even see this with something like chat GPT or things like that.
You can fairly, uh, with a reasonable amount of like poking and prodding, get it to say
something that's completely nonsensical.
Or sometimes you can just ask it a straight up question to get like a wrong answer.
They're very confidently wrong answer.
But to be fair, it kind of learned from the internet and that's some degrees the internet.
I played with that early on.
I did get an incorrect response.
I believe I asked it, what was the fastest marine mammal?
And then it told me something that wasn't a mammal and it was a fish and I had to correct
it.
And it's like, you're right, it's actually this.
And then it told me a bird and I was like, that's not a mammal.
And then eventually it got there though.
Like I kept correcting it, but it eventually got there.
It was like, you're right.
This isn't a mammal.
But here.
And I was like, that's a bird, not a mammal.
You're right.
It's a bird anyway.
But yeah, it's been an interesting technology.
So I love to, I love to talk about chat GPT.
But before we, before we jump in there, just one last on content moderation
is what you're mostly seeing just, you know, sort of rules based and then very,
very much human interaction type of deal, like a trust and safety type of team, etc.
Oh, you mean the way things are generally working today in the industry?
Yeah.
Yeah.
So a lot of the organizations will have a dedicated team, some of them use language
like trust and safety teams, some of them use language like site integrity.
Sure.
And what they'll attempt to do is go through the site and apply some degree of like content
moderation policies.
But no matter how well you've written the policies, they're still open to enormous
subjective decision making.
And it's very hard to do that at scale.
Like who's subjective decision making model are you going to use?
And how do you give that to 20,000 contractors as the case may be?
If you remember the, some of the Facebook ramp up to the 2020 election, I believe it was,
they talked about the number of contractors they were hiring to do content moderation.
You can't very well like hand out judgment at scale.
And we just haven't seen a model for that yet or seen anyone like really do that very successfully.
I mean, they can, they can hand out sort of a rule book and try to help people.
If you see violations of these certain rules, take these actions.
But when it comes down to it, people are very good at figuring out ways around rules.
So you'll see the language change or people's behavior change in order to skirt by the rules
that they know are being enforced.
And so the effectiveness isn't all that great.
And what you do is you sort of create a narrative where like
people are seeing that, oh, the things I want to say are being suppressed.
But if I tweak them in this way, I can get around it anyway.
So it's both ineffective and also makes people feel excluded.
So you've kind of got a little bit of a painful like area there for both.
That makes sense.
Moving on to that chat GPT that we were literally just talking about.
I heard today, I think that Microsoft is doing something like a $10 billion investment,
something of this nature. Did you hear about that?
I saw something like that scrolled by, but I must admit, I haven't seen any details.
I also didn't read the details.
I'm totally guilty of just reading the headline, but either they're considering or they already did it.
I would argue it's probably a good idea.
I'm pretty sure that they said that they were going to include it in bang like outright,
no matter what, besides the investment, which ends up leading to, you know,
what do you think is next for sort of open AI and that realm or for that matter, any of these things.
Chat GPT has some pretty strong content moderation built in.
Like I would say strong in the sense of it's pretty straightforward that it won't do certain
things. There are ways around all of them, of course, if you're clever enough with your language,
but they've definitely made an effort for those things.
What do you think is next in sort of that NLP type of world, natural language processing, NLP,
and AI type of world like that?
It's an interesting question, because what you're looking at there is sort of a model that can
respond to you in a way that sounds a lot more natural than so far what we've seen from any of
our sort of query engines that are out there. You'll see organizations like Google are starting
to take this as an actual legitimate threat. I believe Sundar made a statement to that effect
that they were sort of going to shift gears to focus on going after this potential threat.
I heard it was outright called a Code Red. I believe there's different color codes at Google.
I don't know if you remember those, but I remember hearing about a couple of different ones,
and I believe Code Red is like immediate threat to both business and strategy.
So I heard that was flash pretty heavy.
Yeah. So I could see why they want to go that particular route.
It does look like a, in particular, it's probably not an immediate threat,
but it is something that's medium to long term. It is an area where you do need to be concerned,
especially given how much of the internet today exists to trick Google into showing it to you.
So much of the internet is already written by bots. It sort of makes sense to start having
bots that are trying to filter those bots out, which also already exists, but getting more
effective with it, trying to read through a lot of articles you'll see these days on the web have
been generated by a machine. They're not human written. So having another bot that just summarizes
that bot's output is kind of a little bit of getting kind of meta to a point where these
days you might ask a machine a question and get back an answer that it inferred from the text of
another machine. I could see that happening. Yeah. And so when we sort of go down this path,
can you see different types of products coming out for this? Would this be something that
I don't know the Signal Foundation would be interested in? Or for that matter,
you personally, would you like to see certain things come out of this world?
I don't immediately see a scope for this within Signal, but I mean, it is definitely an interesting
area. I do think AI is probably going to be one of the areas going forward. But what it is actually
going to produce at a valuable to society product level, I think that still is still to be figured
out. There's lots of people exploring this space. And there's lots of opportunities if you look at
things where you're asking humans to make kind of routine judgment calls that aren't like strategic
in nature. And so if you ask, well, what does that mean? Like what is a routine judgment call that's
not strategic in nature? The easiest example of that would be self driving cars, where you are
making calls based on the immediate environment around your car, and an overall like GPS map or
something like that. We have the GPS mapping technology. Obviously, people have been using
this for 20 years plus at this point in their cars. And now we're seeing that cars are developing
further into the ability to recognize what the objects are near them. And this is one of the
classic problems in computing of like show me a picture of a cat pretty easy. Tell me that's a
picture of the cat very hard, just for the computer to understand what that is and provide context on
that. And so you'll see those type of ai's I think coming out earliest as opposed to strategic ai's
that are making like very long term planning decisions, just because those, to be honest,
they rely on a lot of unknowns and humans sort of fill in the unknowns and strategic planning with
their intuition and experience. And that's something your machine can't necessarily do yet. It can
throw a random dice and like pick a random value, but it's not necessarily going to be what you
said like you mentioned earlier, mixing a human person doing the strategic direction with a machine
doing the tactics of playing chess. I haven't actually seen that story, but I could believe
that that that makes a lot of sense. Yeah, definitely. Well, leading down this ai path,
what are we looking at here? Are we looking at like a really, really great molding of ai to
human beings and going forward? I'm talking, you know, much further out. Or are we looking at like,
you know, it's terminator style and we're all screwed. There's a lot of question sort of around
this and I'm genuinely curious what your thoughts are there. I've heard, just to preface, I've heard
both extremes from people literally in our field. Actual computer scientists have heard both extremes
and then I've heard, I've even heard people say I have no freaking clue. Yeah. And those are literally
direct ai researchers. They have absolutely no idea where it's going. They're like, I don't know.
Right now it's a bunch of linear algebra and some calculus. Yeah. So I mean, that's, that's what it
is at a fundamental level. Like pretty much all of the ai is different linear algebra and some
calculus is different math. It's different mathematical models. Pretty much. And I've
started to see a little bit of overuse of the term. I've seen things that we would have previously
called like filters and other computer science terminology that meant like simpler algorithms
that do some math. Yeah. People are starting to call them ai now. I'm like that, that didn't
used to be called ai 10 years ago. So there's a little bit of overuse of the term being thrown
around. I would argue there's a lot of overuse, but yeah, you're right. Yeah, well a lot. Yes,
I didn't agree. But if you if you're asking about like the the ai apocalypse or the sort of
terminator style, I don't think we're any in any imminent danger of that coming true. I don't
I there's no evidence yet of like machines that have some sort of ai's that have some sort of grudge
or experience or any kind of emotion. Now, there's the risk of sort of running a foul of say the
trolley car problem. And this one is discussed. Okay, the trolley car problem hit me. Yeah. The
trolley car problem is sort of a question of inaction. Essentially, if there if you have a
trolley car going down a line of tracks, and you have say five people who are tied up on one track
and one person tied on the other track, and the cart is currently going to bear it barrel into
these five people and hurt them or, you know, otherwise. And you're at the switch. Do you
do you throw the switch, take an action that negatively harms one person and saves five,
or do you not take action and it's sort of a moral ethical dilemma in the question and it
comes up in AI. For this reason, if you build a self driving car, there may be situations where
you've reached a point in the processing of the code and the environment around you that
you realize there is no way for this car at this point at this speed to avoid a wreck. What do you
hit? Right. And so at that point, you've got, you know, you've got a question for your machine to
make about like, how do I value life and property damage and all these different things to minimize
the, you know, what am I trying to minimize here? And there's sort of this fundamental question of
ethics really of like, well, do you take an action at all? Or do you let the car just continue its
path into what it's doing? Like, and there's not a right answer to that. Right. I mean, you sort of,
you come around a blind curve, there's a little kid on one side, and there's maybe a family of three
on the other side, but there's no actual kids in the car. And it's like, well, which one do you do?
And it's like, please don't, right. It's like, do not ask me that question. But yeah, it's a good question.
Yeah, it's a really tough answer. I think some people would say, well, the kid, unfortunately,
because there's there's there's more people in that car. And I think, honestly, a lot of people
would say, no, no, I'm gonna hit the car. Yeah, they're reasonably protected. I don't know what
their airbag situation is, etc. But like, that kid is certain death, and maybe, maybe not for those
three. You know what I mean? Like, there's there's a number of different questions you would have
to ask yourself. But man, I wouldn't want to be in that scenario.
Yeah. And it's it's something where like coming around the curve or something like that, you'd
hope your car has been like smart enough to like, know that it can't see around the curve. But it's
like, say that you have a malfunction in your car, or the kid just darts into the street. I mean,
there's there's a million, there's a million questions for this, right? Yeah. And so there's
an unpredictable behavior of others or unpredictable unexpected malfunctions. So you're driving down
the highway and like one of your, you know, wheels falls off or something, you have a wheel bearing
failure. And you know, I'll say this, neither one of us drive Tesla's. And it's not because I
haven't driven one before. But honestly, and this is nothing against Tesla. I just, I'm not sure
I'm ready to trust my entire life to software yet. And that's because I am a software engineer.
I've seen too many bugs. I've seen, I've seen, you know, shipping things when it's good enough,
etc. etc. But my website breaking or having a memory leak, or, you know, in some other way
malfunctioning slightly doesn't, doesn't risk lives.
One would hope that the quality and testing bars are significantly higher for putting a
self-driving car code in place than safe for shipping a website. One would hope, but I'm not
necessarily sure that's the case. I'm not sure that there's laws that that's the case. And then
secondarily, I mean, we've seen some pretty crazy stuff on the pharmaceutical realm in the past.
I can't remember the name of the drug, but there was some drug that they prescribed to people
that was killed like 70 or 80,000 people over X amount of, like a decade or two. And I was like,
that drug took out more people than the Vietnam War. Anyway, they got sued over it and they
apparently knew that it wasn't good for people. I can't remember the name of it, it doesn't matter,
but like, there's definitely questionable decisions. Because again, as you mentioned at the
sort of beginning of this, AI making decisions is one thing, humans making decisions are another
thing. And we're not always the most ethical, unfortunately. Yeah. And so I think where people
are looking at AI's is like, sometimes there's this expectation that you want the AI to be
completely perfect. Right. And that's probably not the right standard. You're probably looking
at the actual question being, is the AI better at this than the human was?
Yes. Now that comes down to another question of like, whether or not you feel responsible,
say you're driving your own car, you get in a wreck, you know, as you're responsible.
If an AI is driving your car and it gets in a wreck, are you then mad? Because even though
the AI statistically is better, you feel like, oh, you could have done better than that AI.
And it's like the same kind of question when you ask everyone, are you better than average driver?
Almost everyone says yes to this, which is not possible for everyone to answer yes to this.
It's true. People also think they're better than average smart. And I can understand that human
ego drives a lot of things. I mean, I'm the type of guy on my couch on Sunday who's yelling at the
coach. Why did you call that play? And there's no way there is no way that I'm a better coach
than them. But I totally say it. I totally say it. Unfortunately, that does happen. And again,
this is what happens when you throw that irrationality of humans into the mix. Right.
All right. So I want to come back to a different part of software for a second. You've done some
a lot of mobile things, but you've also done some non-mobile things.
Is there different standards for web versus app store type of moderation in terms of both content
and various other things? Do you see that as a bit of an issue?
It's definitely a concern. If you look at, say, the web, for instance, the web is quite open.
You can move your domain around who's hosting it. There's a lot of different hosting providers
available and a lot of different competing platforms for putting your content on. I mean,
if you look even at just the sort of cloud hosting, which is not the only answer available,
there's sort of three very big players in the space now between Azure and Google Cloud Platform
and AWS. So you've got a lot of competition available for who's going to host your website.
If you're going to, say, install an iPhone application, you're basically going to need
Apple to say yes, because it's going to have to go in the Apple App Store. Google on Android,
there's a little bit more openness there, but for your average user, not much.
Yes. It is possible to install a different app store on your phone, but the vast majority of
people will never do that. So for most folks, it's the Google Play Store. Although some phones do
ship with things like the Samsung Store, things like that. So Android's a little bit more open,
but even there, it's not nearly as open as the web. And so yeah, that does lend to a place where
there is not an open field of competition available to select between policies for who's
going to host your website that's available to choose from, who's going to host your application.
Sometimes you have few or no choices. So for instance, because there's been a lot of talk
about this, if they ban TikTok, let's just say, if one of the stores, a solution could be, okay,
cool, just sign in on the web and effectively it's not banned. The reason that I asked this
question, and I wanted to talk about this for a second, was do you think there's sort of an issue
with having sort of these two fairly massive companies, both of which we actually have a bit
of a, both of us have a little bit of a connection to both of them actually for various reasons, but
do you think it's sort of a little bit of an issue for them having effectively like a virtual
monopoly on like what you're able to see? And then juxtapose that with Google, let's just say
a Google search engine. If you search for porn or some horrible Nazi stuff, or what would be
considered to be generally like not great things for some definition of that phrase,
Google still pulls it up. They don't moderate their search engine really. I mean, I would imagine
the only thing they pull off there is direct links to like Kitty porn or something, but they
definitely don't pull out links like if you search for Nazi things in Germany, it comes up and it's
illegal in Germany, at least some form of it is actually in a few different countries in Europe,
et cetera. And yet the app store will like ban like outright ban like, no, this app can't do it
because there's too much nonsense on there. It's like, right, but the nonsense is in the app,
but your search engine pulls it up anyway. So you see where I'm going with this, like you see sort
of like a dichotomy there? Are you certain that the search engine actually pulls that up and say
someplace like Germany? Google does actually filter the search pretty heavily in certain
in different markets. Okay, which is fair, but do they do that according to only the law or is it
like actual content moderation? Because you're right. In like Germany, Austria, I'm sure, you
know, various other countries in Europe, you know, mentioning of that party in like any positive
light whatsoever is I believe it's like a criminal action. That's fair. But that's, that's, that's
law. We have almost no laws against any type of speech in the United States, except for basically
like inciting a riot fire in a theater type of stuff. We have effectively no other laws
regarding that stuff. My point is they pulled stuff off the app stores that doesn't seem to
sort of violate those things because there is no, there is no violation of the law. And yet
they don't really pull them off the web. I mean, they're still out there. You can go find them.
Mm hmm. It's an interesting case, because what you're, you're talking about here is
to some degree, they are the ones publishing things on their app store. So I can understand
their argument that they have the right to decide what's on their app store. But it's also difficult
in that in many cases, they're more or less the one of the few or the only option for actually
installing the application. And so there's, there's sort of a split case here where you've got, yes,
they shouldn't be forced to publish things as a business. They don't want to publish, but also,
okay, you can't say that like this platform that's got a billion users, I can't get an application
on because that, that just locks too much, too much competition out. It's, it's very,
very difficult for say, an app developer who gets pulled out of one of these stores to like
overcome that and get distribution to phones again. So yeah, there's, there's not really a
great answer here. It's a, it's a, it's a problem. Like we, we would, it would be great if there was
sort of more openness in the sense of like the way the web is open with the way applications work.
But there's also some degree of you do want someone like checking some of these applications,
because it's, it's much like installing an application on your, on your computer at home,
if you have a desktop, you don't want to run applications, you don't trust on it. And
for better or worse, the way that things have worked since we've moved into the mobile world,
people tend to just sort of trust whatever applications they have access to on their device.
And that shouldn't really be how you think about apps. They should think about them. This is running
the software on your machine. It has access to a lot of the things on your machine, whether
that's your desktop at home or your phone in your pocket. And in many ways, your phone in your
pocket is probably worse because your desktop at home doesn't have all the sensors attached to it
that your phone does. Sure. Quite, quite a few. As you were, as you were sort of speaking, it was,
it was reminding me of a big problem that we had a long time ago. You remember Napster,
the sort of song sharing service, you know that they didn't actually host any songs, right?
It was just a directory of songs that other people hosted on their machines. And yet they got
effectively sued out of existence. Fanning was a good, good buddy of mine.
And the issue that I sort of see with that is, doesn't that sort of mirror what Google does? I mean,
it's just a directory of stuff that's not on their machines. It's on other people's machines.
And so if you can make the case that you can end up censoring this Napster style,
why not make the case for search engines? Yeah, I don't, I actually am not that familiar with
the basis for why Napster was taken down. I'm familiar with the name and know that they were,
they did get sued out of existence, like you said. I believe it was just an RIAA issue.
Recording industry or whatever. Yeah. Did they, the basis for that, did they actually
lose those lawsuits? Or was it just the expense of defending the lawsuits? I think eventually,
I think it eventually was the, it was, it was, I believe, you gotta kind of fact check me on this
one, but I believe it was not only a defense, but it was effectively, they didn't see any tenable
way forward. So they ended up shutting down operations. I see. So that makes sense. And,
and so yeah, although ultimately, Sean Parker got his revenge because he ended up investing in
Spotify. And now it's, it's doing pretty, pretty dang well. Okay. Yeah. Shifting gears.
FTX and Sam Bigman freed in the crypto nonsense that's been going on. Let's hear your thoughts.
We're bull tech guys. I'd love to be able to hear someone who's actually in like much more of a
security focused, I mean, you know, crypto claims to be secure and all the, all the rest of this
stuff, even though the heists in this field have been the largest heists in history, literally
billion dollar heists that have never happened ever. Yeah. 100 million dollar heists that have
never happened ever. And these are like, you know, on an almost monthly basis, it's, it's, it's
getting effectively ridiculous, at least in my opinion. I'm not saying that there's not some
good uses for it, but I don't know. They're few and far in between. What are your thoughts?
Yeah. When I look at the, the sort of, you're talking about the, the web three phenomenon,
where web three was kind of what everyone was labeling as all the distributed crypto systems
that were coming out a couple of years ago. And I think there are a few of the technologies that
are sort of salvageable from, from that, that I think are going to be useful. You know, looking
at some of the, the blockchain technologies and the zero knowledge proofs and things that came out
of, of that industry that I think will actually be quite interesting and have a lot of applications
in the field of like privacy and secure communication. But in general, I, that there was
definitely a frenzy in that space for the last couple of years. And I think for me, the, the
peak of it that sticks in my mind was an article that came out at one point, I forget what the,
the first letter stood for, but it was something that started with an S cash and money. This
guy literally made a coin. He called scam coin. And so still managed to sell $3 million worth of it.
I forget what the first letter was, but it was something S cash and money scam. It was literally
named scan coin and he made $3 million. I'm like, this is obviously sort of an excessive
bubble and frenzy in the space. I can't remember which one it was. I want to say light coin,
but I need to double check this as well. So don't take this as gospel for anybody listening.
But yeah, I recall this also happening with one of the founders of a coin who ended up
cashing out with literally several hundred million and just being like, yeah, I sold,
sold everything. And they're like, well, you know, why aren't you doing any more to promote it?
He's like, because I already made my money. I don't know what you're talking about. Why,
why would I do that? You guys go ahead, feel free. It's still out there. It's still
tradable, et cetera. But like, I'm good. Next. So yeah, so
what are some of those technologies that you were mentioning that we actually could sort of
salvage? You mentioned zero knowledge proofs and whatnot. Yeah, I think zero knowledge proofs.
There's sort of a large expansion and investigation of that space over the era of sort of the burst
of Web three. Let's explain what they are proof. Yeah. Yeah. Zero knowledge proofs are a proof
that allows you to prove that you know a thing without revealing to the person that you're
proving it to what the thing is you're proving a knowledge about. So they're kind of the classic
example that's used and explained in what they are is what I believe is referred to as sort of
the Alibaba's cave situation where you have two tunnels into a cave and there's a locked door
in the middle in the back. And so someone stands out at the front and basically waits for the
person who's doing the proof to disappear into the cave. Right. And then they call out
which side of the tunnel they want this other person to appear on. And basically,
if this person is able to appear on the side of the tunnel that they keep calling out repeatedly
several times in a row, it like the more times they do this, the more times they know, okay,
this person must know the they have the key or the code to get through that door in the back of
the cave. And so that's kind of the the short summary of like how zero knowledge proofs work
is they they prove to some other person that this the person who's issuing the proof knows
something without telling that person what the what the thing is that they know. So you learn
nothing other than I know the thing, but you don't you don't learn what the thing is. Okay.
And so how would how would we apply this to like something in computer science or, you know,
for an application or you mentioned it was salvageable, what would we salvage it for?
Well, so for example, I can tell you what we use zero knowledge proofs for in signal.
Let's do it. We have a group system that effectively allows our server to manage a group.
So you have a list of members in the group, you have a subject and avatar,
all these sort of properties of a group. And we don't want to know who the actual members
of the group are. And so what we have done is effectively create like an encrypted list of
members of the group. But I can create a zero knowledge proof system that allows our mobile
applications or iPhone or Android app that you might have on your phone to actually prove to
the server. I am one of the members of this encrypted list that you have without proving to
the server who you actually are. And so you effectively get a proof of authorization to do
something to this group without actually a proof of authentication. So it's an authorization
system without authentication. That's interesting. So basically, Signal has no idea who is talking in
this group whatsoever. It's really only the members of the group. And even the members of the group
are like, yeah, we know who each other are. But as far as the service concern, it's like,
yeah, I don't know. Yeah, I have no idea who these people are. But yes, they definitely told me that
they belong here because there's a way to do it, do that. Yeah, that's interesting. Our server can
see a group exists and it has five people in it. But who they are, couldn't tell you. There's a key
that we don't have access to that would say who those five people are only the group members have.
Gotta love Signal. Definitely want to dig in more on that. And so,
do you have any particular thoughts around the actual crypto beyond the technology,
like the actual folks involved in crypto, etc. Is it one big giant Ponzi scheme type of deal?
Is it just arbitrarily trading math problems back and forth?
Well, there was a lot of it during the frenzy that you definitely
looks an awful suspect. And some of them are more blatant about it. If you call your coin
scam coin, that's kind of obvious what it is. But if you look at some of the foundational
technologies in there, if you look at, say, the Bitcoin blockchain or the Ethereum blockchain,
both of those have very interesting properties in creating a distributed consensus system.
Where Bitcoin is effectively a proof-of-work model. Ethereum is, I believe, still proof-of-work
and trying to transition over to proof-of-stake. And to kind of define what those mean,
proof-of-work is essentially you have a hard math problem that's associated with
committing the transaction to Bitcoin. So, it's like if you were to go to a credit card
transaction in addition to doing the transaction before it's committed to the blockchain,
someone has to solve a math problem that's really tough. And so, you've got lots of computers
around the world trying to solve these math problems constantly in order to add things to the
Bitcoin blockchain. On Ethereum, it currently works the same way, but they're looking to
transition into a model where there's more of a proof-of-stake for getting to decide who's
going to commit the transaction to the blockchain. And that will sort of save energy. And that's one
of the big constraints or big attacks, really, if you will, on how blockchains work today is the
large portion of that work. A lot of electricity is being consumed to some degree, useless problems.
Sure. But when we say proof-of-stake, right? What's the difference between that one? And then,
obviously, the proof-of-work is literally, yeah, I did a ton of work in solving these math problems.
This part of this coin is mine. What's the stake part?
Proof-of-stake is effectively a proof that you have something to lose if you are to commit a
fraudulent transaction into this chain. So, usually, it is a function of how many of the
currency units of that chain that you own kind of decides, like, with a probability function of,
like, who gets to commit to this chain. So, there's a incentive to not screw it up because you've
effectively owned part of it. You've got stake in the game.
Yes, exactly. Okay.
Proof-of-stake. Exactly. All right. I like it. I like it. Okay.
And then, has there been... I don't know if there's been any update on this, but I think they...
I mean, it's interesting where you were going, but going back to the people,
I mean, they let that guy out of jail, didn't they? Did they let Sam
Bankman freed out of prison? I think he posted a $250 million bail.
As I recall correctly, even when you post bail, it's not the full bail amount, but isn't it 10%
which is like 25 mil? And yet he claims he's broke.
I saw some articles about that story that claimed it was the only bail that was actually posted or
the only collateral that was put up was like his parents' home in Palo Alto or something like that.
But I only know the details of this from articles I haven't seen it myself.
Okay. Yeah. I mean, there's going to be some interesting stuff there. There's definitely
going to be some interesting stuff there. I think it wasn't his either current or former girlfriend.
She was running some type of hedge fund alongside of this, some type of crypto hedge fund.
That's my understanding. I think he was running FTX and then she was running some sort of hedge fund
that had a large stake or a large investment from FTX. And I think it was the insolvency of
that hedge fund that sort of backtracked into the insolvency of FTX, but I'm not an expert on this.
I've just seen the articles on it. Yikes. Okay. So this 3.0 internet, where are we going with this?
Anywhere. I think what was happening in that space is largely quieted down.
I still think there is a possible future for some of the technologies in that space.
Sure. Especially when they move to a proof of stake. I think that
eliminates one of the major concerns that people had about it. Where does it go from there?
Hard to say. There's probably a place for having a decentralized currency
of some form. And the problem just there becomes like ultimately many of these things started with
a bootstrapping problem of in order to get people on the network to start out with the rewards for
mining on the blockchain early on were high and they diminish over time.
And many of those systems are actually set up to transition into a transaction fee model
towards the tail end of their like give out free mining rewards portion of their lifetime.
So the long-term goal there kind of makes some sense, but ultimately getting there is going to be
interesting. To some degree, you're going to be dealing with problems of like currency and
securities. Because at some degree, that's what some of these things are, is like alternate forms
of securities. Like you can buy the stock in a company in a similar fashion. You buy an element
of a Bitcoin or Ethereum or something like that. So there's an argument to be made there. And if I
recall correctly, I think the SEC has started making rulings saying they intend to treat these
like securities, but I haven't kept up on that. I'm not 100% about the SEC. I know if you Google
cryptocurrency IRS, they tell you explicitly this is not currency. Like when you buy versus
when you sell, if it goes up or down in value, etc., like you owe taxes. So that is not the case
with actual currency. Okay, so you mentioned sort of them going to a transaction model.
How is that different than what we have? I mean, that's what we do now, except for its FDIC
insured. And then, as I understood, it stood at 3.0. It was also supposed to be very decentralized.
Everybody having their own wallet. But as it turns out, no one wants to run their own wallet.
That's why Coinbase and these various other things exist. So in other words, all this decentralization
and all this stuff seems to have literally gone exactly the exact opposite way that it started.
We're going towards centralization, and now it's going to be towards transaction fees,
which is, I mean, that's what we do now. We do transaction fees when you wire
money on ACH or SWIFT, or when you do, it's 2.5% every time you swipe a card and,
well, 3.5 for AMAX. But some fee, etc. So I guess the question that I want to ask is,
what's the point? Why use the cryptocurrencies? I mean, outside of we don't have anything better
to do, what's driving this? What's the point of this?
Attempt to decentralize trust. But you're right about a lot of people don't run the
wallets and things like that. But I don't think that's as critical an element of that ecosystem
as the decentralization of the trust itself of who is storing accounts. And so you can see this
if you look at over the past year. I mean, do your dollars buy as much groceries as they did
a year ago? No. And part of the reason for that is there's a massive amount of dollar
expenditures going on from the government and interest rates were low for quite a long time,
leading to expansion of the monetary supply of US dollars. And so you look at cryptocurrencies,
to some degree, a lot of them have been sort of hedges against the sort of loss of trust in
fiat currencies where there is some political party or group of people that controls how much
of this currency exists. Whereas with a cryptocurrency, no one can come in and say,
okay, tomorrow there's twice as much of it. That's not the case with the US dollar. The thing that
maintains it is just trust that the government or the Federal Reserve is not going to do that and
come in and tomorrow be like, okay, there's twice as much now. But the sort of the larger amounts
that we spend, the less trust there is in that and you start to see that in the form of inflation.
Which is fair. But at the same time, I mean, you're right that there's not, I mean,
I think Bitcoin halves every single year until what, 2040? And then there's no more
Bitcoins ever? Something like that? Something like that, yeah. Well, yeah, which is great.
But Bitcoin at one point was pretty high and now it's pretty low. So I think that the world
markets do at least a, again, for some definition of the word okay job, phrase okay job, they do
an okay job of sort of keeping things pegged against fiat currency whereas Bitcoin, I mean,
it's all over the place. People who bought a Tesla like two years ago, they're pretty happy
with themselves. They bought it for maybe two Bitcoin and now it's going to cost them like 12
or whatever it is. Yeah. Yeah, so those are definitely volatile assets and you'll see that
anything with like low volumes of transactions and cryptocurrencies are still relatively low
volume transaction vehicles are going to have a high degree of variability in their pricing.
But this is not unprecedented in fiat currencies either. If you look at the 2008 housing crisis,
I mean housing plummeted. Yep. And if you look at the stock market over the past year,
a lot of stocks have plummeted. There's a lot of stocks that are down 50% or in that ballpark
from where they were a year ago. That's fair. So in many aspects, it's another financial vehicle.
It's not like you should bet the farm on it. Sure. At the same time, it's a bit strange,
right? I mean, basically, you're right, a lot of stocks are down, but the dollar is incredibly
strong, even though it's not. Yes. It's incredibly strong overseas, but it's not
particularly strong here. You're right. You're going to pay more for groceries today than last year
and at the same time, like, well, you're going to spend actually quite a bit less
for groceries if you're converting your dollars from the dollars to pounds or especially euros.
So I guess it really depends. It's all relative, I guess.
Yeah. It's a challenging financial aspect of it. There's variability in the way
everything's measured against everything else. And so if you look at assets only priced in dollars,
you'll see variability there that you don't necessarily see. It's just because that's our
frame of reference, I guess is what I'm trying to say. We in the US will put frame of reference
at like how much something costs in dollars. Sure. But you could also define a different
frame of reference. You could define a frame of reference based on the price of silver or the
price of gold. And to some extent, that's sort of what some of these cryptocurrencies feel like,
is an attempt to replicate something like gold or silver, but without the ease of stealing it.
I mean, if you fundamentally lock away a gold bar in a safe or something,
someone can break into your house and take that pretty easily. Whereas with the cryptocurrency,
at least with the knowledge that we have today, it's pretty hard to reverse those keys.
Yeah. I mean, it is with the knowledge that we have today. But of course,
now I have to ask you about quantum computing because then we end up in a pretty rough world.
Indeed. So theoretically, I think there are backdoors for these keys when you use a
quantum computer because it's just so unbelievably fast at math, right? And quantum computing is
effectively computing, but with qubits instead of bits, instead of a one and zero, you have a one
or a zero or one and a zero at the same time or various other super positions of the actual,
the quantum states of the particles inside, correct? Why are those so much better at cracking
these types of things? I mean, this has been a problem that sort of security has been at least
mindful of for at least a decade or two in the sense of it can theoretically render all encryption
useless for all intents and purposes. And you could literally decrypt, you could end up literally
reversing bitcoins and just about everything you could think of, again, with the standard
cryptography we currently use. So what makes these machines
that much better at doing what would effectively be like heat death of the universe for any other
computer to do? Yeah, they're not like that. It's not that they're faster at math per se.
It's that the way they can compute answers is different. And it's different in a way that
allows us to create new algorithms that you couldn't run on a classical machine in the same way,
where you can entangle the the qubits and the states between them in such a way that you can
effectively cancel out all of the effectively waveforms of probability there, you create these
like probability distribution functions where at the end of all your logic gates, your your qubits
end up in a state where the most likely outcome is the answer to your math problem. And if you can
come up with an algorithm that works that way, then your your quantum computer can solve something
that we've seen as exceptionally difficult in the sort of standard computing model, the von Neumann
model that we've been kind of working with. And so, and so it's the algorithm design itself,
it's not necessarily the speed of the computer, it's literally the it's you would almost have to
say it's the architecture of the computer that allows you to create these algorithms that are
just not possible with classical computing, or even if they are, it's like, yeah, but again,
time to solve a still heat death of universe as opposed to potentially seconds minutes hours.
Yes. And so what you'll see there is lots of disagreements still on whether or not these things
are even possible. We've got algorithms that work in theory, and in theory, we can build machines
that do them. But at an engineering level, the building these machines and keeping them coherent
is the fundamental problem, because you're talking about entangling things, bits that are you're
starting to work down on a quantum scale here. And there's a lot of noise at that level. And so
you have a problem there of lots of noise gets in and so your your data gets corrupted by all
this noise. And that problem, you'll find massive disagreement in the industry about how soon that
problem is going to be solved, you'll see some of the optimists saying it's coming in like five
years, you'll see some of the pessimists saying it's never going to happen. And so there's a wide
range of views about how far out that is. Where do you stand? I know you're not an expert on
quantum computing, I'm just, you know, what are your thoughts? Well, for the longest time now,
it's been one of those technologies that people have talked about in the same way for years.
And all of a sudden, in the recent years, the soon estimates, the like, we're the optimists
are thinking, have started to come in. And they started to come in from beyond, they used to be
like, Oh, it's always 10 years out. And they started to come into five years out or three years out.
And when you see people like moving their estimates into within 10 years, you start to think,
Okay, this is probably not going to actually happen in five years. But there's a lot more belief
that this is possible and buildable now. And so you have to sort of start to take that as a serious
risk. I would argue that's probably a pretty good measure for our particular industry.
Anytime anybody says 10 years or further, it's basically magic at that point,
because we can never predict our industry a decade out. It's just not possible. But
as soon as I agree with you, as soon as they start to come in, and it's like, yeah, I mean,
you know, even eight or nine, it's like, Yeah, you're still, you're still basically 10.
I'm rounding you up. Well, they start to say something like seven or even six, like, Ah,
okay, there's, there's definitely like, you can see the horizon at this point, something is there.
And so they've started to come in. So your thoughts is potentially inside of 10 years,
again, from the, from the optimist point of view.
Yeah, I think that's a possibility. It still looks like the most likely outcome is probably
further out than that. But the risk of it being sooner has certainly started to rise in my,
in my opinion, based on what I'm reading and what I've heard from folks.
That's good stuff. All right, that'll be interesting. That'll certainly disrupt
things to say the bare minimum. Although that's a bit of an overloaded word.
So speaking of quantum computers, the last time we chatted,
the last time we chatted, you, you literally hacked the matrix as we were sitting there
and predicted something that hadn't happened yet. And it happened literally the next day.
And I remember the article, it was in a quantum magazine, I sent it to you the next day, and it
literally was published at like 8am that morning. And we had talked that night. It was the craziest
thing I've ever seen. You literally predicted something. You want to talk, talk us through
that a little bit? Sure. I was talking about quantum information tunneling. I believe you
asked me the question sort of like, if I could, will any technology into existence, what would it
be? And that's coming. So you can't use this answer. But yeah, let's, let's hear this one.
Yeah. So you ruled out teleportation. So I sort of cheated and went with, okay, well,
you're not going to let me teleport matter. I'm going to teleport information.
Sure. And so essentially answered quantum information tunneling, because what that
allows you to do is entangle some, basically some physical information, like physical state between
two objects and then take them far apart. And that would sort of give you the ultimate insecure
tunnels. If there is no medium that your information is being transmitted over, it's not like there's
a wire in between to tap and listen to what you're saying. There's not a radio transmission.
It is a effectively a quantum entanglement state jump from you. You edit this bit over here,
that bit over there flips. And as far as we know, I'm not aware of like a way that you
can intercept that. And so yeah, basically what you're talking about is that is sort of this
principle in quantum physics, where if you're able to entangle to a particle, right, or two
particles, you're able to hold that entanglement. And you put one on literally one side of the
known universe and more on the other side, the information is almost instantaneously transmitted
like way faster than light speed. And they ended up doing that on a supercomputer, if I recall
correctly, through some sort of like hologram thing or whatever it was. I mean, do you remember the
sort of the details of the article now that we've kind of got it a bit explained?
I forget the exact details of the article. But yeah, and I don't know if it if it actually goes
faster than the lightspeed or not. I forget if that is allowed to break the rules of causality.
Last time I saw it, the answer is it was because Einstein referred to it as spooky action at a
distance. That's right. And effectively, like we don't know how much faster, but it is literally
faster than observable light. Like if it's one light year away, it will be effectively instantaneous
as opposed to taking a literal a year just like it would take light to get there. Something of
this nature. So this has, you know, a lot of implications. If you could actually make a sustainable
system like that and then shrink it down to fit into a home computer or portable phone,
you could have a secure tunnel to to anywhere and it would be basically uninterceptible
communications and instantaneous. So none of that, you know, none of that sci fi stuff where the
enterprise has to wait because they're in a, you know, a different part of the galaxy or whatever.
It's like, no, no, you're good. You're just right there. You just need, you know, the main view
screen needs to switch to the to whatever entangled particle. It's got it back on earth or whatever,
right? Back at Starfleet command or whatever it is. I'm nerding out over here. Okay. Yeah. So,
but yeah, but you literally predicted this. It happened. I was there. I sent it to you in the
morning. You were like, what the, um, so that's pretty exciting. Are there other things in that
field that maybe we can, maybe we could talk about and maybe they'll come true tomorrow?
I'd love to, I'd love to, love to have the next Aaron thing out there.
I don't know. I think I've got a tracker there. I don't know how to beat that one.
You, you already hacked the matrix once. Just figure out what it was and just do it again.
Um, all right. Well, um, you know what? Let's dive into signal a little bit.
So you're obviously the chief technology officer at signal. Um, you've been working there for,
for how, I mean, for a while, like almost since it started almost.
Oh, no, no, definitely not since it started. It, uh, well, no, it began life as a different
organization. Uh, in 2013, it was, I believe the first name was open whisper systems.
Um, and in 2018, it was, I believe was one of those renamed signal. I joined in 2020,
so I've been there about three years now.
Oh, okay. I'm sorry about that. I just, I, you know, I remember you being there forever
in a day, but I guess I'm wrong, but three years is a good amount of time. All right. So,
um, so as the chief technology officer, right, you've got, you've got access to, you know,
effectively everything. And you've got, you know, the good old keyboard veto and, you know, all the,
all the nice things that, that come with that role. My question to you is,
what's the over, I mean, everyone, I mean, for those listening, it's a, it's a secure messenger.
It's awesome. It's like WhatsApp only better. Um, and because the FBI hasn't compromised it or
whatever. Um, but basically like it's, um, and it's, it's got video chat. It's got regular chat.
It's got group messaging. It's got, um, uh, payments, if I recall correctly. Um, and, uh,
and I have my donation badge on there. So you guys are looking to like set up sort of a donation
system. Can you, can you sort of talk me through this? Like, what's the deal with the Signal
Foundation was started by, by, uh, Brian Acton, one of the founders of WhatsApp. Talk, talk me
through this a bit. Like what's the, where are we going with this? Yeah. Um, so the Signal Foundation
exists to essentially try to explore, can we make a sustainable, uh, organization building
consumer, uh, communications products without going down, uh, the road that pretty much every
other consumer, uh, communication products relies on, which is targeted advertising. So you look at
Facebook, Twitter, uh, you know, any of the other, many of the other messaging products that a lot
of times that we're lying on an advertising model, uh, for funding the operations. And, uh, these
things are, uh, you know, I think it would be shockingly expensive to a lot of folks to realize
how much it costs to operate, uh, an application like this. It's not just like the personnel cost
of like hiring your employees. Uh, but there's also the, the server operations for the amount of
messages people like to send, uh, bandwidth is unfortunately not inexpensive. Uh, it costs a
fair bit of money to transmit all the, you know, random cat videos and other things that people
take on their phone and share with their friends on a daily basis. Sure. Um, and, and you know,
these things are, everyone sort of learned to think of them as free because they are free at
point of use for the vast majority of people on the vast majority of sites because the advertisers
are paying for that, uh, site to operate. And therefore the, the users are not being charged
for it. But, uh, that effectively makes the user the product of the actual application
rather than the application itself being the product. I think this is a revelation that a
lot of people just started figuring out literally in the last year or two was, yeah, if you don't pay,
you are the product. Yes. Yeah. Your attention is the, is the product that they're collecting.
And there's sort of a misunderstanding into some degree about what it is actually that people are
doing, uh, with, uh, information about what you look at. Like you'll see this if you look at,
for example, the congressional hearings where they were, uh, asking Mark Zuckerberg to testify.
Um, there's sort of a misunderstanding like Facebook is selling the data about what you
look at. That is not at all what they're doing. And it's not in their business interest to do so.
No. They're selling access to that information. So some advertiser comes in and says, I want to
send this message to, uh, you know, women who are between the ages of, uh, 18 and 24 in major
metro areas in the U S Facebook can help that message reach those people, but it's not about
to turn around and tell you who they are because then you don't need Facebook anymore. Um, so what
they're doing is selling access to that, uh, targeting information. They're not selling the
information itself. And so that ultimately makes what you're looking at on these products. Uh,
it ultimately is the product that they sell. That's where they actually make their money
is selling access to, uh, the information that they have about, uh, about the people using them.
Well, which makes sense, which makes sense. Um, yeah, there's really no reason, um,
when people are like, Oh, I'm, you know, I don't want to give my data to Google. I'm like, they
already have it for starters, but secondarily, they don't sell it. They sell it to advertisers.
They do not sell it to advertisers. They do not sell it to, that's like the worst decision you
could make. They don't, they keep all that data. They sell access to target the data points that
they have, but you don't know. And, but yeah, you're exactly right. It's, it's, you know,
it's targeting the age and the, sometimes it's the race. Sometimes it's the socioeconomic or the
gender or, you know, one of a hundred other different slices that you can, you can possibly
think of. You're absolutely right. Um, okay. So you guys don't want to do that at signal.
Yeah. We sort of view that as like a lot of consumer products, they'll start out with this,
like, uh, vision that you're going to be a pure consumer product. And then once you bring in that
monetization aspect, so much of the product becomes focused on, uh, the monetization aspects of the
product that the consumer aspect, uh, aspects of it fall by the wayside. And, uh, essentially what
we're looking to do is try to build a directly user supported model, uh, to see if that, that is
viable. And if that makes it possible to focus solely on the consumer product and not have to
worry about someone else's pain for the bills here, it's like, no, the users are directly
supporting it. So we can focus on making the best, uh, product possible for those users.
Yeah. I mean, Brian can pretty much fund it ad nauseam. I mean, I'm not saying that he should.
Sorry, Brian, if you're less excited, sorry, buddy. Um, I'm not saying that he should, but yeah,
I mean, it's, it's great that you sort of have a, a pretty solid backer, but like, I mean, I've
donated, um, to signal and, um, the, the, the ideas is basically like, you know, do we have
enough of a product here that people will actually say, Hey, um, you know, this is worth, this is
worth X amount or, you know, I just, I want to keep things going, right? Um, okay. So what's next?
I mean, you didn't used to have video calling. He and I have video called before it works
fricking great. What's next? Like what's, what's on the roadmap? Obviously things that you're able
to share and, you know, uh, what, what does that look like? Yeah. Probably the, the soonest thing
that's coming that will be a major change for folks is the ability to look up other folks by
usernames, uh, because usernames are, uh, something that's been long time asked for.
Cause right now the only way you can find someone else on signal is to give out your phone number.
And that's not, you know, that's not something people want to hand out all the time.
Um, now there's some complexity about doing this where, uh, the sort of naive approach is,
well, you okay, you just create like a totally separate account with a, with a username.
But the problem with that is you, you now have this sort of complexity of like multiple inbox
system to monitor. Right. So what we're trying to do is sort of thread a needle there and create
a system that allows people to look up others by username, uh, but not, uh, have, not to have
to have multiple accounts for dealing with that. And, and that's a little bit of a hard problem
to solve. And it's like an imperfect solution where you are allowing people to look up by,
by username or, or possibly by phone number, but you let the user turn off whether or not they
can find, uh, find them by a phone number. That may, I mean, to my mind, that makes some sense
because effectively giving out your phone number. I mean, this is where all the extreme vast
majority of people are getting their, you know, two factor authentication and, and various other,
other notifications. And if you don't have to give that out, it's one more layer of security.
And for that matter, potentially zero knowledge on your end, right? Okay. That makes a lot of
sense. All right. Well, that's a, I'll look forward to it. When is that coming up?
That project has been a long time in flight. That project actually began before I joined
Signal, which tells you it's been a while. Okay. Um, well, I won't hold you any dates then. That's
fine. Yeah. Um, okay. So beyond the messaging service, are there other things that we can look
forward to? Like what I'm genuinely curious, is there going to be a browser you're going to compete
with Brave or some of the other things, or are we looking at a potential social network?
I don't know. None of those things are in the cards at the moment. Okay. But if you look at
the way the Signal Foundation itself is set up, the Signal Messenger is just one part of it.
And the ultimate thinking being that we can have a foundation that looks at consumer technologies
in the, in the long, long term for trying to make them usually supported. But I think we want to
get to a place where Signal Messenger itself is set up for the long, long term success before we
look at anything else. So right now there's nothing else in the works, but we're set up for
possibly doing that in the, in the long term future. And, uh, yeah, it's a, it's an interesting
experiment still because these, uh, these products do cost a lot of money to run. Yeah. And you'll
find that it's not even necessarily, uh, you know, some of the things you wouldn't expect actually
cost quite a bit. One of the largest expenses of operating something like Signal is the SMS's
that it sends in order to do user registration. At the beginning, when you tell us our phone
number and we confirm that you own that phone number, that is one of our largest single expenses.
Which is crazy given how SMS actually works. Can you talk, talk us through sort of some of the,
the expenses there? I mean, a lot of, sometimes it's, it's literally quite a bit of money,
depending on what country you're SMSing, where you're coming from, et cetera.
Yeah. So if you look at countries like the US, uh, sending SMS is, is very, um, affordable in the US.
It's often, uh, fractions of a penny or, or hundred, like tens or hundreds of a penny.
If you say go, uh, around the world to other countries, um, if I remember correctly, I believe
Germany is something like eight or nine cents per SMS. And there's what, like 90 hundred million
people in Germany. That's a little, that's, that's, I mean, that's like real cash. Yes. So it, it,
it doesn't seem like a lot when you're sending one, but when you're sending, uh, hundreds of
thousands or millions, it, it adds up pretty quick. Um, and also you'll see like people get new
phones, uh, you know, every two, three, four years, however, often people get new phones
and you want to switch to a new phone, put signal on a phone. That's another SMS again.
And so it's not a one-time cost at registration. It's a recurring cost that happens every time
someone gets a new device. Uh, and as what's app has taken over, uh, like communications around
the world, like what's app has become so much of the communications that telcos are, are hurting
from the loss of what was SMS revenue. Sure. And they're kind of figuring out, uh, that most
SMSes these days are two-factor off codes and OTP codes and like various technology companies,
verifying phone numbers. Uh, they're seeing this and they're like, okay, we're going to turn the,
turn the price dial up. Uh, and so these are not getting less expensive as is the case with most
data over time. You think, oh, six digits of six digit number, that should be pretty cheap to
transmit like almost nothing. Uh, but these days, uh, SMS has got to the price point where I believe
there were some like kind of somewhat satir, satirical, but also a truthful, uh, analysis done
that it's like, oh, it's cheaper to like send data to Mars to the like Mars rover than it is to send
SMSes to certain countries. Setting data to the Mars rover sounds expensive, but I believe you,
I believe you, I, especially at scale. Yeah. Um, yikes. Yeah. So it's, it's really kind of shocking
some of these things, how much they, they cost. Still having to deal with that, with that, you know,
that, that ancient tech, I mean, when did SMS come out? 90s, right?
Uh, was it before then or was it 90s? It's, it's, I don't remember if you could send a text in the
80s. It's kind of a hack on the SMS, on the, the way cell phones check in with their towers,
and that's why it's got the 140 character limit. Right. Uh, because they, the, the way that cell
phones just sort of check in with their towers, there was some reserved space in that, in that,
protocol, the handshake definition that the cell phones have, and that's, SMS was added is like,
oh, we can sell this like add on feature that sits in this empty space and this
check in between the phone and the tower. Yikes. Um, so still having to deal with, let's call it
40 year old technology, even though you're, you're, you know, you're as, as modern and, and, and fast
as, as you could be. Yeah. That's kind of a, it's kind of a pain considering it's one of the largest
costs. Indeed. All right. Well, um, continuing sort of, uh, uh, on our, on our tech journey here.
What caused you to want to go over to Signal? Uh, yeah. What, um, there was a number of blog posts
that came out in the 2017, 2018, 2019 timeframe from Signal that I thought were, uh, very interesting
of what's the problem signal was working on and the problems it was focused on. Um, at, at WhatsApp,
we had, uh, worked with, uh, with the founder of, of, uh, Signal, uh, Moxie, uh, to bring encryption
into, into WhatsApp. And so I'd worked pretty closely with him there. And so I knew him, worked
with him. Uh, and I felt like we got to a place where, okay, we encrypted the product, but there
was more we could do and it wasn't something we were necessarily investing in anymore at that point.
When you were at WhatsApp and Facebook. Yes. Okay. And so when I saw Signal moving forward
with like their private group system, which we discussed a little bit earlier about how
zero knowledge proofs play into our group system. Um, and, uh, there were a few other articles that
came out about, uh, sort of using trusted execution environments to provide, uh, like a, uh, basically
taking a pin and turning it into something, uh, higher, um, higher entropy, which is, uh, kind of
term, meaning the amount of data that packed in. So if you've got a six digit pin, there's only one
of a million possible values there. Sure. That's way too small to use to unlock something that's
encrypted. You need something that's got, uh, just an enormous number of values and one out of
a million is not nearly high enough. Right. Um, so there was sort of an interesting article that
Signal put out about how they were using, um, a trusted execution environment from Intel to do
that. And, um, yeah, basically seeing some of these articles thinking those are interesting
problems and also having experience like working with the people at Signal in the past, uh, it was
sort of a combination of factors that I decided to join. That's good. Um, speaking of the founder of,
of, of Signal Moxie, did you ever, did you ever actually play rock, paper, scissors with him?
Because I hear that this is, this is not a good thing to do. Supposedly he's like world class at
this and that there's an actual method to this madness. If you learned that where I did,
I also learned that from the Joe Morgan podcast. Me too. Me too. I have not,
I have not played rock, paper, scissors with him. And that was the first time I've heard that,
that story, but, uh, but that is what he claimed on there. So that was an amusing one.
I wonder if it's true. I couldn't say it. Uh, he, he claims he'll only play it for like, uh,
you know, high, high stakes. So yeah, if I recall correctly, he tried to bet Joe that he was going
to try to bet Joe that he could pick the, pick the lineup for the next week. And Joe was like,
yeah, zero chance, zero chance. I think Joe told him there was nothing he had that was worth.
Yeah. Um, probably a wise decision on Joe's part on that one. Um, and so, um,
at present, I think Brian has come back and been, been sort of CEOing things, etc.
Which is great. Um, good. I'm glad, glad to hear signaled signals doing well. Um,
how are you enjoying back being back in Austin, by the way?
Uh, it's great. I mean, I, I moved back here about the same time I joined Signal. So, um,
I was, I was happy to, to return back to, to Austin. I mean, I went to school here and I'd
been out in the Bay Area since then. So I was happy to return. Yeah. The Bay Area is a,
I'll just use the word interesting place. Well, you know, it's, it's one of the things
you always hear about Austin is how bad the traffic is. But after you've lived out in the
San Francisco Bay Area, you're like, Austin traffic is not that bad. I mean, Mopak can get
pretty jammed, but it's not like one-on-one in the, in the morning in the San Francisco Bay Area.
Having lived in the Bay Area and LA and Jakarta, Indonesia, Austin traffic is nothing, nothing,
zero. I could drive literally home backwards in this traffic. It's not an issue. Um,
I remember being like stuck for like three and four and five hours in Jakarta traffic.
Yeah. Um, some monster stuff, couple hours in LA. Have you ever been to, uh, Sao Paulo?
No, I've been to Rio, but not Sao Paulo. Is it rough down there? Sao Paulo is probably the
worst traffic I've ever seen. I, like, uh, I was in a car there. We took about an hour to go three
miles. It was like, at this point, like walking would be almost be faster. Way faster. Well,
you had luggage, so going to the airport, but still, I don't know. I mean, did it roll because,
yeah. Um, all right. And then, um,
is it, is it sort of surreal to, to, to move back to Austin? I mean, you went, you went to college,
you went to UT. How come? Nice. Um, so is it sort of surreal to move back here after going,
going to college when you did? I mean, as I understand it, the town is completely different.
I mean, I, I moved here in like early 2019. So, um, I visited here when I was in 96,
so, so way back and the city is, I don't recognize it at all. Um, but when you went to colleges,
I mean, that was, that was only for, for like a month or two, but you, you, I mean, you were,
you were here four years, right? Yeah. Is it completely different? Um, in some aspects,
yes and some no. I mean, uh, the, the city is largely, um, largely laid out the same. Things
are kind of generally like, uh, where people live, where they commute to are, are somewhat the same,
but there's been a lot of development in the last, uh, you know, 15 years or so since I went to
university here. Uh, for example, when I was in university up on the north side of Austin,
where the domain is now, uh, is kind of a, um, built up semi second downtown almost for, for
Austin. It was, um, it was an empty manufacturing building, uh, that IBM, uh, owned and, uh, had,
I had some sparse offices in, uh, in there. Um, so that's built up a lot. Uh, even just around
the university, west campus, uh, the west side of campus and university of Texas, uh, used to be
largely like large single family homes that were used as kind of the, the, the, or the Greek system,
uh, folks were, were living and had their, their, their homes there. Uh, now it's all high rises.
If you go over there now on the west side of campus is 20, 30 story buildings full of apartments.
Uh, so, uh, there's been a lot of development and I recall at one point coming back to, uh,
the university of Texas while I was working for WhatsApp, uh, to recruit from the career fair.
And, uh, taking a picture, uh, southwest from the Frank Irwin center towards the Capitol.
And there is just like, that's only a few blocks, you know, if you know Austin,
that's like three blocks down to the Capitol from there. And in that shot, I have six tower
cranes putting up buildings. Um, so yes, Austin is, is developing a lot. There's a lot of, uh,
tall buildings going on, but, uh, hey, that's great. That's, that's part of one of the problems with
the Bay Area and, uh, is the fact that it doesn't develop. There, there is, uh, pretty much a height
limit of three stories almost everywhere around the Bay Area. And, uh, that's led to a lot of
contention for places to live for people where every city has, uh, uh, uh, an overbundance of
workplaces or offices and no one wants to build anyone for the, anywhere for the people who work
in those offices to live. Uh, so it's, it's great to see like places being built to live in Austin,
even though unfortunately Austin has not escaped the, uh, rise of the cost of living with regard to
the, you know, rents have gone up a fair bit too. So what, again, in your opinion, are we,
are we Silicon Valley 2.0? Are we an offshoot? Are we an alternative? Like what's, what's,
what's going on? What do you, what do you think is happening? The reason I ask is if I recall
correctly, there's more than a few companies that have moved here. Didn't Oracle move here?
I don't know. I think Oracle might have moved here. I know Tesla did. Um, but yeah,
there's more than a few, few, uh, Bay Area companies who actually got out of there and
ended up moving here. Um, and, uh, people are loving, I mean, you know, there's no state tax,
et cetera. What, what, what's your feeling? Like what is, are we, are we sort of like Silicon
Valley evolved or for that matter, maybe de-evolved, depending on how you look at it? Like what does
that, what does it look like from your perspective? Um, yeah, I think there's sort of a growing, uh,
industry here. Like the industry's moving here. Like, you know, parts of it are, are certainly
moving here. And to some degree that's been going on in, in bits and pieces for, for a long time.
And that's part of why over the past 10, 15 years, there's been so much development. Um, but I, I do
think the, the, the pandemic era probably helped accelerate that. It was, uh, sort of, there was
already a bit of a fire, uh, burning with regards to things moving here. And then that was basically
gasoline dumped on that fire. It, uh, it, it, it helped a lot for, say, company like a Tesla.
I mean, part of the reason he moved here is because there was so much pressure to keep the,
the new me plant in Fremont closed, uh, that was making their vehicles and they're an automobile
company. If you close down their manufacturing plant, they've got no business. Um, so yeah,
I think that was part of the incentive for, uh, him moving here. And I think there were other
businesses that likely made similar calls, especially when you consider, I guess,
yeah, I didn't really think about that for the automobile business, but I guess, I guess when
you consider that he effectively has no inventory, like every car he builds is, has been sold, all
of them. Um, so yeah, a shutdown is literally no, we're shut all the way down. We're not making
anything. Yeah. Um, okay. Okay. And if you remember the articles at the time, he got in kind of a
pretty public fight with, uh, uh, some government official in the Bay Area. I forget which one.
I, I, I don't, I don't remember. Too busy digital banking at the time. Um, okay.
So before I, before I ask you, uh, before I ask you the ultimate question before that,
do you want to tell our listeners, like, is there any way to find you? Like, do you have a,
you know what your signal or username would be if they ever want a message or like,
are you active on anything like, you know, LinkedIn or Twitter or whatever it is that you'd
like people to follow? Uh, I don't tend to use a whole lot of the public social media products a
whole lot. So, uh, yeah, I mean, I have a Twitter, but I don't really actively use it. Um, I would,
probably the easiest way to reach out to me is basically my, my first name at signal.org is an
email. Awesome. Yeah. Um, but yeah, I mean, even beyond that, um, obviously, you know,
you could just say, yeah, just signal.org in general, just go there, download the app, etc.
Exactly. Okay. Um, the ultimate question, of course, is this,
and you already did this once for us. So I'm hoping you can hack the matrix
and create something in reality again. And that would be,
if you could will a technology into existence, right? And again,
remove your engineer brain from this question because you're allowed to just wave a wand and it
exists. So let's ignore some complexities of what it would take to build. And you can't say
teleportation. I already know where you're going. What, what, what would it be?
Any technology at all, you say? Yeah.
Well, let's see. Last time we talked about this, I sort of went with the quantum
timeline thing that we talked about earlier. That you willed into existence. So nice work.
I think if I were to look at this, uh, at this question and say, like,
what is beyond that, uh, beyond that answer of like,
quantum timeline, providing secure communication between two remote points,
I would say probably the, the area that I would probably wave magic wand at the most,
because I, I would feel the, like I know the least about it would probably be sort of the
biotech space. And if you look at, uh, some of the things that are happening there,
it feels like it's on pretty early stages, uh, of like figuring out how to, uh, work with, uh,
genetic code in a way that we haven't been able to, to do before. Yeah. Um,
and so if I were to just wave a magic wand at this and say, like, um, whatever you could, uh,
you could come up with, uh, I would say that you probably want something that is, uh, more
efficient at editing the code, uh, the code of life, the genome, if you will, uh, then say
CRISPR. I think CRISPR is sort of the best technology that exists for that today. If you
could come up with a way to edit it in the same way that we sort of edit, uh, source code for
computers, um, that would be a pretty powerful tool and I think it would unlock a lot of, uh,
it's sort of a double-edged sword though. Sure. Um, so it's a risk, but I think that the benefits
would probably outweigh the, uh, the cost with, with that. So, um, that's probably what I would, uh,
go with just thinking about what's my, my next answer beyond. Sure. I mean,
effectively, like you could turn off genes where you've, you've got, you know, a, a, a, a, a, uh,
predisposition to cancer or, you know, something of this nature. Or if you could do targeted
editing of certain cells, uh, I mean, you could, you could go in and like turn off the cancer. I
mean, what you're looking at with, with things like cancer is like cells that are replicating
beyond where the, the amount that they're supposed to do to some sort of damage in, in their internal,
uh, mech, mech mechanisms. Right. Yeah. Uh, that's, that's actually a, yeah, I love that answer,
by the way. Um, that might be my answer now. Oh really? Okay. That's a pretty damn good one.
What was your answer before? Now I want to know. Oh, mine's teleportation. I get to
cheat. You don't. You get to choose teleportation. Okay. I get to cheat. You don't. Um, but yeah,
no, that's, that's a really good one. Um, I, uh, um, I don't really know a lot about CRISPR.
Uh, it's, uh, it's interesting. I wouldn't say that I know a whole lot about it either,
other than I've seen some articles talking about it. And that's, that's really good.
I believe, uh, if I remember correctly, I believe it was like a bit of, uh, of protein harvested
from a virus, I believe. And it actually allows you to like pattern target certain segments of
DNA and have this thing go along the, the, the chain of DNA until it finds this pattern and
actually cut it there, put it in a replacement and move on. It's sort of like a patching tool.
Whoa. Um, and so that's, that's been kind of an interesting thing to hear about. It's been
a number of years now since that came along, but it kind of, it sounded like it was, uh,
going to unlock a lot of possibilities. I haven't heard more about it since then. So I don't know
if it's not been as promising as it was originally made out to be, or if it's just, it's not efficient
enough or hard enough. So hence why I wave the magic wand and say, uh, some way for the people
who are working in biotech to just edit that as efficiently as we edit source code and software.
Yeah. It's, it's odd. Um, when I was out, when I was in sixth grade, so what was this 1990 or
whatever it was, maybe 91, um, we were learning about HIV and AIDS. We were literally learning
about like, what is a, what is a retro virus? What does this thing do? And you know, it was, oh, well,
uh, what it does is it, you know, it goes into your immune system and attacks, uh, it attacks the
T cells, which is crazy because those are actually your fighter cells. So it doesn't actually kill
you, but it just, you have effectively no fighting cells left in your immune system. So some, like
a common cold will kill you. Something will kill you. Um, I think a lot of times it's pneumonia
or something. Regardless, um, I remember hearing about that. And then I remember the same year,
they were also talking about genes and like that in the future you could edit these genes,
et cetera. And I remember putting these two concepts together in my head and going,
why can't you just take again from someone who knows very little about this, but why can't you
just take this AIDS via HIV or whatever it may be? Why can't you just take that and have it
basically look at cancer cells instead of T cells, invade the cancer cells and explode them
just like you do the T ones, but effectively mask it. And I come to find out, um, that a buddy of
mine, what was it? Uh, he was getting one, one of the, not one of the very first, like one of the
first wave of treatments, um, he has, uh, he has cancer in his neck. Um, and he's getting literally
anti retro viral treatments, uh, or maybe not, it's not anti retro viral treatments where he
effectively gets injected with a retro virus and it targets directly targets the cancer cells.
His, I believe he went from like, you know, you've got three years to like you've now,
I think he has now 25 years. Wow. Right. Crazy. Yeah. Like really crazy. I think it's inoperable,
et cetera. But like whatever type this is apparently responds extraordinarily well to this retro
virus, uh, treatment that they've got going on now. So, um, it'd be really interesting to see
what they, you know, what CRISPR could do and how it could do that. Yeah. Um, such that it would
be like, yeah, I mean, could we just do this for everybody so that everybody gets like a targeted
thing that would target whatever is in their body and just, you know, annihilate it type of deal?
Well, as I understand, that's the hard part is the targeting because a cancer, at least the,
the kind of cancer that, that grows and becomes a threat to you is, it's you. Like those are,
those cells are your cells. And so how do you target them without also targeting the normal,
like healthy tissue? And that's the hard part. You have to find something about them that you
can target and then build something that like the, um, molecular level that targets that.
And so that's probably pretty tough. Yeah. You're talking about, uh, on a scale that, uh, you know,
we have, we have, uh, machine, uh, processes now for making silicon chips, like in these machines
that, uh, is down to like two nanometers. You're still talking about, uh, a significant difference
between that and like the size of molecule. That's, that's true. Although I still don't
understand how they're going to get to two nanometers and not actually have literally
molecular problems holding the, the, the boards together and whatnot. I don't, I still don't
understand how that's possible. Yeah. I think those problems are definitely problems they're
having to, to overcome because at five nanometers, we're pushing it at three, we were really pushing
it to nanometers. Like you, the molecular bonds even going to hold up on these chips. I don't,
anyway, it's not my problem. Um, all right. Um,
yeah. I mean, the, the CRISPR stuff is, is, is pretty dang interesting. Is there anything else
you want to sort of say or expand upon that? Oh no, I would, I'm not at all an expert in that.
That's just like an interesting area that I've, I've, I've read a little bit about, uh, and it's
kind of like fascinated with the idea that like someday we, we might be able to, uh, do more editing
there. Absolutely. All right. Well, Aaron, this has been amazing. Thank you so much for coming
on. I really appreciate you, buddy. And, uh, for those listening, we have been standing on the
shoulders of giants and I'm David Mackay. Thank you
