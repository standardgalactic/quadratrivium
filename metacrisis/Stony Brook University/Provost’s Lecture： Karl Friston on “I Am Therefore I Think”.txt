I'm really delighted to see that we have, you know, filled the entire house.
So welcome, one and all.
Welcome to this iteration of the 2019 Provost Lecture Series.
Today we're thrilled to welcome Professor Carl Friston, the Principal Research Fellow
and Scientific Director of the Welcome Trust Center for Neuroimaging, as well as Professor
at the Institute of Neurology at University College London and a Consultant at the National
Hospital for Neurology and Neurosurgery in the United Kingdom.
So this talk is sponsored not only by the Provost's Office, but it's also sponsored
by the Center for Neurocircuit Dynamics at Stony Brook University, the Department of
Neurobiology and Behavior, as well as the Department of Psychiatry at Stony Brook University.
So welcome, Carl, on behalf of all of us, and we're delighted to have you here.
So the, and as well, we are welcomed by my own organization, the Institute for Advanced
Computational Science, of which I'm the student president.
And the ICS, the Institute for Advanced Computational Science, really tries hard to make sure that
we invite speakers whose work touches on a wide variety of perspectives.
And Carl really embodies that ethos.
So it's really hard to define an area of research where Carl's methods haven't influenced,
right?
So Carl, for example, is the inventor of statistical parametric mapping, voxel-based morphometry
and dynamic causal modeling, all motivated by schizophrenia research.
His mathematical contributions include variational Laplacian procedures and generalized filtering
for hierarchical Bayesian model inversion, as well as contributions in theoretical neurobiology,
his most famous contribution being the free energy principle for action and perception,
which I expect will feature heavily in today's talk.
Okay?
Professor Friston also holds honorary doctorates from the universities of York, Zurich, and
Radboud University.
He's a member of the Academia Europea, a member of the European Molecular Biology Organization,
the Royal Society, the Academy of Medical Sciences, and he was president of the International
Organization of Human Brain Mapping.
He's the first recipient of the Young Investigator's Award in Human Brain Mapping.
He's a recipient of the Minerva Golden Brain Award, received a medal from the Coll√®ge
de France, received the Weldon Memorial Prize and medal in 2013 for contributions to mathematical
biology, and most recently he was the 2016 recipient of the Charles Branch Award for
unparalleled breakthroughs in brain research, as well as the Glass Brain Award, which is
a lifetime achievement award in the field of human brain mapping.
More recently, Friston's work has been on the models of functional integration in the
human brain and the principles that underline neuronal interactions.
So today we're very happy to welcome here to talk about this subject and more broadly
on the topic of I am, therefore I think.
So please join me in welcoming Professor Friston.
Thank you for that lovely introduction.
I told him he could say three things about me, and there are 30 things.
It's always a pleasure to hear them there, thank you.
It's also a great pleasure to be here.
You have one of those beautiful parts of America I've ever visited.
It must be gorgeous working here.
I've also enjoyed meeting hundreds of you.
I have to say I'm absolutely worn out now.
I've met so many interesting people, heard so many interesting things and been asked
so many difficult questions that forgive me if my brain's starting to slow down for this
lecture.
This lecture is really a survey, a backstory to a trend in the cognitive neurosciences
of the past decade or so, which is a move towards understanding the brain as a statistical
organ, a predictive processing machine.
So what I want to do is just cast for you the main elements of the backstory as would
be articulated in the first half of a talk by a physicist and in the second half of the
talk by a neuroscientist.
Now I'm doing that because I am aware that I'm speaking to a very eclectic and possibly
informed, more informed than usual audience.
So I will have equations in case you're worried, it's going to be too back-story-ish.
So here's the overview of the talk.
I'm going to just discuss the properties that systems must possess if they exist, and by
exist I mean show some form of existential invariance of the sort we associate with living
systems.
I'm going to illustrate and demystify some of those principles using numerical analysis
simulations of a primordial soup, just to evolve a little creature and ask some questions
about the nature of its behavior and how we can understand that behavior.
And then I'm going to turn to the point of view of a neuroscientist, and I'm going to
tell exactly the same story, but this time as a neurobiologist and talking about the
anatomy of inference, bringing in predictive coding implementations of these principles
and how they might be implemented by neural networks.
And then finally, if we have time, and I'm going to get a helpful hurry-up sign from
my host if we run out of time, I'm going to justify the use of the quirky title.
I am therefore, I think, or I think therefore I am, whichever you prefer.
So we're going to make the final move, which is really rehearsing the same principles,
but now under a prior belief that I am the sort of creature that exists and therefore
must conform to these principles, and we'll conclude with simulations of visual foraging
and epistemic affordance.
So let's start.
I'm going to start with a question posed by Schrodinger.
How can the events in space and time, which take place within the spatial boundary of
a living organism, be accounted for by physics and chemistry?
I'm not going to answer that question clearly, but we'll pick up on the notion of a spatial
boundary and just note that in order to talk about anything, you need to be able to demarcate
or distinguish, disambiguate, the thing from something else or nothing, and that really
is the role of the boundary that separates the thing from the non-thing.
And Schrodinger will be the first person to acknowledge that this boundary was, in and
of itself, a probabilistic, stochastic quantity.
So I'm going to take that boundary to be a Markov blanket.
So at this point I normally ask, can you put your hand up if you know what a Markov blanket
is?
Good.
Can you tell your friends what a Markov blanket is?
No.
You could have been clever and used the excuse that you haven't got the microphone for the
recording, but I think it's just shyness.
Anyway, what he would have told you, what he would have said, was that, well, let's take
this graphic here.
Let's assume that this is a description of some little universe, and all these circles
here denote states of any abstract sort, and the edges, the arrows denote an influence
of one state or over another state.
And let's just take some internal states of interest, and the Markov blanket comprises
those other states that in a statistical sense insulate, blanket, render insular, the internal
states from the external states.
And by that I mean that if I wanted to predict the internal state based upon the rest of
the universe, I would only ever need to know these blanket states.
And technically they're defined in terms of the parents, the children, and the parents
of the children of the internal states of interest.
So a very simple definition just in terms of conditional dependencies or influences
or some adjacency matrix on this graph that provides a set of states that separates internal
from external.
Now, only about 25% of you put your hand up, and I said, what is a Markov blanket?
In fact, you do all know what a Markov blanket is.
So any of you that have worked with time series or Markov models or Markovian processes have
implicitly been using the concept and know the concept of a Markov blanket.
So if you just think of these states being states of the universe in time, then the Markov
blanket is just the present moment in the sense that everything I need to know about
the past that informs the future under a Markovian assumption is in the present.
So the present provides a Markov blanket that statistically separates the past from the
future.
So that's all this means.
All that we're doing here is generalizing that notion to any arbitrary set of states
that can be articulated in terms of their dependencies and influences in this form here.
I'm going to make another distinction, which will become important later on, and I'm going
to make a bipartition of the set of states here into sensory states that are not influenced
by internal states and active states that are not influenced by external states.
Just to motivate that distinction, what I'm going to invite you to do is just to think
about these conditional dependencies, this causal statistical architecture in the context
of things that we all know and love and sometimes study.
So these blanket states comprise the active and sensory states that separate external
from internal states.
What I've done here is just rewrite that dependency graph in a form that as a neuroscientist you
recognize, as a cellular biologist you recognize, where we can associate the internal states
with every state of the brain, though I'd need to list in order to say this is the state
of the brain at the moment, all the synaptic efficacies and activities and connection strengths.
The active states could be the states of all my muscles, my autonomic reflexes, my motor
system that cause changes in the external states that produce sensory impressions upon
my sensory states, my sensory epithelium that subsequently change my internal states to
induce changes in action and so the cycle unfolds.
I use the word cycle deliberately here because what we have is just a statistical statement
of some form of action perception or perception action cycle.
Exactly the same dependency structure can be found at the cellular level, so we have
all the intracellular states that could constitute a little cell here.
We can associate, say, the active states with the actin filaments that support and provide
motility to the surface or sensory states of a cell with receptors that are in receipt
of influences from the external milieu that in turn affect the internal states that affect
the cell motility.
This structure just rests upon the absence of two conditional dependencies that define
the active and the internal states, an absence of an influence of internal states on the
sensory states and an absence of the influence of the external states on the active states
and that's it.
That's all you need to define something that can be separated from something else.
So what I'm going to do now is to ask you just to forget about the Markov blanket for
a moment.
What we're going to do is just quickly run through the dynamics of stuff that exists and
then what we're going to do is to put the Markov blanket back in play and see what interpretations
follow from the existence of a Markov blanket under more generic principles of self-organization.
What I've cartooned here is a state space, there's two states here, and we have some
system, say me, and I'm in one state at any one particular time and I trace out a trajectory
or a path through my state or my space here and as time unfolds, I habitually revisit
or systematically revisit neighborhoods of states that I have been in before.
So you can think of this, say for example, I'm getting up in the morning, I'm having
my cup of coffee, I do my emails, I do the morning work, I have lunch and so on, this
could be my daily cycle or it could be my cardiac cycle with sisterly and dastily as
I circulate around this attracting set, this attracting manifold, crucially returning to
the same state of being periodically in a very itinerant way, this enormously complicated,
very high dimensional attracting set, but it must exist in the sense that I exist in
the sense that I have measurable states that I keep on returning to define the sort of
system or the thing that I am. Technically this would be a pullback or a random dynamical
attractor, I'm just going to refer to it as a set of attracting states that must be there
if something exists. Now the reason I'm going on about that is that there's a lot of machinery
which some of us will know and love that is apt for describing some of the fundamental
dynamics that must be in play if this attracting set is in play. So here I've just written
the long van description of this system in terms of motion which is equal to flow, dependent
upon states plus some random fluctuations omega. I can describe not just the flow on
this attracting set but interpret this flow in terms of the probability that I would
be in this state if I was sampled at random at a random time in terms of a probability
density and I'm going to associate that probability density with the source of states that I'm
in when I have attained or settled down to my attracting set when I am in non-equilibrium
steady state. And if I do that, that means that this probability, the probability of
being in a particular state given me is described by the density dynamics where I change the
probability of my states given me and I can write that down using the Fokker-Pank equation,
the master equation, the Comber-Rofts forward equation, whatever you want to describe this.
Interestingly, it will transpire also to be the scrolling away equation. And I can write
it down as a function of the amplitude of the random fluctuations and the gradients
of this and the flow and the probability distribution. If you don't know what this means, don't worry
about it. It's just something that has to apply if this attracting set or non-equilibrium
steady state exists. The key thing about it is that I know that once I settle down, this
is zero. And if this is zero, that now allows me to write down the flow as a function of
the gradients of the log probabilities of states of being that I am typically in, given
the amplitude of the random fluctuations and the solenoidal component here, q, which is
an anti-symmetric matrix. So this is going to be quite crucial. It's basically if I exist,
my dynamics, my flow, must satisfy this equation. And this equation is a functional or a function
of a log probability, which is just the sorts of states that characterize me. For those of
you who don't know this formalism, I'll just very quickly go through in a more intuitive
fashion. Imagine that I place a drop of ink in a cup of water and due to the random thermal
fluctuations, the molecules of that ink will disperse themselves throughout the solvent.
So I would expect to see for a system that wasn't going to attain any form of steady
state equilibrium or otherwise, the ink diffuse until the concentration is uniform everywhere
in the solvent. That is not the characteristic of the systems that are interesting us. What
we are talking about are systems that do this. I drop the water in and then it seems to the
oil ink and it seems to gather itself up. So it gains this non-equilibrium self-assembly
as if the molecules are flowing up probability gradients. It's like a reverse diffusion.
It is exactly that particular dynamics that solution to the Fokker-Planck equation describes.
So if we associate the concentration of the ink molecules with the probability distribution,
then what we're saying is we can understand these two components of the flow as basically
this gradient flow climbing up probability or concentration gradients and this solenoidal
or divergence free flow as flowing around the isocontors here. In particular, this gradient
flow that I want to drill down on, it is there in order to exactly balance the dispersion
of the random fluctuations. So I'm not talking about detailed balance, I'm talking about something
much more general that if I have attained non-equilibrium steady state and I exist in
that sense, then it must be that on average my flow is exactly countering the dispersion
of my non-equilibrium steady state probability distribution. So that's good. Is it interesting?
It is very interesting as the godfather of most of physics. So that solution in particular
the Fokker-Planck equation underwrites or you can coerce it to underwrite classical mechanics
and quantum mechanics. So for example, we can set the amplitude of those random fluctuations
to zero and what falls out of that solenoidal flow because the gamma part, the gradient flow
has gone away is just classical Lagrangian mechanics and Newtonian laws. We can go to
the other end of the scale and ignore the solenoidal bits and just focus on the random
fluctuation and all the interesting behaviors that one gets from random fluctuations that
do not, cannot see these probability gradients, they just pass through potential barriers
for example. And then what we get from that is basically a formulation that ends up with
things like the fluctuation theorem, fluctuation dissipation theorem and stochastic or for
ensemble statistical mechanics. We can just look at the square root, complex square root
of that non-equilibrium steady state density and treat that as a wave function and then
the Fokker-Planck equation writes itself as a Sprodinger equation. What we're going to
do though is consider another sort of mechanics that rests explicitly on the Markov-Planck
it. So that's the move here. We're just taking standard physics and saying what would it
look like if there was always a Markov-Planck it there. And that brings some interesting
things to the table. First of all it means that there are two sets of dynamics that pertain
to the internal states and the active states that look as if they're doing gradient flows
and they have a purpose and furthermore we're going to interpret a bound on the thing that
they are flowing on in terms of a variation free energy. So that's the basic story. I'm
just foreshadowing or foregrounding that story as an extension. It's entirely consistent
with and complementary to things that we have been taught at school. So that's our gradient
flow, the solution to the Fokker-Planck equation and this is the same solution but now just
written down in terms of the states of a particle where I'm assuming that a particle
comprises the internal states and its Markov-Planck it that has active and sensory states and
I'm focusing on the active states here. And because of those independences I only need
to concentrate on the probability of the blanket states, the sensory and active states. So this
is the solution to this non-equilibrium steady state that must be there describing the flow
of internal and active states. And the interesting thing here is that both look as if they're
trying to optimise or maximise the same quantity and that's the gradient of the log probability
of the blanket states given the system me in question. And the story is going to be basically
that we can look at this mechanics as perception and the flow of active states in terms of
action. And what licences me to say that? Well, just the form of that equation makes a lot
of sense from the point of view of many, many different perspectives in psychology and the
life sciences. So I'll just briefly run through a few of them and you will know this stuff
or at least one or two of these things. Just so you can see how I've joined the dots from
the point of view of motivating the central importance of this log probability up here.
So we've just said that these describe attracting states. So the great of the probability of
being in any attracting state or blanket state here means those are the sorts of states that
I'm attracted to that I will be typically found in. Basically they can be construed
as having value for me, the things that I aspire to or that attract me. And what we're
saying is basically that both perception and action are in the game of maximizing value.
And on that reading, we can spin out things like reinforcement learning, optimal control
theory, and indeed if we're doing economics, it could even be expected utility theory.
That's nice because the negative of this value is known as self-information, information
theory. Tribe is called it's surprise, or I'm just going to refer to it as surprise.
This is the improbability, the negative log probability of being in some state. Incidentally
that's the quantity that's going to be upper bounded by the free energy. So I'm going to
use free energy synonymously really with this surprise or surprise. So what this says is
that systems that possess a Markov blanket and have attained non-equilibrium steady state
are basically trying to put an upper bound on surprise. And from that we can understand
things like the infimax principle, principles of minimum redundancy, and indeed the variational
free energy principle that we're going to be talking about. That's nice because this
thing here, when taken in expectation or the average of this over time or over the path,
is entropy. So what we're saying is that this dual minimization of this quantity here,
this surprise, is just a statement of self-organization. It's putting an upper bound on the dispersion
or the entropy of the disorder of me. And that's how you might understand it as a physicist
or from the point of view of synergetics. Of course if you're a physiologist it's just
a statement of homeostasis. That's all we're saying. We're just saying that systems that
persevere, endure in a changing world are those that keep their physiological states
within viable bounds. They gather themselves up and place bounds upon that dispersion.
The final interpretation, which is the one that I want to leverage, is from the point
of view of a statistician, this probability here is just the probability of some sensory
or blanket data condition. Now not upon me, but if I treat me as a model of those data,
this now becomes something called model evidence or marginal likelihood. And it is the holy
grail in terms of the quantity that you want to optimize when doing Bayesian inference.
And if we take that interpretation then what we are saying is that this is equivalent to
saying that we can understand, say the brain did this as a Bayesian brain, we can understand
that in terms of evidence accumulation and indeed predictive coding. And that's the story
that I'm going to try and tell you for the remainder of the talk. Before I do say that,
I promise you that I'll try and demystify some of the behavior entailed by that formulation
of non-equilibrium steady state using simulations. So here are the simulations. What I've done
here is take 100 and so little macromolecules, synthetic macromolecules, equip them with
autonomous dynamics like a little, creating a little active super active matter, and then
couple them with strong and weak forces, strong repulsive forces that depend upon the spatial
distance and weak electrochemical coupling here. And just let them self-organized and
fold, settle down onto their attracting set. And once I've done that, I've created a little
universe where crucially I know all those dependencies and I know all of the dependencies
that would otherwise define or that would define the Markov blanket. So I can now go
in there and search for the Markov blanket and ask is there a little creature living
in the middle of this little soup? And if I identify the eight most connected states,
I can then using the dependencies encoded by the JCC matrix here, find the parents,
the children, and the parents of the children, and identify this little synthetic creature
with its internal states encoded in blue, the active states surrounding it encoded in
red that support the sensory states of magenta that then separate the internal states from
the external states in cyan. And it sits there happily wiggling away, wagging its tail, could
be like a little psyllium here. Now I've simulated that thing that has a Markov blanket, I can
now ask, well, is that self, that Bayesian interpretation of the dynamics that must be
there given it's now settled down to non-equilibrium steady state? Is that a viable description
of the behavior of this little synthetic creature? So in other words, are there any attributes
or states of the configurations of internal states that in some sense model or predict
the states on the outside? And it's very simple to show that, yes indeed, that has to be the
case and it is the case. So here's a numerical example of that. What I've done here is just
taken a mixture of time lagged internal electrochemical states and asked what mixture best predicts
some mixture or some motion, physical motion of the external states. And these are the
internal states and here in the solid line is a prediction and the dotted line is the
actual velocity of these external states. So if you're a neuroscientist you can imagine
this is a simulated visual motion experiment. Are there any internal electrochemical fluctuations
that predict or are predicted by changes in visual motion out there that I cannot access
directly but I can do through my sensory epithelial and my retina? And you can see that not only
is there a correlation but you can actually pick up events and even see them in terms
of the internal fluctuations here as highlighted by the white arrow. The reason I've shown
this example is if you look closely you can see that the internal states actually predate
this rapid expulsion of this external state a little bit like a solar flare and then it's
pulled back again. So the internal states are not really seeing the external states it
looks as if they may also cause in terms of temporal precedence the external states that
may be causing the internal states. The question is what's causing what? Let me ask a question
that is a question. Are the internal states causing the external states or the external
states causing the internal states? What? It is very much a jib and a leg. Which side
do you want to come down on? The very fact that you're teasing me with a flipper down
so it means you know the right answer which of course neither. This is just an instance
of what Huygens noted centuries ago of generalized synchronization of chaos or generalized synchronization.
This is the story where you have old fashioned clocks that are suspended from the same wall
or the same beam and inevitably their attracting set requires them to be on the same synchronization
manifolds so they will eventually come to swing in synchrony inevitably. And that's
all that we're seeing here. We're just seeing a completely symmetrical synchronization of
dynamics in virtue of them both the outside and the inside being conditioned upon the
Markov blanket. It can be no other way. Which is an interesting picture so in fact this
is a picture that he actually drew of his two clocks with the beam here. So from our
point of view one clock would be the internal states, these could be the external states
and the beam is the constituting the blanket states. And one interesting aspect of this
is it shows you the symmetry of the mathematical argument here so I have had an interesting
conversation this afternoon what this symmetry means and what it means is if you subscribe
to the view that the dynamics here are all about inferring what's going on over here
then the converse has to be true. That means that the environment is trying to infer and
to learn about you as much as you are trying to learn and infer about the environment and
our conversation went right through to evolution and eco-niche construction so it's not a
silly view and it's certainly a mathematical truism. Anyway so that's all the heavy lifting
that's all the hard part done. Just to summarize what we said so far the existence of a Markov
blanket necessarily implies a partition of states into internal states, the blanket sensory
and active states and external or hidden states hidden behind the blanket. And because active
states change but are not changed by external states they minimise the entropy of the internal
states and their blanket and this means that action will appear to maintain the structural
and functional integrity of the blanket and some people have written about that in terms
of auto-poesis or self-assembly and the like. Internal states appear to infer the hidden
causes of sensory states by maximising Bayesian model evidence and influence those causes
through action and I'm going to refer to that as active inference. So just different takes
or losses on something that is necessarily there if you exist and you have a Markov blanket.
Oh I've forgotten about this. This is something that one of my visiting research fellows sent
me not last weekend, the weekend before. So for those of you who think the Markov blanket
is some abstract mathematical concept, it is not. You can buy them in America. So this
is Francis' little baby, Kira, two months and two weeks old now and this is what his
wife bought him so that's actually Markov circa 1858 I think, keeping her states warm
and she makes her inferences. So as promised what I'm going to do now is just rehearse
but using a different rhetoric, the same story as if I were giving a lecture or talking to
neuroscientists and I'm going to now say well what this means or what it would look like
is that things that have brains will appear to be little constructive organs, statistical
organs that will always appear to trying to infer, predict and model what's going on beyond
their sensorium and this is beautifully illustrated by this 16th century oil painter who was known
for painting still lives that when viewed from another perspective have a very different
interpretation, you immediately have a very different hypothesis about what caused that
particular pattern of sensory input. So if you now see a face there where you didn't
before, the key thing is you made that. That face was on the inside. So the argument here
in contrast to the 20th century view of sexual synthesis and in particular some visual inference
is that it is not an outside in process. It is not as a series of clever filters or
extraction devices. It's very much an inside out process that you have a hypothesis that's
in there and you submit that hypothesis to the sensory evidence and then reject or accept
that hypothesis if you can predict what's going on. That's the basic idea. It's a sort
of strange inversion of a denit like sort of 20th century thinking about perception.
So it's a much more constructivist one that speaks to the sort of circular causality that
was seen from the physical perspective. So this idea is not new. You can trace it back
to the students of Plato. So here are some of my favourite intellectual architects of
this style of thinking. Probably best articulated by Helmholtz. For example, objects are always
imagined as being present in the field of vision as would have to be there in order
to produce the same impression on nervous mechanism. So again what he's saying is you
have to have the hypothesis, the model, the internal dynamics that would be able to predict
what I would see if that was actually out there. Otherwise you can't perceive it. And
this of course is very closely related to Richard Gregory's notion of perception as
hypothesis testing that literally we palpate the world and we'll see an example of this
in the final slide with our eyes. We visually palpate the world to garner, gather evidence
that confirms or disconfirms our beliefs about what's out there causing our sensory impressions.
And these ideas have been taken to use a great effect by people in machine learning. Geoffrey
Hinton and Peter Diane came up with the Helmholtz machine and borrowed the notion of variational
base or variational free energy minimization developed by Richard Feynman, Quantum Mechanics
in the setting of a sort of Bayesian formulation of probability theory to use these ideas that
are still being used in various incarnations, for example variational autoencoders in deep
learning, to great effect in terms of inferring on classifying and recognizing.
Let's go back to Helmholtz and the notion of an impression on the nervous system. So
for us that's basically this sort of sensory impression on our sensory blanket or sensory
veil. So if this inference perspective is right, what this means is that we have to
explain how our brains can take these sensory impressions and from them derive an explanation
as to what causes. So what's behind, what's hidden behind this sensory blanket? And of
course the answer, we've already got the answer, it's just the solution to the Pocaplanck
equation. So what would that look like if you were a neuroscientist? Well I've actually
written it down in a way that you'd recognize if you were an engineer doing time series analysis
here. So what I've done is written down this gradient flow that we've established as the
solution to the non-equilibrium steady state. I've just swapped out the log probability
with this free energy bound on the log probability but we don't need to worry about that at the
moment. So now we're doing a gradient flow on variation free energy and I've just rewritten
these two gradient and solenoidal components in terms of a divergence free update where
mu now stands in for the internal states and I've rewritten the free energy here in terms
of prediction error weighted by their precision or the square prediction error weighted by
their inverse variance or prediction here. Now the reason I've done that is that that is a
Kalman filter where the precision now plays the role of a Kalman gain and the way that
these things work is that they gather evidence to infer the hidden states of the causes of
sense data based upon a prediction given what they believe there, so their expectations. So
let's take mu now the internal states to encode a belief, namely the expectation about what
will happen next, so this is a derivative operator so describing the change in the states
and an update term based upon a prediction error. Now what is a prediction error? Well let's just
say we have this sensory impression here this shadow and we have this hypothesis encoded
by our internal expectations say neural activity that it was caused by a howling dog and if
I had a model or a generative mapping between my expectation of the causes and the sensory
consequences of that cause say g to generate the consequences from the causes I could simply
compare my predictions with what I'm actually sensing to generate a prediction error and
that means that we can understand this gradient flow that must be there in terms of updating
my expectations to minimize prediction error and if I can do that successfully I always
then have an adequate explanation for my sensorial. Crucially it doesn't actually have to be the
correct explanation so it might not be a dog but I will never know that and I never need
to know that provided I can always keep my prediction error so my explanation for the
world is perfectly or sufficiently good provided I can always get that prediction error precision
where to prediction error minimize or upper bounded or minimize the generalization of
that which is this variational free energy that itself is a bound upon this surprise
or self information. So that's the basic idea it's nice because it provides a very simple
perspective on the intimate relationship between action and perception. If everything is in
the game of minimizing prediction error then there are we have a nice way of understanding
the two complementary ways in which we can do that. First of all we can change our predictions
to make them more like the sensory impressions and we can think of that as belief updating
in the brain to improve our predictions to minimize the prediction error namely perception
by changing predictions but there's another way of doing it. We can make the sensations
that we sample more like our predictions so we can actually act upon the world to go
and literally palpate it in a way that selectively samples those sensory outcomes that we predicted
a priori and it turns out that that looks exactly like classical reflex arcs both in
motor control theory and also in terms of autonomic reflexes. Basically a servo that
is provided with a like a thermostat that's provided with a prediction at set point and
all the peripheral machinery the action is just in the service of changing the world bring
the temperature back down to the set point just minimizing that precision weighted prediction
error and that's basically what I'm going to try and illustrate in the final few slides.
First of all just to say if this is going to work then we have to make realistic predictions
of our sensory impressions and clearly the sorts of impressions that we are subject to
are deeply structured very dynamic which means that our generative models that are used to
generate these predictions to form the prediction error are going to have to be in turn deeply
structured basically deep models but also dynamic there will be deep dynamic generative models
and clearly that's nice to hear if you're a neurobiologist because that's exactly how
the brain is organized certainly it hits you in the face if you look at the visual system
so I'll just cartoon that here so we have these two hypotheses or causes if you wanted
to predict some retinal sensory data here what am I looking at and where am I palpating
it and I put these two causes together and I cascade them down ultimately to make some
predictions about the sensory flow that would actually be sampled if these explanations
were correct. So here is a generative process these causes cascading down here to produce
sensory states of the Markov blanket plus the random fluctuations at each point so what
would an inference machine what would self-organization at non-equilibrium state look like based upon
this architecture well it would just have the form of our gradient flow and when I write
that down and swap out the way in which these sensory states were generated with the prediction
errors and the predictions or expectations here what we get is a message passing scheme
that looks very much like what we see in the real brain so the random fluctuations are
now being replaced by prediction errors and the causes or external states are being replaced
by expectations about those hidden states and they still cascade down but they do so
via the prediction errors that crucially now are returned back up to update and inform
the expectations using this gradient flow or Kalman filter or predictive coding equation
here so the picture that falls out for free from that gradient flow interpretation of
non-equilibrium self-organization to steady state is exactly what we see in the brain
this counter stream of ascending prediction errors that induce belief updating or base
in belief updating to provide better explanations that can be returned by descending predictions
to prediction error cells so they are self-cancelling through this recurrent message passing that
is hierarchically composed or arranged here's a quick example for the individual system
system just to sort of put action back into the story so imagine we have some visual retinal
information coming in here gets the lateral geniculate nucleus it's in receipt of top
down predictions from the visual cortex and they are partially good but not completely
so there's a prediction error that gets passed up as the newsworthy information that has
yet to be explained that excites changes in the expectations in the visual cortex but
crucially these expectations are themselves being predicted by a high level so there's
a secondary prediction error and that's passed up and so on and so on to increasingly hierarchical
depth until you've minimized prediction error all levels in the hierarchy and you have a
set of expectations at different levels of coarse graining in space and in time that
provides an account of your sensorium at multiple levels of abstraction I've also put in here
there's another sort of sensory information from the sensory states of the Markov Bank
at the proprioceptive input the status of my muscles myocular motor system now these
could come in they could be in receipt of top down predictions and I could change my
mind about where I am looking but here's where the reflex comes in this is where action
comes in there's another way in which these particular prediction errors can be minimized
and that's if they couple straight back to the outside world through the active states
so all that means is if I register there's a difference between my sensed stretch of
my muscle and my predictive stretch of the muscle then I will contract or relax the muscle
until the sensations match the predictions so what I've just described is a classic
thank you a classical reflex arc and we can use that to simulate all sorts of things I
just give you one example really to illustrate the difference between this example and the
interesting thing which justifies the title of this talk in the last couple of minutes
we've just used that hill climbing equation with a particular gerontive model to emulate
or simulate slope suit tracking I won't go into the maths if I can't because there's
a font substitution error here you don't need to know that it's a simple Newtonian mechanics
that describe an interesting model where I believe that the same things that pull a target
around are also pulling my eyeball so we've written into this particular simulated subject
or synthetic agent the prior belief in their gerontive model that causes predictions of
both what they see and what they feel from their eye movements the belief that there's
some fictive invisible point of attraction out there that is pulling a target around
and is also pulling their centre of gaze and if the agent believes this is the best explanation
for its sensory world then it will fulfil those predictions by tracking and also anticipating
the location of the target and which is very very realistic slope suit target movements
realistic to the extent that you can simulate occlusion so this is just a simulation here
with a sinusoidal target here that goes behind an occluder here and then we're looking at
the beliefs of this simulated agent during the periods of occlusion denoted by the grey bars
here and in particular what would happen if I changed the precision of the gain or the
confidence or afforded the prediction errors would it make the sorts of mistakes that people
with schizophrenia make and indeed it does and you can simulate both the psychophysics
and also the tracking of the target in the slope suit paradigm to emulate very very precisely
and in detail the sorts of slope suit deficits you get from a lesion of this sort of active
inference formulation of how we sample our world. I don't want to talk about this is what I want
to talk about in the last couple of minutes I want to talk about active inference and
epistemic affordance so I'm going to make the final move now which is taking us to a more
abstract application of these ideas where I'm going beyond just saying I have beliefs about
the world and I'm going to act upon the world to make those beliefs come true by minimizing
my prediction error. I'm going to say that my generative model now entertains the consequences
of acting in the future and furthermore I believe that I am the sort of creature that will act
as if I have I am minimizing the free energy that will ensue or the prediction errors that will
ensue if I did this or that and I'm now going to select from one policy or another policy
purely in the service of minimizing this free energy bound on surprise. If I were talking to
philosophers what we're saying is basically if I act I must have beliefs about the consequences
of action. So if I have posterior beliefs about action I must have prior beliefs about action
and therefore it follows that what are those prior beliefs well if I am a self-evidence
in creature in other words if I try to maximize my model evidence therefore I believe I behave as
if I am a self-evidence in creature which technically means that I will select those
actions that minimize expected surprise or self-information i.e. free energy consequent
upon an action. So very briefly what happens is that you set up a bunch of policies actions like
where to look next and then you work out technically using the posterior predictive density of the
outcomes if I did that the free energy that you would have got. If you write that down it
actually transpires that it has very intimate relationships with a lot of extant approaches
to planning and optimal control and economics. So the expected free energy has these two bits
to it it's expectation of a posterior predictive density of the sensory outcomes here's the normal
here's the evidence bit and here's a KL divergence. So I'm going to demonstrate that basically in
the context of just choosing where to look next that's basically my space of policies that I have
to select from. So what I'm going to be doing is selecting the place to look next that max
minimizes my expected free energy what does that mean it's basically minimizing expected surprise
which means minimizing uncertainty which means maximizing information gain reducing as much
uncertainties I can by selecting those epistemically rich sensory or what I believe will be epistemically
rich parts of the world that will reduce as much uncertainty as possible about about what I think
is causing it and indeed if you compute this sort of expected free energy it creates salience
maps so we've actually referred to this expected free energy or an important component of it as
salience it's also known as Bayesian surprise and this was just making the point that you can
actually go into this expected free energy expression and just focus in on various mixtures
of its terms and pull out stuff which has been on the literature for decades. So if I ignore
the pragmatic or the prior beliefs my prior preferences I have no preference about what
I'm going to see then what is left is what it in body would call Bayesian surprise what Horace Barlow
would call mutual information. So if I take preferences out of the game then I end up with
basically an informatics or minimum redundancy principle but it's still it's only part of the
story. I can put the preferences back in but I can retain uncertainty about the outcomes of action
and then I get risk sensitive control that people are not able to control theory use
where they minimize the divergence between preferred sensations or outcomes and those that
I predict under a particular outcome so if you're an economist this would also be risk sensitive
choice behavior in economics and I can take the final sort of uncertainty out and I can actually
just get back to expected utility theory or reinforcement learning. So I take all sorts
of uncertainty off the table both in terms of what will happen if I did that and my uncertainty
about the state of the world we get back to good old fashioned reinforcement learning
and expected utility theory and this is the final slide that just shows you the solutions to this
gradient flow with a particular gerentive model where it's just trying to resolve uncertainty
about the causes of these sensations these foveal samplings that you're seeing here
under the hypothesis that could be an upright face a sideways face or an inverted face
and how it's choosing by appeal to this expected free energy or salience map
the best bits of the image to look at to resolve as much uncertainty as it can so with a few moves
it's pretty certain it was an upright face and indeed it was an upright face so I will conclude
by giving the last word as always to Helmholtz who basically said what I've just said but said it
in one sentence each movement we make by which we alter the the appearance of objects should be
thought of as an experiment designed to test whether we have understood correctly the inherent
relations of the phenomena before us that is their existence in definite spatial relations
and with that I just want to thank all the people whose ideas I've been talking about
and of course thank you for your attention thank you very much indeed
questions yeah
so that's a nice gentle question I don't know excitement is the word worry is more and it's
usually worry about the agenda the people that I supervise so at the moment the it seems to be
taken towards natural language processing and natural language understanding the people I work
with the cognitive neuroscientists interested in speech and noise and hearing and recovery of
language function following stroke on the other side of the coin there are people who want to
see if these ideas scale up in a in a commercial setting so they're going off trying to you know
get funding for startups and the like so that that agenda is really finding toy proofs of principle
where you get these sorts of schemes outperforming deep learning and you know open open AI gym
formats and the like so that's that's not exciting but it's worrying I think
so I should also say a large number of my younger colleagues are also come from ecology
and ethology and theoretical biology so they've taken these ideas and made them work in the
context of eco niche construction and mathematical modeling of sort of not selection but the sorts
of processes that you'd see in new wave evolutionary psychology and you know where the cultures come
in and how does this bootstrap into in the inside and the outside states where the outside states
are other creatures like me get into the game of making the world much more predictable and
learnable so that that's also very interesting and I've mentioned already some people might leaven
at Tufts has taken these ideas and seeing if we can use them to explain games and dances and
self-organization active inference at the level of cells and whether that is explanation for
pattern formation in terms of morphogenesis and possibly in the context of neoplasia and cancer
so there are lots of exciting applications but I repeat most of them are just worries are supposed
to excite whether we can keep up or
it sounds like you're describing a certain personality type a lot of researchers are under
that like you know you have to have a hypothesis but I think there's place for free will or the
bone liver poor as in you know yellow submarine yes here's the liver I have no idea what to have
in fact but am I poor liver poor yes so where does the bone liver poor link you know
oh well it lives center stage yeah so
this notion of epistemic affordance that you get from these simulations where this is just
about lever pulling this is basically what would happen if I did if I did that this I think is
one of the most beautiful expressions of this imperative to reduce uncertainty so remember
mathematically free energy upper bound surprise and expected surprise is uncertainty it's entropy
so all that we are saying here is that we are things that act to minimize uncertainty now one
of the best ways to act to minimize uncertainty is to see what happened if I did that so when you
look at the posterior beliefs over the consequences of action what would happen if I pull that lever
that becomes incredibly attractive from the point you know in the jargon of Gibsonian people
the the inactivist movement it has epistemic affordance so this Bayesian surprise or this
sometimes this mutual information if you're Horace Barlow I think it's probably more easily
understood as this this intense epistemic affordance or attractiveness so the yellow lever
the lever in the yellow submarine if it has not been pulled before all other things being
equal is the most has the greatest affordance to because it's novel so when you rewrite this
Bayesian surprise not in terms of posterior beliefs about states of the world but posterior
beliefs about contingencies of the parameters that generate states of the world the consequences
of action that looks exactly like novelty so that question I think is a great question on
two levels first of all it allows me just to sort of de-technicalize the basic imperative
we're talking about it it's just about sampling salient stuff just novelty seeking but on another
level you're absolutely right as well that you know these imperatives do describe people and
particular scientists you know this is just the you know describing exactly what we do
all we spend our entire lives doing is generating hypotheses carefully designing these experiments
with epistemic affordance to disclose and reveal the most evidence that we can and if we're good
scientists we make these good epistemic moves and if we're not we don't get funding and we
confirm our own ideas or get ignored and so really this is this is another way of just articulating
the notion of the brain as a scientist you know both subject to exactly the same the same the same
notions. How does reproduction have any epistemic affordance? That's a tricky question to answer in
terms of normality and how a simulation to show you how it works reproduction here is one way of
if you like a particular class of having these itinerant attracting sets so at one level from
the point of view of a species over a certain period of time before and after the speciation
occurred to create that species you can write down the trajectory of the species where each of those
cycles I was pretending before was my daily life cycle or my heartbeat that could actually be over
at an evolutionary timescale so you can look at that as you know that as revisiting certain
states of being over somatic time like being an embryo being a zygote being an infant and
going through a neurodevelopmental cycle so the key question there is do the same mechanics apply
at the level of evolution that must be in play if there is an attracting set that is a species
and that leads us into the game of now reinterpreting the price equation or the replicated dynamics
that are used to model evolution not so much specifically in terms of reproduction but certainly
in terms of you know evolutionary theory more generally as basically a process of inference
and that's very interesting because there are a lot of there's a lot of
um mathematically the answer is yes absolutely and I think the chap called S Frank has written
about that and John Campbell talking about universal Darwinism it's a truism that the
population dynamics that are used to model theoretical evolution are just Kalman filters they
are just very atrial free energy minimizing great gradient flows the more interesting thing I think
is the the memes and the rhetoric you can put on top of that so now if that is true it means a
natural selection now becomes Bayesian model selection and now beliefs become or internal
states now become phenotypes so the phenotype now becomes if you're like a statement of belief
about what sorts of things are fit for purpose in this eco niche and the Bayesian model selection
now does a structural learning on the phenotype where you've actually got explicitly an ensemble
density encoding the posterior belief so evolution now becomes a scientist so evolution now does
its belief updating using a sample density over the phenotypes that constitute the population
density that conforms to exactly the same rules that I the Fokker Plan equation describes
so I think there's a there's a lovely game to be played in terms of theoretical biology just
unpacking the same math that you might use to describe you know it's creating a wave equation
but applying it to population dynamics and just seeing what you mean when you talk about
natural selection and how that means you know relates to things like structural learning
in say natural language processing for example mathematically they all have the same form
that was a bit of a hand wavy answer at the level of reproduction the reproduction is an
interesting one because it implies a spitting of the genotype and you know so that that's that
I think requires some finer and more detailed analysis
