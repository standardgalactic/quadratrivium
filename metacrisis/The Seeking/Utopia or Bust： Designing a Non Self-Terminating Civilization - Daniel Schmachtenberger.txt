Welcome back to the Emerge podcast. Today I'm joined by Daniel Schmockdenberger. Daniel
is a social engineer and evolutionary philosopher and strategist. He is the founder of Critical
Path Institute, the Emergence Project, and the co-founder of the Neurohacker Collective.
Daniel has become very well known in the weird corner of the internet that this podcast occupies
the sense-making media, the meta-media, whatever we're going to call it. In any case, for me personally,
Daniel's thinking has colored many of the conversations I've had on the podcast and his
formulations, his kind of abstractions, have been named by many of the people that I have talked
with. Daniel is a close collaborator with folks I've had on the show, people like Jordan Greenhaul
and Zach Stein. Daniel was also kind enough to offer to come back on the show if there are any
follow-up questions that people have. If while you're listening to the conversation or
after you finish listening to the conversation, you have some questions, some curiosities
that you'd like to hear Daniel reflect on, you can send them to me on Twitter. I'm at D. Thorson,
or you can email them to me. I'm at dthorsonatgmail.com. I will collate those questions, find a way to
kind of rank them and prioritize them, and then maybe we'll do a sort of AMA episode with Daniel
sometime in the future. Who knows? All right, without further ado, here is Daniel Schmockdenberger
on The Emerge Podcast.
The Emerge Podcast is proud to be sponsored by the Monastic Academy for the Preservation of Life
on Earth. The Monastic Academy, located in Lowell, Vermont, is a training center
dedicated to the amplification of human maturity in the age of the Anthropocene.
The Academy trains its participants through a unique combination of rigorous contemplative
training, project-based learning, and a disciplined commitment to ethical behavior,
all held in the context of deep community. The Monastic Academy is currently accepting
applications for the apprenticeship program. This program lasting two or three months
includes silent retreats, daily meditation instruction, and regular authentic relating
practices. This program is free. Other ways to participate include daily visits, week-long
retreats, or if you can work remotely, joining the Academy through the co-working program,
allowing you to deepen your practice while keeping your job. For more information,
you can go to www.monasticacademy.com.
Welcome back to Emerge. Today on the show, I am very excited to welcome, for the first time,
Daniel Schmockdenberger. Daniel, welcome to Emerge.
Thanks for having me, Daniel. Happy to be here.
Yeah, so your thinking and I guess what you've shared on the internet as you've been
wrestling with our era has already flavored many of the conversations we've had on the show
with people like Jordan Greenhall, Hansi Freinacht, Bonita Roy. Your thinking has,
in various ways, informed those conversations. This conversation is going to assume some degree
of background knowledge about your approach to the kinds of inquiries this show is all about,
collapse, phase shift, human potential. Yeah, and to start off, I think I would love to hear
your take on what I think of as the current state of play. My sense as an observer of culture
is that things seem to be accelerating as they have, but there's a kind of, I don't know,
some sort of point that's been reached, a pivot point or something, collapse is puncturing the
mainstream discourse. You can look at the New York Times article on the rebranding of the Pinkerton's
to be kind of like a post-collapse militia. You can look at Jim Bendell's deep adaptation paper
getting just more attention than any other academic paper that gets published and it wasn't
even published. It was just put on the internet or the fact that Extinction Rebellion is gathering
so much steam. I'm curious, what are you seeing now? If there's anything that has changed in your
models or expectations or sense of how collapse or phase shift will unfold?
Yeah, so you're mentioning that the general zeitgeist is getting more familiar with and
considerate about collapse models and I think thinking about the emergence of that phenomena
historically is kind of interesting. So there have been some people talking about something like an
eminent phase shift that would either look like collapse or emergence forever, right? I mean,
for a very long time and that's the way I think about it is that that's a way of thinking about
the biblical rapture story. It's a way of being able to interpret the end of the Mayan calendar or
the end of Satyuga or Kalyuga in the beginning of Satyuga in the Hindu system is that the idea
that we're in a time that doesn't continue the way that this time has been unfolding and that
at a certain point there's something like a hard fork, we can see that being a pretty old idea,
right? And kind of the way I think about that and I'm thinking about it metaphorically,
I don't know what the actual history was, but let's imagine that we're thinking about kind of the
rapture story from Christian and even earlier Jewish kind of thinking. So
if we were people like you and I having a conversation like this where we're thinking
about the future during the Bronze Age and we're noticing that as we've continued to develop
more powerful technology, we have developed more powerful technology of warfare. So as soon as we
get arrows and then as soon as we get arrows that can pierce armor and armor and all those things
that there's an escalation of military capacity on all sides and we can kill a lot more people
from further distances than the records of previous warfare. And it's pretty clear that
we're going to keep developing more projectile capacity and we're going to get catapults and
then cannons and whatever. And we're also developing technology for accumulation, being able to store
resources so that there's more of an orientation to accumulate surplus and the ability to extract
resources, everything from better saws to take trees down and better fishing technology to
smithing technology. And so we can see that as our technology is growing, both our capacity to
kill each other and our capacity to unrenewably destroy the environment. And so we see that
there are deserts near our civilization that are the results of our unrenewable agriculture and
forestry practices and they're growing. And that the military technology we're getting that's
upratcheting is also upratcheting on the other sides and it's not that hard to just kind of run
the scenario and say, okay, if we keep increasing our technology and using it in ways that directly
harm each other or indirectly harm the commons, we just don't get to do that forever on a finite
playing field. And so there's a reckoning that's going to come with how we use power as we keep
getting more powerful. And so we get the kind of purgatory story that there's right now,
it's only a few precient people, prophets that see that it's going to go this way,
but there's a certain point at which the fact that we don't get to keep going this way becomes
eminently obvious to everyone. And if we continue to try and use our power in game
theoretic ways that advantage self at the expense of other or commons, and in doing so we have to
get more, we have to get some asymmetric power over the others seeking to do that. And the moment
we deploy the asymmetric power, it gets reverse engineered and iterated on to all sides or
exponentially upratcheting power that is used to externalize harm. As soon as that becomes
eminent, then there's this kind of great reckoning of if we keep doing that,
we do, we don't get to keep doing that in a sustainable way. So we get something like a
collapse in a health scenario. And to get something like a not collapse scenario,
we have to be safe stewards for our power. And we don't really have any record of the
thing we call civilization using our power all that well, right? Meaning we've of course used
power to do some lovely things and a bunch of dreadful things. But if we take the distribution
of the types of choices that we made as Sumerians or Romans or British or Egyptians or whatever,
and we multiply the power of how we've made choices by an exponential set of capacities,
that self terminates everywhere. Because, and this is where the mythopoetics of
heaven on earth or the consciousness chains that would have to come comes in, which is
if technology gives us something like the power of gods, we have to have something like the love
and wisdom of gods to be able to rightly wield it. Otherwise, the misapplication of that power
self terminates. And so I think that metaphor holds quite strongly. And I think we can kind of think
of it as that we're entering something like the purgatory phase where rather than a few
precient people recognizing it, you kind of have to be not paying attention to recognize it.
And whether we're looking at climate change, or we're looking at biodiversity loss or species
extinction or specific cases like loss of pollinators or issues with coral or getting to
peak oil, peak nitrogen, peak resources of different types, or we're looking at the effects of
exponential terrorism or exponential warfare or the massive human migration issues that could be
occurring or even accidental externalities for more powerful tech like AI or CRISPR and biotech,
it's not like there's one collapse scenario. It's like there's lots and lots and lots of them.
And even if we protect it against several of them, all that does is move the curve of when
the collapse happens by a tiny bit because we're developing power on all fronts and using it in
ways where we're advantaging some metrics, meaning either advantaging some in-group at the expense
of out-groups, advantaging the near-term at the expense of the long-term, advantaging a particular
metric like GDP at the expense of other metrics like biodiversity. And as long as we are advantaging
some things at the expense of other things with exponentially more capacity to do so, that's
going to be self-terminating across all of the applications of the power. And so yeah,
I think it is fair to say that we're moving into a place where at least there is a general
sensibility of this that is increasing. And even amongst some smaller populations, like people
on your listenership probably, some deeper understanding that it's not one scenario,
it's a lot of scenarios and it's not the result of a few bad dumb people, it's actually the
result of the structure of civilization itself. Yeah, yeah. And so I'd be curious,
I believe that you've read Jim Bendell's deep adaptation paper and he was on the show and
we explored together his sense of what he calls the inevitable near-term collapse of
social systems due to climate change. And obviously, even that's just one factor of
collapse, right, is ecological related collapse. And so that question of like, we're past the
point of no return and now it's sort of inevitable. A lot of people I hear are looking at this situation
that way, that we're kind of past this point of no return. How do you relate to that possibility?
Is that something you're tracking? And like, do you agree with that? Yeah, I'm curious what your
thoughts are. I think that we're past the point of no return in terms of the type of
world order that we have and the underlying civilization architectures are definitely
going to collapse. That doesn't mean that the biosphere and our species has to collapse with
it, it just means that if our species is going to not collapse with it, it has to figure out
new systems for mediating itself, right? And yeah, so I'm not fatalistic about this. I'm looking at
which civilizations can't further, which systems can't further from an architectural
perspective. So like, let's, okay, there's a bunch of things worth looking at. First,
we should make the distinction between an existential risk and a catastrophic risk,
meaning if we describe an existential risk as an extinction, a lack to continue our existence
as a species, there are risks that could be fully existential to Homo sapien or even fully existential
to say all mammals or all hydrocarbon life. But I don't think there's that many of them that are
all that probable currently. Then there are catastrophic risks where it's like, okay, we're
talking about some humans in pockets making it through a World War scenario or environmental
collapse scenario, but we lose so much of what we have developed as a civilization. And I think
there are a lot more scenarios that are more likely of that class. But for now, I would just put them
all together as, you know, massive to complete collapse type scenarios. So if we look at climate
change, for instance, I don't think there are any climate change scenarios that very reasonably are
existential, meaning directly, meaning that we create a climate where that is Venus formed where
humans just can't live in the climate. I don't think that is likely. So I do think we can have
a situation where environmental issues that include climate change, but also include desertification
and fishery collapse and resource issues of various kinds, lead to massive human migrations.
And that those massive human migrations
lead to really significantly increased resource pressures, which definitely have a good chance
of leading to war and escalating war and economic collapse and grid collapse and those types of
things. Yeah. And so, you know, in the Future Thinkers podcast, it's really important to listen
to. It's one of the most important podcasts I think I've ever heard in my estimation. And
in that podcast, you talk about this idea of scaled interpersonal coherence as being a kind of
solution to the current problem set or problematic architecture of our civilization.
And I'm curious if there's anywhere that you now see signs of the emergence of this sort of
collective intelligence, you know, the one that could help us thread this needle. I understand
you may not be able to name the specifics because these things are often very fragile when they're
getting going. But even just to know that you're seeing like embryonic versions of what you've
been calling for would be, yeah, just curious to hear if that is happening yet in your view.
Okay. So when you were talking about solutions in terms of new types of
collective intelligence and sense making systems that could inform new types of choice making,
new social architectures, to be able to look at what an adequate social architecture would be,
we do need to understand adequacy. We do need to understand the nature of the problems in
current social architecture. And you mentioned that a number of those were discussed in Future
Thinkers in ways that took a while. So I won't take a while with it, but I think it might be
worth just briefly naming what the primary issues are. So then we could say emergent experiments
that would be interesting would be things that would address these types of issues. Does that make
sense? Yeah. Okay. So briefly, we were just mentioning that there's a lot of different types
of risks that emerge from the same underlying dynamics. I've talked about these underlying
dynamics as generator functions, which means we're not looking at a particular type of pollution
or a particular type of resource depletion or a particular type of warfare. We're looking at what
creates pollution or resource depletion or warfare writ large in the nature of how humans
coordinate activity. And if we can identify underneath all of the future risk scenarios,
we can identify a hopefully relatively small set of social architectures or generator functions
that give rise to all those problems, then we can say, well, rather than solve for the instance
of a particular collapse scenario, can we solve for the class of the generator functions writ large?
And if we could find a finite set of generator functions that we could show to be subsumptive
that all of the risks come from these things and we could actually solve for the class of those
generator functions, then that would be the kernel of a new civilization model and a civilization
that would be by its design parameters, not self-terminating. And so we'll just kind of
describe that real quick. There's a lot of ways to think about why a particular system that is
auto-poetic, that's self-organizing and self-advancing, why it would self-terminate.
But it's not uncommon. If we think about cancer in a body, cancer is a auto-poetic,
self-terminating thing. So the cancer cells figure that they can defect on the rest of the body.
I'm saying this in an anthropomorphic way, but they defect on the agreement of the rest of the
body in a way that has them actually gain more resources. They consume sugar faster than the
surrounding cells and they replicate faster. So they're doing an increased consumption and reproduction,
but in doing so, they're actually debasing the integrity of the entire system. And if they
succeed, if the rest of the system doesn't reverse them, stop them doing that, then you actually
have the most cancer cells right before the body dies and then they all die. And so as they are
in the short term advancing what it seems like is their mission, they're also debasing the substrate
upon which they depend. Because the cancer cells emerge out of a healthy body that can live for a
lot longer than a cancerous body can. And so in general, we can say that if you have any system
that emerges out of a base layer, a more fundamental layer, if that emergent layer debases the layer
that it emerges out of and depends upon, that system's going to self-terminate eventually,
right? You can't debase your own substrate sustainably. But we can see that nature gives rise to
humans. We see that humans give rise to technology and then humans use the tech to kill each other,
debase nature and make better tech to do both of those things. That's an unstable scenario.
And so if we want to have stability of creatures that have the amount of power that technology
enables us to have that is totally unprecedented in the rest of life, then if nature gives rise to
humans and humans give rise to tech, the tech has to be in service to the actual resilience of nature
so that there is a closed resiliency loop. Well, building technology and infrastructure
with the goal of increasing the orderly complexity and the meta-stability and
anti-fragility of nature itself is not something we've really ever done. But it's something we
obviously have to do, right? And so we can start thinking about what currently is
underneath how we develop tech. There's both a set of motivation structures, economic structures,
and a type of sense-making. We develop a particular piece of technology for a particular goal,
but it's going to interact with a lot of things other than the goal for which we made it, which
are areas that can create externality of harm, right? So there's both a change of the motivation
of how we do technology, the comprehensivity of it, the nature of the sense-making process that
would have to change for us to be able to do tech properly. So thinking about a civilization that is
debasing its own substrate, self-terminating is just so people kind of get a sense of why
self-termination would happen in that way. A simple way of thinking about the generator functions that
a generator function that I think is familiar to most people is just a topic of perverse incentive
writ large, the idea of what perverse incentive is, which is if we want to look at biodiversity
loss and we say, okay, why are we extincting so many species and why are the large fish species
so overfished in the whales and why have we cut down so many of the trees, as soon as we have a
system where the trees are worth more dead as lumber than they are alive or the fish are worth
more dead than they are swimming in the ocean and war raises GDP and is more profitable than
peace and sick people are more profitable than healthy people, then and on and on underneath
all of those problems is a perverse incentive complex where someone has a lot more incentive to
cause a problem than they do to not cause a problem, right? And if we take a look at the
like dead trees example, we get this multipolar trap where I don't, me cutting down this tree or
these few trees is not killing all forests, but it is getting my family meaningfully ahead and my,
you know, like if I leave them, my family doesn't get ahead and doesn't even eat, right? And if I do
this, then my family gets ahead. And so I don't think about it at kind of a great debasing our
whole substrate scale. And I don't even think I have options because I don't necessarily know
another way other than cutting the trees down. And if I don't cut the trees down, someone else
is going to cut the trees down. So I don't even have an option to leave them. And so if someone
else going to cut them down anyways, then I might as well do it to be able to get my family to move
forward. So we have a situation in which each person or each company or each country acting in
its own rational near term self interest leads and so each person doing what actually seems smart
to them in the near term is actually suicidal for the whole over the long term. It's a dysfunctional
collective intelligence where the coupling of the choices of the individual actors doesn't
couple to good choices at the level of the whole system, right? So we have a system where
for the most part, nobody really wants climate change. There are some examples that there are
some exceptions that matter. Like, you know, if I was Russia, I would be pretty stoked on climate
change because the opening up of the Northern Passage would be economically powerful. But for
the most part, nobody wants climate change. And yet all of us are doing actions that are
advancing climate change. And but in our own self interest, I need to just put some gas on the
car to drive. And what I'm doing is so tiny relative to the whole thing. And on and on,
whether it's an individual actor, corporate actor, military actor, and in the presence of what
everybody else is doing. And so there's this weird thing where the invisible hand of the market,
the emergent property of everybody interacting where they're all doing utility maximization
within a current system is perpetuating the system. So the invisible hand of the market is
driving climate change and driving biodiversity loss and upratcheting exponential warfare,
even though no actual actors really want any of those things. And that is a dysfunctional
collective intelligence, right? But basically a scenario where we have game theoretic actors,
whether it's an individual person or a family or a tribe, or a nation state or a corporation or
a political party or a race that identifies as an in group in competition for scarce resources
with some other out group, if they're acting in their own interest, then and they're empowered
by the ability to create technology, whether we're talking about social technology, like
democracy or markets or physical technology, like extraction capacity from the environment or
information tech or warfare tech. The difference between humans and all the rest of animals and
nature in this way, because obviously, in nature, there's a lot of cooperation, there's a lot of
symbiosis, but there's also competition. And there are rival risk dynamics. And we might see
two animals of the same species actually competing over reproductive opportunity in a rival risk
way, and even in a zero sum way. And we might see a predator and prey in a zero sum dynamic,
one specific predator hunting one prey animal. And yet, we still see this kind of meta stability
in nature. And so we take this idea that, you know, hey, the lion's chasing the gazelle,
eat the slow gazelle, they don't catch the fast one. So then the fastest of the gazelles are the
ones that reproduce and the gazelles get faster as a result of what the lions are doing. So,
hey, this rivalry is actually good, the competition drives innovation. The lions as a whole, if they
weren't there, the gazelles would actually overpopulate themselves into extinction. So the gazelles
need the lions and the lions make the gazelles better. And the speed of the gazelles getting
away a lot of the time has the slow lion starved. So the fast lions get faster and, you know,
etc. And so we see that this rivalry in this competition is actually necessary because they
couldn't maintain without it, and it upratch its everybody's capacity and drives this thing called
evolution. And so we're like, okay, well, that's how nature works. So we should work that way.
And hey, that's how theory of markets works, right? And this is basically a simple way of
understanding social Darwinism, where we reify theory of markets as if it's a Darwinian process.
And we say, evolution is defined by an environmental niche, and then selection dynamics
inside of that niche. And the selection dynamics are a result of three things.
Mutation, survival selection and mate selection. So the mutation happens randomly in evolution,
right? It's not consciously controlled where a lion gets to say, I want my DNA to mutate in this
way. It just mutation occurs from gamma rays, from oxidative stress, from copying errors,
from whatever. And so some mutations lead to a slightly longer neck. And if that is advantageous,
because there are leaves up high that aren't being eaten, and a couple that have a similar
mutation breed together, that moves in a direction towards giraffes, right? But most mutations won't
be advantageous, and most of them will fail. So we have basically mutation, and then which
mutations survive? Most of them aren't going to survive. They're not even going to be able to eat.
Which, and then of the ones that survive, they mate with each other, and only those genetics,
only those offspring go through. So for something to be selected for a long term,
it has to survive, and it has to be able to reproduce. So we think about markets, and we say,
demand in a supply and demand dynamic, demand is like an environmental niche. There are some
resource there. And something is going to emerge to fill that niche, to create a source of supply.
So then it's usually not one something, it's a number of some things competing. And so you get
multiple people or companies trying to make a product or service to fulfill that demand,
but they do slightly different versions. They have their own innovations, and that's like
mutation, right? It's like modifications on the product. And so most of the companies are going
to fail. And only the company that actually figures out how to provide the best value at the best
price is the one that's going to make it through, i.e. survival selection. And then maybe you've
got a couple companies that are doing something really positive. And if they were to join IP,
it'd be even better. So you get a merger or an acquisition. And that's like kind of mate dynamics,
where you get recombinatorial dynamics on the underlying innovations. And so we say, well,
great. So markets drive innovation. And as a result of they drive innovation and the competition
pressure is actually a healthy good thing. And that's how we get new tech. And that's how we
actually get higher quality of life for everybody. This is, of course, not true at all and silly,
even though like, it's not not true at all. There's some truth to it. But the reason that
it is fundamentally not true and we can't model ourselves in a Darwinian way is because
the other animals can't upratch it their rival risk capacity with technology. And that really
changes everything. And so if we look at an apex predator, say we take an orco or a lion or a
polar bear, one lion just can't do that much harm to all lions or to all gazelles or to its whole
ecosystem. It's just not that powerful. But one person today with nuclear weapons or biotech can
really fuck a lot of stuff up. And so the system becomes very fragile when one person or one group
has so much power relative to the entire system, right? Our technologies allowed us to upratch
at our power relative to each other and relative to the other species and relative to the system
as a whole in a way that nothing in evolution has anything even closely resembled. And so you think
about a great white and its ability to catch fish. And then you think about an ocean trawler with a
mile long drift net and its ability to catch fish. And you're like, Oh, we are clearly not apex
predators, we can't model ourselves as apex predators anymore. Because if we keep competing
for who's apex predator in that way, but we can pull up miles of fish at once, we clearly debase
the planet's ability to support us. And so the key thing to really get is that in nature,
the mutations that lead to advantage are symmetrically distributed across the entire ecosystem.
So all lions are undergoing mutation and all gazelles are and there's similarity from some
lions to others and there's similarity in the mutation dynamics between the lions and the
gazelles and also the everything else. So you never get the lions getting 1000 times more powerful
in one step irrespective of the gazelles having a similar step. If they did, you would actually lose
the metastability of the whole system. The lion's going to get a tiny bit faster or the gazelle will
get a tiny bit faster through mutation. As that happens, then the slowest of the gazelles will
get eaten, the faster ones will now rebreat and combine. And so you get this thing where power
increases anywhere lead to power increases everywhere because there's a symmetry in the
distribution of power. So that's a result of the symmetrical distribution of mutation pressures
and the co selective pressures. The fact that as one is elevating, it is having real time interaction
with the other ones. So they're also elevating, which is why an invasive species can ruin a whole
ecosystem is that it didn't have co selective pressure. So if we bring an invasive species in
that figured out how to have some kind of power that the whole ecosystem is not adapted to deal
with, it can really massively fuck up a system. Well, us developing the kind of tech that we
have makes us like, like a super invasive species across every ecosystem, with nothing ever being
able to really check that capacity. And so this is where when we recognize no other animal has the
ability to destroy whole ecosystems or build new types of ecosystems or genetically engineer new
species and hybridize new species and extinct species. So we don't have power like apex predators,
where we can model ourselves that way and all do our own competitive dynamics, we have power to
affect the world that really only nature had previously. And nature is tending to the orderly
complexity of the whole. So if we have that much power, it has to be used to actually tend to the
orderly complexity and the metastability of the whole or bust, right? And this very much goes
back to this kind of earlier narrative of made in the image and likeness of God having God like
powers emerge, we have to have some God like wisdom and love for how to steward that or we get
destruction. So coming to that and coming back to the generator function topic to then be able
to answer your question of what needs to emerge and where do we see it happening? So three generator
functions that relate to perverse incentive and relate to debase or substrate and these things,
but I'll say them more specifically so that we can look out what needs to emerge is something
that can deal with these things. One is we can't keep running rivalrous dynamics with exponentially
more power. And so rivalrous dynamics can work fine in nature, but as soon as we get techne,
we get the capacity to create massive jumps in power where we can increase our predative
capacity faster than the environment can increase its resilience to our predative capacity,
we can't keep running it that way. So given that exponential tech is happening
and it can't really be stopped, then we have to develop anti-rivalrous systems for the
development and deployment of that tech. And anti-rivalrous means a nation state that has its
own metrics, right? Like its own balance sheet of its resources, its GDP, its security, its
longevity, its healthcare metrics. A nation state that can benefit its people independently of and
even at the expense of other nations or the commons is a basis for a rivalrous game. And a
corporation that can benefit its shareholders at the expense of other shareholders or the market
writ large or the environment or all the way down to individual private balance sheets and
private property type dynamics are all the basis of rivalrous games. So of course,
they have been very useful for the kinds of progress we have made thus far. They've been so
useful that if I say something like problems associated with private property, people freak
out in the way that like fundamentalist religious people freak out when I'm talking,
saying that their religion isn't the only truth. They freak out because they assume that what I want
is Stalin's idea to be instantiated, right? And that we want some dreadful thing called
Marxism that was already figured out to be not true. And look, so it's important that we recognize
that if we don't understand the nature of the problem well, we can't solve it. If we do understand
the nature of the problem well, we might be able to come up with solutions that we've never tried
before. Of course, we're not going to suggest previous systems that also suck. We're going to
suggest systems that we haven't done yet that involve new insights and new capacities. But
we've got to even define the problem well to know what we're trying to solve. This relates to another
generator function that I'll get to, I guess I'll get to it now. So the first one is we've got to
figure out anti-rivalrous dynamics so that we're not, see, one, something else to understand about
the rivalry is it's not just us going to physical warfare with each other or competing for economic
extraction from the planet or figuring that to increase on profit margins, we externalize more
of our costs to the commons in the form of pollution. It's also that in a rival risk game,
true information about reality is a source of strategic competitive advantage. If I know where
the gold is or where the water is or whatever is a tribe, then, but there's not enough for the other
tribe, then I want to hoard that information from ourself. And because I don't want the other tribe
to stumble upon it, I even want to disinform them about where it is, right? And so you'll notice
that in any competitive game, any rival risk, zero-sum type game, disinformation emerges,
not just withholding, but actually disinforming. It's what a bluff is in poker, or it's what faking
left and going right is in soccer or football, right? Like we see it everywhere. And of course,
we see it in the history of tribal warfare all the way on to advanced civilization type dynamics.
But the problem is in rival risk games, multiplied by a world with exponential information technology,
we get exponential disinformation capacity, meaning that we can have a Facebook feed that says that
ends up having an AI algorithm that optimizes it for stickiness for you,
which means whatever hijacks your limbic system the most, which means whatever version of information
ends up appealing to your in-group dynamics and your biases and your fear and susceptibility
and like that, and totally independent of actual good information. And so if we think about the
world today from the point of view of the damage not just to the physical commons, but to the
epistemic commons, because there's incentive to have disinformation, well, how the fuck can we
solve any problems if we don't even know what the problems are? Because the epistemic commons are so
destroyed that nobody has sense making, how do you do good choice making without sense making?
Well, you don't, right? And so if we ask, well, how long do we have before the coral die off?
What will the effect of the coral dying off be? Will they all die off or will
thermally resistant species emerge? Are they dying off mostly from temperature or from
pH change from carbonic acid or from nitrogen effluent affecting the phosphorus cycle or
from trophic cascades from lots of the large fish and whale species? So how do we deal with that
thing? Why was North Korea about to be a nuclear war with us a year ago and now everything is fine
for the first time since the seventies? What the fuck happened? Did they really have
tactical nuclear capabilities? How much stuff really leaked out of Fukushima? Is Fukushima
solved now? What is the real risk with AI? Elon says it's too late, Bill Gates says there's no risk
at all. What we find is that on the most concerning issues in the world that are the most pertinent
to the continuation of life on earth, everybody gives up on sense making or defects to believing
what their in-group believes because it's too hard to actually figure stuff out.
And when I say defect, I mean defects on their own sense making. And so rival risk dynamics are
going to lead to not only physical warfare and economic warfare but also information and narrative
warfare which the pollution of the epistemic commons through that ends up being a destruction
of sense making and the capacity to even know what a good choice would be, to even know what
issues we're trying to make choices and service to. And so of course if we have more people with more
power per capita totally that is increasingly blind, moving increasingly powerfully and quickly,
that's not a good scenario. And so here's something I had mentioned with regard to this one and sense
making is so many people have tried to figure out the vaccine thing, right? Like wait are vaccines
totally safe or are they totally bad or is it like maybe the ones that cure polio are worth it but
not the flu ones or maybe the problem was tamarisol but without the tamarisol they're fine or maybe
or they try to figure out the was Lyme disease a bio weapon or they try to figure out what really
happened with 9-11 or whatever it is or the current state of AI and they get so much conflicting
information that they just fucking give up, right? And they give up on actually making sense of it
but then what happens you have to say well what does it mean to give up on making sense of the
world you live in in the most consequential topics? Well it's a form of nihilism, right?
This is a kind of epistemic nihilism because if reality is meaningful then I need to understand
it to know how to interact in an appropriate way. And if I give up on understanding it because it
seems impossible or too fucking hard, can I actually make choices that are aligned with
what's meaningful if I have no idea of what world I live in? And so you know something I can
talk about what is emerging or not or what I would encourage is for people to look at the nature of
their epistemic drive and their epistemic nihilism and like how much are they actually committed to
making sense earnestly of the world they live in as a basis to have their choice possibly be meaningful.
Come back to that because I want to finish these general functions and I've talked for a long time
and you probably have questions so briefly we'll say arrival risk dynamics we got to address.
The other thing is intrinsic to how we do problem solving is that for the most part
humanity solves problems in ways that make worse problems. There's not that many exceptions and
whether we're creating a piece of technology to solve a problem or we're creating a bill
or a political solution or we're creating a new set of memetics for like a social solution or
whatever any of the methods we have a new company for a market solution. So you look at it and you
say all right well it was we were running out of easy big game and so there was a problem of
feeding enough people and whatever so we figured out the plow. Well the plow was awesome for us
but it was also the beginning of massive desertification and having enough surplus that war
was really advantageous for other people to come capture our surplus and the beginning of the types
of animal husbandry that led to so many of the problems in the world and actually the beginning
of certain types of fundamental patriarchies and we're like wow a lot of things got fucked up by
the nature of how we did the plow thing and if we all the way back to stone tools if we hadn't
got stone tools there'd be no environmental issues right like we wouldn't have went and
became the apex predator in every environment and started extincting earlier species say if we
hadn't got the wheel come to modern time we say all right we we have you know I think this example
is funny but it's actually a good one. The internal combustion engine to be able to make the automobile
was super helpful for us we could travel further faster easier than we could by horse and carriage
by a lot and we were trying to solve the problem of the limitation of horses that we had to feed
them that they shit all over the place you know those types of things and so we the internal
combustion engine solved the horseshit problem right London was covered in horseshit and the
other associated horse difficulties and that's awesome and we all like the quality of life
associated with cars but then we look at the proliferation of internal combustion engines
that left cars and also went into you know tanks and trucks and ships and whatever
and we recognize that all of the oil spells in the Amazon and the Valdez and the you know
Gulf and whatever and all the wars over oil and the destabilization of the Middle East forever
and all of the global economy based on the US petrodollar and climate change itself and all of
those issues are the result of the success of solving the horseshit problem and because what
happens is for us to solve a problem we define the problem in a narrow way right the the narrow
problem is defined in one or two or five metrics so we want the carriages to be able to go faster
without the limitation of horses or something right and so we're working on a solution to
that narrowly defined problem but the solution we create is going to interact with the complexity
of the actual world in a lot of metrics that weren't part of what we were designing to optimize
and so we didn't say also in as environmentally sustainable way that doesn't create
oil spills and wars over oil and you know we weren't factoring those things but for the solution
to really be a solution to a problem it has to be the larger than the problem it has to be able
to overtake the problem and if it does overtake the problem and it solves certain definitions of
the problem narrow definitions but that it interacts with the complex world where it ends up externalizing
harm in other areas but it's larger than the original problem was those places where it externalizes
harm will probably be larger or more complex and you know another way of saying it is just as humans
develop more power we are just shitty users of power currently right so that's coming back
to the rival risk thing but it's also coming back to the even not rival risk just we aren't
sense making well enough to say if we're making a new piece of tech are we making something that
even if we weren't doing it for a rival risk purpose isn't going to externalize harm because
we're being adequately considerate of not just defining the problem in a narrow way but defining
the problem embedding space where we can make sure that our solution doesn't cause worse problems
and so this this is a fundamental change in not the nature of whether we're trying to serve
a rival risk goal but the nature of our sense making to understand complexity better and to be
able to understand the embedding space of our solutions better so this is another thing at
the generator function that we have to address is we have to define problems in such a way that
the solution to that problem is actually omnipositive rather than positive for something and damaging for
something else because it's not just rival risk groups it's also rival risk metrics right a metric
based on theory of trade-offs where we benefit something and harm a bunch of other things and
maybe things that we haven't even anticipated is going to create inexorable problems especially
as we're as powerful as we are so there's one other generator function I can get into but I
feel like I've talked for a long time so maybe I'll take a break now and see if framing things up this
way uh if you have any questions on it or thoughts before we start to say well what is emerging that's
actually interesting yeah well let's let's wrap up the generator function like list that's let's
finish it and then I want to respond and we can explore what's going to emerge I think that will
work well so the last one briefly is that the way we have made technology
is fundamentally problematic and you'll notice all three of these relate but
there are distinctions it's fundamentally problematic independent of how we use it
there's this idea that tech is not good or bad its value is neutral and it's whether we use
whether we use it in service of which values we can use a hammer to build a house or to you
know hit somebody as a weapon this is not true technology has in certain fundamental and inexorable
effects in its existence that we actually have to factor and so inherent to increasing power is
you know the nature of how embedded within a rival risk game theoretic dynamic it will
lead to the utilization of that power for rival risk purposes you can't not use it for rival risk
purposes inside of those dynamics so that's how it relates to the the first topic that's the
multipolar trap and where if if anyone uses it for the fucked up purpose everybody has to where
they lose by default and we can't assume that other people aren't going to so we want first
mover advantage on using it for the fucked up purpose right and but then also also so technology
embedded within a rival risk context will get used for rival risk purposes technology defined in
narrow ways ends up causing these problems the other one but as we even look at things like
the biosphere is made up mostly of six atoms that almost all organic life is made out of and trace
amounts of the rest of the periodic table but most of the nickel and the chromium and the iron and
the uranium and the lead and the mercury is bound in rocks way deep underground far away
from the biosphere and it actually took geological processes and hydrological and then early biological
process billions of years to get it that way right to get the distribution of stuff where we
mostly had the organic elements all circling within a very narrow biosphere so the tree is
made of the same stuff that the frog and the gazelle and the lion and the virus are all made
out of right and as a result of that when the tree dies or the lion dies the microbes can eat it and
then the tree can eat it and the and so the actual elements of which everything is made
are the same elements with similar distribution and so we can have closed cycle process on it
now as soon as we start mining and we start pulling up things that are fundamentally toxic to biology
right the lead the mercury the arsenic the whatever are all toxic things we start pulling
it up in huge amounts and then we start doing the smelting and refining where we have both
the active product is toxic and the tailings are also toxic and now we're leaving them up
here in the biosphere we're undoing what took billions of years to make which was the right
elemental constituents for a healthy biosphere well that's a fundamental problem right like
so either we have to make our built world mostly out of the same elements that nature
makes stuff out of or if we're going to use other elements we have to figure out how to have
closed loop atomic cycling on them so we don't have to keep taking them out of nature and where
they don't become pollution they become like atomically accounted for cycled processes
and where those processes that we create we can ensure aren't going to break down into the future
so inherent to the nature of something like mining is an inherent toxicity independent
of how we think we're going to use the stuff right we can give a bunch of other examples of
like inherent to the nature of an internal combustion engine is it can't not pollute and
it can't not depend on resource extraction it's built into the nature of the tech it doesn't
have anything to do with what we try to use it for and this has something to do with making
things that are totally different than the evolutionary precedent of the biosphere and
of a different kind we make complicated systems nature's complex systems also the interface
between the complicated and complex is that the complex is antifragile you burn a forest it
regrows the complicated stuff that we build is fragile you burn a house down it doesn't regrow
and so as we are killing more and more of the antifragility of nature and converting it into
the complicatedness of the human built world we're decreasing the antifragility of the biosphere
and making an increasingly fragile human built sphere that's also a collapse scenario so this
doesn't mean we aren't going to have tech but it means we have to think about it fundamentally
differently we have to think about it in a much more considerate holistic way where we're thinking
about what is intrinsically the entire effect across the entire supply chain of effect of
the development of this tech not just the really obvious effect of how I utilize it
and so again this requires a different level of both motive and sense making capacity to be able
to develop it rightly so now when we look at all of the catastrophic possible risks whether we're
looking at any of the environmental dynamics or social collapse or warfare or unintended
consequence of exponential tech we can see these generator functions underneath and driving
all of those scenarios so then we can say if we could solve for these generator functions
categorically which means methods for humans interacting that is anti-rival risk that is
building tech in relationship with the natural world in a metastable way and that is defining
problems in a comprehensive enough way that the solutions don't create worse problems
then we would actually have a human organizational system a choice making system that was not
driving its own collapse great so thank thank you Daniel I'm having the a similar experience
that I often have when I listen to you speak where there's a way in which I feel like I get
what you're saying like on both an intuitive and a conceptual level like as you're saying it I feel
like you're pulling me into your world but then like the typically you know I'm not I'm not
participating in the conversation the conversation is on a podcast or something that I'm listening to
the conversation then ends and I feel like oh shit I like understand the problem real well now
and I see like how big and how deep it is for the first time again you know every time I hear
it listen to you speak it's like it on boards this way of seeing again and it's just like I don't I
almost don't know what to do with that and there's actually a sense of in me often of like helplessness
because now I see the problem and how big it is how vast it is and how like deeply it's encoded
into the structure of both the the system that I live in like my civilization and even my own
consciousness but then like the work of just even reformatting my own consciousness is like
real real hard and then I think oh and we have to do this for a lot of people and then we also
have to do it for all the systems up and down the stack and I'm like whoa that's a like and I guess
what what what comes from that is you know I feel like you're in a kind of unique position and I
almost just want to ask you like before we get into what you're seeing that's emerging it's like
are you are you optimistic that we're going to be able to like do this?
Yeah so most of us have a kind of learned helplessness right where we really want to help the homeless
person that we're walking past we really actually don't feel good about our busyness to get to
something that doesn't matter that much having us walk past another human that's actually really
hurting and yet there's so many homeless people and we could spend our whole life doing it that
way and not really touch it and that's just one tiny issue and there's a learned helplessness where
I don't feel like I can keep caring in the same way if I can't act on the care it's too devastating
and so I start putting blinders on and I start numbing in a particular way because I can only
care about stuff I can do stuff about and it seems like I can do so so both my impossibility to respond
and my impossibility to even make sense of adequately well are my impossibility to respond
will have me turn sense making off also my and care off my inability to even make sense of things
will have me turn care off and so I'll tell you a little bit about kind of my process
I'm I'm sharing some things that I've come to understand or how I see things as a result of
you know somewhat long curve of really trying to make sense of what the problems are in the world
but I started with much smaller definition of the problems right it was like it started for me
that the problem was factory farms and then it expanded to know we actually do fucked up stuff
to lots of animals and then like and it kept expanding in steps as I would work with it but at
each step there was a devastation of both how horrific and how huge the problem was and then
based on that sense making and the care and then there was an up leveling of okay well what could
I do to help this and a kind of agency that would emerge but then as I would work with the solution
that emerged I would realize it wasn't a real solution because the problem was actually deeper
and bigger than I was thinking it was and I was solving the wrong problem so okay we're going to
work and put the fences around the elephant preserve so the poachers can't get to them to
protect the elephants but given that even when we so we succeeded that but we haven't addressed the
poverty of the poachers who can't feed their kids any other way and we haven't addressed a macro
economy that creates poverty because of a power law distribution on wealth and we haven't created
affected the mindset towards animals and we haven't affected population dynamics and all
those things and so as a result when we succeed at protecting the elephants because the fences go
up the poachers move to start hunting the white rhino that's more endangered than the mountain
gorilla right this was an actual experience I had when I was 13 working with an activism project
and I'm like wow the best solution because it didn't understand the problem well enough actually
made a worse problem it moved the harm to a more sensitive area so then understand the larger
definition of the problem and then try to work on a solution there and that would happen again
and so then that took me on a process to kind of the maximum abstraction of generator functions of
all the things right but at each step as there was a deeper understanding of the nature of the
problems there was a while before there was a up leveling of a sense of agency now if I'm going
straight to the most abstract in general case there aren't all those steps of the up leveling
of agency and then there's going to be like oh fuck I went from thinking about what I could do
with a community garden to you know how do we deal with the nature of how human sense make
technology differently and rival risk dynamics writ large globally and so something I can say is
like so part of my process this may or may not be relevant for anybody but part of my process was
in facing the actual situation of the world was there were a few vows that I made
when I was pretty young actually as a teenager the first vow was that I would never turn away
from the pain of the world like like decide I'm not gonna go to the factory farm and I have an
opportunity or avoid the poor area or turn off the pita video that I wanted to actually see
the world that I lived in and what was going on because I didn't want to be able to
live in a blind bubble right so that was the first vow and then the second vow of course
when you start to do that you're it's fucking devastating and so then the next vow was to
feel all of it and not go numb and then the next vow was to not if if not going numb not
getting stuck in anger and blame and then the next vow was to also not get stuck in hopelessness
or overwhelm those were all basically unacceptable choices so the first one of I just won't look
at the problems I will live in a tiny bubble where I get to feel like I'm succeeding while
there's massive suffering and torture happening is a kind of dissociation that makes me as if
a sociopath right I'm stoked there's huge pain in the world but I don't have to care about it
so I'm like all right that doesn't work and going numb getting stuck and blame or getting
overwhelmed doesn't work so it's like the only fucking way through is to say I'm going to feel
it all I'm going to recognize that the devastation the anger whatever is a result of love which is
if I didn't love the animals if I didn't love the kids if I didn't love the environment if
it wasn't beautiful to me I wouldn't care that it was being harmed but underneath
everyone of underneath the fear the anger everything is a reality that is so beautiful
that I love which is why I care so then I trace it back to the love and I feel that
and I also tune in not just to the tragedies that are happening and could happen but also to the
intrinsic beauty and meaningfulness of life and then I say okay I have some agency I don't have
gods you know omnipotence but I have some agency so what do I do with that agency in
service of what I care about and you know every time I meet a nurse who's who actually really
cares about the people that she's nursing and makes the pain of what they're experiencing when
they go to the hospital less painful has them feel cared about like I feel this I feel this
kind of existential relief that she's doing that or he's doing that and every time I find
someone who is tending to street dogs in Tijuana or anything even if it's not addressing the
generator functions of x-risk like all those things matter and for a lot of people they will
understand the big picture and they'll say I'm glad some people are working on it I care about
all of it but based on the sense making I currently have and based on what I know how to do this is
where I can actually add value and the last thing I would want to do is have is have the nature of
my communication say because those actions aren't totally sufficient for everything that you would
feel less motivated to take them fuck no I want people to feel deeply motivated to do the things
that they actually can do that are expressions of their care and some people will be oriented to
the kind of abstractions to say well how would we build a new resource provisioning system a new
economics that reverse that removes perverse incentive or a new collective intelligence system
that doesn't have some of the failings of our existing governance systems and
so the people who are called to abstractions and to systems like that awesome I want you to work on
those things but whatever it is that you're called to there's a lot of things that actually need to
happen and just because something doesn't meet the sufficiency doesn't mean it's not necessary right
there's a lot that's necessary and so you know these vows for me I'm sharing because they're
ones that I hope other people take a version of their own version of which is how do I stay
connected to what I care about in the world and how do I stay empowered in my relationship to what I
care about thank you for that that feels really important to presence after the work you did to
name the generator functions and yeah so now that we have that ground covered conceptually
what are you seeing that is emerging that is sufficient perhaps to base a new
civilization operating system on or however you want to frame it yeah what are you seeing that's
emerging it's a very interesting question
in terms of things that are seeable
there's nothing that maps to sufficiency yet that doesn't mean there isn't progress
so do we see types of collective intelligence processes that could solve problems without
making worse problems and types of resource provisioning that could solve rivalrous dynamics
at scale no not yet do we at least see more people understanding some of these dynamics and taking
them seriously in a way they hadn't yes that's one thing that's emerging is actually just even
a higher level of conversation and consideration which is always going to proceed
the ability to address the things emerging in that conversation
now you know if we look at things like
dow stack or back feed that's working on kind of dow based governance structures or
you know hollow chain or other of the groups that are kind of at the front end of the decentralized
computing decentralized governance process that are working on better systems of governance and
collective intelligence do they map to sufficient yet no are they making progress that is actually
meaningful over previous systems yes so that's an example of some spaces that are interesting
as we see more groups starting to explore
things like collective intelligence and small group process and seeing how shared sense making
can work better than just the org chart of a corporation or a government or a traditional
academic type dynamic i think the collective intelligence group process space there are
things that are moving in the right direction it's interesting on the topic of things like
the work in psychology or psychospiritual development feels like it is both some of the most
important and most problematic work happening because the software of rivalry is embedded in
us right it's embedded in our psyche and so as long as i've got underlying insecurities that
i've been trained have to be resolved by getting other people's approval of me in relationship
to being better on finite metrics than the other guy then we are just we just can't work with those
types of people to make a effective collective intelligence very well and trauma is auto poetic
right the more traumatized i am the more likely i am to behave in ways that will perpetuate trauma
to myself and others so trauma healing and actually dealing with the underlying bases of
rivalrous conditioning in ourselves and learning how to have more authentic and effective relationships
and communication with other people this is all super important the place where so that's all
stuff i'm inspired by i'll tell you the place where i'm concerned about it is where
where people actually get overwhelmed by the problems of the world they seem too big so they
say well i'm just going to focus on my own healing and the world will magically shift
through the morphogenetic field change as our consciousness elevates or the right solutions
will kind of magically emerge out of this and it's actually a way of disconnecting from what they
care about in the world and yet feeling some sense of soothing or or agency and so you know one thing
i would say is any psychology that is helping people actually be more okay with the things
they shouldn't be okay with is not good so helping people just be at peace with institutionalized
violence and you know broken systems like i i am very glad that someone didn't talk gondi
in the early days into just understanding that personal development and working on ourselves
and becoming the change in our own self is the only thing to do and to not have like to not focus
on the british empire because that was just an expression of his own upset and unhealed traumas
you'll notice that you know whether it's jesus with the romans and the jews or
martin luther king with the current state of affairs regarding black people or gondi with
regard to the british empire like they weren't they weren't actually trying to just be peaceful with
what is they actually cared about then reality enough that there were things where they're like
this actually needs to change and i'm interested in the kind of psychospiritual development that
empowers me to change it not the kind that is kind of like spiritual opiates yeah i've listened to
all of your podcasts all the appearance you've made i think i've read everything on civilization
emerging i think there are a lot of people like at least in my weird corner of the internet
and the sign of subcultures that i participate in who are kind of like looking to you for answers
solutions and the way forward and i i guess i'm like curious about you personally like how are you
relating are you like aware that there's that kind of expectation or that that's put on you or
that people look to you that way and like what's it like to be that person around such like deeply
critical topics well i feel like you know i've i've had the fortune to spend a lot of time with
people that have helped me make sense of the world a lot and a lot of them people who don't speak
publicly because they're oriented to be making sense of the world rather than other things
and then you know been able to bring a number of frameworks together that
uh seem like they are adding useful clarity to the ability to make sense of the world and
you know what i'm i'm focused on how do we actually design solutions to these problems
but i'm also focused on just you know in the last couple years starting to share some of these
frameworks in a way that can hopefully support as you're mentioning an up leveling of the
collective consciousness intelligence consideration around these things so that
you know not just those of us who are working together but in a decentralized way more people
are informed by the things that i have found useful uh and so in so far as some of those
things that resonate with me are resonating with other people i feel happy about that and
you know it's interesting there's something that i think about like when you're asking though what
do we do if we think about the psychology of people who have done fundamental pioneering
and fundamental invention and discovery they don't ever get to ask anyone else how to do
what they're doing right like that's intrinsic to the nature of figuring out new stuff is that
you can't ask anyone else how to do it now that doesn't mean that you don't learn from
a tremendous amount of stuff and stand on the shoulders of giants but then if you're newton
you're standing on the shoulders of giants you're making sure you've learned those things
but you're also then advancing the edge and there's there's a kind of
there's a kind of psychology that is necessary to be willing to work at something that nobody
can tell you how to do and that there's no precedent in a history of smart people at figuring out
and it's not hubris it's just a depth of care that can't turn away
and there's like that i can't not focus on this so even though i have no idea if i'll succeed i
still have to be working on it and you know i think that growing up as kids most of us got
most of our praise from doing things that the authorities wanted us to do and that had already
been figured out so we got the right answer to to answers in sunday school that the teachers had
already predetermined what the right answer was or in actual school where we figured out how to
spell our math or whatever or winning a game where the rules of the game were set or doing the chores
where we didn't really have a say in the nature of how the house was designed or and so we get all
this praise for doing things that are already figured out that someone else tells us to do
and almost all the times we got punished were for doing something that we wanted to do
and so there's a very deep psychological program that is running that has to be unwound because
that psychology is itself one of the generator functions of the problem it keeps people perpetuating
the existing systems and so you know if someone asks me well what should i do i'm more interested
in the meta question of like how do you i can share some things with you and a number of people
can share some things with you but how do you navigate sovereignty in a way that says when
i come to the edge of things that aren't known how do i figure out what to do how do i discover
stuff as opposed to do stuff that somebody else told me is the thing to do like there's a there's
a psychological shift there that is really critical so that's one thing and coming together
with other people that are also really earnestly endeavoring to figure out how to do things that
they care about that aren't currently known and figuring out how to actually collaborate in that
together so how to be in it ourselves and how to collaborate with others in it and this requires
it this actually requires a mature relationship with certainty and uncertainty where i can sit
in uncertainty about something that's really consequential i don't know how to solve the
problems of the world yes it really matters i don't know how to solve even this particular
problem yes it matters but i can sit in the uncertainty which also means the uncomfort
of it so that i don't just have to distract myself with something else or default to a
quick answer that's the wrong answer because i need some certainty so there's a psychologic
willingness to sit in the discomfort of that uncertainty but there's also a psychologic
willingness to go through the epistemic process to bring about enough certainty to act so it's
easy for us to be very uncomfortable with uncertainty and want certainty fundamentalism
of all kinds does that but it's also very easy for us to kind of do the postmodern move and be
uncomfortable with any certainties and be sure that all certainty is imperialism and only need
to rest in uncertainty which means we never have an epistemic basis for good choice and so a mature
relationship to reality knows that there is knowable and unknowable stuff and within the knowable
there's mostly unknown and some known and that even the known my epistemic confidence margin is not
100% and yet there are better confidence margins than others as a basis for action and a mature
relationship to all that says that i can sit with uncertainty and i can sit with certainty both
comfortably emotionally so that i'm not being emotionally biased one way or the other
and i can explore what is the right process to bring about a particular confidence margin
for the certainty to act i think that people who haven't received a lot of attention often
misassess how uncomfortable it is um and misassess that it'll actually be fun
yep um you know i i had whatever wounded childhood dynamics that created insecurity that
sought external approval like everybody does and figured out my what i can be good at to get
approval strategies and i remember the first times that i was like speaking somewhere that
had respectable people respecting me and should have been some kind of success in that way
and i remember feeling really terrible as the people were focusing on being stoked on me because
they weren't focusing on actually caring about the issues and what they could do about it they
were focusing on me and that was like actually doesn't do shit for me and i'm like no no no
don't do that i'm talking about these issues because i care about them hoping to connect to
where you care about them and i'm i have any insights because i have to because i care about
them enough i keep working on it and i want to know how we can kind of collaborate together but
focusing on me in a way where you get to say like oh i'm glad he's working on that like that's
actually dreadful um so uh yeah you know i i think that's kind of interesting getting to be
part of conversations with people who are really earnestly working on stuff is obviously meaningful
and also getting to be in conversations that increase my sense making about the world is meaningful
and i will say that well you know mostly i talk about ideas that i'm hoping give people
frames to make sense of the world that empower whatever they're doing if we never talk or interact
you know if they're if there are people who are very called to
how do we make new systems and who have developed some capacities in some of these areas
there are things that we're researching that could use
support and research and so if if there are people who would like to
explore the possibility of um engaging and supporting some sense making
send me a message well thank you so much daniel for for taking the time to speak about all this
and um as we kind of head towards the closing of the conversation i'm curious like
is there anything uh at this point that's on your heart or mind that you feel like would be
would be good to presence before we close this conversation up
i really like what you're doing with this podcast and um you know the the fact that you
listen to all of the things and read all the things you did and
have really worked to make sense and then want to help advance the conversation and are connected to
the you know it seems like you have a community of people that are all kind of at the front of
a bell curve of really trying to make sense of certain things in the world and working you know
you're working to empower them to do a better job with that and you know when you ask where are
there things that are emerging that i feel good about this would be an example
oh
You
