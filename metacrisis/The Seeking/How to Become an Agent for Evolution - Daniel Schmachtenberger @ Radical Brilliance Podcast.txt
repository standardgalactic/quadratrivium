Welcome to the Radical Brilliance podcast with Arjuna Arda and brilliant guests from
around the world who are contributing to the evolution of humanity.
Today's guest is Daniel Schmacktenberger who's going to talk to us about how to become an agent of evolution.
So here's your host Arjuna Arda.
Hey, welcome back to the Radical Brilliance podcast. You know, when I was writing the book Radical Brilliance,
I drew upon about 420 existing interviews that I had conducted over many, many years for different other books.
And I did an additional about 30 interviews for Radical Brilliance. So by the time I was done, I'd done about 450 interviews.
And people used to ask, okay, you've written this book Radical Brilliance. It's about brilliance. So who is the most brilliant person you've ever interviewed?
And you know, I never hesitated very much when people would ask me that question in that way. My answer would always be, without a moment's hesitation,
Daniel Schmacktenberger. And you're about to find out why. Sometimes it feels to me when I talk to Daniel about any topic.
I've talked to him about the judicial system, about the financial system. I've talked to him about new tropics, about nutrition, about the way food's grown.
I've talked to him about relationships, about monogamy, about everything. I've spent a lot of time with him.
I stay frequently at his house and we talk for hours. Almost any topic I can think of to talk with Daniel about, it's like you're transporting 30 or 50 years into the future
and speaking with someone with that more evolved perspective. It's like speaking to a time traveler.
And it really goes across the board. And he actually will even talk about that. He will talk about what he calls lateral thinking,
which means the capacity to take insights from one discipline and apply them to another.
And I particularly love the conversation we had today because it is about how the potentially imminent crisis we face,
not only ecologically but financially and in many other sectors as well, is actually all determinant on upgrading our thinking, upgrading our understanding.
And many people have pieces of that puzzle, but there are very few people I know who have an inclusive integral view of that evolution needed in the way that Daniel does.
So I hope you'll really enjoy this conversation with Daniel. It's quite dense. He's a highly intelligent, multi-dimensional thinking person.
I found in many of the conversations I've had with him before, I need to go back and listen to the recording several times to fully grok what he was talking about.
So this is a podcast you might like to just press the Rewind a few times and listen to certain parts over and over again to really get the full implication of what he's talking about.
I hope you'll enjoy this. Please come back. Please stick around at the end and I'll have some suggestions for you for how to take this particular conversation
and turn it into practices that we can use to deepen our radical brilliance in our own day-to-day lives. Enjoy.
Hey Daniel, thank you so much for sitting down today. I'm looking forward to talking about some important things together.
You know, to jump right in, for a long time there has been an awareness, at least among a small subculture, that we are potentially heading towards crisis.
I mean, if we go all the way back to the 70s, people were talking about climate change then, people were talking about the nuclear clock.
The sense of we need to upgrade, we need to change our ways has been in the collective for quite a long time.
However, I've noticed, and I'm interested to know if you're aware of this too, that in the news, in casual conversation, at conferences, this is becoming much more now of a mainstream collective conversation.
Hey, we have little time left to dramatically change our ways and upgrade the software that we're running together in being human.
There's definitely been an increase in awareness of certain phenomena in recent years and even months.
Climate change and other environmental issues like plastic in the ocean and dead zones in the ocean and species extinction and biodiversity loss have moved from pretty fringy topics to more widely understood to more widely actually really cared about and sources of concern.
And add to that significant geopolitical shifts where in recent years large scale war became a more eminent topic than it had been in a long time where climate change induced refugee crises at impending huge future scales.
Because you look at how much got destabilized from Syria and that that was largely kicked off through climate change, through droughts that led to the subsistence farmers not being able to farm, moving to the city, leading to resource shortages, leading to war, leading to refugees.
And that got Brexit that was very involved in the Trump election, people's views toward refugees here, etc. And when we look at the numbers of refugees anticipated over the next decade, decade and a half, the world has no solutions for it at all.
And then we add to this things like artificial intelligence associated risks, artificial intelligence weapons, all the way to real AGI scenarios and seeing people like Elon Musk talking on popular shows as popular as Joe Rogan saying we're not going to solve this and kind of being given up about it.
Like these are definitely, there have been people working in the AI risk community for a decade that have had those concerns, but they haven't been on Joe Rogan, right, like that is a new level of awareness.
And it's partly because AI is an exponential tech. And that means that it's growing at an exponential rate. It also means that the things like climate change were just getting to thresholds that have been in underway for decades or longer.
But the threshold points are now becoming eminent. So yes, that's the case that there is more awareness and there is more actual eminence of some of the issues. But I would contextualize it slightly differently, just because I think it's important.
So when you were saying back to the kind of 60s and 70s and, you know, maybe even before, if we think about World War II and the development of nuclear weapons as the beginning of humanity having the technology that it could wipe itself out with, that was an important point.
Before that we could definitely cause wars and we did for all of human history, but we couldn't cause a war that could cause nuclear winter, right, like it took an asteroid coming dinosaur level kind of activity for something like that.
So all of a sudden we became capable of inducing that ourselves. And so with that existential level technology we can extinct ourselves, became a really new awareness.
Can I just make a comment for a minute? I'm realizing that's true in a kind of quick and dramatic way that grabs people's attention rather like when someone has a gun in the house now they have greater ability to commit suicide.
But there are other ways that we now have the ability to wipe ourselves out, not just in pressing a red button on a nuclear device, but through the gradual erosion of environmental integrity, of depletion of resources.
So that would be analogous to somebody could kill themselves by smoking two packs of cigarettes a day and it would be another form of suicide but much slower.
So I can see that what you're saying about our impact on other species as well as our own survival is true short, is true quick and long term.
Right, so let's take, let's look at a couple of these key points to understand now in context because history is actually valuable here.
So World War II gave us the ability to extinct ourselves quickly.
That was a new possibility in the whole history of not just our species but all species on this planet as far as we know.
Right, none of them ever had the ability to extinct themselves because of their own technological capabilities.
I was like, whoa, we have no evolutionary precedent for this.
And so that led to the creation of the United Nations to try and say, oh, obviously World War II is a sign that we did national governments alone aren't enough to stop wars.
And yet the wars we have now are so catastrophic in their possibility, what do we do?
And, you know, the goal there largely was how do we prevent World War III and how do we do nuclear deep proliferation.
And we, I won't get into this now, maybe we will later, but we obviously have not succeeded at nuclear deep proliferation.
There's a lot more countries with nukes now and nukes aren't even the most interesting weapon anymore.
So, but you go back and you see World War I was the first war that was at such significant scale that we could start to taste the eminence of real catastrophe
even before we had nukes, which is what led to the League of Nations where it's kind of failing to prevent World War II.
It had us change the name to United Nations, but there's a deeper structural level of what leads to war, what leads to environmental damage.
Where we go back and we see, well, humans have done more environmental damage since the beginning of the thing we call civilization.
We're just getting much bigger tools to mediate the ways that we've been.
So now, now let's kind of, this is the story that I wanted to tie it back to.
You go back to the Dark Ages and the idea that Armageddon's just around the corner.
If we think about this mythopoetically, so we say, okay, the Rapture story.
The end of the Mayan calendar, or the end of the Aztec calendar, or the Hopi end of this cycle, or the end of Kali Yuga and the Hindu system going into Satyuga.
Like they're kind of all the same story.
So let's take the kind of the purgatory Rapture story.
So the story roughly, if we aren't interpreting it literally says, this phase of the world doesn't last forever.
It's going to kind of come to an end and the end is nigh.
We can see it, right?
And at a certain point, as it's kind of coming to an end, there's going to be some really hard choices to make.
This kind of a purgatory period where based on the choices we make and it's not predetermined, there's a pretty hard fork in the road.
And we end up going one way that looks kind of like terrible for everybody, hell.
And one way that looks like re-entering the garden, Satyuga, the Golden Age, Heaven on Earth, whatever.
And if you just think about it from the point of view of just like kind of smart, prescient people paying attention in the Bronze Age
and looking around saying, hey, now that we've got metal weapons, the wars are way bigger than when we had stone weapons.
Like we just kill way more people from a further distance.
We've got catapults.
And these metal tools allow us to cut down trees way faster.
And now there's desert scenarios that didn't used to be deserts.
And we're getting bigger ones.
We're getting better metals down.
We can kill people from further.
We can cut down trees faster.
We can grow populations faster with our agricultural technology.
This doesn't get a last forever.
Like this increased destructive capacity doesn't get a last forever.
At some point, this phase is going to end because we aren't using our power well.
Like we aren't using our power in a considerate way to the fact that we live on a finite space.
And so if you think about it, it's just like the rapture story is just actually literally true.
Because we have been acting like apex predators, but who can increase their predative capacity via tools in ways predators actually can't.
Faster than the environment can become resilient to that increased predative capacity.
So a great white shark can't become much faster, faster than the tuna can become faster and get away.
There's a cemetery.
But we can make, you think about the fish killing capacity of a great white,
compared to the fish killing capacity of an ocean super trawler.
They can pull up hundreds of tons of fish and one net and you're like,
okay, we can't actually think of ourselves as apex predators.
Like we can't do that thing anymore because we've broken the power cemetery through tech so completely.
And so when you actually look back, you say, okay, the end is nigh, we need to change the boat.
Right, we need to turn the ship around.
Well, Rome didn't turn the ship around and it fell.
And the Aztec Empire and the Inca Empire and the Egyptian Empire and the Sumerian Empire all have something in common,
is that they were world ruling, world leading empires and they all collapsed.
There's a book that started this exploration, kind of popularly called The Collapse of Complex Societies by Tainter.
And just the first valuable insight about all previous civilizations is that none of them exist anymore.
So basically what I'm going to say is that it's not like we need to change the humanity
in terms of what's causing climate change or what's causing potential larger scale wars with AI weapons
or that we need to, that it's a modern society issue.
That there is something that has led, and we could get into this if this is where we decide to go,
there's something that has led to the ways we build civilizations not being sustainable
for as long as we've been building civilizations.
And the difference now is just that we have a global scale civilization
and that we're in the verticalizing part of the tech that extends the capacity of human choices.
It's great. So you've just referred to historical precedent on a local scale
about how societies have collapsed, right? Rome being a great example.
And you gave a number of other parallels, which doesn't bode very well for what we're doing globally.
Do we have any precedent for societies that came close to collapse and actually did successfully turn it around?
Yes and no.
There are examples where like the Mayans, the Mayan collapse didn't mean there were no Mayans left.
There are still Mayans, right? There are still people who practice Mayan influenced ideas,
but they went from being a like major city constructing civilization
to being small numbers of people back in the woods.
So they didn't lose everything, but they lost most of it.
So do we call that a success? We call it limiting the total extent of catastrophe.
And if we want to look at like Greece, Greece got taken over by Rome,
but at least Greece and ideals influenced the Roman Empire, which didn't spread them, so it didn't totally die.
But do we have examples where any of those civilizations changed something intrinsic to themselves
that then led to enduring sustainability?
Well, let me run a couple of examples about you. Can I do that?
Sure.
One, I think one big turning point within our predominant civilization would be the Renaissance.
Now, if you read what people were talking about and writing about,
soon after they've mentioned the printing press actually,
the whole conversation was about what happens when ships fall off the edge of the disk.
So there was a whole conversation about that, but also because there was the belief that all the planets were going around the Earth,
it suggested a chaotic out of control deity who just had ADD.
So actually things were not looking so good in medieval Europe.
There was a lot of despair, a lot of doomsday theory going on then,
and it was actually what Copernicus, of course, and associated things,
as well as the success of exploration, which brought on the Renaissance.
So that was a positive uplift for a civilization which,
I mean, it's hard to say if it exactly averted catastrophe,
but it certainly changed the conversation from predominantly negative to positive.
And another one, let me just throw your way, and then I'll get your comment,
was post-Industrial Revolution in England,
but before the popularization of the motor car,
London had this massive problem with horses.
They had, I think there were 50,000 horse-drawn calves,
I don't remember exactly the details, but basically they did a calculation.
The Times of London, no less, in 1884 did this calculation.
They said based on current trends, the entire city was going to be buried under nine feet of horseship by the turn of the century.
But of course that didn't happen because it took a bit longer
and then because of the popularization of the Model T Ford.
So we do see where things were looking really grim and there was an intervention.
And if we had paid more attention at the time, we could probably have seen that intervention,
because it has in the past taken about 30 years for us to go from an invention to mass assimilation.
So what can we see on the horizon for us today that could be majorly game-changing and game-solving?
These are actually important examples to explore a little bit.
If we look at the periods that at least standard narrative of history tells us are where some positive upturns happened.
If we look at the Greek Enlightenment or if we look at the Renaissance or the Enlightenment that followed it or et cetera,
Industrial Revolution itself.
Wherever we see these meaningful increases or changes in direction,
they correspond to meaningful increases in capacity that arose from new insights.
So as you were mentioning, coming out of the Dark Ages was Copernicus, Kepler Galileo coming into Newton,
having a new way of understanding reality that was demonstrably more effective.
You could use Newton's calculus to have your cannonball hit the spot better than pendulum dowsing,
better than just praying could.
So those who kind of bought the idea just did better.
They did better in agriculture, they did better in war, so the idea spread because it was effective.
But there was a very small number of people who developed fundamentally new insights about the nature of reality,
much in the same way that it was like von Neumann and Turing and a few people that figured out computation that affects all of our lives,
or a few people that figured out quantum mechanics that made that possible.
So there were upticks in understanding that was usually a few people going very deep to say,
the current way we understand reality is inadequate.
The Dark Ages were such a clear example.
We can't actually solve the problems at the level of consciousness we have right now,
like we actually need deeper insights.
So then as we get deeper ontology, we get deeper insight about the nature of reality, we get new capacities.
So I would say in general that has been a process,
that whenever there's been a deep doubling down on understanding the nature of reality better,
that has led to new insights, new capacities emerge.
But at the same time, what I would say is that each of those places where then some very positive thing happened,
little ways down the road some really negative thing came from that new thing that was bigger in scale and faster in earth.
The motor car is such a great example.
It's like horseshit covering London would have been a bummer for London,
but it wouldn't have possibly been catastrophic for the ability of the biosphere to support humans writ large.
And yet cars then were exactly that.
And so like everybody likes that we have cars and it doesn't take 30 years to get across the country.
And yet the political destabilization and wars over oil,
and just all of the kind of war political dynamics that are associated
and climate change and ocean acidification and all that are very related to having cars.
And so, and even when you talk about science compared to the religious ideology,
well, so it's like science is super more effective at a lot of things.
But then also said that the nature of reality is objective.
We end up getting a philosophy that emerges with science in most cases, which is physicalism.
What's real is physical stuff that started at the Big Bang and the constants are what they are for some reason.
And the laws of physics are what they are for some reason.
There's no consciousness and at a certain point you get galaxies and then planets
and then eventually life and consciousness pops out as an emergent property.
And if you run that you say, well, the consciousness couldn't in turn affect the underlying physics,
brains or causal systems deterministically unfolding.
So there is no actual choice and you're left with nihilism.
And then people are like trying to reconcile science with Buddhism
or some religious idea to try and solve that.
But again, it's one of those places where the solution was adequate for the next step
but not adequate long term.
But as we're getting as the consequences as we exponentiate are getting faster and faster.
So we have less time to respond but also being able to disseminate faster and faster and be more consequential.
The process itself has to change rather than just here's the next step.
We have to actually think better about what will be not currently obviously anticipated effects.
What will the externalized effects be and how do we internalize all of those to the design, to the strategy itself?
Yeah, great. That's awesome.
If you're enjoying this podcast with Arjuna Arda and his radically brilliant guest,
you might also enjoy our eight week online group coaching program.
It's an opportunity to go deep and get stable in practices that enhance your own brilliance.
We only take 20 participants at a time so in a small and intimate group,
you can go through the whole radical brilliance cycle.
You'll have an accountability partner and another brilliant aspirant from somewhere around the world.
The eight week coaching program involves eight one hour webinars with Arjuna Arda
and a group of other radical brilliance coaches.
You'll also receive one 30 minute coaching session with your own personal coach every week
and one 90 minute coaching session with Arjuna himself.
It's the ideal opportunity to drop deep into yourself into the source of your own creativity
and to get support for an entire eight weeks of mining your own radical brilliance
and bringing it forth into a project or creation that can truly serve the future of humanity.
Find out more at radicalbrilliance.com and click on the programs tab.
What I'm thinking we might do with that is go from now from collective to individual,
because what you're describing of finding radically different ways to not only arrive at conclusions
but the very mechanism of that computation is going to be different.
So that's probably not going to happen universally or at the same time as a week.
It's going to happen in certain individuals experimenting and reporting back
which may lead them to a gradual shift.
In the same way Copernicus didn't have to go door to door to every household in medieval Europe
for Galileo to prove his theories and for us to be headlong into the Renaissance.
It took a tiny percentage of people.
So let's go individual for a moment.
Let's imagine that somebody listening to this really felt all I want to do with my life
is contribute in the absolutely best possible way.
I'm going to dedicate my life to an upgrade and to the best possible upgrade.
What's the kind of shift that needs to happen on an individual level for someone to become a catalyst of evolution?
Beautiful.
If you'll indulge me, I would like to say one kind of broad thing first and then dive into it
because specifically when you said an individual becoming a catalyst of evolution
that's actually very different than our idea in biology of what evolution is.
And so the idea itself warrants speaking to.
When we think about what evolution is, there are mutations
and then some of those mutations lead to dynamics that are adaptive in that environment in the moment
so those ones are selected for and two types of selection.
That animal survives and it gets to mate.
If it survives and doesn't mate, it doesn't get selected for.
If it doesn't survive, obviously it won't get to mate.
So there's mutation and selection and the things that kind of work make it through.
But if some animal works well, but it works so well that it kills all of the prey
or it debases its environment so completely then it ends up killing itself too
because it has to be part of a self-sustainable environment.
So in evolution what ends up making it through are whole self-stabilizing ecologies
because anything else doesn't make it through long-term.
They'll make it to only short-term.
So evolution, the way we traditionally think about evolution is that it's a creative process.
It's a process by which new stuff comes into existence.
You had drafts and we didn't have drafts before.
We had whatever, right?
Because some mutation of the longer neck was useful and we kept doubling down on it.
So it's a creative process but we don't consider it conscious
that somebody is saying we like some long-necked drafts.
It was just like the mutation happened and then it was adaptive and then it got doubled down on it, right?
It's happening everywhere at once.
You have kind of mutation occurring everywhere at once.
And massive parallel processing and almost everything fails.
Most species don't make it through.
Most mutations don't get selected for at all.
But the few things that do make it through long-term are intercompatible with everything else
in a way that gives you profoundly complex, self-stabilizing holes.
So we can think of biology and the ecology that way.
That's one creative process.
And this is key to understand our crisis and all the crises we've had.
There's a second creative process which is tool-making or technology or design
that started with Homo habilis, probably, and then got doubled down on in Homo sapien.
And that is a fundamentally different creative process that we can't call evolution
because the spear isn't coming about through random mutation.
Somebody consciously understood a principle of sharpness in a different way than the chimp did, right?
The chimp will use a sharp rock to cut something, but it doesn't make a sharper rock.
And there's a really key difference is that the chimp will experience this rock in the eminent sense.
They're experiencing that it cuts.
And they pick up this other rock and it cuts better, and they'll use the one that cuts better.
And if you give it a knife, it'll even use that.
But it won't make the knife because to make a better one,
you have to understand this rock and this rock and this rock all have something in common,
which is none of the rocks, which is this abstract principle of sharpness.
What is sharpness? What makes sharpness? How could I make more of it?
Oh, maybe it has to do with the angle and maybe the hardness of the thing.
So that process of abstraction is unique to humans as we understand it.
Again, starting, give or take, Homo habilis, standard narrative of human history.
Humans or Homo sapiens?
I mean, as far as we understand, it's common to all of the previous kinds of Homo before Homo sapiens.
Like I'm saying, Homo habilis is the first tool maker that was designing new tools as we best kind of understand it.
Was that prior to us?
Two and a half million years ago, give or take.
Oh, way prior to us.
But that was the beginning of us starting to fundamentally be different in the whole rest of the animal kingdom.
Got it.
And the thing I'm trying to bring about here is that's not evolution anymore.
Yes.
So those tools are being created consciously.
Yes.
Whereas the mutations that are creating a slightly different animal are being created unconsciously.
I don't know if you are aware of this, but Barbara Marx hovered in one point coined the term conscious evolution.
Yes.
To describe exactly what you're saying.
It's evolution through a kind of conscious design, which she talks about as co-creating with the source of everything.
So now human beings are kind of a marriage of an animal evolutionary, unconscious evolutionary process, and a kind of divinely inspired ability to create something that wasn't there before.
Okay.
Yes.
And I think it's one of the most important kind of ideas that we can think about.
Barbara has really like advanced that so much, and I just want to add some specificity to it.
Yeah.
So us making tools is not conscious evolution.
It is a second creative process, which is design or toolmaking, but to just kind of go through the difference.
So evolution, like we said, is unconscious.
It's very slow.
It's massively parallel process there.
You got mutations everywhere and which ones make it through and then which ones make it through long term is what ends up making it through.
Toolmaking is actually not decentralized.
It's centralized inside of a single brain that can understand something to be able to make it, right?
Or inside of a single tribe that can communicate to each other to be able to make a complex tool.
There's actually consciousness involved rather than unconsciousness.
There's centralization rather than just totally decentralization.
So it's more of a serial than a parallel process.
And it's not trying to make holes.
It's making parts.
So we have kind of evolution creating unconsciously, creating radically complex holes and then toolmaking, creating conscious parts much faster.
One of the key things that the relationship between these two is fundamentally unstable and self-terminates.
Say more about that.
This is what explains everything from the fall of Rome in the Mayan Empire to the eminent fall of our current one,
if we don't actually come up with a new third process, which we'll speak to in a moment.
Wow, okay.
So let's do a little quick summary because I'm feeling like if I'm losing the plot a little bit, other people might as well.
So let's just briefly redefine one and two and make space for three.
I think I'm clearer about two, but...
Evolution, toolmaking.
So evolution is something that happens basically through trial and error genetic mutation.
That's what Darwin went through with evolution.
Toolmaking is more of a cognitive process, which as far as we know is singular to human beings.
And what you're saying is that those two tend to go on a collision course with each other?
No, I'm saying that...
So evolution has this kind of selection of what actually survives, makes it through.
The tools give us increased ability to survive.
They give us, as the species who can make the tool, increased ability to survive by debasing all the rest of the environment that we depend upon.
Okay, okay.
So when we talked about environmental degradation and we talked about war, our tools become the implements of larger scale war than lions or gorillas could have.
And they become the basis for larger scale environmental destruction than lions or gorillas could have.
Okay.
And so if we behave the way that a lion behaves, but we get to extend that through massive toolmaking, it actually is problematic.
So we become like a lion with machine guns.
Yeah, so if you think about it, like great whites didn't overfish the ocean.
Yeah.
Because they couldn't.
Yeah.
Because they would only get faster slowly as tuna were also getting faster, able to get away because the slowest sharks that didn't catch fish,
died.
And the slowest tuna, they got caught, died.
And so there's a way that their rivalry with each other actually made both of them evolve in advance.
Yes.
And our whole theory of markets is based on that, hey, competition is a good creative force.
It'll make us all strive to do better.
The best products and services of the best value will be the ones that the market selects for.
That'll be good for everybody.
But we're not acknowledging that the way that tools extend the power capacity and break the cemetery, right?
There's a cemetery of speed between the tuna and the shark where the tuna gets away a lot of times and the sharks die, right?
Sharks catch the tuna sometimes, same as the lion and the gazelle or the fox and the rabbit, right?
There's a cemetery of power where if the predator could become a hundred times faster in a hurry,
they would do better for one generation and then they would extinct themselves because they would eat all of...
That extend themselves and the prey.
Well, they would extinct the prey, which would then extinct themselves.
Exactly, yeah.
But only because there's a cemetery of their power with each other that they don't extinct themselves.
Our ability to make tools allowed us to become a hundred times better predators
and with exponential tools, a billion times better predators.
And so where that same evolutionary kind of competitive imperative doesn't end up creating sustainable holes,
it ends up creating a being that is debasing the substrate that it depends upon.
There you go.
So let's zoom in a little bit before we get back into this question of how can an individual best position themselves dedicated to future generations.
Let's just zoom in a little bit on defining tools because tools, obviously, the example we've given so far is sharpening a stone to make an axe.
But today, software is a tool.
An understanding in a book, I suppose, could be a tool.
The results of abstraction.
Right.
Applied abstraction.
It's also a tool, right?
All tools are applied abstractions.
Right, right, right.
So again, how we said earlier that it was always a new understanding about the nature of reality that gave us a new capacity that is what shifted, right?
A new understanding of the nature of what sharpness is that allowed us to make sharper things.
Humans with spears were so different than humans without spears.
Humans without spears, lions just take out.
Groups of humans with spears can kill every animal on the planet.
So automatically, we become this apex predator because our claws aren't that big, but we can make really big claws, right?
So our capacity to understand something allowed us to then apply that understanding in technology, right, in toolmaking.
So a spear is a technology and so is software.
But now we're still acting on the same kind of rivalrous evolutionary basis of like we're trying to get ahead at the expense of something else that the lion would be.
But there is now, rather than the slow humans don't make it through, or we come up to steady state with our local population and find steady state here,
we could kill everything and then migrate and then go kill everything somewhere else.
We could make tools like clothes where we could go to the Arctic and the Savannah and the islands.
No other animal could do that.
So we could go everywhere, become the apex predator everywhere, debase the environment everywhere, build new tools to succeed at that.
When other humans are competing with us too much, build the tools to kill the other humans.
Let me ask you a question because we're sitting here in your very nice spacious dining room, reflecting upon this.
So we're not having a conversation together about how can we build even more powerful tools to get more for you and me.
We're having a conversation about the potentially perilous impact of our tool building abilities, which adds another layer to the whole dynamic.
So maybe that, I don't know if we're heading in the direction of number three, but what impact does this insight have on our tool building ability?
For us to make it through a particular, so the crises that we've had historically were induced by our own behavior.
Some people had to be using abstraction to reflect on that, to either an outside group that was seeing how to prey on that weakness and be able to win in a war,
or the inside group saying, how do we solve this?
So that's what our abstraction can do, right?
So this does bring us to the number three.
If roughly we say evolution is kind of this unconscious evolution of holes though, because again, parts don't make it through long term only short term.
And then tool making gives us conscious creation of parts.
The third thing that we have to get is the conscious creation of holes.
There you go.
The conscious creation of whole self stabilizing ecology.
So this is the thing is that individual species don't make it through an evolution very long if they ruin the environment that they depend upon.
So the only species that make it through are the species that are part of a self stabilizing ecology.
When we think about social Darwinism, like applying Darwinian theory to the theory of markets, the idea of a market is an evolutionary idea, right?
We use competition and the survival of the fetus, the best things make it through.
But we're not understanding that our way that we think of social Darwinism is wrong in two really critical ways.
Short term, a highly successful animal will make it through or a highly successful species, but long term, if it is so successful that it damages the environment that it depends upon,
it won't make it through.
So the only thing that makes it through long term is whole self stabilizing ecologies.
We're not paying attention to that in the way we create markets, in the way we try to make a business get ahead or a country get ahead.
We can do it at the expense of the world that we depend upon.
So that is slowly suiciding ourselves.
As you mentioned, it's the cigarette rather than the gun, but it's still, if I debase that which I depend upon, I am self terminating.
The second thing we didn't get is that in getting social Darwinism wrong is that the animals can't increase their capacity to do their competitive thing quickly and we can.
And as a result, there's a certain kind of stability and evolution where the rivalry of the lion and the gazelle leads to both of them getting faster, but very slowly.
Very slowly, the best gazelles that made it through and the best lions made it through.
But if one of them got 100 times faster, quickly, right?
If gazelles got 100 times faster, all the lions would starve to death in a generation, and then the gazelles would eat themselves to extinction.
If the lion got 100 times faster, it would eat all the gazelles and then it would die.
So our ability to have tools extend our predatory capacity, but we're still acting like predators, is suiciding.
And so we need not just, okay, how do we maximally get ahead, our company, our country, our own personal balance sheet.
But when we can affect the whole as profoundly as we can, we can extinct species, we can create new species, we can ruin ecosystems, we can create new ecosystems.
That's not the power of a predator, that's the power of nature itself, right?
There's nothing in nature that has the power that we have other than all of nature.
So we can't think like an apex predator, because again, think about a great white and then think about an ocean trawler, and you're like, what?
Think about a lion as the apex predator and then think about a nuclear bomb.
So when we have that much power to affect the entire systems, we have to actually become stewards of the entire systems.
Now we're starting to talk about conscious evolution by design, not design, which is just making parts consciously, and not evolution, which is creation of self-stabilizing holes unconsciously.
But the creation of self-stabilizing holes consciously.
And this is what you were saying, how do we become the agents for evolution?
Yes.
It's actually, the idea of being an agent for evolution is not evolution, it's not the mathematics of it, it is a new third thing.
Yes, exactly.
And it's an ecology that has to be the base ecology, but also our technological built world ecology.
How do we make a technological built world in harmony with a natural world that is self-stabilizing?
That in nature there is no such thing as trash, and there is no such thing as unrenovable resource.
All the new stuff comes from old stuff, all those social cycles.
How do we make a built world that is actually stable, that is metastable, self-evolving?
That's the thing that actually I would say nobody ever figured out.
The earlier species that didn't, I mean the earlier versions of humans that didn't have as big of tools as we had now seem more sustainable just because they couldn't destroy stuff as quickly.
But that's the core thing that we actually need to figure out now.
Yeah.
As you're listening to this conversation with Arjuna Arda and his radically brilliant guest, you might feel inspired to go deeper into your own expression of radical brilliance.
Come join us for a one week radical brilliance laboratory held in a beautiful rural location in the Sierra Nevada mountains of California.
During the laboratory, you'll have an opportunity to dive deeply into all four quadrants of the brilliant cycle.
This means you'll be able to explore experiences of consciousness without boundaries.
And you'll be able to start accessing original impulses of creativity from within yourself that can become your unique contribution to the world.
You can get in touch with your own learning and integrate mistakes that will allow you to mature and grow.
You'll have the chance to deeply mine your own resources as well as connect with other brilliant people in a small, intimate context for a week.
You can check out the radical brilliance laboratories at radicalbrilliance.com under the events tab.
Well, let's do it before we, I want to ask you a question before we get into the kind of the really micro level of this.
Let's just reflect a little bit how we're doing because there is a whole new kind of industry evolving,
which people call social entrepreneurship or eco businesses,
where at least the visionary statement is to create technologies that have either minimum ecological impact or even an ecological restorative impact.
And there's always the danger if we come back to the way that we solved the problem with the horseshit in London was something that was actually more harmful.
So how can we evaluate today the well-intentioned new industries that are evolving to try and be eco-friendly?
How much do they contain within themselves unprecedented consequence?
Lots of people won't like what I have to say about this, so they can listen to other things.
When Einstein was developing relativity, he did not intend of all.
He didn't intend the first ever tool that could extinct everything, but it was directly the result of the work he did.
If we look at that phenomenon, we didn't intend climate change and destabilization of the whole world politically and more from cars.
But that happened.
And when the Wright brothers were making the first planes, they weren't necessarily focused on the military industrial complex,
having plane technologies to be able to kill people at a scale never previously dreamed of that only could happen with those planes.
So there's this topic of weaponization.
And I don't just mean a military weapon.
I mean a tool that gets used for some rivalrous purpose once it's been developed.
When I talk about weaponization, I mean the ability to win a finite win-lose game.
That can be a kinetic warfare where we're actually physically killing each other.
It can also be an economic warfare where we're trying to compete for market share.
It can be an info warfare where we're trying to keep the actual info about reality to ourselves and maybe even disinform the other guy.
Or a narrative warfare. We have the best narrative.
And it's our religion is the best religion or our political party or our nation or our race or religion.
Those are all basically ways that an in-group tries to maintain an advance, its competitive advantage related to an out-group,
where they believe that they're in a zero-sum relationship with each other.
So somebody tells me, hey, some academics workmen, AI called me recently who identify as progressive and said,
we figured out some great new AI capacity for being able to take the progressive doctrine and spread it through the world.
We can basically customize people's news feeds the way that the right is currently doing, but better, whatever.
And I said, let's not even discuss whether that progressive doctrine is the right one or the true one,
but let's just take for granted that you assume you're right and that you should use all the tools possible to win at the game that you're sure you're right on,
which is what all wars have always been on all sides.
Do you think that once you deploy the technology, if it is found to be effective,
that it won't be reverse engineered and used by all sides for all purposes?
Because, of course, it will be.
So all you do, the moment you deploy a technology and it's advantageous,
everyone reverse engineers, it makes mutations on it, uses it and then seeks to advance insights in a rival resetting.
So you might get some near term advantage, but really you just up the ante of the scale of warfare for everybody.
This is the thing we actually have to solve as a species, we're at large.
Right now, if I develop a fundamentally new capacity, I'm developing AI for medical research and it's going to use visual recognition on patient data records
that are being scanned in to then have big data and deep learning to do early predictive disease stuff.
Awesome, that seems like we're going to save a lot of lives.
Can that same AI technology be used for weaponized purposes?
Yes.
Where there is major advantage to do so in financial and etc.
Yes.
And where no group will avoid doing it really because they assume that the other groups are doing it anyways.
And so then they lose if they don't.
So this is this idea of a race to the bottom, right?
Nobody wants to give up their nukes first.
Because everybody knows like we're not a sucker, we're the first ones to give up our nukes, we get taken over at the top.
And you can't force anyone who has nukes to give up their nukes.
Everybody else wants more nukes, but now we're in the same place with AI weapons like nobody wants to live in a world with AI weapons.
Everyone knows that that's just a comprehensively worse world for everyone.
But everybody's working on making them.
Because we assume that if we don't, the other guy is, and then we just lose by default.
So to not lose by default, if anyone does, we have to and we have to race towards the worst world possible.
This is called a multipolar trap.
And as long as we have separable interests, one nation that can advance itself at the expense of another,
one company that can, or even one balance sheet that can, we won't be able to get out of the multipolar traps.
Where even if I'm developing new capacity for a positive purpose, it will get weaponized.
And that's one issue.
The other one is if I'm seeking to advance some metric that's important, might I be damaging other metrics in the process?
Like let's do geoengineering to bring temperature down, but in the process we might drive acid rain and pollution of whole environments and whatever.
The way we think about how to solve problems is not adequate to the complexity of our problems.
We can't try and isolate out some metrics as if the world isn't interconnected.
Try to advantage those, and we can't pretend that our capacity won't be utilized for all purposes that there's incentive to utilize them for.
Now when I say conscious creation of new holes, that's what I mean.
It's not just we're going to create some solution for this thing, which is a part, which is what most social entrepreneurship is doing.
But can we think about how do all these problems relate?
What are the underlying drivers that have all humans working towards things that nobody actually wants?
Nobody actually wants war, but a for-profit military-industrial complex and these multi-polar kind of dynamics make it hard for anyone to avoid doing it.
How do we solve those?
So I think this is a good point because it's actually, at least in my view right now, my mind just crumples in the thought of doing that collectively right now.
But when we think about how can an individual shift their values, their belief systems, their way of life, their daily practices to come more into that view, it seems very attainable on a micro level.
So I mean, I think you and I probably, given choice, we would probably look to whole system solutions more than individual solutions.
A good parent will often put the needs of their children before their own needs, and we can extrapolate that out.
But there have been, and hopefully today there are examples of leaders who will put the good of the whole beyond the good of even the nation state or certainly beyond the need of their own party.
So we have seen examples of that.
So I'd like to zero in to make this really, see if we can turn this into some kind of action steps for people.
What can we do if we want to really fully align ourselves with the best possible future?
What are some ways that we can change the way we think and behave individually so that healthy trees become a healthy forest?
I mean, perhaps before you answer the question, let's ask, do you think that's a helpful question?
Sometimes we end up asking the wrong question.
There's a deeper analysis we haven't done yet.
I'll just allude to it, which is that the processes that have been most successful so far for how we solve problems
are problem solving toolkit itself.
I propose are inadequate to solve the types of problems we have now.
So democracy is an example.
Capitalism is an example, and science is an example.
These are like our favorite best things yet, right?
As meta processes for how we do stuff.
So democracy, we can see that in the U.S., the left-right polarization is untenable,
that really good, clear understanding of the world and what comprehensively good strategies would be don't exist anywhere in any political party.
We can see that not just in the U.S., but kind of everywhere.
But then as we just kind of look at the math of it, if we look at the just fundamental structure,
we say, okay, democracy is a way that when there's too many people for everyone to be part of one conversation,
rather than just have a few people rule everything, right, some kind of dictatorship or meritocracy,
how do we at least make sure that, since everybody can't agree, can we at least get that most people agree?
That's kind of the idea.
I just have to quickly slip in there.
Dictatorship is not always a meritocracy.
Structurally, meritocracy, dictatorship and consensus, this is a way we would structuralize it.
Consensus, as everybody agrees.
Democracy is at least most people agree on something.
Meritocracy is for some reason, some people make most of the decisions,
and it's based on some idea of who should make the decisions.
And maybe the merit is, I just won the power game, the Game of Thrones.
Or I'm just a bigger asshole than everybody else.
That's the Game of Thrones, right? I won the power game.
Sometimes it was just I was born into that royal family lineage, sometimes I was elected, whatever.
I think it would be worth looping back to that later, because there might be a genuine meritocracy we could propose,
which is actually not so much based upon those kind of accidental factors,
but a genuine ability to be able to embrace the good of the whole.
But let's put that aside.
That actually comes very much back to what you were saying is,
can people increase their capacity and then put the whole first,
and then can those people maybe work together in some meaningful way?
Right, yeah.
But so just when we look at democracy, we say,
okay, well, when there's, if everybody can't agree,
at least more people liken something than not seems fairer than more people not liking it, okay?
But if everyone can't be part of one conversation, who even makes the propositions?
So somebody, some small, some process makes propositions
that usually is focused on benefiting something that is cared about by that group,
special interest group or whatever it is.
But that proposition to benefit that thing they care about
is connected to other stuff that they might not be aware of at all or might not care about.
Exactly, yeah.
So every proposition pretty much benefits something and harms something else,
because the way it was formed didn't have everyone sense making
actually informing what a good proposition would even be.
Great point, yeah.
And so that's why you never have a time where everybody votes yes or everybody votes no on a proposition
because if I really care about the thing that's being benefited, I like it, the proposition.
But if I really care about the thing that's being harmed, I don't like it.
Now, if you really care about the thing that's being benefited
and you're voting yes for it and it would make your children's lives better
because it's going to help jobs or whatever and you guys can't get jobs,
but I say it's going to hurt the environment.
And so I'm saying no, because I care about the environment, I don't need the job as much,
then you see that I am actively lobbying to make your child's life worse.
Now, that creates so much enmity and polarization, right,
that then now we start spending most of our time not coordinating with each other but fighting each other.
So now this is a massive coordination failure.
And the truth is something that was good for the environment and good for jobs
would be preferred by everyone, but we don't have a process of collective intelligence
to come up with what would a good way forward for everyone even look like.
So the process of voting, yes, no on any proposition, is inherently polarizing.
So any system that just even uses voting,
it's not a good enough system of collective intelligence to have a population actually be able to
do collective sense-making of what's needed and collective choice-making.
So that's an example of like, well, it was a good tool, it got us pretty far,
but that tool itself is not a collective intelligence tool that will solve these problems.
I'll make a suggestion. What do you think if we, because I can see we could have an equally in-depth conversation
about democracy, capitalism and science.
Right.
How about we put that into a second conversation and let's see if we can loop back to a few takeaways for...
So the proposition, you're right, the proposition I was going to say is that our processes themselves
for how we solve things are themselves actually the cause of the major problems we're dealing with now.
We can see that capitalism and market-driven solutions of most of the problems in the world
are financially incented, right?
And we can see that science makes all the techs that is causing the problems,
but science is not commensurate with an ethical system for how do we actually, you know,
science says what is, but not what ought.
And so it makes all the applied tech power without having any guidance on it.
So then again, capitalism and power games end up being what applies it.
So then we say, okay, if I try and just make a new business within capitalism
or a new tech within science or a new proposition or a new representative within democracy,
those are not deep enough solutions for the nature of the issues we have.
And that's us thinking within a certain axiomatic framework of what has got us here.
But what has got us here has got us the successes, but also all of the systemic failures.
So what I'm saying is that we actually need a new problem-solving toolkit
that is deeper than capitalism, the philosophy of science, and democracy.
And that, so if I default to an action bias, what can I do?
And I'm assuming that I do it within those frameworks that we've done stuff before.
I would propose we don't actually solve the problems we need to solve.
At best, we will solve one problem, make another problem worse.
Great. So I'm actually hearing kind of an answer to both these questions.
Because I'm thinking about how can individual best position themselves to make the greatest contribution.
And you're saying to make any kind of contribution within the existing system
is going to be, you know, at worst disastrous and at best irrelevant.
So what I'm hearing in this is that what individuals actually need to cultivate more than anything
is what is sometimes called like disruptive thinking, right?
Which is this central mantra of who says it has to be this way.
One of my other guests, I don't know if you've met them yet, but there are twins.
Mickey and Radha Agawal, do you know them?
Oh, well, that's a treat coming your way soon.
Most incredible. Mickey is married to Andrew Horn, Sam Horn's son.
They just have this innate ability to question status quo.
Not in an aggressive way, but in a like, wait a minute, who says it has to be like that?
How about we do it like this instead? But at a very fundamental level.
Right.
A simple example is Radha, she loves dance, she loves party, right?
If I tell you, I'll just give you a quick example about disruptive thinking
because I'm thinking it's a great way for us to explore.
So if you think about, you know, she loves to be with a large group of people,
with loud music and everybody's dancing and sweaty, you know?
And if I was to ask you, you know, your assumptions, if a bunch of people get together,
you know, what time of day is it usually?
Middle of the night, right? And then what are they consuming?
It's probably alcohol, cocaine, you know, we could keep going.
So she was disruptive. She thought, well, there are things I really like about this,
but there are things that are regrettable because it bounces and everything.
So what does she do? She created this thing called Daybreaker,
which is basically raves at six o'clock in the morning, right?
So everybody gets up, gets up after a good night's sleep,
goes up to some factory somewhere, you know, some abandoned factory,
has a rave where there's going to be good quality coffee, green smoothies,
you know, instead of bounces, there are huggers, you know.
So this is disruptive, you know, disrupting what we think is necessary for something to happen.
And what I'm hearing you say is that for an individual,
rather than learning to compete really effectively within the existing system,
is to really think disruptively about the systems themselves?
Yes, thinking outside of the frameworks of what has already been accepted,
we could call disruption.
In as deep a way as possible, that's what I'm hearing.
In as deep a way as possible.
But obviously I can disrupt stuff in lots of ways that don't fall forward.
Yes.
And so just, just forgive me.
Disruption is one of those terms that it's kind of like when you,
when there's a pop song you really like, but then it's played so many times
that you kind of stop liking it.
Disruption is one of those terms that has been made so sadly weak
because Silicon Valley caught on to it and then basically
any company that is going to be able to get a lot of market shares disruptive
even if it's the same fundamental, the same fundamental concept
of how to win at a win-lose game.
And even if it's a kind of narcissistic disruption, just disruption for disruption's sake.
Yeah, or it's disrupting how an industry does things,
but for the meta-purpose of why industries exist at all,
which is for somebody to get ahead in a win-lose fashion.
Yes.
So I'm thinking about applying disruption to the very fundamentals
of decision-making process of economics and of the way that we gather information.
Yes.
So now let's think about that and say we said we can't just depend on evolution
because it is too slow and it's changes
and that we're affecting things at too big a scale through now technology creation.
That technology creation and evolution together give us kind of this rivalry spaces
from evolution but multiplied by radical power asymmetry.
If we don't start thinking about the conscious creation of what are actual sustainable holes
and take responsibility for the whole, not parts within it,
then we fail.
If all of my organs separate, like all the parts that seem well-designed are not interesting.
It is actually only the way that it all comes together.
If I think about all the ways to arrange the molecules in a cell,
there's trillions of ways of arranging those molecules that all fail.
There are very few that actually make a cell that respirates
even though none of the molecules respirate.
And so it's how all the parts come together into a hole that is the synergy
that is more than some of its parts that's the whole thing.
It's a brilliant analogy actually because I mean you couldn't imagine
if the stomach and the liver competed greedily for blood.
We would just dissolve into goo.
Yes.
And so when you think about, well, in the body, how does it work?
It's not we divvy up the resources equally between all cells or all organs.
It's also not that they compete with each other and hoard.
It's a much more complex process of what is most needed right now
factoring everything and a distribution of the resources to everything
factoring the whole.
It's a different process, right?
And so there is a difference between the lungs and the heart,
but they are inseparable so you can't factor their difference in a separable way.
So what I want to see people,
so you ask what is a way that people can start right now thinking about this?
Yeah.
If people started to say, well, what if I was responsible?
Like what if I was responsible for the whole?
For all of it.
Yeah.
If I even start to think about how to approach that,
how would I start to design that?
Because there's a way where I can think about my people and how to defend my people
that just leads me to continuing warfare,
knowing that the other side will then also continue warfare
and we get big enough warfare that kills everyone.
I can think about how to solve temperature
because I don't want the ice caps to melt by reflecting 20% of the sunlight
that then has, okay, well, what happens all that stuff I put in the atmosphere
to reflect the sunlight when it comes down into the water.
And when it, you know, I can think about partial problems,
not in relationship to the whole,
where all I do is actually move the problem somewhere else
and oftentimes make it worse.
That doesn't work anymore.
So what I'm saying is partial problems are not solvable anymore.
The whole is too complexly interconnected.
The whole has always been interconnected,
but our level of globalized technology and the total impact of technology
makes the eminence of the interconnection sets that we have to.
This is the core thing.
We are too powerful in our effect on the whole
to not be taking active responsibility for how that power affects the whole.
So if I'm going to be making a choice that affects stuff,
I need to be contemplating everything that's affected
and internalizing all of those effects to the design.
I call that omniconsideration.
How do I consider?
How do I both care about and think about the cause and effect of everything affected?
I love how that distinction between care about and think about.
It has to be both.
Those are actually two different things, right?
Because thinking about is where it's necessary to be able to think,
but it's intrinsically limited by knowledge and by the restraints of logic.
But then care about actually has more of a...
Yeah, I guess we'd use a cliche word like more heart,
but more compassion, more of an intelligence that's not limited by rationality.
We've got an e-book for you which explains the radical brilliant cycle,
the way the cycle gets blocked,
and the practices that best open up the cycle again.
We also have five days of gifts and insights for you,
delivered every day by email and video,
which go much more deeply into the phases of the cycle,
the ways that the cycle can become a kind of diagnosis of blocked brilliance,
and a way to accurately find the right practice for each person.
In addition, you'll receive a video about the single most important practice
that we have determined affects brilliance.
And another video about everyone's favorite topic.
Brilliant sex.
It's all totally free.
Prepared for you as our guest.
Please come to radicalbrilliance.com.
Register on the homepage and you'll receive the e-book right away.
Then you'll be guided through the five days of videos
to take you deeper into your own radical brilliance.
So, lots of people have recognized there's not one kind of intelligence, right?
Howard Gardner talked about eight types of intelligence that are all different
and the chakra system of Indian thinking or Chinese or Egyptian thinking
were like different kinds of intelligences
and they said they actually all need to be lit up, right?
And aligned with each other.
Let's just do a super simplified version for a moment
where we talk about kind of will, heart, and mind.
Okay.
And again, recognizing we're simplifying and making a model
which is always kind of wrong but useful.
So, for some of this, a lot of people are going to be hearing this.
So, let's just, I'm just going to say where you were pointing.
So, will, you were pointing like to your solar plexus, I believe.
Yeah.
Heart, you obviously pointed to your heart
and mind you pointed to a place just between your eyebrows.
Head, roughly, yeah.
So, if we take will as the actual force to make choices, right?
The actual impulse and capacity to make choices at all.
Okay.
If we take heart as what is it that I actually care about
and what is it that I actually value that I want my choice to be in service to?
And then I take mind as how do I understand what an effective choice would be?
How do I understand cause and effect to be able to do design or strategy or tactics, right?
We see that they all play in together.
So, we can talk about choice making resulting from the way we do sense making.
What's actually happening and what would happen if I did X?
And values generation.
What do we care about?
What are we trying to affect?
So, again, as we saw in that example earlier with democracy,
if what I care about is the economy and people being able to get jobs
and I say that's all I care about, I'll ruin the environment.
If all I care about is the environment, I'll create poverty.
No, I actually care about both.
Now they're both design constraints to be able to come up with a better proposal
that doesn't pit them against each other.
Yeah.
And so...
That's a fundamental change in a human being.
It is a fundamental change that we stop thinking in terms of theory of trade-offs
of things that are actually synergistic or symbiotic with each other
and say, if I take both of them as design constraints,
what is a better design that actually serves the relationship between them?
Yeah.
You know, the analogy that comes that's most visceral,
and I can imagine, would be a parent who, going to their kid's football game,
who's actually wants the other team to win as much as she wants her son's team to win
because they're all kids wanting to,
they're all kids who, you know, have the same right to a good time
and to a feeling of heroism, a feeling of triumphing.
And if I take that example, I say within one game,
the game is by definition zero sum.
There's only one win that can happen,
and if one side gets it, the other side does not get it.
Yeah, but exercise isn't the game, you know?
Exercise isn't.
But even if I take the iteration of the game and I say,
hey, this, if the mom only supports this one side
and the other side is not well supported,
they come from low income and their parents aren't there or whatever it is,
then, one, I'm not caring about the whole,
but it doesn't even create a good sports game from my side
because they stop having a good team to play against.
So if I care about the quality of play more than a particular win,
then, of course, I want to support everyone to keep increasing the quality of play.
But unlike a football game, most things actually aren't zero sum.
We artificially assume that they are and make them that way.
Most of the time, if I say, OK, well, I want to protect the environment
and I want to make the economy better.
If I don't, if basically, if I don't consciously think about that,
I can just cut down the tree's helmets too by force.
Dead trees are worth more than living trees.
Living trees aren't worth anything.
On my economic balance sheet, we'll cut all the trees down, which we've done.
But if I say, is there a way I could make a forest worth more alive than dead?
And I took that as a design challenge
and I started to think about ecotourism in the area or whatever it would be.
As soon as the forest is worth more alive than dead,
protecting the forest and advancing the economy aren't in a theory of trade-offs anymore.
They're synergistic.
Well, you're using the word worth in its commonly used meaning tied to money.
But if we thought about worth in terms of the quality of life of our grandchildren,
then definitely a living forest is worth more than a dead forest
to our grandchildren having a good life.
Now this comes down to why I said capitalism is an inadequate framework.
Exactly.
Because if those two worths are decoupled,
the people who focus on the money get the near-term advantage
because now they're concentrating choice-making.
More money means I can put more people in my employment
and more technology in my employment, which means I have more choice-making.
And then they'll end up winning at how they affect the world
because they're increasing their capacity to affect the world.
And those who are trying to conserve for future generations
aren't increasing their choice-making capacity and they lose.
So Tibet loses to China, Greece loses to Rome,
they make sure our old nice tribes lose to the warring tribes.
We can't keep doing that thing, right?
Exactly.
And so if I could have a place where the near-term advantage
and the long-term well-being are decoupled and we're just screwed
and capitalism happens to decouple
what provides the most near-term advantage to me
and what provides the best long-term well-being for the whole are not the same.
I think we need to have a whole conversation about what would be required for coupling those.
Great.
But let's come back to the three things real quick because we didn't close that
and that's actually the thing I wanted to close with. Is that all right?
Yeah, sure, sure, sure.
Well, let's close that and then let's finish with a takeaway,
particularly I'd like to think of a takeaway for a younger person
for like, you know, what's actually just like a daily practice for your doctor
or some commitment you could make to inject whole systems thinking into your day.
This will relate.
Okay, great.
So let's go ahead and just take this simplified model of my capacity to make choices.
Will, my...
And this is non-trivial, right?
Because a lot of people feel like, oh, I want to make a certain kind of choice
like to exercise or meditate or eat a certain way, but my habits overwhelm me.
So I don't feel like my will is strong enough to actually make the choices
aligned with what I value and what I know.
And so the development of will is the ability to have your own choice
be a deeper influence in your life than the choice of everybody else
or habits or past conditioning.
So that's the development of will, right?
That my choice is actually more coupled internally to what I care about
and what I understand rather than to a bunch of other stuff, habits and defaults and whatever.
So the development of will, one thing, right?
The development of what do I care about?
I can care about my people and as a result, support a war.
Not realizing that the other people who care about their people
will keep also trying to win at the war and we just keep escalating war for everybody, right?
I can care about my family getting ahead,
not realizing that everyone caring about their family getting ahead within the current construct
actually ruins the environment in a way that no families will get ahead.
So how do I expand the scope of what I care about to include more because it is all connected?
And then sense making.
How do I actually understand the way that it's like,
okay, well, if I want to try and solve these problems, what causes the problems?
Why there's $70 trillion that trades hands every day that all represents human motive,
but most of it is actually externalizing harm somewhere.
How do we create a better system that doesn't incentivize the wrong things?
How do I advance my understanding?
How do I advance my understanding of how is climate change and war an expression of the same thing?
When lose kinds of structures or how does this metric and this metric relate?
So now let's look at just any of those in isolation or even couplings of them.
If I take really effective mind, the capacity to do strategy well and really effective will together
without widely inclusive values, I get effective sociopaths.
Yes.
I get the military industrial complex.
That with a coupling of will and intellect.
Correct.
But without compassion or caring or heart.
And of course this is a generalization because everybody has heart towards something but it might be quite narrow.
Right?
So we're going to get our narrow agenda ahead but with a tremendous amount of action and a tremendous amount of strategy.
So that coupling is kind of actively ruining the world.
If I take mind and heart together, I get like a smart carrying academic but who can't actually do stuff because they don't have effective will.
And they're just kind of crippled by the scope of the problems.
If I take will and heart together without mind, I get activists who are working their ass off will towards the goal of the whole but without good strategies.
And as a result, the military industrial complex and multinationals who have better strategies will just win every time.
So we can see that like ineffective activists or overwhelmed, unpowerful carrying academics or kind of sociopathic effective like none of those couplings are okay.
It takes all of them.
If you take away any of those three legs of the stool, the stool is going to fall off.
And what ends up happening is the effective sociopathy wins and the short term and kills everything in the long term.
And we rationalize the sociopathy.
Hey, if I don't do this, somebody will.
I'm trying to do at least the one part I can do.
I have to break some eggs to make the omelette because it's the only thing we can think to do.
But when you look at like, okay, so Gandhi was a person who ended up defeating the world ruling empire and freeing 400 million slaves.
Not to say he didn't have some failings, but you look at the will and the heart and the strategy together.
It's all deeply invested in.
And everyone who made the most meaningful changes, there's a way that those are coupled together.
So if you think about in your own life, what are you developing?
If every day or every month or week or whatever, you are in some ways developing your will so that the choices you make are more aligned with what you understand and what you care about.
And there are ways of doing this.
There's ways of like, okay.
So before I turn my phone on, I meditate.
Meditation itself, even if it's just short, is how do I actually bring my thoughts and body under will more?
When I consciously breathe, I'm bringing something that's normally unconscious in the consciousness and having choice influence it more.
Choice influence my thoughts.
So how do I keep advancing my will?
And we could have a whole talk on that.
I keep expanding, deepening what I care about and expanding it.
So I go to a factory farm and I see the condition that the animals are in and I'm like, fuck.
Is there a model of my life that feels like a success to me as long as these animals are in this condition?
They can't get themselves out and it's not their fault they're here, but I could do something to get them out on the outside.
What do I need to do about this?
And I go look at the trash in the ocean.
I go look at, so how do I extend my scope of care and deepen it?
So it is more in the forefront of my experience.
And then mind is, am I seeking to understand what's actually going on in the world better and what could be effective?
Am I seeking to think more deeply about how could we solve these problems?
What would a world that worked for everyone even look like?
Have I thought through this that well?
How one of my favorite practices my whole life was imagining, what would life on an enlightened planet be like?
Totally.
And it's not obvious because you start to run and you say, well, they would vote, would they vote?
How would that not create polarization between them?
Would they even do that?
How would they craft a proposal in the first place?
How would they listen to each other?
How would they actually deal with emotions and with sexuality and with conflict?
I've got an idea.
Let's do a whole conversation just about that.
Just fantasizing what would life be like on a planet where they didn't make any mistakes?
I wouldn't even say didn't make any mistakes.
I would say where people's will was developed and their heart and their mind were all developed.
We take that as kind of a definition of enlightenment that they are all caring about the whole.
They're thinking about the whole effectively and they're acting aligned with their thinking and caring.
How would they do stuff?
And we could do a whole podcast on that, but I guess the thing I'm encouraging is that everyone actually has that be central to their life.
And that they're really thinking about that.
Because they're like, well, am I even working to bring about a world that makes any sense?
What would a world that make any sense even mean?
I haven't even thought about what a world that would make any sense would look like well enough to have a sense that that's actually the right thing.
One of the other guests I have on this series is Martin Rue, who actually developed this thing called the Heaven Earth Project.
And he does all he does.
He just gets people to imagine what is your idea of Heaven on Earth?
Well, of course, just imagining it warms the whole thing up.
Then we start to compare our actions today with what we imagine.
So I think that's a beautiful practice.
And if people are, if you were just asking, we're talking about very like collective structural issues like the tool design and evolution together create instability.
And we need to create this new third process for how humans consciously take responsibility for the power that we have in creating, creating holes.
And you're like, well, what do individuals do?
If every period of time, day, week, whatever you want to consider, your will is advancing.
You're actually getting better at choosing a way that's aligned with what you care about and what you understand.
What you care about is advancing.
You're deepening your consideration of what do I care about and feeling it, right?
So you watch the documentaries and you let them hurt.
But then you say they only hurt because I care.
If I didn't care about the animals or the oceans, this wouldn't hurt at all.
And then you take the hurt back to the care and be like, wow, I actually really fucking love the ecosystem.
I really love people.
I love those people who I've never met in poverty where that's why when I see them hurting there, it hurts me, right?
Actually, just love the essence of humanity.
Let yourself deepen that and be coupled to it where all the choices of your life have to be expressions of it.
And let yourself keep deepening on the everyday, week, etc. basis how we understand the world.
What do I understand?
And like we said, it was Newton deepening the way of understanding the world that led to the whole world shifting.
Or Einstein or Von Neumann or the Greeks or whatever.
How do I deepen?
So how do I deepen what I care about?
How do I deepen my understanding of the world and how do I deepen the congruency of my actions being aligned with those?
I would say that's just a very simplified framework for am I developing myself as the type of person that can be an agent for the whole?
Brilliant.
Brilliant.
You know, we could add one little piece to that which I think is so important is developing friendships and relationships which directly cultivate those three qualities.
Because that's, you know, we are so much more effective at bringing about changes in the way we operate when we do it together.
Thanks a lot for spending time.
Two things on the friendship, just briefly.
Yeah, okay.
That one is the individuals can't change these things.
It has to be groups.
So when we were asking about individuals, like yes, but then of course, even to the degree I'm succeeding, how do I come together with other people to do this?
But then it's also even recursive who I'm hanging out around is going to influence how I'm developing as a person.
More than pretty much anything else.
So consciously paying attention to am I interacting with people in ways that are supporting the evolution of who I'm wanting to be?
You know, it's funny, because I'm doing a, you know, I'm sitting in your house.
I did a coaching session with a client this morning and he said, oh, where are you?
Because there's this four poster bed and I said, I said, oh, I'm at Daniel Schmacktenberger's house.
He said, oh my God.
And because the last week that I talked to him, I was coaching him sitting in the car outside the Linden Twist House.
And I said, every time I talked to him, I'm about to meet somebody that he really admires.
He said, oh my God, you know, you're constantly surrounded by these amazing people.
Yeah, why would you choose anything else?
I mean, just in the same way, if you go to, I shop at our local co-op, you know, and I buy the best ingredients.
Why would you choose to put anything else in your body except what's going to help us to operate in the best way?
So friendships can be like that.
It's like eating organic food.
You surround yourself with people who share your intention to make the best possible difference.
It has an exponential effect.
We kind of, we support each other in an upward direction.
And thank you for doing that with me for the last, for the last period of time here.
Thank you.
This was fun.
I look forward to it.
Hey, well, that was Daniel Schmacktenberger.
Always amazing.
Gets you thinking in a deep way.
You know, in Nevada City, where I live, on Friday nights, I go to an event called Fusion Dance.
It's a great, it's a greater form of dance merged together from different styles of dance from the streets rather than from the ballroom.
So when I go along there, there's sometimes, you know, somewhere between 40 and 60 people.
I used to have this unspoken code in my mind that you can only dance with the same person once in the evening.
So if you've danced with somebody, you've got to go ask somebody else to dance.
But after a long time of going to Fusion Dance on Friday nights, I asked myself the question, who says, who says you can only dance with the same partner once?
If you really enjoy dancing with somebody, you could dance with them over and over again in the same, same evening.
And I've taken the same approach to this podcast.
So you'll be hearing plenty more from Daniel, who says that I can only have him as a guest once.
So he's one of my favorite people, one of the most intelligent, altruistic, compassionate people I know,
using his powerful way of lateral thinking, not for his own self advancement, but for all of us.
It's really kind of Bodhisattva thinking at its highest level.
So we'll be hearing plenty more from Daniel in the weeks and months to come.
Now, in our podcast today, as you heard, I was kind of pressing Daniel a little bit for a takeaway.
How can we take this understanding of what we need collectively to advance, to evolve, to survive, and apply it individually?
And he spoke about the cultivation of understanding, mind, of caring, heart, and of will of action.
And then he asked a question, we just brushed over it quite quickly, but he asked this question,
what would a society look like?
Either a society we imagine from our own future, or perhaps from a society on another planet in a science fiction scenario,
what would a society look like where people were living in highly advanced states of understanding, caring,
and the capacity to implement and create results?
Daniel pointed out the disastrous results of mind and will without heart, which is sociopathology,
of mind and heart without will, which is the sort of disempowered, caring academic.
And he also spoke about implementing and heart without understanding, which he called a kind of activism,
which doesn't include the whole, or which becomes fragmented from other activism.
So what would a human being look like, and what would society look like with the full development and the full integration of those three?
Of mind, the capacity to understand things in a whole systems way, of heart, the capacity to care deeply about things that don't only affect you personally,
and will, the capacity to create results in a physical way.
So I'm going to ask you to contemplate that as our takeaway from today.
You could do it maybe right now in your journal, is imagine a society, imagine a society in our own future or on another planet
where people collectively have developed the capacity to have all three of these operating at a peak level together.
You can share the fruits of your contemplation on radicalbrilliance.com, go to the podcast tab, you'll find this podcast there where you can comment,
or you could go to facebook.com forward slash radicalbrilliance, scroll down, you'll find this podcast, you can comment there as well.
I'm always, we are always very interested to hear what you have to say.
Till next time, we've got a whole bunch of amazing guests lined up, all of whom in their own way have dedicated their lives to a sense of contribution.
Everybody I invite onto this podcast has found a way, a kind of a modest, unastentatious bodhisattva vow,
a way to make their lives a contribution to the sustainability and the quality of life of people not even yet born.
See you next time.
