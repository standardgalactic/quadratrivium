I'm a graduate student at the CUNY Graduate Center, and today I want to talk to you about
Bayes' theorem.
Bayes' theorem is a fact about probabilities, a version of which was first discovered in
the 18th century by Thomas Bayes.
The theorem is Bayes' most famous contribution to the mathematical theory of probability.
It has a lot of applications, and some philosophers even think it's the key to understanding what
it means to think rationally.
In order to understand the theorem, though, we'll have to understand a little bit about
probabilities.
The probability of a proposition is the chance or likelihood that that proposition is true.
Suppose you know that one student in a class of 20 has the flu, but you don't know who.
If you know that Sally is a student in the class, you would say the probability that
Sally has the flu is 1 in 20, or 5%, or .05.
We can call this your prior probability that Sally has the flu because it's your probability
prior to finding out any new information.
As a shorthand, we'll write P of Sally has the flu equals .05.
Suppose now that there are 5 girls and 15 boys in the class.
Now, you don't know whether the class's flu patient is a boy or a girl, but if you
were to find out that the patient was a girl, your probability that Sally has the flu would
go up to 1 in 5, or 20%, or .2.
On the other hand, if you were to find out that the patient was a boy, your probability
that Sally has the flu would go down to zero.
Because these things are still iffy, though, remember you don't yet know whether the flu
patient is a boy or a girl, we'll call these things conditional probabilities.
Your probability that Sally has the flu conditional on the flu patient being a girl is .2.
Your probability that Sally has the flu given that the flu patient is a boy is zero.
As a shorthand, we'll write P of Sally has the flu given that the flu patient is a girl
equals .2, and P of Sally has the flu given that the flu patient is a boy equals zero.
The little vertical line tells you that we're talking about conditional probabilities.
Now, here's the thing.
Sometimes you don't know what your conditional probabilities should be.
In other words, you know that you might encounter some new evidence in the future, but you don't
yet know how that evidence should affect the probability you assigned to some hypothesis.
Here's where Bayes' theorem comes in.
It gives you a way of figuring out what your conditional probabilities should be.
So what does Bayes' theorem actually say?
Remember our shorthand.
Your probability in some hypothesis, let's call it H, conditional on some new piece of
evidence, let's call it E, is written P of H given E.
Here's what Bayes' theorem tells us.
P of H given E equals P of E given H times P of H divided by P of E.
In other words, it tells us the three ingredients that go into the probability of a hypothesis
conditional on some evidence.
The probability of the evidence conditional on the hypothesis, the prior probability of
the hypothesis, and the prior probability of the evidence.
Let's look at an example.
Imagine that one morning you don't feel right and you go on WebMD to figure out what's
wrong.
You're browsing around until you find an illness that catches your eye, hypothesis.
So the hypothesis under consideration is that you've come down with hypothesis.
As you read through the list of symptoms, you realize that you have all of them.
In other words, you have all of the symptoms that you would have if you had hypothesis.
So let's say P of E given H or P of symptoms given hypothesis equals 0.95.
You begin to freak out, but then you remember Bayes' theorem.
It tells you that there are two more things you need to know in order to figure out the
probability that you have hypothesis, the prior probability that you would come down
with hypothesis, and the prior probability that you would have the symptoms that you
actually have.
With a little more googling, you discover that the disease is extremely rare.
Only one in 100,000 people have it.
So P of hypothesis is 0.0001.
Now for the last ingredient.
What kind of symptoms are they?
Suppose they're very common, like a headache and a runny nose.
Lots of people have those.
Google tells you one in 100.
So P of symptoms, your prior probability that you would come down with the symptoms you
have, is 0.01.
At last, you know everything that you need to know in order to figure out the probability
that you have hypothesis given your symptoms.
Bayes' theorem tells you that P of hypothesis given symptoms equals P of symptoms given
hypothesis times P of hypothesis divided by P of symptoms.
In other words, P of hypothesis given symptoms equals 0.00095, or a little less than one
in a thousand.
Bayes' theorem is very helpful because in figuring out what to make of some new piece
of evidence, people often ignore the prior probability of the hypothesis, or treat P
of H given E as P of E given H.
This mistake is sometimes known as the base rate fallacy.
In the case we just looked at, P of H given E is very different from P of E given H. One
is less than one tenth of a percent, and the other is 95 percent.
Without Bayes' theorem, you might have gotten a lot more worked up about hypothesis than
you needed to be.
Wrapping up then, Bayes' theorem is a formula that tells you how to calculate conditional
probabilities, or the probability you should assign to some hypothesis given a piece of
evidence.
Even if you forget the formula though, try to remember that the conditional probability
of H given E is determined by three things.
The conditional probability of E given H, the prior probability of H, and the prior probability
of E. If you leave one of those three things out, you don't have a complete picture.
