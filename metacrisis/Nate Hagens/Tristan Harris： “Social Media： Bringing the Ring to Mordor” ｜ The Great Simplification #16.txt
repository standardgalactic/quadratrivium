Today's guest probably needs no introduction to those paying attention to the social media space
and to issues around democracy and polarization. Tristan Harris is the co-founder of the non-profit
The Center for Humane Technology, whose work was highlighted in the film The Social Dilemma,
which was viewed over a hundred million times. Tristan and I have become friends in the past
year. I've introduced him to people in DC and elsewhere because I've concluded that without
people understanding what's real, what is science, what is algorithm driven, if we can't have that
conversation and discourse nationally, we will never be able to solve the longer-term issues of
climate change, resource depletion, financial overshoot, etc. As you'll see from our discussion,
Tristan knows the intersection of society with our social media technology cold.
It is my hope his organization and efforts can help pave a way to some healthier,
more sustainable relationship between our social technology and our culture.
I hope you find our conversation educational and helpful.
Since I first met you last year, I think I need to call out your team's influence on our social
media conversation. Obviously, my listeners probably know you made the movie The Social Dilemma
and with the Center of Humane Technology in Francis Haugen and presentations, I'm sure you've
given all over the world for the first time last quarter, Facebook's daily user interactions declined.
So that is kind of a David and Goliath story of sorts that your education and evangelizing the
risks of social media actually made a difference. So congratulations on that.
Well, Nate, I'm glad you mentioned that because obviously there are wins for the whole of humanity
to educate the world about why these systems are so toxic. But I just wanted to say it's
actually worth mentioning because I think some people might hear the problems we're going to
talk about today and feel like it's just the most uphill climb in the world. I mean,
how can you ever change a trillion-dollar market cap set of companies, each of them with a trillion
dollar market cap business models that are entrenched? No, no longer a trillion-dollar
market cap. Now it's $500 billion. That's right. And that's the point. If you had asked me back
in 2013 when we started working on the topics of the arms race for attention and trying to raise
awareness inside of Google and trying to get engineers and product managers to come forward
and getting people to say, we do have a fundamental misalignment of incentives,
I would have never believed you in 2013 that we would be sitting in a place where Facebook's stock
price would be cut in half since the releases by Francis Haugen, the brave whistleblower that
came forward, who I know and who's a friend, that we would see people who say, I don't want to work
at these toxic companies. I want to work at something else. I would have never believed you
that you regulator Marguerite Vestiger would be using our language and the language of the
social dilemma and crafting policy that we would have a film that would reach 100 million people
in 190 countries in 30 languages. So I know we're going to get into some probably some dark topics
today through the nature of the topic, but more has been changing than has ever changed in the
space. And I think that's an important note too to Mark. No, absolutely. So I hope you don't mind
me sharing this, but when we met, we talked for a couple hours, if you recall, when we first met
at a Starbucks. And then we talked another month later and you said, Nate, since I met you, I
haven't been sleeping that well because of the things we discussed, energy, depletion, finance,
climate change, the interconnected nature of everything. But something I've not shared with
you is after we met, I also started sleeping more poorly because I realized that the things that you
and your colleagues are working on, the information ecosystem, polarization, social media, what people
believe versus what is reality. If we don't solve that, we can't solve the other things.
And so we need to solve everything. But if people don't share a common understanding of what is
going on in the real world, then I don't know what hope we have. So can you maybe for the people that
didn't watch, the few people that didn't watch your documentary, can you just give us an umbrella
overview of what's happening with our social media infrastructure, why it's getting worse,
and why this is a critical risk, just a few minute overview?
Sure. And also just to say, meeting you has been one of the most transformational experiences of
the last year, I would say. I think I've sent your talks to so many people because it's so
impacted how I'm thinking about the bigger risks that we face. And I just anywhere I can go to
recommend people watch your talks and read your work, I do because I think it's just so fundamental.
So right back at you. Well, thank you for that. We'll pin that because I have a response to that,
but keep going. Okay, so let me give a little overview of the social dilemma for those who
might not have seen it. So this film came out in September 2020. And it's a documentary made by the
previous climate change films, film team, Chasing Ice, Chasing Coral about the glaciers
melting and then coral reefs bleaching. And so these are environmentalists who've been studying
global impact problems for a long time. And it was an old friend of mine in college, Jeff Orlowski,
who is the director of the film. The film is basically about tech insiders like myself. I
used to be a design ethicist at Google. It has the guy who invented Facebook's business model,
brought Facebook's business model of advertising to the company, Roger McNamee, who actually like
advised Zuckerberg in the early days, Renee DiResta, who was one of the few researchers who got the
full rush of data set from 2016 and how they were influencing the US political sphere,
tech insiders who were inside of the companies, people from Pinterest, Snapchat, Instagram, etc.
And they were coming forward to basically say, we have a problem. There is a fundamental misalignment
of incentives between the business model of these companies, which is not just advertising,
but it's the incentive to capture human attention. And we famously call this the race to the bottom
of the brainstem, to capture human attention. Because you can be better at capturing human
attention, the deeper into our vices and into our fears, into our emotions, into our paleolithic
brain, the deeper you go, the more attention you'll get. And so what started off as just honestly
offering products on a marketplace where I can choose this social network or that social network,
turns into this arms race for, can I stimulate your ego and narcissism and get you more reach
and followers than the other guy can? And literally right now, Instagram and TikTok
are kind of in an arms race for who can get you more viewers to that video, more likes,
more followers, because that's how I inflate your ego and then get you coming back. And the more
followers you have on my platform, the more likely you are to post your next video on my thing and
not the other guy's thing. And so if I don't copy what you're doing, if you, for example, beautify
photos, right? So there's these filters on these photo sharing apps. Snapchat has it, Instagram has
it, TikTok has it. And when you take a photo or a selfie, the one that plumps your cheeks, that,
you know, plumps your eyes, that plumps your lips the most and does the best, it's like mirror,
mirror on the wall, who's the fairest of them all. And if you make me look best, then I'm probably
going to post using your app. So just to give you an example of this arms race, it started off where
each of them were competing to offer these different filters, right? Instagram has some filters,
Snapchat has some filters, TikTok has some filters. But now it was found out that TikTok
actually, without asking you, does the beautification by, I think it's like two to three percent or
something like that. Because in that arms race, I'm going to do better if I automatically do it
than if I wait for you to do it. And it's the same thing as with video sites where I'm going to do
better if I automatically autoplay the next video than if I don't automatically autoplay the next
video. And if the other guy does it, then I have to too. If Netflix starts autoplaying the next
episode and YouTube has to start doing it too. And this is the arms race of a different kind
of super organism in your language that continues to grow, but it's feeding off the substrate
of what makes our society work because it preys on isolating us in that race for attention.
So just in the macro sense, the super organism is a collective action problem because we want to use
dollars that are spent on energy because that contributes to economic growth and salary and
money and other people are doing it. So to use less, we lose out versus other people
unless we're really mature and have self-discipline. But you're saying that this same collective
action problem happens in social media where the best thing for me would be to not use filters
and be authentic and honest. But if I make that choice, I'm out competed on whatever I'm trying
to share by other people that do use these filters, et cetera. Yeah. So there's two different arms
races. There's an arms race on individuals. So if some population of teen girls are not using
the photo filters and some populations of teen girls are using the beautification filters and
the ones that are using beautification filters get access to more likes, more followers, more
reshares, then suddenly it's going to be harder for the other ones not to. But that's on the
user side, on the platform side, what I was talking about is the design. And that's really what
our work at the Center for Humane Technology focuses on is the design of Snapchat, Instagram,
Discord, Facebook, et cetera, because these are design choices made by people in Menlo Park,
in Mountain View, in California, and their choices. So the superorganism part is the design
is optimized for clicks, which result in dollars. That's right. And the corollary is our economic
system doesn't care about externalities. It doesn't care about the fact that we're mispricing
this finite one-time bolus of fossil magic. It just cares about profits. So there's the analogy,
yes? Exactly. Exactly. And just like there's a runaway growth imperative on an economy or a
GDP of a country or an oil company that was directly tied to the financial system and that
causes climate change, much of our stock market is propped up by the big five tech companies
whose business models are, well, not all of them, by the way, some of them, we should talk about
the distinction. But for those who optimize for maximizing attention and engagement, they call
it engagement, their business model is making sure they get more time spent, more usage, and more
engagement every year. And if it starts to go down, if they have to do and make choices,
they're about getting it to go back up. And that's the essence of our work and what we've been saying
is a massive problem and breaks the way that society works. Because to your original point,
the deepest harm here, I think, is if you break shared reality, if you break the notion of our
ability to see a same reality and have shared facts and shared understanding so we can coordinate
what solutions we want. But in a business model of doing what's best for keeping you swiping,
you, Nate Hagans, sitting there by yourself with your phone and your finger, I want you swiping
the most. And so I'm going to show just not what makes everyone keep scrolling together
to make that whole society work. I'm going to show what keeps Nate Hagans scrolling. And if
that's doom scrolling on climate stuff and videos on oil and debt, then I'm going to show him that.
But if it's for your daughter, who might be swiping through anorexia videos because that
tends to work best. And by the way, this is not deliberately done. What usually happens is someone
starts swiping on dieting videos and food tips and healthy food. And then the algorithms are
figuring out, well, what tends to work well for that cluster of users. And it turns out that the
anorexia videos work really, really well. And the algorithms don't know what the word anorexia
means. It doesn't know that those photos are good or bad. All it knows is that it works. And that's
the same thing. So that's important because we do kind of apply agency to these algorithms thinking
that they're evil and trying to show us things. They're just following mathematical algorithms
that optimize for clicks. So there is not a hidden brain there choosing to lead us down
the dark path. It's just optimizing what our own behaviors default click to, yes?
That's right. A lot of people want to vilify the tech companies and the founders of those
companies and the people that work there. But I promise you, they're not all growing
mustaches and twirling them as the world burns. They're instead caught in this arms race. Now,
there are decisions that they can make and they have been denying the fundamental reality that
their products are causing these effects. And for that, we should be holding them accountable.
And I want to make sure I'm clear about that. There's definitely responsibility in the equation.
But even if it weren't these set of founders, people have been very critical of Facebook and
because of our collective efforts, people are using some of their products a lot less. But now
people are moving to TikTok. And TikTok is doing just as much of the race to the bottom of the
brainstem that just crossed, I believe, YouTube and maybe Facebook and time spent on Android.
So it's actually grown even more so. And that's because it's just a supercomputer pointed at
your brain saying, what's the next video that's going to keep you swiping instead of saying,
maybe I should do something else. And that supercomputer is trained on two billion users
behavior. It figures out exactly what's kept users just like you swiping. And so it knows
way more than you know yourself, what will work. What we're saying then is that climate change
and biodiversity loss and other natural resource sync effects are the externalities downstream
of the macro super organism profit seeking market dominated exponential growth system.
And behaviors in especially teen women, polarization, addiction, lack of attention span
to do gardening because you're addicted to online games or playing Overwatch or watching
TikTok videos. Those are the externalities of the digital infrastructure that our culture has
developed. Yeah, that's right. I think that that is the digital fallout or what we used to call the
climate change of culture. Because much like we have an extractive energy economy, whose externality
is climate change and it occurs through what you talked about planetary overshoot, you know,
the over extraction over pollution over depletion, you know, past the kind of metabolizing capacities
of the earth. In different ecosystems, we have to be specific about that. But in the same way,
you know, you can have certain amounts of polar personalization of content in society.
But if you over extract, if you do overshoot on personalization, you break the shared what Daniel
Schmackenberg calls the epistemic commons or the information ecology. These are fancy terms. We
should just call it as our shared reality, our ability to make sense of the world together.
And when was the last time we had a shared reality?
Well, that's a great that's a great point because it's we shouldn't do the classic Garden of Eden
naturalistic fallacy thing where we say, Hey, there was this pristine state of affairs where
everybody viewed the world the same way. But we can talk about certain periods of history,
where in media, there was a smaller number of channels. And there was a cost to that, you know,
when we had Walter Cronkite, we had, we didn't have an arms race on who could keep people's
attention. And we didn't have a thousand Walter Cronkites who started realizing that the best
way to keep their attention was to be, you know, Mr. Cronkite Q and on extreme and to pull people
down into the Cronkite echo chamber that would keep people going. We have tens of millions of
Cronkites now, they all have their AM radio shows. Yeah, but they're not Cronkites because
their incentives have been to figure out how do I inflame your emotions to keep you coming back.
And if I tell you that you're right, that's going to work a lot better than saying, well,
actually, that view you have, it's not that you're wrong, it's just that here's a more complex
picture. The guy who's saying, well, here's nuance and complexity, they're going to get massively
outcompeted by saying, here's a simple story and here's why you're right.
But why, what does that say about our genome, Homo sapiens, if we're more likely to click
something that inflames us than informs us? Well, I think it is key to, I think,
just about most of the guests you've had on your podcast and to be consistent to
sociobiologist EO Wilson, who kind of framed this as, I think this is how you,
when you and I met, we both talked about all these concepts that the fundamental problem of
humanity is we have Paleolithic emotions and brains, medieval institutions and godlike technology.
And, you know, our brains and our emotions, it's not that they're bad or they're wrong,
they're just evolved for a different environment. And they were not just like salt, sugar and fat
were not available on the savannah in the abundant quantities that they are today and also
not combined in this perfect, you know, optimized way. Well, now we have the perfect optimized
combinations of fear, amusement, you know, ego, narcissism, and we're sort of combining those
as the new salt, sugar, fat, but for society delivered through digital tech products.
Right. So gossip and inflaming arguments about some hated outgroup or some super great praise
about my in group or sex or controversy, all those things shout louder to our brains than
an objective accounting of the fact that fish are migrating northward because they need more
oxygen because of warmer waters in the ocean, which so this is a real example of why fitness
matters more than truth. These things, at least we perceive in our brains that they matter more
to our lives, even though they don't relative to the ecological circumstances that are unfolding.
What does it say? We get caught in the drama treadmill, right? And so think about if I'm
Twitter, right? So people use Twitter and Twitter is like a drama internet. Every piece of drama is
hyperlinked to every other piece of drama. So it's never been easier to see which drama inflamed
in every other drama and then go click down the rabbit hole and then see everyone's response to
that drama. Drama is really good for Twitter because drama is engagement. And so they're
trying to hyperlink all those things together because that makes them more successful as the
sort of internet sinkhole of competing for attention. And all that's just to say that again,
their business models of capturing attention are fundamentally misaligned with a, you know,
civic society that really works. So here's another analog to the energy story.
Our culture is energy blind in that we tend to be naive or ignore the massive benefits that we
are getting from fossil hydrocarbons added to our system. We know that there are some bad things
that happen with fossil fuels, pollution, climate change, et cetera. And yet we're not
strong enough to stop using them in the same way we know or we feel that six hours of screen time
a day or I don't know what the average is per day. Mine was six hours on last Sunday. That's what
my Apple said. We know that that's not good for us yet. We can't, we're not strong enough. Our
stone age medieval minds aren't strong enough to go cold turkey on that. Now part of that is maybe
in the realm of addiction and part of it is the collective action problems. If you or I, given our
roles in trying to change the cultural conversation, were to totally give up social media, we would
then be at a disadvantage of, you know, promoting the message that we want to promote. But just
speaking as a human, I'm pretty tired of Facebook to be honest. I have a lot of my friends and
family on there and I like to post videos of my chickens. And by the way, the rooster Tristan
got eaten by a coyote earlier this week. I named him after you when he was a chick. Yeah,
so I'm the first time in nine years I'm roosterless as an aside. I need a replacement rooster. We're
down to 15 hens. But anyways, I'm not strong enough to completely unsubscribe from all that.
And it is useful to me because I need to pay attention to the information. But Facebook,
I've almost completely given up on. I do post pictures of my dogs and my chickens. But beyond
that, I don't use it much. But is that a reasonable analogy? We know we should give it up, but we
push back a little bit actually, because oftentimes this gets classed as an addiction problem.
And in fact, in Francis Haugen, when she came forward, she's the Facebook whistleblower people
remember. And she said that in Facebook's own research, they know that parents give their
kids bad advice, like just put the phone down, just don't use it, just use it for less, just
don't use it after 10pm. What this misses in the picture is that Facebook or Instagram or TikTok
or whatever have colonized the basis of social participation in society. It's not an individual
choice for me to not use it. If I'm a small, medium-sized business, do I have another place I
can go to micro-target my ads to get the COVID economy rebooted after COVID? I don't have another
place to go. You don't have a choice. If I'm a kid and all 12 of my closest friends are on Instagram,
they're not on some other thing. They're on Instagram. So it's not about whether I have no
choice. If I'm a politician and all of my competitors are advertising on Facebook or Twitter or
YouTube, do I have a choice about whether I try to match them in the arms race? And so just like
to your point about the climate change thing and the oil companies, I'd say the analogy is closer
to not just that, it's just closest in the sense that to participate in society for me to get on
that plane to speak at the South by Southwest conference last week, I had to use the fossil
hydrocarbon economy to get myself there. No, they're exactly linked. We have downward causation
caused by the financial markets that we are outsourcing our decisions to the market,
to the financial system, and we're part of this culture. We can't live outside of it yet until
there are options or a change. And it seems like that is another parallel with the social media
infrastructure. So just like we have been on one phase of the energy infrastructure,
that you can say that hydrocarbons were a great way of bootloading our society,
hopefully into a different energy paradigm that would be more friendly to the environment.
The attention economy based on advertising generated a bunch of wealth based on extracting
human attention, treating us as the product, not the customer. And it got us to an area of
prosperity, but now we need to switch to a new paradigm, just like we have to do with energy.
And so I think they're very similar. In fact, of possible ways to talk about this issue,
I've purposely tried to talk about it this way, because I think it does double work at seeing
the connection between economics, climate, and technology, and the social climate. And just to
say one last thing about the Paleolithic emotions and that I am a magician by trade as a background.
I do know you're a magician. I figured that out last week.
Yeah. Well, so in seeing how these products are working, one of the things you have to realize
is that they're designed with an asymmetry of knowledge, just like a magician knows something
about your mind and how you're going to make meaning of the situation. And they know they can
manipulate that meaning making that you're doing. Technologists also have an asymmetry of information.
They know something about what tends to be sticky for people, but they don't know about
themselves. So like if I walk into Las Vegas in a casino, one of the things they figured out is if I
remove the clock from the casino, people stay a lot longer, because I'm essentially removing the
reasons that as your mind is scanning around using its perceptual apparatus, it doesn't see clocks
anywhere. You kind of forget, you know, time just passes more in flow. And it turned out,
someone actually pointed this out to me, I didn't realize it until a week ago. TikTok,
if you open the app on an iPhone or an Android that doesn't have the notch with the uneven top,
TikTok actually removes the clock as you're watching videos, because they don't want you
thinking about what time it is. Right. And so these are the magician like tricks on the human
mind. And you know, my co-founder Azar Raskin from the Center for Humane Technology, he actually
invented the infinite scroll, which is that instead of hitting next for a video or, you know,
clicking a button, that what if you just scroll and it just kept loading them at the bottom
over and over and over again. And he invented that feature and he deeply regrets it. He
estimates that it wastes several million lives per day in human time. And it's because they're
removing the stopping cue, which is that cue that your mind needs in a conversation. Like if I stop
talking right now and there's a space, we'll know that we can kind of switch turns. But if I keep
talking and you're trying to jump in, then you won't be able to, right? So I'm doing the infinite
scroll right now as I'm not letting you speak. Well, in this particular case, I would probably
eventually just butt in and speak, which is sometimes what our brains do when they catch up
to realizing that we've been spending too long. Right. Right. Well, exactly. So a little bit on
the magic, just to let you know, you and I were together a couple of weeks ago. I can't remember
exactly when it was two weeks ago. And you did this magic trick on me where you had this quarter
in my hand and you set a story and my hand was closed and then the quarter was bent in half.
And it wasn't before and it was a real quarter and I still have it. It's in the other room on my
shelf. And I purposely don't believe that that was actually magic. I purposely did not look on the
internet to see an explanation for that because in the doing of that, I would have lost some of the
specialness of you cracking up at watching my reaction and me wondering how the hell did he
do that? There's a key thing there, right? Which is that the magician, when they use the asymmetry
of knowledge, that they know something about your mind that you don't know about themselves,
they're not using that to take all your money or to manipulate your psychology and make you
anorexic or to make you vote for a different candidate or to ruin a democracy that you're a
part of. They use the asymmetry of information to create a magical experience, to create entertainment
in a way they have a fiduciary obligation to you to be entertaining you. They're operating
with that asymmetry of information to help or to entertain. But contrast to that, technology
companies have way more knowledge about the vulnerabilities of your mind, way more privileged
information. They also know a lot more how the technology works, but they're not using it to
the best benefit of your children or to the democracy to function better.
So to use an obscure Dungeons and Dragons metaphor, the tech companies are lawful, evil,
and magicians are chaotic, good. I actually haven't played that much Dungeons and Dragons,
so you'd be educating me. But no, but my point is you can use magic in the broader sense to change
people's perception of their reality. You do it all the time with your public talks and you use
word combinations for our prehistoric brain that change how people think and perhaps behave.
But you're not doing that to generate clicks or money, you're doing that to change
people's hearts and minds. So magic in the sense of changing people's perception of reality
can be a real thing and a good thing, yes? Yeah, well, I think there's this other trend that
if you think about a timeline of any intelligence species, if it gets to a sufficient
level of intelligence, it starts to use its intelligence to understand itself.
A lion doesn't have a capacity to point its own intelligence capacities to figure out how
the lion brains work and then become self-aware of, man, why do I like gazelles and why do I like
gazelles that look like that and not this? They can't interrogate their own mind. What's unique
about humans in our intelligence is that we can actually build tools and build instruments and
then actually become self-aware. Well, first, we don't need tools, we can actually just do
like what the Buddhists did where we just sit with our minds and we can study how we really work.
We can notice that we have something called loss aversion that gaining 100 bucks doesn't
hurt, doesn't feel as good as not losing 100 bucks feels bad. And that's for an evolutionary
reason, but we can discover facts like that about the human mind. And that's what magicians have
done. They've discovered these ancient facts about how minds make meaning and biases that we have.
And you can think of a timeline that from Edward Bernays and Sigmund Freud discovering some basic
things about human minds to developing marketing and focus groups to then the magicians coming
along and figuring out how magic works and then figuring out Frank Luntz and Drew Weston and people
like this who know how language can shape thoughts and minds. Then you can figure out the pickup
artist community and then cults and then you can think about this increasing trajectory of
self-knowledge about the predictability of human social animals' behavior if you control the
environment and the situation. And that is like this sort of body of knowledge, which is how to
turn the creativity and free will of human beings into predictable dead slabs of human behavior
because there's an asymmetry where you can cause things to happen.
This is why I lost sleep after I met you because I realized that me just college professor
reality 101 trying to do a wide boundary comprehensive library treatment of the human
predicament on energy, human behavior, climate, biodiversity, money, economic growth, the future
isn't what you just described. It's relevant, but it's boring and dry and not going to be able
to capture people with language, etc. So I really struggle with should I just discard all the science
other than what it informs in my head and use PR and tricks to change people's behavior.
And that's not who I am. So I'm doing these educational videos and using some art and music
and such, but it's really depressing to me that unless we change how people get information and
have a discourse together in society that these larger issues aren't going to be solved.
I think that we can make some distinctions that this knowledge about how human minds work doesn't
mean we can inform the people who are communicating the most important things to the world and then
wrap around it, this efficacy program, this to communicate even more powerfully things that
people need to know. But of course, this ability to persuade minds, if you think about that sort
of this is this ability to persuade minds, that's what's going up on a curve. And you can use that
for good and for for bad, you know, Frank Luntz, the climate, the Republican pollster, you know,
famously use these focus groups to come up with phrases like death panels in the salesmanship
of Obamacare, right? So instead of the Affordable Care Act is helping people,
they're going to have death panels, panels that are going to decide whether you're going to live
or die, right? That was a powerful phrase or, you know. Yeah. And I disagree with him. And I don't
know a lot about that issue, but just you framing it that way, I feel an aversion to whatever he
was describing. Right. But, you know, he was he was finding and that's what the point is that these
are values neutral. There's a values neutral capacity here that can be used for for many
different purposes. And he also discovered that the phrase climate change was less alarming than
the phrase global warming, because the climate's always changing. And so it's it's a neutral statement
and it's this grand irony of history that the that the left in the United States ended up adopting
in the environmental movement ended up adopting the phrase climate change, which is one of the
least effective phrases you could use. Yeah, it's a euphemism. Where did that name come from? I don't
even know. Well, from Frank Luntz. I don't believe that he invented it. And by the way, he regrets
all this and has been trying to work to improve climate communication. And someone that I know
and he's actually been trying to do as much as he can to kind of help use the tools that he's had to
help reverse polarization and reverse climate change and things like this. But, you know,
I think he didn't invent the phrase, I think he just discovered that it was the phrase that
pulled in the way that it did. But, you know, across the board, I've studied this and there's
people like Lara Borditsky, who we actually had on our podcast, we have a podcast called
Your Undivided Attention. And we interviewed her about the power of language. And people don't
know that, you know, if you talk about a pre-owned car, people like the idea of buying a pre-owned
car. But if you talk about a used car, no one wants a used car, right? And there's just all these
games. George Lakoff at Berkeley will talk about this ad nauseam. He wrote a famous book called
Metaphors We Live By, where if you frame the nation, for example, as a family, mother Russia,
we don't want those missiles in our backyard. We don't send our sons and daughters to war.
In each of these phrases that I'm mentioning, we're invoking the nation as not just a nation.
We're talking about the nation as a family member, as a parent, right? The backyard of our country,
the mother Russia, the father Russia. These are all ways that we manipulate culture into
believing in ideas like a nation, which are abstract. They're totally fictions.
Do all these language tricks or leanings that you just said have their core roots in
evolutionary psychology that they're honing in on an impulse that was conserved over
evolutionary time that was important to us? Well, I mean, take that one nation as a family, right?
So the family is going to be pretty core in terms of the human experience. Over time,
people are going to have mothers and fathers, and they tend to use the same basic ma for mother
and dada for father, vaguely that direction, right? And then the, I think the clever political
usage here is to link concepts that you want to be associated according to that childhood-like
experience, that childhood-like loyalty and warmth that you get from a mother to, say, mother Russia.
And when you link these things together, you can start constructing realities.
So people call it ontological design. But this is just giving people a taste. I mean,
I think we can get more into the tech topics. The important thing to establish here is that
the mind can be persuaded. Everyone is persuadable. It's not just that because you and I are here,
and our listeners are listening to this, that only us, you know, three of us, that you, the
listener, and the two of us, Nate and I are the smart ones. And it's only those dumb people
way over there that are manipulated by propaganda. You have to see that you're not ever not using
language. You're always using language. And when you use language, you're casting spells
that create a framework for seeing reality. And we just have to be aware of this because
increasingly, there are actors that are better and better at knowing which language to use to get
us to feel or believe one way or the other. And then you link this with the tech equation,
and technology is getting better and better at reinforcing certain language patterns
over and over again. I just hired a coach to help me with various
efforts with my organization. And one thing she said off the bat was that the language I used
to describe our situation is too negative. And I say the problem. And instead, I should say the
challenge or the opportunity. And the facts are all the same, but the language that I use tends
to be too negative because I'm freaking terrified about what's coming. So naturally, I have negative
sounding words. But I think another issue that I learned recently is that if you're a certain
personality type or if you're a certain temperament or if you're a certain Myers-Briggs type,
the fact that other people think differently isn't the issue. The issue is that we naturally assume
that other people think like we do and that we're the same personality types.
And there's a name for that. I think I forgot the name right now.
We overestimate the number of people who share our beliefs. And if you think about it evolutionarily,
speaking, you would expect that people who you meet in your tribe are likely to vaguely have the
same notion and construction of reality as us. And so we wouldn't evolutionary be like evolved to
think about how different every reality would be for everyone else around us.
Right. Because mostly 20 or 40 people around us, we pretty much kind of knew what was going on. And
now there's so many different demographics that we come in contact with and different personality
types. So when you meet people and you say, oh my God, how do they're showing up at January 6th?
They must be insurrectionists or something like that. It's like, well, what if you've been fed
a narrative for the last 10 years that showed that there was manipulation of the media that
people are not saying things that are true? And by the way, those are legitimate examples. Like,
I'm talking not just a conspiracy theory, but legitimate ways that the media has not been very
honest about a whole bunch of things. And then someone says to you, the election was rigged.
And in so many ways, you can say that it kind of was rigged and not actually rigged, but I mean
the media environment, the questions that were asked to Trump or whatever. And then you say,
hey, the election was stolen. If you genuinely believe that, and then you show up at the January
6th event, the other side now has been fed this whole news feed of the last four years that said
we're living in this authoritarian state for Trump or whatever. And these are the kind of
fascist Trump followers who are showing up at a rally. And so each of our perceptions of each
other, I'm not trying to say this in a way that's as sympathetic to at least the media
environments that each have been living in. It causes us to be upset at each other, but from
not even a shared ground. We don't have a shared understanding of even what history is
or what narratives we're living in. And so we're constantly misinterpreting each other's behavior,
which drives up itself more conflict. Well, I want to get into that in a second,
because I think polarization is one of our biggest risks that we face in the near term.
But coming across your work, I had an interesting reaction. First was depression,
that this was actually happening. The second was when I hear someone that's a January 6th
conspiracy person, my initial reaction is frustration and anger. But after being exposed
to yours and others' work in this space, I have developed more tolerance and empathy,
because I understand that someone in my direct blood relative family who will remain unmentioned
believes in that narrative. And now I can understand that it's their newsfeed. They only
have one newsfeed and they just don't get exposed to the things that you and I are talking about.
So I have an understanding of why they come to that. So at least that's a mature direction for
me to think about. It's frustrating. It's still a giant, giant problem.
Right. And notice, by the way, that so I know this is a polarizing example. So I excuse myself
hopefully with your listeners just to for a moment, let's just cool off any emotions that might occur
here. But there were armed insurrectionists and people with zip ties who were going to take hostages
and kill and harm, I think people in our capital. So I just want to be very clear that I see that too.
But if you're on the Trump supporter side, you saw infinite videos of very regular old Trump
supporters who were just showing up at election day, believing that their election was stolen,
and they're just showing up excited about Trump. They saw those videos. They didn't see the videos
of the zip ties and the stuff. Whereas on the left media ecosystem, you saw videos on a loop of all
these guys with guns and slamming police officers and violence. And so again, when we're talking
about this event, we've been seeing very different examples on the Black Lives Matter side. If you're
on one side of that, you clicked on a video of an innocent African-American person getting beaten
by the police in a way that would make you just so outraged. And then you clicked on one of those
and Twitter sees a pattern. It says, oh, I know what videos to serve people like you. And it shows
you infinite videos of innocent African-Americans getting beaten by Black people. But if you're
on the other side of that, you might click on a video of a police officer getting really unfairly
treated. And then you see infinite videos of police officers getting really unfairly treated.
And you start to realize that we've again been in this reinforcement loops of confirmation bias.
And it's really fragmented in a very deep and subtle way our ability to ever even empathize
with each other or where we're coming from. And again, there's no billionaire behind that saying,
hey, let's foment this, send those people these videos. This is just that algorithm
upgrading for drama and clicks like you said earlier.
That's right. Although bad actors and foreign adversaries have been and will continue to
amplify the narratives that they want. And so if I'm Russia, it's the best news in the world for
me that this fault line emerged in your society around Black Lives Matter. So I'm going to dial
up both sides. If you actually look at the behavior of the Russian bots, they're not pushing
for one side. They're just pushing for what makes both sides angry. And they say things that people
who are on each side would even agree with. They're not saying it's not propaganda. That's what my
colleague Rene de Resta calls amplifaganda, because they're just selecting what your own domestic
voices in your country are saying, the most polarizing and divisive voices. And they're just
piling onto those things. And so you can think of the newsfeed algorithm behind Facebook and
Twitter and so on as a fault line finder. You know, you've got a trillion dollars of compute
power that says, okay, whenever there's a fault line, because the fault lines emerge when people
post an inflammatory content, and then it just puts an amplification loop on that fault line.
And so it's like turning up the contrast in a photograph where all the lines suddenly get really
visible, right? Suddenly all at once. That's what it's doing to our society. And we have to really
see that at a fundamental level because we have to see that it's incompatible with democracy.
So I take a stronger view that when we talk about solutions to this problem, which I know
probably want to get into, that it, you know, when we think about solutions, our lawmakers
typically go to the legible ones, like we have privacy reform and we have content liabilities
and they call it section 230 reform, we have antitrust, these companies have gotten too big,
it's too much concentrated power. But you take those three levers, privacy, content liability,
and antitrust or concentrated power, and you don't get to a world where technology is strengthening
democracy. You might get to a world where technologies may be 10% less toxic for society
than it is now. And I want to claim that our goal here in this conversation shouldn't be how do we
reduce the harm of social media. We have to ask, what is technology plus democracy equals stronger
democracy? Is there anything on the horizon right now, technology-wise or regulation-wise or anything
that would dramatically improve or deteriorate the existing situation that you've outlined?
Well, there's all sorts of things that we can do and can be done. I just wanted to focus on,
you know, back to the E.O. Wilson quote, we have paleolithic emotions, medieval institutions,
and then accelerating godlike technology. The medieval institutions part is just that our law,
the letter of the law always lags the spirit of the law and the way that the spirit of law has to
get reinterpreted in an increasingly complex world where technology is redefining our concept.
So we have a concept called protect freedom of speech, but that didn't anticipate a world where
computers could generate speech and flood the internet with synthetic media of videos of things
that didn't happen, of photos of fake bombings in Kharkiv and Ukraine, which it can do. And so what
I was just trying to point out was that oftentimes our institutions reach for that which was legible
in the concepts that it had articulated in the past, like consent or privacy or free speech.
But what do those terms mean in a world where technology is changing the definition of what
would privacy even mean when, for example, without you filling out a form and telling me your name
and address and personality traits for Cambridge Analytica, there's a new paper out with AI that
in 2018, with 70% accuracy, I can get your same big five personality traits, your openness,
conscientiousness, extroversion, acceptance, I think I got the right, and neuroticism.
And I can get those traits by looking at your mouse patterns, just by looking about how you
move on a screen and click and the speed at which you click, you can read things. So think about
it as like the end of the poker face, right? A regular person, they use their eyeballs and
they're reading, it's like cold reading, it's another magician type thing. I can look at you
and I can read certain things about you. A lot of that's kind of fake and they're manipulating
how much they think they know, but increasingly technology is able to read our micro expressions
and predict there's another paper about that in 2018. I think that AI can predict our micro
expressions better than we know ourselves. And so I'm just, I'm plotting this out because they
challenge some of these things, these sacred cows that we've had that we've enshrined like privacy,
where the definition of privacy isn't whether a service collected, your name in a registration
form, it's the ability for technology to know more things about us without even us filling in any
explicit information. Well, that was where I was going with the question is, are the developments
that are coming with AI and GPT-3 machine language and that in the coming years going to accelerate
the trends that you're already describing on polarization and clicks and reading our minds
and then directing political voting and market capture. They do unless we take action and we
realize what it'll take to lock some of this down. So even while I'm trying to be very clear also,
I don't want to just scare people or cause a moral panic around the boogeyman of technology
reading our face and Michael expressions. It's not like every company is doing that and Apple has
control over face ID and what people can and can't use face ID for, right? And so on your iPhone,
you know, whether it reads those expressions or not has to be, you have to give access for a
phone to get access to your camera. So I just want to make sure I'm really clear that while
these are capacities that are getting rolled out and they do challenge the situation, the key is
that there are certain actors that we need to operate in our best interest. And if you think
about it Nate, like I often really like to think about this from the perspective of a doctor or a
lawyer or a financial professional because in all three of those fields, you know, if I'm a doctor,
I know way more about the complexity of medicine that you, the patient don't know. And you're giving
me privileged information, private information about you so that I can hopefully make you make
the best decision in that complexity, right? So I have to be operating in your best interest because
if I use the fact that I know about medicine and you don't, I could just charge you for the,
you know, pharmaceuticals that make me the most money. And similarly, if I'm a financial
professional, I know about finance more than you know about finance. And so you've got to trust
that they're solving the principal agent problem of being a fiduciary to our best interests.
And the same thing is true for a lawyer, they know about the law. And so in that divorce case,
they need to be navigating for your best interest. So when you compare those fields and the amount
of complexity that's on the other side, technology needs to act as a fiduciary to us in that complexity
because the complexity in technology is racing ahead faster and faster. Like you said, we have
synthetic media, we have news feeds, we have different forms of privacy that we're going to need.
We need to make sure if you look at the first and second derivative of how fast those curves
are going, the way to solve it isn't by regulating yesterday's misinformation problem from the 2016
election, which is what the regulation conversation is. The best way would be to pass something like
the Tech Fiduciaries Act, which says that if you're above a certain size, you have to act with
that complexity in the best interests of people. And we need better ways, I mean, democratic ways
of defining what the best interests of people means, but we need to make sure that more and more
of their decisions are not extractive. Because in that complexity, right now you have Facebook
operating for its best interests, which is whatever personalizes and outrages and flames the most.
And that's the same for Twitter and, you know, similar for China and TikTok.
And so that's what we need to change.
And do you have any existing examples of what that might look like or conceptually,
how might technology for the betterment of society as a regulatory thing look like?
It looks like technology being a sidekick for our values, for the two marshmallow version of us,
not the one marshmallow version of us, right? And so that's the marshmallow test of, you know,
show you one marshmallow and can the kid resist it? And can they have an executive
controllability of their neocortex that they can go for the two marshmallows 10 minutes
from now instead of the one marshmallow now? And there's an ability to develop that capacity.
But right now, technology wants to develop the one marshmallow society, as Daniel will often say.
But what if we're 80 to 90% of us are already the one marshmallow societies,
and we're asking for more marshmallows, do we need to train and educate and help meditate and
mindful living as a precursor to these new technology laws? Do they need to happen
hand in hand? Or is it only a super organism top down downward causation sort of situation
that the technology has to change otherwise we're screwed?
You know, you and I have talked about my executive director of the Center for Humane Technology,
Randy Fernando, used to run, so we work on these problems of social media together.
And he used to run a nonprofit called Mindful Schools that trained mindfulness to kids,
and they would teach kids mindfulness for 10 minutes every day or something like that.
They'd give the materials to train kids to teachers, and then they got this program into
schools and, you know, so you get kids meditating, and it's great. And they can show the metrics
showing it's making things better, whatever. The problem is, when those same kids spend five
hours more later that day on TikTok, it just completely undermines all of the work that you
did on the meditation. And that's actually why Randy, you know, joined us in working to do this,
is we see the asymmetry of power. Let me give you a couple more examples of that. I don't mean to
depress people, but there are philanthropists that spend a billion dollars on depolarization efforts
in the United States, where you put people into rooms with each other. And I think that's great.
But the problem is, if those same Americans who spend, you know, let's say 10 hours in a room
with other Americans, and they get a taste of the fact that, hey, people don't have nearly the same
extreme views as I saw on social media, that's great. But then again, once I'm dosed with five
hours a day of Twitter showing me the outrage machine and the other side being acting in bad
faith over and over and over again, because the bad faith examples of their behavior go more viral
than the good faith examples of their behavior, then I'm going to believe the bad faith thing.
So what's going to matter more, the billion dollars spent on depolarization or five hours a day
on the tech platforms, which is to say the tech platforms are going to matter more,
what's going to matter more, teaching kids better mental health habits, meditation,
mindfulness, feeling self secure and confident about your body, all these things.
Or the five hours a day you spend on Instagram, where I make you feel bad about your body.
So the tech does have primacy. And that's the thing that people should have to get,
is that this is the problem beneath other problems, because tech is gradually taking
over the way that we see ourselves, our identity in the case of children, and the case that we see,
how we see ourselves in our democracy. And right now, just one last thing that I think
it's really important for your listeners to know, there's this super important research
by this group called more in common. And what they studied was how we believe a stereotype
of the other side, because social media rewards the most extreme views from the other side and
presents those way more disproportionately than the moderate views, because we get hit by a double
whammy, the extreme voices participate more often than moderate voices. And the extreme voices,
when they say stuff, it goes more viral than a moderate person saying stuff. And so we get hit
by a double whammy of over representation of those extreme views. And just to make this
concrete, Democrats believe that a third of Republicans make more than $250,000 a year,
meaning are rich, only 2% of Republicans make more than $250,000 a year. Republicans believe
that more than a third of Democrats are LGBTQ, and only 6% of Democrats are LGBTQ. And if you
ask both sides before the 2020 election, what percentage of the other side do you believe
would justify violence before the election if they lost? And they believe that 50% of the other side
would justify violence. But when you ask their own side, when they ask themselves, what was the
actual number of that would justify violence, it was only 5%. So again, we're in a hall of
mirrors of seeing the most extreme stuff. And even though I can tell you this, notice that
your mind is still running the malware of the emotions of the last 10 years that reinforced
a false view of who the other side is. The natural landing spot for that, and we're almost there
already, is the positive feedback on the extreme demographic and the extreme message within that
demographic is going to end up with a third of our society super far on the left with radical
views, a third of society super far on the right with radical views, and a third of society,
which is probably where I would be, which is just fed up and don't want to look at any more
information ever again because they don't know what to trust. And in that world, how can we have
a discourse about a collective future? Exactly. We can't, which is why I say that I think between
you and Daniel and I, we've been just reiterating that our biggest problems in the world are all
collective action problems or coordination problems. We're in a game theory matrix and we need to
figure out how to cooperate to achieve solutions and believe that the other side's not going to
defect, which means we need to have a shared reality, whether we're talking about inequality
or deforestation or poaching or any of these problems, nuclear risk, we need to have a shared
view of reality and then be able to coordinate around that reality. And that's why we need a
social media infotech environment that's rewarding synthesis and creating those who are creating
shared reality. So imagine instead of division entrepreneurs that are paid in more likes and
followers, the more clever they are at finding devulsive fault lines, we get synthesis
entrepreneurs, we reward synthesis entrepreneurs. And I don't mean we, the people like we pay them
where we like and follow their stuff more, but just like we subsidize corn or we subsidize the
forms of energy we want to transition to, we could subsidize synthesis entrepreneurs,
those who are doing that job and that work. And then other people say, well, who's successful on
TikTok? Who's getting the most likes, followers and rewards? And we'd say, oh, look, it's those
synthesizers, not those dividers. And we want that society and we need that society and the tech
platforms need to get off the business model of profiting from the wrong thing so that we can do
the right thing. Is there any hope of that happening? Or is that happening anywhere in the world right
now? There's a bunch of groups that are working on it. I think the best hope we have of this and the
best living example of this is what's happening with Audrey Tang, because the digital minister of
Taiwan. I'd say that Taiwan is a unique example, not for what people know in terms of China being
interested in taking over Taiwan. But Taiwan has actually pioneered a form of digital democracy,
where they actually sort in their online environment for what they call unlikely consensus. So they
have this online polling system. We do our democracy using physical ballots and physical
places that we gather and things like that. They're trying to ask the question, if we did
democracy, not just trying to copy the old 18th century form of democracy online, but if we
did a new kind of democracy online, where we have even more people than we could fit in the
town hall. But we're searching for agreement. We're searching for where there's an unlikely
consensus about what the problems are and what we want to do about them. And they built lots of
technologies to help instrument that process. And there's a system called VTaiwan and Polis and
Gubzero. People can check out, we did an interview with Audrey Tang on our podcast called Your Undivided
Attention that I really highly recommend, because it's the most inspiring example. I think the
podcast is called Digital Democracy is within reach, because instead of a complaint about the
tax system or climate change, turning into a shitpost on Facebook that generates an outrage
feed that then generates resignation and apathy, like you're saying, in their system, when I'm
upset about something, I go to this online place and I talk about something I want to change.
And instead of it turning into an outrage feed, they basically sort for who are the unlikely
agreement participants in that process, and then invite them into a Zoom call or a physical meeting
where they are actually in a civic design process to talk about what, you know, to get an expert
input and then to actually talk about what they want to do about it. And it's basically,
it's a machine. It could be someone from the far left and the far right, or or Taiwan's version
of the same, but that they show some elements of facilitation or diplomacy or empathy or whatever,
and those get operated as opposed to the more flamboyant, extreme divisive comments with is
think of it like a, it's like an incentive. It's a landscape. It's an evolutionary search
algorithm that's searching for legitimacy across party boundaries across different points of view.
And it finds these areas. And once it finds them, it's, it sort of inflates them just like
instead of doing narcissism inflation, they're doing synthesis inflation and finding who can,
how can we inflate the areas where people actually agree on something and want to do something. So
when they get something like an 80% approval that, Hey, this is what we want to do the way that this
the way she became digital minister is that the government in Taiwan saw that 80% of the public
agreed that we should do X. And what are democracies looking for more than simply that there's just an
overwhelming majority of people who want X. And right now, that's, that's the thing that we really
need. And that's the best example of it working in real time. And, you know, why the Biden
administration doesn't invite Audrey Tang immediately to the US to help bootstrap a Manhattan project
for a US digital democracy right now is staggering to me. Well, I think they're kind of busy with
other problems. But to me, this seems like a real central problem. So I want to, I want to be sensitive
to the time constraints here. I'm sure you and I could talk for five hours on this stuff, but I
want to get back to when we first met. You also told me something else. You said that you had
lost sleep after hearing about all the, the metacrisis and how things fit together. But you
also said that you shared my video with some of your colleagues at your organization and your
friends. And then in addition to feeling scared and depressed, you also simultaneously felt alive
and this feeling of purpose and like community that you were like seeing the map and it made
sense and it energized you. And that really fired me up because that's what I'm trying to do with
all this work is to get some fraction of society to roll up their sleeves and see what we face
and work together. And it's the working together. I mean, you and I, we don't talk that often,
but when we do, it's like a little shot of adrenaline because you are a pro-social,
you know, adventurer and a catalyst for better futures for humanity. And when I interact with you,
I sense that and I feel like there's a lot more people on the team. That's what we need to do
is grow that team somehow. But with the down regulating of reality and social media, it seems
difficult to do that, but building that community seems really important. Maybe you could talk about
that just a bit. Look, these are challenging topics and what you said is true and real. I think
we both faced it and felt it in our physical health. And I think though that there's nothing
more powerful than seeing those problems together. I mean, ironically, that's what we're talking about
with social media. Like the ideal outcome is that we're able to synthesize and find common ground
about what we actually are all seeing together as opposed to some people are upset about a, you
know, cabal of pedophile elite and some people are upset about Fauci and some people are upset
about Biden and some people are upset about Trump and everyone's just in this different reality.
I've said about different things. It's really hard to feel purpose when that division exists.
And what I love about your work is it's about, you know, you can't have a society be energy blind
if it depends on energy. Just like you can't have an economy be blind to the biosphere if it
depends on the biosphere. And so I think that what's so important about your work is it's
foundational to the life support systems that give rise to our ability to do everything else.
And similarly, I think our work at the Center for Humane Technology is foundational to the
social fabric that we need, the sort of social trust, social contract that we need to be able
to do all the other problems. Now that's daunting when you realize that both are in such a dire
predicament. But when you find the others, as Jamie Weale likes to say, of people who are seeing
the same system that you are. And I think one of the challenges, I mean, I listened to your
podcast, Nate, and it's excellent. It's wonderful. And it's such important work that you're doing
here. And I know that if I'm another listener that I'm speaking to you right now,
it can often feel like you're alone when you're a listener listening to these things.
And I think the strongest thing you can do is find community who see this problem with you.
Because when you know that other people are working on different aspects, it gives you some
hope. You know, I think Daniel and you and I meeting together this year has been some of the
most inspiring jolts of inspiration and energy to keep working on this stuff.
Because we know that there's an invisible team of allies that are kind of doing the best that we
can, at least to navigate, right? We're not going to be able to, quote, unquote, solve or
fix all of this. It's just how do we mitigate and navigate and make wise choices, no matter what
happens? I agree with you. And I think I'm trying to come up with a list of interventions at the
global national community level, at the individual level. There's no easy answers here. And I think
telling people or suggesting people how to be instead of what to do is probably what I'm going
to do for this year's Earth Day Talk. Because we just need a lot more people speaking the same
language, knowing that they're not alone. And the key, I think, is there are so many people who know
that something is wrong with our trajectory. I call them the walking worried. And if we need
to get those people connected and talking to each other in Topeka, Kansas and Albuquerque,
New Mexico and Mendocino, California, et cetera. And even if it's a small group, you form the
social bonds now when things are relatively stable and peaceful and relatively. And those social
networks are going to be really important no matter what happens in the future. And this,
coming back to your work again, with the social media, A, the distraction of it, because people
spend so much time in their little castles ordering stuff from Amazon and getting their dopamine and
entertainment on various social media and other things. That's part of it. The other part is the
forming of the little viral memetic tribes that we've splintered away from the natural physical
tribes in our communities where we live. And I think that needs to be reversed. It's going to
be reversed because we're going to need those people again in our lives. I just want to accelerate
it, if possible. It's like your friend, Nora Bateson, who, when your podcast said that her
friend was starting laundromats or something like that in small cities, I think I heard her say.
Because laundromats are little micro community gathering points, right? And we have hollowed
out the social fabric because as the Amazonification and DoorDashification and Seamlessification
of the world, one click and you're at my door and I get to live more and more in my own
physical isolated reality comes true. It undermines those shared places and hollows out
those shared places of physical gathering. And we are Paleolithic social animal beings,
and we need that. And one of the things that Jamie Weill does with his recapture of the Rapture
gatherings is how do we just bring people together to do the human things, the dancing,
the music, just the being with each other. And by the way, this doesn't have to be this way.
Like if Facebook's business model was bringing people together, they could be just dialing up
the events sort of coordination system so that it's all about it's never been easier
to have community, a rich community life. You can imagine a version of social media that's
actually all about making social coordination of being in the physical world together easier.
But of course, so long as the business model. Why doesn't that spontaneously evolve somewhere
as an alternative? And then there's PR to advertise to send people there.
And that's what's operated. Why isn't that happening? There's got to be some barrier that
keeps that from happening. Well, even if it stops them from doing it, the current incumbent
platforms is that their business models are based on attention. So the hiking trips and the shared
ecstatic dance experiences and the book clubs in person, those don't make them money. And the
isolated screen time watching stuff, laughing stuff by yourself does make them money. So that's
why we need to have an platform. I mean, Apple is one of the best position companies to address
these problems, by the way, because their business model is the hardware. And, you know,
they already have a feature called find my friends or find my, and you can add your friends on there.
And maybe we should do that. So I know more when you're in town. And, you know, it could be much,
they could, they could. Well, we did that two weeks ago. That's right. Exactly. But imagine
that that kind of future set was built out by Apple, again, his business model is totally
friendly to the things that we've talked about. And they could say, Hey, instead of just a static
map that you can just see where your friends are in real time, what if they had ways of signaling
where we're going to be, what, which friends were open to seeing ways of making scheduling and
calendaring a little bit smoother? Like there are ways of strengthening that possibility. And
by the way, there should be smaller actors and startups and things like that. But there are
technical and psychological reasons for why it's hard for small startups to do it.
So Apple is just one of the viable actors that can kind of move the whole thing in this direction.
Well, that gives me hope. And I do think that going out there and alerting people to the risks
from social media or from climate change or resource depletion, et cetera, is necessary as
well so that they kind of know we need to do it a different way. So keep, keep doing what you're
doing. And good luck with, with all your successes on Center for Humanity Technology.
So I just on due to the time, I have some closing questions that I ask all my guests
a little bit more on the personal side. So I hope you're okay answering them. But given
everything that you just outlined, what kind of advice would you give to people, especially
young people who today understand your story and maybe my story, that they're alive during this
time of a fractured information system and this giant panoply of risks, the metacrisis,
the human predicament? What, what sort of advice would you give to a young person?
First, I just, I empathize with when you see things like this, it can be really hard. And
taking it in on your own is not advice. I think the key thing we've already talked about is having
community. You know, but like you've already said, Nate, like the best things in life are free.
I find that in this period of COVID and knowing the things I know, the things I get the most
pleasure from is having dinner with a small group of friends. You know, it's just like the film,
Don't Look Up, right? It's like the asteroids coming to hit Earth. And what do people do? What
do they do the last night before the asteroid, you know, is hitting Earth is they're bringing
in some food and wine over and they're, they're hanging out. And I think that our ability to be
resilient, no matter what, you know, more volatility and chaos is coming our way. And there's going
to be more volatility. I think that it's about going through it together. There's actually a
powerful thing a friend said to me recently over the summer, and kind of reckoning with these topics
is like, yep, it's going to get a little bit bumpy. And the key thing is that we're going to go
through that bumpiness together. And there's just something about not just those words, but
actually feeling it like if you feel like you have that community, it doesn't mean hide in your
hole. It means just build resilience with the people around you that, you know, you want to
navigate this, this whole thing with and find the people, find the others who see it in similar
ways so that we can all make wiser choices together. Yeah, I wholeheartedly agree with that.
I try to, and when I bike, where I bike and finally at spring, so I'm biking again,
every bike ride I go in this county, this rural county I live in, I try and stop and say hello
to someone that I've never met before who's out working in their yard, because these are the
people that live in my county and I know very few of them. So I agree with you on the community.
So next question, Tristan, personal question. And I don't know how you're going to answer this.
What do you care most about in the world?
That's a deep questions. I don't know if I care most about one thing. I think,
you know, having a good future as best a future as we can have is I think every day I wake up and
I just ask every moment of my life, what am I doing? That's what's the most leveraged thing that I can
do to enable us to have a better future than the one that we're currently on the trajectory on.
And, you know, there are things that are moving in that direction. Like it's actually
interesting if we can survive this Ukraine-Russia situation and it's been awful obviously for
everyone in Ukraine and I just want to completely honor that.
The social media issues have really weakened democracies everywhere. They weakened shared
reality. They made it hard to come together. But this Ukraine situation has actually kind of
activated democracies more than ever into more coherence to drop a lot of their local
inside differences and fault lines and to instead focus on a more shared threat,
which is really, I think, viewing the monster that is the authoritarian thing that happens when
you have a small, you know, one person at the top of a massive thing that has a lot of power,
a lot of economic resources, nuclear weapons, and is acting in a unilateral way and can be
inside of the bubble and echo chamber of their own mind. And that's true of Xi Jinping. That's
true of Putin. And we're seeing how that form of governance can act in a way that it doesn't have
checks and balances against it. And I think that that, again, if we can make it through this,
is an interesting development at reversing a lot of the trends that we've talked about.
Because on the one hand, I'd love to see social media platforms that, you know,
reward the synthesis entrepreneurs and those who are better at bringing us together.
And I want to see that. I think that these external events could, you know, be used to
flip things the other way. And I go back to the, I think it's a Taoist story of the Zen maybe,
that's a minute, the maybe, let me say it again. I go back to this Taoist story of the farmer.
I think it's called the maybe story. Are you familiar with this one, Nate?
It's like a, it's sort of a series of stories where the farmer's son breaks his leg
and the person comes over to the farmer and says, oh, I'm so sorry that this tragedy, you know,
the fell, the fall fell upon your son. And he says, you know, aren't you feel bad about that?
And the farmer says, maybe the next moment, a week later, there's a war breaks out,
and all of the sons have to go into the war. But then his son who broke his leg doesn't have to go.
And then the person comes up to him and says, aren't you glad your son didn't have to go to the war?
And he says, maybe, and it keeps flipping back and forth the meaning of each event.
Oh, it's the worst thing that ever happened. That's the best thing that ever happened.
And I just think that story provides a lot of calm to the situation because you realize you,
uncertainty is the place from which not, not a kind of, hey, it's all going to work out okay.
But that's, if there's, if hope lives anywhere, it's in the things that we don't know,
because in the places of certainty, it's not, it's not going to be there.
We, we like certainty. And that's one of the pieces of advice I give my students is to embrace
uncertainty. It doesn't feel good, but we're going to have to get more familiar with it.
So given that maybe Zen story, two other questions for you that are bookends,
what are you most worried about in the coming decade? And what are you most hopeful about
in the coming decade? Most worried about is all of the things we've discussed. I mean,
maybe I'm too close to the problem that I'm focused on, but
you know, I, what I worry about is how hard it is to reverse people out of very deep and
trench belief systems on, on any side, right? It's, it's much easier to pull someone into
a cult than to get them out, ask anybody who's been in a cult. Yeah. And it's really hard once
we've bound our identities up with something to, to let go of that, because it is controlled and
taken over our identities and our relationships. And one of the ways that cults prey on people,
I actually studied cults in my work on persuasive technology. And one of the ways that cults prey
on people is that they increase the price tag of leaving because they tell everybody who your,
your relationships in the cult that they're going to disconnect from you completely if you leave.
And they suck in your family. So if you leave the cult, you're going to leave your family and
then also the family that is in the cult. And they, their design, manipulative design imperative
is to increase that price tag. So it's much, much harder to leave. And that's invisibly and
implicitly happening with the way that social media kind of isolates us more and more into
these bubbles, where it's really hard, no matter what extreme perspective we've been pulled into,
to sort of say, well, I'm willing to like let go of some of that a little bit. So what worries me
is, is that it's much harder to hit the reverse than it is to hit the gas. And that's also why,
you know, for so long, we were really trying to scream as loud as we could upstream from these
problems so that we could get ahead of it. Unfortunately, we've gone pretty deep into
the cult factory. But the thing that gives me hope maybe to turn to your second question
is just that I would never have seen as much change that has in fact happened as over the
last even six months. If you had told me that the president of the United States would be
during a state of the union address, asking someone who is whistleblowing about this fundamental
problem, you know, stand up at the state of the union, which is what Biden did just recently
and inviting Francis Haugen, the Facebook whistleblower, giving this national attention
and saying this is a shared problem for our democracy. You know, to go from something that
a handful of people inside of tech companies know is a problem that are clamoring about to
something that has, you know, the most esteemed elite attention in the world, I think we've
totally traversed that. And the stock prices of these companies have dropped tremendously. We're
seeing attorney generals file big tobacco style lawsuits and litigation that's increasing the
risks of future investors don't want to fund more products like this that are in the race to
the bottom of the brainstem. You know, Apple is making small changes in this direction.
There's a lot to be proud of in the amount that is changing in the other way. We're not there
yet. But I think it's important to if you had a Geiger counter that's sort of like a clicker
for each click on the timeline of things moving in a better direction, it would sound like, you
know, click, click, and then it's getting faster and faster. So that's where I at least, you know,
get hope from and hopefully people waking up and listening more to your podcast and, you know,
seeing these problems. Thank you. I think my podcast is just trying to outline how all the
different issues interconnect and most people in climate energy finance space don't get your
perspective. I think they've probably seen your your documentary and are a little aware of this,
but this issue affects everything. So I really wish you luck and continued success on this.
And we'll have to have you back in six months or so and get an update because there's so much more
that I want to talk to you about. Do you have any other closing words of wisdom advice or thoughts
for our listeners? No, I don't think that I can barely say something wise about the things that
you asked me before. So I just appreciate being on with you, Nate. It's really great to do this
with you. Final honest question, should I unsubscribe from social media? I would say that if you don't
need these things, then get off. The problem is that we justify to ourselves, oh, but what if I
were to miss, and there it is again, the loss aversion, there's that Paleolithic emotion,
but what if I were to miss that video, that one video of, you know, that would change my view
on this topic and we would miss things, but we're missing things all the time. And I'll tell you
maybe one last story. Steve Jobs was once asked when someone who's building the podcast app for
the iPhone, the probably the one that you're listening to this podcast on right now. The guy
was building this podcast app was in a meeting with Steve Jobs at Apple and said, I have an idea,
why don't we make a news feed that shows you what all the podcasts your friends are listening to?
So I would see when Nate's listening to his podcast and he'd see what things I'm listening to
and we'd be able to see each other stuff. And then we can create a different kind of social
network around it. And Steve Jobs sort of like slammed his fist on the table and said, no.
He said, if something is actually that important, then your friend will copy and paste it,
the link to it and they'll send it to you. And we've gotten sort of normalized to this view that
everything has to be shared with us and go viral and put it in a feed and all of this stuff.
I would prefer to live in a society of what's time we'll spend or sort of worthy of our lives and
our finite time and attention given the challenges that we face. And I think that if we develop a
social norm in a culture where when things are really important, we take the time to send it
to those handful of people that need to know about it, because if we knew that was the decentralized
operating system running inside of everybody else, then we could have a lot more faith,
not worrying that we're going to miss something important from these feeds.
Well, on that note, I am going to bid you a good afternoon. I'm going to change my clothes.
I'm going to get on my bike. It's 48 degrees out. And because of the pro social shot of
comradery, I'm going to leave my phone here on my bike ride and I'll check how many likes I got
for this podcast to see if people are still giving me. Thanks. All right, my friend,
to be continued, be well. I'll talk to you soon. And thanks for your time.
If you enjoyed or learned from this episode of The Great Simplification,
please subscribe to us on your favorite podcast platform and visit thegreatsimplification.com
for more information on future releases.
