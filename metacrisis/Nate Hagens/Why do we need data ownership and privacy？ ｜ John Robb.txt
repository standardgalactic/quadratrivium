We're kind of in that kind of situation in society with technology. I mean, as these things
start to roll out, as we start to get augmented reality and selective reality, and then you get
AIs and AIs as companions and AIs as accelerants, tutors, a certain subgroup is going to pull away
and they're going to be people at various stages all the way down to people who are disconnected.
And it's going to be harder to make money in the disconnected and lower strata of that.
More likely to be automated, more likely to be replaced, more likely to just be used for their
data production. Every single job that you have, everyone going forward is going to be a data
strip mining effort by your employer. They're going to be sucking your data and feeding it into
systems either to get paid for it or to put into a system that they control in order to replace you.
Who owns all that data? Well, that's the thing that we didn't fix. I went in front of the Senate
a couple of years ago about social networks and data and how this all works. And just before
OpenAI hit, and I said, we have to get this data thing right, because data is becoming the new
oil. It's becoming so important. It's going to be used. All these social networks are accumulating
it, Google included, to build AIs. And people are like, AI is not going to have or happen. But
what we need to do is make sure that people have data ownership, just as a core right.
Otherwise, we're going to be like surf. So we're going to be contributing our labor for free to
the nobles and feudal landlords. And our data will be strip mined and excavated. These AIs are
going to be the most valuable technological artifacts we've ever created, built off of our data.
And we don't have any equity stake in their value. They're just saying, hey, we'll give you
cheap services or relatively cheap services based on these AIs. And that's the payment you get for
contributing the data that produce these. OpenAI would have been possible without strip mining
our data.
