Kurt Friston's free energy principle is a cool concept which I do not yet understand.
That means I'm going to make a Taken Squid video essay about it.
The phrase free energy made me immediately skeptical.
It sounds like making infinite energy for free using a perpetually spinning wheel or
whatever.
Friston's free energy principle isn't like that at all.
It's kind of the opposite.
A neuroscientist Friston claims sentient beings and some cool robots he simulated work by
minimizing a variable called free energy in a mathematical formula from Bayesian statistics.
Here's a picture of a brain.
Don't worry about the scary Greek letters representing numbers.
Let's just put our foot down and say whatever the brain's whole deal is, it's got some internal
states.
Something's going on in there.
Something's going on outside the brain too.
We can put our other foot down about that and we call it hidden states or external states.
Brains don't get to know everything going on out there, but they do get sensations.
And brains don't get to touch everything going on out there, but they can take actions.
Internal states and external states don't directly interact, but they do interact.
Minimizing free energy is minimizing surprise.
Sometimes the sensations the universe provides are just bewildering.
A bewildered brain doesn't even know what its next action will be because it's never
been bewildered like this before.
To minimize surprise, the brain takes actions which make the universe less bewildering all
the time.
The brain finds loops, actions which lead to sensations it knows how to react to.
That sounds familiar, right?
You and I have daily routines.
We know how to eat breakfast, we know how to commute to work, we know how to eat lunch,
we know how to commute back home, we know how to eat dinner, we know how to watch TV,
we know how to fall asleep and do it all again when we wake up.
If any aspect of this routine surprises us one day, we might take actions to get the
routine back on track.
We have routines which last weeks, months or years like holidays.
We also have routines which last minutes or even moments like breathing or having a heartbeat.
If any of those routines surprise us, we'll do whatever it takes to get back to normal.
In surprise, minimizing free energy means maximizing the likelihood that our conceptualization
of the world is correct.
Our internal states need to share information with the sensations.
Information out there in the universe has to be represented in here.
Your brain created your universe and recreates it at every moment.
Just so you, yes you, can take action.
So cool.
There's a lot of discussion about the free energy principle and not everyone is sold
on the idea, but Friston has developed a generator which uses the math version of what I've just
described to generate simple actions.
He says his generator, which is sort of a simulated robot, captures the bare essentials
of a maze forging task under novelty or uncertainty in the absence of any knowledge about the
maze that has been accrued through previous learning or experience.
The subject had to forage for local information to build an internal model of the maze structure
using short sequences of psychotic eye movements.
In conclusion, we have described an active inference scheme for epistemic foraging and
goal directed navigation using a minimal setup.
The key contribution or insight afforded by these simulations is to show that purposeful
goal directed behavior can be prescribed through simple prior beliefs about the outcomes that
will be encountered under allowable policies.
So it works.
Minimizing free energy works.
Maybe it's not how the human brain literally operates, but it can make working robot brains
and that's good enough for me.
It works.
How does it work?
If x and y are events, we can write the probability of x happening as px and the probability of
y happening as py.
This is Bayes' theorem.
The probability of x happening, assuming y is happening, is equal to the probability
of x times the probability of y assuming x divided by the probability of y.
For example, rolling a die, a regular old die.
The probability that the die rolls a six is one out of six.
The probability that the die rolls an even number is one in two.
If the die rolls a six, it's certainly rolled an even number.
So the probability that the die rolls a six, given that the die shows an even number, is
one in six times one divided by one in two.
One in three.
If you roll a die and it's even, there's a one-third chance that it's a six.
That's pretty simple.
Reality?
Not simple.
How does our brain use sensations to figure out the most likely nature of reality around
us?
We're trying to maximize this, which Bayes says is the same as maximizing this.
If we assume our sensations are continuous instead of discrete, we can rewrite this like
this.
This integral is just bad, bad integral, intractable, too hard.
But we can approximate it using a generator like the one Friston made, which predicts
the joint probability of getting whatever sensations based on whatever corresponding
environment.
I'm not completely sure I understand any of what I just said, but in my experience,
I've got to learn something like this five or six times before I actually understand
it.
I hope I can learn about it a couple more times at the Okinawa Institute of Science and Technology.
I've been thinking more about the project I'm proposing to OIST.
It seems like that's all I do here at Thanks to.
Last time I said I wanted to simulate a swarm of turtles, but learning more about free energy
has convinced me to turn the turtles into bees.
I made an animation to describe what I've got in mind.
This is a grid.
Yellow tiles are bees, pink tiles are flowers, and black tiles are the hive.
Bees are always choosing actions that do nothing or move around.
If they move to a flower, they collect some nectar.
If they move to the hive, they deposit that nectar.
Bees eventually die, but new bees are born whenever enough nectar is collected.
These bees are just moving randomly, but I'd like to attach each bee to a neural network
sort of like this one.
Actions are chosen based on the bee's memory of the world around it and its own previous
actions.
If I ran a real simulation like this, I think the bees would just die.
I'm not telling them to collect nectar and make more bees, so they'll probably wander
aimlessly.
But if I ran a thousand of these simulations, I bet a few of them would accidentally collect
some nectar and start a new generation.
This could begin a loop of survival, where the bees keep starting new generations because
that's their routine.
If older bees start doing waggle dances to teach new bees what to do, that'd be philosophically
intriguing.
I like to think this is how DNA works in natural selection.
No one gave DNA a goal to keep making copies of itself, but DNA which doesn't make copies
of itself doesn't tend to stick around.
I'm going to keep playing with these bees.
Bye-bye.
