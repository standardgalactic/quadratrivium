Attention, wee-yoo, wee-yoo, my application to OIST has gotten me an interview.
At the end of May, I'll talk to some professors in Okinawa on Zoom.
So for this week's video, I'm going to practice my pitch.
A few weeks ago, my Talking Squid video essay was about Friston's free energy principle,
neuroscience's latest model of the sentient being.
I described a project involving bees.
I still like the idea, but it's another classic example of me getting way too complicated,
way too quick.
The project I actually proposed to OIST is much more simple.
Carl Friston demonstrated his free energy principle by training a program to navigate
a maze.
I want to train two programs to navigate a maze, one predator and one prey.
The predator wants to minimize its distance to the prey.
The prey wants to maximize its distance from the predator.
At OIST, I'd like to make this work continuously, but for now, let's leave it discrete, like
a board game.
In each time step, the predator and prey both move one space up, left, down, or right.
The two agents compete, learning how to best interpret their perceptions of reality by
minimizing free energy in a generative adversarial network.
Last time I talked about free energy, I skipped most of the deeper math.
Now I've read and reread enough tutorials to go over one step by step, explaining how
it applies to my project here.
Also, thank you, Professor Jun Tani, for recommending this tutorial from Medium.com.
Reality can be called a collection of hidden variables, which I'll label S, meaning state.
Our reality is big and complicated, but the predator and prey have a pretty simple reality
we can edit in a photo editor.
Every white tile is open.
Every black tile is an obstacle.
Let's call this area an X by Y matrix of 1s and 0s.
Let's add two layers, which are just zeros, except one at the predator's position and
another one at the prey's position.
This reality is a 3 by X by Y matrix of 1s and 0s.
But all this is hidden.
No one gets to see every part of reality at once, except us deities who made this reality
in a photo editor.
Predator and prey only observe reality within a few spaces of their position.
Let's say Z spaces.
So predator and prey get 3 by Z by Z matrices of 1s and 0s, which I'll label O, meaning
observation.
They both use these small observations to understand their larger reality, generating
an inferred state.
In some observation, what's the probability reality is one state or another?
If reality was one state or the other, what's the probability to get this observation?
This is called active inference.
Our conceptualization of reality should maximize the likelihood of the observations we're getting.
Decreasing the probability of our observations is the same as minimizing the negative log
of the probability of our observations, also called our surprise.
Okay, the tutorial notes that the probability of an event is equal to the sum of the probabilities
of that event occurring alongside every alternative for another event.
For instance, the probability of rolling a 6 on a die is 1 out of 6, and if we rolled
another die next to it, we can think of that 1 sixth probability as divided into sections
based on the other die.
So we can include all possibilities for reality inside this expression we're calling surprise.
We also multiply by q of s divided by q of s.
Whatever q of s is, q of s divided by q of s is 1, and multiplying by 1 is a perfectly
fine thing to do.
Now we're trying to minimize this surprise, and that's hard.
It would be a little easier to minimize this thing, because this q of s is outside the
logarithm.
This expression is called free energy.
Thankfully, it just so happens that free energy is the upper bound of surprise, so minimizing
free energy does minimize surprise approximately.
The tutorial loses this minus sign by inverting this fraction in the logarithm.
Then the tutorial shows another way to represent free energy with a notation I had never heard
of before.
Callback Leibler divergence, also called relative entropy.
The kl of two probability distributions is a measure of difference which best measures
zero when the probability distributions are exactly the same.
If we can manage that here, then the free energy happens to be equal to the surprise,
and we can probably get pretty close, because q of s is an arbitrary nonsense function we
made up.
We just have to nudge it closer to p of s given o.
To turn math into a metaphor, we're making our private notion of the universe into something
similar to what our observations are suggesting.
Professor June Taney might suggest our private notion of the universe should involve long,
short-term memory networks.
Okay, I'm going to quote directly from the tutorial just to make sure I'm reading it
right.
By minimizing free energy, the arbitrary distribution q of s gets closer to the posterior p of s
given o, and if they match, kl term becomes zero and free energy is exactly equal to surprise.
So the more we minimize free energy by wiggling q of s, the more it becomes closer to surprise
since it's an upper bound, and by minimizing free energy by wiggling parameters of p of
s and s, we can minimize surprise even further.
So that's what it means to actively infer for one discrete moment.
But because reality changes in every moment, we can't stick to one discrete moment.
Our inner model might not work so well with whatever we observe next, so we have to improve
our model in every time step.
And reality can change based on what we chose to do lately.
To minimize free energy, we've got to choose our own actions responsibly.
At every time step, we approximate these terms for every possible policy.
We might like to consider our policies and actions several steps into the future, but
we can't predict the future, so we've got to approximate it.
I'm skipping a few complicated steps here, but the tutorial's final way to write free
energy is like this, the sum of cost and ambiguity.
To quote the tutorial again, because I think this is the sort of thing I might be learning
to understand for months or years, the left term called cost or risk favors policies that
will result in observations we like.
And the right term, ambiguity, quantifies how uncertain is the mapping between state
and observations.
Let's cover the tutorial's incredibly simple example, and then try to stretch that example
out to my predator slash prey project proposal.
Suppose the universe has only two possible states.
Your stomach has food, or your stomach does not have food.
There are only two possible observations, two feeling fed or feeling hungry.
There are also only two possible actions, eating or not eating.
Where does a mind fit into this?
Squint, or you'll miss it, says the tutorial, we like to be fed and not hungry, so we assign
a higher probability to observation one, fed.
In other words, we express preferences over observations as probability P of O.
Doesn't that sound a little backward?
I thought we'd be estimating probability, but the concept of assigning probability to
our observations makes it sound the other way around.
We want to feel fed, so we're putting a higher probability on the chance of us feeling fed.
When we make a decision, we consider our high likelihood to feel fed, and that might inspire
us to feed ourselves, because that would explain the feeling fed.
To put it the tutorial's way, we start by estimating the hidden states under each policy,
and end up acting such as we observe what we expect.
No wonder motivational speakers are all about optimism and vision.
The numbers say, you go where you aim.
Not everyone who thinks they become president becomes president, but no one who thinks they
won't become president becomes president.
They don't bother taking any of the steps.
So if we want our computer to do something for us, we should tell it, this is going to
be accomplished, I'm 100% sure, do it.
So let's stretch this out to the predator and prey.
The reality here is bigger than two states, food or no food.
There is a whole 3 by x by y matrix of zeros and ones.
The observations are bigger than Boolean 2.
The predator and prey both have a 3 by z by z matrix of zeros and ones, and they can tell
how far apart they are from the other agent.
Red and prey both have four possible actions, up left down or right.
I want the predator to chase the prey, so I tell it, closeness has high probability.
When the predator makes a decision, it picks the action which leads to what I told it to
expect.
At the same time, I want the prey to escape from the predator, so I tell it, distance has
a high probability.
When the prey makes a decision, it picks the action which leads to what I told it to expect.
This predator and prey are animated by me, hi.
But I'm confident, with the right setup, Friston's free energy principle could get
these two agents moving as if by their own thought.
How?
No matter how much I read, I don't think I'll ever find a tutorial which explains
where the thoughts come from.
Really, there are no quote-unquote thoughts here.
When I made those generative adversarial networks which produced Pokemon pictures, I never
wondered, gosh, where did that Pokemon come from?
I never gave the generator a Pokemon, how did it get one?
The Pokemon I see don't live in the generator, or the picture.
The Pokemon I see come from within me, the viewer, the observer, the beholder.
I've been reading a book called You Are the Universe by Depak Chopra.
The book tries to disprove a determinist notion of the mind.
It says the mind isn't limited by the brain, because the brain is not the origin of the
mind.
As the sort of math squid who makes this sort of video essay, I'll always be ranting about
the complexity of machine learning algorithms deep as the human brain, but when I perceive
the predator and prey seeming to make their own decisions, even though I know their thoughts
I'm seeing are my own, I wonder where my thoughts are coming from.
Who does the thinking hear it thinkster?
The tutorial gets more explicit with the math in another post, and I'll get there eventually.
I'll get there eventually, because I believe it's likely that I will get there eventually,
and therefore I reliably choose actions which lead me closer to getting there eventually,
because that's what I expect.
Somehow, there is little doubt in my mind that this is how the mind works.
I'll see you a few time steps in the future, bye-bye.
By the way, I've got a Patreon at patreon.com slash thinkster.
I want to thank all these squidlings and elder squids.
Thanks.
