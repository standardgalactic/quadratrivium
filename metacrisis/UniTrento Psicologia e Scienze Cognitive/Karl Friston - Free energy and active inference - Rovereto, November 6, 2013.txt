So, good morning. Can you hear me? No. You can hear me. Okay. So, good morning and welcome to the
inaugural lecture for the new PhD year. So, I'll welcome today Professor Friston on behalf of the
director of CHIMEC, Professor Giorgio Vallortigara. Professor Friston is the scientific director of the
Welcome Trust Center for Neury Imaging and Professor at the Institute of Neurology in UCL. Earlier in his
presentation he said that the research that he did in the U.S. has been done in the U.S.
in the past, and that he has been doing research in the U.S. in the U.S. and in the U.S.
in the U.S. in the U.S. in the U.S. in the U.S. in the U.S. in the U.S. in the U.S. in the U.S.
Institute of Neurology in UCL. Earlier in his career he studied physics and psychology as an
undergraduate at Cambridge University. Then he obtained a medical degree with training in
psychiatry at King's College London and at Oxford University. And I was just telling
Professor Friston how I think his lecture and his background and his expertise is going to be
perfect because I met yesterday with a PhD student and the diversified background of the PhD
student I think represents very well the approach that CIMEC has and that the school has. And so I
think it's a perfect match for the new PhD students. Professor Friston is one of the
pioneers of neuroimaging and contributed greatly to the field both in advancing theoretical
and development and for the construction of methods and formal approaches used by thousands in the
field. He has led the development of the most popular toolkit for analysis of functional MRI
data, SPM, the study of structural differences through quantification of voxel-based morphometry
and the study of online interactions between brain regions via dynamic causal modelling.
The impact of these methods and formalisms on the field cannot be understated and they constitute a
common reference for describing structural and functional data. Professor Friston is also a
rentless innovator with numerous contributions to various domains of study such as modelling of
diseases, the implementation of formal Bayesian models for modelling neurobiological processes and
most recently the development of a formal framework for explaining how the human brain processes
and samples information given prior knowledge. Professor Friston has been the president of the
International Organization of Human Brain Mapping and received numerous international recognitions.
Just to mention a few, in 2006 he was elected fellow of the Royal Society and in 2008 he
received a medal from the College of France. So it's a great pleasure and honour to have him
today, so please join me in welcoming Professor Friston.
Thank you for that lovely introduction, it's very full. I also learned a lot about myself when
we introduced so courteously and thoroughly as that. It's also a great pleasure to be here.
It's a wonderful place, the environment is absolutely splendid and I've been very impressed by
the academic prowess and the clear ascendancy that all the people I've spoken to and the groups I've
spoken to are demonstrating and I'd also like to extend my welcome to the new PhD student.
So where are you? Put your hand down there. There you are, all in two rows, that's very nice.
Welcome. Now I usually start this lecture by saying you don't have to remember anything and you
are going to learn nothing and I mean that in a practical way because what I'm going to do is
really just provide a context or a framework within which you can understand what you already know.
So this is more a synthesis of different perspectives within a single point of view.
And the point of view is basically that the brain actively generates and constructs explanations
for its sensory input. So it's an active Bayesian engine generating predictions of sensations
and in generating those predictions or hypotheses it's trying to explain actively what is happening
in the outside world. And what I'm going to do is take that idea and contextualize it in terms of
developing the underlying basic premise, the fundamentals in a very abstract way.
I'm going to use simulations of a very abstract thing which will be a primordial soup.
And then using exactly the same formalism and differential equations, use those ideas to try
and understand the dynamics and the organization of the brain and will conclude with a simulation
of a fairly advanced capacity of the brain, namely to observe one's own actions and the actions
of other people. So we're going to go from primordial soups to action observation in 50 minutes.
You ready? So let's start with a question posed by Schrodinger. I'll just read this out because
it's a fascinating question. How can the events in space and time which take place within the spatial
boundary of a living organism be accounted for by physics and chemistry? So this was one of his
phrases from his famous monograph or essay, What is Life? In this question though, there is a deep
challenge. It is the notion of a spatial boundary and of course if an organism or any self-organizing
system, a biotic system, exists within a spatial boundary, it must possess a spatial boundary.
So we have to understand what maintains the integrity, both functional and dynamic, of the
spatial boundary of any arbitrary system. So that's the challenge. We're going to set ourselves
the first third of the talk. We're going to get the answers and then apply them to the brain
as a self-organizing system. So as Schrodinger would acknowledge, the boundary itself is a
statistical object, is a probabilistic object and in probability theory, a boundary is usually
referred to as a Markov blanket. So this is a, if you haven't come across this concept before,
think of it as a collection of states or variables that insulates you from the outside in the sense
that if I wanted to know anything about myself, I would only need to know the states of my Markov
blanket and I wouldn't need to know anything beyond that blanket. So it induces a conditional,
if I, independence between some internal states and some external states. So more formally,
what I've done here is just to try and cartoon this. Is this, have I got the wrong?
Oh, thank you very much. That's perfect. So let's just look at this notion a little bit more graphically
or formally. What I've done here, I'm associating the variables or the quantities that would describe
any arbitrary system from a virus to a vegan with these nodes or circles here and the
dependencies amongst these time varying quantities by these arrows or edges. If I take one or a
collection for simplicity, I'll just take one state here and I'll call that the internal state.
Then the Markov blanket is defined by the parents, the children and the parents of the children of
those states or in this example that one state. So this would be the Markov blanket of this
internal state here and these would be the external states. And there's one further aspect
of this Markov blanket that must exist for any system that has these causal dependencies
that are not complete, not all to all. And that further partition is in terms of states that are
and are not influenced by the internal states. So here we have states that are not influenced by
internal states and here we have the Markov blanket that is influenced by the internal states.
I'm going to call this by partition of the Markov blanket a partition into sensory and active states
and the reason for doing that is shown on the next slide. What I'm going to do is invite you to think
of this sort of four-way partition of the states of any random system, dynamical system
from the point of view of a cell or indeed a brain where we have all the internal states,
the intracellular states of a cell, all the concentrations of its internal constituents,
they will constitute the internal states and they might associate the A, the active states
with the actin myfilaments that support the structure, the skeletal structure and movement of the cell
and those support the cell membrane on the cell surface which I'm going to associate with sensory states
that are subject to influence from external states on the external layer of the cell.
And in exactly the same way I'm going to associate or you can associate the internal states of the brain
the activity of every cell in the brain, the connection strengths that wax and wane,
anything that you need to write down to specify the state of the brain at this point in time,
those will become internal states and then our active states would be the state of effect organs,
our motor, our muscle plant that again support the sensory epithelia containing the sensory receptors
or the sensory states that are again influenced by fluctuations or changes in external states.
I'm also going to refer to external states as hidden states because they are hidden behind the Markov blanket.
So with that partition in mind let's just stop there and then consider the basic behaviour of any dynamical system.
So I'm going to get a bit abstract here and ask you to think of any system comprising all of these states
in terms of a trajectory through some state space.
So I've cartoon that here in terms of this what's called a random dynamical attractor.
So the states just change as a function of time tracing out a trajectory in two states here
but imagine there are thousands, millions, possibly an uncountable number of states describing the system.
And what I'm going to assume is that this system exists in the sense that it is a gothic or that it has some probability measure.
In other words, these trajectories can be regarded as reporting the frequency with which particular states
or positions in state space are visited again and again and again.
The probability that they are occupied.
So if these states were X for any given system say me, M, then this can be regarded as a probability distribution
over the potential states that I occupy.
Now I'm going to try and suppress the number of equations here but if you allow me two very important ones
these are probably the two that I have in fact used.
This is the Fokker-Planck equation, also known as the Convergraf forward equation,
and also nicely the master equation.
So it's perfectly okay to show the master equation in the presentation.
And what it does is it describes the evolution of this density.
In and of itself this is not important.
What is important is the solution to this equation which is a probability distribution of the system
in the long term once it has settled down is a gothic distribution.
And that solution has been written out here in a form which you may not recognize
but it is a standard form, in fact this equation is called the standard form.
And the reason I'm putting it down is I want to try and interpret and unpack it in terms of what it would look like
if we looked at the different components of this solution and then use that apparent behavior
to understand or interpret self-organization from a biological perspective.
The particular form here, the standard form, basically decomposes the flow in terms of a gradient ascent
or hill climbing on the log density or probability of occupying different states.
And this decomposition is in terms of two components, it's actually known as a Helmholtz decomposition,
they're called curl and divergence free.
That sounds complicated, it's actually very, very simple.
If you imagine that the dynamics of this arbitrary system here are constituted by the system
and we're trying to go uphill towards the states that it likes to visit.
So climbing a hill and it's being knocked back by random fluctuations omega here,
such that the hill climbing and the knocking back are in perfect balance,
so the density is not in itself changing.
Then we can decompose the hill climbing into two components,
there's one that actually ascends the hill directly.
And then there's another component that is orthogonal or at right angles,
which is in fact the divergence free component, which goes around the isocontours of the hill.
So in the absence of any hill climbing I would just be going round and round the base of the hill.
So these two components can be interpreted as one which doesn't change this quantity here,
the log probability, and another one that is on average trying to increase it
to offset the random fluctuations that undo that gentle hill climbing.
Now that's an important understanding or description of any dynamical system
that becomes incredibly important when we bring back the Markov blanket into the equation.
So remember the Markov blanket is defined operationally in a way that means
the internal active states, basically my brain and all my muscles,
is never directly influenced by the external states or the hidden states.
And yet this decomposition, this sort of nuanced hill climbing flow or behaviour still applies,
but in this instance the hill climbing is not a function of the hidden states or the external states.
So there's nothing remarkable about that, this is just the standard form marginalised over the hidden states,
until one thinks about the different interpretations of this standard form here.
So if I just saw this system and I knew it's Markov blanket, what would it look like?
How would I interpret it? And there are a number of very important interpretations
that all rest upon how you understand or interpret this quantity here.
I've just listed a few of the very important ones because they all speak to global theories,
grand theories of life and the brain or the neuroscience and self-organisation.
The first one is relatively simple.
If the probability of the states that I like to occupy, given that I and me
is scored by this log probability here, then this log probability becomes a value function
or an energy function that describes the sorts of states I like to occupy.
It is simply a value function.
So I would interpret the standard flow that is inevitable, it has to exist,
in terms of the system trying to maximise its value, trying to recover and get to states it likes to occupy.
And from that one can see very easily how that perspective underpins reinforcement learning,
optimal control theory, say motor control, and indeed right up to the level of economics
in terms of expected utility theory.
We're always trying to maximise some function of our states.
In fact, the whole game of normative theories defined in terms of there being a function
that the system is trying to optimise or maximise can be explained by the interpretation
of this log density as a value function.
Interestingly, the negative log density or the negative value is called self-information
and information theory, also called surprising or more simply surprise.
It's the quantity that is upper bounded by free energy, which is in the title of this presentation,
but I don't need to talk about free energy any more other than to say that it is equivalent to
or upper bounds surprise.
And this information theoretic perspective means that as we're maximising this quantity,
we're minimising surprise.
And that can be fairly easily unpacked in terms of a lot of information theoretic descriptions
of adaptive behaviour such as the principle of maximum information transfer,
the principle of maximum huge information, principle of minimum redundancy by Horace Barlow,
informax by Linzka.
There are lots of takes on this, but they all can be essentially reduced to the minimisation
of surprise.
That's very closely related to broader perspectives through the fact that by the
egotic assumption that this system exists, the time average of surprise is equal to entropy.
So this natural hill climbing is equivalent to minimising on average the entropy of the system.
In other words, it would look as though the stuff inside the Markov blanket is locally
resisting the second law of thermodynamics, a resisting a natural tendency to dispersion
and decay in disorder, unpredictability, which of course is at the heart of self-organisation
and cybernetics.
And to put these notions very, very simply, and Ross Ashby did put them very, very simply,
all that this is saying is that biological systems have a homeostasis.
They keep things within bounds.
They resist a natural tendency to dispersion.
The final interpretation, which is the one that I'm going to appeal to time and time again,
is a purely statistical one.
In fact, it comes from Bayesian statistics.
And it's a probability of some sensory data given a model.
That's the log model evidence.
Sorry, it's a model evidence and value becomes a log model evidence,
and surprise becomes a negative log model evidence.
And this quantity is the holy grail of most statisticians,
evaluating and comparing the evidence in some data, in some sensations,
for a particular model of those data.
Because you have to model them because you can never see these hidden states
by virtue of the Markov blanket.
And that perspective leads us to the Bayesian brain hypothesis,
active inference, which I will talk about, and predictive coding.
And those ideas were first articulated by Helmholtz, which we'll see in a second.
Before we do that, what I want to do is just illustrate those two aspects of these interpretations.
This notion of, well, let's just see how we're going to simulate it first.
What I'm going to do is I'm trying to illustrate some of these emergent interpretations,
emergent behaviors that have these interpretations,
by using a completely arbitrary, nonlinear random dynamical system
that I just picked out of the blue to show the sorts of behaviors that we're talking about.
This particular system comprises about 120 little macromolecules,
each with an electrochemical state, three states that are described by the Renzi tractor.
These are the dynamics that, in a simple way, predict convection in weather pattern formations.
There's a simple set of equations that you can find on Wikipedia that have this nice butterfly tractor here.
So each of these little cyan locations is a location of a molecule.
These dots represent the states which move around quickly, modelling electrochemical dynamics.
And crucially, the molecules attract and repulse each other over the short range,
where the attraction depends upon the synchrony of the electrochemical states.
It really doesn't matter how you can play around, it doesn't really change the nature of the simulation.
So here is this little soup where I've just coloured the locations in terms of the phase of the electrochemical states.
This will show you typically how fast they change.
And here, as a function of time, the electrochemical states, the one in blue,
and the physical location, showing occasional catastrophic explosions
as one of these little molecules is expelled to the periphery
and then slowly collapses back into this little well containing the primordial soup.
So it bubbles away there gently.
Now, our game now is to see if we can find any evidence for life
of the sort that I've just described within that dynamic.
And the doing of that rests upon identifying the Markov blanket.
If I can find the Markov blanket, I can see whether it maximises its value,
whether it minimises its model evidence, whether it resists natural tendency to decay.
So the first job is to find the Markov blanket, and that is actually very easy.
I won't bother describing how other than to tell you,
you appeal to something called spectral graph theory to take the eigenvector,
the principal eigenvector of a matrix encoding the parents, the children,
the parents of the children, and that identifies a little collection of internal states,
eight internal states here, the blue states here, large blue circles,
that have formed a little ring with a tiny little tail or cilium that's wiggling around.
And once I've defined those, I can define the Markov blanket
and I can divide that into active states in red that surround the internal states
and the complement of the Markov blanket, which are the sensory states,
which unsurprisingly rest upon the active states and form the surface of this little simulated organism.
So by finding the Markov blanket, I've now identified in this soup a little organism
and now I can do tests on that organism to demonstrate the sorts of behaviours
that those interpretations suggest should be present, and there are effectively just two of them.
One, this auto-poetic, the self-assembly and self-maintenance of the Markov blanket
in the internal states by resisting a natural tendency to disorder,
and two, some statistical or inference property in the sense that what goes on inside
should encode or represent or be able to be used to predict what is going on outside in the hidden states.
So I'm going to demonstrate that by doing what we as neuroscientists do to human brains all the time.
We either look for correlates of internal brain states with changes in the sensorium,
or we do brain activation experiments, or we do lesion experiments.
I'm going to start with a lesion experiment, and my hope is that I will be able to show that just by changing subtly
the interactions between one of these four sets of states, I can demonstrate a decay and an increase in entropy,
thereby illustrating that the resistance to that decay is inherent in this self-organization.
So the next slide shows you what would happen or what happens in terms of the position.
Just wait patiently, I think it's got confused by its movement.
So here are the positions of the elements of the little organism here, over 512 seconds without any lesion,
and here are the decay, the loss of this auto-polysis or the loss of this structural homeostasis,
induced by making it blind by destroying the sensitivity to external Newtonian forces
and only in the sensory states, by paralyzing it, by rendering the active states insensitive,
and finally by giving it a brain insult or a stroke by changing or lesioning the internal states.
And in every case we see the basic of the system just decays and dissipates into the environment.
Basically it dies, which is quite sad.
So the next illustration is the illustration of this predictability, this inference,
this modeling of the external world.
I'm showing one example here to illustrate the sort of thing that emerges from this,
effectively what's called generalized synchronization between the internal and the external states
that are separated by the Markov blanket.
And what I've done here is ask, if given the electrochemical internal states,
can I predict the motion of external states?
So it'd be like, does neuronal depolarization in V1 predict the motion of something in the visual field?
And indeed it does.
I won't show any statistics, I'll just show one particular self-evident example.
So here this is the motion of this peripheral state out here,
and here are the internal states that best predict it.
In fact, one can almost see eyeballing these data.
This distributed set of fluctuating fluctuations or transient here that predicts this,
and a smaller version can be seen out here with this excursion here.
Interestingly, these fluctuations that do the encoding actually predate the event.
So it's a tricky question as to whether the event here has been registered and sensed by the organism,
or whether the organism actually, or the internal states through the active states,
actually caused this through, if you like, waves of propagation or generalized synchrony through the Markov blanket.
In the same way that you never quite know in, say, a saccade, an isochalic experiment,
whether the responses are visually evoked,
or whether you're looking at the ocular motor drive to the saccadic eye movement.
There's a circular causality here because this agent is effectively causing its own sensations,
because it is intrinsically embedded within the environment.
So just to summarize these basic sort of behaviors,
the existence of a Markov blanket necessarily implies a partition of states into hidden states,
their Markov blanket, which can itself be divided into sensory and active states,
and external or hidden states.
And because active states change, but are not changed by external states,
they minimize the entropy of internal states in their Markov blanket.
And this means that action will appear to minimize, or maintain, sorry,
the structural and functional integrity of the Markov blanket by minimizing the entropy.
And that's very similar to Varela's notion of water polices.
Internal states appear to infer the hidden causes of sensory states by maximizing Bayesian model evidence,
and influence those causes, the causes of sensory states, through action.
And we're going to call that active inference.
So that's the basic behavior that I want to now revisit in the context of neuroscience,
and see if we can see those sorts of behavior applying to neuronal dynamics
in the way that we sample our world.
I'm taking my lead here from these intellectual architects, and in particular Helmholtz.
And he articulated, certainly the Bayesian perspective, I think beautifully in this phrase,
objects are always imagined as being present in the field of vision,
as would have to be there in order to produce the same impression on the nervous mechanism.
And this idea has been championed in psychology and perception by people like Richard Gregory,
who proposed the notion that perception is hypothesis testing,
that the way that we perceive is by confirming or disconfirming hypotheses about the causes of sensory input,
using that sensory input as a test of those hypotheses.
Then ideas be formalized by Geoffrey Hinton, Peter Diane, and colleagues in machine learning,
borrowing ideas from Bayesian probability theory and statistical physics, particularly variation free energy.
And these are the people who formerly I've taken most of the inspiration
for the work that I'm going to be using to illustrate these ideas.
I think this phrase is nice because this notion of an impression fits very comfortably with the notion of this Markov blanket
that acts as a veil, a shroud separating you from the external events that are projecting their impressions upon that blanket or veil.
And your job is to work out what is happening behind the blanket, to try and infer and understand and explain,
in this instance, what caused the shadows on the Markov blanket or the veil.
Just to illustrate that, or to sort of unpack that for those people who are like philosophy in its history,
this is very reminiscent of Plato's allegorical cave, where the notion was that we, or the plebeians at least,
are all prisoners in a cave, and all we see are the shadows of real performers or objects or animates in the real world
being back illuminated from a fire or sunlight here, to produce shadows on the back of the cave.
Now, I think that Plato, no expert in this, but I think he was using this allegorically to explain that if you had a philosopher,
he could kind of explain that to you and you would be enlightened.
However, I think that the metaphor has a deeper meaning in the sense that we are all perpetual, perceptual prisoners
that are contained and imprisoned by a Markov blanket, and I don't know that there is any true enlightenment.
To show that in slightly more formal terms, I'm going to go back to our standard form, our standard hill climbing equation
that must apply to our internal brain states.
And what I can do is actually write that standard form, that equation of motion,
as in terms of the divergence-free and the curl-free component, where I'm expressing the curl-free component
in terms of something called a prediction error.
And I'll explain what a prediction error is in a second.
And what this basically means is we can interpret this sort of maximization of Bayesian model evidence as a minimization of prediction error.
So what's prediction error?
Well, it's just the difference between some sensory impressions here
and the best prediction of those impressions given the internal states.
So if I can find some generating function or mapping of the internal states
to produce the best prediction of the sensory states s here,
the difference between the two will be the prediction error.
And therefore, we can interpret the changes in internal brain states
as trying to minimize the prediction error between what is actually sensed
and what we predict will be sensed.
And in this example, I've shown here the internal states in coding
or representing a howling wolf as a best explanation for this shadow.
It's important to realize that you never know the true causes.
This is a very sweet picture.
In fact, it was a little pussycat.
It wasn't a wolf at all.
However, if you didn't know that, it would never matter.
And in fact, on average, you would be Bayes optimal assuming the cause was a wolf, not a cat.
The point I'm trying to make here is that the predictions, the hypotheses are not necessarily true
and are always fantasies.
And in that sense, the brain is literally a fantastic organ.
It generates fantasies to explain its sensory inputs.
Right, so we haven't spoken about action, but this schematic, I think,
just highlights the simple relationship between action and perception.
What I've just said is that one can interpret this necessary imperative
to maximize model evidence or minimize prediction error
as minimizing the difference between sensations and predictions.
Now, clearly, we can understand that minimization in one of two ways.
It can either be that we're changing the top-down predictions to match the sensory input
and we're going to associate that with perception,
or we can change the sensory samples through action to match the predictions
and we're going to think about that in terms of action.
In other words, active sampling to make our predictions come true.
This will be an equivalent perspective on this underlying dynamic.
And I'm going to try and illustrate that in the last few minutes just by giving you a few examples.
Before I do that, let's just think about the nature of this mapping,
this gene, this generative model or generative mapping from internal expectations
or internal states that encode those expectations and the sensory predictions.
So what I've done here is taken us into the world of hierarchical models or mappings.
My motivation for that is clear that the world is hierarchically composed.
And also, if the internal states recapitulate the causal structure of the hierarchical world,
they should also have a hierarchical anatomy,
and indeed they do with the famous Vanessa and Feldman diagram in the background here.
What I'm trying to illustrate here is a notion of a hierarchical generative model
where in the real world, all these external hidden states, all subject to random fluctuations,
cascade down upon each other with complicated non-linear dynamics
to produce the final sensory input which we actually sample.
And so one example here would be if I needed to generate for a simulation
the retinal sampling of the visual field as I scanned or searched a face,
in order to do that I would need to know the object being scanned,
its reflective and illuminance properties.
I would also need to know the kinetics of the sampling of that object.
So I need to know the wattness and the awareness,
and I have to compose those in a hierarchical and non-linear way
to generate the way that this object is being sampled here,
to actually produce, say, the foveal representation that would then constitute the sensory signals.
And now the idea is to actually understand the internal brain states
as minimising prediction error by inverting that mapping from cause to sensory consequence,
in other words going from sensory consequence on the Markov blanket
back to the causes, back to the expectations that cause those sensations.
And to do it, it's actually quite simple.
One takes the hierarchical model here and simply using this equation,
I think that it's got these two terms as this sort of updating prediction error minimisation
and there's this sort of prediction, the absence of any prediction error
of where the state is going to move to next.
And these two components are essentially modelled in this,
now what has become a hierarchical neural network, implementation of this equation,
are shown in terms of the prediction errors here, driving updates here,
and then the prediction terms here doing the prediction term.
I'm using the terms for these dynamic updates of expectations,
namely prediction and update deliberately.
So for those people who are from machine learning or the engineering community,
you will recognise those as being parts of the Kalman filter.
This is a Kalman filter.
It's a generalised, but it can be rewritten as a Kalman filter,
which is like a linear Bayesian filter.
And they have prediction and update terms to like correction terms
based on the argument or nuance of the prediction given the current states.
And that's precisely what this little scheme does.
So here we have these expectations generating top-down predictions of the level below
and they are compared with the expectations of the level below to form a data prediction error.
And that's set back up the hierarchy to update the expectations at the level above.
So you get this reciprocal message passing or recurrent neural activity
between hierarchical levels all in the service of minimising prediction error.
So what you end up with is a description of your sensory input at the bottom
in terms of hierarchically organised or composed expectations
at different levels of abstraction
that in an internally consistent way minimises prediction error
at every level of the hierarchy.
And that is a simple description of hierarchical predictive coding
or hierarchical Bayesian filtering for linear systems.
That would be a hierarchical Kalman filter.
Intuitively, what we have is ascending prediction errors
from the sensory periphery deep into the brain's hierarchy
with this counter-stream of descending predictions
that are forming the prediction errors and are informed by the prediction errors.
So there's this recurrent circular anatomy here
with these two top-down bottom-up counter-streams
dynamically optimising or minimising our prediction error.
For those of you who didn't quite get that,
let me just go through that idea a bit more heuristically
in the context, say, of eye movement control.
So imagine that we had some visual input coming from the retina
and that's passed up to the lateral geniculate nucleus here
and then it's compared with top-down predictions from the visual cortex.
These form a prediction error that's passed forward to visual cortex
and forms the expectations in visual cortex to provide better predictions
so that the prediction error is eliminated.
Now, before there are top-down predictions, say, before the stimulus arrives,
the prediction error is just the stimulus content.
There's no difference between a classical feed-forward volley of sensory information
and the prediction error because there's no prediction to subtract away.
However, this organisation necessarily eliminates the expression of that prediction error.
So you basically have a transient-devote response, like an ERP,
which has a very related potential, even with a continuous stimulus.
Now, this predictive mechanism is also occurring at the higher hierarchical level.
So this expectation is being revised here by these ascending prediction errors from the LGN,
but they are also being compared, the expectations with top-down predictions,
to form a new prediction error that is then sent high
to revise expectations or beliefs about the causes of sensations higher in the hierarchy.
But again, what about action?
Well, we've just considered visual input here.
What about proprioceptive input from the muscles
controlling the position of the direction of gaze of the eye?
These send sensory signals to the pontine nuclei here.
These could be compared with top-down predictions
to elaborate a proprioceptive prediction error
that could be passed forward to revise our expectations
or beliefs about where we are currently feeling our eye pointing.
However, the important thing here is that these prediction errors
also have the opportunity to couple back to the environment and engage active states.
So these can just actually excite if they say,
ah, the length of this muscle is much longer than the top-down prediction.
That prediction error can be eliminated by contracting the muscle.
So these prediction errors can directly eliminate themselves
by affecting hidden states, real physical states, in the environment.
And all that we've done is describe the classical reflex arc,
where the top-down predictions provide the set point or the reference point
or the equilibrium point for the classical reflex arc
to minimize its proprioceptive prediction errors.
A very simple mechanism. There's nothing magical about this.
We're not saying that somehow the pons knows what we expect to see next.
Well, it does know exactly what it expects to feel next
in a fairly low-dimensional, say, six-ocular motor muscles.
And the brain has very precise predictions about what it expects to feel.
And these predictions can be fulfilled very, very quickly
and very, very efficiently by ocular motor reflexes.
Now, clearly these top-down predictions will be informed
and contextualized by deep hierarchical inference based upon visual input,
but the actual prediction errors minimized by action are proprioceptive
and very, very simple low-level ones.
So all we're saying is that we can understand this basic imperative
to minimize prediction error or maximize model evidence
in terms of the brain as a predictive coding machine
that is equipped with classical reflexes.
This is the fine side of this section before we look at the examples.
I'm showing it just to illustrate that there is an intriguing game
of trying to map those equations and that message passing
on known neuroanatomy and neurophysiology
and trying to associate various populations in the cortical layers
with different roles in terms of expectations or prediction errors
and trying to look at the dynamics in terms of known neuroanatomy.
I won't take you through this other than to say it's a great game
and you'd be very welcome to play it when you get older.
These are illustrations of how the best guess has been evolving
over the recent years from these rather iconic forms here
through a micro-circuit architecture
published last year by Andre Bastos
who tried to conform to known neuroanatomy
in terms of intrinsic connectivity
and then a soon-to-appear embellishment
or a nuancing of the simple circuit in the motor system by stewardship.
It's like doing a jigsaw.
You've got all these constraints and all these known facts
and it's a question of rearranging them
until you satisfy as many constraints as is possible.
In summary, biological agents minimize their average surprise entropy.
They minimize surprise by suppressing prediction error
and this can be reduced by changing predictions
and we're thinking of that in terms of perception.
Prediction error can also be reduced by changing sensations through action
where perception entails recurrent message-passing to optimize predictions
which are made true or by action that obviously minimizes surprise.
So that's the basic idea.
I'm going to close now by just giving you a couple of examples.
One the perceptual domain and the final two in the action domain.
Just to give you an idea of the nature of the inference processes
that one can model using this hierarchical predictive coding scheme
and the next two examples, what happens when you put reflexes
on top of that predictive coding scheme.
So let's come back to our Lorenz Attractor.
This is exactly the same little attractor that I used
for the electrochemical states of the molecules
in this context.
I'm now using the two of the states of this Lorenz Attractor
to modulate the frequency and the amplitude of a synthetic songbird's song
shown here in sonogram format.
But crucially, I'm not just using the amplitude and frequency modulation
from any fixed Lorenz Attractor.
I'm actually slowly changing the shape of this attractor
with another attractor taking two states from that attractor
that moves more slowly and doing that deliberately
to introduce a deep hierarchical structuring
to the unfolding temporal contingencies that are expressed
in terms of the song's chirps here.
So we now have sequences of chirps
but now we have sequences of sequences of chirps
that constitute this bird song.
And if I can, I'll just play that to you and find the...
Can you hear that?
Isn't that pretty?
So that's a Lorenz Attractor that's singing to you.
One more time if we can find it.
The reason I've used that hierarchical structure
is just to illustrate on the next slide
something which some of you will be familiar with in electrophysiology,
namely omission-related responses.
I just wanted to demonstrate that because this system
now has expectations about deep hierarchical structure,
it gets upset and it records prediction errors
when that structure is omitted or violated.
So I'm showing that there by now using that generated bird song
as a stimulus and presenting it to a predictive coding simulated bird
that's trying to recognise the causes of that sequence of inputs.
And those causes are just the states of the high level attractor.
And the reason I'm doing that is that I can omit or terminate the song
after the first say five chirps
and look at the responses in terms of prediction errors.
So I'm not sure whether this will work but here...
That's the percept. It's not quite the same as the stimulus.
One of the chirps is missing but once it's realised the causes
and the dynamics of the way that the stimulus is caused,
then it can fairly faithfully and accurately produce the predictions.
And here's the percept when I abruptly terminate the input.
Now if you were listening carefully, you would hear
you actually heard something after the cessation of the sound
and that's reflected here in terms of the prediction error here.
So the key thing I just wanted to point out here
is that the prediction error to the absence of a sensory input,
namely the emission response here,
is bigger than the prediction error when there is a stimulus
that is not actually perceived.
And I think this is a nice example which is, I repeat,
many of you will be familiar with empirically.
But it's a very nice example both in these simulations
and the empirical examples of the brain as a generative organ,
as a fantastic organ, that you wouldn't get
evoked responses to nothing unless you were predicting something.
You just can't get that.
And it's very simple, very clear evidence of the brain behaving
as if it were a predictive, a little predictive engine or Bayesian engine.
So finally, let me conclude with an illustration of active inference.
The example I'm choosing here is to set up the final slide.
What I've done here is equip this little agent with expectations
or hierarchical beliefs which are called empirical primes,
that whenever the cue, the colour of a cue changes,
it will feel and see its fingers being drawn to the target.
Which means that when the colour does change,
it then confirms the hypothesis that has been a colour change,
that necessarily engages an invisible spring or elastic band.
So it expects to feel and to see its arm reach towards the target.
And that's exactly what happens.
And with this relatively simple setup here,
you can simulate quite gracefully simulated cue reaching movements
using this invisible spring.
It does not exist in the real world,
but it exists in the agent's model of the world.
But remember, the real world is caused by this active state,
this active sampling of the world.
So if it exists in terms of the agent's beliefs,
it also comes to exist in the real world, or effectively so.
And illustrating now a sort of generalised synchrony
is being skewed towards the beliefs of the agent.
I wanted to show you that example,
because what I'm going to do now is make the target invisible
and make the target move.
And I'm going to make the target move in a stereotyped way
to produce handwriting-like behaviour.
And the way that I'm going to do that is just by giving it expectations
that the target will be attracted successively
to these unspable fixed points generated from a heteroclinic cycle.
That's a dynamical systems description.
Also, we can think of this as a central pattern generator
that controls the location of some fixed five fixed points
in a Euclidean space that attracts the arm with this invisible spring
and produces predictions of sensations.
That, when fulfilled, look very much like handwriting behaviour here.
Now, one of the reasons I've chosen to show you this simulation
is that it makes a number of key points about the nature of predictive coding
and the nature of hierarchical inference,
or this interpretation in terms of hierarchical inference.
Notice that these top-down predictions, the descending predictions,
are proprioceptive but they're also providing predictions of visual input.
Which means that we, in principle, could use exactly the same expectations
to explain visual input in the absence of proprioceptive input.
And I can simulate that just by turning down the gain or the calibration
or the precision of the proprioceptive input
but maintaining the visual input.
And if I do that, then I can simulate the sorts of observations
that one would make under action and action observation
in the sense that if this agent sees its hand move but can't feel it,
it's like watching another person's hand move or watching passively action
because it can't feel nor can it emit actions
because the proprioceptive prediction errors have no influence anymore
because I switched off their gain or their precision.
If I now run the simulation under the original context, just generating action,
and then plot the activity of one of these five neural populations here
as a red dot whenever it exceeds its half maximum activity
as a function of where it is in this Euclidean space,
then I get this profile responses under action and this under action observation.
This is a nice metaphor for something called mirror neurons in the brain.
Again, most of you will know what they are if you don't.
It's just the observation electrophysiologically
where there are certain populations that respond coincidentally
to doing a movement and watching somebody else doing the same movement.
And that, I think, again beautifully illustrates the concept that this is trying to speak to,
that these are amodal conceptual representations
producing either proprioceptive movement predictions that cause actual movement
or they could be visual or there could be another modality in and of themselves.
These are schemata, they're contingencies of an amodal sort
that can be engaged either by visual prediction errors
or proprioceptive prediction errors
or they can be used to predict action through reflexes.
That is an interesting perspective
because if you just looked at, say, the response properties of this cell
from the point of view of an electrophysiologist who had discovered
that when the hand was moving or the agent was or the animal was moving
through a particular place in some Euclidean space,
they fired there and nowhere else.
And furthermore, they only fired when moving in the down stroke of the J
as opposed to the up stroke, in other words they have a directional C-lectivity.
You would say a number of things.
You'd say, ah, I've discovered hippocampal place cells.
Oh, ah, I have discovered classical receptive fields
that have both place and direction C-lectivity.
Or you, if you're a motor electrophysiologist, you might say,
ah, now I've found the dynamical correlates,
the central pattern generators underlying this rhythmic movement.
And all of these perspectives would be absolutely correct
and more importantly, all internally consistent
and they're rendered internally consistent in this simulation
because we know that these things are not only predicting
the sensory consequences of movement,
they're actually causing the movement themselves.
So they are true sensory motor predictions.
So I'm going to close with a quote from Helmholt
that captures that notion of actively sampling the environment
in a way that discloses the geometries that we suppose underlie the causal structure.
So each movement we make by which we alter the appearance of objects
should be thought of as an experiment designed to test
whether we have understood correctly the invariant relations of the phenomena before us,
that is their existence in definite spatial relations.
He was very eloquent, wasn't he?
So with that, I'd like to thank all my friends and collaborators
and colleagues whose ideas I've been talking about
and, most of all, you for your attention.
Thank you very much indeed.
APPLAUSE
Go ahead. Yes, I'd love taking questions if it's not too tight.
Are there questions from the buildings?
Thank you.
I'm coming from a complete other direction.
I'm doing cognitive neuroscience, basic neuroscience.
And the small amount I'm actually able to understand
from your talk and I've heard your lecture the second time
now is that you're implying that we should think more
of the brain as a system, as a complex dynamic system,
that's actually an organ to make sense out
of all the sensory input and all the input that it receives.
And I think we're moving into that direction
with electrophysiology and all the research we are doing.
What I would like to ask you is about the implications
for our line of work.
So what could, in our line of research,
what could we do to understand the brain better
to prove your implications and your theories
that you are presenting here?
I mean, practically, I think combining your empirical
electrophysiology with modeling studies,
I think practically, it's a very simple answer.
But if you really want to understand what's going on
and you can generate a little base optimal
or some normative optimal coding scheme
that actually does the job that you're studying,
the processing that you're studying
in a neuraly plausible way, you will there have a formal model
that makes very, very particular specific predictions
both about the dynamics and the specificity
of the evoked responses.
I know it's a tall order, but in many respects,
that's how our empirical standard electrophysiology research
is going, that we're trying to make,
say the dynamic calls and models we heard about
in the introduction, more and more
like the predictive coding, neuraly plausible predictive
coding schemes, purely because it
becomes easier then to interpret certain response
components, say P300 or P1 sort of transient,
in terms of what it might mean computationally under,
say, a predictive coding implementation.
What I didn't say, and I think it's
relevant for the empiricists here,
also the electrophysiologists, is that people like David
Mumford and many, many people, and there's
lots and lots of circumstantial evidence to suggest
that it is the case that if the brain is using some form of Bayesian
filtering, i.e. that's a posh name for predictive coding,
then the prediction errors that are
subject to the Kalman gain or that constitute
the prediction errors in predictive coding
are likely to be encoded by the superficial
pyramidal cells, and that's very important
because it is those cells by their geometry
that predominate in the generation of ERP and RFP signals.
So unlike fMRI where you don't know quite
which population you're looking at and you don't know
whether it's excitatory or inhibitory,
there may well be many more signatures
on specificity in EEG and MEG data
that allow you to get in there.
Another thing which is starting to fascinate people
is that just taking, I think you're a student,
a nicely summarised take-home message
that the brain is a complicated dynamical system.
I don't think anybody would deny that as the case,
and you're absolutely right.
I think we have to understand that complexity
in terms of principles of organisation
that are inferential in nature, that can be cast
either in terms of information theory
or in terms of inferences as I've done here.
But the dynamics of them and the asymmetries
and the structure you get in those complex interactions
tells you a lot, and in particular the reciprocal message
passing and the asymmetries between the differences
in the nature of top-down versus bottom-up signals
in this dynamic context starts to put very interesting
questions to classical characterisations
of the sources of bottom-up and top-down signals
in terms of, say, gamma and beta and in terms
of time-frequency resolved induced responses
in electrophysiology.
So you wouldn't know this unless you'd actually written
down models of this message passing in silico
and thought about them being enacted in vivo
and then thinking about the sorts of things
you'd expect to observe.
So that would be, I mean, it is a tall order,
but we were discussing, oh, there you are,
we were discussing before about the whole point of,
you lot here is a principle, you have all the intellectual
technology and skills available too.
You've got the cognitive neural linguistics,
you've got machine learning, you've got the expertise
in sort of Bayesian modelling and computer science
and the cognitive neuroscience.
So if you can exploit that to make models
of the system working in silico that are biologically grounded,
you should be able to make very strong predictions
about the dynamics you're actually observing
electrophysiologically or with fMRI.
And that's the way we try and do it.
We don't have as many people as you either.
A little bit slow.
Thank you.
Thanks for the wonderful talk.
I was wondering whether, so you said,
we're not gonna learn anything new
and do not have to remember anything.
I don't think you are serious with that
because you want to make predictions,
testable predictions.
On the other hand, I was wondering,
could one use your mathematical formulations
to identify systems that behave the way they should
if they were Markov carpets given the data?
So the non-Bayesian approach, are you also into that?
So identifying areas, for example, in brain activity
that behave like little nuclei like closed systems
given the data you observe?
That's, I hadn't thought about it, it's an excellent idea.
Yeah, in principle, I suppose then,
now thinking about it in response to your question,
but by virtue of the fact that in the simulations,
we had to go straight to graph theory and spectral graph.
Spectral graph, the spectrum here is just a spectrum
of eigenvalues, it's just a way of organizing
the adjacency matrix in a way that discloses
the big structures you're interested in.
So you're absolutely right, there's no reason why one couldn't
in a, use exactly the same spectral graph theoretic
definitions of Markov blankets in connect terms
based upon functional connectivity or DTI data
at certain scales and look for Markov blankets
in bits of the brain.
And certainly theoretically, that would be quite consistent
with the application of the free energy minimization
or the surprise minimization implicit
in the existence of those blankets
in the sense that there are papers showing
that even the dendritic tree can be,
the message passing electrochemical and depolarization wise
in the dendritic tree can be thought of
in terms of Bayesian inference,
whether the tree is trying to model and predict
its presynaptic inputs that represent its external milieu.
And so that has its Markov blanket at the cellular level
and one can imagine the same story,
Markov blankets living inside Markov blankets
right until an economics level.
And indeed that has to be the case.
So for any one system, there is no one Markov blanket.
There are probably uncountable number of Markov blankets
and many of them will be nested within each other
and in principle amenable to empirical analysis.
I have a second remark if I may.
So looking at the Markov blanket,
you showed some simulations of what happens
if you're lesion the sensory states
or if you're lesion the representational states.
So in one of the main tenets of cognitive neuropsychology
is that nothing new comes when you're through a lesion.
The system doesn't really change.
Is that also your impression from,
or is that also your view?
If you change the representational space,
will there be new systems emerging possibly?
Oh, I see.
Again, I hadn't thought about that.
I won't imagine that being the case.
Yes, I mean, I thought you were gonna talk
about paradoxical lesions,
but is it what the simulations didn't emphasize
was the hierarchical structure
and the fact you have to,
this tendency to minimize surprise of free energy
operates over both somatic time in developmental,
say in developmental psychology,
but also in an evolutionary timescale.
And of course, in terms of a form of some conceptual lesion,
you can look at a young, an infant as the product
of a graceful lesion to an adult that doesn't have a hierarchy.
So you would certainly could use that
as a metaphorical model for cognitive decline in aging.
If it indeed is declined,
there are some people who believe it's actually not.
So the reducing the complexity of your models
when they're not necessary could be regarded
as an optimal form of lesioning in the aging brain.
And certainly stuff, certainly not emerges.
It certainly is maintained in that context.
Thank you.
There was a question.
Thanks.
Thank you for this nice talk.
I just had a theoretical question.
So what would happen in the case
that I would be in a room
in which I cannot predict,
not reduce my prediction error anymore?
Meaning that I'm in a white room
and I've seen it from all the different angles
and every next glance that I do,
it would be exactly the same than the one before.
Wouldn't I be able or wouldn't I not perceive
the room at all anymore
if I'm not able to reduce my prediction error?
No, so there are two answers there,
which is a good question,
because it brings up a couple of points.
The expectation, when I said the prediction error
eliminates itself or is self-suppressing, self-destroying.
That destruction leaves the expectation elevated.
So in principle, a Kalman filter would obviously infer
that you'd reached a stationary or a fixed point
and that expectation would be consistent with that.
So the expectation or the belief doesn't decay
just the prediction error.
So technically speaking,
in the absence of any prediction error,
you will have found your optimum belief or expectation
for that stationary environment.
Of course, the deeper question is,
do biological systems ever predict
or do they ever emerge from a stationary fixed point?
And the answer is clearly no.
So by implication,
the one of the most surprising things
for an animate system is stationarity or fixed pointedness.
And one can see that in terms of ambiguous figures
or dioptics, binocular rivalry, for example,
you cannot hold a perception in mind,
an inference in mind for an extended period of time,
if it's an equally accurate competing hypothesis.
So that has a number of interpretations,
but the simplest one is a priori,
you believe things will change.
That becomes such an overriding priori belief
that your expectations about the causes
of a particular stimulus will always change,
even if there is no change in the sensory input.
I think that's generally true.
And then you get into interesting arguments
about exploitation versus exploration,
versus exploitation, various principal explanations
for visual searches, for example.
They're all rest upon the belief
that you will search in a principal and dynamic way.
There is no stationary beliefs underline that behavior.
A very reasonable follow-up question would just be,
if I may, what happens in the other extreme opposite case
so that every time I try to minimize
my prediction error, my sensation is already different.
So I would already have,
and maybe an even higher prediction error
than I had before, because the next glance,
it results in a kind of over-sampling
that the environment is over-sampling
the exploration of the environment in this case.
I think you will not survive in an environment
that provided that level.
I think what you're talking about
is probably an environment where you wouldn't last very long.
Literally.
So if you actually think of a physical environment,
and what normally people ask is,
what about the dark room where you can't see anything
so there's no prediction error,
so you should be perfectly happy.
But you're asking something like a white room here.
But imagine what you're talking about
where nothing is predictable.
And it's not just your beliefs about your skin temperature,
your girlfriend, or your dog.
These are beliefs about your physiological status.
So if you can't predict your heart rate,
you can't predict your blood has morality,
you can't predict your blood pressure,
you're not gonna survive very long in that environment.
So this perspective speaks very much
to the increasing acknowledgement
of the importance of situatedness in cognition.
So embodied cognition,
and certainly the notion of active perception.
So active vision, for example,
being one example of that
in computer science and machine learning.
So that you cannot divorce the system
from the environment in which it is engaging
and exchanging with.
So the environment has to be compatible and predictable,
but also dynamic to support you
as an infant's machine in it.
If you can't infer it,
you will be subject ultimately
to the destruction of that Markov blanket
and you will decay.
I mean, I hope that doesn't happen.
It will happen to us all eventually, but we're trying.
Okay, final question.
I'm, so the framework seems very forward oriented,
but sometimes it seems to me like our system,
in certain cases, reinterprets the past.
So it implements hypotheses in a sense of,
one can call it post-addiction.
In a sense, I think classic examples
are like the Berman effect where you have a tone,
you have a tone in white noise,
you hear tone in white noise,
but if you have a tone, white noise in tone,
you actually, your phenomenological experience
is as a continuous white tone.
That is, how would that fit into your system?
Is it the case that upper levels
have a longer temporal integration fields
or in this discrete time dynamic systems
that have similar integration fields,
but they actually operate over the past
as well rather than being just forward looking?
Well, you've just answered your own question.
I prefer, and I'm familiar with,
and can model the first one.
So as you said, generally what happens is,
perhaps just standing back for a second,
because it's very courtesy to say my framework,
this is your framework.
So when I say you will learn nothing,
it's your job to put your intuitions,
and you've just done that, give a lovely example,
within the framework that is formally constrained
by what has to happen.
And provides a graceful link
between optimal control theory and Kalman filtering
and otopoeesis.
In your case, I would imagine that you would build
or you would appeal to a hierarchical predictive
coding scheme or Kalman-Busey filter,
where exactly as you say,
the higher levels have longer time constants.
They have much more extended temporal integration windows.
So the example I showed here with the two lens attractors
where one was changing the shape of the other.
The only reason that works is that the higher
Lorenz attractor at the higher level of the hierarchy
had much slower dynamics and much more extended
temporal time constants, which means it is representing
in the sense of an expectation,
stuff that transcends and subsumes many events
at the lower level.
So I think what you're saying is that the way that
the dynamics have become absolutely crucial
when you think about the real world implementation,
either empirically or in simulation,
of the real sorts of inferences that we do,
which are not in discrete time.
They have dynamics and they have quantifiable
and very distinct hierarchically separable timescales
to them where each super-order timescale
contextualizes what is happening in the timescale below.
So everything like post-diction,
everything like attentional blink,
I think even planning, even at the level,
or even sort of a lot of neuroinquisites and semantics,
narratives, these all speak to hierarchical
multiple levels of description with increasing
temporal integration windows.
I think that once you try and write that down,
either in simulation or at least theoretically,
a lot of stuff starts to make sense then.
So thank you very much again.
Thank you.
