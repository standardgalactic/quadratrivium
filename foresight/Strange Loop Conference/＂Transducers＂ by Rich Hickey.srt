1
00:00:00,000 --> 00:00:11,000
Transducers. Of course, everything is just some combination of the same ingredients.

2
00:00:11,000 --> 00:00:18,000
The shell is on the outside, the inside, the cheese is in, it's on top, whatever. I'm not claiming any novelty here.

3
00:00:18,000 --> 00:00:29,000
This is just another rearrangement of the same old stuff as usual. But, you know, sometimes the cheese on top, you know, tastes better than when it's inside.

4
00:00:29,000 --> 00:00:43,000
Alright. So, what are transducers? The basic idea is to go and look again at map and filter and see if there's some idea inside of them that could be made more reusable than map and filter.

5
00:00:43,000 --> 00:00:54,000
Because we see map and filter being implemented over and over again in different contexts, right? We have map and filter on collections, we have map and filter on streams, we have map and filter on observables.

6
00:00:54,000 --> 00:01:05,000
We were starting to write map and filter and so on on channels and there was just, there's no sharing here, there's no ability to create reusable things.

7
00:01:05,000 --> 00:01:14,000
So, we want to take the essence out and see if we can reuse them. And the way that we're going to do that is by recasting them as process transformations.

8
00:01:14,000 --> 00:01:30,000
And I'll talk a lot more about that, but that's essentially the entire idea. Recasting the core logic of these, what were sequence processing functions as process transformations and then providing context in which we could host those transformations.

9
00:01:30,000 --> 00:01:40,000
So, when I talk about processes, what am I saying? It's not every kind of process. There are all kinds of processes that cannot be modeled this way, but there are a ton of processes that can, right?

10
00:01:40,000 --> 00:01:56,000
And the critical words here are that if you can model your process as a succession of steps, right? And if you can talk about a step or think about a step as ingesting an input, as taking in or absorbing some input, a single input.

11
00:01:56,000 --> 00:02:08,000
So, something going on, there's an input, we're going to absorb that input into the something going on and proceed. That's the kind of process that we can use transducers on.

12
00:02:08,000 --> 00:02:23,000
And when you think about it that way, building a collection is just one instance of a process with that shape, right? Building a collection is you have the collection so far, you have the new input, and you incorporate the new input into the collection and you keep going, right?

13
00:02:23,000 --> 00:02:36,000
But that's a specialization of the idea. The general idea is the idea of a seeded left reduce of, you know, taking something that you're building up and a new thing and continually building up.

14
00:02:36,000 --> 00:02:47,000
But we want to get away from the idea that the reduction is about creating a particular thing and focus more on it being a process. Some processes build particular things, other processes are infinite.

15
00:02:47,000 --> 00:02:58,000
They just run indefinitely. So, we made up words. Actually, we didn't make up a word. Again, this is actually a word. But why this word?

16
00:02:58,000 --> 00:03:08,000
Well, we think it's related to reduce, and reduce is already a programming word, and it's also already a regular word, and the regular word means to lead back, right?

17
00:03:08,000 --> 00:03:18,000
To bring something back. And we've sort of, the word has come to mean over time to bring something down or to make something smaller.

18
00:03:18,000 --> 00:03:27,000
But it doesn't necessarily mean that. It just means to lead it back to some, you know, mothership, and in this case we're going to say this process that we're trying to accomplish.

19
00:03:27,000 --> 00:03:39,000
The word ingest means to carry something into, so it's the same kind of idea, but that's about one byte, right? Reduction is about a series of things, and ingest itself means one thing.

20
00:03:39,000 --> 00:03:48,000
And transduce means to lead across. And the idea basically is, as we're taking inputs into this reduction, we're going to lead them through a series of transformations.

21
00:03:48,000 --> 00:03:56,000
We're going to carry them across a set of functions. So we're going to be talking about manipulating input during a reduction.

22
00:03:56,000 --> 00:04:07,000
So this is not a programming thing. This is a thing that we do all the time in the real world. We don't call them transducers. We call them instructions, right?

23
00:04:07,000 --> 00:04:15,000
And so we will talk about this scenario through the course of this talk, which is put the baggage on the plane.

24
00:04:15,000 --> 00:04:22,000
And that's the overall thing that we're doing. But I have this transformation I want you to do to the baggage, right?

25
00:04:22,000 --> 00:04:27,000
I want you to, while you're doing it, while you're putting the baggage on the plane, break apart the pallets.

26
00:04:27,000 --> 00:04:34,000
So we're going to have pallets, you know, big, you know, wooden things with a pile of luggage on it that's sort of shrink wrapped.

27
00:04:34,000 --> 00:04:42,000
We want to break them apart, so now we have individual pieces of luggage. We want to smell each bag and see if it smells like food.

28
00:04:42,000 --> 00:04:50,000
If it smells like food, we don't want to put it on the plane. And then we want to take the bags and see if they're heavy, and we want to label them.

29
00:04:50,000 --> 00:04:55,000
Right, that's what you have to do. So we're talking to the luggage handlers, we say, that's what you're going to do.

30
00:04:55,000 --> 00:05:08,000
And they all say, great, I can do that. One of the really important things about the way that was just said and the way you talk to luggage handlers and your kids and anybody else you need to give instructions to,

31
00:05:08,000 --> 00:05:14,000
is that the conveyance and the sources and the sinks of that process are irrelevant.

32
00:05:14,000 --> 00:05:22,000
Right, do the luggage handlers get the bags on a conveyor belt or on a trolley?

33
00:05:22,000 --> 00:05:34,000
We didn't say, we don't care. In fact, we really don't want to care. We don't want to say to the luggage guys today, there's going to be luggage on a trolley, do this to it, and then put it on another trolley.

34
00:05:34,000 --> 00:05:39,000
And then tomorrow when we switch to conveyor belts, have them say, we didn't know what to do.

35
00:05:39,000 --> 00:05:49,000
We came on a conveyor belt and like, I have rules for trolleys.

36
00:05:49,000 --> 00:05:59,000
So the rules don't care, the instructions don't care. This is the real world. Then we have programming. What are we doing programming?

37
00:05:59,000 --> 00:06:06,000
We have collection function composition, we're so cool. We have lists, we have functions from list to list.

38
00:06:06,000 --> 00:06:12,000
So we can compose our functions. We're going to say, well, labeling the heavy bags is like mapping, right?

39
00:06:12,000 --> 00:06:19,000
Every bag comes through and it gets a label or it doesn't. But for every bag that comes through, there's a bag that comes out and maybe it has a label or it doesn't.

40
00:06:19,000 --> 00:06:28,000
And taking out the non-food bags is, or keeping the non-food bags, is a filter. It's analogous to filter.

41
00:06:28,000 --> 00:06:36,000
Is it food? We don't want it. If it's not food, we're going to keep it. So we may or may not have an input depending on this predicate.

42
00:06:36,000 --> 00:06:44,000
And unbuttling the pallets is like map cap. There's some function that, given a pallet, gives you a whole bunch of individual pieces of luggage.

43
00:06:44,000 --> 00:06:51,000
So we already know how to do this. We're done. We're finished. Programming can model the real world.

44
00:06:51,000 --> 00:06:58,000
Except there's a big difference between this and what I just described happens in the real world, right?

45
00:06:58,000 --> 00:07:04,000
Because map is a function from whatever, collection to collection or sequence to sequence or pick your programming language.

46
00:07:04,000 --> 00:07:10,000
But it's basically a function of aggregate to aggregate. And so is filter and so is map cap, right?

47
00:07:10,000 --> 00:07:15,000
And the rules that we have only work on those things. They're not independent of those things.

48
00:07:15,000 --> 00:07:23,000
If we have something new, like a channel or a stream or observable, none of the rules we have apply to that.

49
00:07:23,000 --> 00:07:32,000
And in addition, we have all this in-between stuff. It's as if we said to the luggage guys, take everything off the trolley, trolley, right?

50
00:07:32,000 --> 00:07:39,000
And unbutton the pallet and put it on another trolley, right? And then take it off that trolley and then see if it smells like food.

51
00:07:39,000 --> 00:07:46,000
And if it doesn't, put it on another trolley. And then take it off that trolley. And if it's heavy, put a label on it and put it on another trolley.

52
00:07:46,000 --> 00:07:50,000
This is what we're doing in programming. This is what we do all the time, right?

53
00:07:50,000 --> 00:08:00,000
And we wait for a sufficiently smart supervisor to come and, like, say, what are you guys doing, right?

54
00:08:00,000 --> 00:08:06,000
So we don't want to do this anymore, right? We don't have any reuse, right?

55
00:08:06,000 --> 00:08:11,000
Every time we do this, we end up writing a new thing, right? A new kind of stream. We have a new set of these functions, right?

56
00:08:11,000 --> 00:08:19,000
You invent Rx. Boom. You know, it was 100 functions. We were starting to do this enclosure, right?

57
00:08:19,000 --> 00:08:27,000
We had channels, and we're starting to write map and filter again. So it's time to say, time out. Can we do this?

58
00:08:27,000 --> 00:08:34,000
Because there are two things that happen. One is, all the things we're doing are specific, and the other is, there's a potential inefficiency here, right?

59
00:08:34,000 --> 00:08:40,000
Yeah, maybe there are sufficiently smart compilers, and maybe for some context, they can make the intermediate stuff go away.

60
00:08:40,000 --> 00:08:49,000
Maybe they can. The problem is our initial statement really doesn't like what we normally do. It's not general. It's specific.

61
00:08:49,000 --> 00:08:53,000
We're relying on something else to fix it, right?

62
00:08:53,000 --> 00:08:58,000
We also have this problem, right, where we're going to go from, you know, one kind of conveyance to another.

63
00:08:58,000 --> 00:09:05,000
And now, all of a sudden, well, you know, map is from X to X, and whatever, you know, how do we fix this?

64
00:09:05,000 --> 00:09:10,000
And I know what everybody's thinking, of course.

65
00:09:10,000 --> 00:09:16,000
Yeah.

66
00:09:16,000 --> 00:09:22,000
So, I mean, that may fix some of this, but in general, it doesn't solve the problem.

67
00:09:22,000 --> 00:09:28,000
And the problem is mostly about the fact that we're talking about the entire job, right?

68
00:09:28,000 --> 00:09:36,000
Those instructions, they were about the step. They weren't about the entire job. The entire job was around it.

69
00:09:36,000 --> 00:09:40,000
While you're doing this thing, here's what you're going to do to the inputs.

70
00:09:40,000 --> 00:09:43,000
Here's how you're going to transform them, while you're doing the bigger thing, which could change, right?

71
00:09:43,000 --> 00:09:46,000
We could change from conveyor belts to trolleys and stuff like that.

72
00:09:46,000 --> 00:09:49,000
So we want to just take a different approach, right?

73
00:09:49,000 --> 00:09:57,000
If we have something that's about the steps, we can build things that are about the whole jobs, but not vice versa.

74
00:09:57,000 --> 00:10:04,000
Okay. So, there's just going to be some usages here, and then I'll explain the details in a little bit.

75
00:10:04,000 --> 00:10:08,000
Because usually I do it the opposite way, and people are like, oh, my brain hurt for so long.

76
00:10:08,000 --> 00:10:12,000
And then, like, 40 minutes in, you show me the thing that made it all valuable.

77
00:10:12,000 --> 00:10:16,000
So here's the value proposition, right? We make transducers like this.

78
00:10:16,000 --> 00:10:19,000
We say, I want to make a transducer. I want to make a set of instructions.

79
00:10:19,000 --> 00:10:21,000
I'm going to call it process bags.

80
00:10:21,000 --> 00:10:29,000
I'm going to compose the idea of map catting using unbundled pallet as the function, right?

81
00:10:29,000 --> 00:10:31,000
So I want to unbundle the pallets.

82
00:10:31,000 --> 00:10:35,000
Then I want to filter out the non-food, or keep the non-food, filter out the food.

83
00:10:35,000 --> 00:10:40,000
And I want to map labeling the heavy bags.

84
00:10:40,000 --> 00:10:44,000
And in this case, we're going to compose those functions with comp,

85
00:10:44,000 --> 00:10:47,000
which is Clojure's ordinary function composition thing.

86
00:10:47,000 --> 00:10:53,000
So map catting, filtering, and mapping return transducers.

87
00:10:53,000 --> 00:10:59,000
And process bags, which is the composition of those things, is itself a transducer.

88
00:10:59,000 --> 00:11:02,000
So we're going to call map catting, call filtering, call mapping,

89
00:11:02,000 --> 00:11:07,000
get three transducers, compose them, and make another transducer.

90
00:11:07,000 --> 00:11:14,000
Each transducer takes a process step, or it's reducing function,

91
00:11:14,000 --> 00:11:16,000
and transforms. It changes it a little bit.

92
00:11:16,000 --> 00:11:20,000
It says, before you do that step, do this.

93
00:11:20,000 --> 00:11:24,000
I'll explain why that seems backwards in a little bit.

94
00:11:24,000 --> 00:11:28,000
Having made those instructions, we can go into completely different

95
00:11:28,000 --> 00:11:31,000
Contexts and reuse them.

96
00:11:31,000 --> 00:11:35,000
Amongst the several contexts that we're supporting in Clojure in the first

97
00:11:35,000 --> 00:11:39,000
Version is supporting transducers in intu, and intu is Clojure's

98
00:11:39,000 --> 00:11:42,000
Function that takes a collection and another collection and pours one

99
00:11:42,000 --> 00:11:45,000
Into the other. Instead of having, you know, more

100
00:11:45,000 --> 00:11:48,000
Object-oriented, you know, collections that know how to absorb

101
00:11:48,000 --> 00:11:51,000
Other collections with build from, we just have the standalone

102
00:11:51,000 --> 00:11:53,000
Thing called intu, but it's the same idea.

103
00:11:53,000 --> 00:11:56,000
Your source and destination could be different.

104
00:11:56,000 --> 00:11:59,000
So we want to pour the pallets into the airplane, but we're going to

105
00:11:59,000 --> 00:12:02,000
Take them through this process bags transformation first.

106
00:12:02,000 --> 00:12:05,000
So this is collection building. Intu was already a function in

107
00:12:05,000 --> 00:12:07,000
Clojure. We just added an additional

108
00:12:07,000 --> 00:12:11,000
Arity that takes transducers. Then we have sequence.

109
00:12:11,000 --> 00:12:17,000
Sequence takes some source of stuff and makes a lazy sequence out of it.

110
00:12:17,000 --> 00:12:22,000
Sequence now additionally takes a transducer and will perform

111
00:12:22,000 --> 00:12:26,000
That transformation and all the stuff as it lazily produces results.

112
00:12:26,000 --> 00:12:29,000
So we can get laziness out of this.

113
00:12:29,000 --> 00:12:32,000
There's a function called transduce, which is just like reduce,

114
00:12:32,000 --> 00:12:37,000
Except it also takes a transducer. So that takes a transducer,

115
00:12:37,000 --> 00:12:41,000
An operation, an initial value, and a source.

116
00:12:41,000 --> 00:12:45,000
So the transducer is a modification of process bags.

117
00:12:45,000 --> 00:12:49,000
I'll talk about in a second. The operation is sum.

118
00:12:49,000 --> 00:12:52,000
The initial value is zero and the source of the pallets.

119
00:12:52,000 --> 00:12:58,000
So what does this composition do? What is this going to do?

120
00:12:58,000 --> 00:13:02,000
It's going to sum the weight of the bags. It's the weight of all the bags.

121
00:13:02,000 --> 00:13:05,000
So it's cool. Look, we can take the process that we already had and

122
00:13:05,000 --> 00:13:09,000
Modify it a little bit. We can add weighing the bags at the end of that

123
00:13:09,000 --> 00:13:14,000
Set of instructions and that gives us a number and we can use that number

124
00:13:14,000 --> 00:13:18,000
With plus to build the sum.

125
00:13:18,000 --> 00:13:21,000
So that's transduced. The other thing we can do is go to a

126
00:13:21,000 --> 00:13:24,000
Completely different context now. So we have some channels.

127
00:13:24,000 --> 00:13:27,000
We're going to be sending pallets of luggage across channels.

128
00:13:27,000 --> 00:13:30,000
But they don't really fit. But the idea is there.

129
00:13:30,000 --> 00:13:33,000
This is a very different context. Channels run indefinitely.

130
00:13:33,000 --> 00:13:36,000
You can feed them stuff all the time and get stuff out of the

131
00:13:36,000 --> 00:13:40,000
Other end on a continuous basis. But the critical thing here is

132
00:13:40,000 --> 00:13:43,000
That these things are not parameterized.

133
00:13:43,000 --> 00:13:46,000
They're not, i'm a thing that you can tell me later.

134
00:13:46,000 --> 00:13:50,000
You're going to tell me if it's trolleys or conveyor belts.

135
00:13:50,000 --> 00:13:54,000
This is the exact same process bags i defined here.

136
00:13:54,000 --> 00:13:58,000
This concrete thing being reused in completely different

137
00:13:58,000 --> 00:14:02,000
Context. So this is concrete reuse, not

138
00:14:02,000 --> 00:14:06,000
Parameterization. So we can use transducers on channels.

139
00:14:06,000 --> 00:14:10,000
The channel constructor now optionally takes a transducer and

140
00:14:10,000 --> 00:14:13,000
It will transduce everything that flows through.

141
00:14:13,000 --> 00:14:17,000
It has its own internal processing step and it's going to

142
00:14:17,000 --> 00:14:21,000
Modify its inputs accordingly with the transducer it's given.

143
00:14:21,000 --> 00:14:24,000
It's an open system. I can imagine, but i did not get time

144
00:14:24,000 --> 00:14:28,000
To implement, that you could plug this into rx java trivially

145
00:14:28,000 --> 00:14:32,000
And take half of the rx java functions and throw them away.

146
00:14:32,000 --> 00:14:36,000
Because you can just build a transducer and plug it into one

147
00:14:36,000 --> 00:14:39,000
Observable function that takes an observable and a transducer

148
00:14:39,000 --> 00:14:44,000
And returns an observable. And that's the idea.

149
00:14:44,000 --> 00:14:47,000
So we call all of these things into and sequence and transduce

150
00:14:47,000 --> 00:14:52,000
And transduceable processes. They satisfy the definition of

151
00:14:52,000 --> 00:14:56,000
Process we gave before. And they accept a transducer.

152
00:14:56,000 --> 00:15:00,000
So transducers have two parts. You make functions that create

153
00:15:00,000 --> 00:15:03,000
Transducers and in context where they make sense, you start

154
00:15:03,000 --> 00:15:06,000
Accepting transducers. And then you have these two

155
00:15:06,000 --> 00:15:10,000
Orthogonal legos you can put together. Inside each process,

156
00:15:10,000 --> 00:15:14,000
They're going to take that transducer and their internal

157
00:15:14,000 --> 00:15:17,000
Processing function. So what's the internal processing

158
00:15:17,000 --> 00:15:20,000
Function of into? The thing that adds one thing to a

159
00:15:20,000 --> 00:15:24,000
Collection. In closure, it's called conge for conjoin.

160
00:15:24,000 --> 00:15:29,000
Similarly, inside lazy sequences, there's some

161
00:15:29,000 --> 00:15:32,000
Thunk mechanism that produces a result on demand and then

162
00:15:32,000 --> 00:15:35,000
Waits to produce the next thing. So that has a step inside of it

163
00:15:35,000 --> 00:15:39,000
That can be transformed this way. Channels also take inputs

164
00:15:39,000 --> 00:15:43,000
Somewhere inside channels is a little step function that adds

165
00:15:43,000 --> 00:15:46,000
An input to a buffer. That step function has exactly the

166
00:15:46,000 --> 00:15:50,000
Same shape as conge. And as laziness.

167
00:15:50,000 --> 00:15:54,000
So it can transform its fundamental internal operation.

168
00:15:54,000 --> 00:15:57,000
But the operation remains completely encapsulated.

169
00:15:57,000 --> 00:16:00,000
The transducible context takes the transducer, modifies its

170
00:16:00,000 --> 00:16:05,000
Own step function and proceeds with that.

171
00:16:05,000 --> 00:16:08,000
So as i said before, there's nothing new.

172
00:16:08,000 --> 00:16:12,000
Two papers i find useful for helping you think about these

173
00:16:12,000 --> 00:16:15,000
Things are lectures and construct functional programming

174
00:16:15,000 --> 00:16:18,000
Which is a lot closer to the source of when people started

175
00:16:18,000 --> 00:16:25,000
Thinking about folds and their relationship to lists.

176
00:16:25,000 --> 00:16:29,000
And the second grand paper is a summary paper which summarizes

177
00:16:29,000 --> 00:16:32,000
The current thinking at the time it was written.

178
00:16:32,000 --> 00:16:35,000
So they're both really good. But now i'm going to take you

179
00:16:35,000 --> 00:16:39,000
Through how do we get to this point? How do we think about these things?

180
00:16:39,000 --> 00:16:42,000
So one of the fundamental things that the bird paper and the work

181
00:16:42,000 --> 00:16:45,000
That preceded it talk about is the relationship between these

182
00:16:45,000 --> 00:16:49,000
List processing operations and fold. In fact, there's a lot of

183
00:16:49,000 --> 00:16:53,000
Interesting mathematics that shows that they're the same thing.

184
00:16:53,000 --> 00:16:58,000
That you can go backwards and forwards between a concrete list

185
00:16:58,000 --> 00:17:03,000
And the operations that constructed it. They're sort of isomorphic to each other.

186
00:17:03,000 --> 00:17:07,000
So many of the list functions that we have can be redefined in

187
00:17:07,000 --> 00:17:11,000
Terms of fold. There's the definition of map in several

188
00:17:11,000 --> 00:17:15,000
Talks here, i think. But the traditional definition of

189
00:17:15,000 --> 00:17:19,000
Map says if it's empty, return empty sequence, if you're

190
00:17:19,000 --> 00:17:23,000
Getting a new input, cons that input onto the result of mapping

191
00:17:23,000 --> 00:17:28,000
To the rest of the input. It's recursive and calls itself.

192
00:17:28,000 --> 00:17:31,000
But map does that, filter does that, map cat does that.

193
00:17:31,000 --> 00:17:35,000
They all have these structures. But filter is a little bit different.

194
00:17:35,000 --> 00:17:38,000
It has a predicate inside. It has a conditional branch.

195
00:17:38,000 --> 00:17:42,000
And then it then it recurses in two parts of the branch with different arguments.

196
00:17:42,000 --> 00:17:46,000
So what this work, this earlier work did was say you can think about

197
00:17:46,000 --> 00:17:50,000
All these things as folds. If you do, you get a lot of regularity

198
00:17:50,000 --> 00:17:53,000
And things that you can prove about folds which are now all uniform

199
00:17:53,000 --> 00:17:56,000
Will apply to all these functions that otherwise look a little

200
00:17:56,000 --> 00:17:59,000
Different from each other. So there's a lot of value to this.

201
00:17:59,000 --> 00:18:03,000
Fold encapsulates the recursion. And it's easy to reason about.

202
00:18:03,000 --> 00:18:07,000
If we look at a redefinition of map, it's not often defined this way.

203
00:18:07,000 --> 00:18:11,000
But if we look at a redefinition of map in terms of fold,

204
00:18:11,000 --> 00:18:18,000
Then we say we're going to fold this function that cons is the first thing onto the rest.

205
00:18:18,000 --> 00:18:22,000
And we start with an empty list. So this is fold, fold right.

206
00:18:22,000 --> 00:18:26,000
And we do that over a collection. We can similarly define filter this way.

207
00:18:26,000 --> 00:18:30,000
And what's really interesting about these things is that the fold are the empty list

208
00:18:30,000 --> 00:18:34,000
And the call, that's all boilerplate, right? It's exactly the same.

209
00:18:34,000 --> 00:18:37,000
Map and filter are precisely the same in those things.

210
00:18:37,000 --> 00:18:41,000
All that's different is what's inside the inner function definition.

211
00:18:41,000 --> 00:18:45,000
And even there, there's something the same.

212
00:18:45,000 --> 00:18:49,000
So it ends up that you can similarly redefine these functions

213
00:18:49,000 --> 00:18:53,000
Or define these functions in terms of fold L.

214
00:18:53,000 --> 00:18:56,000
And fold L is just left reduced.

215
00:18:56,000 --> 00:18:59,000
And so here's some what if definitions of map and filter.

216
00:18:59,000 --> 00:19:05,000
And we added map cat that are left folds that use left reduced.

217
00:19:05,000 --> 00:19:08,000
And so the trade off between left reduced and right reduced

218
00:19:08,000 --> 00:19:11,000
Is right reduced sort of puts you on the laziness path

219
00:19:11,000 --> 00:19:13,000
And left reduced puts you on the loop path.

220
00:19:13,000 --> 00:19:17,000
It ends up that the loop path is better and faster and more general

221
00:19:17,000 --> 00:19:19,000
For the kinds of things we want to apply this to.

222
00:19:19,000 --> 00:19:25,000
Especially if we can get laziness later, which I just said we kind of could.

223
00:19:25,000 --> 00:19:28,000
So we like that. So this means we can turn these things into loops.

224
00:19:28,000 --> 00:19:30,000
Because reduced becomes a loop.

225
00:19:30,000 --> 00:19:33,000
But the same thing. We have the boilerplate. We have reduced.

226
00:19:33,000 --> 00:19:38,000
These definitions use vectors, which in closure are like arrays.

227
00:19:38,000 --> 00:19:41,000
But their fundamental conging operation adds at the end.

228
00:19:41,000 --> 00:19:44,000
So this has the same shape I want to talk about for the rest of the talk.

229
00:19:44,000 --> 00:19:47,000
We have something that we're building up, a new input,

230
00:19:47,000 --> 00:19:50,000
And we produce a new thing. And sort of the stuff's coming from the right

231
00:19:50,000 --> 00:19:52,000
And getting added to the right-hand side.

232
00:19:52,000 --> 00:19:56,000
So it just makes more sense here. So these are eager and they return vectors.

233
00:19:56,000 --> 00:19:58,000
But it's the same idea. We're reducing.

234
00:19:58,000 --> 00:20:01,000
We have a function that takes, you know, the vector so far.

235
00:20:01,000 --> 00:20:05,000
And a new value. We're conjoining the new value.

236
00:20:05,000 --> 00:20:09,000
Having applied f to it, right? That's the idea of mapping, right?

237
00:20:09,000 --> 00:20:14,000
There's an idea behind mapping that luggage handlers understand, right?

238
00:20:14,000 --> 00:20:17,000
Put the label on everything that comes through.

239
00:20:17,000 --> 00:20:20,000
It's very general, right? That's mapping.

240
00:20:20,000 --> 00:20:23,000
They get that. We get that. We're all human beings.

241
00:20:23,000 --> 00:20:26,000
We understand the same thing. As programmers, we've mucked this up.

242
00:20:26,000 --> 00:20:29,000
Because look at what's happening here.

243
00:20:29,000 --> 00:20:33,000
Map says there's this fundamental thing that you do to everything as it comes through.

244
00:20:33,000 --> 00:20:37,000
Filter says there's this fundamental tiny thing that you do to everything as it comes through.

245
00:20:37,000 --> 00:20:42,000
And map cat says there's this fundamental tiny thing that you do to everything as it comes through.

246
00:20:42,000 --> 00:20:48,000
What's the problem? Conge.

247
00:20:48,000 --> 00:20:53,000
Conge is basically like saying to the trolley or to the conveyor belt, right?

248
00:20:53,000 --> 00:21:01,000
It's something about the outer job that's leaked or it's inside the middle of the idea.

249
00:21:01,000 --> 00:21:05,000
Inside the middle of the idea of mapping is this conge.

250
00:21:05,000 --> 00:21:10,000
It does not belong. Inside the middle of the idea of filter is this conge.

251
00:21:10,000 --> 00:21:13,000
It shouldn't be there. Same thing with map cat.

252
00:21:13,000 --> 00:21:18,000
This is specific stuff in the middle of a general idea.

253
00:21:18,000 --> 00:21:21,000
The general idea is just take stuff out.

254
00:21:21,000 --> 00:21:25,000
We don't want to know about conge. Maybe we want to do something different.

255
00:21:25,000 --> 00:21:28,000
So again, we have a lot of boilerplate. We have these essences.

256
00:21:28,000 --> 00:21:32,000
And the other critical thing is the essences can be expressed as reducing functions.

257
00:21:32,000 --> 00:21:36,000
Each of these little inner functions is exactly the same shape as conge.

258
00:21:36,000 --> 00:21:41,000
It takes a result so far and a new input returns the next result.

259
00:21:41,000 --> 00:21:47,000
So to turn those inner functions into transducers,

260
00:21:47,000 --> 00:21:51,000
we're just going to parameterize that conge, right?

261
00:21:51,000 --> 00:21:56,000
We're going to parameterize the old-fashioned way with the function argument.

262
00:21:56,000 --> 00:21:59,000
Anything higher order, blah, blah, blah.

263
00:21:59,000 --> 00:22:02,000
We're going to take an argument, which is the step.

264
00:22:02,000 --> 00:22:06,000
So right in the middle body of this mapping...

265
00:22:07,000 --> 00:22:10,000
You can't see my cursor.

266
00:22:10,000 --> 00:22:13,000
Right in the middle body, this is the same as it was on the last slide.

267
00:22:13,000 --> 00:22:16,000
This is where it said conge. Now we say step.

268
00:22:16,000 --> 00:22:20,000
We put that inside a function that takes the step.

269
00:22:20,000 --> 00:22:22,000
So this is a function.

270
00:22:22,000 --> 00:22:26,000
Mapping takes the thing that you're going to map, you know, label the baggage.

271
00:22:26,000 --> 00:22:30,000
And it returns something that is a function that expects a step.

272
00:22:30,000 --> 00:22:32,000
What are we doing? Putting stuff on conveyor belts.

273
00:22:32,000 --> 00:22:35,000
What are we doing? We're putting stuff on trolleys.

274
00:22:35,000 --> 00:22:42,000
Okay? And it says, before I do that, I'm going to call f on the luggage.

275
00:22:42,000 --> 00:22:44,000
I'm going to put a label on the luggage.

276
00:22:44,000 --> 00:22:46,000
But I don't know about luggage anymore.

277
00:22:46,000 --> 00:22:48,000
The step you're going to tell me later. What are we doing today?

278
00:22:48,000 --> 00:22:51,000
Conveyor belts or trolleys? Conveyor belts. Cool.

279
00:22:51,000 --> 00:22:56,000
I got the rules. I understand how to do mapping and filtering and map catting.

280
00:22:56,000 --> 00:22:58,000
So same thing, filter.

281
00:22:58,000 --> 00:23:00,000
And what's beautiful about this is what's the essence of filtering.

282
00:23:00,000 --> 00:23:04,000
Apply a predicate, then maybe you do the step, or maybe you don't.

283
00:23:04,000 --> 00:23:07,000
There's no stuff here, right? It's a choice about activity.

284
00:23:07,000 --> 00:23:12,000
It's a choice about action. Same thing with concatenate, cat.

285
00:23:12,000 --> 00:23:15,000
What does it do? It basically says, do the step more than once.

286
00:23:15,000 --> 00:23:18,000
I'm giving you an input that's really a set of things.

287
00:23:18,000 --> 00:23:23,000
Do it to each thing. And map catting is just composing

288
00:23:23,000 --> 00:23:27,000
Mapping cat, which it should be.

289
00:23:27,000 --> 00:23:32,000
Okay. So we can take these transducer returning functions.

290
00:23:32,000 --> 00:23:36,000
So mapping returns a transducer, filtering returns a transducer,

291
00:23:36,000 --> 00:23:41,000
cat is a transducer, and map catting returns a transducer.

292
00:23:41,000 --> 00:23:44,000
And we can then plug them into the code we saw before.

293
00:23:44,000 --> 00:23:48,000
Like, how could we define map now that we've made mapping into this abstract thing

294
00:23:48,000 --> 00:23:52,000
that doesn't really know about lists or vectors anymore?

295
00:23:52,000 --> 00:23:55,000
And what we do is we just call mapping. That gives us a transducer.

296
00:23:55,000 --> 00:24:00,000
It says, if you give me a step function, I'll modify it to do F first on the input.

297
00:24:00,000 --> 00:24:04,000
And we say, okay, here's the step function, conge.

298
00:24:04,000 --> 00:24:07,000
Now I rebuilt the functions I had before.

299
00:24:07,000 --> 00:24:11,000
Except conge is not inside mapping and filtering and map catting anymore.

300
00:24:11,000 --> 00:24:15,000
It's an argument. Woo-hoo!

301
00:24:15,000 --> 00:24:19,000
We now have the essence of these things, a la carte.

302
00:24:19,000 --> 00:24:21,000
And that's the point.

303
00:24:21,000 --> 00:24:24,000
Transducers are fully decoupled.

304
00:24:24,000 --> 00:24:26,000
They don't know what they're doing.

305
00:24:26,000 --> 00:24:28,000
They don't know what process they're modifying.

306
00:24:28,000 --> 00:24:31,000
The step function is completely encapsulated.

307
00:24:31,000 --> 00:24:33,000
They have some freedom.

308
00:24:33,000 --> 00:24:37,000
They can call the step function, not at all, once exactly per input

309
00:24:37,000 --> 00:24:39,000
or more than once per input.

310
00:24:39,000 --> 00:24:42,000
But they don't really know what it does, so that's what they're limited to doing,

311
00:24:42,000 --> 00:24:44,000
using it or not using it.

312
00:24:44,000 --> 00:24:46,000
That's pretty much it.

313
00:24:46,000 --> 00:24:48,000
Except they do have access to the input.

314
00:24:48,000 --> 00:24:51,000
So when we said map cat, unbundled pallet,

315
00:24:51,000 --> 00:24:54,000
the function we're supplying there is something that knows about pallets.

316
00:24:54,000 --> 00:24:56,000
It doesn't know about conveyor belts.

317
00:24:56,000 --> 00:24:59,000
It doesn't know what the overall job is, but it knows about pallets,

318
00:24:59,000 --> 00:25:04,000
and it's going to know how to turn a pallet into a set of pieces of luggage.

319
00:25:04,000 --> 00:25:07,000
There's a critical thing about how they use that step function that they've been passed,

320
00:25:07,000 --> 00:25:10,000
and it goes back to that successor notion I mentioned before.

321
00:25:10,000 --> 00:25:16,000
They must pass the previous result from calling the step function

322
00:25:16,000 --> 00:25:20,000
as the next first argument to the next call to the step function.

323
00:25:20,000 --> 00:25:25,000
That is the rule for step functions and their use, and no others.

324
00:25:25,000 --> 00:25:29,000
They can transform the input argument, the second argument.

325
00:25:29,000 --> 00:25:33,000
So let's talk a little bit about the backwards part,

326
00:25:33,000 --> 00:25:35,000
because this is a frequent question I get.

327
00:25:35,000 --> 00:25:37,000
What did you do?

328
00:25:37,000 --> 00:25:39,000
Does transducers change comp?

329
00:25:39,000 --> 00:25:41,000
That is the first thing.

330
00:25:41,000 --> 00:25:43,000
They ruin comp or something like that.

331
00:25:43,000 --> 00:25:46,000
So what we have to do is look at what transducers do.

332
00:25:46,000 --> 00:25:53,000
A transducer function takes a function, wraps it, and returns a new step function.

333
00:25:53,000 --> 00:25:56,000
That is still happening right to left.

334
00:25:56,000 --> 00:25:59,000
This is ordinary comp, and it works right to left.

335
00:25:59,000 --> 00:26:02,000
So mapping gets run first.

336
00:26:02,000 --> 00:26:07,000
We're going to have some operation, you know, put stuff on a trolley or conge.

337
00:26:07,000 --> 00:26:10,000
Mapping will be the first thing that happens.

338
00:26:10,000 --> 00:26:14,000
It's going to make a little modified step that labels the heavy bags

339
00:26:14,000 --> 00:26:17,000
before it calls, put it on the airplane.

340
00:26:17,000 --> 00:26:19,000
Then filtering gets called.

341
00:26:19,000 --> 00:26:21,000
It does go right to left.

342
00:26:21,000 --> 00:26:25,000
That step, I'll make you a new step that first sees if it's food.

343
00:26:25,000 --> 00:26:28,000
If it's food, I'm going to throw it away.

344
00:26:28,000 --> 00:26:30,000
If it's not food, I'm going to use it.

345
00:26:30,000 --> 00:26:34,000
Then map catting runs, or the result of map catting runs.

346
00:26:34,000 --> 00:26:38,000
And that says, give me a step, and I will take its input,

347
00:26:38,000 --> 00:26:40,000
presume it's a pallet, unbundle it,

348
00:26:40,000 --> 00:26:43,000
and supply each of those arguments to the nested thing.

349
00:26:43,000 --> 00:26:47,000
So the composition of the transformers runs right to left.

350
00:26:47,000 --> 00:26:51,000
But it builds a transformation step that runs in the order

351
00:26:51,000 --> 00:26:54,000
that they appear, left to right, in the comp.

352
00:26:54,000 --> 00:26:56,000
In other words, comp is working ordinarily.

353
00:26:56,000 --> 00:26:58,000
It's building steps right to left.

354
00:26:58,000 --> 00:27:02,000
The resulting step runs the transformations left to right.

355
00:27:02,000 --> 00:27:06,000
So when we actually run this, we'll unbundle the pallets first,

356
00:27:06,000 --> 00:27:09,000
call the next step, which is to get rid of the food,

357
00:27:09,000 --> 00:27:11,000
call the next step, which is to label the heavy bags.

358
00:27:11,000 --> 00:27:14,000
So that's why it looks backwards.

359
00:27:14,000 --> 00:27:18,000
Okay, so the other nice thing about transducers is that there's

360
00:27:18,000 --> 00:27:20,000
no intermediate stuff.

361
00:27:20,000 --> 00:27:22,000
They're just a stack of function calls.

362
00:27:22,000 --> 00:27:23,000
They're short.

363
00:27:23,000 --> 00:27:25,000
Potentially they could be inlined.

364
00:27:25,000 --> 00:27:27,000
There's no laziness overhead.

365
00:27:27,000 --> 00:27:28,000
There's no laziness required.

366
00:27:28,000 --> 00:27:30,000
There's no laziness utilized.

367
00:27:30,000 --> 00:27:32,000
There's no interim collections.

368
00:27:32,000 --> 00:27:34,000
We're not going to have you make everything into a list.

369
00:27:34,000 --> 00:27:36,000
So you can say an empty list is nothing.

370
00:27:36,000 --> 00:27:38,000
Now, nothing is nothing.

371
00:27:38,000 --> 00:27:40,000
Empty list is an empty list.

372
00:27:40,000 --> 00:27:41,000
And one thing is one thing.

373
00:27:41,000 --> 00:27:43,000
A list of one thing is a list of one thing.

374
00:27:43,000 --> 00:27:46,000
And these are not the same.

375
00:27:46,000 --> 00:27:49,000
So you use the step function or you don't.

376
00:27:49,000 --> 00:27:52,000
And there's no extra boxes required of boxing for communicating

377
00:27:52,000 --> 00:27:55,000
about the mechanism.

378
00:27:55,000 --> 00:27:59,000
So the other thing that was sort of interesting was,

379
00:27:59,000 --> 00:28:02,000
sorry to talk about transducers and a lot of people in Haskell

380
00:28:02,000 --> 00:28:04,000
were trying to figure out what the actual types were

381
00:28:04,000 --> 00:28:07,000
because I had a shorthand in my blog post.

382
00:28:07,000 --> 00:28:10,000
And I'm not going to get into that right now.

383
00:28:10,000 --> 00:28:14,000
Except to say that I think it's a very interesting type problem

384
00:28:14,000 --> 00:28:18,000
and I'm very excited to see how people do with it

385
00:28:18,000 --> 00:28:20,000
in their various languages.

386
00:28:20,000 --> 00:28:23,000
I've seen results that were sort of, it works pretty well to,

387
00:28:23,000 --> 00:28:26,000
and types are, you know, these types are killing me.

388
00:28:26,000 --> 00:28:29,000
Depending on whether the user's type system could deal with it.

389
00:28:29,000 --> 00:28:33,000
But let's just try to capture what we know so far graphically.

390
00:28:33,000 --> 00:28:35,000
And somebody who reviewed these slides for me said

391
00:28:35,000 --> 00:28:37,000
these should have been subscripts,

392
00:28:37,000 --> 00:28:41,000
computers are so hard to use I couldn't switch them in time.

393
00:28:41,000 --> 00:28:43,000
So they're superscripts.

394
00:28:43,000 --> 00:28:47,000
But the idea is that if you're trying to produce the next process

395
00:28:47,000 --> 00:28:53,000
n, you must supply the result from step n minus one as the input.

396
00:28:53,000 --> 00:28:57,000
If you try to model this in your type system saying r to r,

397
00:28:57,000 --> 00:28:59,000
that's wrong, right?

398
00:28:59,000 --> 00:29:02,000
Because I can call the step function five times

399
00:29:02,000 --> 00:29:05,000
and then on the sixth time take the return value from the first time

400
00:29:05,000 --> 00:29:08,000
and pass it as the first thing. That's wrong.

401
00:29:08,000 --> 00:29:11,000
So you ought to make your type system make that wrong.

402
00:29:11,000 --> 00:29:13,000
So figure that out.

403
00:29:13,000 --> 00:29:17,000
Also, if you make the black box and the black box the same thing,

404
00:29:17,000 --> 00:29:20,000
that's also arbitrarily restrictive, right?

405
00:29:20,000 --> 00:29:23,000
You can have a state machine that every time it was given x,

406
00:29:23,000 --> 00:29:26,000
returned y, every time it was given y, returned z,

407
00:29:26,000 --> 00:29:28,000
every time it was given z, returned x.

408
00:29:28,000 --> 00:29:30,000
That's a perfectly valid step function.

409
00:29:30,000 --> 00:29:33,000
It has three separate input types and three separate output types

410
00:29:33,000 --> 00:29:35,000
that only happen at particular times.

411
00:29:35,000 --> 00:29:37,000
There's nothing wrong with that state machine.

412
00:29:37,000 --> 00:29:39,000
It is a perfectly fine reducing function.

413
00:29:39,000 --> 00:29:43,000
It may be tough to model in a type system.

414
00:29:43,000 --> 00:29:46,000
And don't say x or y or z, because it doesn't take x or y or z

415
00:29:46,000 --> 00:29:48,000
and return x or y or z.

416
00:29:48,000 --> 00:29:51,000
When it's given x, it only returns y. It never returns z.

417
00:29:51,000 --> 00:29:57,000
So it seems like a good project for the bar later on.

418
00:29:57,000 --> 00:30:00,000
But the thing that we're capturing here is that the new step function

419
00:30:00,000 --> 00:30:02,000
might take a different kind of input.

420
00:30:02,000 --> 00:30:04,000
It might take a b instead of an a.

421
00:30:04,000 --> 00:30:06,000
Our first step does that.

422
00:30:06,000 --> 00:30:09,000
It takes a palette and returns a set of pieces of luggage,

423
00:30:09,000 --> 00:30:13,000
but each step returns a piece of luggage.

424
00:30:13,000 --> 00:30:15,000
Okay.

425
00:30:15,000 --> 00:30:20,000
So there are other interesting things that happen in processes, right?

426
00:30:20,000 --> 00:30:23,000
Ordinary reduction processes everything.

427
00:30:23,000 --> 00:30:26,000
But we want this to be usable in cases that run arbitrarily long.

428
00:30:26,000 --> 00:30:29,000
We're not just talking about turning one kind of collection

429
00:30:29,000 --> 00:30:31,000
into another kind of collection, right?

430
00:30:31,000 --> 00:30:33,000
A transducer that's running on a channel

431
00:30:33,000 --> 00:30:35,000
has got an arbitrary amount of stuff coming through.

432
00:30:35,000 --> 00:30:38,000
A transducer on an event stream has an arbitrary amount of stuff coming through.

433
00:30:38,000 --> 00:30:41,000
But sometimes you want, you know, either the reducing process

434
00:30:41,000 --> 00:30:44,000
or somebody who says, whoa, I have had enough.

435
00:30:44,000 --> 00:30:46,000
I don't want to see any more input.

436
00:30:46,000 --> 00:30:48,000
We're done. I want to say we're done now,

437
00:30:48,000 --> 00:30:50,000
even though you may have more input.

438
00:30:50,000 --> 00:30:52,000
So we're going to call that early termination.

439
00:30:52,000 --> 00:30:54,000
And it may be desired by the process itself,

440
00:30:54,000 --> 00:30:56,000
like the thing at the bottom.

441
00:30:56,000 --> 00:30:59,000
Or it may be a function of one of the steps.

442
00:30:59,000 --> 00:31:02,000
One of the steps may say, you know what, that's all I was supposed to do.

443
00:31:02,000 --> 00:31:05,000
And so I don't want to see any more input.

444
00:31:05,000 --> 00:31:07,000
And the example here will be, you know,

445
00:31:07,000 --> 00:31:09,000
we're going to modify our instructions and say,

446
00:31:09,000 --> 00:31:11,000
if the bag is ticking, you're finished.

447
00:31:11,000 --> 00:31:13,000
Go home.

448
00:31:13,000 --> 00:31:15,000
We're done loading the plane.

449
00:31:15,000 --> 00:31:17,000
So we're going to add that.

450
00:31:17,000 --> 00:31:19,000
Taking while.

451
00:31:19,000 --> 00:31:21,000
Taking while non-ticking.

452
00:31:21,000 --> 00:31:24,000
And taking while non-ticking needs to stop the whole job in the middle.

453
00:31:24,000 --> 00:31:26,000
It doesn't matter if there's more stuff on the trolley.

454
00:31:26,000 --> 00:31:28,000
When it's ticking, we're finished.

455
00:31:28,000 --> 00:31:30,000
Okay?

456
00:31:30,000 --> 00:31:32,000
So how do we do that?

457
00:31:32,000 --> 00:31:34,000
It ends up in closure.

458
00:31:34,000 --> 00:31:36,000
We already have support for this idea in reduced.

459
00:31:36,000 --> 00:31:40,000
There's a constructor of a special, you know,

460
00:31:40,000 --> 00:31:46,000
wrapper object called reduced, which says this represents the end of the...

461
00:31:46,000 --> 00:31:48,000
It just says, I don't want to see any more input.

462
00:31:48,000 --> 00:31:50,000
Here's what I've come up with so far.

463
00:31:50,000 --> 00:31:52,000
And don't give me any more input.

464
00:31:52,000 --> 00:31:54,000
There's a predicate called reduced question mark

465
00:31:54,000 --> 00:31:57,000
that allows you to ask if something is in this wrapper.

466
00:31:57,000 --> 00:32:01,000
And there's a way to unwrap the thing and look at what's in it.

467
00:32:01,000 --> 00:32:03,000
So you can say, you know, is the reduced thing reduced?

468
00:32:03,000 --> 00:32:05,000
That will always return true.

469
00:32:05,000 --> 00:32:07,000
And you can de-wrap a reduced thing and get the thing.

470
00:32:07,000 --> 00:32:09,000
That's inside it.

471
00:32:09,000 --> 00:32:11,000
This is not the same thing as maybe, right?

472
00:32:11,000 --> 00:32:15,000
Because maybe also wraps the other things that are not reduced, right?

473
00:32:15,000 --> 00:32:19,000
Or either, or all those other boxy kind of things.

474
00:32:19,000 --> 00:32:21,000
So we don't do that.

475
00:32:21,000 --> 00:32:25,000
We only wrap when we're doing this special termination.

476
00:32:25,000 --> 00:32:30,000
So like reduce, transducers also must support reduced.

477
00:32:30,000 --> 00:32:35,000
That means that the step functions are allowed to return a reduced value.

478
00:32:35,000 --> 00:32:41,000
And that if a transducing process or a transducer gets a reduced value,

479
00:32:41,000 --> 00:32:44,000
it must never call the step function with input again.

480
00:32:44,000 --> 00:32:46,000
That's the rule.

481
00:32:46,000 --> 00:32:49,000
Again, implement the rule in your type system, have at it.

482
00:32:49,000 --> 00:32:51,000
But that's the rule.

483
00:32:51,000 --> 00:32:53,000
So now we can look at the insides of taking while.

484
00:32:53,000 --> 00:32:55,000
It takes a predicate.

485
00:32:55,000 --> 00:32:57,000
It takes a step that it's going to modify.

486
00:32:57,000 --> 00:32:59,000
It runs the predicate on the input.

487
00:32:59,000 --> 00:33:03,000
If it's okay, it runs the step.

488
00:33:03,000 --> 00:33:06,000
If it's not okay, it takes what has been built up so far and says,

489
00:33:06,000 --> 00:33:09,000
we're finished, reduced result.

490
00:33:09,000 --> 00:33:11,000
That's how we bail out.

491
00:33:11,000 --> 00:33:15,000
But notice the ordinary result is not in a wrapper.

492
00:33:15,000 --> 00:33:18,000
And so the reducing processes must also play this game, right?

493
00:33:18,000 --> 00:33:21,000
The transducer has to follow the rule from before.

494
00:33:21,000 --> 00:33:24,000
And a reducing process similarly has to support reduced.

495
00:33:24,000 --> 00:33:29,000
If it ever sees a reduced thing, it must never supply input again.

496
00:33:29,000 --> 00:33:33,000
The dereference value is the final accumulated value.

497
00:33:33,000 --> 00:33:36,000
But the final accumulated value is still subject to completion,

498
00:33:36,000 --> 00:33:38,000
which I'm going to talk about in a second.

499
00:33:38,000 --> 00:33:41,000
So there's a rule for the transducers as well.

500
00:33:41,000 --> 00:33:43,000
They have to follow this rule.

501
00:33:43,000 --> 00:33:47,000
So now we get new pictorial types in the graphical type language.

502
00:33:47,000 --> 00:33:50,000
That is Omnigraphil.

503
00:33:50,000 --> 00:33:56,000
So we can have, you know, a process, right,

504
00:33:56,000 --> 00:34:01,000
that takes some black box at the prior step and an input

505
00:34:01,000 --> 00:34:03,000
and returns a black box at the next step.

506
00:34:03,000 --> 00:34:08,000
Or maybe, right, it returns a reduced version of that.

507
00:34:08,000 --> 00:34:10,000
So one of those two things can happen.

508
00:34:10,000 --> 00:34:12,000
Or vertical bars, or.

509
00:34:12,000 --> 00:34:16,000
And it returns another step function that similarly can take

510
00:34:16,000 --> 00:34:19,000
a different kind of input, a black box, returns a black box,

511
00:34:19,000 --> 00:34:22,000
or reduced black box.

512
00:34:22,000 --> 00:34:26,000
Same rules about successorship apply.

513
00:34:26,000 --> 00:34:28,000
All right.

514
00:34:28,000 --> 00:34:32,000
So some interesting sequence functions require state.

515
00:34:32,000 --> 00:34:34,000
And in the purely functional implementations,

516
00:34:34,000 --> 00:34:38,000
they get to use the stack or laziness to put that state.

517
00:34:38,000 --> 00:34:42,000
They get somewhere in the execution machinery,

518
00:34:42,000 --> 00:34:44,000
a place to put stuff.

519
00:34:44,000 --> 00:34:47,000
Now we're saying, I don't want to be in the business of specifying

520
00:34:47,000 --> 00:34:55,000
if we're lazy or not lazy or recursive.

521
00:34:55,000 --> 00:34:58,000
I'm not going to give you space inside the execution strategy

522
00:34:58,000 --> 00:35:01,000
because I'm trying to keep the execution strategy from you.

523
00:35:01,000 --> 00:35:04,000
And that means that state has to be explicit when you have transducers.

524
00:35:04,000 --> 00:35:07,000
Each transducer that needs state must create it.

525
00:35:07,000 --> 00:35:11,000
So examples of sequence functions that need state are take, partition,

526
00:35:11,000 --> 00:35:13,000
all partition by, and things like that.

527
00:35:13,000 --> 00:35:17,000
They're counting or accumulating some stuff to spit it out later.

528
00:35:17,000 --> 00:35:19,000
Where's that going to go?

529
00:35:19,000 --> 00:35:21,000
And it has to go inside the transducer object.

530
00:35:21,000 --> 00:35:23,000
They have to make state.

531
00:35:23,000 --> 00:35:25,000
And there's some rules about that.

532
00:35:25,000 --> 00:35:28,000
If you need state as a transducer author, you have to create it

533
00:35:28,000 --> 00:35:31,000
every time uniquely, and again, every time you're asked to transform

534
00:35:31,000 --> 00:35:33,000
a step function.

535
00:35:33,000 --> 00:35:37,000
So a new, you're going to create state every time you transform a step function.

536
00:35:37,000 --> 00:35:40,000
That means that if you build up a transducer stack,

537
00:35:40,000 --> 00:35:44,000
which are stateful transducers, and you apply it,

538
00:35:44,000 --> 00:35:47,000
not when you build it, no state exists then.

539
00:35:47,000 --> 00:35:49,000
After you call it comp, there's no state.

540
00:35:49,000 --> 00:35:53,000
When you've applied it, you now have a new process step.

541
00:35:53,000 --> 00:35:56,000
But as we should be thinking about all transducer process steps,

542
00:35:56,000 --> 00:36:00,000
including the ones at the bottom, that may be stateful.

543
00:36:00,000 --> 00:36:06,000
You don't know that the very bottom process isn't launched stuff into space.

544
00:36:06,000 --> 00:36:10,000
So you should always treat an applied transducer stack as if it

545
00:36:10,000 --> 00:36:14,000
returned a stateful process, which means you shouldn't alias it.

546
00:36:14,000 --> 00:36:17,000
What ends up happening in practice is all of the transducable

547
00:36:17,000 --> 00:36:20,000
processes, they do the applying.

548
00:36:20,000 --> 00:36:22,000
It's not in the user's hands to do it.

549
00:36:22,000 --> 00:36:27,000
You pass around a transducer and input to the job, to the job.

550
00:36:27,000 --> 00:36:30,000
The job applies the transducer to its process,

551
00:36:30,000 --> 00:36:34,000
gets a fresh set of state when it does that, and there's no harm.

552
00:36:34,000 --> 00:36:37,000
But you do have to do this by convention.

553
00:36:37,000 --> 00:36:40,000
So here's an example of a stateful transducer dropping

554
00:36:40,000 --> 00:36:42,000
while a predicate is true.

555
00:36:42,000 --> 00:36:45,000
So we start with our flag that says it's true.

556
00:36:45,000 --> 00:36:47,000
As long as it's still true, we're going to drop.

557
00:36:47,000 --> 00:36:51,000
When we see that it's not true, we're going to reset it and

558
00:36:51,000 --> 00:36:53,000
continue with applying the step.

559
00:36:53,000 --> 00:36:56,000
And then from then on forward, we're going to apply the step.

560
00:36:56,000 --> 00:37:01,000
So that is not the prettiest thing.

561
00:37:01,000 --> 00:37:03,000
I talked before about completion.

562
00:37:03,000 --> 00:37:05,000
So we have the idea of early termination.

563
00:37:05,000 --> 00:37:08,000
The other idea that transducer support is completion, which is

564
00:37:08,000 --> 00:37:12,000
that at the end of input, which may not happen, there'll be

565
00:37:12,000 --> 00:37:14,000
plenty of jobs that don't complete.

566
00:37:14,000 --> 00:37:16,000
They don't have ends.

567
00:37:16,000 --> 00:37:19,000
They're not consuming a finite thing like a collection.

568
00:37:19,000 --> 00:37:22,000
They're processing everything that comes through a channel or

569
00:37:22,000 --> 00:37:24,000
everything that comes through an event source.

570
00:37:24,000 --> 00:37:26,000
There's no end.

571
00:37:26,000 --> 00:37:28,000
But for things that have an end, there's a notion of

572
00:37:28,000 --> 00:37:33,000
completion, which is to say, if either the innermost process

573
00:37:33,000 --> 00:37:37,000
step wants to do something finally when everything's

574
00:37:37,000 --> 00:37:39,000
finished, they can.

575
00:37:39,000 --> 00:37:41,000
Or if any of the transducers have some flushing they need to

576
00:37:41,000 --> 00:37:43,000
do, they can do it.

577
00:37:43,000 --> 00:37:46,000
So the process may want to do a final transformation on the

578
00:37:46,000 --> 00:37:47,000
output.

579
00:37:47,000 --> 00:37:51,000
Any stateful transducer, in particular, a transducer like

580
00:37:51,000 --> 00:37:56,000
partition, it's aggregating to return aggregates.

581
00:37:56,000 --> 00:37:59,000
You say partition five, and it collects five things and spits

582
00:37:59,000 --> 00:38:00,000
it out.

583
00:38:00,000 --> 00:38:02,000
If you say we're done, it's got three things.

584
00:38:02,000 --> 00:38:04,000
It wants to spit out the three things.

585
00:38:04,000 --> 00:38:08,000
But you need to be able to tell it we exhausted input.

586
00:38:08,000 --> 00:38:10,000
In order to do that, the way that's implemented in the

587
00:38:10,000 --> 00:38:13,000
closure implementation of transducers is that all the

588
00:38:13,000 --> 00:38:15,000
step functions must have a second operation.

589
00:38:15,000 --> 00:38:19,000
So there's the operation that takes a new input and the

590
00:38:19,000 --> 00:38:23,000
accumulated value so far and returns a new accumulated value

591
00:38:23,000 --> 00:38:24,000
or whatever.

592
00:38:24,000 --> 00:38:26,000
I mean, it's up to the process what the meaning of the black

593
00:38:26,000 --> 00:38:27,000
box is.

594
00:38:27,000 --> 00:38:31,000
But there must be another operation which takes just the

595
00:38:31,000 --> 00:38:34,000
accumulated value and no input.

596
00:38:34,000 --> 00:38:37,000
So an Rd1 operation.

597
00:38:37,000 --> 00:38:38,000
So that's required.

598
00:38:38,000 --> 00:38:41,000
So we'll talk about what that does or how that gets used.

599
00:38:41,000 --> 00:38:45,000
If the process itself, if the overall job has finished, if

600
00:38:45,000 --> 00:38:48,000
it's exhausted input or it has a notion of being finished, this

601
00:38:48,000 --> 00:38:49,000
is not bailing out.

602
00:38:49,000 --> 00:38:51,000
This is like there's nothing more to do.

603
00:38:51,000 --> 00:38:53,000
There's no more input ordinarily.

604
00:38:53,000 --> 00:38:57,000
It must call the completion operation exactly once on the

605
00:38:57,000 --> 00:38:58,000
accumulated value.

606
00:38:58,000 --> 00:38:59,000
So there's no more inputs.

607
00:38:59,000 --> 00:39:01,000
I'm going to call you once with no input.

608
00:39:01,000 --> 00:39:03,000
Do whatever you want.

609
00:39:03,000 --> 00:39:05,000
Each transducer must do the same thing.

610
00:39:05,000 --> 00:39:08,000
It has to have one of these completion operations and it

611
00:39:08,000 --> 00:39:11,000
must call its nested completion operation.

612
00:39:11,000 --> 00:39:16,000
It may, however, before it does that, flush.

613
00:39:16,000 --> 00:39:19,000
So if you have something like partition that's accumulated

614
00:39:19,000 --> 00:39:24,000
some stuff along the way, it can call the ordinary step

615
00:39:24,000 --> 00:39:28,000
function and then call complete on the result.

616
00:39:28,000 --> 00:39:32,000
And that's how we accomplish flushing.

617
00:39:32,000 --> 00:39:34,000
There's just one caveat here, which is that if you're a

618
00:39:34,000 --> 00:39:37,000
stateful thing like partition and you've ever seen reduced

619
00:39:37,000 --> 00:39:41,000
come up, well, the earlier rule says you can never call the

620
00:39:41,000 --> 00:39:42,000
input function.

621
00:39:42,000 --> 00:39:44,000
So you just drop whatever you have hanging around because

622
00:39:44,000 --> 00:39:46,000
somebody bailed out on this process.

623
00:39:46,000 --> 00:39:49,000
There's going to be no ordinary completion.

624
00:39:49,000 --> 00:39:55,000
So we can look at our types again in Omnigraphful 2000,

625
00:39:55,000 --> 00:40:01,000
latest programming innovation, and think about a reducing

626
00:40:01,000 --> 00:40:04,000
function as a pair of operations.

627
00:40:04,000 --> 00:40:06,000
They'll be different in each programming language.

628
00:40:06,000 --> 00:40:08,000
It's not really important.

629
00:40:08,000 --> 00:40:11,000
In closure, it ends up a single function can capture both of

630
00:40:11,000 --> 00:40:12,000
these arities.

631
00:40:12,000 --> 00:40:15,000
But whatever you need to do to take two operations, the first

632
00:40:15,000 --> 00:40:19,000
one up there that takes no input is the completion operation.

633
00:40:19,000 --> 00:40:22,000
And the second is the step operation that we've been seeing

634
00:40:22,000 --> 00:40:23,000
so far.

635
00:40:23,000 --> 00:40:25,000
It takes a pair of those things and returns a pair of those

636
00:40:25,000 --> 00:40:26,000
things.

637
00:40:26,000 --> 00:40:29,000
That's it.

638
00:40:29,000 --> 00:40:31,000
And again, we don't want to concretely parameterize the

639
00:40:31,000 --> 00:40:33,000
result type there either.

640
00:40:33,000 --> 00:40:35,000
You've got to use rank two polymorphism or something because

641
00:40:35,000 --> 00:40:39,000
if you concretely parameterize that, you'll have something that

642
00:40:39,000 --> 00:40:43,000
only knows about transducing into airplanes as opposed to the

643
00:40:43,000 --> 00:40:46,000
general instructions.

644
00:40:46,000 --> 00:40:47,000
OK.

645
00:40:47,000 --> 00:40:49,000
There's a third kind of operation that's associated with

646
00:40:49,000 --> 00:40:54,000
sort of processing in general, which is init.

647
00:40:54,000 --> 00:40:56,000
We've had talks before that mentioned monoids and things like

648
00:40:56,000 --> 00:40:57,000
that.

649
00:40:57,000 --> 00:41:01,000
The basic idea is just sometimes it's nice for a

650
00:41:01,000 --> 00:41:04,000
transformation operation to carry around an initialization

651
00:41:04,000 --> 00:41:06,000
capability.

652
00:41:06,000 --> 00:41:09,000
It need not be the identity value or anything like that.

653
00:41:09,000 --> 00:41:11,000
It does not matter.

654
00:41:11,000 --> 00:41:14,000
What does matter is that a reducing function is allowed to

655
00:41:14,000 --> 00:41:17,000
may support arity zero.

656
00:41:17,000 --> 00:41:21,000
In other words, given nothing at all, here's an initial

657
00:41:21,000 --> 00:41:24,000
accumulator value from nothing.

658
00:41:24,000 --> 00:41:28,000
Obviously, a transducer can't do that because it's a black box.

659
00:41:28,000 --> 00:41:30,000
The one thing it definitely does not know how to do is make a

660
00:41:30,000 --> 00:41:32,000
black box out of nothing.

661
00:41:32,000 --> 00:41:33,000
Can't do it.

662
00:41:33,000 --> 00:41:37,000
So all it can ever do is call down to the nested function.

663
00:41:37,000 --> 00:41:42,000
So transducers must support arity zero init, and they just

664
00:41:42,000 --> 00:41:45,000
define it in terms of a call to the nested step.

665
00:41:45,000 --> 00:41:48,000
They can't really do it, but they can carry it forward so that

666
00:41:48,000 --> 00:41:52,000
the resulting transducer also has an init, if the bottom

667
00:41:52,000 --> 00:41:55,000
transducer has an init.

668
00:41:55,000 --> 00:41:57,000
I've talked about the arity overloading, and so here's an

669
00:41:57,000 --> 00:41:58,000
example.

670
00:41:58,000 --> 00:42:00,000
Oh, I'm over time already.

671
00:42:00,000 --> 00:42:01,000
I'm sorry.

672
00:42:01,000 --> 00:42:02,000
So here's an example.

673
00:42:02,000 --> 00:42:06,000
Plus, from Lisp, this is older than transducers.

674
00:42:06,000 --> 00:42:08,000
Lisp programmers have been doing this for a while.

675
00:42:08,000 --> 00:42:09,000
Sorry, currying fans.

676
00:42:09,000 --> 00:42:11,000
This is what we do.

677
00:42:11,000 --> 00:42:15,000
Plus with nothing returns the identity value for plus zero.

678
00:42:15,000 --> 00:42:18,000
Multiplication with nothing returns one.

679
00:42:18,000 --> 00:42:22,000
It implements plus of an accumulated result as identity,

680
00:42:22,000 --> 00:42:26,000
and the binary operation that does the work.

681
00:42:26,000 --> 00:42:28,000
So here's the types again.

682
00:42:28,000 --> 00:42:33,000
We now have an optional init from nothing, and we're taking a

683
00:42:33,000 --> 00:42:36,000
set of three operations and returning a new set of three

684
00:42:36,000 --> 00:42:37,000
operations.

685
00:42:37,000 --> 00:42:41,000
In closure, we just use arity to do this.

686
00:42:41,000 --> 00:42:43,000
A transducer enclosure then is just something that takes the

687
00:42:43,000 --> 00:42:46,000
reducing function and returns one, where a reducing function

688
00:42:46,000 --> 00:42:48,000
has these three arities.

689
00:42:48,000 --> 00:42:50,000
We haven't actually called the reducing functions mapping and

690
00:42:50,000 --> 00:42:52,000
filtering and ing this and ing that.

691
00:42:52,000 --> 00:42:54,000
I think that's an Englishism that's not going to carry over

692
00:42:54,000 --> 00:42:58,000
very well, and we have available to us arity overloading

693
00:42:58,000 --> 00:43:00,000
because we don't have currying.

694
00:43:00,000 --> 00:43:03,000
So the map of f with no collection argument returns the

695
00:43:03,000 --> 00:43:07,000
transducer, and we've modified so far all of these sequence

696
00:43:07,000 --> 00:43:10,000
functions to do that.

697
00:43:10,000 --> 00:43:14,000
So this is a final example of filter returning a transducer.

698
00:43:14,000 --> 00:43:19,000
It takes a predicate and returns a step modifying function,

699
00:43:19,000 --> 00:43:22,000
which takes a reducing function, which presumably has these

700
00:43:22,000 --> 00:43:25,000
three arities, and defines a function with three arities.

701
00:43:25,000 --> 00:43:27,000
init, which just flows it through because it doesn't know

702
00:43:27,000 --> 00:43:29,000
what it could possibly do.

703
00:43:29,000 --> 00:43:32,000
Complete, filter doesn't have anything special to do, so it

704
00:43:32,000 --> 00:43:33,000
just flows that through.

705
00:43:33,000 --> 00:43:36,000
And then the result and input one, which is the one we've

706
00:43:36,000 --> 00:43:37,000
seen before.

707
00:43:37,000 --> 00:43:41,000
Then we can see, we can define the collection implementing one

708
00:43:41,000 --> 00:43:44,000
by just calling sequence with this transducer.

709
00:43:44,000 --> 00:43:46,000
And that's true of all of these functions.

710
00:43:46,000 --> 00:43:49,000
You can define the collection version exactly like this,

711
00:43:49,000 --> 00:43:53,000
which shows that transducer is more primitive than the other.

712
00:43:53,000 --> 00:43:55,000
So this is what we're trying to accomplish.

713
00:43:55,000 --> 00:43:57,000
You define a set of transducers once.

714
00:43:57,000 --> 00:43:59,000
You define all your new cool stuff.

715
00:43:59,000 --> 00:44:02,000
It's a channel today, observables tomorrow, whatever the next

716
00:44:02,000 --> 00:44:03,000
day.

717
00:44:03,000 --> 00:44:05,000
You just make it accept transducers.

718
00:44:05,000 --> 00:44:09,000
And every specific implementation of these things you get for

719
00:44:09,000 --> 00:44:10,000
free.

720
00:44:10,000 --> 00:44:14,000
And every recipe that somebody creates, that's a composition of

721
00:44:14,000 --> 00:44:18,000
those transducing operations, works with your thing right

722
00:44:18,000 --> 00:44:19,000
away.

723
00:44:19,000 --> 00:44:21,000
That's what we want.

724
00:44:21,000 --> 00:44:24,000
We're going to take Perlis and just say, it's even better.

725
00:44:24,000 --> 00:44:28,000
We want 100 functions with no data structure.

726
00:44:28,000 --> 00:44:32,000
So transducers are context independent.

727
00:44:32,000 --> 00:44:34,000
There's tremendous value in that.

728
00:44:34,000 --> 00:44:36,000
They're concretely reusable.

729
00:44:36,000 --> 00:44:39,000
So somebody can make this and not know how you're going to use it.

730
00:44:39,000 --> 00:44:41,000
That has tremendous value.

731
00:44:41,000 --> 00:44:44,000
It's much stronger than parameterization because you can

732
00:44:44,000 --> 00:44:46,000
Flow it.

733
00:44:46,000 --> 00:44:48,000
It supports early termination.

734
00:44:48,000 --> 00:44:50,000
They support early termination completion.

735
00:44:50,000 --> 00:44:52,000
You can compose them just as easily as you can compose the

736
00:44:52,000 --> 00:44:53,000
Other ones.

737
00:44:53,000 --> 00:44:55,000
They're efficient and tasty.

738
00:44:55,000 --> 00:44:57,000
Thanks.

