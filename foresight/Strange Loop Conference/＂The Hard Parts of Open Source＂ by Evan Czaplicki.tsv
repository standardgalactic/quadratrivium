start	end	text
0	14960	Welcome, everybody. Thanks for coming to this session. So I'm Evan Trepliki. I'm the designer
14960	20520	of the Elm programming language. And I got started on it about seven years ago with a
20520	25960	paper called Elm Concurrent FRP for Functional Goose. And I was like, I really think I can
25960	31040	make this functional programming stuff easier. And I didn't nail it immediately with that
31040	37840	title. But I had this idea of this experience with type functional programming that was
37840	43640	really joyful. And what I wanted to get out with Elm was I wanted to take that part that
43640	49480	I felt was so fun and make it accessible to other people and share that joy that I had
49480	53720	felt. And so part of that is technical. You have to write a compiler and all this kind
53720	60040	of stuff. But another part is like practical stuff. Like getting set up should be easy.
60040	64880	And that was part of what was important to me having spent a whole day just trying to
64880	69060	learn something, trying to see if something was interesting and being really frustrated.
69060	73240	Another piece of that was if program is going to be fun, I want the community to be friendly.
73240	78400	I didn't want it to be a cool club for the cool kids. You know, oh, we're functional
78400	84560	programmers and you're not because you're dumb. Like, I didn't relate to that. I just
84560	89280	had a nice time programming and I wanted to share that nice time in the same way that
89280	95480	I like sushi. And I might say, hey, you should try it out. It's pretty nice. And so I might
95480	103200	say, no, thanks. Oh, okay. You know, that's the kind of interactions I wanted to have
103200	110080	because it was just about having this experience. So as I've talked to more open source developers,
110080	115080	people who design languages, people work on databases, people work on machine learning
115080	121720	or discussion platforms or environmental sensors, however much we disagree on design
121720	127560	or what our goals are, we all have stories in common about like having a friendly community
127560	131360	is really, really difficult. And that's one of the places in open source where, you know,
131360	136240	as good as you can be at the technical stuff, like you don't have a lot of, ultimately, you
136240	140680	can't control what's going to happen. And if someone's going to yell, it's like, I wish
140680	147360	that didn't happen. So I've been doing this for about seven years now and I've started
147360	152040	to notice some patterns of behavior that I think probably a lot of people who've worked
152040	159440	in open source with larger prize will relate to. So one is this, why don't you just? And
159440	165000	in Elm, it's like, why don't you just get the JS API directly or release an incremental
165000	171520	version instead of a bigger release or, hey, can we derive JSON decoders? And the short
171520	176920	answer in all these cases is that it's more complex than it sounds. Like if there's something
176920	182600	that you can think of in five minutes or an hour or a day, probably someone has thought
182600	186280	about that and considered it. And there might be implications that you don't see from your
186280	190620	perspective, but someone else in the community might have a problem with that that's not
190620	195800	obvious to you. So when you're doing design, why don't you just? It's like, well, there's
195800	200720	all these different parties that we have to sort of make things work for. And I can do
200720	205400	my best on my intuition, but ultimately, even after I spend like a week trying to design
205400	208960	something that way, I need to go out and show it to people and see what objections they
208960	215320	bring and then maybe do it with another design. So this why don't you just is like, it's quite
215360	219520	frustrating. And one thing that happens is there's a lot of people who are new to the
219520	223160	project. So maybe there's 10,000 people who might be curious, like, oh, why don't you
223160	228440	just try out this kind of thing? And the number of people who know the full context is pretty
228440	234080	small. So maybe there's like 10, 20 people. So if it takes five minutes to say, why don't
234080	238160	you just blah, blah, blah? And it takes two pages of writing. And you have to write it
238160	242200	very carefully because if you're an influential community member, people will refer back to
242240	247080	what you said four or five years ago and say like, man, there's such a jerk here. Here's
247080	253200	the evidence. They said this in 2013. And it's like, yeah, yeah, yeah, I said that in
253200	263040	2013. Yeah. So one thing that's common is like, well, if it's so much work, like, why don't
263040	269160	you just delegate the work, right? So this is a comment I got in real life and the italics
269240	274120	are from the person talking to me. They said there's another way to deal with this, like,
274120	279120	delegation. And then they go on to describe how delegation works and what benefits it might
279120	286160	have. I was like, oh, very interesting. Yes, I hadn't thought about that. And they describe
286160	291000	a person who can do all this work. And they say this somebody, again, that is their italics,
291000	298320	can also be a proxy who's gathering feedback. So like, you don't have to be in these discussions.
298480	306680	So I was initially very upset about this. So like the unfiltered in my own mind version was
306680	312960	like, oh, hello, is this the somebody store? Yes, we'd like someone to take unsolicited advice on
312960	318080	the internet. Oh, yeah, it's it's really mean. Yeah, it's it's going to be rough. And no, yeah,
318080	325160	no one's going to say thank you. Yeah, no, it's it's unpaid. Yeah, it's unpaid. It takes you
326040	334120	don't have any. I was told there would be somebody who would do this. And, you know, so this was
334120	342160	me in my own life, like walking around my room, just like, and that's, you know, that's not a
342160	346440	healthy place to be. That's not how I want to look to a community. That's not what I want the
346440	352520	community. I'm a part of to be either. And when I took some time and thought about it more, I
352560	357160	realized there's actually like a pretty reasonable assumption going on here, which is like free
357160	363880	rice means you can take as much as you want. The rest is free. Take a lot of rice. And so does
363880	370000	that imply that free labor means you can use as much as you want? Well, the labor's free. But in
370000	375960	fact, this isn't how labor works. If you don't pay for labor, you get less. And so I think that's
375960	380920	sort of the root thing. It's like, Oh, well, it should be unlimited. Anyone can help. Now, let's
380960	385760	assume it is unlimited that everybody in the world actually can help. In practice, you actually
385760	393080	have to work together, right? These are highly technical projects. Are you able to work well
393080	397480	together? Is your goals with the project aligned? How much time does it take to coordinate with
397480	401520	that person to get stuff done? So even if you can work with anybody you want, there's still
401520	406960	these limitations on like who is going to be really effective in doing the right stuff. So I
407000	414800	wrote about that a little bit in this post. I think, no, sorry, Richard wrote about that in this
414800	421800	post here of like, what actually does it take to get involved? And it's like, it's not just somebody
421800	428120	store. So, you know, some people may be thinking like, you know, Evan, you're doing a lot of telling
428120	434480	us what's the situation, but like, who are you to say that? And so this is another pattern that I
434520	440360	see a lot. It's like on who's authority. And this is actually the title of a post that was sent
440360	450360	to the closure community. And the post started out, F closure. There I said it, and God, it feels
450360	461320	good. I say it with much admiration and respect to all the community members. And then they go on
461320	466960	to say some criticisms and talk about the relationship with women. And it's quite a roller
466960	478040	coaster of a post. But what's interesting, besides sort of like it as a journal entry, is that it
478040	483560	gets a lot of engagement, right? So 320 comments on the Reddit thread. I'm sure people talked about
483560	490680	it in other contexts as well, where there would have been more comments. And, you know, as someone
490680	496400	who's been working on an open source project for a bunch of years now, enough people have told me
496400	501760	that Elm is going to die next month. That I'm like, I don't think they're right this time. You know,
501760	509880	like I have that fear doesn't speak to me anymore because I have the experience. But there are
509880	514520	other people in the community who don't have that same experience. And like this can be like a
514520	519800	scary thing of like, man, people like aren't liking this thing. Are we doing something wrong? They
519840	526920	feel like maybe it could be better. They might get defensive. So in one of these 320 comments, the
526920	533720	creator of closure says, I found out about this while sitting down to spend my weekend contributing
533720	538880	to the closure ecosystem. Time spent in lieu of spending time with my wife, having already spent
538880	545720	my work week on other closure related stuff. And I relate to this a lot. I've definitely written
545960	551600	like, hey, like we, I get there's different viewpoints, but like we can't yell our viewpoints at
551600	558160	each other. And that was my Saturday. And, you know, as you work over the course of the years,
558160	564560	like, there can only be so many Saturdays that are like that before it starts to hurt you in larger
564560	572760	ways. So Rich Chicky goes on to say, you know, every time I have to process a diatribe like this,
572760	576920	and it's aftermath, the effects on myself, my family and my coworkers, I have to struggle back
576920	581800	from why should I bother? And every time it gets harder to justify to myself and my family that
581800	586920	it's worth the time, energy and emotional burden. Now, I've talked to some people about this post
586920	591720	and they, they thought different things stood out to me. This last part is what stands out,
591720	597960	because I think a lot of people in open source feel this way and like would never say it out loud.
597960	603480	I was really surprised to see it that way. And it kind of gave me some confidence to talk about
603480	611320	that kind of stuff as well. So, you know, we have our posts like this in the Elm community
612600	619320	with a bunch of comments as well. And I see it not just as like, oh man, this is hard for me to
619320	623800	process, but the people I work with have a hard time processing it. And then if you just add up
623800	628120	all the time, let's say maybe 10 minutes is spent on each of these comments, which I think is low,
628120	635320	like a conservative estimate. We're talking about like 50 hours for this one, that's just like
635320	642040	dealing with someone's anger. And could that have been helping someone new or spending time with
642600	648360	some family members or like learning some hobby that could get you out of work and get you like
648360	654360	a more healthy attitude? So, one thing I hear a lot when I talk about this stuff is like, if it
654360	665480	makes you so mad, why don't you just not read it? Why don't you just not read it? So, another pattern
665480	672120	that's really common is that all discussion is constructive. You know, I'm just saying how I
672200	679560	feel. I feel like F you, and I respect you a lot. And you know, I think you're an idiot, but like,
679560	685800	I really learned a lot from you. And like, that's a difficult, like personal relations to have,
685800	688760	I don't know if people have people like that in their life, but that's a difficult thing to deal
688760	696120	with a lot. So, one discussion that was along these lines is like, should Elm have user definable
696120	700920	infix operators? This came up recently with our recent release. And if we just focus on this
700920	707800	question, like textually, someone might say, yeah, there are cases where it makes code shorter
707800	713240	and more convenient. And someone else might say, no, because it can make code harder to read,
713240	718840	especially in a large team. And you know, textually, like, this is an interesting argument. Like,
718840	724200	yeah, it can make coach. That's a good point. And it might hurt people in a large team. And then
724200	730120	onlookers will sort of say, oh, which one seems to make more sense to me? But when you take a step
730120	735320	back and stop thinking of it just as like a textual argument about who is right and who's wrong
735320	740760	and say, okay, all these people have different priorities. Some of them may value flexibility
740760	746840	a lot. And some people might value simplicity a lot. And all these people exist on this
747720	750520	with different priorities. So the person who's like, yeah, we should have this,
751080	756040	really might value flexibility. And the person who says no is saying, well,
756520	763240	if like all these benefits are telling me about flexibility or like how code can be shorter
763240	766760	and more convenient, it's like, that's not persuasive to me. Like, that's not a good
766760	772600	rational argument because it's not important. And likewise, you know, how does it work on
772600	776840	a large team? It's like, well, that doesn't, it doesn't matter. It's not about that. And all the
776840	782440	people exist on this spectrum is with different priorities as well. So they're evaluating it
782440	788440	not as which is the true objective argument, but given my priorities, which is the one that
788440	796600	makes the most sense to me. So I've come to see constructive discussion is about mutual understanding
796600	800920	rather than mutual agreement. And a lot of discussions online are like, we're going to get
800920	806440	to a point where you agree with me rather than saying like, huh, this person's seeing it different.
806440	811720	Why is that maybe they're seeing something I don't. So
814120	819160	when I take a step back and think about these different patterns, I just think like, why,
819160	824520	why is this happening? You know, I don't have problems like this in normal life. You know,
824520	833160	if I'm at an Elm conference or a meetup or like nothing ever is so emotionally difficult as these
833160	838920	interactions. So I found this documentary called All Watched Over by Machines of Loving Grace by
838920	845880	Adam Curtis. It's excellent as is all of his work. And that sort of taught me or I found through that
845880	852520	a book called From Counterculture to Cyberculture. So this revealed to me a sort of an intellectual
852520	858120	history going back to the 1950s that really helps explain what's going on in open source right now.
858760	868920	So it traces things from a book called The Human Use of Human Beings. So this came out of MIT in
868920	876840	like 1952 by a person who had created artillery that could automatically track planes and shoot them
876840	884360	down. And then the whole earth catalog, which was popular in the back to the land movement. So
884440	887880	a lot of people on communes might have bought this, but it was a much larger thing than that.
888760	892520	And then finally the Electronic Frontier Foundation, and it sort of ties these together in a very
892520	898520	interesting way. So we'll look at some of the things going on here. So in The Human Use of Human
898520	906760	Beings, Norbert Weiner introduces the idea of cybernetics. He defines it as the study of messages
906760	917480	as a means of controlling machinery and society. So it's a little weird. Okay, okay, fine. And as
917480	923480	you start to read it, it's like this way of like, let's not look at the person, but let's look at the
923480	928120	messages going around, and that's how we'll think about how the world works. And so you see things
928120	934360	like words such as life, purpose, and soul are grossly inadequate to precise scientific thinking,
935080	940600	which is it's like fair enough, but also like those things like life and purpose are like
941560	950200	pretty important to people as well to consider. But you know, a person's just a special sort of
950200	955880	machine, right? Like we can consider it as a thing that takes inputs and does stuff. Emotions are
955880	965000	just a useless epiphenomenon. That's real. He said that. Another thing he's like, we have
965000	969160	modified our environment so radically that we must now modify ourselves in order to exist in
969160	974680	this new environment. So it's sort of how can we take a person and simplify it down to a machine
974680	980920	or a system that we can understand well? And then once we're starting to think of people that way,
980920	984680	well, we can improve machines. We can add things to them and the machines get more
984680	991240	capabilities. Maybe that's how we move forward as people. And life and purpose is like that.
992200	999880	We can't go back to that. It's too different now. So the sort of connecting thread and whole
999880	1005640	earth catalog besides Stuart Brand, the author of this knowing a bunch of the people in the
1005640	1014680	cybernetics group, is this idea of access to tools, right? So like we are now, our relationship
1014680	1020440	with our tools is going to be how we move forward. So this catalog starts with we are as gods and
1020440	1026920	we might as well get good at it. So far, remotely done power and glory as government, big business,
1026920	1032360	formal education, church has succeeded to the point where the gross defects obscure actual gains.
1032680	1042440	In response, personal power is developing. So he's focused on a bunch of different topics.
1043560	1050200	And so education, finding inspiration, shaping his environment, sharing the adventure. Now,
1050200	1054280	keep in mind this is written in 1969. So this is before the internet. And if you read these
1054280	1059320	points as like what an ideal view of the internet should be, it works really well. Like you can
1059320	1065160	find out all sorts of interesting stuff. You can be inspired by what's going on out there. You can
1065160	1069640	find a place where you really fit in, even if you don't fit in, in your local community that has
1069640	1076200	different values than you. And you can share that with whoever you want to. Like there's this place
1076200	1081640	for self-expression. And so he says tools that aid this process are sought and promoted by the
1081640	1087160	whole earth catalog. So some people have argued that this is sort of like the what preceded the
1087160	1093480	internet. It sort of foresaw what was going to happen there. And this publication and the
1093480	1098920	creator, Stuart Brand, had been really influential. So one of the positive quotes is when I was young,
1098920	1102440	there was an amazing publication called the whole earth catalog, which was one of the
1102440	1110120	Bibles of my generation. So that was Steve Jobs. There was a project that Stuart Brand created
1110120	1117480	called the 10,000 year clock, which Jeff Bezos helped fund with $42 million. So what is this,
1117480	1123880	like this book that was popular on back to the land communes, became very influential because of this
1124680	1131960	how tools and like a rejection of hierarchy, we're somehow in this new place where we're
1131960	1137240	going to choose our own future through our connection with tools. And finally, the electronic
1137320	1141880	frontier foundation. Interestingly, the founders of this met on the whole earth
1141880	1148840	electronic link, one of the earliest bullet or message boards. And so one of the founders
1148840	1154040	wrote the declaration of independence of cyberspace, governments of the industrial world,
1154040	1160280	you weary giants of flesh and steel, you have no sovereignty where we gather. I declare the global
1160280	1165560	space, social space we are building to be naturally independent of the tyrannies you seek to impose on
1165560	1171560	us. So again, you see this like distrust of hierarchy, big businesses failed, government has
1171560	1177000	failed. We are going to find a new way through this thing. So one of the early cases that the
1177000	1182600	electronic frontier foundation that inspired the creation of this foundation was there was a
1182600	1191080	programmer called Lloyd Blankenship. And Bell South found that some of their 911 alert system
1191080	1195640	documentation had been posted on a bulletin board. And so they got the secret service involved
1195640	1201480	and took some computers that might have sensitive information. So Lloyd was arrested and the
1201480	1206520	electronic frontier foundation like was created around that time to help protect people in the
1206520	1212280	situation. So after Lloyd was arrested, he wrote something called the hackers manifesto,
1213560	1219080	which I think gives a raw version of what's going on in this world. So he says,
1219880	1223640	I'm smarter than most of the other kids. This crap they teach us bores me.
1225000	1228200	I've listened to my teacher explain for the 15th time how to reduce a fraction.
1228200	1231560	I understand it. No, Miss Smith, I didn't show my work. I did it in my head.
1233400	1242440	And you can see, well, he says, I made a discovery today. I found a computer. It does what I
1242440	1247720	want it to do. If I make a mistake, it's because I screwed up, not because it doesn't like me,
1247800	1252520	or it feels threatened by me, or it thinks I'm a smart ass, or it doesn't like teaching and
1252520	1258360	shouldn't be here. So you're seeing this, this guy is 21 when he's writing this. He's somebody
1258360	1263400	sort of very disillusioned, not just with government or big business, but like just his
1263400	1269400	classroom, the social environment he's living in. And he goes on to say, this is our world now.
1269400	1273400	We explore, but you call us criminals. You build atomic bombs, wage wars.
1274040	1277720	You try to make us believe it's for our own good, yet we're the criminals.
1279560	1284600	So again, you see that explicit distrust of hierarchy. And then finally,
1284600	1288200	my crime is that of outsmarting you, something you will never forgive me for.
1290040	1294760	So I don't know how many people who work on open source will recognize aspects of this attitude
1294760	1302360	and interactions they have. But there's sort of such a strong rejection of the social things
1302440	1307400	going on. It's like, well, the teacher who's not teaching you well has a bunch of other students,
1307400	1312680	and it's difficult to balance all their needs. Maybe it's malicious, but maybe there's another
1312680	1318440	reason. But this worldview is kind of like, I outsmarted you. You don't see it how I see it.
1319080	1326760	So when I take a step back on this intellectual pathway, the things I sort of draw out from
1326760	1334200	reading these books and things is, one, we're gods. Two, hierarchy has failed us. There's
1334200	1339640	sort of a deep distrust of hierarchical structures. I think rightly, there's a lot of bad things that
1339640	1346920	come out of hierarchy. And finally, order will emerge from the new technology. So when we reconsider
1346920	1352760	the patterns we've seen open source, stuff makes a lot of sense. So it's like, why don't you just?
1352760	1358840	It's like, haven't you, we can just, through reason and rationality, figure out the answer.
1358840	1364360	Why don't you just do the obvious thing? Hierarchy has failed us. So again, on whose
1364360	1369160	authority is coming out of this tradition of hierarchical structures haven't served us well.
1369160	1374040	We need to find a way that isn't structured in that way. Your authority as the author
1376040	1381240	is not legitimate on those grounds. And all discussion is constructive. It's like, well,
1382040	1386200	this is the new technology. This is what the new technology is producing. So this must be
1387080	1395080	the way forward to this place that we want to go. So I found this pathway really interesting,
1395080	1400040	and it informed, like, it helped me understand a lot what was going on. But it's just one of
1400040	1405320	a couple of different ways of looking at how we got to this level of conflict in open source.
1405320	1412760	So I'm calling this sort of the intellectual issue of freedom. People are primarily prioritizing
1412760	1417720	freedom. But there are other ones, such as people who are primarily prioritizing engagement.
1418600	1424680	So I want to start with a quote, the enormous expansion of communications has entirely transformed
1424680	1429080	the conditions of trade and commerce. Everything is done in haste at fever pitch. The night is
1429080	1433640	used for travel, the day for business, even holiday trips put strain on the nervous system.
1434360	1439800	And do people relate to that? Holiday trips being stressful? I feel that. Or I struggle with that,
1439800	1450200	at least. I try to take a break or whatever. Great political, industrial, and financial crises
1450200	1454040	carry this segment into far wider areas of the population than ever before.
1454040	1458120	Interest in political life has become universal. Tempers are inflamed by political, religious,
1458120	1463560	and social struggles, party politics, electioneering. Sound familiar to anybody?
1466680	1470120	Finally, people are forced to engage in a constant mental activity and robbed of the
1470120	1474360	time needed for relaxation, sleep, and rest. So if you had to guess when this was written,
1475480	1480280	it's reasonable. It could be this year, it could be 2017, or maybe someone was really
1480280	1484040	prophetic and they wrote it in like 1980. It's like, I see where this is all going.
1485000	1488200	So this is actually from something Freud wrote in 1902.
1489560	1495000	The part I left out is due to the worldwide telegraph and telephone networks
1496040	1502920	and the immense growth of trade unionism. So I mean, I think it makes sense that he would
1502920	1506760	have seen these kinds of things. He seems like a smart dude, or at least someone who's very
1506760	1514360	sensitive to human behavior. And so this is kind of where this intellectual history starts.
1514360	1519000	So we have Freud, but we're going to look at two other books. One is called Propaganda
1519000	1525720	from 1928, and one is called Nudge, much more recent from 2008. So with Propaganda,
1525720	1530600	this is written by Edward Bernays. This is actually Freud's nephew. The connections between
1530600	1536840	all these works are crazy. And as you look into any parts of these, like everybody met,
1536840	1540840	everybody worked with someone's nephew or cousin or mom, or it's very strange.
1542840	1546920	So this book is essentially a bunch of stories about how Edward Bernays sort of created the
1546920	1551400	idea of public relations. So one of the stories he tells is about torches of freedom.
1552600	1557960	So this was an ad campaign to break the taboo against women smoking. At the time men would
1557960	1564040	smoke, and it was acceptable to some degree, and women couldn't. It was very looked down upon.
1565320	1571640	So the president of the American Tobacco Company said, if we can break this taboo,
1571640	1577000	it'll be like a gold mine opening right in our front yard. So he hires Edward Bernays.
1577800	1584440	And what Edward Bernays does is he hires women who are good looking, but not too modally. That's
1584440	1588920	the quote I found good looking, but not too modally. To walk in an Easter Sunday parade
1588920	1594360	and smoke, he also hired photographers to get really good photos of these women,
1594360	1598840	and then distributed those photos to newspaper, like through newspaper connections that he had
1598840	1606600	to make sure it got published all around the world. So this torches of freedom idea was saying,
1606600	1613240	we see this trend about women's liberation happening, and like this is aligned with that
1613240	1620040	movement, and that this is a way of punching up against those taboos. But it's very focused on
1620040	1624600	like, hey, we're going to sell a bunch, we're going to make a bunch of money here. And so one of the
1624600	1630520	ads that came out of this was an ancient precious has been removed. And what's interesting about
1630520	1637960	this ad is that visually it's clearly about women smoking, but texturally it's saying toasting did
1638040	1644600	it. It's because they toast the tobacco, it's less harsh on your throat, and that's what has
1644600	1650920	removed the prejudice. So texturally, they can say, look, we're not getting into politics. We're
1650920	1656760	just saying that toasting is cool, and that's a lady who smokes. It's like, I don't see the problem.
1657400	1664360	But meanwhile, you have hired Edward Bernays to actually run this campaign. So, oh yeah,
1664440	1670280	I want to read a little bit from his book. This is the book. He says, the old-fashioned
1670280	1676120	propagandist using almost exclusively the appeal to the printed word tried to persuade the individual
1676120	1684760	reader to buy a definite article immediately. So his example of this is like, you buy O'Leary's
1684760	1692280	rubber bands now. And he's like, okay, that's the old-fashioned way. The modern propagandist
1692280	1697880	therefore sets to work to create the circumstances that will modify the custom. It doesn't matter
1697880	1703480	what this ad says. It's about creating circumstances such that the custom will change in whatever
1703480	1709640	direction someone pays me to change it. So another example he gives is for Mozart pianos.
1710200	1715000	So I don't know exactly the finances of Mozart pianos, but let's say they had 30% of market share
1715720	1721000	and he gets hired to make it higher. Maybe it can go to 35 or 40. That'd be a huge for Mozart
1721000	1727320	pianos. So Bernays comes in and he says, okay, I could say to people, will you please buy a piano,
1727320	1734440	but I'm not going to do that. I know that pianos have this sort of elite cachet. And so what I'm
1734440	1740040	going to do is I want to make an architecture expo in New York City where we're going to showcase
1740040	1746600	music parlors and we're going to bring in famous people, influential artists and musicians to
1746600	1752360	be in the rooms. We're going to have expensive tapestries and really lean into this elite picture
1752360	1758680	and promote it in our connections with newspapers. He also invites architects from all over the
1758680	1764280	country. He wants influential architects and they'll bring designs for music parlors. So what this
1764280	1771160	expo does is it creates a music parlor as an aspirational goal and it brings in architects
1771160	1775960	who will then go back to wherever they're from with designs for music parlors and they'll start
1775960	1780600	building houses that have that. And ideally they'll influence other architects who are not as
1780600	1786680	influential to add music parlors as well. And so instead of saying, hey, will you please buy this
1786680	1790520	piano, people are now saying, hey, I have this piano shaped hole that I need to fill. Like,
1790520	1798600	do you have something piano shaped? So again, the modern propagandist sets to work to create
1798600	1803880	the circumstances that will modify the custom. So this got modernized and sort of made a bit
1803880	1811160	nicer in nudge. So here we see a nudge is any aspect of a choice architecture that will alter
1811160	1815720	people's behavior in a predictable way without forbidding any options or significantly changing
1815720	1823080	their economic incentives. So this book has been really influential in tech recently. So one thing
1823080	1829480	that we're probably all familiar that's an example of this is autoplay of videos. So you just finished
1830120	1836920	a show. It ends on a cliffhanger because they wrote it that way. And you're like, man, that was
1836920	1848600	cool. And then you're like, oh, my body. Is it hungry? Does it need a walk? Did it have plans
1849320	1857720	for today? Or for anything? And then the music starts again and you're like, no, no.
1860680	1866840	So this is a nudge, right? You're free to do some other behavior, but through the choice
1866840	1872360	architecture that was created, a predictable amount of people don't make that free choice.
1873320	1879240	So this ended up being popular at Google. So if anyone's visited Google cafeterias, you'll
1879240	1884600	probably have seen all the food is marked with colors. So green means eat anytime. Yellow means
1884600	1888920	once in a while. Red means not often, please. And it's all marked. It's actually very helpful.
1889960	1895960	You can be like, oh, I just had one red thing today. It's kind of nice. But this interest in
1896440	1902680	colors changing people's behavior was used to Google in other ways. So when you look at the
1902680	1909560	history of their ad labeling, you see something similar. So when ads started, they sort of just
1909560	1917640	start by playing around with colors. It's like, well, maybe green is fun. Or maybe this lavender,
1917640	1923480	purple thing is the way to go. So in a new phase of things, you start to see, okay, well, let's
1923560	1930920	do something more white. Can it be something more white? Yeah, maybe a little more white, you know?
1933720	1937080	Well, how about something like a little more white? Like, all this color is like,
1937080	1940760	let's just put it in one place. We'll take all the saturation, put it in one place.
1942040	1949400	And like, hey, it works fine. No problem. And then it's like, well, that yellow is pretty ugly.
1949960	1955480	We could just, you know, it's still labeled. It's no problem. And then it's like, I mean,
1956680	1962360	who wanted it to be yellow? And I mean, it wasn't really that important. And then it's like, you
1962360	1974680	know, the background, I mean, people get it. They get it. So when you search for Italy tour, for
1974680	1982840	example, everything above the fold is an ad and it's labeled in this very, you know, subtle and
1982840	1990440	nice way. So I found this very interesting quote from the head of text ads at Google. He says,
1990440	1995560	we want to make it easier for our users to adjust information on the page. So we're gradually trying
1995560	1999880	to reduce the number of variations of colors and patterns on the page and bring a little bit more
1999880	2008520	harmony to the page. Like, we just want harmony. And that's why we reduced one of the color
2008520	2013160	elements on the page. We could have reduced other color elements. Yeah, it's just one color element.
2013160	2019480	Like, what's the big deal? So some of you may be thinking, like, Evan, if you're so mad about this,
2019480	2025640	you know, why don't you just change your default search? Like, you typed it into Safari, so clearly
2025640	2032040	that's the default. Well, another thing I learned when I was looking into this is Google paid $1
2032040	2036840	billion to Apple to keep the search bar on iPhones. Furthermore, these sums called traffic
2036840	2045480	acquisition costs rose to $5.5 billion or 23% of ad revenue. So we're in a situation where
2047960	2054360	a choice architecture has been created, you know, the circumstances have been modified such that,
2054360	2059960	you know, well, I don't mind searching in this way, or I could scroll down below these ads,
2059960	2065640	but I don't really want to. So the circumstances have been created such that custom is modified.
2065640	2069960	And if we wanted to mess with this, like, it's going to cost a lot of money, right? The fact that I,
2069960	2073800	that DuckDuckDog exists doesn't mean that they can compete with these kinds of
2074360	2084760	numbers. So I think this whole intellectual lineage leads to something that we see in online
2085320	2091240	communities a lot, which is like this, things are viral by design. So when Bernays starts an
2091240	2095880	advertising campaign, all these stories he tells, he always starts with a psychological hook. So
2095880	2101160	you might observe that people process emotions by sharing them with others. So that might look like,
2101240	2106280	you know, someone's going about their day, it's fine. And someone shows up and they're like,
2106280	2111000	that work you did last week, it was terrible. Like, it's not going to work out. It was really not
2111000	2117880	carefully considered. And that person feels sad. And that person goes, the person yelling at them
2117880	2124520	goes away. So they might mope around for a day or however long. And hopefully they run into a friend
2124520	2128840	who hears this story and they're like, oh man, that sucks. But, you know, I don't think that was
2128840	2134760	really a fair assessment. And through talking it through, the person can sort of deal with that
2134760	2139960	and move through. Another interaction that might be possible is you're going about your day and
2139960	2144120	someone says, did you hear about that terrible thing that's happening over there? And you say,
2144120	2148680	whoa, that's terrible. And then you see a friend and you say, hey, did you hear about that? And
2148680	2152280	they're like, oh, that's terrible. And they see some of their friends and they're like, man, that
2152360	2164120	thing over there is really bad. Viral. So when we're choosing what kind of messages we want to
2164120	2171560	put into society to control it, as the cyberneticist might say, this one has a very interesting
2171560	2176360	pattern. So when you get something that has a viral reaction, that's something that has more
2176360	2183480	engagement. And a lot of people who are running Silicon Valley companies in an idealistic way,
2183480	2188200	you know, they want to make the world better through tools, they're put in this choice architecture
2188200	2191960	where it's like you have, you know, these investors and you don't want to disappoint them. There's
2191960	2196600	all these people who work at your company, you don't want to lay them off. So do you want hashtag
2196600	2204200	disappointing Q3? Or do you want the viral one? So once you have this psychological hook, you can
2204200	2209880	start designing ways to make it work better. So the ones I sort of noticed have been to mix
2209880	2215080	extremes. So if we come back to our priorities graph of different people, these people don't
2215080	2219320	necessarily congregate in the same place. But what we really want to happen is for the most
2219320	2226760	extreme people to yell at each other as aggressively as possible. And so one way to do that might be
2226760	2230200	to put all the different programming communities in one place.
2234680	2241160	So if you look at sort of different online discussion forums, I think the degree to which
2241160	2245960	different communities collide will predict the amount of conflict that you see there. So on
2245960	2252680	Hacker News, I find that the sort of most difficult and most combative place. And then on the R
2252680	2257880	programming, you'll see more of that. And on the subreddits for individual languages, you'll see
2257880	2263960	less on places that are just community places that don't have accounts that are shared between
2263960	2272040	you'll see less. So another approach is to decontextualize the person. So instead of two people
2272040	2278120	talking, you have Tango dango talking to Foxtrot. And what's interesting here is like when they
2278120	2282440	saw each other's faces, they might be able to say, oh, this person isn't trying to be malicious.
2282440	2288200	They feel this way. But when it's Tango dango, it could literally be Hitler. It could.
2290520	2295320	You don't know. He's just in Argentina being like, infix operators are stupid.
2297720	2305640	Unclean. So another way to decontextualize things is to limit the amount of characters
2305640	2310600	that are available to people. Another way is to limit the kind of feedback that's available.
2310600	2317320	So instead of saying, hey, that was pretty hurtful, you say down. Like a lot of nuance is lost in
2317320	2324600	that sort of thing. So when I take a step back on all this, I think there's a big conflict here
2324600	2331320	where there's very powerful incentives for our interactions to go really poorly. And I don't
2331320	2337320	think the intellectual issue of freedom really is well set up to protect against that. Like if
2337320	2342520	you are living in a choice architecture that predictably alters people's behavior, yeah, you
2342520	2347240	were given a free choice, but you happen to choose a different thing 30% of the time.
2348920	2354360	So this got me interested in a different pathway. So I ask a lot, why don't I have any of these
2354360	2360120	problems in person? So like at work or at conferences or at meetups or on the street,
2362520	2368040	all these places are for something. So when a place is for something, you can ask what's
2368040	2373240	inappropriate behavior. If I'm at work and a discussion keeps going and going, at some point
2373240	2377160	it's like we have to stop having the discussion and make a choice. We can't be in discussion forever.
2377160	2385480	It's clear because of work is for work. And at a conference, it's against the norms to jump
2385480	2390440	up on a stage and being like, that's wrong. The idea is like you carefully select speakers who
2390440	2396120	might have something interesting to say to folks and try to efficiently and in a nice way present
2396120	2401400	that. At a meetup, if someone's being really aggressive, they're always like, oh, I need to go
2401400	2407400	to the bathroom. There's ways out of those kinds of conflicts or and you're talking face to face
2407400	2412200	on the street, you know, someone's like standing outside Starbucks and being like, I had better
2412200	2423240	coffee one time. It's like that's weird. That's weird behavior. And then and the croissants could
2423240	2433800	be done better. I don't know how, but they could. This isn't it. So this idea of like a place being
2433800	2439160	for something I think is really important. And so I had this idea for intentional communication.
2439160	2443160	And so the idea is that instead of just having a blank box you write into, you first choose
2443160	2448440	some intent. My intent is to learn, let's say. And I'll get prompted to say, okay, what's your
2448440	2452520	background? Maybe they started using Elm and they've been doing Java for a long time. And the
2452520	2457960	question is, why do I have to explicitly cast between int and float when doing math? And then I
2457960	2463960	can submit the post. So when that shows up, this question might have been read in a combative way.
2463960	2469960	Like, why do I have to explicitly cast between int and float when doing math? Or like, why do I have
2469960	2475240	to explicitly cast between? Like, both of those are valid interpretations of this text. But when
2475240	2479640	you give some background, it's like, okay, I see where this person is coming from. I can see why
2479640	2484120	they'd be frustrated with that. And it's really harder to read it in a malicious way. So instead
2484120	2489160	of just having a reply button, maybe you can say, okay, I can either ask for clarification or I can
2489160	2496360	give an answer. And so if I say, I'm going to give an answer, again, we might have this structured way
2496360	2504520	of replying. Restate the question, answer it, and then we can say, hey, we value citations. We value
2504520	2508680	like people backing up with evidence or experience. So maybe they give a citation and they can post
2508680	2514760	it. And so again, you get the answer. And the person asking says, oh, that's not the question I was
2514760	2522600	asking, actually. So that can really help clarify and make this process more efficient. So again,
2522600	2528760	instead of reply, maybe you say, ask for clarification or thank the person. And so there's a couple
2528760	2533560	of things you can add to this I think that would help. So one is the idea of conversation flows.
2533560	2537800	So we saw someone wants to learn, you can clarify or answer. If you choose to answer,
2537800	2544200	they can ask a clarifying question or thank you. Now if they clarify, maybe you give another answer.
2545240	2550520	But in the other pathways, say, hey, maybe can you give me an example to clarify your question?
2551160	2557160	They can restate it and then you can answer. So the point here is just that yell angrily isn't one
2557240	2565320	of the states in the discussion flow. It's unreachable. So this isn't to say that all discussion
2565320	2569400	should be this way. Because there are places where you want self-expression. You say, hey,
2569400	2572360	I had a really nice time at the park. Here's a photo of it. And someone says, oh, that's great.
2572360	2577480	That reminds me of last week we were clicking something really nice. And so you can have these
2577480	2582760	cycles. But when someone's doing self-expression, you say, man, that's really like a terrible thing
2582760	2587160	to say. Maybe you could have a conversation flow that says, hey, I want to learn about that
2587160	2590520	perspective. I don't want to tell you it's wrong. I just want to know why you feel that way.
2591640	2597000	So what might be interesting here is the discussion flows will be different depending
2597000	2600520	on the goals of the community. If it's about learning, it might be one way. If it's about
2600520	2605640	self-expression, it might be another way. And maybe you want safety valves to jump around.
2605640	2609640	So another thing that I think is interesting is say discussion is happening and it's getting
2609640	2614040	really out of control. And it's like, hey, this is nice. And then by the end, they're like,
2614600	2622280	your mom is a bad person. And she threw a bicycle on the ground. I don't know.
2624040	2628600	So this is where you don't really want things to go. So one thing that might be interesting is
2628600	2633080	when you see someone about to reply, say, hey, what would be a successful conclusion to this
2633080	2638840	interaction? Or would it be easier to chat for five minutes? Is there somewhere to take this
2638840	2643480	that's going to be more constructive? Like, what do you want to get out of this? Another thing that
2643480	2648920	might be really valuable. So we talked about private feed or sorry, upvote, downvote stuff.
2649560	2653400	When someone gets downvoted, they say, they think to themselves, these people who just can't take
2653400	2659320	it, you know, I outsmarted them and they can't accept that. But the people might actually be
2659320	2663800	saying, man, that was pretty rude and uncalled for. And so that feedback is not reaching that person
2663800	2668520	and they feel increasingly alienated by these kinds of reactions. Furthermore, these buttons
2668520	2674200	sort of uniquely pick out like, ah, I'm mad. Oh, I like that. So what we might be able to do instead
2674200	2679320	is say, hey, for any post, here's a couple of things that you might notice about it. Is it off
2679320	2685480	topic? Is it helpful? And if the goal of the place is to help professionals, maybe these are the ones
2685480	2689320	you want to choose. But if the goal is helping beginners, maybe you want to choose scary versus
2689320	2694920	encouraging or confusing versus clear. And if the place is about self-expression, maybe you want
2695000	2701640	to choose funny and downer. So there's a bunch of extras. I'm running out of time, so I'm going to
2701640	2707640	skip. But there's a lot of cool things to do here. So some people may be looking at this and thinking,
2708840	2714760	if a planned culture necessarily meant uniform, like, hey, like, all this planning is going to ruin
2715400	2721080	these communities. So I found this book, it says, if planned culture necessarily meant uniformity
2721080	2725640	and regimentation, it might indeed work against further evolution. If men were very much alike,
2725640	2729640	they would be less likely to hit upon or design new practices. And a culture which made people as
2729640	2733400	much alike as possible might slip into a standard pattern from which there would be no escape.
2734120	2739080	That would be bad design. But if we are looking for a variety, we should not fall back on accident.
2739080	2744040	Many accidental cultures have been marked by uniformity and regimentation. So this is from a
2744040	2749160	book called Beyond Freedom and Dignity by B.F. Skinner. And I think this is one of the clearest
2749160	2753880	books that's sort of recognizing that there are these people who understand choice architectures
2753880	2759000	and that freedom doesn't help you escape from choice architectures. Like, design of other
2759000	2765480	choice architectures is a way to deal with that. So ultimately, I'm not here to say, like, here's
2765480	2769240	one way that's right or the others. It's like, people are going to have different priorities
2769240	2774360	depending on, you know, their life and their experiences. I think the point that's important
2774360	2779560	is that there's a lot of people in open source communities who are getting hurt, right? So like,
2779560	2783960	it's hard emotionally to work on these kinds of projects. You see people around you getting hurt.
2783960	2788840	And just saying, well, people are just expressing themselves isn't solving the question. And we
2788840	2794600	have these very influential people controlling billions of dollars who have particular goals
2794600	2799800	for what happens in these communities. So I hope that's an interesting way to think about
2799800	2804040	the hard parts of open source. And I have a bunch of references if you're interested in looking
2804040	2810200	back on things. And I hope people will explore through programming, like creating the communities
2810200	2817000	that we kind of talked about. Maybe exploring intentional communication. And maybe it will
2817000	2821720	be beautiful. Maybe people won't use it. Maybe people will use it. And then it will just become
2821720	2828280	another tool for engagement. It's likely. We'll see. But thank you very much for your attention
2828280	2829320	and consideration.
