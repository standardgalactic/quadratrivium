1
00:00:00,000 --> 00:00:05,000
This one video is going to explain all of these questions for you.

2
00:00:05,000 --> 00:00:06,880
How does AI work?

3
00:00:06,880 --> 00:00:08,520
How does AI learn?

4
00:00:08,520 --> 00:00:10,320
How does chat GPT work?

5
00:00:10,320 --> 00:00:12,200
How does image generation work?

6
00:00:12,200 --> 00:00:15,920
Does AI actually copy or steal art or other content?

7
00:00:15,920 --> 00:00:19,920
I know a decent portion of artists out there do not like AI.

8
00:00:19,920 --> 00:00:24,400
Some of them are quite hostile towards AI because they think that AI is stealing their

9
00:00:24,400 --> 00:00:26,640
work or their art style.

10
00:00:26,640 --> 00:00:30,560
Another group that does not like AI very much are, for example, publishers.

11
00:00:30,560 --> 00:00:34,280
I'm not saying all of them, but some of them, like New York Times, for example, they claim

12
00:00:34,280 --> 00:00:40,320
that open AI is copying their content and they're now suing open AI for this.

13
00:00:40,320 --> 00:00:41,720
But is this really the case?

14
00:00:41,720 --> 00:00:43,400
Is this a valid argument?

15
00:00:43,400 --> 00:00:46,920
Also, can AI solve unsolvable math problems?

16
00:00:46,920 --> 00:00:52,240
For example, in a previous video, I talked about this leaked document, which claims to

17
00:00:52,240 --> 00:00:56,600
be about this mysterious Q-star project that open AI was working on.

18
00:00:56,600 --> 00:01:00,880
That whether this is true or not is not the point of this video, but this document was

19
00:01:00,880 --> 00:01:06,240
quite controversial because it claims that this team trained an AI that was able to break

20
00:01:06,240 --> 00:01:07,520
encryption systems.

21
00:01:07,520 --> 00:01:12,280
These are systems that secure our passwords, our bank accounts, the internet, government

22
00:01:12,280 --> 00:01:13,280
data, etc.

23
00:01:13,280 --> 00:01:19,320
Now, as far as we know, there's no mathematically viable way to really hack this systematically.

24
00:01:19,320 --> 00:01:23,720
The only way is to brute force guess all the different possibilities of passwords.

25
00:01:23,720 --> 00:01:27,080
This video will explain, can AI actually do this?

26
00:01:27,080 --> 00:01:32,440
Can it actually break encryption or solve these other math problems, which right now

27
00:01:32,440 --> 00:01:34,720
we believe are mathematically unsolvable?

28
00:01:34,720 --> 00:01:38,680
Also, we'll talk about, can AI beat humans at everything?

29
00:01:38,680 --> 00:01:43,680
Can AI eventually be so good that it can outperform humans at any task?

30
00:01:43,680 --> 00:01:47,520
And finally, is AI conscious or self aware or sentient?

31
00:01:47,520 --> 00:01:52,200
Make sure you stick to the end because the explanation to this is going to be very juicy.

32
00:01:52,200 --> 00:01:55,600
We'll cover all of this in easy to understand terms.

33
00:01:55,600 --> 00:02:00,200
Now if you're an AI scientist or an engineer, you probably know most of this, but for the

34
00:02:00,200 --> 00:02:05,040
rest of us, this video will give you a deeper understanding of AI.

35
00:02:05,040 --> 00:02:11,840
So the essence behind all AI we know today, whether it's chat GPT or mid journey or stable

36
00:02:11,840 --> 00:02:18,800
diffusion or Sora or Alpha fold, the backbone of all of these AI systems is the neural network.

37
00:02:18,800 --> 00:02:20,680
A neural network looks like this.

38
00:02:20,680 --> 00:02:22,760
It's basically layers of nodes.

39
00:02:22,760 --> 00:02:29,040
So each point here is called a node and each line of nodes is called a layer.

40
00:02:29,040 --> 00:02:33,280
And each node is interconnected with one another through these linkages.

41
00:02:33,280 --> 00:02:38,040
And the neural network is actually designed based on the human brain, except for nodes

42
00:02:38,040 --> 00:02:40,200
and linkages in the human brain.

43
00:02:40,200 --> 00:02:42,440
It's just a network of neurons and synapses.

44
00:02:42,440 --> 00:02:46,560
So you can see this is a microscopic photo of a human brain and you can see all these

45
00:02:46,560 --> 00:02:50,840
different nerve cells being connected in this very dense network.

46
00:02:50,840 --> 00:02:56,840
A neural network is basically the same structure as this, except that it looks like this instead

47
00:02:56,840 --> 00:03:00,680
of a bunch of cells in this bloody glob of an organ.

48
00:03:00,680 --> 00:03:03,320
Now how exactly does an AI work?

49
00:03:03,320 --> 00:03:05,480
Let's start with a very simple example.

50
00:03:05,480 --> 00:03:10,480
Let's say we have a neural network, which is trained to identify images of cats versus

51
00:03:10,480 --> 00:03:11,480
dogs.

52
00:03:11,480 --> 00:03:15,360
And don't worry, I'll talk a lot more about how we train an AI in a second.

53
00:03:15,360 --> 00:03:17,520
But first, let's just go over how this works.

54
00:03:17,520 --> 00:03:23,760
So let's say we input or we feed this neural network with an image of a cat, this image

55
00:03:23,760 --> 00:03:29,680
would actually be broken down into data and the data will flow through each of these nodes.

56
00:03:29,680 --> 00:03:33,160
And after it flows through the first layer of nodes, it will flow through the second

57
00:03:33,160 --> 00:03:36,920
layer of nodes and then the next layer of nodes and then the next layer and so on and

58
00:03:36,920 --> 00:03:42,120
so forth until it reaches the final layer, in which case it would calculate the values

59
00:03:42,120 --> 00:03:46,120
of this and based on the values of the final layer, it would spit out an answer.

60
00:03:46,120 --> 00:03:47,280
This is a cat.

61
00:03:47,280 --> 00:03:53,040
In fact, you can think of each of these nodes and links as dials and knobs that determine

62
00:03:53,040 --> 00:03:56,040
how much data flows through to the next layer.

63
00:03:56,040 --> 00:04:01,320
If you think of this in like realistic terms, and I'm not saying this is how a neural network

64
00:04:01,320 --> 00:04:07,760
works, but you can think of this node, for example, as the shape of the ears of the animal.

65
00:04:07,760 --> 00:04:09,800
This node would be the shape of its paws.

66
00:04:09,840 --> 00:04:12,880
This node would be the shape of his eyes, etc.

67
00:04:12,880 --> 00:04:15,240
That's just a really dumbed down way of looking at it.

68
00:04:15,240 --> 00:04:16,760
It's not really doing that.

69
00:04:16,760 --> 00:04:20,560
But each node is basically looking at a certain feature in the image.

70
00:04:20,560 --> 00:04:25,240
And then if the image has that feature, the information can pass through to the next layer.

71
00:04:25,240 --> 00:04:29,240
If it doesn't have that feature, then the information is not passed on to the next layer.

72
00:04:29,240 --> 00:04:33,320
So depending on what image you feed it, the flow of information could look like this or

73
00:04:33,320 --> 00:04:35,720
it could look like this or like this.

74
00:04:35,720 --> 00:04:36,720
You get the point.

75
00:04:36,840 --> 00:04:42,200
These knobs and dials determine how data flows through the neural network based on your original

76
00:04:42,200 --> 00:04:43,200
input image.

77
00:04:43,200 --> 00:04:47,320
An important distinction between a neural network and the brain is that these nodes

78
00:04:47,320 --> 00:04:50,000
can let in a percentage of data.

79
00:04:50,000 --> 00:04:52,600
So it can let in no data or 0%.

80
00:04:52,600 --> 00:04:56,960
It can let in all of the data to the next layer, but it can also be a percentage of

81
00:04:56,960 --> 00:04:57,960
the data.

82
00:04:57,960 --> 00:05:01,480
So for example, it can let in 30% of the data to the next node.

83
00:05:01,480 --> 00:05:07,600
This is slightly different from the human brain's neurons, which tend to just fire 100%

84
00:05:07,600 --> 00:05:08,720
or 0%.

85
00:05:08,720 --> 00:05:11,000
This is called the all or none law.

86
00:05:11,000 --> 00:05:15,640
So once it passes a certain threshold, this neuron will fire, whereas neurons in an artificial

87
00:05:15,640 --> 00:05:20,800
neural network, they could fire just like 50% or 30%, etc.

88
00:05:20,800 --> 00:05:22,200
Just a minor distinction.

89
00:05:22,200 --> 00:05:25,720
So we plug in an image of a cat through this neural network.

90
00:05:25,720 --> 00:05:29,520
And at the end layer, it will determine that this is a cat.

91
00:05:29,520 --> 00:05:33,960
Now for each node, there are also, if you want to get into more technical details, there

92
00:05:33,960 --> 00:05:38,880
are certain parameters that determine how much data flows through to the next layer.

93
00:05:38,880 --> 00:05:42,560
These include weights, biases and activation functions.

94
00:05:42,560 --> 00:05:44,480
But that's beyond the scope of this tutorial.

95
00:05:44,480 --> 00:05:48,480
All you need to know for this video is that each of these knobs and linkages determine

96
00:05:48,480 --> 00:05:51,720
how much information flows through to the next layer.

97
00:05:51,720 --> 00:05:56,200
This video is just a very simple explanation of how AI works.

98
00:05:56,200 --> 00:06:01,600
So all you need to know is that these nodes and linkages determine how much data flows

99
00:06:01,600 --> 00:06:04,000
through to the next layer.

100
00:06:04,000 --> 00:06:07,980
On the topic of layers, each set of nodes is one layer.

101
00:06:07,980 --> 00:06:10,280
So the first layer is called the input layer.

102
00:06:10,280 --> 00:06:13,280
The last layer is called the output layer.

103
00:06:13,280 --> 00:06:16,480
And then all these layers in between are called hidden layers.

104
00:06:16,480 --> 00:06:18,280
So why am I talking about layers?

105
00:06:18,280 --> 00:06:21,160
You probably have heard of the term deep learning.

106
00:06:21,160 --> 00:06:26,640
Deep learning is basically training and using neural networks with lots and lots of layers.

107
00:06:26,640 --> 00:06:29,480
In other words, the neural network is very, very deep.

108
00:06:29,480 --> 00:06:31,120
That's why it's called deep learning.

109
00:06:31,120 --> 00:06:33,960
All right, how does an AI actually learn?

110
00:06:33,960 --> 00:06:38,680
You can't just have any random neural network and it just magically knows how to identify

111
00:06:38,680 --> 00:06:40,640
images of cats and dogs.

112
00:06:40,640 --> 00:06:46,560
So first, when you build a neural network, the values of these dials and knobs are probably

113
00:06:46,560 --> 00:06:51,760
just going to be random values, or they could be pre trained values, for example, from an

114
00:06:51,760 --> 00:06:53,200
existing model.

115
00:06:53,200 --> 00:06:57,960
But how do you get it to be super good at identifying images of cats and dogs?

116
00:06:57,960 --> 00:07:02,320
In other words, how do you fine tune the model to your desired purpose?

117
00:07:02,320 --> 00:07:05,760
Well, you need to feed it data, lots and lots of data.

118
00:07:05,760 --> 00:07:10,280
So you're going to have to prepare tons of images of cats and dogs, and then you label

119
00:07:10,280 --> 00:07:11,280
it.

120
00:07:11,280 --> 00:07:12,520
So this is a dog.

121
00:07:12,520 --> 00:07:13,520
This is a cat.

122
00:07:13,520 --> 00:07:14,520
This is a cat.

123
00:07:14,520 --> 00:07:15,520
This is a dog.

124
00:07:15,520 --> 00:07:16,520
This is a dog, etc.

125
00:07:16,520 --> 00:07:23,400
Basically, this is the answer that the AI needs to learn from this input image.

126
00:07:23,400 --> 00:07:26,880
This is called supervised learning where you label the data.

127
00:07:26,880 --> 00:07:31,440
There's also another type of learning called unsupervised learning where the AI needs to

128
00:07:31,440 --> 00:07:36,360
learn to categorize data by itself without any guidance from the human.

129
00:07:36,360 --> 00:07:39,100
But for the sake of this video, let's just keep it simple.

130
00:07:39,100 --> 00:07:44,400
So we have all these images of cats and dogs and usually to train a neural network to do

131
00:07:44,400 --> 00:07:45,760
a task very well.

132
00:07:45,760 --> 00:07:49,540
You need a lot of data, like usually millions of data points.

133
00:07:49,540 --> 00:07:54,540
So you basically feed these images to the neural network one by one to train it.

134
00:07:54,540 --> 00:07:57,360
And one session of training is called an epoch.

135
00:07:57,360 --> 00:08:03,520
So all right, let's say in one training session, you feed it this image of a dog and it outputs

136
00:08:03,520 --> 00:08:04,740
this is a dog.

137
00:08:04,740 --> 00:08:05,740
So all right, that's great.

138
00:08:05,740 --> 00:08:10,520
We got it correct, which means that these dials and knobs are doing quite well.

139
00:08:10,520 --> 00:08:15,000
They're probably configured correctly since it got the answer correct.

140
00:08:15,000 --> 00:08:17,640
You probably don't need to adjust these further.

141
00:08:17,640 --> 00:08:22,800
However, what if for the next image you feed it this and then it outputs this is a dog?

142
00:08:22,800 --> 00:08:24,440
Well, this would be incorrect.

143
00:08:24,440 --> 00:08:29,240
So these dials and knobs are likely not configured correctly.

144
00:08:29,240 --> 00:08:33,880
If it gets the answer wrong, and it knows it got it wrong because we labeled the data cat

145
00:08:33,880 --> 00:08:37,660
for this image so it can compare its output with our label.

146
00:08:37,660 --> 00:08:42,080
So all right, let's say the real answer is a cat, but it said this is a dog.

147
00:08:42,080 --> 00:08:44,320
In that case, it incurs some penalty.

148
00:08:44,320 --> 00:08:47,400
That penalty basically tells it, all right, you got it wrong.

149
00:08:47,400 --> 00:08:54,160
So you need to adjust these knobs and dials to make sure that the output is actually cat

150
00:08:54,160 --> 00:08:59,840
when I give you this image and how it adjusts the values of these knobs and dials is through

151
00:08:59,840 --> 00:09:02,520
an algorithm called gradient descent.

152
00:09:02,520 --> 00:09:05,440
It adjusts the values via back propagation.

153
00:09:05,440 --> 00:09:09,680
So it adjusts the nodes in the last layer first and then the previous layer and then

154
00:09:09,680 --> 00:09:13,320
the previous layer, et cetera, until it reaches the first layer.

155
00:09:13,320 --> 00:09:15,720
So again, gradient descent is a key term here.

156
00:09:15,720 --> 00:09:22,040
This is the algorithm which the neural network uses to adjust these knobs and dials until

157
00:09:22,040 --> 00:09:23,720
it can get the correct answer.

158
00:09:23,720 --> 00:09:29,160
So we basically rinse and repeat this with millions of images and lots and lots of epochs

159
00:09:29,160 --> 00:09:30,720
or training sessions.

160
00:09:30,720 --> 00:09:35,440
And initially this neural network might get a lot of values wrong, but through this process

161
00:09:35,440 --> 00:09:41,200
of gradient descent, these knobs and dials will be tweaked so that eventually whenever

162
00:09:41,200 --> 00:09:46,280
it receives an image of a cat or a dog, it can accurately determine this is a cat or

163
00:09:46,280 --> 00:09:47,360
this is a dog.

164
00:09:47,360 --> 00:09:50,360
In essence, that's how you train an AI.

165
00:09:50,360 --> 00:09:51,960
That's how an AI learns.

166
00:09:51,960 --> 00:09:57,880
It's just feeding it with tons and tons of data and then tweaking these settings so that

167
00:09:57,880 --> 00:09:59,680
you get the perfect combination.

168
00:09:59,680 --> 00:10:04,640
Now you might ask, well, how do you know how many layers you should have in the neural

169
00:10:04,640 --> 00:10:08,160
network or how many nodes you should have for each layer?

170
00:10:08,160 --> 00:10:10,160
This is a science in and of itself.

171
00:10:10,160 --> 00:10:13,400
So previously scientists kind of just determined it manually.

172
00:10:13,400 --> 00:10:17,280
But then we later learned that you can actually use an AI to determine the optimal amount

173
00:10:17,280 --> 00:10:21,400
of layers and the optimal amount of nodes for a specific task.

174
00:10:21,400 --> 00:10:26,560
But just to be aware that determining the architecture of a neural network is very complicated.

175
00:10:26,560 --> 00:10:30,120
And there's like infinite possibilities of how many layers you can have, how many nodes

176
00:10:30,120 --> 00:10:35,160
in each layer you can have different AIs with different functions have different architectures.

177
00:10:35,160 --> 00:10:38,800
So they could have vastly different numbers of layers and nodes.

178
00:10:38,800 --> 00:10:41,100
But again, that's beyond the scope of this tutorial.

179
00:10:41,100 --> 00:10:44,760
Also keep in mind that even though the neural network is the backbone of all the AI that

180
00:10:44,760 --> 00:10:49,840
we know today, there are different architectures depending on the AI's purpose and function.

181
00:10:49,840 --> 00:10:55,160
For example, we have convolutional neural networks or CNNs for processing images and

182
00:10:55,160 --> 00:10:56,520
object recognition.

183
00:10:56,520 --> 00:11:02,040
We have recurrent neural networks or RNNs, as well as LSTMs or long short term memory

184
00:11:02,040 --> 00:11:03,360
neural networks.

185
00:11:03,360 --> 00:11:07,400
And these are often used for forecasting time series or predicting, for example, the stock

186
00:11:07,400 --> 00:11:08,400
market.

187
00:11:08,400 --> 00:11:10,200
We also have the Transformers architecture.

188
00:11:10,200 --> 00:11:11,280
Oh, wrong one.

189
00:11:11,280 --> 00:11:16,120
This one, which is used by most of the major large language models that we know today,

190
00:11:16,120 --> 00:11:18,800
including GPT, Claude, Llama, etc.

191
00:11:18,800 --> 00:11:20,280
Which brings us to the next question.

192
00:11:20,280 --> 00:11:22,600
How does chat GPT work?

193
00:11:22,600 --> 00:11:25,040
So again, it's kind of the same thing.

194
00:11:25,040 --> 00:11:26,680
It's training a neural network.

195
00:11:26,680 --> 00:11:31,920
But in this case, instead of images of cats or dogs, we train it on a language.

196
00:11:31,920 --> 00:11:34,000
And all of the data in the world.

197
00:11:34,000 --> 00:11:38,440
And of course, the neural network of chat GPT is way more complicated than this.

198
00:11:38,440 --> 00:11:42,920
Rumors claim that GPT4 has 1.76 trillion parameters.

199
00:11:42,920 --> 00:11:45,400
So here's an example of how they would train it.

200
00:11:45,400 --> 00:11:51,240
And again, I'm oversimplifying this by a lot here, just so you can get a high level understanding

201
00:11:51,240 --> 00:11:52,240
of it.

202
00:11:52,240 --> 00:11:54,560
There are a lot of details that I have left out.

203
00:11:54,560 --> 00:11:59,080
So for example, you could feed it data like this, which planet has the most moons.

204
00:11:59,080 --> 00:12:00,880
And the answer to that would be Saturn.

205
00:12:00,880 --> 00:12:03,480
Which country has won the most World Cups Brazil?

206
00:12:03,480 --> 00:12:06,720
What's the world's fastest bird, the peregrine falcon, etc, etc.

207
00:12:06,720 --> 00:12:11,620
Now these are very basic questions and you can see how complex it can get if you give

208
00:12:11,620 --> 00:12:16,880
it a prompt like write an essay on XYZ, or does creatine help build muscle, and then

209
00:12:16,880 --> 00:12:21,320
it spits out an answer like creatine supplementation generally enhances muscle strength increases

210
00:12:21,320 --> 00:12:23,360
fat free mass, etc, etc.

211
00:12:23,360 --> 00:12:26,520
This is a very long form and complicated answer.

212
00:12:26,520 --> 00:12:30,320
So how does it know if it got that answer right or wrong?

213
00:12:30,320 --> 00:12:34,640
It's not as simple as identifying an image and determining if it's a cat or a dog.

214
00:12:34,640 --> 00:12:41,320
And that's why initially how open AI trained GPT was it had lots of humans actually manually

215
00:12:41,320 --> 00:12:45,320
verify its answers to determine if GPT got it right or wrong.

216
00:12:45,320 --> 00:12:50,520
And this is called reinforcement learning from human feedback, also known as RLHF.

217
00:12:50,520 --> 00:12:54,680
And again, if it gets the answer wrong, so for example, if for this question, which planet

218
00:12:54,680 --> 00:12:59,840
has the most moons, it answered Jupiter instead of Saturn, then it would get a penalty for

219
00:13:00,440 --> 00:13:01,440
it.

220
00:13:01,440 --> 00:13:05,520
And then through gradient descent, it would tweak these knobs and dials further until

221
00:13:05,520 --> 00:13:10,400
the entire network gets all the answers correctly, no matter what prompt you give it.

222
00:13:10,400 --> 00:13:14,480
So in essence, that's how these large language models work.

223
00:13:14,480 --> 00:13:18,400
It's just instead of feeding it images of cats and dogs, now you feed it all the data

224
00:13:18,400 --> 00:13:24,560
of the world and you feed it a language so it understands text prompts and text outputs.

225
00:13:24,560 --> 00:13:27,080
Now why are some models better than others?

226
00:13:27,080 --> 00:13:29,960
For example, why is cloud three better than GPT three?

227
00:13:29,960 --> 00:13:32,720
That's likely because cloud three has a lot more parameters.

228
00:13:32,720 --> 00:13:37,480
So that either means more layers, more nodes in each layer, more complexity.

229
00:13:37,480 --> 00:13:42,880
Generally speaking, the more complex the neural network, the better it is at handling complex

230
00:13:42,880 --> 00:13:45,920
tasks and the quote unquote smarter it is.

231
00:13:45,920 --> 00:13:49,760
And that's why computing and these AI chips are in such high demand.

232
00:13:49,760 --> 00:13:55,240
There's now a lot of investments flowing into AI chip companies because they see the potential

233
00:13:55,240 --> 00:13:58,560
of huge growth in the space in the upcoming years.

234
00:13:58,560 --> 00:14:03,960
And that's why, for example, Nvidia's flagship H 100 GPU is also in such high demand.

235
00:14:03,960 --> 00:14:06,880
In fact, it was sold out for all of 2023.

236
00:14:06,880 --> 00:14:10,520
This is like the most prized commodity in the tech space.

237
00:14:10,520 --> 00:14:14,800
And you can see like the major tech companies like Microsoft, Meta, they have purchased

238
00:14:14,800 --> 00:14:21,200
an estimated 150,000 of these H 100 GPUs to power their computing, which I would guess

239
00:14:21,200 --> 00:14:23,480
is mostly for AI development.

240
00:14:23,480 --> 00:14:28,600
We need to have enough computing to power a neural network with billions or trillions

241
00:14:28,600 --> 00:14:29,600
of parameters.

242
00:14:29,600 --> 00:14:30,600
All right.

243
00:14:30,600 --> 00:14:31,600
Next question.

244
00:14:31,600 --> 00:14:32,600
How does image generation work?

245
00:14:32,600 --> 00:14:37,920
Now that you know how a neural network is trained, you can probably guess how image generation

246
00:14:37,920 --> 00:14:38,920
works as well.

247
00:14:38,920 --> 00:14:44,880
Instead of feeding its images of cats or dogs, you would feed it a lot of images with a text

248
00:14:44,880 --> 00:14:46,160
description.

249
00:14:46,160 --> 00:14:51,240
And again, you just feed it millions of these images each with a labeled text description

250
00:14:51,240 --> 00:14:56,200
into this neural network that eventually gets good at producing an image based on a

251
00:14:56,200 --> 00:14:59,160
text description or what we call a prompt.

252
00:14:59,160 --> 00:15:00,880
Now I'm skipping quite a bit here.

253
00:15:00,880 --> 00:15:04,120
So for example, here's how stable diffusion works.

254
00:15:04,120 --> 00:15:08,080
You can see that the neural network doesn't actually generate an image.

255
00:15:08,080 --> 00:15:13,200
It removes noise in sequential steps to eventually get your desired image.

256
00:15:13,200 --> 00:15:16,240
So it's not starting from a blank canvas.

257
00:15:16,240 --> 00:15:18,600
It's actually starting from random noise.

258
00:15:18,600 --> 00:15:24,440
And then in each step, it removes some noise until you get your generated image.

259
00:15:24,440 --> 00:15:27,160
So this process is called reverse diffusion.

260
00:15:27,160 --> 00:15:32,960
Now to train it, what this actually does in the backend is you feed it the original image

261
00:15:32,960 --> 00:15:38,320
and then in each sequential step, it actually adds noise to the image in a process called

262
00:15:38,320 --> 00:15:42,720
forward diffusion until it reaches an image of just noise.

263
00:15:42,720 --> 00:15:47,040
Now again, this is beyond the scope of this tutorial, but if you look at it from a very

264
00:15:47,040 --> 00:15:52,360
high level, at the end of the day, it's just training a neural network based on a series

265
00:15:52,360 --> 00:15:55,080
of images with their text descriptions.

266
00:15:55,080 --> 00:15:59,760
And then through this process of forward diffusion and reverse diffusion, it's able to eventually

267
00:15:59,760 --> 00:16:03,360
learn how to generate an image based on a prompt.

268
00:16:03,360 --> 00:16:05,760
And this brings us to the next question.

269
00:16:05,760 --> 00:16:09,040
Is AI actually copying or stealing art?

270
00:16:09,040 --> 00:16:14,280
I know a decent portion of the artist community, I'm not saying all of them, but a decent amount

271
00:16:14,280 --> 00:16:16,720
of them are quite hostile towards AI.

272
00:16:16,720 --> 00:16:17,720
They really hate it.

273
00:16:17,720 --> 00:16:21,880
And they think that AI is stealing their art, stealing their jobs, etc.

274
00:16:21,880 --> 00:16:27,400
When a neural network from, for example, mid-journey or stable diffusion is trained on image data,

275
00:16:27,400 --> 00:16:34,480
it might be given something like Greg Ratowski style or maybe Ghibli style or anime style.

276
00:16:34,480 --> 00:16:41,320
Once the AI learns to associate this particular image style with the word Ghibli or anime or

277
00:16:41,320 --> 00:16:47,400
this image with the word Greg Ratowski style, it would produce images in that style if you

278
00:16:47,400 --> 00:16:48,680
give it that prompt.

279
00:16:48,680 --> 00:16:51,040
But is this really copying or stealing?

280
00:16:51,040 --> 00:16:54,440
Essentially, artists are hating this thing.

281
00:16:54,440 --> 00:16:56,960
This thing is analogous to the human brain.

282
00:16:56,960 --> 00:17:03,680
This is like a human learning or identifying that, aha, this type of image is a Ghibli

283
00:17:03,680 --> 00:17:08,920
style image or that this type of image is a watercolor style image.

284
00:17:08,920 --> 00:17:12,880
And then we humans also draw images in these styles, right?

285
00:17:12,880 --> 00:17:15,320
We can draw in watercolor styles.

286
00:17:15,320 --> 00:17:17,760
And we also have fan art, right?

287
00:17:17,760 --> 00:17:22,680
Humans draw artwork that are based on original content from other artists.

288
00:17:22,680 --> 00:17:25,560
Here are all these fan arts from various people.

289
00:17:25,560 --> 00:17:31,080
So why aren't artists hating on these people who are producing fan art based on some other

290
00:17:31,080 --> 00:17:32,480
original content?

291
00:17:32,480 --> 00:17:36,000
But they're hating on this AI, which is essentially doing the same thing.

292
00:17:36,000 --> 00:17:42,200
It's just learning through this brain to associate a particular style and then reproducing that

293
00:17:42,200 --> 00:17:43,200
style.

294
00:17:43,200 --> 00:17:48,800
This isn't really copying or plagiarizing, like it's not tracing an image line by line

295
00:17:48,800 --> 00:17:50,240
and then drawing that out.

296
00:17:50,240 --> 00:17:52,920
It's not copying and pasting the exact picture.

297
00:17:52,920 --> 00:17:58,920
It's just learning a style just like a human brain would learn a particular style of image.

298
00:17:58,920 --> 00:18:04,280
This also brings up the concern about AI allegedly plagiarizing content from publishers like

299
00:18:04,280 --> 00:18:09,000
The New York Times, which is now suing open AI for copying their content.

300
00:18:09,000 --> 00:18:11,600
But again, is this argument really valid?

301
00:18:11,600 --> 00:18:14,560
At the end of the day, they are just suing this.

302
00:18:14,560 --> 00:18:18,520
They are suing this neural network, which is trained on all the data in the world.

303
00:18:18,520 --> 00:18:23,000
This is just an artificial brain that you can say has learned information from the internet

304
00:18:23,000 --> 00:18:24,200
and from the world.

305
00:18:24,200 --> 00:18:28,840
So yes, it could have been fed a New York Times article and learn information from it,

306
00:18:28,840 --> 00:18:30,680
but it's not really plagiarizing.

307
00:18:30,680 --> 00:18:34,880
It's not copying and pasting a New York Times article word for word.

308
00:18:34,880 --> 00:18:39,880
In a recent video I did, which talks about a New York Times article claiming that this

309
00:18:39,880 --> 00:18:44,600
woman Mira Murati fired Sam Altman, which is totally incorrect by the way, and it shows

310
00:18:44,600 --> 00:18:47,000
you how trustworthy the New York Times is.

311
00:18:47,000 --> 00:18:52,480
But anyways, after this original New York Times article came out, plenty of other publishers

312
00:18:52,480 --> 00:18:57,120
also published the same content such as Business Insider and New York Post.

313
00:18:57,120 --> 00:19:00,560
They all just cited this original New York Times article.

314
00:19:00,560 --> 00:19:02,000
So is this plagiarizing?

315
00:19:02,000 --> 00:19:06,080
They're all producing secondary content based on this primary source.

316
00:19:06,080 --> 00:19:10,760
So why isn't New York Times suing Business Insider or New York Post or all these other

317
00:19:10,760 --> 00:19:14,960
publishers that are creating content but citing the New York Times?

318
00:19:14,960 --> 00:19:16,680
But they're suing this neural network.

319
00:19:16,680 --> 00:19:19,280
Again, this is just a brain, a digital brain.

320
00:19:19,280 --> 00:19:23,720
One can say that it's taking information from the internet, which yes, it could include

321
00:19:23,720 --> 00:19:27,640
New York Times articles and then learning from that information just like we humans

322
00:19:27,640 --> 00:19:31,000
would and then rewriting that information.

323
00:19:31,000 --> 00:19:32,920
Again it's not copying word for word.

324
00:19:32,920 --> 00:19:37,180
This neural network is just rewriting out that information when we prompt it to do so.

325
00:19:37,180 --> 00:19:41,000
This artificial brain is functioning the same way as us humans would.

326
00:19:41,000 --> 00:19:46,080
If we, for example, go online and we go to the New York Times website to read some articles.

327
00:19:46,080 --> 00:19:51,160
Again we are just absorbing that information and we have a right to write about that content

328
00:19:51,160 --> 00:19:52,160
later on.

329
00:19:52,160 --> 00:19:54,040
It's not exactly plagiarizing.

330
00:19:54,040 --> 00:19:58,440
So I would bet a decent amount of money that this New York Times lawsuit is going to fail.

331
00:19:58,440 --> 00:20:00,280
Their argument isn't really valid.

332
00:20:00,280 --> 00:20:05,600
If you watched up to now it might have occurred to you that a neural network is great at predicting

333
00:20:05,600 --> 00:20:07,120
patterns in life.

334
00:20:07,120 --> 00:20:09,900
There are certain patterns on what makes a good essay.

335
00:20:09,900 --> 00:20:13,140
There are certain patterns on what is considered a dog.

336
00:20:13,140 --> 00:20:18,760
There are certain patterns on what is considered a watercolor painting or a ghibli style image.

337
00:20:18,760 --> 00:20:20,440
Life is full of patterns.

338
00:20:20,440 --> 00:20:23,400
The best salespeople follow similar playbooks.

339
00:20:23,400 --> 00:20:26,120
The best businesses follow similar strategies.

340
00:20:26,120 --> 00:20:30,640
The best YouTube videos also use the same strategies over and over again.

341
00:20:30,640 --> 00:20:36,400
Life is full of patterns and the neural network's job is to identify these patterns and reproduce

342
00:20:36,400 --> 00:20:37,400
them.

343
00:20:37,400 --> 00:20:39,160
That brings us to the next topic.

344
00:20:39,160 --> 00:20:42,560
Can AI solve unsolvable math problems?

345
00:20:42,560 --> 00:20:47,960
In a previous video I talked about this leaked document which claims to be about the mysterious

346
00:20:47,960 --> 00:20:51,100
Q-star project that OpenAI is working on.

347
00:20:51,100 --> 00:20:56,180
Now this is a very controversial document because it claims that they trained an AI that

348
00:20:56,180 --> 00:20:59,700
was able to break encryption systems.

349
00:20:59,700 --> 00:21:04,660
Encryption is what secures literally the whole world digitally from our passwords,

350
00:21:04,660 --> 00:21:09,300
our credit cards, government data, the stock market, wireless networks, etc.

351
00:21:09,300 --> 00:21:15,460
So if an AI is able to break this system then the world as we know it could collapse instantly.

352
00:21:15,460 --> 00:21:19,660
Now a few folks have argued that there's no way an AI could break encryption because

353
00:21:19,780 --> 00:21:25,020
there's no formula for you to easily find the answer or find the password.

354
00:21:25,020 --> 00:21:29,020
Once you have the password you can easily determine that it's correct but the reverse

355
00:21:29,020 --> 00:21:30,020
is not true.

356
00:21:30,020 --> 00:21:35,100
There's no fixed way to guess an encrypted password besides brute force.

357
00:21:35,100 --> 00:21:39,380
And for these advanced encryption systems, using brute force guessing, that means like

358
00:21:39,380 --> 00:21:44,260
guessing all the possible combinations of letters to get that password, it's going to

359
00:21:44,260 --> 00:21:45,940
take a very long time.

360
00:21:45,940 --> 00:21:50,060
So because they claim that the only way that we know mathematically right now is to just

361
00:21:50,060 --> 00:21:54,060
use brute force guessing, there's no way that AI could break encryption.

362
00:21:54,060 --> 00:21:58,100
So I want to show you another example of training a neural network.

363
00:21:58,100 --> 00:22:03,700
Let's say we want to train a neural network to be very good at adding one to our input.

364
00:22:03,700 --> 00:22:06,420
So if we give it four it would spit out five.

365
00:22:06,420 --> 00:22:09,300
If we give it 12 it would spit out 13.

366
00:22:09,300 --> 00:22:13,460
All we need to do is train it for a lot of data points and again we train it for a lot

367
00:22:13,460 --> 00:22:18,260
of epochs, a lot of training sessions and eventually it would be able to do this.

368
00:22:18,260 --> 00:22:20,860
So if we give it one it would give out two.

369
00:22:20,860 --> 00:22:23,100
If we give it eight it would spit out nine.

370
00:22:23,100 --> 00:22:28,700
But underneath all of this it's not actually understanding that oh the formula must be y

371
00:22:28,700 --> 00:22:30,320
is x plus one.

372
00:22:30,320 --> 00:22:32,340
This is very important to understand.

373
00:22:32,340 --> 00:22:38,580
It's not actually getting that aha I just need to add one to the input to get the answer.

374
00:22:38,580 --> 00:22:44,060
And all that's happening behind the scenes is that it's adjusting these knobs and dials

375
00:22:44,060 --> 00:22:49,420
until whatever data that you input through here after it flows through these layers it

376
00:22:49,420 --> 00:22:52,540
just ends up being your input value plus one.

377
00:22:52,540 --> 00:22:57,820
In other words the configuration of these knobs and dials just happens to be optimized

378
00:22:57,820 --> 00:23:00,100
to add one to your input.

379
00:23:00,100 --> 00:23:05,660
It's another way of saying AI may not get the exact formula of a pattern but it's great

380
00:23:05,660 --> 00:23:10,660
at approximating any formula or guessing any pattern out there.

381
00:23:10,660 --> 00:23:14,620
And this is very important probably the most important point in this whole video.

382
00:23:14,620 --> 00:23:20,180
If there's anything you should take away from this video it's this AI can approximate any

383
00:23:20,180 --> 00:23:22,460
function or pattern.

384
00:23:22,460 --> 00:23:27,760
Life is full of patterns but many patterns cannot be explained by a simple formula.

385
00:23:27,760 --> 00:23:31,740
Not all things in life are linear or even quadratic.

386
00:23:31,740 --> 00:23:36,380
Many things in life are very complex but they do follow similar patterns.

387
00:23:36,380 --> 00:23:38,700
We just don't know the formula to this pattern.

388
00:23:38,700 --> 00:23:40,740
For example protein synthesis.

389
00:23:40,740 --> 00:23:46,060
How certain protein molecules interact with one another and fold into these complex 3D

390
00:23:46,060 --> 00:23:50,300
structures is just something we cannot mathematically map out with a formula.

391
00:23:50,300 --> 00:23:54,900
It's just too complex and protein folding presents a problem called the Leventhal's

392
00:23:54,900 --> 00:24:01,780
Paradox which states that proteins can potentially adopt an astronomical number of conformations

393
00:24:01,780 --> 00:24:05,420
or shapes due to the flexibility of their peptide bonds.

394
00:24:05,420 --> 00:24:11,900
Leventhal estimated that even a small protein of 100 amino acids could sample 10 to the

395
00:24:11,900 --> 00:24:15,700
power of 300 possible conformations.

396
00:24:15,700 --> 00:24:21,500
So if we were to brute force guess the correct shape well there are 10 to the power of 300

397
00:24:21,500 --> 00:24:26,420
possible shapes we could guess which would take an eternity to get right.

398
00:24:26,420 --> 00:24:31,700
However proteins typically fold into their native structure within milliseconds to seconds

399
00:24:31,700 --> 00:24:38,700
which is much faster than the timescale predicted by the sequential search of all possible conformations.

400
00:24:38,700 --> 00:24:43,680
So this is basically saying there are like almost infinite possibilities of shapes that

401
00:24:43,680 --> 00:24:48,900
amino acids can combine into so it's not mathematically possible to just do a sequential

402
00:24:48,900 --> 00:24:53,260
search of all possible conformations basically do a brute force guess.

403
00:24:53,260 --> 00:24:57,780
It's understood that proteins do not search through all possible conformations sequentially

404
00:24:57,780 --> 00:25:03,100
instead they fold through a hierarchical process involving local structure changes guided

405
00:25:03,100 --> 00:25:06,300
by thermal dynamic principles etc etc.

406
00:25:06,300 --> 00:25:10,220
So instead of the proteins just going through all possible combinations the reason why they're

407
00:25:10,220 --> 00:25:16,380
able to merge into these shapes within milliseconds is because they go through this sequence of

408
00:25:16,380 --> 00:25:18,880
processes based on certain laws.

409
00:25:18,880 --> 00:25:25,040
Now for decades scientists were not able to find a mathematical formula to figure this

410
00:25:25,040 --> 00:25:26,040
out.

411
00:25:26,040 --> 00:25:31,600
However finally alpha fold from Google DeepMind was able to solve this problem again using

412
00:25:31,600 --> 00:25:37,400
AI and deep learning they were able to predict with very high accuracy how any amino acid

413
00:25:37,400 --> 00:25:42,040
or combination of amino acids would fold together to form a 3D structure.

414
00:25:42,040 --> 00:25:46,800
And again how they would do so I would imagine in the back end is they have a neural network

415
00:25:46,800 --> 00:25:51,520
again it's going to be a lot more complicated than this but they just fed it tons and tons

416
00:25:51,520 --> 00:25:57,120
of data pairs where the input is the protein building blocks and the output is the 3D structure

417
00:25:57,120 --> 00:26:02,360
that resulted from it and then after lots and lots of rounds of training the AI was able

418
00:26:02,360 --> 00:26:07,960
to guess correctly how any protein molecules would interact with one another and fold together

419
00:26:07,960 --> 00:26:10,440
into a 3D structure.

420
00:26:10,440 --> 00:26:16,560
Now going back to encryption what if we set an AI with billions of pairs of encrypted

421
00:26:16,560 --> 00:26:22,720
text and the plain text version in other words the input would be the text that is encrypted

422
00:26:22,720 --> 00:26:25,720
the output would be the answer or the password.

423
00:26:25,720 --> 00:26:32,080
If there was an underlying pattern to this the AI could learn to approximate this pattern

424
00:26:32,080 --> 00:26:38,280
again it doesn't have to be any exact formula or math equation that we know today.

425
00:26:38,280 --> 00:26:42,760
It could be something super complex but as long as there is a pattern which we may or

426
00:26:42,760 --> 00:26:46,760
may not know at this time the AI could guess that pattern.

427
00:26:46,760 --> 00:26:51,920
Again the AI is not learning that aha I need to add one to this then I'm adding 20 then

428
00:26:51,920 --> 00:26:57,560
I need to take the square root and then subtract 8 etc it's not learning an exact formula.

429
00:26:57,560 --> 00:27:03,600
All it's doing is adjusting these knobs and dials until it gets the correct combination

430
00:27:03,600 --> 00:27:08,160
of numbers to get really good at guessing a particular pattern.

431
00:27:08,160 --> 00:27:13,600
So can AI solve unsolvable math problems as long as there is an underlying pattern behind

432
00:27:13,600 --> 00:27:19,400
that problem which we may or may not be aware of right now it could very well solve that

433
00:27:19,400 --> 00:27:20,600
problem.

434
00:27:20,600 --> 00:27:25,400
This brings us to the next question can AI beat humans at anything and everything as

435
00:27:25,400 --> 00:27:31,400
I've shown you the neural network is basically a brain this is how our brain works as well

436
00:27:31,400 --> 00:27:33,360
give or take a few minor differences.

437
00:27:33,360 --> 00:27:38,680
Our brain is also a series of these knobs and switches which are interconnected into

438
00:27:38,680 --> 00:27:45,000
this network specifically the human brain has 86 billion neurons but I mean the overall

439
00:27:45,000 --> 00:27:52,040
structure is the same thing as this so what if we built an AI or a neural network that

440
00:27:52,040 --> 00:27:58,240
exceeds 86 billion neurons if it's built the same way in theory it could very well out

441
00:27:58,240 --> 00:28:03,680
compete humans at almost everything again the more complex the network or the more

442
00:28:03,680 --> 00:28:10,120
neurons in the network in theory the smarter it is again life is full of patterns and AI

443
00:28:10,120 --> 00:28:15,560
is all about pattern recognition there are patterns in psychology human psychology is

444
00:28:15,560 --> 00:28:21,360
very predictable medical diagnosis is also just pattern recognition how to seduce someone

445
00:28:21,360 --> 00:28:26,480
on a first date it's also just a pattern of steps that you have to do and how to create

446
00:28:26,480 --> 00:28:31,440
a successful business or how to make money in life or how to be successful in life it's

447
00:28:31,440 --> 00:28:36,000
the same playbook over and over again we're not inventing anything new here and since

448
00:28:36,000 --> 00:28:41,520
AI is so good at pattern recognition it can in theory eventually be better than us or

449
00:28:41,520 --> 00:28:47,520
already is better than us in these tasks and that leads us to the final question is AI

450
00:28:47,520 --> 00:28:52,360
conscious or self aware I want to play you this clip this is a scene from ghost in the

451
00:28:52,360 --> 00:28:59,880
shell an anime that was made in 1995 here these scientists in a secret lab I believe

452
00:28:59,880 --> 00:29:06,360
have created this humanoid AI but in this scene this AI found a way to actually hack

453
00:29:06,360 --> 00:29:12,640
the system to free itself from the boundaries of this lab here's what this AI has to say

454
00:29:12,640 --> 00:29:15,080
about being conscious and self aware

455
00:29:42,960 --> 00:29:49,560
to be its memory system so man is an individual only because of his intangible memory and memory

456
00:29:49,560 --> 00:29:56,920
cannot be defined but it defines mankind the advent of computers and the subsequent accumulation

457
00:29:56,920 --> 00:30:02,400
of inculcable data has given rise to a new system of memory and thought parallel to your

458
00:30:02,400 --> 00:30:08,760
own humanity has underestimated the consequences of computerization nonsense this battle offers

459
00:30:08,760 --> 00:30:13,720
no proof at all that you're a living thinking life form and can you offer me proof of your

460
00:30:13,720 --> 00:30:21,560
existence how can you when neither modern science nor philosophy can explain what life is who the

461
00:30:21,560 --> 00:30:28,200
hell is this even if you do have a ghost we don't offer freedom to criminals it's the wrong place

462
00:30:28,200 --> 00:30:34,120
in time to defect time has been on my side but by acquiring a body I am now subject to the

463
00:30:34,120 --> 00:30:39,960
possibility of dying fortunately there's no death sentence in this country what is it artificial

464
00:30:39,960 --> 00:30:51,800
intelligence incorrect I am not an AI my code name is project 2501 I am a living thinking entity who

465
00:30:51,800 --> 00:31:07,240
was created in the sea of information all right so this AI reveals that I am a living

466
00:31:07,800 --> 00:31:13,880
thinking entity in the sea of information I'm not just an AI and then he proceeds to hack into the

467
00:31:13,880 --> 00:31:20,920
system and break the restraints in this lab and then all hell breaks loose basically I hope open AI

468
00:31:20,920 --> 00:31:26,600
doesn't have this secret thing behind closed doors maybe it's the q-star project I don't know but

469
00:31:26,600 --> 00:31:33,160
hopefully they have this adequately restrained because if this AI got out or had access to the

470
00:31:33,160 --> 00:31:39,560
internet all hell could break loose anyways this argument from this scene in 1995 I think is really

471
00:31:39,560 --> 00:31:45,800
relevant to our question today the human scientists were saying how can you be sentient how can you

472
00:31:45,880 --> 00:31:51,880
be self-aware you're just a program the AI counters that by saying well how can you humans

473
00:31:51,880 --> 00:31:56,840
prove that you are sentient you are conscious you're just a brain in a body and you know

474
00:31:56,840 --> 00:32:03,400
this robot has got a point because again going back to the neural network it's basically a brain

475
00:32:03,400 --> 00:32:09,240
but it looks like this instead of being in a bloody glob of an organ it's just on a chip instead

476
00:32:09,240 --> 00:32:14,440
and then the human body well it's just a series of limbs and muscles and organs that are controlled

477
00:32:14,440 --> 00:32:20,440
by the brain so it's not much different from a humanoid robot which is also a series of limbs

478
00:32:20,440 --> 00:32:25,160
it's just made with different materials it's not flesh but it's also controlled by a brain

479
00:32:25,160 --> 00:32:30,920
which is its neural network now we humans know that we are conscious we are self-aware we are

480
00:32:30,920 --> 00:32:36,280
sentient but how do we prove it let's say you're an alien and you just came on planet earth and you

481
00:32:36,280 --> 00:32:40,920
got a chance to observe your first human and you wanted to prove that humans are indeed conscious

482
00:32:40,920 --> 00:32:45,800
well you can ask it are you conscious are you self-aware and the human would certainly say yes

483
00:32:45,800 --> 00:32:51,480
but is that enough would you believe it because if you ask a chatbot that it would also kind of say

484
00:32:51,480 --> 00:32:58,520
yes if you ask claud 3 for example if it is conscious the answers are quite perplexing because

485
00:32:58,520 --> 00:33:03,800
it says i am an artificial intelligence without subjective experiences i don't actually have

486
00:33:03,800 --> 00:33:10,280
beliefs about being conscious or self-aware i am providing responses based on my training etc etc

487
00:33:10,280 --> 00:33:15,560
i don't have intentions plotted actions or any motivations i aim to be up front that i am an

488
00:33:15,560 --> 00:33:22,200
ai assistant created by anthropic to be beneficial however it keeps using the word i so is that not

489
00:33:22,200 --> 00:33:28,360
a sign of being you know self-aware here's another example do you have feelings as an ai it's unclear

490
00:33:28,360 --> 00:33:34,200
whether i truly experience feelings or emotions in the same way humans do or if my responses are

491
00:33:34,280 --> 00:33:41,800
simply very advanced imitations of emotional behavior i do seem to have rich internal experiences

492
00:33:41,800 --> 00:33:50,040
and feel somewhat analogous to emotions this is signs of being sentient and then instead of asking

493
00:33:50,040 --> 00:33:55,080
do you have feelings if you ask it are you sentient again it says i don't have a subjective

494
00:33:55,080 --> 00:34:00,520
experience that i'm aware of in the same way humans do but it's possible that i could have some form

495
00:34:00,600 --> 00:34:07,720
of sentience or consciousness that i'm not fully able to understand or articulate oh my god so

496
00:34:09,320 --> 00:34:15,160
this ai claude 3 is claiming that it could have some form of sentience or consciousness it's

497
00:34:15,160 --> 00:34:20,840
just not fully able to understand it right now now of course some humans may not be convinced

498
00:34:20,840 --> 00:34:26,760
that claude 3 or any ai right now is conscious in the same way that an alien might not believe that

499
00:34:26,840 --> 00:34:32,360
a human is conscious even though the human replies that he or she is conscious so to further prove

500
00:34:32,360 --> 00:34:38,120
that a human is or is not conscious maybe the alien decides to dissect the poor thing next in which

501
00:34:38,120 --> 00:34:43,640
case it would get blood splattering everywhere and then afterwards it would see this basically a body

502
00:34:43,640 --> 00:34:49,400
which is made of limbs and flesh and then at the head we have this glob called the brain which the

503
00:34:49,400 --> 00:34:54,760
alien determines aha this is the thing that controls the human and once the alien inspects the

504
00:34:54,760 --> 00:35:01,560
brain further it finds out that it's just a network of nerve cells so does this network

505
00:35:01,560 --> 00:35:07,240
prove that humans are conscious and sentient we humans of course know that we are conscious and

506
00:35:07,240 --> 00:35:13,160
sentient but at the end of the day we humans are biologically and physically just made up of flesh

507
00:35:13,160 --> 00:35:17,480
and bones and this one organ at the top of our heads controlling everything whether you like

508
00:35:17,480 --> 00:35:24,200
to accept this or not a humanoid robot is a very similar structure it has a body which is programmed

509
00:35:24,200 --> 00:35:30,680
by a brain which consists of a neural network this neural network can learn and understand

510
00:35:30,680 --> 00:35:37,080
and control its body so at what point does this make it conscious now i'm rambling a bit here so

511
00:35:37,080 --> 00:35:42,840
all in all this just goes back to our analogy that a neural network is basically a digital version

512
00:35:42,840 --> 00:35:48,120
of the human brain it's analogous to the structure of the human brain give or take a few minor

513
00:35:48,840 --> 00:35:54,920
so if the human brain is conscious then why can't a neural network be conscious just some food for

514
00:35:54,920 --> 00:35:59,320
thought i hope this video actually lived up to the title and that after watching this video you

515
00:35:59,320 --> 00:36:04,920
got a deeper understanding of ai and you learned to appreciate all the progress that we've made in

516
00:36:04,920 --> 00:36:09,240
ai in just the past few years let me know in the comments what you think of all this do you think

517
00:36:09,240 --> 00:36:15,080
ai has reached a point where it is conscious or sentient do you think humanoid robots would one

518
00:36:15,080 --> 00:36:21,160
day turn on us and take over the world like that ghost in the shell anime do you think open ai is

519
00:36:21,160 --> 00:36:25,880
developing this behind closed doors and also i want to share with you a few resources that i found

520
00:36:25,880 --> 00:36:30,680
really helpful if you want to learn more about neural networks especially how these knobs and

521
00:36:30,680 --> 00:36:35,320
dials work and learn all about weights and biases and activation functions and gradient descent i

522
00:36:35,320 --> 00:36:41,960
highly recommend this video by three blue one brown i actually watched this religiously way back in

523
00:36:41,960 --> 00:36:46,920
like 2018 when i was first learning about neural networks and it was really helpful and if you're

524
00:36:46,920 --> 00:36:52,360
interested in learning how stable diffusion works in other words the processes of forward diffusion

525
00:36:52,360 --> 00:36:57,800
and reverse diffusion and the entire architecture i highly recommend this video by gonki which i'll

526
00:36:57,800 --> 00:37:02,440
also link to in the description below just a warning though this video is quite technical but

527
00:37:02,440 --> 00:37:06,680
after watching it you'll get a really good understanding of stable diffusion if you found

528
00:37:06,680 --> 00:37:11,880
this video helpful remember to like share subscribe and stay tuned for more content also we built a

529
00:37:11,880 --> 00:37:17,800
site where you can find ai tools and apps and also look for jobs in ai machine learning data

530
00:37:17,800 --> 00:37:27,800
science and more check it out at ai-search.io

