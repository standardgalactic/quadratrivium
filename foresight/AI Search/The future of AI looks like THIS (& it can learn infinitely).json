{"text": " AI, as we know it today, is actually quite dumb. Yes, this includes chatGPT, stable diffusion, Sora, and all the other state-of-the-art models that we have right now. They're still very incapable and inefficient, and the future generation of AI will look very different from what we have now. So in this video, I'm going to explain why the current generation is so limited and what the future generation of AI will look like. First we need to understand the mechanics of AI. As we know today, all AI is based on the neural network, which is designed based on the human brain. This is basically a network of nodes in which information flows through from one end to the other. Now, this is going to be a very simplified explanation of how a neural network works. I'm explaining this for people without a technical background in AI, so if you do have experience in AI, feel free to skip this section. Each dot in a neural network is called a node or neuron, and each line of nodes is called a layer. You might have heard of the term deep learning, or deep neural networks. This is basically a neural network with many layers, hence it is very deep. Each node determines how much information flows through to the next layer. Now again, this is an oversimplification. There are a lot of settings like weights and biases and activation functions, but basically just think of this neural network as a series of dials and knobs, which determine how much information flows through to the next layer. Here's a simple example. Let's say we have this neural network, which is designed to determine whether an image is a cat or a dog. For its input, we would feed it an image of a cat or a dog, and this image would be broken down into data, also known as tokens, which are then fed through this neural network. Eventually after the data flows through all these layers, it reaches the end layer, which would conclude whether the image is a cat or a dog. Now what about training a model? How does that work? Well, a neural network needs to undergo usually millions of rounds of training to learn how to do something. Here's an example of how one round of training would look like. Let's say you input an image of a dog, and then this image would be broken down into data, which flows through this neural network, and it spits out the answer. This is a dog. Well, in that case, since it got the answer correct, it's likely that these dials and knobs, which we can also refer to as weights, are set correctly. If it gets the answer right, well, we don't really need to tweak these weights further. However, what if it gets it wrong? What if it says that this is a cat? Well, in that case, it would incur a penalty. And this penalty would cause the weights in this neural network to be updated so that this penalty would be minimized in the future. Specifically, the weights would be updated from the last layer to the next layer back to the next layer back in a process which is called back propagation all the way until it reaches the first layer of nodes. And usually one round of training isn't good enough. So the network would undergo millions of rounds of training where the weights would be slightly tweaked to minimize the penalty incurred from any errors. And this goes on and on until finally, we reach the right configuration of dials and knobs so that this neural network can very accurately determine whether any image is a cat or a dog. And this is how AI models that we know today are trained as well. So for example, GPT is basically a neural network, but these dials and knobs are optimized for understanding natural language. Stable diffusion is another neural network where the dials and knobs are optimized for image generation. Now again, this is very much an oversimplification and the architecture or basically the design of the neural network is also very important. For example, how many layers should we have? How many nodes in each layer should we have? There are also many different architectures, such as the transformer model for large language models or LSTM for time series data or convolutional neural networks for object detection and image classification. But in a nutshell, the backbone behind all these AI models is just a neural network, which has a preconfigured set of dials and knobs to do the job accurately. So now that you understand how the current generation of AI works, let's look at the biggest limitations of this. First of all, once the model is finished training, the weights or basically these dials and knobs are fixed in value. When the user asks chat GPT something or when the user uses stable diffusion to generate an image, these dials and knobs do not change in value. In other words, all the AI models that we have today are fixed. Think of this as a brain that cannot learn or get any smarter. For example, GPT-4 cannot continue learning and become smarter and smarter with time. If we want a smarter model, well, we need to train a new generation of GPT such as GPT-4.0 or GPT-5 or whatever you want to call it. Same with stable diffusion. For example, stable diffusion 2 cannot get smarter and generate better images as we use it more and more. In order for it to improve, we currently need to train a new generation, also known as stable diffusion 3. And once stable diffusion 3 is finished training, well, that's as smart as it gets. And if you don't think it's good enough, well, you need to train a new model. So basically all the AI models that we have today are fixed in their intelligence and their capabilities. Again, think of this as a brain that has stopped growing and cannot learn or get smarter. But this is not how the human brain works. There's a term called neuroplasticity, which refers to how the brain can reorganize or reconfigure itself by forming new neural connections over time in order to adapt to new environments or learn new things. And that's exactly what the next generation of AI can do, which we'll talk about in a second. But there's another huge limitation of current AI models. They are extremely inefficient and compute intensive. As you may know, AI is designed based on the architecture of the human brain. So let's compare it to the efficiency of the human brain right now. GPT-3 has 175 billion parameters. This was trained using thousands of GPUs over several weeks or several months. The total power required for training GPT-3 was estimated to be around 1287 megawatt hours of electricity. This is roughly equivalent to the monthly electricity consumption of 1500 homes in the USA. Now, keep in mind GPT-3 was completed in 2020. That's four years ago. The latest version, GPT-4, is closed source. So we don't actually know its architecture or how long it took to train. But we do know that it has around 1.76 trillion parameters, 10 times more than GPT-3. Keep in mind that the amount of computations required scales exponentially as the parameter size gets larger. So from a rough calculation, GPT-4 could have taken around 41,000 megawatt hours of energy to train. That's enough energy to power around 47,000 homes in the US for a month. The compute used to create these state-of-the-art models that we know today, such as GPT-4 Clawd-3 or Gemini 1.5 Pro, requires massive data centers and a lot of energy. That's why tech giants are scrambling to invest and build even bigger data centers, because they know that compute is the main limitation here. And that's exactly why Microsoft and OpenAI are planning a $100 billion Stargate project to build the biggest data center in the world. All of this is for more compute. Now contrast this to the human brain. Some might say the human brain is still more intelligent than GPT-4, at least in some regards. The human brain only uses 175 kilowatt hours in an entire year, and it gets this energy in the form of calories from the food we eat. So training GPT-4 is estimated to require approximately 234,000 times more energy than what the human brain uses in an entire year. In other words, the energy required to train GPT-4 once could power the human brain for over 234,000 years. Now I gave this comparison to show you that there's something fundamentally wrong with AI models today. They are very energy inefficient, and they take up a lot of compute. It's not even close to the efficiency of the human brain. So the next generation of AI has to solve this inefficiency problem as well, otherwise it will not be sustainable. So to summarize the major limitations of current AI models is number one, they are fixed and unable to improve or learn further after being trained, and number two, they're also very energy intensive and inefficient. These are the two biggest problems of the current generation of AI. Now let's enter the next generation. We aren't there yet, but there are a few possible architectures that are being discussed and developed as we speak. The first architecture is called liquid neural networks. Now liquid neural networks are designed to mimic the flexibility or the plasticity of the human brain. The human brain is very flexible and can reorganize or reconfigure itself over time, and this ability allows the brain to adapt to new situations or learn new skills or compensate for injury and disease. For example, when you learn something new, your brain changes structurally and functionally to accommodate the new information. Learning a new language can lead to changes in the brain's structure and function, such as increased density of gray matter in the left hemisphere. The brain can also reconfigure itself to recover from injury. For example, after a traumatic brain injury, physical therapy and cognitive exercises can help rewire the brain to regain lost functions. And for people who've lost a sense, like sight or hearing, the brain will reorganize itself to compensate for the loss and make other senses become more acute. So this flexibility, this plasticity is exactly what liquid neural networks are designed to have. Liquid neural networks can adapt in real time to new data. This means that the configuration of the neural network can change as it receives new inputs, and that's why it's called liquid. These connections in the network and these dials and knobs are fluid, so they can change dynamically over time. Liquid neural networks also retain what they have learned while incorporating new information. This is similar to how our brains can remember old information while learning new things. So here's how liquid neural networks work. They have three main components, much like a traditional neural network. It has an input layer, which receives the input data. But then in the middle, we have this liquid layer, otherwise known as a reservoir. This is the core component of a liquid neural network. And it's basically a large recurrent neural network. Think of this as a big bowl of water in which each splash creates a ripple. These ripples are basically the neurons in this network reacting to inputs. The reservoir acts as a dynamic system that transforms the input data into a high dimensional representation called reservoir states. And this reservoir's rich dynamics and transformations capture the complex temporal patterns in the input data. And then finally, we have the output layer. This layer receives the reservoir states and maps them to the desired output using what is called a readout function. In layman terms, this is a layer that looks at the ripples in the reservoir and tries to understand what it all means. It takes the dynamic patterns from the reservoir and makes predictions or decisions from it. The key aspect of liquid neural networks is this reservoir layer, which remains untrained during the entire learning process. Finally the output layer is trained to map the reservoir states to the target outputs. In other words, to understand what these ripples mean. And because this reservoir remains fluid and flexible throughout time, it's not fixed in value, that allows this liquid neural network to basically adapt to new data and learn new things. Here's how you would train a liquid neural network. The connections between neurons in the reservoirs are set up randomly at the start. These connections typically stay the same and don't change during training. Next you would feed the input layer some data. And when this data is broken down into tokens and it reaches the reservoir layer, it causes the neurons in the reservoir to react and create complex patterns, much like ripples in water. So as this input data creates ripples, you basically observe and analyze the patterns created in the reservoir over time. And that's exactly what the readout layer does. It learns to recognize these patterns. It's like learning, aha, this is what caused this type of ripple and that is what caused this other type of ripple. And eventually after lots and lots of rounds of training, the readout layer can make accurate predictions based on observed patterns. Again note that only the readout layer is trained, which is simpler and faster because you're not adjusting anything in the reservoir layer. This is much quicker and needs less compute compared to traditional neural networks. That's because in neural networks that we know today, all the weights including those in the hidden layers are trainable. This means more parameters to optimize leading to longer training times and higher computational requirements. But in liquid neural networks, you don't adjust the weights of the reservoir during training. Only the readout layer is trained. And this significantly reduces the computational burden during training since fewer parameters need to be optimized. Plus it's a lot faster to train. Thanks to our sponsor Bright Data. Bright Data is an all-in-one platform designed to help businesses collect high quality web data at scale. This is especially useful for AI companies which require huge amounts of diverse and high quality training data to build robust and unbiased AI models. Collecting this training data manually can be time consuming and prone to errors. And that's where Bright Data comes in. With Bright Data, you can access high volume, high quality web data effortlessly. From parsed validated data sets to custom scraping solutions, they've got you covered. Get parsed and cleaned data sets ready to use on demand. Customize any data set to fit your specific needs and benefit from reliable delivery and full compliance. In fact every 15 minutes their customers scrape enough data to train chat GPT from scratch. That's a lot of data, to say the least. They have many tools like the web scraper API, the proxy manager, and unblocking technologies to help automate your data scraping at scale, allowing you to build reliable data sets to train any AI or LLM. Visit the link in the description below to learn more. It's a lot faster for these liquid neural networks to converge at an optimum. And because of this reservoir where the weights and configurations can change dynamically depending on the data that you feed it, liquid neural networks can potentially be much smaller than traditional neural networks which have fixed weights and connections. And this offers a lot more efficient learning and inference. So for example, researchers at MIT were able to pilot a drone using a liquid neural network with only 20,000 parameters, which is very tiny compared to state-of-the-art AI models such as GPT4, which often have over a trillion parameters. Just think about that. 20,000 parameters versus over a trillion parameters. So these smaller sizes generally translate to faster inference and lower computational requirements. Liquid neural networks are also way less memory intensive. Again, since you don't train the reservoir's weights, memory usage is much lower during training compared to traditional neural networks where the gradients and the parameters for all layers must be stored in memory. Liquid neural networks are particularly good at processing temporal data due to their dynamic reservoir. So they excel in tasks that involve complex time series data. Now you might be wondering, well, how can these liquid neural networks actually be applied in the real world? So here are some use cases. As we race to build fully autonomous AI robots, these robots will be deployed in the real world and oftentimes they might encounter situations that they've never seen before during training. For example, there could be unpredictable environments in search and rescue missions, but with liquid neural networks, these robots can adapt to changing conditions and learn new tasks on the fly. And eventually we're going to have these autonomous robots in our houses helping us do chores and other tasks. But maybe you have a certain way of folding clothes or doing the laundry or cooking that the robot was never trained on. So with a traditional neural network, these robots aren't able to learn new skills after being deployed. But with liquid neural networks built into a humanoid robot, it can learn new tasks that you teach it. And this robot will become a lot more personalized for you. And then we have autonomous driving. There's no doubt that self-driving cars will eventually become the future. But current technologies still do not perform well, especially in challenging environments or new conditions. Again, this is because traditional neural networks can only do well on data that they were trained on. They're not able to adapt to new environments. But with liquid neural networks, autonomous vehicles can navigate complex and dynamic environments by continuously learning and training from sensor data and adjusting their behavior accordingly. It's constantly training and improving over time. Now as I've mentioned before, liquid neural networks often incorporate recurrent connections, making them suitable for processing time series data. So it's great for things like weather prediction and of course, stock trading. The stock market is filled with ever-changing trends and cycles, so it's close to impossible for one fixed algorithm or formula to beat the market. However, because liquid neural networks can adapt to ever-changing data, it can optimize trading strategies in real time to maximize profits. In other words, you could be constantly streaming the latest market data to this liquid neural network, which would change its configuration to adapt to this data in real time to help you maximize profits. Another use case would be healthcare. Liquid neural networks can be used in wearable devices to monitor patients in real time, adapting to changes in the patient's conditions and predicting potential health issues before they become critical. In cybersecurity, liquid neural networks can continuously learn from network traffic and user behavior to adapt access control policies and detect anomalies or unauthorized access attempts. Yet another use case would be streaming services such as Netflix. They can use liquid neural networks to adapt to each user's viewing habits and preferences, providing more personalized content recommendations. Another use case would be smart city management. For example, liquid neural networks can optimize traffic flow in real time by learning from traffic patterns and changing traffic lights accordingly to reduce congestion and improve efficiency. Energy management is also very relevant. Smart grids can use liquid neural networks to balance power, supply, and demand in real time, improving efficiency and reducing costs by adapting to consumption patterns. However, although liquid neural networks seem promising, it does have its limitations. This is still a relatively new concept in the field of neural networks and research on them is still in its early stages compared to more traditional architectures. While liquid neural networks show promising theoretical benefits such as the ability to process continuous data streams and adapt on the fly, there is still a lack of real world results demonstrating their superiority on a large scale. Many researchers are likely waiting for more compelling benchmark results before investing significant effort into liquid neural networks. Also as I mentioned previously, they're particularly suited for temporal or sequence data. Also for tasks that do not involve time such as identifying images of cats or dogs, traditional neural networks might actually be more effective and straightforward to implement. Also the dynamics within this reservoir layer can be very complex and difficult to interpret and this makes it challenging to understand how the reservoir processes these inputs. It would be quite hard to fine tune it for optimal performance. Finally, there is a lack of standardized support and fewer established frameworks for liquid neural networks compared to traditional neural networks. And this can make implementation and experimentation more challenging. So all in all, liquid neural networks are still a very early concept and an area of active research. Unlike traditional neural networks that are fixed and need to be retrained with a large data set to learn new information, liquid neural networks can update their knowledge incrementally with each new piece of data. This offers a flexible and adaptive model which could potentially become infinitely smarter over time. Now liquid neural networks aren't the only possibility that could become the next generation of AI. We have another type of neural network which is designed to mimic the human brain even more than traditional neural networks. And this brings us to spiking neural networks. These are closely inspired by the way neurons in our brains communicate using discrete spikes or action potentials. You see, in the human brain, which is basically a network of neurons, each neuron doesn't immediately fire to the next set of neurons when it receives input. Instead, the input has to build up to a certain threshold and once it passes this threshold, then it fires to the next set of neurons. And after it fires, it goes back to its resting state. Well, spiking neural networks are designed to mimic this behavior. So here's how it works. The architecture is quite similar to traditional neural networks. However, for each neuron, it waits to receive signals or spikes from other neurons. Think of these spikes as like little electric pulses. The input data, such as an image or a sound, is turned into the spikes that move through this neural network. For example, if it's a loud sound, it might generate more spikes while a quiet sound might generate fewer spikes. Now each neuron in the network collects incoming spikes. Imagine a bucket collecting drops of water. As more spikes come in, the bucket fills up. And when the neuron gets enough spikes, in other words, when it reaches a certain threshold, it fires a spike to the next set of neurons. And after firing, it resets and starts collecting again from zero. So instead of using continuous signals like traditional neural networks, spiking neural networks uses spikes, which are basically bursts of activity at discrete time points to process information. In other words, spiking neural networks incorporate time into their processing, with neurons firing only when their potential exceeds a certain threshold. Now there are different methods and algorithms to train a spiking neural network, and there currently isn't a standard wave that's set in stone. So this is still an active field of research. One common method is called spike timing dependent plasticity, or STDP. This method is inspired by how the brain strengthens or weakens connections between neurons. So if one neuron spikes just before another, then the connection between them gets stronger. If it spikes just after, then the connection gets weaker. It's like learning which connections are important based on the timing of the spikes. And speaking of timing, it's the exact timing of spikes that matters. It's not just about how many spikes there are, but when they happen. Now STDP is only one method to train the spiking neural networks. There are a few other ones, which are beyond the scope of this video. But like traditional neural networks, spiking neural networks have to undergo millions of rounds of training with a lot of data, and eventually the configuration of the network and all its parameters will reach an optimum state. Now again, I'd like to remind you that this is a very simplified explanation of spiking neural networks, and I've left out a lot of mathematical details. But in a nutshell, that's how it works. So you might be wondering, well, what are the benefits of spiking neural networks? First of all, it's designed to mimic the human brain even more by implementing this spiking mechanism. So in theory, maybe we could reach a superior level of intelligence compared to the current generation of AI if we mimicked the human brain even more. But the biggest benefit of spiking neural networks is their efficiency. If you remember at the beginning of the video, I compared the energy consumption of the human brain versus a current state of the art model like GPT-4, which requires huge data centers and huge amounts of compute. That's because traditional neural networks are always active. Each input of data activates the entire neural network. So you have to do an insane amount of matrix multiplications across the entire network just to do one round of training or inference. However, for spiking neural networks, they only use energy where spikes occur, while the rest of the neural network remains inactive. This makes it a lot more energy efficient. Plus, spiking neural networks are particularly suitable for neuromorphic chips which are designed to mimic the human brain. Now, neuromorphic chips are a huge topic and deserves its own full video. So let me know in the comments if you'd like me to make a video on this as well. So how can these spiking neural networks actually be applied to the real world? Well, because these neural networks can encode and process information in the timing of spikes, this is great for processing temporal data. This makes them great for adaptive and autonomous systems, plus this spike timing-dependent plasticity, which I mentioned before, where the timing of the spikes influences the strength of the connections in the network. This can lead to more robust and adaptive learning capability. So this dynamic learning can make spiking neural networks suitable for autonomous systems such as self-driving, where the AI has to learn and adapt to changing environments. Or it can be used in real-time processing like predicting the stock market or patient monitoring and personalized medicine, and of course, autonomous robots. Now, although spiking neural networks offer some huge benefits, especially regarding energy efficiency, they do have some limitations. Setting up and programming spiking neural networks is more complicated compared to traditional neural networks. This spiking behavior, of course, adds a layer of complexity, making them harder to design and understand. Studying spiking neural networks is also quite difficult. Current neural networks use methods like backpropagation to adjust their parameters, but this process doesn't work well with these discrete time-based spikes. Researchers are still trying to find an effective training algorithm for spiking neural networks. Also given this additional dimension of time, spiking neural networks might actually require more computational resources to simulate. This is because they need to track and process spikes over time, which can be computationally expensive. Yet, another limitation is that running spiking neural networks efficiently often requires specialized hardware such as neuromorphic chips, which are not widely available or standardized compared to conventional computing hardware. Neuromorphic chips are optimized for this spike-based processing and are still being developed. And that's why, for example, Sam Altman is investing millions of dollars into a neuromorphic chip company called RAIN. Finally, while spiking neural networks show promising results, especially for time-based data, they often lag behind current neural networks for non-time-based data. They often underperform compared with current AI models, particularly for complex tasks. This is partly due to the challenges in training spiking neural networks effectively. And as with liquid neural networks, spiking neural networks are also relatively new. So there are fewer tools and frameworks available for developing spiking neural networks compared to current AI models. This makes experimentation and development slower and more difficult. But anyways, that sums up what could potentially be the next generation of AI. To bring it all back, the current generation of AI is very energy inefficient, requiring huge amounts of compute. Plus, it can't learn new things after being trained. If we want to achieve AGI or ASI, we need to essentially create something as efficient and as fluid as the human brain, which can constantly learn new things and adapt to changing environments. These are the two essential things that new types of neural networks, such as liquid neural networks and spiking neural networks can solve, at least in theory. However, these are still relatively new and they are still being developed, but the potential could be massive. Imagine an AI that can keep learning and get infinitely smarter. Let me know what you think about these neural networks in the comments below. Things are happening so fast in the world of AI, it's quite hard to keep up with all the technological innovations that are happening right now. So if I've missed any other groundbreaking architectures that are worth mentioning, please let me know in the comments below and I'll try to do a video on that as well. As always, if you enjoyed this video, remember to like, share, subscribe and stay tuned for more content. Also we built a site where you can find all the AI tools out there as well as find jobs in machine learning, data science and more. Check it out at ai-search.io. Thanks for watching and I'll see you in the next one.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.84, "text": " AI, as we know it today, is actually quite dumb.", "tokens": [50364, 7318, 11, 382, 321, 458, 309, 965, 11, 307, 767, 1596, 10316, 13, 50556], "temperature": 0.0, "avg_logprob": -0.16192291057215327, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.18167506158351898}, {"id": 1, "seek": 0, "start": 3.84, "end": 10.32, "text": " Yes, this includes chatGPT, stable diffusion, Sora, and all the other state-of-the-art models", "tokens": [50556, 1079, 11, 341, 5974, 5081, 38, 47, 51, 11, 8351, 25242, 11, 46639, 11, 293, 439, 264, 661, 1785, 12, 2670, 12, 3322, 12, 446, 5245, 50880], "temperature": 0.0, "avg_logprob": -0.16192291057215327, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.18167506158351898}, {"id": 2, "seek": 0, "start": 10.32, "end": 12.200000000000001, "text": " that we have right now.", "tokens": [50880, 300, 321, 362, 558, 586, 13, 50974], "temperature": 0.0, "avg_logprob": -0.16192291057215327, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.18167506158351898}, {"id": 3, "seek": 0, "start": 12.200000000000001, "end": 16.88, "text": " They're still very incapable and inefficient, and the future generation of AI will look", "tokens": [50974, 814, 434, 920, 588, 44174, 293, 43495, 11, 293, 264, 2027, 5125, 295, 7318, 486, 574, 51208], "temperature": 0.0, "avg_logprob": -0.16192291057215327, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.18167506158351898}, {"id": 4, "seek": 0, "start": 16.88, "end": 19.56, "text": " very different from what we have now.", "tokens": [51208, 588, 819, 490, 437, 321, 362, 586, 13, 51342], "temperature": 0.0, "avg_logprob": -0.16192291057215327, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.18167506158351898}, {"id": 5, "seek": 0, "start": 19.56, "end": 24.84, "text": " So in this video, I'm going to explain why the current generation is so limited and", "tokens": [51342, 407, 294, 341, 960, 11, 286, 478, 516, 281, 2903, 983, 264, 2190, 5125, 307, 370, 5567, 293, 51606], "temperature": 0.0, "avg_logprob": -0.16192291057215327, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.18167506158351898}, {"id": 6, "seek": 0, "start": 24.84, "end": 28.560000000000002, "text": " what the future generation of AI will look like.", "tokens": [51606, 437, 264, 2027, 5125, 295, 7318, 486, 574, 411, 13, 51792], "temperature": 0.0, "avg_logprob": -0.16192291057215327, "compression_ratio": 1.6798418972332017, "no_speech_prob": 0.18167506158351898}, {"id": 7, "seek": 2856, "start": 28.56, "end": 31.439999999999998, "text": " First we need to understand the mechanics of AI.", "tokens": [50364, 2386, 321, 643, 281, 1223, 264, 12939, 295, 7318, 13, 50508], "temperature": 0.0, "avg_logprob": -0.10145711898803711, "compression_ratio": 1.64453125, "no_speech_prob": 0.060043804347515106}, {"id": 8, "seek": 2856, "start": 31.439999999999998, "end": 37.4, "text": " As we know today, all AI is based on the neural network, which is designed based on the human", "tokens": [50508, 1018, 321, 458, 965, 11, 439, 7318, 307, 2361, 322, 264, 18161, 3209, 11, 597, 307, 4761, 2361, 322, 264, 1952, 50806], "temperature": 0.0, "avg_logprob": -0.10145711898803711, "compression_ratio": 1.64453125, "no_speech_prob": 0.060043804347515106}, {"id": 9, "seek": 2856, "start": 37.4, "end": 38.4, "text": " brain.", "tokens": [50806, 3567, 13, 50856], "temperature": 0.0, "avg_logprob": -0.10145711898803711, "compression_ratio": 1.64453125, "no_speech_prob": 0.060043804347515106}, {"id": 10, "seek": 2856, "start": 38.4, "end": 44.0, "text": " This is basically a network of nodes in which information flows through from one end to", "tokens": [50856, 639, 307, 1936, 257, 3209, 295, 13891, 294, 597, 1589, 12867, 807, 490, 472, 917, 281, 51136], "temperature": 0.0, "avg_logprob": -0.10145711898803711, "compression_ratio": 1.64453125, "no_speech_prob": 0.060043804347515106}, {"id": 11, "seek": 2856, "start": 44.0, "end": 45.0, "text": " the other.", "tokens": [51136, 264, 661, 13, 51186], "temperature": 0.0, "avg_logprob": -0.10145711898803711, "compression_ratio": 1.64453125, "no_speech_prob": 0.060043804347515106}, {"id": 12, "seek": 2856, "start": 45.0, "end": 50.879999999999995, "text": " Now, this is going to be a very simplified explanation of how a neural network works.", "tokens": [51186, 823, 11, 341, 307, 516, 281, 312, 257, 588, 26335, 10835, 295, 577, 257, 18161, 3209, 1985, 13, 51480], "temperature": 0.0, "avg_logprob": -0.10145711898803711, "compression_ratio": 1.64453125, "no_speech_prob": 0.060043804347515106}, {"id": 13, "seek": 2856, "start": 50.879999999999995, "end": 56.4, "text": " I'm explaining this for people without a technical background in AI, so if you do have", "tokens": [51480, 286, 478, 13468, 341, 337, 561, 1553, 257, 6191, 3678, 294, 7318, 11, 370, 498, 291, 360, 362, 51756], "temperature": 0.0, "avg_logprob": -0.10145711898803711, "compression_ratio": 1.64453125, "no_speech_prob": 0.060043804347515106}, {"id": 14, "seek": 5640, "start": 56.4, "end": 59.68, "text": " experience in AI, feel free to skip this section.", "tokens": [50364, 1752, 294, 7318, 11, 841, 1737, 281, 10023, 341, 3541, 13, 50528], "temperature": 0.0, "avg_logprob": -0.11574052174886068, "compression_ratio": 1.689795918367347, "no_speech_prob": 0.03962470591068268}, {"id": 15, "seek": 5640, "start": 59.68, "end": 65.32, "text": " Each dot in a neural network is called a node or neuron, and each line of nodes is", "tokens": [50528, 6947, 5893, 294, 257, 18161, 3209, 307, 1219, 257, 9984, 420, 34090, 11, 293, 1184, 1622, 295, 13891, 307, 50810], "temperature": 0.0, "avg_logprob": -0.11574052174886068, "compression_ratio": 1.689795918367347, "no_speech_prob": 0.03962470591068268}, {"id": 16, "seek": 5640, "start": 65.32, "end": 66.88, "text": " called a layer.", "tokens": [50810, 1219, 257, 4583, 13, 50888], "temperature": 0.0, "avg_logprob": -0.11574052174886068, "compression_ratio": 1.689795918367347, "no_speech_prob": 0.03962470591068268}, {"id": 17, "seek": 5640, "start": 66.88, "end": 71.7, "text": " You might have heard of the term deep learning, or deep neural networks.", "tokens": [50888, 509, 1062, 362, 2198, 295, 264, 1433, 2452, 2539, 11, 420, 2452, 18161, 9590, 13, 51129], "temperature": 0.0, "avg_logprob": -0.11574052174886068, "compression_ratio": 1.689795918367347, "no_speech_prob": 0.03962470591068268}, {"id": 18, "seek": 5640, "start": 71.7, "end": 76.75999999999999, "text": " This is basically a neural network with many layers, hence it is very deep.", "tokens": [51129, 639, 307, 1936, 257, 18161, 3209, 365, 867, 7914, 11, 16678, 309, 307, 588, 2452, 13, 51382], "temperature": 0.0, "avg_logprob": -0.11574052174886068, "compression_ratio": 1.689795918367347, "no_speech_prob": 0.03962470591068268}, {"id": 19, "seek": 5640, "start": 76.75999999999999, "end": 81.2, "text": " Each node determines how much information flows through to the next layer.", "tokens": [51382, 6947, 9984, 24799, 577, 709, 1589, 12867, 807, 281, 264, 958, 4583, 13, 51604], "temperature": 0.0, "avg_logprob": -0.11574052174886068, "compression_ratio": 1.689795918367347, "no_speech_prob": 0.03962470591068268}, {"id": 20, "seek": 5640, "start": 81.2, "end": 83.4, "text": " Now again, this is an oversimplification.", "tokens": [51604, 823, 797, 11, 341, 307, 364, 15488, 332, 564, 3774, 13, 51714], "temperature": 0.0, "avg_logprob": -0.11574052174886068, "compression_ratio": 1.689795918367347, "no_speech_prob": 0.03962470591068268}, {"id": 21, "seek": 8340, "start": 83.4, "end": 88.08000000000001, "text": " There are a lot of settings like weights and biases and activation functions, but basically", "tokens": [50364, 821, 366, 257, 688, 295, 6257, 411, 17443, 293, 32152, 293, 24433, 6828, 11, 457, 1936, 50598], "temperature": 0.0, "avg_logprob": -0.10031576667513166, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.011685386300086975}, {"id": 22, "seek": 8340, "start": 88.08000000000001, "end": 93.60000000000001, "text": " just think of this neural network as a series of dials and knobs, which determine how much", "tokens": [50598, 445, 519, 295, 341, 18161, 3209, 382, 257, 2638, 295, 5502, 82, 293, 46999, 11, 597, 6997, 577, 709, 50874], "temperature": 0.0, "avg_logprob": -0.10031576667513166, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.011685386300086975}, {"id": 23, "seek": 8340, "start": 93.60000000000001, "end": 97.12, "text": " information flows through to the next layer.", "tokens": [50874, 1589, 12867, 807, 281, 264, 958, 4583, 13, 51050], "temperature": 0.0, "avg_logprob": -0.10031576667513166, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.011685386300086975}, {"id": 24, "seek": 8340, "start": 97.12, "end": 98.72, "text": " Here's a simple example.", "tokens": [51050, 1692, 311, 257, 2199, 1365, 13, 51130], "temperature": 0.0, "avg_logprob": -0.10031576667513166, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.011685386300086975}, {"id": 25, "seek": 8340, "start": 98.72, "end": 104.24000000000001, "text": " Let's say we have this neural network, which is designed to determine whether an image", "tokens": [51130, 961, 311, 584, 321, 362, 341, 18161, 3209, 11, 597, 307, 4761, 281, 6997, 1968, 364, 3256, 51406], "temperature": 0.0, "avg_logprob": -0.10031576667513166, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.011685386300086975}, {"id": 26, "seek": 8340, "start": 104.24000000000001, "end": 106.16000000000001, "text": " is a cat or a dog.", "tokens": [51406, 307, 257, 3857, 420, 257, 3000, 13, 51502], "temperature": 0.0, "avg_logprob": -0.10031576667513166, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.011685386300086975}, {"id": 27, "seek": 8340, "start": 106.16000000000001, "end": 110.96000000000001, "text": " For its input, we would feed it an image of a cat or a dog, and this image would be broken", "tokens": [51502, 1171, 1080, 4846, 11, 321, 576, 3154, 309, 364, 3256, 295, 257, 3857, 420, 257, 3000, 11, 293, 341, 3256, 576, 312, 5463, 51742], "temperature": 0.0, "avg_logprob": -0.10031576667513166, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.011685386300086975}, {"id": 28, "seek": 11096, "start": 110.96, "end": 117.0, "text": " down into data, also known as tokens, which are then fed through this neural network.", "tokens": [50364, 760, 666, 1412, 11, 611, 2570, 382, 22667, 11, 597, 366, 550, 4636, 807, 341, 18161, 3209, 13, 50666], "temperature": 0.0, "avg_logprob": -0.13535275629588536, "compression_ratio": 1.7290076335877862, "no_speech_prob": 0.051830682903528214}, {"id": 29, "seek": 11096, "start": 117.0, "end": 122.36, "text": " Eventually after the data flows through all these layers, it reaches the end layer, which", "tokens": [50666, 17586, 934, 264, 1412, 12867, 807, 439, 613, 7914, 11, 309, 14235, 264, 917, 4583, 11, 597, 50934], "temperature": 0.0, "avg_logprob": -0.13535275629588536, "compression_ratio": 1.7290076335877862, "no_speech_prob": 0.051830682903528214}, {"id": 30, "seek": 11096, "start": 122.36, "end": 126.55999999999999, "text": " would conclude whether the image is a cat or a dog.", "tokens": [50934, 576, 16886, 1968, 264, 3256, 307, 257, 3857, 420, 257, 3000, 13, 51144], "temperature": 0.0, "avg_logprob": -0.13535275629588536, "compression_ratio": 1.7290076335877862, "no_speech_prob": 0.051830682903528214}, {"id": 31, "seek": 11096, "start": 126.55999999999999, "end": 128.95999999999998, "text": " Now what about training a model?", "tokens": [51144, 823, 437, 466, 3097, 257, 2316, 30, 51264], "temperature": 0.0, "avg_logprob": -0.13535275629588536, "compression_ratio": 1.7290076335877862, "no_speech_prob": 0.051830682903528214}, {"id": 32, "seek": 11096, "start": 128.95999999999998, "end": 130.24, "text": " How does that work?", "tokens": [51264, 1012, 775, 300, 589, 30, 51328], "temperature": 0.0, "avg_logprob": -0.13535275629588536, "compression_ratio": 1.7290076335877862, "no_speech_prob": 0.051830682903528214}, {"id": 33, "seek": 11096, "start": 130.24, "end": 135.28, "text": " Well, a neural network needs to undergo usually millions of rounds of training to learn how", "tokens": [51328, 1042, 11, 257, 18161, 3209, 2203, 281, 26426, 2673, 6803, 295, 13757, 295, 3097, 281, 1466, 577, 51580], "temperature": 0.0, "avg_logprob": -0.13535275629588536, "compression_ratio": 1.7290076335877862, "no_speech_prob": 0.051830682903528214}, {"id": 34, "seek": 11096, "start": 135.28, "end": 136.28, "text": " to do something.", "tokens": [51580, 281, 360, 746, 13, 51630], "temperature": 0.0, "avg_logprob": -0.13535275629588536, "compression_ratio": 1.7290076335877862, "no_speech_prob": 0.051830682903528214}, {"id": 35, "seek": 11096, "start": 136.28, "end": 140.84, "text": " Here's an example of how one round of training would look like.", "tokens": [51630, 1692, 311, 364, 1365, 295, 577, 472, 3098, 295, 3097, 576, 574, 411, 13, 51858], "temperature": 0.0, "avg_logprob": -0.13535275629588536, "compression_ratio": 1.7290076335877862, "no_speech_prob": 0.051830682903528214}, {"id": 36, "seek": 14084, "start": 140.84, "end": 146.32, "text": " Let's say you input an image of a dog, and then this image would be broken down into data,", "tokens": [50364, 961, 311, 584, 291, 4846, 364, 3256, 295, 257, 3000, 11, 293, 550, 341, 3256, 576, 312, 5463, 760, 666, 1412, 11, 50638], "temperature": 0.0, "avg_logprob": -0.10910178290473091, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0636940523982048}, {"id": 37, "seek": 14084, "start": 146.32, "end": 150.12, "text": " which flows through this neural network, and it spits out the answer.", "tokens": [50638, 597, 12867, 807, 341, 18161, 3209, 11, 293, 309, 637, 1208, 484, 264, 1867, 13, 50828], "temperature": 0.0, "avg_logprob": -0.10910178290473091, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0636940523982048}, {"id": 38, "seek": 14084, "start": 150.12, "end": 151.12, "text": " This is a dog.", "tokens": [50828, 639, 307, 257, 3000, 13, 50878], "temperature": 0.0, "avg_logprob": -0.10910178290473091, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0636940523982048}, {"id": 39, "seek": 14084, "start": 151.12, "end": 156.08, "text": " Well, in that case, since it got the answer correct, it's likely that these dials and", "tokens": [50878, 1042, 11, 294, 300, 1389, 11, 1670, 309, 658, 264, 1867, 3006, 11, 309, 311, 3700, 300, 613, 5502, 82, 293, 51126], "temperature": 0.0, "avg_logprob": -0.10910178290473091, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0636940523982048}, {"id": 40, "seek": 14084, "start": 156.08, "end": 160.56, "text": " knobs, which we can also refer to as weights, are set correctly.", "tokens": [51126, 46999, 11, 597, 321, 393, 611, 2864, 281, 382, 17443, 11, 366, 992, 8944, 13, 51350], "temperature": 0.0, "avg_logprob": -0.10910178290473091, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0636940523982048}, {"id": 41, "seek": 14084, "start": 160.56, "end": 165.32, "text": " If it gets the answer right, well, we don't really need to tweak these weights further.", "tokens": [51350, 759, 309, 2170, 264, 1867, 558, 11, 731, 11, 321, 500, 380, 534, 643, 281, 29879, 613, 17443, 3052, 13, 51588], "temperature": 0.0, "avg_logprob": -0.10910178290473091, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0636940523982048}, {"id": 42, "seek": 14084, "start": 165.32, "end": 167.44, "text": " However, what if it gets it wrong?", "tokens": [51588, 2908, 11, 437, 498, 309, 2170, 309, 2085, 30, 51694], "temperature": 0.0, "avg_logprob": -0.10910178290473091, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0636940523982048}, {"id": 43, "seek": 14084, "start": 167.44, "end": 169.68, "text": " What if it says that this is a cat?", "tokens": [51694, 708, 498, 309, 1619, 300, 341, 307, 257, 3857, 30, 51806], "temperature": 0.0, "avg_logprob": -0.10910178290473091, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.0636940523982048}, {"id": 44, "seek": 16968, "start": 169.68, "end": 173.0, "text": " Well, in that case, it would incur a penalty.", "tokens": [50364, 1042, 11, 294, 300, 1389, 11, 309, 576, 35774, 257, 16263, 13, 50530], "temperature": 0.0, "avg_logprob": -0.11677393823299768, "compression_ratio": 1.8375, "no_speech_prob": 0.06557370722293854}, {"id": 45, "seek": 16968, "start": 173.0, "end": 177.72, "text": " And this penalty would cause the weights in this neural network to be updated so that", "tokens": [50530, 400, 341, 16263, 576, 3082, 264, 17443, 294, 341, 18161, 3209, 281, 312, 10588, 370, 300, 50766], "temperature": 0.0, "avg_logprob": -0.11677393823299768, "compression_ratio": 1.8375, "no_speech_prob": 0.06557370722293854}, {"id": 46, "seek": 16968, "start": 177.72, "end": 180.76000000000002, "text": " this penalty would be minimized in the future.", "tokens": [50766, 341, 16263, 576, 312, 4464, 1602, 294, 264, 2027, 13, 50918], "temperature": 0.0, "avg_logprob": -0.11677393823299768, "compression_ratio": 1.8375, "no_speech_prob": 0.06557370722293854}, {"id": 47, "seek": 16968, "start": 180.76000000000002, "end": 185.44, "text": " Specifically, the weights would be updated from the last layer to the next layer back", "tokens": [50918, 26058, 11, 264, 17443, 576, 312, 10588, 490, 264, 1036, 4583, 281, 264, 958, 4583, 646, 51152], "temperature": 0.0, "avg_logprob": -0.11677393823299768, "compression_ratio": 1.8375, "no_speech_prob": 0.06557370722293854}, {"id": 48, "seek": 16968, "start": 185.44, "end": 190.28, "text": " to the next layer back in a process which is called back propagation all the way until", "tokens": [51152, 281, 264, 958, 4583, 646, 294, 257, 1399, 597, 307, 1219, 646, 38377, 439, 264, 636, 1826, 51394], "temperature": 0.0, "avg_logprob": -0.11677393823299768, "compression_ratio": 1.8375, "no_speech_prob": 0.06557370722293854}, {"id": 49, "seek": 16968, "start": 190.28, "end": 193.08, "text": " it reaches the first layer of nodes.", "tokens": [51394, 309, 14235, 264, 700, 4583, 295, 13891, 13, 51534], "temperature": 0.0, "avg_logprob": -0.11677393823299768, "compression_ratio": 1.8375, "no_speech_prob": 0.06557370722293854}, {"id": 50, "seek": 16968, "start": 193.08, "end": 196.24, "text": " And usually one round of training isn't good enough.", "tokens": [51534, 400, 2673, 472, 3098, 295, 3097, 1943, 380, 665, 1547, 13, 51692], "temperature": 0.0, "avg_logprob": -0.11677393823299768, "compression_ratio": 1.8375, "no_speech_prob": 0.06557370722293854}, {"id": 51, "seek": 19624, "start": 196.24, "end": 200.84, "text": " So the network would undergo millions of rounds of training where the weights would", "tokens": [50364, 407, 264, 3209, 576, 26426, 6803, 295, 13757, 295, 3097, 689, 264, 17443, 576, 50594], "temperature": 0.0, "avg_logprob": -0.08676671479877672, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.012819532305002213}, {"id": 52, "seek": 19624, "start": 200.84, "end": 206.28, "text": " be slightly tweaked to minimize the penalty incurred from any errors.", "tokens": [50594, 312, 4748, 6986, 7301, 281, 17522, 264, 16263, 35774, 986, 490, 604, 13603, 13, 50866], "temperature": 0.0, "avg_logprob": -0.08676671479877672, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.012819532305002213}, {"id": 53, "seek": 19624, "start": 206.28, "end": 211.76000000000002, "text": " And this goes on and on until finally, we reach the right configuration of dials and", "tokens": [50866, 400, 341, 1709, 322, 293, 322, 1826, 2721, 11, 321, 2524, 264, 558, 11694, 295, 5502, 82, 293, 51140], "temperature": 0.0, "avg_logprob": -0.08676671479877672, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.012819532305002213}, {"id": 54, "seek": 19624, "start": 211.76000000000002, "end": 217.24, "text": " knobs so that this neural network can very accurately determine whether any image is", "tokens": [51140, 46999, 370, 300, 341, 18161, 3209, 393, 588, 20095, 6997, 1968, 604, 3256, 307, 51414], "temperature": 0.0, "avg_logprob": -0.08676671479877672, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.012819532305002213}, {"id": 55, "seek": 19624, "start": 217.24, "end": 219.0, "text": " a cat or a dog.", "tokens": [51414, 257, 3857, 420, 257, 3000, 13, 51502], "temperature": 0.0, "avg_logprob": -0.08676671479877672, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.012819532305002213}, {"id": 56, "seek": 19624, "start": 219.0, "end": 223.28, "text": " And this is how AI models that we know today are trained as well.", "tokens": [51502, 400, 341, 307, 577, 7318, 5245, 300, 321, 458, 965, 366, 8895, 382, 731, 13, 51716], "temperature": 0.0, "avg_logprob": -0.08676671479877672, "compression_ratio": 1.6330645161290323, "no_speech_prob": 0.012819532305002213}, {"id": 57, "seek": 22328, "start": 223.28, "end": 229.96, "text": " So for example, GPT is basically a neural network, but these dials and knobs are optimized", "tokens": [50364, 407, 337, 1365, 11, 26039, 51, 307, 1936, 257, 18161, 3209, 11, 457, 613, 5502, 82, 293, 46999, 366, 26941, 50698], "temperature": 0.0, "avg_logprob": -0.09954060340414242, "compression_ratio": 1.7416666666666667, "no_speech_prob": 0.3169713020324707}, {"id": 58, "seek": 22328, "start": 229.96, "end": 232.72, "text": " for understanding natural language.", "tokens": [50698, 337, 3701, 3303, 2856, 13, 50836], "temperature": 0.0, "avg_logprob": -0.09954060340414242, "compression_ratio": 1.7416666666666667, "no_speech_prob": 0.3169713020324707}, {"id": 59, "seek": 22328, "start": 232.72, "end": 237.16, "text": " Stable diffusion is another neural network where the dials and knobs are optimized for", "tokens": [50836, 745, 712, 25242, 307, 1071, 18161, 3209, 689, 264, 5502, 82, 293, 46999, 366, 26941, 337, 51058], "temperature": 0.0, "avg_logprob": -0.09954060340414242, "compression_ratio": 1.7416666666666667, "no_speech_prob": 0.3169713020324707}, {"id": 60, "seek": 22328, "start": 237.16, "end": 238.96, "text": " image generation.", "tokens": [51058, 3256, 5125, 13, 51148], "temperature": 0.0, "avg_logprob": -0.09954060340414242, "compression_ratio": 1.7416666666666667, "no_speech_prob": 0.3169713020324707}, {"id": 61, "seek": 22328, "start": 238.96, "end": 245.46, "text": " Now again, this is very much an oversimplification and the architecture or basically the design", "tokens": [51148, 823, 797, 11, 341, 307, 588, 709, 364, 15488, 332, 564, 3774, 293, 264, 9482, 420, 1936, 264, 1715, 51473], "temperature": 0.0, "avg_logprob": -0.09954060340414242, "compression_ratio": 1.7416666666666667, "no_speech_prob": 0.3169713020324707}, {"id": 62, "seek": 22328, "start": 245.46, "end": 248.56, "text": " of the neural network is also very important.", "tokens": [51473, 295, 264, 18161, 3209, 307, 611, 588, 1021, 13, 51628], "temperature": 0.0, "avg_logprob": -0.09954060340414242, "compression_ratio": 1.7416666666666667, "no_speech_prob": 0.3169713020324707}, {"id": 63, "seek": 22328, "start": 248.56, "end": 251.88, "text": " For example, how many layers should we have?", "tokens": [51628, 1171, 1365, 11, 577, 867, 7914, 820, 321, 362, 30, 51794], "temperature": 0.0, "avg_logprob": -0.09954060340414242, "compression_ratio": 1.7416666666666667, "no_speech_prob": 0.3169713020324707}, {"id": 64, "seek": 25188, "start": 251.88, "end": 255.4, "text": " How many nodes in each layer should we have?", "tokens": [50364, 1012, 867, 13891, 294, 1184, 4583, 820, 321, 362, 30, 50540], "temperature": 0.0, "avg_logprob": -0.12084021027555171, "compression_ratio": 1.5741444866920151, "no_speech_prob": 0.012818182818591595}, {"id": 65, "seek": 25188, "start": 255.4, "end": 261.68, "text": " There are also many different architectures, such as the transformer model for large language", "tokens": [50540, 821, 366, 611, 867, 819, 6331, 1303, 11, 1270, 382, 264, 31782, 2316, 337, 2416, 2856, 50854], "temperature": 0.0, "avg_logprob": -0.12084021027555171, "compression_ratio": 1.5741444866920151, "no_speech_prob": 0.012818182818591595}, {"id": 66, "seek": 25188, "start": 261.68, "end": 269.08, "text": " models or LSTM for time series data or convolutional neural networks for object detection and image", "tokens": [50854, 5245, 420, 441, 6840, 44, 337, 565, 2638, 1412, 420, 45216, 304, 18161, 9590, 337, 2657, 17784, 293, 3256, 51224], "temperature": 0.0, "avg_logprob": -0.12084021027555171, "compression_ratio": 1.5741444866920151, "no_speech_prob": 0.012818182818591595}, {"id": 67, "seek": 25188, "start": 269.08, "end": 270.64, "text": " classification.", "tokens": [51224, 21538, 13, 51302], "temperature": 0.0, "avg_logprob": -0.12084021027555171, "compression_ratio": 1.5741444866920151, "no_speech_prob": 0.012818182818591595}, {"id": 68, "seek": 25188, "start": 270.64, "end": 276.12, "text": " But in a nutshell, the backbone behind all these AI models is just a neural network,", "tokens": [51302, 583, 294, 257, 37711, 11, 264, 34889, 2261, 439, 613, 7318, 5245, 307, 445, 257, 18161, 3209, 11, 51576], "temperature": 0.0, "avg_logprob": -0.12084021027555171, "compression_ratio": 1.5741444866920151, "no_speech_prob": 0.012818182818591595}, {"id": 69, "seek": 25188, "start": 276.12, "end": 281.15999999999997, "text": " which has a preconfigured set of dials and knobs to do the job accurately.", "tokens": [51576, 597, 575, 257, 47473, 20646, 3831, 992, 295, 5502, 82, 293, 46999, 281, 360, 264, 1691, 20095, 13, 51828], "temperature": 0.0, "avg_logprob": -0.12084021027555171, "compression_ratio": 1.5741444866920151, "no_speech_prob": 0.012818182818591595}, {"id": 70, "seek": 28116, "start": 281.16, "end": 285.52000000000004, "text": " So now that you understand how the current generation of AI works, let's look at the", "tokens": [50364, 407, 586, 300, 291, 1223, 577, 264, 2190, 5125, 295, 7318, 1985, 11, 718, 311, 574, 412, 264, 50582], "temperature": 0.0, "avg_logprob": -0.09903847087513316, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.05832703411579132}, {"id": 71, "seek": 28116, "start": 285.52000000000004, "end": 288.20000000000005, "text": " biggest limitations of this.", "tokens": [50582, 3880, 15705, 295, 341, 13, 50716], "temperature": 0.0, "avg_logprob": -0.09903847087513316, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.05832703411579132}, {"id": 72, "seek": 28116, "start": 288.20000000000005, "end": 293.40000000000003, "text": " First of all, once the model is finished training, the weights or basically these dials and knobs", "tokens": [50716, 2386, 295, 439, 11, 1564, 264, 2316, 307, 4335, 3097, 11, 264, 17443, 420, 1936, 613, 5502, 82, 293, 46999, 50976], "temperature": 0.0, "avg_logprob": -0.09903847087513316, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.05832703411579132}, {"id": 73, "seek": 28116, "start": 293.40000000000003, "end": 295.12, "text": " are fixed in value.", "tokens": [50976, 366, 6806, 294, 2158, 13, 51062], "temperature": 0.0, "avg_logprob": -0.09903847087513316, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.05832703411579132}, {"id": 74, "seek": 28116, "start": 295.12, "end": 300.76000000000005, "text": " When the user asks chat GPT something or when the user uses stable diffusion to generate", "tokens": [51062, 1133, 264, 4195, 8962, 5081, 26039, 51, 746, 420, 562, 264, 4195, 4960, 8351, 25242, 281, 8460, 51344], "temperature": 0.0, "avg_logprob": -0.09903847087513316, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.05832703411579132}, {"id": 75, "seek": 28116, "start": 300.76000000000005, "end": 304.32000000000005, "text": " an image, these dials and knobs do not change in value.", "tokens": [51344, 364, 3256, 11, 613, 5502, 82, 293, 46999, 360, 406, 1319, 294, 2158, 13, 51522], "temperature": 0.0, "avg_logprob": -0.09903847087513316, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.05832703411579132}, {"id": 76, "seek": 28116, "start": 304.32000000000005, "end": 308.36, "text": " In other words, all the AI models that we have today are fixed.", "tokens": [51522, 682, 661, 2283, 11, 439, 264, 7318, 5245, 300, 321, 362, 965, 366, 6806, 13, 51724], "temperature": 0.0, "avg_logprob": -0.09903847087513316, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.05832703411579132}, {"id": 77, "seek": 30836, "start": 308.36, "end": 313.08000000000004, "text": " Think of this as a brain that cannot learn or get any smarter.", "tokens": [50364, 6557, 295, 341, 382, 257, 3567, 300, 2644, 1466, 420, 483, 604, 20294, 13, 50600], "temperature": 0.0, "avg_logprob": -0.12570611217565703, "compression_ratio": 1.751054852320675, "no_speech_prob": 0.7682854533195496}, {"id": 78, "seek": 30836, "start": 313.08000000000004, "end": 319.16, "text": " For example, GPT-4 cannot continue learning and become smarter and smarter with time.", "tokens": [50600, 1171, 1365, 11, 26039, 51, 12, 19, 2644, 2354, 2539, 293, 1813, 20294, 293, 20294, 365, 565, 13, 50904], "temperature": 0.0, "avg_logprob": -0.12570611217565703, "compression_ratio": 1.751054852320675, "no_speech_prob": 0.7682854533195496}, {"id": 79, "seek": 30836, "start": 319.16, "end": 326.16, "text": " If we want a smarter model, well, we need to train a new generation of GPT such as GPT-4.0", "tokens": [50904, 759, 321, 528, 257, 20294, 2316, 11, 731, 11, 321, 643, 281, 3847, 257, 777, 5125, 295, 26039, 51, 1270, 382, 26039, 51, 12, 19, 13, 15, 51254], "temperature": 0.0, "avg_logprob": -0.12570611217565703, "compression_ratio": 1.751054852320675, "no_speech_prob": 0.7682854533195496}, {"id": 80, "seek": 30836, "start": 326.16, "end": 329.12, "text": " or GPT-5 or whatever you want to call it.", "tokens": [51254, 420, 26039, 51, 12, 20, 420, 2035, 291, 528, 281, 818, 309, 13, 51402], "temperature": 0.0, "avg_logprob": -0.12570611217565703, "compression_ratio": 1.751054852320675, "no_speech_prob": 0.7682854533195496}, {"id": 81, "seek": 30836, "start": 329.12, "end": 330.72, "text": " Same with stable diffusion.", "tokens": [51402, 10635, 365, 8351, 25242, 13, 51482], "temperature": 0.0, "avg_logprob": -0.12570611217565703, "compression_ratio": 1.751054852320675, "no_speech_prob": 0.7682854533195496}, {"id": 82, "seek": 30836, "start": 330.72, "end": 336.04, "text": " For example, stable diffusion 2 cannot get smarter and generate better images as we use", "tokens": [51482, 1171, 1365, 11, 8351, 25242, 568, 2644, 483, 20294, 293, 8460, 1101, 5267, 382, 321, 764, 51748], "temperature": 0.0, "avg_logprob": -0.12570611217565703, "compression_ratio": 1.751054852320675, "no_speech_prob": 0.7682854533195496}, {"id": 83, "seek": 30836, "start": 336.04, "end": 337.18, "text": " it more and more.", "tokens": [51748, 309, 544, 293, 544, 13, 51805], "temperature": 0.0, "avg_logprob": -0.12570611217565703, "compression_ratio": 1.751054852320675, "no_speech_prob": 0.7682854533195496}, {"id": 84, "seek": 33718, "start": 337.18, "end": 342.78000000000003, "text": " In order for it to improve, we currently need to train a new generation, also known as stable", "tokens": [50364, 682, 1668, 337, 309, 281, 3470, 11, 321, 4362, 643, 281, 3847, 257, 777, 5125, 11, 611, 2570, 382, 8351, 50644], "temperature": 0.0, "avg_logprob": -0.09563447675134382, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.0050597419030964375}, {"id": 85, "seek": 33718, "start": 342.78000000000003, "end": 344.28000000000003, "text": " diffusion 3.", "tokens": [50644, 25242, 805, 13, 50719], "temperature": 0.0, "avg_logprob": -0.09563447675134382, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.0050597419030964375}, {"id": 86, "seek": 33718, "start": 344.28000000000003, "end": 349.54, "text": " And once stable diffusion 3 is finished training, well, that's as smart as it gets.", "tokens": [50719, 400, 1564, 8351, 25242, 805, 307, 4335, 3097, 11, 731, 11, 300, 311, 382, 4069, 382, 309, 2170, 13, 50982], "temperature": 0.0, "avg_logprob": -0.09563447675134382, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.0050597419030964375}, {"id": 87, "seek": 33718, "start": 349.54, "end": 353.54, "text": " And if you don't think it's good enough, well, you need to train a new model.", "tokens": [50982, 400, 498, 291, 500, 380, 519, 309, 311, 665, 1547, 11, 731, 11, 291, 643, 281, 3847, 257, 777, 2316, 13, 51182], "temperature": 0.0, "avg_logprob": -0.09563447675134382, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.0050597419030964375}, {"id": 88, "seek": 33718, "start": 353.54, "end": 359.22, "text": " So basically all the AI models that we have today are fixed in their intelligence and", "tokens": [51182, 407, 1936, 439, 264, 7318, 5245, 300, 321, 362, 965, 366, 6806, 294, 641, 7599, 293, 51466], "temperature": 0.0, "avg_logprob": -0.09563447675134382, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.0050597419030964375}, {"id": 89, "seek": 33718, "start": 359.22, "end": 360.42, "text": " their capabilities.", "tokens": [51466, 641, 10862, 13, 51526], "temperature": 0.0, "avg_logprob": -0.09563447675134382, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.0050597419030964375}, {"id": 90, "seek": 33718, "start": 360.42, "end": 366.42, "text": " Again, think of this as a brain that has stopped growing and cannot learn or get smarter.", "tokens": [51526, 3764, 11, 519, 295, 341, 382, 257, 3567, 300, 575, 5936, 4194, 293, 2644, 1466, 420, 483, 20294, 13, 51826], "temperature": 0.0, "avg_logprob": -0.09563447675134382, "compression_ratio": 1.724907063197026, "no_speech_prob": 0.0050597419030964375}, {"id": 91, "seek": 36642, "start": 366.42, "end": 368.90000000000003, "text": " But this is not how the human brain works.", "tokens": [50364, 583, 341, 307, 406, 577, 264, 1952, 3567, 1985, 13, 50488], "temperature": 0.0, "avg_logprob": -0.1126499090875898, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.020326483994722366}, {"id": 92, "seek": 36642, "start": 368.90000000000003, "end": 374.54, "text": " There's a term called neuroplasticity, which refers to how the brain can reorganize or", "tokens": [50488, 821, 311, 257, 1433, 1219, 16499, 564, 2750, 507, 11, 597, 14942, 281, 577, 264, 3567, 393, 41203, 1125, 420, 50770], "temperature": 0.0, "avg_logprob": -0.1126499090875898, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.020326483994722366}, {"id": 93, "seek": 36642, "start": 374.54, "end": 380.82, "text": " reconfigure itself by forming new neural connections over time in order to adapt to new environments", "tokens": [50770, 9993, 20646, 540, 2564, 538, 15745, 777, 18161, 9271, 670, 565, 294, 1668, 281, 6231, 281, 777, 12388, 51084], "temperature": 0.0, "avg_logprob": -0.1126499090875898, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.020326483994722366}, {"id": 94, "seek": 36642, "start": 380.82, "end": 382.14000000000004, "text": " or learn new things.", "tokens": [51084, 420, 1466, 777, 721, 13, 51150], "temperature": 0.0, "avg_logprob": -0.1126499090875898, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.020326483994722366}, {"id": 95, "seek": 36642, "start": 382.14000000000004, "end": 386.78000000000003, "text": " And that's exactly what the next generation of AI can do, which we'll talk about in a", "tokens": [51150, 400, 300, 311, 2293, 437, 264, 958, 5125, 295, 7318, 393, 360, 11, 597, 321, 603, 751, 466, 294, 257, 51382], "temperature": 0.0, "avg_logprob": -0.1126499090875898, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.020326483994722366}, {"id": 96, "seek": 36642, "start": 386.78000000000003, "end": 387.78000000000003, "text": " second.", "tokens": [51382, 1150, 13, 51432], "temperature": 0.0, "avg_logprob": -0.1126499090875898, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.020326483994722366}, {"id": 97, "seek": 36642, "start": 387.78000000000003, "end": 391.22, "text": " But there's another huge limitation of current AI models.", "tokens": [51432, 583, 456, 311, 1071, 2603, 27432, 295, 2190, 7318, 5245, 13, 51604], "temperature": 0.0, "avg_logprob": -0.1126499090875898, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.020326483994722366}, {"id": 98, "seek": 36642, "start": 391.22, "end": 395.5, "text": " They are extremely inefficient and compute intensive.", "tokens": [51604, 814, 366, 4664, 43495, 293, 14722, 18957, 13, 51818], "temperature": 0.0, "avg_logprob": -0.1126499090875898, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.020326483994722366}, {"id": 99, "seek": 39550, "start": 395.5, "end": 400.1, "text": " As you may know, AI is designed based on the architecture of the human brain.", "tokens": [50364, 1018, 291, 815, 458, 11, 7318, 307, 4761, 2361, 322, 264, 9482, 295, 264, 1952, 3567, 13, 50594], "temperature": 0.0, "avg_logprob": -0.11349622319253642, "compression_ratio": 1.4914529914529915, "no_speech_prob": 0.10368944704532623}, {"id": 100, "seek": 39550, "start": 400.1, "end": 404.54, "text": " So let's compare it to the efficiency of the human brain right now.", "tokens": [50594, 407, 718, 311, 6794, 309, 281, 264, 10493, 295, 264, 1952, 3567, 558, 586, 13, 50816], "temperature": 0.0, "avg_logprob": -0.11349622319253642, "compression_ratio": 1.4914529914529915, "no_speech_prob": 0.10368944704532623}, {"id": 101, "seek": 39550, "start": 404.54, "end": 409.92, "text": " GPT-3 has 175 billion parameters.", "tokens": [50816, 26039, 51, 12, 18, 575, 41165, 5218, 9834, 13, 51085], "temperature": 0.0, "avg_logprob": -0.11349622319253642, "compression_ratio": 1.4914529914529915, "no_speech_prob": 0.10368944704532623}, {"id": 102, "seek": 39550, "start": 409.92, "end": 416.3, "text": " This was trained using thousands of GPUs over several weeks or several months.", "tokens": [51085, 639, 390, 8895, 1228, 5383, 295, 18407, 82, 670, 2940, 3259, 420, 2940, 2493, 13, 51404], "temperature": 0.0, "avg_logprob": -0.11349622319253642, "compression_ratio": 1.4914529914529915, "no_speech_prob": 0.10368944704532623}, {"id": 103, "seek": 39550, "start": 416.3, "end": 425.06, "text": " The total power required for training GPT-3 was estimated to be around 1287 megawatt hours", "tokens": [51404, 440, 3217, 1347, 4739, 337, 3097, 26039, 51, 12, 18, 390, 14109, 281, 312, 926, 2272, 23853, 10816, 1607, 1591, 2496, 51842], "temperature": 0.0, "avg_logprob": -0.11349622319253642, "compression_ratio": 1.4914529914529915, "no_speech_prob": 0.10368944704532623}, {"id": 104, "seek": 42506, "start": 425.46, "end": 426.58, "text": " of electricity.", "tokens": [50384, 295, 10356, 13, 50440], "temperature": 0.0, "avg_logprob": -0.1605713170602781, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.2225068062543869}, {"id": 105, "seek": 42506, "start": 426.58, "end": 432.66, "text": " This is roughly equivalent to the monthly electricity consumption of 1500 homes in the", "tokens": [50440, 639, 307, 9810, 10344, 281, 264, 12878, 10356, 12126, 295, 22671, 7388, 294, 264, 50744], "temperature": 0.0, "avg_logprob": -0.1605713170602781, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.2225068062543869}, {"id": 106, "seek": 42506, "start": 432.66, "end": 433.66, "text": " USA.", "tokens": [50744, 10827, 13, 50794], "temperature": 0.0, "avg_logprob": -0.1605713170602781, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.2225068062543869}, {"id": 107, "seek": 42506, "start": 433.66, "end": 438.14, "text": " Now, keep in mind GPT-3 was completed in 2020.", "tokens": [50794, 823, 11, 1066, 294, 1575, 26039, 51, 12, 18, 390, 7365, 294, 4808, 13, 51018], "temperature": 0.0, "avg_logprob": -0.1605713170602781, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.2225068062543869}, {"id": 108, "seek": 42506, "start": 438.14, "end": 439.7, "text": " That's four years ago.", "tokens": [51018, 663, 311, 1451, 924, 2057, 13, 51096], "temperature": 0.0, "avg_logprob": -0.1605713170602781, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.2225068062543869}, {"id": 109, "seek": 42506, "start": 439.7, "end": 443.14, "text": " The latest version, GPT-4, is closed source.", "tokens": [51096, 440, 6792, 3037, 11, 26039, 51, 12, 19, 11, 307, 5395, 4009, 13, 51268], "temperature": 0.0, "avg_logprob": -0.1605713170602781, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.2225068062543869}, {"id": 110, "seek": 42506, "start": 443.14, "end": 447.98, "text": " So we don't actually know its architecture or how long it took to train.", "tokens": [51268, 407, 321, 500, 380, 767, 458, 1080, 9482, 420, 577, 938, 309, 1890, 281, 3847, 13, 51510], "temperature": 0.0, "avg_logprob": -0.1605713170602781, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.2225068062543869}, {"id": 111, "seek": 42506, "start": 447.98, "end": 455.02, "text": " But we do know that it has around 1.76 trillion parameters, 10 times more than GPT-3.", "tokens": [51510, 583, 321, 360, 458, 300, 309, 575, 926, 502, 13, 25026, 18723, 9834, 11, 1266, 1413, 544, 813, 26039, 51, 12, 18, 13, 51862], "temperature": 0.0, "avg_logprob": -0.1605713170602781, "compression_ratio": 1.4767441860465116, "no_speech_prob": 0.2225068062543869}, {"id": 112, "seek": 45502, "start": 455.02, "end": 460.85999999999996, "text": " Keep in mind that the amount of computations required scales exponentially as the parameter", "tokens": [50364, 5527, 294, 1575, 300, 264, 2372, 295, 2807, 763, 4739, 17408, 37330, 382, 264, 13075, 50656], "temperature": 0.0, "avg_logprob": -0.10617699342615464, "compression_ratio": 1.4900398406374502, "no_speech_prob": 0.002889223862439394}, {"id": 113, "seek": 45502, "start": 460.85999999999996, "end": 462.62, "text": " size gets larger.", "tokens": [50656, 2744, 2170, 4833, 13, 50744], "temperature": 0.0, "avg_logprob": -0.10617699342615464, "compression_ratio": 1.4900398406374502, "no_speech_prob": 0.002889223862439394}, {"id": 114, "seek": 45502, "start": 462.62, "end": 469.94, "text": " So from a rough calculation, GPT-4 could have taken around 41,000 megawatt hours of", "tokens": [50744, 407, 490, 257, 5903, 17108, 11, 26039, 51, 12, 19, 727, 362, 2726, 926, 18173, 11, 1360, 10816, 1607, 1591, 2496, 295, 51110], "temperature": 0.0, "avg_logprob": -0.10617699342615464, "compression_ratio": 1.4900398406374502, "no_speech_prob": 0.002889223862439394}, {"id": 115, "seek": 45502, "start": 469.94, "end": 471.78, "text": " energy to train.", "tokens": [51110, 2281, 281, 3847, 13, 51202], "temperature": 0.0, "avg_logprob": -0.10617699342615464, "compression_ratio": 1.4900398406374502, "no_speech_prob": 0.002889223862439394}, {"id": 116, "seek": 45502, "start": 471.78, "end": 477.82, "text": " That's enough energy to power around 47,000 homes in the US for a month.", "tokens": [51202, 663, 311, 1547, 2281, 281, 1347, 926, 16953, 11, 1360, 7388, 294, 264, 2546, 337, 257, 1618, 13, 51504], "temperature": 0.0, "avg_logprob": -0.10617699342615464, "compression_ratio": 1.4900398406374502, "no_speech_prob": 0.002889223862439394}, {"id": 117, "seek": 45502, "start": 477.82, "end": 484.21999999999997, "text": " The compute used to create these state-of-the-art models that we know today, such as GPT-4", "tokens": [51504, 440, 14722, 1143, 281, 1884, 613, 1785, 12, 2670, 12, 3322, 12, 446, 5245, 300, 321, 458, 965, 11, 1270, 382, 26039, 51, 12, 19, 51824], "temperature": 0.0, "avg_logprob": -0.10617699342615464, "compression_ratio": 1.4900398406374502, "no_speech_prob": 0.002889223862439394}, {"id": 118, "seek": 48422, "start": 484.22, "end": 491.02000000000004, "text": " Clawd-3 or Gemini 1.5 Pro, requires massive data centers and a lot of energy.", "tokens": [50364, 383, 5901, 67, 12, 18, 420, 22894, 3812, 502, 13, 20, 1705, 11, 7029, 5994, 1412, 10898, 293, 257, 688, 295, 2281, 13, 50704], "temperature": 0.0, "avg_logprob": -0.16256207758837407, "compression_ratio": 1.505791505791506, "no_speech_prob": 0.09802688658237457}, {"id": 119, "seek": 48422, "start": 491.02000000000004, "end": 496.14000000000004, "text": " That's why tech giants are scrambling to invest and build even bigger data centers,", "tokens": [50704, 663, 311, 983, 7553, 31894, 366, 5918, 19391, 281, 1963, 293, 1322, 754, 3801, 1412, 10898, 11, 50960], "temperature": 0.0, "avg_logprob": -0.16256207758837407, "compression_ratio": 1.505791505791506, "no_speech_prob": 0.09802688658237457}, {"id": 120, "seek": 48422, "start": 496.14000000000004, "end": 499.90000000000003, "text": " because they know that compute is the main limitation here.", "tokens": [50960, 570, 436, 458, 300, 14722, 307, 264, 2135, 27432, 510, 13, 51148], "temperature": 0.0, "avg_logprob": -0.16256207758837407, "compression_ratio": 1.505791505791506, "no_speech_prob": 0.09802688658237457}, {"id": 121, "seek": 48422, "start": 499.90000000000003, "end": 506.22, "text": " And that's exactly why Microsoft and OpenAI are planning a $100 billion Stargate project", "tokens": [51148, 400, 300, 311, 2293, 983, 8116, 293, 7238, 48698, 366, 5038, 257, 1848, 6879, 5218, 5705, 22514, 1716, 51464], "temperature": 0.0, "avg_logprob": -0.16256207758837407, "compression_ratio": 1.505791505791506, "no_speech_prob": 0.09802688658237457}, {"id": 122, "seek": 48422, "start": 506.22, "end": 509.06, "text": " to build the biggest data center in the world.", "tokens": [51464, 281, 1322, 264, 3880, 1412, 3056, 294, 264, 1002, 13, 51606], "temperature": 0.0, "avg_logprob": -0.16256207758837407, "compression_ratio": 1.505791505791506, "no_speech_prob": 0.09802688658237457}, {"id": 123, "seek": 48422, "start": 509.06, "end": 511.74, "text": " All of this is for more compute.", "tokens": [51606, 1057, 295, 341, 307, 337, 544, 14722, 13, 51740], "temperature": 0.0, "avg_logprob": -0.16256207758837407, "compression_ratio": 1.505791505791506, "no_speech_prob": 0.09802688658237457}, {"id": 124, "seek": 51174, "start": 511.74, "end": 514.5, "text": " Now contrast this to the human brain.", "tokens": [50364, 823, 8712, 341, 281, 264, 1952, 3567, 13, 50502], "temperature": 0.0, "avg_logprob": -0.07421593089680095, "compression_ratio": 1.5829596412556053, "no_speech_prob": 0.4603578746318817}, {"id": 125, "seek": 51174, "start": 514.5, "end": 520.42, "text": " Some might say the human brain is still more intelligent than GPT-4, at least in some regards.", "tokens": [50502, 2188, 1062, 584, 264, 1952, 3567, 307, 920, 544, 13232, 813, 26039, 51, 12, 19, 11, 412, 1935, 294, 512, 14258, 13, 50798], "temperature": 0.0, "avg_logprob": -0.07421593089680095, "compression_ratio": 1.5829596412556053, "no_speech_prob": 0.4603578746318817}, {"id": 126, "seek": 51174, "start": 520.42, "end": 528.02, "text": " The human brain only uses 175 kilowatt hours in an entire year, and it gets this energy", "tokens": [50798, 440, 1952, 3567, 787, 4960, 41165, 41295, 1591, 2496, 294, 364, 2302, 1064, 11, 293, 309, 2170, 341, 2281, 51178], "temperature": 0.0, "avg_logprob": -0.07421593089680095, "compression_ratio": 1.5829596412556053, "no_speech_prob": 0.4603578746318817}, {"id": 127, "seek": 51174, "start": 528.02, "end": 530.98, "text": " in the form of calories from the food we eat.", "tokens": [51178, 294, 264, 1254, 295, 14904, 490, 264, 1755, 321, 1862, 13, 51326], "temperature": 0.0, "avg_logprob": -0.07421593089680095, "compression_ratio": 1.5829596412556053, "no_speech_prob": 0.4603578746318817}, {"id": 128, "seek": 51174, "start": 530.98, "end": 538.98, "text": " So training GPT-4 is estimated to require approximately 234,000 times more energy than", "tokens": [51326, 407, 3097, 26039, 51, 12, 19, 307, 14109, 281, 3651, 10447, 6673, 19, 11, 1360, 1413, 544, 2281, 813, 51726], "temperature": 0.0, "avg_logprob": -0.07421593089680095, "compression_ratio": 1.5829596412556053, "no_speech_prob": 0.4603578746318817}, {"id": 129, "seek": 53898, "start": 538.98, "end": 542.46, "text": " what the human brain uses in an entire year.", "tokens": [50364, 437, 264, 1952, 3567, 4960, 294, 364, 2302, 1064, 13, 50538], "temperature": 0.0, "avg_logprob": -0.09970956802368164, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.037312112748622894}, {"id": 130, "seek": 53898, "start": 542.46, "end": 548.1, "text": " In other words, the energy required to train GPT-4 once could power the human brain for", "tokens": [50538, 682, 661, 2283, 11, 264, 2281, 4739, 281, 3847, 26039, 51, 12, 19, 1564, 727, 1347, 264, 1952, 3567, 337, 50820], "temperature": 0.0, "avg_logprob": -0.09970956802368164, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.037312112748622894}, {"id": 131, "seek": 53898, "start": 548.1, "end": 552.0600000000001, "text": " over 234,000 years.", "tokens": [50820, 670, 6673, 19, 11, 1360, 924, 13, 51018], "temperature": 0.0, "avg_logprob": -0.09970956802368164, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.037312112748622894}, {"id": 132, "seek": 53898, "start": 552.0600000000001, "end": 556.3000000000001, "text": " Now I gave this comparison to show you that there's something fundamentally wrong with", "tokens": [51018, 823, 286, 2729, 341, 9660, 281, 855, 291, 300, 456, 311, 746, 17879, 2085, 365, 51230], "temperature": 0.0, "avg_logprob": -0.09970956802368164, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.037312112748622894}, {"id": 133, "seek": 53898, "start": 556.3000000000001, "end": 558.02, "text": " AI models today.", "tokens": [51230, 7318, 5245, 965, 13, 51316], "temperature": 0.0, "avg_logprob": -0.09970956802368164, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.037312112748622894}, {"id": 134, "seek": 53898, "start": 558.02, "end": 563.1, "text": " They are very energy inefficient, and they take up a lot of compute.", "tokens": [51316, 814, 366, 588, 2281, 43495, 11, 293, 436, 747, 493, 257, 688, 295, 14722, 13, 51570], "temperature": 0.0, "avg_logprob": -0.09970956802368164, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.037312112748622894}, {"id": 135, "seek": 53898, "start": 563.1, "end": 566.66, "text": " It's not even close to the efficiency of the human brain.", "tokens": [51570, 467, 311, 406, 754, 1998, 281, 264, 10493, 295, 264, 1952, 3567, 13, 51748], "temperature": 0.0, "avg_logprob": -0.09970956802368164, "compression_ratio": 1.5761316872427984, "no_speech_prob": 0.037312112748622894}, {"id": 136, "seek": 56666, "start": 566.66, "end": 571.5, "text": " So the next generation of AI has to solve this inefficiency problem as well, otherwise", "tokens": [50364, 407, 264, 958, 5125, 295, 7318, 575, 281, 5039, 341, 7167, 49086, 1154, 382, 731, 11, 5911, 50606], "temperature": 0.0, "avg_logprob": -0.10737622138297204, "compression_ratio": 1.6964980544747081, "no_speech_prob": 0.05031560733914375}, {"id": 137, "seek": 56666, "start": 571.5, "end": 573.18, "text": " it will not be sustainable.", "tokens": [50606, 309, 486, 406, 312, 11235, 13, 50690], "temperature": 0.0, "avg_logprob": -0.10737622138297204, "compression_ratio": 1.6964980544747081, "no_speech_prob": 0.05031560733914375}, {"id": 138, "seek": 56666, "start": 573.18, "end": 579.02, "text": " So to summarize the major limitations of current AI models is number one, they are fixed and", "tokens": [50690, 407, 281, 20858, 264, 2563, 15705, 295, 2190, 7318, 5245, 307, 1230, 472, 11, 436, 366, 6806, 293, 50982], "temperature": 0.0, "avg_logprob": -0.10737622138297204, "compression_ratio": 1.6964980544747081, "no_speech_prob": 0.05031560733914375}, {"id": 139, "seek": 56666, "start": 579.02, "end": 584.78, "text": " unable to improve or learn further after being trained, and number two, they're also very", "tokens": [50982, 11299, 281, 3470, 420, 1466, 3052, 934, 885, 8895, 11, 293, 1230, 732, 11, 436, 434, 611, 588, 51270], "temperature": 0.0, "avg_logprob": -0.10737622138297204, "compression_ratio": 1.6964980544747081, "no_speech_prob": 0.05031560733914375}, {"id": 140, "seek": 56666, "start": 584.78, "end": 587.5799999999999, "text": " energy intensive and inefficient.", "tokens": [51270, 2281, 18957, 293, 43495, 13, 51410], "temperature": 0.0, "avg_logprob": -0.10737622138297204, "compression_ratio": 1.6964980544747081, "no_speech_prob": 0.05031560733914375}, {"id": 141, "seek": 56666, "start": 587.5799999999999, "end": 591.9, "text": " These are the two biggest problems of the current generation of AI.", "tokens": [51410, 1981, 366, 264, 732, 3880, 2740, 295, 264, 2190, 5125, 295, 7318, 13, 51626], "temperature": 0.0, "avg_logprob": -0.10737622138297204, "compression_ratio": 1.6964980544747081, "no_speech_prob": 0.05031560733914375}, {"id": 142, "seek": 56666, "start": 591.9, "end": 594.3, "text": " Now let's enter the next generation.", "tokens": [51626, 823, 718, 311, 3242, 264, 958, 5125, 13, 51746], "temperature": 0.0, "avg_logprob": -0.10737622138297204, "compression_ratio": 1.6964980544747081, "no_speech_prob": 0.05031560733914375}, {"id": 143, "seek": 59430, "start": 594.3, "end": 598.9, "text": " We aren't there yet, but there are a few possible architectures that are being discussed", "tokens": [50364, 492, 3212, 380, 456, 1939, 11, 457, 456, 366, 257, 1326, 1944, 6331, 1303, 300, 366, 885, 7152, 50594], "temperature": 0.0, "avg_logprob": -0.09387757014302374, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.5460823774337769}, {"id": 144, "seek": 59430, "start": 598.9, "end": 601.02, "text": " and developed as we speak.", "tokens": [50594, 293, 4743, 382, 321, 1710, 13, 50700], "temperature": 0.0, "avg_logprob": -0.09387757014302374, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.5460823774337769}, {"id": 145, "seek": 59430, "start": 601.02, "end": 604.66, "text": " The first architecture is called liquid neural networks.", "tokens": [50700, 440, 700, 9482, 307, 1219, 6553, 18161, 9590, 13, 50882], "temperature": 0.0, "avg_logprob": -0.09387757014302374, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.5460823774337769}, {"id": 146, "seek": 59430, "start": 604.66, "end": 610.4599999999999, "text": " Now liquid neural networks are designed to mimic the flexibility or the plasticity of", "tokens": [50882, 823, 6553, 18161, 9590, 366, 4761, 281, 31075, 264, 12635, 420, 264, 5900, 507, 295, 51172], "temperature": 0.0, "avg_logprob": -0.09387757014302374, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.5460823774337769}, {"id": 147, "seek": 59430, "start": 610.4599999999999, "end": 611.74, "text": " the human brain.", "tokens": [51172, 264, 1952, 3567, 13, 51236], "temperature": 0.0, "avg_logprob": -0.09387757014302374, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.5460823774337769}, {"id": 148, "seek": 59430, "start": 611.74, "end": 617.62, "text": " The human brain is very flexible and can reorganize or reconfigure itself over time,", "tokens": [51236, 440, 1952, 3567, 307, 588, 11358, 293, 393, 41203, 1125, 420, 9993, 20646, 540, 2564, 670, 565, 11, 51530], "temperature": 0.0, "avg_logprob": -0.09387757014302374, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.5460823774337769}, {"id": 149, "seek": 59430, "start": 617.62, "end": 623.42, "text": " and this ability allows the brain to adapt to new situations or learn new skills or compensate", "tokens": [51530, 293, 341, 3485, 4045, 264, 3567, 281, 6231, 281, 777, 6851, 420, 1466, 777, 3942, 420, 29458, 51820], "temperature": 0.0, "avg_logprob": -0.09387757014302374, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.5460823774337769}, {"id": 150, "seek": 62342, "start": 623.42, "end": 625.54, "text": " for injury and disease.", "tokens": [50364, 337, 10454, 293, 4752, 13, 50470], "temperature": 0.0, "avg_logprob": -0.09630639076232911, "compression_ratio": 1.76171875, "no_speech_prob": 0.21719878911972046}, {"id": 151, "seek": 62342, "start": 625.54, "end": 630.9, "text": " For example, when you learn something new, your brain changes structurally and functionally", "tokens": [50470, 1171, 1365, 11, 562, 291, 1466, 746, 777, 11, 428, 3567, 2962, 6594, 6512, 293, 2445, 379, 50738], "temperature": 0.0, "avg_logprob": -0.09630639076232911, "compression_ratio": 1.76171875, "no_speech_prob": 0.21719878911972046}, {"id": 152, "seek": 62342, "start": 630.9, "end": 633.2199999999999, "text": " to accommodate the new information.", "tokens": [50738, 281, 21410, 264, 777, 1589, 13, 50854], "temperature": 0.0, "avg_logprob": -0.09630639076232911, "compression_ratio": 1.76171875, "no_speech_prob": 0.21719878911972046}, {"id": 153, "seek": 62342, "start": 633.2199999999999, "end": 637.8199999999999, "text": " Learning a new language can lead to changes in the brain's structure and function, such", "tokens": [50854, 15205, 257, 777, 2856, 393, 1477, 281, 2962, 294, 264, 3567, 311, 3877, 293, 2445, 11, 1270, 51084], "temperature": 0.0, "avg_logprob": -0.09630639076232911, "compression_ratio": 1.76171875, "no_speech_prob": 0.21719878911972046}, {"id": 154, "seek": 62342, "start": 637.8199999999999, "end": 641.78, "text": " as increased density of gray matter in the left hemisphere.", "tokens": [51084, 382, 6505, 10305, 295, 10855, 1871, 294, 264, 1411, 38453, 13, 51282], "temperature": 0.0, "avg_logprob": -0.09630639076232911, "compression_ratio": 1.76171875, "no_speech_prob": 0.21719878911972046}, {"id": 155, "seek": 62342, "start": 641.78, "end": 646.02, "text": " The brain can also reconfigure itself to recover from injury.", "tokens": [51282, 440, 3567, 393, 611, 9993, 20646, 540, 2564, 281, 8114, 490, 10454, 13, 51494], "temperature": 0.0, "avg_logprob": -0.09630639076232911, "compression_ratio": 1.76171875, "no_speech_prob": 0.21719878911972046}, {"id": 156, "seek": 62342, "start": 646.02, "end": 651.8199999999999, "text": " For example, after a traumatic brain injury, physical therapy and cognitive exercises can", "tokens": [51494, 1171, 1365, 11, 934, 257, 26456, 3567, 10454, 11, 4001, 9492, 293, 15605, 11900, 393, 51784], "temperature": 0.0, "avg_logprob": -0.09630639076232911, "compression_ratio": 1.76171875, "no_speech_prob": 0.21719878911972046}, {"id": 157, "seek": 65182, "start": 651.82, "end": 656.1400000000001, "text": " help rewire the brain to regain lost functions.", "tokens": [50364, 854, 319, 42689, 264, 3567, 281, 35336, 2731, 6828, 13, 50580], "temperature": 0.0, "avg_logprob": -0.10871437774307427, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.2118971049785614}, {"id": 158, "seek": 65182, "start": 656.1400000000001, "end": 660.86, "text": " And for people who've lost a sense, like sight or hearing, the brain will reorganize", "tokens": [50580, 400, 337, 561, 567, 600, 2731, 257, 2020, 11, 411, 7860, 420, 4763, 11, 264, 3567, 486, 41203, 1125, 50816], "temperature": 0.0, "avg_logprob": -0.10871437774307427, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.2118971049785614}, {"id": 159, "seek": 65182, "start": 660.86, "end": 666.1400000000001, "text": " itself to compensate for the loss and make other senses become more acute.", "tokens": [50816, 2564, 281, 29458, 337, 264, 4470, 293, 652, 661, 17057, 1813, 544, 24390, 13, 51080], "temperature": 0.0, "avg_logprob": -0.10871437774307427, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.2118971049785614}, {"id": 160, "seek": 65182, "start": 666.1400000000001, "end": 672.1400000000001, "text": " So this flexibility, this plasticity is exactly what liquid neural networks are designed to", "tokens": [51080, 407, 341, 12635, 11, 341, 5900, 507, 307, 2293, 437, 6553, 18161, 9590, 366, 4761, 281, 51380], "temperature": 0.0, "avg_logprob": -0.10871437774307427, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.2118971049785614}, {"id": 161, "seek": 65182, "start": 672.1400000000001, "end": 673.46, "text": " have.", "tokens": [51380, 362, 13, 51446], "temperature": 0.0, "avg_logprob": -0.10871437774307427, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.2118971049785614}, {"id": 162, "seek": 65182, "start": 673.46, "end": 677.3000000000001, "text": " Liquid neural networks can adapt in real time to new data.", "tokens": [51446, 38943, 18161, 9590, 393, 6231, 294, 957, 565, 281, 777, 1412, 13, 51638], "temperature": 0.0, "avg_logprob": -0.10871437774307427, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.2118971049785614}, {"id": 163, "seek": 67730, "start": 677.3, "end": 683.06, "text": " This means that the configuration of the neural network can change as it receives new inputs,", "tokens": [50364, 639, 1355, 300, 264, 11694, 295, 264, 18161, 3209, 393, 1319, 382, 309, 20717, 777, 15743, 11, 50652], "temperature": 0.0, "avg_logprob": -0.08227798313770479, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.39935359358787537}, {"id": 164, "seek": 67730, "start": 683.06, "end": 684.9799999999999, "text": " and that's why it's called liquid.", "tokens": [50652, 293, 300, 311, 983, 309, 311, 1219, 6553, 13, 50748], "temperature": 0.0, "avg_logprob": -0.08227798313770479, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.39935359358787537}, {"id": 165, "seek": 67730, "start": 684.9799999999999, "end": 690.2199999999999, "text": " These connections in the network and these dials and knobs are fluid, so they can change", "tokens": [50748, 1981, 9271, 294, 264, 3209, 293, 613, 5502, 82, 293, 46999, 366, 9113, 11, 370, 436, 393, 1319, 51010], "temperature": 0.0, "avg_logprob": -0.08227798313770479, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.39935359358787537}, {"id": 166, "seek": 67730, "start": 690.2199999999999, "end": 692.78, "text": " dynamically over time.", "tokens": [51010, 43492, 670, 565, 13, 51138], "temperature": 0.0, "avg_logprob": -0.08227798313770479, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.39935359358787537}, {"id": 167, "seek": 67730, "start": 692.78, "end": 698.26, "text": " Liquid neural networks also retain what they have learned while incorporating new information.", "tokens": [51138, 38943, 18161, 9590, 611, 18340, 437, 436, 362, 3264, 1339, 33613, 777, 1589, 13, 51412], "temperature": 0.0, "avg_logprob": -0.08227798313770479, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.39935359358787537}, {"id": 168, "seek": 67730, "start": 698.26, "end": 703.66, "text": " This is similar to how our brains can remember old information while learning new things.", "tokens": [51412, 639, 307, 2531, 281, 577, 527, 15442, 393, 1604, 1331, 1589, 1339, 2539, 777, 721, 13, 51682], "temperature": 0.0, "avg_logprob": -0.08227798313770479, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.39935359358787537}, {"id": 169, "seek": 67730, "start": 703.66, "end": 706.8599999999999, "text": " So here's how liquid neural networks work.", "tokens": [51682, 407, 510, 311, 577, 6553, 18161, 9590, 589, 13, 51842], "temperature": 0.0, "avg_logprob": -0.08227798313770479, "compression_ratio": 1.806949806949807, "no_speech_prob": 0.39935359358787537}, {"id": 170, "seek": 70686, "start": 706.86, "end": 711.42, "text": " They have three main components, much like a traditional neural network.", "tokens": [50364, 814, 362, 1045, 2135, 6677, 11, 709, 411, 257, 5164, 18161, 3209, 13, 50592], "temperature": 0.0, "avg_logprob": -0.10206042726834615, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.14792320132255554}, {"id": 171, "seek": 70686, "start": 711.42, "end": 714.98, "text": " It has an input layer, which receives the input data.", "tokens": [50592, 467, 575, 364, 4846, 4583, 11, 597, 20717, 264, 4846, 1412, 13, 50770], "temperature": 0.0, "avg_logprob": -0.10206042726834615, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.14792320132255554}, {"id": 172, "seek": 70686, "start": 714.98, "end": 719.94, "text": " But then in the middle, we have this liquid layer, otherwise known as a reservoir.", "tokens": [50770, 583, 550, 294, 264, 2808, 11, 321, 362, 341, 6553, 4583, 11, 5911, 2570, 382, 257, 26316, 13, 51018], "temperature": 0.0, "avg_logprob": -0.10206042726834615, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.14792320132255554}, {"id": 173, "seek": 70686, "start": 719.94, "end": 723.1, "text": " This is the core component of a liquid neural network.", "tokens": [51018, 639, 307, 264, 4965, 6542, 295, 257, 6553, 18161, 3209, 13, 51176], "temperature": 0.0, "avg_logprob": -0.10206042726834615, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.14792320132255554}, {"id": 174, "seek": 70686, "start": 723.1, "end": 726.62, "text": " And it's basically a large recurrent neural network.", "tokens": [51176, 400, 309, 311, 1936, 257, 2416, 18680, 1753, 18161, 3209, 13, 51352], "temperature": 0.0, "avg_logprob": -0.10206042726834615, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.14792320132255554}, {"id": 175, "seek": 70686, "start": 726.62, "end": 732.46, "text": " Think of this as a big bowl of water in which each splash creates a ripple.", "tokens": [51352, 6557, 295, 341, 382, 257, 955, 6571, 295, 1281, 294, 597, 1184, 25757, 7829, 257, 40688, 13, 51644], "temperature": 0.0, "avg_logprob": -0.10206042726834615, "compression_ratio": 1.7236842105263157, "no_speech_prob": 0.14792320132255554}, {"id": 176, "seek": 73246, "start": 732.46, "end": 737.5400000000001, "text": " These ripples are basically the neurons in this network reacting to inputs.", "tokens": [50364, 1981, 367, 37674, 366, 1936, 264, 22027, 294, 341, 3209, 25817, 281, 15743, 13, 50618], "temperature": 0.0, "avg_logprob": -0.09742894071213742, "compression_ratio": 1.812, "no_speech_prob": 0.5539331436157227}, {"id": 177, "seek": 73246, "start": 737.5400000000001, "end": 743.7, "text": " The reservoir acts as a dynamic system that transforms the input data into a high dimensional", "tokens": [50618, 440, 26316, 10672, 382, 257, 8546, 1185, 300, 35592, 264, 4846, 1412, 666, 257, 1090, 18795, 50926], "temperature": 0.0, "avg_logprob": -0.09742894071213742, "compression_ratio": 1.812, "no_speech_prob": 0.5539331436157227}, {"id": 178, "seek": 73246, "start": 743.7, "end": 746.7, "text": " representation called reservoir states.", "tokens": [50926, 10290, 1219, 26316, 4368, 13, 51076], "temperature": 0.0, "avg_logprob": -0.09742894071213742, "compression_ratio": 1.812, "no_speech_prob": 0.5539331436157227}, {"id": 179, "seek": 73246, "start": 746.7, "end": 753.0600000000001, "text": " And this reservoir's rich dynamics and transformations capture the complex temporal patterns in the", "tokens": [51076, 400, 341, 26316, 311, 4593, 15679, 293, 34852, 7983, 264, 3997, 30881, 8294, 294, 264, 51394], "temperature": 0.0, "avg_logprob": -0.09742894071213742, "compression_ratio": 1.812, "no_speech_prob": 0.5539331436157227}, {"id": 180, "seek": 73246, "start": 753.0600000000001, "end": 754.46, "text": " input data.", "tokens": [51394, 4846, 1412, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09742894071213742, "compression_ratio": 1.812, "no_speech_prob": 0.5539331436157227}, {"id": 181, "seek": 73246, "start": 754.46, "end": 757.14, "text": " And then finally, we have the output layer.", "tokens": [51464, 400, 550, 2721, 11, 321, 362, 264, 5598, 4583, 13, 51598], "temperature": 0.0, "avg_logprob": -0.09742894071213742, "compression_ratio": 1.812, "no_speech_prob": 0.5539331436157227}, {"id": 182, "seek": 73246, "start": 757.14, "end": 762.38, "text": " This layer receives the reservoir states and maps them to the desired output using what", "tokens": [51598, 639, 4583, 20717, 264, 26316, 4368, 293, 11317, 552, 281, 264, 14721, 5598, 1228, 437, 51860], "temperature": 0.0, "avg_logprob": -0.09742894071213742, "compression_ratio": 1.812, "no_speech_prob": 0.5539331436157227}, {"id": 183, "seek": 76238, "start": 762.38, "end": 764.62, "text": " is called a readout function.", "tokens": [50364, 307, 1219, 257, 1401, 346, 2445, 13, 50476], "temperature": 0.0, "avg_logprob": -0.0711338852727136, "compression_ratio": 1.6757990867579908, "no_speech_prob": 0.006487365812063217}, {"id": 184, "seek": 76238, "start": 764.62, "end": 769.58, "text": " In layman terms, this is a layer that looks at the ripples in the reservoir and tries", "tokens": [50476, 682, 2360, 1601, 2115, 11, 341, 307, 257, 4583, 300, 1542, 412, 264, 367, 37674, 294, 264, 26316, 293, 9898, 50724], "temperature": 0.0, "avg_logprob": -0.0711338852727136, "compression_ratio": 1.6757990867579908, "no_speech_prob": 0.006487365812063217}, {"id": 185, "seek": 76238, "start": 769.58, "end": 772.06, "text": " to understand what it all means.", "tokens": [50724, 281, 1223, 437, 309, 439, 1355, 13, 50848], "temperature": 0.0, "avg_logprob": -0.0711338852727136, "compression_ratio": 1.6757990867579908, "no_speech_prob": 0.006487365812063217}, {"id": 186, "seek": 76238, "start": 772.06, "end": 777.78, "text": " It takes the dynamic patterns from the reservoir and makes predictions or decisions from it.", "tokens": [50848, 467, 2516, 264, 8546, 8294, 490, 264, 26316, 293, 1669, 21264, 420, 5327, 490, 309, 13, 51134], "temperature": 0.0, "avg_logprob": -0.0711338852727136, "compression_ratio": 1.6757990867579908, "no_speech_prob": 0.006487365812063217}, {"id": 187, "seek": 76238, "start": 777.78, "end": 784.62, "text": " The key aspect of liquid neural networks is this reservoir layer, which remains untrained", "tokens": [51134, 440, 2141, 4171, 295, 6553, 18161, 9590, 307, 341, 26316, 4583, 11, 597, 7023, 1701, 31774, 51476], "temperature": 0.0, "avg_logprob": -0.0711338852727136, "compression_ratio": 1.6757990867579908, "no_speech_prob": 0.006487365812063217}, {"id": 188, "seek": 76238, "start": 784.62, "end": 787.34, "text": " during the entire learning process.", "tokens": [51476, 1830, 264, 2302, 2539, 1399, 13, 51612], "temperature": 0.0, "avg_logprob": -0.0711338852727136, "compression_ratio": 1.6757990867579908, "no_speech_prob": 0.006487365812063217}, {"id": 189, "seek": 78734, "start": 787.34, "end": 792.9, "text": " Finally the output layer is trained to map the reservoir states to the target outputs.", "tokens": [50364, 6288, 264, 5598, 4583, 307, 8895, 281, 4471, 264, 26316, 4368, 281, 264, 3779, 23930, 13, 50642], "temperature": 0.0, "avg_logprob": -0.10787090265525962, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.44524383544921875}, {"id": 190, "seek": 78734, "start": 792.9, "end": 795.5400000000001, "text": " In other words, to understand what these ripples mean.", "tokens": [50642, 682, 661, 2283, 11, 281, 1223, 437, 613, 367, 37674, 914, 13, 50774], "temperature": 0.0, "avg_logprob": -0.10787090265525962, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.44524383544921875}, {"id": 191, "seek": 78734, "start": 795.5400000000001, "end": 800.6600000000001, "text": " And because this reservoir remains fluid and flexible throughout time, it's not fixed", "tokens": [50774, 400, 570, 341, 26316, 7023, 9113, 293, 11358, 3710, 565, 11, 309, 311, 406, 6806, 51030], "temperature": 0.0, "avg_logprob": -0.10787090265525962, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.44524383544921875}, {"id": 192, "seek": 78734, "start": 800.6600000000001, "end": 805.74, "text": " in value, that allows this liquid neural network to basically adapt to new data and learn", "tokens": [51030, 294, 2158, 11, 300, 4045, 341, 6553, 18161, 3209, 281, 1936, 6231, 281, 777, 1412, 293, 1466, 51284], "temperature": 0.0, "avg_logprob": -0.10787090265525962, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.44524383544921875}, {"id": 193, "seek": 78734, "start": 805.74, "end": 807.22, "text": " new things.", "tokens": [51284, 777, 721, 13, 51358], "temperature": 0.0, "avg_logprob": -0.10787090265525962, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.44524383544921875}, {"id": 194, "seek": 78734, "start": 807.22, "end": 810.26, "text": " Here's how you would train a liquid neural network.", "tokens": [51358, 1692, 311, 577, 291, 576, 3847, 257, 6553, 18161, 3209, 13, 51510], "temperature": 0.0, "avg_logprob": -0.10787090265525962, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.44524383544921875}, {"id": 195, "seek": 78734, "start": 810.26, "end": 815.24, "text": " The connections between neurons in the reservoirs are set up randomly at the start.", "tokens": [51510, 440, 9271, 1296, 22027, 294, 264, 26316, 82, 366, 992, 493, 16979, 412, 264, 722, 13, 51759], "temperature": 0.0, "avg_logprob": -0.10787090265525962, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.44524383544921875}, {"id": 196, "seek": 81524, "start": 815.24, "end": 820.0, "text": " These connections typically stay the same and don't change during training.", "tokens": [50364, 1981, 9271, 5850, 1754, 264, 912, 293, 500, 380, 1319, 1830, 3097, 13, 50602], "temperature": 0.0, "avg_logprob": -0.0905180743762425, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.015422341413795948}, {"id": 197, "seek": 81524, "start": 820.0, "end": 822.4, "text": " Next you would feed the input layer some data.", "tokens": [50602, 3087, 291, 576, 3154, 264, 4846, 4583, 512, 1412, 13, 50722], "temperature": 0.0, "avg_logprob": -0.0905180743762425, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.015422341413795948}, {"id": 198, "seek": 81524, "start": 822.4, "end": 827.38, "text": " And when this data is broken down into tokens and it reaches the reservoir layer, it causes", "tokens": [50722, 400, 562, 341, 1412, 307, 5463, 760, 666, 22667, 293, 309, 14235, 264, 26316, 4583, 11, 309, 7700, 50971], "temperature": 0.0, "avg_logprob": -0.0905180743762425, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.015422341413795948}, {"id": 199, "seek": 81524, "start": 827.38, "end": 832.64, "text": " the neurons in the reservoir to react and create complex patterns, much like ripples", "tokens": [50971, 264, 22027, 294, 264, 26316, 281, 4515, 293, 1884, 3997, 8294, 11, 709, 411, 367, 37674, 51234], "temperature": 0.0, "avg_logprob": -0.0905180743762425, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.015422341413795948}, {"id": 200, "seek": 81524, "start": 832.64, "end": 833.64, "text": " in water.", "tokens": [51234, 294, 1281, 13, 51284], "temperature": 0.0, "avg_logprob": -0.0905180743762425, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.015422341413795948}, {"id": 201, "seek": 81524, "start": 833.64, "end": 838.6800000000001, "text": " So as this input data creates ripples, you basically observe and analyze the patterns", "tokens": [51284, 407, 382, 341, 4846, 1412, 7829, 367, 37674, 11, 291, 1936, 11441, 293, 12477, 264, 8294, 51536], "temperature": 0.0, "avg_logprob": -0.0905180743762425, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.015422341413795948}, {"id": 202, "seek": 81524, "start": 838.6800000000001, "end": 841.04, "text": " created in the reservoir over time.", "tokens": [51536, 2942, 294, 264, 26316, 670, 565, 13, 51654], "temperature": 0.0, "avg_logprob": -0.0905180743762425, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.015422341413795948}, {"id": 203, "seek": 81524, "start": 841.04, "end": 843.36, "text": " And that's exactly what the readout layer does.", "tokens": [51654, 400, 300, 311, 2293, 437, 264, 1401, 346, 4583, 775, 13, 51770], "temperature": 0.0, "avg_logprob": -0.0905180743762425, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.015422341413795948}, {"id": 204, "seek": 84336, "start": 843.36, "end": 845.72, "text": " It learns to recognize these patterns.", "tokens": [50364, 467, 27152, 281, 5521, 613, 8294, 13, 50482], "temperature": 0.0, "avg_logprob": -0.11578836934319858, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.10370773822069168}, {"id": 205, "seek": 84336, "start": 845.72, "end": 850.44, "text": " It's like learning, aha, this is what caused this type of ripple and that is what caused", "tokens": [50482, 467, 311, 411, 2539, 11, 47340, 11, 341, 307, 437, 7008, 341, 2010, 295, 40688, 293, 300, 307, 437, 7008, 50718], "temperature": 0.0, "avg_logprob": -0.11578836934319858, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.10370773822069168}, {"id": 206, "seek": 84336, "start": 850.44, "end": 851.72, "text": " this other type of ripple.", "tokens": [50718, 341, 661, 2010, 295, 40688, 13, 50782], "temperature": 0.0, "avg_logprob": -0.11578836934319858, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.10370773822069168}, {"id": 207, "seek": 84336, "start": 851.72, "end": 856.1800000000001, "text": " And eventually after lots and lots of rounds of training, the readout layer can make accurate", "tokens": [50782, 400, 4728, 934, 3195, 293, 3195, 295, 13757, 295, 3097, 11, 264, 1401, 346, 4583, 393, 652, 8559, 51005], "temperature": 0.0, "avg_logprob": -0.11578836934319858, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.10370773822069168}, {"id": 208, "seek": 84336, "start": 856.1800000000001, "end": 859.2, "text": " predictions based on observed patterns.", "tokens": [51005, 21264, 2361, 322, 13095, 8294, 13, 51156], "temperature": 0.0, "avg_logprob": -0.11578836934319858, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.10370773822069168}, {"id": 209, "seek": 84336, "start": 859.2, "end": 864.44, "text": " Again note that only the readout layer is trained, which is simpler and faster because", "tokens": [51156, 3764, 3637, 300, 787, 264, 1401, 346, 4583, 307, 8895, 11, 597, 307, 18587, 293, 4663, 570, 51418], "temperature": 0.0, "avg_logprob": -0.11578836934319858, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.10370773822069168}, {"id": 210, "seek": 84336, "start": 864.44, "end": 867.2, "text": " you're not adjusting anything in the reservoir layer.", "tokens": [51418, 291, 434, 406, 23559, 1340, 294, 264, 26316, 4583, 13, 51556], "temperature": 0.0, "avg_logprob": -0.11578836934319858, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.10370773822069168}, {"id": 211, "seek": 84336, "start": 867.2, "end": 872.96, "text": " This is much quicker and needs less compute compared to traditional neural networks.", "tokens": [51556, 639, 307, 709, 16255, 293, 2203, 1570, 14722, 5347, 281, 5164, 18161, 9590, 13, 51844], "temperature": 0.0, "avg_logprob": -0.11578836934319858, "compression_ratio": 1.7972027972027973, "no_speech_prob": 0.10370773822069168}, {"id": 212, "seek": 87296, "start": 872.96, "end": 877.24, "text": " That's because in neural networks that we know today, all the weights including those", "tokens": [50364, 663, 311, 570, 294, 18161, 9590, 300, 321, 458, 965, 11, 439, 264, 17443, 3009, 729, 50578], "temperature": 0.0, "avg_logprob": -0.14020803659269127, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.04883912205696106}, {"id": 213, "seek": 87296, "start": 877.24, "end": 879.52, "text": " in the hidden layers are trainable.", "tokens": [50578, 294, 264, 7633, 7914, 366, 3847, 712, 13, 50692], "temperature": 0.0, "avg_logprob": -0.14020803659269127, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.04883912205696106}, {"id": 214, "seek": 87296, "start": 879.52, "end": 884.6800000000001, "text": " This means more parameters to optimize leading to longer training times and higher computational", "tokens": [50692, 639, 1355, 544, 9834, 281, 19719, 5775, 281, 2854, 3097, 1413, 293, 2946, 28270, 50950], "temperature": 0.0, "avg_logprob": -0.14020803659269127, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.04883912205696106}, {"id": 215, "seek": 87296, "start": 884.6800000000001, "end": 885.88, "text": " requirements.", "tokens": [50950, 7728, 13, 51010], "temperature": 0.0, "avg_logprob": -0.14020803659269127, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.04883912205696106}, {"id": 216, "seek": 87296, "start": 885.88, "end": 892.2800000000001, "text": " But in liquid neural networks, you don't adjust the weights of the reservoir during training.", "tokens": [51010, 583, 294, 6553, 18161, 9590, 11, 291, 500, 380, 4369, 264, 17443, 295, 264, 26316, 1830, 3097, 13, 51330], "temperature": 0.0, "avg_logprob": -0.14020803659269127, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.04883912205696106}, {"id": 217, "seek": 87296, "start": 892.2800000000001, "end": 894.62, "text": " Only the readout layer is trained.", "tokens": [51330, 5686, 264, 1401, 346, 4583, 307, 8895, 13, 51447], "temperature": 0.0, "avg_logprob": -0.14020803659269127, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.04883912205696106}, {"id": 218, "seek": 87296, "start": 894.62, "end": 900.48, "text": " And this significantly reduces the computational burden during training since fewer parameters", "tokens": [51447, 400, 341, 10591, 18081, 264, 28270, 12578, 1830, 3097, 1670, 13366, 9834, 51740], "temperature": 0.0, "avg_logprob": -0.14020803659269127, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.04883912205696106}, {"id": 219, "seek": 87296, "start": 900.48, "end": 902.24, "text": " need to be optimized.", "tokens": [51740, 643, 281, 312, 26941, 13, 51828], "temperature": 0.0, "avg_logprob": -0.14020803659269127, "compression_ratio": 1.7769516728624535, "no_speech_prob": 0.04883912205696106}, {"id": 220, "seek": 90224, "start": 902.24, "end": 904.6800000000001, "text": " Plus it's a lot faster to train.", "tokens": [50364, 7721, 309, 311, 257, 688, 4663, 281, 3847, 13, 50486], "temperature": 0.0, "avg_logprob": -0.17067938735804608, "compression_ratio": 1.6215139442231075, "no_speech_prob": 0.12585440278053284}, {"id": 221, "seek": 90224, "start": 904.6800000000001, "end": 907.28, "text": " Thanks to our sponsor Bright Data.", "tokens": [50486, 2561, 281, 527, 16198, 24271, 11888, 13, 50616], "temperature": 0.0, "avg_logprob": -0.17067938735804608, "compression_ratio": 1.6215139442231075, "no_speech_prob": 0.12585440278053284}, {"id": 222, "seek": 90224, "start": 907.28, "end": 912.5600000000001, "text": " Bright Data is an all-in-one platform designed to help businesses collect high quality web", "tokens": [50616, 24271, 11888, 307, 364, 439, 12, 259, 12, 546, 3663, 4761, 281, 854, 6011, 2500, 1090, 3125, 3670, 50880], "temperature": 0.0, "avg_logprob": -0.17067938735804608, "compression_ratio": 1.6215139442231075, "no_speech_prob": 0.12585440278053284}, {"id": 223, "seek": 90224, "start": 912.5600000000001, "end": 914.52, "text": " data at scale.", "tokens": [50880, 1412, 412, 4373, 13, 50978], "temperature": 0.0, "avg_logprob": -0.17067938735804608, "compression_ratio": 1.6215139442231075, "no_speech_prob": 0.12585440278053284}, {"id": 224, "seek": 90224, "start": 914.52, "end": 919.36, "text": " This is especially useful for AI companies which require huge amounts of diverse and", "tokens": [50978, 639, 307, 2318, 4420, 337, 7318, 3431, 597, 3651, 2603, 11663, 295, 9521, 293, 51220], "temperature": 0.0, "avg_logprob": -0.17067938735804608, "compression_ratio": 1.6215139442231075, "no_speech_prob": 0.12585440278053284}, {"id": 225, "seek": 90224, "start": 919.36, "end": 925.4, "text": " high quality training data to build robust and unbiased AI models.", "tokens": [51220, 1090, 3125, 3097, 1412, 281, 1322, 13956, 293, 517, 5614, 1937, 7318, 5245, 13, 51522], "temperature": 0.0, "avg_logprob": -0.17067938735804608, "compression_ratio": 1.6215139442231075, "no_speech_prob": 0.12585440278053284}, {"id": 226, "seek": 90224, "start": 925.4, "end": 930.4, "text": " Collecting this training data manually can be time consuming and prone to errors.", "tokens": [51522, 31896, 278, 341, 3097, 1412, 16945, 393, 312, 565, 19867, 293, 25806, 281, 13603, 13, 51772], "temperature": 0.0, "avg_logprob": -0.17067938735804608, "compression_ratio": 1.6215139442231075, "no_speech_prob": 0.12585440278053284}, {"id": 227, "seek": 93040, "start": 930.4, "end": 932.52, "text": " And that's where Bright Data comes in.", "tokens": [50364, 400, 300, 311, 689, 24271, 11888, 1487, 294, 13, 50470], "temperature": 0.0, "avg_logprob": -0.13249112247081285, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.472427636384964}, {"id": 228, "seek": 93040, "start": 932.52, "end": 937.64, "text": " With Bright Data, you can access high volume, high quality web data effortlessly.", "tokens": [50470, 2022, 24271, 11888, 11, 291, 393, 2105, 1090, 5523, 11, 1090, 3125, 3670, 1412, 4630, 12048, 13, 50726], "temperature": 0.0, "avg_logprob": -0.13249112247081285, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.472427636384964}, {"id": 229, "seek": 93040, "start": 937.64, "end": 944.04, "text": " From parsed validated data sets to custom scraping solutions, they've got you covered.", "tokens": [50726, 3358, 21156, 292, 40693, 1412, 6352, 281, 2375, 43738, 6547, 11, 436, 600, 658, 291, 5343, 13, 51046], "temperature": 0.0, "avg_logprob": -0.13249112247081285, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.472427636384964}, {"id": 230, "seek": 93040, "start": 944.04, "end": 948.72, "text": " Get parsed and cleaned data sets ready to use on demand.", "tokens": [51046, 3240, 21156, 292, 293, 16146, 1412, 6352, 1919, 281, 764, 322, 4733, 13, 51280], "temperature": 0.0, "avg_logprob": -0.13249112247081285, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.472427636384964}, {"id": 231, "seek": 93040, "start": 948.72, "end": 954.1999999999999, "text": " Customize any data set to fit your specific needs and benefit from reliable delivery and", "tokens": [51280, 16649, 1125, 604, 1412, 992, 281, 3318, 428, 2685, 2203, 293, 5121, 490, 12924, 8982, 293, 51554], "temperature": 0.0, "avg_logprob": -0.13249112247081285, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.472427636384964}, {"id": 232, "seek": 93040, "start": 954.1999999999999, "end": 956.0799999999999, "text": " full compliance.", "tokens": [51554, 1577, 15882, 13, 51648], "temperature": 0.0, "avg_logprob": -0.13249112247081285, "compression_ratio": 1.608695652173913, "no_speech_prob": 0.472427636384964}, {"id": 233, "seek": 95608, "start": 956.08, "end": 963.1600000000001, "text": " In fact every 15 minutes their customers scrape enough data to train chat GPT from scratch.", "tokens": [50364, 682, 1186, 633, 2119, 2077, 641, 4581, 32827, 1547, 1412, 281, 3847, 5081, 26039, 51, 490, 8459, 13, 50718], "temperature": 0.0, "avg_logprob": -0.1241430950164795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.8052206039428711}, {"id": 234, "seek": 95608, "start": 963.1600000000001, "end": 965.36, "text": " That's a lot of data, to say the least.", "tokens": [50718, 663, 311, 257, 688, 295, 1412, 11, 281, 584, 264, 1935, 13, 50828], "temperature": 0.0, "avg_logprob": -0.1241430950164795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.8052206039428711}, {"id": 235, "seek": 95608, "start": 965.36, "end": 971.5600000000001, "text": " They have many tools like the web scraper API, the proxy manager, and unblocking technologies", "tokens": [50828, 814, 362, 867, 3873, 411, 264, 3670, 13943, 610, 9362, 11, 264, 29690, 6598, 11, 293, 517, 28830, 278, 7943, 51138], "temperature": 0.0, "avg_logprob": -0.1241430950164795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.8052206039428711}, {"id": 236, "seek": 95608, "start": 971.5600000000001, "end": 977.5200000000001, "text": " to help automate your data scraping at scale, allowing you to build reliable data sets to", "tokens": [51138, 281, 854, 31605, 428, 1412, 43738, 412, 4373, 11, 8293, 291, 281, 1322, 12924, 1412, 6352, 281, 51436], "temperature": 0.0, "avg_logprob": -0.1241430950164795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.8052206039428711}, {"id": 237, "seek": 95608, "start": 977.5200000000001, "end": 980.72, "text": " train any AI or LLM.", "tokens": [51436, 3847, 604, 7318, 420, 441, 43, 44, 13, 51596], "temperature": 0.0, "avg_logprob": -0.1241430950164795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.8052206039428711}, {"id": 238, "seek": 95608, "start": 980.72, "end": 983.84, "text": " Visit the link in the description below to learn more.", "tokens": [51596, 24548, 264, 2113, 294, 264, 3855, 2507, 281, 1466, 544, 13, 51752], "temperature": 0.0, "avg_logprob": -0.1241430950164795, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.8052206039428711}, {"id": 239, "seek": 98384, "start": 983.84, "end": 988.24, "text": " It's a lot faster for these liquid neural networks to converge at an optimum.", "tokens": [50364, 467, 311, 257, 688, 4663, 337, 613, 6553, 18161, 9590, 281, 41881, 412, 364, 39326, 13, 50584], "temperature": 0.0, "avg_logprob": -0.09738640785217285, "compression_ratio": 1.7753623188405796, "no_speech_prob": 0.8470423817634583}, {"id": 240, "seek": 98384, "start": 988.24, "end": 993.6600000000001, "text": " And because of this reservoir where the weights and configurations can change dynamically depending", "tokens": [50584, 400, 570, 295, 341, 26316, 689, 264, 17443, 293, 31493, 393, 1319, 43492, 5413, 50855], "temperature": 0.0, "avg_logprob": -0.09738640785217285, "compression_ratio": 1.7753623188405796, "no_speech_prob": 0.8470423817634583}, {"id": 241, "seek": 98384, "start": 993.6600000000001, "end": 998.24, "text": " on the data that you feed it, liquid neural networks can potentially be much smaller than", "tokens": [50855, 322, 264, 1412, 300, 291, 3154, 309, 11, 6553, 18161, 9590, 393, 7263, 312, 709, 4356, 813, 51084], "temperature": 0.0, "avg_logprob": -0.09738640785217285, "compression_ratio": 1.7753623188405796, "no_speech_prob": 0.8470423817634583}, {"id": 242, "seek": 98384, "start": 998.24, "end": 1002.32, "text": " traditional neural networks which have fixed weights and connections.", "tokens": [51084, 5164, 18161, 9590, 597, 362, 6806, 17443, 293, 9271, 13, 51288], "temperature": 0.0, "avg_logprob": -0.09738640785217285, "compression_ratio": 1.7753623188405796, "no_speech_prob": 0.8470423817634583}, {"id": 243, "seek": 98384, "start": 1002.32, "end": 1005.5600000000001, "text": " And this offers a lot more efficient learning and inference.", "tokens": [51288, 400, 341, 7736, 257, 688, 544, 7148, 2539, 293, 38253, 13, 51450], "temperature": 0.0, "avg_logprob": -0.09738640785217285, "compression_ratio": 1.7753623188405796, "no_speech_prob": 0.8470423817634583}, {"id": 244, "seek": 98384, "start": 1005.5600000000001, "end": 1011.2800000000001, "text": " So for example, researchers at MIT were able to pilot a drone using a liquid neural network", "tokens": [51450, 407, 337, 1365, 11, 10309, 412, 13100, 645, 1075, 281, 9691, 257, 13852, 1228, 257, 6553, 18161, 3209, 51736], "temperature": 0.0, "avg_logprob": -0.09738640785217285, "compression_ratio": 1.7753623188405796, "no_speech_prob": 0.8470423817634583}, {"id": 245, "seek": 101128, "start": 1011.36, "end": 1017.1999999999999, "text": " with only 20,000 parameters, which is very tiny compared to state-of-the-art AI models", "tokens": [50368, 365, 787, 945, 11, 1360, 9834, 11, 597, 307, 588, 5870, 5347, 281, 1785, 12, 2670, 12, 3322, 12, 446, 7318, 5245, 50660], "temperature": 0.0, "avg_logprob": -0.17773112621936168, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.05183286964893341}, {"id": 246, "seek": 101128, "start": 1017.1999999999999, "end": 1021.8, "text": " such as GPT4, which often have over a trillion parameters.", "tokens": [50660, 1270, 382, 26039, 51, 19, 11, 597, 2049, 362, 670, 257, 18723, 9834, 13, 50890], "temperature": 0.0, "avg_logprob": -0.17773112621936168, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.05183286964893341}, {"id": 247, "seek": 101128, "start": 1021.8, "end": 1022.8, "text": " Just think about that.", "tokens": [50890, 1449, 519, 466, 300, 13, 50940], "temperature": 0.0, "avg_logprob": -0.17773112621936168, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.05183286964893341}, {"id": 248, "seek": 101128, "start": 1022.8, "end": 1026.8799999999999, "text": " 20,000 parameters versus over a trillion parameters.", "tokens": [50940, 945, 11, 1360, 9834, 5717, 670, 257, 18723, 9834, 13, 51144], "temperature": 0.0, "avg_logprob": -0.17773112621936168, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.05183286964893341}, {"id": 249, "seek": 101128, "start": 1026.8799999999999, "end": 1032.6, "text": " So these smaller sizes generally translate to faster inference and lower computational", "tokens": [51144, 407, 613, 4356, 11602, 5101, 13799, 281, 4663, 38253, 293, 3126, 28270, 51430], "temperature": 0.0, "avg_logprob": -0.17773112621936168, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.05183286964893341}, {"id": 250, "seek": 101128, "start": 1032.6, "end": 1034.2, "text": " requirements.", "tokens": [51430, 7728, 13, 51510], "temperature": 0.0, "avg_logprob": -0.17773112621936168, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.05183286964893341}, {"id": 251, "seek": 101128, "start": 1034.2, "end": 1037.56, "text": " Liquid neural networks are also way less memory intensive.", "tokens": [51510, 38943, 18161, 9590, 366, 611, 636, 1570, 4675, 18957, 13, 51678], "temperature": 0.0, "avg_logprob": -0.17773112621936168, "compression_ratio": 1.6144067796610169, "no_speech_prob": 0.05183286964893341}, {"id": 252, "seek": 103756, "start": 1037.56, "end": 1043.24, "text": " Again, since you don't train the reservoir's weights, memory usage is much lower during", "tokens": [50364, 3764, 11, 1670, 291, 500, 380, 3847, 264, 26316, 311, 17443, 11, 4675, 14924, 307, 709, 3126, 1830, 50648], "temperature": 0.0, "avg_logprob": -0.10814197464744643, "compression_ratio": 1.7236363636363636, "no_speech_prob": 0.010011906735599041}, {"id": 253, "seek": 103756, "start": 1043.24, "end": 1047.8799999999999, "text": " training compared to traditional neural networks where the gradients and the parameters for", "tokens": [50648, 3097, 5347, 281, 5164, 18161, 9590, 689, 264, 2771, 2448, 293, 264, 9834, 337, 50880], "temperature": 0.0, "avg_logprob": -0.10814197464744643, "compression_ratio": 1.7236363636363636, "no_speech_prob": 0.010011906735599041}, {"id": 254, "seek": 103756, "start": 1047.8799999999999, "end": 1050.84, "text": " all layers must be stored in memory.", "tokens": [50880, 439, 7914, 1633, 312, 12187, 294, 4675, 13, 51028], "temperature": 0.0, "avg_logprob": -0.10814197464744643, "compression_ratio": 1.7236363636363636, "no_speech_prob": 0.010011906735599041}, {"id": 255, "seek": 103756, "start": 1050.84, "end": 1056.2, "text": " Liquid neural networks are particularly good at processing temporal data due to their dynamic", "tokens": [51028, 38943, 18161, 9590, 366, 4098, 665, 412, 9007, 30881, 1412, 3462, 281, 641, 8546, 51296], "temperature": 0.0, "avg_logprob": -0.10814197464744643, "compression_ratio": 1.7236363636363636, "no_speech_prob": 0.010011906735599041}, {"id": 256, "seek": 103756, "start": 1056.2, "end": 1057.2, "text": " reservoir.", "tokens": [51296, 26316, 13, 51346], "temperature": 0.0, "avg_logprob": -0.10814197464744643, "compression_ratio": 1.7236363636363636, "no_speech_prob": 0.010011906735599041}, {"id": 257, "seek": 103756, "start": 1057.2, "end": 1061.6799999999998, "text": " So they excel in tasks that involve complex time series data.", "tokens": [51346, 407, 436, 24015, 294, 9608, 300, 9494, 3997, 565, 2638, 1412, 13, 51570], "temperature": 0.0, "avg_logprob": -0.10814197464744643, "compression_ratio": 1.7236363636363636, "no_speech_prob": 0.010011906735599041}, {"id": 258, "seek": 103756, "start": 1061.6799999999998, "end": 1066.44, "text": " Now you might be wondering, well, how can these liquid neural networks actually be applied", "tokens": [51570, 823, 291, 1062, 312, 6359, 11, 731, 11, 577, 393, 613, 6553, 18161, 9590, 767, 312, 6456, 51808], "temperature": 0.0, "avg_logprob": -0.10814197464744643, "compression_ratio": 1.7236363636363636, "no_speech_prob": 0.010011906735599041}, {"id": 259, "seek": 106644, "start": 1066.44, "end": 1067.8, "text": " in the real world?", "tokens": [50364, 294, 264, 957, 1002, 30, 50432], "temperature": 0.0, "avg_logprob": -0.10918454449586194, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.037318237125873566}, {"id": 260, "seek": 106644, "start": 1067.8, "end": 1069.8400000000001, "text": " So here are some use cases.", "tokens": [50432, 407, 510, 366, 512, 764, 3331, 13, 50534], "temperature": 0.0, "avg_logprob": -0.10918454449586194, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.037318237125873566}, {"id": 261, "seek": 106644, "start": 1069.8400000000001, "end": 1075.28, "text": " As we race to build fully autonomous AI robots, these robots will be deployed in the real", "tokens": [50534, 1018, 321, 4569, 281, 1322, 4498, 23797, 7318, 14733, 11, 613, 14733, 486, 312, 17826, 294, 264, 957, 50806], "temperature": 0.0, "avg_logprob": -0.10918454449586194, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.037318237125873566}, {"id": 262, "seek": 106644, "start": 1075.28, "end": 1080.2, "text": " world and oftentimes they might encounter situations that they've never seen before", "tokens": [50806, 1002, 293, 18349, 436, 1062, 8593, 6851, 300, 436, 600, 1128, 1612, 949, 51052], "temperature": 0.0, "avg_logprob": -0.10918454449586194, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.037318237125873566}, {"id": 263, "seek": 106644, "start": 1080.2, "end": 1081.6000000000001, "text": " during training.", "tokens": [51052, 1830, 3097, 13, 51122], "temperature": 0.0, "avg_logprob": -0.10918454449586194, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.037318237125873566}, {"id": 264, "seek": 106644, "start": 1081.6000000000001, "end": 1086.72, "text": " For example, there could be unpredictable environments in search and rescue missions,", "tokens": [51122, 1171, 1365, 11, 456, 727, 312, 31160, 12388, 294, 3164, 293, 13283, 13744, 11, 51378], "temperature": 0.0, "avg_logprob": -0.10918454449586194, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.037318237125873566}, {"id": 265, "seek": 106644, "start": 1086.72, "end": 1091.3200000000002, "text": " but with liquid neural networks, these robots can adapt to changing conditions and learn", "tokens": [51378, 457, 365, 6553, 18161, 9590, 11, 613, 14733, 393, 6231, 281, 4473, 4487, 293, 1466, 51608], "temperature": 0.0, "avg_logprob": -0.10918454449586194, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.037318237125873566}, {"id": 266, "seek": 106644, "start": 1091.3200000000002, "end": 1093.2, "text": " new tasks on the fly.", "tokens": [51608, 777, 9608, 322, 264, 3603, 13, 51702], "temperature": 0.0, "avg_logprob": -0.10918454449586194, "compression_ratio": 1.6254681647940075, "no_speech_prob": 0.037318237125873566}, {"id": 267, "seek": 109320, "start": 1093.2, "end": 1097.64, "text": " And eventually we're going to have these autonomous robots in our houses helping us do chores", "tokens": [50364, 400, 4728, 321, 434, 516, 281, 362, 613, 23797, 14733, 294, 527, 8078, 4315, 505, 360, 39551, 50586], "temperature": 0.0, "avg_logprob": -0.10777326673269272, "compression_ratio": 1.7516339869281046, "no_speech_prob": 0.03409353271126747}, {"id": 268, "seek": 109320, "start": 1097.64, "end": 1098.88, "text": " and other tasks.", "tokens": [50586, 293, 661, 9608, 13, 50648], "temperature": 0.0, "avg_logprob": -0.10777326673269272, "compression_ratio": 1.7516339869281046, "no_speech_prob": 0.03409353271126747}, {"id": 269, "seek": 109320, "start": 1098.88, "end": 1103.24, "text": " But maybe you have a certain way of folding clothes or doing the laundry or cooking that", "tokens": [50648, 583, 1310, 291, 362, 257, 1629, 636, 295, 25335, 5534, 420, 884, 264, 19811, 420, 6361, 300, 50866], "temperature": 0.0, "avg_logprob": -0.10777326673269272, "compression_ratio": 1.7516339869281046, "no_speech_prob": 0.03409353271126747}, {"id": 270, "seek": 109320, "start": 1103.24, "end": 1105.0800000000002, "text": " the robot was never trained on.", "tokens": [50866, 264, 7881, 390, 1128, 8895, 322, 13, 50958], "temperature": 0.0, "avg_logprob": -0.10777326673269272, "compression_ratio": 1.7516339869281046, "no_speech_prob": 0.03409353271126747}, {"id": 271, "seek": 109320, "start": 1105.0800000000002, "end": 1109.82, "text": " So with a traditional neural network, these robots aren't able to learn new skills after", "tokens": [50958, 407, 365, 257, 5164, 18161, 3209, 11, 613, 14733, 3212, 380, 1075, 281, 1466, 777, 3942, 934, 51195], "temperature": 0.0, "avg_logprob": -0.10777326673269272, "compression_ratio": 1.7516339869281046, "no_speech_prob": 0.03409353271126747}, {"id": 272, "seek": 109320, "start": 1109.82, "end": 1111.2, "text": " being deployed.", "tokens": [51195, 885, 17826, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10777326673269272, "compression_ratio": 1.7516339869281046, "no_speech_prob": 0.03409353271126747}, {"id": 273, "seek": 109320, "start": 1111.2, "end": 1116.3600000000001, "text": " But with liquid neural networks built into a humanoid robot, it can learn new tasks that", "tokens": [51264, 583, 365, 6553, 18161, 9590, 3094, 666, 257, 1952, 17079, 7881, 11, 309, 393, 1466, 777, 9608, 300, 51522], "temperature": 0.0, "avg_logprob": -0.10777326673269272, "compression_ratio": 1.7516339869281046, "no_speech_prob": 0.03409353271126747}, {"id": 274, "seek": 109320, "start": 1116.3600000000001, "end": 1117.3600000000001, "text": " you teach it.", "tokens": [51522, 291, 2924, 309, 13, 51572], "temperature": 0.0, "avg_logprob": -0.10777326673269272, "compression_ratio": 1.7516339869281046, "no_speech_prob": 0.03409353271126747}, {"id": 275, "seek": 109320, "start": 1117.3600000000001, "end": 1120.72, "text": " And this robot will become a lot more personalized for you.", "tokens": [51572, 400, 341, 7881, 486, 1813, 257, 688, 544, 28415, 337, 291, 13, 51740], "temperature": 0.0, "avg_logprob": -0.10777326673269272, "compression_ratio": 1.7516339869281046, "no_speech_prob": 0.03409353271126747}, {"id": 276, "seek": 109320, "start": 1120.72, "end": 1122.96, "text": " And then we have autonomous driving.", "tokens": [51740, 400, 550, 321, 362, 23797, 4840, 13, 51852], "temperature": 0.0, "avg_logprob": -0.10777326673269272, "compression_ratio": 1.7516339869281046, "no_speech_prob": 0.03409353271126747}, {"id": 277, "seek": 112296, "start": 1122.96, "end": 1127.2, "text": " There's no doubt that self-driving cars will eventually become the future.", "tokens": [50364, 821, 311, 572, 6385, 300, 2698, 12, 47094, 5163, 486, 4728, 1813, 264, 2027, 13, 50576], "temperature": 0.0, "avg_logprob": -0.09318158285958426, "compression_ratio": 1.6877076411960132, "no_speech_prob": 0.06949647516012192}, {"id": 278, "seek": 112296, "start": 1127.2, "end": 1132.04, "text": " But current technologies still do not perform well, especially in challenging environments", "tokens": [50576, 583, 2190, 7943, 920, 360, 406, 2042, 731, 11, 2318, 294, 7595, 12388, 50818], "temperature": 0.0, "avg_logprob": -0.09318158285958426, "compression_ratio": 1.6877076411960132, "no_speech_prob": 0.06949647516012192}, {"id": 279, "seek": 112296, "start": 1132.04, "end": 1133.04, "text": " or new conditions.", "tokens": [50818, 420, 777, 4487, 13, 50868], "temperature": 0.0, "avg_logprob": -0.09318158285958426, "compression_ratio": 1.6877076411960132, "no_speech_prob": 0.06949647516012192}, {"id": 280, "seek": 112296, "start": 1133.04, "end": 1138.68, "text": " Again, this is because traditional neural networks can only do well on data that they", "tokens": [50868, 3764, 11, 341, 307, 570, 5164, 18161, 9590, 393, 787, 360, 731, 322, 1412, 300, 436, 51150], "temperature": 0.0, "avg_logprob": -0.09318158285958426, "compression_ratio": 1.6877076411960132, "no_speech_prob": 0.06949647516012192}, {"id": 281, "seek": 112296, "start": 1138.68, "end": 1139.68, "text": " were trained on.", "tokens": [51150, 645, 8895, 322, 13, 51200], "temperature": 0.0, "avg_logprob": -0.09318158285958426, "compression_ratio": 1.6877076411960132, "no_speech_prob": 0.06949647516012192}, {"id": 282, "seek": 112296, "start": 1139.68, "end": 1142.2, "text": " They're not able to adapt to new environments.", "tokens": [51200, 814, 434, 406, 1075, 281, 6231, 281, 777, 12388, 13, 51326], "temperature": 0.0, "avg_logprob": -0.09318158285958426, "compression_ratio": 1.6877076411960132, "no_speech_prob": 0.06949647516012192}, {"id": 283, "seek": 112296, "start": 1142.2, "end": 1147.0, "text": " But with liquid neural networks, autonomous vehicles can navigate complex and dynamic", "tokens": [51326, 583, 365, 6553, 18161, 9590, 11, 23797, 8948, 393, 12350, 3997, 293, 8546, 51566], "temperature": 0.0, "avg_logprob": -0.09318158285958426, "compression_ratio": 1.6877076411960132, "no_speech_prob": 0.06949647516012192}, {"id": 284, "seek": 112296, "start": 1147.0, "end": 1152.4, "text": " environments by continuously learning and training from sensor data and adjusting their", "tokens": [51566, 12388, 538, 15684, 2539, 293, 3097, 490, 10200, 1412, 293, 23559, 641, 51836], "temperature": 0.0, "avg_logprob": -0.09318158285958426, "compression_ratio": 1.6877076411960132, "no_speech_prob": 0.06949647516012192}, {"id": 285, "seek": 115240, "start": 1152.4, "end": 1154.2, "text": " behavior accordingly.", "tokens": [50364, 5223, 19717, 13, 50454], "temperature": 0.0, "avg_logprob": -0.14590009053548178, "compression_ratio": 1.6101083032490975, "no_speech_prob": 0.06369610875844955}, {"id": 286, "seek": 115240, "start": 1154.2, "end": 1157.3200000000002, "text": " It's constantly training and improving over time.", "tokens": [50454, 467, 311, 6460, 3097, 293, 11470, 670, 565, 13, 50610], "temperature": 0.0, "avg_logprob": -0.14590009053548178, "compression_ratio": 1.6101083032490975, "no_speech_prob": 0.06369610875844955}, {"id": 287, "seek": 115240, "start": 1157.3200000000002, "end": 1163.1200000000001, "text": " Now as I've mentioned before, liquid neural networks often incorporate recurrent connections,", "tokens": [50610, 823, 382, 286, 600, 2835, 949, 11, 6553, 18161, 9590, 2049, 16091, 18680, 1753, 9271, 11, 50900], "temperature": 0.0, "avg_logprob": -0.14590009053548178, "compression_ratio": 1.6101083032490975, "no_speech_prob": 0.06369610875844955}, {"id": 288, "seek": 115240, "start": 1163.1200000000001, "end": 1167.0400000000002, "text": " making them suitable for processing time series data.", "tokens": [50900, 1455, 552, 12873, 337, 9007, 565, 2638, 1412, 13, 51096], "temperature": 0.0, "avg_logprob": -0.14590009053548178, "compression_ratio": 1.6101083032490975, "no_speech_prob": 0.06369610875844955}, {"id": 289, "seek": 115240, "start": 1167.0400000000002, "end": 1171.44, "text": " So it's great for things like weather prediction and of course, stock trading.", "tokens": [51096, 407, 309, 311, 869, 337, 721, 411, 5503, 17630, 293, 295, 1164, 11, 4127, 9529, 13, 51316], "temperature": 0.0, "avg_logprob": -0.14590009053548178, "compression_ratio": 1.6101083032490975, "no_speech_prob": 0.06369610875844955}, {"id": 290, "seek": 115240, "start": 1171.44, "end": 1177.18, "text": " The stock market is filled with ever-changing trends and cycles, so it's close to impossible", "tokens": [51316, 440, 4127, 2142, 307, 6412, 365, 1562, 12, 27123, 13892, 293, 17796, 11, 370, 309, 311, 1998, 281, 6243, 51603], "temperature": 0.0, "avg_logprob": -0.14590009053548178, "compression_ratio": 1.6101083032490975, "no_speech_prob": 0.06369610875844955}, {"id": 291, "seek": 115240, "start": 1177.18, "end": 1181.2800000000002, "text": " for one fixed algorithm or formula to beat the market.", "tokens": [51603, 337, 472, 6806, 9284, 420, 8513, 281, 4224, 264, 2142, 13, 51808], "temperature": 0.0, "avg_logprob": -0.14590009053548178, "compression_ratio": 1.6101083032490975, "no_speech_prob": 0.06369610875844955}, {"id": 292, "seek": 118128, "start": 1181.28, "end": 1186.68, "text": " However, because liquid neural networks can adapt to ever-changing data, it can optimize", "tokens": [50364, 2908, 11, 570, 6553, 18161, 9590, 393, 6231, 281, 1562, 12, 27123, 1412, 11, 309, 393, 19719, 50634], "temperature": 0.0, "avg_logprob": -0.1189658183317918, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.3699972629547119}, {"id": 293, "seek": 118128, "start": 1186.68, "end": 1190.56, "text": " trading strategies in real time to maximize profits.", "tokens": [50634, 9529, 9029, 294, 957, 565, 281, 19874, 17982, 13, 50828], "temperature": 0.0, "avg_logprob": -0.1189658183317918, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.3699972629547119}, {"id": 294, "seek": 118128, "start": 1190.56, "end": 1195.28, "text": " In other words, you could be constantly streaming the latest market data to this liquid neural", "tokens": [50828, 682, 661, 2283, 11, 291, 727, 312, 6460, 11791, 264, 6792, 2142, 1412, 281, 341, 6553, 18161, 51064], "temperature": 0.0, "avg_logprob": -0.1189658183317918, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.3699972629547119}, {"id": 295, "seek": 118128, "start": 1195.28, "end": 1200.24, "text": " network, which would change its configuration to adapt to this data in real time to help", "tokens": [51064, 3209, 11, 597, 576, 1319, 1080, 11694, 281, 6231, 281, 341, 1412, 294, 957, 565, 281, 854, 51312], "temperature": 0.0, "avg_logprob": -0.1189658183317918, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.3699972629547119}, {"id": 296, "seek": 118128, "start": 1200.24, "end": 1202.3999999999999, "text": " you maximize profits.", "tokens": [51312, 291, 19874, 17982, 13, 51420], "temperature": 0.0, "avg_logprob": -0.1189658183317918, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.3699972629547119}, {"id": 297, "seek": 118128, "start": 1202.3999999999999, "end": 1204.8, "text": " Another use case would be healthcare.", "tokens": [51420, 3996, 764, 1389, 576, 312, 8884, 13, 51540], "temperature": 0.0, "avg_logprob": -0.1189658183317918, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.3699972629547119}, {"id": 298, "seek": 118128, "start": 1204.8, "end": 1210.36, "text": " Liquid neural networks can be used in wearable devices to monitor patients in real time,", "tokens": [51540, 38943, 18161, 9590, 393, 312, 1143, 294, 3728, 712, 5759, 281, 6002, 4209, 294, 957, 565, 11, 51818], "temperature": 0.0, "avg_logprob": -0.1189658183317918, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.3699972629547119}, {"id": 299, "seek": 121036, "start": 1210.36, "end": 1215.36, "text": " adapting to changes in the patient's conditions and predicting potential health issues before", "tokens": [50364, 34942, 281, 2962, 294, 264, 4537, 311, 4487, 293, 32884, 3995, 1585, 2663, 949, 50614], "temperature": 0.0, "avg_logprob": -0.14302518519949406, "compression_ratio": 1.695970695970696, "no_speech_prob": 0.33772510290145874}, {"id": 300, "seek": 121036, "start": 1215.36, "end": 1217.04, "text": " they become critical.", "tokens": [50614, 436, 1813, 4924, 13, 50698], "temperature": 0.0, "avg_logprob": -0.14302518519949406, "compression_ratio": 1.695970695970696, "no_speech_prob": 0.33772510290145874}, {"id": 301, "seek": 121036, "start": 1217.04, "end": 1222.4799999999998, "text": " In cybersecurity, liquid neural networks can continuously learn from network traffic and", "tokens": [50698, 682, 38765, 11, 6553, 18161, 9590, 393, 15684, 1466, 490, 3209, 6419, 293, 50970], "temperature": 0.0, "avg_logprob": -0.14302518519949406, "compression_ratio": 1.695970695970696, "no_speech_prob": 0.33772510290145874}, {"id": 302, "seek": 121036, "start": 1222.4799999999998, "end": 1228.9599999999998, "text": " user behavior to adapt access control policies and detect anomalies or unauthorized access", "tokens": [50970, 4195, 5223, 281, 6231, 2105, 1969, 7657, 293, 5531, 24769, 48872, 420, 517, 34224, 1602, 2105, 51294], "temperature": 0.0, "avg_logprob": -0.14302518519949406, "compression_ratio": 1.695970695970696, "no_speech_prob": 0.33772510290145874}, {"id": 303, "seek": 121036, "start": 1228.9599999999998, "end": 1230.3999999999999, "text": " attempts.", "tokens": [51294, 15257, 13, 51366], "temperature": 0.0, "avg_logprob": -0.14302518519949406, "compression_ratio": 1.695970695970696, "no_speech_prob": 0.33772510290145874}, {"id": 304, "seek": 121036, "start": 1230.3999999999999, "end": 1234.84, "text": " Yet another use case would be streaming services such as Netflix.", "tokens": [51366, 10890, 1071, 764, 1389, 576, 312, 11791, 3328, 1270, 382, 12778, 13, 51588], "temperature": 0.0, "avg_logprob": -0.14302518519949406, "compression_ratio": 1.695970695970696, "no_speech_prob": 0.33772510290145874}, {"id": 305, "seek": 121036, "start": 1234.84, "end": 1240.28, "text": " They can use liquid neural networks to adapt to each user's viewing habits and preferences,", "tokens": [51588, 814, 393, 764, 6553, 18161, 9590, 281, 6231, 281, 1184, 4195, 311, 17480, 14100, 293, 21910, 11, 51860], "temperature": 0.0, "avg_logprob": -0.14302518519949406, "compression_ratio": 1.695970695970696, "no_speech_prob": 0.33772510290145874}, {"id": 306, "seek": 124028, "start": 1240.28, "end": 1243.72, "text": " providing more personalized content recommendations.", "tokens": [50364, 6530, 544, 28415, 2701, 10434, 13, 50536], "temperature": 0.0, "avg_logprob": -0.13775801104168559, "compression_ratio": 1.65625, "no_speech_prob": 0.11271142959594727}, {"id": 307, "seek": 124028, "start": 1243.72, "end": 1246.6, "text": " Another use case would be smart city management.", "tokens": [50536, 3996, 764, 1389, 576, 312, 4069, 2307, 4592, 13, 50680], "temperature": 0.0, "avg_logprob": -0.13775801104168559, "compression_ratio": 1.65625, "no_speech_prob": 0.11271142959594727}, {"id": 308, "seek": 124028, "start": 1246.6, "end": 1251.72, "text": " For example, liquid neural networks can optimize traffic flow in real time by learning from", "tokens": [50680, 1171, 1365, 11, 6553, 18161, 9590, 393, 19719, 6419, 3095, 294, 957, 565, 538, 2539, 490, 50936], "temperature": 0.0, "avg_logprob": -0.13775801104168559, "compression_ratio": 1.65625, "no_speech_prob": 0.11271142959594727}, {"id": 309, "seek": 124028, "start": 1251.72, "end": 1257.84, "text": " traffic patterns and changing traffic lights accordingly to reduce congestion and improve", "tokens": [50936, 6419, 8294, 293, 4473, 6419, 5811, 19717, 281, 5407, 40816, 293, 3470, 51242], "temperature": 0.0, "avg_logprob": -0.13775801104168559, "compression_ratio": 1.65625, "no_speech_prob": 0.11271142959594727}, {"id": 310, "seek": 124028, "start": 1257.84, "end": 1259.2, "text": " efficiency.", "tokens": [51242, 10493, 13, 51310], "temperature": 0.0, "avg_logprob": -0.13775801104168559, "compression_ratio": 1.65625, "no_speech_prob": 0.11271142959594727}, {"id": 311, "seek": 124028, "start": 1259.2, "end": 1261.96, "text": " Energy management is also very relevant.", "tokens": [51310, 14939, 4592, 307, 611, 588, 7340, 13, 51448], "temperature": 0.0, "avg_logprob": -0.13775801104168559, "compression_ratio": 1.65625, "no_speech_prob": 0.11271142959594727}, {"id": 312, "seek": 124028, "start": 1261.96, "end": 1266.68, "text": " Smart grids can use liquid neural networks to balance power, supply, and demand in real", "tokens": [51448, 12923, 677, 3742, 393, 764, 6553, 18161, 9590, 281, 4772, 1347, 11, 5847, 11, 293, 4733, 294, 957, 51684], "temperature": 0.0, "avg_logprob": -0.13775801104168559, "compression_ratio": 1.65625, "no_speech_prob": 0.11271142959594727}, {"id": 313, "seek": 126668, "start": 1266.68, "end": 1272.44, "text": " time, improving efficiency and reducing costs by adapting to consumption patterns.", "tokens": [50364, 565, 11, 11470, 10493, 293, 12245, 5497, 538, 34942, 281, 12126, 8294, 13, 50652], "temperature": 0.0, "avg_logprob": -0.11213113026446607, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.5731050968170166}, {"id": 314, "seek": 126668, "start": 1272.44, "end": 1278.0, "text": " However, although liquid neural networks seem promising, it does have its limitations.", "tokens": [50652, 2908, 11, 4878, 6553, 18161, 9590, 1643, 20257, 11, 309, 775, 362, 1080, 15705, 13, 50930], "temperature": 0.0, "avg_logprob": -0.11213113026446607, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.5731050968170166}, {"id": 315, "seek": 126668, "start": 1278.0, "end": 1283.16, "text": " This is still a relatively new concept in the field of neural networks and research on", "tokens": [50930, 639, 307, 920, 257, 7226, 777, 3410, 294, 264, 2519, 295, 18161, 9590, 293, 2132, 322, 51188], "temperature": 0.0, "avg_logprob": -0.11213113026446607, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.5731050968170166}, {"id": 316, "seek": 126668, "start": 1283.16, "end": 1288.5600000000002, "text": " them is still in its early stages compared to more traditional architectures.", "tokens": [51188, 552, 307, 920, 294, 1080, 2440, 10232, 5347, 281, 544, 5164, 6331, 1303, 13, 51458], "temperature": 0.0, "avg_logprob": -0.11213113026446607, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.5731050968170166}, {"id": 317, "seek": 126668, "start": 1288.5600000000002, "end": 1293.8, "text": " While liquid neural networks show promising theoretical benefits such as the ability to", "tokens": [51458, 3987, 6553, 18161, 9590, 855, 20257, 20864, 5311, 1270, 382, 264, 3485, 281, 51720], "temperature": 0.0, "avg_logprob": -0.11213113026446607, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.5731050968170166}, {"id": 318, "seek": 129380, "start": 1293.8, "end": 1299.1599999999999, "text": " process continuous data streams and adapt on the fly, there is still a lack of real", "tokens": [50364, 1399, 10957, 1412, 15842, 293, 6231, 322, 264, 3603, 11, 456, 307, 920, 257, 5011, 295, 957, 50632], "temperature": 0.0, "avg_logprob": -0.11634668144019875, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.5111865401268005}, {"id": 319, "seek": 129380, "start": 1299.1599999999999, "end": 1303.72, "text": " world results demonstrating their superiority on a large scale.", "tokens": [50632, 1002, 3542, 29889, 641, 48668, 322, 257, 2416, 4373, 13, 50860], "temperature": 0.0, "avg_logprob": -0.11634668144019875, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.5111865401268005}, {"id": 320, "seek": 129380, "start": 1303.72, "end": 1308.8, "text": " Many researchers are likely waiting for more compelling benchmark results before investing", "tokens": [50860, 5126, 10309, 366, 3700, 3806, 337, 544, 20050, 18927, 3542, 949, 10978, 51114], "temperature": 0.0, "avg_logprob": -0.11634668144019875, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.5111865401268005}, {"id": 321, "seek": 129380, "start": 1308.8, "end": 1312.1599999999999, "text": " significant effort into liquid neural networks.", "tokens": [51114, 4776, 4630, 666, 6553, 18161, 9590, 13, 51282], "temperature": 0.0, "avg_logprob": -0.11634668144019875, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.5111865401268005}, {"id": 322, "seek": 129380, "start": 1312.1599999999999, "end": 1318.24, "text": " Also as I mentioned previously, they're particularly suited for temporal or sequence data.", "tokens": [51282, 2743, 382, 286, 2835, 8046, 11, 436, 434, 4098, 24736, 337, 30881, 420, 8310, 1412, 13, 51586], "temperature": 0.0, "avg_logprob": -0.11634668144019875, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.5111865401268005}, {"id": 323, "seek": 131824, "start": 1318.24, "end": 1324.08, "text": " Also for tasks that do not involve time such as identifying images of cats or dogs, traditional", "tokens": [50364, 2743, 337, 9608, 300, 360, 406, 9494, 565, 1270, 382, 16696, 5267, 295, 11111, 420, 7197, 11, 5164, 50656], "temperature": 0.0, "avg_logprob": -0.10354010264078777, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.5346445441246033}, {"id": 324, "seek": 131824, "start": 1324.08, "end": 1328.96, "text": " neural networks might actually be more effective and straightforward to implement.", "tokens": [50656, 18161, 9590, 1062, 767, 312, 544, 4942, 293, 15325, 281, 4445, 13, 50900], "temperature": 0.0, "avg_logprob": -0.10354010264078777, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.5346445441246033}, {"id": 325, "seek": 131824, "start": 1328.96, "end": 1334.76, "text": " Also the dynamics within this reservoir layer can be very complex and difficult to interpret", "tokens": [50900, 2743, 264, 15679, 1951, 341, 26316, 4583, 393, 312, 588, 3997, 293, 2252, 281, 7302, 51190], "temperature": 0.0, "avg_logprob": -0.10354010264078777, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.5346445441246033}, {"id": 326, "seek": 131824, "start": 1334.76, "end": 1339.68, "text": " and this makes it challenging to understand how the reservoir processes these inputs.", "tokens": [51190, 293, 341, 1669, 309, 7595, 281, 1223, 577, 264, 26316, 7555, 613, 15743, 13, 51436], "temperature": 0.0, "avg_logprob": -0.10354010264078777, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.5346445441246033}, {"id": 327, "seek": 131824, "start": 1339.68, "end": 1342.96, "text": " It would be quite hard to fine tune it for optimal performance.", "tokens": [51436, 467, 576, 312, 1596, 1152, 281, 2489, 10864, 309, 337, 16252, 3389, 13, 51600], "temperature": 0.0, "avg_logprob": -0.10354010264078777, "compression_ratio": 1.6007604562737643, "no_speech_prob": 0.5346445441246033}, {"id": 328, "seek": 134296, "start": 1342.96, "end": 1349.04, "text": " Finally, there is a lack of standardized support and fewer established frameworks for liquid", "tokens": [50364, 6288, 11, 456, 307, 257, 5011, 295, 31677, 1406, 293, 13366, 7545, 29834, 337, 6553, 50668], "temperature": 0.0, "avg_logprob": -0.14229906172979445, "compression_ratio": 1.7553648068669527, "no_speech_prob": 0.03409471735358238}, {"id": 329, "seek": 134296, "start": 1349.04, "end": 1352.0, "text": " neural networks compared to traditional neural networks.", "tokens": [50668, 18161, 9590, 5347, 281, 5164, 18161, 9590, 13, 50816], "temperature": 0.0, "avg_logprob": -0.14229906172979445, "compression_ratio": 1.7553648068669527, "no_speech_prob": 0.03409471735358238}, {"id": 330, "seek": 134296, "start": 1352.0, "end": 1356.44, "text": " And this can make implementation and experimentation more challenging.", "tokens": [50816, 400, 341, 393, 652, 11420, 293, 37142, 544, 7595, 13, 51038], "temperature": 0.0, "avg_logprob": -0.14229906172979445, "compression_ratio": 1.7553648068669527, "no_speech_prob": 0.03409471735358238}, {"id": 331, "seek": 134296, "start": 1356.44, "end": 1361.8, "text": " So all in all, liquid neural networks are still a very early concept and an area of active", "tokens": [51038, 407, 439, 294, 439, 11, 6553, 18161, 9590, 366, 920, 257, 588, 2440, 3410, 293, 364, 1859, 295, 4967, 51306], "temperature": 0.0, "avg_logprob": -0.14229906172979445, "compression_ratio": 1.7553648068669527, "no_speech_prob": 0.03409471735358238}, {"id": 332, "seek": 134296, "start": 1361.8, "end": 1362.8, "text": " research.", "tokens": [51306, 2132, 13, 51356], "temperature": 0.0, "avg_logprob": -0.14229906172979445, "compression_ratio": 1.7553648068669527, "no_speech_prob": 0.03409471735358238}, {"id": 333, "seek": 134296, "start": 1362.8, "end": 1367.52, "text": " Unlike traditional neural networks that are fixed and need to be retrained with a large", "tokens": [51356, 17657, 5164, 18161, 9590, 300, 366, 6806, 293, 643, 281, 312, 1533, 31774, 365, 257, 2416, 51592], "temperature": 0.0, "avg_logprob": -0.14229906172979445, "compression_ratio": 1.7553648068669527, "no_speech_prob": 0.03409471735358238}, {"id": 334, "seek": 136752, "start": 1367.52, "end": 1372.4, "text": " data set to learn new information, liquid neural networks can update their knowledge", "tokens": [50364, 1412, 992, 281, 1466, 777, 1589, 11, 6553, 18161, 9590, 393, 5623, 641, 3601, 50608], "temperature": 0.0, "avg_logprob": -0.11053278028350516, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.3343632221221924}, {"id": 335, "seek": 136752, "start": 1372.4, "end": 1375.4, "text": " incrementally with each new piece of data.", "tokens": [50608, 26200, 379, 365, 1184, 777, 2522, 295, 1412, 13, 50758], "temperature": 0.0, "avg_logprob": -0.11053278028350516, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.3343632221221924}, {"id": 336, "seek": 136752, "start": 1375.4, "end": 1380.56, "text": " This offers a flexible and adaptive model which could potentially become infinitely", "tokens": [50758, 639, 7736, 257, 11358, 293, 27912, 2316, 597, 727, 7263, 1813, 36227, 51016], "temperature": 0.0, "avg_logprob": -0.11053278028350516, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.3343632221221924}, {"id": 337, "seek": 136752, "start": 1380.56, "end": 1382.72, "text": " smarter over time.", "tokens": [51016, 20294, 670, 565, 13, 51124], "temperature": 0.0, "avg_logprob": -0.11053278028350516, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.3343632221221924}, {"id": 338, "seek": 136752, "start": 1382.72, "end": 1388.0, "text": " Now liquid neural networks aren't the only possibility that could become the next generation", "tokens": [51124, 823, 6553, 18161, 9590, 3212, 380, 264, 787, 7959, 300, 727, 1813, 264, 958, 5125, 51388], "temperature": 0.0, "avg_logprob": -0.11053278028350516, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.3343632221221924}, {"id": 339, "seek": 136752, "start": 1388.0, "end": 1389.0, "text": " of AI.", "tokens": [51388, 295, 7318, 13, 51438], "temperature": 0.0, "avg_logprob": -0.11053278028350516, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.3343632221221924}, {"id": 340, "seek": 136752, "start": 1389.0, "end": 1393.54, "text": " We have another type of neural network which is designed to mimic the human brain even", "tokens": [51438, 492, 362, 1071, 2010, 295, 18161, 3209, 597, 307, 4761, 281, 31075, 264, 1952, 3567, 754, 51665], "temperature": 0.0, "avg_logprob": -0.11053278028350516, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.3343632221221924}, {"id": 341, "seek": 136752, "start": 1393.54, "end": 1396.4, "text": " more than traditional neural networks.", "tokens": [51665, 544, 813, 5164, 18161, 9590, 13, 51808], "temperature": 0.0, "avg_logprob": -0.11053278028350516, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.3343632221221924}, {"id": 342, "seek": 139640, "start": 1396.4, "end": 1399.64, "text": " And this brings us to spiking neural networks.", "tokens": [50364, 400, 341, 5607, 505, 281, 637, 13085, 18161, 9590, 13, 50526], "temperature": 0.0, "avg_logprob": -0.1251441725978145, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.11914560943841934}, {"id": 343, "seek": 139640, "start": 1399.64, "end": 1406.1200000000001, "text": " These are closely inspired by the way neurons in our brains communicate using discrete spikes", "tokens": [50526, 1981, 366, 8185, 7547, 538, 264, 636, 22027, 294, 527, 15442, 7890, 1228, 27706, 28997, 50850], "temperature": 0.0, "avg_logprob": -0.1251441725978145, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.11914560943841934}, {"id": 344, "seek": 139640, "start": 1406.1200000000001, "end": 1408.0800000000002, "text": " or action potentials.", "tokens": [50850, 420, 3069, 3995, 82, 13, 50948], "temperature": 0.0, "avg_logprob": -0.1251441725978145, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.11914560943841934}, {"id": 345, "seek": 139640, "start": 1408.0800000000002, "end": 1413.52, "text": " You see, in the human brain, which is basically a network of neurons, each neuron doesn't", "tokens": [50948, 509, 536, 11, 294, 264, 1952, 3567, 11, 597, 307, 1936, 257, 3209, 295, 22027, 11, 1184, 34090, 1177, 380, 51220], "temperature": 0.0, "avg_logprob": -0.1251441725978145, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.11914560943841934}, {"id": 346, "seek": 139640, "start": 1413.52, "end": 1417.8000000000002, "text": " immediately fire to the next set of neurons when it receives input.", "tokens": [51220, 4258, 2610, 281, 264, 958, 992, 295, 22027, 562, 309, 20717, 4846, 13, 51434], "temperature": 0.0, "avg_logprob": -0.1251441725978145, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.11914560943841934}, {"id": 347, "seek": 139640, "start": 1417.8000000000002, "end": 1423.8400000000001, "text": " Instead, the input has to build up to a certain threshold and once it passes this threshold,", "tokens": [51434, 7156, 11, 264, 4846, 575, 281, 1322, 493, 281, 257, 1629, 14678, 293, 1564, 309, 11335, 341, 14678, 11, 51736], "temperature": 0.0, "avg_logprob": -0.1251441725978145, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.11914560943841934}, {"id": 348, "seek": 139640, "start": 1423.8400000000001, "end": 1426.0, "text": " then it fires to the next set of neurons.", "tokens": [51736, 550, 309, 15044, 281, 264, 958, 992, 295, 22027, 13, 51844], "temperature": 0.0, "avg_logprob": -0.1251441725978145, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.11914560943841934}, {"id": 349, "seek": 142600, "start": 1426.0, "end": 1429.52, "text": " And after it fires, it goes back to its resting state.", "tokens": [50364, 400, 934, 309, 15044, 11, 309, 1709, 646, 281, 1080, 21221, 1785, 13, 50540], "temperature": 0.0, "avg_logprob": -0.11874842193891418, "compression_ratio": 1.6528301886792454, "no_speech_prob": 0.0010649370960891247}, {"id": 350, "seek": 142600, "start": 1429.52, "end": 1433.92, "text": " Well, spiking neural networks are designed to mimic this behavior.", "tokens": [50540, 1042, 11, 637, 13085, 18161, 9590, 366, 4761, 281, 31075, 341, 5223, 13, 50760], "temperature": 0.0, "avg_logprob": -0.11874842193891418, "compression_ratio": 1.6528301886792454, "no_speech_prob": 0.0010649370960891247}, {"id": 351, "seek": 142600, "start": 1433.92, "end": 1435.92, "text": " So here's how it works.", "tokens": [50760, 407, 510, 311, 577, 309, 1985, 13, 50860], "temperature": 0.0, "avg_logprob": -0.11874842193891418, "compression_ratio": 1.6528301886792454, "no_speech_prob": 0.0010649370960891247}, {"id": 352, "seek": 142600, "start": 1435.92, "end": 1440.0, "text": " The architecture is quite similar to traditional neural networks.", "tokens": [50860, 440, 9482, 307, 1596, 2531, 281, 5164, 18161, 9590, 13, 51064], "temperature": 0.0, "avg_logprob": -0.11874842193891418, "compression_ratio": 1.6528301886792454, "no_speech_prob": 0.0010649370960891247}, {"id": 353, "seek": 142600, "start": 1440.0, "end": 1446.8, "text": " However, for each neuron, it waits to receive signals or spikes from other neurons.", "tokens": [51064, 2908, 11, 337, 1184, 34090, 11, 309, 40597, 281, 4774, 12354, 420, 28997, 490, 661, 22027, 13, 51404], "temperature": 0.0, "avg_logprob": -0.11874842193891418, "compression_ratio": 1.6528301886792454, "no_speech_prob": 0.0010649370960891247}, {"id": 354, "seek": 142600, "start": 1446.8, "end": 1449.8, "text": " Think of these spikes as like little electric pulses.", "tokens": [51404, 6557, 295, 613, 28997, 382, 411, 707, 5210, 45279, 13, 51554], "temperature": 0.0, "avg_logprob": -0.11874842193891418, "compression_ratio": 1.6528301886792454, "no_speech_prob": 0.0010649370960891247}, {"id": 355, "seek": 142600, "start": 1449.8, "end": 1455.24, "text": " The input data, such as an image or a sound, is turned into the spikes that move through", "tokens": [51554, 440, 4846, 1412, 11, 1270, 382, 364, 3256, 420, 257, 1626, 11, 307, 3574, 666, 264, 28997, 300, 1286, 807, 51826], "temperature": 0.0, "avg_logprob": -0.11874842193891418, "compression_ratio": 1.6528301886792454, "no_speech_prob": 0.0010649370960891247}, {"id": 356, "seek": 145524, "start": 1455.28, "end": 1456.76, "text": " this neural network.", "tokens": [50366, 341, 18161, 3209, 13, 50440], "temperature": 0.0, "avg_logprob": -0.11337097712925502, "compression_ratio": 1.7563025210084033, "no_speech_prob": 0.03409101814031601}, {"id": 357, "seek": 145524, "start": 1456.76, "end": 1462.1200000000001, "text": " For example, if it's a loud sound, it might generate more spikes while a quiet sound might", "tokens": [50440, 1171, 1365, 11, 498, 309, 311, 257, 6588, 1626, 11, 309, 1062, 8460, 544, 28997, 1339, 257, 5677, 1626, 1062, 50708], "temperature": 0.0, "avg_logprob": -0.11337097712925502, "compression_ratio": 1.7563025210084033, "no_speech_prob": 0.03409101814031601}, {"id": 358, "seek": 145524, "start": 1462.1200000000001, "end": 1464.0, "text": " generate fewer spikes.", "tokens": [50708, 8460, 13366, 28997, 13, 50802], "temperature": 0.0, "avg_logprob": -0.11337097712925502, "compression_ratio": 1.7563025210084033, "no_speech_prob": 0.03409101814031601}, {"id": 359, "seek": 145524, "start": 1464.0, "end": 1468.48, "text": " Now each neuron in the network collects incoming spikes.", "tokens": [50802, 823, 1184, 34090, 294, 264, 3209, 39897, 22341, 28997, 13, 51026], "temperature": 0.0, "avg_logprob": -0.11337097712925502, "compression_ratio": 1.7563025210084033, "no_speech_prob": 0.03409101814031601}, {"id": 360, "seek": 145524, "start": 1468.48, "end": 1470.84, "text": " Imagine a bucket collecting drops of water.", "tokens": [51026, 11739, 257, 13058, 12510, 11438, 295, 1281, 13, 51144], "temperature": 0.0, "avg_logprob": -0.11337097712925502, "compression_ratio": 1.7563025210084033, "no_speech_prob": 0.03409101814031601}, {"id": 361, "seek": 145524, "start": 1470.84, "end": 1473.44, "text": " As more spikes come in, the bucket fills up.", "tokens": [51144, 1018, 544, 28997, 808, 294, 11, 264, 13058, 22498, 493, 13, 51274], "temperature": 0.0, "avg_logprob": -0.11337097712925502, "compression_ratio": 1.7563025210084033, "no_speech_prob": 0.03409101814031601}, {"id": 362, "seek": 145524, "start": 1473.44, "end": 1478.24, "text": " And when the neuron gets enough spikes, in other words, when it reaches a certain threshold,", "tokens": [51274, 400, 562, 264, 34090, 2170, 1547, 28997, 11, 294, 661, 2283, 11, 562, 309, 14235, 257, 1629, 14678, 11, 51514], "temperature": 0.0, "avg_logprob": -0.11337097712925502, "compression_ratio": 1.7563025210084033, "no_speech_prob": 0.03409101814031601}, {"id": 363, "seek": 145524, "start": 1478.24, "end": 1481.0, "text": " it fires a spike to the next set of neurons.", "tokens": [51514, 309, 15044, 257, 21053, 281, 264, 958, 992, 295, 22027, 13, 51652], "temperature": 0.0, "avg_logprob": -0.11337097712925502, "compression_ratio": 1.7563025210084033, "no_speech_prob": 0.03409101814031601}, {"id": 364, "seek": 148100, "start": 1481.0, "end": 1485.6, "text": " And after firing, it resets and starts collecting again from zero.", "tokens": [50364, 400, 934, 16045, 11, 309, 725, 1385, 293, 3719, 12510, 797, 490, 4018, 13, 50594], "temperature": 0.0, "avg_logprob": -0.11047003989995913, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0018101357854902744}, {"id": 365, "seek": 148100, "start": 1485.6, "end": 1491.16, "text": " So instead of using continuous signals like traditional neural networks, spiking neural", "tokens": [50594, 407, 2602, 295, 1228, 10957, 12354, 411, 5164, 18161, 9590, 11, 637, 13085, 18161, 50872], "temperature": 0.0, "avg_logprob": -0.11047003989995913, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0018101357854902744}, {"id": 366, "seek": 148100, "start": 1491.16, "end": 1497.04, "text": " networks uses spikes, which are basically bursts of activity at discrete time points", "tokens": [50872, 9590, 4960, 28997, 11, 597, 366, 1936, 41663, 295, 5191, 412, 27706, 565, 2793, 51166], "temperature": 0.0, "avg_logprob": -0.11047003989995913, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0018101357854902744}, {"id": 367, "seek": 148100, "start": 1497.04, "end": 1499.12, "text": " to process information.", "tokens": [51166, 281, 1399, 1589, 13, 51270], "temperature": 0.0, "avg_logprob": -0.11047003989995913, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0018101357854902744}, {"id": 368, "seek": 148100, "start": 1499.12, "end": 1505.0, "text": " In other words, spiking neural networks incorporate time into their processing, with neurons firing", "tokens": [51270, 682, 661, 2283, 11, 637, 13085, 18161, 9590, 16091, 565, 666, 641, 9007, 11, 365, 22027, 16045, 51564], "temperature": 0.0, "avg_logprob": -0.11047003989995913, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0018101357854902744}, {"id": 369, "seek": 148100, "start": 1505.0, "end": 1508.56, "text": " only when their potential exceeds a certain threshold.", "tokens": [51564, 787, 562, 641, 3995, 43305, 257, 1629, 14678, 13, 51742], "temperature": 0.0, "avg_logprob": -0.11047003989995913, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.0018101357854902744}, {"id": 370, "seek": 150856, "start": 1508.56, "end": 1513.2, "text": " Now there are different methods and algorithms to train a spiking neural network, and there", "tokens": [50364, 823, 456, 366, 819, 7150, 293, 14642, 281, 3847, 257, 637, 13085, 18161, 3209, 11, 293, 456, 50596], "temperature": 0.0, "avg_logprob": -0.09083138260186888, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.020328819751739502}, {"id": 371, "seek": 150856, "start": 1513.2, "end": 1516.52, "text": " currently isn't a standard wave that's set in stone.", "tokens": [50596, 4362, 1943, 380, 257, 3832, 5772, 300, 311, 992, 294, 7581, 13, 50762], "temperature": 0.0, "avg_logprob": -0.09083138260186888, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.020328819751739502}, {"id": 372, "seek": 150856, "start": 1516.52, "end": 1519.3999999999999, "text": " So this is still an active field of research.", "tokens": [50762, 407, 341, 307, 920, 364, 4967, 2519, 295, 2132, 13, 50906], "temperature": 0.0, "avg_logprob": -0.09083138260186888, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.020328819751739502}, {"id": 373, "seek": 150856, "start": 1519.3999999999999, "end": 1525.24, "text": " One common method is called spike timing dependent plasticity, or STDP.", "tokens": [50906, 1485, 2689, 3170, 307, 1219, 21053, 10822, 12334, 5900, 507, 11, 420, 4904, 11373, 13, 51198], "temperature": 0.0, "avg_logprob": -0.09083138260186888, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.020328819751739502}, {"id": 374, "seek": 150856, "start": 1525.24, "end": 1530.52, "text": " This method is inspired by how the brain strengthens or weakens connections between neurons.", "tokens": [51198, 639, 3170, 307, 7547, 538, 577, 264, 3567, 3800, 694, 420, 5336, 694, 9271, 1296, 22027, 13, 51462], "temperature": 0.0, "avg_logprob": -0.09083138260186888, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.020328819751739502}, {"id": 375, "seek": 150856, "start": 1530.52, "end": 1536.9199999999998, "text": " So if one neuron spikes just before another, then the connection between them gets stronger.", "tokens": [51462, 407, 498, 472, 34090, 28997, 445, 949, 1071, 11, 550, 264, 4984, 1296, 552, 2170, 7249, 13, 51782], "temperature": 0.0, "avg_logprob": -0.09083138260186888, "compression_ratio": 1.671641791044776, "no_speech_prob": 0.020328819751739502}, {"id": 376, "seek": 153692, "start": 1536.92, "end": 1540.8000000000002, "text": " If it spikes just after, then the connection gets weaker.", "tokens": [50364, 759, 309, 28997, 445, 934, 11, 550, 264, 4984, 2170, 24286, 13, 50558], "temperature": 0.0, "avg_logprob": -0.1127410943691547, "compression_ratio": 1.7061224489795919, "no_speech_prob": 0.21720246970653534}, {"id": 377, "seek": 153692, "start": 1540.8000000000002, "end": 1545.8400000000001, "text": " It's like learning which connections are important based on the timing of the spikes.", "tokens": [50558, 467, 311, 411, 2539, 597, 9271, 366, 1021, 2361, 322, 264, 10822, 295, 264, 28997, 13, 50810], "temperature": 0.0, "avg_logprob": -0.1127410943691547, "compression_ratio": 1.7061224489795919, "no_speech_prob": 0.21720246970653534}, {"id": 378, "seek": 153692, "start": 1545.8400000000001, "end": 1551.1200000000001, "text": " And speaking of timing, it's the exact timing of spikes that matters.", "tokens": [50810, 400, 4124, 295, 10822, 11, 309, 311, 264, 1900, 10822, 295, 28997, 300, 7001, 13, 51074], "temperature": 0.0, "avg_logprob": -0.1127410943691547, "compression_ratio": 1.7061224489795919, "no_speech_prob": 0.21720246970653534}, {"id": 379, "seek": 153692, "start": 1551.1200000000001, "end": 1555.44, "text": " It's not just about how many spikes there are, but when they happen.", "tokens": [51074, 467, 311, 406, 445, 466, 577, 867, 28997, 456, 366, 11, 457, 562, 436, 1051, 13, 51290], "temperature": 0.0, "avg_logprob": -0.1127410943691547, "compression_ratio": 1.7061224489795919, "no_speech_prob": 0.21720246970653534}, {"id": 380, "seek": 153692, "start": 1555.44, "end": 1559.96, "text": " Now STDP is only one method to train the spiking neural networks.", "tokens": [51290, 823, 4904, 11373, 307, 787, 472, 3170, 281, 3847, 264, 637, 13085, 18161, 9590, 13, 51516], "temperature": 0.0, "avg_logprob": -0.1127410943691547, "compression_ratio": 1.7061224489795919, "no_speech_prob": 0.21720246970653534}, {"id": 381, "seek": 153692, "start": 1559.96, "end": 1563.44, "text": " There are a few other ones, which are beyond the scope of this video.", "tokens": [51516, 821, 366, 257, 1326, 661, 2306, 11, 597, 366, 4399, 264, 11923, 295, 341, 960, 13, 51690], "temperature": 0.0, "avg_logprob": -0.1127410943691547, "compression_ratio": 1.7061224489795919, "no_speech_prob": 0.21720246970653534}, {"id": 382, "seek": 156344, "start": 1563.44, "end": 1568.0, "text": " But like traditional neural networks, spiking neural networks have to undergo millions of", "tokens": [50364, 583, 411, 5164, 18161, 9590, 11, 637, 13085, 18161, 9590, 362, 281, 26426, 6803, 295, 50592], "temperature": 0.0, "avg_logprob": -0.08665527960266729, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.20673678815364838}, {"id": 383, "seek": 156344, "start": 1568.0, "end": 1572.88, "text": " rounds of training with a lot of data, and eventually the configuration of the network", "tokens": [50592, 13757, 295, 3097, 365, 257, 688, 295, 1412, 11, 293, 4728, 264, 11694, 295, 264, 3209, 50836], "temperature": 0.0, "avg_logprob": -0.08665527960266729, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.20673678815364838}, {"id": 384, "seek": 156344, "start": 1572.88, "end": 1576.64, "text": " and all its parameters will reach an optimum state.", "tokens": [50836, 293, 439, 1080, 9834, 486, 2524, 364, 39326, 1785, 13, 51024], "temperature": 0.0, "avg_logprob": -0.08665527960266729, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.20673678815364838}, {"id": 385, "seek": 156344, "start": 1576.64, "end": 1582.4, "text": " Now again, I'd like to remind you that this is a very simplified explanation of spiking", "tokens": [51024, 823, 797, 11, 286, 1116, 411, 281, 4160, 291, 300, 341, 307, 257, 588, 26335, 10835, 295, 637, 13085, 51312], "temperature": 0.0, "avg_logprob": -0.08665527960266729, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.20673678815364838}, {"id": 386, "seek": 156344, "start": 1582.4, "end": 1586.76, "text": " neural networks, and I've left out a lot of mathematical details.", "tokens": [51312, 18161, 9590, 11, 293, 286, 600, 1411, 484, 257, 688, 295, 18894, 4365, 13, 51530], "temperature": 0.0, "avg_logprob": -0.08665527960266729, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.20673678815364838}, {"id": 387, "seek": 156344, "start": 1586.76, "end": 1589.24, "text": " But in a nutshell, that's how it works.", "tokens": [51530, 583, 294, 257, 37711, 11, 300, 311, 577, 309, 1985, 13, 51654], "temperature": 0.0, "avg_logprob": -0.08665527960266729, "compression_ratio": 1.7154471544715446, "no_speech_prob": 0.20673678815364838}, {"id": 388, "seek": 158924, "start": 1589.24, "end": 1593.84, "text": " So you might be wondering, well, what are the benefits of spiking neural networks?", "tokens": [50364, 407, 291, 1062, 312, 6359, 11, 731, 11, 437, 366, 264, 5311, 295, 637, 13085, 18161, 9590, 30, 50594], "temperature": 0.0, "avg_logprob": -0.08002152542273204, "compression_ratio": 1.7, "no_speech_prob": 0.0636913850903511}, {"id": 389, "seek": 158924, "start": 1593.84, "end": 1598.8, "text": " First of all, it's designed to mimic the human brain even more by implementing this", "tokens": [50594, 2386, 295, 439, 11, 309, 311, 4761, 281, 31075, 264, 1952, 3567, 754, 544, 538, 18114, 341, 50842], "temperature": 0.0, "avg_logprob": -0.08002152542273204, "compression_ratio": 1.7, "no_speech_prob": 0.0636913850903511}, {"id": 390, "seek": 158924, "start": 1598.8, "end": 1600.16, "text": " spiking mechanism.", "tokens": [50842, 637, 13085, 7513, 13, 50910], "temperature": 0.0, "avg_logprob": -0.08002152542273204, "compression_ratio": 1.7, "no_speech_prob": 0.0636913850903511}, {"id": 391, "seek": 158924, "start": 1600.16, "end": 1606.16, "text": " So in theory, maybe we could reach a superior level of intelligence compared to the current", "tokens": [50910, 407, 294, 5261, 11, 1310, 321, 727, 2524, 257, 13028, 1496, 295, 7599, 5347, 281, 264, 2190, 51210], "temperature": 0.0, "avg_logprob": -0.08002152542273204, "compression_ratio": 1.7, "no_speech_prob": 0.0636913850903511}, {"id": 392, "seek": 158924, "start": 1606.16, "end": 1610.24, "text": " generation of AI if we mimicked the human brain even more.", "tokens": [51210, 5125, 295, 7318, 498, 321, 12247, 12598, 264, 1952, 3567, 754, 544, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08002152542273204, "compression_ratio": 1.7, "no_speech_prob": 0.0636913850903511}, {"id": 393, "seek": 158924, "start": 1610.24, "end": 1614.6, "text": " But the biggest benefit of spiking neural networks is their efficiency.", "tokens": [51414, 583, 264, 3880, 5121, 295, 637, 13085, 18161, 9590, 307, 641, 10493, 13, 51632], "temperature": 0.0, "avg_logprob": -0.08002152542273204, "compression_ratio": 1.7, "no_speech_prob": 0.0636913850903511}, {"id": 394, "seek": 161460, "start": 1614.6, "end": 1619.6799999999998, "text": " If you remember at the beginning of the video, I compared the energy consumption of the human", "tokens": [50364, 759, 291, 1604, 412, 264, 2863, 295, 264, 960, 11, 286, 5347, 264, 2281, 12126, 295, 264, 1952, 50618], "temperature": 0.0, "avg_logprob": -0.08604667541828562, "compression_ratio": 1.6653386454183268, "no_speech_prob": 0.7656932473182678}, {"id": 395, "seek": 161460, "start": 1619.6799999999998, "end": 1626.1999999999998, "text": " brain versus a current state of the art model like GPT-4, which requires huge data centers", "tokens": [50618, 3567, 5717, 257, 2190, 1785, 295, 264, 1523, 2316, 411, 26039, 51, 12, 19, 11, 597, 7029, 2603, 1412, 10898, 50944], "temperature": 0.0, "avg_logprob": -0.08604667541828562, "compression_ratio": 1.6653386454183268, "no_speech_prob": 0.7656932473182678}, {"id": 396, "seek": 161460, "start": 1626.1999999999998, "end": 1628.1599999999999, "text": " and huge amounts of compute.", "tokens": [50944, 293, 2603, 11663, 295, 14722, 13, 51042], "temperature": 0.0, "avg_logprob": -0.08604667541828562, "compression_ratio": 1.6653386454183268, "no_speech_prob": 0.7656932473182678}, {"id": 397, "seek": 161460, "start": 1628.1599999999999, "end": 1632.1999999999998, "text": " That's because traditional neural networks are always active.", "tokens": [51042, 663, 311, 570, 5164, 18161, 9590, 366, 1009, 4967, 13, 51244], "temperature": 0.0, "avg_logprob": -0.08604667541828562, "compression_ratio": 1.6653386454183268, "no_speech_prob": 0.7656932473182678}, {"id": 398, "seek": 161460, "start": 1632.1999999999998, "end": 1636.6399999999999, "text": " Each input of data activates the entire neural network.", "tokens": [51244, 6947, 4846, 295, 1412, 43869, 264, 2302, 18161, 3209, 13, 51466], "temperature": 0.0, "avg_logprob": -0.08604667541828562, "compression_ratio": 1.6653386454183268, "no_speech_prob": 0.7656932473182678}, {"id": 399, "seek": 161460, "start": 1636.6399999999999, "end": 1642.6799999999998, "text": " So you have to do an insane amount of matrix multiplications across the entire network", "tokens": [51466, 407, 291, 362, 281, 360, 364, 10838, 2372, 295, 8141, 17596, 763, 2108, 264, 2302, 3209, 51768], "temperature": 0.0, "avg_logprob": -0.08604667541828562, "compression_ratio": 1.6653386454183268, "no_speech_prob": 0.7656932473182678}, {"id": 400, "seek": 164268, "start": 1642.76, "end": 1645.68, "text": " just to do one round of training or inference.", "tokens": [50368, 445, 281, 360, 472, 3098, 295, 3097, 420, 38253, 13, 50514], "temperature": 0.0, "avg_logprob": -0.13875049703261433, "compression_ratio": 1.7044534412955465, "no_speech_prob": 0.1402660608291626}, {"id": 401, "seek": 164268, "start": 1645.68, "end": 1651.0800000000002, "text": " However, for spiking neural networks, they only use energy where spikes occur, while", "tokens": [50514, 2908, 11, 337, 637, 13085, 18161, 9590, 11, 436, 787, 764, 2281, 689, 28997, 5160, 11, 1339, 50784], "temperature": 0.0, "avg_logprob": -0.13875049703261433, "compression_ratio": 1.7044534412955465, "no_speech_prob": 0.1402660608291626}, {"id": 402, "seek": 164268, "start": 1651.0800000000002, "end": 1654.24, "text": " the rest of the neural network remains inactive.", "tokens": [50784, 264, 1472, 295, 264, 18161, 3209, 7023, 294, 12596, 13, 50942], "temperature": 0.0, "avg_logprob": -0.13875049703261433, "compression_ratio": 1.7044534412955465, "no_speech_prob": 0.1402660608291626}, {"id": 403, "seek": 164268, "start": 1654.24, "end": 1657.04, "text": " This makes it a lot more energy efficient.", "tokens": [50942, 639, 1669, 309, 257, 688, 544, 2281, 7148, 13, 51082], "temperature": 0.0, "avg_logprob": -0.13875049703261433, "compression_ratio": 1.7044534412955465, "no_speech_prob": 0.1402660608291626}, {"id": 404, "seek": 164268, "start": 1657.04, "end": 1662.68, "text": " Plus, spiking neural networks are particularly suitable for neuromorphic chips which are", "tokens": [51082, 7721, 11, 637, 13085, 18161, 9590, 366, 4098, 12873, 337, 12087, 32702, 299, 11583, 597, 366, 51364], "temperature": 0.0, "avg_logprob": -0.13875049703261433, "compression_ratio": 1.7044534412955465, "no_speech_prob": 0.1402660608291626}, {"id": 405, "seek": 164268, "start": 1662.68, "end": 1665.4, "text": " designed to mimic the human brain.", "tokens": [51364, 4761, 281, 31075, 264, 1952, 3567, 13, 51500], "temperature": 0.0, "avg_logprob": -0.13875049703261433, "compression_ratio": 1.7044534412955465, "no_speech_prob": 0.1402660608291626}, {"id": 406, "seek": 164268, "start": 1665.4, "end": 1671.2, "text": " Now, neuromorphic chips are a huge topic and deserves its own full video.", "tokens": [51500, 823, 11, 12087, 32702, 299, 11583, 366, 257, 2603, 4829, 293, 17037, 1080, 1065, 1577, 960, 13, 51790], "temperature": 0.0, "avg_logprob": -0.13875049703261433, "compression_ratio": 1.7044534412955465, "no_speech_prob": 0.1402660608291626}, {"id": 407, "seek": 167120, "start": 1671.2, "end": 1675.44, "text": " So let me know in the comments if you'd like me to make a video on this as well.", "tokens": [50364, 407, 718, 385, 458, 294, 264, 3053, 498, 291, 1116, 411, 385, 281, 652, 257, 960, 322, 341, 382, 731, 13, 50576], "temperature": 0.0, "avg_logprob": -0.11726811657781186, "compression_ratio": 1.6752136752136753, "no_speech_prob": 0.11588029563426971}, {"id": 408, "seek": 167120, "start": 1675.44, "end": 1681.24, "text": " So how can these spiking neural networks actually be applied to the real world?", "tokens": [50576, 407, 577, 393, 613, 637, 13085, 18161, 9590, 767, 312, 6456, 281, 264, 957, 1002, 30, 50866], "temperature": 0.0, "avg_logprob": -0.11726811657781186, "compression_ratio": 1.6752136752136753, "no_speech_prob": 0.11588029563426971}, {"id": 409, "seek": 167120, "start": 1681.24, "end": 1688.0800000000002, "text": " Well, because these neural networks can encode and process information in the timing of spikes,", "tokens": [50866, 1042, 11, 570, 613, 18161, 9590, 393, 2058, 1429, 293, 1399, 1589, 294, 264, 10822, 295, 28997, 11, 51208], "temperature": 0.0, "avg_logprob": -0.11726811657781186, "compression_ratio": 1.6752136752136753, "no_speech_prob": 0.11588029563426971}, {"id": 410, "seek": 167120, "start": 1688.0800000000002, "end": 1691.32, "text": " this is great for processing temporal data.", "tokens": [51208, 341, 307, 869, 337, 9007, 30881, 1412, 13, 51370], "temperature": 0.0, "avg_logprob": -0.11726811657781186, "compression_ratio": 1.6752136752136753, "no_speech_prob": 0.11588029563426971}, {"id": 411, "seek": 167120, "start": 1691.32, "end": 1698.0, "text": " This makes them great for adaptive and autonomous systems, plus this spike timing-dependent", "tokens": [51370, 639, 1669, 552, 869, 337, 27912, 293, 23797, 3652, 11, 1804, 341, 21053, 10822, 12, 36763, 317, 51704], "temperature": 0.0, "avg_logprob": -0.11726811657781186, "compression_ratio": 1.6752136752136753, "no_speech_prob": 0.11588029563426971}, {"id": 412, "seek": 169800, "start": 1698.0, "end": 1703.88, "text": " plasticity, which I mentioned before, where the timing of the spikes influences the strength", "tokens": [50364, 5900, 507, 11, 597, 286, 2835, 949, 11, 689, 264, 10822, 295, 264, 28997, 21222, 264, 3800, 50658], "temperature": 0.0, "avg_logprob": -0.1048558098929269, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.0488465391099453}, {"id": 413, "seek": 169800, "start": 1703.88, "end": 1706.0, "text": " of the connections in the network.", "tokens": [50658, 295, 264, 9271, 294, 264, 3209, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1048558098929269, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.0488465391099453}, {"id": 414, "seek": 169800, "start": 1706.0, "end": 1709.84, "text": " This can lead to more robust and adaptive learning capability.", "tokens": [50764, 639, 393, 1477, 281, 544, 13956, 293, 27912, 2539, 13759, 13, 50956], "temperature": 0.0, "avg_logprob": -0.1048558098929269, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.0488465391099453}, {"id": 415, "seek": 169800, "start": 1709.84, "end": 1715.88, "text": " So this dynamic learning can make spiking neural networks suitable for autonomous systems", "tokens": [50956, 407, 341, 8546, 2539, 393, 652, 637, 13085, 18161, 9590, 12873, 337, 23797, 3652, 51258], "temperature": 0.0, "avg_logprob": -0.1048558098929269, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.0488465391099453}, {"id": 416, "seek": 169800, "start": 1715.88, "end": 1721.28, "text": " such as self-driving, where the AI has to learn and adapt to changing environments.", "tokens": [51258, 1270, 382, 2698, 12, 47094, 11, 689, 264, 7318, 575, 281, 1466, 293, 6231, 281, 4473, 12388, 13, 51528], "temperature": 0.0, "avg_logprob": -0.1048558098929269, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.0488465391099453}, {"id": 417, "seek": 169800, "start": 1721.28, "end": 1726.16, "text": " Or it can be used in real-time processing like predicting the stock market or patient", "tokens": [51528, 1610, 309, 393, 312, 1143, 294, 957, 12, 3766, 9007, 411, 32884, 264, 4127, 2142, 420, 4537, 51772], "temperature": 0.0, "avg_logprob": -0.1048558098929269, "compression_ratio": 1.6728624535315986, "no_speech_prob": 0.0488465391099453}, {"id": 418, "seek": 172616, "start": 1726.16, "end": 1730.5600000000002, "text": " monitoring and personalized medicine, and of course, autonomous robots.", "tokens": [50364, 11028, 293, 28415, 7195, 11, 293, 295, 1164, 11, 23797, 14733, 13, 50584], "temperature": 0.0, "avg_logprob": -0.17924972110324436, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.3699173331260681}, {"id": 419, "seek": 172616, "start": 1730.5600000000002, "end": 1736.16, "text": " Now, although spiking neural networks offer some huge benefits, especially regarding energy", "tokens": [50584, 823, 11, 4878, 637, 13085, 18161, 9590, 2626, 512, 2603, 5311, 11, 2318, 8595, 2281, 50864], "temperature": 0.0, "avg_logprob": -0.17924972110324436, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.3699173331260681}, {"id": 420, "seek": 172616, "start": 1736.16, "end": 1739.48, "text": " efficiency, they do have some limitations.", "tokens": [50864, 10493, 11, 436, 360, 362, 512, 15705, 13, 51030], "temperature": 0.0, "avg_logprob": -0.17924972110324436, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.3699173331260681}, {"id": 421, "seek": 172616, "start": 1739.48, "end": 1744.44, "text": " Setting up and programming spiking neural networks is more complicated compared to", "tokens": [51030, 21063, 493, 293, 9410, 637, 13085, 18161, 9590, 307, 544, 6179, 5347, 281, 51278], "temperature": 0.0, "avg_logprob": -0.17924972110324436, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.3699173331260681}, {"id": 422, "seek": 172616, "start": 1744.44, "end": 1746.0400000000002, "text": " traditional neural networks.", "tokens": [51278, 5164, 18161, 9590, 13, 51358], "temperature": 0.0, "avg_logprob": -0.17924972110324436, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.3699173331260681}, {"id": 423, "seek": 172616, "start": 1746.0400000000002, "end": 1751.6000000000001, "text": " This spiking behavior, of course, adds a layer of complexity, making them harder to design", "tokens": [51358, 639, 637, 13085, 5223, 11, 295, 1164, 11, 10860, 257, 4583, 295, 14024, 11, 1455, 552, 6081, 281, 1715, 51636], "temperature": 0.0, "avg_logprob": -0.17924972110324436, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.3699173331260681}, {"id": 424, "seek": 172616, "start": 1751.6000000000001, "end": 1753.24, "text": " and understand.", "tokens": [51636, 293, 1223, 13, 51718], "temperature": 0.0, "avg_logprob": -0.17924972110324436, "compression_ratio": 1.7206477732793521, "no_speech_prob": 0.3699173331260681}, {"id": 425, "seek": 175324, "start": 1753.24, "end": 1756.76, "text": " Studying spiking neural networks is also quite difficult.", "tokens": [50364, 4541, 1840, 637, 13085, 18161, 9590, 307, 611, 1596, 2252, 13, 50540], "temperature": 0.0, "avg_logprob": -0.14972411945302, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.2844117283821106}, {"id": 426, "seek": 175324, "start": 1756.76, "end": 1761.04, "text": " Current neural networks use methods like backpropagation to adjust their parameters,", "tokens": [50540, 15629, 18161, 9590, 764, 7150, 411, 646, 79, 1513, 559, 399, 281, 4369, 641, 9834, 11, 50754], "temperature": 0.0, "avg_logprob": -0.14972411945302, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.2844117283821106}, {"id": 427, "seek": 175324, "start": 1761.04, "end": 1766.36, "text": " but this process doesn't work well with these discrete time-based spikes.", "tokens": [50754, 457, 341, 1399, 1177, 380, 589, 731, 365, 613, 27706, 565, 12, 6032, 28997, 13, 51020], "temperature": 0.0, "avg_logprob": -0.14972411945302, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.2844117283821106}, {"id": 428, "seek": 175324, "start": 1766.36, "end": 1772.4, "text": " Researchers are still trying to find an effective training algorithm for spiking neural networks.", "tokens": [51020, 43555, 366, 920, 1382, 281, 915, 364, 4942, 3097, 9284, 337, 637, 13085, 18161, 9590, 13, 51322], "temperature": 0.0, "avg_logprob": -0.14972411945302, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.2844117283821106}, {"id": 429, "seek": 175324, "start": 1772.4, "end": 1777.24, "text": " Also given this additional dimension of time, spiking neural networks might actually require", "tokens": [51322, 2743, 2212, 341, 4497, 10139, 295, 565, 11, 637, 13085, 18161, 9590, 1062, 767, 3651, 51564], "temperature": 0.0, "avg_logprob": -0.14972411945302, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.2844117283821106}, {"id": 430, "seek": 175324, "start": 1777.24, "end": 1780.36, "text": " more computational resources to simulate.", "tokens": [51564, 544, 28270, 3593, 281, 27817, 13, 51720], "temperature": 0.0, "avg_logprob": -0.14972411945302, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.2844117283821106}, {"id": 431, "seek": 178036, "start": 1780.36, "end": 1786.08, "text": " This is because they need to track and process spikes over time, which can be computationally", "tokens": [50364, 639, 307, 570, 436, 643, 281, 2837, 293, 1399, 28997, 670, 565, 11, 597, 393, 312, 24903, 379, 50650], "temperature": 0.0, "avg_logprob": -0.13649393437982915, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.07805881649255753}, {"id": 432, "seek": 178036, "start": 1786.08, "end": 1787.08, "text": " expensive.", "tokens": [50650, 5124, 13, 50700], "temperature": 0.0, "avg_logprob": -0.13649393437982915, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.07805881649255753}, {"id": 433, "seek": 178036, "start": 1787.08, "end": 1793.6799999999998, "text": " Yet, another limitation is that running spiking neural networks efficiently often requires", "tokens": [50700, 10890, 11, 1071, 27432, 307, 300, 2614, 637, 13085, 18161, 9590, 19621, 2049, 7029, 51030], "temperature": 0.0, "avg_logprob": -0.13649393437982915, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.07805881649255753}, {"id": 434, "seek": 178036, "start": 1793.6799999999998, "end": 1800.04, "text": " specialized hardware such as neuromorphic chips, which are not widely available or standardized", "tokens": [51030, 19813, 8837, 1270, 382, 12087, 32702, 299, 11583, 11, 597, 366, 406, 13371, 2435, 420, 31677, 51348], "temperature": 0.0, "avg_logprob": -0.13649393437982915, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.07805881649255753}, {"id": 435, "seek": 178036, "start": 1800.04, "end": 1803.52, "text": " compared to conventional computing hardware.", "tokens": [51348, 5347, 281, 16011, 15866, 8837, 13, 51522], "temperature": 0.0, "avg_logprob": -0.13649393437982915, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.07805881649255753}, {"id": 436, "seek": 178036, "start": 1803.52, "end": 1808.1599999999999, "text": " Neuromorphic chips are optimized for this spike-based processing and are still being", "tokens": [51522, 1734, 374, 32702, 299, 11583, 366, 26941, 337, 341, 21053, 12, 6032, 9007, 293, 366, 920, 885, 51754], "temperature": 0.0, "avg_logprob": -0.13649393437982915, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.07805881649255753}, {"id": 437, "seek": 178036, "start": 1808.1599999999999, "end": 1809.1599999999999, "text": " developed.", "tokens": [51754, 4743, 13, 51804], "temperature": 0.0, "avg_logprob": -0.13649393437982915, "compression_ratio": 1.6809338521400778, "no_speech_prob": 0.07805881649255753}, {"id": 438, "seek": 180916, "start": 1809.16, "end": 1815.1000000000001, "text": " And that's why, for example, Sam Altman is investing millions of dollars into a neuromorphic", "tokens": [50364, 400, 300, 311, 983, 11, 337, 1365, 11, 4832, 15992, 1601, 307, 10978, 6803, 295, 3808, 666, 257, 12087, 32702, 299, 50661], "temperature": 0.0, "avg_logprob": -0.11445038894127155, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.008314711973071098}, {"id": 439, "seek": 180916, "start": 1815.1000000000001, "end": 1817.0800000000002, "text": " chip company called RAIN.", "tokens": [50661, 11409, 2237, 1219, 14626, 1464, 13, 50760], "temperature": 0.0, "avg_logprob": -0.11445038894127155, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.008314711973071098}, {"id": 440, "seek": 180916, "start": 1817.0800000000002, "end": 1822.3600000000001, "text": " Finally, while spiking neural networks show promising results, especially for time-based", "tokens": [50760, 6288, 11, 1339, 637, 13085, 18161, 9590, 855, 20257, 3542, 11, 2318, 337, 565, 12, 6032, 51024], "temperature": 0.0, "avg_logprob": -0.11445038894127155, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.008314711973071098}, {"id": 441, "seek": 180916, "start": 1822.3600000000001, "end": 1828.2, "text": " data, they often lag behind current neural networks for non-time-based data.", "tokens": [51024, 1412, 11, 436, 2049, 8953, 2261, 2190, 18161, 9590, 337, 2107, 12, 3766, 12, 6032, 1412, 13, 51316], "temperature": 0.0, "avg_logprob": -0.11445038894127155, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.008314711973071098}, {"id": 442, "seek": 180916, "start": 1828.2, "end": 1834.8400000000001, "text": " They often underperform compared with current AI models, particularly for complex tasks.", "tokens": [51316, 814, 2049, 833, 26765, 5347, 365, 2190, 7318, 5245, 11, 4098, 337, 3997, 9608, 13, 51648], "temperature": 0.0, "avg_logprob": -0.11445038894127155, "compression_ratio": 1.5738396624472575, "no_speech_prob": 0.008314711973071098}, {"id": 443, "seek": 183484, "start": 1834.84, "end": 1840.1599999999999, "text": " This is partly due to the challenges in training spiking neural networks effectively.", "tokens": [50364, 639, 307, 17031, 3462, 281, 264, 4759, 294, 3097, 637, 13085, 18161, 9590, 8659, 13, 50630], "temperature": 0.0, "avg_logprob": -0.08601260971237015, "compression_ratio": 1.749003984063745, "no_speech_prob": 0.6614159941673279}, {"id": 444, "seek": 183484, "start": 1840.1599999999999, "end": 1845.32, "text": " And as with liquid neural networks, spiking neural networks are also relatively new.", "tokens": [50630, 400, 382, 365, 6553, 18161, 9590, 11, 637, 13085, 18161, 9590, 366, 611, 7226, 777, 13, 50888], "temperature": 0.0, "avg_logprob": -0.08601260971237015, "compression_ratio": 1.749003984063745, "no_speech_prob": 0.6614159941673279}, {"id": 445, "seek": 183484, "start": 1845.32, "end": 1851.0, "text": " So there are fewer tools and frameworks available for developing spiking neural networks compared", "tokens": [50888, 407, 456, 366, 13366, 3873, 293, 29834, 2435, 337, 6416, 637, 13085, 18161, 9590, 5347, 51172], "temperature": 0.0, "avg_logprob": -0.08601260971237015, "compression_ratio": 1.749003984063745, "no_speech_prob": 0.6614159941673279}, {"id": 446, "seek": 183484, "start": 1851.0, "end": 1853.3999999999999, "text": " to current AI models.", "tokens": [51172, 281, 2190, 7318, 5245, 13, 51292], "temperature": 0.0, "avg_logprob": -0.08601260971237015, "compression_ratio": 1.749003984063745, "no_speech_prob": 0.6614159941673279}, {"id": 447, "seek": 183484, "start": 1853.3999999999999, "end": 1858.1599999999999, "text": " This makes experimentation and development slower and more difficult.", "tokens": [51292, 639, 1669, 37142, 293, 3250, 14009, 293, 544, 2252, 13, 51530], "temperature": 0.0, "avg_logprob": -0.08601260971237015, "compression_ratio": 1.749003984063745, "no_speech_prob": 0.6614159941673279}, {"id": 448, "seek": 183484, "start": 1858.1599999999999, "end": 1863.52, "text": " But anyways, that sums up what could potentially be the next generation of AI.", "tokens": [51530, 583, 13448, 11, 300, 34499, 493, 437, 727, 7263, 312, 264, 958, 5125, 295, 7318, 13, 51798], "temperature": 0.0, "avg_logprob": -0.08601260971237015, "compression_ratio": 1.749003984063745, "no_speech_prob": 0.6614159941673279}, {"id": 449, "seek": 186352, "start": 1863.52, "end": 1868.96, "text": " To bring it all back, the current generation of AI is very energy inefficient, requiring", "tokens": [50364, 1407, 1565, 309, 439, 646, 11, 264, 2190, 5125, 295, 7318, 307, 588, 2281, 43495, 11, 24165, 50636], "temperature": 0.0, "avg_logprob": -0.09608667746357534, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.46816569566726685}, {"id": 450, "seek": 186352, "start": 1868.96, "end": 1870.92, "text": " huge amounts of compute.", "tokens": [50636, 2603, 11663, 295, 14722, 13, 50734], "temperature": 0.0, "avg_logprob": -0.09608667746357534, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.46816569566726685}, {"id": 451, "seek": 186352, "start": 1870.92, "end": 1874.56, "text": " Plus, it can't learn new things after being trained.", "tokens": [50734, 7721, 11, 309, 393, 380, 1466, 777, 721, 934, 885, 8895, 13, 50916], "temperature": 0.0, "avg_logprob": -0.09608667746357534, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.46816569566726685}, {"id": 452, "seek": 186352, "start": 1874.56, "end": 1881.16, "text": " If we want to achieve AGI or ASI, we need to essentially create something as efficient", "tokens": [50916, 759, 321, 528, 281, 4584, 316, 26252, 420, 7469, 40, 11, 321, 643, 281, 4476, 1884, 746, 382, 7148, 51246], "temperature": 0.0, "avg_logprob": -0.09608667746357534, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.46816569566726685}, {"id": 453, "seek": 186352, "start": 1881.16, "end": 1886.72, "text": " and as fluid as the human brain, which can constantly learn new things and adapt to", "tokens": [51246, 293, 382, 9113, 382, 264, 1952, 3567, 11, 597, 393, 6460, 1466, 777, 721, 293, 6231, 281, 51524], "temperature": 0.0, "avg_logprob": -0.09608667746357534, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.46816569566726685}, {"id": 454, "seek": 186352, "start": 1886.72, "end": 1888.8, "text": " changing environments.", "tokens": [51524, 4473, 12388, 13, 51628], "temperature": 0.0, "avg_logprob": -0.09608667746357534, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.46816569566726685}, {"id": 455, "seek": 188880, "start": 1888.8, "end": 1893.52, "text": " These are the two essential things that new types of neural networks, such as liquid neural", "tokens": [50364, 1981, 366, 264, 732, 7115, 721, 300, 777, 3467, 295, 18161, 9590, 11, 1270, 382, 6553, 18161, 50600], "temperature": 0.0, "avg_logprob": -0.12572635982347571, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.7571830153465271}, {"id": 456, "seek": 188880, "start": 1893.52, "end": 1898.2, "text": " networks and spiking neural networks can solve, at least in theory.", "tokens": [50600, 9590, 293, 637, 13085, 18161, 9590, 393, 5039, 11, 412, 1935, 294, 5261, 13, 50834], "temperature": 0.0, "avg_logprob": -0.12572635982347571, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.7571830153465271}, {"id": 457, "seek": 188880, "start": 1898.2, "end": 1903.72, "text": " However, these are still relatively new and they are still being developed, but the potential", "tokens": [50834, 2908, 11, 613, 366, 920, 7226, 777, 293, 436, 366, 920, 885, 4743, 11, 457, 264, 3995, 51110], "temperature": 0.0, "avg_logprob": -0.12572635982347571, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.7571830153465271}, {"id": 458, "seek": 188880, "start": 1903.72, "end": 1905.48, "text": " could be massive.", "tokens": [51110, 727, 312, 5994, 13, 51198], "temperature": 0.0, "avg_logprob": -0.12572635982347571, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.7571830153465271}, {"id": 459, "seek": 188880, "start": 1905.48, "end": 1909.8799999999999, "text": " Imagine an AI that can keep learning and get infinitely smarter.", "tokens": [51198, 11739, 364, 7318, 300, 393, 1066, 2539, 293, 483, 36227, 20294, 13, 51418], "temperature": 0.0, "avg_logprob": -0.12572635982347571, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.7571830153465271}, {"id": 460, "seek": 188880, "start": 1909.8799999999999, "end": 1914.0, "text": " Let me know what you think about these neural networks in the comments below.", "tokens": [51418, 961, 385, 458, 437, 291, 519, 466, 613, 18161, 9590, 294, 264, 3053, 2507, 13, 51624], "temperature": 0.0, "avg_logprob": -0.12572635982347571, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.7571830153465271}, {"id": 461, "seek": 188880, "start": 1914.0, "end": 1918.1599999999999, "text": " Things are happening so fast in the world of AI, it's quite hard to keep up with all", "tokens": [51624, 9514, 366, 2737, 370, 2370, 294, 264, 1002, 295, 7318, 11, 309, 311, 1596, 1152, 281, 1066, 493, 365, 439, 51832], "temperature": 0.0, "avg_logprob": -0.12572635982347571, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.7571830153465271}, {"id": 462, "seek": 191816, "start": 1918.16, "end": 1921.28, "text": " the technological innovations that are happening right now.", "tokens": [50364, 264, 18439, 24283, 300, 366, 2737, 558, 586, 13, 50520], "temperature": 0.0, "avg_logprob": -0.1414676999288892, "compression_ratio": 1.6423841059602649, "no_speech_prob": 0.4409765899181366}, {"id": 463, "seek": 191816, "start": 1921.28, "end": 1926.0, "text": " So if I've missed any other groundbreaking architectures that are worth mentioning, please", "tokens": [50520, 407, 498, 286, 600, 6721, 604, 661, 42491, 6331, 1303, 300, 366, 3163, 18315, 11, 1767, 50756], "temperature": 0.0, "avg_logprob": -0.1414676999288892, "compression_ratio": 1.6423841059602649, "no_speech_prob": 0.4409765899181366}, {"id": 464, "seek": 191816, "start": 1926.0, "end": 1930.5600000000002, "text": " let me know in the comments below and I'll try to do a video on that as well.", "tokens": [50756, 718, 385, 458, 294, 264, 3053, 2507, 293, 286, 603, 853, 281, 360, 257, 960, 322, 300, 382, 731, 13, 50984], "temperature": 0.0, "avg_logprob": -0.1414676999288892, "compression_ratio": 1.6423841059602649, "no_speech_prob": 0.4409765899181366}, {"id": 465, "seek": 191816, "start": 1930.5600000000002, "end": 1935.52, "text": " As always, if you enjoyed this video, remember to like, share, subscribe and stay tuned for", "tokens": [50984, 1018, 1009, 11, 498, 291, 4626, 341, 960, 11, 1604, 281, 411, 11, 2073, 11, 3022, 293, 1754, 10870, 337, 51232], "temperature": 0.0, "avg_logprob": -0.1414676999288892, "compression_ratio": 1.6423841059602649, "no_speech_prob": 0.4409765899181366}, {"id": 466, "seek": 191816, "start": 1935.52, "end": 1937.16, "text": " more content.", "tokens": [51232, 544, 2701, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1414676999288892, "compression_ratio": 1.6423841059602649, "no_speech_prob": 0.4409765899181366}, {"id": 467, "seek": 191816, "start": 1937.16, "end": 1942.0, "text": " Also we built a site where you can find all the AI tools out there as well as find jobs", "tokens": [51314, 2743, 321, 3094, 257, 3621, 689, 291, 393, 915, 439, 264, 7318, 3873, 484, 456, 382, 731, 382, 915, 4782, 51556], "temperature": 0.0, "avg_logprob": -0.1414676999288892, "compression_ratio": 1.6423841059602649, "no_speech_prob": 0.4409765899181366}, {"id": 468, "seek": 191816, "start": 1942.0, "end": 1944.8400000000001, "text": " in machine learning, data science and more.", "tokens": [51556, 294, 3479, 2539, 11, 1412, 3497, 293, 544, 13, 51698], "temperature": 0.0, "avg_logprob": -0.1414676999288892, "compression_ratio": 1.6423841059602649, "no_speech_prob": 0.4409765899181366}, {"id": 469, "seek": 191816, "start": 1944.8400000000001, "end": 1947.72, "text": " Check it out at ai-search.io.", "tokens": [51698, 6881, 309, 484, 412, 9783, 12, 405, 1178, 13, 1004, 13, 51842], "temperature": 0.0, "avg_logprob": -0.1414676999288892, "compression_ratio": 1.6423841059602649, "no_speech_prob": 0.4409765899181366}, {"id": 470, "seek": 194772, "start": 1947.72, "end": 1950.32, "text": " Thanks for watching and I'll see you in the next one.", "tokens": [50366, 2561, 337, 1976, 293, 286, 603, 536, 291, 294, 264, 958, 472, 13, 50494], "temperature": 0.0, "avg_logprob": -0.23590686917304993, "compression_ratio": 0.8688524590163934, "no_speech_prob": 0.3483802080154419}], "language": "en"}