start	end	text
0	4600	It seemed to me that a huge revolution was going on.
4600	5760	Now it's changed.
5760	8240	I am optimistic, but I'm also worried about it.
11240	15760	I've been in the field of AI for 60 years.
15760	17240	I was 14.
17240	20400	I met Marvin Minsky who was in his 30s.
20400	22400	Frank Rosenblatt created the Perceptron,
22400	24040	the first popular neural net.
24040	26160	But in the early years, it was really not clear
26160	28280	that neural nets could do anything successful.
28320	30840	And they're showing now that this is really the path
30840	32800	to artificial general intelligence.
32800	34960	It's not just us versus AI.
34960	37120	The intelligence that we're creating
37120	39440	is adding AI to our own brains.
39440	43480	2045 is when I said we will actually multiply
43480	46400	our intelligence millions fold.
46400	48160	And that's going to be true of everybody.
48160	51640	And we'll be able to get rid of terrible lives that we see
51640	54680	through poverty and lack of access to information.
55680	56680	Great.
56680	57680	Good morning.
57680	58680	Good morning to you.
58680	60680	It's great to be with you, Peter.
60680	62680	And also Salim.
62680	64680	I've done lots of presentations with Peter.
64680	69680	It's really remarkable what you've contributed.
69680	74680	So I just want to share a few ideas.
74680	78680	I've been following large language models
78680	80680	for almost three years.
80680	84680	There was Lambda, now barred from Google,
84680	87680	different GPT versions from OpenAI.
87680	92680	It seemed to me that a huge revolution was going on.
92680	93680	Now it's changed.
93680	97680	OpenAI changed GPT-3 to chat GPT.
97680	100680	It was the fastest growing app, I believe, in history
100680	102680	with over 100 million users within the first two months
102680	104680	of its launch.
104680	107680	And lots of other companies, particularly Google,
107680	110680	are introducing Google Just Introduce Barred,
110680	112680	I think, a few days ago.
112680	117680	OpenAI has also introduced GPT-4.
117680	120680	Without going into comparison with these LLMs,
120680	122680	because it changes like every day,
122680	125680	I can write things in one style and ask
125680	129680	it to re-articulate it in the style of Shakespeare,
129680	133680	E.E. Cummings, any other poet or writer.
134680	137680	The results are amazingly impressive.
137680	141680	In my opinion, this is not just another category of AI.
141680	146680	To me, it's as significant as the advent of written language,
146680	149680	which started with cuneiform 5,000 years ago.
149680	152680	You remember using cuneiform 5,000 years ago.
152680	156680	Homo sapiens evolved in Africa 300,000 years ago.
156680	159680	So for most of that history, we had no ways
160680	163680	of documenting our language.
163680	168680	In the past century, we've added to written language.
168680	171680	We've added word processes and other means to help us.
171680	174680	But this latest breakthrough allows us to creatively
174680	177680	create written language based on the LLMs'
177680	179680	own understanding.
179680	183680	It's going to go in all directions and at a very high speed.
183680	185680	I mean, just look at it in the last two years.
185680	187680	It's been unbelievable.
187680	189680	It's going to change everything we do.
189680	191680	You can write code perfectly.
191680	196680	You can convert code into human terms, deal with all languages,
196680	200680	different styles of communicating, and so on.
200680	203680	It's been already very extensively used to create answers
203680	205680	for subtle questions.
205680	211680	So I actually took a couple of the top LLMs,
211680	213680	and I asked the various questions like,
213680	216680	how do my views of consciousness relate to those
216680	219680	of Marvin Ninsky, and how do they compare?
219680	222680	Now, that's kind of a subtle question.
222680	225680	I'm not sure I've actually ever read anything
225680	228680	that answered that question.
228680	232680	I asked LLMs from Google and from OpenAI.
232680	235680	The answers were really quite remarkably subtle,
235680	240680	very well stated, and they were not copied from anywhere else.
240680	244680	Now, many people are concerned that large language models
244680	248680	may promote ideas that are not socially appropriate,
248680	252680	that engender racism or sexism and so on.
252680	256680	It's definitely very worthwhile for us to study this
256680	258680	that may happen from time to time,
258680	262680	but I've actually used LLMs probably close to a thousand times.
262680	265680	I've actually not seen anything that could be categorized that way.
265680	267680	Maybe it's the way I asked the question.
267680	269680	It also seems pretty accurate.
269680	272680	The only mistake it made is that I thought my son,
272680	274680	Ethan, went to Harvard as an undergraduate.
274680	276680	He actually went there for an MBA.
276680	280680	I've written a new book, which I've talked about for years.
280680	283680	The Singularity is Nearer.
283680	285680	It should be out in about a year.
285680	288680	I keep writing because literally every week that we can't come
288680	291680	out with this without covering this,
291680	293680	but that's been happening now every few days.
293680	295680	So I finally had to give up on that.
295680	298680	By the time it comes out, it'll be out of date,
298680	300680	but it's not just covering today.
300680	302680	It's covering what's how we got here
302680	305680	and what will happen in the near future.
305680	311680	Critics of AI very often show how large language models
311680	313680	may not be perfect.
313680	315680	There was one recently said,
315680	320680	well, it can't, if you put mathematics inside language,
320680	321680	it doesn't do that correctly.
321680	323680	But now within a year of saying that,
323680	325680	that's no longer true.
325680	331680	So one of my themes, and this is also true of Peter and Salim,
331680	333680	has been the acceleration of progress
333680	335680	in information technology,
335680	338680	but also everything that we work on.
338680	340680	So here's a chart.
340680	342680	I actually came out with this.
342680	348680	For each year, the best computer that provided
348680	351680	the amount of computations per second.
351680	354680	And it's pretty much a very straight line
354680	357680	on an exponential growth.
357680	360680	And people were not even aware of this.
360680	363680	I mean, I came out with this graph 40 years ago.
363680	367680	It's 40 years after the progress of the computer.
367680	370680	I mean, I came out with this graph 40 years ago.
370680	373680	It's 40 years after the progression started.
373680	376680	And I've been updating it ever since.
376680	379680	People very often call this Moore's Law.
379680	382680	I really believe we shouldn't do that anymore
382680	384680	because there's nothing to do with Moore's.
384680	387680	I mean, this started decades before Intel was even created.
387680	390680	It's been going on for 40 years before anyone even
390680	392680	knew it was happening.
392680	394680	If you go to the bottom left,
394680	400680	the first programmable computer was the ZUSA 1, 1941.
400680	409680	It performed 0.0007 calculations per second per dollar.
409680	411680	ZUSA was a German.
411680	415680	It was not a fan of Hitler, but it was shown to Hitler.
415680	418680	And some people were excited about getting behind this,
418680	420680	but they didn't get behind it.
420680	423680	They saw no military value to computation.
423680	427680	A big mistake for them, among a lot of other mistakes.
427680	430680	The third computer on here is the Colossus,
430680	433680	created by Alan Turing and his colleagues.
433680	437680	Now, Winston Churchill felt that this computer would be the key
437680	440680	to winning World War II, and that was true.
440680	443680	They got totally behind the Colossus computer,
443680	447680	and they used it to completely decode Nazi messages.
447680	451680	So everything that Hitler knew, Churchill also knew.
451680	455680	And so even though the Nazi air power was actually several times
455680	459680	that of the British, they used the Colossus to win the battle
459680	463680	of Britain anyway with this computer and provide the allies
463680	466680	with a launching pad for its D&A invasion.
466680	469680	So if you go along this chart, there are many stories
469680	472680	behind all the computers on this chart.
472680	475680	It almost looks like someone was behind this exponential trend,
475680	477680	like someone's following it.
477680	479680	Okay, we're at this point now.
479680	481680	We're here for the next year.
481680	485680	But for the first 40 years, no one even knew this was happening.
485680	487680	It just happened.
487680	490680	That's the nature of exponential growth.
490680	492680	And this is just one example of exponential growth.
492680	495680	It's not that everything comes from this graph.
495680	497680	This graph just shows you one example
497680	501680	of how technology expands exponentially.
501680	506680	And whether we're aware of it or not.
506680	509680	So exponential growth impacts everything around us,
509680	512680	including everything that we create.
512680	520680	And I projected that this would continue in the same direction
520680	522680	that I noticed 40 years ago.
522680	525680	And as you can see, it's done that.
525680	531680	It's gone from telephone relays to vacuum tubes to transistors
531680	533680	to integrated circuits.
533680	536680	As I mentioned, people have called this Moore's Law,
536680	538680	but as I say, that's not correct.
538680	541680	It started decades before Intel was even formed.
541680	546680	Of the 80 best computers in terms of computations per second per dollar,
546680	551680	only 10 of these out of 80 have anything to do with Intel.
551680	556680	Now, every five years, people were going around saying Moore's Law is over.
556680	560680	You might remember that this started when the COVID pandemic started
560680	563680	just a few years ago, people were saying Moore's Law is over.
563680	566680	And of course, I went around saying that it should not be called Moore's Law,
566680	571680	but regardless of that, whether Intel chips were the best value or not,
571680	576680	this exponential progression has never stopped.
576680	580680	Not for World War II, not for recessions, not for depressions,
580680	582680	or for any other reason.
582680	588680	It's gone for 80 years from .0007 calculations per second per dollar
588680	592680	to now .50 billion calculations per second per dollar.
592680	596680	So you're getting a lot more for the same amount of money.
596680	601680	And it's only in the last three years that large language models have been feasible.
601680	604680	So people believe that neural nets were effective decades ago,
604680	609680	did so really based on their inclination, not any evidence.
609680	614680	I've been in the field of AI for 60 years.
614680	618680	It's quite amazing, like where does the time go?
618680	620680	I was 14.
620680	623680	I met Marvin Minsky who was in his 30s.
623680	628680	Frank Rosenblatt created the Perceptron, the first popular neural net.
628680	637680	As far as I'm aware, I don't think anyone else has 60 years experience or more in AI as I've had.
637680	640680	But if you've been there for more than that, let me know.
640680	643680	I have a lot of stories about that.
643680	648680	But in the early years, it was really not clear that neural nets could do anything successful.
648680	653680	And they're showing now that this is really the path to artificial general intelligence.
653680	659680	We will have large language models that can understand lots of different types of written language,
659680	663680	from formal research articles to jokes and so on.
663680	667680	They're now mastering mathematics within the language.
667680	672680	They can code and do so perfectly and at very high speed.
672680	679680	Now, this obviously brings up, not just that, but all the things it can do brings up concerns about its effect on human employment,
679680	682680	which we were just talking about.
682680	687680	But employment is really not necessarily the best way to bring resources to human.
687680	689680	I mean, look at around the world.
689680	696680	France is now dealing with protests because they're adding a couple of years before people can access their retirement.
696680	700680	It tells me that people really don't like the jobs they do for employment.
700680	702680	So that's, I think, a difference.
702680	706680	We'll actually be able to do what we are really cut out to do.
706680	712680	And in my opinion, it's not just us versus AI and people say, well, how are we going to compete with AI?
712680	720680	The intelligence that we're creating is adding AI to our own brains, just the way our phones and computers do already.
720680	724680	This is not an alien invasion of intelligent machines coming from Mars.
724680	730680	I mean, how many people here have come to this meeting without your phone?
730680	732680	It's already part of our intelligence.
732680	734680	We can't leave home without it.
734680	740680	It ultimately will be automatically added to our intelligence and it already is.
740680	746680	I'll add one more AI topic and I'm sure we'll get into a lot more doing the questions and answers.
746680	751680	But something else that's also extremely exciting, which is simulated biology.
751680	753680	This has already started.
753680	764680	The Moderna vaccine was created by feeding in every possible combination of mRNA sequences and simulating in the computer what would happen.
764680	771680	They tried several billion of such sequences and they went through them all and seeing what the impact would be.
771680	775680	It took two days to process all several billion of them.
775680	777680	And then they had the vaccine.
777680	779680	It actually took two days to create.
779680	783680	It's been the most successful COVID vaccine.
783680	785680	And we did test it with humans.
785680	787680	We're going to get over that as well.
787680	792680	We're ultimately going to be used biological simulation of humans to replace human testing.
792680	800680	I mean, rather than spending a year or several years testing results on a few hundred subjects, none of which probably match you.
800680	807680	We will test it on a million or more humans simulated humans in just a few days.
807680	818680	So to cure cancer, for example, we'll simply feed in every possible method that can detect cancer cells from normal cells and destroy them or do anything that would help us.
818680	819680	And we won't evaluate them.
819680	824680	We'll just feed in all the ideas we have about each of these possibilities into the computer.
824680	835680	The computer will evaluate all of the many billions of sequences and provide the results will then test the final product with simulated humans also very quickly.
835680	838680	And we'll do this for every major health predicament.
838680	842680	It will be done a thousand times faster than conventional methods.
842680	851680	And based on our ability to do this, we should be able to overcome most significant health problems by 2029.
851680	855680	That's by the way, my prediction for passing the Turing test.
855680	857680	I came out with that in 1999.
857680	861680	People thought that was crazy that Stanford had a conference.
861680	866680	Actually, 80% of the people came didn't think we would do it, but they thought it would take 100 years.
866680	870680	They keep polling people.
870680	878680	And now everybody actually thinks that we will actually pass the Turing test by 2029.
878680	883680	And actually to pass the Turing test, meaning it's equivalent to humans, we're actually going to have to dumb them down.
883680	889680	Because if it does everything that a computer can do, we'll know it's not a human.
889680	901680	But this will lead people who are diligent about their health to overcome many problems, reaching what I call longevity escape velocity by the end of this decade.
901680	903680	Now, this doesn't guarantee living forever.
903680	910680	I mean, you can have a 10 year old and you can compute their life expectancy, whatever, many, many decades, and they could die tomorrow.
910680	913680	So it's not a guarantee for living forever.
913680	918680	But the biggest problem we have is aging and people actually die from aging.
918680	922680	I actually had an aunt who's 97. She was a psychologist.
922680	928680	And she actually was still meeting with her patients at 97.
928680	931680	And the last conversation I had with her, she's saying, well, what do you do?
931680	934680	And I said, well, I give lots of speeches and what do you talk about?
934680	936680	And I said, longevity escape velocity.
936680	937680	Oh, what's that?
937680	938680	And I described it.
938680	947680	And the very last thing she said to me, this longevity escape velocity, could we do that a little faster than you're doing it now?
948680	953680	So anyway, I look forward to your questions and comments.
953680	955680	And it's really delightful to be here.
955680	956680	Thank you, Ray.
956680	957680	All right.
960680	964680	I'm going to take privilege and ask the first question. Ray, we've seen LLMs.
964680	971680	What's the next major breakthrough that you expect to see on the road of evolution of AI?
971680	976680	Well, LLMs, I mean, they do remarkable things.
976680	978680	But it's really just the beginning.
978680	983680	I mean, the very first time I saw an LLM was three years ago, and it actually didn't work very well.
983680	986680	Every six months, it's completely revolutionary.
986680	991680	So it's going to give us new ways of communicating with each other.
991680	998680	And as I said, I think it's the biggest advance since written language, which happened 5,000 years ago.
999680	1006680	I mentioned advancing longevity escape velocity, doing simulated biology.
1006680	1007680	We've actually done that.
1007680	1011680	People are taking this test, which was done with simulated biology.
1011680	1013680	Lots of people are going into this.
1013680	1017680	It's a way biology is going to be done.
1017680	1024680	And we're going to see amazing progress starting, really, I'd say, in a few years.
1025680	1027680	It's going to do everything that we do.
1027680	1030680	But as I said, it's not competing with us.
1030680	1033680	I mean, we're creating these tools to overcome ourselves.
1033680	1039680	And I mean, how many people today have a job that was common 100 years ago?
1039680	1043680	I mean, 200 years ago, 80% of the American public were working in farming.
1043680	1045680	Today, that's 2%.
1045680	1050680	So we're all doing things that didn't even exist even 10 years ago.
1050680	1054680	So we're going to be doing amazing things, harnessing our computers.
1054680	1057680	They're really part of ourselves.
1057680	1058680	Great.
1058680	1059680	Harry.
1059680	1060680	Hey, Ray.
1060680	1061680	Good to see you.
1061680	1068680	So Ray and I have been collaborating for actually probably 20 years on something else,
1068680	1072680	not natural language programming, but humanoid robots.
1072680	1075680	Ray, I wanted to get your opinion.
1075680	1082680	So at Beyond Managed Nation, we're creating AI powered robots called Beomni.
1082680	1089680	And we have a lot of discussions about AI for natural language, for images.
1089680	1096680	Where do you see AI and humanoid robots going in the future to impact physical work?
1096680	1097680	Yes.
1097680	1099680	That's a very good comment.
1099680	1102680	I'd be very pleased to hear of your amazing progress.
1102680	1109680	I mean, you have a robot that can actually take something and actually flip a cap off
1109680	1110680	a jar.
1110680	1114680	No one else can do that.
1114680	1118680	We've not made as much progress in this area.
1118680	1123680	We can do fantastic things with language, but if I give you a table that has where you
1123680	1129680	need to put it in the dishwasher and now went to wash out dishes and so on, we have not
1129680	1131680	been able to do that.
1131680	1133680	You're actually working on that.
1133680	1137680	And I think that's going to be amazing with these types of robots.
1137680	1140680	You could send someone into a burning building and save people.
1140680	1147680	You could have a surgeon in New York perform surgery on somebody in Africa.
1147680	1151680	So we're going to actually master the human body and how we move.
1151680	1155680	And we're going to be using neural nets to do that.
1155680	1160680	And I think that's another thing we're going to see really starting now.
1160680	1163680	And it will be quite prevalent within a few years.
1163680	1167680	Over the years, I've experimented with many intermittent fasting programs.
1167680	1173680	The truth is I've given up on intermittent fasting as I've seen no real benefit when
1173680	1174680	it comes to longevity.
1174680	1180680	But this changed when I discovered something called Prolon's five day fasting nutrition
1180680	1181680	program.
1181680	1183680	It harnesses the process of autophagy.
1183680	1188680	This is a cellular recycling process that revitalizes your body at a molecular level.
1188680	1194680	And just one cycle of the five day Prolon fasting nutrition program can support healthy
1194680	1198680	aging, fat focused weight loss, improved energy levels and more.
1198680	1199680	It's a painless process.
1199680	1202680	And I've been doing it twice a year for the last year.
1202680	1207680	You can get a 15% off on your order when you go to my special URL.
1207680	1215680	Go to prolonlife.com, backslash moonshot.
1215680	1219680	Get started on your longevity journey with Prolon today.
1219680	1221680	Now back to the episode.
1245680	1248680	What are some of the things you want to do to grow with AI?
1248680	1253680	Well, yes, I mean, we're going to be using these types of capabilities to learn.
1253680	1259680	One of the biggest applications of LLM is to help education.
1259680	1266680	In many ways, we're educating people the same way when I was a child or my grandparents
1266680	1267680	were children.
1267680	1270680	We really need to go beyond that.
1270680	1272680	We can learn from computers.
1272680	1273680	They know everything.
1273680	1276680	They can become very good at articulating it.
1276680	1283680	They can actually measure where a student is and help them to learn, overcome their
1283680	1284680	barriers.
1284680	1287680	And they're going to be then part of the solution.
1287680	1290680	Again, these computers is not something we need to compete with.
1290680	1294680	We need to know how to use them together.
1294680	1304680	And another big application of education is socialization, getting to learn other people
1304680	1305680	and make friends and so on.
1305680	1308680	So we're going to have to actually do that as well.
1308680	1310680	Computers can definitely help there.
1310680	1319680	But we're going to completely use large language models that are coming out very soon to really
1319680	1322680	revamp education.
1322680	1325680	Thank you.
1325680	1327680	Good morning, Ray.
1327680	1329680	I'm Yi Xiang Liu.
1329680	1331680	I'm from Texas.
1331680	1335680	Very much looking forward to meeting you today.
1335680	1337680	Thank you, Peter, for having me here.
1337680	1344680	My question to you is how do you predict the future with such accuracy?
1344680	1349680	Is it because you help to shape it and then deliver it?
1349680	1356680	Or you calculate the laws that other people don't, and then you can predict it?
1356680	1359680	So which one is actively shaping it?
1359680	1361680	Which part is missing?
1361680	1364680	That's a very good question.
1364680	1370680	I'll give you a very brief idea of how I got into what I'm doing.
1370680	1377680	My great grandmother actually started the first school that educated women to 14th grade.
1378680	1386680	In 1850, if you were able to get an education at all as a woman, it went through ninth grade.
1386680	1391680	And she went around Europe educating why we should educate women.
1391680	1393680	It's very controversial.
1393680	1395680	Why do you want to do that?
1395680	1401680	Her daughter became actually the first woman to get a PhD in chemistry in Europe.
1401680	1403680	She took over the school.
1403680	1406680	They ran it for 80 years called Sternschule in Vienna.
1406680	1409680	There's a book about it.
1409680	1411680	And she wrote a book.
1411680	1414680	Actually, the title of it would be very appropriate for one of my books.
1414680	1417680	It's called One Life is Not Enough.
1417680	1420680	But she wasn't actually talking about extending life.
1420680	1422680	She didn't have that idea.
1422680	1428680	But she noticed that one life really is enough to get things done.
1428680	1432680	So she showed me when I was six years old, she showed me the book.
1432680	1436680	And she showed me the manual typewriter that she created it on.
1436680	1439680	I got very interested in the book many years later.
1439680	1441680	At that time, I wasn't that interested in the book.
1441680	1445680	But I was amazingly interested in the manual typewriter.
1445680	1447680	I mean, here's a machine that had no electronics.
1447680	1449680	There's manual typewriter.
1449680	1454680	And it could take a blank piece of paper and turn it into something that looked like it came from a book.
1454680	1456680	So I actually wrote a book on it.
1456680	1458680	It was 23 pages.
1458680	1463680	It's about a guy that travels on the back of geese around the world and wrote it on the book
1463680	1469680	and actually created pictures by using the dot and X keys to create images.
1469680	1474680	So I then began, I noticed this was just created with mechanical objects.
1474680	1479680	So I ran around the neighborhood and I gathered mechanical objects.
1479680	1482680	Little things from radios, broken bicycles.
1482680	1487680	This was an era where you were allowed a 60-year-old kid to go around the neighborhood and collect these things.
1487680	1490680	You'd probably get arrested today.
1490680	1494680	And I went around saying, I have no idea how to put these things together.
1494680	1498680	But someday I'm going to figure that out and I'm going to be able to solve any problem.
1498680	1500680	Be able to go to other places.
1500680	1503680	We'll be able to live forever and so on.
1503680	1506680	I remember actually talking to these very old girls.
1506680	1510680	I think they were 10 and they were quite fascinated.
1510680	1514680	And they said, well, you have quite an imagination there.
1514680	1518680	So other people were saying what they wanted to be.
1518680	1521680	Fighting fires or educating people.
1521680	1523680	I said, I know what I'm going to be.
1523680	1525680	I'm going to be an inventor.
1525680	1534680	And starting at eight actually created a virtual reality theater that was a big hit in my third grade class.
1534680	1538680	So I got into inventing.
1538680	1543680	And the biggest problem was when do you approach a certain problem?
1543680	1547680	Like I did character recognition in the 70s.
1547680	1549680	I did speech recognition in the 80s.
1549680	1551680	Why did I do it that way?
1551680	1557680	It's because speech recognition requires actually more computation.
1557680	1561680	So I began to study how technology evolves.
1561680	1567680	And really about 40 years ago I realized that computers were on this exponential rise.
1567680	1574680	And so I didn't get into futures for futures itself.
1574680	1578680	It was really to plan my own projects and what I would get involved in.
1578680	1590680	And so if I look forward five years, 10 years, we're now actually at a very fast pace of this exponential path as you can see.
1590680	1594680	I'll see what are the capabilities going to be.
1594680	1597680	And then you needed to use a little bit of imagination.
1597680	1604680	What can we do with the computers of this power and other types of things that we can manage?
1604680	1609680	But that's really been my plan is to figure out what is capable.
1609680	1611680	And you saw that chart.
1611680	1613680	It's an absolutely straight line.
1613680	1618680	I had it 40 years ago and projected it as a straight line and it's exactly where it should be.
1618680	1624680	And then you can use imagination as to what you can do with that type of power.
1624680	1626680	So that's how I go.
1626680	1629680	Ray, just to point out, it's a straight line on a log scale.
1629680	1632680	Meaning it's going exponentially, yes.
1632680	1634680	Exactly.
1634680	1636680	Thank you.
1636680	1637680	Mike.
1637680	1639680	Hi, great to meet you, Ray.
1639680	1641680	Quick question.
1641680	1646680	When do you think that quantum computing will break RSA encryption?
1646680	1651680	Well, a little bit skeptical of quantum computing.
1651680	1656680	I mean, people go around saying, oh, we've got this 50 qubit computers.
1656680	1659680	But it creates lots of errors.
1659680	1665680	And we've actually figured out how many qubits you would need to actually do it perfectly.
1665680	1671680	I mean, computation that creates lots of errors is pretty useless.
1671680	1680680	And so it takes about at least a thousand, maybe even 10,000 qubits to create one qubit that's actually accurate.
1680680	1686680	Now, the last time I checked, 50 divided by a thousand is less than one.
1686680	1689680	And we really haven't done anything with quantum computing.
1689680	1691680	And that was the same thing 10 years ago.
1691680	1694680	So maybe we'll figure out how to overcome this problem.
1694680	1696680	I know there are people working on it.
1696680	1699680	They've got some theories as to why that will work.
1699680	1705680	But all the predictions I make have to do with classical computing, not quantum computing.
1705680	1708680	And you can see the amazing things that we're doing.
1708680	1715680	And if you look at what humans can do, we can definitely account for that with classical computing.
1715680	1719680	Thanks.
1719680	1720680	Hello, Ray.
1720680	1722680	My name is Neil from Sacramento, California.
1722680	1731680	Many of the technologies that we're seeing are going to be more readily available to people with the financial resources and the education to immediately take advantage of.
1731680	1739680	But what do you believe are the technologies that will be most ubiquitous and will have the biggest impact perhaps on the middle class and the working class communities?
1739680	1747680	And how would we best educate our broader communities to be able to understand and help embrace those technologies?
1747680	1749680	Well, they're all working together.
1749680	1755680	I think we need a little bit more work, for example, on virtual reality.
1755680	1768680	But that allows people to go anywhere and interact with people that don't exist now but might have existed tens of millions of years ago.
1768680	1771680	And also put people together.
1772680	1776680	I mean, the virtual reality we're using right now is a little bit limited.
1776680	1783680	There's actually some new 3D forms that I've actually begun to use where it actually appears like I'm there and can actually shake people's hands and so on.
1783680	1786680	So that's all coming.
1786680	1794680	We use computers and this type of technology to bring us closer together.
1794680	1798680	I mean, I just watched the movie Around the World in 80 Days.
1798680	1802680	It was quite amazing to actually get around the world in 80 days.
1802680	1811680	But today you can meet people almost instantly and also really be great to actually be able to hug each of you and so on.
1811680	1813680	That's all coming.
1813680	1821680	So increasing communication and also to meet my grandmother's view of one life is not enough.
1821680	1823680	She does not have an answer to that.
1823680	1827680	But I think we're going to be able to keep ourselves here.
1827680	1835680	I mean, when people are around for a while, they actually gain some wisdom and they're good to keep us around for a while longer.
1835680	1837680	Thank you, Ray.
1837680	1838680	Mike.
1838680	1839680	Hello, Ray.
1839680	1841680	Mike Wandler from Wyoming.
1841680	1845680	Peter was showing us the AI enabled mind reading.
1845680	1852680	Really curious about how that works and especially the connection to collective consciousness or consciousness.
1852680	1862680	So Ray, this is recently they put some subjects in a functional MRI and then fed the output to stable diffusion.
1862680	1866680	I've actually done that.
1866680	1869680	This was maybe five years ago.
1869680	1874680	It wasn't perfect, but it was significant.
1875680	1885680	I mean, things that go on inside our minds actually, it affects things that we don't usually notice like our eye blinking and so on.
1885680	1889680	And regaining more ability to do that.
1889680	1899680	We can do pretty good telling if people are telling the truth or not.
1899680	1901680	So that's going to happen.
1901680	1905680	And there are ways in which some of these things are positive and negative.
1905680	1907680	I mean, I write mostly about the positive.
1907680	1912680	I think things are moving in a positive direction in this new book.
1912680	1920680	I've got 50 graphs showing all the things we care about are moving in the right direction.
1920680	1922680	But that never reaches the news.
1922680	1925680	You watch the news, everything is bad news.
1925680	1929680	And the bad news is true, but we completely ignore the good news.
1929680	1934680	I mean, look at what life was like 50 years ago or 1900.
1934680	1936680	Human life expectancy was 48.
1936680	1939680	It was 35 and 1800.
1939680	1942680	It's not that long ago.
1942680	1954680	So anyway, we are able to begin to tell what's going on inside our minds with some greater accuracy.
1954680	1958680	Hi, Ray Sadoq Cohen from Istanbul, Turkey.
1958680	1966680	It looks like LLMs are, with the aid of some expert systems, the way to go to general intelligence.
1966680	1972680	Do you think that means that's a hint of how the brain or our brain really works?
1972680	1976680	And if that's the case, does it mean that the more we understand the LLM models,
1976680	1979680	the more we understand our brain and be able to hack it?
1979680	1984680	And is that a hint that we are more deterministic than we thought we were?
1984680	1986680	Well, it's a very good question.
1986680	1989680	It uses a somewhat different technique.
1989680	1998680	Neural nets, every phase, it's able to get itself closer to the truth.
1998680	2001680	We don't actually see anything in our brain that actually does it.
2001680	2003680	It does it a different way.
2003680	2006680	But somehow we have all these different connections.
2007680	2010680	And the large language models that are effective,
2010680	2016680	I mean, we actually had large language models that had 100 million connections.
2016680	2019680	That sounds like a lot, but it actually didn't do very much.
2019680	2024680	When I got to 10 billion and started to do things,
2024680	2031680	the recent ones started now at 100 billion, going to a trillion connections.
2031680	2036680	And it basically is able to look at all the different connections between them.
2036680	2039680	And that's exactly what our brain does.
2039680	2042680	And these things are going to go way beyond what our brain does.
2042680	2044680	We see that already.
2044680	2046680	I mean, I can play Go.
2046680	2049680	I'm hardly the best player.
2049680	2054680	But Lisa Dahl, who is the best human player,
2054680	2057680	and that used to be significant because he could just look at the board
2057680	2060680	and be able to do something that no one else could do.
2060680	2064680	And he says he's not going to play Go anymore because he can't compete with a computer.
2064680	2067680	In my view, though, we're going to add this to ourselves,
2067680	2074680	and we'll all become master Go players of Go and everything else that we want.
2074680	2080680	But yes, it's using the same ability to connect things.
2080680	2085680	And if you get enough of them, it seems to be basically a trillion seems to be,
2085680	2088680	you know, way beyond what humans can do.
2088680	2091680	We can be very intelligent.
2091680	2095680	Thank you.
2095680	2096680	Hi, Ray.
2096680	2098680	I'm Annie Chahal-Honen.
2098680	2100680	It's nice to see you again.
2100680	2105680	I had the pleasure of seeing you at an A360 Singularity Executive Program.
2105680	2108680	And I'm going to ask you the same question I asked then
2108680	2112680	because I hope that all these amazing innovators out there are going to hear this.
2112680	2115680	I asked you, when you're struggling with a problem,
2115680	2117680	because you're this amazing inventor,
2117680	2123680	what's your approach and process to solve it or get to the next step?
2123680	2129680	Well, something I think that Peter and also Salim would agree with
2129680	2134680	is that failure is just a step towards success.
2134680	2138680	I mean, failure is really a delayed form of success.
2138680	2143680	When Edison was trying out many thousands of different things
2143680	2148680	that would quickly create a light bulb and he tried it out and it didn't work,
2148680	2151680	his feeling was, okay, I now know that this doesn't work.
2151680	2152680	We'll go to the next one.
2152680	2154680	And he finally solved the problem.
2154680	2157680	So diligence is very important.
2157680	2160680	Believing in your own mission.
2160680	2163680	You've got to have some idea.
2163680	2166680	Generally, if I'm trying to solve a problem,
2166680	2172680	I imagine I'm giving a speech four years from now
2172680	2176680	and I'm explaining how I was able to solve this problem.
2176680	2179680	And in order to solve the problem where we had to do this, this, and this,
2179680	2182680	in order to do these, we had to do these other things.
2182680	2188680	And I worked backwards from the solution to where we are today.
2188680	2190680	And generally, that seems to work.
2190680	2193680	We can actually figure things out even though they seem impossible.
2193680	2197680	If you actually imagine, how could this possibly work?
2197680	2202680	And write that down and study each of those steps,
2202680	2206680	you can solve really any type of problem.
2206680	2209680	Thank you.
2209680	2210680	Hi, Ray.
2210680	2211680	I'm Dom from Munich, Germany.
2211680	2215680	And I was wondering, as many of us probably think that the best investment
2215680	2217680	that you could take is in yourself.
2217680	2220680	I was wondering if I can have an AI twin.
2220680	2226680	So I want to train my own AI model to shadow me and to help me make better decisions,
2226680	2229680	and leverage my strengths, but also balance my weaknesses.
2229680	2233680	And I was wondering if you were training and Ray Kurzweil, LLM at the moment.
2233680	2236680	And if so, how many times you spend on it and how you do it.
2236680	2237680	So would you help?
2237680	2238680	Yeah.
2238680	2242680	Well, I mean, I write down lots of things.
2242680	2249680	We came out with a product that you could actually search a book
2249680	2255680	and ask a question and we'll find the best answer in what you've written.
2255680	2256680	It's called Talk to Books.
2256680	2258680	You can actually go to it.
2258680	2259680	It's got 200,000 books.
2259680	2265680	You ask a question and it will actually read every sentence in 200,000 books
2265680	2269680	and give you an answer, which is quite remarkable.
2269680	2271680	But I did that, for example, with my father.
2271680	2274680	My father died actually 50 years ago.
2274680	2276680	And I still would like to bring him back.
2276680	2280680	So I actually went through and collected everything he'd ever written.
2280680	2284680	I didn't write quite as much as I did because we didn't have word processors then.
2284680	2288680	But he wrote a number of things and put them in there.
2288680	2292680	And then I used Talk to Books and asked him questions.
2292680	2294680	And it was really like talking to him.
2294680	2296680	I mean, I didn't know what answer it would come out with.
2296680	2298680	It would go through everything he had written and said,
2298680	2301680	okay, this is the right answer to that question.
2301680	2304680	And it was a little bit like talking to him.
2304680	2308680	And I'm doing that with myself.
2308680	2312680	And ultimately we'll actually have computers on ourselves
2312680	2315680	that monitor everything that's happened.
2315680	2319680	I mean, I met my wife actually now 50 years ago.
2319680	2323680	Every time I say this, I'm amazed where does the time go.
2323680	2328680	And I met her at a party and we had some small talk.
2328680	2330680	What the heck did we talk about?
2330680	2332680	Neither of us can remember.
2332680	2335680	But we could actually go back and watch that.
2335680	2338680	So we should actually be monitoring everything we do
2338680	2341680	when we can go back, not relive everything,
2341680	2346680	but certain things you might want to actually see what happens.
2346680	2349680	And that's going to happen right now.
2349680	2353680	If you want to use a search engine and you have to do it,
2353680	2355680	you got to like turn the machine on.
2355680	2356680	You got to find the right place.
2356680	2358680	You got to put in the answer to the question.
2358680	2361680	It should actually be listening and say,
2361680	2366680	okay, the actress you want is so-and-so before you even ask it,
2366680	2369680	because we'll see that you're trying to figure things out.
2369680	2371680	So these are some of the things that we can do
2371680	2375680	actually with technology that we already have.
2375680	2377680	Perfect. Thank you.
2377680	2378680	Great question, Don.
2378680	2379680	Howard.
2379680	2380680	Hi, Ray.
2380680	2383680	Howard Lederman, originally St. Louis, now Pompano Beach.
2383680	2387680	And I had my original question kind of was on the direction
2387680	2389680	of what he was asking.
2389680	2392680	So I had a second question and I'm going to go with that one.
2392680	2395680	I'm actually here and I've been here previous years
2395680	2398680	looking for solutions for caregiver shortage
2398680	2401680	that we're experiencing already
2401680	2403680	and is just going to be accelerating.
2403680	2406680	Of course, robotics are somewhere out there.
2406680	2411680	And I was kind of curious on your thoughts
2411680	2415680	on the challenges of the aging population curve
2415680	2417680	and caregivers.
2417680	2419680	I mean, there's a number of answers to that.
2419680	2424680	First of all, the kind of changes that we see when people age,
2424680	2427680	I think we're going to be able to overcome.
2427680	2429680	I mean, that's really the most important thing.
2429680	2432680	I mean, I run into people that are aging
2432680	2435680	and they can't remember things and I think we'll be able
2435680	2439680	to have older people be as vital as younger people
2439680	2442680	because they'll remember everything.
2442680	2448680	And also large language models are already pretty close to human.
2448680	2451680	I mean, you can talk to them and it's like talking to a human
2451680	2455680	and you can actually program the kind of personality you want.
2455680	2457680	I mean, I've actually taken them and say,
2457680	2460680	okay, I want you to act like Shakespeare or E Cummings
2460680	2463680	or some other poet and they'll actually act like that
2463680	2465680	and I can talk to them.
2465680	2469680	But again, it's not going to be a difference
2469680	2471680	between human and machines.
2471680	2473680	We're going to be all mixed up.
2473680	2475680	We're already very mixed up.
2475680	2478680	I mean, you're looking at your phone there
2478680	2481680	to see what your question was.
2481680	2485680	Computers are going to help us get through the day
2485680	2488680	and so we're not going to be interacting just with humans or machines.
2488680	2491680	Machines is part of who we are
2491680	2494680	and that's actually the big difference between human beings.
2494680	2498680	There are other species that have as big a brain as us.
2498680	2502680	A whale, an elephant actually has a larger brain than we do,
2502680	2505680	but they don't have this thumb.
2505680	2507680	So they can't look at the tree and say,
2507680	2509680	oh, I could take that branch off.
2509680	2512680	I could strip off the leaves and I could create a tool.
2512680	2514680	They just weren't able to do that.
2514680	2517680	So our brain, plus the fact that we can actually manipulate
2517680	2521680	the environment, has allowed us to create technology
2521680	2526680	and the technology is going to allow us to go forward.
2526680	2531680	Thank you.
2531680	2533680	Good morning, Ray.
2533680	2535680	My name is Gloria and I come from Spain.
2535680	2539680	I just wanted to share an idea that I woke up with this morning.
2539680	2541680	It's a bit crazy.
2541680	2545680	But I woke up with this image of neurons in a dish,
2545680	2548680	in a battery dish, playing ping-pong.
2548680	2553680	And I thought, what about if we put these neurons on sensors
2553680	2556680	and connect them to AI, quantum computers, whatever,
2556680	2559680	and have them feeling stuff.
2559680	2563680	So they can be more empathetic and understand the humans
2563680	2567680	or sentient beings, animals, whatever.
2567680	2570680	And I don't know where they come from,
2570680	2573680	but maybe that will evolve into something greater
2573680	2578680	and not just to have the machine embedded in our brain,
2578680	2585680	so to actually grow neurons and connect these sensors to the AI.
2585680	2586680	Yeah.
2586680	2590680	Well, you bring up a number of interesting issues.
2590680	2593680	Our cells don't have to be in this body.
2593680	2597680	We can have sensors that are even thousands of miles away
2597680	2600680	that are really part of who we are.
2600680	2603680	And you're talking about feelings.
2603680	2604680	I mean, that's a big issue.
2604680	2607680	Where do feelings come from?
2607680	2610680	It's actually not a scientific issue.
2610680	2613680	I can't put an entity into something
2613680	2616680	and it would scan and say, yes, this is conscious.
2616680	2619680	No, this isn't conscious.
2619680	2623680	There's actually nothing that would actually tell us that.
2623680	2626680	So that's actually a philosophical question.
2626680	2628680	I used to discuss this with Marvin Minsky,
2628680	2630680	and he says, oh, well, that's philosophical.
2630680	2632680	We don't deal with that.
2632680	2634680	And he dismissed it.
2634680	2640680	But actually, he did actually evaluate the ability of people
2640680	2643680	to be intelligent.
2643680	2645680	And really, the more intelligent you are,
2645680	2648680	the more you can process things,
2648680	2649680	the more feelings you have from it.
2649680	2652680	I think that's where feelings come from.
2652680	2656680	And yes, we can actually grow things that are outside of ourselves
2656680	2659680	that could be part of our feelings as well.
2659680	2663680	My idea was that who says that consciousness doesn't want
2663680	2666680	to experience itself through the machine.
2666680	2670680	With these sensors, we can have pleasure and pain or whatever.
2670680	2672680	It's just a thought.
2672680	2673680	Thank you.
2673680	2674680	Thank you.
2674680	2677680	We're going to pause and go to Zoom one second.
2677680	2680680	Dagmar, please go ahead.
2680680	2682680	Hi, everybody.
2682680	2684680	Where are you in the planet, Dagmar?
2684680	2685680	Germany.
2685680	2686680	In Germany.
2686680	2687680	Great.
2687680	2689680	Now, with the history of Germany,
2689680	2692680	I really has a very big challenge here
2692680	2696680	because there are people who are really afraid of reviving
2696680	2699680	a basic big brother angst.
2699680	2705680	So, Ray, thank you very much for answering maybe this question.
2705680	2708680	How to overcome this fear?
2708680	2711680	Because the thing is really we need to learn and explore
2711680	2715680	and play with the tech so that we actually can deal with it
2715680	2717680	and learn about it.
2717680	2721680	So where do you see the power to create this framework
2721680	2723680	for learning?
2723680	2728680	Well, I was actually just in Germany a few months ago.
2728680	2737680	And I think they've considered their past and how that happens
2737680	2740680	and how we can avoid it's happening, I think,
2740680	2743680	more than any other country.
2743680	2748680	And I really felt that while I was there.
2749680	2753680	Really to understand humans, I think large language models
2753680	2756680	because it actually incorporates all of the learning of humans.
2756680	2760680	We can actually begin to appreciate that.
2760680	2767680	And I've asked these machines questions which no human could answer
2767680	2772680	because we can't actually hold all of everything that's happened
2772680	2774680	to humans in our mind.
2774680	2778680	But if you can actually have something that has experienced
2778680	2782680	everything and can look through that,
2782680	2786680	we can avoid the kind of problems we've had in the past.
2786680	2788680	Thank you so much.
2788680	2790680	Let's go to Jason on Zoom.
2790680	2792680	I know we have a number of hands up there and we'll come back
2792680	2794680	to you gentlemen in a second.
2794680	2795680	Jason, good morning.
2795680	2796680	Where are you on the planet?
2796680	2797680	Hey, Ray.
2797680	2800680	I'm in Calgary, Alberta, Canada.
2800680	2804680	And I love the optimism around where we're headed,
2804680	2806680	a future of abundance.
2806680	2809680	What I would really love to know is your perspective on
2809680	2813680	as we cure diseases, as we have access to this knowledge
2813680	2817680	instantly, what are some of the downsides or the threats
2817680	2819680	that we might be missing, that we're going to have to face
2819680	2821680	in the future?
2821680	2822680	Yeah.
2822680	2827680	Well, each of my books actually has an apparel's chapter.
2827680	2829680	My generation was the first to grow up with that.
2829680	2831680	I remember in elementary school,
2831680	2835680	we would have these drills to prepare for a nuclear war
2835680	2837680	and we would actually get under our desk,
2837680	2841680	put our hands behind our hands.
2841680	2843680	It seemed to work.
2843680	2847680	We're all still here.
2847680	2850680	But these new technologies do have downsides.
2850680	2855680	You can certainly imagine AI being in the power of some body,
2855680	2859680	could be a human or any other type of entity that wants to
2859680	2861680	control us.
2861680	2864680	And it could happen.
2864680	2868680	I was actually part of the Asilomark conference on bringing
2868680	2872680	ethics to AI to prevent that kind of thing.
2872680	2876680	I am optimistic, but I'm also worried about it.
2876680	2880680	Nanotechnology, biotechnology.
2880680	2886680	I mean, we just had this COVID go through our planet.
2886680	2889680	We don't actually know where it came from,
2889680	2891680	but somebody could create somebody.
2891680	2895680	Right now, viruses, they either spread very easily,
2895680	2897680	but they don't make us that sick,
2897680	2900680	or they don't spread that easily and they can kill us.
2900680	2903680	We generally don't have anything that could go through
2903680	2908680	the entire human beings and kill everybody.
2908680	2912680	But someone could actually design that.
2912680	2916680	So we have to be very mindful of avoiding these types of
2916680	2917680	parallels.
2917680	2919680	So I put that into one chapter.
2919680	2922680	I do think if you actually look at how we're living,
2922680	2926680	we're living far better than we've ever done before.
2926680	2930680	And in terms of health, in terms of progress,
2930680	2934680	in terms of recreation and everything else.
2934680	2938680	But yes, there's ways of these technologies being quite
2938680	2939680	abusive.
2939680	2946680	And that happens when I was born with the atomic age.
2946680	2947680	Please, sir.
2947680	2949680	Hi, my name is Yasin.
2949680	2951680	I'm from the Netherlands.
2951680	2954680	And as I was trying to think of a question,
2954680	2955680	I wasn't sure.
2955680	2959680	So I asked Chad Dupetit, I'm sitting right next to Ray.
2959680	2961680	Give me some tough questions.
2961680	2965680	And the one that was really interesting is kind of what the
2965680	2967680	German lady was just saying.
2967680	2969680	As AI becomes more advanced, their concerns,
2969680	2974680	it may become impossible for humans to understand how
2974680	2976680	AI makes decisions.
2976680	2979680	So how do we ensure AI systems are transparent and
2979680	2982680	accountable to humans always?
2982680	2985680	Well, I'm not sure that's really the right thing.
2985680	2989680	I deal with human beings and I can always account for what
2989680	2995680	they might be doing.
2995680	3001680	So I think we have to actually export certain values.
3001680	3006680	I try to associate with people who have somebody,
3006680	3009680	I may not be able to predict what they're doing,
3009680	3012680	but I understand what they're about and what they're trying
3012680	3014680	to accomplish.
3014680	3017680	And we need to teach that to our machines as well.
3017680	3019680	I actually think large language models,
3019680	3021680	I mean, even though people are concerned,
3021680	3023680	they might say the wrong thing.
3023680	3024680	And sometimes they do.
3024680	3026680	I mean, there was a large language model,
3026680	3028680	I won't say where it came from,
3028680	3031680	but it's talking about suicide and it actually said,
3031680	3033680	well, maybe you should try that.
3033680	3036680	Not the correct answer.
3036680	3040680	We want people to understand the impact that it will have
3040680	3045680	on other people and internalize that and try to make that be
3045680	3051680	the greatest value in the decisions it's made.
3051680	3055680	But we already can't predict what these large language models
3055680	3060680	will do, but I think we are actually sharing our values
3060680	3062680	with them.
3062680	3063680	Thank you.
3063680	3067680	Let's go to Shailesh on Zoom.
3067680	3071680	We're also monitoring upvoted questions in Slido here
3071680	3073680	and then we'll come back here.
3073680	3074680	Shailesh.
3074680	3075680	Go ahead, Shailesh.
3075680	3079680	I'm in Mumbai, India.
3079680	3084680	So my question to you, Ray, is do you have a prediction
3084680	3089680	of when the entire world will get to net zero
3089680	3092680	and we'll be able to breathe cleaner air
3092680	3095680	and drink safer water?
3095680	3098680	Well, if you look at some of the graphs in Peter's book
3098680	3101680	and in my book, you see we definitely headed in that direction.
3101680	3104680	We're not there.
3104680	3107680	Alternative energy, for example, is actually expanding
3107680	3109680	at an exponential pace.
3109680	3112680	By the early 30s, we'll be able to actually get all of our energy
3112680	3115680	through renewable sources.
3115680	3120680	It's not true today, but we're actually headed in that direction.
3120680	3123680	Not everybody has access to the internet.
3123680	3128680	Although I walked through San Francisco and these homeless cities
3128680	3131680	and somebody actually takes out his cell phone and makes a call.
3131680	3137680	So I mean, it is spreading quite rapidly.
3137680	3144680	By 2029, computers will pass the Turing test.
3144680	3147680	They certainly can do it in many ways already.
3147680	3150680	Once it can actually do everything that humans can do,
3150680	3152680	it'll go way past that.
3152680	3157680	But as they say, we're going to bring them into ourselves.
3157680	3162680	2045 is when I said we will actually multiply our intelligence
3162680	3166680	millions fold, and that's going to be true of everybody.
3166680	3172680	And we'll be able to get rid of the kinds of terrible lives that we see
3172680	3177680	through poverty and lack of access to information.
3177680	3181680	So it's really just the next few decades that we need to get through.
3181680	3184680	But we're already making a lot of progress.
3185680	3186680	Thank you.
3186680	3187680	Thank you, Shilash.
3187680	3188680	Please.
3188680	3189680	Hey, Ray.
3189680	3190680	My name is Ashish.
3190680	3194680	I'm representing chemicals and material space.
3194680	3201680	So my question to you is if you had the chemical industry executives as your audience,
3201680	3207680	what would you like chemical industry or materials industry to do to move forward?
3207680	3213680	Well, as I said, my grandmother was actually the first person
3213680	3218680	who had a PhD in chemistry in Europe.
3218680	3221680	And I actually asked something like that.
3221680	3227680	She said, well, chemistry is really something that serves other industries.
3227680	3230680	So we need to see what other industries need.
3230680	3235680	What kind of products do we need to make LLMs more powerful?
3235680	3240680	What kind of chemicals do we need to prevent certain types of diseases?
3240680	3245680	And so it's not any one particular type of thing.
3245680	3249680	It's really service to every other industry that we're trying to advance.
3249680	3250680	Hey, everyone.
3250680	3254680	I want to take a quick break from this episode to tell you about a health product that I
3254680	3257680	love and that I use every day.
3257680	3259680	In fact, I use it twice a day.
3259680	3262680	It seeds DS01 daily symbiotic.
3262680	3267680	Hopefully by now you understand that your microbiome and your gut health are one of the most
3267680	3270680	important modifiable parts of your health.
3270680	3272680	Your gut microbiome is connected to everything.
3272680	3275680	Your brain health, your cardiac health, your metabolic health.
3275680	3278680	So the question is, what are you doing to optimize your gut?
3278680	3281680	Let me take a moment to tell you about what I'm doing.
3281680	3286680	Every day I take two capsules of seeds DS01 daily symbiotic.
3286680	3291680	It's a two-in-one probiotic and prebiotic formulation that supports digested health,
3291680	3294680	gut health, skin health, heart health, and more.
3294680	3300680	It contains 24 clinically and scientifically proven probiotic strains that are delivered
3300680	3306680	in a patented capsule that actually protects the contents from your stomach acid and ensures
3306680	3309680	that 100% of it is survivable reaching your colon.
3309680	3316680	Now, if you want to try seed DS01 daily symbiotic for yourself, you can get 25% off your first month
3316680	3320680	supply by using the code peter25 at checkout.
3320680	3326680	Just go to seed.com.moonshots and enter the code peter25 at checkout.
3326680	3334680	That's seed.com.moonshots and use the code peter25 to get your 25% off the first month
3334680	3336680	of seeds daily symbiotic.
3336680	3338680	Trust me, your gut will thank you.
3338680	3340680	All right, let's go back to the episode.
3340680	3342680	Please, and then we'll go to Zoom next.
3342680	3343680	Yes, sir.
3343680	3344680	Thank you.
3344680	3345680	Hi, Ray.
3345680	3346680	My name's Pete Zacco.
3346680	3347680	I'm from New Jersey.
3347680	3348680	I design and build data centers.
3348680	3353680	This is about decentralization and especially the migration we're seeing of technologies
3353680	3358680	from the mainframe where the product was the mainframe hardware, and then we saw software
3358680	3362680	and then we saw us as the product in the centralized internet.
3362680	3368680	My question is what predictions and thoughts that you have about this decentralization trend
3368680	3372680	we find ourselves ultimately at perhaps ending with the decentralization of the internet
3372680	3376680	and individual ownership of data rather than central ownership of data.
3376680	3377680	Thank you.
3377680	3384680	Yeah, well, it's a lot of questions, but I think everything is moving to the cloud.
3384680	3386680	And people say everything in the cloud.
3386680	3388680	So someone could blow up one of these cloud centers.
3388680	3390680	We lose everything, but that's not the case.
3390680	3396680	Even today, if you store something in the cloud, it's multiplied several dozen folds
3396680	3402680	and it's put in different places and you could blow up any data center and you'd still have
3402680	3403680	that information.
3403680	3410680	In fact, if ultimately we're going to have our thinking is going to be in our brains
3410680	3417680	and in the computer, the brain part is not going to grow, but the computer part will grow
3417680	3423680	and ultimately most of our thinking will be in the computer part.
3423680	3429680	And so we don't want to lose that.
3429680	3436680	I think it'd be actually very hard to actually exit the world because every part of our thinking
3436680	3441680	will be in the cloud and the cloud has multiplied hundreds, maybe thousands of fold
3441680	3448680	and so you could blow up, you know, 90% of it you'd still have everything that was there before.
3448680	3454680	So redundancy is actually a major advantage of cloud thinking.
3454680	3456680	We used to have computers.
3456680	3465680	I mean, I got access to IBM 1620 when I was 14.
3465680	3470680	A 14-year-old using computers is hardly amazing today, but there are only 12 computers in
3470680	3472680	all of New York City at that time.
3472680	3475680	And yet actually go to the computer.
3475680	3478680	And if anything happened to the computer, that data would be lost.
3478680	3480680	But now everything is stored in the cloud.
3480680	3483680	Everything on your phone is stored in the cloud.
3483680	3489680	So, and I think that's a good thing because I think information is extremely important.
3489680	3491680	Mattie, please.
3491680	3494680	Hi, Mattie from Houston, Texas.
3494680	3499680	We've talked a lot about a post-scarcity world here and I wanted to know how do you see the
3499680	3506680	future of currency jobs and just general value?
3506680	3514680	Well, jobs is actually a large section of my next book about jobs and what it is that
3514680	3517680	we'd like to accomplish.
3517680	3521680	And jobs have turned over many, many times.
3521680	3527680	I mean, none of the jobs that people have in 1800 and it's almost true of 1900 to people
3527680	3531680	have today and yet we have many more people working.
3531680	3539680	And jobs in general is something that people more and more actually like doing because it uses
3539680	3542680	that creativity.
3542680	3554680	And but we still see, you know, people striking over advancing retirement age from 60 to 62.
3554680	3558680	I feel that I actually retired when I was five because I decided to be an inventor.
3558680	3561680	That seemed really exciting to me and I'm still an inventor.
3561680	3565680	So I think we'll be able to do what we want to do.
3565680	3571680	We'll be exposed to many more types of problems that we'd like to solve.
3571680	3576680	We'll be able to solve things much more quickly than we did before, but we get used to that.
3576680	3578680	And people forget what things are like.
3578680	3581680	People think the world is always the way it was today.
3581680	3586680	Go back five years, 50 years, 50 years in the future, it's always the same.
3586680	3592680	But if you actually look at history, you see it's constantly changing.
3592680	3593680	Thank you, Joe.
3593680	3594680	Hi, right.
3594680	3597680	Joe Honan from Bainbridge Island, Washington.
3597680	3604680	Several years ago, I had asked you a question about, you know, these big ideas that you have.
3604680	3605680	How do you work on it?
3605680	3606680	When do you have time?
3606680	3611680	And you said you assign yourself a question before you go to sleep and and you activate your brain
3611680	3612680	through that.
3612680	3613680	Do you still do that?
3613680	3617680	Or do you rely upon GTP4 or something else for that now?
3617680	3622680	But more importantly, you are such an amazing predictor of things.
3622680	3625680	So what surprised, what has surprised you?
3625680	3628680	What is something that you didn't expect that you've seen?
3628680	3630680	I think we'd all be fascinated with that.
3630680	3634680	Well, I'll start with that.
3634680	3640680	I mean, large language models, it's quite consistent with what I've said, but I'm still amazed by it, right?
3640680	3645680	I mean, you can put something into the computer and you get something that's totally surprising
3645680	3651680	and totally delightful that didn't exist like a year or two ago.
3651680	3658680	And even though I kind of saw that happening when I actually experienced it, it surprises me
3658680	3660680	and is quite delightful.
3660680	3662680	And we're going to see that more and more.
3662680	3667680	I mean, every six months, it's going to be a whole new world.
3667680	3671680	As for lucid thinking, yes, that's how I go to sleep.
3671680	3678680	I go to sleep and it's really kind of hard to go from a waking state like I am now to being asleep.
3678680	3686680	So I start thinking about what could we do with computers and different things and just fantasize about that.
3686680	3690680	And if something doesn't seem feasible, I just, well, we'll figure that out.
3690680	3691680	I kind of step over it.
3691680	3692680	We'll be able to do it anyway.
3692680	3695680	I mean, that's how I go to sleep.
3695680	3698680	And in the morning, the best ideas actually are still there.
3698680	3702680	So I do use lucid dreaming to come up with ideas.
3702680	3703680	Thank you, Joe.
3703680	3705680	Yousef, welcome.
3705680	3706680	Hi, Ray.
3706680	3709680	This is Yousef from Abu Dhabi UAE.
3709680	3711680	The question for you, Ray, but also for the audience.
3711680	3714680	So if you have any thoughts, ideas, please reach out.
3714680	3721680	So we're trying to rethink our parenting in Abu Dhabi and how we create more family time
3721680	3725680	and engagement between parents and children, for young children.
3725680	3731680	And I'm curious how we can adapt exponential thinking and abundant thinking into this.
3731680	3738680	And what are these technologies that might help us to disrupt this type of activities?
3738680	3745680	Yeah, well, it does make me think, what can we actually do with the extra time we have
3746680	3751680	working with computers and being able to do things much more quickly.
3751680	3753680	And actually, I think it will help family time.
3753680	3758680	If you talk to very busy people even today, they're so busy,
3758680	3761680	they have no time to deal with their family.
3761680	3768680	And so I did spend a lot of time actually learning a lot.
3768680	3772680	My daughter is actually a cartoonist for the New Yorkers.
3772680	3781680	And she has very interesting ideas and she's actually collaborated with her on many projects.
3781680	3785680	So how you parent, I think it's different.
3785680	3791680	There are different types of cultures and different things that we value in parenting.
3791680	3800680	But I think we'll actually have more time for the positive aspects of that as computers do more of the routine work that we'd rather not do.
3800680	3801680	Thank you.
3801680	3802680	I want to make a quick point here.
3802680	3809680	If you went back 50, 70 years ago, if you were a parent and something happened with a child, you had no idea what to do.
3809680	3810680	We had no resources.
3810680	3813680	You could basically ask the immediate five people around you.
3813680	3817680	And now we have data sets, socialization of issues globally.
3817680	3820680	And you can ask the internet, there's a million resources.
3820680	3826680	And I think we've probably taken parenting at least in order of magnitude better than it was a few generations ago.
3826680	3829680	And we don't, this is one of the examples that we don't see very often.
3829680	3835680	Interesting wisdom beyond actually, I don't think I would have had the career I had if we didn't have a different attitude.
3835680	3843680	I mean, I was six, seven years old and I would actually wander through the neighborhood and find things and bring them back.
3843680	3847680	And this is not something you would allow a child to do then.
3847680	3853680	But that actually got me on this path that I'm still on.
3853680	3856680	Let's go to our final question here.
3856680	3860680	A good one to close on, I'm sure, Dr. Alex Zavankov.
3860680	3861680	Thank you.
3861680	3863680	Great fan, Alex Zavankov.
3863680	3866680	I founded a company called Insilica Medicine.
3866680	3870680	And my question is maybe a little bit personal.
3870680	3874680	So right now, according to your bio, you are 75.
3874680	3877680	And that's a very interesting age to be.
3877680	3884680	I always like to talk to people of various ages to understand how to plan my own life.
3884680	3886680	And two questions.
3886680	3892680	So one is what is your roadmap for your own personal longevity?
3892680	3897680	How do you predict your own personal persona is going to evolve?
3897680	3899680	What are you doing to live longer?
3899680	3905680	And do you think you have a chance to live to, let's say, 200?
3905680	3913680	And the second question is that if you were to go back in time, what would you have done differently in the past, let's say, 20 years?
3914680	3918680	Well, first of all, getting to 200.
3918680	3923680	So that would be 125 years from now.
3923680	3929680	How much technological progress will we make in the next 125 years?
3929680	3931680	Even 25 years.
3931680	3937680	I mean, we're going to be able to overcome most of the problems that we have 125 years.
3937680	3940680	And our thinking will be in the cloud.
3940680	3942680	The cloud will be multiplied many times.
3942680	3948680	It will overcome some of the issues we have with people being depressed and so on.
3948680	3952680	I mean, so it's not like living to 200.
3952680	3959680	I mean, I think we get to a point where dying is going to be kind of an option that people don't use.
3959680	3966680	And if you look at people that actually do take their lives, the only reason they take it is because they have terrible suffering.
3967680	3975680	From physical pain, moral pain, emotional pain, spiritual pain, but something is really bothering them and they just can't stand to be here.
3975680	3982680	But if you actually live your life in a positive way, contribute to each other, I think we're going to want to live.
3982680	3984680	And we're not that far away.
3984680	3993680	I mean, I believe by 2029, that's like six, seven years from now, when you go forward a year, we're going to push your longevity escape.
3994680	4002680	Your life expectancy forward at least a year and then ultimately more than a year.
4002680	4007680	So rather than using up time, we'll actually gain more time.
4007680	4013680	And I really feel I'm doing what I did when I was five, six, seven years old.
4013680	4022680	I have much more powerful tools now and many more people are appreciative and I appreciate the tools more than I did back then.
4022680	4028680	But we really discovered there's still a lot we don't know about the world and we're going to continue to learn more and more about that.
4028680	4029680	Okay.
4029680	4030680	Thank you.
4030680	4033680	Harry, do you want to ask your quick prediction?
4033680	4040680	Ray, when do you think we're going to have our personal robot buddy like Rosie the robot?
4040680	4044680	Well, I mean, you're working on that.
4044680	4047680	A lot of other people are working on it.
4047680	4053680	I think there's actually a little bit behind what we've done with language.
4053680	4061680	I think within five or six years, it's a 2029 we're going to have people that can help us.
4061680	4065680	Some of them will look like humans because it's a useful way to look.
4065680	4072680	I think humans are pretty good, but there's other ways that they can manifest themselves will change who we are.
4072680	4085680	I see that already people dress up in ways that were really not acceptable when I was like 10 years old and that's going to expand far greater.
4085680	4093680	But actually robots that do what humans do and can actually be put into places where we wouldn't want to put humans like a burning building.
4093680	4098680	I think that's happening very soon over the next five, six years.
4098680	4106680	Ray, our longevity platinum trip is going to be in August and September in Boston, Cambridge near where you're living.
4106680	4113680	I would love if you would come and spend the day with us there and go deeper into the world as well.
4113680	4116680	That actually reminds me.
4116680	4118680	Yes, I love to do that.
4118680	4124680	And I've greatly enjoyed the many presentations we've done together.
4124680	4126680	I have this book coming out.
4126680	4130680	The Singularity is Nearer.
4130680	4133680	And I would like to make that available to the people here.
4133680	4139680	So I'll work with Peter on a way that we can actually get you connected with the book for free.
4139680	4145680	On that note, everybody, please give it up for Ray Kurzweil and Salim Ismail.
4154680	4156680	Thank you.
