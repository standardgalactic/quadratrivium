WEBVTT

00:00.000 --> 00:03.840
By next year, end of the year, I believe you'll have ChatGPT on your mobile phone.

00:03.840 --> 00:04.760
Say that one more time.

00:04.760 --> 00:08.360
By the end of next year, you'll have ChatGPT on your mobile phone without internet.

00:10.160 --> 00:12.080
Today, the world changes.

00:12.080 --> 00:13.880
This is a regime change.

00:13.880 --> 00:17.680
Four of the top 10 apps or apps in December were based on stable diffusion.

00:17.680 --> 00:20.880
41% of all code on GitHub right now is AI generated.

00:20.880 --> 00:22.960
We have figured out how to make humans scale.

00:22.960 --> 00:25.560
So you have this amazing thing that can create anything.

00:25.560 --> 00:28.000
How far out are you able to see?

00:28.040 --> 00:32.160
Can you have a sense of predicting where we are in 10 years?

00:32.160 --> 00:33.480
I can't see past my tears.

00:33.480 --> 00:37.800
There's enough fear and some of it is deserved, but there also needs to be hope.

00:37.800 --> 00:39.240
Humans are humans.

00:39.240 --> 00:42.560
Bring them the information that creates the most value and you will change the world.

00:46.360 --> 00:49.640
I'm excited to share with you one of the most extraordinary conversations

00:49.640 --> 00:52.880
I had at this year's annual Abundance 360 Summit.

00:53.600 --> 00:57.480
It was with a friend, someone I've had on this podcast before,

00:57.480 --> 01:01.800
Imad Moustak, who's the founder and CEO of Stability AI.

01:01.800 --> 01:06.320
You know his company from a number of his products, including stable diffusion.

01:06.320 --> 01:10.520
We sat down to talk about his moonshots to talk about how

01:10.520 --> 01:12.640
generative AI is changing the world.

01:12.640 --> 01:16.720
What do you do if you're a 20-year-old just getting involved?

01:16.720 --> 01:19.840
Or if you're a seasoned CEO or entrepreneur,

01:19.840 --> 01:24.720
and how is this going to change the world of Hollywood education, health care?

01:24.720 --> 01:27.280
You know, it was an incredible conversation.

01:27.280 --> 01:29.120
I'm excited for you to hear.

01:29.120 --> 01:34.560
You know, my mission through this podcast is to help you hear the voices

01:34.560 --> 01:37.760
that are filled with optimism and abundance.

01:37.760 --> 01:41.080
If that's of interest to you, then please subscribe to this podcast.

01:41.080 --> 01:42.400
All right, enjoy the episode.

01:42.400 --> 01:47.440
By the end of this episode, you should have a pretty good idea where you stand on AI.

01:47.440 --> 01:48.480
Are you excited about it?

01:48.480 --> 01:49.840
Are you fearful of it?

01:49.840 --> 01:50.800
I'd love to know.

01:50.800 --> 01:53.720
Feel free to share your stance with me on Twitter.

01:53.720 --> 01:54.200
Hey, pal.

01:54.200 --> 01:54.800
Hey.

01:54.800 --> 01:56.000
How's it going, buddy?

01:56.000 --> 02:00.360
Listen, I know you have so much going on right now.

02:00.360 --> 02:01.320
It's insane.

02:01.320 --> 02:06.680
We're in the midst of the most extraordinary period of technology ever,

02:06.680 --> 02:08.480
and you're in the thick of it.

02:08.480 --> 02:10.080
Yeah, I think, what's it?

02:10.080 --> 02:12.320
A good phrase is, everything ever, all at once?

02:12.320 --> 02:13.320
Yes.

02:13.320 --> 02:13.800
Yeah.

02:13.800 --> 02:16.640
That's basically what it is.

02:16.640 --> 02:19.680
I can't mention the conversations he's been having the last 30 minutes,

02:19.680 --> 02:22.360
but it would blow your mind.

02:22.360 --> 02:23.480
I'm going to give you this clicker.

02:23.480 --> 02:26.440
You have some slides to show.

02:26.440 --> 02:30.200
I think the very first question to ask

02:30.200 --> 02:35.200
is if you were going to bring people up to speed on where we are right now,

02:35.200 --> 02:38.080
would you share some of what your thoughts are here?

02:38.080 --> 02:40.960
We have figured out how to make human scale.

02:40.960 --> 02:43.400
How do you make human scale?

02:43.400 --> 02:45.800
That's the most difficult thing.

02:45.800 --> 02:49.800
Basically, classical AI was all about taking stuff and extrapolating it.

02:49.840 --> 02:53.920
We figured out how to figure out principles and latent knowledge

02:53.920 --> 02:57.160
with huge compression in these files, as we all talk about in a bit.

02:57.160 --> 03:01.560
The most valuable thing you can have is a good EA or a really good analyst.

03:01.560 --> 03:03.400
I have asked her if she's amazing.

03:03.400 --> 03:04.360
It makes such a difference.

03:04.360 --> 03:06.920
I'm sure all of you in this audience will realize that.

03:06.920 --> 03:08.160
We now have that.

03:08.160 --> 03:12.160
Basically, what we've done is we've trained these things on huge amounts of data

03:12.160 --> 03:15.200
to understand principles, and now when you use a GPT-4,

03:15.200 --> 03:18.840
it's like a really talented intern analyst with a bad memory,

03:18.880 --> 03:20.880
and we're about to fix the memory.

03:20.880 --> 03:25.120
It knows how to pass the medical bar exam or medical licensing and others.

03:25.120 --> 03:29.640
It knows how to draw beautiful pictures or create audio of any type,

03:29.640 --> 03:32.320
and it's basically available to everyone for pennies.

03:32.320 --> 03:34.040
That's a great thing. What does that mean?

03:34.040 --> 03:36.080
It can mean huge disruption,

03:36.080 --> 03:40.600
or it can mean basically we're at the point of utopia and abundance.

03:40.600 --> 03:44.440
If you don't mind, people know stable diffusion,

03:44.440 --> 03:49.800
and you'll show them the chart that really rocked me when I first saw it.

03:49.800 --> 03:55.680
But what are the wide range of things that Stability AI is working on right now?

03:55.680 --> 03:57.040
Where do you want to go?

03:58.400 --> 04:00.000
Can you tell us about it, please?

04:00.000 --> 04:01.000
No, I can tell you.

04:01.000 --> 04:06.200
My aim is to provide the building blocks for a society OS.

04:06.200 --> 04:10.080
Every part of society, if you have skilled experts in them,

04:11.080 --> 04:14.520
our mission is to build the foundation to activate human entities' potential.

04:14.520 --> 04:17.320
Across every single modality, we're building models,

04:17.320 --> 04:23.560
so audio, video, protein folding, DNA, chemical reactions, language, and others.

04:23.560 --> 04:27.120
We're doing it for every sector, so you've got a bank of GPT, a board GPT,

04:27.120 --> 04:29.720
to replace all your crap board members,

04:29.720 --> 04:32.080
all the way down to national models.

04:32.080 --> 04:35.720
We're doing an Indian national model at the moment, an Indonesian one, a Japanese one,

04:36.160 --> 04:41.080
so that everyone can have a file that they put words in,

04:41.080 --> 04:45.600
and images, audio, text, anything pops out that's appropriate to you to enhance you.

04:45.600 --> 04:49.240
So I want to click on that one because it's very important.

04:49.240 --> 04:52.720
People talk about biases in the system,

04:52.720 --> 04:56.920
but what you're talking about is creating what you're calling a foundational model

04:56.920 --> 05:01.400
that is biased to you, or to your company, or your country.

05:01.400 --> 05:02.040
Yes?

05:02.040 --> 05:05.120
The existing internet has centralized artificial intelligence

05:05.120 --> 05:09.880
that guides our attention, our memorization, where we go.

05:09.880 --> 05:13.040
With this technology, we can push internet intelligence to the edge,

05:13.040 --> 05:17.720
so every single person, country, culture, company can have their own AIs.

05:17.720 --> 05:21.400
And that's an amazing thing because it can work for you, not against you.

05:21.400 --> 05:24.800
And so that's the personalization because what is bias, right?

05:24.800 --> 05:27.200
There are inherent biases in our society and things,

05:27.200 --> 05:28.760
but we can never move fast on this thing.

05:28.760 --> 05:31.760
We can't move fast enough to address them.

05:31.760 --> 05:33.200
But then what if you could have your own stories?

05:33.240 --> 05:34.440
Everyone here has a story.

05:34.440 --> 05:37.400
Your members of A360, you believe in abundance.

05:37.400 --> 05:39.680
There's a whole variety of things that make us who we are.

05:39.680 --> 05:43.360
Have the AI respond to your own story and work for you.

05:43.360 --> 05:45.240
And I think that's the intelligent internet

05:45.240 --> 05:47.160
and that's the amazing future we have coming.

05:47.160 --> 05:47.840
That is.

05:47.840 --> 05:52.560
And you built Stability AI as an open platform,

05:52.560 --> 05:54.920
which is very different from everybody else.

05:54.920 --> 05:56.800
I mean, it's interesting, right?

05:56.800 --> 05:58.920
OpenAI has that name.

05:58.920 --> 06:02.080
And very funny, if you go to OpenAI.com,

06:02.120 --> 06:04.240
it doesn't go to OpenAI, it goes to stable.

06:04.240 --> 06:05.640
Well, actually, open.ai here.

06:05.640 --> 06:06.800
Open.ai, sorry.

06:06.800 --> 06:08.040
Yeah.

06:08.040 --> 06:09.200
Which is pretty funny.

06:09.200 --> 06:14.920
So inappropriate because you are the open AI platform.

06:14.920 --> 06:15.280
We are.

06:15.280 --> 06:17.880
I mean, actually, openai.com also works.

06:17.880 --> 06:20.880
But yeah, I mean, basically where we were

06:20.880 --> 06:25.000
was that we had this explosion of research.

06:25.000 --> 06:26.400
Look at this is, again, exponential,

06:26.400 --> 06:29.280
literal exponential of the amount of ML research that occurred.

06:29.280 --> 06:31.280
And we were like, let's build a generalized intelligence.

06:31.280 --> 06:34.080
When OpenAI and others started, we didn't know how to do it.

06:34.080 --> 06:35.960
And then we found this one thing called a transformer

06:35.960 --> 06:37.680
that pays attention to the important things.

06:37.680 --> 06:39.160
Like, you guys are paying attention

06:39.160 --> 06:41.240
to the important things that we're saying right now,

06:41.240 --> 06:43.240
as opposed to just treating everything the same.

06:43.240 --> 06:45.440
And it figured out that we could scale it with these GPUs,

06:45.440 --> 06:47.400
like, gigantic supercomputers.

06:47.400 --> 06:48.920
They didn't really know exactly how to do it,

06:48.920 --> 06:51.320
so they just kept on adding more and more supercomputers.

06:51.320 --> 06:51.920
And we've got a lot.

06:51.920 --> 06:54.840
Like, our supercomputer is 10 times faster than NASA's, right?

06:54.840 --> 06:57.400
Our new supercomputer is 10 times faster than that.

06:57.400 --> 06:59.640
So again, exponential.

06:59.680 --> 07:03.920
But then they thought this solves everything, scale solves everything.

07:03.920 --> 07:06.080
But have you ever seen a generalized system

07:06.080 --> 07:08.120
that outperforms a specialized system?

07:08.120 --> 07:09.120
No.

07:09.120 --> 07:10.760
But that means you have to give people the tools

07:10.760 --> 07:12.480
to make it a specialized system.

07:12.480 --> 07:15.800
You're never going to send all your internal company data

07:15.800 --> 07:17.720
to chat GPT or GPT-4.

07:17.720 --> 07:19.600
So that's an interesting point.

07:19.600 --> 07:21.880
And I don't know if I heard it from you or elsewhere,

07:21.880 --> 07:24.120
where some of the banks and large corporations

07:24.120 --> 07:28.080
are not sending their data and allowing employees

07:28.120 --> 07:29.960
to use chat GPT.

07:29.960 --> 07:31.720
They don't want Microsoft having access to it.

07:31.720 --> 07:32.720
So what's the alternative?

07:32.720 --> 07:33.920
How do you go around that?

07:33.920 --> 07:35.960
We have the most popular language models in the world,

07:35.960 --> 07:38.320
GPT-J, Neo-NX, 25 million downloads.

07:38.320 --> 07:41.840
We're about to release our next generation open source models.

07:41.840 --> 07:42.880
Again, base models.

07:42.880 --> 07:44.760
And then you'll have the banker, board versions,

07:44.760 --> 07:45.760
Indian versions.

07:45.760 --> 07:48.240
So I get to use it on my own system

07:48.240 --> 07:49.600
that no one else has access to.

07:49.600 --> 07:52.600
You get to go, is it via Amazon, Google, Intel, anyone?

07:52.600 --> 07:55.280
On-prem, in your cloud, you own it.

07:55.280 --> 07:57.160
Again, it's like you basically.

07:57.160 --> 07:58.880
It's like actually one thing.

07:58.880 --> 08:03.280
It's like, again, these are like very talented analysts.

08:03.280 --> 08:05.920
Getting an analyst on secondment from Microsoft,

08:05.920 --> 08:09.520
he goes back to Microsoft versus hiring your own analyst.

08:09.520 --> 08:10.600
These are the two modalities.

08:10.600 --> 08:13.240
So you'll have these big private proprietary models

08:13.240 --> 08:14.360
where there's lots of secret sources.

08:14.360 --> 08:16.440
They have these open interpretable models

08:16.440 --> 08:19.480
where you see how the cookie is made, as it were,

08:19.480 --> 08:20.800
that you own.

08:20.800 --> 08:23.280
And I think the latter is far more powerful than the former

08:23.280 --> 08:25.240
because you don't need a model that does everything then.

08:25.240 --> 08:28.800
You give people the tools they need and the ownership

08:28.800 --> 08:32.200
to create their own experiences and accelerate themselves.

08:32.200 --> 08:34.320
Let me ask you, we're all here to understand

08:34.320 --> 08:35.720
where this is going.

08:35.720 --> 08:38.120
How far out are you able to see?

08:38.120 --> 08:40.720
Can you have a sense of predicting where we are

08:40.720 --> 08:43.360
in 10 years, five years?

08:43.360 --> 08:44.920
I can't see past five years.

08:44.920 --> 08:45.920
You can't see past five years.

08:45.920 --> 08:48.200
No, because by next year, end of the year,

08:48.200 --> 08:50.680
I believe you'll have chat GPT on your mobile phone.

08:50.680 --> 08:51.600
Say that one more time.

08:51.600 --> 08:53.480
By the end of next year, you'll have chat GPT

08:53.480 --> 08:55.520
on your mobile phone without internet.

08:55.520 --> 08:56.000
Wow.

08:56.000 --> 09:02.560
So we're talking about a stability chat, right?

09:02.560 --> 09:03.360
Yeah, a stable chat.

09:03.360 --> 09:06.280
Stable chat, let's name it properly.

09:06.280 --> 09:08.640
So incredible because you've talked

09:08.640 --> 09:10.920
about taking how many terabytes of data

09:10.920 --> 09:12.440
down to a couple of gigabytes.

09:12.440 --> 09:15.720
So like, actually, this is probably one thing

09:15.720 --> 09:17.160
that I wanted to talk about quickly.

09:17.160 --> 09:19.240
Please, yeah.

09:19.240 --> 09:21.040
The easiest way for us to communicate

09:21.040 --> 09:22.640
has been speech is what we're doing now.

09:22.640 --> 09:24.720
Text has been harder, but you've seen with chat GPT,

09:24.720 --> 09:25.240
it's not easy.

09:25.240 --> 09:27.760
You just ask it to rewrite your kind of emails.

09:27.760 --> 09:29.400
And with Office 365 and Workspace,

09:29.400 --> 09:31.400
we'll do that, and Visual was the hardest.

09:31.400 --> 09:33.480
These have all been flattened by this technology now,

09:33.480 --> 09:34.960
so we can communicate anything.

09:34.960 --> 09:37.880
But the technology behind it, as you said, was a bit crazy.

09:37.880 --> 09:39.880
To do this, what we did, so stable diffusion

09:39.880 --> 09:41.680
was our text-to-image model.

09:41.680 --> 09:43.720
We were like, do we do it big and do loads of layers,

09:43.720 --> 09:45.240
or do we make it accessible?

09:45.240 --> 09:47.040
And we were like, accessible.

09:47.040 --> 09:49.120
So we worked super hard Manhattan project,

09:49.120 --> 09:52.880
and we took 100,000 gigabytes of images, 2 billion,

09:52.880 --> 09:55.280
and created a 2-gigabyte file that can generate anything.

09:55.280 --> 09:57.920
OK, let's slow that down, because the meaning of that

09:57.920 --> 10:00.080
is insane.

10:00.080 --> 10:02.240
How many terabytes was it?

10:02.240 --> 10:07.560
It was 0.1, 100 terabytes, 100,000 gigabytes,

10:07.560 --> 10:11.520
and the output was a 2-gigabyte file that can create anything.

10:11.520 --> 10:16.720
And that 2 gigabytes sits on your phone, your laptop,

10:16.720 --> 10:17.560
in your brain.

10:17.560 --> 10:18.480
It was the whole stack.

10:18.480 --> 10:20.600
So intelligence is compression.

10:20.600 --> 10:22.640
You're going to go away from this event,

10:22.640 --> 10:25.000
and you're going to compress the things that you learn

10:25.000 --> 10:26.640
and have to take away.

10:26.640 --> 10:29.240
That's what we do, and that's what these machines do now.

10:29.240 --> 10:30.480
But again, it's a single file.

10:30.480 --> 10:33.000
Four of the top 10 app store apps in December

10:33.000 --> 10:34.840
were based on stable diffusion.

10:34.840 --> 10:39.880
And it was the entire stack, a single file of weights,

10:39.880 --> 10:40.840
of numbers.

10:40.840 --> 10:42.200
That's extraordinary.

10:42.200 --> 10:44.600
Words go in, images come out.

10:44.600 --> 10:45.640
And it's the same.

10:45.640 --> 10:48.000
ChatGPT is a single file, actually, it's a couple files.

10:48.000 --> 10:49.760
So this is a single file.

10:49.760 --> 10:54.960
Words go in, code comes out, amazing essays come out.

10:54.960 --> 10:56.320
So this is something a bit different.

10:56.320 --> 10:57.920
And again, it's like, again, you've

10:57.920 --> 11:00.640
taught an analyst just about everything,

11:00.640 --> 11:03.200
or as an artist, the analyst, and things like that.

11:03.200 --> 11:06.320
I think we'll get it down to 100 megabytes.

11:06.320 --> 11:08.600
And it went insane, because we made it like that.

11:08.600 --> 11:12.600
So this is what you texted me, and I said, huh?

11:12.600 --> 11:17.160
So a lot of us were doing Web 3, and we were all developers.

11:17.160 --> 11:19.360
Developers are cool, right?

11:19.360 --> 11:21.720
In three months, we ever took Bitcoin and Ethereum

11:21.720 --> 11:23.280
and developed for popularity.

11:23.280 --> 11:26.040
So on the bottom here is the years.

11:26.040 --> 11:32.920
And on the Y axis here is the number of GitHub developers.

11:32.920 --> 11:35.080
GitHub stars, yeah, developers who love it.

11:35.080 --> 11:40.360
And so when you sent me that, I thought that was the axis line.

11:40.360 --> 11:41.280
Yeah.

11:41.280 --> 11:43.280
So cumulatively, the whole ecosystem

11:43.280 --> 11:45.520
built around this thing, which is a bit like a game engine,

11:45.560 --> 11:47.240
has overtaken Linux.

11:47.240 --> 11:51.000
Again, Linux 20 years this five months,

11:51.000 --> 11:53.440
because we gave it to everyone, and it runs on your MacBook

11:53.440 --> 11:56.080
or your iPhone without internet.

11:56.080 --> 11:59.480
So you have this amazing thing that can create anything.

11:59.480 --> 12:02.200
I think that's profound, right?

12:02.200 --> 12:06.360
So we've seen the speed, profound indeed.

12:06.360 --> 12:09.560
We've seen the speed just explode.

12:09.560 --> 12:11.480
Can we expect it to get faster and faster?

12:11.480 --> 12:12.640
Yeah, I think you can.

12:12.640 --> 12:14.840
So look, words go in, images come out.

12:14.840 --> 12:17.960
A lot of you have kind of seen this, you can generate anything.

12:17.960 --> 12:21.320
But since the release in August, we've sped up 100 times.

12:21.320 --> 12:23.840
Well, we've gone from six seconds in image

12:23.840 --> 12:26.360
to 60 images a second.

12:26.360 --> 12:28.440
And the quality has improved, and basically the next version

12:28.440 --> 12:29.680
is photorealistic.

12:29.680 --> 12:33.000
So 60 images per second is like video?

12:33.000 --> 12:34.640
Yeah, we pretty much got video.

12:34.640 --> 12:36.880
So my question is, is Hollywood scared shitless,

12:36.880 --> 12:38.080
or are they excited?

12:38.080 --> 12:38.760
They're scared.

12:38.760 --> 12:39.600
It's a mixture.

12:39.600 --> 12:41.080
There's a few people who are scared shitless,

12:41.080 --> 12:43.280
and we'll talk about some of the stuff coming down the pipeline

12:43.280 --> 12:45.600
later, because, you know, Preetr and I had a discussion,

12:45.600 --> 12:47.760
like, should we scare everyone shitless completely,

12:47.760 --> 12:49.200
or should we kind of do hope?

12:49.200 --> 12:50.600
And so I'm going to do hope, actually.

12:50.600 --> 12:52.240
I think I'm going to focus on this.

12:52.240 --> 12:54.920
This is the most disruptive thing ever, because, again, humans

12:54.920 --> 12:56.800
can scale, so you don't need as many humans.

12:56.800 --> 12:59.000
There was an MIT study, I think, I'll send it to you,

12:59.000 --> 13:00.040
which just came out.

13:00.040 --> 13:03.200
It showed that, basically, the third to the seventh

13:03.200 --> 13:05.880
decile got, like, 30% better.

13:05.880 --> 13:08.160
The top 5% got orders of magnitude better,

13:08.160 --> 13:10.720
or multiples better, with this technology.

13:10.720 --> 13:12.880
And so it lifts humanity and the ability

13:12.880 --> 13:14.200
to communicate and do things.

13:14.200 --> 13:17.600
So this is the hopeful future that we share,

13:17.600 --> 13:21.560
and the abundance mindset that I think

13:21.560 --> 13:23.320
is really important for people to take away.

13:23.320 --> 13:27.040
There's enough fear, and some of it is deserved,

13:27.040 --> 13:28.640
but there also needs to be hope.

13:28.640 --> 13:31.280
I think we always have to look at the unchanging

13:31.280 --> 13:33.120
between versus the inevitable.

13:33.120 --> 13:36.520
So an inevitable is 41% of all code on GitHub right now

13:36.520 --> 13:37.640
is AI generated.

13:37.640 --> 13:38.840
Wow.

13:38.840 --> 13:40.400
To six months.

13:40.400 --> 13:43.760
Which at GPT can pass a GLU level 3 programmer exam,

13:43.760 --> 13:46.440
and it will run pretty much on a MacBook or a phone.

13:46.440 --> 13:47.320
And that's this year.

13:47.320 --> 13:48.080
This year, right now.

13:48.080 --> 13:49.120
Yeah.

13:49.120 --> 13:51.040
There are no programmers in five years.

13:51.040 --> 13:53.640
No programmers in five years.

13:53.640 --> 13:56.160
So those of you with kids who you are having,

13:56.160 --> 13:58.920
you know, with Python lessons and so forth,

13:58.920 --> 14:02.640
maybe it's instead helping them to understand

14:02.640 --> 14:05.480
how to ask great questions or give great directions or prompts.

14:05.480 --> 14:07.720
Yeah, like with this, this is a technological marvel

14:07.720 --> 14:10.160
that we've sped up 100 times, because we have amazing developers,

14:10.160 --> 14:12.680
and we have communities of hundreds of thousands.

14:12.680 --> 14:16.960
I went to GPT4, and I said, help me write some code

14:16.960 --> 14:19.360
to change the nature of inference

14:19.360 --> 14:22.400
to something called int8 to int4, which is only a year old,

14:22.400 --> 14:24.360
so it's not in the data set.

14:24.360 --> 14:25.640
And it figured it out, and it worked.

14:25.640 --> 14:26.120
It figured it out.

14:26.120 --> 14:26.520
Awesome.

14:26.520 --> 14:27.080
Straight out.

14:27.080 --> 14:29.240
I asked it to create asteroids in D3.

14:29.240 --> 14:29.720
I love asteroids.

14:29.720 --> 14:30.600
We're the high school thing.

14:30.600 --> 14:30.840
Yeah.

14:30.840 --> 14:33.480
And I copy-pasted it, and it worked the game straight out.

14:33.480 --> 14:34.920
So again, we have to kind of think about this,

14:34.920 --> 14:36.440
and we have to think, but what can you do?

14:36.440 --> 14:38.360
Well, the answer is you can do anything now.

14:38.400 --> 14:42.080
Because a lot of the stuff that blocks you isn't there anymore.

14:42.080 --> 14:44.200
Any of you can now be creative.

14:44.200 --> 14:47.480
Any of you can now build systems.

14:47.480 --> 14:49.960
And so you build the systems that adhere

14:49.960 --> 14:53.680
to the unchanging demands of people to make their lives better.

14:53.680 --> 14:56.440
And that's value, and they'll pay you for that value.

14:56.440 --> 14:59.280
We're all creators, and we're, in fact,

14:59.280 --> 15:02.200
we had Will I Am last night at our patron dinner,

15:02.200 --> 15:07.920
who's this incredible creative energy across all modalities.

15:07.920 --> 15:10.960
And all of a sudden, you're not restricted by what

15:10.960 --> 15:12.760
you learned in school.

15:12.760 --> 15:15.640
You can bring the best to anything you desire.

15:15.640 --> 15:16.600
It's the best to anything done.

15:16.600 --> 15:17.440
You can control it.

15:17.440 --> 15:19.520
So you can just say, take something

15:19.520 --> 15:22.880
and change it to its original form, like this.

15:22.880 --> 15:25.040
From mindset to materialization.

15:25.040 --> 15:27.560
Which version of you do you like best?

15:27.560 --> 15:28.320
Exactly.

15:28.320 --> 15:29.600
And this is just with words.

15:29.600 --> 15:30.480
There's no more prompts.

15:30.480 --> 15:33.200
I just say, I want to change it to this or that.

15:33.200 --> 15:37.360
And it happens instantly now with a new version.

15:38.000 --> 15:40.280
You can say, let's do dynamic adaptation.

15:40.280 --> 15:42.000
Again, it happens in one second.

15:42.000 --> 15:44.960
You generate all of these variants.

15:44.960 --> 15:46.240
And you don't need those prompts.

15:46.240 --> 15:48.280
People say, there's all these magical spells.

15:48.280 --> 15:48.880
You don't say that.

15:48.880 --> 15:52.160
You say, I want to turn Woody into a still from a Western,

15:52.160 --> 15:54.160
or a place of fruit with cake.

15:54.160 --> 15:55.560
So it also becomes more natural.

15:55.560 --> 15:57.840
What are interfaces in the future?

15:57.840 --> 15:58.920
Interfaces are nothing.

15:58.920 --> 16:01.080
It's all about human extension.

16:01.080 --> 16:03.120
And it's about information theories

16:03.120 --> 16:04.320
at the core of all computer science.

16:04.320 --> 16:06.360
Information is valuable in as much

16:06.360 --> 16:07.880
as it changes the state.

16:07.880 --> 16:10.760
Now we finally have a friend to be with us all the time

16:10.760 --> 16:12.560
that can bring us the most valuable information

16:12.560 --> 16:14.040
and the most valuable state changes.

16:14.040 --> 16:17.480
You're a 20-year-old on our Zoom audience here,

16:17.480 --> 16:19.280
or in the room, or 23-year-old.

16:19.280 --> 16:23.040
And you're trying to decide what to do now.

16:23.040 --> 16:24.560
What is your advice?

16:24.560 --> 16:26.360
You just throw yourself 100% into this.

16:26.360 --> 16:29.280
It's the biggest change in society ever.

16:29.280 --> 16:31.400
It will be more disruptive than the pandemic

16:31.400 --> 16:32.320
in the next year or so.

16:32.320 --> 16:35.680
And I led the United Nations AI Initiative against COVID-19,

16:35.720 --> 16:38.360
Kayak, helping organize the world's COVID knowledge

16:38.360 --> 16:40.160
and making it accessible and useful.

16:40.160 --> 16:41.400
So I saw that coming.

16:42.440 --> 16:44.320
It'll be for positive and negative,

16:44.320 --> 16:46.200
because you can do things that can never be heard of.

16:46.200 --> 16:49.320
As an example, we have an upscaler.

16:49.320 --> 16:52.840
It goes from 128 pixels to 4K in 1.5 seconds.

16:54.040 --> 16:54.880
That to that.

16:55.720 --> 16:56.560
That's amazing.

16:56.560 --> 16:58.600
What can you do with that?

16:58.600 --> 16:59.440
This is the thing.

16:59.440 --> 17:01.400
You are given now the recipes and tools.

17:01.400 --> 17:02.800
What can you do?

17:02.800 --> 17:05.120
So there's gonna be a thousand companies

17:05.120 --> 17:07.080
spending $10 million each this year.

17:07.080 --> 17:09.120
I spoke to one of the big four accounting firms.

17:09.120 --> 17:10.400
They were like, do we need auditors anymore?

17:10.400 --> 17:12.080
I'm like, probably not as many.

17:13.280 --> 17:14.120
All right?

17:14.120 --> 17:14.960
And then they said, okay,

17:14.960 --> 17:17.600
we're gonna spend $300 million in the next two quarters

17:17.600 --> 17:19.520
trying to figure this out.

17:19.520 --> 17:22.680
But that's times many, many firms.

17:22.680 --> 17:24.560
Everything everywhere, all at once.

17:24.560 --> 17:25.920
And again, this is the emeticness.

17:25.920 --> 17:27.160
We've seen this type of thing happen

17:27.160 --> 17:29.680
like with the Silicon Valley Bank collapse.

17:29.680 --> 17:31.120
Society's become more and more connected.

17:31.120 --> 17:32.560
And we've talked about expert systems.

17:32.560 --> 17:34.640
How long have we talked about expert systems for?

17:34.640 --> 17:35.480
Yeah, a bit.

17:35.480 --> 17:36.320
Yolks.

17:36.320 --> 17:37.840
They're here now, right?

17:37.840 --> 17:41.000
And again, this is why you can do these crazy things.

17:41.000 --> 17:42.840
Like, why don't you create your own studio?

17:42.840 --> 17:45.360
So, how do we play this?

17:45.360 --> 17:46.600
We play this video.

17:46.600 --> 17:48.960
You speak and it magically happens.

17:48.960 --> 17:50.120
Play.

17:50.120 --> 17:50.960
There you go.

17:51.840 --> 17:53.680
This is a video of rock, paper, scissors

17:53.680 --> 17:55.880
that was done using our technology by two guys

17:55.880 --> 17:57.240
in like four days.

17:57.240 --> 17:58.640
And it's a whole seven minute video

17:58.640 --> 18:00.000
at this level of quality.

18:01.280 --> 18:02.280
That's all you need.

18:02.280 --> 18:04.440
So why not create amazing kind of videos

18:04.440 --> 18:05.680
and things like that?

18:05.680 --> 18:07.360
But we're gonna get to a point soon enough

18:07.360 --> 18:09.080
and I'll ask for your prediction where I can say,

18:09.080 --> 18:13.320
I want a movie about this theme, 90 minutes long,

18:13.320 --> 18:15.740
starring my favorite stars.

18:16.920 --> 18:18.680
How, when do we see that?

18:18.680 --> 18:19.680
That's why it's a movie.

18:19.680 --> 18:21.600
I think you get there in the next couple of years.

18:21.600 --> 18:22.960
Like rock, paper, scissors too.

18:22.960 --> 18:24.400
Again, look it up on Google.

18:24.400 --> 18:26.760
We'll be five times as fast.

18:26.760 --> 18:28.920
The next version will be fully generated

18:28.920 --> 18:30.400
by putting a script in.

18:30.400 --> 18:32.160
I mean, like this one, if you press play

18:32.160 --> 18:33.320
and it automatically generates

18:33.320 --> 18:34.320
a loop music lyric video.

18:34.320 --> 18:35.840
So unfortunately we don't have sound,

18:35.840 --> 18:38.600
but you can go on Deep Floyd AI on Twitter and see it.

18:38.600 --> 18:41.640
Automatically generated kind of this music lyric video.

18:43.120 --> 18:44.400
Just from a song input

18:44.400 --> 18:46.960
with the entire kind of style of this as well.

18:46.960 --> 18:48.680
So everyone here is a filmmaker.

18:48.680 --> 18:50.720
I mean, for me, we have a common passion

18:50.720 --> 18:53.240
in disrupting and reinventing education.

18:54.240 --> 18:57.920
Where I can have in a virtual world,

18:57.920 --> 18:59.640
learn about anything I want,

18:59.680 --> 19:03.600
a time machine to go and have my favorite characters

19:03.600 --> 19:05.640
teaching me about what anything I need.

19:06.680 --> 19:08.160
And that's two years away.

19:08.160 --> 19:10.200
Yeah, I mean, that actually might be here right now.

19:10.200 --> 19:12.000
I mean, again, kind of you've seen glasses,

19:12.000 --> 19:15.000
three 3D displays and all sorts of crazy things.

19:15.000 --> 19:17.800
But one of the things with this is contextualization.

19:17.800 --> 19:19.160
Because again, we are the stories we make.

19:19.160 --> 19:20.880
So one of the things we're working on that's quite fun

19:20.880 --> 19:25.400
is can you remake Game of Thrones as a J-Drama from Korea?

19:26.760 --> 19:29.440
So you're going to end the character's turn Korean, right?

19:29.680 --> 19:32.160
I'm also trying to get George R.R. Martin and H.V.O.

19:32.160 --> 19:34.240
to let me remake Game of Thrones season eight,

19:34.240 --> 19:35.560
because it was terrible.

19:38.080 --> 19:39.800
Yeah, and actually it's very interesting why.

19:39.800 --> 19:41.920
Because Game of Thrones season one to seven,

19:41.920 --> 19:44.600
everyone had agency and the meaning was in the interaction

19:44.600 --> 19:46.720
between our stories or the characters.

19:46.720 --> 19:48.440
Whereas the last one tried to get us to an ending

19:48.440 --> 19:50.200
and so it felt so disjointed.

19:50.200 --> 19:51.480
So I'm like, I'll help you write your book.

19:51.480 --> 19:53.240
We have the script writing AI coming out

19:53.240 --> 19:54.920
and a book writing AI coming out.

19:54.920 --> 19:56.240
And so we can tell better stories

19:56.240 --> 19:57.560
that are more empathetic and engaging.

19:57.560 --> 20:00.160
Because again, this is more engaging for the thing.

20:00.160 --> 20:02.280
You can customize your thing everywhere.

20:03.440 --> 20:05.400
You can customize to every learner.

20:05.400 --> 20:06.360
How crazy is that?

20:06.360 --> 20:07.200
And there's even crazy.

20:07.200 --> 20:09.120
All at once, a brand new theme.

20:09.120 --> 20:11.720
Iman, let's imagine you're in the audience here,

20:11.720 --> 20:14.920
you're a business owner, entrepreneur, CEO,

20:14.920 --> 20:19.920
and what do you do next?

20:19.920 --> 20:20.960
I think what you have to do next again

20:20.960 --> 20:21.800
is kind of what you said.

20:21.800 --> 20:23.120
You need to have a dedicated,

20:23.120 --> 20:24.440
there's nothing more important

20:24.440 --> 20:26.160
in your entire business than this.

20:26.160 --> 20:27.000
Yeah.

20:27.200 --> 20:29.400
So I want to echo that, right?

20:29.400 --> 20:31.520
Today, the world changes.

20:31.520 --> 20:32.920
Electricity is made available,

20:32.920 --> 20:34.640
the telephone is made available,

20:34.640 --> 20:35.800
the internet is made available,

20:35.800 --> 20:39.560
and this is all of those things together,

20:39.560 --> 20:40.600
all at once everywhere.

20:40.600 --> 20:41.840
Yeah, this is 5G.

20:41.840 --> 20:43.120
This is bigger than 5G.

20:43.120 --> 20:44.640
Over a trillion dollars went to 5G,

20:44.640 --> 20:45.840
more will go into here.

20:45.840 --> 20:46.800
Actually, I'll give you an example,

20:46.800 --> 20:48.640
because again, it's always the unchanging

20:48.640 --> 20:50.600
versus the inevitable, right?

20:50.600 --> 20:53.440
I gave the whole of stability AI

20:53.440 --> 20:54.480
the week off at the end of the year,

20:54.480 --> 20:56.000
because I was like, holy crap, you're doing a lot, right?

20:56.000 --> 20:57.160
Because we do everything, right?

20:57.160 --> 20:59.600
And we do it with, we only have 150 people,

20:59.600 --> 21:00.840
yet we do every modality

21:00.840 --> 21:02.320
because we have the power of community

21:02.320 --> 21:05.200
and open behind us, setting the standard.

21:05.200 --> 21:06.440
So I give the whole team the week off,

21:06.440 --> 21:09.480
said go to sleep, turned off all the things,

21:09.480 --> 21:11.480
because you're all going to die

21:11.480 --> 21:12.920
if you don't get some rest.

21:12.920 --> 21:14.640
So of course, business side of covered that.

21:14.640 --> 21:16.640
Stability AI CEO, I'm Adam Mostak,

21:16.640 --> 21:17.480
compared to Open AI,

21:17.480 --> 21:19.440
it says you're all going to die in 2023.

21:21.440 --> 21:22.240
What are we doing?

21:22.240 --> 21:23.680
We might be make press as well.

21:23.680 --> 21:24.520
What can I say?

21:25.520 --> 21:27.960
But then what happened is I was just chilling

21:27.960 --> 21:31.480
and I got like five calls from headmasters of UK schools.

21:32.640 --> 21:34.840
Emma, what's our generative AI strategy?

21:34.840 --> 21:37.040
I was like, what?

21:37.040 --> 21:41.040
All our children are using chat GPT to do their homework essays.

21:41.040 --> 21:44.280
I was like, don't set homework essays, get good.

21:44.280 --> 21:46.600
So again, homework is never the same

21:46.600 --> 21:48.680
for every teacher all at once.

21:48.680 --> 21:49.680
And so you have to look at your industry

21:49.680 --> 21:50.960
and again, what will not be the same

21:50.960 --> 21:53.400
when you have the ability to scale humans?

21:53.440 --> 21:55.600
This is the question that you have to ask yourself.

21:55.600 --> 21:58.960
Like an eaten now, a bastion of British education,

21:58.960 --> 22:01.720
they do their essays live by hand,

22:01.720 --> 22:02.680
because I told them to do that,

22:02.680 --> 22:03.640
because I went to Westminster,

22:03.640 --> 22:05.160
who I told to embrace the technology.

22:06.160 --> 22:08.000
It arrived at me, right?

22:08.000 --> 22:09.360
So again, it says Peter says,

22:09.360 --> 22:10.800
there will only be companies that embrace AI

22:10.800 --> 22:12.000
and those who don't.

22:12.000 --> 22:13.160
I think the way that it pays out,

22:13.160 --> 22:14.880
because I was a hedge fund manager,

22:14.880 --> 22:16.880
invested tens of billions of dollars,

22:16.880 --> 22:18.960
you know, like I understand markets as well,

22:18.960 --> 22:23.160
is that if you are in something that's a SaaS company,

22:23.240 --> 22:24.760
you're gonna have to really think hard,

22:24.760 --> 22:27.720
because GPT-4, for example,

22:27.720 --> 22:29.240
and again, we'll have our equivalent of that,

22:29.240 --> 22:30.320
but we're taking a different approach

22:30.320 --> 22:32.360
of swarm intelligence versus general,

22:32.360 --> 22:35.840
has a 32,000 token context window,

22:35.840 --> 22:39.640
which means you can feed it 20,000 words of instructions.

22:39.640 --> 22:41.480
Well, what is OpenAI at right now?

22:41.480 --> 22:43.120
That's their one, GPT-4.

22:43.120 --> 22:44.960
The one that they, OpenAI is the best language.

22:44.960 --> 22:46.760
And all you should use OpenAI,

22:46.760 --> 22:48.560
and you should use our models coming up as well,

22:48.560 --> 22:52.240
private data and general data, hybrid AI, you know?

22:52.240 --> 22:55.120
But that means you can basically tell it all of HR

22:55.120 --> 22:56.720
instructions for something like Workday.

22:56.720 --> 22:58.160
What does Workday do then?

22:59.240 --> 23:02.160
Because it can be replaced by a single 200 megabyte file.

23:02.160 --> 23:04.120
Which you can query on your laptop or your phone.

23:04.120 --> 23:05.920
Well, yeah, eventually, but not now,

23:05.920 --> 23:07.040
but it just doesn't matter.

23:07.040 --> 23:08.840
It costs like $2 for query, right?

23:08.840 --> 23:09.680
Right.

23:09.680 --> 23:10.800
I mean, it's insane.

23:10.800 --> 23:11.960
So, but then you have to think,

23:11.960 --> 23:13.240
if you're in a regulated industry,

23:13.240 --> 23:14.640
how's super normal margins?

23:15.600 --> 23:17.440
You know, if you're in a creative industry,

23:17.440 --> 23:19.640
again, you can basically either embrace it

23:19.640 --> 23:22.400
to have higher revenue, cheaper costs, or not.

23:22.400 --> 23:23.400
Like I give you an example,

23:23.400 --> 23:27.680
one of our movie directors did a film,

23:27.680 --> 23:29.200
who actually, I can't give you an example.

23:29.200 --> 23:30.320
Let's just say millions of dollars

23:30.320 --> 23:33.040
are being saved at the moment using this technology.

23:33.040 --> 23:34.800
And again, you just have to really think through it.

23:34.800 --> 23:37.320
So, going back to our audience here,

23:37.320 --> 23:39.760
who, you know, use technology,

23:39.760 --> 23:43.560
but don't have AI embedded in their DNA.

23:43.560 --> 23:46.600
I've shared the idea of having a chief AI officer

23:46.600 --> 23:48.160
who's really a strategist for you,

23:48.160 --> 23:50.480
because you're not building your own AIs,

23:50.480 --> 23:53.640
you're deciding which platforms to use, right?

23:53.640 --> 23:54.480
Yeah.

23:54.480 --> 23:56.720
And again, a very few companies will build their own AI.

23:56.720 --> 23:58.440
So, I think it'll just be Google, Microsoft,

23:58.440 --> 24:00.560
OpenAI, and us that build the foundation models

24:00.560 --> 24:02.600
that everyone uses, because you don't need to.

24:02.600 --> 24:04.080
Because again, it's like,

24:04.080 --> 24:06.160
where the university is churning out

24:06.160 --> 24:08.800
the most amazing graduates, effectively.

24:08.800 --> 24:10.160
You know, some of them you can borrow,

24:10.160 --> 24:12.000
and they're specialized by those guys,

24:12.000 --> 24:14.120
and some of them you can hire yourself,

24:14.120 --> 24:16.880
through your GPUs, or kind of whatever.

24:16.880 --> 24:19.040
My suggestion is that that, what's the,

24:19.040 --> 24:21.280
but the thing is, how do you find that person?

24:21.280 --> 24:22.120
Hmm.

24:22.120 --> 24:23.720
You know, and until they're an AI.

24:23.720 --> 24:24.840
No, how do you find that person?

24:24.840 --> 24:25.680
Advice?

24:25.680 --> 24:27.360
The advice is, you need to first find someone

24:27.360 --> 24:30.160
who's passionate about this, because this is so new.

24:30.160 --> 24:31.760
So, one of the things that makes us different

24:31.760 --> 24:33.360
is that we're a community-based organization.

24:33.360 --> 24:34.960
We came out of a community.

24:34.960 --> 24:37.520
So, we have developers, one of them was an Amazon warehouse

24:37.520 --> 24:39.440
worker last year, and taught himself how to code.

24:39.440 --> 24:40.280
Nice.

24:40.280 --> 24:42.120
Another one's a 19-year-old, 50-year PhD

24:42.120 --> 24:44.000
with three graduate degrees, you know?

24:44.000 --> 24:46.600
It'll be clear, it's not gonna be the person

24:46.680 --> 24:49.160
who is traditionally the person you would think about.

24:49.160 --> 24:50.320
It is driven by passion.

24:50.320 --> 24:51.160
It's driven by passion.

24:51.160 --> 24:53.520
Everyone here understands the importance of passion,

24:53.520 --> 24:54.640
and passion is what you need for this,

24:54.640 --> 24:57.160
because this is a regime change.

24:57.160 --> 24:59.160
It is not more of what came before.

24:59.160 --> 25:00.480
So, you have to throw yourself in it,

25:00.480 --> 25:03.240
and have that flexibility of mind.

25:03.240 --> 25:04.680
And the key thing is, can it bring you

25:04.680 --> 25:07.120
what the next thing is for your industry?

25:07.120 --> 25:08.120
You know?

25:08.120 --> 25:10.920
Everybody, this is Peter, a quick break from the episode.

25:10.920 --> 25:14.000
I'm a firm believer that science and technology,

25:14.000 --> 25:16.680
and how entrepreneurs can change the world,

25:16.680 --> 25:20.000
is the only real news out there worth consuming.

25:20.000 --> 25:22.160
I don't watch the Crisis News Network.

25:22.160 --> 25:25.520
I call CNN or Fox, and hear every devastating piece

25:25.520 --> 25:26.880
of news on the planet.

25:26.880 --> 25:29.960
I spend my time training my neural net,

25:29.960 --> 25:31.480
the way I see the world,

25:31.480 --> 25:34.400
by looking at the incredible breakthroughs in science

25:34.400 --> 25:36.160
and technology, and how entrepreneurs

25:36.160 --> 25:38.400
are solving the world's grand challenges,

25:38.400 --> 25:41.200
what the breakthroughs are in longevity,

25:41.200 --> 25:45.120
how exponential technologies are transforming our world.

25:45.120 --> 25:47.400
So, twice a week, I put out a blog.

25:47.400 --> 25:50.720
One blog is looking at the future of longevity,

25:50.720 --> 25:54.960
age reversal, biotech, increasing your health span.

25:54.960 --> 25:59.080
The other blog looks at exponential technologies, AI,

25:59.080 --> 26:02.440
3D printing, synthetic biology, AR, VR, blockchain.

26:02.440 --> 26:04.120
These technologies are transforming

26:04.120 --> 26:05.720
what you as an entrepreneur can do.

26:05.720 --> 26:07.800
If this is the kind of news you wanna learn about,

26:07.800 --> 26:09.600
and shape your neural nets with,

26:09.640 --> 26:14.200
go to dmandis.com, backslash blog, and learn more.

26:14.200 --> 26:15.640
Now, back to the episode.

26:15.640 --> 26:18.480
We share a moonshot in education.

26:18.480 --> 26:21.080
I've had the ability to support, to some degree,

26:21.080 --> 26:22.360
what you're doing.

26:22.360 --> 26:25.640
Just chat one second about your vision on Malawi.

26:25.640 --> 26:29.080
Yeah, so, you know, X Prize for Learning,

26:29.080 --> 26:31.760
fantastic prize by Tony, who's here next week tomorrow,

26:31.760 --> 26:33.760
I think, and then Elon Musk.

26:33.760 --> 26:34.600
Yeah.

26:34.600 --> 26:36.280
For the first app that could teach literacy and numeracy

26:36.280 --> 26:38.840
in 18 months without internet.

26:38.880 --> 26:40.600
We've been deploying that into refugee camps,

26:40.600 --> 26:42.520
the winner of that, all around the world,

26:42.520 --> 26:44.560
from Rohingya to Malawi to Kenya,

26:44.560 --> 26:48.520
and we're teaching 76% of kids literacy and numeracy

26:48.520 --> 26:50.680
in one hour a day in 13 months,

26:50.680 --> 26:53.480
in the worst places in the world with adaptive learning.

26:53.480 --> 26:54.960
Yeah, let's give it up for this.

26:54.960 --> 26:55.800
Yeah.

26:58.800 --> 27:02.800
That's been the core of Elon's passion and moonshot,

27:02.800 --> 27:04.320
but he's taking it a step further.

27:04.320 --> 27:07.440
Taking it a step further, because by doing that,

27:07.480 --> 27:08.880
this is without this AI.

27:09.800 --> 27:11.720
So we work with the Malawi in government,

27:11.720 --> 27:13.280
as the first, for example,

27:13.280 --> 27:15.320
we're feeding 30% of all the kids in Malawi,

27:15.320 --> 27:17.960
we're gonna go to 100% and give every child in Malawi

27:17.960 --> 27:19.160
their own AI.

27:19.160 --> 27:20.280
I wanna call it one AI for a child,

27:20.280 --> 27:21.440
but I've been told not to.

27:22.440 --> 27:25.040
And that's kind of what our charity Imagine Worldwide,

27:25.040 --> 27:26.680
but then we've built a special type of bond

27:26.680 --> 27:27.920
with the World Bank and UBS,

27:27.920 --> 27:29.480
whereby you put down $20 million,

27:29.480 --> 27:32.360
you only pay if a million kids are provably educated.

27:33.640 --> 27:35.320
And so we're gonna use that,

27:35.320 --> 27:36.440
and the World Bank pays up front,

27:36.440 --> 27:37.640
and then you can have it in your pension fund

27:37.640 --> 27:39.200
and see how a million kids are doing.

27:39.200 --> 27:40.840
We're gonna use that to scale these tablets,

27:40.840 --> 27:42.480
plus high-speed internet in every school,

27:42.480 --> 27:44.520
to every child across Africa.

27:44.520 --> 27:46.160
Nine out of 10 kids in Africa

27:46.160 --> 27:48.640
cannot read and write a sentence by the age of 10.

27:48.640 --> 27:50.880
What happens when they all have their own AI

27:50.880 --> 27:51.920
that works for them,

27:51.920 --> 27:54.440
that's in as intelligent as chat GPT,

27:54.440 --> 27:56.200
and healthcare on that tablet?

27:56.200 --> 27:57.040
Yes.

27:57.040 --> 27:59.280
The AI teaches the kids, learns from the kids,

27:59.280 --> 28:01.120
and that will also create the national models

28:01.120 --> 28:02.280
for every country.

28:02.280 --> 28:04.080
Right now, we hold the eyes open of the AI,

28:04.080 --> 28:05.480
and we teach the whole internet,

28:05.520 --> 28:08.480
which is why it goes a bit crazy, you know?

28:08.480 --> 28:09.760
And again, we use reinforcement learning

28:09.760 --> 28:10.800
and other things to guide it.

28:10.800 --> 28:11.960
This will be different.

28:11.960 --> 28:14.640
So that technology scales.

28:14.640 --> 28:16.880
Again, there's nothing more as impactful

28:16.880 --> 28:18.000
as one-to-one tuition,

28:18.000 --> 28:19.920
and now we can do it in an empathetic way

28:19.920 --> 28:21.400
that adapts to each child.

28:21.400 --> 28:23.120
I believe that we can also address things

28:23.120 --> 28:24.280
like dyslexia and other things,

28:24.280 --> 28:26.240
so it's just information processing.

28:26.240 --> 28:27.240
And you will see that coming.

28:27.240 --> 28:29.440
We're doing a big drive towards that.

28:29.440 --> 28:32.040
Any information processing issues will be solved by this.

28:32.040 --> 28:33.720
Are you an auditory learner, visual learner?

28:33.720 --> 28:34.760
There are no more interfaces.

28:34.760 --> 28:36.360
So it's completely customized learning

28:36.360 --> 28:37.480
for the individual,

28:37.480 --> 28:39.320
their favorite color sports star,

28:39.320 --> 28:40.640
way of learning modality,

28:40.640 --> 28:43.880
knows exactly where they are and where they need to go.

28:43.880 --> 28:46.640
Building the foundation to activate humanity's potential.

28:46.640 --> 28:49.600
And so we're gonna open source on new language models

28:49.600 --> 28:51.520
in our next month,

28:51.520 --> 28:54.480
and then we're gonna announce the next generation of this.

28:54.480 --> 28:57.160
An open model for all of the world

28:57.160 --> 28:58.720
that you deserve for education and health

28:58.720 --> 29:01.240
and other things, because humans are humans.

29:01.240 --> 29:03.480
Bring them the information that creates the most value

29:03.480 --> 29:05.000
and you will change the world.

29:06.280 --> 29:09.560
Is this gonna revolutionize healthcare to the point of...

29:09.560 --> 29:11.560
Yes, let's give it up for Imad on that one, yes?

29:11.560 --> 29:12.400
Yes.

29:12.400 --> 29:13.240
Yes.

29:16.240 --> 29:17.840
You got just two minutes left here, health,

29:17.840 --> 29:19.240
and then you're coming back to the Q&A,

29:19.240 --> 29:20.120
which will be the fun part,

29:20.120 --> 29:22.080
because the audience gets to participate.

29:23.280 --> 29:25.320
I've always talked about the best diagnosticians,

29:25.320 --> 29:27.560
the best healthcare is gonna be AI,

29:27.560 --> 29:29.400
which is gonna level the playing field,

29:29.400 --> 29:31.480
the poorest child, the wealthiest child,

29:31.480 --> 29:34.120
at the same level across the board, yes?

29:34.120 --> 29:35.560
Humans are humans.

29:35.560 --> 29:37.320
This is why I kind of did the Kayak project,

29:37.320 --> 29:38.160
lots of years ago.

29:38.160 --> 29:39.600
What a great advantage that is.

29:39.600 --> 29:43.120
It's a huge advantage, and again, this is the thing.

29:43.120 --> 29:45.680
This is the great equalizer, or it's the great controller,

29:45.680 --> 29:48.040
which is why I'm open versus closed.

29:48.040 --> 29:49.960
This cannot be controlled by any entity.

29:49.960 --> 29:51.560
We have to distribute this,

29:51.560 --> 29:53.520
because I believe this is a human right,

29:53.520 --> 29:55.920
because it's the next element we're gonna introduce you.

29:55.920 --> 30:00.920
So, speaking about that,

30:01.280 --> 30:04.040
we're in the middle of the AI wars,

30:04.040 --> 30:06.720
and a little rumor told me

30:06.720 --> 30:08.560
that you got kicked off LinkedIn today.

30:08.560 --> 30:12.200
Yeah, they identified our website as Malware first last week,

30:12.200 --> 30:13.560
and then made all our job descriptions.

30:13.560 --> 30:14.400
Today we're going to be kids.

30:14.400 --> 30:15.440
Who owns LinkedIn, by the way?

30:15.440 --> 30:16.480
I couldn't say.

30:17.320 --> 30:19.120
Oh, Microsoft, huh?

30:20.400 --> 30:21.600
So, it's gonna be very interesting.

30:21.600 --> 30:23.400
The stakes are really high.

30:23.400 --> 30:24.440
So, there's a lot of people

30:24.440 --> 30:26.920
that don't want this technology to go out to the world.

30:26.920 --> 30:29.000
Again, I think putting it on these tablets

30:29.000 --> 30:31.680
for all these kids, building a national mold to everyone,

30:31.680 --> 30:34.040
again, our mission is to build the foundation

30:34.040 --> 30:36.080
to activate humanized potential,

30:36.080 --> 30:37.640
and our motto is not, don't be evil,

30:37.640 --> 30:39.160
let's make people happier.

30:39.160 --> 30:41.720
And the happiest you can be is when you have agency.

30:41.720 --> 30:43.200
Let everyone have their own agency

30:43.200 --> 30:45.600
and create insane things.

30:45.600 --> 30:48.160
On that note, let's give it up for Emon Scott.

30:48.160 --> 30:49.000
Good.

30:49.000 --> 30:49.840
Good.

