1
00:00:00,000 --> 00:00:09,520
Great. So what I was hoping, Carla, is that we could get your thoughts on how the whole

2
00:00:09,520 --> 00:00:15,800
Active Inference Framework could be applied to something that we've been developing. And

3
00:00:15,800 --> 00:00:18,680
I don't know if you had a chance to look at any of this stuff, but I'll just give you

4
00:00:18,680 --> 00:00:24,160
a brief, you know, kind of a brief summary so that it's clear what we've got. And then

5
00:00:24,160 --> 00:00:28,680
I have some basic questions and then a couple of wacky ideas to kind of bounce off of you

6
00:00:28,680 --> 00:00:35,040
and see what you think. So the basic thing is this, that what I was trying to do is to

7
00:00:35,040 --> 00:00:47,200
have a very basal model of distributed intelligence. And the idea was that we were interested in

8
00:00:47,200 --> 00:00:52,240
unexpected competencies in places where unlike in biology, you know, in biology, no matter

9
00:00:52,240 --> 00:00:56,040
how simple your model, you never have all the information about mechanisms and somebody

10
00:00:56,040 --> 00:00:59,560
can always say, well, there is a mechanism for that, you just haven't found it yet, right?

11
00:00:59,560 --> 00:01:05,880
So we wanted something that was incredibly simple, incredibly transparent, deterministic,

12
00:01:05,880 --> 00:01:09,480
something that everybody thinks they know what it does. And then we can, we can apply

13
00:01:09,480 --> 00:01:13,600
some of the approaches that we take in my lab about taking something that doesn't seem

14
00:01:13,600 --> 00:01:18,320
cognitive and saying, okay, but what, what actual competencies might it have, right?

15
00:01:18,320 --> 00:01:22,520
And so we chose this thing called sorting algorithms. And so these are the same simple

16
00:01:22,520 --> 00:01:25,720
algorithms that all computer science students study for, you know, and they've been studied

17
00:01:25,720 --> 00:01:32,440
for decades. And then we made a couple of, a couple of twists to it. One is that we visualize

18
00:01:32,440 --> 00:01:38,560
their progress from being a jumbled set of digits to an ordered set of digits as a kind

19
00:01:38,560 --> 00:01:42,240
of a traversal of space, right? So the idea is they start in different locations and they

20
00:01:42,240 --> 00:01:47,800
all sooner or later, they all end up in one location where everything is. And so once,

21
00:01:47,800 --> 00:01:51,320
once you view it as navigating that space, then you can ask some questions about what

22
00:01:51,360 --> 00:01:55,520
are their competencies and navigating that space under, under odd perturbations. One

23
00:01:55,520 --> 00:02:02,400
of the perturbations that we made was the introduction of what we call broken cells or

24
00:02:02,400 --> 00:02:06,960
barriers in the space. So if the algorithm wants to swap two numbers in order to proceed

25
00:02:06,960 --> 00:02:10,680
in its, in its sorting trajectory, well, one of the numbers could be broken, it doesn't

26
00:02:10,680 --> 00:02:14,640
move, you can't, you can't move. And so, and we have two kinds of broken numbers, ones

27
00:02:14,640 --> 00:02:20,840
that never initiate swaps and ones that actually never, never swapped no matter, you know,

28
00:02:20,880 --> 00:02:27,120
who initiates them. And so that allows us to ask questions about things like delayed

29
00:02:27,120 --> 00:02:31,640
gratification. In other words, can it go further from it? If it encounters a barrier,

30
00:02:31,640 --> 00:02:36,200
can it go further away from its goal in order to then acquire gains afterwards? And this

31
00:02:36,200 --> 00:02:40,560
is, you know, William James talked about this, of course, as, as an important type of basal

32
00:02:40,560 --> 00:02:44,680
intelligence. And, and that, and that breaks a common assumption with these algorithms,

33
00:02:44,680 --> 00:02:49,760
which is typically you assume that the material is, is robust. In other words, when you, when

34
00:02:49,760 --> 00:02:55,440
an algorithm says to do something, it gets done. But, but in our case, not necessarily. And

35
00:02:55,440 --> 00:03:00,080
we never introduced, this is important, we never introduced any extra code to check if

36
00:03:00,080 --> 00:03:04,400
things got done. It's, it's the standard algorithm. So it just keeps on rolling. There is no

37
00:03:04,400 --> 00:03:09,240
code to see how am I doing? Did things work out? No, no code for any of that. The second

38
00:03:09,240 --> 00:03:15,200
thing we did was to break the, the, the general version of this is centralized. So there's

39
00:03:15,200 --> 00:03:18,840
like this omniscient controller, and it's following one of several algorithms to kind

40
00:03:18,880 --> 00:03:23,800
of move numbers around. And we got rid of that and instead made it all bottom up. So every

41
00:03:23,800 --> 00:03:30,000
digit, aka every cell now has its own version of the algorithm running, and it has a limited

42
00:03:30,000 --> 00:03:34,520
local view of who its neighbors are. And it's just following the steps of the algorithm to

43
00:03:34,520 --> 00:03:39,240
try to improve its local environment, that there is no more global, global control. So

44
00:03:39,240 --> 00:03:45,280
it's distributed. And, and, and, you know, we learned a few things. We learned that a, the

45
00:03:45,280 --> 00:03:49,840
distributed version of this works quite well. It actually, you know, they do sort nicely. So,

46
00:03:49,840 --> 00:03:54,040
so that's great. We did see some delayed gratification in the sense that if you, if you

47
00:03:54,040 --> 00:03:59,440
sprinkle in some broken cells, it actually will go backwards and unsort the string a little bit,

48
00:03:59,440 --> 00:04:05,320
and it's effort to then go around the defect as it were. So that's kind of cool. But the most

49
00:04:05,360 --> 00:04:12,760
kind of surprising thing, which is what I'd love to get your take on is this. We, because now

50
00:04:12,800 --> 00:04:17,440
it's distributed and every cell is following its own algorithm, that enables us to do an

51
00:04:17,440 --> 00:04:21,640
experiment that otherwise you couldn't do, which is to make a chimeric string. And it's what we do

52
00:04:21,640 --> 00:04:25,800
in developmental biology, when we put together, you know, axolotl cells and frog cells, and now

53
00:04:25,800 --> 00:04:29,280
you get this frog a lot, and you can ask questions like, well, what shape is it going to have,

54
00:04:29,280 --> 00:04:34,600
right? So, so what you can make is a chimeric string where some of the numbers are following one

55
00:04:34,600 --> 00:04:39,240
algorithm, some of them are following a different algorithm. And again, there is this is important,

56
00:04:39,240 --> 00:04:45,440
there is no code to determine either your own or your neighbor's algotype. And algotype is the

57
00:04:45,440 --> 00:04:49,480
word that Adam coined for this, like, you know, what algorithm, what set of properties are you

58
00:04:49,480 --> 00:04:53,160
actually following a policy? Is it actually following? So there is no code for any of that,

59
00:04:53,160 --> 00:05:00,240
but we know which, which algotype all the cells. So that, and that also works. So chimeric strings

60
00:05:00,240 --> 00:05:05,400
also sort, sort the, sort the arrays, and that's fine. What we then did was we asked basically a

61
00:05:05,400 --> 00:05:09,600
developmental biology question was to say, okay, at any particular point during its journey,

62
00:05:09,600 --> 00:05:15,680
what is the distribution of algotypes within the string? And what we know, and we defined

63
00:05:15,680 --> 00:05:22,600
a quantity called clustering, which basically just means you look, you look next to you and what,

64
00:05:22,600 --> 00:05:28,720
what's the probability that your neighbor next to you is the same algotype as you are. So what

65
00:05:28,720 --> 00:05:33,320
happens is that in the very beginning, that probability is 50% because the algotypes are

66
00:05:33,320 --> 00:05:39,760
randomly assigned to the digits. So 50%. That's our baseline. At the very end, it's also 50%

67
00:05:39,760 --> 00:05:44,560
because at the end, everybody has to be sorted. And there is no relationship between the actual

68
00:05:44,560 --> 00:05:49,880
sort order of the numbers and the algotype. So again, it's 50%. But the wild thing is that in

69
00:05:49,880 --> 00:05:54,440
between those two points, if you actually plot that curve over time, it actually goes like this.

70
00:05:54,440 --> 00:05:59,800
And in between, it's quite a bit higher in statistically very significantly higher than 50%.

71
00:06:00,360 --> 00:06:07,400
And what we see is clustering significant tendency of cells with the same algotype to locate close

72
00:06:07,400 --> 00:06:12,120
together. Eventually, the inevitable, the inevitable physics of the algorithm will yank

73
00:06:12,120 --> 00:06:16,920
them apart and make sure that everybody's in numerical order. But until that happens, they

74
00:06:16,920 --> 00:06:22,200
enjoy some amount of clustering with their, you know, with their conspecific, so to speak, until

75
00:06:22,200 --> 00:06:28,040
then. And so, you know, any thoughts you might have, but more specifically, like one hypothesis

76
00:06:28,040 --> 00:06:32,280
the one could make, even though there's no explicit mechanism for this, but it might be a,

77
00:06:32,280 --> 00:06:36,520
you know, an emergent thing, could they be preferring to be next to their neighbors because

78
00:06:36,520 --> 00:06:42,440
their neighbors be one of the same algotype or more predictable, right? It's less surprise,

79
00:06:42,440 --> 00:06:45,480
you're less surprised when you're sitting next to somebody who's following exactly the same

80
00:06:45,480 --> 00:06:52,040
policies as you are. So I'm curious what you think about that. And I'm curious if there, you know,

81
00:06:52,120 --> 00:06:58,280
what might be a set of experiments that we could do to test that what's going on here is some sort

82
00:06:58,280 --> 00:07:03,240
of implicit surprise minimization, even though there's no actual code for it. So I'll stop there

83
00:07:03,240 --> 00:07:10,200
and listen to what you've got to say. Sorry, I think you're still muted.

84
00:07:14,600 --> 00:07:19,880
I was saying that was a very succinct and clear, a nice summary. I reread the paper a couple of

85
00:07:19,880 --> 00:07:27,240
days ago just to refresh myself, my memory for this conversation. So I didn't realize that that was

86
00:07:27,240 --> 00:07:34,760
the, that final chimeric demonstration was sort of, you know, the most intriguing from your point of

87
00:07:34,760 --> 00:07:43,880
view. But indeed, the way you express it, you know, that does call for further analysis, understanding

88
00:07:43,880 --> 00:07:56,520
and numerical experiments. So overall, just to endorse the choice of the sorting algorithm as,

89
00:07:56,520 --> 00:08:05,880
if you like, a minimal kind of self-organization. I think that, you know, that the self-organization

90
00:08:05,880 --> 00:08:12,680
word needs to be centre stage in terms of, you know, what you're trying to understand here.

91
00:08:13,960 --> 00:08:19,640
And framing like that, it does remind me a lot of self-organizing maps. I don't know if you remember

92
00:08:19,640 --> 00:08:26,440
van der Molzberg's treatment and people, Peter Dion's supervisor, I've forgotten now.

93
00:08:28,840 --> 00:08:35,240
So this notion of self-organizing maps as a very sort of biomimetic aspect of self-organization,

94
00:08:35,240 --> 00:08:43,560
I think certainly puts sorting like algorithms centre stage in terms of biological self-organization,

95
00:08:43,560 --> 00:08:50,920
particularly in things like the visual cortex and why you get that kind of pinwheel architecture,

96
00:08:50,920 --> 00:08:58,040
for example, where receptive field properties tend to cluster together in a smooth way and you get

97
00:08:58,040 --> 00:09:04,120
all sorts of interesting symmetry breaking when you're trying to represent, say, a 5D perceptual

98
00:09:04,120 --> 00:09:10,840
space on a 2D manifold. So that does strike me having this sort of linear sorting algorithm.

99
00:09:11,160 --> 00:09:23,400
And without really having not thought about it before, but certainly the dual pressure to find

100
00:09:23,400 --> 00:09:30,840
a free energy minimizing solution, viewing free energy as an extensive quantity,

101
00:09:32,200 --> 00:09:37,480
more simply, you know, the collective free energy being the joint free energy minimum solution.

102
00:09:37,480 --> 00:09:44,040
You're asking us where the free energy just bounds the likelihood of this particular arrangement.

103
00:09:45,240 --> 00:09:55,160
Then you're looking for the precise functional form of the free energy. And if you've got this kind

104
00:09:55,160 --> 00:10:02,840
of a ponency between the similarity of the algorithm and the similarity of the content of the value,

105
00:10:03,640 --> 00:10:11,800
then I can certainly see interesting behaviors arise in exactly the same spirit that you get

106
00:10:11,800 --> 00:10:21,480
these interesting structures in not epithelia, but in the functional specialization of

107
00:10:21,480 --> 00:10:30,600
cortical representations or sensory epithelia that try to sort of pack three dimensions into one

108
00:10:30,600 --> 00:10:36,600
dimension or are accountable to two kinds of constraints. So again, without really thinking

109
00:10:36,600 --> 00:10:41,000
about it, because I wasn't anticipating that particular question, but I think what you would be

110
00:10:42,120 --> 00:10:48,280
the first thing that you would be looking for is basically what is the Lagrangian or the energy

111
00:10:48,280 --> 00:10:57,560
function that is being minimized. So you could regard this as the sorting algorithm as an application

112
00:10:57,560 --> 00:11:05,240
of the sorting algorithm as a process that is trying to minimize some energy function very

113
00:11:05,240 --> 00:11:09,640
much in the spirit of Markov-Random fields, but in your instance, you just got a one dimensional

114
00:11:09,640 --> 00:11:18,200
field. But the technology of Markov-Random fields I think would be apt to try to understand the

115
00:11:18,200 --> 00:11:25,720
functional forms of the energy functions were under the special constraint, which of course is

116
00:11:25,720 --> 00:11:32,040
the one that you're predicating this whole thesis on, that interactions are only local and therefore

117
00:11:32,040 --> 00:11:37,880
any collective behavior has to be an emergent property, which is truly distributed. So the

118
00:11:37,880 --> 00:11:44,280
definitive aspect of a Markov-Random field is you just have local, you just have local interactions.

119
00:11:44,280 --> 00:11:51,160
And I think that's a really another important architectural feature that comes along with

120
00:11:51,160 --> 00:11:58,120
the choice of the sorting algorithm, which you should foreground, because any distributed,

121
00:11:58,120 --> 00:12:05,400
collective or emergent behavior at a scale beyond local interactions, that emergence

122
00:12:05,400 --> 00:12:11,400
is truly emergent in the sense that all your interactions are local. And of course that is

123
00:12:11,400 --> 00:12:19,480
what the Markov-Random field gives you. It says that you can only express the energy function,

124
00:12:20,200 --> 00:12:24,840
which is the probability of getting this particular arrangement or these particular numbers

125
00:12:25,640 --> 00:12:34,280
in this local clique. You can only express that in terms of a local energy function. And then

126
00:12:34,280 --> 00:12:38,840
of course you can tell all sorts of stories about the importance of that for machine learning and

127
00:12:38,840 --> 00:12:45,720
the like. But you probably want to stick to self-organization. So, and I would imagine the

128
00:12:45,720 --> 00:12:53,960
energy function is now going to be some simple measure of the local differences of the local

129
00:12:53,960 --> 00:13:01,560
gradients. And of course what one would anticipate would be a smoothing, a resolution of, as you say,

130
00:13:01,560 --> 00:13:11,640
the differences. So I think that would be one way of approaching naturalizing this phenomena in

131
00:13:11,720 --> 00:13:19,080
terms of maths by just invoking an arbitrary, not a variational free energy in the spirit of

132
00:13:19,080 --> 00:13:29,160
the free energy principle, but just a Lagrangian or try to identify what is the generic free energy

133
00:13:29,160 --> 00:13:36,200
function that's being minimized here. So that now your view through this sorting space or

134
00:13:36,520 --> 00:13:44,360
your morphological space is now a progression on some wonderful landscape that is defined

135
00:13:44,360 --> 00:13:52,920
by this free energy functional. And whether you can reverse engineer that or not, I don't think

136
00:13:52,920 --> 00:13:59,320
it really matters other than because I think the nice aspect of that is then you can talk about

137
00:13:59,960 --> 00:14:07,400
the dynamics on this free energy landscape. And once led then to very similar sort of notions

138
00:14:07,400 --> 00:14:14,360
in computational chemistry and protein folding and the like, there's a very complex, sorry,

139
00:14:14,360 --> 00:14:19,960
there is a complex Wellington landscape or free energy landscape that self-organization

140
00:14:19,960 --> 00:14:25,160
and computational chemistry adheres to and can be understood in terms of free energy minimum.

141
00:14:25,160 --> 00:14:32,440
Indeed, most of computational chemistry sort of follows this. And indeed, that is identifying

142
00:14:32,440 --> 00:14:39,240
that landscape is the whole point of applying things like large language models or deep RL to

143
00:14:39,240 --> 00:14:49,800
sort of protein folding and other applications. So that would be certainly one view to get a free

144
00:14:49,800 --> 00:14:57,320
energy like formalism or naturalization of this behavior, which I repeat has lots of really

145
00:14:57,320 --> 00:15:03,880
interesting links with self-organizing maps, marker, random fields, image reconstruction,

146
00:15:03,880 --> 00:15:10,120
and self-organization in certainly in some things like the visual cortex, I don't imagine

147
00:15:10,200 --> 00:15:17,320
any mapped representation would conform to these rules. To get this into a

148
00:15:19,560 --> 00:15:31,080
to get it into a free energy principle story, I think you would have to commit to the notion that

149
00:15:31,080 --> 00:15:37,320
each of the cell has its own boundary. And now you're starting to interpret each number

150
00:15:37,320 --> 00:15:45,960
as a thing. And in so doing, acknowledge its openness to everything else, or in this instance,

151
00:15:45,960 --> 00:15:52,920
just its neighbors, which will require sort of a by your formalism of the bi-directional exchange,

152
00:15:52,920 --> 00:16:00,520
so that the value of my next door neighbor is something that I can sense and is, and likewise,

153
00:16:01,320 --> 00:16:07,800
the broadcasting of my number to the next door neighbor is something is an action. So you've got

154
00:16:07,800 --> 00:16:15,960
this openness that is mediated in the simplest way, which is just the broadcasting and sensing

155
00:16:15,960 --> 00:16:22,520
of one unit dimensional, one number, if that is a discrete number. And the view like that,

156
00:16:22,520 --> 00:16:28,680
that means you can then I think deploy the free energy principle in the sense that any

157
00:16:29,640 --> 00:16:36,440
non equilibrium or far from equilibrium, steady state, which I think you would probably have here,

158
00:16:37,240 --> 00:16:39,960
just in virtue of the fact that there is going to be some

159
00:16:41,080 --> 00:16:46,360
breaking of detail balance in the itinerant way in which you move through this space in a

160
00:16:46,360 --> 00:16:52,360
developmental to get to your steady state. One can imagine, well, perhaps not, but

161
00:16:52,360 --> 00:16:58,920
you know, if one puts a little bit of dynamics into this, I would imagine you would advance very,

162
00:16:58,920 --> 00:17:09,320
very clearly the breaking of detail balance, and you know, and have those kinds of solenoidal flows.

163
00:17:11,320 --> 00:17:18,920
I mean, sorry, I distracted myself just by the addition of the frozen cells. That's one way of

164
00:17:18,920 --> 00:17:26,760
breaking. In a sense, the detail balance, and you know, just open brackets. It's exactly the same

165
00:17:26,760 --> 00:17:36,520
device that I resorted to in the very first paper on the life as we know it paper when

166
00:17:36,520 --> 00:17:42,520
simulating the little macro molecules using Lorenz attractors that had inherent dynamics.

167
00:17:42,520 --> 00:17:49,480
But to make it interesting, you had to have a small a certain popular number of the of the

168
00:17:50,040 --> 00:17:56,600
synthetic macro molecules that were insensitive to influences from other macro molecules and

169
00:17:56,600 --> 00:18:01,560
another proportion that could not influence the other one. So it's almost exactly the same

170
00:18:02,280 --> 00:18:08,200
choice. And that's what gave it the interesting behavior. Otherwise, it just basically converged

171
00:18:08,280 --> 00:18:17,800
either to a gas or it at a certain temperature, it would just convert to a crystal.

172
00:18:19,320 --> 00:18:24,200
So both of them being steady state solutions, free energy minimizing solutions. But things got

173
00:18:24,200 --> 00:18:29,320
interesting when you broke the detail balance symmetry breaking by having this

174
00:18:30,280 --> 00:18:38,920
this, you know, this requisite variety in terms of the frozenness in terms of action or sensation.

175
00:18:38,920 --> 00:18:46,360
So I think that's another that's another important thing to foreground. That this may be this

176
00:18:46,360 --> 00:18:52,680
kind of requisite variety may be absolutely necessary for symmetry breaking. And in this

177
00:18:52,680 --> 00:18:59,160
particular instance, breaking detail bounds to get this kind of cell biologically plausible

178
00:18:59,800 --> 00:19:06,280
by mimetic kind of stuff organization, you're unlikely to get that if you're in the absence

179
00:19:06,280 --> 00:19:12,760
of it in the sense that it would converge to a crystal in your instance, just a linear sorting

180
00:19:12,760 --> 00:19:18,040
perfect sorting, which which is which is, you know, doesn't doesn't have that chimeric or itinerant

181
00:19:18,600 --> 00:19:25,320
itinerant aspect to it. So sorry, close back it. So where were we? Oh, yeah. So

182
00:19:25,320 --> 00:19:33,400
if you've got now an interesting system that has a non equilibrium steady state, and in your case

183
00:19:33,400 --> 00:19:38,360
actually because you haven't got dynamics, it will also be an equilibrium steady state,

184
00:19:38,360 --> 00:19:44,360
but it'll still be a free energy minimizing solution. Then you are perfectly entitled to

185
00:19:44,360 --> 00:19:52,200
interpret the numbers as things and inferring things. And all they're trying to infer is the

186
00:19:52,200 --> 00:19:58,600
cause of their sensations, which is just the value of the numbers on one side and the other side,

187
00:19:58,600 --> 00:20:08,600
and they are broadcasting their inferences through broadcasting their own number, which of course

188
00:20:08,600 --> 00:20:17,960
will be the average of well, when sorted, it will be the average of the neighboring numbers.

189
00:20:17,960 --> 00:20:24,760
So on that view, I think you could very easily license an active inference interpretation

190
00:20:24,760 --> 00:20:31,240
a teleology. You mean you would actually need this to simulate protein folding or self organizing

191
00:20:31,240 --> 00:20:37,080
maps or anything, but you would be able to say there is a teleological interpretation of the

192
00:20:37,080 --> 00:20:43,960
self organization using the rhetoric of inference and belief updating simply because we can treat

193
00:20:43,960 --> 00:20:51,080
each number now as a Markov blanket and then something which will never be accessible, but we

194
00:20:51,080 --> 00:21:01,960
can imply or induce internal to each number could be interpreted as an inference process,

195
00:21:01,960 --> 00:21:08,840
and then the story, which you've already said what the answer is, under the assumption that

196
00:21:09,640 --> 00:21:17,080
I live in a world that is maximally predictable, then everything around me is the same as me and

197
00:21:17,080 --> 00:21:26,680
therefore I am going my free energy, my variational free energy minimizer is now going to be

198
00:21:28,360 --> 00:21:35,400
bound when there's the least surprising input. And if I believe that everything is like me,

199
00:21:36,040 --> 00:21:46,440
then that will be when the numbers that I am sensing in my peak are as similar to the estimate of

200
00:21:46,440 --> 00:21:54,280
the number, the place that I should be coming back to our sort of no-deal place paper.

201
00:21:55,480 --> 00:22:05,320
And I think that kind of story will have to be nuanced for the same algorithm

202
00:22:06,280 --> 00:22:13,000
so I'd have to think about that a little bit more, but certainly at least at a narrative level or

203
00:22:13,000 --> 00:22:18,440
a conceptual level I think you can tell the same story there that if the sequence of moves that I

204
00:22:18,440 --> 00:22:26,200
see my neighbour doing in relation to what I know about my neighbour belies the same underlying

205
00:22:26,200 --> 00:22:34,360
dynamic or algorithmic computations, then in some sense they are predictable if I have exactly the

206
00:22:34,360 --> 00:22:43,080
same algorithm under the hood. And therefore, mathematically speaking, that would be the

207
00:22:43,080 --> 00:22:50,280
free energy minimising solution if I can now read my broadcasting of the number as a broadcasting

208
00:22:50,280 --> 00:22:59,080
my posterior beliefs about the number, the estimate of this locale, my niche

209
00:22:59,720 --> 00:23:09,240
in this instance is just labelled with one number. So the number that I have

210
00:23:10,600 --> 00:23:17,800
is basically my prior belief about my niche and I'm just now going to

211
00:23:19,000 --> 00:23:27,240
move my niche around in a sort of egocentric frame until it is consistent with my prior belief

212
00:23:27,320 --> 00:23:33,720
that this is my place, my niche is number 62 for example. And that should be, you should be

213
00:23:33,720 --> 00:23:41,480
able to reproduce the same kind of sorting either analytically through showing that with an appropriately

214
00:23:41,480 --> 00:23:48,280
configured Lagrangian or free energy functional that the system operationally appears to be

215
00:23:48,920 --> 00:23:56,440
minimising, you can now write down the generative model and then show that this can also be

216
00:23:56,440 --> 00:24:04,440
interpreted as an inference process. I repeat under the assumption that the best way to make the

217
00:24:04,440 --> 00:24:11,800
world predictable is to surround yourself with things like you, which and also of course the

218
00:24:11,800 --> 00:24:17,960
locality assumption that I can only talk to the person to whom I'm immediately connected.

219
00:24:17,960 --> 00:24:23,080
So those are some of my thoughts but a lot of those were invented on the fly in response to

220
00:24:23,320 --> 00:24:29,240
your question I'm afraid. Superb. I've got many questions but Adam why don't you ask yours?

221
00:24:29,240 --> 00:24:37,480
Yeah, so it strikes me that up until now we've talked about the relevant sort of agent as being

222
00:24:37,480 --> 00:24:42,840
the individual number with an algoritite. You can think of it as a cell but it strikes me that

223
00:24:42,840 --> 00:24:49,480
there's an interesting macro phenomenon that occurs in the process of sorting which is that it

224
00:24:49,480 --> 00:24:57,960
appears that the list actually minimizes the Komogorov complexity or the description length

225
00:24:57,960 --> 00:25:05,160
necessary to render it. So let's just say you've got an unsorted list with random distribution

226
00:25:05,160 --> 00:25:13,080
of algotypes and there's 10 items in the list. You would need to enumerate 10 numbers and 10

227
00:25:13,080 --> 00:25:17,240
algotypes and there's no reason a priori to think that that would be compressible in any way.

228
00:25:17,880 --> 00:25:21,000
I mean maybe maybe you'd get lucky and there'd be a string of a certain number,

229
00:25:21,000 --> 00:25:24,440
a string of a certain algoritite but in the general case I think you'd actually need to

230
00:25:24,440 --> 00:25:32,360
write out every single entry. But as the list starts to sort itself it actually starts to create

231
00:25:32,360 --> 00:25:38,520
these longer strings of algotypes which means that the minimum description length actually gets

232
00:25:38,520 --> 00:25:44,760
shorter. Yet you still need to write each number out but you can coarse-grain the descriptions

233
00:25:44,760 --> 00:25:49,640
of the algotypes. You can say the first five numbers have the same you know algotype and then

234
00:25:49,640 --> 00:25:56,200
the next three have the same and so on. Now that that's a macro phenomenon but I'm wondering if

235
00:25:56,200 --> 00:26:02,280
there's any evidence or any research that suggests that sort of these self-organizing systems

236
00:26:02,920 --> 00:26:08,840
have a tendency to minimize their description length to minimize the number of factors needed

237
00:26:08,840 --> 00:26:14,360
or something like that. Because if that's the case then it gives us another view where there's

238
00:26:14,360 --> 00:26:21,960
this sort of emergent complexity minimization happening at the collective level. Yes, no that's

239
00:26:21,960 --> 00:26:31,240
an excellent point. I think the simple answer is yes absolutely and I can sort of give you my take

240
00:26:31,240 --> 00:26:37,720
on the literature or the citations that you'd want to appeal to. But I should say it's going to be

241
00:26:37,720 --> 00:26:43,800
a nuanced yes because of the particular focus on the clustering of the algotype. Now the algotype

242
00:26:44,360 --> 00:26:49,320
induces a certain kind of dynamics into the game so it's not as simple as a self-organizing map.

243
00:26:49,320 --> 00:26:59,400
It's how the map actually self-organizes so there's a process under the hood and that I think makes

244
00:26:59,400 --> 00:27:08,120
it slightly more complicated than just understanding self-organized maps. But in terms of another thing

245
00:27:08,120 --> 00:27:12,280
you might want to look into here of course and you probably know more about this than I do but

246
00:27:13,160 --> 00:27:16,280
this has a lot of resonance with artificial life

247
00:27:18,040 --> 00:27:26,280
games in the 1990s and 1980s. It also could be if you wanted to so do

248
00:27:27,320 --> 00:27:33,800
interestingly linked to Stephen Wolfram's Ruliad which is also another local scheme

249
00:27:34,520 --> 00:27:42,760
that generates everything apparently. There's the same sort of notion so he has algorithms

250
00:27:42,760 --> 00:27:49,480
which he calls rules and the rules are recursively applied in a local fashion to generate everything

251
00:27:50,280 --> 00:27:59,000
including black holes apparently and quantum physics and everything. There might be an

252
00:27:59,080 --> 00:28:05,720
interesting point of contact here with these sorry but to come back to the simple answer yes

253
00:28:05,720 --> 00:28:12,920
absolutely so certainly from the point of view of self-organization as described by the free

254
00:28:12,920 --> 00:28:17,960
energy principle. So notice here the free energy principle is just a description of systems that

255
00:28:17,960 --> 00:28:24,520
self-organize to a far from equilibrium non-equilibrium as I said he stayed. It's not a recipe for sorry

256
00:28:24,840 --> 00:28:33,960
in its statement it is not a description or a theological description of inferential

257
00:28:33,960 --> 00:28:39,880
processing. You are licensed to equip your explanation of the self-organization with

258
00:28:39,880 --> 00:28:45,560
reference to inference but that's an application of the free energy principle in itself it's just

259
00:28:45,560 --> 00:28:53,400
a description of anything that self-organizes or any things that self-organize. So in that sense

260
00:28:55,240 --> 00:29:00,280
if there is self-organization under the hood and the free energy principle has to apply and you can

261
00:29:00,280 --> 00:29:07,080
motivate the free energy principle along two lines one would be the sort of playing the Feynman

262
00:29:07,080 --> 00:29:22,760
card which is basically looking at the minimization of free energy as an optimization process

263
00:29:23,480 --> 00:29:27,640
which can be viewed as a gradient descent on sub-fitness landscape or free energy landscape

264
00:29:27,640 --> 00:29:35,560
or into landscape or you can take the Russian perspective which would be the Kalmolov complexity

265
00:29:35,560 --> 00:29:43,800
and from the Kalmolov complexity you get to Solov induction and from that you get to universal

266
00:29:43,800 --> 00:29:49,240
computation which is the home of the minimum description length and minimum message length

267
00:29:50,120 --> 00:29:58,440
so it's the algorithmic complexity version of free energy and so David McKay wrote a quirky

268
00:29:58,440 --> 00:30:08,680
little paper I think 1992 for where he interpreted variational free energy in relation to minimum

269
00:30:08,680 --> 00:30:15,480
message length using crypto analysis as a vehicle to tell that story but to my mind I think wonderfully

270
00:30:15,480 --> 00:30:21,000
connected to two different two different perspectives on exactly the same phenomenon

271
00:30:21,000 --> 00:30:30,200
the ways of describing self-organizing systems that basically both entail a minimization of complexity

272
00:30:31,240 --> 00:30:37,240
a simplification an emergence of order of a particular sort that entails

273
00:30:37,320 --> 00:30:45,480
either compression hence the minimum description or the minimum message length

274
00:30:46,200 --> 00:30:51,800
view from the algorithmic complexity in terms of sort of you know rate coding theorems rate

275
00:30:51,800 --> 00:30:57,240
distortion theorems and the like or you can write it down in terms of continuous probability

276
00:30:57,240 --> 00:31:03,000
distributions and sort of follow through from the Feynman's path integral I think they're both

277
00:31:03,000 --> 00:31:11,960
saying the same thing you know the way I think of this is the you know the end point of any

278
00:31:11,960 --> 00:31:19,160
self-organizing thing or set of things is just going to be the most likely configuration that

279
00:31:19,160 --> 00:31:27,960
they occupy given the kind of things that they are and that basically means that you can always

280
00:31:28,040 --> 00:31:38,360
describe this in a statistical and theological sense as everything providing an accurate prediction

281
00:31:38,360 --> 00:31:46,520
of what its sense is that is minimally complex in exactly the same spirit as the the way that you

282
00:31:46,520 --> 00:31:53,720
would frame complexity in terms of lossy or not losses but lossy compression or minimum

283
00:31:53,800 --> 00:32:01,160
description length or minimum algorithmic complexity so I think that if you if you

284
00:32:03,240 --> 00:32:07,560
if you tell the story that the free energy is an extensive quantity which means that all the

285
00:32:07,560 --> 00:32:14,040
set of numbers or any subset of numbers any partition will all will all look as if they

286
00:32:14,040 --> 00:32:21,560
are minimizing a free energy functional then you can I think say that you know one view of this

287
00:32:21,560 --> 00:32:27,960
functional is to minimize the complexity of the arrangement which should be manifest in terms of

288
00:32:27,960 --> 00:32:34,680
a minimization of algorithmic complexity and you can use it I can never I can never remember

289
00:32:35,800 --> 00:32:41,880
Zemmell Lippf or Lippf what do you know what I'm talking about there's one of these

290
00:32:43,560 --> 00:32:45,720
hierarchical sequential entropy measures

291
00:32:46,440 --> 00:32:54,280
you know there's one way of quickly enumerating the the algorithmic complexity so I think the

292
00:32:55,000 --> 00:33:00,520
if you could join the dots that would be a really powerful view of this and indeed you know

293
00:33:01,400 --> 00:33:03,560
it would be interesting if you could

294
00:33:04,040 --> 00:33:09,640
just for using numerical experiments join the dots

295
00:33:11,320 --> 00:33:20,120
quantitatively in terms of this handcrafted intuitive free energy Lagrangian just based

296
00:33:20,120 --> 00:33:25,640
upon you given three numbers you have to now write down an energy function that is always

297
00:33:25,640 --> 00:33:33,320
going to be minimized by the sorting algorithm so the endpoint conforms shares the same minima of

298
00:33:33,560 --> 00:33:37,640
your energy function it could be really simple it could be this the two differences squared

299
00:33:37,640 --> 00:33:44,520
and added together something as simple as that and if you can prove that the the minima of this

300
00:33:45,160 --> 00:33:56,600
is the same is the same as the the endpoint of your self-organization then you can say this is one

301
00:33:56,600 --> 00:34:03,800
free energy functional that very much in the spirit of hopfield nets and harmony functions

302
00:34:03,800 --> 00:34:12,280
you know in the early days of neural networks spin glass models pots models all of these

303
00:34:13,560 --> 00:34:18,520
mark of random fields you have to write down this kind of energy function and then you just

304
00:34:18,520 --> 00:34:22,680
simulate you know you can you can just do a gradient descent or rearrangement in order to

305
00:34:22,680 --> 00:34:29,480
minimize that so that's one very simple kind of free energy description of it then you'd have

306
00:34:30,440 --> 00:34:36,200
an inferential one under an assumed generative model so if you assume each number actually

307
00:34:36,200 --> 00:34:40,920
has a little mind and a generative model it's trying to estimate or trying to act upon its world

308
00:34:40,920 --> 00:34:46,200
to realize its beliefs about what it's sensing you'd have a variational free energy but then you'd

309
00:34:46,200 --> 00:34:54,760
also have the the algorithmic free energy that you could that apply to any partition

310
00:34:54,760 --> 00:35:01,720
and the point that if you can show that all three all three share the same minimum at the point of

311
00:35:03,000 --> 00:35:08,680
attaining non-equilibrium steady state I think that will be really you know a really nice illustration

312
00:35:08,680 --> 00:35:13,720
that all of these are different facets of exactly the same thing I mean you know it is just a

313
00:35:13,720 --> 00:35:20,280
description of self-organization but articulated in slightly different ways but I repeat you know

314
00:35:20,280 --> 00:35:31,880
once you've got different algorithms I think the process of sorting now is is somewhat constrained

315
00:35:31,880 --> 00:35:40,280
so that it's you know because you've got three different ways of doing this they may have different

316
00:35:41,240 --> 00:35:47,640
they may have different functionals that are being minimized and it may be but I'm not absolutely

317
00:35:47,640 --> 00:35:54,840
sure that the the order matters and as soon as the order matters then you've got dynamics in play

318
00:35:54,840 --> 00:36:00,680
once you've got dynamics in play that I think slightly complicates the simple

319
00:36:02,520 --> 00:36:09,880
algorithmic complexity argument because the algorithmic complexity the universal computation

320
00:36:10,040 --> 00:36:19,080
view it's not really fit for purpose to understand dynamics of organization and indeed most people

321
00:36:19,080 --> 00:36:24,360
would argue it's not fit for purpose to do anything because it's intractable but it's a

322
00:36:24,360 --> 00:36:35,640
beautiful mathematical object does that make sense yeah so one thing then for with Adam's point so

323
00:36:35,720 --> 00:36:41,960
I think that's a really interesting point and it raises another question which is if on the

324
00:36:41,960 --> 00:36:46,760
compression so it's on the compression issue so if we say that what you're trying to compress is

325
00:36:46,760 --> 00:36:52,440
the actual list of numbers plus the ordering of the algotypes then you know everything as you guys

326
00:36:52,440 --> 00:36:58,680
just said but I wonder couldn't somebody argue that in fact there is no list of algotypes to

327
00:36:58,680 --> 00:37:04,120
compress there's only the numbers because it's sort of like you know by the time you get to the end

328
00:37:04,920 --> 00:37:09,640
it's kind of like it's immaterial information it doesn't do you know it gets lost by the time

329
00:37:09,640 --> 00:37:13,560
you've sorted the numbers what do you need the list of algotypes for right they're not really

330
00:37:14,680 --> 00:37:21,640
I don't know I there's something here no I don't think so like if you take the position that the

331
00:37:21,640 --> 00:37:28,920
algotypes aren't relevant once they stop being used then you're imposing as an observer an assumption

332
00:37:28,920 --> 00:37:36,520
that the list is finished moving right but like how do you know that yeah yeah no that's that's

333
00:37:36,520 --> 00:37:41,480
that's super interesting and and and it's like the bigger question of there is this notion of

334
00:37:41,480 --> 00:37:46,920
algotypes that maybe you have to take into account what else do you have to take into account that

335
00:37:46,920 --> 00:37:50,840
we don't know about right like that's that's one of the things that I see is so interesting about

336
00:37:50,840 --> 00:37:56,120
this and then the next thing I was going to ask you Carl is what's the status of the fact that

337
00:37:56,120 --> 00:38:00,440
like all the things that we were just talking about about the cells you know being objects and

338
00:38:00,440 --> 00:38:04,520
exchanging information with their neighbors about algotypes and having predictions I mean

339
00:38:05,240 --> 00:38:09,000
none of that is actually in the algorithm you can see that the algorithm is like six lines of

340
00:38:09,000 --> 00:38:13,240
code like you can see what the algorithm is none of that is there so what's you know it's more

341
00:38:13,240 --> 00:38:18,120
of a philosophical question you know what what's the status of of something and I have the same

342
00:38:18,120 --> 00:38:21,320
question when I first heard about you know photons and least action and all that I was like but there's

343
00:38:21,320 --> 00:38:26,360
no mechanism to know you know to calculate which path you know is going to be best for you so

344
00:38:26,360 --> 00:38:33,080
what do we do with this what what do we do I'm super interested in the sort of I don't know

345
00:38:33,080 --> 00:38:39,560
why they're almost almost you know implicit things that it's doing whereas the explicit algorithm

346
00:38:39,560 --> 00:38:45,480
doesn't have any of that what do you think about that um well probably think the same thing that

347
00:38:45,480 --> 00:38:55,400
you do um I think um yep in a sorry in a sense what I was saying about a nuanced answer once

348
00:38:55,400 --> 00:39:02,040
you're dealing with you know isomorphisms between the local algorithms was exactly this issue that

349
00:39:02,040 --> 00:39:08,200
you bring to the table it's not you know um yeah it could be as simple as each algorithm has a

350
00:39:08,200 --> 00:39:12,520
different objective function different free energy or lipoonov function

351
00:39:14,360 --> 00:39:21,480
or it could be that they have the same but the the actual sequence of updates or moves

352
00:39:21,480 --> 00:39:27,400
is somehow constrained so the movement on the same free energy surface is is it is somehow

353
00:39:27,400 --> 00:39:31,560
constrained to be different so I'd have to know it precisely what the algorithms are

354
00:39:32,120 --> 00:39:37,800
um it probably is the case that I'm just guessing um that they probably don't have

355
00:39:37,800 --> 00:39:43,560
quite the same um objective function or or and often point of view the free energy principle

356
00:39:43,560 --> 00:39:51,480
implicit generative model um so the chimerical um um self-organization is a reflection of the fact

357
00:39:51,480 --> 00:39:58,040
that um not everything is trying to has the same generative model and therefore by definition

358
00:39:58,040 --> 00:40:04,840
will not have the same free energy um functional so that that does complicate the situation and

359
00:40:04,840 --> 00:40:09,800
makes it more interesting in fact um you know from the point of view of this this kind of

360
00:40:09,800 --> 00:40:17,400
requisite variety um but now I've forgotten the your your actual question um which I did have

361
00:40:17,400 --> 00:40:22,840
an answer to what can you remind me what the actual question was sure sure it's so so what

362
00:40:22,840 --> 00:40:26,920
these algorithms have in common with some of the things that you and and chris fields have said

363
00:40:26,920 --> 00:40:30,920
about particles and things and other people apart which is different from what happens in

364
00:40:30,920 --> 00:40:35,320
biology right if if if in biology I said look this cell is exchanging information with that

365
00:40:35,320 --> 00:40:39,560
cell and it's making decisions the next question is excellent what's the mechanism right like what

366
00:40:39,560 --> 00:40:44,600
it like show me show me the the the explicit uh the set of steps by which this cell does that

367
00:40:44,600 --> 00:40:48,760
but but here we don't have that and and presumably you know when we get down to particles and things

368
00:40:48,760 --> 00:40:52,920
we don't have that either so what's what what's the status of these all these amazing things that

369
00:40:52,920 --> 00:41:00,360
they're doing without a a mechanism to explicitly do it right and I'm going to give you an answer which

370
00:41:02,760 --> 00:41:10,040
comes from conversations with philosophers of maths people like max or ramsted that that question

371
00:41:10,040 --> 00:41:20,600
technically would be answered by appeal to what is a mechanics so a mechanics is um for example

372
00:41:20,600 --> 00:41:27,880
the basic mechanics of the theology principle or Lagrangian or classical mechanics under certain

373
00:41:29,000 --> 00:41:41,160
dynamics you know the non-dissipative or conservative so or quantum mechanics where

374
00:41:41,960 --> 00:41:49,080
you can't uh you you you you have to focus exclusively on the on the dissipative dynamics

375
00:41:49,720 --> 00:41:56,840
so the mechanics is a description of the realization of something

376
00:41:58,120 --> 00:42:05,080
where the thing usually conforms to a principle of least action so this is where this is a sort

377
00:42:05,080 --> 00:42:11,480
of deflationary answer to your question that the mechanics in and of itself is an emergent

378
00:42:11,480 --> 00:42:16,520
property of a variational principle of least action that can be cast in gage theoretic terms or

379
00:42:17,080 --> 00:42:23,080
or in terms of things like maximum entropy principles so there are principles

380
00:42:24,680 --> 00:42:34,280
that just describe the shape the spacetime shape of our world these give rise to and usually you

381
00:42:34,280 --> 00:42:43,000
can usually reduce all physics principles to principles of least action the the straight line

382
00:42:43,000 --> 00:42:49,800
the path of least effort um um and once you've written you've written down your principle as a

383
00:42:49,800 --> 00:42:58,440
principle of least action then the particular functional form of the system to which that

384
00:42:58,440 --> 00:43:07,720
principle applies then gives you a mechanics and then that now um acquires a teleology in

385
00:43:07,720 --> 00:43:14,920
conversation but only in conversation you don't need the mechanics mechanics does not engineer

386
00:43:14,920 --> 00:43:21,320
anything it is just an expression of the principle of least action um so very much in the spirit of

387
00:43:21,320 --> 00:43:25,160
basic mechanics are saying before the free energy principle is just a description of things that

388
00:43:25,160 --> 00:43:32,360
self-organize you may or may not want to then go and say oh well this self-organization could be

389
00:43:32,360 --> 00:43:38,440
described teologically as self-evidencing or active inference or decision-making or basal

390
00:43:38,440 --> 00:43:43,720
cognition or distributed intelligence you don't have to do that but it sometimes it can be very

391
00:43:43,720 --> 00:43:50,120
useful when talking to somebody else about it to to to teologically frame it like that and that I

392
00:43:50,120 --> 00:43:55,880
think is your mission I think that's what you're bringing to the table in in the widest sense

393
00:43:55,880 --> 00:44:03,320
you're saying that the mechanics of biotics self-organization have a certain tealogy which is

394
00:44:03,320 --> 00:44:09,560
almost isomorphic to the same tealogy of finding psychiatry or immunotherapy or climate change

395
00:44:10,280 --> 00:44:15,480
and we just got to find the cross-cutting themes so the mechanics the mechanisms

396
00:44:17,400 --> 00:44:23,320
are really just tealogical unpacking of of of the mechanics so in this instance I gave you an

397
00:44:23,320 --> 00:44:30,280
example before that simply the algorithm to implement the algorithm which is probably a

398
00:44:30,280 --> 00:44:36,280
series of Boolean operators would need certain inputs they need arguments and they need certain

399
00:44:36,280 --> 00:44:42,280
outputs those are the the sensory and active states those those define now the Markov blanket

400
00:44:43,240 --> 00:44:50,440
then so you're taking the input is basically whatever my neighbor neighbor's value

401
00:44:51,640 --> 00:44:56,760
whatever I can see and what I can see is my neighbor's value and it has to be a neighbor I

402
00:44:56,760 --> 00:45:03,400
can't see but you know the one for yeah I can't see something along the way away so that defines

403
00:45:03,400 --> 00:45:08,840
the input and the output is my particular number that's what I broadcast but I only broadcasted

404
00:45:08,920 --> 00:45:15,560
in a loop in a local sense so when you're starting to express things in terms of a

405
00:45:16,840 --> 00:45:24,600
a tealogy of self-organization of the kind that people use in you know in the free energy

406
00:45:24,600 --> 00:45:32,040
principle I think you're then you're quite licensed to say well this is just a description for

407
00:45:32,040 --> 00:45:38,600
example of electrochemical signaling you know it there's a magic is this is this is this is the

408
00:45:38,600 --> 00:45:48,600
mechanism it just means that there has to be a local signal that reports or has some morphism

409
00:45:48,600 --> 00:45:57,800
between my state and and you know everything that is not me and we find multiple instances of this

410
00:45:57,800 --> 00:46:03,720
in in biology at different temperance spatial scales and you know the more you drill down the

411
00:46:03,720 --> 00:46:10,520
more you actually specify what it is the more mechanistic you know it will become but you know

412
00:46:11,480 --> 00:46:16,360
at the end of the day that's just the mechanics you're talking about so if you you know if you

413
00:46:16,360 --> 00:46:22,520
wanted to describe self-organization of massive bodies that had no dissipative aspects to them

414
00:46:22,520 --> 00:46:26,360
you know the motion of the planets for example if you if you take yourself back and pretend you

415
00:46:26,360 --> 00:46:33,240
Kepler and you know what is the mechanics of motion of the heavenly bodies they're Lagrangian

416
00:46:33,240 --> 00:46:39,160
conservative mechanics they inherit from the principle of least action that you know has a

417
00:46:39,160 --> 00:46:47,560
relatively simple form before Einstein came along and in terms of you know energy conservation

418
00:46:47,640 --> 00:46:56,280
and you know and all that is implicit in a pattern a path of least you know the least action least

419
00:46:56,280 --> 00:47:01,480
action principle so that would be his kind of mechanics and you start to invent things like

420
00:47:01,480 --> 00:47:07,800
gravity and mass and you know and talk about the teleology of massive bodies being attracted to

421
00:47:07,800 --> 00:47:15,160
each other and that would be you know quite comfortably received as an intuitive mechanistic

422
00:47:15,160 --> 00:47:20,600
explanation for the thing at hand which in this instance is a the motion of heavenly bodies

423
00:47:20,600 --> 00:47:25,800
you know I I don't see there's any real problem from your point of view you've already told the

424
00:47:25,800 --> 00:47:34,440
story you've already got the mechanics it's just you know a question of showing how universal this

425
00:47:34,440 --> 00:47:40,840
kind of mechanics is and universal in the in the special context of local interactions

426
00:47:41,800 --> 00:47:49,320
and all the all the consequences of having a principle or the principles that would apply

427
00:47:49,320 --> 00:47:55,640
to self-organising systems out of equilibrium or non-equilibrium self-organisation, biotic

428
00:47:55,640 --> 00:48:03,160
self-organisation what kind of mechanics must be in play and then you can give particular

429
00:48:03,240 --> 00:48:11,000
exemplars and talk about gravity or cell intercellular signaling or you know and the

430
00:48:11,000 --> 00:48:17,480
locality of that does that make sense yeah yeah yeah yeah and I guess Adam did you want to say

431
00:48:17,480 --> 00:48:24,520
anything before I because I've got another okay so so this is kind of the the really

432
00:48:24,520 --> 00:48:28,600
kind of far out thing and feel free to tell me that this is not a good analogy and you know

433
00:48:28,600 --> 00:48:34,200
kind of too too too far out but I was thinking I was thinking about the analogy of us trying to

434
00:48:34,200 --> 00:48:39,640
analyse these algorithms and what it is that what what are the causes of their behavior as we observe

435
00:48:39,640 --> 00:48:47,320
them and trying to analogize to in a in a you know biological or maybe in a psychological

436
00:48:47,320 --> 00:48:53,400
slash psychiatric context where you have what you think is the algorithm and maybe that's what

437
00:48:53,400 --> 00:48:57,400
your subject thinks is the cause of their actions and maybe that's what you think is the cause of

438
00:48:57,400 --> 00:49:02,600
their actions but it turns out that there's this underlying dynamic that is it's an extra goal

439
00:49:02,600 --> 00:49:07,480
that you didn't know because you couldn't you you didn't see it in the in the steps of the

440
00:49:07,480 --> 00:49:13,720
of the policies that they're supposedly following and I wonder if this is a sort of really basal

441
00:49:13,720 --> 00:49:19,240
kind of I don't know I just just a really basal kind of behavioral analysis that might be important

442
00:49:19,240 --> 00:49:27,320
for the larger and more complex systems in the sense of finding underlying goals for for

443
00:49:27,320 --> 00:49:33,000
for complex behaviors that are not to be found in the by enumerating the mechanisms that you

444
00:49:33,000 --> 00:49:37,480
know that are there which is you know like it basically basically looking at the tendency to

445
00:49:37,480 --> 00:49:43,640
cluster as a as a hidden motivation for their behavior if I can use this kind of like psychological

446
00:49:43,640 --> 00:49:48,360
term what do you think about that Zachary is that silly or are there oh no no I think that's

447
00:49:49,240 --> 00:49:55,320
exactly the application of these principles and the attendant mechanics you know in terms of say

448
00:49:55,320 --> 00:50:04,360
voting dynamics or geopolitical and or just a spread of information on the internet you know

449
00:50:07,320 --> 00:50:13,480
I think some really important deep questions there and things you know why is it

450
00:50:13,480 --> 00:50:21,640
that almost inevitably whenever you look at some ideological political or theological commitment

451
00:50:21,640 --> 00:50:28,040
everybody's 50-50 you know Trump versus Biden Brexit versus stay you know wherever you look

452
00:50:28,920 --> 00:50:35,240
the only evolutionary stable strategy on or for energy minimizing not an equilibrium steady state

453
00:50:35,240 --> 00:50:41,320
is you know usually a 50-50 because that can be subdivided within what this this 50 percent

454
00:50:41,320 --> 00:50:46,280
there's another 50 percent in a sort of self-similar way all the way down so there's some must be

455
00:50:46,280 --> 00:50:52,760
something generically very important universal about that and I would imagine that's you know

456
00:50:52,760 --> 00:50:57,720
you will see that kind of clustering it's interesting I didn't realize I didn't read

457
00:50:57,720 --> 00:51:03,560
it Kevin have to realize you have this sort of the actual order wins out at the end of the day

458
00:51:03,560 --> 00:51:07,080
so you get the increase and then the decrease in clustering that was interesting

459
00:51:07,720 --> 00:51:14,280
I would be if I was a young man working for you as a PhD student I'd like to put a bit of

460
00:51:14,280 --> 00:51:19,880
noise on the numbers and just see if you can keep it alive and dynamic and see that clustering and

461
00:51:19,880 --> 00:51:27,640
that chimeric behavior look at its dynamics and you know something in dynamical systems

462
00:51:27,640 --> 00:51:34,520
theory called frustration that you get in these in these chimeric situations when

463
00:51:34,520 --> 00:51:41,400
you've broken detailed bounds like this which may be a good metaphor for voting dynamics for

464
00:51:41,400 --> 00:51:46,840
example and so I think it's a very sensible idea I'm just reminded have you read that paper by

465
00:51:46,840 --> 00:51:56,680
Connor Hines and if not I'll send it to you so he's he's he he was making an analogy between

466
00:51:57,640 --> 00:52:07,880
Gibbs energy and free energy in terms of exchanging ideas as a model of

467
00:52:10,760 --> 00:52:17,800
collective behavior and it may be you'll find some interesting ethological references

468
00:52:18,840 --> 00:52:25,160
references to that yeah interesting that you know the thing about the thing about them being

469
00:52:25,320 --> 00:52:32,040
pulled apart at the end so so one way one of the things that we did was to ask okay how how

470
00:52:32,040 --> 00:52:37,400
strong would this tendency to cluster be if you if you didn't have this super overlying

471
00:52:37,400 --> 00:52:40,920
being a basic physics of this world that eventually is just going to yank you apart

472
00:52:40,920 --> 00:52:45,720
and and one way to do that is to allow repeat numbers so if I allow repeat numbers then you

473
00:52:45,720 --> 00:52:50,440
can have a long run of fives and the first half of them could be one I'll go type the second half

474
00:52:50,440 --> 00:52:54,200
could be the other and the actual sorting algorithm would be perfectly happy to keep them as is because

475
00:52:54,200 --> 00:52:58,840
the fives are between the four yeah so so we did that and and when you do that you find out that

476
00:52:58,840 --> 00:53:03,080
yeah if you let them do that it actually goes higher the the tendency to cluster is actually

477
00:53:03,080 --> 00:53:08,440
higher that you know so there's this like competing you know and and again looking at it it almost

478
00:53:08,440 --> 00:53:16,520
it almost provides a very minimal model of of the existential sort of I don't know way of life

479
00:53:16,520 --> 00:53:21,400
facing living systems right that the physics of the world are like you're trying to grind you down

480
00:53:21,400 --> 00:53:25,320
but but in the meantime you can do some interesting things that are not incompatible

481
00:53:25,320 --> 00:53:29,240
with them there's no magic I mean it does the algorithm there's no you know there's no errors

482
00:53:29,240 --> 00:53:33,880
but but but yet not quite what what the you know what what the end goal is going to be

483
00:53:33,880 --> 00:53:36,840
according to the actual physics of the system yeah

