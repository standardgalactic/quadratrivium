WEBVTT

00:00.600 --> 00:01.680
No, that's great.

00:01.680 --> 00:03.560
Okay, so maybe we could start.

00:03.560 --> 00:05.840
I think, Alex, if you could start

00:05.840 --> 00:10.840
and just give a few more words on this,

00:11.160 --> 00:13.240
the whole notion of mortal computation

00:13.240 --> 00:18.240
and specifically the issue of programmability

00:18.720 --> 00:23.720
and morphology and how we can sort of distinguish

00:24.920 --> 00:26.000
when we're looking at a system,

00:26.000 --> 00:27.680
how can we distinguish what aspects

00:27.680 --> 00:30.840
of mortal computation we're looking at.

00:30.840 --> 00:32.040
Anything along those lines,

00:32.040 --> 00:34.160
I think would be very useful for us.

00:34.160 --> 00:35.880
Maybe we could start there.

00:35.880 --> 00:38.760
Yeah, so I did, by the way, read last night

00:38.760 --> 00:41.520
the paper you shared with me and Carl and Chris

00:41.520 --> 00:44.640
at one point and some of your notions in there.

00:44.640 --> 00:46.880
First of all, a lot of it sounds like parts

00:46.880 --> 00:49.480
of mortal computation, just maybe you're not using

00:49.480 --> 00:51.240
the word mortal computation phrase.

00:52.240 --> 00:56.360
So in terms of the morphology part,

00:56.360 --> 00:59.040
so the argument that Carl and I make in that paper

00:59.040 --> 01:01.560
is just that the structure, right,

01:01.560 --> 01:05.320
is critically important to the actual system itself.

01:05.320 --> 01:07.360
So you don't want to devour,

01:07.360 --> 01:11.040
there's a lot of this idea of the amorphic formulation

01:11.040 --> 01:12.880
of computational models.

01:12.880 --> 01:16.200
So when you take, and actually Carl and Chris had a paper

01:16.200 --> 01:19.480
that predated the mortal computation paper,

01:19.520 --> 01:22.080
but we developed that metaphor further,

01:22.080 --> 01:26.480
you can draw a dot and arrow diagram of a neural network

01:26.480 --> 01:31.160
and that endows it with this pedagogical morphology,

01:31.160 --> 01:32.960
but really at the end of the day, it doesn't matter.

01:32.960 --> 01:35.120
It's just a pile of linear algebra

01:35.120 --> 01:36.840
that will do its calculations.

01:36.840 --> 01:38.360
And then we have to go through

01:38.360 --> 01:41.400
the von Neumann computing architecture

01:41.400 --> 01:44.040
to transmit the weight, memory and all that.

01:44.040 --> 01:47.560
And then that's where this great thermodynamic cost.

01:47.560 --> 01:52.280
So living systems, I know as you know very well, Michael,

01:52.280 --> 01:54.400
but in general are inherently morphic.

01:54.400 --> 01:56.400
And actually this is the part where we didn't have it

01:56.400 --> 02:00.000
in the paper, but your paper used the word polycomputing,

02:00.000 --> 02:01.720
which is the idea that a substance

02:01.720 --> 02:03.840
can compute many different things simultaneously

02:03.840 --> 02:06.320
is like one way to look at that word.

02:06.320 --> 02:08.800
And the idea is that it's all about the substrate.

02:08.800 --> 02:11.240
And so mortal computation then just says,

02:11.240 --> 02:14.120
if we're going to think about artificial

02:14.120 --> 02:16.680
general intelligence or machine intelligence,

02:16.680 --> 02:18.360
we're sort of going about it in the wrong,

02:18.360 --> 02:21.360
potentially wrong direction by having this divorce

02:21.360 --> 02:25.000
of the computational architecture and construct

02:25.000 --> 02:28.240
separate from the morphology or the substrate too,

02:28.240 --> 02:30.200
that this is going to be enacted on

02:30.200 --> 02:33.880
because living systems, if you change the morphology,

02:33.880 --> 02:36.160
you change the properties of the system,

02:36.160 --> 02:38.840
you change also what it can compute, what it can do.

02:38.840 --> 02:42.480
Now you talk about the liquid kind of brain

02:42.480 --> 02:45.120
or the idea that we have this self over time,

02:45.120 --> 02:49.120
which doesn't actually sit at odds with mortal computation.

02:49.120 --> 02:52.640
So the idea is that you're constantly through change,

02:52.640 --> 02:56.280
you're persisting, you're almost like I want to persist,

02:56.280 --> 02:57.960
but I understand that my system

02:57.960 --> 02:59.920
is going through like auto pieces.

02:59.920 --> 03:02.080
So mortal computation sort of absorbs that

03:02.080 --> 03:04.040
and tries to say we should be designing systems

03:04.040 --> 03:05.420
from that perspective.

03:06.360 --> 03:08.720
So just so I don't keep rambling,

03:08.720 --> 03:11.720
you were talking about programmability.

03:11.720 --> 03:13.600
And I think that was an interesting part

03:13.600 --> 03:16.200
that we didn't really get to chat a whole lot about

03:16.200 --> 03:19.320
and it wasn't 100% clear what was meant

03:19.320 --> 03:23.120
by programming the morphology or the system

03:23.120 --> 03:24.960
because actually after reading your paper,

03:24.960 --> 03:27.560
I think that sort of gave the answer as to how,

03:27.560 --> 03:29.240
because I said originally, oh well,

03:29.240 --> 03:32.440
I'm thinking that the morphology or the substrate

03:32.440 --> 03:34.880
dictates strictly what you can and can't do.

03:34.880 --> 03:37.080
Yes, it will change and it will repair

03:37.080 --> 03:40.960
and go through damage or do things like self-replication.

03:40.960 --> 03:43.160
But I wasn't thinking about the human designer,

03:43.160 --> 03:45.720
he would say if we are designing a chimeric system

03:45.720 --> 03:49.160
or something new, manipulating that morphology so easily,

03:49.160 --> 03:50.800
it's more like, well, we're gonna be looking

03:50.800 --> 03:54.120
at computational simulations of that

03:54.120 --> 03:55.520
and that would be programmable.

03:55.520 --> 03:56.920
And then that's where I was talking about,

03:56.920 --> 04:00.280
oh, we could do like a software simulation

04:00.280 --> 04:04.440
of Anthrobots or something, or Xenobots of that form.

04:04.440 --> 04:06.960
And then you could sort of set the properties

04:06.960 --> 04:09.840
of the environment in the system roughly

04:09.840 --> 04:11.480
according to something you wanna look at

04:11.480 --> 04:13.840
and then simulate it and see what it does.

04:13.840 --> 04:15.960
But then your paper sort of essentially,

04:15.960 --> 04:19.320
in your work as an example of you can directly program

04:19.320 --> 04:24.240
like the genetic aspects of a system,

04:24.240 --> 04:27.440
or you can kind of manipulate the bioelectrical chemicals.

04:27.440 --> 04:31.480
You had an example of like a tadpole or a froglet

04:31.480 --> 04:34.840
where if we apply the right electrical stimulation,

04:34.840 --> 04:37.840
you can get it to grow a tail or get it to grow a leg

04:37.840 --> 04:38.960
and there's some properties there.

04:38.960 --> 04:43.360
So I think that is where the programmability is.

04:43.360 --> 04:44.640
And then that would be more,

04:44.640 --> 04:46.920
you would have even actual experience

04:46.920 --> 04:48.640
programming the morphologies.

04:48.640 --> 04:51.080
Whereas I was thinking more from the perspective

04:51.080 --> 04:55.080
of neural networks where we have the structure

04:55.080 --> 04:57.240
and we want that to now be at the very top

04:57.240 --> 04:59.120
of what Karl and I call mills.

04:59.120 --> 05:00.400
And that you remember in the paper,

05:00.400 --> 05:03.160
there's the mortal inference learning and selection.

05:03.160 --> 05:05.240
And at the very, very top is structure.

05:05.240 --> 05:08.080
And that would be something that I think is underexplored

05:08.120 --> 05:11.720
in the area about, oh, maybe we have neurogenesis

05:11.720 --> 05:14.200
and naphyogenesis and then the system sort of has to use

05:14.200 --> 05:18.040
that as another aspect of how it evolves over time.

05:18.040 --> 05:19.640
But that was thought of,

05:19.640 --> 05:22.040
or at least the way I was writing it originally,

05:22.040 --> 05:24.280
it's sort of doing that in its own way.

05:24.280 --> 05:25.960
You're not really involved in saying,

05:25.960 --> 05:28.280
oh, I'm gonna help you do model selection,

05:28.280 --> 05:30.480
but maybe if you encode priors,

05:30.480 --> 05:32.280
that was the other aspect I had.

05:32.280 --> 05:34.120
If you were encoding certain constraints,

05:34.120 --> 05:37.280
you say, well, I just, I'm gonna play,

05:37.280 --> 05:39.280
I'm gonna skip ahead for what evolution

05:39.280 --> 05:41.960
would naturally walk, randomly walk you to and say,

05:41.960 --> 05:43.800
these types of structures are invalid.

05:43.800 --> 05:45.680
That would be like programming,

05:45.680 --> 05:47.880
maybe structure from that perspective.

05:47.880 --> 05:49.520
I don't know if this is making sense,

05:49.520 --> 05:51.320
but I think it's a tricky topic

05:51.320 --> 05:54.800
because I wasn't entirely sure what exactly two

05:54.800 --> 05:56.320
was meant by programmability

05:56.320 --> 05:59.160
because you have experience actually doing that.

05:59.160 --> 06:03.160
So the answer is yes, it can be done from your perspective

06:03.160 --> 06:06.680
and we would just be translating it to chimeric systems

06:06.720 --> 06:08.080
or artificial systems

06:08.080 --> 06:11.240
rather than it only just being like biological material.

06:12.240 --> 06:13.520
I hope that makes sense.

06:13.520 --> 06:15.920
Yeah, yeah, I mean, the kind of programmability

06:15.920 --> 06:18.640
I had in mind, so just as an example,

06:18.640 --> 06:20.880
we have these flatworms, these planaria,

06:20.880 --> 06:22.720
and you can chop them into pieces

06:22.720 --> 06:24.560
and every piece regrows a complete,

06:24.560 --> 06:26.400
perfectly patterned little worm.

06:26.400 --> 06:28.200
And you could ask the question,

06:28.200 --> 06:30.200
how does it know how many heads to make?

06:30.200 --> 06:32.600
And so it turns out that there's an electrical pattern

06:32.600 --> 06:35.400
that sort of a body-wide electrical pattern

06:35.400 --> 06:38.080
that dictates the number and the location of the head.

06:38.080 --> 06:40.160
And the amazing thing about that substrate

06:40.160 --> 06:43.560
is that if you change that pattern,

06:43.560 --> 06:44.560
the tissue will hold it.

06:44.560 --> 06:46.160
So we can change the pattern to say no,

06:46.160 --> 06:48.240
two heads instead of one, and it holds.

06:48.240 --> 06:51.520
And those worms in perpetuity forevermore,

06:51.520 --> 06:53.400
despite their completely normal genetics,

06:53.400 --> 06:56.520
will continue to regenerate as two-headed worms.

06:56.520 --> 06:59.680
So it's a very minimal example of reprogrammability

06:59.680 --> 07:02.280
because we don't have anything like complete control yet,

07:02.280 --> 07:03.960
I think in the future, maybe we will,

07:03.960 --> 07:05.680
but at the moment we don't.

07:05.680 --> 07:08.640
But it is an example where the hardware

07:08.640 --> 07:11.320
in an important sense, so the genetics are normal,

07:11.320 --> 07:13.440
all this, there are no weird nanomaterials,

07:13.440 --> 07:14.520
there's no genomic editing,

07:14.520 --> 07:17.160
there are no synthetic biology circuits,

07:17.160 --> 07:20.680
it's stock hardware, but because of this experience,

07:20.680 --> 07:23.000
this physiological experience that it's had,

07:23.000 --> 07:25.200
it now has a different pattern that it uses

07:25.200 --> 07:27.400
as the sort of target morphology

07:27.400 --> 07:29.600
of what it's going to do if it gets cut.

07:29.600 --> 07:31.760
So that's the kind of thing,

07:31.880 --> 07:34.120
the kind of plasticity that it has where

07:34.120 --> 07:37.200
the material is basically the same,

07:37.200 --> 07:41.400
but it has really a memory of a past event

07:41.400 --> 07:43.200
and that memory guides how it behaves

07:43.200 --> 07:44.920
in anatomical space in the future.

07:44.920 --> 07:47.800
So that's the kind of thing I wanted to sort of explore

07:47.800 --> 07:50.000
with respect to this framework.

07:51.560 --> 07:54.520
And I don't think what you described is at odds

07:54.520 --> 07:57.160
with what you would do with a mortal computer.

07:57.160 --> 08:00.440
I mean, the idea is that is where the programmability

08:00.440 --> 08:02.880
comes into play, you're kind of encoding that

08:02.880 --> 08:04.600
and then seeing how the morphology

08:04.600 --> 08:06.160
and the system evolve over time.

08:06.160 --> 08:08.920
If you want the two-headed worm example,

08:08.920 --> 08:11.240
I don't see any reason why that wouldn't translate

08:11.240 --> 08:15.720
to artificial systems or maybe non-biological systems

08:15.720 --> 08:18.680
if we are able to formulate what that morphology looks like.

08:18.680 --> 08:20.600
I think the key is setting that up

08:20.600 --> 08:23.120
and that's what Carl and I have at the very end of the paper

08:23.120 --> 08:26.080
we talk about, well, for example, someone like me,

08:26.080 --> 08:28.320
a computational neuroscientist, computer scientist,

08:28.320 --> 08:31.000
I don't have access to Xenobots

08:31.000 --> 08:33.320
or the biological material that I'd love to,

08:33.320 --> 08:34.280
or organoids, right?

08:34.280 --> 08:36.560
I really find those fascinating,

08:36.560 --> 08:37.840
but maybe we could simulate them

08:37.840 --> 08:40.480
and that's what we have at the appendix, actually,

08:40.480 --> 08:43.720
at the already long paper, digital morphology.

08:43.720 --> 08:46.360
Maybe that could be a way to sort of bridge the gap

08:46.360 --> 08:48.480
between the computational researchers

08:48.480 --> 08:50.120
and researchers like yourself.

08:50.120 --> 08:53.400
Oh, can we come up with benchmarks or system setups

08:53.400 --> 08:56.040
that I could play with the properties,

08:56.080 --> 08:57.920
mathematical models, maybe,

08:57.920 --> 09:00.280
of these biological morphologies

09:00.280 --> 09:02.720
and then kind of do investigation, right,

09:02.720 --> 09:06.520
without the costs and the barriers to entry

09:06.520 --> 09:08.840
to working with biological material

09:08.840 --> 09:10.520
or some of the things I don't have.

09:10.520 --> 09:13.080
So I don't see anything at odds.

09:13.080 --> 09:15.880
I don't know if Carl would wanna add anything

09:15.880 --> 09:18.220
that I might be missing or not getting.

09:22.680 --> 09:24.840
No, that was very fluent.

09:24.960 --> 09:26.960
I think you've covered everything there.

09:29.320 --> 09:31.640
If I can just jump in for a minute.

09:31.640 --> 09:36.640
It seems to me that this dimension of programmability

09:37.840 --> 09:42.840
could also be expressed as the dimension from uniqueness,

09:44.360 --> 09:47.240
which mortal computers, as I understand it,

09:47.240 --> 09:50.600
have more of than my laptop,

09:51.600 --> 09:56.600
to replicability or exact replicability, copyability.

09:59.880 --> 10:04.400
And to the extent that a system is really unique,

10:04.400 --> 10:05.680
you can't program it.

10:08.680 --> 10:13.680
And in part, just because you don't have two copies of it,

10:13.880 --> 10:16.720
so you can't test what you're doing in any way.

10:16.720 --> 10:18.480
You can't test reproducibility

10:18.480 --> 10:21.600
if you're working with a system that's completely unique.

10:26.000 --> 10:31.000
And biological systems are somewhere in the middle, right?

10:31.160 --> 10:34.560
Laptops are intended to be way out

10:34.560 --> 10:37.160
on the extreme replicability end.

10:38.760 --> 10:43.760
And so because a laptop is completely replicable,

10:45.360 --> 10:47.640
it's a completely generic entity,

10:49.320 --> 10:52.000
it's almost a Turing machine, right?

10:52.000 --> 10:54.420
It's almost just an abstraction.

10:55.800 --> 10:57.880
And so when we're programming,

10:57.880 --> 10:59.800
we can treat it as an abstraction.

10:59.800 --> 11:02.320
And we don't have to worry about things like

11:02.320 --> 11:03.720
where the power comes from

11:03.720 --> 11:08.720
and why the thing maintains the same shape over time

11:09.120 --> 11:11.520
and et cetera, et cetera.

11:11.520 --> 11:14.560
I mean, if it doesn't maintain the same shape over time,

11:14.560 --> 11:15.920
you take it to the repair shop

11:15.920 --> 11:17.680
or recycle it and buy another one.

11:19.480 --> 11:21.680
Whereas in biological systems,

11:21.680 --> 11:24.520
you have to worry about all of that stuff.

11:24.520 --> 11:27.320
And as you point out in the paper,

11:28.760 --> 11:33.760
and as the 4E people kind of have been pointing out

11:33.880 --> 11:38.880
for decades now, that's part of the algorithm,

11:39.920 --> 11:44.920
or that's part of the operating system, that shape.

11:45.680 --> 11:49.640
Whereas it's not involved at all in my laptop

11:49.640 --> 11:51.000
in the operating system.

11:51.000 --> 11:52.640
I mean, even the operating system

11:52.640 --> 11:55.360
can treat the hardware as an abstraction.

11:57.240 --> 12:02.240
So we can, I think more or less identify those two axes,

12:03.920 --> 12:06.040
the dimension of programmability

12:06.040 --> 12:07.680
and the dimension of uniqueness.

12:09.520 --> 12:14.240
And so one of the things that you emphasized in your paper,

12:14.280 --> 12:16.960
I thought this was very interesting,

12:16.960 --> 12:21.960
was the energetics of using the body

12:23.960 --> 12:26.040
as part of the operating system.

12:27.920 --> 12:32.920
And it meant that you didn't have to pay for a lot of memory,

12:36.120 --> 12:39.240
for example, or quite so much processing power.

12:39.680 --> 12:44.240
You do, of course, have to pay the cost

12:44.240 --> 12:46.320
of keeping the body intact.

12:48.000 --> 12:53.000
But as you pointed out, at least in organisms,

12:53.000 --> 12:58.000
that's cheaper than the cost of stamping out more laptops

12:58.880 --> 13:02.120
and then equipping them with enough voltage

13:02.120 --> 13:05.160
to keep them in the classical domain

13:05.160 --> 13:08.160
so that they don't start acting like quantum computers,

13:08.160 --> 13:09.440
which they actually are.

13:11.880 --> 13:16.880
So I think that it would be useful to try to

13:18.520 --> 13:21.080
relate this issue or resource cost

13:21.080 --> 13:23.360
to the issue of uniqueness,

13:25.440 --> 13:28.120
and as well as the issue of programmability.

13:28.120 --> 13:30.920
I'm not sure whether those are,

13:30.920 --> 13:33.000
I suspect those are distinct dimensions,

13:33.000 --> 13:37.440
but I think the usable area of that state space

13:37.440 --> 13:40.400
involves a lot of correlation between those dimensions.

13:44.080 --> 13:45.040
Yeah, I agree.

13:45.040 --> 13:48.520
I think that would be very interesting to explore.

13:48.520 --> 13:50.800
I don't know, Michael, if that resonated with you,

13:50.800 --> 13:52.920
because I feel like that touches on even

13:52.920 --> 13:56.160
pairing the Mortal Computation paper for me and Carl

13:56.160 --> 13:59.160
in the paper you shared with all of us, of yours.

13:59.160 --> 14:01.560
I think the two sort of start to get into that idea

14:01.560 --> 14:05.120
of uniqueness, programmability, and resource cost.

14:05.120 --> 14:06.960
And there are some different dimensions

14:06.960 --> 14:07.800
that you could explore,

14:07.800 --> 14:10.280
because yeah, I also just wanted to comment, Chris,

14:10.280 --> 14:14.960
that at least when I first was writing the paper

14:14.960 --> 14:16.440
and then I shared it with Carl,

14:16.440 --> 14:18.920
I wasn't thinking of the,

14:18.920 --> 14:20.840
I was thinking of biological systems

14:20.840 --> 14:22.560
as sort of an ideal target, right?

14:22.560 --> 14:25.680
You're sort of emulating some aspects of those systems.

14:25.680 --> 14:28.280
So I guess I'd be giving up some uniqueness, right?

14:28.280 --> 14:31.760
Because you said it lies in between the immortal laptop

14:31.760 --> 14:34.720
and the perfectly unique system itself.

14:34.720 --> 14:37.280
I think the other thing I was concerned with

14:37.280 --> 14:39.800
is the artificial intelligence community

14:39.800 --> 14:43.400
really liking the idea of immortal computation

14:43.400 --> 14:45.080
and that complete divorcing,

14:45.080 --> 14:48.280
because you're right, you do lose the moment you leave,

14:48.280 --> 14:51.360
even just a few steps away from immortal computation,

14:51.360 --> 14:54.160
that reproducibility, because it's,

14:54.160 --> 14:56.360
that substrate now is important.

14:56.360 --> 14:59.000
And then Carl and I argue even stronger,

14:59.000 --> 15:01.200
it's the morphogenesis too,

15:01.200 --> 15:02.880
and the changing process, which again,

15:02.880 --> 15:05.880
compliments your paper, Michael, as well.

15:05.880 --> 15:08.920
The idea is that change is also very important

15:08.920 --> 15:10.680
in that evolution over time,

15:10.680 --> 15:12.360
which is not something you're going to have

15:12.360 --> 15:14.480
on your typical deep neural network

15:14.480 --> 15:18.040
that just lives at the top of the von Neumann architecture.

15:18.040 --> 15:20.080
And then the last comment I just wanted to make, Chris,

15:20.080 --> 15:22.760
is yes, that's exactly the key,

15:22.760 --> 15:25.720
is that in-memory processing that we want.

15:25.720 --> 15:29.080
And that's why bringing ourselves as close as possible

15:29.080 --> 15:31.840
until we eventually just reach what we can,

15:31.840 --> 15:33.520
which is the Landauer limit,

15:33.520 --> 15:35.600
and getting ourselves real close to the hardware,

15:35.600 --> 15:39.040
now we're optimizing thermodynamic cost.

15:39.040 --> 15:41.320
And then of course, as you and Carl

15:41.320 --> 15:43.640
and everyone here has shown over time,

15:43.640 --> 15:46.960
that's the flip side to the information theoretic,

15:46.960 --> 15:49.880
variational free energy, but the thermodynamic free energy.

15:49.880 --> 15:51.960
But at the end of the day, we want to be there,

15:51.960 --> 15:53.960
because that's what biological systems are.

15:53.960 --> 15:57.160
They are much closer to the Landauer limit

15:57.160 --> 16:00.640
than pretty much anything in machine intelligence

16:00.640 --> 16:01.600
that we have today.

16:01.600 --> 16:03.840
And that would argue it's even getting worse

16:03.840 --> 16:07.680
because big, big transformers are really bad.

16:07.680 --> 16:10.960
And Carl also and I state the carbon footprint.

16:10.960 --> 16:12.720
So that's a good motivator.

16:15.960 --> 16:18.840
Yeah, I find that energetic analysis very compelling.

16:20.880 --> 16:25.440
You know, I'm very interested in why biological systems

16:25.440 --> 16:26.760
can be quite so efficient.

16:26.760 --> 16:30.240
And I think in many cases, they're efficient

16:30.240 --> 16:34.120
because they're able to use quantum resources

16:35.720 --> 16:38.400
when they're doing molecular computing.

16:38.400 --> 16:42.120
And maybe even when they're doing macromolecular computing.

16:45.200 --> 16:49.000
I guess the one other comment about a dimension

16:49.000 --> 16:51.120
that I wanted to throw in,

16:51.120 --> 16:53.800
which you mentioned a little bit about in the paper,

16:53.800 --> 16:58.800
was this dimension of explainability.

17:01.240 --> 17:06.240
Which AI is very obsessed with the explanation problem now.

17:10.160 --> 17:15.160
And as one gets away from reproducibility,

17:15.600 --> 17:18.520
the explanation problem gets harder and harder.

17:18.520 --> 17:21.600
And in the limit of a unique system,

17:21.600 --> 17:23.840
the explanation problem is infinitely hard

17:23.840 --> 17:26.280
because you can't do experiments.

17:26.280 --> 17:28.640
Because you can't replicate anything.

17:29.640 --> 17:34.640
So we have that other access to work with also.

17:42.440 --> 17:44.680
Maybe it would be kind of interesting

17:44.680 --> 17:48.000
is since you were bringing up these so far three axes

17:48.000 --> 17:52.080
that I caught, you know, uniqueness, programmability,

17:52.080 --> 17:55.320
explainability, we also did talk about resource cost,

17:55.320 --> 17:56.960
kind of putting out this grid

17:57.120 --> 18:00.600
and then you saw Michael and actually I presented,

18:00.600 --> 18:02.080
you guys would have seen in the paper,

18:02.080 --> 18:03.600
but I presented it a couple of times,

18:03.600 --> 18:05.320
like the different types of things

18:05.320 --> 18:09.240
that Carl and I consider variants of mortal computers.

18:09.240 --> 18:11.920
And so obviously Xenobot is a mortal computer.

18:11.920 --> 18:13.840
It actually had a lot more qualities

18:13.840 --> 18:16.880
after I re-read papers again, looking back.

18:16.880 --> 18:20.080
But even, you know, the silicon model

18:20.080 --> 18:23.720
that we had for the non-biological model from Ashby,

18:23.720 --> 18:27.400
we can never forget the great homeostat or allostat.

18:27.400 --> 18:29.880
And so maybe we could plot these a little bit

18:29.880 --> 18:34.080
on those axes too is what degrees that they're trading off.

18:34.080 --> 18:35.840
Obviously we need to figure out

18:35.840 --> 18:38.920
which one of these starts to get real close to the,

18:38.920 --> 18:41.520
like you said, Chris, the really unique.

18:41.520 --> 18:43.880
And then, you know, that would be the extreme one

18:43.880 --> 18:46.160
where explainability would be, you know,

18:46.160 --> 18:47.680
really, really, really difficult.

18:47.680 --> 18:49.400
And we could kind of plot where those are.

18:49.400 --> 18:52.400
That could be an interesting figure to show examples.

18:52.400 --> 18:55.080
And I'm sure, Michael, you probably have other examples

18:55.080 --> 18:57.600
that Carl and I might have missed.

18:57.600 --> 19:01.680
So there might be some other nice biological chimeric systems,

19:01.680 --> 19:03.400
things that are even less biological,

19:03.400 --> 19:04.840
but have a little bit of it.

19:04.840 --> 19:08.040
You did touch on nano technology as well.

19:08.040 --> 19:11.680
And in your, the polycomputing paper you shared with us.

19:11.680 --> 19:13.880
So maybe there might be some in soft robotics.

19:13.880 --> 19:15.240
There might be something there too

19:15.240 --> 19:19.400
that could count as variations to mortal computers

19:19.400 --> 19:21.160
that trade off on these axes.

19:21.160 --> 19:22.000
That's something else.

19:22.000 --> 19:24.720
I just thought of this, Chris explaining.

19:26.480 --> 19:29.720
Yeah, so another model system to think about.

19:29.720 --> 19:33.840
And by the way, we do have simulators of some of this stuff.

19:33.840 --> 19:36.440
So we should be in touch, you know,

19:36.440 --> 19:37.520
give you access to some of that

19:37.520 --> 19:41.000
because maybe you can do some analyses.

19:41.000 --> 19:42.680
You know, we have bioelectric simulators

19:42.680 --> 19:43.680
and things like that.

19:44.800 --> 19:47.400
You know, another kind of model system to think about,

19:47.400 --> 19:50.800
and this is something that Patrick is doing at the bench.

19:50.800 --> 19:53.080
And then I have somebody who is doing this,

19:53.080 --> 19:55.080
you know, the computational analysis of it,

19:55.080 --> 19:57.600
are these gene regulatory networks, right?

19:57.600 --> 20:00.120
And so the abstraction, of course, is quite simple.

20:00.120 --> 20:04.240
It's just, in the continuous case, it's a few ODE's

20:04.240 --> 20:05.760
and they just, you know, their nodes

20:05.760 --> 20:07.960
that turn each other on and off and that's it.

20:07.960 --> 20:09.720
But if you study these things,

20:09.720 --> 20:13.040
you find some really interesting features.

20:13.040 --> 20:15.840
For us, one of the most interesting things is that

20:15.840 --> 20:20.440
if you do temporary stimulation

20:20.440 --> 20:21.440
of the different nodes, right?

20:21.440 --> 20:23.080
So you just grab one of the node values

20:23.080 --> 20:25.360
and you crank it up or down for a little bit

20:25.360 --> 20:29.360
and you keep the structure of the network completely fixed.

20:29.360 --> 20:31.080
So you're not changing the weights,

20:31.080 --> 20:33.000
you're not changing the topology,

20:33.000 --> 20:34.520
the hardware is completely fixed.

20:34.520 --> 20:37.120
All you get to do is temporarily raise or lower

20:37.120 --> 20:39.320
the activation of any node

20:39.320 --> 20:41.080
and then you wait and you see what happens, right?

20:41.080 --> 20:42.440
So if you do that and if you treat it

20:42.440 --> 20:45.240
in a sort of behavioral science context,

20:45.240 --> 20:48.680
you can show things like habituation,

20:49.520 --> 20:51.120
basically six different kinds of memory,

20:51.120 --> 20:52.880
including Pavlovian conditioning.

20:52.880 --> 20:54.280
So these things learn.

20:54.280 --> 20:58.080
And we've been very interested in this question.

20:58.080 --> 20:59.920
I mean, so I have a couple of papers showing how they learn,

20:59.920 --> 21:03.160
but one of the really interesting things

21:03.160 --> 21:06.680
is because we don't let the hardware vary.

21:06.680 --> 21:07.960
So this is not a scenario

21:07.960 --> 21:09.080
where there's some kind of synapse

21:09.080 --> 21:12.000
whose weight gets tweaked by experience.

21:12.000 --> 21:14.320
The fact that they learn the most,

21:14.320 --> 21:16.480
to me, one of the most interesting things about it is,

21:16.480 --> 21:18.480
where is the learning stored?

21:18.480 --> 21:20.800
And this is something that all of the reviewers

21:20.800 --> 21:22.560
of the original two papers got hung up on

21:22.560 --> 21:25.480
because we say again and again, the hardware does not change.

21:25.480 --> 21:27.080
And then they all said, great,

21:27.080 --> 21:29.600
but then you can't have it

21:29.600 --> 21:32.280
because where could the memory possibly be, right?

21:32.280 --> 21:34.320
And it's this dynamical systems thing

21:34.320 --> 21:35.920
where they get chased into a regime

21:35.920 --> 21:39.760
where future stimuli are going to cause

21:39.760 --> 21:42.400
very different outcomes because of their history

21:42.400 --> 21:44.080
than past outcomes.

21:44.080 --> 21:47.000
But I wonder, and so this is what I was gonna ask you guys

21:47.000 --> 21:48.280
to kind of think of them,

21:48.280 --> 21:51.520
to talk about from your framework's perspective.

21:51.520 --> 21:54.120
I wonder if the business of uniqueness

21:54.120 --> 21:56.960
is related to this sort of issue.

21:56.960 --> 21:59.760
I think maybe called privacy or something like that,

21:59.760 --> 22:02.640
this idea that there is an inner perspective to a system

22:02.640 --> 22:05.000
that's had a certain set of experiences, right?

22:05.000 --> 22:06.800
It has a history in the world

22:06.800 --> 22:10.680
that is not available to outside observers.

22:10.680 --> 22:14.800
And this is, we spent a lot of time with my postdoc,

22:15.120 --> 22:17.440
Federico and I spent a lot of time thinking about,

22:17.440 --> 22:18.640
you look at a network,

22:18.640 --> 22:20.640
can you tell whether it's been trained?

22:20.640 --> 22:22.880
And if so, what hasn't been, like, can you read its mind,

22:22.880 --> 22:25.120
you know, this kind of neural decoding kind of thing

22:25.120 --> 22:26.640
because you're not gonna get it from the hardware.

22:26.640 --> 22:28.160
You can, the nodes are no different, right?

22:28.160 --> 22:31.080
So in fact, we have a visualizer

22:31.080 --> 22:34.000
that tries to show various aspects of it.

22:34.000 --> 22:36.760
And if you, you know, on the left and right of the screen,

22:36.760 --> 22:39.480
first you start off with the hardware of view of it.

22:39.480 --> 22:42.360
And that never changes throughout the whole time.

22:42.360 --> 22:43.760
But as it learns, right,

22:43.760 --> 22:46.320
over multiple experiences and stimuli,

22:46.320 --> 22:48.000
something absolutely changes.

22:48.000 --> 22:49.840
And then we have some ways of thinking about it.

22:49.840 --> 22:54.120
But this question of, can you, as an outsider,

22:54.120 --> 22:56.160
is there anything about mortal computation

22:56.160 --> 23:00.160
that speaks to this issue of what you can tell

23:00.160 --> 23:02.280
about a system as an outside observer

23:02.280 --> 23:04.920
versus what you know as the system yourself?

23:04.920 --> 23:06.480
You know, from the inner perspective,

23:06.480 --> 23:08.480
is that something you guys think about?

23:09.480 --> 23:11.400
Well, I'm gonna give a piece of it

23:11.400 --> 23:14.280
and then I'm gonna hope Carl can tag in a little bit

23:14.280 --> 23:18.000
because I think he can flesh this out a little bit better.

23:18.000 --> 23:20.720
So, and this might be confusion

23:20.720 --> 23:22.520
over what you might have explained, Michael,

23:22.520 --> 23:23.680
about the reviewers.

23:23.680 --> 23:26.280
So you said, I fixed the hardware

23:26.280 --> 23:28.600
and on top of that, I fixed the plasticity

23:28.600 --> 23:30.320
because you said we can't change the, you know,

23:30.320 --> 23:34.240
the values of the synapses or the connection strengths.

23:34.240 --> 23:37.200
And I do think mortal computer, mortal computation,

23:37.240 --> 23:38.200
we did address this.

23:38.200 --> 23:40.920
So Carl and I decomposed it in, again,

23:40.920 --> 23:42.960
it goes back to mills.

23:42.960 --> 23:44.520
But again, I might be misunderstanding.

23:44.520 --> 23:46.760
So we're gonna decouple the privacy

23:46.760 --> 23:48.560
and the observer perspective

23:48.560 --> 23:50.760
because I wanna hear what Carl might have to say to that.

23:50.760 --> 23:53.320
But for why learning would still happen,

23:53.320 --> 23:56.600
even when you fix those things, it's just the inference.

23:56.600 --> 23:59.000
And the way that we looked at it in mills

23:59.000 --> 24:01.800
was there's these different time scales of learning.

24:01.800 --> 24:05.880
So if you were to pin the structure of the S and mills

24:05.920 --> 24:09.760
and then pin L and say, you can't modify those.

24:09.760 --> 24:11.360
Well, we still had one more piece,

24:11.360 --> 24:13.600
which was the very fast time scale.

24:13.600 --> 24:16.400
And you talk in your poly computing paper,

24:16.400 --> 24:18.120
I've done a lot of work in that.

24:18.120 --> 24:19.680
Carl obviously has done a lot as well,

24:19.680 --> 24:21.840
predictive coding, predictive processing.

24:21.840 --> 24:23.680
We always have the inference dynamic.

24:23.680 --> 24:27.400
So the idea is that, and I'm sure you thought of this.

24:27.400 --> 24:28.600
This is why I was kind of surprised

24:28.600 --> 24:31.480
the reviewers were maybe not understanding.

24:31.480 --> 24:33.520
So there's like short-term plasticity, right?

24:33.560 --> 24:36.000
So the idea is that when you're doing

24:36.000 --> 24:39.080
expectation maximization in a predictive coding network,

24:39.080 --> 24:41.880
I can still change the neuronal activities,

24:41.880 --> 24:44.000
the firing rates or the spiking rates,

24:44.000 --> 24:45.760
depending on what model you're constructing.

24:45.760 --> 24:47.600
And the synapses never change

24:47.600 --> 24:49.480
and forget about the morphology

24:49.480 --> 24:52.120
because that's a whole nother ball game.

24:52.120 --> 24:53.680
And I would get adaptation.

24:53.680 --> 24:56.720
And there was a very interesting paper that came out,

24:56.720 --> 24:59.160
I don't know now, just like two weeks ago,

24:59.160 --> 25:03.240
Wolfgang Maas in spiking neural nets talked about,

25:03.240 --> 25:05.520
well, look, I don't need to modify the synapses.

25:05.520 --> 25:08.840
I'm gonna do everything in my spiking neural architecture

25:08.840 --> 25:11.400
with just homeostatic variables,

25:11.400 --> 25:12.880
which is, you didn't call it them,

25:12.880 --> 25:14.680
but that's just the adaptive thresholds.

25:14.680 --> 25:15.880
He's like, if these change,

25:15.880 --> 25:20.880
so we have this short-term kind of non-synaptic adaptation,

25:21.520 --> 25:22.560
you get all these effects.

25:22.560 --> 25:23.680
And he actually showed it again,

25:23.680 --> 25:25.240
it's a machine intelligence task,

25:25.240 --> 25:27.080
but showing in all these tasks

25:27.080 --> 25:31.720
without learning in the sense of modifying synapses.

25:31.720 --> 25:33.960
And that was very interesting that you can go very far.

25:33.960 --> 25:35.320
And I'll try to dig up that paper.

25:35.320 --> 25:38.920
It was something I wanted to go in more detail later myself.

25:39.840 --> 25:42.520
So in Mills, right, we're just saying,

25:42.520 --> 25:45.000
well, okay, we're obviously under mortal,

25:45.000 --> 25:46.760
but the inference dynamics

25:46.760 --> 25:49.960
and the fact that these still follow the gradient flow

25:49.960 --> 25:52.120
of the variational free energy

25:52.120 --> 25:53.640
that defines your system

25:53.640 --> 25:56.120
or your functionals that you're looking at

25:56.120 --> 26:01.200
would explain why that adaptation that you found would happen.

26:01.200 --> 26:02.240
And I'm sure you thought of that.

26:02.240 --> 26:05.000
I don't know why the reviewers specifically wouldn't have said,

26:05.000 --> 26:06.160
well, this doesn't make sense.

26:06.160 --> 26:07.600
How could you learn?

26:07.600 --> 26:09.240
If you would pin doll three,

26:09.240 --> 26:10.400
well, it's a static system.

26:10.400 --> 26:11.840
You are freezing it in time.

26:11.840 --> 26:14.200
And then that would baffle me.

26:15.120 --> 26:16.360
So that's my comment

26:16.360 --> 26:18.960
that I do think the framework definitely speaks to that

26:18.960 --> 26:21.760
because Carl and I were very adamant

26:21.760 --> 26:24.360
about the separation of time scales,

26:24.360 --> 26:26.120
at least these big time scales.

26:26.120 --> 26:27.640
I mean, there's all these intermediate ones

26:27.640 --> 26:29.640
that I'm sure you could bring up.

26:29.640 --> 26:30.960
And you need them all

26:30.960 --> 26:32.920
because there's a causal circularity

26:32.920 --> 26:35.800
if you want to build the most powerful type

26:35.800 --> 26:37.720
of mortal computer.

26:37.720 --> 26:39.720
And there was a sentence I can't remember

26:39.720 --> 26:42.880
because Carl and I have done many revisions of that paper.

26:42.880 --> 26:44.560
It might have been in one of the earlier ones

26:44.560 --> 26:46.160
where I mentioned something like,

26:46.160 --> 26:50.160
well, even though I'm seeing morphology as important,

26:50.160 --> 26:52.840
technically, if I was only allowed one,

26:52.840 --> 26:54.320
I still have mills.

26:54.320 --> 26:56.680
It's just a very simple search space, right?

26:56.680 --> 26:58.600
It's a, well, we know that you're here.

26:58.600 --> 27:00.880
You can't change the architecture.

27:00.880 --> 27:02.800
So we didn't break our framework.

27:02.800 --> 27:05.200
So that would allow us to subsume machine learning

27:05.200 --> 27:06.600
and say, well, machine learning

27:06.600 --> 27:09.360
is like this very, very narrow case.

27:09.360 --> 27:13.000
It is doing something that you mills could explain.

27:13.000 --> 27:16.680
It's not mortal, but at least it has like a fixed topology

27:16.680 --> 27:19.280
and synaptic plasticity is there.

27:19.280 --> 27:21.600
And we are just really, really speeding up

27:21.600 --> 27:24.160
the inference dynamics by making it one step

27:24.160 --> 27:27.680
because we don't use EM most times.

27:27.680 --> 27:30.240
And deep neural nets for sure we don't.

27:30.240 --> 27:33.320
So that was my comment about addressing the learning,

27:33.320 --> 27:36.760
the fact that things, if you fix so much,

27:36.760 --> 27:38.320
why would that still happen?

27:38.320 --> 27:39.920
And I definitely think mills,

27:39.920 --> 27:43.580
that piece of the backbone of mortal computation

27:43.580 --> 27:45.280
would speak to that.

27:45.280 --> 27:47.040
Now, in terms of the observer effect

27:47.040 --> 27:50.320
and what does that tell us about what's going on inside?

27:50.320 --> 27:52.160
I have tag team Carl.

27:52.160 --> 27:53.920
What do you have to say to that Carl?

27:58.280 --> 27:59.440
Right.

27:59.440 --> 28:00.720
Well, before I address that,

28:00.720 --> 28:04.600
which in my world is a very simple answer, you can't.

28:04.600 --> 28:08.360
This week I come back to the,

28:08.360 --> 28:10.200
so that was a really interesting exchange

28:10.200 --> 28:13.800
and really interesting examples there.

28:13.800 --> 28:15.760
And I was just thinking from the point of view

28:15.760 --> 28:20.760
of the sort of the classical flows and physics

28:21.360 --> 28:26.120
that would provide a simple picture

28:26.160 --> 28:28.120
of how on earth you can remember stuff

28:28.120 --> 28:30.160
without changing your connection weights.

28:30.160 --> 28:34.400
And I think Alex, you identified the key thing here,

28:34.400 --> 28:36.160
which is the temporal scale.

28:37.080 --> 28:40.240
So, well, where to start?

28:40.240 --> 28:42.120
It's interesting you introduced Wolfgang Maas

28:42.120 --> 28:45.560
because he for many years has been the king

28:45.560 --> 28:48.040
of liquid computation and neck of state machines,

28:48.040 --> 28:51.760
which is not, has the same kind of semantics

28:51.760 --> 28:54.880
as the liquid brain and it's a very powerful

28:55.880 --> 28:58.920
black boxy like kind of a dynamical system

28:58.920 --> 29:03.920
approximator that has been proposed as one architecture

29:04.560 --> 29:06.360
for doing predictive processing

29:06.360 --> 29:10.040
and model computation of the sort.

29:10.040 --> 29:13.360
But the key, I think the key point that has just been made here

29:14.920 --> 29:18.800
is that the dynamics matter

29:18.800 --> 29:23.800
and the dynamics are shaped by the landscape

29:24.600 --> 29:27.200
Lagrangian variation free energy, whatever you want.

29:28.200 --> 29:33.200
And that is a function of the implicit gradients

29:33.640 --> 29:36.840
that depend upon the sensitivity of all say the nodes

29:36.840 --> 29:38.840
in any given network.

29:38.840 --> 29:43.000
That sensitivity can either be read as a connection strength

29:43.000 --> 29:47.880
or it can just be read as a sensitivity,

29:47.880 --> 29:52.480
in terms of to what extent do I change my internal dynamics

29:52.520 --> 29:55.480
given this particular external perturbation.

29:55.480 --> 29:58.920
And of course, that becomes time and context sensitive

29:58.920 --> 30:00.200
with any nonlinearities.

30:00.200 --> 30:03.000
So if you're talking about a nonlinear system,

30:04.240 --> 30:09.240
then there is a, the bright line between the connection

30:09.280 --> 30:12.920
strengths and the current effective connectivity

30:12.920 --> 30:15.440
at this point of time in this context,

30:15.440 --> 30:18.160
in this part of face space or state space

30:18.160 --> 30:19.480
becomes very blurred.

30:20.320 --> 30:22.280
So if you're writing down the differential equations,

30:22.280 --> 30:23.440
you could go one of two ways.

30:23.440 --> 30:27.200
You could just write down a random differential equation

30:27.200 --> 30:32.200
with loads of variables representing interactions

30:32.640 --> 30:35.760
between different types of states

30:35.760 --> 30:38.320
and the response, the rate of change

30:38.320 --> 30:42.200
of any particular state that would entail

30:42.200 --> 30:44.400
the nonlinearity in question.

30:44.400 --> 30:46.160
Or you could arbitrarily say, okay,

30:46.160 --> 30:50.240
now one subset of these variables changes very, very slowly

30:50.280 --> 30:53.200
and I'm gonna call them connection strengths.

30:53.200 --> 30:55.920
And I'm now gonna lift those out of my equation.

30:55.920 --> 30:58.720
So I'm now left with a much simpler sort of

30:58.720 --> 31:00.280
autonomous differential equations

31:00.280 --> 31:02.960
that are now parameterized by other states

31:02.960 --> 31:05.360
that change very, very slowly.

31:05.360 --> 31:07.120
Mathematically, you haven't done anything

31:07.120 --> 31:09.480
but introduce a separation of temporal time scales.

31:09.480 --> 31:13.480
But in so doing, you have now got a different kind of rhetoric

31:13.480 --> 31:18.160
where initially you were talking about voltage sensitive

31:19.120 --> 31:20.720
receptors and sensitivity

31:20.720 --> 31:24.600
and contextualization conductances and the like,

31:24.600 --> 31:26.320
which sets the synaptic efficacy,

31:26.320 --> 31:28.640
which is fluctuating moment to moment.

31:28.640 --> 31:32.320
And now you're talking about these being the connection

31:32.320 --> 31:36.080
strengths, the parameters of your structure

31:36.080 --> 31:41.080
in a mills-like context or the strengths of your connections

31:43.000 --> 31:46.520
or weights in a machine learning context.

31:46.520 --> 31:49.120
But the only difference, I repeat, is just the time scale.

31:49.120 --> 31:51.960
So talking to Mike's example,

31:52.960 --> 31:56.160
how can you have memory without changing your connectivity?

31:56.160 --> 32:00.520
Well, you're just appealing to initial conditions

32:00.520 --> 32:02.080
in the context of a nonlinear dynamical

32:02.080 --> 32:03.760
and run of a dynamical system.

32:05.880 --> 32:08.560
At what point would you start calling this

32:09.680 --> 32:11.600
the kind of memory that could be encoded

32:11.600 --> 32:12.800
in terms of connection strengths?

32:12.800 --> 32:14.960
Well, in those kinds of systems

32:14.960 --> 32:19.440
where the key, not second order nonlinear interactions

32:19.440 --> 32:22.040
rest upon a subset of variables that change very, very slowly

32:22.040 --> 32:25.480
and you say, well, okay, under that adiabatic approximation,

32:25.480 --> 32:27.520
then we'll now call this a different kind of memory.

32:27.520 --> 32:30.560
And it's just because it's slightly slower.

32:30.560 --> 32:35.560
So I think it's, well, I liked the emphasis

32:36.680 --> 32:39.280
on the separation of time scales

32:39.280 --> 32:44.280
because I think that would have dissolved the reviewer's concerns

32:44.760 --> 32:47.760
if you were just talking about really fast learning

32:47.760 --> 32:50.240
in the moment that is all in the nonlinearities

32:50.240 --> 32:52.080
and the dynamics.

32:52.080 --> 32:54.360
I keep emphasizing the nonlinearities, Mike,

32:54.360 --> 32:59.360
because of that sort of the paradox of change.

33:00.000 --> 33:04.480
So as soon as you have nonlinear dynamics in any system

33:04.480 --> 33:07.600
that has at one particular time scale

33:07.600 --> 33:12.160
an attracting set or a random or a pullback attractor,

33:13.040 --> 33:14.960
you have that itinerancy,

33:14.960 --> 33:17.320
which means that there will be some form

33:17.320 --> 33:22.320
of changing sensitivity to all the things

33:22.520 --> 33:24.600
that I am coupled to.

33:24.600 --> 33:29.520
That is definitional of things that have that biotic

33:29.520 --> 33:31.520
or sort of characteristic kind of set.

33:31.520 --> 33:35.440
So, you know, the nonlinearities are certainly

33:35.440 --> 33:36.520
from a classical perspective,

33:36.520 --> 33:38.520
I think they're absolutely key here

33:38.520 --> 33:40.880
and resolve a lot of the distinctions

33:41.320 --> 33:44.840
and give you now a relatively simple picture

33:44.840 --> 33:49.840
that if there was some way to tell the next version of me

33:50.080 --> 33:54.720
where I started, give the next version of me

33:54.720 --> 33:57.720
my initial conditions in the past version of me,

33:57.720 --> 34:00.280
you can, I would imagine quite simply

34:00.280 --> 34:03.080
just write down systems that have this kind of memory

34:03.080 --> 34:04.920
which does not involve it anyway,

34:04.920 --> 34:07.920
a change in the connection weights.

34:07.920 --> 34:10.920
And I'm just wondering whether that, you know,

34:10.920 --> 34:15.160
that if you wanted to simulate that remarkable fact

34:15.160 --> 34:18.840
that the worms remember

34:18.840 --> 34:22.760
that they are on a two-headed trajectory

34:22.760 --> 34:24.920
even when they start again.

34:24.920 --> 34:27.000
I mean, I think the deep question here is

34:27.000 --> 34:30.000
how on earth did they inherit the initial conditions

34:30.000 --> 34:35.000
that characterised the termination of their parent

34:36.000 --> 34:37.960
or what they inherited from.

34:37.960 --> 34:41.520
I think, again, that speaks to this coupling

34:41.520 --> 34:43.600
between different temporal scales.

34:43.600 --> 34:46.000
You know, is this a messenger RNA, you know,

34:46.000 --> 34:49.760
and how does that propagate through to the electric fields

34:49.760 --> 34:51.880
and how does it get back top-down causation,

34:51.880 --> 34:54.160
get back in again, it's a fascinating example.

34:54.160 --> 34:56.200
And I've heard that before, I'm sure you've told me

34:56.200 --> 34:59.560
but I probably ignored it because it's so remarkable.

35:01.080 --> 35:02.800
Not easy to explain.

35:02.800 --> 35:05.520
In answer to the question, can you ever know

35:06.520 --> 35:09.520
what's going on inside a system?

35:09.520 --> 35:10.360
No.

35:11.600 --> 35:13.560
And I say no polemically from the point of view

35:13.560 --> 35:14.680
of the Fianco principle.

35:14.680 --> 35:18.160
You can never know what's beneath a Markov blanket.

35:18.160 --> 35:19.920
You can never know what's on the other side

35:19.920 --> 35:21.200
of a holographic screen.

35:21.200 --> 35:23.240
That's the whole point of a holographic screen

35:23.240 --> 35:24.720
or a Markov blanket.

35:24.720 --> 35:27.760
All you can do is bring a best guess

35:27.760 --> 35:30.640
and as if explanation to the poly computing,

35:30.640 --> 35:34.400
if you like, in the bulk on the other side,

35:34.400 --> 35:39.400
which means, you know, I think that's simple observation.

35:39.400 --> 35:44.400
The whole point of that screen or Markov boundary

35:46.320 --> 35:49.040
is that there is a conditional independence

35:49.040 --> 35:51.160
given what you can measure.

35:51.160 --> 35:55.560
So you can never know other than infer

35:55.560 --> 35:57.920
by what you measure from the behavior,

35:57.920 --> 36:01.560
the inputs and the outputs of a particular system.

36:03.000 --> 36:03.840
Amazing.

36:03.840 --> 36:05.520
So two questions then.

36:05.520 --> 36:09.920
One is, is there, is it just a flat no?

36:09.920 --> 36:12.640
Or is there a degree that is easier to know

36:12.640 --> 36:13.920
for certain kinds of systems?

36:13.920 --> 36:17.280
And then for sort of advanced living cognitive systems,

36:17.280 --> 36:18.120
it's really no.

36:18.120 --> 36:20.400
Or is it just like, is it always the same?

36:20.400 --> 36:22.560
Or is it a matter of degree?

36:22.560 --> 36:23.680
If you're directing at me,

36:23.680 --> 36:26.240
the answer I'm afraid is always no.

36:26.240 --> 36:29.600
But I don't mean that in a sort of pessimistic or,

36:29.600 --> 36:32.240
I mean, the question, you know,

36:32.240 --> 36:37.240
how do you infer what kind of Bayesian mechanics

36:39.640 --> 36:42.840
or poly computation is going on underneath the Markov blanket

36:42.840 --> 36:45.200
or inside a cell or inside a brain?

36:46.200 --> 36:50.000
That question is, of course, my day job

36:50.000 --> 36:52.960
and the day job of nearly every neuroscientist.

36:52.960 --> 36:54.960
It's peaking underneath the Markov blanket

36:54.960 --> 36:56.840
in a noninvasive way that doesn't destroy it

36:56.840 --> 37:00.800
to try and understand the mechanics

37:00.800 --> 37:03.240
and to test hypotheses about what is going on.

37:03.240 --> 37:06.720
But you're always testing hypotheses you will never know.

37:06.720 --> 37:09.440
So there will be situations where the functional anatomy

37:09.440 --> 37:12.640
or the architect reveals itself

37:12.640 --> 37:14.480
through noninvasive imaging, for example,

37:14.480 --> 37:16.640
or even invasive techniques

37:16.640 --> 37:19.280
of the kind that you use every day.

37:19.280 --> 37:22.480
But all you're doing is basically testing hypotheses

37:22.480 --> 37:26.480
about what you think the gerative model is under the hood.

37:27.440 --> 37:30.200
And once you know that or put it another way,

37:30.200 --> 37:31.920
if you knew the gerative model,

37:31.920 --> 37:33.040
then you know the Lagrangian.

37:33.040 --> 37:33.880
If you know the Lagrangian,

37:33.880 --> 37:36.120
you know the intrinsic or internal dynamics

37:36.120 --> 37:40.080
and you can tell a story about poly computing,

37:40.080 --> 37:42.120
tell a story about Bayesian mechanics.

37:42.120 --> 37:43.960
You can tell a story about perception.

37:43.960 --> 37:45.680
You can tell a story about memory.

37:45.680 --> 37:47.520
You can tell your basal cognition.

37:47.520 --> 37:51.320
But these are just stories predicated on the Lagrangian

37:51.320 --> 37:54.320
that governs the intrinsic dynamics

37:54.320 --> 37:56.880
and all that the free energy principle brings to the table

37:56.880 --> 38:00.000
is that you can express that Lagrangian

38:00.000 --> 38:03.640
as a function of a probabilistic gerative model.

38:03.640 --> 38:06.960
So your job is now to identify the form,

38:06.960 --> 38:09.840
the functional form and structure of that model

38:09.840 --> 38:12.320
and all the processes that it entails.

38:12.320 --> 38:13.720
But every time you do that,

38:13.720 --> 38:17.680
you're just testing a hypothesis theory of mind for me

38:17.680 --> 38:19.440
and theory of mind for your Xenobox

38:20.080 --> 38:22.520
and theory of mind for yourselves.

38:22.520 --> 38:25.600
Of course, you can break down at different scales.

38:25.600 --> 38:30.320
So it would be possible to ask about the sense making

38:30.320 --> 38:33.960
and sentient behavior of a single cell in my brain

38:33.960 --> 38:36.960
if you were able to isolate it and get inside there

38:36.960 --> 38:40.920
and do molecular biology or do cellular biology.

38:40.920 --> 38:44.720
But you would no longer be looking at my brain at that scale.

38:45.600 --> 38:49.040
And so, you know, but you could sort of cut across scales

38:49.040 --> 38:50.640
in the good old fashioned way

38:50.640 --> 38:53.280
and start to tell an internally coherent story

38:53.280 --> 38:56.520
about how it all fits together across scales.

38:58.280 --> 39:00.160
Could you back up what Carl said quickly?

39:00.160 --> 39:01.280
Not to interrupt you, Michael.

39:01.280 --> 39:02.120
Yeah, go for it, go for it.

39:02.120 --> 39:04.920
And it's partially gonna be a question for Carl

39:04.920 --> 39:06.600
as he triggered an interesting thought

39:06.600 --> 39:09.040
and then just to quickly say to you, Michael,

39:09.040 --> 39:12.400
that's also why I was hesitant because by definition

39:12.680 --> 39:15.840
since mortal computation rests on the Markov blanket

39:15.840 --> 39:18.400
and it's underwritten by the free energy principle,

39:18.400 --> 39:21.160
I also commit to that as well that no, the answer is no,

39:21.160 --> 39:23.760
you can't see what's under the Markov blanket.

39:23.760 --> 39:25.400
And that's why I was curious enough Carl

39:25.400 --> 39:28.360
would give me anything that may I just didn't know about.

39:28.360 --> 39:30.480
So that was one comment to you,

39:30.480 --> 39:32.960
to Carl and to everyone, really.

39:33.880 --> 39:38.880
So mortal computation also subsumes artificial systems.

39:38.880 --> 39:41.160
So this is where I was curious to know

39:41.160 --> 39:45.480
if Carl, we were to design the internal states,

39:45.480 --> 39:49.240
all the dynamics, we, again, we have the environment

39:49.240 --> 39:51.200
but let's just say you dissimulate it,

39:51.200 --> 39:52.920
you're designing the environment

39:52.920 --> 39:54.520
and you design the Markov blanket

39:54.520 --> 39:57.000
because we talk about even in our paper,

39:57.000 --> 39:59.400
potential sketches of things that you could use

39:59.400 --> 40:03.240
to build the boundary and the transduction pumps

40:03.240 --> 40:05.720
and all the sub pumps and to actually build

40:05.720 --> 40:08.400
a viable artificial organism.

40:08.400 --> 40:10.720
Now we have the internal dynamics.

40:11.480 --> 40:14.880
We are the designer and we have specified internal,

40:14.880 --> 40:17.360
external and the boundary.

40:17.360 --> 40:20.200
Is there something I'm missing that we would still,

40:20.200 --> 40:22.040
cause we've created the Markov blanket.

40:22.040 --> 40:23.560
So now we know what's on the other side.

40:23.560 --> 40:26.660
So the answer to Michael is not for natural systems

40:26.660 --> 40:30.200
that we obviously cannot, did not create, but we made it.

40:30.200 --> 40:31.520
So we made the internal systems.

40:31.520 --> 40:34.360
There's some other concept I'm missing

40:34.360 --> 40:36.040
cause you would be able to now say,

40:36.040 --> 40:39.440
I know everything cause I built the internal states,

40:39.440 --> 40:42.040
I specified every bit of the dynamics

40:43.160 --> 40:45.400
and let's say the environment, you know,

40:45.400 --> 40:47.240
we've constructed that,

40:47.240 --> 40:50.360
we've constructed the Markov blanket, the boundary.

40:51.280 --> 40:52.880
What about that case?

40:52.880 --> 40:55.760
Is it, now we are inspecting it cause we made it.

40:55.760 --> 40:58.880
So we obviously don't need to infer it, we know it.

40:58.880 --> 41:00.080
What about that?

41:00.080 --> 41:03.440
I was curious to know your thought of designed internal states

41:03.440 --> 41:07.240
and designed external states and designed Markov blankets.

41:08.200 --> 41:09.600
If that makes any sense.

41:09.600 --> 41:14.600
Yeah, Mike's gone to the door, so I'll respond to that.

41:18.440 --> 41:22.040
So, yeah, I'm not going to give you

41:22.040 --> 41:25.200
any deep philosophical insight.

41:25.200 --> 41:28.120
You don't already have, but just a very practical one.

41:28.120 --> 41:31.760
I mean, you know, what you just described

41:31.760 --> 41:36.760
is an application of the free energy principle

41:36.920 --> 41:41.920
as a method to simulate various mortal computations

41:43.880 --> 41:47.480
in the service of building hypotheses

41:47.480 --> 41:49.880
about how this thing might work mortally.

41:50.880 --> 41:54.200
So practically that's what we use the free energy principle for

41:54.200 --> 41:59.240
and the design is at least mathematically

41:59.240 --> 42:01.680
very straightforward in the sense I repeat,

42:01.680 --> 42:04.840
all you need to know is the gerative model.

42:04.840 --> 42:06.680
So all you need to be able to write down

42:06.680 --> 42:09.600
is a probability distribution of all the causes

42:09.600 --> 42:11.840
and consequences that constitute your system.

42:11.840 --> 42:12.840
That's it.

42:12.840 --> 42:14.480
If you can write that down

42:14.480 --> 42:17.720
and you can instantiate that in a von Neumann architecture,

42:17.720 --> 42:19.640
you then just solve the equations of motion

42:19.640 --> 42:21.680
that are the gradient flows.

42:21.680 --> 42:24.800
We will have a certain amount of component on that Lagrangian

42:24.800 --> 42:26.800
and you can simulate sentient behavior

42:26.800 --> 42:29.560
and sense making, perceptual actions, self-organization,

42:29.560 --> 42:31.600
everything that you want to do.

42:31.600 --> 42:33.320
Why would you ever want to do that?

42:33.320 --> 42:35.800
Well, in order to test hypotheses

42:35.800 --> 42:38.880
that this reproduces the kind of behavioral thing of interest

42:38.880 --> 42:41.600
which for something like me would be a psychiatric patient

42:41.600 --> 42:46.600
for something like might be a multicellular organism.

42:50.920 --> 42:55.920
So you are now using a simulation

42:58.800 --> 43:02.560
as a way of generating predictions

43:02.640 --> 43:05.880
that then you can match against the observable parts

43:05.880 --> 43:08.120
of the system of interest which adjust the surface.

43:08.120 --> 43:11.360
You have to adjust the action on that system

43:11.360 --> 43:14.760
and to the extent that the sensory inputs of that system

43:14.760 --> 43:16.360
are also known.

43:16.360 --> 43:17.840
That's all you have access to.

43:17.840 --> 43:20.080
So literally that's how we practically use

43:20.080 --> 43:21.920
active inference for example.

43:21.920 --> 43:26.920
We just create simulations of Bayesian mechanics

43:28.760 --> 43:30.440
in a given paradigm

43:30.440 --> 43:32.000
and then we adjust the gerative model

43:32.000 --> 43:34.760
more specifically the priors of that gerative model

43:34.760 --> 43:39.360
until it renders impurity observed choice behavior

43:39.360 --> 43:43.440
the most likely under the probability distribution

43:43.440 --> 43:47.200
of the actions of my simulated simulated.

43:47.200 --> 43:49.440
So in that sense you're specifying the structure

43:49.440 --> 43:54.440
but one could argue that even treating the laptop computer

43:55.080 --> 43:57.600
that is so non-unique

43:57.600 --> 43:59.760
because it affords the opportunity to abstract

43:59.760 --> 44:01.560
and do these simulations.

44:01.560 --> 44:03.640
I'll come back to Chris's point.

44:03.640 --> 44:05.040
Even then you don't actually know

44:05.040 --> 44:07.520
what's going on underneath the hood.

44:07.520 --> 44:09.000
And certainly in conversation

44:09.000 --> 44:11.240
with people designing some risk architectures

44:11.240 --> 44:14.680
and sort of looking at the most efficient buses

44:14.680 --> 44:19.680
they have to guess what's actually being passed here

44:19.840 --> 44:21.840
and there and measure it and get proxies

44:21.840 --> 44:24.320
like temperature and that kind of thing.

44:24.320 --> 44:26.640
You can certainly specify the initial conditions

44:26.640 --> 44:30.120
and the structure and you can do a,

44:30.120 --> 44:31.920
you can reboot and reset it.

44:31.920 --> 44:35.480
So you can to a certain precision specify

44:35.480 --> 44:38.440
the initial conditions and the structure

44:38.440 --> 44:42.320
of which the, you know, that the ensuing dynamics will occur

44:42.320 --> 44:47.320
but to actually know the message passing of a computer

44:47.580 --> 44:50.120
even in simulation, I think would be,

44:51.320 --> 44:54.280
I think you would be able to return to your hard no.

44:56.600 --> 44:58.640
Certainly on the level of, you know

44:58.640 --> 45:01.480
the quantum level that Chris was referring to.

45:01.480 --> 45:03.000
Again, it would be unknowable.

45:03.920 --> 45:04.960
But it's an interesting point

45:04.960 --> 45:07.680
but it does foreground the role of simulations in this,

45:07.680 --> 45:11.320
I think and it comes back to, you know, this, you know

45:11.320 --> 45:12.960
why do we want to know all this?

45:12.960 --> 45:15.480
Well, it's just to basically build,

45:16.840 --> 45:21.720
formalize hypotheses in terms of simulations

45:21.720 --> 45:24.600
that now embody our hypothesis

45:24.600 --> 45:26.920
and then look at the empirical system

45:26.920 --> 45:28.040
to see whether, you know

45:28.040 --> 45:30.680
that hypothesis was correct.

45:32.920 --> 45:36.480
Can I just add another point of view on this?

45:39.960 --> 45:43.600
And if we think about what we do in practice

45:43.600 --> 45:46.520
with ordinary computers

45:48.280 --> 45:50.400
where we have built the thing, et cetera,

45:51.360 --> 45:53.560
part of building the thing,

45:53.560 --> 45:55.900
it's not just assembling the hardware.

45:56.780 --> 46:01.220
We also put a lot of work into building these interfaces

46:01.220 --> 46:03.180
that we call programs.

46:04.340 --> 46:09.340
And so if I'm using some sort of debugging tool

46:09.340 --> 46:10.540
or something like that

46:10.540 --> 46:14.540
where I can run a program in one window

46:14.540 --> 46:16.100
and see what's happening

46:18.980 --> 46:23.980
at some level of the execution trace in some other window

46:24.980 --> 46:29.980
what I've done is constructed a Markov blanket effectively

46:32.860 --> 46:33.940
to use that language

46:34.980 --> 46:38.100
that has a bunch of different IO channels

46:39.180 --> 46:44.180
that access different parts of what's going on in the device.

46:44.940 --> 46:49.940
So we could think about from a biological perspective,

46:50.020 --> 46:51.500
we have these cells

46:52.500 --> 46:57.500
that come equipped with their own native IO channels.

47:01.860 --> 47:04.300
But there's nothing that says that we couldn't,

47:04.300 --> 47:08.900
in principle, build some more channels into the things

47:10.260 --> 47:12.100
so that we could see,

47:12.100 --> 47:15.980
we could see more about what was going on in the inside

47:15.980 --> 47:18.900
not by penetrating the Markov blanket

47:18.900 --> 47:22.860
but by adding some IO capacity to the Markov blanket.

47:23.780 --> 47:25.500
What does that mean physically?

47:25.500 --> 47:27.940
It just means you're using a different interaction

47:30.420 --> 47:34.220
because it's the interaction that defines the blanket

47:35.060 --> 47:39.180
as a set of information transmitting states.

47:40.180 --> 47:45.180
So I think we always have the hard no of the Markov blanket

47:48.980 --> 47:51.980
but we also from an engineering perspective

47:53.540 --> 47:58.540
because we can interact with these systems

47:59.940 --> 48:03.380
in ways that other parts of their environments

48:03.380 --> 48:06.740
can't interact with them or don't interact with them at least.

48:07.020 --> 48:10.780
We're a part of the environment that can open up

48:12.860 --> 48:15.140
new communication channels through the blanket

48:15.140 --> 48:17.660
by changing the interaction

48:18.580 --> 48:22.900
that effectively changes the state space

48:22.900 --> 48:25.020
in which the blanket is defined.

48:29.540 --> 48:32.700
Augmenting the Markov, let's say with reporters

48:32.700 --> 48:34.700
or with optogenetics, I would imagine

48:34.700 --> 48:36.420
it's a good example of this too.

48:38.220 --> 48:40.140
Yeah, well, I mean, in a sense,

48:41.380 --> 48:43.420
FMRI is a good example of that.

48:44.620 --> 48:45.580
Yes, yeah.

48:45.580 --> 48:48.380
Right, we were just adding an IO channel to the brain

48:48.380 --> 48:51.060
that wasn't there before.

48:54.820 --> 48:56.220
I want to...

48:56.220 --> 48:57.060
Sorry.

48:57.060 --> 48:58.980
No, no, please, Carl, keep going.

48:58.980 --> 49:01.500
No, I was just thinking out loud,

49:02.500 --> 49:07.500
so the catch word in my world is sort of non-invasive,

49:07.980 --> 49:09.580
brain imaging, and that has a meaning,

49:09.580 --> 49:11.820
that you're non-invasive, but there isn't,

49:11.820 --> 49:16.820
there is a whole centuries worth of legacy

49:17.020 --> 49:19.900
of invasive studies and lesion deficit models

49:19.900 --> 49:22.140
and depth recordings and the like,

49:22.140 --> 49:24.980
which I think speak to this,

49:24.980 --> 49:28.700
how far into the Markov blanket can you peer

49:28.700 --> 49:32.380
without destroying the thing that you're trying to,

49:32.380 --> 49:35.260
in the Heisenberg sense, trying to get out.

49:35.260 --> 49:36.100
I was witching.

49:36.100 --> 49:37.860
I'll shut up and have a quiet cigarette

49:37.860 --> 49:39.860
while I listen to you now.

49:39.860 --> 49:44.860
I just add that it's non-invasive kind of by convention

49:44.940 --> 49:48.300
and that you're invading the brain with a magnetic field

49:48.300 --> 49:50.260
that wasn't there before.

49:50.260 --> 49:52.100
You're just not damaging it much.

49:54.180 --> 49:56.940
Like Carl said, it's invasive,

49:56.940 --> 49:59.700
but I wonder what that tells us then

49:59.700 --> 50:03.260
about augmenting the Markov blanket.

50:03.260 --> 50:05.780
Because yeah, Carl usually will say,

50:05.780 --> 50:07.980
if we want to non-invasively understand it,

50:07.980 --> 50:11.020
well, then yeah, you can't peer under the Markov blanket.

50:11.020 --> 50:13.980
So mortal computation, I think,

50:13.980 --> 50:16.500
kind of is connecting towards the idea

50:16.500 --> 50:17.700
of what you're saying, Chris, right?

50:17.700 --> 50:20.260
Because we can augment, we can add IO channels.

50:20.260 --> 50:23.340
You are designing, engineering these things.

50:23.340 --> 50:25.500
So now this was something that did not exist.

50:25.500 --> 50:28.740
I don't know, Michael, how does that shed light

50:28.740 --> 50:31.100
on the question that you originally wanted to get at,

50:31.100 --> 50:34.420
which is, you know, peering at these internal states.

50:34.420 --> 50:36.220
Because I think this is like an indirect way.

50:36.220 --> 50:39.380
Because I was, Carl gave me great answer about,

50:39.380 --> 50:40.460
well, if I just design,

50:40.460 --> 50:42.460
because my brain goes to the ultimate engineering,

50:42.460 --> 50:44.060
I'll just design it all myself.

50:44.060 --> 50:46.940
And I even was thinking about if I build the hardware,

50:46.940 --> 50:49.860
but Carl's right, even when you get to hardware,

50:49.860 --> 50:51.420
you're guessing a lot of times,

50:51.420 --> 50:53.300
even with the best educated guesses.

50:53.300 --> 50:56.340
So there's still the Markov blanket

50:56.340 --> 50:58.500
that you're not really breaching.

50:58.500 --> 51:01.340
But if you perturb or change,

51:01.340 --> 51:04.100
it's even like augmenting the cell membrane

51:04.100 --> 51:05.980
with something in your lab's group

51:05.980 --> 51:09.300
is, you know, an example of modifying these things.

51:09.300 --> 51:11.540
What does that do to your question?

51:11.540 --> 51:13.700
How does that shed light on what you're thinking?

51:13.700 --> 51:17.300
Yeah, yeah, I mean, I even wanted to do,

51:17.300 --> 51:19.580
talk about a much more annoying aspect of this,

51:19.580 --> 51:22.620
which as I always do, which is to take it way down.

51:22.900 --> 51:26.620
So nevermind brains, nevermind even cells, right?

51:26.620 --> 51:30.220
My question, you know, also extends like that transition

51:30.220 --> 51:32.140
from, you know, you got a pendulum,

51:32.140 --> 51:35.220
you got a thermostat, you've got, you know, right?

51:35.220 --> 51:36.700
And you can sort of build these things up

51:36.700 --> 51:38.780
and then eventually at some point you get to a cell.

51:38.780 --> 51:43.060
So I'm still curious about whether this impenetrability

51:43.060 --> 51:44.740
goes all the way down.

51:44.740 --> 51:47.020
So we can't read the mind of a pendulum either,

51:47.020 --> 51:52.140
or there is some sense of progressive opacity

51:52.140 --> 51:55.660
as you climb this sort of continuum of cognition

51:55.660 --> 51:57.700
from extremely simple systems,

51:57.700 --> 52:00.540
where I think the conventional story is,

52:00.540 --> 52:02.740
hey, look, it's all third person accessible.

52:02.740 --> 52:04.460
We know exactly what's going on,

52:04.460 --> 52:06.660
but at some point you don't.

52:06.660 --> 52:08.820
And so I'm curious, when does that happen?

52:08.820 --> 52:10.580
And if we think there's a phase transition here,

52:10.580 --> 52:12.500
or if we think this is smooth, I mean,

52:12.500 --> 52:14.780
I tend to think everything is more or less smooth

52:14.780 --> 52:16.740
in these cases, but maybe I'm wrong.

52:18.300 --> 52:21.740
Yeah, that's one thing I wanted to kind of probe

52:21.740 --> 52:23.460
a little bit is how does this play out

52:23.460 --> 52:25.940
when you start, not start at the brain, you know,

52:25.940 --> 52:29.060
where, okay, we can all agree that's sort of very opaque,

52:29.060 --> 52:32.540
but what about from the most simple physics systems, right?

52:32.540 --> 52:34.220
How do you get to that opacity?

52:35.420 --> 52:37.460
Yeah, and then on the flip side,

52:37.460 --> 52:39.740
and I'm conscious that I don't want to monopolize this up,

52:39.740 --> 52:40.860
we only have five minutes left,

52:40.860 --> 52:45.460
but something that's very interesting,

52:45.460 --> 52:48.180
I think an implication of this is that we can't really know

52:48.180 --> 52:49.340
and we're all inferring.

52:49.340 --> 52:53.980
If you take the approach that I took in this memories paper,

52:53.980 --> 52:58.180
where your future self has to make a lot of guesses

52:58.180 --> 52:59.900
as to what your memories mean,

52:59.900 --> 53:01.900
because they were written down by your past self

53:01.900 --> 53:03.300
and you don't have all the metadata,

53:03.300 --> 53:06.220
you have to now interpret these compressed n-grams,

53:06.220 --> 53:09.260
then that leads to this kind of more,

53:09.260 --> 53:11.540
the little kind of disturbing question is,

53:11.540 --> 53:14.940
so we can't even tell what we used to think really, right?

53:14.940 --> 53:17.780
We can sort of guess, but we don't really know then

53:17.780 --> 53:21.580
if this is the case, if that impenetrability holds,

53:21.580 --> 53:23.820
then it's there with respect to our past self

53:23.820 --> 53:25.580
and our past memories too.

53:25.580 --> 53:27.740
So that's kind of wild.

53:27.740 --> 53:29.860
I don't know what we all have to say about those.

53:31.300 --> 53:33.500
I'll refer to this wonderful thing

53:33.500 --> 53:35.580
called the Conway-Cocon Theorem,

53:35.580 --> 53:37.500
Conway of the Game of Life

53:37.500 --> 53:40.420
and Cocon of Quantum Contextuality.

53:41.940 --> 53:44.180
This was published three decades ago now

53:44.180 --> 53:45.700
or something like this,

53:45.700 --> 53:49.660
but they proved using mainly relativity theory

53:49.660 --> 53:54.660
that if they considered a generic observational scenario

53:58.340 --> 54:02.500
and they said, if in any generic scenario,

54:02.500 --> 54:06.580
what you consider the observer has free will

54:06.580 --> 54:08.820
in the following defined sense

54:08.820 --> 54:13.260
that what the observer does is not completely determined

54:13.340 --> 54:15.700
by that observer's past like tone.

54:16.540 --> 54:19.860
So this is, if the observer is not subject

54:19.860 --> 54:22.060
to local determinism,

54:22.060 --> 54:23.500
then the thing being observed

54:23.500 --> 54:26.020
is not subject to local determinism either.

54:27.140 --> 54:28.980
And at the end of the paper, they say,

54:28.980 --> 54:32.100
so one could ask, do we really mean

54:32.100 --> 54:34.580
that electrons have free will

54:34.580 --> 54:36.860
in the same sense that observers do?

54:36.860 --> 54:38.460
And the answer is yes.

54:40.420 --> 54:43.220
They say in their paper emphatically.

54:43.220 --> 54:45.300
So if you did on the free will theorem,

54:45.300 --> 54:47.500
yeah, I remember you're catching this.

54:47.500 --> 54:51.700
Yeah, and if you drag quantum theory into the picture,

54:51.700 --> 54:53.940
then you get an equally strong result

54:53.940 --> 54:58.940
that any system has to be able to effectively choose

55:03.660 --> 55:06.700
its own semantics for how it interprets

55:06.700 --> 55:08.660
whatever incoming information is.

55:09.660 --> 55:11.180
And if you take that choice away,

55:11.180 --> 55:12.460
then you get entanglement.

55:12.780 --> 55:15.820
The system ceases to have a separate identity.

55:17.260 --> 55:20.380
So I think the answer,

55:20.380 --> 55:22.860
kind of the principle answer about opacity is,

55:22.860 --> 55:24.460
yeah, it goes all the way down.

55:28.020 --> 55:29.620
Can I just follow up on that

55:29.620 --> 55:34.100
and refer to Chris's in a screen hypothesis

55:34.100 --> 55:36.860
and the notion of an irreducible Markov blanket?

55:38.300 --> 55:40.620
If you've got a system

55:40.620 --> 55:42.500
that has no internal Markov blankets,

55:42.500 --> 55:44.660
has no deep structure or hierarchical structure

55:44.660 --> 55:46.460
or heterarchal structure,

55:46.460 --> 55:51.020
then that is, I think, where the hard no would apply

55:51.020 --> 55:54.180
or the hard yes of unknowability.

55:54.180 --> 55:56.580
But clearly if it has internal Markov blankets,

55:56.580 --> 55:58.860
you can peel away and invasively

55:58.860 --> 56:01.460
or non-invasively start to get within that.

56:01.460 --> 56:04.260
So I think what you're talking about

56:04.260 --> 56:08.180
is in that sort of vague gradation

56:08.180 --> 56:10.740
of things that are noble and unknowable,

56:10.740 --> 56:12.940
it's just the hierarchical, well,

56:12.940 --> 56:16.380
the depth of the Markov blankets of the Markov blankets.

56:16.380 --> 56:19.420
And there is a kernel of either

56:19.420 --> 56:21.380
an irreducible Markov blanket,

56:21.380 --> 56:23.060
which you can never get into

56:23.060 --> 56:27.140
because you change the thing itself.

56:27.140 --> 56:28.580
But there's also a limiting case

56:28.580 --> 56:30.260
from the point of view of classical physics,

56:30.260 --> 56:32.060
which is when the inner states,

56:32.060 --> 56:35.340
intrinsic, the internal states are the empty set.

56:35.340 --> 56:39.660
So things like inert particles or stones

56:39.660 --> 56:42.260
don't have internal states,

56:42.260 --> 56:45.340
they just have Markov boundary states.

56:45.340 --> 56:47.420
So I think you're absolutely right to think of this

56:47.420 --> 56:52.420
as a gradation, that there are inert things

56:53.500 --> 56:54.860
that are defined operationally

56:54.860 --> 56:57.740
in the sense that their internal states are the empty set.

56:58.820 --> 57:02.060
And you could also say that there are sessile things

57:02.060 --> 57:03.260
that don't have active states.

57:03.260 --> 57:07.220
So all of the states of this kind of particle

57:07.220 --> 57:09.460
are just sensory states, they're just inputs.

57:10.460 --> 57:12.940
Inputs that can also influence the outside.

57:12.940 --> 57:14.660
There's no restriction that sensory states

57:14.660 --> 57:17.300
have to not influence the outside.

57:17.300 --> 57:18.980
So there still can be observable.

57:18.980 --> 57:21.540
And then you get to things that now have a non-antiactive

57:21.540 --> 57:26.540
sector of the holographic screen or the Markov blanket.

57:28.180 --> 57:29.300
And these are things that move.

57:29.300 --> 57:32.020
So you might think these are natural kinds

57:32.060 --> 57:34.420
that have mobility or motility.

57:34.420 --> 57:39.420
And then you get to things that whose internal states now

57:40.580 --> 57:43.500
have a Markov blanket within them.

57:43.500 --> 57:46.700
And these would be the kinds of things that can fan.

57:46.700 --> 57:48.820
And these are usually multicellular things

57:48.820 --> 57:52.020
or certainly compartmentalized things.

57:52.020 --> 57:56.180
I think at each stage, the no ability depends upon

57:56.180 --> 58:00.460
whether either the internal sets are empty or not,

58:01.300 --> 58:03.460
or they are irreducible in the sense

58:03.460 --> 58:05.060
there are no Markov blankets within them.

58:05.060 --> 58:08.580
So I think it's a nice, simple mathematical picture

58:08.580 --> 58:12.900
of that gradation that speaks exactly to the electron

58:12.900 --> 58:16.380
through to the pendulum, to the thermostat

58:16.380 --> 58:20.340
through to a smart thermostat that starts to worry

58:20.340 --> 58:22.940
about whether you want it warmer or colder or not

58:22.940 --> 58:25.380
and starts to pan ahead and moves from homeostasis

58:25.380 --> 58:26.620
to allostasis.

58:26.620 --> 58:29.700
All of this would speak to at different scales,

58:29.740 --> 58:32.180
equipping Markov blankets and Markov blankets

58:32.180 --> 58:33.660
and inducing a deep structure.

