WEBVTT

00:00.000 --> 00:09.520
Great. So what I was hoping, Carla, is that we could get your thoughts on how the whole

00:09.520 --> 00:15.800
Active Inference Framework could be applied to something that we've been developing. And

00:15.800 --> 00:18.680
I don't know if you had a chance to look at any of this stuff, but I'll just give you

00:18.680 --> 00:24.160
a brief, you know, kind of a brief summary so that it's clear what we've got. And then

00:24.160 --> 00:28.680
I have some basic questions and then a couple of wacky ideas to kind of bounce off of you

00:28.680 --> 00:35.040
and see what you think. So the basic thing is this, that what I was trying to do is to

00:35.040 --> 00:47.200
have a very basal model of distributed intelligence. And the idea was that we were interested in

00:47.200 --> 00:52.240
unexpected competencies in places where unlike in biology, you know, in biology, no matter

00:52.240 --> 00:56.040
how simple your model, you never have all the information about mechanisms and somebody

00:56.040 --> 00:59.560
can always say, well, there is a mechanism for that, you just haven't found it yet, right?

00:59.560 --> 01:05.880
So we wanted something that was incredibly simple, incredibly transparent, deterministic,

01:05.880 --> 01:09.480
something that everybody thinks they know what it does. And then we can, we can apply

01:09.480 --> 01:13.600
some of the approaches that we take in my lab about taking something that doesn't seem

01:13.600 --> 01:18.320
cognitive and saying, okay, but what, what actual competencies might it have, right?

01:18.320 --> 01:22.520
And so we chose this thing called sorting algorithms. And so these are the same simple

01:22.520 --> 01:25.720
algorithms that all computer science students study for, you know, and they've been studied

01:25.720 --> 01:32.440
for decades. And then we made a couple of, a couple of twists to it. One is that we visualize

01:32.440 --> 01:38.560
their progress from being a jumbled set of digits to an ordered set of digits as a kind

01:38.560 --> 01:42.240
of a traversal of space, right? So the idea is they start in different locations and they

01:42.240 --> 01:47.800
all sooner or later, they all end up in one location where everything is. And so once,

01:47.800 --> 01:51.320
once you view it as navigating that space, then you can ask some questions about what

01:51.360 --> 01:55.520
are their competencies and navigating that space under, under odd perturbations. One

01:55.520 --> 02:02.400
of the perturbations that we made was the introduction of what we call broken cells or

02:02.400 --> 02:06.960
barriers in the space. So if the algorithm wants to swap two numbers in order to proceed

02:06.960 --> 02:10.680
in its, in its sorting trajectory, well, one of the numbers could be broken, it doesn't

02:10.680 --> 02:14.640
move, you can't, you can't move. And so, and we have two kinds of broken numbers, ones

02:14.640 --> 02:20.840
that never initiate swaps and ones that actually never, never swapped no matter, you know,

02:20.880 --> 02:27.120
who initiates them. And so that allows us to ask questions about things like delayed

02:27.120 --> 02:31.640
gratification. In other words, can it go further from it? If it encounters a barrier,

02:31.640 --> 02:36.200
can it go further away from its goal in order to then acquire gains afterwards? And this

02:36.200 --> 02:40.560
is, you know, William James talked about this, of course, as, as an important type of basal

02:40.560 --> 02:44.680
intelligence. And, and that, and that breaks a common assumption with these algorithms,

02:44.680 --> 02:49.760
which is typically you assume that the material is, is robust. In other words, when you, when

02:49.760 --> 02:55.440
an algorithm says to do something, it gets done. But, but in our case, not necessarily. And

02:55.440 --> 03:00.080
we never introduced, this is important, we never introduced any extra code to check if

03:00.080 --> 03:04.400
things got done. It's, it's the standard algorithm. So it just keeps on rolling. There is no

03:04.400 --> 03:09.240
code to see how am I doing? Did things work out? No, no code for any of that. The second

03:09.240 --> 03:15.200
thing we did was to break the, the, the general version of this is centralized. So there's

03:15.200 --> 03:18.840
like this omniscient controller, and it's following one of several algorithms to kind

03:18.880 --> 03:23.800
of move numbers around. And we got rid of that and instead made it all bottom up. So every

03:23.800 --> 03:30.000
digit, aka every cell now has its own version of the algorithm running, and it has a limited

03:30.000 --> 03:34.520
local view of who its neighbors are. And it's just following the steps of the algorithm to

03:34.520 --> 03:39.240
try to improve its local environment, that there is no more global, global control. So

03:39.240 --> 03:45.280
it's distributed. And, and, and, you know, we learned a few things. We learned that a, the

03:45.280 --> 03:49.840
distributed version of this works quite well. It actually, you know, they do sort nicely. So,

03:49.840 --> 03:54.040
so that's great. We did see some delayed gratification in the sense that if you, if you

03:54.040 --> 03:59.440
sprinkle in some broken cells, it actually will go backwards and unsort the string a little bit,

03:59.440 --> 04:05.320
and it's effort to then go around the defect as it were. So that's kind of cool. But the most

04:05.360 --> 04:12.760
kind of surprising thing, which is what I'd love to get your take on is this. We, because now

04:12.800 --> 04:17.440
it's distributed and every cell is following its own algorithm, that enables us to do an

04:17.440 --> 04:21.640
experiment that otherwise you couldn't do, which is to make a chimeric string. And it's what we do

04:21.640 --> 04:25.800
in developmental biology, when we put together, you know, axolotl cells and frog cells, and now

04:25.800 --> 04:29.280
you get this frog a lot, and you can ask questions like, well, what shape is it going to have,

04:29.280 --> 04:34.600
right? So, so what you can make is a chimeric string where some of the numbers are following one

04:34.600 --> 04:39.240
algorithm, some of them are following a different algorithm. And again, there is this is important,

04:39.240 --> 04:45.440
there is no code to determine either your own or your neighbor's algotype. And algotype is the

04:45.440 --> 04:49.480
word that Adam coined for this, like, you know, what algorithm, what set of properties are you

04:49.480 --> 04:53.160
actually following a policy? Is it actually following? So there is no code for any of that,

04:53.160 --> 05:00.240
but we know which, which algotype all the cells. So that, and that also works. So chimeric strings

05:00.240 --> 05:05.400
also sort, sort the, sort the arrays, and that's fine. What we then did was we asked basically a

05:05.400 --> 05:09.600
developmental biology question was to say, okay, at any particular point during its journey,

05:09.600 --> 05:15.680
what is the distribution of algotypes within the string? And what we know, and we defined

05:15.680 --> 05:22.600
a quantity called clustering, which basically just means you look, you look next to you and what,

05:22.600 --> 05:28.720
what's the probability that your neighbor next to you is the same algotype as you are. So what

05:28.720 --> 05:33.320
happens is that in the very beginning, that probability is 50% because the algotypes are

05:33.320 --> 05:39.760
randomly assigned to the digits. So 50%. That's our baseline. At the very end, it's also 50%

05:39.760 --> 05:44.560
because at the end, everybody has to be sorted. And there is no relationship between the actual

05:44.560 --> 05:49.880
sort order of the numbers and the algotype. So again, it's 50%. But the wild thing is that in

05:49.880 --> 05:54.440
between those two points, if you actually plot that curve over time, it actually goes like this.

05:54.440 --> 05:59.800
And in between, it's quite a bit higher in statistically very significantly higher than 50%.

06:00.360 --> 06:07.400
And what we see is clustering significant tendency of cells with the same algotype to locate close

06:07.400 --> 06:12.120
together. Eventually, the inevitable, the inevitable physics of the algorithm will yank

06:12.120 --> 06:16.920
them apart and make sure that everybody's in numerical order. But until that happens, they

06:16.920 --> 06:22.200
enjoy some amount of clustering with their, you know, with their conspecific, so to speak, until

06:22.200 --> 06:28.040
then. And so, you know, any thoughts you might have, but more specifically, like one hypothesis

06:28.040 --> 06:32.280
the one could make, even though there's no explicit mechanism for this, but it might be a,

06:32.280 --> 06:36.520
you know, an emergent thing, could they be preferring to be next to their neighbors because

06:36.520 --> 06:42.440
their neighbors be one of the same algotype or more predictable, right? It's less surprise,

06:42.440 --> 06:45.480
you're less surprised when you're sitting next to somebody who's following exactly the same

06:45.480 --> 06:52.040
policies as you are. So I'm curious what you think about that. And I'm curious if there, you know,

06:52.120 --> 06:58.280
what might be a set of experiments that we could do to test that what's going on here is some sort

06:58.280 --> 07:03.240
of implicit surprise minimization, even though there's no actual code for it. So I'll stop there

07:03.240 --> 07:10.200
and listen to what you've got to say. Sorry, I think you're still muted.

07:14.600 --> 07:19.880
I was saying that was a very succinct and clear, a nice summary. I reread the paper a couple of

07:19.880 --> 07:27.240
days ago just to refresh myself, my memory for this conversation. So I didn't realize that that was

07:27.240 --> 07:34.760
the, that final chimeric demonstration was sort of, you know, the most intriguing from your point of

07:34.760 --> 07:43.880
view. But indeed, the way you express it, you know, that does call for further analysis, understanding

07:43.880 --> 07:56.520
and numerical experiments. So overall, just to endorse the choice of the sorting algorithm as,

07:56.520 --> 08:05.880
if you like, a minimal kind of self-organization. I think that, you know, that the self-organization

08:05.880 --> 08:12.680
word needs to be centre stage in terms of, you know, what you're trying to understand here.

08:13.960 --> 08:19.640
And framing like that, it does remind me a lot of self-organizing maps. I don't know if you remember

08:19.640 --> 08:26.440
van der Molzberg's treatment and people, Peter Dion's supervisor, I've forgotten now.

08:28.840 --> 08:35.240
So this notion of self-organizing maps as a very sort of biomimetic aspect of self-organization,

08:35.240 --> 08:43.560
I think certainly puts sorting like algorithms centre stage in terms of biological self-organization,

08:43.560 --> 08:50.920
particularly in things like the visual cortex and why you get that kind of pinwheel architecture,

08:50.920 --> 08:58.040
for example, where receptive field properties tend to cluster together in a smooth way and you get

08:58.040 --> 09:04.120
all sorts of interesting symmetry breaking when you're trying to represent, say, a 5D perceptual

09:04.120 --> 09:10.840
space on a 2D manifold. So that does strike me having this sort of linear sorting algorithm.

09:11.160 --> 09:23.400
And without really having not thought about it before, but certainly the dual pressure to find

09:23.400 --> 09:30.840
a free energy minimizing solution, viewing free energy as an extensive quantity,

09:32.200 --> 09:37.480
more simply, you know, the collective free energy being the joint free energy minimum solution.

09:37.480 --> 09:44.040
You're asking us where the free energy just bounds the likelihood of this particular arrangement.

09:45.240 --> 09:55.160
Then you're looking for the precise functional form of the free energy. And if you've got this kind

09:55.160 --> 10:02.840
of a ponency between the similarity of the algorithm and the similarity of the content of the value,

10:03.640 --> 10:11.800
then I can certainly see interesting behaviors arise in exactly the same spirit that you get

10:11.800 --> 10:21.480
these interesting structures in not epithelia, but in the functional specialization of

10:21.480 --> 10:30.600
cortical representations or sensory epithelia that try to sort of pack three dimensions into one

10:30.600 --> 10:36.600
dimension or are accountable to two kinds of constraints. So again, without really thinking

10:36.600 --> 10:41.000
about it, because I wasn't anticipating that particular question, but I think what you would be

10:42.120 --> 10:48.280
the first thing that you would be looking for is basically what is the Lagrangian or the energy

10:48.280 --> 10:57.560
function that is being minimized. So you could regard this as the sorting algorithm as an application

10:57.560 --> 11:05.240
of the sorting algorithm as a process that is trying to minimize some energy function very

11:05.240 --> 11:09.640
much in the spirit of Markov-Random fields, but in your instance, you just got a one dimensional

11:09.640 --> 11:18.200
field. But the technology of Markov-Random fields I think would be apt to try to understand the

11:18.200 --> 11:25.720
functional forms of the energy functions were under the special constraint, which of course is

11:25.720 --> 11:32.040
the one that you're predicating this whole thesis on, that interactions are only local and therefore

11:32.040 --> 11:37.880
any collective behavior has to be an emergent property, which is truly distributed. So the

11:37.880 --> 11:44.280
definitive aspect of a Markov-Random field is you just have local, you just have local interactions.

11:44.280 --> 11:51.160
And I think that's a really another important architectural feature that comes along with

11:51.160 --> 11:58.120
the choice of the sorting algorithm, which you should foreground, because any distributed,

11:58.120 --> 12:05.400
collective or emergent behavior at a scale beyond local interactions, that emergence

12:05.400 --> 12:11.400
is truly emergent in the sense that all your interactions are local. And of course that is

12:11.400 --> 12:19.480
what the Markov-Random field gives you. It says that you can only express the energy function,

12:20.200 --> 12:24.840
which is the probability of getting this particular arrangement or these particular numbers

12:25.640 --> 12:34.280
in this local clique. You can only express that in terms of a local energy function. And then

12:34.280 --> 12:38.840
of course you can tell all sorts of stories about the importance of that for machine learning and

12:38.840 --> 12:45.720
the like. But you probably want to stick to self-organization. So, and I would imagine the

12:45.720 --> 12:53.960
energy function is now going to be some simple measure of the local differences of the local

12:53.960 --> 13:01.560
gradients. And of course what one would anticipate would be a smoothing, a resolution of, as you say,

13:01.560 --> 13:11.640
the differences. So I think that would be one way of approaching naturalizing this phenomena in

13:11.720 --> 13:19.080
terms of maths by just invoking an arbitrary, not a variational free energy in the spirit of

13:19.080 --> 13:29.160
the free energy principle, but just a Lagrangian or try to identify what is the generic free energy

13:29.160 --> 13:36.200
function that's being minimized here. So that now your view through this sorting space or

13:36.520 --> 13:44.360
your morphological space is now a progression on some wonderful landscape that is defined

13:44.360 --> 13:52.920
by this free energy functional. And whether you can reverse engineer that or not, I don't think

13:52.920 --> 13:59.320
it really matters other than because I think the nice aspect of that is then you can talk about

13:59.960 --> 14:07.400
the dynamics on this free energy landscape. And once led then to very similar sort of notions

14:07.400 --> 14:14.360
in computational chemistry and protein folding and the like, there's a very complex, sorry,

14:14.360 --> 14:19.960
there is a complex Wellington landscape or free energy landscape that self-organization

14:19.960 --> 14:25.160
and computational chemistry adheres to and can be understood in terms of free energy minimum.

14:25.160 --> 14:32.440
Indeed, most of computational chemistry sort of follows this. And indeed, that is identifying

14:32.440 --> 14:39.240
that landscape is the whole point of applying things like large language models or deep RL to

14:39.240 --> 14:49.800
sort of protein folding and other applications. So that would be certainly one view to get a free

14:49.800 --> 14:57.320
energy like formalism or naturalization of this behavior, which I repeat has lots of really

14:57.320 --> 15:03.880
interesting links with self-organizing maps, marker, random fields, image reconstruction,

15:03.880 --> 15:10.120
and self-organization in certainly in some things like the visual cortex, I don't imagine

15:10.200 --> 15:17.320
any mapped representation would conform to these rules. To get this into a

15:19.560 --> 15:31.080
to get it into a free energy principle story, I think you would have to commit to the notion that

15:31.080 --> 15:37.320
each of the cell has its own boundary. And now you're starting to interpret each number

15:37.320 --> 15:45.960
as a thing. And in so doing, acknowledge its openness to everything else, or in this instance,

15:45.960 --> 15:52.920
just its neighbors, which will require sort of a by your formalism of the bi-directional exchange,

15:52.920 --> 16:00.520
so that the value of my next door neighbor is something that I can sense and is, and likewise,

16:01.320 --> 16:07.800
the broadcasting of my number to the next door neighbor is something is an action. So you've got

16:07.800 --> 16:15.960
this openness that is mediated in the simplest way, which is just the broadcasting and sensing

16:15.960 --> 16:22.520
of one unit dimensional, one number, if that is a discrete number. And the view like that,

16:22.520 --> 16:28.680
that means you can then I think deploy the free energy principle in the sense that any

16:29.640 --> 16:36.440
non equilibrium or far from equilibrium, steady state, which I think you would probably have here,

16:37.240 --> 16:39.960
just in virtue of the fact that there is going to be some

16:41.080 --> 16:46.360
breaking of detail balance in the itinerant way in which you move through this space in a

16:46.360 --> 16:52.360
developmental to get to your steady state. One can imagine, well, perhaps not, but

16:52.360 --> 16:58.920
you know, if one puts a little bit of dynamics into this, I would imagine you would advance very,

16:58.920 --> 17:09.320
very clearly the breaking of detail balance, and you know, and have those kinds of solenoidal flows.

17:11.320 --> 17:18.920
I mean, sorry, I distracted myself just by the addition of the frozen cells. That's one way of

17:18.920 --> 17:26.760
breaking. In a sense, the detail balance, and you know, just open brackets. It's exactly the same

17:26.760 --> 17:36.520
device that I resorted to in the very first paper on the life as we know it paper when

17:36.520 --> 17:42.520
simulating the little macro molecules using Lorenz attractors that had inherent dynamics.

17:42.520 --> 17:49.480
But to make it interesting, you had to have a small a certain popular number of the of the

17:50.040 --> 17:56.600
synthetic macro molecules that were insensitive to influences from other macro molecules and

17:56.600 --> 18:01.560
another proportion that could not influence the other one. So it's almost exactly the same

18:02.280 --> 18:08.200
choice. And that's what gave it the interesting behavior. Otherwise, it just basically converged

18:08.280 --> 18:17.800
either to a gas or it at a certain temperature, it would just convert to a crystal.

18:19.320 --> 18:24.200
So both of them being steady state solutions, free energy minimizing solutions. But things got

18:24.200 --> 18:29.320
interesting when you broke the detail balance symmetry breaking by having this

18:30.280 --> 18:38.920
this, you know, this requisite variety in terms of the frozenness in terms of action or sensation.

18:38.920 --> 18:46.360
So I think that's another that's another important thing to foreground. That this may be this

18:46.360 --> 18:52.680
kind of requisite variety may be absolutely necessary for symmetry breaking. And in this

18:52.680 --> 18:59.160
particular instance, breaking detail bounds to get this kind of cell biologically plausible

18:59.800 --> 19:06.280
by mimetic kind of stuff organization, you're unlikely to get that if you're in the absence

19:06.280 --> 19:12.760
of it in the sense that it would converge to a crystal in your instance, just a linear sorting

19:12.760 --> 19:18.040
perfect sorting, which which is which is, you know, doesn't doesn't have that chimeric or itinerant

19:18.600 --> 19:25.320
itinerant aspect to it. So sorry, close back it. So where were we? Oh, yeah. So

19:25.320 --> 19:33.400
if you've got now an interesting system that has a non equilibrium steady state, and in your case

19:33.400 --> 19:38.360
actually because you haven't got dynamics, it will also be an equilibrium steady state,

19:38.360 --> 19:44.360
but it'll still be a free energy minimizing solution. Then you are perfectly entitled to

19:44.360 --> 19:52.200
interpret the numbers as things and inferring things. And all they're trying to infer is the

19:52.200 --> 19:58.600
cause of their sensations, which is just the value of the numbers on one side and the other side,

19:58.600 --> 20:08.600
and they are broadcasting their inferences through broadcasting their own number, which of course

20:08.600 --> 20:17.960
will be the average of well, when sorted, it will be the average of the neighboring numbers.

20:17.960 --> 20:24.760
So on that view, I think you could very easily license an active inference interpretation

20:24.760 --> 20:31.240
a teleology. You mean you would actually need this to simulate protein folding or self organizing

20:31.240 --> 20:37.080
maps or anything, but you would be able to say there is a teleological interpretation of the

20:37.080 --> 20:43.960
self organization using the rhetoric of inference and belief updating simply because we can treat

20:43.960 --> 20:51.080
each number now as a Markov blanket and then something which will never be accessible, but we

20:51.080 --> 21:01.960
can imply or induce internal to each number could be interpreted as an inference process,

21:01.960 --> 21:08.840
and then the story, which you've already said what the answer is, under the assumption that

21:09.640 --> 21:17.080
I live in a world that is maximally predictable, then everything around me is the same as me and

21:17.080 --> 21:26.680
therefore I am going my free energy, my variational free energy minimizer is now going to be

21:28.360 --> 21:35.400
bound when there's the least surprising input. And if I believe that everything is like me,

21:36.040 --> 21:46.440
then that will be when the numbers that I am sensing in my peak are as similar to the estimate of

21:46.440 --> 21:54.280
the number, the place that I should be coming back to our sort of no-deal place paper.

21:55.480 --> 22:05.320
And I think that kind of story will have to be nuanced for the same algorithm

22:06.280 --> 22:13.000
so I'd have to think about that a little bit more, but certainly at least at a narrative level or

22:13.000 --> 22:18.440
a conceptual level I think you can tell the same story there that if the sequence of moves that I

22:18.440 --> 22:26.200
see my neighbour doing in relation to what I know about my neighbour belies the same underlying

22:26.200 --> 22:34.360
dynamic or algorithmic computations, then in some sense they are predictable if I have exactly the

22:34.360 --> 22:43.080
same algorithm under the hood. And therefore, mathematically speaking, that would be the

22:43.080 --> 22:50.280
free energy minimising solution if I can now read my broadcasting of the number as a broadcasting

22:50.280 --> 22:59.080
my posterior beliefs about the number, the estimate of this locale, my niche

22:59.720 --> 23:09.240
in this instance is just labelled with one number. So the number that I have

23:10.600 --> 23:17.800
is basically my prior belief about my niche and I'm just now going to

23:19.000 --> 23:27.240
move my niche around in a sort of egocentric frame until it is consistent with my prior belief

23:27.320 --> 23:33.720
that this is my place, my niche is number 62 for example. And that should be, you should be

23:33.720 --> 23:41.480
able to reproduce the same kind of sorting either analytically through showing that with an appropriately

23:41.480 --> 23:48.280
configured Lagrangian or free energy functional that the system operationally appears to be

23:48.920 --> 23:56.440
minimising, you can now write down the generative model and then show that this can also be

23:56.440 --> 24:04.440
interpreted as an inference process. I repeat under the assumption that the best way to make the

24:04.440 --> 24:11.800
world predictable is to surround yourself with things like you, which and also of course the

24:11.800 --> 24:17.960
locality assumption that I can only talk to the person to whom I'm immediately connected.

24:17.960 --> 24:23.080
So those are some of my thoughts but a lot of those were invented on the fly in response to

24:23.320 --> 24:29.240
your question I'm afraid. Superb. I've got many questions but Adam why don't you ask yours?

24:29.240 --> 24:37.480
Yeah, so it strikes me that up until now we've talked about the relevant sort of agent as being

24:37.480 --> 24:42.840
the individual number with an algoritite. You can think of it as a cell but it strikes me that

24:42.840 --> 24:49.480
there's an interesting macro phenomenon that occurs in the process of sorting which is that it

24:49.480 --> 24:57.960
appears that the list actually minimizes the Komogorov complexity or the description length

24:57.960 --> 25:05.160
necessary to render it. So let's just say you've got an unsorted list with random distribution

25:05.160 --> 25:13.080
of algotypes and there's 10 items in the list. You would need to enumerate 10 numbers and 10

25:13.080 --> 25:17.240
algotypes and there's no reason a priori to think that that would be compressible in any way.

25:17.880 --> 25:21.000
I mean maybe maybe you'd get lucky and there'd be a string of a certain number,

25:21.000 --> 25:24.440
a string of a certain algoritite but in the general case I think you'd actually need to

25:24.440 --> 25:32.360
write out every single entry. But as the list starts to sort itself it actually starts to create

25:32.360 --> 25:38.520
these longer strings of algotypes which means that the minimum description length actually gets

25:38.520 --> 25:44.760
shorter. Yet you still need to write each number out but you can coarse-grain the descriptions

25:44.760 --> 25:49.640
of the algotypes. You can say the first five numbers have the same you know algotype and then

25:49.640 --> 25:56.200
the next three have the same and so on. Now that that's a macro phenomenon but I'm wondering if

25:56.200 --> 26:02.280
there's any evidence or any research that suggests that sort of these self-organizing systems

26:02.920 --> 26:08.840
have a tendency to minimize their description length to minimize the number of factors needed

26:08.840 --> 26:14.360
or something like that. Because if that's the case then it gives us another view where there's

26:14.360 --> 26:21.960
this sort of emergent complexity minimization happening at the collective level. Yes, no that's

26:21.960 --> 26:31.240
an excellent point. I think the simple answer is yes absolutely and I can sort of give you my take

26:31.240 --> 26:37.720
on the literature or the citations that you'd want to appeal to. But I should say it's going to be

26:37.720 --> 26:43.800
a nuanced yes because of the particular focus on the clustering of the algotype. Now the algotype

26:44.360 --> 26:49.320
induces a certain kind of dynamics into the game so it's not as simple as a self-organizing map.

26:49.320 --> 26:59.400
It's how the map actually self-organizes so there's a process under the hood and that I think makes

26:59.400 --> 27:08.120
it slightly more complicated than just understanding self-organized maps. But in terms of another thing

27:08.120 --> 27:12.280
you might want to look into here of course and you probably know more about this than I do but

27:13.160 --> 27:16.280
this has a lot of resonance with artificial life

27:18.040 --> 27:26.280
games in the 1990s and 1980s. It also could be if you wanted to so do

27:27.320 --> 27:33.800
interestingly linked to Stephen Wolfram's Ruliad which is also another local scheme

27:34.520 --> 27:42.760
that generates everything apparently. There's the same sort of notion so he has algorithms

27:42.760 --> 27:49.480
which he calls rules and the rules are recursively applied in a local fashion to generate everything

27:50.280 --> 27:59.000
including black holes apparently and quantum physics and everything. There might be an

27:59.080 --> 28:05.720
interesting point of contact here with these sorry but to come back to the simple answer yes

28:05.720 --> 28:12.920
absolutely so certainly from the point of view of self-organization as described by the free

28:12.920 --> 28:17.960
energy principle. So notice here the free energy principle is just a description of systems that

28:17.960 --> 28:24.520
self-organize to a far from equilibrium non-equilibrium as I said he stayed. It's not a recipe for sorry

28:24.840 --> 28:33.960
in its statement it is not a description or a theological description of inferential

28:33.960 --> 28:39.880
processing. You are licensed to equip your explanation of the self-organization with

28:39.880 --> 28:45.560
reference to inference but that's an application of the free energy principle in itself it's just

28:45.560 --> 28:53.400
a description of anything that self-organizes or any things that self-organize. So in that sense

28:55.240 --> 29:00.280
if there is self-organization under the hood and the free energy principle has to apply and you can

29:00.280 --> 29:07.080
motivate the free energy principle along two lines one would be the sort of playing the Feynman

29:07.080 --> 29:22.760
card which is basically looking at the minimization of free energy as an optimization process

29:23.480 --> 29:27.640
which can be viewed as a gradient descent on sub-fitness landscape or free energy landscape

29:27.640 --> 29:35.560
or into landscape or you can take the Russian perspective which would be the Kalmolov complexity

29:35.560 --> 29:43.800
and from the Kalmolov complexity you get to Solov induction and from that you get to universal

29:43.800 --> 29:49.240
computation which is the home of the minimum description length and minimum message length

29:50.120 --> 29:58.440
so it's the algorithmic complexity version of free energy and so David McKay wrote a quirky

29:58.440 --> 30:08.680
little paper I think 1992 for where he interpreted variational free energy in relation to minimum

30:08.680 --> 30:15.480
message length using crypto analysis as a vehicle to tell that story but to my mind I think wonderfully

30:15.480 --> 30:21.000
connected to two different two different perspectives on exactly the same phenomenon

30:21.000 --> 30:30.200
the ways of describing self-organizing systems that basically both entail a minimization of complexity

30:31.240 --> 30:37.240
a simplification an emergence of order of a particular sort that entails

30:37.320 --> 30:45.480
either compression hence the minimum description or the minimum message length

30:46.200 --> 30:51.800
view from the algorithmic complexity in terms of sort of you know rate coding theorems rate

30:51.800 --> 30:57.240
distortion theorems and the like or you can write it down in terms of continuous probability

30:57.240 --> 31:03.000
distributions and sort of follow through from the Feynman's path integral I think they're both

31:03.000 --> 31:11.960
saying the same thing you know the way I think of this is the you know the end point of any

31:11.960 --> 31:19.160
self-organizing thing or set of things is just going to be the most likely configuration that

31:19.160 --> 31:27.960
they occupy given the kind of things that they are and that basically means that you can always

31:28.040 --> 31:38.360
describe this in a statistical and theological sense as everything providing an accurate prediction

31:38.360 --> 31:46.520
of what its sense is that is minimally complex in exactly the same spirit as the the way that you

31:46.520 --> 31:53.720
would frame complexity in terms of lossy or not losses but lossy compression or minimum

31:53.800 --> 32:01.160
description length or minimum algorithmic complexity so I think that if you if you

32:03.240 --> 32:07.560
if you tell the story that the free energy is an extensive quantity which means that all the

32:07.560 --> 32:14.040
set of numbers or any subset of numbers any partition will all will all look as if they

32:14.040 --> 32:21.560
are minimizing a free energy functional then you can I think say that you know one view of this

32:21.560 --> 32:27.960
functional is to minimize the complexity of the arrangement which should be manifest in terms of

32:27.960 --> 32:34.680
a minimization of algorithmic complexity and you can use it I can never I can never remember

32:35.800 --> 32:41.880
Zemmell Lippf or Lippf what do you know what I'm talking about there's one of these

32:43.560 --> 32:45.720
hierarchical sequential entropy measures

32:46.440 --> 32:54.280
you know there's one way of quickly enumerating the the algorithmic complexity so I think the

32:55.000 --> 33:00.520
if you could join the dots that would be a really powerful view of this and indeed you know

33:01.400 --> 33:03.560
it would be interesting if you could

33:04.040 --> 33:09.640
just for using numerical experiments join the dots

33:11.320 --> 33:20.120
quantitatively in terms of this handcrafted intuitive free energy Lagrangian just based

33:20.120 --> 33:25.640
upon you given three numbers you have to now write down an energy function that is always

33:25.640 --> 33:33.320
going to be minimized by the sorting algorithm so the endpoint conforms shares the same minima of

33:33.560 --> 33:37.640
your energy function it could be really simple it could be this the two differences squared

33:37.640 --> 33:44.520
and added together something as simple as that and if you can prove that the the minima of this

33:45.160 --> 33:56.600
is the same is the same as the the endpoint of your self-organization then you can say this is one

33:56.600 --> 34:03.800
free energy functional that very much in the spirit of hopfield nets and harmony functions

34:03.800 --> 34:12.280
you know in the early days of neural networks spin glass models pots models all of these

34:13.560 --> 34:18.520
mark of random fields you have to write down this kind of energy function and then you just

34:18.520 --> 34:22.680
simulate you know you can you can just do a gradient descent or rearrangement in order to

34:22.680 --> 34:29.480
minimize that so that's one very simple kind of free energy description of it then you'd have

34:30.440 --> 34:36.200
an inferential one under an assumed generative model so if you assume each number actually

34:36.200 --> 34:40.920
has a little mind and a generative model it's trying to estimate or trying to act upon its world

34:40.920 --> 34:46.200
to realize its beliefs about what it's sensing you'd have a variational free energy but then you'd

34:46.200 --> 34:54.760
also have the the algorithmic free energy that you could that apply to any partition

34:54.760 --> 35:01.720
and the point that if you can show that all three all three share the same minimum at the point of

35:03.000 --> 35:08.680
attaining non-equilibrium steady state I think that will be really you know a really nice illustration

35:08.680 --> 35:13.720
that all of these are different facets of exactly the same thing I mean you know it is just a

35:13.720 --> 35:20.280
description of self-organization but articulated in slightly different ways but I repeat you know

35:20.280 --> 35:31.880
once you've got different algorithms I think the process of sorting now is is somewhat constrained

35:31.880 --> 35:40.280
so that it's you know because you've got three different ways of doing this they may have different

35:41.240 --> 35:47.640
they may have different functionals that are being minimized and it may be but I'm not absolutely

35:47.640 --> 35:54.840
sure that the the order matters and as soon as the order matters then you've got dynamics in play

35:54.840 --> 36:00.680
once you've got dynamics in play that I think slightly complicates the simple

36:02.520 --> 36:09.880
algorithmic complexity argument because the algorithmic complexity the universal computation

36:10.040 --> 36:19.080
view it's not really fit for purpose to understand dynamics of organization and indeed most people

36:19.080 --> 36:24.360
would argue it's not fit for purpose to do anything because it's intractable but it's a

36:24.360 --> 36:35.640
beautiful mathematical object does that make sense yeah so one thing then for with Adam's point so

36:35.720 --> 36:41.960
I think that's a really interesting point and it raises another question which is if on the

36:41.960 --> 36:46.760
compression so it's on the compression issue so if we say that what you're trying to compress is

36:46.760 --> 36:52.440
the actual list of numbers plus the ordering of the algotypes then you know everything as you guys

36:52.440 --> 36:58.680
just said but I wonder couldn't somebody argue that in fact there is no list of algotypes to

36:58.680 --> 37:04.120
compress there's only the numbers because it's sort of like you know by the time you get to the end

37:04.920 --> 37:09.640
it's kind of like it's immaterial information it doesn't do you know it gets lost by the time

37:09.640 --> 37:13.560
you've sorted the numbers what do you need the list of algotypes for right they're not really

37:14.680 --> 37:21.640
I don't know I there's something here no I don't think so like if you take the position that the

37:21.640 --> 37:28.920
algotypes aren't relevant once they stop being used then you're imposing as an observer an assumption

37:28.920 --> 37:36.520
that the list is finished moving right but like how do you know that yeah yeah no that's that's

37:36.520 --> 37:41.480
that's super interesting and and and it's like the bigger question of there is this notion of

37:41.480 --> 37:46.920
algotypes that maybe you have to take into account what else do you have to take into account that

37:46.920 --> 37:50.840
we don't know about right like that's that's one of the things that I see is so interesting about

37:50.840 --> 37:56.120
this and then the next thing I was going to ask you Carl is what's the status of the fact that

37:56.120 --> 38:00.440
like all the things that we were just talking about about the cells you know being objects and

38:00.440 --> 38:04.520
exchanging information with their neighbors about algotypes and having predictions I mean

38:05.240 --> 38:09.000
none of that is actually in the algorithm you can see that the algorithm is like six lines of

38:09.000 --> 38:13.240
code like you can see what the algorithm is none of that is there so what's you know it's more

38:13.240 --> 38:18.120
of a philosophical question you know what what's the status of of something and I have the same

38:18.120 --> 38:21.320
question when I first heard about you know photons and least action and all that I was like but there's

38:21.320 --> 38:26.360
no mechanism to know you know to calculate which path you know is going to be best for you so

38:26.360 --> 38:33.080
what do we do with this what what do we do I'm super interested in the sort of I don't know

38:33.080 --> 38:39.560
why they're almost almost you know implicit things that it's doing whereas the explicit algorithm

38:39.560 --> 38:45.480
doesn't have any of that what do you think about that um well probably think the same thing that

38:45.480 --> 38:55.400
you do um I think um yep in a sorry in a sense what I was saying about a nuanced answer once

38:55.400 --> 39:02.040
you're dealing with you know isomorphisms between the local algorithms was exactly this issue that

39:02.040 --> 39:08.200
you bring to the table it's not you know um yeah it could be as simple as each algorithm has a

39:08.200 --> 39:12.520
different objective function different free energy or lipoonov function

39:14.360 --> 39:21.480
or it could be that they have the same but the the actual sequence of updates or moves

39:21.480 --> 39:27.400
is somehow constrained so the movement on the same free energy surface is is it is somehow

39:27.400 --> 39:31.560
constrained to be different so I'd have to know it precisely what the algorithms are

39:32.120 --> 39:37.800
um it probably is the case that I'm just guessing um that they probably don't have

39:37.800 --> 39:43.560
quite the same um objective function or or and often point of view the free energy principle

39:43.560 --> 39:51.480
implicit generative model um so the chimerical um um self-organization is a reflection of the fact

39:51.480 --> 39:58.040
that um not everything is trying to has the same generative model and therefore by definition

39:58.040 --> 40:04.840
will not have the same free energy um functional so that that does complicate the situation and

40:04.840 --> 40:09.800
makes it more interesting in fact um you know from the point of view of this this kind of

40:09.800 --> 40:17.400
requisite variety um but now I've forgotten the your your actual question um which I did have

40:17.400 --> 40:22.840
an answer to what can you remind me what the actual question was sure sure it's so so what

40:22.840 --> 40:26.920
these algorithms have in common with some of the things that you and and chris fields have said

40:26.920 --> 40:30.920
about particles and things and other people apart which is different from what happens in

40:30.920 --> 40:35.320
biology right if if if in biology I said look this cell is exchanging information with that

40:35.320 --> 40:39.560
cell and it's making decisions the next question is excellent what's the mechanism right like what

40:39.560 --> 40:44.600
it like show me show me the the the explicit uh the set of steps by which this cell does that

40:44.600 --> 40:48.760
but but here we don't have that and and presumably you know when we get down to particles and things

40:48.760 --> 40:52.920
we don't have that either so what's what what's the status of these all these amazing things that

40:52.920 --> 41:00.360
they're doing without a a mechanism to explicitly do it right and I'm going to give you an answer which

41:02.760 --> 41:10.040
comes from conversations with philosophers of maths people like max or ramsted that that question

41:10.040 --> 41:20.600
technically would be answered by appeal to what is a mechanics so a mechanics is um for example

41:20.600 --> 41:27.880
the basic mechanics of the theology principle or Lagrangian or classical mechanics under certain

41:29.000 --> 41:41.160
dynamics you know the non-dissipative or conservative so or quantum mechanics where

41:41.960 --> 41:49.080
you can't uh you you you you have to focus exclusively on the on the dissipative dynamics

41:49.720 --> 41:56.840
so the mechanics is a description of the realization of something

41:58.120 --> 42:05.080
where the thing usually conforms to a principle of least action so this is where this is a sort

42:05.080 --> 42:11.480
of deflationary answer to your question that the mechanics in and of itself is an emergent

42:11.480 --> 42:16.520
property of a variational principle of least action that can be cast in gage theoretic terms or

42:17.080 --> 42:23.080
or in terms of things like maximum entropy principles so there are principles

42:24.680 --> 42:34.280
that just describe the shape the spacetime shape of our world these give rise to and usually you

42:34.280 --> 42:43.000
can usually reduce all physics principles to principles of least action the the straight line

42:43.000 --> 42:49.800
the path of least effort um um and once you've written you've written down your principle as a

42:49.800 --> 42:58.440
principle of least action then the particular functional form of the system to which that

42:58.440 --> 43:07.720
principle applies then gives you a mechanics and then that now um acquires a teleology in

43:07.720 --> 43:14.920
conversation but only in conversation you don't need the mechanics mechanics does not engineer

43:14.920 --> 43:21.320
anything it is just an expression of the principle of least action um so very much in the spirit of

43:21.320 --> 43:25.160
basic mechanics are saying before the free energy principle is just a description of things that

43:25.160 --> 43:32.360
self-organize you may or may not want to then go and say oh well this self-organization could be

43:32.360 --> 43:38.440
described teologically as self-evidencing or active inference or decision-making or basal

43:38.440 --> 43:43.720
cognition or distributed intelligence you don't have to do that but it sometimes it can be very

43:43.720 --> 43:50.120
useful when talking to somebody else about it to to to teologically frame it like that and that I

43:50.120 --> 43:55.880
think is your mission I think that's what you're bringing to the table in in the widest sense

43:55.880 --> 44:03.320
you're saying that the mechanics of biotics self-organization have a certain tealogy which is

44:03.320 --> 44:09.560
almost isomorphic to the same tealogy of finding psychiatry or immunotherapy or climate change

44:10.280 --> 44:15.480
and we just got to find the cross-cutting themes so the mechanics the mechanisms

44:17.400 --> 44:23.320
are really just tealogical unpacking of of of the mechanics so in this instance I gave you an

44:23.320 --> 44:30.280
example before that simply the algorithm to implement the algorithm which is probably a

44:30.280 --> 44:36.280
series of Boolean operators would need certain inputs they need arguments and they need certain

44:36.280 --> 44:42.280
outputs those are the the sensory and active states those those define now the Markov blanket

44:43.240 --> 44:50.440
then so you're taking the input is basically whatever my neighbor neighbor's value

44:51.640 --> 44:56.760
whatever I can see and what I can see is my neighbor's value and it has to be a neighbor I

44:56.760 --> 45:03.400
can't see but you know the one for yeah I can't see something along the way away so that defines

45:03.400 --> 45:08.840
the input and the output is my particular number that's what I broadcast but I only broadcasted

45:08.920 --> 45:15.560
in a loop in a local sense so when you're starting to express things in terms of a

45:16.840 --> 45:24.600
a tealogy of self-organization of the kind that people use in you know in the free energy

45:24.600 --> 45:32.040
principle I think you're then you're quite licensed to say well this is just a description for

45:32.040 --> 45:38.600
example of electrochemical signaling you know it there's a magic is this is this is this is the

45:38.600 --> 45:48.600
mechanism it just means that there has to be a local signal that reports or has some morphism

45:48.600 --> 45:57.800
between my state and and you know everything that is not me and we find multiple instances of this

45:57.800 --> 46:03.720
in in biology at different temperance spatial scales and you know the more you drill down the

46:03.720 --> 46:10.520
more you actually specify what it is the more mechanistic you know it will become but you know

46:11.480 --> 46:16.360
at the end of the day that's just the mechanics you're talking about so if you you know if you

46:16.360 --> 46:22.520
wanted to describe self-organization of massive bodies that had no dissipative aspects to them

46:22.520 --> 46:26.360
you know the motion of the planets for example if you if you take yourself back and pretend you

46:26.360 --> 46:33.240
Kepler and you know what is the mechanics of motion of the heavenly bodies they're Lagrangian

46:33.240 --> 46:39.160
conservative mechanics they inherit from the principle of least action that you know has a

46:39.160 --> 46:47.560
relatively simple form before Einstein came along and in terms of you know energy conservation

46:47.640 --> 46:56.280
and you know and all that is implicit in a pattern a path of least you know the least action least

46:56.280 --> 47:01.480
action principle so that would be his kind of mechanics and you start to invent things like

47:01.480 --> 47:07.800
gravity and mass and you know and talk about the teleology of massive bodies being attracted to

47:07.800 --> 47:15.160
each other and that would be you know quite comfortably received as an intuitive mechanistic

47:15.160 --> 47:20.600
explanation for the thing at hand which in this instance is a the motion of heavenly bodies

47:20.600 --> 47:25.800
you know I I don't see there's any real problem from your point of view you've already told the

47:25.800 --> 47:34.440
story you've already got the mechanics it's just you know a question of showing how universal this

47:34.440 --> 47:40.840
kind of mechanics is and universal in the in the special context of local interactions

47:41.800 --> 47:49.320
and all the all the consequences of having a principle or the principles that would apply

47:49.320 --> 47:55.640
to self-organising systems out of equilibrium or non-equilibrium self-organisation, biotic

47:55.640 --> 48:03.160
self-organisation what kind of mechanics must be in play and then you can give particular

48:03.240 --> 48:11.000
exemplars and talk about gravity or cell intercellular signaling or you know and the

48:11.000 --> 48:17.480
locality of that does that make sense yeah yeah yeah yeah and I guess Adam did you want to say

48:17.480 --> 48:24.520
anything before I because I've got another okay so so this is kind of the the really

48:24.520 --> 48:28.600
kind of far out thing and feel free to tell me that this is not a good analogy and you know

48:28.600 --> 48:34.200
kind of too too too far out but I was thinking I was thinking about the analogy of us trying to

48:34.200 --> 48:39.640
analyse these algorithms and what it is that what what are the causes of their behavior as we observe

48:39.640 --> 48:47.320
them and trying to analogize to in a in a you know biological or maybe in a psychological

48:47.320 --> 48:53.400
slash psychiatric context where you have what you think is the algorithm and maybe that's what

48:53.400 --> 48:57.400
your subject thinks is the cause of their actions and maybe that's what you think is the cause of

48:57.400 --> 49:02.600
their actions but it turns out that there's this underlying dynamic that is it's an extra goal

49:02.600 --> 49:07.480
that you didn't know because you couldn't you you didn't see it in the in the steps of the

49:07.480 --> 49:13.720
of the policies that they're supposedly following and I wonder if this is a sort of really basal

49:13.720 --> 49:19.240
kind of I don't know I just just a really basal kind of behavioral analysis that might be important

49:19.240 --> 49:27.320
for the larger and more complex systems in the sense of finding underlying goals for for

49:27.320 --> 49:33.000
for complex behaviors that are not to be found in the by enumerating the mechanisms that you

49:33.000 --> 49:37.480
know that are there which is you know like it basically basically looking at the tendency to

49:37.480 --> 49:43.640
cluster as a as a hidden motivation for their behavior if I can use this kind of like psychological

49:43.640 --> 49:48.360
term what do you think about that Zachary is that silly or are there oh no no I think that's

49:49.240 --> 49:55.320
exactly the application of these principles and the attendant mechanics you know in terms of say

49:55.320 --> 50:04.360
voting dynamics or geopolitical and or just a spread of information on the internet you know

50:07.320 --> 50:13.480
I think some really important deep questions there and things you know why is it

50:13.480 --> 50:21.640
that almost inevitably whenever you look at some ideological political or theological commitment

50:21.640 --> 50:28.040
everybody's 50-50 you know Trump versus Biden Brexit versus stay you know wherever you look

50:28.920 --> 50:35.240
the only evolutionary stable strategy on or for energy minimizing not an equilibrium steady state

50:35.240 --> 50:41.320
is you know usually a 50-50 because that can be subdivided within what this this 50 percent

50:41.320 --> 50:46.280
there's another 50 percent in a sort of self-similar way all the way down so there's some must be

50:46.280 --> 50:52.760
something generically very important universal about that and I would imagine that's you know

50:52.760 --> 50:57.720
you will see that kind of clustering it's interesting I didn't realize I didn't read

50:57.720 --> 51:03.560
it Kevin have to realize you have this sort of the actual order wins out at the end of the day

51:03.560 --> 51:07.080
so you get the increase and then the decrease in clustering that was interesting

51:07.720 --> 51:14.280
I would be if I was a young man working for you as a PhD student I'd like to put a bit of

51:14.280 --> 51:19.880
noise on the numbers and just see if you can keep it alive and dynamic and see that clustering and

51:19.880 --> 51:27.640
that chimeric behavior look at its dynamics and you know something in dynamical systems

51:27.640 --> 51:34.520
theory called frustration that you get in these in these chimeric situations when

51:34.520 --> 51:41.400
you've broken detailed bounds like this which may be a good metaphor for voting dynamics for

51:41.400 --> 51:46.840
example and so I think it's a very sensible idea I'm just reminded have you read that paper by

51:46.840 --> 51:56.680
Connor Hines and if not I'll send it to you so he's he's he he was making an analogy between

51:57.640 --> 52:07.880
Gibbs energy and free energy in terms of exchanging ideas as a model of

52:10.760 --> 52:17.800
collective behavior and it may be you'll find some interesting ethological references

52:18.840 --> 52:25.160
references to that yeah interesting that you know the thing about the thing about them being

52:25.320 --> 52:32.040
pulled apart at the end so so one way one of the things that we did was to ask okay how how

52:32.040 --> 52:37.400
strong would this tendency to cluster be if you if you didn't have this super overlying

52:37.400 --> 52:40.920
being a basic physics of this world that eventually is just going to yank you apart

52:40.920 --> 52:45.720
and and one way to do that is to allow repeat numbers so if I allow repeat numbers then you

52:45.720 --> 52:50.440
can have a long run of fives and the first half of them could be one I'll go type the second half

52:50.440 --> 52:54.200
could be the other and the actual sorting algorithm would be perfectly happy to keep them as is because

52:54.200 --> 52:58.840
the fives are between the four yeah so so we did that and and when you do that you find out that

52:58.840 --> 53:03.080
yeah if you let them do that it actually goes higher the the tendency to cluster is actually

53:03.080 --> 53:08.440
higher that you know so there's this like competing you know and and again looking at it it almost

53:08.440 --> 53:16.520
it almost provides a very minimal model of of the existential sort of I don't know way of life

53:16.520 --> 53:21.400
facing living systems right that the physics of the world are like you're trying to grind you down

53:21.400 --> 53:25.320
but but in the meantime you can do some interesting things that are not incompatible

53:25.320 --> 53:29.240
with them there's no magic I mean it does the algorithm there's no you know there's no errors

53:29.240 --> 53:33.880
but but but yet not quite what what the you know what what the end goal is going to be

53:33.880 --> 53:36.840
according to the actual physics of the system yeah

