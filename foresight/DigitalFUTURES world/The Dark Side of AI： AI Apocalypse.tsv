start	end	text
0	2000	Okay, shh, no more.
6000	11000	Hello and welcome to the first session of 2024.
11000	14000	This is sightly out of sequence.
14000	19000	It's part of our doctoral consortium series from last semester.
19000	22000	Our final session had to be cancelled the last minute,
22000	26000	but we're delighted to have a follow-up session
26000	30000	to complete the series on the theme of AI apocalypse,
30000	33000	the series that was called the dark side of AI.
33000	36000	And all of the previous sessions are uploaded
36000	43000	onto our digitalfutures.international YouTube channel.
43000	47000	And I would say that from that, the first five in the series,
47000	50000	that we became a bit more, I guess, lenient in some way.
50000	54000	I started off by saying, well, actually we do need to worry about AI.
54000	56000	And over this course of the series,
56000	58000	which is actually fascinating because we had a series
58000	61000	on questions such as copyright and so on and so on.
61000	63000	I think people softened up a bit and said,
63000	65000	no, we don't have to worry about AI.
65000	70000	Today I'm really delighted to have Eric Kessel here with us.
70000	74000	Eric is a designer, educator, writer,
74000	79000	and host disaster expert, professor disaster, I guess.
79000	88000	And Eric takes a rather more kind of concerned attitude towards AI.
88000	92000	He was formerly the director of the Sustainable Environment Design
92000	99000	major at the College of Environmental Design at UC Berkeley.
99000	101000	He's currently a special program instructor
101000	103000	at Harvard Extension School.
103000	105000	And Eric really has made a name for himself
105000	109000	because using the kind of lens, shall we say,
109000	112000	of disaster theory, disaster studies to look at things.
112000	118000	He recently published what I think was an extraordinary article
118000	122000	in Design Intelligence, looking at the question
122000	127000	of what the impact of AI would be on the profession.
127000	130000	Today then, Eric is going to make a presentation.
130000	134000	We are going to have, I will have a short discussion with him.
134000	137000	And then we'll open up to questions from,
137000	142000	not only on the Zoom audience itself, but also from YouTube.
142000	146000	So feel free to put in some of these questions.
146000	149000	Probably not as long a session as sometimes some of our sessions,
149000	152000	but this is, I think, going to pick up as we go
152000	155000	because I think this is an absolutely fascinating topic.
155000	159000	So Eric, welcome.
159000	161000	It's great to see you.
161000	165000	And it's a great way to kick off the new year
165000	167000	with a bang, shall we say.
167000	171000	AI Apocalypse.
171000	173000	Yeah, well, thank you for having me.
173000	176000	I appreciate the chance to talk about it.
176000	179000	I've actually entitled my lecture,
179000	181000	AI Apocalypse, question mark.
181000	183000	I think it still remains to be seen,
183000	186000	and we have some agency in what happens
186000	190000	in the future of design, architecture, and AI.
190000	193000	But first, let's break this down.
193000	196000	We're going to go through an introduction,
196000	198000	talking about crisis and disaster,
198000	203000	how to cultivate a disaster lens, what that looks like,
203000	207000	then deconstruct some myths on AI and architecture,
207000	210000	and then finally wrap it up with the brighter side of disaster
210000	214000	because there is one, and fundamentally an optimist.
214000	217000	So I hope everybody sticks around for that.
217000	219000	So a bit about me.
219000	222000	I've done a lot of things in my career.
222000	225000	I've had a pretty eclectic experience,
225000	229000	been an activist, a humanitarian builder,
229000	232000	periodically an architect, a construction manager,
232000	234000	a pre-fed or lewd for graduate school,
234000	237000	a disaster responder, a kind of design,
237000	239000	Cassandra, you might call it,
239000	243000	a writer, radio host, professor, and academic director.
244000	247000	And that brings us into 23-24,
247000	249000	which was an interesting year for me
249000	253000	because a lot of these things effectively came together
253000	258000	to launch this recent mission around AI and architecture
258000	261000	and the potential consequences for it.
261000	264000	My work has been all over the place,
264000	267000	but I think I'm probably principally known for two things.
267000	272000	One, writing a book called Down Detour Road in 2010
272000	274000	at the height of the Great Procession,
274000	277000	and that was inspired by a different kind of crisis.
277000	280000	I read an article in The Nation, I believe it was,
280000	282000	or maybe it was The Guardian,
282000	284000	that talked about the relative unemployment rates
284000	286000	for different professions,
286000	288000	and I was shocked, slash not shocked,
288000	292000	to find out that architects were at the bottom of the list
292000	295000	out of, you know, 700-something professions,
295000	298000	or 380 professions, I'm sorry,
298000	301000	but they were facing seven-fold, eight-fold increase
301000	303000	in unemployment claims, and, you know,
303000	306000	this didn't make a ton of sense to me.
306000	309000	And my read on it was that the profession was in crisis.
309000	312000	I mean, it was a recession, so everybody was in crisis,
312000	314000	but architecture was in its own particular crisis,
314000	317000	and to me, it was a crisis about value.
317000	320000	People had ceased to really value architecture
320000	322000	was what explained that for me.
322000	325000	I wrote a book about it called Down Detour Road,
325000	328000	which the premise of was that, you know,
328000	331000	people had ceased to see the value in architecture
331000	333000	because I think architecture had ceased
333000	335000	to see the value in people.
335000	337000	During the deconstructivist period,
337000	340000	we got into a lot of formalism and distance ourselves
340000	343000	from the problems that people deal with in their everyday life,
343000	347000	and, you know, that led to a lot of openings
347000	350000	and hopefully an optimistic message about architecture.
350000	354000	Secondly, I'm probably best known for my post-disaster work,
354000	357000	which began while I was still a student.
357000	360000	This is a picture taken of me right before I went down
360000	363000	from my first assignment in Biloxi, Mississippi,
363000	366000	where I was working with the Biloxi Gulf Coast
366000	369000	Community Design Studio under David Perks.
369000	371000	And it was an education, I think,
371000	375000	that put me in touch with the real power of architecture.
375000	378000	From there, I went to Haiti with Architecture of Humanity,
378000	382000	and that was a furtherance of my design education
382000	387000	and understanding about what the real power of architecture
387000	390000	can be when it's pointed in the right direction.
390000	393000	And it was blessed to be surrounded by an incredible team
393000	395000	from all over the world.
395000	398000	It was about a third Haitian, about a third Haitian diaspora,
398000	400000	and about a third international,
400000	404000	which in itself is composed of architects from 10 countries.
404000	407000	And we put together a pretty incredible program
407000	409000	of community-based design,
409000	412000	working with survivors of the earthquake in 2010
412000	417000	to rebuild schools, clinics, whole communities at times
417000	419000	to offer training.
419000	422000	This has been the bulk of my practice, actually,
422000	425000	is helping people through disaster
425000	429000	and helping them imagine better futures
429000	431000	because there's always the potential
431000	435000	for a better future after disaster.
435000	438000	So from there, I went to Japan
438000	442000	and assisted with that program under a similar remit.
442000	447000	Subsequently, New York, the Philippines, kind of all lower,
447000	451000	and that work was enough to earn me a kind of dubious moniker
451000	454000	of being architecture's first responder,
454000	457000	or so-called by the daily beast.
457000	461000	I retired from field work in 2015
461000	463000	after the Nepal earthquake
463000	466000	and turned my attention to teaching first at Washu
466000	468000	and then subsequently at Berkeley
468000	470000	and most recently at Harvard.
470000	473000	And in those programs in varying ways,
473000	475000	I teach about disaster and resilience
475000	478000	to try and bring those lessons
478000	484000	and those conversations forward into the practice of architecture
484000	488000	and the teaching of the practice of architecture and design,
488000	490000	among other things.
490000	493000	And through that work, I developed,
493000	496000	I guess you could call it a theory of disaster
496000	499000	and how to look for it, how to understand it,
499000	503000	how to see the world through that particular lens.
503000	506000	And all of this came together last year
506000	508000	when I was asked to write an article
508000	510000	for Design Intelligence Quarterly,
510000	513000	the article that Neil mentioned in the introduction.
513000	516000	And it wasn't originally supposed to be on AI,
516000	519000	but between myself and the editor there,
519000	521000	we agreed that it would be.
521000	524000	And that launched an exploration
524000	527000	and it was fueled by skepticism, I think.
527000	531000	At the time, this would have been February of 2023,
531000	534000	there was a disconnect between what was happening in the world
534000	536000	and what was happening in design.
536000	538000	I mean, I suppose there typically is,
538000	542000	but this one seemed a bit more ominous.
542000	545000	In the world, we were hearing messages about,
545000	548000	you know, AI is going to destabilize everything
548000	550000	and the World Bank and the IMF
550000	554000	were predicting huge job losses and massive change.
554000	557000	Professors at Wharton and top business schools
557000	559000	and economists were, you know,
559000	562000	looking at this as a very, very serious development
562000	564000	in the future of work.
564000	567000	And then there was, you know, the design world.
567000	569000	So, you know, I read the same design rags
569000	571000	as everybody else, I suppose.
571000	573000	So, you know, we kept hearing messages
573000	576000	from design leaders to this effect.
576000	581000	You know, there's nothing that can compete with architects.
581000	584000	This one from Shane Berger, you know,
584000	589000	the design process is going to remain fundamentally human.
589000	592000	There's this kind of limited capabilities.
592000	595000	And I wanted to understand for myself where the truth lay.
595000	600000	I suspected it lays somewhere between those two polarities.
600000	603000	And, you know, I asked if I could explore this
603000	605000	through this article for design intelligence
605000	608000	and they gratefully said yes.
608000	611000	So, you know, I sat down to figure out, you know,
611000	615000	what exactly I thought the impact was going to be.
615000	618000	And the prevailing line at that time was that, you know,
618000	621000	AI is going to automate the simple things.
621000	624000	It's not going to automate the more complex work.
624000	626000	So, for me, the greater challenge was, you know,
626000	632000	how do you envision or propose that AI might actually,
633000	635000	you know, replicate some of that higher level work
635000	638000	that architects and designers do.
638000	640000	And I borrowed something from Phil Bernstein's book,
640000	643000	Machine Learning, a framework for understanding
643000	646000	the relative cognitive complexity of different tasks
646000	649000	that exist within an architect's day.
649000	651000	If you've read that book, if you haven't read that book,
651000	653000	you should. It's a great book.
653000	656000	But Phil has this framework, essentially,
656000	659000	for ordering projects between, you know,
659000	661000	a procedural, like really kind of task,
661000	664000	repetitive task sort of things,
664000	667000	up to integrative and perceptive.
667000	670000	Those are the higher level cognitive functions.
670000	673000	And he provides us with a brilliant map, essentially,
673000	677000	for where all these things occur within the architectural process.
677000	679000	And just to make my life difficult, I said,
679000	682000	well, you know, what if we aspire to get it
682000	685000	to replicate the harder parts rather than the easier parts?
685000	688000	I figured the easier parts would figure itself out.
688000	691000	To me, and I think to Phil as well,
691000	695000	you know, the hardest parts are the integrative stuff, right?
695000	699000	It's the vision. It's being able to sit with a client
699000	703000	and context and understand through typically inarticulate words
703000	706000	what that vision is actually going to be
706000	710000	and to bear it out in the form of an idea
710000	713000	for a building or something like that.
713000	715000	And as a proof of concept that, you know,
715000	718000	I was initially made for myself just to make sure I knew
718000	721000	what I was talking about. I developed a video,
721000	724000	which I think, you know, also mentioned in the beginning,
724000	726000	but it's attached to the article.
726000	728000	You can find it on my YouTube channel,
728000	730000	or you can find it on Design Intelligence.
730000	732000	But I'm going to play a short clip
732000	734000	just to introduce what I'm talking about here.
734000	736000	Hilda told me a bit about your project,
736000	738000	and I'm excited to learn more.
738000	740000	Can you share your vision for it?
740000	743000	I'm looking to build a modern, sustainable home for myself
743000	746000	and be environmentally friendly. It's important for me to...
746000	749000	So what you're looking at, and this goes on for about 20 minutes,
749000	753000	is two GPTs set in opposition to each other.
753000	756000	And they've both been programmed with personalities.
756000	760000	So I said to the model, like, you are the client,
760000	762000	you are a successful tech executive,
762000	764000	you are a mother of two,
764000	767000	you have a passion about kayaking, you know, this sort of thing.
767000	770000	But I didn't give her any specific information necessarily
770000	773000	about the architectural process or anything like that.
773000	776000	And I did the same thing with the gentleman on the left,
776000	779000	who was the architect, right?
779000	782000	He was an architect, he was 55.
782000	785000	You know, he went to school at Columbia, this, that,
785000	788000	and the other thing, I didn't give him any instructions
788000	791000	on what being an architect actually meant.
791000	793000	And Hilda told me a bit about you.
793000	795000	Let's fast forward through that.
795000	797000	Through that conversation,
797000	801000	GPT was able to generate a design brief
801000	804000	based on the interview that the client had.
804000	807000	Truthfully, it was just GPT having a conversation with itself.
807000	810000	But nonetheless, based on that exchange,
810000	813000	which was totally autonomous, it generated a design brief,
813000	817000	which was then able to convert to image prompts,
817000	819000	which went into mid-journey.
819000	821000	Once mid-journey five debuted,
821000	824000	I was able to actually get image recognition to play along.
824000	828000	So Carla, the client, could actually look at the design options
828000	832000	and respond.
832000	834000	That was a little disarming.
834000	837000	The really alarming part were all of the emerging phenomena
837000	839000	that came out of this.
839000	843000	I guess emerging capabilities is what the AI world calls them.
843000	848000	But chat GPT illustrated some alarming knowledge
848000	850000	about the process itself.
850000	853000	So, you know, once it had gone through this design process,
853000	856000	I asked it to produce a door and room schedule,
856000	858000	which it did.
858000	862000	And, you know, oddly, somehow knew that, like,
862000	865000	bathrooms should have one window and not two,
865000	868000	and that a powder room might be the exception.
868000	872000	A powder room might have zero windows as opposed to one.
872000	875000	So, you know, it was picking up on all these lot of things
875000	877000	that might be known to an architect
877000	880000	or might even be known to a layperson.
880000	884000	But I certainly did not expect that the model would be able
884000	888000	to extrapolate all that information just from a 20-minute
888000	891000	conversation between an artificial architect
891000	893000	and an artificial client.
893000	896000	It did the same thing with budget.
896000	899000	It came up with a budget for 2.2 million.
899000	901000	Again, no extraneous information.
901000	904000	I mean, it inferred that from the site
904000	908000	and from whatever Carla the client was saying to this architect
908000	911000	that she wanted out of her house,
911000	913000	checked with a few contractor friends
913000	916000	and, like, a lot of this AEI stuff, you know,
916000	918000	wasn't wrong, could have been better,
918000	921000	but it was in the ballpark.
921000	925000	So, this immediately struck me as a disaster,
925000	928000	because disasters typically happen
928000	930000	when the perceived threat is much different
930000	932000	than the actual threat.
932000	935000	That's what gets us into trouble as a species.
935000	938000	So, in my estimation, you know,
938000	941000	I didn't believe the doomsayers that were saying that,
941000	943000	you know, this is the end times,
943000	945000	but I didn't believe the Pollyanna stuff
945000	949000	that I felt was coming out of a lot of the design professions.
949000	952000	The truth was somewhere in the middle
952000	955000	and didn't look great.
955000	958000	But let me flesh out what I mean by disaster lens
958000	960000	to shed some light on that.
960000	963000	So, how do we cultivate a disaster lens?
963000	965000	I want to teach my students that there are things
965000	970000	that you can look at that speak to the growing vulnerability
970000	975000	and precarity of a particular context or situation, right?
975000	978000	So, if you're looking at a natural disaster,
978000	980000	like an earthquake, fire, hurricane, that sort of thing,
980000	983000	you might look towards, you know, neglected infrastructure,
983000	985000	trending towards decay, you know,
985000	987000	bridges and power stations
987000	989000	that should have been replaced a long time ago.
989000	992000	You might also look to the emergence of patchwork solutions.
992000	995000	So, if instead of replacing the broken levee,
995000	997000	we just keep building it two feet higher over and over,
997000	999000	that's usually a pretty good clue.
999000	1002000	A widening or deepening of the zone of vulnerability.
1002000	1005000	So, 100,000 people living in a fault line,
1005000	1007000	that could be a problem.
1007000	1009000	That can be a disaster.
1009000	1011000	That city swells to 3 million people.
1011000	1014000	Then you've got a really serious disaster on your hand.
1014000	1017000	Same fault line, just different zone of vulnerability.
1017000	1021000	Widespread irrational and credibility.
1021000	1023000	This is a tough one to pin down,
1023000	1027000	but basically it's the anti-chicken little bone.
1027000	1030000	The people who believe it can't happen here,
1030000	1033000	and that is an emotional and a psychological belief
1033000	1037000	that isn't particularly grounded in any evidence or analysis.
1037000	1041000	It's just the way that people feel about things.
1041000	1045000	All of these things taken in their sum, or even one by one,
1045000	1048000	don't necessarily constitute a disaster.
1048000	1050000	This is merely the framework,
1050000	1055000	the things that set up the possibility of disaster.
1055000	1059000	I liken it to a tornado watch and a tornado warning,
1059000	1063000	and then I find that people don't really understand what that is,
1063000	1065000	especially if you're outside the United States.
1065000	1068000	So, I've actually happened upon the taco watch,
1068000	1071000	and the taco warning is the way to explain it.
1071000	1075000	So, taco watch is like, you have all the ingredients for a taco,
1075000	1079000	but there's no taco, it's just a bunch of ingredients laying around.
1079000	1082000	The taco warning is like, we have a taco.
1082000	1084000	We're having tacos right now,
1084000	1087000	you need to react to that sort of situation.
1087000	1091000	The four things, and that's not a comprehensive or exhaustive list.
1091000	1093000	We go through much more through the course of the semester,
1093000	1096000	but there's things that you can look at
1096000	1100000	that essentially create the possibility of tacos, so to speak.
1101000	1104000	Finally, you need to trigger an event.
1104000	1109000	That's the thing that ultimately brings a disaster into the news,
1109000	1111000	into reality, and believe it or not,
1111000	1116000	I've always found the best way to explain this is by using beavers as an analogy.
1116000	1119000	So, when a beaver goes to cut down a tree,
1119000	1122000	it doesn't cut down the entire tree,
1122000	1124000	and it doesn't push the tree over.
1124000	1126000	It's not a very strong animal.
1126000	1131000	A 30 or 40-pound animal versus a 10,000-pound tree.
1131000	1134000	What it does do is it eats around the base
1134000	1137000	and subtly erodes the structural integrity of the tree,
1137000	1142000	and eventually a gust of wind comes along and it blows the tree over.
1142000	1145000	That is not the beaver's doing.
1145000	1147000	It's the wind that blew over the tree.
1147000	1151000	The beaver just set up the conditions for the wind to be able to do that.
1151000	1154000	We can map this over time
1154000	1158000	and look at essentially a wind condition,
1158000	1161000	then the wind's blowing, however the wind's blowing,
1161000	1166000	and then a rate of chewing that is constant, presumably,
1166000	1169000	and then because the rate of chewing is constant,
1169000	1173000	the structural integrity of the tree is steadily declining.
1173000	1176000	Disasters have been here in the red circle.
1176000	1182000	At that intersection of some event and some trajectory of vulnerability,
1182000	1186000	that's where the disaster, in fact, occurs.
1186000	1188000	It does not occur when the wind is strongest.
1188000	1192000	It does not occur at some particular point of vulnerability.
1192000	1195000	You really have to bring those two things together in time
1195000	1199000	in order to have a disaster.
1199000	1202000	You can apply the same logic to a city,
1202000	1204000	and in fact, in my classes, we often do.
1204000	1206000	You can take the healthy growth of a city,
1206000	1209000	maybe at 2% or something like that,
1209000	1213000	but the population density is growing faster than that,
1213000	1219000	which suggests a lack of housing or something else going on.
1219000	1222000	The average wealth of population is going down,
1222000	1224000	which means people have fewer resources
1224000	1227000	to support themselves in the event of a disaster.
1227000	1230000	The budget for emergency services is static,
1230000	1234000	even though the population and the population density is increasing.
1234000	1237000	The average age of critical infrastructure,
1237000	1241000	bridges and buildings and everything is falling apart.
1241000	1243000	You can roll this stuff up together,
1243000	1245000	not necessarily in an arithmetically way,
1245000	1247000	but you can roll this stuff up
1247000	1251000	into some kind of picture of overall resilience,
1251000	1254000	based on the number of things that are going up
1254000	1256000	and the number of things that are going down,
1256000	1258000	and how impactful those things are.
1258000	1261000	You get a sense of whether the resilience,
1261000	1263000	the ability to resist an event
1263000	1267000	is going up or down for a particular city in this case.
1267000	1269000	Then you have the event itself,
1269000	1273000	like the earthquake that happens every 100 years,
1273000	1276000	200 years, 500 years, whatever it is,
1276000	1279000	but when it does, as it crosses that intersection,
1279000	1282000	that's what creates a disaster.
1282000	1285000	I mentioned the 2010 Haiti earthquake previously.
1285000	1291000	Haiti had actually had a similar sized earthquake 200 years prior.
1291000	1293000	Of course, nobody remembered,
1293000	1296000	because we don't remember things that happened 200 years ago.
1296000	1299000	Not a big disaster, not a lot of damage,
1299000	1301000	because there was hardly anyone there.
1301000	1303000	It was 200 years ago, so Port-au-Prince was there.
1303000	1305000	It was just a very, very small city,
1305000	1307000	and most of the buildings were made of wood.
1307000	1310000	You really have to look at the possibility of disaster
1310000	1313000	as something that is happening through time.
1313000	1317000	We can actually translate this disaster lens,
1317000	1319000	this disaster thinking to non-physical things,
1319000	1323000	and that also happens in my classes from time to time.
1323000	1326000	We can apply it to non-physical things,
1326000	1328000	like a profession itself,
1328000	1331000	which is kind of how I started looking at all of this stuff.
1331000	1333000	In terms of infrastructure,
1333000	1336000	well, a profession of architecture is terrible infrastructure.
1336000	1340000	We have long licensing periods, low pay, precarious employment,
1340000	1342000	cutthroat competition.
1342000	1347000	It's not a structurally sound profession necessarily.
1347000	1351000	We can debate that, but yeah, anyway.
1351000	1354000	Then we have patchwork solutions.
1354000	1358000	If the profession is facing a crisis of value,
1358000	1361000	then it keeps doing these stepwise things,
1361000	1365000	like slightly changing the internship program
1365000	1369000	that everybody has always disliked under any particular form,
1369000	1371000	or transitioning to BIM,
1371000	1375000	but not capturing the value off of that transition.
1376000	1378000	A widening zone of vulnerability.
1378000	1382000	Well, there's 17% more architects than were a decade ago,
1382000	1385000	but AI is going to leave them with less work to do.
1385000	1387000	How much less work, I'm not really sure,
1387000	1392000	but that pool of vulnerability is getting larger.
1392000	1396000	Then the widespread irrational incredulity.
1396000	1400000	I would put in this box specifically,
1400000	1402000	design voices that are saying,
1402000	1405000	there's not going to be any impact on architecture.
1405000	1408000	There's just going to be impact everywhere else.
1408000	1411000	That ignores all fundamental laws of economics.
1411000	1415000	If there's huge job losses in the non-architectural world
1415000	1417000	and the rest of the economy,
1417000	1420000	that has macroeconomic effects.
1420000	1425000	Probably gets us to 5%, 10% employment, causes a recession.
1425000	1429000	The last time that there was a recession with 10% unemployment
1429000	1433000	in this country, a third of all architects lost their jobs.
1433000	1437000	The idea that AI might have some huge effect
1437000	1439000	on all their professions,
1439000	1444000	but not on architecture is incoherent, in my opinion.
1444000	1446000	The triggering event.
1446000	1448000	What is the triggering event in this case?
1448000	1451000	In 2008, it was the great recession.
1451000	1456000	I think that the debut of natural language generative AI
1456000	1459000	may in this case be the triggering event.
1459000	1463000	We can map this out the same way that we have with these other things
1463000	1466000	and say, look, for the profession of architecture,
1466000	1468000	the complexity of buildings is increasing.
1468000	1472000	That's good for architects because it means they have more to do.
1472000	1478000	The cost of construction is increasing.
1478000	1481000	That's also good because design fees usually track
1481000	1482000	with construction costs.
1482000	1484000	Student loan balance is going up.
1484000	1487000	That's not good because it means architects themselves,
1487000	1488000	especially the younger ones,
1488000	1491000	are in more precarious individual situations.
1491000	1494000	Pay relative to inflation is going down.
1494000	1496000	That's not so good.
1496000	1499000	The overall resilience is going downwards.
1499000	1503000	Similar to what we saw with the tree and what's going on with the city,
1503000	1506000	we have this curve.
1506000	1508000	Whatever it is, the shock to the system,
1508000	1512000	be it a recession or a new technology or something like that,
1512000	1515000	that brings about the disaster.
1515000	1519000	The disaster happens at some point in the future.
1519000	1522000	Why doesn't this feel like a disaster?
1522000	1524000	I can hear some of you saying,
1524000	1527000	we don't think of it as a disaster the way we do an earthquake
1527000	1530000	or a hurricane or something like that.
1530000	1534000	I think that the hesitancy to understand it as such
1534000	1538000	is translatable from physical hazards to professional hazards
1538000	1539000	and et cetera.
1539000	1542000	We protect ourselves from the psychological toll
1542000	1545000	of impending disaster through myths.
1545000	1548000	We invent ideas about what's going to happen
1548000	1552000	and what's not going to happen in order to protect ourselves
1552000	1556000	from the really high emotional and psychological costs
1556000	1558000	of understanding that.
1558000	1561000	That's the logic of it can't happen here.
1561000	1563000	It can't happen to me.
1563000	1567000	Human beings are actually not very good at judging the future.
1568000	1572000	We create these myths about what's going to happen in the future.
1572000	1575000	They keep us safe when we tell ourselves,
1575000	1578000	it can't happen here.
1578000	1581000	That's a problem because if we really believe that,
1581000	1583000	we're not preparing for it.
1583000	1586000	I think that was part of the point of Sinclair-New Louis' novels
1586000	1588000	that if you think it can happen here,
1588000	1590000	you'll take steps to prepare for it.
1590000	1593000	If you've washed out the possibility in your own mind,
1594000	1599000	then it opens the door to whatever's coming next.
1599000	1602000	Not a guarantee, but it opens that door.
1602000	1605000	How do we deconstruct these myths?
1605000	1607000	This is my favorite part.
1607000	1610000	On my sub-stack, Life is a Disaster,
1610000	1613000	you'll find lots of examples of this where I go
1613000	1617000	and break down myths associated with AI and architecture.
1617000	1621000	Let's deal with five of them just for today real quick.
1621000	1625000	Myth one, AI won't replace jobs, not tasks.
1625000	1628000	I started with this one because it's patently absurd.
1628000	1630000	That's what a job is.
1630000	1634000	It's just a bunch of tasks that roll up into some project
1634000	1637000	and projects that roll up into programs
1637000	1640000	and programs that roll up into practices.
1640000	1644000	What we've been being told about this AI stuff
1644000	1647000	is that you're going to have a firm
1647000	1652000	and then everybody is going to essentially have more time
1652000	1656000	because all of this technology is going to automate away
1656000	1659000	all of the boring tasks that we have.
1659000	1662000	This isn't how it plays out.
1662000	1666000	If anybody's ever been in a firm where layoffs are going,
1666000	1668000	this isn't what happens.
1668000	1671000	They don't allow people to just have their workload
1671000	1673000	reduced necessarily.
1673000	1676000	Every firm principle in the world is obsessed with utilization.
1676000	1680000	How do we get people to a maximum level of utilization
1680000	1684000	so that we're billing the clients for that person's time?
1684000	1687000	The more likely stairs is actually this one.
1687000	1691000	Workload is reduced through technological efficiencies
1691000	1695000	and you just don't need that fifth person anymore.
1695000	1700000	That is what happens in the face of technological evolution
1700000	1702000	and efficiency gains.
1702000	1706000	At the end, you have four architects instead of five
1706000	1710000	and they're fully utilized because that work has been redistributed.
1710000	1715000	This has to be the case because of the way that we define work.
1715000	1721000	Work is just some amount of effort times some amount of time.
1721000	1723000	That's all it is.
1723000	1727000	An example on screen, two full-time equivalents for six months
1727000	1731000	is equivalent to about 2,000 hours a month.
1731000	1733000	A year, rather.
1733000	1737000	That's the same as one person working full-time for a year.
1737000	1741000	It's also the same as three people working for four months.
1741000	1743000	That's all the same amount of work.
1743000	1747000	Any technological evolution is going to have one or two effects.
1747000	1750000	It's either going to give us less work to do,
1750000	1754000	meaning it reduces the overall amount of labor involved in a task,
1754000	1756000	or it's going to speed things up,
1756000	1759000	meaning we can get things done faster.
1759000	1761000	Or it's going to do both.
1761000	1765000	Both of these are problematic for architecture.
1765000	1769000	Under scenario one, where it just reduces the overall work,
1769000	1773000	we've got a problem because there's just not as much work to do.
1773000	1776000	Technology has taken something that used to take a week,
1776000	1778000	and now it takes an hour,
1778000	1783000	so we've got to find something for that person to do with the rest of their week.
1783000	1786000	Scenario two, things moving faster,
1786000	1790000	could also be problematic, almost certainly will be,
1790000	1792000	because as you start to speed things up,
1792000	1796000	you end up with these holes in the project cycle.
1796000	1800000	What do you do with that time?
1800000	1802000	The most likely scenario, in my opinion,
1802000	1805000	is that it's actually both, that it speeds things up
1805000	1810000	but also reduces the overall amount of labor involved.
1810000	1812000	Yeah, we've got problems.
1812000	1815000	This is potentially disastrous.
1815000	1819000	Myth number two, AI will automate the tasks we don't like,
1819000	1822000	leaving us more time to design.
1822000	1824000	I've heard this everywhere,
1824000	1830000	in kind of every article and position point on AI.
1830000	1833000	There's somehow this belief that,
1833000	1836000	once AI automates away all the shop drawings
1836000	1840000	and red light and CAD drawings and all this shit,
1840000	1844000	we can just spend all of our time designing,
1844000	1846000	and it's a very attractive idea,
1846000	1849000	because we love design, that's what we were trained for
1849000	1852000	and that's what we went to school for.
1852000	1855000	I like designing, but I don't think that this is possible,
1855000	1860000	because it's actually constructed on top of several other myths.
1860000	1864000	If this is the idea that we're going to have huge amounts of time
1864000	1867000	to spend in design, now that construction documents
1867000	1869000	and all the rest have been sped up,
1869000	1872000	I think the problem there is,
1872000	1877000	we don't necessarily choose where technology is going to have an impact.
1877000	1882000	The presumption behind that idea of having more and more design time
1882000	1886000	is that AI is going to have a huge impact here
1886000	1890000	on the stuff that we don't like to do, and then none here.
1890000	1893000	Technology does never really work that way.
1893000	1898000	Once a technology like cell phones or electricity or computers penetrates,
1898000	1901000	it becomes a de facto expectation.
1901000	1904000	If you're a photographer and you don't want to use Photoshop,
1904000	1907000	you don't have to, it's not like the law,
1907000	1911000	but you're going to have a real problem coexisting in a competitive economy
1911000	1913000	with photographers that do.
1913000	1919000	We don't necessarily just get to decide where technology applies,
1919000	1921000	generally speaking.
1921000	1925000	I think there's also something about the law of diminishing returns,
1925000	1929000	and I think mature designers get to a point where they realize
1929000	1936000	that designs get to a point where they're 95%, 96% of perfect,
1936000	1940000	and we have that drive within us to get them to 100%,
1940000	1945000	and we know that we can, but the closer you are to design perfection
1945000	1951000	if such a thing exists, the harder it is to resolve those last little bits
1951000	1954000	without going back and reinventing everything that you just did.
1954000	1960000	I think clients also understand this, which is why they put a deadline on you.
1960000	1961000	Professors understand it.
1961000	1965000	That's why you have final review, because if those deadlines didn't exist,
1965000	1967000	we would just keep working forever.
1967000	1970000	If you imagine this graphically, you say,
1970000	1974000	okay, there's a design that it's 95% of perfect,
1974000	1980000	and I'm going to work asymptotically to get it towards that final product.
1980000	1984000	This has financial implications for whoever's paying the bill for your design time.
1984000	1989000	At first, it's a loss because the design adaptations, whatever it is,
1989000	1991000	have not been fully resolved.
1991000	1993000	You need time to think through that and to think through,
1993000	1998000	okay, how do I get from 95% to 100% perfect design,
1998000	2001000	idealized design, and everybody's fine.
2001000	2005000	So someone is taking a loss on that particular time.
2005000	2009000	As those choices start to mature, assuming that you are a brilliant designer,
2009000	2013000	which I'm sure you are, the payout becomes really high.
2013000	2020000	The marginal payout for every additional unit, day, week, month of design time,
2020000	2026000	climbs rapidly because you're resolving the things that weren't resolved in the 95% scenario.
2026000	2034000	But the closer you get to perfection, the more those gains start to diminish.
2034000	2040000	That's in the nature of diminishing returns of asymptotic growth and all these other things.
2040000	2045000	So that's why it seems like for a lot of clients, 95% is good enough.
2045000	2049000	They're not interested in paying for you to get to 100%.
2049000	2057000	Exceptions exist, obviously, but for a lot of clients, good enough is good enough.
2057000	2060000	And because fundamentally when we're working like this,
2060000	2065000	different kinds of changes have different value through time.
2065000	2072000	So I think the most convincing micro myth under this myth is what I call the creativity surplus.
2072000	2076000	And I'm sure everybody has seen some version of this cartoon at some point.
2076000	2083000	The architect starts out with some brilliant vision, hugely aspirational about what to do with the design.
2083000	2086000	It gets a little knocked down with the meeting with the clients.
2086000	2091000	And then you go through all the working drawings and budget revisions and value engineering.
2091000	2096000	And pretty soon the building is kind of ordinary.
2096000	2107000	So I think from a standpoint of value analysis, if we can't get clients to pay us for all the creativity that we have now,
2107000	2112000	why would we suspect that they're going to pay us for more of it?
2112000	2121000	So this idea that this technological advance will lead to this explosion in design activity and design time.
2121000	2124000	Unless you're working for yourself, I don't see it being true.
2124000	2129000	Like someone is still going to have to pay you for all of that time.
2129000	2138000	So myth number three, AI won't place architects because architects are too smart or creative or charming, attractive.
2138000	2142000	Take your pick. I've seen lots of ideas like this.
2142000	2146000	I think that's probably true.
2146000	2154000	And I think it's a red herring argument that people are making sometimes where they say AI will not get to the level of human.
2154000	2161000	The reality that we need to understand is that AI does not need to get to human level in order to displace humans.
2161000	2166000	Because that's not how people make purchasing decisions.
2166000	2174000	Everybody has had some cheapo client at some point and everybody has had a dream client at some point.
2174000	2180000	And we can borrow a concept from economics called indifference curve to map this out.
2180000	2186000	This is not exactly how an indifference curve is supposed to be used, but we're using it as a proxy.
2186000	2192000	So how do we exchange things between good architecture and cheap architecture?
2192000	2196000	Like how do people assess that balance? Well, you can map that with a curve.
2196000	2201000	And the easiest way to understand it is through its slope, through rise and run, just like a stair.
2201000	2212000	So what this is visualizing is a client who is willing to reduce the quality of design by 50% if the cost is reduced by 40%.
2212000	2219000	Not great, not terrible, probably a middle of the road client or something like that.
2219000	2229000	The second client is a lot worse because this is a client that will reduce the quality of design by 50% for a 10% drop in cost.
2229000	2235000	So I've certainly had clients like that, maybe some other people have too.
2235000	2242000	But these are the clients who don't really care about design and they're just good enough is good enough.
2242000	2247000	They're just willing to pass over everything if it saves a few bucks.
2247000	2253000	And that's kind of tragic and I know that a lot of architects live with that frustration on a daily basis.
2253000	2262000	So how does this play out in terms of the competition between human architects and generative design?
2262000	2265000	Well, we can also map this over time.
2265000	2274000	So if we assume that human is the standard, that's 100%, that is the talent and capability and vision of a human architect.
2274000	2283000	And we've got generative design either with human assistance or without that's rising and we commit to the idea that it will never get there.
2283000	2293000	It will never reach human capability, no matter how much time we give it, it's just going to be 90% of what an architect can be.
2293000	2300000	We're here, we're living in the yellow zone where capabilities of this technology is rising very quickly.
2300000	2304000	But at the same time, like we know that it's just never going to get there.
2304000	2305000	Okay, fine.
2305000	2306000	How does that compare to costs?
2306000	2317000	Well, the costs of a human architect, human design is going up steadily as you expect it would with inflation, hopefully, you know, a raise once in a while.
2317000	2327000	The cost of generative AI is dropping precipitously and has been for decades and will likely continue to do so.
2327000	2341000	So when you take the ratio of cost to, you know, whatever that design quality is, and these numbers are arbitrary, understand like you can substitute your own numbers if you really want to, but the effect will be the same.
2341000	2356000	You get cost over quality of human architect kind of rising steadily because, you know, the quality is what it is, that's the standard, and costs are rising, you know, slow rate inflation, something like that.
2356000	2359000	But the cost over quality of AI is dropping.
2359000	2366000	So the quality is getting better and the cost is coming down, which creates this very, very sharp curve towards the bottom.
2366000	2376000	And that creates a whole different set of problems for architects because all of a sudden, you're not choosing between these two cheapo clients, you've got a different dynamic.
2376000	2385000	Now you've got a position where a client can reduce the quality of design by 10% and achieve a 50% reduction in cost.
2385000	2393000	And that becomes a lot more seductive than I think potentially disastrous because we don't want to design this 90%, right?
2393000	2397000	We want like the best design to be out there in the world.
2397000	2405000	But as you make it more and more attractive by hacking the cost 50%, 80%, 90%, I think it's going to seduce a lot of people.
2405000	2411000	Alright, myth number four, AI won't be a threat in the future because of something it can't do now.
2411000	2413000	We've heard a lot of this, too.
2413000	2421000	So from Kermit Baker, the chief economist of the AI, AI can't pour concrete, paint a wall, or install flooring.
2421000	2428000	Momentarily setting aside the fact that it actually can pour concrete and paint a wall and install flooring.
2428000	2431000	It does all those things today.
2431000	2438000	So we can think about this whole thing a little bit more abstractly in terms of what AI is going to do in the future.
2438000	2441000	So AI is growing exponentially.
2441000	2445000	What that means, what rates, we don't know.
2445000	2456000	It's not necessary for this illustration, but you've got AI growing at an exponential rate in terms of its learning, its capability, everything that it can do, etc.
2456000	2463000	AI's grow at a linear rate, which is probably not a big deal if you're over 50.
2463000	2474000	So if you're an architect and you're pretty senior, it probably fuels that speculation that you have that AI can't actually compete with your knowledge and skills because it can't.
2474000	2482000	Like not now, probably not ever because you're going to retire prior to the point where AI ever gets to that level.
2482000	2494000	So the skills that you have after 40, 50 years of practice remain valuable today and will probably remain valuable for the next couple of years or 10 years or something like that.
2494000	2499000	And that's probably why older architects seem to be a lot less concerned about all of this AI business.
2499000	2502000	But the picture is different for senior architects.
2502000	2520000	So some of them 10, 15, 20 years of experience, they're going to have their growth cut off at some point by, you know, this red wall of AI growth and AI will grow to the point where it assumes the capabilities that senior architect actually has.
2520000	2532000	That senior architect never really gets a chance to ascend to the level of professional maturity and skill set that the principal architect did because their progress is essentially cut off.
2532000	2547000	Much bigger problem for a recent grant because someone who's graduating architecture school today has to look at the possibility that as they're out there and they're trying to build their skills and their capabilities, you know, they're cut off.
2547000	2555000	They've got a few years in the profession, maybe 10 before the capabilities of AI exceed their own capabilities.
2555000	2568000	So they'll never get to that skill level that the prior generations have because by the time they do, AI will be better than they are at the task of architecture.
2568000	2583000	And it's hugely problematic if you're a child, you know, if you're a 16 year old and you're thinking about going into architecture, you're not going to get there for at least another, you know, six, seven, eight years.
2583000	2591000	You're not going to be licensed for another 10, 12, 15 years. And by that time you've come in underneath the growth curve of AI.
2591000	2601000	So all this discussion about what AI can do today as a measure about what it can do tomorrow, I think is a false profit.
2601000	2609000	You know, we need to be looking at the growth rates of AI and understand what it's going to be able to do in the future.
2609000	2617000	And here in argument, I think, you know, well, AI is not going to be a threat in the future because it can't do this thing right now.
2617000	2621000	I would just set it aside because it's relatively nonsense.
2621000	2626000	All right, final myth, we'll just do more projects.
2626000	2632000	This is also mythological because it violates basic laws of supply and demand.
2632000	2638000	And I'm going to illustrate this with golf clubs, because I think golf is an urban crime.
2638000	2644000	By the way, apologies to anybody who does. So let's imagine a golf club market and you have three suppliers, right?
2644000	2650000	And they all produce about 20 golf club sets per quarter.
2650000	2658000	This creates an overall industry supply of 60 golf clubs, golf club sets per quarter, and the demand is also 60 golf club sets.
2658000	2662000	Perfect supply and demand like in balance, right?
2662000	2669000	Now, what happens when supplier B comes upon a technology that allows them to triple their production of golf clubs?
2669000	2673000	They're producing 60 a quarter while the overall supply goes to 100.
2673000	2676000	But then what happens to the demand?
2676000	2680000	Does it also swell to meet that supply?
2680000	2682000	No.
2682000	2690000	I mean, very rarely with very specific things does demand rise to meet supply that almost never happens.
2690000	2697000	One scenario is that supplier B puts their competition out of business and just gobbles up all of the work as may happen in architecture.
2697000	2705000	As, you know, big technologically advanced firms adopt this new technology faster and just decide to, you know, take over everybody else's business.
2705000	2712000	I think the more likely scenario is that all of this extra golf club sets go in the trash, right?
2712000	2716000	Because there is no market to actually absorb what they're doing.
2716000	2718000	This is the key thing.
2718000	2720000	The demand is fixed.
2720000	2730000	Just because you produce three times as many golf club sets doesn't mean that, you know, people are going to go out and buy three times as many golf club sets because how many do you need?
2730000	2736000	Like people are not going to spontaneously start playing golf because you've produced all these extra golf sets.
2736000	2746000	And I think that's the problem with a lot of this thinking around design is that, you know, just because we can do the design a lot faster and produce more of it,
2746000	2749000	doesn't mean that people want more of it.
2749000	2754000	The demand for design services is fundamentally driven by the demand for buildings.
2754000	2759000	The demand for buildings is driven by all these things, but it's also related to the money supply.
2759000	2765000	So the money supply and the demand for buildings combine to create the demand for design services.
2765000	2774000	And this has no relationship to anything that's going on within the AC world, the software we use, how fast it is, like whatever dynamo scripts you've written.
2774000	2778000	So none of that influences demand at all.
2778000	2781000	Maybe in some very, very peripheral ways.
2781000	2792000	But the point is that, you know, our work as designers as architects is trapped between like the money supply, the money that coming in, the demand for buildings on the demand side.
2792000	2797000	And, you know, what we do inside doesn't fundamentally change either of those things.
2797000	2805000	So if you produce 10 times as many coffee makers, it doesn't mean people need 10 times as many coffee makers.
2805000	2811000	If we could produce 10 times as much design, doesn't mean people need 10 times as many buildings.
2811000	2820000	And that is the fundamental constraint that I'm most worried about is people think, oh, well, we're just going to do, you know, more and more work.
2820000	2823000	We can't, there's not a demand.
2823000	2828000	There's no way to sort of justify all of that extra work.
2828000	2835000	So let's wrap this up by looking at the brighter side of disaster. I love teaching disaster because I think disaster is fundamentally optimistic.
2835000	2838000	And we have thousands of years of history to prove it.
2838000	2851000	Ever since our ancestors started utilizing floods on the Nile River Delta to kickstart the policy and, you know, invent civilization, humanities has really productive relationship with disaster.
2851000	2858000	Lisbon 1755 suffered earthquake tsunami and a city white fire at the same time.
2858000	2862000	They all kind of caused each other one earthquake caused the rest of it.
2862000	2868000	But anyway, very, very tenuous time, you know, the seeds of the enlightenment were there.
2868000	2870000	But it happened on all scenes day.
2870000	2879000	So a lot of the very religious people in Portugal were saying to themselves, oh my God, we didn't pray enough and that's why this is happening.
2879000	2884000	Let's, you know, return to religious fundamentalism and all this stuff.
2884000	2892000	And the course of history was changed by the Marquis de Pombo, who basically drove the response to this particular earthquake.
2892000	2897000	Now the earthquake, fire, etc. already had become well known throughout Europe.
2897000	2905000	It had influenced a lot of thinkers because it provoked a question, you know, this horrible, horrible trifecta of disaster happens on all Saints Day.
2905000	2909000	Does that mean that there is a God or does that mean that there is no God?
2909000	2914000	And like what should we actually be doing about this condition?
2914000	2921000	So Marquis de Pombo leaned in the enlightenment direction and we should thank him for it.
2921000	2933000	So he developed early approaches to seismology and horses, riders on horses go out in radial directions and interview people about the length of the shaking and what happened and everything like that.
2933000	2944000	And when he started to establish an epicenter, he created the Pombo lean style or had it created, which we still use today in many parts of the world.
2944000	2955000	So I've ever seen this kind of construction like that really became popularized after this this Lisbon earthquake at the direction of the Marquis.
2955000	2974000	Well, generally speaking, kind of jump started the enlightenment, right? I mean, this was a huge historical event told us like when an act of God happens, we can respond with design, you know, we can actually design that particular disaster away and protect ourselves in the future.
2974000	2986000	Nowhere has this ever been more evident than the city wide fire and it's an old memory. But we used to have those all the time, right? Cities which is burned to the ground.
2986000	2998000	And that was it. London, of course, in 1666, Chicago in 1871, Baltimore, 1904, San Francisco in 1906.
2998000	3010000	We used to have cities would like burn to the ground and now it's inconceivable that anything like that would ever happen. It's tough to even imagine how that might happen. So what changed?
3010000	3024000	The Triangle Shirtways Company fire in 1911 was a horrible fire and a tragedy that inspired a public outcry which in turn sponsored provoked legislation about, you know, new building codes, new ways to design buildings.
3024000	3032000	Fire sprinklers, emergency exit doors, having alleys, you know, this sort of thing.
3032000	3044000	And, you know, I love telling this story because, you know, it's an example to me of the way that urban planners and architects and engineers quite literally designed a disaster out of existence.
3044000	3052000	And, you know, our cities exists today because we adapted to that particular disaster.
3052000	3066000	And I said that disaster is fundamentally optimistic because it is because we have a chance of deciding what to do. So, you know, is the future of our detection AI apocalypse, I think it just depends on what we design.
3066000	3079000	So apologies for running a bit long, but thank you to everyone, and especially to my hosts, and love to start a discussion.
3079000	3087000	Yeah, that was fabulous. Really fabulous, and don't apologize for taking so long.
3087000	3104000	I think what, I mean, some of those notions I've kind of had before, but I've never been a systematic in investigating them through the lens of, you know, much more kind of like a structured analysis.
3104000	3110000	I think it was, it was really very, very instructive.
3110000	3131000	I just, there are a number of things that come up. I think that what I think what it points towards, I mean, the emphasis seems the background concern was the issue of cost that seems to be the driver in many ways, or the primary concern, certainly as far as the client
3131000	3145000	is concerned. And it kind of in some senses echoed the Susskin's work on what's going to happen in the future in terms of the professions and the primary driver of change is going to be economics.
3145000	3159000	People just want to get cheaper and cheaper and cheaper. And that is always kind of in a way, I think there is a background condition that makes us as a profession architects very vulnerable.
3159000	3171000	And that is the lack of concern about cost. I wrote a long time back a book called The Anesthetic of Architecture, which is about how we tend to see things through a rose-tinted lens and just see them in terms of their beauty.
3171000	3182000	And that rinses out often concerns about socioeconomic, political, environmental disasters, whatever. It just rinses that out, and we just look at it.
3183000	3198000	And I mean, whatever. I mean, you could think about looking out over the Pacific Ocean and seeing this kind of pink mushroom cloud, which is clearly a kind of nuclear explosion, the French testing out their nuclear weapons over at Bikini et al.
3199000	3210000	And look at it and say, wow, what a beautiful pink mushroom cloud kind of thing. And that is, I think, that is kind of endemic with the problem in some senses of architecture.
3210000	3224000	We see things and say, wow, isn't it beautiful? And the client was thinking things about how much it costs. And the classic kind of issue is you come up with a design and my chair at Cambridge would come up with this as argument.
3224000	3234000	And the client would say, but how much does it cost? Don't worry about that. If you get this, you'll get a beautiful building. And the problem is that is really the issue.
3234000	3246000	The aestheticization runs through the architectural culture. And I think it also affects architects themselves in the sense that we are so happy doing beautiful designs, we don't worry too much about our own pay.
3246000	3270000	In fact, we've got no say over that, really. There's nothing to to effectively protect fees, nothing at all. And so that becomes the kind of the crucial issue. And I think you're absolutely right in pinpointing or at least it seems to me the core of your argument was really about economics, about cost, supply and demand.
3270000	3286000	And I totally agree with your golf club's kind of analogy. There are going to be no more buildings required. So don't assume that you're going to be employed more in the future.
3286000	3290000	Anyway, maybe I'll just put that comment in there if you want to.
3290000	3305000	I agree. I would refine it a little bit and I'll tell you a story. I practiced architecture for five years commercially before going to graduate school and I went to do my master's in architecture and an MBA.
3305000	3314000	And of course, as a young architect, we were always talking about cost because clients were always beating us over the head, like, this costs too much, this costs too much.
3314000	3331000	And I adopted that common sentiment among architects that architects care about the building, the design, and clients care about the cost. And then I went to business school and it's just kind of like rapid fire, doing case studies and everything like that.
3331000	3339000	And no one ever talked about cost. And I was like, what the fuck is going on? Because I thought I would go to business school and we would just be talking about this.
3340000	3351000	And I think that's where I developed my sensibilities about value. Value being the difference between what something is worth and what something costs in there.
3351000	3368000	And, you know, we make decisions about what we buy based on the differential, right, you know, the relative value of two things. So when you go out to buy shoes, you know, you don't buy like the best pair of shoes that's ever been invented.
3368000	3379000	You don't buy like the least expensive shoes that's ever been invented. You look at that. And I think that to what you said about the sort of viewpoint difference between architects and their clients.
3379000	3386000	That gets amplified because, you know, from an architect's perspective, the cost is immaterial because they're not paying for it.
3386000	3397000	The worth of the building is very much tied up in its aesthetics. So, you know, we want it to be beautiful to us because that is good for us.
3397000	3408000	But the worth and cost equations are completely different for the client. One, they're paying the cost. And two, you know, the worth is it encompasses things other than just aesthetics.
3408000	3419000	I mean, there's rental payments from tenants. You know, there's tax like, you know, I mean, there's all sorts of other things going on. But I think that, you know, you're absolutely right.
3419000	3430000	And thank you for bringing up Suskin too. You know, they've been hugely influential in my work as well. Because, you know, fundamentally, you know, you may love architecture.
3430000	3441000	You may be the best architect in the world. But when alternative technologies create a solution that is 90% is good, but 10% of the cost, like that, that's all she wrote.
3441000	3447000	I mean, like 99% of clients are just going to flock over there. And you would do the same thing, you know.
3447000	3456000	Yeah, I would just add to that that I think that the questions of aesthetics, we assume that everyone shares our aesthetic. We assume that.
3456000	3473000	But actually, they don't. I mean, I don't know. I've got a relative who I had a pair of Nike yellow shoes and I went into the Sahas office and Patrick said, Where did you get those? I want a pair of those.
3473000	3484000	And I got some flak when I went to one of my relatives homes. What are you wearing yellow shoes for? You're not a teenager anymore kind of like, you know.
3484000	3499000	I think this is something that is and it's actually in some senses. So we assume everyone's going to share that aesthetic and they, they, you know, I think, I would say that postmodernism has meant that we kind of more aware of appearances and so on, I would say, but on the whole, no one actually
3499000	3513000	quite shares that same aesthetic. And to my mind, this was the tragedy of the Bauhaus in some senses that they thought they would transform society, give the modern citizen what they wanted.
3513000	3529000	But the problem was it was, it was expensive. You know, it was, you know, if you go to the Bauhaus now in Dessau, you'll see all these beautiful kind of whatever they are, designer objects, or you find them anywhere, you find them in museum shops all over the world and fine if you've got the money to pay for your
3529000	3545000	start lemon squeezer or whatever, but actually, you know, it's actually expensive. Whereas Ikea, and I think there's a lot of lessons for us from Ikea, they produce something that actually did what Adolf Los claimed he wanted to do by reducing the
3545000	3561000	ornament, you save on costs and produce something that is much cheaper. Of course, there are other kind of smart factors they introduced, I mean, flatbacking things, allowing you to assemble themselves and, and all that out.
3561000	3573000	But this means that Ikea is now populating the living rooms of many, many people, but not because of the aesthetic, because of the fact that it's going to be cheaper and that's the best way to do it.
3573000	3585000	So you do actually, and maybe you do begin to influence people's taste and they say I quite like Ikea or whatever, but you do it through a fundamentally different mechanism, I think that is absolutely central to how we operate.
3585000	3595000	So I, I really appreciate that and the layered way that you address the question about cost itself.
3595000	3607000	Let me just say, if anyone's got any questions, please put them in, so we've got a YouTube audience, we've got a Zoom audience, the YouTube ones that you can put in there into the chat and we can relay them here.
3607000	3624000	I wanted to pick up on on something which I thought was, I mean, maybe as a way of kind of not just my work, but maybe something you could add into the mix and that is to say there was a recent study that was done by essentially a group of
3624000	3640000	sociologists from Harvard, MIT, and the guy called Ethan Mollick who is from, I think, UPenn, was also part, he's an AI expert, I think he's at the business school there at UPenn.
3640000	3656000	Anyway, they did a study on a consulting group, Boston Consulting Group, and what they were doing was attempting to measure, now we don't know how to measure these things, but sociologists do, to measure the impact of using AI.
3656000	3668000	And they were able to come up with some result, they were able to quantify it in some way, and I think this is probably the first of many studies, I'm sure there'll be a lot of them.
3668000	3688000	And of course they weren't necessarily dealing with the design as such, although that was vaguely included in their study because they asked this group to suggest a new line of footwear,
3688000	3702000	responding in some way to whatever, no, dot, dot, dot, another line. And so it was kind of creativity in very loosely was part of that thing. They were using chat GPT to study this thing.
3702000	3714000	But what they came up with, I think was really, really interesting, was a series of quite significant factors and there is this very crude graph that Ethan Mollick has published online.
3714000	3722000	The whole thing was published as part of a Harvard Business School journal, but he made his own graph and so on, which puts it very graphically right up.
3722000	3735000	And he says, and what they found basically, in the study, using AI, it was a group using control group, using AI versus a control group, not using AI.
3735000	3750000	And those that were using AI finished 12.2% more tasks, so they achieved more. What's more, they completed those tasks at 25.1% quicker.
3750000	3759000	Now, I guess you've got to multiply those to get the real impact. You're doing more tasks and you're doing them quicker. So the overall impact is actually more significant than that.
3759000	3766000	And they also came up with the figure, which I think is difficult to evaluate, but it was 40% better quality.
3766000	3777000	Now, that's anyway, you put those together, those three factors are quite significant. And as you say, it's a question really ultimately the task.
3777000	3786000	And to something that I do, I mean, that is a factor in the sense that there are those differences between certain tasks and others.
3786000	3792000	For example, your comparison must be the task and the job itself or the profession.
3792000	3807000	I think that renderers are in a lot of trouble right now. There are a number of tools out there you put in a sketch. I mean, famously, Tim Foo was using look X and he put in a crumpled piece of paper and looked at it and produced a Gehry building,
3808000	3820000	based on that, and each one was, and you can do that now. So, so I think certain, clearly, there is a differential in there, one has to take that into account.
3820000	3836000	But very, very significant, and it will be interesting to find out what that figure was. I once was talking about this as with one of the developers AI soccer, I would mention her name, but she once said, and she wanted to attract it.
3836000	3849000	Some person using AI could achieve as much as five, not using AI. And I, it's a little bit of a, and she was worried about that information getting out there because it might put off people from using AI.
3849000	3859000	But nonetheless, there is, there is a significant difference in what you can do. So I don't think the quality necessarily is going to be that important in terms of aesthetic, shall we say.
3859000	3870000	Although, I mean, I think that you can judge quality in other terms. And I think these are really hugely significant factors. And we need to do a study, I think, in architecture for that.
3870000	3872000	Let it go.
3872000	3875000	I mean, okay.
3875000	3885000	Any, any, any, any pops, I've got a few more, a couple more points. We'll open up. We've got some questions coming in from that from from YouTube as well. So, but, yeah.
3885000	3905000	So, anyway, I think there's, there's, there's the concern that's kind of connected in some way to, to, to, to all those issues. The one thing that I think that I would question about your approach and, and, and, well, I don't mean critical but I think one,
3905000	3918000	maybe suggestion. And you mentioned the law of diminishing returns and that's course was Kurtz while what he followed and a lot of people are following on from Moore's law.
3918000	3931000	Now, for those of you don't know Moore's law, Gordon Moore was an industrialist who was made a comment. It wasn't the law as such but made a comment back in the 60s on observation shall we say that that in terms of circuit boards,
3931000	3944000	the number of conductors, the transistors on the circuit board would double every two years and the price would come down by half, which meant that this was exponential change.
3944000	3957000	So, if it's, if it's that factor, you would be considered going one, two, three, four, five, you'd go one, two, four, eight, 16, and there's a huge difference between five and 16.
3957000	3969000	It's exponential change and that has been applied more recently to these large language models and I want to mention those again in a second because I think these are absolutely hugely significant.
3969000	3984000	And Pishai, the CEO of Google, made the comment that these large language models are increasing in their capabilities, going faster than Moore's law, and that was the comment he made.
3984000	3994000	I don't think that Moore's law is relevant in this context because it's tying it to some kind of production and the kind of economics.
3994000	4003000	Now, the key question when it comes to capabilities is, in my view anyway, the speed of learning, the speed of learning.
4003000	4013000	Now, this is something that Geoffrey Hinton comments on and Geoffrey Hinton is known largely as the Godfather of AI.
4013000	4023000	Certainly he was the one who was promoting, who was working on neural networks and what we call now deep learning at a time when that approach was out of favor.
4023000	4030000	It wasn't working, everyone abandoned it in favor of a different logic, symbolic AI based on logic and so on.
4030000	4035000	But really all it required was a change in terms of the technology.
4035000	4046000	And as soon as we got GPUs invented and suddenly the capabilities of computers and the speed of computers was vastly, vastly increased and these neural networks worked.
4046000	4048000	So that's a background to him.
4048000	4057000	But he has made the comment recently and he's been in the news because he resigned from Google in order to sound a warning.
4058000	4067000	And his warning basically, or part of his warning, was the speed at which computers could learn.
4067000	4079000	Because the way that it works, he said, and I need to look into this further, is that it shares information with a thousand other computers at once.
4079000	4086000	And I don't know why he mentioned a thousand, not a million, whatever, but it shares information with a thousand computers at once.
4086000	4090000	Whereas if I'm sharing information with you, it's a one on one.
4090000	4093000	But a thousand to a thousand others.
4093000	4096000	Now, that somehow reminds you of COVID in some senses.
4096000	4101000	If you share COVID, the key issue was what they call the R-Ratio.
4101000	4104000	If it was more than one, be worried.
4104000	4109000	If it was less than one, you're kind of okay because the spread is going down, whatever.
4109000	4112000	Now, we never had an R-Ratio of a thousand.
4112000	4114000	Now, I'm not even sure if that figure is correct.
4114000	4116000	But this is the real problem.
4116000	4122000	It is the capabilities of these large language models that is exploding.
4122000	4128000	And it's exploding at a rate that we cannot even conceive.
4128000	4131000	Maybe I'll just throw that out to you, Eric, and see what's going on.
4131000	4133000	Sure, sure. Let me react to a few things.
4133000	4140000	First, the diminishing returns diagram and the thread there.
4140000	4145000	That's not actually, that's irrespective of AI or no AI.
4145000	4149000	You know, the diminishing returns is just an economic phenomena that exists either way.
4149000	4152000	So that's separate.
4152000	4154000	The Moore's Law thing, yes.
4154000	4160000	And we need to get the word out about that because I think there's still people who think that Moore's Law is relevant.
4160000	4163000	It's not, things are moving much, much faster than that.
4163000	4167000	I mean, Kurzweil puts it at a double exponential or triple exponential.
4167000	4174000	I mean, these are growth rates that are very hard for people to understand, like intuitively.
4174000	4176000	And I don't mean like people other than me.
4176000	4179000	I mean, I have a hard time, like the human brain has a hard time.
4179000	4181000	Here's a benchmark that I always use.
4181000	4186000	Stanford's whatever annual AI survey that they do.
4186000	4202000	They put the doubling of artificial intelligence capability, rolling in, you know, algorithmic development, advances in cloud computing, like all the things like the raw capability of AI, doubling every four and a half months.
4202000	4208000	Now, if something's doubling every four and a half months, that's a million X in seven years.
4208000	4217000	So when people say, hey, you know, AI is like, there's nothing to be afraid of insulting that AI could actually like, you know, ape the performance of a human designer.
4217000	4218000	I agree.
4218000	4228000	I'm like, yeah, you know, at this point, but do I believe that an AI that's a million times more powerful than what we have today might be capable of designing a building.
4228000	4229000	Yes.
4229000	4230000	Yes, I do.
4230000	4233000	And I'm very, very concerned about it.
4233000	4241000	So, yeah, I mean, I think that, well, you just deconstructed another myth, Neil, you know, this myth around Moore's law.
4241000	4257000	I think we have a responsibility to kind of get the word out that some of this, some of these polyanish positions are based on, you know, data and ideas that are actually outdated.
4257000	4259000	I think I'll just throw that back at you.
4259000	4264000	I mean, I love that video, the 24 minute video.
4264000	4267000	But it struck me that it doesn't have to be 24 minutes.
4267000	4274000	And I base this on, I mean, it's what you're doing basically is you're recording a conversation.
4274000	4281000	And which and you're, you're showing it between these, these AI agents and.
4281000	4292000	The 24 minutes space is basically taken up in showing them talking to one another, whereas actually the speed of the operations could be pretty instantaneous.
4292000	4301000	Now, I was alarmed by the, what we now know as large language models and their speed of operations.
4301000	4312000	Several years ago, in the world of AI, one of the great moments when we kind of a wake up call it was called a Sputnik moment.
4312000	4319000	When Sputnik basically was a wake up call for the American, the Americans in the space race and let the foundation of NASA.
4319000	4326000	I mean, holy shit, the Soviets were suddenly sending a satellite to orbit and America was nowhere near that.
4326000	4327000	And that was a wake up call.
4327000	4330000	So in terms of your kind of like, there's something good that comes out of it.
4330000	4333000	Well, NASA came out of that particular moment.
4333000	4340000	Anyway, this particular game, it was, and we were not, it wasn't really on our radar because it was a game of go, a match of go.
4340000	4342000	And we don't really play go, but they do in Asia.
4342000	4352000	And there was this match AlphaGo developed by DeepMind of London versus Lisa Doll, who was kind of this followed on from the Gary Kasparov chess match.
4352000	4355000	And he was the kind of Gary Kasparov, shall we say, of go.
4355000	4357000	And AI trounced him.
4357000	4361000	And that was the wake up call for all go playing nations.
4361000	4370000	And the Chinese immediate president, she said, okay, by 2030, we are going to catch up with the Americans and overtake them and so on and so on.
4370000	4376000	So that was kind of like a hugely sort of significant moment in sort of in wake up.
4376000	4380000	But the more important one was something that wasn't really mentioned at all, which was a follow up.
4380000	4385000	And the follow up was this was the next model of AlphaGo, which is AlphaGo Zero.
4385000	4390000	But first of all, it wasn't documented, it wasn't on TV and whatever, but it was, it went out on our radar.
4390000	4393000	But that one, it beat AlphaGo 100 games to zero.
4393000	4394000	Right.
4394000	4396000	That's better.
4396000	4404000	But the important thing was it learned to do things without being trained to do so.
4404000	4406000	It was not taught the rules of go.
4406000	4411000	And this talks about the emerging capabilities, which we should come back to in a moment.
4411000	4416000	But the other aspect of how it looked, it was playing games of go against itself.
4416000	4421000	And I think the total was 4.9 million over four over three days.
4421000	4422000	Yeah.
4422000	4423000	And that sounds like a lot.
4423000	4425000	That sounds like a lot.
4425000	4427000	But the real point is, it is art.
4427000	4432000	I mean, you go down to it, you know, it's basically it's 20 games of go per second.
4432000	4434000	Now that is very, very significant.
4434000	4435000	It is weak.
4435000	4436000	It's mind boggling me fast.
4436000	4437000	Yeah.
4437000	4440000	And I would say, and I didn't know why it took so long, frankly.
4440000	4443000	I mean, how could you even take, you know, that much.
4443000	4449000	So my point would be with that video is the actual calculations were pretty instantaneous.
4449000	4452000	And it wasn't 24 minutes of calculations.
4452000	4456000	I mean, that was what it took to show the operations happening in terms of discourse,
4456000	4460000	shall we say, but the calculations were pretty instantaneous.
4460000	4462000	And that really is.
4463000	4464000	Anyway, that was what it might be.
4464000	4468000	My comment on the video, which I thought was a fabulous video anyway.
4468000	4470000	No, I mean, I think you're right.
4470000	4475000	I mean, it's, you know, there's something evolutionary about it, right?
4475000	4477000	You know, we just, we have trouble.
4477000	4481000	The human brain has trouble like kind of wrapping our heads around, you know,
4481000	4483000	exponentials and these sorts of things.
4483000	4487000	So, you know, we got to support each other and like check each other and say, like, yeah,
4487000	4490000	that whole 24 minute video could have been under a second.
4490000	4495000	You know, if it was just two AIs, you know, talking to each other and designing a building
4495000	4497000	or something like that.
4497000	4500000	In my own writing, I refer to this as the million monkey problem, right?
4500000	4503000	Where we've all heard that adage about, you know,
4503000	4507000	if a million monkeys were banging on a million typewriters for a million years,
4507000	4510000	would they at some point write, handle it?
4510000	4513000	And, you know, maybe you think, yes, maybe you think, no,
4513000	4517000	but a billion monkeys working on a billion typewriters for a billion or a trillion.
4517000	4520000	You know, those are the scales that we're into now.
4520000	4526000	So, yeah, I think we need to be very, very concerned.
4526000	4533000	And it's interesting that you brought up the Go match because that was one of my initial inspirations
4533000	4537000	getting started on this project because, you know, there were architects in the ether who were saying,
4537000	4539000	no, like, you can't compete with architecture.
4539000	4541000	Architecture is just like too complicated.
4541000	4545000	And like, you know, AI is like beating world champions ago.
4545000	4549000	It's doing protein folding, you know, it's solving all these like cancer research problems.
4549000	4552000	And, you know, architecture is plenty, plenty complicated,
4552000	4556000	but I'm not sure that it's more complicated than everything, you know,
4556000	4560000	like it's not like the last thing that that AI is going to figure out.
4560000	4563000	So, yeah, yeah, we got a big job.
4563000	4567000	Yeah, no, so one more point for me and then we'll open up to the other questions in the audience.
4567000	4569000	But, you know, I absolutely totally agree.
4569000	4574000	Also, you're picking up on what are called emergent capabilities or emergent abilities.
4574000	4578000	I think these are things that are hugely significant.
4578000	4584000	And I was intrigued by what you discovered in terms of what AI had learned how to do, you know.
4584000	4591000	So just to say for those who don't know, I mean, I'm not sure if the term emergence is intended to be taken the way that I've taken it.
4591000	4598000	But I, in my work years ago on swarm intelligence, and I came across the term emergence,
4598000	4604000	which is about that Steve, that John Holland initially kind of written about as a kind of principle,
4604000	4612000	whereby things start emerging out of any multient system that are unpredictable and not expected.
4612000	4619000	And classically, you think about a flock of birds in the way that it produces this area, acrobatics.
4619000	4626000	But it's also been taken more recently to apply these to these mysterious abilities that go back to that alpha go zero.
4626000	4629000	It taught itself to play go.
4629000	4636000	And, you know, that the right that that was when the alarm bells should have been sounding because now we're discovering through these large language models.
4636000	4639000	It is developing similar capabilities.
4639000	4642000	It can learn languages and translate.
4642000	4643000	That is pretty astonishing.
4643000	4648000	It does it. It does it actually. I mean, emergency stuff is kind of a rather mysterious thing.
4648000	4649000	And we can observe it.
4649000	4651000	We can't really explain it scientifically yet.
4651000	4654000	But nonetheless, we can see this thing happening.
4654000	4657000	Now it can learn to translate and it can learn to write code.
4657000	4659000	Oh, that's that's very.
4659000	4660000	That's huge.
4660000	4661000	Yeah.
4661000	4669000	So I got a friend from college who was who used to run the biggest translation agency in the world.
4669000	4675000	And he sold his company two years ago because he could see that I was going to be able to do it.
4675000	4687000	And I've been exploring that myself in terms of the translation of some of my books and it's incredibly cheap, very fast, even with a human editor to come in and go and check all the things and so on.
4687000	4696000	So there's there's there's that but I mean, it's so it has this capacity to do these things and I claim that it's very imperfect moment.
4696000	4701000	And I would claim though that there are moments in which it has learned how to design.
4701000	4712000	It seems to have learned that the rules of composition in the sense of mid-journey and Dali, particularly mid-journey, it's coming up with some pretty impressive designs, not everyone.
4712000	4715000	I mean, about only one in about 50 is really good.
4715000	4719000	But nonetheless, it is surprising that it's doing those things.
4719000	4729000	I could only assume there are a lot of other things that we don't know what it's doing, but it's doing, you know, it's looking at the data and understanding systems and putting them together.
4729000	4739000	I actually put this question to when you heard yesterday, I said, Well, what about I mean, could it not also learn how you do the plumbing or how you do, you know, other aspects of architectural design.
4739000	4745000	And she was saying, well, the difficulties, the three dimensions, that's when errors start creeping in.
4745000	4748000	And it's, it's fine with language.
4748000	4751000	I mean, language, it doesn't matter too much of your slightly out.
4751000	4752000	There's a lot of tolerance there.
4752000	4755000	But with architectural drawings and things, that is the challenge.
4755000	4756000	It's not there yet.
4756000	4763000	But I do think I do think that these emerging capabilities are, I mean, they're fascinating.
4763000	4770000	And they don't sound particularly interesting, not indeed to large language models, but they are extraordinary.
4770000	4780000	And just one final point for the audiences, the large language models, they, they get these abilities, not through the sophistication of the code, because the code is quite straightforward.
4780000	4786000	It's based on the size of these things and the larger they get, the more they seem to manifest these things.
4786000	4788000	So I was just intrigued.
4788000	4794000	Maybe you'd like to comment just briefly again on, on what you discovered it was able to do that you had never predicted.
4794000	4796000	Yeah, you want to hear the wildest?
4796000	4798000	Yeah, yeah, yeah.
4798000	4808000	I mean, the windows and the bathrooms and the constant, like that, that surprised me, you know, that it was able to kind of get all of that right.
4808000	4820000	The biggest thing that I did not put in the presentation was that I did find that it had some kind of 3D spatial world building capability.
4820000	4834000	So after, you know, Carla had designed the house, you know, I drew it out, you know, I drew the floor plans as I would have drawn them based on, you know, what she was talking about and, you know, the local conditions and things like that.
4834000	4846000	And then I described it to chat GPT and said, you know, if I go into, you know, the front hallway and make a left and go up the stairs and make a right, what room am I in?
4846000	4849000	And it was like bedroom.
4850000	4866000	And it would get that right. So in the way that you might communicate it to an unsighted person or something like that, you know, I was able to kind of articulate directions like around the house and, you know, across like multiple floors and things like that.
4866000	4875000	And it would seemingly understand like where it was in, in some three dimensional mental model.
4875000	4891000	So that's an artifact of just like the language. So, I mean, to us, you know, if I described to you a building like over the telephone and said, you know, these are the mentions of the building like you could sit down and draw it out and go vice versa.
4891000	4895000	So, you know, maybe it's not.
4895000	4899000	Yeah, I don't know where it comes from. I haven't figured it out, but it's scared the shit out of me.
4899000	4908000	I'm just, just an aside, I want to go to some of the questions and yeah, yeah, let's do it in a moment. I want to ask Mitra, but just as an aside, I think the obvious point that needs to be reinforced.
4908000	4921000	Traditionally, we are the ones that interpret the verbal instructions of the client and produce an image, which is exactly what mid-journey and dali do.
4921000	4939000	And that's kind of worrying. I don't know. Mitra has got a question. I don't know if you're able to use your microphone and to read it out, or if not, if you can, if you can unmute yourself, or I can read it for you.
4939000	4946000	I don't know whether you, I don't know if you've got a microphone on your computer.
4947000	4955000	I can see you're still muted. Oh, did someone have to allow her to unmute themselves? Okay. Okay, Mitra.
4955000	4957000	Hello, hello everyone.
4957000	4958000	Hi.
4958000	4962000	Hi. Thank you so much for the great lecture.
4962000	4974000	Actually, I have a question about, actually, we have these days we are facing an increase in the use of the social networks.
4974000	5001000	So the analysis of invisibility of the data and social network could be significant. For example, in urban studies, we have the geolocation data, including the GPS or data about connection with local Wi-Fi equipment.
5001000	5018000	So my question is, would it be possible to collect data from social networks for architects? And where is the data stored?
5018000	5025000	Would it be possible to collect data from social networks for what, for design purposes?
5025000	5026000	Yeah.
5027000	5041000	I imagine that's much more of a social and legal problem than it is a technological one. You know, your social networks already know everything about where you are and what you're doing and how fast you're moving and what stores you visit and all those other things.
5042000	5059000	Because, you know, you signed off on a license agreement that allows them to have and use that data. I think in order for architects and designers to use it at other scale, at any significant scale, we'd have to have a similar sort of arrangement.
5059000	5072000	I mean, the idea of a municipality collecting that data on its citizens for use by designers frightened me a little bit because they would almost certainly use it for other things.
5072000	5077000	But I've seen a use to brilliant effect actually in disaster zones.
5077000	5083000	After the Haiti 2010 earthquake, Port-au-Prince was a city of about three million people, sorry.
5083000	5098000	And once the earthquake struck, you know, it destroyed most of Port-au-Prince and, you know, people fanned outward, you know, from the city and then at varying rates started to come back as recovery progressed.
5098000	5107000	And did you sell the main phone carrier there actually had that data as a result of like, you know, having everybody's SIM card in a database.
5107000	5114000	So, you know, we could understand how quickly, you know, people were moving back and into what neighborhoods and this sort of thing.
5114000	5120000	So, I mean, from an urban and from a design perspective, that data is enormously useful.
5120000	5129000	I think we just have to make the case that we should have it as designers and that we can put it into good use.
5129000	5138000	Just to decide, Eric, the, I think the one of your disasters, just maybe you didn't know this, but the Great Fire of London.
5138000	5143000	Actually, it came off the Great Plague, and it actually effectively got rid of the Great Plague.
5143000	5147000	So maybe you had two disasters on one counter to the other.
5147000	5151000	So we've got a number of questions from YouTube.
5151000	5155000	And I think these are separate questions.
5155000	5162000	First is you can see them in the chat if you want to look at them from Mandu Tiger in YouTube.
5162000	5164000	Some excellent points.
5164000	5173000	Unfortunately, another influencing factor for the long term is this rising level of indifference that is poisoning creativity and quality.
5173000	5180000	Two huge values architects provide.
5180000	5187000	Unfortunately, another influencing factor for the long term is this rising level of indifference that is poisoning creativity and quality.
5187000	5191000	Two huge values architects provide.
5191000	5195000	I would say, you know, Mandu Tiger, you're not wrong.
5195000	5202000	There's certainly a surplus of indifference in the world these days.
5202000	5210000	But I will reference my father and probably several debate coaches as well.
5210000	5228000	You know, always advise me never to argue a position that requires that, that I believe or that you believe that my opponent is, is somehow stupid or morally corrupt or ignorant or something like that.
5228000	5231000	Because it's an easy out, right?
5231000	5240000	And I think what I think with architecture has nothing to do with architecture. It's all these other people and the fact that they don't care about this and they don't care about that.
5240000	5243000	That may be true. It just doesn't go anywhere.
5243000	5255000	I mean, it's kind of fatalistic for the profession, if you think about it, because, you know, if you imagine that, that architects are, you know, these passionate designers concerned with beauty and progress and, you know, everybody else is indifferent to such things
5255000	5263000	as beauty and architect, you know, I mean, like, you need a world to pay fees to design things.
5263000	5273000	So, I mean, I think that, you know, when I'm confronted with questions like that, you know, I asked myself, well, how do you, how do you make indifferent people different?
5273000	5278000	Or, you know what I mean, they make indifferent people like actually care.
5278000	5283000	You have to find the ways to speak in their language and to speak to their priorities.
5283000	5286000	That's actually why I went to business school, you know.
5286000	5290000	You know, I went to get an MBA and people thought I wanted to be a developer.
5290000	5293000	I didn't. I never have.
5293000	5299000	But it struck me as a good decision because I wanted to be able to defend our work in their language, right?
5299000	5305000	Because when I was a practicing architect, you know, the whole design team would come up with all these great ideas and everything.
5305000	5310000	And then, you know, at some meeting somewhere, there's some like 30-year-old with a clipboard and an Excel spreadsheet.
5310000	5313000	And it's like, we're not doing this. We're not doing that.
5313000	5317000	And I started to ask myself, well, who's really designing this building, you know.
5317000	5324000	And I didn't have the vocabulary or the skill set to actually argue with that person in their language.
5324000	5327000	So, I went to business school to learn that.
5327000	5330000	So, Mandu, just to tie it off.
5330000	5337000	I mean, I would suggest that you think about the people that you think are standing in opposition to design and ask yourself, like,
5337000	5344000	how do I convince them that design is valuable in their language, you know, with their value system?
5344000	5346000	Great, great point, Eric.
5346000	5349000	I think that just a comment from the U.A.
5349000	5355000	the studio discovered one of the successful ways of speaking to the client in their own language was to diagram things.
5355000	5360000	That would be much more convinced by the diagrams than the designs themselves.
5360000	5362000	Yeah, yeah.
5362000	5365000	So, we have another question from the chat.
5365000	5369000	Again, great, do you get a lot of praise here for this talk? It was a fabulous talk, very good.
5369000	5373000	Great talk, and thank you. I have a question, but I want you to know more about your opinion.
5373000	5381000	Do you think that there are safe havens against the AI and architecture disasters?
5381000	5383000	Are they physical places?
5383000	5391000	Should we, as architects, look for a way to design to make a sound from what AI could do against the profession?
5391000	5393000	Yeah.
5393000	5395000	Yeah, is there a name attached to that?
5395000	5398000	No, there's no.
5398000	5401000	Well, to whom ever asked that question.
5401000	5408000	I think that architects fundamentally need to be thinking about expansion.
5408000	5412000	And I think that exists along several axes.
5412000	5416000	One is a kind of domain expansion.
5416000	5424000	I think there's a great opportunity to actually reclaim a lot of the territory that we seeded during the 20th century to other professions.
5424000	5433000	And we had to spin off interiors and landscape architecture and construction management, owners reps, and all these other things because shit got too complicated.
5433000	5437000	And we also just wanted to spend time designing.
5437000	5444000	And I think it's unfortunately eroded a lot of the authority of an architect in that overall design process.
5444000	5454000	So I think there's an opportunity there to claw some of that back and to say, like, look, with these augmented tools, we can now do the construction management bit.
5454000	5457000	We can do the interiors bit.
5457000	5459000	We can do all these different things.
5459000	5464000	Now, all those other professions are going to be saying the same thing, so we have to find a way to work that out.
5464000	5470000	But ultimately, you know, we can expand in that direction from a domain standpoint.
5470000	5474000	I think geographic expansion is another one.
5474000	5481000	Most of the architects in the world are in places where the least architects are needed the least.
5482000	5489000	The global south is going to need something like, I don't know, like a billion units of housing in the next 25 years.
5489000	5496000	And there's not necessarily like the infrastructure there to support good design for all of them.
5496000	5507000	And I think, you know, maybe technology offers a route to that so that, you know, someone born in a slum in Lagos now has access to good design.
5507000	5513000	What does that mean? How do you accomplish that without, you know, fully like techno enabled colonialist strategy?
5513000	5515000	I'm not really sure.
5515000	5522000	But, you know, through my work, I know like most of the world really, really needs design and they can't get it.
5522000	5527000	So hopefully that is another axis of expansion.
5527000	5531000	The third one I'll mention is actually digital and metaversal.
5531000	5536000	And I'm not a metaverse fanboy by any scrap of the imagination.
5536000	5542000	But I do believe that the metaverse is inevitable that it's coming sooner or later.
5542000	5550000	And that once it does, we're going to need a strategy to marry design strategies in the real world with the metaversal world.
5550000	5560000	So if you're designing for a client like Nike, you know, they're going to have a metaversal store and they're going to have a regular store and augmented reality in their physical store.
5560000	5563000	They're going to want all of that stuff to work together.
5563000	5573000	Right. So how do architects start to think about digital experiences and how those complement, you know, physical spaces.
5573000	5577000	So I mean, I think there's there's lots of that's just three, there's probably some more.
5577000	5587000	But I think there's lots of ways that we can look at doing new things or doing old things or doing unprecedented things that haven't been invented yet.
5587000	5597000	The part that makes me worry, the part that makes me think that we might be in a disaster is architects looking at these sorts of technologies as ways to just do what we're already doing just faster and cheaper.
5597000	5602000	Like that's that's raised to the bottom. Like there's no good outcome there.
5602000	5608000	So I think fundamentally, the safe place is everywhere except architecture.
5608000	5626000	Like, look out, chart new territory, explore new civilizations, design housing for the moon, like, you know, whatever it is, like you got to go out there and use this technology that we've never seen before to do things that we've never done before.
5627000	5631000	I was struck by your video.
5631000	5644000	Conversation should actually would be great to see the whole thing because it was so interesting, but it's out there anyway for those who want to see was actually effectively the architect became the construction manager there he was talking to the to the construction person which is quite unusual.
5644000	5663000	I mean, normally there's a very adversarial role and now increasingly in certainly in the UK, most contracts are designed built and the, and the developers in charge, you know, so we've surrendered that idea that we used to have of being the person that's what the word architect means literally from the ancient
5663000	5678000	30 reminded us the person in charge and we've surrendered that but we could do that and I would also say we could also become the developer I think that's an area that is probably very, very well paid that we could also take over or indeed the person
5678000	5693000	apparently selling the property gets the most money so we will go in terms of costs per hour. So the another question here in the chat from Ren right a Rainville at youth YouTube.
5693000	5699000	Do you have any suggestions on how firms should prepare for this oncoming disaster.
5699000	5705000	He has a second question but let's ask them first. Do you have any suggestions on how firms should prepare for this oncoming disaster.
5705000	5715000	Yeah, I mean I think, well, building on what I said in my last response in terms of like looking outward to do to do new things and impressive things.
5715000	5733000	I think education is critically important at this point, you know, I mean, I, I advise everybody calls me like, do your own homework, you know, read learn something and, you know, I think 90% of the architects read like the same like 10 design magazines like, you
5733000	5749000	don't have to stop doing that but read some other things to, you know, I think most of my perspectives are informed by things that are actually going on in the tech sector and like the AI sector and like that's where I get my intel is like, you know, who's
5749000	5765000	researching new research on machine learning and, you know, liquid neural nets and these sorts of things so that's how I personally keep an eye on what's happening and develop a sense of the future that I can feel comfortable with that, you know, I feel like I understand
5765000	5783000	what might be coming. I think, I don't know, not disparaging any sort of design media but, you know, design could be a very conservative profession, you know, and I think it's the sort of thing where, you know, we're radically adventurous and our work right within the four corners of the drafting
5783000	5803000	I mean, metaphorically at this point, you know, we create whole new worlds and new civilizations and things like that, but then tend to be like conservative about processing environment and like the rest of the things so I think that it would be good to educate oneself and to do your homework
5803000	5817000	and to figure out what is going on outside of architecture because that's where the real action is at the moment and it's inducing a tidal wave that's going to, you know, hit architecture at some point.
5817000	5829000	In terms of, you know, other like more tactical preparation I think that would probably depend on the specifics of, you know, a particular firm or a geography. So, should we go to part two, Neil?
5829000	5837000	Yeah, yeah. Secondly, how best can architects direct the value conversation away from the client cost concern?
5837000	5851000	Yeah, I mean, I think the first step there is to figure out what's your client values. And again, I mean, I think there's, there's an unfortunate, you know, mythology and architecture that thinks, oh, you know, the client only cares about cost.
5851000	5870000	I've had clients like that. I've had clients like that. But clients are people and people tend to be more complex. So I think different clients value different things to varying degrees. So like, that's step one is knowing that.
5870000	5885000	The second part is, you know, don't bring a hammer to a gunfight. You know, I mean, if your client is someone who values like cost exclusively, then you need to find a way to make that argument for value in economic terms.
5885000	5897000	And you say, you know, we want to redo the lobby and don't talk about why from an architectural standpoint, it's going to be better. Talk about like, how you can charge like higher rents or like the cost comes down or something like that.
5897000	5910000	You know, if you're working with a client that cares about some, you know, other social issue or political issue or something, you know, find out what that is and make arguments to people in their language.
5910000	5925000	I mean, I think that's one of the, and Neil alluded to it earlier. I think that's one of the biggest kind of universal mistakes that architects make. We try and convince people to follow like whatever suggestion we're making using the language of architects, instead of their language.
5925000	5928000	And it falls flat.
5928000	5930000	A lot of times.
5930000	5938000	Maybe I said, I don't want to, I'm talking too much, but I just add to that there was, there was occasion in Cambridge once, but there was a disaster.
5938000	5949000	Many years ago, when there was a competition and one of the colleges decided to forget the results of the competition and just go to a builder and they got this really very, very tedious building as a result.
5949000	5964000	But then they learned a different strategy. They discovered that actually if you mentioned you had a big name architect like foster and partners, whatever, it was much easier to attract funding from alumni by saying we have got so and so.
5964000	5973000	And it became on their terms, it made sense it became an economic argument to improve the design so I very much agree with that.
5973000	5991000	So we have James McBennett on on on YouTube, and his question which again is in the chat. Most buildings are not designed by architects, demand of buildings or demand for buildings is far greater than demand for well designed buildings.
5991000	5999000	As the cost of design changes, surely blue ocean strategy in the middle.
5999000	6002000	Yeah, I would absolutely agree.
6002000	6020000	I mean, I think that, you know, my my humanitarian work was largely about bringing design to two communities and to people who otherwise would never have had access to it by virtue of geography or economics.
6020000	6041000	Because I think you're pointing out James like that includes like, you know, most Europeans, most Americans like, you know, architectural services cannot be provided at a cross point, where, you know, it makes sense for someone who is, you know, got a $500,000 house budget to engage with an architect like that's just not going to happen.
6041000	6056000	Yeah, as the cost of design comes down, does it then become possible to provide design services at, you know, the same level of quality but at a lower cost point.
6056000	6069000	You know, I was teasing an architect the other day about creating a digital version of themselves, right, so they could actually like, you know, service service clients, you know, essentially at zero cost.
6069000	6083000	And this sort of thing and, you know, that technology still probably a few years away for, you know, sort of full package solution but, you know, it's a taco watch like all of the ingredients are currently there the technologies exist.
6083000	6087000	And they need to be assembled at some point in order to do that.
6087000	6104000	But I think, you know, I love, I love that idea. I love the idea of like everybody having an architect, everybody getting the benefit. And one of the things that that's fueled my career and the thing that makes me so mad is that, you know, architectures is like great
6104000	6119000	I mean, it's so beautiful, like so many brilliant and creative people and, you know, it's offered almost exclusively to, to the rich to the 1%, you know, and like, we can't, we can't get it out there to everybody else.
6119000	6133000	And that's not because we suck. I mean, it's just because, like, it's, it's a lengthy and expensive process. So I hope that one of the things that, you know, architecture starts to embrace as these technologies unfold and design costs come down as
6133000	6138000	we give design to everybody. Yeah.
6138000	6141000	Actually, James has got a follow up question.
6142000	6160000	By golf analogy, if 2% of buildings are designed by architects, and 2% of golfers can afford a full set of clubs, would more golf golfers justify buying a full set of clubs if the cost dropped dramatically.
6160000	6173000	Okay, interesting. I think what's implied by this question is that there are people running around out there with like, two or three, like golf clubs, but don't have like a full set.
6173000	6180000	So they go and play golf with like a couple of clubs and if the price of a set of clubs came down.
6180000	6183000	They might actually buy the full set. Is that how you read it, Neil?
6183000	6184000	Yes, absolutely.
6184000	6185000	Okay.
6185000	6201000	I don't play golf, so maybe I'm like out of my depth here, but I don't think most people like play golf with just like a few loose clubs. My understanding is that like, you need the full set in order to properly play a game of golf.
6201000	6205000	And if that's wrong, someone in the chat, please correct me.
6205000	6214000	I mean, I think to James is kind of like wider point, if the cost comes down to more people embrace it.
6214000	6219000	Sometimes yes, for some goods, yes.
6219000	6227000	You know, energy is the prototypical example, right? The more energy we make and the lower the cost, the more people consume.
6227000	6233000	And there's some name for that kind of exception to the laws of supply and demand.
6233000	6245000	I think that if the cost of design comes down, people may embrace it further and more people might be interested in utilizing the services of an architect.
6245000	6257000	And the same necessarily applies to buildings, because like, you know, you've got a town of 30, 40,000 people, it needs a hospital, right, or at least like a regional medical center.
6257000	6268000	It doesn't need four of them, right? I mean, we have to have some kind of justification to make the buildings that we make because they're expensive and they take a while and they're complicated.
6268000	6286000	So, yeah, like I could see like a minor expansion and just to play on James's previous points, you know, like homeowners might have the opportunity to, you know, at the scale of a single family house for, you know, half a million dollars actually like work with an architect.
6286000	6294000	On the other hand, you know, that brings in the specter of like a custom designed house of some kind. I don't know how that's actually going to play out.
6294000	6308000	But James, to your point, yes, I think that probably there will be a slight expansion of the market in design services, but it will be constrained by fundamentally by the limits of the building market.
6308000	6329000	There's another question in the chat with no name attached to it. I think that maybe the way we should think about architects within our ecosystem as a researcher, what is our role, what is our role as architects in the loop of research along with computation and big data?
6329000	6338000	Will it help? Sorry, this is not very clear. Will it help us solve problems ahead? Let's read out what he said actually.
6338000	6342000	Yeah, I'm reading it.
6342000	6355000	What is our role of architects in the loop of research with computation? You think that means like the role of architects within the wider field of research on, you know, IT and data and computer science related issues?
6355000	6359000	I think so.
6359000	6371000	Well, I mean, I think, you know, architects have really amazing perspective and an amazing facility with certain skills that lend themselves very easily to research.
6371000	6382000	So, you know, the ability to zoom in and zoom out really quickly and think small scale and big scale and be fluent and fluid between those things.
6382000	6385000	Architects do that better than just about anybody I know.
6385000	6395000	The ability to think about time, right? So, architect is one of those professions where you have to like make a decision today that's like binding for 30 years.
6395000	6403000	And I think we lose sight of the fact that there are very few professions where that's true, you know, maybe medicine or law or engineering or something like that.
6403000	6417000	But for the most part, like, you know, you fuck up at your job, like you've got lots of time to fix it with architecture, like your issues, your decisions get set in concrete, literally.
6417000	6424000	So I think, you know, the mind of an architect lends itself very easily to that sort of thing.
6424000	6434000	I think it's about, you know, integrating with what's already going on. I mean, there's already a lot of research going on into these things.
6434000	6442000	So the question is, like, what is the entry point for, you know, architects who want to be involved in that?
6442000	6449000	I think there's a lot of data issues around buildings and cities that we haven't quite figured out.
6449000	6466000	We spoke about it earlier during the Q&A. But I've had the conversation many times over the past year about data and architects thinking, oh, well, we got all this data, like, from the buildings and, you know, we can use that in some sort of data science way.
6466000	6475000	And, you know, my question is always like, you know, will it use it for what? Like, what data is going to be useful to anyone?
6475000	6485000	If you're talking about data about how people use the design that you made, that seems like it would be the owner's data and not yours.
6485000	6494000	So that's one problem. And if you're using the data from, you know, the designs that you made in the past, might be good.
6494000	6506000	But unless you're like a Gensler or HOK or something or an AEcom, you probably don't have, like, enough projects there to actually build any sort of machine learning data set or anything like that.
6506000	6514000	So, you know, I think architects have a natural role based on their, you know, psychology and their disposition.
6514000	6522000	But I'm not sure what that role is. And I think we'll have to design it.
6522000	6532000	There's another question from Vasco Ashik Vasco on YouTube, who's in Bangladesh. You should know that you've got an audience all over the world today.
6532000	6533000	Awesome.
6533000	6549000	In AI driven architecture, how do you tackle worries about losing human centric values and cultural nuances, especially in post disaster reconstruction where community identity is crucial?
6549000	6565000	Yeah, and I'm reading the follow up comment, which I agree with, I would argue that a lot of buildings have already lost a human centric value. It did not take AI, it was modernism and effects of industrialization, post World War II prefab and building without ornament.
6565000	6572000	So Ashik, I think that's a great question, Ren. I think that's a great answer. And similar to the one that I would have offered.
6572000	6583000	Yeah, I mean, I think, you know, architecture loses human centric values all the time. And I think that's one of the reasons that a lot of people don't appreciate architecture because, you know, we spent 40 years making
6583000	6602000	artificial architecture and, you know, kind of turning our attention away from the problems that people were actually dealing with in their lives. So, I mean, I think that, you know, how do you correct for that problem? How do you introduce human centered thinking?
6602000	6616000	And my advice is always like, spend time with humans. You know, we, we don't always appreciate I don't think just how insular architecture is as a profession and how weird that is.
6616000	6628000	You know, we take someone when they're 19 years old and we put them in studio. And frankly, a lot of architects never come out, you know, like mentally like they stay in studio for forever.
6628000	6638000	And, you know, they come out, graduate, they know how to walk like an architect, talk like an architect, they, you know, have cool glasses and wear black and this sort of thing.
6638000	6647000	But they don't necessarily like have human beings at the center of like whatever their design ambition is.
6647000	6661000	You know, in my work, like it's impossible not to, you know, you can't, you can't go into a community of friendly loving people who are having a hard time and say like, okay, like I'm just going to ignore all that.
6661000	6677000	I mean, not unless you're some kind of monster, I guess, but yeah, I mean, the point is, the point I'm not trying to make. I think I'm advising you to one, like spend more time with with people.
6677000	6690000	And, you know, to appreciate the fact that we don't have much human centeredness to begin with. So maybe paradoxically, AI is the way that we find it.
6690000	6702000	You know, I'm sure some of you have seen the same studies that I have where, you know, they measure the responsiveness of a human doctor and, you know, a medical chat GPT like, what is it?
6702000	6707000	You know, they call poem one or something, the Google one, the medical one.
6707000	6723000	And, you know, the respondents like drastically prefer interacting with the robot, because it's perceived as being like more caring and more attentive and it has, you know, infinite time and my doctor comes in to see me and like 30 seconds later, you know, he's gone like to do with another patient because
6723000	6741000	some is looking stupid like that. But, you know, maybe this tool like retrieves some of our humanity by, you know, giving us time to be human and giving us time to to sit with patients and to sit with clients and things like that.
6741000	6745000	So, yeah, I don't know that felt like a rambling response.
6746000	6747000	It's a tough question.
6747000	6764000	Rambling responses, Eric, fabulous. I just made me to follow up on that in a way. I mean, I had this last semester, I asked my, instead of asking my students to go and write essay, I got them to ask to do a video, but they went, I think, to chat GPT and got this.
6764000	6773000	I think, I think you're right, because in your article, you mentioned the fact that the chat that chat GPT has been conditioned to respond in a certain way.
6773000	6789000	And if I mean, I always go back to chat GPT is like, what, do you really mean that? And it kind of is open. Well, not really. But I mean, so, so, but the kind of responses that seemed to they seem to be getting was feeding into their videos was, well, AI lacks the empathy.
6789000	6792000	It doesn't have the empathy of human beings.
6792000	6799000	Now, I'm not sure that empathy actually in design necessarily makes a better design. I'm not sure about that at all.
6799000	6807000	But what I would say is that that discussion you had in your video and I really would recommend everybody to have a look at that discussion.
6807000	6814000	It was absolutely fabulous. They were much more polite than any human being was astonishing.
6815000	6819000	Yeah.
6819000	6836000	I mean, it's, it's fascinating because it's, you know, it's a customizable intelligence, right? So, you know, whatever chat GPT generally is, you know, if you needed a situation that that if you had a situation where you needed the empathy dialed up to 11,
6837000	6852000	you could do that, right? And, you know, if you had some sort of alien intelligence designing buildings in Bangladesh and shout out to Bangladesh, by the way, I went to a conference there about seven years ago, one of the best weeks of my life.
6852000	6867000	If you had, you know, an alien intelligence designing something, you know, you could pre-program that with like, you know, let's keep the colonial influences to a minimum and like not cover Bangladesh with, you know, international style architecture
6867000	6877000	and this sort of thing, like whatever you do has to, you know, honor the traditional building practices and materiality and form making like present in Bangladesh architecture.
6878000	6894000	You know, I mean, these models currently are overly programmed with Western influences, which is predictable because like they were created in the West, but I'm optimistic that that AI is capable of overcoming that problem and learning new tricks.
6894000	6906000	No, I totally agree with that. I mean, I think one of the big issues people talk about AI is the bias, you know, and the bias, of course, comes from us. I mean, it's from the data that we're producing, and it's been replicated in AI.
6906000	6916000	And you could recalibrate any machine learning system, as you say, to get rid of that, but humans will always have that bias. So I completely agree with that.
6916000	6928000	Yeah, it's not algorithmic bias. It's our bias. And, you know, that's another myth. I mean, we sometimes look in the mirror and we don't like what we see coming back at us. So we blame the technology.
6929000	6941000	Yeah, I mean, just go look at Google. If you go to Google and say, and Google Nurse, you will get women, female figures. And that's, you know, it's absolutely, that's there.
6941000	6959000	But just, I want to just pick up on this a bit, a bit more, because you kind of hinted that you thought, in your article in your videos, well, you thought that there was the check TPT being programmed to be a bit soft on certain questions.
6959000	6972000	I mean, I've noticed that with, you know, is AI going to affect employment? And it says, no, not at all. You know, it's going to be assistant and so on. Do you think it's been, it's been conditioned or framed or programmed in a certain way?
6972000	6982000	I mean, we get with, for example, with, with mid journey, the aesthetic that comes out, isn't just in the data, something that's been framed in a way. What do you think?
6982000	7000000	I mean, I think the most alarming thing is that we, we, no one may know the answer to that question. You know, I mean, if you take, you know, Altman and Brockman and the rest of them at their word, like, they don't actually know what's going on inside the black box, right?
7000000	7020000	They don't know how these, these LMS are actually working and putting this stuff together. If that's the case, you know, what level of control do they have over how, how the model is, is worked, you know, is there a switch that they can flip and say, okay, you know, make chat GPT mean now or make it nicer.
7021000	7029000	I assume they have some level of control, but they probably don't have as much control as we wouldn't like them to have.
7029000	7042000	And I think, you know, that's, that's terrifying as well as exciting is, is that we're dealing with something that is growing, and that is learning to some degree, like, on its own.
7042000	7053000	We're trying to have to nurture that intelligence so it doesn't kill us. Because, you know, if we don't do it the right way, we may encounter a problem.
7053000	7070000	I mean, clearly there are, there's some things going on with chat GPT so I don't know if you've caught these articles but like, you know, the latest thing seems to be like, if you ask chat GPT like really nicely or you sound desperate, like it gets more cooperative.
7070000	7083000	Like, we're right in a prompt that says like, hey, I need to write a report for my boss and I'm going to get fired, like he'll be right this thing, like it does a better job than it would if you just like asked it to do something.
7083000	7098000	Or, you know, it gets lazier towards like the end of the year that was a story that came out in December, because it's imitating us and because, you know, people do, you know, unless work gets done in December, I mean it's kind of global phenomena.
7098000	7114000	So, yeah, I don't know. I mean, there's, there's two terrifying possibilities, one that a small number of people at a private corporation have entire control over how responsive GPT is and in what way.
7114000	7124000	And the other terrifying possibility is that no one has any control. So, you know, strap in. It's going to be an interesting time.
7124000	7131000	Yeah, this has been great. I don't ask us those in the zoom conversation if they've got any questions they want to ask this stage.
7131000	7134000	I don't know how do you want to ask one.
7134000	7142000	Yeah, Neil. Hi, everyone. Hi. Hi, Eric. This was a great talk and actually great discussion really really enjoyed it. Can you all hear me well this is a new microphone.
7142000	7146000	Anyway, okay, wonderful.
7146000	7159000	Just picking up on the on the last remark, you may Eric, I was just watching before this I was watching a lecture from Jeffrey Hinton at MIT, a recent lecture.
7159000	7175000	And Hinton, I think as much as people like, you know, Joshua Bach takes, I think takes the position that ultimately humanity is kind of transitional, whatever that really means but I think Hinton would take the point that
7175000	7190000	we might have to come to terms with the fact that we are, we are going to, well, I guess, replacement is not the right word, but there is an evolution and there may be beings in the future that are smarter than us, and
7190000	7206000	maybe humanity as we know it today is not going to be around forever in a certain way. And I was thinking, I was thinking of apocalypse and disaster and maybe timescales and what qualifies as disaster.
7206000	7223000	I suppose within within a kind of timeframe, like, would that be would that is that do we think of that as a kind of as a kind of disaster or as a kind of apocalypse, they thought that we as we know ourselves today.
7224000	7236000	You know, may, may not exist in some kind of future. Well, I guess we know that for some distant future, right, but maybe this is the point is going to would be, I could be closer than we are actually thinking.
7236000	7255000	And I was actually wondering if that if, you know, if we think of design practices that are that we would, you know, we might think of as like more than human or like designing with and for other forms of being and other forms of intelligence.
7255000	7279000	And that actually in a sense contains in itself, a sense that humanity, at least is is sort of is sort of changing. And if that is, I don't know, if that one could seek could think of as also relating to a kind of, I wouldn't say disaster but I kind of a, a,
7279000	7285000	Yeah, I'll leave that I'll leave that open. Just curious to hear your thoughts on this. I think I hear what you're saying.
7286000	7304000	And I think the words that Elon Musk had used to describe that phenomenon was describing humanity as a bootloader for an artificial intelligence right like we were the pain that that then loaded up the thing that that lasts to eternity.
7304000	7325000	And whether or not it's a disaster I think is is a philosophical and perhaps a spiritual issue. I mean, I think it has special relevance for architects because I gotta assume that that part of the joy of being an architect is making something bigger and more permanent than yourself.
7325000	7339000	You know, if you're really invested in your design, you're taking something out of yourself and you're putting it into the world in the form of steel and concrete and, you know, it's going to be there hopefully after you're gone.
7339000	7346000	And, you know, it will stand as this sort of, you know, memory of of you.
7346000	7371000	It's intrinsic, I think to the process of creation, like we all seek to create things that might outlast us. So in the case of, you know, AI and humanity, you know, I've had this conversation with myself and say, you know, look, if we're ultimately the fate of the human race, that we, you know, essentially gave birth to this, this alternate intelligence that
7371000	7384000	you know, fanned out like across the cosmos and did all these wonderful things. Would that be bad? Like, would that be a history that we would be ashamed of as human beings or dissatisfied with somehow?
7384000	7395000	And I wonder, you know, what, how it relates to the process of parenthood. I don't have any children so I'm speculating and hopefully no parents in the audience get mad at me for doing so.
7396000	7411000	You know, when you have a child and you raise up that child, if that child goes on to do things that transcend you, you're not mad, like, you're not like pissed at the kid, because you are part of its success.
7411000	7429000	You know, you can look at the ways in which that child has transcended you and gone beyond you and be proud because that has a lot to do with what you did as a parent, you know, like that's your creation that's transcending you and in most cases outlasting you.
7429000	7453000	So, yeah, I mean, I, you know, is there, is there generally speaking the future for humanity? Yes, I think so. But I think even in the event that there wasn't and that the ultimate story of planet Earth is that there are a bunch of dinosaurs, they died, and then there are a bunch of animals, and one of the animals got really smart and invented a machine intelligence.
7453000	7465000	You know, then that became the thing that lasted forever. I still think that'd be a pretty good story, you know, I mean, assuming we create the right kind of successor to whatever our time has been.
7465000	7472000	So, nice. I appreciate the question. I appreciate ending on some, you know, really slowly.
7472000	7487000	Thanks, Eric. Yeah, I mean, we could go on, I guess, for another two hours on this question, but it's it's super interesting. And yeah, wonderful. Thanks for this. This is, I'm guessing we've already gone for two hours and something. So, yeah.
7487000	7492000	Neil, we have, I don't know if Smora wants to ask questions, one final one for Smora.
7492000	7511000	Yeah, I would just like to ask whether you think this type of, let's say somewhat negative speculation about the future taps a little bit into the unconscious mind and it makes us feel as humans that there's something to worry about to care about for the future.
7511000	7529000	Or like, it has a psychological effect to it because I think people are very much drawn to this type of disaster thinking it's all over the news. It's a little bit of a different realm, I think, of thinking and speculating about it.
7529000	7541000	I think I understand the phenomena you're speculating on, but can I be clear about the question? Are you asking me whether that that is that negative speculation is a good thing or like where it comes from?
7541000	7565000	Yeah, I mean, because so far it feels like it has all been like with negative connotations, the whole talk. And I'm just asking whether it has for you as a writer, as an architect, is it something that you do consciously or is it just how you see things or do you feel like people are more drawn to this type of speculation?
7566000	7578000	Yeah. I mean, it's not a marketing gimmick. It's not, as far as I know, you know, some latent psychological trait. And I don't consider my message negative.
7579000	7589000	You know, for me, disaster is fundamentally a positive thing, because there are a lot of things that don't happen, frankly, until we have a disaster.
7589000	7599000	So, you know, we needed the fire of Lisbon in order to have the enlightenment, like we needed the city fires in order to develop building codes.
7600000	7611000	Human beings are funny that way, right? I mean, Churchill said something about, you know, Americans can always be trusted to do the right thing after they've exhausted every other option.
7611000	7628000	And I kind of feel the way about people generally in response to disaster, you know, I mean, they'll just watch that dam and they'll see crack and crack and leak and leak and leak and not do anything until like the dam collapses, but then they'll get their ass and gear and actually do things.
7628000	7645000	So, you know, in my work and in my teaching and my lecturing and, you know, the things that I'm doing related to AI, it's not morbid, in my opinion, like it's not intended to be, you know, hey, let's get together and commiserate about like the awful future.
7645000	7659000	It's a proposition that if we can acknowledge that something really bad could happen and we could agree on that, then that's the first step to us getting together and making something really good happen, right?
7659000	7668000	That's the moment where we can all get together and say, hey, the dam's about to collapse, let's evacuate people, let's design a dam, let's do all these things.
7668000	7672000	And indeed, that's the way that it's always been with human beings, right?
7672000	7676000	Things have to get really bad before we do really good things.
7676000	7691000	And I think this AI business specifically as applying to architecture, you know, my hope is that more architects can look at it and say, holy shit, like this thing is coming from my job and, you know, half of all architects are going to be unemployed in five years.
7691000	7693000	What should we do instead?
7693000	7705000	Right. And, you know, don't leave and like go sell real estate. Well, I mean, sell real estate if that's your passion or something like that, but let's initiate a collective conversation about what architecture is going to become.
7705000	7716000	And, you know, how are we, what are we going to design next, you know, now that machines have taken over all the construction documents, like, what, what can we do?
7716000	7734000	And I think there's just, there's enormous possibilities, you know, climate change is bearing down on all of us and it needs solutions and some of those solutions are the sort of solutions that, you know, architects should be at the head of the table, if not at least in the room or something like that, you know, we need to be engaged with those sorts of things.
7734000	7747000	And smart, my, my worry is that with the, I keep calling them Polly Anish, you know, maybe that's a little bit too harsh, but with the really, you know, positive messages, people go back to sleep, right.
7747000	7756000	And they say, okay, you know, so-and-so at the AIA or Reba said, you know, AI is not an issue, I'm not going to worry about it.
7757000	7765000	Those are the people that are going to hurt, hurt most, because we tend to prepare for the disasters that we see coming.
7765000	7768000	And we tend to be unprepared for the disasters that we don't.
7768000	7774000	And if you prepare for a disaster that's coming, then most of the time it doesn't actually become a disaster, right?
7774000	7779000	So, like, you solve the problem ahead of time, so the disaster just never materializes.
7779000	7785000	So, yeah, that's also kind of a rambling answer, but I think your question is an important one.
7785000	7795000	I don't see my work as negative, you know, I mean, I think we have to be brutally honest about the wolf at the door before we start doing the really positive things.
7795000	7800000	And I think that's why I have the message that I do.
7800000	7804000	And that was a fabulous answer, Eric, and a fabulous answer to end on.
7804000	7812000	I always think that the, from my background in critical theory, the point about critical theory and problematizing things was actually the idea was to improve something.
7812000	7814000	You pinpoint a problem and then you'd improve it.
7814000	7826000	But also critical theory was a technique that certainly I tried to employ to bring into the architectural domain that was otherwise a kind of self legitimizing kind of discourse, some critical tools that were absent.
7826000	7838000	And I thought what we did, what we saw today was a really fabulous demonstration of bringing some critical tools into the debate about architecture, tools that we were otherwise previously unaware of.
7838000	7844000	And I thought they were very, very powerful to kind of burst that bubble and expose some of these issues.
7844000	7847000	And I think this was really an astonishing presentation.
7847000	7851000	I think, you know, cutting through all the myths that we have in architecture one by one.
7851000	7854000	I think there are a few more by the way.
7854000	7856000	That's part two.
7856000	7858000	Well, we need to have a part two at some point.
7858000	7863000	I think Gary, this is really, I think, was one of the most productive things because it was completely unexpected.
7863000	7865000	And I think this is exactly what we need.
7865000	7870000	Someone coming from a different angle and asking tough questions.
7870000	7882000	Because without that, we are going to be, and I have to, when you mentioned sleep, I have to say that one of the comments that chat GBT threw back at me was the thing that otherwise we will be sleepwalking into oblivion.
7882000	7886000	And that struck me as precisely the warning that you were giving.
7886000	7888000	We need to wake up to this.
7888000	7891000	Otherwise, we will be sleepwalking into oblivion as a profession.
7891000	7893000	But I also agree with a potential optimism.
7893000	7897000	No, there are ways in which we could adapt, absorb these tools.
7897000	7903000	But we need to engage them now to prevent the disaster rather than once the disasters happen.
7903000	7905000	And I think this is the very, very clear message, Eric.
7905000	7907000	This is absolutely fabulous.
7907000	7911000	And I think everybody, every single, every single student of architecture,
7911000	7920000	especially because you pinpointed something I never read this before, that actually it's those who are younger, who are more at risk, need to listen to this.
7920000	7922000	Everybody needs to listen to this talk.
7922000	7924000	It was absolutely amazing.
7924000	7926000	Thank you so much, Eric.
7926000	7928000	Thanks for having me, y'all.
7928000	7929000	This has been great.
7929000	7932000	And I hope we continue the discussion.
7932000	7933000	Yes.
7933000	7939000	And I just want to thank also the Digital Futures team, especially Michael and so on, for putting it, it's like an iceberg.
7939000	7941000	There are a lot of people working on this behind the scenes.
7941000	7955000	And just to mention briefly that Michele and I are working on another series that's going to start on the 18th of February on architecture and philosophy as part of the Doctoral Consortium.
7955000	7969000	And we're now kicking off the rest of the years, the years presentations about for Digital Futures itself, and including it's going to be a series on AI plus, which is about AI being applied to different domains and so on.
7969000	7973000	But this was so, so helpful, Eric.
7973000	7975000	I want you to write a book on this.
7975000	7977000	This is really very useful.
7977000	7980000	Incredibly useful.
7980000	7987000	I'm going to take a look by a lot for it. So thank you so much. Thank you to our audience and thank you to those questions.
7987000	7990000	Amazing, truly amazing. Thanks so much.
7990000	7991000	Thanks everyone.
7991000	7992000	Thank you everybody.
7992000	7993000	Thank you.
7993000	7994000	Thanks everyone.
7994000	7995000	This is great.
7995000	7996000	Great.
7996000	7997000	See you soon.
