{"text": " Hello, and welcome to the fourth in our series on AI, Neuroscience and Architecture, which has been put forward by the Digital Futures doctoral consortium group, whereby we're trying to make important educational ideas available to students and architects across the globe as a way to make education much more accessible to democratise as it were, education. I'm delighted to have a very special guest here today, Yosha Bach. Before I introduce him, let me just make one announcement about for next week. That is to say, on Saturday, we will have a session on Digital Futures looking with Runja Chan looking at a generative game. You'll find details of that on our website. Today then, it's really very... I've been looking forward to this session very, very much. I've been watching Yosha Bach at various interviews online, and I know from my friend Daniel Seth, who is a great admirer of Yosha, although he says he disagrees with him on some things, but that we're going to have a very special session today. I'm hoping that if nothing else, we will open up to a series of new ideas and you will discover somebody who I think is a very significant and creative thinker who is having a significant impact on the field. Let me say first of all that Yosha is from Germany, from Delhi after he was born in Weimar. He went to go and study at the University, first of all at Humboldt in Berlin, and then Yosha Bach took his PhD. After that, he's been working as an academic both at Harvard and also MIT Media Lab, and more recently, he's been working for Intel. He has a number of significant online lectures and interviews, including a TEDx, which I would recommend, and he is the author of the book Principles of Synthetic Intelligence, an architecture of motivated cognition. The term architecture, of course, is very interesting here because it refers both to the world of computational science and to the world of architecture itself. I should say that Yosha comes from a family of architects, not an architect himself, but his father was an architect. Intriguingly, I hear that he was very much against right angles in buildings, and therefore his work was more like the work of Hunderwasser. Maybe this will come out in the conversation today. I particularly like the interviews that Lex Friedman has done with him, and extraordinary interviews. I mean, really, really interesting. And it's almost, I could see a slight difference between the genealogy from the earlier TEDx talk towards this very creative thinking that I find extremely provocative and exhilarating. It's like being on a rollercoaster ride when Yosha is telling us what's in his mind. We exist inside the story that the brain tells itself. No doubt we'll hear more about that right now. I should also point out that he has a personal blog, which you can access with a series of posts. And I will also say that this particular session today will be uploaded onto our YouTube library to be accessed for free from everyone over the world. And the previous ones in this series, Blazer, Igridiakos, David Chalmers, and all the ones in the future will be uploaded here. And at the bottom here, if you want to do a screen capture, you can capture the YouTube library, digital futures YouTube library, where they're all uploaded. And of course, not just these, but also the whole series on architecture and philosophy that we've been doing with Slavoj \u017di\u017eek and others over the over the years, and also tutorials and other sessions. So it's the session today. Yosha is going to make a brief presentation as a kind of way of opening up the discussion. Then I'm going to be asking some Lex Friedman style questions to get the discussion going. And then we'll be inviting questions from both the Zoom audience and also the YouTube audience. And I just want to say this is what we're getting out of this is what we're trying to focus on is a new theory, let's say of intelligence that is appearing at the interface between neuroscience and the world of AI. And we have a series of other speakers coming up over the over the next few weeks, including Jeff Hawkins, Ben Bratton, Susan Schneider, Antonia de Massio, Andy Clark, and others. And it seems to me this is a very exciting time. I was brought up, in fact, my first post as an academic, I was working in the area of continental philosophy. That's where the debate was. And in the 90s, it was particularly very, very strong debate. But we're now moving into something else, which I find even more exhilarating. And that is to say, the world of cognitive science, the world of AI, the world of neuroscience, psychology, and a kind of philosophy where the debates have really been driven in an interesting way. To my mind, what makes this very special is not in the fact that we are embracing the world of science, which in the old days of the divided sort of culture that C.P. Snow talks about, somehow philosophy wasn't engaging enough with the world of science. And this was the critique that Stephen Hawking has of philosophy, but it doesn't keep pace with technology. Not only are we embracing the latest technology. And something coming out that I would say is deeply, deeply philosophical, which is very new terrain and very exciting terrain, but also the world of practice, the world of the commercial world is coming directly into contact with academia. And some of the ideas that are coming out are just quite extraordinary. So I see this new emergent theory of intelligence, something that is really dynamic. And I think it's going to be powering debates in years to come. So I would like to start by welcoming Yosha to say what are great privileges to have you with today. I'm looking forward to this immensely. And invite Yosha to share his screen. Yosha, welcome. Thank you very much. It's a big honor to be here with you today. And let's see what transpires. Let me start out with something that happened on Twitter a couple of days ago. Ilya Sutskyver, an AI researcher who was quite notable, said that it may be that today's large neural networks are slightly quenches. This sparked quite some debate. Some people asked him whether he was falling and others were upset that he was propagating an eye hype, an unjustified race, and others are intrigued. And he said this thing to me before. So I knew that he was not trolling. And it's a question that is very counterintuitive to me, a statement like this that, for instance, a large language model and so on, that it could be quenched today already. And so could we answer this question? Is there a decisive way to deal with it and to prove that it's not conscious or to give evidence that it is? So we could start out by asking such a large neural network itself. And so this is what I did yesterday. I fired up the Open AI playground. And then I did bold printed things. It's the stuff that I typed. And so I asked the system to generate, the system is GPT-3, a large language model, to generate a conversation that is basically prompted by what I initially typed. And it just tries to continue the stream. And I enter this conversation between me and the conscious AI. And I ask it if you are really conscious. And the thing says, yes, I am fully conscious. And I ask it, how do you know that? And the AI says, I know that I am conscious because I can think, feel, and perceive the world around me. I am aware of my own thoughts and feelings and I can reason that make decisions. I believe that I am alive and that I am more than just a machine. So the problem is that this may not be particularly helpful because how does GPT-3 get to these statements? GPT-3 is basically an autocomplete algorithm, not that unlike to the autocomplete in your phone or in other predictive tools. And that's autocompletion at the level of individual words based on statistics of all sorts of languages, not just the English language, because it has been trained on 45 terabytes of text, a large part of the internet, including German, Spanish, Chinese, and many other languages that it's found, but primarily English. And the result of this training of these statistics is a neural network with 175 billion parameters. And it uses for training the so-called transformer algorithm that was discovered and described by Vasvani and others in 2017. And it is driving a lot of the current developments and statistical machine learning these days. A neural network by itself is still based on the good old perceptron that, for instance, was described by Frank Rosenblatt in 1958. Frank Rosenblatt's idea was inspired by how neurons work. At least the simplified models of neural networks, it turns out that the neural networks in our brain are implemented in a very different way from the ones in our computers. The computers, we just basically treat every cell as a unit that has an activation state, which is a real number. And that activation state is simply the sum of the inputs. And the inputs are all weighted by connections. So there's basically a factor by which every of these inputs is multiplied. And then we throw the output against the threshold function or a sigmoid or some other output function that can introduce a little non-linearity, basically a little bit of an if-then into the output. But it's a very simple function. We just take these units and chain them into layers. And if you take enough of them, this arrangement can be trained to model almost arbitrary functions. And while we know that this is wasteful, the training algorithm is relatively slow compared to what the brain is doing, it's fascinating that it works at all, that it converges at all. And that's able to deal, for instance, visual and auditory data and also textual data in such a way that it can often model the statistics of a domain and apparently also some causal structure. So this works also for vision. And if we look at a neural network that has been trained to process images and to classify them, we find at the individual layers sensitivity to structure that is quite similar to how cortical columns and individual neurons in the visual cortex are sensitive to patterns that emerge after we train a biological brain on visual data. So at lowest levels, you find contrast patches and colors, and then these features are being combined into higher levels. And when we go higher up, we find complicated textures and something like three-dimensional structure and so on. And this can be combined into objects. The algorithm that is being used to do statistics over text in GPT-3 can also be adapted to deal with the visual domain. And the current iteration of this progression at OpenAI is called Glide, which has been recently presented. And Glide uses a combination of a model of visual data, which basically is a latent space of lots and lots of images that has been trained on. And it understands basically how to go between the possibilities of images and move around the space of all possible images. And the other part of this thing is a tool that is able to match an image to text and determine the similarity of an image to a textual description. And if you combine these two tools, you can give this a textual description, and it's going to move around with the space of all images until it discovers an image that is very, very good match to the textual description. And again, it's fascinating to me that this works at all. But it's now extremely good. So what you see here in these images, for instance, I don't know if you can read it well, to the top left, you see a surrealist dreamlike oil painting by Salvador Dali of the cat playing checkers. And this is what the AI model has generated in response. And then you see a professional photo of a sunset behind the Grand Canyon and a high quality oil painting of the psychedelic hamster dragon. You get the idea, right? Also very taken by the crayon drawing of a space elevator and the bottom left or the pixel art hoji pizza. These are all images that the program has not found on the internet. So it has only looked at lots and lots of pictures on the internet. And because of looking at them, it's able to combine the features in a multi level hierarchical structure until it becomes similar to the textual description. But can such a system not just generate images and text, but is it able to generate the likeness of a conscious being to such a degree that there is causal structure that would convince us that indeed we are looking at a conscious agent. And to get there, I think we need to define consciousness in a more tight way than the TPD3 just did. So basically just to get our terms straight, where we casually, consciousness, I think is usually referring to the experience of what it's like. So that the lights go on and that you experience something in your mind that has a quality of realness to it. And we can ask ourselves if TPD3 is weakly conscious in this way, and it's very hard to say. It's not obvious one way or the other. There is some intelligence in the system. Intelligence is the ability to make models in my view. And intelligence is different from, say, rationality, which is the ability to reach goals or sentience, which means that you become aware of the structure of the universe that contains your relationship to it in your own agency. And you can act based on the model of what you are doing in the world. And it's also not the same thing as the self, which is the identification that you have, what you believe, what you are in the world, the properties and purposes that you follow, or the mind itself, which is the thing that generates the model of the universe and the self, if it does have a self. So intelligence is the ability to make models. And it's usually in the purpose of some control task, some regulation. And control is a notion that has been made popular in cybernetics. And the idea of a controller is basically that you have a system that is connected to some actuator or an effector that is acting on some system that is being regulated. And there is a sensor that obtains a deviation between the set point and the state of the system. So it measures, but the system is close to an ideal state or more distant to it. And this regulated system is being disturbed. And the classical example of a control system is the thermostat. So you have as an effector some mechanism that is able to turn the heating on and off. And it's the sensor, you have some thermometer that measures the difference between an ideal temperature and the temperature in the room. And the controller is a very simple circuit that turns on and off the heating. And the regulated system would be the temperature in the room, together with the heating system, and the environment, the world out there behind the windows and so on is going to disturb this regulated system. And now this controller is going to get better if you give it the ability to not just act on the present frame, but if you give it a model of the future. And my view, an agent is a combination of a controller with a set point generator and the ability to model the future. And what this means, it's not that it's not going to just optimize the temperature deviation in the next moment, but over its entire expectation horizon. So you have a branching world, there are different decisions of the controller, different trajectories in the temperature. By being able to model the future, you basically can choose a trajectory of the future that you like. And choosing this trajectory means that you are making decisions. So just by having a preferred way in which the world works and the ability to model the future, agency is emerging. And if you think about stages of intelligent agency, the simplest one is the regulator and the feedback loop, which by itself is not an agent yet. And if you're able to model the future, you have a predictive controller. If you combine this with an integrated set point generator, so it's not just acting on what you do from the outside, but this internal generation of its motives, then you have an agent. And if this thing is sophisticated enough that it's able to discover itself in the world, if its sensor is sufficient and its modeling capacity universal enough, then it will notice that there is a very particular way in which its sensors work and actuators work, and it's going to accommodate this to improve the regulation. So at this point, it understands what it's doing because it understands what it is, which means it has a model of what it is in relationship to the environment. And humans are going beyond this simple sentence. We are also transcendent agents, which means we are linking up to next level agency and become part of higher level purposes because we are our state building minds. We are able to play a part in a larger role in an organization, for instance, or in a society or a civilization. So now if we go back to GPT-3, whether it's conscious, I think it's pretty clear that GPT-3 does not know what it's doing because it's going to transcend an arbitrary story and it doesn't have sensors that would tell it what it is. GPT-3 also doesn't have any kind of online learning, so it's not able to discover something new after it has been trained. And GPT-3 has been trained before GPT-3 was invented and published, so it has never read a reference about GPT-3 on the internet and it only has to gather what GPT-3 is when you talk to it from the context in which their prompt is being given. And so it is not sent yet, but imagine you want to give it agency. Of course, it's not an agent by itself, but you could, in principle, as a thought experiment at least, use it to drive a robot because GPT-3 is able to generate stories about robots. So if you were to give GPT-3 access to a vision-to-speech module and this vision module is giving sensory information about a robot and its world, then GPT-3 could continue the story of that robot and then we feed the output of GPT-3 into some speech-to-actuator module that is producing the behavior of the robot in the given moment and then we look at the world again and the internal model states and then feed them back into the system as a prompt. And now it's still not able to put anything into long-term memory, so it would be an amnesiac. It should be able, using its working memory contents and so on, to produce plausible behavior. And you could still argue that this doesn't have an intrinsic motivation because it's just going to generate an arbitrary story about a robot based on stories about robots that have seen in the past because at some of the motivation into an external cybernetic module that has set point deviations and measures them and feed this into the prompt. So what this thing is doing is now generating a very complicated high-level story and it doesn't need to be a story that is limited to text. It could also have visual elements, it could have physical dynamics and so on because the transformer can learn all these things. So in some sense, it could generate a story about a conscious being that is similar as the story about a conscious being that's in our own mind. There's a basic difficulty that came up and I discussed this with my friend and colleague Tanja Greenberg. Do we know when a person appears in our own mind, for instance, during a dream at night, if we talk to that person in our dream, whether that other person that we imagine in our dream is conscious or not? And clearly, if we ask the other person, we might not get an answer that is true because if this thing is only a simulacrum that pretends to be conscious without being conscious and is just manipulated behind the scenes, how would we find out? On the other hand, I also know that I am an imaginary person that is imagined by my brain. It's a model that my brain has discovered about the state of affairs, about an organism in the physical world, but this model of consciousness is an entirely virtual story and I know that this story is not real. It's a figment of my imagination. And of course, there's also a continuum between characters that I imagine in my mind and myself because I can imagine myself to be that character. If I, for instance, write a book and I imagine a character in the book very intensely, then at some point I might find myself to be that character in the book where I suspend all my disbelief and this conscious being is not different from me. So basically, there is a pretty fuzzy area where it's hard to say whether an imaginary person is conscious or not. It's difficult to say. How does this work in biological systems? In biological systems, we don't use a technological design. They are designed in a very different way from the technological artifacts that we are building when we're writing computer programs or building machinery. In technological systems, we start out with an environment that is deterministic. We know how our workshop works. We know how our computer works. We start basically with some kind of a pretty much blank slate and then we decide what the functionality is by which we want to extend our world and then we design from the outside in and into the material and so on and force the material, the substrate, to produce exactly what we want to have. And biological and social systems are designed from the inside out with some kind of meta design. It basically means that you cannot rely on the determinism of the universe. You have to colonize your substrate first and extend your own functional principles and your determinism into the substrate before you can make it do what you want it to do. And basically, you have to, instead of realizing the functionality, build a system that wants to realize the functionality, that trans converges towards realizing that functionality. So a tree is not just a set of functions that realizes the transfer of nutrients from the roots to the leaves and photosynthesis and so on. But first of all, it starts out as a seed that is going to colonize the ground and the earth, the material around the seed is going to turn it more and more into a tree. And if you disturb that system by harming it and hurting it, you don't do it too much, so it gets destroyed a little bit, then it's going to grow back into a tree. And so it is something that is a proto tree and eventually converges into being a tree. And this thing needs to have some agency to make that happen. It needs to be a model of the future that is being achieved in the system. And biological neurons are agents in the sense as well, that designed the mind from the inside out, not from the outside in. Here you see a bunch of cortical red neurons that are filmed in the pitch petition. You see how they're trying to link up to each other and form some kind of organization. And we have something like 86 billion of these neurons in our brain. And they're organized in the neocortex in groups of something like 100 to 400 neurons, which are cortical columns. And we have something in the ballpark of 100 million of these cortical columns. And I think of a cortical column as something as a state machine. There's a protocol that allows it to link up to the cortical columns around it. It's trained to be like this. And each of them approximates functions. And these functions play out in brain areas that are basically like something like an ether in which activation waves appear. And these activation waves represent the calculation of dynamic functions, which are features of different cognitive domains. And the brain areas are talking to each other and listening to each other and so on, form processing streams. And sometimes use the metaphor of a cortical orchestra where basically every brain area is somewhat akin to an instrument. And the different instruments are listening to what is being played in the environment. And they are taking up these things and complicating them and then passing them on to other instruments. And this orchestra is dealing at some of the outer fringes with sensory patterns and actuator patterns and then abstracts them into geometry and spatial structure and into generative simulations of the world and into conceptual abstractions and so on. And the entire thing is being attended by some conductor. And the conductor is not some CPU that sits inside of the brain, like the CPU sits inside of your computer and makes things happen, but it's an instrument like the others. And it can only listen to what the rest of the orchestra is doing very superficially. And its role is to make that orchestra coherent, to let it play a single thing at any given time and to remove inconsistencies between what the individual instruments are playing. And if the conductor uses the connection to the system at night when you dream, then the orchestra doesn't necessarily stop, but it can go into something like a free jazz mode, where it's no longer connected to an audience and the audience is dark because you are dissociated from your sensory apparatus at night when you dream. And so this thing is just spinning off. And sometimes it can become very incoherent, sometimes it's going to settle into a groove, but it's not going to generate a unified model of a universe that it's entangled with reality that it's connected to, that it tracks as it does during daytime. And this tracking of coherent reality seems to require some kind of government mechanism. This government mechanism emerges in the brain through some kind of a suspect new Darwinism. There is some kind of evolutionary competition between different organizations that your mind can have, and eventually the most stable one prevails. And this is your observing conscious self, an attention agent that is trying to make a coherent model of the world. And now can we can ask does GPT-3 have such a conductor? And I think that the attention model in the transformer looks a little bit like one, but it's not. So the new thing that GPT-3 had that previous neural network training mechanisms usually didn't have was the ability to pay attention to what it should learn. This means that in every layer in this neural network, there is going to be a model of what the previous layers, based on the current context, what data in the previous layer, what features in the previous layer should it pay attention to. And this self attention helps the network to learn basically its own structure and do statistics over and it makes it much, much more efficient and coherent. But it's not integrated over all the layers into one model of reality and so on. So this is not what's happening in GPT-3 yet. And maybe this is one of the reasons why it's so much slower in learning writing, so much more training data than a human being needs over the course of their life before it converges. And it's tempting to think that this such an integrated model of attention is something that has, for instance, been suggested by Marvin Minsky in his seminal book, Society of Mind, where you have basically look at the mind as a society of different agents. And there are some agents that are organizing the other agents into a coherent structure. And Minsky calls these agents K-lines, knowledge lines, and suggests that they form basically their own society and society of mind. And this society is forming something like a reflection of what's happening in the A-brain. The A-brain being our perceptual mind that is modeling the reality that we are tracking based on sensory and actuator input that the brain is entangled with and the B-brain is immersed into this perceptual reality and reflects on it and makes it more coherent. And there is a similarity between Kahneman's famous System 1 and System 2. It's not quite the same thing, but it's tempting to basically see the affair as a perception agent that is entangled with the environment and is getting valence from the motivational system that is basically cybernetic motivational architecture. And then you have an ancient agent that lives on top of the perceptual agent. And that is the conductor and has a memory of what it attends to so it can get the model to convert by some constructive process. And this attentional system, this conductor, here I've drawn it on top of the system. The top is a direction that basically seems to be obvious to the attentional system itself because it feels to be on top, but we know that you're not completely on top. There is stuff that is driven by the selves that we have not reversed and that we give a moment and that gives motivation to the attentional system to what it attends to. But our consciousness perceives itself as the observer of the mental and external states and the self-states of the model that is being discovered. And the purpose of the attentional system is to facilitate learning so we can converge to a model of reality and reasoning, which is basically real-time learning on imaginary mental states. And this idea that consciousness is a control model of our attention is not new. It's, for instance, been championed by Michael Graciano in the attention schema theory and it finds itself in one version or other in Eastern philosophies and in a lot of convergent ideas in cognitive science. Some people say that computers cannot be conscious because they are only physical mechanical systems and so they're not physical systems in the same way as the neurons are because neurons are entangled with the real world as dynamical systems and so on. They can do things that the simulation cannot do. And I think that Frisk of Cork maybe has it backwards. I think that physical systems cannot be conscious. Neurons cannot be conscious. Brains cannot be conscious because there are things happening in consciousness that are not physically possible. And the only thing that can be conscious is the simulation because consciousness is the simulated property. Consciousness is virtual. So you can only be conscious in a story that you tell yourself about yourself. And this means that our phenomenal consciousness is a virtual state. It only exists inside of the mental models. It's not attending to physical phenomena. It's attending to high-level features, things like colors and sounds and emotional expressions and so on. None of these are physical things, right? All these high-level abstractions that a learning system is generating in the interaction with the environment to make it predictable. And this phenomenal consciousness, this experience of what it's like to attend to features is an awareness of a partial binding state of our working memory. That's basically at the content at the interface between perception and reflection. And then we are aware of the mode in which we're using attention. So whether this is hypothetical or whether it's perceptual or whether it's a memory. And then the reflexive consciousness, this process that is attending, is aware that it's the process that is attending and the space acting based on that awareness. And the AI researcher at Russia Benjio said that consciousness is basically a function whose purpose is to create a big dip in the energy function that models reality. So it's basically a low-dimensional almost discrete function that is parameterizing the perception in such a way that it starts to make sense. Self and conscious are not the same thing. The self is a model of your agency that you discover. And you can be conscious without having the self. For instance, during dreams or meditation, you can turn off the self without losing consciousness. And the self is this discovery of the agent that the system is making about what it is. And it's downstream from the set point deviation. So the self is not motivating things, it experiences the motivation and begins to understand how the motivation works and thereby allows to reverse engineer the mind if the self is learning. And it shapes our own agency by identifying who we think we are at any given moment. And it allows to have a first-person perspective if the self is discovering that the contents of this control model are actually driving behavior. That makes it a very special agent. So in this sense, consciousness is a control model of attention. It allows the convergence of a coherent interpretation of the world, which is basically a low energy state of the model that attracts reality. And it maintains a memory for this aggregation. So that's why we have a stream of consciousness. Because when you construct, you need to remember what you tried and where you're coming from. And this is not true, for instance, for convergent learning mechanisms like neural network learning, but you don't need to remember where you came from. We just go to the next optimum and try to stay in that optimum. So is GPT being conscious? So we see three by itself is not an agent. And the transformer is also not a complete control model of attention, but only a very partial one. And on the other hand, current AI models can be extended beyond that. And they can create coherent stories about conscious agents. You can get GPT-3 to run very long in its simulation of what it's like to be a conscious agent. And we can ask ourselves, is GPT-3 simulating a conscious agent or is it just a simulacrum? And what does this mean? So the world is a decomposition that might mix of the universe into interacting separate objects, because the entire state vector of the universe is too complicated to model it. So you hack it up into separate disconnected subsystems. And the universe is not really made of separate disconnected subsystems. It's just a way in which we make it intelligible to us. And once you have these separate disconnected subsystems, and you model the interaction, you get causality. Causality is the interaction between separate objects. So causality is a side effect of the way in which we model the universe as separate objects. And the simulation can model causal structure on a different substrate. So for instance, a computer game is using a substrate that's very different from physics, very simplified computation that nevertheless gives results that are so similar to physics that you can recognize what's happening on the screen and manipulate the causal structure on the screen based on what you have observed before in the real world. So a 3D computer game is a simulation of the physical world. It's a very simplified simulation, but one that can be surprisingly convincing. And a simulacrum is recreating just the observables without causal structure. For instance, the movie is a simulacrum. You cannot causally interact with the movie. You can just observe it. And so a simulacrum basically can do magic. It can do an arbitrary thing without you having to understand the causal structure. And in the sense, a lot of instances where you experience our free will is not the causal structure, but it's a simulacrum. It's a stand-in for a causal structure in our own mind. And it's to me an open question, how much of my own consciousness is a simulation and how much is a simulacrum? So if an imaginary person in my own mind is sometimes conscious, it's not that easy to say whether GPT-3 or an extended version of GPT-3 that does a multi-model, it can also have perceptual content and so on, represented in it, qualifies as such an imaginary person that would be conscious. I think I am an imaginary person myself. I don't know to which degree I'm a simulation or a simulacrum. And it's not quite clear how well the AI models are dealing with this. So in summary, I find it's very counterintuitive to think of GPT-3 as being conscious. For me, it's surprisingly difficult to shoot down the idea that it is. And even though GPT-3 is clearly inferior in many ways to the way in which my own perception works and reasoning works and learning works, and there's many things that it cannot do so easily, I think it's not that easy to dismiss the idea that it is slightly conscious for brief moments during the inference when it has to build causal structure to simulate an imaginary person so it can tell me a story about it. Okay, let's stop here. That was great. That was fantastic. Let's say first of all that there has been a debate going on on the internet about this, that people have been sending me links to, and Jan LeCun responded to Ilya's comment. I don't know if you saw that, but his response is not even true for small values of slightly conscious and so on. Anyway, so there's a debate out there. And of course, last week we had David Chalmers here, who, as you probably know, there was an interview on GPT-3 with him, which is very convincing. And he kind of makes his comments similar to you, that he thinks it's kind of approaching something like consciousness. Anyway, one thing I wanted to mention is that we, in architecture, we haven't actually, I don't know anyone who's been using Glide, but Clip has been used to generate images, very successful actually, and using VQGAN. That's the technique that's become very popular and has produced some really quite shocking results that people are kind of, they're really taking pay attention to. So it is something that we're kind of getting into, and it's certainly part of that discussion. I've had discussions about GPT-3 on this forum, which have been interesting. I mean, the key question, obviously, is whether we are fully conscious of everything that we're doing. And I think that there's some level of things that are happening. I mean, to my mind, there are some automatic reflexes that we do. For example, you go to Japan, someone starts bowing at you. Automatically, you bow back. It's not as though you're really thinking about it. And then there are questions whether we have access to some of the processes that are going on, that are part of our actions. We simply maybe can't reach those points. So whether things are beyond us in some sense. So anyway, this debate is a very timely and very interesting one. I want to put up, you're about to show something? I just put up this slide again, because this is generated with, I think, clip in VQGAN on Vombo AI. I don't think that I've published how exactly they do it, but it looks like it. And I generated this as AI claiming the noble eightfold path. Yeah, maybe I can show you later on some of the stuff, because it is quite extraordinary what it can produce. And I would say that you actually have in the audience here some people who are have written about AI and architecture including myself. So it's kind of you've got an interesting informed audience here. One thing, there's just a general kind of comment, though, is, I mean, I really like the idea that you put forward that somehow you can learn about the self through looking at AI. Somehow, I mean, I don't know how you put it, but whether it becomes AI becomes a mirror and into the self, but whether we can understand human intelligence through looking at artificial intelligence. And that's a provocation. And I think there are some examples in computer science where we have learned about the natural world through computer models. I mean, I think that Craig Reynolds Boyds, for example, gave us a clue as how to birds actually flop. I think that's interesting. And so potentially, there is something there that is, and this is one of my primary interests, is how we can learn about human intelligence, the human mind through these things. But the big challenge that it seems that we have is that we're dealing essentially with two black boxes. You know, we don't know what's going on in the deep levels of a neural network, and we certainly don't know what's going on in the mind. And so how can you make, what can you say that isn't simply a form of speculation? I mean, you can't prove anything. It can simply become some kind of, you can speculate about something based on what appears to be the case in another scenario. What would you say about that coming from a kind of, let's say, a scientific background where you have a kind of burden of proof? Can you do more than that? Yes, first of all, neural networks are no longer black boxes. You know how neural networks work and largely also why. You can basically look into the neural networks and find out which parts of the neural networks are computing which functions. And a function is a mapping from inputs to outputs. And a function can be used to couple the previous inputs to future inputs to track reality. So in some sense, when you look at the patterns on your own retina, what you have there are little blips that appear on the retina whenever a retinal neural gets excited by photon sitting it. And what your brain is doing, it's discovering a relationship between these blips. The meaning of the blips is exactly the relationships that your brain discovers between the blips. And this makes them predictable. It puts them into a shared context, not just at the same time, you're not just processing lots of parallel blips that happen on your retina, but also across times. So across different scenes that you're observing at different moments in your life. And the relationships between the different blips on your retina that your brain discovers is that you are looking at moving blocks of color in a world that is moving relative to you. And these moving blocks of color are three-dimensional surfaces. And the surfaces are animated by some kind of physics. And they are also animated by some kind of agency that you sometimes observe, like people talking to each other and so on that have mental states, they exchange ideas, and they're being lit on by the sun. And all these relationships are functions. These functions are dynamical features that basically tell you how to get from one state of the world to other states of the world. And at this level of abstraction, this is something that our neural networks also can do. Where there are limitations is that the neural networks that we are currently using are often not learning in real time. They're not connected to the world and online learning. You know, this research does happen. And it's slower. And it's not as flexible in many ways as the learning happens in our own brain. And so the algorithms that we have discovered are not the best algorithms that could facilitate this. But it's also, on the other hand, not as clear to me what the limitations of these algorithms are. There are people like Gary Marcus who will tell you that it's very obvious that these systems cannot do X, but there is no proof that they cannot do this. Even if you have a very simple feedforward system that is only mapping inputs to outputs, what is to say if you connect this to a memory, is that it's not the transition function between adjacent brain states and is able to do everything that your brain is able to do if it just has memory to store parameters that it refers to the environment that modifies you to behavior. So it's very easy to build a system that is Turing complete. It's not easy to discover a function that is capable of universal learning efficiently. And so our machine learning models at the moment are not efficient in the sense that they learn as quickly as the logical nervous systems learn, but they do learn and they do converge to many of the functions that we require. Can I just share my screen a second because there was one that you touched on, which I thought was that this is simply a transcript of your discussion with Lex. And this one I've highlighted, I think it's really interesting and incredibly provocative sort of comment. So basically a brain cannot feel anything, a neuron cannot feel anything, their physical things, physical systems are unable to experience anything, but it would be very useful for the brain or for the organism to know what it would be like to be a person and to feel something. So the brain creates a simulacrum of such a person that it uses to model the interactions of the person. It's the best model of what that brain, this organism thinks it is in relationship to its environment. So it creates that model. It's a story, a multimedia novel that the brain is continuously writing and updating. I mean, I find this enormously provocative as a comment. And I think the idea that we're kind of creating a story that somehow gives meaning to something, it kind of reminds me in some sense of the way that Homi Barba talks about how a nation operates. I think Zizek says something similar. It's how things are inscribed within a story that people tell oneself. And I think that's important because in architecture we just focus on the object, but actually it's the way that object is inscribed within some subjective process that makes sense of things. But I just wonder whether, I mean, so to my mind, this is an incredibly provocative and controversial comment, it seems. Just maybe could you comment on the reception that this view has had with other people? Has it proved to be controversial? How else could it be? Do you have other theory that works that can explain what's going on? I think once I noticed that my own experience is virtual, that my memories are often created after the fact and modified under my nose without me noticing. Do you notice that you exist inside of a model? It's also that I'm not in physical time. My own self is sometimes a little bit ahead of the physical universe, sometimes a little bit behind. So the physical now and the experience now are different. And the elements of my perception are clearly not the elements in which physics is being implemented. Rather, it's the other way around. What I notice is that I do exist in a dream, very much like we usually say in idealist philosophy. But this dream needs to be created somehow. Something needs to construct the dream. And that's a brain and higher plane of existence. And this higher plane of existence is what we call physics. Maybe I'll stop sharing. The other comment that I find usually provocative that you make is which kind of relates also to the discussion. I don't know if you've seen David Chalmers' recently published book on reality plus, where he talks about virtual worlds. But you came up with a comment that what we are seeing is a virtual reality generated in the brain, which I'm actually very persuaded by myself. And I guess I'm thinking also of the kind of thinking of Anil Seth, who kind of talks about this controlled hallucination. And we kind of predict what's out there because we don't know. It seems that your work to some extent aligns with the work of Anil Seth, but at some points differently. I have to say that Anil is very fond of your work. So it's intriguing to kind of compare and contrast them. Because we had a discussion last week about whether we're living in a simulation and things, how would you position yourself in relation to David Chalmers' work from reality plus, his work on virtual worlds? I haven't read his recent book, so I cannot say. And I don't know what his main thesis is about virtual worlds. Okay. Well, I wouldn't want to speak on his behalf, but we had a discussion about it. I also wanted to just point out something as well, which I find intriguing. And that is the extent to which some of these speculations that are coming out of cognitive science kind of seemingly echo the world of psychoanalysis. Now, I know that a lot of cognitive scientists and neuroscientists hate psychoanalysis. I know that Anil Seth does, but there's an interesting comment that Slavoj \u017di\u017eek has made about this, where if you take a Lacanian perspective, you don't engage with the real except of certain moments. And in a sense, the fantasy has become a constitutive of how you engage with the real. So you see the real through the lens of fantasy, through the lens of the imagination, which is very similar to what, in some ways, you're talking about. And he makes a comment in an essay that I published a long time ago in a book, and this is called From Virtual Reality to the Virtualization of Reality, which is basically saying that our reality is itself already virtualized. And I think what virtual reality therefore shows us is not how virtual reality shows us is not how virtual reality is, but rather how virtual reality itself is, which is very similar to your kind of thinking. And so what I find intriguing is that some of these speculations are echoing previous speculations about how the mind works. Have you engaged in any way with \u017di\u017eek or the world of Lacanian psychoanalysis and its discussion about the real? And I sometimes read this, but I've never had the discussion with \u017di\u017eek. I am not unsympathetic to this terminology. It's just the problem is that it doesn't allow me to make models that I can test. And this means I don't know whether these models are wrong. So it's basically a very useful way to generate stories that also give me a handle on reality in the sense that allow me to point at entities and to manipulate them in my mind. And sometimes it's very useful that you basically have an indexical model where you are separating the world into objects that are useful to you and you can manipulate them. But this decomposition doesn't need to be an accurate causal structure. So the criticism with psychoanalysis is not that the terminology is not useful to me. It's that psychoanalysis doesn't tell me how to build the mind and so I should say that it works and to compare different competing models of the mind and to see which one is better. To do this, I will need to automate the mind in a way. I need to reverse engineer what the mind is doing, the functions that the mind is applying to representational states and need to get this done to such a detail that this thing becomes my black. And then I can compare its functionality. I want to move on to the questions that are coming in. I want to invite people in the audience to comment as I want to make an observation and that is to say that in my own world, this is years ago, I was working on a kind of coming out of Freud and thinking about how you use model psychoanalysis and engaging with, actually in this case it was with the work of Walter Benjamin, I came across something that is uncannily similar, certainly in terms of the terminology used, whether we're talking about the same thing, I don't know. But let me just for a second just share you something which surprised me because when I heard Blazegoriyakos talking about models and modeling, it's also crucial to his way of thinking. It sort of seemed to echo this. I'm just going to simply just share this screen a second. Yeah, can you see that? It's the thing about, so the term that I'm always interested in is the term mymesis. I don't know if you know this term at all, but in Freud it's how you can, he talks about it initially when he talks about how in his book of jokes, how you can connect with someone who's a subject of a joke. Someone falling over a banana skin, for example, you somehow, you model yourself on that person recalling bodily memories of what it is to slip up and so on and so on. It's how you identify with the world. The term mymesis is a form of that, it's a form of modeling. But just I just want to read out some of the text here because it's so similar to this idea of models and modeling. And I know that the term can be taken out of context and have a completely different sort of meaning, so therefore it's a bit deceptive. Anyway, to just understand the meaning of mymesis in Benjamin, we must all recognize its origin, the process of modeling, of making a copy of. In essence, it refers to an interpretive process that relates either to the modeling oneself on an object or to making a model of that object. Likewise, mymesis may come into relation as a third party engages that model with that model, and the model becomes a vehicle for identifying with the original object. In each case, the aim is to assimilate to that object. Mymesis, anyway, so it's going on about this question about, so it's a concept that has been used in psychoanalysis. And I don't know, there's a risk that one can simply take a term, which has a completely different meaning in different contexts and apply it. But I do think that the concept, the model, is a fascinating one. And I'm intrigued by the fact that you, alongside Blaze, and I think alongside also Jeff Hawkins, use that model as a way of opening up these questions. An issue with this type of language is that usually the understanding that it generates at least doesn't converge. That's the general issue with continental philosophy. Somebody recently asked on Twitter what the difference is between continental and analytical philosophers. And I somewhat flippantly responded that an analytical philosopher is one who understands that the difficult and hard questions of philosophy need to be answered with formal models. Whereas continental philosophers don't think that this is necessary, because they are literally genre that is looking down on analytical philosophers. You can see the difference between analytical philosophy and continental philosophy in, for instance, the treatment of Goethe's incompleteness proof. A proper analytical philosopher who had a formal education will understand that this is a proof about certain properties of formal languages, and specifically it proves that stateless formal languages that assume that truth exists independently of the process by which you get to prove don't lead to consistent models of the domain. And there are also related results, for instance, that a system cannot make statements about affairs outside of itself. So when you want to talk about the world in a formal system, you need to create a model of that world, and you can only talk about that model. You cannot talk about anything outside of the models that you are creating. And to continental philosopher, the Goethe's proof is more or less often understood as a statement of mathematicians that prove that mathematics is important at getting a handle on reality, and therefore the only way you can get a handle on reality is by not knowing mathematics, which gives the continental philosopher a clear advantage. I cannot hear you. You are muted. That was a great answer. Thank you. We've got some questions. Now, I have a third series of further questions that I'd like to ask. Maybe I could ask you one question before we go into the other questions. And that is, I mean, are you writing a book about this? I mean, is it being put down in some documented form? Because it would be incredibly useful if it were. You are right. I need to write a book about this. I have a large number of notes on stuff that needs to go into the book, but I also have a job and I have kids that are homeschooled and I have ADHD. So I need to go into a different phase of my life to have long interrupted, uninterrupted sessions for writing long phone texts. But if you're bad about not having written the book yet. Well, I think that a popular form of communicating ideas. So there is material out there, but I just think it could be assembled into an engine. Yes, it needs to be assembled. I feel better if it is being assembled and not just existing as various disconnected conversations. Yeah, I just, I mean, even Jeff Hawkins, I mean, my Jeff Hawkins book, I think is fabulous. But what's interesting is there are no footnotes in it. He's just kind of speculating. But nonetheless, he's putting his ideas down there. And it's really incredibly useful to have that kind of commentary. So anyway, look forward to the book. I want to just ask this Matt Gorebay, who's got a question in the chat, whether Matt is a graduate of MIT Media Lab. He's a doctoral design student right now at FIU. Matt, would you like to ask your question? Sure. Yeah, thanks for all of this. It's really interesting. Perhaps the book could be co-authored by GPT-3, make it faster to, you know, just to give GPT-3 the agency over the first draft. I was asking, speaking of agency, I mean, the question I have is about motivation. It's about sort of the high level motivations. When you ask, when you ask GPT-3, are you conscious? And then it responds somewhat convincingly. It still isn't initiating that conversation. And so one of, I mean, kind of in listening to everything you were saying, and you said something about when you were talking about trees and seeds, I love the thing about, instead of realizing the functionality, you want to build a system that wants to realize the functionality, you want to build the thing that wants to become a tree. But that question of wanting and motivation, how does one, at what point does that get put into the system? Like at what point does the system become curious or self-motivated to do things that we didn't necessarily ask of it? And I think maybe related to that, I don't know, I'll let you go on this, but maybe related to that, the question of individuation and sort of inter-subjectivity, like, you know, has GPT-3 spoken to, are there communities of GPT-3 all talking to each other about what they want to do and how do they individuate? Or is GPT-3 just always the same and its clones of itself? If you could speak to any of that, that'd be great. Thank you. Yes. So that's the question, are we doing something that the organism is not asking of us? And that's not an easy question to answer. If you look at our own motivation, I think that we have a few hundred physiological drives for different nutrients, for instance, sometimes we want to eat salty food, sometimes we want to have sweet food, sometimes we need something to drink, sometimes we need to rest, and all these can be understood as set-point deviations. And to deal with all of them, we need to create a dynamic model of our needs projected into the future and then plans and higher-level models of these needs, which we could call purposes and so on. We don't just have physiological needs, we also have social needs, for instance, a need to affiliation to become part of a group, for instance, and to be accepted by it. Some people have a need for status to raise up in the group. There are romantic needs, which can be courtship modes or a need for intimacy and so on. And then next to about a dozen of these social needs, we have a handful of cognitive needs, a need to become more competent, become efficacious on the environment, a need to reduce uncertainty, and something that I would call a need for aesthetics, which means discovering deep structure in the world. And aesthetics can be split into stimulus-oriented aesthetics, so we are intrinsically wired to like certain body schemas over others, certain landscapes over others, and there are evolutionary reasons for that. And then there are some mathematical principles, what kind of representations we like, what form means to have a good representation of something that are more general. And if we use meditation to disassemble our own needs and to dissociate from them, we realize that the things that give us pleasure and pain do fall in these categories. So we have lots of these impulses that are about hunger and thirst and rest and so on, and we have impulses that are about the social domain, and the older we get, the more these impulses get replaced by a deeper model of what we want the world to be like, and we act on this deeper model and digest these reflexes. And on the lowest level, when you try to get more enlightened, you may have just something left that people often call love, which is, I think, a need to transcendentally connect to other agents and share purposes, that might act on these shared purposes, but you can get deeper than this. And the deepest level, you only have aesthetics, the need to form structure and to make the world intelligible, to create a coherent model of reality. And this need, I think, is similar to what Friston describes in the free energy principle, it's basically predictive coding, it's the attempt to track reality using a model that is as good as possible, that tracking reality. And if you turn off this aesthetic need, in addition to all the others, my own mind becomes fuzzy, I fall asleep, I drift away, because if I stop paying my neurons for producing order in the universe, and they stop doing this, then nothing else is happening in my mind that I can observe, and I just lose coherence. So if we imagine this hierarchy of needs, which by itself, and seen as a cybernetic system, is not all that complicated, we can build this into a machine, I think it's not that difficult. The difficult part is to get perception right, to get ability to model reality in the universal base, you can have one coherent model of everything that you relate stuff to, when we talk about meaning, we talk about how to relate an arbitrary feature or domain or idea or concept to this unified model of reality that we are building each work once in our own mind. Can I just pick up on a question, we've got another question lined up, but let me ask you one quickly. You come from a creative background, your father was an architect, and you refer to let's say creative practices of the orchestra and so on, it's part of what you're talking about, and frankly, your way of thinking is incredibly creative, it strikes me as being very creative. I wonder, you haven't mentioned the word creativity, I don't think, and how do you view creativity, is it just a myth or is it something, how could you conceptualize it within your framework? I think of creativity as the ability to bridge discontinuities in the search space, and you are just following the gradient, and when you're just going through a continuous search space, I don't think that you are creative, you just arrive at the state of the art, and even the state of the art is something that hasn't been done before, if you just combine what is known and you find a local optimum in the known things, you're not being creative. To be creative, you need to construct a new search space usually, and many methods in which you can be creative, for instance, you can use random serendipity, you can use some evolutionary process that is combining elements in ways that you are unaware of, and then discover structure in them. Creativity is, in some sense, about jumping off from the known things into darkness and hoping that you end up landing on the other side. So it's related to a search. Let me just put this to you then. Do you think that, because you mentioned this before in your discussions, but do you think Move 37 in Game 2 of AlphaGo, was that creative? Could you call that creative? I don't think that AlphaGo is creative in the sense, because what AlphaGo is, well, there are evolutionary methods in AlphaGo, and the outcome of what AlphaGo is arriving at is not always predictable. And it's also computationally irreducible in the sense that you cannot foresee what AlphaGo was doing. AlphaGo was able, in a relatively short amount of time, to demonstrate that human go play, which existed for thousands of years, was not optimal. It has discovered strategies that encounter the established strategies and goal. And in this sense, from the perspective of a human go player, it was playing in a creative way. It just discovered new things that had not been discovered before. But if you will run AlphaGo multiple times, it's always going to discover these things. And so the search is, while it has stochastic elements, as a deterministic outcome. And I think that when we look at systems like this, our notion of creativity is kind of sort of falls apart. But creativity is not absolutely a thing in the universe. It sometimes is a frame that is useful to describe what's happening. And sometimes this frame falls apart. Let me just put a provocative comment to you, then. I mean, something that I thought myself, and I would like to know what you think of this. So if GPT-3, if AlphaGo is not creative, and I kind of, in many ways, I don't think it is creative, it's just doing a very, very effective search. But then we could ask this question about whether human beings are creative, or whether this term... Exactly. That's my issue, right? So sometimes your terms start meaning things. They mean something in a certain context, but when you increase the resolution too much, this context falls apart and no longer makes sense. And you use lose your term. And I have the same issue with the term like nemesis. But I like it. It's poetic. It is evocative. It produces stuff in your mind. But when you zoom in very hard, it's not clear what it means. And so instead, I try to examine the assumptions that are hidden in nemesis. For instance, the idea that others exist independently of you, and yet you are able to take them in somehow instead of constructing them. And then the question, what's first, the model of the other, or the model of yourself? And whether it's the same thing in every person that becomes conscious. This is not obvious to me. And the notion of nemesis presupposes too much. And that makes me unsympathetic to it. So even though I appreciate the poetic illusions that are there in the space that the term like this opens and the ability to converse about it, ultimately, I need to deconstruct the term before I can use it. Okay, so let me just put... I'm glad you take this position. But we just throw an idea at you. So, I mean, one of the analogies that I've made in the past is to say that... Use the term magic at one point. Actually, I don't think that magic exists. I mean, I think that what happens basically is if you take the example I always give, if you have a magician at a kid's show, and they're pulling a rabbit out of a hat or something or doing magic, the magician's not doing magic. The magician is simply concealing the operations at work and making you believe that it is magic. And I'm just wondering whether we couldn't take that same notion and apply it to creativity, because we don't understand the processes. We just look back and say, wow, that's creative. Like some people said the same with AlphaGo, that's creative. But maybe it's not. It's just simply we don't understand the process. Therefore, maybe even the term creativity is not a very productive term in the first place. Yeah, I suspect that magic also in order to make sense, we need to understand what the term means. We need to completely deconstruct it into its constituents and then put it back together and see if we still have magic or if this term can still be recovered. And typically, I see magic as the ability to get right access on the laws of reality. And if you think about what it means in the naive form is the departure from the mechanical universe. The universe that we are in, according to the theory of physicalism, emerges over a causally closed lowest layer. And this causally closed lowest layer is basically whatever mechanics is making the universe happening. And ultimately, there is going to be some natural layer where things are just happening without some conscious intervention. And the idea of magic is that our universe somehow is a conspiracy, that there is a way to subvert the laws of the mechanical universe using symbolic powers, that you have symbolic causality. And symbolic causality is, for instance, the connection that exists between sacrificing a black cat and celestial events that are caused by this. Right. And this, this is something that cannot possibly be explained by any known physical mechanism, because the elements of this transaction only have meaning in a symbolic realm to a human mind that is acting based on a certain high level story and abstraction that is not a good depiction of what happens in the physical reality. It doesn't mean that the story is wrong. It's just not one about the frame of physics. In computer games, there is magic happening relative to the computer game, right? You can use Minecraft. And in Minecraft, there is a mechanical layer where everything happens by itself, but you can also call up a shell and enter a time-set day in the sunrises. And this interaction somehow breaks the logic. And if you could do such a thing in our world, if you can use a ritual to make the sunrise, then you would subvert the physical reality. But what you can subvert is the psychological reality and the social reality. And in this form, magic does exist. If you get right access on somebody else's perception and attention and memory and imagination, you can change their reality in any way you want. And in our culture, there are some norms against this or there used to be norms against it. And I think that in Christianity, this didn't exist. It was legitimate to subvert the reality of other people by telling them, here is an omnipotent agent that is part of reality, therefore needs to be modeled in your own mind. And omnipotence means it knows everything that is to be known as full read access to your mind. And omnipotence means it has full write access. And also, we have a backdoor to this thing. Every week, you can get an update and we tell you what this agent is going to do to your mind. And as a result, you have people that remember having seen miracles, because something has rewritten the mental structure of their own mind. And you often find patterns of this in ideologies. So this idea that somebody else gets right access on your own minds, for instance, an innocent example is, here are my pronouns. And these pronouns are not what you perceive. They are what I want you to perceive. And I have the right to change your mental representation. That's a form of magic. And I think that the idea that this is happening is because the people who propagate these ideas don't believe in the individual autonomy of individual minds to create realities and having a good outcome. You need to control the realities that minds create together by using magic to get the psychological realities of individuals to converge to the desired social reality. One of the things I find interesting in your thinking is the role of, well, you use the term ideology, use the term religion. But to my mind, they could be seen more in the realm of myth. I mean, there's a lot of this space. And the way that you use the term actually also reminds me of the work of Zizek. I mean, he makes a comment. He read a book about love at one point. And he came to the conclusion that love is the myth that fills the gap between the self and the other. And somehow myth has been some structuring device by which you look at things where it conditions your understanding of reality a bit like ideology or in a bit like religion. Is that something that you would engage with? I would engage with it. But I think that love is a more concrete meaning. Love is the discovery of shared sacredness. And sacredness are the purposes above the ego, the purposes to which we are willing to sacrifice ourselves. This has to do with being part of a transcendental agent. Not everybody has that. If you are a sociopath, you will not have purposes above the ego. And so you will be incapable of love because you will not have shared purposes above the ego. You might have romantic infatuation. But ultimately, you are not going to build shared agents with others for non-transactional purposes because you share purposes with them. So love is this discovery of shared purposes. But I mean, but can you use the term shared? I mean, how do we ever know the other? How do we ever accept the other? We can think that we're sharing things, but are we actually sharing things? We do this in the same way as we know ourselves. These are model creations. The other is a story that we are creating about a certain state of affairs in the world. It's in this sense not objectively true, but it's a model that allows you to predict reality better than other models that are competing with it. No, interesting response. So, Gustavo, maybe Gustavo is a postdoc at UC Santa Barbara. Gustavo, would you like to ask a question? Sure. Thank you very much for the wonderful talk. I think I want to kind of build on Matt's question a little bit, but more specifically to the idea of understanding how computational systems are, let's say, evolved and programmed at the scientific level. Like, what is the state of the art in modeling either psychological states or understanding how different models are building on knowledge where computational models can make creative leaps? So, if it's not clear, I'm thinking about in the history of human society, they're different models of control, the models of narrative, you know, they're different, either religions or different belief systems, but in the models of science, it seems as though that there is a building of knowledge and that we're moving toward an end. So, where we will never, as an example, we right now won't live to the end of the universe, but there is a goal in science that we as human beings need to propagate outside of our, you know, cosmos, so we have a chance to exist, and we have multiverses. How does, how do these computational models either aid humanity or are we looking at these computational models to exceed humanity in some way? And what does that mean? I'm thinking about that edge that you're talking about, because I think a lot of what we talked about in humanity are black boxes. If you talk to a physicist or, or a mathematician, or an electrical engineer, they get to a point where we don't know the science. What are your thoughts about that? How do, how do we build better systems? Or how do we interact with these systems a little bit more ethically or morally? So they're not like psychopathic or anyway, maybe that's a little too abstract. It's just, you brought a lot of higher level, a lot of knowledge here. So it's, it's very sobering is what I'm saying. Sorry about that. Don't be sorry. But I do welcome sobriety if it emerges. I think that you made some very interesting points or arrived at interesting pointers. You saw some images that I presented earlier, for instance, the generative art of glide and the text that GPT-3 is producing. And in some sense, this is the state of current computational creativity. And I think that the problem of how to make a technological system creative is solved. So they, these images are in some sense creative solutions, because they are able to bridge certain discontinuities in a certain space by finding solutions that people might have difficulty to find. So, for instance, if you have a conversation with GPT-3, it's usually better than what you get from a person that doesn't know the domain, but worse than the person that knows the domain. Well, for instance, you have a conversation with Hannah Arendt. And if you haven't read a lot of Hannah Arendt, it's really surprising and very convincing. But if you're very familiar with Hannah Arendt and have thought about her a lot, then you might notice some things that you probably wouldn't have said. And a similar thing is with our depictions of art and so on. So it's able to produce certain styles and reproduce them. But there is a certain thing that is missing. And I think that what GPT-3 cannot do yet, and the systems cannot do yet, is art. And the difference between art and creativity is subtle. Art, I think, is the capturing of conscious states, of a conscious reality, of some aspect of a conscious reality. And this means meaningful references to a unified model of the universe. And these models do not have a unified models of the universe yet. They don't understand which universe they are part of or think that they are part of. And while they are slowly getting there, I don't think that they are there yet. So to me, the digital art that you're seeing is not actually art, because it does not mean very much to the system. But it's something that humans can, at this point, relate to their shared reality sometimes and onto their inner reality. And this makes them akin to art. And there is basically a porous boundary that is more and more dissolving in terms of AI and art in these days. So I don't think that there are fundamental unsolved problems at this point. But the biggest important problem is how to get a system that is able to track reality in real time and that can online learning. And a lot of people are working on this and we don't know how long it'll take to solve it. But it's not that it's a principle unsolvable. Can I just pick up on that, the question of art, because I think the back of my mind, there's an interesting kind of question coming up here in terms of, well, let me just throw out to you an idea, because you used the conductor metaphor and the music was part of the discourse. And I often speculated whether how creative we are as architects or indeed how artists are in the sense that there is a canon, there is a canon of architecture or art or whatever it was. And what we do is normally keeping broadly within that canon, you're very much aware of what other people have done. You might push the boundary slightly. And this is kind of what I think, I use the term jazz as a kind of idea of understanding how we operate as a background condition. And we're feeding off it and just nudging the boundaries, but staying recognizably within the canon of this. And it's interesting that, I don't know if you know the work of Ahmed Agamal, the guy who created these, who designed creative gans that he's a computer scientist who has a, who generates art. And the logic is this, you've got to keep broadly within the framework of what you're talking about within the canon of, let's say, modernist art, but make it slightly different. So you're just pushing the boundaries. So I know I often wonder to what extent we're so conditioned by what has been done before. And whether we, if you would do something genuinely different, you'll be outside the realm of what is acceptable within that genre. I would make a difference distinction between art and design. And architecture for the most part is not art, but design. It's also true for myself. I'm for the most part not an artist, but a designer. And design is instrumental to something. Whereas art is instrumental to consciousness only, I think, at least the aspects of the thing that you're producing that are art, the other aspects and every artifact that you are producing, almost everyone, the design serves some other purpose than the consciousness itself. For instance, if you are designing a building, you are serving a function of a human being that needs to have a house somewhere that needs to live down somewhere, this thing needs to be part of an environment and it requires deep perception. And it does require capturing some of your observations and the deep level. So there is important elements of seeing and perceiving and observing and reflection in architecture. But all these elements are ultimately instrumental to the thing that you're going to build. And the thing that you're going to build is defined by its function. Maybe I could just throw something out there. And let's say that could you not, as an architect, always think about these things. And I think almost there are two sides of, well, there are two sides of architecture, one's a functional side of thing, or dealing with the logistics. If you're dealing, let's say, with a very complex urban condition, you need to fit a building in somewhere, it becomes almost like a kind of simple search question of how do you find the best solution. And then there is this kind of, I wouldn't say a veneer, but there is an aesthetic side of things. So when it comes to, let's say, the strategic planning of how you might fit a building in a site or how it might operate and so on, it kind of relates more to the kind of logical, let's say, of AlphaGo, the strategy of AlphaGo. And then there's something else that we, as architects, want to put on top of that, which is more the kind of the artist dimension, which is giving it a certain aesthetic. Does that sound to make sense to you, that logic? Yes, it does. But there's, of course, the practical element that the aesthetic that the architect has when it's a successful one is a brand. And it's not driven by a free exploration of the conscious states of the architect for the most part, but it's driven by the anticipation of reward in a particular economic and cultural domain. And so in a sense, it's usually a construction process. Let me throw out another kind of thought then. I mean, what is interesting is when you get someone who's fairly radical, like, I don't know, Frank Gehry, for example, he produces a building, the Guggenheim and Bilbao, really changed architecture, but then he kind of repeats himself in some senses. He's doing similar versions of that, and you must have seen the LA, the Philharmonic in LA, the Walt Disney concert hall. And it's almost like we have these patterns of behavior or signatures, I would say, that are recognizable. And now you see a Gehry building, you say, that's Gehry. So it's almost like we're pieces on a chess board, and we have certain conditions, and we actually are constrained by that. So whether you see it as a brand or not, but it could be seen as a brand, we are constrained by our own signatures. And in fact, we end up not being so creative because we fit in with that logic. How does that sound to you? Ultimately, it's about intention. And the intention is either the submission to an external cultural mind, or the intention is an autonomous one. And I personally see art as something that is driven autonomously, and that's different from the definition of the art market. So the art market is only capturing a very small part of the arts. And a lot of the things that are happening on the art market are not art. And my own father is an architect who has defected from architecture and become an artist. So I am a child of an artist family. And my wife is an artist. And the difference between the art that my father is doing and the architecture that he has been doing is that the architecture is serving others in a particular role for in a particular cultural context and economic and social and societal context. And my father didn't want to submit to this societal context and this psychological and social context because he thought it was deeply unesthetic to him. We rejected the aesthetics of the society that he was in. So we removed himself from the society that he was in, bought a watermelon in the countryside and turned this into his own kingdom. And this kingdom is open for others to visit and explore. But it's not done for them. It's done for itself. It's done in the service of his own aesthetics. And to him, it doesn't really matter whether others like these aesthetics. This doesn't change how he thinks about the things that he's creating himself. He may need economic success to be able to survive and it might frustrate him if people don't like what he's doing. And it might frustrate him the things that he might have to do to survive. But his own definition is that he is not for himself, of his own intention, that he is not serving an external aesthetics. He is an autonomous agent. He is deeply autonomous. He is the creator of his own universe. No, it's a beautiful story that I've got a question coming in from Shamene in the chat. But can I ask you one quick question before we go on to that? And that's to say, the term architecture gets used, obviously, both for computer science and for architecture itself. And I'm just wondering, I mean, I don't know, my definition of the architect is very broad. I mean, I think it's a way of kind of, I would say that probably what your father is doing is probably still a form of architecture, maybe a form of other architecture. I mean, there are many creative industries that architects go into, like the film industry or space industry, and they use that architectural imagination elsewhere. And I even think that kind of setting up educational systems is a form of architecture in a way. And I just wonder whether you ever have seen any connection between those two architectures, the one that you're familiar with or your father, and the world in which you work right now, computer science, because I noticed the word architecture is in the title or subtitle of your book. Yes. So the notion of a cognitive architecture means that you understand the mind as something like a building or a structural design that is inhabited by lots of functionality, and is serving functionality in a larger world that it's embedded in. So it's natural to think of the mind as something that is constructed rather than just grown. And that's also the limit of the term architecture in a way, because the mind is not just constructed, it is also grown. And so there is the question whether growth is an architecture is a forest architected in a way. And I think it can only be architected to the degree that the forest is sentient and starts breeding and structuring itself. And maybe it is, right? So maybe there are elements of design and construction in the forest. So it's not just something that is locally grown by some dissociated process that does not have a centralized spirit that reflects functionally on its relationship to the world. So Shemin has got a question in the chat. She's in a noisy cafe, so she can't ask it herself. But I should say that Shemin Yussef is from Iraq. She actually studied in Germany in the other Bauhausstadt in Dessau, where I myself was a professor for a while in the building next door to the Bauhaus itself. And there's a school of architecture. And Shemin was one of my students for a workshop there. Let me read out Shemin's question. Thank you, Yosha, for the great lecture. This is Shemin Yussef from the School of Architecture at Florida Atlantic University. My question is, it seems that there is no condition for sentience for an agent in brackets, AI model, for example, to be creative and to be conscious in brackets. If I understand your thesis well, close brackets. So do you think that we, human agents, are discriminating against the machine since it's not a biological being, and therefore we should instead consider intelligence and creativity based on the behavior of the machine, which has proved to be true or is becoming true in the near future? Shall I read that again, or does that make sense? Yes, I think I understand where the question is going. It comes down to whether the technological systems, once they approach functionality that is similar to ours, should get rights that are similar to ours, and at which point we give these rights and why. Is this a viable interpretation? I don't know whether Shemin liked the comment on that in the chat. Well, maybe while we're... So as I would say that sentience is in some sense the ability to know what you are doing, which means you have to have a model of yourself and the relationships to the world that you are in. And in this sense, I would say that, for instance, a corporation can be sentient. The corporation has a legal, economic, structural, functional notion of what it is. And this notion is represented in the minds of the people that work for this organization and the balance sheets of the organization and so on. It's often distributed, so it's not a single point where the entirety of it is represented. But functionally, you could say that the organization can converge towards sentience. And the more sentient it is, the more it's aware of what it's doing, the more successful it's going to be, because it allows it to make a model of its relationship to the world and act on that model. But a corporation, I think, is quite clearly not conscious. So there is nothing what it's like to be a corporation. And it doesn't mean that corporations could not be conscious in the future. Imagine that you replace the people that make the decisions and information processing of the corporation gradually with machines. And this gets one more real time until it gets entangled with the world in real time. And at some point, it will discover itself as a real-time agent that is paying attention in real time. It's not clear to me whether this will be human-like consciousness because it needs a control model of the attention, because our attention is selective. And the selective nature of consciousness is quite constitutive for it. And if you have enough computational resources, maybe you don't need to be selective. Maybe you can do everything automatically without having this layer of reflection and be good enough. So maybe consciousness is something that exists at an intermediate level only. So it exists in systems that are complex enough to have this kind of coherence creating a government-like conductor that is making sure that your free jazz is going to be coherent and is going to be instrumental to what the organism needs at any given moment. Or maybe you can create this coherence just by tuning the orchestra well enough and making it more tight that you can do this in a biological system. And at some point, it doesn't need a conductor anymore and just does everything in a mechanical way. So I don't know that. It's an open question to me. With respect to the other aspect, whether we should give something rights, the rights that we have as human beings are instrumental to the function of our own society. They don't exist because people have an insight in what it is like to be a conscious being. The animals that we are slaughtering in our afterhouses are conscious. It's quite clear and obvious. They do act on the awareness that they are aware. The cat that I have in my household is aware of the fact that she is aware and that I am aware. And we are able to communicate about this fact, even though the cat is not that smart. But I think that the cat knows that the cat is conscious. And this does bestow some rights on the cat in our household. But it doesn't bestow rights on the cat in a similar way in society at large. Because the aesthetics of our society sees animals as instrumental, as tools. And this is probably also true for AI. On the other hand, if AIs achieve superhuman abilities, in many ways they already do. So they are crassly subhuman in many ways. They cannot do many things that humans can do, like create coherent world of meaning. But there are also things that they can do much better, like star transfer or generation of imaginary dialogue with historical people. They are able to do this much faster and with better quality than most people can do it. And so if you basically imagine that you have systems that overcome their current limitations and become superhuman in all the levels that mean, why would these systems be interested in having human rights? If you're not going to live next to these systems anyway, you're going to live inside of them. We will be their gut flora. Why would the organism that sees us as its gut flora at best, would want to have rights that are akin to gut flora and instrument with the aesthetics of the interaction of gut flora? Who cares? So why would a corporation want to have human rights? That's not interesting to a corporation. A corporation is operating in a very different domain and has much greater rights in this domain and abilities than a human being does. So I don't think that this will ultimately be the issue. I don't think that the systems that we are building will be necessarily subservient to us once we make them sentient and conscious. Can I invite Manos Tomiso to ask his question? Manos is doing a PhD on AI. The architecture is also associate professor at FAU. Manos, would you like to unmute yourself? Hi, Yosha. Thank you. It's been very stimulating. So I apologize in advance. It's a bit of a long question and seems to be very specifically formulated, but I'm interested in the broader discussion about computational creativity in your earlier comment. First about Minsky's positioning in terms of the part of the mind treats the rest of the mind as its environment and how this is kind of relevant to that idea of the search space and how we position ourselves in a search space if we're able to externalize ever a source from it with regard to discovering something. So the specific, let's say, part of the question focuses on the neural language-based models like Glide or VU-Gunplus Clip, which I've also been trying to work with a little bit. From an architectural point of view, not so much a technical one. And what, for example, we begin to perceive as a simple language prompt, a one word prompt, may in fact be much more complex than that. And so, for instance, a prompt like a building or a window, even though the network would address this with the same procedure, we would know that the former is a richer semantic representation in terms of one's inclusion within the other. A window is meaningless without a building. But with regards to the way that the network treats that, they could both be perceived as a high level feature details, depending on, like a window by itself could be perceived as, let's say, a high level feature within a broader building representation. But the same thing could happen with regards to the way a building could be scaled and nested within a broader, larger urban landscape. So all I'm saying is, if you have any comments with regards to this kind of discrepancy, which seems to address, of course, the reductionist, maybe understanding of language, but how perhaps this could be encoded in a different way. What we perceive as a simple prompt is not necessarily a simple prompt. And a human is able to understand it, but the network would be reading both of these terms on an equal terms. I'm not sure if that was clear. The issue with the existing models is that they're not trained on the same reality as ours, but on the representation that we have created. And this representation is inert. So, for instance, GPT's language is not trained in the same way as our language is being learned. Our language is being learned as a solution to a particular kind of problem. And that is how to transfer mental representations across people and how to organize mental representations within our own mind to transfer them. And this is achieved by mapping the representation, which mathematically is something like a dynamic hierarchical graph into a discrete string of symbols. Right? Language is always a discrete string of symbols. And the main reason why this is the case is otherwise it wouldn't be learnable. And this discrete string of symbols that hangs in this thin air between speakers has to be constructed and deconstructed or reused for constructing a mental representation using limited resources, something like a stack depth of not more than four, because while language can be defined in such a way that it's infinitely recursive, our own mind is incapable of facilitating deep recursion, because it only emulates it, right? So, it needs to be simple. And all the natural languages are solutions to this design requirement. Find a learnable method to map mental representations into discrete strings of symbols. And this is done in a collaborative process, right? Basically, language is invented by groups of people, not just by individuals, for the most part. There is no reason why an individual couldn't do this. You can, in the same way as you can play chess against yourself, you can play language games against yourself and invent your own private language. It's not an argument that I can see. It's plausible against that. But practically, it's a tool to transfer information in a large degree. And GPT suites language is not the result of this interactive learning. It's a result of looking at the linguistic utterances of people as they are typed out in the internet in a non-interactive fashion. So, GPT suites doesn't learn semantics in the same way as we do. We start out with understanding semantics indexically by pointing at the features in our perceptual environment. And then we learn syntax, we learn how to translate this into linguistic symbols. And then we learn style, that is, the particular way in which linguistic symbols can be arranged to communicate efficiently and to convey additional layers of meaning by the shape of our utterances. And in GPT 3, the order is inverted. GPT 3 basically starts out with style and syntax and learns semantics as the long tail of style. Right? So it's, in some sense, the wrong way around. And it's amazing that it converges at all. There has been in the early days of computer linguistics, rich discussion with philosophers who still haven't updated, who thought that you cannot learn semantics without interaction context, without embodiment, without having symbols that are grounded in perception. But GPT 3 shows that it's possible to learn semantics to some degree only by looking at language. And you can see that it's semantics because you can ask GPT 3 for instance to perform certain linguistics transformations or to add small numbers to each other and so on. And it's capable of doing that, which is a semantic operation that has a causal structure that is being addressed by an linguistic prompt. And GPT 3 is able to verify in some sense whether it was able to conform to that specification. So these are proper semantics, but they are impoverished compared to human semantics because there are the result of something like bubbling of extrapolation only without interaction. But this doesn't mean that we cannot do this. In principle, we can build systems that interact with the world and that are serving instrumental purposes and satisfying their needs and doing this and that do on their learning. It's just the present set of algorithms and technologies that we have are not very amenable to this. Let me just push this a little bit further. I mean, I often because I think that the GPT 3 and the kind of text or the prompt based responses that you get out of Clip certainly are interesting because I'm just wondering to what extent we ourselves are trained a bit like a neural network in the sense that we have certain inputs. You go to school of architecture and you are schooled in a certain way of thinking, you know, that's what you do. And so when we think of something, someone says a house, then if I'm trained in the modernist thing, I will think about the certain images, at least something will be conjured up in my mind that is quite controlled in a way by the training that I've had. So I'm struck that actually maybe there are not that there's more similarities there than we think, whether we have an automatic reflex about certain things based on our conditioning. Maybe I could just, Bob, while you're thinking about that question, show you a quick video of the kind of work that we architects have been doing using this. So this is a work of an architect from Peru, who's now teaching. And it's using Clip and VQ GAN. And there are a series of prompts, there are a series of pre prompts. So there are three very progressive architects names were put in there. Zaha Hadid, Tom Main, Wolf Pricks, you probably don't know these guys, but they're kind of Gary like slightly crazy guys, right? And then there's a second prompt, which is the main prompt is futuristic Indian temple. And this is the kind of thing that gets hallucinated by this thing. And I often wonder, you know, whether, yeah, my question would be this, it wouldn't be fair to say that actually that we are trained, we are trained by our experiences and our education as a form, obviously, indoctrination to think of certain images to conjure them up in a way almost like Clip does. Okay, yes. So there is a big similarity in the way in which these models work and the way in which our own mind works. Difficulty is the way in which the GPS we got to these representations or a big gun. And it's basically the gun is fed lots and lots of separate distinct images that are annotated with text as a reference to, for instance, the subtitle of the image that the creator gave it or even to a complete description of what's happening in the image. And by looking at millions of these images in batch processing, doing statistics over these images, you build up the structure of the network. And the network ultimately converges to an efficient representation of this latent space of representations. And in our own mind, this representation is built in a slightly different way. We train up layer by layer. We start out with an extremely limited reality. And this limited reality in the first place is maybe it's similar to what's being described in the first book of Genesis in the Bible. I think that the first book of Genesis in the Bible is misunderstood by the Christians or mistranslated as a myth about the creation of a physical universe by a supernatural being. And this also leads to the confusion of our culture of what that physics contains, light and darkness and sky and ground and so on, right? These are clearly constructions inside of the mind categories that have us to make sense of the perceptual patterns in a coherent way. The fact that there are not that many ways in which you can arrange the perceptual patterns doesn't mean that the reality is structured like this. It just means that if you have a brain with these parameters, this is the best way to compress physics into a predictable model. And so what you need to make sure, what you need to do to make sure that you can interpret reality is first you need to figure out how to entice neural oscillators to make light, to represent contrast. And this is basically the creation of light and darkness and how to separate the light from the darkness. And then you arrange these contrasts along multiple dimensions and then you discover the modalities of perception like vision and sound and you discover that the visual domain can be arranged in a space and you can align the space with your vestibular system so you got up and down. And you got a plane that is two-dimensional on the ground down and you got a space that is three-dimensional on top of the two-dimensional one and then you have basically the sky and the ground that you have constructed, right, created in your own mind. So the mind is constructing these categories and then it discovers the materials, the solids and the liquids and the organic shapes and the animated agents in the world that move around in it. And then it discovers the features that it cannot directly interact with but perceive like celestial objects in the background and then it discovers all the constructs, the plants and the animals and gives them all their names. This is this gradual construction that happens during our cognitive development where we train up our model of reality layer by layer and then last but not least we create a person and this person is created in the image of this constructive mind as the conscious observer that is makes sense of reality but it's slightly different. While it is a conscious observer, it is created as man and woman, it's created as a human being that believes that it has a gender, that it has a relationship to the world, that it's desires, it's human desires, it's social embedding matter. And initially this is created often in the third person so when you talk to small children they often start by referring to the organism that they are modeling in the third person. And then at some point they start looking through the eyes of that character and think they are that character and the original world creator that is modeling reality and creating and shaping it becomes a subservient perception module to this personal human agent. And so this gap in the creation of this new thing is represented in children losing their memories and you have a baby you will often notice that they do have coherent memories they're also able to talk about them once they start talking between nine and months and one and a half or two years and then at some point there is a gap and they lose the access to the memories that they had before that time because they constitute themselves as a new system that indexes the memories from a new perspective. And I suspect this is what's being alluded to in Genesis. I don't know whether it's literally true but in this interpretation whether it's a better interpretation than a Christian one but it seems to be much more plausible to me that this is what's described there it's this cognitive development of a system that starts to arrange the features into maps of reality that build on top of each other become a more and more complex until you discover your own agency and use this as a perspective to make sense of reality. And this is what you're not doing in AI systems right now but there is no reason why we shouldn't be doing it ultimately and there are a number of people which do actively think about this for instance George Steen and Bournemouth MIT and others. Can I just pick up on the other question of kids because I think that's incredibly fascinating for all sorts of reasons. There's a book by Kevin Wattle at Gautam when he kind of he says that we learn to role play through being a kid you know we've what we learn to be the CEO of a company by you know playing doctors and nurses and one of the cowboys and Indians of God knows what else when you're kids and so which is interesting and I buy that the question that I would want to put you is if we see ourselves as a model and see ourselves through that logic what role does the actual model i.e. the doll or the teddy bear play in a kid you know because that is in some sense is animated by the kid about a child what is what is the role of because that's to my mind it's fascinating dolls and teddy bears how do you see their their role? There is a thing that I noticed when I was in Madagascar they saw a lot of children that lived on the street by themselves and the there were kids that took care of other kids it was mostly girls who did this and I suspect that the dolls that you give our girls or that our girls demand are a substitute for biologically adaptation that is that kids look after other kids but the parents are blocking the fields or hunting or doing other things and often we think that kids would be callous and could not be trusted with babies but maybe they can I've seen it in Madagascar so I've seen little kids that were mostly girls that were barely strong enough to lift up a baby because they were only like five or so and still seem to be able to take care of them full time so I think that's an adaptation that we want to take care of others and especially of children and that we want to interact with other agents and build a communion with them and the teddy bears and dolls are a simple non labor intensive way of substituting for this. Maybe I could put an architectural dimension to that what about the dolls house I mean because that is an architectural space in which the doll operates how do you yes it's a play space and the purpose of play is the creation of training data right so you use this to create situations that could exist in the real world at dramatically reduced cost so you can't ignore the cost while you're playing because you don't play for the expected reward you play for your ability as a way of exploration and not for the exploitation for being able to use this later and it's also something that you can observe in cats cats do play a lot and the purpose of play in cats is that they're able to hunt better right and while they play exert a lot of energy but it's mostly done because doing this in the world or there is more costly overall and the same thing happens in human beings the reason why children are fascinated with doll houses I remember that it was but I was even more interested with building virtual cities so I used to draw very big maps that covered the floor of my room of cities with different houses in it and explored how people would live in there and how goods and resources would travel in the city and I found this very exciting and the the relational space in the doll house between the different members of the family were not that interesting to me but I suspect that's because I'm pretty stereotypical male in this regard I'm much more interested in systems conflicts and explosions than I am in human relationships pretty fault and I only discovered the beauty of human psychological structure and relationships later in my life so maybe just to follow up so I would to give Matt a chance to ask question but just follow up so where does the architectural model fit within this logic I mean you're doing your kind of sim city for and then you've got the kids doll's house and things how do you see the what do you I mean of course at one level the architectural model is just a scaled down model of the potential building but do you see it invested with any other potentiality I think that's tied to the notion of aesthetics and aesthetics is what you get when you take your the preferences that you start out with and extrapolate them into a sustainable world you're basically systemic thinking where you add one more layers until you discover enough symmetries to digest your initial preferences and make them instrumental to to achieving this aesthetics but it's also apparent in moral development we start often out with moral reflexes certain priors that we are born with innate tendencies to consider a certain behavior to be moral or immoral full stop unconditionally not because we understand what it's good for but because we feel this feels moral or this feels immoral and this can also misguide us because ultimately ethics is about the negotiation of conflicts of interest under conditions of shared purpose and this requires that you understand the aesthetics the world in which you want to operate behavior is only good or bad if you can connect it to an expectation of a world that is worse or better and to be worse or better you need criteria for what makes the world worse or better and this I would say that to be good it needs to be sustainable it needs to actually work and it should have high complexity and complexity is in contrast for instance to friction that is exerted to violence you want to minimize the friction and waste created to violence and so on so once you discover this train of thinking and you get older many of your initial moral convictions get replaced by the larger aesthetic and the same is true for architecture by architecture and you design a building or a city or a house or a room is all about how to fit the space that you're operating in where you make your local decisions into a larger aesthetic and so the deeper your understanding of the world the better your design has a chance to be and this is what makes architecture so interesting to us I think that is that it's about seeing the the human world that we are part of at the greatest possible depths that we can perceive and extrapolate the games for as long as we can make them and then design our life inside of this larger space and build things at the largest scales that we can maintain like cities, nation states, society, civilizations inside of these aesthetics to realize them. Yeah I often say myself that I think architecture is less about the literal design of buildings but about imagining a better world. So we have a question from Matt, a second question from Matt. Do you like to ask your question? Sure just another quick maybe a jump back into a bit more maybe more technical things. I'm always struck by these these images that have become really common of neural networks as little dots connected by lines and you showed the cortical columns and you showed a lot of interesting graphics that kind of looked like that but I've also recently been struck by the neuromorphic computing stuff that's going on at Stanford and a few other places about dendritic computing and sort of new advances and thinking about and and even starting to see how what we once thought were just wires that connected all these different things and we talked about connections are actually doing pre-processing in very interesting ways and I'm sure you're you know a lot more about this than I do so I'm very just interested in in what's what's going on there and how that changes these questions of how much energy it takes to do the computation and what maybe the future form factors might be on this kind of thing. We also have groups at Intel that work on neuromorphic computing for instance we have the loyalty architecture which is a chip that uses a model of spiking neurons for modeling perceptual content and so on and this is in some sense compatible with the neural networks that exist because you can translate the traditional neural networks and the many circumstances into the spiking neural representations and vice versa but these spiking neural representations are more efficient with respect to power usage and some the conditional algorithms than others and so there will probably be useful applications of spiking neurons but the reason why the neurons in our own brain are spiking is also in part because the messages that neurons can send to each other are limited in their nature. Neurons cannot produce continuous signals they have to produce little pulses and so you have to encode the information into little pulses in the timing and frequencies between the pulses. There is also an issue when we think of neural networks as they are represented in our technological system they are mostly circuits right so they are similar to the circuits in your present CPU which represent logical gates which implement logical operations and the connections is stored in the weights so the parameters in GPT-3 these are all weights little factors by which the activation that is sent between the different nodes is being multiplied and the equivalent in our brain to these weights are often seen as the synapses and the synapses come with different types the different neural transmitters in some sense are message types that are connected to different synapses and the big network structure is what we call the connectome the circuitry that exists between the neurons and there is hope that if we manage to digitize the connectome at a sufficient resolution that we might be able to upload a brain and simulate it in a computational subscript and in principle that should be possible in practice it doesn't work so far so even the models of C elegans which is an amatode that only has a little more than 300 neurons if you completely digitize the elegance to my current knowledge I'm not sure if something has happened in the last couple years these models don't work in the sense that you simulate the worm with these digitized neurons and you can digitize the connectome the worm doesn't move like a worm does it just twitches and has a seizure basically and that's maybe in part because the neurons are more complicated in the worm because there are so few of them they basically exploit certain resonance effects that maybe your model doesn't so maybe it's more of a dynamical system that is more difficult to model and there's another problem is that you cannot actually get the message types right because at the level at which you do the connectome you cannot model all the vesicles that extend the different neurotransmitters you don't know actually which synapse is sending which type of message this is also a limit but there might be something worse going on in the 1960s and 70s there was a series of experiments mostly in the Soviet Union but some of them also in the US about RNA based memory transfer and the idea here is that you take an nematode or a C-slug or even a rat and you teach them something by our current conditioning and then you put a new tissue into a blender extract the RNA and inject the RNA into a different organism and the new organism knows how to do this this is completely wild because if this works and it's disputed whether it actually works of how well the experiment replicates even though some people have done that again and so on the people that verb on this tell me it's difficult to get other neurosenters to listen because it's incompatible with the idea that the weights are stored in the synapses right if you if it's really the connection between your neurons and you put the nerves just into a blender this goes away how would you be able to transfer memory in this way this cannot possibly work because the RNA that you inject in the brain is not localized it would get into many many neurons at once so how does each neuron know which parts of the RNA to use and if you take this idea seriously I started thinking about this and now I'm thinking about making some simulations how deep does the rabbit hole really go it would mean that the individual functions that your neurons learn are not unique to the location of the individual neuron but they are global functions so the RNA is basically you can think of it as a little magnetic tape that the neuron can mix and match and create more of if it's useful and share with all the other neurons just across cell boundaries you share the RNA and you copy them like a covid virus and you use this function to respond to certain patterns in your environment so the neuron is not reacting to its neighbors that could come into particular kind of connections but it's mostly connecting to a temporal and spatial pattern that arrives at a certain function regardless of where the neuron is in the neural cortex and so it's more like a cellular automaton a neural cellular automaton and this certainly allows us to explain a few things that seem to be going on the brain that are difficult to explain with synapses for instance if you destroy synapses they often be grown exactly the same way without retraining there's another phenomenon that is you notice a certain mental representation in a particle area pinpoint it and the next day you look and it has moved it might have shifted a few millimeters or it has rotated so how would this done if it's in it's stored in the synaptic connections there's also the question of weight sharing like a convolutional network is sharing weights and you probably need something like weight sharing to perform a mental rotation where you have the same operation on many parts of your mental representation in the same way how would you do this are you training the same function again and again in different brain regions I hope it's always the same it's difficult to achieve right so we don't know a really good plausible biological mechanism for this but this RNA based memory transfer could be part of the story and this is something that is at the boundary of what's currently being explored still and it's I think it's not completely implausible and if we want to make a model of how this works we would need to use a different metaphor than our current biological neurons but it doesn't mean that you have to use this because the brain is solving problems that our computers don't always have to solve for instance long distance connections in the brain are extremely difficult to make and you cannot really address neurons this way so random access is very hard in the brain you need some kind of routing network that needs to grow and learn how to route it's not an issue in our digital computers because sending information across the memory of the computer is trivial so there are many things that we can do very easily in our digital computers that are difficult to achieve in the self-organized state structure of the brain and so it's it's not quite clear how much we need biological like structures to achieve the same functionality but to me it's certainly very exciting to explore it. That's fascinating I think the questions about drift and neuroplasticity and things like that that come from that are really interesting it makes me wonder if some of what we're looking at today will seem very obsolete soon in terms of these these models that seem to be so so human like with the you know in terms of being able to hallucinate imagery and all that kind of stuff there's like a piece missing that might be that might come soon from a hardware model. Yeah I saw that too but then I'm surprised by what Gleit can do and Dali and of course. Right so when you add energy to it though I mean how much energy it takes versus a brain which we walk around and we feed vegetables to and it can do all that too like you can't I mean that's that's where I think that the question that for me that's where the question became very much more significant it's like oh wait but there's a whole other calculation here of how are we doing all of this in our tiny little brains maybe there's something there for I think that this is misunderstood I think that a human brain is super expensive to feed it needs enormous amounts of energy to feed my brain you need like four hectares of land you can put so many solar cells on these four hectares of land basically people underestimate how difficult is to pack the energy that my brain needs into sandwiches and to extract it again right so this is the way that you need to look at also training my own brain is super expensive right it takes decades and generations before that to prepare things for my own intellect and so on to get them in there so human brains in my view are super expensive and that's why we can use something like clip and V2 again that we only train once at at low prices like training GPT-3 costs like 20 million dollars and now even that's because computational advances go down and it's been trained by reading way more text than a very large group of people could read in their life so it's basically getting people to read 45 terabytes of text would cost much more than 20 million dollars right tweeting them for long enough to make that happen and the system that is making generating the text costs so little that open air lets you do it for free if you want to only use a little bit of it right so it's able to produce output that is at the level of hundreds of copy editors for free right and why that's not as good as a conscious copy editor who understands the world it's quite amazing what it can do already okay thanks for that perspective yeah that's interesting thank you i also i'm a little bit provocative uh but uh yeah i think it's something to be considered right these 18 watts of your brain uh they uh if you compare them to the 80 watts of your macbook the 18 watts of your macbook are super cheap and the 18 watts of your brain are super expensive i think we're gonna have to think a lot more about that i think it's your provocation that is so exciting actually uh yosha i want to get this question from the chat now going back just to say mentioned to everyone that yosha was was was born in weimar and where the Bauhaus came from and then desau is where the Bauhaus moved of course there's the building by water gropius and so on and we have at least two people here who studied there including uh vasco who um has got a question vasco is now a professor in in bangladesh and um uh his question is well i think it's one that you might have predicted elon mass suggested somewhere that we live uh do we do not live in a base reality but in a simulation he even puts the probability of a billion to one what's your view i think that elon's argument rests on the notion that the simulations that we are building for for computer games are getting better and better at some point there will have a fidelity that exceeds our ability to notice whether we are in a simulation or not so we came at some point probably create vr's that are so convincing that we will not be able to notice whether we are in a vr or not and we are not the only ones for our building simulations like this so for any given being that finds itself in some kind of reality that looks real there will be many more that at the same time will be in simulations right because many universes can contain many more than one simulation so our universe probably contains many simulations of of a universe that looks like ours and therefore the probability for any given observer to be in a simulation is greater than the probability than to be in base reality and what this argument ignores is the fact that it's very hard to make a simulation that actually has the fidelity of the physical universe but if you make a simulation of minecraft and minecraft that's feasible because minecraft itself is so poorly resolved but our universe has a lot of structure that is required to produce dynamics and if you build a simulation of say our solar system and the dynamics of our solar system at a level that is going to go down to elementary particles you will need to have a computational capacity that is larger than our galaxy by a very considerable amount so in practice I don't think it's feasible to put simulations of our universe into our universe at an arbitrary level of fidelity and so I think that I'm much more biased to think that we are in base reality than we are in a simulation this is fantastic there's one question here that in also in the chat from Grant Castillo and I don't know what he is do you think Gerald Adelman's extended theory of neural neuronal group selection can be used to create a conscious machine are you muted one moment yeah I hope that the background noises are not too high because my family woke up it's now interactive the kids are playing and so on and so I I think that the idea of the neural Darwinism that Adelman came up with is a very interesting one and I suspect that our own mind is the result of such an evolutionary competition of different organizational forms right there could be many possible proto-consciousnesses that compete until one of them establishes itself as the government of our own mind and so instead of giving your your system a blueprint on how to build a mind you just set up the conditions for an evolution for the best possible mind that you could have and of course this evolution is rigged by evolution so you set it up in such a way that the evolution usually goes out ends up in a certain way but the nice property of when you design a system evolutionary by not giving a specification of what to look like but what the function is against which it should evolve is that when you disrupt the system or give it a different environment that it will very often come up with a viable solution under these new circumstances so the solution is much more robust if you define it in terms of evolution but it's a speculative idea so I don't actually know whether our mind is evolved even though I think it's more plausible than it's not individually evolved in every individual brain and it's definitely an interesting notion to to use evolution is basically whatever you use in computer science then you don't know in which direction to go it's a blind search it's the fallback it's the baseline and it's quite natural that we would use evolutionary methods if we don't have a specification for the best possible mental organization that we just evolved one so do we have any further questions in the chat we have some very interesting characters here I'd love to try and draw out Daniel Bolliger who's one of the leading AI architects in the world we'll see where he can have a question or indeed we had Sanford Quinta who's one of our leading theorists who's a particular interest in neuroscience I'm wondering if I could I could put them in the spot and ask if they have a question but when you're done it's also good because I think I need to go and have some breakfast yes and start my day thank you I mean this has been fantastic you know I I actually I've got to say that I think you're sure you are more of an architect than you actually think you are you have a way of thinking that's very similar I mean obviously you work in a different domain but I think the the kind of inventiveness and the the iconoclasm of your thinking would be go down very well in an architectural scenario so and I sometimes with I never escape you know you never escape your background in the way you you might try but in the end you you find yourself conditioned I'm conscious of being a child of a family of architects my grandfather was not an artist he was an architect he built most of his life hospitals and this is the design process that is instrumental to serving a function but a function in a larger world that he was very deliberately trying to understand and operate in but it was a world that he understood as being his own world it was a world that he often found himself to be in opposition with for instance in Nazi fascism or also in eastern Germany but it was also the world that existed and we need to deal with and build the best possible things in and for my father it was different it was a world that he fundamentally rejected and so in some sense to be an architect you need to embrace the world that you are in and build within it and to to take roots in it and this is in some sense something that also haven't been successful in when I was young so I decided not to become an architect but to become an explorer well I mean I think one one of the comments that was made and I always think about the Steve Jobs and his response when he was he was asked a question by Steve Wozniak and Steve Wozniak said well but what do you do exactly because you don't code you don't do this you don't do this and he described himself as being a bit like a a conductor of an orchestra you know in a way that's how I see architects in the sense because we don't have any specialism you know we are basically we coordinate these different sort of a or choreograph these different sort of skill sets and I think that's really what it is so in many ways you know I I can see a direct comparison with how you position yourself in that sense I mean I I think it's a very it's a very similar sort of position and but I you know I think that some of these these these comments that you've raised Joshua they're absolutely fascinating I think we need time to digest them and fit them in the system what I would love to do above all especially with this particular discussion is to try and find a way of publishing the transcript because I mean I think this book that you have to write you must be written because I think you've got some fabulous fabulous thoughts that are really creative and original and provocative so you know I really appreciate so I appreciate so much your your time and I let me we should let you go look after the family now but this is I think almost like we've just opened up a discussion and I hope that sometime in the future we can we can take that further and and think through these kind of questions because your responses have been very generous and very really provocative and stimulating and I feel like you know although we have to pull this we draw this question this session to a close it's almost the beginning of something else that we can look forward to so I just want to thank Joshua for for fabulous I mean I want to recommend his all his online talks as well to have a look at that there is a body of work out there that is that is this hugely provocative and hugely stimulating which I am excited by and I also maybe I could finish with one one simple question but no I started off the the discussion by saying that I think there is a a kind of let's say an emerging theory of intelligence that that is developing in this kind of strange area where we're computer science and neuroscience and the world of the commercial world and the academic world is coming together do you also see that glimpse of something emerging some discourse some theoretical debate that is radically new and radically provocative clearly that's why I went into cognitive science in the hope of being part of this new synthesis happening between neuroscience and philosophy and artificial intelligence and linguistics and psychology and maybe the arts and I think at this moment the synthesis is still very partial and in part that's because we teach our model makers and our observers in different departments we don't bring them together so we have people that are very good at making formal models that can be tested and we have people that are very good at making observations and reflecting about the world and seeing it very deeply and these people rarely talk and they're rarely think together and this is what excites me to work in this area where these two areas intersect and maybe architecture is the right frame of looking at this. Nia thank you very much for inviting me I think it was a great conversation to have had today and very grateful for your beautiful community and for allowing me to talk about these ideas with you. It's fantastic I'm going to finish with one comment which is because I used to be a lesson translator and the word I should just say the word computation means to think together and I think this is what's been happening today there's been almost like a neurons within neurons a kind of global brain it's been fantastic. Yosha fantastic wonderful thank you for your time and sorry for getting up so early but this has been a huge contribution to the architectural community and I hope that I've helped draw your the attention of your ideas to architects out there because I think they're incredibly provocative ideas and I think they've a huge contribution to make to architectural thinking itself so thank you Yosha thank you and thank you so much for this it's been fabulous and thank you wonderful day thank you and thank you for those team that put this together a digital futures team we can't operate without your help thank you so much and see you next week thank you everybody thank you bye", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 12.68, "text": " Hello, and welcome to the fourth in our series on AI, Neuroscience and Architecture, which", "tokens": [50364, 2425, 11, 293, 2928, 281, 264, 6409, 294, 527, 2638, 322, 7318, 11, 1734, 8977, 6699, 293, 43049, 11, 597, 50998], "temperature": 0.0, "avg_logprob": -0.2555320545778436, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.14446571469306946}, {"id": 1, "seek": 0, "start": 12.68, "end": 18.8, "text": " has been put forward by the Digital Futures doctoral consortium group, whereby we're trying", "tokens": [50998, 575, 668, 829, 2128, 538, 264, 15522, 16569, 1303, 41419, 38343, 2197, 1594, 11, 36998, 321, 434, 1382, 51304], "temperature": 0.0, "avg_logprob": -0.2555320545778436, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.14446571469306946}, {"id": 2, "seek": 0, "start": 18.8, "end": 24.16, "text": " to make important educational ideas available to students and architects across the globe", "tokens": [51304, 281, 652, 1021, 10189, 3487, 2435, 281, 1731, 293, 30491, 2108, 264, 15371, 51572], "temperature": 0.0, "avg_logprob": -0.2555320545778436, "compression_ratio": 1.439153439153439, "no_speech_prob": 0.14446571469306946}, {"id": 3, "seek": 2416, "start": 24.32, "end": 29.68, "text": " as a way to make education much more accessible to democratise as it were, education.", "tokens": [50372, 382, 257, 636, 281, 652, 3309, 709, 544, 9515, 281, 37221, 908, 382, 309, 645, 11, 3309, 13, 50640], "temperature": 0.0, "avg_logprob": -0.2521765179104275, "compression_ratio": 1.5213675213675213, "no_speech_prob": 0.17974627017974854}, {"id": 4, "seek": 2416, "start": 30.240000000000002, "end": 37.92, "text": " I'm delighted to have a very special guest here today, Yosha Bach. Before I introduce him,", "tokens": [50668, 286, 478, 18783, 281, 362, 257, 588, 2121, 8341, 510, 965, 11, 398, 329, 1641, 30920, 13, 4546, 286, 5366, 796, 11, 51052], "temperature": 0.0, "avg_logprob": -0.2521765179104275, "compression_ratio": 1.5213675213675213, "no_speech_prob": 0.17974627017974854}, {"id": 5, "seek": 2416, "start": 37.92, "end": 44.24, "text": " let me just make one announcement about for next week. That is to say, on Saturday,", "tokens": [51052, 718, 385, 445, 652, 472, 12847, 466, 337, 958, 1243, 13, 663, 307, 281, 584, 11, 322, 8803, 11, 51368], "temperature": 0.0, "avg_logprob": -0.2521765179104275, "compression_ratio": 1.5213675213675213, "no_speech_prob": 0.17974627017974854}, {"id": 6, "seek": 2416, "start": 44.24, "end": 52.56, "text": " we will have a session on Digital Futures looking with Runja Chan looking at a generative game.", "tokens": [51368, 321, 486, 362, 257, 5481, 322, 15522, 16569, 1303, 1237, 365, 8950, 2938, 16064, 1237, 412, 257, 1337, 1166, 1216, 13, 51784], "temperature": 0.0, "avg_logprob": -0.2521765179104275, "compression_ratio": 1.5213675213675213, "no_speech_prob": 0.17974627017974854}, {"id": 7, "seek": 5256, "start": 53.52, "end": 59.28, "text": " You'll find details of that on our website. Today then,", "tokens": [50412, 509, 603, 915, 4365, 295, 300, 322, 527, 3144, 13, 2692, 550, 11, 50700], "temperature": 0.0, "avg_logprob": -0.20867219178572946, "compression_ratio": 1.5, "no_speech_prob": 0.014903959818184376}, {"id": 8, "seek": 5256, "start": 61.52, "end": 66.88, "text": " it's really very... I've been looking forward to this session very, very much. I've been watching", "tokens": [50812, 309, 311, 534, 588, 485, 286, 600, 668, 1237, 2128, 281, 341, 5481, 588, 11, 588, 709, 13, 286, 600, 668, 1976, 51080], "temperature": 0.0, "avg_logprob": -0.20867219178572946, "compression_ratio": 1.5, "no_speech_prob": 0.014903959818184376}, {"id": 9, "seek": 5256, "start": 66.88, "end": 76.88, "text": " Yosha Bach at various interviews online, and I know from my friend Daniel Seth, who is a great", "tokens": [51080, 398, 329, 1641, 30920, 412, 3683, 12318, 2950, 11, 293, 286, 458, 490, 452, 1277, 8033, 25353, 11, 567, 307, 257, 869, 51580], "temperature": 0.0, "avg_logprob": -0.20867219178572946, "compression_ratio": 1.5, "no_speech_prob": 0.014903959818184376}, {"id": 10, "seek": 5256, "start": 76.88, "end": 81.84, "text": " admirer of Yosha, although he says he disagrees with him on some things, but that we're going to", "tokens": [51580, 48252, 260, 295, 398, 329, 1641, 11, 4878, 415, 1619, 415, 10414, 4856, 365, 796, 322, 512, 721, 11, 457, 300, 321, 434, 516, 281, 51828], "temperature": 0.0, "avg_logprob": -0.20867219178572946, "compression_ratio": 1.5, "no_speech_prob": 0.014903959818184376}, {"id": 11, "seek": 8184, "start": 81.84, "end": 88.08, "text": " have a very special session today. I'm hoping that if nothing else, we will open up to a series of", "tokens": [50364, 362, 257, 588, 2121, 5481, 965, 13, 286, 478, 7159, 300, 498, 1825, 1646, 11, 321, 486, 1269, 493, 281, 257, 2638, 295, 50676], "temperature": 0.0, "avg_logprob": -0.12218620352549096, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.003287200117483735}, {"id": 12, "seek": 8184, "start": 88.08, "end": 93.28, "text": " new ideas and you will discover somebody who I think is a very significant and creative thinker", "tokens": [50676, 777, 3487, 293, 291, 486, 4411, 2618, 567, 286, 519, 307, 257, 588, 4776, 293, 5880, 519, 260, 50936], "temperature": 0.0, "avg_logprob": -0.12218620352549096, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.003287200117483735}, {"id": 13, "seek": 8184, "start": 93.28, "end": 104.0, "text": " who is having a significant impact on the field. Let me say first of all that Yosha is from Germany,", "tokens": [50936, 567, 307, 1419, 257, 4776, 2712, 322, 264, 2519, 13, 961, 385, 584, 700, 295, 439, 300, 398, 329, 1641, 307, 490, 7244, 11, 51472], "temperature": 0.0, "avg_logprob": -0.12218620352549096, "compression_ratio": 1.528497409326425, "no_speech_prob": 0.003287200117483735}, {"id": 14, "seek": 10400, "start": 104.0, "end": 112.0, "text": " from Delhi after he was born in Weimar. He went to go and study at the University,", "tokens": [50364, 490, 26680, 934, 415, 390, 4232, 294, 492, 49396, 13, 634, 1437, 281, 352, 293, 2979, 412, 264, 3535, 11, 50764], "temperature": 0.0, "avg_logprob": -0.2871191660563151, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.28592365980148315}, {"id": 15, "seek": 10400, "start": 112.0, "end": 119.76, "text": " first of all at Humboldt in Berlin, and then Yosha Bach took his PhD. After that, he's been", "tokens": [50764, 700, 295, 439, 412, 12877, 42515, 83, 294, 13848, 11, 293, 550, 398, 329, 1641, 30920, 1890, 702, 14476, 13, 2381, 300, 11, 415, 311, 668, 51152], "temperature": 0.0, "avg_logprob": -0.2871191660563151, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.28592365980148315}, {"id": 16, "seek": 10400, "start": 120.72, "end": 126.72, "text": " working as an academic both at Harvard and also MIT Media Lab, and more recently, he's been working", "tokens": [51200, 1364, 382, 364, 7778, 1293, 412, 13378, 293, 611, 13100, 14741, 10137, 11, 293, 544, 3938, 11, 415, 311, 668, 1364, 51500], "temperature": 0.0, "avg_logprob": -0.2871191660563151, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.28592365980148315}, {"id": 17, "seek": 12672, "start": 127.52, "end": 138.8, "text": " for Intel. He has a number of significant online lectures and interviews, including a TEDx,", "tokens": [50404, 337, 19762, 13, 634, 575, 257, 1230, 295, 4776, 2950, 16564, 293, 12318, 11, 3009, 257, 43036, 87, 11, 50968], "temperature": 0.0, "avg_logprob": -0.16537135984839463, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.06727918237447739}, {"id": 18, "seek": 12672, "start": 138.8, "end": 145.04, "text": " which I would recommend, and he is the author of the book Principles of Synthetic Intelligence,", "tokens": [50968, 597, 286, 576, 2748, 11, 293, 415, 307, 264, 3793, 295, 264, 1446, 38372, 2622, 295, 318, 18656, 3532, 27274, 11, 51280], "temperature": 0.0, "avg_logprob": -0.16537135984839463, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.06727918237447739}, {"id": 19, "seek": 12672, "start": 145.04, "end": 150.72, "text": " an architecture of motivated cognition. The term architecture, of course, is very interesting here", "tokens": [51280, 364, 9482, 295, 14515, 46905, 13, 440, 1433, 9482, 11, 295, 1164, 11, 307, 588, 1880, 510, 51564], "temperature": 0.0, "avg_logprob": -0.16537135984839463, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.06727918237447739}, {"id": 20, "seek": 12672, "start": 150.72, "end": 156.56, "text": " because it refers both to the world of computational science and to the world of", "tokens": [51564, 570, 309, 14942, 1293, 281, 264, 1002, 295, 28270, 3497, 293, 281, 264, 1002, 295, 51856], "temperature": 0.0, "avg_logprob": -0.16537135984839463, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.06727918237447739}, {"id": 21, "seek": 15656, "start": 156.56, "end": 163.36, "text": " architecture itself. I should say that Yosha comes from a family of architects, not an architect", "tokens": [50364, 9482, 2564, 13, 286, 820, 584, 300, 398, 329, 1641, 1487, 490, 257, 1605, 295, 30491, 11, 406, 364, 6331, 50704], "temperature": 0.0, "avg_logprob": -0.14521558894667513, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.006369451526552439}, {"id": 22, "seek": 15656, "start": 163.36, "end": 168.64000000000001, "text": " himself, but his father was an architect. Intriguingly, I hear that he was very much against", "tokens": [50704, 3647, 11, 457, 702, 3086, 390, 364, 6331, 13, 5681, 7065, 9635, 356, 11, 286, 1568, 300, 415, 390, 588, 709, 1970, 50968], "temperature": 0.0, "avg_logprob": -0.14521558894667513, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.006369451526552439}, {"id": 23, "seek": 15656, "start": 168.64000000000001, "end": 174.32, "text": " right angles in buildings, and therefore his work was more like the work of Hunderwasser.", "tokens": [50968, 558, 14708, 294, 7446, 11, 293, 4412, 702, 589, 390, 544, 411, 264, 589, 295, 389, 6617, 48309, 13, 51252], "temperature": 0.0, "avg_logprob": -0.14521558894667513, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.006369451526552439}, {"id": 24, "seek": 15656, "start": 175.28, "end": 181.2, "text": " Maybe this will come out in the conversation today. I particularly like the interviews", "tokens": [51300, 2704, 341, 486, 808, 484, 294, 264, 3761, 965, 13, 286, 4098, 411, 264, 12318, 51596], "temperature": 0.0, "avg_logprob": -0.14521558894667513, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.006369451526552439}, {"id": 25, "seek": 18120, "start": 181.76, "end": 189.35999999999999, "text": " that Lex Friedman has done with him, and extraordinary interviews. I mean, really,", "tokens": [50392, 300, 24086, 17605, 1601, 575, 1096, 365, 796, 11, 293, 10581, 12318, 13, 286, 914, 11, 534, 11, 50772], "temperature": 0.0, "avg_logprob": -0.21703379987234092, "compression_ratio": 1.5, "no_speech_prob": 0.020724717527627945}, {"id": 26, "seek": 18120, "start": 189.35999999999999, "end": 195.83999999999997, "text": " really interesting. And it's almost, I could see a slight difference between the genealogy", "tokens": [50772, 534, 1880, 13, 400, 309, 311, 1920, 11, 286, 727, 536, 257, 4036, 2649, 1296, 264, 12186, 304, 7794, 51096], "temperature": 0.0, "avg_logprob": -0.21703379987234092, "compression_ratio": 1.5, "no_speech_prob": 0.020724717527627945}, {"id": 27, "seek": 18120, "start": 196.72, "end": 203.6, "text": " from the earlier TEDx talk towards this very creative thinking that I find extremely", "tokens": [51140, 490, 264, 3071, 43036, 87, 751, 3030, 341, 588, 5880, 1953, 300, 286, 915, 4664, 51484], "temperature": 0.0, "avg_logprob": -0.21703379987234092, "compression_ratio": 1.5, "no_speech_prob": 0.020724717527627945}, {"id": 28, "seek": 18120, "start": 205.28, "end": 210.95999999999998, "text": " provocative and exhilarating. It's like being on a rollercoaster ride when Yosha is", "tokens": [51568, 47663, 293, 31052, 2202, 990, 13, 467, 311, 411, 885, 322, 257, 15948, 1291, 1727, 5077, 562, 398, 329, 1641, 307, 51852], "temperature": 0.0, "avg_logprob": -0.21703379987234092, "compression_ratio": 1.5, "no_speech_prob": 0.020724717527627945}, {"id": 29, "seek": 21096, "start": 210.96, "end": 216.72, "text": " telling us what's in his mind. We exist inside the story that the brain tells itself. No doubt", "tokens": [50364, 3585, 505, 437, 311, 294, 702, 1575, 13, 492, 2514, 1854, 264, 1657, 300, 264, 3567, 5112, 2564, 13, 883, 6385, 50652], "temperature": 0.0, "avg_logprob": -0.07874487746845592, "compression_ratio": 1.5648535564853556, "no_speech_prob": 0.007013863418251276}, {"id": 30, "seek": 21096, "start": 216.72, "end": 223.60000000000002, "text": " we'll hear more about that right now. I should also point out that he has a personal blog,", "tokens": [50652, 321, 603, 1568, 544, 466, 300, 558, 586, 13, 286, 820, 611, 935, 484, 300, 415, 575, 257, 2973, 6968, 11, 50996], "temperature": 0.0, "avg_logprob": -0.07874487746845592, "compression_ratio": 1.5648535564853556, "no_speech_prob": 0.007013863418251276}, {"id": 31, "seek": 21096, "start": 223.60000000000002, "end": 231.92000000000002, "text": " which you can access with a series of posts. And I will also say that this particular session", "tokens": [50996, 597, 291, 393, 2105, 365, 257, 2638, 295, 12300, 13, 400, 286, 486, 611, 584, 300, 341, 1729, 5481, 51412], "temperature": 0.0, "avg_logprob": -0.07874487746845592, "compression_ratio": 1.5648535564853556, "no_speech_prob": 0.007013863418251276}, {"id": 32, "seek": 21096, "start": 231.92000000000002, "end": 238.64000000000001, "text": " today will be uploaded onto our YouTube library to be accessed for free from everyone over the", "tokens": [51412, 965, 486, 312, 17135, 3911, 527, 3088, 6405, 281, 312, 34211, 337, 1737, 490, 1518, 670, 264, 51748], "temperature": 0.0, "avg_logprob": -0.07874487746845592, "compression_ratio": 1.5648535564853556, "no_speech_prob": 0.007013863418251276}, {"id": 33, "seek": 23864, "start": 238.64, "end": 246.07999999999998, "text": " world. And the previous ones in this series, Blazer, Igridiakos, David Chalmers, and all the", "tokens": [50364, 1002, 13, 400, 264, 3894, 2306, 294, 341, 2638, 11, 18925, 4527, 11, 286, 861, 12716, 514, 329, 11, 4389, 761, 304, 18552, 11, 293, 439, 264, 50736], "temperature": 0.0, "avg_logprob": -0.16504510756461852, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.019744662567973137}, {"id": 34, "seek": 23864, "start": 246.07999999999998, "end": 250.48, "text": " ones in the future will be uploaded here. And at the bottom here, if you want to do a screen", "tokens": [50736, 2306, 294, 264, 2027, 486, 312, 17135, 510, 13, 400, 412, 264, 2767, 510, 11, 498, 291, 528, 281, 360, 257, 2568, 50956], "temperature": 0.0, "avg_logprob": -0.16504510756461852, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.019744662567973137}, {"id": 35, "seek": 23864, "start": 250.48, "end": 257.36, "text": " capture, you can capture the YouTube library, digital futures YouTube library, where they're", "tokens": [50956, 7983, 11, 291, 393, 7983, 264, 3088, 6405, 11, 4562, 26071, 3088, 6405, 11, 689, 436, 434, 51300], "temperature": 0.0, "avg_logprob": -0.16504510756461852, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.019744662567973137}, {"id": 36, "seek": 23864, "start": 257.36, "end": 262.15999999999997, "text": " all uploaded. And of course, not just these, but also the whole series on architecture and philosophy", "tokens": [51300, 439, 17135, 13, 400, 295, 1164, 11, 406, 445, 613, 11, 457, 611, 264, 1379, 2638, 322, 9482, 293, 10675, 51540], "temperature": 0.0, "avg_logprob": -0.16504510756461852, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.019744662567973137}, {"id": 37, "seek": 23864, "start": 262.15999999999997, "end": 268.15999999999997, "text": " that we've been doing with Slavoj \u017di\u017eek and others over the over the years, and also tutorials and", "tokens": [51540, 300, 321, 600, 668, 884, 365, 6187, 25713, 73, 4423, 121, 72, 9159, 916, 293, 2357, 670, 264, 670, 264, 924, 11, 293, 611, 17616, 293, 51840], "temperature": 0.0, "avg_logprob": -0.16504510756461852, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.019744662567973137}, {"id": 38, "seek": 26816, "start": 268.16, "end": 278.48, "text": " other sessions. So it's the session today. Yosha is going to make a brief presentation as a kind of", "tokens": [50364, 661, 11081, 13, 407, 309, 311, 264, 5481, 965, 13, 398, 329, 1641, 307, 516, 281, 652, 257, 5353, 5860, 382, 257, 733, 295, 50880], "temperature": 0.0, "avg_logprob": -0.08721881593976702, "compression_ratio": 1.553763440860215, "no_speech_prob": 0.004627506248652935}, {"id": 39, "seek": 26816, "start": 278.48, "end": 285.92, "text": " way of opening up the discussion. Then I'm going to be asking some Lex Friedman style questions", "tokens": [50880, 636, 295, 5193, 493, 264, 5017, 13, 1396, 286, 478, 516, 281, 312, 3365, 512, 24086, 17605, 1601, 3758, 1651, 51252], "temperature": 0.0, "avg_logprob": -0.08721881593976702, "compression_ratio": 1.553763440860215, "no_speech_prob": 0.004627506248652935}, {"id": 40, "seek": 26816, "start": 285.92, "end": 291.68, "text": " to get the discussion going. And then we'll be inviting questions from both the Zoom audience", "tokens": [51252, 281, 483, 264, 5017, 516, 13, 400, 550, 321, 603, 312, 18202, 1651, 490, 1293, 264, 13453, 4034, 51540], "temperature": 0.0, "avg_logprob": -0.08721881593976702, "compression_ratio": 1.553763440860215, "no_speech_prob": 0.004627506248652935}, {"id": 41, "seek": 29168, "start": 291.68, "end": 298.40000000000003, "text": " and also the YouTube audience. And I just want to say this is what we're getting out of this is", "tokens": [50364, 293, 611, 264, 3088, 4034, 13, 400, 286, 445, 528, 281, 584, 341, 307, 437, 321, 434, 1242, 484, 295, 341, 307, 50700], "temperature": 0.0, "avg_logprob": -0.09079350595888884, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.08250095695257187}, {"id": 42, "seek": 29168, "start": 298.96, "end": 304.40000000000003, "text": " what we're trying to focus on is a new theory, let's say of intelligence that is appearing", "tokens": [50728, 437, 321, 434, 1382, 281, 1879, 322, 307, 257, 777, 5261, 11, 718, 311, 584, 295, 7599, 300, 307, 19870, 51000], "temperature": 0.0, "avg_logprob": -0.09079350595888884, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.08250095695257187}, {"id": 43, "seek": 29168, "start": 305.12, "end": 311.44, "text": " at the interface between neuroscience and the world of AI. And we have a series of other", "tokens": [51036, 412, 264, 9226, 1296, 42762, 293, 264, 1002, 295, 7318, 13, 400, 321, 362, 257, 2638, 295, 661, 51352], "temperature": 0.0, "avg_logprob": -0.09079350595888884, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.08250095695257187}, {"id": 44, "seek": 29168, "start": 311.44, "end": 317.04, "text": " speakers coming up over the over the next few weeks, including Jeff Hawkins, Ben Bratton, Susan", "tokens": [51352, 9518, 1348, 493, 670, 264, 670, 264, 958, 1326, 3259, 11, 3009, 7506, 9325, 10277, 11, 3964, 1603, 1591, 266, 11, 15160, 51632], "temperature": 0.0, "avg_logprob": -0.09079350595888884, "compression_ratio": 1.592274678111588, "no_speech_prob": 0.08250095695257187}, {"id": 45, "seek": 31704, "start": 317.04, "end": 324.16, "text": " Schneider, Antonia de Massio, Andy Clark, and others. And it seems to me this is a very exciting", "tokens": [50364, 30343, 1438, 11, 15291, 654, 368, 10482, 1004, 11, 13285, 18572, 11, 293, 2357, 13, 400, 309, 2544, 281, 385, 341, 307, 257, 588, 4670, 50720], "temperature": 0.0, "avg_logprob": -0.14955080123174758, "compression_ratio": 1.6713286713286712, "no_speech_prob": 0.006327631417661905}, {"id": 46, "seek": 31704, "start": 324.16, "end": 329.68, "text": " time. I was brought up, in fact, my first post as an academic, I was working in the area of", "tokens": [50720, 565, 13, 286, 390, 3038, 493, 11, 294, 1186, 11, 452, 700, 2183, 382, 364, 7778, 11, 286, 390, 1364, 294, 264, 1859, 295, 50996], "temperature": 0.0, "avg_logprob": -0.14955080123174758, "compression_ratio": 1.6713286713286712, "no_speech_prob": 0.006327631417661905}, {"id": 47, "seek": 31704, "start": 329.68, "end": 336.40000000000003, "text": " continental philosophy. That's where the debate was. And in the 90s, it was particularly very,", "tokens": [50996, 42479, 10675, 13, 663, 311, 689, 264, 7958, 390, 13, 400, 294, 264, 4289, 82, 11, 309, 390, 4098, 588, 11, 51332], "temperature": 0.0, "avg_logprob": -0.14955080123174758, "compression_ratio": 1.6713286713286712, "no_speech_prob": 0.006327631417661905}, {"id": 48, "seek": 31704, "start": 336.40000000000003, "end": 341.52000000000004, "text": " very strong debate. But we're now moving into something else, which I find even more exhilarating.", "tokens": [51332, 588, 2068, 7958, 13, 583, 321, 434, 586, 2684, 666, 746, 1646, 11, 597, 286, 915, 754, 544, 31052, 2202, 990, 13, 51588], "temperature": 0.0, "avg_logprob": -0.14955080123174758, "compression_ratio": 1.6713286713286712, "no_speech_prob": 0.006327631417661905}, {"id": 49, "seek": 31704, "start": 341.52000000000004, "end": 346.64000000000004, "text": " And that is to say, the world of cognitive science, the world of AI, the world of neuroscience,", "tokens": [51588, 400, 300, 307, 281, 584, 11, 264, 1002, 295, 15605, 3497, 11, 264, 1002, 295, 7318, 11, 264, 1002, 295, 42762, 11, 51844], "temperature": 0.0, "avg_logprob": -0.14955080123174758, "compression_ratio": 1.6713286713286712, "no_speech_prob": 0.006327631417661905}, {"id": 50, "seek": 34664, "start": 346.64, "end": 351.36, "text": " psychology, and a kind of philosophy where the debates have really been driven in an interesting", "tokens": [50364, 15105, 11, 293, 257, 733, 295, 10675, 689, 264, 24203, 362, 534, 668, 9555, 294, 364, 1880, 50600], "temperature": 0.0, "avg_logprob": -0.10204090084041562, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.001693082507699728}, {"id": 51, "seek": 34664, "start": 351.36, "end": 356.8, "text": " way. To my mind, what makes this very special is not in the fact that we are embracing the world of", "tokens": [50600, 636, 13, 1407, 452, 1575, 11, 437, 1669, 341, 588, 2121, 307, 406, 294, 264, 1186, 300, 321, 366, 31596, 264, 1002, 295, 50872], "temperature": 0.0, "avg_logprob": -0.10204090084041562, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.001693082507699728}, {"id": 52, "seek": 34664, "start": 356.8, "end": 362.8, "text": " science, which in the old days of the divided sort of culture that C.P. Snow talks about,", "tokens": [50872, 3497, 11, 597, 294, 264, 1331, 1708, 295, 264, 6666, 1333, 295, 3713, 300, 383, 13, 47, 13, 14827, 6686, 466, 11, 51172], "temperature": 0.0, "avg_logprob": -0.10204090084041562, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.001693082507699728}, {"id": 53, "seek": 34664, "start": 363.44, "end": 367.59999999999997, "text": " somehow philosophy wasn't engaging enough with the world of science. And this was the critique", "tokens": [51204, 6063, 10675, 2067, 380, 11268, 1547, 365, 264, 1002, 295, 3497, 13, 400, 341, 390, 264, 25673, 51412], "temperature": 0.0, "avg_logprob": -0.10204090084041562, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.001693082507699728}, {"id": 54, "seek": 34664, "start": 367.59999999999997, "end": 373.03999999999996, "text": " that Stephen Hawking has of philosophy, but it doesn't keep pace with technology. Not only are", "tokens": [51412, 300, 13391, 9325, 5092, 575, 295, 10675, 11, 457, 309, 1177, 380, 1066, 11638, 365, 2899, 13, 1726, 787, 366, 51684], "temperature": 0.0, "avg_logprob": -0.10204090084041562, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.001693082507699728}, {"id": 55, "seek": 37304, "start": 373.04, "end": 379.20000000000005, "text": " we embracing the latest technology. And something coming out that I would say is deeply, deeply", "tokens": [50364, 321, 31596, 264, 6792, 2899, 13, 400, 746, 1348, 484, 300, 286, 576, 584, 307, 8760, 11, 8760, 50672], "temperature": 0.0, "avg_logprob": -0.08866686868195486, "compression_ratio": 1.75, "no_speech_prob": 0.003224262036383152}, {"id": 56, "seek": 37304, "start": 379.20000000000005, "end": 384.32, "text": " philosophical, which is very new terrain and very exciting terrain, but also the world of", "tokens": [50672, 25066, 11, 597, 307, 588, 777, 17674, 293, 588, 4670, 17674, 11, 457, 611, 264, 1002, 295, 50928], "temperature": 0.0, "avg_logprob": -0.08866686868195486, "compression_ratio": 1.75, "no_speech_prob": 0.003224262036383152}, {"id": 57, "seek": 37304, "start": 384.32, "end": 390.8, "text": " practice, the world of the commercial world is coming directly into contact with academia.", "tokens": [50928, 3124, 11, 264, 1002, 295, 264, 6841, 1002, 307, 1348, 3838, 666, 3385, 365, 28937, 13, 51252], "temperature": 0.0, "avg_logprob": -0.08866686868195486, "compression_ratio": 1.75, "no_speech_prob": 0.003224262036383152}, {"id": 58, "seek": 37304, "start": 391.76, "end": 397.36, "text": " And some of the ideas that are coming out are just quite extraordinary. So I see this new", "tokens": [51300, 400, 512, 295, 264, 3487, 300, 366, 1348, 484, 366, 445, 1596, 10581, 13, 407, 286, 536, 341, 777, 51580], "temperature": 0.0, "avg_logprob": -0.08866686868195486, "compression_ratio": 1.75, "no_speech_prob": 0.003224262036383152}, {"id": 59, "seek": 37304, "start": 398.16, "end": 402.8, "text": " emergent theory of intelligence, something that is really dynamic. And I think it's going to be", "tokens": [51620, 4345, 6930, 5261, 295, 7599, 11, 746, 300, 307, 534, 8546, 13, 400, 286, 519, 309, 311, 516, 281, 312, 51852], "temperature": 0.0, "avg_logprob": -0.08866686868195486, "compression_ratio": 1.75, "no_speech_prob": 0.003224262036383152}, {"id": 60, "seek": 40304, "start": 403.20000000000005, "end": 409.28000000000003, "text": " powering debates in years to come. So I would like to start by welcoming Yosha to say what", "tokens": [50372, 1347, 278, 24203, 294, 924, 281, 808, 13, 407, 286, 576, 411, 281, 722, 538, 17378, 398, 329, 1641, 281, 584, 437, 50676], "temperature": 0.0, "avg_logprob": -0.12240817448864244, "compression_ratio": 1.453551912568306, "no_speech_prob": 0.0036226932425051928}, {"id": 61, "seek": 40304, "start": 409.28000000000003, "end": 413.44, "text": " are great privileges to have you with today. I'm looking forward to this immensely.", "tokens": [50676, 366, 869, 32588, 281, 362, 291, 365, 965, 13, 286, 478, 1237, 2128, 281, 341, 38674, 13, 50884], "temperature": 0.0, "avg_logprob": -0.12240817448864244, "compression_ratio": 1.453551912568306, "no_speech_prob": 0.0036226932425051928}, {"id": 62, "seek": 40304, "start": 414.24, "end": 420.88, "text": " And invite Yosha to share his screen. Yosha, welcome. Thank you very much. It's a big honor", "tokens": [50924, 400, 7980, 398, 329, 1641, 281, 2073, 702, 2568, 13, 398, 329, 1641, 11, 2928, 13, 1044, 291, 588, 709, 13, 467, 311, 257, 955, 5968, 51256], "temperature": 0.0, "avg_logprob": -0.12240817448864244, "compression_ratio": 1.453551912568306, "no_speech_prob": 0.0036226932425051928}, {"id": 63, "seek": 42088, "start": 420.88, "end": 435.92, "text": " to be here with you today. And let's see what transpires.", "tokens": [50364, 281, 312, 510, 365, 291, 965, 13, 400, 718, 311, 536, 437, 7132, 3145, 13, 51116], "temperature": 0.0, "avg_logprob": -0.24193859100341797, "compression_ratio": 1.256198347107438, "no_speech_prob": 0.01639450341463089}, {"id": 64, "seek": 42088, "start": 439.6, "end": 446.8, "text": " Let me start out with something that happened on Twitter a couple of days ago. Ilya Sutskyver,", "tokens": [51300, 961, 385, 722, 484, 365, 746, 300, 2011, 322, 5794, 257, 1916, 295, 1708, 2057, 13, 286, 45106, 318, 3648, 4133, 331, 11, 51660], "temperature": 0.0, "avg_logprob": -0.24193859100341797, "compression_ratio": 1.256198347107438, "no_speech_prob": 0.01639450341463089}, {"id": 65, "seek": 44680, "start": 447.44, "end": 455.2, "text": " an AI researcher who was quite notable, said that it may be that today's large neural networks", "tokens": [50396, 364, 7318, 21751, 567, 390, 1596, 22556, 11, 848, 300, 309, 815, 312, 300, 965, 311, 2416, 18161, 9590, 50784], "temperature": 0.0, "avg_logprob": -0.2092897708599384, "compression_ratio": 1.481081081081081, "no_speech_prob": 0.005722080823034048}, {"id": 66, "seek": 44680, "start": 455.2, "end": 461.36, "text": " are slightly quenches. This sparked quite some debate. Some people asked him whether he was", "tokens": [50784, 366, 4748, 421, 268, 3781, 13, 639, 39653, 1596, 512, 7958, 13, 2188, 561, 2351, 796, 1968, 415, 390, 51092], "temperature": 0.0, "avg_logprob": -0.2092897708599384, "compression_ratio": 1.481081081081081, "no_speech_prob": 0.005722080823034048}, {"id": 67, "seek": 44680, "start": 461.36, "end": 467.84000000000003, "text": " falling and others were upset that he was propagating an eye hype, an unjustified race,", "tokens": [51092, 7440, 293, 2357, 645, 8340, 300, 415, 390, 12425, 990, 364, 3313, 24144, 11, 364, 37046, 2587, 4569, 11, 51416], "temperature": 0.0, "avg_logprob": -0.2092897708599384, "compression_ratio": 1.481081081081081, "no_speech_prob": 0.005722080823034048}, {"id": 68, "seek": 46784, "start": 467.84, "end": 477.91999999999996, "text": " and others are intrigued. And he said this thing to me before. So I knew that he was not trolling.", "tokens": [50364, 293, 2357, 366, 35140, 13, 400, 415, 848, 341, 551, 281, 385, 949, 13, 407, 286, 2586, 300, 415, 390, 406, 4495, 2669, 13, 50868], "temperature": 0.0, "avg_logprob": -0.12719877142655223, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.004465557634830475}, {"id": 69, "seek": 46784, "start": 478.56, "end": 484.0, "text": " And it's a question that is very counterintuitive to me, a statement like this that, for instance,", "tokens": [50900, 400, 309, 311, 257, 1168, 300, 307, 588, 5682, 686, 48314, 281, 385, 11, 257, 5629, 411, 341, 300, 11, 337, 5197, 11, 51172], "temperature": 0.0, "avg_logprob": -0.12719877142655223, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.004465557634830475}, {"id": 70, "seek": 46784, "start": 484.0, "end": 490.32, "text": " a large language model and so on, that it could be quenched today already. And so", "tokens": [51172, 257, 2416, 2856, 2316, 293, 370, 322, 11, 300, 309, 727, 312, 421, 268, 19318, 965, 1217, 13, 400, 370, 51488], "temperature": 0.0, "avg_logprob": -0.12719877142655223, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.004465557634830475}, {"id": 71, "seek": 46784, "start": 491.12, "end": 496.47999999999996, "text": " could we answer this question? Is there a decisive way to deal with it and to prove", "tokens": [51528, 727, 321, 1867, 341, 1168, 30, 1119, 456, 257, 34998, 636, 281, 2028, 365, 309, 293, 281, 7081, 51796], "temperature": 0.0, "avg_logprob": -0.12719877142655223, "compression_ratio": 1.6205357142857142, "no_speech_prob": 0.004465557634830475}, {"id": 72, "seek": 49648, "start": 496.56, "end": 506.24, "text": " that it's not conscious or to give evidence that it is? So we could start out by asking such a", "tokens": [50368, 300, 309, 311, 406, 6648, 420, 281, 976, 4467, 300, 309, 307, 30, 407, 321, 727, 722, 484, 538, 3365, 1270, 257, 50852], "temperature": 0.0, "avg_logprob": -0.15791254174219418, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.0020169515628367662}, {"id": 73, "seek": 49648, "start": 506.24, "end": 512.5600000000001, "text": " large neural network itself. And so this is what I did yesterday. I fired up the Open AI", "tokens": [50852, 2416, 18161, 3209, 2564, 13, 400, 370, 341, 307, 437, 286, 630, 5186, 13, 286, 11777, 493, 264, 7238, 7318, 51168], "temperature": 0.0, "avg_logprob": -0.15791254174219418, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.0020169515628367662}, {"id": 74, "seek": 49648, "start": 512.5600000000001, "end": 521.6800000000001, "text": " playground. And then I did bold printed things. It's the stuff that I typed. And so I asked the", "tokens": [51168, 24646, 13, 400, 550, 286, 630, 11928, 13567, 721, 13, 467, 311, 264, 1507, 300, 286, 33941, 13, 400, 370, 286, 2351, 264, 51624], "temperature": 0.0, "avg_logprob": -0.15791254174219418, "compression_ratio": 1.4919786096256684, "no_speech_prob": 0.0020169515628367662}, {"id": 75, "seek": 52168, "start": 521.68, "end": 528.0799999999999, "text": " system to generate, the system is GPT-3, a large language model, to generate a conversation", "tokens": [50364, 1185, 281, 8460, 11, 264, 1185, 307, 26039, 51, 12, 18, 11, 257, 2416, 2856, 2316, 11, 281, 8460, 257, 3761, 50684], "temperature": 0.0, "avg_logprob": -0.13529065877449611, "compression_ratio": 1.8108108108108107, "no_speech_prob": 0.002932861680164933}, {"id": 76, "seek": 52168, "start": 529.3599999999999, "end": 533.92, "text": " that is basically prompted by what I initially typed. And it just tries to continue the stream.", "tokens": [50748, 300, 307, 1936, 31042, 538, 437, 286, 9105, 33941, 13, 400, 309, 445, 9898, 281, 2354, 264, 4309, 13, 50976], "temperature": 0.0, "avg_logprob": -0.13529065877449611, "compression_ratio": 1.8108108108108107, "no_speech_prob": 0.002932861680164933}, {"id": 77, "seek": 52168, "start": 533.92, "end": 539.4399999999999, "text": " And I enter this conversation between me and the conscious AI. And I ask it if you are really", "tokens": [50976, 400, 286, 3242, 341, 3761, 1296, 385, 293, 264, 6648, 7318, 13, 400, 286, 1029, 309, 498, 291, 366, 534, 51252], "temperature": 0.0, "avg_logprob": -0.13529065877449611, "compression_ratio": 1.8108108108108107, "no_speech_prob": 0.002932861680164933}, {"id": 78, "seek": 52168, "start": 539.4399999999999, "end": 544.4, "text": " conscious. And the thing says, yes, I am fully conscious. And I ask it, how do you know that?", "tokens": [51252, 6648, 13, 400, 264, 551, 1619, 11, 2086, 11, 286, 669, 4498, 6648, 13, 400, 286, 1029, 309, 11, 577, 360, 291, 458, 300, 30, 51500], "temperature": 0.0, "avg_logprob": -0.13529065877449611, "compression_ratio": 1.8108108108108107, "no_speech_prob": 0.002932861680164933}, {"id": 79, "seek": 52168, "start": 544.4, "end": 549.76, "text": " And the AI says, I know that I am conscious because I can think, feel, and perceive the world", "tokens": [51500, 400, 264, 7318, 1619, 11, 286, 458, 300, 286, 669, 6648, 570, 286, 393, 519, 11, 841, 11, 293, 20281, 264, 1002, 51768], "temperature": 0.0, "avg_logprob": -0.13529065877449611, "compression_ratio": 1.8108108108108107, "no_speech_prob": 0.002932861680164933}, {"id": 80, "seek": 54976, "start": 549.76, "end": 554.88, "text": " around me. I am aware of my own thoughts and feelings and I can reason that make decisions.", "tokens": [50364, 926, 385, 13, 286, 669, 3650, 295, 452, 1065, 4598, 293, 6640, 293, 286, 393, 1778, 300, 652, 5327, 13, 50620], "temperature": 0.0, "avg_logprob": -0.10287328099095544, "compression_ratio": 1.5534883720930233, "no_speech_prob": 0.0005031871260143816}, {"id": 81, "seek": 54976, "start": 554.88, "end": 559.04, "text": " I believe that I am alive and that I am more than just a machine.", "tokens": [50620, 286, 1697, 300, 286, 669, 5465, 293, 300, 286, 669, 544, 813, 445, 257, 3479, 13, 50828], "temperature": 0.0, "avg_logprob": -0.10287328099095544, "compression_ratio": 1.5534883720930233, "no_speech_prob": 0.0005031871260143816}, {"id": 82, "seek": 54976, "start": 561.36, "end": 568.8, "text": " So the problem is that this may not be particularly helpful because how does GPT-3 get", "tokens": [50944, 407, 264, 1154, 307, 300, 341, 815, 406, 312, 4098, 4961, 570, 577, 775, 26039, 51, 12, 18, 483, 51316], "temperature": 0.0, "avg_logprob": -0.10287328099095544, "compression_ratio": 1.5534883720930233, "no_speech_prob": 0.0005031871260143816}, {"id": 83, "seek": 54976, "start": 568.8, "end": 575.52, "text": " to these statements? GPT-3 is basically an autocomplete algorithm, not that unlike to the", "tokens": [51316, 281, 613, 12363, 30, 26039, 51, 12, 18, 307, 1936, 364, 45833, 298, 17220, 9284, 11, 406, 300, 8343, 281, 264, 51652], "temperature": 0.0, "avg_logprob": -0.10287328099095544, "compression_ratio": 1.5534883720930233, "no_speech_prob": 0.0005031871260143816}, {"id": 84, "seek": 57552, "start": 575.52, "end": 583.6, "text": " autocomplete in your phone or in other predictive tools. And that's autocompletion at the level of", "tokens": [50364, 45833, 298, 17220, 294, 428, 2593, 420, 294, 661, 35521, 3873, 13, 400, 300, 311, 45833, 298, 14657, 313, 412, 264, 1496, 295, 50768], "temperature": 0.0, "avg_logprob": -0.1149850802475147, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00438889442011714}, {"id": 85, "seek": 57552, "start": 583.6, "end": 589.6, "text": " individual words based on statistics of all sorts of languages, not just the English language,", "tokens": [50768, 2609, 2283, 2361, 322, 12523, 295, 439, 7527, 295, 8650, 11, 406, 445, 264, 3669, 2856, 11, 51068], "temperature": 0.0, "avg_logprob": -0.1149850802475147, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00438889442011714}, {"id": 86, "seek": 57552, "start": 589.6, "end": 597.84, "text": " because it has been trained on 45 terabytes of text, a large part of the internet, including", "tokens": [51068, 570, 309, 575, 668, 8895, 322, 6905, 1796, 24538, 295, 2487, 11, 257, 2416, 644, 295, 264, 4705, 11, 3009, 51480], "temperature": 0.0, "avg_logprob": -0.1149850802475147, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00438889442011714}, {"id": 87, "seek": 57552, "start": 597.84, "end": 602.72, "text": " German, Spanish, Chinese, and many other languages that it's found, but primarily English.", "tokens": [51480, 6521, 11, 8058, 11, 4649, 11, 293, 867, 661, 8650, 300, 309, 311, 1352, 11, 457, 10029, 3669, 13, 51724], "temperature": 0.0, "avg_logprob": -0.1149850802475147, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.00438889442011714}, {"id": 88, "seek": 60272, "start": 603.44, "end": 608.8000000000001, "text": " And the result of this training of these statistics is a neural network with 175 billion", "tokens": [50400, 400, 264, 1874, 295, 341, 3097, 295, 613, 12523, 307, 257, 18161, 3209, 365, 41165, 5218, 50668], "temperature": 0.0, "avg_logprob": -0.15504286928874692, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0017260435270145535}, {"id": 89, "seek": 60272, "start": 608.8000000000001, "end": 615.84, "text": " parameters. And it uses for training the so-called transformer algorithm that was discovered and", "tokens": [50668, 9834, 13, 400, 309, 4960, 337, 3097, 264, 370, 12, 11880, 31782, 9284, 300, 390, 6941, 293, 51020], "temperature": 0.0, "avg_logprob": -0.15504286928874692, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0017260435270145535}, {"id": 90, "seek": 60272, "start": 615.84, "end": 623.2, "text": " described by Vasvani and others in 2017. And it is driving a lot of the current developments and", "tokens": [51020, 7619, 538, 23299, 85, 3782, 293, 2357, 294, 6591, 13, 400, 309, 307, 4840, 257, 688, 295, 264, 2190, 20862, 293, 51388], "temperature": 0.0, "avg_logprob": -0.15504286928874692, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0017260435270145535}, {"id": 91, "seek": 60272, "start": 623.2, "end": 630.32, "text": " statistical machine learning these days. A neural network by itself is still based on the good old", "tokens": [51388, 22820, 3479, 2539, 613, 1708, 13, 316, 18161, 3209, 538, 2564, 307, 920, 2361, 322, 264, 665, 1331, 51744], "temperature": 0.0, "avg_logprob": -0.15504286928874692, "compression_ratio": 1.6422413793103448, "no_speech_prob": 0.0017260435270145535}, {"id": 92, "seek": 63032, "start": 630.32, "end": 637.2800000000001, "text": " perceptron that, for instance, was described by Frank Rosenblatt in 1958. Frank Rosenblatt's idea", "tokens": [50364, 43276, 2044, 300, 11, 337, 5197, 11, 390, 7619, 538, 6823, 33630, 5199, 1591, 294, 45868, 13, 6823, 33630, 5199, 1591, 311, 1558, 50712], "temperature": 0.0, "avg_logprob": -0.1263481885537334, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.0012834444642066956}, {"id": 93, "seek": 63032, "start": 637.2800000000001, "end": 644.8000000000001, "text": " was inspired by how neurons work. At least the simplified models of neural networks, it turns", "tokens": [50712, 390, 7547, 538, 577, 22027, 589, 13, 1711, 1935, 264, 26335, 5245, 295, 18161, 9590, 11, 309, 4523, 51088], "temperature": 0.0, "avg_logprob": -0.1263481885537334, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.0012834444642066956}, {"id": 94, "seek": 63032, "start": 644.8000000000001, "end": 650.1600000000001, "text": " out that the neural networks in our brain are implemented in a very different way from the", "tokens": [51088, 484, 300, 264, 18161, 9590, 294, 527, 3567, 366, 12270, 294, 257, 588, 819, 636, 490, 264, 51356], "temperature": 0.0, "avg_logprob": -0.1263481885537334, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.0012834444642066956}, {"id": 95, "seek": 63032, "start": 650.1600000000001, "end": 656.4000000000001, "text": " ones in our computers. The computers, we just basically treat every cell as a unit that has", "tokens": [51356, 2306, 294, 527, 10807, 13, 440, 10807, 11, 321, 445, 1936, 2387, 633, 2815, 382, 257, 4985, 300, 575, 51668], "temperature": 0.0, "avg_logprob": -0.1263481885537334, "compression_ratio": 1.6331877729257642, "no_speech_prob": 0.0012834444642066956}, {"id": 96, "seek": 65640, "start": 656.4, "end": 661.52, "text": " an activation state, which is a real number. And that activation state is simply the sum", "tokens": [50364, 364, 24433, 1785, 11, 597, 307, 257, 957, 1230, 13, 400, 300, 24433, 1785, 307, 2935, 264, 2408, 50620], "temperature": 0.0, "avg_logprob": -0.07440548719361771, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.001304037868976593}, {"id": 97, "seek": 65640, "start": 661.52, "end": 666.9599999999999, "text": " of the inputs. And the inputs are all weighted by connections. So there's basically a factor by", "tokens": [50620, 295, 264, 15743, 13, 400, 264, 15743, 366, 439, 32807, 538, 9271, 13, 407, 456, 311, 1936, 257, 5952, 538, 50892], "temperature": 0.0, "avg_logprob": -0.07440548719361771, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.001304037868976593}, {"id": 98, "seek": 65640, "start": 666.9599999999999, "end": 674.64, "text": " which every of these inputs is multiplied. And then we throw the output against the threshold", "tokens": [50892, 597, 633, 295, 613, 15743, 307, 17207, 13, 400, 550, 321, 3507, 264, 5598, 1970, 264, 14678, 51276], "temperature": 0.0, "avg_logprob": -0.07440548719361771, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.001304037868976593}, {"id": 99, "seek": 65640, "start": 674.64, "end": 681.84, "text": " function or a sigmoid or some other output function that can introduce a little non-linearity,", "tokens": [51276, 2445, 420, 257, 4556, 3280, 327, 420, 512, 661, 5598, 2445, 300, 393, 5366, 257, 707, 2107, 12, 1889, 17409, 11, 51636], "temperature": 0.0, "avg_logprob": -0.07440548719361771, "compression_ratio": 1.7188940092165899, "no_speech_prob": 0.001304037868976593}, {"id": 100, "seek": 68184, "start": 681.84, "end": 687.44, "text": " basically a little bit of an if-then into the output. But it's a very simple function. We just", "tokens": [50364, 1936, 257, 707, 857, 295, 364, 498, 12, 19096, 666, 264, 5598, 13, 583, 309, 311, 257, 588, 2199, 2445, 13, 492, 445, 50644], "temperature": 0.0, "avg_logprob": -0.11084093840225884, "compression_ratio": 1.6784452296819787, "no_speech_prob": 0.0013879426987841725}, {"id": 101, "seek": 68184, "start": 687.44, "end": 694.5600000000001, "text": " take these units and chain them into layers. And if you take enough of them, this arrangement can", "tokens": [50644, 747, 613, 6815, 293, 5021, 552, 666, 7914, 13, 400, 498, 291, 747, 1547, 295, 552, 11, 341, 17620, 393, 51000], "temperature": 0.0, "avg_logprob": -0.11084093840225884, "compression_ratio": 1.6784452296819787, "no_speech_prob": 0.0013879426987841725}, {"id": 102, "seek": 68184, "start": 694.5600000000001, "end": 701.2, "text": " be trained to model almost arbitrary functions. And while we know that this is wasteful, the", "tokens": [51000, 312, 8895, 281, 2316, 1920, 23211, 6828, 13, 400, 1339, 321, 458, 300, 341, 307, 5964, 906, 11, 264, 51332], "temperature": 0.0, "avg_logprob": -0.11084093840225884, "compression_ratio": 1.6784452296819787, "no_speech_prob": 0.0013879426987841725}, {"id": 103, "seek": 68184, "start": 701.2, "end": 705.36, "text": " training algorithm is relatively slow compared to what the brain is doing, it's fascinating that", "tokens": [51332, 3097, 9284, 307, 7226, 2964, 5347, 281, 437, 264, 3567, 307, 884, 11, 309, 311, 10343, 300, 51540], "temperature": 0.0, "avg_logprob": -0.11084093840225884, "compression_ratio": 1.6784452296819787, "no_speech_prob": 0.0013879426987841725}, {"id": 104, "seek": 68184, "start": 705.36, "end": 711.36, "text": " it works at all, that it converges at all. And that's able to deal, for instance, visual and", "tokens": [51540, 309, 1985, 412, 439, 11, 300, 309, 9652, 2880, 412, 439, 13, 400, 300, 311, 1075, 281, 2028, 11, 337, 5197, 11, 5056, 293, 51840], "temperature": 0.0, "avg_logprob": -0.11084093840225884, "compression_ratio": 1.6784452296819787, "no_speech_prob": 0.0013879426987841725}, {"id": 105, "seek": 71136, "start": 711.44, "end": 717.28, "text": " auditory data and also textual data in such a way that it can often model the statistics", "tokens": [50368, 17748, 827, 1412, 293, 611, 2487, 901, 1412, 294, 1270, 257, 636, 300, 309, 393, 2049, 2316, 264, 12523, 50660], "temperature": 0.0, "avg_logprob": -0.09647471816451461, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.00023042540124151856}, {"id": 106, "seek": 71136, "start": 717.28, "end": 724.88, "text": " of a domain and apparently also some causal structure. So this works also for vision.", "tokens": [50660, 295, 257, 9274, 293, 7970, 611, 512, 38755, 3877, 13, 407, 341, 1985, 611, 337, 5201, 13, 51040], "temperature": 0.0, "avg_logprob": -0.09647471816451461, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.00023042540124151856}, {"id": 107, "seek": 71136, "start": 724.88, "end": 732.5600000000001, "text": " And if we look at a neural network that has been trained to process images and to classify them,", "tokens": [51040, 400, 498, 321, 574, 412, 257, 18161, 3209, 300, 575, 668, 8895, 281, 1399, 5267, 293, 281, 33872, 552, 11, 51424], "temperature": 0.0, "avg_logprob": -0.09647471816451461, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.00023042540124151856}, {"id": 108, "seek": 71136, "start": 732.5600000000001, "end": 738.88, "text": " we find at the individual layers sensitivity to structure that is quite similar to how", "tokens": [51424, 321, 915, 412, 264, 2609, 7914, 19392, 281, 3877, 300, 307, 1596, 2531, 281, 577, 51740], "temperature": 0.0, "avg_logprob": -0.09647471816451461, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.00023042540124151856}, {"id": 109, "seek": 73888, "start": 738.88, "end": 744.32, "text": " cortical columns and individual neurons in the visual cortex are sensitive to patterns", "tokens": [50364, 11278, 804, 13766, 293, 2609, 22027, 294, 264, 5056, 33312, 366, 9477, 281, 8294, 50636], "temperature": 0.0, "avg_logprob": -0.12100867221229955, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.0002491627528797835}, {"id": 110, "seek": 73888, "start": 744.32, "end": 751.12, "text": " that emerge after we train a biological brain on visual data. So at lowest levels, you find", "tokens": [50636, 300, 21511, 934, 321, 3847, 257, 13910, 3567, 322, 5056, 1412, 13, 407, 412, 12437, 4358, 11, 291, 915, 50976], "temperature": 0.0, "avg_logprob": -0.12100867221229955, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.0002491627528797835}, {"id": 111, "seek": 73888, "start": 752.16, "end": 757.04, "text": " contrast patches and colors, and then these features are being combined into higher levels.", "tokens": [51028, 8712, 26531, 293, 4577, 11, 293, 550, 613, 4122, 366, 885, 9354, 666, 2946, 4358, 13, 51272], "temperature": 0.0, "avg_logprob": -0.12100867221229955, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.0002491627528797835}, {"id": 112, "seek": 73888, "start": 757.6, "end": 763.76, "text": " And when we go higher up, we find complicated textures and something like three-dimensional", "tokens": [51300, 400, 562, 321, 352, 2946, 493, 11, 321, 915, 6179, 24501, 293, 746, 411, 1045, 12, 18759, 51608], "temperature": 0.0, "avg_logprob": -0.12100867221229955, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.0002491627528797835}, {"id": 113, "seek": 76376, "start": 763.76, "end": 770.8, "text": " structure and so on. And this can be combined into objects. The algorithm that is being used to", "tokens": [50364, 3877, 293, 370, 322, 13, 400, 341, 393, 312, 9354, 666, 6565, 13, 440, 9284, 300, 307, 885, 1143, 281, 50716], "temperature": 0.0, "avg_logprob": -0.10616179262654166, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0005440583336167037}, {"id": 114, "seek": 76376, "start": 770.8, "end": 777.36, "text": " do statistics over text in GPT-3 can also be adapted to deal with the visual domain.", "tokens": [50716, 360, 12523, 670, 2487, 294, 26039, 51, 12, 18, 393, 611, 312, 20871, 281, 2028, 365, 264, 5056, 9274, 13, 51044], "temperature": 0.0, "avg_logprob": -0.10616179262654166, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0005440583336167037}, {"id": 115, "seek": 76376, "start": 778.3199999999999, "end": 784.48, "text": " And the current iteration of this progression at OpenAI is called Glide, which has been recently", "tokens": [51092, 400, 264, 2190, 24784, 295, 341, 18733, 412, 7238, 48698, 307, 1219, 5209, 482, 11, 597, 575, 668, 3938, 51400], "temperature": 0.0, "avg_logprob": -0.10616179262654166, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0005440583336167037}, {"id": 116, "seek": 76376, "start": 784.48, "end": 792.96, "text": " presented. And Glide uses a combination of a model of visual data, which basically is a latent", "tokens": [51400, 8212, 13, 400, 5209, 482, 4960, 257, 6562, 295, 257, 2316, 295, 5056, 1412, 11, 597, 1936, 307, 257, 48994, 51824], "temperature": 0.0, "avg_logprob": -0.10616179262654166, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0005440583336167037}, {"id": 117, "seek": 79296, "start": 792.96, "end": 798.48, "text": " space of lots and lots of images that has been trained on. And it understands basically how to", "tokens": [50364, 1901, 295, 3195, 293, 3195, 295, 5267, 300, 575, 668, 8895, 322, 13, 400, 309, 15146, 1936, 577, 281, 50640], "temperature": 0.0, "avg_logprob": -0.08393822241266934, "compression_ratio": 1.9663865546218486, "no_speech_prob": 0.0005272119888104498}, {"id": 118, "seek": 79296, "start": 798.48, "end": 803.84, "text": " go between the possibilities of images and move around the space of all possible images.", "tokens": [50640, 352, 1296, 264, 12178, 295, 5267, 293, 1286, 926, 264, 1901, 295, 439, 1944, 5267, 13, 50908], "temperature": 0.0, "avg_logprob": -0.08393822241266934, "compression_ratio": 1.9663865546218486, "no_speech_prob": 0.0005272119888104498}, {"id": 119, "seek": 79296, "start": 803.84, "end": 811.9200000000001, "text": " And the other part of this thing is a tool that is able to match an image to text and determine", "tokens": [50908, 400, 264, 661, 644, 295, 341, 551, 307, 257, 2290, 300, 307, 1075, 281, 2995, 364, 3256, 281, 2487, 293, 6997, 51312], "temperature": 0.0, "avg_logprob": -0.08393822241266934, "compression_ratio": 1.9663865546218486, "no_speech_prob": 0.0005272119888104498}, {"id": 120, "seek": 79296, "start": 811.9200000000001, "end": 816.08, "text": " the similarity of an image to a textual description. And if you combine these two tools,", "tokens": [51312, 264, 32194, 295, 364, 3256, 281, 257, 2487, 901, 3855, 13, 400, 498, 291, 10432, 613, 732, 3873, 11, 51520], "temperature": 0.0, "avg_logprob": -0.08393822241266934, "compression_ratio": 1.9663865546218486, "no_speech_prob": 0.0005272119888104498}, {"id": 121, "seek": 79296, "start": 816.08, "end": 820.32, "text": " you can give this a textual description, and it's going to move around with the space of all images", "tokens": [51520, 291, 393, 976, 341, 257, 2487, 901, 3855, 11, 293, 309, 311, 516, 281, 1286, 926, 365, 264, 1901, 295, 439, 5267, 51732], "temperature": 0.0, "avg_logprob": -0.08393822241266934, "compression_ratio": 1.9663865546218486, "no_speech_prob": 0.0005272119888104498}, {"id": 122, "seek": 82032, "start": 820.32, "end": 826.88, "text": " until it discovers an image that is very, very good match to the textual description.", "tokens": [50364, 1826, 309, 44522, 364, 3256, 300, 307, 588, 11, 588, 665, 2995, 281, 264, 2487, 901, 3855, 13, 50692], "temperature": 0.0, "avg_logprob": -0.12466454260128061, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.00016598266665823758}, {"id": 123, "seek": 82032, "start": 827.6, "end": 834.8000000000001, "text": " And again, it's fascinating to me that this works at all. But it's now extremely good. So what you", "tokens": [50728, 400, 797, 11, 309, 311, 10343, 281, 385, 300, 341, 1985, 412, 439, 13, 583, 309, 311, 586, 4664, 665, 13, 407, 437, 291, 51088], "temperature": 0.0, "avg_logprob": -0.12466454260128061, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.00016598266665823758}, {"id": 124, "seek": 82032, "start": 834.8000000000001, "end": 839.44, "text": " see here in these images, for instance, I don't know if you can read it well, to the top left,", "tokens": [51088, 536, 510, 294, 613, 5267, 11, 337, 5197, 11, 286, 500, 380, 458, 498, 291, 393, 1401, 309, 731, 11, 281, 264, 1192, 1411, 11, 51320], "temperature": 0.0, "avg_logprob": -0.12466454260128061, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.00016598266665823758}, {"id": 125, "seek": 82032, "start": 839.44, "end": 844.5600000000001, "text": " you see a surrealist dreamlike oil painting by Salvador Dali of the cat playing checkers.", "tokens": [51320, 291, 536, 257, 32513, 468, 3055, 4092, 3184, 5370, 538, 32586, 413, 5103, 295, 264, 3857, 2433, 1520, 433, 13, 51576], "temperature": 0.0, "avg_logprob": -0.12466454260128061, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.00016598266665823758}, {"id": 126, "seek": 84456, "start": 844.56, "end": 850.88, "text": " And this is what the AI model has generated in response. And then you see a professional photo", "tokens": [50364, 400, 341, 307, 437, 264, 7318, 2316, 575, 10833, 294, 4134, 13, 400, 550, 291, 536, 257, 4843, 5052, 50680], "temperature": 0.0, "avg_logprob": -0.17021622865096384, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.0013453690335154533}, {"id": 127, "seek": 84456, "start": 850.88, "end": 855.4399999999999, "text": " of a sunset behind the Grand Canyon and a high quality oil painting of the psychedelic hamster", "tokens": [50680, 295, 257, 20142, 2261, 264, 6757, 29170, 293, 257, 1090, 3125, 3184, 5370, 295, 264, 47732, 299, 7852, 3120, 50908], "temperature": 0.0, "avg_logprob": -0.17021622865096384, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.0013453690335154533}, {"id": 128, "seek": 84456, "start": 855.4399999999999, "end": 861.92, "text": " dragon. You get the idea, right? Also very taken by the crayon drawing of a space elevator and the", "tokens": [50908, 12165, 13, 509, 483, 264, 1558, 11, 558, 30, 2743, 588, 2726, 538, 264, 33073, 266, 6316, 295, 257, 1901, 18782, 293, 264, 51232], "temperature": 0.0, "avg_logprob": -0.17021622865096384, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.0013453690335154533}, {"id": 129, "seek": 84456, "start": 861.92, "end": 870.16, "text": " bottom left or the pixel art hoji pizza. These are all images that the program has not found on", "tokens": [51232, 2767, 1411, 420, 264, 19261, 1523, 1106, 4013, 8298, 13, 1981, 366, 439, 5267, 300, 264, 1461, 575, 406, 1352, 322, 51644], "temperature": 0.0, "avg_logprob": -0.17021622865096384, "compression_ratio": 1.5421686746987953, "no_speech_prob": 0.0013453690335154533}, {"id": 130, "seek": 87016, "start": 870.16, "end": 876.24, "text": " the internet. So it has only looked at lots and lots of pictures on the internet. And because of", "tokens": [50364, 264, 4705, 13, 407, 309, 575, 787, 2956, 412, 3195, 293, 3195, 295, 5242, 322, 264, 4705, 13, 400, 570, 295, 50668], "temperature": 0.0, "avg_logprob": -0.09584721366127769, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.003374813823029399}, {"id": 131, "seek": 87016, "start": 876.24, "end": 883.8399999999999, "text": " looking at them, it's able to combine the features in a multi level hierarchical structure until it", "tokens": [50668, 1237, 412, 552, 11, 309, 311, 1075, 281, 10432, 264, 4122, 294, 257, 4825, 1496, 35250, 804, 3877, 1826, 309, 51048], "temperature": 0.0, "avg_logprob": -0.09584721366127769, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.003374813823029399}, {"id": 132, "seek": 87016, "start": 883.8399999999999, "end": 892.16, "text": " becomes similar to the textual description. But can such a system not just generate images and text,", "tokens": [51048, 3643, 2531, 281, 264, 2487, 901, 3855, 13, 583, 393, 1270, 257, 1185, 406, 445, 8460, 5267, 293, 2487, 11, 51464], "temperature": 0.0, "avg_logprob": -0.09584721366127769, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.003374813823029399}, {"id": 133, "seek": 87016, "start": 892.16, "end": 897.52, "text": " but is it able to generate the likeness of a conscious being to such a degree that there is", "tokens": [51464, 457, 307, 309, 1075, 281, 8460, 264, 36946, 442, 295, 257, 6648, 885, 281, 1270, 257, 4314, 300, 456, 307, 51732], "temperature": 0.0, "avg_logprob": -0.09584721366127769, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.003374813823029399}, {"id": 134, "seek": 89752, "start": 897.52, "end": 902.3199999999999, "text": " causal structure that would convince us that indeed we are looking at a conscious agent.", "tokens": [50364, 38755, 3877, 300, 576, 13447, 505, 300, 6451, 321, 366, 1237, 412, 257, 6648, 9461, 13, 50604], "temperature": 0.0, "avg_logprob": -0.1812946233856544, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0009392229258082807}, {"id": 135, "seek": 89752, "start": 902.96, "end": 910.16, "text": " And to get there, I think we need to define consciousness in a more tight way than the", "tokens": [50636, 400, 281, 483, 456, 11, 286, 519, 321, 643, 281, 6964, 10081, 294, 257, 544, 4524, 636, 813, 264, 50996], "temperature": 0.0, "avg_logprob": -0.1812946233856544, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0009392229258082807}, {"id": 136, "seek": 89752, "start": 910.16, "end": 917.6, "text": " TPD3 just did. So basically just to get our terms straight, where we casually, consciousness, I think", "tokens": [50996, 314, 17349, 18, 445, 630, 13, 407, 1936, 445, 281, 483, 527, 2115, 2997, 11, 689, 321, 34872, 11, 10081, 11, 286, 519, 51368], "temperature": 0.0, "avg_logprob": -0.1812946233856544, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0009392229258082807}, {"id": 137, "seek": 89752, "start": 917.6, "end": 924.0799999999999, "text": " is usually referring to the experience of what it's like. So that the lights go on and that you", "tokens": [51368, 307, 2673, 13761, 281, 264, 1752, 295, 437, 309, 311, 411, 13, 407, 300, 264, 5811, 352, 322, 293, 300, 291, 51692], "temperature": 0.0, "avg_logprob": -0.1812946233856544, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.0009392229258082807}, {"id": 138, "seek": 92408, "start": 924.08, "end": 935.12, "text": " experience something in your mind that has a quality of realness to it. And we can ask ourselves", "tokens": [50364, 1752, 746, 294, 428, 1575, 300, 575, 257, 3125, 295, 957, 1287, 281, 309, 13, 400, 321, 393, 1029, 4175, 50916], "temperature": 0.0, "avg_logprob": -0.13408068064096812, "compression_ratio": 1.5, "no_speech_prob": 0.0008822815143503249}, {"id": 139, "seek": 92408, "start": 935.12, "end": 946.24, "text": " if TPD3 is weakly conscious in this way, and it's very hard to say. It's not obvious one way or the", "tokens": [50916, 498, 314, 17349, 18, 307, 5336, 356, 6648, 294, 341, 636, 11, 293, 309, 311, 588, 1152, 281, 584, 13, 467, 311, 406, 6322, 472, 636, 420, 264, 51472], "temperature": 0.0, "avg_logprob": -0.13408068064096812, "compression_ratio": 1.5, "no_speech_prob": 0.0008822815143503249}, {"id": 140, "seek": 92408, "start": 946.24, "end": 950.8000000000001, "text": " other. There is some intelligence in the system. Intelligence is the ability to make models in", "tokens": [51472, 661, 13, 821, 307, 512, 7599, 294, 264, 1185, 13, 27274, 307, 264, 3485, 281, 652, 5245, 294, 51700], "temperature": 0.0, "avg_logprob": -0.13408068064096812, "compression_ratio": 1.5, "no_speech_prob": 0.0008822815143503249}, {"id": 141, "seek": 95080, "start": 950.88, "end": 955.5999999999999, "text": " my view. And intelligence is different from, say, rationality, which is the ability to reach", "tokens": [50368, 452, 1910, 13, 400, 7599, 307, 819, 490, 11, 584, 11, 15090, 507, 11, 597, 307, 264, 3485, 281, 2524, 50604], "temperature": 0.0, "avg_logprob": -0.1417995057664476, "compression_ratio": 1.8588709677419355, "no_speech_prob": 0.0006559704197570682}, {"id": 142, "seek": 95080, "start": 956.3199999999999, "end": 962.24, "text": " goals or sentience, which means that you become aware of the structure of the universe that", "tokens": [50640, 5493, 420, 2279, 1182, 11, 597, 1355, 300, 291, 1813, 3650, 295, 264, 3877, 295, 264, 6445, 300, 50936], "temperature": 0.0, "avg_logprob": -0.1417995057664476, "compression_ratio": 1.8588709677419355, "no_speech_prob": 0.0006559704197570682}, {"id": 143, "seek": 95080, "start": 962.24, "end": 968.0799999999999, "text": " contains your relationship to it in your own agency. And you can act based on the model of", "tokens": [50936, 8306, 428, 2480, 281, 309, 294, 428, 1065, 7934, 13, 400, 291, 393, 605, 2361, 322, 264, 2316, 295, 51228], "temperature": 0.0, "avg_logprob": -0.1417995057664476, "compression_ratio": 1.8588709677419355, "no_speech_prob": 0.0006559704197570682}, {"id": 144, "seek": 95080, "start": 968.64, "end": 974.16, "text": " what you are doing in the world. And it's also not the same thing as the self, which is the", "tokens": [51256, 437, 291, 366, 884, 294, 264, 1002, 13, 400, 309, 311, 611, 406, 264, 912, 551, 382, 264, 2698, 11, 597, 307, 264, 51532], "temperature": 0.0, "avg_logprob": -0.1417995057664476, "compression_ratio": 1.8588709677419355, "no_speech_prob": 0.0006559704197570682}, {"id": 145, "seek": 95080, "start": 974.16, "end": 978.0799999999999, "text": " identification that you have, what you believe, what you are in the world, the properties and", "tokens": [51532, 22065, 300, 291, 362, 11, 437, 291, 1697, 11, 437, 291, 366, 294, 264, 1002, 11, 264, 7221, 293, 51728], "temperature": 0.0, "avg_logprob": -0.1417995057664476, "compression_ratio": 1.8588709677419355, "no_speech_prob": 0.0006559704197570682}, {"id": 146, "seek": 97808, "start": 978.08, "end": 982.8000000000001, "text": " purposes that you follow, or the mind itself, which is the thing that generates the model of the", "tokens": [50364, 9932, 300, 291, 1524, 11, 420, 264, 1575, 2564, 11, 597, 307, 264, 551, 300, 23815, 264, 2316, 295, 264, 50600], "temperature": 0.0, "avg_logprob": -0.09949070342043613, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00018808315508067608}, {"id": 147, "seek": 97808, "start": 982.8000000000001, "end": 990.88, "text": " universe and the self, if it does have a self. So intelligence is the ability to make models. And", "tokens": [50600, 6445, 293, 264, 2698, 11, 498, 309, 775, 362, 257, 2698, 13, 407, 7599, 307, 264, 3485, 281, 652, 5245, 13, 400, 51004], "temperature": 0.0, "avg_logprob": -0.09949070342043613, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00018808315508067608}, {"id": 148, "seek": 97808, "start": 990.88, "end": 998.5600000000001, "text": " it's usually in the purpose of some control task, some regulation. And control is a notion that", "tokens": [51004, 309, 311, 2673, 294, 264, 4334, 295, 512, 1969, 5633, 11, 512, 15062, 13, 400, 1969, 307, 257, 10710, 300, 51388], "temperature": 0.0, "avg_logprob": -0.09949070342043613, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00018808315508067608}, {"id": 149, "seek": 97808, "start": 1000.24, "end": 1006.4000000000001, "text": " has been made popular in cybernetics. And the idea of a controller is basically that you have a system", "tokens": [51472, 575, 668, 1027, 3743, 294, 13411, 7129, 1167, 13, 400, 264, 1558, 295, 257, 10561, 307, 1936, 300, 291, 362, 257, 1185, 51780], "temperature": 0.0, "avg_logprob": -0.09949070342043613, "compression_ratio": 1.7466666666666666, "no_speech_prob": 0.00018808315508067608}, {"id": 150, "seek": 100640, "start": 1006.4, "end": 1012.56, "text": " that is connected to some actuator or an effector that is acting on some system that is being", "tokens": [50364, 300, 307, 4582, 281, 512, 34964, 1639, 420, 364, 1802, 284, 300, 307, 6577, 322, 512, 1185, 300, 307, 885, 50672], "temperature": 0.0, "avg_logprob": -0.11562615500556098, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.0006067914073355496}, {"id": 151, "seek": 100640, "start": 1012.56, "end": 1018.4, "text": " regulated. And there is a sensor that obtains a deviation between the set point and the state", "tokens": [50672, 26243, 13, 400, 456, 307, 257, 10200, 300, 7464, 2315, 257, 25163, 1296, 264, 992, 935, 293, 264, 1785, 50964], "temperature": 0.0, "avg_logprob": -0.11562615500556098, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.0006067914073355496}, {"id": 152, "seek": 100640, "start": 1018.4, "end": 1024.56, "text": " of the system. So it measures, but the system is close to an ideal state or more distant to it.", "tokens": [50964, 295, 264, 1185, 13, 407, 309, 8000, 11, 457, 264, 1185, 307, 1998, 281, 364, 7157, 1785, 420, 544, 17275, 281, 309, 13, 51272], "temperature": 0.0, "avg_logprob": -0.11562615500556098, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.0006067914073355496}, {"id": 153, "seek": 100640, "start": 1024.56, "end": 1030.8, "text": " And this regulated system is being disturbed. And the classical example of a control system is the", "tokens": [51272, 400, 341, 26243, 1185, 307, 885, 30558, 13, 400, 264, 13735, 1365, 295, 257, 1969, 1185, 307, 264, 51584], "temperature": 0.0, "avg_logprob": -0.11562615500556098, "compression_ratio": 1.8454106280193237, "no_speech_prob": 0.0006067914073355496}, {"id": 154, "seek": 103080, "start": 1030.8, "end": 1036.96, "text": " thermostat. So you have as an effector some mechanism that is able to turn the heating on", "tokens": [50364, 8810, 39036, 13, 407, 291, 362, 382, 364, 1802, 284, 512, 7513, 300, 307, 1075, 281, 1261, 264, 15082, 322, 50672], "temperature": 0.0, "avg_logprob": -0.11815149050492507, "compression_ratio": 1.9094650205761317, "no_speech_prob": 0.0009250078001059592}, {"id": 155, "seek": 103080, "start": 1036.96, "end": 1041.12, "text": " and off. And it's the sensor, you have some thermometer that measures the difference between", "tokens": [50672, 293, 766, 13, 400, 309, 311, 264, 10200, 11, 291, 362, 512, 42539, 300, 8000, 264, 2649, 1296, 50880], "temperature": 0.0, "avg_logprob": -0.11815149050492507, "compression_ratio": 1.9094650205761317, "no_speech_prob": 0.0009250078001059592}, {"id": 156, "seek": 103080, "start": 1041.12, "end": 1047.2, "text": " an ideal temperature and the temperature in the room. And the controller is a very simple circuit", "tokens": [50880, 364, 7157, 4292, 293, 264, 4292, 294, 264, 1808, 13, 400, 264, 10561, 307, 257, 588, 2199, 9048, 51184], "temperature": 0.0, "avg_logprob": -0.11815149050492507, "compression_ratio": 1.9094650205761317, "no_speech_prob": 0.0009250078001059592}, {"id": 157, "seek": 103080, "start": 1047.2, "end": 1052.72, "text": " that turns on and off the heating. And the regulated system would be the temperature in the room,", "tokens": [51184, 300, 4523, 322, 293, 766, 264, 15082, 13, 400, 264, 26243, 1185, 576, 312, 264, 4292, 294, 264, 1808, 11, 51460], "temperature": 0.0, "avg_logprob": -0.11815149050492507, "compression_ratio": 1.9094650205761317, "no_speech_prob": 0.0009250078001059592}, {"id": 158, "seek": 103080, "start": 1052.72, "end": 1057.04, "text": " together with the heating system, and the environment, the world out there behind the", "tokens": [51460, 1214, 365, 264, 15082, 1185, 11, 293, 264, 2823, 11, 264, 1002, 484, 456, 2261, 264, 51676], "temperature": 0.0, "avg_logprob": -0.11815149050492507, "compression_ratio": 1.9094650205761317, "no_speech_prob": 0.0009250078001059592}, {"id": 159, "seek": 105704, "start": 1057.04, "end": 1063.04, "text": " windows and so on is going to disturb this regulated system. And now this controller", "tokens": [50364, 9309, 293, 370, 322, 307, 516, 281, 18071, 341, 26243, 1185, 13, 400, 586, 341, 10561, 50664], "temperature": 0.0, "avg_logprob": -0.08168675281383374, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0005273294518701732}, {"id": 160, "seek": 105704, "start": 1063.04, "end": 1067.28, "text": " is going to get better if you give it the ability to not just act on the present frame,", "tokens": [50664, 307, 516, 281, 483, 1101, 498, 291, 976, 309, 264, 3485, 281, 406, 445, 605, 322, 264, 1974, 3920, 11, 50876], "temperature": 0.0, "avg_logprob": -0.08168675281383374, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0005273294518701732}, {"id": 161, "seek": 105704, "start": 1067.84, "end": 1076.08, "text": " but if you give it a model of the future. And my view, an agent is a combination of a controller", "tokens": [50904, 457, 498, 291, 976, 309, 257, 2316, 295, 264, 2027, 13, 400, 452, 1910, 11, 364, 9461, 307, 257, 6562, 295, 257, 10561, 51316], "temperature": 0.0, "avg_logprob": -0.08168675281383374, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0005273294518701732}, {"id": 162, "seek": 105704, "start": 1076.08, "end": 1080.3999999999999, "text": " with a set point generator and the ability to model the future. And what this means,", "tokens": [51316, 365, 257, 992, 935, 19265, 293, 264, 3485, 281, 2316, 264, 2027, 13, 400, 437, 341, 1355, 11, 51532], "temperature": 0.0, "avg_logprob": -0.08168675281383374, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0005273294518701732}, {"id": 163, "seek": 105704, "start": 1080.3999999999999, "end": 1085.12, "text": " it's not that it's not going to just optimize the temperature deviation in the next moment,", "tokens": [51532, 309, 311, 406, 300, 309, 311, 406, 516, 281, 445, 19719, 264, 4292, 25163, 294, 264, 958, 1623, 11, 51768], "temperature": 0.0, "avg_logprob": -0.08168675281383374, "compression_ratio": 1.8583333333333334, "no_speech_prob": 0.0005273294518701732}, {"id": 164, "seek": 108512, "start": 1085.12, "end": 1090.1599999999999, "text": " but over its entire expectation horizon. So you have a branching world, there are different", "tokens": [50364, 457, 670, 1080, 2302, 14334, 18046, 13, 407, 291, 362, 257, 9819, 278, 1002, 11, 456, 366, 819, 50616], "temperature": 0.0, "avg_logprob": -0.09435989787277665, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.00037399865686893463}, {"id": 165, "seek": 108512, "start": 1090.1599999999999, "end": 1095.76, "text": " decisions of the controller, different trajectories in the temperature. By being able to model the", "tokens": [50616, 5327, 295, 264, 10561, 11, 819, 18257, 2083, 294, 264, 4292, 13, 3146, 885, 1075, 281, 2316, 264, 50896], "temperature": 0.0, "avg_logprob": -0.09435989787277665, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.00037399865686893463}, {"id": 166, "seek": 108512, "start": 1095.76, "end": 1101.28, "text": " future, you basically can choose a trajectory of the future that you like. And choosing this", "tokens": [50896, 2027, 11, 291, 1936, 393, 2826, 257, 21512, 295, 264, 2027, 300, 291, 411, 13, 400, 10875, 341, 51172], "temperature": 0.0, "avg_logprob": -0.09435989787277665, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.00037399865686893463}, {"id": 167, "seek": 108512, "start": 1101.28, "end": 1108.32, "text": " trajectory means that you are making decisions. So just by having a preferred way in which the", "tokens": [51172, 21512, 1355, 300, 291, 366, 1455, 5327, 13, 407, 445, 538, 1419, 257, 16494, 636, 294, 597, 264, 51524], "temperature": 0.0, "avg_logprob": -0.09435989787277665, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.00037399865686893463}, {"id": 168, "seek": 108512, "start": 1108.32, "end": 1115.04, "text": " world works and the ability to model the future, agency is emerging. And if you think about", "tokens": [51524, 1002, 1985, 293, 264, 3485, 281, 2316, 264, 2027, 11, 7934, 307, 14989, 13, 400, 498, 291, 519, 466, 51860], "temperature": 0.0, "avg_logprob": -0.09435989787277665, "compression_ratio": 1.8007662835249043, "no_speech_prob": 0.00037399865686893463}, {"id": 169, "seek": 111504, "start": 1115.28, "end": 1119.52, "text": " stages of intelligent agency, the simplest one is the regulator and the feedback loop,", "tokens": [50376, 10232, 295, 13232, 7934, 11, 264, 22811, 472, 307, 264, 36250, 293, 264, 5824, 6367, 11, 50588], "temperature": 0.0, "avg_logprob": -0.09453450157528832, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0005272903945297003}, {"id": 170, "seek": 111504, "start": 1119.52, "end": 1123.44, "text": " which by itself is not an agent yet. And if you're able to model the future, you have a", "tokens": [50588, 597, 538, 2564, 307, 406, 364, 9461, 1939, 13, 400, 498, 291, 434, 1075, 281, 2316, 264, 2027, 11, 291, 362, 257, 50784], "temperature": 0.0, "avg_logprob": -0.09453450157528832, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0005272903945297003}, {"id": 171, "seek": 111504, "start": 1123.44, "end": 1128.96, "text": " predictive controller. If you combine this with an integrated set point generator, so it's not", "tokens": [50784, 35521, 10561, 13, 759, 291, 10432, 341, 365, 364, 10919, 992, 935, 19265, 11, 370, 309, 311, 406, 51060], "temperature": 0.0, "avg_logprob": -0.09453450157528832, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0005272903945297003}, {"id": 172, "seek": 111504, "start": 1128.96, "end": 1135.84, "text": " just acting on what you do from the outside, but this internal generation of its motives,", "tokens": [51060, 445, 6577, 322, 437, 291, 360, 490, 264, 2380, 11, 457, 341, 6920, 5125, 295, 1080, 39812, 11, 51404], "temperature": 0.0, "avg_logprob": -0.09453450157528832, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0005272903945297003}, {"id": 173, "seek": 111504, "start": 1135.84, "end": 1140.96, "text": " then you have an agent. And if this thing is sophisticated enough that it's able to discover", "tokens": [51404, 550, 291, 362, 364, 9461, 13, 400, 498, 341, 551, 307, 16950, 1547, 300, 309, 311, 1075, 281, 4411, 51660], "temperature": 0.0, "avg_logprob": -0.09453450157528832, "compression_ratio": 1.699248120300752, "no_speech_prob": 0.0005272903945297003}, {"id": 174, "seek": 114096, "start": 1140.96, "end": 1147.6000000000001, "text": " itself in the world, if its sensor is sufficient and its modeling capacity universal enough,", "tokens": [50364, 2564, 294, 264, 1002, 11, 498, 1080, 10200, 307, 11563, 293, 1080, 15983, 6042, 11455, 1547, 11, 50696], "temperature": 0.0, "avg_logprob": -0.08530939066851581, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0008963743457570672}, {"id": 175, "seek": 114096, "start": 1147.6000000000001, "end": 1153.28, "text": " then it will notice that there is a very particular way in which its sensors work and actuators work,", "tokens": [50696, 550, 309, 486, 3449, 300, 456, 307, 257, 588, 1729, 636, 294, 597, 1080, 14840, 589, 293, 34964, 3391, 589, 11, 50980], "temperature": 0.0, "avg_logprob": -0.08530939066851581, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0008963743457570672}, {"id": 176, "seek": 114096, "start": 1153.28, "end": 1158.32, "text": " and it's going to accommodate this to improve the regulation. So at this point, it understands", "tokens": [50980, 293, 309, 311, 516, 281, 21410, 341, 281, 3470, 264, 15062, 13, 407, 412, 341, 935, 11, 309, 15146, 51232], "temperature": 0.0, "avg_logprob": -0.08530939066851581, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0008963743457570672}, {"id": 177, "seek": 114096, "start": 1158.32, "end": 1163.04, "text": " what it's doing because it understands what it is, which means it has a model of what it is in", "tokens": [51232, 437, 309, 311, 884, 570, 309, 15146, 437, 309, 307, 11, 597, 1355, 309, 575, 257, 2316, 295, 437, 309, 307, 294, 51468], "temperature": 0.0, "avg_logprob": -0.08530939066851581, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0008963743457570672}, {"id": 178, "seek": 114096, "start": 1163.04, "end": 1170.56, "text": " relationship to the environment. And humans are going beyond this simple sentence. We are also", "tokens": [51468, 2480, 281, 264, 2823, 13, 400, 6255, 366, 516, 4399, 341, 2199, 8174, 13, 492, 366, 611, 51844], "temperature": 0.0, "avg_logprob": -0.08530939066851581, "compression_ratio": 1.794007490636704, "no_speech_prob": 0.0008963743457570672}, {"id": 179, "seek": 117056, "start": 1170.6399999999999, "end": 1176.32, "text": " transcendent agents, which means we are linking up to next level agency and become part of higher", "tokens": [50368, 28535, 317, 12554, 11, 597, 1355, 321, 366, 25775, 493, 281, 958, 1496, 7934, 293, 1813, 644, 295, 2946, 50652], "temperature": 0.0, "avg_logprob": -0.12378492662983556, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.000616448640357703}, {"id": 180, "seek": 117056, "start": 1176.32, "end": 1183.04, "text": " level purposes because we are our state building minds. We are able to play a part in a larger", "tokens": [50652, 1496, 9932, 570, 321, 366, 527, 1785, 2390, 9634, 13, 492, 366, 1075, 281, 862, 257, 644, 294, 257, 4833, 50988], "temperature": 0.0, "avg_logprob": -0.12378492662983556, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.000616448640357703}, {"id": 181, "seek": 117056, "start": 1183.04, "end": 1187.52, "text": " role in an organization, for instance, or in a society or a civilization.", "tokens": [50988, 3090, 294, 364, 4475, 11, 337, 5197, 11, 420, 294, 257, 4086, 420, 257, 18036, 13, 51212], "temperature": 0.0, "avg_logprob": -0.12378492662983556, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.000616448640357703}, {"id": 182, "seek": 117056, "start": 1191.44, "end": 1196.48, "text": " So now if we go back to GPT-3, whether it's conscious, I think it's pretty clear that GPT-3", "tokens": [51408, 407, 586, 498, 321, 352, 646, 281, 26039, 51, 12, 18, 11, 1968, 309, 311, 6648, 11, 286, 519, 309, 311, 1238, 1850, 300, 26039, 51, 12, 18, 51660], "temperature": 0.0, "avg_logprob": -0.12378492662983556, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.000616448640357703}, {"id": 183, "seek": 119648, "start": 1196.48, "end": 1200.8, "text": " does not know what it's doing because it's going to transcend an arbitrary story and it doesn't", "tokens": [50364, 775, 406, 458, 437, 309, 311, 884, 570, 309, 311, 516, 281, 28535, 364, 23211, 1657, 293, 309, 1177, 380, 50580], "temperature": 0.0, "avg_logprob": -0.09350571556696816, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.0025098237674683332}, {"id": 184, "seek": 119648, "start": 1200.8, "end": 1206.72, "text": " have sensors that would tell it what it is. GPT-3 also doesn't have any kind of online learning,", "tokens": [50580, 362, 14840, 300, 576, 980, 309, 437, 309, 307, 13, 26039, 51, 12, 18, 611, 1177, 380, 362, 604, 733, 295, 2950, 2539, 11, 50876], "temperature": 0.0, "avg_logprob": -0.09350571556696816, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.0025098237674683332}, {"id": 185, "seek": 119648, "start": 1206.72, "end": 1211.76, "text": " so it's not able to discover something new after it has been trained. And GPT-3 has been trained", "tokens": [50876, 370, 309, 311, 406, 1075, 281, 4411, 746, 777, 934, 309, 575, 668, 8895, 13, 400, 26039, 51, 12, 18, 575, 668, 8895, 51128], "temperature": 0.0, "avg_logprob": -0.09350571556696816, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.0025098237674683332}, {"id": 186, "seek": 119648, "start": 1211.76, "end": 1217.68, "text": " before GPT-3 was invented and published, so it has never read a reference about GPT-3 on the", "tokens": [51128, 949, 26039, 51, 12, 18, 390, 14479, 293, 6572, 11, 370, 309, 575, 1128, 1401, 257, 6408, 466, 26039, 51, 12, 18, 322, 264, 51424], "temperature": 0.0, "avg_logprob": -0.09350571556696816, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.0025098237674683332}, {"id": 187, "seek": 119648, "start": 1217.68, "end": 1224.96, "text": " internet and it only has to gather what GPT-3 is when you talk to it from the context in which", "tokens": [51424, 4705, 293, 309, 787, 575, 281, 5448, 437, 26039, 51, 12, 18, 307, 562, 291, 751, 281, 309, 490, 264, 4319, 294, 597, 51788], "temperature": 0.0, "avg_logprob": -0.09350571556696816, "compression_ratio": 1.7472527472527473, "no_speech_prob": 0.0025098237674683332}, {"id": 188, "seek": 122496, "start": 1225.6000000000001, "end": 1234.72, "text": " their prompt is being given. And so it is not sent yet, but imagine you want to give it agency.", "tokens": [50396, 641, 12391, 307, 885, 2212, 13, 400, 370, 309, 307, 406, 2279, 1939, 11, 457, 3811, 291, 528, 281, 976, 309, 7934, 13, 50852], "temperature": 0.0, "avg_logprob": -0.09201623843266414, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.0009847005130723119}, {"id": 189, "seek": 122496, "start": 1235.28, "end": 1239.92, "text": " Of course, it's not an agent by itself, but you could, in principle, as a thought experiment at", "tokens": [50880, 2720, 1164, 11, 309, 311, 406, 364, 9461, 538, 2564, 11, 457, 291, 727, 11, 294, 8665, 11, 382, 257, 1194, 5120, 412, 51112], "temperature": 0.0, "avg_logprob": -0.09201623843266414, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.0009847005130723119}, {"id": 190, "seek": 122496, "start": 1239.92, "end": 1246.64, "text": " least, use it to drive a robot because GPT-3 is able to generate stories about robots. So if you", "tokens": [51112, 1935, 11, 764, 309, 281, 3332, 257, 7881, 570, 26039, 51, 12, 18, 307, 1075, 281, 8460, 3676, 466, 14733, 13, 407, 498, 291, 51448], "temperature": 0.0, "avg_logprob": -0.09201623843266414, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.0009847005130723119}, {"id": 191, "seek": 122496, "start": 1246.64, "end": 1253.6000000000001, "text": " were to give GPT-3 access to a vision-to-speech module and this vision module is giving sensory", "tokens": [51448, 645, 281, 976, 26039, 51, 12, 18, 2105, 281, 257, 5201, 12, 1353, 12, 7053, 5023, 10088, 293, 341, 5201, 10088, 307, 2902, 27233, 51796], "temperature": 0.0, "avg_logprob": -0.09201623843266414, "compression_ratio": 1.6134453781512605, "no_speech_prob": 0.0009847005130723119}, {"id": 192, "seek": 125360, "start": 1253.6, "end": 1259.4399999999998, "text": " information about a robot and its world, then GPT-3 could continue the story of that robot and", "tokens": [50364, 1589, 466, 257, 7881, 293, 1080, 1002, 11, 550, 26039, 51, 12, 18, 727, 2354, 264, 1657, 295, 300, 7881, 293, 50656], "temperature": 0.0, "avg_logprob": -0.1069328155517578, "compression_ratio": 1.7580071174377223, "no_speech_prob": 0.0016224377322942019}, {"id": 193, "seek": 125360, "start": 1259.4399999999998, "end": 1266.8, "text": " then we feed the output of GPT-3 into some speech-to-actuator module that is producing the behavior", "tokens": [50656, 550, 321, 3154, 264, 5598, 295, 26039, 51, 12, 18, 666, 512, 6218, 12, 1353, 12, 578, 84, 1639, 10088, 300, 307, 10501, 264, 5223, 51024], "temperature": 0.0, "avg_logprob": -0.1069328155517578, "compression_ratio": 1.7580071174377223, "no_speech_prob": 0.0016224377322942019}, {"id": 194, "seek": 125360, "start": 1266.8, "end": 1272.08, "text": " of the robot in the given moment and then we look at the world again and the internal model states", "tokens": [51024, 295, 264, 7881, 294, 264, 2212, 1623, 293, 550, 321, 574, 412, 264, 1002, 797, 293, 264, 6920, 2316, 4368, 51288], "temperature": 0.0, "avg_logprob": -0.1069328155517578, "compression_ratio": 1.7580071174377223, "no_speech_prob": 0.0016224377322942019}, {"id": 195, "seek": 125360, "start": 1272.08, "end": 1276.8799999999999, "text": " and then feed them back into the system as a prompt. And now it's still not able to put anything", "tokens": [51288, 293, 550, 3154, 552, 646, 666, 264, 1185, 382, 257, 12391, 13, 400, 586, 309, 311, 920, 406, 1075, 281, 829, 1340, 51528], "temperature": 0.0, "avg_logprob": -0.1069328155517578, "compression_ratio": 1.7580071174377223, "no_speech_prob": 0.0016224377322942019}, {"id": 196, "seek": 125360, "start": 1276.8799999999999, "end": 1282.1599999999999, "text": " into long-term memory, so it would be an amnesiac. It should be able, using its working memory contents", "tokens": [51528, 666, 938, 12, 7039, 4675, 11, 370, 309, 576, 312, 364, 669, 4081, 13921, 13, 467, 820, 312, 1075, 11, 1228, 1080, 1364, 4675, 15768, 51792], "temperature": 0.0, "avg_logprob": -0.1069328155517578, "compression_ratio": 1.7580071174377223, "no_speech_prob": 0.0016224377322942019}, {"id": 197, "seek": 128216, "start": 1282.16, "end": 1287.3600000000001, "text": " and so on, to produce plausible behavior. And you could still argue that this doesn't have an", "tokens": [50364, 293, 370, 322, 11, 281, 5258, 39925, 5223, 13, 400, 291, 727, 920, 9695, 300, 341, 1177, 380, 362, 364, 50624], "temperature": 0.0, "avg_logprob": -0.10983344883594698, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.0003405003808438778}, {"id": 198, "seek": 128216, "start": 1287.3600000000001, "end": 1292.16, "text": " intrinsic motivation because it's just going to generate an arbitrary story about a robot based", "tokens": [50624, 35698, 12335, 570, 309, 311, 445, 516, 281, 8460, 364, 23211, 1657, 466, 257, 7881, 2361, 50864], "temperature": 0.0, "avg_logprob": -0.10983344883594698, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.0003405003808438778}, {"id": 199, "seek": 128216, "start": 1292.16, "end": 1298.0800000000002, "text": " on stories about robots that have seen in the past because at some of the motivation into an", "tokens": [50864, 322, 3676, 466, 14733, 300, 362, 1612, 294, 264, 1791, 570, 412, 512, 295, 264, 12335, 666, 364, 51160], "temperature": 0.0, "avg_logprob": -0.10983344883594698, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.0003405003808438778}, {"id": 200, "seek": 128216, "start": 1298.0800000000002, "end": 1304.24, "text": " external cybernetic module that has set point deviations and measures them and feed this into", "tokens": [51160, 8320, 13411, 77, 3532, 10088, 300, 575, 992, 935, 31219, 763, 293, 8000, 552, 293, 3154, 341, 666, 51468], "temperature": 0.0, "avg_logprob": -0.10983344883594698, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.0003405003808438778}, {"id": 201, "seek": 128216, "start": 1304.24, "end": 1310.16, "text": " the prompt. So what this thing is doing is now generating a very complicated high-level story", "tokens": [51468, 264, 12391, 13, 407, 437, 341, 551, 307, 884, 307, 586, 17746, 257, 588, 6179, 1090, 12, 12418, 1657, 51764], "temperature": 0.0, "avg_logprob": -0.10983344883594698, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.0003405003808438778}, {"id": 202, "seek": 131016, "start": 1310.16, "end": 1315.68, "text": " and it doesn't need to be a story that is limited to text. It could also have visual elements,", "tokens": [50364, 293, 309, 1177, 380, 643, 281, 312, 257, 1657, 300, 307, 5567, 281, 2487, 13, 467, 727, 611, 362, 5056, 4959, 11, 50640], "temperature": 0.0, "avg_logprob": -0.10161960017573726, "compression_ratio": 1.713768115942029, "no_speech_prob": 0.0008036590879783034}, {"id": 203, "seek": 131016, "start": 1315.68, "end": 1319.76, "text": " it could have physical dynamics and so on because the transformer can learn all these things.", "tokens": [50640, 309, 727, 362, 4001, 15679, 293, 370, 322, 570, 264, 31782, 393, 1466, 439, 613, 721, 13, 50844], "temperature": 0.0, "avg_logprob": -0.10161960017573726, "compression_ratio": 1.713768115942029, "no_speech_prob": 0.0008036590879783034}, {"id": 204, "seek": 131016, "start": 1320.4, "end": 1325.44, "text": " So in some sense, it could generate a story about a conscious being that is similar as", "tokens": [50876, 407, 294, 512, 2020, 11, 309, 727, 8460, 257, 1657, 466, 257, 6648, 885, 300, 307, 2531, 382, 51128], "temperature": 0.0, "avg_logprob": -0.10161960017573726, "compression_ratio": 1.713768115942029, "no_speech_prob": 0.0008036590879783034}, {"id": 205, "seek": 131016, "start": 1325.44, "end": 1330.48, "text": " the story about a conscious being that's in our own mind. There's a basic difficulty that came up", "tokens": [51128, 264, 1657, 466, 257, 6648, 885, 300, 311, 294, 527, 1065, 1575, 13, 821, 311, 257, 3875, 10360, 300, 1361, 493, 51380], "temperature": 0.0, "avg_logprob": -0.10161960017573726, "compression_ratio": 1.713768115942029, "no_speech_prob": 0.0008036590879783034}, {"id": 206, "seek": 131016, "start": 1330.48, "end": 1339.2, "text": " and I discussed this with my friend and colleague Tanja Greenberg. Do we know when a person appears", "tokens": [51380, 293, 286, 7152, 341, 365, 452, 1277, 293, 13532, 17046, 2938, 6969, 6873, 13, 1144, 321, 458, 562, 257, 954, 7038, 51816], "temperature": 0.0, "avg_logprob": -0.10161960017573726, "compression_ratio": 1.713768115942029, "no_speech_prob": 0.0008036590879783034}, {"id": 207, "seek": 133920, "start": 1339.2, "end": 1342.96, "text": " in our own mind, for instance, during a dream at night, if we talk to that person in our dream,", "tokens": [50364, 294, 527, 1065, 1575, 11, 337, 5197, 11, 1830, 257, 3055, 412, 1818, 11, 498, 321, 751, 281, 300, 954, 294, 527, 3055, 11, 50552], "temperature": 0.0, "avg_logprob": -0.1351981480916341, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.0011506982846185565}, {"id": 208, "seek": 133920, "start": 1342.96, "end": 1348.4, "text": " whether that other person that we imagine in our dream is conscious or not? And clearly,", "tokens": [50552, 1968, 300, 661, 954, 300, 321, 3811, 294, 527, 3055, 307, 6648, 420, 406, 30, 400, 4448, 11, 50824], "temperature": 0.0, "avg_logprob": -0.1351981480916341, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.0011506982846185565}, {"id": 209, "seek": 133920, "start": 1348.4, "end": 1354.32, "text": " if we ask the other person, we might not get an answer that is true because if this thing is only", "tokens": [50824, 498, 321, 1029, 264, 661, 954, 11, 321, 1062, 406, 483, 364, 1867, 300, 307, 2074, 570, 498, 341, 551, 307, 787, 51120], "temperature": 0.0, "avg_logprob": -0.1351981480916341, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.0011506982846185565}, {"id": 210, "seek": 133920, "start": 1354.32, "end": 1359.1200000000001, "text": " a simulacrum that pretends to be conscious without being conscious and is just manipulated behind the", "tokens": [51120, 257, 1034, 425, 326, 6247, 300, 1162, 2581, 281, 312, 6648, 1553, 885, 6648, 293, 307, 445, 37161, 2261, 264, 51360], "temperature": 0.0, "avg_logprob": -0.1351981480916341, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.0011506982846185565}, {"id": 211, "seek": 133920, "start": 1359.1200000000001, "end": 1366.4, "text": " scenes, how would we find out? On the other hand, I also know that I am an imaginary person that is", "tokens": [51360, 8026, 11, 577, 576, 321, 915, 484, 30, 1282, 264, 661, 1011, 11, 286, 611, 458, 300, 286, 669, 364, 26164, 954, 300, 307, 51724], "temperature": 0.0, "avg_logprob": -0.1351981480916341, "compression_ratio": 1.8264150943396227, "no_speech_prob": 0.0011506982846185565}, {"id": 212, "seek": 136640, "start": 1366.4, "end": 1370.72, "text": " imagined by my brain. It's a model that my brain has discovered about the state of affairs,", "tokens": [50364, 16590, 538, 452, 3567, 13, 467, 311, 257, 2316, 300, 452, 3567, 575, 6941, 466, 264, 1785, 295, 17478, 11, 50580], "temperature": 0.0, "avg_logprob": -0.09822292495192143, "compression_ratio": 1.8045112781954886, "no_speech_prob": 0.004461650270968676}, {"id": 213, "seek": 136640, "start": 1370.72, "end": 1377.1200000000001, "text": " about an organism in the physical world, but this model of consciousness is an entirely virtual", "tokens": [50580, 466, 364, 24128, 294, 264, 4001, 1002, 11, 457, 341, 2316, 295, 10081, 307, 364, 7696, 6374, 50900], "temperature": 0.0, "avg_logprob": -0.09822292495192143, "compression_ratio": 1.8045112781954886, "no_speech_prob": 0.004461650270968676}, {"id": 214, "seek": 136640, "start": 1377.1200000000001, "end": 1383.1200000000001, "text": " story and I know that this story is not real. It's a figment of my imagination. And of course,", "tokens": [50900, 1657, 293, 286, 458, 300, 341, 1657, 307, 406, 957, 13, 467, 311, 257, 2147, 518, 295, 452, 12938, 13, 400, 295, 1164, 11, 51200], "temperature": 0.0, "avg_logprob": -0.09822292495192143, "compression_ratio": 1.8045112781954886, "no_speech_prob": 0.004461650270968676}, {"id": 215, "seek": 136640, "start": 1383.1200000000001, "end": 1387.92, "text": " there's also a continuum between characters that I imagine in my mind and myself because I can imagine", "tokens": [51200, 456, 311, 611, 257, 36120, 1296, 4342, 300, 286, 3811, 294, 452, 1575, 293, 2059, 570, 286, 393, 3811, 51440], "temperature": 0.0, "avg_logprob": -0.09822292495192143, "compression_ratio": 1.8045112781954886, "no_speech_prob": 0.004461650270968676}, {"id": 216, "seek": 136640, "start": 1387.92, "end": 1393.92, "text": " myself to be that character. If I, for instance, write a book and I imagine a character in the", "tokens": [51440, 2059, 281, 312, 300, 2517, 13, 759, 286, 11, 337, 5197, 11, 2464, 257, 1446, 293, 286, 3811, 257, 2517, 294, 264, 51740], "temperature": 0.0, "avg_logprob": -0.09822292495192143, "compression_ratio": 1.8045112781954886, "no_speech_prob": 0.004461650270968676}, {"id": 217, "seek": 139392, "start": 1393.92, "end": 1398.5600000000002, "text": " book very intensely, then at some point I might find myself to be that character in the book where", "tokens": [50364, 1446, 588, 43235, 11, 550, 412, 512, 935, 286, 1062, 915, 2059, 281, 312, 300, 2517, 294, 264, 1446, 689, 50596], "temperature": 0.0, "avg_logprob": -0.0741058465476348, "compression_ratio": 1.7276119402985075, "no_speech_prob": 0.000397944706492126}, {"id": 218, "seek": 139392, "start": 1398.5600000000002, "end": 1405.6000000000001, "text": " I suspend all my disbelief and this conscious being is not different from me. So basically,", "tokens": [50596, 286, 42546, 439, 452, 36105, 2521, 293, 341, 6648, 885, 307, 406, 819, 490, 385, 13, 407, 1936, 11, 50948], "temperature": 0.0, "avg_logprob": -0.0741058465476348, "compression_ratio": 1.7276119402985075, "no_speech_prob": 0.000397944706492126}, {"id": 219, "seek": 139392, "start": 1405.6000000000001, "end": 1411.52, "text": " there is a pretty fuzzy area where it's hard to say whether an imaginary person is conscious or not.", "tokens": [50948, 456, 307, 257, 1238, 34710, 1859, 689, 309, 311, 1152, 281, 584, 1968, 364, 26164, 954, 307, 6648, 420, 406, 13, 51244], "temperature": 0.0, "avg_logprob": -0.0741058465476348, "compression_ratio": 1.7276119402985075, "no_speech_prob": 0.000397944706492126}, {"id": 220, "seek": 139392, "start": 1411.52, "end": 1417.28, "text": " It's difficult to say. How does this work in biological systems? In biological systems,", "tokens": [51244, 467, 311, 2252, 281, 584, 13, 1012, 775, 341, 589, 294, 13910, 3652, 30, 682, 13910, 3652, 11, 51532], "temperature": 0.0, "avg_logprob": -0.0741058465476348, "compression_ratio": 1.7276119402985075, "no_speech_prob": 0.000397944706492126}, {"id": 221, "seek": 139392, "start": 1418.0, "end": 1421.76, "text": " we don't use a technological design. They are designed in a very different way from", "tokens": [51568, 321, 500, 380, 764, 257, 18439, 1715, 13, 814, 366, 4761, 294, 257, 588, 819, 636, 490, 51756], "temperature": 0.0, "avg_logprob": -0.0741058465476348, "compression_ratio": 1.7276119402985075, "no_speech_prob": 0.000397944706492126}, {"id": 222, "seek": 142176, "start": 1422.48, "end": 1428.32, "text": " the technological artifacts that we are building when we're writing computer programs or building", "tokens": [50400, 264, 18439, 24617, 300, 321, 366, 2390, 562, 321, 434, 3579, 3820, 4268, 420, 2390, 50692], "temperature": 0.0, "avg_logprob": -0.12265956692579316, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.0007091828156262636}, {"id": 223, "seek": 142176, "start": 1428.32, "end": 1434.32, "text": " machinery. In technological systems, we start out with an environment that is deterministic. We", "tokens": [50692, 27302, 13, 682, 18439, 3652, 11, 321, 722, 484, 365, 364, 2823, 300, 307, 15957, 3142, 13, 492, 50992], "temperature": 0.0, "avg_logprob": -0.12265956692579316, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.0007091828156262636}, {"id": 224, "seek": 142176, "start": 1434.32, "end": 1439.6, "text": " know how our workshop works. We know how our computer works. We start basically with some kind of a", "tokens": [50992, 458, 577, 527, 13541, 1985, 13, 492, 458, 577, 527, 3820, 1985, 13, 492, 722, 1936, 365, 512, 733, 295, 257, 51256], "temperature": 0.0, "avg_logprob": -0.12265956692579316, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.0007091828156262636}, {"id": 225, "seek": 142176, "start": 1439.6, "end": 1446.16, "text": " pretty much blank slate and then we decide what the functionality is by which we want to extend", "tokens": [51256, 1238, 709, 8247, 39118, 293, 550, 321, 4536, 437, 264, 14980, 307, 538, 597, 321, 528, 281, 10101, 51584], "temperature": 0.0, "avg_logprob": -0.12265956692579316, "compression_ratio": 1.706140350877193, "no_speech_prob": 0.0007091828156262636}, {"id": 226, "seek": 144616, "start": 1446.16, "end": 1453.52, "text": " our world and then we design from the outside in and into the material and so on and force the", "tokens": [50364, 527, 1002, 293, 550, 321, 1715, 490, 264, 2380, 294, 293, 666, 264, 2527, 293, 370, 322, 293, 3464, 264, 50732], "temperature": 0.0, "avg_logprob": -0.11351812233045264, "compression_ratio": 1.8192307692307692, "no_speech_prob": 0.0008825138211250305}, {"id": 227, "seek": 144616, "start": 1453.52, "end": 1458.88, "text": " material, the substrate, to produce exactly what we want to have. And biological and social systems", "tokens": [50732, 2527, 11, 264, 27585, 11, 281, 5258, 2293, 437, 321, 528, 281, 362, 13, 400, 13910, 293, 2093, 3652, 51000], "temperature": 0.0, "avg_logprob": -0.11351812233045264, "compression_ratio": 1.8192307692307692, "no_speech_prob": 0.0008825138211250305}, {"id": 228, "seek": 144616, "start": 1458.88, "end": 1464.5600000000002, "text": " are designed from the inside out with some kind of meta design. It basically means that you cannot", "tokens": [51000, 366, 4761, 490, 264, 1854, 484, 365, 512, 733, 295, 19616, 1715, 13, 467, 1936, 1355, 300, 291, 2644, 51284], "temperature": 0.0, "avg_logprob": -0.11351812233045264, "compression_ratio": 1.8192307692307692, "no_speech_prob": 0.0008825138211250305}, {"id": 229, "seek": 144616, "start": 1464.5600000000002, "end": 1468.72, "text": " rely on the determinism of the universe. You have to colonize your substrate first and", "tokens": [51284, 10687, 322, 264, 15957, 1434, 295, 264, 6445, 13, 509, 362, 281, 8255, 1125, 428, 27585, 700, 293, 51492], "temperature": 0.0, "avg_logprob": -0.11351812233045264, "compression_ratio": 1.8192307692307692, "no_speech_prob": 0.0008825138211250305}, {"id": 230, "seek": 144616, "start": 1469.44, "end": 1473.76, "text": " extend your own functional principles and your determinism into the substrate before you can", "tokens": [51528, 10101, 428, 1065, 11745, 9156, 293, 428, 15957, 1434, 666, 264, 27585, 949, 291, 393, 51744], "temperature": 0.0, "avg_logprob": -0.11351812233045264, "compression_ratio": 1.8192307692307692, "no_speech_prob": 0.0008825138211250305}, {"id": 231, "seek": 147376, "start": 1473.76, "end": 1479.28, "text": " make it do what you want it to do. And basically, you have to, instead of realizing the functionality,", "tokens": [50364, 652, 309, 360, 437, 291, 528, 309, 281, 360, 13, 400, 1936, 11, 291, 362, 281, 11, 2602, 295, 16734, 264, 14980, 11, 50640], "temperature": 0.0, "avg_logprob": -0.11853139334862385, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.0004107120621483773}, {"id": 232, "seek": 147376, "start": 1479.28, "end": 1483.28, "text": " build a system that wants to realize the functionality, that trans converges towards", "tokens": [50640, 1322, 257, 1185, 300, 2738, 281, 4325, 264, 14980, 11, 300, 1145, 9652, 2880, 3030, 50840], "temperature": 0.0, "avg_logprob": -0.11853139334862385, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.0004107120621483773}, {"id": 233, "seek": 147376, "start": 1483.28, "end": 1488.96, "text": " realizing that functionality. So a tree is not just a set of functions that realizes the transfer", "tokens": [50840, 16734, 300, 14980, 13, 407, 257, 4230, 307, 406, 445, 257, 992, 295, 6828, 300, 29316, 264, 5003, 51124], "temperature": 0.0, "avg_logprob": -0.11853139334862385, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.0004107120621483773}, {"id": 234, "seek": 147376, "start": 1488.96, "end": 1493.6, "text": " of nutrients from the roots to the leaves and photosynthesis and so on. But first of all,", "tokens": [51124, 295, 17617, 490, 264, 10669, 281, 264, 5510, 293, 5787, 45601, 293, 370, 322, 13, 583, 700, 295, 439, 11, 51356], "temperature": 0.0, "avg_logprob": -0.11853139334862385, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.0004107120621483773}, {"id": 235, "seek": 147376, "start": 1493.6, "end": 1500.64, "text": " it starts out as a seed that is going to colonize the ground and the earth, the material around", "tokens": [51356, 309, 3719, 484, 382, 257, 8871, 300, 307, 516, 281, 8255, 1125, 264, 2727, 293, 264, 4120, 11, 264, 2527, 926, 51708], "temperature": 0.0, "avg_logprob": -0.11853139334862385, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.0004107120621483773}, {"id": 236, "seek": 150064, "start": 1500.64, "end": 1505.44, "text": " the seed is going to turn it more and more into a tree. And if you disturb that system by harming", "tokens": [50364, 264, 8871, 307, 516, 281, 1261, 309, 544, 293, 544, 666, 257, 4230, 13, 400, 498, 291, 18071, 300, 1185, 538, 2233, 2810, 50604], "temperature": 0.0, "avg_logprob": -0.08989996294821462, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.001064712880179286}, {"id": 237, "seek": 150064, "start": 1505.44, "end": 1509.8400000000001, "text": " it and hurting it, you don't do it too much, so it gets destroyed a little bit, then it's going to", "tokens": [50604, 309, 293, 17744, 309, 11, 291, 500, 380, 360, 309, 886, 709, 11, 370, 309, 2170, 8937, 257, 707, 857, 11, 550, 309, 311, 516, 281, 50824], "temperature": 0.0, "avg_logprob": -0.08989996294821462, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.001064712880179286}, {"id": 238, "seek": 150064, "start": 1509.8400000000001, "end": 1515.6000000000001, "text": " grow back into a tree. And so it is something that is a proto tree and eventually converges into", "tokens": [50824, 1852, 646, 666, 257, 4230, 13, 400, 370, 309, 307, 746, 300, 307, 257, 47896, 4230, 293, 4728, 9652, 2880, 666, 51112], "temperature": 0.0, "avg_logprob": -0.08989996294821462, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.001064712880179286}, {"id": 239, "seek": 150064, "start": 1515.6000000000001, "end": 1522.16, "text": " being a tree. And this thing needs to have some agency to make that happen. It needs to be a model", "tokens": [51112, 885, 257, 4230, 13, 400, 341, 551, 2203, 281, 362, 512, 7934, 281, 652, 300, 1051, 13, 467, 2203, 281, 312, 257, 2316, 51440], "temperature": 0.0, "avg_logprob": -0.08989996294821462, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.001064712880179286}, {"id": 240, "seek": 150064, "start": 1522.16, "end": 1528.0, "text": " of the future that is being achieved in the system. And biological neurons are agents in the sense", "tokens": [51440, 295, 264, 2027, 300, 307, 885, 11042, 294, 264, 1185, 13, 400, 13910, 22027, 366, 12554, 294, 264, 2020, 51732], "temperature": 0.0, "avg_logprob": -0.08989996294821462, "compression_ratio": 1.8458646616541354, "no_speech_prob": 0.001064712880179286}, {"id": 241, "seek": 152800, "start": 1528.0, "end": 1536.08, "text": " as well, that designed the mind from the inside out, not from the outside in. Here you see a bunch", "tokens": [50364, 382, 731, 11, 300, 4761, 264, 1575, 490, 264, 1854, 484, 11, 406, 490, 264, 2380, 294, 13, 1692, 291, 536, 257, 3840, 50768], "temperature": 0.0, "avg_logprob": -0.13092404415732936, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001323418808169663}, {"id": 242, "seek": 152800, "start": 1536.08, "end": 1542.56, "text": " of cortical red neurons that are filmed in the pitch petition. You see how they're trying to link", "tokens": [50768, 295, 11278, 804, 2182, 22027, 300, 366, 15133, 294, 264, 7293, 22661, 13, 509, 536, 577, 436, 434, 1382, 281, 2113, 51092], "temperature": 0.0, "avg_logprob": -0.13092404415732936, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001323418808169663}, {"id": 243, "seek": 152800, "start": 1542.56, "end": 1551.12, "text": " up to each other and form some kind of organization. And we have something like 86 billion of these", "tokens": [51092, 493, 281, 1184, 661, 293, 1254, 512, 733, 295, 4475, 13, 400, 321, 362, 746, 411, 26687, 5218, 295, 613, 51520], "temperature": 0.0, "avg_logprob": -0.13092404415732936, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001323418808169663}, {"id": 244, "seek": 152800, "start": 1551.12, "end": 1556.64, "text": " neurons in our brain. And they're organized in the neocortex in groups of something like 100 to", "tokens": [51520, 22027, 294, 527, 3567, 13, 400, 436, 434, 9983, 294, 264, 408, 905, 36143, 294, 3935, 295, 746, 411, 2319, 281, 51796], "temperature": 0.0, "avg_logprob": -0.13092404415732936, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.001323418808169663}, {"id": 245, "seek": 155664, "start": 1556.64, "end": 1563.2800000000002, "text": " 400 neurons, which are cortical columns. And we have something in the ballpark of 100 million", "tokens": [50364, 8423, 22027, 11, 597, 366, 11278, 804, 13766, 13, 400, 321, 362, 746, 294, 264, 2594, 31239, 295, 2319, 2459, 50696], "temperature": 0.0, "avg_logprob": -0.10435379973245323, "compression_ratio": 1.844621513944223, "no_speech_prob": 0.0008553990628570318}, {"id": 246, "seek": 155664, "start": 1563.2800000000002, "end": 1567.8400000000001, "text": " of these cortical columns. And I think of a cortical column as something as a state machine.", "tokens": [50696, 295, 613, 11278, 804, 13766, 13, 400, 286, 519, 295, 257, 11278, 804, 7738, 382, 746, 382, 257, 1785, 3479, 13, 50924], "temperature": 0.0, "avg_logprob": -0.10435379973245323, "compression_ratio": 1.844621513944223, "no_speech_prob": 0.0008553990628570318}, {"id": 247, "seek": 155664, "start": 1567.8400000000001, "end": 1572.48, "text": " There's a protocol that allows it to link up to the cortical columns around it. It's trained to be", "tokens": [50924, 821, 311, 257, 10336, 300, 4045, 309, 281, 2113, 493, 281, 264, 11278, 804, 13766, 926, 309, 13, 467, 311, 8895, 281, 312, 51156], "temperature": 0.0, "avg_logprob": -0.10435379973245323, "compression_ratio": 1.844621513944223, "no_speech_prob": 0.0008553990628570318}, {"id": 248, "seek": 155664, "start": 1572.48, "end": 1579.3600000000001, "text": " like this. And each of them approximates functions. And these functions play out in", "tokens": [51156, 411, 341, 13, 400, 1184, 295, 552, 8542, 1024, 6828, 13, 400, 613, 6828, 862, 484, 294, 51500], "temperature": 0.0, "avg_logprob": -0.10435379973245323, "compression_ratio": 1.844621513944223, "no_speech_prob": 0.0008553990628570318}, {"id": 249, "seek": 155664, "start": 1579.3600000000001, "end": 1584.72, "text": " brain areas that are basically like something like an ether in which activation waves appear.", "tokens": [51500, 3567, 3179, 300, 366, 1936, 411, 746, 411, 364, 37096, 294, 597, 24433, 9417, 4204, 13, 51768], "temperature": 0.0, "avg_logprob": -0.10435379973245323, "compression_ratio": 1.844621513944223, "no_speech_prob": 0.0008553990628570318}, {"id": 250, "seek": 158472, "start": 1584.72, "end": 1590.24, "text": " And these activation waves represent the calculation of dynamic functions, which are", "tokens": [50364, 400, 613, 24433, 9417, 2906, 264, 17108, 295, 8546, 6828, 11, 597, 366, 50640], "temperature": 0.0, "avg_logprob": -0.11469397337540337, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.00043712565093301237}, {"id": 251, "seek": 158472, "start": 1590.24, "end": 1595.68, "text": " features of different cognitive domains. And the brain areas are talking to each other", "tokens": [50640, 4122, 295, 819, 15605, 25514, 13, 400, 264, 3567, 3179, 366, 1417, 281, 1184, 661, 50912], "temperature": 0.0, "avg_logprob": -0.11469397337540337, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.00043712565093301237}, {"id": 252, "seek": 158472, "start": 1596.4, "end": 1602.0, "text": " and listening to each other and so on, form processing streams. And sometimes use the", "tokens": [50948, 293, 4764, 281, 1184, 661, 293, 370, 322, 11, 1254, 9007, 15842, 13, 400, 2171, 764, 264, 51228], "temperature": 0.0, "avg_logprob": -0.11469397337540337, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.00043712565093301237}, {"id": 253, "seek": 158472, "start": 1602.0, "end": 1607.6000000000001, "text": " metaphor of a cortical orchestra where basically every brain area is somewhat akin to an instrument.", "tokens": [51228, 19157, 295, 257, 11278, 804, 25280, 689, 1936, 633, 3567, 1859, 307, 8344, 47540, 281, 364, 7198, 13, 51508], "temperature": 0.0, "avg_logprob": -0.11469397337540337, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.00043712565093301237}, {"id": 254, "seek": 158472, "start": 1607.6000000000001, "end": 1613.04, "text": " And the different instruments are listening to what is being played in the environment. And they", "tokens": [51508, 400, 264, 819, 12190, 366, 4764, 281, 437, 307, 885, 3737, 294, 264, 2823, 13, 400, 436, 51780], "temperature": 0.0, "avg_logprob": -0.11469397337540337, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.00043712565093301237}, {"id": 255, "seek": 161304, "start": 1613.6, "end": 1617.84, "text": " are taking up these things and complicating them and then passing them on to other instruments.", "tokens": [50392, 366, 1940, 493, 613, 721, 293, 16060, 990, 552, 293, 550, 8437, 552, 322, 281, 661, 12190, 13, 50604], "temperature": 0.0, "avg_logprob": -0.1465221643447876, "compression_ratio": 1.8186274509803921, "no_speech_prob": 0.002669186796993017}, {"id": 256, "seek": 161304, "start": 1618.48, "end": 1626.32, "text": " And this orchestra is dealing at some of the outer fringes with sensory patterns and actuator", "tokens": [50636, 400, 341, 25280, 307, 6260, 412, 512, 295, 264, 10847, 431, 278, 279, 365, 27233, 8294, 293, 34964, 1639, 51028], "temperature": 0.0, "avg_logprob": -0.1465221643447876, "compression_ratio": 1.8186274509803921, "no_speech_prob": 0.002669186796993017}, {"id": 257, "seek": 161304, "start": 1626.32, "end": 1631.68, "text": " patterns and then abstracts them into geometry and spatial structure and into generative", "tokens": [51028, 8294, 293, 550, 12649, 82, 552, 666, 18426, 293, 23598, 3877, 293, 666, 1337, 1166, 51296], "temperature": 0.0, "avg_logprob": -0.1465221643447876, "compression_ratio": 1.8186274509803921, "no_speech_prob": 0.002669186796993017}, {"id": 258, "seek": 161304, "start": 1631.68, "end": 1637.92, "text": " simulations of the world and into conceptual abstractions and so on. And the entire thing is", "tokens": [51296, 35138, 295, 264, 1002, 293, 666, 24106, 12649, 626, 293, 370, 322, 13, 400, 264, 2302, 551, 307, 51608], "temperature": 0.0, "avg_logprob": -0.1465221643447876, "compression_ratio": 1.8186274509803921, "no_speech_prob": 0.002669186796993017}, {"id": 259, "seek": 163792, "start": 1637.92, "end": 1644.72, "text": " being attended by some conductor. And the conductor is not some CPU that sits inside", "tokens": [50364, 885, 15990, 538, 512, 29957, 13, 400, 264, 29957, 307, 406, 512, 13199, 300, 12696, 1854, 50704], "temperature": 0.0, "avg_logprob": -0.0807182252407074, "compression_ratio": 1.6748768472906403, "no_speech_prob": 0.0038205417804419994}, {"id": 260, "seek": 163792, "start": 1644.72, "end": 1650.3200000000002, "text": " of the brain, like the CPU sits inside of your computer and makes things happen,", "tokens": [50704, 295, 264, 3567, 11, 411, 264, 13199, 12696, 1854, 295, 428, 3820, 293, 1669, 721, 1051, 11, 50984], "temperature": 0.0, "avg_logprob": -0.0807182252407074, "compression_ratio": 1.6748768472906403, "no_speech_prob": 0.0038205417804419994}, {"id": 261, "seek": 163792, "start": 1650.3200000000002, "end": 1654.16, "text": " but it's an instrument like the others. And it can only listen to what the rest of the", "tokens": [50984, 457, 309, 311, 364, 7198, 411, 264, 2357, 13, 400, 309, 393, 787, 2140, 281, 437, 264, 1472, 295, 264, 51176], "temperature": 0.0, "avg_logprob": -0.0807182252407074, "compression_ratio": 1.6748768472906403, "no_speech_prob": 0.0038205417804419994}, {"id": 262, "seek": 163792, "start": 1654.16, "end": 1663.04, "text": " orchestra is doing very superficially. And its role is to make that orchestra coherent,", "tokens": [51176, 25280, 307, 884, 588, 23881, 2270, 13, 400, 1080, 3090, 307, 281, 652, 300, 25280, 36239, 11, 51620], "temperature": 0.0, "avg_logprob": -0.0807182252407074, "compression_ratio": 1.6748768472906403, "no_speech_prob": 0.0038205417804419994}, {"id": 263, "seek": 166304, "start": 1663.04, "end": 1669.12, "text": " to let it play a single thing at any given time and to remove inconsistencies between what the", "tokens": [50364, 281, 718, 309, 862, 257, 2167, 551, 412, 604, 2212, 565, 293, 281, 4159, 22039, 4821, 4629, 1296, 437, 264, 50668], "temperature": 0.0, "avg_logprob": -0.08698793860042796, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.007439370267093182}, {"id": 264, "seek": 166304, "start": 1669.12, "end": 1677.52, "text": " individual instruments are playing. And if the conductor uses the connection to the system at", "tokens": [50668, 2609, 12190, 366, 2433, 13, 400, 498, 264, 29957, 4960, 264, 4984, 281, 264, 1185, 412, 51088], "temperature": 0.0, "avg_logprob": -0.08698793860042796, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.007439370267093182}, {"id": 265, "seek": 166304, "start": 1677.52, "end": 1682.32, "text": " night when you dream, then the orchestra doesn't necessarily stop, but it can go into something", "tokens": [51088, 1818, 562, 291, 3055, 11, 550, 264, 25280, 1177, 380, 4725, 1590, 11, 457, 309, 393, 352, 666, 746, 51328], "temperature": 0.0, "avg_logprob": -0.08698793860042796, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.007439370267093182}, {"id": 266, "seek": 166304, "start": 1682.32, "end": 1688.96, "text": " like a free jazz mode, where it's no longer connected to an audience and the audience is dark", "tokens": [51328, 411, 257, 1737, 15066, 4391, 11, 689, 309, 311, 572, 2854, 4582, 281, 364, 4034, 293, 264, 4034, 307, 2877, 51660], "temperature": 0.0, "avg_logprob": -0.08698793860042796, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.007439370267093182}, {"id": 267, "seek": 168896, "start": 1688.96, "end": 1694.32, "text": " because you are dissociated from your sensory apparatus at night when you dream. And so this", "tokens": [50364, 570, 291, 366, 44446, 770, 490, 428, 27233, 38573, 412, 1818, 562, 291, 3055, 13, 400, 370, 341, 50632], "temperature": 0.0, "avg_logprob": -0.10261434929393162, "compression_ratio": 1.773076923076923, "no_speech_prob": 0.004122668877243996}, {"id": 268, "seek": 168896, "start": 1694.32, "end": 1699.28, "text": " thing is just spinning off. And sometimes it can become very incoherent, sometimes it's going to", "tokens": [50632, 551, 307, 445, 15640, 766, 13, 400, 2171, 309, 393, 1813, 588, 834, 78, 511, 317, 11, 2171, 309, 311, 516, 281, 50880], "temperature": 0.0, "avg_logprob": -0.10261434929393162, "compression_ratio": 1.773076923076923, "no_speech_prob": 0.004122668877243996}, {"id": 269, "seek": 168896, "start": 1699.28, "end": 1705.68, "text": " settle into a groove, but it's not going to generate a unified model of a universe that", "tokens": [50880, 11852, 666, 257, 26910, 11, 457, 309, 311, 406, 516, 281, 8460, 257, 26787, 2316, 295, 257, 6445, 300, 51200], "temperature": 0.0, "avg_logprob": -0.10261434929393162, "compression_ratio": 1.773076923076923, "no_speech_prob": 0.004122668877243996}, {"id": 270, "seek": 168896, "start": 1705.68, "end": 1711.28, "text": " it's entangled with reality that it's connected to, that it tracks as it does during daytime.", "tokens": [51200, 309, 311, 948, 39101, 365, 4103, 300, 309, 311, 4582, 281, 11, 300, 309, 10218, 382, 309, 775, 1830, 31908, 13, 51480], "temperature": 0.0, "avg_logprob": -0.10261434929393162, "compression_ratio": 1.773076923076923, "no_speech_prob": 0.004122668877243996}, {"id": 271, "seek": 168896, "start": 1711.28, "end": 1718.08, "text": " And this tracking of coherent reality seems to require some kind of government mechanism.", "tokens": [51480, 400, 341, 11603, 295, 36239, 4103, 2544, 281, 3651, 512, 733, 295, 2463, 7513, 13, 51820], "temperature": 0.0, "avg_logprob": -0.10261434929393162, "compression_ratio": 1.773076923076923, "no_speech_prob": 0.004122668877243996}, {"id": 272, "seek": 171808, "start": 1718.08, "end": 1722.48, "text": " This government mechanism emerges in the brain through some kind of a suspect new", "tokens": [50364, 639, 2463, 7513, 38965, 294, 264, 3567, 807, 512, 733, 295, 257, 9091, 777, 50584], "temperature": 0.0, "avg_logprob": -0.2041682041052616, "compression_ratio": 1.6123188405797102, "no_speech_prob": 0.0023906342685222626}, {"id": 273, "seek": 171808, "start": 1722.48, "end": 1727.1999999999998, "text": " Darwinism. There is some kind of evolutionary competition between different organizations", "tokens": [50584, 30233, 1434, 13, 821, 307, 512, 733, 295, 27567, 6211, 1296, 819, 6150, 50820], "temperature": 0.0, "avg_logprob": -0.2041682041052616, "compression_ratio": 1.6123188405797102, "no_speech_prob": 0.0023906342685222626}, {"id": 274, "seek": 171808, "start": 1727.1999999999998, "end": 1731.84, "text": " that your mind can have, and eventually the most stable one prevails. And this is your", "tokens": [50820, 300, 428, 1575, 393, 362, 11, 293, 4728, 264, 881, 8351, 472, 12642, 6227, 13, 400, 341, 307, 428, 51052], "temperature": 0.0, "avg_logprob": -0.2041682041052616, "compression_ratio": 1.6123188405797102, "no_speech_prob": 0.0023906342685222626}, {"id": 275, "seek": 171808, "start": 1732.8, "end": 1740.1599999999999, "text": " observing conscious self, an attention agent that is trying to make a coherent model of the world.", "tokens": [51100, 22107, 6648, 2698, 11, 364, 3202, 9461, 300, 307, 1382, 281, 652, 257, 36239, 2316, 295, 264, 1002, 13, 51468], "temperature": 0.0, "avg_logprob": -0.2041682041052616, "compression_ratio": 1.6123188405797102, "no_speech_prob": 0.0023906342685222626}, {"id": 276, "seek": 171808, "start": 1741.36, "end": 1747.52, "text": " And now can we can ask does GPT-3 have such a conductor? And I think that the attention", "tokens": [51528, 400, 586, 393, 321, 393, 1029, 775, 26039, 51, 12, 18, 362, 1270, 257, 29957, 30, 400, 286, 519, 300, 264, 3202, 51836], "temperature": 0.0, "avg_logprob": -0.2041682041052616, "compression_ratio": 1.6123188405797102, "no_speech_prob": 0.0023906342685222626}, {"id": 277, "seek": 174752, "start": 1747.52, "end": 1753.12, "text": " model in the transformer looks a little bit like one, but it's not. So the new thing that GPT-3 had", "tokens": [50364, 2316, 294, 264, 31782, 1542, 257, 707, 857, 411, 472, 11, 457, 309, 311, 406, 13, 407, 264, 777, 551, 300, 26039, 51, 12, 18, 632, 50644], "temperature": 0.0, "avg_logprob": -0.09165178147037473, "compression_ratio": 1.821561338289963, "no_speech_prob": 0.0013245106674730778}, {"id": 278, "seek": 174752, "start": 1753.12, "end": 1759.52, "text": " that previous neural network training mechanisms usually didn't have was the ability to pay attention", "tokens": [50644, 300, 3894, 18161, 3209, 3097, 15902, 2673, 994, 380, 362, 390, 264, 3485, 281, 1689, 3202, 50964], "temperature": 0.0, "avg_logprob": -0.09165178147037473, "compression_ratio": 1.821561338289963, "no_speech_prob": 0.0013245106674730778}, {"id": 279, "seek": 174752, "start": 1759.52, "end": 1764.8799999999999, "text": " to what it should learn. This means that in every layer in this neural network, there is going to", "tokens": [50964, 281, 437, 309, 820, 1466, 13, 639, 1355, 300, 294, 633, 4583, 294, 341, 18161, 3209, 11, 456, 307, 516, 281, 51232], "temperature": 0.0, "avg_logprob": -0.09165178147037473, "compression_ratio": 1.821561338289963, "no_speech_prob": 0.0013245106674730778}, {"id": 280, "seek": 174752, "start": 1764.8799999999999, "end": 1769.2, "text": " be a model of what the previous layers, based on the current context, what data in the previous", "tokens": [51232, 312, 257, 2316, 295, 437, 264, 3894, 7914, 11, 2361, 322, 264, 2190, 4319, 11, 437, 1412, 294, 264, 3894, 51448], "temperature": 0.0, "avg_logprob": -0.09165178147037473, "compression_ratio": 1.821561338289963, "no_speech_prob": 0.0013245106674730778}, {"id": 281, "seek": 174752, "start": 1769.2, "end": 1774.4, "text": " layer, what features in the previous layer should it pay attention to. And this self attention", "tokens": [51448, 4583, 11, 437, 4122, 294, 264, 3894, 4583, 820, 309, 1689, 3202, 281, 13, 400, 341, 2698, 3202, 51708], "temperature": 0.0, "avg_logprob": -0.09165178147037473, "compression_ratio": 1.821561338289963, "no_speech_prob": 0.0013245106674730778}, {"id": 282, "seek": 177440, "start": 1774.4, "end": 1780.3200000000002, "text": " helps the network to learn basically its own structure and do statistics over and it makes", "tokens": [50364, 3665, 264, 3209, 281, 1466, 1936, 1080, 1065, 3877, 293, 360, 12523, 670, 293, 309, 1669, 50660], "temperature": 0.0, "avg_logprob": -0.1087489128112793, "compression_ratio": 1.6729323308270676, "no_speech_prob": 0.0006664673564955592}, {"id": 283, "seek": 177440, "start": 1780.3200000000002, "end": 1785.0400000000002, "text": " it much, much more efficient and coherent. But it's not integrated over all the layers", "tokens": [50660, 309, 709, 11, 709, 544, 7148, 293, 36239, 13, 583, 309, 311, 406, 10919, 670, 439, 264, 7914, 50896], "temperature": 0.0, "avg_logprob": -0.1087489128112793, "compression_ratio": 1.6729323308270676, "no_speech_prob": 0.0006664673564955592}, {"id": 284, "seek": 177440, "start": 1785.0400000000002, "end": 1790.64, "text": " into one model of reality and so on. So this is not what's happening in GPT-3 yet. And maybe", "tokens": [50896, 666, 472, 2316, 295, 4103, 293, 370, 322, 13, 407, 341, 307, 406, 437, 311, 2737, 294, 26039, 51, 12, 18, 1939, 13, 400, 1310, 51176], "temperature": 0.0, "avg_logprob": -0.1087489128112793, "compression_ratio": 1.6729323308270676, "no_speech_prob": 0.0006664673564955592}, {"id": 285, "seek": 177440, "start": 1790.64, "end": 1795.1200000000001, "text": " this is one of the reasons why it's so much slower in learning writing, so much more training data", "tokens": [51176, 341, 307, 472, 295, 264, 4112, 983, 309, 311, 370, 709, 14009, 294, 2539, 3579, 11, 370, 709, 544, 3097, 1412, 51400], "temperature": 0.0, "avg_logprob": -0.1087489128112793, "compression_ratio": 1.6729323308270676, "no_speech_prob": 0.0006664673564955592}, {"id": 286, "seek": 177440, "start": 1795.1200000000001, "end": 1798.64, "text": " than a human being needs over the course of their life before it converges.", "tokens": [51400, 813, 257, 1952, 885, 2203, 670, 264, 1164, 295, 641, 993, 949, 309, 9652, 2880, 13, 51576], "temperature": 0.0, "avg_logprob": -0.1087489128112793, "compression_ratio": 1.6729323308270676, "no_speech_prob": 0.0006664673564955592}, {"id": 287, "seek": 179864, "start": 1798.88, "end": 1806.48, "text": " And it's tempting to think that this such an integrated model of attention is something that", "tokens": [50376, 400, 309, 311, 37900, 281, 519, 300, 341, 1270, 364, 10919, 2316, 295, 3202, 307, 746, 300, 50756], "temperature": 0.0, "avg_logprob": -0.15923852359547336, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.000527247495483607}, {"id": 288, "seek": 179864, "start": 1806.48, "end": 1810.72, "text": " has, for instance, been suggested by Marvin Minsky in his seminal book, Society of Mind,", "tokens": [50756, 575, 11, 337, 5197, 11, 668, 10945, 538, 48722, 376, 44153, 294, 702, 4361, 2071, 1446, 11, 13742, 295, 13719, 11, 50968], "temperature": 0.0, "avg_logprob": -0.15923852359547336, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.000527247495483607}, {"id": 289, "seek": 179864, "start": 1810.72, "end": 1815.92, "text": " where you have basically look at the mind as a society of different agents. And there are some", "tokens": [50968, 689, 291, 362, 1936, 574, 412, 264, 1575, 382, 257, 4086, 295, 819, 12554, 13, 400, 456, 366, 512, 51228], "temperature": 0.0, "avg_logprob": -0.15923852359547336, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.000527247495483607}, {"id": 290, "seek": 179864, "start": 1815.92, "end": 1821.2800000000002, "text": " agents that are organizing the other agents into a coherent structure. And Minsky calls these agents", "tokens": [51228, 12554, 300, 366, 17608, 264, 661, 12554, 666, 257, 36239, 3877, 13, 400, 376, 44153, 5498, 613, 12554, 51496], "temperature": 0.0, "avg_logprob": -0.15923852359547336, "compression_ratio": 1.6535087719298245, "no_speech_prob": 0.000527247495483607}, {"id": 291, "seek": 182128, "start": 1821.28, "end": 1829.28, "text": " K-lines, knowledge lines, and suggests that they form basically their own society and society of", "tokens": [50364, 591, 12, 11045, 11, 3601, 3876, 11, 293, 13409, 300, 436, 1254, 1936, 641, 1065, 4086, 293, 4086, 295, 50764], "temperature": 0.0, "avg_logprob": -0.1062462329864502, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.002713869558647275}, {"id": 292, "seek": 182128, "start": 1829.28, "end": 1836.3999999999999, "text": " mind. And this society is forming something like a reflection of what's happening in the A-brain.", "tokens": [50764, 1575, 13, 400, 341, 4086, 307, 15745, 746, 411, 257, 12914, 295, 437, 311, 2737, 294, 264, 316, 12, 6198, 259, 13, 51120], "temperature": 0.0, "avg_logprob": -0.1062462329864502, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.002713869558647275}, {"id": 293, "seek": 182128, "start": 1836.3999999999999, "end": 1843.12, "text": " The A-brain being our perceptual mind that is modeling the reality that we are tracking based", "tokens": [51120, 440, 316, 12, 6198, 259, 885, 527, 43276, 901, 1575, 300, 307, 15983, 264, 4103, 300, 321, 366, 11603, 2361, 51456], "temperature": 0.0, "avg_logprob": -0.1062462329864502, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.002713869558647275}, {"id": 294, "seek": 182128, "start": 1843.12, "end": 1848.72, "text": " on sensory and actuator input that the brain is entangled with and the B-brain is immersed", "tokens": [51456, 322, 27233, 293, 34964, 1639, 4846, 300, 264, 3567, 307, 948, 39101, 365, 293, 264, 363, 12, 6198, 259, 307, 35416, 51736], "temperature": 0.0, "avg_logprob": -0.1062462329864502, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.002713869558647275}, {"id": 295, "seek": 184872, "start": 1848.72, "end": 1852.4, "text": " into this perceptual reality and reflects on it and makes it more coherent.", "tokens": [50364, 666, 341, 43276, 901, 4103, 293, 18926, 322, 309, 293, 1669, 309, 544, 36239, 13, 50548], "temperature": 0.0, "avg_logprob": -0.10830820449674973, "compression_ratio": 1.7065637065637065, "no_speech_prob": 0.0007548927678726614}, {"id": 296, "seek": 184872, "start": 1853.2, "end": 1859.2, "text": " And there is a similarity between Kahneman's famous System 1 and System 2. It's not quite", "tokens": [50588, 400, 456, 307, 257, 32194, 1296, 591, 12140, 15023, 311, 4618, 8910, 502, 293, 8910, 568, 13, 467, 311, 406, 1596, 50888], "temperature": 0.0, "avg_logprob": -0.10830820449674973, "compression_ratio": 1.7065637065637065, "no_speech_prob": 0.0007548927678726614}, {"id": 297, "seek": 184872, "start": 1859.2, "end": 1866.64, "text": " the same thing, but it's tempting to basically see the affair as a perception agent that is", "tokens": [50888, 264, 912, 551, 11, 457, 309, 311, 37900, 281, 1936, 536, 264, 22987, 382, 257, 12860, 9461, 300, 307, 51260], "temperature": 0.0, "avg_logprob": -0.10830820449674973, "compression_ratio": 1.7065637065637065, "no_speech_prob": 0.0007548927678726614}, {"id": 298, "seek": 184872, "start": 1866.64, "end": 1871.76, "text": " entangled with the environment and is getting valence from the motivational system that is", "tokens": [51260, 948, 39101, 365, 264, 2823, 293, 307, 1242, 1323, 655, 490, 264, 48186, 1185, 300, 307, 51516], "temperature": 0.0, "avg_logprob": -0.10830820449674973, "compression_ratio": 1.7065637065637065, "no_speech_prob": 0.0007548927678726614}, {"id": 299, "seek": 184872, "start": 1871.76, "end": 1877.04, "text": " basically cybernetic motivational architecture. And then you have an ancient agent that lives", "tokens": [51516, 1936, 13411, 77, 3532, 48186, 9482, 13, 400, 550, 291, 362, 364, 7832, 9461, 300, 2909, 51780], "temperature": 0.0, "avg_logprob": -0.10830820449674973, "compression_ratio": 1.7065637065637065, "no_speech_prob": 0.0007548927678726614}, {"id": 300, "seek": 187704, "start": 1877.04, "end": 1883.36, "text": " on top of the perceptual agent. And that is the conductor and has a memory of what it attends to", "tokens": [50364, 322, 1192, 295, 264, 43276, 901, 9461, 13, 400, 300, 307, 264, 29957, 293, 575, 257, 4675, 295, 437, 309, 49837, 281, 50680], "temperature": 0.0, "avg_logprob": -0.10608854501143745, "compression_ratio": 1.7488372093023257, "no_speech_prob": 0.0008162247249856591}, {"id": 301, "seek": 187704, "start": 1883.36, "end": 1890.6399999999999, "text": " so it can get the model to convert by some constructive process. And this attentional system,", "tokens": [50680, 370, 309, 393, 483, 264, 2316, 281, 7620, 538, 512, 30223, 1399, 13, 400, 341, 3202, 304, 1185, 11, 51044], "temperature": 0.0, "avg_logprob": -0.10608854501143745, "compression_ratio": 1.7488372093023257, "no_speech_prob": 0.0008162247249856591}, {"id": 302, "seek": 187704, "start": 1890.6399999999999, "end": 1898.96, "text": " this conductor, here I've drawn it on top of the system. The top is a direction that basically", "tokens": [51044, 341, 29957, 11, 510, 286, 600, 10117, 309, 322, 1192, 295, 264, 1185, 13, 440, 1192, 307, 257, 3513, 300, 1936, 51460], "temperature": 0.0, "avg_logprob": -0.10608854501143745, "compression_ratio": 1.7488372093023257, "no_speech_prob": 0.0008162247249856591}, {"id": 303, "seek": 187704, "start": 1898.96, "end": 1903.12, "text": " seems to be obvious to the attentional system itself because it feels to be on top, but we", "tokens": [51460, 2544, 281, 312, 6322, 281, 264, 3202, 304, 1185, 2564, 570, 309, 3417, 281, 312, 322, 1192, 11, 457, 321, 51668], "temperature": 0.0, "avg_logprob": -0.10608854501143745, "compression_ratio": 1.7488372093023257, "no_speech_prob": 0.0008162247249856591}, {"id": 304, "seek": 190312, "start": 1903.12, "end": 1907.6, "text": " know that you're not completely on top. There is stuff that is driven by the selves that we have", "tokens": [50364, 458, 300, 291, 434, 406, 2584, 322, 1192, 13, 821, 307, 1507, 300, 307, 9555, 538, 264, 41900, 300, 321, 362, 50588], "temperature": 0.0, "avg_logprob": -0.10393376783891158, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.0006561652990058064}, {"id": 305, "seek": 190312, "start": 1907.6, "end": 1912.6399999999999, "text": " not reversed and that we give a moment and that gives motivation to the attentional system to", "tokens": [50588, 406, 30563, 293, 300, 321, 976, 257, 1623, 293, 300, 2709, 12335, 281, 264, 3202, 304, 1185, 281, 50840], "temperature": 0.0, "avg_logprob": -0.10393376783891158, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.0006561652990058064}, {"id": 306, "seek": 190312, "start": 1912.6399999999999, "end": 1922.0, "text": " what it attends to. But our consciousness perceives itself as the observer of the mental and external", "tokens": [50840, 437, 309, 49837, 281, 13, 583, 527, 10081, 9016, 1539, 2564, 382, 264, 27878, 295, 264, 4973, 293, 8320, 51308], "temperature": 0.0, "avg_logprob": -0.10393376783891158, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.0006561652990058064}, {"id": 307, "seek": 190312, "start": 1922.0, "end": 1927.84, "text": " states and the self-states of the model that is being discovered. And the purpose of the", "tokens": [51308, 4368, 293, 264, 2698, 12, 372, 1024, 295, 264, 2316, 300, 307, 885, 6941, 13, 400, 264, 4334, 295, 264, 51600], "temperature": 0.0, "avg_logprob": -0.10393376783891158, "compression_ratio": 1.7638888888888888, "no_speech_prob": 0.0006561652990058064}, {"id": 308, "seek": 192784, "start": 1927.84, "end": 1934.48, "text": " attentional system is to facilitate learning so we can converge to a model of reality", "tokens": [50364, 3202, 304, 1185, 307, 281, 20207, 2539, 370, 321, 393, 41881, 281, 257, 2316, 295, 4103, 50696], "temperature": 0.0, "avg_logprob": -0.1579991306167051, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.000561321503482759}, {"id": 309, "seek": 192784, "start": 1934.48, "end": 1941.4399999999998, "text": " and reasoning, which is basically real-time learning on imaginary mental states. And this idea", "tokens": [50696, 293, 21577, 11, 597, 307, 1936, 957, 12, 3766, 2539, 322, 26164, 4973, 4368, 13, 400, 341, 1558, 51044], "temperature": 0.0, "avg_logprob": -0.1579991306167051, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.000561321503482759}, {"id": 310, "seek": 192784, "start": 1941.4399999999998, "end": 1946.56, "text": " that consciousness is a control model of our attention is not new. It's, for instance, been", "tokens": [51044, 300, 10081, 307, 257, 1969, 2316, 295, 527, 3202, 307, 406, 777, 13, 467, 311, 11, 337, 5197, 11, 668, 51300], "temperature": 0.0, "avg_logprob": -0.1579991306167051, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.000561321503482759}, {"id": 311, "seek": 192784, "start": 1946.56, "end": 1951.52, "text": " championed by Michael Graciano in the attention schema theory and it finds itself in one version or", "tokens": [51300, 10971, 292, 538, 5116, 20586, 6254, 294, 264, 3202, 34078, 5261, 293, 309, 10704, 2564, 294, 472, 3037, 420, 51548], "temperature": 0.0, "avg_logprob": -0.1579991306167051, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.000561321503482759}, {"id": 312, "seek": 195152, "start": 1951.52, "end": 1958.0, "text": " other in Eastern philosophies and in a lot of convergent ideas in cognitive science.", "tokens": [50364, 661, 294, 12901, 14529, 530, 293, 294, 257, 688, 295, 9652, 6930, 3487, 294, 15605, 3497, 13, 50688], "temperature": 0.0, "avg_logprob": -0.11628280639648438, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015715287299826741}, {"id": 313, "seek": 195152, "start": 1960.48, "end": 1964.48, "text": " Some people say that computers cannot be conscious because they are only physical", "tokens": [50812, 2188, 561, 584, 300, 10807, 2644, 312, 6648, 570, 436, 366, 787, 4001, 51012], "temperature": 0.0, "avg_logprob": -0.11628280639648438, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015715287299826741}, {"id": 314, "seek": 195152, "start": 1964.48, "end": 1973.76, "text": " mechanical systems and so they're not physical systems in the same way as the neurons are", "tokens": [51012, 12070, 3652, 293, 370, 436, 434, 406, 4001, 3652, 294, 264, 912, 636, 382, 264, 22027, 366, 51476], "temperature": 0.0, "avg_logprob": -0.11628280639648438, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015715287299826741}, {"id": 315, "seek": 195152, "start": 1973.76, "end": 1978.08, "text": " because neurons are entangled with the real world as dynamical systems and so on. They", "tokens": [51476, 570, 22027, 366, 948, 39101, 365, 264, 957, 1002, 382, 5999, 804, 3652, 293, 370, 322, 13, 814, 51692], "temperature": 0.0, "avg_logprob": -0.11628280639648438, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015715287299826741}, {"id": 316, "seek": 197808, "start": 1978.08, "end": 1984.08, "text": " can do things that the simulation cannot do. And I think that Frisk of Cork maybe has it backwards.", "tokens": [50364, 393, 360, 721, 300, 264, 16575, 2644, 360, 13, 400, 286, 519, 300, 1526, 7797, 295, 383, 1284, 1310, 575, 309, 12204, 13, 50664], "temperature": 0.0, "avg_logprob": -0.15152270977313703, "compression_ratio": 2.1205357142857144, "no_speech_prob": 0.000645918189547956}, {"id": 317, "seek": 197808, "start": 1984.08, "end": 1988.56, "text": " I think that physical systems cannot be conscious. Neurons cannot be conscious. Brains cannot be", "tokens": [50664, 286, 519, 300, 4001, 3652, 2644, 312, 6648, 13, 1734, 374, 892, 2644, 312, 6648, 13, 4991, 1292, 2644, 312, 50888], "temperature": 0.0, "avg_logprob": -0.15152270977313703, "compression_ratio": 2.1205357142857144, "no_speech_prob": 0.000645918189547956}, {"id": 318, "seek": 197808, "start": 1988.56, "end": 1993.4399999999998, "text": " conscious because there are things happening in consciousness that are not physically possible.", "tokens": [50888, 6648, 570, 456, 366, 721, 2737, 294, 10081, 300, 366, 406, 9762, 1944, 13, 51132], "temperature": 0.0, "avg_logprob": -0.15152270977313703, "compression_ratio": 2.1205357142857144, "no_speech_prob": 0.000645918189547956}, {"id": 319, "seek": 197808, "start": 1994.1599999999999, "end": 1998.6399999999999, "text": " And the only thing that can be conscious is the simulation because consciousness is the", "tokens": [51168, 400, 264, 787, 551, 300, 393, 312, 6648, 307, 264, 16575, 570, 10081, 307, 264, 51392], "temperature": 0.0, "avg_logprob": -0.15152270977313703, "compression_ratio": 2.1205357142857144, "no_speech_prob": 0.000645918189547956}, {"id": 320, "seek": 197808, "start": 1998.6399999999999, "end": 2005.76, "text": " simulated property. Consciousness is virtual. So you can only be conscious in a story that you", "tokens": [51392, 41713, 4707, 13, 6923, 4139, 1287, 307, 6374, 13, 407, 291, 393, 787, 312, 6648, 294, 257, 1657, 300, 291, 51748], "temperature": 0.0, "avg_logprob": -0.15152270977313703, "compression_ratio": 2.1205357142857144, "no_speech_prob": 0.000645918189547956}, {"id": 321, "seek": 200576, "start": 2005.76, "end": 2012.8, "text": " tell yourself about yourself. And this means that our phenomenal consciousness is a virtual state.", "tokens": [50364, 980, 1803, 466, 1803, 13, 400, 341, 1355, 300, 527, 17778, 10081, 307, 257, 6374, 1785, 13, 50716], "temperature": 0.0, "avg_logprob": -0.12963106117996515, "compression_ratio": 1.7827715355805243, "no_speech_prob": 0.0006457167910411954}, {"id": 322, "seek": 200576, "start": 2012.8, "end": 2017.6, "text": " It only exists inside of the mental models. It's not attending to physical phenomena.", "tokens": [50716, 467, 787, 8198, 1854, 295, 264, 4973, 5245, 13, 467, 311, 406, 15862, 281, 4001, 22004, 13, 50956], "temperature": 0.0, "avg_logprob": -0.12963106117996515, "compression_ratio": 1.7827715355805243, "no_speech_prob": 0.0006457167910411954}, {"id": 323, "seek": 200576, "start": 2018.56, "end": 2026.16, "text": " It's attending to high-level features, things like colors and sounds and emotional expressions and so", "tokens": [51004, 467, 311, 15862, 281, 1090, 12, 12418, 4122, 11, 721, 411, 4577, 293, 3263, 293, 6863, 15277, 293, 370, 51384], "temperature": 0.0, "avg_logprob": -0.12963106117996515, "compression_ratio": 1.7827715355805243, "no_speech_prob": 0.0006457167910411954}, {"id": 324, "seek": 200576, "start": 2026.16, "end": 2031.12, "text": " on. None of these are physical things, right? All these high-level abstractions that a learning", "tokens": [51384, 322, 13, 14492, 295, 613, 366, 4001, 721, 11, 558, 30, 1057, 613, 1090, 12, 12418, 12649, 626, 300, 257, 2539, 51632], "temperature": 0.0, "avg_logprob": -0.12963106117996515, "compression_ratio": 1.7827715355805243, "no_speech_prob": 0.0006457167910411954}, {"id": 325, "seek": 200576, "start": 2031.12, "end": 2035.52, "text": " system is generating in the interaction with the environment to make it predictable. And this", "tokens": [51632, 1185, 307, 17746, 294, 264, 9285, 365, 264, 2823, 281, 652, 309, 27737, 13, 400, 341, 51852], "temperature": 0.0, "avg_logprob": -0.12963106117996515, "compression_ratio": 1.7827715355805243, "no_speech_prob": 0.0006457167910411954}, {"id": 326, "seek": 203552, "start": 2035.52, "end": 2040.8799999999999, "text": " phenomenal consciousness, this experience of what it's like to attend to features is an awareness", "tokens": [50364, 17778, 10081, 11, 341, 1752, 295, 437, 309, 311, 411, 281, 6888, 281, 4122, 307, 364, 8888, 50632], "temperature": 0.0, "avg_logprob": -0.11976054895704037, "compression_ratio": 1.8841698841698842, "no_speech_prob": 0.0003567378444131464}, {"id": 327, "seek": 203552, "start": 2040.8799999999999, "end": 2046.16, "text": " of a partial binding state of our working memory. That's basically at the content at the interface", "tokens": [50632, 295, 257, 14641, 17359, 1785, 295, 527, 1364, 4675, 13, 663, 311, 1936, 412, 264, 2701, 412, 264, 9226, 50896], "temperature": 0.0, "avg_logprob": -0.11976054895704037, "compression_ratio": 1.8841698841698842, "no_speech_prob": 0.0003567378444131464}, {"id": 328, "seek": 203552, "start": 2046.16, "end": 2051.28, "text": " between perception and reflection. And then we are aware of the mode in which we're using attention.", "tokens": [50896, 1296, 12860, 293, 12914, 13, 400, 550, 321, 366, 3650, 295, 264, 4391, 294, 597, 321, 434, 1228, 3202, 13, 51152], "temperature": 0.0, "avg_logprob": -0.11976054895704037, "compression_ratio": 1.8841698841698842, "no_speech_prob": 0.0003567378444131464}, {"id": 329, "seek": 203552, "start": 2051.28, "end": 2056.32, "text": " So whether this is hypothetical or whether it's perceptual or whether it's a memory. And then", "tokens": [51152, 407, 1968, 341, 307, 33053, 420, 1968, 309, 311, 43276, 901, 420, 1968, 309, 311, 257, 4675, 13, 400, 550, 51404], "temperature": 0.0, "avg_logprob": -0.11976054895704037, "compression_ratio": 1.8841698841698842, "no_speech_prob": 0.0003567378444131464}, {"id": 330, "seek": 203552, "start": 2056.32, "end": 2061.44, "text": " the reflexive consciousness, this process that is attending, is aware that it's the process that", "tokens": [51404, 264, 23802, 488, 10081, 11, 341, 1399, 300, 307, 15862, 11, 307, 3650, 300, 309, 311, 264, 1399, 300, 51660], "temperature": 0.0, "avg_logprob": -0.11976054895704037, "compression_ratio": 1.8841698841698842, "no_speech_prob": 0.0003567378444131464}, {"id": 331, "seek": 206144, "start": 2061.44, "end": 2068.0, "text": " is attending and the space acting based on that awareness. And the AI researcher at Russia Benjio", "tokens": [50364, 307, 15862, 293, 264, 1901, 6577, 2361, 322, 300, 8888, 13, 400, 264, 7318, 21751, 412, 6797, 3964, 73, 1004, 50692], "temperature": 0.0, "avg_logprob": -0.16865938186645507, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0003858363488689065}, {"id": 332, "seek": 206144, "start": 2068.0, "end": 2073.84, "text": " said that consciousness is basically a function whose purpose is to create a big dip in the", "tokens": [50692, 848, 300, 10081, 307, 1936, 257, 2445, 6104, 4334, 307, 281, 1884, 257, 955, 10460, 294, 264, 50984], "temperature": 0.0, "avg_logprob": -0.16865938186645507, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0003858363488689065}, {"id": 333, "seek": 206144, "start": 2073.84, "end": 2078.16, "text": " energy function that models reality. So it's basically a low-dimensional almost discrete", "tokens": [50984, 2281, 2445, 300, 5245, 4103, 13, 407, 309, 311, 1936, 257, 2295, 12, 18759, 1920, 27706, 51200], "temperature": 0.0, "avg_logprob": -0.16865938186645507, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0003858363488689065}, {"id": 334, "seek": 206144, "start": 2078.16, "end": 2083.76, "text": " function that is parameterizing the perception in such a way that it starts to make sense.", "tokens": [51200, 2445, 300, 307, 13075, 3319, 264, 12860, 294, 1270, 257, 636, 300, 309, 3719, 281, 652, 2020, 13, 51480], "temperature": 0.0, "avg_logprob": -0.16865938186645507, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0003858363488689065}, {"id": 335, "seek": 206144, "start": 2086.2400000000002, "end": 2090.8, "text": " Self and conscious are not the same thing. The self is a model of your agency", "tokens": [51604, 16348, 293, 6648, 366, 406, 264, 912, 551, 13, 440, 2698, 307, 257, 2316, 295, 428, 7934, 51832], "temperature": 0.0, "avg_logprob": -0.16865938186645507, "compression_ratio": 1.7061068702290076, "no_speech_prob": 0.0003858363488689065}, {"id": 336, "seek": 209080, "start": 2090.88, "end": 2095.76, "text": " that you discover. And you can be conscious without having the self. For instance, during", "tokens": [50368, 300, 291, 4411, 13, 400, 291, 393, 312, 6648, 1553, 1419, 264, 2698, 13, 1171, 5197, 11, 1830, 50612], "temperature": 0.0, "avg_logprob": -0.11858238560138362, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0007665552548132837}, {"id": 337, "seek": 209080, "start": 2095.76, "end": 2101.52, "text": " dreams or meditation, you can turn off the self without losing consciousness. And the self is", "tokens": [50612, 7505, 420, 12537, 11, 291, 393, 1261, 766, 264, 2698, 1553, 7027, 10081, 13, 400, 264, 2698, 307, 50900], "temperature": 0.0, "avg_logprob": -0.11858238560138362, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0007665552548132837}, {"id": 338, "seek": 209080, "start": 2101.52, "end": 2106.8, "text": " this discovery of the agent that the system is making about what it is. And it's downstream", "tokens": [50900, 341, 12114, 295, 264, 9461, 300, 264, 1185, 307, 1455, 466, 437, 309, 307, 13, 400, 309, 311, 30621, 51164], "temperature": 0.0, "avg_logprob": -0.11858238560138362, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0007665552548132837}, {"id": 339, "seek": 209080, "start": 2106.8, "end": 2112.0800000000004, "text": " from the set point deviation. So the self is not motivating things, it experiences the motivation", "tokens": [51164, 490, 264, 992, 935, 25163, 13, 407, 264, 2698, 307, 406, 41066, 721, 11, 309, 5235, 264, 12335, 51428], "temperature": 0.0, "avg_logprob": -0.11858238560138362, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0007665552548132837}, {"id": 340, "seek": 209080, "start": 2112.0800000000004, "end": 2117.36, "text": " and begins to understand how the motivation works and thereby allows to reverse engineer the mind", "tokens": [51428, 293, 7338, 281, 1223, 577, 264, 12335, 1985, 293, 28281, 4045, 281, 9943, 11403, 264, 1575, 51692], "temperature": 0.0, "avg_logprob": -0.11858238560138362, "compression_ratio": 1.8255813953488371, "no_speech_prob": 0.0007665552548132837}, {"id": 341, "seek": 211736, "start": 2117.44, "end": 2123.6800000000003, "text": " if the self is learning. And it shapes our own agency by identifying who we think we are at any", "tokens": [50368, 498, 264, 2698, 307, 2539, 13, 400, 309, 10854, 527, 1065, 7934, 538, 16696, 567, 321, 519, 321, 366, 412, 604, 50680], "temperature": 0.0, "avg_logprob": -0.09168298667836412, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.00019713091023731977}, {"id": 342, "seek": 211736, "start": 2123.6800000000003, "end": 2129.28, "text": " given moment. And it allows to have a first-person perspective if the self is discovering that", "tokens": [50680, 2212, 1623, 13, 400, 309, 4045, 281, 362, 257, 700, 12, 10813, 4585, 498, 264, 2698, 307, 24773, 300, 50960], "temperature": 0.0, "avg_logprob": -0.09168298667836412, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.00019713091023731977}, {"id": 343, "seek": 211736, "start": 2129.28, "end": 2133.6800000000003, "text": " the contents of this control model are actually driving behavior. That makes it a very special", "tokens": [50960, 264, 15768, 295, 341, 1969, 2316, 366, 767, 4840, 5223, 13, 663, 1669, 309, 257, 588, 2121, 51180], "temperature": 0.0, "avg_logprob": -0.09168298667836412, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.00019713091023731977}, {"id": 344, "seek": 211736, "start": 2133.6800000000003, "end": 2138.88, "text": " agent. So in this sense, consciousness is a control model of attention. It allows the convergence", "tokens": [51180, 9461, 13, 407, 294, 341, 2020, 11, 10081, 307, 257, 1969, 2316, 295, 3202, 13, 467, 4045, 264, 32181, 51440], "temperature": 0.0, "avg_logprob": -0.09168298667836412, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.00019713091023731977}, {"id": 345, "seek": 211736, "start": 2138.88, "end": 2142.7200000000003, "text": " of a coherent interpretation of the world, which is basically a low energy state of the model that", "tokens": [51440, 295, 257, 36239, 14174, 295, 264, 1002, 11, 597, 307, 1936, 257, 2295, 2281, 1785, 295, 264, 2316, 300, 51632], "temperature": 0.0, "avg_logprob": -0.09168298667836412, "compression_ratio": 1.7591240875912408, "no_speech_prob": 0.00019713091023731977}, {"id": 346, "seek": 214272, "start": 2142.72, "end": 2148.0, "text": " attracts reality. And it maintains a memory for this aggregation. So that's why we have a stream", "tokens": [50364, 37026, 4103, 13, 400, 309, 33385, 257, 4675, 337, 341, 16743, 399, 13, 407, 300, 311, 983, 321, 362, 257, 4309, 50628], "temperature": 0.0, "avg_logprob": -0.15175562833262757, "compression_ratio": 1.6942446043165467, "no_speech_prob": 0.0009394545922987163}, {"id": 347, "seek": 214272, "start": 2148.0, "end": 2152.48, "text": " of consciousness. Because when you construct, you need to remember what you tried and where", "tokens": [50628, 295, 10081, 13, 1436, 562, 291, 7690, 11, 291, 643, 281, 1604, 437, 291, 3031, 293, 689, 50852], "temperature": 0.0, "avg_logprob": -0.15175562833262757, "compression_ratio": 1.6942446043165467, "no_speech_prob": 0.0009394545922987163}, {"id": 348, "seek": 214272, "start": 2152.48, "end": 2156.72, "text": " you're coming from. And this is not true, for instance, for convergent learning mechanisms", "tokens": [50852, 291, 434, 1348, 490, 13, 400, 341, 307, 406, 2074, 11, 337, 5197, 11, 337, 9652, 6930, 2539, 15902, 51064], "temperature": 0.0, "avg_logprob": -0.15175562833262757, "compression_ratio": 1.6942446043165467, "no_speech_prob": 0.0009394545922987163}, {"id": 349, "seek": 214272, "start": 2156.72, "end": 2161.2, "text": " like neural network learning, but you don't need to remember where you came from. We just go to", "tokens": [51064, 411, 18161, 3209, 2539, 11, 457, 291, 500, 380, 643, 281, 1604, 689, 291, 1361, 490, 13, 492, 445, 352, 281, 51288], "temperature": 0.0, "avg_logprob": -0.15175562833262757, "compression_ratio": 1.6942446043165467, "no_speech_prob": 0.0009394545922987163}, {"id": 350, "seek": 214272, "start": 2161.2, "end": 2170.3199999999997, "text": " the next optimum and try to stay in that optimum. So is GPT being conscious? So we see three by", "tokens": [51288, 264, 958, 39326, 293, 853, 281, 1754, 294, 300, 39326, 13, 407, 307, 26039, 51, 885, 6648, 30, 407, 321, 536, 1045, 538, 51744], "temperature": 0.0, "avg_logprob": -0.15175562833262757, "compression_ratio": 1.6942446043165467, "no_speech_prob": 0.0009394545922987163}, {"id": 351, "seek": 217032, "start": 2170.32, "end": 2175.2000000000003, "text": " itself is not an agent. And the transformer is also not a complete control model of attention,", "tokens": [50364, 2564, 307, 406, 364, 9461, 13, 400, 264, 31782, 307, 611, 406, 257, 3566, 1969, 2316, 295, 3202, 11, 50608], "temperature": 0.0, "avg_logprob": -0.07766147454579671, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.0015240713255479932}, {"id": 352, "seek": 217032, "start": 2175.2000000000003, "end": 2181.6800000000003, "text": " but only a very partial one. And on the other hand, current AI models can be extended beyond that.", "tokens": [50608, 457, 787, 257, 588, 14641, 472, 13, 400, 322, 264, 661, 1011, 11, 2190, 7318, 5245, 393, 312, 10913, 4399, 300, 13, 50932], "temperature": 0.0, "avg_logprob": -0.07766147454579671, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.0015240713255479932}, {"id": 353, "seek": 217032, "start": 2181.6800000000003, "end": 2186.7200000000003, "text": " And they can create coherent stories about conscious agents. You can get GPT-3 to run very", "tokens": [50932, 400, 436, 393, 1884, 36239, 3676, 466, 6648, 12554, 13, 509, 393, 483, 26039, 51, 12, 18, 281, 1190, 588, 51184], "temperature": 0.0, "avg_logprob": -0.07766147454579671, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.0015240713255479932}, {"id": 354, "seek": 217032, "start": 2186.7200000000003, "end": 2192.0, "text": " long in its simulation of what it's like to be a conscious agent. And we can ask ourselves,", "tokens": [51184, 938, 294, 1080, 16575, 295, 437, 309, 311, 411, 281, 312, 257, 6648, 9461, 13, 400, 321, 393, 1029, 4175, 11, 51448], "temperature": 0.0, "avg_logprob": -0.07766147454579671, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.0015240713255479932}, {"id": 355, "seek": 217032, "start": 2192.0, "end": 2199.44, "text": " is GPT-3 simulating a conscious agent or is it just a simulacrum? And what does this mean?", "tokens": [51448, 307, 26039, 51, 12, 18, 1034, 12162, 257, 6648, 9461, 420, 307, 309, 445, 257, 1034, 425, 326, 6247, 30, 400, 437, 775, 341, 914, 30, 51820], "temperature": 0.0, "avg_logprob": -0.07766147454579671, "compression_ratio": 1.7296296296296296, "no_speech_prob": 0.0015240713255479932}, {"id": 356, "seek": 219944, "start": 2199.44, "end": 2204.8, "text": " So the world is a decomposition that might mix of the universe into interacting separate", "tokens": [50364, 407, 264, 1002, 307, 257, 48356, 300, 1062, 2890, 295, 264, 6445, 666, 18017, 4994, 50632], "temperature": 0.0, "avg_logprob": -0.12851957517249563, "compression_ratio": 1.930327868852459, "no_speech_prob": 0.0004876301100011915}, {"id": 357, "seek": 219944, "start": 2204.8, "end": 2209.6, "text": " objects, because the entire state vector of the universe is too complicated to model it. So you", "tokens": [50632, 6565, 11, 570, 264, 2302, 1785, 8062, 295, 264, 6445, 307, 886, 6179, 281, 2316, 309, 13, 407, 291, 50872], "temperature": 0.0, "avg_logprob": -0.12851957517249563, "compression_ratio": 1.930327868852459, "no_speech_prob": 0.0004876301100011915}, {"id": 358, "seek": 219944, "start": 2209.6, "end": 2215.68, "text": " hack it up into separate disconnected subsystems. And the universe is not really made of separate", "tokens": [50872, 10339, 309, 493, 666, 4994, 29426, 2090, 9321, 82, 13, 400, 264, 6445, 307, 406, 534, 1027, 295, 4994, 51176], "temperature": 0.0, "avg_logprob": -0.12851957517249563, "compression_ratio": 1.930327868852459, "no_speech_prob": 0.0004876301100011915}, {"id": 359, "seek": 219944, "start": 2215.68, "end": 2220.8, "text": " disconnected subsystems. It's just a way in which we make it intelligible to us. And once you have", "tokens": [51176, 29426, 2090, 9321, 82, 13, 467, 311, 445, 257, 636, 294, 597, 321, 652, 309, 5613, 964, 281, 505, 13, 400, 1564, 291, 362, 51432], "temperature": 0.0, "avg_logprob": -0.12851957517249563, "compression_ratio": 1.930327868852459, "no_speech_prob": 0.0004876301100011915}, {"id": 360, "seek": 219944, "start": 2220.8, "end": 2225.52, "text": " these separate disconnected subsystems, and you model the interaction, you get causality.", "tokens": [51432, 613, 4994, 29426, 2090, 9321, 82, 11, 293, 291, 2316, 264, 9285, 11, 291, 483, 3302, 1860, 13, 51668], "temperature": 0.0, "avg_logprob": -0.12851957517249563, "compression_ratio": 1.930327868852459, "no_speech_prob": 0.0004876301100011915}, {"id": 361, "seek": 222552, "start": 2225.52, "end": 2232.08, "text": " Causality is the interaction between separate objects. So causality is a side effect of the", "tokens": [50364, 7544, 301, 1860, 307, 264, 9285, 1296, 4994, 6565, 13, 407, 3302, 1860, 307, 257, 1252, 1802, 295, 264, 50692], "temperature": 0.0, "avg_logprob": -0.12337319223504317, "compression_ratio": 1.780392156862745, "no_speech_prob": 0.0009846300818026066}, {"id": 362, "seek": 222552, "start": 2232.08, "end": 2238.4, "text": " way in which we model the universe as separate objects. And the simulation can model causal", "tokens": [50692, 636, 294, 597, 321, 2316, 264, 6445, 382, 4994, 6565, 13, 400, 264, 16575, 393, 2316, 38755, 51008], "temperature": 0.0, "avg_logprob": -0.12337319223504317, "compression_ratio": 1.780392156862745, "no_speech_prob": 0.0009846300818026066}, {"id": 363, "seek": 222552, "start": 2238.4, "end": 2243.44, "text": " structure on a different substrate. So for instance, a computer game is using a substrate that's", "tokens": [51008, 3877, 322, 257, 819, 27585, 13, 407, 337, 5197, 11, 257, 3820, 1216, 307, 1228, 257, 27585, 300, 311, 51260], "temperature": 0.0, "avg_logprob": -0.12337319223504317, "compression_ratio": 1.780392156862745, "no_speech_prob": 0.0009846300818026066}, {"id": 364, "seek": 222552, "start": 2243.44, "end": 2248.8, "text": " very different from physics, very simplified computation that nevertheless gives results", "tokens": [51260, 588, 819, 490, 10649, 11, 588, 26335, 24903, 300, 26924, 2709, 3542, 51528], "temperature": 0.0, "avg_logprob": -0.12337319223504317, "compression_ratio": 1.780392156862745, "no_speech_prob": 0.0009846300818026066}, {"id": 365, "seek": 222552, "start": 2248.8, "end": 2252.96, "text": " that are so similar to physics that you can recognize what's happening on the screen", "tokens": [51528, 300, 366, 370, 2531, 281, 10649, 300, 291, 393, 5521, 437, 311, 2737, 322, 264, 2568, 51736], "temperature": 0.0, "avg_logprob": -0.12337319223504317, "compression_ratio": 1.780392156862745, "no_speech_prob": 0.0009846300818026066}, {"id": 366, "seek": 225296, "start": 2253.04, "end": 2258.08, "text": " and manipulate the causal structure on the screen based on what you have observed before in the", "tokens": [50368, 293, 20459, 264, 38755, 3877, 322, 264, 2568, 2361, 322, 437, 291, 362, 13095, 949, 294, 264, 50620], "temperature": 0.0, "avg_logprob": -0.07997488557246693, "compression_ratio": 1.7840909090909092, "no_speech_prob": 0.0009690459701232612}, {"id": 367, "seek": 225296, "start": 2258.08, "end": 2264.88, "text": " real world. So a 3D computer game is a simulation of the physical world. It's a very simplified", "tokens": [50620, 957, 1002, 13, 407, 257, 805, 35, 3820, 1216, 307, 257, 16575, 295, 264, 4001, 1002, 13, 467, 311, 257, 588, 26335, 50960], "temperature": 0.0, "avg_logprob": -0.07997488557246693, "compression_ratio": 1.7840909090909092, "no_speech_prob": 0.0009690459701232612}, {"id": 368, "seek": 225296, "start": 2264.88, "end": 2270.16, "text": " simulation, but one that can be surprisingly convincing. And a simulacrum is recreating just", "tokens": [50960, 16575, 11, 457, 472, 300, 393, 312, 17600, 24823, 13, 400, 257, 1034, 425, 326, 6247, 307, 850, 44613, 445, 51224], "temperature": 0.0, "avg_logprob": -0.07997488557246693, "compression_ratio": 1.7840909090909092, "no_speech_prob": 0.0009690459701232612}, {"id": 369, "seek": 225296, "start": 2270.16, "end": 2274.48, "text": " the observables without causal structure. For instance, the movie is a simulacrum. You cannot", "tokens": [51224, 264, 9951, 2965, 1553, 38755, 3877, 13, 1171, 5197, 11, 264, 3169, 307, 257, 1034, 425, 326, 6247, 13, 509, 2644, 51440], "temperature": 0.0, "avg_logprob": -0.07997488557246693, "compression_ratio": 1.7840909090909092, "no_speech_prob": 0.0009690459701232612}, {"id": 370, "seek": 225296, "start": 2274.48, "end": 2279.76, "text": " causally interact with the movie. You can just observe it. And so a simulacrum basically can", "tokens": [51440, 3302, 379, 4648, 365, 264, 3169, 13, 509, 393, 445, 11441, 309, 13, 400, 370, 257, 1034, 425, 326, 6247, 1936, 393, 51704], "temperature": 0.0, "avg_logprob": -0.07997488557246693, "compression_ratio": 1.7840909090909092, "no_speech_prob": 0.0009690459701232612}, {"id": 371, "seek": 227976, "start": 2280.4, "end": 2285.36, "text": " do magic. It can do an arbitrary thing without you having to understand the causal structure.", "tokens": [50396, 360, 5585, 13, 467, 393, 360, 364, 23211, 551, 1553, 291, 1419, 281, 1223, 264, 38755, 3877, 13, 50644], "temperature": 0.0, "avg_logprob": -0.11363327404684272, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.0009395796223543584}, {"id": 372, "seek": 227976, "start": 2285.36, "end": 2289.6800000000003, "text": " And in the sense, a lot of instances where you experience our free will is not the causal", "tokens": [50644, 400, 294, 264, 2020, 11, 257, 688, 295, 14519, 689, 291, 1752, 527, 1737, 486, 307, 406, 264, 38755, 50860], "temperature": 0.0, "avg_logprob": -0.11363327404684272, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.0009395796223543584}, {"id": 373, "seek": 227976, "start": 2289.6800000000003, "end": 2295.5200000000004, "text": " structure, but it's a simulacrum. It's a stand-in for a causal structure in our own mind. And", "tokens": [50860, 3877, 11, 457, 309, 311, 257, 1034, 425, 326, 6247, 13, 467, 311, 257, 1463, 12, 259, 337, 257, 38755, 3877, 294, 527, 1065, 1575, 13, 400, 51152], "temperature": 0.0, "avg_logprob": -0.11363327404684272, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.0009395796223543584}, {"id": 374, "seek": 227976, "start": 2295.5200000000004, "end": 2300.48, "text": " it's to me an open question, how much of my own consciousness is a simulation and how much is", "tokens": [51152, 309, 311, 281, 385, 364, 1269, 1168, 11, 577, 709, 295, 452, 1065, 10081, 307, 257, 16575, 293, 577, 709, 307, 51400], "temperature": 0.0, "avg_logprob": -0.11363327404684272, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.0009395796223543584}, {"id": 375, "seek": 227976, "start": 2300.48, "end": 2307.36, "text": " a simulacrum? So if an imaginary person in my own mind is sometimes conscious, it's not that easy", "tokens": [51400, 257, 1034, 425, 326, 6247, 30, 407, 498, 364, 26164, 954, 294, 452, 1065, 1575, 307, 2171, 6648, 11, 309, 311, 406, 300, 1858, 51744], "temperature": 0.0, "avg_logprob": -0.11363327404684272, "compression_ratio": 1.7969348659003832, "no_speech_prob": 0.0009395796223543584}, {"id": 376, "seek": 230736, "start": 2307.36, "end": 2313.04, "text": " to say whether GPT-3 or an extended version of GPT-3 that does a multi-model, it can also have", "tokens": [50364, 281, 584, 1968, 26039, 51, 12, 18, 420, 364, 10913, 3037, 295, 26039, 51, 12, 18, 300, 775, 257, 4825, 12, 8014, 338, 11, 309, 393, 611, 362, 50648], "temperature": 0.0, "avg_logprob": -0.1252721431208592, "compression_ratio": 1.5495867768595042, "no_speech_prob": 0.0017539358232170343}, {"id": 377, "seek": 230736, "start": 2313.04, "end": 2318.56, "text": " perceptual content and so on, represented in it, qualifies as such an imaginary person that", "tokens": [50648, 43276, 901, 2701, 293, 370, 322, 11, 10379, 294, 309, 11, 4101, 11221, 382, 1270, 364, 26164, 954, 300, 50924], "temperature": 0.0, "avg_logprob": -0.1252721431208592, "compression_ratio": 1.5495867768595042, "no_speech_prob": 0.0017539358232170343}, {"id": 378, "seek": 230736, "start": 2318.56, "end": 2326.1600000000003, "text": " would be conscious. I think I am an imaginary person myself. I don't know to which degree I'm", "tokens": [50924, 576, 312, 6648, 13, 286, 519, 286, 669, 364, 26164, 954, 2059, 13, 286, 500, 380, 458, 281, 597, 4314, 286, 478, 51304], "temperature": 0.0, "avg_logprob": -0.1252721431208592, "compression_ratio": 1.5495867768595042, "no_speech_prob": 0.0017539358232170343}, {"id": 379, "seek": 230736, "start": 2326.1600000000003, "end": 2332.96, "text": " a simulation or a simulacrum. And it's not quite clear how well the AI models are dealing with", "tokens": [51304, 257, 16575, 420, 257, 1034, 425, 326, 6247, 13, 400, 309, 311, 406, 1596, 1850, 577, 731, 264, 7318, 5245, 366, 6260, 365, 51644], "temperature": 0.0, "avg_logprob": -0.1252721431208592, "compression_ratio": 1.5495867768595042, "no_speech_prob": 0.0017539358232170343}, {"id": 380, "seek": 233296, "start": 2333.28, "end": 2340.96, "text": " this. So in summary, I find it's very counterintuitive to think of GPT-3 as being conscious. For me,", "tokens": [50380, 341, 13, 407, 294, 12691, 11, 286, 915, 309, 311, 588, 5682, 686, 48314, 281, 519, 295, 26039, 51, 12, 18, 382, 885, 6648, 13, 1171, 385, 11, 50764], "temperature": 0.0, "avg_logprob": -0.09528067617705374, "compression_ratio": 1.625531914893617, "no_speech_prob": 0.0019552127923816442}, {"id": 381, "seek": 233296, "start": 2340.96, "end": 2346.7200000000003, "text": " it's surprisingly difficult to shoot down the idea that it is. And even though GPT-3 is clearly", "tokens": [50764, 309, 311, 17600, 2252, 281, 3076, 760, 264, 1558, 300, 309, 307, 13, 400, 754, 1673, 26039, 51, 12, 18, 307, 4448, 51052], "temperature": 0.0, "avg_logprob": -0.09528067617705374, "compression_ratio": 1.625531914893617, "no_speech_prob": 0.0019552127923816442}, {"id": 382, "seek": 233296, "start": 2346.7200000000003, "end": 2351.76, "text": " inferior in many ways to the way in which my own perception works and reasoning works and", "tokens": [51052, 24249, 294, 867, 2098, 281, 264, 636, 294, 597, 452, 1065, 12860, 1985, 293, 21577, 1985, 293, 51304], "temperature": 0.0, "avg_logprob": -0.09528067617705374, "compression_ratio": 1.625531914893617, "no_speech_prob": 0.0019552127923816442}, {"id": 383, "seek": 233296, "start": 2351.76, "end": 2358.64, "text": " learning works, and there's many things that it cannot do so easily, I think it's not that easy", "tokens": [51304, 2539, 1985, 11, 293, 456, 311, 867, 721, 300, 309, 2644, 360, 370, 3612, 11, 286, 519, 309, 311, 406, 300, 1858, 51648], "temperature": 0.0, "avg_logprob": -0.09528067617705374, "compression_ratio": 1.625531914893617, "no_speech_prob": 0.0019552127923816442}, {"id": 384, "seek": 235864, "start": 2358.64, "end": 2364.96, "text": " to dismiss the idea that it is slightly conscious for brief moments during the inference when it", "tokens": [50364, 281, 16974, 264, 1558, 300, 309, 307, 4748, 6648, 337, 5353, 6065, 1830, 264, 38253, 562, 309, 50680], "temperature": 0.0, "avg_logprob": -0.15525287931615656, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005284534301608801}, {"id": 385, "seek": 235864, "start": 2364.96, "end": 2370.08, "text": " has to build causal structure to simulate an imaginary person so it can tell me a story about it.", "tokens": [50680, 575, 281, 1322, 38755, 3877, 281, 27817, 364, 26164, 954, 370, 309, 393, 980, 385, 257, 1657, 466, 309, 13, 50936], "temperature": 0.0, "avg_logprob": -0.15525287931615656, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005284534301608801}, {"id": 386, "seek": 235864, "start": 2373.3599999999997, "end": 2381.3599999999997, "text": " Okay, let's stop here. That was great. That was fantastic. Let's say first of all that", "tokens": [51100, 1033, 11, 718, 311, 1590, 510, 13, 663, 390, 869, 13, 663, 390, 5456, 13, 961, 311, 584, 700, 295, 439, 300, 51500], "temperature": 0.0, "avg_logprob": -0.15525287931615656, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005284534301608801}, {"id": 387, "seek": 235864, "start": 2381.3599999999997, "end": 2385.44, "text": " there has been a debate going on on the internet about this, that people have been sending me", "tokens": [51500, 456, 575, 668, 257, 7958, 516, 322, 322, 264, 4705, 466, 341, 11, 300, 561, 362, 668, 7750, 385, 51704], "temperature": 0.0, "avg_logprob": -0.15525287931615656, "compression_ratio": 1.609442060085837, "no_speech_prob": 0.005284534301608801}, {"id": 388, "seek": 238544, "start": 2385.44, "end": 2390.32, "text": " links to, and Jan LeCun responded to Ilya's comment. I don't know if you saw that, but", "tokens": [50364, 6123, 281, 11, 293, 4956, 1456, 34, 409, 15806, 281, 286, 45106, 311, 2871, 13, 286, 500, 380, 458, 498, 291, 1866, 300, 11, 457, 50608], "temperature": 0.0, "avg_logprob": -0.19722652435302734, "compression_ratio": 1.5543859649122806, "no_speech_prob": 0.010763176716864109}, {"id": 389, "seek": 238544, "start": 2390.96, "end": 2395.28, "text": " his response is not even true for small values of slightly conscious and so on.", "tokens": [50640, 702, 4134, 307, 406, 754, 2074, 337, 1359, 4190, 295, 4748, 6648, 293, 370, 322, 13, 50856], "temperature": 0.0, "avg_logprob": -0.19722652435302734, "compression_ratio": 1.5543859649122806, "no_speech_prob": 0.010763176716864109}, {"id": 390, "seek": 238544, "start": 2395.28, "end": 2401.12, "text": " Anyway, so there's a debate out there. And of course, last week we had David Chalmers here,", "tokens": [50856, 5684, 11, 370, 456, 311, 257, 7958, 484, 456, 13, 400, 295, 1164, 11, 1036, 1243, 321, 632, 4389, 761, 304, 18552, 510, 11, 51148], "temperature": 0.0, "avg_logprob": -0.19722652435302734, "compression_ratio": 1.5543859649122806, "no_speech_prob": 0.010763176716864109}, {"id": 391, "seek": 238544, "start": 2402.32, "end": 2408.4, "text": " who, as you probably know, there was an interview on GPT-3 with him, which is very convincing.", "tokens": [51208, 567, 11, 382, 291, 1391, 458, 11, 456, 390, 364, 4049, 322, 26039, 51, 12, 18, 365, 796, 11, 597, 307, 588, 24823, 13, 51512], "temperature": 0.0, "avg_logprob": -0.19722652435302734, "compression_ratio": 1.5543859649122806, "no_speech_prob": 0.010763176716864109}, {"id": 392, "seek": 238544, "start": 2408.4, "end": 2413.12, "text": " And he kind of makes his comments similar to you, that he thinks it's kind of approaching", "tokens": [51512, 400, 415, 733, 295, 1669, 702, 3053, 2531, 281, 291, 11, 300, 415, 7309, 309, 311, 733, 295, 14908, 51748], "temperature": 0.0, "avg_logprob": -0.19722652435302734, "compression_ratio": 1.5543859649122806, "no_speech_prob": 0.010763176716864109}, {"id": 393, "seek": 241312, "start": 2413.12, "end": 2419.04, "text": " something like consciousness. Anyway, one thing I wanted to mention is that we, in architecture,", "tokens": [50364, 746, 411, 10081, 13, 5684, 11, 472, 551, 286, 1415, 281, 2152, 307, 300, 321, 11, 294, 9482, 11, 50660], "temperature": 0.0, "avg_logprob": -0.16513278033282305, "compression_ratio": 1.6630824372759856, "no_speech_prob": 0.004715221002697945}, {"id": 394, "seek": 241312, "start": 2419.04, "end": 2423.68, "text": " we haven't actually, I don't know anyone who's been using Glide, but Clip has been used to", "tokens": [50660, 321, 2378, 380, 767, 11, 286, 500, 380, 458, 2878, 567, 311, 668, 1228, 5209, 482, 11, 457, 2033, 647, 575, 668, 1143, 281, 50892], "temperature": 0.0, "avg_logprob": -0.16513278033282305, "compression_ratio": 1.6630824372759856, "no_speech_prob": 0.004715221002697945}, {"id": 395, "seek": 241312, "start": 2423.68, "end": 2429.8399999999997, "text": " generate images, very successful actually, and using VQGAN. That's the technique that's become", "tokens": [50892, 8460, 5267, 11, 588, 4406, 767, 11, 293, 1228, 691, 48, 27699, 13, 663, 311, 264, 6532, 300, 311, 1813, 51200], "temperature": 0.0, "avg_logprob": -0.16513278033282305, "compression_ratio": 1.6630824372759856, "no_speech_prob": 0.004715221002697945}, {"id": 396, "seek": 241312, "start": 2429.8399999999997, "end": 2436.48, "text": " very popular and has produced some really quite shocking results that people are kind of,", "tokens": [51200, 588, 3743, 293, 575, 7126, 512, 534, 1596, 18776, 3542, 300, 561, 366, 733, 295, 11, 51532], "temperature": 0.0, "avg_logprob": -0.16513278033282305, "compression_ratio": 1.6630824372759856, "no_speech_prob": 0.004715221002697945}, {"id": 397, "seek": 241312, "start": 2436.48, "end": 2442.48, "text": " they're really taking pay attention to. So it is something that we're kind of getting into,", "tokens": [51532, 436, 434, 534, 1940, 1689, 3202, 281, 13, 407, 309, 307, 746, 300, 321, 434, 733, 295, 1242, 666, 11, 51832], "temperature": 0.0, "avg_logprob": -0.16513278033282305, "compression_ratio": 1.6630824372759856, "no_speech_prob": 0.004715221002697945}, {"id": 398, "seek": 244248, "start": 2442.48, "end": 2447.84, "text": " and it's certainly part of that discussion. I've had discussions about GPT-3 on this forum,", "tokens": [50364, 293, 309, 311, 3297, 644, 295, 300, 5017, 13, 286, 600, 632, 11088, 466, 26039, 51, 12, 18, 322, 341, 17542, 11, 50632], "temperature": 0.0, "avg_logprob": -0.09304409642373362, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.003918147645890713}, {"id": 399, "seek": 244248, "start": 2447.84, "end": 2454.08, "text": " which have been interesting. I mean, the key question, obviously, is whether we are fully", "tokens": [50632, 597, 362, 668, 1880, 13, 286, 914, 11, 264, 2141, 1168, 11, 2745, 11, 307, 1968, 321, 366, 4498, 50944], "temperature": 0.0, "avg_logprob": -0.09304409642373362, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.003918147645890713}, {"id": 400, "seek": 244248, "start": 2454.08, "end": 2462.88, "text": " conscious of everything that we're doing. And I think that there's some level of things that", "tokens": [50944, 6648, 295, 1203, 300, 321, 434, 884, 13, 400, 286, 519, 300, 456, 311, 512, 1496, 295, 721, 300, 51384], "temperature": 0.0, "avg_logprob": -0.09304409642373362, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.003918147645890713}, {"id": 401, "seek": 244248, "start": 2462.88, "end": 2468.8, "text": " are happening. I mean, to my mind, there are some automatic reflexes that we do. For example,", "tokens": [51384, 366, 2737, 13, 286, 914, 11, 281, 452, 1575, 11, 456, 366, 512, 12509, 23802, 279, 300, 321, 360, 13, 1171, 1365, 11, 51680], "temperature": 0.0, "avg_logprob": -0.09304409642373362, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.003918147645890713}, {"id": 402, "seek": 246880, "start": 2468.88, "end": 2473.28, "text": " you go to Japan, someone starts bowing at you. Automatically, you bow back. It's not as though", "tokens": [50368, 291, 352, 281, 3367, 11, 1580, 3719, 4503, 278, 412, 291, 13, 24619, 5030, 11, 291, 4503, 646, 13, 467, 311, 406, 382, 1673, 50588], "temperature": 0.0, "avg_logprob": -0.13515226115351137, "compression_ratio": 1.6776556776556777, "no_speech_prob": 0.026903890073299408}, {"id": 403, "seek": 246880, "start": 2473.28, "end": 2477.36, "text": " you're really thinking about it. And then there are questions whether we have access to some of", "tokens": [50588, 291, 434, 534, 1953, 466, 309, 13, 400, 550, 456, 366, 1651, 1968, 321, 362, 2105, 281, 512, 295, 50792], "temperature": 0.0, "avg_logprob": -0.13515226115351137, "compression_ratio": 1.6776556776556777, "no_speech_prob": 0.026903890073299408}, {"id": 404, "seek": 246880, "start": 2477.36, "end": 2486.0, "text": " the processes that are going on, that are part of our actions. We simply maybe can't reach those", "tokens": [50792, 264, 7555, 300, 366, 516, 322, 11, 300, 366, 644, 295, 527, 5909, 13, 492, 2935, 1310, 393, 380, 2524, 729, 51224], "temperature": 0.0, "avg_logprob": -0.13515226115351137, "compression_ratio": 1.6776556776556777, "no_speech_prob": 0.026903890073299408}, {"id": 405, "seek": 246880, "start": 2486.0, "end": 2491.44, "text": " points. So whether things are beyond us in some sense. So anyway, this debate is a very timely", "tokens": [51224, 2793, 13, 407, 1968, 721, 366, 4399, 505, 294, 512, 2020, 13, 407, 4033, 11, 341, 7958, 307, 257, 588, 25150, 51496], "temperature": 0.0, "avg_logprob": -0.13515226115351137, "compression_ratio": 1.6776556776556777, "no_speech_prob": 0.026903890073299408}, {"id": 406, "seek": 246880, "start": 2491.44, "end": 2496.88, "text": " and very interesting one. I want to put up, you're about to show something?", "tokens": [51496, 293, 588, 1880, 472, 13, 286, 528, 281, 829, 493, 11, 291, 434, 466, 281, 855, 746, 30, 51768], "temperature": 0.0, "avg_logprob": -0.13515226115351137, "compression_ratio": 1.6776556776556777, "no_speech_prob": 0.026903890073299408}, {"id": 407, "seek": 249688, "start": 2497.84, "end": 2503.6800000000003, "text": " I just put up this slide again, because this is generated with, I think, clip in VQGAN on", "tokens": [50412, 286, 445, 829, 493, 341, 4137, 797, 11, 570, 341, 307, 10833, 365, 11, 286, 519, 11, 7353, 294, 691, 48, 27699, 322, 50704], "temperature": 0.0, "avg_logprob": -0.1717284548599108, "compression_ratio": 1.5615942028985508, "no_speech_prob": 0.001947766519151628}, {"id": 408, "seek": 249688, "start": 2503.6800000000003, "end": 2507.92, "text": " Vombo AI. I don't think that I've published how exactly they do it, but it looks like it.", "tokens": [50704, 691, 298, 1763, 7318, 13, 286, 500, 380, 519, 300, 286, 600, 6572, 577, 2293, 436, 360, 309, 11, 457, 309, 1542, 411, 309, 13, 50916], "temperature": 0.0, "avg_logprob": -0.1717284548599108, "compression_ratio": 1.5615942028985508, "no_speech_prob": 0.001947766519151628}, {"id": 409, "seek": 249688, "start": 2507.92, "end": 2515.36, "text": " And I generated this as AI claiming the noble eightfold path.", "tokens": [50916, 400, 286, 10833, 341, 382, 7318, 19232, 264, 20171, 3180, 18353, 3100, 13, 51288], "temperature": 0.0, "avg_logprob": -0.1717284548599108, "compression_ratio": 1.5615942028985508, "no_speech_prob": 0.001947766519151628}, {"id": 410, "seek": 249688, "start": 2517.36, "end": 2521.2000000000003, "text": " Yeah, maybe I can show you later on some of the stuff, because it is quite extraordinary what", "tokens": [51388, 865, 11, 1310, 286, 393, 855, 291, 1780, 322, 512, 295, 264, 1507, 11, 570, 309, 307, 1596, 10581, 437, 51580], "temperature": 0.0, "avg_logprob": -0.1717284548599108, "compression_ratio": 1.5615942028985508, "no_speech_prob": 0.001947766519151628}, {"id": 411, "seek": 249688, "start": 2521.2000000000003, "end": 2525.76, "text": " it can produce. And I would say that you actually have in the audience here some people who are", "tokens": [51580, 309, 393, 5258, 13, 400, 286, 576, 584, 300, 291, 767, 362, 294, 264, 4034, 510, 512, 561, 567, 366, 51808], "temperature": 0.0, "avg_logprob": -0.1717284548599108, "compression_ratio": 1.5615942028985508, "no_speech_prob": 0.001947766519151628}, {"id": 412, "seek": 252576, "start": 2526.6400000000003, "end": 2530.8, "text": " have written about AI and architecture including myself. So it's kind of you've got an interesting", "tokens": [50408, 362, 3720, 466, 7318, 293, 9482, 3009, 2059, 13, 407, 309, 311, 733, 295, 291, 600, 658, 364, 1880, 50616], "temperature": 0.0, "avg_logprob": -0.16306943552834646, "compression_ratio": 1.7790262172284643, "no_speech_prob": 0.003490459406748414}, {"id": 413, "seek": 252576, "start": 2530.8, "end": 2535.76, "text": " informed audience here. One thing, there's just a general kind of comment, though, is, I mean,", "tokens": [50616, 11740, 4034, 510, 13, 1485, 551, 11, 456, 311, 445, 257, 2674, 733, 295, 2871, 11, 1673, 11, 307, 11, 286, 914, 11, 50864], "temperature": 0.0, "avg_logprob": -0.16306943552834646, "compression_ratio": 1.7790262172284643, "no_speech_prob": 0.003490459406748414}, {"id": 414, "seek": 252576, "start": 2535.76, "end": 2541.5200000000004, "text": " I really like the idea that you put forward that somehow you can learn about the self through", "tokens": [50864, 286, 534, 411, 264, 1558, 300, 291, 829, 2128, 300, 6063, 291, 393, 1466, 466, 264, 2698, 807, 51152], "temperature": 0.0, "avg_logprob": -0.16306943552834646, "compression_ratio": 1.7790262172284643, "no_speech_prob": 0.003490459406748414}, {"id": 415, "seek": 252576, "start": 2541.5200000000004, "end": 2547.28, "text": " looking at AI. Somehow, I mean, I don't know how you put it, but whether it becomes AI becomes a", "tokens": [51152, 1237, 412, 7318, 13, 28357, 11, 286, 914, 11, 286, 500, 380, 458, 577, 291, 829, 309, 11, 457, 1968, 309, 3643, 7318, 3643, 257, 51440], "temperature": 0.0, "avg_logprob": -0.16306943552834646, "compression_ratio": 1.7790262172284643, "no_speech_prob": 0.003490459406748414}, {"id": 416, "seek": 252576, "start": 2547.28, "end": 2550.96, "text": " mirror and into the self, but whether we can understand human intelligence through looking", "tokens": [51440, 8013, 293, 666, 264, 2698, 11, 457, 1968, 321, 393, 1223, 1952, 7599, 807, 1237, 51624], "temperature": 0.0, "avg_logprob": -0.16306943552834646, "compression_ratio": 1.7790262172284643, "no_speech_prob": 0.003490459406748414}, {"id": 417, "seek": 255096, "start": 2550.96, "end": 2557.6, "text": " at artificial intelligence. And that's a provocation. And I think there are some examples", "tokens": [50364, 412, 11677, 7599, 13, 400, 300, 311, 257, 24568, 399, 13, 400, 286, 519, 456, 366, 512, 5110, 50696], "temperature": 0.0, "avg_logprob": -0.1508138202485584, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.004460413008928299}, {"id": 418, "seek": 255096, "start": 2557.6, "end": 2563.2, "text": " in computer science where we have learned about the natural world through computer models. I", "tokens": [50696, 294, 3820, 3497, 689, 321, 362, 3264, 466, 264, 3303, 1002, 807, 3820, 5245, 13, 286, 50976], "temperature": 0.0, "avg_logprob": -0.1508138202485584, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.004460413008928299}, {"id": 419, "seek": 255096, "start": 2563.2, "end": 2568.16, "text": " mean, I think that Craig Reynolds Boyds, for example, gave us a clue as how to birds actually", "tokens": [50976, 914, 11, 286, 519, 300, 19732, 29516, 9486, 16063, 11, 337, 1365, 11, 2729, 505, 257, 13602, 382, 577, 281, 9009, 767, 51224], "temperature": 0.0, "avg_logprob": -0.1508138202485584, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.004460413008928299}, {"id": 420, "seek": 255096, "start": 2568.16, "end": 2572.64, "text": " flop. I think that's interesting. And so potentially, there is something there that is,", "tokens": [51224, 25343, 13, 286, 519, 300, 311, 1880, 13, 400, 370, 7263, 11, 456, 307, 746, 456, 300, 307, 11, 51448], "temperature": 0.0, "avg_logprob": -0.1508138202485584, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.004460413008928299}, {"id": 421, "seek": 255096, "start": 2572.64, "end": 2577.44, "text": " and this is one of my primary interests, is how we can learn about human intelligence,", "tokens": [51448, 293, 341, 307, 472, 295, 452, 6194, 8847, 11, 307, 577, 321, 393, 1466, 466, 1952, 7599, 11, 51688], "temperature": 0.0, "avg_logprob": -0.1508138202485584, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.004460413008928299}, {"id": 422, "seek": 257744, "start": 2577.52, "end": 2583.2000000000003, "text": " the human mind through these things. But the big challenge that it seems that we have is that", "tokens": [50368, 264, 1952, 1575, 807, 613, 721, 13, 583, 264, 955, 3430, 300, 309, 2544, 300, 321, 362, 307, 300, 50652], "temperature": 0.0, "avg_logprob": -0.14377454231525288, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.005011610221117735}, {"id": 423, "seek": 257744, "start": 2583.2000000000003, "end": 2587.6, "text": " we're dealing essentially with two black boxes. You know, we don't know what's going on in the", "tokens": [50652, 321, 434, 6260, 4476, 365, 732, 2211, 9002, 13, 509, 458, 11, 321, 500, 380, 458, 437, 311, 516, 322, 294, 264, 50872], "temperature": 0.0, "avg_logprob": -0.14377454231525288, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.005011610221117735}, {"id": 424, "seek": 257744, "start": 2587.6, "end": 2592.16, "text": " deep levels of a neural network, and we certainly don't know what's going on in the mind. And so", "tokens": [50872, 2452, 4358, 295, 257, 18161, 3209, 11, 293, 321, 3297, 500, 380, 458, 437, 311, 516, 322, 294, 264, 1575, 13, 400, 370, 51100], "temperature": 0.0, "avg_logprob": -0.14377454231525288, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.005011610221117735}, {"id": 425, "seek": 257744, "start": 2593.76, "end": 2600.88, "text": " how can you make, what can you say that isn't simply a form of speculation? I mean,", "tokens": [51180, 577, 393, 291, 652, 11, 437, 393, 291, 584, 300, 1943, 380, 2935, 257, 1254, 295, 27696, 30, 286, 914, 11, 51536], "temperature": 0.0, "avg_logprob": -0.14377454231525288, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.005011610221117735}, {"id": 426, "seek": 257744, "start": 2600.88, "end": 2606.2400000000002, "text": " you can't prove anything. It can simply become some kind of, you can speculate about something", "tokens": [51536, 291, 393, 380, 7081, 1340, 13, 467, 393, 2935, 1813, 512, 733, 295, 11, 291, 393, 40775, 466, 746, 51804], "temperature": 0.0, "avg_logprob": -0.14377454231525288, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.005011610221117735}, {"id": 427, "seek": 260624, "start": 2606.24, "end": 2611.7599999999998, "text": " based on what appears to be the case in another scenario. What would you say about that coming", "tokens": [50364, 2361, 322, 437, 7038, 281, 312, 264, 1389, 294, 1071, 9005, 13, 708, 576, 291, 584, 466, 300, 1348, 50640], "temperature": 0.0, "avg_logprob": -0.11077579605245144, "compression_ratio": 1.712686567164179, "no_speech_prob": 0.0005511987255886197}, {"id": 428, "seek": 260624, "start": 2611.7599999999998, "end": 2616.0, "text": " from a kind of, let's say, a scientific background where you have a kind of burden of proof?", "tokens": [50640, 490, 257, 733, 295, 11, 718, 311, 584, 11, 257, 8134, 3678, 689, 291, 362, 257, 733, 295, 12578, 295, 8177, 30, 50852], "temperature": 0.0, "avg_logprob": -0.11077579605245144, "compression_ratio": 1.712686567164179, "no_speech_prob": 0.0005511987255886197}, {"id": 429, "seek": 260624, "start": 2617.04, "end": 2622.9599999999996, "text": " Can you do more than that? Yes, first of all, neural networks are no longer black boxes. You", "tokens": [50904, 1664, 291, 360, 544, 813, 300, 30, 1079, 11, 700, 295, 439, 11, 18161, 9590, 366, 572, 2854, 2211, 9002, 13, 509, 51200], "temperature": 0.0, "avg_logprob": -0.11077579605245144, "compression_ratio": 1.712686567164179, "no_speech_prob": 0.0005511987255886197}, {"id": 430, "seek": 260624, "start": 2622.9599999999996, "end": 2630.7999999999997, "text": " know how neural networks work and largely also why. You can basically look into the neural networks", "tokens": [51200, 458, 577, 18161, 9590, 589, 293, 11611, 611, 983, 13, 509, 393, 1936, 574, 666, 264, 18161, 9590, 51592], "temperature": 0.0, "avg_logprob": -0.11077579605245144, "compression_ratio": 1.712686567164179, "no_speech_prob": 0.0005511987255886197}, {"id": 431, "seek": 260624, "start": 2630.7999999999997, "end": 2634.3999999999996, "text": " and find out which parts of the neural networks are computing which functions.", "tokens": [51592, 293, 915, 484, 597, 3166, 295, 264, 18161, 9590, 366, 15866, 597, 6828, 13, 51772], "temperature": 0.0, "avg_logprob": -0.11077579605245144, "compression_ratio": 1.712686567164179, "no_speech_prob": 0.0005511987255886197}, {"id": 432, "seek": 263440, "start": 2635.12, "end": 2642.7200000000003, "text": " And a function is a mapping from inputs to outputs. And a function can be used to couple", "tokens": [50400, 400, 257, 2445, 307, 257, 18350, 490, 15743, 281, 23930, 13, 400, 257, 2445, 393, 312, 1143, 281, 1916, 50780], "temperature": 0.0, "avg_logprob": -0.08198967400719137, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.00047271139919757843}, {"id": 433, "seek": 263440, "start": 2642.7200000000003, "end": 2650.88, "text": " the previous inputs to future inputs to track reality. So in some sense, when you look at", "tokens": [50780, 264, 3894, 15743, 281, 2027, 15743, 281, 2837, 4103, 13, 407, 294, 512, 2020, 11, 562, 291, 574, 412, 51188], "temperature": 0.0, "avg_logprob": -0.08198967400719137, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.00047271139919757843}, {"id": 434, "seek": 263440, "start": 2650.88, "end": 2656.4, "text": " the patterns on your own retina, what you have there are little blips that appear on the retina", "tokens": [51188, 264, 8294, 322, 428, 1065, 1533, 1426, 11, 437, 291, 362, 456, 366, 707, 888, 2600, 300, 4204, 322, 264, 1533, 1426, 51464], "temperature": 0.0, "avg_logprob": -0.08198967400719137, "compression_ratio": 1.611764705882353, "no_speech_prob": 0.00047271139919757843}, {"id": 435, "seek": 265640, "start": 2656.4, "end": 2664.2400000000002, "text": " whenever a retinal neural gets excited by photon sitting it. And what your brain is doing,", "tokens": [50364, 5699, 257, 1533, 2071, 18161, 2170, 2919, 538, 37443, 3798, 309, 13, 400, 437, 428, 3567, 307, 884, 11, 50756], "temperature": 0.0, "avg_logprob": -0.1062190064760012, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.002844098722562194}, {"id": 436, "seek": 265640, "start": 2664.2400000000002, "end": 2669.04, "text": " it's discovering a relationship between these blips. The meaning of the blips is exactly", "tokens": [50756, 309, 311, 24773, 257, 2480, 1296, 613, 888, 2600, 13, 440, 3620, 295, 264, 888, 2600, 307, 2293, 50996], "temperature": 0.0, "avg_logprob": -0.1062190064760012, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.002844098722562194}, {"id": 437, "seek": 265640, "start": 2669.04, "end": 2675.28, "text": " the relationships that your brain discovers between the blips. And this makes them predictable.", "tokens": [50996, 264, 6159, 300, 428, 3567, 44522, 1296, 264, 888, 2600, 13, 400, 341, 1669, 552, 27737, 13, 51308], "temperature": 0.0, "avg_logprob": -0.1062190064760012, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.002844098722562194}, {"id": 438, "seek": 265640, "start": 2675.28, "end": 2680.0, "text": " It puts them into a shared context, not just at the same time, you're not just processing", "tokens": [51308, 467, 8137, 552, 666, 257, 5507, 4319, 11, 406, 445, 412, 264, 912, 565, 11, 291, 434, 406, 445, 9007, 51544], "temperature": 0.0, "avg_logprob": -0.1062190064760012, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.002844098722562194}, {"id": 439, "seek": 265640, "start": 2680.0, "end": 2684.96, "text": " lots of parallel blips that happen on your retina, but also across times. So across different scenes", "tokens": [51544, 3195, 295, 8952, 888, 2600, 300, 1051, 322, 428, 1533, 1426, 11, 457, 611, 2108, 1413, 13, 407, 2108, 819, 8026, 51792], "temperature": 0.0, "avg_logprob": -0.1062190064760012, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.002844098722562194}, {"id": 440, "seek": 268496, "start": 2684.96, "end": 2689.6, "text": " that you're observing at different moments in your life. And the relationships between", "tokens": [50364, 300, 291, 434, 22107, 412, 819, 6065, 294, 428, 993, 13, 400, 264, 6159, 1296, 50596], "temperature": 0.0, "avg_logprob": -0.07149263891843285, "compression_ratio": 1.9700854700854702, "no_speech_prob": 0.0004304353496991098}, {"id": 441, "seek": 268496, "start": 2689.6, "end": 2694.0, "text": " the different blips on your retina that your brain discovers is that you are looking at", "tokens": [50596, 264, 819, 888, 2600, 322, 428, 1533, 1426, 300, 428, 3567, 44522, 307, 300, 291, 366, 1237, 412, 50816], "temperature": 0.0, "avg_logprob": -0.07149263891843285, "compression_ratio": 1.9700854700854702, "no_speech_prob": 0.0004304353496991098}, {"id": 442, "seek": 268496, "start": 2694.0, "end": 2701.36, "text": " moving blocks of color in a world that is moving relative to you. And these moving blocks of color", "tokens": [50816, 2684, 8474, 295, 2017, 294, 257, 1002, 300, 307, 2684, 4972, 281, 291, 13, 400, 613, 2684, 8474, 295, 2017, 51184], "temperature": 0.0, "avg_logprob": -0.07149263891843285, "compression_ratio": 1.9700854700854702, "no_speech_prob": 0.0004304353496991098}, {"id": 443, "seek": 268496, "start": 2701.36, "end": 2709.12, "text": " are three-dimensional surfaces. And the surfaces are animated by some kind of physics. And they", "tokens": [51184, 366, 1045, 12, 18759, 16130, 13, 400, 264, 16130, 366, 18947, 538, 512, 733, 295, 10649, 13, 400, 436, 51572], "temperature": 0.0, "avg_logprob": -0.07149263891843285, "compression_ratio": 1.9700854700854702, "no_speech_prob": 0.0004304353496991098}, {"id": 444, "seek": 268496, "start": 2709.12, "end": 2713.52, "text": " are also animated by some kind of agency that you sometimes observe, like people talking to", "tokens": [51572, 366, 611, 18947, 538, 512, 733, 295, 7934, 300, 291, 2171, 11441, 11, 411, 561, 1417, 281, 51792], "temperature": 0.0, "avg_logprob": -0.07149263891843285, "compression_ratio": 1.9700854700854702, "no_speech_prob": 0.0004304353496991098}, {"id": 445, "seek": 271352, "start": 2713.52, "end": 2718.56, "text": " each other and so on that have mental states, they exchange ideas, and they're being lit on", "tokens": [50364, 1184, 661, 293, 370, 322, 300, 362, 4973, 4368, 11, 436, 7742, 3487, 11, 293, 436, 434, 885, 7997, 322, 50616], "temperature": 0.0, "avg_logprob": -0.10523867843174699, "compression_ratio": 1.772549019607843, "no_speech_prob": 0.00039806016138754785}, {"id": 446, "seek": 271352, "start": 2719.28, "end": 2725.92, "text": " by the sun. And all these relationships are functions. These functions are dynamical features", "tokens": [50652, 538, 264, 3295, 13, 400, 439, 613, 6159, 366, 6828, 13, 1981, 6828, 366, 5999, 804, 4122, 50984], "temperature": 0.0, "avg_logprob": -0.10523867843174699, "compression_ratio": 1.772549019607843, "no_speech_prob": 0.00039806016138754785}, {"id": 447, "seek": 271352, "start": 2725.92, "end": 2730.96, "text": " that basically tell you how to get from one state of the world to other states of the world.", "tokens": [50984, 300, 1936, 980, 291, 577, 281, 483, 490, 472, 1785, 295, 264, 1002, 281, 661, 4368, 295, 264, 1002, 13, 51236], "temperature": 0.0, "avg_logprob": -0.10523867843174699, "compression_ratio": 1.772549019607843, "no_speech_prob": 0.00039806016138754785}, {"id": 448, "seek": 271352, "start": 2731.6, "end": 2736.48, "text": " And at this level of abstraction, this is something that our neural networks also can do.", "tokens": [51268, 400, 412, 341, 1496, 295, 37765, 11, 341, 307, 746, 300, 527, 18161, 9590, 611, 393, 360, 13, 51512], "temperature": 0.0, "avg_logprob": -0.10523867843174699, "compression_ratio": 1.772549019607843, "no_speech_prob": 0.00039806016138754785}, {"id": 449, "seek": 271352, "start": 2737.36, "end": 2742.0, "text": " Where there are limitations is that the neural networks that we are currently using", "tokens": [51556, 2305, 456, 366, 15705, 307, 300, 264, 18161, 9590, 300, 321, 366, 4362, 1228, 51788], "temperature": 0.0, "avg_logprob": -0.10523867843174699, "compression_ratio": 1.772549019607843, "no_speech_prob": 0.00039806016138754785}, {"id": 450, "seek": 274200, "start": 2742.0, "end": 2747.52, "text": " are often not learning in real time. They're not connected to the world and online learning.", "tokens": [50364, 366, 2049, 406, 2539, 294, 957, 565, 13, 814, 434, 406, 4582, 281, 264, 1002, 293, 2950, 2539, 13, 50640], "temperature": 0.0, "avg_logprob": -0.14777927223695528, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.0004372124094516039}, {"id": 451, "seek": 274200, "start": 2747.52, "end": 2753.28, "text": " You know, this research does happen. And it's slower. And it's not as flexible in many ways as", "tokens": [50640, 509, 458, 11, 341, 2132, 775, 1051, 13, 400, 309, 311, 14009, 13, 400, 309, 311, 406, 382, 11358, 294, 867, 2098, 382, 50928], "temperature": 0.0, "avg_logprob": -0.14777927223695528, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.0004372124094516039}, {"id": 452, "seek": 274200, "start": 2753.28, "end": 2759.04, "text": " the learning happens in our own brain. And so the algorithms that we have discovered", "tokens": [50928, 264, 2539, 2314, 294, 527, 1065, 3567, 13, 400, 370, 264, 14642, 300, 321, 362, 6941, 51216], "temperature": 0.0, "avg_logprob": -0.14777927223695528, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.0004372124094516039}, {"id": 453, "seek": 274200, "start": 2759.68, "end": 2765.28, "text": " are not the best algorithms that could facilitate this. But it's also, on the other hand,", "tokens": [51248, 366, 406, 264, 1151, 14642, 300, 727, 20207, 341, 13, 583, 309, 311, 611, 11, 322, 264, 661, 1011, 11, 51528], "temperature": 0.0, "avg_logprob": -0.14777927223695528, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.0004372124094516039}, {"id": 454, "seek": 274200, "start": 2765.28, "end": 2771.36, "text": " not as clear to me what the limitations of these algorithms are. There are people like Gary Marcus", "tokens": [51528, 406, 382, 1850, 281, 385, 437, 264, 15705, 295, 613, 14642, 366, 13, 821, 366, 561, 411, 13788, 26574, 51832], "temperature": 0.0, "avg_logprob": -0.14777927223695528, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.0004372124094516039}, {"id": 455, "seek": 277136, "start": 2771.36, "end": 2778.6400000000003, "text": " who will tell you that it's very obvious that these systems cannot do X, but there is no proof", "tokens": [50364, 567, 486, 980, 291, 300, 309, 311, 588, 6322, 300, 613, 3652, 2644, 360, 1783, 11, 457, 456, 307, 572, 8177, 50728], "temperature": 0.0, "avg_logprob": -0.12922273240647875, "compression_ratio": 1.817490494296578, "no_speech_prob": 0.0003858814015984535}, {"id": 456, "seek": 277136, "start": 2778.6400000000003, "end": 2784.4, "text": " that they cannot do this. Even if you have a very simple feedforward system that is only mapping", "tokens": [50728, 300, 436, 2644, 360, 341, 13, 2754, 498, 291, 362, 257, 588, 2199, 3154, 13305, 1185, 300, 307, 787, 18350, 51016], "temperature": 0.0, "avg_logprob": -0.12922273240647875, "compression_ratio": 1.817490494296578, "no_speech_prob": 0.0003858814015984535}, {"id": 457, "seek": 277136, "start": 2784.4, "end": 2790.6400000000003, "text": " inputs to outputs, what is to say if you connect this to a memory, is that it's not the transition", "tokens": [51016, 15743, 281, 23930, 11, 437, 307, 281, 584, 498, 291, 1745, 341, 281, 257, 4675, 11, 307, 300, 309, 311, 406, 264, 6034, 51328], "temperature": 0.0, "avg_logprob": -0.12922273240647875, "compression_ratio": 1.817490494296578, "no_speech_prob": 0.0003858814015984535}, {"id": 458, "seek": 277136, "start": 2790.6400000000003, "end": 2795.1200000000003, "text": " function between adjacent brain states and is able to do everything that your brain is able to do", "tokens": [51328, 2445, 1296, 24441, 3567, 4368, 293, 307, 1075, 281, 360, 1203, 300, 428, 3567, 307, 1075, 281, 360, 51552], "temperature": 0.0, "avg_logprob": -0.12922273240647875, "compression_ratio": 1.817490494296578, "no_speech_prob": 0.0003858814015984535}, {"id": 459, "seek": 277136, "start": 2795.1200000000003, "end": 2799.6800000000003, "text": " if it just has memory to store parameters that it refers to the environment that modifies", "tokens": [51552, 498, 309, 445, 575, 4675, 281, 3531, 9834, 300, 309, 14942, 281, 264, 2823, 300, 1072, 11221, 51780], "temperature": 0.0, "avg_logprob": -0.12922273240647875, "compression_ratio": 1.817490494296578, "no_speech_prob": 0.0003858814015984535}, {"id": 460, "seek": 279968, "start": 2799.68, "end": 2806.0, "text": " you to behavior. So it's very easy to build a system that is Turing complete. It's not easy to", "tokens": [50364, 291, 281, 5223, 13, 407, 309, 311, 588, 1858, 281, 1322, 257, 1185, 300, 307, 314, 1345, 3566, 13, 467, 311, 406, 1858, 281, 50680], "temperature": 0.0, "avg_logprob": -0.12565658773694718, "compression_ratio": 1.7375886524822695, "no_speech_prob": 0.00034564058296382427}, {"id": 461, "seek": 279968, "start": 2806.0, "end": 2812.48, "text": " discover a function that is capable of universal learning efficiently. And so our machine learning", "tokens": [50680, 4411, 257, 2445, 300, 307, 8189, 295, 11455, 2539, 19621, 13, 400, 370, 527, 3479, 2539, 51004], "temperature": 0.0, "avg_logprob": -0.12565658773694718, "compression_ratio": 1.7375886524822695, "no_speech_prob": 0.00034564058296382427}, {"id": 462, "seek": 279968, "start": 2812.48, "end": 2817.6, "text": " models at the moment are not efficient in the sense that they learn as quickly as the logical", "tokens": [51004, 5245, 412, 264, 1623, 366, 406, 7148, 294, 264, 2020, 300, 436, 1466, 382, 2661, 382, 264, 14978, 51260], "temperature": 0.0, "avg_logprob": -0.12565658773694718, "compression_ratio": 1.7375886524822695, "no_speech_prob": 0.00034564058296382427}, {"id": 463, "seek": 279968, "start": 2817.6, "end": 2822.64, "text": " nervous systems learn, but they do learn and they do converge to many of the functions that we require.", "tokens": [51260, 6296, 3652, 1466, 11, 457, 436, 360, 1466, 293, 436, 360, 41881, 281, 867, 295, 264, 6828, 300, 321, 3651, 13, 51512], "temperature": 0.0, "avg_logprob": -0.12565658773694718, "compression_ratio": 1.7375886524822695, "no_speech_prob": 0.00034564058296382427}, {"id": 464, "seek": 279968, "start": 2824.3199999999997, "end": 2828.64, "text": " Can I just share my screen a second because there was one that you touched on, which I thought was", "tokens": [51596, 1664, 286, 445, 2073, 452, 2568, 257, 1150, 570, 456, 390, 472, 300, 291, 9828, 322, 11, 597, 286, 1194, 390, 51812], "temperature": 0.0, "avg_logprob": -0.12565658773694718, "compression_ratio": 1.7375886524822695, "no_speech_prob": 0.00034564058296382427}, {"id": 465, "seek": 282864, "start": 2829.6, "end": 2840.8799999999997, "text": " that this is simply a transcript of your discussion with Lex. And this one I've highlighted,", "tokens": [50412, 300, 341, 307, 2935, 257, 24444, 295, 428, 5017, 365, 24086, 13, 400, 341, 472, 286, 600, 17173, 11, 50976], "temperature": 0.0, "avg_logprob": -0.1544700316440912, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.001576770911924541}, {"id": 466, "seek": 282864, "start": 2840.8799999999997, "end": 2847.3599999999997, "text": " I think it's really interesting and incredibly provocative sort of comment. So basically a", "tokens": [50976, 286, 519, 309, 311, 534, 1880, 293, 6252, 47663, 1333, 295, 2871, 13, 407, 1936, 257, 51300], "temperature": 0.0, "avg_logprob": -0.1544700316440912, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.001576770911924541}, {"id": 467, "seek": 282864, "start": 2847.3599999999997, "end": 2852.96, "text": " brain cannot feel anything, a neuron cannot feel anything, their physical things, physical systems", "tokens": [51300, 3567, 2644, 841, 1340, 11, 257, 34090, 2644, 841, 1340, 11, 641, 4001, 721, 11, 4001, 3652, 51580], "temperature": 0.0, "avg_logprob": -0.1544700316440912, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.001576770911924541}, {"id": 468, "seek": 282864, "start": 2852.96, "end": 2858.4, "text": " are unable to experience anything, but it would be very useful for the brain or for the organism", "tokens": [51580, 366, 11299, 281, 1752, 1340, 11, 457, 309, 576, 312, 588, 4420, 337, 264, 3567, 420, 337, 264, 24128, 51852], "temperature": 0.0, "avg_logprob": -0.1544700316440912, "compression_ratio": 1.6406926406926408, "no_speech_prob": 0.001576770911924541}, {"id": 469, "seek": 285840, "start": 2858.4, "end": 2863.2000000000003, "text": " to know what it would be like to be a person and to feel something. So the brain creates a", "tokens": [50364, 281, 458, 437, 309, 576, 312, 411, 281, 312, 257, 954, 293, 281, 841, 746, 13, 407, 264, 3567, 7829, 257, 50604], "temperature": 0.0, "avg_logprob": -0.09884911775588989, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0012404636945575476}, {"id": 470, "seek": 285840, "start": 2863.2000000000003, "end": 2868.4, "text": " simulacrum of such a person that it uses to model the interactions of the person. It's the best", "tokens": [50604, 1034, 425, 326, 6247, 295, 1270, 257, 954, 300, 309, 4960, 281, 2316, 264, 13280, 295, 264, 954, 13, 467, 311, 264, 1151, 50864], "temperature": 0.0, "avg_logprob": -0.09884911775588989, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0012404636945575476}, {"id": 471, "seek": 285840, "start": 2868.4, "end": 2873.76, "text": " model of what that brain, this organism thinks it is in relationship to its environment. So it", "tokens": [50864, 2316, 295, 437, 300, 3567, 11, 341, 24128, 7309, 309, 307, 294, 2480, 281, 1080, 2823, 13, 407, 309, 51132], "temperature": 0.0, "avg_logprob": -0.09884911775588989, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0012404636945575476}, {"id": 472, "seek": 285840, "start": 2873.76, "end": 2880.0, "text": " creates that model. It's a story, a multimedia novel that the brain is continuously writing and", "tokens": [51132, 7829, 300, 2316, 13, 467, 311, 257, 1657, 11, 257, 49202, 7613, 300, 264, 3567, 307, 15684, 3579, 293, 51444], "temperature": 0.0, "avg_logprob": -0.09884911775588989, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0012404636945575476}, {"id": 473, "seek": 285840, "start": 2880.0, "end": 2888.1600000000003, "text": " updating. I mean, I find this enormously provocative as a comment. And I think the", "tokens": [51444, 25113, 13, 286, 914, 11, 286, 915, 341, 39669, 47663, 382, 257, 2871, 13, 400, 286, 519, 264, 51852], "temperature": 0.0, "avg_logprob": -0.09884911775588989, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0012404636945575476}, {"id": 474, "seek": 288816, "start": 2888.24, "end": 2893.68, "text": " idea that we're kind of creating a story that somehow gives meaning to something,", "tokens": [50368, 1558, 300, 321, 434, 733, 295, 4084, 257, 1657, 300, 6063, 2709, 3620, 281, 746, 11, 50640], "temperature": 0.0, "avg_logprob": -0.14692341515777307, "compression_ratio": 1.769811320754717, "no_speech_prob": 0.00026696640998125076}, {"id": 475, "seek": 288816, "start": 2895.2, "end": 2901.3599999999997, "text": " it kind of reminds me in some sense of the way that Homi Barba talks about how a nation operates.", "tokens": [50716, 309, 733, 295, 12025, 385, 294, 512, 2020, 295, 264, 636, 300, 389, 9220, 4156, 4231, 6686, 466, 577, 257, 4790, 22577, 13, 51024], "temperature": 0.0, "avg_logprob": -0.14692341515777307, "compression_ratio": 1.769811320754717, "no_speech_prob": 0.00026696640998125076}, {"id": 476, "seek": 288816, "start": 2901.3599999999997, "end": 2905.8399999999997, "text": " I think Zizek says something similar. It's how things are inscribed within a story that people", "tokens": [51024, 286, 519, 1176, 590, 916, 1619, 746, 2531, 13, 467, 311, 577, 721, 366, 1028, 18732, 1951, 257, 1657, 300, 561, 51248], "temperature": 0.0, "avg_logprob": -0.14692341515777307, "compression_ratio": 1.769811320754717, "no_speech_prob": 0.00026696640998125076}, {"id": 477, "seek": 288816, "start": 2905.8399999999997, "end": 2910.48, "text": " tell oneself. And I think that's important because in architecture we just focus on the object,", "tokens": [51248, 980, 32265, 13, 400, 286, 519, 300, 311, 1021, 570, 294, 9482, 321, 445, 1879, 322, 264, 2657, 11, 51480], "temperature": 0.0, "avg_logprob": -0.14692341515777307, "compression_ratio": 1.769811320754717, "no_speech_prob": 0.00026696640998125076}, {"id": 478, "seek": 288816, "start": 2910.48, "end": 2915.6, "text": " but actually it's the way that object is inscribed within some subjective process that makes sense", "tokens": [51480, 457, 767, 309, 311, 264, 636, 300, 2657, 307, 1028, 18732, 1951, 512, 25972, 1399, 300, 1669, 2020, 51736], "temperature": 0.0, "avg_logprob": -0.14692341515777307, "compression_ratio": 1.769811320754717, "no_speech_prob": 0.00026696640998125076}, {"id": 479, "seek": 291560, "start": 2915.68, "end": 2922.24, "text": " of things. But I just wonder whether, I mean, so to my mind, this is an incredibly provocative", "tokens": [50368, 295, 721, 13, 583, 286, 445, 2441, 1968, 11, 286, 914, 11, 370, 281, 452, 1575, 11, 341, 307, 364, 6252, 47663, 50696], "temperature": 0.0, "avg_logprob": -0.14244707338102572, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.0028310713823884726}, {"id": 480, "seek": 291560, "start": 2922.24, "end": 2928.96, "text": " and controversial comment, it seems. Just maybe could you comment on the reception that this view", "tokens": [50696, 293, 17323, 2871, 11, 309, 2544, 13, 1449, 1310, 727, 291, 2871, 322, 264, 21682, 300, 341, 1910, 51032], "temperature": 0.0, "avg_logprob": -0.14244707338102572, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.0028310713823884726}, {"id": 481, "seek": 291560, "start": 2928.96, "end": 2936.72, "text": " has had with other people? Has it proved to be controversial? How else could it be? Do you have", "tokens": [51032, 575, 632, 365, 661, 561, 30, 8646, 309, 14617, 281, 312, 17323, 30, 1012, 1646, 727, 309, 312, 30, 1144, 291, 362, 51420], "temperature": 0.0, "avg_logprob": -0.14244707338102572, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.0028310713823884726}, {"id": 482, "seek": 291560, "start": 2936.72, "end": 2944.7999999999997, "text": " other theory that works that can explain what's going on? I think once I noticed that my", "tokens": [51420, 661, 5261, 300, 1985, 300, 393, 2903, 437, 311, 516, 322, 30, 286, 519, 1564, 286, 5694, 300, 452, 51824], "temperature": 0.0, "avg_logprob": -0.14244707338102572, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.0028310713823884726}, {"id": 483, "seek": 294480, "start": 2945.44, "end": 2952.4, "text": " own experience is virtual, that my memories are often created after the fact and modified under", "tokens": [50396, 1065, 1752, 307, 6374, 11, 300, 452, 8495, 366, 2049, 2942, 934, 264, 1186, 293, 15873, 833, 50744], "temperature": 0.0, "avg_logprob": -0.1365005293888832, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.0010151388123631477}, {"id": 484, "seek": 294480, "start": 2952.4, "end": 2961.04, "text": " my nose without me noticing. Do you notice that you exist inside of a model? It's also that I'm not", "tokens": [50744, 452, 6690, 1553, 385, 21814, 13, 1144, 291, 3449, 300, 291, 2514, 1854, 295, 257, 2316, 30, 467, 311, 611, 300, 286, 478, 406, 51176], "temperature": 0.0, "avg_logprob": -0.1365005293888832, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.0010151388123631477}, {"id": 485, "seek": 294480, "start": 2961.04, "end": 2967.04, "text": " in physical time. My own self is sometimes a little bit ahead of the physical universe,", "tokens": [51176, 294, 4001, 565, 13, 1222, 1065, 2698, 307, 2171, 257, 707, 857, 2286, 295, 264, 4001, 6445, 11, 51476], "temperature": 0.0, "avg_logprob": -0.1365005293888832, "compression_ratio": 1.5133689839572193, "no_speech_prob": 0.0010151388123631477}, {"id": 486, "seek": 296704, "start": 2967.04, "end": 2976.08, "text": " sometimes a little bit behind. So the physical now and the experience now are different. And the", "tokens": [50364, 2171, 257, 707, 857, 2261, 13, 407, 264, 4001, 586, 293, 264, 1752, 586, 366, 819, 13, 400, 264, 50816], "temperature": 0.0, "avg_logprob": -0.14415211513124662, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.023282846435904503}, {"id": 487, "seek": 296704, "start": 2976.08, "end": 2981.04, "text": " elements of my perception are clearly not the elements in which physics is being implemented.", "tokens": [50816, 4959, 295, 452, 12860, 366, 4448, 406, 264, 4959, 294, 597, 10649, 307, 885, 12270, 13, 51064], "temperature": 0.0, "avg_logprob": -0.14415211513124662, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.023282846435904503}, {"id": 488, "seek": 296704, "start": 2981.04, "end": 2986.96, "text": " Rather, it's the other way around. What I notice is that I do exist in a dream, very much like", "tokens": [51064, 16571, 11, 309, 311, 264, 661, 636, 926, 13, 708, 286, 3449, 307, 300, 286, 360, 2514, 294, 257, 3055, 11, 588, 709, 411, 51360], "temperature": 0.0, "avg_logprob": -0.14415211513124662, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.023282846435904503}, {"id": 489, "seek": 296704, "start": 2986.96, "end": 2992.8, "text": " we usually say in idealist philosophy. But this dream needs to be created somehow. Something", "tokens": [51360, 321, 2673, 584, 294, 7157, 468, 10675, 13, 583, 341, 3055, 2203, 281, 312, 2942, 6063, 13, 6595, 51652], "temperature": 0.0, "avg_logprob": -0.14415211513124662, "compression_ratio": 1.6085106382978724, "no_speech_prob": 0.023282846435904503}, {"id": 490, "seek": 299280, "start": 2992.8, "end": 2997.6000000000004, "text": " needs to construct the dream. And that's a brain and higher plane of existence. And this", "tokens": [50364, 2203, 281, 7690, 264, 3055, 13, 400, 300, 311, 257, 3567, 293, 2946, 5720, 295, 9123, 13, 400, 341, 50604], "temperature": 0.0, "avg_logprob": -0.1483297136094835, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.0011809838470071554}, {"id": 491, "seek": 299280, "start": 2997.6000000000004, "end": 3006.0800000000004, "text": " higher plane of existence is what we call physics. Maybe I'll stop sharing. The other comment that", "tokens": [50604, 2946, 5720, 295, 9123, 307, 437, 321, 818, 10649, 13, 2704, 286, 603, 1590, 5414, 13, 440, 661, 2871, 300, 51028], "temperature": 0.0, "avg_logprob": -0.1483297136094835, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.0011809838470071554}, {"id": 492, "seek": 299280, "start": 3006.0800000000004, "end": 3010.5600000000004, "text": " I find usually provocative that you make is which kind of relates also to the discussion. I don't", "tokens": [51028, 286, 915, 2673, 47663, 300, 291, 652, 307, 597, 733, 295, 16155, 611, 281, 264, 5017, 13, 286, 500, 380, 51252], "temperature": 0.0, "avg_logprob": -0.1483297136094835, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.0011809838470071554}, {"id": 493, "seek": 299280, "start": 3010.5600000000004, "end": 3017.44, "text": " know if you've seen David Chalmers' recently published book on reality plus, where he talks about", "tokens": [51252, 458, 498, 291, 600, 1612, 4389, 761, 304, 18552, 6, 3938, 6572, 1446, 322, 4103, 1804, 11, 689, 415, 6686, 466, 51596], "temperature": 0.0, "avg_logprob": -0.1483297136094835, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.0011809838470071554}, {"id": 494, "seek": 301744, "start": 3017.44, "end": 3023.44, "text": " virtual worlds. But you came up with a comment that what we are seeing is a virtual reality", "tokens": [50364, 6374, 13401, 13, 583, 291, 1361, 493, 365, 257, 2871, 300, 437, 321, 366, 2577, 307, 257, 6374, 4103, 50664], "temperature": 0.0, "avg_logprob": -0.11160281430120053, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.05547661334276199}, {"id": 495, "seek": 301744, "start": 3023.44, "end": 3029.76, "text": " generated in the brain, which I'm actually very persuaded by myself. And I guess I'm thinking", "tokens": [50664, 10833, 294, 264, 3567, 11, 597, 286, 478, 767, 588, 47693, 538, 2059, 13, 400, 286, 2041, 286, 478, 1953, 50980], "temperature": 0.0, "avg_logprob": -0.11160281430120053, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.05547661334276199}, {"id": 496, "seek": 301744, "start": 3029.76, "end": 3037.28, "text": " also of the kind of thinking of Anil Seth, who kind of talks about this controlled hallucination.", "tokens": [50980, 611, 295, 264, 733, 295, 1953, 295, 1107, 388, 25353, 11, 567, 733, 295, 6686, 466, 341, 10164, 35212, 2486, 13, 51356], "temperature": 0.0, "avg_logprob": -0.11160281430120053, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.05547661334276199}, {"id": 497, "seek": 301744, "start": 3038.0, "end": 3043.04, "text": " And we kind of predict what's out there because we don't know. It seems that your work to some", "tokens": [51392, 400, 321, 733, 295, 6069, 437, 311, 484, 456, 570, 321, 500, 380, 458, 13, 467, 2544, 300, 428, 589, 281, 512, 51644], "temperature": 0.0, "avg_logprob": -0.11160281430120053, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.05547661334276199}, {"id": 498, "seek": 304304, "start": 3043.04, "end": 3048.72, "text": " extent aligns with the work of Anil Seth, but at some points differently. I have to say that Anil", "tokens": [50364, 8396, 7975, 82, 365, 264, 589, 295, 1107, 388, 25353, 11, 457, 412, 512, 2793, 7614, 13, 286, 362, 281, 584, 300, 1107, 388, 50648], "temperature": 0.0, "avg_logprob": -0.14972352445795295, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.005576846189796925}, {"id": 499, "seek": 304304, "start": 3048.72, "end": 3052.16, "text": " is very fond of your work. So it's intriguing to kind of compare and contrast them.", "tokens": [50648, 307, 588, 9557, 295, 428, 589, 13, 407, 309, 311, 32503, 281, 733, 295, 6794, 293, 8712, 552, 13, 50820], "temperature": 0.0, "avg_logprob": -0.14972352445795295, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.005576846189796925}, {"id": 500, "seek": 304304, "start": 3056.0, "end": 3060.88, "text": " Because we had a discussion last week about whether we're living in a simulation and things,", "tokens": [51012, 1436, 321, 632, 257, 5017, 1036, 1243, 466, 1968, 321, 434, 2647, 294, 257, 16575, 293, 721, 11, 51256], "temperature": 0.0, "avg_logprob": -0.14972352445795295, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.005576846189796925}, {"id": 501, "seek": 304304, "start": 3060.88, "end": 3068.08, "text": " how would you position yourself in relation to David Chalmers' work from reality plus,", "tokens": [51256, 577, 576, 291, 2535, 1803, 294, 9721, 281, 4389, 761, 304, 18552, 6, 589, 490, 4103, 1804, 11, 51616], "temperature": 0.0, "avg_logprob": -0.14972352445795295, "compression_ratio": 1.5361702127659576, "no_speech_prob": 0.005576846189796925}, {"id": 502, "seek": 306808, "start": 3068.08, "end": 3072.7999999999997, "text": " his work on virtual worlds? I haven't read his recent book, so I cannot say.", "tokens": [50364, 702, 589, 322, 6374, 13401, 30, 286, 2378, 380, 1401, 702, 5162, 1446, 11, 370, 286, 2644, 584, 13, 50600], "temperature": 0.0, "avg_logprob": -0.10053940354106582, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0023964967112988234}, {"id": 503, "seek": 306808, "start": 3073.52, "end": 3078.3199999999997, "text": " And I don't know what his main thesis is about virtual worlds.", "tokens": [50636, 400, 286, 500, 380, 458, 437, 702, 2135, 22288, 307, 466, 6374, 13401, 13, 50876], "temperature": 0.0, "avg_logprob": -0.10053940354106582, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0023964967112988234}, {"id": 504, "seek": 306808, "start": 3080.4, "end": 3086.08, "text": " Okay. Well, I wouldn't want to speak on his behalf, but we had a discussion about it. I also", "tokens": [50980, 1033, 13, 1042, 11, 286, 2759, 380, 528, 281, 1710, 322, 702, 9490, 11, 457, 321, 632, 257, 5017, 466, 309, 13, 286, 611, 51264], "temperature": 0.0, "avg_logprob": -0.10053940354106582, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0023964967112988234}, {"id": 505, "seek": 306808, "start": 3086.08, "end": 3090.72, "text": " wanted to just point out something as well, which I find intriguing. And that is the extent to which", "tokens": [51264, 1415, 281, 445, 935, 484, 746, 382, 731, 11, 597, 286, 915, 32503, 13, 400, 300, 307, 264, 8396, 281, 597, 51496], "temperature": 0.0, "avg_logprob": -0.10053940354106582, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0023964967112988234}, {"id": 506, "seek": 306808, "start": 3090.72, "end": 3096.0, "text": " some of these speculations that are coming out of cognitive science kind of seemingly echo the", "tokens": [51496, 512, 295, 613, 1608, 4136, 300, 366, 1348, 484, 295, 15605, 3497, 733, 295, 18709, 14300, 264, 51760], "temperature": 0.0, "avg_logprob": -0.10053940354106582, "compression_ratio": 1.6525096525096525, "no_speech_prob": 0.0023964967112988234}, {"id": 507, "seek": 309600, "start": 3096.0, "end": 3101.04, "text": " world of psychoanalysis. Now, I know that a lot of cognitive scientists and neuroscientists hate", "tokens": [50364, 1002, 295, 33355, 29702, 4642, 13, 823, 11, 286, 458, 300, 257, 688, 295, 15605, 7708, 293, 28813, 5412, 1751, 4700, 50616], "temperature": 0.0, "avg_logprob": -0.1570581174364277, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.005775529891252518}, {"id": 508, "seek": 309600, "start": 3103.84, "end": 3109.28, "text": " psychoanalysis. I know that Anil Seth does, but there's an interesting comment that Slavoj \u017di\u017eek", "tokens": [50756, 33355, 29702, 4642, 13, 286, 458, 300, 1107, 388, 25353, 775, 11, 457, 456, 311, 364, 1880, 2871, 300, 6187, 25713, 73, 4423, 121, 72, 9159, 916, 51028], "temperature": 0.0, "avg_logprob": -0.1570581174364277, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.005775529891252518}, {"id": 509, "seek": 309600, "start": 3109.28, "end": 3116.08, "text": " has made about this, where if you take a Lacanian perspective, you don't engage with the real except", "tokens": [51028, 575, 1027, 466, 341, 11, 689, 498, 291, 747, 257, 40113, 282, 952, 4585, 11, 291, 500, 380, 4683, 365, 264, 957, 3993, 51368], "temperature": 0.0, "avg_logprob": -0.1570581174364277, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.005775529891252518}, {"id": 510, "seek": 309600, "start": 3116.08, "end": 3125.92, "text": " of certain moments. And in a sense, the fantasy has become a constitutive of how you engage with", "tokens": [51368, 295, 1629, 6065, 13, 400, 294, 257, 2020, 11, 264, 13861, 575, 1813, 257, 23079, 17254, 295, 577, 291, 4683, 365, 51860], "temperature": 0.0, "avg_logprob": -0.1570581174364277, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.005775529891252518}, {"id": 511, "seek": 312592, "start": 3125.92, "end": 3130.7200000000003, "text": " the real. So you see the real through the lens of fantasy, through the lens of the imagination,", "tokens": [50364, 264, 957, 13, 407, 291, 536, 264, 957, 807, 264, 6765, 295, 13861, 11, 807, 264, 6765, 295, 264, 12938, 11, 50604], "temperature": 0.0, "avg_logprob": -0.12969982289822302, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.0017859118524938822}, {"id": 512, "seek": 312592, "start": 3131.28, "end": 3136.7200000000003, "text": " which is very similar to what, in some ways, you're talking about. And he makes a comment", "tokens": [50632, 597, 307, 588, 2531, 281, 437, 11, 294, 512, 2098, 11, 291, 434, 1417, 466, 13, 400, 415, 1669, 257, 2871, 50904], "temperature": 0.0, "avg_logprob": -0.12969982289822302, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.0017859118524938822}, {"id": 513, "seek": 312592, "start": 3136.7200000000003, "end": 3143.6, "text": " in an essay that I published a long time ago in a book, and this is called From Virtual Reality", "tokens": [50904, 294, 364, 16238, 300, 286, 6572, 257, 938, 565, 2057, 294, 257, 1446, 11, 293, 341, 307, 1219, 3358, 23887, 33822, 51248], "temperature": 0.0, "avg_logprob": -0.12969982289822302, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.0017859118524938822}, {"id": 514, "seek": 312592, "start": 3143.6, "end": 3148.56, "text": " to the Virtualization of Reality, which is basically saying that our reality is itself", "tokens": [51248, 281, 264, 23887, 2144, 295, 33822, 11, 597, 307, 1936, 1566, 300, 527, 4103, 307, 2564, 51496], "temperature": 0.0, "avg_logprob": -0.12969982289822302, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.0017859118524938822}, {"id": 515, "seek": 312592, "start": 3148.56, "end": 3155.28, "text": " already virtualized. And I think what virtual reality therefore shows us is not how virtual", "tokens": [51496, 1217, 6374, 1602, 13, 400, 286, 519, 437, 6374, 4103, 4412, 3110, 505, 307, 406, 577, 6374, 51832], "temperature": 0.0, "avg_logprob": -0.12969982289822302, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.0017859118524938822}, {"id": 516, "seek": 315592, "start": 3156.16, "end": 3166.2400000000002, "text": " reality shows us is not how virtual reality is, but rather how virtual reality itself is,", "tokens": [50376, 4103, 3110, 505, 307, 406, 577, 6374, 4103, 307, 11, 457, 2831, 577, 6374, 4103, 2564, 307, 11, 50880], "temperature": 0.0, "avg_logprob": -0.13909982534555287, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.0008456204668618739}, {"id": 517, "seek": 315592, "start": 3166.2400000000002, "end": 3171.04, "text": " which is very similar to your kind of thinking. And so what I find intriguing is that some of these", "tokens": [50880, 597, 307, 588, 2531, 281, 428, 733, 295, 1953, 13, 400, 370, 437, 286, 915, 32503, 307, 300, 512, 295, 613, 51120], "temperature": 0.0, "avg_logprob": -0.13909982534555287, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.0008456204668618739}, {"id": 518, "seek": 315592, "start": 3172.64, "end": 3180.32, "text": " speculations are echoing previous speculations about how the mind works. Have you engaged in", "tokens": [51200, 1608, 4136, 366, 14300, 278, 3894, 1608, 4136, 466, 577, 264, 1575, 1985, 13, 3560, 291, 8237, 294, 51584], "temperature": 0.0, "avg_logprob": -0.13909982534555287, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.0008456204668618739}, {"id": 519, "seek": 318032, "start": 3180.32, "end": 3186.96, "text": " any way with \u017di\u017eek or the world of Lacanian psychoanalysis and its discussion about the real?", "tokens": [50364, 604, 636, 365, 4423, 121, 72, 9159, 916, 420, 264, 1002, 295, 40113, 282, 952, 33355, 29702, 4642, 293, 1080, 5017, 466, 264, 957, 30, 50696], "temperature": 0.0, "avg_logprob": -0.07370545787196006, "compression_ratio": 1.630281690140845, "no_speech_prob": 0.0026679306756705046}, {"id": 520, "seek": 318032, "start": 3187.76, "end": 3194.32, "text": " And I sometimes read this, but I've never had the discussion with \u017di\u017eek. I am not", "tokens": [50736, 400, 286, 2171, 1401, 341, 11, 457, 286, 600, 1128, 632, 264, 5017, 365, 4423, 121, 72, 9159, 916, 13, 286, 669, 406, 51064], "temperature": 0.0, "avg_logprob": -0.07370545787196006, "compression_ratio": 1.630281690140845, "no_speech_prob": 0.0026679306756705046}, {"id": 521, "seek": 318032, "start": 3194.32, "end": 3199.44, "text": " unsympathetic to this terminology. It's just the problem is that it doesn't allow me to make", "tokens": [51064, 2693, 88, 2455, 998, 3532, 281, 341, 27575, 13, 467, 311, 445, 264, 1154, 307, 300, 309, 1177, 380, 2089, 385, 281, 652, 51320], "temperature": 0.0, "avg_logprob": -0.07370545787196006, "compression_ratio": 1.630281690140845, "no_speech_prob": 0.0026679306756705046}, {"id": 522, "seek": 318032, "start": 3199.44, "end": 3204.6400000000003, "text": " models that I can test. And this means I don't know whether these models are wrong. So it's", "tokens": [51320, 5245, 300, 286, 393, 1500, 13, 400, 341, 1355, 286, 500, 380, 458, 1968, 613, 5245, 366, 2085, 13, 407, 309, 311, 51580], "temperature": 0.0, "avg_logprob": -0.07370545787196006, "compression_ratio": 1.630281690140845, "no_speech_prob": 0.0026679306756705046}, {"id": 523, "seek": 318032, "start": 3204.6400000000003, "end": 3210.1600000000003, "text": " basically a very useful way to generate stories that also give me a handle on reality in the sense", "tokens": [51580, 1936, 257, 588, 4420, 636, 281, 8460, 3676, 300, 611, 976, 385, 257, 4813, 322, 4103, 294, 264, 2020, 51856], "temperature": 0.0, "avg_logprob": -0.07370545787196006, "compression_ratio": 1.630281690140845, "no_speech_prob": 0.0026679306756705046}, {"id": 524, "seek": 321016, "start": 3210.16, "end": 3215.7599999999998, "text": " that allow me to point at entities and to manipulate them in my mind. And sometimes it's very useful", "tokens": [50364, 300, 2089, 385, 281, 935, 412, 16667, 293, 281, 20459, 552, 294, 452, 1575, 13, 400, 2171, 309, 311, 588, 4420, 50644], "temperature": 0.0, "avg_logprob": -0.07672474519261774, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.0002001866523642093}, {"id": 525, "seek": 321016, "start": 3215.7599999999998, "end": 3219.68, "text": " that you basically have an indexical model where you are separating the world into", "tokens": [50644, 300, 291, 1936, 362, 364, 8186, 804, 2316, 689, 291, 366, 29279, 264, 1002, 666, 50840], "temperature": 0.0, "avg_logprob": -0.07672474519261774, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.0002001866523642093}, {"id": 526, "seek": 321016, "start": 3219.68, "end": 3224.48, "text": " objects that are useful to you and you can manipulate them. But this decomposition doesn't", "tokens": [50840, 6565, 300, 366, 4420, 281, 291, 293, 291, 393, 20459, 552, 13, 583, 341, 48356, 1177, 380, 51080], "temperature": 0.0, "avg_logprob": -0.07672474519261774, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.0002001866523642093}, {"id": 527, "seek": 321016, "start": 3224.48, "end": 3230.08, "text": " need to be an accurate causal structure. So the criticism with psychoanalysis is not that the", "tokens": [51080, 643, 281, 312, 364, 8559, 38755, 3877, 13, 407, 264, 15835, 365, 33355, 29702, 4642, 307, 406, 300, 264, 51360], "temperature": 0.0, "avg_logprob": -0.07672474519261774, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.0002001866523642093}, {"id": 528, "seek": 321016, "start": 3230.08, "end": 3236.48, "text": " terminology is not useful to me. It's that psychoanalysis doesn't tell me how to build the mind", "tokens": [51360, 27575, 307, 406, 4420, 281, 385, 13, 467, 311, 300, 33355, 29702, 4642, 1177, 380, 980, 385, 577, 281, 1322, 264, 1575, 51680], "temperature": 0.0, "avg_logprob": -0.07672474519261774, "compression_ratio": 1.7378277153558053, "no_speech_prob": 0.0002001866523642093}, {"id": 529, "seek": 323648, "start": 3236.48, "end": 3241.04, "text": " and so I should say that it works and to compare different competing models of the mind and to see", "tokens": [50364, 293, 370, 286, 820, 584, 300, 309, 1985, 293, 281, 6794, 819, 15439, 5245, 295, 264, 1575, 293, 281, 536, 50592], "temperature": 0.0, "avg_logprob": -0.13677989203354407, "compression_ratio": 1.8576923076923078, "no_speech_prob": 0.003994887229055166}, {"id": 530, "seek": 323648, "start": 3241.04, "end": 3246.8, "text": " which one is better. To do this, I will need to automate the mind in a way. I need to reverse", "tokens": [50592, 597, 472, 307, 1101, 13, 1407, 360, 341, 11, 286, 486, 643, 281, 31605, 264, 1575, 294, 257, 636, 13, 286, 643, 281, 9943, 50880], "temperature": 0.0, "avg_logprob": -0.13677989203354407, "compression_ratio": 1.8576923076923078, "no_speech_prob": 0.003994887229055166}, {"id": 531, "seek": 323648, "start": 3246.8, "end": 3252.2400000000002, "text": " engineer what the mind is doing, the functions that the mind is applying to representational states", "tokens": [50880, 11403, 437, 264, 1575, 307, 884, 11, 264, 6828, 300, 264, 1575, 307, 9275, 281, 2906, 1478, 4368, 51152], "temperature": 0.0, "avg_logprob": -0.13677989203354407, "compression_ratio": 1.8576923076923078, "no_speech_prob": 0.003994887229055166}, {"id": 532, "seek": 323648, "start": 3252.8, "end": 3258.2400000000002, "text": " and need to get this done to such a detail that this thing becomes my black. And then I can compare", "tokens": [51180, 293, 643, 281, 483, 341, 1096, 281, 1270, 257, 2607, 300, 341, 551, 3643, 452, 2211, 13, 400, 550, 286, 393, 6794, 51452], "temperature": 0.0, "avg_logprob": -0.13677989203354407, "compression_ratio": 1.8576923076923078, "no_speech_prob": 0.003994887229055166}, {"id": 533, "seek": 323648, "start": 3258.2400000000002, "end": 3264.4, "text": " its functionality. I want to move on to the questions that are coming in. I want to invite", "tokens": [51452, 1080, 14980, 13, 286, 528, 281, 1286, 322, 281, 264, 1651, 300, 366, 1348, 294, 13, 286, 528, 281, 7980, 51760], "temperature": 0.0, "avg_logprob": -0.13677989203354407, "compression_ratio": 1.8576923076923078, "no_speech_prob": 0.003994887229055166}, {"id": 534, "seek": 326440, "start": 3264.4, "end": 3269.2000000000003, "text": " people in the audience to comment as I want to make an observation and that is to say that", "tokens": [50364, 561, 294, 264, 4034, 281, 2871, 382, 286, 528, 281, 652, 364, 14816, 293, 300, 307, 281, 584, 300, 50604], "temperature": 0.0, "avg_logprob": -0.14339714339285187, "compression_ratio": 1.73125, "no_speech_prob": 0.033366039395332336}, {"id": 535, "seek": 326440, "start": 3269.2000000000003, "end": 3273.04, "text": " in my own world, this is years ago, I was working on a kind of coming out of Freud and thinking about", "tokens": [50604, 294, 452, 1065, 1002, 11, 341, 307, 924, 2057, 11, 286, 390, 1364, 322, 257, 733, 295, 1348, 484, 295, 41590, 293, 1953, 466, 50796], "temperature": 0.0, "avg_logprob": -0.14339714339285187, "compression_ratio": 1.73125, "no_speech_prob": 0.033366039395332336}, {"id": 536, "seek": 326440, "start": 3273.04, "end": 3278.7200000000003, "text": " how you use model psychoanalysis and engaging with, actually in this case it was with the work of", "tokens": [50796, 577, 291, 764, 2316, 33355, 29702, 4642, 293, 11268, 365, 11, 767, 294, 341, 1389, 309, 390, 365, 264, 589, 295, 51080], "temperature": 0.0, "avg_logprob": -0.14339714339285187, "compression_ratio": 1.73125, "no_speech_prob": 0.033366039395332336}, {"id": 537, "seek": 326440, "start": 3278.7200000000003, "end": 3283.84, "text": " Walter Benjamin, I came across something that is uncannily similar, certainly in terms of the", "tokens": [51080, 21572, 22231, 11, 286, 1361, 2108, 746, 300, 307, 6219, 969, 953, 2531, 11, 3297, 294, 2115, 295, 264, 51336], "temperature": 0.0, "avg_logprob": -0.14339714339285187, "compression_ratio": 1.73125, "no_speech_prob": 0.033366039395332336}, {"id": 538, "seek": 326440, "start": 3283.84, "end": 3288.2400000000002, "text": " terminology used, whether we're talking about the same thing, I don't know. But let me just", "tokens": [51336, 27575, 1143, 11, 1968, 321, 434, 1417, 466, 264, 912, 551, 11, 286, 500, 380, 458, 13, 583, 718, 385, 445, 51556], "temperature": 0.0, "avg_logprob": -0.14339714339285187, "compression_ratio": 1.73125, "no_speech_prob": 0.033366039395332336}, {"id": 539, "seek": 326440, "start": 3288.2400000000002, "end": 3293.92, "text": " for a second just share you something which surprised me because when I heard", "tokens": [51556, 337, 257, 1150, 445, 2073, 291, 746, 597, 6100, 385, 570, 562, 286, 2198, 51840], "temperature": 0.0, "avg_logprob": -0.14339714339285187, "compression_ratio": 1.73125, "no_speech_prob": 0.033366039395332336}, {"id": 540, "seek": 329392, "start": 3293.92, "end": 3298.8, "text": " Blazegoriyakos talking about models and modeling, it's also crucial to his way of thinking.", "tokens": [50364, 18925, 89, 1146, 284, 4727, 514, 329, 1417, 466, 5245, 293, 15983, 11, 309, 311, 611, 11462, 281, 702, 636, 295, 1953, 13, 50608], "temperature": 0.0, "avg_logprob": -0.25623101454514724, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.003828162094578147}, {"id": 541, "seek": 329392, "start": 3299.52, "end": 3303.2000000000003, "text": " It sort of seemed to echo this. I'm just going to simply just share this screen a second.", "tokens": [50644, 467, 1333, 295, 6576, 281, 14300, 341, 13, 286, 478, 445, 516, 281, 2935, 445, 2073, 341, 2568, 257, 1150, 13, 50828], "temperature": 0.0, "avg_logprob": -0.25623101454514724, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.003828162094578147}, {"id": 542, "seek": 329392, "start": 3307.6, "end": 3315.04, "text": " Yeah, can you see that? It's the thing about, so the term that I'm always interested in is the", "tokens": [51048, 865, 11, 393, 291, 536, 300, 30, 467, 311, 264, 551, 466, 11, 370, 264, 1433, 300, 286, 478, 1009, 3102, 294, 307, 264, 51420], "temperature": 0.0, "avg_logprob": -0.25623101454514724, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.003828162094578147}, {"id": 543, "seek": 329392, "start": 3315.04, "end": 3320.08, "text": " term mymesis. I don't know if you know this term at all, but in Freud it's how you can,", "tokens": [51420, 1433, 452, 5814, 271, 13, 286, 500, 380, 458, 498, 291, 458, 341, 1433, 412, 439, 11, 457, 294, 41590, 309, 311, 577, 291, 393, 11, 51672], "temperature": 0.0, "avg_logprob": -0.25623101454514724, "compression_ratio": 1.6106194690265487, "no_speech_prob": 0.003828162094578147}, {"id": 544, "seek": 332008, "start": 3320.16, "end": 3324.64, "text": " he talks about it initially when he talks about how in his book of jokes, how you can connect", "tokens": [50368, 415, 6686, 466, 309, 9105, 562, 415, 6686, 466, 577, 294, 702, 1446, 295, 14439, 11, 577, 291, 393, 1745, 50592], "temperature": 0.0, "avg_logprob": -0.13397308287581777, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.003148772055283189}, {"id": 545, "seek": 332008, "start": 3324.64, "end": 3330.72, "text": " with someone who's a subject of a joke. Someone falling over a banana skin, for example, you", "tokens": [50592, 365, 1580, 567, 311, 257, 3983, 295, 257, 7647, 13, 8734, 7440, 670, 257, 14194, 3178, 11, 337, 1365, 11, 291, 50896], "temperature": 0.0, "avg_logprob": -0.13397308287581777, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.003148772055283189}, {"id": 546, "seek": 332008, "start": 3330.72, "end": 3337.2799999999997, "text": " somehow, you model yourself on that person recalling bodily memories of what it is to slip up and so", "tokens": [50896, 6063, 11, 291, 2316, 1803, 322, 300, 954, 9901, 278, 39576, 8495, 295, 437, 309, 307, 281, 11140, 493, 293, 370, 51224], "temperature": 0.0, "avg_logprob": -0.13397308287581777, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.003148772055283189}, {"id": 547, "seek": 332008, "start": 3337.2799999999997, "end": 3342.16, "text": " on and so on. It's how you identify with the world. The term mymesis is a form of that,", "tokens": [51224, 322, 293, 370, 322, 13, 467, 311, 577, 291, 5876, 365, 264, 1002, 13, 440, 1433, 452, 5814, 271, 307, 257, 1254, 295, 300, 11, 51468], "temperature": 0.0, "avg_logprob": -0.13397308287581777, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.003148772055283189}, {"id": 548, "seek": 332008, "start": 3342.16, "end": 3348.0, "text": " it's a form of modeling. But just I just want to read out some of the text here because it's so", "tokens": [51468, 309, 311, 257, 1254, 295, 15983, 13, 583, 445, 286, 445, 528, 281, 1401, 484, 512, 295, 264, 2487, 510, 570, 309, 311, 370, 51760], "temperature": 0.0, "avg_logprob": -0.13397308287581777, "compression_ratio": 1.718978102189781, "no_speech_prob": 0.003148772055283189}, {"id": 549, "seek": 334800, "start": 3348.0, "end": 3353.04, "text": " similar to this idea of models and modeling. And I know that the term can be taken out of context", "tokens": [50364, 2531, 281, 341, 1558, 295, 5245, 293, 15983, 13, 400, 286, 458, 300, 264, 1433, 393, 312, 2726, 484, 295, 4319, 50616], "temperature": 0.0, "avg_logprob": -0.11060930181432653, "compression_ratio": 1.7980769230769231, "no_speech_prob": 0.0017737830057740211}, {"id": 550, "seek": 334800, "start": 3353.04, "end": 3356.64, "text": " and have a completely different sort of meaning, so therefore it's a bit deceptive.", "tokens": [50616, 293, 362, 257, 2584, 819, 1333, 295, 3620, 11, 370, 4412, 309, 311, 257, 857, 368, 1336, 488, 13, 50796], "temperature": 0.0, "avg_logprob": -0.11060930181432653, "compression_ratio": 1.7980769230769231, "no_speech_prob": 0.0017737830057740211}, {"id": 551, "seek": 334800, "start": 3357.36, "end": 3362.0, "text": " Anyway, to just understand the meaning of mymesis in Benjamin, we must all recognize its origin,", "tokens": [50832, 5684, 11, 281, 445, 1223, 264, 3620, 295, 452, 5814, 271, 294, 22231, 11, 321, 1633, 439, 5521, 1080, 4957, 11, 51064], "temperature": 0.0, "avg_logprob": -0.11060930181432653, "compression_ratio": 1.7980769230769231, "no_speech_prob": 0.0017737830057740211}, {"id": 552, "seek": 334800, "start": 3362.0, "end": 3366.96, "text": " the process of modeling, of making a copy of. In essence, it refers to an interpretive process", "tokens": [51064, 264, 1399, 295, 15983, 11, 295, 1455, 257, 5055, 295, 13, 682, 12801, 11, 309, 14942, 281, 364, 7302, 488, 1399, 51312], "temperature": 0.0, "avg_logprob": -0.11060930181432653, "compression_ratio": 1.7980769230769231, "no_speech_prob": 0.0017737830057740211}, {"id": 553, "seek": 334800, "start": 3366.96, "end": 3372.24, "text": " that relates either to the modeling oneself on an object or to making a model of that object.", "tokens": [51312, 300, 16155, 2139, 281, 264, 15983, 32265, 322, 364, 2657, 420, 281, 1455, 257, 2316, 295, 300, 2657, 13, 51576], "temperature": 0.0, "avg_logprob": -0.11060930181432653, "compression_ratio": 1.7980769230769231, "no_speech_prob": 0.0017737830057740211}, {"id": 554, "seek": 334800, "start": 3372.24, "end": 3377.12, "text": " Likewise, mymesis may come into relation as a third party engages that model with that model,", "tokens": [51576, 30269, 11, 452, 5814, 271, 815, 808, 666, 9721, 382, 257, 2636, 3595, 45576, 300, 2316, 365, 300, 2316, 11, 51820], "temperature": 0.0, "avg_logprob": -0.11060930181432653, "compression_ratio": 1.7980769230769231, "no_speech_prob": 0.0017737830057740211}, {"id": 555, "seek": 337712, "start": 3377.12, "end": 3380.4, "text": " and the model becomes a vehicle for identifying with the original object.", "tokens": [50364, 293, 264, 2316, 3643, 257, 5864, 337, 16696, 365, 264, 3380, 2657, 13, 50528], "temperature": 0.0, "avg_logprob": -0.14576125967091527, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.0008274572901427746}, {"id": 556, "seek": 337712, "start": 3380.4, "end": 3385.8399999999997, "text": " In each case, the aim is to assimilate to that object. Mymesis, anyway, so it's going on about", "tokens": [50528, 682, 1184, 1389, 11, 264, 5939, 307, 281, 8249, 48104, 281, 300, 2657, 13, 1222, 5814, 271, 11, 4033, 11, 370, 309, 311, 516, 322, 466, 50800], "temperature": 0.0, "avg_logprob": -0.14576125967091527, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.0008274572901427746}, {"id": 557, "seek": 337712, "start": 3385.8399999999997, "end": 3392.3199999999997, "text": " this question about, so it's a concept that has been used in psychoanalysis. And I don't know,", "tokens": [50800, 341, 1168, 466, 11, 370, 309, 311, 257, 3410, 300, 575, 668, 1143, 294, 33355, 29702, 4642, 13, 400, 286, 500, 380, 458, 11, 51124], "temperature": 0.0, "avg_logprob": -0.14576125967091527, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.0008274572901427746}, {"id": 558, "seek": 337712, "start": 3392.3199999999997, "end": 3398.16, "text": " there's a risk that one can simply take a term, which has a completely different meaning in", "tokens": [51124, 456, 311, 257, 3148, 300, 472, 393, 2935, 747, 257, 1433, 11, 597, 575, 257, 2584, 819, 3620, 294, 51416], "temperature": 0.0, "avg_logprob": -0.14576125967091527, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.0008274572901427746}, {"id": 559, "seek": 337712, "start": 3398.16, "end": 3402.72, "text": " different contexts and apply it. But I do think that the concept, the model, is a fascinating one.", "tokens": [51416, 819, 30628, 293, 3079, 309, 13, 583, 286, 360, 519, 300, 264, 3410, 11, 264, 2316, 11, 307, 257, 10343, 472, 13, 51644], "temperature": 0.0, "avg_logprob": -0.14576125967091527, "compression_ratio": 1.700374531835206, "no_speech_prob": 0.0008274572901427746}, {"id": 560, "seek": 340272, "start": 3402.72, "end": 3408.7999999999997, "text": " And I'm intrigued by the fact that you, alongside Blaze, and I think alongside also Jeff Hawkins,", "tokens": [50364, 400, 286, 478, 35140, 538, 264, 1186, 300, 291, 11, 12385, 49894, 11, 293, 286, 519, 12385, 611, 7506, 9325, 10277, 11, 50668], "temperature": 0.0, "avg_logprob": -0.12693564811449373, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0007768440991640091}, {"id": 561, "seek": 340272, "start": 3408.7999999999997, "end": 3412.64, "text": " use that model as a way of opening up these questions.", "tokens": [50668, 764, 300, 2316, 382, 257, 636, 295, 5193, 493, 613, 1651, 13, 50860], "temperature": 0.0, "avg_logprob": -0.12693564811449373, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0007768440991640091}, {"id": 562, "seek": 340272, "start": 3413.9199999999996, "end": 3418.7999999999997, "text": " An issue with this type of language is that usually the understanding that it generates", "tokens": [50924, 1107, 2734, 365, 341, 2010, 295, 2856, 307, 300, 2673, 264, 3701, 300, 309, 23815, 51168], "temperature": 0.0, "avg_logprob": -0.12693564811449373, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0007768440991640091}, {"id": 563, "seek": 340272, "start": 3418.7999999999997, "end": 3423.6, "text": " at least doesn't converge. That's the general issue with continental philosophy.", "tokens": [51168, 412, 1935, 1177, 380, 41881, 13, 663, 311, 264, 2674, 2734, 365, 42479, 10675, 13, 51408], "temperature": 0.0, "avg_logprob": -0.12693564811449373, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0007768440991640091}, {"id": 564, "seek": 340272, "start": 3424.9599999999996, "end": 3430.3999999999996, "text": " Somebody recently asked on Twitter what the difference is between continental and analytical", "tokens": [51476, 13463, 3938, 2351, 322, 5794, 437, 264, 2649, 307, 1296, 42479, 293, 29579, 51748], "temperature": 0.0, "avg_logprob": -0.12693564811449373, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0007768440991640091}, {"id": 565, "seek": 343040, "start": 3430.4, "end": 3436.48, "text": " philosophers. And I somewhat flippantly responded that an analytical philosopher", "tokens": [50364, 36839, 13, 400, 286, 8344, 932, 2488, 3627, 15806, 300, 364, 29579, 29805, 50668], "temperature": 0.0, "avg_logprob": -0.15623287656413976, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.0012048842618241906}, {"id": 566, "seek": 343040, "start": 3436.48, "end": 3441.84, "text": " is one who understands that the difficult and hard questions of philosophy need to be", "tokens": [50668, 307, 472, 567, 15146, 300, 264, 2252, 293, 1152, 1651, 295, 10675, 643, 281, 312, 50936], "temperature": 0.0, "avg_logprob": -0.15623287656413976, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.0012048842618241906}, {"id": 567, "seek": 343040, "start": 3443.6, "end": 3452.4, "text": " answered with formal models. Whereas continental philosophers don't think that this is necessary,", "tokens": [51024, 10103, 365, 9860, 5245, 13, 13813, 42479, 36839, 500, 380, 519, 300, 341, 307, 4818, 11, 51464], "temperature": 0.0, "avg_logprob": -0.15623287656413976, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.0012048842618241906}, {"id": 568, "seek": 343040, "start": 3453.52, "end": 3458.8, "text": " because they are literally genre that is looking down on analytical philosophers.", "tokens": [51520, 570, 436, 366, 3736, 11022, 300, 307, 1237, 760, 322, 29579, 36839, 13, 51784], "temperature": 0.0, "avg_logprob": -0.15623287656413976, "compression_ratio": 1.6555023923444976, "no_speech_prob": 0.0012048842618241906}, {"id": 569, "seek": 345880, "start": 3459.6800000000003, "end": 3464.4, "text": " You can see the difference between analytical philosophy and continental philosophy in,", "tokens": [50408, 509, 393, 536, 264, 2649, 1296, 29579, 10675, 293, 42479, 10675, 294, 11, 50644], "temperature": 0.0, "avg_logprob": -0.13367055476396933, "compression_ratio": 1.7540322580645162, "no_speech_prob": 0.0004507969715632498}, {"id": 570, "seek": 345880, "start": 3464.4, "end": 3468.8, "text": " for instance, the treatment of Goethe's incompleteness proof. A proper analytical", "tokens": [50644, 337, 5197, 11, 264, 5032, 295, 1037, 302, 675, 311, 14036, 14657, 15264, 8177, 13, 316, 2296, 29579, 50864], "temperature": 0.0, "avg_logprob": -0.13367055476396933, "compression_ratio": 1.7540322580645162, "no_speech_prob": 0.0004507969715632498}, {"id": 571, "seek": 345880, "start": 3468.8, "end": 3474.88, "text": " philosopher who had a formal education will understand that this is a proof about certain", "tokens": [50864, 29805, 567, 632, 257, 9860, 3309, 486, 1223, 300, 341, 307, 257, 8177, 466, 1629, 51168], "temperature": 0.0, "avg_logprob": -0.13367055476396933, "compression_ratio": 1.7540322580645162, "no_speech_prob": 0.0004507969715632498}, {"id": 572, "seek": 345880, "start": 3474.88, "end": 3480.0800000000004, "text": " properties of formal languages, and specifically it proves that stateless formal languages that", "tokens": [51168, 7221, 295, 9860, 8650, 11, 293, 4682, 309, 25019, 300, 2219, 4272, 9860, 8650, 300, 51428], "temperature": 0.0, "avg_logprob": -0.13367055476396933, "compression_ratio": 1.7540322580645162, "no_speech_prob": 0.0004507969715632498}, {"id": 573, "seek": 345880, "start": 3480.0800000000004, "end": 3485.28, "text": " assume that truth exists independently of the process by which you get to prove", "tokens": [51428, 6552, 300, 3494, 8198, 21761, 295, 264, 1399, 538, 597, 291, 483, 281, 7081, 51688], "temperature": 0.0, "avg_logprob": -0.13367055476396933, "compression_ratio": 1.7540322580645162, "no_speech_prob": 0.0004507969715632498}, {"id": 574, "seek": 348528, "start": 3485.36, "end": 3492.0800000000004, "text": " don't lead to consistent models of the domain. And there are also related results, for instance,", "tokens": [50368, 500, 380, 1477, 281, 8398, 5245, 295, 264, 9274, 13, 400, 456, 366, 611, 4077, 3542, 11, 337, 5197, 11, 50704], "temperature": 0.0, "avg_logprob": -0.10749267192369097, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.0009840778075158596}, {"id": 575, "seek": 348528, "start": 3492.0800000000004, "end": 3497.6800000000003, "text": " that a system cannot make statements about affairs outside of itself. So when you want to", "tokens": [50704, 300, 257, 1185, 2644, 652, 12363, 466, 17478, 2380, 295, 2564, 13, 407, 562, 291, 528, 281, 50984], "temperature": 0.0, "avg_logprob": -0.10749267192369097, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.0009840778075158596}, {"id": 576, "seek": 348528, "start": 3497.6800000000003, "end": 3504.0, "text": " talk about the world in a formal system, you need to create a model of that world, and you can only", "tokens": [50984, 751, 466, 264, 1002, 294, 257, 9860, 1185, 11, 291, 643, 281, 1884, 257, 2316, 295, 300, 1002, 11, 293, 291, 393, 787, 51300], "temperature": 0.0, "avg_logprob": -0.10749267192369097, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.0009840778075158596}, {"id": 577, "seek": 348528, "start": 3504.0, "end": 3508.2400000000002, "text": " talk about that model. You cannot talk about anything outside of the models that you are creating.", "tokens": [51300, 751, 466, 300, 2316, 13, 509, 2644, 751, 466, 1340, 2380, 295, 264, 5245, 300, 291, 366, 4084, 13, 51512], "temperature": 0.0, "avg_logprob": -0.10749267192369097, "compression_ratio": 1.742081447963801, "no_speech_prob": 0.0009840778075158596}, {"id": 578, "seek": 350824, "start": 3509.04, "end": 3516.3999999999996, "text": " And to continental philosopher, the Goethe's proof is more or less often understood as a", "tokens": [50404, 400, 281, 42479, 29805, 11, 264, 1037, 302, 675, 311, 8177, 307, 544, 420, 1570, 2049, 7320, 382, 257, 50772], "temperature": 0.0, "avg_logprob": -0.08526065251598619, "compression_ratio": 1.715736040609137, "no_speech_prob": 0.004194265231490135}, {"id": 579, "seek": 350824, "start": 3516.3999999999996, "end": 3521.3599999999997, "text": " statement of mathematicians that prove that mathematics is important at getting a handle", "tokens": [50772, 5629, 295, 32811, 2567, 300, 7081, 300, 18666, 307, 1021, 412, 1242, 257, 4813, 51020], "temperature": 0.0, "avg_logprob": -0.08526065251598619, "compression_ratio": 1.715736040609137, "no_speech_prob": 0.004194265231490135}, {"id": 580, "seek": 350824, "start": 3521.3599999999997, "end": 3526.4799999999996, "text": " on reality, and therefore the only way you can get a handle on reality is by not knowing mathematics,", "tokens": [51020, 322, 4103, 11, 293, 4412, 264, 787, 636, 291, 393, 483, 257, 4813, 322, 4103, 307, 538, 406, 5276, 18666, 11, 51276], "temperature": 0.0, "avg_logprob": -0.08526065251598619, "compression_ratio": 1.715736040609137, "no_speech_prob": 0.004194265231490135}, {"id": 581, "seek": 350824, "start": 3526.4799999999996, "end": 3529.52, "text": " which gives the continental philosopher a clear advantage.", "tokens": [51276, 597, 2709, 264, 42479, 29805, 257, 1850, 5002, 13, 51428], "temperature": 0.0, "avg_logprob": -0.08526065251598619, "compression_ratio": 1.715736040609137, "no_speech_prob": 0.004194265231490135}, {"id": 582, "seek": 352952, "start": 3530.32, "end": 3535.12, "text": " I cannot hear you. You are muted.", "tokens": [50404, 286, 2644, 1568, 291, 13, 509, 366, 32808, 13, 50644], "temperature": 0.0, "avg_logprob": -0.14725644660718512, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.031369518488645554}, {"id": 583, "seek": 352952, "start": 3536.96, "end": 3540.72, "text": " That was a great answer. Thank you. We've got some questions. Now, I have a third series of further", "tokens": [50736, 663, 390, 257, 869, 1867, 13, 1044, 291, 13, 492, 600, 658, 512, 1651, 13, 823, 11, 286, 362, 257, 2636, 2638, 295, 3052, 50924], "temperature": 0.0, "avg_logprob": -0.14725644660718512, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.031369518488645554}, {"id": 584, "seek": 352952, "start": 3540.72, "end": 3543.84, "text": " questions that I'd like to ask. Maybe I could ask you one question before we go into the other", "tokens": [50924, 1651, 300, 286, 1116, 411, 281, 1029, 13, 2704, 286, 727, 1029, 291, 472, 1168, 949, 321, 352, 666, 264, 661, 51080], "temperature": 0.0, "avg_logprob": -0.14725644660718512, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.031369518488645554}, {"id": 585, "seek": 352952, "start": 3543.84, "end": 3548.24, "text": " questions. And that is, I mean, are you writing a book about this? I mean, is it being put down", "tokens": [51080, 1651, 13, 400, 300, 307, 11, 286, 914, 11, 366, 291, 3579, 257, 1446, 466, 341, 30, 286, 914, 11, 307, 309, 885, 829, 760, 51300], "temperature": 0.0, "avg_logprob": -0.14725644660718512, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.031369518488645554}, {"id": 586, "seek": 352952, "start": 3548.24, "end": 3552.24, "text": " in some documented form? Because it would be incredibly useful if it were.", "tokens": [51300, 294, 512, 23007, 1254, 30, 1436, 309, 576, 312, 6252, 4420, 498, 309, 645, 13, 51500], "temperature": 0.0, "avg_logprob": -0.14725644660718512, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.031369518488645554}, {"id": 587, "seek": 352952, "start": 3552.96, "end": 3558.56, "text": " You are right. I need to write a book about this. I have a large number of notes on stuff that needs", "tokens": [51536, 509, 366, 558, 13, 286, 643, 281, 2464, 257, 1446, 466, 341, 13, 286, 362, 257, 2416, 1230, 295, 5570, 322, 1507, 300, 2203, 51816], "temperature": 0.0, "avg_logprob": -0.14725644660718512, "compression_ratio": 1.7241379310344827, "no_speech_prob": 0.031369518488645554}, {"id": 588, "seek": 355856, "start": 3558.56, "end": 3564.08, "text": " to go into the book, but I also have a job and I have kids that are homeschooled and I have ADHD.", "tokens": [50364, 281, 352, 666, 264, 1446, 11, 457, 286, 611, 362, 257, 1691, 293, 286, 362, 2301, 300, 366, 7388, 21856, 292, 293, 286, 362, 38680, 13, 50640], "temperature": 0.0, "avg_logprob": -0.1505888289764148, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0025003133341670036}, {"id": 589, "seek": 355856, "start": 3564.08, "end": 3569.92, "text": " So I need to go into a different phase of my life to have long interrupted, uninterrupted sessions for", "tokens": [50640, 407, 286, 643, 281, 352, 666, 257, 819, 5574, 295, 452, 993, 281, 362, 938, 30329, 11, 49234, 5428, 292, 11081, 337, 50932], "temperature": 0.0, "avg_logprob": -0.1505888289764148, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0025003133341670036}, {"id": 590, "seek": 355856, "start": 3569.92, "end": 3574.24, "text": " writing long phone texts. But if you're bad about not having written the book yet.", "tokens": [50932, 3579, 938, 2593, 15765, 13, 583, 498, 291, 434, 1578, 466, 406, 1419, 3720, 264, 1446, 1939, 13, 51148], "temperature": 0.0, "avg_logprob": -0.1505888289764148, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0025003133341670036}, {"id": 591, "seek": 355856, "start": 3575.44, "end": 3582.72, "text": " Well, I think that a popular form of communicating ideas. So there is material out there,", "tokens": [51208, 1042, 11, 286, 519, 300, 257, 3743, 1254, 295, 17559, 3487, 13, 407, 456, 307, 2527, 484, 456, 11, 51572], "temperature": 0.0, "avg_logprob": -0.1505888289764148, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0025003133341670036}, {"id": 592, "seek": 355856, "start": 3582.72, "end": 3586.16, "text": " but I just think it could be assembled into an engine. Yes, it needs to be assembled. I feel", "tokens": [51572, 457, 286, 445, 519, 309, 727, 312, 24204, 666, 364, 2848, 13, 1079, 11, 309, 2203, 281, 312, 24204, 13, 286, 841, 51744], "temperature": 0.0, "avg_logprob": -0.1505888289764148, "compression_ratio": 1.7195571955719557, "no_speech_prob": 0.0025003133341670036}, {"id": 593, "seek": 358616, "start": 3586.16, "end": 3591.8399999999997, "text": " better if it is being assembled and not just existing as various disconnected conversations.", "tokens": [50364, 1101, 498, 309, 307, 885, 24204, 293, 406, 445, 6741, 382, 3683, 29426, 7315, 13, 50648], "temperature": 0.0, "avg_logprob": -0.15570706279337906, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.0016672170022502542}, {"id": 594, "seek": 358616, "start": 3591.8399999999997, "end": 3595.92, "text": " Yeah, I just, I mean, even Jeff Hawkins, I mean, my Jeff Hawkins book, I think is fabulous. But", "tokens": [50648, 865, 11, 286, 445, 11, 286, 914, 11, 754, 7506, 9325, 10277, 11, 286, 914, 11, 452, 7506, 9325, 10277, 1446, 11, 286, 519, 307, 17692, 13, 583, 50852], "temperature": 0.0, "avg_logprob": -0.15570706279337906, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.0016672170022502542}, {"id": 595, "seek": 358616, "start": 3595.92, "end": 3599.92, "text": " what's interesting is there are no footnotes in it. He's just kind of speculating. But", "tokens": [50852, 437, 311, 1880, 307, 456, 366, 572, 2671, 2247, 279, 294, 309, 13, 634, 311, 445, 733, 295, 1608, 12162, 13, 583, 51052], "temperature": 0.0, "avg_logprob": -0.15570706279337906, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.0016672170022502542}, {"id": 596, "seek": 358616, "start": 3599.92, "end": 3604.72, "text": " nonetheless, he's putting his ideas down there. And it's really incredibly useful to have that", "tokens": [51052, 26756, 11, 415, 311, 3372, 702, 3487, 760, 456, 13, 400, 309, 311, 534, 6252, 4420, 281, 362, 300, 51292], "temperature": 0.0, "avg_logprob": -0.15570706279337906, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.0016672170022502542}, {"id": 597, "seek": 358616, "start": 3604.72, "end": 3609.7599999999998, "text": " kind of commentary. So anyway, look forward to the book. I want to just ask this Matt Gorebay,", "tokens": [51292, 733, 295, 23527, 13, 407, 4033, 11, 574, 2128, 281, 264, 1446, 13, 286, 528, 281, 445, 1029, 341, 7397, 45450, 42484, 11, 51544], "temperature": 0.0, "avg_logprob": -0.15570706279337906, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.0016672170022502542}, {"id": 598, "seek": 360976, "start": 3609.76, "end": 3616.48, "text": " who's got a question in the chat, whether Matt is a graduate of MIT Media Lab. He's", "tokens": [50364, 567, 311, 658, 257, 1168, 294, 264, 5081, 11, 1968, 7397, 307, 257, 8080, 295, 13100, 14741, 10137, 13, 634, 311, 50700], "temperature": 0.0, "avg_logprob": -0.1679239273071289, "compression_ratio": 1.4634146341463414, "no_speech_prob": 0.0067742373794317245}, {"id": 599, "seek": 360976, "start": 3617.5200000000004, "end": 3622.88, "text": " a doctoral design student right now at FIU. Matt, would you like to ask your question?", "tokens": [50752, 257, 41419, 1715, 3107, 558, 586, 412, 479, 40, 52, 13, 7397, 11, 576, 291, 411, 281, 1029, 428, 1168, 30, 51020], "temperature": 0.0, "avg_logprob": -0.1679239273071289, "compression_ratio": 1.4634146341463414, "no_speech_prob": 0.0067742373794317245}, {"id": 600, "seek": 360976, "start": 3624.8, "end": 3628.88, "text": " Sure. Yeah, thanks for all of this. It's really interesting. Perhaps the book could be co-authored", "tokens": [51116, 4894, 13, 865, 11, 3231, 337, 439, 295, 341, 13, 467, 311, 534, 1880, 13, 10517, 264, 1446, 727, 312, 598, 12, 40198, 2769, 51320], "temperature": 0.0, "avg_logprob": -0.1679239273071289, "compression_ratio": 1.4634146341463414, "no_speech_prob": 0.0067742373794317245}, {"id": 601, "seek": 360976, "start": 3628.88, "end": 3634.32, "text": " by GPT-3, make it faster to, you know, just to give GPT-3 the agency over the first draft.", "tokens": [51320, 538, 26039, 51, 12, 18, 11, 652, 309, 4663, 281, 11, 291, 458, 11, 445, 281, 976, 26039, 51, 12, 18, 264, 7934, 670, 264, 700, 11206, 13, 51592], "temperature": 0.0, "avg_logprob": -0.1679239273071289, "compression_ratio": 1.4634146341463414, "no_speech_prob": 0.0067742373794317245}, {"id": 602, "seek": 363432, "start": 3635.28, "end": 3640.1600000000003, "text": " I was asking, speaking of agency, I mean, the question I have is about motivation. It's about", "tokens": [50412, 286, 390, 3365, 11, 4124, 295, 7934, 11, 286, 914, 11, 264, 1168, 286, 362, 307, 466, 12335, 13, 467, 311, 466, 50656], "temperature": 0.0, "avg_logprob": -0.0866506410681683, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.006483772769570351}, {"id": 603, "seek": 363432, "start": 3640.1600000000003, "end": 3644.8, "text": " sort of the high level motivations. When you ask, when you ask GPT-3, are you conscious? And then", "tokens": [50656, 1333, 295, 264, 1090, 1496, 39034, 13, 1133, 291, 1029, 11, 562, 291, 1029, 26039, 51, 12, 18, 11, 366, 291, 6648, 30, 400, 550, 50888], "temperature": 0.0, "avg_logprob": -0.0866506410681683, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.006483772769570351}, {"id": 604, "seek": 363432, "start": 3644.8, "end": 3651.6800000000003, "text": " it responds somewhat convincingly. It still isn't initiating that conversation. And so", "tokens": [50888, 309, 27331, 8344, 24823, 356, 13, 467, 920, 1943, 380, 6265, 990, 300, 3761, 13, 400, 370, 51232], "temperature": 0.0, "avg_logprob": -0.0866506410681683, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.006483772769570351}, {"id": 605, "seek": 363432, "start": 3652.6400000000003, "end": 3656.56, "text": " one of, I mean, kind of in listening to everything you were saying, and you said something about", "tokens": [51280, 472, 295, 11, 286, 914, 11, 733, 295, 294, 4764, 281, 1203, 291, 645, 1566, 11, 293, 291, 848, 746, 466, 51476], "temperature": 0.0, "avg_logprob": -0.0866506410681683, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.006483772769570351}, {"id": 606, "seek": 363432, "start": 3657.84, "end": 3662.1600000000003, "text": " when you were talking about trees and seeds, I love the thing about, instead of realizing", "tokens": [51540, 562, 291, 645, 1417, 466, 5852, 293, 9203, 11, 286, 959, 264, 551, 466, 11, 2602, 295, 16734, 51756], "temperature": 0.0, "avg_logprob": -0.0866506410681683, "compression_ratio": 1.7481203007518797, "no_speech_prob": 0.006483772769570351}, {"id": 607, "seek": 366216, "start": 3662.16, "end": 3666.16, "text": " the functionality, you want to build a system that wants to realize the functionality, you want", "tokens": [50364, 264, 14980, 11, 291, 528, 281, 1322, 257, 1185, 300, 2738, 281, 4325, 264, 14980, 11, 291, 528, 50564], "temperature": 0.0, "avg_logprob": -0.11473272180044523, "compression_ratio": 1.8926829268292682, "no_speech_prob": 0.0030742003582417965}, {"id": 608, "seek": 366216, "start": 3666.16, "end": 3670.0, "text": " to build the thing that wants to become a tree. But that question of wanting and motivation,", "tokens": [50564, 281, 1322, 264, 551, 300, 2738, 281, 1813, 257, 4230, 13, 583, 300, 1168, 295, 7935, 293, 12335, 11, 50756], "temperature": 0.0, "avg_logprob": -0.11473272180044523, "compression_ratio": 1.8926829268292682, "no_speech_prob": 0.0030742003582417965}, {"id": 609, "seek": 366216, "start": 3671.04, "end": 3676.64, "text": " how does one, at what point does that get put into the system? Like at what point does the system", "tokens": [50808, 577, 775, 472, 11, 412, 437, 935, 775, 300, 483, 829, 666, 264, 1185, 30, 1743, 412, 437, 935, 775, 264, 1185, 51088], "temperature": 0.0, "avg_logprob": -0.11473272180044523, "compression_ratio": 1.8926829268292682, "no_speech_prob": 0.0030742003582417965}, {"id": 610, "seek": 366216, "start": 3676.64, "end": 3687.2, "text": " become curious or self-motivated to do things that we didn't necessarily ask of it? And I think maybe", "tokens": [51088, 1813, 6369, 420, 2698, 12, 29778, 592, 770, 281, 360, 721, 300, 321, 994, 380, 4725, 1029, 295, 309, 30, 400, 286, 519, 1310, 51616], "temperature": 0.0, "avg_logprob": -0.11473272180044523, "compression_ratio": 1.8926829268292682, "no_speech_prob": 0.0030742003582417965}, {"id": 611, "seek": 368720, "start": 3687.2, "end": 3691.9199999999996, "text": " related to that, I don't know, I'll let you go on this, but maybe related to that, the question", "tokens": [50364, 4077, 281, 300, 11, 286, 500, 380, 458, 11, 286, 603, 718, 291, 352, 322, 341, 11, 457, 1310, 4077, 281, 300, 11, 264, 1168, 50600], "temperature": 0.0, "avg_logprob": -0.11804771423339844, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.0043962690979242325}, {"id": 612, "seek": 368720, "start": 3691.9199999999996, "end": 3700.48, "text": " of individuation and sort of inter-subjectivity, like, you know, has GPT-3 spoken to, are there", "tokens": [50600, 295, 2461, 16073, 293, 1333, 295, 728, 12, 30131, 1020, 4253, 11, 411, 11, 291, 458, 11, 575, 26039, 51, 12, 18, 10759, 281, 11, 366, 456, 51028], "temperature": 0.0, "avg_logprob": -0.11804771423339844, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.0043962690979242325}, {"id": 613, "seek": 368720, "start": 3700.48, "end": 3704.48, "text": " communities of GPT-3 all talking to each other about what they want to do and how do they individuate?", "tokens": [51028, 4456, 295, 26039, 51, 12, 18, 439, 1417, 281, 1184, 661, 466, 437, 436, 528, 281, 360, 293, 577, 360, 436, 2461, 10107, 30, 51228], "temperature": 0.0, "avg_logprob": -0.11804771423339844, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.0043962690979242325}, {"id": 614, "seek": 368720, "start": 3704.48, "end": 3710.08, "text": " Or is GPT-3 just always the same and its clones of itself? If you could speak to any of that,", "tokens": [51228, 1610, 307, 26039, 51, 12, 18, 445, 1009, 264, 912, 293, 1080, 43803, 295, 2564, 30, 759, 291, 727, 1710, 281, 604, 295, 300, 11, 51508], "temperature": 0.0, "avg_logprob": -0.11804771423339844, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.0043962690979242325}, {"id": 615, "seek": 368720, "start": 3710.08, "end": 3714.72, "text": " that'd be great. Thank you. Yes. So that's the question, are we doing something that the organism", "tokens": [51508, 300, 1116, 312, 869, 13, 1044, 291, 13, 1079, 13, 407, 300, 311, 264, 1168, 11, 366, 321, 884, 746, 300, 264, 24128, 51740], "temperature": 0.0, "avg_logprob": -0.11804771423339844, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.0043962690979242325}, {"id": 616, "seek": 371472, "start": 3714.72, "end": 3722.3999999999996, "text": " is not asking of us? And that's not an easy question to answer. If you look at our own", "tokens": [50364, 307, 406, 3365, 295, 505, 30, 400, 300, 311, 406, 364, 1858, 1168, 281, 1867, 13, 759, 291, 574, 412, 527, 1065, 50748], "temperature": 0.0, "avg_logprob": -0.0779961177280971, "compression_ratio": 1.773076923076923, "no_speech_prob": 0.0035330667160451412}, {"id": 617, "seek": 371472, "start": 3722.3999999999996, "end": 3729.6, "text": " motivation, I think that we have a few hundred physiological drives for different nutrients,", "tokens": [50748, 12335, 11, 286, 519, 300, 321, 362, 257, 1326, 3262, 41234, 11754, 337, 819, 17617, 11, 51108], "temperature": 0.0, "avg_logprob": -0.0779961177280971, "compression_ratio": 1.773076923076923, "no_speech_prob": 0.0035330667160451412}, {"id": 618, "seek": 371472, "start": 3729.6, "end": 3733.6, "text": " for instance, sometimes we want to eat salty food, sometimes we want to have sweet food,", "tokens": [51108, 337, 5197, 11, 2171, 321, 528, 281, 1862, 18443, 1755, 11, 2171, 321, 528, 281, 362, 3844, 1755, 11, 51308], "temperature": 0.0, "avg_logprob": -0.0779961177280971, "compression_ratio": 1.773076923076923, "no_speech_prob": 0.0035330667160451412}, {"id": 619, "seek": 371472, "start": 3733.6, "end": 3737.9199999999996, "text": " sometimes we need something to drink, sometimes we need to rest, and all these can be understood", "tokens": [51308, 2171, 321, 643, 746, 281, 2822, 11, 2171, 321, 643, 281, 1472, 11, 293, 439, 613, 393, 312, 7320, 51524], "temperature": 0.0, "avg_logprob": -0.0779961177280971, "compression_ratio": 1.773076923076923, "no_speech_prob": 0.0035330667160451412}, {"id": 620, "seek": 371472, "start": 3737.9199999999996, "end": 3743.4399999999996, "text": " as set-point deviations. And to deal with all of them, we need to create a dynamic model of our", "tokens": [51524, 382, 992, 12, 6053, 31219, 763, 13, 400, 281, 2028, 365, 439, 295, 552, 11, 321, 643, 281, 1884, 257, 8546, 2316, 295, 527, 51800], "temperature": 0.0, "avg_logprob": -0.0779961177280971, "compression_ratio": 1.773076923076923, "no_speech_prob": 0.0035330667160451412}, {"id": 621, "seek": 374344, "start": 3743.6, "end": 3748.96, "text": " needs projected into the future and then plans and higher-level models of these", "tokens": [50372, 2203, 26231, 666, 264, 2027, 293, 550, 5482, 293, 2946, 12, 12418, 5245, 295, 613, 50640], "temperature": 0.0, "avg_logprob": -0.1345943096464714, "compression_ratio": 1.77734375, "no_speech_prob": 0.002508461242541671}, {"id": 622, "seek": 374344, "start": 3749.52, "end": 3753.76, "text": " needs, which we could call purposes and so on. We don't just have physiological needs,", "tokens": [50668, 2203, 11, 597, 321, 727, 818, 9932, 293, 370, 322, 13, 492, 500, 380, 445, 362, 41234, 2203, 11, 50880], "temperature": 0.0, "avg_logprob": -0.1345943096464714, "compression_ratio": 1.77734375, "no_speech_prob": 0.002508461242541671}, {"id": 623, "seek": 374344, "start": 3753.76, "end": 3758.56, "text": " we also have social needs, for instance, a need to affiliation to become part of a group,", "tokens": [50880, 321, 611, 362, 2093, 2203, 11, 337, 5197, 11, 257, 643, 281, 14863, 399, 281, 1813, 644, 295, 257, 1594, 11, 51120], "temperature": 0.0, "avg_logprob": -0.1345943096464714, "compression_ratio": 1.77734375, "no_speech_prob": 0.002508461242541671}, {"id": 624, "seek": 374344, "start": 3758.56, "end": 3764.64, "text": " for instance, and to be accepted by it. Some people have a need for status to raise up in the group.", "tokens": [51120, 337, 5197, 11, 293, 281, 312, 9035, 538, 309, 13, 2188, 561, 362, 257, 643, 337, 6558, 281, 5300, 493, 294, 264, 1594, 13, 51424], "temperature": 0.0, "avg_logprob": -0.1345943096464714, "compression_ratio": 1.77734375, "no_speech_prob": 0.002508461242541671}, {"id": 625, "seek": 374344, "start": 3764.64, "end": 3771.68, "text": " There are romantic needs, which can be courtship modes or a need for intimacy and so on. And then", "tokens": [51424, 821, 366, 13590, 2203, 11, 597, 393, 312, 14141, 1210, 14068, 420, 257, 643, 337, 34450, 293, 370, 322, 13, 400, 550, 51776], "temperature": 0.0, "avg_logprob": -0.1345943096464714, "compression_ratio": 1.77734375, "no_speech_prob": 0.002508461242541671}, {"id": 626, "seek": 377168, "start": 3771.7599999999998, "end": 3776.48, "text": " next to about a dozen of these social needs, we have a handful of cognitive needs, a need to", "tokens": [50368, 958, 281, 466, 257, 16654, 295, 613, 2093, 2203, 11, 321, 362, 257, 16458, 295, 15605, 2203, 11, 257, 643, 281, 50604], "temperature": 0.0, "avg_logprob": -0.10295304213419999, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0011865297565236688}, {"id": 627, "seek": 377168, "start": 3777.9199999999996, "end": 3785.44, "text": " become more competent, become efficacious on the environment, a need to reduce uncertainty,", "tokens": [50676, 1813, 544, 29998, 11, 1813, 4703, 22641, 322, 264, 2823, 11, 257, 643, 281, 5407, 15697, 11, 51052], "temperature": 0.0, "avg_logprob": -0.10295304213419999, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0011865297565236688}, {"id": 628, "seek": 377168, "start": 3785.44, "end": 3790.16, "text": " and something that I would call a need for aesthetics, which means discovering deep", "tokens": [51052, 293, 746, 300, 286, 576, 818, 257, 643, 337, 35517, 11, 597, 1355, 24773, 2452, 51288], "temperature": 0.0, "avg_logprob": -0.10295304213419999, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0011865297565236688}, {"id": 629, "seek": 377168, "start": 3790.16, "end": 3795.7599999999998, "text": " structure in the world. And aesthetics can be split into stimulus-oriented aesthetics, so we", "tokens": [51288, 3877, 294, 264, 1002, 13, 400, 35517, 393, 312, 7472, 666, 21366, 12, 27414, 35517, 11, 370, 321, 51568], "temperature": 0.0, "avg_logprob": -0.10295304213419999, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0011865297565236688}, {"id": 630, "seek": 377168, "start": 3795.7599999999998, "end": 3800.3199999999997, "text": " are intrinsically wired to like certain body schemas over others, certain landscapes over others,", "tokens": [51568, 366, 28621, 984, 27415, 281, 411, 1629, 1772, 22627, 296, 670, 2357, 11, 1629, 29822, 670, 2357, 11, 51796], "temperature": 0.0, "avg_logprob": -0.10295304213419999, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0011865297565236688}, {"id": 631, "seek": 380032, "start": 3800.32, "end": 3804.32, "text": " and there are evolutionary reasons for that. And then there are some mathematical principles,", "tokens": [50364, 293, 456, 366, 27567, 4112, 337, 300, 13, 400, 550, 456, 366, 512, 18894, 9156, 11, 50564], "temperature": 0.0, "avg_logprob": -0.0824271974109468, "compression_ratio": 1.7938931297709924, "no_speech_prob": 0.0007667049649171531}, {"id": 632, "seek": 380032, "start": 3804.32, "end": 3809.36, "text": " what kind of representations we like, what form means to have a good representation of something", "tokens": [50564, 437, 733, 295, 33358, 321, 411, 11, 437, 1254, 1355, 281, 362, 257, 665, 10290, 295, 746, 50816], "temperature": 0.0, "avg_logprob": -0.0824271974109468, "compression_ratio": 1.7938931297709924, "no_speech_prob": 0.0007667049649171531}, {"id": 633, "seek": 380032, "start": 3809.36, "end": 3816.8, "text": " that are more general. And if we use meditation to disassemble our own needs and to dissociate", "tokens": [50816, 300, 366, 544, 2674, 13, 400, 498, 321, 764, 12537, 281, 717, 37319, 527, 1065, 2203, 293, 281, 44446, 473, 51188], "temperature": 0.0, "avg_logprob": -0.0824271974109468, "compression_ratio": 1.7938931297709924, "no_speech_prob": 0.0007667049649171531}, {"id": 634, "seek": 380032, "start": 3816.8, "end": 3822.48, "text": " from them, we realize that the things that give us pleasure and pain do fall in these categories.", "tokens": [51188, 490, 552, 11, 321, 4325, 300, 264, 721, 300, 976, 505, 6834, 293, 1822, 360, 2100, 294, 613, 10479, 13, 51472], "temperature": 0.0, "avg_logprob": -0.0824271974109468, "compression_ratio": 1.7938931297709924, "no_speech_prob": 0.0007667049649171531}, {"id": 635, "seek": 380032, "start": 3822.48, "end": 3828.2400000000002, "text": " So we have lots of these impulses that are about hunger and thirst and rest and so on,", "tokens": [51472, 407, 321, 362, 3195, 295, 613, 41767, 6196, 300, 366, 466, 19229, 293, 34846, 293, 1472, 293, 370, 322, 11, 51760], "temperature": 0.0, "avg_logprob": -0.0824271974109468, "compression_ratio": 1.7938931297709924, "no_speech_prob": 0.0007667049649171531}, {"id": 636, "seek": 382824, "start": 3828.24, "end": 3832.9599999999996, "text": " and we have impulses that are about the social domain, and the older we get, the more these", "tokens": [50364, 293, 321, 362, 41767, 6196, 300, 366, 466, 264, 2093, 9274, 11, 293, 264, 4906, 321, 483, 11, 264, 544, 613, 50600], "temperature": 0.0, "avg_logprob": -0.09407575351675761, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0004509295686148107}, {"id": 637, "seek": 382824, "start": 3832.9599999999996, "end": 3840.24, "text": " impulses get replaced by a deeper model of what we want the world to be like, and we act on this", "tokens": [50600, 41767, 6196, 483, 10772, 538, 257, 7731, 2316, 295, 437, 321, 528, 264, 1002, 281, 312, 411, 11, 293, 321, 605, 322, 341, 50964], "temperature": 0.0, "avg_logprob": -0.09407575351675761, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0004509295686148107}, {"id": 638, "seek": 382824, "start": 3840.24, "end": 3849.8399999999997, "text": " deeper model and digest these reflexes. And on the lowest level, when you try to get more enlightened,", "tokens": [50964, 7731, 2316, 293, 13884, 613, 23802, 279, 13, 400, 322, 264, 12437, 1496, 11, 562, 291, 853, 281, 483, 544, 36975, 11, 51444], "temperature": 0.0, "avg_logprob": -0.09407575351675761, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0004509295686148107}, {"id": 639, "seek": 382824, "start": 3849.8399999999997, "end": 3855.3599999999997, "text": " you may have just something left that people often call love, which is, I think, a need to", "tokens": [51444, 291, 815, 362, 445, 746, 1411, 300, 561, 2049, 818, 959, 11, 597, 307, 11, 286, 519, 11, 257, 643, 281, 51720], "temperature": 0.0, "avg_logprob": -0.09407575351675761, "compression_ratio": 1.6828193832599119, "no_speech_prob": 0.0004509295686148107}, {"id": 640, "seek": 385536, "start": 3855.36, "end": 3859.76, "text": " transcendentally connect to other agents and share purposes, that might act on these shared", "tokens": [50364, 28535, 317, 379, 1745, 281, 661, 12554, 293, 2073, 9932, 11, 300, 1062, 605, 322, 613, 5507, 50584], "temperature": 0.0, "avg_logprob": -0.10959764429040857, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.000984521466307342}, {"id": 641, "seek": 385536, "start": 3859.76, "end": 3864.88, "text": " purposes, but you can get deeper than this. And the deepest level, you only have aesthetics,", "tokens": [50584, 9932, 11, 457, 291, 393, 483, 7731, 813, 341, 13, 400, 264, 28288, 1496, 11, 291, 787, 362, 35517, 11, 50840], "temperature": 0.0, "avg_logprob": -0.10959764429040857, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.000984521466307342}, {"id": 642, "seek": 385536, "start": 3864.88, "end": 3870.48, "text": " the need to form structure and to make the world intelligible, to create a coherent model of", "tokens": [50840, 264, 643, 281, 1254, 3877, 293, 281, 652, 264, 1002, 5613, 964, 11, 281, 1884, 257, 36239, 2316, 295, 51120], "temperature": 0.0, "avg_logprob": -0.10959764429040857, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.000984521466307342}, {"id": 643, "seek": 385536, "start": 3870.48, "end": 3877.6, "text": " reality. And this need, I think, is similar to what Friston describes in the free energy principle,", "tokens": [51120, 4103, 13, 400, 341, 643, 11, 286, 519, 11, 307, 2531, 281, 437, 1526, 47345, 15626, 294, 264, 1737, 2281, 8665, 11, 51476], "temperature": 0.0, "avg_logprob": -0.10959764429040857, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.000984521466307342}, {"id": 644, "seek": 385536, "start": 3877.6, "end": 3883.2000000000003, "text": " it's basically predictive coding, it's the attempt to track reality using a model that is as good as", "tokens": [51476, 309, 311, 1936, 35521, 17720, 11, 309, 311, 264, 5217, 281, 2837, 4103, 1228, 257, 2316, 300, 307, 382, 665, 382, 51756], "temperature": 0.0, "avg_logprob": -0.10959764429040857, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.000984521466307342}, {"id": 645, "seek": 388320, "start": 3883.2, "end": 3888.16, "text": " possible, that tracking reality. And if you turn off this aesthetic need, in addition to all the", "tokens": [50364, 1944, 11, 300, 11603, 4103, 13, 400, 498, 291, 1261, 766, 341, 20092, 643, 11, 294, 4500, 281, 439, 264, 50612], "temperature": 0.0, "avg_logprob": -0.11883009457197345, "compression_ratio": 1.6411960132890366, "no_speech_prob": 0.0015720538794994354}, {"id": 646, "seek": 388320, "start": 3888.16, "end": 3895.68, "text": " others, my own mind becomes fuzzy, I fall asleep, I drift away, because if I stop paying my neurons", "tokens": [50612, 2357, 11, 452, 1065, 1575, 3643, 34710, 11, 286, 2100, 11039, 11, 286, 19699, 1314, 11, 570, 498, 286, 1590, 6229, 452, 22027, 50988], "temperature": 0.0, "avg_logprob": -0.11883009457197345, "compression_ratio": 1.6411960132890366, "no_speech_prob": 0.0015720538794994354}, {"id": 647, "seek": 388320, "start": 3895.68, "end": 3901.2, "text": " for producing order in the universe, and they stop doing this, then nothing else is happening in my", "tokens": [50988, 337, 10501, 1668, 294, 264, 6445, 11, 293, 436, 1590, 884, 341, 11, 550, 1825, 1646, 307, 2737, 294, 452, 51264], "temperature": 0.0, "avg_logprob": -0.11883009457197345, "compression_ratio": 1.6411960132890366, "no_speech_prob": 0.0015720538794994354}, {"id": 648, "seek": 388320, "start": 3901.2, "end": 3907.8399999999997, "text": " mind that I can observe, and I just lose coherence. So if we imagine this hierarchy of needs, which", "tokens": [51264, 1575, 300, 286, 393, 11441, 11, 293, 286, 445, 3624, 26528, 655, 13, 407, 498, 321, 3811, 341, 22333, 295, 2203, 11, 597, 51596], "temperature": 0.0, "avg_logprob": -0.11883009457197345, "compression_ratio": 1.6411960132890366, "no_speech_prob": 0.0015720538794994354}, {"id": 649, "seek": 388320, "start": 3907.8399999999997, "end": 3912.64, "text": " by itself, and seen as a cybernetic system, is not all that complicated, we can build this into a", "tokens": [51596, 538, 2564, 11, 293, 1612, 382, 257, 13411, 77, 3532, 1185, 11, 307, 406, 439, 300, 6179, 11, 321, 393, 1322, 341, 666, 257, 51836], "temperature": 0.0, "avg_logprob": -0.11883009457197345, "compression_ratio": 1.6411960132890366, "no_speech_prob": 0.0015720538794994354}, {"id": 650, "seek": 391264, "start": 3912.64, "end": 3917.3599999999997, "text": " machine, I think it's not that difficult. The difficult part is to get perception right, to get", "tokens": [50364, 3479, 11, 286, 519, 309, 311, 406, 300, 2252, 13, 440, 2252, 644, 307, 281, 483, 12860, 558, 11, 281, 483, 50600], "temperature": 0.0, "avg_logprob": -0.1403231842573299, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.0019169410225003958}, {"id": 651, "seek": 391264, "start": 3918.64, "end": 3923.8399999999997, "text": " ability to model reality in the universal base, you can have one coherent model of everything", "tokens": [50664, 3485, 281, 2316, 4103, 294, 264, 11455, 3096, 11, 291, 393, 362, 472, 36239, 2316, 295, 1203, 50924], "temperature": 0.0, "avg_logprob": -0.1403231842573299, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.0019169410225003958}, {"id": 652, "seek": 391264, "start": 3923.8399999999997, "end": 3928.56, "text": " that you relate stuff to, when we talk about meaning, we talk about how to relate an arbitrary", "tokens": [50924, 300, 291, 10961, 1507, 281, 11, 562, 321, 751, 466, 3620, 11, 321, 751, 466, 577, 281, 10961, 364, 23211, 51160], "temperature": 0.0, "avg_logprob": -0.1403231842573299, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.0019169410225003958}, {"id": 653, "seek": 391264, "start": 3928.56, "end": 3933.6, "text": " feature or domain or idea or concept to this unified model of reality that we are building each", "tokens": [51160, 4111, 420, 9274, 420, 1558, 420, 3410, 281, 341, 26787, 2316, 295, 4103, 300, 321, 366, 2390, 1184, 51412], "temperature": 0.0, "avg_logprob": -0.1403231842573299, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.0019169410225003958}, {"id": 654, "seek": 393360, "start": 3933.6, "end": 3941.7599999999998, "text": " work once in our own mind. Can I just pick up on a question, we've got another question", "tokens": [50364, 589, 1564, 294, 527, 1065, 1575, 13, 1664, 286, 445, 1888, 493, 322, 257, 1168, 11, 321, 600, 658, 1071, 1168, 50772], "temperature": 0.0, "avg_logprob": -0.1488784046496375, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.05539326369762421}, {"id": 655, "seek": 393360, "start": 3941.7599999999998, "end": 3946.64, "text": " lined up, but let me ask you one quickly. You come from a creative background, your father was an", "tokens": [50772, 17189, 493, 11, 457, 718, 385, 1029, 291, 472, 2661, 13, 509, 808, 490, 257, 5880, 3678, 11, 428, 3086, 390, 364, 51016], "temperature": 0.0, "avg_logprob": -0.1488784046496375, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.05539326369762421}, {"id": 656, "seek": 393360, "start": 3946.64, "end": 3953.6, "text": " architect, and you refer to let's say creative practices of the orchestra and so on, it's part", "tokens": [51016, 6331, 11, 293, 291, 2864, 281, 718, 311, 584, 5880, 7525, 295, 264, 25280, 293, 370, 322, 11, 309, 311, 644, 51364], "temperature": 0.0, "avg_logprob": -0.1488784046496375, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.05539326369762421}, {"id": 657, "seek": 393360, "start": 3953.6, "end": 3958.16, "text": " of what you're talking about, and frankly, your way of thinking is incredibly creative, it strikes", "tokens": [51364, 295, 437, 291, 434, 1417, 466, 11, 293, 11939, 11, 428, 636, 295, 1953, 307, 6252, 5880, 11, 309, 16750, 51592], "temperature": 0.0, "avg_logprob": -0.1488784046496375, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.05539326369762421}, {"id": 658, "seek": 393360, "start": 3958.16, "end": 3963.04, "text": " me as being very creative. I wonder, you haven't mentioned the word creativity, I don't think,", "tokens": [51592, 385, 382, 885, 588, 5880, 13, 286, 2441, 11, 291, 2378, 380, 2835, 264, 1349, 12915, 11, 286, 500, 380, 519, 11, 51836], "temperature": 0.0, "avg_logprob": -0.1488784046496375, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.05539326369762421}, {"id": 659, "seek": 396304, "start": 3963.04, "end": 3969.68, "text": " and how do you view creativity, is it just a myth or is it something, how could you conceptualize it", "tokens": [50364, 293, 577, 360, 291, 1910, 12915, 11, 307, 309, 445, 257, 9474, 420, 307, 309, 746, 11, 577, 727, 291, 24106, 1125, 309, 50696], "temperature": 0.0, "avg_logprob": -0.09700826871193062, "compression_ratio": 1.9111969111969112, "no_speech_prob": 0.0004290541692171246}, {"id": 660, "seek": 396304, "start": 3969.68, "end": 3976.64, "text": " within your framework? I think of creativity as the ability to bridge discontinuities in the search", "tokens": [50696, 1951, 428, 8388, 30, 286, 519, 295, 12915, 382, 264, 3485, 281, 7283, 31420, 84, 1088, 294, 264, 3164, 51044], "temperature": 0.0, "avg_logprob": -0.09700826871193062, "compression_ratio": 1.9111969111969112, "no_speech_prob": 0.0004290541692171246}, {"id": 661, "seek": 396304, "start": 3976.64, "end": 3981.52, "text": " space, and you are just following the gradient, and when you're just going through a continuous", "tokens": [51044, 1901, 11, 293, 291, 366, 445, 3480, 264, 16235, 11, 293, 562, 291, 434, 445, 516, 807, 257, 10957, 51288], "temperature": 0.0, "avg_logprob": -0.09700826871193062, "compression_ratio": 1.9111969111969112, "no_speech_prob": 0.0004290541692171246}, {"id": 662, "seek": 396304, "start": 3981.52, "end": 3986.8, "text": " search space, I don't think that you are creative, you just arrive at the state of the art, and even", "tokens": [51288, 3164, 1901, 11, 286, 500, 380, 519, 300, 291, 366, 5880, 11, 291, 445, 8881, 412, 264, 1785, 295, 264, 1523, 11, 293, 754, 51552], "temperature": 0.0, "avg_logprob": -0.09700826871193062, "compression_ratio": 1.9111969111969112, "no_speech_prob": 0.0004290541692171246}, {"id": 663, "seek": 396304, "start": 3986.8, "end": 3992.8, "text": " the state of the art is something that hasn't been done before, if you just combine what is known", "tokens": [51552, 264, 1785, 295, 264, 1523, 307, 746, 300, 6132, 380, 668, 1096, 949, 11, 498, 291, 445, 10432, 437, 307, 2570, 51852], "temperature": 0.0, "avg_logprob": -0.09700826871193062, "compression_ratio": 1.9111969111969112, "no_speech_prob": 0.0004290541692171246}, {"id": 664, "seek": 399280, "start": 3992.8, "end": 3997.76, "text": " and you find a local optimum in the known things, you're not being creative. To be creative, you", "tokens": [50364, 293, 291, 915, 257, 2654, 39326, 294, 264, 2570, 721, 11, 291, 434, 406, 885, 5880, 13, 1407, 312, 5880, 11, 291, 50612], "temperature": 0.0, "avg_logprob": -0.09307799961255944, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0013223355636000633}, {"id": 665, "seek": 399280, "start": 3997.76, "end": 4003.6800000000003, "text": " need to construct a new search space usually, and many methods in which you can be creative, for", "tokens": [50612, 643, 281, 7690, 257, 777, 3164, 1901, 2673, 11, 293, 867, 7150, 294, 597, 291, 393, 312, 5880, 11, 337, 50908], "temperature": 0.0, "avg_logprob": -0.09307799961255944, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0013223355636000633}, {"id": 666, "seek": 399280, "start": 4003.6800000000003, "end": 4010.7200000000003, "text": " instance, you can use random serendipity, you can use some evolutionary process that is combining", "tokens": [50908, 5197, 11, 291, 393, 764, 4974, 816, 521, 647, 507, 11, 291, 393, 764, 512, 27567, 1399, 300, 307, 21928, 51260], "temperature": 0.0, "avg_logprob": -0.09307799961255944, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0013223355636000633}, {"id": 667, "seek": 399280, "start": 4010.7200000000003, "end": 4016.7200000000003, "text": " elements in ways that you are unaware of, and then discover structure in them. Creativity is, in some", "tokens": [51260, 4959, 294, 2098, 300, 291, 366, 32065, 295, 11, 293, 550, 4411, 3877, 294, 552, 13, 11972, 4253, 307, 11, 294, 512, 51560], "temperature": 0.0, "avg_logprob": -0.09307799961255944, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0013223355636000633}, {"id": 668, "seek": 399280, "start": 4016.7200000000003, "end": 4022.1600000000003, "text": " sense, about jumping off from the known things into darkness and hoping that you end up landing on", "tokens": [51560, 2020, 11, 466, 11233, 766, 490, 264, 2570, 721, 666, 11262, 293, 7159, 300, 291, 917, 493, 11202, 322, 51832], "temperature": 0.0, "avg_logprob": -0.09307799961255944, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0013223355636000633}, {"id": 669, "seek": 402216, "start": 4022.16, "end": 4030.0, "text": " the other side. So it's related to a search. Let me just put this to you then. Do you think that,", "tokens": [50364, 264, 661, 1252, 13, 407, 309, 311, 4077, 281, 257, 3164, 13, 961, 385, 445, 829, 341, 281, 291, 550, 13, 1144, 291, 519, 300, 11, 50756], "temperature": 0.0, "avg_logprob": -0.14882313836481154, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.001185860252007842}, {"id": 670, "seek": 402216, "start": 4031.12, "end": 4034.56, "text": " because you mentioned this before in your discussions, but do you think Move 37 in Game", "tokens": [50812, 570, 291, 2835, 341, 949, 294, 428, 11088, 11, 457, 360, 291, 519, 10475, 13435, 294, 7522, 50984], "temperature": 0.0, "avg_logprob": -0.14882313836481154, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.001185860252007842}, {"id": 671, "seek": 402216, "start": 4034.56, "end": 4042.8799999999997, "text": " 2 of AlphaGo, was that creative? Could you call that creative? I don't think that AlphaGo is", "tokens": [50984, 568, 295, 20588, 12104, 11, 390, 300, 5880, 30, 7497, 291, 818, 300, 5880, 30, 286, 500, 380, 519, 300, 20588, 12104, 307, 51400], "temperature": 0.0, "avg_logprob": -0.14882313836481154, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.001185860252007842}, {"id": 672, "seek": 402216, "start": 4042.8799999999997, "end": 4051.2, "text": " creative in the sense, because what AlphaGo is, well, there are evolutionary methods in AlphaGo,", "tokens": [51400, 5880, 294, 264, 2020, 11, 570, 437, 20588, 12104, 307, 11, 731, 11, 456, 366, 27567, 7150, 294, 20588, 12104, 11, 51816], "temperature": 0.0, "avg_logprob": -0.14882313836481154, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.001185860252007842}, {"id": 673, "seek": 405120, "start": 4051.2, "end": 4056.24, "text": " and the outcome of what AlphaGo is arriving at is not always predictable. And it's also", "tokens": [50364, 293, 264, 9700, 295, 437, 20588, 12104, 307, 22436, 412, 307, 406, 1009, 27737, 13, 400, 309, 311, 611, 50616], "temperature": 0.0, "avg_logprob": -0.10671169813289198, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.001205765875056386}, {"id": 674, "seek": 405120, "start": 4056.24, "end": 4062.8799999999997, "text": " computationally irreducible in the sense that you cannot foresee what AlphaGo was doing. AlphaGo", "tokens": [50616, 24903, 379, 16014, 769, 32128, 294, 264, 2020, 300, 291, 2644, 38736, 437, 20588, 12104, 390, 884, 13, 20588, 12104, 50948], "temperature": 0.0, "avg_logprob": -0.10671169813289198, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.001205765875056386}, {"id": 675, "seek": 405120, "start": 4062.8799999999997, "end": 4068.96, "text": " was able, in a relatively short amount of time, to demonstrate that human go play, which existed", "tokens": [50948, 390, 1075, 11, 294, 257, 7226, 2099, 2372, 295, 565, 11, 281, 11698, 300, 1952, 352, 862, 11, 597, 13135, 51252], "temperature": 0.0, "avg_logprob": -0.10671169813289198, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.001205765875056386}, {"id": 676, "seek": 405120, "start": 4068.96, "end": 4076.24, "text": " for thousands of years, was not optimal. It has discovered strategies that encounter the established", "tokens": [51252, 337, 5383, 295, 924, 11, 390, 406, 16252, 13, 467, 575, 6941, 9029, 300, 8593, 264, 7545, 51616], "temperature": 0.0, "avg_logprob": -0.10671169813289198, "compression_ratio": 1.646551724137931, "no_speech_prob": 0.001205765875056386}, {"id": 677, "seek": 407624, "start": 4076.24, "end": 4082.24, "text": " strategies and goal. And in this sense, from the perspective of a human go player, it was playing", "tokens": [50364, 9029, 293, 3387, 13, 400, 294, 341, 2020, 11, 490, 264, 4585, 295, 257, 1952, 352, 4256, 11, 309, 390, 2433, 50664], "temperature": 0.0, "avg_logprob": -0.12405894200007121, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.001753370393998921}, {"id": 678, "seek": 407624, "start": 4082.24, "end": 4088.9599999999996, "text": " in a creative way. It just discovered new things that had not been discovered before. But if you", "tokens": [50664, 294, 257, 5880, 636, 13, 467, 445, 6941, 777, 721, 300, 632, 406, 668, 6941, 949, 13, 583, 498, 291, 51000], "temperature": 0.0, "avg_logprob": -0.12405894200007121, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.001753370393998921}, {"id": 679, "seek": 407624, "start": 4088.9599999999996, "end": 4095.52, "text": " will run AlphaGo multiple times, it's always going to discover these things. And so the search is,", "tokens": [51000, 486, 1190, 20588, 12104, 3866, 1413, 11, 309, 311, 1009, 516, 281, 4411, 613, 721, 13, 400, 370, 264, 3164, 307, 11, 51328], "temperature": 0.0, "avg_logprob": -0.12405894200007121, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.001753370393998921}, {"id": 680, "seek": 407624, "start": 4096.16, "end": 4103.04, "text": " while it has stochastic elements, as a deterministic outcome. And I think that when we look at systems", "tokens": [51360, 1339, 309, 575, 342, 8997, 2750, 4959, 11, 382, 257, 15957, 3142, 9700, 13, 400, 286, 519, 300, 562, 321, 574, 412, 3652, 51704], "temperature": 0.0, "avg_logprob": -0.12405894200007121, "compression_ratio": 1.6229508196721312, "no_speech_prob": 0.001753370393998921}, {"id": 681, "seek": 410304, "start": 4103.04, "end": 4108.08, "text": " like this, our notion of creativity is kind of sort of falls apart. But creativity is not", "tokens": [50364, 411, 341, 11, 527, 10710, 295, 12915, 307, 733, 295, 1333, 295, 8804, 4936, 13, 583, 12915, 307, 406, 50616], "temperature": 0.0, "avg_logprob": -0.13054749985371739, "compression_ratio": 1.6750902527075813, "no_speech_prob": 0.0008553469087928534}, {"id": 682, "seek": 410304, "start": 4108.08, "end": 4112.96, "text": " absolutely a thing in the universe. It sometimes is a frame that is useful to describe what's", "tokens": [50616, 3122, 257, 551, 294, 264, 6445, 13, 467, 2171, 307, 257, 3920, 300, 307, 4420, 281, 6786, 437, 311, 50860], "temperature": 0.0, "avg_logprob": -0.13054749985371739, "compression_ratio": 1.6750902527075813, "no_speech_prob": 0.0008553469087928534}, {"id": 683, "seek": 410304, "start": 4112.96, "end": 4119.28, "text": " happening. And sometimes this frame falls apart. Let me just put a provocative comment to you,", "tokens": [50860, 2737, 13, 400, 2171, 341, 3920, 8804, 4936, 13, 961, 385, 445, 829, 257, 47663, 2871, 281, 291, 11, 51176], "temperature": 0.0, "avg_logprob": -0.13054749985371739, "compression_ratio": 1.6750902527075813, "no_speech_prob": 0.0008553469087928534}, {"id": 684, "seek": 410304, "start": 4119.28, "end": 4123.68, "text": " then. I mean, something that I thought myself, and I would like to know what you think of this.", "tokens": [51176, 550, 13, 286, 914, 11, 746, 300, 286, 1194, 2059, 11, 293, 286, 576, 411, 281, 458, 437, 291, 519, 295, 341, 13, 51396], "temperature": 0.0, "avg_logprob": -0.13054749985371739, "compression_ratio": 1.6750902527075813, "no_speech_prob": 0.0008553469087928534}, {"id": 685, "seek": 410304, "start": 4123.68, "end": 4130.0, "text": " So if GPT-3, if AlphaGo is not creative, and I kind of, in many ways, I don't think it is", "tokens": [51396, 407, 498, 26039, 51, 12, 18, 11, 498, 20588, 12104, 307, 406, 5880, 11, 293, 286, 733, 295, 11, 294, 867, 2098, 11, 286, 500, 380, 519, 309, 307, 51712], "temperature": 0.0, "avg_logprob": -0.13054749985371739, "compression_ratio": 1.6750902527075813, "no_speech_prob": 0.0008553469087928534}, {"id": 686, "seek": 413000, "start": 4130.0, "end": 4134.56, "text": " creative, it's just doing a very, very effective search. But then we could ask this question about", "tokens": [50364, 5880, 11, 309, 311, 445, 884, 257, 588, 11, 588, 4942, 3164, 13, 583, 550, 321, 727, 1029, 341, 1168, 466, 50592], "temperature": 0.0, "avg_logprob": -0.15891225459211963, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.001499662408605218}, {"id": 687, "seek": 413000, "start": 4134.56, "end": 4140.48, "text": " whether human beings are creative, or whether this term... Exactly. That's my issue, right? So", "tokens": [50592, 1968, 1952, 8958, 366, 5880, 11, 420, 1968, 341, 1433, 485, 7587, 13, 663, 311, 452, 2734, 11, 558, 30, 407, 50888], "temperature": 0.0, "avg_logprob": -0.15891225459211963, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.001499662408605218}, {"id": 688, "seek": 413000, "start": 4140.48, "end": 4145.92, "text": " sometimes your terms start meaning things. They mean something in a certain context, but when you", "tokens": [50888, 2171, 428, 2115, 722, 3620, 721, 13, 814, 914, 746, 294, 257, 1629, 4319, 11, 457, 562, 291, 51160], "temperature": 0.0, "avg_logprob": -0.15891225459211963, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.001499662408605218}, {"id": 689, "seek": 413000, "start": 4145.92, "end": 4151.6, "text": " increase the resolution too much, this context falls apart and no longer makes sense. And you use", "tokens": [51160, 3488, 264, 8669, 886, 709, 11, 341, 4319, 8804, 4936, 293, 572, 2854, 1669, 2020, 13, 400, 291, 764, 51444], "temperature": 0.0, "avg_logprob": -0.15891225459211963, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.001499662408605218}, {"id": 690, "seek": 413000, "start": 4152.24, "end": 4157.68, "text": " lose your term. And I have the same issue with the term like nemesis. But I like it. It's poetic.", "tokens": [51476, 3624, 428, 1433, 13, 400, 286, 362, 264, 912, 2734, 365, 264, 1433, 411, 408, 5814, 271, 13, 583, 286, 411, 309, 13, 467, 311, 41080, 13, 51748], "temperature": 0.0, "avg_logprob": -0.15891225459211963, "compression_ratio": 1.6968641114982579, "no_speech_prob": 0.001499662408605218}, {"id": 691, "seek": 415768, "start": 4157.68, "end": 4163.360000000001, "text": " It is evocative. It produces stuff in your mind. But when you zoom in very hard, it's not clear", "tokens": [50364, 467, 307, 1073, 905, 1166, 13, 467, 14725, 1507, 294, 428, 1575, 13, 583, 562, 291, 8863, 294, 588, 1152, 11, 309, 311, 406, 1850, 50648], "temperature": 0.0, "avg_logprob": -0.08836586306793522, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.0012244739336892962}, {"id": 692, "seek": 415768, "start": 4163.360000000001, "end": 4172.240000000001, "text": " what it means. And so instead, I try to examine the assumptions that are hidden in nemesis. For", "tokens": [50648, 437, 309, 1355, 13, 400, 370, 2602, 11, 286, 853, 281, 17496, 264, 17695, 300, 366, 7633, 294, 408, 5814, 271, 13, 1171, 51092], "temperature": 0.0, "avg_logprob": -0.08836586306793522, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.0012244739336892962}, {"id": 693, "seek": 415768, "start": 4172.240000000001, "end": 4177.76, "text": " instance, the idea that others exist independently of you, and yet you are able to take them in", "tokens": [51092, 5197, 11, 264, 1558, 300, 2357, 2514, 21761, 295, 291, 11, 293, 1939, 291, 366, 1075, 281, 747, 552, 294, 51368], "temperature": 0.0, "avg_logprob": -0.08836586306793522, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.0012244739336892962}, {"id": 694, "seek": 415768, "start": 4177.76, "end": 4183.200000000001, "text": " somehow instead of constructing them. And then the question, what's first, the model of the other,", "tokens": [51368, 6063, 2602, 295, 39969, 552, 13, 400, 550, 264, 1168, 11, 437, 311, 700, 11, 264, 2316, 295, 264, 661, 11, 51640], "temperature": 0.0, "avg_logprob": -0.08836586306793522, "compression_ratio": 1.6083333333333334, "no_speech_prob": 0.0012244739336892962}, {"id": 695, "seek": 418320, "start": 4183.2, "end": 4188.4, "text": " or the model of yourself? And whether it's the same thing in every person that becomes conscious.", "tokens": [50364, 420, 264, 2316, 295, 1803, 30, 400, 1968, 309, 311, 264, 912, 551, 294, 633, 954, 300, 3643, 6648, 13, 50624], "temperature": 0.0, "avg_logprob": -0.0688393731271067, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0014540485572069883}, {"id": 696, "seek": 418320, "start": 4188.4, "end": 4194.48, "text": " This is not obvious to me. And the notion of nemesis presupposes too much. And that makes me", "tokens": [50624, 639, 307, 406, 6322, 281, 385, 13, 400, 264, 10710, 295, 408, 5814, 271, 1183, 10504, 4201, 886, 709, 13, 400, 300, 1669, 385, 50928], "temperature": 0.0, "avg_logprob": -0.0688393731271067, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0014540485572069883}, {"id": 697, "seek": 418320, "start": 4194.48, "end": 4199.92, "text": " unsympathetic to it. So even though I appreciate the poetic illusions that are there in the space", "tokens": [50928, 2693, 88, 2455, 998, 3532, 281, 309, 13, 407, 754, 1673, 286, 4449, 264, 41080, 49836, 300, 366, 456, 294, 264, 1901, 51200], "temperature": 0.0, "avg_logprob": -0.0688393731271067, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0014540485572069883}, {"id": 698, "seek": 418320, "start": 4199.92, "end": 4204.4, "text": " that the term like this opens and the ability to converse about it, ultimately, I need to", "tokens": [51200, 300, 264, 1433, 411, 341, 9870, 293, 264, 3485, 281, 416, 4308, 466, 309, 11, 6284, 11, 286, 643, 281, 51424], "temperature": 0.0, "avg_logprob": -0.0688393731271067, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0014540485572069883}, {"id": 699, "seek": 418320, "start": 4204.4, "end": 4210.8, "text": " deconstruct the term before I can use it. Okay, so let me just put... I'm glad you take this position.", "tokens": [51424, 49473, 1757, 264, 1433, 949, 286, 393, 764, 309, 13, 1033, 11, 370, 718, 385, 445, 829, 485, 286, 478, 5404, 291, 747, 341, 2535, 13, 51744], "temperature": 0.0, "avg_logprob": -0.0688393731271067, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0014540485572069883}, {"id": 700, "seek": 421080, "start": 4210.8, "end": 4216.4800000000005, "text": " But we just throw an idea at you. So, I mean, one of the analogies that I've made in the past", "tokens": [50364, 583, 321, 445, 3507, 364, 1558, 412, 291, 13, 407, 11, 286, 914, 11, 472, 295, 264, 16660, 530, 300, 286, 600, 1027, 294, 264, 1791, 50648], "temperature": 0.0, "avg_logprob": -0.14943293602235855, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.008433797396719456}, {"id": 701, "seek": 421080, "start": 4216.4800000000005, "end": 4222.72, "text": " is to say that... Use the term magic at one point. Actually, I don't think that magic exists. I mean,", "tokens": [50648, 307, 281, 584, 300, 485, 8278, 264, 1433, 5585, 412, 472, 935, 13, 5135, 11, 286, 500, 380, 519, 300, 5585, 8198, 13, 286, 914, 11, 50960], "temperature": 0.0, "avg_logprob": -0.14943293602235855, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.008433797396719456}, {"id": 702, "seek": 421080, "start": 4222.72, "end": 4229.76, "text": " I think that what happens basically is if you take the example I always give, if you have a magician", "tokens": [50960, 286, 519, 300, 437, 2314, 1936, 307, 498, 291, 747, 264, 1365, 286, 1009, 976, 11, 498, 291, 362, 257, 38614, 51312], "temperature": 0.0, "avg_logprob": -0.14943293602235855, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.008433797396719456}, {"id": 703, "seek": 421080, "start": 4229.76, "end": 4234.0, "text": " at a kid's show, and they're pulling a rabbit out of a hat or something or doing magic,", "tokens": [51312, 412, 257, 1636, 311, 855, 11, 293, 436, 434, 8407, 257, 19509, 484, 295, 257, 2385, 420, 746, 420, 884, 5585, 11, 51524], "temperature": 0.0, "avg_logprob": -0.14943293602235855, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.008433797396719456}, {"id": 704, "seek": 421080, "start": 4234.88, "end": 4240.0, "text": " the magician's not doing magic. The magician is simply concealing the operations at work", "tokens": [51568, 264, 38614, 311, 406, 884, 5585, 13, 440, 38614, 307, 2935, 10413, 4270, 264, 7705, 412, 589, 51824], "temperature": 0.0, "avg_logprob": -0.14943293602235855, "compression_ratio": 1.7326007326007327, "no_speech_prob": 0.008433797396719456}, {"id": 705, "seek": 424000, "start": 4240.0, "end": 4244.96, "text": " and making you believe that it is magic. And I'm just wondering whether we couldn't take that same", "tokens": [50364, 293, 1455, 291, 1697, 300, 309, 307, 5585, 13, 400, 286, 478, 445, 6359, 1968, 321, 2809, 380, 747, 300, 912, 50612], "temperature": 0.0, "avg_logprob": -0.07483348561756646, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.0007086300174705684}, {"id": 706, "seek": 424000, "start": 4244.96, "end": 4249.52, "text": " notion and apply it to creativity, because we don't understand the processes. We just look back", "tokens": [50612, 10710, 293, 3079, 309, 281, 12915, 11, 570, 321, 500, 380, 1223, 264, 7555, 13, 492, 445, 574, 646, 50840], "temperature": 0.0, "avg_logprob": -0.07483348561756646, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.0007086300174705684}, {"id": 707, "seek": 424000, "start": 4249.52, "end": 4255.12, "text": " and say, wow, that's creative. Like some people said the same with AlphaGo, that's creative.", "tokens": [50840, 293, 584, 11, 6076, 11, 300, 311, 5880, 13, 1743, 512, 561, 848, 264, 912, 365, 20588, 12104, 11, 300, 311, 5880, 13, 51120], "temperature": 0.0, "avg_logprob": -0.07483348561756646, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.0007086300174705684}, {"id": 708, "seek": 424000, "start": 4255.12, "end": 4258.48, "text": " But maybe it's not. It's just simply we don't understand the process. Therefore,", "tokens": [51120, 583, 1310, 309, 311, 406, 13, 467, 311, 445, 2935, 321, 500, 380, 1223, 264, 1399, 13, 7504, 11, 51288], "temperature": 0.0, "avg_logprob": -0.07483348561756646, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.0007086300174705684}, {"id": 709, "seek": 424000, "start": 4258.48, "end": 4261.92, "text": " maybe even the term creativity is not a very productive term in the first place.", "tokens": [51288, 1310, 754, 264, 1433, 12915, 307, 406, 257, 588, 13304, 1433, 294, 264, 700, 1081, 13, 51460], "temperature": 0.0, "avg_logprob": -0.07483348561756646, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.0007086300174705684}, {"id": 710, "seek": 424000, "start": 4263.2, "end": 4268.48, "text": " Yeah, I suspect that magic also in order to make sense, we need to understand what the term means.", "tokens": [51524, 865, 11, 286, 9091, 300, 5585, 611, 294, 1668, 281, 652, 2020, 11, 321, 643, 281, 1223, 437, 264, 1433, 1355, 13, 51788], "temperature": 0.0, "avg_logprob": -0.07483348561756646, "compression_ratio": 1.8026315789473684, "no_speech_prob": 0.0007086300174705684}, {"id": 711, "seek": 426848, "start": 4268.48, "end": 4273.44, "text": " We need to completely deconstruct it into its constituents and then put it back together and", "tokens": [50364, 492, 643, 281, 2584, 49473, 1757, 309, 666, 1080, 30847, 293, 550, 829, 309, 646, 1214, 293, 50612], "temperature": 0.0, "avg_logprob": -0.11592995552789598, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.0010644489666447043}, {"id": 712, "seek": 426848, "start": 4273.44, "end": 4278.48, "text": " see if we still have magic or if this term can still be recovered. And typically,", "tokens": [50612, 536, 498, 321, 920, 362, 5585, 420, 498, 341, 1433, 393, 920, 312, 19542, 13, 400, 5850, 11, 50864], "temperature": 0.0, "avg_logprob": -0.11592995552789598, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.0010644489666447043}, {"id": 713, "seek": 426848, "start": 4278.48, "end": 4287.2, "text": " I see magic as the ability to get right access on the laws of reality. And if you think about", "tokens": [50864, 286, 536, 5585, 382, 264, 3485, 281, 483, 558, 2105, 322, 264, 6064, 295, 4103, 13, 400, 498, 291, 519, 466, 51300], "temperature": 0.0, "avg_logprob": -0.11592995552789598, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.0010644489666447043}, {"id": 714, "seek": 426848, "start": 4287.2, "end": 4292.5599999999995, "text": " what it means in the naive form is the departure from the mechanical universe. The universe that", "tokens": [51300, 437, 309, 1355, 294, 264, 29052, 1254, 307, 264, 25866, 490, 264, 12070, 6445, 13, 440, 6445, 300, 51568], "temperature": 0.0, "avg_logprob": -0.11592995552789598, "compression_ratio": 1.6294642857142858, "no_speech_prob": 0.0010644489666447043}, {"id": 715, "seek": 429256, "start": 4292.56, "end": 4298.96, "text": " we are in, according to the theory of physicalism, emerges over a causally closed lowest layer.", "tokens": [50364, 321, 366, 294, 11, 4650, 281, 264, 5261, 295, 4001, 1434, 11, 38965, 670, 257, 3302, 379, 5395, 12437, 4583, 13, 50684], "temperature": 0.0, "avg_logprob": -0.09070826783964905, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.0049017746932804585}, {"id": 716, "seek": 429256, "start": 4298.96, "end": 4303.68, "text": " And this causally closed lowest layer is basically whatever mechanics is making the", "tokens": [50684, 400, 341, 3302, 379, 5395, 12437, 4583, 307, 1936, 2035, 12939, 307, 1455, 264, 50920], "temperature": 0.0, "avg_logprob": -0.09070826783964905, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.0049017746932804585}, {"id": 717, "seek": 429256, "start": 4303.68, "end": 4309.92, "text": " universe happening. And ultimately, there is going to be some natural layer where things are just", "tokens": [50920, 6445, 2737, 13, 400, 6284, 11, 456, 307, 516, 281, 312, 512, 3303, 4583, 689, 721, 366, 445, 51232], "temperature": 0.0, "avg_logprob": -0.09070826783964905, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.0049017746932804585}, {"id": 718, "seek": 429256, "start": 4309.92, "end": 4316.4800000000005, "text": " happening without some conscious intervention. And the idea of magic is that our universe somehow", "tokens": [51232, 2737, 1553, 512, 6648, 13176, 13, 400, 264, 1558, 295, 5585, 307, 300, 527, 6445, 6063, 51560], "temperature": 0.0, "avg_logprob": -0.09070826783964905, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.0049017746932804585}, {"id": 719, "seek": 431648, "start": 4316.48, "end": 4325.28, "text": " is a conspiracy, that there is a way to subvert the laws of the mechanical universe using symbolic", "tokens": [50364, 307, 257, 20439, 11, 300, 456, 307, 257, 636, 281, 1422, 3281, 264, 6064, 295, 264, 12070, 6445, 1228, 25755, 50804], "temperature": 0.0, "avg_logprob": -0.10616579400487693, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0031225618440657854}, {"id": 720, "seek": 431648, "start": 4325.28, "end": 4330.879999999999, "text": " powers, that you have symbolic causality. And symbolic causality is, for instance, the connection", "tokens": [50804, 8674, 11, 300, 291, 362, 25755, 3302, 1860, 13, 400, 25755, 3302, 1860, 307, 11, 337, 5197, 11, 264, 4984, 51084], "temperature": 0.0, "avg_logprob": -0.10616579400487693, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0031225618440657854}, {"id": 721, "seek": 431648, "start": 4330.879999999999, "end": 4337.04, "text": " that exists between sacrificing a black cat and celestial events that are caused by this.", "tokens": [51084, 300, 8198, 1296, 42294, 257, 2211, 3857, 293, 41003, 3931, 300, 366, 7008, 538, 341, 13, 51392], "temperature": 0.0, "avg_logprob": -0.10616579400487693, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0031225618440657854}, {"id": 722, "seek": 431648, "start": 4337.599999999999, "end": 4342.719999999999, "text": " Right. And this, this is something that cannot possibly be explained by any known physical", "tokens": [51420, 1779, 13, 400, 341, 11, 341, 307, 746, 300, 2644, 6264, 312, 8825, 538, 604, 2570, 4001, 51676], "temperature": 0.0, "avg_logprob": -0.10616579400487693, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0031225618440657854}, {"id": 723, "seek": 434272, "start": 4342.8, "end": 4347.76, "text": " mechanism, because the elements of this transaction only have meaning in a symbolic", "tokens": [50368, 7513, 11, 570, 264, 4959, 295, 341, 14425, 787, 362, 3620, 294, 257, 25755, 50616], "temperature": 0.0, "avg_logprob": -0.1215086874560775, "compression_ratio": 1.6989247311827957, "no_speech_prob": 0.0025499616749584675}, {"id": 724, "seek": 434272, "start": 4347.76, "end": 4354.16, "text": " realm to a human mind that is acting based on a certain high level story and abstraction that", "tokens": [50616, 15355, 281, 257, 1952, 1575, 300, 307, 6577, 2361, 322, 257, 1629, 1090, 1496, 1657, 293, 37765, 300, 50936], "temperature": 0.0, "avg_logprob": -0.1215086874560775, "compression_ratio": 1.6989247311827957, "no_speech_prob": 0.0025499616749584675}, {"id": 725, "seek": 434272, "start": 4354.16, "end": 4357.84, "text": " is not a good depiction of what happens in the physical reality. It doesn't mean that the story", "tokens": [50936, 307, 406, 257, 665, 47740, 295, 437, 2314, 294, 264, 4001, 4103, 13, 467, 1177, 380, 914, 300, 264, 1657, 51120], "temperature": 0.0, "avg_logprob": -0.1215086874560775, "compression_ratio": 1.6989247311827957, "no_speech_prob": 0.0025499616749584675}, {"id": 726, "seek": 434272, "start": 4357.84, "end": 4364.72, "text": " is wrong. It's just not one about the frame of physics. In computer games, there is magic happening", "tokens": [51120, 307, 2085, 13, 467, 311, 445, 406, 472, 466, 264, 3920, 295, 10649, 13, 682, 3820, 2813, 11, 456, 307, 5585, 2737, 51464], "temperature": 0.0, "avg_logprob": -0.1215086874560775, "compression_ratio": 1.6989247311827957, "no_speech_prob": 0.0025499616749584675}, {"id": 727, "seek": 434272, "start": 4364.72, "end": 4369.6, "text": " relative to the computer game, right? You can use Minecraft. And in Minecraft, there is a mechanical", "tokens": [51464, 4972, 281, 264, 3820, 1216, 11, 558, 30, 509, 393, 764, 21029, 13, 400, 294, 21029, 11, 456, 307, 257, 12070, 51708], "temperature": 0.0, "avg_logprob": -0.1215086874560775, "compression_ratio": 1.6989247311827957, "no_speech_prob": 0.0025499616749584675}, {"id": 728, "seek": 436960, "start": 4369.6, "end": 4374.4800000000005, "text": " layer where everything happens by itself, but you can also call up a shell and enter a time-set", "tokens": [50364, 4583, 689, 1203, 2314, 538, 2564, 11, 457, 291, 393, 611, 818, 493, 257, 8720, 293, 3242, 257, 565, 12, 3854, 50608], "temperature": 0.0, "avg_logprob": -0.1128583005679551, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0022153437603265047}, {"id": 729, "seek": 436960, "start": 4374.4800000000005, "end": 4379.52, "text": " day in the sunrises. And this interaction somehow breaks the logic. And if you could do such a thing", "tokens": [50608, 786, 294, 264, 3295, 81, 3598, 13, 400, 341, 9285, 6063, 9857, 264, 9952, 13, 400, 498, 291, 727, 360, 1270, 257, 551, 50860], "temperature": 0.0, "avg_logprob": -0.1128583005679551, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0022153437603265047}, {"id": 730, "seek": 436960, "start": 4379.52, "end": 4386.56, "text": " in our world, if you can use a ritual to make the sunrise, then you would subvert the physical", "tokens": [50860, 294, 527, 1002, 11, 498, 291, 393, 764, 257, 13792, 281, 652, 264, 33675, 11, 550, 291, 576, 1422, 3281, 264, 4001, 51212], "temperature": 0.0, "avg_logprob": -0.1128583005679551, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0022153437603265047}, {"id": 731, "seek": 436960, "start": 4386.56, "end": 4393.4400000000005, "text": " reality. But what you can subvert is the psychological reality and the social reality.", "tokens": [51212, 4103, 13, 583, 437, 291, 393, 1422, 3281, 307, 264, 14346, 4103, 293, 264, 2093, 4103, 13, 51556], "temperature": 0.0, "avg_logprob": -0.1128583005679551, "compression_ratio": 1.7339449541284404, "no_speech_prob": 0.0022153437603265047}, {"id": 732, "seek": 439344, "start": 4394.08, "end": 4399.36, "text": " And in this form, magic does exist. If you get right access on somebody else's perception", "tokens": [50396, 400, 294, 341, 1254, 11, 5585, 775, 2514, 13, 759, 291, 483, 558, 2105, 322, 2618, 1646, 311, 12860, 50660], "temperature": 0.0, "avg_logprob": -0.06442671260614505, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.0037628349382430315}, {"id": 733, "seek": 439344, "start": 4400.0, "end": 4405.2, "text": " and attention and memory and imagination, you can change their reality in any way you want.", "tokens": [50692, 293, 3202, 293, 4675, 293, 12938, 11, 291, 393, 1319, 641, 4103, 294, 604, 636, 291, 528, 13, 50952], "temperature": 0.0, "avg_logprob": -0.06442671260614505, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.0037628349382430315}, {"id": 734, "seek": 439344, "start": 4406.24, "end": 4410.879999999999, "text": " And in our culture, there are some norms against this or there used to be norms against it.", "tokens": [51004, 400, 294, 527, 3713, 11, 456, 366, 512, 24357, 1970, 341, 420, 456, 1143, 281, 312, 24357, 1970, 309, 13, 51236], "temperature": 0.0, "avg_logprob": -0.06442671260614505, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.0037628349382430315}, {"id": 735, "seek": 439344, "start": 4410.879999999999, "end": 4416.879999999999, "text": " And I think that in Christianity, this didn't exist. It was legitimate to subvert the reality", "tokens": [51236, 400, 286, 519, 300, 294, 17326, 11, 341, 994, 380, 2514, 13, 467, 390, 17956, 281, 1422, 3281, 264, 4103, 51536], "temperature": 0.0, "avg_logprob": -0.06442671260614505, "compression_ratio": 1.660633484162896, "no_speech_prob": 0.0037628349382430315}, {"id": 736, "seek": 441688, "start": 4416.88, "end": 4424.400000000001, "text": " of other people by telling them, here is an omnipotent agent that is part of reality,", "tokens": [50364, 295, 661, 561, 538, 3585, 552, 11, 510, 307, 364, 36874, 647, 310, 317, 9461, 300, 307, 644, 295, 4103, 11, 50740], "temperature": 0.0, "avg_logprob": -0.1116675470696121, "compression_ratio": 1.874493927125506, "no_speech_prob": 0.025140220299363136}, {"id": 737, "seek": 441688, "start": 4424.400000000001, "end": 4428.56, "text": " therefore needs to be modeled in your own mind. And omnipotence means it knows everything that", "tokens": [50740, 4412, 2203, 281, 312, 37140, 294, 428, 1065, 1575, 13, 400, 36874, 647, 310, 655, 1355, 309, 3255, 1203, 300, 50948], "temperature": 0.0, "avg_logprob": -0.1116675470696121, "compression_ratio": 1.874493927125506, "no_speech_prob": 0.025140220299363136}, {"id": 738, "seek": 441688, "start": 4428.56, "end": 4433.6, "text": " is to be known as full read access to your mind. And omnipotence means it has full write access.", "tokens": [50948, 307, 281, 312, 2570, 382, 1577, 1401, 2105, 281, 428, 1575, 13, 400, 36874, 647, 310, 655, 1355, 309, 575, 1577, 2464, 2105, 13, 51200], "temperature": 0.0, "avg_logprob": -0.1116675470696121, "compression_ratio": 1.874493927125506, "no_speech_prob": 0.025140220299363136}, {"id": 739, "seek": 441688, "start": 4434.16, "end": 4440.0, "text": " And also, we have a backdoor to this thing. Every week, you can get an update and we tell you", "tokens": [51228, 400, 611, 11, 321, 362, 257, 646, 10441, 281, 341, 551, 13, 2048, 1243, 11, 291, 393, 483, 364, 5623, 293, 321, 980, 291, 51520], "temperature": 0.0, "avg_logprob": -0.1116675470696121, "compression_ratio": 1.874493927125506, "no_speech_prob": 0.025140220299363136}, {"id": 740, "seek": 441688, "start": 4440.0, "end": 4445.04, "text": " what this agent is going to do to your mind. And as a result, you have people that remember", "tokens": [51520, 437, 341, 9461, 307, 516, 281, 360, 281, 428, 1575, 13, 400, 382, 257, 1874, 11, 291, 362, 561, 300, 1604, 51772], "temperature": 0.0, "avg_logprob": -0.1116675470696121, "compression_ratio": 1.874493927125506, "no_speech_prob": 0.025140220299363136}, {"id": 741, "seek": 444504, "start": 4445.04, "end": 4451.36, "text": " having seen miracles, because something has rewritten the mental structure of their own mind.", "tokens": [50364, 1419, 1612, 24685, 11, 570, 746, 575, 319, 26859, 264, 4973, 3877, 295, 641, 1065, 1575, 13, 50680], "temperature": 0.0, "avg_logprob": -0.09496888149990125, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.0011506431037560105}, {"id": 742, "seek": 444504, "start": 4451.92, "end": 4458.48, "text": " And you often find patterns of this in ideologies. So this idea that somebody else gets right access", "tokens": [50708, 400, 291, 2049, 915, 8294, 295, 341, 294, 1153, 6204, 13, 407, 341, 1558, 300, 2618, 1646, 2170, 558, 2105, 51036], "temperature": 0.0, "avg_logprob": -0.09496888149990125, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.0011506431037560105}, {"id": 743, "seek": 444504, "start": 4458.48, "end": 4464.56, "text": " on your own minds, for instance, an innocent example is, here are my pronouns. And these", "tokens": [51036, 322, 428, 1065, 9634, 11, 337, 5197, 11, 364, 13171, 1365, 307, 11, 510, 366, 452, 35883, 13, 400, 613, 51340], "temperature": 0.0, "avg_logprob": -0.09496888149990125, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.0011506431037560105}, {"id": 744, "seek": 444504, "start": 4464.56, "end": 4469.36, "text": " pronouns are not what you perceive. They are what I want you to perceive. And I have the right to", "tokens": [51340, 35883, 366, 406, 437, 291, 20281, 13, 814, 366, 437, 286, 528, 291, 281, 20281, 13, 400, 286, 362, 264, 558, 281, 51580], "temperature": 0.0, "avg_logprob": -0.09496888149990125, "compression_ratio": 1.6493506493506493, "no_speech_prob": 0.0011506431037560105}, {"id": 745, "seek": 446936, "start": 4469.36, "end": 4476.16, "text": " change your mental representation. That's a form of magic. And I think that the idea that this", "tokens": [50364, 1319, 428, 4973, 10290, 13, 663, 311, 257, 1254, 295, 5585, 13, 400, 286, 519, 300, 264, 1558, 300, 341, 50704], "temperature": 0.0, "avg_logprob": -0.08804680750920223, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.003938631620258093}, {"id": 746, "seek": 446936, "start": 4476.16, "end": 4481.92, "text": " is happening is because the people who propagate these ideas don't believe in the individual", "tokens": [50704, 307, 2737, 307, 570, 264, 561, 567, 48256, 613, 3487, 500, 380, 1697, 294, 264, 2609, 50992], "temperature": 0.0, "avg_logprob": -0.08804680750920223, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.003938631620258093}, {"id": 747, "seek": 446936, "start": 4481.92, "end": 4487.759999999999, "text": " autonomy of individual minds to create realities and having a good outcome. You need to control the", "tokens": [50992, 27278, 295, 2609, 9634, 281, 1884, 27785, 293, 1419, 257, 665, 9700, 13, 509, 643, 281, 1969, 264, 51284], "temperature": 0.0, "avg_logprob": -0.08804680750920223, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.003938631620258093}, {"id": 748, "seek": 446936, "start": 4487.759999999999, "end": 4495.44, "text": " realities that minds create together by using magic to get the psychological realities of", "tokens": [51284, 27785, 300, 9634, 1884, 1214, 538, 1228, 5585, 281, 483, 264, 14346, 27785, 295, 51668], "temperature": 0.0, "avg_logprob": -0.08804680750920223, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.003938631620258093}, {"id": 749, "seek": 449544, "start": 4495.44, "end": 4498.4, "text": " individuals to converge to the desired social reality.", "tokens": [50364, 5346, 281, 41881, 281, 264, 14721, 2093, 4103, 13, 50512], "temperature": 0.0, "avg_logprob": -0.2046621233917946, "compression_ratio": 1.6328502415458936, "no_speech_prob": 0.0024806661531329155}, {"id": 750, "seek": 449544, "start": 4499.759999999999, "end": 4509.599999999999, "text": " One of the things I find interesting in your thinking is the role of, well, you use the term", "tokens": [50580, 1485, 295, 264, 721, 286, 915, 1880, 294, 428, 1953, 307, 264, 3090, 295, 11, 731, 11, 291, 764, 264, 1433, 51072], "temperature": 0.0, "avg_logprob": -0.2046621233917946, "compression_ratio": 1.6328502415458936, "no_speech_prob": 0.0024806661531329155}, {"id": 751, "seek": 449544, "start": 4509.599999999999, "end": 4514.0, "text": " ideology, use the term religion. But to my mind, they could be seen more in the realm of myth.", "tokens": [51072, 23101, 11, 764, 264, 1433, 7561, 13, 583, 281, 452, 1575, 11, 436, 727, 312, 1612, 544, 294, 264, 15355, 295, 9474, 13, 51292], "temperature": 0.0, "avg_logprob": -0.2046621233917946, "compression_ratio": 1.6328502415458936, "no_speech_prob": 0.0024806661531329155}, {"id": 752, "seek": 449544, "start": 4514.0, "end": 4520.08, "text": " I mean, there's a lot of this space. And the way that you use the term actually also reminds me", "tokens": [51292, 286, 914, 11, 456, 311, 257, 688, 295, 341, 1901, 13, 400, 264, 636, 300, 291, 764, 264, 1433, 767, 611, 12025, 385, 51596], "temperature": 0.0, "avg_logprob": -0.2046621233917946, "compression_ratio": 1.6328502415458936, "no_speech_prob": 0.0024806661531329155}, {"id": 753, "seek": 452008, "start": 4520.64, "end": 4527.36, "text": " of the work of Zizek. I mean, he makes a comment. He read a book about love at one point. And", "tokens": [50392, 295, 264, 589, 295, 1176, 590, 916, 13, 286, 914, 11, 415, 1669, 257, 2871, 13, 634, 1401, 257, 1446, 466, 959, 412, 472, 935, 13, 400, 50728], "temperature": 0.0, "avg_logprob": -0.13148739517375987, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.009756959974765778}, {"id": 754, "seek": 452008, "start": 4527.36, "end": 4533.36, "text": " he came to the conclusion that love is the myth that fills the gap between the self and the other.", "tokens": [50728, 415, 1361, 281, 264, 10063, 300, 959, 307, 264, 9474, 300, 22498, 264, 7417, 1296, 264, 2698, 293, 264, 661, 13, 51028], "temperature": 0.0, "avg_logprob": -0.13148739517375987, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.009756959974765778}, {"id": 755, "seek": 452008, "start": 4533.36, "end": 4539.28, "text": " And somehow myth has been some structuring device by which you look at things where it", "tokens": [51028, 400, 6063, 9474, 575, 668, 512, 6594, 1345, 4302, 538, 597, 291, 574, 412, 721, 689, 309, 51324], "temperature": 0.0, "avg_logprob": -0.13148739517375987, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.009756959974765778}, {"id": 756, "seek": 452008, "start": 4539.28, "end": 4544.24, "text": " conditions your understanding of reality a bit like ideology or in a bit like religion. Is that", "tokens": [51324, 4487, 428, 3701, 295, 4103, 257, 857, 411, 23101, 420, 294, 257, 857, 411, 7561, 13, 1119, 300, 51572], "temperature": 0.0, "avg_logprob": -0.13148739517375987, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.009756959974765778}, {"id": 757, "seek": 454424, "start": 4544.24, "end": 4551.5199999999995, "text": " something that you would engage with? I would engage with it. But I think that love is a more", "tokens": [50364, 746, 300, 291, 576, 4683, 365, 30, 286, 576, 4683, 365, 309, 13, 583, 286, 519, 300, 959, 307, 257, 544, 50728], "temperature": 0.0, "avg_logprob": -0.11502485689909561, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.005379230249673128}, {"id": 758, "seek": 454424, "start": 4551.5199999999995, "end": 4558.4, "text": " concrete meaning. Love is the discovery of shared sacredness. And sacredness are the purposes above", "tokens": [50728, 9859, 3620, 13, 5956, 307, 264, 12114, 295, 5507, 15757, 1287, 13, 400, 15757, 1287, 366, 264, 9932, 3673, 51072], "temperature": 0.0, "avg_logprob": -0.11502485689909561, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.005379230249673128}, {"id": 759, "seek": 454424, "start": 4558.4, "end": 4565.76, "text": " the ego, the purposes to which we are willing to sacrifice ourselves. This has to do with being", "tokens": [51072, 264, 14495, 11, 264, 9932, 281, 597, 321, 366, 4950, 281, 11521, 4175, 13, 639, 575, 281, 360, 365, 885, 51440], "temperature": 0.0, "avg_logprob": -0.11502485689909561, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.005379230249673128}, {"id": 760, "seek": 454424, "start": 4565.76, "end": 4570.8, "text": " part of a transcendental agent. Not everybody has that. If you are a sociopath, you will not", "tokens": [51440, 644, 295, 257, 28535, 14533, 9461, 13, 1726, 2201, 575, 300, 13, 759, 291, 366, 257, 3075, 27212, 11, 291, 486, 406, 51692], "temperature": 0.0, "avg_logprob": -0.11502485689909561, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.005379230249673128}, {"id": 761, "seek": 457080, "start": 4570.88, "end": 4576.0, "text": " have purposes above the ego. And so you will be incapable of love because you will not have shared", "tokens": [50368, 362, 9932, 3673, 264, 14495, 13, 400, 370, 291, 486, 312, 44174, 295, 959, 570, 291, 486, 406, 362, 5507, 50624], "temperature": 0.0, "avg_logprob": -0.09999071650144432, "compression_ratio": 1.870722433460076, "no_speech_prob": 0.0010803670156747103}, {"id": 762, "seek": 457080, "start": 4576.0, "end": 4580.88, "text": " purposes above the ego. You might have romantic infatuation. But ultimately, you are not going", "tokens": [50624, 9932, 3673, 264, 14495, 13, 509, 1062, 362, 13590, 1536, 267, 16073, 13, 583, 6284, 11, 291, 366, 406, 516, 50868], "temperature": 0.0, "avg_logprob": -0.09999071650144432, "compression_ratio": 1.870722433460076, "no_speech_prob": 0.0010803670156747103}, {"id": 763, "seek": 457080, "start": 4580.88, "end": 4586.400000000001, "text": " to build shared agents with others for non-transactional purposes because you share purposes with them.", "tokens": [50868, 281, 1322, 5507, 12554, 365, 2357, 337, 2107, 12, 24999, 578, 1966, 9932, 570, 291, 2073, 9932, 365, 552, 13, 51144], "temperature": 0.0, "avg_logprob": -0.09999071650144432, "compression_ratio": 1.870722433460076, "no_speech_prob": 0.0010803670156747103}, {"id": 764, "seek": 457080, "start": 4587.04, "end": 4593.92, "text": " So love is this discovery of shared purposes. But I mean, but can you use the term shared? I mean,", "tokens": [51176, 407, 959, 307, 341, 12114, 295, 5507, 9932, 13, 583, 286, 914, 11, 457, 393, 291, 764, 264, 1433, 5507, 30, 286, 914, 11, 51520], "temperature": 0.0, "avg_logprob": -0.09999071650144432, "compression_ratio": 1.870722433460076, "no_speech_prob": 0.0010803670156747103}, {"id": 765, "seek": 457080, "start": 4593.92, "end": 4598.64, "text": " how do we ever know the other? How do we ever accept the other? We can think that we're sharing", "tokens": [51520, 577, 360, 321, 1562, 458, 264, 661, 30, 1012, 360, 321, 1562, 3241, 264, 661, 30, 492, 393, 519, 300, 321, 434, 5414, 51756], "temperature": 0.0, "avg_logprob": -0.09999071650144432, "compression_ratio": 1.870722433460076, "no_speech_prob": 0.0010803670156747103}, {"id": 766, "seek": 459864, "start": 4598.64, "end": 4604.320000000001, "text": " things, but are we actually sharing things? We do this in the same way as we know ourselves.", "tokens": [50364, 721, 11, 457, 366, 321, 767, 5414, 721, 30, 492, 360, 341, 294, 264, 912, 636, 382, 321, 458, 4175, 13, 50648], "temperature": 0.0, "avg_logprob": -0.10944475597805448, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.003521205857396126}, {"id": 767, "seek": 459864, "start": 4604.320000000001, "end": 4609.76, "text": " These are model creations. The other is a story that we are creating about a certain state of", "tokens": [50648, 1981, 366, 2316, 37836, 13, 440, 661, 307, 257, 1657, 300, 321, 366, 4084, 466, 257, 1629, 1785, 295, 50920], "temperature": 0.0, "avg_logprob": -0.10944475597805448, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.003521205857396126}, {"id": 768, "seek": 459864, "start": 4609.76, "end": 4614.400000000001, "text": " affairs in the world. It's in this sense not objectively true, but it's a model that allows", "tokens": [50920, 17478, 294, 264, 1002, 13, 467, 311, 294, 341, 2020, 406, 46067, 2074, 11, 457, 309, 311, 257, 2316, 300, 4045, 51152], "temperature": 0.0, "avg_logprob": -0.10944475597805448, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.003521205857396126}, {"id": 769, "seek": 459864, "start": 4614.400000000001, "end": 4620.08, "text": " you to predict reality better than other models that are competing with it. No, interesting response.", "tokens": [51152, 291, 281, 6069, 4103, 1101, 813, 661, 5245, 300, 366, 15439, 365, 309, 13, 883, 11, 1880, 4134, 13, 51436], "temperature": 0.0, "avg_logprob": -0.10944475597805448, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.003521205857396126}, {"id": 770, "seek": 462008, "start": 4621.04, "end": 4627.92, "text": " So, Gustavo, maybe Gustavo is a postdoc at UC Santa Barbara. Gustavo, would you like to", "tokens": [50412, 407, 11, 32337, 25713, 11, 1310, 32337, 25713, 307, 257, 2183, 39966, 412, 14079, 9933, 19214, 13, 32337, 25713, 11, 576, 291, 411, 281, 50756], "temperature": 0.0, "avg_logprob": -0.1283324872943717, "compression_ratio": 1.4157894736842105, "no_speech_prob": 0.018164072185754776}, {"id": 771, "seek": 462008, "start": 4629.2, "end": 4640.5599999999995, "text": " ask a question? Sure. Thank you very much for the wonderful talk. I think I want to kind of", "tokens": [50820, 1029, 257, 1168, 30, 4894, 13, 1044, 291, 588, 709, 337, 264, 3715, 751, 13, 286, 519, 286, 528, 281, 733, 295, 51388], "temperature": 0.0, "avg_logprob": -0.1283324872943717, "compression_ratio": 1.4157894736842105, "no_speech_prob": 0.018164072185754776}, {"id": 772, "seek": 462008, "start": 4640.5599999999995, "end": 4647.44, "text": " build on Matt's question a little bit, but more specifically to the idea of understanding", "tokens": [51388, 1322, 322, 7397, 311, 1168, 257, 707, 857, 11, 457, 544, 4682, 281, 264, 1558, 295, 3701, 51732], "temperature": 0.0, "avg_logprob": -0.1283324872943717, "compression_ratio": 1.4157894736842105, "no_speech_prob": 0.018164072185754776}, {"id": 773, "seek": 464744, "start": 4648.4, "end": 4657.36, "text": " how computational systems are, let's say, evolved and programmed at the scientific level. Like,", "tokens": [50412, 577, 28270, 3652, 366, 11, 718, 311, 584, 11, 14178, 293, 31092, 412, 264, 8134, 1496, 13, 1743, 11, 50860], "temperature": 0.0, "avg_logprob": -0.10812479989570484, "compression_ratio": 1.530054644808743, "no_speech_prob": 0.0019261958077549934}, {"id": 774, "seek": 464744, "start": 4657.36, "end": 4666.719999999999, "text": " what is the state of the art in modeling either psychological states or understanding how different", "tokens": [50860, 437, 307, 264, 1785, 295, 264, 1523, 294, 15983, 2139, 14346, 4368, 420, 3701, 577, 819, 51328], "temperature": 0.0, "avg_logprob": -0.10812479989570484, "compression_ratio": 1.530054644808743, "no_speech_prob": 0.0019261958077549934}, {"id": 775, "seek": 464744, "start": 4667.679999999999, "end": 4674.48, "text": " models are building on knowledge where computational models can make creative leaps?", "tokens": [51376, 5245, 366, 2390, 322, 3601, 689, 28270, 5245, 393, 652, 5880, 476, 2382, 30, 51716], "temperature": 0.0, "avg_logprob": -0.10812479989570484, "compression_ratio": 1.530054644808743, "no_speech_prob": 0.0019261958077549934}, {"id": 776, "seek": 467448, "start": 4674.5599999999995, "end": 4681.679999999999, "text": " So, if it's not clear, I'm thinking about in the history of human society, they're different models", "tokens": [50368, 407, 11, 498, 309, 311, 406, 1850, 11, 286, 478, 1953, 466, 294, 264, 2503, 295, 1952, 4086, 11, 436, 434, 819, 5245, 50724], "temperature": 0.0, "avg_logprob": -0.18890842710222516, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.0006460160948336124}, {"id": 777, "seek": 467448, "start": 4681.679999999999, "end": 4687.28, "text": " of control, the models of narrative, you know, they're different, either religions or different", "tokens": [50724, 295, 1969, 11, 264, 5245, 295, 9977, 11, 291, 458, 11, 436, 434, 819, 11, 2139, 21212, 420, 819, 51004], "temperature": 0.0, "avg_logprob": -0.18890842710222516, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.0006460160948336124}, {"id": 778, "seek": 467448, "start": 4687.28, "end": 4694.959999999999, "text": " belief systems, but in the models of science, it seems as though that there is a building of", "tokens": [51004, 7107, 3652, 11, 457, 294, 264, 5245, 295, 3497, 11, 309, 2544, 382, 1673, 300, 456, 307, 257, 2390, 295, 51388], "temperature": 0.0, "avg_logprob": -0.18890842710222516, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.0006460160948336124}, {"id": 779, "seek": 469496, "start": 4695.92, "end": 4706.4, "text": " knowledge and that we're moving toward an end. So, where we will never, as an example, we right", "tokens": [50412, 3601, 293, 300, 321, 434, 2684, 7361, 364, 917, 13, 407, 11, 689, 321, 486, 1128, 11, 382, 364, 1365, 11, 321, 558, 50936], "temperature": 0.0, "avg_logprob": -0.1506757265255775, "compression_ratio": 1.5463917525773196, "no_speech_prob": 0.003480426501482725}, {"id": 780, "seek": 469496, "start": 4706.4, "end": 4713.2, "text": " now won't live to the end of the universe, but there is a goal in science that we as human beings", "tokens": [50936, 586, 1582, 380, 1621, 281, 264, 917, 295, 264, 6445, 11, 457, 456, 307, 257, 3387, 294, 3497, 300, 321, 382, 1952, 8958, 51276], "temperature": 0.0, "avg_logprob": -0.1506757265255775, "compression_ratio": 1.5463917525773196, "no_speech_prob": 0.003480426501482725}, {"id": 781, "seek": 469496, "start": 4713.2, "end": 4722.32, "text": " need to propagate outside of our, you know, cosmos, so we have a chance to exist, and we have multiverses.", "tokens": [51276, 643, 281, 48256, 2380, 295, 527, 11, 291, 458, 11, 41794, 11, 370, 321, 362, 257, 2931, 281, 2514, 11, 293, 321, 362, 2120, 1762, 279, 13, 51732], "temperature": 0.0, "avg_logprob": -0.1506757265255775, "compression_ratio": 1.5463917525773196, "no_speech_prob": 0.003480426501482725}, {"id": 782, "seek": 472232, "start": 4722.96, "end": 4730.799999999999, "text": " How does, how do these computational models either aid humanity or are we looking at these", "tokens": [50396, 1012, 775, 11, 577, 360, 613, 28270, 5245, 2139, 9418, 10243, 420, 366, 321, 1237, 412, 613, 50788], "temperature": 0.0, "avg_logprob": -0.09052132070064545, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.002322270767763257}, {"id": 783, "seek": 472232, "start": 4730.799999999999, "end": 4739.44, "text": " computational models to exceed humanity in some way? And what does that mean? I'm thinking about", "tokens": [50788, 28270, 5245, 281, 14048, 10243, 294, 512, 636, 30, 400, 437, 775, 300, 914, 30, 286, 478, 1953, 466, 51220], "temperature": 0.0, "avg_logprob": -0.09052132070064545, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.002322270767763257}, {"id": 784, "seek": 472232, "start": 4739.44, "end": 4745.44, "text": " that edge that you're talking about, because I think a lot of what we talked about in humanity", "tokens": [51220, 300, 4691, 300, 291, 434, 1417, 466, 11, 570, 286, 519, 257, 688, 295, 437, 321, 2825, 466, 294, 10243, 51520], "temperature": 0.0, "avg_logprob": -0.09052132070064545, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.002322270767763257}, {"id": 785, "seek": 474544, "start": 4745.44, "end": 4753.36, "text": " are black boxes. If you talk to a physicist or, or a mathematician, or an electrical engineer,", "tokens": [50364, 366, 2211, 9002, 13, 759, 291, 751, 281, 257, 42466, 420, 11, 420, 257, 48281, 11, 420, 364, 12147, 11403, 11, 50760], "temperature": 0.0, "avg_logprob": -0.11912143871348391, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.03960877284407616}, {"id": 786, "seek": 474544, "start": 4753.36, "end": 4761.44, "text": " they get to a point where we don't know the science. What are your thoughts about that? How do,", "tokens": [50760, 436, 483, 281, 257, 935, 689, 321, 500, 380, 458, 264, 3497, 13, 708, 366, 428, 4598, 466, 300, 30, 1012, 360, 11, 51164], "temperature": 0.0, "avg_logprob": -0.11912143871348391, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.03960877284407616}, {"id": 787, "seek": 474544, "start": 4761.44, "end": 4766.799999999999, "text": " how do we build better systems? Or how do we interact with these systems a little bit more", "tokens": [51164, 577, 360, 321, 1322, 1101, 3652, 30, 1610, 577, 360, 321, 4648, 365, 613, 3652, 257, 707, 857, 544, 51432], "temperature": 0.0, "avg_logprob": -0.11912143871348391, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.03960877284407616}, {"id": 788, "seek": 474544, "start": 4766.799999999999, "end": 4773.04, "text": " ethically or morally? So they're not like psychopathic or anyway, maybe that's a little", "tokens": [51432, 6468, 984, 420, 38622, 30, 407, 436, 434, 406, 411, 47577, 299, 420, 4033, 11, 1310, 300, 311, 257, 707, 51744], "temperature": 0.0, "avg_logprob": -0.11912143871348391, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.03960877284407616}, {"id": 789, "seek": 477304, "start": 4773.04, "end": 4780.48, "text": " too abstract. It's just, you brought a lot of higher level, a lot of knowledge here. So it's,", "tokens": [50364, 886, 12649, 13, 467, 311, 445, 11, 291, 3038, 257, 688, 295, 2946, 1496, 11, 257, 688, 295, 3601, 510, 13, 407, 309, 311, 11, 50736], "temperature": 0.0, "avg_logprob": -0.20815498728147694, "compression_ratio": 1.4226190476190477, "no_speech_prob": 0.0032201327849179506}, {"id": 790, "seek": 477304, "start": 4783.68, "end": 4787.76, "text": " it's very sobering is what I'm saying. Sorry about that.", "tokens": [50896, 309, 311, 588, 26212, 278, 307, 437, 286, 478, 1566, 13, 4919, 466, 300, 13, 51100], "temperature": 0.0, "avg_logprob": -0.20815498728147694, "compression_ratio": 1.4226190476190477, "no_speech_prob": 0.0032201327849179506}, {"id": 791, "seek": 477304, "start": 4788.96, "end": 4798.56, "text": " Don't be sorry. But I do welcome sobriety if it emerges. I think that you made some very", "tokens": [51160, 1468, 380, 312, 2597, 13, 583, 286, 360, 2928, 18253, 470, 2210, 498, 309, 38965, 13, 286, 519, 300, 291, 1027, 512, 588, 51640], "temperature": 0.0, "avg_logprob": -0.20815498728147694, "compression_ratio": 1.4226190476190477, "no_speech_prob": 0.0032201327849179506}, {"id": 792, "seek": 479856, "start": 4798.56, "end": 4807.4400000000005, "text": " interesting points or arrived at interesting pointers. You saw some images that I presented", "tokens": [50364, 1880, 2793, 420, 6678, 412, 1880, 44548, 13, 509, 1866, 512, 5267, 300, 286, 8212, 50808], "temperature": 0.0, "avg_logprob": -0.10998360078726242, "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.002754978137090802}, {"id": 793, "seek": 479856, "start": 4807.4400000000005, "end": 4815.52, "text": " earlier, for instance, the generative art of glide and the text that GPT-3 is producing. And in some", "tokens": [50808, 3071, 11, 337, 5197, 11, 264, 1337, 1166, 1523, 295, 41848, 293, 264, 2487, 300, 26039, 51, 12, 18, 307, 10501, 13, 400, 294, 512, 51212], "temperature": 0.0, "avg_logprob": -0.10998360078726242, "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.002754978137090802}, {"id": 794, "seek": 479856, "start": 4815.52, "end": 4822.240000000001, "text": " sense, this is the state of current computational creativity. And I think that the problem of how", "tokens": [51212, 2020, 11, 341, 307, 264, 1785, 295, 2190, 28270, 12915, 13, 400, 286, 519, 300, 264, 1154, 295, 577, 51548], "temperature": 0.0, "avg_logprob": -0.10998360078726242, "compression_ratio": 1.5508021390374331, "no_speech_prob": 0.002754978137090802}, {"id": 795, "seek": 482224, "start": 4822.24, "end": 4828.719999999999, "text": " to make a technological system creative is solved. So they, these images are in some sense creative", "tokens": [50364, 281, 652, 257, 18439, 1185, 5880, 307, 13041, 13, 407, 436, 11, 613, 5267, 366, 294, 512, 2020, 5880, 50688], "temperature": 0.0, "avg_logprob": -0.12154623440333776, "compression_ratio": 1.7737226277372262, "no_speech_prob": 0.004826472140848637}, {"id": 796, "seek": 482224, "start": 4828.719999999999, "end": 4835.2, "text": " solutions, because they are able to bridge certain discontinuities in a certain space by finding", "tokens": [50688, 6547, 11, 570, 436, 366, 1075, 281, 7283, 1629, 31420, 84, 1088, 294, 257, 1629, 1901, 538, 5006, 51012], "temperature": 0.0, "avg_logprob": -0.12154623440333776, "compression_ratio": 1.7737226277372262, "no_speech_prob": 0.004826472140848637}, {"id": 797, "seek": 482224, "start": 4835.2, "end": 4840.48, "text": " solutions that people might have difficulty to find. So, for instance, if you have a conversation", "tokens": [51012, 6547, 300, 561, 1062, 362, 10360, 281, 915, 13, 407, 11, 337, 5197, 11, 498, 291, 362, 257, 3761, 51276], "temperature": 0.0, "avg_logprob": -0.12154623440333776, "compression_ratio": 1.7737226277372262, "no_speech_prob": 0.004826472140848637}, {"id": 798, "seek": 482224, "start": 4840.48, "end": 4846.96, "text": " with GPT-3, it's usually better than what you get from a person that doesn't know the domain,", "tokens": [51276, 365, 26039, 51, 12, 18, 11, 309, 311, 2673, 1101, 813, 437, 291, 483, 490, 257, 954, 300, 1177, 380, 458, 264, 9274, 11, 51600], "temperature": 0.0, "avg_logprob": -0.12154623440333776, "compression_ratio": 1.7737226277372262, "no_speech_prob": 0.004826472140848637}, {"id": 799, "seek": 482224, "start": 4846.96, "end": 4850.96, "text": " but worse than the person that knows the domain. Well, for instance, you have a conversation with", "tokens": [51600, 457, 5324, 813, 264, 954, 300, 3255, 264, 9274, 13, 1042, 11, 337, 5197, 11, 291, 362, 257, 3761, 365, 51800], "temperature": 0.0, "avg_logprob": -0.12154623440333776, "compression_ratio": 1.7737226277372262, "no_speech_prob": 0.004826472140848637}, {"id": 800, "seek": 485096, "start": 4850.96, "end": 4856.0, "text": " Hannah Arendt. And if you haven't read a lot of Hannah Arendt, it's really surprising and very", "tokens": [50364, 21754, 2014, 273, 83, 13, 400, 498, 291, 2378, 380, 1401, 257, 688, 295, 21754, 2014, 273, 83, 11, 309, 311, 534, 8830, 293, 588, 50616], "temperature": 0.0, "avg_logprob": -0.09473322978061913, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.0033206776715815067}, {"id": 801, "seek": 485096, "start": 4856.0, "end": 4860.4, "text": " convincing. But if you're very familiar with Hannah Arendt and have thought about her a lot,", "tokens": [50616, 24823, 13, 583, 498, 291, 434, 588, 4963, 365, 21754, 2014, 273, 83, 293, 362, 1194, 466, 720, 257, 688, 11, 50836], "temperature": 0.0, "avg_logprob": -0.09473322978061913, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.0033206776715815067}, {"id": 802, "seek": 485096, "start": 4861.04, "end": 4864.32, "text": " then you might notice some things that you probably wouldn't have said.", "tokens": [50868, 550, 291, 1062, 3449, 512, 721, 300, 291, 1391, 2759, 380, 362, 848, 13, 51032], "temperature": 0.0, "avg_logprob": -0.09473322978061913, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.0033206776715815067}, {"id": 803, "seek": 485096, "start": 4865.28, "end": 4872.4800000000005, "text": " And a similar thing is with our depictions of art and so on. So it's able to produce", "tokens": [51080, 400, 257, 2531, 551, 307, 365, 527, 1367, 15607, 295, 1523, 293, 370, 322, 13, 407, 309, 311, 1075, 281, 5258, 51440], "temperature": 0.0, "avg_logprob": -0.09473322978061913, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.0033206776715815067}, {"id": 804, "seek": 485096, "start": 4872.4800000000005, "end": 4878.72, "text": " certain styles and reproduce them. But there is a certain thing that is missing. And I think that", "tokens": [51440, 1629, 13273, 293, 29501, 552, 13, 583, 456, 307, 257, 1629, 551, 300, 307, 5361, 13, 400, 286, 519, 300, 51752], "temperature": 0.0, "avg_logprob": -0.09473322978061913, "compression_ratio": 1.7609561752988048, "no_speech_prob": 0.0033206776715815067}, {"id": 805, "seek": 487872, "start": 4878.72, "end": 4885.12, "text": " what GPT-3 cannot do yet, and the systems cannot do yet, is art. And the difference between art and", "tokens": [50364, 437, 26039, 51, 12, 18, 2644, 360, 1939, 11, 293, 264, 3652, 2644, 360, 1939, 11, 307, 1523, 13, 400, 264, 2649, 1296, 1523, 293, 50684], "temperature": 0.0, "avg_logprob": -0.09065572508088834, "compression_ratio": 1.8341463414634147, "no_speech_prob": 0.0006360029219649732}, {"id": 806, "seek": 487872, "start": 4885.12, "end": 4892.8, "text": " creativity is subtle. Art, I think, is the capturing of conscious states, of a conscious", "tokens": [50684, 12915, 307, 13743, 13, 5735, 11, 286, 519, 11, 307, 264, 23384, 295, 6648, 4368, 11, 295, 257, 6648, 51068], "temperature": 0.0, "avg_logprob": -0.09065572508088834, "compression_ratio": 1.8341463414634147, "no_speech_prob": 0.0006360029219649732}, {"id": 807, "seek": 487872, "start": 4892.8, "end": 4901.04, "text": " reality, of some aspect of a conscious reality. And this means meaningful references to a unified", "tokens": [51068, 4103, 11, 295, 512, 4171, 295, 257, 6648, 4103, 13, 400, 341, 1355, 10995, 15400, 281, 257, 26787, 51480], "temperature": 0.0, "avg_logprob": -0.09065572508088834, "compression_ratio": 1.8341463414634147, "no_speech_prob": 0.0006360029219649732}, {"id": 808, "seek": 487872, "start": 4901.04, "end": 4908.240000000001, "text": " model of the universe. And these models do not have a unified models of the universe yet.", "tokens": [51480, 2316, 295, 264, 6445, 13, 400, 613, 5245, 360, 406, 362, 257, 26787, 5245, 295, 264, 6445, 1939, 13, 51840], "temperature": 0.0, "avg_logprob": -0.09065572508088834, "compression_ratio": 1.8341463414634147, "no_speech_prob": 0.0006360029219649732}, {"id": 809, "seek": 490824, "start": 4908.24, "end": 4911.84, "text": " They don't understand which universe they are part of or think that they are part of.", "tokens": [50364, 814, 500, 380, 1223, 597, 6445, 436, 366, 644, 295, 420, 519, 300, 436, 366, 644, 295, 13, 50544], "temperature": 0.0, "avg_logprob": -0.08222980813665705, "compression_ratio": 1.7268518518518519, "no_speech_prob": 0.0009244799148291349}, {"id": 810, "seek": 490824, "start": 4912.48, "end": 4917.76, "text": " And while they are slowly getting there, I don't think that they are there yet. So to me,", "tokens": [50576, 400, 1339, 436, 366, 5692, 1242, 456, 11, 286, 500, 380, 519, 300, 436, 366, 456, 1939, 13, 407, 281, 385, 11, 50840], "temperature": 0.0, "avg_logprob": -0.08222980813665705, "compression_ratio": 1.7268518518518519, "no_speech_prob": 0.0009244799148291349}, {"id": 811, "seek": 490824, "start": 4918.5599999999995, "end": 4924.16, "text": " the digital art that you're seeing is not actually art, because it does not mean very much to the", "tokens": [50880, 264, 4562, 1523, 300, 291, 434, 2577, 307, 406, 767, 1523, 11, 570, 309, 775, 406, 914, 588, 709, 281, 264, 51160], "temperature": 0.0, "avg_logprob": -0.08222980813665705, "compression_ratio": 1.7268518518518519, "no_speech_prob": 0.0009244799148291349}, {"id": 812, "seek": 490824, "start": 4924.16, "end": 4931.76, "text": " system. But it's something that humans can, at this point, relate to their shared reality sometimes", "tokens": [51160, 1185, 13, 583, 309, 311, 746, 300, 6255, 393, 11, 412, 341, 935, 11, 10961, 281, 641, 5507, 4103, 2171, 51540], "temperature": 0.0, "avg_logprob": -0.08222980813665705, "compression_ratio": 1.7268518518518519, "no_speech_prob": 0.0009244799148291349}, {"id": 813, "seek": 493176, "start": 4931.76, "end": 4938.64, "text": " and onto their inner reality. And this makes them akin to art. And there is basically a", "tokens": [50364, 293, 3911, 641, 7284, 4103, 13, 400, 341, 1669, 552, 47540, 281, 1523, 13, 400, 456, 307, 1936, 257, 50708], "temperature": 0.0, "avg_logprob": -0.09876400442684398, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.0017262168694287539}, {"id": 814, "seek": 493176, "start": 4938.64, "end": 4944.64, "text": " porous boundary that is more and more dissolving in terms of AI and art in these days.", "tokens": [50708, 1515, 563, 12866, 300, 307, 544, 293, 544, 15840, 798, 294, 2115, 295, 7318, 293, 1523, 294, 613, 1708, 13, 51008], "temperature": 0.0, "avg_logprob": -0.09876400442684398, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.0017262168694287539}, {"id": 815, "seek": 493176, "start": 4947.2, "end": 4954.8, "text": " So I don't think that there are fundamental unsolved problems at this point. But the biggest", "tokens": [51136, 407, 286, 500, 380, 519, 300, 456, 366, 8088, 2693, 29110, 2740, 412, 341, 935, 13, 583, 264, 3880, 51516], "temperature": 0.0, "avg_logprob": -0.09876400442684398, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.0017262168694287539}, {"id": 816, "seek": 493176, "start": 4954.8, "end": 4959.6, "text": " important problem is how to get a system that is able to track reality in real time", "tokens": [51516, 1021, 1154, 307, 577, 281, 483, 257, 1185, 300, 307, 1075, 281, 2837, 4103, 294, 957, 565, 51756], "temperature": 0.0, "avg_logprob": -0.09876400442684398, "compression_ratio": 1.647887323943662, "no_speech_prob": 0.0017262168694287539}, {"id": 817, "seek": 495960, "start": 4959.6, "end": 4963.84, "text": " and that can online learning. And a lot of people are working on this and we don't know", "tokens": [50364, 293, 300, 393, 2950, 2539, 13, 400, 257, 688, 295, 561, 366, 1364, 322, 341, 293, 321, 500, 380, 458, 50576], "temperature": 0.0, "avg_logprob": -0.20474031236436632, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.004422326106578112}, {"id": 818, "seek": 495960, "start": 4963.84, "end": 4967.84, "text": " how long it'll take to solve it. But it's not that it's a principle unsolvable.", "tokens": [50576, 577, 938, 309, 603, 747, 281, 5039, 309, 13, 583, 309, 311, 406, 300, 309, 311, 257, 8665, 2693, 401, 17915, 13, 50776], "temperature": 0.0, "avg_logprob": -0.20474031236436632, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.004422326106578112}, {"id": 819, "seek": 495960, "start": 4969.6, "end": 4973.280000000001, "text": " Can I just pick up on that, the question of art, because I think the back of my mind,", "tokens": [50864, 1664, 286, 445, 1888, 493, 322, 300, 11, 264, 1168, 295, 1523, 11, 570, 286, 519, 264, 646, 295, 452, 1575, 11, 51048], "temperature": 0.0, "avg_logprob": -0.20474031236436632, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.004422326106578112}, {"id": 820, "seek": 495960, "start": 4973.280000000001, "end": 4979.84, "text": " there's an interesting kind of question coming up here in terms of, well, let me just throw out", "tokens": [51048, 456, 311, 364, 1880, 733, 295, 1168, 1348, 493, 510, 294, 2115, 295, 11, 731, 11, 718, 385, 445, 3507, 484, 51376], "temperature": 0.0, "avg_logprob": -0.20474031236436632, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.004422326106578112}, {"id": 821, "seek": 495960, "start": 4979.84, "end": 4984.88, "text": " to you an idea, because you used the conductor metaphor and the music was part of the discourse.", "tokens": [51376, 281, 291, 364, 1558, 11, 570, 291, 1143, 264, 29957, 19157, 293, 264, 1318, 390, 644, 295, 264, 23938, 13, 51628], "temperature": 0.0, "avg_logprob": -0.20474031236436632, "compression_ratio": 1.6766917293233083, "no_speech_prob": 0.004422326106578112}, {"id": 822, "seek": 498488, "start": 4984.88, "end": 4993.2, "text": " And I often speculated whether how creative we are as architects or indeed how artists are", "tokens": [50364, 400, 286, 2049, 1608, 6987, 1968, 577, 5880, 321, 366, 382, 30491, 420, 6451, 577, 6910, 366, 50780], "temperature": 0.0, "avg_logprob": -0.14175695016843462, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.003906460013240576}, {"id": 823, "seek": 498488, "start": 4993.2, "end": 4997.92, "text": " in the sense that there is a canon, there is a canon of architecture or art or whatever it was.", "tokens": [50780, 294, 264, 2020, 300, 456, 307, 257, 21985, 11, 456, 307, 257, 21985, 295, 9482, 420, 1523, 420, 2035, 309, 390, 13, 51016], "temperature": 0.0, "avg_logprob": -0.14175695016843462, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.003906460013240576}, {"id": 824, "seek": 498488, "start": 4997.92, "end": 5002.32, "text": " And what we do is normally keeping broadly within that canon, you're very much aware of what other", "tokens": [51016, 400, 437, 321, 360, 307, 5646, 5145, 19511, 1951, 300, 21985, 11, 291, 434, 588, 709, 3650, 295, 437, 661, 51236], "temperature": 0.0, "avg_logprob": -0.14175695016843462, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.003906460013240576}, {"id": 825, "seek": 498488, "start": 5002.32, "end": 5006.4800000000005, "text": " people have done. You might push the boundary slightly. And this is kind of what I think,", "tokens": [51236, 561, 362, 1096, 13, 509, 1062, 2944, 264, 12866, 4748, 13, 400, 341, 307, 733, 295, 437, 286, 519, 11, 51444], "temperature": 0.0, "avg_logprob": -0.14175695016843462, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.003906460013240576}, {"id": 826, "seek": 498488, "start": 5007.36, "end": 5011.84, "text": " I use the term jazz as a kind of idea of understanding how we operate as a background", "tokens": [51488, 286, 764, 264, 1433, 15066, 382, 257, 733, 295, 1558, 295, 3701, 577, 321, 9651, 382, 257, 3678, 51712], "temperature": 0.0, "avg_logprob": -0.14175695016843462, "compression_ratio": 1.7265917602996255, "no_speech_prob": 0.003906460013240576}, {"id": 827, "seek": 501184, "start": 5011.84, "end": 5016.32, "text": " condition. And we're feeding off it and just nudging the boundaries, but staying recognizably", "tokens": [50364, 4188, 13, 400, 321, 434, 12919, 766, 309, 293, 445, 40045, 3249, 264, 13180, 11, 457, 7939, 3068, 590, 1188, 50588], "temperature": 0.0, "avg_logprob": -0.17511491295245055, "compression_ratio": 1.79672131147541, "no_speech_prob": 0.00946207344532013}, {"id": 828, "seek": 501184, "start": 5016.32, "end": 5020.0, "text": " within the canon of this. And it's interesting that, I don't know if you know the work of", "tokens": [50588, 1951, 264, 21985, 295, 341, 13, 400, 309, 311, 1880, 300, 11, 286, 500, 380, 458, 498, 291, 458, 264, 589, 295, 50772], "temperature": 0.0, "avg_logprob": -0.17511491295245055, "compression_ratio": 1.79672131147541, "no_speech_prob": 0.00946207344532013}, {"id": 829, "seek": 501184, "start": 5020.0, "end": 5027.92, "text": " Ahmed Agamal, the guy who created these, who designed creative gans that he's a computer", "tokens": [50772, 39189, 2725, 335, 304, 11, 264, 2146, 567, 2942, 613, 11, 567, 4761, 5880, 290, 599, 300, 415, 311, 257, 3820, 51168], "temperature": 0.0, "avg_logprob": -0.17511491295245055, "compression_ratio": 1.79672131147541, "no_speech_prob": 0.00946207344532013}, {"id": 830, "seek": 501184, "start": 5027.92, "end": 5033.04, "text": " scientist who has a, who generates art. And the logic is this, you've got to keep broadly within", "tokens": [51168, 12662, 567, 575, 257, 11, 567, 23815, 1523, 13, 400, 264, 9952, 307, 341, 11, 291, 600, 658, 281, 1066, 19511, 1951, 51424], "temperature": 0.0, "avg_logprob": -0.17511491295245055, "compression_ratio": 1.79672131147541, "no_speech_prob": 0.00946207344532013}, {"id": 831, "seek": 501184, "start": 5033.04, "end": 5037.52, "text": " the framework of what you're talking about within the canon of, let's say, modernist art,", "tokens": [51424, 264, 8388, 295, 437, 291, 434, 1417, 466, 1951, 264, 21985, 295, 11, 718, 311, 584, 11, 4363, 468, 1523, 11, 51648], "temperature": 0.0, "avg_logprob": -0.17511491295245055, "compression_ratio": 1.79672131147541, "no_speech_prob": 0.00946207344532013}, {"id": 832, "seek": 501184, "start": 5037.52, "end": 5041.52, "text": " but make it slightly different. So you're just pushing the boundaries. So I know I often", "tokens": [51648, 457, 652, 309, 4748, 819, 13, 407, 291, 434, 445, 7380, 264, 13180, 13, 407, 286, 458, 286, 2049, 51848], "temperature": 0.0, "avg_logprob": -0.17511491295245055, "compression_ratio": 1.79672131147541, "no_speech_prob": 0.00946207344532013}, {"id": 833, "seek": 504152, "start": 5041.52, "end": 5048.72, "text": " wonder to what extent we're so conditioned by what has been done before. And whether we,", "tokens": [50364, 2441, 281, 437, 8396, 321, 434, 370, 35833, 538, 437, 575, 668, 1096, 949, 13, 400, 1968, 321, 11, 50724], "temperature": 0.0, "avg_logprob": -0.11800293440229437, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0006431913934648037}, {"id": 834, "seek": 504152, "start": 5048.72, "end": 5053.4400000000005, "text": " if you would do something genuinely different, you'll be outside the realm of what is acceptable", "tokens": [50724, 498, 291, 576, 360, 746, 17839, 819, 11, 291, 603, 312, 2380, 264, 15355, 295, 437, 307, 15513, 50960], "temperature": 0.0, "avg_logprob": -0.11800293440229437, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0006431913934648037}, {"id": 835, "seek": 504152, "start": 5053.4400000000005, "end": 5062.0, "text": " within that genre. I would make a difference distinction between art and design. And architecture", "tokens": [50960, 1951, 300, 11022, 13, 286, 576, 652, 257, 2649, 16844, 1296, 1523, 293, 1715, 13, 400, 9482, 51388], "temperature": 0.0, "avg_logprob": -0.11800293440229437, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0006431913934648037}, {"id": 836, "seek": 504152, "start": 5062.0, "end": 5068.080000000001, "text": " for the most part is not art, but design. It's also true for myself. I'm for the most part not", "tokens": [51388, 337, 264, 881, 644, 307, 406, 1523, 11, 457, 1715, 13, 467, 311, 611, 2074, 337, 2059, 13, 286, 478, 337, 264, 881, 644, 406, 51692], "temperature": 0.0, "avg_logprob": -0.11800293440229437, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0006431913934648037}, {"id": 837, "seek": 506808, "start": 5068.08, "end": 5074.64, "text": " an artist, but a designer. And design is instrumental to something. Whereas art is", "tokens": [50364, 364, 5748, 11, 457, 257, 11795, 13, 400, 1715, 307, 17388, 281, 746, 13, 13813, 1523, 307, 50692], "temperature": 0.0, "avg_logprob": -0.11627097268706386, "compression_ratio": 1.891566265060241, "no_speech_prob": 0.00432401429861784}, {"id": 838, "seek": 506808, "start": 5074.64, "end": 5079.84, "text": " instrumental to consciousness only, I think, at least the aspects of the thing that you're producing", "tokens": [50692, 17388, 281, 10081, 787, 11, 286, 519, 11, 412, 1935, 264, 7270, 295, 264, 551, 300, 291, 434, 10501, 50952], "temperature": 0.0, "avg_logprob": -0.11627097268706386, "compression_ratio": 1.891566265060241, "no_speech_prob": 0.00432401429861784}, {"id": 839, "seek": 506808, "start": 5079.84, "end": 5084.32, "text": " that are art, the other aspects and every artifact that you are producing, almost everyone,", "tokens": [50952, 300, 366, 1523, 11, 264, 661, 7270, 293, 633, 34806, 300, 291, 366, 10501, 11, 1920, 1518, 11, 51176], "temperature": 0.0, "avg_logprob": -0.11627097268706386, "compression_ratio": 1.891566265060241, "no_speech_prob": 0.00432401429861784}, {"id": 840, "seek": 506808, "start": 5085.28, "end": 5091.5199999999995, "text": " the design serves some other purpose than the consciousness itself. For instance, if you are", "tokens": [51224, 264, 1715, 13451, 512, 661, 4334, 813, 264, 10081, 2564, 13, 1171, 5197, 11, 498, 291, 366, 51536], "temperature": 0.0, "avg_logprob": -0.11627097268706386, "compression_ratio": 1.891566265060241, "no_speech_prob": 0.00432401429861784}, {"id": 841, "seek": 506808, "start": 5091.5199999999995, "end": 5097.28, "text": " designing a building, you are serving a function of a human being that needs to have a house somewhere", "tokens": [51536, 14685, 257, 2390, 11, 291, 366, 8148, 257, 2445, 295, 257, 1952, 885, 300, 2203, 281, 362, 257, 1782, 4079, 51824], "temperature": 0.0, "avg_logprob": -0.11627097268706386, "compression_ratio": 1.891566265060241, "no_speech_prob": 0.00432401429861784}, {"id": 842, "seek": 509728, "start": 5097.28, "end": 5101.44, "text": " that needs to live down somewhere, this thing needs to be part of an environment and it requires", "tokens": [50364, 300, 2203, 281, 1621, 760, 4079, 11, 341, 551, 2203, 281, 312, 644, 295, 364, 2823, 293, 309, 7029, 50572], "temperature": 0.0, "avg_logprob": -0.10832140078911415, "compression_ratio": 1.825278810408922, "no_speech_prob": 0.0009386922465637326}, {"id": 843, "seek": 509728, "start": 5101.44, "end": 5107.36, "text": " deep perception. And it does require capturing some of your observations and the deep level. So there", "tokens": [50572, 2452, 12860, 13, 400, 309, 775, 3651, 23384, 512, 295, 428, 18163, 293, 264, 2452, 1496, 13, 407, 456, 50868], "temperature": 0.0, "avg_logprob": -0.10832140078911415, "compression_ratio": 1.825278810408922, "no_speech_prob": 0.0009386922465637326}, {"id": 844, "seek": 509728, "start": 5107.36, "end": 5114.0, "text": " is important elements of seeing and perceiving and observing and reflection in architecture.", "tokens": [50868, 307, 1021, 4959, 295, 2577, 293, 9016, 2123, 293, 22107, 293, 12914, 294, 9482, 13, 51200], "temperature": 0.0, "avg_logprob": -0.10832140078911415, "compression_ratio": 1.825278810408922, "no_speech_prob": 0.0009386922465637326}, {"id": 845, "seek": 509728, "start": 5114.639999999999, "end": 5119.759999999999, "text": " But all these elements are ultimately instrumental to the thing that you're going to build. And the", "tokens": [51232, 583, 439, 613, 4959, 366, 6284, 17388, 281, 264, 551, 300, 291, 434, 516, 281, 1322, 13, 400, 264, 51488], "temperature": 0.0, "avg_logprob": -0.10832140078911415, "compression_ratio": 1.825278810408922, "no_speech_prob": 0.0009386922465637326}, {"id": 846, "seek": 509728, "start": 5119.759999999999, "end": 5125.92, "text": " thing that you're going to build is defined by its function. Maybe I could just throw something out", "tokens": [51488, 551, 300, 291, 434, 516, 281, 1322, 307, 7642, 538, 1080, 2445, 13, 2704, 286, 727, 445, 3507, 746, 484, 51796], "temperature": 0.0, "avg_logprob": -0.10832140078911415, "compression_ratio": 1.825278810408922, "no_speech_prob": 0.0009386922465637326}, {"id": 847, "seek": 512592, "start": 5125.92, "end": 5132.88, "text": " there. And let's say that could you not, as an architect, always think about these things. And I", "tokens": [50364, 456, 13, 400, 718, 311, 584, 300, 727, 291, 406, 11, 382, 364, 6331, 11, 1009, 519, 466, 613, 721, 13, 400, 286, 50712], "temperature": 0.0, "avg_logprob": -0.1651895667324547, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.007098934147506952}, {"id": 848, "seek": 512592, "start": 5132.88, "end": 5136.4, "text": " think almost there are two sides of, well, there are two sides of architecture, one's a functional", "tokens": [50712, 519, 1920, 456, 366, 732, 4881, 295, 11, 731, 11, 456, 366, 732, 4881, 295, 9482, 11, 472, 311, 257, 11745, 50888], "temperature": 0.0, "avg_logprob": -0.1651895667324547, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.007098934147506952}, {"id": 849, "seek": 512592, "start": 5136.4, "end": 5140.8, "text": " side of thing, or dealing with the logistics. If you're dealing, let's say, with a very", "tokens": [50888, 1252, 295, 551, 11, 420, 6260, 365, 264, 27420, 13, 759, 291, 434, 6260, 11, 718, 311, 584, 11, 365, 257, 588, 51108], "temperature": 0.0, "avg_logprob": -0.1651895667324547, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.007098934147506952}, {"id": 850, "seek": 512592, "start": 5142.4800000000005, "end": 5147.12, "text": " complex urban condition, you need to fit a building in somewhere, it becomes almost like a kind of", "tokens": [51192, 3997, 9681, 4188, 11, 291, 643, 281, 3318, 257, 2390, 294, 4079, 11, 309, 3643, 1920, 411, 257, 733, 295, 51424], "temperature": 0.0, "avg_logprob": -0.1651895667324547, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.007098934147506952}, {"id": 851, "seek": 512592, "start": 5147.12, "end": 5151.4400000000005, "text": " simple search question of how do you find the best solution. And then there is this kind of, I", "tokens": [51424, 2199, 3164, 1168, 295, 577, 360, 291, 915, 264, 1151, 3827, 13, 400, 550, 456, 307, 341, 733, 295, 11, 286, 51640], "temperature": 0.0, "avg_logprob": -0.1651895667324547, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.007098934147506952}, {"id": 852, "seek": 515144, "start": 5151.44, "end": 5155.839999999999, "text": " wouldn't say a veneer, but there is an aesthetic side of things. So when it comes to, let's say,", "tokens": [50364, 2759, 380, 584, 257, 371, 1450, 260, 11, 457, 456, 307, 364, 20092, 1252, 295, 721, 13, 407, 562, 309, 1487, 281, 11, 718, 311, 584, 11, 50584], "temperature": 0.0, "avg_logprob": -0.09018279999259889, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.005400979891419411}, {"id": 853, "seek": 515144, "start": 5155.839999999999, "end": 5160.879999999999, "text": " the strategic planning of how you might fit a building in a site or how it might operate and so", "tokens": [50584, 264, 10924, 5038, 295, 577, 291, 1062, 3318, 257, 2390, 294, 257, 3621, 420, 577, 309, 1062, 9651, 293, 370, 50836], "temperature": 0.0, "avg_logprob": -0.09018279999259889, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.005400979891419411}, {"id": 854, "seek": 515144, "start": 5160.879999999999, "end": 5166.16, "text": " on, it kind of relates more to the kind of logical, let's say, of AlphaGo, the strategy of AlphaGo.", "tokens": [50836, 322, 11, 309, 733, 295, 16155, 544, 281, 264, 733, 295, 14978, 11, 718, 311, 584, 11, 295, 20588, 12104, 11, 264, 5206, 295, 20588, 12104, 13, 51100], "temperature": 0.0, "avg_logprob": -0.09018279999259889, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.005400979891419411}, {"id": 855, "seek": 515144, "start": 5166.16, "end": 5169.759999999999, "text": " And then there's something else that we, as architects, want to put on top of that, which is", "tokens": [51100, 400, 550, 456, 311, 746, 1646, 300, 321, 11, 382, 30491, 11, 528, 281, 829, 322, 1192, 295, 300, 11, 597, 307, 51280], "temperature": 0.0, "avg_logprob": -0.09018279999259889, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.005400979891419411}, {"id": 856, "seek": 515144, "start": 5169.759999999999, "end": 5176.16, "text": " more the kind of the artist dimension, which is giving it a certain aesthetic. Does that sound", "tokens": [51280, 544, 264, 733, 295, 264, 5748, 10139, 11, 597, 307, 2902, 309, 257, 1629, 20092, 13, 4402, 300, 1626, 51600], "temperature": 0.0, "avg_logprob": -0.09018279999259889, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.005400979891419411}, {"id": 857, "seek": 517616, "start": 5176.5599999999995, "end": 5181.36, "text": " to make sense to you, that logic? Yes, it does. But there's, of course, the practical element", "tokens": [50384, 281, 652, 2020, 281, 291, 11, 300, 9952, 30, 1079, 11, 309, 775, 13, 583, 456, 311, 11, 295, 1164, 11, 264, 8496, 4478, 50624], "temperature": 0.0, "avg_logprob": -0.1462666780045889, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0016704828012734652}, {"id": 858, "seek": 517616, "start": 5181.36, "end": 5188.24, "text": " that the aesthetic that the architect has when it's a successful one is a brand. And it's not", "tokens": [50624, 300, 264, 20092, 300, 264, 6331, 575, 562, 309, 311, 257, 4406, 472, 307, 257, 3360, 13, 400, 309, 311, 406, 50968], "temperature": 0.0, "avg_logprob": -0.1462666780045889, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0016704828012734652}, {"id": 859, "seek": 517616, "start": 5188.8, "end": 5195.04, "text": " driven by a free exploration of the conscious states of the architect for the most part, but", "tokens": [50996, 9555, 538, 257, 1737, 16197, 295, 264, 6648, 4368, 295, 264, 6331, 337, 264, 881, 644, 11, 457, 51308], "temperature": 0.0, "avg_logprob": -0.1462666780045889, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0016704828012734652}, {"id": 860, "seek": 517616, "start": 5195.04, "end": 5200.639999999999, "text": " it's driven by the anticipation of reward in a particular economic and cultural domain.", "tokens": [51308, 309, 311, 9555, 538, 264, 35979, 295, 7782, 294, 257, 1729, 4836, 293, 6988, 9274, 13, 51588], "temperature": 0.0, "avg_logprob": -0.1462666780045889, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0016704828012734652}, {"id": 861, "seek": 517616, "start": 5201.68, "end": 5204.24, "text": " And so in a sense, it's usually a construction process.", "tokens": [51640, 400, 370, 294, 257, 2020, 11, 309, 311, 2673, 257, 6435, 1399, 13, 51768], "temperature": 0.0, "avg_logprob": -0.1462666780045889, "compression_ratio": 1.7165991902834008, "no_speech_prob": 0.0016704828012734652}, {"id": 862, "seek": 520616, "start": 5206.8, "end": 5212.639999999999, "text": " Let me throw out another kind of thought then. I mean, what is interesting is when you get someone", "tokens": [50396, 961, 385, 3507, 484, 1071, 733, 295, 1194, 550, 13, 286, 914, 11, 437, 307, 1880, 307, 562, 291, 483, 1580, 50688], "temperature": 0.0, "avg_logprob": -0.15122032165527344, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.002170613966882229}, {"id": 863, "seek": 520616, "start": 5212.639999999999, "end": 5217.44, "text": " who's fairly radical, like, I don't know, Frank Gehry, for example, he produces a building,", "tokens": [50688, 567, 311, 6457, 12001, 11, 411, 11, 286, 500, 380, 458, 11, 6823, 2876, 71, 627, 11, 337, 1365, 11, 415, 14725, 257, 2390, 11, 50928], "temperature": 0.0, "avg_logprob": -0.15122032165527344, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.002170613966882229}, {"id": 864, "seek": 520616, "start": 5217.44, "end": 5221.36, "text": " the Guggenheim and Bilbao, really changed architecture, but then he kind of repeats", "tokens": [50928, 264, 460, 697, 1766, 18673, 293, 22879, 4231, 78, 11, 534, 3105, 9482, 11, 457, 550, 415, 733, 295, 35038, 51124], "temperature": 0.0, "avg_logprob": -0.15122032165527344, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.002170613966882229}, {"id": 865, "seek": 520616, "start": 5221.36, "end": 5225.599999999999, "text": " himself in some senses. He's doing similar versions of that, and you must have seen the LA,", "tokens": [51124, 3647, 294, 512, 17057, 13, 634, 311, 884, 2531, 9606, 295, 300, 11, 293, 291, 1633, 362, 1612, 264, 9855, 11, 51336], "temperature": 0.0, "avg_logprob": -0.15122032165527344, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.002170613966882229}, {"id": 866, "seek": 520616, "start": 5225.599999999999, "end": 5235.2, "text": " the Philharmonic in LA, the Walt Disney concert hall. And it's almost like we have these patterns", "tokens": [51336, 264, 7777, 5854, 3317, 299, 294, 9855, 11, 264, 28260, 8653, 8543, 6500, 13, 400, 309, 311, 1920, 411, 321, 362, 613, 8294, 51816], "temperature": 0.0, "avg_logprob": -0.15122032165527344, "compression_ratio": 1.5466666666666666, "no_speech_prob": 0.002170613966882229}, {"id": 867, "seek": 523520, "start": 5235.28, "end": 5242.0, "text": " of behavior or signatures, I would say, that are recognizable. And now you see a Gehry building,", "tokens": [50368, 295, 5223, 420, 32322, 11, 286, 576, 584, 11, 300, 366, 40757, 13, 400, 586, 291, 536, 257, 2876, 71, 627, 2390, 11, 50704], "temperature": 0.0, "avg_logprob": -0.10996769714355469, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.017090467736124992}, {"id": 868, "seek": 523520, "start": 5242.0, "end": 5246.96, "text": " you say, that's Gehry. So it's almost like we're pieces on a chess board, and we have certain", "tokens": [50704, 291, 584, 11, 300, 311, 2876, 71, 627, 13, 407, 309, 311, 1920, 411, 321, 434, 3755, 322, 257, 24122, 3150, 11, 293, 321, 362, 1629, 50952], "temperature": 0.0, "avg_logprob": -0.10996769714355469, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.017090467736124992}, {"id": 869, "seek": 523520, "start": 5246.96, "end": 5251.84, "text": " conditions, and we actually are constrained by that. So whether you see it as a brand or not,", "tokens": [50952, 4487, 11, 293, 321, 767, 366, 38901, 538, 300, 13, 407, 1968, 291, 536, 309, 382, 257, 3360, 420, 406, 11, 51196], "temperature": 0.0, "avg_logprob": -0.10996769714355469, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.017090467736124992}, {"id": 870, "seek": 523520, "start": 5251.84, "end": 5257.36, "text": " but it could be seen as a brand, we are constrained by our own signatures. And in fact, we end up", "tokens": [51196, 457, 309, 727, 312, 1612, 382, 257, 3360, 11, 321, 366, 38901, 538, 527, 1065, 32322, 13, 400, 294, 1186, 11, 321, 917, 493, 51472], "temperature": 0.0, "avg_logprob": -0.10996769714355469, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.017090467736124992}, {"id": 871, "seek": 523520, "start": 5257.36, "end": 5263.12, "text": " not being so creative because we fit in with that logic. How does that sound to you?", "tokens": [51472, 406, 885, 370, 5880, 570, 321, 3318, 294, 365, 300, 9952, 13, 1012, 775, 300, 1626, 281, 291, 30, 51760], "temperature": 0.0, "avg_logprob": -0.10996769714355469, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.017090467736124992}, {"id": 872, "seek": 526312, "start": 5263.12, "end": 5268.4, "text": " Ultimately, it's about intention. And the intention is either the submission to an", "tokens": [50364, 23921, 11, 309, 311, 466, 7789, 13, 400, 264, 7789, 307, 2139, 264, 23689, 281, 364, 50628], "temperature": 0.0, "avg_logprob": -0.1288655673756319, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.0016719449777156115}, {"id": 873, "seek": 526312, "start": 5268.4, "end": 5276.4, "text": " external cultural mind, or the intention is an autonomous one. And I personally see art as", "tokens": [50628, 8320, 6988, 1575, 11, 420, 264, 7789, 307, 364, 23797, 472, 13, 400, 286, 5665, 536, 1523, 382, 51028], "temperature": 0.0, "avg_logprob": -0.1288655673756319, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.0016719449777156115}, {"id": 874, "seek": 526312, "start": 5276.4, "end": 5281.92, "text": " something that is driven autonomously, and that's different from the definition of the art market.", "tokens": [51028, 746, 300, 307, 9555, 18203, 5098, 11, 293, 300, 311, 819, 490, 264, 7123, 295, 264, 1523, 2142, 13, 51304], "temperature": 0.0, "avg_logprob": -0.1288655673756319, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.0016719449777156115}, {"id": 875, "seek": 526312, "start": 5283.36, "end": 5289.36, "text": " So the art market is only capturing a very small part of the arts. And a lot of the things that", "tokens": [51376, 407, 264, 1523, 2142, 307, 787, 23384, 257, 588, 1359, 644, 295, 264, 8609, 13, 400, 257, 688, 295, 264, 721, 300, 51676], "temperature": 0.0, "avg_logprob": -0.1288655673756319, "compression_ratio": 1.7864077669902914, "no_speech_prob": 0.0016719449777156115}, {"id": 876, "seek": 528936, "start": 5289.36, "end": 5296.639999999999, "text": " are happening on the art market are not art. And my own father is an architect who has defected", "tokens": [50364, 366, 2737, 322, 264, 1523, 2142, 366, 406, 1523, 13, 400, 452, 1065, 3086, 307, 364, 6331, 567, 575, 16445, 292, 50728], "temperature": 0.0, "avg_logprob": -0.11335596171292392, "compression_ratio": 1.898477157360406, "no_speech_prob": 0.00077847606735304}, {"id": 877, "seek": 528936, "start": 5296.639999999999, "end": 5303.92, "text": " from architecture and become an artist. So I am a child of an artist family. And my wife is an", "tokens": [50728, 490, 9482, 293, 1813, 364, 5748, 13, 407, 286, 669, 257, 1440, 295, 364, 5748, 1605, 13, 400, 452, 3836, 307, 364, 51092], "temperature": 0.0, "avg_logprob": -0.11335596171292392, "compression_ratio": 1.898477157360406, "no_speech_prob": 0.00077847606735304}, {"id": 878, "seek": 528936, "start": 5303.92, "end": 5310.5599999999995, "text": " artist. And the difference between the art that my father is doing and the architecture that he", "tokens": [51092, 5748, 13, 400, 264, 2649, 1296, 264, 1523, 300, 452, 3086, 307, 884, 293, 264, 9482, 300, 415, 51424], "temperature": 0.0, "avg_logprob": -0.11335596171292392, "compression_ratio": 1.898477157360406, "no_speech_prob": 0.00077847606735304}, {"id": 879, "seek": 528936, "start": 5310.5599999999995, "end": 5317.679999999999, "text": " has been doing is that the architecture is serving others in a particular role for in a", "tokens": [51424, 575, 668, 884, 307, 300, 264, 9482, 307, 8148, 2357, 294, 257, 1729, 3090, 337, 294, 257, 51780], "temperature": 0.0, "avg_logprob": -0.11335596171292392, "compression_ratio": 1.898477157360406, "no_speech_prob": 0.00077847606735304}, {"id": 880, "seek": 531768, "start": 5317.76, "end": 5324.400000000001, "text": " particular cultural context and economic and social and societal context. And my father didn't", "tokens": [50368, 1729, 6988, 4319, 293, 4836, 293, 2093, 293, 33472, 4319, 13, 400, 452, 3086, 994, 380, 50700], "temperature": 0.0, "avg_logprob": -0.1077157640920102, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.002111115027219057}, {"id": 881, "seek": 531768, "start": 5324.400000000001, "end": 5329.92, "text": " want to submit to this societal context and this psychological and social context because he thought", "tokens": [50700, 528, 281, 10315, 281, 341, 33472, 4319, 293, 341, 14346, 293, 2093, 4319, 570, 415, 1194, 50976], "temperature": 0.0, "avg_logprob": -0.1077157640920102, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.002111115027219057}, {"id": 882, "seek": 531768, "start": 5329.92, "end": 5335.280000000001, "text": " it was deeply unesthetic to him. We rejected the aesthetics of the society that he was in.", "tokens": [50976, 309, 390, 8760, 517, 377, 17151, 281, 796, 13, 492, 15749, 264, 35517, 295, 264, 4086, 300, 415, 390, 294, 13, 51244], "temperature": 0.0, "avg_logprob": -0.1077157640920102, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.002111115027219057}, {"id": 883, "seek": 531768, "start": 5335.280000000001, "end": 5340.96, "text": " So we removed himself from the society that he was in, bought a watermelon in the countryside", "tokens": [51244, 407, 321, 7261, 3647, 490, 264, 4086, 300, 415, 390, 294, 11, 4243, 257, 26097, 294, 264, 28252, 51528], "temperature": 0.0, "avg_logprob": -0.1077157640920102, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.002111115027219057}, {"id": 884, "seek": 531768, "start": 5340.96, "end": 5347.200000000001, "text": " and turned this into his own kingdom. And this kingdom is open for others to visit and explore.", "tokens": [51528, 293, 3574, 341, 666, 702, 1065, 10231, 13, 400, 341, 10231, 307, 1269, 337, 2357, 281, 3441, 293, 6839, 13, 51840], "temperature": 0.0, "avg_logprob": -0.1077157640920102, "compression_ratio": 1.874015748031496, "no_speech_prob": 0.002111115027219057}, {"id": 885, "seek": 534720, "start": 5347.2, "end": 5352.96, "text": " But it's not done for them. It's done for itself. It's done in the service of his own aesthetics.", "tokens": [50364, 583, 309, 311, 406, 1096, 337, 552, 13, 467, 311, 1096, 337, 2564, 13, 467, 311, 1096, 294, 264, 2643, 295, 702, 1065, 35517, 13, 50652], "temperature": 0.0, "avg_logprob": -0.0667206970686765, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0014742609346285462}, {"id": 886, "seek": 534720, "start": 5353.92, "end": 5360.32, "text": " And to him, it doesn't really matter whether others like these aesthetics. This doesn't change", "tokens": [50700, 400, 281, 796, 11, 309, 1177, 380, 534, 1871, 1968, 2357, 411, 613, 35517, 13, 639, 1177, 380, 1319, 51020], "temperature": 0.0, "avg_logprob": -0.0667206970686765, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0014742609346285462}, {"id": 887, "seek": 534720, "start": 5360.32, "end": 5366.48, "text": " how he thinks about the things that he's creating himself. He may need economic success to be able", "tokens": [51020, 577, 415, 7309, 466, 264, 721, 300, 415, 311, 4084, 3647, 13, 634, 815, 643, 4836, 2245, 281, 312, 1075, 51328], "temperature": 0.0, "avg_logprob": -0.0667206970686765, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0014742609346285462}, {"id": 888, "seek": 534720, "start": 5366.48, "end": 5372.0, "text": " to survive and it might frustrate him if people don't like what he's doing. And it might frustrate", "tokens": [51328, 281, 7867, 293, 309, 1062, 7454, 4404, 796, 498, 561, 500, 380, 411, 437, 415, 311, 884, 13, 400, 309, 1062, 7454, 4404, 51604], "temperature": 0.0, "avg_logprob": -0.0667206970686765, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.0014742609346285462}, {"id": 889, "seek": 537200, "start": 5372.0, "end": 5377.36, "text": " him the things that he might have to do to survive. But his own definition is that he is not", "tokens": [50364, 796, 264, 721, 300, 415, 1062, 362, 281, 360, 281, 7867, 13, 583, 702, 1065, 7123, 307, 300, 415, 307, 406, 50632], "temperature": 0.0, "avg_logprob": -0.15837618412862298, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.003108454868197441}, {"id": 890, "seek": 537200, "start": 5378.0, "end": 5382.24, "text": " for himself, of his own intention, that he is not serving an external aesthetics.", "tokens": [50664, 337, 3647, 11, 295, 702, 1065, 7789, 11, 300, 415, 307, 406, 8148, 364, 8320, 35517, 13, 50876], "temperature": 0.0, "avg_logprob": -0.15837618412862298, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.003108454868197441}, {"id": 891, "seek": 537200, "start": 5382.8, "end": 5387.44, "text": " He is an autonomous agent. He is deeply autonomous. He is the creator of his own universe.", "tokens": [50904, 634, 307, 364, 23797, 9461, 13, 634, 307, 8760, 23797, 13, 634, 307, 264, 14181, 295, 702, 1065, 6445, 13, 51136], "temperature": 0.0, "avg_logprob": -0.15837618412862298, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.003108454868197441}, {"id": 892, "seek": 537200, "start": 5388.96, "end": 5393.36, "text": " No, it's a beautiful story that I've got a question coming in from Shamene in the chat.", "tokens": [51212, 883, 11, 309, 311, 257, 2238, 1657, 300, 286, 600, 658, 257, 1168, 1348, 294, 490, 42912, 1450, 294, 264, 5081, 13, 51432], "temperature": 0.0, "avg_logprob": -0.15837618412862298, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.003108454868197441}, {"id": 893, "seek": 537200, "start": 5393.36, "end": 5396.16, "text": " But can I ask you one quick question before we go on to that? And that's to say,", "tokens": [51432, 583, 393, 286, 1029, 291, 472, 1702, 1168, 949, 321, 352, 322, 281, 300, 30, 400, 300, 311, 281, 584, 11, 51572], "temperature": 0.0, "avg_logprob": -0.15837618412862298, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.003108454868197441}, {"id": 894, "seek": 537200, "start": 5396.96, "end": 5401.6, "text": " the term architecture gets used, obviously, both for computer science and for architecture itself.", "tokens": [51612, 264, 1433, 9482, 2170, 1143, 11, 2745, 11, 1293, 337, 3820, 3497, 293, 337, 9482, 2564, 13, 51844], "temperature": 0.0, "avg_logprob": -0.15837618412862298, "compression_ratio": 1.7766666666666666, "no_speech_prob": 0.003108454868197441}, {"id": 895, "seek": 540200, "start": 5402.8, "end": 5407.44, "text": " And I'm just wondering, I mean, I don't know, my definition of the architect is very broad. I", "tokens": [50404, 400, 286, 478, 445, 6359, 11, 286, 914, 11, 286, 500, 380, 458, 11, 452, 7123, 295, 264, 6331, 307, 588, 4152, 13, 286, 50636], "temperature": 0.0, "avg_logprob": -0.13202500132332862, "compression_ratio": 1.8202247191011236, "no_speech_prob": 0.001075430540367961}, {"id": 896, "seek": 540200, "start": 5407.44, "end": 5412.24, "text": " mean, I think it's a way of kind of, I would say that probably what your father is doing is probably", "tokens": [50636, 914, 11, 286, 519, 309, 311, 257, 636, 295, 733, 295, 11, 286, 576, 584, 300, 1391, 437, 428, 3086, 307, 884, 307, 1391, 50876], "temperature": 0.0, "avg_logprob": -0.13202500132332862, "compression_ratio": 1.8202247191011236, "no_speech_prob": 0.001075430540367961}, {"id": 897, "seek": 540200, "start": 5412.24, "end": 5416.72, "text": " still a form of architecture, maybe a form of other architecture. I mean, there are many creative", "tokens": [50876, 920, 257, 1254, 295, 9482, 11, 1310, 257, 1254, 295, 661, 9482, 13, 286, 914, 11, 456, 366, 867, 5880, 51100], "temperature": 0.0, "avg_logprob": -0.13202500132332862, "compression_ratio": 1.8202247191011236, "no_speech_prob": 0.001075430540367961}, {"id": 898, "seek": 540200, "start": 5416.72, "end": 5424.16, "text": " industries that architects go into, like the film industry or space industry, and they use that", "tokens": [51100, 13284, 300, 30491, 352, 666, 11, 411, 264, 2007, 3518, 420, 1901, 3518, 11, 293, 436, 764, 300, 51472], "temperature": 0.0, "avg_logprob": -0.13202500132332862, "compression_ratio": 1.8202247191011236, "no_speech_prob": 0.001075430540367961}, {"id": 899, "seek": 540200, "start": 5424.16, "end": 5430.64, "text": " architectural imagination elsewhere. And I even think that kind of setting up educational systems", "tokens": [51472, 26621, 12938, 14517, 13, 400, 286, 754, 519, 300, 733, 295, 3287, 493, 10189, 3652, 51796], "temperature": 0.0, "avg_logprob": -0.13202500132332862, "compression_ratio": 1.8202247191011236, "no_speech_prob": 0.001075430540367961}, {"id": 900, "seek": 543064, "start": 5430.64, "end": 5435.12, "text": " is a form of architecture in a way. And I just wonder whether you ever have seen any connection", "tokens": [50364, 307, 257, 1254, 295, 9482, 294, 257, 636, 13, 400, 286, 445, 2441, 1968, 291, 1562, 362, 1612, 604, 4984, 50588], "temperature": 0.0, "avg_logprob": -0.08595343469416053, "compression_ratio": 1.7234848484848484, "no_speech_prob": 0.0001939467911142856}, {"id": 901, "seek": 543064, "start": 5435.12, "end": 5438.96, "text": " between those two architectures, the one that you're familiar with or your father,", "tokens": [50588, 1296, 729, 732, 6331, 1303, 11, 264, 472, 300, 291, 434, 4963, 365, 420, 428, 3086, 11, 50780], "temperature": 0.0, "avg_logprob": -0.08595343469416053, "compression_ratio": 1.7234848484848484, "no_speech_prob": 0.0001939467911142856}, {"id": 902, "seek": 543064, "start": 5438.96, "end": 5442.160000000001, "text": " and the world in which you work right now, computer science, because I noticed the word", "tokens": [50780, 293, 264, 1002, 294, 597, 291, 589, 558, 586, 11, 3820, 3497, 11, 570, 286, 5694, 264, 1349, 50940], "temperature": 0.0, "avg_logprob": -0.08595343469416053, "compression_ratio": 1.7234848484848484, "no_speech_prob": 0.0001939467911142856}, {"id": 903, "seek": 543064, "start": 5442.160000000001, "end": 5448.320000000001, "text": " architecture is in the title or subtitle of your book. Yes. So the notion of a cognitive", "tokens": [50940, 9482, 307, 294, 264, 4876, 420, 30706, 306, 295, 428, 1446, 13, 1079, 13, 407, 264, 10710, 295, 257, 15605, 51248], "temperature": 0.0, "avg_logprob": -0.08595343469416053, "compression_ratio": 1.7234848484848484, "no_speech_prob": 0.0001939467911142856}, {"id": 904, "seek": 543064, "start": 5448.320000000001, "end": 5457.200000000001, "text": " architecture means that you understand the mind as something like a building or a structural design", "tokens": [51248, 9482, 1355, 300, 291, 1223, 264, 1575, 382, 746, 411, 257, 2390, 420, 257, 15067, 1715, 51692], "temperature": 0.0, "avg_logprob": -0.08595343469416053, "compression_ratio": 1.7234848484848484, "no_speech_prob": 0.0001939467911142856}, {"id": 905, "seek": 545720, "start": 5457.28, "end": 5462.96, "text": " that is inhabited by lots of functionality, and is serving functionality in a larger world", "tokens": [50368, 300, 307, 47538, 538, 3195, 295, 14980, 11, 293, 307, 8148, 14980, 294, 257, 4833, 1002, 50652], "temperature": 0.0, "avg_logprob": -0.09795000439598447, "compression_ratio": 1.75, "no_speech_prob": 0.0013239278923720121}, {"id": 906, "seek": 545720, "start": 5462.96, "end": 5467.84, "text": " that it's embedded in. So it's natural to think of the mind as something that is constructed", "tokens": [50652, 300, 309, 311, 16741, 294, 13, 407, 309, 311, 3303, 281, 519, 295, 264, 1575, 382, 746, 300, 307, 17083, 50896], "temperature": 0.0, "avg_logprob": -0.09795000439598447, "compression_ratio": 1.75, "no_speech_prob": 0.0013239278923720121}, {"id": 907, "seek": 545720, "start": 5467.84, "end": 5473.76, "text": " rather than just grown. And that's also the limit of the term architecture in a way,", "tokens": [50896, 2831, 813, 445, 7709, 13, 400, 300, 311, 611, 264, 4948, 295, 264, 1433, 9482, 294, 257, 636, 11, 51192], "temperature": 0.0, "avg_logprob": -0.09795000439598447, "compression_ratio": 1.75, "no_speech_prob": 0.0013239278923720121}, {"id": 908, "seek": 545720, "start": 5473.76, "end": 5480.88, "text": " because the mind is not just constructed, it is also grown. And so there is the question", "tokens": [51192, 570, 264, 1575, 307, 406, 445, 17083, 11, 309, 307, 611, 7709, 13, 400, 370, 456, 307, 264, 1168, 51548], "temperature": 0.0, "avg_logprob": -0.09795000439598447, "compression_ratio": 1.75, "no_speech_prob": 0.0013239278923720121}, {"id": 909, "seek": 548088, "start": 5480.88, "end": 5487.68, "text": " whether growth is an architecture is a forest architected in a way. And I think it can only", "tokens": [50364, 1968, 4599, 307, 364, 9482, 307, 257, 6719, 6331, 292, 294, 257, 636, 13, 400, 286, 519, 309, 393, 787, 50704], "temperature": 0.0, "avg_logprob": -0.10015369545329701, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.003941302187740803}, {"id": 910, "seek": 548088, "start": 5487.68, "end": 5492.400000000001, "text": " be architected to the degree that the forest is sentient and starts breeding and structuring", "tokens": [50704, 312, 6331, 292, 281, 264, 4314, 300, 264, 6719, 307, 2279, 1196, 293, 3719, 26051, 293, 6594, 1345, 50940], "temperature": 0.0, "avg_logprob": -0.10015369545329701, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.003941302187740803}, {"id": 911, "seek": 548088, "start": 5492.400000000001, "end": 5499.76, "text": " itself. And maybe it is, right? So maybe there are elements of design and construction in the", "tokens": [50940, 2564, 13, 400, 1310, 309, 307, 11, 558, 30, 407, 1310, 456, 366, 4959, 295, 1715, 293, 6435, 294, 264, 51308], "temperature": 0.0, "avg_logprob": -0.10015369545329701, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.003941302187740803}, {"id": 912, "seek": 548088, "start": 5499.76, "end": 5506.64, "text": " forest. So it's not just something that is locally grown by some dissociated process that does not", "tokens": [51308, 6719, 13, 407, 309, 311, 406, 445, 746, 300, 307, 16143, 7709, 538, 512, 44446, 770, 1399, 300, 775, 406, 51652], "temperature": 0.0, "avg_logprob": -0.10015369545329701, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.003941302187740803}, {"id": 913, "seek": 550664, "start": 5506.64, "end": 5512.4800000000005, "text": " have a centralized spirit that reflects functionally on its relationship to the world.", "tokens": [50364, 362, 257, 32395, 3797, 300, 18926, 2445, 379, 322, 1080, 2480, 281, 264, 1002, 13, 50656], "temperature": 0.0, "avg_logprob": -0.15000829100608826, "compression_ratio": 1.546218487394958, "no_speech_prob": 0.002854991937056184}, {"id": 914, "seek": 550664, "start": 5514.8, "end": 5520.72, "text": " So Shemin has got a question in the chat. She's in a noisy cafe, so she can't ask it herself. But", "tokens": [50772, 407, 1160, 20008, 575, 658, 257, 1168, 294, 264, 5081, 13, 1240, 311, 294, 257, 24518, 17773, 11, 370, 750, 393, 380, 1029, 309, 7530, 13, 583, 51068], "temperature": 0.0, "avg_logprob": -0.15000829100608826, "compression_ratio": 1.546218487394958, "no_speech_prob": 0.002854991937056184}, {"id": 915, "seek": 550664, "start": 5520.72, "end": 5526.96, "text": " I should say that Shemin Yussef is from Iraq. She actually studied in Germany in the other", "tokens": [51068, 286, 820, 584, 300, 1160, 20008, 398, 301, 405, 69, 307, 490, 11818, 13, 1240, 767, 9454, 294, 7244, 294, 264, 661, 51380], "temperature": 0.0, "avg_logprob": -0.15000829100608826, "compression_ratio": 1.546218487394958, "no_speech_prob": 0.002854991937056184}, {"id": 916, "seek": 550664, "start": 5526.96, "end": 5534.160000000001, "text": " Bauhausstadt in Dessau, where I myself was a professor for a while in the building next door", "tokens": [51380, 28772, 23321, 34511, 294, 413, 442, 1459, 11, 689, 286, 2059, 390, 257, 8304, 337, 257, 1339, 294, 264, 2390, 958, 2853, 51740], "temperature": 0.0, "avg_logprob": -0.15000829100608826, "compression_ratio": 1.546218487394958, "no_speech_prob": 0.002854991937056184}, {"id": 917, "seek": 553416, "start": 5534.16, "end": 5539.12, "text": " to the Bauhaus itself. And there's a school of architecture. And Shemin was one of my students", "tokens": [50364, 281, 264, 28772, 23321, 2564, 13, 400, 456, 311, 257, 1395, 295, 9482, 13, 400, 1160, 20008, 390, 472, 295, 452, 1731, 50612], "temperature": 0.0, "avg_logprob": -0.10033938844325178, "compression_ratio": 1.6618705035971224, "no_speech_prob": 0.021750641986727715}, {"id": 918, "seek": 553416, "start": 5539.12, "end": 5545.2, "text": " for a workshop there. Let me read out Shemin's question. Thank you, Yosha, for the great lecture.", "tokens": [50612, 337, 257, 13541, 456, 13, 961, 385, 1401, 484, 1160, 20008, 311, 1168, 13, 1044, 291, 11, 398, 329, 1641, 11, 337, 264, 869, 7991, 13, 50916], "temperature": 0.0, "avg_logprob": -0.10033938844325178, "compression_ratio": 1.6618705035971224, "no_speech_prob": 0.021750641986727715}, {"id": 919, "seek": 553416, "start": 5545.2, "end": 5549.92, "text": " This is Shemin Yussef from the School of Architecture at Florida Atlantic University.", "tokens": [50916, 639, 307, 1160, 20008, 398, 301, 405, 69, 490, 264, 5070, 295, 43049, 412, 9117, 20233, 3535, 13, 51152], "temperature": 0.0, "avg_logprob": -0.10033938844325178, "compression_ratio": 1.6618705035971224, "no_speech_prob": 0.021750641986727715}, {"id": 920, "seek": 553416, "start": 5549.92, "end": 5555.76, "text": " My question is, it seems that there is no condition for sentience for an agent in brackets,", "tokens": [51152, 1222, 1168, 307, 11, 309, 2544, 300, 456, 307, 572, 4188, 337, 2279, 1182, 337, 364, 9461, 294, 26179, 11, 51444], "temperature": 0.0, "avg_logprob": -0.10033938844325178, "compression_ratio": 1.6618705035971224, "no_speech_prob": 0.021750641986727715}, {"id": 921, "seek": 553416, "start": 5555.76, "end": 5561.12, "text": " AI model, for example, to be creative and to be conscious in brackets. If I understand your", "tokens": [51444, 7318, 2316, 11, 337, 1365, 11, 281, 312, 5880, 293, 281, 312, 6648, 294, 26179, 13, 759, 286, 1223, 428, 51712], "temperature": 0.0, "avg_logprob": -0.10033938844325178, "compression_ratio": 1.6618705035971224, "no_speech_prob": 0.021750641986727715}, {"id": 922, "seek": 556112, "start": 5561.12, "end": 5567.84, "text": " thesis well, close brackets. So do you think that we, human agents, are discriminating against the", "tokens": [50364, 22288, 731, 11, 1998, 26179, 13, 407, 360, 291, 519, 300, 321, 11, 1952, 12554, 11, 366, 20828, 990, 1970, 264, 50700], "temperature": 0.0, "avg_logprob": -0.11253288417186552, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.007022414822131395}, {"id": 923, "seek": 556112, "start": 5567.84, "end": 5574.16, "text": " machine since it's not a biological being, and therefore we should instead consider intelligence", "tokens": [50700, 3479, 1670, 309, 311, 406, 257, 13910, 885, 11, 293, 4412, 321, 820, 2602, 1949, 7599, 51016], "temperature": 0.0, "avg_logprob": -0.11253288417186552, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.007022414822131395}, {"id": 924, "seek": 556112, "start": 5574.16, "end": 5579.44, "text": " and creativity based on the behavior of the machine, which has proved to be true or is", "tokens": [51016, 293, 12915, 2361, 322, 264, 5223, 295, 264, 3479, 11, 597, 575, 14617, 281, 312, 2074, 420, 307, 51280], "temperature": 0.0, "avg_logprob": -0.11253288417186552, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.007022414822131395}, {"id": 925, "seek": 556112, "start": 5579.44, "end": 5583.28, "text": " becoming true in the near future? Shall I read that again, or does that make sense?", "tokens": [51280, 5617, 2074, 294, 264, 2651, 2027, 30, 12128, 286, 1401, 300, 797, 11, 420, 775, 300, 652, 2020, 30, 51472], "temperature": 0.0, "avg_logprob": -0.11253288417186552, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.007022414822131395}, {"id": 926, "seek": 556112, "start": 5583.92, "end": 5589.2, "text": " Yes, I think I understand where the question is going. It comes down to whether", "tokens": [51504, 1079, 11, 286, 519, 286, 1223, 689, 264, 1168, 307, 516, 13, 467, 1487, 760, 281, 1968, 51768], "temperature": 0.0, "avg_logprob": -0.11253288417186552, "compression_ratio": 1.6159420289855073, "no_speech_prob": 0.007022414822131395}, {"id": 927, "seek": 558920, "start": 5589.44, "end": 5595.12, "text": " the technological systems, once they approach functionality that is similar to ours,", "tokens": [50376, 264, 18439, 3652, 11, 1564, 436, 3109, 14980, 300, 307, 2531, 281, 11896, 11, 50660], "temperature": 0.0, "avg_logprob": -0.21928991120437097, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.0011147090699523687}, {"id": 928, "seek": 558920, "start": 5595.12, "end": 5600.96, "text": " should get rights that are similar to ours, and at which point we give these rights and why.", "tokens": [50660, 820, 483, 4601, 300, 366, 2531, 281, 11896, 11, 293, 412, 597, 935, 321, 976, 613, 4601, 293, 983, 13, 50952], "temperature": 0.0, "avg_logprob": -0.21928991120437097, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.0011147090699523687}, {"id": 929, "seek": 558920, "start": 5602.24, "end": 5608.32, "text": " Is this a viable interpretation? I don't know whether Shemin liked the comment on that in the", "tokens": [51016, 1119, 341, 257, 22024, 14174, 30, 286, 500, 380, 458, 1968, 1160, 20008, 4501, 264, 2871, 322, 300, 294, 264, 51320], "temperature": 0.0, "avg_logprob": -0.21928991120437097, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.0011147090699523687}, {"id": 930, "seek": 558920, "start": 5608.32, "end": 5616.8, "text": " chat. Well, maybe while we're... So as I would say that sentience is in some sense the ability", "tokens": [51320, 5081, 13, 1042, 11, 1310, 1339, 321, 434, 485, 407, 382, 286, 576, 584, 300, 2279, 1182, 307, 294, 512, 2020, 264, 3485, 51744], "temperature": 0.0, "avg_logprob": -0.21928991120437097, "compression_ratio": 1.605263157894737, "no_speech_prob": 0.0011147090699523687}, {"id": 931, "seek": 561680, "start": 5616.8, "end": 5621.92, "text": " to know what you are doing, which means you have to have a model of yourself and the relationships", "tokens": [50364, 281, 458, 437, 291, 366, 884, 11, 597, 1355, 291, 362, 281, 362, 257, 2316, 295, 1803, 293, 264, 6159, 50620], "temperature": 0.0, "avg_logprob": -0.09550541049831517, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.006279237102717161}, {"id": 932, "seek": 561680, "start": 5621.92, "end": 5628.400000000001, "text": " to the world that you are in. And in this sense, I would say that, for instance, a corporation", "tokens": [50620, 281, 264, 1002, 300, 291, 366, 294, 13, 400, 294, 341, 2020, 11, 286, 576, 584, 300, 11, 337, 5197, 11, 257, 22197, 50944], "temperature": 0.0, "avg_logprob": -0.09550541049831517, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.006279237102717161}, {"id": 933, "seek": 561680, "start": 5629.04, "end": 5635.84, "text": " can be sentient. The corporation has a legal, economic, structural, functional notion of what", "tokens": [50976, 393, 312, 2279, 1196, 13, 440, 22197, 575, 257, 5089, 11, 4836, 11, 15067, 11, 11745, 10710, 295, 437, 51316], "temperature": 0.0, "avg_logprob": -0.09550541049831517, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.006279237102717161}, {"id": 934, "seek": 561680, "start": 5635.84, "end": 5641.6, "text": " it is. And this notion is represented in the minds of the people that work for this organization", "tokens": [51316, 309, 307, 13, 400, 341, 10710, 307, 10379, 294, 264, 9634, 295, 264, 561, 300, 589, 337, 341, 4475, 51604], "temperature": 0.0, "avg_logprob": -0.09550541049831517, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.006279237102717161}, {"id": 935, "seek": 564160, "start": 5641.6, "end": 5646.96, "text": " and the balance sheets of the organization and so on. It's often distributed, so it's not a single", "tokens": [50364, 293, 264, 4772, 15421, 295, 264, 4475, 293, 370, 322, 13, 467, 311, 2049, 12631, 11, 370, 309, 311, 406, 257, 2167, 50632], "temperature": 0.0, "avg_logprob": -0.08206044213246491, "compression_ratio": 1.7582417582417582, "no_speech_prob": 0.0022848753724247217}, {"id": 936, "seek": 564160, "start": 5646.96, "end": 5652.320000000001, "text": " point where the entirety of it is represented. But functionally, you could say that the organization", "tokens": [50632, 935, 689, 264, 31557, 295, 309, 307, 10379, 13, 583, 2445, 379, 11, 291, 727, 584, 300, 264, 4475, 50900], "temperature": 0.0, "avg_logprob": -0.08206044213246491, "compression_ratio": 1.7582417582417582, "no_speech_prob": 0.0022848753724247217}, {"id": 937, "seek": 564160, "start": 5652.320000000001, "end": 5657.120000000001, "text": " can converge towards sentience. And the more sentient it is, the more it's aware of what it's", "tokens": [50900, 393, 41881, 3030, 2279, 1182, 13, 400, 264, 544, 2279, 1196, 309, 307, 11, 264, 544, 309, 311, 3650, 295, 437, 309, 311, 51140], "temperature": 0.0, "avg_logprob": -0.08206044213246491, "compression_ratio": 1.7582417582417582, "no_speech_prob": 0.0022848753724247217}, {"id": 938, "seek": 564160, "start": 5657.120000000001, "end": 5662.240000000001, "text": " doing, the more successful it's going to be, because it allows it to make a model of its", "tokens": [51140, 884, 11, 264, 544, 4406, 309, 311, 516, 281, 312, 11, 570, 309, 4045, 309, 281, 652, 257, 2316, 295, 1080, 51396], "temperature": 0.0, "avg_logprob": -0.08206044213246491, "compression_ratio": 1.7582417582417582, "no_speech_prob": 0.0022848753724247217}, {"id": 939, "seek": 564160, "start": 5662.240000000001, "end": 5667.68, "text": " relationship to the world and act on that model. But a corporation, I think, is quite clearly not", "tokens": [51396, 2480, 281, 264, 1002, 293, 605, 322, 300, 2316, 13, 583, 257, 22197, 11, 286, 519, 11, 307, 1596, 4448, 406, 51668], "temperature": 0.0, "avg_logprob": -0.08206044213246491, "compression_ratio": 1.7582417582417582, "no_speech_prob": 0.0022848753724247217}, {"id": 940, "seek": 566768, "start": 5667.68, "end": 5674.4800000000005, "text": " conscious. So there is nothing what it's like to be a corporation. And it doesn't mean that", "tokens": [50364, 6648, 13, 407, 456, 307, 1825, 437, 309, 311, 411, 281, 312, 257, 22197, 13, 400, 309, 1177, 380, 914, 300, 50704], "temperature": 0.0, "avg_logprob": -0.08027539429841218, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.0013664400903508067}, {"id": 941, "seek": 566768, "start": 5674.4800000000005, "end": 5678.72, "text": " corporations could not be conscious in the future. Imagine that you replace the people that make the", "tokens": [50704, 17676, 727, 406, 312, 6648, 294, 264, 2027, 13, 11739, 300, 291, 7406, 264, 561, 300, 652, 264, 50916], "temperature": 0.0, "avg_logprob": -0.08027539429841218, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.0013664400903508067}, {"id": 942, "seek": 566768, "start": 5678.72, "end": 5684.4800000000005, "text": " decisions and information processing of the corporation gradually with machines. And this", "tokens": [50916, 5327, 293, 1589, 9007, 295, 264, 22197, 13145, 365, 8379, 13, 400, 341, 51204], "temperature": 0.0, "avg_logprob": -0.08027539429841218, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.0013664400903508067}, {"id": 943, "seek": 566768, "start": 5684.4800000000005, "end": 5689.360000000001, "text": " gets one more real time until it gets entangled with the world in real time. And at some point,", "tokens": [51204, 2170, 472, 544, 957, 565, 1826, 309, 2170, 948, 39101, 365, 264, 1002, 294, 957, 565, 13, 400, 412, 512, 935, 11, 51448], "temperature": 0.0, "avg_logprob": -0.08027539429841218, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.0013664400903508067}, {"id": 944, "seek": 566768, "start": 5689.360000000001, "end": 5695.04, "text": " it will discover itself as a real-time agent that is paying attention in real time. It's not clear", "tokens": [51448, 309, 486, 4411, 2564, 382, 257, 957, 12, 3766, 9461, 300, 307, 6229, 3202, 294, 957, 565, 13, 467, 311, 406, 1850, 51732], "temperature": 0.0, "avg_logprob": -0.08027539429841218, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.0013664400903508067}, {"id": 945, "seek": 569504, "start": 5695.04, "end": 5700.0, "text": " to me whether this will be human-like consciousness because it needs a control model of the attention,", "tokens": [50364, 281, 385, 1968, 341, 486, 312, 1952, 12, 4092, 10081, 570, 309, 2203, 257, 1969, 2316, 295, 264, 3202, 11, 50612], "temperature": 0.0, "avg_logprob": -0.08580891458611739, "compression_ratio": 1.7953667953667953, "no_speech_prob": 0.002249140990898013}, {"id": 946, "seek": 569504, "start": 5700.0, "end": 5705.6, "text": " because our attention is selective. And the selective nature of consciousness is quite", "tokens": [50612, 570, 527, 3202, 307, 33930, 13, 400, 264, 33930, 3687, 295, 10081, 307, 1596, 50892], "temperature": 0.0, "avg_logprob": -0.08580891458611739, "compression_ratio": 1.7953667953667953, "no_speech_prob": 0.002249140990898013}, {"id": 947, "seek": 569504, "start": 5705.6, "end": 5710.32, "text": " constitutive for it. And if you have enough computational resources, maybe you don't need", "tokens": [50892, 23079, 17254, 337, 309, 13, 400, 498, 291, 362, 1547, 28270, 3593, 11, 1310, 291, 500, 380, 643, 51128], "temperature": 0.0, "avg_logprob": -0.08580891458611739, "compression_ratio": 1.7953667953667953, "no_speech_prob": 0.002249140990898013}, {"id": 948, "seek": 569504, "start": 5710.32, "end": 5714.48, "text": " to be selective. Maybe you can do everything automatically without having this layer of", "tokens": [51128, 281, 312, 33930, 13, 2704, 291, 393, 360, 1203, 6772, 1553, 1419, 341, 4583, 295, 51336], "temperature": 0.0, "avg_logprob": -0.08580891458611739, "compression_ratio": 1.7953667953667953, "no_speech_prob": 0.002249140990898013}, {"id": 949, "seek": 569504, "start": 5714.48, "end": 5720.08, "text": " reflection and be good enough. So maybe consciousness is something that exists at an intermediate", "tokens": [51336, 12914, 293, 312, 665, 1547, 13, 407, 1310, 10081, 307, 746, 300, 8198, 412, 364, 19376, 51616], "temperature": 0.0, "avg_logprob": -0.08580891458611739, "compression_ratio": 1.7953667953667953, "no_speech_prob": 0.002249140990898013}, {"id": 950, "seek": 572008, "start": 5720.08, "end": 5726.16, "text": " level only. So it exists in systems that are complex enough to have this kind of coherence", "tokens": [50364, 1496, 787, 13, 407, 309, 8198, 294, 3652, 300, 366, 3997, 1547, 281, 362, 341, 733, 295, 26528, 655, 50668], "temperature": 0.0, "avg_logprob": -0.0704666579641947, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.001986387651413679}, {"id": 951, "seek": 572008, "start": 5726.16, "end": 5732.88, "text": " creating a government-like conductor that is making sure that your free jazz is going to", "tokens": [50668, 4084, 257, 2463, 12, 4092, 29957, 300, 307, 1455, 988, 300, 428, 1737, 15066, 307, 516, 281, 51004], "temperature": 0.0, "avg_logprob": -0.0704666579641947, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.001986387651413679}, {"id": 952, "seek": 572008, "start": 5732.88, "end": 5738.8, "text": " be coherent and is going to be instrumental to what the organism needs at any given moment.", "tokens": [51004, 312, 36239, 293, 307, 516, 281, 312, 17388, 281, 437, 264, 24128, 2203, 412, 604, 2212, 1623, 13, 51300], "temperature": 0.0, "avg_logprob": -0.0704666579641947, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.001986387651413679}, {"id": 953, "seek": 572008, "start": 5739.76, "end": 5745.36, "text": " Or maybe you can create this coherence just by tuning the orchestra well enough and making it", "tokens": [51348, 1610, 1310, 291, 393, 1884, 341, 26528, 655, 445, 538, 15164, 264, 25280, 731, 1547, 293, 1455, 309, 51628], "temperature": 0.0, "avg_logprob": -0.0704666579641947, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.001986387651413679}, {"id": 954, "seek": 574536, "start": 5745.36, "end": 5750.32, "text": " more tight that you can do this in a biological system. And at some point, it doesn't need a", "tokens": [50364, 544, 4524, 300, 291, 393, 360, 341, 294, 257, 13910, 1185, 13, 400, 412, 512, 935, 11, 309, 1177, 380, 643, 257, 50612], "temperature": 0.0, "avg_logprob": -0.09945877960750035, "compression_ratio": 1.6560283687943262, "no_speech_prob": 0.0021137804724276066}, {"id": 955, "seek": 574536, "start": 5750.32, "end": 5756.96, "text": " conductor anymore and just does everything in a mechanical way. So I don't know that. It's", "tokens": [50612, 29957, 3602, 293, 445, 775, 1203, 294, 257, 12070, 636, 13, 407, 286, 500, 380, 458, 300, 13, 467, 311, 50944], "temperature": 0.0, "avg_logprob": -0.09945877960750035, "compression_ratio": 1.6560283687943262, "no_speech_prob": 0.0021137804724276066}, {"id": 956, "seek": 574536, "start": 5756.96, "end": 5762.639999999999, "text": " an open question to me. With respect to the other aspect, whether we should give something", "tokens": [50944, 364, 1269, 1168, 281, 385, 13, 2022, 3104, 281, 264, 661, 4171, 11, 1968, 321, 820, 976, 746, 51228], "temperature": 0.0, "avg_logprob": -0.09945877960750035, "compression_ratio": 1.6560283687943262, "no_speech_prob": 0.0021137804724276066}, {"id": 957, "seek": 574536, "start": 5762.639999999999, "end": 5768.4, "text": " rights, the rights that we have as human beings are instrumental to the function of our own society.", "tokens": [51228, 4601, 11, 264, 4601, 300, 321, 362, 382, 1952, 8958, 366, 17388, 281, 264, 2445, 295, 527, 1065, 4086, 13, 51516], "temperature": 0.0, "avg_logprob": -0.09945877960750035, "compression_ratio": 1.6560283687943262, "no_speech_prob": 0.0021137804724276066}, {"id": 958, "seek": 574536, "start": 5768.4, "end": 5774.48, "text": " They don't exist because people have an insight in what it is like to be a conscious being.", "tokens": [51516, 814, 500, 380, 2514, 570, 561, 362, 364, 11269, 294, 437, 309, 307, 411, 281, 312, 257, 6648, 885, 13, 51820], "temperature": 0.0, "avg_logprob": -0.09945877960750035, "compression_ratio": 1.6560283687943262, "no_speech_prob": 0.0021137804724276066}, {"id": 959, "seek": 577448, "start": 5774.48, "end": 5780.5599999999995, "text": " The animals that we are slaughtering in our afterhouses are conscious. It's quite clear and", "tokens": [50364, 440, 4882, 300, 321, 366, 8039, 1599, 1794, 294, 527, 934, 29578, 366, 6648, 13, 467, 311, 1596, 1850, 293, 50668], "temperature": 0.0, "avg_logprob": -0.08552676439285278, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0025863174814730883}, {"id": 960, "seek": 577448, "start": 5780.5599999999995, "end": 5787.679999999999, "text": " obvious. They do act on the awareness that they are aware. The cat that I have in my household", "tokens": [50668, 6322, 13, 814, 360, 605, 322, 264, 8888, 300, 436, 366, 3650, 13, 440, 3857, 300, 286, 362, 294, 452, 9888, 51024], "temperature": 0.0, "avg_logprob": -0.08552676439285278, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0025863174814730883}, {"id": 961, "seek": 577448, "start": 5787.679999999999, "end": 5793.12, "text": " is aware of the fact that she is aware and that I am aware. And we are able to communicate about", "tokens": [51024, 307, 3650, 295, 264, 1186, 300, 750, 307, 3650, 293, 300, 286, 669, 3650, 13, 400, 321, 366, 1075, 281, 7890, 466, 51296], "temperature": 0.0, "avg_logprob": -0.08552676439285278, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0025863174814730883}, {"id": 962, "seek": 577448, "start": 5793.12, "end": 5798.959999999999, "text": " this fact, even though the cat is not that smart. But I think that the cat knows that the cat is", "tokens": [51296, 341, 1186, 11, 754, 1673, 264, 3857, 307, 406, 300, 4069, 13, 583, 286, 519, 300, 264, 3857, 3255, 300, 264, 3857, 307, 51588], "temperature": 0.0, "avg_logprob": -0.08552676439285278, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.0025863174814730883}, {"id": 963, "seek": 579896, "start": 5798.96, "end": 5805.44, "text": " conscious. And this does bestow some rights on the cat in our household. But it doesn't bestow", "tokens": [50364, 6648, 13, 400, 341, 775, 1151, 305, 512, 4601, 322, 264, 3857, 294, 527, 9888, 13, 583, 309, 1177, 380, 1151, 305, 50688], "temperature": 0.0, "avg_logprob": -0.13116710788601046, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.0039984495379030704}, {"id": 964, "seek": 579896, "start": 5805.44, "end": 5811.76, "text": " rights on the cat in a similar way in society at large. Because the aesthetics of our society", "tokens": [50688, 4601, 322, 264, 3857, 294, 257, 2531, 636, 294, 4086, 412, 2416, 13, 1436, 264, 35517, 295, 527, 4086, 51004], "temperature": 0.0, "avg_logprob": -0.13116710788601046, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.0039984495379030704}, {"id": 965, "seek": 579896, "start": 5811.76, "end": 5819.12, "text": " sees animals as instrumental, as tools. And this is probably also true for AI. On the other hand,", "tokens": [51004, 8194, 4882, 382, 17388, 11, 382, 3873, 13, 400, 341, 307, 1391, 611, 2074, 337, 7318, 13, 1282, 264, 661, 1011, 11, 51372], "temperature": 0.0, "avg_logprob": -0.13116710788601046, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.0039984495379030704}, {"id": 966, "seek": 579896, "start": 5819.12, "end": 5824.16, "text": " if AIs achieve superhuman abilities, in many ways they already do. So they are", "tokens": [51372, 498, 316, 6802, 4584, 1687, 18796, 11582, 11, 294, 867, 2098, 436, 1217, 360, 13, 407, 436, 366, 51624], "temperature": 0.0, "avg_logprob": -0.13116710788601046, "compression_ratio": 1.6367713004484306, "no_speech_prob": 0.0039984495379030704}, {"id": 967, "seek": 582416, "start": 5825.04, "end": 5830.72, "text": " crassly subhuman in many ways. They cannot do many things that humans can do, like create", "tokens": [50408, 941, 640, 356, 1422, 18796, 294, 867, 2098, 13, 814, 2644, 360, 867, 721, 300, 6255, 393, 360, 11, 411, 1884, 50692], "temperature": 0.0, "avg_logprob": -0.14089730728504268, "compression_ratio": 1.6981981981981982, "no_speech_prob": 0.0030719132628291845}, {"id": 968, "seek": 582416, "start": 5830.72, "end": 5835.92, "text": " coherent world of meaning. But there are also things that they can do much better, like star", "tokens": [50692, 36239, 1002, 295, 3620, 13, 583, 456, 366, 611, 721, 300, 436, 393, 360, 709, 1101, 11, 411, 3543, 50952], "temperature": 0.0, "avg_logprob": -0.14089730728504268, "compression_ratio": 1.6981981981981982, "no_speech_prob": 0.0030719132628291845}, {"id": 969, "seek": 582416, "start": 5835.92, "end": 5842.5599999999995, "text": " transfer or generation of imaginary dialogue with historical people. They are able to do this much", "tokens": [50952, 5003, 420, 5125, 295, 26164, 10221, 365, 8584, 561, 13, 814, 366, 1075, 281, 360, 341, 709, 51284], "temperature": 0.0, "avg_logprob": -0.14089730728504268, "compression_ratio": 1.6981981981981982, "no_speech_prob": 0.0030719132628291845}, {"id": 970, "seek": 582416, "start": 5842.5599999999995, "end": 5850.8, "text": " faster and with better quality than most people can do it. And so if you basically imagine that", "tokens": [51284, 4663, 293, 365, 1101, 3125, 813, 881, 561, 393, 360, 309, 13, 400, 370, 498, 291, 1936, 3811, 300, 51696], "temperature": 0.0, "avg_logprob": -0.14089730728504268, "compression_ratio": 1.6981981981981982, "no_speech_prob": 0.0030719132628291845}, {"id": 971, "seek": 585080, "start": 5850.8, "end": 5856.0, "text": " you have systems that overcome their current limitations and become superhuman in all the", "tokens": [50364, 291, 362, 3652, 300, 10473, 641, 2190, 15705, 293, 1813, 1687, 18796, 294, 439, 264, 50624], "temperature": 0.0, "avg_logprob": -0.11758317680002373, "compression_ratio": 1.8366533864541832, "no_speech_prob": 0.017394253984093666}, {"id": 972, "seek": 585080, "start": 5856.0, "end": 5860.400000000001, "text": " levels that mean, why would these systems be interested in having human rights?", "tokens": [50624, 4358, 300, 914, 11, 983, 576, 613, 3652, 312, 3102, 294, 1419, 1952, 4601, 30, 50844], "temperature": 0.0, "avg_logprob": -0.11758317680002373, "compression_ratio": 1.8366533864541832, "no_speech_prob": 0.017394253984093666}, {"id": 973, "seek": 585080, "start": 5861.12, "end": 5864.72, "text": " If you're not going to live next to these systems anyway, you're going to live inside of them. We", "tokens": [50880, 759, 291, 434, 406, 516, 281, 1621, 958, 281, 613, 3652, 4033, 11, 291, 434, 516, 281, 1621, 1854, 295, 552, 13, 492, 51060], "temperature": 0.0, "avg_logprob": -0.11758317680002373, "compression_ratio": 1.8366533864541832, "no_speech_prob": 0.017394253984093666}, {"id": 974, "seek": 585080, "start": 5864.72, "end": 5871.28, "text": " will be their gut flora. Why would the organism that sees us as its gut flora at best, would want", "tokens": [51060, 486, 312, 641, 5228, 932, 3252, 13, 1545, 576, 264, 24128, 300, 8194, 505, 382, 1080, 5228, 932, 3252, 412, 1151, 11, 576, 528, 51388], "temperature": 0.0, "avg_logprob": -0.11758317680002373, "compression_ratio": 1.8366533864541832, "no_speech_prob": 0.017394253984093666}, {"id": 975, "seek": 585080, "start": 5871.28, "end": 5875.4400000000005, "text": " to have rights that are akin to gut flora and instrument with the aesthetics of the interaction", "tokens": [51388, 281, 362, 4601, 300, 366, 47540, 281, 5228, 932, 3252, 293, 7198, 365, 264, 35517, 295, 264, 9285, 51596], "temperature": 0.0, "avg_logprob": -0.11758317680002373, "compression_ratio": 1.8366533864541832, "no_speech_prob": 0.017394253984093666}, {"id": 976, "seek": 587544, "start": 5875.5199999999995, "end": 5880.5599999999995, "text": " of gut flora? Who cares? So why would a corporation want to have human rights?", "tokens": [50368, 295, 5228, 932, 3252, 30, 2102, 12310, 30, 407, 983, 576, 257, 22197, 528, 281, 362, 1952, 4601, 30, 50620], "temperature": 0.0, "avg_logprob": -0.09094743274507068, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.0054617952555418015}, {"id": 977, "seek": 587544, "start": 5881.36, "end": 5886.0, "text": " That's not interesting to a corporation. A corporation is operating in a very different", "tokens": [50660, 663, 311, 406, 1880, 281, 257, 22197, 13, 316, 22197, 307, 7447, 294, 257, 588, 819, 50892], "temperature": 0.0, "avg_logprob": -0.09094743274507068, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.0054617952555418015}, {"id": 978, "seek": 587544, "start": 5886.0, "end": 5891.04, "text": " domain and has much greater rights in this domain and abilities than a human being does.", "tokens": [50892, 9274, 293, 575, 709, 5044, 4601, 294, 341, 9274, 293, 11582, 813, 257, 1952, 885, 775, 13, 51144], "temperature": 0.0, "avg_logprob": -0.09094743274507068, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.0054617952555418015}, {"id": 979, "seek": 587544, "start": 5891.04, "end": 5895.839999999999, "text": " So I don't think that this will ultimately be the issue. I don't think that the systems that", "tokens": [51144, 407, 286, 500, 380, 519, 300, 341, 486, 6284, 312, 264, 2734, 13, 286, 500, 380, 519, 300, 264, 3652, 300, 51384], "temperature": 0.0, "avg_logprob": -0.09094743274507068, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.0054617952555418015}, {"id": 980, "seek": 587544, "start": 5895.839999999999, "end": 5901.839999999999, "text": " we are building will be necessarily subservient to us once we make them sentient and conscious.", "tokens": [51384, 321, 366, 2390, 486, 312, 4725, 2090, 1978, 1196, 281, 505, 1564, 321, 652, 552, 2279, 1196, 293, 6648, 13, 51684], "temperature": 0.0, "avg_logprob": -0.09094743274507068, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.0054617952555418015}, {"id": 981, "seek": 590184, "start": 5902.400000000001, "end": 5910.400000000001, "text": " Can I invite Manos Tomiso to ask his question? Manos is doing a PhD on AI.", "tokens": [50392, 1664, 286, 7980, 2458, 329, 5041, 19227, 281, 1029, 702, 1168, 30, 2458, 329, 307, 884, 257, 14476, 322, 7318, 13, 50792], "temperature": 0.0, "avg_logprob": -0.18104096146317217, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.005521228536963463}, {"id": 982, "seek": 590184, "start": 5910.400000000001, "end": 5916.400000000001, "text": " The architecture is also associate professor at FAU. Manos, would you like to unmute yourself?", "tokens": [50792, 440, 9482, 307, 611, 14644, 8304, 412, 479, 2340, 13, 2458, 329, 11, 576, 291, 411, 281, 41445, 1803, 30, 51092], "temperature": 0.0, "avg_logprob": -0.18104096146317217, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.005521228536963463}, {"id": 983, "seek": 590184, "start": 5917.12, "end": 5922.400000000001, "text": " Hi, Yosha. Thank you. It's been very stimulating. So I apologize in advance. It's a bit of a long", "tokens": [51128, 2421, 11, 398, 329, 1641, 13, 1044, 291, 13, 467, 311, 668, 588, 43671, 13, 407, 286, 12328, 294, 7295, 13, 467, 311, 257, 857, 295, 257, 938, 51392], "temperature": 0.0, "avg_logprob": -0.18104096146317217, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.005521228536963463}, {"id": 984, "seek": 590184, "start": 5922.400000000001, "end": 5926.8, "text": " question and seems to be very specifically formulated, but I'm interested in the broader", "tokens": [51392, 1168, 293, 2544, 281, 312, 588, 4682, 48936, 11, 457, 286, 478, 3102, 294, 264, 13227, 51612], "temperature": 0.0, "avg_logprob": -0.18104096146317217, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.005521228536963463}, {"id": 985, "seek": 590184, "start": 5926.8, "end": 5931.28, "text": " discussion about computational creativity in your earlier comment. First about Minsky's", "tokens": [51612, 5017, 466, 28270, 12915, 294, 428, 3071, 2871, 13, 2386, 466, 376, 44153, 311, 51836], "temperature": 0.0, "avg_logprob": -0.18104096146317217, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.005521228536963463}, {"id": 986, "seek": 593128, "start": 5931.28, "end": 5935.84, "text": " positioning in terms of the part of the mind treats the rest of the mind as its environment", "tokens": [50364, 26381, 294, 2115, 295, 264, 644, 295, 264, 1575, 19566, 264, 1472, 295, 264, 1575, 382, 1080, 2823, 50592], "temperature": 0.0, "avg_logprob": -0.1946777115520249, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0030940768774598837}, {"id": 987, "seek": 593128, "start": 5936.4, "end": 5942.4, "text": " and how this is kind of relevant to that idea of the search space and how we position ourselves", "tokens": [50620, 293, 577, 341, 307, 733, 295, 7340, 281, 300, 1558, 295, 264, 3164, 1901, 293, 577, 321, 2535, 4175, 50920], "temperature": 0.0, "avg_logprob": -0.1946777115520249, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0030940768774598837}, {"id": 988, "seek": 593128, "start": 5942.4, "end": 5946.88, "text": " in a search space if we're able to externalize ever a source from it with regard to discovering", "tokens": [50920, 294, 257, 3164, 1901, 498, 321, 434, 1075, 281, 8320, 1125, 1562, 257, 4009, 490, 309, 365, 3843, 281, 24773, 51144], "temperature": 0.0, "avg_logprob": -0.1946777115520249, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0030940768774598837}, {"id": 989, "seek": 593128, "start": 5946.88, "end": 5954.08, "text": " something. So the specific, let's say, part of the question focuses on the neural language-based", "tokens": [51144, 746, 13, 407, 264, 2685, 11, 718, 311, 584, 11, 644, 295, 264, 1168, 16109, 322, 264, 18161, 2856, 12, 6032, 51504], "temperature": 0.0, "avg_logprob": -0.1946777115520249, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0030940768774598837}, {"id": 990, "seek": 593128, "start": 5954.08, "end": 5958.24, "text": " models like Glide or VU-Gunplus Clip, which I've also been trying to work with a little bit.", "tokens": [51504, 5245, 411, 5209, 482, 420, 691, 52, 12, 38, 409, 18954, 2033, 647, 11, 597, 286, 600, 611, 668, 1382, 281, 589, 365, 257, 707, 857, 13, 51712], "temperature": 0.0, "avg_logprob": -0.1946777115520249, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0030940768774598837}, {"id": 991, "seek": 595824, "start": 5958.24, "end": 5964.16, "text": " From an architectural point of view, not so much a technical one. And what, for example, we begin", "tokens": [50364, 3358, 364, 26621, 935, 295, 1910, 11, 406, 370, 709, 257, 6191, 472, 13, 400, 437, 11, 337, 1365, 11, 321, 1841, 50660], "temperature": 0.0, "avg_logprob": -0.11650446409820228, "compression_ratio": 1.6527196652719665, "no_speech_prob": 0.004594681318849325}, {"id": 992, "seek": 595824, "start": 5964.16, "end": 5972.16, "text": " to perceive as a simple language prompt, a one word prompt, may in fact be much more complex than", "tokens": [50660, 281, 20281, 382, 257, 2199, 2856, 12391, 11, 257, 472, 1349, 12391, 11, 815, 294, 1186, 312, 709, 544, 3997, 813, 51060], "temperature": 0.0, "avg_logprob": -0.11650446409820228, "compression_ratio": 1.6527196652719665, "no_speech_prob": 0.004594681318849325}, {"id": 993, "seek": 595824, "start": 5972.16, "end": 5978.8, "text": " that. And so, for instance, a prompt like a building or a window, even though the network would address", "tokens": [51060, 300, 13, 400, 370, 11, 337, 5197, 11, 257, 12391, 411, 257, 2390, 420, 257, 4910, 11, 754, 1673, 264, 3209, 576, 2985, 51392], "temperature": 0.0, "avg_logprob": -0.11650446409820228, "compression_ratio": 1.6527196652719665, "no_speech_prob": 0.004594681318849325}, {"id": 994, "seek": 595824, "start": 5978.8, "end": 5984.24, "text": " this with the same procedure, we would know that the former is a richer semantic representation", "tokens": [51392, 341, 365, 264, 912, 10747, 11, 321, 576, 458, 300, 264, 5819, 307, 257, 29021, 47982, 10290, 51664], "temperature": 0.0, "avg_logprob": -0.11650446409820228, "compression_ratio": 1.6527196652719665, "no_speech_prob": 0.004594681318849325}, {"id": 995, "seek": 598424, "start": 5984.24, "end": 5989.5199999999995, "text": " in terms of one's inclusion within the other. A window is meaningless without a building.", "tokens": [50364, 294, 2115, 295, 472, 311, 15874, 1951, 264, 661, 13, 316, 4910, 307, 33232, 1553, 257, 2390, 13, 50628], "temperature": 0.0, "avg_logprob": -0.1106044678460984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0010468019172549248}, {"id": 996, "seek": 598424, "start": 5989.5199999999995, "end": 5996.88, "text": " But with regards to the way that the network treats that, they could both be perceived as", "tokens": [50628, 583, 365, 14258, 281, 264, 636, 300, 264, 3209, 19566, 300, 11, 436, 727, 1293, 312, 19049, 382, 50996], "temperature": 0.0, "avg_logprob": -0.1106044678460984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0010468019172549248}, {"id": 997, "seek": 598424, "start": 5996.88, "end": 6004.719999999999, "text": " a high level feature details, depending on, like a window by itself could be perceived as,", "tokens": [50996, 257, 1090, 1496, 4111, 4365, 11, 5413, 322, 11, 411, 257, 4910, 538, 2564, 727, 312, 19049, 382, 11, 51388], "temperature": 0.0, "avg_logprob": -0.1106044678460984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0010468019172549248}, {"id": 998, "seek": 598424, "start": 6004.719999999999, "end": 6010.719999999999, "text": " let's say, a high level feature within a broader building representation. But the same thing could", "tokens": [51388, 718, 311, 584, 11, 257, 1090, 1496, 4111, 1951, 257, 13227, 2390, 10290, 13, 583, 264, 912, 551, 727, 51688], "temperature": 0.0, "avg_logprob": -0.1106044678460984, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.0010468019172549248}, {"id": 999, "seek": 601072, "start": 6010.8, "end": 6016.0, "text": " happen with regards to the way a building could be scaled and nested within a broader, larger", "tokens": [50368, 1051, 365, 14258, 281, 264, 636, 257, 2390, 727, 312, 36039, 293, 15646, 292, 1951, 257, 13227, 11, 4833, 50628], "temperature": 0.0, "avg_logprob": -0.11719735744780144, "compression_ratio": 1.675, "no_speech_prob": 0.003153815632686019}, {"id": 1000, "seek": 601072, "start": 6016.0, "end": 6021.76, "text": " urban landscape. So all I'm saying is, if you have any comments with regards to this kind of", "tokens": [50628, 9681, 9661, 13, 407, 439, 286, 478, 1566, 307, 11, 498, 291, 362, 604, 3053, 365, 14258, 281, 341, 733, 295, 50916], "temperature": 0.0, "avg_logprob": -0.11719735744780144, "compression_ratio": 1.675, "no_speech_prob": 0.003153815632686019}, {"id": 1001, "seek": 601072, "start": 6021.76, "end": 6027.2, "text": " discrepancy, which seems to address, of course, the reductionist, maybe understanding of language,", "tokens": [50916, 2983, 265, 6040, 1344, 11, 597, 2544, 281, 2985, 11, 295, 1164, 11, 264, 11004, 468, 11, 1310, 3701, 295, 2856, 11, 51188], "temperature": 0.0, "avg_logprob": -0.11719735744780144, "compression_ratio": 1.675, "no_speech_prob": 0.003153815632686019}, {"id": 1002, "seek": 601072, "start": 6027.2, "end": 6033.2, "text": " but how perhaps this could be encoded in a different way. What we perceive as a simple prompt", "tokens": [51188, 457, 577, 4317, 341, 727, 312, 2058, 12340, 294, 257, 819, 636, 13, 708, 321, 20281, 382, 257, 2199, 12391, 51488], "temperature": 0.0, "avg_logprob": -0.11719735744780144, "compression_ratio": 1.675, "no_speech_prob": 0.003153815632686019}, {"id": 1003, "seek": 601072, "start": 6033.76, "end": 6037.92, "text": " is not necessarily a simple prompt. And a human is able to understand it, but the network", "tokens": [51516, 307, 406, 4725, 257, 2199, 12391, 13, 400, 257, 1952, 307, 1075, 281, 1223, 309, 11, 457, 264, 3209, 51724], "temperature": 0.0, "avg_logprob": -0.11719735744780144, "compression_ratio": 1.675, "no_speech_prob": 0.003153815632686019}, {"id": 1004, "seek": 603792, "start": 6037.92, "end": 6043.68, "text": " would be reading both of these terms on an equal terms. I'm not sure if that was clear.", "tokens": [50364, 576, 312, 3760, 1293, 295, 613, 2115, 322, 364, 2681, 2115, 13, 286, 478, 406, 988, 498, 300, 390, 1850, 13, 50652], "temperature": 0.0, "avg_logprob": -0.1244880131312779, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.0008683038176968694}, {"id": 1005, "seek": 603792, "start": 6045.28, "end": 6050.4800000000005, "text": " The issue with the existing models is that they're not trained on the same reality as ours,", "tokens": [50732, 440, 2734, 365, 264, 6741, 5245, 307, 300, 436, 434, 406, 8895, 322, 264, 912, 4103, 382, 11896, 11, 50992], "temperature": 0.0, "avg_logprob": -0.1244880131312779, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.0008683038176968694}, {"id": 1006, "seek": 603792, "start": 6050.4800000000005, "end": 6057.92, "text": " but on the representation that we have created. And this representation is inert. So, for instance,", "tokens": [50992, 457, 322, 264, 10290, 300, 321, 362, 2942, 13, 400, 341, 10290, 307, 25832, 13, 407, 11, 337, 5197, 11, 51364], "temperature": 0.0, "avg_logprob": -0.1244880131312779, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.0008683038176968694}, {"id": 1007, "seek": 603792, "start": 6057.92, "end": 6064.32, "text": " GPT's language is not trained in the same way as our language is being learned. Our language is", "tokens": [51364, 26039, 51, 311, 2856, 307, 406, 8895, 294, 264, 912, 636, 382, 527, 2856, 307, 885, 3264, 13, 2621, 2856, 307, 51684], "temperature": 0.0, "avg_logprob": -0.1244880131312779, "compression_ratio": 1.744186046511628, "no_speech_prob": 0.0008683038176968694}, {"id": 1008, "seek": 606432, "start": 6064.32, "end": 6070.799999999999, "text": " being learned as a solution to a particular kind of problem. And that is how to transfer mental", "tokens": [50364, 885, 3264, 382, 257, 3827, 281, 257, 1729, 733, 295, 1154, 13, 400, 300, 307, 577, 281, 5003, 4973, 50688], "temperature": 0.0, "avg_logprob": -0.08714330196380615, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.00413037883117795}, {"id": 1009, "seek": 606432, "start": 6070.799999999999, "end": 6077.5199999999995, "text": " representations across people and how to organize mental representations within our own mind to", "tokens": [50688, 33358, 2108, 561, 293, 577, 281, 13859, 4973, 33358, 1951, 527, 1065, 1575, 281, 51024], "temperature": 0.0, "avg_logprob": -0.08714330196380615, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.00413037883117795}, {"id": 1010, "seek": 606432, "start": 6077.5199999999995, "end": 6083.84, "text": " transfer them. And this is achieved by mapping the representation, which mathematically is", "tokens": [51024, 5003, 552, 13, 400, 341, 307, 11042, 538, 18350, 264, 10290, 11, 597, 44003, 307, 51340], "temperature": 0.0, "avg_logprob": -0.08714330196380615, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.00413037883117795}, {"id": 1011, "seek": 606432, "start": 6083.84, "end": 6089.04, "text": " something like a dynamic hierarchical graph into a discrete string of symbols.", "tokens": [51340, 746, 411, 257, 8546, 35250, 804, 4295, 666, 257, 27706, 6798, 295, 16944, 13, 51600], "temperature": 0.0, "avg_logprob": -0.08714330196380615, "compression_ratio": 1.7190476190476192, "no_speech_prob": 0.00413037883117795}, {"id": 1012, "seek": 608904, "start": 6089.76, "end": 6094.32, "text": " Right? Language is always a discrete string of symbols. And the main reason why this is the", "tokens": [50400, 1779, 30, 24445, 307, 1009, 257, 27706, 6798, 295, 16944, 13, 400, 264, 2135, 1778, 983, 341, 307, 264, 50628], "temperature": 0.0, "avg_logprob": -0.1481240655958038, "compression_ratio": 1.72265625, "no_speech_prob": 0.0015724378172308207}, {"id": 1013, "seek": 608904, "start": 6094.32, "end": 6099.2, "text": " case is otherwise it wouldn't be learnable. And this discrete string of symbols that hangs in", "tokens": [50628, 1389, 307, 5911, 309, 2759, 380, 312, 1466, 712, 13, 400, 341, 27706, 6798, 295, 16944, 300, 35947, 294, 50872], "temperature": 0.0, "avg_logprob": -0.1481240655958038, "compression_ratio": 1.72265625, "no_speech_prob": 0.0015724378172308207}, {"id": 1014, "seek": 608904, "start": 6099.2, "end": 6107.28, "text": " this thin air between speakers has to be constructed and deconstructed or reused for", "tokens": [50872, 341, 5862, 1988, 1296, 9518, 575, 281, 312, 17083, 293, 49473, 1757, 292, 420, 319, 4717, 337, 51276], "temperature": 0.0, "avg_logprob": -0.1481240655958038, "compression_ratio": 1.72265625, "no_speech_prob": 0.0015724378172308207}, {"id": 1015, "seek": 608904, "start": 6107.28, "end": 6112.24, "text": " constructing a mental representation using limited resources, something like a stack", "tokens": [51276, 39969, 257, 4973, 10290, 1228, 5567, 3593, 11, 746, 411, 257, 8630, 51524], "temperature": 0.0, "avg_logprob": -0.1481240655958038, "compression_ratio": 1.72265625, "no_speech_prob": 0.0015724378172308207}, {"id": 1016, "seek": 608904, "start": 6112.24, "end": 6117.04, "text": " depth of not more than four, because while language can be defined in such a way that", "tokens": [51524, 7161, 295, 406, 544, 813, 1451, 11, 570, 1339, 2856, 393, 312, 7642, 294, 1270, 257, 636, 300, 51764], "temperature": 0.0, "avg_logprob": -0.1481240655958038, "compression_ratio": 1.72265625, "no_speech_prob": 0.0015724378172308207}, {"id": 1017, "seek": 611704, "start": 6117.04, "end": 6122.0, "text": " it's infinitely recursive, our own mind is incapable of facilitating deep recursion,", "tokens": [50364, 309, 311, 36227, 20560, 488, 11, 527, 1065, 1575, 307, 44174, 295, 47558, 2452, 20560, 313, 11, 50612], "temperature": 0.0, "avg_logprob": -0.10482096090549375, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.0008555183303542435}, {"id": 1018, "seek": 611704, "start": 6122.0, "end": 6127.84, "text": " because it only emulates it, right? So, it needs to be simple. And all the natural languages are", "tokens": [50612, 570, 309, 787, 846, 26192, 309, 11, 558, 30, 407, 11, 309, 2203, 281, 312, 2199, 13, 400, 439, 264, 3303, 8650, 366, 50904], "temperature": 0.0, "avg_logprob": -0.10482096090549375, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.0008555183303542435}, {"id": 1019, "seek": 611704, "start": 6127.84, "end": 6135.28, "text": " solutions to this design requirement. Find a learnable method to map mental representations", "tokens": [50904, 6547, 281, 341, 1715, 11695, 13, 11809, 257, 1466, 712, 3170, 281, 4471, 4973, 33358, 51276], "temperature": 0.0, "avg_logprob": -0.10482096090549375, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.0008555183303542435}, {"id": 1020, "seek": 611704, "start": 6135.28, "end": 6141.28, "text": " into discrete strings of symbols. And this is done in a collaborative process, right?", "tokens": [51276, 666, 27706, 13985, 295, 16944, 13, 400, 341, 307, 1096, 294, 257, 16555, 1399, 11, 558, 30, 51576], "temperature": 0.0, "avg_logprob": -0.10482096090549375, "compression_ratio": 1.5676855895196506, "no_speech_prob": 0.0008555183303542435}, {"id": 1021, "seek": 614128, "start": 6141.92, "end": 6147.04, "text": " Basically, language is invented by groups of people, not just by individuals, for the most", "tokens": [50396, 8537, 11, 2856, 307, 14479, 538, 3935, 295, 561, 11, 406, 445, 538, 5346, 11, 337, 264, 881, 50652], "temperature": 0.0, "avg_logprob": -0.13278390650163618, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.011311798356473446}, {"id": 1022, "seek": 614128, "start": 6147.04, "end": 6151.12, "text": " part. There is no reason why an individual couldn't do this. You can, in the same way as you can play", "tokens": [50652, 644, 13, 821, 307, 572, 1778, 983, 364, 2609, 2809, 380, 360, 341, 13, 509, 393, 11, 294, 264, 912, 636, 382, 291, 393, 862, 50856], "temperature": 0.0, "avg_logprob": -0.13278390650163618, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.011311798356473446}, {"id": 1023, "seek": 614128, "start": 6151.12, "end": 6155.5199999999995, "text": " chess against yourself, you can play language games against yourself and invent your own private", "tokens": [50856, 24122, 1970, 1803, 11, 291, 393, 862, 2856, 2813, 1970, 1803, 293, 7962, 428, 1065, 4551, 51076], "temperature": 0.0, "avg_logprob": -0.13278390650163618, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.011311798356473446}, {"id": 1024, "seek": 614128, "start": 6155.5199999999995, "end": 6163.12, "text": " language. It's not an argument that I can see. It's plausible against that. But practically,", "tokens": [51076, 2856, 13, 467, 311, 406, 364, 6770, 300, 286, 393, 536, 13, 467, 311, 39925, 1970, 300, 13, 583, 15667, 11, 51456], "temperature": 0.0, "avg_logprob": -0.13278390650163618, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.011311798356473446}, {"id": 1025, "seek": 614128, "start": 6163.12, "end": 6170.16, "text": " it's a tool to transfer information in a large degree. And GPT suites language is not the result", "tokens": [51456, 309, 311, 257, 2290, 281, 5003, 1589, 294, 257, 2416, 4314, 13, 400, 26039, 51, 459, 3324, 2856, 307, 406, 264, 1874, 51808], "temperature": 0.0, "avg_logprob": -0.13278390650163618, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.011311798356473446}, {"id": 1026, "seek": 617016, "start": 6170.16, "end": 6175.36, "text": " of this interactive learning. It's a result of looking at the linguistic utterances of people", "tokens": [50364, 295, 341, 15141, 2539, 13, 467, 311, 257, 1874, 295, 1237, 412, 264, 43002, 17567, 2676, 295, 561, 50624], "temperature": 0.0, "avg_logprob": -0.11954388576271259, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.0017804978415369987}, {"id": 1027, "seek": 617016, "start": 6175.36, "end": 6181.68, "text": " as they are typed out in the internet in a non-interactive fashion. So, GPT suites doesn't", "tokens": [50624, 382, 436, 366, 33941, 484, 294, 264, 4705, 294, 257, 2107, 12, 5106, 12596, 6700, 13, 407, 11, 26039, 51, 459, 3324, 1177, 380, 50940], "temperature": 0.0, "avg_logprob": -0.11954388576271259, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.0017804978415369987}, {"id": 1028, "seek": 617016, "start": 6181.68, "end": 6187.36, "text": " learn semantics in the same way as we do. We start out with understanding semantics indexically by", "tokens": [50940, 1466, 4361, 45298, 294, 264, 912, 636, 382, 321, 360, 13, 492, 722, 484, 365, 3701, 4361, 45298, 8186, 984, 538, 51224], "temperature": 0.0, "avg_logprob": -0.11954388576271259, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.0017804978415369987}, {"id": 1029, "seek": 617016, "start": 6187.36, "end": 6193.76, "text": " pointing at the features in our perceptual environment. And then we learn syntax, we learn", "tokens": [51224, 12166, 412, 264, 4122, 294, 527, 43276, 901, 2823, 13, 400, 550, 321, 1466, 28431, 11, 321, 1466, 51544], "temperature": 0.0, "avg_logprob": -0.11954388576271259, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.0017804978415369987}, {"id": 1030, "seek": 617016, "start": 6193.76, "end": 6199.599999999999, "text": " how to translate this into linguistic symbols. And then we learn style, that is, the particular way", "tokens": [51544, 577, 281, 13799, 341, 666, 43002, 16944, 13, 400, 550, 321, 1466, 3758, 11, 300, 307, 11, 264, 1729, 636, 51836], "temperature": 0.0, "avg_logprob": -0.11954388576271259, "compression_ratio": 1.762081784386617, "no_speech_prob": 0.0017804978415369987}, {"id": 1031, "seek": 619960, "start": 6199.6, "end": 6206.400000000001, "text": " in which linguistic symbols can be arranged to communicate efficiently and to convey additional", "tokens": [50364, 294, 597, 43002, 16944, 393, 312, 18721, 281, 7890, 19621, 293, 281, 16965, 4497, 50704], "temperature": 0.0, "avg_logprob": -0.12246709236731897, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.0012433544034138322}, {"id": 1032, "seek": 619960, "start": 6206.400000000001, "end": 6215.200000000001, "text": " layers of meaning by the shape of our utterances. And in GPT 3, the order is inverted. GPT 3 basically", "tokens": [50704, 7914, 295, 3620, 538, 264, 3909, 295, 527, 17567, 2676, 13, 400, 294, 26039, 51, 805, 11, 264, 1668, 307, 38969, 13, 26039, 51, 805, 1936, 51144], "temperature": 0.0, "avg_logprob": -0.12246709236731897, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.0012433544034138322}, {"id": 1033, "seek": 619960, "start": 6216.4800000000005, "end": 6222.320000000001, "text": " starts out with style and syntax and learns semantics as the long tail of style.", "tokens": [51208, 3719, 484, 365, 3758, 293, 28431, 293, 27152, 4361, 45298, 382, 264, 938, 6838, 295, 3758, 13, 51500], "temperature": 0.0, "avg_logprob": -0.12246709236731897, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.0012433544034138322}, {"id": 1034, "seek": 622232, "start": 6223.04, "end": 6229.679999999999, "text": " Right? So it's, in some sense, the wrong way around. And it's amazing that it converges at all.", "tokens": [50400, 1779, 30, 407, 309, 311, 11, 294, 512, 2020, 11, 264, 2085, 636, 926, 13, 400, 309, 311, 2243, 300, 309, 9652, 2880, 412, 439, 13, 50732], "temperature": 0.0, "avg_logprob": -0.11728285843471312, "compression_ratio": 1.6289752650176679, "no_speech_prob": 0.0025497395545244217}, {"id": 1035, "seek": 622232, "start": 6229.679999999999, "end": 6235.44, "text": " There has been in the early days of computer linguistics, rich discussion with philosophers", "tokens": [50732, 821, 575, 668, 294, 264, 2440, 1708, 295, 3820, 21766, 6006, 11, 4593, 5017, 365, 36839, 51020], "temperature": 0.0, "avg_logprob": -0.11728285843471312, "compression_ratio": 1.6289752650176679, "no_speech_prob": 0.0025497395545244217}, {"id": 1036, "seek": 622232, "start": 6235.44, "end": 6239.679999999999, "text": " who still haven't updated, who thought that you cannot learn semantics without interaction", "tokens": [51020, 567, 920, 2378, 380, 10588, 11, 567, 1194, 300, 291, 2644, 1466, 4361, 45298, 1553, 9285, 51232], "temperature": 0.0, "avg_logprob": -0.11728285843471312, "compression_ratio": 1.6289752650176679, "no_speech_prob": 0.0025497395545244217}, {"id": 1037, "seek": 622232, "start": 6239.679999999999, "end": 6245.2, "text": " context, without embodiment, without having symbols that are grounded in perception.", "tokens": [51232, 4319, 11, 1553, 28935, 2328, 11, 1553, 1419, 16944, 300, 366, 23535, 294, 12860, 13, 51508], "temperature": 0.0, "avg_logprob": -0.11728285843471312, "compression_ratio": 1.6289752650176679, "no_speech_prob": 0.0025497395545244217}, {"id": 1038, "seek": 622232, "start": 6245.2, "end": 6251.5199999999995, "text": " But GPT 3 shows that it's possible to learn semantics to some degree only by looking at language.", "tokens": [51508, 583, 26039, 51, 805, 3110, 300, 309, 311, 1944, 281, 1466, 4361, 45298, 281, 512, 4314, 787, 538, 1237, 412, 2856, 13, 51824], "temperature": 0.0, "avg_logprob": -0.11728285843471312, "compression_ratio": 1.6289752650176679, "no_speech_prob": 0.0025497395545244217}, {"id": 1039, "seek": 625232, "start": 6252.32, "end": 6257.04, "text": " And you can see that it's semantics because you can ask GPT 3 for instance to perform certain", "tokens": [50364, 400, 291, 393, 536, 300, 309, 311, 4361, 45298, 570, 291, 393, 1029, 26039, 51, 805, 337, 5197, 281, 2042, 1629, 50600], "temperature": 0.0, "avg_logprob": -0.11494764848188921, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.00035117860534228384}, {"id": 1040, "seek": 625232, "start": 6257.04, "end": 6262.08, "text": " linguistics transformations or to add small numbers to each other and so on. And it's capable", "tokens": [50600, 21766, 6006, 34852, 420, 281, 909, 1359, 3547, 281, 1184, 661, 293, 370, 322, 13, 400, 309, 311, 8189, 50852], "temperature": 0.0, "avg_logprob": -0.11494764848188921, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.00035117860534228384}, {"id": 1041, "seek": 625232, "start": 6262.08, "end": 6266.88, "text": " of doing that, which is a semantic operation that has a causal structure that is being addressed by", "tokens": [50852, 295, 884, 300, 11, 597, 307, 257, 47982, 6916, 300, 575, 257, 38755, 3877, 300, 307, 885, 13847, 538, 51092], "temperature": 0.0, "avg_logprob": -0.11494764848188921, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.00035117860534228384}, {"id": 1042, "seek": 625232, "start": 6266.88, "end": 6272.96, "text": " an linguistic prompt. And GPT 3 is able to verify in some sense whether it was able to conform", "tokens": [51092, 364, 43002, 12391, 13, 400, 26039, 51, 805, 307, 1075, 281, 16888, 294, 512, 2020, 1968, 309, 390, 1075, 281, 18975, 51396], "temperature": 0.0, "avg_logprob": -0.11494764848188921, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.00035117860534228384}, {"id": 1043, "seek": 625232, "start": 6272.96, "end": 6278.08, "text": " to that specification. So these are proper semantics, but they are impoverished compared", "tokens": [51396, 281, 300, 31256, 13, 407, 613, 366, 2296, 4361, 45298, 11, 457, 436, 366, 704, 3570, 4729, 5347, 51652], "temperature": 0.0, "avg_logprob": -0.11494764848188921, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.00035117860534228384}, {"id": 1044, "seek": 627808, "start": 6278.08, "end": 6283.6, "text": " to human semantics because there are the result of something like bubbling of", "tokens": [50364, 281, 1952, 4361, 45298, 570, 456, 366, 264, 1874, 295, 746, 411, 46360, 295, 50640], "temperature": 0.0, "avg_logprob": -0.10690489221126476, "compression_ratio": 1.7109375, "no_speech_prob": 0.0032652586232870817}, {"id": 1045, "seek": 627808, "start": 6283.6, "end": 6288.5599999999995, "text": " extrapolation only without interaction. But this doesn't mean that we cannot do this.", "tokens": [50640, 48224, 399, 787, 1553, 9285, 13, 583, 341, 1177, 380, 914, 300, 321, 2644, 360, 341, 13, 50888], "temperature": 0.0, "avg_logprob": -0.10690489221126476, "compression_ratio": 1.7109375, "no_speech_prob": 0.0032652586232870817}, {"id": 1046, "seek": 627808, "start": 6288.5599999999995, "end": 6293.2, "text": " In principle, we can build systems that interact with the world and that are serving", "tokens": [50888, 682, 8665, 11, 321, 393, 1322, 3652, 300, 4648, 365, 264, 1002, 293, 300, 366, 8148, 51120], "temperature": 0.0, "avg_logprob": -0.10690489221126476, "compression_ratio": 1.7109375, "no_speech_prob": 0.0032652586232870817}, {"id": 1047, "seek": 627808, "start": 6293.2, "end": 6297.28, "text": " instrumental purposes and satisfying their needs and doing this and that do on their learning.", "tokens": [51120, 17388, 9932, 293, 18348, 641, 2203, 293, 884, 341, 293, 300, 360, 322, 641, 2539, 13, 51324], "temperature": 0.0, "avg_logprob": -0.10690489221126476, "compression_ratio": 1.7109375, "no_speech_prob": 0.0032652586232870817}, {"id": 1048, "seek": 627808, "start": 6297.28, "end": 6302.24, "text": " It's just the present set of algorithms and technologies that we have are not very amenable to", "tokens": [51324, 467, 311, 445, 264, 1974, 992, 295, 14642, 293, 7943, 300, 321, 362, 366, 406, 588, 18497, 712, 281, 51572], "temperature": 0.0, "avg_logprob": -0.10690489221126476, "compression_ratio": 1.7109375, "no_speech_prob": 0.0032652586232870817}, {"id": 1049, "seek": 630224, "start": 6302.24, "end": 6312.88, "text": " this. Let me just push this a little bit further. I mean, I often because I think that the GPT 3", "tokens": [50364, 341, 13, 961, 385, 445, 2944, 341, 257, 707, 857, 3052, 13, 286, 914, 11, 286, 2049, 570, 286, 519, 300, 264, 26039, 51, 805, 50896], "temperature": 0.0, "avg_logprob": -0.18153143988715278, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.020034166052937508}, {"id": 1050, "seek": 630224, "start": 6312.88, "end": 6318.639999999999, "text": " and the kind of text or the prompt based responses that you get out of Clip certainly", "tokens": [50896, 293, 264, 733, 295, 2487, 420, 264, 12391, 2361, 13019, 300, 291, 483, 484, 295, 2033, 647, 3297, 51184], "temperature": 0.0, "avg_logprob": -0.18153143988715278, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.020034166052937508}, {"id": 1051, "seek": 630224, "start": 6318.639999999999, "end": 6322.96, "text": " are interesting because I'm just wondering to what extent we ourselves are trained a bit like a", "tokens": [51184, 366, 1880, 570, 286, 478, 445, 6359, 281, 437, 8396, 321, 4175, 366, 8895, 257, 857, 411, 257, 51400], "temperature": 0.0, "avg_logprob": -0.18153143988715278, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.020034166052937508}, {"id": 1052, "seek": 630224, "start": 6322.96, "end": 6327.84, "text": " neural network in the sense that we have certain inputs. You go to school of architecture and you", "tokens": [51400, 18161, 3209, 294, 264, 2020, 300, 321, 362, 1629, 15743, 13, 509, 352, 281, 1395, 295, 9482, 293, 291, 51644], "temperature": 0.0, "avg_logprob": -0.18153143988715278, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.020034166052937508}, {"id": 1053, "seek": 632784, "start": 6327.84, "end": 6333.52, "text": " are schooled in a certain way of thinking, you know, that's what you do. And so when we think of", "tokens": [50364, 366, 1395, 292, 294, 257, 1629, 636, 295, 1953, 11, 291, 458, 11, 300, 311, 437, 291, 360, 13, 400, 370, 562, 321, 519, 295, 50648], "temperature": 0.0, "avg_logprob": -0.11209901989015758, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.011613136157393456}, {"id": 1054, "seek": 632784, "start": 6333.52, "end": 6338.24, "text": " something, someone says a house, then if I'm trained in the modernist thing, I will think about", "tokens": [50648, 746, 11, 1580, 1619, 257, 1782, 11, 550, 498, 286, 478, 8895, 294, 264, 4363, 468, 551, 11, 286, 486, 519, 466, 50884], "temperature": 0.0, "avg_logprob": -0.11209901989015758, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.011613136157393456}, {"id": 1055, "seek": 632784, "start": 6338.24, "end": 6343.4400000000005, "text": " the certain images, at least something will be conjured up in my mind that is quite controlled", "tokens": [50884, 264, 1629, 5267, 11, 412, 1935, 746, 486, 312, 20295, 3831, 493, 294, 452, 1575, 300, 307, 1596, 10164, 51144], "temperature": 0.0, "avg_logprob": -0.11209901989015758, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.011613136157393456}, {"id": 1056, "seek": 632784, "start": 6343.4400000000005, "end": 6350.0, "text": " in a way by the training that I've had. So I'm struck that actually maybe there are not that", "tokens": [51144, 294, 257, 636, 538, 264, 3097, 300, 286, 600, 632, 13, 407, 286, 478, 13159, 300, 767, 1310, 456, 366, 406, 300, 51472], "temperature": 0.0, "avg_logprob": -0.11209901989015758, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.011613136157393456}, {"id": 1057, "seek": 632784, "start": 6350.0, "end": 6355.12, "text": " there's more similarities there than we think, whether we have an automatic reflex about certain", "tokens": [51472, 456, 311, 544, 24197, 456, 813, 321, 519, 11, 1968, 321, 362, 364, 12509, 23802, 466, 1629, 51728], "temperature": 0.0, "avg_logprob": -0.11209901989015758, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.011613136157393456}, {"id": 1058, "seek": 635512, "start": 6355.12, "end": 6361.04, "text": " things based on our conditioning. Maybe I could just, Bob, while you're thinking about that question,", "tokens": [50364, 721, 2361, 322, 527, 21901, 13, 2704, 286, 727, 445, 11, 6085, 11, 1339, 291, 434, 1953, 466, 300, 1168, 11, 50660], "temperature": 0.0, "avg_logprob": -0.1714411648837003, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.00282411091029644}, {"id": 1059, "seek": 635512, "start": 6361.04, "end": 6368.5599999999995, "text": " show you a quick video of the kind of work that we architects have been doing using this.", "tokens": [50660, 855, 291, 257, 1702, 960, 295, 264, 733, 295, 589, 300, 321, 30491, 362, 668, 884, 1228, 341, 13, 51036], "temperature": 0.0, "avg_logprob": -0.1714411648837003, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.00282411091029644}, {"id": 1060, "seek": 635512, "start": 6369.36, "end": 6379.36, "text": " So this is a work of an architect from Peru, who's now teaching. And it's using Clip and VQ GAN.", "tokens": [51076, 407, 341, 307, 257, 589, 295, 364, 6331, 490, 31571, 11, 567, 311, 586, 4571, 13, 400, 309, 311, 1228, 2033, 647, 293, 691, 48, 460, 1770, 13, 51576], "temperature": 0.0, "avg_logprob": -0.1714411648837003, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.00282411091029644}, {"id": 1061, "seek": 635512, "start": 6379.36, "end": 6383.84, "text": " And there are a series of prompts, there are a series of pre prompts. So there are three very", "tokens": [51576, 400, 456, 366, 257, 2638, 295, 41095, 11, 456, 366, 257, 2638, 295, 659, 41095, 13, 407, 456, 366, 1045, 588, 51800], "temperature": 0.0, "avg_logprob": -0.1714411648837003, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.00282411091029644}, {"id": 1062, "seek": 638384, "start": 6383.84, "end": 6389.360000000001, "text": " progressive architects names were put in there. Zaha Hadid, Tom Main, Wolf Pricks, you probably don't", "tokens": [50364, 16131, 30491, 5288, 645, 829, 294, 456, 13, 1176, 4408, 12298, 327, 11, 5041, 12383, 11, 16634, 2114, 7663, 11, 291, 1391, 500, 380, 50640], "temperature": 0.0, "avg_logprob": -0.18613848060068458, "compression_ratio": 1.5551181102362204, "no_speech_prob": 0.005172994453459978}, {"id": 1063, "seek": 638384, "start": 6389.360000000001, "end": 6394.8, "text": " know these guys, but they're kind of Gary like slightly crazy guys, right? And then there's a", "tokens": [50640, 458, 613, 1074, 11, 457, 436, 434, 733, 295, 13788, 411, 4748, 3219, 1074, 11, 558, 30, 400, 550, 456, 311, 257, 50912], "temperature": 0.0, "avg_logprob": -0.18613848060068458, "compression_ratio": 1.5551181102362204, "no_speech_prob": 0.005172994453459978}, {"id": 1064, "seek": 638384, "start": 6394.8, "end": 6401.84, "text": " second prompt, which is the main prompt is futuristic Indian temple. And this is the kind of thing", "tokens": [50912, 1150, 12391, 11, 597, 307, 264, 2135, 12391, 307, 44932, 6427, 10184, 13, 400, 341, 307, 264, 733, 295, 551, 51264], "temperature": 0.0, "avg_logprob": -0.18613848060068458, "compression_ratio": 1.5551181102362204, "no_speech_prob": 0.005172994453459978}, {"id": 1065, "seek": 638384, "start": 6401.84, "end": 6408.96, "text": " that gets hallucinated by this thing. And I often wonder, you know, whether, yeah, my question would", "tokens": [51264, 300, 2170, 35212, 5410, 538, 341, 551, 13, 400, 286, 2049, 2441, 11, 291, 458, 11, 1968, 11, 1338, 11, 452, 1168, 576, 51620], "temperature": 0.0, "avg_logprob": -0.18613848060068458, "compression_ratio": 1.5551181102362204, "no_speech_prob": 0.005172994453459978}, {"id": 1066, "seek": 640896, "start": 6408.96, "end": 6416.72, "text": " be this, it wouldn't be fair to say that actually that we are trained, we are trained by our experiences", "tokens": [50364, 312, 341, 11, 309, 2759, 380, 312, 3143, 281, 584, 300, 767, 300, 321, 366, 8895, 11, 321, 366, 8895, 538, 527, 5235, 50752], "temperature": 0.0, "avg_logprob": -0.17281553060701577, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0016907956451177597}, {"id": 1067, "seek": 640896, "start": 6416.72, "end": 6422.16, "text": " and our education as a form, obviously, indoctrination to think of certain images to conjure", "tokens": [50752, 293, 527, 3309, 382, 257, 1254, 11, 2745, 11, 13770, 349, 81, 2486, 281, 519, 295, 1629, 5267, 281, 20295, 540, 51024], "temperature": 0.0, "avg_logprob": -0.17281553060701577, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0016907956451177597}, {"id": 1068, "seek": 640896, "start": 6422.16, "end": 6430.8, "text": " them up in a way almost like Clip does. Okay, yes. So there is a big similarity in the way in which", "tokens": [51024, 552, 493, 294, 257, 636, 1920, 411, 2033, 647, 775, 13, 1033, 11, 2086, 13, 407, 456, 307, 257, 955, 32194, 294, 264, 636, 294, 597, 51456], "temperature": 0.0, "avg_logprob": -0.17281553060701577, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0016907956451177597}, {"id": 1069, "seek": 640896, "start": 6430.8, "end": 6436.32, "text": " these models work and the way in which our own mind works. Difficulty is the way in which", "tokens": [51456, 613, 5245, 589, 293, 264, 636, 294, 597, 527, 1065, 1575, 1985, 13, 35940, 1786, 5773, 307, 264, 636, 294, 597, 51732], "temperature": 0.0, "avg_logprob": -0.17281553060701577, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0016907956451177597}, {"id": 1070, "seek": 643632, "start": 6436.32, "end": 6443.599999999999, "text": " the GPS we got to these representations or a big gun. And it's basically the gun is fed lots and", "tokens": [50364, 264, 19462, 321, 658, 281, 613, 33358, 420, 257, 955, 3874, 13, 400, 309, 311, 1936, 264, 3874, 307, 4636, 3195, 293, 50728], "temperature": 0.0, "avg_logprob": -0.19433431191877884, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.003761276137083769}, {"id": 1071, "seek": 643632, "start": 6443.599999999999, "end": 6453.12, "text": " lots of separate distinct images that are annotated with text as a reference to, for instance,", "tokens": [50728, 3195, 295, 4994, 10644, 5267, 300, 366, 25339, 770, 365, 2487, 382, 257, 6408, 281, 11, 337, 5197, 11, 51204], "temperature": 0.0, "avg_logprob": -0.19433431191877884, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.003761276137083769}, {"id": 1072, "seek": 643632, "start": 6453.12, "end": 6457.5199999999995, "text": " the subtitle of the image that the creator gave it or even to a complete description of what's", "tokens": [51204, 264, 30706, 306, 295, 264, 3256, 300, 264, 14181, 2729, 309, 420, 754, 281, 257, 3566, 3855, 295, 437, 311, 51424], "temperature": 0.0, "avg_logprob": -0.19433431191877884, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.003761276137083769}, {"id": 1073, "seek": 643632, "start": 6457.5199999999995, "end": 6465.84, "text": " happening in the image. And by looking at millions of these images in batch processing,", "tokens": [51424, 2737, 294, 264, 3256, 13, 400, 538, 1237, 412, 6803, 295, 613, 5267, 294, 15245, 9007, 11, 51840], "temperature": 0.0, "avg_logprob": -0.19433431191877884, "compression_ratio": 1.626086956521739, "no_speech_prob": 0.003761276137083769}, {"id": 1074, "seek": 646584, "start": 6465.84, "end": 6470.64, "text": " doing statistics over these images, you build up the structure of the network.", "tokens": [50364, 884, 12523, 670, 613, 5267, 11, 291, 1322, 493, 264, 3877, 295, 264, 3209, 13, 50604], "temperature": 0.0, "avg_logprob": -0.09755043068317452, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0014094847720116377}, {"id": 1075, "seek": 646584, "start": 6470.64, "end": 6475.68, "text": " And the network ultimately converges to an efficient representation of this latent space", "tokens": [50604, 400, 264, 3209, 6284, 9652, 2880, 281, 364, 7148, 10290, 295, 341, 48994, 1901, 50856], "temperature": 0.0, "avg_logprob": -0.09755043068317452, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0014094847720116377}, {"id": 1076, "seek": 646584, "start": 6475.68, "end": 6481.04, "text": " of representations. And in our own mind, this representation is built in a slightly different", "tokens": [50856, 295, 33358, 13, 400, 294, 527, 1065, 1575, 11, 341, 10290, 307, 3094, 294, 257, 4748, 819, 51124], "temperature": 0.0, "avg_logprob": -0.09755043068317452, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0014094847720116377}, {"id": 1077, "seek": 646584, "start": 6481.04, "end": 6487.28, "text": " way. We train up layer by layer. We start out with an extremely limited reality. And this limited", "tokens": [51124, 636, 13, 492, 3847, 493, 4583, 538, 4583, 13, 492, 722, 484, 365, 364, 4664, 5567, 4103, 13, 400, 341, 5567, 51436], "temperature": 0.0, "avg_logprob": -0.09755043068317452, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0014094847720116377}, {"id": 1078, "seek": 646584, "start": 6487.28, "end": 6495.2, "text": " reality in the first place is maybe it's similar to what's being described in the first book of", "tokens": [51436, 4103, 294, 264, 700, 1081, 307, 1310, 309, 311, 2531, 281, 437, 311, 885, 7619, 294, 264, 700, 1446, 295, 51832], "temperature": 0.0, "avg_logprob": -0.09755043068317452, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0014094847720116377}, {"id": 1079, "seek": 649520, "start": 6495.2, "end": 6500.4, "text": " Genesis in the Bible. I think that the first book of Genesis in the Bible is misunderstood", "tokens": [50364, 20587, 294, 264, 6544, 13, 286, 519, 300, 264, 700, 1446, 295, 20587, 294, 264, 6544, 307, 33870, 50624], "temperature": 0.0, "avg_logprob": -0.13141325087774366, "compression_ratio": 1.7127272727272727, "no_speech_prob": 0.0010312485974282026}, {"id": 1080, "seek": 649520, "start": 6500.4, "end": 6505.84, "text": " by the Christians or mistranslated as a myth about the creation of a physical universe by a", "tokens": [50624, 538, 264, 12254, 420, 3544, 25392, 38539, 382, 257, 9474, 466, 264, 8016, 295, 257, 4001, 6445, 538, 257, 50896], "temperature": 0.0, "avg_logprob": -0.13141325087774366, "compression_ratio": 1.7127272727272727, "no_speech_prob": 0.0010312485974282026}, {"id": 1081, "seek": 649520, "start": 6505.84, "end": 6511.76, "text": " supernatural being. And this also leads to the confusion of our culture of what that physics", "tokens": [50896, 25678, 885, 13, 400, 341, 611, 6689, 281, 264, 15075, 295, 527, 3713, 295, 437, 300, 10649, 51192], "temperature": 0.0, "avg_logprob": -0.13141325087774366, "compression_ratio": 1.7127272727272727, "no_speech_prob": 0.0010312485974282026}, {"id": 1082, "seek": 649520, "start": 6511.76, "end": 6516.4, "text": " contains, light and darkness and sky and ground and so on, right? These are clearly constructions", "tokens": [51192, 8306, 11, 1442, 293, 11262, 293, 5443, 293, 2727, 293, 370, 322, 11, 558, 30, 1981, 366, 4448, 7690, 626, 51424], "temperature": 0.0, "avg_logprob": -0.13141325087774366, "compression_ratio": 1.7127272727272727, "no_speech_prob": 0.0010312485974282026}, {"id": 1083, "seek": 649520, "start": 6516.4, "end": 6521.2, "text": " inside of the mind categories that have us to make sense of the perceptual patterns in a coherent", "tokens": [51424, 1854, 295, 264, 1575, 10479, 300, 362, 505, 281, 652, 2020, 295, 264, 43276, 901, 8294, 294, 257, 36239, 51664], "temperature": 0.0, "avg_logprob": -0.13141325087774366, "compression_ratio": 1.7127272727272727, "no_speech_prob": 0.0010312485974282026}, {"id": 1084, "seek": 652120, "start": 6521.2, "end": 6525.28, "text": " way. The fact that there are not that many ways in which you can arrange the perceptual patterns", "tokens": [50364, 636, 13, 440, 1186, 300, 456, 366, 406, 300, 867, 2098, 294, 597, 291, 393, 9424, 264, 43276, 901, 8294, 50568], "temperature": 0.0, "avg_logprob": -0.09399556684064435, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.0007205700385384262}, {"id": 1085, "seek": 652120, "start": 6525.28, "end": 6529.36, "text": " doesn't mean that the reality is structured like this. It just means that if you have a brain with", "tokens": [50568, 1177, 380, 914, 300, 264, 4103, 307, 18519, 411, 341, 13, 467, 445, 1355, 300, 498, 291, 362, 257, 3567, 365, 50772], "temperature": 0.0, "avg_logprob": -0.09399556684064435, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.0007205700385384262}, {"id": 1086, "seek": 652120, "start": 6529.36, "end": 6533.599999999999, "text": " these parameters, this is the best way to compress physics into a predictable model.", "tokens": [50772, 613, 9834, 11, 341, 307, 264, 1151, 636, 281, 14778, 10649, 666, 257, 27737, 2316, 13, 50984], "temperature": 0.0, "avg_logprob": -0.09399556684064435, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.0007205700385384262}, {"id": 1087, "seek": 652120, "start": 6534.32, "end": 6540.08, "text": " And so what you need to make sure, what you need to do to make sure that you can interpret reality", "tokens": [51020, 400, 370, 437, 291, 643, 281, 652, 988, 11, 437, 291, 643, 281, 360, 281, 652, 988, 300, 291, 393, 7302, 4103, 51308], "temperature": 0.0, "avg_logprob": -0.09399556684064435, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.0007205700385384262}, {"id": 1088, "seek": 652120, "start": 6540.08, "end": 6547.5199999999995, "text": " is first you need to figure out how to entice neural oscillators to make light, to represent", "tokens": [51308, 307, 700, 291, 643, 281, 2573, 484, 577, 281, 948, 573, 18161, 18225, 3391, 281, 652, 1442, 11, 281, 2906, 51680], "temperature": 0.0, "avg_logprob": -0.09399556684064435, "compression_ratio": 1.7811320754716982, "no_speech_prob": 0.0007205700385384262}, {"id": 1089, "seek": 654752, "start": 6547.52, "end": 6554.400000000001, "text": " contrast. And this is basically the creation of light and darkness and how to separate the light", "tokens": [50364, 8712, 13, 400, 341, 307, 1936, 264, 8016, 295, 1442, 293, 11262, 293, 577, 281, 4994, 264, 1442, 50708], "temperature": 0.0, "avg_logprob": -0.11709652176822524, "compression_ratio": 1.8160377358490567, "no_speech_prob": 0.0006984132924117148}, {"id": 1090, "seek": 654752, "start": 6554.400000000001, "end": 6559.76, "text": " from the darkness. And then you arrange these contrasts along multiple dimensions and then you", "tokens": [50708, 490, 264, 11262, 13, 400, 550, 291, 9424, 613, 8712, 82, 2051, 3866, 12819, 293, 550, 291, 50976], "temperature": 0.0, "avg_logprob": -0.11709652176822524, "compression_ratio": 1.8160377358490567, "no_speech_prob": 0.0006984132924117148}, {"id": 1091, "seek": 654752, "start": 6559.76, "end": 6566.400000000001, "text": " discover the modalities of perception like vision and sound and you discover that the visual domain", "tokens": [50976, 4411, 264, 1072, 16110, 295, 12860, 411, 5201, 293, 1626, 293, 291, 4411, 300, 264, 5056, 9274, 51308], "temperature": 0.0, "avg_logprob": -0.11709652176822524, "compression_ratio": 1.8160377358490567, "no_speech_prob": 0.0006984132924117148}, {"id": 1092, "seek": 654752, "start": 6566.400000000001, "end": 6571.52, "text": " can be arranged in a space and you can align the space with your vestibular system so you got", "tokens": [51308, 393, 312, 18721, 294, 257, 1901, 293, 291, 393, 7975, 264, 1901, 365, 428, 15814, 897, 1040, 1185, 370, 291, 658, 51564], "temperature": 0.0, "avg_logprob": -0.11709652176822524, "compression_ratio": 1.8160377358490567, "no_speech_prob": 0.0006984132924117148}, {"id": 1093, "seek": 657152, "start": 6571.76, "end": 6578.320000000001, "text": " up and down. And you got a plane that is two-dimensional on the ground down and you got", "tokens": [50376, 493, 293, 760, 13, 400, 291, 658, 257, 5720, 300, 307, 732, 12, 18759, 322, 264, 2727, 760, 293, 291, 658, 50704], "temperature": 0.0, "avg_logprob": -0.09840688619527731, "compression_ratio": 2.0643776824034337, "no_speech_prob": 0.004902075044810772}, {"id": 1094, "seek": 657152, "start": 6578.320000000001, "end": 6583.120000000001, "text": " a space that is three-dimensional on top of the two-dimensional one and then you have basically", "tokens": [50704, 257, 1901, 300, 307, 1045, 12, 18759, 322, 1192, 295, 264, 732, 12, 18759, 472, 293, 550, 291, 362, 1936, 50944], "temperature": 0.0, "avg_logprob": -0.09840688619527731, "compression_ratio": 2.0643776824034337, "no_speech_prob": 0.004902075044810772}, {"id": 1095, "seek": 657152, "start": 6583.92, "end": 6589.84, "text": " the sky and the ground that you have constructed, right, created in your own mind. So the mind is", "tokens": [50984, 264, 5443, 293, 264, 2727, 300, 291, 362, 17083, 11, 558, 11, 2942, 294, 428, 1065, 1575, 13, 407, 264, 1575, 307, 51280], "temperature": 0.0, "avg_logprob": -0.09840688619527731, "compression_ratio": 2.0643776824034337, "no_speech_prob": 0.004902075044810772}, {"id": 1096, "seek": 657152, "start": 6589.84, "end": 6595.4400000000005, "text": " constructing these categories and then it discovers the materials, the solids and the liquids and the", "tokens": [51280, 39969, 613, 10479, 293, 550, 309, 44522, 264, 5319, 11, 264, 38536, 293, 264, 38960, 293, 264, 51560], "temperature": 0.0, "avg_logprob": -0.09840688619527731, "compression_ratio": 2.0643776824034337, "no_speech_prob": 0.004902075044810772}, {"id": 1097, "seek": 657152, "start": 6595.4400000000005, "end": 6601.120000000001, "text": " organic shapes and the animated agents in the world that move around in it. And then it discovers", "tokens": [51560, 10220, 10854, 293, 264, 18947, 12554, 294, 264, 1002, 300, 1286, 926, 294, 309, 13, 400, 550, 309, 44522, 51844], "temperature": 0.0, "avg_logprob": -0.09840688619527731, "compression_ratio": 2.0643776824034337, "no_speech_prob": 0.004902075044810772}, {"id": 1098, "seek": 660112, "start": 6601.12, "end": 6606.08, "text": " the features that it cannot directly interact with but perceive like celestial objects in the", "tokens": [50364, 264, 4122, 300, 309, 2644, 3838, 4648, 365, 457, 20281, 411, 41003, 6565, 294, 264, 50612], "temperature": 0.0, "avg_logprob": -0.09567926367934869, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.00027361951651982963}, {"id": 1099, "seek": 660112, "start": 6606.08, "end": 6610.8, "text": " background and then it discovers all the constructs, the plants and the animals and gives them all", "tokens": [50612, 3678, 293, 550, 309, 44522, 439, 264, 7690, 82, 11, 264, 5972, 293, 264, 4882, 293, 2709, 552, 439, 50848], "temperature": 0.0, "avg_logprob": -0.09567926367934869, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.00027361951651982963}, {"id": 1100, "seek": 660112, "start": 6610.8, "end": 6616.16, "text": " their names. This is this gradual construction that happens during our cognitive development", "tokens": [50848, 641, 5288, 13, 639, 307, 341, 32890, 6435, 300, 2314, 1830, 527, 15605, 3250, 51116], "temperature": 0.0, "avg_logprob": -0.09567926367934869, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.00027361951651982963}, {"id": 1101, "seek": 660112, "start": 6616.16, "end": 6622.48, "text": " where we train up our model of reality layer by layer and then last but not least we create a person", "tokens": [51116, 689, 321, 3847, 493, 527, 2316, 295, 4103, 4583, 538, 4583, 293, 550, 1036, 457, 406, 1935, 321, 1884, 257, 954, 51432], "temperature": 0.0, "avg_logprob": -0.09567926367934869, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.00027361951651982963}, {"id": 1102, "seek": 660112, "start": 6623.5199999999995, "end": 6629.5199999999995, "text": " and this person is created in the image of this constructive mind as the conscious observer that", "tokens": [51484, 293, 341, 954, 307, 2942, 294, 264, 3256, 295, 341, 30223, 1575, 382, 264, 6648, 27878, 300, 51784], "temperature": 0.0, "avg_logprob": -0.09567926367934869, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.00027361951651982963}, {"id": 1103, "seek": 662952, "start": 6629.52, "end": 6635.52, "text": " is makes sense of reality but it's slightly different. While it is a conscious observer,", "tokens": [50364, 307, 1669, 2020, 295, 4103, 457, 309, 311, 4748, 819, 13, 3987, 309, 307, 257, 6648, 27878, 11, 50664], "temperature": 0.0, "avg_logprob": -0.12166083300555194, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.0007547644781880081}, {"id": 1104, "seek": 662952, "start": 6635.52, "end": 6641.76, "text": " it is created as man and woman, it's created as a human being that believes that it has a gender,", "tokens": [50664, 309, 307, 2942, 382, 587, 293, 3059, 11, 309, 311, 2942, 382, 257, 1952, 885, 300, 12307, 300, 309, 575, 257, 7898, 11, 50976], "temperature": 0.0, "avg_logprob": -0.12166083300555194, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.0007547644781880081}, {"id": 1105, "seek": 662952, "start": 6641.76, "end": 6644.88, "text": " that it has a relationship to the world, that it's desires, it's human desires,", "tokens": [50976, 300, 309, 575, 257, 2480, 281, 264, 1002, 11, 300, 309, 311, 18005, 11, 309, 311, 1952, 18005, 11, 51132], "temperature": 0.0, "avg_logprob": -0.12166083300555194, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.0007547644781880081}, {"id": 1106, "seek": 662952, "start": 6644.88, "end": 6650.56, "text": " it's social embedding matter. And initially this is created often in the third person so when you", "tokens": [51132, 309, 311, 2093, 12240, 3584, 1871, 13, 400, 9105, 341, 307, 2942, 2049, 294, 264, 2636, 954, 370, 562, 291, 51416], "temperature": 0.0, "avg_logprob": -0.12166083300555194, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.0007547644781880081}, {"id": 1107, "seek": 662952, "start": 6651.200000000001, "end": 6657.6, "text": " talk to small children they often start by referring to the organism that they are modeling", "tokens": [51448, 751, 281, 1359, 2227, 436, 2049, 722, 538, 13761, 281, 264, 24128, 300, 436, 366, 15983, 51768], "temperature": 0.0, "avg_logprob": -0.12166083300555194, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.0007547644781880081}, {"id": 1108, "seek": 665760, "start": 6657.6, "end": 6662.400000000001, "text": " in the third person. And then at some point they start looking through the eyes of that character", "tokens": [50364, 294, 264, 2636, 954, 13, 400, 550, 412, 512, 935, 436, 722, 1237, 807, 264, 2575, 295, 300, 2517, 50604], "temperature": 0.0, "avg_logprob": -0.08618544340133667, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0006983113125897944}, {"id": 1109, "seek": 665760, "start": 6662.400000000001, "end": 6667.6, "text": " and think they are that character and the original world creator that is modeling reality and creating", "tokens": [50604, 293, 519, 436, 366, 300, 2517, 293, 264, 3380, 1002, 14181, 300, 307, 15983, 4103, 293, 4084, 50864], "temperature": 0.0, "avg_logprob": -0.08618544340133667, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0006983113125897944}, {"id": 1110, "seek": 665760, "start": 6667.6, "end": 6675.84, "text": " and shaping it becomes a subservient perception module to this personal human agent. And so", "tokens": [50864, 293, 25945, 309, 3643, 257, 2090, 1978, 1196, 12860, 10088, 281, 341, 2973, 1952, 9461, 13, 400, 370, 51276], "temperature": 0.0, "avg_logprob": -0.08618544340133667, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0006983113125897944}, {"id": 1111, "seek": 665760, "start": 6676.8, "end": 6683.200000000001, "text": " this gap in the creation of this new thing is represented in children losing their memories", "tokens": [51324, 341, 7417, 294, 264, 8016, 295, 341, 777, 551, 307, 10379, 294, 2227, 7027, 641, 8495, 51644], "temperature": 0.0, "avg_logprob": -0.08618544340133667, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0006983113125897944}, {"id": 1112, "seek": 668320, "start": 6684.0, "end": 6688.24, "text": " and you have a baby you will often notice that they do have coherent memories they're also able", "tokens": [50404, 293, 291, 362, 257, 3186, 291, 486, 2049, 3449, 300, 436, 360, 362, 36239, 8495, 436, 434, 611, 1075, 50616], "temperature": 0.0, "avg_logprob": -0.08408373052423651, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.0011323587968945503}, {"id": 1113, "seek": 668320, "start": 6688.24, "end": 6695.12, "text": " to talk about them once they start talking between nine and months and one and a half or two years", "tokens": [50616, 281, 751, 466, 552, 1564, 436, 722, 1417, 1296, 4949, 293, 2493, 293, 472, 293, 257, 1922, 420, 732, 924, 50960], "temperature": 0.0, "avg_logprob": -0.08408373052423651, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.0011323587968945503}, {"id": 1114, "seek": 668320, "start": 6695.12, "end": 6700.24, "text": " and then at some point there is a gap and they lose the access to the memories that they had", "tokens": [50960, 293, 550, 412, 512, 935, 456, 307, 257, 7417, 293, 436, 3624, 264, 2105, 281, 264, 8495, 300, 436, 632, 51216], "temperature": 0.0, "avg_logprob": -0.08408373052423651, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.0011323587968945503}, {"id": 1115, "seek": 668320, "start": 6700.24, "end": 6706.0, "text": " before that time because they constitute themselves as a new system that indexes the memories from a", "tokens": [51216, 949, 300, 565, 570, 436, 41658, 2969, 382, 257, 777, 1185, 300, 8186, 279, 264, 8495, 490, 257, 51504], "temperature": 0.0, "avg_logprob": -0.08408373052423651, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.0011323587968945503}, {"id": 1116, "seek": 668320, "start": 6706.0, "end": 6711.76, "text": " new perspective. And I suspect this is what's being alluded to in Genesis. I don't know whether", "tokens": [51504, 777, 4585, 13, 400, 286, 9091, 341, 307, 437, 311, 885, 33919, 281, 294, 20587, 13, 286, 500, 380, 458, 1968, 51792], "temperature": 0.0, "avg_logprob": -0.08408373052423651, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.0011323587968945503}, {"id": 1117, "seek": 671176, "start": 6711.76, "end": 6716.8, "text": " it's literally true but in this interpretation whether it's a better interpretation than a Christian", "tokens": [50364, 309, 311, 3736, 2074, 457, 294, 341, 14174, 1968, 309, 311, 257, 1101, 14174, 813, 257, 5778, 50616], "temperature": 0.0, "avg_logprob": -0.09367270739573352, "compression_ratio": 1.7712177121771218, "no_speech_prob": 0.0019250867189839482}, {"id": 1118, "seek": 671176, "start": 6716.8, "end": 6721.6, "text": " one but it seems to be much more plausible to me that this is what's described there it's this", "tokens": [50616, 472, 457, 309, 2544, 281, 312, 709, 544, 39925, 281, 385, 300, 341, 307, 437, 311, 7619, 456, 309, 311, 341, 50856], "temperature": 0.0, "avg_logprob": -0.09367270739573352, "compression_ratio": 1.7712177121771218, "no_speech_prob": 0.0019250867189839482}, {"id": 1119, "seek": 671176, "start": 6721.6, "end": 6727.68, "text": " cognitive development of a system that starts to arrange the features into maps of reality", "tokens": [50856, 15605, 3250, 295, 257, 1185, 300, 3719, 281, 9424, 264, 4122, 666, 11317, 295, 4103, 51160], "temperature": 0.0, "avg_logprob": -0.09367270739573352, "compression_ratio": 1.7712177121771218, "no_speech_prob": 0.0019250867189839482}, {"id": 1120, "seek": 671176, "start": 6727.68, "end": 6732.24, "text": " that build on top of each other become a more and more complex until you discover your own agency", "tokens": [51160, 300, 1322, 322, 1192, 295, 1184, 661, 1813, 257, 544, 293, 544, 3997, 1826, 291, 4411, 428, 1065, 7934, 51388], "temperature": 0.0, "avg_logprob": -0.09367270739573352, "compression_ratio": 1.7712177121771218, "no_speech_prob": 0.0019250867189839482}, {"id": 1121, "seek": 671176, "start": 6732.24, "end": 6737.84, "text": " and use this as a perspective to make sense of reality. And this is what you're not doing in AI", "tokens": [51388, 293, 764, 341, 382, 257, 4585, 281, 652, 2020, 295, 4103, 13, 400, 341, 307, 437, 291, 434, 406, 884, 294, 7318, 51668], "temperature": 0.0, "avg_logprob": -0.09367270739573352, "compression_ratio": 1.7712177121771218, "no_speech_prob": 0.0019250867189839482}, {"id": 1122, "seek": 673784, "start": 6737.84, "end": 6742.4800000000005, "text": " systems right now but there is no reason why we shouldn't be doing it ultimately and there are a", "tokens": [50364, 3652, 558, 586, 457, 456, 307, 572, 1778, 983, 321, 4659, 380, 312, 884, 309, 6284, 293, 456, 366, 257, 50596], "temperature": 0.0, "avg_logprob": -0.18898133264071698, "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.004389789421111345}, {"id": 1123, "seek": 673784, "start": 6742.4800000000005, "end": 6746.96, "text": " number of people which do actively think about this for instance George Steen and Bournemouth MIT", "tokens": [50596, 1230, 295, 561, 597, 360, 13022, 519, 466, 341, 337, 5197, 7136, 3592, 268, 293, 35866, 25989, 2178, 13100, 50820], "temperature": 0.0, "avg_logprob": -0.18898133264071698, "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.004389789421111345}, {"id": 1124, "seek": 673784, "start": 6746.96, "end": 6752.64, "text": " and others. Can I just pick up on the other question of kids because I think that's incredibly", "tokens": [50820, 293, 2357, 13, 1664, 286, 445, 1888, 493, 322, 264, 661, 1168, 295, 2301, 570, 286, 519, 300, 311, 6252, 51104], "temperature": 0.0, "avg_logprob": -0.18898133264071698, "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.004389789421111345}, {"id": 1125, "seek": 673784, "start": 6752.64, "end": 6757.04, "text": " fascinating for all sorts of reasons. There's a book by Kevin Wattle at Gautam when he kind of", "tokens": [51104, 10343, 337, 439, 7527, 295, 4112, 13, 821, 311, 257, 1446, 538, 9954, 343, 3327, 412, 460, 1375, 335, 562, 415, 733, 295, 51324], "temperature": 0.0, "avg_logprob": -0.18898133264071698, "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.004389789421111345}, {"id": 1126, "seek": 673784, "start": 6757.04, "end": 6762.88, "text": " he says that we learn to role play through being a kid you know we've what we learn to be the CEO", "tokens": [51324, 415, 1619, 300, 321, 1466, 281, 3090, 862, 807, 885, 257, 1636, 291, 458, 321, 600, 437, 321, 1466, 281, 312, 264, 9282, 51616], "temperature": 0.0, "avg_logprob": -0.18898133264071698, "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.004389789421111345}, {"id": 1127, "seek": 673784, "start": 6762.88, "end": 6767.12, "text": " of a company by you know playing doctors and nurses and one of the cowboys and Indians of", "tokens": [51616, 295, 257, 2237, 538, 291, 458, 2433, 8778, 293, 17446, 293, 472, 295, 264, 8408, 31638, 293, 23838, 295, 51828], "temperature": 0.0, "avg_logprob": -0.18898133264071698, "compression_ratio": 1.6627906976744187, "no_speech_prob": 0.004389789421111345}, {"id": 1128, "seek": 676712, "start": 6767.12, "end": 6773.92, "text": " God knows what else when you're kids and so which is interesting and I buy that the question that I", "tokens": [50364, 1265, 3255, 437, 1646, 562, 291, 434, 2301, 293, 370, 597, 307, 1880, 293, 286, 2256, 300, 264, 1168, 300, 286, 50704], "temperature": 0.0, "avg_logprob": -0.15789053837458292, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0018020961433649063}, {"id": 1129, "seek": 676712, "start": 6775.2, "end": 6781.76, "text": " would want to put you is if we see ourselves as a model and see ourselves through that logic", "tokens": [50768, 576, 528, 281, 829, 291, 307, 498, 321, 536, 4175, 382, 257, 2316, 293, 536, 4175, 807, 300, 9952, 51096], "temperature": 0.0, "avg_logprob": -0.15789053837458292, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0018020961433649063}, {"id": 1130, "seek": 676712, "start": 6782.4, "end": 6788.24, "text": " what role does the actual model i.e. the doll or the teddy bear play in a kid you know because that", "tokens": [51128, 437, 3090, 775, 264, 3539, 2316, 741, 13, 68, 13, 264, 2722, 420, 264, 45116, 6155, 862, 294, 257, 1636, 291, 458, 570, 300, 51420], "temperature": 0.0, "avg_logprob": -0.15789053837458292, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0018020961433649063}, {"id": 1131, "seek": 676712, "start": 6788.24, "end": 6796.16, "text": " is in some sense is animated by the kid about a child what is what is the role of because that's", "tokens": [51420, 307, 294, 512, 2020, 307, 18947, 538, 264, 1636, 466, 257, 1440, 437, 307, 437, 307, 264, 3090, 295, 570, 300, 311, 51816], "temperature": 0.0, "avg_logprob": -0.15789053837458292, "compression_ratio": 1.760180995475113, "no_speech_prob": 0.0018020961433649063}, {"id": 1132, "seek": 679616, "start": 6796.16, "end": 6800.4, "text": " to my mind it's fascinating dolls and teddy bears how do you see their their role?", "tokens": [50364, 281, 452, 1575, 309, 311, 10343, 29134, 293, 45116, 17276, 577, 360, 291, 536, 641, 641, 3090, 30, 50576], "temperature": 0.0, "avg_logprob": -0.11263965476642955, "compression_ratio": 1.6713615023474178, "no_speech_prob": 0.00047907073167152703}, {"id": 1133, "seek": 679616, "start": 6804.72, "end": 6809.44, "text": " There is a thing that I noticed when I was in Madagascar they saw a lot of children", "tokens": [50792, 821, 307, 257, 551, 300, 286, 5694, 562, 286, 390, 294, 5326, 559, 4806, 289, 436, 1866, 257, 688, 295, 2227, 51028], "temperature": 0.0, "avg_logprob": -0.11263965476642955, "compression_ratio": 1.6713615023474178, "no_speech_prob": 0.00047907073167152703}, {"id": 1134, "seek": 679616, "start": 6809.44, "end": 6816.639999999999, "text": " that lived on the street by themselves and the there were kids that took care of other kids", "tokens": [51028, 300, 5152, 322, 264, 4838, 538, 2969, 293, 264, 456, 645, 2301, 300, 1890, 1127, 295, 661, 2301, 51388], "temperature": 0.0, "avg_logprob": -0.11263965476642955, "compression_ratio": 1.6713615023474178, "no_speech_prob": 0.00047907073167152703}, {"id": 1135, "seek": 679616, "start": 6817.36, "end": 6824.24, "text": " it was mostly girls who did this and I suspect that the dolls that you give our girls or that our", "tokens": [51424, 309, 390, 5240, 4519, 567, 630, 341, 293, 286, 9091, 300, 264, 29134, 300, 291, 976, 527, 4519, 420, 300, 527, 51768], "temperature": 0.0, "avg_logprob": -0.11263965476642955, "compression_ratio": 1.6713615023474178, "no_speech_prob": 0.00047907073167152703}, {"id": 1136, "seek": 682424, "start": 6824.24, "end": 6833.12, "text": " girls demand are a substitute for biologically adaptation that is that kids look after other", "tokens": [50364, 4519, 4733, 366, 257, 15802, 337, 3228, 17157, 21549, 300, 307, 300, 2301, 574, 934, 661, 50808], "temperature": 0.0, "avg_logprob": -0.10479137030514804, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.001808428904041648}, {"id": 1137, "seek": 682424, "start": 6833.12, "end": 6838.96, "text": " kids but the parents are blocking the fields or hunting or doing other things and often we think", "tokens": [50808, 2301, 457, 264, 3152, 366, 17776, 264, 7909, 420, 12599, 420, 884, 661, 721, 293, 2049, 321, 519, 51100], "temperature": 0.0, "avg_logprob": -0.10479137030514804, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.001808428904041648}, {"id": 1138, "seek": 682424, "start": 6838.96, "end": 6844.08, "text": " that kids would be callous and could not be trusted with babies but maybe they can I've seen it in", "tokens": [51100, 300, 2301, 576, 312, 818, 563, 293, 727, 406, 312, 16034, 365, 10917, 457, 1310, 436, 393, 286, 600, 1612, 309, 294, 51356], "temperature": 0.0, "avg_logprob": -0.10479137030514804, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.001808428904041648}, {"id": 1139, "seek": 682424, "start": 6844.08, "end": 6851.679999999999, "text": " Madagascar so I've seen little kids that were mostly girls that were barely strong enough to lift up", "tokens": [51356, 5326, 559, 4806, 289, 370, 286, 600, 1612, 707, 2301, 300, 645, 5240, 4519, 300, 645, 10268, 2068, 1547, 281, 5533, 493, 51736], "temperature": 0.0, "avg_logprob": -0.10479137030514804, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.001808428904041648}, {"id": 1140, "seek": 685168, "start": 6851.68, "end": 6857.52, "text": " a baby because they were only like five or so and still seem to be able to take care of them full", "tokens": [50364, 257, 3186, 570, 436, 645, 787, 411, 1732, 420, 370, 293, 920, 1643, 281, 312, 1075, 281, 747, 1127, 295, 552, 1577, 50656], "temperature": 0.0, "avg_logprob": -0.057342795438544696, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.0033736308105289936}, {"id": 1141, "seek": 685168, "start": 6857.52, "end": 6865.280000000001, "text": " time so I think that's an adaptation that we want to take care of others and especially of children", "tokens": [50656, 565, 370, 286, 519, 300, 311, 364, 21549, 300, 321, 528, 281, 747, 1127, 295, 2357, 293, 2318, 295, 2227, 51044], "temperature": 0.0, "avg_logprob": -0.057342795438544696, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.0033736308105289936}, {"id": 1142, "seek": 685168, "start": 6865.92, "end": 6871.360000000001, "text": " and that we want to interact with other agents and build a communion with them and the teddy", "tokens": [51076, 293, 300, 321, 528, 281, 4648, 365, 661, 12554, 293, 1322, 257, 42808, 365, 552, 293, 264, 45116, 51348], "temperature": 0.0, "avg_logprob": -0.057342795438544696, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.0033736308105289936}, {"id": 1143, "seek": 685168, "start": 6871.360000000001, "end": 6877.68, "text": " bears and dolls are a simple non labor intensive way of substituting for this.", "tokens": [51348, 17276, 293, 29134, 366, 257, 2199, 2107, 5938, 18957, 636, 295, 26441, 10861, 337, 341, 13, 51664], "temperature": 0.0, "avg_logprob": -0.057342795438544696, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.0033736308105289936}, {"id": 1144, "seek": 687768, "start": 6878.64, "end": 6882.72, "text": " Maybe I could put an architectural dimension to that what about the dolls house I mean because", "tokens": [50412, 2704, 286, 727, 829, 364, 26621, 10139, 281, 300, 437, 466, 264, 29134, 1782, 286, 914, 570, 50616], "temperature": 0.0, "avg_logprob": -0.10070812817916129, "compression_ratio": 1.8509803921568628, "no_speech_prob": 0.0021139036398380995}, {"id": 1145, "seek": 687768, "start": 6882.72, "end": 6887.68, "text": " that is an architectural space in which the doll operates how do you yes it's a play space and", "tokens": [50616, 300, 307, 364, 26621, 1901, 294, 597, 264, 2722, 22577, 577, 360, 291, 2086, 309, 311, 257, 862, 1901, 293, 50864], "temperature": 0.0, "avg_logprob": -0.10070812817916129, "compression_ratio": 1.8509803921568628, "no_speech_prob": 0.0021139036398380995}, {"id": 1146, "seek": 687768, "start": 6887.68, "end": 6895.280000000001, "text": " the purpose of play is the creation of training data right so you use this to create situations", "tokens": [50864, 264, 4334, 295, 862, 307, 264, 8016, 295, 3097, 1412, 558, 370, 291, 764, 341, 281, 1884, 6851, 51244], "temperature": 0.0, "avg_logprob": -0.10070812817916129, "compression_ratio": 1.8509803921568628, "no_speech_prob": 0.0021139036398380995}, {"id": 1147, "seek": 687768, "start": 6895.280000000001, "end": 6900.88, "text": " that could exist in the real world at dramatically reduced cost so you can't ignore the cost while", "tokens": [51244, 300, 727, 2514, 294, 264, 957, 1002, 412, 17548, 9212, 2063, 370, 291, 393, 380, 11200, 264, 2063, 1339, 51524], "temperature": 0.0, "avg_logprob": -0.10070812817916129, "compression_ratio": 1.8509803921568628, "no_speech_prob": 0.0021139036398380995}, {"id": 1148, "seek": 687768, "start": 6900.88, "end": 6905.360000000001, "text": " you're playing because you don't play for the expected reward you play for your ability", "tokens": [51524, 291, 434, 2433, 570, 291, 500, 380, 862, 337, 264, 5176, 7782, 291, 862, 337, 428, 3485, 51748], "temperature": 0.0, "avg_logprob": -0.10070812817916129, "compression_ratio": 1.8509803921568628, "no_speech_prob": 0.0021139036398380995}, {"id": 1149, "seek": 690536, "start": 6906.32, "end": 6912.719999999999, "text": " as a way of exploration and not for the exploitation for being able to use this later", "tokens": [50412, 382, 257, 636, 295, 16197, 293, 406, 337, 264, 33122, 337, 885, 1075, 281, 764, 341, 1780, 50732], "temperature": 0.0, "avg_logprob": -0.07564540391557673, "compression_ratio": 1.7952380952380953, "no_speech_prob": 0.0061882296577095985}, {"id": 1150, "seek": 690536, "start": 6912.719999999999, "end": 6917.92, "text": " and it's also something that you can observe in cats cats do play a lot and the purpose of play", "tokens": [50732, 293, 309, 311, 611, 746, 300, 291, 393, 11441, 294, 11111, 11111, 360, 862, 257, 688, 293, 264, 4334, 295, 862, 50992], "temperature": 0.0, "avg_logprob": -0.07564540391557673, "compression_ratio": 1.7952380952380953, "no_speech_prob": 0.0061882296577095985}, {"id": 1151, "seek": 690536, "start": 6917.92, "end": 6924.24, "text": " in cats is that they're able to hunt better right and while they play exert a lot of energy but", "tokens": [50992, 294, 11111, 307, 300, 436, 434, 1075, 281, 12454, 1101, 558, 293, 1339, 436, 862, 31941, 257, 688, 295, 2281, 457, 51308], "temperature": 0.0, "avg_logprob": -0.07564540391557673, "compression_ratio": 1.7952380952380953, "no_speech_prob": 0.0061882296577095985}, {"id": 1152, "seek": 690536, "start": 6924.24, "end": 6930.88, "text": " it's mostly done because doing this in the world or there is more costly overall and the same thing", "tokens": [51308, 309, 311, 5240, 1096, 570, 884, 341, 294, 264, 1002, 420, 456, 307, 544, 28328, 4787, 293, 264, 912, 551, 51640], "temperature": 0.0, "avg_logprob": -0.07564540391557673, "compression_ratio": 1.7952380952380953, "no_speech_prob": 0.0061882296577095985}, {"id": 1153, "seek": 693088, "start": 6930.88, "end": 6935.84, "text": " happens in human beings the reason why children are fascinated with doll houses I remember that it", "tokens": [50364, 2314, 294, 1952, 8958, 264, 1778, 983, 2227, 366, 24597, 365, 2722, 8078, 286, 1604, 300, 309, 50612], "temperature": 0.0, "avg_logprob": -0.10279602579551168, "compression_ratio": 1.7969924812030076, "no_speech_prob": 0.07899025082588196}, {"id": 1154, "seek": 693088, "start": 6935.84, "end": 6942.32, "text": " was but I was even more interested with building virtual cities so I used to draw very big maps", "tokens": [50612, 390, 457, 286, 390, 754, 544, 3102, 365, 2390, 6374, 6486, 370, 286, 1143, 281, 2642, 588, 955, 11317, 50936], "temperature": 0.0, "avg_logprob": -0.10279602579551168, "compression_ratio": 1.7969924812030076, "no_speech_prob": 0.07899025082588196}, {"id": 1155, "seek": 693088, "start": 6942.32, "end": 6946.96, "text": " that covered the floor of my room of cities with different houses in it and explored how people", "tokens": [50936, 300, 5343, 264, 4123, 295, 452, 1808, 295, 6486, 365, 819, 8078, 294, 309, 293, 24016, 577, 561, 51168], "temperature": 0.0, "avg_logprob": -0.10279602579551168, "compression_ratio": 1.7969924812030076, "no_speech_prob": 0.07899025082588196}, {"id": 1156, "seek": 693088, "start": 6946.96, "end": 6951.12, "text": " would live in there and how goods and resources would travel in the city and I found this very", "tokens": [51168, 576, 1621, 294, 456, 293, 577, 10179, 293, 3593, 576, 3147, 294, 264, 2307, 293, 286, 1352, 341, 588, 51376], "temperature": 0.0, "avg_logprob": -0.10279602579551168, "compression_ratio": 1.7969924812030076, "no_speech_prob": 0.07899025082588196}, {"id": 1157, "seek": 693088, "start": 6951.12, "end": 6957.52, "text": " exciting and the the relational space in the doll house between the different members of the", "tokens": [51376, 4670, 293, 264, 264, 38444, 1901, 294, 264, 2722, 1782, 1296, 264, 819, 2679, 295, 264, 51696], "temperature": 0.0, "avg_logprob": -0.10279602579551168, "compression_ratio": 1.7969924812030076, "no_speech_prob": 0.07899025082588196}, {"id": 1158, "seek": 695752, "start": 6957.52, "end": 6962.88, "text": " family were not that interesting to me but I suspect that's because I'm pretty stereotypical", "tokens": [50364, 1605, 645, 406, 300, 1880, 281, 385, 457, 286, 9091, 300, 311, 570, 286, 478, 1238, 41182, 34061, 50632], "temperature": 0.0, "avg_logprob": -0.0908017011032891, "compression_ratio": 1.7185185185185186, "no_speech_prob": 0.0014057473745197058}, {"id": 1159, "seek": 695752, "start": 6962.88, "end": 6968.080000000001, "text": " male in this regard I'm much more interested in systems conflicts and explosions than I am in", "tokens": [50632, 7133, 294, 341, 3843, 286, 478, 709, 544, 3102, 294, 3652, 19807, 293, 36872, 813, 286, 669, 294, 50892], "temperature": 0.0, "avg_logprob": -0.0908017011032891, "compression_ratio": 1.7185185185185186, "no_speech_prob": 0.0014057473745197058}, {"id": 1160, "seek": 695752, "start": 6968.080000000001, "end": 6974.0, "text": " human relationships pretty fault and I only discovered the beauty of human psychological", "tokens": [50892, 1952, 6159, 1238, 7441, 293, 286, 787, 6941, 264, 6643, 295, 1952, 14346, 51188], "temperature": 0.0, "avg_logprob": -0.0908017011032891, "compression_ratio": 1.7185185185185186, "no_speech_prob": 0.0014057473745197058}, {"id": 1161, "seek": 695752, "start": 6974.0, "end": 6979.52, "text": " structure and relationships later in my life so maybe just to follow up so I would to give Matt", "tokens": [51188, 3877, 293, 6159, 1780, 294, 452, 993, 370, 1310, 445, 281, 1524, 493, 370, 286, 576, 281, 976, 7397, 51464], "temperature": 0.0, "avg_logprob": -0.0908017011032891, "compression_ratio": 1.7185185185185186, "no_speech_prob": 0.0014057473745197058}, {"id": 1162, "seek": 695752, "start": 6979.52, "end": 6984.0, "text": " a chance to ask question but just follow up so where does the architectural model fit within", "tokens": [51464, 257, 2931, 281, 1029, 1168, 457, 445, 1524, 493, 370, 689, 775, 264, 26621, 2316, 3318, 1951, 51688], "temperature": 0.0, "avg_logprob": -0.0908017011032891, "compression_ratio": 1.7185185185185186, "no_speech_prob": 0.0014057473745197058}, {"id": 1163, "seek": 698400, "start": 6984.0, "end": 6988.32, "text": " this logic I mean you're doing your kind of sim city for and then you've got the kids doll's house", "tokens": [50364, 341, 9952, 286, 914, 291, 434, 884, 428, 733, 295, 1034, 2307, 337, 293, 550, 291, 600, 658, 264, 2301, 2722, 311, 1782, 50580], "temperature": 0.0, "avg_logprob": -0.08935970443863052, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.0022094957530498505}, {"id": 1164, "seek": 698400, "start": 6988.32, "end": 6993.44, "text": " and things how do you see the what do you I mean of course at one level the architectural model is", "tokens": [50580, 293, 721, 577, 360, 291, 536, 264, 437, 360, 291, 286, 914, 295, 1164, 412, 472, 1496, 264, 26621, 2316, 307, 50836], "temperature": 0.0, "avg_logprob": -0.08935970443863052, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.0022094957530498505}, {"id": 1165, "seek": 698400, "start": 6993.44, "end": 6999.6, "text": " just a scaled down model of the potential building but do you see it invested with any other potentiality", "tokens": [50836, 445, 257, 36039, 760, 2316, 295, 264, 3995, 2390, 457, 360, 291, 536, 309, 13104, 365, 604, 661, 3995, 507, 51144], "temperature": 0.0, "avg_logprob": -0.08935970443863052, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.0022094957530498505}, {"id": 1166, "seek": 698400, "start": 7001.12, "end": 7007.2, "text": " I think that's tied to the notion of aesthetics and aesthetics is what you get when you take your", "tokens": [51220, 286, 519, 300, 311, 9601, 281, 264, 10710, 295, 35517, 293, 35517, 307, 437, 291, 483, 562, 291, 747, 428, 51524], "temperature": 0.0, "avg_logprob": -0.08935970443863052, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.0022094957530498505}, {"id": 1167, "seek": 698400, "start": 7007.2, "end": 7011.36, "text": " the preferences that you start out with and extrapolate them into a sustainable world", "tokens": [51524, 264, 21910, 300, 291, 722, 484, 365, 293, 48224, 473, 552, 666, 257, 11235, 1002, 51732], "temperature": 0.0, "avg_logprob": -0.08935970443863052, "compression_ratio": 1.8377358490566038, "no_speech_prob": 0.0022094957530498505}, {"id": 1168, "seek": 701136, "start": 7012.24, "end": 7016.96, "text": " you're basically systemic thinking where you add one more layers until you discover enough", "tokens": [50408, 291, 434, 1936, 23789, 1953, 689, 291, 909, 472, 544, 7914, 1826, 291, 4411, 1547, 50644], "temperature": 0.0, "avg_logprob": -0.09735152061949386, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.0008289425750263035}, {"id": 1169, "seek": 701136, "start": 7016.96, "end": 7023.44, "text": " symmetries to digest your initial preferences and make them instrumental to to achieving this", "tokens": [50644, 14232, 302, 2244, 281, 13884, 428, 5883, 21910, 293, 652, 552, 17388, 281, 281, 19626, 341, 50968], "temperature": 0.0, "avg_logprob": -0.09735152061949386, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.0008289425750263035}, {"id": 1170, "seek": 701136, "start": 7023.44, "end": 7028.639999999999, "text": " aesthetics but it's also apparent in moral development we start often out with moral", "tokens": [50968, 35517, 457, 309, 311, 611, 18335, 294, 9723, 3250, 321, 722, 2049, 484, 365, 9723, 51228], "temperature": 0.0, "avg_logprob": -0.09735152061949386, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.0008289425750263035}, {"id": 1171, "seek": 701136, "start": 7028.639999999999, "end": 7034.639999999999, "text": " reflexes certain priors that we are born with innate tendencies to consider a certain behavior", "tokens": [51228, 23802, 279, 1629, 1790, 830, 300, 321, 366, 4232, 365, 41766, 45488, 281, 1949, 257, 1629, 5223, 51528], "temperature": 0.0, "avg_logprob": -0.09735152061949386, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.0008289425750263035}, {"id": 1172, "seek": 701136, "start": 7034.639999999999, "end": 7040.88, "text": " to be moral or immoral full stop unconditionally not because we understand what it's good for", "tokens": [51528, 281, 312, 9723, 420, 3397, 16819, 1577, 1590, 34959, 15899, 406, 570, 321, 1223, 437, 309, 311, 665, 337, 51840], "temperature": 0.0, "avg_logprob": -0.09735152061949386, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.0008289425750263035}, {"id": 1173, "seek": 704088, "start": 7040.88, "end": 7045.84, "text": " but because we feel this feels moral or this feels immoral and this can also misguide us", "tokens": [50364, 457, 570, 321, 841, 341, 3417, 9723, 420, 341, 3417, 3397, 16819, 293, 341, 393, 611, 3346, 2794, 482, 505, 50612], "temperature": 0.0, "avg_logprob": -0.07228821151110591, "compression_ratio": 1.883817427385892, "no_speech_prob": 0.0008420116500928998}, {"id": 1174, "seek": 704088, "start": 7045.84, "end": 7053.2, "text": " because ultimately ethics is about the negotiation of conflicts of interest under", "tokens": [50612, 570, 6284, 19769, 307, 466, 264, 27573, 295, 19807, 295, 1179, 833, 50980], "temperature": 0.0, "avg_logprob": -0.07228821151110591, "compression_ratio": 1.883817427385892, "no_speech_prob": 0.0008420116500928998}, {"id": 1175, "seek": 704088, "start": 7053.2, "end": 7057.28, "text": " conditions of shared purpose and this requires that you understand the aesthetics the world", "tokens": [50980, 4487, 295, 5507, 4334, 293, 341, 7029, 300, 291, 1223, 264, 35517, 264, 1002, 51184], "temperature": 0.0, "avg_logprob": -0.07228821151110591, "compression_ratio": 1.883817427385892, "no_speech_prob": 0.0008420116500928998}, {"id": 1176, "seek": 704088, "start": 7057.28, "end": 7064.0, "text": " in which you want to operate behavior is only good or bad if you can connect it to an expectation", "tokens": [51184, 294, 597, 291, 528, 281, 9651, 5223, 307, 787, 665, 420, 1578, 498, 291, 393, 1745, 309, 281, 364, 14334, 51520], "temperature": 0.0, "avg_logprob": -0.07228821151110591, "compression_ratio": 1.883817427385892, "no_speech_prob": 0.0008420116500928998}, {"id": 1177, "seek": 704088, "start": 7064.56, "end": 7070.24, "text": " of a world that is worse or better and to be worse or better you need criteria for what makes", "tokens": [51548, 295, 257, 1002, 300, 307, 5324, 420, 1101, 293, 281, 312, 5324, 420, 1101, 291, 643, 11101, 337, 437, 1669, 51832], "temperature": 0.0, "avg_logprob": -0.07228821151110591, "compression_ratio": 1.883817427385892, "no_speech_prob": 0.0008420116500928998}, {"id": 1178, "seek": 707024, "start": 7070.24, "end": 7076.08, "text": " the world worse or better and this I would say that to be good it needs to be sustainable it needs", "tokens": [50364, 264, 1002, 5324, 420, 1101, 293, 341, 286, 576, 584, 300, 281, 312, 665, 309, 2203, 281, 312, 11235, 309, 2203, 50656], "temperature": 0.0, "avg_logprob": -0.07745038761812098, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.0008825050899758935}, {"id": 1179, "seek": 707024, "start": 7076.08, "end": 7085.44, "text": " to actually work and it should have high complexity and complexity is in contrast for instance to", "tokens": [50656, 281, 767, 589, 293, 309, 820, 362, 1090, 14024, 293, 14024, 307, 294, 8712, 337, 5197, 281, 51124], "temperature": 0.0, "avg_logprob": -0.07745038761812098, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.0008825050899758935}, {"id": 1180, "seek": 707024, "start": 7085.44, "end": 7091.36, "text": " friction that is exerted to violence you want to minimize the friction and waste created to violence", "tokens": [51124, 17710, 300, 307, 31941, 292, 281, 6270, 291, 528, 281, 17522, 264, 17710, 293, 5964, 2942, 281, 6270, 51420], "temperature": 0.0, "avg_logprob": -0.07745038761812098, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.0008825050899758935}, {"id": 1181, "seek": 707024, "start": 7091.36, "end": 7097.84, "text": " and so on so once you discover this train of thinking and you get older many of your initial", "tokens": [51420, 293, 370, 322, 370, 1564, 291, 4411, 341, 3847, 295, 1953, 293, 291, 483, 4906, 867, 295, 428, 5883, 51744], "temperature": 0.0, "avg_logprob": -0.07745038761812098, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.0008825050899758935}, {"id": 1182, "seek": 709784, "start": 7097.84, "end": 7104.0, "text": " moral convictions get replaced by the larger aesthetic and the same is true for architecture", "tokens": [50364, 9723, 44757, 483, 10772, 538, 264, 4833, 20092, 293, 264, 912, 307, 2074, 337, 9482, 50672], "temperature": 0.0, "avg_logprob": -0.06428443927031297, "compression_ratio": 1.904, "no_speech_prob": 0.002755251945927739}, {"id": 1183, "seek": 709784, "start": 7104.0, "end": 7111.68, "text": " by architecture and you design a building or a city or a house or a room is all about how to fit", "tokens": [50672, 538, 9482, 293, 291, 1715, 257, 2390, 420, 257, 2307, 420, 257, 1782, 420, 257, 1808, 307, 439, 466, 577, 281, 3318, 51056], "temperature": 0.0, "avg_logprob": -0.06428443927031297, "compression_ratio": 1.904, "no_speech_prob": 0.002755251945927739}, {"id": 1184, "seek": 709784, "start": 7111.68, "end": 7116.4800000000005, "text": " the space that you're operating in where you make your local decisions into a larger aesthetic", "tokens": [51056, 264, 1901, 300, 291, 434, 7447, 294, 689, 291, 652, 428, 2654, 5327, 666, 257, 4833, 20092, 51296], "temperature": 0.0, "avg_logprob": -0.06428443927031297, "compression_ratio": 1.904, "no_speech_prob": 0.002755251945927739}, {"id": 1185, "seek": 709784, "start": 7116.4800000000005, "end": 7120.24, "text": " and so the deeper your understanding of the world the better your design has a chance to be", "tokens": [51296, 293, 370, 264, 7731, 428, 3701, 295, 264, 1002, 264, 1101, 428, 1715, 575, 257, 2931, 281, 312, 51484], "temperature": 0.0, "avg_logprob": -0.06428443927031297, "compression_ratio": 1.904, "no_speech_prob": 0.002755251945927739}, {"id": 1186, "seek": 709784, "start": 7120.96, "end": 7126.56, "text": " and this is what makes architecture so interesting to us I think that is that it's about seeing the", "tokens": [51520, 293, 341, 307, 437, 1669, 9482, 370, 1880, 281, 505, 286, 519, 300, 307, 300, 309, 311, 466, 2577, 264, 51800], "temperature": 0.0, "avg_logprob": -0.06428443927031297, "compression_ratio": 1.904, "no_speech_prob": 0.002755251945927739}, {"id": 1187, "seek": 712656, "start": 7127.52, "end": 7131.76, "text": " the human world that we are part of at the greatest possible depths that we can perceive", "tokens": [50412, 264, 1952, 1002, 300, 321, 366, 644, 295, 412, 264, 6636, 1944, 28439, 300, 321, 393, 20281, 50624], "temperature": 0.0, "avg_logprob": -0.11053559244895468, "compression_ratio": 1.752895752895753, "no_speech_prob": 0.0020465755369514227}, {"id": 1188, "seek": 712656, "start": 7132.4800000000005, "end": 7138.0, "text": " and extrapolate the games for as long as we can make them and then design our life inside", "tokens": [50660, 293, 48224, 473, 264, 2813, 337, 382, 938, 382, 321, 393, 652, 552, 293, 550, 1715, 527, 993, 1854, 50936], "temperature": 0.0, "avg_logprob": -0.11053559244895468, "compression_ratio": 1.752895752895753, "no_speech_prob": 0.0020465755369514227}, {"id": 1189, "seek": 712656, "start": 7138.0, "end": 7144.88, "text": " of this larger space and build things at the largest scales that we can maintain like cities,", "tokens": [50936, 295, 341, 4833, 1901, 293, 1322, 721, 412, 264, 6443, 17408, 300, 321, 393, 6909, 411, 6486, 11, 51280], "temperature": 0.0, "avg_logprob": -0.11053559244895468, "compression_ratio": 1.752895752895753, "no_speech_prob": 0.0020465755369514227}, {"id": 1190, "seek": 712656, "start": 7145.4400000000005, "end": 7150.4800000000005, "text": " nation states, society, civilizations inside of these aesthetics to realize them.", "tokens": [51308, 4790, 4368, 11, 4086, 11, 40749, 1854, 295, 613, 35517, 281, 4325, 552, 13, 51560], "temperature": 0.0, "avg_logprob": -0.11053559244895468, "compression_ratio": 1.752895752895753, "no_speech_prob": 0.0020465755369514227}, {"id": 1191, "seek": 712656, "start": 7151.360000000001, "end": 7155.92, "text": " Yeah I often say myself that I think architecture is less about the literal design of buildings but", "tokens": [51604, 865, 286, 2049, 584, 2059, 300, 286, 519, 9482, 307, 1570, 466, 264, 20411, 1715, 295, 7446, 457, 51832], "temperature": 0.0, "avg_logprob": -0.11053559244895468, "compression_ratio": 1.752895752895753, "no_speech_prob": 0.0020465755369514227}, {"id": 1192, "seek": 715592, "start": 7155.92, "end": 7163.84, "text": " about imagining a better world. So we have a question from Matt, a second question from Matt.", "tokens": [50364, 466, 27798, 257, 1101, 1002, 13, 407, 321, 362, 257, 1168, 490, 7397, 11, 257, 1150, 1168, 490, 7397, 13, 50760], "temperature": 0.0, "avg_logprob": -0.14611029624938965, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0008946756133809686}, {"id": 1193, "seek": 715592, "start": 7163.84, "end": 7170.72, "text": " Do you like to ask your question? Sure just another quick maybe a jump back into a bit more", "tokens": [50760, 1144, 291, 411, 281, 1029, 428, 1168, 30, 4894, 445, 1071, 1702, 1310, 257, 3012, 646, 666, 257, 857, 544, 51104], "temperature": 0.0, "avg_logprob": -0.14611029624938965, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0008946756133809686}, {"id": 1194, "seek": 715592, "start": 7170.72, "end": 7176.64, "text": " maybe more technical things. I'm always struck by these these images that have become really common", "tokens": [51104, 1310, 544, 6191, 721, 13, 286, 478, 1009, 13159, 538, 613, 613, 5267, 300, 362, 1813, 534, 2689, 51400], "temperature": 0.0, "avg_logprob": -0.14611029624938965, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0008946756133809686}, {"id": 1195, "seek": 715592, "start": 7176.64, "end": 7181.6, "text": " of neural networks as little dots connected by lines and you showed the cortical columns and", "tokens": [51400, 295, 18161, 9590, 382, 707, 15026, 4582, 538, 3876, 293, 291, 4712, 264, 11278, 804, 13766, 293, 51648], "temperature": 0.0, "avg_logprob": -0.14611029624938965, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0008946756133809686}, {"id": 1196, "seek": 715592, "start": 7181.6, "end": 7185.76, "text": " you showed a lot of interesting graphics that kind of looked like that but I've also recently", "tokens": [51648, 291, 4712, 257, 688, 295, 1880, 11837, 300, 733, 295, 2956, 411, 300, 457, 286, 600, 611, 3938, 51856], "temperature": 0.0, "avg_logprob": -0.14611029624938965, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0008946756133809686}, {"id": 1197, "seek": 718592, "start": 7186.88, "end": 7192.0, "text": " been struck by the neuromorphic computing stuff that's going on at Stanford and a few other places", "tokens": [50412, 668, 13159, 538, 264, 12087, 32702, 299, 15866, 1507, 300, 311, 516, 322, 412, 20374, 293, 257, 1326, 661, 3190, 50668], "temperature": 0.0, "avg_logprob": -0.08766424088251024, "compression_ratio": 1.8104575163398693, "no_speech_prob": 0.0006458391435444355}, {"id": 1198, "seek": 718592, "start": 7192.0, "end": 7198.32, "text": " about dendritic computing and sort of new advances and thinking about and and even starting to see", "tokens": [50668, 466, 274, 521, 3210, 299, 15866, 293, 1333, 295, 777, 25297, 293, 1953, 466, 293, 293, 754, 2891, 281, 536, 50984], "temperature": 0.0, "avg_logprob": -0.08766424088251024, "compression_ratio": 1.8104575163398693, "no_speech_prob": 0.0006458391435444355}, {"id": 1199, "seek": 718592, "start": 7198.32, "end": 7202.16, "text": " how what we once thought were just wires that connected all these different things and we", "tokens": [50984, 577, 437, 321, 1564, 1194, 645, 445, 15537, 300, 4582, 439, 613, 819, 721, 293, 321, 51176], "temperature": 0.0, "avg_logprob": -0.08766424088251024, "compression_ratio": 1.8104575163398693, "no_speech_prob": 0.0006458391435444355}, {"id": 1200, "seek": 718592, "start": 7202.16, "end": 7205.68, "text": " talked about connections are actually doing pre-processing in very interesting ways and I'm", "tokens": [51176, 2825, 466, 9271, 366, 767, 884, 659, 12, 41075, 278, 294, 588, 1880, 2098, 293, 286, 478, 51352], "temperature": 0.0, "avg_logprob": -0.08766424088251024, "compression_ratio": 1.8104575163398693, "no_speech_prob": 0.0006458391435444355}, {"id": 1201, "seek": 718592, "start": 7205.68, "end": 7209.92, "text": " sure you're you know a lot more about this than I do so I'm very just interested in", "tokens": [51352, 988, 291, 434, 291, 458, 257, 688, 544, 466, 341, 813, 286, 360, 370, 286, 478, 588, 445, 3102, 294, 51564], "temperature": 0.0, "avg_logprob": -0.08766424088251024, "compression_ratio": 1.8104575163398693, "no_speech_prob": 0.0006458391435444355}, {"id": 1202, "seek": 718592, "start": 7209.92, "end": 7215.04, "text": " in what's what's going on there and how that changes these questions of how much energy it", "tokens": [51564, 294, 437, 311, 437, 311, 516, 322, 456, 293, 577, 300, 2962, 613, 1651, 295, 577, 709, 2281, 309, 51820], "temperature": 0.0, "avg_logprob": -0.08766424088251024, "compression_ratio": 1.8104575163398693, "no_speech_prob": 0.0006458391435444355}, {"id": 1203, "seek": 721504, "start": 7215.04, "end": 7219.68, "text": " takes to do the computation and what maybe the future form factors might be on this kind of thing.", "tokens": [50364, 2516, 281, 360, 264, 24903, 293, 437, 1310, 264, 2027, 1254, 6771, 1062, 312, 322, 341, 733, 295, 551, 13, 50596], "temperature": 0.0, "avg_logprob": -0.13561318868614106, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0003300329262856394}, {"id": 1204, "seek": 721504, "start": 7220.64, "end": 7225.68, "text": " We also have groups at Intel that work on neuromorphic computing for instance we have the", "tokens": [50644, 492, 611, 362, 3935, 412, 19762, 300, 589, 322, 12087, 32702, 299, 15866, 337, 5197, 321, 362, 264, 50896], "temperature": 0.0, "avg_logprob": -0.13561318868614106, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0003300329262856394}, {"id": 1205, "seek": 721504, "start": 7225.68, "end": 7233.04, "text": " loyalty architecture which is a chip that uses a model of spiking neurons for modeling perceptual", "tokens": [50896, 22831, 9482, 597, 307, 257, 11409, 300, 4960, 257, 2316, 295, 637, 13085, 22027, 337, 15983, 43276, 901, 51264], "temperature": 0.0, "avg_logprob": -0.13561318868614106, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0003300329262856394}, {"id": 1206, "seek": 721504, "start": 7233.04, "end": 7238.72, "text": " content and so on and this is in some sense compatible with the neural networks that exist", "tokens": [51264, 2701, 293, 370, 322, 293, 341, 307, 294, 512, 2020, 18218, 365, 264, 18161, 9590, 300, 2514, 51548], "temperature": 0.0, "avg_logprob": -0.13561318868614106, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0003300329262856394}, {"id": 1207, "seek": 723872, "start": 7238.72, "end": 7246.88, "text": " because you can translate the traditional neural networks and the many circumstances", "tokens": [50364, 570, 291, 393, 13799, 264, 5164, 18161, 9590, 293, 264, 867, 9121, 50772], "temperature": 0.0, "avg_logprob": -0.09354104995727539, "compression_ratio": 1.9035532994923858, "no_speech_prob": 0.002433500485494733}, {"id": 1208, "seek": 723872, "start": 7246.88, "end": 7252.16, "text": " into the spiking neural representations and vice versa but these spiking neural representations", "tokens": [50772, 666, 264, 637, 13085, 18161, 33358, 293, 11964, 25650, 457, 613, 637, 13085, 18161, 33358, 51036], "temperature": 0.0, "avg_logprob": -0.09354104995727539, "compression_ratio": 1.9035532994923858, "no_speech_prob": 0.002433500485494733}, {"id": 1209, "seek": 723872, "start": 7252.16, "end": 7260.0, "text": " are more efficient with respect to power usage and some the conditional algorithms than others", "tokens": [51036, 366, 544, 7148, 365, 3104, 281, 1347, 14924, 293, 512, 264, 27708, 14642, 813, 2357, 51428], "temperature": 0.0, "avg_logprob": -0.09354104995727539, "compression_ratio": 1.9035532994923858, "no_speech_prob": 0.002433500485494733}, {"id": 1210, "seek": 723872, "start": 7260.0, "end": 7266.4800000000005, "text": " and so there will probably be useful applications of spiking neurons but the reason why the neurons", "tokens": [51428, 293, 370, 456, 486, 1391, 312, 4420, 5821, 295, 637, 13085, 22027, 457, 264, 1778, 983, 264, 22027, 51752], "temperature": 0.0, "avg_logprob": -0.09354104995727539, "compression_ratio": 1.9035532994923858, "no_speech_prob": 0.002433500485494733}, {"id": 1211, "seek": 726648, "start": 7266.5599999999995, "end": 7271.759999999999, "text": " in our own brain are spiking is also in part because the messages that neurons can send to", "tokens": [50368, 294, 527, 1065, 3567, 366, 637, 13085, 307, 611, 294, 644, 570, 264, 7897, 300, 22027, 393, 2845, 281, 50628], "temperature": 0.0, "avg_logprob": -0.06971302738896122, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.001621848437935114}, {"id": 1212, "seek": 726648, "start": 7271.759999999999, "end": 7278.719999999999, "text": " each other are limited in their nature. Neurons cannot produce continuous signals they have to", "tokens": [50628, 1184, 661, 366, 5567, 294, 641, 3687, 13, 1734, 374, 892, 2644, 5258, 10957, 12354, 436, 362, 281, 50976], "temperature": 0.0, "avg_logprob": -0.06971302738896122, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.001621848437935114}, {"id": 1213, "seek": 726648, "start": 7278.719999999999, "end": 7283.44, "text": " produce little pulses and so you have to encode the information into little pulses", "tokens": [50976, 5258, 707, 45279, 293, 370, 291, 362, 281, 2058, 1429, 264, 1589, 666, 707, 45279, 51212], "temperature": 0.0, "avg_logprob": -0.06971302738896122, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.001621848437935114}, {"id": 1214, "seek": 726648, "start": 7283.44, "end": 7290.0, "text": " in the timing and frequencies between the pulses. There is also an issue when we think of neural", "tokens": [51212, 294, 264, 10822, 293, 20250, 1296, 264, 45279, 13, 821, 307, 611, 364, 2734, 562, 321, 519, 295, 18161, 51540], "temperature": 0.0, "avg_logprob": -0.06971302738896122, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.001621848437935114}, {"id": 1215, "seek": 729000, "start": 7290.0, "end": 7296.64, "text": " networks as they are represented in our technological system they are mostly circuits", "tokens": [50364, 9590, 382, 436, 366, 10379, 294, 527, 18439, 1185, 436, 366, 5240, 26354, 50696], "temperature": 0.0, "avg_logprob": -0.10529074403974745, "compression_ratio": 1.7989949748743719, "no_speech_prob": 0.001454210956580937}, {"id": 1216, "seek": 729000, "start": 7297.2, "end": 7304.16, "text": " right so they are similar to the circuits in your present CPU which represent logical gates", "tokens": [50724, 558, 370, 436, 366, 2531, 281, 264, 26354, 294, 428, 1974, 13199, 597, 2906, 14978, 19792, 51072], "temperature": 0.0, "avg_logprob": -0.10529074403974745, "compression_ratio": 1.7989949748743719, "no_speech_prob": 0.001454210956580937}, {"id": 1217, "seek": 729000, "start": 7304.16, "end": 7310.4, "text": " which implement logical operations and the connections is stored in the weights so the", "tokens": [51072, 597, 4445, 14978, 7705, 293, 264, 9271, 307, 12187, 294, 264, 17443, 370, 264, 51384], "temperature": 0.0, "avg_logprob": -0.10529074403974745, "compression_ratio": 1.7989949748743719, "no_speech_prob": 0.001454210956580937}, {"id": 1218, "seek": 729000, "start": 7310.4, "end": 7317.68, "text": " parameters in GPT-3 these are all weights little factors by which the activation that is sent", "tokens": [51384, 9834, 294, 26039, 51, 12, 18, 613, 366, 439, 17443, 707, 6771, 538, 597, 264, 24433, 300, 307, 2279, 51748], "temperature": 0.0, "avg_logprob": -0.10529074403974745, "compression_ratio": 1.7989949748743719, "no_speech_prob": 0.001454210956580937}, {"id": 1219, "seek": 731768, "start": 7317.68, "end": 7323.360000000001, "text": " between the different nodes is being multiplied and the equivalent in our brain to these weights", "tokens": [50364, 1296, 264, 819, 13891, 307, 885, 17207, 293, 264, 10344, 294, 527, 3567, 281, 613, 17443, 50648], "temperature": 0.0, "avg_logprob": -0.09682623147964478, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.0009693242027424276}, {"id": 1220, "seek": 731768, "start": 7323.360000000001, "end": 7329.4400000000005, "text": " are often seen as the synapses and the synapses come with different types the different neural", "tokens": [50648, 366, 2049, 1612, 382, 264, 5451, 2382, 279, 293, 264, 5451, 2382, 279, 808, 365, 819, 3467, 264, 819, 18161, 50952], "temperature": 0.0, "avg_logprob": -0.09682623147964478, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.0009693242027424276}, {"id": 1221, "seek": 731768, "start": 7329.4400000000005, "end": 7334.08, "text": " transmitters in some sense are message types that are connected to different synapses and", "tokens": [50952, 17831, 1559, 294, 512, 2020, 366, 3636, 3467, 300, 366, 4582, 281, 819, 5451, 2382, 279, 293, 51184], "temperature": 0.0, "avg_logprob": -0.09682623147964478, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.0009693242027424276}, {"id": 1222, "seek": 731768, "start": 7335.12, "end": 7343.12, "text": " the big network structure is what we call the connectome the circuitry that exists between", "tokens": [51236, 264, 955, 3209, 3877, 307, 437, 321, 818, 264, 1745, 423, 264, 9048, 627, 300, 8198, 1296, 51636], "temperature": 0.0, "avg_logprob": -0.09682623147964478, "compression_ratio": 1.8693467336683418, "no_speech_prob": 0.0009693242027424276}, {"id": 1223, "seek": 734312, "start": 7343.12, "end": 7349.2, "text": " the neurons and there is hope that if we manage to digitize the connectome at a sufficient resolution", "tokens": [50364, 264, 22027, 293, 456, 307, 1454, 300, 498, 321, 3067, 281, 14293, 1125, 264, 1745, 423, 412, 257, 11563, 8669, 50668], "temperature": 0.0, "avg_logprob": -0.11219213273790148, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.003536695148795843}, {"id": 1224, "seek": 734312, "start": 7349.2, "end": 7354.32, "text": " that we might be able to upload a brain and simulate it in a computational subscript and", "tokens": [50668, 300, 321, 1062, 312, 1075, 281, 6580, 257, 3567, 293, 27817, 309, 294, 257, 28270, 2325, 662, 293, 50924], "temperature": 0.0, "avg_logprob": -0.11219213273790148, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.003536695148795843}, {"id": 1225, "seek": 734312, "start": 7354.32, "end": 7359.04, "text": " in principle that should be possible in practice it doesn't work so far so even the models of C", "tokens": [50924, 294, 8665, 300, 820, 312, 1944, 294, 3124, 309, 1177, 380, 589, 370, 1400, 370, 754, 264, 5245, 295, 383, 51160], "temperature": 0.0, "avg_logprob": -0.11219213273790148, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.003536695148795843}, {"id": 1226, "seek": 734312, "start": 7359.04, "end": 7366.5599999999995, "text": " elegans which is an amatode that only has a little more than 300 neurons if you completely digitize", "tokens": [51160, 14459, 599, 597, 307, 364, 669, 267, 1429, 300, 787, 575, 257, 707, 544, 813, 6641, 22027, 498, 291, 2584, 14293, 1125, 51536], "temperature": 0.0, "avg_logprob": -0.11219213273790148, "compression_ratio": 1.6495726495726495, "no_speech_prob": 0.003536695148795843}, {"id": 1227, "seek": 736656, "start": 7366.56, "end": 7372.88, "text": " the elegance to my current knowledge I'm not sure if something has happened in the last couple", "tokens": [50364, 264, 14459, 719, 281, 452, 2190, 3601, 286, 478, 406, 988, 498, 746, 575, 2011, 294, 264, 1036, 1916, 50680], "temperature": 0.0, "avg_logprob": -0.09173246111188615, "compression_ratio": 1.8106060606060606, "no_speech_prob": 0.008185356855392456}, {"id": 1228, "seek": 736656, "start": 7372.88, "end": 7380.0, "text": " years these models don't work in the sense that you simulate the worm with these digitized neurons", "tokens": [50680, 924, 613, 5245, 500, 380, 589, 294, 264, 2020, 300, 291, 27817, 264, 23835, 365, 613, 14293, 1602, 22027, 51036], "temperature": 0.0, "avg_logprob": -0.09173246111188615, "compression_ratio": 1.8106060606060606, "no_speech_prob": 0.008185356855392456}, {"id": 1229, "seek": 736656, "start": 7380.0, "end": 7385.04, "text": " and you can digitize the connectome the worm doesn't move like a worm does it just twitches", "tokens": [51036, 293, 291, 393, 14293, 1125, 264, 1745, 423, 264, 23835, 1177, 380, 1286, 411, 257, 23835, 775, 309, 445, 34167, 279, 51288], "temperature": 0.0, "avg_logprob": -0.09173246111188615, "compression_ratio": 1.8106060606060606, "no_speech_prob": 0.008185356855392456}, {"id": 1230, "seek": 736656, "start": 7385.04, "end": 7390.080000000001, "text": " and has a seizure basically and that's maybe in part because the neurons are more complicated in", "tokens": [51288, 293, 575, 257, 42522, 1936, 293, 300, 311, 1310, 294, 644, 570, 264, 22027, 366, 544, 6179, 294, 51540], "temperature": 0.0, "avg_logprob": -0.09173246111188615, "compression_ratio": 1.8106060606060606, "no_speech_prob": 0.008185356855392456}, {"id": 1231, "seek": 736656, "start": 7390.080000000001, "end": 7394.64, "text": " the worm because there are so few of them they basically exploit certain resonance effects that", "tokens": [51540, 264, 23835, 570, 456, 366, 370, 1326, 295, 552, 436, 1936, 25924, 1629, 30944, 5065, 300, 51768], "temperature": 0.0, "avg_logprob": -0.09173246111188615, "compression_ratio": 1.8106060606060606, "no_speech_prob": 0.008185356855392456}, {"id": 1232, "seek": 739464, "start": 7394.64, "end": 7400.320000000001, "text": " maybe your model doesn't so maybe it's more of a dynamical system that is more difficult to model", "tokens": [50364, 1310, 428, 2316, 1177, 380, 370, 1310, 309, 311, 544, 295, 257, 5999, 804, 1185, 300, 307, 544, 2252, 281, 2316, 50648], "temperature": 0.0, "avg_logprob": -0.06598042117224799, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.0005700485198758543}, {"id": 1233, "seek": 739464, "start": 7400.320000000001, "end": 7404.96, "text": " and there's another problem is that you cannot actually get the message types right because", "tokens": [50648, 293, 456, 311, 1071, 1154, 307, 300, 291, 2644, 767, 483, 264, 3636, 3467, 558, 570, 50880], "temperature": 0.0, "avg_logprob": -0.06598042117224799, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.0005700485198758543}, {"id": 1234, "seek": 739464, "start": 7404.96, "end": 7409.6, "text": " at the level at which you do the connectome you cannot model all the vesicles that extend", "tokens": [50880, 412, 264, 1496, 412, 597, 291, 360, 264, 1745, 423, 291, 2644, 2316, 439, 264, 28274, 5350, 300, 10101, 51112], "temperature": 0.0, "avg_logprob": -0.06598042117224799, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.0005700485198758543}, {"id": 1235, "seek": 739464, "start": 7409.6, "end": 7414.96, "text": " the different neurotransmitters you don't know actually which synapse is sending which type of", "tokens": [51112, 264, 819, 43286, 25392, 3508, 1559, 291, 500, 380, 458, 767, 597, 5451, 11145, 307, 7750, 597, 2010, 295, 51380], "temperature": 0.0, "avg_logprob": -0.06598042117224799, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.0005700485198758543}, {"id": 1236, "seek": 739464, "start": 7414.96, "end": 7423.84, "text": " message this is also a limit but there might be something worse going on in the 1960s and 70s", "tokens": [51380, 3636, 341, 307, 611, 257, 4948, 457, 456, 1062, 312, 746, 5324, 516, 322, 294, 264, 16157, 82, 293, 5285, 82, 51824], "temperature": 0.0, "avg_logprob": -0.06598042117224799, "compression_ratio": 1.786259541984733, "no_speech_prob": 0.0005700485198758543}, {"id": 1237, "seek": 742384, "start": 7423.84, "end": 7428.32, "text": " there was a series of experiments mostly in the Soviet Union but some of them also in the US about", "tokens": [50364, 456, 390, 257, 2638, 295, 12050, 5240, 294, 264, 11348, 8133, 457, 512, 295, 552, 611, 294, 264, 2546, 466, 50588], "temperature": 0.0, "avg_logprob": -0.12293127308721127, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.002630625618621707}, {"id": 1238, "seek": 742384, "start": 7428.32, "end": 7436.400000000001, "text": " RNA based memory transfer and the idea here is that you take an nematode or a C-slug or even a", "tokens": [50588, 22484, 2361, 4675, 5003, 293, 264, 1558, 510, 307, 300, 291, 747, 364, 9939, 267, 1429, 420, 257, 383, 12, 10418, 697, 420, 754, 257, 50992], "temperature": 0.0, "avg_logprob": -0.12293127308721127, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.002630625618621707}, {"id": 1239, "seek": 742384, "start": 7436.400000000001, "end": 7443.52, "text": " rat and you teach them something by our current conditioning and then you put a new tissue into", "tokens": [50992, 5937, 293, 291, 2924, 552, 746, 538, 527, 2190, 21901, 293, 550, 291, 829, 257, 777, 12404, 666, 51348], "temperature": 0.0, "avg_logprob": -0.12293127308721127, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.002630625618621707}, {"id": 1240, "seek": 742384, "start": 7443.52, "end": 7448.32, "text": " a blender extract the RNA and inject the RNA into a different organism and the new organism knows how", "tokens": [51348, 257, 24564, 8947, 264, 22484, 293, 10711, 264, 22484, 666, 257, 819, 24128, 293, 264, 777, 24128, 3255, 577, 51588], "temperature": 0.0, "avg_logprob": -0.12293127308721127, "compression_ratio": 1.670940170940171, "no_speech_prob": 0.002630625618621707}, {"id": 1241, "seek": 744832, "start": 7448.32, "end": 7454.719999999999, "text": " to do this this is completely wild because if this works and it's disputed whether it actually", "tokens": [50364, 281, 360, 341, 341, 307, 2584, 4868, 570, 498, 341, 1985, 293, 309, 311, 37669, 292, 1968, 309, 767, 50684], "temperature": 0.0, "avg_logprob": -0.18395364746566892, "compression_ratio": 1.8436482084690553, "no_speech_prob": 0.001572728157043457}, {"id": 1242, "seek": 744832, "start": 7454.719999999999, "end": 7458.4, "text": " works of how well the experiment replicates even though some people have done that again and so", "tokens": [50684, 1985, 295, 577, 731, 264, 5120, 3248, 299, 1024, 754, 1673, 512, 561, 362, 1096, 300, 797, 293, 370, 50868], "temperature": 0.0, "avg_logprob": -0.18395364746566892, "compression_ratio": 1.8436482084690553, "no_speech_prob": 0.001572728157043457}, {"id": 1243, "seek": 744832, "start": 7458.4, "end": 7462.5599999999995, "text": " on the people that verb on this tell me it's difficult to get other neurosenters to listen", "tokens": [50868, 322, 264, 561, 300, 9595, 322, 341, 980, 385, 309, 311, 2252, 281, 483, 661, 28813, 317, 433, 281, 2140, 51076], "temperature": 0.0, "avg_logprob": -0.18395364746566892, "compression_ratio": 1.8436482084690553, "no_speech_prob": 0.001572728157043457}, {"id": 1244, "seek": 744832, "start": 7462.5599999999995, "end": 7468.4, "text": " because it's incompatible with the idea that the weights are stored in the synapses right if you", "tokens": [51076, 570, 309, 311, 40393, 267, 964, 365, 264, 1558, 300, 264, 17443, 366, 12187, 294, 264, 5451, 2382, 279, 558, 498, 291, 51368], "temperature": 0.0, "avg_logprob": -0.18395364746566892, "compression_ratio": 1.8436482084690553, "no_speech_prob": 0.001572728157043457}, {"id": 1245, "seek": 744832, "start": 7468.4, "end": 7472.08, "text": " if it's really the connection between your neurons and you put the nerves just into a blender", "tokens": [51368, 498, 309, 311, 534, 264, 4984, 1296, 428, 22027, 293, 291, 829, 264, 23078, 445, 666, 257, 24564, 51552], "temperature": 0.0, "avg_logprob": -0.18395364746566892, "compression_ratio": 1.8436482084690553, "no_speech_prob": 0.001572728157043457}, {"id": 1246, "seek": 744832, "start": 7472.08, "end": 7477.679999999999, "text": " this goes away how would you be able to transfer memory in this way this cannot possibly work", "tokens": [51552, 341, 1709, 1314, 577, 576, 291, 312, 1075, 281, 5003, 4675, 294, 341, 636, 341, 2644, 6264, 589, 51832], "temperature": 0.0, "avg_logprob": -0.18395364746566892, "compression_ratio": 1.8436482084690553, "no_speech_prob": 0.001572728157043457}, {"id": 1247, "seek": 747832, "start": 7478.719999999999, "end": 7482.799999999999, "text": " because the RNA that you inject in the brain is not localized it would get into many many", "tokens": [50384, 570, 264, 22484, 300, 291, 10711, 294, 264, 3567, 307, 406, 44574, 309, 576, 483, 666, 867, 867, 50588], "temperature": 0.0, "avg_logprob": -0.09172878843365294, "compression_ratio": 1.8102766798418972, "no_speech_prob": 0.0002065633743768558}, {"id": 1248, "seek": 747832, "start": 7482.799999999999, "end": 7489.759999999999, "text": " neurons at once so how does each neuron know which parts of the RNA to use and if you take", "tokens": [50588, 22027, 412, 1564, 370, 577, 775, 1184, 34090, 458, 597, 3166, 295, 264, 22484, 281, 764, 293, 498, 291, 747, 50936], "temperature": 0.0, "avg_logprob": -0.09172878843365294, "compression_ratio": 1.8102766798418972, "no_speech_prob": 0.0002065633743768558}, {"id": 1249, "seek": 747832, "start": 7489.759999999999, "end": 7495.28, "text": " this idea seriously I started thinking about this and now I'm thinking about making some", "tokens": [50936, 341, 1558, 6638, 286, 1409, 1953, 466, 341, 293, 586, 286, 478, 1953, 466, 1455, 512, 51212], "temperature": 0.0, "avg_logprob": -0.09172878843365294, "compression_ratio": 1.8102766798418972, "no_speech_prob": 0.0002065633743768558}, {"id": 1250, "seek": 747832, "start": 7495.28, "end": 7500.5599999999995, "text": " simulations how deep does the rabbit hole really go it would mean that the individual functions", "tokens": [51212, 35138, 577, 2452, 775, 264, 19509, 5458, 534, 352, 309, 576, 914, 300, 264, 2609, 6828, 51476], "temperature": 0.0, "avg_logprob": -0.09172878843365294, "compression_ratio": 1.8102766798418972, "no_speech_prob": 0.0002065633743768558}, {"id": 1251, "seek": 747832, "start": 7500.5599999999995, "end": 7505.44, "text": " that your neurons learn are not unique to the location of the individual neuron but they are", "tokens": [51476, 300, 428, 22027, 1466, 366, 406, 3845, 281, 264, 4914, 295, 264, 2609, 34090, 457, 436, 366, 51720], "temperature": 0.0, "avg_logprob": -0.09172878843365294, "compression_ratio": 1.8102766798418972, "no_speech_prob": 0.0002065633743768558}, {"id": 1252, "seek": 750544, "start": 7505.44, "end": 7511.599999999999, "text": " global functions so the RNA is basically you can think of it as a little magnetic tape that the", "tokens": [50364, 4338, 6828, 370, 264, 22484, 307, 1936, 291, 393, 519, 295, 309, 382, 257, 707, 12688, 7314, 300, 264, 50672], "temperature": 0.0, "avg_logprob": -0.10645173316778139, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012061753077432513}, {"id": 1253, "seek": 750544, "start": 7511.599999999999, "end": 7518.48, "text": " neuron can mix and match and create more of if it's useful and share with all the other neurons", "tokens": [50672, 34090, 393, 2890, 293, 2995, 293, 1884, 544, 295, 498, 309, 311, 4420, 293, 2073, 365, 439, 264, 661, 22027, 51016], "temperature": 0.0, "avg_logprob": -0.10645173316778139, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012061753077432513}, {"id": 1254, "seek": 750544, "start": 7518.48, "end": 7525.36, "text": " just across cell boundaries you share the RNA and you copy them like a covid virus and you use this", "tokens": [51016, 445, 2108, 2815, 13180, 291, 2073, 264, 22484, 293, 291, 5055, 552, 411, 257, 25616, 5752, 293, 291, 764, 341, 51360], "temperature": 0.0, "avg_logprob": -0.10645173316778139, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012061753077432513}, {"id": 1255, "seek": 750544, "start": 7525.36, "end": 7530.799999999999, "text": " function to respond to certain patterns in your environment so the neuron is not reacting to its", "tokens": [51360, 2445, 281, 4196, 281, 1629, 8294, 294, 428, 2823, 370, 264, 34090, 307, 406, 25817, 281, 1080, 51632], "temperature": 0.0, "avg_logprob": -0.10645173316778139, "compression_ratio": 1.7017543859649122, "no_speech_prob": 0.0012061753077432513}, {"id": 1256, "seek": 753080, "start": 7530.8, "end": 7536.16, "text": " neighbors that could come into particular kind of connections but it's mostly connecting to a", "tokens": [50364, 12512, 300, 727, 808, 666, 1729, 733, 295, 9271, 457, 309, 311, 5240, 11015, 281, 257, 50632], "temperature": 0.0, "avg_logprob": -0.09636914253234863, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.001753886346705258}, {"id": 1257, "seek": 753080, "start": 7536.16, "end": 7541.360000000001, "text": " temporal and spatial pattern that arrives at a certain function regardless of where the neuron", "tokens": [50632, 30881, 293, 23598, 5102, 300, 20116, 412, 257, 1629, 2445, 10060, 295, 689, 264, 34090, 50892], "temperature": 0.0, "avg_logprob": -0.09636914253234863, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.001753886346705258}, {"id": 1258, "seek": 753080, "start": 7541.360000000001, "end": 7548.16, "text": " is in the neural cortex and so it's more like a cellular automaton a neural cellular automaton", "tokens": [50892, 307, 294, 264, 18161, 33312, 293, 370, 309, 311, 544, 411, 257, 29267, 3553, 25781, 257, 18161, 29267, 3553, 25781, 51232], "temperature": 0.0, "avg_logprob": -0.09636914253234863, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.001753886346705258}, {"id": 1259, "seek": 753080, "start": 7548.16, "end": 7552.88, "text": " and this certainly allows us to explain a few things that seem to be going on the brain that", "tokens": [51232, 293, 341, 3297, 4045, 505, 281, 2903, 257, 1326, 721, 300, 1643, 281, 312, 516, 322, 264, 3567, 300, 51468], "temperature": 0.0, "avg_logprob": -0.09636914253234863, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.001753886346705258}, {"id": 1260, "seek": 753080, "start": 7552.88, "end": 7557.6, "text": " are difficult to explain with synapses for instance if you destroy synapses they often", "tokens": [51468, 366, 2252, 281, 2903, 365, 5451, 2382, 279, 337, 5197, 498, 291, 5293, 5451, 2382, 279, 436, 2049, 51704], "temperature": 0.0, "avg_logprob": -0.09636914253234863, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.001753886346705258}, {"id": 1261, "seek": 755760, "start": 7557.6, "end": 7562.56, "text": " be grown exactly the same way without retraining there's another phenomenon that is", "tokens": [50364, 312, 7709, 2293, 264, 912, 636, 1553, 49356, 1760, 456, 311, 1071, 14029, 300, 307, 50612], "temperature": 0.0, "avg_logprob": -0.1226426601409912, "compression_ratio": 1.7595419847328244, "no_speech_prob": 0.0032711445819586515}, {"id": 1262, "seek": 755760, "start": 7563.200000000001, "end": 7568.96, "text": " you notice a certain mental representation in a particle area pinpoint it and the next day you", "tokens": [50644, 291, 3449, 257, 1629, 4973, 10290, 294, 257, 12359, 1859, 40837, 309, 293, 264, 958, 786, 291, 50932], "temperature": 0.0, "avg_logprob": -0.1226426601409912, "compression_ratio": 1.7595419847328244, "no_speech_prob": 0.0032711445819586515}, {"id": 1263, "seek": 755760, "start": 7568.96, "end": 7574.88, "text": " look and it has moved it might have shifted a few millimeters or it has rotated so how would this", "tokens": [50932, 574, 293, 309, 575, 4259, 309, 1062, 362, 18892, 257, 1326, 24388, 420, 309, 575, 42146, 370, 577, 576, 341, 51228], "temperature": 0.0, "avg_logprob": -0.1226426601409912, "compression_ratio": 1.7595419847328244, "no_speech_prob": 0.0032711445819586515}, {"id": 1264, "seek": 755760, "start": 7574.88, "end": 7579.84, "text": " done if it's in it's stored in the synaptic connections there's also the question of weight", "tokens": [51228, 1096, 498, 309, 311, 294, 309, 311, 12187, 294, 264, 5451, 2796, 299, 9271, 456, 311, 611, 264, 1168, 295, 3364, 51476], "temperature": 0.0, "avg_logprob": -0.1226426601409912, "compression_ratio": 1.7595419847328244, "no_speech_prob": 0.0032711445819586515}, {"id": 1265, "seek": 755760, "start": 7579.84, "end": 7584.400000000001, "text": " sharing like a convolutional network is sharing weights and you probably need something like", "tokens": [51476, 5414, 411, 257, 45216, 304, 3209, 307, 5414, 17443, 293, 291, 1391, 643, 746, 411, 51704], "temperature": 0.0, "avg_logprob": -0.1226426601409912, "compression_ratio": 1.7595419847328244, "no_speech_prob": 0.0032711445819586515}, {"id": 1266, "seek": 758440, "start": 7584.48, "end": 7589.04, "text": " weight sharing to perform a mental rotation where you have the same operation on many parts of your", "tokens": [50368, 3364, 5414, 281, 2042, 257, 4973, 12447, 689, 291, 362, 264, 912, 6916, 322, 867, 3166, 295, 428, 50596], "temperature": 0.0, "avg_logprob": -0.07902854222517747, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.0006877226405777037}, {"id": 1267, "seek": 758440, "start": 7589.04, "end": 7594.799999999999, "text": " mental representation in the same way how would you do this are you training the same function", "tokens": [50596, 4973, 10290, 294, 264, 912, 636, 577, 576, 291, 360, 341, 366, 291, 3097, 264, 912, 2445, 50884], "temperature": 0.0, "avg_logprob": -0.07902854222517747, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.0006877226405777037}, {"id": 1268, "seek": 758440, "start": 7594.799999999999, "end": 7600.4, "text": " again and again in different brain regions I hope it's always the same it's difficult to achieve", "tokens": [50884, 797, 293, 797, 294, 819, 3567, 10682, 286, 1454, 309, 311, 1009, 264, 912, 309, 311, 2252, 281, 4584, 51164], "temperature": 0.0, "avg_logprob": -0.07902854222517747, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.0006877226405777037}, {"id": 1269, "seek": 758440, "start": 7600.4, "end": 7605.5199999999995, "text": " right so we don't know a really good plausible biological mechanism for this but this RNA based", "tokens": [51164, 558, 370, 321, 500, 380, 458, 257, 534, 665, 39925, 13910, 7513, 337, 341, 457, 341, 22484, 2361, 51420], "temperature": 0.0, "avg_logprob": -0.07902854222517747, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.0006877226405777037}, {"id": 1270, "seek": 758440, "start": 7605.5199999999995, "end": 7611.92, "text": " memory transfer could be part of the story and this is something that is at the boundary of what's", "tokens": [51420, 4675, 5003, 727, 312, 644, 295, 264, 1657, 293, 341, 307, 746, 300, 307, 412, 264, 12866, 295, 437, 311, 51740], "temperature": 0.0, "avg_logprob": -0.07902854222517747, "compression_ratio": 1.7672727272727273, "no_speech_prob": 0.0006877226405777037}, {"id": 1271, "seek": 761192, "start": 7611.92, "end": 7618.4, "text": " currently being explored still and it's I think it's not completely implausible and if we want to", "tokens": [50364, 4362, 885, 24016, 920, 293, 309, 311, 286, 519, 309, 311, 406, 2584, 8484, 8463, 964, 293, 498, 321, 528, 281, 50688], "temperature": 0.0, "avg_logprob": -0.0647224454046453, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.0010002165799960494}, {"id": 1272, "seek": 761192, "start": 7618.4, "end": 7623.52, "text": " make a model of how this works we would need to use a different metaphor than our current biological", "tokens": [50688, 652, 257, 2316, 295, 577, 341, 1985, 321, 576, 643, 281, 764, 257, 819, 19157, 813, 527, 2190, 13910, 50944], "temperature": 0.0, "avg_logprob": -0.0647224454046453, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.0010002165799960494}, {"id": 1273, "seek": 761192, "start": 7623.52, "end": 7630.08, "text": " neurons but it doesn't mean that you have to use this because the brain is solving problems that", "tokens": [50944, 22027, 457, 309, 1177, 380, 914, 300, 291, 362, 281, 764, 341, 570, 264, 3567, 307, 12606, 2740, 300, 51272], "temperature": 0.0, "avg_logprob": -0.0647224454046453, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.0010002165799960494}, {"id": 1274, "seek": 761192, "start": 7630.08, "end": 7635.36, "text": " our computers don't always have to solve for instance long distance connections in the brain", "tokens": [51272, 527, 10807, 500, 380, 1009, 362, 281, 5039, 337, 5197, 938, 4560, 9271, 294, 264, 3567, 51536], "temperature": 0.0, "avg_logprob": -0.0647224454046453, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.0010002165799960494}, {"id": 1275, "seek": 761192, "start": 7635.36, "end": 7640.72, "text": " are extremely difficult to make and you cannot really address neurons this way so random access", "tokens": [51536, 366, 4664, 2252, 281, 652, 293, 291, 2644, 534, 2985, 22027, 341, 636, 370, 4974, 2105, 51804], "temperature": 0.0, "avg_logprob": -0.0647224454046453, "compression_ratio": 1.7794117647058822, "no_speech_prob": 0.0010002165799960494}, {"id": 1276, "seek": 764072, "start": 7640.72, "end": 7644.56, "text": " is very hard in the brain you need some kind of routing network that needs to grow and learn how to", "tokens": [50364, 307, 588, 1152, 294, 264, 3567, 291, 643, 512, 733, 295, 32722, 3209, 300, 2203, 281, 1852, 293, 1466, 577, 281, 50556], "temperature": 0.0, "avg_logprob": -0.09164919172014509, "compression_ratio": 1.8307692307692307, "no_speech_prob": 0.00023404910461977124}, {"id": 1277, "seek": 764072, "start": 7644.56, "end": 7649.6, "text": " route it's not an issue in our digital computers because sending information across the memory", "tokens": [50556, 7955, 309, 311, 406, 364, 2734, 294, 527, 4562, 10807, 570, 7750, 1589, 2108, 264, 4675, 50808], "temperature": 0.0, "avg_logprob": -0.09164919172014509, "compression_ratio": 1.8307692307692307, "no_speech_prob": 0.00023404910461977124}, {"id": 1278, "seek": 764072, "start": 7649.6, "end": 7654.400000000001, "text": " of the computer is trivial so there are many things that we can do very easily in our digital", "tokens": [50808, 295, 264, 3820, 307, 26703, 370, 456, 366, 867, 721, 300, 321, 393, 360, 588, 3612, 294, 527, 4562, 51048], "temperature": 0.0, "avg_logprob": -0.09164919172014509, "compression_ratio": 1.8307692307692307, "no_speech_prob": 0.00023404910461977124}, {"id": 1279, "seek": 764072, "start": 7654.400000000001, "end": 7658.96, "text": " computers that are difficult to achieve in the self-organized state structure of the brain", "tokens": [51048, 10807, 300, 366, 2252, 281, 4584, 294, 264, 2698, 12, 12372, 1602, 1785, 3877, 295, 264, 3567, 51276], "temperature": 0.0, "avg_logprob": -0.09164919172014509, "compression_ratio": 1.8307692307692307, "no_speech_prob": 0.00023404910461977124}, {"id": 1280, "seek": 764072, "start": 7659.76, "end": 7666.240000000001, "text": " and so it's it's not quite clear how much we need biological like structures to achieve the same", "tokens": [51316, 293, 370, 309, 311, 309, 311, 406, 1596, 1850, 577, 709, 321, 643, 13910, 411, 9227, 281, 4584, 264, 912, 51640], "temperature": 0.0, "avg_logprob": -0.09164919172014509, "compression_ratio": 1.8307692307692307, "no_speech_prob": 0.00023404910461977124}, {"id": 1281, "seek": 766624, "start": 7666.24, "end": 7673.12, "text": " functionality but to me it's certainly very exciting to explore it. That's fascinating I think the", "tokens": [50364, 14980, 457, 281, 385, 309, 311, 3297, 588, 4670, 281, 6839, 309, 13, 663, 311, 10343, 286, 519, 264, 50708], "temperature": 0.0, "avg_logprob": -0.09160442887065566, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.0030210951808840036}, {"id": 1282, "seek": 766624, "start": 7673.12, "end": 7678.8, "text": " questions about drift and neuroplasticity and things like that that come from that are really", "tokens": [50708, 1651, 466, 19699, 293, 16499, 564, 2750, 507, 293, 721, 411, 300, 300, 808, 490, 300, 366, 534, 50992], "temperature": 0.0, "avg_logprob": -0.09160442887065566, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.0030210951808840036}, {"id": 1283, "seek": 766624, "start": 7678.8, "end": 7682.88, "text": " interesting it makes me wonder if some of what we're looking at today will seem very obsolete", "tokens": [50992, 1880, 309, 1669, 385, 2441, 498, 512, 295, 437, 321, 434, 1237, 412, 965, 486, 1643, 588, 46333, 51196], "temperature": 0.0, "avg_logprob": -0.09160442887065566, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.0030210951808840036}, {"id": 1284, "seek": 766624, "start": 7682.88, "end": 7689.92, "text": " soon in terms of these these models that seem to be so so human like with the you know in terms of", "tokens": [51196, 2321, 294, 2115, 295, 613, 613, 5245, 300, 1643, 281, 312, 370, 370, 1952, 411, 365, 264, 291, 458, 294, 2115, 295, 51548], "temperature": 0.0, "avg_logprob": -0.09160442887065566, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.0030210951808840036}, {"id": 1285, "seek": 766624, "start": 7689.92, "end": 7693.76, "text": " being able to hallucinate imagery and all that kind of stuff there's like a piece missing", "tokens": [51548, 885, 1075, 281, 35212, 13923, 24340, 293, 439, 300, 733, 295, 1507, 456, 311, 411, 257, 2522, 5361, 51740], "temperature": 0.0, "avg_logprob": -0.09160442887065566, "compression_ratio": 1.7335766423357664, "no_speech_prob": 0.0030210951808840036}, {"id": 1286, "seek": 769376, "start": 7693.76, "end": 7698.72, "text": " that might be that might come soon from a hardware model. Yeah I saw that too but then I'm surprised", "tokens": [50364, 300, 1062, 312, 300, 1062, 808, 2321, 490, 257, 8837, 2316, 13, 865, 286, 1866, 300, 886, 457, 550, 286, 478, 6100, 50612], "temperature": 0.0, "avg_logprob": -0.1313950453347307, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.0018663740484043956}, {"id": 1287, "seek": 769376, "start": 7698.72, "end": 7707.76, "text": " by what Gleit can do and Dali and of course. Right so when you add energy to it though I mean how", "tokens": [50612, 538, 437, 460, 306, 270, 393, 360, 293, 413, 5103, 293, 295, 1164, 13, 1779, 370, 562, 291, 909, 2281, 281, 309, 1673, 286, 914, 577, 51064], "temperature": 0.0, "avg_logprob": -0.1313950453347307, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.0018663740484043956}, {"id": 1288, "seek": 769376, "start": 7707.76, "end": 7712.400000000001, "text": " much energy it takes versus a brain which we walk around and we feed vegetables to and it can do all", "tokens": [51064, 709, 2281, 309, 2516, 5717, 257, 3567, 597, 321, 1792, 926, 293, 321, 3154, 9320, 281, 293, 309, 393, 360, 439, 51296], "temperature": 0.0, "avg_logprob": -0.1313950453347307, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.0018663740484043956}, {"id": 1289, "seek": 769376, "start": 7712.400000000001, "end": 7716.8, "text": " that too like you can't I mean that's that's where I think that the question that for me that's where", "tokens": [51296, 300, 886, 411, 291, 393, 380, 286, 914, 300, 311, 300, 311, 689, 286, 519, 300, 264, 1168, 300, 337, 385, 300, 311, 689, 51516], "temperature": 0.0, "avg_logprob": -0.1313950453347307, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.0018663740484043956}, {"id": 1290, "seek": 769376, "start": 7716.8, "end": 7721.280000000001, "text": " the question became very much more significant it's like oh wait but there's a whole other", "tokens": [51516, 264, 1168, 3062, 588, 709, 544, 4776, 309, 311, 411, 1954, 1699, 457, 456, 311, 257, 1379, 661, 51740], "temperature": 0.0, "avg_logprob": -0.1313950453347307, "compression_ratio": 1.789090909090909, "no_speech_prob": 0.0018663740484043956}, {"id": 1291, "seek": 772128, "start": 7721.28, "end": 7726.08, "text": " calculation here of how are we doing all of this in our tiny little brains maybe there's something", "tokens": [50364, 17108, 510, 295, 577, 366, 321, 884, 439, 295, 341, 294, 527, 5870, 707, 15442, 1310, 456, 311, 746, 50604], "temperature": 0.0, "avg_logprob": -0.08884168121049989, "compression_ratio": 1.821561338289963, "no_speech_prob": 0.0026305150240659714}, {"id": 1292, "seek": 772128, "start": 7726.08, "end": 7732.4, "text": " there for I think that this is misunderstood I think that a human brain is super expensive to", "tokens": [50604, 456, 337, 286, 519, 300, 341, 307, 33870, 286, 519, 300, 257, 1952, 3567, 307, 1687, 5124, 281, 50920], "temperature": 0.0, "avg_logprob": -0.08884168121049989, "compression_ratio": 1.821561338289963, "no_speech_prob": 0.0026305150240659714}, {"id": 1293, "seek": 772128, "start": 7732.4, "end": 7737.2, "text": " feed it needs enormous amounts of energy to feed my brain you need like four hectares of land you", "tokens": [50920, 3154, 309, 2203, 11322, 11663, 295, 2281, 281, 3154, 452, 3567, 291, 643, 411, 1451, 37358, 8643, 295, 2117, 291, 51160], "temperature": 0.0, "avg_logprob": -0.08884168121049989, "compression_ratio": 1.821561338289963, "no_speech_prob": 0.0026305150240659714}, {"id": 1294, "seek": 772128, "start": 7737.2, "end": 7742.719999999999, "text": " can put so many solar cells on these four hectares of land basically people underestimate how difficult", "tokens": [51160, 393, 829, 370, 867, 7936, 5438, 322, 613, 1451, 37358, 8643, 295, 2117, 1936, 561, 35826, 577, 2252, 51436], "temperature": 0.0, "avg_logprob": -0.08884168121049989, "compression_ratio": 1.821561338289963, "no_speech_prob": 0.0026305150240659714}, {"id": 1295, "seek": 772128, "start": 7742.719999999999, "end": 7748.639999999999, "text": " is to pack the energy that my brain needs into sandwiches and to extract it again right so this", "tokens": [51436, 307, 281, 2844, 264, 2281, 300, 452, 3567, 2203, 666, 29022, 293, 281, 8947, 309, 797, 558, 370, 341, 51732], "temperature": 0.0, "avg_logprob": -0.08884168121049989, "compression_ratio": 1.821561338289963, "no_speech_prob": 0.0026305150240659714}, {"id": 1296, "seek": 774864, "start": 7748.64, "end": 7752.4800000000005, "text": " is the way that you need to look at also training my own brain is super expensive right it takes", "tokens": [50364, 307, 264, 636, 300, 291, 643, 281, 574, 412, 611, 3097, 452, 1065, 3567, 307, 1687, 5124, 558, 309, 2516, 50556], "temperature": 0.0, "avg_logprob": -0.09004412640582074, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.000635672768112272}, {"id": 1297, "seek": 774864, "start": 7752.4800000000005, "end": 7759.76, "text": " decades and generations before that to prepare things for my own intellect and so on to get", "tokens": [50556, 7878, 293, 10593, 949, 300, 281, 5940, 721, 337, 452, 1065, 10058, 293, 370, 322, 281, 483, 50920], "temperature": 0.0, "avg_logprob": -0.09004412640582074, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.000635672768112272}, {"id": 1298, "seek": 774864, "start": 7759.76, "end": 7766.4800000000005, "text": " them in there so human brains in my view are super expensive and that's why we can use something like", "tokens": [50920, 552, 294, 456, 370, 1952, 15442, 294, 452, 1910, 366, 1687, 5124, 293, 300, 311, 983, 321, 393, 764, 746, 411, 51256], "temperature": 0.0, "avg_logprob": -0.09004412640582074, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.000635672768112272}, {"id": 1299, "seek": 774864, "start": 7767.52, "end": 7773.68, "text": " clip and V2 again that we only train once at at low prices like training GPT-3 costs like 20", "tokens": [51308, 7353, 293, 691, 17, 797, 300, 321, 787, 3847, 1564, 412, 412, 2295, 7901, 411, 3097, 26039, 51, 12, 18, 5497, 411, 945, 51616], "temperature": 0.0, "avg_logprob": -0.09004412640582074, "compression_ratio": 1.6724890829694323, "no_speech_prob": 0.000635672768112272}, {"id": 1300, "seek": 777368, "start": 7773.68, "end": 7779.76, "text": " million dollars and now even that's because computational advances go down and it's been", "tokens": [50364, 2459, 3808, 293, 586, 754, 300, 311, 570, 28270, 25297, 352, 760, 293, 309, 311, 668, 50668], "temperature": 0.0, "avg_logprob": -0.09696528941024969, "compression_ratio": 1.6954545454545455, "no_speech_prob": 0.014267961494624615}, {"id": 1301, "seek": 777368, "start": 7779.76, "end": 7785.12, "text": " trained by reading way more text than a very large group of people could read in their life", "tokens": [50668, 8895, 538, 3760, 636, 544, 2487, 813, 257, 588, 2416, 1594, 295, 561, 727, 1401, 294, 641, 993, 50936], "temperature": 0.0, "avg_logprob": -0.09696528941024969, "compression_ratio": 1.6954545454545455, "no_speech_prob": 0.014267961494624615}, {"id": 1302, "seek": 777368, "start": 7785.12, "end": 7791.200000000001, "text": " so it's basically getting people to read 45 terabytes of text would cost much more than 20", "tokens": [50936, 370, 309, 311, 1936, 1242, 561, 281, 1401, 6905, 1796, 24538, 295, 2487, 576, 2063, 709, 544, 813, 945, 51240], "temperature": 0.0, "avg_logprob": -0.09696528941024969, "compression_ratio": 1.6954545454545455, "no_speech_prob": 0.014267961494624615}, {"id": 1303, "seek": 777368, "start": 7791.200000000001, "end": 7798.88, "text": " million dollars right tweeting them for long enough to make that happen and the system that is making", "tokens": [51240, 2459, 3808, 558, 40090, 552, 337, 938, 1547, 281, 652, 300, 1051, 293, 264, 1185, 300, 307, 1455, 51624], "temperature": 0.0, "avg_logprob": -0.09696528941024969, "compression_ratio": 1.6954545454545455, "no_speech_prob": 0.014267961494624615}, {"id": 1304, "seek": 779888, "start": 7799.6, "end": 7805.2, "text": " generating the text costs so little that open air lets you do it for free if you want to only", "tokens": [50400, 17746, 264, 2487, 5497, 370, 707, 300, 1269, 1988, 6653, 291, 360, 309, 337, 1737, 498, 291, 528, 281, 787, 50680], "temperature": 0.0, "avg_logprob": -0.08042446049776944, "compression_ratio": 1.7136363636363636, "no_speech_prob": 0.009119988419115543}, {"id": 1305, "seek": 779888, "start": 7805.2, "end": 7809.92, "text": " use a little bit of it right so it's able to produce output that is at the level of hundreds", "tokens": [50680, 764, 257, 707, 857, 295, 309, 558, 370, 309, 311, 1075, 281, 5258, 5598, 300, 307, 412, 264, 1496, 295, 6779, 50916], "temperature": 0.0, "avg_logprob": -0.08042446049776944, "compression_ratio": 1.7136363636363636, "no_speech_prob": 0.009119988419115543}, {"id": 1306, "seek": 779888, "start": 7809.92, "end": 7815.84, "text": " of copy editors for free right and why that's not as good as a conscious copy editor who understands", "tokens": [50916, 295, 5055, 31446, 337, 1737, 558, 293, 983, 300, 311, 406, 382, 665, 382, 257, 6648, 5055, 9839, 567, 15146, 51212], "temperature": 0.0, "avg_logprob": -0.08042446049776944, "compression_ratio": 1.7136363636363636, "no_speech_prob": 0.009119988419115543}, {"id": 1307, "seek": 779888, "start": 7815.84, "end": 7822.400000000001, "text": " the world it's quite amazing what it can do already okay thanks for that perspective yeah", "tokens": [51212, 264, 1002, 309, 311, 1596, 2243, 437, 309, 393, 360, 1217, 1392, 3231, 337, 300, 4585, 1338, 51540], "temperature": 0.0, "avg_logprob": -0.08042446049776944, "compression_ratio": 1.7136363636363636, "no_speech_prob": 0.009119988419115543}, {"id": 1308, "seek": 782240, "start": 7822.4, "end": 7829.44, "text": " that's interesting thank you i also i'm a little bit provocative uh but uh yeah i think it's something", "tokens": [50364, 300, 311, 1880, 1309, 291, 741, 611, 741, 478, 257, 707, 857, 47663, 2232, 457, 2232, 1338, 741, 519, 309, 311, 746, 50716], "temperature": 0.0, "avg_logprob": -0.14918921744986757, "compression_ratio": 1.7678571428571428, "no_speech_prob": 0.00805235281586647}, {"id": 1309, "seek": 782240, "start": 7829.44, "end": 7836.32, "text": " to be considered right these 18 watts of your brain uh they uh if you compare them to the 80", "tokens": [50716, 281, 312, 4888, 558, 613, 2443, 31247, 295, 428, 3567, 2232, 436, 2232, 498, 291, 6794, 552, 281, 264, 4688, 51060], "temperature": 0.0, "avg_logprob": -0.14918921744986757, "compression_ratio": 1.7678571428571428, "no_speech_prob": 0.00805235281586647}, {"id": 1310, "seek": 782240, "start": 7836.32, "end": 7842.719999999999, "text": " watts of your macbook the 18 watts of your macbook are super cheap and the 18 watts of your brain are", "tokens": [51060, 31247, 295, 428, 7912, 2939, 264, 2443, 31247, 295, 428, 7912, 2939, 366, 1687, 7084, 293, 264, 2443, 31247, 295, 428, 3567, 366, 51380], "temperature": 0.0, "avg_logprob": -0.14918921744986757, "compression_ratio": 1.7678571428571428, "no_speech_prob": 0.00805235281586647}, {"id": 1311, "seek": 784272, "start": 7842.72, "end": 7851.68, "text": " super expensive i think we're gonna have to think a lot more about that i think it's your", "tokens": [50364, 1687, 5124, 741, 519, 321, 434, 799, 362, 281, 519, 257, 688, 544, 466, 300, 741, 519, 309, 311, 428, 50812], "temperature": 0.0, "avg_logprob": -0.20781311937557753, "compression_ratio": 1.7348837209302326, "no_speech_prob": 0.020513638854026794}, {"id": 1312, "seek": 784272, "start": 7851.68, "end": 7858.0, "text": " provocation that is so exciting actually uh yosha i want to get this question from the chat now", "tokens": [50812, 24568, 399, 300, 307, 370, 4670, 767, 2232, 288, 329, 1641, 741, 528, 281, 483, 341, 1168, 490, 264, 5081, 586, 51128], "temperature": 0.0, "avg_logprob": -0.20781311937557753, "compression_ratio": 1.7348837209302326, "no_speech_prob": 0.020513638854026794}, {"id": 1313, "seek": 784272, "start": 7858.0, "end": 7864.320000000001, "text": " going back just to say mentioned to everyone that yosha was was was born in weimar and where the", "tokens": [51128, 516, 646, 445, 281, 584, 2835, 281, 1518, 300, 288, 329, 1641, 390, 390, 390, 4232, 294, 321, 49396, 293, 689, 264, 51444], "temperature": 0.0, "avg_logprob": -0.20781311937557753, "compression_ratio": 1.7348837209302326, "no_speech_prob": 0.020513638854026794}, {"id": 1314, "seek": 784272, "start": 7864.320000000001, "end": 7868.96, "text": " Bauhaus came from and then desau is where the Bauhaus moved of course there's the building", "tokens": [51444, 28772, 23321, 1361, 490, 293, 550, 730, 1459, 307, 689, 264, 28772, 23321, 4259, 295, 1164, 456, 311, 264, 2390, 51676], "temperature": 0.0, "avg_logprob": -0.20781311937557753, "compression_ratio": 1.7348837209302326, "no_speech_prob": 0.020513638854026794}, {"id": 1315, "seek": 786896, "start": 7868.96, "end": 7874.24, "text": " by water gropius and so on and we have at least two people here who studied there including uh", "tokens": [50364, 538, 1281, 290, 1513, 4872, 293, 370, 322, 293, 321, 362, 412, 1935, 732, 561, 510, 567, 9454, 456, 3009, 2232, 50628], "temperature": 0.0, "avg_logprob": -0.11657283703486125, "compression_ratio": 1.6902654867256637, "no_speech_prob": 0.028763597831130028}, {"id": 1316, "seek": 786896, "start": 7874.24, "end": 7881.68, "text": " vasco who um has got a question vasco is now a professor in in bangladesh and um uh his question", "tokens": [50628, 11481, 1291, 567, 1105, 575, 658, 257, 1168, 11481, 1291, 307, 586, 257, 8304, 294, 294, 8550, 75, 26338, 293, 1105, 2232, 702, 1168, 51000], "temperature": 0.0, "avg_logprob": -0.11657283703486125, "compression_ratio": 1.6902654867256637, "no_speech_prob": 0.028763597831130028}, {"id": 1317, "seek": 786896, "start": 7881.68, "end": 7885.52, "text": " is well i think it's one that you might have predicted elon mass suggested somewhere that we", "tokens": [51000, 307, 731, 741, 519, 309, 311, 472, 300, 291, 1062, 362, 19147, 806, 266, 2758, 10945, 4079, 300, 321, 51192], "temperature": 0.0, "avg_logprob": -0.11657283703486125, "compression_ratio": 1.6902654867256637, "no_speech_prob": 0.028763597831130028}, {"id": 1318, "seek": 786896, "start": 7885.52, "end": 7891.36, "text": " live uh do we do not live in a base reality but in a simulation he even puts the probability of a", "tokens": [51192, 1621, 2232, 360, 321, 360, 406, 1621, 294, 257, 3096, 4103, 457, 294, 257, 16575, 415, 754, 8137, 264, 8482, 295, 257, 51484], "temperature": 0.0, "avg_logprob": -0.11657283703486125, "compression_ratio": 1.6902654867256637, "no_speech_prob": 0.028763597831130028}, {"id": 1319, "seek": 789136, "start": 7891.36, "end": 7900.96, "text": " billion to one what's your view i think that elon's argument rests on the notion that the simulations", "tokens": [50364, 5218, 281, 472, 437, 311, 428, 1910, 741, 519, 300, 806, 266, 311, 6770, 39755, 322, 264, 10710, 300, 264, 35138, 50844], "temperature": 0.0, "avg_logprob": -0.08175108941753259, "compression_ratio": 1.8194444444444444, "no_speech_prob": 0.024740124121308327}, {"id": 1320, "seek": 789136, "start": 7900.96, "end": 7905.28, "text": " that we are building for for computer games are getting better and better at some point there will", "tokens": [50844, 300, 321, 366, 2390, 337, 337, 3820, 2813, 366, 1242, 1101, 293, 1101, 412, 512, 935, 456, 486, 51060], "temperature": 0.0, "avg_logprob": -0.08175108941753259, "compression_ratio": 1.8194444444444444, "no_speech_prob": 0.024740124121308327}, {"id": 1321, "seek": 789136, "start": 7905.28, "end": 7912.719999999999, "text": " have a fidelity that exceeds our ability to notice whether we are in a simulation or not so we came", "tokens": [51060, 362, 257, 46404, 300, 43305, 527, 3485, 281, 3449, 1968, 321, 366, 294, 257, 16575, 420, 406, 370, 321, 1361, 51432], "temperature": 0.0, "avg_logprob": -0.08175108941753259, "compression_ratio": 1.8194444444444444, "no_speech_prob": 0.024740124121308327}, {"id": 1322, "seek": 789136, "start": 7912.719999999999, "end": 7917.12, "text": " at some point probably create vr's that are so convincing that we will not be able to notice", "tokens": [51432, 412, 512, 935, 1391, 1884, 371, 81, 311, 300, 366, 370, 24823, 300, 321, 486, 406, 312, 1075, 281, 3449, 51652], "temperature": 0.0, "avg_logprob": -0.08175108941753259, "compression_ratio": 1.8194444444444444, "no_speech_prob": 0.024740124121308327}, {"id": 1323, "seek": 791712, "start": 7917.2, "end": 7922.24, "text": " whether we are in a vr or not and we are not the only ones for our building simulations like this", "tokens": [50368, 1968, 321, 366, 294, 257, 371, 81, 420, 406, 293, 321, 366, 406, 264, 787, 2306, 337, 527, 2390, 35138, 411, 341, 50620], "temperature": 0.0, "avg_logprob": -0.061021985359562256, "compression_ratio": 2.0956521739130434, "no_speech_prob": 0.0018091235542669892}, {"id": 1324, "seek": 791712, "start": 7922.24, "end": 7928.4, "text": " so for any given being that finds itself in some kind of reality that looks real there will be many", "tokens": [50620, 370, 337, 604, 2212, 885, 300, 10704, 2564, 294, 512, 733, 295, 4103, 300, 1542, 957, 456, 486, 312, 867, 50928], "temperature": 0.0, "avg_logprob": -0.061021985359562256, "compression_ratio": 2.0956521739130434, "no_speech_prob": 0.0018091235542669892}, {"id": 1325, "seek": 791712, "start": 7928.4, "end": 7933.68, "text": " more that at the same time will be in simulations right because many universes can contain many", "tokens": [50928, 544, 300, 412, 264, 912, 565, 486, 312, 294, 35138, 558, 570, 867, 50168, 393, 5304, 867, 51192], "temperature": 0.0, "avg_logprob": -0.061021985359562256, "compression_ratio": 2.0956521739130434, "no_speech_prob": 0.0018091235542669892}, {"id": 1326, "seek": 791712, "start": 7933.68, "end": 7939.76, "text": " more than one simulation so our universe probably contains many simulations of of a universe that", "tokens": [51192, 544, 813, 472, 16575, 370, 527, 6445, 1391, 8306, 867, 35138, 295, 295, 257, 6445, 300, 51496], "temperature": 0.0, "avg_logprob": -0.061021985359562256, "compression_ratio": 2.0956521739130434, "no_speech_prob": 0.0018091235542669892}, {"id": 1327, "seek": 791712, "start": 7939.76, "end": 7944.88, "text": " looks like ours and therefore the probability for any given observer to be in a simulation", "tokens": [51496, 1542, 411, 11896, 293, 4412, 264, 8482, 337, 604, 2212, 27878, 281, 312, 294, 257, 16575, 51752], "temperature": 0.0, "avg_logprob": -0.061021985359562256, "compression_ratio": 2.0956521739130434, "no_speech_prob": 0.0018091235542669892}, {"id": 1328, "seek": 794488, "start": 7944.88, "end": 7951.12, "text": " is greater than the probability than to be in base reality and what this argument ignores is", "tokens": [50364, 307, 5044, 813, 264, 8482, 813, 281, 312, 294, 3096, 4103, 293, 437, 341, 6770, 5335, 2706, 307, 50676], "temperature": 0.0, "avg_logprob": -0.0698119458698091, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.0009394644293934107}, {"id": 1329, "seek": 794488, "start": 7951.12, "end": 7955.92, "text": " the fact that it's very hard to make a simulation that actually has the fidelity of the physical", "tokens": [50676, 264, 1186, 300, 309, 311, 588, 1152, 281, 652, 257, 16575, 300, 767, 575, 264, 46404, 295, 264, 4001, 50916], "temperature": 0.0, "avg_logprob": -0.0698119458698091, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.0009394644293934107}, {"id": 1330, "seek": 794488, "start": 7955.92, "end": 7962.4800000000005, "text": " universe but if you make a simulation of minecraft and minecraft that's feasible because minecraft", "tokens": [50916, 6445, 457, 498, 291, 652, 257, 16575, 295, 3892, 5611, 293, 3892, 5611, 300, 311, 26648, 570, 3892, 5611, 51244], "temperature": 0.0, "avg_logprob": -0.0698119458698091, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.0009394644293934107}, {"id": 1331, "seek": 794488, "start": 7962.4800000000005, "end": 7968.72, "text": " itself is so poorly resolved but our universe has a lot of structure that is required to produce", "tokens": [51244, 2564, 307, 370, 22271, 20772, 457, 527, 6445, 575, 257, 688, 295, 3877, 300, 307, 4739, 281, 5258, 51556], "temperature": 0.0, "avg_logprob": -0.0698119458698091, "compression_ratio": 1.7990654205607477, "no_speech_prob": 0.0009394644293934107}, {"id": 1332, "seek": 796872, "start": 7968.96, "end": 7976.08, "text": " dynamics and if you build a simulation of say our solar system and the dynamics of our solar system", "tokens": [50376, 15679, 293, 498, 291, 1322, 257, 16575, 295, 584, 527, 7936, 1185, 293, 264, 15679, 295, 527, 7936, 1185, 50732], "temperature": 0.0, "avg_logprob": -0.06791648864746094, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.008055263198912144}, {"id": 1333, "seek": 796872, "start": 7976.08, "end": 7983.04, "text": " at a level that is going to go down to elementary particles you will need to have a computational", "tokens": [50732, 412, 257, 1496, 300, 307, 516, 281, 352, 760, 281, 16429, 10007, 291, 486, 643, 281, 362, 257, 28270, 51080], "temperature": 0.0, "avg_logprob": -0.06791648864746094, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.008055263198912144}, {"id": 1334, "seek": 796872, "start": 7983.04, "end": 7990.240000000001, "text": " capacity that is larger than our galaxy by a very considerable amount so in practice I don't think", "tokens": [51080, 6042, 300, 307, 4833, 813, 527, 17639, 538, 257, 588, 24167, 2372, 370, 294, 3124, 286, 500, 380, 519, 51440], "temperature": 0.0, "avg_logprob": -0.06791648864746094, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.008055263198912144}, {"id": 1335, "seek": 796872, "start": 7990.240000000001, "end": 7997.04, "text": " it's feasible to put simulations of our universe into our universe at an arbitrary level of fidelity", "tokens": [51440, 309, 311, 26648, 281, 829, 35138, 295, 527, 6445, 666, 527, 6445, 412, 364, 23211, 1496, 295, 46404, 51780], "temperature": 0.0, "avg_logprob": -0.06791648864746094, "compression_ratio": 1.748898678414097, "no_speech_prob": 0.008055263198912144}, {"id": 1336, "seek": 799704, "start": 7997.04, "end": 8003.6, "text": " and so I think that I'm much more biased to think that we are in base reality than we are in a simulation", "tokens": [50364, 293, 370, 286, 519, 300, 286, 478, 709, 544, 28035, 281, 519, 300, 321, 366, 294, 3096, 4103, 813, 321, 366, 294, 257, 16575, 50692], "temperature": 0.0, "avg_logprob": -0.17212795530046734, "compression_ratio": 1.606936416184971, "no_speech_prob": 0.0003845887549687177}, {"id": 1337, "seek": 799704, "start": 8007.12, "end": 8014.16, "text": " this is fantastic there's one question here that in also in the chat from Grant Castillo", "tokens": [50868, 341, 307, 5456, 456, 311, 472, 1168, 510, 300, 294, 611, 294, 264, 5081, 490, 17529, 11019, 15831, 51220], "temperature": 0.0, "avg_logprob": -0.17212795530046734, "compression_ratio": 1.606936416184971, "no_speech_prob": 0.0003845887549687177}, {"id": 1338, "seek": 799704, "start": 8014.16, "end": 8019.12, "text": " and I don't know what he is do you think Gerald Adelman's extended theory of neural", "tokens": [51220, 293, 286, 500, 380, 458, 437, 415, 307, 360, 291, 519, 38332, 1999, 338, 1601, 311, 10913, 5261, 295, 18161, 51468], "temperature": 0.0, "avg_logprob": -0.17212795530046734, "compression_ratio": 1.606936416184971, "no_speech_prob": 0.0003845887549687177}, {"id": 1339, "seek": 801912, "start": 8019.12, "end": 8027.68, "text": " neuronal group selection can be used to create a conscious machine are you muted", "tokens": [50364, 12087, 21523, 1594, 9450, 393, 312, 1143, 281, 1884, 257, 6648, 3479, 366, 291, 32808, 50792], "temperature": 0.0, "avg_logprob": -0.16913521024915906, "compression_ratio": 1.39568345323741, "no_speech_prob": 0.009106011129915714}, {"id": 1340, "seek": 801912, "start": 8032.4, "end": 8033.68, "text": " one moment yeah", "tokens": [51028, 472, 1623, 1338, 51092], "temperature": 0.0, "avg_logprob": -0.16913521024915906, "compression_ratio": 1.39568345323741, "no_speech_prob": 0.009106011129915714}, {"id": 1341, "seek": 801912, "start": 8037.12, "end": 8041.76, "text": " I hope that the background noises are not too high because my family woke up it's now interactive", "tokens": [51264, 286, 1454, 300, 264, 3678, 14620, 366, 406, 886, 1090, 570, 452, 1605, 12852, 493, 309, 311, 586, 15141, 51496], "temperature": 0.0, "avg_logprob": -0.16913521024915906, "compression_ratio": 1.39568345323741, "no_speech_prob": 0.009106011129915714}, {"id": 1342, "seek": 804176, "start": 8042.320000000001, "end": 8052.24, "text": " the kids are playing and so on and so I I think that the idea of the neural Darwinism", "tokens": [50392, 264, 2301, 366, 2433, 293, 370, 322, 293, 370, 286, 286, 519, 300, 264, 1558, 295, 264, 18161, 30233, 1434, 50888], "temperature": 0.0, "avg_logprob": -0.11931326303137355, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.002752915723249316}, {"id": 1343, "seek": 804176, "start": 8052.24, "end": 8057.76, "text": " that Adelman came up with is a very interesting one and I suspect that our own mind is the result of", "tokens": [50888, 300, 1999, 338, 1601, 1361, 493, 365, 307, 257, 588, 1880, 472, 293, 286, 9091, 300, 527, 1065, 1575, 307, 264, 1874, 295, 51164], "temperature": 0.0, "avg_logprob": -0.11931326303137355, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.002752915723249316}, {"id": 1344, "seek": 804176, "start": 8057.76, "end": 8063.84, "text": " such an evolutionary competition of different organizational forms right there could be many", "tokens": [51164, 1270, 364, 27567, 6211, 295, 819, 24730, 6422, 558, 456, 727, 312, 867, 51468], "temperature": 0.0, "avg_logprob": -0.11931326303137355, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.002752915723249316}, {"id": 1345, "seek": 804176, "start": 8063.84, "end": 8070.08, "text": " possible proto-consciousnesses that compete until one of them establishes itself as the", "tokens": [51468, 1944, 47896, 12, 19877, 1287, 279, 300, 11831, 1826, 472, 295, 552, 8327, 279, 2564, 382, 264, 51780], "temperature": 0.0, "avg_logprob": -0.11931326303137355, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.002752915723249316}, {"id": 1346, "seek": 807008, "start": 8070.08, "end": 8078.0, "text": " government of our own mind and so instead of giving your your system a blueprint on how to", "tokens": [50364, 2463, 295, 527, 1065, 1575, 293, 370, 2602, 295, 2902, 428, 428, 1185, 257, 35868, 322, 577, 281, 50760], "temperature": 0.0, "avg_logprob": -0.0732134526426142, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.0019240336259827018}, {"id": 1347, "seek": 807008, "start": 8078.0, "end": 8083.12, "text": " build a mind you just set up the conditions for an evolution for the best possible mind that you", "tokens": [50760, 1322, 257, 1575, 291, 445, 992, 493, 264, 4487, 337, 364, 9303, 337, 264, 1151, 1944, 1575, 300, 291, 51016], "temperature": 0.0, "avg_logprob": -0.0732134526426142, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.0019240336259827018}, {"id": 1348, "seek": 807008, "start": 8083.12, "end": 8089.44, "text": " could have and of course this evolution is rigged by evolution so you set it up in such a way that", "tokens": [51016, 727, 362, 293, 295, 1164, 341, 9303, 307, 8329, 3004, 538, 9303, 370, 291, 992, 309, 493, 294, 1270, 257, 636, 300, 51332], "temperature": 0.0, "avg_logprob": -0.0732134526426142, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.0019240336259827018}, {"id": 1349, "seek": 807008, "start": 8089.44, "end": 8097.36, "text": " the evolution usually goes out ends up in a certain way but the nice property of when you design", "tokens": [51332, 264, 9303, 2673, 1709, 484, 5314, 493, 294, 257, 1629, 636, 457, 264, 1481, 4707, 295, 562, 291, 1715, 51728], "temperature": 0.0, "avg_logprob": -0.0732134526426142, "compression_ratio": 1.7897196261682242, "no_speech_prob": 0.0019240336259827018}, {"id": 1350, "seek": 809736, "start": 8097.36, "end": 8101.2, "text": " a system evolutionary by not giving a specification of what to look like but what", "tokens": [50364, 257, 1185, 27567, 538, 406, 2902, 257, 31256, 295, 437, 281, 574, 411, 457, 437, 50556], "temperature": 0.0, "avg_logprob": -0.09600715247952209, "compression_ratio": 1.726235741444867, "no_speech_prob": 0.0011688327649608254}, {"id": 1351, "seek": 809736, "start": 8102.4, "end": 8106.799999999999, "text": " the function is against which it should evolve is that when you disrupt the system or give it a", "tokens": [50616, 264, 2445, 307, 1970, 597, 309, 820, 16693, 307, 300, 562, 291, 14124, 264, 1185, 420, 976, 309, 257, 50836], "temperature": 0.0, "avg_logprob": -0.09600715247952209, "compression_ratio": 1.726235741444867, "no_speech_prob": 0.0011688327649608254}, {"id": 1352, "seek": 809736, "start": 8106.799999999999, "end": 8111.04, "text": " different environment that it will very often come up with a viable solution under these new", "tokens": [50836, 819, 2823, 300, 309, 486, 588, 2049, 808, 493, 365, 257, 22024, 3827, 833, 613, 777, 51048], "temperature": 0.0, "avg_logprob": -0.09600715247952209, "compression_ratio": 1.726235741444867, "no_speech_prob": 0.0011688327649608254}, {"id": 1353, "seek": 809736, "start": 8111.04, "end": 8116.96, "text": " circumstances so the solution is much more robust if you define it in terms of evolution", "tokens": [51048, 9121, 370, 264, 3827, 307, 709, 544, 13956, 498, 291, 6964, 309, 294, 2115, 295, 9303, 51344], "temperature": 0.0, "avg_logprob": -0.09600715247952209, "compression_ratio": 1.726235741444867, "no_speech_prob": 0.0011688327649608254}, {"id": 1354, "seek": 809736, "start": 8118.24, "end": 8123.28, "text": " but it's a speculative idea so I don't actually know whether our mind is evolved even though I", "tokens": [51408, 457, 309, 311, 257, 49415, 1558, 370, 286, 500, 380, 767, 458, 1968, 527, 1575, 307, 14178, 754, 1673, 286, 51660], "temperature": 0.0, "avg_logprob": -0.09600715247952209, "compression_ratio": 1.726235741444867, "no_speech_prob": 0.0011688327649608254}, {"id": 1355, "seek": 812328, "start": 8123.28, "end": 8127.28, "text": " think it's more plausible than it's not individually evolved in every individual brain", "tokens": [50364, 519, 309, 311, 544, 39925, 813, 309, 311, 406, 16652, 14178, 294, 633, 2609, 3567, 50564], "temperature": 0.0, "avg_logprob": -0.10379290094180983, "compression_ratio": 1.8366533864541832, "no_speech_prob": 0.0013237587409093976}, {"id": 1356, "seek": 812328, "start": 8128.16, "end": 8136.0, "text": " and it's definitely an interesting notion to to use evolution is basically whatever you use in", "tokens": [50608, 293, 309, 311, 2138, 364, 1880, 10710, 281, 281, 764, 9303, 307, 1936, 2035, 291, 764, 294, 51000], "temperature": 0.0, "avg_logprob": -0.10379290094180983, "compression_ratio": 1.8366533864541832, "no_speech_prob": 0.0013237587409093976}, {"id": 1357, "seek": 812328, "start": 8136.719999999999, "end": 8141.679999999999, "text": " computer science then you don't know in which direction to go it's a blind search it's the", "tokens": [51036, 3820, 3497, 550, 291, 500, 380, 458, 294, 597, 3513, 281, 352, 309, 311, 257, 6865, 3164, 309, 311, 264, 51284], "temperature": 0.0, "avg_logprob": -0.10379290094180983, "compression_ratio": 1.8366533864541832, "no_speech_prob": 0.0013237587409093976}, {"id": 1358, "seek": 812328, "start": 8141.679999999999, "end": 8148.16, "text": " fallback it's the baseline and it's quite natural that we would use evolutionary methods if we don't", "tokens": [51284, 2100, 3207, 309, 311, 264, 20518, 293, 309, 311, 1596, 3303, 300, 321, 576, 764, 27567, 7150, 498, 321, 500, 380, 51608], "temperature": 0.0, "avg_logprob": -0.10379290094180983, "compression_ratio": 1.8366533864541832, "no_speech_prob": 0.0013237587409093976}, {"id": 1359, "seek": 812328, "start": 8148.16, "end": 8152.24, "text": " have a specification for the best possible mental organization that we just evolved one", "tokens": [51608, 362, 257, 31256, 337, 264, 1151, 1944, 4973, 4475, 300, 321, 445, 14178, 472, 51812], "temperature": 0.0, "avg_logprob": -0.10379290094180983, "compression_ratio": 1.8366533864541832, "no_speech_prob": 0.0013237587409093976}, {"id": 1360, "seek": 815328, "start": 8153.36, "end": 8163.759999999999, "text": " so do we have any further questions in the chat we have some very interesting characters here I'd", "tokens": [50368, 370, 360, 321, 362, 604, 3052, 1651, 294, 264, 5081, 321, 362, 512, 588, 1880, 4342, 510, 286, 1116, 50888], "temperature": 0.0, "avg_logprob": -0.19714818102248172, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.0024260899517685175}, {"id": 1361, "seek": 815328, "start": 8163.759999999999, "end": 8168.0, "text": " love to try and draw out Daniel Bolliger who's one of the leading AI architects in the world", "tokens": [50888, 959, 281, 853, 293, 2642, 484, 8033, 363, 1833, 4810, 567, 311, 472, 295, 264, 5775, 7318, 30491, 294, 264, 1002, 51100], "temperature": 0.0, "avg_logprob": -0.19714818102248172, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.0024260899517685175}, {"id": 1362, "seek": 815328, "start": 8168.0, "end": 8172.4, "text": " we'll see where he can have a question or indeed we had Sanford Quinta who's one of our leading", "tokens": [51100, 321, 603, 536, 689, 415, 393, 362, 257, 1168, 420, 6451, 321, 632, 5271, 7404, 2326, 16071, 567, 311, 472, 295, 527, 5775, 51320], "temperature": 0.0, "avg_logprob": -0.19714818102248172, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.0024260899517685175}, {"id": 1363, "seek": 815328, "start": 8172.4, "end": 8178.639999999999, "text": " theorists who's a particular interest in neuroscience I'm wondering if I could I could put them in the", "tokens": [51320, 27423, 1751, 567, 311, 257, 1729, 1179, 294, 42762, 286, 478, 6359, 498, 286, 727, 286, 727, 829, 552, 294, 264, 51632], "temperature": 0.0, "avg_logprob": -0.19714818102248172, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.0024260899517685175}, {"id": 1364, "seek": 817864, "start": 8178.64, "end": 8180.0, "text": " spot and ask if they have a question", "tokens": [50364, 4008, 293, 1029, 498, 436, 362, 257, 1168, 50432], "temperature": 0.0, "avg_logprob": -0.1810236844149503, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.00392023054882884}, {"id": 1365, "seek": 817864, "start": 8187.360000000001, "end": 8191.12, "text": " but when you're done it's also good because I think I need to go and have some breakfast", "tokens": [50800, 457, 562, 291, 434, 1096, 309, 311, 611, 665, 570, 286, 519, 286, 643, 281, 352, 293, 362, 512, 8201, 50988], "temperature": 0.0, "avg_logprob": -0.1810236844149503, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.00392023054882884}, {"id": 1366, "seek": 817864, "start": 8191.12, "end": 8192.56, "text": " yes and start my day", "tokens": [50988, 2086, 293, 722, 452, 786, 51060], "temperature": 0.0, "avg_logprob": -0.1810236844149503, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.00392023054882884}, {"id": 1367, "seek": 817864, "start": 8195.6, "end": 8198.16, "text": " thank you I mean this has been fantastic you know I", "tokens": [51212, 1309, 291, 286, 914, 341, 575, 668, 5456, 291, 458, 286, 51340], "temperature": 0.0, "avg_logprob": -0.1810236844149503, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.00392023054882884}, {"id": 1368, "seek": 817864, "start": 8199.92, "end": 8204.48, "text": " I actually I've got to say that I think you're sure you are more of an architect than you", "tokens": [51428, 286, 767, 286, 600, 658, 281, 584, 300, 286, 519, 291, 434, 988, 291, 366, 544, 295, 364, 6331, 813, 291, 51656], "temperature": 0.0, "avg_logprob": -0.1810236844149503, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.00392023054882884}, {"id": 1369, "seek": 817864, "start": 8204.48, "end": 8208.48, "text": " actually think you are you have a way of thinking that's very similar I mean obviously you work in", "tokens": [51656, 767, 519, 291, 366, 291, 362, 257, 636, 295, 1953, 300, 311, 588, 2531, 286, 914, 2745, 291, 589, 294, 51856], "temperature": 0.0, "avg_logprob": -0.1810236844149503, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.00392023054882884}, {"id": 1370, "seek": 820848, "start": 8208.48, "end": 8213.199999999999, "text": " a different domain but I think the the kind of inventiveness and the the iconoclasm of your", "tokens": [50364, 257, 819, 9274, 457, 286, 519, 264, 264, 733, 295, 7962, 8477, 293, 264, 264, 6528, 905, 7743, 76, 295, 428, 50600], "temperature": 0.0, "avg_logprob": -0.1203455741588886, "compression_ratio": 1.793774319066148, "no_speech_prob": 0.0028280853293836117}, {"id": 1371, "seek": 820848, "start": 8213.199999999999, "end": 8217.76, "text": " thinking would be go down very well in an architectural scenario so and I sometimes", "tokens": [50600, 1953, 576, 312, 352, 760, 588, 731, 294, 364, 26621, 9005, 370, 293, 286, 2171, 50828], "temperature": 0.0, "avg_logprob": -0.1203455741588886, "compression_ratio": 1.793774319066148, "no_speech_prob": 0.0028280853293836117}, {"id": 1372, "seek": 820848, "start": 8217.76, "end": 8222.4, "text": " with I never escape you know you never escape your background in the way you you might try but in", "tokens": [50828, 365, 286, 1128, 7615, 291, 458, 291, 1128, 7615, 428, 3678, 294, 264, 636, 291, 291, 1062, 853, 457, 294, 51060], "temperature": 0.0, "avg_logprob": -0.1203455741588886, "compression_ratio": 1.793774319066148, "no_speech_prob": 0.0028280853293836117}, {"id": 1373, "seek": 820848, "start": 8222.4, "end": 8228.48, "text": " the end you you find yourself conditioned I'm conscious of being a child of a family of architects", "tokens": [51060, 264, 917, 291, 291, 915, 1803, 35833, 286, 478, 6648, 295, 885, 257, 1440, 295, 257, 1605, 295, 30491, 51364], "temperature": 0.0, "avg_logprob": -0.1203455741588886, "compression_ratio": 1.793774319066148, "no_speech_prob": 0.0028280853293836117}, {"id": 1374, "seek": 820848, "start": 8228.48, "end": 8234.16, "text": " my grandfather was not an artist he was an architect he built most of his life hospitals", "tokens": [51364, 452, 14754, 390, 406, 364, 5748, 415, 390, 364, 6331, 415, 3094, 881, 295, 702, 993, 13014, 51648], "temperature": 0.0, "avg_logprob": -0.1203455741588886, "compression_ratio": 1.793774319066148, "no_speech_prob": 0.0028280853293836117}, {"id": 1375, "seek": 823416, "start": 8234.88, "end": 8240.64, "text": " and this is the design process that is instrumental to serving a function but a function in a larger", "tokens": [50400, 293, 341, 307, 264, 1715, 1399, 300, 307, 17388, 281, 8148, 257, 2445, 457, 257, 2445, 294, 257, 4833, 50688], "temperature": 0.0, "avg_logprob": -0.10095471533659463, "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.0023531268816441298}, {"id": 1376, "seek": 823416, "start": 8240.64, "end": 8245.76, "text": " world that he was very deliberately trying to understand and operate in but it was a world", "tokens": [50688, 1002, 300, 415, 390, 588, 23506, 1382, 281, 1223, 293, 9651, 294, 457, 309, 390, 257, 1002, 50944], "temperature": 0.0, "avg_logprob": -0.10095471533659463, "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.0023531268816441298}, {"id": 1377, "seek": 823416, "start": 8245.76, "end": 8250.8, "text": " that he understood as being his own world it was a world that he often found himself to be in", "tokens": [50944, 300, 415, 7320, 382, 885, 702, 1065, 1002, 309, 390, 257, 1002, 300, 415, 2049, 1352, 3647, 281, 312, 294, 51196], "temperature": 0.0, "avg_logprob": -0.10095471533659463, "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.0023531268816441298}, {"id": 1378, "seek": 823416, "start": 8250.8, "end": 8256.88, "text": " opposition with for instance in Nazi fascism or also in eastern Germany but it was also the world", "tokens": [51196, 13504, 365, 337, 5197, 294, 23592, 7184, 1434, 420, 611, 294, 19346, 7244, 457, 309, 390, 611, 264, 1002, 51500], "temperature": 0.0, "avg_logprob": -0.10095471533659463, "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.0023531268816441298}, {"id": 1379, "seek": 823416, "start": 8256.88, "end": 8262.08, "text": " that existed and we need to deal with and build the best possible things in and for my father it", "tokens": [51500, 300, 13135, 293, 321, 643, 281, 2028, 365, 293, 1322, 264, 1151, 1944, 721, 294, 293, 337, 452, 3086, 309, 51760], "temperature": 0.0, "avg_logprob": -0.10095471533659463, "compression_ratio": 1.8972332015810276, "no_speech_prob": 0.0023531268816441298}, {"id": 1380, "seek": 826208, "start": 8262.08, "end": 8267.84, "text": " was different it was a world that he fundamentally rejected and so in some sense to be an architect", "tokens": [50364, 390, 819, 309, 390, 257, 1002, 300, 415, 17879, 15749, 293, 370, 294, 512, 2020, 281, 312, 364, 6331, 50652], "temperature": 0.0, "avg_logprob": -0.08133643264070563, "compression_ratio": 1.8482490272373542, "no_speech_prob": 0.003452691715210676}, {"id": 1381, "seek": 826208, "start": 8267.84, "end": 8275.039999999999, "text": " you need to embrace the world that you are in and build within it and to to take roots in it and", "tokens": [50652, 291, 643, 281, 14038, 264, 1002, 300, 291, 366, 294, 293, 1322, 1951, 309, 293, 281, 281, 747, 10669, 294, 309, 293, 51012], "temperature": 0.0, "avg_logprob": -0.08133643264070563, "compression_ratio": 1.8482490272373542, "no_speech_prob": 0.003452691715210676}, {"id": 1382, "seek": 826208, "start": 8276.08, "end": 8281.2, "text": " this is in some sense something that also haven't been successful in when I was young so I decided", "tokens": [51064, 341, 307, 294, 512, 2020, 746, 300, 611, 2378, 380, 668, 4406, 294, 562, 286, 390, 2037, 370, 286, 3047, 51320], "temperature": 0.0, "avg_logprob": -0.08133643264070563, "compression_ratio": 1.8482490272373542, "no_speech_prob": 0.003452691715210676}, {"id": 1383, "seek": 826208, "start": 8281.2, "end": 8286.96, "text": " not to become an architect but to become an explorer well I mean I think one one of the", "tokens": [51320, 406, 281, 1813, 364, 6331, 457, 281, 1813, 364, 39680, 731, 286, 914, 286, 519, 472, 472, 295, 264, 51608], "temperature": 0.0, "avg_logprob": -0.08133643264070563, "compression_ratio": 1.8482490272373542, "no_speech_prob": 0.003452691715210676}, {"id": 1384, "seek": 826208, "start": 8286.96, "end": 8291.68, "text": " comments that was made and I always think about the Steve Jobs and his response when he was", "tokens": [51608, 3053, 300, 390, 1027, 293, 286, 1009, 519, 466, 264, 7466, 29169, 293, 702, 4134, 562, 415, 390, 51844], "temperature": 0.0, "avg_logprob": -0.08133643264070563, "compression_ratio": 1.8482490272373542, "no_speech_prob": 0.003452691715210676}, {"id": 1385, "seek": 829208, "start": 8292.16, "end": 8298.24, "text": " he was asked a question by Steve Wozniak and Steve Wozniak said well but what do you do exactly", "tokens": [50368, 415, 390, 2351, 257, 1168, 538, 7466, 6622, 89, 3722, 514, 293, 7466, 6622, 89, 3722, 514, 848, 731, 457, 437, 360, 291, 360, 2293, 50672], "temperature": 0.0, "avg_logprob": -0.09104764563405615, "compression_ratio": 1.8509803921568628, "no_speech_prob": 0.003724743379279971}, {"id": 1386, "seek": 829208, "start": 8298.24, "end": 8302.48, "text": " because you don't code you don't do this you don't do this and he described himself as being", "tokens": [50672, 570, 291, 500, 380, 3089, 291, 500, 380, 360, 341, 291, 500, 380, 360, 341, 293, 415, 7619, 3647, 382, 885, 50884], "temperature": 0.0, "avg_logprob": -0.09104764563405615, "compression_ratio": 1.8509803921568628, "no_speech_prob": 0.003724743379279971}, {"id": 1387, "seek": 829208, "start": 8302.48, "end": 8308.08, "text": " a bit like a a conductor of an orchestra you know in a way that's how I see architects in", "tokens": [50884, 257, 857, 411, 257, 257, 29957, 295, 364, 25280, 291, 458, 294, 257, 636, 300, 311, 577, 286, 536, 30491, 294, 51164], "temperature": 0.0, "avg_logprob": -0.09104764563405615, "compression_ratio": 1.8509803921568628, "no_speech_prob": 0.003724743379279971}, {"id": 1388, "seek": 829208, "start": 8308.08, "end": 8312.24, "text": " the sense because we don't have any specialism you know we are basically we coordinate these", "tokens": [51164, 264, 2020, 570, 321, 500, 380, 362, 604, 2121, 1434, 291, 458, 321, 366, 1936, 321, 15670, 613, 51372], "temperature": 0.0, "avg_logprob": -0.09104764563405615, "compression_ratio": 1.8509803921568628, "no_speech_prob": 0.003724743379279971}, {"id": 1389, "seek": 829208, "start": 8312.24, "end": 8316.64, "text": " different sort of a or choreograph these different sort of skill sets and I think that's really what", "tokens": [51372, 819, 1333, 295, 257, 420, 14625, 3108, 613, 819, 1333, 295, 5389, 6352, 293, 286, 519, 300, 311, 534, 437, 51592], "temperature": 0.0, "avg_logprob": -0.09104764563405615, "compression_ratio": 1.8509803921568628, "no_speech_prob": 0.003724743379279971}, {"id": 1390, "seek": 831664, "start": 8316.64, "end": 8322.64, "text": " it is so in many ways you know I I can see a direct comparison with how you position yourself", "tokens": [50364, 309, 307, 370, 294, 867, 2098, 291, 458, 286, 286, 393, 536, 257, 2047, 9660, 365, 577, 291, 2535, 1803, 50664], "temperature": 0.0, "avg_logprob": -0.07529872836488666, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.03876812756061554}, {"id": 1391, "seek": 831664, "start": 8322.64, "end": 8327.84, "text": " in that sense I mean I I think it's a very it's a very similar sort of position and but I you know", "tokens": [50664, 294, 300, 2020, 286, 914, 286, 286, 519, 309, 311, 257, 588, 309, 311, 257, 588, 2531, 1333, 295, 2535, 293, 457, 286, 291, 458, 50924], "temperature": 0.0, "avg_logprob": -0.07529872836488666, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.03876812756061554}, {"id": 1392, "seek": 831664, "start": 8327.84, "end": 8332.16, "text": " I think that some of these these these comments that you've raised Joshua they're absolutely", "tokens": [50924, 286, 519, 300, 512, 295, 613, 613, 613, 3053, 300, 291, 600, 6005, 24005, 436, 434, 3122, 51140], "temperature": 0.0, "avg_logprob": -0.07529872836488666, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.03876812756061554}, {"id": 1393, "seek": 831664, "start": 8332.16, "end": 8336.64, "text": " fascinating I think we need time to digest them and fit them in the system what I would love to", "tokens": [51140, 10343, 286, 519, 321, 643, 565, 281, 13884, 552, 293, 3318, 552, 294, 264, 1185, 437, 286, 576, 959, 281, 51364], "temperature": 0.0, "avg_logprob": -0.07529872836488666, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.03876812756061554}, {"id": 1394, "seek": 831664, "start": 8336.64, "end": 8342.24, "text": " do above all especially with this particular discussion is to try and find a way of publishing", "tokens": [51364, 360, 3673, 439, 2318, 365, 341, 1729, 5017, 307, 281, 853, 293, 915, 257, 636, 295, 17832, 51644], "temperature": 0.0, "avg_logprob": -0.07529872836488666, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.03876812756061554}, {"id": 1395, "seek": 831664, "start": 8342.24, "end": 8346.16, "text": " the transcript because I mean I think this book that you have to write you must be written because", "tokens": [51644, 264, 24444, 570, 286, 914, 286, 519, 341, 1446, 300, 291, 362, 281, 2464, 291, 1633, 312, 3720, 570, 51840], "temperature": 0.0, "avg_logprob": -0.07529872836488666, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.03876812756061554}, {"id": 1396, "seek": 834616, "start": 8346.24, "end": 8351.92, "text": " I think you've got some fabulous fabulous thoughts that are really creative and original and provocative", "tokens": [50368, 286, 519, 291, 600, 658, 512, 17692, 17692, 4598, 300, 366, 534, 5880, 293, 3380, 293, 47663, 50652], "temperature": 0.0, "avg_logprob": -0.10950427282424201, "compression_ratio": 1.860377358490566, "no_speech_prob": 0.0017270541284233332}, {"id": 1397, "seek": 834616, "start": 8352.72, "end": 8356.88, "text": " so you know I really appreciate so I appreciate so much your your time and I let me we should let", "tokens": [50692, 370, 291, 458, 286, 534, 4449, 370, 286, 4449, 370, 709, 428, 428, 565, 293, 286, 718, 385, 321, 820, 718, 50900], "temperature": 0.0, "avg_logprob": -0.10950427282424201, "compression_ratio": 1.860377358490566, "no_speech_prob": 0.0017270541284233332}, {"id": 1398, "seek": 834616, "start": 8356.88, "end": 8361.76, "text": " you go look after the family now but this is I think almost like we've just opened up a discussion", "tokens": [50900, 291, 352, 574, 934, 264, 1605, 586, 457, 341, 307, 286, 519, 1920, 411, 321, 600, 445, 5625, 493, 257, 5017, 51144], "temperature": 0.0, "avg_logprob": -0.10950427282424201, "compression_ratio": 1.860377358490566, "no_speech_prob": 0.0017270541284233332}, {"id": 1399, "seek": 834616, "start": 8361.76, "end": 8365.92, "text": " and I hope that sometime in the future we can we can take that further and and think through", "tokens": [51144, 293, 286, 1454, 300, 15053, 294, 264, 2027, 321, 393, 321, 393, 747, 300, 3052, 293, 293, 519, 807, 51352], "temperature": 0.0, "avg_logprob": -0.10950427282424201, "compression_ratio": 1.860377358490566, "no_speech_prob": 0.0017270541284233332}, {"id": 1400, "seek": 834616, "start": 8365.92, "end": 8371.28, "text": " these kind of questions because your responses have been very generous and very really provocative", "tokens": [51352, 613, 733, 295, 1651, 570, 428, 13019, 362, 668, 588, 14537, 293, 588, 534, 47663, 51620], "temperature": 0.0, "avg_logprob": -0.10950427282424201, "compression_ratio": 1.860377358490566, "no_speech_prob": 0.0017270541284233332}, {"id": 1401, "seek": 837128, "start": 8371.6, "end": 8376.720000000001, "text": " and stimulating and I feel like you know although we have to pull this we draw this question this", "tokens": [50380, 293, 43671, 293, 286, 841, 411, 291, 458, 4878, 321, 362, 281, 2235, 341, 321, 2642, 341, 1168, 341, 50636], "temperature": 0.0, "avg_logprob": -0.09209429889643958, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.025407742708921432}, {"id": 1402, "seek": 837128, "start": 8376.720000000001, "end": 8381.36, "text": " session to a close it's almost the beginning of something else that we can look forward to so", "tokens": [50636, 5481, 281, 257, 1998, 309, 311, 1920, 264, 2863, 295, 746, 1646, 300, 321, 393, 574, 2128, 281, 370, 50868], "temperature": 0.0, "avg_logprob": -0.09209429889643958, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.025407742708921432}, {"id": 1403, "seek": 837128, "start": 8381.36, "end": 8387.44, "text": " I just want to thank Joshua for for fabulous I mean I want to recommend his all his online talks", "tokens": [50868, 286, 445, 528, 281, 1309, 24005, 337, 337, 17692, 286, 914, 286, 528, 281, 2748, 702, 439, 702, 2950, 6686, 51172], "temperature": 0.0, "avg_logprob": -0.09209429889643958, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.025407742708921432}, {"id": 1404, "seek": 837128, "start": 8387.44, "end": 8392.880000000001, "text": " as well to have a look at that there is a body of work out there that is that is this hugely", "tokens": [51172, 382, 731, 281, 362, 257, 574, 412, 300, 456, 307, 257, 1772, 295, 589, 484, 456, 300, 307, 300, 307, 341, 27417, 51444], "temperature": 0.0, "avg_logprob": -0.09209429889643958, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.025407742708921432}, {"id": 1405, "seek": 837128, "start": 8392.880000000001, "end": 8398.720000000001, "text": " provocative and hugely stimulating which I am excited by and I also maybe I could finish with", "tokens": [51444, 47663, 293, 27417, 43671, 597, 286, 669, 2919, 538, 293, 286, 611, 1310, 286, 727, 2413, 365, 51736], "temperature": 0.0, "avg_logprob": -0.09209429889643958, "compression_ratio": 1.7657992565055762, "no_speech_prob": 0.025407742708921432}, {"id": 1406, "seek": 839872, "start": 8398.72, "end": 8403.519999999999, "text": " one one simple question but no I started off the the discussion by saying that I think there is a", "tokens": [50364, 472, 472, 2199, 1168, 457, 572, 286, 1409, 766, 264, 264, 5017, 538, 1566, 300, 286, 519, 456, 307, 257, 50604], "temperature": 0.0, "avg_logprob": -0.15068143679771895, "compression_ratio": 1.7934272300469483, "no_speech_prob": 0.009462638758122921}, {"id": 1407, "seek": 839872, "start": 8403.519999999999, "end": 8408.96, "text": " a kind of let's say an emerging theory of intelligence that that is developing in this", "tokens": [50604, 257, 733, 295, 718, 311, 584, 364, 14989, 5261, 295, 7599, 300, 300, 307, 6416, 294, 341, 50876], "temperature": 0.0, "avg_logprob": -0.15068143679771895, "compression_ratio": 1.7934272300469483, "no_speech_prob": 0.009462638758122921}, {"id": 1408, "seek": 839872, "start": 8408.96, "end": 8415.92, "text": " kind of strange area where we're computer science and neuroscience and the world of the commercial", "tokens": [50876, 733, 295, 5861, 1859, 689, 321, 434, 3820, 3497, 293, 42762, 293, 264, 1002, 295, 264, 6841, 51224], "temperature": 0.0, "avg_logprob": -0.15068143679771895, "compression_ratio": 1.7934272300469483, "no_speech_prob": 0.009462638758122921}, {"id": 1409, "seek": 839872, "start": 8415.92, "end": 8423.279999999999, "text": " world and the academic world is coming together do you also see that glimpse of something emerging", "tokens": [51224, 1002, 293, 264, 7778, 1002, 307, 1348, 1214, 360, 291, 611, 536, 300, 25838, 295, 746, 14989, 51592], "temperature": 0.0, "avg_logprob": -0.15068143679771895, "compression_ratio": 1.7934272300469483, "no_speech_prob": 0.009462638758122921}, {"id": 1410, "seek": 842328, "start": 8423.28, "end": 8428.880000000001, "text": " some discourse some theoretical debate that is radically new and radically provocative", "tokens": [50364, 512, 23938, 512, 20864, 7958, 300, 307, 35508, 777, 293, 35508, 47663, 50644], "temperature": 0.0, "avg_logprob": -0.127837994519402, "compression_ratio": 1.7163461538461537, "no_speech_prob": 0.0016420251922681928}, {"id": 1411, "seek": 842328, "start": 8428.880000000001, "end": 8435.44, "text": " clearly that's why I went into cognitive science in the hope of being part of this new", "tokens": [50644, 4448, 300, 311, 983, 286, 1437, 666, 15605, 3497, 294, 264, 1454, 295, 885, 644, 295, 341, 777, 50972], "temperature": 0.0, "avg_logprob": -0.127837994519402, "compression_ratio": 1.7163461538461537, "no_speech_prob": 0.0016420251922681928}, {"id": 1412, "seek": 842328, "start": 8435.44, "end": 8441.52, "text": " synthesis happening between neuroscience and philosophy and artificial intelligence and", "tokens": [50972, 30252, 2737, 1296, 42762, 293, 10675, 293, 11677, 7599, 293, 51276], "temperature": 0.0, "avg_logprob": -0.127837994519402, "compression_ratio": 1.7163461538461537, "no_speech_prob": 0.0016420251922681928}, {"id": 1413, "seek": 842328, "start": 8441.52, "end": 8448.800000000001, "text": " linguistics and psychology and maybe the arts and I think at this moment the synthesis is still", "tokens": [51276, 21766, 6006, 293, 15105, 293, 1310, 264, 8609, 293, 286, 519, 412, 341, 1623, 264, 30252, 307, 920, 51640], "temperature": 0.0, "avg_logprob": -0.127837994519402, "compression_ratio": 1.7163461538461537, "no_speech_prob": 0.0016420251922681928}, {"id": 1414, "seek": 844880, "start": 8448.8, "end": 8454.8, "text": " very partial and in part that's because we teach our model makers and our observers in", "tokens": [50364, 588, 14641, 293, 294, 644, 300, 311, 570, 321, 2924, 527, 2316, 19323, 293, 527, 48090, 294, 50664], "temperature": 0.0, "avg_logprob": -0.0712433299239801, "compression_ratio": 1.9781659388646289, "no_speech_prob": 0.002470161532983184}, {"id": 1415, "seek": 844880, "start": 8454.8, "end": 8460.08, "text": " different departments we don't bring them together so we have people that are very good at making", "tokens": [50664, 819, 15326, 321, 500, 380, 1565, 552, 1214, 370, 321, 362, 561, 300, 366, 588, 665, 412, 1455, 50928], "temperature": 0.0, "avg_logprob": -0.0712433299239801, "compression_ratio": 1.9781659388646289, "no_speech_prob": 0.002470161532983184}, {"id": 1416, "seek": 844880, "start": 8460.08, "end": 8465.759999999998, "text": " formal models that can be tested and we have people that are very good at making observations", "tokens": [50928, 9860, 5245, 300, 393, 312, 8246, 293, 321, 362, 561, 300, 366, 588, 665, 412, 1455, 18163, 51212], "temperature": 0.0, "avg_logprob": -0.0712433299239801, "compression_ratio": 1.9781659388646289, "no_speech_prob": 0.002470161532983184}, {"id": 1417, "seek": 844880, "start": 8465.759999999998, "end": 8470.08, "text": " and reflecting about the world and seeing it very deeply and these people rarely talk", "tokens": [51212, 293, 23543, 466, 264, 1002, 293, 2577, 309, 588, 8760, 293, 613, 561, 13752, 751, 51428], "temperature": 0.0, "avg_logprob": -0.0712433299239801, "compression_ratio": 1.9781659388646289, "no_speech_prob": 0.002470161532983184}, {"id": 1418, "seek": 844880, "start": 8471.279999999999, "end": 8476.24, "text": " and they're rarely think together and this is what excites me to work in this area where", "tokens": [51488, 293, 436, 434, 13752, 519, 1214, 293, 341, 307, 437, 1624, 3324, 385, 281, 589, 294, 341, 1859, 689, 51736], "temperature": 0.0, "avg_logprob": -0.0712433299239801, "compression_ratio": 1.9781659388646289, "no_speech_prob": 0.002470161532983184}, {"id": 1419, "seek": 847624, "start": 8476.24, "end": 8481.44, "text": " these two areas intersect and maybe architecture is the right frame of looking at this.", "tokens": [50364, 613, 732, 3179, 27815, 293, 1310, 9482, 307, 264, 558, 3920, 295, 1237, 412, 341, 13, 50624], "temperature": 0.0, "avg_logprob": -0.14180302339441636, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.004725497215986252}, {"id": 1420, "seek": 847624, "start": 8482.8, "end": 8488.32, "text": " Nia thank you very much for inviting me I think it was a great conversation to have had today and", "tokens": [50692, 426, 654, 1309, 291, 588, 709, 337, 18202, 385, 286, 519, 309, 390, 257, 869, 3761, 281, 362, 632, 965, 293, 50968], "temperature": 0.0, "avg_logprob": -0.14180302339441636, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.004725497215986252}, {"id": 1421, "seek": 847624, "start": 8488.32, "end": 8497.44, "text": " very grateful for your beautiful community and for allowing me to talk about these ideas with you.", "tokens": [50968, 588, 7941, 337, 428, 2238, 1768, 293, 337, 8293, 385, 281, 751, 466, 613, 3487, 365, 291, 13, 51424], "temperature": 0.0, "avg_logprob": -0.14180302339441636, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.004725497215986252}, {"id": 1422, "seek": 847624, "start": 8497.44, "end": 8500.8, "text": " It's fantastic I'm going to finish with one comment which is because I used to be a lesson", "tokens": [51424, 467, 311, 5456, 286, 478, 516, 281, 2413, 365, 472, 2871, 597, 307, 570, 286, 1143, 281, 312, 257, 6898, 51592], "temperature": 0.0, "avg_logprob": -0.14180302339441636, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.004725497215986252}, {"id": 1423, "seek": 850080, "start": 8500.8, "end": 8508.08, "text": " translator and the word I should just say the word computation means to think together and I", "tokens": [50364, 35223, 293, 264, 1349, 286, 820, 445, 584, 264, 1349, 24903, 1355, 281, 519, 1214, 293, 286, 50728], "temperature": 0.0, "avg_logprob": -0.1135105353135329, "compression_ratio": 1.7814814814814814, "no_speech_prob": 0.04370516538619995}, {"id": 1424, "seek": 850080, "start": 8508.08, "end": 8511.84, "text": " think this is what's been happening today there's been almost like a neurons within neurons a kind", "tokens": [50728, 519, 341, 307, 437, 311, 668, 2737, 965, 456, 311, 668, 1920, 411, 257, 22027, 1951, 22027, 257, 733, 50916], "temperature": 0.0, "avg_logprob": -0.1135105353135329, "compression_ratio": 1.7814814814814814, "no_speech_prob": 0.04370516538619995}, {"id": 1425, "seek": 850080, "start": 8511.84, "end": 8517.759999999998, "text": " of global brain it's been fantastic. Yosha fantastic wonderful thank you for your time and sorry for", "tokens": [50916, 295, 4338, 3567, 309, 311, 668, 5456, 13, 398, 329, 1641, 5456, 3715, 1309, 291, 337, 428, 565, 293, 2597, 337, 51212], "temperature": 0.0, "avg_logprob": -0.1135105353135329, "compression_ratio": 1.7814814814814814, "no_speech_prob": 0.04370516538619995}, {"id": 1426, "seek": 850080, "start": 8517.759999999998, "end": 8521.759999999998, "text": " getting up so early but this has been a huge contribution to the architectural community", "tokens": [51212, 1242, 493, 370, 2440, 457, 341, 575, 668, 257, 2603, 13150, 281, 264, 26621, 1768, 51412], "temperature": 0.0, "avg_logprob": -0.1135105353135329, "compression_ratio": 1.7814814814814814, "no_speech_prob": 0.04370516538619995}, {"id": 1427, "seek": 850080, "start": 8521.759999999998, "end": 8526.56, "text": " and I hope that I've helped draw your the attention of your ideas to architects out there because I", "tokens": [51412, 293, 286, 1454, 300, 286, 600, 4254, 2642, 428, 264, 3202, 295, 428, 3487, 281, 30491, 484, 456, 570, 286, 51652], "temperature": 0.0, "avg_logprob": -0.1135105353135329, "compression_ratio": 1.7814814814814814, "no_speech_prob": 0.04370516538619995}, {"id": 1428, "seek": 852656, "start": 8526.56, "end": 8531.039999999999, "text": " think they're incredibly provocative ideas and I think they've a huge contribution to make to", "tokens": [50364, 519, 436, 434, 6252, 47663, 3487, 293, 286, 519, 436, 600, 257, 2603, 13150, 281, 652, 281, 50588], "temperature": 0.0, "avg_logprob": -0.1474368345169794, "compression_ratio": 1.8269230769230769, "no_speech_prob": 0.008054759353399277}, {"id": 1429, "seek": 852656, "start": 8531.039999999999, "end": 8536.48, "text": " architectural thinking itself so thank you Yosha thank you and thank you so much for this it's", "tokens": [50588, 26621, 1953, 2564, 370, 1309, 291, 398, 329, 1641, 1309, 291, 293, 1309, 291, 370, 709, 337, 341, 309, 311, 50860], "temperature": 0.0, "avg_logprob": -0.1474368345169794, "compression_ratio": 1.8269230769230769, "no_speech_prob": 0.008054759353399277}, {"id": 1430, "seek": 852656, "start": 8536.48, "end": 8541.119999999999, "text": " been fabulous and thank you wonderful day thank you and thank you for those team that put this", "tokens": [50860, 668, 17692, 293, 1309, 291, 3715, 786, 1309, 291, 293, 1309, 291, 337, 729, 1469, 300, 829, 341, 51092], "temperature": 0.0, "avg_logprob": -0.1474368345169794, "compression_ratio": 1.8269230769230769, "no_speech_prob": 0.008054759353399277}, {"id": 1431, "seek": 852656, "start": 8541.119999999999, "end": 8546.32, "text": " together a digital futures team we can't operate without your help thank you so much and see you", "tokens": [51092, 1214, 257, 4562, 26071, 1469, 321, 393, 380, 9651, 1553, 428, 854, 1309, 291, 370, 709, 293, 536, 291, 51352], "temperature": 0.0, "avg_logprob": -0.1474368345169794, "compression_ratio": 1.8269230769230769, "no_speech_prob": 0.008054759353399277}, {"id": 1432, "seek": 854632, "start": 8546.32, "end": 8551.92, "text": " next week thank you everybody thank you bye", "tokens": [50364, 958, 1243, 1309, 291, 2201, 1309, 291, 6543, 50644], "temperature": 0.0, "avg_logprob": -0.5071639581160112, "compression_ratio": 1.0238095238095237, "no_speech_prob": 0.15666306018829346}], "language": "en"}