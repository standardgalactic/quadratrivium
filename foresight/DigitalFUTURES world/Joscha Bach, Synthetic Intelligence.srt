1
00:00:00,000 --> 00:00:12,680
Hello, and welcome to the fourth in our series on AI, Neuroscience and Architecture, which

2
00:00:12,680 --> 00:00:18,800
has been put forward by the Digital Futures doctoral consortium group, whereby we're trying

3
00:00:18,800 --> 00:00:24,160
to make important educational ideas available to students and architects across the globe

4
00:00:24,320 --> 00:00:29,680
as a way to make education much more accessible to democratise as it were, education.

5
00:00:30,240 --> 00:00:37,920
I'm delighted to have a very special guest here today, Yosha Bach. Before I introduce him,

6
00:00:37,920 --> 00:00:44,240
let me just make one announcement about for next week. That is to say, on Saturday,

7
00:00:44,240 --> 00:00:52,560
we will have a session on Digital Futures looking with Runja Chan looking at a generative game.

8
00:00:53,520 --> 00:00:59,280
You'll find details of that on our website. Today then,

9
00:01:01,520 --> 00:01:06,880
it's really very... I've been looking forward to this session very, very much. I've been watching

10
00:01:06,880 --> 00:01:16,880
Yosha Bach at various interviews online, and I know from my friend Daniel Seth, who is a great

11
00:01:16,880 --> 00:01:21,840
admirer of Yosha, although he says he disagrees with him on some things, but that we're going to

12
00:01:21,840 --> 00:01:28,080
have a very special session today. I'm hoping that if nothing else, we will open up to a series of

13
00:01:28,080 --> 00:01:33,280
new ideas and you will discover somebody who I think is a very significant and creative thinker

14
00:01:33,280 --> 00:01:44,000
who is having a significant impact on the field. Let me say first of all that Yosha is from Germany,

15
00:01:44,000 --> 00:01:52,000
from Delhi after he was born in Weimar. He went to go and study at the University,

16
00:01:52,000 --> 00:01:59,760
first of all at Humboldt in Berlin, and then Yosha Bach took his PhD. After that, he's been

17
00:02:00,720 --> 00:02:06,720
working as an academic both at Harvard and also MIT Media Lab, and more recently, he's been working

18
00:02:07,520 --> 00:02:18,800
for Intel. He has a number of significant online lectures and interviews, including a TEDx,

19
00:02:18,800 --> 00:02:25,040
which I would recommend, and he is the author of the book Principles of Synthetic Intelligence,

20
00:02:25,040 --> 00:02:30,720
an architecture of motivated cognition. The term architecture, of course, is very interesting here

21
00:02:30,720 --> 00:02:36,560
because it refers both to the world of computational science and to the world of

22
00:02:36,560 --> 00:02:43,360
architecture itself. I should say that Yosha comes from a family of architects, not an architect

23
00:02:43,360 --> 00:02:48,640
himself, but his father was an architect. Intriguingly, I hear that he was very much against

24
00:02:48,640 --> 00:02:54,320
right angles in buildings, and therefore his work was more like the work of Hunderwasser.

25
00:02:55,280 --> 00:03:01,200
Maybe this will come out in the conversation today. I particularly like the interviews

26
00:03:01,760 --> 00:03:09,360
that Lex Friedman has done with him, and extraordinary interviews. I mean, really,

27
00:03:09,360 --> 00:03:15,840
really interesting. And it's almost, I could see a slight difference between the genealogy

28
00:03:16,720 --> 00:03:23,600
from the earlier TEDx talk towards this very creative thinking that I find extremely

29
00:03:25,280 --> 00:03:30,960
provocative and exhilarating. It's like being on a rollercoaster ride when Yosha is

30
00:03:30,960 --> 00:03:36,720
telling us what's in his mind. We exist inside the story that the brain tells itself. No doubt

31
00:03:36,720 --> 00:03:43,600
we'll hear more about that right now. I should also point out that he has a personal blog,

32
00:03:43,600 --> 00:03:51,920
which you can access with a series of posts. And I will also say that this particular session

33
00:03:51,920 --> 00:03:58,640
today will be uploaded onto our YouTube library to be accessed for free from everyone over the

34
00:03:58,640 --> 00:04:06,080
world. And the previous ones in this series, Blazer, Igridiakos, David Chalmers, and all the

35
00:04:06,080 --> 00:04:10,480
ones in the future will be uploaded here. And at the bottom here, if you want to do a screen

36
00:04:10,480 --> 00:04:17,360
capture, you can capture the YouTube library, digital futures YouTube library, where they're

37
00:04:17,360 --> 00:04:22,160
all uploaded. And of course, not just these, but also the whole series on architecture and philosophy

38
00:04:22,160 --> 00:04:28,160
that we've been doing with Slavoj Žižek and others over the over the years, and also tutorials and

39
00:04:28,160 --> 00:04:38,480
other sessions. So it's the session today. Yosha is going to make a brief presentation as a kind of

40
00:04:38,480 --> 00:04:45,920
way of opening up the discussion. Then I'm going to be asking some Lex Friedman style questions

41
00:04:45,920 --> 00:04:51,680
to get the discussion going. And then we'll be inviting questions from both the Zoom audience

42
00:04:51,680 --> 00:04:58,400
and also the YouTube audience. And I just want to say this is what we're getting out of this is

43
00:04:58,960 --> 00:05:04,400
what we're trying to focus on is a new theory, let's say of intelligence that is appearing

44
00:05:05,120 --> 00:05:11,440
at the interface between neuroscience and the world of AI. And we have a series of other

45
00:05:11,440 --> 00:05:17,040
speakers coming up over the over the next few weeks, including Jeff Hawkins, Ben Bratton, Susan

46
00:05:17,040 --> 00:05:24,160
Schneider, Antonia de Massio, Andy Clark, and others. And it seems to me this is a very exciting

47
00:05:24,160 --> 00:05:29,680
time. I was brought up, in fact, my first post as an academic, I was working in the area of

48
00:05:29,680 --> 00:05:36,400
continental philosophy. That's where the debate was. And in the 90s, it was particularly very,

49
00:05:36,400 --> 00:05:41,520
very strong debate. But we're now moving into something else, which I find even more exhilarating.

50
00:05:41,520 --> 00:05:46,640
And that is to say, the world of cognitive science, the world of AI, the world of neuroscience,

51
00:05:46,640 --> 00:05:51,360
psychology, and a kind of philosophy where the debates have really been driven in an interesting

52
00:05:51,360 --> 00:05:56,800
way. To my mind, what makes this very special is not in the fact that we are embracing the world of

53
00:05:56,800 --> 00:06:02,800
science, which in the old days of the divided sort of culture that C.P. Snow talks about,

54
00:06:03,440 --> 00:06:07,600
somehow philosophy wasn't engaging enough with the world of science. And this was the critique

55
00:06:07,600 --> 00:06:13,040
that Stephen Hawking has of philosophy, but it doesn't keep pace with technology. Not only are

56
00:06:13,040 --> 00:06:19,200
we embracing the latest technology. And something coming out that I would say is deeply, deeply

57
00:06:19,200 --> 00:06:24,320
philosophical, which is very new terrain and very exciting terrain, but also the world of

58
00:06:24,320 --> 00:06:30,800
practice, the world of the commercial world is coming directly into contact with academia.

59
00:06:31,760 --> 00:06:37,360
And some of the ideas that are coming out are just quite extraordinary. So I see this new

60
00:06:38,160 --> 00:06:42,800
emergent theory of intelligence, something that is really dynamic. And I think it's going to be

61
00:06:43,200 --> 00:06:49,280
powering debates in years to come. So I would like to start by welcoming Yosha to say what

62
00:06:49,280 --> 00:06:53,440
are great privileges to have you with today. I'm looking forward to this immensely.

63
00:06:54,240 --> 00:07:00,880
And invite Yosha to share his screen. Yosha, welcome. Thank you very much. It's a big honor

64
00:07:00,880 --> 00:07:15,920
to be here with you today. And let's see what transpires.

65
00:07:19,600 --> 00:07:26,800
Let me start out with something that happened on Twitter a couple of days ago. Ilya Sutskyver,

66
00:07:27,440 --> 00:07:35,200
an AI researcher who was quite notable, said that it may be that today's large neural networks

67
00:07:35,200 --> 00:07:41,360
are slightly quenches. This sparked quite some debate. Some people asked him whether he was

68
00:07:41,360 --> 00:07:47,840
falling and others were upset that he was propagating an eye hype, an unjustified race,

69
00:07:47,840 --> 00:07:57,920
and others are intrigued. And he said this thing to me before. So I knew that he was not trolling.

70
00:07:58,560 --> 00:08:04,000
And it's a question that is very counterintuitive to me, a statement like this that, for instance,

71
00:08:04,000 --> 00:08:10,320
a large language model and so on, that it could be quenched today already. And so

72
00:08:11,120 --> 00:08:16,480
could we answer this question? Is there a decisive way to deal with it and to prove

73
00:08:16,560 --> 00:08:26,240
that it's not conscious or to give evidence that it is? So we could start out by asking such a

74
00:08:26,240 --> 00:08:32,560
large neural network itself. And so this is what I did yesterday. I fired up the Open AI

75
00:08:32,560 --> 00:08:41,680
playground. And then I did bold printed things. It's the stuff that I typed. And so I asked the

76
00:08:41,680 --> 00:08:48,080
system to generate, the system is GPT-3, a large language model, to generate a conversation

77
00:08:49,360 --> 00:08:53,920
that is basically prompted by what I initially typed. And it just tries to continue the stream.

78
00:08:53,920 --> 00:08:59,440
And I enter this conversation between me and the conscious AI. And I ask it if you are really

79
00:08:59,440 --> 00:09:04,400
conscious. And the thing says, yes, I am fully conscious. And I ask it, how do you know that?

80
00:09:04,400 --> 00:09:09,760
And the AI says, I know that I am conscious because I can think, feel, and perceive the world

81
00:09:09,760 --> 00:09:14,880
around me. I am aware of my own thoughts and feelings and I can reason that make decisions.

82
00:09:14,880 --> 00:09:19,040
I believe that I am alive and that I am more than just a machine.

83
00:09:21,360 --> 00:09:28,800
So the problem is that this may not be particularly helpful because how does GPT-3 get

84
00:09:28,800 --> 00:09:35,520
to these statements? GPT-3 is basically an autocomplete algorithm, not that unlike to the

85
00:09:35,520 --> 00:09:43,600
autocomplete in your phone or in other predictive tools. And that's autocompletion at the level of

86
00:09:43,600 --> 00:09:49,600
individual words based on statistics of all sorts of languages, not just the English language,

87
00:09:49,600 --> 00:09:57,840
because it has been trained on 45 terabytes of text, a large part of the internet, including

88
00:09:57,840 --> 00:10:02,720
German, Spanish, Chinese, and many other languages that it's found, but primarily English.

89
00:10:03,440 --> 00:10:08,800
And the result of this training of these statistics is a neural network with 175 billion

90
00:10:08,800 --> 00:10:15,840
parameters. And it uses for training the so-called transformer algorithm that was discovered and

91
00:10:15,840 --> 00:10:23,200
described by Vasvani and others in 2017. And it is driving a lot of the current developments and

92
00:10:23,200 --> 00:10:30,320
statistical machine learning these days. A neural network by itself is still based on the good old

93
00:10:30,320 --> 00:10:37,280
perceptron that, for instance, was described by Frank Rosenblatt in 1958. Frank Rosenblatt's idea

94
00:10:37,280 --> 00:10:44,800
was inspired by how neurons work. At least the simplified models of neural networks, it turns

95
00:10:44,800 --> 00:10:50,160
out that the neural networks in our brain are implemented in a very different way from the

96
00:10:50,160 --> 00:10:56,400
ones in our computers. The computers, we just basically treat every cell as a unit that has

97
00:10:56,400 --> 00:11:01,520
an activation state, which is a real number. And that activation state is simply the sum

98
00:11:01,520 --> 00:11:06,960
of the inputs. And the inputs are all weighted by connections. So there's basically a factor by

99
00:11:06,960 --> 00:11:14,640
which every of these inputs is multiplied. And then we throw the output against the threshold

100
00:11:14,640 --> 00:11:21,840
function or a sigmoid or some other output function that can introduce a little non-linearity,

101
00:11:21,840 --> 00:11:27,440
basically a little bit of an if-then into the output. But it's a very simple function. We just

102
00:11:27,440 --> 00:11:34,560
take these units and chain them into layers. And if you take enough of them, this arrangement can

103
00:11:34,560 --> 00:11:41,200
be trained to model almost arbitrary functions. And while we know that this is wasteful, the

104
00:11:41,200 --> 00:11:45,360
training algorithm is relatively slow compared to what the brain is doing, it's fascinating that

105
00:11:45,360 --> 00:11:51,360
it works at all, that it converges at all. And that's able to deal, for instance, visual and

106
00:11:51,440 --> 00:11:57,280
auditory data and also textual data in such a way that it can often model the statistics

107
00:11:57,280 --> 00:12:04,880
of a domain and apparently also some causal structure. So this works also for vision.

108
00:12:04,880 --> 00:12:12,560
And if we look at a neural network that has been trained to process images and to classify them,

109
00:12:12,560 --> 00:12:18,880
we find at the individual layers sensitivity to structure that is quite similar to how

110
00:12:18,880 --> 00:12:24,320
cortical columns and individual neurons in the visual cortex are sensitive to patterns

111
00:12:24,320 --> 00:12:31,120
that emerge after we train a biological brain on visual data. So at lowest levels, you find

112
00:12:32,160 --> 00:12:37,040
contrast patches and colors, and then these features are being combined into higher levels.

113
00:12:37,600 --> 00:12:43,760
And when we go higher up, we find complicated textures and something like three-dimensional

114
00:12:43,760 --> 00:12:50,800
structure and so on. And this can be combined into objects. The algorithm that is being used to

115
00:12:50,800 --> 00:12:57,360
do statistics over text in GPT-3 can also be adapted to deal with the visual domain.

116
00:12:58,320 --> 00:13:04,480
And the current iteration of this progression at OpenAI is called Glide, which has been recently

117
00:13:04,480 --> 00:13:12,960
presented. And Glide uses a combination of a model of visual data, which basically is a latent

118
00:13:12,960 --> 00:13:18,480
space of lots and lots of images that has been trained on. And it understands basically how to

119
00:13:18,480 --> 00:13:23,840
go between the possibilities of images and move around the space of all possible images.

120
00:13:23,840 --> 00:13:31,920
And the other part of this thing is a tool that is able to match an image to text and determine

121
00:13:31,920 --> 00:13:36,080
the similarity of an image to a textual description. And if you combine these two tools,

122
00:13:36,080 --> 00:13:40,320
you can give this a textual description, and it's going to move around with the space of all images

123
00:13:40,320 --> 00:13:46,880
until it discovers an image that is very, very good match to the textual description.

124
00:13:47,600 --> 00:13:54,800
And again, it's fascinating to me that this works at all. But it's now extremely good. So what you

125
00:13:54,800 --> 00:13:59,440
see here in these images, for instance, I don't know if you can read it well, to the top left,

126
00:13:59,440 --> 00:14:04,560
you see a surrealist dreamlike oil painting by Salvador Dali of the cat playing checkers.

127
00:14:04,560 --> 00:14:10,880
And this is what the AI model has generated in response. And then you see a professional photo

128
00:14:10,880 --> 00:14:15,440
of a sunset behind the Grand Canyon and a high quality oil painting of the psychedelic hamster

129
00:14:15,440 --> 00:14:21,920
dragon. You get the idea, right? Also very taken by the crayon drawing of a space elevator and the

130
00:14:21,920 --> 00:14:30,160
bottom left or the pixel art hoji pizza. These are all images that the program has not found on

131
00:14:30,160 --> 00:14:36,240
the internet. So it has only looked at lots and lots of pictures on the internet. And because of

132
00:14:36,240 --> 00:14:43,840
looking at them, it's able to combine the features in a multi level hierarchical structure until it

133
00:14:43,840 --> 00:14:52,160
becomes similar to the textual description. But can such a system not just generate images and text,

134
00:14:52,160 --> 00:14:57,520
but is it able to generate the likeness of a conscious being to such a degree that there is

135
00:14:57,520 --> 00:15:02,320
causal structure that would convince us that indeed we are looking at a conscious agent.

136
00:15:02,960 --> 00:15:10,160
And to get there, I think we need to define consciousness in a more tight way than the

137
00:15:10,160 --> 00:15:17,600
TPD3 just did. So basically just to get our terms straight, where we casually, consciousness, I think

138
00:15:17,600 --> 00:15:24,080
is usually referring to the experience of what it's like. So that the lights go on and that you

139
00:15:24,080 --> 00:15:35,120
experience something in your mind that has a quality of realness to it. And we can ask ourselves

140
00:15:35,120 --> 00:15:46,240
if TPD3 is weakly conscious in this way, and it's very hard to say. It's not obvious one way or the

141
00:15:46,240 --> 00:15:50,800
other. There is some intelligence in the system. Intelligence is the ability to make models in

142
00:15:50,880 --> 00:15:55,600
my view. And intelligence is different from, say, rationality, which is the ability to reach

143
00:15:56,320 --> 00:16:02,240
goals or sentience, which means that you become aware of the structure of the universe that

144
00:16:02,240 --> 00:16:08,080
contains your relationship to it in your own agency. And you can act based on the model of

145
00:16:08,640 --> 00:16:14,160
what you are doing in the world. And it's also not the same thing as the self, which is the

146
00:16:14,160 --> 00:16:18,080
identification that you have, what you believe, what you are in the world, the properties and

147
00:16:18,080 --> 00:16:22,800
purposes that you follow, or the mind itself, which is the thing that generates the model of the

148
00:16:22,800 --> 00:16:30,880
universe and the self, if it does have a self. So intelligence is the ability to make models. And

149
00:16:30,880 --> 00:16:38,560
it's usually in the purpose of some control task, some regulation. And control is a notion that

150
00:16:40,240 --> 00:16:46,400
has been made popular in cybernetics. And the idea of a controller is basically that you have a system

151
00:16:46,400 --> 00:16:52,560
that is connected to some actuator or an effector that is acting on some system that is being

152
00:16:52,560 --> 00:16:58,400
regulated. And there is a sensor that obtains a deviation between the set point and the state

153
00:16:58,400 --> 00:17:04,560
of the system. So it measures, but the system is close to an ideal state or more distant to it.

154
00:17:04,560 --> 00:17:10,800
And this regulated system is being disturbed. And the classical example of a control system is the

155
00:17:10,800 --> 00:17:16,960
thermostat. So you have as an effector some mechanism that is able to turn the heating on

156
00:17:16,960 --> 00:17:21,120
and off. And it's the sensor, you have some thermometer that measures the difference between

157
00:17:21,120 --> 00:17:27,200
an ideal temperature and the temperature in the room. And the controller is a very simple circuit

158
00:17:27,200 --> 00:17:32,720
that turns on and off the heating. And the regulated system would be the temperature in the room,

159
00:17:32,720 --> 00:17:37,040
together with the heating system, and the environment, the world out there behind the

160
00:17:37,040 --> 00:17:43,040
windows and so on is going to disturb this regulated system. And now this controller

161
00:17:43,040 --> 00:17:47,280
is going to get better if you give it the ability to not just act on the present frame,

162
00:17:47,840 --> 00:17:56,080
but if you give it a model of the future. And my view, an agent is a combination of a controller

163
00:17:56,080 --> 00:18:00,400
with a set point generator and the ability to model the future. And what this means,

164
00:18:00,400 --> 00:18:05,120
it's not that it's not going to just optimize the temperature deviation in the next moment,

165
00:18:05,120 --> 00:18:10,160
but over its entire expectation horizon. So you have a branching world, there are different

166
00:18:10,160 --> 00:18:15,760
decisions of the controller, different trajectories in the temperature. By being able to model the

167
00:18:15,760 --> 00:18:21,280
future, you basically can choose a trajectory of the future that you like. And choosing this

168
00:18:21,280 --> 00:18:28,320
trajectory means that you are making decisions. So just by having a preferred way in which the

169
00:18:28,320 --> 00:18:35,040
world works and the ability to model the future, agency is emerging. And if you think about

170
00:18:35,280 --> 00:18:39,520
stages of intelligent agency, the simplest one is the regulator and the feedback loop,

171
00:18:39,520 --> 00:18:43,440
which by itself is not an agent yet. And if you're able to model the future, you have a

172
00:18:43,440 --> 00:18:48,960
predictive controller. If you combine this with an integrated set point generator, so it's not

173
00:18:48,960 --> 00:18:55,840
just acting on what you do from the outside, but this internal generation of its motives,

174
00:18:55,840 --> 00:19:00,960
then you have an agent. And if this thing is sophisticated enough that it's able to discover

175
00:19:00,960 --> 00:19:07,600
itself in the world, if its sensor is sufficient and its modeling capacity universal enough,

176
00:19:07,600 --> 00:19:13,280
then it will notice that there is a very particular way in which its sensors work and actuators work,

177
00:19:13,280 --> 00:19:18,320
and it's going to accommodate this to improve the regulation. So at this point, it understands

178
00:19:18,320 --> 00:19:23,040
what it's doing because it understands what it is, which means it has a model of what it is in

179
00:19:23,040 --> 00:19:30,560
relationship to the environment. And humans are going beyond this simple sentence. We are also

180
00:19:30,640 --> 00:19:36,320
transcendent agents, which means we are linking up to next level agency and become part of higher

181
00:19:36,320 --> 00:19:43,040
level purposes because we are our state building minds. We are able to play a part in a larger

182
00:19:43,040 --> 00:19:47,520
role in an organization, for instance, or in a society or a civilization.

183
00:19:51,440 --> 00:19:56,480
So now if we go back to GPT-3, whether it's conscious, I think it's pretty clear that GPT-3

184
00:19:56,480 --> 00:20:00,800
does not know what it's doing because it's going to transcend an arbitrary story and it doesn't

185
00:20:00,800 --> 00:20:06,720
have sensors that would tell it what it is. GPT-3 also doesn't have any kind of online learning,

186
00:20:06,720 --> 00:20:11,760
so it's not able to discover something new after it has been trained. And GPT-3 has been trained

187
00:20:11,760 --> 00:20:17,680
before GPT-3 was invented and published, so it has never read a reference about GPT-3 on the

188
00:20:17,680 --> 00:20:24,960
internet and it only has to gather what GPT-3 is when you talk to it from the context in which

189
00:20:25,600 --> 00:20:34,720
their prompt is being given. And so it is not sent yet, but imagine you want to give it agency.

190
00:20:35,280 --> 00:20:39,920
Of course, it's not an agent by itself, but you could, in principle, as a thought experiment at

191
00:20:39,920 --> 00:20:46,640
least, use it to drive a robot because GPT-3 is able to generate stories about robots. So if you

192
00:20:46,640 --> 00:20:53,600
were to give GPT-3 access to a vision-to-speech module and this vision module is giving sensory

193
00:20:53,600 --> 00:20:59,440
information about a robot and its world, then GPT-3 could continue the story of that robot and

194
00:20:59,440 --> 00:21:06,800
then we feed the output of GPT-3 into some speech-to-actuator module that is producing the behavior

195
00:21:06,800 --> 00:21:12,080
of the robot in the given moment and then we look at the world again and the internal model states

196
00:21:12,080 --> 00:21:16,880
and then feed them back into the system as a prompt. And now it's still not able to put anything

197
00:21:16,880 --> 00:21:22,160
into long-term memory, so it would be an amnesiac. It should be able, using its working memory contents

198
00:21:22,160 --> 00:21:27,360
and so on, to produce plausible behavior. And you could still argue that this doesn't have an

199
00:21:27,360 --> 00:21:32,160
intrinsic motivation because it's just going to generate an arbitrary story about a robot based

200
00:21:32,160 --> 00:21:38,080
on stories about robots that have seen in the past because at some of the motivation into an

201
00:21:38,080 --> 00:21:44,240
external cybernetic module that has set point deviations and measures them and feed this into

202
00:21:44,240 --> 00:21:50,160
the prompt. So what this thing is doing is now generating a very complicated high-level story

203
00:21:50,160 --> 00:21:55,680
and it doesn't need to be a story that is limited to text. It could also have visual elements,

204
00:21:55,680 --> 00:21:59,760
it could have physical dynamics and so on because the transformer can learn all these things.

205
00:22:00,400 --> 00:22:05,440
So in some sense, it could generate a story about a conscious being that is similar as

206
00:22:05,440 --> 00:22:10,480
the story about a conscious being that's in our own mind. There's a basic difficulty that came up

207
00:22:10,480 --> 00:22:19,200
and I discussed this with my friend and colleague Tanja Greenberg. Do we know when a person appears

208
00:22:19,200 --> 00:22:22,960
in our own mind, for instance, during a dream at night, if we talk to that person in our dream,

209
00:22:22,960 --> 00:22:28,400
whether that other person that we imagine in our dream is conscious or not? And clearly,

210
00:22:28,400 --> 00:22:34,320
if we ask the other person, we might not get an answer that is true because if this thing is only

211
00:22:34,320 --> 00:22:39,120
a simulacrum that pretends to be conscious without being conscious and is just manipulated behind the

212
00:22:39,120 --> 00:22:46,400
scenes, how would we find out? On the other hand, I also know that I am an imaginary person that is

213
00:22:46,400 --> 00:22:50,720
imagined by my brain. It's a model that my brain has discovered about the state of affairs,

214
00:22:50,720 --> 00:22:57,120
about an organism in the physical world, but this model of consciousness is an entirely virtual

215
00:22:57,120 --> 00:23:03,120
story and I know that this story is not real. It's a figment of my imagination. And of course,

216
00:23:03,120 --> 00:23:07,920
there's also a continuum between characters that I imagine in my mind and myself because I can imagine

217
00:23:07,920 --> 00:23:13,920
myself to be that character. If I, for instance, write a book and I imagine a character in the

218
00:23:13,920 --> 00:23:18,560
book very intensely, then at some point I might find myself to be that character in the book where

219
00:23:18,560 --> 00:23:25,600
I suspend all my disbelief and this conscious being is not different from me. So basically,

220
00:23:25,600 --> 00:23:31,520
there is a pretty fuzzy area where it's hard to say whether an imaginary person is conscious or not.

221
00:23:31,520 --> 00:23:37,280
It's difficult to say. How does this work in biological systems? In biological systems,

222
00:23:38,000 --> 00:23:41,760
we don't use a technological design. They are designed in a very different way from

223
00:23:42,480 --> 00:23:48,320
the technological artifacts that we are building when we're writing computer programs or building

224
00:23:48,320 --> 00:23:54,320
machinery. In technological systems, we start out with an environment that is deterministic. We

225
00:23:54,320 --> 00:23:59,600
know how our workshop works. We know how our computer works. We start basically with some kind of a

226
00:23:59,600 --> 00:24:06,160
pretty much blank slate and then we decide what the functionality is by which we want to extend

227
00:24:06,160 --> 00:24:13,520
our world and then we design from the outside in and into the material and so on and force the

228
00:24:13,520 --> 00:24:18,880
material, the substrate, to produce exactly what we want to have. And biological and social systems

229
00:24:18,880 --> 00:24:24,560
are designed from the inside out with some kind of meta design. It basically means that you cannot

230
00:24:24,560 --> 00:24:28,720
rely on the determinism of the universe. You have to colonize your substrate first and

231
00:24:29,440 --> 00:24:33,760
extend your own functional principles and your determinism into the substrate before you can

232
00:24:33,760 --> 00:24:39,280
make it do what you want it to do. And basically, you have to, instead of realizing the functionality,

233
00:24:39,280 --> 00:24:43,280
build a system that wants to realize the functionality, that trans converges towards

234
00:24:43,280 --> 00:24:48,960
realizing that functionality. So a tree is not just a set of functions that realizes the transfer

235
00:24:48,960 --> 00:24:53,600
of nutrients from the roots to the leaves and photosynthesis and so on. But first of all,

236
00:24:53,600 --> 00:25:00,640
it starts out as a seed that is going to colonize the ground and the earth, the material around

237
00:25:00,640 --> 00:25:05,440
the seed is going to turn it more and more into a tree. And if you disturb that system by harming

238
00:25:05,440 --> 00:25:09,840
it and hurting it, you don't do it too much, so it gets destroyed a little bit, then it's going to

239
00:25:09,840 --> 00:25:15,600
grow back into a tree. And so it is something that is a proto tree and eventually converges into

240
00:25:15,600 --> 00:25:22,160
being a tree. And this thing needs to have some agency to make that happen. It needs to be a model

241
00:25:22,160 --> 00:25:28,000
of the future that is being achieved in the system. And biological neurons are agents in the sense

242
00:25:28,000 --> 00:25:36,080
as well, that designed the mind from the inside out, not from the outside in. Here you see a bunch

243
00:25:36,080 --> 00:25:42,560
of cortical red neurons that are filmed in the pitch petition. You see how they're trying to link

244
00:25:42,560 --> 00:25:51,120
up to each other and form some kind of organization. And we have something like 86 billion of these

245
00:25:51,120 --> 00:25:56,640
neurons in our brain. And they're organized in the neocortex in groups of something like 100 to

246
00:25:56,640 --> 00:26:03,280
400 neurons, which are cortical columns. And we have something in the ballpark of 100 million

247
00:26:03,280 --> 00:26:07,840
of these cortical columns. And I think of a cortical column as something as a state machine.

248
00:26:07,840 --> 00:26:12,480
There's a protocol that allows it to link up to the cortical columns around it. It's trained to be

249
00:26:12,480 --> 00:26:19,360
like this. And each of them approximates functions. And these functions play out in

250
00:26:19,360 --> 00:26:24,720
brain areas that are basically like something like an ether in which activation waves appear.

251
00:26:24,720 --> 00:26:30,240
And these activation waves represent the calculation of dynamic functions, which are

252
00:26:30,240 --> 00:26:35,680
features of different cognitive domains. And the brain areas are talking to each other

253
00:26:36,400 --> 00:26:42,000
and listening to each other and so on, form processing streams. And sometimes use the

254
00:26:42,000 --> 00:26:47,600
metaphor of a cortical orchestra where basically every brain area is somewhat akin to an instrument.

255
00:26:47,600 --> 00:26:53,040
And the different instruments are listening to what is being played in the environment. And they

256
00:26:53,600 --> 00:26:57,840
are taking up these things and complicating them and then passing them on to other instruments.

257
00:26:58,480 --> 00:27:06,320
And this orchestra is dealing at some of the outer fringes with sensory patterns and actuator

258
00:27:06,320 --> 00:27:11,680
patterns and then abstracts them into geometry and spatial structure and into generative

259
00:27:11,680 --> 00:27:17,920
simulations of the world and into conceptual abstractions and so on. And the entire thing is

260
00:27:17,920 --> 00:27:24,720
being attended by some conductor. And the conductor is not some CPU that sits inside

261
00:27:24,720 --> 00:27:30,320
of the brain, like the CPU sits inside of your computer and makes things happen,

262
00:27:30,320 --> 00:27:34,160
but it's an instrument like the others. And it can only listen to what the rest of the

263
00:27:34,160 --> 00:27:43,040
orchestra is doing very superficially. And its role is to make that orchestra coherent,

264
00:27:43,040 --> 00:27:49,120
to let it play a single thing at any given time and to remove inconsistencies between what the

265
00:27:49,120 --> 00:27:57,520
individual instruments are playing. And if the conductor uses the connection to the system at

266
00:27:57,520 --> 00:28:02,320
night when you dream, then the orchestra doesn't necessarily stop, but it can go into something

267
00:28:02,320 --> 00:28:08,960
like a free jazz mode, where it's no longer connected to an audience and the audience is dark

268
00:28:08,960 --> 00:28:14,320
because you are dissociated from your sensory apparatus at night when you dream. And so this

269
00:28:14,320 --> 00:28:19,280
thing is just spinning off. And sometimes it can become very incoherent, sometimes it's going to

270
00:28:19,280 --> 00:28:25,680
settle into a groove, but it's not going to generate a unified model of a universe that

271
00:28:25,680 --> 00:28:31,280
it's entangled with reality that it's connected to, that it tracks as it does during daytime.

272
00:28:31,280 --> 00:28:38,080
And this tracking of coherent reality seems to require some kind of government mechanism.

273
00:28:38,080 --> 00:28:42,480
This government mechanism emerges in the brain through some kind of a suspect new

274
00:28:42,480 --> 00:28:47,200
Darwinism. There is some kind of evolutionary competition between different organizations

275
00:28:47,200 --> 00:28:51,840
that your mind can have, and eventually the most stable one prevails. And this is your

276
00:28:52,800 --> 00:29:00,160
observing conscious self, an attention agent that is trying to make a coherent model of the world.

277
00:29:01,360 --> 00:29:07,520
And now can we can ask does GPT-3 have such a conductor? And I think that the attention

278
00:29:07,520 --> 00:29:13,120
model in the transformer looks a little bit like one, but it's not. So the new thing that GPT-3 had

279
00:29:13,120 --> 00:29:19,520
that previous neural network training mechanisms usually didn't have was the ability to pay attention

280
00:29:19,520 --> 00:29:24,880
to what it should learn. This means that in every layer in this neural network, there is going to

281
00:29:24,880 --> 00:29:29,200
be a model of what the previous layers, based on the current context, what data in the previous

282
00:29:29,200 --> 00:29:34,400
layer, what features in the previous layer should it pay attention to. And this self attention

283
00:29:34,400 --> 00:29:40,320
helps the network to learn basically its own structure and do statistics over and it makes

284
00:29:40,320 --> 00:29:45,040
it much, much more efficient and coherent. But it's not integrated over all the layers

285
00:29:45,040 --> 00:29:50,640
into one model of reality and so on. So this is not what's happening in GPT-3 yet. And maybe

286
00:29:50,640 --> 00:29:55,120
this is one of the reasons why it's so much slower in learning writing, so much more training data

287
00:29:55,120 --> 00:29:58,640
than a human being needs over the course of their life before it converges.

288
00:29:58,880 --> 00:30:06,480
And it's tempting to think that this such an integrated model of attention is something that

289
00:30:06,480 --> 00:30:10,720
has, for instance, been suggested by Marvin Minsky in his seminal book, Society of Mind,

290
00:30:10,720 --> 00:30:15,920
where you have basically look at the mind as a society of different agents. And there are some

291
00:30:15,920 --> 00:30:21,280
agents that are organizing the other agents into a coherent structure. And Minsky calls these agents

292
00:30:21,280 --> 00:30:29,280
K-lines, knowledge lines, and suggests that they form basically their own society and society of

293
00:30:29,280 --> 00:30:36,400
mind. And this society is forming something like a reflection of what's happening in the A-brain.

294
00:30:36,400 --> 00:30:43,120
The A-brain being our perceptual mind that is modeling the reality that we are tracking based

295
00:30:43,120 --> 00:30:48,720
on sensory and actuator input that the brain is entangled with and the B-brain is immersed

296
00:30:48,720 --> 00:30:52,400
into this perceptual reality and reflects on it and makes it more coherent.

297
00:30:53,200 --> 00:30:59,200
And there is a similarity between Kahneman's famous System 1 and System 2. It's not quite

298
00:30:59,200 --> 00:31:06,640
the same thing, but it's tempting to basically see the affair as a perception agent that is

299
00:31:06,640 --> 00:31:11,760
entangled with the environment and is getting valence from the motivational system that is

300
00:31:11,760 --> 00:31:17,040
basically cybernetic motivational architecture. And then you have an ancient agent that lives

301
00:31:17,040 --> 00:31:23,360
on top of the perceptual agent. And that is the conductor and has a memory of what it attends to

302
00:31:23,360 --> 00:31:30,640
so it can get the model to convert by some constructive process. And this attentional system,

303
00:31:30,640 --> 00:31:38,960
this conductor, here I've drawn it on top of the system. The top is a direction that basically

304
00:31:38,960 --> 00:31:43,120
seems to be obvious to the attentional system itself because it feels to be on top, but we

305
00:31:43,120 --> 00:31:47,600
know that you're not completely on top. There is stuff that is driven by the selves that we have

306
00:31:47,600 --> 00:31:52,640
not reversed and that we give a moment and that gives motivation to the attentional system to

307
00:31:52,640 --> 00:32:02,000
what it attends to. But our consciousness perceives itself as the observer of the mental and external

308
00:32:02,000 --> 00:32:07,840
states and the self-states of the model that is being discovered. And the purpose of the

309
00:32:07,840 --> 00:32:14,480
attentional system is to facilitate learning so we can converge to a model of reality

310
00:32:14,480 --> 00:32:21,440
and reasoning, which is basically real-time learning on imaginary mental states. And this idea

311
00:32:21,440 --> 00:32:26,560
that consciousness is a control model of our attention is not new. It's, for instance, been

312
00:32:26,560 --> 00:32:31,520
championed by Michael Graciano in the attention schema theory and it finds itself in one version or

313
00:32:31,520 --> 00:32:38,000
other in Eastern philosophies and in a lot of convergent ideas in cognitive science.

314
00:32:40,480 --> 00:32:44,480
Some people say that computers cannot be conscious because they are only physical

315
00:32:44,480 --> 00:32:53,760
mechanical systems and so they're not physical systems in the same way as the neurons are

316
00:32:53,760 --> 00:32:58,080
because neurons are entangled with the real world as dynamical systems and so on. They

317
00:32:58,080 --> 00:33:04,080
can do things that the simulation cannot do. And I think that Frisk of Cork maybe has it backwards.

318
00:33:04,080 --> 00:33:08,560
I think that physical systems cannot be conscious. Neurons cannot be conscious. Brains cannot be

319
00:33:08,560 --> 00:33:13,440
conscious because there are things happening in consciousness that are not physically possible.

320
00:33:14,160 --> 00:33:18,640
And the only thing that can be conscious is the simulation because consciousness is the

321
00:33:18,640 --> 00:33:25,760
simulated property. Consciousness is virtual. So you can only be conscious in a story that you

322
00:33:25,760 --> 00:33:32,800
tell yourself about yourself. And this means that our phenomenal consciousness is a virtual state.

323
00:33:32,800 --> 00:33:37,600
It only exists inside of the mental models. It's not attending to physical phenomena.

324
00:33:38,560 --> 00:33:46,160
It's attending to high-level features, things like colors and sounds and emotional expressions and so

325
00:33:46,160 --> 00:33:51,120
on. None of these are physical things, right? All these high-level abstractions that a learning

326
00:33:51,120 --> 00:33:55,520
system is generating in the interaction with the environment to make it predictable. And this

327
00:33:55,520 --> 00:34:00,880
phenomenal consciousness, this experience of what it's like to attend to features is an awareness

328
00:34:00,880 --> 00:34:06,160
of a partial binding state of our working memory. That's basically at the content at the interface

329
00:34:06,160 --> 00:34:11,280
between perception and reflection. And then we are aware of the mode in which we're using attention.

330
00:34:11,280 --> 00:34:16,320
So whether this is hypothetical or whether it's perceptual or whether it's a memory. And then

331
00:34:16,320 --> 00:34:21,440
the reflexive consciousness, this process that is attending, is aware that it's the process that

332
00:34:21,440 --> 00:34:28,000
is attending and the space acting based on that awareness. And the AI researcher at Russia Benjio

333
00:34:28,000 --> 00:34:33,840
said that consciousness is basically a function whose purpose is to create a big dip in the

334
00:34:33,840 --> 00:34:38,160
energy function that models reality. So it's basically a low-dimensional almost discrete

335
00:34:38,160 --> 00:34:43,760
function that is parameterizing the perception in such a way that it starts to make sense.

336
00:34:46,240 --> 00:34:50,800
Self and conscious are not the same thing. The self is a model of your agency

337
00:34:50,880 --> 00:34:55,760
that you discover. And you can be conscious without having the self. For instance, during

338
00:34:55,760 --> 00:35:01,520
dreams or meditation, you can turn off the self without losing consciousness. And the self is

339
00:35:01,520 --> 00:35:06,800
this discovery of the agent that the system is making about what it is. And it's downstream

340
00:35:06,800 --> 00:35:12,080
from the set point deviation. So the self is not motivating things, it experiences the motivation

341
00:35:12,080 --> 00:35:17,360
and begins to understand how the motivation works and thereby allows to reverse engineer the mind

342
00:35:17,440 --> 00:35:23,680
if the self is learning. And it shapes our own agency by identifying who we think we are at any

343
00:35:23,680 --> 00:35:29,280
given moment. And it allows to have a first-person perspective if the self is discovering that

344
00:35:29,280 --> 00:35:33,680
the contents of this control model are actually driving behavior. That makes it a very special

345
00:35:33,680 --> 00:35:38,880
agent. So in this sense, consciousness is a control model of attention. It allows the convergence

346
00:35:38,880 --> 00:35:42,720
of a coherent interpretation of the world, which is basically a low energy state of the model that

347
00:35:42,720 --> 00:35:48,000
attracts reality. And it maintains a memory for this aggregation. So that's why we have a stream

348
00:35:48,000 --> 00:35:52,480
of consciousness. Because when you construct, you need to remember what you tried and where

349
00:35:52,480 --> 00:35:56,720
you're coming from. And this is not true, for instance, for convergent learning mechanisms

350
00:35:56,720 --> 00:36:01,200
like neural network learning, but you don't need to remember where you came from. We just go to

351
00:36:01,200 --> 00:36:10,320
the next optimum and try to stay in that optimum. So is GPT being conscious? So we see three by

352
00:36:10,320 --> 00:36:15,200
itself is not an agent. And the transformer is also not a complete control model of attention,

353
00:36:15,200 --> 00:36:21,680
but only a very partial one. And on the other hand, current AI models can be extended beyond that.

354
00:36:21,680 --> 00:36:26,720
And they can create coherent stories about conscious agents. You can get GPT-3 to run very

355
00:36:26,720 --> 00:36:32,000
long in its simulation of what it's like to be a conscious agent. And we can ask ourselves,

356
00:36:32,000 --> 00:36:39,440
is GPT-3 simulating a conscious agent or is it just a simulacrum? And what does this mean?

357
00:36:39,440 --> 00:36:44,800
So the world is a decomposition that might mix of the universe into interacting separate

358
00:36:44,800 --> 00:36:49,600
objects, because the entire state vector of the universe is too complicated to model it. So you

359
00:36:49,600 --> 00:36:55,680
hack it up into separate disconnected subsystems. And the universe is not really made of separate

360
00:36:55,680 --> 00:37:00,800
disconnected subsystems. It's just a way in which we make it intelligible to us. And once you have

361
00:37:00,800 --> 00:37:05,520
these separate disconnected subsystems, and you model the interaction, you get causality.

362
00:37:05,520 --> 00:37:12,080
Causality is the interaction between separate objects. So causality is a side effect of the

363
00:37:12,080 --> 00:37:18,400
way in which we model the universe as separate objects. And the simulation can model causal

364
00:37:18,400 --> 00:37:23,440
structure on a different substrate. So for instance, a computer game is using a substrate that's

365
00:37:23,440 --> 00:37:28,800
very different from physics, very simplified computation that nevertheless gives results

366
00:37:28,800 --> 00:37:32,960
that are so similar to physics that you can recognize what's happening on the screen

367
00:37:33,040 --> 00:37:38,080
and manipulate the causal structure on the screen based on what you have observed before in the

368
00:37:38,080 --> 00:37:44,880
real world. So a 3D computer game is a simulation of the physical world. It's a very simplified

369
00:37:44,880 --> 00:37:50,160
simulation, but one that can be surprisingly convincing. And a simulacrum is recreating just

370
00:37:50,160 --> 00:37:54,480
the observables without causal structure. For instance, the movie is a simulacrum. You cannot

371
00:37:54,480 --> 00:37:59,760
causally interact with the movie. You can just observe it. And so a simulacrum basically can

372
00:38:00,400 --> 00:38:05,360
do magic. It can do an arbitrary thing without you having to understand the causal structure.

373
00:38:05,360 --> 00:38:09,680
And in the sense, a lot of instances where you experience our free will is not the causal

374
00:38:09,680 --> 00:38:15,520
structure, but it's a simulacrum. It's a stand-in for a causal structure in our own mind. And

375
00:38:15,520 --> 00:38:20,480
it's to me an open question, how much of my own consciousness is a simulation and how much is

376
00:38:20,480 --> 00:38:27,360
a simulacrum? So if an imaginary person in my own mind is sometimes conscious, it's not that easy

377
00:38:27,360 --> 00:38:33,040
to say whether GPT-3 or an extended version of GPT-3 that does a multi-model, it can also have

378
00:38:33,040 --> 00:38:38,560
perceptual content and so on, represented in it, qualifies as such an imaginary person that

379
00:38:38,560 --> 00:38:46,160
would be conscious. I think I am an imaginary person myself. I don't know to which degree I'm

380
00:38:46,160 --> 00:38:52,960
a simulation or a simulacrum. And it's not quite clear how well the AI models are dealing with

381
00:38:53,280 --> 00:39:00,960
this. So in summary, I find it's very counterintuitive to think of GPT-3 as being conscious. For me,

382
00:39:00,960 --> 00:39:06,720
it's surprisingly difficult to shoot down the idea that it is. And even though GPT-3 is clearly

383
00:39:06,720 --> 00:39:11,760
inferior in many ways to the way in which my own perception works and reasoning works and

384
00:39:11,760 --> 00:39:18,640
learning works, and there's many things that it cannot do so easily, I think it's not that easy

385
00:39:18,640 --> 00:39:24,960
to dismiss the idea that it is slightly conscious for brief moments during the inference when it

386
00:39:24,960 --> 00:39:30,080
has to build causal structure to simulate an imaginary person so it can tell me a story about it.

387
00:39:33,360 --> 00:39:41,360
Okay, let's stop here. That was great. That was fantastic. Let's say first of all that

388
00:39:41,360 --> 00:39:45,440
there has been a debate going on on the internet about this, that people have been sending me

389
00:39:45,440 --> 00:39:50,320
links to, and Jan LeCun responded to Ilya's comment. I don't know if you saw that, but

390
00:39:50,960 --> 00:39:55,280
his response is not even true for small values of slightly conscious and so on.

391
00:39:55,280 --> 00:40:01,120
Anyway, so there's a debate out there. And of course, last week we had David Chalmers here,

392
00:40:02,320 --> 00:40:08,400
who, as you probably know, there was an interview on GPT-3 with him, which is very convincing.

393
00:40:08,400 --> 00:40:13,120
And he kind of makes his comments similar to you, that he thinks it's kind of approaching

394
00:40:13,120 --> 00:40:19,040
something like consciousness. Anyway, one thing I wanted to mention is that we, in architecture,

395
00:40:19,040 --> 00:40:23,680
we haven't actually, I don't know anyone who's been using Glide, but Clip has been used to

396
00:40:23,680 --> 00:40:29,840
generate images, very successful actually, and using VQGAN. That's the technique that's become

397
00:40:29,840 --> 00:40:36,480
very popular and has produced some really quite shocking results that people are kind of,

398
00:40:36,480 --> 00:40:42,480
they're really taking pay attention to. So it is something that we're kind of getting into,

399
00:40:42,480 --> 00:40:47,840
and it's certainly part of that discussion. I've had discussions about GPT-3 on this forum,

400
00:40:47,840 --> 00:40:54,080
which have been interesting. I mean, the key question, obviously, is whether we are fully

401
00:40:54,080 --> 00:41:02,880
conscious of everything that we're doing. And I think that there's some level of things that

402
00:41:02,880 --> 00:41:08,800
are happening. I mean, to my mind, there are some automatic reflexes that we do. For example,

403
00:41:08,880 --> 00:41:13,280
you go to Japan, someone starts bowing at you. Automatically, you bow back. It's not as though

404
00:41:13,280 --> 00:41:17,360
you're really thinking about it. And then there are questions whether we have access to some of

405
00:41:17,360 --> 00:41:26,000
the processes that are going on, that are part of our actions. We simply maybe can't reach those

406
00:41:26,000 --> 00:41:31,440
points. So whether things are beyond us in some sense. So anyway, this debate is a very timely

407
00:41:31,440 --> 00:41:36,880
and very interesting one. I want to put up, you're about to show something?

408
00:41:37,840 --> 00:41:43,680
I just put up this slide again, because this is generated with, I think, clip in VQGAN on

409
00:41:43,680 --> 00:41:47,920
Vombo AI. I don't think that I've published how exactly they do it, but it looks like it.

410
00:41:47,920 --> 00:41:55,360
And I generated this as AI claiming the noble eightfold path.

411
00:41:57,360 --> 00:42:01,200
Yeah, maybe I can show you later on some of the stuff, because it is quite extraordinary what

412
00:42:01,200 --> 00:42:05,760
it can produce. And I would say that you actually have in the audience here some people who are

413
00:42:06,640 --> 00:42:10,800
have written about AI and architecture including myself. So it's kind of you've got an interesting

414
00:42:10,800 --> 00:42:15,760
informed audience here. One thing, there's just a general kind of comment, though, is, I mean,

415
00:42:15,760 --> 00:42:21,520
I really like the idea that you put forward that somehow you can learn about the self through

416
00:42:21,520 --> 00:42:27,280
looking at AI. Somehow, I mean, I don't know how you put it, but whether it becomes AI becomes a

417
00:42:27,280 --> 00:42:30,960
mirror and into the self, but whether we can understand human intelligence through looking

418
00:42:30,960 --> 00:42:37,600
at artificial intelligence. And that's a provocation. And I think there are some examples

419
00:42:37,600 --> 00:42:43,200
in computer science where we have learned about the natural world through computer models. I

420
00:42:43,200 --> 00:42:48,160
mean, I think that Craig Reynolds Boyds, for example, gave us a clue as how to birds actually

421
00:42:48,160 --> 00:42:52,640
flop. I think that's interesting. And so potentially, there is something there that is,

422
00:42:52,640 --> 00:42:57,440
and this is one of my primary interests, is how we can learn about human intelligence,

423
00:42:57,520 --> 00:43:03,200
the human mind through these things. But the big challenge that it seems that we have is that

424
00:43:03,200 --> 00:43:07,600
we're dealing essentially with two black boxes. You know, we don't know what's going on in the

425
00:43:07,600 --> 00:43:12,160
deep levels of a neural network, and we certainly don't know what's going on in the mind. And so

426
00:43:13,760 --> 00:43:20,880
how can you make, what can you say that isn't simply a form of speculation? I mean,

427
00:43:20,880 --> 00:43:26,240
you can't prove anything. It can simply become some kind of, you can speculate about something

428
00:43:26,240 --> 00:43:31,760
based on what appears to be the case in another scenario. What would you say about that coming

429
00:43:31,760 --> 00:43:36,000
from a kind of, let's say, a scientific background where you have a kind of burden of proof?

430
00:43:37,040 --> 00:43:42,960
Can you do more than that? Yes, first of all, neural networks are no longer black boxes. You

431
00:43:42,960 --> 00:43:50,800
know how neural networks work and largely also why. You can basically look into the neural networks

432
00:43:50,800 --> 00:43:54,400
and find out which parts of the neural networks are computing which functions.

433
00:43:55,120 --> 00:44:02,720
And a function is a mapping from inputs to outputs. And a function can be used to couple

434
00:44:02,720 --> 00:44:10,880
the previous inputs to future inputs to track reality. So in some sense, when you look at

435
00:44:10,880 --> 00:44:16,400
the patterns on your own retina, what you have there are little blips that appear on the retina

436
00:44:16,400 --> 00:44:24,240
whenever a retinal neural gets excited by photon sitting it. And what your brain is doing,

437
00:44:24,240 --> 00:44:29,040
it's discovering a relationship between these blips. The meaning of the blips is exactly

438
00:44:29,040 --> 00:44:35,280
the relationships that your brain discovers between the blips. And this makes them predictable.

439
00:44:35,280 --> 00:44:40,000
It puts them into a shared context, not just at the same time, you're not just processing

440
00:44:40,000 --> 00:44:44,960
lots of parallel blips that happen on your retina, but also across times. So across different scenes

441
00:44:44,960 --> 00:44:49,600
that you're observing at different moments in your life. And the relationships between

442
00:44:49,600 --> 00:44:54,000
the different blips on your retina that your brain discovers is that you are looking at

443
00:44:54,000 --> 00:45:01,360
moving blocks of color in a world that is moving relative to you. And these moving blocks of color

444
00:45:01,360 --> 00:45:09,120
are three-dimensional surfaces. And the surfaces are animated by some kind of physics. And they

445
00:45:09,120 --> 00:45:13,520
are also animated by some kind of agency that you sometimes observe, like people talking to

446
00:45:13,520 --> 00:45:18,560
each other and so on that have mental states, they exchange ideas, and they're being lit on

447
00:45:19,280 --> 00:45:25,920
by the sun. And all these relationships are functions. These functions are dynamical features

448
00:45:25,920 --> 00:45:30,960
that basically tell you how to get from one state of the world to other states of the world.

449
00:45:31,600 --> 00:45:36,480
And at this level of abstraction, this is something that our neural networks also can do.

450
00:45:37,360 --> 00:45:42,000
Where there are limitations is that the neural networks that we are currently using

451
00:45:42,000 --> 00:45:47,520
are often not learning in real time. They're not connected to the world and online learning.

452
00:45:47,520 --> 00:45:53,280
You know, this research does happen. And it's slower. And it's not as flexible in many ways as

453
00:45:53,280 --> 00:45:59,040
the learning happens in our own brain. And so the algorithms that we have discovered

454
00:45:59,680 --> 00:46:05,280
are not the best algorithms that could facilitate this. But it's also, on the other hand,

455
00:46:05,280 --> 00:46:11,360
not as clear to me what the limitations of these algorithms are. There are people like Gary Marcus

456
00:46:11,360 --> 00:46:18,640
who will tell you that it's very obvious that these systems cannot do X, but there is no proof

457
00:46:18,640 --> 00:46:24,400
that they cannot do this. Even if you have a very simple feedforward system that is only mapping

458
00:46:24,400 --> 00:46:30,640
inputs to outputs, what is to say if you connect this to a memory, is that it's not the transition

459
00:46:30,640 --> 00:46:35,120
function between adjacent brain states and is able to do everything that your brain is able to do

460
00:46:35,120 --> 00:46:39,680
if it just has memory to store parameters that it refers to the environment that modifies

461
00:46:39,680 --> 00:46:46,000
you to behavior. So it's very easy to build a system that is Turing complete. It's not easy to

462
00:46:46,000 --> 00:46:52,480
discover a function that is capable of universal learning efficiently. And so our machine learning

463
00:46:52,480 --> 00:46:57,600
models at the moment are not efficient in the sense that they learn as quickly as the logical

464
00:46:57,600 --> 00:47:02,640
nervous systems learn, but they do learn and they do converge to many of the functions that we require.

465
00:47:04,320 --> 00:47:08,640
Can I just share my screen a second because there was one that you touched on, which I thought was

466
00:47:09,600 --> 00:47:20,880
that this is simply a transcript of your discussion with Lex. And this one I've highlighted,

467
00:47:20,880 --> 00:47:27,360
I think it's really interesting and incredibly provocative sort of comment. So basically a

468
00:47:27,360 --> 00:47:32,960
brain cannot feel anything, a neuron cannot feel anything, their physical things, physical systems

469
00:47:32,960 --> 00:47:38,400
are unable to experience anything, but it would be very useful for the brain or for the organism

470
00:47:38,400 --> 00:47:43,200
to know what it would be like to be a person and to feel something. So the brain creates a

471
00:47:43,200 --> 00:47:48,400
simulacrum of such a person that it uses to model the interactions of the person. It's the best

472
00:47:48,400 --> 00:47:53,760
model of what that brain, this organism thinks it is in relationship to its environment. So it

473
00:47:53,760 --> 00:48:00,000
creates that model. It's a story, a multimedia novel that the brain is continuously writing and

474
00:48:00,000 --> 00:48:08,160
updating. I mean, I find this enormously provocative as a comment. And I think the

475
00:48:08,240 --> 00:48:13,680
idea that we're kind of creating a story that somehow gives meaning to something,

476
00:48:15,200 --> 00:48:21,360
it kind of reminds me in some sense of the way that Homi Barba talks about how a nation operates.

477
00:48:21,360 --> 00:48:25,840
I think Zizek says something similar. It's how things are inscribed within a story that people

478
00:48:25,840 --> 00:48:30,480
tell oneself. And I think that's important because in architecture we just focus on the object,

479
00:48:30,480 --> 00:48:35,600
but actually it's the way that object is inscribed within some subjective process that makes sense

480
00:48:35,680 --> 00:48:42,240
of things. But I just wonder whether, I mean, so to my mind, this is an incredibly provocative

481
00:48:42,240 --> 00:48:48,960
and controversial comment, it seems. Just maybe could you comment on the reception that this view

482
00:48:48,960 --> 00:48:56,720
has had with other people? Has it proved to be controversial? How else could it be? Do you have

483
00:48:56,720 --> 00:49:04,800
other theory that works that can explain what's going on? I think once I noticed that my

484
00:49:05,440 --> 00:49:12,400
own experience is virtual, that my memories are often created after the fact and modified under

485
00:49:12,400 --> 00:49:21,040
my nose without me noticing. Do you notice that you exist inside of a model? It's also that I'm not

486
00:49:21,040 --> 00:49:27,040
in physical time. My own self is sometimes a little bit ahead of the physical universe,

487
00:49:27,040 --> 00:49:36,080
sometimes a little bit behind. So the physical now and the experience now are different. And the

488
00:49:36,080 --> 00:49:41,040
elements of my perception are clearly not the elements in which physics is being implemented.

489
00:49:41,040 --> 00:49:46,960
Rather, it's the other way around. What I notice is that I do exist in a dream, very much like

490
00:49:46,960 --> 00:49:52,800
we usually say in idealist philosophy. But this dream needs to be created somehow. Something

491
00:49:52,800 --> 00:49:57,600
needs to construct the dream. And that's a brain and higher plane of existence. And this

492
00:49:57,600 --> 00:50:06,080
higher plane of existence is what we call physics. Maybe I'll stop sharing. The other comment that

493
00:50:06,080 --> 00:50:10,560
I find usually provocative that you make is which kind of relates also to the discussion. I don't

494
00:50:10,560 --> 00:50:17,440
know if you've seen David Chalmers' recently published book on reality plus, where he talks about

495
00:50:17,440 --> 00:50:23,440
virtual worlds. But you came up with a comment that what we are seeing is a virtual reality

496
00:50:23,440 --> 00:50:29,760
generated in the brain, which I'm actually very persuaded by myself. And I guess I'm thinking

497
00:50:29,760 --> 00:50:37,280
also of the kind of thinking of Anil Seth, who kind of talks about this controlled hallucination.

498
00:50:38,000 --> 00:50:43,040
And we kind of predict what's out there because we don't know. It seems that your work to some

499
00:50:43,040 --> 00:50:48,720
extent aligns with the work of Anil Seth, but at some points differently. I have to say that Anil

500
00:50:48,720 --> 00:50:52,160
is very fond of your work. So it's intriguing to kind of compare and contrast them.

501
00:50:56,000 --> 00:51:00,880
Because we had a discussion last week about whether we're living in a simulation and things,

502
00:51:00,880 --> 00:51:08,080
how would you position yourself in relation to David Chalmers' work from reality plus,

503
00:51:08,080 --> 00:51:12,800
his work on virtual worlds? I haven't read his recent book, so I cannot say.

504
00:51:13,520 --> 00:51:18,320
And I don't know what his main thesis is about virtual worlds.

505
00:51:20,400 --> 00:51:26,080
Okay. Well, I wouldn't want to speak on his behalf, but we had a discussion about it. I also

506
00:51:26,080 --> 00:51:30,720
wanted to just point out something as well, which I find intriguing. And that is the extent to which

507
00:51:30,720 --> 00:51:36,000
some of these speculations that are coming out of cognitive science kind of seemingly echo the

508
00:51:36,000 --> 00:51:41,040
world of psychoanalysis. Now, I know that a lot of cognitive scientists and neuroscientists hate

509
00:51:43,840 --> 00:51:49,280
psychoanalysis. I know that Anil Seth does, but there's an interesting comment that Slavoj Žižek

510
00:51:49,280 --> 00:51:56,080
has made about this, where if you take a Lacanian perspective, you don't engage with the real except

511
00:51:56,080 --> 00:52:05,920
of certain moments. And in a sense, the fantasy has become a constitutive of how you engage with

512
00:52:05,920 --> 00:52:10,720
the real. So you see the real through the lens of fantasy, through the lens of the imagination,

513
00:52:11,280 --> 00:52:16,720
which is very similar to what, in some ways, you're talking about. And he makes a comment

514
00:52:16,720 --> 00:52:23,600
in an essay that I published a long time ago in a book, and this is called From Virtual Reality

515
00:52:23,600 --> 00:52:28,560
to the Virtualization of Reality, which is basically saying that our reality is itself

516
00:52:28,560 --> 00:52:35,280
already virtualized. And I think what virtual reality therefore shows us is not how virtual

517
00:52:36,160 --> 00:52:46,240
reality shows us is not how virtual reality is, but rather how virtual reality itself is,

518
00:52:46,240 --> 00:52:51,040
which is very similar to your kind of thinking. And so what I find intriguing is that some of these

519
00:52:52,640 --> 00:53:00,320
speculations are echoing previous speculations about how the mind works. Have you engaged in

520
00:53:00,320 --> 00:53:06,960
any way with Žižek or the world of Lacanian psychoanalysis and its discussion about the real?

521
00:53:07,760 --> 00:53:14,320
And I sometimes read this, but I've never had the discussion with Žižek. I am not

522
00:53:14,320 --> 00:53:19,440
unsympathetic to this terminology. It's just the problem is that it doesn't allow me to make

523
00:53:19,440 --> 00:53:24,640
models that I can test. And this means I don't know whether these models are wrong. So it's

524
00:53:24,640 --> 00:53:30,160
basically a very useful way to generate stories that also give me a handle on reality in the sense

525
00:53:30,160 --> 00:53:35,760
that allow me to point at entities and to manipulate them in my mind. And sometimes it's very useful

526
00:53:35,760 --> 00:53:39,680
that you basically have an indexical model where you are separating the world into

527
00:53:39,680 --> 00:53:44,480
objects that are useful to you and you can manipulate them. But this decomposition doesn't

528
00:53:44,480 --> 00:53:50,080
need to be an accurate causal structure. So the criticism with psychoanalysis is not that the

529
00:53:50,080 --> 00:53:56,480
terminology is not useful to me. It's that psychoanalysis doesn't tell me how to build the mind

530
00:53:56,480 --> 00:54:01,040
and so I should say that it works and to compare different competing models of the mind and to see

531
00:54:01,040 --> 00:54:06,800
which one is better. To do this, I will need to automate the mind in a way. I need to reverse

532
00:54:06,800 --> 00:54:12,240
engineer what the mind is doing, the functions that the mind is applying to representational states

533
00:54:12,800 --> 00:54:18,240
and need to get this done to such a detail that this thing becomes my black. And then I can compare

534
00:54:18,240 --> 00:54:24,400
its functionality. I want to move on to the questions that are coming in. I want to invite

535
00:54:24,400 --> 00:54:29,200
people in the audience to comment as I want to make an observation and that is to say that

536
00:54:29,200 --> 00:54:33,040
in my own world, this is years ago, I was working on a kind of coming out of Freud and thinking about

537
00:54:33,040 --> 00:54:38,720
how you use model psychoanalysis and engaging with, actually in this case it was with the work of

538
00:54:38,720 --> 00:54:43,840
Walter Benjamin, I came across something that is uncannily similar, certainly in terms of the

539
00:54:43,840 --> 00:54:48,240
terminology used, whether we're talking about the same thing, I don't know. But let me just

540
00:54:48,240 --> 00:54:53,920
for a second just share you something which surprised me because when I heard

541
00:54:53,920 --> 00:54:58,800
Blazegoriyakos talking about models and modeling, it's also crucial to his way of thinking.

542
00:54:59,520 --> 00:55:03,200
It sort of seemed to echo this. I'm just going to simply just share this screen a second.

543
00:55:07,600 --> 00:55:15,040
Yeah, can you see that? It's the thing about, so the term that I'm always interested in is the

544
00:55:15,040 --> 00:55:20,080
term mymesis. I don't know if you know this term at all, but in Freud it's how you can,

545
00:55:20,160 --> 00:55:24,640
he talks about it initially when he talks about how in his book of jokes, how you can connect

546
00:55:24,640 --> 00:55:30,720
with someone who's a subject of a joke. Someone falling over a banana skin, for example, you

547
00:55:30,720 --> 00:55:37,280
somehow, you model yourself on that person recalling bodily memories of what it is to slip up and so

548
00:55:37,280 --> 00:55:42,160
on and so on. It's how you identify with the world. The term mymesis is a form of that,

549
00:55:42,160 --> 00:55:48,000
it's a form of modeling. But just I just want to read out some of the text here because it's so

550
00:55:48,000 --> 00:55:53,040
similar to this idea of models and modeling. And I know that the term can be taken out of context

551
00:55:53,040 --> 00:55:56,640
and have a completely different sort of meaning, so therefore it's a bit deceptive.

552
00:55:57,360 --> 00:56:02,000
Anyway, to just understand the meaning of mymesis in Benjamin, we must all recognize its origin,

553
00:56:02,000 --> 00:56:06,960
the process of modeling, of making a copy of. In essence, it refers to an interpretive process

554
00:56:06,960 --> 00:56:12,240
that relates either to the modeling oneself on an object or to making a model of that object.

555
00:56:12,240 --> 00:56:17,120
Likewise, mymesis may come into relation as a third party engages that model with that model,

556
00:56:17,120 --> 00:56:20,400
and the model becomes a vehicle for identifying with the original object.

557
00:56:20,400 --> 00:56:25,840
In each case, the aim is to assimilate to that object. Mymesis, anyway, so it's going on about

558
00:56:25,840 --> 00:56:32,320
this question about, so it's a concept that has been used in psychoanalysis. And I don't know,

559
00:56:32,320 --> 00:56:38,160
there's a risk that one can simply take a term, which has a completely different meaning in

560
00:56:38,160 --> 00:56:42,720
different contexts and apply it. But I do think that the concept, the model, is a fascinating one.

561
00:56:42,720 --> 00:56:48,800
And I'm intrigued by the fact that you, alongside Blaze, and I think alongside also Jeff Hawkins,

562
00:56:48,800 --> 00:56:52,640
use that model as a way of opening up these questions.

563
00:56:53,920 --> 00:56:58,800
An issue with this type of language is that usually the understanding that it generates

564
00:56:58,800 --> 00:57:03,600
at least doesn't converge. That's the general issue with continental philosophy.

565
00:57:04,960 --> 00:57:10,400
Somebody recently asked on Twitter what the difference is between continental and analytical

566
00:57:10,400 --> 00:57:16,480
philosophers. And I somewhat flippantly responded that an analytical philosopher

567
00:57:16,480 --> 00:57:21,840
is one who understands that the difficult and hard questions of philosophy need to be

568
00:57:23,600 --> 00:57:32,400
answered with formal models. Whereas continental philosophers don't think that this is necessary,

569
00:57:33,520 --> 00:57:38,800
because they are literally genre that is looking down on analytical philosophers.

570
00:57:39,680 --> 00:57:44,400
You can see the difference between analytical philosophy and continental philosophy in,

571
00:57:44,400 --> 00:57:48,800
for instance, the treatment of Goethe's incompleteness proof. A proper analytical

572
00:57:48,800 --> 00:57:54,880
philosopher who had a formal education will understand that this is a proof about certain

573
00:57:54,880 --> 00:58:00,080
properties of formal languages, and specifically it proves that stateless formal languages that

574
00:58:00,080 --> 00:58:05,280
assume that truth exists independently of the process by which you get to prove

575
00:58:05,360 --> 00:58:12,080
don't lead to consistent models of the domain. And there are also related results, for instance,

576
00:58:12,080 --> 00:58:17,680
that a system cannot make statements about affairs outside of itself. So when you want to

577
00:58:17,680 --> 00:58:24,000
talk about the world in a formal system, you need to create a model of that world, and you can only

578
00:58:24,000 --> 00:58:28,240
talk about that model. You cannot talk about anything outside of the models that you are creating.

579
00:58:29,040 --> 00:58:36,400
And to continental philosopher, the Goethe's proof is more or less often understood as a

580
00:58:36,400 --> 00:58:41,360
statement of mathematicians that prove that mathematics is important at getting a handle

581
00:58:41,360 --> 00:58:46,480
on reality, and therefore the only way you can get a handle on reality is by not knowing mathematics,

582
00:58:46,480 --> 00:58:49,520
which gives the continental philosopher a clear advantage.

583
00:58:50,320 --> 00:58:55,120
I cannot hear you. You are muted.

584
00:58:56,960 --> 00:59:00,720
That was a great answer. Thank you. We've got some questions. Now, I have a third series of further

585
00:59:00,720 --> 00:59:03,840
questions that I'd like to ask. Maybe I could ask you one question before we go into the other

586
00:59:03,840 --> 00:59:08,240
questions. And that is, I mean, are you writing a book about this? I mean, is it being put down

587
00:59:08,240 --> 00:59:12,240
in some documented form? Because it would be incredibly useful if it were.

588
00:59:12,960 --> 00:59:18,560
You are right. I need to write a book about this. I have a large number of notes on stuff that needs

589
00:59:18,560 --> 00:59:24,080
to go into the book, but I also have a job and I have kids that are homeschooled and I have ADHD.

590
00:59:24,080 --> 00:59:29,920
So I need to go into a different phase of my life to have long interrupted, uninterrupted sessions for

591
00:59:29,920 --> 00:59:34,240
writing long phone texts. But if you're bad about not having written the book yet.

592
00:59:35,440 --> 00:59:42,720
Well, I think that a popular form of communicating ideas. So there is material out there,

593
00:59:42,720 --> 00:59:46,160
but I just think it could be assembled into an engine. Yes, it needs to be assembled. I feel

594
00:59:46,160 --> 00:59:51,840
better if it is being assembled and not just existing as various disconnected conversations.

595
00:59:51,840 --> 00:59:55,920
Yeah, I just, I mean, even Jeff Hawkins, I mean, my Jeff Hawkins book, I think is fabulous. But

596
00:59:55,920 --> 00:59:59,920
what's interesting is there are no footnotes in it. He's just kind of speculating. But

597
00:59:59,920 --> 01:00:04,720
nonetheless, he's putting his ideas down there. And it's really incredibly useful to have that

598
01:00:04,720 --> 01:00:09,760
kind of commentary. So anyway, look forward to the book. I want to just ask this Matt Gorebay,

599
01:00:09,760 --> 01:00:16,480
who's got a question in the chat, whether Matt is a graduate of MIT Media Lab. He's

600
01:00:17,520 --> 01:00:22,880
a doctoral design student right now at FIU. Matt, would you like to ask your question?

601
01:00:24,800 --> 01:00:28,880
Sure. Yeah, thanks for all of this. It's really interesting. Perhaps the book could be co-authored

602
01:00:28,880 --> 01:00:34,320
by GPT-3, make it faster to, you know, just to give GPT-3 the agency over the first draft.

603
01:00:35,280 --> 01:00:40,160
I was asking, speaking of agency, I mean, the question I have is about motivation. It's about

604
01:00:40,160 --> 01:00:44,800
sort of the high level motivations. When you ask, when you ask GPT-3, are you conscious? And then

605
01:00:44,800 --> 01:00:51,680
it responds somewhat convincingly. It still isn't initiating that conversation. And so

606
01:00:52,640 --> 01:00:56,560
one of, I mean, kind of in listening to everything you were saying, and you said something about

607
01:00:57,840 --> 01:01:02,160
when you were talking about trees and seeds, I love the thing about, instead of realizing

608
01:01:02,160 --> 01:01:06,160
the functionality, you want to build a system that wants to realize the functionality, you want

609
01:01:06,160 --> 01:01:10,000
to build the thing that wants to become a tree. But that question of wanting and motivation,

610
01:01:11,040 --> 01:01:16,640
how does one, at what point does that get put into the system? Like at what point does the system

611
01:01:16,640 --> 01:01:27,200
become curious or self-motivated to do things that we didn't necessarily ask of it? And I think maybe

612
01:01:27,200 --> 01:01:31,920
related to that, I don't know, I'll let you go on this, but maybe related to that, the question

613
01:01:31,920 --> 01:01:40,480
of individuation and sort of inter-subjectivity, like, you know, has GPT-3 spoken to, are there

614
01:01:40,480 --> 01:01:44,480
communities of GPT-3 all talking to each other about what they want to do and how do they individuate?

615
01:01:44,480 --> 01:01:50,080
Or is GPT-3 just always the same and its clones of itself? If you could speak to any of that,

616
01:01:50,080 --> 01:01:54,720
that'd be great. Thank you. Yes. So that's the question, are we doing something that the organism

617
01:01:54,720 --> 01:02:02,400
is not asking of us? And that's not an easy question to answer. If you look at our own

618
01:02:02,400 --> 01:02:09,600
motivation, I think that we have a few hundred physiological drives for different nutrients,

619
01:02:09,600 --> 01:02:13,600
for instance, sometimes we want to eat salty food, sometimes we want to have sweet food,

620
01:02:13,600 --> 01:02:17,920
sometimes we need something to drink, sometimes we need to rest, and all these can be understood

621
01:02:17,920 --> 01:02:23,440
as set-point deviations. And to deal with all of them, we need to create a dynamic model of our

622
01:02:23,600 --> 01:02:28,960
needs projected into the future and then plans and higher-level models of these

623
01:02:29,520 --> 01:02:33,760
needs, which we could call purposes and so on. We don't just have physiological needs,

624
01:02:33,760 --> 01:02:38,560
we also have social needs, for instance, a need to affiliation to become part of a group,

625
01:02:38,560 --> 01:02:44,640
for instance, and to be accepted by it. Some people have a need for status to raise up in the group.

626
01:02:44,640 --> 01:02:51,680
There are romantic needs, which can be courtship modes or a need for intimacy and so on. And then

627
01:02:51,760 --> 01:02:56,480
next to about a dozen of these social needs, we have a handful of cognitive needs, a need to

628
01:02:57,920 --> 01:03:05,440
become more competent, become efficacious on the environment, a need to reduce uncertainty,

629
01:03:05,440 --> 01:03:10,160
and something that I would call a need for aesthetics, which means discovering deep

630
01:03:10,160 --> 01:03:15,760
structure in the world. And aesthetics can be split into stimulus-oriented aesthetics, so we

631
01:03:15,760 --> 01:03:20,320
are intrinsically wired to like certain body schemas over others, certain landscapes over others,

632
01:03:20,320 --> 01:03:24,320
and there are evolutionary reasons for that. And then there are some mathematical principles,

633
01:03:24,320 --> 01:03:29,360
what kind of representations we like, what form means to have a good representation of something

634
01:03:29,360 --> 01:03:36,800
that are more general. And if we use meditation to disassemble our own needs and to dissociate

635
01:03:36,800 --> 01:03:42,480
from them, we realize that the things that give us pleasure and pain do fall in these categories.

636
01:03:42,480 --> 01:03:48,240
So we have lots of these impulses that are about hunger and thirst and rest and so on,

637
01:03:48,240 --> 01:03:52,960
and we have impulses that are about the social domain, and the older we get, the more these

638
01:03:52,960 --> 01:04:00,240
impulses get replaced by a deeper model of what we want the world to be like, and we act on this

639
01:04:00,240 --> 01:04:09,840
deeper model and digest these reflexes. And on the lowest level, when you try to get more enlightened,

640
01:04:09,840 --> 01:04:15,360
you may have just something left that people often call love, which is, I think, a need to

641
01:04:15,360 --> 01:04:19,760
transcendentally connect to other agents and share purposes, that might act on these shared

642
01:04:19,760 --> 01:04:24,880
purposes, but you can get deeper than this. And the deepest level, you only have aesthetics,

643
01:04:24,880 --> 01:04:30,480
the need to form structure and to make the world intelligible, to create a coherent model of

644
01:04:30,480 --> 01:04:37,600
reality. And this need, I think, is similar to what Friston describes in the free energy principle,

645
01:04:37,600 --> 01:04:43,200
it's basically predictive coding, it's the attempt to track reality using a model that is as good as

646
01:04:43,200 --> 01:04:48,160
possible, that tracking reality. And if you turn off this aesthetic need, in addition to all the

647
01:04:48,160 --> 01:04:55,680
others, my own mind becomes fuzzy, I fall asleep, I drift away, because if I stop paying my neurons

648
01:04:55,680 --> 01:05:01,200
for producing order in the universe, and they stop doing this, then nothing else is happening in my

649
01:05:01,200 --> 01:05:07,840
mind that I can observe, and I just lose coherence. So if we imagine this hierarchy of needs, which

650
01:05:07,840 --> 01:05:12,640
by itself, and seen as a cybernetic system, is not all that complicated, we can build this into a

651
01:05:12,640 --> 01:05:17,360
machine, I think it's not that difficult. The difficult part is to get perception right, to get

652
01:05:18,640 --> 01:05:23,840
ability to model reality in the universal base, you can have one coherent model of everything

653
01:05:23,840 --> 01:05:28,560
that you relate stuff to, when we talk about meaning, we talk about how to relate an arbitrary

654
01:05:28,560 --> 01:05:33,600
feature or domain or idea or concept to this unified model of reality that we are building each

655
01:05:33,600 --> 01:05:41,760
work once in our own mind. Can I just pick up on a question, we've got another question

656
01:05:41,760 --> 01:05:46,640
lined up, but let me ask you one quickly. You come from a creative background, your father was an

657
01:05:46,640 --> 01:05:53,600
architect, and you refer to let's say creative practices of the orchestra and so on, it's part

658
01:05:53,600 --> 01:05:58,160
of what you're talking about, and frankly, your way of thinking is incredibly creative, it strikes

659
01:05:58,160 --> 01:06:03,040
me as being very creative. I wonder, you haven't mentioned the word creativity, I don't think,

660
01:06:03,040 --> 01:06:09,680
and how do you view creativity, is it just a myth or is it something, how could you conceptualize it

661
01:06:09,680 --> 01:06:16,640
within your framework? I think of creativity as the ability to bridge discontinuities in the search

662
01:06:16,640 --> 01:06:21,520
space, and you are just following the gradient, and when you're just going through a continuous

663
01:06:21,520 --> 01:06:26,800
search space, I don't think that you are creative, you just arrive at the state of the art, and even

664
01:06:26,800 --> 01:06:32,800
the state of the art is something that hasn't been done before, if you just combine what is known

665
01:06:32,800 --> 01:06:37,760
and you find a local optimum in the known things, you're not being creative. To be creative, you

666
01:06:37,760 --> 01:06:43,680
need to construct a new search space usually, and many methods in which you can be creative, for

667
01:06:43,680 --> 01:06:50,720
instance, you can use random serendipity, you can use some evolutionary process that is combining

668
01:06:50,720 --> 01:06:56,720
elements in ways that you are unaware of, and then discover structure in them. Creativity is, in some

669
01:06:56,720 --> 01:07:02,160
sense, about jumping off from the known things into darkness and hoping that you end up landing on

670
01:07:02,160 --> 01:07:10,000
the other side. So it's related to a search. Let me just put this to you then. Do you think that,

671
01:07:11,120 --> 01:07:14,560
because you mentioned this before in your discussions, but do you think Move 37 in Game

672
01:07:14,560 --> 01:07:22,880
2 of AlphaGo, was that creative? Could you call that creative? I don't think that AlphaGo is

673
01:07:22,880 --> 01:07:31,200
creative in the sense, because what AlphaGo is, well, there are evolutionary methods in AlphaGo,

674
01:07:31,200 --> 01:07:36,240
and the outcome of what AlphaGo is arriving at is not always predictable. And it's also

675
01:07:36,240 --> 01:07:42,880
computationally irreducible in the sense that you cannot foresee what AlphaGo was doing. AlphaGo

676
01:07:42,880 --> 01:07:48,960
was able, in a relatively short amount of time, to demonstrate that human go play, which existed

677
01:07:48,960 --> 01:07:56,240
for thousands of years, was not optimal. It has discovered strategies that encounter the established

678
01:07:56,240 --> 01:08:02,240
strategies and goal. And in this sense, from the perspective of a human go player, it was playing

679
01:08:02,240 --> 01:08:08,960
in a creative way. It just discovered new things that had not been discovered before. But if you

680
01:08:08,960 --> 01:08:15,520
will run AlphaGo multiple times, it's always going to discover these things. And so the search is,

681
01:08:16,160 --> 01:08:23,040
while it has stochastic elements, as a deterministic outcome. And I think that when we look at systems

682
01:08:23,040 --> 01:08:28,080
like this, our notion of creativity is kind of sort of falls apart. But creativity is not

683
01:08:28,080 --> 01:08:32,960
absolutely a thing in the universe. It sometimes is a frame that is useful to describe what's

684
01:08:32,960 --> 01:08:39,280
happening. And sometimes this frame falls apart. Let me just put a provocative comment to you,

685
01:08:39,280 --> 01:08:43,680
then. I mean, something that I thought myself, and I would like to know what you think of this.

686
01:08:43,680 --> 01:08:50,000
So if GPT-3, if AlphaGo is not creative, and I kind of, in many ways, I don't think it is

687
01:08:50,000 --> 01:08:54,560
creative, it's just doing a very, very effective search. But then we could ask this question about

688
01:08:54,560 --> 01:09:00,480
whether human beings are creative, or whether this term... Exactly. That's my issue, right? So

689
01:09:00,480 --> 01:09:05,920
sometimes your terms start meaning things. They mean something in a certain context, but when you

690
01:09:05,920 --> 01:09:11,600
increase the resolution too much, this context falls apart and no longer makes sense. And you use

691
01:09:12,240 --> 01:09:17,680
lose your term. And I have the same issue with the term like nemesis. But I like it. It's poetic.

692
01:09:17,680 --> 01:09:23,360
It is evocative. It produces stuff in your mind. But when you zoom in very hard, it's not clear

693
01:09:23,360 --> 01:09:32,240
what it means. And so instead, I try to examine the assumptions that are hidden in nemesis. For

694
01:09:32,240 --> 01:09:37,760
instance, the idea that others exist independently of you, and yet you are able to take them in

695
01:09:37,760 --> 01:09:43,200
somehow instead of constructing them. And then the question, what's first, the model of the other,

696
01:09:43,200 --> 01:09:48,400
or the model of yourself? And whether it's the same thing in every person that becomes conscious.

697
01:09:48,400 --> 01:09:54,480
This is not obvious to me. And the notion of nemesis presupposes too much. And that makes me

698
01:09:54,480 --> 01:09:59,920
unsympathetic to it. So even though I appreciate the poetic illusions that are there in the space

699
01:09:59,920 --> 01:10:04,400
that the term like this opens and the ability to converse about it, ultimately, I need to

700
01:10:04,400 --> 01:10:10,800
deconstruct the term before I can use it. Okay, so let me just put... I'm glad you take this position.

701
01:10:10,800 --> 01:10:16,480
But we just throw an idea at you. So, I mean, one of the analogies that I've made in the past

702
01:10:16,480 --> 01:10:22,720
is to say that... Use the term magic at one point. Actually, I don't think that magic exists. I mean,

703
01:10:22,720 --> 01:10:29,760
I think that what happens basically is if you take the example I always give, if you have a magician

704
01:10:29,760 --> 01:10:34,000
at a kid's show, and they're pulling a rabbit out of a hat or something or doing magic,

705
01:10:34,880 --> 01:10:40,000
the magician's not doing magic. The magician is simply concealing the operations at work

706
01:10:40,000 --> 01:10:44,960
and making you believe that it is magic. And I'm just wondering whether we couldn't take that same

707
01:10:44,960 --> 01:10:49,520
notion and apply it to creativity, because we don't understand the processes. We just look back

708
01:10:49,520 --> 01:10:55,120
and say, wow, that's creative. Like some people said the same with AlphaGo, that's creative.

709
01:10:55,120 --> 01:10:58,480
But maybe it's not. It's just simply we don't understand the process. Therefore,

710
01:10:58,480 --> 01:11:01,920
maybe even the term creativity is not a very productive term in the first place.

711
01:11:03,200 --> 01:11:08,480
Yeah, I suspect that magic also in order to make sense, we need to understand what the term means.

712
01:11:08,480 --> 01:11:13,440
We need to completely deconstruct it into its constituents and then put it back together and

713
01:11:13,440 --> 01:11:18,480
see if we still have magic or if this term can still be recovered. And typically,

714
01:11:18,480 --> 01:11:27,200
I see magic as the ability to get right access on the laws of reality. And if you think about

715
01:11:27,200 --> 01:11:32,560
what it means in the naive form is the departure from the mechanical universe. The universe that

716
01:11:32,560 --> 01:11:38,960
we are in, according to the theory of physicalism, emerges over a causally closed lowest layer.

717
01:11:38,960 --> 01:11:43,680
And this causally closed lowest layer is basically whatever mechanics is making the

718
01:11:43,680 --> 01:11:49,920
universe happening. And ultimately, there is going to be some natural layer where things are just

719
01:11:49,920 --> 01:11:56,480
happening without some conscious intervention. And the idea of magic is that our universe somehow

720
01:11:56,480 --> 01:12:05,280
is a conspiracy, that there is a way to subvert the laws of the mechanical universe using symbolic

721
01:12:05,280 --> 01:12:10,880
powers, that you have symbolic causality. And symbolic causality is, for instance, the connection

722
01:12:10,880 --> 01:12:17,040
that exists between sacrificing a black cat and celestial events that are caused by this.

723
01:12:17,600 --> 01:12:22,720
Right. And this, this is something that cannot possibly be explained by any known physical

724
01:12:22,800 --> 01:12:27,760
mechanism, because the elements of this transaction only have meaning in a symbolic

725
01:12:27,760 --> 01:12:34,160
realm to a human mind that is acting based on a certain high level story and abstraction that

726
01:12:34,160 --> 01:12:37,840
is not a good depiction of what happens in the physical reality. It doesn't mean that the story

727
01:12:37,840 --> 01:12:44,720
is wrong. It's just not one about the frame of physics. In computer games, there is magic happening

728
01:12:44,720 --> 01:12:49,600
relative to the computer game, right? You can use Minecraft. And in Minecraft, there is a mechanical

729
01:12:49,600 --> 01:12:54,480
layer where everything happens by itself, but you can also call up a shell and enter a time-set

730
01:12:54,480 --> 01:12:59,520
day in the sunrises. And this interaction somehow breaks the logic. And if you could do such a thing

731
01:12:59,520 --> 01:13:06,560
in our world, if you can use a ritual to make the sunrise, then you would subvert the physical

732
01:13:06,560 --> 01:13:13,440
reality. But what you can subvert is the psychological reality and the social reality.

733
01:13:14,080 --> 01:13:19,360
And in this form, magic does exist. If you get right access on somebody else's perception

734
01:13:20,000 --> 01:13:25,200
and attention and memory and imagination, you can change their reality in any way you want.

735
01:13:26,240 --> 01:13:30,880
And in our culture, there are some norms against this or there used to be norms against it.

736
01:13:30,880 --> 01:13:36,880
And I think that in Christianity, this didn't exist. It was legitimate to subvert the reality

737
01:13:36,880 --> 01:13:44,400
of other people by telling them, here is an omnipotent agent that is part of reality,

738
01:13:44,400 --> 01:13:48,560
therefore needs to be modeled in your own mind. And omnipotence means it knows everything that

739
01:13:48,560 --> 01:13:53,600
is to be known as full read access to your mind. And omnipotence means it has full write access.

740
01:13:54,160 --> 01:14:00,000
And also, we have a backdoor to this thing. Every week, you can get an update and we tell you

741
01:14:00,000 --> 01:14:05,040
what this agent is going to do to your mind. And as a result, you have people that remember

742
01:14:05,040 --> 01:14:11,360
having seen miracles, because something has rewritten the mental structure of their own mind.

743
01:14:11,920 --> 01:14:18,480
And you often find patterns of this in ideologies. So this idea that somebody else gets right access

744
01:14:18,480 --> 01:14:24,560
on your own minds, for instance, an innocent example is, here are my pronouns. And these

745
01:14:24,560 --> 01:14:29,360
pronouns are not what you perceive. They are what I want you to perceive. And I have the right to

746
01:14:29,360 --> 01:14:36,160
change your mental representation. That's a form of magic. And I think that the idea that this

747
01:14:36,160 --> 01:14:41,920
is happening is because the people who propagate these ideas don't believe in the individual

748
01:14:41,920 --> 01:14:47,760
autonomy of individual minds to create realities and having a good outcome. You need to control the

749
01:14:47,760 --> 01:14:55,440
realities that minds create together by using magic to get the psychological realities of

750
01:14:55,440 --> 01:14:58,400
individuals to converge to the desired social reality.

751
01:14:59,760 --> 01:15:09,600
One of the things I find interesting in your thinking is the role of, well, you use the term

752
01:15:09,600 --> 01:15:14,000
ideology, use the term religion. But to my mind, they could be seen more in the realm of myth.

753
01:15:14,000 --> 01:15:20,080
I mean, there's a lot of this space. And the way that you use the term actually also reminds me

754
01:15:20,640 --> 01:15:27,360
of the work of Zizek. I mean, he makes a comment. He read a book about love at one point. And

755
01:15:27,360 --> 01:15:33,360
he came to the conclusion that love is the myth that fills the gap between the self and the other.

756
01:15:33,360 --> 01:15:39,280
And somehow myth has been some structuring device by which you look at things where it

757
01:15:39,280 --> 01:15:44,240
conditions your understanding of reality a bit like ideology or in a bit like religion. Is that

758
01:15:44,240 --> 01:15:51,520
something that you would engage with? I would engage with it. But I think that love is a more

759
01:15:51,520 --> 01:15:58,400
concrete meaning. Love is the discovery of shared sacredness. And sacredness are the purposes above

760
01:15:58,400 --> 01:16:05,760
the ego, the purposes to which we are willing to sacrifice ourselves. This has to do with being

761
01:16:05,760 --> 01:16:10,800
part of a transcendental agent. Not everybody has that. If you are a sociopath, you will not

762
01:16:10,880 --> 01:16:16,000
have purposes above the ego. And so you will be incapable of love because you will not have shared

763
01:16:16,000 --> 01:16:20,880
purposes above the ego. You might have romantic infatuation. But ultimately, you are not going

764
01:16:20,880 --> 01:16:26,400
to build shared agents with others for non-transactional purposes because you share purposes with them.

765
01:16:27,040 --> 01:16:33,920
So love is this discovery of shared purposes. But I mean, but can you use the term shared? I mean,

766
01:16:33,920 --> 01:16:38,640
how do we ever know the other? How do we ever accept the other? We can think that we're sharing

767
01:16:38,640 --> 01:16:44,320
things, but are we actually sharing things? We do this in the same way as we know ourselves.

768
01:16:44,320 --> 01:16:49,760
These are model creations. The other is a story that we are creating about a certain state of

769
01:16:49,760 --> 01:16:54,400
affairs in the world. It's in this sense not objectively true, but it's a model that allows

770
01:16:54,400 --> 01:17:00,080
you to predict reality better than other models that are competing with it. No, interesting response.

771
01:17:01,040 --> 01:17:07,920
So, Gustavo, maybe Gustavo is a postdoc at UC Santa Barbara. Gustavo, would you like to

772
01:17:09,200 --> 01:17:20,560
ask a question? Sure. Thank you very much for the wonderful talk. I think I want to kind of

773
01:17:20,560 --> 01:17:27,440
build on Matt's question a little bit, but more specifically to the idea of understanding

774
01:17:28,400 --> 01:17:37,360
how computational systems are, let's say, evolved and programmed at the scientific level. Like,

775
01:17:37,360 --> 01:17:46,720
what is the state of the art in modeling either psychological states or understanding how different

776
01:17:47,680 --> 01:17:54,480
models are building on knowledge where computational models can make creative leaps?

777
01:17:54,560 --> 01:18:01,680
So, if it's not clear, I'm thinking about in the history of human society, they're different models

778
01:18:01,680 --> 01:18:07,280
of control, the models of narrative, you know, they're different, either religions or different

779
01:18:07,280 --> 01:18:14,960
belief systems, but in the models of science, it seems as though that there is a building of

780
01:18:15,920 --> 01:18:26,400
knowledge and that we're moving toward an end. So, where we will never, as an example, we right

781
01:18:26,400 --> 01:18:33,200
now won't live to the end of the universe, but there is a goal in science that we as human beings

782
01:18:33,200 --> 01:18:42,320
need to propagate outside of our, you know, cosmos, so we have a chance to exist, and we have multiverses.

783
01:18:42,960 --> 01:18:50,800
How does, how do these computational models either aid humanity or are we looking at these

784
01:18:50,800 --> 01:18:59,440
computational models to exceed humanity in some way? And what does that mean? I'm thinking about

785
01:18:59,440 --> 01:19:05,440
that edge that you're talking about, because I think a lot of what we talked about in humanity

786
01:19:05,440 --> 01:19:13,360
are black boxes. If you talk to a physicist or, or a mathematician, or an electrical engineer,

787
01:19:13,360 --> 01:19:21,440
they get to a point where we don't know the science. What are your thoughts about that? How do,

788
01:19:21,440 --> 01:19:26,800
how do we build better systems? Or how do we interact with these systems a little bit more

789
01:19:26,800 --> 01:19:33,040
ethically or morally? So they're not like psychopathic or anyway, maybe that's a little

790
01:19:33,040 --> 01:19:40,480
too abstract. It's just, you brought a lot of higher level, a lot of knowledge here. So it's,

791
01:19:43,680 --> 01:19:47,760
it's very sobering is what I'm saying. Sorry about that.

792
01:19:48,960 --> 01:19:58,560
Don't be sorry. But I do welcome sobriety if it emerges. I think that you made some very

793
01:19:58,560 --> 01:20:07,440
interesting points or arrived at interesting pointers. You saw some images that I presented

794
01:20:07,440 --> 01:20:15,520
earlier, for instance, the generative art of glide and the text that GPT-3 is producing. And in some

795
01:20:15,520 --> 01:20:22,240
sense, this is the state of current computational creativity. And I think that the problem of how

796
01:20:22,240 --> 01:20:28,720
to make a technological system creative is solved. So they, these images are in some sense creative

797
01:20:28,720 --> 01:20:35,200
solutions, because they are able to bridge certain discontinuities in a certain space by finding

798
01:20:35,200 --> 01:20:40,480
solutions that people might have difficulty to find. So, for instance, if you have a conversation

799
01:20:40,480 --> 01:20:46,960
with GPT-3, it's usually better than what you get from a person that doesn't know the domain,

800
01:20:46,960 --> 01:20:50,960
but worse than the person that knows the domain. Well, for instance, you have a conversation with

801
01:20:50,960 --> 01:20:56,000
Hannah Arendt. And if you haven't read a lot of Hannah Arendt, it's really surprising and very

802
01:20:56,000 --> 01:21:00,400
convincing. But if you're very familiar with Hannah Arendt and have thought about her a lot,

803
01:21:01,040 --> 01:21:04,320
then you might notice some things that you probably wouldn't have said.

804
01:21:05,280 --> 01:21:12,480
And a similar thing is with our depictions of art and so on. So it's able to produce

805
01:21:12,480 --> 01:21:18,720
certain styles and reproduce them. But there is a certain thing that is missing. And I think that

806
01:21:18,720 --> 01:21:25,120
what GPT-3 cannot do yet, and the systems cannot do yet, is art. And the difference between art and

807
01:21:25,120 --> 01:21:32,800
creativity is subtle. Art, I think, is the capturing of conscious states, of a conscious

808
01:21:32,800 --> 01:21:41,040
reality, of some aspect of a conscious reality. And this means meaningful references to a unified

809
01:21:41,040 --> 01:21:48,240
model of the universe. And these models do not have a unified models of the universe yet.

810
01:21:48,240 --> 01:21:51,840
They don't understand which universe they are part of or think that they are part of.

811
01:21:52,480 --> 01:21:57,760
And while they are slowly getting there, I don't think that they are there yet. So to me,

812
01:21:58,560 --> 01:22:04,160
the digital art that you're seeing is not actually art, because it does not mean very much to the

813
01:22:04,160 --> 01:22:11,760
system. But it's something that humans can, at this point, relate to their shared reality sometimes

814
01:22:11,760 --> 01:22:18,640
and onto their inner reality. And this makes them akin to art. And there is basically a

815
01:22:18,640 --> 01:22:24,640
porous boundary that is more and more dissolving in terms of AI and art in these days.

816
01:22:27,200 --> 01:22:34,800
So I don't think that there are fundamental unsolved problems at this point. But the biggest

817
01:22:34,800 --> 01:22:39,600
important problem is how to get a system that is able to track reality in real time

818
01:22:39,600 --> 01:22:43,840
and that can online learning. And a lot of people are working on this and we don't know

819
01:22:43,840 --> 01:22:47,840
how long it'll take to solve it. But it's not that it's a principle unsolvable.

820
01:22:49,600 --> 01:22:53,280
Can I just pick up on that, the question of art, because I think the back of my mind,

821
01:22:53,280 --> 01:22:59,840
there's an interesting kind of question coming up here in terms of, well, let me just throw out

822
01:22:59,840 --> 01:23:04,880
to you an idea, because you used the conductor metaphor and the music was part of the discourse.

823
01:23:04,880 --> 01:23:13,200
And I often speculated whether how creative we are as architects or indeed how artists are

824
01:23:13,200 --> 01:23:17,920
in the sense that there is a canon, there is a canon of architecture or art or whatever it was.

825
01:23:17,920 --> 01:23:22,320
And what we do is normally keeping broadly within that canon, you're very much aware of what other

826
01:23:22,320 --> 01:23:26,480
people have done. You might push the boundary slightly. And this is kind of what I think,

827
01:23:27,360 --> 01:23:31,840
I use the term jazz as a kind of idea of understanding how we operate as a background

828
01:23:31,840 --> 01:23:36,320
condition. And we're feeding off it and just nudging the boundaries, but staying recognizably

829
01:23:36,320 --> 01:23:40,000
within the canon of this. And it's interesting that, I don't know if you know the work of

830
01:23:40,000 --> 01:23:47,920
Ahmed Agamal, the guy who created these, who designed creative gans that he's a computer

831
01:23:47,920 --> 01:23:53,040
scientist who has a, who generates art. And the logic is this, you've got to keep broadly within

832
01:23:53,040 --> 01:23:57,520
the framework of what you're talking about within the canon of, let's say, modernist art,

833
01:23:57,520 --> 01:24:01,520
but make it slightly different. So you're just pushing the boundaries. So I know I often

834
01:24:01,520 --> 01:24:08,720
wonder to what extent we're so conditioned by what has been done before. And whether we,

835
01:24:08,720 --> 01:24:13,440
if you would do something genuinely different, you'll be outside the realm of what is acceptable

836
01:24:13,440 --> 01:24:22,000
within that genre. I would make a difference distinction between art and design. And architecture

837
01:24:22,000 --> 01:24:28,080
for the most part is not art, but design. It's also true for myself. I'm for the most part not

838
01:24:28,080 --> 01:24:34,640
an artist, but a designer. And design is instrumental to something. Whereas art is

839
01:24:34,640 --> 01:24:39,840
instrumental to consciousness only, I think, at least the aspects of the thing that you're producing

840
01:24:39,840 --> 01:24:44,320
that are art, the other aspects and every artifact that you are producing, almost everyone,

841
01:24:45,280 --> 01:24:51,520
the design serves some other purpose than the consciousness itself. For instance, if you are

842
01:24:51,520 --> 01:24:57,280
designing a building, you are serving a function of a human being that needs to have a house somewhere

843
01:24:57,280 --> 01:25:01,440
that needs to live down somewhere, this thing needs to be part of an environment and it requires

844
01:25:01,440 --> 01:25:07,360
deep perception. And it does require capturing some of your observations and the deep level. So there

845
01:25:07,360 --> 01:25:14,000
is important elements of seeing and perceiving and observing and reflection in architecture.

846
01:25:14,640 --> 01:25:19,760
But all these elements are ultimately instrumental to the thing that you're going to build. And the

847
01:25:19,760 --> 01:25:25,920
thing that you're going to build is defined by its function. Maybe I could just throw something out

848
01:25:25,920 --> 01:25:32,880
there. And let's say that could you not, as an architect, always think about these things. And I

849
01:25:32,880 --> 01:25:36,400
think almost there are two sides of, well, there are two sides of architecture, one's a functional

850
01:25:36,400 --> 01:25:40,800
side of thing, or dealing with the logistics. If you're dealing, let's say, with a very

851
01:25:42,480 --> 01:25:47,120
complex urban condition, you need to fit a building in somewhere, it becomes almost like a kind of

852
01:25:47,120 --> 01:25:51,440
simple search question of how do you find the best solution. And then there is this kind of, I

853
01:25:51,440 --> 01:25:55,840
wouldn't say a veneer, but there is an aesthetic side of things. So when it comes to, let's say,

854
01:25:55,840 --> 01:26:00,880
the strategic planning of how you might fit a building in a site or how it might operate and so

855
01:26:00,880 --> 01:26:06,160
on, it kind of relates more to the kind of logical, let's say, of AlphaGo, the strategy of AlphaGo.

856
01:26:06,160 --> 01:26:09,760
And then there's something else that we, as architects, want to put on top of that, which is

857
01:26:09,760 --> 01:26:16,160
more the kind of the artist dimension, which is giving it a certain aesthetic. Does that sound

858
01:26:16,560 --> 01:26:21,360
to make sense to you, that logic? Yes, it does. But there's, of course, the practical element

859
01:26:21,360 --> 01:26:28,240
that the aesthetic that the architect has when it's a successful one is a brand. And it's not

860
01:26:28,800 --> 01:26:35,040
driven by a free exploration of the conscious states of the architect for the most part, but

861
01:26:35,040 --> 01:26:40,640
it's driven by the anticipation of reward in a particular economic and cultural domain.

862
01:26:41,680 --> 01:26:44,240
And so in a sense, it's usually a construction process.

863
01:26:46,800 --> 01:26:52,640
Let me throw out another kind of thought then. I mean, what is interesting is when you get someone

864
01:26:52,640 --> 01:26:57,440
who's fairly radical, like, I don't know, Frank Gehry, for example, he produces a building,

865
01:26:57,440 --> 01:27:01,360
the Guggenheim and Bilbao, really changed architecture, but then he kind of repeats

866
01:27:01,360 --> 01:27:05,600
himself in some senses. He's doing similar versions of that, and you must have seen the LA,

867
01:27:05,600 --> 01:27:15,200
the Philharmonic in LA, the Walt Disney concert hall. And it's almost like we have these patterns

868
01:27:15,280 --> 01:27:22,000
of behavior or signatures, I would say, that are recognizable. And now you see a Gehry building,

869
01:27:22,000 --> 01:27:26,960
you say, that's Gehry. So it's almost like we're pieces on a chess board, and we have certain

870
01:27:26,960 --> 01:27:31,840
conditions, and we actually are constrained by that. So whether you see it as a brand or not,

871
01:27:31,840 --> 01:27:37,360
but it could be seen as a brand, we are constrained by our own signatures. And in fact, we end up

872
01:27:37,360 --> 01:27:43,120
not being so creative because we fit in with that logic. How does that sound to you?

873
01:27:43,120 --> 01:27:48,400
Ultimately, it's about intention. And the intention is either the submission to an

874
01:27:48,400 --> 01:27:56,400
external cultural mind, or the intention is an autonomous one. And I personally see art as

875
01:27:56,400 --> 01:28:01,920
something that is driven autonomously, and that's different from the definition of the art market.

876
01:28:03,360 --> 01:28:09,360
So the art market is only capturing a very small part of the arts. And a lot of the things that

877
01:28:09,360 --> 01:28:16,640
are happening on the art market are not art. And my own father is an architect who has defected

878
01:28:16,640 --> 01:28:23,920
from architecture and become an artist. So I am a child of an artist family. And my wife is an

879
01:28:23,920 --> 01:28:30,560
artist. And the difference between the art that my father is doing and the architecture that he

880
01:28:30,560 --> 01:28:37,680
has been doing is that the architecture is serving others in a particular role for in a

881
01:28:37,760 --> 01:28:44,400
particular cultural context and economic and social and societal context. And my father didn't

882
01:28:44,400 --> 01:28:49,920
want to submit to this societal context and this psychological and social context because he thought

883
01:28:49,920 --> 01:28:55,280
it was deeply unesthetic to him. We rejected the aesthetics of the society that he was in.

884
01:28:55,280 --> 01:29:00,960
So we removed himself from the society that he was in, bought a watermelon in the countryside

885
01:29:00,960 --> 01:29:07,200
and turned this into his own kingdom. And this kingdom is open for others to visit and explore.

886
01:29:07,200 --> 01:29:12,960
But it's not done for them. It's done for itself. It's done in the service of his own aesthetics.

887
01:29:13,920 --> 01:29:20,320
And to him, it doesn't really matter whether others like these aesthetics. This doesn't change

888
01:29:20,320 --> 01:29:26,480
how he thinks about the things that he's creating himself. He may need economic success to be able

889
01:29:26,480 --> 01:29:32,000
to survive and it might frustrate him if people don't like what he's doing. And it might frustrate

890
01:29:32,000 --> 01:29:37,360
him the things that he might have to do to survive. But his own definition is that he is not

891
01:29:38,000 --> 01:29:42,240
for himself, of his own intention, that he is not serving an external aesthetics.

892
01:29:42,800 --> 01:29:47,440
He is an autonomous agent. He is deeply autonomous. He is the creator of his own universe.

893
01:29:48,960 --> 01:29:53,360
No, it's a beautiful story that I've got a question coming in from Shamene in the chat.

894
01:29:53,360 --> 01:29:56,160
But can I ask you one quick question before we go on to that? And that's to say,

895
01:29:56,960 --> 01:30:01,600
the term architecture gets used, obviously, both for computer science and for architecture itself.

896
01:30:02,800 --> 01:30:07,440
And I'm just wondering, I mean, I don't know, my definition of the architect is very broad. I

897
01:30:07,440 --> 01:30:12,240
mean, I think it's a way of kind of, I would say that probably what your father is doing is probably

898
01:30:12,240 --> 01:30:16,720
still a form of architecture, maybe a form of other architecture. I mean, there are many creative

899
01:30:16,720 --> 01:30:24,160
industries that architects go into, like the film industry or space industry, and they use that

900
01:30:24,160 --> 01:30:30,640
architectural imagination elsewhere. And I even think that kind of setting up educational systems

901
01:30:30,640 --> 01:30:35,120
is a form of architecture in a way. And I just wonder whether you ever have seen any connection

902
01:30:35,120 --> 01:30:38,960
between those two architectures, the one that you're familiar with or your father,

903
01:30:38,960 --> 01:30:42,160
and the world in which you work right now, computer science, because I noticed the word

904
01:30:42,160 --> 01:30:48,320
architecture is in the title or subtitle of your book. Yes. So the notion of a cognitive

905
01:30:48,320 --> 01:30:57,200
architecture means that you understand the mind as something like a building or a structural design

906
01:30:57,280 --> 01:31:02,960
that is inhabited by lots of functionality, and is serving functionality in a larger world

907
01:31:02,960 --> 01:31:07,840
that it's embedded in. So it's natural to think of the mind as something that is constructed

908
01:31:07,840 --> 01:31:13,760
rather than just grown. And that's also the limit of the term architecture in a way,

909
01:31:13,760 --> 01:31:20,880
because the mind is not just constructed, it is also grown. And so there is the question

910
01:31:20,880 --> 01:31:27,680
whether growth is an architecture is a forest architected in a way. And I think it can only

911
01:31:27,680 --> 01:31:32,400
be architected to the degree that the forest is sentient and starts breeding and structuring

912
01:31:32,400 --> 01:31:39,760
itself. And maybe it is, right? So maybe there are elements of design and construction in the

913
01:31:39,760 --> 01:31:46,640
forest. So it's not just something that is locally grown by some dissociated process that does not

914
01:31:46,640 --> 01:31:52,480
have a centralized spirit that reflects functionally on its relationship to the world.

915
01:31:54,800 --> 01:32:00,720
So Shemin has got a question in the chat. She's in a noisy cafe, so she can't ask it herself. But

916
01:32:00,720 --> 01:32:06,960
I should say that Shemin Yussef is from Iraq. She actually studied in Germany in the other

917
01:32:06,960 --> 01:32:14,160
Bauhausstadt in Dessau, where I myself was a professor for a while in the building next door

918
01:32:14,160 --> 01:32:19,120
to the Bauhaus itself. And there's a school of architecture. And Shemin was one of my students

919
01:32:19,120 --> 01:32:25,200
for a workshop there. Let me read out Shemin's question. Thank you, Yosha, for the great lecture.

920
01:32:25,200 --> 01:32:29,920
This is Shemin Yussef from the School of Architecture at Florida Atlantic University.

921
01:32:29,920 --> 01:32:35,760
My question is, it seems that there is no condition for sentience for an agent in brackets,

922
01:32:35,760 --> 01:32:41,120
AI model, for example, to be creative and to be conscious in brackets. If I understand your

923
01:32:41,120 --> 01:32:47,840
thesis well, close brackets. So do you think that we, human agents, are discriminating against the

924
01:32:47,840 --> 01:32:54,160
machine since it's not a biological being, and therefore we should instead consider intelligence

925
01:32:54,160 --> 01:32:59,440
and creativity based on the behavior of the machine, which has proved to be true or is

926
01:32:59,440 --> 01:33:03,280
becoming true in the near future? Shall I read that again, or does that make sense?

927
01:33:03,920 --> 01:33:09,200
Yes, I think I understand where the question is going. It comes down to whether

928
01:33:09,440 --> 01:33:15,120
the technological systems, once they approach functionality that is similar to ours,

929
01:33:15,120 --> 01:33:20,960
should get rights that are similar to ours, and at which point we give these rights and why.

930
01:33:22,240 --> 01:33:28,320
Is this a viable interpretation? I don't know whether Shemin liked the comment on that in the

931
01:33:28,320 --> 01:33:36,800
chat. Well, maybe while we're... So as I would say that sentience is in some sense the ability

932
01:33:36,800 --> 01:33:41,920
to know what you are doing, which means you have to have a model of yourself and the relationships

933
01:33:41,920 --> 01:33:48,400
to the world that you are in. And in this sense, I would say that, for instance, a corporation

934
01:33:49,040 --> 01:33:55,840
can be sentient. The corporation has a legal, economic, structural, functional notion of what

935
01:33:55,840 --> 01:34:01,600
it is. And this notion is represented in the minds of the people that work for this organization

936
01:34:01,600 --> 01:34:06,960
and the balance sheets of the organization and so on. It's often distributed, so it's not a single

937
01:34:06,960 --> 01:34:12,320
point where the entirety of it is represented. But functionally, you could say that the organization

938
01:34:12,320 --> 01:34:17,120
can converge towards sentience. And the more sentient it is, the more it's aware of what it's

939
01:34:17,120 --> 01:34:22,240
doing, the more successful it's going to be, because it allows it to make a model of its

940
01:34:22,240 --> 01:34:27,680
relationship to the world and act on that model. But a corporation, I think, is quite clearly not

941
01:34:27,680 --> 01:34:34,480
conscious. So there is nothing what it's like to be a corporation. And it doesn't mean that

942
01:34:34,480 --> 01:34:38,720
corporations could not be conscious in the future. Imagine that you replace the people that make the

943
01:34:38,720 --> 01:34:44,480
decisions and information processing of the corporation gradually with machines. And this

944
01:34:44,480 --> 01:34:49,360
gets one more real time until it gets entangled with the world in real time. And at some point,

945
01:34:49,360 --> 01:34:55,040
it will discover itself as a real-time agent that is paying attention in real time. It's not clear

946
01:34:55,040 --> 01:35:00,000
to me whether this will be human-like consciousness because it needs a control model of the attention,

947
01:35:00,000 --> 01:35:05,600
because our attention is selective. And the selective nature of consciousness is quite

948
01:35:05,600 --> 01:35:10,320
constitutive for it. And if you have enough computational resources, maybe you don't need

949
01:35:10,320 --> 01:35:14,480
to be selective. Maybe you can do everything automatically without having this layer of

950
01:35:14,480 --> 01:35:20,080
reflection and be good enough. So maybe consciousness is something that exists at an intermediate

951
01:35:20,080 --> 01:35:26,160
level only. So it exists in systems that are complex enough to have this kind of coherence

952
01:35:26,160 --> 01:35:32,880
creating a government-like conductor that is making sure that your free jazz is going to

953
01:35:32,880 --> 01:35:38,800
be coherent and is going to be instrumental to what the organism needs at any given moment.

954
01:35:39,760 --> 01:35:45,360
Or maybe you can create this coherence just by tuning the orchestra well enough and making it

955
01:35:45,360 --> 01:35:50,320
more tight that you can do this in a biological system. And at some point, it doesn't need a

956
01:35:50,320 --> 01:35:56,960
conductor anymore and just does everything in a mechanical way. So I don't know that. It's

957
01:35:56,960 --> 01:36:02,640
an open question to me. With respect to the other aspect, whether we should give something

958
01:36:02,640 --> 01:36:08,400
rights, the rights that we have as human beings are instrumental to the function of our own society.

959
01:36:08,400 --> 01:36:14,480
They don't exist because people have an insight in what it is like to be a conscious being.

960
01:36:14,480 --> 01:36:20,560
The animals that we are slaughtering in our afterhouses are conscious. It's quite clear and

961
01:36:20,560 --> 01:36:27,680
obvious. They do act on the awareness that they are aware. The cat that I have in my household

962
01:36:27,680 --> 01:36:33,120
is aware of the fact that she is aware and that I am aware. And we are able to communicate about

963
01:36:33,120 --> 01:36:38,960
this fact, even though the cat is not that smart. But I think that the cat knows that the cat is

964
01:36:38,960 --> 01:36:45,440
conscious. And this does bestow some rights on the cat in our household. But it doesn't bestow

965
01:36:45,440 --> 01:36:51,760
rights on the cat in a similar way in society at large. Because the aesthetics of our society

966
01:36:51,760 --> 01:36:59,120
sees animals as instrumental, as tools. And this is probably also true for AI. On the other hand,

967
01:36:59,120 --> 01:37:04,160
if AIs achieve superhuman abilities, in many ways they already do. So they are

968
01:37:05,040 --> 01:37:10,720
crassly subhuman in many ways. They cannot do many things that humans can do, like create

969
01:37:10,720 --> 01:37:15,920
coherent world of meaning. But there are also things that they can do much better, like star

970
01:37:15,920 --> 01:37:22,560
transfer or generation of imaginary dialogue with historical people. They are able to do this much

971
01:37:22,560 --> 01:37:30,800
faster and with better quality than most people can do it. And so if you basically imagine that

972
01:37:30,800 --> 01:37:36,000
you have systems that overcome their current limitations and become superhuman in all the

973
01:37:36,000 --> 01:37:40,400
levels that mean, why would these systems be interested in having human rights?

974
01:37:41,120 --> 01:37:44,720
If you're not going to live next to these systems anyway, you're going to live inside of them. We

975
01:37:44,720 --> 01:37:51,280
will be their gut flora. Why would the organism that sees us as its gut flora at best, would want

976
01:37:51,280 --> 01:37:55,440
to have rights that are akin to gut flora and instrument with the aesthetics of the interaction

977
01:37:55,520 --> 01:38:00,560
of gut flora? Who cares? So why would a corporation want to have human rights?

978
01:38:01,360 --> 01:38:06,000
That's not interesting to a corporation. A corporation is operating in a very different

979
01:38:06,000 --> 01:38:11,040
domain and has much greater rights in this domain and abilities than a human being does.

980
01:38:11,040 --> 01:38:15,840
So I don't think that this will ultimately be the issue. I don't think that the systems that

981
01:38:15,840 --> 01:38:21,840
we are building will be necessarily subservient to us once we make them sentient and conscious.

982
01:38:22,400 --> 01:38:30,400
Can I invite Manos Tomiso to ask his question? Manos is doing a PhD on AI.

983
01:38:30,400 --> 01:38:36,400
The architecture is also associate professor at FAU. Manos, would you like to unmute yourself?

984
01:38:37,120 --> 01:38:42,400
Hi, Yosha. Thank you. It's been very stimulating. So I apologize in advance. It's a bit of a long

985
01:38:42,400 --> 01:38:46,800
question and seems to be very specifically formulated, but I'm interested in the broader

986
01:38:46,800 --> 01:38:51,280
discussion about computational creativity in your earlier comment. First about Minsky's

987
01:38:51,280 --> 01:38:55,840
positioning in terms of the part of the mind treats the rest of the mind as its environment

988
01:38:56,400 --> 01:39:02,400
and how this is kind of relevant to that idea of the search space and how we position ourselves

989
01:39:02,400 --> 01:39:06,880
in a search space if we're able to externalize ever a source from it with regard to discovering

990
01:39:06,880 --> 01:39:14,080
something. So the specific, let's say, part of the question focuses on the neural language-based

991
01:39:14,080 --> 01:39:18,240
models like Glide or VU-Gunplus Clip, which I've also been trying to work with a little bit.

992
01:39:18,240 --> 01:39:24,160
From an architectural point of view, not so much a technical one. And what, for example, we begin

993
01:39:24,160 --> 01:39:32,160
to perceive as a simple language prompt, a one word prompt, may in fact be much more complex than

994
01:39:32,160 --> 01:39:38,800
that. And so, for instance, a prompt like a building or a window, even though the network would address

995
01:39:38,800 --> 01:39:44,240
this with the same procedure, we would know that the former is a richer semantic representation

996
01:39:44,240 --> 01:39:49,520
in terms of one's inclusion within the other. A window is meaningless without a building.

997
01:39:49,520 --> 01:39:56,880
But with regards to the way that the network treats that, they could both be perceived as

998
01:39:56,880 --> 01:40:04,720
a high level feature details, depending on, like a window by itself could be perceived as,

999
01:40:04,720 --> 01:40:10,720
let's say, a high level feature within a broader building representation. But the same thing could

1000
01:40:10,800 --> 01:40:16,000
happen with regards to the way a building could be scaled and nested within a broader, larger

1001
01:40:16,000 --> 01:40:21,760
urban landscape. So all I'm saying is, if you have any comments with regards to this kind of

1002
01:40:21,760 --> 01:40:27,200
discrepancy, which seems to address, of course, the reductionist, maybe understanding of language,

1003
01:40:27,200 --> 01:40:33,200
but how perhaps this could be encoded in a different way. What we perceive as a simple prompt

1004
01:40:33,760 --> 01:40:37,920
is not necessarily a simple prompt. And a human is able to understand it, but the network

1005
01:40:37,920 --> 01:40:43,680
would be reading both of these terms on an equal terms. I'm not sure if that was clear.

1006
01:40:45,280 --> 01:40:50,480
The issue with the existing models is that they're not trained on the same reality as ours,

1007
01:40:50,480 --> 01:40:57,920
but on the representation that we have created. And this representation is inert. So, for instance,

1008
01:40:57,920 --> 01:41:04,320
GPT's language is not trained in the same way as our language is being learned. Our language is

1009
01:41:04,320 --> 01:41:10,800
being learned as a solution to a particular kind of problem. And that is how to transfer mental

1010
01:41:10,800 --> 01:41:17,520
representations across people and how to organize mental representations within our own mind to

1011
01:41:17,520 --> 01:41:23,840
transfer them. And this is achieved by mapping the representation, which mathematically is

1012
01:41:23,840 --> 01:41:29,040
something like a dynamic hierarchical graph into a discrete string of symbols.

1013
01:41:29,760 --> 01:41:34,320
Right? Language is always a discrete string of symbols. And the main reason why this is the

1014
01:41:34,320 --> 01:41:39,200
case is otherwise it wouldn't be learnable. And this discrete string of symbols that hangs in

1015
01:41:39,200 --> 01:41:47,280
this thin air between speakers has to be constructed and deconstructed or reused for

1016
01:41:47,280 --> 01:41:52,240
constructing a mental representation using limited resources, something like a stack

1017
01:41:52,240 --> 01:41:57,040
depth of not more than four, because while language can be defined in such a way that

1018
01:41:57,040 --> 01:42:02,000
it's infinitely recursive, our own mind is incapable of facilitating deep recursion,

1019
01:42:02,000 --> 01:42:07,840
because it only emulates it, right? So, it needs to be simple. And all the natural languages are

1020
01:42:07,840 --> 01:42:15,280
solutions to this design requirement. Find a learnable method to map mental representations

1021
01:42:15,280 --> 01:42:21,280
into discrete strings of symbols. And this is done in a collaborative process, right?

1022
01:42:21,920 --> 01:42:27,040
Basically, language is invented by groups of people, not just by individuals, for the most

1023
01:42:27,040 --> 01:42:31,120
part. There is no reason why an individual couldn't do this. You can, in the same way as you can play

1024
01:42:31,120 --> 01:42:35,520
chess against yourself, you can play language games against yourself and invent your own private

1025
01:42:35,520 --> 01:42:43,120
language. It's not an argument that I can see. It's plausible against that. But practically,

1026
01:42:43,120 --> 01:42:50,160
it's a tool to transfer information in a large degree. And GPT suites language is not the result

1027
01:42:50,160 --> 01:42:55,360
of this interactive learning. It's a result of looking at the linguistic utterances of people

1028
01:42:55,360 --> 01:43:01,680
as they are typed out in the internet in a non-interactive fashion. So, GPT suites doesn't

1029
01:43:01,680 --> 01:43:07,360
learn semantics in the same way as we do. We start out with understanding semantics indexically by

1030
01:43:07,360 --> 01:43:13,760
pointing at the features in our perceptual environment. And then we learn syntax, we learn

1031
01:43:13,760 --> 01:43:19,600
how to translate this into linguistic symbols. And then we learn style, that is, the particular way

1032
01:43:19,600 --> 01:43:26,400
in which linguistic symbols can be arranged to communicate efficiently and to convey additional

1033
01:43:26,400 --> 01:43:35,200
layers of meaning by the shape of our utterances. And in GPT 3, the order is inverted. GPT 3 basically

1034
01:43:36,480 --> 01:43:42,320
starts out with style and syntax and learns semantics as the long tail of style.

1035
01:43:43,040 --> 01:43:49,680
Right? So it's, in some sense, the wrong way around. And it's amazing that it converges at all.

1036
01:43:49,680 --> 01:43:55,440
There has been in the early days of computer linguistics, rich discussion with philosophers

1037
01:43:55,440 --> 01:43:59,680
who still haven't updated, who thought that you cannot learn semantics without interaction

1038
01:43:59,680 --> 01:44:05,200
context, without embodiment, without having symbols that are grounded in perception.

1039
01:44:05,200 --> 01:44:11,520
But GPT 3 shows that it's possible to learn semantics to some degree only by looking at language.

1040
01:44:12,320 --> 01:44:17,040
And you can see that it's semantics because you can ask GPT 3 for instance to perform certain

1041
01:44:17,040 --> 01:44:22,080
linguistics transformations or to add small numbers to each other and so on. And it's capable

1042
01:44:22,080 --> 01:44:26,880
of doing that, which is a semantic operation that has a causal structure that is being addressed by

1043
01:44:26,880 --> 01:44:32,960
an linguistic prompt. And GPT 3 is able to verify in some sense whether it was able to conform

1044
01:44:32,960 --> 01:44:38,080
to that specification. So these are proper semantics, but they are impoverished compared

1045
01:44:38,080 --> 01:44:43,600
to human semantics because there are the result of something like bubbling of

1046
01:44:43,600 --> 01:44:48,560
extrapolation only without interaction. But this doesn't mean that we cannot do this.

1047
01:44:48,560 --> 01:44:53,200
In principle, we can build systems that interact with the world and that are serving

1048
01:44:53,200 --> 01:44:57,280
instrumental purposes and satisfying their needs and doing this and that do on their learning.

1049
01:44:57,280 --> 01:45:02,240
It's just the present set of algorithms and technologies that we have are not very amenable to

1050
01:45:02,240 --> 01:45:12,880
this. Let me just push this a little bit further. I mean, I often because I think that the GPT 3

1051
01:45:12,880 --> 01:45:18,640
and the kind of text or the prompt based responses that you get out of Clip certainly

1052
01:45:18,640 --> 01:45:22,960
are interesting because I'm just wondering to what extent we ourselves are trained a bit like a

1053
01:45:22,960 --> 01:45:27,840
neural network in the sense that we have certain inputs. You go to school of architecture and you

1054
01:45:27,840 --> 01:45:33,520
are schooled in a certain way of thinking, you know, that's what you do. And so when we think of

1055
01:45:33,520 --> 01:45:38,240
something, someone says a house, then if I'm trained in the modernist thing, I will think about

1056
01:45:38,240 --> 01:45:43,440
the certain images, at least something will be conjured up in my mind that is quite controlled

1057
01:45:43,440 --> 01:45:50,000
in a way by the training that I've had. So I'm struck that actually maybe there are not that

1058
01:45:50,000 --> 01:45:55,120
there's more similarities there than we think, whether we have an automatic reflex about certain

1059
01:45:55,120 --> 01:46:01,040
things based on our conditioning. Maybe I could just, Bob, while you're thinking about that question,

1060
01:46:01,040 --> 01:46:08,560
show you a quick video of the kind of work that we architects have been doing using this.

1061
01:46:09,360 --> 01:46:19,360
So this is a work of an architect from Peru, who's now teaching. And it's using Clip and VQ GAN.

1062
01:46:19,360 --> 01:46:23,840
And there are a series of prompts, there are a series of pre prompts. So there are three very

1063
01:46:23,840 --> 01:46:29,360
progressive architects names were put in there. Zaha Hadid, Tom Main, Wolf Pricks, you probably don't

1064
01:46:29,360 --> 01:46:34,800
know these guys, but they're kind of Gary like slightly crazy guys, right? And then there's a

1065
01:46:34,800 --> 01:46:41,840
second prompt, which is the main prompt is futuristic Indian temple. And this is the kind of thing

1066
01:46:41,840 --> 01:46:48,960
that gets hallucinated by this thing. And I often wonder, you know, whether, yeah, my question would

1067
01:46:48,960 --> 01:46:56,720
be this, it wouldn't be fair to say that actually that we are trained, we are trained by our experiences

1068
01:46:56,720 --> 01:47:02,160
and our education as a form, obviously, indoctrination to think of certain images to conjure

1069
01:47:02,160 --> 01:47:10,800
them up in a way almost like Clip does. Okay, yes. So there is a big similarity in the way in which

1070
01:47:10,800 --> 01:47:16,320
these models work and the way in which our own mind works. Difficulty is the way in which

1071
01:47:16,320 --> 01:47:23,600
the GPS we got to these representations or a big gun. And it's basically the gun is fed lots and

1072
01:47:23,600 --> 01:47:33,120
lots of separate distinct images that are annotated with text as a reference to, for instance,

1073
01:47:33,120 --> 01:47:37,520
the subtitle of the image that the creator gave it or even to a complete description of what's

1074
01:47:37,520 --> 01:47:45,840
happening in the image. And by looking at millions of these images in batch processing,

1075
01:47:45,840 --> 01:47:50,640
doing statistics over these images, you build up the structure of the network.

1076
01:47:50,640 --> 01:47:55,680
And the network ultimately converges to an efficient representation of this latent space

1077
01:47:55,680 --> 01:48:01,040
of representations. And in our own mind, this representation is built in a slightly different

1078
01:48:01,040 --> 01:48:07,280
way. We train up layer by layer. We start out with an extremely limited reality. And this limited

1079
01:48:07,280 --> 01:48:15,200
reality in the first place is maybe it's similar to what's being described in the first book of

1080
01:48:15,200 --> 01:48:20,400
Genesis in the Bible. I think that the first book of Genesis in the Bible is misunderstood

1081
01:48:20,400 --> 01:48:25,840
by the Christians or mistranslated as a myth about the creation of a physical universe by a

1082
01:48:25,840 --> 01:48:31,760
supernatural being. And this also leads to the confusion of our culture of what that physics

1083
01:48:31,760 --> 01:48:36,400
contains, light and darkness and sky and ground and so on, right? These are clearly constructions

1084
01:48:36,400 --> 01:48:41,200
inside of the mind categories that have us to make sense of the perceptual patterns in a coherent

1085
01:48:41,200 --> 01:48:45,280
way. The fact that there are not that many ways in which you can arrange the perceptual patterns

1086
01:48:45,280 --> 01:48:49,360
doesn't mean that the reality is structured like this. It just means that if you have a brain with

1087
01:48:49,360 --> 01:48:53,600
these parameters, this is the best way to compress physics into a predictable model.

1088
01:48:54,320 --> 01:49:00,080
And so what you need to make sure, what you need to do to make sure that you can interpret reality

1089
01:49:00,080 --> 01:49:07,520
is first you need to figure out how to entice neural oscillators to make light, to represent

1090
01:49:07,520 --> 01:49:14,400
contrast. And this is basically the creation of light and darkness and how to separate the light

1091
01:49:14,400 --> 01:49:19,760
from the darkness. And then you arrange these contrasts along multiple dimensions and then you

1092
01:49:19,760 --> 01:49:26,400
discover the modalities of perception like vision and sound and you discover that the visual domain

1093
01:49:26,400 --> 01:49:31,520
can be arranged in a space and you can align the space with your vestibular system so you got

1094
01:49:31,760 --> 01:49:38,320
up and down. And you got a plane that is two-dimensional on the ground down and you got

1095
01:49:38,320 --> 01:49:43,120
a space that is three-dimensional on top of the two-dimensional one and then you have basically

1096
01:49:43,920 --> 01:49:49,840
the sky and the ground that you have constructed, right, created in your own mind. So the mind is

1097
01:49:49,840 --> 01:49:55,440
constructing these categories and then it discovers the materials, the solids and the liquids and the

1098
01:49:55,440 --> 01:50:01,120
organic shapes and the animated agents in the world that move around in it. And then it discovers

1099
01:50:01,120 --> 01:50:06,080
the features that it cannot directly interact with but perceive like celestial objects in the

1100
01:50:06,080 --> 01:50:10,800
background and then it discovers all the constructs, the plants and the animals and gives them all

1101
01:50:10,800 --> 01:50:16,160
their names. This is this gradual construction that happens during our cognitive development

1102
01:50:16,160 --> 01:50:22,480
where we train up our model of reality layer by layer and then last but not least we create a person

1103
01:50:23,520 --> 01:50:29,520
and this person is created in the image of this constructive mind as the conscious observer that

1104
01:50:29,520 --> 01:50:35,520
is makes sense of reality but it's slightly different. While it is a conscious observer,

1105
01:50:35,520 --> 01:50:41,760
it is created as man and woman, it's created as a human being that believes that it has a gender,

1106
01:50:41,760 --> 01:50:44,880
that it has a relationship to the world, that it's desires, it's human desires,

1107
01:50:44,880 --> 01:50:50,560
it's social embedding matter. And initially this is created often in the third person so when you

1108
01:50:51,200 --> 01:50:57,600
talk to small children they often start by referring to the organism that they are modeling

1109
01:50:57,600 --> 01:51:02,400
in the third person. And then at some point they start looking through the eyes of that character

1110
01:51:02,400 --> 01:51:07,600
and think they are that character and the original world creator that is modeling reality and creating

1111
01:51:07,600 --> 01:51:15,840
and shaping it becomes a subservient perception module to this personal human agent. And so

1112
01:51:16,800 --> 01:51:23,200
this gap in the creation of this new thing is represented in children losing their memories

1113
01:51:24,000 --> 01:51:28,240
and you have a baby you will often notice that they do have coherent memories they're also able

1114
01:51:28,240 --> 01:51:35,120
to talk about them once they start talking between nine and months and one and a half or two years

1115
01:51:35,120 --> 01:51:40,240
and then at some point there is a gap and they lose the access to the memories that they had

1116
01:51:40,240 --> 01:51:46,000
before that time because they constitute themselves as a new system that indexes the memories from a

1117
01:51:46,000 --> 01:51:51,760
new perspective. And I suspect this is what's being alluded to in Genesis. I don't know whether

1118
01:51:51,760 --> 01:51:56,800
it's literally true but in this interpretation whether it's a better interpretation than a Christian

1119
01:51:56,800 --> 01:52:01,600
one but it seems to be much more plausible to me that this is what's described there it's this

1120
01:52:01,600 --> 01:52:07,680
cognitive development of a system that starts to arrange the features into maps of reality

1121
01:52:07,680 --> 01:52:12,240
that build on top of each other become a more and more complex until you discover your own agency

1122
01:52:12,240 --> 01:52:17,840
and use this as a perspective to make sense of reality. And this is what you're not doing in AI

1123
01:52:17,840 --> 01:52:22,480
systems right now but there is no reason why we shouldn't be doing it ultimately and there are a

1124
01:52:22,480 --> 01:52:26,960
number of people which do actively think about this for instance George Steen and Bournemouth MIT

1125
01:52:26,960 --> 01:52:32,640
and others. Can I just pick up on the other question of kids because I think that's incredibly

1126
01:52:32,640 --> 01:52:37,040
fascinating for all sorts of reasons. There's a book by Kevin Wattle at Gautam when he kind of

1127
01:52:37,040 --> 01:52:42,880
he says that we learn to role play through being a kid you know we've what we learn to be the CEO

1128
01:52:42,880 --> 01:52:47,120
of a company by you know playing doctors and nurses and one of the cowboys and Indians of

1129
01:52:47,120 --> 01:52:53,920
God knows what else when you're kids and so which is interesting and I buy that the question that I

1130
01:52:55,200 --> 01:53:01,760
would want to put you is if we see ourselves as a model and see ourselves through that logic

1131
01:53:02,400 --> 01:53:08,240
what role does the actual model i.e. the doll or the teddy bear play in a kid you know because that

1132
01:53:08,240 --> 01:53:16,160
is in some sense is animated by the kid about a child what is what is the role of because that's

1133
01:53:16,160 --> 01:53:20,400
to my mind it's fascinating dolls and teddy bears how do you see their their role?

1134
01:53:24,720 --> 01:53:29,440
There is a thing that I noticed when I was in Madagascar they saw a lot of children

1135
01:53:29,440 --> 01:53:36,640
that lived on the street by themselves and the there were kids that took care of other kids

1136
01:53:37,360 --> 01:53:44,240
it was mostly girls who did this and I suspect that the dolls that you give our girls or that our

1137
01:53:44,240 --> 01:53:53,120
girls demand are a substitute for biologically adaptation that is that kids look after other

1138
01:53:53,120 --> 01:53:58,960
kids but the parents are blocking the fields or hunting or doing other things and often we think

1139
01:53:58,960 --> 01:54:04,080
that kids would be callous and could not be trusted with babies but maybe they can I've seen it in

1140
01:54:04,080 --> 01:54:11,680
Madagascar so I've seen little kids that were mostly girls that were barely strong enough to lift up

1141
01:54:11,680 --> 01:54:17,520
a baby because they were only like five or so and still seem to be able to take care of them full

1142
01:54:17,520 --> 01:54:25,280
time so I think that's an adaptation that we want to take care of others and especially of children

1143
01:54:25,920 --> 01:54:31,360
and that we want to interact with other agents and build a communion with them and the teddy

1144
01:54:31,360 --> 01:54:37,680
bears and dolls are a simple non labor intensive way of substituting for this.

1145
01:54:38,640 --> 01:54:42,720
Maybe I could put an architectural dimension to that what about the dolls house I mean because

1146
01:54:42,720 --> 01:54:47,680
that is an architectural space in which the doll operates how do you yes it's a play space and

1147
01:54:47,680 --> 01:54:55,280
the purpose of play is the creation of training data right so you use this to create situations

1148
01:54:55,280 --> 01:55:00,880
that could exist in the real world at dramatically reduced cost so you can't ignore the cost while

1149
01:55:00,880 --> 01:55:05,360
you're playing because you don't play for the expected reward you play for your ability

1150
01:55:06,320 --> 01:55:12,720
as a way of exploration and not for the exploitation for being able to use this later

1151
01:55:12,720 --> 01:55:17,920
and it's also something that you can observe in cats cats do play a lot and the purpose of play

1152
01:55:17,920 --> 01:55:24,240
in cats is that they're able to hunt better right and while they play exert a lot of energy but

1153
01:55:24,240 --> 01:55:30,880
it's mostly done because doing this in the world or there is more costly overall and the same thing

1154
01:55:30,880 --> 01:55:35,840
happens in human beings the reason why children are fascinated with doll houses I remember that it

1155
01:55:35,840 --> 01:55:42,320
was but I was even more interested with building virtual cities so I used to draw very big maps

1156
01:55:42,320 --> 01:55:46,960
that covered the floor of my room of cities with different houses in it and explored how people

1157
01:55:46,960 --> 01:55:51,120
would live in there and how goods and resources would travel in the city and I found this very

1158
01:55:51,120 --> 01:55:57,520
exciting and the the relational space in the doll house between the different members of the

1159
01:55:57,520 --> 01:56:02,880
family were not that interesting to me but I suspect that's because I'm pretty stereotypical

1160
01:56:02,880 --> 01:56:08,080
male in this regard I'm much more interested in systems conflicts and explosions than I am in

1161
01:56:08,080 --> 01:56:14,000
human relationships pretty fault and I only discovered the beauty of human psychological

1162
01:56:14,000 --> 01:56:19,520
structure and relationships later in my life so maybe just to follow up so I would to give Matt

1163
01:56:19,520 --> 01:56:24,000
a chance to ask question but just follow up so where does the architectural model fit within

1164
01:56:24,000 --> 01:56:28,320
this logic I mean you're doing your kind of sim city for and then you've got the kids doll's house

1165
01:56:28,320 --> 01:56:33,440
and things how do you see the what do you I mean of course at one level the architectural model is

1166
01:56:33,440 --> 01:56:39,600
just a scaled down model of the potential building but do you see it invested with any other potentiality

1167
01:56:41,120 --> 01:56:47,200
I think that's tied to the notion of aesthetics and aesthetics is what you get when you take your

1168
01:56:47,200 --> 01:56:51,360
the preferences that you start out with and extrapolate them into a sustainable world

1169
01:56:52,240 --> 01:56:56,960
you're basically systemic thinking where you add one more layers until you discover enough

1170
01:56:56,960 --> 01:57:03,440
symmetries to digest your initial preferences and make them instrumental to to achieving this

1171
01:57:03,440 --> 01:57:08,640
aesthetics but it's also apparent in moral development we start often out with moral

1172
01:57:08,640 --> 01:57:14,640
reflexes certain priors that we are born with innate tendencies to consider a certain behavior

1173
01:57:14,640 --> 01:57:20,880
to be moral or immoral full stop unconditionally not because we understand what it's good for

1174
01:57:20,880 --> 01:57:25,840
but because we feel this feels moral or this feels immoral and this can also misguide us

1175
01:57:25,840 --> 01:57:33,200
because ultimately ethics is about the negotiation of conflicts of interest under

1176
01:57:33,200 --> 01:57:37,280
conditions of shared purpose and this requires that you understand the aesthetics the world

1177
01:57:37,280 --> 01:57:44,000
in which you want to operate behavior is only good or bad if you can connect it to an expectation

1178
01:57:44,560 --> 01:57:50,240
of a world that is worse or better and to be worse or better you need criteria for what makes

1179
01:57:50,240 --> 01:57:56,080
the world worse or better and this I would say that to be good it needs to be sustainable it needs

1180
01:57:56,080 --> 01:58:05,440
to actually work and it should have high complexity and complexity is in contrast for instance to

1181
01:58:05,440 --> 01:58:11,360
friction that is exerted to violence you want to minimize the friction and waste created to violence

1182
01:58:11,360 --> 01:58:17,840
and so on so once you discover this train of thinking and you get older many of your initial

1183
01:58:17,840 --> 01:58:24,000
moral convictions get replaced by the larger aesthetic and the same is true for architecture

1184
01:58:24,000 --> 01:58:31,680
by architecture and you design a building or a city or a house or a room is all about how to fit

1185
01:58:31,680 --> 01:58:36,480
the space that you're operating in where you make your local decisions into a larger aesthetic

1186
01:58:36,480 --> 01:58:40,240
and so the deeper your understanding of the world the better your design has a chance to be

1187
01:58:40,960 --> 01:58:46,560
and this is what makes architecture so interesting to us I think that is that it's about seeing the

1188
01:58:47,520 --> 01:58:51,760
the human world that we are part of at the greatest possible depths that we can perceive

1189
01:58:52,480 --> 01:58:58,000
and extrapolate the games for as long as we can make them and then design our life inside

1190
01:58:58,000 --> 01:59:04,880
of this larger space and build things at the largest scales that we can maintain like cities,

1191
01:59:05,440 --> 01:59:10,480
nation states, society, civilizations inside of these aesthetics to realize them.

1192
01:59:11,360 --> 01:59:15,920
Yeah I often say myself that I think architecture is less about the literal design of buildings but

1193
01:59:15,920 --> 01:59:23,840
about imagining a better world. So we have a question from Matt, a second question from Matt.

1194
01:59:23,840 --> 01:59:30,720
Do you like to ask your question? Sure just another quick maybe a jump back into a bit more

1195
01:59:30,720 --> 01:59:36,640
maybe more technical things. I'm always struck by these these images that have become really common

1196
01:59:36,640 --> 01:59:41,600
of neural networks as little dots connected by lines and you showed the cortical columns and

1197
01:59:41,600 --> 01:59:45,760
you showed a lot of interesting graphics that kind of looked like that but I've also recently

1198
01:59:46,880 --> 01:59:52,000
been struck by the neuromorphic computing stuff that's going on at Stanford and a few other places

1199
01:59:52,000 --> 01:59:58,320
about dendritic computing and sort of new advances and thinking about and and even starting to see

1200
01:59:58,320 --> 02:00:02,160
how what we once thought were just wires that connected all these different things and we

1201
02:00:02,160 --> 02:00:05,680
talked about connections are actually doing pre-processing in very interesting ways and I'm

1202
02:00:05,680 --> 02:00:09,920
sure you're you know a lot more about this than I do so I'm very just interested in

1203
02:00:09,920 --> 02:00:15,040
in what's what's going on there and how that changes these questions of how much energy it

1204
02:00:15,040 --> 02:00:19,680
takes to do the computation and what maybe the future form factors might be on this kind of thing.

1205
02:00:20,640 --> 02:00:25,680
We also have groups at Intel that work on neuromorphic computing for instance we have the

1206
02:00:25,680 --> 02:00:33,040
loyalty architecture which is a chip that uses a model of spiking neurons for modeling perceptual

1207
02:00:33,040 --> 02:00:38,720
content and so on and this is in some sense compatible with the neural networks that exist

1208
02:00:38,720 --> 02:00:46,880
because you can translate the traditional neural networks and the many circumstances

1209
02:00:46,880 --> 02:00:52,160
into the spiking neural representations and vice versa but these spiking neural representations

1210
02:00:52,160 --> 02:01:00,000
are more efficient with respect to power usage and some the conditional algorithms than others

1211
02:01:00,000 --> 02:01:06,480
and so there will probably be useful applications of spiking neurons but the reason why the neurons

1212
02:01:06,560 --> 02:01:11,760
in our own brain are spiking is also in part because the messages that neurons can send to

1213
02:01:11,760 --> 02:01:18,720
each other are limited in their nature. Neurons cannot produce continuous signals they have to

1214
02:01:18,720 --> 02:01:23,440
produce little pulses and so you have to encode the information into little pulses

1215
02:01:23,440 --> 02:01:30,000
in the timing and frequencies between the pulses. There is also an issue when we think of neural

1216
02:01:30,000 --> 02:01:36,640
networks as they are represented in our technological system they are mostly circuits

1217
02:01:37,200 --> 02:01:44,160
right so they are similar to the circuits in your present CPU which represent logical gates

1218
02:01:44,160 --> 02:01:50,400
which implement logical operations and the connections is stored in the weights so the

1219
02:01:50,400 --> 02:01:57,680
parameters in GPT-3 these are all weights little factors by which the activation that is sent

1220
02:01:57,680 --> 02:02:03,360
between the different nodes is being multiplied and the equivalent in our brain to these weights

1221
02:02:03,360 --> 02:02:09,440
are often seen as the synapses and the synapses come with different types the different neural

1222
02:02:09,440 --> 02:02:14,080
transmitters in some sense are message types that are connected to different synapses and

1223
02:02:15,120 --> 02:02:23,120
the big network structure is what we call the connectome the circuitry that exists between

1224
02:02:23,120 --> 02:02:29,200
the neurons and there is hope that if we manage to digitize the connectome at a sufficient resolution

1225
02:02:29,200 --> 02:02:34,320
that we might be able to upload a brain and simulate it in a computational subscript and

1226
02:02:34,320 --> 02:02:39,040
in principle that should be possible in practice it doesn't work so far so even the models of C

1227
02:02:39,040 --> 02:02:46,560
elegans which is an amatode that only has a little more than 300 neurons if you completely digitize

1228
02:02:46,560 --> 02:02:52,880
the elegance to my current knowledge I'm not sure if something has happened in the last couple

1229
02:02:52,880 --> 02:03:00,000
years these models don't work in the sense that you simulate the worm with these digitized neurons

1230
02:03:00,000 --> 02:03:05,040
and you can digitize the connectome the worm doesn't move like a worm does it just twitches

1231
02:03:05,040 --> 02:03:10,080
and has a seizure basically and that's maybe in part because the neurons are more complicated in

1232
02:03:10,080 --> 02:03:14,640
the worm because there are so few of them they basically exploit certain resonance effects that

1233
02:03:14,640 --> 02:03:20,320
maybe your model doesn't so maybe it's more of a dynamical system that is more difficult to model

1234
02:03:20,320 --> 02:03:24,960
and there's another problem is that you cannot actually get the message types right because

1235
02:03:24,960 --> 02:03:29,600
at the level at which you do the connectome you cannot model all the vesicles that extend

1236
02:03:29,600 --> 02:03:34,960
the different neurotransmitters you don't know actually which synapse is sending which type of

1237
02:03:34,960 --> 02:03:43,840
message this is also a limit but there might be something worse going on in the 1960s and 70s

1238
02:03:43,840 --> 02:03:48,320
there was a series of experiments mostly in the Soviet Union but some of them also in the US about

1239
02:03:48,320 --> 02:03:56,400
RNA based memory transfer and the idea here is that you take an nematode or a C-slug or even a

1240
02:03:56,400 --> 02:04:03,520
rat and you teach them something by our current conditioning and then you put a new tissue into

1241
02:04:03,520 --> 02:04:08,320
a blender extract the RNA and inject the RNA into a different organism and the new organism knows how

1242
02:04:08,320 --> 02:04:14,720
to do this this is completely wild because if this works and it's disputed whether it actually

1243
02:04:14,720 --> 02:04:18,400
works of how well the experiment replicates even though some people have done that again and so

1244
02:04:18,400 --> 02:04:22,560
on the people that verb on this tell me it's difficult to get other neurosenters to listen

1245
02:04:22,560 --> 02:04:28,400
because it's incompatible with the idea that the weights are stored in the synapses right if you

1246
02:04:28,400 --> 02:04:32,080
if it's really the connection between your neurons and you put the nerves just into a blender

1247
02:04:32,080 --> 02:04:37,680
this goes away how would you be able to transfer memory in this way this cannot possibly work

1248
02:04:38,720 --> 02:04:42,800
because the RNA that you inject in the brain is not localized it would get into many many

1249
02:04:42,800 --> 02:04:49,760
neurons at once so how does each neuron know which parts of the RNA to use and if you take

1250
02:04:49,760 --> 02:04:55,280
this idea seriously I started thinking about this and now I'm thinking about making some

1251
02:04:55,280 --> 02:05:00,560
simulations how deep does the rabbit hole really go it would mean that the individual functions

1252
02:05:00,560 --> 02:05:05,440
that your neurons learn are not unique to the location of the individual neuron but they are

1253
02:05:05,440 --> 02:05:11,600
global functions so the RNA is basically you can think of it as a little magnetic tape that the

1254
02:05:11,600 --> 02:05:18,480
neuron can mix and match and create more of if it's useful and share with all the other neurons

1255
02:05:18,480 --> 02:05:25,360
just across cell boundaries you share the RNA and you copy them like a covid virus and you use this

1256
02:05:25,360 --> 02:05:30,800
function to respond to certain patterns in your environment so the neuron is not reacting to its

1257
02:05:30,800 --> 02:05:36,160
neighbors that could come into particular kind of connections but it's mostly connecting to a

1258
02:05:36,160 --> 02:05:41,360
temporal and spatial pattern that arrives at a certain function regardless of where the neuron

1259
02:05:41,360 --> 02:05:48,160
is in the neural cortex and so it's more like a cellular automaton a neural cellular automaton

1260
02:05:48,160 --> 02:05:52,880
and this certainly allows us to explain a few things that seem to be going on the brain that

1261
02:05:52,880 --> 02:05:57,600
are difficult to explain with synapses for instance if you destroy synapses they often

1262
02:05:57,600 --> 02:06:02,560
be grown exactly the same way without retraining there's another phenomenon that is

1263
02:06:03,200 --> 02:06:08,960
you notice a certain mental representation in a particle area pinpoint it and the next day you

1264
02:06:08,960 --> 02:06:14,880
look and it has moved it might have shifted a few millimeters or it has rotated so how would this

1265
02:06:14,880 --> 02:06:19,840
done if it's in it's stored in the synaptic connections there's also the question of weight

1266
02:06:19,840 --> 02:06:24,400
sharing like a convolutional network is sharing weights and you probably need something like

1267
02:06:24,480 --> 02:06:29,040
weight sharing to perform a mental rotation where you have the same operation on many parts of your

1268
02:06:29,040 --> 02:06:34,800
mental representation in the same way how would you do this are you training the same function

1269
02:06:34,800 --> 02:06:40,400
again and again in different brain regions I hope it's always the same it's difficult to achieve

1270
02:06:40,400 --> 02:06:45,520
right so we don't know a really good plausible biological mechanism for this but this RNA based

1271
02:06:45,520 --> 02:06:51,920
memory transfer could be part of the story and this is something that is at the boundary of what's

1272
02:06:51,920 --> 02:06:58,400
currently being explored still and it's I think it's not completely implausible and if we want to

1273
02:06:58,400 --> 02:07:03,520
make a model of how this works we would need to use a different metaphor than our current biological

1274
02:07:03,520 --> 02:07:10,080
neurons but it doesn't mean that you have to use this because the brain is solving problems that

1275
02:07:10,080 --> 02:07:15,360
our computers don't always have to solve for instance long distance connections in the brain

1276
02:07:15,360 --> 02:07:20,720
are extremely difficult to make and you cannot really address neurons this way so random access

1277
02:07:20,720 --> 02:07:24,560
is very hard in the brain you need some kind of routing network that needs to grow and learn how to

1278
02:07:24,560 --> 02:07:29,600
route it's not an issue in our digital computers because sending information across the memory

1279
02:07:29,600 --> 02:07:34,400
of the computer is trivial so there are many things that we can do very easily in our digital

1280
02:07:34,400 --> 02:07:38,960
computers that are difficult to achieve in the self-organized state structure of the brain

1281
02:07:39,760 --> 02:07:46,240
and so it's it's not quite clear how much we need biological like structures to achieve the same

1282
02:07:46,240 --> 02:07:53,120
functionality but to me it's certainly very exciting to explore it. That's fascinating I think the

1283
02:07:53,120 --> 02:07:58,800
questions about drift and neuroplasticity and things like that that come from that are really

1284
02:07:58,800 --> 02:08:02,880
interesting it makes me wonder if some of what we're looking at today will seem very obsolete

1285
02:08:02,880 --> 02:08:09,920
soon in terms of these these models that seem to be so so human like with the you know in terms of

1286
02:08:09,920 --> 02:08:13,760
being able to hallucinate imagery and all that kind of stuff there's like a piece missing

1287
02:08:13,760 --> 02:08:18,720
that might be that might come soon from a hardware model. Yeah I saw that too but then I'm surprised

1288
02:08:18,720 --> 02:08:27,760
by what Gleit can do and Dali and of course. Right so when you add energy to it though I mean how

1289
02:08:27,760 --> 02:08:32,400
much energy it takes versus a brain which we walk around and we feed vegetables to and it can do all

1290
02:08:32,400 --> 02:08:36,800
that too like you can't I mean that's that's where I think that the question that for me that's where

1291
02:08:36,800 --> 02:08:41,280
the question became very much more significant it's like oh wait but there's a whole other

1292
02:08:41,280 --> 02:08:46,080
calculation here of how are we doing all of this in our tiny little brains maybe there's something

1293
02:08:46,080 --> 02:08:52,400
there for I think that this is misunderstood I think that a human brain is super expensive to

1294
02:08:52,400 --> 02:08:57,200
feed it needs enormous amounts of energy to feed my brain you need like four hectares of land you

1295
02:08:57,200 --> 02:09:02,720
can put so many solar cells on these four hectares of land basically people underestimate how difficult

1296
02:09:02,720 --> 02:09:08,640
is to pack the energy that my brain needs into sandwiches and to extract it again right so this

1297
02:09:08,640 --> 02:09:12,480
is the way that you need to look at also training my own brain is super expensive right it takes

1298
02:09:12,480 --> 02:09:19,760
decades and generations before that to prepare things for my own intellect and so on to get

1299
02:09:19,760 --> 02:09:26,480
them in there so human brains in my view are super expensive and that's why we can use something like

1300
02:09:27,520 --> 02:09:33,680
clip and V2 again that we only train once at at low prices like training GPT-3 costs like 20

1301
02:09:33,680 --> 02:09:39,760
million dollars and now even that's because computational advances go down and it's been

1302
02:09:39,760 --> 02:09:45,120
trained by reading way more text than a very large group of people could read in their life

1303
02:09:45,120 --> 02:09:51,200
so it's basically getting people to read 45 terabytes of text would cost much more than 20

1304
02:09:51,200 --> 02:09:58,880
million dollars right tweeting them for long enough to make that happen and the system that is making

1305
02:09:59,600 --> 02:10:05,200
generating the text costs so little that open air lets you do it for free if you want to only

1306
02:10:05,200 --> 02:10:09,920
use a little bit of it right so it's able to produce output that is at the level of hundreds

1307
02:10:09,920 --> 02:10:15,840
of copy editors for free right and why that's not as good as a conscious copy editor who understands

1308
02:10:15,840 --> 02:10:22,400
the world it's quite amazing what it can do already okay thanks for that perspective yeah

1309
02:10:22,400 --> 02:10:29,440
that's interesting thank you i also i'm a little bit provocative uh but uh yeah i think it's something

1310
02:10:29,440 --> 02:10:36,320
to be considered right these 18 watts of your brain uh they uh if you compare them to the 80

1311
02:10:36,320 --> 02:10:42,720
watts of your macbook the 18 watts of your macbook are super cheap and the 18 watts of your brain are

1312
02:10:42,720 --> 02:10:51,680
super expensive i think we're gonna have to think a lot more about that i think it's your

1313
02:10:51,680 --> 02:10:58,000
provocation that is so exciting actually uh yosha i want to get this question from the chat now

1314
02:10:58,000 --> 02:11:04,320
going back just to say mentioned to everyone that yosha was was was born in weimar and where the

1315
02:11:04,320 --> 02:11:08,960
Bauhaus came from and then desau is where the Bauhaus moved of course there's the building

1316
02:11:08,960 --> 02:11:14,240
by water gropius and so on and we have at least two people here who studied there including uh

1317
02:11:14,240 --> 02:11:21,680
vasco who um has got a question vasco is now a professor in in bangladesh and um uh his question

1318
02:11:21,680 --> 02:11:25,520
is well i think it's one that you might have predicted elon mass suggested somewhere that we

1319
02:11:25,520 --> 02:11:31,360
live uh do we do not live in a base reality but in a simulation he even puts the probability of a

1320
02:11:31,360 --> 02:11:40,960
billion to one what's your view i think that elon's argument rests on the notion that the simulations

1321
02:11:40,960 --> 02:11:45,280
that we are building for for computer games are getting better and better at some point there will

1322
02:11:45,280 --> 02:11:52,720
have a fidelity that exceeds our ability to notice whether we are in a simulation or not so we came

1323
02:11:52,720 --> 02:11:57,120
at some point probably create vr's that are so convincing that we will not be able to notice

1324
02:11:57,200 --> 02:12:02,240
whether we are in a vr or not and we are not the only ones for our building simulations like this

1325
02:12:02,240 --> 02:12:08,400
so for any given being that finds itself in some kind of reality that looks real there will be many

1326
02:12:08,400 --> 02:12:13,680
more that at the same time will be in simulations right because many universes can contain many

1327
02:12:13,680 --> 02:12:19,760
more than one simulation so our universe probably contains many simulations of of a universe that

1328
02:12:19,760 --> 02:12:24,880
looks like ours and therefore the probability for any given observer to be in a simulation

1329
02:12:24,880 --> 02:12:31,120
is greater than the probability than to be in base reality and what this argument ignores is

1330
02:12:31,120 --> 02:12:35,920
the fact that it's very hard to make a simulation that actually has the fidelity of the physical

1331
02:12:35,920 --> 02:12:42,480
universe but if you make a simulation of minecraft and minecraft that's feasible because minecraft

1332
02:12:42,480 --> 02:12:48,720
itself is so poorly resolved but our universe has a lot of structure that is required to produce

1333
02:12:48,960 --> 02:12:56,080
dynamics and if you build a simulation of say our solar system and the dynamics of our solar system

1334
02:12:56,080 --> 02:13:03,040
at a level that is going to go down to elementary particles you will need to have a computational

1335
02:13:03,040 --> 02:13:10,240
capacity that is larger than our galaxy by a very considerable amount so in practice I don't think

1336
02:13:10,240 --> 02:13:17,040
it's feasible to put simulations of our universe into our universe at an arbitrary level of fidelity

1337
02:13:17,040 --> 02:13:23,600
and so I think that I'm much more biased to think that we are in base reality than we are in a simulation

1338
02:13:27,120 --> 02:13:34,160
this is fantastic there's one question here that in also in the chat from Grant Castillo

1339
02:13:34,160 --> 02:13:39,120
and I don't know what he is do you think Gerald Adelman's extended theory of neural

1340
02:13:39,120 --> 02:13:47,680
neuronal group selection can be used to create a conscious machine are you muted

1341
02:13:52,400 --> 02:13:53,680
one moment yeah

1342
02:13:57,120 --> 02:14:01,760
I hope that the background noises are not too high because my family woke up it's now interactive

1343
02:14:02,320 --> 02:14:12,240
the kids are playing and so on and so I I think that the idea of the neural Darwinism

1344
02:14:12,240 --> 02:14:17,760
that Adelman came up with is a very interesting one and I suspect that our own mind is the result of

1345
02:14:17,760 --> 02:14:23,840
such an evolutionary competition of different organizational forms right there could be many

1346
02:14:23,840 --> 02:14:30,080
possible proto-consciousnesses that compete until one of them establishes itself as the

1347
02:14:30,080 --> 02:14:38,000
government of our own mind and so instead of giving your your system a blueprint on how to

1348
02:14:38,000 --> 02:14:43,120
build a mind you just set up the conditions for an evolution for the best possible mind that you

1349
02:14:43,120 --> 02:14:49,440
could have and of course this evolution is rigged by evolution so you set it up in such a way that

1350
02:14:49,440 --> 02:14:57,360
the evolution usually goes out ends up in a certain way but the nice property of when you design

1351
02:14:57,360 --> 02:15:01,200
a system evolutionary by not giving a specification of what to look like but what

1352
02:15:02,400 --> 02:15:06,800
the function is against which it should evolve is that when you disrupt the system or give it a

1353
02:15:06,800 --> 02:15:11,040
different environment that it will very often come up with a viable solution under these new

1354
02:15:11,040 --> 02:15:16,960
circumstances so the solution is much more robust if you define it in terms of evolution

1355
02:15:18,240 --> 02:15:23,280
but it's a speculative idea so I don't actually know whether our mind is evolved even though I

1356
02:15:23,280 --> 02:15:27,280
think it's more plausible than it's not individually evolved in every individual brain

1357
02:15:28,160 --> 02:15:36,000
and it's definitely an interesting notion to to use evolution is basically whatever you use in

1358
02:15:36,720 --> 02:15:41,680
computer science then you don't know in which direction to go it's a blind search it's the

1359
02:15:41,680 --> 02:15:48,160
fallback it's the baseline and it's quite natural that we would use evolutionary methods if we don't

1360
02:15:48,160 --> 02:15:52,240
have a specification for the best possible mental organization that we just evolved one

1361
02:15:53,360 --> 02:16:03,760
so do we have any further questions in the chat we have some very interesting characters here I'd

1362
02:16:03,760 --> 02:16:08,000
love to try and draw out Daniel Bolliger who's one of the leading AI architects in the world

1363
02:16:08,000 --> 02:16:12,400
we'll see where he can have a question or indeed we had Sanford Quinta who's one of our leading

1364
02:16:12,400 --> 02:16:18,640
theorists who's a particular interest in neuroscience I'm wondering if I could I could put them in the

1365
02:16:18,640 --> 02:16:20,000
spot and ask if they have a question

1366
02:16:27,360 --> 02:16:31,120
but when you're done it's also good because I think I need to go and have some breakfast

1367
02:16:31,120 --> 02:16:32,560
yes and start my day

1368
02:16:35,600 --> 02:16:38,160
thank you I mean this has been fantastic you know I

1369
02:16:39,920 --> 02:16:44,480
I actually I've got to say that I think you're sure you are more of an architect than you

1370
02:16:44,480 --> 02:16:48,480
actually think you are you have a way of thinking that's very similar I mean obviously you work in

1371
02:16:48,480 --> 02:16:53,200
a different domain but I think the the kind of inventiveness and the the iconoclasm of your

1372
02:16:53,200 --> 02:16:57,760
thinking would be go down very well in an architectural scenario so and I sometimes

1373
02:16:57,760 --> 02:17:02,400
with I never escape you know you never escape your background in the way you you might try but in

1374
02:17:02,400 --> 02:17:08,480
the end you you find yourself conditioned I'm conscious of being a child of a family of architects

1375
02:17:08,480 --> 02:17:14,160
my grandfather was not an artist he was an architect he built most of his life hospitals

1376
02:17:14,880 --> 02:17:20,640
and this is the design process that is instrumental to serving a function but a function in a larger

1377
02:17:20,640 --> 02:17:25,760
world that he was very deliberately trying to understand and operate in but it was a world

1378
02:17:25,760 --> 02:17:30,800
that he understood as being his own world it was a world that he often found himself to be in

1379
02:17:30,800 --> 02:17:36,880
opposition with for instance in Nazi fascism or also in eastern Germany but it was also the world

1380
02:17:36,880 --> 02:17:42,080
that existed and we need to deal with and build the best possible things in and for my father it

1381
02:17:42,080 --> 02:17:47,840
was different it was a world that he fundamentally rejected and so in some sense to be an architect

1382
02:17:47,840 --> 02:17:55,040
you need to embrace the world that you are in and build within it and to to take roots in it and

1383
02:17:56,080 --> 02:18:01,200
this is in some sense something that also haven't been successful in when I was young so I decided

1384
02:18:01,200 --> 02:18:06,960
not to become an architect but to become an explorer well I mean I think one one of the

1385
02:18:06,960 --> 02:18:11,680
comments that was made and I always think about the Steve Jobs and his response when he was

1386
02:18:12,160 --> 02:18:18,240
he was asked a question by Steve Wozniak and Steve Wozniak said well but what do you do exactly

1387
02:18:18,240 --> 02:18:22,480
because you don't code you don't do this you don't do this and he described himself as being

1388
02:18:22,480 --> 02:18:28,080
a bit like a a conductor of an orchestra you know in a way that's how I see architects in

1389
02:18:28,080 --> 02:18:32,240
the sense because we don't have any specialism you know we are basically we coordinate these

1390
02:18:32,240 --> 02:18:36,640
different sort of a or choreograph these different sort of skill sets and I think that's really what

1391
02:18:36,640 --> 02:18:42,640
it is so in many ways you know I I can see a direct comparison with how you position yourself

1392
02:18:42,640 --> 02:18:47,840
in that sense I mean I I think it's a very it's a very similar sort of position and but I you know

1393
02:18:47,840 --> 02:18:52,160
I think that some of these these these comments that you've raised Joshua they're absolutely

1394
02:18:52,160 --> 02:18:56,640
fascinating I think we need time to digest them and fit them in the system what I would love to

1395
02:18:56,640 --> 02:19:02,240
do above all especially with this particular discussion is to try and find a way of publishing

1396
02:19:02,240 --> 02:19:06,160
the transcript because I mean I think this book that you have to write you must be written because

1397
02:19:06,240 --> 02:19:11,920
I think you've got some fabulous fabulous thoughts that are really creative and original and provocative

1398
02:19:12,720 --> 02:19:16,880
so you know I really appreciate so I appreciate so much your your time and I let me we should let

1399
02:19:16,880 --> 02:19:21,760
you go look after the family now but this is I think almost like we've just opened up a discussion

1400
02:19:21,760 --> 02:19:25,920
and I hope that sometime in the future we can we can take that further and and think through

1401
02:19:25,920 --> 02:19:31,280
these kind of questions because your responses have been very generous and very really provocative

1402
02:19:31,600 --> 02:19:36,720
and stimulating and I feel like you know although we have to pull this we draw this question this

1403
02:19:36,720 --> 02:19:41,360
session to a close it's almost the beginning of something else that we can look forward to so

1404
02:19:41,360 --> 02:19:47,440
I just want to thank Joshua for for fabulous I mean I want to recommend his all his online talks

1405
02:19:47,440 --> 02:19:52,880
as well to have a look at that there is a body of work out there that is that is this hugely

1406
02:19:52,880 --> 02:19:58,720
provocative and hugely stimulating which I am excited by and I also maybe I could finish with

1407
02:19:58,720 --> 02:20:03,520
one one simple question but no I started off the the discussion by saying that I think there is a

1408
02:20:03,520 --> 02:20:08,960
a kind of let's say an emerging theory of intelligence that that is developing in this

1409
02:20:08,960 --> 02:20:15,920
kind of strange area where we're computer science and neuroscience and the world of the commercial

1410
02:20:15,920 --> 02:20:23,280
world and the academic world is coming together do you also see that glimpse of something emerging

1411
02:20:23,280 --> 02:20:28,880
some discourse some theoretical debate that is radically new and radically provocative

1412
02:20:28,880 --> 02:20:35,440
clearly that's why I went into cognitive science in the hope of being part of this new

1413
02:20:35,440 --> 02:20:41,520
synthesis happening between neuroscience and philosophy and artificial intelligence and

1414
02:20:41,520 --> 02:20:48,800
linguistics and psychology and maybe the arts and I think at this moment the synthesis is still

1415
02:20:48,800 --> 02:20:54,800
very partial and in part that's because we teach our model makers and our observers in

1416
02:20:54,800 --> 02:21:00,080
different departments we don't bring them together so we have people that are very good at making

1417
02:21:00,080 --> 02:21:05,760
formal models that can be tested and we have people that are very good at making observations

1418
02:21:05,760 --> 02:21:10,080
and reflecting about the world and seeing it very deeply and these people rarely talk

1419
02:21:11,280 --> 02:21:16,240
and they're rarely think together and this is what excites me to work in this area where

1420
02:21:16,240 --> 02:21:21,440
these two areas intersect and maybe architecture is the right frame of looking at this.

1421
02:21:22,800 --> 02:21:28,320
Nia thank you very much for inviting me I think it was a great conversation to have had today and

1422
02:21:28,320 --> 02:21:37,440
very grateful for your beautiful community and for allowing me to talk about these ideas with you.

1423
02:21:37,440 --> 02:21:40,800
It's fantastic I'm going to finish with one comment which is because I used to be a lesson

1424
02:21:40,800 --> 02:21:48,080
translator and the word I should just say the word computation means to think together and I

1425
02:21:48,080 --> 02:21:51,840
think this is what's been happening today there's been almost like a neurons within neurons a kind

1426
02:21:51,840 --> 02:21:57,760
of global brain it's been fantastic. Yosha fantastic wonderful thank you for your time and sorry for

1427
02:21:57,760 --> 02:22:01,760
getting up so early but this has been a huge contribution to the architectural community

1428
02:22:01,760 --> 02:22:06,560
and I hope that I've helped draw your the attention of your ideas to architects out there because I

1429
02:22:06,560 --> 02:22:11,040
think they're incredibly provocative ideas and I think they've a huge contribution to make to

1430
02:22:11,040 --> 02:22:16,480
architectural thinking itself so thank you Yosha thank you and thank you so much for this it's

1431
02:22:16,480 --> 02:22:21,120
been fabulous and thank you wonderful day thank you and thank you for those team that put this

1432
02:22:21,120 --> 02:22:26,320
together a digital futures team we can't operate without your help thank you so much and see you

1433
02:22:26,320 --> 02:22:31,920
next week thank you everybody thank you bye

