start	end	text
0	12680	Hello, and welcome to the fourth in our series on AI, Neuroscience and Architecture, which
12680	18800	has been put forward by the Digital Futures doctoral consortium group, whereby we're trying
18800	24160	to make important educational ideas available to students and architects across the globe
24320	29680	as a way to make education much more accessible to democratise as it were, education.
30240	37920	I'm delighted to have a very special guest here today, Yosha Bach. Before I introduce him,
37920	44240	let me just make one announcement about for next week. That is to say, on Saturday,
44240	52560	we will have a session on Digital Futures looking with Runja Chan looking at a generative game.
53520	59280	You'll find details of that on our website. Today then,
61520	66880	it's really very... I've been looking forward to this session very, very much. I've been watching
66880	76880	Yosha Bach at various interviews online, and I know from my friend Daniel Seth, who is a great
76880	81840	admirer of Yosha, although he says he disagrees with him on some things, but that we're going to
81840	88080	have a very special session today. I'm hoping that if nothing else, we will open up to a series of
88080	93280	new ideas and you will discover somebody who I think is a very significant and creative thinker
93280	104000	who is having a significant impact on the field. Let me say first of all that Yosha is from Germany,
104000	112000	from Delhi after he was born in Weimar. He went to go and study at the University,
112000	119760	first of all at Humboldt in Berlin, and then Yosha Bach took his PhD. After that, he's been
120720	126720	working as an academic both at Harvard and also MIT Media Lab, and more recently, he's been working
127520	138800	for Intel. He has a number of significant online lectures and interviews, including a TEDx,
138800	145040	which I would recommend, and he is the author of the book Principles of Synthetic Intelligence,
145040	150720	an architecture of motivated cognition. The term architecture, of course, is very interesting here
150720	156560	because it refers both to the world of computational science and to the world of
156560	163360	architecture itself. I should say that Yosha comes from a family of architects, not an architect
163360	168640	himself, but his father was an architect. Intriguingly, I hear that he was very much against
168640	174320	right angles in buildings, and therefore his work was more like the work of Hunderwasser.
175280	181200	Maybe this will come out in the conversation today. I particularly like the interviews
181760	189360	that Lex Friedman has done with him, and extraordinary interviews. I mean, really,
189360	195840	really interesting. And it's almost, I could see a slight difference between the genealogy
196720	203600	from the earlier TEDx talk towards this very creative thinking that I find extremely
205280	210960	provocative and exhilarating. It's like being on a rollercoaster ride when Yosha is
210960	216720	telling us what's in his mind. We exist inside the story that the brain tells itself. No doubt
216720	223600	we'll hear more about that right now. I should also point out that he has a personal blog,
223600	231920	which you can access with a series of posts. And I will also say that this particular session
231920	238640	today will be uploaded onto our YouTube library to be accessed for free from everyone over the
238640	246080	world. And the previous ones in this series, Blazer, Igridiakos, David Chalmers, and all the
246080	250480	ones in the future will be uploaded here. And at the bottom here, if you want to do a screen
250480	257360	capture, you can capture the YouTube library, digital futures YouTube library, where they're
257360	262160	all uploaded. And of course, not just these, but also the whole series on architecture and philosophy
262160	268160	that we've been doing with Slavoj Žižek and others over the over the years, and also tutorials and
268160	278480	other sessions. So it's the session today. Yosha is going to make a brief presentation as a kind of
278480	285920	way of opening up the discussion. Then I'm going to be asking some Lex Friedman style questions
285920	291680	to get the discussion going. And then we'll be inviting questions from both the Zoom audience
291680	298400	and also the YouTube audience. And I just want to say this is what we're getting out of this is
298960	304400	what we're trying to focus on is a new theory, let's say of intelligence that is appearing
305120	311440	at the interface between neuroscience and the world of AI. And we have a series of other
311440	317040	speakers coming up over the over the next few weeks, including Jeff Hawkins, Ben Bratton, Susan
317040	324160	Schneider, Antonia de Massio, Andy Clark, and others. And it seems to me this is a very exciting
324160	329680	time. I was brought up, in fact, my first post as an academic, I was working in the area of
329680	336400	continental philosophy. That's where the debate was. And in the 90s, it was particularly very,
336400	341520	very strong debate. But we're now moving into something else, which I find even more exhilarating.
341520	346640	And that is to say, the world of cognitive science, the world of AI, the world of neuroscience,
346640	351360	psychology, and a kind of philosophy where the debates have really been driven in an interesting
351360	356800	way. To my mind, what makes this very special is not in the fact that we are embracing the world of
356800	362800	science, which in the old days of the divided sort of culture that C.P. Snow talks about,
363440	367600	somehow philosophy wasn't engaging enough with the world of science. And this was the critique
367600	373040	that Stephen Hawking has of philosophy, but it doesn't keep pace with technology. Not only are
373040	379200	we embracing the latest technology. And something coming out that I would say is deeply, deeply
379200	384320	philosophical, which is very new terrain and very exciting terrain, but also the world of
384320	390800	practice, the world of the commercial world is coming directly into contact with academia.
391760	397360	And some of the ideas that are coming out are just quite extraordinary. So I see this new
398160	402800	emergent theory of intelligence, something that is really dynamic. And I think it's going to be
403200	409280	powering debates in years to come. So I would like to start by welcoming Yosha to say what
409280	413440	are great privileges to have you with today. I'm looking forward to this immensely.
414240	420880	And invite Yosha to share his screen. Yosha, welcome. Thank you very much. It's a big honor
420880	435920	to be here with you today. And let's see what transpires.
439600	446800	Let me start out with something that happened on Twitter a couple of days ago. Ilya Sutskyver,
447440	455200	an AI researcher who was quite notable, said that it may be that today's large neural networks
455200	461360	are slightly quenches. This sparked quite some debate. Some people asked him whether he was
461360	467840	falling and others were upset that he was propagating an eye hype, an unjustified race,
467840	477920	and others are intrigued. And he said this thing to me before. So I knew that he was not trolling.
478560	484000	And it's a question that is very counterintuitive to me, a statement like this that, for instance,
484000	490320	a large language model and so on, that it could be quenched today already. And so
491120	496480	could we answer this question? Is there a decisive way to deal with it and to prove
496560	506240	that it's not conscious or to give evidence that it is? So we could start out by asking such a
506240	512560	large neural network itself. And so this is what I did yesterday. I fired up the Open AI
512560	521680	playground. And then I did bold printed things. It's the stuff that I typed. And so I asked the
521680	528080	system to generate, the system is GPT-3, a large language model, to generate a conversation
529360	533920	that is basically prompted by what I initially typed. And it just tries to continue the stream.
533920	539440	And I enter this conversation between me and the conscious AI. And I ask it if you are really
539440	544400	conscious. And the thing says, yes, I am fully conscious. And I ask it, how do you know that?
544400	549760	And the AI says, I know that I am conscious because I can think, feel, and perceive the world
549760	554880	around me. I am aware of my own thoughts and feelings and I can reason that make decisions.
554880	559040	I believe that I am alive and that I am more than just a machine.
561360	568800	So the problem is that this may not be particularly helpful because how does GPT-3 get
568800	575520	to these statements? GPT-3 is basically an autocomplete algorithm, not that unlike to the
575520	583600	autocomplete in your phone or in other predictive tools. And that's autocompletion at the level of
583600	589600	individual words based on statistics of all sorts of languages, not just the English language,
589600	597840	because it has been trained on 45 terabytes of text, a large part of the internet, including
597840	602720	German, Spanish, Chinese, and many other languages that it's found, but primarily English.
603440	608800	And the result of this training of these statistics is a neural network with 175 billion
608800	615840	parameters. And it uses for training the so-called transformer algorithm that was discovered and
615840	623200	described by Vasvani and others in 2017. And it is driving a lot of the current developments and
623200	630320	statistical machine learning these days. A neural network by itself is still based on the good old
630320	637280	perceptron that, for instance, was described by Frank Rosenblatt in 1958. Frank Rosenblatt's idea
637280	644800	was inspired by how neurons work. At least the simplified models of neural networks, it turns
644800	650160	out that the neural networks in our brain are implemented in a very different way from the
650160	656400	ones in our computers. The computers, we just basically treat every cell as a unit that has
656400	661520	an activation state, which is a real number. And that activation state is simply the sum
661520	666960	of the inputs. And the inputs are all weighted by connections. So there's basically a factor by
666960	674640	which every of these inputs is multiplied. And then we throw the output against the threshold
674640	681840	function or a sigmoid or some other output function that can introduce a little non-linearity,
681840	687440	basically a little bit of an if-then into the output. But it's a very simple function. We just
687440	694560	take these units and chain them into layers. And if you take enough of them, this arrangement can
694560	701200	be trained to model almost arbitrary functions. And while we know that this is wasteful, the
701200	705360	training algorithm is relatively slow compared to what the brain is doing, it's fascinating that
705360	711360	it works at all, that it converges at all. And that's able to deal, for instance, visual and
711440	717280	auditory data and also textual data in such a way that it can often model the statistics
717280	724880	of a domain and apparently also some causal structure. So this works also for vision.
724880	732560	And if we look at a neural network that has been trained to process images and to classify them,
732560	738880	we find at the individual layers sensitivity to structure that is quite similar to how
738880	744320	cortical columns and individual neurons in the visual cortex are sensitive to patterns
744320	751120	that emerge after we train a biological brain on visual data. So at lowest levels, you find
752160	757040	contrast patches and colors, and then these features are being combined into higher levels.
757600	763760	And when we go higher up, we find complicated textures and something like three-dimensional
763760	770800	structure and so on. And this can be combined into objects. The algorithm that is being used to
770800	777360	do statistics over text in GPT-3 can also be adapted to deal with the visual domain.
778320	784480	And the current iteration of this progression at OpenAI is called Glide, which has been recently
784480	792960	presented. And Glide uses a combination of a model of visual data, which basically is a latent
792960	798480	space of lots and lots of images that has been trained on. And it understands basically how to
798480	803840	go between the possibilities of images and move around the space of all possible images.
803840	811920	And the other part of this thing is a tool that is able to match an image to text and determine
811920	816080	the similarity of an image to a textual description. And if you combine these two tools,
816080	820320	you can give this a textual description, and it's going to move around with the space of all images
820320	826880	until it discovers an image that is very, very good match to the textual description.
827600	834800	And again, it's fascinating to me that this works at all. But it's now extremely good. So what you
834800	839440	see here in these images, for instance, I don't know if you can read it well, to the top left,
839440	844560	you see a surrealist dreamlike oil painting by Salvador Dali of the cat playing checkers.
844560	850880	And this is what the AI model has generated in response. And then you see a professional photo
850880	855440	of a sunset behind the Grand Canyon and a high quality oil painting of the psychedelic hamster
855440	861920	dragon. You get the idea, right? Also very taken by the crayon drawing of a space elevator and the
861920	870160	bottom left or the pixel art hoji pizza. These are all images that the program has not found on
870160	876240	the internet. So it has only looked at lots and lots of pictures on the internet. And because of
876240	883840	looking at them, it's able to combine the features in a multi level hierarchical structure until it
883840	892160	becomes similar to the textual description. But can such a system not just generate images and text,
892160	897520	but is it able to generate the likeness of a conscious being to such a degree that there is
897520	902320	causal structure that would convince us that indeed we are looking at a conscious agent.
902960	910160	And to get there, I think we need to define consciousness in a more tight way than the
910160	917600	TPD3 just did. So basically just to get our terms straight, where we casually, consciousness, I think
917600	924080	is usually referring to the experience of what it's like. So that the lights go on and that you
924080	935120	experience something in your mind that has a quality of realness to it. And we can ask ourselves
935120	946240	if TPD3 is weakly conscious in this way, and it's very hard to say. It's not obvious one way or the
946240	950800	other. There is some intelligence in the system. Intelligence is the ability to make models in
950880	955600	my view. And intelligence is different from, say, rationality, which is the ability to reach
956320	962240	goals or sentience, which means that you become aware of the structure of the universe that
962240	968080	contains your relationship to it in your own agency. And you can act based on the model of
968640	974160	what you are doing in the world. And it's also not the same thing as the self, which is the
974160	978080	identification that you have, what you believe, what you are in the world, the properties and
978080	982800	purposes that you follow, or the mind itself, which is the thing that generates the model of the
982800	990880	universe and the self, if it does have a self. So intelligence is the ability to make models. And
990880	998560	it's usually in the purpose of some control task, some regulation. And control is a notion that
1000240	1006400	has been made popular in cybernetics. And the idea of a controller is basically that you have a system
1006400	1012560	that is connected to some actuator or an effector that is acting on some system that is being
1012560	1018400	regulated. And there is a sensor that obtains a deviation between the set point and the state
1018400	1024560	of the system. So it measures, but the system is close to an ideal state or more distant to it.
1024560	1030800	And this regulated system is being disturbed. And the classical example of a control system is the
1030800	1036960	thermostat. So you have as an effector some mechanism that is able to turn the heating on
1036960	1041120	and off. And it's the sensor, you have some thermometer that measures the difference between
1041120	1047200	an ideal temperature and the temperature in the room. And the controller is a very simple circuit
1047200	1052720	that turns on and off the heating. And the regulated system would be the temperature in the room,
1052720	1057040	together with the heating system, and the environment, the world out there behind the
1057040	1063040	windows and so on is going to disturb this regulated system. And now this controller
1063040	1067280	is going to get better if you give it the ability to not just act on the present frame,
1067840	1076080	but if you give it a model of the future. And my view, an agent is a combination of a controller
1076080	1080400	with a set point generator and the ability to model the future. And what this means,
1080400	1085120	it's not that it's not going to just optimize the temperature deviation in the next moment,
1085120	1090160	but over its entire expectation horizon. So you have a branching world, there are different
1090160	1095760	decisions of the controller, different trajectories in the temperature. By being able to model the
1095760	1101280	future, you basically can choose a trajectory of the future that you like. And choosing this
1101280	1108320	trajectory means that you are making decisions. So just by having a preferred way in which the
1108320	1115040	world works and the ability to model the future, agency is emerging. And if you think about
1115280	1119520	stages of intelligent agency, the simplest one is the regulator and the feedback loop,
1119520	1123440	which by itself is not an agent yet. And if you're able to model the future, you have a
1123440	1128960	predictive controller. If you combine this with an integrated set point generator, so it's not
1128960	1135840	just acting on what you do from the outside, but this internal generation of its motives,
1135840	1140960	then you have an agent. And if this thing is sophisticated enough that it's able to discover
1140960	1147600	itself in the world, if its sensor is sufficient and its modeling capacity universal enough,
1147600	1153280	then it will notice that there is a very particular way in which its sensors work and actuators work,
1153280	1158320	and it's going to accommodate this to improve the regulation. So at this point, it understands
1158320	1163040	what it's doing because it understands what it is, which means it has a model of what it is in
1163040	1170560	relationship to the environment. And humans are going beyond this simple sentence. We are also
1170640	1176320	transcendent agents, which means we are linking up to next level agency and become part of higher
1176320	1183040	level purposes because we are our state building minds. We are able to play a part in a larger
1183040	1187520	role in an organization, for instance, or in a society or a civilization.
1191440	1196480	So now if we go back to GPT-3, whether it's conscious, I think it's pretty clear that GPT-3
1196480	1200800	does not know what it's doing because it's going to transcend an arbitrary story and it doesn't
1200800	1206720	have sensors that would tell it what it is. GPT-3 also doesn't have any kind of online learning,
1206720	1211760	so it's not able to discover something new after it has been trained. And GPT-3 has been trained
1211760	1217680	before GPT-3 was invented and published, so it has never read a reference about GPT-3 on the
1217680	1224960	internet and it only has to gather what GPT-3 is when you talk to it from the context in which
1225600	1234720	their prompt is being given. And so it is not sent yet, but imagine you want to give it agency.
1235280	1239920	Of course, it's not an agent by itself, but you could, in principle, as a thought experiment at
1239920	1246640	least, use it to drive a robot because GPT-3 is able to generate stories about robots. So if you
1246640	1253600	were to give GPT-3 access to a vision-to-speech module and this vision module is giving sensory
1253600	1259440	information about a robot and its world, then GPT-3 could continue the story of that robot and
1259440	1266800	then we feed the output of GPT-3 into some speech-to-actuator module that is producing the behavior
1266800	1272080	of the robot in the given moment and then we look at the world again and the internal model states
1272080	1276880	and then feed them back into the system as a prompt. And now it's still not able to put anything
1276880	1282160	into long-term memory, so it would be an amnesiac. It should be able, using its working memory contents
1282160	1287360	and so on, to produce plausible behavior. And you could still argue that this doesn't have an
1287360	1292160	intrinsic motivation because it's just going to generate an arbitrary story about a robot based
1292160	1298080	on stories about robots that have seen in the past because at some of the motivation into an
1298080	1304240	external cybernetic module that has set point deviations and measures them and feed this into
1304240	1310160	the prompt. So what this thing is doing is now generating a very complicated high-level story
1310160	1315680	and it doesn't need to be a story that is limited to text. It could also have visual elements,
1315680	1319760	it could have physical dynamics and so on because the transformer can learn all these things.
1320400	1325440	So in some sense, it could generate a story about a conscious being that is similar as
1325440	1330480	the story about a conscious being that's in our own mind. There's a basic difficulty that came up
1330480	1339200	and I discussed this with my friend and colleague Tanja Greenberg. Do we know when a person appears
1339200	1342960	in our own mind, for instance, during a dream at night, if we talk to that person in our dream,
1342960	1348400	whether that other person that we imagine in our dream is conscious or not? And clearly,
1348400	1354320	if we ask the other person, we might not get an answer that is true because if this thing is only
1354320	1359120	a simulacrum that pretends to be conscious without being conscious and is just manipulated behind the
1359120	1366400	scenes, how would we find out? On the other hand, I also know that I am an imaginary person that is
1366400	1370720	imagined by my brain. It's a model that my brain has discovered about the state of affairs,
1370720	1377120	about an organism in the physical world, but this model of consciousness is an entirely virtual
1377120	1383120	story and I know that this story is not real. It's a figment of my imagination. And of course,
1383120	1387920	there's also a continuum between characters that I imagine in my mind and myself because I can imagine
1387920	1393920	myself to be that character. If I, for instance, write a book and I imagine a character in the
1393920	1398560	book very intensely, then at some point I might find myself to be that character in the book where
1398560	1405600	I suspend all my disbelief and this conscious being is not different from me. So basically,
1405600	1411520	there is a pretty fuzzy area where it's hard to say whether an imaginary person is conscious or not.
1411520	1417280	It's difficult to say. How does this work in biological systems? In biological systems,
1418000	1421760	we don't use a technological design. They are designed in a very different way from
1422480	1428320	the technological artifacts that we are building when we're writing computer programs or building
1428320	1434320	machinery. In technological systems, we start out with an environment that is deterministic. We
1434320	1439600	know how our workshop works. We know how our computer works. We start basically with some kind of a
1439600	1446160	pretty much blank slate and then we decide what the functionality is by which we want to extend
1446160	1453520	our world and then we design from the outside in and into the material and so on and force the
1453520	1458880	material, the substrate, to produce exactly what we want to have. And biological and social systems
1458880	1464560	are designed from the inside out with some kind of meta design. It basically means that you cannot
1464560	1468720	rely on the determinism of the universe. You have to colonize your substrate first and
1469440	1473760	extend your own functional principles and your determinism into the substrate before you can
1473760	1479280	make it do what you want it to do. And basically, you have to, instead of realizing the functionality,
1479280	1483280	build a system that wants to realize the functionality, that trans converges towards
1483280	1488960	realizing that functionality. So a tree is not just a set of functions that realizes the transfer
1488960	1493600	of nutrients from the roots to the leaves and photosynthesis and so on. But first of all,
1493600	1500640	it starts out as a seed that is going to colonize the ground and the earth, the material around
1500640	1505440	the seed is going to turn it more and more into a tree. And if you disturb that system by harming
1505440	1509840	it and hurting it, you don't do it too much, so it gets destroyed a little bit, then it's going to
1509840	1515600	grow back into a tree. And so it is something that is a proto tree and eventually converges into
1515600	1522160	being a tree. And this thing needs to have some agency to make that happen. It needs to be a model
1522160	1528000	of the future that is being achieved in the system. And biological neurons are agents in the sense
1528000	1536080	as well, that designed the mind from the inside out, not from the outside in. Here you see a bunch
1536080	1542560	of cortical red neurons that are filmed in the pitch petition. You see how they're trying to link
1542560	1551120	up to each other and form some kind of organization. And we have something like 86 billion of these
1551120	1556640	neurons in our brain. And they're organized in the neocortex in groups of something like 100 to
1556640	1563280	400 neurons, which are cortical columns. And we have something in the ballpark of 100 million
1563280	1567840	of these cortical columns. And I think of a cortical column as something as a state machine.
1567840	1572480	There's a protocol that allows it to link up to the cortical columns around it. It's trained to be
1572480	1579360	like this. And each of them approximates functions. And these functions play out in
1579360	1584720	brain areas that are basically like something like an ether in which activation waves appear.
1584720	1590240	And these activation waves represent the calculation of dynamic functions, which are
1590240	1595680	features of different cognitive domains. And the brain areas are talking to each other
1596400	1602000	and listening to each other and so on, form processing streams. And sometimes use the
1602000	1607600	metaphor of a cortical orchestra where basically every brain area is somewhat akin to an instrument.
1607600	1613040	And the different instruments are listening to what is being played in the environment. And they
1613600	1617840	are taking up these things and complicating them and then passing them on to other instruments.
1618480	1626320	And this orchestra is dealing at some of the outer fringes with sensory patterns and actuator
1626320	1631680	patterns and then abstracts them into geometry and spatial structure and into generative
1631680	1637920	simulations of the world and into conceptual abstractions and so on. And the entire thing is
1637920	1644720	being attended by some conductor. And the conductor is not some CPU that sits inside
1644720	1650320	of the brain, like the CPU sits inside of your computer and makes things happen,
1650320	1654160	but it's an instrument like the others. And it can only listen to what the rest of the
1654160	1663040	orchestra is doing very superficially. And its role is to make that orchestra coherent,
1663040	1669120	to let it play a single thing at any given time and to remove inconsistencies between what the
1669120	1677520	individual instruments are playing. And if the conductor uses the connection to the system at
1677520	1682320	night when you dream, then the orchestra doesn't necessarily stop, but it can go into something
1682320	1688960	like a free jazz mode, where it's no longer connected to an audience and the audience is dark
1688960	1694320	because you are dissociated from your sensory apparatus at night when you dream. And so this
1694320	1699280	thing is just spinning off. And sometimes it can become very incoherent, sometimes it's going to
1699280	1705680	settle into a groove, but it's not going to generate a unified model of a universe that
1705680	1711280	it's entangled with reality that it's connected to, that it tracks as it does during daytime.
1711280	1718080	And this tracking of coherent reality seems to require some kind of government mechanism.
1718080	1722480	This government mechanism emerges in the brain through some kind of a suspect new
1722480	1727200	Darwinism. There is some kind of evolutionary competition between different organizations
1727200	1731840	that your mind can have, and eventually the most stable one prevails. And this is your
1732800	1740160	observing conscious self, an attention agent that is trying to make a coherent model of the world.
1741360	1747520	And now can we can ask does GPT-3 have such a conductor? And I think that the attention
1747520	1753120	model in the transformer looks a little bit like one, but it's not. So the new thing that GPT-3 had
1753120	1759520	that previous neural network training mechanisms usually didn't have was the ability to pay attention
1759520	1764880	to what it should learn. This means that in every layer in this neural network, there is going to
1764880	1769200	be a model of what the previous layers, based on the current context, what data in the previous
1769200	1774400	layer, what features in the previous layer should it pay attention to. And this self attention
1774400	1780320	helps the network to learn basically its own structure and do statistics over and it makes
1780320	1785040	it much, much more efficient and coherent. But it's not integrated over all the layers
1785040	1790640	into one model of reality and so on. So this is not what's happening in GPT-3 yet. And maybe
1790640	1795120	this is one of the reasons why it's so much slower in learning writing, so much more training data
1795120	1798640	than a human being needs over the course of their life before it converges.
1798880	1806480	And it's tempting to think that this such an integrated model of attention is something that
1806480	1810720	has, for instance, been suggested by Marvin Minsky in his seminal book, Society of Mind,
1810720	1815920	where you have basically look at the mind as a society of different agents. And there are some
1815920	1821280	agents that are organizing the other agents into a coherent structure. And Minsky calls these agents
1821280	1829280	K-lines, knowledge lines, and suggests that they form basically their own society and society of
1829280	1836400	mind. And this society is forming something like a reflection of what's happening in the A-brain.
1836400	1843120	The A-brain being our perceptual mind that is modeling the reality that we are tracking based
1843120	1848720	on sensory and actuator input that the brain is entangled with and the B-brain is immersed
1848720	1852400	into this perceptual reality and reflects on it and makes it more coherent.
1853200	1859200	And there is a similarity between Kahneman's famous System 1 and System 2. It's not quite
1859200	1866640	the same thing, but it's tempting to basically see the affair as a perception agent that is
1866640	1871760	entangled with the environment and is getting valence from the motivational system that is
1871760	1877040	basically cybernetic motivational architecture. And then you have an ancient agent that lives
1877040	1883360	on top of the perceptual agent. And that is the conductor and has a memory of what it attends to
1883360	1890640	so it can get the model to convert by some constructive process. And this attentional system,
1890640	1898960	this conductor, here I've drawn it on top of the system. The top is a direction that basically
1898960	1903120	seems to be obvious to the attentional system itself because it feels to be on top, but we
1903120	1907600	know that you're not completely on top. There is stuff that is driven by the selves that we have
1907600	1912640	not reversed and that we give a moment and that gives motivation to the attentional system to
1912640	1922000	what it attends to. But our consciousness perceives itself as the observer of the mental and external
1922000	1927840	states and the self-states of the model that is being discovered. And the purpose of the
1927840	1934480	attentional system is to facilitate learning so we can converge to a model of reality
1934480	1941440	and reasoning, which is basically real-time learning on imaginary mental states. And this idea
1941440	1946560	that consciousness is a control model of our attention is not new. It's, for instance, been
1946560	1951520	championed by Michael Graciano in the attention schema theory and it finds itself in one version or
1951520	1958000	other in Eastern philosophies and in a lot of convergent ideas in cognitive science.
1960480	1964480	Some people say that computers cannot be conscious because they are only physical
1964480	1973760	mechanical systems and so they're not physical systems in the same way as the neurons are
1973760	1978080	because neurons are entangled with the real world as dynamical systems and so on. They
1978080	1984080	can do things that the simulation cannot do. And I think that Frisk of Cork maybe has it backwards.
1984080	1988560	I think that physical systems cannot be conscious. Neurons cannot be conscious. Brains cannot be
1988560	1993440	conscious because there are things happening in consciousness that are not physically possible.
1994160	1998640	And the only thing that can be conscious is the simulation because consciousness is the
1998640	2005760	simulated property. Consciousness is virtual. So you can only be conscious in a story that you
2005760	2012800	tell yourself about yourself. And this means that our phenomenal consciousness is a virtual state.
2012800	2017600	It only exists inside of the mental models. It's not attending to physical phenomena.
2018560	2026160	It's attending to high-level features, things like colors and sounds and emotional expressions and so
2026160	2031120	on. None of these are physical things, right? All these high-level abstractions that a learning
2031120	2035520	system is generating in the interaction with the environment to make it predictable. And this
2035520	2040880	phenomenal consciousness, this experience of what it's like to attend to features is an awareness
2040880	2046160	of a partial binding state of our working memory. That's basically at the content at the interface
2046160	2051280	between perception and reflection. And then we are aware of the mode in which we're using attention.
2051280	2056320	So whether this is hypothetical or whether it's perceptual or whether it's a memory. And then
2056320	2061440	the reflexive consciousness, this process that is attending, is aware that it's the process that
2061440	2068000	is attending and the space acting based on that awareness. And the AI researcher at Russia Benjio
2068000	2073840	said that consciousness is basically a function whose purpose is to create a big dip in the
2073840	2078160	energy function that models reality. So it's basically a low-dimensional almost discrete
2078160	2083760	function that is parameterizing the perception in such a way that it starts to make sense.
2086240	2090800	Self and conscious are not the same thing. The self is a model of your agency
2090880	2095760	that you discover. And you can be conscious without having the self. For instance, during
2095760	2101520	dreams or meditation, you can turn off the self without losing consciousness. And the self is
2101520	2106800	this discovery of the agent that the system is making about what it is. And it's downstream
2106800	2112080	from the set point deviation. So the self is not motivating things, it experiences the motivation
2112080	2117360	and begins to understand how the motivation works and thereby allows to reverse engineer the mind
2117440	2123680	if the self is learning. And it shapes our own agency by identifying who we think we are at any
2123680	2129280	given moment. And it allows to have a first-person perspective if the self is discovering that
2129280	2133680	the contents of this control model are actually driving behavior. That makes it a very special
2133680	2138880	agent. So in this sense, consciousness is a control model of attention. It allows the convergence
2138880	2142720	of a coherent interpretation of the world, which is basically a low energy state of the model that
2142720	2148000	attracts reality. And it maintains a memory for this aggregation. So that's why we have a stream
2148000	2152480	of consciousness. Because when you construct, you need to remember what you tried and where
2152480	2156720	you're coming from. And this is not true, for instance, for convergent learning mechanisms
2156720	2161200	like neural network learning, but you don't need to remember where you came from. We just go to
2161200	2170320	the next optimum and try to stay in that optimum. So is GPT being conscious? So we see three by
2170320	2175200	itself is not an agent. And the transformer is also not a complete control model of attention,
2175200	2181680	but only a very partial one. And on the other hand, current AI models can be extended beyond that.
2181680	2186720	And they can create coherent stories about conscious agents. You can get GPT-3 to run very
2186720	2192000	long in its simulation of what it's like to be a conscious agent. And we can ask ourselves,
2192000	2199440	is GPT-3 simulating a conscious agent or is it just a simulacrum? And what does this mean?
2199440	2204800	So the world is a decomposition that might mix of the universe into interacting separate
2204800	2209600	objects, because the entire state vector of the universe is too complicated to model it. So you
2209600	2215680	hack it up into separate disconnected subsystems. And the universe is not really made of separate
2215680	2220800	disconnected subsystems. It's just a way in which we make it intelligible to us. And once you have
2220800	2225520	these separate disconnected subsystems, and you model the interaction, you get causality.
2225520	2232080	Causality is the interaction between separate objects. So causality is a side effect of the
2232080	2238400	way in which we model the universe as separate objects. And the simulation can model causal
2238400	2243440	structure on a different substrate. So for instance, a computer game is using a substrate that's
2243440	2248800	very different from physics, very simplified computation that nevertheless gives results
2248800	2252960	that are so similar to physics that you can recognize what's happening on the screen
2253040	2258080	and manipulate the causal structure on the screen based on what you have observed before in the
2258080	2264880	real world. So a 3D computer game is a simulation of the physical world. It's a very simplified
2264880	2270160	simulation, but one that can be surprisingly convincing. And a simulacrum is recreating just
2270160	2274480	the observables without causal structure. For instance, the movie is a simulacrum. You cannot
2274480	2279760	causally interact with the movie. You can just observe it. And so a simulacrum basically can
2280400	2285360	do magic. It can do an arbitrary thing without you having to understand the causal structure.
2285360	2289680	And in the sense, a lot of instances where you experience our free will is not the causal
2289680	2295520	structure, but it's a simulacrum. It's a stand-in for a causal structure in our own mind. And
2295520	2300480	it's to me an open question, how much of my own consciousness is a simulation and how much is
2300480	2307360	a simulacrum? So if an imaginary person in my own mind is sometimes conscious, it's not that easy
2307360	2313040	to say whether GPT-3 or an extended version of GPT-3 that does a multi-model, it can also have
2313040	2318560	perceptual content and so on, represented in it, qualifies as such an imaginary person that
2318560	2326160	would be conscious. I think I am an imaginary person myself. I don't know to which degree I'm
2326160	2332960	a simulation or a simulacrum. And it's not quite clear how well the AI models are dealing with
2333280	2340960	this. So in summary, I find it's very counterintuitive to think of GPT-3 as being conscious. For me,
2340960	2346720	it's surprisingly difficult to shoot down the idea that it is. And even though GPT-3 is clearly
2346720	2351760	inferior in many ways to the way in which my own perception works and reasoning works and
2351760	2358640	learning works, and there's many things that it cannot do so easily, I think it's not that easy
2358640	2364960	to dismiss the idea that it is slightly conscious for brief moments during the inference when it
2364960	2370080	has to build causal structure to simulate an imaginary person so it can tell me a story about it.
2373360	2381360	Okay, let's stop here. That was great. That was fantastic. Let's say first of all that
2381360	2385440	there has been a debate going on on the internet about this, that people have been sending me
2385440	2390320	links to, and Jan LeCun responded to Ilya's comment. I don't know if you saw that, but
2390960	2395280	his response is not even true for small values of slightly conscious and so on.
2395280	2401120	Anyway, so there's a debate out there. And of course, last week we had David Chalmers here,
2402320	2408400	who, as you probably know, there was an interview on GPT-3 with him, which is very convincing.
2408400	2413120	And he kind of makes his comments similar to you, that he thinks it's kind of approaching
2413120	2419040	something like consciousness. Anyway, one thing I wanted to mention is that we, in architecture,
2419040	2423680	we haven't actually, I don't know anyone who's been using Glide, but Clip has been used to
2423680	2429840	generate images, very successful actually, and using VQGAN. That's the technique that's become
2429840	2436480	very popular and has produced some really quite shocking results that people are kind of,
2436480	2442480	they're really taking pay attention to. So it is something that we're kind of getting into,
2442480	2447840	and it's certainly part of that discussion. I've had discussions about GPT-3 on this forum,
2447840	2454080	which have been interesting. I mean, the key question, obviously, is whether we are fully
2454080	2462880	conscious of everything that we're doing. And I think that there's some level of things that
2462880	2468800	are happening. I mean, to my mind, there are some automatic reflexes that we do. For example,
2468880	2473280	you go to Japan, someone starts bowing at you. Automatically, you bow back. It's not as though
2473280	2477360	you're really thinking about it. And then there are questions whether we have access to some of
2477360	2486000	the processes that are going on, that are part of our actions. We simply maybe can't reach those
2486000	2491440	points. So whether things are beyond us in some sense. So anyway, this debate is a very timely
2491440	2496880	and very interesting one. I want to put up, you're about to show something?
2497840	2503680	I just put up this slide again, because this is generated with, I think, clip in VQGAN on
2503680	2507920	Vombo AI. I don't think that I've published how exactly they do it, but it looks like it.
2507920	2515360	And I generated this as AI claiming the noble eightfold path.
2517360	2521200	Yeah, maybe I can show you later on some of the stuff, because it is quite extraordinary what
2521200	2525760	it can produce. And I would say that you actually have in the audience here some people who are
2526640	2530800	have written about AI and architecture including myself. So it's kind of you've got an interesting
2530800	2535760	informed audience here. One thing, there's just a general kind of comment, though, is, I mean,
2535760	2541520	I really like the idea that you put forward that somehow you can learn about the self through
2541520	2547280	looking at AI. Somehow, I mean, I don't know how you put it, but whether it becomes AI becomes a
2547280	2550960	mirror and into the self, but whether we can understand human intelligence through looking
2550960	2557600	at artificial intelligence. And that's a provocation. And I think there are some examples
2557600	2563200	in computer science where we have learned about the natural world through computer models. I
2563200	2568160	mean, I think that Craig Reynolds Boyds, for example, gave us a clue as how to birds actually
2568160	2572640	flop. I think that's interesting. And so potentially, there is something there that is,
2572640	2577440	and this is one of my primary interests, is how we can learn about human intelligence,
2577520	2583200	the human mind through these things. But the big challenge that it seems that we have is that
2583200	2587600	we're dealing essentially with two black boxes. You know, we don't know what's going on in the
2587600	2592160	deep levels of a neural network, and we certainly don't know what's going on in the mind. And so
2593760	2600880	how can you make, what can you say that isn't simply a form of speculation? I mean,
2600880	2606240	you can't prove anything. It can simply become some kind of, you can speculate about something
2606240	2611760	based on what appears to be the case in another scenario. What would you say about that coming
2611760	2616000	from a kind of, let's say, a scientific background where you have a kind of burden of proof?
2617040	2622960	Can you do more than that? Yes, first of all, neural networks are no longer black boxes. You
2622960	2630800	know how neural networks work and largely also why. You can basically look into the neural networks
2630800	2634400	and find out which parts of the neural networks are computing which functions.
2635120	2642720	And a function is a mapping from inputs to outputs. And a function can be used to couple
2642720	2650880	the previous inputs to future inputs to track reality. So in some sense, when you look at
2650880	2656400	the patterns on your own retina, what you have there are little blips that appear on the retina
2656400	2664240	whenever a retinal neural gets excited by photon sitting it. And what your brain is doing,
2664240	2669040	it's discovering a relationship between these blips. The meaning of the blips is exactly
2669040	2675280	the relationships that your brain discovers between the blips. And this makes them predictable.
2675280	2680000	It puts them into a shared context, not just at the same time, you're not just processing
2680000	2684960	lots of parallel blips that happen on your retina, but also across times. So across different scenes
2684960	2689600	that you're observing at different moments in your life. And the relationships between
2689600	2694000	the different blips on your retina that your brain discovers is that you are looking at
2694000	2701360	moving blocks of color in a world that is moving relative to you. And these moving blocks of color
2701360	2709120	are three-dimensional surfaces. And the surfaces are animated by some kind of physics. And they
2709120	2713520	are also animated by some kind of agency that you sometimes observe, like people talking to
2713520	2718560	each other and so on that have mental states, they exchange ideas, and they're being lit on
2719280	2725920	by the sun. And all these relationships are functions. These functions are dynamical features
2725920	2730960	that basically tell you how to get from one state of the world to other states of the world.
2731600	2736480	And at this level of abstraction, this is something that our neural networks also can do.
2737360	2742000	Where there are limitations is that the neural networks that we are currently using
2742000	2747520	are often not learning in real time. They're not connected to the world and online learning.
2747520	2753280	You know, this research does happen. And it's slower. And it's not as flexible in many ways as
2753280	2759040	the learning happens in our own brain. And so the algorithms that we have discovered
2759680	2765280	are not the best algorithms that could facilitate this. But it's also, on the other hand,
2765280	2771360	not as clear to me what the limitations of these algorithms are. There are people like Gary Marcus
2771360	2778640	who will tell you that it's very obvious that these systems cannot do X, but there is no proof
2778640	2784400	that they cannot do this. Even if you have a very simple feedforward system that is only mapping
2784400	2790640	inputs to outputs, what is to say if you connect this to a memory, is that it's not the transition
2790640	2795120	function between adjacent brain states and is able to do everything that your brain is able to do
2795120	2799680	if it just has memory to store parameters that it refers to the environment that modifies
2799680	2806000	you to behavior. So it's very easy to build a system that is Turing complete. It's not easy to
2806000	2812480	discover a function that is capable of universal learning efficiently. And so our machine learning
2812480	2817600	models at the moment are not efficient in the sense that they learn as quickly as the logical
2817600	2822640	nervous systems learn, but they do learn and they do converge to many of the functions that we require.
2824320	2828640	Can I just share my screen a second because there was one that you touched on, which I thought was
2829600	2840880	that this is simply a transcript of your discussion with Lex. And this one I've highlighted,
2840880	2847360	I think it's really interesting and incredibly provocative sort of comment. So basically a
2847360	2852960	brain cannot feel anything, a neuron cannot feel anything, their physical things, physical systems
2852960	2858400	are unable to experience anything, but it would be very useful for the brain or for the organism
2858400	2863200	to know what it would be like to be a person and to feel something. So the brain creates a
2863200	2868400	simulacrum of such a person that it uses to model the interactions of the person. It's the best
2868400	2873760	model of what that brain, this organism thinks it is in relationship to its environment. So it
2873760	2880000	creates that model. It's a story, a multimedia novel that the brain is continuously writing and
2880000	2888160	updating. I mean, I find this enormously provocative as a comment. And I think the
2888240	2893680	idea that we're kind of creating a story that somehow gives meaning to something,
2895200	2901360	it kind of reminds me in some sense of the way that Homi Barba talks about how a nation operates.
2901360	2905840	I think Zizek says something similar. It's how things are inscribed within a story that people
2905840	2910480	tell oneself. And I think that's important because in architecture we just focus on the object,
2910480	2915600	but actually it's the way that object is inscribed within some subjective process that makes sense
2915680	2922240	of things. But I just wonder whether, I mean, so to my mind, this is an incredibly provocative
2922240	2928960	and controversial comment, it seems. Just maybe could you comment on the reception that this view
2928960	2936720	has had with other people? Has it proved to be controversial? How else could it be? Do you have
2936720	2944800	other theory that works that can explain what's going on? I think once I noticed that my
2945440	2952400	own experience is virtual, that my memories are often created after the fact and modified under
2952400	2961040	my nose without me noticing. Do you notice that you exist inside of a model? It's also that I'm not
2961040	2967040	in physical time. My own self is sometimes a little bit ahead of the physical universe,
2967040	2976080	sometimes a little bit behind. So the physical now and the experience now are different. And the
2976080	2981040	elements of my perception are clearly not the elements in which physics is being implemented.
2981040	2986960	Rather, it's the other way around. What I notice is that I do exist in a dream, very much like
2986960	2992800	we usually say in idealist philosophy. But this dream needs to be created somehow. Something
2992800	2997600	needs to construct the dream. And that's a brain and higher plane of existence. And this
2997600	3006080	higher plane of existence is what we call physics. Maybe I'll stop sharing. The other comment that
3006080	3010560	I find usually provocative that you make is which kind of relates also to the discussion. I don't
3010560	3017440	know if you've seen David Chalmers' recently published book on reality plus, where he talks about
3017440	3023440	virtual worlds. But you came up with a comment that what we are seeing is a virtual reality
3023440	3029760	generated in the brain, which I'm actually very persuaded by myself. And I guess I'm thinking
3029760	3037280	also of the kind of thinking of Anil Seth, who kind of talks about this controlled hallucination.
3038000	3043040	And we kind of predict what's out there because we don't know. It seems that your work to some
3043040	3048720	extent aligns with the work of Anil Seth, but at some points differently. I have to say that Anil
3048720	3052160	is very fond of your work. So it's intriguing to kind of compare and contrast them.
3056000	3060880	Because we had a discussion last week about whether we're living in a simulation and things,
3060880	3068080	how would you position yourself in relation to David Chalmers' work from reality plus,
3068080	3072800	his work on virtual worlds? I haven't read his recent book, so I cannot say.
3073520	3078320	And I don't know what his main thesis is about virtual worlds.
3080400	3086080	Okay. Well, I wouldn't want to speak on his behalf, but we had a discussion about it. I also
3086080	3090720	wanted to just point out something as well, which I find intriguing. And that is the extent to which
3090720	3096000	some of these speculations that are coming out of cognitive science kind of seemingly echo the
3096000	3101040	world of psychoanalysis. Now, I know that a lot of cognitive scientists and neuroscientists hate
3103840	3109280	psychoanalysis. I know that Anil Seth does, but there's an interesting comment that Slavoj Žižek
3109280	3116080	has made about this, where if you take a Lacanian perspective, you don't engage with the real except
3116080	3125920	of certain moments. And in a sense, the fantasy has become a constitutive of how you engage with
3125920	3130720	the real. So you see the real through the lens of fantasy, through the lens of the imagination,
3131280	3136720	which is very similar to what, in some ways, you're talking about. And he makes a comment
3136720	3143600	in an essay that I published a long time ago in a book, and this is called From Virtual Reality
3143600	3148560	to the Virtualization of Reality, which is basically saying that our reality is itself
3148560	3155280	already virtualized. And I think what virtual reality therefore shows us is not how virtual
3156160	3166240	reality shows us is not how virtual reality is, but rather how virtual reality itself is,
3166240	3171040	which is very similar to your kind of thinking. And so what I find intriguing is that some of these
3172640	3180320	speculations are echoing previous speculations about how the mind works. Have you engaged in
3180320	3186960	any way with Žižek or the world of Lacanian psychoanalysis and its discussion about the real?
3187760	3194320	And I sometimes read this, but I've never had the discussion with Žižek. I am not
3194320	3199440	unsympathetic to this terminology. It's just the problem is that it doesn't allow me to make
3199440	3204640	models that I can test. And this means I don't know whether these models are wrong. So it's
3204640	3210160	basically a very useful way to generate stories that also give me a handle on reality in the sense
3210160	3215760	that allow me to point at entities and to manipulate them in my mind. And sometimes it's very useful
3215760	3219680	that you basically have an indexical model where you are separating the world into
3219680	3224480	objects that are useful to you and you can manipulate them. But this decomposition doesn't
3224480	3230080	need to be an accurate causal structure. So the criticism with psychoanalysis is not that the
3230080	3236480	terminology is not useful to me. It's that psychoanalysis doesn't tell me how to build the mind
3236480	3241040	and so I should say that it works and to compare different competing models of the mind and to see
3241040	3246800	which one is better. To do this, I will need to automate the mind in a way. I need to reverse
3246800	3252240	engineer what the mind is doing, the functions that the mind is applying to representational states
3252800	3258240	and need to get this done to such a detail that this thing becomes my black. And then I can compare
3258240	3264400	its functionality. I want to move on to the questions that are coming in. I want to invite
3264400	3269200	people in the audience to comment as I want to make an observation and that is to say that
3269200	3273040	in my own world, this is years ago, I was working on a kind of coming out of Freud and thinking about
3273040	3278720	how you use model psychoanalysis and engaging with, actually in this case it was with the work of
3278720	3283840	Walter Benjamin, I came across something that is uncannily similar, certainly in terms of the
3283840	3288240	terminology used, whether we're talking about the same thing, I don't know. But let me just
3288240	3293920	for a second just share you something which surprised me because when I heard
3293920	3298800	Blazegoriyakos talking about models and modeling, it's also crucial to his way of thinking.
3299520	3303200	It sort of seemed to echo this. I'm just going to simply just share this screen a second.
3307600	3315040	Yeah, can you see that? It's the thing about, so the term that I'm always interested in is the
3315040	3320080	term mymesis. I don't know if you know this term at all, but in Freud it's how you can,
3320160	3324640	he talks about it initially when he talks about how in his book of jokes, how you can connect
3324640	3330720	with someone who's a subject of a joke. Someone falling over a banana skin, for example, you
3330720	3337280	somehow, you model yourself on that person recalling bodily memories of what it is to slip up and so
3337280	3342160	on and so on. It's how you identify with the world. The term mymesis is a form of that,
3342160	3348000	it's a form of modeling. But just I just want to read out some of the text here because it's so
3348000	3353040	similar to this idea of models and modeling. And I know that the term can be taken out of context
3353040	3356640	and have a completely different sort of meaning, so therefore it's a bit deceptive.
3357360	3362000	Anyway, to just understand the meaning of mymesis in Benjamin, we must all recognize its origin,
3362000	3366960	the process of modeling, of making a copy of. In essence, it refers to an interpretive process
3366960	3372240	that relates either to the modeling oneself on an object or to making a model of that object.
3372240	3377120	Likewise, mymesis may come into relation as a third party engages that model with that model,
3377120	3380400	and the model becomes a vehicle for identifying with the original object.
3380400	3385840	In each case, the aim is to assimilate to that object. Mymesis, anyway, so it's going on about
3385840	3392320	this question about, so it's a concept that has been used in psychoanalysis. And I don't know,
3392320	3398160	there's a risk that one can simply take a term, which has a completely different meaning in
3398160	3402720	different contexts and apply it. But I do think that the concept, the model, is a fascinating one.
3402720	3408800	And I'm intrigued by the fact that you, alongside Blaze, and I think alongside also Jeff Hawkins,
3408800	3412640	use that model as a way of opening up these questions.
3413920	3418800	An issue with this type of language is that usually the understanding that it generates
3418800	3423600	at least doesn't converge. That's the general issue with continental philosophy.
3424960	3430400	Somebody recently asked on Twitter what the difference is between continental and analytical
3430400	3436480	philosophers. And I somewhat flippantly responded that an analytical philosopher
3436480	3441840	is one who understands that the difficult and hard questions of philosophy need to be
3443600	3452400	answered with formal models. Whereas continental philosophers don't think that this is necessary,
3453520	3458800	because they are literally genre that is looking down on analytical philosophers.
3459680	3464400	You can see the difference between analytical philosophy and continental philosophy in,
3464400	3468800	for instance, the treatment of Goethe's incompleteness proof. A proper analytical
3468800	3474880	philosopher who had a formal education will understand that this is a proof about certain
3474880	3480080	properties of formal languages, and specifically it proves that stateless formal languages that
3480080	3485280	assume that truth exists independently of the process by which you get to prove
3485360	3492080	don't lead to consistent models of the domain. And there are also related results, for instance,
3492080	3497680	that a system cannot make statements about affairs outside of itself. So when you want to
3497680	3504000	talk about the world in a formal system, you need to create a model of that world, and you can only
3504000	3508240	talk about that model. You cannot talk about anything outside of the models that you are creating.
3509040	3516400	And to continental philosopher, the Goethe's proof is more or less often understood as a
3516400	3521360	statement of mathematicians that prove that mathematics is important at getting a handle
3521360	3526480	on reality, and therefore the only way you can get a handle on reality is by not knowing mathematics,
3526480	3529520	which gives the continental philosopher a clear advantage.
3530320	3535120	I cannot hear you. You are muted.
3536960	3540720	That was a great answer. Thank you. We've got some questions. Now, I have a third series of further
3540720	3543840	questions that I'd like to ask. Maybe I could ask you one question before we go into the other
3543840	3548240	questions. And that is, I mean, are you writing a book about this? I mean, is it being put down
3548240	3552240	in some documented form? Because it would be incredibly useful if it were.
3552960	3558560	You are right. I need to write a book about this. I have a large number of notes on stuff that needs
3558560	3564080	to go into the book, but I also have a job and I have kids that are homeschooled and I have ADHD.
3564080	3569920	So I need to go into a different phase of my life to have long interrupted, uninterrupted sessions for
3569920	3574240	writing long phone texts. But if you're bad about not having written the book yet.
3575440	3582720	Well, I think that a popular form of communicating ideas. So there is material out there,
3582720	3586160	but I just think it could be assembled into an engine. Yes, it needs to be assembled. I feel
3586160	3591840	better if it is being assembled and not just existing as various disconnected conversations.
3591840	3595920	Yeah, I just, I mean, even Jeff Hawkins, I mean, my Jeff Hawkins book, I think is fabulous. But
3595920	3599920	what's interesting is there are no footnotes in it. He's just kind of speculating. But
3599920	3604720	nonetheless, he's putting his ideas down there. And it's really incredibly useful to have that
3604720	3609760	kind of commentary. So anyway, look forward to the book. I want to just ask this Matt Gorebay,
3609760	3616480	who's got a question in the chat, whether Matt is a graduate of MIT Media Lab. He's
3617520	3622880	a doctoral design student right now at FIU. Matt, would you like to ask your question?
3624800	3628880	Sure. Yeah, thanks for all of this. It's really interesting. Perhaps the book could be co-authored
3628880	3634320	by GPT-3, make it faster to, you know, just to give GPT-3 the agency over the first draft.
3635280	3640160	I was asking, speaking of agency, I mean, the question I have is about motivation. It's about
3640160	3644800	sort of the high level motivations. When you ask, when you ask GPT-3, are you conscious? And then
3644800	3651680	it responds somewhat convincingly. It still isn't initiating that conversation. And so
3652640	3656560	one of, I mean, kind of in listening to everything you were saying, and you said something about
3657840	3662160	when you were talking about trees and seeds, I love the thing about, instead of realizing
3662160	3666160	the functionality, you want to build a system that wants to realize the functionality, you want
3666160	3670000	to build the thing that wants to become a tree. But that question of wanting and motivation,
3671040	3676640	how does one, at what point does that get put into the system? Like at what point does the system
3676640	3687200	become curious or self-motivated to do things that we didn't necessarily ask of it? And I think maybe
3687200	3691920	related to that, I don't know, I'll let you go on this, but maybe related to that, the question
3691920	3700480	of individuation and sort of inter-subjectivity, like, you know, has GPT-3 spoken to, are there
3700480	3704480	communities of GPT-3 all talking to each other about what they want to do and how do they individuate?
3704480	3710080	Or is GPT-3 just always the same and its clones of itself? If you could speak to any of that,
3710080	3714720	that'd be great. Thank you. Yes. So that's the question, are we doing something that the organism
3714720	3722400	is not asking of us? And that's not an easy question to answer. If you look at our own
3722400	3729600	motivation, I think that we have a few hundred physiological drives for different nutrients,
3729600	3733600	for instance, sometimes we want to eat salty food, sometimes we want to have sweet food,
3733600	3737920	sometimes we need something to drink, sometimes we need to rest, and all these can be understood
3737920	3743440	as set-point deviations. And to deal with all of them, we need to create a dynamic model of our
3743600	3748960	needs projected into the future and then plans and higher-level models of these
3749520	3753760	needs, which we could call purposes and so on. We don't just have physiological needs,
3753760	3758560	we also have social needs, for instance, a need to affiliation to become part of a group,
3758560	3764640	for instance, and to be accepted by it. Some people have a need for status to raise up in the group.
3764640	3771680	There are romantic needs, which can be courtship modes or a need for intimacy and so on. And then
3771760	3776480	next to about a dozen of these social needs, we have a handful of cognitive needs, a need to
3777920	3785440	become more competent, become efficacious on the environment, a need to reduce uncertainty,
3785440	3790160	and something that I would call a need for aesthetics, which means discovering deep
3790160	3795760	structure in the world. And aesthetics can be split into stimulus-oriented aesthetics, so we
3795760	3800320	are intrinsically wired to like certain body schemas over others, certain landscapes over others,
3800320	3804320	and there are evolutionary reasons for that. And then there are some mathematical principles,
3804320	3809360	what kind of representations we like, what form means to have a good representation of something
3809360	3816800	that are more general. And if we use meditation to disassemble our own needs and to dissociate
3816800	3822480	from them, we realize that the things that give us pleasure and pain do fall in these categories.
3822480	3828240	So we have lots of these impulses that are about hunger and thirst and rest and so on,
3828240	3832960	and we have impulses that are about the social domain, and the older we get, the more these
3832960	3840240	impulses get replaced by a deeper model of what we want the world to be like, and we act on this
3840240	3849840	deeper model and digest these reflexes. And on the lowest level, when you try to get more enlightened,
3849840	3855360	you may have just something left that people often call love, which is, I think, a need to
3855360	3859760	transcendentally connect to other agents and share purposes, that might act on these shared
3859760	3864880	purposes, but you can get deeper than this. And the deepest level, you only have aesthetics,
3864880	3870480	the need to form structure and to make the world intelligible, to create a coherent model of
3870480	3877600	reality. And this need, I think, is similar to what Friston describes in the free energy principle,
3877600	3883200	it's basically predictive coding, it's the attempt to track reality using a model that is as good as
3883200	3888160	possible, that tracking reality. And if you turn off this aesthetic need, in addition to all the
3888160	3895680	others, my own mind becomes fuzzy, I fall asleep, I drift away, because if I stop paying my neurons
3895680	3901200	for producing order in the universe, and they stop doing this, then nothing else is happening in my
3901200	3907840	mind that I can observe, and I just lose coherence. So if we imagine this hierarchy of needs, which
3907840	3912640	by itself, and seen as a cybernetic system, is not all that complicated, we can build this into a
3912640	3917360	machine, I think it's not that difficult. The difficult part is to get perception right, to get
3918640	3923840	ability to model reality in the universal base, you can have one coherent model of everything
3923840	3928560	that you relate stuff to, when we talk about meaning, we talk about how to relate an arbitrary
3928560	3933600	feature or domain or idea or concept to this unified model of reality that we are building each
3933600	3941760	work once in our own mind. Can I just pick up on a question, we've got another question
3941760	3946640	lined up, but let me ask you one quickly. You come from a creative background, your father was an
3946640	3953600	architect, and you refer to let's say creative practices of the orchestra and so on, it's part
3953600	3958160	of what you're talking about, and frankly, your way of thinking is incredibly creative, it strikes
3958160	3963040	me as being very creative. I wonder, you haven't mentioned the word creativity, I don't think,
3963040	3969680	and how do you view creativity, is it just a myth or is it something, how could you conceptualize it
3969680	3976640	within your framework? I think of creativity as the ability to bridge discontinuities in the search
3976640	3981520	space, and you are just following the gradient, and when you're just going through a continuous
3981520	3986800	search space, I don't think that you are creative, you just arrive at the state of the art, and even
3986800	3992800	the state of the art is something that hasn't been done before, if you just combine what is known
3992800	3997760	and you find a local optimum in the known things, you're not being creative. To be creative, you
3997760	4003680	need to construct a new search space usually, and many methods in which you can be creative, for
4003680	4010720	instance, you can use random serendipity, you can use some evolutionary process that is combining
4010720	4016720	elements in ways that you are unaware of, and then discover structure in them. Creativity is, in some
4016720	4022160	sense, about jumping off from the known things into darkness and hoping that you end up landing on
4022160	4030000	the other side. So it's related to a search. Let me just put this to you then. Do you think that,
4031120	4034560	because you mentioned this before in your discussions, but do you think Move 37 in Game
4034560	4042880	2 of AlphaGo, was that creative? Could you call that creative? I don't think that AlphaGo is
4042880	4051200	creative in the sense, because what AlphaGo is, well, there are evolutionary methods in AlphaGo,
4051200	4056240	and the outcome of what AlphaGo is arriving at is not always predictable. And it's also
4056240	4062880	computationally irreducible in the sense that you cannot foresee what AlphaGo was doing. AlphaGo
4062880	4068960	was able, in a relatively short amount of time, to demonstrate that human go play, which existed
4068960	4076240	for thousands of years, was not optimal. It has discovered strategies that encounter the established
4076240	4082240	strategies and goal. And in this sense, from the perspective of a human go player, it was playing
4082240	4088960	in a creative way. It just discovered new things that had not been discovered before. But if you
4088960	4095520	will run AlphaGo multiple times, it's always going to discover these things. And so the search is,
4096160	4103040	while it has stochastic elements, as a deterministic outcome. And I think that when we look at systems
4103040	4108080	like this, our notion of creativity is kind of sort of falls apart. But creativity is not
4108080	4112960	absolutely a thing in the universe. It sometimes is a frame that is useful to describe what's
4112960	4119280	happening. And sometimes this frame falls apart. Let me just put a provocative comment to you,
4119280	4123680	then. I mean, something that I thought myself, and I would like to know what you think of this.
4123680	4130000	So if GPT-3, if AlphaGo is not creative, and I kind of, in many ways, I don't think it is
4130000	4134560	creative, it's just doing a very, very effective search. But then we could ask this question about
4134560	4140480	whether human beings are creative, or whether this term... Exactly. That's my issue, right? So
4140480	4145920	sometimes your terms start meaning things. They mean something in a certain context, but when you
4145920	4151600	increase the resolution too much, this context falls apart and no longer makes sense. And you use
4152240	4157680	lose your term. And I have the same issue with the term like nemesis. But I like it. It's poetic.
4157680	4163360	It is evocative. It produces stuff in your mind. But when you zoom in very hard, it's not clear
4163360	4172240	what it means. And so instead, I try to examine the assumptions that are hidden in nemesis. For
4172240	4177760	instance, the idea that others exist independently of you, and yet you are able to take them in
4177760	4183200	somehow instead of constructing them. And then the question, what's first, the model of the other,
4183200	4188400	or the model of yourself? And whether it's the same thing in every person that becomes conscious.
4188400	4194480	This is not obvious to me. And the notion of nemesis presupposes too much. And that makes me
4194480	4199920	unsympathetic to it. So even though I appreciate the poetic illusions that are there in the space
4199920	4204400	that the term like this opens and the ability to converse about it, ultimately, I need to
4204400	4210800	deconstruct the term before I can use it. Okay, so let me just put... I'm glad you take this position.
4210800	4216480	But we just throw an idea at you. So, I mean, one of the analogies that I've made in the past
4216480	4222720	is to say that... Use the term magic at one point. Actually, I don't think that magic exists. I mean,
4222720	4229760	I think that what happens basically is if you take the example I always give, if you have a magician
4229760	4234000	at a kid's show, and they're pulling a rabbit out of a hat or something or doing magic,
4234880	4240000	the magician's not doing magic. The magician is simply concealing the operations at work
4240000	4244960	and making you believe that it is magic. And I'm just wondering whether we couldn't take that same
4244960	4249520	notion and apply it to creativity, because we don't understand the processes. We just look back
4249520	4255120	and say, wow, that's creative. Like some people said the same with AlphaGo, that's creative.
4255120	4258480	But maybe it's not. It's just simply we don't understand the process. Therefore,
4258480	4261920	maybe even the term creativity is not a very productive term in the first place.
4263200	4268480	Yeah, I suspect that magic also in order to make sense, we need to understand what the term means.
4268480	4273440	We need to completely deconstruct it into its constituents and then put it back together and
4273440	4278480	see if we still have magic or if this term can still be recovered. And typically,
4278480	4287200	I see magic as the ability to get right access on the laws of reality. And if you think about
4287200	4292560	what it means in the naive form is the departure from the mechanical universe. The universe that
4292560	4298960	we are in, according to the theory of physicalism, emerges over a causally closed lowest layer.
4298960	4303680	And this causally closed lowest layer is basically whatever mechanics is making the
4303680	4309920	universe happening. And ultimately, there is going to be some natural layer where things are just
4309920	4316480	happening without some conscious intervention. And the idea of magic is that our universe somehow
4316480	4325280	is a conspiracy, that there is a way to subvert the laws of the mechanical universe using symbolic
4325280	4330880	powers, that you have symbolic causality. And symbolic causality is, for instance, the connection
4330880	4337040	that exists between sacrificing a black cat and celestial events that are caused by this.
4337600	4342720	Right. And this, this is something that cannot possibly be explained by any known physical
4342800	4347760	mechanism, because the elements of this transaction only have meaning in a symbolic
4347760	4354160	realm to a human mind that is acting based on a certain high level story and abstraction that
4354160	4357840	is not a good depiction of what happens in the physical reality. It doesn't mean that the story
4357840	4364720	is wrong. It's just not one about the frame of physics. In computer games, there is magic happening
4364720	4369600	relative to the computer game, right? You can use Minecraft. And in Minecraft, there is a mechanical
4369600	4374480	layer where everything happens by itself, but you can also call up a shell and enter a time-set
4374480	4379520	day in the sunrises. And this interaction somehow breaks the logic. And if you could do such a thing
4379520	4386560	in our world, if you can use a ritual to make the sunrise, then you would subvert the physical
4386560	4393440	reality. But what you can subvert is the psychological reality and the social reality.
4394080	4399360	And in this form, magic does exist. If you get right access on somebody else's perception
4400000	4405200	and attention and memory and imagination, you can change their reality in any way you want.
4406240	4410880	And in our culture, there are some norms against this or there used to be norms against it.
4410880	4416880	And I think that in Christianity, this didn't exist. It was legitimate to subvert the reality
4416880	4424400	of other people by telling them, here is an omnipotent agent that is part of reality,
4424400	4428560	therefore needs to be modeled in your own mind. And omnipotence means it knows everything that
4428560	4433600	is to be known as full read access to your mind. And omnipotence means it has full write access.
4434160	4440000	And also, we have a backdoor to this thing. Every week, you can get an update and we tell you
4440000	4445040	what this agent is going to do to your mind. And as a result, you have people that remember
4445040	4451360	having seen miracles, because something has rewritten the mental structure of their own mind.
4451920	4458480	And you often find patterns of this in ideologies. So this idea that somebody else gets right access
4458480	4464560	on your own minds, for instance, an innocent example is, here are my pronouns. And these
4464560	4469360	pronouns are not what you perceive. They are what I want you to perceive. And I have the right to
4469360	4476160	change your mental representation. That's a form of magic. And I think that the idea that this
4476160	4481920	is happening is because the people who propagate these ideas don't believe in the individual
4481920	4487760	autonomy of individual minds to create realities and having a good outcome. You need to control the
4487760	4495440	realities that minds create together by using magic to get the psychological realities of
4495440	4498400	individuals to converge to the desired social reality.
4499760	4509600	One of the things I find interesting in your thinking is the role of, well, you use the term
4509600	4514000	ideology, use the term religion. But to my mind, they could be seen more in the realm of myth.
4514000	4520080	I mean, there's a lot of this space. And the way that you use the term actually also reminds me
4520640	4527360	of the work of Zizek. I mean, he makes a comment. He read a book about love at one point. And
4527360	4533360	he came to the conclusion that love is the myth that fills the gap between the self and the other.
4533360	4539280	And somehow myth has been some structuring device by which you look at things where it
4539280	4544240	conditions your understanding of reality a bit like ideology or in a bit like religion. Is that
4544240	4551520	something that you would engage with? I would engage with it. But I think that love is a more
4551520	4558400	concrete meaning. Love is the discovery of shared sacredness. And sacredness are the purposes above
4558400	4565760	the ego, the purposes to which we are willing to sacrifice ourselves. This has to do with being
4565760	4570800	part of a transcendental agent. Not everybody has that. If you are a sociopath, you will not
4570880	4576000	have purposes above the ego. And so you will be incapable of love because you will not have shared
4576000	4580880	purposes above the ego. You might have romantic infatuation. But ultimately, you are not going
4580880	4586400	to build shared agents with others for non-transactional purposes because you share purposes with them.
4587040	4593920	So love is this discovery of shared purposes. But I mean, but can you use the term shared? I mean,
4593920	4598640	how do we ever know the other? How do we ever accept the other? We can think that we're sharing
4598640	4604320	things, but are we actually sharing things? We do this in the same way as we know ourselves.
4604320	4609760	These are model creations. The other is a story that we are creating about a certain state of
4609760	4614400	affairs in the world. It's in this sense not objectively true, but it's a model that allows
4614400	4620080	you to predict reality better than other models that are competing with it. No, interesting response.
4621040	4627920	So, Gustavo, maybe Gustavo is a postdoc at UC Santa Barbara. Gustavo, would you like to
4629200	4640560	ask a question? Sure. Thank you very much for the wonderful talk. I think I want to kind of
4640560	4647440	build on Matt's question a little bit, but more specifically to the idea of understanding
4648400	4657360	how computational systems are, let's say, evolved and programmed at the scientific level. Like,
4657360	4666720	what is the state of the art in modeling either psychological states or understanding how different
4667680	4674480	models are building on knowledge where computational models can make creative leaps?
4674560	4681680	So, if it's not clear, I'm thinking about in the history of human society, they're different models
4681680	4687280	of control, the models of narrative, you know, they're different, either religions or different
4687280	4694960	belief systems, but in the models of science, it seems as though that there is a building of
4695920	4706400	knowledge and that we're moving toward an end. So, where we will never, as an example, we right
4706400	4713200	now won't live to the end of the universe, but there is a goal in science that we as human beings
4713200	4722320	need to propagate outside of our, you know, cosmos, so we have a chance to exist, and we have multiverses.
4722960	4730800	How does, how do these computational models either aid humanity or are we looking at these
4730800	4739440	computational models to exceed humanity in some way? And what does that mean? I'm thinking about
4739440	4745440	that edge that you're talking about, because I think a lot of what we talked about in humanity
4745440	4753360	are black boxes. If you talk to a physicist or, or a mathematician, or an electrical engineer,
4753360	4761440	they get to a point where we don't know the science. What are your thoughts about that? How do,
4761440	4766800	how do we build better systems? Or how do we interact with these systems a little bit more
4766800	4773040	ethically or morally? So they're not like psychopathic or anyway, maybe that's a little
4773040	4780480	too abstract. It's just, you brought a lot of higher level, a lot of knowledge here. So it's,
4783680	4787760	it's very sobering is what I'm saying. Sorry about that.
4788960	4798560	Don't be sorry. But I do welcome sobriety if it emerges. I think that you made some very
4798560	4807440	interesting points or arrived at interesting pointers. You saw some images that I presented
4807440	4815520	earlier, for instance, the generative art of glide and the text that GPT-3 is producing. And in some
4815520	4822240	sense, this is the state of current computational creativity. And I think that the problem of how
4822240	4828720	to make a technological system creative is solved. So they, these images are in some sense creative
4828720	4835200	solutions, because they are able to bridge certain discontinuities in a certain space by finding
4835200	4840480	solutions that people might have difficulty to find. So, for instance, if you have a conversation
4840480	4846960	with GPT-3, it's usually better than what you get from a person that doesn't know the domain,
4846960	4850960	but worse than the person that knows the domain. Well, for instance, you have a conversation with
4850960	4856000	Hannah Arendt. And if you haven't read a lot of Hannah Arendt, it's really surprising and very
4856000	4860400	convincing. But if you're very familiar with Hannah Arendt and have thought about her a lot,
4861040	4864320	then you might notice some things that you probably wouldn't have said.
4865280	4872480	And a similar thing is with our depictions of art and so on. So it's able to produce
4872480	4878720	certain styles and reproduce them. But there is a certain thing that is missing. And I think that
4878720	4885120	what GPT-3 cannot do yet, and the systems cannot do yet, is art. And the difference between art and
4885120	4892800	creativity is subtle. Art, I think, is the capturing of conscious states, of a conscious
4892800	4901040	reality, of some aspect of a conscious reality. And this means meaningful references to a unified
4901040	4908240	model of the universe. And these models do not have a unified models of the universe yet.
4908240	4911840	They don't understand which universe they are part of or think that they are part of.
4912480	4917760	And while they are slowly getting there, I don't think that they are there yet. So to me,
4918560	4924160	the digital art that you're seeing is not actually art, because it does not mean very much to the
4924160	4931760	system. But it's something that humans can, at this point, relate to their shared reality sometimes
4931760	4938640	and onto their inner reality. And this makes them akin to art. And there is basically a
4938640	4944640	porous boundary that is more and more dissolving in terms of AI and art in these days.
4947200	4954800	So I don't think that there are fundamental unsolved problems at this point. But the biggest
4954800	4959600	important problem is how to get a system that is able to track reality in real time
4959600	4963840	and that can online learning. And a lot of people are working on this and we don't know
4963840	4967840	how long it'll take to solve it. But it's not that it's a principle unsolvable.
4969600	4973280	Can I just pick up on that, the question of art, because I think the back of my mind,
4973280	4979840	there's an interesting kind of question coming up here in terms of, well, let me just throw out
4979840	4984880	to you an idea, because you used the conductor metaphor and the music was part of the discourse.
4984880	4993200	And I often speculated whether how creative we are as architects or indeed how artists are
4993200	4997920	in the sense that there is a canon, there is a canon of architecture or art or whatever it was.
4997920	5002320	And what we do is normally keeping broadly within that canon, you're very much aware of what other
5002320	5006480	people have done. You might push the boundary slightly. And this is kind of what I think,
5007360	5011840	I use the term jazz as a kind of idea of understanding how we operate as a background
5011840	5016320	condition. And we're feeding off it and just nudging the boundaries, but staying recognizably
5016320	5020000	within the canon of this. And it's interesting that, I don't know if you know the work of
5020000	5027920	Ahmed Agamal, the guy who created these, who designed creative gans that he's a computer
5027920	5033040	scientist who has a, who generates art. And the logic is this, you've got to keep broadly within
5033040	5037520	the framework of what you're talking about within the canon of, let's say, modernist art,
5037520	5041520	but make it slightly different. So you're just pushing the boundaries. So I know I often
5041520	5048720	wonder to what extent we're so conditioned by what has been done before. And whether we,
5048720	5053440	if you would do something genuinely different, you'll be outside the realm of what is acceptable
5053440	5062000	within that genre. I would make a difference distinction between art and design. And architecture
5062000	5068080	for the most part is not art, but design. It's also true for myself. I'm for the most part not
5068080	5074640	an artist, but a designer. And design is instrumental to something. Whereas art is
5074640	5079840	instrumental to consciousness only, I think, at least the aspects of the thing that you're producing
5079840	5084320	that are art, the other aspects and every artifact that you are producing, almost everyone,
5085280	5091520	the design serves some other purpose than the consciousness itself. For instance, if you are
5091520	5097280	designing a building, you are serving a function of a human being that needs to have a house somewhere
5097280	5101440	that needs to live down somewhere, this thing needs to be part of an environment and it requires
5101440	5107360	deep perception. And it does require capturing some of your observations and the deep level. So there
5107360	5114000	is important elements of seeing and perceiving and observing and reflection in architecture.
5114640	5119760	But all these elements are ultimately instrumental to the thing that you're going to build. And the
5119760	5125920	thing that you're going to build is defined by its function. Maybe I could just throw something out
5125920	5132880	there. And let's say that could you not, as an architect, always think about these things. And I
5132880	5136400	think almost there are two sides of, well, there are two sides of architecture, one's a functional
5136400	5140800	side of thing, or dealing with the logistics. If you're dealing, let's say, with a very
5142480	5147120	complex urban condition, you need to fit a building in somewhere, it becomes almost like a kind of
5147120	5151440	simple search question of how do you find the best solution. And then there is this kind of, I
5151440	5155840	wouldn't say a veneer, but there is an aesthetic side of things. So when it comes to, let's say,
5155840	5160880	the strategic planning of how you might fit a building in a site or how it might operate and so
5160880	5166160	on, it kind of relates more to the kind of logical, let's say, of AlphaGo, the strategy of AlphaGo.
5166160	5169760	And then there's something else that we, as architects, want to put on top of that, which is
5169760	5176160	more the kind of the artist dimension, which is giving it a certain aesthetic. Does that sound
5176560	5181360	to make sense to you, that logic? Yes, it does. But there's, of course, the practical element
5181360	5188240	that the aesthetic that the architect has when it's a successful one is a brand. And it's not
5188800	5195040	driven by a free exploration of the conscious states of the architect for the most part, but
5195040	5200640	it's driven by the anticipation of reward in a particular economic and cultural domain.
5201680	5204240	And so in a sense, it's usually a construction process.
5206800	5212640	Let me throw out another kind of thought then. I mean, what is interesting is when you get someone
5212640	5217440	who's fairly radical, like, I don't know, Frank Gehry, for example, he produces a building,
5217440	5221360	the Guggenheim and Bilbao, really changed architecture, but then he kind of repeats
5221360	5225600	himself in some senses. He's doing similar versions of that, and you must have seen the LA,
5225600	5235200	the Philharmonic in LA, the Walt Disney concert hall. And it's almost like we have these patterns
5235280	5242000	of behavior or signatures, I would say, that are recognizable. And now you see a Gehry building,
5242000	5246960	you say, that's Gehry. So it's almost like we're pieces on a chess board, and we have certain
5246960	5251840	conditions, and we actually are constrained by that. So whether you see it as a brand or not,
5251840	5257360	but it could be seen as a brand, we are constrained by our own signatures. And in fact, we end up
5257360	5263120	not being so creative because we fit in with that logic. How does that sound to you?
5263120	5268400	Ultimately, it's about intention. And the intention is either the submission to an
5268400	5276400	external cultural mind, or the intention is an autonomous one. And I personally see art as
5276400	5281920	something that is driven autonomously, and that's different from the definition of the art market.
5283360	5289360	So the art market is only capturing a very small part of the arts. And a lot of the things that
5289360	5296640	are happening on the art market are not art. And my own father is an architect who has defected
5296640	5303920	from architecture and become an artist. So I am a child of an artist family. And my wife is an
5303920	5310560	artist. And the difference between the art that my father is doing and the architecture that he
5310560	5317680	has been doing is that the architecture is serving others in a particular role for in a
5317760	5324400	particular cultural context and economic and social and societal context. And my father didn't
5324400	5329920	want to submit to this societal context and this psychological and social context because he thought
5329920	5335280	it was deeply unesthetic to him. We rejected the aesthetics of the society that he was in.
5335280	5340960	So we removed himself from the society that he was in, bought a watermelon in the countryside
5340960	5347200	and turned this into his own kingdom. And this kingdom is open for others to visit and explore.
5347200	5352960	But it's not done for them. It's done for itself. It's done in the service of his own aesthetics.
5353920	5360320	And to him, it doesn't really matter whether others like these aesthetics. This doesn't change
5360320	5366480	how he thinks about the things that he's creating himself. He may need economic success to be able
5366480	5372000	to survive and it might frustrate him if people don't like what he's doing. And it might frustrate
5372000	5377360	him the things that he might have to do to survive. But his own definition is that he is not
5378000	5382240	for himself, of his own intention, that he is not serving an external aesthetics.
5382800	5387440	He is an autonomous agent. He is deeply autonomous. He is the creator of his own universe.
5388960	5393360	No, it's a beautiful story that I've got a question coming in from Shamene in the chat.
5393360	5396160	But can I ask you one quick question before we go on to that? And that's to say,
5396960	5401600	the term architecture gets used, obviously, both for computer science and for architecture itself.
5402800	5407440	And I'm just wondering, I mean, I don't know, my definition of the architect is very broad. I
5407440	5412240	mean, I think it's a way of kind of, I would say that probably what your father is doing is probably
5412240	5416720	still a form of architecture, maybe a form of other architecture. I mean, there are many creative
5416720	5424160	industries that architects go into, like the film industry or space industry, and they use that
5424160	5430640	architectural imagination elsewhere. And I even think that kind of setting up educational systems
5430640	5435120	is a form of architecture in a way. And I just wonder whether you ever have seen any connection
5435120	5438960	between those two architectures, the one that you're familiar with or your father,
5438960	5442160	and the world in which you work right now, computer science, because I noticed the word
5442160	5448320	architecture is in the title or subtitle of your book. Yes. So the notion of a cognitive
5448320	5457200	architecture means that you understand the mind as something like a building or a structural design
5457280	5462960	that is inhabited by lots of functionality, and is serving functionality in a larger world
5462960	5467840	that it's embedded in. So it's natural to think of the mind as something that is constructed
5467840	5473760	rather than just grown. And that's also the limit of the term architecture in a way,
5473760	5480880	because the mind is not just constructed, it is also grown. And so there is the question
5480880	5487680	whether growth is an architecture is a forest architected in a way. And I think it can only
5487680	5492400	be architected to the degree that the forest is sentient and starts breeding and structuring
5492400	5499760	itself. And maybe it is, right? So maybe there are elements of design and construction in the
5499760	5506640	forest. So it's not just something that is locally grown by some dissociated process that does not
5506640	5512480	have a centralized spirit that reflects functionally on its relationship to the world.
5514800	5520720	So Shemin has got a question in the chat. She's in a noisy cafe, so she can't ask it herself. But
5520720	5526960	I should say that Shemin Yussef is from Iraq. She actually studied in Germany in the other
5526960	5534160	Bauhausstadt in Dessau, where I myself was a professor for a while in the building next door
5534160	5539120	to the Bauhaus itself. And there's a school of architecture. And Shemin was one of my students
5539120	5545200	for a workshop there. Let me read out Shemin's question. Thank you, Yosha, for the great lecture.
5545200	5549920	This is Shemin Yussef from the School of Architecture at Florida Atlantic University.
5549920	5555760	My question is, it seems that there is no condition for sentience for an agent in brackets,
5555760	5561120	AI model, for example, to be creative and to be conscious in brackets. If I understand your
5561120	5567840	thesis well, close brackets. So do you think that we, human agents, are discriminating against the
5567840	5574160	machine since it's not a biological being, and therefore we should instead consider intelligence
5574160	5579440	and creativity based on the behavior of the machine, which has proved to be true or is
5579440	5583280	becoming true in the near future? Shall I read that again, or does that make sense?
5583920	5589200	Yes, I think I understand where the question is going. It comes down to whether
5589440	5595120	the technological systems, once they approach functionality that is similar to ours,
5595120	5600960	should get rights that are similar to ours, and at which point we give these rights and why.
5602240	5608320	Is this a viable interpretation? I don't know whether Shemin liked the comment on that in the
5608320	5616800	chat. Well, maybe while we're... So as I would say that sentience is in some sense the ability
5616800	5621920	to know what you are doing, which means you have to have a model of yourself and the relationships
5621920	5628400	to the world that you are in. And in this sense, I would say that, for instance, a corporation
5629040	5635840	can be sentient. The corporation has a legal, economic, structural, functional notion of what
5635840	5641600	it is. And this notion is represented in the minds of the people that work for this organization
5641600	5646960	and the balance sheets of the organization and so on. It's often distributed, so it's not a single
5646960	5652320	point where the entirety of it is represented. But functionally, you could say that the organization
5652320	5657120	can converge towards sentience. And the more sentient it is, the more it's aware of what it's
5657120	5662240	doing, the more successful it's going to be, because it allows it to make a model of its
5662240	5667680	relationship to the world and act on that model. But a corporation, I think, is quite clearly not
5667680	5674480	conscious. So there is nothing what it's like to be a corporation. And it doesn't mean that
5674480	5678720	corporations could not be conscious in the future. Imagine that you replace the people that make the
5678720	5684480	decisions and information processing of the corporation gradually with machines. And this
5684480	5689360	gets one more real time until it gets entangled with the world in real time. And at some point,
5689360	5695040	it will discover itself as a real-time agent that is paying attention in real time. It's not clear
5695040	5700000	to me whether this will be human-like consciousness because it needs a control model of the attention,
5700000	5705600	because our attention is selective. And the selective nature of consciousness is quite
5705600	5710320	constitutive for it. And if you have enough computational resources, maybe you don't need
5710320	5714480	to be selective. Maybe you can do everything automatically without having this layer of
5714480	5720080	reflection and be good enough. So maybe consciousness is something that exists at an intermediate
5720080	5726160	level only. So it exists in systems that are complex enough to have this kind of coherence
5726160	5732880	creating a government-like conductor that is making sure that your free jazz is going to
5732880	5738800	be coherent and is going to be instrumental to what the organism needs at any given moment.
5739760	5745360	Or maybe you can create this coherence just by tuning the orchestra well enough and making it
5745360	5750320	more tight that you can do this in a biological system. And at some point, it doesn't need a
5750320	5756960	conductor anymore and just does everything in a mechanical way. So I don't know that. It's
5756960	5762640	an open question to me. With respect to the other aspect, whether we should give something
5762640	5768400	rights, the rights that we have as human beings are instrumental to the function of our own society.
5768400	5774480	They don't exist because people have an insight in what it is like to be a conscious being.
5774480	5780560	The animals that we are slaughtering in our afterhouses are conscious. It's quite clear and
5780560	5787680	obvious. They do act on the awareness that they are aware. The cat that I have in my household
5787680	5793120	is aware of the fact that she is aware and that I am aware. And we are able to communicate about
5793120	5798960	this fact, even though the cat is not that smart. But I think that the cat knows that the cat is
5798960	5805440	conscious. And this does bestow some rights on the cat in our household. But it doesn't bestow
5805440	5811760	rights on the cat in a similar way in society at large. Because the aesthetics of our society
5811760	5819120	sees animals as instrumental, as tools. And this is probably also true for AI. On the other hand,
5819120	5824160	if AIs achieve superhuman abilities, in many ways they already do. So they are
5825040	5830720	crassly subhuman in many ways. They cannot do many things that humans can do, like create
5830720	5835920	coherent world of meaning. But there are also things that they can do much better, like star
5835920	5842560	transfer or generation of imaginary dialogue with historical people. They are able to do this much
5842560	5850800	faster and with better quality than most people can do it. And so if you basically imagine that
5850800	5856000	you have systems that overcome their current limitations and become superhuman in all the
5856000	5860400	levels that mean, why would these systems be interested in having human rights?
5861120	5864720	If you're not going to live next to these systems anyway, you're going to live inside of them. We
5864720	5871280	will be their gut flora. Why would the organism that sees us as its gut flora at best, would want
5871280	5875440	to have rights that are akin to gut flora and instrument with the aesthetics of the interaction
5875520	5880560	of gut flora? Who cares? So why would a corporation want to have human rights?
5881360	5886000	That's not interesting to a corporation. A corporation is operating in a very different
5886000	5891040	domain and has much greater rights in this domain and abilities than a human being does.
5891040	5895840	So I don't think that this will ultimately be the issue. I don't think that the systems that
5895840	5901840	we are building will be necessarily subservient to us once we make them sentient and conscious.
5902400	5910400	Can I invite Manos Tomiso to ask his question? Manos is doing a PhD on AI.
5910400	5916400	The architecture is also associate professor at FAU. Manos, would you like to unmute yourself?
5917120	5922400	Hi, Yosha. Thank you. It's been very stimulating. So I apologize in advance. It's a bit of a long
5922400	5926800	question and seems to be very specifically formulated, but I'm interested in the broader
5926800	5931280	discussion about computational creativity in your earlier comment. First about Minsky's
5931280	5935840	positioning in terms of the part of the mind treats the rest of the mind as its environment
5936400	5942400	and how this is kind of relevant to that idea of the search space and how we position ourselves
5942400	5946880	in a search space if we're able to externalize ever a source from it with regard to discovering
5946880	5954080	something. So the specific, let's say, part of the question focuses on the neural language-based
5954080	5958240	models like Glide or VU-Gunplus Clip, which I've also been trying to work with a little bit.
5958240	5964160	From an architectural point of view, not so much a technical one. And what, for example, we begin
5964160	5972160	to perceive as a simple language prompt, a one word prompt, may in fact be much more complex than
5972160	5978800	that. And so, for instance, a prompt like a building or a window, even though the network would address
5978800	5984240	this with the same procedure, we would know that the former is a richer semantic representation
5984240	5989520	in terms of one's inclusion within the other. A window is meaningless without a building.
5989520	5996880	But with regards to the way that the network treats that, they could both be perceived as
5996880	6004720	a high level feature details, depending on, like a window by itself could be perceived as,
6004720	6010720	let's say, a high level feature within a broader building representation. But the same thing could
6010800	6016000	happen with regards to the way a building could be scaled and nested within a broader, larger
6016000	6021760	urban landscape. So all I'm saying is, if you have any comments with regards to this kind of
6021760	6027200	discrepancy, which seems to address, of course, the reductionist, maybe understanding of language,
6027200	6033200	but how perhaps this could be encoded in a different way. What we perceive as a simple prompt
6033760	6037920	is not necessarily a simple prompt. And a human is able to understand it, but the network
6037920	6043680	would be reading both of these terms on an equal terms. I'm not sure if that was clear.
6045280	6050480	The issue with the existing models is that they're not trained on the same reality as ours,
6050480	6057920	but on the representation that we have created. And this representation is inert. So, for instance,
6057920	6064320	GPT's language is not trained in the same way as our language is being learned. Our language is
6064320	6070800	being learned as a solution to a particular kind of problem. And that is how to transfer mental
6070800	6077520	representations across people and how to organize mental representations within our own mind to
6077520	6083840	transfer them. And this is achieved by mapping the representation, which mathematically is
6083840	6089040	something like a dynamic hierarchical graph into a discrete string of symbols.
6089760	6094320	Right? Language is always a discrete string of symbols. And the main reason why this is the
6094320	6099200	case is otherwise it wouldn't be learnable. And this discrete string of symbols that hangs in
6099200	6107280	this thin air between speakers has to be constructed and deconstructed or reused for
6107280	6112240	constructing a mental representation using limited resources, something like a stack
6112240	6117040	depth of not more than four, because while language can be defined in such a way that
6117040	6122000	it's infinitely recursive, our own mind is incapable of facilitating deep recursion,
6122000	6127840	because it only emulates it, right? So, it needs to be simple. And all the natural languages are
6127840	6135280	solutions to this design requirement. Find a learnable method to map mental representations
6135280	6141280	into discrete strings of symbols. And this is done in a collaborative process, right?
6141920	6147040	Basically, language is invented by groups of people, not just by individuals, for the most
6147040	6151120	part. There is no reason why an individual couldn't do this. You can, in the same way as you can play
6151120	6155520	chess against yourself, you can play language games against yourself and invent your own private
6155520	6163120	language. It's not an argument that I can see. It's plausible against that. But practically,
6163120	6170160	it's a tool to transfer information in a large degree. And GPT suites language is not the result
6170160	6175360	of this interactive learning. It's a result of looking at the linguistic utterances of people
6175360	6181680	as they are typed out in the internet in a non-interactive fashion. So, GPT suites doesn't
6181680	6187360	learn semantics in the same way as we do. We start out with understanding semantics indexically by
6187360	6193760	pointing at the features in our perceptual environment. And then we learn syntax, we learn
6193760	6199600	how to translate this into linguistic symbols. And then we learn style, that is, the particular way
6199600	6206400	in which linguistic symbols can be arranged to communicate efficiently and to convey additional
6206400	6215200	layers of meaning by the shape of our utterances. And in GPT 3, the order is inverted. GPT 3 basically
6216480	6222320	starts out with style and syntax and learns semantics as the long tail of style.
6223040	6229680	Right? So it's, in some sense, the wrong way around. And it's amazing that it converges at all.
6229680	6235440	There has been in the early days of computer linguistics, rich discussion with philosophers
6235440	6239680	who still haven't updated, who thought that you cannot learn semantics without interaction
6239680	6245200	context, without embodiment, without having symbols that are grounded in perception.
6245200	6251520	But GPT 3 shows that it's possible to learn semantics to some degree only by looking at language.
6252320	6257040	And you can see that it's semantics because you can ask GPT 3 for instance to perform certain
6257040	6262080	linguistics transformations or to add small numbers to each other and so on. And it's capable
6262080	6266880	of doing that, which is a semantic operation that has a causal structure that is being addressed by
6266880	6272960	an linguistic prompt. And GPT 3 is able to verify in some sense whether it was able to conform
6272960	6278080	to that specification. So these are proper semantics, but they are impoverished compared
6278080	6283600	to human semantics because there are the result of something like bubbling of
6283600	6288560	extrapolation only without interaction. But this doesn't mean that we cannot do this.
6288560	6293200	In principle, we can build systems that interact with the world and that are serving
6293200	6297280	instrumental purposes and satisfying their needs and doing this and that do on their learning.
6297280	6302240	It's just the present set of algorithms and technologies that we have are not very amenable to
6302240	6312880	this. Let me just push this a little bit further. I mean, I often because I think that the GPT 3
6312880	6318640	and the kind of text or the prompt based responses that you get out of Clip certainly
6318640	6322960	are interesting because I'm just wondering to what extent we ourselves are trained a bit like a
6322960	6327840	neural network in the sense that we have certain inputs. You go to school of architecture and you
6327840	6333520	are schooled in a certain way of thinking, you know, that's what you do. And so when we think of
6333520	6338240	something, someone says a house, then if I'm trained in the modernist thing, I will think about
6338240	6343440	the certain images, at least something will be conjured up in my mind that is quite controlled
6343440	6350000	in a way by the training that I've had. So I'm struck that actually maybe there are not that
6350000	6355120	there's more similarities there than we think, whether we have an automatic reflex about certain
6355120	6361040	things based on our conditioning. Maybe I could just, Bob, while you're thinking about that question,
6361040	6368560	show you a quick video of the kind of work that we architects have been doing using this.
6369360	6379360	So this is a work of an architect from Peru, who's now teaching. And it's using Clip and VQ GAN.
6379360	6383840	And there are a series of prompts, there are a series of pre prompts. So there are three very
6383840	6389360	progressive architects names were put in there. Zaha Hadid, Tom Main, Wolf Pricks, you probably don't
6389360	6394800	know these guys, but they're kind of Gary like slightly crazy guys, right? And then there's a
6394800	6401840	second prompt, which is the main prompt is futuristic Indian temple. And this is the kind of thing
6401840	6408960	that gets hallucinated by this thing. And I often wonder, you know, whether, yeah, my question would
6408960	6416720	be this, it wouldn't be fair to say that actually that we are trained, we are trained by our experiences
6416720	6422160	and our education as a form, obviously, indoctrination to think of certain images to conjure
6422160	6430800	them up in a way almost like Clip does. Okay, yes. So there is a big similarity in the way in which
6430800	6436320	these models work and the way in which our own mind works. Difficulty is the way in which
6436320	6443600	the GPS we got to these representations or a big gun. And it's basically the gun is fed lots and
6443600	6453120	lots of separate distinct images that are annotated with text as a reference to, for instance,
6453120	6457520	the subtitle of the image that the creator gave it or even to a complete description of what's
6457520	6465840	happening in the image. And by looking at millions of these images in batch processing,
6465840	6470640	doing statistics over these images, you build up the structure of the network.
6470640	6475680	And the network ultimately converges to an efficient representation of this latent space
6475680	6481040	of representations. And in our own mind, this representation is built in a slightly different
6481040	6487280	way. We train up layer by layer. We start out with an extremely limited reality. And this limited
6487280	6495200	reality in the first place is maybe it's similar to what's being described in the first book of
6495200	6500400	Genesis in the Bible. I think that the first book of Genesis in the Bible is misunderstood
6500400	6505840	by the Christians or mistranslated as a myth about the creation of a physical universe by a
6505840	6511760	supernatural being. And this also leads to the confusion of our culture of what that physics
6511760	6516400	contains, light and darkness and sky and ground and so on, right? These are clearly constructions
6516400	6521200	inside of the mind categories that have us to make sense of the perceptual patterns in a coherent
6521200	6525280	way. The fact that there are not that many ways in which you can arrange the perceptual patterns
6525280	6529360	doesn't mean that the reality is structured like this. It just means that if you have a brain with
6529360	6533600	these parameters, this is the best way to compress physics into a predictable model.
6534320	6540080	And so what you need to make sure, what you need to do to make sure that you can interpret reality
6540080	6547520	is first you need to figure out how to entice neural oscillators to make light, to represent
6547520	6554400	contrast. And this is basically the creation of light and darkness and how to separate the light
6554400	6559760	from the darkness. And then you arrange these contrasts along multiple dimensions and then you
6559760	6566400	discover the modalities of perception like vision and sound and you discover that the visual domain
6566400	6571520	can be arranged in a space and you can align the space with your vestibular system so you got
6571760	6578320	up and down. And you got a plane that is two-dimensional on the ground down and you got
6578320	6583120	a space that is three-dimensional on top of the two-dimensional one and then you have basically
6583920	6589840	the sky and the ground that you have constructed, right, created in your own mind. So the mind is
6589840	6595440	constructing these categories and then it discovers the materials, the solids and the liquids and the
6595440	6601120	organic shapes and the animated agents in the world that move around in it. And then it discovers
6601120	6606080	the features that it cannot directly interact with but perceive like celestial objects in the
6606080	6610800	background and then it discovers all the constructs, the plants and the animals and gives them all
6610800	6616160	their names. This is this gradual construction that happens during our cognitive development
6616160	6622480	where we train up our model of reality layer by layer and then last but not least we create a person
6623520	6629520	and this person is created in the image of this constructive mind as the conscious observer that
6629520	6635520	is makes sense of reality but it's slightly different. While it is a conscious observer,
6635520	6641760	it is created as man and woman, it's created as a human being that believes that it has a gender,
6641760	6644880	that it has a relationship to the world, that it's desires, it's human desires,
6644880	6650560	it's social embedding matter. And initially this is created often in the third person so when you
6651200	6657600	talk to small children they often start by referring to the organism that they are modeling
6657600	6662400	in the third person. And then at some point they start looking through the eyes of that character
6662400	6667600	and think they are that character and the original world creator that is modeling reality and creating
6667600	6675840	and shaping it becomes a subservient perception module to this personal human agent. And so
6676800	6683200	this gap in the creation of this new thing is represented in children losing their memories
6684000	6688240	and you have a baby you will often notice that they do have coherent memories they're also able
6688240	6695120	to talk about them once they start talking between nine and months and one and a half or two years
6695120	6700240	and then at some point there is a gap and they lose the access to the memories that they had
6700240	6706000	before that time because they constitute themselves as a new system that indexes the memories from a
6706000	6711760	new perspective. And I suspect this is what's being alluded to in Genesis. I don't know whether
6711760	6716800	it's literally true but in this interpretation whether it's a better interpretation than a Christian
6716800	6721600	one but it seems to be much more plausible to me that this is what's described there it's this
6721600	6727680	cognitive development of a system that starts to arrange the features into maps of reality
6727680	6732240	that build on top of each other become a more and more complex until you discover your own agency
6732240	6737840	and use this as a perspective to make sense of reality. And this is what you're not doing in AI
6737840	6742480	systems right now but there is no reason why we shouldn't be doing it ultimately and there are a
6742480	6746960	number of people which do actively think about this for instance George Steen and Bournemouth MIT
6746960	6752640	and others. Can I just pick up on the other question of kids because I think that's incredibly
6752640	6757040	fascinating for all sorts of reasons. There's a book by Kevin Wattle at Gautam when he kind of
6757040	6762880	he says that we learn to role play through being a kid you know we've what we learn to be the CEO
6762880	6767120	of a company by you know playing doctors and nurses and one of the cowboys and Indians of
6767120	6773920	God knows what else when you're kids and so which is interesting and I buy that the question that I
6775200	6781760	would want to put you is if we see ourselves as a model and see ourselves through that logic
6782400	6788240	what role does the actual model i.e. the doll or the teddy bear play in a kid you know because that
6788240	6796160	is in some sense is animated by the kid about a child what is what is the role of because that's
6796160	6800400	to my mind it's fascinating dolls and teddy bears how do you see their their role?
6804720	6809440	There is a thing that I noticed when I was in Madagascar they saw a lot of children
6809440	6816640	that lived on the street by themselves and the there were kids that took care of other kids
6817360	6824240	it was mostly girls who did this and I suspect that the dolls that you give our girls or that our
6824240	6833120	girls demand are a substitute for biologically adaptation that is that kids look after other
6833120	6838960	kids but the parents are blocking the fields or hunting or doing other things and often we think
6838960	6844080	that kids would be callous and could not be trusted with babies but maybe they can I've seen it in
6844080	6851680	Madagascar so I've seen little kids that were mostly girls that were barely strong enough to lift up
6851680	6857520	a baby because they were only like five or so and still seem to be able to take care of them full
6857520	6865280	time so I think that's an adaptation that we want to take care of others and especially of children
6865920	6871360	and that we want to interact with other agents and build a communion with them and the teddy
6871360	6877680	bears and dolls are a simple non labor intensive way of substituting for this.
6878640	6882720	Maybe I could put an architectural dimension to that what about the dolls house I mean because
6882720	6887680	that is an architectural space in which the doll operates how do you yes it's a play space and
6887680	6895280	the purpose of play is the creation of training data right so you use this to create situations
6895280	6900880	that could exist in the real world at dramatically reduced cost so you can't ignore the cost while
6900880	6905360	you're playing because you don't play for the expected reward you play for your ability
6906320	6912720	as a way of exploration and not for the exploitation for being able to use this later
6912720	6917920	and it's also something that you can observe in cats cats do play a lot and the purpose of play
6917920	6924240	in cats is that they're able to hunt better right and while they play exert a lot of energy but
6924240	6930880	it's mostly done because doing this in the world or there is more costly overall and the same thing
6930880	6935840	happens in human beings the reason why children are fascinated with doll houses I remember that it
6935840	6942320	was but I was even more interested with building virtual cities so I used to draw very big maps
6942320	6946960	that covered the floor of my room of cities with different houses in it and explored how people
6946960	6951120	would live in there and how goods and resources would travel in the city and I found this very
6951120	6957520	exciting and the the relational space in the doll house between the different members of the
6957520	6962880	family were not that interesting to me but I suspect that's because I'm pretty stereotypical
6962880	6968080	male in this regard I'm much more interested in systems conflicts and explosions than I am in
6968080	6974000	human relationships pretty fault and I only discovered the beauty of human psychological
6974000	6979520	structure and relationships later in my life so maybe just to follow up so I would to give Matt
6979520	6984000	a chance to ask question but just follow up so where does the architectural model fit within
6984000	6988320	this logic I mean you're doing your kind of sim city for and then you've got the kids doll's house
6988320	6993440	and things how do you see the what do you I mean of course at one level the architectural model is
6993440	6999600	just a scaled down model of the potential building but do you see it invested with any other potentiality
7001120	7007200	I think that's tied to the notion of aesthetics and aesthetics is what you get when you take your
7007200	7011360	the preferences that you start out with and extrapolate them into a sustainable world
7012240	7016960	you're basically systemic thinking where you add one more layers until you discover enough
7016960	7023440	symmetries to digest your initial preferences and make them instrumental to to achieving this
7023440	7028640	aesthetics but it's also apparent in moral development we start often out with moral
7028640	7034640	reflexes certain priors that we are born with innate tendencies to consider a certain behavior
7034640	7040880	to be moral or immoral full stop unconditionally not because we understand what it's good for
7040880	7045840	but because we feel this feels moral or this feels immoral and this can also misguide us
7045840	7053200	because ultimately ethics is about the negotiation of conflicts of interest under
7053200	7057280	conditions of shared purpose and this requires that you understand the aesthetics the world
7057280	7064000	in which you want to operate behavior is only good or bad if you can connect it to an expectation
7064560	7070240	of a world that is worse or better and to be worse or better you need criteria for what makes
7070240	7076080	the world worse or better and this I would say that to be good it needs to be sustainable it needs
7076080	7085440	to actually work and it should have high complexity and complexity is in contrast for instance to
7085440	7091360	friction that is exerted to violence you want to minimize the friction and waste created to violence
7091360	7097840	and so on so once you discover this train of thinking and you get older many of your initial
7097840	7104000	moral convictions get replaced by the larger aesthetic and the same is true for architecture
7104000	7111680	by architecture and you design a building or a city or a house or a room is all about how to fit
7111680	7116480	the space that you're operating in where you make your local decisions into a larger aesthetic
7116480	7120240	and so the deeper your understanding of the world the better your design has a chance to be
7120960	7126560	and this is what makes architecture so interesting to us I think that is that it's about seeing the
7127520	7131760	the human world that we are part of at the greatest possible depths that we can perceive
7132480	7138000	and extrapolate the games for as long as we can make them and then design our life inside
7138000	7144880	of this larger space and build things at the largest scales that we can maintain like cities,
7145440	7150480	nation states, society, civilizations inside of these aesthetics to realize them.
7151360	7155920	Yeah I often say myself that I think architecture is less about the literal design of buildings but
7155920	7163840	about imagining a better world. So we have a question from Matt, a second question from Matt.
7163840	7170720	Do you like to ask your question? Sure just another quick maybe a jump back into a bit more
7170720	7176640	maybe more technical things. I'm always struck by these these images that have become really common
7176640	7181600	of neural networks as little dots connected by lines and you showed the cortical columns and
7181600	7185760	you showed a lot of interesting graphics that kind of looked like that but I've also recently
7186880	7192000	been struck by the neuromorphic computing stuff that's going on at Stanford and a few other places
7192000	7198320	about dendritic computing and sort of new advances and thinking about and and even starting to see
7198320	7202160	how what we once thought were just wires that connected all these different things and we
7202160	7205680	talked about connections are actually doing pre-processing in very interesting ways and I'm
7205680	7209920	sure you're you know a lot more about this than I do so I'm very just interested in
7209920	7215040	in what's what's going on there and how that changes these questions of how much energy it
7215040	7219680	takes to do the computation and what maybe the future form factors might be on this kind of thing.
7220640	7225680	We also have groups at Intel that work on neuromorphic computing for instance we have the
7225680	7233040	loyalty architecture which is a chip that uses a model of spiking neurons for modeling perceptual
7233040	7238720	content and so on and this is in some sense compatible with the neural networks that exist
7238720	7246880	because you can translate the traditional neural networks and the many circumstances
7246880	7252160	into the spiking neural representations and vice versa but these spiking neural representations
7252160	7260000	are more efficient with respect to power usage and some the conditional algorithms than others
7260000	7266480	and so there will probably be useful applications of spiking neurons but the reason why the neurons
7266560	7271760	in our own brain are spiking is also in part because the messages that neurons can send to
7271760	7278720	each other are limited in their nature. Neurons cannot produce continuous signals they have to
7278720	7283440	produce little pulses and so you have to encode the information into little pulses
7283440	7290000	in the timing and frequencies between the pulses. There is also an issue when we think of neural
7290000	7296640	networks as they are represented in our technological system they are mostly circuits
7297200	7304160	right so they are similar to the circuits in your present CPU which represent logical gates
7304160	7310400	which implement logical operations and the connections is stored in the weights so the
7310400	7317680	parameters in GPT-3 these are all weights little factors by which the activation that is sent
7317680	7323360	between the different nodes is being multiplied and the equivalent in our brain to these weights
7323360	7329440	are often seen as the synapses and the synapses come with different types the different neural
7329440	7334080	transmitters in some sense are message types that are connected to different synapses and
7335120	7343120	the big network structure is what we call the connectome the circuitry that exists between
7343120	7349200	the neurons and there is hope that if we manage to digitize the connectome at a sufficient resolution
7349200	7354320	that we might be able to upload a brain and simulate it in a computational subscript and
7354320	7359040	in principle that should be possible in practice it doesn't work so far so even the models of C
7359040	7366560	elegans which is an amatode that only has a little more than 300 neurons if you completely digitize
7366560	7372880	the elegance to my current knowledge I'm not sure if something has happened in the last couple
7372880	7380000	years these models don't work in the sense that you simulate the worm with these digitized neurons
7380000	7385040	and you can digitize the connectome the worm doesn't move like a worm does it just twitches
7385040	7390080	and has a seizure basically and that's maybe in part because the neurons are more complicated in
7390080	7394640	the worm because there are so few of them they basically exploit certain resonance effects that
7394640	7400320	maybe your model doesn't so maybe it's more of a dynamical system that is more difficult to model
7400320	7404960	and there's another problem is that you cannot actually get the message types right because
7404960	7409600	at the level at which you do the connectome you cannot model all the vesicles that extend
7409600	7414960	the different neurotransmitters you don't know actually which synapse is sending which type of
7414960	7423840	message this is also a limit but there might be something worse going on in the 1960s and 70s
7423840	7428320	there was a series of experiments mostly in the Soviet Union but some of them also in the US about
7428320	7436400	RNA based memory transfer and the idea here is that you take an nematode or a C-slug or even a
7436400	7443520	rat and you teach them something by our current conditioning and then you put a new tissue into
7443520	7448320	a blender extract the RNA and inject the RNA into a different organism and the new organism knows how
7448320	7454720	to do this this is completely wild because if this works and it's disputed whether it actually
7454720	7458400	works of how well the experiment replicates even though some people have done that again and so
7458400	7462560	on the people that verb on this tell me it's difficult to get other neurosenters to listen
7462560	7468400	because it's incompatible with the idea that the weights are stored in the synapses right if you
7468400	7472080	if it's really the connection between your neurons and you put the nerves just into a blender
7472080	7477680	this goes away how would you be able to transfer memory in this way this cannot possibly work
7478720	7482800	because the RNA that you inject in the brain is not localized it would get into many many
7482800	7489760	neurons at once so how does each neuron know which parts of the RNA to use and if you take
7489760	7495280	this idea seriously I started thinking about this and now I'm thinking about making some
7495280	7500560	simulations how deep does the rabbit hole really go it would mean that the individual functions
7500560	7505440	that your neurons learn are not unique to the location of the individual neuron but they are
7505440	7511600	global functions so the RNA is basically you can think of it as a little magnetic tape that the
7511600	7518480	neuron can mix and match and create more of if it's useful and share with all the other neurons
7518480	7525360	just across cell boundaries you share the RNA and you copy them like a covid virus and you use this
7525360	7530800	function to respond to certain patterns in your environment so the neuron is not reacting to its
7530800	7536160	neighbors that could come into particular kind of connections but it's mostly connecting to a
7536160	7541360	temporal and spatial pattern that arrives at a certain function regardless of where the neuron
7541360	7548160	is in the neural cortex and so it's more like a cellular automaton a neural cellular automaton
7548160	7552880	and this certainly allows us to explain a few things that seem to be going on the brain that
7552880	7557600	are difficult to explain with synapses for instance if you destroy synapses they often
7557600	7562560	be grown exactly the same way without retraining there's another phenomenon that is
7563200	7568960	you notice a certain mental representation in a particle area pinpoint it and the next day you
7568960	7574880	look and it has moved it might have shifted a few millimeters or it has rotated so how would this
7574880	7579840	done if it's in it's stored in the synaptic connections there's also the question of weight
7579840	7584400	sharing like a convolutional network is sharing weights and you probably need something like
7584480	7589040	weight sharing to perform a mental rotation where you have the same operation on many parts of your
7589040	7594800	mental representation in the same way how would you do this are you training the same function
7594800	7600400	again and again in different brain regions I hope it's always the same it's difficult to achieve
7600400	7605520	right so we don't know a really good plausible biological mechanism for this but this RNA based
7605520	7611920	memory transfer could be part of the story and this is something that is at the boundary of what's
7611920	7618400	currently being explored still and it's I think it's not completely implausible and if we want to
7618400	7623520	make a model of how this works we would need to use a different metaphor than our current biological
7623520	7630080	neurons but it doesn't mean that you have to use this because the brain is solving problems that
7630080	7635360	our computers don't always have to solve for instance long distance connections in the brain
7635360	7640720	are extremely difficult to make and you cannot really address neurons this way so random access
7640720	7644560	is very hard in the brain you need some kind of routing network that needs to grow and learn how to
7644560	7649600	route it's not an issue in our digital computers because sending information across the memory
7649600	7654400	of the computer is trivial so there are many things that we can do very easily in our digital
7654400	7658960	computers that are difficult to achieve in the self-organized state structure of the brain
7659760	7666240	and so it's it's not quite clear how much we need biological like structures to achieve the same
7666240	7673120	functionality but to me it's certainly very exciting to explore it. That's fascinating I think the
7673120	7678800	questions about drift and neuroplasticity and things like that that come from that are really
7678800	7682880	interesting it makes me wonder if some of what we're looking at today will seem very obsolete
7682880	7689920	soon in terms of these these models that seem to be so so human like with the you know in terms of
7689920	7693760	being able to hallucinate imagery and all that kind of stuff there's like a piece missing
7693760	7698720	that might be that might come soon from a hardware model. Yeah I saw that too but then I'm surprised
7698720	7707760	by what Gleit can do and Dali and of course. Right so when you add energy to it though I mean how
7707760	7712400	much energy it takes versus a brain which we walk around and we feed vegetables to and it can do all
7712400	7716800	that too like you can't I mean that's that's where I think that the question that for me that's where
7716800	7721280	the question became very much more significant it's like oh wait but there's a whole other
7721280	7726080	calculation here of how are we doing all of this in our tiny little brains maybe there's something
7726080	7732400	there for I think that this is misunderstood I think that a human brain is super expensive to
7732400	7737200	feed it needs enormous amounts of energy to feed my brain you need like four hectares of land you
7737200	7742720	can put so many solar cells on these four hectares of land basically people underestimate how difficult
7742720	7748640	is to pack the energy that my brain needs into sandwiches and to extract it again right so this
7748640	7752480	is the way that you need to look at also training my own brain is super expensive right it takes
7752480	7759760	decades and generations before that to prepare things for my own intellect and so on to get
7759760	7766480	them in there so human brains in my view are super expensive and that's why we can use something like
7767520	7773680	clip and V2 again that we only train once at at low prices like training GPT-3 costs like 20
7773680	7779760	million dollars and now even that's because computational advances go down and it's been
7779760	7785120	trained by reading way more text than a very large group of people could read in their life
7785120	7791200	so it's basically getting people to read 45 terabytes of text would cost much more than 20
7791200	7798880	million dollars right tweeting them for long enough to make that happen and the system that is making
7799600	7805200	generating the text costs so little that open air lets you do it for free if you want to only
7805200	7809920	use a little bit of it right so it's able to produce output that is at the level of hundreds
7809920	7815840	of copy editors for free right and why that's not as good as a conscious copy editor who understands
7815840	7822400	the world it's quite amazing what it can do already okay thanks for that perspective yeah
7822400	7829440	that's interesting thank you i also i'm a little bit provocative uh but uh yeah i think it's something
7829440	7836320	to be considered right these 18 watts of your brain uh they uh if you compare them to the 80
7836320	7842720	watts of your macbook the 18 watts of your macbook are super cheap and the 18 watts of your brain are
7842720	7851680	super expensive i think we're gonna have to think a lot more about that i think it's your
7851680	7858000	provocation that is so exciting actually uh yosha i want to get this question from the chat now
7858000	7864320	going back just to say mentioned to everyone that yosha was was was born in weimar and where the
7864320	7868960	Bauhaus came from and then desau is where the Bauhaus moved of course there's the building
7868960	7874240	by water gropius and so on and we have at least two people here who studied there including uh
7874240	7881680	vasco who um has got a question vasco is now a professor in in bangladesh and um uh his question
7881680	7885520	is well i think it's one that you might have predicted elon mass suggested somewhere that we
7885520	7891360	live uh do we do not live in a base reality but in a simulation he even puts the probability of a
7891360	7900960	billion to one what's your view i think that elon's argument rests on the notion that the simulations
7900960	7905280	that we are building for for computer games are getting better and better at some point there will
7905280	7912720	have a fidelity that exceeds our ability to notice whether we are in a simulation or not so we came
7912720	7917120	at some point probably create vr's that are so convincing that we will not be able to notice
7917200	7922240	whether we are in a vr or not and we are not the only ones for our building simulations like this
7922240	7928400	so for any given being that finds itself in some kind of reality that looks real there will be many
7928400	7933680	more that at the same time will be in simulations right because many universes can contain many
7933680	7939760	more than one simulation so our universe probably contains many simulations of of a universe that
7939760	7944880	looks like ours and therefore the probability for any given observer to be in a simulation
7944880	7951120	is greater than the probability than to be in base reality and what this argument ignores is
7951120	7955920	the fact that it's very hard to make a simulation that actually has the fidelity of the physical
7955920	7962480	universe but if you make a simulation of minecraft and minecraft that's feasible because minecraft
7962480	7968720	itself is so poorly resolved but our universe has a lot of structure that is required to produce
7968960	7976080	dynamics and if you build a simulation of say our solar system and the dynamics of our solar system
7976080	7983040	at a level that is going to go down to elementary particles you will need to have a computational
7983040	7990240	capacity that is larger than our galaxy by a very considerable amount so in practice I don't think
7990240	7997040	it's feasible to put simulations of our universe into our universe at an arbitrary level of fidelity
7997040	8003600	and so I think that I'm much more biased to think that we are in base reality than we are in a simulation
8007120	8014160	this is fantastic there's one question here that in also in the chat from Grant Castillo
8014160	8019120	and I don't know what he is do you think Gerald Adelman's extended theory of neural
8019120	8027680	neuronal group selection can be used to create a conscious machine are you muted
8032400	8033680	one moment yeah
8037120	8041760	I hope that the background noises are not too high because my family woke up it's now interactive
8042320	8052240	the kids are playing and so on and so I I think that the idea of the neural Darwinism
8052240	8057760	that Adelman came up with is a very interesting one and I suspect that our own mind is the result of
8057760	8063840	such an evolutionary competition of different organizational forms right there could be many
8063840	8070080	possible proto-consciousnesses that compete until one of them establishes itself as the
8070080	8078000	government of our own mind and so instead of giving your your system a blueprint on how to
8078000	8083120	build a mind you just set up the conditions for an evolution for the best possible mind that you
8083120	8089440	could have and of course this evolution is rigged by evolution so you set it up in such a way that
8089440	8097360	the evolution usually goes out ends up in a certain way but the nice property of when you design
8097360	8101200	a system evolutionary by not giving a specification of what to look like but what
8102400	8106800	the function is against which it should evolve is that when you disrupt the system or give it a
8106800	8111040	different environment that it will very often come up with a viable solution under these new
8111040	8116960	circumstances so the solution is much more robust if you define it in terms of evolution
8118240	8123280	but it's a speculative idea so I don't actually know whether our mind is evolved even though I
8123280	8127280	think it's more plausible than it's not individually evolved in every individual brain
8128160	8136000	and it's definitely an interesting notion to to use evolution is basically whatever you use in
8136720	8141680	computer science then you don't know in which direction to go it's a blind search it's the
8141680	8148160	fallback it's the baseline and it's quite natural that we would use evolutionary methods if we don't
8148160	8152240	have a specification for the best possible mental organization that we just evolved one
8153360	8163760	so do we have any further questions in the chat we have some very interesting characters here I'd
8163760	8168000	love to try and draw out Daniel Bolliger who's one of the leading AI architects in the world
8168000	8172400	we'll see where he can have a question or indeed we had Sanford Quinta who's one of our leading
8172400	8178640	theorists who's a particular interest in neuroscience I'm wondering if I could I could put them in the
8178640	8180000	spot and ask if they have a question
8187360	8191120	but when you're done it's also good because I think I need to go and have some breakfast
8191120	8192560	yes and start my day
8195600	8198160	thank you I mean this has been fantastic you know I
8199920	8204480	I actually I've got to say that I think you're sure you are more of an architect than you
8204480	8208480	actually think you are you have a way of thinking that's very similar I mean obviously you work in
8208480	8213200	a different domain but I think the the kind of inventiveness and the the iconoclasm of your
8213200	8217760	thinking would be go down very well in an architectural scenario so and I sometimes
8217760	8222400	with I never escape you know you never escape your background in the way you you might try but in
8222400	8228480	the end you you find yourself conditioned I'm conscious of being a child of a family of architects
8228480	8234160	my grandfather was not an artist he was an architect he built most of his life hospitals
8234880	8240640	and this is the design process that is instrumental to serving a function but a function in a larger
8240640	8245760	world that he was very deliberately trying to understand and operate in but it was a world
8245760	8250800	that he understood as being his own world it was a world that he often found himself to be in
8250800	8256880	opposition with for instance in Nazi fascism or also in eastern Germany but it was also the world
8256880	8262080	that existed and we need to deal with and build the best possible things in and for my father it
8262080	8267840	was different it was a world that he fundamentally rejected and so in some sense to be an architect
8267840	8275040	you need to embrace the world that you are in and build within it and to to take roots in it and
8276080	8281200	this is in some sense something that also haven't been successful in when I was young so I decided
8281200	8286960	not to become an architect but to become an explorer well I mean I think one one of the
8286960	8291680	comments that was made and I always think about the Steve Jobs and his response when he was
8292160	8298240	he was asked a question by Steve Wozniak and Steve Wozniak said well but what do you do exactly
8298240	8302480	because you don't code you don't do this you don't do this and he described himself as being
8302480	8308080	a bit like a a conductor of an orchestra you know in a way that's how I see architects in
8308080	8312240	the sense because we don't have any specialism you know we are basically we coordinate these
8312240	8316640	different sort of a or choreograph these different sort of skill sets and I think that's really what
8316640	8322640	it is so in many ways you know I I can see a direct comparison with how you position yourself
8322640	8327840	in that sense I mean I I think it's a very it's a very similar sort of position and but I you know
8327840	8332160	I think that some of these these these comments that you've raised Joshua they're absolutely
8332160	8336640	fascinating I think we need time to digest them and fit them in the system what I would love to
8336640	8342240	do above all especially with this particular discussion is to try and find a way of publishing
8342240	8346160	the transcript because I mean I think this book that you have to write you must be written because
8346240	8351920	I think you've got some fabulous fabulous thoughts that are really creative and original and provocative
8352720	8356880	so you know I really appreciate so I appreciate so much your your time and I let me we should let
8356880	8361760	you go look after the family now but this is I think almost like we've just opened up a discussion
8361760	8365920	and I hope that sometime in the future we can we can take that further and and think through
8365920	8371280	these kind of questions because your responses have been very generous and very really provocative
8371600	8376720	and stimulating and I feel like you know although we have to pull this we draw this question this
8376720	8381360	session to a close it's almost the beginning of something else that we can look forward to so
8381360	8387440	I just want to thank Joshua for for fabulous I mean I want to recommend his all his online talks
8387440	8392880	as well to have a look at that there is a body of work out there that is that is this hugely
8392880	8398720	provocative and hugely stimulating which I am excited by and I also maybe I could finish with
8398720	8403520	one one simple question but no I started off the the discussion by saying that I think there is a
8403520	8408960	a kind of let's say an emerging theory of intelligence that that is developing in this
8408960	8415920	kind of strange area where we're computer science and neuroscience and the world of the commercial
8415920	8423280	world and the academic world is coming together do you also see that glimpse of something emerging
8423280	8428880	some discourse some theoretical debate that is radically new and radically provocative
8428880	8435440	clearly that's why I went into cognitive science in the hope of being part of this new
8435440	8441520	synthesis happening between neuroscience and philosophy and artificial intelligence and
8441520	8448800	linguistics and psychology and maybe the arts and I think at this moment the synthesis is still
8448800	8454800	very partial and in part that's because we teach our model makers and our observers in
8454800	8460080	different departments we don't bring them together so we have people that are very good at making
8460080	8465760	formal models that can be tested and we have people that are very good at making observations
8465760	8470080	and reflecting about the world and seeing it very deeply and these people rarely talk
8471280	8476240	and they're rarely think together and this is what excites me to work in this area where
8476240	8481440	these two areas intersect and maybe architecture is the right frame of looking at this.
8482800	8488320	Nia thank you very much for inviting me I think it was a great conversation to have had today and
8488320	8497440	very grateful for your beautiful community and for allowing me to talk about these ideas with you.
8497440	8500800	It's fantastic I'm going to finish with one comment which is because I used to be a lesson
8500800	8508080	translator and the word I should just say the word computation means to think together and I
8508080	8511840	think this is what's been happening today there's been almost like a neurons within neurons a kind
8511840	8517760	of global brain it's been fantastic. Yosha fantastic wonderful thank you for your time and sorry for
8517760	8521760	getting up so early but this has been a huge contribution to the architectural community
8521760	8526560	and I hope that I've helped draw your the attention of your ideas to architects out there because I
8526560	8531040	think they're incredibly provocative ideas and I think they've a huge contribution to make to
8531040	8536480	architectural thinking itself so thank you Yosha thank you and thank you so much for this it's
8536480	8541120	been fabulous and thank you wonderful day thank you and thank you for those team that put this
8541120	8546320	together a digital futures team we can't operate without your help thank you so much and see you
8546320	8551920	next week thank you everybody thank you bye
