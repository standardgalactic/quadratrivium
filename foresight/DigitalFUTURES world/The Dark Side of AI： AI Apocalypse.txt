Okay, shh, no more.
Hello and welcome to the first session of 2024.
This is sightly out of sequence.
It's part of our doctoral consortium series from last semester.
Our final session had to be cancelled the last minute,
but we're delighted to have a follow-up session
to complete the series on the theme of AI apocalypse,
the series that was called the dark side of AI.
And all of the previous sessions are uploaded
onto our digitalfutures.international YouTube channel.
And I would say that from that, the first five in the series,
that we became a bit more, I guess, lenient in some way.
I started off by saying, well, actually we do need to worry about AI.
And over this course of the series,
which is actually fascinating because we had a series
on questions such as copyright and so on and so on.
I think people softened up a bit and said,
no, we don't have to worry about AI.
Today I'm really delighted to have Eric Kessel here with us.
Eric is a designer, educator, writer,
and host disaster expert, professor disaster, I guess.
And Eric takes a rather more kind of concerned attitude towards AI.
He was formerly the director of the Sustainable Environment Design
major at the College of Environmental Design at UC Berkeley.
He's currently a special program instructor
at Harvard Extension School.
And Eric really has made a name for himself
because using the kind of lens, shall we say,
of disaster theory, disaster studies to look at things.
He recently published what I think was an extraordinary article
in Design Intelligence, looking at the question
of what the impact of AI would be on the profession.
Today then, Eric is going to make a presentation.
We are going to have, I will have a short discussion with him.
And then we'll open up to questions from,
not only on the Zoom audience itself, but also from YouTube.
So feel free to put in some of these questions.
Probably not as long a session as sometimes some of our sessions,
but this is, I think, going to pick up as we go
because I think this is an absolutely fascinating topic.
So Eric, welcome.
It's great to see you.
And it's a great way to kick off the new year
with a bang, shall we say.
AI Apocalypse.
Yeah, well, thank you for having me.
I appreciate the chance to talk about it.
I've actually entitled my lecture,
AI Apocalypse, question mark.
I think it still remains to be seen,
and we have some agency in what happens
in the future of design, architecture, and AI.
But first, let's break this down.
We're going to go through an introduction,
talking about crisis and disaster,
how to cultivate a disaster lens, what that looks like,
then deconstruct some myths on AI and architecture,
and then finally wrap it up with the brighter side of disaster
because there is one, and fundamentally an optimist.
So I hope everybody sticks around for that.
So a bit about me.
I've done a lot of things in my career.
I've had a pretty eclectic experience,
been an activist, a humanitarian builder,
periodically an architect, a construction manager,
a pre-fed or lewd for graduate school,
a disaster responder, a kind of design,
Cassandra, you might call it,
a writer, radio host, professor, and academic director.
And that brings us into 23-24,
which was an interesting year for me
because a lot of these things effectively came together
to launch this recent mission around AI and architecture
and the potential consequences for it.
My work has been all over the place,
but I think I'm probably principally known for two things.
One, writing a book called Down Detour Road in 2010
at the height of the Great Procession,
and that was inspired by a different kind of crisis.
I read an article in The Nation, I believe it was,
or maybe it was The Guardian,
that talked about the relative unemployment rates
for different professions,
and I was shocked, slash not shocked,
to find out that architects were at the bottom of the list
out of, you know, 700-something professions,
or 380 professions, I'm sorry,
but they were facing seven-fold, eight-fold increase
in unemployment claims, and, you know,
this didn't make a ton of sense to me.
And my read on it was that the profession was in crisis.
I mean, it was a recession, so everybody was in crisis,
but architecture was in its own particular crisis,
and to me, it was a crisis about value.
People had ceased to really value architecture
was what explained that for me.
I wrote a book about it called Down Detour Road,
which the premise of was that, you know,
people had ceased to see the value in architecture
because I think architecture had ceased
to see the value in people.
During the deconstructivist period,
we got into a lot of formalism and distance ourselves
from the problems that people deal with in their everyday life,
and, you know, that led to a lot of openings
and hopefully an optimistic message about architecture.
Secondly, I'm probably best known for my post-disaster work,
which began while I was still a student.
This is a picture taken of me right before I went down
from my first assignment in Biloxi, Mississippi,
where I was working with the Biloxi Gulf Coast
Community Design Studio under David Perks.
And it was an education, I think,
that put me in touch with the real power of architecture.
From there, I went to Haiti with Architecture of Humanity,
and that was a furtherance of my design education
and understanding about what the real power of architecture
can be when it's pointed in the right direction.
And it was blessed to be surrounded by an incredible team
from all over the world.
It was about a third Haitian, about a third Haitian diaspora,
and about a third international,
which in itself is composed of architects from 10 countries.
And we put together a pretty incredible program
of community-based design,
working with survivors of the earthquake in 2010
to rebuild schools, clinics, whole communities at times
to offer training.
This has been the bulk of my practice, actually,
is helping people through disaster
and helping them imagine better futures
because there's always the potential
for a better future after disaster.
So from there, I went to Japan
and assisted with that program under a similar remit.
Subsequently, New York, the Philippines, kind of all lower,
and that work was enough to earn me a kind of dubious moniker
of being architecture's first responder,
or so-called by the daily beast.
I retired from field work in 2015
after the Nepal earthquake
and turned my attention to teaching first at Washu
and then subsequently at Berkeley
and most recently at Harvard.
And in those programs in varying ways,
I teach about disaster and resilience
to try and bring those lessons
and those conversations forward into the practice of architecture
and the teaching of the practice of architecture and design,
among other things.
And through that work, I developed,
I guess you could call it a theory of disaster
and how to look for it, how to understand it,
how to see the world through that particular lens.
And all of this came together last year
when I was asked to write an article
for Design Intelligence Quarterly,
the article that Neil mentioned in the introduction.
And it wasn't originally supposed to be on AI,
but between myself and the editor there,
we agreed that it would be.
And that launched an exploration
and it was fueled by skepticism, I think.
At the time, this would have been February of 2023,
there was a disconnect between what was happening in the world
and what was happening in design.
I mean, I suppose there typically is,
but this one seemed a bit more ominous.
In the world, we were hearing messages about,
you know, AI is going to destabilize everything
and the World Bank and the IMF
were predicting huge job losses and massive change.
Professors at Wharton and top business schools
and economists were, you know,
looking at this as a very, very serious development
in the future of work.
And then there was, you know, the design world.
So, you know, I read the same design rags
as everybody else, I suppose.
So, you know, we kept hearing messages
from design leaders to this effect.
You know, there's nothing that can compete with architects.
This one from Shane Berger, you know,
the design process is going to remain fundamentally human.
There's this kind of limited capabilities.
And I wanted to understand for myself where the truth lay.
I suspected it lays somewhere between those two polarities.
And, you know, I asked if I could explore this
through this article for design intelligence
and they gratefully said yes.
So, you know, I sat down to figure out, you know,
what exactly I thought the impact was going to be.
And the prevailing line at that time was that, you know,
AI is going to automate the simple things.
It's not going to automate the more complex work.
So, for me, the greater challenge was, you know,
how do you envision or propose that AI might actually,
you know, replicate some of that higher level work
that architects and designers do.
And I borrowed something from Phil Bernstein's book,
Machine Learning, a framework for understanding
the relative cognitive complexity of different tasks
that exist within an architect's day.
If you've read that book, if you haven't read that book,
you should. It's a great book.
But Phil has this framework, essentially,
for ordering projects between, you know,
a procedural, like really kind of task,
repetitive task sort of things,
up to integrative and perceptive.
Those are the higher level cognitive functions.
And he provides us with a brilliant map, essentially,
for where all these things occur within the architectural process.
And just to make my life difficult, I said,
well, you know, what if we aspire to get it
to replicate the harder parts rather than the easier parts?
I figured the easier parts would figure itself out.
To me, and I think to Phil as well,
you know, the hardest parts are the integrative stuff, right?
It's the vision. It's being able to sit with a client
and context and understand through typically inarticulate words
what that vision is actually going to be
and to bear it out in the form of an idea
for a building or something like that.
And as a proof of concept that, you know,
I was initially made for myself just to make sure I knew
what I was talking about. I developed a video,
which I think, you know, also mentioned in the beginning,
but it's attached to the article.
You can find it on my YouTube channel,
or you can find it on Design Intelligence.
But I'm going to play a short clip
just to introduce what I'm talking about here.
Hilda told me a bit about your project,
and I'm excited to learn more.
Can you share your vision for it?
I'm looking to build a modern, sustainable home for myself
and be environmentally friendly. It's important for me to...
So what you're looking at, and this goes on for about 20 minutes,
is two GPTs set in opposition to each other.
And they've both been programmed with personalities.
So I said to the model, like, you are the client,
you are a successful tech executive,
you are a mother of two,
you have a passion about kayaking, you know, this sort of thing.
But I didn't give her any specific information necessarily
about the architectural process or anything like that.
And I did the same thing with the gentleman on the left,
who was the architect, right?
He was an architect, he was 55.
You know, he went to school at Columbia, this, that,
and the other thing, I didn't give him any instructions
on what being an architect actually meant.
And Hilda told me a bit about you.
Let's fast forward through that.
Through that conversation,
GPT was able to generate a design brief
based on the interview that the client had.
Truthfully, it was just GPT having a conversation with itself.
But nonetheless, based on that exchange,
which was totally autonomous, it generated a design brief,
which was then able to convert to image prompts,
which went into mid-journey.
Once mid-journey five debuted,
I was able to actually get image recognition to play along.
So Carla, the client, could actually look at the design options
and respond.
That was a little disarming.
The really alarming part were all of the emerging phenomena
that came out of this.
I guess emerging capabilities is what the AI world calls them.
But chat GPT illustrated some alarming knowledge
about the process itself.
So, you know, once it had gone through this design process,
I asked it to produce a door and room schedule,
which it did.
And, you know, oddly, somehow knew that, like,
bathrooms should have one window and not two,
and that a powder room might be the exception.
A powder room might have zero windows as opposed to one.
So, you know, it was picking up on all these lot of things
that might be known to an architect
or might even be known to a layperson.
But I certainly did not expect that the model would be able
to extrapolate all that information just from a 20-minute
conversation between an artificial architect
and an artificial client.
It did the same thing with budget.
It came up with a budget for 2.2 million.
Again, no extraneous information.
I mean, it inferred that from the site
and from whatever Carla the client was saying to this architect
that she wanted out of her house,
checked with a few contractor friends
and, like, a lot of this AEI stuff, you know,
wasn't wrong, could have been better,
but it was in the ballpark.
So, this immediately struck me as a disaster,
because disasters typically happen
when the perceived threat is much different
than the actual threat.
That's what gets us into trouble as a species.
So, in my estimation, you know,
I didn't believe the doomsayers that were saying that,
you know, this is the end times,
but I didn't believe the Pollyanna stuff
that I felt was coming out of a lot of the design professions.
The truth was somewhere in the middle
and didn't look great.
But let me flesh out what I mean by disaster lens
to shed some light on that.
So, how do we cultivate a disaster lens?
I want to teach my students that there are things
that you can look at that speak to the growing vulnerability
and precarity of a particular context or situation, right?
So, if you're looking at a natural disaster,
like an earthquake, fire, hurricane, that sort of thing,
you might look towards, you know, neglected infrastructure,
trending towards decay, you know,
bridges and power stations
that should have been replaced a long time ago.
You might also look to the emergence of patchwork solutions.
So, if instead of replacing the broken levee,
we just keep building it two feet higher over and over,
that's usually a pretty good clue.
A widening or deepening of the zone of vulnerability.
So, 100,000 people living in a fault line,
that could be a problem.
That can be a disaster.
That city swells to 3 million people.
Then you've got a really serious disaster on your hand.
Same fault line, just different zone of vulnerability.
Widespread irrational and credibility.
This is a tough one to pin down,
but basically it's the anti-chicken little bone.
The people who believe it can't happen here,
and that is an emotional and a psychological belief
that isn't particularly grounded in any evidence or analysis.
It's just the way that people feel about things.
All of these things taken in their sum, or even one by one,
don't necessarily constitute a disaster.
This is merely the framework,
the things that set up the possibility of disaster.
I liken it to a tornado watch and a tornado warning,
and then I find that people don't really understand what that is,
especially if you're outside the United States.
So, I've actually happened upon the taco watch,
and the taco warning is the way to explain it.
So, taco watch is like, you have all the ingredients for a taco,
but there's no taco, it's just a bunch of ingredients laying around.
The taco warning is like, we have a taco.
We're having tacos right now,
you need to react to that sort of situation.
The four things, and that's not a comprehensive or exhaustive list.
We go through much more through the course of the semester,
but there's things that you can look at
that essentially create the possibility of tacos, so to speak.
Finally, you need to trigger an event.
That's the thing that ultimately brings a disaster into the news,
into reality, and believe it or not,
I've always found the best way to explain this is by using beavers as an analogy.
So, when a beaver goes to cut down a tree,
it doesn't cut down the entire tree,
and it doesn't push the tree over.
It's not a very strong animal.
A 30 or 40-pound animal versus a 10,000-pound tree.
What it does do is it eats around the base
and subtly erodes the structural integrity of the tree,
and eventually a gust of wind comes along and it blows the tree over.
That is not the beaver's doing.
It's the wind that blew over the tree.
The beaver just set up the conditions for the wind to be able to do that.
We can map this over time
and look at essentially a wind condition,
then the wind's blowing, however the wind's blowing,
and then a rate of chewing that is constant, presumably,
and then because the rate of chewing is constant,
the structural integrity of the tree is steadily declining.
Disasters have been here in the red circle.
At that intersection of some event and some trajectory of vulnerability,
that's where the disaster, in fact, occurs.
It does not occur when the wind is strongest.
It does not occur at some particular point of vulnerability.
You really have to bring those two things together in time
in order to have a disaster.
You can apply the same logic to a city,
and in fact, in my classes, we often do.
You can take the healthy growth of a city,
maybe at 2% or something like that,
but the population density is growing faster than that,
which suggests a lack of housing or something else going on.
The average wealth of population is going down,
which means people have fewer resources
to support themselves in the event of a disaster.
The budget for emergency services is static,
even though the population and the population density is increasing.
The average age of critical infrastructure,
bridges and buildings and everything is falling apart.
You can roll this stuff up together,
not necessarily in an arithmetically way,
but you can roll this stuff up
into some kind of picture of overall resilience,
based on the number of things that are going up
and the number of things that are going down,
and how impactful those things are.
You get a sense of whether the resilience,
the ability to resist an event
is going up or down for a particular city in this case.
Then you have the event itself,
like the earthquake that happens every 100 years,
200 years, 500 years, whatever it is,
but when it does, as it crosses that intersection,
that's what creates a disaster.
I mentioned the 2010 Haiti earthquake previously.
Haiti had actually had a similar sized earthquake 200 years prior.
Of course, nobody remembered,
because we don't remember things that happened 200 years ago.
Not a big disaster, not a lot of damage,
because there was hardly anyone there.
It was 200 years ago, so Port-au-Prince was there.
It was just a very, very small city,
and most of the buildings were made of wood.
You really have to look at the possibility of disaster
as something that is happening through time.
We can actually translate this disaster lens,
this disaster thinking to non-physical things,
and that also happens in my classes from time to time.
We can apply it to non-physical things,
like a profession itself,
which is kind of how I started looking at all of this stuff.
In terms of infrastructure,
well, a profession of architecture is terrible infrastructure.
We have long licensing periods, low pay, precarious employment,
cutthroat competition.
It's not a structurally sound profession necessarily.
We can debate that, but yeah, anyway.
Then we have patchwork solutions.
If the profession is facing a crisis of value,
then it keeps doing these stepwise things,
like slightly changing the internship program
that everybody has always disliked under any particular form,
or transitioning to BIM,
but not capturing the value off of that transition.
A widening zone of vulnerability.
Well, there's 17% more architects than were a decade ago,
but AI is going to leave them with less work to do.
How much less work, I'm not really sure,
but that pool of vulnerability is getting larger.
Then the widespread irrational incredulity.
I would put in this box specifically,
design voices that are saying,
there's not going to be any impact on architecture.
There's just going to be impact everywhere else.
That ignores all fundamental laws of economics.
If there's huge job losses in the non-architectural world
and the rest of the economy,
that has macroeconomic effects.
Probably gets us to 5%, 10% employment, causes a recession.
The last time that there was a recession with 10% unemployment
in this country, a third of all architects lost their jobs.
The idea that AI might have some huge effect
on all their professions,
but not on architecture is incoherent, in my opinion.
The triggering event.
What is the triggering event in this case?
In 2008, it was the great recession.
I think that the debut of natural language generative AI
may in this case be the triggering event.
We can map this out the same way that we have with these other things
and say, look, for the profession of architecture,
the complexity of buildings is increasing.
That's good for architects because it means they have more to do.
The cost of construction is increasing.
That's also good because design fees usually track
with construction costs.
Student loan balance is going up.
That's not good because it means architects themselves,
especially the younger ones,
are in more precarious individual situations.
Pay relative to inflation is going down.
That's not so good.
The overall resilience is going downwards.
Similar to what we saw with the tree and what's going on with the city,
we have this curve.
Whatever it is, the shock to the system,
be it a recession or a new technology or something like that,
that brings about the disaster.
The disaster happens at some point in the future.
Why doesn't this feel like a disaster?
I can hear some of you saying,
we don't think of it as a disaster the way we do an earthquake
or a hurricane or something like that.
I think that the hesitancy to understand it as such
is translatable from physical hazards to professional hazards
and et cetera.
We protect ourselves from the psychological toll
of impending disaster through myths.
We invent ideas about what's going to happen
and what's not going to happen in order to protect ourselves
from the really high emotional and psychological costs
of understanding that.
That's the logic of it can't happen here.
It can't happen to me.
Human beings are actually not very good at judging the future.
We create these myths about what's going to happen in the future.
They keep us safe when we tell ourselves,
it can't happen here.
That's a problem because if we really believe that,
we're not preparing for it.
I think that was part of the point of Sinclair-New Louis' novels
that if you think it can happen here,
you'll take steps to prepare for it.
If you've washed out the possibility in your own mind,
then it opens the door to whatever's coming next.
Not a guarantee, but it opens that door.
How do we deconstruct these myths?
This is my favorite part.
On my sub-stack, Life is a Disaster,
you'll find lots of examples of this where I go
and break down myths associated with AI and architecture.
Let's deal with five of them just for today real quick.
Myth one, AI won't replace jobs, not tasks.
I started with this one because it's patently absurd.
That's what a job is.
It's just a bunch of tasks that roll up into some project
and projects that roll up into programs
and programs that roll up into practices.
What we've been being told about this AI stuff
is that you're going to have a firm
and then everybody is going to essentially have more time
because all of this technology is going to automate away
all of the boring tasks that we have.
This isn't how it plays out.
If anybody's ever been in a firm where layoffs are going,
this isn't what happens.
They don't allow people to just have their workload
reduced necessarily.
Every firm principle in the world is obsessed with utilization.
How do we get people to a maximum level of utilization
so that we're billing the clients for that person's time?
The more likely stairs is actually this one.
Workload is reduced through technological efficiencies
and you just don't need that fifth person anymore.
That is what happens in the face of technological evolution
and efficiency gains.
At the end, you have four architects instead of five
and they're fully utilized because that work has been redistributed.
This has to be the case because of the way that we define work.
Work is just some amount of effort times some amount of time.
That's all it is.
An example on screen, two full-time equivalents for six months
is equivalent to about 2,000 hours a month.
A year, rather.
That's the same as one person working full-time for a year.
It's also the same as three people working for four months.
That's all the same amount of work.
Any technological evolution is going to have one or two effects.
It's either going to give us less work to do,
meaning it reduces the overall amount of labor involved in a task,
or it's going to speed things up,
meaning we can get things done faster.
Or it's going to do both.
Both of these are problematic for architecture.
Under scenario one, where it just reduces the overall work,
we've got a problem because there's just not as much work to do.
Technology has taken something that used to take a week,
and now it takes an hour,
so we've got to find something for that person to do with the rest of their week.
Scenario two, things moving faster,
could also be problematic, almost certainly will be,
because as you start to speed things up,
you end up with these holes in the project cycle.
What do you do with that time?
The most likely scenario, in my opinion,
is that it's actually both, that it speeds things up
but also reduces the overall amount of labor involved.
Yeah, we've got problems.
This is potentially disastrous.
Myth number two, AI will automate the tasks we don't like,
leaving us more time to design.
I've heard this everywhere,
in kind of every article and position point on AI.
There's somehow this belief that,
once AI automates away all the shop drawings
and red light and CAD drawings and all this shit,
we can just spend all of our time designing,
and it's a very attractive idea,
because we love design, that's what we were trained for
and that's what we went to school for.
I like designing, but I don't think that this is possible,
because it's actually constructed on top of several other myths.
If this is the idea that we're going to have huge amounts of time
to spend in design, now that construction documents
and all the rest have been sped up,
I think the problem there is,
we don't necessarily choose where technology is going to have an impact.
The presumption behind that idea of having more and more design time
is that AI is going to have a huge impact here
on the stuff that we don't like to do, and then none here.
Technology does never really work that way.
Once a technology like cell phones or electricity or computers penetrates,
it becomes a de facto expectation.
If you're a photographer and you don't want to use Photoshop,
you don't have to, it's not like the law,
but you're going to have a real problem coexisting in a competitive economy
with photographers that do.
We don't necessarily just get to decide where technology applies,
generally speaking.
I think there's also something about the law of diminishing returns,
and I think mature designers get to a point where they realize
that designs get to a point where they're 95%, 96% of perfect,
and we have that drive within us to get them to 100%,
and we know that we can, but the closer you are to design perfection
if such a thing exists, the harder it is to resolve those last little bits
without going back and reinventing everything that you just did.
I think clients also understand this, which is why they put a deadline on you.
Professors understand it.
That's why you have final review, because if those deadlines didn't exist,
we would just keep working forever.
If you imagine this graphically, you say,
okay, there's a design that it's 95% of perfect,
and I'm going to work asymptotically to get it towards that final product.
This has financial implications for whoever's paying the bill for your design time.
At first, it's a loss because the design adaptations, whatever it is,
have not been fully resolved.
You need time to think through that and to think through,
okay, how do I get from 95% to 100% perfect design,
idealized design, and everybody's fine.
So someone is taking a loss on that particular time.
As those choices start to mature, assuming that you are a brilliant designer,
which I'm sure you are, the payout becomes really high.
The marginal payout for every additional unit, day, week, month of design time,
climbs rapidly because you're resolving the things that weren't resolved in the 95% scenario.
But the closer you get to perfection, the more those gains start to diminish.
That's in the nature of diminishing returns of asymptotic growth and all these other things.
So that's why it seems like for a lot of clients, 95% is good enough.
They're not interested in paying for you to get to 100%.
Exceptions exist, obviously, but for a lot of clients, good enough is good enough.
And because fundamentally when we're working like this,
different kinds of changes have different value through time.
So I think the most convincing micro myth under this myth is what I call the creativity surplus.
And I'm sure everybody has seen some version of this cartoon at some point.
The architect starts out with some brilliant vision, hugely aspirational about what to do with the design.
It gets a little knocked down with the meeting with the clients.
And then you go through all the working drawings and budget revisions and value engineering.
And pretty soon the building is kind of ordinary.
So I think from a standpoint of value analysis, if we can't get clients to pay us for all the creativity that we have now,
why would we suspect that they're going to pay us for more of it?
So this idea that this technological advance will lead to this explosion in design activity and design time.
Unless you're working for yourself, I don't see it being true.
Like someone is still going to have to pay you for all of that time.
So myth number three, AI won't place architects because architects are too smart or creative or charming, attractive.
Take your pick. I've seen lots of ideas like this.
I think that's probably true.
And I think it's a red herring argument that people are making sometimes where they say AI will not get to the level of human.
The reality that we need to understand is that AI does not need to get to human level in order to displace humans.
Because that's not how people make purchasing decisions.
Everybody has had some cheapo client at some point and everybody has had a dream client at some point.
And we can borrow a concept from economics called indifference curve to map this out.
This is not exactly how an indifference curve is supposed to be used, but we're using it as a proxy.
So how do we exchange things between good architecture and cheap architecture?
Like how do people assess that balance? Well, you can map that with a curve.
And the easiest way to understand it is through its slope, through rise and run, just like a stair.
So what this is visualizing is a client who is willing to reduce the quality of design by 50% if the cost is reduced by 40%.
Not great, not terrible, probably a middle of the road client or something like that.
The second client is a lot worse because this is a client that will reduce the quality of design by 50% for a 10% drop in cost.
So I've certainly had clients like that, maybe some other people have too.
But these are the clients who don't really care about design and they're just good enough is good enough.
They're just willing to pass over everything if it saves a few bucks.
And that's kind of tragic and I know that a lot of architects live with that frustration on a daily basis.
So how does this play out in terms of the competition between human architects and generative design?
Well, we can also map this over time.
So if we assume that human is the standard, that's 100%, that is the talent and capability and vision of a human architect.
And we've got generative design either with human assistance or without that's rising and we commit to the idea that it will never get there.
It will never reach human capability, no matter how much time we give it, it's just going to be 90% of what an architect can be.
We're here, we're living in the yellow zone where capabilities of this technology is rising very quickly.
But at the same time, like we know that it's just never going to get there.
Okay, fine.
How does that compare to costs?
Well, the costs of a human architect, human design is going up steadily as you expect it would with inflation, hopefully, you know, a raise once in a while.
The cost of generative AI is dropping precipitously and has been for decades and will likely continue to do so.
So when you take the ratio of cost to, you know, whatever that design quality is, and these numbers are arbitrary, understand like you can substitute your own numbers if you really want to, but the effect will be the same.
You get cost over quality of human architect kind of rising steadily because, you know, the quality is what it is, that's the standard, and costs are rising, you know, slow rate inflation, something like that.
But the cost over quality of AI is dropping.
So the quality is getting better and the cost is coming down, which creates this very, very sharp curve towards the bottom.
And that creates a whole different set of problems for architects because all of a sudden, you're not choosing between these two cheapo clients, you've got a different dynamic.
Now you've got a position where a client can reduce the quality of design by 10% and achieve a 50% reduction in cost.
And that becomes a lot more seductive than I think potentially disastrous because we don't want to design this 90%, right?
We want like the best design to be out there in the world.
But as you make it more and more attractive by hacking the cost 50%, 80%, 90%, I think it's going to seduce a lot of people.
Alright, myth number four, AI won't be a threat in the future because of something it can't do now.
We've heard a lot of this, too.
So from Kermit Baker, the chief economist of the AI, AI can't pour concrete, paint a wall, or install flooring.
Momentarily setting aside the fact that it actually can pour concrete and paint a wall and install flooring.
It does all those things today.
So we can think about this whole thing a little bit more abstractly in terms of what AI is going to do in the future.
So AI is growing exponentially.
What that means, what rates, we don't know.
It's not necessary for this illustration, but you've got AI growing at an exponential rate in terms of its learning, its capability, everything that it can do, etc.
AI's grow at a linear rate, which is probably not a big deal if you're over 50.
So if you're an architect and you're pretty senior, it probably fuels that speculation that you have that AI can't actually compete with your knowledge and skills because it can't.
Like not now, probably not ever because you're going to retire prior to the point where AI ever gets to that level.
So the skills that you have after 40, 50 years of practice remain valuable today and will probably remain valuable for the next couple of years or 10 years or something like that.
And that's probably why older architects seem to be a lot less concerned about all of this AI business.
But the picture is different for senior architects.
So some of them 10, 15, 20 years of experience, they're going to have their growth cut off at some point by, you know, this red wall of AI growth and AI will grow to the point where it assumes the capabilities that senior architect actually has.
That senior architect never really gets a chance to ascend to the level of professional maturity and skill set that the principal architect did because their progress is essentially cut off.
Much bigger problem for a recent grant because someone who's graduating architecture school today has to look at the possibility that as they're out there and they're trying to build their skills and their capabilities, you know, they're cut off.
They've got a few years in the profession, maybe 10 before the capabilities of AI exceed their own capabilities.
So they'll never get to that skill level that the prior generations have because by the time they do, AI will be better than they are at the task of architecture.
And it's hugely problematic if you're a child, you know, if you're a 16 year old and you're thinking about going into architecture, you're not going to get there for at least another, you know, six, seven, eight years.
You're not going to be licensed for another 10, 12, 15 years. And by that time you've come in underneath the growth curve of AI.
So all this discussion about what AI can do today as a measure about what it can do tomorrow, I think is a false profit.
You know, we need to be looking at the growth rates of AI and understand what it's going to be able to do in the future.
And here in argument, I think, you know, well, AI is not going to be a threat in the future because it can't do this thing right now.
I would just set it aside because it's relatively nonsense.
All right, final myth, we'll just do more projects.
This is also mythological because it violates basic laws of supply and demand.
And I'm going to illustrate this with golf clubs, because I think golf is an urban crime.
By the way, apologies to anybody who does. So let's imagine a golf club market and you have three suppliers, right?
And they all produce about 20 golf club sets per quarter.
This creates an overall industry supply of 60 golf clubs, golf club sets per quarter, and the demand is also 60 golf club sets.
Perfect supply and demand like in balance, right?
Now, what happens when supplier B comes upon a technology that allows them to triple their production of golf clubs?
They're producing 60 a quarter while the overall supply goes to 100.
But then what happens to the demand?
Does it also swell to meet that supply?
No.
I mean, very rarely with very specific things does demand rise to meet supply that almost never happens.
One scenario is that supplier B puts their competition out of business and just gobbles up all of the work as may happen in architecture.
As, you know, big technologically advanced firms adopt this new technology faster and just decide to, you know, take over everybody else's business.
I think the more likely scenario is that all of this extra golf club sets go in the trash, right?
Because there is no market to actually absorb what they're doing.
This is the key thing.
The demand is fixed.
Just because you produce three times as many golf club sets doesn't mean that, you know, people are going to go out and buy three times as many golf club sets because how many do you need?
Like people are not going to spontaneously start playing golf because you've produced all these extra golf sets.
And I think that's the problem with a lot of this thinking around design is that, you know, just because we can do the design a lot faster and produce more of it,
doesn't mean that people want more of it.
The demand for design services is fundamentally driven by the demand for buildings.
The demand for buildings is driven by all these things, but it's also related to the money supply.
So the money supply and the demand for buildings combine to create the demand for design services.
And this has no relationship to anything that's going on within the AC world, the software we use, how fast it is, like whatever dynamo scripts you've written.
So none of that influences demand at all.
Maybe in some very, very peripheral ways.
But the point is that, you know, our work as designers as architects is trapped between like the money supply, the money that coming in, the demand for buildings on the demand side.
And, you know, what we do inside doesn't fundamentally change either of those things.
So if you produce 10 times as many coffee makers, it doesn't mean people need 10 times as many coffee makers.
If we could produce 10 times as much design, doesn't mean people need 10 times as many buildings.
And that is the fundamental constraint that I'm most worried about is people think, oh, well, we're just going to do, you know, more and more work.
We can't, there's not a demand.
There's no way to sort of justify all of that extra work.
So let's wrap this up by looking at the brighter side of disaster. I love teaching disaster because I think disaster is fundamentally optimistic.
And we have thousands of years of history to prove it.
Ever since our ancestors started utilizing floods on the Nile River Delta to kickstart the policy and, you know, invent civilization, humanities has really productive relationship with disaster.
Lisbon 1755 suffered earthquake tsunami and a city white fire at the same time.
They all kind of caused each other one earthquake caused the rest of it.
But anyway, very, very tenuous time, you know, the seeds of the enlightenment were there.
But it happened on all scenes day.
So a lot of the very religious people in Portugal were saying to themselves, oh my God, we didn't pray enough and that's why this is happening.
Let's, you know, return to religious fundamentalism and all this stuff.
And the course of history was changed by the Marquis de Pombo, who basically drove the response to this particular earthquake.
Now the earthquake, fire, etc. already had become well known throughout Europe.
It had influenced a lot of thinkers because it provoked a question, you know, this horrible, horrible trifecta of disaster happens on all Saints Day.
Does that mean that there is a God or does that mean that there is no God?
And like what should we actually be doing about this condition?
So Marquis de Pombo leaned in the enlightenment direction and we should thank him for it.
So he developed early approaches to seismology and horses, riders on horses go out in radial directions and interview people about the length of the shaking and what happened and everything like that.
And when he started to establish an epicenter, he created the Pombo lean style or had it created, which we still use today in many parts of the world.
So I've ever seen this kind of construction like that really became popularized after this this Lisbon earthquake at the direction of the Marquis.
Well, generally speaking, kind of jump started the enlightenment, right? I mean, this was a huge historical event told us like when an act of God happens, we can respond with design, you know, we can actually design that particular disaster away and protect ourselves in the future.
Nowhere has this ever been more evident than the city wide fire and it's an old memory. But we used to have those all the time, right? Cities which is burned to the ground.
And that was it. London, of course, in 1666, Chicago in 1871, Baltimore, 1904, San Francisco in 1906.
We used to have cities would like burn to the ground and now it's inconceivable that anything like that would ever happen. It's tough to even imagine how that might happen. So what changed?
The Triangle Shirtways Company fire in 1911 was a horrible fire and a tragedy that inspired a public outcry which in turn sponsored provoked legislation about, you know, new building codes, new ways to design buildings.
Fire sprinklers, emergency exit doors, having alleys, you know, this sort of thing.
And, you know, I love telling this story because, you know, it's an example to me of the way that urban planners and architects and engineers quite literally designed a disaster out of existence.
And, you know, our cities exists today because we adapted to that particular disaster.
And I said that disaster is fundamentally optimistic because it is because we have a chance of deciding what to do. So, you know, is the future of our detection AI apocalypse, I think it just depends on what we design.
So apologies for running a bit long, but thank you to everyone, and especially to my hosts, and love to start a discussion.
Yeah, that was fabulous. Really fabulous, and don't apologize for taking so long.
I think what, I mean, some of those notions I've kind of had before, but I've never been a systematic in investigating them through the lens of, you know, much more kind of like a structured analysis.
I think it was, it was really very, very instructive.
I just, there are a number of things that come up. I think that what I think what it points towards, I mean, the emphasis seems the background concern was the issue of cost that seems to be the driver in many ways, or the primary concern, certainly as far as the client
is concerned. And it kind of in some senses echoed the Susskin's work on what's going to happen in the future in terms of the professions and the primary driver of change is going to be economics.
People just want to get cheaper and cheaper and cheaper. And that is always kind of in a way, I think there is a background condition that makes us as a profession architects very vulnerable.
And that is the lack of concern about cost. I wrote a long time back a book called The Anesthetic of Architecture, which is about how we tend to see things through a rose-tinted lens and just see them in terms of their beauty.
And that rinses out often concerns about socioeconomic, political, environmental disasters, whatever. It just rinses that out, and we just look at it.
And I mean, whatever. I mean, you could think about looking out over the Pacific Ocean and seeing this kind of pink mushroom cloud, which is clearly a kind of nuclear explosion, the French testing out their nuclear weapons over at Bikini et al.
And look at it and say, wow, what a beautiful pink mushroom cloud kind of thing. And that is, I think, that is kind of endemic with the problem in some senses of architecture.
We see things and say, wow, isn't it beautiful? And the client was thinking things about how much it costs. And the classic kind of issue is you come up with a design and my chair at Cambridge would come up with this as argument.
And the client would say, but how much does it cost? Don't worry about that. If you get this, you'll get a beautiful building. And the problem is that is really the issue.
The aestheticization runs through the architectural culture. And I think it also affects architects themselves in the sense that we are so happy doing beautiful designs, we don't worry too much about our own pay.
In fact, we've got no say over that, really. There's nothing to to effectively protect fees, nothing at all. And so that becomes the kind of the crucial issue. And I think you're absolutely right in pinpointing or at least it seems to me the core of your argument was really about economics, about cost, supply and demand.
And I totally agree with your golf club's kind of analogy. There are going to be no more buildings required. So don't assume that you're going to be employed more in the future.
Anyway, maybe I'll just put that comment in there if you want to.
I agree. I would refine it a little bit and I'll tell you a story. I practiced architecture for five years commercially before going to graduate school and I went to do my master's in architecture and an MBA.
And of course, as a young architect, we were always talking about cost because clients were always beating us over the head, like, this costs too much, this costs too much.
And I adopted that common sentiment among architects that architects care about the building, the design, and clients care about the cost. And then I went to business school and it's just kind of like rapid fire, doing case studies and everything like that.
And no one ever talked about cost. And I was like, what the fuck is going on? Because I thought I would go to business school and we would just be talking about this.
And I think that's where I developed my sensibilities about value. Value being the difference between what something is worth and what something costs in there.
And, you know, we make decisions about what we buy based on the differential, right, you know, the relative value of two things. So when you go out to buy shoes, you know, you don't buy like the best pair of shoes that's ever been invented.
You don't buy like the least expensive shoes that's ever been invented. You look at that. And I think that to what you said about the sort of viewpoint difference between architects and their clients.
That gets amplified because, you know, from an architect's perspective, the cost is immaterial because they're not paying for it.
The worth of the building is very much tied up in its aesthetics. So, you know, we want it to be beautiful to us because that is good for us.
But the worth and cost equations are completely different for the client. One, they're paying the cost. And two, you know, the worth is it encompasses things other than just aesthetics.
I mean, there's rental payments from tenants. You know, there's tax like, you know, I mean, there's all sorts of other things going on. But I think that, you know, you're absolutely right.
And thank you for bringing up Suskin too. You know, they've been hugely influential in my work as well. Because, you know, fundamentally, you know, you may love architecture.
You may be the best architect in the world. But when alternative technologies create a solution that is 90% is good, but 10% of the cost, like that, that's all she wrote.
I mean, like 99% of clients are just going to flock over there. And you would do the same thing, you know.
Yeah, I would just add to that that I think that the questions of aesthetics, we assume that everyone shares our aesthetic. We assume that.
But actually, they don't. I mean, I don't know. I've got a relative who I had a pair of Nike yellow shoes and I went into the Sahas office and Patrick said, Where did you get those? I want a pair of those.
And I got some flak when I went to one of my relatives homes. What are you wearing yellow shoes for? You're not a teenager anymore kind of like, you know.
I think this is something that is and it's actually in some senses. So we assume everyone's going to share that aesthetic and they, they, you know, I think, I would say that postmodernism has meant that we kind of more aware of appearances and so on, I would say, but on the whole, no one actually
quite shares that same aesthetic. And to my mind, this was the tragedy of the Bauhaus in some senses that they thought they would transform society, give the modern citizen what they wanted.
But the problem was it was, it was expensive. You know, it was, you know, if you go to the Bauhaus now in Dessau, you'll see all these beautiful kind of whatever they are, designer objects, or you find them anywhere, you find them in museum shops all over the world and fine if you've got the money to pay for your
start lemon squeezer or whatever, but actually, you know, it's actually expensive. Whereas Ikea, and I think there's a lot of lessons for us from Ikea, they produce something that actually did what Adolf Los claimed he wanted to do by reducing the
ornament, you save on costs and produce something that is much cheaper. Of course, there are other kind of smart factors they introduced, I mean, flatbacking things, allowing you to assemble themselves and, and all that out.
But this means that Ikea is now populating the living rooms of many, many people, but not because of the aesthetic, because of the fact that it's going to be cheaper and that's the best way to do it.
So you do actually, and maybe you do begin to influence people's taste and they say I quite like Ikea or whatever, but you do it through a fundamentally different mechanism, I think that is absolutely central to how we operate.
So I, I really appreciate that and the layered way that you address the question about cost itself.
Let me just say, if anyone's got any questions, please put them in, so we've got a YouTube audience, we've got a Zoom audience, the YouTube ones that you can put in there into the chat and we can relay them here.
I wanted to pick up on on something which I thought was, I mean, maybe as a way of kind of not just my work, but maybe something you could add into the mix and that is to say there was a recent study that was done by essentially a group of
sociologists from Harvard, MIT, and the guy called Ethan Mollick who is from, I think, UPenn, was also part, he's an AI expert, I think he's at the business school there at UPenn.
Anyway, they did a study on a consulting group, Boston Consulting Group, and what they were doing was attempting to measure, now we don't know how to measure these things, but sociologists do, to measure the impact of using AI.
And they were able to come up with some result, they were able to quantify it in some way, and I think this is probably the first of many studies, I'm sure there'll be a lot of them.
And of course they weren't necessarily dealing with the design as such, although that was vaguely included in their study because they asked this group to suggest a new line of footwear,
responding in some way to whatever, no, dot, dot, dot, another line. And so it was kind of creativity in very loosely was part of that thing. They were using chat GPT to study this thing.
But what they came up with, I think was really, really interesting, was a series of quite significant factors and there is this very crude graph that Ethan Mollick has published online.
The whole thing was published as part of a Harvard Business School journal, but he made his own graph and so on, which puts it very graphically right up.
And he says, and what they found basically, in the study, using AI, it was a group using control group, using AI versus a control group, not using AI.
And those that were using AI finished 12.2% more tasks, so they achieved more. What's more, they completed those tasks at 25.1% quicker.
Now, I guess you've got to multiply those to get the real impact. You're doing more tasks and you're doing them quicker. So the overall impact is actually more significant than that.
And they also came up with the figure, which I think is difficult to evaluate, but it was 40% better quality.
Now, that's anyway, you put those together, those three factors are quite significant. And as you say, it's a question really ultimately the task.
And to something that I do, I mean, that is a factor in the sense that there are those differences between certain tasks and others.
For example, your comparison must be the task and the job itself or the profession.
I think that renderers are in a lot of trouble right now. There are a number of tools out there you put in a sketch. I mean, famously, Tim Foo was using look X and he put in a crumpled piece of paper and looked at it and produced a Gehry building,
based on that, and each one was, and you can do that now. So, so I think certain, clearly, there is a differential in there, one has to take that into account.
But very, very significant, and it will be interesting to find out what that figure was. I once was talking about this as with one of the developers AI soccer, I would mention her name, but she once said, and she wanted to attract it.
Some person using AI could achieve as much as five, not using AI. And I, it's a little bit of a, and she was worried about that information getting out there because it might put off people from using AI.
But nonetheless, there is, there is a significant difference in what you can do. So I don't think the quality necessarily is going to be that important in terms of aesthetic, shall we say.
Although, I mean, I think that you can judge quality in other terms. And I think these are really hugely significant factors. And we need to do a study, I think, in architecture for that.
Let it go.
I mean, okay.
Any, any, any, any pops, I've got a few more, a couple more points. We'll open up. We've got some questions coming in from that from from YouTube as well. So, but, yeah.
So, anyway, I think there's, there's, there's the concern that's kind of connected in some way to, to, to, to all those issues. The one thing that I think that I would question about your approach and, and, and, well, I don't mean critical but I think one,
maybe suggestion. And you mentioned the law of diminishing returns and that's course was Kurtz while what he followed and a lot of people are following on from Moore's law.
Now, for those of you don't know Moore's law, Gordon Moore was an industrialist who was made a comment. It wasn't the law as such but made a comment back in the 60s on observation shall we say that that in terms of circuit boards,
the number of conductors, the transistors on the circuit board would double every two years and the price would come down by half, which meant that this was exponential change.
So, if it's, if it's that factor, you would be considered going one, two, three, four, five, you'd go one, two, four, eight, 16, and there's a huge difference between five and 16.
It's exponential change and that has been applied more recently to these large language models and I want to mention those again in a second because I think these are absolutely hugely significant.
And Pishai, the CEO of Google, made the comment that these large language models are increasing in their capabilities, going faster than Moore's law, and that was the comment he made.
I don't think that Moore's law is relevant in this context because it's tying it to some kind of production and the kind of economics.
Now, the key question when it comes to capabilities is, in my view anyway, the speed of learning, the speed of learning.
Now, this is something that Geoffrey Hinton comments on and Geoffrey Hinton is known largely as the Godfather of AI.
Certainly he was the one who was promoting, who was working on neural networks and what we call now deep learning at a time when that approach was out of favor.
It wasn't working, everyone abandoned it in favor of a different logic, symbolic AI based on logic and so on.
But really all it required was a change in terms of the technology.
And as soon as we got GPUs invented and suddenly the capabilities of computers and the speed of computers was vastly, vastly increased and these neural networks worked.
So that's a background to him.
But he has made the comment recently and he's been in the news because he resigned from Google in order to sound a warning.
And his warning basically, or part of his warning, was the speed at which computers could learn.
Because the way that it works, he said, and I need to look into this further, is that it shares information with a thousand other computers at once.
And I don't know why he mentioned a thousand, not a million, whatever, but it shares information with a thousand computers at once.
Whereas if I'm sharing information with you, it's a one on one.
But a thousand to a thousand others.
Now, that somehow reminds you of COVID in some senses.
If you share COVID, the key issue was what they call the R-Ratio.
If it was more than one, be worried.
If it was less than one, you're kind of okay because the spread is going down, whatever.
Now, we never had an R-Ratio of a thousand.
Now, I'm not even sure if that figure is correct.
But this is the real problem.
It is the capabilities of these large language models that is exploding.
And it's exploding at a rate that we cannot even conceive.
Maybe I'll just throw that out to you, Eric, and see what's going on.
Sure, sure. Let me react to a few things.
First, the diminishing returns diagram and the thread there.
That's not actually, that's irrespective of AI or no AI.
You know, the diminishing returns is just an economic phenomena that exists either way.
So that's separate.
The Moore's Law thing, yes.
And we need to get the word out about that because I think there's still people who think that Moore's Law is relevant.
It's not, things are moving much, much faster than that.
I mean, Kurzweil puts it at a double exponential or triple exponential.
I mean, these are growth rates that are very hard for people to understand, like intuitively.
And I don't mean like people other than me.
I mean, I have a hard time, like the human brain has a hard time.
Here's a benchmark that I always use.
Stanford's whatever annual AI survey that they do.
They put the doubling of artificial intelligence capability, rolling in, you know, algorithmic development, advances in cloud computing, like all the things like the raw capability of AI, doubling every four and a half months.
Now, if something's doubling every four and a half months, that's a million X in seven years.
So when people say, hey, you know, AI is like, there's nothing to be afraid of insulting that AI could actually like, you know, ape the performance of a human designer.
I agree.
I'm like, yeah, you know, at this point, but do I believe that an AI that's a million times more powerful than what we have today might be capable of designing a building.
Yes.
Yes, I do.
And I'm very, very concerned about it.
So, yeah, I mean, I think that, well, you just deconstructed another myth, Neil, you know, this myth around Moore's law.
I think we have a responsibility to kind of get the word out that some of this, some of these polyanish positions are based on, you know, data and ideas that are actually outdated.
I think I'll just throw that back at you.
I mean, I love that video, the 24 minute video.
But it struck me that it doesn't have to be 24 minutes.
And I base this on, I mean, it's what you're doing basically is you're recording a conversation.
And which and you're, you're showing it between these, these AI agents and.
The 24 minutes space is basically taken up in showing them talking to one another, whereas actually the speed of the operations could be pretty instantaneous.
Now, I was alarmed by the, what we now know as large language models and their speed of operations.
Several years ago, in the world of AI, one of the great moments when we kind of a wake up call it was called a Sputnik moment.
When Sputnik basically was a wake up call for the American, the Americans in the space race and let the foundation of NASA.
I mean, holy shit, the Soviets were suddenly sending a satellite to orbit and America was nowhere near that.
And that was a wake up call.
So in terms of your kind of like, there's something good that comes out of it.
Well, NASA came out of that particular moment.
Anyway, this particular game, it was, and we were not, it wasn't really on our radar because it was a game of go, a match of go.
And we don't really play go, but they do in Asia.
And there was this match AlphaGo developed by DeepMind of London versus Lisa Doll, who was kind of this followed on from the Gary Kasparov chess match.
And he was the kind of Gary Kasparov, shall we say, of go.
And AI trounced him.
And that was the wake up call for all go playing nations.
And the Chinese immediate president, she said, okay, by 2030, we are going to catch up with the Americans and overtake them and so on and so on.
So that was kind of like a hugely sort of significant moment in sort of in wake up.
But the more important one was something that wasn't really mentioned at all, which was a follow up.
And the follow up was this was the next model of AlphaGo, which is AlphaGo Zero.
But first of all, it wasn't documented, it wasn't on TV and whatever, but it was, it went out on our radar.
But that one, it beat AlphaGo 100 games to zero.
Right.
That's better.
But the important thing was it learned to do things without being trained to do so.
It was not taught the rules of go.
And this talks about the emerging capabilities, which we should come back to in a moment.
But the other aspect of how it looked, it was playing games of go against itself.
And I think the total was 4.9 million over four over three days.
Yeah.
And that sounds like a lot.
That sounds like a lot.
But the real point is, it is art.
I mean, you go down to it, you know, it's basically it's 20 games of go per second.
Now that is very, very significant.
It is weak.
It's mind boggling me fast.
Yeah.
And I would say, and I didn't know why it took so long, frankly.
I mean, how could you even take, you know, that much.
So my point would be with that video is the actual calculations were pretty instantaneous.
And it wasn't 24 minutes of calculations.
I mean, that was what it took to show the operations happening in terms of discourse,
shall we say, but the calculations were pretty instantaneous.
And that really is.
Anyway, that was what it might be.
My comment on the video, which I thought was a fabulous video anyway.
No, I mean, I think you're right.
I mean, it's, you know, there's something evolutionary about it, right?
You know, we just, we have trouble.
The human brain has trouble like kind of wrapping our heads around, you know,
exponentials and these sorts of things.
So, you know, we got to support each other and like check each other and say, like, yeah,
that whole 24 minute video could have been under a second.
You know, if it was just two AIs, you know, talking to each other and designing a building
or something like that.
In my own writing, I refer to this as the million monkey problem, right?
Where we've all heard that adage about, you know,
if a million monkeys were banging on a million typewriters for a million years,
would they at some point write, handle it?
And, you know, maybe you think, yes, maybe you think, no,
but a billion monkeys working on a billion typewriters for a billion or a trillion.
You know, those are the scales that we're into now.
So, yeah, I think we need to be very, very concerned.
And it's interesting that you brought up the Go match because that was one of my initial inspirations
getting started on this project because, you know, there were architects in the ether who were saying,
no, like, you can't compete with architecture.
Architecture is just like too complicated.
And like, you know, AI is like beating world champions ago.
It's doing protein folding, you know, it's solving all these like cancer research problems.
And, you know, architecture is plenty, plenty complicated,
but I'm not sure that it's more complicated than everything, you know,
like it's not like the last thing that that AI is going to figure out.
So, yeah, yeah, we got a big job.
Yeah, no, so one more point for me and then we'll open up to the other questions in the audience.
But, you know, I absolutely totally agree.
Also, you're picking up on what are called emergent capabilities or emergent abilities.
I think these are things that are hugely significant.
And I was intrigued by what you discovered in terms of what AI had learned how to do, you know.
So just to say for those who don't know, I mean, I'm not sure if the term emergence is intended to be taken the way that I've taken it.
But I, in my work years ago on swarm intelligence, and I came across the term emergence,
which is about that Steve, that John Holland initially kind of written about as a kind of principle,
whereby things start emerging out of any multient system that are unpredictable and not expected.
And classically, you think about a flock of birds in the way that it produces this area, acrobatics.
But it's also been taken more recently to apply these to these mysterious abilities that go back to that alpha go zero.
It taught itself to play go.
And, you know, that the right that that was when the alarm bells should have been sounding because now we're discovering through these large language models.
It is developing similar capabilities.
It can learn languages and translate.
That is pretty astonishing.
It does it. It does it actually. I mean, emergency stuff is kind of a rather mysterious thing.
And we can observe it.
We can't really explain it scientifically yet.
But nonetheless, we can see this thing happening.
Now it can learn to translate and it can learn to write code.
Oh, that's that's very.
That's huge.
Yeah.
So I got a friend from college who was who used to run the biggest translation agency in the world.
And he sold his company two years ago because he could see that I was going to be able to do it.
And I've been exploring that myself in terms of the translation of some of my books and it's incredibly cheap, very fast, even with a human editor to come in and go and check all the things and so on.
So there's there's there's that but I mean, it's so it has this capacity to do these things and I claim that it's very imperfect moment.
And I would claim though that there are moments in which it has learned how to design.
It seems to have learned that the rules of composition in the sense of mid-journey and Dali, particularly mid-journey, it's coming up with some pretty impressive designs, not everyone.
I mean, about only one in about 50 is really good.
But nonetheless, it is surprising that it's doing those things.
I could only assume there are a lot of other things that we don't know what it's doing, but it's doing, you know, it's looking at the data and understanding systems and putting them together.
I actually put this question to when you heard yesterday, I said, Well, what about I mean, could it not also learn how you do the plumbing or how you do, you know, other aspects of architectural design.
And she was saying, well, the difficulties, the three dimensions, that's when errors start creeping in.
And it's, it's fine with language.
I mean, language, it doesn't matter too much of your slightly out.
There's a lot of tolerance there.
But with architectural drawings and things, that is the challenge.
It's not there yet.
But I do think I do think that these emerging capabilities are, I mean, they're fascinating.
And they don't sound particularly interesting, not indeed to large language models, but they are extraordinary.
And just one final point for the audiences, the large language models, they, they get these abilities, not through the sophistication of the code, because the code is quite straightforward.
It's based on the size of these things and the larger they get, the more they seem to manifest these things.
So I was just intrigued.
Maybe you'd like to comment just briefly again on, on what you discovered it was able to do that you had never predicted.
Yeah, you want to hear the wildest?
Yeah, yeah, yeah.
I mean, the windows and the bathrooms and the constant, like that, that surprised me, you know, that it was able to kind of get all of that right.
The biggest thing that I did not put in the presentation was that I did find that it had some kind of 3D spatial world building capability.
So after, you know, Carla had designed the house, you know, I drew it out, you know, I drew the floor plans as I would have drawn them based on, you know, what she was talking about and, you know, the local conditions and things like that.
And then I described it to chat GPT and said, you know, if I go into, you know, the front hallway and make a left and go up the stairs and make a right, what room am I in?
And it was like bedroom.
And it would get that right. So in the way that you might communicate it to an unsighted person or something like that, you know, I was able to kind of articulate directions like around the house and, you know, across like multiple floors and things like that.
And it would seemingly understand like where it was in, in some three dimensional mental model.
So that's an artifact of just like the language. So, I mean, to us, you know, if I described to you a building like over the telephone and said, you know, these are the mentions of the building like you could sit down and draw it out and go vice versa.
So, you know, maybe it's not.
Yeah, I don't know where it comes from. I haven't figured it out, but it's scared the shit out of me.
I'm just, just an aside, I want to go to some of the questions and yeah, yeah, let's do it in a moment. I want to ask Mitra, but just as an aside, I think the obvious point that needs to be reinforced.
Traditionally, we are the ones that interpret the verbal instructions of the client and produce an image, which is exactly what mid-journey and dali do.
And that's kind of worrying. I don't know. Mitra has got a question. I don't know if you're able to use your microphone and to read it out, or if not, if you can, if you can unmute yourself, or I can read it for you.
I don't know whether you, I don't know if you've got a microphone on your computer.
I can see you're still muted. Oh, did someone have to allow her to unmute themselves? Okay. Okay, Mitra.
Hello, hello everyone.
Hi.
Hi. Thank you so much for the great lecture.
Actually, I have a question about, actually, we have these days we are facing an increase in the use of the social networks.
So the analysis of invisibility of the data and social network could be significant. For example, in urban studies, we have the geolocation data, including the GPS or data about connection with local Wi-Fi equipment.
So my question is, would it be possible to collect data from social networks for architects? And where is the data stored?
Would it be possible to collect data from social networks for what, for design purposes?
Yeah.
I imagine that's much more of a social and legal problem than it is a technological one. You know, your social networks already know everything about where you are and what you're doing and how fast you're moving and what stores you visit and all those other things.
Because, you know, you signed off on a license agreement that allows them to have and use that data. I think in order for architects and designers to use it at other scale, at any significant scale, we'd have to have a similar sort of arrangement.
I mean, the idea of a municipality collecting that data on its citizens for use by designers frightened me a little bit because they would almost certainly use it for other things.
But I've seen a use to brilliant effect actually in disaster zones.
After the Haiti 2010 earthquake, Port-au-Prince was a city of about three million people, sorry.
And once the earthquake struck, you know, it destroyed most of Port-au-Prince and, you know, people fanned outward, you know, from the city and then at varying rates started to come back as recovery progressed.
And did you sell the main phone carrier there actually had that data as a result of like, you know, having everybody's SIM card in a database.
So, you know, we could understand how quickly, you know, people were moving back and into what neighborhoods and this sort of thing.
So, I mean, from an urban and from a design perspective, that data is enormously useful.
I think we just have to make the case that we should have it as designers and that we can put it into good use.
Just to decide, Eric, the, I think the one of your disasters, just maybe you didn't know this, but the Great Fire of London.
Actually, it came off the Great Plague, and it actually effectively got rid of the Great Plague.
So maybe you had two disasters on one counter to the other.
So we've got a number of questions from YouTube.
And I think these are separate questions.
First is you can see them in the chat if you want to look at them from Mandu Tiger in YouTube.
Some excellent points.
Unfortunately, another influencing factor for the long term is this rising level of indifference that is poisoning creativity and quality.
Two huge values architects provide.
Unfortunately, another influencing factor for the long term is this rising level of indifference that is poisoning creativity and quality.
Two huge values architects provide.
I would say, you know, Mandu Tiger, you're not wrong.
There's certainly a surplus of indifference in the world these days.
But I will reference my father and probably several debate coaches as well.
You know, always advise me never to argue a position that requires that, that I believe or that you believe that my opponent is, is somehow stupid or morally corrupt or ignorant or something like that.
Because it's an easy out, right?
And I think what I think with architecture has nothing to do with architecture. It's all these other people and the fact that they don't care about this and they don't care about that.
That may be true. It just doesn't go anywhere.
I mean, it's kind of fatalistic for the profession, if you think about it, because, you know, if you imagine that, that architects are, you know, these passionate designers concerned with beauty and progress and, you know, everybody else is indifferent to such things
as beauty and architect, you know, I mean, like, you need a world to pay fees to design things.
So, I mean, I think that, you know, when I'm confronted with questions like that, you know, I asked myself, well, how do you, how do you make indifferent people different?
Or, you know what I mean, they make indifferent people like actually care.
You have to find the ways to speak in their language and to speak to their priorities.
That's actually why I went to business school, you know.
You know, I went to get an MBA and people thought I wanted to be a developer.
I didn't. I never have.
But it struck me as a good decision because I wanted to be able to defend our work in their language, right?
Because when I was a practicing architect, you know, the whole design team would come up with all these great ideas and everything.
And then, you know, at some meeting somewhere, there's some like 30-year-old with a clipboard and an Excel spreadsheet.
And it's like, we're not doing this. We're not doing that.
And I started to ask myself, well, who's really designing this building, you know.
And I didn't have the vocabulary or the skill set to actually argue with that person in their language.
So, I went to business school to learn that.
So, Mandu, just to tie it off.
I mean, I would suggest that you think about the people that you think are standing in opposition to design and ask yourself, like,
how do I convince them that design is valuable in their language, you know, with their value system?
Great, great point, Eric.
I think that just a comment from the U.A.
the studio discovered one of the successful ways of speaking to the client in their own language was to diagram things.
That would be much more convinced by the diagrams than the designs themselves.
Yeah, yeah.
So, we have another question from the chat.
Again, great, do you get a lot of praise here for this talk? It was a fabulous talk, very good.
Great talk, and thank you. I have a question, but I want you to know more about your opinion.
Do you think that there are safe havens against the AI and architecture disasters?
Are they physical places?
Should we, as architects, look for a way to design to make a sound from what AI could do against the profession?
Yeah.
Yeah, is there a name attached to that?
No, there's no.
Well, to whom ever asked that question.
I think that architects fundamentally need to be thinking about expansion.
And I think that exists along several axes.
One is a kind of domain expansion.
I think there's a great opportunity to actually reclaim a lot of the territory that we seeded during the 20th century to other professions.
And we had to spin off interiors and landscape architecture and construction management, owners reps, and all these other things because shit got too complicated.
And we also just wanted to spend time designing.
And I think it's unfortunately eroded a lot of the authority of an architect in that overall design process.
So I think there's an opportunity there to claw some of that back and to say, like, look, with these augmented tools, we can now do the construction management bit.
We can do the interiors bit.
We can do all these different things.
Now, all those other professions are going to be saying the same thing, so we have to find a way to work that out.
But ultimately, you know, we can expand in that direction from a domain standpoint.
I think geographic expansion is another one.
Most of the architects in the world are in places where the least architects are needed the least.
The global south is going to need something like, I don't know, like a billion units of housing in the next 25 years.
And there's not necessarily like the infrastructure there to support good design for all of them.
And I think, you know, maybe technology offers a route to that so that, you know, someone born in a slum in Lagos now has access to good design.
What does that mean? How do you accomplish that without, you know, fully like techno enabled colonialist strategy?
I'm not really sure.
But, you know, through my work, I know like most of the world really, really needs design and they can't get it.
So hopefully that is another axis of expansion.
The third one I'll mention is actually digital and metaversal.
And I'm not a metaverse fanboy by any scrap of the imagination.
But I do believe that the metaverse is inevitable that it's coming sooner or later.
And that once it does, we're going to need a strategy to marry design strategies in the real world with the metaversal world.
So if you're designing for a client like Nike, you know, they're going to have a metaversal store and they're going to have a regular store and augmented reality in their physical store.
They're going to want all of that stuff to work together.
Right. So how do architects start to think about digital experiences and how those complement, you know, physical spaces.
So I mean, I think there's there's lots of that's just three, there's probably some more.
But I think there's lots of ways that we can look at doing new things or doing old things or doing unprecedented things that haven't been invented yet.
The part that makes me worry, the part that makes me think that we might be in a disaster is architects looking at these sorts of technologies as ways to just do what we're already doing just faster and cheaper.
Like that's that's raised to the bottom. Like there's no good outcome there.
So I think fundamentally, the safe place is everywhere except architecture.
Like, look out, chart new territory, explore new civilizations, design housing for the moon, like, you know, whatever it is, like you got to go out there and use this technology that we've never seen before to do things that we've never done before.
I was struck by your video.
Conversation should actually would be great to see the whole thing because it was so interesting, but it's out there anyway for those who want to see was actually effectively the architect became the construction manager there he was talking to the to the construction person which is quite unusual.
I mean, normally there's a very adversarial role and now increasingly in certainly in the UK, most contracts are designed built and the, and the developers in charge, you know, so we've surrendered that idea that we used to have of being the person that's what the word architect means literally from the ancient
30 reminded us the person in charge and we've surrendered that but we could do that and I would also say we could also become the developer I think that's an area that is probably very, very well paid that we could also take over or indeed the person
apparently selling the property gets the most money so we will go in terms of costs per hour. So the another question here in the chat from Ren right a Rainville at youth YouTube.
Do you have any suggestions on how firms should prepare for this oncoming disaster.
He has a second question but let's ask them first. Do you have any suggestions on how firms should prepare for this oncoming disaster.
Yeah, I mean I think, well, building on what I said in my last response in terms of like looking outward to do to do new things and impressive things.
I think education is critically important at this point, you know, I mean, I, I advise everybody calls me like, do your own homework, you know, read learn something and, you know, I think 90% of the architects read like the same like 10 design magazines like, you
don't have to stop doing that but read some other things to, you know, I think most of my perspectives are informed by things that are actually going on in the tech sector and like the AI sector and like that's where I get my intel is like, you know, who's
researching new research on machine learning and, you know, liquid neural nets and these sorts of things so that's how I personally keep an eye on what's happening and develop a sense of the future that I can feel comfortable with that, you know, I feel like I understand
what might be coming. I think, I don't know, not disparaging any sort of design media but, you know, design could be a very conservative profession, you know, and I think it's the sort of thing where, you know, we're radically adventurous and our work right within the four corners of the drafting
I mean, metaphorically at this point, you know, we create whole new worlds and new civilizations and things like that, but then tend to be like conservative about processing environment and like the rest of the things so I think that it would be good to educate oneself and to do your homework
and to figure out what is going on outside of architecture because that's where the real action is at the moment and it's inducing a tidal wave that's going to, you know, hit architecture at some point.
In terms of, you know, other like more tactical preparation I think that would probably depend on the specifics of, you know, a particular firm or a geography. So, should we go to part two, Neil?
Yeah, yeah. Secondly, how best can architects direct the value conversation away from the client cost concern?
Yeah, I mean, I think the first step there is to figure out what's your client values. And again, I mean, I think there's, there's an unfortunate, you know, mythology and architecture that thinks, oh, you know, the client only cares about cost.
I've had clients like that. I've had clients like that. But clients are people and people tend to be more complex. So I think different clients value different things to varying degrees. So like, that's step one is knowing that.
The second part is, you know, don't bring a hammer to a gunfight. You know, I mean, if your client is someone who values like cost exclusively, then you need to find a way to make that argument for value in economic terms.
And you say, you know, we want to redo the lobby and don't talk about why from an architectural standpoint, it's going to be better. Talk about like, how you can charge like higher rents or like the cost comes down or something like that.
You know, if you're working with a client that cares about some, you know, other social issue or political issue or something, you know, find out what that is and make arguments to people in their language.
I mean, I think that's one of the, and Neil alluded to it earlier. I think that's one of the biggest kind of universal mistakes that architects make. We try and convince people to follow like whatever suggestion we're making using the language of architects, instead of their language.
And it falls flat.
A lot of times.
Maybe I said, I don't want to, I'm talking too much, but I just add to that there was, there was occasion in Cambridge once, but there was a disaster.
Many years ago, when there was a competition and one of the colleges decided to forget the results of the competition and just go to a builder and they got this really very, very tedious building as a result.
But then they learned a different strategy. They discovered that actually if you mentioned you had a big name architect like foster and partners, whatever, it was much easier to attract funding from alumni by saying we have got so and so.
And it became on their terms, it made sense it became an economic argument to improve the design so I very much agree with that.
So we have James McBennett on on on YouTube, and his question which again is in the chat. Most buildings are not designed by architects, demand of buildings or demand for buildings is far greater than demand for well designed buildings.
As the cost of design changes, surely blue ocean strategy in the middle.
Yeah, I would absolutely agree.
I mean, I think that, you know, my my humanitarian work was largely about bringing design to two communities and to people who otherwise would never have had access to it by virtue of geography or economics.
Because I think you're pointing out James like that includes like, you know, most Europeans, most Americans like, you know, architectural services cannot be provided at a cross point, where, you know, it makes sense for someone who is, you know, got a $500,000 house budget to engage with an architect like that's just not going to happen.
Yeah, as the cost of design comes down, does it then become possible to provide design services at, you know, the same level of quality but at a lower cost point.
You know, I was teasing an architect the other day about creating a digital version of themselves, right, so they could actually like, you know, service service clients, you know, essentially at zero cost.
And this sort of thing and, you know, that technology still probably a few years away for, you know, sort of full package solution but, you know, it's a taco watch like all of the ingredients are currently there the technologies exist.
And they need to be assembled at some point in order to do that.
But I think, you know, I love, I love that idea. I love the idea of like everybody having an architect, everybody getting the benefit. And one of the things that that's fueled my career and the thing that makes me so mad is that, you know, architectures is like great
I mean, it's so beautiful, like so many brilliant and creative people and, you know, it's offered almost exclusively to, to the rich to the 1%, you know, and like, we can't, we can't get it out there to everybody else.
And that's not because we suck. I mean, it's just because, like, it's, it's a lengthy and expensive process. So I hope that one of the things that, you know, architecture starts to embrace as these technologies unfold and design costs come down as
we give design to everybody. Yeah.
Actually, James has got a follow up question.
By golf analogy, if 2% of buildings are designed by architects, and 2% of golfers can afford a full set of clubs, would more golf golfers justify buying a full set of clubs if the cost dropped dramatically.
Okay, interesting. I think what's implied by this question is that there are people running around out there with like, two or three, like golf clubs, but don't have like a full set.
So they go and play golf with like a couple of clubs and if the price of a set of clubs came down.
They might actually buy the full set. Is that how you read it, Neil?
Yes, absolutely.
Okay.
I don't play golf, so maybe I'm like out of my depth here, but I don't think most people like play golf with just like a few loose clubs. My understanding is that like, you need the full set in order to properly play a game of golf.
And if that's wrong, someone in the chat, please correct me.
I mean, I think to James is kind of like wider point, if the cost comes down to more people embrace it.
Sometimes yes, for some goods, yes.
You know, energy is the prototypical example, right? The more energy we make and the lower the cost, the more people consume.
And there's some name for that kind of exception to the laws of supply and demand.
I think that if the cost of design comes down, people may embrace it further and more people might be interested in utilizing the services of an architect.
And the same necessarily applies to buildings, because like, you know, you've got a town of 30, 40,000 people, it needs a hospital, right, or at least like a regional medical center.
It doesn't need four of them, right? I mean, we have to have some kind of justification to make the buildings that we make because they're expensive and they take a while and they're complicated.
So, yeah, like I could see like a minor expansion and just to play on James's previous points, you know, like homeowners might have the opportunity to, you know, at the scale of a single family house for, you know, half a million dollars actually like work with an architect.
On the other hand, you know, that brings in the specter of like a custom designed house of some kind. I don't know how that's actually going to play out.
But James, to your point, yes, I think that probably there will be a slight expansion of the market in design services, but it will be constrained by fundamentally by the limits of the building market.
There's another question in the chat with no name attached to it. I think that maybe the way we should think about architects within our ecosystem as a researcher, what is our role, what is our role as architects in the loop of research along with computation and big data?
Will it help? Sorry, this is not very clear. Will it help us solve problems ahead? Let's read out what he said actually.
Yeah, I'm reading it.
What is our role of architects in the loop of research with computation? You think that means like the role of architects within the wider field of research on, you know, IT and data and computer science related issues?
I think so.
Well, I mean, I think, you know, architects have really amazing perspective and an amazing facility with certain skills that lend themselves very easily to research.
So, you know, the ability to zoom in and zoom out really quickly and think small scale and big scale and be fluent and fluid between those things.
Architects do that better than just about anybody I know.
The ability to think about time, right? So, architect is one of those professions where you have to like make a decision today that's like binding for 30 years.
And I think we lose sight of the fact that there are very few professions where that's true, you know, maybe medicine or law or engineering or something like that.
But for the most part, like, you know, you fuck up at your job, like you've got lots of time to fix it with architecture, like your issues, your decisions get set in concrete, literally.
So I think, you know, the mind of an architect lends itself very easily to that sort of thing.
I think it's about, you know, integrating with what's already going on. I mean, there's already a lot of research going on into these things.
So the question is, like, what is the entry point for, you know, architects who want to be involved in that?
I think there's a lot of data issues around buildings and cities that we haven't quite figured out.
We spoke about it earlier during the Q&A. But I've had the conversation many times over the past year about data and architects thinking, oh, well, we got all this data, like, from the buildings and, you know, we can use that in some sort of data science way.
And, you know, my question is always like, you know, will it use it for what? Like, what data is going to be useful to anyone?
If you're talking about data about how people use the design that you made, that seems like it would be the owner's data and not yours.
So that's one problem. And if you're using the data from, you know, the designs that you made in the past, might be good.
But unless you're like a Gensler or HOK or something or an AEcom, you probably don't have, like, enough projects there to actually build any sort of machine learning data set or anything like that.
So, you know, I think architects have a natural role based on their, you know, psychology and their disposition.
But I'm not sure what that role is. And I think we'll have to design it.
There's another question from Vasco Ashik Vasco on YouTube, who's in Bangladesh. You should know that you've got an audience all over the world today.
Awesome.
In AI driven architecture, how do you tackle worries about losing human centric values and cultural nuances, especially in post disaster reconstruction where community identity is crucial?
Yeah, and I'm reading the follow up comment, which I agree with, I would argue that a lot of buildings have already lost a human centric value. It did not take AI, it was modernism and effects of industrialization, post World War II prefab and building without ornament.
So Ashik, I think that's a great question, Ren. I think that's a great answer. And similar to the one that I would have offered.
Yeah, I mean, I think, you know, architecture loses human centric values all the time. And I think that's one of the reasons that a lot of people don't appreciate architecture because, you know, we spent 40 years making
artificial architecture and, you know, kind of turning our attention away from the problems that people were actually dealing with in their lives. So, I mean, I think that, you know, how do you correct for that problem? How do you introduce human centered thinking?
And my advice is always like, spend time with humans. You know, we, we don't always appreciate I don't think just how insular architecture is as a profession and how weird that is.
You know, we take someone when they're 19 years old and we put them in studio. And frankly, a lot of architects never come out, you know, like mentally like they stay in studio for forever.
And, you know, they come out, graduate, they know how to walk like an architect, talk like an architect, they, you know, have cool glasses and wear black and this sort of thing.
But they don't necessarily like have human beings at the center of like whatever their design ambition is.
You know, in my work, like it's impossible not to, you know, you can't, you can't go into a community of friendly loving people who are having a hard time and say like, okay, like I'm just going to ignore all that.
I mean, not unless you're some kind of monster, I guess, but yeah, I mean, the point is, the point I'm not trying to make. I think I'm advising you to one, like spend more time with with people.
And, you know, to appreciate the fact that we don't have much human centeredness to begin with. So maybe paradoxically, AI is the way that we find it.
You know, I'm sure some of you have seen the same studies that I have where, you know, they measure the responsiveness of a human doctor and, you know, a medical chat GPT like, what is it?
You know, they call poem one or something, the Google one, the medical one.
And, you know, the respondents like drastically prefer interacting with the robot, because it's perceived as being like more caring and more attentive and it has, you know, infinite time and my doctor comes in to see me and like 30 seconds later, you know, he's gone like to do with another patient because
some is looking stupid like that. But, you know, maybe this tool like retrieves some of our humanity by, you know, giving us time to be human and giving us time to to sit with patients and to sit with clients and things like that.
So, yeah, I don't know that felt like a rambling response.
It's a tough question.
Rambling responses, Eric, fabulous. I just made me to follow up on that in a way. I mean, I had this last semester, I asked my, instead of asking my students to go and write essay, I got them to ask to do a video, but they went, I think, to chat GPT and got this.
I think, I think you're right, because in your article, you mentioned the fact that the chat that chat GPT has been conditioned to respond in a certain way.
And if I mean, I always go back to chat GPT is like, what, do you really mean that? And it kind of is open. Well, not really. But I mean, so, so, but the kind of responses that seemed to they seem to be getting was feeding into their videos was, well, AI lacks the empathy.
It doesn't have the empathy of human beings.
Now, I'm not sure that empathy actually in design necessarily makes a better design. I'm not sure about that at all.
But what I would say is that that discussion you had in your video and I really would recommend everybody to have a look at that discussion.
It was absolutely fabulous. They were much more polite than any human being was astonishing.
Yeah.
I mean, it's, it's fascinating because it's, you know, it's a customizable intelligence, right? So, you know, whatever chat GPT generally is, you know, if you needed a situation that that if you had a situation where you needed the empathy dialed up to 11,
you could do that, right? And, you know, if you had some sort of alien intelligence designing buildings in Bangladesh and shout out to Bangladesh, by the way, I went to a conference there about seven years ago, one of the best weeks of my life.
If you had, you know, an alien intelligence designing something, you know, you could pre-program that with like, you know, let's keep the colonial influences to a minimum and like not cover Bangladesh with, you know, international style architecture
and this sort of thing, like whatever you do has to, you know, honor the traditional building practices and materiality and form making like present in Bangladesh architecture.
You know, I mean, these models currently are overly programmed with Western influences, which is predictable because like they were created in the West, but I'm optimistic that that AI is capable of overcoming that problem and learning new tricks.
No, I totally agree with that. I mean, I think one of the big issues people talk about AI is the bias, you know, and the bias, of course, comes from us. I mean, it's from the data that we're producing, and it's been replicated in AI.
And you could recalibrate any machine learning system, as you say, to get rid of that, but humans will always have that bias. So I completely agree with that.
Yeah, it's not algorithmic bias. It's our bias. And, you know, that's another myth. I mean, we sometimes look in the mirror and we don't like what we see coming back at us. So we blame the technology.
Yeah, I mean, just go look at Google. If you go to Google and say, and Google Nurse, you will get women, female figures. And that's, you know, it's absolutely, that's there.
But just, I want to just pick up on this a bit, a bit more, because you kind of hinted that you thought, in your article in your videos, well, you thought that there was the check TPT being programmed to be a bit soft on certain questions.
I mean, I've noticed that with, you know, is AI going to affect employment? And it says, no, not at all. You know, it's going to be assistant and so on. Do you think it's been, it's been conditioned or framed or programmed in a certain way?
I mean, we get with, for example, with, with mid journey, the aesthetic that comes out, isn't just in the data, something that's been framed in a way. What do you think?
I mean, I think the most alarming thing is that we, we, no one may know the answer to that question. You know, I mean, if you take, you know, Altman and Brockman and the rest of them at their word, like, they don't actually know what's going on inside the black box, right?
They don't know how these, these LMS are actually working and putting this stuff together. If that's the case, you know, what level of control do they have over how, how the model is, is worked, you know, is there a switch that they can flip and say, okay, you know, make chat GPT mean now or make it nicer.
I assume they have some level of control, but they probably don't have as much control as we wouldn't like them to have.
And I think, you know, that's, that's terrifying as well as exciting is, is that we're dealing with something that is growing, and that is learning to some degree, like, on its own.
We're trying to have to nurture that intelligence so it doesn't kill us. Because, you know, if we don't do it the right way, we may encounter a problem.
I mean, clearly there are, there's some things going on with chat GPT so I don't know if you've caught these articles but like, you know, the latest thing seems to be like, if you ask chat GPT like really nicely or you sound desperate, like it gets more cooperative.
Like, we're right in a prompt that says like, hey, I need to write a report for my boss and I'm going to get fired, like he'll be right this thing, like it does a better job than it would if you just like asked it to do something.
Or, you know, it gets lazier towards like the end of the year that was a story that came out in December, because it's imitating us and because, you know, people do, you know, unless work gets done in December, I mean it's kind of global phenomena.
So, yeah, I don't know. I mean, there's, there's two terrifying possibilities, one that a small number of people at a private corporation have entire control over how responsive GPT is and in what way.
And the other terrifying possibility is that no one has any control. So, you know, strap in. It's going to be an interesting time.
Yeah, this has been great. I don't ask us those in the zoom conversation if they've got any questions they want to ask this stage.
I don't know how do you want to ask one.
Yeah, Neil. Hi, everyone. Hi. Hi, Eric. This was a great talk and actually great discussion really really enjoyed it. Can you all hear me well this is a new microphone.
Anyway, okay, wonderful.
Just picking up on the on the last remark, you may Eric, I was just watching before this I was watching a lecture from Jeffrey Hinton at MIT, a recent lecture.
And Hinton, I think as much as people like, you know, Joshua Bach takes, I think takes the position that ultimately humanity is kind of transitional, whatever that really means but I think Hinton would take the point that
we might have to come to terms with the fact that we are, we are going to, well, I guess, replacement is not the right word, but there is an evolution and there may be beings in the future that are smarter than us, and
maybe humanity as we know it today is not going to be around forever in a certain way. And I was thinking, I was thinking of apocalypse and disaster and maybe timescales and what qualifies as disaster.
I suppose within within a kind of timeframe, like, would that be would that is that do we think of that as a kind of as a kind of disaster or as a kind of apocalypse, they thought that we as we know ourselves today.
You know, may, may not exist in some kind of future. Well, I guess we know that for some distant future, right, but maybe this is the point is going to would be, I could be closer than we are actually thinking.
And I was actually wondering if that if, you know, if we think of design practices that are that we would, you know, we might think of as like more than human or like designing with and for other forms of being and other forms of intelligence.
And that actually in a sense contains in itself, a sense that humanity, at least is is sort of is sort of changing. And if that is, I don't know, if that one could seek could think of as also relating to a kind of, I wouldn't say disaster but I kind of a, a,
Yeah, I'll leave that I'll leave that open. Just curious to hear your thoughts on this. I think I hear what you're saying.
And I think the words that Elon Musk had used to describe that phenomenon was describing humanity as a bootloader for an artificial intelligence right like we were the pain that that then loaded up the thing that that lasts to eternity.
And whether or not it's a disaster I think is is a philosophical and perhaps a spiritual issue. I mean, I think it has special relevance for architects because I gotta assume that that part of the joy of being an architect is making something bigger and more permanent than yourself.
You know, if you're really invested in your design, you're taking something out of yourself and you're putting it into the world in the form of steel and concrete and, you know, it's going to be there hopefully after you're gone.
And, you know, it will stand as this sort of, you know, memory of of you.
It's intrinsic, I think to the process of creation, like we all seek to create things that might outlast us. So in the case of, you know, AI and humanity, you know, I've had this conversation with myself and say, you know, look, if we're ultimately the fate of the human race, that we, you know, essentially gave birth to this, this alternate intelligence that
you know, fanned out like across the cosmos and did all these wonderful things. Would that be bad? Like, would that be a history that we would be ashamed of as human beings or dissatisfied with somehow?
And I wonder, you know, what, how it relates to the process of parenthood. I don't have any children so I'm speculating and hopefully no parents in the audience get mad at me for doing so.
You know, when you have a child and you raise up that child, if that child goes on to do things that transcend you, you're not mad, like, you're not like pissed at the kid, because you are part of its success.
You know, you can look at the ways in which that child has transcended you and gone beyond you and be proud because that has a lot to do with what you did as a parent, you know, like that's your creation that's transcending you and in most cases outlasting you.
So, yeah, I mean, I, you know, is there, is there generally speaking the future for humanity? Yes, I think so. But I think even in the event that there wasn't and that the ultimate story of planet Earth is that there are a bunch of dinosaurs, they died, and then there are a bunch of animals, and one of the animals got really smart and invented a machine intelligence.
You know, then that became the thing that lasted forever. I still think that'd be a pretty good story, you know, I mean, assuming we create the right kind of successor to whatever our time has been.
So, nice. I appreciate the question. I appreciate ending on some, you know, really slowly.
Thanks, Eric. Yeah, I mean, we could go on, I guess, for another two hours on this question, but it's it's super interesting. And yeah, wonderful. Thanks for this. This is, I'm guessing we've already gone for two hours and something. So, yeah.
Neil, we have, I don't know if Smora wants to ask questions, one final one for Smora.
Yeah, I would just like to ask whether you think this type of, let's say somewhat negative speculation about the future taps a little bit into the unconscious mind and it makes us feel as humans that there's something to worry about to care about for the future.
Or like, it has a psychological effect to it because I think people are very much drawn to this type of disaster thinking it's all over the news. It's a little bit of a different realm, I think, of thinking and speculating about it.
I think I understand the phenomena you're speculating on, but can I be clear about the question? Are you asking me whether that that is that negative speculation is a good thing or like where it comes from?
Yeah, I mean, because so far it feels like it has all been like with negative connotations, the whole talk. And I'm just asking whether it has for you as a writer, as an architect, is it something that you do consciously or is it just how you see things or do you feel like people are more drawn to this type of speculation?
Yeah. I mean, it's not a marketing gimmick. It's not, as far as I know, you know, some latent psychological trait. And I don't consider my message negative.
You know, for me, disaster is fundamentally a positive thing, because there are a lot of things that don't happen, frankly, until we have a disaster.
So, you know, we needed the fire of Lisbon in order to have the enlightenment, like we needed the city fires in order to develop building codes.
Human beings are funny that way, right? I mean, Churchill said something about, you know, Americans can always be trusted to do the right thing after they've exhausted every other option.
And I kind of feel the way about people generally in response to disaster, you know, I mean, they'll just watch that dam and they'll see crack and crack and leak and leak and leak and not do anything until like the dam collapses, but then they'll get their ass and gear and actually do things.
So, you know, in my work and in my teaching and my lecturing and, you know, the things that I'm doing related to AI, it's not morbid, in my opinion, like it's not intended to be, you know, hey, let's get together and commiserate about like the awful future.
It's a proposition that if we can acknowledge that something really bad could happen and we could agree on that, then that's the first step to us getting together and making something really good happen, right?
That's the moment where we can all get together and say, hey, the dam's about to collapse, let's evacuate people, let's design a dam, let's do all these things.
And indeed, that's the way that it's always been with human beings, right?
Things have to get really bad before we do really good things.
And I think this AI business specifically as applying to architecture, you know, my hope is that more architects can look at it and say, holy shit, like this thing is coming from my job and, you know, half of all architects are going to be unemployed in five years.
What should we do instead?
Right. And, you know, don't leave and like go sell real estate. Well, I mean, sell real estate if that's your passion or something like that, but let's initiate a collective conversation about what architecture is going to become.
And, you know, how are we, what are we going to design next, you know, now that machines have taken over all the construction documents, like, what, what can we do?
And I think there's just, there's enormous possibilities, you know, climate change is bearing down on all of us and it needs solutions and some of those solutions are the sort of solutions that, you know, architects should be at the head of the table, if not at least in the room or something like that, you know, we need to be engaged with those sorts of things.
And smart, my, my worry is that with the, I keep calling them Polly Anish, you know, maybe that's a little bit too harsh, but with the really, you know, positive messages, people go back to sleep, right.
And they say, okay, you know, so-and-so at the AIA or Reba said, you know, AI is not an issue, I'm not going to worry about it.
Those are the people that are going to hurt, hurt most, because we tend to prepare for the disasters that we see coming.
And we tend to be unprepared for the disasters that we don't.
And if you prepare for a disaster that's coming, then most of the time it doesn't actually become a disaster, right?
So, like, you solve the problem ahead of time, so the disaster just never materializes.
So, yeah, that's also kind of a rambling answer, but I think your question is an important one.
I don't see my work as negative, you know, I mean, I think we have to be brutally honest about the wolf at the door before we start doing the really positive things.
And I think that's why I have the message that I do.
And that was a fabulous answer, Eric, and a fabulous answer to end on.
I always think that the, from my background in critical theory, the point about critical theory and problematizing things was actually the idea was to improve something.
You pinpoint a problem and then you'd improve it.
But also critical theory was a technique that certainly I tried to employ to bring into the architectural domain that was otherwise a kind of self legitimizing kind of discourse, some critical tools that were absent.
And I thought what we did, what we saw today was a really fabulous demonstration of bringing some critical tools into the debate about architecture, tools that we were otherwise previously unaware of.
And I thought they were very, very powerful to kind of burst that bubble and expose some of these issues.
And I think this was really an astonishing presentation.
I think, you know, cutting through all the myths that we have in architecture one by one.
I think there are a few more by the way.
That's part two.
Well, we need to have a part two at some point.
I think Gary, this is really, I think, was one of the most productive things because it was completely unexpected.
And I think this is exactly what we need.
Someone coming from a different angle and asking tough questions.
Because without that, we are going to be, and I have to, when you mentioned sleep, I have to say that one of the comments that chat GBT threw back at me was the thing that otherwise we will be sleepwalking into oblivion.
And that struck me as precisely the warning that you were giving.
We need to wake up to this.
Otherwise, we will be sleepwalking into oblivion as a profession.
But I also agree with a potential optimism.
No, there are ways in which we could adapt, absorb these tools.
But we need to engage them now to prevent the disaster rather than once the disasters happen.
And I think this is the very, very clear message, Eric.
This is absolutely fabulous.
And I think everybody, every single, every single student of architecture,
especially because you pinpointed something I never read this before, that actually it's those who are younger, who are more at risk, need to listen to this.
Everybody needs to listen to this talk.
It was absolutely amazing.
Thank you so much, Eric.
Thanks for having me, y'all.
This has been great.
And I hope we continue the discussion.
Yes.
And I just want to thank also the Digital Futures team, especially Michael and so on, for putting it, it's like an iceberg.
There are a lot of people working on this behind the scenes.
And just to mention briefly that Michele and I are working on another series that's going to start on the 18th of February on architecture and philosophy as part of the Doctoral Consortium.
And we're now kicking off the rest of the years, the years presentations about for Digital Futures itself, and including it's going to be a series on AI plus, which is about AI being applied to different domains and so on.
But this was so, so helpful, Eric.
I want you to write a book on this.
This is really very useful.
Incredibly useful.
I'm going to take a look by a lot for it. So thank you so much. Thank you to our audience and thank you to those questions.
Amazing, truly amazing. Thanks so much.
Thanks everyone.
Thank you everybody.
Thank you.
Thanks everyone.
This is great.
Great.
See you soon.
