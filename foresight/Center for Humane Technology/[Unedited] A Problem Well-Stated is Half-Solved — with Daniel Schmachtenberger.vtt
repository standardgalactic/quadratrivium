WEBVTT

00:00.000 --> 00:05.000
Hi, everyone. It's Tristan, and this is your Undivided Attention.

00:05.000 --> 00:09.000
Up next, we have our unedited conversation with Daniel Schmacktenberger.

00:09.000 --> 00:13.000
And because it's unedited, it's longer and not corrected for fact-checking purposes,

00:13.000 --> 00:17.000
but you can find our shorter, edited version wherever you found this one.

00:17.000 --> 00:21.000
Listen to both versions, and then come to our podcast club with Daniel and me,

00:21.000 --> 00:25.000
and hopefully you, on July 9th. Details are in the show notes.

00:25.000 --> 00:27.000
And with that, here we go.

00:31.000 --> 00:33.000
Welcome to your Undivided Attention.

00:33.000 --> 00:38.000
Today, I am so honored and happy to have my friend, Daniel Schmacktenberger,

00:38.000 --> 00:42.000
as our guest, who works on the topics of existential risk

00:42.000 --> 00:46.000
and what are the underlying drivers of all of the major problems,

00:46.000 --> 00:50.000
or many of the major problems, that are really facing us today as a civilization,

00:50.000 --> 00:54.000
be it climate change, breakdown of truth, social media, our information systems.

00:54.000 --> 00:58.000
Those of you who've been following your Undivided Attention will hear this

00:58.000 --> 01:00.000
as a very different kind of episode.

01:00.000 --> 01:05.000
We almost think of it as a meta-episode about the underlying drivers

01:05.000 --> 01:10.000
of many of the topics that we have covered on your Undivided Attention thus far.

01:10.000 --> 01:13.000
So if you think about the topics that we've covered,

01:13.000 --> 01:17.000
whether you've seen the social dilemma or you followed our interviews previously

01:17.000 --> 01:23.000
on topics like attention span shortening or addiction or information overwhelm and distraction,

01:23.000 --> 01:27.000
the fall of trust in society, more polarization, breakdown of truth,

01:27.000 --> 01:30.000
our inability to solve problems like climate change,

01:30.000 --> 01:35.000
well, this is really about an interconnected set of problems

01:35.000 --> 01:40.000
and the kind of core generator functions that are leading to all of these things to happen at once.

01:40.000 --> 01:44.000
And so I really encourage you to listen to this all the way through,

01:44.000 --> 01:48.000
and I think that we're going to get into some very deep and important knowledge

01:48.000 --> 01:51.000
that will hopefully be orienting for all of us.

01:52.000 --> 01:55.000
One of my favorite quotes is by Charles Kettering,

01:55.000 --> 02:00.000
who said that a problem not fully understood is unsolvable

02:00.000 --> 02:03.000
and a problem that is fully understood is half-solved.

02:03.000 --> 02:08.000
And what I hope we talk about with Daniel is what about the framework that we are using

02:08.000 --> 02:13.000
to address or try to meet the various problems that we have has been inadequate

02:13.000 --> 02:16.000
and what is the problem-solving framework that we're going to need

02:16.000 --> 02:19.000
to deal with the existential crises that face us.

02:19.000 --> 02:22.000
So Daniel, welcome to Your Undivided Detention.

02:22.000 --> 02:24.000
Thank you, Tristan.

02:24.000 --> 02:28.000
I've been looking forward to us dialoguing about these things publicly for a while.

02:28.000 --> 02:30.000
Well, you and me both.

02:30.000 --> 02:33.000
And for those who don't know, Daniel and I have been friends for a very long time,

02:33.000 --> 02:38.000
and his work has been highly influential to me and many people in my circles.

02:38.000 --> 02:43.000
So Daniel, maybe we should just start with what is the metacrisis

02:43.000 --> 02:47.000
and why are these problems seemingly not getting solved,

02:47.000 --> 02:51.000
whether it's the SDGs, climate change, or anything that we really care about right now?

02:53.000 --> 02:58.000
I think a lot of people have the general sense that there is an increasing number

02:58.000 --> 03:06.000
of possibly catastrophic issues and that as new categories of tech,

03:06.000 --> 03:09.000
tech that allows major cyber attacks on infrastructure,

03:09.000 --> 03:12.000
tech that allows weaponized drone attacks on infrastructure,

03:12.000 --> 03:17.000
biotechnologies, artificial intelligence and moving towards AGI,

03:17.000 --> 03:21.000
that there are new catastrophic risks with all of those categories of tech

03:21.000 --> 03:28.000
and that those tech are creating larger jumps in power faster than any types of jumps of tech,

03:28.000 --> 03:32.000
including the development of the nuclear bomb in the past by many orders of magnitude.

03:32.000 --> 03:40.000
So there's a general sense that whether we're talking about future pandemic related issues

03:40.000 --> 03:45.000
or whether we're talking about climate change or climate change as a forcing function

03:45.000 --> 03:50.000
for human migration that then causes resource wars and political instability

03:50.000 --> 03:55.000
or the fragility of the highly interconnected globalized world

03:55.000 --> 03:58.000
where a problem in one part of the world can create supply chain issues

03:58.000 --> 04:00.000
that create problems all around the world,

04:00.000 --> 04:04.000
there's a sense that there's an increasing number of catastrophic risks

04:04.000 --> 04:07.000
and that they're increasing faster than we are solving them.

04:07.000 --> 04:10.000
And that when you mention like with the UN,

04:10.000 --> 04:16.000
while progress has been made in certain defined areas of the sustainable development goals

04:16.000 --> 04:19.000
and progress was made back when they were called the Millennium Development Goals,

04:19.000 --> 04:23.000
we're very far from anything like a comprehensive solution to any of them.

04:23.000 --> 04:28.000
We're not even on track for something that is converging towards a comprehensive solution.

04:28.000 --> 04:35.000
And if we look at kind of the core initial mandate of the United Nations

04:35.000 --> 04:39.000
in terms of thinking about how to recognizing after World War II

04:39.000 --> 04:43.000
that nations take government alone wouldn't prevent World War

04:43.000 --> 04:45.000
and now that World War was no longer viable

04:45.000 --> 04:49.000
because the amount of technology we had made it a war that no one could win,

04:49.000 --> 04:52.000
we still haven't succeeded at nuclear disarmament.

04:52.000 --> 04:57.000
We did some very limited nuclear disarmament success while doing nuclear arms races at the same time

04:57.000 --> 05:01.000
and we went from two countries with nukes to more countries with better nukes.

05:01.000 --> 05:03.000
And that's simultaneous to that.

05:03.000 --> 05:06.000
Every new type of tech that has emerged has created an arms race.

05:06.000 --> 05:08.000
We haven't been able to prevent any of those.

05:08.000 --> 05:12.000
And the major tragedy of the commons issues like climate change and overfishing

05:12.000 --> 05:17.000
and dead zones in the oceans and microplastics in the oceans and biodiversity loss,

05:17.000 --> 05:19.000
we haven't been able to solve those either.

05:19.000 --> 05:25.000
And so rather than just think about this as like an overwhelming number of totally separate issues,

05:25.000 --> 05:34.000
the question of why are the patterns of human behavior

05:34.000 --> 05:36.000
as we increase our total technological capacity,

05:36.000 --> 05:40.000
why are they increasing catastrophic risk and why are we not solving them well?

05:40.000 --> 05:43.000
Are there underlying patterns that we could think of as,

05:43.000 --> 05:47.000
as you mentioned, generator functions of the catastrophic risk,

05:47.000 --> 05:49.000
generator functions of our inability to solve them,

05:49.000 --> 05:52.000
that if we were to identify those and work at that level,

05:52.000 --> 05:55.000
we could solve all of the expressions or symptoms.

05:55.000 --> 05:58.000
And if we don't work at that level, we might not be able to solve any of them.

05:58.000 --> 06:01.000
And again, people have been thinking about this for a long time,

06:01.000 --> 06:03.000
kind of notice these issues.

06:03.000 --> 06:08.000
They notice that you try to solve a,

06:08.000 --> 06:10.000
like the first one I noticed when I was a kid

06:10.000 --> 06:14.000
was trying to solve an elephant poaching issue in one particular region of Africa

06:14.000 --> 06:20.000
that didn't address the poverty of the people that had no mechanism other than black market on poaching,

06:20.000 --> 06:22.000
didn't address people's mindset towards animals,

06:22.000 --> 06:25.000
didn't address a macroeconomy that created poverty at scale.

06:25.000 --> 06:29.000
So when the laws were put in place and the fences were put in place

06:29.000 --> 06:31.000
to protect those elephants in that area better,

06:31.000 --> 06:34.000
the poachers moved to poaching other animals,

06:34.000 --> 06:38.000
particularly in that situation rhinos and gorillas

06:38.000 --> 06:40.000
that were both more endangered than the elephants had been.

06:40.000 --> 06:44.000
So you moved a problem from one area to another and actually a more sensitive area.

06:44.000 --> 06:47.000
And we see this with, well, can we solve hunger

06:47.000 --> 06:51.000
by bringing commercial agriculture to parts of the world that don't have it

06:51.000 --> 06:54.000
so that the people don't either not have food or we have to ship them food,

06:54.000 --> 06:58.000
but if it's commercial agriculture based on the kind of unsustainable,

06:58.000 --> 07:01.000
environmentally unsustainable agricultural processes

07:01.000 --> 07:04.000
that lead to huge amounts of nitrogen runoff going into river deltas

07:04.000 --> 07:06.000
that are causing dead zones in the ocean

07:06.000 --> 07:10.000
that can actually collapse the biosphere's capacity to support life faster

07:10.000 --> 07:13.000
than we're solving for a short-term issue that's important

07:13.000 --> 07:15.000
and driving even worse long-term issues.

07:15.000 --> 07:21.000
We see that many of the reasons people who oppose climate change solutions

07:21.000 --> 07:24.000
in the West oppose them is because,

07:24.000 --> 07:28.000
not because they have even really deeply engaged in the underlying science

07:28.000 --> 07:31.000
and say the climate change isn't real,

07:31.000 --> 07:33.000
that will oftentimes be what's said,

07:33.000 --> 07:36.000
but because the solution itself seems like it'll cause problems

07:36.000 --> 07:39.000
to other areas that they're paying attention to that seem even more critical to them.

07:39.000 --> 07:43.000
So if the solution involves some kind of carbon tax

07:43.000 --> 07:48.000
or something that would decrease GDP for the countries that agree to it

07:48.000 --> 07:51.000
and some other countries don't agree to it,

07:51.000 --> 07:53.000
and let's say in this particular case,

07:53.000 --> 07:56.000
the model that many people have is western countries agree to it,

07:56.000 --> 07:59.000
their GDP growth decreases, China doesn't agree to it,

07:59.000 --> 08:03.000
and there's already a very, very close neck-in-neck fight

08:03.000 --> 08:06.000
for who controls power in the 21st century.

08:06.000 --> 08:09.000
Are we seeding the world to Chinese control

08:09.000 --> 08:12.000
that many people would think it has less civil liberties

08:12.000 --> 08:15.000
and is more authoritarian in its nature?

08:15.000 --> 08:21.000
Or some people's answer to climate change is what we just have to use less energy,

08:21.000 --> 08:24.000
but when you understand that energy correlates directly to GDP

08:24.000 --> 08:27.000
and when GDP goes down, it affects poverty,

08:27.000 --> 08:29.000
people in extreme poverty first and worst,

08:29.000 --> 08:33.000
and wars increase because people who have desire to get more

08:33.000 --> 08:35.000
end up going zero sum on each other,

08:35.000 --> 08:38.000
and only when it's very positive sum does that not happen.

08:38.000 --> 08:40.000
You see all these intricate theory of trade-off,

08:40.000 --> 08:43.000
so we can't see that the problem is climate change.

08:43.000 --> 08:47.000
Everybody knows the problem of climate change seems like a big thing,

08:47.000 --> 08:52.000
but you've got to look at climate change plus the macroeconomic issues

08:52.000 --> 08:54.000
that would affect the poorest people

08:54.000 --> 08:56.000
and that would increase the chance of war

08:56.000 --> 09:01.000
and the geopolitical dynamics between the West and China,

09:01.000 --> 09:04.000
and the enforcement dynamics of international agreement.

09:04.000 --> 09:08.000
When you start to recognize that the problem is that suite of things together,

09:08.000 --> 09:12.000
in a way it seems, well, that's too hard, we can't even begin to focus on it.

09:12.000 --> 09:14.000
I would say that that's actually easier

09:14.000 --> 09:17.000
because trying to solve climate change on its own is actually impossible,

09:17.000 --> 09:21.000
because if you're trying to solve something

09:21.000 --> 09:24.000
that is going to externalize harm to some other thing,

09:24.000 --> 09:28.000
maybe you solve that thing,

09:28.000 --> 09:30.000
but you find out that you're in a worse position,

09:30.000 --> 09:33.000
so I would say that it's impossible to actually improve the world that way,

09:33.000 --> 09:37.000
or half the world that is paying attention to that other thing disagrees with you

09:37.000 --> 09:40.000
so vehemently that all the energy goes into infighting

09:40.000 --> 09:42.000
and whatever some part of the world is trying to organize to do,

09:42.000 --> 09:45.000
the other part of the world is doing everything they can to resist from happening,

09:45.000 --> 09:48.000
then all the creative energy just burns up as heat

09:48.000 --> 09:50.000
and we don't actually accomplish anything.

09:50.000 --> 09:55.000
So I would say that the way we're trying to solve the problems is actually mostly impossible.

09:55.000 --> 09:58.000
It either solves it in a very narrow way

09:58.000 --> 10:01.000
while externalizing harm and causing worse problems,

10:01.000 --> 10:05.000
or it makes it impossible to solve it all because it drives polarization.

10:05.000 --> 10:08.000
And so going to the level at which the problems interconnect

10:08.000 --> 10:11.000
where that which everybody cares about is being factored

10:11.000 --> 10:13.000
and where you're not externalizing other problems

10:13.000 --> 10:16.000
while it seems more complex is actually possible.

10:16.000 --> 10:18.000
Impossible is easier than impossible.

10:18.000 --> 10:23.000
And so it's not just that there's a lot of issues, right?

10:23.000 --> 10:25.000
There are a lot of issues,

10:25.000 --> 10:29.000
and just that the issues are both more consequential at greater scope

10:29.000 --> 10:31.000
and moving faster than previous issues

10:31.000 --> 10:34.000
because of the nature of exponentiating technology.

10:34.000 --> 10:35.000
That's part of it.

10:35.000 --> 10:37.000
It's not just that the problems are all interconnected.

10:37.000 --> 10:41.000
It's also that they do have underlying drivers that have to be addressed,

10:41.000 --> 10:44.000
otherwise a symptomatic only approach doesn't work.

10:44.000 --> 10:48.000
The first underlying driver that when people look at it they generally see

10:48.000 --> 10:55.000
is they see things like structural perverse incentive built into macroeconomics,

10:55.000 --> 11:00.000
that the elephant dead is worth more than the elephant alive is,

11:00.000 --> 11:02.000
and so is the rhino, and so is the...

11:02.000 --> 11:07.000
And so how do you have a situation where that's the nature of incentive,

11:07.000 --> 11:10.000
where you're incentivizing an activity and then trying to bind it,

11:10.000 --> 11:12.000
or keep it from happening?

11:12.000 --> 11:14.000
And the same would be true with overfishing,

11:14.000 --> 11:17.000
as long as live fish are worth nothing and dead fish are worth more.

11:17.000 --> 11:22.000
There's something fundamentally perverse about the nature of the economic incentive.

11:22.000 --> 11:29.000
And the same is true that when we have war and there's more military manufacturing, GDP goes up.

11:29.000 --> 11:33.000
And when there's more addiction and people are buying the supply of their addiction, GDP goes up.

11:33.000 --> 11:36.000
And when there are more sick people paying for health care, cost GDP goes up.

11:36.000 --> 11:40.000
So it's obviously a perverse kind of metric.

11:40.000 --> 11:46.000
So anytime someone can fiscally advantage themselves or a corporation can

11:46.000 --> 11:53.000
in a way that either directly causes harm or indirectly externalizes harm,

11:53.000 --> 11:55.000
we have to fundamentally solve that.

11:55.000 --> 11:59.000
If there's something like 70 trillion dollars a day of activity happening

11:59.000 --> 12:02.000
that is a decentralized system of incentive,

12:02.000 --> 12:06.000
that is incenting people to do things that are directly or indirectly causing harm,

12:06.000 --> 12:12.000
there's really nothing we can do with some billions of dollars of nonprofit or state

12:12.000 --> 12:14.000
or whatever money that is going to solve that thing.

12:14.000 --> 12:18.000
So we have to say, well, what changes at the level of macroeconomics need to happen

12:18.000 --> 12:23.000
where the incentive of individuals and the incentive of corporations and the incentive of nations

12:23.000 --> 12:26.000
is more well aligned with the well-being and the incentive of others.

12:26.000 --> 12:30.000
And so we're less fundamentally rivalrous in the nature of our incentive.

12:30.000 --> 12:37.000
So we can see that underneath heaps of the problems, structures of macroeconomic incentive are there.

12:37.000 --> 12:40.000
That's kind of maybe the first one that most people see.

12:40.000 --> 12:44.000
We can go deeper to seeing that even as an expression,

12:44.000 --> 12:49.000
because whether it's a economic incentive for a corporation or whether it's a power incentive,

12:49.000 --> 12:52.000
a political power incentive or a political party or for a country,

12:52.000 --> 12:57.000
they're both instantiations of rivalrous-type dynamics that end up driving arms races,

12:57.000 --> 13:01.000
because if you win at a rivalrous dynamic, the other side reverse-engineers your tech,

13:01.000 --> 13:05.000
figures out how to make better versions, comes back, which creates an exponentiation in warfare

13:05.000 --> 13:11.000
and eventually exponential warfare becomes self-terminating on a finite planet.

13:11.000 --> 13:14.000
Exponential externalities also become self-terminating.

13:14.000 --> 13:19.000
So if we want to say, what are the underlying generator functions of catastrophic risk?

13:19.000 --> 13:24.000
First, maybe just to make clear, the catastrophic risk landscape.

13:24.000 --> 13:29.000
Is this all right if we do a brief aside on that?

13:29.000 --> 13:30.000
Yeah, let's do it.

13:30.000 --> 13:34.000
I think what we should do, let's do that, and then let's recap just what these structures are.

13:34.000 --> 13:39.000
People are tracking each of these components, because you've already mentioned a few different things.

13:39.000 --> 13:46.000
The first thing is just many listeners might hear what you're sharing as an overwhelming set of problems,

13:46.000 --> 13:48.000
and I think it's just to recap.

13:48.000 --> 13:53.000
It's important people understand that it's overwhelming if you're not using a problem-solving framework

13:53.000 --> 13:56.000
that allows you to see the interconnected nature of those problems,

13:56.000 --> 13:59.000
because if you solve them with the limited tools we have now,

13:59.000 --> 14:03.000
let's just solve the social media problem by pulling one lever and changing one business model of one company,

14:03.000 --> 14:09.000
or banning TikTok, but then you get 20 other TikToks that come and sit in its place with the same perverse incentive of addiction,

14:09.000 --> 14:13.000
the same rival risk dynamic competing for human attention.

14:13.000 --> 14:15.000
We're going to end up perpetuating those problems.

14:15.000 --> 14:18.000
And so just to sort of maybe recap some of that for listeners,

14:18.000 --> 14:21.000
and I think maybe let you continue with the other generator function.

14:21.000 --> 14:24.000
Let's just make sure that people really get those frameworks.

14:24.000 --> 14:27.000
I think it's really important.

14:27.000 --> 14:33.000
Yeah, I mean, in the case that you in Center for Humane Technology have brought so much attention to,

14:33.000 --> 14:40.000
with regard to the attention harvesting and directing economy,

14:40.000 --> 14:50.000
it's fair to say that it probably was not Facebook or Google's goal to create the type of effects that they had.

14:50.000 --> 14:52.000
Those were unintended externalities.

14:52.000 --> 14:53.000
They were second order effects.

14:53.000 --> 14:55.000
But they were trying to solve problems, right?

14:55.000 --> 14:59.000
Like, let's solve the problem if we're Google of organizing the world's information and making better search.

14:59.000 --> 15:01.000
That seems like a pretty good thing to do.

15:01.000 --> 15:04.000
And let's solve the problem of making it freely available to everybody.

15:04.000 --> 15:06.000
That seems like a pretty good thing to do.

15:06.000 --> 15:09.000
And with the AdModel, we can make it freely available to everyone.

15:09.000 --> 15:14.000
And let's recognize that only if we get a lot of data will our machine learning get better.

15:14.000 --> 15:17.000
And so we need to actually get everybody on this thing.

15:17.000 --> 15:19.000
So we definitely have to make it free.

15:19.000 --> 15:24.000
And then we get this kind of recursive process.

15:24.000 --> 15:32.000
Well, then the nature of the AdModel, doing time on site optimization and stuff I'm not going to get into because you've addressed it so well,

15:32.000 --> 15:39.000
ends up appealing to people's existing biases rather than correcting their bias,

15:39.000 --> 15:42.000
appealing to their tribal in-group identities rather than correcting them,

15:42.000 --> 15:45.000
and appealing to limbic hijacks rather than helping people transcend them.

15:45.000 --> 15:54.000
And as a result, you end up actually breaking the social solidarity and epistemic capacity necessary for democracy.

15:54.000 --> 15:57.000
So it's like, oh, let's solve the search problem.

15:57.000 --> 15:58.000
That seems like a nice thing.

15:58.000 --> 16:03.000
The side effect is we're going to destroy democracy and open societies in the process and all those other things.

16:03.000 --> 16:08.000
Like, those are examples of solving a problem in a way that is externalizing harm,

16:08.000 --> 16:10.000
causing other problems that are oftentimes worse.

16:10.000 --> 16:15.000
And so let's just focus on the opportunity.

16:15.000 --> 16:21.000
And just to say, typically, this will get accounted for as, oh, this is just an unintended consequence.

16:21.000 --> 16:23.000
But there's some other generator functions I think we should outline.

16:23.000 --> 16:29.000
I mean, if YouTube and Google didn't personalize search results and what video to show you next,

16:29.000 --> 16:36.000
and the other guy did on TikTok starts personalizing, they're caught in a race to the bottom of whoever personalizes more for the best limbic hijack.

16:36.000 --> 16:40.000
And so just to sort of connect some of those things together for listeners.

16:40.000 --> 16:44.000
So you mentioned race to the bottom, and obviously CHT has discussed this before,

16:44.000 --> 16:51.000
and this is a key piece of the game theoretic challenge and global coordination.

16:51.000 --> 16:57.000
And the two primary ways it expresses itself is arms races and tragedy of the commons.

16:57.000 --> 17:07.000
And the tragedy of the commons scenario is if we don't overfish that area of virgin ocean,

17:07.000 --> 17:14.000
but we can't control that someone else doesn't, because how do we do enforcement if they're also a nuclear country?

17:14.000 --> 17:19.000
That's a tricky thing, right? How do you do enforcement on nuclear countries, equipped countries?

17:19.000 --> 17:23.000
So us not doing it doesn't mean that the fish don't all get taken.

17:23.000 --> 17:28.000
It just means that they grow their populations and their GDP faster, which they will use rivalrously.

17:28.000 --> 17:33.000
So we might as well do it. In fact, we might as well race to do it faster than they do.

17:33.000 --> 17:35.000
Those are the tragedy of the commons type issues.

17:35.000 --> 17:41.000
The arms race version is if we can't ensure that they don't build AI weapons or they don't build surveillance tech

17:41.000 --> 17:47.000
and they get increased near-term power from doing so, we just have to race to get there before them.

17:47.000 --> 17:49.000
That's the arms race type thing.

17:49.000 --> 17:54.000
It just happens to be that while that makes sense for each agent on their own in the short term,

17:54.000 --> 17:59.000
it creates global dynamics for the whole and the long term that self-terminate,

17:59.000 --> 18:04.000
because you can't run exponential externality on a finite planet.

18:04.000 --> 18:09.000
That's the tragedy of the commons one, and you can't run exponential arms races and exponential conflict on a finite planet.

18:09.000 --> 18:15.000
So the thing that has always made sense, which is just keep winning at the arms races,

18:15.000 --> 18:22.000
has had a world where we've had lots of wars increasing in their scale and lots of environmental damage.

18:22.000 --> 18:24.000
We started desertification thousands of years ago.

18:24.000 --> 18:30.000
It's just has been a long, slow, exponential curve that really started to pick up with the industrial revolution

18:30.000 --> 18:36.000
and is now really verticalizing with the digital revolution and the cumulative harm of that kind of thing becomes impossible now.

18:36.000 --> 18:45.000
So basically, with the environmental destruction, with the wars and with the class subjugation things that civilization has had in the past,

18:45.000 --> 18:52.000
pretty much anyone would say we have not been the best stewards of power, and technology is increasing our power.

18:52.000 --> 18:57.000
Exponential tech means tech that makes better versions of itself, so you get an exponent on the curve.

18:57.000 --> 19:00.000
We're now in a process where that's a very, very rapid.

19:00.000 --> 19:04.000
Computation gives the ability to design better systems of computation.

19:04.000 --> 19:13.000
Computation and AI applied to biological big data and protein folding gives the ability to do that on biotech and on and on, right?

19:13.000 --> 19:22.000
So we could say the central question of our time is if we've been poor stewards of power for a long time and that's always caused problems,

19:22.000 --> 19:26.000
but the problems now become existential, they become catastrophic, we can't keep doing that.

19:26.000 --> 19:35.000
How do we become adequately good stewards of exponential power in time, right?

19:35.000 --> 19:43.000
How do we develop the good decision-making processes, the wisdom necessary to be able to be stewards of that much power?

19:43.000 --> 19:47.000
I think that's a fair way to talk about the central thing.

19:47.000 --> 19:55.000
If it's okay, the thread we were about to get to, I think, is a good one, which was the history of catastrophic risk coming up to now,

19:55.000 --> 20:05.000
is that before World War II, catastrophic risk was actually a real part of people's experience.

20:05.000 --> 20:14.000
It was just always local, but an individual kingdom might face existential risk in a war where they would lose.

20:14.000 --> 20:22.000
And so the people faced those kinds of reality, and in fact, one thing that we can see when you read books like The Collapse of Complex Societies by Joseph Tainter

20:22.000 --> 20:34.000
and any study of history is that all the great civilizations don't still exist, which means that one of the first things we can say about civilizations is that they die.

20:34.000 --> 20:36.000
They have a finite lifespan on them.

20:36.000 --> 20:41.000
One of the interesting things we can find is that they usually die from self-induced causes.

20:41.000 --> 20:49.000
They either over-consume the resources and then stop being able to meet the needs of the people through unrenewable environmental dynamics, and that's old.

20:49.000 --> 21:01.000
Or they have increasing border conflicts that lead to enmity, that has more arms race activity coming back at them,

21:01.000 --> 21:11.000
or they have increasing institutional decay of their internal coordination processes that leads to inability to operate quickly in those types of things.

21:11.000 --> 21:22.000
So we can say that it's the fundamentally most all civilizations collapse in a way that is based on generally self-terminating dynamics.

21:22.000 --> 21:32.000
And we see that even when they were overtaken by armies, oftentimes they were armies that were smaller than ones they had defended against successfully at earlier peaks in their adaptive capacity.

21:32.000 --> 21:37.000
Okay, so catastrophic risk has been a real thing. It's just been local.

21:37.000 --> 21:48.000
And it wasn't until World War II that we had enough technological power that catastrophic risk became a global possibility for the first time ever.

21:48.000 --> 21:55.500
And this is a really important thing to get because the world before World War II and the world after was different and kind so fundamentally.

21:55.500 --> 22:04.000
And this is why when you study history, so much of what you're studying is history of warfare, of neighboring kingdoms and neighboring empires fighting.

22:04.000 --> 22:13.500
And because the wars were fundamentally winnable, at least for some, right? They weren't winnable for all the people who died, but at least for some.

22:13.500 --> 22:20.500
And with World War II and the development of the bomb became the beginning of wars that were no longer winnable.

22:20.500 --> 22:33.500
And that if we employed our full tech and continued the arms race even beyond the existing tech, it's a war where when lose becomes omni-lose-lose at that particular level of power.

22:33.500 --> 22:41.500
And so that created the need to do something that humanity had never done, which was that the major superpowers didn't war.

22:41.500 --> 22:46.500
The whole history of the world, the history of the thing we call civilization, they always did.

22:46.500 --> 22:54.500
And so we made an entire world system, a globalized world system that was with the aim of preventing World War III.

22:54.500 --> 23:03.500
So we could have non-kinetic wars, and we did, right? Increasingly you can see from World War II to now a movement to unconventional warfare,

23:03.500 --> 23:09.500
narrative and information warfare, economic, diplomatic warfare, those types of things, resource warfare.

23:09.500 --> 23:12.500
And you could, if you were going to have a physical kinetic war, it had to be a proxy war.

23:12.500 --> 23:19.500
But to have a proxy war, that also required narrative warfare to be able to create a justification for it.

23:19.500 --> 23:29.500
But also to be able to prevent the war, so the post-World War II Bretton Woods Mutually Assured Destruction United Nations World

23:29.500 --> 23:35.500
was a solution to be able to steward that level of tech without destroying ourselves.

23:35.500 --> 23:42.500
And it really was a reorganization of the world. It was a whole new advent of social technologies or social systems,

23:42.500 --> 23:46.500
just like the U.S. was new social technologies or social systems coming out of the Industrial Revolution.

23:46.500 --> 23:50.500
The Industrial Revolution ended up giving rise to kind of nation-state democracies.

23:50.500 --> 23:56.500
The nuclear revolution in this way kind of gave rise to this I.G.O. intergovernmental world.

23:56.500 --> 24:01.500
And it was predicated on a few things. Mutually Assured Destruction was critical.

24:01.500 --> 24:09.500
Globalization and economic trade was critical that we, if the computer that we're talking on and the phone that we talk on

24:09.500 --> 24:14.500
is made over six continents and no countries can make them on our own, we don't want to blow them up and ruin their infrastructure

24:14.500 --> 24:20.500
because we depend upon it. So let's create radical economic interdependence so we have more economic incentive to cooperate.

24:20.500 --> 24:29.500
Makes sense. And let's grow the materials economy so fast through this globalization

24:29.500 --> 24:34.500
that the world gets to be very positive GDP and gets to be very positive sum

24:34.500 --> 24:37.500
so that everybody can have more without having to take each other's stuff.

24:37.500 --> 24:41.500
That was kind of like the basis of that whole world system.

24:41.500 --> 24:45.500
And we can see that we've had wars, but they've been proxy wars and cold wars.

24:45.500 --> 24:49.500
They haven't been major superpower wars and they've been unconventional ones.

24:49.500 --> 24:56.500
But we haven't had a kinetic World War III. We have had increase of prosperity of certain kinds.

24:56.500 --> 25:03.500
75 years give or take. Now we're at a point where that radically positive sum economy

25:03.500 --> 25:09.500
that required an exponential growth of the economy, which means of the materials economy,

25:09.500 --> 25:15.500
and it's a linear materials economy that unrenewably takes resources from the earth faster than they can reproduce themselves

25:15.500 --> 25:20.500
and turns them into waste faster than they can process themselves, has led to the planetary boundaries issue

25:20.500 --> 25:28.500
where it's not just climate change or overfishing or dead zones in the ocean or microplastics or species extinction

25:28.500 --> 25:31.500
or peak phosphorus. It's a hundred things, right?

25:31.500 --> 25:38.500
There's all these planetary boundaries so we can't keep doing exponential linear materials economy.

25:38.500 --> 25:43.500
That thing has come to an end because now that drives its own set of catastrophic risks.

25:43.500 --> 25:48.500
We see that the radical interconnection of the world was good in terms of will not bomb each other

25:48.500 --> 25:55.500
but it also created very high fragility because what it meant is a failure anywhere could cascade to failures everywhere

25:55.500 --> 26:03.500
because of that much dependence. So we can see with COVID we had what was a local issue to an area of China

26:03.500 --> 26:08.500
but because of how interconnected the world is with travel it became a global issue at the pandemic level

26:08.500 --> 26:16.500
and it also became an issue where to shut down the transmission of the virus we shut down travel

26:16.500 --> 26:21.500
which also meant shut down supply chains which meant so many things, right?

26:21.500 --> 26:29.500
And very fundamental things that weren't obvious to people at first like that countries agriculture depends upon the shipment of pesticides that they don't have stored

26:29.500 --> 26:34.500
and so we got these swarms of locusts because of not having the pesticides which damaged the food supply

26:34.500 --> 26:43.500
and shipments of fertilizer and shipments of seed so we end up seeing a drive of food insecurity of extreme poverty

26:43.500 --> 26:47.500
at a scale of death threat that is larger than the COVID death threat was.

26:47.500 --> 26:52.500
As a second order effect of our problem we were trying to solve the problem of don't spread COVID

26:52.500 --> 26:57.500
and the solution had these massive second third order effects that are still playing out, right?

26:57.500 --> 27:04.500
And that was a relatively benign pandemic a relatively benign catastrophe compared to a lot of scenarios we can model out

27:04.500 --> 27:10.500
so we can say okay well we like the benefit of interconnectivity so we're not invested in bombing each other

27:10.500 --> 27:13.500
but we need more anti-fragility in the system.

27:13.500 --> 27:20.500
And then the mutually assured destruction thing doesn't work anymore because we don't have two countries with one catastrophe weapon

27:20.500 --> 27:24.500
that's really really hard to make and easy to monitor because there's not that many places that have uranium

27:24.500 --> 27:27.500
it's hard to enrich it you can monitor by satellites.

27:27.500 --> 27:33.500
We have lots of countries with nukes but we also have lots of new catastrophe weapons that are not hard to make

27:33.500 --> 27:37.500
that are not easy to monitor that don't even take nation states to make them.

27:37.500 --> 27:44.500
So if you have many many actors of different kinds with many different types of catastrophe weapons

27:44.500 --> 27:46.500
how do you do mutually assured destruction?

27:46.500 --> 27:48.500
You can't do it the same way.

27:48.500 --> 27:56.500
And so what we find is that the set of solutions post World War II that kept us from blowing ourselves up with our new power

27:56.500 --> 28:04.500
lasted for a while but those set of solutions have ended and they have now created their own set of new problems.

28:04.500 --> 28:10.500
So there's kind of the catastrophic risk world before World War II

28:10.500 --> 28:14.500
the catastrophic risk world from World War II till now and then the new thing.

28:14.500 --> 28:19.500
So the new thing says we have to have solutions that deal with the planetary boundary issues

28:19.500 --> 28:24.500
that deal with global fragility issues and that deal with the exponential tech issues

28:24.500 --> 28:28.500
both in terms of the way exponential tech can be intentionally used to cause harm

28:28.500 --> 28:31.500
i.e. exponential tech empowered warfare and unintentionally

28:31.500 --> 28:37.500
i.e. exponential tech empowered externalities and even just totally unanticipated types of mistakes

28:37.500 --> 28:42.500
the Facebook Google type problem multiplied by AGI and things like that.

28:42.500 --> 28:49.500
And so when we talk about what the catastrophic risk landscape is like that's the landscape

28:49.500 --> 28:55.500
the metacrisis is how do we solve all of that and recognizing that our problem solving mechanisms

28:55.500 --> 29:01.500
haven't even been able to solve the problems we've had for the last many years let alone prevent these things

29:01.500 --> 29:07.500
and so the central orienting question it's like the UNS-17 Sustainable Development Goals

29:07.500 --> 29:13.500
there's really one that must supersede them all which is develop the capacity for global coordination

29:13.500 --> 29:18.500
that can solve global problems. If you get that one you get all the other ones

29:18.500 --> 29:26.500
if you don't get that one you don't get any of the other ones and so we can talk about how do we do that

29:26.500 --> 29:32.500
but that becomes the central imperative for the world at this time.

29:32.500 --> 29:40.500
So you're saying a whole bunch of things and one thing that comes to mind here

29:40.500 --> 29:44.500
if I'm just reading back some of the things you've shared

29:44.500 --> 29:48.500
the development of the let's call it one of the first exponential technologies which is the nuclear bomb

29:48.500 --> 29:55.500
led to a new social system which was sort of the post Bretton Woods world of trying to stabilize

29:55.500 --> 29:59.500
that one exponential technology in the world in a way that would not be catastrophic

29:59.500 --> 30:02.500
and even there we weren't able to sort of make it all work

30:02.500 --> 30:07.500
and I think people should have maybe a list of some of the other exponential technologies

30:07.500 --> 30:12.500
because I want to make sure that phrase is defined for listeners and there's a lot of different ways

30:12.500 --> 30:17.500
that we've now not just created more exponential technologies but more decentralized exponential technologies

30:17.500 --> 30:23.500
and I think people should see Facebook and Google as exponential attention mapping

30:23.500 --> 30:28.500
or information driving technologies that are shaping the global information flows

30:28.500 --> 30:33.500
or the wiring diagram of the sort of global societal brain at scales that are exponential

30:33.500 --> 30:39.500
it's sort of a nuclear scale rewiring of the human civilization

30:39.500 --> 30:42.500
we couldn't do that with newspapers we couldn't do that with a printing press

30:42.500 --> 30:44.500
not at the scale speed et cetera that we have now

30:44.500 --> 30:47.500
so do you want to give maybe some more examples of exponential technologies

30:47.500 --> 30:51.500
because I think that's going to lead to we're going to need a new kinds of social systems

30:51.500 --> 30:57.500
to manage this different landscape of not just one exponential nuclear bomb but a landscape

30:57.500 --> 31:04.500
indulge me as I tell a story first that leads into it because it'll be a relevant framework

31:04.500 --> 31:09.500
obviously the bomb was central to World War II and the world system that came afterwards

31:09.500 --> 31:14.500
and what motivated our activity getting into it but it was not the only tech

31:14.500 --> 31:20.500
it was one new technology that was part of a suite of new technologies that could all be developed

31:20.500 --> 31:23.500
because of kind of the level science had gotten to

31:23.500 --> 31:30.500
and basically like physics and chemistry had gotten to the point that we could work on a nuclear bomb

31:30.500 --> 31:33.500
we could start to work on computation

31:33.500 --> 31:41.500
we could get things like the V2 rocket and rockets and a whole host of applied chemistry

31:41.500 --> 31:46.500
and one way of thinking about what World War II was

31:46.500 --> 31:51.500
one way of thinking about it but it's useful frame and I think it's a fair frame

31:51.500 --> 31:56.500
is that there were a few competing social ideologies at the time

31:56.500 --> 32:04.500
primarily kind of German fascism fascism socialism whatever you want to call it

32:04.500 --> 32:10.500
Soviet communism and Western liberalism something like that

32:10.500 --> 32:17.500
and that this new suite of technologies whoever kind of developed it and was able to implement it at scale first would win

32:17.500 --> 32:21.500
that social ideology would win because it's just so much more powerful

32:21.500 --> 32:24.500
if you have nukes and they have guns you're going to win right

32:24.500 --> 32:28.500
and Germans were actually ahead of both the US and the Soviets

32:28.500 --> 32:33.500
because of some things that they did to invest in education and tech development

32:33.500 --> 32:39.500
but that led both the Soviets and the US to really working to catch up as fast as they can

32:39.500 --> 32:44.500
and when the US finally figured it out which we were actually a little bit slow to right

32:44.500 --> 32:48.500
Einstein actually wrote a letter the Einstein solar letter that went to the US government

32:48.500 --> 32:52.500
saying now the science really does say that this thing could happen and the Germans could get it

32:52.500 --> 32:55.500
and you should focus on it and at first they didn't take them up on it

32:55.500 --> 33:00.500
it wasn't until the private sector actually nonprofit supported advanced it further

33:00.500 --> 33:05.500
that then the Manhattan Project was engaged in but then it was engaged in when they recognized the seriousness

33:05.500 --> 33:13.500
that there was an actual eminent existential risk to the nation and the whole Western ideology and whatever

33:13.500 --> 33:17.500
then it was an unlimited budget right it was a let's find all the smartest people in the world

33:17.500 --> 33:21.500
and let's bring them here and let's organize however we need to to make this thing happen

33:21.500 --> 33:26.500
and let's do it for all of the new areas of tech we're going to get the enigma machine and crack the enigma code

33:26.500 --> 33:30.500
we're going to get a v2 rocket we're going to figure out how to reverse engineer that in advanced rocketry

33:30.500 --> 33:34.500
we're going to do everything needed to make a nuclear bomb and then more advanced ones

33:34.500 --> 33:40.500
it was the biggest jump in technology ever in the history of the world in record history as we know it

33:40.500 --> 33:45.500
and it wasn't actually done by the market right it was done by the state that's a very important thing

33:45.500 --> 33:49.500
this idea that markets innovate and states don't innovate is just historically not true here

33:49.500 --> 33:55.500
this was state funds and state controlled operation in the same way that the Apollo project coming out of it was

33:55.500 --> 34:04.500
and a technological jump of that kind hasn't happened since

34:04.500 --> 34:11.500
so it's an important thing to understand but we can say though this is not a totally fair thing to say

34:11.500 --> 34:16.500
we can say that the US came out dominant in that technological race

34:16.500 --> 34:22.500
the US and the USSR both had a lot of capacity so that was the Cold War and then finally the US came out

34:22.500 --> 34:26.500
and so the post-World War II system was a US led system

34:26.500 --> 34:31.500
the UN was in the US the Bretton Wood system was pegged to the US dollar

34:31.500 --> 34:38.500
what I would say is that so it wasn't one type of tech

34:38.500 --> 34:43.500
it was the recognition that science had got to a place where there's going to be a whole suite of new tech

34:43.500 --> 34:49.500
and the new tech meant more power and whoever had the power would determine the next phase of the world

34:49.500 --> 34:54.500
and if we didn't like the social ideologies that were going to be guiding it

34:54.500 --> 34:59.500
of course we can also think of it as just who wanted to win at the game of power

34:59.500 --> 35:05.500
but from the philosophical argument if we didn't like the social ideologies then we have another social ideology

35:05.500 --> 35:06.500
get it

35:06.500 --> 35:11.500
what I would say is that there is an emerging suite of technologies now

35:11.500 --> 35:20.500
that is much more powerful in the total level of jump

35:20.500 --> 35:23.500
technological jump than the World War II suite was

35:23.500 --> 35:25.500
in fact orders of magnitude more

35:25.500 --> 35:32.500
and only those who are developing and employing exponential tech

35:32.500 --> 35:34.500
will have much of a say in the direction of the future

35:34.500 --> 35:38.500
because just from a real politic point of view that's where the power is

35:38.500 --> 35:42.500
and if you don't have the power you won't be able to oppose it

35:42.500 --> 35:45.500
and so what do we mean by exponential tech?

35:45.500 --> 35:47.500
there's a couple different ways of thinking about it

35:47.500 --> 35:50.500
just exponentially more powerful is a very simplistic way

35:50.500 --> 35:53.500
and in that definition nuclear is exponential tech

35:53.500 --> 36:00.500
but what we typically mean with exponential tech is tech that makes it possible to make better versions of itself

36:00.500 --> 36:03.500
so that there is like a compounding interest kind of curve

36:03.500 --> 36:07.500
the tech makes it easier to make a better version which makes it easier to make a better version

36:07.500 --> 36:12.500
and so we see that starting with computation really in a fundamental way

36:12.500 --> 36:17.500
because computation allows us to advance models of computation

36:17.500 --> 36:19.500
how do we make better computational substrates

36:19.500 --> 36:22.500
how do we get more transistors in a chip

36:22.500 --> 36:27.500
how do we make better arrangements of chip so we get GPUs and those types of things

36:27.500 --> 36:34.500
and so in this new suite of technology the center of it is computation

36:34.500 --> 36:39.500
the very very center of that is AI

36:39.500 --> 36:45.500
is kind of self-learning computation on large fields of data

36:45.500 --> 36:54.500
the other kind of software advances like advances in various meaningful advances in cryptography

36:54.500 --> 37:02.500
and big data and the ability to get data from sensors and you know sensor processing image recognition

37:02.500 --> 37:05.500
that is a part of that central suite

37:05.500 --> 37:12.500
and the application of that to the directing of attention and the directing of behavior by directing attention

37:12.500 --> 37:15.500
which you focused on very centrally

37:15.500 --> 37:19.500
then the next phase is the application of the tech

37:19.500 --> 37:24.500
the application of computation to increasing computational substrate

37:24.500 --> 37:29.500
so this is now the software advancing the hardware that can advance the total level of software

37:29.500 --> 37:33.500
so that's not just continuously better chips

37:33.500 --> 37:37.500
it's also quantum computing, photo computing, DNA computing, those other types of things

37:37.500 --> 37:41.500
and the other types of hardware that need to be part of that thing

37:41.500 --> 37:44.500
i.e. sensor tech in particular

37:44.500 --> 37:50.500
so that you can keep getting more data going into that system that can do big data machine learning on it

37:50.500 --> 37:55.500
then it's the application of that computation in AI specifically to physical tech

37:55.500 --> 38:01.500
so to nanotech, material sciences, biotech and even things like modeling how to do better nuclear

38:01.500 --> 38:05.500
and you know robotics and automation

38:05.500 --> 38:10.500
and so when you start thinking about better computational substrates running better software

38:10.500 --> 38:13.500
with more total data going in with better sensors in better robots

38:13.500 --> 38:17.500
you start getting the sense of what that whole suite of things looks like

38:18.500 --> 38:26.500
so that's the suite of things that I would say is what we would kind of call exponential tech

38:26.500 --> 38:33.500
and the reason why the term exponential is important is we don't think exponentially well

38:33.500 --> 38:38.500
our intuitions are bad for it because we think about how much progress was made over the last five years

38:38.500 --> 38:40.500
and we imagine there will be a similar amount over the next five years

38:40.500 --> 38:43.500
and that's not the way exponential curves work, right?

38:43.500 --> 38:48.500
and so it's very hard for us, our intuition was calibrated on the past

38:48.500 --> 38:55.500
and it's going to be miscalibrated for forecasting the total rate of change and the magnitude of change

38:58.500 --> 39:04.500
so to link this for one much more narrow aspect for our listeners who are familiar with social media

39:04.500 --> 39:10.500
and social dilemma and you're talking about sort of self-compounding systems that improve recursively like that

39:11.500 --> 39:18.500
if I'm TikTok or if I'm Facebook and I use data to figure out what's the thing to show you

39:18.500 --> 39:22.500
and that's going to keep you here for long since going to bypass your prefrontal cortex

39:22.500 --> 39:25.500
and go straight to your limbic system, your lizard brain

39:25.500 --> 39:28.500
well the better it gets at doing that and succeeding at that

39:28.500 --> 39:30.500
the more data it has to make a better prediction the next time

39:30.500 --> 39:32.500
but then a new user comes along who it's never seen before

39:32.500 --> 39:36.500
but hey they're clicking on exactly the same pattern of anorexia videos

39:36.500 --> 39:39.500
that we've seen these other 2 million users have that turn out to be teenage girls

39:39.500 --> 39:43.500
and it just happens to know that this other set of videos that are more anorexia videos

39:43.500 --> 39:45.500
are also going to work really really well

39:45.500 --> 39:48.500
so there's sort of a self-compounding loop that's learning not just from one person

39:48.500 --> 39:52.500
and getting a better version of hijacking your nervous system

39:52.500 --> 39:54.500
but learning across individuals

39:54.500 --> 39:57.500
and so now you get a new person coming in from developing countries

39:57.500 --> 40:02.500
never used TikTok before and they're just barely walking in for the front door the very first time

40:02.500 --> 40:05.500
it's sort of like when Coca-Cola goes to Southeast Asia for the first time

40:05.500 --> 40:10.500
and you get diabetes 10 years later because you refined all the techniques of marketing so effectively

40:10.500 --> 40:13.500
but now happening at scales that are automated with computation

40:13.500 --> 40:16.500
so what you're talking about is the impact of computation

40:16.500 --> 40:18.500
and learning on top of learning data on top of data

40:18.500 --> 40:21.500
and then cross-referencing look-alike models and all of this kind of thing

40:21.500 --> 40:24.500
you could apply to the domain at least that social dilemma

40:24.500 --> 40:28.500
watchers and people who are familiar with our work might be able to tie into

40:28.500 --> 40:34.500
Yeah, the more people you have in the system and the more data per person that you're able to harvest

40:34.500 --> 40:38.500
the more stuff you have for the machine learning to figure out patterns on

40:38.500 --> 40:42.500
which also means that the machine learning can provide things that the users want more

40:42.500 --> 40:46.500
even if it's manufactured want, right, even if it's manufactured demand

40:46.500 --> 40:49.500
which means that then more users will come and put more data in

40:49.500 --> 40:54.500
and it can specifically figure out how to manufacture the types of behavior that increase data collection

40:54.500 --> 41:00.500
and so you do get this recursive process on how many people, how much data, how good are the machine learning algorithms

41:00.500 --> 41:05.500
you know, that kind of thing and this is one of the reasons that we see these natural monopoly formations

41:05.500 --> 41:08.500
within these categories of tech

41:08.500 --> 41:12.500
and this is another reason that's important to understand like

41:12.500 --> 41:18.500
these types of self-reinforcing dynamics and things like network effects like Metcalf's law

41:18.500 --> 41:23.500
didn't exist when the Scottish Enlightenment was coming up with its ideas of capitalism

41:23.500 --> 41:27.500
and market and the healthy competition and markets and why that creates checks and balances on power

41:27.500 --> 41:31.500
they didn't exist, Adam Smith did not get to think about those things

41:31.500 --> 41:38.500
and so when you have a situation where the value of the network is proportional to the square of the

41:38.500 --> 41:45.500
people coming into the network then you're incented to keep it free up front, maximize addiction, drive behavior into the system

41:45.500 --> 41:54.500
and then once you get to the kind of breakaway point on the return of that thing

41:54.500 --> 41:58.500
it becomes nearly impossible for anyone else to come in and overtake that thing

41:58.500 --> 42:01.500
so you get a power law distribution in each vertical

42:01.500 --> 42:05.500
you get one online market that is bigger than all the other online markets

42:05.500 --> 42:09.500
one video player that's bigger than all the other video players, one search, one social network one

42:09.500 --> 42:15.500
and that's not because of a government monopoly, that's because of this kind of natural tech monopoly

42:15.500 --> 42:20.500
this also means that when we created the laws around monopolies they don't apply to this thing

42:20.500 --> 42:26.500
and yet this thing still has the same spirit of power concentration and unchecked power

42:26.500 --> 42:32.500
that our ideas of monopoly had but it's able to grow much faster than law is able to figure out how to deal with it

42:32.500 --> 42:36.500
or faster than economic theory can change itself, right?

42:36.500 --> 42:41.500
and so one of the things that we see is that our social technologies like law, like governance, like economics

42:41.500 --> 42:46.500
are actually being obsolete by the development of totally new types of behavior and mechanics

42:46.500 --> 42:52.500
that weren't part of the world they were trying to solve problems for, right?

42:52.500 --> 42:58.500
and so the Scottish Enlightenment was the development of new ideas of how to problem solve, the problems of its time

42:58.500 --> 43:03.500
the constitution was trying to figure out how to solve the problems of its time

43:03.500 --> 43:06.500
I would say they were good thinking, right? they were good work

43:06.500 --> 43:10.500
the Bretton Woods world was, none of them are adequate to solve these problems

43:10.500 --> 43:13.500
because these problems are different in kind

43:13.500 --> 43:18.500
and even where they're just an extension of magnitude, when you get enough change in magnitude

43:18.500 --> 43:22.500
sometimes it becomes a difference in kind, like as you're getting more and more information to process

43:22.500 --> 43:26.500
once you get past what humans can process, infosingularity type issues

43:26.500 --> 43:30.500
okay, well now it's a difference in magnitude that becomes a difference in kind

43:30.500 --> 43:33.500
which means you need a fundamentally different approach

43:33.500 --> 43:38.500
so I would say this is where it's important to recognize that those social technologies that we loved so much

43:38.500 --> 43:41.500
because they seemed so much better than all the other options we had at the time

43:41.500 --> 43:44.500
like markets and like democracy

43:44.500 --> 43:47.500
these are not terminal goods in and of themselves

43:47.500 --> 43:50.500
the terminal goods were things like human liberty

43:50.500 --> 43:54.500
and justice and checks and balances on power

43:54.500 --> 44:00.500
and opportunity and distribution of opportunity and things like that

44:00.500 --> 44:04.500
these were the best social technologies possible at the time

44:04.500 --> 44:07.500
the new technologies both kill those things

44:07.500 --> 44:08.500
they don't work anymore, right?

44:08.500 --> 44:12.500
you can't have the social technology of the fourth estate

44:12.500 --> 44:14.500
that was necessary for democracy

44:14.500 --> 44:16.500
which is why founding fathers said things like

44:16.500 --> 44:18.500
if I could have perfect newspapers and a broken government

44:18.500 --> 44:21.500
or perfect government and broken newspapers, I'd take the newspapers

44:21.500 --> 44:24.500
because if you have an educated populace that all understands what's going on

44:24.500 --> 44:26.500
they can make a new form of government

44:26.500 --> 44:28.500
if you have people that have no idea what's going on

44:28.500 --> 44:32.500
how could they possibly make good choices if their sense making is totally broken

44:32.500 --> 44:36.500
so we had this idea that the fourth estate was a prerequisite

44:36.500 --> 44:38.500
to a participatory governance

44:38.500 --> 44:44.500
but that was based on a very narrow limited capacity for print

44:44.500 --> 44:47.500
and again it was the technology of the Gutenberg Press

44:47.500 --> 44:50.500
that was one of the things that actually ended feudalism

44:50.500 --> 44:54.500
and so the founding fathers were employing that new tech

44:54.500 --> 44:57.500
both because it upended the previous tech and it made this new thing possible

44:57.500 --> 44:59.500
same with guns

44:59.500 --> 45:03.500
they needed guns and second amendments to make this new thing possible

45:03.500 --> 45:07.500
but once we get to a internet world

45:07.500 --> 45:09.500
where you don't have centralized broadcasts

45:09.500 --> 45:11.500
you have decentralized and then there's so much stuff

45:11.500 --> 45:13.500
that you can never possibly find at all in search

45:13.500 --> 45:15.500
whoever coordinates the search

45:15.500 --> 45:18.500
the content aggregators, which is the Facebook, the YouTube, whatever

45:18.500 --> 45:21.500
are doing it with the types of business models we have

45:21.500 --> 45:23.500
the fourth estate is just dead forever

45:23.500 --> 45:26.500
that old version, there's no way to recreate that version

45:26.500 --> 45:28.500
that either means democracy is dead forever

45:28.500 --> 45:31.500
or anything like a well-informed citizenry

45:31.500 --> 45:33.500
that could participate in its governance in any form

45:33.500 --> 45:39.500
or you have to say what is a post-internet, post-social media, post-infosingularity

45:39.500 --> 45:43.500
fourth estate that creates an adequately educated citizenry

45:43.500 --> 45:46.500
that's thinking about the way that our social technologies

45:46.500 --> 45:49.500
our social systems have to upgrade themselves

45:49.500 --> 45:52.500
in the presence of the tech that obsoleted the way they did work

45:52.500 --> 45:54.500
but we can also see and we can give examples of this

45:54.500 --> 45:58.500
the new tech also makes possible new things that weren't possible before

45:58.500 --> 46:00.500
so we can do something better than industrial-era democracy

46:00.500 --> 46:02.500
or industrial-era markets

46:02.500 --> 46:04.500
which is why I say they aren't a terminal good

46:04.500 --> 46:07.500
they're a way to deliver certain human values that really matter

46:07.500 --> 46:10.500
and the new technology that obsoletes those

46:10.500 --> 46:15.500
can actually also be facilitative in designing systems

46:15.500 --> 46:17.500
that also serve those values

46:17.500 --> 46:19.500
but it's not a given that it does

46:19.500 --> 46:22.500
that has to become the kind of central orienting mission

46:22.500 --> 46:26.500
so Dan just to make sure we're linking this back to the start of this conversation

46:26.500 --> 46:28.500
we started this conversation by saying

46:28.500 --> 46:31.500
the way that we are going about solving problems

46:31.500 --> 46:36.500
let's say using the legacy systems of lawmaking in a congress

46:36.500 --> 46:40.500
or using the legacy systems of a town hall to vote on a proposition

46:40.500 --> 46:45.500
or trying to pass laws as fast as social media as rewiring society

46:45.500 --> 46:47.500
the lines don't match

46:47.500 --> 46:49.500
and so what you're saying is that

46:49.500 --> 46:52.500
and just for listeners because I know that you use the phrase social technology

46:52.500 --> 46:55.500
but I think you're really talking about it

46:55.500 --> 46:58.500
social systems, ways of organizing democracy

46:58.500 --> 47:01.500
technology in the most fundamental sense of the word

47:01.500 --> 47:07.500
of something humans design to facilitate certain kinds of activity or outcomes

47:07.500 --> 47:09.500
like language is a technology

47:09.500 --> 47:11.500
or democracy is a technology

47:11.500 --> 47:13.500
social systems

47:13.500 --> 47:17.500
and so if the kind of old world approach of

47:17.500 --> 47:19.500
some people might be hearing this and say to themselves

47:19.500 --> 47:20.500
now hold on a second

47:20.500 --> 47:22.500
so we have all these institutions

47:22.500 --> 47:24.500
we have all these structures

47:24.500 --> 47:25.500
we live in a democracy

47:25.500 --> 47:28.500
and we live in a system that is working the way it does

47:28.500 --> 47:30.500
it has its courts, it has its attorney generals

47:30.500 --> 47:32.500
it has its litigation procedures

47:32.500 --> 47:34.500
it has its lawmaking bodies

47:34.500 --> 47:37.500
if you're saying that we can't use those things

47:37.500 --> 47:39.500
because they're not adequate

47:39.500 --> 47:41.500
or they won't help us solve those problems

47:41.500 --> 47:43.500
we need to have new social systems

47:43.500 --> 47:46.500
maybe you could give us some hope about why that might be feasible

47:46.500 --> 47:48.500
instead of feeling impossible

47:48.500 --> 47:51.500
because this is actually precedented in our history

47:51.500 --> 47:53.500
when new technologies show up

47:53.500 --> 47:55.500
and then new social systems emerge

47:55.500 --> 47:58.500
to make room for those technologies functioning well

47:58.500 --> 47:59.500
you briefly touched on that

47:59.500 --> 48:03.500
but I think it's important to give listeners a few concrete examples

48:03.500 --> 48:08.500
there's a number of good academics and disciplines of academics

48:08.500 --> 48:12.500
that look at the history of evolutions and physical technology

48:12.500 --> 48:15.500
and the corresponding evolutions in

48:15.500 --> 48:18.500
thought and culture and social systems

48:18.500 --> 48:21.500
Marvin Harris, the cultural materialism

48:21.500 --> 48:23.500
did a kind of major opus work here

48:23.500 --> 48:26.500
where he specifically looked at how changes in social systems and cultures

48:26.500 --> 48:28.500
followed changes in technology

48:28.500 --> 48:31.500
there are other bodies of work that will

48:31.500 --> 48:33.500
look at the social systems as primary

48:33.500 --> 48:35.500
or the cultures as primary

48:35.500 --> 48:37.500
and we can say they're inter-affecting

48:37.500 --> 48:40.500
but for instance

48:40.500 --> 48:43.500
the vast majority of human history was tribal

48:43.500 --> 48:46.500
however much 200,000 years of humans

48:46.500 --> 48:50.500
in the small Dunbar number villages

48:50.500 --> 48:52.500
there was a social technology

48:52.500 --> 48:53.500
social systems that mediated that

48:53.500 --> 48:55.500
that had to do with how the tribal circles worked

48:55.500 --> 48:59.500
and the nature of how resources were shared

48:59.500 --> 49:01.500
it was a very different kind of economic system

49:01.500 --> 49:03.500
a very different kind of judicial system

49:03.500 --> 49:05.500
a different educational system

49:05.500 --> 49:06.500
it had all those things

49:06.500 --> 49:07.500
it had a way of education

49:07.500 --> 49:09.500
meaning intergenerational knowledge transfer

49:09.500 --> 49:11.500
of the entire knowledge set that was needed

49:11.500 --> 49:15.500
for the tribe to continue operating

49:15.500 --> 49:18.500
the development of certain technologies

49:18.500 --> 49:20.500
particularly the plow

49:20.500 --> 49:23.500
but baskets and a few other things

49:23.500 --> 49:24.500
obsolete that thing

49:24.500 --> 49:27.500
because all of a sudden it made possible

49:27.500 --> 49:28.500
big amounts of surplus

49:28.500 --> 49:31.500
that made reason for much larger populations

49:31.500 --> 49:32.500
to emerge

49:32.500 --> 49:34.500
those larger populations

49:34.500 --> 49:36.500
were going to win in conflict against

49:36.500 --> 49:38.500
the smaller populations

49:38.500 --> 49:40.500
and so you can see that then the emergence

49:40.500 --> 49:41.500
of new social technology

49:41.500 --> 49:43.500
to facilitate large groups of people

49:43.500 --> 49:45.500
empire types

49:45.500 --> 49:47.500
civilization technology emerged

49:47.500 --> 49:49.500
you can see

49:49.500 --> 49:52.500
and that there were a few other shifts in technology

49:52.500 --> 49:55.500
that evolved the types of empires that were there

49:55.500 --> 49:57.500
and then the next one that people talk about a lot

49:57.500 --> 49:59.500
is the industrial revolution

49:59.500 --> 50:01.500
from the printing press specifically

50:01.500 --> 50:02.500
and then steam engine

50:02.500 --> 50:04.500
the gunpowder revolution was part of it

50:04.500 --> 50:06.500
that kind of ended feudalism

50:06.500 --> 50:08.500
and began the nation state world

50:08.500 --> 50:10.500
and so you can see like

50:10.500 --> 50:13.500
what is the thing that the founding fathers

50:13.500 --> 50:14.500
in the US were doing

50:14.500 --> 50:17.500
well they weren't trying to keep winning at feudalism

50:17.500 --> 50:19.500
there was a game that had been happening

50:19.500 --> 50:20.500
for a long time

50:20.500 --> 50:21.500
and they were saying

50:21.500 --> 50:23.500
like no we're all people who are in

50:23.500 --> 50:25.500
of the type of people who could do well

50:25.500 --> 50:26.500
at that system

50:26.500 --> 50:28.500
and rather than do that

50:28.500 --> 50:29.500
we recognize that there are

50:29.500 --> 50:31.500
fundamentally things wrong with this system

50:31.500 --> 50:33.500
and fundamentally new possibilities

50:33.500 --> 50:35.500
that hadn't been previously recognized

50:35.500 --> 50:37.500
so we're going to actually try to design

50:37.500 --> 50:39.500
a fundamentally different system

50:39.500 --> 50:40.500
that we think

50:40.500 --> 50:42.500
a more perfect union

50:42.500 --> 50:44.500
that makes life liberty in the pursuit of happiness

50:44.500 --> 50:45.500
better for everybody

50:45.500 --> 50:47.500
and increases productive capacity

50:47.500 --> 50:48.500
and things like that

50:48.500 --> 50:50.500
so that was fundamentally in advance

50:50.500 --> 50:52.500
in social technology or social systems

50:52.500 --> 50:53.500
that both utilized

50:53.500 --> 50:55.500
new physical technology

50:55.500 --> 50:57.500
and was enabled by it

51:00.500 --> 51:02.500
in the current situation

51:03.500 --> 51:05.500
there are groups that are advancing

51:05.500 --> 51:07.500
the exponential technologies

51:07.500 --> 51:09.500
and that means whatever social systems

51:09.500 --> 51:10.500
that they're employing

51:10.500 --> 51:12.500
are the social systems of the future

51:12.500 --> 51:13.500
if we don't change it

51:13.500 --> 51:15.500
and that's what I want to get to in a moment

51:15.500 --> 51:18.500
but like who is working to

51:18.500 --> 51:21.500
implement any of the new emerging

51:21.500 --> 51:23.500
tech for better social systems

51:23.500 --> 51:25.500
that are aligned with social systems we want

51:25.500 --> 51:27.500
you've had Audrey Tang

51:27.500 --> 51:28.500
on the show

51:28.500 --> 51:30.500
do you want to just briefly describe

51:30.500 --> 51:32.500
an example of what she

51:32.500 --> 51:34.500
and what they have done there

51:34.500 --> 51:36.500
because if people aren't aware of it

51:36.500 --> 51:38.500
that's a pretty prime example

51:38.500 --> 51:40.500
of for this particular iteration

51:40.500 --> 51:42.500
sure well

51:42.500 --> 51:45.500
and maybe just to go back briefly

51:45.500 --> 51:47.500
because you gave this example

51:47.500 --> 51:49.500
in one of our earlier conversations

51:49.500 --> 51:51.500
that the printing press

51:51.500 --> 51:53.500
could have been used by the feudal lords

51:53.500 --> 51:55.500
for consciously reinforcing feudalism

51:55.500 --> 51:57.500
but instead this new technology

51:57.500 --> 51:59.500
the printing press gives way

51:59.500 --> 52:01.500
to new ways of organizing society

52:01.500 --> 52:03.500
so we can actually have things like

52:03.500 --> 52:05.500
a fourth estate or newspapers

52:05.500 --> 52:07.500
or things like that

52:07.500 --> 52:09.500
both happen

52:09.500 --> 52:11.500
but then the new thing theoretically

52:11.500 --> 52:13.500
has to win out over the old thing

52:13.500 --> 52:15.500
at least the one that we want

52:15.500 --> 52:17.500
that holds the values that the society wants

52:17.500 --> 52:19.500
so

52:19.500 --> 52:21.500
I think a lot of people can hear our conversation

52:21.500 --> 52:23.500
we've had this riff before

52:23.500 --> 52:25.500
actually following our last episode

52:25.500 --> 52:27.500
after my senate testimony

52:27.500 --> 52:29.500
speaking about a frame

52:29.500 --> 52:31.500
that you have offered and know well

52:31.500 --> 52:33.500
which is that we can notice

52:33.500 --> 52:35.500
that digital authoritarian societies

52:35.500 --> 52:37.500
right now like China

52:37.500 --> 52:39.500
are consciously using exponential technologies

52:39.500 --> 52:41.500
to make stronger more effective digital

52:41.500 --> 52:43.500
closed and authoritarian societies

52:43.500 --> 52:45.500
and in contrast digital open societies

52:45.500 --> 52:47.500
democracies like the United States

52:47.500 --> 52:49.500
are not consciously using technology

52:49.500 --> 52:51.500
to make stronger healthier open societies

52:51.500 --> 52:53.500
instead they've sort of surrendered

52:53.500 --> 52:55.500
what they are to

52:55.500 --> 52:57.500
private technology

52:57.500 --> 52:59.500
corporations pursuing self-interest

52:59.500 --> 53:01.500
to shareholders and are

53:01.500 --> 53:03.500
profiting from the degradation

53:03.500 --> 53:05.500
and dysfunction of democracies

53:05.500 --> 53:07.500
and so

53:07.500 --> 53:09.500
when we say all this and we talk about

53:09.500 --> 53:11.500
how do we build the kind of next social system

53:11.500 --> 53:13.500
and Audrey Tang and her work

53:13.500 --> 53:15.500
I think people

53:15.500 --> 53:17.500
get tripped up in thinking that what we really mean

53:17.500 --> 53:19.500
is we have to make some kind of 21st century

53:19.500 --> 53:21.500
digital democracy in fact I probably said those words

53:21.500 --> 53:23.500
but what we're really talking about here

53:23.500 --> 53:25.500
is some new concept that preserves

53:25.500 --> 53:27.500
the principles of what we meant by

53:27.500 --> 53:29.500
a democracy

53:29.500 --> 53:31.500
but instantiated with the new technologies

53:31.500 --> 53:33.500
our version of the new printing press

53:33.500 --> 53:35.500
which is networked

53:35.500 --> 53:37.500
information environments and

53:37.500 --> 53:39.500
all of the new capacities that we have in the 21st century

53:39.500 --> 53:41.500
with

53:41.500 --> 53:43.500
mobility where everyone's connected to everywhere

53:43.500 --> 53:45.500
and everything all at once

53:45.500 --> 53:47.500
so what is that system

53:47.500 --> 53:49.500
that leverages the current technology

53:49.500 --> 53:51.500
and makes a stronger healthier open society

53:51.500 --> 53:53.500
and I think Audrey Tang's work

53:53.500 --> 53:55.500
I mean I would probably send listeners back

53:55.500 --> 53:57.500
to listen to that episode I think it's one of our

53:57.500 --> 53:59.500
most listened to and most popular episodes for a reason

53:59.500 --> 54:01.500
because in Taiwan

54:01.500 --> 54:03.500
she's essentially built an entire

54:03.500 --> 54:05.500
civic technology ecosystem

54:05.500 --> 54:07.500
in which people are really participating

54:07.500 --> 54:09.500
in the governance of their society

54:09.500 --> 54:11.500
we need masks, we need

54:11.500 --> 54:13.500
better air quality sensors, we need to fix these

54:13.500 --> 54:15.500
potholes, there are processes

54:15.500 --> 54:17.500
by which every time you're frustrated by something

54:17.500 --> 54:19.500
you actually get invited into a civic design process

54:19.500 --> 54:21.500
where whether it's the potholes or the masks

54:21.500 --> 54:23.500
you can actually participate in having a better

54:23.500 --> 54:25.500
system

54:25.500 --> 54:27.500
complaining about the tax system and filing your taxes

54:27.500 --> 54:29.500
and maybe it's an inefficient form

54:29.500 --> 54:31.500
or something like that you get brought into a design process

54:31.500 --> 54:33.500
of what would make it better

54:33.500 --> 54:35.500
and so the system is participatory but not in that

54:35.500 --> 54:37.500
kind of 18th century way of hey there's a

54:37.500 --> 54:39.500
physical wooden townhouse and we're going to walk into it

54:39.500 --> 54:41.500
and we're going to hang out there for three hours

54:41.500 --> 54:43.500
and we're going to yell and scream about issues that are more local

54:43.500 --> 54:45.500
within 10, 15 miles

54:45.500 --> 54:47.500
of where we are because we were existing in a world before automobiles

54:47.500 --> 54:49.500
we're now talking about how do you do

54:49.500 --> 54:51.500
an open society social system

54:51.500 --> 54:53.500
but in a world with all of the new technologies

54:53.500 --> 54:55.500
that are not just here today but emerging

54:55.500 --> 54:57.500
and so do you want to talk a little bit

54:57.500 --> 54:59.500
about what

54:59.500 --> 55:01.500
how we even navigate that challenge

55:01.500 --> 55:03.500
and why is some new social system like that

55:03.500 --> 55:05.500
necessary

55:05.500 --> 55:07.500
for dealing with these problems that you've

55:07.500 --> 55:09.500
sort of laid out at the beginning

55:09.500 --> 55:11.500
because I'm sure people would like to feel

55:11.500 --> 55:13.500
less anxiety about those things

55:13.500 --> 55:15.500
hanging around for longer

55:15.500 --> 55:17.500
yeah I think

55:17.500 --> 55:19.500
I think what

55:19.500 --> 55:21.500
Taiwan has been doing

55:21.500 --> 55:23.500
and what Audrey Tang

55:23.500 --> 55:25.500
in the digital ministry position

55:25.500 --> 55:27.500
in particular has been leading

55:27.500 --> 55:29.500
is probably the best example

55:29.500 --> 55:31.500
certainly one of the best examples in the world of this kind of

55:31.500 --> 55:33.500
process in thinking

55:33.500 --> 55:35.500
and

55:35.500 --> 55:37.500
does it apply in the

55:37.500 --> 55:39.500
or could it apply in the exact same way to the US

55:39.500 --> 55:41.500
no of course not like we know that

55:41.500 --> 55:43.500
because

55:43.500 --> 55:45.500
of the relatively small geography

55:45.500 --> 55:47.500
and

55:47.500 --> 55:49.500
high-speed train transportation

55:49.500 --> 55:51.500
you can get across Taiwan in an hour and a half

55:51.500 --> 55:53.500
and so when you're mentioning the small scale

55:53.500 --> 55:55.500
of local government at the beginning of the US

55:55.500 --> 55:57.500
where you come to the town hall in a way they have

55:57.500 --> 55:59.500
that right like it's 23 million people

55:59.500 --> 56:01.500
but there is

56:01.500 --> 56:03.500
an older shared culture

56:03.500 --> 56:05.500
there is all there also happens

56:05.500 --> 56:07.500
to be an existential threat just right

56:07.500 --> 56:09.500
off their border that is

56:09.500 --> 56:11.500
you know big enough that they can't

56:11.500 --> 56:13.500
just chill and not focus on it

56:13.500 --> 56:15.500
everyone has to be civically engaged

56:15.500 --> 56:17.500
with some civic identity and like that

56:17.500 --> 56:19.500
they didn't start making

56:19.500 --> 56:21.500
their culture in the industrial era and then have to

56:21.500 --> 56:23.500
upgrade it right like they started

56:23.500 --> 56:25.500
later

56:25.500 --> 56:27.500
where they're we're able to start at a higher

56:27.500 --> 56:29.500
level of the tech stack

56:29.500 --> 56:31.500
so there's a number of reasons why it's different

56:31.500 --> 56:33.500
so we're not going to naively say what you do

56:33.500 --> 56:35.500
in a tiny country that is culturally

56:35.500 --> 56:37.500
and ethnically homogeneous

56:39.500 --> 56:41.500
and has a higher GDP

56:41.500 --> 56:43.500
education per capita and whatever is the same thing

56:43.500 --> 56:45.500
you would do but we can certainly take a lot

56:45.500 --> 56:47.500
of the examples and say how would

56:47.500 --> 56:49.500
they apply differently in different

56:49.500 --> 56:51.500
contexts

56:53.500 --> 56:55.500
so

56:55.500 --> 56:57.500
the thing we said earlier

56:57.500 --> 56:59.500
that this suite of

56:59.500 --> 57:01.500
exponential technologies is so much more powerful

57:01.500 --> 57:03.500
than all of the previous types

57:03.500 --> 57:05.500
of power that only

57:05.500 --> 57:07.500
those who are

57:07.500 --> 57:09.500
developing and deploying

57:09.500 --> 57:11.500
them will be

57:11.500 --> 57:13.500
really steering the direction of the future

57:13.500 --> 57:15.500
and

57:15.500 --> 57:17.500
that there are ways of employing them

57:17.500 --> 57:19.500
that do cause

57:19.500 --> 57:21.500
catastrophic risk

57:21.500 --> 57:23.500
and

57:23.500 --> 57:25.500
the catastrophic risk is of two primary

57:25.500 --> 57:27.500
kinds right conflict theory mediated

57:27.500 --> 57:29.500
and

57:29.500 --> 57:31.500
you can't

57:31.500 --> 57:33.500
you just can't do warfare

57:33.500 --> 57:35.500
with this level of technology

57:35.500 --> 57:37.500
and this interconnected a world

57:37.500 --> 57:39.500
and make it through well

57:39.500 --> 57:41.500
not all catastrophic risk means existential

57:41.500 --> 57:43.500
doesn't all mean nuclear

57:43.500 --> 57:45.500
war and nuclear winter and we've killed

57:45.500 --> 57:47.500
all the mammals on earth it might

57:47.500 --> 57:49.500
just mean we break global supply chains

57:49.500 --> 57:51.500
kill lots of people and regress

57:51.500 --> 57:53.500
humanity and the quality of the biosphere

57:53.500 --> 57:55.500
pretty significantly so

57:55.500 --> 57:57.500
I'm not

57:57.500 --> 57:59.500
just focused on existential risk I'm interested

57:59.500 --> 58:01.500
in kind of catastrophic risk

58:01.500 --> 58:03.500
at scale in general

58:03.500 --> 58:05.500
and we can see that exponential tech

58:05.500 --> 58:07.500
applied

58:07.500 --> 58:09.500
as

58:09.500 --> 58:11.500
in conflict theory and in

58:11.500 --> 58:13.500
mistake

58:13.500 --> 58:15.500
as externalities and the cumulative effects

58:15.500 --> 58:17.500
could you define

58:17.500 --> 58:19.500
conflict theory and mistake theory for people

58:19.500 --> 58:21.500
who are not familiar with those terms

58:21.500 --> 58:23.500
yeah there's

58:23.500 --> 58:25.500
a very nice

58:25.500 --> 58:27.500
discussion on the less wrong forum

58:27.500 --> 58:29.500
if people are interested to go deeper

58:29.500 --> 58:31.500
and it's this question of

58:31.500 --> 58:33.500
how much of the problems in the world

58:33.500 --> 58:35.500
are the result of

58:35.500 --> 58:37.500
conflict theory versus mistake theory

58:37.500 --> 58:39.500
meaning conflict theory is

58:39.500 --> 58:41.500
we knew we either wanted to cause

58:41.500 --> 58:43.500
that problem that harm to whomever

58:43.500 --> 58:45.500
as in a knowingly wanted to win

58:45.500 --> 58:47.500
at a war and

58:47.500 --> 58:49.500
or at least we knew we were

58:49.500 --> 58:51.500
going to cause that problem and didn't care because

58:51.500 --> 58:53.500
it was attached to something we wanted

58:53.500 --> 58:55.500
right conflict theory or mistake

58:55.500 --> 58:57.500
theory we didn't know we didn't want to cause

58:57.500 --> 58:59.500
it and we really didn't know and it was just

58:59.500 --> 59:01.500
unintended unanticipatable consequence

59:01.500 --> 59:03.500
and it's fair to say that there's

59:03.500 --> 59:05.500
both right there's plenty of both

59:05.500 --> 59:07.500
one

59:07.500 --> 59:09.500
thing that is worth knowing is that

59:09.500 --> 59:11.500
if I

59:11.500 --> 59:13.500
if I'm trying to do something that is

59:13.500 --> 59:15.500
actually motivated by conflict theory

59:15.500 --> 59:17.500
it benefits me to pretend that it was mistake

59:17.500 --> 59:19.500
theory benefits me to pretend that I had no idea

59:19.500 --> 59:21.500
and then afterwards say oh it was

59:21.500 --> 59:23.500
an unintended unanticipatable consequence

59:23.500 --> 59:25.500
it was too complex people can't predict stuff

59:25.500 --> 59:27.500
like that and so

59:27.500 --> 59:29.500
the reality

59:29.500 --> 59:31.500
of mistake theory

59:31.500 --> 59:33.500
ends up being a source of plausible

59:33.500 --> 59:35.500
deniability for conflict theory

59:35.500 --> 59:37.500
and

59:37.500 --> 59:39.500
but they're both things and we have to

59:39.500 --> 59:41.500
overcome both meaning we have to

59:41.500 --> 59:43.500
have choice making processes in our new system

59:43.500 --> 59:45.500
of coordination and like this sounds

59:45.500 --> 59:47.500
like maybe hippy stuff

59:47.500 --> 59:49.500
until you take

59:49.500 --> 59:51.500
seriously the change of context

59:51.500 --> 59:53.500
oh we have to have problems of choice making that

59:53.500 --> 59:55.500
consider the whole that sounds like

59:55.500 --> 59:57.500
unrealizable hippy stuff

59:57.500 --> 59:59.500
until you realize

59:59.500 --> 01:00:01.500
but we're making choices that affect

01:00:01.500 --> 01:00:03.500
the whole

01:00:03.500 --> 01:00:05.500
at a level that

01:00:05.500 --> 01:00:07.500
can even individually be catastrophic

01:00:07.500 --> 01:00:09.500
and is definitely catastrophic cumulatively

01:00:09.500 --> 01:00:11.500
so if we aren't factoring

01:00:11.500 --> 01:00:13.500
it

01:00:13.500 --> 01:00:15.500
then the human experiment self terminates and maybe that's

01:00:15.500 --> 01:00:17.500
the answer to the great filter hypothesis

01:00:17.500 --> 01:00:19.500
right and so

01:00:19.500 --> 01:00:21.500
our

01:00:21.500 --> 01:00:23.500
well yeah

01:00:23.500 --> 01:00:25.500
I think people don't have an intuitive grasp of

01:00:25.500 --> 01:00:27.500
what it means that each of us

01:00:27.500 --> 01:00:29.500
are walking around with the power of

01:00:29.500 --> 01:00:31.500
gods to influence huge enormous

01:00:31.500 --> 01:00:33.500
consequences I mean

01:00:33.500 --> 01:00:35.500
I could give a few examples every time you

01:00:35.500 --> 01:00:37.500
enact with the global supply chain and hit buy on Amazon

01:00:37.500 --> 01:00:39.500
you invisibly enacted

01:00:39.500 --> 01:00:41.500
shipping and planes

01:00:41.500 --> 01:00:43.500
and petroleum and wars in the middle east

01:00:43.500 --> 01:00:45.500
there's a whole bunch of things that we're

01:00:45.500 --> 01:00:47.500
sort of tied into when you are

01:00:47.500 --> 01:00:49.500
posting something on social media and have

01:00:49.500 --> 01:00:51.500
more than a million followers you're

01:00:51.500 --> 01:00:53.500
influencing the global information ecology

01:00:53.500 --> 01:00:55.500
and if you're angry and biased about one

01:00:55.500 --> 01:00:57.500
side of the other of the pandemic is real

01:00:57.500 --> 01:00:59.500
or it's not real or something like that you're

01:00:59.500 --> 01:01:01.500
externalizing more bias into the commons

01:01:01.500 --> 01:01:03.500
of how keep the rest of the world understands

01:01:03.500 --> 01:01:05.500
things so we're walking around with increasing

01:01:05.500 --> 01:01:07.500
power but I don't think the increasing power

01:01:07.500 --> 01:01:09.500
that we've granted is intuitive

01:01:09.500 --> 01:01:11.500
for some folks did you explain

01:01:11.500 --> 01:01:13.500
some more examples of that there's both

01:01:13.500 --> 01:01:15.500
cumulative effect and

01:01:15.500 --> 01:01:17.500
like cumulative long-term

01:01:17.500 --> 01:01:19.500
and fairly singular short-term

01:01:19.500 --> 01:01:21.500
and cumulative long-term

01:01:21.500 --> 01:01:23.500
I mean you go back to

01:01:25.500 --> 01:01:27.500
early

01:01:27.500 --> 01:01:29.500
US settlers coming into the

01:01:29.500 --> 01:01:31.500
US moving west

01:01:31.500 --> 01:01:33.500
and they're being buffalo everywhere and there had

01:01:33.500 --> 01:01:35.500
been buffalo everywhere for a very long time

01:01:35.500 --> 01:01:37.500
and then there's no buffalo in whole areas that

01:01:37.500 --> 01:01:39.500
were forested with old growth forest became

01:01:39.500 --> 01:01:41.500
deforested and it was

01:01:41.500 --> 01:01:43.500
like no it's impossible we could never get rid of all the

01:01:43.500 --> 01:01:45.500
buffalo like I we could never

01:01:45.500 --> 01:01:47.500
cut down all the trees but the cumulative effect

01:01:47.500 --> 01:01:49.500
of lots of people thinking that way we're individually

01:01:49.500 --> 01:01:51.500
I have no incentive to leave the buffalo alive

01:01:51.500 --> 01:01:53.500
and I do have an incentive for my family individually

01:01:53.500 --> 01:01:55.500
to kill it but everybody thinking

01:01:55.500 --> 01:01:57.500
that way and

01:01:57.500 --> 01:01:59.500
increasing our

01:01:59.500 --> 01:02:01.500
desire for how much we consume per capita

01:02:01.500 --> 01:02:03.500
our technology that allows us

01:02:03.500 --> 01:02:05.500
to consume more per capita

01:02:05.500 --> 01:02:07.500
and developing more capital

01:02:07.500 --> 01:02:09.500
more total people well

01:02:09.500 --> 01:02:11.500
then you start getting

01:02:11.500 --> 01:02:13.500
environmental destruction and species extinction at scale

01:02:13.500 --> 01:02:15.500
and that's a long time ago

01:02:15.500 --> 01:02:17.500
right like that's much lower tech and much less

01:02:17.500 --> 01:02:19.500
people and it's

01:02:19.500 --> 01:02:21.500
distributed action it's a

01:02:21.500 --> 01:02:23.500
cumulative effect issue

01:02:23.500 --> 01:02:25.500
and obviously we see that with

01:02:27.500 --> 01:02:29.500
nobody's intending to fill the

01:02:29.500 --> 01:02:31.500
ocean with microplastics

01:02:31.500 --> 01:02:33.500
but everybody's buying shit that is filling the

01:02:33.500 --> 01:02:35.500
oceans with microplastics and

01:02:35.500 --> 01:02:37.500
so everyone is participating with systems where

01:02:37.500 --> 01:02:39.500
the system as a whole

01:02:39.500 --> 01:02:41.500
is sociopathic the system is self-terminating

01:02:41.500 --> 01:02:43.500
the system doesn't exist without all the agents

01:02:43.500 --> 01:02:45.500
interacting with it all the agents feel like

01:02:45.500 --> 01:02:47.500
their behavior is so small

01:02:47.500 --> 01:02:49.500
that that justifies everybody doing

01:02:49.500 --> 01:02:51.500
that thing right so that's what we

01:02:51.500 --> 01:02:53.500
mean by cumulative kind of catastrophic risk

01:02:53.500 --> 01:02:55.500
but it's

01:02:55.500 --> 01:02:57.500
also true that

01:02:57.500 --> 01:02:59.500
whoever made

01:02:59.500 --> 01:03:01.500
that

01:03:01.500 --> 01:03:03.500
thermite bomb and hooked it to a drone and hit

01:03:03.500 --> 01:03:05.500
the Ukrainian munitions factory a couple years

01:03:05.500 --> 01:03:07.500
ago that caused a billion dollars

01:03:07.500 --> 01:03:09.500
in damage exploded munitions factory

01:03:09.500 --> 01:03:11.500
the effect of a bomb as big

01:03:11.500 --> 01:03:13.500
as the largest

01:03:13.500 --> 01:03:15.500
nuclear bomb the U.S. arsenal has an incendiary bomb

01:03:15.500 --> 01:03:17.500
this is a home

01:03:17.500 --> 01:03:19.500
that was a homemade little bomb in a

01:03:19.500 --> 01:03:21.500
drone right and

01:03:21.500 --> 01:03:23.500
so and crisper gene

01:03:23.500 --> 01:03:25.500
drives are

01:03:25.500 --> 01:03:27.500
cheap and easy and it doesn't take

01:03:27.500 --> 01:03:29.500
that much advanced

01:03:29.500 --> 01:03:31.500
knowledge to start working with them and

01:03:31.500 --> 01:03:33.500
so that that starts to look

01:03:33.500 --> 01:03:35.500
like

01:03:35.500 --> 01:03:37.500
individuals and small

01:03:37.500 --> 01:03:39.500
groups with real catastrophic ability

01:03:39.500 --> 01:03:41.500
not long-term and cumulatively

01:03:41.500 --> 01:03:43.500
the increase in our tech

01:03:43.500 --> 01:03:45.500
gives us both issues via

01:03:45.500 --> 01:03:47.500
globalization and the overall system you

01:03:47.500 --> 01:03:49.500
get these cumulative long-term effects

01:03:49.500 --> 01:03:51.500
and with the exponential

01:03:51.500 --> 01:03:53.500
tech creating decentralized catastrophic

01:03:53.500 --> 01:03:55.500
capabilities one

01:03:55.500 --> 01:03:57.500
of the core questions we have to answer is how do we

01:03:57.500 --> 01:03:59.500
make a world that is anti fragile

01:03:59.500 --> 01:04:01.500
in the presence of

01:04:01.500 --> 01:04:03.500
those kind of catastrophic capabilities that are

01:04:03.500 --> 01:04:05.500
easy to produce and thus

01:04:05.500 --> 01:04:07.500
decentralizable

01:04:07.500 --> 01:04:09.500
and so

01:04:09.500 --> 01:04:11.500
how do we do that

01:04:11.500 --> 01:04:13.500
what are the social systems that we need

01:04:13.500 --> 01:04:15.500
to employ to bind some of these

01:04:15.500 --> 01:04:17.500
bad

01:04:17.500 --> 01:04:19.500
facts and ways that the natural

01:04:19.500 --> 01:04:21.500
inclinations of self-interested actors

01:04:21.500 --> 01:04:23.500
will drive things in that direction just

01:04:23.500 --> 01:04:25.500
to link this to the social media space for people

01:04:25.500 --> 01:04:27.500
if I know that I can get

01:04:27.500 --> 01:04:29.500
a little bit more attention and a little bit

01:04:29.500 --> 01:04:31.500
more likes and clicks and follows and shares

01:04:31.500 --> 01:04:33.500
and so on if I exaggerate the truth

01:04:33.500 --> 01:04:35.500
by five percent just to use a little bit

01:04:35.500 --> 01:04:37.500
more of an extreme adjective

01:04:37.500 --> 01:04:39.500
you know I know that that in the long

01:04:39.500 --> 01:04:41.500
run would be bad if everybody did that

01:04:41.500 --> 01:04:43.500
but for me right now I can win a few hits

01:04:43.500 --> 01:04:45.500
and I can get more influence and I'm an Instagram influencer

01:04:45.500 --> 01:04:47.500
and I'm making ten thousand dollars a month and if I don't do it

01:04:47.500 --> 01:04:49.500
I'm noticing everyone else's do it and if I don't use

01:04:49.500 --> 01:04:51.500
the filter everyone else is using the filter

01:04:51.500 --> 01:04:53.500
and so everyone ends up in this sort of another race

01:04:53.500 --> 01:04:55.500
at the bottom sort of situation

01:04:55.500 --> 01:04:57.500
that has that kind of cumulative degradation

01:04:57.500 --> 01:04:59.500
or cumulative

01:04:59.500 --> 01:05:01.500
derangement where there's increasing distance

01:05:01.500 --> 01:05:03.500
between what is true and what people believe

01:05:03.500 --> 01:05:05.500
because we've all been subtly exaggerating it

01:05:05.500 --> 01:05:07.500
to make our point and gain influence and so on

01:05:07.500 --> 01:05:09.500
and so

01:05:09.500 --> 01:05:11.500
just to give another example

01:05:11.500 --> 01:05:13.500
maybe for listeners in kind of the space that they're

01:05:13.500 --> 01:05:15.500
more familiar with

01:05:15.500 --> 01:05:17.500
but going back I mean the whole premise

01:05:17.500 --> 01:05:19.500
of this is as we gain more

01:05:19.500 --> 01:05:21.500
exponential technologies that have

01:05:21.500 --> 01:05:23.500
more capacity and more hands

01:05:23.500 --> 01:05:25.500
so instead of having just the US and Russia having this

01:05:25.500 --> 01:05:27.500
you have

01:05:27.500 --> 01:05:29.500
whether as you mentioned CRISPR gene drives or

01:05:29.500 --> 01:05:31.500
some of the drone things that are out there

01:05:31.500 --> 01:05:33.500
more and more people have access to these things

01:05:33.500 --> 01:05:35.500
how can we bind

01:05:35.500 --> 01:05:37.500
those kinds of forces and what are the

01:05:37.500 --> 01:05:39.500
social systems that we need to make that happen

01:05:39.500 --> 01:05:41.500
yeah I want to go back

01:05:41.500 --> 01:05:43.500
as you were describing this

01:05:43.500 --> 01:05:45.500
I was thinking about how many people

01:05:45.500 --> 01:05:47.500
who

01:05:47.500 --> 01:05:49.500
listen to your show

01:05:49.500 --> 01:05:51.500
who maybe work in technology who might have

01:05:51.500 --> 01:05:53.500
they work in technology

01:05:53.500 --> 01:05:55.500
because they see the positive things technology can do

01:05:55.500 --> 01:05:57.500
and have more of a kind of techno-optimist

01:05:57.500 --> 01:05:59.500
point of view and this overall conversation

01:05:59.500 --> 01:06:01.500
might sound very techno-pessimist and

01:06:01.500 --> 01:06:03.500
like did we not

01:06:03.500 --> 01:06:05.500
read Pinker and watch Hans Rosling and

01:06:05.500 --> 01:06:07.500
you know those types of things

01:06:07.500 --> 01:06:09.500
and

01:06:09.500 --> 01:06:11.500
so I want to speak to that briefly

01:06:15.500 --> 01:06:17.500
first this is a meta-point

01:06:17.500 --> 01:06:19.500
but it's worth saying right now

01:06:19.500 --> 01:06:21.500
particularly in on this podcast

01:06:21.500 --> 01:06:23.500
and in the kind of post-truth

01:06:23.500 --> 01:06:25.500
post or fake fact

01:06:25.500 --> 01:06:27.500
world where then so much

01:06:27.500 --> 01:06:29.500
of the emphasis has gone into we need fact

01:06:29.500 --> 01:06:31.500
checkers and we need real

01:06:31.500 --> 01:06:33.500
facts

01:06:33.500 --> 01:06:35.500
obviously it's possible

01:06:35.500 --> 01:06:37.500
to have an epistemic

01:06:37.500 --> 01:06:39.500
error or even intentional error in the

01:06:39.500 --> 01:06:41.500
process of generating a fact

01:06:41.500 --> 01:06:43.500
is there corruption in the institutions

01:06:43.500 --> 01:06:45.500
and that kind of thing but let's even say that wasn't

01:06:45.500 --> 01:06:47.500
an issue and the things that go through the right epistemic

01:06:47.500 --> 01:06:49.500
process as facts are facts

01:06:49.500 --> 01:06:51.500
can you lie with facts

01:06:51.500 --> 01:06:53.500
totally can you can you mislead

01:06:53.500 --> 01:06:55.500
with facts yeah because nobody

01:06:55.500 --> 01:06:57.500
is going to make their choice on one fact

01:06:57.500 --> 01:06:59.500
they make their choice based on a situational assessment

01:06:59.500 --> 01:07:01.500
based on a narrative based on a gestalt

01:07:01.500 --> 01:07:03.500
of a whole thing that's lots of different facts

01:07:03.500 --> 01:07:05.500
well which facts do I include and which facts do I not

01:07:05.500 --> 01:07:07.500
include and

01:07:07.500 --> 01:07:09.500
am I de-contextualizing the fact

01:07:09.500 --> 01:07:11.500
so

01:07:11.500 --> 01:07:13.500
the quality of life has gone up

01:07:13.500 --> 01:07:15.500
so much because we average person lived

01:07:15.500 --> 01:07:17.500
on less than a dollar a day in the US in 1815

01:07:17.500 --> 01:07:19.500
and now they live on this many dollars

01:07:19.500 --> 01:07:21.500
a day which inflation adjusted means higher quality

01:07:21.500 --> 01:07:23.500
of life yeah but in 1815 most

01:07:23.500 --> 01:07:25.500
of their needs didn't come through dollars

01:07:25.500 --> 01:07:27.500
they grew their own vegetables they hunted

01:07:27.500 --> 01:07:29.500
so I'm de-contextualizing

01:07:29.500 --> 01:07:31.500
the facts to compare something that's really apples

01:07:31.500 --> 01:07:33.500
and oranges so even if the fact is quote unquote

01:07:33.500 --> 01:07:35.500
true the de-contextualization and

01:07:35.500 --> 01:07:37.500
recontextualization makes it seem like it means

01:07:37.500 --> 01:07:39.500
something different than it means

01:07:39.500 --> 01:07:41.500
and the same with the cherry picking

01:07:41.500 --> 01:07:43.500
of facts and I can very easily

01:07:43.500 --> 01:07:45.500
say oh there's a lower percentage of people in extreme

01:07:45.500 --> 01:07:47.500
poverty but I might also be changing the definitions

01:07:47.500 --> 01:07:49.500
of extreme poverty I can also

01:07:49.500 --> 01:07:51.500
rather than focus on percentage say well there's more

01:07:51.500 --> 01:07:53.500
total people in poverty than there were total people

01:07:53.500 --> 01:07:55.500
in the world before the industrial revolution so like

01:07:55.500 --> 01:07:57.500
so there's the

01:07:57.500 --> 01:07:59.500
abilities to de-contextualize

01:07:59.500 --> 01:08:01.500
and recontextualize facts there's the ability to

01:08:01.500 --> 01:08:03.500
cherry pick facts and there's

01:08:03.500 --> 01:08:05.500
the ability to lake off frame facts

01:08:05.500 --> 01:08:07.500
and put particular kinds

01:08:07.500 --> 01:08:09.500
of sentiment and moral valence

01:08:09.500 --> 01:08:11.500
on it and so am I talking about them as

01:08:11.500 --> 01:08:13.500
illegal aliens or undocumented

01:08:13.500 --> 01:08:15.500
workers and I get a very different kind

01:08:15.500 --> 01:08:17.500
of sentiment so talking about it

01:08:17.500 --> 01:08:19.500
as a pre-owned car or a used car

01:08:19.500 --> 01:08:21.500
everyone loves a pre-owned car no one wants

01:08:21.500 --> 01:08:23.500
a used car and so these

01:08:23.500 --> 01:08:25.500
very simple semantic frames

01:08:25.500 --> 01:08:27.500
contextual frames cherry picking

01:08:27.500 --> 01:08:29.500
of the things means that I can

01:08:29.500 --> 01:08:31.500
make a narrative

01:08:31.500 --> 01:08:33.500
where all the facts went through the most

01:08:33.500 --> 01:08:35.500
rigorous fact checker and yet the narrative

01:08:35.500 --> 01:08:37.500
as a whole is misleading

01:08:37.500 --> 01:08:39.500
and so fact checking is necessary

01:08:39.500 --> 01:08:41.500
but it is not sufficient for a good

01:08:41.500 --> 01:08:43.500
epistemic and good sense making and not

01:08:43.500 --> 01:08:45.500
only is it not sufficient it's even weaponizable

01:08:45.500 --> 01:08:47.500
this is a very important thing

01:08:47.500 --> 01:08:49.500
to understand because if you are not

01:08:49.500 --> 01:08:51.500
pursuing that

01:08:51.500 --> 01:08:53.500
you're if you're not recognizing

01:08:53.500 --> 01:08:55.500
that you might be believing

01:08:55.500 --> 01:08:57.500
nonsense thinking that you're using

01:08:57.500 --> 01:08:59.500
epistemic rigor

01:09:01.500 --> 01:09:03.500
okay so the techno pessimists

01:09:03.500 --> 01:09:05.500
and the techno optimists both cherry pick

01:09:05.500 --> 01:09:07.500
and they both lake off

01:09:07.500 --> 01:09:09.500
frame and

01:09:09.500 --> 01:09:11.500
this is true with

01:09:11.500 --> 01:09:13.500
all the difference in almost every

01:09:13.500 --> 01:09:15.500
political ideology the woke and the

01:09:15.500 --> 01:09:17.500
woke the

01:09:17.500 --> 01:09:19.500
the pro socialist

01:09:19.500 --> 01:09:21.500
pro capitalist you'll notice that the way

01:09:21.500 --> 01:09:23.500
they do their arguments the

01:09:23.500 --> 01:09:25.500
systemic racism is really really terrible

01:09:25.500 --> 01:09:27.500
no there's not that bad the systemic racism

01:09:27.500 --> 01:09:29.500
they both have stats

01:09:29.500 --> 01:09:31.500
but this is actually you can almost think

01:09:31.500 --> 01:09:33.500
of it as statistical warfare as a tool

01:09:33.500 --> 01:09:35.500
of narrative warfare and

01:09:37.500 --> 01:09:39.500
so this is where

01:09:39.500 --> 01:09:41.500
a higher level of earnestness

01:09:41.500 --> 01:09:43.500
rather than a particular

01:09:43.500 --> 01:09:45.500
bested interest or bias a higher willingness

01:09:45.500 --> 01:09:47.500
to look at biases a higher level of rigor

01:09:47.500 --> 01:09:49.500
you know ends up being critical to

01:09:49.500 --> 01:09:51.500
actually overcome any of these things

01:09:51.500 --> 01:09:53.500
so

01:09:53.500 --> 01:09:55.500
can I cherry pick stats that make it look like everything is getting

01:09:55.500 --> 01:09:57.500
better totally those things are true

01:09:57.500 --> 01:09:59.500
and nobody wants to go back to a world

01:09:59.500 --> 01:10:01.500
before novocaine when you have to do dentistry

01:10:01.500 --> 01:10:03.500
and

01:10:03.500 --> 01:10:05.500
nobody wants to go back to a world before

01:10:05.500 --> 01:10:07.500
penicillin when basic bacterial infections go around

01:10:07.500 --> 01:10:09.500
and like there's totally good stuff that has

01:10:09.500 --> 01:10:11.500
emerged

01:10:11.500 --> 01:10:13.500
and are there all

01:10:13.500 --> 01:10:15.500
kinds of

01:10:15.500 --> 01:10:17.500
ubiquitous

01:10:17.500 --> 01:10:19.500
mental illnesses and

01:10:19.500 --> 01:10:21.500
chronic complex disease

01:10:21.500 --> 01:10:23.500
that didn't exist before and

01:10:23.500 --> 01:10:25.500
increase in the total

01:10:25.500 --> 01:10:27.500
number of addictive type behaviors within populations

01:10:27.500 --> 01:10:29.500
and

01:10:29.500 --> 01:10:31.500
and a radical

01:10:31.500 --> 01:10:33.500
increase in the catastrophic risk landscape

01:10:33.500 --> 01:10:35.500
and negative effect to environmental metrics

01:10:35.500 --> 01:10:37.500
so things are getting better and things are getting worse at the same time

01:10:37.500 --> 01:10:39.500
it's important to understand that depending upon what you pick

01:10:39.500 --> 01:10:41.500
it's just that the things that are getting worse are heading

01:10:41.500 --> 01:10:43.500
towards

01:10:43.500 --> 01:10:45.500
tipping points that make the whole thing no longer viable

01:10:45.500 --> 01:10:47.500
and so that we're not

01:10:47.500 --> 01:10:49.500
denying that there are things that are getting better we're

01:10:49.500 --> 01:10:51.500
saying that for the game to continue

01:10:51.500 --> 01:10:53.500
at all right to have it

01:10:53.500 --> 01:10:55.500
be an infinite game that gets to keep continuing

01:10:55.500 --> 01:10:57.500
there are certain things that have to not happen

01:10:57.500 --> 01:10:59.500
and you can't have the things that are getting worse keep getting

01:10:59.500 --> 01:11:01.500
worse at the curve that they are

01:11:01.500 --> 01:11:03.500
and have the things that are getting better be able to

01:11:03.500 --> 01:11:05.500
continue at all so I just want to

01:11:05.500 --> 01:11:07.500
say that so

01:11:07.500 --> 01:11:09.500
naive techno optimism

01:11:09.500 --> 01:11:11.500
can actually

01:11:11.500 --> 01:11:13.500
make you a part of the problem because

01:11:13.500 --> 01:11:15.500
then you do things like develop

01:11:15.500 --> 01:11:17.500
a solution to a narrowly

01:11:17.500 --> 01:11:19.500
defined problem and externalize harm to other areas

01:11:19.500 --> 01:11:21.500
because you weren't taking seriously enough

01:11:21.500 --> 01:11:23.500
not doing that

01:11:23.500 --> 01:11:25.500
but techno pessimism also

01:11:25.500 --> 01:11:27.500
makes you a part of the problem

01:11:27.500 --> 01:11:29.500
or at least not a part of the solution because

01:11:29.500 --> 01:11:31.500
because the world is the future

01:11:31.500 --> 01:11:33.500
is not going to be determined by Luddites

01:11:33.500 --> 01:11:35.500
it's not going to be determined by people who aren't developing the tools of power

01:11:35.500 --> 01:11:37.500
so if you aren't actually looking at

01:11:37.500 --> 01:11:39.500
how do we develop a high

01:11:39.500 --> 01:11:41.500
tech world that is also a fundamentally desirable

01:11:41.500 --> 01:11:43.500
in terms of a high nature and high touch

01:11:43.500 --> 01:11:45.500
world then you really

01:11:45.500 --> 01:11:47.500
aren't thinking about it in a way that ends up

01:11:47.500 --> 01:11:49.500
mattering and so we are

01:11:49.500 --> 01:11:51.500
techno optimist but

01:11:51.500 --> 01:11:53.500
not naive techno optimist we go through the

01:11:53.500 --> 01:11:55.500
totally cynical phase of man tech

01:11:55.500 --> 01:11:57.500
is a serious issue and then you go to a post

01:11:57.500 --> 01:11:59.500
cynical phase of

01:11:59.500 --> 01:12:01.500
if I want to be techno optimist

01:12:01.500 --> 01:12:03.500
and not be silly

01:12:03.500 --> 01:12:05.500
what does it take to imagine a world

01:12:05.500 --> 01:12:07.500
where humans have that much power

01:12:07.500 --> 01:12:09.500
and we are good stewards of it

01:12:09.500 --> 01:12:11.500
meaning that we actually tend to each other

01:12:11.500 --> 01:12:13.500
well and we don't create a

01:12:13.500 --> 01:12:15.500
dystopic world that has

01:12:15.500 --> 01:12:17.500
exponential wealth and equality

01:12:17.500 --> 01:12:19.500
and an underclass that nobody in the upper class would want to trade places with

01:12:19.500 --> 01:12:21.500
and that doesn't cause catastrophic risk

01:12:21.500 --> 01:12:23.500
right now the amount

01:12:23.500 --> 01:12:25.500
of power of exponential tech

01:12:25.500 --> 01:12:27.500
makes two attractors most likely

01:12:27.500 --> 01:12:29.500
catastrophic risk

01:12:29.500 --> 01:12:31.500
of some kind

01:12:31.500 --> 01:12:33.500
or social systems

01:12:33.500 --> 01:12:35.500
that do not preserve

01:12:35.500 --> 01:12:37.500
the values that we care most about

01:12:37.500 --> 01:12:39.500
that are the ones that are currently most

01:12:39.500 --> 01:12:41.500
working to develop and deploy that technology

01:12:41.500 --> 01:12:43.500
and to just give a very brief

01:12:43.500 --> 01:12:45.500
recap of the frame that Tristan

01:12:45.500 --> 01:12:47.500
you gave on earlier as you mentioned

01:12:49.500 --> 01:12:51.500
China is not leaving 100%

01:12:51.500 --> 01:12:53.500
of its technology

01:12:53.500 --> 01:12:55.500
development to the market to develop however

01:12:55.500 --> 01:12:57.500
it wants even if it harms the nation state

01:12:57.500 --> 01:12:59.500
they are happy to bind technology

01:12:59.500 --> 01:13:01.500
companies that are getting too large

01:13:01.500 --> 01:13:03.500
and in ways that would damage the nation state

01:13:03.500 --> 01:13:05.500
as we saw with Ant Corporation

01:13:05.500 --> 01:13:07.500
and they are doing a lot of

01:13:07.500 --> 01:13:09.500
very centralized innovation

01:13:09.500 --> 01:13:11.500
as well

01:13:11.500 --> 01:13:13.500
associated with long term planning

01:13:13.500 --> 01:13:15.500
long term planning is a key thing

01:13:15.500 --> 01:13:17.500
in the US

01:13:17.500 --> 01:13:19.500
term limits make long term planning very hard

01:13:19.500 --> 01:13:21.500
as does a highly rival risk

01:13:21.500 --> 01:13:23.500
two party system that is

01:13:23.500 --> 01:13:25.500
willing to damage the

01:13:25.500 --> 01:13:27.500
nation as a whole to drive party wins

01:13:27.500 --> 01:13:29.500
so in that system

01:13:29.500 --> 01:13:31.500
almost all the energy

01:13:31.500 --> 01:13:33.500
just goes into trying to win

01:13:33.500 --> 01:13:35.500
you spend at least a couple years

01:13:35.500 --> 01:13:37.500
but even the years before that are fundraising

01:13:37.500 --> 01:13:39.500
creating alliances to just try to win

01:13:39.500 --> 01:13:41.500
then you are not going to invest in anything

01:13:41.500 --> 01:13:43.500
heavily that has return times

01:13:43.500 --> 01:13:45.500
longer than four years because it won't get you re-elected

01:13:45.500 --> 01:13:47.500
so no real long term planning

01:13:47.500 --> 01:13:49.500
and then

01:13:49.500 --> 01:13:51.500
whatever you do do in those four years

01:13:51.500 --> 01:13:53.500
will get undone systematically in the next four years

01:13:53.500 --> 01:13:55.500
for the most part

01:13:55.500 --> 01:13:57.500
that system of governance

01:13:57.500 --> 01:13:59.500
will just fail comprehensively

01:14:01.500 --> 01:14:03.500
in relationship to a more

01:14:05.500 --> 01:14:07.500
to a system that

01:14:07.500 --> 01:14:09.500
doesn't have that much internal infighting

01:14:09.500 --> 01:14:11.500
and that has

01:14:11.500 --> 01:14:13.500
the capacity to do long term planning

01:14:13.500 --> 01:14:15.500
and there is a million examples we can look at

01:14:15.500 --> 01:14:17.500
but just when did high speed

01:14:17.500 --> 01:14:19.500
trains start? they started

01:14:19.500 --> 01:14:21.500
we saw them emerge in Europe

01:14:21.500 --> 01:14:23.500
we saw them emerge in Japan and in China

01:14:23.500 --> 01:14:25.500
we started to export them all around the world

01:14:25.500 --> 01:14:27.500
and the US still doesn't have any high speed trains

01:14:27.500 --> 01:14:29.500
and it's like what happened?

01:14:29.500 --> 01:14:31.500
and we can see

01:14:31.500 --> 01:14:33.500
that the US innovated in fundamental

01:14:33.500 --> 01:14:35.500
tech in the Manhattan project

01:14:35.500 --> 01:14:37.500
kind of through the Apollo project

01:14:37.500 --> 01:14:39.500
but then it started to privatize almost everything to the market

01:14:39.500 --> 01:14:41.500
the market started to develop in ways that really

01:14:41.500 --> 01:14:43.500
were not advancing the technology

01:14:43.500 --> 01:14:45.500
in a way that increased the coherence

01:14:45.500 --> 01:14:47.500
of the nation

01:14:47.500 --> 01:14:49.500
and the fundamental civic values and ideas of the nation

01:14:49.500 --> 01:14:51.500
even the World War II thing

01:14:51.500 --> 01:14:53.500
increased our military capacities radically

01:14:53.500 --> 01:14:55.500
but that didn't mean we actually really advanced the ideas

01:14:55.500 --> 01:14:57.500
of democracy or those values of

01:14:57.500 --> 01:14:59.500
do we make a better system

01:14:59.500 --> 01:15:01.500
to educate the people and inform them

01:15:01.500 --> 01:15:03.500
and help them participate in their governance

01:15:03.500 --> 01:15:05.500
do we make better governance?

01:15:05.500 --> 01:15:07.500
this is why the US military is so powerful

01:15:07.500 --> 01:15:09.500
but the US government is so kind of inept

01:15:09.500 --> 01:15:11.500
which is why nobody wants to fight a war

01:15:11.500 --> 01:15:13.500
with the US, a kinetic war

01:15:13.500 --> 01:15:15.500
but it's very easy

01:15:15.500 --> 01:15:17.500
right now to

01:15:17.500 --> 01:15:19.500
engage in

01:15:19.500 --> 01:15:21.500
supporting narrative warfare

01:15:21.500 --> 01:15:23.500
where you turn the left and the right against each other

01:15:23.500 --> 01:15:25.500
increasingly

01:15:25.500 --> 01:15:27.500
and where you do long-term planning

01:15:27.500 --> 01:15:29.500
where the US can't do long-term planning of those kinds

01:15:29.500 --> 01:15:31.500
so we can see

01:15:31.500 --> 01:15:33.500
that the

01:15:33.500 --> 01:15:35.500
government of the US

01:15:35.500 --> 01:15:37.500
and not just the US but like we can see that

01:15:37.500 --> 01:15:39.500
open societies are not innovating

01:15:39.500 --> 01:15:41.500
in how to be better open societies

01:15:41.500 --> 01:15:43.500
for the most part, more effective ones

01:15:43.500 --> 01:15:45.500
where they're using the new tech to make better open societies

01:15:45.500 --> 01:15:47.500
that's happening in the market sector

01:15:47.500 --> 01:15:49.500
the market is making exponentially

01:15:49.500 --> 01:15:51.500
more powerful companies

01:15:51.500 --> 01:15:53.500
a company is not a democracy

01:15:53.500 --> 01:15:55.500
it's not a participatory governance structure

01:15:55.500 --> 01:15:57.500
in general, it's a kind of very top-down

01:15:57.500 --> 01:15:59.500
autocratic type system

01:15:59.500 --> 01:16:01.500
and so we see that

01:16:01.500 --> 01:16:03.500
there's more authoritarian

01:16:03.500 --> 01:16:05.500
nation states that are

01:16:05.500 --> 01:16:07.500
intentionally doing long-term

01:16:07.500 --> 01:16:09.500
planning of the development and deployment of

01:16:09.500 --> 01:16:11.500
exponential tech to make better

01:16:11.500 --> 01:16:13.500
nation states of that kind

01:16:13.500 --> 01:16:15.500
and we can't even blame them

01:16:15.500 --> 01:16:17.500
they look at

01:16:17.500 --> 01:16:19.500
trying to have the benefit of getting to see both where the USA

01:16:19.500 --> 01:16:21.500
failed and where the USSR failed

01:16:21.500 --> 01:16:23.500
and try to make something they didn't fail in either of those ways

01:16:23.500 --> 01:16:25.500
and there's some things that are very smart about

01:16:25.500 --> 01:16:27.500
those approaches

01:16:27.500 --> 01:16:29.500
so we see though exponentially empowered

01:16:31.500 --> 01:16:33.500
more autocratic type structures

01:16:33.500 --> 01:16:35.500
and the emergence of

01:16:35.500 --> 01:16:37.500
one natural

01:16:37.500 --> 01:16:39.500
monopoly per tech sector

01:16:39.500 --> 01:16:41.500
and then the interaction of those that kind of

01:16:41.500 --> 01:16:43.500
becomes like oligarchic feudalism

01:16:43.500 --> 01:16:45.500
tech feudalism

01:16:45.500 --> 01:16:47.500
neither of those

01:16:47.500 --> 01:16:49.500
have the types of jurisprudence

01:16:49.500 --> 01:16:51.500
or public accountability or whatever

01:16:51.500 --> 01:16:53.500
that we're really interested in

01:16:53.500 --> 01:16:55.500
so the two attractors right now

01:16:55.500 --> 01:16:57.500
is

01:16:57.500 --> 01:16:59.500
the emergence of social systems

01:16:59.500 --> 01:17:01.500
that are deploying

01:17:01.500 --> 01:17:03.500
the exponential tech

01:17:03.500 --> 01:17:05.500
that will probably not preserve

01:17:05.500 --> 01:17:07.500
the social values that we're interested in

01:17:07.500 --> 01:17:09.500
and not be maximally desirable civilizations

01:17:09.500 --> 01:17:11.500
probably pretty dystopic ones

01:17:11.500 --> 01:17:13.500
or not even guiding it well enough

01:17:13.500 --> 01:17:15.500
to prevent catastrophic risk

01:17:15.500 --> 01:17:17.500
those are the two major types of attractors

01:17:17.500 --> 01:17:19.500
we want a new attractor which is

01:17:19.500 --> 01:17:21.500
how do we

01:17:21.500 --> 01:17:23.500
utilize the new exponential technologies

01:17:23.500 --> 01:17:25.500
the whole suite of them

01:17:25.500 --> 01:17:27.500
to build new systems of collective intelligence

01:17:27.500 --> 01:17:29.500
new better systems of social technology

01:17:29.500 --> 01:17:31.500
how do you make a fourth estate that can really adequately

01:17:31.500 --> 01:17:33.500
educate everyone

01:17:33.500 --> 01:17:35.500
in a post

01:17:35.500 --> 01:17:37.500
Facebook world

01:17:37.500 --> 01:17:39.500
well the same way that we're trying to

01:17:39.500 --> 01:17:41.500
optimize control patterns

01:17:41.500 --> 01:17:43.500
of human behavior for market purposes

01:17:43.500 --> 01:17:45.500
to get them to buy certain things

01:17:45.500 --> 01:17:47.500
and to direct their attention

01:17:47.500 --> 01:17:49.500
could that be used educationally

01:17:49.500 --> 01:17:51.500
of course it could if it was being

01:17:51.500 --> 01:17:53.500
developed for that purpose

01:17:53.500 --> 01:17:55.500
and the AI tech

01:17:55.500 --> 01:17:57.500
that can take a bunch of faces

01:17:57.500 --> 01:17:59.500
and make a new face that is merged out of those

01:17:59.500 --> 01:18:01.500
could it take semantic fields of people's propositions

01:18:01.500 --> 01:18:03.500
and values and create a proposition

01:18:03.500 --> 01:18:05.500
that is kind of the semantic

01:18:05.500 --> 01:18:07.500
center of the space and then could we use

01:18:07.500 --> 01:18:09.500
we can't all fit into a town hall

01:18:09.500 --> 01:18:11.500
but can we engage in digital

01:18:11.500 --> 01:18:13.500
spaces where we can have

01:18:13.500 --> 01:18:15.500
better processes of proposing

01:18:15.500 --> 01:18:17.500
refinements to the propositions

01:18:17.500 --> 01:18:19.500
of course we can, could we use blockchain

01:18:19.500 --> 01:18:21.500
and other types of uncorruptible ledgers

01:18:21.500 --> 01:18:23.500
to solve corruption which is something that universally

01:18:23.500 --> 01:18:25.500
everybody thinks is a good idea

01:18:25.500 --> 01:18:27.500
should all government money

01:18:27.500 --> 01:18:29.500
be on a blockchain

01:18:29.500 --> 01:18:31.500
the movement of it so you have provenance so you can see

01:18:31.500 --> 01:18:33.500
where the money is actually going and if someone wants to be

01:18:33.500 --> 01:18:35.500
a private contractor

01:18:35.500 --> 01:18:37.500
they have to agree that the accounting system

01:18:37.500 --> 01:18:39.500
if they want government money

01:18:39.500 --> 01:18:41.500
goes on the blockchain so we can see the entire provenance

01:18:41.500 --> 01:18:43.500
of the taxpayer money so that

01:18:43.500 --> 01:18:45.500
you can't have representation if there isn't

01:18:45.500 --> 01:18:47.500
transparency of how it happens

01:18:47.500 --> 01:18:49.500
so there's a whole

01:18:49.500 --> 01:18:51.500
bunch of when you start to think about

01:18:51.500 --> 01:18:53.500
attention directing technology

01:18:53.500 --> 01:18:55.500
and what its pedagogical applications could be

01:18:55.500 --> 01:18:57.500
when you start to think about

01:18:57.500 --> 01:18:59.500
AI and how it could actually help

01:18:59.500 --> 01:19:01.500
proposition development

01:19:01.500 --> 01:19:03.500
and parsing huge amounts of information to make a better

01:19:03.500 --> 01:19:05.500
epistemic commons when you start to think about

01:19:05.500 --> 01:19:07.500
blockchain and could we actually resolve corruption

01:19:07.500 --> 01:19:09.500
using uncorruptible ledgers and making

01:19:09.500 --> 01:19:11.500
the provenance of physical supply chains

01:19:11.500 --> 01:19:13.500
and information and money all flow

01:19:13.500 --> 01:19:15.500
across those, totally new possibilities

01:19:15.500 --> 01:19:17.500
start to emerge

01:19:17.500 --> 01:19:19.500
that never emerged before, that were never possible

01:19:19.500 --> 01:19:21.500
before

01:19:21.500 --> 01:19:23.500
but if it doesn't become our central design imperative

01:19:23.500 --> 01:19:25.500
to develop those, those are not

01:19:25.500 --> 01:19:27.500
the highest marketed

01:19:27.500 --> 01:19:29.500
opportunities for those right now

01:19:29.500 --> 01:19:31.500
the highest market opportunity for blockchain is speculative

01:19:31.500 --> 01:19:33.500
tokens that have no real utility

01:19:33.500 --> 01:19:35.500
and for AI is things that actually

01:19:35.500 --> 01:19:37.500
drive ads and purchasing

01:19:37.500 --> 01:19:39.500
and you know, on and on

01:19:39.500 --> 01:19:41.500
and for attention tech it is the same thing

01:19:43.500 --> 01:19:45.500
So you've sold me on the idea that we

01:19:45.500 --> 01:19:47.500
have two dystopian attractors

01:19:47.500 --> 01:19:49.500
that we don't want and the third

01:19:49.500 --> 01:19:51.500
attractor that we're trying to develop

01:19:51.500 --> 01:19:53.500
here is some kind of open society

01:19:53.500 --> 01:19:55.500
that is consciously using

01:19:55.500 --> 01:19:57.500
all the modern technologies

01:19:57.500 --> 01:19:59.500
towards the values that we care about

01:19:59.500 --> 01:20:01.500
can you give some concrete examples

01:20:01.500 --> 01:20:03.500
of what it would look like to

01:20:03.500 --> 01:20:05.500
use you know, AI and attention

01:20:05.500 --> 01:20:07.500
driving tech and click driving tech

01:20:07.500 --> 01:20:09.500
and block chains and all these things

01:20:09.500 --> 01:20:11.500
but in a way that would make a stronger, healthier open society

01:20:11.500 --> 01:20:13.500
Yeah, totally

01:20:17.500 --> 01:20:19.500
So let's say we take

01:20:19.500 --> 01:20:21.500
the attention

01:20:21.500 --> 01:20:23.500
tech that you've looked at so much

01:20:23.500 --> 01:20:25.500
that when it is applied

01:20:25.500 --> 01:20:27.500
for a commercial application

01:20:27.500 --> 01:20:29.500
it is seeking to gather data

01:20:29.500 --> 01:20:31.500
to both maximize time on site

01:20:31.500 --> 01:20:33.500
and maximize engagement with certain kinds of ads

01:20:33.500 --> 01:20:35.500
and whatever

01:20:35.500 --> 01:20:37.500
That's obviously

01:20:37.500 --> 01:20:39.500
the ability to

01:20:39.500 --> 01:20:41.500
direct human behavior

01:20:41.500 --> 01:20:43.500
and direct human feeling

01:20:43.500 --> 01:20:45.500
and thought

01:20:45.500 --> 01:20:47.500
In a way

01:20:47.500 --> 01:20:49.500
that has both emerged out of capitalism

01:20:49.500 --> 01:20:51.500
and has become

01:20:51.500 --> 01:20:53.500
almost a new macroeconomic structure

01:20:53.500 --> 01:20:55.500
more powerful than capitalism

01:20:55.500 --> 01:20:57.500
more powerful than being able to

01:20:57.500 --> 01:20:59.500
incent people's behavior with money

01:20:59.500 --> 01:21:01.500
as being able to direct what they think and feel

01:21:01.500 --> 01:21:03.500
to where the thing that they think of

01:21:03.500 --> 01:21:05.500
as their own intrinsic motive

01:21:05.500 --> 01:21:07.500
has actually been influenced or captured

01:21:07.500 --> 01:21:09.500
So

01:21:09.500 --> 01:21:11.500
if we

01:21:11.500 --> 01:21:13.500
if we wanted to

01:21:13.500 --> 01:21:15.500
apply that type of technology

01:21:15.500 --> 01:21:17.500
and we figured out how to make

01:21:17.500 --> 01:21:19.500
the kind of transparency

01:21:19.500 --> 01:21:21.500
that made institutions

01:21:21.500 --> 01:21:23.500
that were trustworthy enough

01:21:23.500 --> 01:21:25.500
and already we have institutions that have it

01:21:25.500 --> 01:21:27.500
that we have no basis to trust with it

01:21:27.500 --> 01:21:29.500
could that same

01:21:29.500 --> 01:21:31.500
tech be used educationally

01:21:31.500 --> 01:21:33.500
to be able to personalize education

01:21:33.500 --> 01:21:35.500
to the learning style

01:21:35.500 --> 01:21:37.500
of a kid or to an adult to their particular

01:21:37.500 --> 01:21:39.500
areas of interest

01:21:39.500 --> 01:21:41.500
and to be able to

01:21:41.500 --> 01:21:43.500
not

01:21:43.500 --> 01:21:45.500
use

01:21:45.500 --> 01:21:47.500
the ability to control them

01:21:47.500 --> 01:21:49.500
for game-theoretic purposes

01:21:49.500 --> 01:21:51.500
but use the ability to influence them

01:21:51.500 --> 01:21:53.500
to even help them learn

01:21:53.500 --> 01:21:55.500
what makes their own

01:21:55.500 --> 01:21:57.500
center

01:21:57.500 --> 01:21:59.500
their locus of action more internalized

01:21:59.500 --> 01:22:01.500
we could teach people

01:22:01.500 --> 01:22:03.500
with that kind of tech

01:22:03.500 --> 01:22:05.500
how to notice their own bias

01:22:05.500 --> 01:22:07.500
how to notice their own emotional behaviors

01:22:07.500 --> 01:22:09.500
how to notice groupthink type dynamics

01:22:09.500 --> 01:22:11.500
how to understand propaganda and media literacy

01:22:11.500 --> 01:22:13.500
so could we actually use those tools

01:22:13.500 --> 01:22:15.500
to increase people's immune system

01:22:15.500 --> 01:22:17.500
against bad actors' use of those tools

01:22:17.500 --> 01:22:19.500
totally

01:22:19.500 --> 01:22:21.500
could we use them pedagogically

01:22:21.500 --> 01:22:23.500
in general to be able to identify

01:22:23.500 --> 01:22:25.500
rather than manufacturing

01:22:25.500 --> 01:22:27.500
desires in people

01:22:27.500 --> 01:22:29.500
or appealing to the lowest angels of their nature

01:22:29.500 --> 01:22:31.500
because addiction is profitable

01:22:31.500 --> 01:22:33.500
can you appeal to the highest

01:22:33.500 --> 01:22:35.500
angels in people's nature

01:22:35.500 --> 01:22:37.500
but that are aligned with intrinsic incentives

01:22:37.500 --> 01:22:39.500
and be able to

01:22:39.500 --> 01:22:41.500
create customized educational programs

01:22:41.500 --> 01:22:43.500
that are based on what each person is actually

01:22:43.500 --> 01:22:45.500
innately intrinsically motivated by

01:22:45.500 --> 01:22:47.500
but that are their higher innate motivators

01:22:47.500 --> 01:22:49.500
everybody can have a reward circuit

01:22:49.500 --> 01:22:51.500
that is based on

01:22:51.500 --> 01:22:53.500
you know chocolate cake and sloth

01:22:53.500 --> 01:22:55.500
but the immediate spike

01:22:55.500 --> 01:22:57.500
that comes from the chocolate cake

01:22:57.500 --> 01:22:59.500
ends up then having a crash

01:22:59.500 --> 01:23:01.500
and increased weight and inflammation

01:23:01.500 --> 01:23:03.500
and whatever where the baseline of their happiness

01:23:03.500 --> 01:23:05.500
goes down over time

01:23:05.500 --> 01:23:07.500
even though every time they eat the chocolate cake they get a spike

01:23:07.500 --> 01:23:09.500
the exercise reward circuit is maybe

01:23:09.500 --> 01:23:11.500
not that fun maybe even kind of painful

01:23:11.500 --> 01:23:13.500
and dreadful in the moment

01:23:13.500 --> 01:23:15.500
but then creates a higher baseline

01:23:15.500 --> 01:23:17.500
of energy and capacity

01:23:17.500 --> 01:23:19.500
and endurance and self-esteem

01:23:19.500 --> 01:23:21.500
and you start to actually have the process become

01:23:21.500 --> 01:23:23.500
more fun you get a new reward circuit

01:23:23.500 --> 01:23:25.500
and the baseline goes up

01:23:25.500 --> 01:23:27.500
so of course I can appeal to the lower reward

01:23:27.500 --> 01:23:29.500
circuit and say hey I'm just giving people

01:23:29.500 --> 01:23:31.500
what they want

01:23:31.500 --> 01:23:33.500
but if you have a billion dollar

01:23:33.500 --> 01:23:35.500
or a trillion dollar organization

01:23:35.500 --> 01:23:37.500
that is preying upon them

01:23:37.500 --> 01:23:39.500
and you discuss this very well all the time

01:23:39.500 --> 01:23:41.500
the vulnerabilities that make people's life

01:23:41.500 --> 01:23:43.500
worse to then have the plausible deniability

01:23:43.500 --> 01:23:45.500
to say yeah but they wanted it

01:23:45.500 --> 01:23:47.500
but it was a manufactured demand

01:23:47.500 --> 01:23:49.500
and a vulnerability where's the no bless

01:23:49.500 --> 01:23:51.500
oblige where's the obligation

01:23:51.500 --> 01:23:53.500
of having that much power to actually be

01:23:53.500 --> 01:23:55.500
a good steward of power a steward of that

01:23:55.500 --> 01:23:57.500
for other people where if there are

01:23:57.500 --> 01:23:59.500
reward circuits that decrease the quality

01:23:59.500 --> 01:24:01.500
of their life reward circuits that increase

01:24:01.500 --> 01:24:03.500
that we're trying to appeal to one rather than the other

01:24:03.500 --> 01:24:05.500
could we do that yeah totally we could

01:24:05.500 --> 01:24:07.500
could we have an education system as a result

01:24:07.500 --> 01:24:09.500
that was identifying innate

01:24:09.500 --> 01:24:11.500
aptitudes innate interests

01:24:11.500 --> 01:24:13.500
of everyone and facilitating

01:24:13.500 --> 01:24:15.500
their development so not only did they

01:24:15.500 --> 01:24:17.500
become

01:24:17.500 --> 01:24:19.500
good at something but they became increasingly

01:24:19.500 --> 01:24:21.500
more intrinsically motivated fascinated

01:24:21.500 --> 01:24:23.500
and passionate by life

01:24:23.500 --> 01:24:25.500
which also meant continuously better at the thing

01:24:25.500 --> 01:24:27.500
well in a world of

01:24:27.500 --> 01:24:29.500
increasing technological automation

01:24:29.500 --> 01:24:31.500
coming up both robotic and AI automation

01:24:31.500 --> 01:24:33.500
where so many of the jobs are about to be

01:24:33.500 --> 01:24:35.500
obsolete

01:24:35.500 --> 01:24:37.500
our economy

01:24:37.500 --> 01:24:39.500
and our education system

01:24:39.500 --> 01:24:41.500
have to radically change to deal with that

01:24:41.500 --> 01:24:43.500
because

01:24:43.500 --> 01:24:45.500
the core of like one of the core

01:24:45.500 --> 01:24:47.500
things an economy has been trying to do forever

01:24:47.500 --> 01:24:49.500
was

01:24:49.500 --> 01:24:51.500
deal with the need that a society had

01:24:51.500 --> 01:24:53.500
for a labor force

01:24:53.500 --> 01:24:55.500
and that there were these jobs that society

01:24:55.500 --> 01:24:57.500
needed to get done that nobody would really want to do

01:24:57.500 --> 01:24:59.500
so either the state has to force them to do it

01:24:59.500 --> 01:25:01.500
or

01:25:01.500 --> 01:25:03.500
you have to make it to where the people also need the job

01:25:03.500 --> 01:25:05.500
so there's a cemetery and so kind of the market

01:25:05.500 --> 01:25:07.500
forces them to do it well when you technologically

01:25:07.500 --> 01:25:09.500
automate those jobs and it happens

01:25:09.500 --> 01:25:11.500
to be that the things that are the most

01:25:11.500 --> 01:25:13.500
wrote are the least fun for people

01:25:13.500 --> 01:25:15.500
and the easiest to program machines to do

01:25:15.500 --> 01:25:17.500
and

01:25:17.500 --> 01:25:19.500
so

01:25:19.500 --> 01:25:21.500
if you keep the same economy

01:25:21.500 --> 01:25:23.500
where if people don't produce

01:25:23.500 --> 01:25:25.500
they don't have any basic needs met

01:25:25.500 --> 01:25:27.500
then people want

01:25:27.500 --> 01:25:29.500
those crappy jobs right

01:25:29.500 --> 01:25:31.500
but if you make it to where they have other

01:25:31.500 --> 01:25:33.500
opportunities then of course

01:25:33.500 --> 01:25:35.500
having those jobs be automated is fine

01:25:35.500 --> 01:25:37.500
but what does it mean to really be able to have

01:25:37.500 --> 01:25:39.500
other better opportunities

01:25:39.500 --> 01:25:41.500
so

01:25:41.500 --> 01:25:43.500
if one of the fundamental like

01:25:43.500 --> 01:25:45.500
axioms

01:25:45.500 --> 01:25:47.500
of all of our economic theories

01:25:47.500 --> 01:25:49.500
is that we need to figure out how to

01:25:49.500 --> 01:25:51.500
incent a labor force to do things that nobody

01:25:51.500 --> 01:25:53.500
wants to do

01:25:53.500 --> 01:25:55.500
and emerging technological automation starts to

01:25:55.500 --> 01:25:57.500
debase that

01:25:57.500 --> 01:25:59.500
that means we have to rethink economics from scratch

01:25:59.500 --> 01:26:01.500
because we don't have to do that thing anymore

01:26:01.500 --> 01:26:03.500
so maybe if now the jobs don't need the people

01:26:03.500 --> 01:26:05.500
that need the jobs can we start to create

01:26:05.500 --> 01:26:07.500
commonwealth resources that everyone has access to

01:26:07.500 --> 01:26:09.500
where people's access

01:26:09.500 --> 01:26:11.500
isn't based on possession

01:26:11.500 --> 01:26:13.500
that automatically limits everyone else's access

01:26:13.500 --> 01:26:15.500
if you get around

01:26:15.500 --> 01:26:17.500
transportation wise with a car

01:26:17.500 --> 01:26:19.500
based on owning that car

01:26:19.500 --> 01:26:21.500
where the vast majority of the life of the car

01:26:21.500 --> 01:26:23.500
it's just sitting not being used

01:26:23.500 --> 01:26:25.500
for you to have access to the car you have to have

01:26:25.500 --> 01:26:27.500
possession of it which means that it's a

01:26:27.500 --> 01:26:29.500
mostly underutilized asset I don't have

01:26:29.500 --> 01:26:31.500
access to the thing that you possess

01:26:31.500 --> 01:26:33.500
now what we see with Uber of course is a situation

01:26:33.500 --> 01:26:35.500
where your access

01:26:35.500 --> 01:26:37.500
is not mediated by your possession

01:26:37.500 --> 01:26:39.500
so now turn that into electric

01:26:39.500 --> 01:26:41.500
self-driving cars and now make the entire

01:26:41.500 --> 01:26:43.500
thing on a blockchain so you disintermediate

01:26:43.500 --> 01:26:45.500
even the central business make it a commonwealth

01:26:45.500 --> 01:26:47.500
resource and everyone has access to

01:26:47.500 --> 01:26:49.500
transportation as a commonwealth resource

01:26:49.500 --> 01:26:51.500
it'll take a 20th of the number of cars

01:26:51.500 --> 01:26:53.500
to meet the same level

01:26:53.500 --> 01:26:55.500
of convenience during peak demand time

01:26:55.500 --> 01:26:57.500
so much less environmental harm

01:26:57.500 --> 01:26:59.500
it'll actually be more convenient because I don't

01:26:59.500 --> 01:27:01.500
have to be engaged in driving the thing

01:27:01.500 --> 01:27:03.500
and there's less traffic because of the coordination

01:27:03.500 --> 01:27:05.500
and better maintenance and there isn't a desire

01:27:05.500 --> 01:27:07.500
for an incentive for designed

01:27:07.500 --> 01:27:09.500
an obsolescence in that system

01:27:09.500 --> 01:27:11.500
you can see a situation where

01:27:11.500 --> 01:27:13.500
can we make it to where

01:27:13.500 --> 01:27:15.500
the wealth augmenting capacity

01:27:15.500 --> 01:27:17.500
of that technologic automation goes back

01:27:17.500 --> 01:27:19.500
into a commonwealth because we don't have to

01:27:19.500 --> 01:27:21.500
have the same axioms of needing to incend the people

01:27:21.500 --> 01:27:23.500
oh yeah but if you don't incend the people

01:27:23.500 --> 01:27:25.500
they'll all be lazy welfare people

01:27:25.500 --> 01:27:27.500
nonsense

01:27:27.500 --> 01:27:29.500
Einstein didn't do what he did based on

01:27:29.500 --> 01:27:31.500
economic incentive and

01:27:31.500 --> 01:27:33.500
neither did Mozart and neither did Gandhi

01:27:33.500 --> 01:27:35.500
and none of the people that we

01:27:35.500 --> 01:27:37.500
are most inspired by through history

01:27:37.500 --> 01:27:39.500
were doing that

01:27:39.500 --> 01:27:41.500
and what kids will

01:27:41.500 --> 01:27:43.500
who will spend so much

01:27:43.500 --> 01:27:45.500
time doing where they ask questions

01:27:45.500 --> 01:27:47.500
about why this why this why this

01:27:47.500 --> 01:27:49.500
and building forts and whatever is intrinsic motive

01:27:49.500 --> 01:27:51.500
it's just we don't facilitate

01:27:51.500 --> 01:27:53.500
the things that they're interested in

01:27:53.500 --> 01:27:55.500
we try to force them to be interested in things

01:27:55.500 --> 01:27:57.500
that's what ends up breaking their interest in life

01:27:57.500 --> 01:27:59.500
and then they just want a hypernormal stimuli

01:27:59.500 --> 01:28:01.500
and play video games whatever

01:28:01.500 --> 01:28:03.500
what if you had a system that was facilitating

01:28:03.500 --> 01:28:05.500
their interest the entire time

01:28:05.500 --> 01:28:07.500
now you have a situation where you can start to

01:28:07.500 --> 01:28:09.500
decrease the total amount of extrinsic

01:28:09.500 --> 01:28:11.500
incentive in the system as a whole

01:28:11.500 --> 01:28:13.500
use the technology

01:28:13.500 --> 01:28:15.500
to the automation to decrease

01:28:15.500 --> 01:28:17.500
the need for extrinsic incentive

01:28:17.500 --> 01:28:19.500
and make an educational system

01:28:19.500 --> 01:28:21.500
and culture that's about optimizing intrinsic

01:28:21.500 --> 01:28:23.500
incentive because if my needs are already

01:28:23.500 --> 01:28:25.500
met getting stuff there's no

01:28:25.500 --> 01:28:27.500
and everybody's needs are met through access

01:28:27.500 --> 01:28:29.500
to commonwealth resources there's no real status

01:28:29.500 --> 01:28:31.500
conferred that there's only status

01:28:31.500 --> 01:28:33.500
conferred by what I create so now there is a

01:28:33.500 --> 01:28:35.500
any status is bound to a kind of creative

01:28:35.500 --> 01:28:37.500
imperative that's an example

01:28:37.500 --> 01:28:39.500
we can look at blockchain

01:28:39.500 --> 01:28:41.500
tech even more near term and say

01:28:41.500 --> 01:28:43.500
but

01:28:43.500 --> 01:28:45.500
but just to come back to this technological

01:28:45.500 --> 01:28:47.500
automation thing so obviously it makes possible

01:28:47.500 --> 01:28:49.500
changing economics and changing education

01:28:49.500 --> 01:28:51.500
but also

01:28:51.500 --> 01:28:53.500
what is the role of humans

01:28:53.500 --> 01:28:55.500
in a

01:28:55.500 --> 01:28:57.500
post AI robotic automation world

01:28:57.500 --> 01:28:59.500
because that is coming very very soon

01:28:59.500 --> 01:29:01.500
and what is the future of

01:29:01.500 --> 01:29:03.500
education where you don't have to prepare

01:29:03.500 --> 01:29:05.500
people to be

01:29:05.500 --> 01:29:07.500
things that you can just program computers

01:29:07.500 --> 01:29:09.500
to be

01:29:09.500 --> 01:29:11.500
well the role of education has to be based on

01:29:11.500 --> 01:29:13.500
what is the role of people in that world

01:29:13.500 --> 01:29:15.500
that is such a deep redesign of civilization

01:29:15.500 --> 01:29:17.500
because the tech is changing

01:29:17.500 --> 01:29:19.500
the possibility set that deeply

01:29:19.500 --> 01:29:21.500
so at the heart of this are kind of

01:29:21.500 --> 01:29:23.500
deep existential questions of what is a meaningful

01:29:23.500 --> 01:29:25.500
human life and then what is a good civilization

01:29:25.500 --> 01:29:27.500
that increases the possibility

01:29:27.500 --> 01:29:29.500
space of that for everybody and how do we design

01:29:29.500 --> 01:29:31.500
that thing we come back to

01:29:31.500 --> 01:29:33.500
blockchain and we say

01:29:33.500 --> 01:29:35.500
well blockchain is an uncorruptible ledger

01:29:35.500 --> 01:29:37.500
well

01:29:37.500 --> 01:29:39.500
one thing that the left and right and everybody

01:29:39.500 --> 01:29:41.500
agrees on is that we did corruption

01:29:41.500 --> 01:29:43.500
happens and it's bad for the societies

01:29:43.500 --> 01:29:45.500
at home we don't like it we just disagree

01:29:45.500 --> 01:29:47.500
on who does it

01:29:47.500 --> 01:29:49.500
is it possible

01:29:49.500 --> 01:29:51.500
that that tech could

01:29:51.500 --> 01:29:53.500
make possible decreasing

01:29:53.500 --> 01:29:55.500
corruption as a whole

01:29:55.500 --> 01:29:57.500
it actually decreases the possibility set for corruption

01:29:57.500 --> 01:29:59.500
yeah in order to do corruption

01:29:59.500 --> 01:30:01.500
I have to be able to hide that I did it

01:30:01.500 --> 01:30:03.500
right I either have to

01:30:03.500 --> 01:30:05.500
to break enforcement or break accounting and mostly

01:30:05.500 --> 01:30:07.500
it's break accounting

01:30:07.500 --> 01:30:09.500
and so what if

01:30:09.500 --> 01:30:11.500
all government spending was on a blockchain

01:30:11.500 --> 01:30:13.500
and doesn't have to be a blockchain

01:30:13.500 --> 01:30:15.500
it has to be an uncorruptible ledger of some kind

01:30:15.500 --> 01:30:17.500
all a chain is a good example

01:30:17.500 --> 01:30:19.500
that is pioneering another way of doing it

01:30:19.500 --> 01:30:21.500
but uncorruptible ledger of some kind

01:30:21.500 --> 01:30:23.500
where you actually see

01:30:23.500 --> 01:30:25.500
where all taxpayer money goes and you see how

01:30:25.500 --> 01:30:27.500
it's utilized the entire thing and have independent

01:30:27.500 --> 01:30:29.500
auditing agencies and the public can transparently

01:30:29.500 --> 01:30:31.500
be engaged in the auditing of it

01:30:31.500 --> 01:30:33.500
and if the government

01:30:33.500 --> 01:30:35.500
is going to privately contract a corporation

01:30:35.500 --> 01:30:37.500
the corporation agrees

01:30:37.500 --> 01:30:39.500
that if they want that government money

01:30:39.500 --> 01:30:41.500
the blockchain accounting has to extend

01:30:41.500 --> 01:30:43.500
into the corporation so there can't be

01:30:43.500 --> 01:30:45.500
very very

01:30:45.500 --> 01:30:47.500
bloated corruption everybody got to see

01:30:47.500 --> 01:30:49.500
that when Elon made

01:30:49.500 --> 01:30:51.500
SpaceX all of a sudden he was making

01:30:51.500 --> 01:30:53.500
rockets for like a hundreds to a thousands

01:30:53.500 --> 01:30:55.500
of the price that Lockheed or Boeing were

01:30:55.500 --> 01:30:57.500
who had just had these almost monopolistic government

01:30:57.500 --> 01:30:59.500
contracts for a long time

01:30:59.500 --> 01:31:01.500
well if the taxpayer money

01:31:01.500 --> 01:31:03.500
is going to the government

01:31:03.500 --> 01:31:05.500
is going to an external private contractor

01:31:05.500 --> 01:31:07.500
who's making the things for a hundred to a thousand

01:31:07.500 --> 01:31:09.500
times more than it costs

01:31:09.500 --> 01:31:11.500
we get this false dichotomy sold to us that

01:31:11.500 --> 01:31:13.500
either

01:31:13.500 --> 01:31:15.500
we have to pay more taxes

01:31:15.500 --> 01:31:17.500
to have better national security

01:31:17.500 --> 01:31:19.500
or if we want to cut taxes

01:31:19.500 --> 01:31:21.500
we're going to have less national security

01:31:21.500 --> 01:31:23.500
what about just having less gruesome

01:31:23.500 --> 01:31:25.500
bloat because you have better accounting

01:31:25.500 --> 01:31:27.500
and we make the rockets for a hundredth

01:31:27.500 --> 01:31:29.500
of the price and we have better national

01:31:29.500 --> 01:31:31.500
security and better social services and less

01:31:31.500 --> 01:31:33.500
taxes well that's

01:31:33.500 --> 01:31:35.500
everyone would vote for that right

01:31:35.500 --> 01:31:37.500
who wouldn't vote for that thing well that wasn't

01:31:37.500 --> 01:31:39.500
possible before uncorruptible ledgers

01:31:39.500 --> 01:31:41.500
also means you can have provenance

01:31:41.500 --> 01:31:43.500
on supply chains to make the supply

01:31:43.500 --> 01:31:45.500
chains closed loop so that you can see

01:31:45.500 --> 01:31:47.500
that all the new stuff is being made from old stuff

01:31:47.500 --> 01:31:49.500
and you can see where all the pollution is going and you can see

01:31:49.500 --> 01:31:51.500
who did it which means you can now internalize

01:31:51.500 --> 01:31:53.500
the externalities rigorously

01:31:53.500 --> 01:31:55.500
and nobody can destroy those

01:31:55.500 --> 01:31:57.500
emails or burn those files right

01:31:57.500 --> 01:31:59.500
what if

01:31:59.500 --> 01:32:01.500
the changes

01:32:01.500 --> 01:32:03.500
in law and

01:32:03.500 --> 01:32:05.500
the

01:32:05.500 --> 01:32:07.500
decision-making processes

01:32:07.500 --> 01:32:09.500
also followed a

01:32:09.500 --> 01:32:11.500
blockchain process where there was a provenance

01:32:11.500 --> 01:32:13.500
on the input of information well that would also

01:32:13.500 --> 01:32:15.500
be a very meaningful thing to be able to

01:32:15.500 --> 01:32:17.500
follow so

01:32:17.500 --> 01:32:19.500
this is an example of like can we actually

01:32:19.500 --> 01:32:21.500
structurally remove

01:32:21.500 --> 01:32:23.500
the capacity for corruption

01:32:23.500 --> 01:32:25.500
by technology that makes

01:32:25.500 --> 01:32:27.500
corruption much much much harder that forces

01:32:27.500 --> 01:32:29.500
types of transparency on auditability

01:32:29.500 --> 01:32:31.500
what if also

01:32:31.500 --> 01:32:33.500
you're able to record history

01:32:33.500 --> 01:32:35.500
you're able to record the events that are occurring

01:32:35.500 --> 01:32:37.500
in a blockchain that's uncruptible where you can't change history later

01:32:37.500 --> 01:32:39.500
so you actually get

01:32:39.500 --> 01:32:41.500
the possibility of real justice and real history

01:32:41.500 --> 01:32:43.500
and multiple different simultaneous timelines

01:32:43.500 --> 01:32:45.500
that are happening that's humongous

01:32:45.500 --> 01:32:47.500
in terms of what it does

01:32:47.500 --> 01:32:49.500
what if you can

01:32:49.500 --> 01:32:51.500
have an open data platform

01:32:51.500 --> 01:32:53.500
and an open science platform where

01:32:53.500 --> 01:32:55.500
someone doesn't get to cherry pick which data

01:32:55.500 --> 01:32:57.500
they include in their peer reviewed paper later

01:32:57.500 --> 01:32:59.500
we get to see all of the data that was happening

01:32:59.500 --> 01:33:01.500
we solve the oracle issues that are associated

01:33:01.500 --> 01:33:03.500
and then if we find out that a particular

01:33:03.500 --> 01:33:05.500
piece of science was wrong later we can see

01:33:05.500 --> 01:33:07.500
downstream everything that used

01:33:07.500 --> 01:33:09.500
that output as an input and automatically

01:33:09.500 --> 01:33:11.500
flag what things need to change

01:33:11.500 --> 01:33:13.500
that's so

01:33:13.500 --> 01:33:15.500
powerful like the least

01:33:15.500 --> 01:33:17.500
interesting example

01:33:17.500 --> 01:33:19.500
of blockchain is currency creation

01:33:19.500 --> 01:33:21.500
these are actually

01:33:21.500 --> 01:33:23.500
like

01:33:23.500 --> 01:33:25.500
the capacity for the right types of

01:33:25.500 --> 01:33:27.500
accounting means the right type of choice making

01:33:27.500 --> 01:33:29.500
right let's take AI

01:33:29.500 --> 01:33:31.500
with AI we can make

01:33:31.500 --> 01:33:33.500
super terrible deep fakes and destroy

01:33:33.500 --> 01:33:35.500
the epistemic commons you know using that

01:33:35.500 --> 01:33:37.500
and other things like that

01:33:37.500 --> 01:33:39.500
but we can see

01:33:39.500 --> 01:33:41.500
the way that the AI makes the deep fake by

01:33:41.500 --> 01:33:43.500
being able to take enough different images of

01:33:43.500 --> 01:33:45.500
the person's face and movements that it can generate

01:33:45.500 --> 01:33:47.500
new ones we can see where it can generate totally

01:33:47.500 --> 01:33:49.500
new faces averaging faces together somebody

01:33:49.500 --> 01:33:51.500
sent me some new work that they were just doing on this

01:33:51.500 --> 01:33:53.500
the other day I found very interesting they said

01:33:53.500 --> 01:33:55.500
we're going to take a very similar type of tech and apply

01:33:55.500 --> 01:33:57.500
it to semantic fields where

01:33:57.500 --> 01:33:59.500
we can take everybody's sentiment on a topic

01:33:59.500 --> 01:34:01.500
and actually generate

01:34:01.500 --> 01:34:03.500
a proposition that is at the semantic

01:34:03.500 --> 01:34:05.500
center or take everybody's

01:34:07.500 --> 01:34:09.500
sentiment and abstract from it the

01:34:09.500 --> 01:34:11.500
values that they care about and create

01:34:11.500 --> 01:34:13.500
values taxonomies and say

01:34:13.500 --> 01:34:15.500
we should come up with a proposition that meets

01:34:15.500 --> 01:34:17.500
all these values then

01:34:17.500 --> 01:34:19.500
can you have digital processes where you can't fit

01:34:19.500 --> 01:34:21.500
everybody into

01:34:21.500 --> 01:34:23.500
into a

01:34:23.500 --> 01:34:25.500
town hall but everybody who wants

01:34:25.500 --> 01:34:27.500
to can participate in a digital space

01:34:27.500 --> 01:34:29.500
that rather than vote

01:34:29.500 --> 01:34:31.500
yes or no on a proposition that was made by a

01:34:31.500 --> 01:34:33.500
special interest group where we didn't have a say

01:34:33.500 --> 01:34:35.500
in the proposition or even the values it was seeking

01:34:35.500 --> 01:34:37.500
to serve so it was made in a very

01:34:37.500 --> 01:34:39.500
narrow way that like we mentioned earlier

01:34:39.500 --> 01:34:41.500
benefits one thing and harms something else which is

01:34:41.500 --> 01:34:43.500
why

01:34:43.500 --> 01:34:45.500
almost every proposition gets about half of the

01:34:45.500 --> 01:34:47.500
vote and inherently polarizes the

01:34:47.500 --> 01:34:49.500
population well people are so

01:34:49.500 --> 01:34:51.500
dumb and so rival risk the process of voting

01:34:51.500 --> 01:34:53.500
with

01:34:53.500 --> 01:34:55.500
bad propositions and

01:34:55.500 --> 01:34:57.500
and bad representation

01:34:57.500 --> 01:34:59.500
process is inherently polarizing

01:34:59.500 --> 01:35:01.500
and downgrading to people so

01:35:01.500 --> 01:35:03.500
what if there's a process by which there's

01:35:03.500 --> 01:35:05.500
a decision that wants to be made you start

01:35:05.500 --> 01:35:07.500
by identifying what are the values everybody cares

01:35:07.500 --> 01:35:09.500
about and then we say the

01:35:09.500 --> 01:35:11.500
first proposition that meets all these

01:35:11.500 --> 01:35:13.500
values well becomes the

01:35:13.500 --> 01:35:15.500
thing that we vote on and then instead of just

01:35:15.500 --> 01:35:17.500
a direct vote do we engage

01:35:17.500 --> 01:35:19.500
types of qualified and liquid democracy

01:35:19.500 --> 01:35:21.500
together where you have to show that you understand

01:35:21.500 --> 01:35:23.500
the basics of

01:35:23.500 --> 01:35:25.500
that topic to be able to vote on it

01:35:25.500 --> 01:35:27.500
but the education is free and you can keep retesting

01:35:27.500 --> 01:35:29.500
and the basics don't show leaning one way or the

01:35:29.500 --> 01:35:31.500
other just shows you understand the stated pros and

01:35:31.500 --> 01:35:33.500
cons so that massive populism

01:35:33.500 --> 01:35:35.500
doesn't happen but if

01:35:35.500 --> 01:35:37.500
you don't want to come to understand it you can seed

01:35:37.500 --> 01:35:39.500
your vote to someone else who has passed that thing

01:35:39.500 --> 01:35:41.500
these are that type of liquid

01:35:41.500 --> 01:35:43.500
democracy that type of qualified

01:35:43.500 --> 01:35:45.500
educated democracy where it doesn't have to

01:35:45.500 --> 01:35:47.500
be educated across everything it can be per

01:35:47.500 --> 01:35:49.500
issue and where you're not just voting

01:35:49.500 --> 01:35:51.500
on a thing you're helping craft the propositions

01:35:51.500 --> 01:35:53.500
these completely change

01:35:53.500 --> 01:35:55.500
the possibility space of social technology

01:35:55.500 --> 01:35:57.500
and we can go on and on in terms of

01:35:57.500 --> 01:35:59.500
examples but these are ways

01:35:59.500 --> 01:36:01.500
that the same type

01:36:01.500 --> 01:36:03.500
of new emergent physical tech

01:36:03.500 --> 01:36:05.500
that can destroy the epistemic

01:36:05.500 --> 01:36:07.500
commons and create autocracies and create catastrophic

01:36:07.500 --> 01:36:09.500
risks could also be used

01:36:09.500 --> 01:36:11.500
to realize a much

01:36:11.500 --> 01:36:13.500
more

01:36:13.500 --> 01:36:15.500
pro-topic world

01:36:15.500 --> 01:36:17.500
so I love so many of those

01:36:17.500 --> 01:36:19.500
examples and I especially on

01:36:19.500 --> 01:36:21.500
the blockchain and corruption one because

01:36:21.500 --> 01:36:23.500
I think as you said something

01:36:23.500 --> 01:36:25.500
the left and the right can both agree on is that

01:36:25.500 --> 01:36:27.500
our systems are not really functional and there's

01:36:27.500 --> 01:36:29.500
definitely corruption and defection going on

01:36:29.500 --> 01:36:31.500
and just to add to your example

01:36:31.500 --> 01:36:33.500
imagine if citizens could even earn money

01:36:33.500 --> 01:36:35.500
by spotting inefficiencies or corruption

01:36:35.500 --> 01:36:37.500
in that transparent ledger

01:36:37.500 --> 01:36:39.500
so that we actually have a system that is

01:36:39.500 --> 01:36:41.500
actually profiting

01:36:41.500 --> 01:36:43.500
by getting more and more efficient over time

01:36:43.500 --> 01:36:45.500
and actually better serving the needs of the people

01:36:45.500 --> 01:36:47.500
and having less and less corruption and so there's

01:36:47.500 --> 01:36:49.500
definitely more trust and faith and that's actually

01:36:49.500 --> 01:36:51.500
a kind of digital society

01:36:51.500 --> 01:36:53.500
that when you look at let's say the closed

01:36:53.500 --> 01:36:55.500
China's digital authoritarian society

01:36:55.500 --> 01:36:57.500
and you look at this open one that's actually operating

01:36:57.500 --> 01:36:59.500
more for the people with more transparency

01:36:59.500 --> 01:37:01.500
with more efficiencies you get more

01:37:01.500 --> 01:37:03.500
SpaceX Elon Musk type cheap

01:37:03.500 --> 01:37:05.500
ways of sending rockets to the moon and becoming a multi-planetary

01:37:05.500 --> 01:37:07.500
civilization as opposed to

01:37:07.500 --> 01:37:09.500
more bloat and more mega monopolies

01:37:09.500 --> 01:37:11.500
defense contractors that are not taking us

01:37:11.500 --> 01:37:13.500
to where we need to go

01:37:13.500 --> 01:37:15.500
that's just an inspiring vision and I just hope

01:37:15.500 --> 01:37:17.500
you share it and kind of go back because there's a lot

01:37:17.500 --> 01:37:19.500
of different aspects there

01:37:19.500 --> 01:37:21.500
I think the question on many people's mind right now

01:37:21.500 --> 01:37:23.500
is going to be

01:37:23.500 --> 01:37:25.500
how do we get from where we are

01:37:25.500 --> 01:37:27.500
to the world that you are talking about

01:37:27.500 --> 01:37:29.500
what are the steps that are in between

01:37:29.500 --> 01:37:31.500
obviously I don't know

01:37:31.500 --> 01:37:33.500
nobody knows

01:37:33.500 --> 01:37:35.500
there's gonna like

01:37:35.500 --> 01:37:37.500
which projects emerge

01:37:37.500 --> 01:37:39.500
and

01:37:39.500 --> 01:37:41.500
first and start really making success

01:37:41.500 --> 01:37:43.500
that there's a lot of different

01:37:43.500 --> 01:37:45.500
possible paths

01:37:45.500 --> 01:37:47.500
I can say some of the things

01:37:47.500 --> 01:37:49.500
that could happen and some of the things

01:37:49.500 --> 01:37:51.500
that I think need to happen

01:37:53.500 --> 01:37:55.500
so we take all the catastrophic

01:37:55.500 --> 01:37:57.500
risks that exponential tech

01:37:57.500 --> 01:37:59.500
makes possible and the dystopic attractors

01:37:59.500 --> 01:38:01.500
and we say okay so we need to solve all those

01:38:01.500 --> 01:38:03.500
problems but we're not doing

01:38:03.500 --> 01:38:05.500
really good at solving those problems right now

01:38:05.500 --> 01:38:07.500
so our problem solving processes need upgraded

01:38:07.500 --> 01:38:09.500
and that means new

01:38:09.500 --> 01:38:11.500
institutions

01:38:11.500 --> 01:38:13.500
and when we say

01:38:13.500 --> 01:38:15.500
institution we usually think of a pretty centralized

01:38:15.500 --> 01:38:17.500
thing and with things like decentralized

01:38:17.500 --> 01:38:19.500
governance emerging

01:38:19.500 --> 01:38:21.500
the institution might be a decentralized one

01:38:21.500 --> 01:38:23.500
but it's individual

01:38:23.500 --> 01:38:25.500
people aren't going to solve all of that right

01:38:25.500 --> 01:38:27.500
so it's new institution

01:38:27.500 --> 01:38:29.500
centralized and decentralized that have the right

01:38:29.500 --> 01:38:31.500
capacities to solve these types of problems

01:38:31.500 --> 01:38:33.500
need to come about

01:38:33.500 --> 01:38:35.500
alright well who develops those

01:38:35.500 --> 01:38:37.500
institutions and who empowers them

01:38:37.500 --> 01:38:39.500
and this is where

01:38:39.500 --> 01:38:41.500
the democratic idea of

01:38:41.500 --> 01:38:43.500
the

01:38:43.500 --> 01:38:45.500
power of government coming from the

01:38:45.500 --> 01:38:47.500
consent of the governed

01:38:47.500 --> 01:38:49.500
is one of the key ideas to what

01:38:49.500 --> 01:38:51.500
we would think of as the values of an open

01:38:51.500 --> 01:38:53.500
society let's say that there's a small

01:38:53.500 --> 01:38:55.500
number of people who think we understand these

01:38:55.500 --> 01:38:57.500
problems we understand the solutions that must happen

01:38:57.500 --> 01:38:59.500
everybody else doesn't get it so we're going to make this

01:38:59.500 --> 01:39:01.500
thing happen and because we have the power we can

01:39:01.500 --> 01:39:03.500
just kind of implement it by force and so

01:39:03.500 --> 01:39:05.500
that becomes

01:39:05.500 --> 01:39:07.500
its own dystopia right

01:39:07.500 --> 01:39:09.500
and implement it by force might be well the people think

01:39:09.500 --> 01:39:11.500
they need to be free so we'll implement it

01:39:11.500 --> 01:39:13.500
by attention hijacking them so that they

01:39:13.500 --> 01:39:15.500
participate with it or

01:39:15.500 --> 01:39:17.500
don't even realize that it's happening and they just

01:39:17.500 --> 01:39:19.500
keep doing whatever is next

01:39:21.500 --> 01:39:23.500
the cultural element why we talk

01:39:23.500 --> 01:39:25.500
about the need for a new cultural enlightenment

01:39:25.500 --> 01:39:27.500
is

01:39:27.500 --> 01:39:29.500
of course when we look at like the founding

01:39:29.500 --> 01:39:31.500
of the US we can see all that was

01:39:33.500 --> 01:39:35.500
super wrong with it right

01:39:35.500 --> 01:39:37.500
just to mention like how when Churchill said

01:39:37.500 --> 01:39:39.500
democracy is the worst form of government ever

01:39:39.500 --> 01:39:41.500
saved for all the other forms

01:39:41.500 --> 01:39:43.500
there's when when Socrates

01:39:43.500 --> 01:39:45.500
talked about in

01:39:45.500 --> 01:39:47.500
in the republic when Plato was

01:39:47.500 --> 01:39:49.500
discussing it why

01:39:49.500 --> 01:39:51.500
democracy was a dreadful idea

01:39:51.500 --> 01:39:53.500
the arguments are good arguments right like

01:39:53.500 --> 01:39:55.500
do you want

01:39:55.500 --> 01:39:57.500
people who understand

01:39:57.500 --> 01:39:59.500
seafaring to man the boat or just a general

01:39:59.500 --> 01:40:01.500
population who knows nothing about it to man the boat

01:40:01.500 --> 01:40:03.500
well that's not a very good idea do you want the general

01:40:03.500 --> 01:40:05.500
population that knows nothing about it to build the NASA

01:40:05.500 --> 01:40:07.500
rocket or do you want people that know what they're doing

01:40:07.500 --> 01:40:09.500
well why would we think people who have no idea what

01:40:09.500 --> 01:40:11.500
they're doing are going to be good at figuring out

01:40:11.500 --> 01:40:13.500
how a civilization should be run what should

01:40:13.500 --> 01:40:15.500
our nuclear first strike policy should be how should

01:40:15.500 --> 01:40:17.500
we deal with the stability of the energy grid

01:40:17.500 --> 01:40:19.500
against Carrington events

01:40:19.500 --> 01:40:21.500
and so what does it take

01:40:21.500 --> 01:40:23.500
to have a population educated enough

01:40:23.500 --> 01:40:25.500
and yet then if we say okay

01:40:25.500 --> 01:40:27.500
but then the other

01:40:27.500 --> 01:40:29.500
problem is if we say the people are

01:40:29.500 --> 01:40:31.500
too uneducated and maybe

01:40:31.500 --> 01:40:33.500
too irrational and rival risk to be able

01:40:33.500 --> 01:40:35.500
to hold that power so it needs to be held by

01:40:35.500 --> 01:40:37.500
some how do we ensure non-corruption and

01:40:37.500 --> 01:40:39.500
who is a trust

01:40:39.500 --> 01:40:41.500
worthy authority to be

01:40:41.500 --> 01:40:43.500
able to hold that power and not have vested

01:40:43.500 --> 01:40:45.500
interest mess it up and so this is why I

01:40:45.500 --> 01:40:47.500
think it was a Jefferson quote of

01:40:47.500 --> 01:40:49.500
the ultimate

01:40:49.500 --> 01:40:51.500
depository of the power must be the people and if

01:40:51.500 --> 01:40:53.500
we think the people too uneducated not enlightened

01:40:53.500 --> 01:40:55.500
to be able to hold that power

01:40:55.500 --> 01:40:57.500
we must do everything we can to seek to

01:40:57.500 --> 01:40:59.500
educate and lighten them not think that there

01:40:59.500 --> 01:41:01.500
is any other safe depository

01:41:01.500 --> 01:41:03.500
and so

01:41:03.500 --> 01:41:05.500
even with that

01:41:05.500 --> 01:41:07.500
we take the

01:41:07.500 --> 01:41:09.500
US formation and

01:41:09.500 --> 01:41:11.500
you've got some founders

01:41:11.500 --> 01:41:13.500
who

01:41:13.500 --> 01:41:15.500
had read most of the books of the time

01:41:15.500 --> 01:41:17.500
read most of the books of philosophy knew the history

01:41:17.500 --> 01:41:19.500
of the Magna Carta and the Treaty of the Forest

01:41:19.500 --> 01:41:21.500
and all these kinds of things thought and talked deeply

01:41:21.500 --> 01:41:23.500
spent many years were willing to die

01:41:23.500 --> 01:41:25.500
fighting a revolutionary war were not

01:41:25.500 --> 01:41:27.500
going along with winning at the current system

01:41:27.500 --> 01:41:29.500
but really trying to do a fundamentally different thing

01:41:29.500 --> 01:41:31.500
to develop a new system

01:41:31.500 --> 01:41:33.500
not everybody who was participating in the US

01:41:33.500 --> 01:41:35.500
was doing that thing they weren't all doing systems

01:41:35.500 --> 01:41:37.500
architecture right

01:41:37.500 --> 01:41:39.500
but they were all basically

01:41:39.500 --> 01:41:41.500
saying

01:41:41.500 --> 01:41:43.500
we agree to this kind of systems

01:41:43.500 --> 01:41:45.500
architecture and we want to

01:41:45.500 --> 01:41:47.500
learn how to participate with it adequately

01:41:47.500 --> 01:41:49.500
will read a newspaper we will do a

01:41:49.500 --> 01:41:51.500
jury duty will come to the town hall that kind of

01:41:51.500 --> 01:41:53.500
thing so

01:41:53.500 --> 01:41:55.500
um

01:41:55.500 --> 01:41:57.500
in Taiwan's example I think their population

01:41:57.500 --> 01:41:59.500
is 23 million people in their

01:41:59.500 --> 01:42:01.500
online citizen engagement platform has something

01:42:01.500 --> 01:42:03.500
like 5 million people engaging

01:42:03.500 --> 01:42:05.500
that's pretty awesome right that's not everybody

01:42:05.500 --> 01:42:07.500
and no one should be forced to be engaging

01:42:09.500 --> 01:42:11.500
and one of the critical things

01:42:11.500 --> 01:42:13.500
when we think deeper about is it a democracy

01:42:13.500 --> 01:42:15.500
is it a republic

01:42:15.500 --> 01:42:17.500
is it a epistocracy is it a

01:42:17.500 --> 01:42:19.500
um we want to think about

01:42:19.500 --> 01:42:21.500
the values not the previous

01:42:21.500 --> 01:42:23.500
frames for them and the values exist

01:42:23.500 --> 01:42:25.500
in dialectics and we need to be able to hold those

01:42:25.500 --> 01:42:27.500
together of course we want individual liberty

01:42:27.500 --> 01:42:29.500
but we don't want individual liberty that gets to harm

01:42:29.500 --> 01:42:31.500
other people and other things so we want

01:42:31.500 --> 01:42:33.500
also you know law justice collective

01:42:33.500 --> 01:42:35.500
integrity how do you relate those things

01:42:35.500 --> 01:42:37.500
one of the core things is the relationship between

01:42:37.500 --> 01:42:39.500
rights and responsibilities so

01:42:39.500 --> 01:42:41.500
there

01:42:41.500 --> 01:42:43.500
if I have rights and I don't have

01:42:43.500 --> 01:42:45.500
responsibilities there ends up

01:42:45.500 --> 01:42:47.500
being like tyranny and entitlement

01:42:47.500 --> 01:42:49.500
if I and we can see

01:42:49.500 --> 01:42:51.500
that that's kind of rampant the entitlement

01:42:51.500 --> 01:42:53.500
thing if I have responsibilities

01:42:53.500 --> 01:42:55.500
and I don't have any attendant rights

01:42:55.500 --> 01:42:57.500
at servitude neither of those

01:42:57.500 --> 01:42:59.500
involve a healthy just society so

01:42:59.500 --> 01:43:01.500
if I want the right

01:43:01.500 --> 01:43:03.500
to drive a car the responsibility

01:43:03.500 --> 01:43:05.500
to do the driver's education and actually

01:43:05.500 --> 01:43:07.500
learn how to drive a car safely is important and we

01:43:07.500 --> 01:43:09.500
can see that some countries have less car

01:43:09.500 --> 01:43:11.500
accidents than others associated with better

01:43:11.500 --> 01:43:13.500
drivers education um and so

01:43:13.500 --> 01:43:15.500
increasing the responsibilities a good

01:43:15.500 --> 01:43:17.500
thing we can see that some countries

01:43:17.500 --> 01:43:19.500
have way less gun violence than others

01:43:19.500 --> 01:43:21.500
even factoring a similar per capita

01:43:21.500 --> 01:43:23.500
amount of guns based on more training

01:43:23.500 --> 01:43:25.500
associated with guns and mental health

01:43:25.500 --> 01:43:27.500
and things like that

01:43:27.500 --> 01:43:29.500
so if I have a right to bear arms

01:43:29.500 --> 01:43:31.500
do I also have a responsibility

01:43:31.500 --> 01:43:33.500
to be part of a well organized militia

01:43:33.500 --> 01:43:35.500
train with them and be willing to actually sacrifice

01:43:35.500 --> 01:43:37.500
myself to protect the whole or

01:43:37.500 --> 01:43:39.500
sign up for a thing to do that to have to be a

01:43:39.500 --> 01:43:41.500
reservist of some kind those are the right

01:43:41.500 --> 01:43:43.500
responsibility if I want the right to vote

01:43:43.500 --> 01:43:45.500
is there a responsibility to be educated

01:43:45.500 --> 01:43:47.500
about the issue

01:43:47.500 --> 01:43:49.500
yes yes now

01:43:49.500 --> 01:43:51.500
does that make it very unequal no

01:43:51.500 --> 01:43:53.500
because the capacity

01:43:53.500 --> 01:43:55.500
to get educated has to be something that the

01:43:55.500 --> 01:43:57.500
society invests in making possible for

01:43:57.500 --> 01:43:59.500
everyone and of course we would all be

01:43:59.500 --> 01:44:01.500
silly to not

01:44:01.500 --> 01:44:03.500
be dubious factoring the previous

01:44:03.500 --> 01:44:05.500
history of these things but this is what we then

01:44:05.500 --> 01:44:07.500
have to insist upon because do we want

01:44:07.500 --> 01:44:09.500
people who really

01:44:09.500 --> 01:44:11.500
don't understand the issues but think they do

01:44:11.500 --> 01:44:13.500
voting now that's a dreadful system

01:44:13.500 --> 01:44:15.500
but do we want people who know

01:44:15.500 --> 01:44:17.500
something to have no avenue or who care

01:44:17.500 --> 01:44:19.500
do we want people who know something to have

01:44:19.500 --> 01:44:21.500
no avenue to input that into the system or

01:44:21.500 --> 01:44:23.500
people who care to have no opportunity

01:44:23.500 --> 01:44:25.500
to learn no that's also dreadful

01:44:25.500 --> 01:44:27.500
so how do we make the on-ramps to learning

01:44:27.500 --> 01:44:29.500
available for everyone not enforced

01:44:29.500 --> 01:44:31.500
but we're actually incentivizing

01:44:31.500 --> 01:44:33.500
can we use those same kind of social media

01:44:33.500 --> 01:44:35.500
behavior and sending technologies to increase

01:44:35.500 --> 01:44:37.500
everyone's desire for more rights

01:44:37.500 --> 01:44:39.500
and attendant responsibilities

01:44:39.500 --> 01:44:41.500
so that there's actually a gradient

01:44:41.500 --> 01:44:43.500
of civic virtue and civic engagement

01:44:43.500 --> 01:44:45.500
yeah we could totally do that

01:44:47.500 --> 01:44:49.500
so this is where the cultural enlightenment

01:44:49.500 --> 01:44:51.500
layer is of course not everyone is going to

01:44:51.500 --> 01:44:53.500
be working on how do we develop AI

01:44:53.500 --> 01:44:55.500
and blockchain for these purposes

01:44:55.500 --> 01:44:57.500
but they can certainly be saying I am going

01:44:57.500 --> 01:44:59.500
to make sure that my representatives are talking

01:44:59.500 --> 01:45:01.500
about these issues I want all the

01:45:01.500 --> 01:45:03.500
presidential candidates to be talking about these issues

01:45:03.500 --> 01:45:05.500
I'm going to pay attention to and support

01:45:05.500 --> 01:45:07.500
candidates who really do in earnest ways

01:45:07.500 --> 01:45:09.500
I'm going to invest in

01:45:09.500 --> 01:45:11.500
companies that are doing those things I'm going to

01:45:11.500 --> 01:45:13.500
invest from companies that are doing the other things

01:45:13.500 --> 01:45:15.500
there is a cultural

01:45:15.500 --> 01:45:17.500
enlightenment that is needed

01:45:17.500 --> 01:45:19.500
to be able to create the

01:45:19.500 --> 01:45:21.500
demand and the support for

01:45:21.500 --> 01:45:23.500
where those projects

01:45:23.500 --> 01:45:25.500
that are earnestly working on and have

01:45:25.500 --> 01:45:27.500
the capability start to emerge

01:45:27.500 --> 01:45:29.500
so you've painted

01:45:29.500 --> 01:45:31.500
a compelling vision of

01:45:31.500 --> 01:45:33.500
some of the ways that a open

01:45:33.500 --> 01:45:35.500
society could consciously employ

01:45:35.500 --> 01:45:37.500
some of these technologies to

01:45:37.500 --> 01:45:39.500
revisit and

01:45:39.500 --> 01:45:41.500
re-fulfill some of the original

01:45:41.500 --> 01:45:43.500
values for which they were intended

01:45:43.500 --> 01:45:45.500
how much of this

01:45:45.500 --> 01:45:47.500
how does this work with the

01:45:47.500 --> 01:45:49.500
existing institutions that we have how much is

01:45:49.500 --> 01:45:51.500
this going to rely on

01:45:51.500 --> 01:45:53.500
transforming the existing

01:45:53.500 --> 01:45:55.500
digital Leviathans into something new

01:45:55.500 --> 01:45:57.500
how much is going to depend on blockchain projects

01:45:57.500 --> 01:45:59.500
how much is going to depend on

01:45:59.500 --> 01:46:01.500
existing institutions would be the Brookings

01:46:01.500 --> 01:46:03.500
institution or

01:46:03.500 --> 01:46:05.500
the New York Times can you speak

01:46:05.500 --> 01:46:07.500
to the role of new

01:46:07.500 --> 01:46:09.500
and future institutions in making this transition

01:46:09.500 --> 01:46:11.500
possible

01:46:13.500 --> 01:46:15.500
yeah

01:46:15.500 --> 01:46:17.500
it's interesting

01:46:17.500 --> 01:46:19.500
when we look at institutions that emerged

01:46:19.500 --> 01:46:21.500
to try to solve some social

01:46:21.500 --> 01:46:23.500
or environmental problems or nonprofits

01:46:23.500 --> 01:46:25.500
in particular and some government branches

01:46:25.500 --> 01:46:27.500
that are associated

01:46:27.500 --> 01:46:29.500
with that there's this kind of structural

01:46:29.500 --> 01:46:31.500
perverse incentive

01:46:31.500 --> 01:46:33.500
that if I

01:46:33.500 --> 01:46:35.500
am an organization which means

01:46:35.500 --> 01:46:37.500
I'm people in an organization

01:46:37.500 --> 01:46:39.500
that

01:46:39.500 --> 01:46:41.500
have some that have job security

01:46:41.500 --> 01:46:43.500
and some actual power and access and whatever

01:46:43.500 --> 01:46:45.500
because of this position

01:46:45.500 --> 01:46:47.500
and my job is to solve a problem

01:46:47.500 --> 01:46:49.500
if I fully solve the problem I would obsolete my job

01:46:49.500 --> 01:46:51.500
and obsolete myself so then there's this kind of

01:46:51.500 --> 01:46:53.500
perverse incentive to continue managing

01:46:53.500 --> 01:46:55.500
the problem continue manufacturing the narrative

01:46:55.500 --> 01:46:57.500
that we're needed to manage the problem continue

01:46:57.500 --> 01:46:59.500
manufacturing the narrative that the problem

01:46:59.500 --> 01:47:01.500
is really hard and is hard to solve and so we got

01:47:01.500 --> 01:47:03.500
to keep doing this thing

01:47:03.500 --> 01:47:05.500
and so one of the fundamental

01:47:05.500 --> 01:47:07.500
dispositions of systems is that

01:47:07.500 --> 01:47:09.500
they want to keep existing and

01:47:09.500 --> 01:47:11.500
so and yet they might

01:47:11.500 --> 01:47:13.500
no longer be fit for purpose they might even be

01:47:13.500 --> 01:47:15.500
antithetical to the purpose we have to be very

01:47:15.500 --> 01:47:17.500
careful about this

01:47:17.500 --> 01:47:19.500
with regard to

01:47:19.500 --> 01:47:21.500
the new institutions we need to what degree could

01:47:21.500 --> 01:47:23.500
existing institutions reform

01:47:23.500 --> 01:47:25.500
themselves to what degree does it need to be new ones

01:47:25.500 --> 01:47:27.500
it's kind of up to them like it's kind of

01:47:27.500 --> 01:47:29.500
up to the the depth of

01:47:29.500 --> 01:47:31.500
realization of the need and the

01:47:31.500 --> 01:47:33.500
sincerity and then the coordination capacity of

01:47:33.500 --> 01:47:35.500
people in current institutions

01:47:35.500 --> 01:47:37.500
how much role they could play we can

01:47:37.500 --> 01:47:39.500
see the way that going into World

01:47:39.500 --> 01:47:41.500
War II coming out of the depression the U.S.

01:47:41.500 --> 01:47:43.500
up-regulated its

01:47:43.500 --> 01:47:45.500
coordination capacity so profoundly

01:47:45.500 --> 01:47:47.500
so could we

01:47:47.500 --> 01:47:49.500
have a Manhattan project like level

01:47:49.500 --> 01:47:51.500
organization

01:47:51.500 --> 01:47:53.500
by organization

01:47:53.500 --> 01:47:55.500
I mean

01:47:55.500 --> 01:47:57.500
the

01:47:57.500 --> 01:47:59.500
capacity to organize not a

01:47:59.500 --> 01:48:01.500
singular thing

01:48:01.500 --> 01:48:03.500
that was oriented

01:48:03.500 --> 01:48:05.500
to how do we

01:48:05.500 --> 01:48:07.500
instantiate the next model

01:48:07.500 --> 01:48:09.500
of civilization how do we instantiate the next model

01:48:09.500 --> 01:48:11.500
of social systems and social technologies

01:48:11.500 --> 01:48:13.500
what is the future of education what's the future of economics

01:48:13.500 --> 01:48:15.500
what's the future of

01:48:15.500 --> 01:48:17.500
the fourth estate of law etc

01:48:17.500 --> 01:48:19.500
that are

01:48:19.500 --> 01:48:21.500
that fulfill the values

01:48:21.500 --> 01:48:23.500
that are meaningful and are antifragile

01:48:23.500 --> 01:48:25.500
in the presence of the current technologies

01:48:25.500 --> 01:48:27.500
and they can actually compete with the other applications

01:48:27.500 --> 01:48:29.500
of those technologies towards

01:48:29.500 --> 01:48:31.500
things that serve different values

01:48:31.500 --> 01:48:33.500
and or aren't antifragile

01:48:33.500 --> 01:48:35.500
I would

01:48:35.500 --> 01:48:37.500
love to see the U.S.

01:48:37.500 --> 01:48:39.500
make that a

01:48:39.500 --> 01:48:41.500
central imperative Manhattan project level

01:48:41.500 --> 01:48:43.500
to be able to do that not just how do we create a more

01:48:43.500 --> 01:48:45.500
powerful military but how do we create

01:48:45.500 --> 01:48:47.500
a more powerful a

01:48:47.500 --> 01:48:49.500
healthier fundamentally a healthier

01:48:49.500 --> 01:48:51.500
society that up regulates

01:48:51.500 --> 01:48:53.500
and engages collective intelligence

01:48:53.500 --> 01:48:55.500
in its own problem solving and innovation better

01:48:55.500 --> 01:48:57.500
I would like to see lots

01:48:57.500 --> 01:48:59.500
of countries do that I think there are countries

01:48:59.500 --> 01:49:01.500
that did

01:49:01.500 --> 01:49:03.500
not yet transition to democracy

01:49:03.500 --> 01:49:05.500
are interested in it and completely bypass

01:49:05.500 --> 01:49:07.500
the industrial era democracies

01:49:07.500 --> 01:49:09.500
and go directly to better systems

01:49:09.500 --> 01:49:11.500
I think networks

01:49:11.500 --> 01:49:13.500
of small countries you see what Taiwan

01:49:13.500 --> 01:49:15.500
is doing Estonia is trying to do some interesting

01:49:15.500 --> 01:49:17.500
things I think networks of small countries could start

01:49:17.500 --> 01:49:19.500
sharing best practices and sharing

01:49:19.500 --> 01:49:21.500
resources so they don't all have to develop the stuff from

01:49:21.500 --> 01:49:23.500
scratch which could start to lead

01:49:23.500 --> 01:49:25.500
to coalitions of countries like the EU

01:49:25.500 --> 01:49:27.500
saying let's do some fundamentally better

01:49:27.500 --> 01:49:29.500
things I think

01:49:29.500 --> 01:49:31.500
it will happen also not at the level of nation

01:49:31.500 --> 01:49:33.500
states were like

01:49:33.500 --> 01:49:35.500
decentralized groups blockchain

01:49:35.500 --> 01:49:37.500
type groups say all right let's

01:49:37.500 --> 01:49:39.500
really earnestly take on what these primary

01:49:39.500 --> 01:49:41.500
problems are and work on developing

01:49:41.500 --> 01:49:43.500
these solutions these capacities

01:49:43.500 --> 01:49:45.500
for the tech companies

01:49:45.500 --> 01:49:47.500
to do so would be very hard because

01:49:47.500 --> 01:49:49.500
while

01:49:49.500 --> 01:49:51.500
it could be

01:49:51.500 --> 01:49:53.500
still

01:49:53.500 --> 01:49:55.500
profitable

01:49:55.500 --> 01:49:57.500
long term it would not be profit

01:49:57.500 --> 01:49:59.500
maximizing short term relative

01:49:59.500 --> 01:50:01.500
to the current thing they're doing as we said

01:50:01.500 --> 01:50:03.500
winning at the current game

01:50:03.500 --> 01:50:05.500
and building a new game are different things

01:50:05.500 --> 01:50:07.500
and winning at a current game that self

01:50:07.500 --> 01:50:09.500
terminating is a very short sighted thing

01:50:09.500 --> 01:50:11.500
to want to keep doing so

01:50:11.500 --> 01:50:13.500
if Facebook or Google or whatever

01:50:13.500 --> 01:50:15.500
were to cut its ad model

01:50:15.500 --> 01:50:17.500
it would have a hard time being able to meet

01:50:17.500 --> 01:50:19.500
its fiduciary responsibility to shareholders a different

01:50:19.500 --> 01:50:21.500
way but could it

01:50:21.500 --> 01:50:23.500
in conjunction with

01:50:23.500 --> 01:50:25.500
a

01:50:25.500 --> 01:50:27.500
participatory

01:50:27.500 --> 01:50:29.500
government regulatory process that wanted

01:50:29.500 --> 01:50:31.500
to help change its fiduciary

01:50:31.500 --> 01:50:33.500
responsibility

01:50:33.500 --> 01:50:35.500
where it became more of a social utility

01:50:35.500 --> 01:50:37.500
start to actually redirect its technology

01:50:37.500 --> 01:50:39.500
and redirect its decision making process

01:50:39.500 --> 01:50:41.500
yeah it could and that would be super interesting

01:50:41.500 --> 01:50:43.500
so

01:50:43.500 --> 01:50:45.500
I would like to see

01:50:45.500 --> 01:50:47.500
as we mentioned earlier I'd like to see the UN

01:50:47.500 --> 01:50:49.500
recognize that the

01:50:49.500 --> 01:50:51.500
level of progress that it has made

01:50:51.500 --> 01:50:53.500
at

01:50:53.500 --> 01:50:55.500
the sustainable development goals, nuclear

01:50:55.500 --> 01:50:57.500
deproliferation and other types of

01:50:57.500 --> 01:50:59.500
international things like

01:50:59.500 --> 01:51:01.500
economic equality

01:51:01.500 --> 01:51:03.500
globally writ large

01:51:03.500 --> 01:51:05.500
and

01:51:05.500 --> 01:51:07.500
preventing arms races and tragedy of the commons that

01:51:07.500 --> 01:51:09.500
well it hasn't done nothing

01:51:09.500 --> 01:51:11.500
what it's doing is not converging

01:51:11.500 --> 01:51:13.500
it's not adequate, it's not converging on

01:51:13.500 --> 01:51:15.500
eventually solving the problem set

01:51:15.500 --> 01:51:17.500
just more of that approach, it needs a different approach

01:51:17.500 --> 01:51:19.500
and so to say

01:51:19.500 --> 01:51:21.500
clearly we don't know how to facilitate

01:51:21.500 --> 01:51:23.500
coordination of global problems well enough

01:51:23.500 --> 01:51:25.500
so let's have the superseding focus

01:51:25.500 --> 01:51:27.500
be innovation towards better methods of global

01:51:27.500 --> 01:51:29.500
coordination, that becomes our new number one

01:51:29.500 --> 01:51:31.500
goal

01:51:31.500 --> 01:51:33.500
because we know we only get all the other goals if we get that

01:51:33.500 --> 01:51:35.500
and you can see that during World War II

01:51:35.500 --> 01:51:37.500
when we had to crack the enigma machine

01:51:37.500 --> 01:51:39.500
and figure out

01:51:39.500 --> 01:51:41.500
computation and whatever

01:51:41.500 --> 01:51:43.500
we got touring, we got von Neumann

01:51:43.500 --> 01:51:45.500
one of the smartest people from

01:51:45.500 --> 01:51:47.500
countries all around the world

01:51:47.500 --> 01:51:49.500
engaged in solving those problems

01:51:49.500 --> 01:51:51.500
I would like to see the US, the UN

01:51:51.500 --> 01:51:53.500
I would like to see other countries and I would like to see private sector

01:51:53.500 --> 01:51:55.500
taking seriously the actual

01:51:55.500 --> 01:51:57.500
problemscape we have

01:51:57.500 --> 01:51:59.500
and innovating not for

01:51:59.500 --> 01:52:01.500
just short-term advantage or narrow

01:52:01.500 --> 01:52:03.500
in-group advantage

01:52:03.500 --> 01:52:05.500
but for long-term

01:52:07.500 --> 01:52:09.500
advantage of the whole, how do we

01:52:09.500 --> 01:52:11.500
since we have global effect

01:52:11.500 --> 01:52:13.500
global coordination adequate to what is needed

01:52:13.500 --> 01:52:15.500
to me that has to become

01:52:15.500 --> 01:52:17.500
the central zeitgeist

01:52:17.500 --> 01:52:19.500
and whatever groups figure out how to do it

01:52:19.500 --> 01:52:21.500
effectively will be the groups

01:52:21.500 --> 01:52:23.500
that can direct the future

01:52:23.500 --> 01:52:25.500
and I know that this is the work

01:52:25.500 --> 01:52:27.500
that you are working towards with the conciliance project

01:52:27.500 --> 01:52:29.500
do you want to talk

01:52:29.500 --> 01:52:31.500
just about how you are working towards that

01:52:31.500 --> 01:52:33.500
with your work and how we are collaborating?

01:52:33.500 --> 01:52:35.500
yeah, I mean we are

01:52:35.500 --> 01:52:37.500
we are at the very very beginning

01:52:37.500 --> 01:52:39.500
the conciliance project

01:52:39.500 --> 01:52:41.500
has a site up that is not even

01:52:41.500 --> 01:52:43.500
a beta yet

01:52:43.500 --> 01:52:45.500
because we

01:52:45.500 --> 01:52:47.500
in just starting wanted to

01:52:49.500 --> 01:52:51.500
work on building stuff

01:52:51.500 --> 01:52:53.500
in association with thinking

01:52:53.500 --> 01:52:55.500
but this talk is very

01:52:55.500 --> 01:52:57.500
central, this conversation you and I are having is very central to the aims of the conciliance project

01:52:57.500 --> 01:52:59.500
which is

01:52:59.500 --> 01:53:01.500
we are wanting to

01:53:01.500 --> 01:53:03.500
inspire, inform and help

01:53:03.500 --> 01:53:05.500
direct a innovation zeitgeist

01:53:05.500 --> 01:53:07.500
where

01:53:07.500 --> 01:53:09.500
the many different problems of the world

01:53:09.500 --> 01:53:11.500
start to get seen in terms of

01:53:11.500 --> 01:53:13.500
having interconnectivity

01:53:13.500 --> 01:53:15.500
and underlying drivers

01:53:15.500 --> 01:53:17.500
and the forcing function

01:53:17.500 --> 01:53:19.500
of the power of exponential tech

01:53:19.500 --> 01:53:21.500
is taken seriously that says in order to become

01:53:21.500 --> 01:53:23.500
good stewards of that requires

01:53:23.500 --> 01:53:25.500
evolutions of both our social

01:53:25.500 --> 01:53:27.500
systems and our culture

01:53:27.500 --> 01:53:29.500
the wisdom to be able to guide

01:53:29.500 --> 01:53:31.500
that power, a recoupling

01:53:31.500 --> 01:53:33.500
of wisdom and power in that

01:53:33.500 --> 01:53:35.500
adequate to what is needed

01:53:35.500 --> 01:53:37.500
so how do we innovate in culture

01:53:37.500 --> 01:53:39.500
the development of people

01:53:39.500 --> 01:53:41.500
and how do we innovate in the social systems

01:53:41.500 --> 01:53:43.500
the advancement of our coordination

01:53:43.500 --> 01:53:45.500
both employing the exponential tech

01:53:45.500 --> 01:53:47.500
and being able to rightly guide it

01:53:47.500 --> 01:53:49.500
and so

01:53:49.500 --> 01:53:51.500
we have

01:53:51.500 --> 01:53:53.500
a really great team of people that are

01:53:53.500 --> 01:53:55.500
doing research

01:53:55.500 --> 01:53:57.500
and writing basically the types

01:53:57.500 --> 01:53:59.500
of things we are talking about here in more depth explaining

01:53:59.500 --> 01:54:01.500
what is the role of

01:54:01.500 --> 01:54:03.500
the various social systems like what is the role of education

01:54:03.500 --> 01:54:05.500
to any society help understand

01:54:05.500 --> 01:54:07.500
fundamentally what that is

01:54:07.500 --> 01:54:09.500
understand why there is

01:54:09.500 --> 01:54:11.500
a particularly higher educational

01:54:11.500 --> 01:54:13.500
threshold for open societies where people

01:54:13.500 --> 01:54:15.500
need to participate not just in the

01:54:15.500 --> 01:54:17.500
market but in governance

01:54:17.500 --> 01:54:19.500
understand how that has been disrupted

01:54:19.500 --> 01:54:21.500
by the emerging tech and will be disrupted further

01:54:21.500 --> 01:54:23.500
by things like technological automation

01:54:23.500 --> 01:54:25.500
and then envision what is the future

01:54:25.500 --> 01:54:27.500
of education adequate to an open

01:54:27.500 --> 01:54:29.500
society in a world that has the

01:54:29.500 --> 01:54:31.500
technology that's emerging

01:54:31.500 --> 01:54:33.500
and we don't necessarily know what the answer is

01:54:33.500 --> 01:54:35.500
but we know examples and we know criteria

01:54:35.500 --> 01:54:37.500
so then it's like innovate in this area

01:54:37.500 --> 01:54:39.500
and make sure you factor these criteria

01:54:39.500 --> 01:54:41.500
and the same thing with the fourth estate the same thing with law

01:54:41.500 --> 01:54:43.500
the same thing with economics

01:54:43.500 --> 01:54:45.500
and so the goal is not how do we take

01:54:45.500 --> 01:54:47.500
some small group of people to build the future

01:54:47.500 --> 01:54:49.500
it's how do we help get

01:54:49.500 --> 01:54:51.500
what the criteria of a viable future

01:54:51.500 --> 01:54:53.500
must be and if people disagree awesome

01:54:53.500 --> 01:54:55.500
publicly disagree and have the conversation now

01:54:55.500 --> 01:54:57.500
but if we get to put out those design constraints

01:54:57.500 --> 01:54:59.500
someone says no we think it's other ones

01:54:59.500 --> 01:55:01.500
the center of culture starts to be thinking about

01:55:01.500 --> 01:55:03.500
the most pressing issues

01:55:03.500 --> 01:55:05.500
in fundamental ways and how to think about them

01:55:05.500 --> 01:55:07.500
appropriately and how to approach them appropriately

01:55:07.500 --> 01:55:09.500
so fundamentally our goal

01:55:09.500 --> 01:55:11.500
is

01:55:11.500 --> 01:55:13.500
supporting an increased

01:55:13.500 --> 01:55:15.500
cultural understanding of the nature of the

01:55:15.500 --> 01:55:17.500
problems that we face a clearer understanding

01:55:17.500 --> 01:55:19.500
rather than just there's lots of problems and it's overwhelming

01:55:19.500 --> 01:55:21.500
and it's a bummer and so

01:55:21.500 --> 01:55:23.500
either some very narrow

01:55:23.500 --> 01:55:25.500
action on some very narrow part

01:55:25.500 --> 01:55:27.500
of it makes sense just most of activism

01:55:27.500 --> 01:55:29.500
or just nihilism

01:55:29.500 --> 01:55:31.500
we want to be able to say actually

01:55:31.500 --> 01:55:33.500
because there are underlying drivers

01:55:33.500 --> 01:55:35.500
there is actually a possibility

01:55:35.500 --> 01:55:37.500
to resolve these things

01:55:37.500 --> 01:55:39.500
it does require the fullness of our capacity

01:55:39.500 --> 01:55:41.500
applied to it

01:55:41.500 --> 01:55:43.500
and with the fullness of our capacity so it's not a

01:55:43.500 --> 01:55:45.500
given but with the fullness of our capacity applied to it

01:55:45.500 --> 01:55:47.500
there is actually a path forward

01:55:47.500 --> 01:55:49.500
and

01:55:49.500 --> 01:55:51.500
so we're writing these papers

01:55:51.500 --> 01:55:53.500
that basically would be kind of like

01:55:53.500 --> 01:55:55.500
a meta-curriculum

01:55:55.500 --> 01:55:57.500
for people who want to be engaged in designing the future

01:55:57.500 --> 01:55:59.500
and

01:55:59.500 --> 01:56:01.500
some of them have to do with current

01:56:01.500 --> 01:56:03.500
public culture and how to be able to

01:56:03.500 --> 01:56:05.500
change patterns of public culture that lead to

01:56:05.500 --> 01:56:07.500
better conversation, better sense

01:56:07.500 --> 01:56:09.500
making, better meaning making and choice making

01:56:09.500 --> 01:56:11.500
so that there's an on-ramp into higher quality

01:56:11.500 --> 01:56:13.500
conversations meaning higher quality process of

01:56:13.500 --> 01:56:15.500
conversation and then some of them are things

01:56:15.500 --> 01:56:17.500
like what are the design criteria

01:56:17.500 --> 01:56:19.500
of the future social systems and how could

01:56:19.500 --> 01:56:21.500
we build those things then

01:56:21.500 --> 01:56:23.500
not everybody will read those

01:56:23.500 --> 01:56:25.500
some people who

01:56:25.500 --> 01:56:27.500
have the ability to help start building them

01:56:27.500 --> 01:56:29.500
will but

01:56:29.500 --> 01:56:31.500
we hope that other people will

01:56:31.500 --> 01:56:33.500
take that and translate it on podcasts

01:56:33.500 --> 01:56:35.500
and into animations and in

01:56:35.500 --> 01:56:37.500
whatever other forms of media

01:56:37.500 --> 01:56:39.500
so that those topics start

01:56:39.500 --> 01:56:41.500
to become increasingly

01:56:41.500 --> 01:56:43.500
present in people's awareness

01:56:43.500 --> 01:56:45.500
then of course

01:56:45.500 --> 01:56:47.500
the next part is what groups start

01:56:47.500 --> 01:56:49.500
emerging wanting to address those

01:56:49.500 --> 01:56:51.500
and what can we do to help facilitate

01:56:51.500 --> 01:56:53.500
good solutions in those groups

01:56:57.500 --> 01:56:59.500
and this is where you and I

01:56:59.500 --> 01:57:01.500
I've learned a lot from you about

01:57:01.500 --> 01:57:03.500
the

01:57:03.500 --> 01:57:05.500
social media issues in particular and how

01:57:05.500 --> 01:57:07.500
central they are to the breakdown of sense making

01:57:07.500 --> 01:57:09.500
because obviously without good shared sense making

01:57:09.500 --> 01:57:11.500
there is no possibility for emergent order

01:57:11.500 --> 01:57:13.500
you either just get chaos or you have to

01:57:13.500 --> 01:57:15.500
have imposed order if you want emergent

01:57:15.500 --> 01:57:17.500
order that means emergent good choice making

01:57:17.500 --> 01:57:19.500
that means emergent good sense making

01:57:19.500 --> 01:57:21.500
and so

01:57:21.500 --> 01:57:23.500
we've learned a lot and discussed these things for a long time

01:57:23.500 --> 01:57:25.500
and obviously also not just you and I

01:57:25.500 --> 01:57:27.500
there's a whole network of people that we're connected to

01:57:27.500 --> 01:57:29.500
that have been thinking deeply about these things

01:57:29.500 --> 01:57:31.500
that we continue to

01:57:31.500 --> 01:57:33.500
try to think about what

01:57:33.500 --> 01:57:35.500
adequate solutions could look like

01:57:35.500 --> 01:57:37.500
and

01:57:37.500 --> 01:57:39.500
I think what

01:57:39.500 --> 01:57:41.500
CHT did with the social dilemma

01:57:41.500 --> 01:57:43.500
took

01:57:43.500 --> 01:57:45.500
one really critical part of this metacrisis

01:57:45.500 --> 01:57:47.500
into popular attention

01:57:47.500 --> 01:57:49.500
in a more powerful way than I have seen done

01:57:49.500 --> 01:57:51.500
otherwise because as big a deal

01:57:51.500 --> 01:57:53.500
is getting climate change and public attention is

01:57:53.500 --> 01:57:55.500
it's not clear that

01:57:55.500 --> 01:57:57.500
climate change is something that is making

01:57:57.500 --> 01:57:59.500
that is driving

01:57:59.500 --> 01:58:01.500
the underlying basis of all the problems

01:58:01.500 --> 01:58:03.500
but a breakdown in sense making and a control

01:58:03.500 --> 01:58:05.500
of patterns of human behavior that kind of downgrade

01:58:05.500 --> 01:58:07.500
people like oh wow that really does make all these

01:58:07.500 --> 01:58:09.500
other things worse

01:58:09.500 --> 01:58:11.500
so I see that as a

01:58:11.500 --> 01:58:13.500
as a very powerful and personal

01:58:13.500 --> 01:58:15.500
on-ramp for those who are interested

01:58:15.500 --> 01:58:17.500
to be able to come into

01:58:17.500 --> 01:58:19.500
this deeper conversation

01:58:19.500 --> 01:58:21.500
and some

01:58:21.500 --> 01:58:23.500
of them it'll simply help them

01:58:23.500 --> 01:58:25.500
be like okay now I know

01:58:25.500 --> 01:58:27.500
what I was intuitively feeling somebody's put it

01:58:27.500 --> 01:58:29.500
into words and I at least feel more oriented

01:58:29.500 --> 01:58:31.500
and that's the extent because they don't necessarily

01:58:31.500 --> 01:58:33.500
have the ability to build new blockchain systems

01:58:33.500 --> 01:58:35.500
or whatever it is and they should be

01:58:35.500 --> 01:58:37.500
doing the nursing or education or whatever really

01:58:37.500 --> 01:58:39.500
other important social value they're doing

01:58:39.500 --> 01:58:41.500
some people

01:58:41.500 --> 01:58:43.500
will be able to say this actually really resonates

01:58:43.500 --> 01:58:45.500
I can translate this to other audiences

01:58:47.500 --> 01:58:49.500
and get more people engaged and some people say

01:58:49.500 --> 01:58:51.500
I can actually start innovating and working with this stuff

01:58:51.500 --> 01:58:53.500
and all of those are good

01:58:55.500 --> 01:58:57.500
yeah I

01:58:57.500 --> 01:58:59.500
I agree and I think

01:58:59.500 --> 01:59:01.500
what we've essentially been

01:59:01.500 --> 01:59:03.500
outlining here and you sort of hit it at the end

01:59:05.500 --> 01:59:07.500
is going back to the Charles Kettering

01:59:07.500 --> 01:59:09.500
quote which I learned from you

01:59:09.500 --> 01:59:11.500
and I've learned so many things from you over the years

01:59:11.500 --> 01:59:13.500
which is

01:59:13.500 --> 01:59:15.500
that a problem not fully

01:59:15.500 --> 01:59:17.500
understood is unsolvable

01:59:17.500 --> 01:59:19.500
and a problem that is fully understood is half

01:59:19.500 --> 01:59:21.500
solved and I just want to maybe

01:59:21.500 --> 01:59:23.500
leave our listeners with that which is

01:59:23.500 --> 01:59:25.500
I think people can look at the

01:59:25.500 --> 01:59:27.500
long litany of problems and

01:59:27.500 --> 01:59:29.500
feel overwhelmed or get to despair

01:59:29.500 --> 01:59:31.500
in a hurry I think is your phrase for it

01:59:31.500 --> 01:59:33.500
and I think that

01:59:33.500 --> 01:59:35.500
when you understand the core generator functions

01:59:35.500 --> 01:59:37.500
for what is driving

01:59:37.500 --> 01:59:39.500
so many of these problems to happen simultaneously

01:59:39.500 --> 01:59:41.500
there's a different

01:59:41.500 --> 01:59:43.500
and more empowering relationship to that

01:59:43.500 --> 01:59:45.500
and you've actually offered a vision

01:59:45.500 --> 01:59:47.500
for how technology can be consciously employed

01:59:47.500 --> 01:59:49.500
these new technologies can be consciously employed

01:59:49.500 --> 01:59:51.500
in ways that should feel inspiring and exciting

01:59:51.500 --> 01:59:53.500
I mean I want that transparent blockchain

01:59:53.500 --> 01:59:55.500
on a budget for every country in the world

01:59:55.500 --> 01:59:57.500
and we can see examples like Estonia and Taiwan

01:59:57.500 --> 01:59:59.500
moving in this direction already

01:59:59.500 --> 02:00:01.500
and we can see Taiwan building some of the technologies

02:00:01.500 --> 02:00:03.500
you mentioned to identify

02:00:03.500 --> 02:00:05.500
propositions of shared values between citizens

02:00:05.500 --> 02:00:07.500
who want to vote collectively on something that

02:00:07.500 --> 02:00:09.500
obviously would have driven up more polarization

02:00:09.500 --> 02:00:11.500
so we're seeing this thing emerging

02:00:11.500 --> 02:00:13.500
and I think what we need is to

02:00:13.500 --> 02:00:15.500
sort of have this be seen as

02:00:15.500 --> 02:00:17.500
a necessary upgrade to

02:00:17.500 --> 02:00:19.500
let me do that again

02:00:19.500 --> 02:00:21.500
I think we need to see this as

02:00:21.500 --> 02:00:23.500
not just an upgrade but

02:00:23.500 --> 02:00:25.500
the kind of cultural enlightenment that you speak of

02:00:25.500 --> 02:00:27.500
that so many different actors are in a sense

02:00:27.500 --> 02:00:29.500
already working on you know we used to

02:00:29.500 --> 02:00:31.500
have this phrase that everyone is on the same team

02:00:31.500 --> 02:00:33.500
they just don't know it yet

02:00:33.500 --> 02:00:35.500
and once you understand the

02:00:35.500 --> 02:00:37.500
degree to which we are in trouble

02:00:37.500 --> 02:00:39.500
if we do not get our heads around

02:00:39.500 --> 02:00:41.500
this and identify the kind of

02:00:41.500 --> 02:00:43.500
core generator functions that we need to be addressing

02:00:43.500 --> 02:00:45.500
once we all see that

02:00:45.500 --> 02:00:47.500
I'll just speak to my own

02:00:47.500 --> 02:00:49.500
experience when I first encountered your work

02:00:49.500 --> 02:00:51.500
and I encountered

02:00:51.500 --> 02:00:53.500
the kind of core drivers

02:00:53.500 --> 02:00:55.500
that drive so much of the danger

02:00:55.500 --> 02:00:57.500
that we are headed towards

02:00:57.500 --> 02:00:59.500
I

02:00:59.500 --> 02:01:01.500
immediately

02:01:01.500 --> 02:01:03.500
I was kind of already in this direction already

02:01:03.500 --> 02:01:05.500
reoriented my whole life to say

02:01:05.500 --> 02:01:07.500
how do we be in service if this is not happening

02:01:07.500 --> 02:01:09.500
and of creating a better world

02:01:09.500 --> 02:01:11.500
that actually meets and addresses these problems

02:01:11.500 --> 02:01:13.500
and I know so many other people

02:01:13.500 --> 02:01:15.500
whose work

02:01:15.500 --> 02:01:17.500
and whose lives and whose daily missions

02:01:17.500 --> 02:01:19.500
and purpose have been redirected

02:01:19.500 --> 02:01:21.500
by I think hearing some of the core

02:01:21.500 --> 02:01:23.500
frames that you offer

02:01:23.500 --> 02:01:25.500
and who I hope

02:01:25.500 --> 02:01:27.500
and who are many of whom are already working on

02:01:27.500 --> 02:01:29.500
active projects to deal with this and those who are not

02:01:29.500 --> 02:01:31.500
are supporting in other ways

02:01:31.500 --> 02:01:33.500
and I hope that our audience takes this as

02:01:33.500 --> 02:01:35.500
an inspiration

02:01:35.500 --> 02:01:37.500
for how can we in the face of

02:01:37.500 --> 02:01:39.500
stark and difficult realities

02:01:39.500 --> 02:01:41.500
as part of this process

02:01:41.500 --> 02:01:43.500
gain the kind of cultural

02:01:43.500 --> 02:01:45.500
strength to face these things head on

02:01:45.500 --> 02:01:47.500
and to orient our lives accordingly

02:01:47.500 --> 02:01:49.500
because I have

02:01:49.500 --> 02:01:51.500
while bearing periods of time

02:01:51.500 --> 02:01:53.500
hit probably low grade despair

02:01:53.500 --> 02:01:55.500
myself

02:01:55.500 --> 02:01:57.500
I actually feel more inspired than ever

02:01:57.500 --> 02:01:59.500
the amount of things and the number of people

02:01:59.500 --> 02:02:01.500
who face these challenges

02:02:01.500 --> 02:02:03.500
and I'll just say that

02:02:03.500 --> 02:02:05.500
I think when you face these challenges alone

02:02:05.500 --> 02:02:07.500
and you feel like you're the only one seeing them

02:02:07.500 --> 02:02:09.500
or you have a weird feeling in your stomach

02:02:09.500 --> 02:02:11.500
it can feel debilitating

02:02:11.500 --> 02:02:13.500
and when you realize the number of people

02:02:13.500 --> 02:02:15.500
who are also putting their heads up to say

02:02:15.500 --> 02:02:17.500
how can we change this

02:02:17.500 --> 02:02:19.500
that's what feels hopeful

02:02:19.500 --> 02:02:21.500
and that's where I derive my optimism

02:02:21.500 --> 02:02:23.500
so Daniel thank you so much for coming on

02:02:23.500 --> 02:02:25.500
it's an honor to have you

02:02:25.500 --> 02:02:27.500
your work has touched the lives

02:02:27.500 --> 02:02:29.500
who may not always say so publicly

02:02:29.500 --> 02:02:31.500
but I know that you

02:02:31.500 --> 02:02:33.500
had also a huge hand in

02:02:33.500 --> 02:02:35.500
inspiring some of the themes that emerged

02:02:35.500 --> 02:02:37.500
in the social dilemma which has impacted so many people

02:02:37.500 --> 02:02:39.500
as well so thank you so much

02:02:39.500 --> 02:02:41.500
really wonderful that we get to have this conversation

02:02:41.500 --> 02:02:43.500
thanks just on

02:02:43.500 --> 02:02:45.500
absolutely

