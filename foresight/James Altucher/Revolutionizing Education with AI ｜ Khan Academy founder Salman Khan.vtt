WEBVTT

00:00.000 --> 00:04.960
From pit lane to podium, the Las Vegas Grand Prix is providing fans a race day experience at the

00:04.960 --> 00:10.160
speed they deserve. With the help of T-Mobile for Business, our 5G Advanced Network solutions

00:10.160 --> 00:14.960
are powering race day operations with event-wide connectivity. From streamlined gate entry to

00:14.960 --> 00:20.480
an immersive app, giving fans blazing fast access to the sport they love. This is accelerating

00:20.480 --> 00:25.760
innovation. This is the Las Vegas Grand Prix with T-Mobile for Business. Take your business further

00:25.840 --> 00:36.640
at T-Mobile.com. Okay, let's do some quick math. The less your business spends on operations,

00:36.640 --> 00:41.440
on multiple systems, on delivering your product or service, the more margin you have and the

00:41.440 --> 00:48.320
more money you keep. That's obvious. But with higher expenses on materials, employees, distribution

00:48.320 --> 00:55.920
and borrowing, everything costs more. To reduce costs and headaches, smart businesses are graduating

00:55.920 --> 01:01.760
to NetSuite by Oracle. Here's the thing. Information is power. Information is money.

01:02.400 --> 01:09.040
Literally, the currency of today's world of entrepreneurship is information. And if you

01:09.040 --> 01:15.600
could bring all of the information about your business into one dashboard, this is incredibly

01:15.600 --> 01:21.440
valuable. NetSuite is the number one cloud financial system, bringing accounting, financial

01:21.440 --> 01:29.920
management, inventory, HR into one platform and one source of the truth about your business.

01:29.920 --> 01:36.240
With NetSuite, you reduce IT costs because NetSuite lives in the cloud with no hardware required,

01:36.240 --> 01:40.800
access from anywhere. You cut the cost of maintaining multiple systems because you've

01:40.800 --> 01:46.240
got one unified business management suite and you're improving efficiency by bringing all of

01:46.240 --> 01:52.880
your major business processes into one platform, slashing manual tasks and errors. This is so

01:52.880 --> 01:56.960
valuable. You just hit a button and you can see all the information about your business instead of

01:56.960 --> 02:01.680
having to like call five different departments and get all these emails and put it all together and

02:01.680 --> 02:08.160
make sense of it. Over 37,000 companies have already made the move. So do the math, see how

02:08.160 --> 02:14.400
you're profit with NetSuite. Back by popular demand, NetSuite has extended its one-of-a-kind

02:14.400 --> 02:21.760
flexible financing program for a few more weeks. Head to netsuite.com slash James net suite.com

02:21.760 --> 02:33.360
slash James net suite.com slash James.

02:41.920 --> 02:48.960
Oh my gosh, I've been wanting to have this guy on my podcast for literally 10 years ever since I

02:48.960 --> 02:57.280
started this podcast. I am so impressed with him and he speaks about a subject near and dear to my

02:57.280 --> 03:05.520
heart. So Salman Khan, Sal Khan is the creator of the Khan Academy, which was really the first big

03:06.160 --> 03:14.000
online academy. It was to learn math, coding, all these things. And there was generating people who

03:14.000 --> 03:20.080
really learned the topics as opposed to people who go all through 10 years of school and never

03:20.080 --> 03:25.520
learned these topics at all or the schools failed to teach them appropriately. The Khan Academy

03:25.520 --> 03:30.640
really seemed to understand education and it became this huge thing. 150 million students have gone

03:30.640 --> 03:37.520
through the Khan Academy or use it every month or that number of registered users. Salman Khan,

03:37.600 --> 03:45.040
Sal Khan, and he just wrote the book about how AI will revolutionize education. The book is called

03:45.040 --> 03:52.880
Brave New Words. How AI will revolutionize education and why that's a good thing. And he addresses

03:52.880 --> 03:58.880
how to use AI with education, whether you're a student, teacher, employer. It was so valuable in

03:58.880 --> 04:04.880
terms of understanding not only education, but AI and how we can use AI on our lives. And it

04:04.880 --> 04:11.200
addresses all the fears people are having right now about AI and its role in creativity and learning

04:11.200 --> 04:16.720
and will it replace jobs or will it make it easier to get a job. So Brave New Words,

04:16.720 --> 04:22.000
how AI will revolutionize education and why that's a good thing. I finally got to interview

04:22.000 --> 04:28.080
Sal Khan about the Khan Academy and AI and I learned so much and I hope you will as well.

04:35.280 --> 04:54.320
Sal, can I start off by asking you a question that is peripherally related to the book, but you do

04:54.320 --> 05:00.240
mention this towards the end of the book, which is there was one line that I was curious about

05:00.240 --> 05:05.760
and it was like a personal thing, but you brought it up in the book. Sure. So you mentioned that you

05:05.760 --> 05:10.560
thought your dad, who you didn't really know, you met him. He left early, your parents separated

05:10.560 --> 05:18.080
when you were very young and you only met him once. He passed away when you were around 14 years old,

05:18.080 --> 05:23.120
but you said he probably suffered from depression and I was curious why you thought that.

05:23.840 --> 05:33.200
You know, I don't have, no one told me that, so I don't have any strong, well, the evidence is

05:34.160 --> 05:41.840
he kind of disappeared and when, the one time I met him when he was, when I was 13,

05:43.200 --> 05:52.720
we briefly went to his place and let's just say it looked like he was down and then it seems to fit

05:52.800 --> 05:59.040
with a lot of the narrative of what we've observed from my end.

05:59.600 --> 06:02.160
What were the circumstances of the visit? Like why did you visit him?

06:02.880 --> 06:12.240
You know, I was 13 years old. I don't remember. If I remember correctly, he had, I guess, a cousin

06:12.240 --> 06:17.440
of mine who I don't know, my father's side of the family that well, a nephew of his, who really

06:17.440 --> 06:24.880
wanted to put him in touch with us again and I forgot all the context. I think we were up in,

06:24.880 --> 06:31.280
he was living in Philadelphia at the time, so we were up in that area anyway and so this cousin,

06:31.280 --> 06:36.720
older cousin than me, you know, probably 20 years older than me, facilitated this, you know, us to

06:36.720 --> 06:40.640
get together and to me and my sister and then we, you know, we spent an evening together.

06:41.520 --> 06:45.760
Well, I was just curious about that particularly since you brought it up in the book, but

06:46.640 --> 06:52.480
look, I've been incredibly impressed with everything you've done. The Khan Academy,

06:53.440 --> 06:59.280
you know, 155 million users, you know, so many people have learned from

07:00.320 --> 07:07.040
the videos on the Khan Academy, the educational style of the Khan Academy and I know people know

07:07.040 --> 07:12.400
the story and it's not central to the book also, but maybe, you know, if you could spend a few

07:12.400 --> 07:17.120
minutes describing how you started this, like it started, apparently, you were, you were tutoring

07:18.000 --> 07:22.800
one of your cousins, Nadia, about math and then other cousins knew, hey,

07:22.800 --> 07:29.520
Sol's available for some free tutoring. We'd, you know, we want to, we want to help and so you

07:29.520 --> 07:36.560
started creating tools and technology and videos and this grew into the Khan Academy.

07:37.200 --> 07:43.120
Yeah, that's generally right. It was back in 2004. I, my original background is technology.

07:43.120 --> 07:47.760
By 2004, I'd gone to business school. I was a year out. I was now working as an analyst at a hedge

07:47.760 --> 07:54.480
fund. I had just gotten married in New Jersey and I was living in Boston and my family from New

07:54.480 --> 07:58.640
Orleans, which is where I was born and raised, were up visiting in the Northeast and they came to,

07:59.280 --> 08:04.320
some of them came to Boston for the July 4th weekend. This was 2004 and just came out of

08:04.320 --> 08:08.800
conversation that my cousin Nadia was having trouble in math. Her mom told me, my aunt,

08:08.800 --> 08:13.680
and that's when I offered to, when I learned more about what was going on with Nadia,

08:13.680 --> 08:20.480
I offered to tutor her and Nadia agreed. And as you mentioned, well, first of all, that tutoring

08:20.480 --> 08:24.960
seemed to work with her. She was struggling with unit conversion, got her caught up even ahead

08:24.960 --> 08:29.120
of her class. And, you know, I joke sometimes I became a tiger cousin at that point. I call up

08:29.120 --> 08:33.840
her school, they let her retake placement exams. It really helped her. Then I started

08:33.840 --> 08:37.760
tutoring her brothers, words, friends, and my family on the free tutoring, as you mentioned. And

08:37.760 --> 08:44.240
before I know it, 10, 15 cousins, family, friends. And I've always been interested in education. So

08:44.240 --> 08:51.280
this wasn't a complete fluke that I was doing this. I'd done tutoring in other times in my life.

08:51.280 --> 08:57.840
And I have always, I had always dreamt of one day starting a school of some kind. So I was always

08:57.840 --> 09:03.120
interested by the problem and I thought I could help my cousins. And I was always interested in

09:03.120 --> 09:07.840
the intersection of, well, if you can solve a problem, can you use technology to help you scale

09:07.840 --> 09:13.280
any solutions that you had? So that was always in the back of my mind a bit. But in 2005,

09:14.080 --> 09:18.800
with that in mind, I did start to make some practice software for these cousins. That was

09:18.800 --> 09:24.720
the first Khan Academy had no videos or anything like that. But it was just to help scale a solution

09:24.720 --> 09:28.400
to a pattern I was seeing. A lot of my cousins just had gaps in their knowledge. They needed more

09:28.400 --> 09:33.760
practice. I as their tutor wanted to make sure that they were getting that practice and I wanted

09:33.760 --> 09:37.920
to monitor it. So that's, that's why I wrote that software. And once again, just as a hobby.

09:37.920 --> 09:43.760
And then in 2006, a friend suggested that I help scale my lessons with videos.

09:43.760 --> 09:49.600
I thought it was, I legitimately thought it was a silly thing to do. I thought it was very low tech.

09:49.600 --> 09:54.240
I thought YouTube was kind of a place for entertainment, not a place for learning.

09:55.120 --> 10:00.480
But I gave that a shot and my cousins famously told me they liked me better on YouTube than in

10:00.480 --> 10:06.240
person. And what they were saying was they liked the pause, the repeat, always accessible, no

10:06.240 --> 10:10.880
embarrassment if they had to review something from before. And so I kept going. And that was

10:10.880 --> 10:14.720
obviously very discoverable by a lot of people as well. So I just kept working on that software

10:14.720 --> 10:21.280
and kept working on those, those, those videos by 2008, 2009. That's where my brain was focusing

10:21.280 --> 10:26.560
most of the time. And so my wife and I looked at our finances. We had some money saved up for a

10:26.560 --> 10:30.240
down payment on a house. At this point, we had moved out to Northern California. But

10:31.360 --> 10:35.440
you know, we felt like this, there's something happening here. There was about 50 to 100,000

10:35.440 --> 10:42.640
folks using the nascent Khan Academy on a monthly basis. And there were some philanthropists that

10:42.640 --> 10:47.520
were, there were actually both venture capitalists and philanthropists who are already signaling

10:47.520 --> 10:52.000
that they were interested. In fact, the venture capitalists were more interested back then.

10:52.640 --> 10:56.720
But it felt important that this would be a nonprofit organization, set it up mission

10:56.720 --> 11:03.280
free world-class education for anyone anywhere. And yeah, 2009, I took the plunge to try to get that

11:03.280 --> 11:09.840
philanthropic support to become a real organization. It was a tough year to be very clear, probably the

11:09.840 --> 11:14.080
most stressful year of my life. Our first child had been born and I'd given up a good career.

11:14.080 --> 11:19.120
But by 2010, we had our first real support. And you know, everything we've been doing since then

11:19.120 --> 11:24.320
has really been that same pattern. How do we scale up that same personalization, that same

11:24.320 --> 11:29.360
student-centered learning that you could do when it was just myself working with Nadia. And, you

11:29.360 --> 11:34.160
know, most of our history has been improving on the software, creating more and more content,

11:34.880 --> 11:40.320
exercises, videos, articles, teacher tools, working with school districts. And obviously,

11:40.320 --> 11:43.440
more recently, it's been leveraging artificial intelligence on top of that.

11:44.320 --> 11:50.320
Right. So your new book, Brave New Words, how AI will revolutionize education and why that's a

11:50.320 --> 11:57.520
good thing. It's a really interesting book because on the one hand, your book is what the title says,

11:57.520 --> 12:03.760
how AI will revolutionize education and you talk about developments in AI, developments that you've

12:03.760 --> 12:09.840
contributed to AI. You were an early user tester and so on of all the versions of

12:09.840 --> 12:19.840
ChatGPT. But the book is also, it almost could be titled, What Everyone is Afraid of in AI

12:19.840 --> 12:27.280
and How We Can Solve Each Fear. And I noticed that is the flip side of AI. I was at a dinner

12:27.280 --> 12:32.640
recently where there was a bunch of academics and journalists and scientists. It was all in the

12:32.640 --> 12:39.200
science domain. And every single one of these scientists or writers of science were really

12:39.200 --> 12:46.720
afraid of AI. They thought AI was dangerous. There was no positive thing said about AI except

12:46.720 --> 12:53.280
when I pointed this out to all of them. Why do you think so many people are afraid of AI? And then

12:53.280 --> 12:55.760
I want to hit how you address some of these things in the book.

12:58.400 --> 13:06.160
I think AI is, it's interesting because it's especially, it's especially threatening to folks

13:06.240 --> 13:13.120
who have always defined their identity by their ability to write and speak and think original

13:13.120 --> 13:19.440
thoughts. So it's not a coincidence that the intelligentsia, so to speak, are the ones that

13:19.440 --> 13:26.240
are probably most concerned about this. And it's not to mean that these aren't legitimate concerns

13:26.240 --> 13:32.720
or a lot of them aren't legitimate concerns. But I think it is affecting folks with education,

13:32.720 --> 13:41.920
folks who write. It gets awfully close to home in terms of identity. And so I think it immediately

13:42.560 --> 13:46.800
puts people into a little bit of a defensive posture and a little bit of a fear-based posture.

13:47.440 --> 13:52.240
And once again, I can't completely predict the future. We even saw that when we first got access

13:52.240 --> 13:57.600
to the technology before the rest of the world did. And I would say half of our team was really

13:57.600 --> 14:02.960
excited about it and want to go all in. And the other half had a lot of this trepidation. And

14:04.000 --> 14:07.680
to your point, maybe your title of the book would have been a better one because you're

14:07.680 --> 14:14.480
right. It really is this pattern that I probably have always tried to lean in this way, but it's

14:14.480 --> 14:19.840
definitely accelerated with AI, which is, all right, we should write down fears. One should not

14:19.840 --> 14:25.280
ignore fears and risks. But fears and risks are not reasons to not try to move forward and make

14:25.280 --> 14:33.920
positive use of it. There are things to address and to deal with so that you can have a positive

14:33.920 --> 14:40.400
outcome. Yeah, I mean, obviously the very first thing that comes up when you talk about AI and

14:40.400 --> 14:46.480
education, and I have all my kids are basically college age or graduate school age. The first

14:46.480 --> 14:54.880
thing that comes up is cheating. And I'll give a just transparent experience

14:55.360 --> 15:02.480
one daughter was in the final stages of her finals on the year. And she had like one day

15:02.480 --> 15:07.920
to write an essay. And she hadn't even read the text she was supposed to be writing the essay

15:07.920 --> 15:16.080
about. And I said, look, there's this thing called chat GPT, just cheat and get it done and graduate.

15:16.080 --> 15:21.120
Just do it. And I don't know if she followed my advice or not, but that was my advice because I

15:21.520 --> 15:25.680
for me it was more important for her to graduate than for her to learn this one thing.

15:26.240 --> 15:33.120
But that is a big concern of teachers and parents and everything because a lot of people don't

15:33.120 --> 15:37.040
care about their education or they don't think that their college or high school or whatever is

15:37.040 --> 15:43.840
giving them a good education. So they're willing to use it to cheat. Yeah, it's a real thing. And

15:44.400 --> 15:48.320
you know, what I write about in the book is I always like to start from first principles,

15:48.320 --> 15:52.720
like, okay, you know, what was the state of things even before chat GPT came on to the scene?

15:52.720 --> 15:58.000
And it didn't take long to realize that cheating was already pretty rampant. And if anything,

15:58.000 --> 16:03.200
there does seem to have been a cultural shift even since you or I were in college in terms of

16:03.200 --> 16:09.040
probably more acceptance of cheating than ever before. And once again, before AI existed,

16:09.040 --> 16:15.760
probably the internet software tools, their services that are happy to write essays for you

16:15.760 --> 16:20.720
or do other types of problem sets for you, their quasi legitimate publicly traded companies that

16:20.720 --> 16:25.600
will help you do your homework and help is I'm saying it very euphemistically, they'll essentially

16:25.600 --> 16:34.400
do your homework for you. So this existed well before. And so I think the question is, in this

16:34.400 --> 16:42.240
world, what are we hoping to get out of students when they do these types of tasks? And if part

16:42.320 --> 16:46.160
of it is to make sure that it is their work. And in the book, I talk about, look, there's

16:46.160 --> 16:50.960
certain cases where you probably want students to use the tools. In fact, these tools are going

16:50.960 --> 16:54.960
to be part of their future. But there are certain cases where you definitely want to make sure that

16:54.960 --> 17:00.960
it's the students own work, how you can, how you can address it. And you know, the AI actually

17:00.960 --> 17:06.240
isn't, it can be part of the problem, obviously, with things like chat GPT. But in a lot of ways,

17:06.240 --> 17:11.120
I'm optimistic that it can be, it can be a very big part of the solution that addresses not just AI

17:11.120 --> 17:16.640
cheating, but cheating in general, where students won't have the work done by the AI, but the AI

17:16.640 --> 17:22.800
can be their coach, an ethical tutor, ethical writing coach, and then it can make transparent

17:22.800 --> 17:28.560
the process to the teacher. So the teacher doesn't just get the essay, they get the whole transcript

17:28.560 --> 17:32.000
of how the student worked on it and the AI's analysis that it's similar to the student's

17:32.000 --> 17:36.400
other writing or that they worked on it for four hours or they had trouble with the thesis statement

17:36.400 --> 17:41.920
initially, but eventually got there and be able to give the teacher insights across the whole

17:41.920 --> 17:45.920
classroom that, look, 15 of your kids are having trouble with thesis statements. Here's a lesson

17:45.920 --> 17:50.560
plan that you might want to go on, go and do. So I'm optimistic on that front.

17:55.440 --> 18:00.080
Take a quick break. If you like this episode, I really, really appreciate it. It means so much

18:00.080 --> 18:06.480
to me. Please share it with your friends and subscribe to the podcast. Email me at AltaturaGmail.com

18:06.480 --> 18:22.400
and tell me why you subscribed. Thanks. I have to say Airbnb has changed my life. I just love

18:22.960 --> 18:28.240
staying in Airbnb's. Like in about a month, I'm going to Cocoa Beach, which is right next to Cape

18:28.240 --> 18:32.880
Canaveral. I'm going to watch some rocket launches. I'm going to, of course, be staying in a very nice

18:32.880 --> 18:39.600
Airbnb on the beach. And it's just such a great experience. Like the whole world is available

18:39.600 --> 18:49.040
to us now because of Airbnb. But whenever I'm at an Airbnb, I always realize, you know, the home

18:49.040 --> 18:56.160
that I left to come to this Airbnb, I could be making money on that right now by hosting and

18:56.160 --> 19:02.640
being an Airbnb myself. So, and I've known people, I had a friend who basically,

19:03.440 --> 19:09.680
you know, made a living from turning his home into an Airbnb. So if you have a home, but you're not

19:09.680 --> 19:15.440
always at home, you do have an Airbnb there. And it can easily fit into your lifestyle,

19:15.440 --> 19:21.920
and it's a great way to earn some money. Your home might be worth more than you think.

19:21.920 --> 19:26.800
Find out how much at Airbnb.com slash host.

19:33.280 --> 19:39.040
The famous Abraham Lincoln quote says, good things come to those who wait. I wonder,

19:39.040 --> 19:41.520
did he really say it? Jay, did he really say that? Can you look that up?

19:42.240 --> 19:45.840
Regardless of who said it, that's only part of the quote. The full quote is,

19:45.840 --> 19:50.480
good things come to those who wait, but only the things left by those who hustle.

19:51.120 --> 19:56.560
Well, if you're a business owner and want the best people on your team, the same applies.

19:57.520 --> 20:03.760
And listen, I've interviewed 1500 people now and a lot of entrepreneurs. I can safely say

20:04.400 --> 20:11.840
the one thing consistent among all entrepreneurs and CEOs, the successful ones, is that it's all

20:11.840 --> 20:17.760
about the people you surround yourself. If you hire well, you're going to have a great business.

20:17.760 --> 20:24.080
And you know, thankfully zip recruiter puts the hustle in your hiring. So you find qualified

20:24.080 --> 20:29.360
candidates fast. This is so important. And I want you to try it. You could try it as a potential

20:29.360 --> 20:34.640
employer or employee. You could try it for free at ziprecruiter.com slash James,

20:34.640 --> 20:39.040
zip recruiters smart technology finds top talent for your roles right away.

20:39.040 --> 20:43.120
Immediately after you post your job, if you're hiring, zip recruiters matching technology

20:43.120 --> 20:48.640
starts showing you qualified people for it. And I will tell you that I signed up on zip recruiter

20:48.640 --> 20:52.400
as a potential employee. You know, I just wanted to see how it works. And right away,

20:52.400 --> 20:57.280
it started matching me with really amazing potential employers. So give it a try at zip

20:57.280 --> 21:02.960
recruiter.com slash James, let's zip recruiter give you the hiring hustle you need. See why four

21:02.960 --> 21:07.280
out of five employers who post in zip recruiter, get a quality candidate within the first day.

21:07.280 --> 21:13.280
Just go to zip recruit.com slash James to try it for free. Again, that's zip recruit.com slash

21:13.280 --> 21:25.840
James zip recruiter, the smartest way to hire. Right. So, and this isn't in general,

21:25.840 --> 21:31.920
like a theme that runs throughout is that viewing AI or, or, or chat GPT like programs

21:31.920 --> 21:40.160
as a collaborator or a partner rather than as a secret weapon is kind of the basic solution to

21:40.160 --> 21:47.280
all of these fears. So, so for instance, teaching doesn't go away. But hey, if just like with the

21:47.280 --> 21:51.680
kind of kind of people were able to watch the video. So now the T and learn basic math lessons.

21:51.680 --> 21:56.960
So now the teachers can focus on more more discussions and interesting topics in the

21:56.960 --> 22:03.280
classroom itself. So, so for instance, if you, if the teacher knows the student is using chat GPT

22:03.920 --> 22:09.600
to answer questions about the great Gatsby, that might actually be a benefit to the educational

22:09.600 --> 22:14.960
experience. Yes and no. I think the key is that everyone is going into it with eyes wide open

22:14.960 --> 22:18.240
that the teachers and the educators know why they're asking students to do things.

22:18.880 --> 22:24.480
They're very clear about certain tasks where it will be pedagogically valuable to use

22:24.560 --> 22:29.200
the chat GPTs of the world and other things where you don't want to use them. But I want to be

22:29.200 --> 22:36.400
very clear about use. There is the use of say a general AI platform like chat GPT that would be,

22:36.400 --> 22:42.480
you know, that it could be used to do very productive things like do research, help understand a

22:42.480 --> 22:48.240
concept. But those also could be used to write your essay for you or do things that a lot of

22:48.240 --> 22:52.240
educators would find, hey, that's probably undermining what I was trying to get out of this.

22:52.240 --> 22:57.040
There's other use cases of generative AI and this is where ConMigo, which right now is built

22:57.040 --> 23:03.680
primarily on GPT-4, but it's a different application than chat GPT. But that's built explicitly to

23:03.680 --> 23:09.280
support students and teachers in a, in a education framework. So it won't cheat, but it will

23:09.280 --> 23:14.480
socratically work with the students. The bottom line is, I think we're entering this phase where

23:15.360 --> 23:19.600
educators have to be more explicit about why they're giving certain tasks and

23:20.400 --> 23:25.280
also explicit on the types of tools that are acceptable and aren't, probably with some

23:26.320 --> 23:31.040
light oversight, potentially AI empowered oversight of what the students are doing.

23:31.040 --> 23:36.080
And it's going to be more and more on the students also to be very clear of like, hey,

23:36.080 --> 23:38.960
this is not something that I should do and this is something I should do, but also know

23:38.960 --> 23:43.200
that they're going to be held accountable by it, that there are, that ConMigo, what we're doing

23:43.280 --> 23:49.840
at Khan Academy, there are tools now to monitor what the student is doing, make sure it is their

23:49.840 --> 23:55.520
own work, when the teacher wants to make sure that it's the students own work. Although it seems

23:55.520 --> 24:03.680
like every time there's an attempt to, oh, this is definitely created by AI, humans are smarter

24:03.680 --> 24:08.160
in this sense. They're always going to develop ways to override whatever tools are being used to

24:08.160 --> 24:14.560
detect AI usage and homework. Yeah. Anyone who tells you that they have some type of an algorithm

24:14.560 --> 24:20.640
or watermarking technology or statistical algorithm, whatever it might be that can detect AI generated

24:20.640 --> 24:31.040
work is either significantly exaggerating or lying to you. There have been plagiarism detectors,

24:31.040 --> 24:38.400
but for the most part, what AI is generating is novel, is novel text. So it's very hard to detect.

24:38.400 --> 24:43.600
Now, the way that some teachers have detected it, just with their spider senses, they have seen

24:44.320 --> 24:49.440
work that just seems different than what the student has turned in before, or it just seems

24:49.440 --> 24:55.920
surprisingly cogent, or maybe a little bit bland compared to what a typical people would write.

24:55.920 --> 25:00.320
Now, even those cases is usually because the student didn't use the AI artfully enough.

25:00.880 --> 25:05.440
That if they really tweaked it a little bit, tweaked their prompts, maybe adapted some of

25:05.440 --> 25:08.800
what the AI was writing to make it a little bit more personal, it would have been very hard to

25:08.800 --> 25:16.000
detect. So our strategy here isn't to try to magically just read a paper and say this was

25:16.000 --> 25:22.720
written by an AI or human or 5050 or some other percentage in between. It's to make the process

25:22.720 --> 25:31.120
transparent to the educator. So with Conmigo, we aren't saying, oh, we ran some algorithm and

25:31.120 --> 25:36.720
there's an 80% chance this is AI written. Instead, we tell the teacher, here's the transcript of the

25:36.720 --> 25:43.600
student working with our AI, working with Conmigo on their essay. It took them four hours. Here's

25:43.600 --> 25:47.520
the conversation. Here's a synopsis of the conversation. They had trouble with the thesis

25:47.520 --> 25:53.600
statement. We worked on outlining in this way, etc. Maybe a comparison to previous writing that

25:53.600 --> 25:58.480
it seems similar. So it's not trying to just detect based only on the output. It's more of giving a

25:58.480 --> 26:04.640
very strong indication based on making the entire process transparent. If the student goes to chat

26:04.640 --> 26:11.440
GPT or gets their sister to write the paper and it just shows up inside of Conmigo, Conmigo is

26:11.440 --> 26:15.520
going to tell the teacher, hey, this just showed up. We didn't work on this. You should look into

26:15.520 --> 26:19.120
it. And by the way, it's very different than what the student has written before. I think that's the

26:19.120 --> 26:26.720
kind of lens that we need to really not only police cheating, but I don't want to make this just about

26:26.720 --> 26:31.680
policing and making it punitive. I also think this is how we're going to better support students and

26:31.680 --> 26:36.000
teachers because the students going to be much more supported as they write and the teacher is

26:36.000 --> 26:40.960
going to get many more insights about where the students strengths and weaknesses are in their

26:40.960 --> 26:50.400
writing. Yeah. So in that sense, the transparency that, hey, I'm using an AI tool and here's the

26:50.400 --> 26:55.280
final output. Part of the final output is the essay I came up with. Part of the final output is

26:55.280 --> 27:01.440
Conmigo's like your AI tool, Conmigo's analysis of our sessions together. That's right.

27:02.720 --> 27:08.240
I think that I think that's very valuable. I think that's I think this idea of AI as collaborator

27:08.240 --> 27:16.160
is an important reframing of the role of AI in our lives where just like we have a calculator now

27:16.160 --> 27:22.800
to do math equations. Oh, I have kind of an intelligence assistant to help me with problems

27:22.800 --> 27:26.960
so I could really focus on the bigger problems. That's right. You know, what we've been doing

27:26.960 --> 27:33.120
when we do professional development with teachers is we tell them, look, imagine if

27:33.920 --> 27:39.040
all of a sudden your school district discovered a few billion dollars and they want to use that

27:39.040 --> 27:46.000
money to hire three or four super hardworking teaching assistants for you that will help you

27:46.000 --> 27:51.600
do lesson plans, help you grade papers, help you write progress reports. They'll also analyze what

27:51.600 --> 27:55.760
your students are doing on a regular basis to let you know. And by the way, they're also going to

27:55.760 --> 28:00.400
be able to tutor the students. They're available 24 seven. These are amazing teaching assistants

28:00.400 --> 28:05.200
and they'll be able to connect what you're doing in class to where the students need help and vice

28:05.200 --> 28:11.520
versa. Every teacher on the planet would say, yes, sign me up for that. And that I truly believe

28:11.520 --> 28:17.200
that's where it's going. This isn't about replacing teachers. Now, one thing we've always said at Khan

28:17.200 --> 28:22.480
Academy, our ideal is let's raise the ceiling when a student does have access to a reasonably good

28:22.480 --> 28:28.560
classroom and educators. But there are cases where students don't have access to a classroom.

28:29.360 --> 28:33.840
It could be a developing nation. There's no school at all. It could be even in the U.S.

28:33.840 --> 28:38.080
you're a rural part of the world or a country where there's not a calculus class within an hour

28:38.640 --> 28:44.960
hour's drive. Then we want Khan Academy and Khan Mego by extension to help raise the floor

28:45.520 --> 28:48.400
so that you can get more supports when there aren't any others.

28:49.680 --> 28:53.920
You know, you talk about teachers being worried about they're going to be replaced by Ann. I

28:53.920 --> 28:58.240
think this is happening in a lot of professions right now. And that's part of this. There's this

28:58.240 --> 29:03.680
existential fear that we're all, you know, horse and buggy drivers and we're not going to need

29:03.680 --> 29:10.960
it anymore once the cars are around. And so whether it's, you know, writers, teachers, other

29:10.960 --> 29:19.920
professionals and so on. But maybe we don't need teachers. Maybe AI and Khan Academy with Khan Mego

29:19.920 --> 29:24.640
can do the job. What is the role of teaching right now?

29:25.280 --> 29:29.360
I'm not saying what I'm about to say just because it's the right thing to say. It's

29:29.360 --> 29:34.160
what I genuinely believe. I wouldn't be saying it otherwise. I would just stay quiet if it wasn't

29:34.160 --> 29:43.760
what I genuinely believe. I think any role that is about the human connection, about the human

29:43.760 --> 29:51.520
motivation is going to be not only in very good shape in an AI world, but those are going to

29:51.520 --> 29:58.400
be the roles, the jobs, the careers that are most enhanced in an AI world. So even though

29:58.400 --> 30:04.800
historically, many people associated teaching with, oh, I'm going to write a lesson plan,

30:04.800 --> 30:08.400
then I'm going to deliver this lecture, then we're going to have a quiz every two weeks,

30:08.400 --> 30:12.800
and then I'm going to grade those quizzes, and then we're going to rinse and repeat for two weeks.

30:14.240 --> 30:20.480
Any great teacher will tell you that's actually not their job. What's actually their job is on a

30:20.480 --> 30:27.440
very human level to connect with their students, either individually in small groups as a whole

30:27.440 --> 30:32.960
class, to motivate them to see the wonder in the world, to make sure that these students feel seen

30:34.240 --> 30:40.240
and supported. And then on top of that, the teachers have to grade papers, write lesson plans,

30:40.240 --> 30:47.920
progress reports, IEPs, prepare them for standardized tests. And because we're asking so

30:47.920 --> 30:53.760
much of teachers and some of that latter half of stuff is more tangible and more measurable,

30:53.760 --> 30:59.840
it's actually squeezed out a lot of teachers' opportunities to do those very human things.

30:59.840 --> 31:04.000
Anyone who goes into the teaching profession, they dream of these moments where they're able

31:04.000 --> 31:09.200
to have some time in a small group with some students or give that one student who was really

31:09.200 --> 31:12.880
down and out of pep talk, and it changes their life forever. And it will change their life forever.

31:12.880 --> 31:20.240
I think in my 12 years, 13 years in the K-12 system, I remember probably every moment

31:20.240 --> 31:25.120
when a teacher did single me out out of the 30 kids and say, hey, Sal, can I talk to you about

31:25.120 --> 31:30.080
something? I really liked what you did, or I really didn't like what you did. It affected me,

31:30.080 --> 31:36.480
it changed who I am. And I think that's what, or a teacher ran a Socratic conversation with 10 of

31:36.480 --> 31:42.000
us as opposed to all 30 at the same time, or we had a field trip where we ran a simulation. And

31:42.000 --> 31:46.080
those are the things that I don't think the AI is going to be able to drive,

31:46.080 --> 31:51.600
but I think the AI will be able to support it. But once again, freeing up the teacher to do more

31:51.600 --> 31:58.880
of that. The jobs that I think will be under threat with AI, or there will be fewer of them,

31:59.600 --> 32:05.360
are the ones that you are, if great writers should not feel threatened, but if you're the

32:05.360 --> 32:11.600
person who writes the fairly generic text every day on the news sites about why the stock market

32:11.600 --> 32:19.120
went up or down. I'm surprised if those aren't already written by AIs. I think a lot of them

32:19.120 --> 32:22.320
actually are. They feel like it. They feel like they've been written by AIs for 10 years.

32:24.160 --> 32:31.440
I think if you are, if I'm dealing with the education system, the registrar's office,

32:31.440 --> 32:36.320
I think is going to be, you're going to see a lot of automation there. But once again,

32:37.280 --> 32:44.320
as just a citizen of the world, I think the more resources that we can save on the non-student

32:44.320 --> 32:49.840
facing thing and put it onto the student facing thing, that's a good thing. If you look at school

32:49.840 --> 32:57.760
districts like New York City, they spend an average of $40,000 per student per year. There are 25

32:57.760 --> 33:02.800
students in an average classroom in the New York City Department of Education. So that means if you

33:02.880 --> 33:08.080
just took $40,000 and multiplied it by those 25 students, that means that there's a million dollars.

33:08.720 --> 33:14.960
I guarantee you that no matter how good the teacher's benefits, pensions, et cetera,

33:14.960 --> 33:20.320
they're getting a small fraction of that million dollars. Maybe a very senior teacher with a great

33:20.320 --> 33:24.800
pension, et cetera, maybe with great health insurance, maybe it's $150,000. If you put all

33:24.800 --> 33:31.040
the benefits in there, approaching $200,000, that's very, I think I'm already being overly,

33:32.000 --> 33:37.680
no one's really making that much. So where are all the other resources going? It's actually

33:37.680 --> 33:42.720
not going through the real estate in most cases. Where is it going? And it's going to all of this,

33:42.720 --> 33:48.240
let's call it back office, administrative stuff that really isn't moving the dial with students.

33:48.240 --> 33:53.200
And actually, I don't write too much about that aspect of it. That's probably less interesting

33:53.200 --> 34:00.640
for a lot of folks. But yeah, register's office, scheduling, just a lot of the administrative

34:00.640 --> 34:03.200
things I think will hopefully get much more streamlined.

34:05.200 --> 34:10.720
You know, what about the current education system is an antique at this point? I mean,

34:10.720 --> 34:17.760
I feel like the current, roughly the current education system's been around for 200 or so years

34:17.760 --> 34:23.920
that you go to a school, you go to a location where there's a bunch of subjects taught throughout

34:23.920 --> 34:28.960
the day. So every day it's like six different subjects. You go from class to class to class

34:29.040 --> 34:34.960
and you get homework. At the end you get tested. So that's roughly the structure of the modern

34:34.960 --> 34:38.560
education system. And what part of that you think is outdated now?

34:39.440 --> 34:43.040
Yeah. And you know, my first book that I had written back in 2012, One World Schoolhouse,

34:43.040 --> 34:49.200
it kind of goes into how did we end up with the system? And it really does, it's not a coincidence

34:49.200 --> 34:56.240
when you say it's roughly 200, 250 years old. It came out of the Industrial Revolution. And for

34:56.240 --> 35:03.440
the most part, it was a very utopian idea. For most of human history, we learned through apprenticeship,

35:03.440 --> 35:09.360
we learned through following around, learning from our cousins or our parents how to hunt or how

35:09.360 --> 35:16.320
to cook. Once society became more advanced and more specialized, we would hang out with the

35:16.320 --> 35:22.720
blacksmith or we would hang out with the, I don't know, the carriage repair guy, whatever it would

35:22.720 --> 35:30.480
be to learn or even things like law and medicine was an apprenticeship until about 200, 250 years

35:30.480 --> 35:36.160
ago. But the issue with a lot of these is that they didn't scale. If you go back 300 years ago,

35:36.160 --> 35:41.600
very, even in more literate parts of the world, you only had a 30 or 40% literacy rates. Most

35:41.600 --> 35:47.760
of the world, you only had about a 10 or 15% literacy rate. And so when we had the Industrial

35:47.760 --> 35:54.160
Revolution, we had a more abundant society because of technology. And a lot of these societies, and

35:54.160 --> 35:58.400
it's not a coincidence that these were some of the first societies to develop a middle class,

35:59.120 --> 36:05.840
the UK, what would eventually become Germany, Japan, the United States, they were the first

36:05.840 --> 36:11.680
to say, hey, let's have a mass public education system. Very utopian idea. But they said the only

36:11.680 --> 36:16.240
way we can afford to do that, the only way we can scale it is by leveraging the techniques of the

36:16.240 --> 36:21.200
Industrial Revolution. We're going to bat students together, usually by age, move them together at

36:21.200 --> 36:26.480
a set process, literally a bell will ring every hour. I mean, that directly comes from a factory.

36:26.480 --> 36:31.280
We're going to have standards. We now take standards for granted in education, but this was

36:31.280 --> 36:40.240
a thing that came out of mass production in a factory. We will assess periodically. But we're

36:40.240 --> 36:45.440
not going to slow down that assembly line. Instead, we're going to assess and some of the quote

36:45.520 --> 36:50.480
product is going to be said, okay, this is the product that's going to be the

36:50.480 --> 36:55.040
doctors, lawyers, engineers, and some of it, well, the information or the knowledge doesn't seem to

36:55.040 --> 37:01.840
be sticking. Well, these will be the less skilled laborers. So it kind of worked. We could talk about,

37:02.560 --> 37:08.480
was it fair for folks? You could have been, and people have been talking about the inequities

37:08.480 --> 37:13.760
of tracking for decades. When you're 12, something's not sticking and all of a sudden you're tracked

37:13.760 --> 37:18.480
into a slower track and now all of a sudden no one expects you to go to college and people expect

37:18.480 --> 37:24.320
you to be a lower skilled laborer versus becoming a doctoral lawyer. Is that fair? That's a very

37:24.320 --> 37:31.520
big question. I don't think it is, but it kind of worked for society in that we didn't need a huge

37:31.520 --> 37:36.560
number of people in the knowledge economy. And we did need a lot of people who are in either the

37:36.560 --> 37:42.640
middle income or lower income jobs, a lot of the mid-skilled or lower skilled labor. We did need

37:43.200 --> 37:48.960
it. But if you imagine the world that we are going into, we know what's going to happen to the

37:48.960 --> 37:53.760
less skilled jobs, you know, or even the mid-skilled jobs. Obviously, we're talking about artificial

37:53.760 --> 38:00.000
intelligence, which is all about kind of that mid-skill processing of information. Everyone I

38:00.000 --> 38:04.320
talk to robotics is not far behind. I think a lot of folks are saying in the next five or ten years,

38:04.320 --> 38:10.640
we're going to have a chat GPT type moment with robotics as well. So that also means that some

38:10.640 --> 38:16.080
of the lower or mid-skilled labor is also going to be automated, probably in the next 10 or 20

38:16.080 --> 38:20.720
years. And so where does that leave us? Well, it leaves the high-skill labor, the knowledge economy,

38:20.720 --> 38:28.160
being a researcher, being an engineer, being an entrepreneur is where all of the productivity,

38:28.160 --> 38:33.040
all of the wealth will accrue there. And so as a society, we have to decide, are we okay with

38:33.040 --> 38:37.200
only right now 10% of people participate there? And then that's not a stable society, or we're

38:37.200 --> 38:41.120
going to have to do redistribution, which to me is still pretty dystopian because people want to

38:41.120 --> 38:46.720
have a sense of purpose. Or do we leverage the technologies that we have to get as many people

38:46.720 --> 38:51.760
as possible into the top of that pyramid to be in the knowledge economy? Instead of having a labor

38:51.760 --> 38:56.320
pyramid, you can have an inverted pyramid where most people are able to be in that knowledge

38:56.320 --> 39:03.200
economy. And so I think that's where the imperative is. So how do you start making those changes in

39:03.200 --> 39:08.560
the educational system? And also, I think there's some question as to whether people effectively

39:08.560 --> 39:14.640
learn by taking six different subjects in a day. Like multi-tasking learning has been shown to me,

39:14.640 --> 39:18.560
not the most effective way to learn. And you even mentioned this in the book, that the more one-on-one

39:18.560 --> 39:25.920
more immersion is probably better for education. Yeah. The core ideas, and this is something I've

39:25.920 --> 39:31.200
been preaching well before artificial intelligence came on the scene, is instead of a traditional

39:31.200 --> 39:36.800
model, what we hold fixed is how long you get to work on something because that assembly line keeps

39:36.800 --> 39:41.360
moving. And what's variable is how well you learn it. And we get that in the form of grades. You

39:41.360 --> 39:46.880
and I take a class together, we're in algebra for this term, you got an A minus, I got a C plus.

39:46.880 --> 39:51.360
All right, it goes in my permanent transcript and we move on. Somehow expecting me that I got to,

39:51.360 --> 39:55.280
you know, expecting someone who got the C plus to now understand algebra two or understand

39:55.920 --> 40:00.800
something more advanced. And so what I've all, what I've been advocating for the last 10 years

40:01.520 --> 40:06.960
or more is let's do it the other way around. What should be, what we should, what should be variable

40:06.960 --> 40:11.520
is when and how long you work on something and what's fixed is how well you learn it. And that's

40:11.520 --> 40:16.880
what a personal tutor, when Aristotle was Alexander the Great's tutor, I'm sure that's what he did.

40:16.880 --> 40:22.640
If young Alexander hadn't mastered a concept yet, he would have slowed down a bit or, you know,

40:22.640 --> 40:26.800
given him a second chance to take that test to make sure that he really mastered whatever,

40:26.800 --> 40:32.000
military strategy or, you know, governance, whatever, whatever was the, whatever was the

40:32.000 --> 40:38.800
topic for the day. Now, if I said this, say 30 years ago, people would have rolled their eyes

40:38.800 --> 40:43.840
or say, well, okay, it's easy for you to say, but unless you have a lot of resources to provide

40:43.840 --> 40:48.240
that level of personalization, there's no way you can, you can have 30 different students learning

40:48.240 --> 40:54.640
at 30 different paces. And if one student is falling a little bit behind for, for them to

40:54.640 --> 41:00.640
have a second chance to take that test, that's just logistically impossible to do. Now, what's

41:00.640 --> 41:05.040
changed over the last 30 years, even before artificial intelligence is you have tools like

41:05.040 --> 41:10.080
Khan Academy, you have software that can let every student practice at their own time and pace,

41:10.080 --> 41:14.800
give teachers real time information. If a student needs to refresh their knowledge on something,

41:14.800 --> 41:19.360
they could watch an on-demand video, they could read an article, now they can have a conversation

41:19.360 --> 41:24.480
with a artificially intelligent tutor. And once again, that tutor is also in contact with the

41:24.480 --> 41:30.560
teacher. So constantly guiding the teacher on how they can be a conductor of this class of 30,

41:30.560 --> 41:34.880
where they don't have to make every person play the same thing at the same time, regardless of how

41:34.880 --> 41:41.200
bad the quality or how, how, how, how not ready for it they are. Now you can, you can, you can

41:41.200 --> 41:47.280
personalize a lot more. And so, and a corollary to that is, you know, I talk about mastery learning,

41:47.280 --> 41:52.160
which is, if you haven't learned it well yet, keep trying. And once again, this is how we've,

41:52.160 --> 41:56.000
we've always instilled do, if you want to be an Olympic athlete, if you want to be a

41:56.000 --> 42:00.720
musician, you are doing mastery learning. We just don't do it in our school system,

42:00.720 --> 42:05.200
and you see the outcome differences between how good people can get us if they have a personal

42:05.200 --> 42:09.920
coach. But, but a corollary to mastery learning is what I would call competency-based learning.

42:09.920 --> 42:14.480
Right now, our entire credentialing system is based on seat time, for the most part.

42:14.480 --> 42:19.760
Did you sit in a chair for 12 years, and kind of do what you were told, even though you don't

42:19.760 --> 42:23.680
really understand a lot of it? Okay, we'll give you something called a high school diploma.

42:23.680 --> 42:30.720
Did you sit in a chair for 12 hours this week for a term? Okay, we'll give you the 12 credit

42:30.720 --> 42:34.880
hours or however they want to account for it for that course, and you kind of learned it.

42:34.880 --> 42:39.360
We know in reality, very few people actually retain most of what they quote are exposed to

42:39.360 --> 42:45.520
in school. 60, 70 percent of kids going to community colleges have to get remediation

42:46.160 --> 42:49.920
not even at a high school level, essentially at a seventh grade level. So, they sat in these

42:49.920 --> 42:54.480
classes called algebra one, algebra two, trigonometry, some of them even take calculus,

42:54.480 --> 42:57.440
and the colleges are saying, you're not even ready to learn algebra yet,

42:57.440 --> 43:02.000
go back, we're going to work on your pre-algebra. So, a corollary to personalization and mastery

43:02.000 --> 43:06.560
learning is moving to a competency-based credentialing system. If you know it,

43:06.560 --> 43:10.160
take some type of a rich assessment and we'll give you credit, even if it only took you two days

43:10.160 --> 43:14.480
to learn it, but if you haven't learned it yet, that's cool too. Here are some resources to

43:14.480 --> 43:18.000
keep learning. Come back in a month, come back in two months, come back in a year,

43:18.000 --> 43:31.680
and I'll give you a second chance to actually learn the material.

43:32.320 --> 43:41.920
There are over 75 million monthly 2B viewers. That's more people than there are influencers

43:41.920 --> 43:48.720
on the internet, which means 2B is more popular than sponsored posts for digestive enzymes and

43:48.720 --> 43:55.600
high coverage foundation, more popular than soft launching your boyfriend, more popular

43:55.600 --> 44:00.480
than making boomers explode with rage when you tell them how much you make on a single post.

44:00.480 --> 44:05.600
2B, it's more popular than influencers. See you in there.

44:30.480 --> 44:47.360
So, now let's bring in AI. How would you use AI to who would decide, would it be the student or

44:47.360 --> 44:54.000
the teacher or both or the AI, who would decide like, oh, James needs a little more work on his

44:54.000 --> 44:59.280
algebra too, as opposed to Sal who got an A plus on every test. Who would decide how I,

44:59.920 --> 45:04.880
you know, how much more time do I need and what would I be assigned to do? Like would the AI give

45:04.880 --> 45:09.920
me tests or teach me or like what would happen? It's a little bit of all of the above where

45:09.920 --> 45:14.880
even before we had artificial intelligence, we have these classrooms where students are working

45:14.880 --> 45:20.240
on Khan Academy and we were able to give signals to teachers as to which students are moving ahead

45:20.240 --> 45:23.440
and we want to encourage them to do so, where students are on track and where students are

45:23.440 --> 45:28.320
maybe falling behind. But we did leave it all, you know, we did professional development for

45:28.320 --> 45:33.040
teachers on how they might want to navigate that. Hey, for the kids who are ready to move ahead,

45:33.040 --> 45:37.440
let them move ahead for the kids who are behind, why don't you do a focused intervention with those

45:37.440 --> 45:42.880
six or seven kids. And a lot of teachers were doing that type of thing, but you can imagine it can get

45:42.880 --> 45:47.040
pretty complex and pretty hard, even if you have some of these software tools.

45:47.040 --> 45:50.960
What we're able to do now with the artificial intelligence is it really is acting like a data

45:50.960 --> 45:55.520
analyst and or teaching assistant for these teachers. So, instead of a teacher every night

45:55.520 --> 46:00.640
having to look at a spreadsheet like dashboard and say, okay, these are the kids who are struggling,

46:00.640 --> 46:04.240
let me break them out or let me do another lesson plan, which is a lot of work for the teacher,

46:04.960 --> 46:09.440
they can just ask the AI what's going on. And the AI says, look, here's what's going on,

46:09.440 --> 46:14.160
these are the kids on track here, you know, if we do a differentiated lesson plan tomorrow,

46:14.160 --> 46:19.600
I recommend these kids work on this task while you spend the first 20 minutes with these students.

46:19.600 --> 46:24.560
And, and the teachers in charge, this thing is in support of the teacher, the teacher is going

46:24.560 --> 46:27.760
to be able to say, no, I don't really like that activity. Can you, and we already have this where

46:27.760 --> 46:31.280
they can highlight parts of it and they can say, let's come up with something that's a little bit

46:31.280 --> 46:35.920
more fun or a little bit more engaging or gets the kids out of their chair. And the AI will say,

46:35.920 --> 46:42.080
yes, sir, yes, ma'am, and do that. But as you can imagine, it dramatically lowers the amount of

46:43.280 --> 46:49.200
analysis and prep time that a teacher has to spend in order to create these really engaging

46:49.200 --> 46:56.080
and differentiated personalized education experiences. It's also going to all this,

46:56.080 --> 47:01.120
all these other trappings of school that as students, we never saw as parents, we oftentimes

47:01.120 --> 47:06.960
don't see writing progress reports, grading papers, you know, IEPs, which are these

47:06.960 --> 47:11.440
plans you have to write for, for students who are, who need special supports, which are

47:12.000 --> 47:16.320
increasingly a larger and larger percentage of the student population takes a lot of the teacher's

47:16.320 --> 47:22.560
time. Teachers have to prep their own knowledge. If the AI can dramatically improve that time,

47:22.560 --> 47:26.800
we've been getting signals from school districts that Kanmigo is helping the teachers with their,

47:26.800 --> 47:33.600
with this non-student facing work, it's saving them five, 10 hours a week. And so you're going to

47:33.600 --> 47:39.040
see it there. You're going to see, you know, there's this phenomenon called learning management

47:39.040 --> 47:43.680
systems, which are increasingly the ways that teachers and students communicate with each other

47:43.680 --> 47:48.400
and, you know, make assignments and submit assignments. And right now these are web-based

47:48.400 --> 47:54.240
things. I see more and more the AI acts as that intermediary, where it's working with the teacher

47:54.240 --> 47:59.360
on the planning, on the creation, it provisions it to the student, it works with the students on

47:59.360 --> 48:04.480
those things, and then it's able to report back to the teacher. So, you know, we can, and I can

48:04.480 --> 48:08.800
daydream more and more. You can imagine a world where an AI can start to even know what's going

48:08.800 --> 48:13.760
on in a classroom and support even more. But even before we go into those more sci-fi use cases,

48:14.720 --> 48:18.400
it, I think it's just going to be a, it's just going to be in the fabric of everything that the

48:18.400 --> 48:22.080
teacher and the students do, and hopefully in a way that supports the students and the teachers

48:22.080 --> 48:27.760
better and streamlines things. Do you think it will happen? Like, let's say, you know, AI is

48:27.760 --> 48:32.240
moving pretty fast, and already there are tools like Kanmigo just, you know, what is it like a

48:32.240 --> 48:38.560
year and a half after the first chat CPT was released? What, where do you see education five

48:38.560 --> 48:42.720
years from now? Like in K through 12, and then I'll ask about other types of education.

48:42.720 --> 48:46.000
Yeah, you know, I think there are certain trends that are going to happen that are not fully

48:46.000 --> 48:49.600
technologically related, and there's going to be things that are going to be AI related.

48:49.600 --> 48:53.920
The non-technologically related, I hope we do move, as I mentioned earlier, to a competency-based

48:53.920 --> 48:59.600
system, less seat time, that we can go more to a mastery-based system. And that starts to involve

48:59.600 --> 49:04.080
a little bit more technology, because if you're asking a teacher to say, hey, if a student got

49:04.080 --> 49:07.840
to see the first time, they should have another chance at that assessment. Well, who's going to

49:07.840 --> 49:12.960
write that assessment? That's work. Who's going to grade that assessment? That's work. And so,

49:12.960 --> 49:19.040
I think that's where the technology plays into it. In terms of how the technology is going to

49:19.040 --> 49:27.920
manifest itself, for sure, all of that support work that we used to bury teachers with, I think

49:27.920 --> 49:32.880
is going to be dramatically streamlined. Once again, lesson planning, writing exit tickets,

49:32.880 --> 49:38.080
grading papers. Teacher's always in charge, but I mean, imagine being a seventh grade English

49:38.080 --> 49:44.960
teacher, and every two weeks, you literally have to sit there and read 100, 150 papers about

49:45.840 --> 49:51.680
great expectations from seventh graders. I could imagine by the third or fourth paper,

49:51.680 --> 49:57.200
it can get a little bit tedious. Instead, you had a reliable AI that can give analysis,

49:57.200 --> 50:02.160
you can spot check it. You're the final arbiter, but it could take that thing that was ruining

50:02.160 --> 50:09.680
your weekend to a task that might take an hour instead of 10. So, you're going to see that.

50:09.680 --> 50:13.920
You're going to see the AIs get better and better at supporting the students, not just conceptually,

50:13.920 --> 50:19.520
not just academically, but I think from an executive functioning, from a metacognitive. So,

50:20.240 --> 50:24.480
one project we're working on, we call it Proactive Conmigo. It doesn't just act as a

50:24.480 --> 50:29.200
Socratic tutor. It's going to start messaging students. Where are you? The things I used to do

50:29.200 --> 50:35.920
at Nadia back in the day. Hey, you said you were going to hit these goals by Friday. It's Saturday

50:35.920 --> 50:41.520
now, and you're only halfway. Come on, what's going on? It's going to be able to facilitate a lot

50:41.520 --> 50:47.120
more communication between the teacher, the student, and the parent. When it finds that,

50:47.120 --> 50:51.120
hey, there's something off parent, you should know about this. And hey, teacher, by the way,

50:51.120 --> 50:55.520
I already told the parent that this is happening. I think you're going to see more of that.

50:55.520 --> 51:00.400
I think the whole area of assessment is going to be really, really interesting. A lot of the

51:00.400 --> 51:06.160
criticism of education over the last 20 or 30 years is we've tried to measure more things,

51:06.160 --> 51:10.240
which for the most part is a good thing. And we've been trying to measure it in standardized

51:10.240 --> 51:16.400
ways, which for the most part is a good thing. But because so many people started indexing

51:16.400 --> 51:21.120
on these things that you can measure in a standardized way, they maybe have lost sight on

51:21.120 --> 51:28.400
other things. I was talking to a senior administrator at Harvard, and he was telling me that even at

51:28.400 --> 51:34.720
Harvard, they're seeing almost an epidemic of kids who can't write. And if Harvard's seeing that,

51:34.720 --> 51:39.360
I can guarantee you it's 10 times worse pretty much everywhere else. And it's probably,

51:40.240 --> 51:44.320
no one knows exactly why. Well, think about what standardized testing has been for the last

51:45.120 --> 51:50.320
20 years. There's no writing in it because writing has fundamentally been hard to assess,

51:50.320 --> 51:55.040
or to be able to give someone standardized clear feedback on. And so it's kind of maybe

51:55.040 --> 52:00.880
started to disappear in many cases. We see in the other things in math, when people focus on a

52:00.880 --> 52:06.080
multiple choice assessment only, multiple choice can have value. There's nothing inherently wrong

52:06.080 --> 52:11.200
with multiple choice, but it might squeeze out other things if we put too much emphasis on it.

52:11.200 --> 52:17.520
And so I think AI with its ability to make sense of more open-ended responses,

52:18.320 --> 52:22.800
and even visual responses, or even video responses, I think it's going to broaden the

52:22.800 --> 52:27.680
aperture of how we assess and how we even assess in a standardized way. And that's going to be good

52:27.680 --> 52:33.680
because it's going to allow school to going back to, let's not just focus on what can be assessed,

52:34.560 --> 52:38.960
or narrowly assessed, but what's important. And now we can hopefully assess that in a broader way.

52:39.920 --> 52:45.200
So do you think, is this hopeful, or do you think this actually will happen in the educational

52:45.200 --> 52:56.800
system? We're working on it. I'm both. There's definitely a possibility that a lot of folks,

52:56.800 --> 53:02.000
well-intentioned folks, have good ideas, and either they don't get traction in a system that

53:02.000 --> 53:07.600
historically has sometimes been slow to move, or it manifests itself in unproductive ways.

53:08.560 --> 53:13.440
That's one of my fears. That's why I tell our team at Khan Academy why our role is important.

53:13.440 --> 53:17.760
We're not for profit. We are focused on how does this actually drive impact?

53:17.760 --> 53:23.440
There are other players. There may be more sales focused, and they're just happy to make the sale

53:23.440 --> 53:30.320
however it gets used. And that might not lead to the best possible outcomes for teachers and students.

53:30.320 --> 53:35.200
But generally speaking, I'm, obviously, I plan on devoting my life to this,

53:35.200 --> 53:40.640
so I wouldn't be doing it if I didn't think that this was going to happen.

53:42.160 --> 53:47.440
And so you mentioned earlier that a lot of times students don't retain what they learn.

53:47.440 --> 53:52.240
I think this is really true. It's what you learn in history class in ninth grade.

53:52.240 --> 53:57.040
I would say there's probably a 1% chance you remember it now, unless it's something that

53:57.040 --> 54:04.400
particularly fascinates you. What do you think will change in the system that will increase

54:04.400 --> 54:10.320
retention? I think if we are more explicit about moving to a competency-based system,

54:10.320 --> 54:15.600
where we say, well, one, competency-based system makes you have to get more clear

54:15.600 --> 54:21.520
about what you care about. And look, some of the things that we learned in ninth grade that we

54:21.520 --> 54:29.600
forgot, that might be okay because it was less about learning the text of, I don't even remember

54:29.600 --> 54:33.840
even the eighth amendment, the text of the eighth amendment, but it was more about learning

54:34.560 --> 54:40.400
to critically analyze things, et cetera. And that might hopefully be a skill that we have retained.

54:40.400 --> 54:44.240
But there probably is content knowledge that we do want. In fact, there for sure is content

54:44.240 --> 54:50.000
knowledge that we want people to retain. But we need to get just more explicit about that.

54:51.040 --> 54:56.880
And then if we get more explicit about, look, everyone who graduates from high school should,

54:56.880 --> 55:03.040
for the rest of their life, be able to solve a simple equation. They should for sure know

55:03.680 --> 55:13.440
who Alexander the Great was. They should for sure know how to make sense of a informational text

55:13.440 --> 55:19.520
written at at least maybe a seventh or eighth grade level, which is what most texts in our life

55:19.520 --> 55:24.560
are actually written at. And then if we can focus on those things, because competency-based learning

55:24.560 --> 55:29.920
also focuses you, because right now there's a lot of just hoop jumping and seat time and this

55:29.920 --> 55:35.280
or that that could be very idiosyncratic to a particular classroom. It allows you to focus

55:35.280 --> 55:39.760
on those things and make sure those things happen. And then hopefully streamlines from some of the

55:39.760 --> 55:45.520
other busy work that doesn't have to happen as much. But do you ever see a point where, okay,

55:46.080 --> 55:51.600
this student's really good at math? Oh, he spent one week learning algebra one. That was all he

55:51.600 --> 55:55.840
was focused on. So now he's able to move on to algebra two, and he goes at his pace. And another

55:55.840 --> 56:02.240
student actually goes at a slower pace. And so you do have, for a classroom of 30 students, you do

56:02.240 --> 56:07.760
have people going at 30 different paces, and they're immersed. So that increases retention. There's

56:07.760 --> 56:14.560
less multitasking from going from biology to history to math or whatever. So some of that's

56:14.560 --> 56:20.320
already happening. After I wrote my last book, and my oldest at the time was entering kindergarten,

56:20.320 --> 56:25.040
we started a school con lab school that implements a lot of these. And I won't claim that we figured

56:25.040 --> 56:31.840
it all out. In fact, I'm always pushing the school to be thinking a little bit more about

56:31.840 --> 56:35.360
questioning a lot of the assumptions. But, you know, at that school, yeah, you do have

56:36.320 --> 56:40.000
a good number of students. And math is probably where we're seeing it the most,

56:40.640 --> 56:45.760
where they could easily be three, four, five, six grade levels ahead. There's a lot of students who

56:45.840 --> 56:52.080
are probably, you know, at or one or two grade levels ahead. And there's a few who, you know,

56:52.080 --> 56:57.040
the faculty is working extra hard to make sure that they're going at least at a reasonable pace,

56:57.040 --> 57:00.320
that they're going to get at least get to calculus before they leave high school,

57:00.320 --> 57:05.200
which in the broader world is already a win, because most kids don't even get there. So we're

57:05.200 --> 57:13.520
already, we're already seeing that type of reality. But I think we need to see more experiments. I

57:13.600 --> 57:17.360
would, you just mentioned of like being able to focus on certain things at a time. I'm intrigued

57:17.360 --> 57:22.320
with that idea. There's universities like Colorado College, or colleges, I should say, that do do

57:22.320 --> 57:28.480
that. You take classes, instead of taking four or five classes, you take one at a time, but you

57:28.480 --> 57:32.320
do it for two weeks. And that's all you do. And then you go and switch and you do another one.

57:32.320 --> 57:36.960
I think that's interesting. And I don't think it's just going to be the con lab schools and the

57:36.960 --> 57:42.080
Colorado colleges of the world. We have partnerships with very mainstream school districts. Newark,

57:42.080 --> 57:46.400
New Jersey, we're seeing some really good things. And they're doing a bit of a hybrid where the

57:46.400 --> 57:50.640
teachers are using Khan Academy to assign the daily practice. And by the way, the kids have

57:50.640 --> 57:56.240
support from Khan Mego. But the district says, Hey, look, if you finish your assignment and you

57:56.240 --> 58:01.520
did it well and you got, you showed your proficiency, you can keep going. But if you did the assignment,

58:01.520 --> 58:06.960
but you only got 30% of it right, you should have another go at it. And now it's going to be

58:06.960 --> 58:11.840
different items because it's sampling from a very deep item bank, or maybe you're not ready for

58:11.840 --> 58:16.720
that assignment because you're missing some prerequisite skills. How do we get you to get

58:16.720 --> 58:21.040
some more practice on that without falling too far behind? This is happening in Newark, New Jersey,

58:21.040 --> 58:29.440
as we speak. It's interesting. In 1982, I was part of this program where these seventh graders would

58:29.440 --> 58:35.200
take the SATs. And if you did well, you were invited to participate in this program at Duke

58:35.200 --> 58:41.680
University called TIP, where it had this immersion experiment. And I always remember, finally,

58:41.680 --> 58:47.280
like in three weeks, I was able to go through like a couple of years of math. And then when I got back

58:47.280 --> 58:51.600
to regular school, so I was in a summer program. And when I got to back to regular school, I was

58:51.600 --> 58:57.040
able to advance more quickly. And I always thought that was an incredible experiment that they were

58:57.040 --> 59:01.520
doing. And then at the time, there was only 22 students in the program. Now there's like tens of

59:01.520 --> 59:07.600
thousands across various campuses. And I just wonder when kind of the mainstream educational

59:07.600 --> 59:11.440
system is going to start adapting this, but it sounds like it is to some extent.

59:11.440 --> 59:17.520
It is. And if you look at communities where I live, I live in the middle of Silicon Valley,

59:17.520 --> 59:24.000
what you're describing is more the norm than the exception. But yeah, and I think the work is how

59:24.000 --> 59:28.800
do we make that accessible and the norm more broadly. And that's why most of our work at

59:28.800 --> 59:34.320
Khan Academy, most of the places where we are deploying Kanmigo are large-scale public school

59:34.320 --> 59:40.400
districts. But we're seeing more traction than I would have guessed a couple of years ago.

59:41.760 --> 59:47.360
Now in terms of the existential threat for various industries, one area that has been

59:47.360 --> 59:54.640
a big concern, and you mentioned this quite a bit, is the ability to write. Like this has been a big

59:55.520 --> 59:59.200
debate in education. Like you mentioned at Harvard, some students don't even have the

59:59.200 --> 01:00:06.400
ability to write. And then in the creative industry, like screenwriting, I think there is a real

01:00:07.760 --> 01:00:20.160
question. Will AI, will the GPT-7 be able to write an Oscar-winning movie? And I think the

01:00:20.160 --> 01:00:24.320
conclusion in general, and your conclusion is that it won't be, but it'll be a useful tool.

01:00:24.400 --> 01:00:30.000
Again, for the creative to be even more creative. But I think people are very worried about this.

01:00:30.000 --> 01:00:35.440
And I will tell you, just from conversations I've had with heads of major movie studios,

01:00:35.440 --> 01:00:39.040
they are looking for solutions other than screenwriters.

01:00:39.760 --> 01:00:49.040
Yeah. Well, I think there's a bunch in this. So on the first level, most writing essentially has

01:00:49.040 --> 01:00:57.280
two pieces to it. There is the putting words on paper in a structured, hopefully engaging way,

01:00:58.080 --> 01:01:03.840
grammatical way. And then there's the, how do you come up with what you're going to write?

01:01:03.840 --> 01:01:09.600
So if you're a journalist, I would think most of your work should be going out there talking

01:01:09.600 --> 01:01:14.800
to people, looking through public documents, attending public hearings, being on the same

01:01:14.800 --> 01:01:19.760
scene of the crime to report what's going on. So that's all the work that I don't think AI is

01:01:19.760 --> 01:01:26.000
going to be able to do anytime soon. And then the journalist takes all of that, and then they write

01:01:26.000 --> 01:01:32.560
the article, you know, and all of that. And so I think AI there very clearly has a role of, well,

01:01:32.560 --> 01:01:38.160
if it can help the journalists, let's say take all of their notes that they just got from multiple

01:01:38.160 --> 01:01:43.520
resources, sources, maybe different recordings, maybe even videos, and then help them get to a

01:01:43.520 --> 01:01:47.840
first draft pretty fast, maybe with a little bit of prompting. I think that's a win for that

01:01:47.840 --> 01:01:52.240
journalist. They're going to be able to spend more time on the information gathering and less

01:01:52.240 --> 01:01:56.400
time on the wordsmithing. But once again, I don't think it's that you're just going to take all that

01:01:56.400 --> 01:02:00.800
input and let the AI just pop something out that, okay, let's put it in the New York Times. No, the

01:02:00.800 --> 01:02:04.960
journalist is then going to tweak it and say, no, that they're going to act more like an editor.

01:02:04.960 --> 01:02:09.360
And they're going to say, no, that let we're burying the lead, let's put this quote up front,

01:02:09.360 --> 01:02:13.120
et cetera, et cetera, let's tighten it, let's make it a little bit more punchy. So there's still

01:02:13.120 --> 01:02:18.240
going to be work and the craft of writing and the ability to recognize good writing is still

01:02:18.240 --> 01:02:26.160
going to matter. I think if we go to the movie industry, I'm not sure exactly how this is going

01:02:26.160 --> 01:02:33.120
to play out, but, and I write about this in the book, I think what is going to happen is AI is

01:02:33.120 --> 01:02:40.720
going to lower, like I found it ironic that it was the screenwriters who are afraid of AI and

01:02:40.800 --> 01:02:47.120
that the production companies really want it. I actually think the AI is going to bring the

01:02:47.120 --> 01:02:52.400
balance of power to the individual, to the screenwriters and take it away from the gatekeepers

01:02:52.400 --> 01:02:57.120
who are the production houses. We already saw that before AI with things like YouTube and social

01:02:57.120 --> 01:03:02.560
media. I mean, you're even seeing this with mainstream news now. It's essentially been

01:03:02.560 --> 01:03:10.400
disrupted already by YouTube and social media. The ability for someone to publish and be discovered

01:03:10.400 --> 01:03:17.200
without having to go through gatekeepers now is completely transformed. Justin Bieber is a

01:03:17.200 --> 01:03:22.960
YouTube artifact. I'm a YouTube artifact. People can publish podcasts now. You don't have to make

01:03:22.960 --> 01:03:28.160
a pitch to some executive at wherever to do that anymore. That's the way the world was 30 years

01:03:28.160 --> 01:03:35.120
ago, 40 years ago. With AI, I think you're going to see a similar, you're lowering the cost of

01:03:35.120 --> 01:03:42.480
getting into the game. Today, if I have a great idea for a science fiction movie, and I have a few,

01:03:43.280 --> 01:03:48.960
I dream about one day, not only would I have to write a screenplay, I would have to get in

01:03:48.960 --> 01:03:53.200
in front of people who take me seriously. Even if I wrote a great screenplay, I might not even

01:03:53.200 --> 01:03:58.240
be noticed unless I'm connected in the right ways, unless I get the right people to read my screenplay.

01:03:59.680 --> 01:04:03.600
Someone will say, it was a pretty good screenplay. I'll pay a couple hundred grand for it if it's

01:04:03.600 --> 01:04:08.560
really good. In most cases, I'll pay a couple of tens of grand for it. Go write another one

01:04:08.560 --> 01:04:14.560
while you're living off of ramen. Then that movie studio might throw some of them away,

01:04:14.560 --> 01:04:17.920
but eventually say, okay, we're going to put $100 million behind this one,

01:04:17.920 --> 01:04:22.480
hire actors, director, blah, blah, blah, blah, blah. Five, 10 years later, the movie comes out.

01:04:23.040 --> 01:04:28.160
If it's a blockbuster, the movie studio is going to make hundreds of millions of dollars that the

01:04:28.160 --> 01:04:33.680
screenplay writer probably made less than that, a lot less, a lot less. If they're very savvy,

01:04:33.680 --> 01:04:36.880
they might have gotten a little bit of a cut of that movie, but in most cases, they're getting

01:04:36.880 --> 01:04:43.200
next to nothing. In the world we're going into, if I have a great sense of story, if I know what a

01:04:43.200 --> 01:04:50.000
great movie should look like, I don't have to stop at the screenplay. I will be able to produce the

01:04:50.000 --> 01:04:57.760
entire movie, probably for tens of thousands of dollars or less, including editing, sound.

01:04:58.800 --> 01:05:03.840
I'm not going to have to pay actors. I would worry if I'm an actor, actually, in this world,

01:05:04.400 --> 01:05:08.720
but the creative who's at the core of the idea is going to be able to go much, much further,

01:05:08.720 --> 01:05:13.120
and then they're going to be able to self-publish it on YouTube and monetize it on YouTube, or

01:05:13.120 --> 01:05:17.360
maybe there'll be paths, maybe there'll be a YouTube slash Netflix-like thing where

01:05:17.440 --> 01:05:23.200
slightly vetted people can surface and put their content out. I would be much more worried if I was

01:05:24.720 --> 01:05:28.800
production houses. The production houses probably are going to invest in it. They're going to figure

01:05:28.800 --> 01:05:34.640
out ways to do editing much cheaper. They are going to be able to write screenplays,

01:05:36.880 --> 01:05:42.960
but a commodity screenplay is very different than a great screenplay. I think for society,

01:05:42.960 --> 01:05:46.320
it's going to be good because think about how many hundred million dollar duds there are,

01:05:46.320 --> 01:05:51.920
how many bad movies, frankly, most hundred million dollar movies are bad. What a waste of

01:05:51.920 --> 01:05:59.280
society's resources. Now, we're going to have a bunch more of movies that probably cost 10 or

01:05:59.280 --> 01:06:04.960
$100,000 to make, and they're going to have a higher percentage of bad ones because it's going

01:06:04.960 --> 01:06:08.400
to be like YouTube, but we're also going to have a higher total quality of good ones.

01:06:09.120 --> 01:06:15.520
It's interesting because Tyler Perry, for instance, he shut down plans to

01:06:16.160 --> 01:06:22.480
build a hundred million dollar studio space because he says AI is going to do this. He's a big

01:06:22.480 --> 01:06:28.560
movie creator. He has the same view as you. I think I agree, but it's interesting to see how

01:06:29.280 --> 01:06:34.080
nervous the writers are. Maybe it's just like an insecurity of writers because they haven't been

01:06:34.080 --> 01:06:38.160
historically making that money. They've been kept down in the system, so they just assumed

01:06:38.160 --> 01:06:42.880
they're going to be kept down again. But you're right, it is going to give them power. But it's

01:06:42.880 --> 01:06:50.480
interesting from your book, there's various groups of people that have these fears. There's

01:06:50.480 --> 01:06:54.720
creatives have these fear. There are teachers that have this existential fear. There's professors who

01:06:54.720 --> 01:06:59.120
worried the students are cheating. An interesting chapter is the one on parenting. Do you see

01:06:59.120 --> 01:07:05.200
parents being afraid AI could take their place? I don't think any parents, well, hopefully parents

01:07:05.200 --> 01:07:15.200
aren't afraid of AI taking their job as a parent. I think most of the fears of a parent are we see

01:07:15.200 --> 01:07:21.360
directly our kids getting addicted to devices. We either see directly in our own families or schools

01:07:21.360 --> 01:07:27.520
or we read about how things like social media and cell phones are affecting mental health of

01:07:27.520 --> 01:07:34.000
especially young people, teenagers, probably disproportionately young girls. That's scary

01:07:34.400 --> 01:07:38.160
to parents. And so when we see a new technology that's as powerful as AI,

01:07:38.160 --> 01:07:42.560
okay, is this going to make everything worse? Not really having a clear idea of how it will

01:07:42.560 --> 01:07:50.080
make it worse. My hope once again is I actually think used well, I'm sure there's going to be

01:07:50.080 --> 01:07:58.320
use cases of AI that are not great, that can almost amplify a lot of the bad things that we

01:07:58.320 --> 01:08:03.440
already see on the internet, whether it's marketing to you, whether it's forms of social media that

01:08:03.440 --> 01:08:09.040
make you feel insecure or you have permanent fear of missing out or whatever's going on

01:08:09.040 --> 01:08:13.680
or hurt your body image, whatever. But I think there's going to be use cases, these are the ones

01:08:13.680 --> 01:08:18.960
we're going to focus on, hopefully others focus on it as well, where the AI beyond just helping you

01:08:18.960 --> 01:08:24.880
academically, it can help you even handle the world that you're dealing with. I write in the book

01:08:24.880 --> 01:08:31.120
about the AI acting as a guardian angel. Right now, when you surf the internet and our children

01:08:31.120 --> 01:08:37.680
surf the internet, they don't realize it, but they're already doing battle and they don't even

01:08:37.680 --> 01:08:42.480
know they're in a battle with AI's where these AI's are figuring out the next thing to show on

01:08:42.480 --> 01:08:48.160
their social media feed or the search results or the next ad. And their objective function is what's

01:08:48.160 --> 01:08:52.880
going to get you to click on that ad or what's going to make you watch longer. And unfortunately,

01:08:52.880 --> 01:08:58.000
it seems like triggering content, polarizing content, content that makes you feel bad about

01:08:58.000 --> 01:09:04.080
yourself is the stuff that makes you sit on it longer. And any of us who have fallen into it,

01:09:04.080 --> 01:09:08.640
we've all spent some time on the internet and clicked on an ad or spent more time on social

01:09:08.640 --> 01:09:13.920
media and we never feel good about it when we're done. We all feel like we kind of wait.

01:09:13.920 --> 01:09:19.360
Is that true? I feel like that's a little bit of a cliche. Sometimes I surf the internet and I

01:09:20.240 --> 01:09:30.240
enjoy the experience. For me, it's true. There's definitely times where my friend sends me a fun

01:09:30.240 --> 01:09:36.800
video or a meme or I fall into it a little bit on YouTube or on TikTok and I get a good giggle and

01:09:36.800 --> 01:09:44.240
that was exactly what I needed that day. But more often than not, we have fully developed front

01:09:44.320 --> 01:09:50.000
to lobes and we can regulate ourselves after 10 or 15 minutes of that. But also even TikTok,

01:09:50.000 --> 01:09:55.120
which I've shut down my account and I had a reason to be on it. We had a social media

01:09:55.120 --> 01:10:00.640
following. I just took it off because I found even myself, I just went to TikTok to announce a new

01:10:00.640 --> 01:10:06.000
feature on Khan Academy and then I end up just swiping and swiping and then 10, 15 minutes

01:10:06.000 --> 01:10:10.400
go by. I'm like, I don't feel good about what I'm doing with my day and I stop. I was able to stop

01:10:10.400 --> 01:10:14.320
at 15 minutes. There's a lot of young people who aren't stopping at all and they're going two,

01:10:14.320 --> 01:10:19.040
three, four hours. And look, it's great if someone has the self-regulation to be able to stop after

01:10:19.040 --> 01:10:24.240
15, 20 minutes. That's probably healthy fun, as long as it's not making them feel bad about

01:10:24.240 --> 01:10:29.680
themselves. But I am imagining a world now and we're working on this where an AI can

01:10:30.720 --> 01:10:36.800
act on your behalf or act on your parents or your teacher's behalf where, yeah, okay, I'll let my

01:10:36.800 --> 01:10:42.320
daughter use a cell phone, but I want to see a world where there is an AI agent on that phone

01:10:42.320 --> 01:10:47.040
that I am in conversation with. And I would tell them, like, look, I'm cool with her spending

01:10:47.040 --> 01:10:53.680
some time on it, but let's be careful about her seeing things that hurt her body image or things

01:10:53.680 --> 01:11:00.480
that make her feel like she's missing out on things or just put her into this polarizing haze

01:11:00.480 --> 01:11:05.600
or whatever it might be. Then the AI can make sense of what she's surfing and looking at and say,

01:11:05.600 --> 01:11:11.520
hey, we've just spent the last 10 minutes looking at pictures of that friend's birthday party

01:11:12.320 --> 01:11:17.600
and when you were out of town, maybe we want to go do something else. Or if it can see patterns in

01:11:17.600 --> 01:11:22.560
what the daughter is doing, tell the parents, hey, did you know you're child spending an awful

01:11:22.560 --> 01:11:27.680
lot of time doing X, Y, or Z? One, that might just be something to police a little bit more,

01:11:27.680 --> 01:11:31.600
or it might be an opportunity to have a connection. Like, did you know that they're really interested

01:11:31.600 --> 01:11:36.240
in crocheting? Maybe you should take it up. Maybe you should have a conversation with them. This

01:11:36.240 --> 01:11:41.520
is something to talk about at the dinner table. So I'm hoping that the AI can act much more as a

01:11:43.040 --> 01:11:48.320
used well, a little bit of a guardian angel, and it can help parents, it can support parents,

01:11:48.320 --> 01:11:52.640
engage with their children more. I hope that, you know, right now we have devices like Siri

01:11:52.640 --> 01:11:57.040
and Alexa and Google Home. And right now they're kind of like, you know, what time is it? Put a

01:11:57.040 --> 01:12:02.480
timer on, you know, what's the weather today? You know, how many people live in Ukraine? That's

01:12:02.480 --> 01:12:08.640
the type of things we use it for. I would love a time, which I think is going to happen in the

01:12:08.640 --> 01:12:15.200
next year or two, where I'm, you know, sometimes we're having dinner together. I want to, and

01:12:16.320 --> 01:12:21.360
we're having a conversation, but I know that there's more that my kids have going on in their life

01:12:21.360 --> 01:12:26.400
that I'm not getting out of them. When I just ask them, how is your day? How was school? What's,

01:12:26.400 --> 01:12:31.280
you know, how's history class going? And I could imagine a world where an AI says,

01:12:31.280 --> 01:12:36.320
I could say, hey, Alexa, can you moderate a conversation, a fun conversation between us as

01:12:36.320 --> 01:12:40.240
kind of an icebreaker? And it does. And it says, all right, we're going to go around and everyone's

01:12:40.240 --> 01:12:44.240
going to say the best part of their day. And then when my nine year old says, oh, my best part of

01:12:44.240 --> 01:12:49.840
the day was getting to hang out with my, you know, my friend who was out sick, then the AI could say,

01:12:49.840 --> 01:12:54.720
well, why was that? And, and, but once again, it's not squeezing out the parent. It's creating a

01:12:54.720 --> 01:13:00.400
context to, as a parent, I create more context where I can engage with my children in a more

01:13:00.400 --> 01:13:05.440
meaningful way, as opposed to just being transactional, put that iPad away, go to bed, eat your food.

01:13:06.080 --> 01:13:10.320
Hey, it's time to get up. Hey, we're late for the bus. I don't, we all have to do that as parents,

01:13:10.320 --> 01:13:14.640
but it squeezes out the like, what do you think is the meaning of life? Or what does it mean to be

01:13:14.640 --> 01:13:21.200
a great friend? Or how can we all be better family members? If we could have an expert facilitator

01:13:21.200 --> 01:13:26.240
all the time, that'd be pretty incredible. Do you think, do you think, are you going to get a

01:13:26.240 --> 01:13:33.840
wearable like AI, like this humane AI pin or, or rabbit or, or maybe make Conmingo a wearable?

01:13:33.840 --> 01:13:39.680
Yeah, yeah, it's, it's, I have no imminent plans to do, to do that. Because I'm also someone who

01:13:39.680 --> 01:13:46.720
really likes going off the grid, so to speak, and being completely unplugged in certain cases.

01:13:47.360 --> 01:13:55.680
But if, if there are devices that come out that could, that I, that I can legitimately believe

01:13:55.680 --> 01:14:00.720
will enhance my life in some way, I'd be open to it. And as long as they have the data privacy and

01:14:01.280 --> 01:14:07.280
all of the right safeguards in place. Now, I'm wondering what, one big question out there is,

01:14:07.280 --> 01:14:14.640
does AI somehow plateau? Like, is there only so much it could learn and simulate, you know,

01:14:14.640 --> 01:14:19.360
human conversation? So you mentioned how like GPT-5 is going to have a trillion parameters

01:14:19.360 --> 01:14:26.480
as opposed to GPT-4, which just had 175 billion as opposed to GPT-1, which had, I don't know,

01:14:26.480 --> 01:14:31.840
a million or whatever it was at a trillion parameters or 10 trillion parameters.

01:14:32.480 --> 01:14:35.440
What can AI do that prior versions couldn't do?

01:14:36.000 --> 01:14:41.280
None of us know for sure. And I think it is a philosophical debate about if an AI is trained

01:14:41.280 --> 01:14:48.640
on human created content for the most part, can it transcend human intelligence in certain ways?

01:14:48.640 --> 01:14:53.120
I think the answer is in certain ways it will be able to, because as these, as the parameters

01:14:53.120 --> 01:15:00.720
increase, it'll be able to find patterns that are not maybe explicitly obvious to us and maybe

01:15:00.720 --> 01:15:06.480
leverage those patterns to create things. But will it be like, you know, a truly transcendent

01:15:06.480 --> 01:15:15.280
intelligence? I don't know. I think one of the interesting things that are going to happen is

01:15:16.880 --> 01:15:22.240
they're going to be collecting more and more inputs. Right now, it's pretty much human created,

01:15:22.240 --> 01:15:29.760
written text for the most part, and now images, videos, sound, files. I think when the AIs are,

01:15:31.120 --> 01:15:35.520
get more sensory perception, you know, once you have wearables, once they have cameras,

01:15:35.520 --> 01:15:39.520
I know this is a little bit dystopian. So, you know, we have to think about how this gets provisioned.

01:15:39.520 --> 01:15:44.640
It's going to get more training data. I also think robotics is interesting because

01:15:45.440 --> 01:15:50.800
when we learn, we don't just observe our environment, we play with the environment. I mean,

01:15:50.800 --> 01:15:55.600
we literally, that's what that play is literally learning. A kid pokes something, throws it, you

01:15:55.600 --> 01:16:02.240
know, shakes it and figures out what, how they're investigating the world. And I can imagine

01:16:02.800 --> 01:16:09.040
once you pair AI with robotics and then it can actively investigate the world,

01:16:10.080 --> 01:16:16.880
it will get even more input on, and maybe even, and look, it's going to be able to have

01:16:16.880 --> 01:16:22.320
sensory input that we don't have. It will be able to see the entire electromagnetic spectrum,

01:16:22.320 --> 01:16:27.840
not just that, you know, it's going to be able to hear every, every frequency of sound. It's going

01:16:27.840 --> 01:16:33.840
to be able to, you know, detect molecules that we can't at least consciously detect.

01:16:34.960 --> 01:16:41.520
So, it's an interesting philosophical debate, but you know, once you start talking about orders

01:16:41.520 --> 01:16:48.400
of magnitude, more parameters than we have synapses in the human brain, and it's tireless,

01:16:48.400 --> 01:16:53.440
and it has access to all of this information, and it can process it faster than we can.

01:16:54.080 --> 01:16:58.000
It is interesting, and I know everything I, even me talking out loud has, I've kind of

01:16:58.000 --> 01:17:04.080
scared myself a bit, but, but, but you know, once again, it's all about intent and how we use it,

01:17:04.080 --> 01:17:09.440
and, and, and can we use it for, for good purposes, because there, there can be a lot of good purposes

01:17:09.440 --> 01:17:17.040
here. I mean, it's just something I said, let's say a good purpose is education. I do, and there's,

01:17:17.040 --> 01:17:26.000
there's evidence that I think with a general AI that basically exceeds our current educational

01:17:26.000 --> 01:17:32.480
efforts, kids are going to get smarter, meaning they're just going to learn faster, they're going

01:17:32.480 --> 01:17:39.280
to retain more, they're going to get that feedback loop much more quickly, and, and so they're going

01:17:39.280 --> 01:17:44.480
to be able to, to advance more quickly than our generation was or the generations in between.

01:17:44.480 --> 01:17:49.680
I mean, an example that you can see in a specific domain, it's not a general domain,

01:17:49.680 --> 01:17:57.920
but look, computers have been better than humans at chess since 1997, and, and computers have

01:17:57.920 --> 01:18:03.280
evolved incredibly since then. So it's been, you know, over 20, you know, 25 years or 20,

01:18:03.280 --> 01:18:09.520
whatever, 27 years of computers improving since they were already better than humans,

01:18:09.520 --> 01:18:17.840
and, and kids use computers to learn chess with some coaching, but 99% is they're playing

01:18:17.840 --> 01:18:22.080
the computer and getting immediate feedback. And then there might be some coaching and kids are

01:18:22.080 --> 01:18:30.080
so much better now than they were back in 1997. And their rate of improvement is so much faster.

01:18:30.080 --> 01:18:35.200
I mean, a 17 year old, just the other day became the challenger to the world championship

01:18:35.280 --> 01:18:42.480
that never would have happened 25 years ago. So it's, it's incredible how in, in that specific

01:18:42.480 --> 01:18:48.000
domain and other domains like that, kids have advanced and learned and retained so much faster

01:18:48.000 --> 01:18:52.160
than kids back then. And I wonder if the same thing's going to happen in, in general education.

01:18:52.160 --> 01:18:59.680
I obviously hope so. And it seems like it definitely will. Like our kids will be smarter.

01:18:59.680 --> 01:19:04.480
And I, you know, I, I, I typically traffic in optimistic scenarios, but I, and so I hope what

01:19:04.480 --> 01:19:08.960
you're saying is right. There's a, there is a, a more dystopian, I don't know if it's dystopian,

01:19:08.960 --> 01:19:13.920
but a less optimistic scenario where you're going to have a segment of students who,

01:19:14.880 --> 01:19:20.400
who take these tools and run with it and will do exactly what you said. They're going to,

01:19:20.400 --> 01:19:25.440
to, to get to heights that we never thought was possible by, at very young ages. And look,

01:19:25.440 --> 01:19:29.760
that's, that by itself is not in any way a negative thing. That is a positive thing.

01:19:29.760 --> 01:19:35.200
These are going to be the young people who cure diseases for us, who start the next, you know,

01:19:35.200 --> 01:19:40.320
great companies who write the next great novel, who produce the next great movies,

01:19:41.360 --> 01:19:46.880
all of the above, push AI forward or make sure that AI is used in a safe way. But I do,

01:19:48.000 --> 01:19:53.200
I think it's how do we make sure that the other, whatever it is, 60, 70% of students

01:19:53.760 --> 01:20:02.720
stay engaged and engaged enough to not be, not be thrown behind by, by all of this.

01:20:02.720 --> 01:20:07.680
Because if they are, it's not, it's not, it's not good for them as human beings and it's not good

01:20:07.680 --> 01:20:11.440
for society. And so that's where a lot of our, well, we're already seeing with Conmigo in the

01:20:11.440 --> 01:20:16.800
classroom is there is a segment of student who just runs with it and they are off to the races.

01:20:16.800 --> 01:20:19.600
And once again, no one should hold them back. I mean, sometimes the school system,

01:20:19.600 --> 01:20:24.880
temptation is to hold those students back. That is not a good idea. We want these students to,

01:20:24.880 --> 01:20:32.000
to move it as fast as they can. But how do we make sure that everyone has a, has a decent chance of,

01:20:32.000 --> 01:20:35.920
of being able to participate without holding people back is where a lot of our work is.

01:20:37.680 --> 01:20:42.080
Well, and you know, you've been involved in, in obviously been involved in education for

01:20:42.080 --> 01:20:47.680
almost 20 years. Con Academy has been around almost that long. Why do we have the old system?

01:20:47.840 --> 01:20:53.360
Why do we have credentialing at all where, oh, in order to get a job in a high profile place,

01:20:53.360 --> 01:20:58.960
I need a degree from Harvard. Why can't I just go to Con Academy for a year or two,

01:20:58.960 --> 01:21:04.960
learn what I need to learn and get a job at Goldman Sachs or Silicon Valley or Hollywood or

01:21:04.960 --> 01:21:10.320
whatever. Like, like what is, what is the real role now of, of higher education? Why can't I just

01:21:10.320 --> 01:21:17.360
use online education for that? I agree with you 100%. And you're starting to see aspects of that

01:21:17.360 --> 01:21:20.960
exist. You're definitely seeing that in, in fields like software engineering, where

01:21:22.160 --> 01:21:25.520
you know, the same employers that 20 or 30 years ago might have said, okay, we're only going to

01:21:25.520 --> 01:21:33.200
hire from MIT and Caltech and Stanford. They're now saying, hey, anyone can take this boot camp

01:21:33.200 --> 01:21:37.280
or take this assessment. And if you pass it, we're going to interview you the same as we would

01:21:37.280 --> 01:21:43.200
interview a, you know, 4.0 grad from Stanford. So that's already happening in, in, in certain fields.

01:21:43.760 --> 01:21:51.360
I think what you're going to see, and this is a passion of mine, is I do want to create

01:21:51.360 --> 01:21:58.080
competency based credentials that have the same or greater prestige as going to Harvard or going

01:21:58.080 --> 01:22:03.120
to Oxford. So much so that even if you go to Oxford or Harvard, you'll still want to get these

01:22:03.120 --> 01:22:08.720
things to show that you actually learned some, some very useful, very useful skills. So,

01:22:09.680 --> 01:22:14.960
you know, systems change is harder than technological change for a whole series of reasons.

01:22:14.960 --> 01:22:19.040
But this is something that I, you know, and hopefully I have many decades left on this

01:22:19.040 --> 01:22:23.840
planet. But I'm hoping in the next 10 or 20 years, hopefully closer to five or 10 years,

01:22:23.840 --> 01:22:28.480
you're going to hear some things even from us about ways that you can get high school,

01:22:28.480 --> 01:22:35.200
college credit, potentially even job opportunities via a pretty streamlined route. Once again,

01:22:35.200 --> 01:22:38.560
that doesn't mean that it's neither or you might want to do both. But if you don't have

01:22:38.560 --> 01:22:43.840
access to Harvard, which very, you know, I was telling some very senior people at Harvard that

01:22:43.840 --> 01:22:48.880
right now there's this false tension where they feel, you know, everyone writes about admissions

01:22:48.880 --> 01:22:55.520
and it feels like a false tension between equity and merit where there's like, oh, affirmative

01:22:55.520 --> 01:23:00.720
action that gets ruled down by the Supreme Court. So how are we going to make sure we have equity

01:23:00.720 --> 01:23:06.160
and that we have right, you know, good representation if we have to go more based purely on test scores

01:23:06.160 --> 01:23:10.480
or whatever else. And what I've told them is like, you know, it's a false tension because

01:23:10.480 --> 01:23:15.040
what you've hold, what you've held constant is capacity. Like you're, you're, you only,

01:23:15.040 --> 01:23:21.360
you only admit whatever 2000 students every year, even though there's probably 100,000

01:23:21.360 --> 01:23:26.960
qualified students every year. If you could, if you could serve all of the 100,000 qualified

01:23:26.960 --> 01:23:32.400
students, you wouldn't have to have these weird, bizarre discussions about admissions and equity

01:23:32.400 --> 01:23:35.840
and all of this that people are having, you would just be able to, if you're, if you can handle the

01:23:35.840 --> 01:23:40.560
work, we are admitting you and you will get a credential that can get, that can open up the

01:23:40.560 --> 01:23:45.200
world to you. So yes, I hope that we can, we can create some pathways like that.

01:23:46.400 --> 01:23:50.240
I think the part of that tension is, is the scarcity principle, which is that

01:23:50.800 --> 01:23:55.120
Harvard prices their scarcity. And so they make money from their scarcity. You and

01:23:55.760 --> 01:24:02.000
Khan Academy or let's say a commercial equivalent makes money from scalability as opposed to scarcity.

01:24:02.480 --> 01:24:07.360
And Harvard doesn't want to have 100,000 students. They want to accept only 2000

01:24:07.360 --> 01:24:12.160
because that loud, they get charged 300,000 a semester and they'd still fill up. And

01:24:14.800 --> 01:24:16.640
you know, I think, I think that's the tension really.

01:24:16.640 --> 01:24:21.120
Yeah. And, you know, and obviously our motivation is, you know, our costs go up as we scale. So

01:24:21.120 --> 01:24:25.120
our motivation is more of just like, well, how do we maximize impact? But you're right about,

01:24:25.120 --> 01:24:30.000
there is, there's always going to be a notion of scarcity and the reality of the Harvard's of the

01:24:30.000 --> 01:24:35.360
world. And so much of the education debate focuses on, let's call it about 30 universities,

01:24:35.360 --> 01:24:42.080
even though it's less than 1% of students go to those 30 universities. But those 30 universities

01:24:42.080 --> 01:24:47.920
are relevant because they, they do over influence society. And so I think there are,

01:24:49.040 --> 01:24:53.280
it's not going to go away anytime soon that there's a certain, you know, the US doesn't

01:24:53.280 --> 01:24:59.040
have a caste system in the traditional sense, but our, our elite institutions are the best proxy

01:24:59.040 --> 01:25:03.760
for them where, oh, oh, you're Harvard class of whatever, wherever, were you there? Oh,

01:25:03.760 --> 01:25:08.800
did you have this professor? Oh, wow. Like we're part of the same, part of the same club.

01:25:10.080 --> 01:25:16.000
I don't think that's going to go away. What I, and I think there's other positives of not just

01:25:16.000 --> 01:25:20.960
a Harvard or a Stanford, but college in general of being there in person, forming bonds. I met

01:25:20.960 --> 01:25:25.120
my wife and many of my best friends in college and we have our best memories there. So I think

01:25:25.120 --> 01:25:30.000
we can always optimize for some of those in person experiences, but I want to create also

01:25:30.000 --> 01:25:34.880
alternative pathways. So that's not the only way that you can get into an upper middle class or,

01:25:34.880 --> 01:25:40.960
you know, promising a career. On, on that optimistic note, and I, and I really hope you're

01:25:40.960 --> 01:25:46.560
right. I've been writing about this also for a long time. And, and I'm really looking forward to

01:25:46.560 --> 01:25:53.120
the utopian world that you have been outlining and creating and explaining particularly in your

01:25:53.120 --> 01:25:59.680
book. I'm going to say the title again, because I always forget things really quickly, brave new

01:25:59.680 --> 01:26:05.440
words, how AI will revolutionize education and why that's a good thing. And I think what you've

01:26:05.440 --> 01:26:10.560
explained today has solved a lot of the, also the fears that many people have about AI, but Salman

01:26:10.560 --> 01:26:16.320
Kahn, creator of the Kahn Academy, thanks once again for coming on the show. Thanks for hugging me, James.

01:26:40.560 --> 01:26:51.760
From a flat tire in the city to a dead battery on a distant drive, Triple A is partnering with

01:26:51.760 --> 01:26:56.880
T-Mobile for business to accelerate response times and get more drivers back on the road fast.

01:26:56.880 --> 01:27:01.120
Our nationwide connectivity powers location telematics so Triple A's fleet can find

01:27:01.120 --> 01:27:04.880
stranded drivers quickly while being fully equipped with the in-vehicle tools to have

01:27:04.880 --> 01:27:10.000
answers when they get there. This is elevating the member experience. This is Triple A with

01:27:10.000 --> 01:27:17.680
T-Mobile for business. Take your business further at T-Mobile.com slash now.

