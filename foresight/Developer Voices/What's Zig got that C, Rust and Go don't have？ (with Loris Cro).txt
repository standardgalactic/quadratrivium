One trend we've seen a lot in programming in recent years is the attempt to replace C.
And I think that's both wise and terrifying.
It's wise because C is about 50 years old,
and being old doesn't make it bad, but it has given us five decades to think about what works
and what doesn't work in programming language design.
We've got 50 years worth of techniques we really ought to be putting into practice.
And putting them into practice is the terrifying part, because C is everywhere.
You may not write C, but I guarantee you're writing something that runs on something that runs C
and was written in C.
It's in the compilation stack for everything we install.
So if languages like Go and Rust want to become the new C,
they've really got their work cut out for them.
All of which makes this week's topic kind of breathtaking.
We're looking at ZIG.
It's a language that's not only trying to take on C and C++ and Rust and Go
for that systems programming crown,
it's also trying to replace the infrastructure that C itself gets built on, things like LLVM.
So it can hopefully become the best way to build systems-level software across all different architectures.
ZIG ends up being a project with a huge scope.
And if you're a fan of programming languages, there is a lot to chew on this week.
We cover cross-platform compilation, to memory management techniques,
to new thoughts in compile-time metaprogramming.
As well as when you've got these huge long-term ambitions,
how do you structure an open-source project for long-term funding?
There is a lot of ground to cover, so this is a bit of a longer episode than usual,
and we'd best get started.
I'm your host, Chris Jenkins.
This is Developer Voices, and today's voice is Loris Crowe.
I'm joined today by Loris Crowe.
How are you doing out there, Loris?
Hello, hi, Chris.
Pretty good, thank you.
Good, good. It's good to have you here.
I always love it when we do a language deep dive,
because I'm a particular fan of the world's programming languages.
And you're going to tell us all about ZIG,
which is a language I don't think I've heard of,
until we had Joran Dirk Grief on the show from Tiger Beetle,
who said they've written a new database in ZIG,
and I thought, well, we have to do something about ZIG.
I have to learn about that.
So let's start here.
I always think new programming languages come into being
as a reaction to what's missing in the marketplace, if you like.
Like, there's a burning reason why ZIG needed to exist.
Do you think that's true?
What's ZIG's raison d'Ãªtre?
Right. So I guess a way of answering this question,
like, actually, is maybe to look at how it was created originally.
So the original creator, Andrew Kelly,
wanted to make a digital audio workstation software.
For making electronic music and that kind of thing.
Exactly.
And he tried a bunch of different languages
and he was unhappy with all the solutions,
with all the trade-offs that each offered.
So I think he started with higher level languages
and then quickly found out that to do real-time audio processing,
you can't use a language with automated memory management.
And languages that don't give you precise control over the hardware.
Yeah.
Because audio is one of the places where we're talking hard real-time.
Exactly.
Yeah.
You have to be there on time.
Yeah.
And but on the other end of the spectrum,
at the time, the main languages that did give you
full control over the machine were like C and C++.
And each had its own, like, if you will, baggage of issues,
which some of it is also up to, like, personal taste.
But for example, C is very low level,
but it doesn't have good metaprogramming facilities.
C macros are very well known for being not particularly good.
Yeah.
Yeah.
They're not much better than string mungent, right?
Yeah, exactly.
You mess around with strings and you have a lot of, like, unwanted side effects.
Oftentimes.
So it's a food gun.
That's how we usually think of it.
Yeah, yeah.
On the other hand, you have C++,
which I don't know if he actually did attempt to use,
but in general, C++ exists in a space
where the language is very powerful.
It's very complex.
And it's a type of language where you are heavy with abstractions, oftentimes.
And that kind of detracts from what you're trying to accomplish.
Or rather, some people can definitely make it work for them.
And that is their preferred way of programming.
So that's good.
But for some other people, C++ doesn't really,
you know, it doesn't feel good in your hand as a tool.
For some people.
Yeah, and I can see how people that we're not going to start a language war,
but you can certainly see how people would feel that way about C++.
Absolutely.
And to me, you know, this is not really a thing of language war at all.
Like, I can fully appreciate how somebody who likes that way of doing things
can make it work for them.
And but on the other hand, like, for me personally,
that doesn't that way of doing things doesn't really click.
So ultimately, I can totally see how somebody would be productive
with C++ and I wouldn't.
So I need a different tool.
Right.
And I think that Andrew also shares,
generally speaking, this perspective.
So he wanted to make a language that was
low level, so they gave you full control over the machine
that would be suitable for an audio workstation.
And that, on the other hand, it wouldn't be overly complicated.
And there's like a sentence that you can you can find in
like Ziggs on the website where we say
it's one of the first things that you can see on the front page.
It says focus on debugging your application
rather than debugging your programming language knowledge.
Right. Yeah. Yeah.
OK, so that's kind of I know people.
Anytime you write something that's sort of competing with C
in the low level world, someone says, why not go and why not rust?
But you yeah, you begin to demarcate those as
I'll let you answer it. Why is it not go or rust?
So the reason why it's not rust, I would say is
like the answer is very in a very general way.
It's kind of the same answer as why not C++?
I think that rust is another language that likes its own complexity
and it gives a ton of power from that, for sure.
But but the complexity is there.
And and also
when it comes to like giving you full control over the machine rust,
it's not entirely of that opinion like rust for good reasons,
for for safety reasons, rust wants to.
Religate certain things inside unsafe rust,
which is a part of rust that you are not supposed to use lightly.
So that means that you will find out their libraries that
when choosing between maximum performance in safety,
they will choose safety, probably overperformance, oftentimes,
because you do get audited if you have unsafe or not.
So in general, rust is going for something slightly different
than what Z is going for. OK.
So both in terms of like tradeoffs between performance and safety,
but also in terms of obstruction.
And I would argue also like readability in terms of like the complexity
because writing abstracted code makes it harder to understand and to read for for a consumer.
But when it comes to to go, I think they go and they both share.
An appreciation for simplicity, although go is not just simple,
it's also very minimalistic.
So I would say that there are like some parallels between Z can go,
but we don't have the exact same take on everything.
And I can get more into detail if you want later.
But but ultimately, go is not as low level as rust and Z are.
I am not sure if go would be the best choice for an audio workstation,
for example, or for an operative system, because go has a runtime,
has a garbage collector.
Also, interoperability with C is a bit complicated in go because,
well, first of all, everything, any language that has a runtime
that makes interoperability with C a little bit more complicated
because you need to give information to the runtime of your language
to the garbage collector about what's going on with memory.
And so that sometimes makes things a little bit awkward.
But we go specifically.
I do think that the for the go team, interoperability with C
was never a priority or something that they really liked.
So go can call C functions, for example.
But you cannot do the inverse easily.
So you cannot make a go function that can be easily called from C.
And I think basically this is like a philosophy of the go team.
Like they basically said, no, we want to do something different.
We don't want to do something.
We don't want people to rely too much on like we want to be able to consume
C libraries, but we don't want to do the inverse.
If you're in go land, you just go.
I think that's kind of their philosophy there.
Yeah, yeah, it's like we want to be able to reuse existing C,
but we're not intending to live in the same ecosystem quite.
Yeah, exactly. I would say that.
And you can see that also in a bunch of choices
that they made also with how compilation works in go
like in terms of the compiler.
But I think it's a reasonable choice.
It makes sense, very different from what Zig is going for.
Yeah, there's there's a I don't think we need language wars
because there's a huge design space to be explored.
And there's plenty of there's plenty of land for everyone.
Right. Yeah.
But OK, so that demarks what you want to be.
What's what's Zig's answer to this set of design constraints?
I think that.
I think the most interesting part about the answer to like,
let's say systems programming like lower level programming in general
is to rebuild it from scratch.
All these other languages that I own, not all these other languages,
but like it is common to consider kind of like see the bottom layer
of abstraction of what you're building.
So for example, there are programming languages that compile to C code.
Yeah, I think name is an example of this.
And Rust itself, it doesn't compile to C, but for example,
Rust depends on the C standard library of the platform that you're targeting.
So if you're writing a Linux program, like a Rust program
that you want to deploy on Linux,
Rust will use the libc of your Linux distribution.
With Zig, the idea instead is to really, really build
everything from the bottom up.
And this is a big scope.
This is not like for the faint of heart.
It's a lot of work, but it does yield some very good
results, like some very good things that you can do once you are willing
to do that work. So I would say that the most important
interesting thing about Zig is that it really is a language
that allows you to build for every target from any target,
meaning that if you want to target like not just normal computers,
but also very tiny embedded devices, you can do so easily.
And that's also cross compilation because you're like you're compiling
on a Linux machine, probably, which is going to be maybe X8664
and you're targeting a very tiny ARM V8 embedded device.
So you're compiling for different architecture there.
But this is also true from computer to computer.
So with Zig, it's a very it's considered fundamental,
the ability to build your program for Mac OS Windows Linux
from any of those other RSS.
So from Linux to Windows, from Windows to Mac, etc.
That's surprisingly rare.
Yeah, but a very nice feature.
And it doesn't end here because we can do this for Zig applications.
And to be fair, I think that Go can do it for Go, Rust can do it for Rust,
but they cannot do it for C.
Well, we can do it also for C and C++.
So the idea is that if you have a project that has Zig code in it
and also a C dependency, not only you can cross compile the Zig part,
but you can also cross compile the C part.
Really? Yes.
And that is, I think, the huge thing.
And it's so big that actually you can use Zig as your C C++ compiler
when you are trying to cross compile a Rust,
a mixed project between Rust and C or a Go and C one.
So, for example, Go people have been using the Zig compiler
to enable to complete the close the circle to enable complete cross
compilation of C Go programs.
C Go is basically what you call a project that has both Go and C in it.
C Go is like a component of their of the Go compiler.
That's how they compile in a link to C code.
So, people having using Go projects,
they are using Zig to cross compile and same with Rust.
Even AWS is using Zig to cross compile.
Rust lambdas for their lambda engines
because Rust depends on the libc of the target
and their machines running lambda functions
are running a specific version of Linux with an older libc.
And you need to be able to target the correct version of the libc
to make sure that everything runs smoothly.
Right. And that's not something that normally compilers can do.
And Rust itself, which doesn't concern itself with C compilation at all,
certainly cannot do.
So, they have there's a package called Cargo Zig build
that allows you to use Zig to basically link
against the correct libc version that works on lambda.
How on earth is that working?
Are you telling me that Zig also has a C compiler built in or?
Yeah, it does.
It straight up does.
And Andrew started out trying to build an audio workstation
and ended up building a language that also includes a C compiler.
Yeah, pretty much. That's legendary.
Yeah. And this is like, I would say we're like halfway through the journey
because we want to get even more hardcore than this.
So, I mean, if you want, we can change subject.
Otherwise, I can. No, I'm fascinated.
Keep going. Yeah. OK.
So, do you remember when Apple released the M1 architecture?
Right? Yeah, they went from Intel to ARM.
And that was big news because, well, turned out it's also pretty good CPU,
like pretty good architecture, Numex, I would say are pretty nice from.
Like they're powerful.
They overheat less. It's they're nice.
So.
When it will release the M1,
Zeke was the first compiler
that was able to cross compile for M1 from another target, from another machine.
So, Apple, obviously, when they really well, well, not only when they released,
but also while they were developing the M1, obviously,
they had a tooling to compile for the M1.
But they never released or other when when everything came out,
they had not released any tooling for compiling for M1 from another machine.
So you had to buy the new Mac in order to build for the new Mac?
Exactly, because what you would get was when you have Mac OS, you get clang.
You like you get a fork of LLVM, which is
yeah, it's I would say it's kind of pretty much LLVM, except with like private patches
that Apple makes specific to their system.
And when the M1 came out, they had patches specific to the new architecture.
So you could compile, obviously, from M1 to M1.
But LLVM itself, the open source project, did not support M1 yet fully.
And so you could not get LLVM like on Windows or Linux
and then use that to compile for Mac OS.
We were the first ones.
And that was because not only Zig is a C compiler and to be fair,
the C compiler stuff right now, I would say at its core, it's not super impressive.
The the idea is that Zig uses LLVM and LLVM is like this library that allows you to.
It's like a unified framework for optimizing for generating optimized machine code.
So the idea is that you your compiler reads the program that it's trying to compile
builds a data structure in memory, does semantic analysis,
all the usual stuff that our language has to do.
But then the final step is to give some of that information to LLVM,
which will then take care of selecting which exact instructions
to use for the for the CPU that you're targeting.
Right. So it's I suppose I want to say it's almost a little bit like WebAssembly.
It's like a very low level language is actually going to generate the final machine code.
Yeah, that's a bit of a stretch, but that's I think that's fair.
That's what that's the that's called the LLVM IR intermediate representation.
Yeah, that's what you create, which is a bit code of some kind.
And by code, sorry, of some kind, kind of like a WebAssembly.
I think that's a fair parallel.
OK. Yeah.
So we give that to LLVM.
And since we are already bundling all of LLVM,
it doesn't take much to also add clang, which is the C compiler that runs on LLVM.
So that's what's allowed us to build C.
There's more than it does, but at its core, it's not super complicated.
But but a compiler is just one step necessary to create an final executable.
There's also a linking page at the end.
So the main problem with the new M1 Max was that linking
needed to be different than it was in the past.
And the reason why we were the first ones to be able to cross compile for M1
was because we had our own in-house linker.
There's a core team member in the project.
His name is Jacob Conca, and he used to work in Microsoft.
And we kind of poached him to work.
Well, I guess he poached himself.
He wanted to work on on linkers.
I think at Microsoft, he was not working on anything even remotely as exciting.
And so he decided to jump ship and join the project full time.
So we have our own linker, and most of the work is done by him.
And so that my point here is that by having our own linker,
we were able to reach to to have a feature even faster than LLVM code.
And LLVM is considered in general like a very good project, and it is.
And it is. Yeah.
But by not the point is that we did not consider LLVM the baseline.
We were willing to get past LLVM and do some of that work ourselves.
And now going forward in this ties back to my point that we are only halfway
through our journey now going forward, we plan to make LLVM a completely
optional component.
So that means that we have our own implementation of some of what LLVM does.
So we have what we call them backends.
So we have our own implementation of what reads the internal representation
of the compiler, the internal data structures and the sides, which
instructions to output.
That's a lot of work because you have to build one of those things for each
architecture they want to support.
So you want to support x8664.
That's one implementation.
Arm 32 bit another arm 64 bit x86 like 32 bit x86.
That's another one.
There's more architectures out there.
So for each one, you have to write a specific one.
And then you have to write another bit based on the OS that you're targeting.
So like x86 64 Windows is a little bit different than x86 64 Mac, not in terms
of like the instructions of the program, but like the packaging, like how
an executable is structured all the like surrounding metadata, the frame in a
sense.
Right.
Yeah.
And we're doing it.
Now, the work that we're doing in that regard right now is not to replace
LVM in terms of optimizations.
So the bulk of what LVM does and what it's considered the state of the art
for is optimizations.
We are not doing that yet.
What we're doing right now is basically do the work so that we can have
debug builds, which are not optimized happen without needing LVM at all.
Oh, that's our starting point.
But the plan is going forward to basically have a competing, optimizing
backend.
So you will still be able to use LVM if you want, how it's going to happen
in practice doesn't matter much.
I think it's going to happen that you basically will need to get LVM through
the package manager.
So you will use the package manager to get LVM instead of getting it bundled
in the compiler itself, but then you will be able to get an LVM optimized
final executable regardless.
But we're going to work on our competing version and you will decide
which one you like more.
And over time, if we do a good job, it might even be that our competing
backend becomes compelling enough that people will use that one over LVM.
Crikey, you're not kidding about going all the way down to the lowest level,
right?
Yeah, geez.
Yeah.
Okay.
That's what's your timeline for that?
Ooh, that's got to be a multi-year project, right?
100%.
Yeah, for sure.
Honestly, I don't know what the timeline is going to be.
The reality is that the timeline of these things can vary dramatically,
depending on the amount of talent that you attract.
One thing that the people usually say when we first tell them, yeah,
we want to get rid of LVM, they start by saying, oh, you're insane.
You're never going to be able to do it.
There's a bunch of geniuses that work on LVM.
Fair.
Fine.
Let's assume that that's right.
I mean, I'm sure that the people working on LVM are smart.
But it's not like they are bound by a blood contract to work on LVM.
And if we work on LVM, it's a humongous C++ project that takes forever
to compile and it's in some ways like it's messy.
What if we were to be able to present to people working in that field
another ecosystem where they can research the same exact kind of
of optimizations that they are researching and implementing on LVM.
But the compiler, instead of taking four hours to build, it takes 20 seconds.
I imagine that would be very seductive.
And I think you're deliberately trying to seduce people over to the zig side,
which is fair enough.
And I mean, we already have people in the core team who have pushed access to LVM.
So it's not like we are like, well, I don't know anybody who is part
like the leadership of LVM, so I wouldn't say we are like insiders.
But we already know people who do this.
So there's a, sounds like there's potential for both knowledge sharing
and maybe some more kinds of sharing out there.
Absolutely. And absolutely.
And if LVM also ends up benefiting from this, it's great for everybody.
Sounds like one of those whoever wins, we all win situations.
Absolutely.
OK. This is getting very low level.
Maybe we should try and pull it back into a user space.
Love the ambition, though, absolutely.
But I do want to get a sense of what it's like to write zig.
What am I going to find as a programmer?
What am I going to like?
What am I going to need to learn?
Right. So.
The hardest part about the zig is not the at all.
Zig is a language is very, very simple.
The most complicated part of zig right now is comp time,
which is the ability to run code at compile time instead of runtime.
And if you're not used to thinking about the two different like.
Lifetimes of your program, the two different phases of its life,
then you might get a little bit confused about what it is that you can can do
at comp time or what it is that you cannot do at comp time.
But overall, the core principle is, in my opinion, kind of straightforward
where things get complicated is once you get into
systems programming more in general.
So if you were like a JavaScript or a Python developer
and you never had in your life to think about the stock versus hip,
or maybe people told you, but like if you're a Python programmer,
this is something that also happened to me like in university.
If you do Python and people told you about the stock versus hip,
that's like philosophy to you because that's yeah, right.
You don't have fascinating, but you'll never use this knowledge.
Exactly. Like you don't have control over it.
And yeah.
When you're getting to low level systems program,
suddenly this becomes a real concern, right?
Exactly. And so people, so the hardest part is, for example,
understanding the difference between an array of which of whose length
you know, you know, statically, like this is going to be a six element array
and it's always going to be six or maybe, you know, you need up to six slots.
Maybe at some point in time, you use fewer than those.
So you have like a counter that tells you how many slots you're using,
but six is the limit.
So and if you know this statically at compile time,
then this can be put on the stock.
And there's some things that you can do with this memory
thanks to the knowledge of the fact that it's bounded to six elements.
And you know exactly how much memory it's going to need
for the whole lifetime of the program.
Exactly. And that is critical information for the compiler itself,
like the language, lower level languages are like designed
around these very critical concepts of like what you know statically
and what you do not know statically.
So if, for example, instead, you have a program
where you ask the user to tell you how many items they want to enter
and they are allowed to enter 10,000 if they want,
or more realistically, imagine parsing a JSON file
like a JSON file can be arbitrarily deeply nested
or big in general.
So in that point, you need to concern yourself with heap allocation,
which again is something that in Python and JavaScript
you don't do directly because the runtime manages that for you.
Yeah. So that's one example.
Another example is all things that your platform
like APIs that your OS operative system gives to you,
which people sometimes are used to think about as in terms of capabilities
that the language gives to them, even though the language
can only act as an intermediary.
So for example, sometimes people ask,
how do I get the size of the terminal window in Zig?
And the answer is, well, the question, the real question is,
how does your OS allow you to get that information?
Right.
And then, and that's going to happen through a syscall of some kind.
And then the, I guess the secondary question is,
well, has somebody written the boilerplate to access that syscall
and where is it in the Zig standard library?
So the question of how you do this kind of stuff in Zig
or in each specific language, it's not completely wrong.
It does make sense.
But understanding what is the actual API below you
can be a little bit annoying, especially when the language
wants to show you precisely what that is.
And it's not trying to give you a sugared interface
that is overly simplified, because sometimes you do also get that
in other languages, which might make sense.
Like a higher level programming language, it makes sense that it doesn't
give you necessarily low level access to, like, to everything.
So I would say these are like the biggest challenges.
People need to learn systems programming.
They need to have this mindset where they have to think, OK,
how like for another example, people sometimes ask,
how do I print, call or text in the terminal?
How do you do that in Zig?
And the answer is, Zig doesn't concern itself with this.
Like these are escape codes.
It depends on which terminal you're using and a bunch of other related concerns
that really are pretty much transparent to Zig.
But people don't have this mindset.
So I would say that is the hardest part about learning Zig.
And connected to this, there aren't a lot of good learning materials, in my opinion.
So this sounds like the usual kind of young national language problem
where maybe there isn't a library for everything.
Yes. And there aren't there isn't documentation for everything yet.
Yeah, for sure.
But also, I mean, it's not like Zig has invented systems programming.
So it would be nice, right?
If there was some good piece of like a good book
that taught you the core principles without too much fuss.
And in fact, there are plenty of books that try to teach you these things.
It's just that in my experience, most of those that I've seen,
they tend to conflate C specific stuff with the OS.
So for example, you have this book that it's trying to teach you systems
programming and it starts by telling you about how the C compilation model works
and how that intertwines with like how libraries are
certain files are like laid out in your system.
And this is all real and concrete.
And it was especially real and concrete and concrete like 40 years ago.
But those concepts are like in other things like macros
and where things are usually in the system library.
But those are things that are specific to C.
So if you're not doing C,
a lot of these things are not as timeless as the book thinks they are.
While instead that versus hip, that one is much more timeless.
So personally, I think that we're missing learning materials
that can discern between really timeless systems programming concepts
like stock versus hip versus C isms that are not the relevant anymore.
Yeah, yeah, that's sort of a long life cycle, but not not mathematically pure.
You almost say, yeah, yeah.
OK, but so I would like to talk about how the C interrupt works
and maybe this is the way to do it.
So if I'm if I'm actually looking to get the size of a terminal window,
am I going to go looking for a sysop call and find
I actually have to do it through an OSC library?
And how's that going to play out when I actually start coding?
So, well, I guess it depends on the US.
Let's assume that the US is Linux. OK, for simplicity.
So if the US is Linux, you're in luck
because in Linux, the syscalls are considered a public API of the US.
So you are not forced to use the C library of your OS.
You can invoke the syscalls directly.
And in the case of Ziggs, since we like doing things from scratch,
you will find in the Ziggs library that we do implement the syscall,
which I think it's IOCTL.
This is called that you can use to get that information from the US.
So in the case of Ziggs, so in the case of Linux,
that's how you find that out.
But in other platforms, yes, you would have to use a C lib,
although we do have also bindings to the C lib.
So in practice, you wouldn't have to do everything yourself from scratch.
When it comes to like these very common things,
but let's imagine that instead you want to use like a C library.
OK, let's imagine that you want to use, I don't know, SQLite.
By the way, SQLite is a perfect example of a very popular library used,
for example, by Go.
There's a lot of Go projects that the bundle SQLite,
but SQLite is a C project.
So that's one major use case of people using Ziggs to do cross compilation
when they also want to bundle SQLite.
Anyway, you want to use SQLite.
So at its baseline, here's what you want to do.
You want to the way this stuff works in C is that you have C files
that contain implementations of things and have header files,
which are like files with a dot h extension.
And those files contain definitions.
So they contain they do not contain the full implementation.
They only contain like the signature of a function, for example.
The original kind of API docs, right?
Exactly. The original API docs, like they're there.
What's it called? Is it called Open API, I think?
The thing that used to be called this walker, it's basically like
it's a system to document like a restful API, right?
That's kind of the idea, except systems programming.
Yeah, so the way this works is that then SQLite comes with a bunch of C files
and one header file that you are supposed to include in your project
to get access to the public API.
With ZIG, you can do that directly.
So in ZIG, you can import a C header file and it will work right away.
Like you import that and you immediately get access to all the definitions in there.
Oh, interesting. OK.
So there's no kind of bridging file that you have to write.
Well, the bridging file, in a sense, gets auto-generated.
That's the idea. Right. OK.
So you don't see this.
And actually, if you do want, you can do that manually.
Like you can take the header file, translate it to C definitions.
And in case there's like the need to tweak something manually, you can do that if you want.
But the happy path, like the most common way you will want to do this
is to straight up import the header file and have ZIG do that bridging internally.
OK.
Then at that point, you can just straight up call all the SQLite.
Functions, they are defining there.
So you can you can just like go read the SQLite documentation
and they will tell you called. I'm making this up.
I don't remember how to use SQLite, but there's going to be maybe a test of the SQLite header API syntax.
Don't worry. OK.
So there's going to be some kind of SQLite in it function.
So you just call it and it works.
There's also a couple other things that ZIG does that help you with interoperability with C.
So, for example, C uses non-terminated strings a lot.
So basically, there's a you when you want to give to a function is string,
you give it a pointer to the beginning of the string.
And the pointer doesn't carry information about the length.
The length will be discovered by the function that you're calling by iterating through the sting
to the string until it encounters a zero character once it like a zero byte.
Once you find this, your body knows that the string is over.
Modern languages don't like to do that anymore.
Modern languages very much prefer something else.
I'll tell you my age.
I can remember when we didn't like to do it at the time.
So in ZIG, for example, normally a string,
it's not just a pointer to the beginning of some data without null in the end.
But in ZIG, we use slices, which other languages sometimes call five pointers.
So the tiny what you call the pointer is a pointer, but also a length.
So, yeah, you have both informations.
And to be fair, sometimes in C, you also have APIs that want a length.
No, they don't want to discover a null byte at some point, but they want you to pass in a length.
But those have have always to be two separate arguments,
two separate values that you need to move around in parallel.
Anyway, so how does ZIG help with the interoperability?
Well, string literals in ZIG are null terminated.
So basically, when you write, I don't know, Hello World,
and you want to use that string literal in ZIG, that's going to be a pointer plus a length.
I don't know how long Hello World is.
Ten characters, nine characters, whatever.
Pencil there, you include the traditional exclamation mark at the end.
OK, so you do have this information, but there's also going to be a null byte
past the end of the string.
So you can take a C, a ZIG string literal and pass it to C transparently.
No need to do anything else, and it's always going to work.
And more in general, ZIG does have a bunch of functions in the Sanda library
that allow you to deal with null terminated strings,
which are not the preferred type of string in ZIG.
Like you don't treat strings as null terminated normally, but
null terminated strings are a reality because not only because of C
interoperability, like in terms of SQLite, but also because of C
interoperability with the OS, like OS APIs, the lib C, that's C,
but also the Cs calls often time inherit some C ism,
some like some ways of communicating data that are like mirroring what C does.
Yeah, unsurprisingly, often the OS is written in C.
Exactly, because the OS is written in C, because that's maybe how people used
to do things at the time.
And so these things are still there.
Yeah. Yeah.
And OK, so to conclude, you have string literals.
You have a lot of other like operators in ZIG that you can also use
with C functions very easily, kind of transparently.
But just to name one, I think it's really cool.
You can use defer.
So defer is almost the same concept as goes defer.
There's like some minor differences.
But the idea is that basically if you want to.
Free a resource while when exiting the function, instead of making sure that
you call free or like file close, for example, like the whatever resource
release function you need to call, instead of making sure that you copy,
paste that call at every exit point of your function, what you can do is
on one line, you open a file and on the line below, you defer, close it.
Oh, OK.
Yeah. So you have basically a cleanup that you can put immediately
after the creation of the resource.
And whenever you leave that scope, no matter how you leave it, whenever
you leave that scope, that function will be called.
Yeah, because it's always deeply dissatisfying that you have to you
have to remember to stick the close call or the free up call at the end.
And it just screams this is going to get forgotten one day.
Yeah, absolutely.
So defer saves you from having to be too careful about like branching
paths in your function.
And if you look at it from a maybe it's not as handy as, you know,
what C plus plus can do with the array with the structures that run
automatically, you don't even have to write defer.
But C plus plus destructors only work with C plus plus defer in zig
also can be called on C functions.
It's completely transparent.
So there's this funny end result.
We were basically zig, in a sense, is better at using C libraries than C
because the same cleanup routine in C would require you maybe to even use go
to like it's not uncommon for people to use go to and have like a label
like a section of the function with all the cleanup functions.
But it gets really messy.
Like I don't think I am able to fully convey how messy cleanup can get in C
because it doesn't have the fur.
I can believe.
Yeah, absolutely.
That's interesting.
That's interesting still being in C, but building on it with new syntax.
I have to ask before we leave this particular thread, what about pointers?
The pointer, does pointer arithmetic come into zig?
Pointer arithmetic can come into zig.
By the way, that's a great point.
I was forgetting that's another great improvement over C that also helps
beautifully with interoperability.
So you can do pointer arithmetic in in zig if you want to,
because because that's what the machine allows you to do.
And maybe occasionally some OS API will require you to do so.
But in general, you do not do pointer arithmetic in zig.
And specifically in zig, you cannot do so in the type system.
You are not allowed to do arithmetic on pointers.
What you have to do is take your pointer, convert it to an integer,
which is not like an operation that does anything at runtime.
It's just like a type system thing.
Like you have to be explicit about taking a pointer,
interpreting it as a number, apply the math to the number
and then convert it back to a pointer.
So you can do it if you want, or if you need.
Probably if you need, you shouldn't want the language.
It's not going to make it easy or like very comfortable to you.
There's a little bit of friction introduced there.
And on the flip side, it helps identify very quickly
where these kind of shenanigans are happening.
Right. So it's mainly there for the sake of C interoper,
rather than writing zig day to day.
Exactly. And I mean, we say C interop, but I don't know.
There might be other things out there like I'm thinking of firmwares,
like your programming tiny embedded device, and you need something like this
because of the very low level stuff that you're doing,
which is not really necessarily specific to C anymore.
But it's like low, super low level bit fiddling.
Maybe at that point you need something like this.
But otherwise you normally don't.
And still related to pointers, there's another crucial thing.
Pointers in C are very under specified in the sense
that you see a char star, so you know it's a pointer.
And when you dereference it, you get a character.
But then the question is, can the pointer be null or not?
You don't know. Maybe documentation tells you, but you're not sure normally.
The second question is, OK, I'm getting a character at the end of this pointer.
Assuming it's not null.
Now, is there going to be just one character on the other side?
Or is this like a string?
Is this like expected to have another character afterwards
and another one afterwards until I encounter a null?
Is there going to be a null or am I supposed to know how many items to get
because of another variable?
This is not encoded in a type system at all in ZIG.
All of these are different type of pointers.
So if a pointer can be null, it's an optional pointer.
So we do the thing that all modern languages are doing
where you have the concept of optional and then you need to unwrap the optional.
And we use that to represent null pointers.
But then we have types for.
So you have normal ZIG slices, which are a pointer and in length.
But then you have a C style pointer that can be
that's going to be a pointer either to one item, one specific item.
So you're explicitly saying there's going to be one character, one chart.
Again, not many.
Or there's a syntax for saying, no, this is like a pointer
to a unknown number of characters.
So there's specific syntax and it's going to tell you,
yes, this is a pointer to many items,
but the pointer itself doesn't tell you how many.
And then there's a pointer to an unknown number of characters
with a null terminator at the end.
And this is in the type system.
So, for example, if you by mistake think that
you're trying to create a string off of another string.
And so like you maybe take a tiny slice from the middle of the string
and you try to pass it to another application
and you forget that that API is expecting an alt terminator at the end,
which is not going to be there because you just split off like a tiny
like two characters from the middle of a string, right?
So there's not going to be an alt terminator on the other side.
The Z-type system will tell you, it will give you a compile error
because it will tell you, I'm expecting an alt term into the string.
But the operation that you like,
the slicing operation that you did on the other string
does not yield an alt terminator string.
So you will get a compile error right away
instead of having your program read random garbage
and maybe sometimes crash.
Yeah, yeah.
That's that's one other question I have to ask you then,
because I can see right now this appealing to people that need to use C,
don't want to use C, got into Rust, didn't make friends with the borough checker.
Yeah.
And now have could find ZIG being the ideal place
if I want more type safety around C, particularly around strings.
Yeah. What about memory management?
Because that's the other big sticking point.
Right. Yeah. Agreed.
So in general, so if we want to talk about.
If we want to talk about ergonomics, what I just what I described earlier,
like the first statement that really helps a lot with memory management
because you allocate a resource, defer, free it, and you're good to go.
You need to have an explicit like malloc free call in ZIGLAND.
Exactly.
And to be even more concrete about this,
ZIG does not have a global allocator.
So in C, you have malloc and malloc is like the allocator
and maybe different projects use a different implementation of malloc.
There's like a few competing implementations, but in ZIG libraries,
there's this idea that in C libraries, there's this idea that you have
malloc coming from the ecosystem that allows you to allocate memory
in ZIG allocators are always passed around explicitly.
So if a function wants to allocate, it needs to accept an allocator as input.
Interesting.
Yeah. So this makes it more easy, dramatically, more easy to audit
what it is that's allocating memory or not.
If a function doesn't accept an allocator or a data structure
that bundles the allocator in it, like it's also like, for example,
we have a RayList, which would be like equivalent of a C++ vector.
So like it's a growable array, right?
When you make an array list, you give to it an allocator.
And then when you pass around the array list,
the array list will be able to allocate
because it bundles a reference to the allocator inside of it.
That's for convenience.
But in general, you can very quickly audit
if a function can allocate or not.
Does that help you audit if a function is forgetting to deallocate?
That by itself, no.
What it helps is that the doing that is that the what we call
the general purpose allocator, the main allocator implementation
that you find inside of Z in the standard library.
That allocator in debug mode has leak detection.
So you cannot check statically if all allocator allocations are
afraid or rather you can't unless you're willing to become Rust.
Rust can.
With all the limits, they also have limits on the type of like
memory management strategies that the borrower can understand.
But they can.
We can't, but we can instrument the default allocator with checks
for leaks in the bug builds.
So when you run your tests, basically the allocator will fail
the test if at the end of it you have like still memory allocated.
Okay.
And that's default built in part of the tests we don't have to
specifically instrument.
Exactly.
You don't have to do anything.
Oh, that's nice.
Yeah, there's another angle to this also, which is that it is
correct for programs to want to leak memory occasionally.
In this sense, I'll use the Z compiler itself as an example.
So the Z compiler, when built in the bug mode, we'll make sure
to free everything when built in release mode, it will not free
once it's about to leave.
It will not free memory when it wants it's about to live to close
because the OS will clean up that memory anyway.
And there's no point in freeing every single item that you've
allocated if your program is about to exit.
Like making sure to free tiny things makes perfect sense when
your program is going to use a ton of memory, or it's going to
be super long lived, like otherwise it's going to consume
more and more memory over time until it eats all the available
memory and everything explodes.
Yeah.
But for like, let's say one shot programs, kind of like a
compiler is like you run utility, it runs to the end and then it
closes cleaning stuff up at the end.
It's just wasted time.
So have you ever used like Visual Studio?
Not for so long.
Yeah, I can't believe.
Thankfully, I haven't had to use it in a while now, but a few
years ago, like seven years ago or something, I had to use it
consistently.
And it drives me nuts that when you close it, not only it takes
forever to load, that is already not okay.
But when you close it, it takes forever to close.
Why?
Why is it taking forever to close?
Because as it's closing, it's trying to free and run the
distractors of every single component and sub component and
sub component.
I have a vague memory of doing this with Eclipse and just
getting into the habit of force quitting because who cares?
Exactly, exactly.
And Eclipse is another in Java, I think it's another language
that has distractors and and so kind of makes people want to use
them a lot.
But then there's moments where you actually really in terms of
like functionality that you're offering to the user, you don't
want to do it.
Like you just want to close it right away.
Yeah, so long story short, I made this point because in
reality, it is a legitimate behavior to have the program in
specific circumstances, like memory, if you think about it.
Because like for real, like the user experience would be
generally significantly improved in both Eclipse and Visual
Studio, if the thing just exited right away.
Of course, you do want to have a toggle like a flag that makes
sure you free all the memory cleanly so that you can guarantee
that you do not have unwanted leaks.
Like Visual Studio, for example, is a long running program in
Eclipse.
Yeah.
So they should not be leaking memory in the normal operations.
So it's not.
So you still want to be able to test for that.
There are like two minutes.
There are at least two memory management strategies.
One is be very careful about what you're using because it's a
limited resource.
Yeah.
But for the long run, you know, whatever memory you're using at
the end, you can just drop on the floor.
Right.
Exactly.
Yeah, yeah, that makes perfect sense.
There's one other big thing that you've talked about a little
bit, but I'm tempted to run over our usual time slots.
I'm fascinated by this.
Go for it.
I'm not in a rush, for sure.
Good.
So comp time, you talked a bit about that.
And as an old list programmer, this is a concept that makes sense
to me, but I think it's never really gone mainstream.
So why don't we talk a bit about the separation between runtime
programs and compile time programs?
Sure.
Sure.
So let me tell you about how Zig does this more specifically.
So comp time in Zig is interesting because Zig as a language
doesn't have runtime type information.
So for example, in JavaScript, Python, also in Go, you can ask
questions to the program running at runtime about its types.
C programs, on the other hand, don't have a runtime, and they
don't have runtime type information.
Usually it's not always the case, but usually runtime type
information tends to go hand in hand with an actual runtime of
the language.
So for example, in Python, you can create new types at runtime.
You can do introspection.
And so having a runtime that can yield those dynamic properties to
you usually benefits from having runtime type information.
C doesn't have those facilities because a struct in C at the end
of the day boils down to offsets in memory.
Oh, the struct is, I don't know, 16 bytes long and eight bytes in.
And it contains two fields.
The first field is at offset zero and the other one is at offset
eight, and that's the end of it.
So everything else has disappeared.
But it is useful to be able to inspect types and reason about
types at least statically.
So that's what ZIG does.
ZIG does not give you runtime type information, but it does give
you com time type information.
So you are not allowed, you're not able to create new types at
runtime, but you are able to create new types at compile time by
reasoning on other types.
And the way you reason on other types, and by the way, this is
also what generic does in other languages.
It's just that this is usually done in other imperative languages.
This is usually done with a funky declarative syntax and a bunch
of diamond brackets where you use diamond brackets to denote
like the generic type and then to put constraints on it using
like some kind of declarative syntax.
Like I want type T to be, I don't know.
To conform to interface A or interface B, et cetera.
Okay, so you're using, you're saying you're using com time to do
things like I want a list of As, but now I need to pin it down
to be a list of eight bit integers.
Yeah.
Yeah, okay.
Because you can, because the idea is that you are creating a new
type by referring to another existing types, another existing
type.
And the way you do this in Zig is not via these custom syntax,
but by using normal Zig syntax.
So literally a list, for example, let's say you want to make a generic
list and you want then to be able to make a list of integers,
a list of characters, whatever.
The way you implement this in Zig is that you create a function
called list that accepts a type as input, which has to be marked
as a com time parameter.
So like the signature would literally read fn list, open parentheses,
com time t column type.
So it's a com time parameter named t of type type.
You have to pass in a type.
And so that could be like integer or whatever.
And then this function returns another type.
And in the function body, you create a, you create a struct,
you return a struct definition that places,
that defines the payload field, like a struct probably that has
the payload field of type t, what you passed in,
which is kind of like generic's work.
But it's normal procedural Zig code that gets executed compile time.
So for example, you could create like an,
let's say you're making a simple array, but the length of that array,
you want to be the result of other reasoning.
You could create a Fibonacci function, run it at com time,
and say that your array is long the 10th Fibonacci number,
which I don't know how much it is, but it's not going to be 10.
It's going to be a bigger number.
Right.
So you can call normal, run normal Z code.
It's going to be interpreted by the compiler while compiling.
And usually you do have some of that in other languages.
It's just not fully general purpose.
They give you restricted language to specify properties
and they have their own special rules in Z.
It's just you run the Z code.
And the compiler has like a concept of a execution quota.
So that like, for example, if you make a mistake and you try to make,
you make an array that is the 1000 Fibonacci number,
but your Fibonacci implementation is very bad.
The compiler after a while is going to tell you
I executed like 10,000 loops.
And I, and since we couldn't come to a conclusion, I gave up.
And if you really think this is, this is not like an infinite loop,
then you can pull up that number,
like the number of executions before giving up and we're going to try again.
But so that way basically we, the compiler is how it deals with like infinite loops
and undecidable stuff.
Yeah. So you're protecting against people making,
accidentally making compile time infinitely long.
Exactly.
Yeah. Yeah. Yeah.
And Alan Turing has opinions on why you can't automate that.
Yeah, exactly.
So, and you know what?
In our case, I think it's fine in practice to solve the indecidability problem
by just giving up because ultimately, like you're trying to compile a program
and you're not willing to sit there forever
or up with radical long to have it compile.
So yeah.
Okay. So this raises two natural questions.
And the first has got to be, what's that like as a,
as a programmer?
Because most of us are used to using like diamond brackets for generics.
Do you prefer the zig way?
Does it feel natural once you get used to it?
I think it feels insanely natural.
Like you mentioned earlier, Lisp to me,
by the way, I also love Lisp.
I've never used Lisp professionally,
but like in university, definitely one of my favorite subjects.
And I also loved writing macros in Lisp.
And it feels like writing macros in Lisp.
Or actually, I would say it's even better than writing macros in Lisp.
Yeah, the spice opinion.
Well, so what I think happens with Lisp is that people say macros in Lisp are nice
because Lisp is an almost iconic language.
So the language itself is the data structure that represents it.
It's the list, the, well, the symbolic expression that represents it,
which is fair.
But I do think that the actual truth is that by having the program be a data structure,
you are naturally, the language is steering you naturally towards treating
the program as a data structure instead of it being a textual transformation.
And in fact, you can write macros in Lisp that don't generalize really well,
that like make assumptions about a specific like argument being,
being or not being a list or being or not being quoted, for example.
In ZIG, you are literally,
comp time is more limited than what you can do with list macros just to be clear.
And that's also kind of by design.
It's kind of like a 80-20 thing.
Like it gives you 80% of the power, but it saves you from the 20% of really cursed stuff
that people will want to do all the time or rather with 20% of the complexity,
which does save you from cursed stuff.
In ZIG, what you do is like the, when you look at the time, you literally call a function,
like you call at type info and you pass in a struct.
So let's say that you made a struct called named person and person has age and name.
And then you call type info on person and what you get back
is a data structure that contains, like it's another struct that contains all the info about
that type. Like among other things, it will contain like an array that contains the two fields
with information about how the field is called, what's the type, etc., etc.
And so your metaprogramming is always going to look at the program as data and never as
syntax. And I think that's the key that makes come time weirdly, weirdly natural.
Okay, yeah. Yeah, it does remind me, I mean, the frustration with Lisp macros was always
that they were untyped and you could really cause things to explode in an even more spectacular way
than normal Lisp. Absolutely. But the nice thing was that there was absolutely no difference between
writing programs that work to compile time and runtime, because it was the same tools,
same language, same everything. Exactly. And it's the same for zig. Because you do use the same
syntax. You like, I have an example on a blog post that I've wrote, trying to introduce people to
the concept of comp time. And my favorite example in there is this idea that, which is actually
taken from real life experience. I was writing a Redis client for zig. And in Redis, you have
commands, like the query language of Redis makes you write commands that are case insensitive.
So if you write it uppercase or lowercase, it doesn't matter. So at some point in my client,
I wanted to recognize some of those commands. So I wanted to check for equality between two
strings. And my idea was, well, to slightly, very slightly improve the performance of the comparison
function. If I know that the constant string, like the string literal that I hard code in my
program that I used to check the user provided string against, if I know that that one is always
going to be uppercase, I can simplify the comparison code ever so slightly. I can just remove one
branch from the comparison. But now I have, I want to enforce that when you call my equal function,
you always pass in the first argument, the argument that you're passing,
like the first argument that you're passing is always going to be uppercase.
Right. So you want some compile time code to check those strings are correctly written.
Exactly. Now, imagine trying to do that with diamond brackets stuff. I have no idea if you
can actually even pull it off. Here's what you do in Zig. In Zig, in the function body,
you open a comp time block. Well, first of all, you have to mark the first argument as always
being available at comp time. So people will be forced to give you, it doesn't have to be a string
literal directly. It can be like a variable name. But ultimately, the value containing that variable
needs to be resolvable at comp time. It doesn't need to depend on weird stuff like the network.
So you open a comp time block, and in there, you have a for loop that loops over the string
and checks that its character is in the correct range. That's it. That's all you do. Nothing
weird. You just use the language to check the string character by character. And if you find a
character that is not in your expected range, so in my case, it was between uppercase A and uppercase
Z, what you do is that you emit a compile error. And you can emit a compile error that says, well,
you are supposed to give me a uppercase string, and you didn't give me an uppercase string because
this character is lowercase. You can even be precise and print the string and point out a
point at the specific character if you want. You can craft the message whichever way you want.
And that becomes the compile error. And so now, users of your API, not only the constraint is
enforced, so if they give you a bad string, they will get a compile error. But the compile error
is also going to be designed by you. So people will get a nice compiler from the compiler that
will tell them you are supposed to pass an uppercase string, but you didn't.
Nice. Yeah, so you can start doing bespoke compiler extensions, and you don't have to learn a new
language to do it. No. That's pretty sweet. Okay. Okay, that gives me a good sense of the
footprint of the language. So there's one other big topic I think we should talk about,
which is, I thought it was really interesting the way that the Zig project is funded, right?
Because every language, particularly in every open source project, has a problem with getting
enough work done because you've got to give up your day job if you really want a language to
take off. Yeah. And your approach, Zig's approach to funding is fairly novel. Tell me about that.
So Zig is a 501c3 non-profit foundation, U.S. non-profit foundation, like 501c3 is a
thing in the U.S. legal system. It's been kind of set up like a charity.
Yeah, it's exactly what we normally would consider a charity. So it's tax exempt,
and you cannot pay dividends. So all the money that goes into the organization has to be used
to pursue your mission. So basically, you have to use the money to run the company. You can take
it out and buy a yacht with it or whatever I mentioned. Zig is not the only language that
has this legal structure. Python, I think, is also another 501c3. But not all languages are that.
Some other languages are a different type of... It's still considered non-profit, but it's a
different type of organization and which does have to pay taxes. This is what is... Usually,
it's 501c6. Like, it might seem that there's not much of a difference between 3 and 6, especially
because it's a place where we normally, in like, the marketing versioning, we would have like,
the patch number. So you think, oh, c6c3, whatever, it's like... They fix the bug in there. No,
that's a huge difference. We're not always consistent with version numbers, but my
god, lawyers, they can really change the rules between versions.
So, Zig specifically leaves mainly off of donations. So most of our income comes from
people donating money to the foundation so that we can move forward with the development of Zig.
Some money also comes from other things. So it's only... It's mainly donations from individuals.
We do have also a good number of donations from companies, but I think in terms of like, if we
were to do a pie chart and plot them both, they would, I think, roughly be balanced. So
we do try actively to keep a balance between our sources of income, because we don't want to get in
a situation where like, one entity or like a very small number of individuals end up having control
basically over the foundation. Maybe not directly, right? Not legally, but if they control the money
flow, then ultimately they do control the destiny of the organization. And we do want to be able to
say no to people. We do have support contracts. All right, we have one with Uber, because Uber
is using Zig to cross compile. They are cross compiling, I think, as of today, all their
backend services that require cross compilation because of ARM servers, mainly. So like, they
wanted a while ago to be able to have ARM servers and not just Intel, well, XAD664. And so they use
Zig. And now they did the work to actually make sure that all their C and C++ stuff
cross-compiles correctly. And yeah, so they have a support contract with us. But then again,
it's not a huge chunk of our income. And that is mainly when it comes from income. So
related to this, also, we kind of want to be independent. And we're very serious about this.
Like, we used to joke that like the, because, you know, people sometimes say, oh, if you want to,
if you want this, your language to succeed, like, you cannot make a successful language
unless you are supported by a big tech company. And we kind of beg to differ, but also
our standard offer is how much money whatever big tech company wants to give us in exchange for
0% of the foundation and zero seats in the board of directors. But they do get Zig at the end.
So they do get something at the end. Yeah, yeah. There is some quid pro quo, but no power.
No power, no control at all, zero, absolute zero. And because we really want to make sure that we
like the Zig is a BDFL run project. So also compared to other languages, we basically
ultimately have Andrew, who is the creator who acts as like the ultimate decision maker. It's
not only him, there's a core team, there's people, there's a process which is also very public,
like you can read proposals to change the language on the GitHub. And discussion happens in public,
and actually anybody can chime in. But for example, it's not a democratic process, like if
feature proposal has a huge number of outputs that counts zero towards the decision of whether
to include that feature of or not in Zig. Right. Yeah, that usually that has some downside,
but usually has great upsides for design consistency. Absolutely. And it's absolutely,
in my opinion, fundamental, if you want to have your language stay small, if you don't want it to
eventually devolve into a kitchen sink. Yeah, that's true. And there was a talk by the creator
of the Elm programming language recently, that I think dove into, dove into this general concept,
I think in a very nice way. Basically, I'm paraphrasing and I'm going to oversimplify.
The talk is titled The Economics of Programming Languages, I think. It's from a strange loop,
and well, it was given a strange loop. I highly recommend it. But the bit that I'm interested
about was said something along the lines of languages that are like 501c6s, like more
corporate languages that end up having like a bunch of organizations come together into a kind
of consortium or like a trade association. They basically look at the language as a marketplace.
They look at the shared infrastructure and all the commerce, all the commerce, all the business
that this thing can support. So which is reasonable, right? You look at a language like
I don't know C sharp or Java, and those languages do enable a certain type of commerce.
So from their perspective, they want the commerce to be as much as possible. They want to give the
best market to their organization members. And so if an organization member wants something,
because it helps them do their business, you have a strong incentive to say yes. And whoever
doesn't need that feature, they cannot use it. They can disable it. They don't have to use it,
right? So there's no point in saying no to people if your goal is to enable the have the biggest
possible market. But as technologies, we know that, well, there's some downsides from that, right?
Once your language becomes a kitchen sink, then it's like, it's not good over time. So there's
huge value in keeping your thing small and consistent. And I think that's what you get by
choosing 501c3 over 501c6, or rather not going down the path of making your
organization like a trade association.
Yeah, yeah. It's interesting the thought that that one decision, how you're structured
as a company, or as a financial organization will influence how you're designed as a language.
Yeah, it has huge influence. People, programmers, don't want to think about this stuff. They like
to think, oh, I just want to focus on the code, which is, it's a sentiment that I can understand.
Frankly, I would like to only focus on the code. But the hard lesson that I learned is that
to have the best technology, you have to get right the business side. Like the business
side comes first. Every time you make a mistake there, the technology will suffer.
It will, in the long run, it really matters. In the short term, it doesn't. The long run,
it has a huge effect. Yeah, that's true. Okay, well, I'm very glad we diverted into comp time,
but we should probably wrap up and let the listeners go to run time. How's that for a segue? So
yeah, if someone wants to get started with ZIG, I know you have LSP support, you have a VS code
plugin, you've got all the quality of life things for a new beginner, but where should they start
learning? My recommendation would be go to the official website, ziglang.org, and there there's
a learn section. The learn section has a guide on how to download ZIG, install it, and it also
links you to some learning resources. Personally, among those, the two, actually the three main ones
that I would suggest is, as a starting point, the language reference, the documentation that
tells you about the language, not the Sunday library. That one teaches you specifically
about like syntax of the language, and it's one page. It's one long page, like it's not an A4
or US letter page, but it's like just one page is not huge. And you don't have to read it all
precisely, you can scroll through it. But that one gives you baseline understanding of ZIG.
Then from there, I would suggest if you don't have like experience with a lower level programming
and you want like a very smooth learning curve, ZIG links is the best starting point in my opinion.
So ZIG links is like a community project where basically you clone the repo and you get a
collection of very tiny programs that don't compile or that don't behave correctly.
Yeah. And the comments tell you how to fix them. So you go one by one and you, the comment will go,
this program is supposed to print all award, but it doesn't fix it. And that's going to be super
simple, right? You're going to just fix the string literal. But then going forward, the
exercises will become very smoothly, but they will become harder and they will require you to
understand more of the syntax.
You know, I think that's how I learned closure. They had a similar thing called, I think the
closure cones as like a series of failing, small failing programs that you have to fix
and you gradually learn the whole language. It's a lovely way to learn a new language.
Yeah. ZIG links is very, very, very popular. I would say it's probably the most popular
piece of educational content in the ZIG ecosystem. And the name ZIG links is also inspired by
Rust links. Because Rust also has it. The same thing. And they call it Rust link.
Right. Nice. I will link to both of those in the show notes.
But for now, Loris, thank you very much for joining us. It's a fascinating language with
almost more scope than C, which I can't believe.
It has pretty much all the scope of C. It tries to fix all the things that C,
for some reason, never wanted to fix. Think about it. Why is ZIG able to cross-compile C?
And a C compiler is not going to be able to give you that out of the box. We didn't get into this,
but you get a ZIG compiler and you write hello world in C and you can compile it from Linux
to Windows. Try to do the same with Clang. It's not going to work.
I'm not even going to try.
Yeah, but it's insane. So yeah, the scope is all of C. All of the things that C
should have done that he didn't do. Well, that's a little bit extra.
Nice. That's enough to keep us busy for a while.
Yeah.
Loris, thank you very much for joining us.
Thank you.
Thank you, Loris. Since we recorded that conversation, I have been playing around
with the Zieglings tutorial he mentioned. And yeah, I can confirm it's a nice way to learn.
I'm also planning to find time to pull out my old Arduino microcontrollers,
because I've dabbled with kind of embedded hardware in the past. I've never really been
happy writing C. I've loved using Rust, but it's been a fight to get things to compile
onto the embedded hardware. So hopefully, Zieg is going to finally make me happy when I'm tinkering
with soldering irons and wires and LEDs and stuff. In the meantime, I leave you with links to the
everything we've discussed. They're all in the show notes. There is a wealth of information
out there about Zieg, how to learn it, what it does, extra features we didn't get a chance to cover.
And I'll leave you with a funny story. If you install Zieg and type Ziegzen, it will tell you
why it exists. I'll let you go and discover that. Before you go, please do take the time to give us
a like or a share or a rate or a review. It is the easiest way to let us know which topics you
find most interesting so we can do more episodes on those kinds of topics. And if you haven't already,
click subscribe or follow to catch future episodes. And until the next episode,
I've been your host, Chris Jenkins. This has been Developer Voices with Loris Crowe. Thanks for listening.
