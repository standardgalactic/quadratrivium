{"text": " One of the areas of computing that I'm really curious about, and I think the software world has a lot to learn from, is game programming. Probably not on a surface level, I've never worked for an e-commerce company that needed collision detection. But get below that surface, and a lot of modern games, especially once they go multiplayer, they're dealing with things like global networking issues, multi-user concurrency, competitive concurrency, massive data volumes, under brutal latency requirements. They have a lot of the programming issues that we're familiar with, but under much harsher conditions. And being a somewhat separate world, they tend to approach the solution from a novel angle. So this week, we're going to go digging for system design ideas in the gaming world. And my guest for this is Tyler Cloutier. He's got a background in distributed systems and data science for the gaming industry. And he's currently building BitCraft, which is a massive multiplayer open world game, and to support it, a really interesting flavor of database called SpacetimeDB, from which we're going to mine some ideas about concurrency, transactions, data security, query management, lots more. A lot of juicy ideas solved from an angle that I'd never considered. So let's get going. I'm your host Chris Jenkins. This is Developer Voices. And today's voice is Tyler Cloutier. My guest this week is Tyler Cloutier. How you doing, Tyler? I'm doing well. How are you? I'm very well. You're going to take me to a new world for me, because I have a long history in programming, but one thing I've never done is computer game programming. And along with that, the one thing I've always wondered is they must have a lot of the same problems that the rest of us industrial programmers have, not like the dealing with graphics and story and stuff, but then there are data problems everywhere, right? That's right. Actually, I would say what I have experience is that they have the normal problems that everybody else has, but times 100, because not only do they have to build the thing, but it has to interact with all of the data in the program besides just sort of individual parts. And then it has to go really, really fast. Yeah. Yeah. All our problems except at 60 times a second. That's right. Yeah. So your background is originally in game design or data science for games or what's your origin story? My original background is actually in chemical and biomolecular engineering, which is completely unrelated to games. And then I did my master's in computer science focusing on distributed systems and machine learning. After that, I did some time at Bloomberg and then Apple and then a company called Machine Zone, which is a game development company. Right. And what did you do for them? So there I worked in their data science and engineering department as a data science engineer. And there we were building two things. One, pipelines for data. So making sure that we got the real live data as quickly as possible into a form that we could then feed into our models. So then the second part of what I did is also build those models, which predicted various things about how players are likely to behave. So like, how likely is this player to turn? How likely is this player to spend money? Will they give us a good review? That kind of thing. This is a pay to play game. This is a free to play game, actually, that is quite expensive. Ultimately. Because it's the business model where like most players don't pay anything, but some pay for like cosmetics upgrades, that kind of thing. And they spend a lot. No, no, it's much worse than that. So it's a mobile game. And it's the whole idea of the game is it's supposed to simulate what it feels like to be a king. And so what that ends up being is that you have this little city, it's called the forex game, which is for the four different types of play that you're going to do. And you build the city up, you upgrade your buildings. And then you can start sending marches out to attack other players. And ultimately, you want to capture a what's called a wonder, which will give you make you the king of the kingdom. And the process of capturing that wonder is quite an expensive endeavor. So the way it works is that they sell you speed ups. So upgrades take time, you can speed things up by paying for it. And some people pay quite a lot. There were individuals who spent upwards of several million dollars in that game. Several million. You heard that correct. If I did not see it myself, I would not have believed it. Gee, I can't, I struggle to compute why someone would do that and how they can be rich enough that that's their disposable income. There were Saudi princes, there were people of that kind. I mean, it was a global game. And so it attracted a lot of people who were interested in simulating what it felt like to be a king. There was one person who was rumored to have hired at least one person or a team of people to actually purchase and open the packs because it's actually mechanically a lot of work to open a $1 million worth of $100 packs, right? That's 10,000. That's 10,000 packs. So there's that. There was another person who used to fly his entire alliance out to Las Vegas to be closer to the servers so that they could do the Super Wonder event more effectively. That's, I mean, A, that's really weird, but B, is it that much weirder than traders putting their computers right by their main exchange? I don't know. I don't, I suppose not. I mean, these people really cared about the game. I asked players, why are you so interested in this game? And I remember one told me, I'm a security guard at a place or something to that effect. And I just sat there all day and I downloaded this just to pass the time. But over time, I found that I had like real actual friends in this game. And when I would log on, they'd say, oh my God, this person's here. And he felt like somebody, whereas in real life, he did not really feel like someone. And that, that was important to him. Okay, I can see that. But, okay, so curious game mechanics, but that's not why I want to talk to you. The thing that's, the reason I get into that is because you're there clearly in a background where there's serious amounts of data coming in live and serious money to be made in understanding the flow of that data. Certainly. Yep. Tell me about that and how it led into what you did next. Sure. So now this is an interesting story because it's sort of obliquely leads into what we actually ended up building. Because certainly my time at Machine Zone inspired it. But it's not the way I would explain exactly what we're doing. But let me tell you, I suppose the origin story. So while I was at Machine Zone, always we wanted historical data. So we wanted to know not only this is the current power of this individual, or this is the current set of items that they have. But what is the full history of what they have? So we can predict, for example, hey, look, this person was attacked, they got zeroed out, and now they left the game, and they're not likely to come back. We always wanted to know that data. And Machine Zone didn't have that data because the traditional infrastructure of companies is to have their game data or their really website data in normal relational databases, like in this case, I believe it was MySQL. Right. And the problem is, when you update someone's power in those databases, the old power goes away. So you need to have some kind of a way to actually get that historical data. And what they started to do was they were snapshotting their databases every 12 hours. And we would then get that snapshot data, and we'd try to piece together a historical data. But that was very sad for two reasons. The first reason is that the data itself was awful, because a lot can happen in 12 hours, that could cause you to leave the game, right? So you don't really have that information. And I should also say there was another stream of data, which was just event data. But it was very loosey-goosey event data that was sort of whatever people had slapped together. Right. So you tried to build up a picture of what had happened historically from these two sources. And the other reason the snapshotting data was bad was that it was enormous, because if you think about it, 99% of the data in a database does not change in 12 hours. If 99% of your players have turned, you're just copying this old data every 12 hours. And so eventually, they had to pert to the old data, so they couldn't keep it forever. And they spent millions of dollars trying to clean up this data and get it into a form. We built a system which was based on the Lambda architecture. And if you're not familiar with how the Lambda architecture works, you essentially set up a streaming part of your data pipeline, and you set up a sort of a batch part of your data pipeline, and you try to weave those two together. So you might put all of your big, well-formed data in Hive, which is a write, append-only database made by Facebook for large data, and then you would have something like Flink or Apache Spark taking your real-time data and trying to make decision space in that and bringing it in with your batch process data as well. There's a huge amount of work. And I would say 95% of the data science was actually just getting the data into the right form in the right place at the right time. That's a very familiar statement that spans way past gaming, right? Absolutely. So when we began to build our own game, I decided I'm not going to have it. We're going to have the full history of the data. So I want to be able to go back to any point in time and actually see what the game state was. But more than that, I want to actually be able to replay it at that time so that you could hop into the game at that time and actually see it being replayed. On that level of granularity. Right. So you're not just storing events, but player thumbstick movements and stuff. Correct. And actually, I saw on an earlier podcast that you had, I think it was maybe two weeks ago, you were talking about event streaming. And the guest there said at the end, this doesn't always work for everything. It doesn't work, for example, for games. And I thought, aha, how wrong you are. In fact, this is exactly what we're doing. So event sourcing is essentially what Space SoundDB does. Okay. That's colossal amounts of data, very widely distributed user base, high response times required, because you've got to deal with things 60 frames a second ideally. That's a big challenge. How do you start to break that down into something? What's your approach? I think the best place to start is to first understand what the game is that we're trying to build. And then from that, you can see why Space SoundDB is a necessary requirement. So we have two products. We have a game called BigCraft Online, which is a massively multiplayer online role playing game. You can sort of think of it as like a combination between RuneScape, if you're familiar with that, and Minecraft. So there's this very long term skilling and progression in the game. But at the same time, you can actually change and edit the world and build your own things within the world. That's the game that we set out to build. And in order to do that, notably, the first thing you think is, well, we need to put everybody in a single world logically, because you can't have people occupying the same space in the way that you could in a normal MMORPG, because they actually are editing the world. So if I was a normal MMORPG, I'd put many, many instances all in the same city, right? It doesn't matter. In our game, it certainly does, because you actually need to do that. So now you have a very interesting distributed systems challenge on your hands. Yeah, you've got a large global mutatable state. Correct. And it has to be persistent. So if your servers crash, people want to have their buildings that they spent their time building and stuff like that. Yeah. So that's the first thing you have to understand about how we came at this problem. And so in order to do that, we realized, okay, well, we need a system which is built around the persistence, right? Because if we're going to be making these permanent changes to the world, and it is everywhere, either we're going to be doing the normal architecture of games, which I'll take a brief aside to explain. So the normal architecture is you'd have a game server, you'd have your databases, the game server itself, unlike a web server, would have quite a bit of state, right? And you at periodic times, at periodic times, or when people did important events, would write to the database with a transaction. And then you get that back. But you as the developer are doing a lot of work to maintain, I suppose, synchronicity between your database and your game server state. Because for example, if I kill an enemy, there's a lot of things you can do that make things pretty crazy. But if I kill an enemy, that enemy is probably not, their position is probably not stored in the database, but they that there was an enemy might be, or that you picked up items probably is because if Susie enters your inventory, you don't want to lose that. Or you could do it periodically, and then they could do replays and stuff. What you end up getting to is a place where you're spending a lot of your time as the game developer, not thinking about the actual gameplay programming, and rather thinking about the distributed system environment in which you're actually building this game. Yeah, I can believe that. So what we decided to do is say, we are going to make that all, I suppose, opaque to the game developer, and we're going to put them in a context where they're operating inside a transaction already. That transaction is going to be manipulating in memory data. And then we are going to do all of the necessary things to persist that data to disk so that the gameplay programmer does not have to think about that at all. What's that look like for the programmer? They just, they're treating their local client side instances, though it's a relational database. Is this what you say? That is one consequence. But the main point of what I'm saying is that on the server, all things inside of BitCraft happen within a database. So let me explain just a little bit about how SpacetimeDB works and what it is actually. So we built this game and we wanted to do this in this way. So we built a system called SpacetimeDB, which is fundamentally a database. So it's very focused on persistence. The way it works is you take BitCraft, you compile it to a WebAssembly module, you upload that into the database, and then clients connect directly to the database. And now I hear a lot of people in the audience screaming, oh, you can't do that. You couldn't do that. And it maybe was a bad idea for databases like Postgres and so forth. But we have built a permissions model around SpacetimeDB that allows you to do that safely. And so the way that works is you, as a client, call what we call reducers on the database. They're very similar to store procedures. And then those store procedures which are written in whatever language you want that compiles the WebAssembly will access things from the database and write them back to the database. So just as an example, let's say we had player move. And notably, everything in BitCraft, including all the player movement, all the chat, all the trees, all the ground, everything is stored within the database. So if we want to move a player, what we do is we call a reducer called move player on the server that updates some rows in the database and then commits those rows. And that's it. Then clients, other clients will subscribe to the database state. So they'll say, I want to select star from player position, where they are near me, basically, would be what that word clause would say. And then all connected clients that have subscribed to that, when that player moves, we'll hear about those rows and their updates, and then automatically update it in the database. I'm sorry, on their local client. So hang on, where is the database? The database is on a server stored. In this case, I believe in New York. Okay, so how on earth does that possibly work when I'm moving and expecting things to update 60 times a second? So, okay, this is the first thing that's interesting about games. You would not have a tick rate on the server that's 60 times per second, unless you were making a game like Counter Strike. So typically, I'll give you sort of a range. Minecraft updates 20 times per second. So every 50 milliseconds. RuneScape updates, I believe, four times a second. So every quarter of a second. So there's a variety of different levels that you can do. Generally speaking, the larger your game is, obviously, the fewer updates per second you want to be doing, because there's so many entities to move within a timeframe. Yeah, but I mean, I'm in London. I'm not sure I can guarantee four frames a second in New York and back. I see. So I understand your question now. With any game like this, you do not wait for the round trip. So how long would the round trip be from New York to London? I actually happen to know it's about 80 milliseconds or 70 milliseconds, something like that. So it's actually not crazy. You can play it without what's called client side prediction. But the typical way that you would actually do this is you'd run client side prediction. What does that mean? That means that I as a client have some subset of the server state. And when a player, my player, decides to do something, I can predict what the server is going to do to my local state, assuming that it will work. So based on the state of the world as I know it, if I try to move, I should be able to update my local state, assuming the server will agree with me. And so I will do that. And then I will immediately see the results of that on my own local client. But I will send something to the server. Now, if the server agrees, we basically come back, we reconcile, no problem. If the server disagrees, let's say somebody exploded a bomb that your client hadn't heard about yet, right on top of you. And the thing you try to do is invalidated by that. Maybe you're dead now. What will happen is you will have sent a request to the server that says, I want to move. The server interjects and says, actually, you died. What will happen is your client will say, oh, I understand, it will roll back to the point at which you were going to move. And it will then play forward the updates as they actually happen from the server and then try to replay your move. So it would go originally before you heard about from the server, it would go, you're standing here, you move, you actually move. Then what happens is you hear about the bomb, you roll back to the point at which you were about to move, you then blow up because of the bomb. And then you find out, then at that point, you try to move, but you can't move because you're dead. Right. And that's how that reconciles. This sounds very like transaction on the client side. Yes, it does. So is there a database on the client side? Well, I believe basically everything is a database. I have more I could talk about that, but essentially, yes, although typically people don't think of it that way. So typically the way that people think about it, first of all, in games is with a tick. So on the client, you would have a frame, essentially, that happens, they would call it like a server frame if it's not the actual render frame. So the render frame always happens at 60 frames per second, or sometimes now like 120 or 144 or whatever your monitor actually has. A server frame typically doesn't go beyond 60 frames per second. And it assumes there's a loop. And basically, we're going to update all the state once a frame. Space IDB actually doesn't make that assumption. You can do that with Space IDB, but it's not a requirement. So I'll just say that. And there's latency versus throughput trade-offs with that. That's essentially what that will end up with. Because if you have something ticking 60 frames a second, the minimum latency that you can have is one 60th of one second. Because you could have the wrong time. You could have tried to do something just as the frame was starting. And now you have to wait the full frame time before you actually that effect is applied. So now, yes, is the client a database? What is happening on the client is there's really two ways of doing it. And so I want to be careful. In the one way of doing it, the client has a deterministic simulation of the game world. So that means that all of the inputs that are going to manipulate the game state are being sent to the server and replicated out to the clients. Those clients then receive that input. And then they run the game forward a little bit, like one frame. And they will find out what actually has changed in the game state and they move their state forward. That requires having total knowledge of all of the state. Because if you don't have total knowledge, you're non-deterministic because you no longer know what you don't know. You don't know that that bomb might come in from outside and actually... Yeah, if you want total knowledge, you have to have the entire world so you can see events that might be coming over the horizon. Yes, this type of server synchronization really only happens with match-based games. So games with a sort of small state, so like League of Legends, that kind of thing. Or like RTSs, which is another match-based game, where the inputs are quite simple, but the outputs are quite complex. So you might click here to move a group of guys, but 500 guys might move. And so that's actually a lot of data to say where all the positions of them are, but you don't have to do that. You just have to replicate. I clicked here, or this player clicked here, and thus when I play my deterministic simulation forward, all the guys will move within my simulation. I don't have to communicate that data over the network. Okay, yeah, I can see that. So that's one way to do it. For MMOs, part of the reason they're so difficult is you can't do that, because I cannot possibly have the total state of the world on my client. It's too big, sort of fundamentally, by design. I can't put the whole world of Warcraft and all its players on every single machine. Correct, alas, you cannot. So instead, what they do is typically the way this would work is you have your game server. That game server knows what a game client is, and when they connect, they know where the player is, and they have a bunch of special logic to say, okay, I know what this player is, I know what they need, I'm going to send down that data to the client. And then I'm going to send down that data to the client let's say once a frame. So every frame, I will compute, okay, what has changed on the server, and I'm going to send a bunch of messages down saying these are the new positions of all the players. That's the typical way of doing it. Now, notably, this means that you have baked in what your client wants to know about into your server code. Because you as the server need to know what they need to know, because you're going to do this streaming update to them. Yeah, so it's more complex than first, for example, let's say a web site with a GraphQL query, because with a GraphQL query, you can say, Oh, I'm this client of client, and I want to know all about this data. And I'm this kind of client, I want to know about this data. But because games are streaming, and they need to go fast, and they have this tick based thing built into it. Historically, people have built them so that you write all the code for synchronizing the clients, and you build in some concepts, like you probably build in the concept of positions and of players, and that players want to know about things that are around them, and all of that good stuff. So if you were to then go build an AI that doesn't care about where certain players are, maybe it's trying to regrow the trees or something. And it wants to listen to the data. No can do. You've already built in the particular query that wants to be done on that game server state. Right. So we're inverting the controls. So the server knows what kind of things you would want and pushes those to you. Correct. So that really bakes in the server then has to have very fixed ideas about what kind of people connect and what they might want to do. Absolutely. Correct. What space time to be does is the opposite. We actually treat it sort of from a formal database perspective and say, actually, clients are just going to write queries, which are going to be executed with a query engine in a subscription based streaming way. So first, we connect, and we send a query, and we say, I want to listen to all of these players in this region or whatever we are interested in. And then that data will be incrementally streamed down. So as the data changes in the database, we compute that query for all the subscribe things and we send it down to their clients. Then you can think of their clients as having a replica of the server database. Now that replica is a subset of the data, and it is only prefix consistent. So it's not strongly consistent. Would you mean by prefix consistent? You have the database state as it existed at some point in time in the past. So you have all of the updates in a prefix of the message log, of the write ahead log, up to a certain point. That's what I mean. Now it's a subset. So it's not, I have the whole database, I have some set of the data as it was in time. So it's not eventually consistent. I don't see any weird things about it. I will see the database state as it was maybe like five milliseconds ago, or if I'm far away a hundred milliseconds ago. Right, yeah. And so what that allows us to do is then you can query your local database as though it were the actual database. And so you can get this information out from your local database much more conveniently and faster than you might otherwise do in a normal game server. You'll forgive me being really boring here, but I'm translating this into a non gaming world. And I can see I can imagine I as a as a client of the second client of a bank or trading platform, I might want to have all the data relating to my accounts and maybe some of my counterparties, but not the entire bank's data. And then I want to be able to optimistically make transactions on that data. They get sent back to the central server and I get told if that works, but I can progress as though it did. Yes. And that would be exactly the same architecture we're talking about in the gaming world. 100%. Yes. So what we are in sense, sense trying to do is unify across both of those things. A lot of people in why, why is that important? Because many people have tried to make a game service, game server back end kind of thing, like a game engine, but for the server, right? So there's unity, you've got Unreal. Wouldn't it be nice if somebody made that for the back end? The problem that people have is that when you think about what a game is on the client, it's the same across all games. If I'm playing chess or solitaire, what I want to do on the client is very similar to what I want to do in World of Warcraft. Let's say I'm making a 3D solitaire. I am rendering objects on a screen and I have all of that stuff. It's all kind of the same across both games. I want to render a 3D world. I want to loop that, apply some logic to the state of that world. And then I want to, yes, and I want to turn it into 3D objects and I want to project them onto a screen and I want to do lighting effects and I want to do sound effects and I want to do all of that. Every game from the client perspective is not identical, but they rhyme. They have a lie in common that an engine could do that we don't have to write over and over and over again, essentially. On the server, if you think about what chess versus World of Warcraft is, those architectures are, they share nothing. They might as well, one is like a web app kind of, right? Like a chess move. I could build that with a web server and Node.js and all that. And the other one is a very complex multi-user, fast-changing state thing, which synchronizes data persistently to the database and updates positions and all of that. So what we're trying to do in some sense with SpacetimeDB is close over all of those things and you really have to go all the way back to the database for it to be general enough to actually apply to both of those scenarios. Yeah. Okay. I can see that. It sounds like a colossal amount of work to do well, though. It does. Nobody knows this better than I do. Let me put it to you this way, though, with respect to that. When we decided we were going to make BitCraft, we were committed to making such a system. The fact that it's available as its own standalone thing is not really that much more work. Every MMO that you have ever seen has an architecture which is at least as complicated as SpacetimeDB. And I actually know that some of them, I can't necessarily name them, operate in the same sort of stored procedure way because it's the sort of convergent evolution that they arrived at, but they just didn't formally call it a database. In some sense, an easier problem because if you treat it as a database formally, you get to use all of the research and learnings that 50 years of database research has brought about. You do not have to reinvent the wheel, is what I'm saying on a lot of these things. And so we were always destined to create a system that's like this. As soon as we decided we wanted to actually create this kind of thing. Ours is arguably just not sort of shoestring and duct tape, not to disparage anyone else. It's very hard to build an MMORPG, but that's kind of how I would think about it. Let's say rather than that, it's not an afterthought. Not an afterthought, yes, correct. Okay, so what we've got here is a system where I as the game programmer, updating a row in a date, someone moves the joystick up, I update the Y position of their player's row in a database. Correct. Magic Clitty, that's going to be synchronized to the server without me worrying about it. And roll back if it turned out it didn't work. And then I just have a rendering function that's also looking at my local database and drawing it to the screen. That is correct, yes, that's essentially correct. Okay, let's start with the first objection. That's going to be too slow, even even if you don't have to do the server round trip every time. So let me ask a follow up question to your question. What specifically would be too slow? Because what I want to ascertain is exactly what you're talking about. There is a perception that databases are slow, and perhaps that's what you're driving at. I think because, okay, it's got to be transactional. It's probably iterate. Once you get into things like, oh, my bullet's flying across the screen and hitting people, it's updating a considerable amount of data. And collision detection, it's got to happen a lot of times a second. I won't give you the number, you can give it to me. But that feels like that's going to grind on a transactional database. Okay, so this is a great question. And I understand where you're coming from. And we had to be a little bit crazy to think that this was a thing that should be done originally. But for several reasons, which I'm about to outline, I think you will come to agree that actually that's completely possible and plausible to do within a database context. So the first thing I will draw your attention to is that we're not, by no means the first, to do things like this in history. There is a database called times 10, which was developed in the 90s. Oh, that was bought out by Oracle, wasn't it? It was bought out by Oracle, correct. And it actually has a very similar architecture to SpacetimeDB. So a couple of things. One, it's fully in memory. So the whole purpose of that database was that for certain very high throughput, low latency applications, current databases weren't hacking it, not even that currently server architectures weren't hacking it. So what they decided to do is to have a database, have in memory state in that database, put the logic of your program, physically within the same process as that database, and then have you access the data within the same process. So you're literally reaching into your current program memory, you're treating your program memory as though it were a database. And then what they do is all the updates to that data, they append in an append-only fashion to a write-ahead log. And this was developed for telecom processing, like routing calls, these kinds of very, very low latency high throughput things. That's the almost identical architecture actually to how SpacetimeDB operates. We have just modernized it for use with WebAssembly and whatever language you would like, and some nice things on top of that, including subscribing to the database, which I don't believe TimeSend actually provides that information. Okay, but that write-ahead log that we've got into persistence, which you said is important, isn't that a blocker to the performance? Not typically. So first thing I would say is that appending to a write-ahead log is actually quite performant on modern hardware. So that's actually how Kafka works, and it's how it's assumed to work. And Kafka is known as sort of a low latency streaming thing. It's not that low latency because of details, but it's relative to what a lot of people use, very low latency. The other thing that's important to know about Kafka and systems like that is that you can trade off throughput for latency. So in the case of Kafka, you can batch more things up, which will cause the latency to increase, but will cause the throughput to go up. You can always say, I care about latency more than I care about throughput. So I will decrease it down to just one transaction. So that would make sense for I want a really high, fast-paced game where I really want the lowest possible latency, or I don't really care if things come in late. So that's one thing. The next thing I would say is that for games, or really any application, choosing the level of durability that you want should be configuration and not code. So what I mean by that is I ought to be able to decide that I want to listen to data that might not be persisted to disk, because I don't actually care about that. For a player movement, if my server crashes and they move back 10 feet, don't really care about that. If I'm running a bank transaction and it rolls back the last 10 seconds or whatever of bank transactions, it could be a problem, because they might have already given away the item that the guy bought, right? Okay, yeah, yeah. So when you say that's configuration, are you configuring it on a per object type basis? So could I make some match levels of persistence, you guaranteed? You actually configure it on a subscriber basis. So you would say, hey, I'm going to subscribe to this data. And for this particular subscription, I want to see the data as soon as it updates. I don't care if it's ready. Like, I want to hear about, so there's sort of levels at which you can listen in. So there's a pipeline of data that comes in. My message happens, I update the data, that changes the stuff in memory, I write it to disk, I replicate it to other machines, all of this. And at any point in time, you can decide, like, you know what, it's good enough, I want to listen in here, right? So I want to listen in after it's been updated memory versus I want to listen after it's been persisted disk versus I want to listen only when it's been replicated to five machines. That's a sort of a different level of listening, if that makes sense. I'm jumping around trying to get my handle or my hands all over. But, okay, so how does that work programming? I let's say the score, player score, is gradually ticking up. It's not the end of the world if it maybe rolls back a little bit. Am I writing some code that just subscribes to the score changing and just renders that corner of the screen? You certainly could do that. Typically, what a client will do is they'll subscribe to all the data that they want right up front. So they'll say, like, let's say it's a chess match, you'll say, I want to subscribe to all the peace positions. Or I want to subscribe to, it depends on how you program that match, but let's say you're going to do it in a certain way. I'm going to listen to all the peace positions and I want to subscribe to the score. You don't actually, a lot of cases, you can actually compute the score on the client based on the state of the game. But let's say you can't, for some reason, in this game, you would subscribe to the score as well. And then that will be updated in a row and you'll just say from score table, subscribe, select off star from essentially. Am I doing like a, am I joining those datasets? So select all from pieces, union, select all from score? Yeah. So in this case, you're going to basically select a subset of each server table. We do not yet support subscription joins. We do actually. So we support what's called a semi-join. So you may filter out rows from a table based on a join from another table. So for example, I might want to subscribe to all players who's, who are friends with this other person. So I would write a join and I could, but I would always get the whole player row. And I'm not going to get any like player plus others data. If you want to do that, you would subscribe to the other table as well. And then we union all of those together and send them down. Okay. And are we writing this query in SQL? SQL. Currently. We, there's no reason we can't also support other query languages like GraphQL in the future. It's just for right now, for building an MMO or RPG, we need SQL. Okay. So as a game programmer, I'm writing, like you say, very much like stored procedures that have a mixture of SQL and coding. And like, what's the language? So the language is the module that you're writing is a WebAssembly module. So it's any language that you want that compiles to WebAssembly. Notably, we support Rust and Csharp in terms of building a library of nice things for you to use in those languages. In principle, anybody else could do whatever language they want that compiles to WebAssembly. But yeah, those are the two that we support right now. Okay. I risk framing this all as objections, but I'm trying to think... Sure. No, no, please. There is an objectionable idea that happens to work. And so it's quite exciting. Okay. So the other thing that people always complain about with stored procedures, I mean, a lot of people dislike stored procedures. And I think the reason is, I think there's two reasons. One is the language can be weird for stored procedures. Personally, I reject that one. If it's valuable enough, you'll learn the language. The real one is management of stored procedures is a misery. Correct. Yes, it is. And I think these are the... So I would actually go a little bit further too. The permissions model of stored procedures at times can be arcane as well. So I believe it's really, to your point, fundamentally a user experience problem, not a theoretical or technological problem, if that makes sense. Yeah. It's like developer experience rather than this simply doesn't work. Yes. I mean, why... If you actually think about stored procedures as they were, it's a nightmare. You have data that's in your database operating that's opaque because somebody updated it, but you don't... It's not in version control. You don't have any idea like, what was running? Did somebody change it? It's like, where is it stored? It's just a nightmare. It's a great point. What I will say to this is actually, we didn't set out to build the database in stored procedures. What actually happened is we built a system that had the right UX for what we wanted our developers to have and then looked at it and said like, oh, from this angle, actually, this is just a database with stored procedures. So it was very much a... We backed into it, we didn't arrive there. So that's number one. Developer experience is the most important aspect of space time DB. And if it is bad, there's no point to doing it. That was why we created it in the first place. The way we solve these problems are, number one is we put all of the stored procedures as the root of your database. It is all in a single module that's based from a single repo, in this case, that you can version in version control and then you can see the versions of it. The thing I would liken it to, from a developer experience perspective, and now I'm going to say something that will maybe trigger a lot of people, but it's similar in principle to smart contracts. So from there, you... Nobody thinks the developer experience of those is bad, except the fact that they have to deal with the blockchain. But ultimately... And the programming language can be pretty terrible. And the programming language can be pretty terrible. But fortunately, we've solved both of those problems by removing the blockchain and making it so you can use whatever programming language you'd like. But it's the same idea, right? You do not need a DevOps team to maintain or an operations team or any of that or AWS credit or any of that to run your smart contract. What you do is you say publish, you set it, you forget it, you walk away. You don't have to deal with that ever again. It's running, someone's running it for you. You really truly don't care. And that is the promise of the developer experience that I think we can provide with store procedures. And it's very easy in the case of smart contracts to keep them in sync. Normally, actually, in a lot of systems, you can't update your smart contracts. So that's one thing. But in our case, you can update a space-time-due module. And it comes from a database, and you can see the version that was up there. And the version is stored in the log. So the fact that you're updating your whole database and you can do migrations within your module, and you're doing the whole module at a time, vastly, vastly improves it. Then you have the language that you want to work within, which is a normal programming language. And then on top of that, we have built a permissions model that allows you to have complex logic, which is easy to understand by the developer, if that makes sense. Let's go through the permissions thing. For instance, if I've got access to subscribing to data from the server, I wouldn't. Hypothetical black hat me would very much like to use it to cheat on the game. By subscribing to other people's data. Okay. So first thing I'll note, all games of the first type that I described, where they have a deterministic client and they're replicating inputs, must know about all data in those games. So League of Legends, you can cheat. In fact, they're doing like a kernel extension to prevent people from cheating. But beside the point, they require you to see all data. So if you see Fog of War in an RTS, you could get data, everything under that Fog of War is there. You could remove the Fog of War on your client and see all of the units. So sad times. So first of all, they're just right out. They don't provide that to you at all. In our case, what you can do is there's two types of permissions. There's sort of write permissions and then there's read permissions. So if you want to update the database, clients are only allowed to update the database through the module. And so what that will be is like, let's say I wanted to move a player, but I try to move a player in a way that's illegal. Like I'm trying to go into this level, this place where I need to be level 56 and I'm only level 50. What the server will do is it will check the level of the player because you're just writing the logic and you'll just fail the transaction. So you'll just say, no, you can't do that. We roll everything back and we throw it away. All right, so that's the first thing. The way that works is each client has an identifier, which is called the identity, makes sense. It's kind of like an Ethereum address, if you want to liken it to something in that regard, you can see who the person is. And then you can say, you do all the procedural checks you want in the whole world. Is this player friends with that or do they know each other, whatever it is, and then fail the transaction if it's not allowed? So that's the right. So right is super simple, very, very easy to do. From a read perspective, there's a couple layers that you can do. So first of all, what we implement today is private tables. So that's just, hey, this table is only viewable by the owner of the module. So based with the database creator. And we would like to add, so we have not yet added because it's not yet 1.0, both column permissions and then column read permissions and then row level security. So what that means is you should be able to write a function inside of your module that says, well, in the case of column, you're just going to annotate columns as being private, right? And that's that's pretty sure for for row level security. That means like, can this person see this row? So if they subscribe to these players, maybe this player is invisible, and I shouldn't be able to see them right now. Right. So you want to be able to write a filter function on a table. So a filter function that applies to a table that allows you to do arbitrary procedural logic that basically says whether or not this player should be or this row in this table should be visible to this subscriber. So if I had like a hypothetical card game of some kind, where I have cards that only I can see, cards that all my teammates can see, and cards that the opponent can also see, would I be able to model that? You certainly would. So you'd be able, what you'd do is you'd say, let's say you just have one table called cards and you'd write a function that says, this is the subscriber, which is like this is the identity of the subscriber. Do you want to show this row or these batch of rows or however we end up ultimately implementing it for performance reasons? And you would look through the row and you would say, ah, is this who is the owner of this card? I am the owner of this card. I can see it. Oh, I'm not the owner of this card. Is the owner of this card my teammate? Okay, I can see it. I am, you know, and so forth and whatever conflicts logic you want. Okay. And I'm writing those functions in the same language? In, yes, in Rust or whatever language. Okay. So the language to define security roles is the general purpose language. The general purpose language. And it's a procedural language, not going very fancy. Obviously, you can do what, for example, SuperBase does, which is they have you write those row level security rules in SQL. So we may also support that. I'm not sure right now, but boy, it is a lot easier to write Rust than some arcane SQL query about row level security. I'll tell you that. Okay. Right. Where does that leave us? So is my experience programming the server side similar to my experience program in the client side? Okay, this is a fantastic question. Let me tell you where we are today. And the vision for where we want to be with SpaceMDB. So where we are today is you write your server module that runs on the server. It's written in, let's say, Rust. You write your client. We have a Rust SDK. And what that does is gives you a bunch of functions that you can use like subscribe function where you can pass in all your SQL queries, and then you can get all the data back. The Rust SDK currently stores that data internally. So it has this like data, little mini database, if you will, like a little mini memory, and you can query that data. The querying of that data is relatively rudimentary. It's based on code generation that we do. So your module has a bunch of types, right? And a bunch of schemas and all that stuff. You can take a module, and then you can extract the schema from that module, and then you can code generate whatever type of clients you want. So for example, you can call a particular function from the client. You can get the type, so if you have a Rust module and a C sharp client, as we do, you can get that C sharp equivalent type to the Rust type on your client, if that makes sense. Okay. Which is important because that's another thing with with store procedures is that like, oh, the type, like you hopefully the types work because it's like dynamic, who knows, it's just crazy the way they do things. Or you have to sort of like apply a type and you have to maintain the types. We are code generating a lot of it's like protobuf, right? So you, you have your schema, we scoop that out of your module. It's like a protobuf representation of your schema, you can then code generate on whatever client you want, whatever types you need. So TypeScript, we support for right now TypeScript, Python, Rust and C sharp for clients. Okay. Yeah, but when I call those functions, they're still going to the local space time to be client instance. Okay. So they do and then they, they get sent out to the server. We don't automatically do client side prediction right now. That is something that for example, in bitcraft, we have to replicate the, the logic of so if you move a player, you have to move them fit like yourself is to rewrite the logic and C sharp and then you have to write the logic in Rust. That's typically how a lot of people do this, these things and it is a huge pain. They duplicate the logic and they have to do this thing and it's a huge pain. Yeah. Some more clever people, actually, I know of some that are developing an RTS use web assembly and they run the server both on the client and the server and they do that. And so that's ultimately where we'd like to go with this. So ultimately, we want to run space and to be not only in the server, but also in the client and have them synchronized between each other automatically based on your subscriptions. And then you have a fully running module. So the same module is running the server is running on the client. And when you update, when you do a call, actually we run the actual server logic on your client, update that and then that does the whole reconciliation. So you automatically get client side prediction for free. Really, how far away do you think that is? It's a good question. So in a sense, we're already doing it on the, what we call space and to be cloud, which is our cloud office. So we have, okay, there are two versions of space and to be there's space and to be standalone, which is the open source version that's on GitHub. You can take a look at that, everything that'll run like a single node clustered as though it were your own personal instance of space and to be, we also have cloud, which is a distributed system, which will run many machines in coordinate between them all. And the way we replicate from one to the other is sort of the normal way in which you would replicate a client. So they're all just clients of each other is an interesting thing. Right. And that has a lot of implications for strong consistency, but I don't think we have time to get into that. But either way, we're working towards that, I suppose on the server. And then we will do that as soon as we can on the client. We're also building an MMORPG. So we're a little bit busy. So I'm not sure exactly when that'll be, but it is still useful in the way that it is right now that is to say, not automatically doing client side prediction. But we will, we will eventually do that. I envision world. So here's the secret. Here's the real secret to what space and to be is actually it's not really a database at all. What it really is, is a distributed operating system in the spirit of plan nine, which has never sort of taken off. Let me explain. Okay. Briefly. So space and to be cloud, as I mentioned, runs over, let's say 100 computers, right? So you've got this, this thing that's running from the outside, it looks like just one instance of space time to be. So you can't really tell that it is made up of 100 computers. And what you're doing is you're taking a program and you're running it on that distributed computer. So it looks again, like a single computer. And you're running a program on it. And we're abstracting away the hardware. Boy, that does sound like an operating system, doesn't it? And so that is really ultimately where we'd like to go is a place where the cloud is not this collection of hardware and services that you have to piece together in this grotesque fashion. But really, it is just a giant computer. And you're going to take your program and you're going to run it on that giant computer. And that's it. This is going to be even more blurred when you've got a series of clients connecting into that who are themselves similarly programmed. Correct. And so what you might say is that you're building a gigantic distributed operating system that the whole world runs on top of, right? You could say that if you were so bold. And I don't know that we are yet, but one day, perhaps we will. So the idea would be that you're all operating on the same protocol to speak with each other and that you can't really even tell. I mean, there's a lot of details in this one. And to be quite honest, I haven't thought through all of it. But if everybody's speaking the same language, you have all of these modules subscribing to each other, it's just the actor model, you know what it is. It's very similar to Erlang, right? It's got the same kind of spirit. You've got these actors, and they are sending messages to each other, and they're listening to messages that are being sent to them, and they're updating their state, and they're moving on. So it's very much in that spirit. Okay. Let me ask you this, and you may not like this question, but I'm going to ask it anyway. If someone thought this is a great idea, but I'm not waiting for you to do it, I'm going to build this on Erlang myself. Sure. What parts would they be missing? What parts would they find hard? Yeah, so the whole database part, right? So don't forget about that. So I've thought about this in a sense. So let's say you want to build this on Erlang. Cool. What is Erlang missing? Well, it's missing the persistence. I know they have persistent actors, but the performance of that is key. The size of each actor is key. So within a space on DB actor, if you think about them as actors, we also do multi-version concurrency control so that we can run as many transactions as possible within one machine as sort of one actor as you might possibly be able to do. So you want each actor to be as large as possible before you start going into other actors because as soon as you go into distributed systems, it's complicated, and you can do a lot with a single machine, it turns out. Although each actor could in principle be more than one machine, but I digress. That's another direction to go in down in the future. And then there's the whole relational model. So you need to build on top of Erlang the ability to do queries on the rows and get the actual row data out, all of the type system stuff. You'd want to be able to run in whatever language you would like to because maybe your programmers are familiar with C-Sharp because they're Unity developers and all that. Let's say also now, what about the subscription? So actors in the Erlang model, as I understand, you can send messages to other clients, but that's kind of like the old way of doing it with the game servers where I need to know what this other actor wants to know or build a subscription system where they send me a message, which is their subscription, and then I run the whole query engine and then I send them what they need to know, which is what we have done. So you have to build that whole query subscription system up from the ground as well. So good luck to you. And I would love to see and use your system if you do that because we wanted to make a game. We are doing this because we must. Okay. Then perhaps we should wrap it up with the last two questions. If someone decides they don't want to do that, what state is SpacetimeDB in for me as a user? Can I go and play with it? You absolutely can. So you can go to spacetimedb.com. You can play with a demo. It's right there. You can also very quickly go to our quick start guide, install spacetimedb, get a local instance of it running, spacetime standalone. You can upload a module to that. You can connect to that. You can call functions on that. You can also upload to our testnet. So our testnet is a version of spacetimedb cloud, which is relatively nascent, but it's meant for you to play around with what the cloud version will be. It's completely free. We give you a free amount of energy. Energy is what powers these things. It's not actual energy, to be clear. It's just points. You can give it AWS credits. We give you AWS credits. You can go to town on that. Then notably for the testnet, we reserve the right monthly to wipe the data because we're still updating the ABI and we don't want to be locked in yet. Early this year, we're trying for, let's say, April to move into 1.0 and the main net. The main net of spacetimedb will be the version of spacetimedb where we guarantee that your data is going to be there forever and it will be persisted and replicated and all that good stuff. You can begin building your applications now for a launch post-April. Okay. Here's another dangerous question because there's only really one right answer. Is your game, BitCraft, going to be running on that testnet? On that main net? It already is. So, yes, 100%. We are working on, so a lot of our focus right now is getting the performance to where it needs to be. BitCraft used to run on what we called janktimedb, which was like spacetimedb, but it was the thing that we built first and it was not its own product. And that works quite well, but it actually was more like the traditional old servers where the server knew what the client wanted and it was relatively performant. And we're now getting back to that point that right around now, we had the same performance of janktimedb and now as we gear up for the alpha, which, by the way, signed up for the BitCraft alpha, it's happening early this year as well. I'll put a link in the show notes. Yes. And we are getting to the point where we are at that performance level that we need for that alpha. So that's like, well, I don't know how much I can say without upsetting the BitCraft team, but it's many more users than we had previously, concurrently, running in the game. Right. Cool. Well, you've got a busy year, a busy few years coming up. We surely do. We surely do. Awesome. Well, good luck with spacetimedb. I hope it takes off. Good luck with BitCraft. I hope that takes off. And if they both take off, you're going to invite me to your private yacht for a follow-up. I don't know that I'll have one of those. I'll be too busy on the next part of spacetimedb. So good luck. I need satellite from there. You'll be able to afford it if both of those work. I guess so. I guess so. Tyler, thanks very much for joining us. Cheers. Thanks for having me. And that's all from Tyler. Thank you very much. You know, in among all the things we discussed in there, I think Tyler must be something like our third guest to reference the Plan 9 operating system. And I don't know much about Plan 9, except it never took off, but it was a huge influence for a lot of people. I think we might have to have some kind of retrospective what we could have learned as an industry episode on Plan 9 one day. So if you're a Plan 9 expert, or if you know one, please get in touch. And the way you get in touch is the same way you send us any feedback. My contact details are in the show notes. If you're on YouTube, there's a comment box just down there. Spotify has a Q&A thing for each episode these days, and so on and so on. Check your app. On the subject of feedback and the future episodes, if you enjoyed this episode, please leave a like or a comment. If you think other people should find this podcast, please rate it or share it with a friend. And make sure you're subscribed because we're going to be back next week with more interesting voices from the software development world. Until then, I've been your host, Chris Jenkins. This has been Developer Voices with Tyler Clute here. Thanks for listening. you", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.92, "text": " One of the areas of computing that I'm really curious about, and I think the software world", "tokens": [50364, 1485, 295, 264, 3179, 295, 15866, 300, 286, 478, 534, 6369, 466, 11, 293, 286, 519, 264, 4722, 1002, 50610], "temperature": 0.0, "avg_logprob": -0.1357813156568087, "compression_ratio": 1.6366906474820144, "no_speech_prob": 0.008707636967301369}, {"id": 1, "seek": 0, "start": 4.92, "end": 11.0, "text": " has a lot to learn from, is game programming. Probably not on a surface level, I've never", "tokens": [50610, 575, 257, 688, 281, 1466, 490, 11, 307, 1216, 9410, 13, 9210, 406, 322, 257, 3753, 1496, 11, 286, 600, 1128, 50914], "temperature": 0.0, "avg_logprob": -0.1357813156568087, "compression_ratio": 1.6366906474820144, "no_speech_prob": 0.008707636967301369}, {"id": 2, "seek": 0, "start": 11.0, "end": 17.12, "text": " worked for an e-commerce company that needed collision detection. But get below that surface,", "tokens": [50914, 2732, 337, 364, 308, 12, 26926, 2237, 300, 2978, 24644, 17784, 13, 583, 483, 2507, 300, 3753, 11, 51220], "temperature": 0.0, "avg_logprob": -0.1357813156568087, "compression_ratio": 1.6366906474820144, "no_speech_prob": 0.008707636967301369}, {"id": 3, "seek": 0, "start": 17.12, "end": 21.36, "text": " and a lot of modern games, especially once they go multiplayer, they're dealing with", "tokens": [51220, 293, 257, 688, 295, 4363, 2813, 11, 2318, 1564, 436, 352, 27325, 11, 436, 434, 6260, 365, 51432], "temperature": 0.0, "avg_logprob": -0.1357813156568087, "compression_ratio": 1.6366906474820144, "no_speech_prob": 0.008707636967301369}, {"id": 4, "seek": 0, "start": 21.36, "end": 28.72, "text": " things like global networking issues, multi-user concurrency, competitive concurrency, massive", "tokens": [51432, 721, 411, 4338, 17985, 2663, 11, 4825, 12, 18088, 23702, 10457, 11, 10043, 23702, 10457, 11, 5994, 51800], "temperature": 0.0, "avg_logprob": -0.1357813156568087, "compression_ratio": 1.6366906474820144, "no_speech_prob": 0.008707636967301369}, {"id": 5, "seek": 2872, "start": 28.72, "end": 34.96, "text": " data volumes, under brutal latency requirements. They have a lot of the programming issues that", "tokens": [50364, 1412, 22219, 11, 833, 17878, 27043, 7728, 13, 814, 362, 257, 688, 295, 264, 9410, 2663, 300, 50676], "temperature": 0.0, "avg_logprob": -0.13428966277236237, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.005553066730499268}, {"id": 6, "seek": 2872, "start": 34.96, "end": 40.239999999999995, "text": " we're familiar with, but under much harsher conditions. And being a somewhat separate world,", "tokens": [50676, 321, 434, 4963, 365, 11, 457, 833, 709, 276, 685, 511, 4487, 13, 400, 885, 257, 8344, 4994, 1002, 11, 50940], "temperature": 0.0, "avg_logprob": -0.13428966277236237, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.005553066730499268}, {"id": 7, "seek": 2872, "start": 40.239999999999995, "end": 45.68, "text": " they tend to approach the solution from a novel angle. So this week, we're going to go digging", "tokens": [50940, 436, 3928, 281, 3109, 264, 3827, 490, 257, 7613, 5802, 13, 407, 341, 1243, 11, 321, 434, 516, 281, 352, 17343, 51212], "temperature": 0.0, "avg_logprob": -0.13428966277236237, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.005553066730499268}, {"id": 8, "seek": 2872, "start": 45.68, "end": 51.76, "text": " for system design ideas in the gaming world. And my guest for this is Tyler Cloutier. He's got a", "tokens": [51212, 337, 1185, 1715, 3487, 294, 264, 9703, 1002, 13, 400, 452, 8341, 337, 341, 307, 16869, 2033, 346, 811, 13, 634, 311, 658, 257, 51516], "temperature": 0.0, "avg_logprob": -0.13428966277236237, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.005553066730499268}, {"id": 9, "seek": 2872, "start": 51.76, "end": 56.92, "text": " background in distributed systems and data science for the gaming industry. And he's", "tokens": [51516, 3678, 294, 12631, 3652, 293, 1412, 3497, 337, 264, 9703, 3518, 13, 400, 415, 311, 51774], "temperature": 0.0, "avg_logprob": -0.13428966277236237, "compression_ratio": 1.6258741258741258, "no_speech_prob": 0.005553066730499268}, {"id": 10, "seek": 5692, "start": 56.92, "end": 63.160000000000004, "text": " currently building BitCraft, which is a massive multiplayer open world game, and to support it,", "tokens": [50364, 4362, 2390, 9101, 34, 4469, 11, 597, 307, 257, 5994, 27325, 1269, 1002, 1216, 11, 293, 281, 1406, 309, 11, 50676], "temperature": 0.0, "avg_logprob": -0.14098148555546017, "compression_ratio": 1.508, "no_speech_prob": 0.004754140041768551}, {"id": 11, "seek": 5692, "start": 63.160000000000004, "end": 69.2, "text": " a really interesting flavor of database called SpacetimeDB, from which we're going to mine", "tokens": [50676, 257, 534, 1880, 6813, 295, 8149, 1219, 1738, 326, 9764, 27735, 11, 490, 597, 321, 434, 516, 281, 3892, 50978], "temperature": 0.0, "avg_logprob": -0.14098148555546017, "compression_ratio": 1.508, "no_speech_prob": 0.004754140041768551}, {"id": 12, "seek": 5692, "start": 69.2, "end": 77.2, "text": " some ideas about concurrency, transactions, data security, query management, lots more. A lot of", "tokens": [50978, 512, 3487, 466, 23702, 10457, 11, 16856, 11, 1412, 3825, 11, 14581, 4592, 11, 3195, 544, 13, 316, 688, 295, 51378], "temperature": 0.0, "avg_logprob": -0.14098148555546017, "compression_ratio": 1.508, "no_speech_prob": 0.004754140041768551}, {"id": 13, "seek": 5692, "start": 77.2, "end": 83.2, "text": " juicy ideas solved from an angle that I'd never considered. So let's get going. I'm your host", "tokens": [51378, 24696, 3487, 13041, 490, 364, 5802, 300, 286, 1116, 1128, 4888, 13, 407, 718, 311, 483, 516, 13, 286, 478, 428, 3975, 51678], "temperature": 0.0, "avg_logprob": -0.14098148555546017, "compression_ratio": 1.508, "no_speech_prob": 0.004754140041768551}, {"id": 14, "seek": 8320, "start": 83.24000000000001, "end": 87.96000000000001, "text": " Chris Jenkins. This is Developer Voices. And today's voice is Tyler Cloutier.", "tokens": [50366, 6688, 41273, 13, 639, 307, 44915, 7518, 1473, 13, 400, 965, 311, 3177, 307, 16869, 2033, 346, 811, 13, 50602], "temperature": 0.0, "avg_logprob": -0.25637195660517764, "compression_ratio": 1.328, "no_speech_prob": 0.019708512350916862}, {"id": 15, "seek": 8320, "start": 101.44, "end": 104.52000000000001, "text": " My guest this week is Tyler Cloutier. How you doing, Tyler?", "tokens": [51276, 1222, 8341, 341, 1243, 307, 16869, 2033, 346, 811, 13, 1012, 291, 884, 11, 16869, 30, 51430], "temperature": 0.0, "avg_logprob": -0.25637195660517764, "compression_ratio": 1.328, "no_speech_prob": 0.019708512350916862}, {"id": 16, "seek": 8320, "start": 104.52000000000001, "end": 105.84, "text": " I'm doing well. How are you?", "tokens": [51430, 286, 478, 884, 731, 13, 1012, 366, 291, 30, 51496], "temperature": 0.0, "avg_logprob": -0.25637195660517764, "compression_ratio": 1.328, "no_speech_prob": 0.019708512350916862}, {"id": 17, "seek": 10584, "start": 106.16, "end": 114.16, "text": " I'm very well. You're going to take me to a new world for me, because I have a long history in", "tokens": [50380, 286, 478, 588, 731, 13, 509, 434, 516, 281, 747, 385, 281, 257, 777, 1002, 337, 385, 11, 570, 286, 362, 257, 938, 2503, 294, 50780], "temperature": 0.0, "avg_logprob": -0.10848088316865019, "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.017967380583286285}, {"id": 18, "seek": 10584, "start": 114.16, "end": 121.28, "text": " programming, but one thing I've never done is computer game programming. And along with that,", "tokens": [50780, 9410, 11, 457, 472, 551, 286, 600, 1128, 1096, 307, 3820, 1216, 9410, 13, 400, 2051, 365, 300, 11, 51136], "temperature": 0.0, "avg_logprob": -0.10848088316865019, "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.017967380583286285}, {"id": 19, "seek": 10584, "start": 121.28, "end": 127.60000000000001, "text": " the one thing I've always wondered is they must have a lot of the same problems that the rest", "tokens": [51136, 264, 472, 551, 286, 600, 1009, 17055, 307, 436, 1633, 362, 257, 688, 295, 264, 912, 2740, 300, 264, 1472, 51452], "temperature": 0.0, "avg_logprob": -0.10848088316865019, "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.017967380583286285}, {"id": 20, "seek": 10584, "start": 127.60000000000001, "end": 132.4, "text": " of us industrial programmers have, not like the dealing with graphics and story and stuff,", "tokens": [51452, 295, 505, 9987, 41504, 362, 11, 406, 411, 264, 6260, 365, 11837, 293, 1657, 293, 1507, 11, 51692], "temperature": 0.0, "avg_logprob": -0.10848088316865019, "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.017967380583286285}, {"id": 21, "seek": 13240, "start": 132.48000000000002, "end": 134.88, "text": " but then there are data problems everywhere, right?", "tokens": [50368, 457, 550, 456, 366, 1412, 2740, 5315, 11, 558, 30, 50488], "temperature": 0.0, "avg_logprob": -0.11964462000295656, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.010980252176523209}, {"id": 22, "seek": 13240, "start": 135.76000000000002, "end": 141.44, "text": " That's right. Actually, I would say what I have experience is that they have the normal problems", "tokens": [50532, 663, 311, 558, 13, 5135, 11, 286, 576, 584, 437, 286, 362, 1752, 307, 300, 436, 362, 264, 2710, 2740, 50816], "temperature": 0.0, "avg_logprob": -0.11964462000295656, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.010980252176523209}, {"id": 23, "seek": 13240, "start": 142.0, "end": 146.32, "text": " that everybody else has, but times 100, because not only do they have to build the thing,", "tokens": [50844, 300, 2201, 1646, 575, 11, 457, 1413, 2319, 11, 570, 406, 787, 360, 436, 362, 281, 1322, 264, 551, 11, 51060], "temperature": 0.0, "avg_logprob": -0.11964462000295656, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.010980252176523209}, {"id": 24, "seek": 13240, "start": 146.88, "end": 153.6, "text": " but it has to interact with all of the data in the program besides just sort of individual parts.", "tokens": [51088, 457, 309, 575, 281, 4648, 365, 439, 295, 264, 1412, 294, 264, 1461, 11868, 445, 1333, 295, 2609, 3166, 13, 51424], "temperature": 0.0, "avg_logprob": -0.11964462000295656, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.010980252176523209}, {"id": 25, "seek": 13240, "start": 153.6, "end": 155.36, "text": " And then it has to go really, really fast.", "tokens": [51424, 400, 550, 309, 575, 281, 352, 534, 11, 534, 2370, 13, 51512], "temperature": 0.0, "avg_logprob": -0.11964462000295656, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.010980252176523209}, {"id": 26, "seek": 13240, "start": 156.08, "end": 159.36, "text": " Yeah. Yeah. All our problems except at 60 times a second.", "tokens": [51548, 865, 13, 865, 13, 1057, 527, 2740, 3993, 412, 4060, 1413, 257, 1150, 13, 51712], "temperature": 0.0, "avg_logprob": -0.11964462000295656, "compression_ratio": 1.693798449612403, "no_speech_prob": 0.010980252176523209}, {"id": 27, "seek": 15936, "start": 159.92000000000002, "end": 166.8, "text": " That's right. Yeah. So your background is originally in game design or data science", "tokens": [50392, 663, 311, 558, 13, 865, 13, 407, 428, 3678, 307, 7993, 294, 1216, 1715, 420, 1412, 3497, 50736], "temperature": 0.0, "avg_logprob": -0.12356183052062988, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.001700389082543552}, {"id": 28, "seek": 15936, "start": 166.8, "end": 171.44000000000003, "text": " for games or what's your origin story? My original background is actually in chemical and", "tokens": [50736, 337, 2813, 420, 437, 311, 428, 4957, 1657, 30, 1222, 3380, 3678, 307, 767, 294, 7313, 293, 50968], "temperature": 0.0, "avg_logprob": -0.12356183052062988, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.001700389082543552}, {"id": 29, "seek": 15936, "start": 171.44000000000003, "end": 177.12, "text": " biomolecular engineering, which is completely unrelated to games. And then I did my master's", "tokens": [50968, 27450, 4812, 17792, 7043, 11, 597, 307, 2584, 38967, 281, 2813, 13, 400, 550, 286, 630, 452, 4505, 311, 51252], "temperature": 0.0, "avg_logprob": -0.12356183052062988, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.001700389082543552}, {"id": 30, "seek": 15936, "start": 177.12, "end": 184.24, "text": " in computer science focusing on distributed systems and machine learning. After that, I did", "tokens": [51252, 294, 3820, 3497, 8416, 322, 12631, 3652, 293, 3479, 2539, 13, 2381, 300, 11, 286, 630, 51608], "temperature": 0.0, "avg_logprob": -0.12356183052062988, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.001700389082543552}, {"id": 31, "seek": 15936, "start": 184.24, "end": 188.48000000000002, "text": " some time at Bloomberg and then Apple and then a company called Machine Zone, which is a game", "tokens": [51608, 512, 565, 412, 40363, 293, 550, 6373, 293, 550, 257, 2237, 1219, 22155, 22800, 11, 597, 307, 257, 1216, 51820], "temperature": 0.0, "avg_logprob": -0.12356183052062988, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.001700389082543552}, {"id": 32, "seek": 18848, "start": 188.48, "end": 194.64, "text": " development company. Right. And what did you do for them? So there I worked in their data science", "tokens": [50364, 3250, 2237, 13, 1779, 13, 400, 437, 630, 291, 360, 337, 552, 30, 407, 456, 286, 2732, 294, 641, 1412, 3497, 50672], "temperature": 0.0, "avg_logprob": -0.06893055154642927, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.00016861782933119684}, {"id": 33, "seek": 18848, "start": 194.64, "end": 201.92, "text": " and engineering department as a data science engineer. And there we were building two things.", "tokens": [50672, 293, 7043, 5882, 382, 257, 1412, 3497, 11403, 13, 400, 456, 321, 645, 2390, 732, 721, 13, 51036], "temperature": 0.0, "avg_logprob": -0.06893055154642927, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.00016861782933119684}, {"id": 34, "seek": 18848, "start": 201.92, "end": 207.2, "text": " One, pipelines for data. So making sure that we got the real live data as quickly as possible", "tokens": [51036, 1485, 11, 40168, 337, 1412, 13, 407, 1455, 988, 300, 321, 658, 264, 957, 1621, 1412, 382, 2661, 382, 1944, 51300], "temperature": 0.0, "avg_logprob": -0.06893055154642927, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.00016861782933119684}, {"id": 35, "seek": 18848, "start": 207.2, "end": 211.6, "text": " into a form that we could then feed into our models. So then the second part of what I did is", "tokens": [51300, 666, 257, 1254, 300, 321, 727, 550, 3154, 666, 527, 5245, 13, 407, 550, 264, 1150, 644, 295, 437, 286, 630, 307, 51520], "temperature": 0.0, "avg_logprob": -0.06893055154642927, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.00016861782933119684}, {"id": 36, "seek": 18848, "start": 211.6, "end": 216.79999999999998, "text": " also build those models, which predicted various things about how players are likely to behave.", "tokens": [51520, 611, 1322, 729, 5245, 11, 597, 19147, 3683, 721, 466, 577, 4150, 366, 3700, 281, 15158, 13, 51780], "temperature": 0.0, "avg_logprob": -0.06893055154642927, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.00016861782933119684}, {"id": 37, "seek": 21680, "start": 216.8, "end": 222.48000000000002, "text": " So like, how likely is this player to turn? How likely is this player to spend money? Will", "tokens": [50364, 407, 411, 11, 577, 3700, 307, 341, 4256, 281, 1261, 30, 1012, 3700, 307, 341, 4256, 281, 3496, 1460, 30, 3099, 50648], "temperature": 0.0, "avg_logprob": -0.11996882079077549, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.002798947971314192}, {"id": 38, "seek": 21680, "start": 222.48000000000002, "end": 227.28, "text": " they give us a good review? That kind of thing. This is a pay to play game. This is a free to", "tokens": [50648, 436, 976, 505, 257, 665, 3131, 30, 663, 733, 295, 551, 13, 639, 307, 257, 1689, 281, 862, 1216, 13, 639, 307, 257, 1737, 281, 50888], "temperature": 0.0, "avg_logprob": -0.11996882079077549, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.002798947971314192}, {"id": 39, "seek": 21680, "start": 227.28, "end": 234.88000000000002, "text": " play game, actually, that is quite expensive. Ultimately. Because it's the business model", "tokens": [50888, 862, 1216, 11, 767, 11, 300, 307, 1596, 5124, 13, 23921, 13, 1436, 309, 311, 264, 1606, 2316, 51268], "temperature": 0.0, "avg_logprob": -0.11996882079077549, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.002798947971314192}, {"id": 40, "seek": 21680, "start": 234.88000000000002, "end": 239.92000000000002, "text": " where like most players don't pay anything, but some pay for like cosmetics upgrades,", "tokens": [51268, 689, 411, 881, 4150, 500, 380, 1689, 1340, 11, 457, 512, 1689, 337, 411, 37416, 24868, 11, 51520], "temperature": 0.0, "avg_logprob": -0.11996882079077549, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.002798947971314192}, {"id": 41, "seek": 21680, "start": 239.92000000000002, "end": 243.28, "text": " that kind of thing. And they spend a lot. No, no, it's much worse than that. So it's a mobile game.", "tokens": [51520, 300, 733, 295, 551, 13, 400, 436, 3496, 257, 688, 13, 883, 11, 572, 11, 309, 311, 709, 5324, 813, 300, 13, 407, 309, 311, 257, 6013, 1216, 13, 51688], "temperature": 0.0, "avg_logprob": -0.11996882079077549, "compression_ratio": 1.7424242424242424, "no_speech_prob": 0.002798947971314192}, {"id": 42, "seek": 24328, "start": 244.24, "end": 250.8, "text": " And it's the whole idea of the game is it's supposed to simulate what it feels like to be a king.", "tokens": [50412, 400, 309, 311, 264, 1379, 1558, 295, 264, 1216, 307, 309, 311, 3442, 281, 27817, 437, 309, 3417, 411, 281, 312, 257, 4867, 13, 50740], "temperature": 0.0, "avg_logprob": -0.1074733432970549, "compression_ratio": 1.6962616822429906, "no_speech_prob": 0.00669053103774786}, {"id": 43, "seek": 24328, "start": 251.36, "end": 257.12, "text": " And so what that ends up being is that you have this little city, it's called the forex game,", "tokens": [50768, 400, 370, 437, 300, 5314, 493, 885, 307, 300, 291, 362, 341, 707, 2307, 11, 309, 311, 1219, 264, 2091, 87, 1216, 11, 51056], "temperature": 0.0, "avg_logprob": -0.1074733432970549, "compression_ratio": 1.6962616822429906, "no_speech_prob": 0.00669053103774786}, {"id": 44, "seek": 24328, "start": 257.12, "end": 262.08, "text": " which is for the four different types of play that you're going to do. And", "tokens": [51056, 597, 307, 337, 264, 1451, 819, 3467, 295, 862, 300, 291, 434, 516, 281, 360, 13, 400, 51304], "temperature": 0.0, "avg_logprob": -0.1074733432970549, "compression_ratio": 1.6962616822429906, "no_speech_prob": 0.00669053103774786}, {"id": 45, "seek": 24328, "start": 264.56, "end": 270.0, "text": " you build the city up, you upgrade your buildings. And then you can start sending marches out to", "tokens": [51428, 291, 1322, 264, 2307, 493, 11, 291, 11484, 428, 7446, 13, 400, 550, 291, 393, 722, 7750, 8368, 279, 484, 281, 51700], "temperature": 0.0, "avg_logprob": -0.1074733432970549, "compression_ratio": 1.6962616822429906, "no_speech_prob": 0.00669053103774786}, {"id": 46, "seek": 27000, "start": 270.0, "end": 275.44, "text": " attack other players. And ultimately, you want to capture a what's called a wonder,", "tokens": [50364, 2690, 661, 4150, 13, 400, 6284, 11, 291, 528, 281, 7983, 257, 437, 311, 1219, 257, 2441, 11, 50636], "temperature": 0.0, "avg_logprob": -0.06408523203252436, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.01639200560748577}, {"id": 47, "seek": 27000, "start": 275.44, "end": 281.28, "text": " which will give you make you the king of the kingdom. And the process of capturing that wonder", "tokens": [50636, 597, 486, 976, 291, 652, 291, 264, 4867, 295, 264, 10231, 13, 400, 264, 1399, 295, 23384, 300, 2441, 50928], "temperature": 0.0, "avg_logprob": -0.06408523203252436, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.01639200560748577}, {"id": 48, "seek": 27000, "start": 281.28, "end": 289.36, "text": " is quite an expensive endeavor. So the way it works is that they sell you speed ups. So upgrades", "tokens": [50928, 307, 1596, 364, 5124, 34975, 13, 407, 264, 636, 309, 1985, 307, 300, 436, 3607, 291, 3073, 15497, 13, 407, 24868, 51332], "temperature": 0.0, "avg_logprob": -0.06408523203252436, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.01639200560748577}, {"id": 49, "seek": 27000, "start": 289.36, "end": 295.04, "text": " take time, you can speed things up by paying for it. And some people pay quite a lot. There were", "tokens": [51332, 747, 565, 11, 291, 393, 3073, 721, 493, 538, 6229, 337, 309, 13, 400, 512, 561, 1689, 1596, 257, 688, 13, 821, 645, 51616], "temperature": 0.0, "avg_logprob": -0.06408523203252436, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.01639200560748577}, {"id": 50, "seek": 29504, "start": 295.04, "end": 300.56, "text": " individuals who spent upwards of several million dollars in that game.", "tokens": [50364, 5346, 567, 4418, 22167, 295, 2940, 2459, 3808, 294, 300, 1216, 13, 50640], "temperature": 0.0, "avg_logprob": -0.1460236061451047, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.016909297555685043}, {"id": 51, "seek": 29504, "start": 301.92, "end": 308.48, "text": " Several million. You heard that correct. If I did not see it myself, I would not have believed it.", "tokens": [50708, 22246, 2459, 13, 509, 2198, 300, 3006, 13, 759, 286, 630, 406, 536, 309, 2059, 11, 286, 576, 406, 362, 7847, 309, 13, 51036], "temperature": 0.0, "avg_logprob": -0.1460236061451047, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.016909297555685043}, {"id": 52, "seek": 29504, "start": 309.36, "end": 315.12, "text": " Gee, I can't, I struggle to compute why someone would do that and how they can be rich enough", "tokens": [51080, 39840, 11, 286, 393, 380, 11, 286, 7799, 281, 14722, 983, 1580, 576, 360, 300, 293, 577, 436, 393, 312, 4593, 1547, 51368], "temperature": 0.0, "avg_logprob": -0.1460236061451047, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.016909297555685043}, {"id": 53, "seek": 29504, "start": 315.12, "end": 320.16, "text": " that that's their disposable income. There were Saudi princes, there were people of that kind.", "tokens": [51368, 300, 300, 311, 641, 41578, 5742, 13, 821, 645, 18121, 41536, 11, 456, 645, 561, 295, 300, 733, 13, 51620], "temperature": 0.0, "avg_logprob": -0.1460236061451047, "compression_ratio": 1.577092511013216, "no_speech_prob": 0.016909297555685043}, {"id": 54, "seek": 32016, "start": 320.16, "end": 325.44, "text": " I mean, it was a global game. And so it attracted a lot of people who were interested in", "tokens": [50364, 286, 914, 11, 309, 390, 257, 4338, 1216, 13, 400, 370, 309, 15912, 257, 688, 295, 561, 567, 645, 3102, 294, 50628], "temperature": 0.0, "avg_logprob": -0.10449591835776528, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.1094944030046463}, {"id": 55, "seek": 32016, "start": 326.24, "end": 332.56, "text": " simulating what it felt like to be a king. There was one person who was rumored to have hired", "tokens": [50668, 1034, 12162, 437, 309, 2762, 411, 281, 312, 257, 4867, 13, 821, 390, 472, 954, 567, 390, 8347, 2769, 281, 362, 13144, 50984], "temperature": 0.0, "avg_logprob": -0.10449591835776528, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.1094944030046463}, {"id": 56, "seek": 32016, "start": 333.12, "end": 337.92, "text": " at least one person or a team of people to actually purchase and open the packs because", "tokens": [51012, 412, 1935, 472, 954, 420, 257, 1469, 295, 561, 281, 767, 8110, 293, 1269, 264, 19403, 570, 51252], "temperature": 0.0, "avg_logprob": -0.10449591835776528, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.1094944030046463}, {"id": 57, "seek": 32016, "start": 338.96000000000004, "end": 345.12, "text": " it's actually mechanically a lot of work to open a $1 million worth of $100 packs,", "tokens": [51304, 309, 311, 767, 4236, 984, 257, 688, 295, 589, 281, 1269, 257, 1848, 16, 2459, 3163, 295, 1848, 6879, 19403, 11, 51612], "temperature": 0.0, "avg_logprob": -0.10449591835776528, "compression_ratio": 1.6192660550458715, "no_speech_prob": 0.1094944030046463}, {"id": 58, "seek": 34512, "start": 345.12, "end": 351.12, "text": " right? That's 10,000. That's 10,000 packs. So there's that. There was another person", "tokens": [50364, 558, 30, 663, 311, 1266, 11, 1360, 13, 663, 311, 1266, 11, 1360, 19403, 13, 407, 456, 311, 300, 13, 821, 390, 1071, 954, 50664], "temperature": 0.0, "avg_logprob": -0.12606825453511786, "compression_ratio": 1.509433962264151, "no_speech_prob": 0.005551200360059738}, {"id": 59, "seek": 34512, "start": 351.12, "end": 356.56, "text": " who used to fly his entire alliance out to Las Vegas to be closer to the servers", "tokens": [50664, 567, 1143, 281, 3603, 702, 2302, 20995, 484, 281, 10663, 15841, 281, 312, 4966, 281, 264, 15909, 50936], "temperature": 0.0, "avg_logprob": -0.12606825453511786, "compression_ratio": 1.509433962264151, "no_speech_prob": 0.005551200360059738}, {"id": 60, "seek": 34512, "start": 357.12, "end": 360.56, "text": " so that they could do the Super Wonder event more effectively.", "tokens": [50964, 370, 300, 436, 727, 360, 264, 4548, 13224, 2280, 544, 8659, 13, 51136], "temperature": 0.0, "avg_logprob": -0.12606825453511786, "compression_ratio": 1.509433962264151, "no_speech_prob": 0.005551200360059738}, {"id": 61, "seek": 34512, "start": 361.6, "end": 367.92, "text": " That's, I mean, A, that's really weird, but B, is it that much weirder than traders putting", "tokens": [51188, 663, 311, 11, 286, 914, 11, 316, 11, 300, 311, 534, 3657, 11, 457, 363, 11, 307, 309, 300, 709, 321, 347, 1068, 813, 26014, 3372, 51504], "temperature": 0.0, "avg_logprob": -0.12606825453511786, "compression_ratio": 1.509433962264151, "no_speech_prob": 0.005551200360059738}, {"id": 62, "seek": 36792, "start": 367.92, "end": 372.08000000000004, "text": " their computers right by their main exchange? I don't know.", "tokens": [50364, 641, 10807, 558, 538, 641, 2135, 7742, 30, 286, 500, 380, 458, 13, 50572], "temperature": 0.0, "avg_logprob": -0.11914380748620194, "compression_ratio": 1.5504587155963303, "no_speech_prob": 0.5268480777740479}, {"id": 63, "seek": 36792, "start": 373.04, "end": 378.48, "text": " I don't, I suppose not. I mean, these people really cared about the game. I asked players,", "tokens": [50620, 286, 500, 380, 11, 286, 7297, 406, 13, 286, 914, 11, 613, 561, 534, 19779, 466, 264, 1216, 13, 286, 2351, 4150, 11, 50892], "temperature": 0.0, "avg_logprob": -0.11914380748620194, "compression_ratio": 1.5504587155963303, "no_speech_prob": 0.5268480777740479}, {"id": 64, "seek": 36792, "start": 379.2, "end": 387.04, "text": " why are you so interested in this game? And I remember one told me, I'm a security guard at", "tokens": [50928, 983, 366, 291, 370, 3102, 294, 341, 1216, 30, 400, 286, 1604, 472, 1907, 385, 11, 286, 478, 257, 3825, 6290, 412, 51320], "temperature": 0.0, "avg_logprob": -0.11914380748620194, "compression_ratio": 1.5504587155963303, "no_speech_prob": 0.5268480777740479}, {"id": 65, "seek": 36792, "start": 387.04, "end": 391.12, "text": " a place or something to that effect. And I just sat there all day and I downloaded this just to", "tokens": [51320, 257, 1081, 420, 746, 281, 300, 1802, 13, 400, 286, 445, 3227, 456, 439, 786, 293, 286, 21748, 341, 445, 281, 51524], "temperature": 0.0, "avg_logprob": -0.11914380748620194, "compression_ratio": 1.5504587155963303, "no_speech_prob": 0.5268480777740479}, {"id": 66, "seek": 39112, "start": 391.12, "end": 397.76, "text": " pass the time. But over time, I found that I had like real actual friends in this game. And", "tokens": [50364, 1320, 264, 565, 13, 583, 670, 565, 11, 286, 1352, 300, 286, 632, 411, 957, 3539, 1855, 294, 341, 1216, 13, 400, 50696], "temperature": 0.0, "avg_logprob": -0.14366978406906128, "compression_ratio": 1.68, "no_speech_prob": 0.07583267241716385}, {"id": 67, "seek": 39112, "start": 399.04, "end": 403.12, "text": " when I would log on, they'd say, oh my God, this person's here. And he felt like somebody,", "tokens": [50760, 562, 286, 576, 3565, 322, 11, 436, 1116, 584, 11, 1954, 452, 1265, 11, 341, 954, 311, 510, 13, 400, 415, 2762, 411, 2618, 11, 50964], "temperature": 0.0, "avg_logprob": -0.14366978406906128, "compression_ratio": 1.68, "no_speech_prob": 0.07583267241716385}, {"id": 68, "seek": 39112, "start": 403.12, "end": 407.28000000000003, "text": " whereas in real life, he did not really feel like someone. And that, that was important to him.", "tokens": [50964, 9735, 294, 957, 993, 11, 415, 630, 406, 534, 841, 411, 1580, 13, 400, 300, 11, 300, 390, 1021, 281, 796, 13, 51172], "temperature": 0.0, "avg_logprob": -0.14366978406906128, "compression_ratio": 1.68, "no_speech_prob": 0.07583267241716385}, {"id": 69, "seek": 39112, "start": 407.28000000000003, "end": 414.24, "text": " Okay, I can see that. But, okay, so curious game mechanics, but that's not why I want to talk to", "tokens": [51172, 1033, 11, 286, 393, 536, 300, 13, 583, 11, 1392, 11, 370, 6369, 1216, 12939, 11, 457, 300, 311, 406, 983, 286, 528, 281, 751, 281, 51520], "temperature": 0.0, "avg_logprob": -0.14366978406906128, "compression_ratio": 1.68, "no_speech_prob": 0.07583267241716385}, {"id": 70, "seek": 39112, "start": 414.24, "end": 420.8, "text": " you. The thing that's, the reason I get into that is because you're there clearly in a", "tokens": [51520, 291, 13, 440, 551, 300, 311, 11, 264, 1778, 286, 483, 666, 300, 307, 570, 291, 434, 456, 4448, 294, 257, 51848], "temperature": 0.0, "avg_logprob": -0.14366978406906128, "compression_ratio": 1.68, "no_speech_prob": 0.07583267241716385}, {"id": 71, "seek": 42080, "start": 420.8, "end": 429.2, "text": " background where there's serious amounts of data coming in live and serious money to be made in", "tokens": [50364, 3678, 689, 456, 311, 3156, 11663, 295, 1412, 1348, 294, 1621, 293, 3156, 1460, 281, 312, 1027, 294, 50784], "temperature": 0.0, "avg_logprob": -0.1123956231509938, "compression_ratio": 1.5919282511210762, "no_speech_prob": 0.0003919687296729535}, {"id": 72, "seek": 42080, "start": 429.2, "end": 436.08000000000004, "text": " understanding the flow of that data. Certainly. Yep. Tell me about that and how it led into", "tokens": [50784, 3701, 264, 3095, 295, 300, 1412, 13, 16628, 13, 7010, 13, 5115, 385, 466, 300, 293, 577, 309, 4684, 666, 51128], "temperature": 0.0, "avg_logprob": -0.1123956231509938, "compression_ratio": 1.5919282511210762, "no_speech_prob": 0.0003919687296729535}, {"id": 73, "seek": 42080, "start": 436.08000000000004, "end": 442.24, "text": " what you did next. Sure. So now this is an interesting story because it's sort of", "tokens": [51128, 437, 291, 630, 958, 13, 4894, 13, 407, 586, 341, 307, 364, 1880, 1657, 570, 309, 311, 1333, 295, 51436], "temperature": 0.0, "avg_logprob": -0.1123956231509938, "compression_ratio": 1.5919282511210762, "no_speech_prob": 0.0003919687296729535}, {"id": 74, "seek": 42080, "start": 442.88, "end": 448.48, "text": " obliquely leads into what we actually ended up building. Because certainly my time at", "tokens": [51468, 1111, 2081, 358, 736, 6689, 666, 437, 321, 767, 4590, 493, 2390, 13, 1436, 3297, 452, 565, 412, 51748], "temperature": 0.0, "avg_logprob": -0.1123956231509938, "compression_ratio": 1.5919282511210762, "no_speech_prob": 0.0003919687296729535}, {"id": 75, "seek": 44848, "start": 448.48, "end": 454.0, "text": " Machine Zone inspired it. But it's not the way I would explain exactly what we're doing. But", "tokens": [50364, 22155, 22800, 7547, 309, 13, 583, 309, 311, 406, 264, 636, 286, 576, 2903, 2293, 437, 321, 434, 884, 13, 583, 50640], "temperature": 0.0, "avg_logprob": -0.0719889481862386, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.0021823332644999027}, {"id": 76, "seek": 44848, "start": 454.0, "end": 460.0, "text": " let me tell you, I suppose the origin story. So while I was at Machine Zone, always we wanted", "tokens": [50640, 718, 385, 980, 291, 11, 286, 7297, 264, 4957, 1657, 13, 407, 1339, 286, 390, 412, 22155, 22800, 11, 1009, 321, 1415, 50940], "temperature": 0.0, "avg_logprob": -0.0719889481862386, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.0021823332644999027}, {"id": 77, "seek": 44848, "start": 460.0, "end": 464.88, "text": " historical data. So we wanted to know not only this is the current power of this individual,", "tokens": [50940, 8584, 1412, 13, 407, 321, 1415, 281, 458, 406, 787, 341, 307, 264, 2190, 1347, 295, 341, 2609, 11, 51184], "temperature": 0.0, "avg_logprob": -0.0719889481862386, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.0021823332644999027}, {"id": 78, "seek": 44848, "start": 464.88, "end": 469.6, "text": " or this is the current set of items that they have. But what is the full history of what they", "tokens": [51184, 420, 341, 307, 264, 2190, 992, 295, 4754, 300, 436, 362, 13, 583, 437, 307, 264, 1577, 2503, 295, 437, 436, 51420], "temperature": 0.0, "avg_logprob": -0.0719889481862386, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.0021823332644999027}, {"id": 79, "seek": 44848, "start": 469.6, "end": 475.84000000000003, "text": " have? So we can predict, for example, hey, look, this person was attacked, they got zeroed out,", "tokens": [51420, 362, 30, 407, 321, 393, 6069, 11, 337, 1365, 11, 4177, 11, 574, 11, 341, 954, 390, 12692, 11, 436, 658, 4018, 292, 484, 11, 51732], "temperature": 0.0, "avg_logprob": -0.0719889481862386, "compression_ratio": 1.724264705882353, "no_speech_prob": 0.0021823332644999027}, {"id": 80, "seek": 47584, "start": 475.84, "end": 479.11999999999995, "text": " and now they left the game, and they're not likely to come back. We always wanted to know", "tokens": [50364, 293, 586, 436, 1411, 264, 1216, 11, 293, 436, 434, 406, 3700, 281, 808, 646, 13, 492, 1009, 1415, 281, 458, 50528], "temperature": 0.0, "avg_logprob": -0.11803901588523781, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.001700292807072401}, {"id": 81, "seek": 47584, "start": 479.11999999999995, "end": 485.59999999999997, "text": " that data. And Machine Zone didn't have that data because the traditional infrastructure of companies", "tokens": [50528, 300, 1412, 13, 400, 22155, 22800, 994, 380, 362, 300, 1412, 570, 264, 5164, 6896, 295, 3431, 50852], "temperature": 0.0, "avg_logprob": -0.11803901588523781, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.001700292807072401}, {"id": 82, "seek": 47584, "start": 485.59999999999997, "end": 496.23999999999995, "text": " is to have their game data or their really website data in normal relational databases, like in this", "tokens": [50852, 307, 281, 362, 641, 1216, 1412, 420, 641, 534, 3144, 1412, 294, 2710, 38444, 22380, 11, 411, 294, 341, 51384], "temperature": 0.0, "avg_logprob": -0.11803901588523781, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.001700292807072401}, {"id": 83, "seek": 47584, "start": 496.23999999999995, "end": 501.76, "text": " case, I believe it was MySQL. Right. And the problem is, when you update someone's power in those", "tokens": [51384, 1389, 11, 286, 1697, 309, 390, 1222, 39934, 13, 1779, 13, 400, 264, 1154, 307, 11, 562, 291, 5623, 1580, 311, 1347, 294, 729, 51660], "temperature": 0.0, "avg_logprob": -0.11803901588523781, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.001700292807072401}, {"id": 84, "seek": 50176, "start": 501.76, "end": 507.92, "text": " databases, the old power goes away. So you need to have some kind of a way to actually get that", "tokens": [50364, 22380, 11, 264, 1331, 1347, 1709, 1314, 13, 407, 291, 643, 281, 362, 512, 733, 295, 257, 636, 281, 767, 483, 300, 50672], "temperature": 0.0, "avg_logprob": -0.07457204225684415, "compression_ratio": 1.7517985611510791, "no_speech_prob": 0.0029804804362356663}, {"id": 85, "seek": 50176, "start": 507.92, "end": 512.96, "text": " historical data. And what they started to do was they were snapshotting their databases every 12", "tokens": [50672, 8584, 1412, 13, 400, 437, 436, 1409, 281, 360, 390, 436, 645, 30163, 783, 641, 22380, 633, 2272, 50924], "temperature": 0.0, "avg_logprob": -0.07457204225684415, "compression_ratio": 1.7517985611510791, "no_speech_prob": 0.0029804804362356663}, {"id": 86, "seek": 50176, "start": 512.96, "end": 519.76, "text": " hours. And we would then get that snapshot data, and we'd try to piece together a historical data.", "tokens": [50924, 2496, 13, 400, 321, 576, 550, 483, 300, 30163, 1412, 11, 293, 321, 1116, 853, 281, 2522, 1214, 257, 8584, 1412, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07457204225684415, "compression_ratio": 1.7517985611510791, "no_speech_prob": 0.0029804804362356663}, {"id": 87, "seek": 50176, "start": 519.76, "end": 525.52, "text": " But that was very sad for two reasons. The first reason is that the data itself was awful, because", "tokens": [51264, 583, 300, 390, 588, 4227, 337, 732, 4112, 13, 440, 700, 1778, 307, 300, 264, 1412, 2564, 390, 11232, 11, 570, 51552], "temperature": 0.0, "avg_logprob": -0.07457204225684415, "compression_ratio": 1.7517985611510791, "no_speech_prob": 0.0029804804362356663}, {"id": 88, "seek": 50176, "start": 526.48, "end": 530.16, "text": " a lot can happen in 12 hours, that could cause you to leave the game, right? So you don't really", "tokens": [51600, 257, 688, 393, 1051, 294, 2272, 2496, 11, 300, 727, 3082, 291, 281, 1856, 264, 1216, 11, 558, 30, 407, 291, 500, 380, 534, 51784], "temperature": 0.0, "avg_logprob": -0.07457204225684415, "compression_ratio": 1.7517985611510791, "no_speech_prob": 0.0029804804362356663}, {"id": 89, "seek": 53016, "start": 530.16, "end": 533.92, "text": " have that information. And I should also say there was another stream of data, which was just event", "tokens": [50364, 362, 300, 1589, 13, 400, 286, 820, 611, 584, 456, 390, 1071, 4309, 295, 1412, 11, 597, 390, 445, 2280, 50552], "temperature": 0.0, "avg_logprob": -0.07718462983438791, "compression_ratio": 1.6644295302013423, "no_speech_prob": 0.002251434838399291}, {"id": 90, "seek": 53016, "start": 533.92, "end": 538.7199999999999, "text": " data. But it was very loosey-goosey event data that was sort of whatever people had slapped together.", "tokens": [50552, 1412, 13, 583, 309, 390, 588, 9612, 88, 12, 1571, 541, 88, 2280, 1412, 300, 390, 1333, 295, 2035, 561, 632, 43309, 1214, 13, 50792], "temperature": 0.0, "avg_logprob": -0.07718462983438791, "compression_ratio": 1.6644295302013423, "no_speech_prob": 0.002251434838399291}, {"id": 91, "seek": 53016, "start": 540.24, "end": 545.1999999999999, "text": " Right. So you tried to build up a picture of what had happened historically from these two sources.", "tokens": [50868, 1779, 13, 407, 291, 3031, 281, 1322, 493, 257, 3036, 295, 437, 632, 2011, 16180, 490, 613, 732, 7139, 13, 51116], "temperature": 0.0, "avg_logprob": -0.07718462983438791, "compression_ratio": 1.6644295302013423, "no_speech_prob": 0.002251434838399291}, {"id": 92, "seek": 53016, "start": 546.0799999999999, "end": 551.76, "text": " And the other reason the snapshotting data was bad was that it was enormous, because if you think", "tokens": [51160, 400, 264, 661, 1778, 264, 30163, 783, 1412, 390, 1578, 390, 300, 309, 390, 11322, 11, 570, 498, 291, 519, 51444], "temperature": 0.0, "avg_logprob": -0.07718462983438791, "compression_ratio": 1.6644295302013423, "no_speech_prob": 0.002251434838399291}, {"id": 93, "seek": 53016, "start": 551.76, "end": 559.68, "text": " about it, 99% of the data in a database does not change in 12 hours. If 99% of your players have", "tokens": [51444, 466, 309, 11, 11803, 4, 295, 264, 1412, 294, 257, 8149, 775, 406, 1319, 294, 2272, 2496, 13, 759, 11803, 4, 295, 428, 4150, 362, 51840], "temperature": 0.0, "avg_logprob": -0.07718462983438791, "compression_ratio": 1.6644295302013423, "no_speech_prob": 0.002251434838399291}, {"id": 94, "seek": 55968, "start": 559.68, "end": 564.7199999999999, "text": " turned, you're just copying this old data every 12 hours. And so eventually, they had to pert to", "tokens": [50364, 3574, 11, 291, 434, 445, 27976, 341, 1331, 1412, 633, 2272, 2496, 13, 400, 370, 4728, 11, 436, 632, 281, 13269, 281, 50616], "temperature": 0.0, "avg_logprob": -0.0904510498046875, "compression_ratio": 1.7723880597014925, "no_speech_prob": 0.0006069859955459833}, {"id": 95, "seek": 55968, "start": 564.7199999999999, "end": 572.56, "text": " the old data, so they couldn't keep it forever. And they spent millions of dollars trying to", "tokens": [50616, 264, 1331, 1412, 11, 370, 436, 2809, 380, 1066, 309, 5680, 13, 400, 436, 4418, 6803, 295, 3808, 1382, 281, 51008], "temperature": 0.0, "avg_logprob": -0.0904510498046875, "compression_ratio": 1.7723880597014925, "no_speech_prob": 0.0006069859955459833}, {"id": 96, "seek": 55968, "start": 572.56, "end": 577.5999999999999, "text": " clean up this data and get it into a form. We built a system which was based on the Lambda", "tokens": [51008, 2541, 493, 341, 1412, 293, 483, 309, 666, 257, 1254, 13, 492, 3094, 257, 1185, 597, 390, 2361, 322, 264, 45691, 51260], "temperature": 0.0, "avg_logprob": -0.0904510498046875, "compression_ratio": 1.7723880597014925, "no_speech_prob": 0.0006069859955459833}, {"id": 97, "seek": 55968, "start": 577.5999999999999, "end": 581.4399999999999, "text": " architecture. And if you're not familiar with how the Lambda architecture works, you essentially", "tokens": [51260, 9482, 13, 400, 498, 291, 434, 406, 4963, 365, 577, 264, 45691, 9482, 1985, 11, 291, 4476, 51452], "temperature": 0.0, "avg_logprob": -0.0904510498046875, "compression_ratio": 1.7723880597014925, "no_speech_prob": 0.0006069859955459833}, {"id": 98, "seek": 55968, "start": 581.4399999999999, "end": 586.64, "text": " set up a streaming part of your data pipeline, and you set up a sort of a batch part of your data", "tokens": [51452, 992, 493, 257, 11791, 644, 295, 428, 1412, 15517, 11, 293, 291, 992, 493, 257, 1333, 295, 257, 15245, 644, 295, 428, 1412, 51712], "temperature": 0.0, "avg_logprob": -0.0904510498046875, "compression_ratio": 1.7723880597014925, "no_speech_prob": 0.0006069859955459833}, {"id": 99, "seek": 58664, "start": 586.64, "end": 594.56, "text": " pipeline, and you try to weave those two together. So you might put all of your big, well-formed data", "tokens": [50364, 15517, 11, 293, 291, 853, 281, 29145, 729, 732, 1214, 13, 407, 291, 1062, 829, 439, 295, 428, 955, 11, 731, 12, 22892, 1412, 50760], "temperature": 0.0, "avg_logprob": -0.10317818972529197, "compression_ratio": 1.576, "no_speech_prob": 0.005909870844334364}, {"id": 100, "seek": 58664, "start": 594.56, "end": 604.3199999999999, "text": " in Hive, which is a write, append-only database made by Facebook for large data, and then you would", "tokens": [50760, 294, 389, 488, 11, 597, 307, 257, 2464, 11, 34116, 12, 25202, 8149, 1027, 538, 4384, 337, 2416, 1412, 11, 293, 550, 291, 576, 51248], "temperature": 0.0, "avg_logprob": -0.10317818972529197, "compression_ratio": 1.576, "no_speech_prob": 0.005909870844334364}, {"id": 101, "seek": 58664, "start": 604.3199999999999, "end": 609.92, "text": " have something like Flink or Apache Spark taking your real-time data and trying to make decision", "tokens": [51248, 362, 746, 411, 3235, 475, 420, 46597, 23424, 1940, 428, 957, 12, 3766, 1412, 293, 1382, 281, 652, 3537, 51528], "temperature": 0.0, "avg_logprob": -0.10317818972529197, "compression_ratio": 1.576, "no_speech_prob": 0.005909870844334364}, {"id": 102, "seek": 58664, "start": 609.92, "end": 615.28, "text": " space in that and bringing it in with your batch process data as well. There's a huge amount of", "tokens": [51528, 1901, 294, 300, 293, 5062, 309, 294, 365, 428, 15245, 1399, 1412, 382, 731, 13, 821, 311, 257, 2603, 2372, 295, 51796], "temperature": 0.0, "avg_logprob": -0.10317818972529197, "compression_ratio": 1.576, "no_speech_prob": 0.005909870844334364}, {"id": 103, "seek": 61528, "start": 615.28, "end": 623.6, "text": " work. And I would say 95% of the data science was actually just getting the data into the", "tokens": [50364, 589, 13, 400, 286, 576, 584, 13420, 4, 295, 264, 1412, 3497, 390, 767, 445, 1242, 264, 1412, 666, 264, 50780], "temperature": 0.0, "avg_logprob": -0.12352539433373345, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.005059018265455961}, {"id": 104, "seek": 61528, "start": 623.6, "end": 629.6, "text": " right form in the right place at the right time. That's a very familiar statement that spans way", "tokens": [50780, 558, 1254, 294, 264, 558, 1081, 412, 264, 558, 565, 13, 663, 311, 257, 588, 4963, 5629, 300, 44086, 636, 51080], "temperature": 0.0, "avg_logprob": -0.12352539433373345, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.005059018265455961}, {"id": 105, "seek": 61528, "start": 629.6, "end": 638.88, "text": " past gaming, right? Absolutely. So when we began to build our own game, I decided I'm not going to", "tokens": [51080, 1791, 9703, 11, 558, 30, 7021, 13, 407, 562, 321, 4283, 281, 1322, 527, 1065, 1216, 11, 286, 3047, 286, 478, 406, 516, 281, 51544], "temperature": 0.0, "avg_logprob": -0.12352539433373345, "compression_ratio": 1.4615384615384615, "no_speech_prob": 0.005059018265455961}, {"id": 106, "seek": 63888, "start": 638.88, "end": 645.52, "text": " have it. We're going to have the full history of the data. So I want to be able to go back to", "tokens": [50364, 362, 309, 13, 492, 434, 516, 281, 362, 264, 1577, 2503, 295, 264, 1412, 13, 407, 286, 528, 281, 312, 1075, 281, 352, 646, 281, 50696], "temperature": 0.0, "avg_logprob": -0.08137739405912511, "compression_ratio": 1.7354260089686098, "no_speech_prob": 0.391975998878479}, {"id": 107, "seek": 63888, "start": 645.52, "end": 650.56, "text": " any point in time and actually see what the game state was. But more than that, I want to actually", "tokens": [50696, 604, 935, 294, 565, 293, 767, 536, 437, 264, 1216, 1785, 390, 13, 583, 544, 813, 300, 11, 286, 528, 281, 767, 50948], "temperature": 0.0, "avg_logprob": -0.08137739405912511, "compression_ratio": 1.7354260089686098, "no_speech_prob": 0.391975998878479}, {"id": 108, "seek": 63888, "start": 650.56, "end": 654.88, "text": " be able to replay it at that time so that you could hop into the game at that time and actually", "tokens": [50948, 312, 1075, 281, 23836, 309, 412, 300, 565, 370, 300, 291, 727, 3818, 666, 264, 1216, 412, 300, 565, 293, 767, 51164], "temperature": 0.0, "avg_logprob": -0.08137739405912511, "compression_ratio": 1.7354260089686098, "no_speech_prob": 0.391975998878479}, {"id": 109, "seek": 63888, "start": 654.88, "end": 663.12, "text": " see it being replayed. On that level of granularity. Right. So you're not just storing events, but", "tokens": [51164, 536, 309, 885, 23836, 292, 13, 1282, 300, 1496, 295, 39962, 507, 13, 1779, 13, 407, 291, 434, 406, 445, 26085, 3931, 11, 457, 51576], "temperature": 0.0, "avg_logprob": -0.08137739405912511, "compression_ratio": 1.7354260089686098, "no_speech_prob": 0.391975998878479}, {"id": 110, "seek": 66312, "start": 663.52, "end": 672.88, "text": " player thumbstick movements and stuff. Correct. And actually, I saw on an earlier podcast that", "tokens": [50384, 4256, 9298, 11881, 9981, 293, 1507, 13, 12753, 13, 400, 767, 11, 286, 1866, 322, 364, 3071, 7367, 300, 50852], "temperature": 0.0, "avg_logprob": -0.10920632615381358, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.0395856648683548}, {"id": 111, "seek": 66312, "start": 672.88, "end": 678.16, "text": " you had, I think it was maybe two weeks ago, you were talking about event streaming. And the guest", "tokens": [50852, 291, 632, 11, 286, 519, 309, 390, 1310, 732, 3259, 2057, 11, 291, 645, 1417, 466, 2280, 11791, 13, 400, 264, 8341, 51116], "temperature": 0.0, "avg_logprob": -0.10920632615381358, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.0395856648683548}, {"id": 112, "seek": 66312, "start": 678.16, "end": 683.92, "text": " there said at the end, this doesn't always work for everything. It doesn't work, for example,", "tokens": [51116, 456, 848, 412, 264, 917, 11, 341, 1177, 380, 1009, 589, 337, 1203, 13, 467, 1177, 380, 589, 11, 337, 1365, 11, 51404], "temperature": 0.0, "avg_logprob": -0.10920632615381358, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.0395856648683548}, {"id": 113, "seek": 66312, "start": 683.92, "end": 689.6, "text": " for games. And I thought, aha, how wrong you are. In fact, this is exactly what we're doing.", "tokens": [51404, 337, 2813, 13, 400, 286, 1194, 11, 47340, 11, 577, 2085, 291, 366, 13, 682, 1186, 11, 341, 307, 2293, 437, 321, 434, 884, 13, 51688], "temperature": 0.0, "avg_logprob": -0.10920632615381358, "compression_ratio": 1.5899581589958158, "no_speech_prob": 0.0395856648683548}, {"id": 114, "seek": 68960, "start": 690.4, "end": 693.76, "text": " So event sourcing is essentially what Space SoundDB does.", "tokens": [50404, 407, 2280, 11006, 2175, 307, 4476, 437, 8705, 14673, 27735, 775, 13, 50572], "temperature": 0.0, "avg_logprob": -0.1715520544897152, "compression_ratio": 1.4424778761061947, "no_speech_prob": 0.0013665144797414541}, {"id": 115, "seek": 68960, "start": 694.48, "end": 701.2, "text": " Okay. That's colossal amounts of data, very widely distributed user base,", "tokens": [50608, 1033, 13, 663, 311, 48683, 304, 11663, 295, 1412, 11, 588, 13371, 12631, 4195, 3096, 11, 50944], "temperature": 0.0, "avg_logprob": -0.1715520544897152, "compression_ratio": 1.4424778761061947, "no_speech_prob": 0.0013665144797414541}, {"id": 116, "seek": 68960, "start": 702.0, "end": 708.5600000000001, "text": " high response times required, because you've got to deal with things 60 frames a second ideally.", "tokens": [50984, 1090, 4134, 1413, 4739, 11, 570, 291, 600, 658, 281, 2028, 365, 721, 4060, 12083, 257, 1150, 22915, 13, 51312], "temperature": 0.0, "avg_logprob": -0.1715520544897152, "compression_ratio": 1.4424778761061947, "no_speech_prob": 0.0013665144797414541}, {"id": 117, "seek": 68960, "start": 711.0400000000001, "end": 716.64, "text": " That's a big challenge. How do you start to break that down into something? What's your approach?", "tokens": [51436, 663, 311, 257, 955, 3430, 13, 1012, 360, 291, 722, 281, 1821, 300, 760, 666, 746, 30, 708, 311, 428, 3109, 30, 51716], "temperature": 0.0, "avg_logprob": -0.1715520544897152, "compression_ratio": 1.4424778761061947, "no_speech_prob": 0.0013665144797414541}, {"id": 118, "seek": 71664, "start": 717.36, "end": 722.64, "text": " I think the best place to start is to first understand what the game is that we're trying to", "tokens": [50400, 286, 519, 264, 1151, 1081, 281, 722, 307, 281, 700, 1223, 437, 264, 1216, 307, 300, 321, 434, 1382, 281, 50664], "temperature": 0.0, "avg_logprob": -0.09769597260848335, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.0006069722585380077}, {"id": 119, "seek": 71664, "start": 722.64, "end": 728.72, "text": " build. And then from that, you can see why Space SoundDB is a necessary requirement. So we have", "tokens": [50664, 1322, 13, 400, 550, 490, 300, 11, 291, 393, 536, 983, 8705, 14673, 27735, 307, 257, 4818, 11695, 13, 407, 321, 362, 50968], "temperature": 0.0, "avg_logprob": -0.09769597260848335, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.0006069722585380077}, {"id": 120, "seek": 71664, "start": 728.72, "end": 734.72, "text": " two products. We have a game called BigCraft Online, which is a massively multiplayer online", "tokens": [50968, 732, 3383, 13, 492, 362, 257, 1216, 1219, 5429, 34, 4469, 16930, 11, 597, 307, 257, 29379, 27325, 2950, 51268], "temperature": 0.0, "avg_logprob": -0.09769597260848335, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.0006069722585380077}, {"id": 121, "seek": 71664, "start": 734.72, "end": 741.28, "text": " role playing game. You can sort of think of it as like a combination between RuneScape,", "tokens": [51268, 3090, 2433, 1216, 13, 509, 393, 1333, 295, 519, 295, 309, 382, 411, 257, 6562, 1296, 497, 2613, 50, 4747, 11, 51596], "temperature": 0.0, "avg_logprob": -0.09769597260848335, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.0006069722585380077}, {"id": 122, "seek": 74128, "start": 741.28, "end": 746.64, "text": " if you're familiar with that, and Minecraft. So there's this very long term", "tokens": [50364, 498, 291, 434, 4963, 365, 300, 11, 293, 21029, 13, 407, 456, 311, 341, 588, 938, 1433, 50632], "temperature": 0.0, "avg_logprob": -0.08182349610835948, "compression_ratio": 1.625, "no_speech_prob": 0.05578918755054474}, {"id": 123, "seek": 74128, "start": 747.4399999999999, "end": 751.76, "text": " skilling and progression in the game. But at the same time, you can actually change and edit the", "tokens": [50672, 5389, 278, 293, 18733, 294, 264, 1216, 13, 583, 412, 264, 912, 565, 11, 291, 393, 767, 1319, 293, 8129, 264, 50888], "temperature": 0.0, "avg_logprob": -0.08182349610835948, "compression_ratio": 1.625, "no_speech_prob": 0.05578918755054474}, {"id": 124, "seek": 74128, "start": 751.76, "end": 758.9599999999999, "text": " world and build your own things within the world. That's the game that we set out to build. And in", "tokens": [50888, 1002, 293, 1322, 428, 1065, 721, 1951, 264, 1002, 13, 663, 311, 264, 1216, 300, 321, 992, 484, 281, 1322, 13, 400, 294, 51248], "temperature": 0.0, "avg_logprob": -0.08182349610835948, "compression_ratio": 1.625, "no_speech_prob": 0.05578918755054474}, {"id": 125, "seek": 74128, "start": 758.9599999999999, "end": 764.3199999999999, "text": " order to do that, notably, the first thing you think is, well, we need to put everybody in a", "tokens": [51248, 1668, 281, 360, 300, 11, 31357, 11, 264, 700, 551, 291, 519, 307, 11, 731, 11, 321, 643, 281, 829, 2201, 294, 257, 51516], "temperature": 0.0, "avg_logprob": -0.08182349610835948, "compression_ratio": 1.625, "no_speech_prob": 0.05578918755054474}, {"id": 126, "seek": 76432, "start": 764.32, "end": 772.24, "text": " single world logically, because you can't have people occupying the same space in the way that", "tokens": [50364, 2167, 1002, 38887, 11, 570, 291, 393, 380, 362, 561, 8073, 1840, 264, 912, 1901, 294, 264, 636, 300, 50760], "temperature": 0.0, "avg_logprob": -0.10291785881167552, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.15602178871631622}, {"id": 127, "seek": 76432, "start": 772.24, "end": 777.7600000000001, "text": " you could in a normal MMORPG, because they actually are editing the world. So if I was a normal MMORPG,", "tokens": [50760, 291, 727, 294, 257, 2710, 34191, 2483, 47, 38, 11, 570, 436, 767, 366, 10000, 264, 1002, 13, 407, 498, 286, 390, 257, 2710, 34191, 2483, 47, 38, 11, 51036], "temperature": 0.0, "avg_logprob": -0.10291785881167552, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.15602178871631622}, {"id": 128, "seek": 76432, "start": 777.7600000000001, "end": 784.32, "text": " I'd put many, many instances all in the same city, right? It doesn't matter. In our game,", "tokens": [51036, 286, 1116, 829, 867, 11, 867, 14519, 439, 294, 264, 912, 2307, 11, 558, 30, 467, 1177, 380, 1871, 13, 682, 527, 1216, 11, 51364], "temperature": 0.0, "avg_logprob": -0.10291785881167552, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.15602178871631622}, {"id": 129, "seek": 76432, "start": 784.32, "end": 788.0, "text": " it certainly does, because you actually need to do that. So now you have a very interesting", "tokens": [51364, 309, 3297, 775, 11, 570, 291, 767, 643, 281, 360, 300, 13, 407, 586, 291, 362, 257, 588, 1880, 51548], "temperature": 0.0, "avg_logprob": -0.10291785881167552, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.15602178871631622}, {"id": 130, "seek": 76432, "start": 788.0, "end": 792.8800000000001, "text": " distributed systems challenge on your hands. Yeah, you've got a large global mutatable state.", "tokens": [51548, 12631, 3652, 3430, 322, 428, 2377, 13, 865, 11, 291, 600, 658, 257, 2416, 4338, 5839, 31415, 1785, 13, 51792], "temperature": 0.0, "avg_logprob": -0.10291785881167552, "compression_ratio": 1.6928571428571428, "no_speech_prob": 0.15602178871631622}, {"id": 131, "seek": 79288, "start": 793.4399999999999, "end": 797.52, "text": " Correct. And it has to be persistent. So if your servers crash, people want to have their", "tokens": [50392, 12753, 13, 400, 309, 575, 281, 312, 24315, 13, 407, 498, 428, 15909, 8252, 11, 561, 528, 281, 362, 641, 50596], "temperature": 0.0, "avg_logprob": -0.08857960753388457, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.0009108033846132457}, {"id": 132, "seek": 79288, "start": 797.52, "end": 804.08, "text": " buildings that they spent their time building and stuff like that. Yeah. So that's the first thing", "tokens": [50596, 7446, 300, 436, 4418, 641, 565, 2390, 293, 1507, 411, 300, 13, 865, 13, 407, 300, 311, 264, 700, 551, 50924], "temperature": 0.0, "avg_logprob": -0.08857960753388457, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.0009108033846132457}, {"id": 133, "seek": 79288, "start": 804.08, "end": 810.56, "text": " you have to understand about how we came at this problem. And so in order to do that, we realized,", "tokens": [50924, 291, 362, 281, 1223, 466, 577, 321, 1361, 412, 341, 1154, 13, 400, 370, 294, 1668, 281, 360, 300, 11, 321, 5334, 11, 51248], "temperature": 0.0, "avg_logprob": -0.08857960753388457, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.0009108033846132457}, {"id": 134, "seek": 79288, "start": 811.12, "end": 816.64, "text": " okay, well, we need a system which is built around the persistence, right? Because", "tokens": [51276, 1392, 11, 731, 11, 321, 643, 257, 1185, 597, 307, 3094, 926, 264, 37617, 11, 558, 30, 1436, 51552], "temperature": 0.0, "avg_logprob": -0.08857960753388457, "compression_ratio": 1.6157205240174672, "no_speech_prob": 0.0009108033846132457}, {"id": 135, "seek": 81664, "start": 817.04, "end": 823.12, "text": " if we're going to be making these permanent changes to the world, and it is everywhere, either we're", "tokens": [50384, 498, 321, 434, 516, 281, 312, 1455, 613, 10996, 2962, 281, 264, 1002, 11, 293, 309, 307, 5315, 11, 2139, 321, 434, 50688], "temperature": 0.0, "avg_logprob": -0.15855584541956583, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.0015010222559794784}, {"id": 136, "seek": 81664, "start": 823.12, "end": 829.12, "text": " going to be doing the normal architecture of games, which I'll take a brief aside to explain. So the", "tokens": [50688, 516, 281, 312, 884, 264, 2710, 9482, 295, 2813, 11, 597, 286, 603, 747, 257, 5353, 7359, 281, 2903, 13, 407, 264, 50988], "temperature": 0.0, "avg_logprob": -0.15855584541956583, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.0015010222559794784}, {"id": 137, "seek": 81664, "start": 829.12, "end": 834.72, "text": " normal architecture is you'd have a game server, you'd have your databases, the game server itself,", "tokens": [50988, 2710, 9482, 307, 291, 1116, 362, 257, 1216, 7154, 11, 291, 1116, 362, 428, 22380, 11, 264, 1216, 7154, 2564, 11, 51268], "temperature": 0.0, "avg_logprob": -0.15855584541956583, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.0015010222559794784}, {"id": 138, "seek": 81664, "start": 834.72, "end": 841.36, "text": " unlike a web server, would have quite a bit of state, right? And you at periodic times,", "tokens": [51268, 8343, 257, 3670, 7154, 11, 576, 362, 1596, 257, 857, 295, 1785, 11, 558, 30, 400, 291, 412, 27790, 1413, 11, 51600], "temperature": 0.0, "avg_logprob": -0.15855584541956583, "compression_ratio": 1.7366071428571428, "no_speech_prob": 0.0015010222559794784}, {"id": 139, "seek": 84136, "start": 841.6, "end": 846.8000000000001, "text": " at periodic times, or when people did important events, would write to the database with a", "tokens": [50376, 412, 27790, 1413, 11, 420, 562, 561, 630, 1021, 3931, 11, 576, 2464, 281, 264, 8149, 365, 257, 50636], "temperature": 0.0, "avg_logprob": -0.11864936485719145, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.009123913012444973}, {"id": 140, "seek": 84136, "start": 846.8000000000001, "end": 853.6, "text": " transaction. And then you get that back. But you as the developer are doing a lot of work to", "tokens": [50636, 14425, 13, 400, 550, 291, 483, 300, 646, 13, 583, 291, 382, 264, 10754, 366, 884, 257, 688, 295, 589, 281, 50976], "temperature": 0.0, "avg_logprob": -0.11864936485719145, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.009123913012444973}, {"id": 141, "seek": 84136, "start": 856.0, "end": 862.0, "text": " maintain, I suppose, synchronicity between your database and your game server state.", "tokens": [51096, 6909, 11, 286, 7297, 11, 5451, 339, 10011, 507, 1296, 428, 8149, 293, 428, 1216, 7154, 1785, 13, 51396], "temperature": 0.0, "avg_logprob": -0.11864936485719145, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.009123913012444973}, {"id": 142, "seek": 84136, "start": 862.64, "end": 869.2, "text": " Because for example, if I kill an enemy, there's a lot of things you can do that make things", "tokens": [51428, 1436, 337, 1365, 11, 498, 286, 1961, 364, 5945, 11, 456, 311, 257, 688, 295, 721, 291, 393, 360, 300, 652, 721, 51756], "temperature": 0.0, "avg_logprob": -0.11864936485719145, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.009123913012444973}, {"id": 143, "seek": 86920, "start": 869.9200000000001, "end": 876.5600000000001, "text": " pretty crazy. But if I kill an enemy, that enemy is probably not, their position is probably not", "tokens": [50400, 1238, 3219, 13, 583, 498, 286, 1961, 364, 5945, 11, 300, 5945, 307, 1391, 406, 11, 641, 2535, 307, 1391, 406, 50732], "temperature": 0.0, "avg_logprob": -0.10119048619674424, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.001169369905255735}, {"id": 144, "seek": 86920, "start": 876.5600000000001, "end": 882.48, "text": " stored in the database, but they that there was an enemy might be, or that you picked up items", "tokens": [50732, 12187, 294, 264, 8149, 11, 457, 436, 300, 456, 390, 364, 5945, 1062, 312, 11, 420, 300, 291, 6183, 493, 4754, 51028], "temperature": 0.0, "avg_logprob": -0.10119048619674424, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.001169369905255735}, {"id": 145, "seek": 86920, "start": 882.48, "end": 887.36, "text": " probably is because if Susie enters your inventory, you don't want to lose that. Or you could do it", "tokens": [51028, 1391, 307, 570, 498, 9545, 414, 18780, 428, 14228, 11, 291, 500, 380, 528, 281, 3624, 300, 13, 1610, 291, 727, 360, 309, 51272], "temperature": 0.0, "avg_logprob": -0.10119048619674424, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.001169369905255735}, {"id": 146, "seek": 86920, "start": 887.36, "end": 892.6400000000001, "text": " periodically, and then they could do replays and stuff. What you end up getting to is a place where", "tokens": [51272, 38916, 11, 293, 550, 436, 727, 360, 23836, 82, 293, 1507, 13, 708, 291, 917, 493, 1242, 281, 307, 257, 1081, 689, 51536], "temperature": 0.0, "avg_logprob": -0.10119048619674424, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.001169369905255735}, {"id": 147, "seek": 86920, "start": 892.6400000000001, "end": 898.5600000000001, "text": " you're spending a lot of your time as the game developer, not thinking about the actual gameplay", "tokens": [51536, 291, 434, 6434, 257, 688, 295, 428, 565, 382, 264, 1216, 10754, 11, 406, 1953, 466, 264, 3539, 11421, 51832], "temperature": 0.0, "avg_logprob": -0.10119048619674424, "compression_ratio": 1.7366548042704626, "no_speech_prob": 0.001169369905255735}, {"id": 148, "seek": 89856, "start": 898.56, "end": 903.5999999999999, "text": " programming, and rather thinking about the distributed system environment in which you're", "tokens": [50364, 9410, 11, 293, 2831, 1953, 466, 264, 12631, 1185, 2823, 294, 597, 291, 434, 50616], "temperature": 0.0, "avg_logprob": -0.08408995650031349, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.0004727331397589296}, {"id": 149, "seek": 89856, "start": 903.5999999999999, "end": 911.1999999999999, "text": " actually building this game. Yeah, I can believe that. So what we decided to do is say, we are going", "tokens": [50616, 767, 2390, 341, 1216, 13, 865, 11, 286, 393, 1697, 300, 13, 407, 437, 321, 3047, 281, 360, 307, 584, 11, 321, 366, 516, 50996], "temperature": 0.0, "avg_logprob": -0.08408995650031349, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.0004727331397589296}, {"id": 150, "seek": 89856, "start": 911.1999999999999, "end": 916.56, "text": " to make that all, I suppose, opaque to the game developer, and we're going to put them in a context", "tokens": [50996, 281, 652, 300, 439, 11, 286, 7297, 11, 42687, 281, 264, 1216, 10754, 11, 293, 321, 434, 516, 281, 829, 552, 294, 257, 4319, 51264], "temperature": 0.0, "avg_logprob": -0.08408995650031349, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.0004727331397589296}, {"id": 151, "seek": 89856, "start": 917.1199999999999, "end": 922.9599999999999, "text": " where they're operating inside a transaction already. That transaction is going to be manipulating", "tokens": [51292, 689, 436, 434, 7447, 1854, 257, 14425, 1217, 13, 663, 14425, 307, 516, 281, 312, 40805, 51584], "temperature": 0.0, "avg_logprob": -0.08408995650031349, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.0004727331397589296}, {"id": 152, "seek": 92296, "start": 923.0400000000001, "end": 930.0, "text": " in memory data. And then we are going to do all of the necessary things to persist that data to", "tokens": [50368, 294, 4675, 1412, 13, 400, 550, 321, 366, 516, 281, 360, 439, 295, 264, 4818, 721, 281, 13233, 300, 1412, 281, 50716], "temperature": 0.0, "avg_logprob": -0.11625604950979854, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.003705098293721676}, {"id": 153, "seek": 92296, "start": 930.0, "end": 936.4000000000001, "text": " disk so that the gameplay programmer does not have to think about that at all. What's that look", "tokens": [50716, 12355, 370, 300, 264, 11421, 32116, 775, 406, 362, 281, 519, 466, 300, 412, 439, 13, 708, 311, 300, 574, 51036], "temperature": 0.0, "avg_logprob": -0.11625604950979854, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.003705098293721676}, {"id": 154, "seek": 92296, "start": 936.4000000000001, "end": 942.8000000000001, "text": " like for the programmer? They just, they're treating their local client side instances,", "tokens": [51036, 411, 337, 264, 32116, 30, 814, 445, 11, 436, 434, 15083, 641, 2654, 6423, 1252, 14519, 11, 51356], "temperature": 0.0, "avg_logprob": -0.11625604950979854, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.003705098293721676}, {"id": 155, "seek": 92296, "start": 942.8000000000001, "end": 951.52, "text": " though it's a relational database. Is this what you say? That is one consequence. But the main", "tokens": [51356, 1673, 309, 311, 257, 38444, 8149, 13, 1119, 341, 437, 291, 584, 30, 663, 307, 472, 18326, 13, 583, 264, 2135, 51792], "temperature": 0.0, "avg_logprob": -0.11625604950979854, "compression_ratio": 1.5914893617021277, "no_speech_prob": 0.003705098293721676}, {"id": 156, "seek": 95152, "start": 951.52, "end": 958.88, "text": " point of what I'm saying is that on the server, all things inside of BitCraft happen", "tokens": [50364, 935, 295, 437, 286, 478, 1566, 307, 300, 322, 264, 7154, 11, 439, 721, 1854, 295, 9101, 34, 4469, 1051, 50732], "temperature": 0.0, "avg_logprob": -0.09162572938568737, "compression_ratio": 1.6347826086956523, "no_speech_prob": 0.012817028909921646}, {"id": 157, "seek": 95152, "start": 959.84, "end": 965.84, "text": " within a database. So let me explain just a little bit about how SpacetimeDB works and what it is", "tokens": [50780, 1951, 257, 8149, 13, 407, 718, 385, 2903, 445, 257, 707, 857, 466, 577, 1738, 326, 9764, 27735, 1985, 293, 437, 309, 307, 51080], "temperature": 0.0, "avg_logprob": -0.09162572938568737, "compression_ratio": 1.6347826086956523, "no_speech_prob": 0.012817028909921646}, {"id": 158, "seek": 95152, "start": 965.84, "end": 970.88, "text": " actually. So we built this game and we wanted to do this in this way. So we built a system called", "tokens": [51080, 767, 13, 407, 321, 3094, 341, 1216, 293, 321, 1415, 281, 360, 341, 294, 341, 636, 13, 407, 321, 3094, 257, 1185, 1219, 51332], "temperature": 0.0, "avg_logprob": -0.09162572938568737, "compression_ratio": 1.6347826086956523, "no_speech_prob": 0.012817028909921646}, {"id": 159, "seek": 95152, "start": 970.88, "end": 978.0799999999999, "text": " SpacetimeDB, which is fundamentally a database. So it's very focused on persistence. The way it", "tokens": [51332, 1738, 326, 9764, 27735, 11, 597, 307, 17879, 257, 8149, 13, 407, 309, 311, 588, 5178, 322, 37617, 13, 440, 636, 309, 51692], "temperature": 0.0, "avg_logprob": -0.09162572938568737, "compression_ratio": 1.6347826086956523, "no_speech_prob": 0.012817028909921646}, {"id": 160, "seek": 97808, "start": 978.08, "end": 985.0400000000001, "text": " works is you take BitCraft, you compile it to a WebAssembly module, you upload that into the", "tokens": [50364, 1985, 307, 291, 747, 9101, 34, 4469, 11, 291, 31413, 309, 281, 257, 9573, 10884, 19160, 10088, 11, 291, 6580, 300, 666, 264, 50712], "temperature": 0.0, "avg_logprob": -0.061594476603498365, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.0022514276206493378}, {"id": 161, "seek": 97808, "start": 985.0400000000001, "end": 990.1600000000001, "text": " database, and then clients connect directly to the database. And now I hear a lot of people", "tokens": [50712, 8149, 11, 293, 550, 6982, 1745, 3838, 281, 264, 8149, 13, 400, 586, 286, 1568, 257, 688, 295, 561, 50968], "temperature": 0.0, "avg_logprob": -0.061594476603498365, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.0022514276206493378}, {"id": 162, "seek": 97808, "start": 990.1600000000001, "end": 995.9200000000001, "text": " in the audience screaming, oh, you can't do that. You couldn't do that. And it maybe was a bad idea", "tokens": [50968, 294, 264, 4034, 12636, 11, 1954, 11, 291, 393, 380, 360, 300, 13, 509, 2809, 380, 360, 300, 13, 400, 309, 1310, 390, 257, 1578, 1558, 51256], "temperature": 0.0, "avg_logprob": -0.061594476603498365, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.0022514276206493378}, {"id": 163, "seek": 97808, "start": 995.9200000000001, "end": 1003.9200000000001, "text": " for databases like Postgres and so forth. But we have built a permissions model around SpacetimeDB", "tokens": [51256, 337, 22380, 411, 10223, 45189, 293, 370, 5220, 13, 583, 321, 362, 3094, 257, 32723, 2316, 926, 1738, 326, 9764, 27735, 51656], "temperature": 0.0, "avg_logprob": -0.061594476603498365, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.0022514276206493378}, {"id": 164, "seek": 100392, "start": 1003.92, "end": 1013.92, "text": " that allows you to do that safely. And so the way that works is you, as a client, call what we", "tokens": [50364, 300, 4045, 291, 281, 360, 300, 11750, 13, 400, 370, 264, 636, 300, 1985, 307, 291, 11, 382, 257, 6423, 11, 818, 437, 321, 50864], "temperature": 0.0, "avg_logprob": -0.08009550419259578, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0026313778944313526}, {"id": 165, "seek": 100392, "start": 1013.92, "end": 1019.4399999999999, "text": " call reducers on the database. They're very similar to store procedures. And then those store procedures", "tokens": [50864, 818, 2783, 8530, 322, 264, 8149, 13, 814, 434, 588, 2531, 281, 3531, 13846, 13, 400, 550, 729, 3531, 13846, 51140], "temperature": 0.0, "avg_logprob": -0.08009550419259578, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0026313778944313526}, {"id": 166, "seek": 100392, "start": 1019.4399999999999, "end": 1023.76, "text": " which are written in whatever language you want that compiles the WebAssembly will access things", "tokens": [51140, 597, 366, 3720, 294, 2035, 2856, 291, 528, 300, 715, 4680, 264, 9573, 10884, 19160, 486, 2105, 721, 51356], "temperature": 0.0, "avg_logprob": -0.08009550419259578, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0026313778944313526}, {"id": 167, "seek": 100392, "start": 1023.76, "end": 1028.3999999999999, "text": " from the database and write them back to the database. So just as an example, let's say we had", "tokens": [51356, 490, 264, 8149, 293, 2464, 552, 646, 281, 264, 8149, 13, 407, 445, 382, 364, 1365, 11, 718, 311, 584, 321, 632, 51588], "temperature": 0.0, "avg_logprob": -0.08009550419259578, "compression_ratio": 1.6926406926406927, "no_speech_prob": 0.0026313778944313526}, {"id": 168, "seek": 102840, "start": 1028.48, "end": 1032.96, "text": " player move. And notably, everything in BitCraft, including all the player movement,", "tokens": [50368, 4256, 1286, 13, 400, 31357, 11, 1203, 294, 9101, 34, 4469, 11, 3009, 439, 264, 4256, 3963, 11, 50592], "temperature": 0.0, "avg_logprob": -0.09985956975391932, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.21453246474266052}, {"id": 169, "seek": 102840, "start": 1032.96, "end": 1037.44, "text": " all the chat, all the trees, all the ground, everything is stored within the database.", "tokens": [50592, 439, 264, 5081, 11, 439, 264, 5852, 11, 439, 264, 2727, 11, 1203, 307, 12187, 1951, 264, 8149, 13, 50816], "temperature": 0.0, "avg_logprob": -0.09985956975391932, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.21453246474266052}, {"id": 170, "seek": 102840, "start": 1038.16, "end": 1042.64, "text": " So if we want to move a player, what we do is we call a reducer called move player", "tokens": [50852, 407, 498, 321, 528, 281, 1286, 257, 4256, 11, 437, 321, 360, 307, 321, 818, 257, 2783, 1776, 1219, 1286, 4256, 51076], "temperature": 0.0, "avg_logprob": -0.09985956975391932, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.21453246474266052}, {"id": 171, "seek": 102840, "start": 1042.64, "end": 1047.44, "text": " on the server that updates some rows in the database and then commits those rows. And that's it.", "tokens": [51076, 322, 264, 7154, 300, 9205, 512, 13241, 294, 264, 8149, 293, 550, 48311, 729, 13241, 13, 400, 300, 311, 309, 13, 51316], "temperature": 0.0, "avg_logprob": -0.09985956975391932, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.21453246474266052}, {"id": 172, "seek": 102840, "start": 1048.4, "end": 1055.44, "text": " Then clients, other clients will subscribe to the database state. So they'll say, I want to select", "tokens": [51364, 1396, 6982, 11, 661, 6982, 486, 3022, 281, 264, 8149, 1785, 13, 407, 436, 603, 584, 11, 286, 528, 281, 3048, 51716], "temperature": 0.0, "avg_logprob": -0.09985956975391932, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.21453246474266052}, {"id": 173, "seek": 105544, "start": 1055.44, "end": 1062.0, "text": " star from player position, where they are near me, basically, would be what that word clause would", "tokens": [50364, 3543, 490, 4256, 2535, 11, 689, 436, 366, 2651, 385, 11, 1936, 11, 576, 312, 437, 300, 1349, 25925, 576, 50692], "temperature": 0.0, "avg_logprob": -0.1497222355433873, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.001244444283656776}, {"id": 174, "seek": 105544, "start": 1062.0, "end": 1067.04, "text": " say. And then all connected clients that have subscribed to that, when that player moves,", "tokens": [50692, 584, 13, 400, 550, 439, 4582, 6982, 300, 362, 16665, 281, 300, 11, 562, 300, 4256, 6067, 11, 50944], "temperature": 0.0, "avg_logprob": -0.1497222355433873, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.001244444283656776}, {"id": 175, "seek": 105544, "start": 1067.04, "end": 1072.48, "text": " we'll hear about those rows and their updates, and then automatically update it in the database.", "tokens": [50944, 321, 603, 1568, 466, 729, 13241, 293, 641, 9205, 11, 293, 550, 6772, 5623, 309, 294, 264, 8149, 13, 51216], "temperature": 0.0, "avg_logprob": -0.1497222355433873, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.001244444283656776}, {"id": 176, "seek": 105544, "start": 1072.48, "end": 1079.68, "text": " I'm sorry, on their local client. So hang on, where is the database? The database is on a server", "tokens": [51216, 286, 478, 2597, 11, 322, 641, 2654, 6423, 13, 407, 3967, 322, 11, 689, 307, 264, 8149, 30, 440, 8149, 307, 322, 257, 7154, 51576], "temperature": 0.0, "avg_logprob": -0.1497222355433873, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.001244444283656776}, {"id": 177, "seek": 107968, "start": 1080.3200000000002, "end": 1086.24, "text": " stored. In this case, I believe in New York. Okay, so how on earth does that possibly work", "tokens": [50396, 12187, 13, 682, 341, 1389, 11, 286, 1697, 294, 1873, 3609, 13, 1033, 11, 370, 577, 322, 4120, 775, 300, 6264, 589, 50692], "temperature": 0.0, "avg_logprob": -0.11018892210357044, "compression_ratio": 1.5609756097560976, "no_speech_prob": 0.04206391051411629}, {"id": 178, "seek": 107968, "start": 1086.24, "end": 1092.16, "text": " when I'm moving and expecting things to update 60 times a second? So, okay, this is the first thing", "tokens": [50692, 562, 286, 478, 2684, 293, 9650, 721, 281, 5623, 4060, 1413, 257, 1150, 30, 407, 11, 1392, 11, 341, 307, 264, 700, 551, 50988], "temperature": 0.0, "avg_logprob": -0.11018892210357044, "compression_ratio": 1.5609756097560976, "no_speech_prob": 0.04206391051411629}, {"id": 179, "seek": 107968, "start": 1092.16, "end": 1098.0800000000002, "text": " that's interesting about games. You would not have a tick rate on the server that's 60 times per", "tokens": [50988, 300, 311, 1880, 466, 2813, 13, 509, 576, 406, 362, 257, 5204, 3314, 322, 264, 7154, 300, 311, 4060, 1413, 680, 51284], "temperature": 0.0, "avg_logprob": -0.11018892210357044, "compression_ratio": 1.5609756097560976, "no_speech_prob": 0.04206391051411629}, {"id": 180, "seek": 107968, "start": 1098.0800000000002, "end": 1103.8400000000001, "text": " second, unless you were making a game like Counter Strike. So typically, I'll give you sort of a", "tokens": [51284, 1150, 11, 5969, 291, 645, 1455, 257, 1216, 411, 35607, 32788, 13, 407, 5850, 11, 286, 603, 976, 291, 1333, 295, 257, 51572], "temperature": 0.0, "avg_logprob": -0.11018892210357044, "compression_ratio": 1.5609756097560976, "no_speech_prob": 0.04206391051411629}, {"id": 181, "seek": 110384, "start": 1103.84, "end": 1110.56, "text": " range. Minecraft updates 20 times per second. So every 50 milliseconds. RuneScape updates,", "tokens": [50364, 3613, 13, 21029, 9205, 945, 1413, 680, 1150, 13, 407, 633, 2625, 34184, 13, 497, 2613, 50, 4747, 9205, 11, 50700], "temperature": 0.0, "avg_logprob": -0.0997839181319527, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.04078739136457443}, {"id": 182, "seek": 110384, "start": 1110.56, "end": 1117.12, "text": " I believe, four times a second. So every quarter of a second. So there's a variety of different", "tokens": [50700, 286, 1697, 11, 1451, 1413, 257, 1150, 13, 407, 633, 6555, 295, 257, 1150, 13, 407, 456, 311, 257, 5673, 295, 819, 51028], "temperature": 0.0, "avg_logprob": -0.0997839181319527, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.04078739136457443}, {"id": 183, "seek": 110384, "start": 1117.12, "end": 1122.9599999999998, "text": " levels that you can do. Generally speaking, the larger your game is, obviously, the fewer updates", "tokens": [51028, 4358, 300, 291, 393, 360, 13, 21082, 4124, 11, 264, 4833, 428, 1216, 307, 11, 2745, 11, 264, 13366, 9205, 51320], "temperature": 0.0, "avg_logprob": -0.0997839181319527, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.04078739136457443}, {"id": 184, "seek": 110384, "start": 1122.9599999999998, "end": 1127.4399999999998, "text": " per second you want to be doing, because there's so many entities to move within a timeframe.", "tokens": [51320, 680, 1150, 291, 528, 281, 312, 884, 11, 570, 456, 311, 370, 867, 16667, 281, 1286, 1951, 257, 34830, 13, 51544], "temperature": 0.0, "avg_logprob": -0.0997839181319527, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.04078739136457443}, {"id": 185, "seek": 112744, "start": 1128.0, "end": 1134.4, "text": " Yeah, but I mean, I'm in London. I'm not sure I can guarantee four frames a second in New York", "tokens": [50392, 865, 11, 457, 286, 914, 11, 286, 478, 294, 7042, 13, 286, 478, 406, 988, 286, 393, 10815, 1451, 12083, 257, 1150, 294, 1873, 3609, 50712], "temperature": 0.0, "avg_logprob": -0.12567846447813744, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.009405199438333511}, {"id": 186, "seek": 112744, "start": 1134.4, "end": 1142.16, "text": " and back. I see. So I understand your question now. With any game like this, you do not wait for", "tokens": [50712, 293, 646, 13, 286, 536, 13, 407, 286, 1223, 428, 1168, 586, 13, 2022, 604, 1216, 411, 341, 11, 291, 360, 406, 1699, 337, 51100], "temperature": 0.0, "avg_logprob": -0.12567846447813744, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.009405199438333511}, {"id": 187, "seek": 112744, "start": 1142.16, "end": 1148.96, "text": " the round trip. So how long would the round trip be from New York to London? I actually happen to", "tokens": [51100, 264, 3098, 4931, 13, 407, 577, 938, 576, 264, 3098, 4931, 312, 490, 1873, 3609, 281, 7042, 30, 286, 767, 1051, 281, 51440], "temperature": 0.0, "avg_logprob": -0.12567846447813744, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.009405199438333511}, {"id": 188, "seek": 112744, "start": 1148.96, "end": 1154.24, "text": " know it's about 80 milliseconds or 70 milliseconds, something like that. So it's actually not crazy.", "tokens": [51440, 458, 309, 311, 466, 4688, 34184, 420, 5285, 34184, 11, 746, 411, 300, 13, 407, 309, 311, 767, 406, 3219, 13, 51704], "temperature": 0.0, "avg_logprob": -0.12567846447813744, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.009405199438333511}, {"id": 189, "seek": 115424, "start": 1154.56, "end": 1158.64, "text": " You can play it without what's called client side prediction. But the typical way", "tokens": [50380, 509, 393, 862, 309, 1553, 437, 311, 1219, 6423, 1252, 17630, 13, 583, 264, 7476, 636, 50584], "temperature": 0.0, "avg_logprob": -0.08516998466001738, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.009121889248490334}, {"id": 190, "seek": 115424, "start": 1158.64, "end": 1162.48, "text": " that you would actually do this is you'd run client side prediction. What does that mean?", "tokens": [50584, 300, 291, 576, 767, 360, 341, 307, 291, 1116, 1190, 6423, 1252, 17630, 13, 708, 775, 300, 914, 30, 50776], "temperature": 0.0, "avg_logprob": -0.08516998466001738, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.009121889248490334}, {"id": 191, "seek": 115424, "start": 1162.48, "end": 1170.64, "text": " That means that I as a client have some subset of the server state. And when a player, my player,", "tokens": [50776, 663, 1355, 300, 286, 382, 257, 6423, 362, 512, 25993, 295, 264, 7154, 1785, 13, 400, 562, 257, 4256, 11, 452, 4256, 11, 51184], "temperature": 0.0, "avg_logprob": -0.08516998466001738, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.009121889248490334}, {"id": 192, "seek": 115424, "start": 1170.64, "end": 1176.48, "text": " decides to do something, I can predict what the server is going to do to my local state,", "tokens": [51184, 14898, 281, 360, 746, 11, 286, 393, 6069, 437, 264, 7154, 307, 516, 281, 360, 281, 452, 2654, 1785, 11, 51476], "temperature": 0.0, "avg_logprob": -0.08516998466001738, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.009121889248490334}, {"id": 193, "seek": 115424, "start": 1177.1200000000001, "end": 1180.16, "text": " assuming that it will work. So based on the state of the world as I know it,", "tokens": [51508, 11926, 300, 309, 486, 589, 13, 407, 2361, 322, 264, 1785, 295, 264, 1002, 382, 286, 458, 309, 11, 51660], "temperature": 0.0, "avg_logprob": -0.08516998466001738, "compression_ratio": 1.7469879518072289, "no_speech_prob": 0.009121889248490334}, {"id": 194, "seek": 118016, "start": 1180.88, "end": 1186.8000000000002, "text": " if I try to move, I should be able to update my local state, assuming the server will agree with", "tokens": [50400, 498, 286, 853, 281, 1286, 11, 286, 820, 312, 1075, 281, 5623, 452, 2654, 1785, 11, 11926, 264, 7154, 486, 3986, 365, 50696], "temperature": 0.0, "avg_logprob": -0.07323818519467214, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.0025504238437861204}, {"id": 195, "seek": 118016, "start": 1186.8000000000002, "end": 1191.8400000000001, "text": " me. And so I will do that. And then I will immediately see the results of that on my own", "tokens": [50696, 385, 13, 400, 370, 286, 486, 360, 300, 13, 400, 550, 286, 486, 4258, 536, 264, 3542, 295, 300, 322, 452, 1065, 50948], "temperature": 0.0, "avg_logprob": -0.07323818519467214, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.0025504238437861204}, {"id": 196, "seek": 118016, "start": 1191.8400000000001, "end": 1197.28, "text": " local client. But I will send something to the server. Now, if the server agrees, we basically", "tokens": [50948, 2654, 6423, 13, 583, 286, 486, 2845, 746, 281, 264, 7154, 13, 823, 11, 498, 264, 7154, 26383, 11, 321, 1936, 51220], "temperature": 0.0, "avg_logprob": -0.07323818519467214, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.0025504238437861204}, {"id": 197, "seek": 118016, "start": 1197.28, "end": 1203.0400000000002, "text": " come back, we reconcile, no problem. If the server disagrees, let's say somebody exploded a bomb", "tokens": [51220, 808, 646, 11, 321, 41059, 11, 572, 1154, 13, 759, 264, 7154, 10414, 4856, 11, 718, 311, 584, 2618, 27049, 257, 7851, 51508], "temperature": 0.0, "avg_logprob": -0.07323818519467214, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.0025504238437861204}, {"id": 198, "seek": 118016, "start": 1203.0400000000002, "end": 1209.8400000000001, "text": " that your client hadn't heard about yet, right on top of you. And the thing you try to do is", "tokens": [51508, 300, 428, 6423, 8782, 380, 2198, 466, 1939, 11, 558, 322, 1192, 295, 291, 13, 400, 264, 551, 291, 853, 281, 360, 307, 51848], "temperature": 0.0, "avg_logprob": -0.07323818519467214, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.0025504238437861204}, {"id": 199, "seek": 120984, "start": 1209.9199999999998, "end": 1216.0, "text": " invalidated by that. Maybe you're dead now. What will happen is you will have sent a request to", "tokens": [50368, 34702, 770, 538, 300, 13, 2704, 291, 434, 3116, 586, 13, 708, 486, 1051, 307, 291, 486, 362, 2279, 257, 5308, 281, 50672], "temperature": 0.0, "avg_logprob": -0.12139014708690155, "compression_ratio": 1.83011583011583, "no_speech_prob": 0.0009398283436894417}, {"id": 200, "seek": 120984, "start": 1216.0, "end": 1220.8, "text": " the server that says, I want to move. The server interjects and says, actually, you died.", "tokens": [50672, 264, 7154, 300, 1619, 11, 286, 528, 281, 1286, 13, 440, 7154, 46787, 82, 293, 1619, 11, 767, 11, 291, 4539, 13, 50912], "temperature": 0.0, "avg_logprob": -0.12139014708690155, "compression_ratio": 1.83011583011583, "no_speech_prob": 0.0009398283436894417}, {"id": 201, "seek": 120984, "start": 1223.04, "end": 1228.32, "text": " What will happen is your client will say, oh, I understand, it will roll back to the point at", "tokens": [51024, 708, 486, 1051, 307, 428, 6423, 486, 584, 11, 1954, 11, 286, 1223, 11, 309, 486, 3373, 646, 281, 264, 935, 412, 51288], "temperature": 0.0, "avg_logprob": -0.12139014708690155, "compression_ratio": 1.83011583011583, "no_speech_prob": 0.0009398283436894417}, {"id": 202, "seek": 120984, "start": 1228.32, "end": 1233.9199999999998, "text": " which you were going to move. And it will then play forward the updates as they actually happen", "tokens": [51288, 597, 291, 645, 516, 281, 1286, 13, 400, 309, 486, 550, 862, 2128, 264, 9205, 382, 436, 767, 1051, 51568], "temperature": 0.0, "avg_logprob": -0.12139014708690155, "compression_ratio": 1.83011583011583, "no_speech_prob": 0.0009398283436894417}, {"id": 203, "seek": 120984, "start": 1233.9199999999998, "end": 1239.36, "text": " from the server and then try to replay your move. So it would go originally before you heard about", "tokens": [51568, 490, 264, 7154, 293, 550, 853, 281, 23836, 428, 1286, 13, 407, 309, 576, 352, 7993, 949, 291, 2198, 466, 51840], "temperature": 0.0, "avg_logprob": -0.12139014708690155, "compression_ratio": 1.83011583011583, "no_speech_prob": 0.0009398283436894417}, {"id": 204, "seek": 123936, "start": 1239.36, "end": 1244.56, "text": " from the server, it would go, you're standing here, you move, you actually move. Then what happens", "tokens": [50364, 490, 264, 7154, 11, 309, 576, 352, 11, 291, 434, 4877, 510, 11, 291, 1286, 11, 291, 767, 1286, 13, 1396, 437, 2314, 50624], "temperature": 0.0, "avg_logprob": -0.09579215730939593, "compression_ratio": 1.7375, "no_speech_prob": 0.0008556681568734348}, {"id": 205, "seek": 123936, "start": 1244.56, "end": 1249.52, "text": " is you hear about the bomb, you roll back to the point at which you were about to move,", "tokens": [50624, 307, 291, 1568, 466, 264, 7851, 11, 291, 3373, 646, 281, 264, 935, 412, 597, 291, 645, 466, 281, 1286, 11, 50872], "temperature": 0.0, "avg_logprob": -0.09579215730939593, "compression_ratio": 1.7375, "no_speech_prob": 0.0008556681568734348}, {"id": 206, "seek": 123936, "start": 1250.32, "end": 1255.1999999999998, "text": " you then blow up because of the bomb. And then you find out, then at that point, you try to move,", "tokens": [50912, 291, 550, 6327, 493, 570, 295, 264, 7851, 13, 400, 550, 291, 915, 484, 11, 550, 412, 300, 935, 11, 291, 853, 281, 1286, 11, 51156], "temperature": 0.0, "avg_logprob": -0.09579215730939593, "compression_ratio": 1.7375, "no_speech_prob": 0.0008556681568734348}, {"id": 207, "seek": 123936, "start": 1255.1999999999998, "end": 1259.52, "text": " but you can't move because you're dead. Right. And that's how that reconciles.", "tokens": [51156, 457, 291, 393, 380, 1286, 570, 291, 434, 3116, 13, 1779, 13, 400, 300, 311, 577, 300, 9993, 3208, 279, 13, 51372], "temperature": 0.0, "avg_logprob": -0.09579215730939593, "compression_ratio": 1.7375, "no_speech_prob": 0.0008556681568734348}, {"id": 208, "seek": 123936, "start": 1259.52, "end": 1262.8, "text": " This sounds very like transaction on the client side.", "tokens": [51372, 639, 3263, 588, 411, 14425, 322, 264, 6423, 1252, 13, 51536], "temperature": 0.0, "avg_logprob": -0.09579215730939593, "compression_ratio": 1.7375, "no_speech_prob": 0.0008556681568734348}, {"id": 209, "seek": 126280, "start": 1263.44, "end": 1264.3999999999999, "text": " Yes, it does.", "tokens": [50396, 1079, 11, 309, 775, 13, 50444], "temperature": 0.0, "avg_logprob": -0.11595909219039113, "compression_ratio": 1.7745901639344261, "no_speech_prob": 0.04600856825709343}, {"id": 210, "seek": 126280, "start": 1264.3999999999999, "end": 1266.32, "text": " So is there a database on the client side?", "tokens": [50444, 407, 307, 456, 257, 8149, 322, 264, 6423, 1252, 30, 50540], "temperature": 0.0, "avg_logprob": -0.11595909219039113, "compression_ratio": 1.7745901639344261, "no_speech_prob": 0.04600856825709343}, {"id": 211, "seek": 126280, "start": 1267.2, "end": 1272.96, "text": " Well, I believe basically everything is a database. I have more I could talk about that,", "tokens": [50584, 1042, 11, 286, 1697, 1936, 1203, 307, 257, 8149, 13, 286, 362, 544, 286, 727, 751, 466, 300, 11, 50872], "temperature": 0.0, "avg_logprob": -0.11595909219039113, "compression_ratio": 1.7745901639344261, "no_speech_prob": 0.04600856825709343}, {"id": 212, "seek": 126280, "start": 1272.96, "end": 1277.36, "text": " but essentially, yes, although typically people don't think of it that way. So typically the way", "tokens": [50872, 457, 4476, 11, 2086, 11, 4878, 5850, 561, 500, 380, 519, 295, 309, 300, 636, 13, 407, 5850, 264, 636, 51092], "temperature": 0.0, "avg_logprob": -0.11595909219039113, "compression_ratio": 1.7745901639344261, "no_speech_prob": 0.04600856825709343}, {"id": 213, "seek": 126280, "start": 1277.36, "end": 1284.56, "text": " that people think about it, first of all, in games is with a tick. So on the client, you would have", "tokens": [51092, 300, 561, 519, 466, 309, 11, 700, 295, 439, 11, 294, 2813, 307, 365, 257, 5204, 13, 407, 322, 264, 6423, 11, 291, 576, 362, 51452], "temperature": 0.0, "avg_logprob": -0.11595909219039113, "compression_ratio": 1.7745901639344261, "no_speech_prob": 0.04600856825709343}, {"id": 214, "seek": 126280, "start": 1285.28, "end": 1290.3999999999999, "text": " a frame, essentially, that happens, they would call it like a server frame if it's not the", "tokens": [51488, 257, 3920, 11, 4476, 11, 300, 2314, 11, 436, 576, 818, 309, 411, 257, 7154, 3920, 498, 309, 311, 406, 264, 51744], "temperature": 0.0, "avg_logprob": -0.11595909219039113, "compression_ratio": 1.7745901639344261, "no_speech_prob": 0.04600856825709343}, {"id": 215, "seek": 129040, "start": 1290.4, "end": 1295.52, "text": " actual render frame. So the render frame always happens at 60 frames per second, or sometimes", "tokens": [50364, 3539, 15529, 3920, 13, 407, 264, 15529, 3920, 1009, 2314, 412, 4060, 12083, 680, 1150, 11, 420, 2171, 50620], "temperature": 0.0, "avg_logprob": -0.10814687480097232, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0018100360175594687}, {"id": 216, "seek": 129040, "start": 1295.52, "end": 1302.8000000000002, "text": " now like 120 or 144 or whatever your monitor actually has. A server frame typically doesn't", "tokens": [50620, 586, 411, 10411, 420, 45218, 420, 2035, 428, 6002, 767, 575, 13, 316, 7154, 3920, 5850, 1177, 380, 50984], "temperature": 0.0, "avg_logprob": -0.10814687480097232, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0018100360175594687}, {"id": 217, "seek": 129040, "start": 1302.8000000000002, "end": 1310.0, "text": " go beyond 60 frames per second. And it assumes there's a loop. And basically, we're going to", "tokens": [50984, 352, 4399, 4060, 12083, 680, 1150, 13, 400, 309, 37808, 456, 311, 257, 6367, 13, 400, 1936, 11, 321, 434, 516, 281, 51344], "temperature": 0.0, "avg_logprob": -0.10814687480097232, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0018100360175594687}, {"id": 218, "seek": 129040, "start": 1310.0, "end": 1314.72, "text": " update all the state once a frame. Space IDB actually doesn't make that assumption. You can", "tokens": [51344, 5623, 439, 264, 1785, 1564, 257, 3920, 13, 8705, 7348, 33, 767, 1177, 380, 652, 300, 15302, 13, 509, 393, 51580], "temperature": 0.0, "avg_logprob": -0.10814687480097232, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0018100360175594687}, {"id": 219, "seek": 129040, "start": 1314.72, "end": 1320.24, "text": " do that with Space IDB, but it's not a requirement. So I'll just say that. And there's latency", "tokens": [51580, 360, 300, 365, 8705, 7348, 33, 11, 457, 309, 311, 406, 257, 11695, 13, 407, 286, 603, 445, 584, 300, 13, 400, 456, 311, 27043, 51856], "temperature": 0.0, "avg_logprob": -0.10814687480097232, "compression_ratio": 1.7222222222222223, "no_speech_prob": 0.0018100360175594687}, {"id": 220, "seek": 132024, "start": 1320.24, "end": 1324.4, "text": " versus throughput trade-offs with that. That's essentially what that will end up with.", "tokens": [50364, 5717, 44629, 4923, 12, 19231, 365, 300, 13, 663, 311, 4476, 437, 300, 486, 917, 493, 365, 13, 50572], "temperature": 0.0, "avg_logprob": -0.14600883339935877, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0004877920146100223}, {"id": 221, "seek": 132024, "start": 1325.2, "end": 1329.92, "text": " Because if you have something ticking 60 frames a second, the minimum latency that you can have", "tokens": [50612, 1436, 498, 291, 362, 746, 33999, 4060, 12083, 257, 1150, 11, 264, 7285, 27043, 300, 291, 393, 362, 50848], "temperature": 0.0, "avg_logprob": -0.14600883339935877, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0004877920146100223}, {"id": 222, "seek": 132024, "start": 1329.92, "end": 1336.96, "text": " is one 60th of one second. Because you could have the wrong time. You could have tried to do", "tokens": [50848, 307, 472, 4060, 392, 295, 472, 1150, 13, 1436, 291, 727, 362, 264, 2085, 565, 13, 509, 727, 362, 3031, 281, 360, 51200], "temperature": 0.0, "avg_logprob": -0.14600883339935877, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0004877920146100223}, {"id": 223, "seek": 132024, "start": 1336.96, "end": 1339.92, "text": " something just as the frame was starting. And now you have to wait the full frame time", "tokens": [51200, 746, 445, 382, 264, 3920, 390, 2891, 13, 400, 586, 291, 362, 281, 1699, 264, 1577, 3920, 565, 51348], "temperature": 0.0, "avg_logprob": -0.14600883339935877, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0004877920146100223}, {"id": 224, "seek": 132024, "start": 1340.64, "end": 1349.68, "text": " before you actually that effect is applied. So now, yes, is the client a database?", "tokens": [51384, 949, 291, 767, 300, 1802, 307, 6456, 13, 407, 586, 11, 2086, 11, 307, 264, 6423, 257, 8149, 30, 51836], "temperature": 0.0, "avg_logprob": -0.14600883339935877, "compression_ratio": 1.718146718146718, "no_speech_prob": 0.0004877920146100223}, {"id": 225, "seek": 135024, "start": 1350.4, "end": 1356.4, "text": " What is happening on the client is there's really two ways of doing it. And so I want to be careful.", "tokens": [50372, 708, 307, 2737, 322, 264, 6423, 307, 456, 311, 534, 732, 2098, 295, 884, 309, 13, 400, 370, 286, 528, 281, 312, 5026, 13, 50672], "temperature": 0.0, "avg_logprob": -0.0750147415244061, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00039199524326249957}, {"id": 226, "seek": 135024, "start": 1358.64, "end": 1364.88, "text": " In the one way of doing it, the client has a deterministic simulation of the game world.", "tokens": [50784, 682, 264, 472, 636, 295, 884, 309, 11, 264, 6423, 575, 257, 15957, 3142, 16575, 295, 264, 1216, 1002, 13, 51096], "temperature": 0.0, "avg_logprob": -0.0750147415244061, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00039199524326249957}, {"id": 227, "seek": 135024, "start": 1365.44, "end": 1372.56, "text": " So that means that all of the inputs that are going to manipulate the game state are being sent", "tokens": [51124, 407, 300, 1355, 300, 439, 295, 264, 15743, 300, 366, 516, 281, 20459, 264, 1216, 1785, 366, 885, 2279, 51480], "temperature": 0.0, "avg_logprob": -0.0750147415244061, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00039199524326249957}, {"id": 228, "seek": 135024, "start": 1372.56, "end": 1377.04, "text": " to the server and replicated out to the clients. Those clients then receive that input. And then", "tokens": [51480, 281, 264, 7154, 293, 46365, 484, 281, 264, 6982, 13, 3950, 6982, 550, 4774, 300, 4846, 13, 400, 550, 51704], "temperature": 0.0, "avg_logprob": -0.0750147415244061, "compression_ratio": 1.7767441860465116, "no_speech_prob": 0.00039199524326249957}, {"id": 229, "seek": 137704, "start": 1377.04, "end": 1384.96, "text": " they run the game forward a little bit, like one frame. And they will find out what actually", "tokens": [50364, 436, 1190, 264, 1216, 2128, 257, 707, 857, 11, 411, 472, 3920, 13, 400, 436, 486, 915, 484, 437, 767, 50760], "temperature": 0.0, "avg_logprob": -0.10675250267495914, "compression_ratio": 1.7339055793991416, "no_speech_prob": 0.0023963230196386576}, {"id": 230, "seek": 137704, "start": 1384.96, "end": 1389.68, "text": " has changed in the game state and they move their state forward. That requires having total", "tokens": [50760, 575, 3105, 294, 264, 1216, 1785, 293, 436, 1286, 641, 1785, 2128, 13, 663, 7029, 1419, 3217, 50996], "temperature": 0.0, "avg_logprob": -0.10675250267495914, "compression_ratio": 1.7339055793991416, "no_speech_prob": 0.0023963230196386576}, {"id": 231, "seek": 137704, "start": 1389.68, "end": 1395.36, "text": " knowledge of all of the state. Because if you don't have total knowledge, you're", "tokens": [50996, 3601, 295, 439, 295, 264, 1785, 13, 1436, 498, 291, 500, 380, 362, 3217, 3601, 11, 291, 434, 51280], "temperature": 0.0, "avg_logprob": -0.10675250267495914, "compression_ratio": 1.7339055793991416, "no_speech_prob": 0.0023963230196386576}, {"id": 232, "seek": 137704, "start": 1395.36, "end": 1399.76, "text": " non-deterministic because you no longer know what you don't know. You don't know that that bomb", "tokens": [51280, 2107, 12, 49136, 259, 3142, 570, 291, 572, 2854, 458, 437, 291, 500, 380, 458, 13, 509, 500, 380, 458, 300, 300, 7851, 51500], "temperature": 0.0, "avg_logprob": -0.10675250267495914, "compression_ratio": 1.7339055793991416, "no_speech_prob": 0.0023963230196386576}, {"id": 233, "seek": 137704, "start": 1400.32, "end": 1403.52, "text": " might come in from outside and actually...", "tokens": [51528, 1062, 808, 294, 490, 2380, 293, 767, 485, 51688], "temperature": 0.0, "avg_logprob": -0.10675250267495914, "compression_ratio": 1.7339055793991416, "no_speech_prob": 0.0023963230196386576}, {"id": 234, "seek": 140352, "start": 1404.48, "end": 1408.0, "text": " Yeah, if you want total knowledge, you have to have the entire world so you can see events", "tokens": [50412, 865, 11, 498, 291, 528, 3217, 3601, 11, 291, 362, 281, 362, 264, 2302, 1002, 370, 291, 393, 536, 3931, 50588], "temperature": 0.0, "avg_logprob": -0.18083531515938894, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.010003449395298958}, {"id": 235, "seek": 140352, "start": 1408.0, "end": 1409.44, "text": " that might be coming over the horizon.", "tokens": [50588, 300, 1062, 312, 1348, 670, 264, 18046, 13, 50660], "temperature": 0.0, "avg_logprob": -0.18083531515938894, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.010003449395298958}, {"id": 236, "seek": 140352, "start": 1410.8799999999999, "end": 1418.08, "text": " Yes, this type of server synchronization really only happens with match-based games.", "tokens": [50732, 1079, 11, 341, 2010, 295, 7154, 19331, 2144, 534, 787, 2314, 365, 2995, 12, 6032, 2813, 13, 51092], "temperature": 0.0, "avg_logprob": -0.18083531515938894, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.010003449395298958}, {"id": 237, "seek": 140352, "start": 1418.8799999999999, "end": 1422.8, "text": " So games with a sort of small state, so like League of Legends, that kind of thing.", "tokens": [51132, 407, 2813, 365, 257, 1333, 295, 1359, 1785, 11, 370, 411, 11199, 295, 28103, 11, 300, 733, 295, 551, 13, 51328], "temperature": 0.0, "avg_logprob": -0.18083531515938894, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.010003449395298958}, {"id": 238, "seek": 140352, "start": 1424.32, "end": 1430.08, "text": " Or like RTSs, which is another match-based game, where the inputs are quite simple,", "tokens": [51404, 1610, 411, 497, 7327, 82, 11, 597, 307, 1071, 2995, 12, 6032, 1216, 11, 689, 264, 15743, 366, 1596, 2199, 11, 51692], "temperature": 0.0, "avg_logprob": -0.18083531515938894, "compression_ratio": 1.5850622406639003, "no_speech_prob": 0.010003449395298958}, {"id": 239, "seek": 143008, "start": 1430.1599999999999, "end": 1434.8, "text": " but the outputs are quite complex. So you might click here to move a group of guys,", "tokens": [50368, 457, 264, 23930, 366, 1596, 3997, 13, 407, 291, 1062, 2052, 510, 281, 1286, 257, 1594, 295, 1074, 11, 50600], "temperature": 0.0, "avg_logprob": -0.10086860656738281, "compression_ratio": 1.7396825396825397, "no_speech_prob": 0.022276975214481354}, {"id": 240, "seek": 143008, "start": 1434.8, "end": 1439.84, "text": " but 500 guys might move. And so that's actually a lot of data to say where all the positions of", "tokens": [50600, 457, 5923, 1074, 1062, 1286, 13, 400, 370, 300, 311, 767, 257, 688, 295, 1412, 281, 584, 689, 439, 264, 8432, 295, 50852], "temperature": 0.0, "avg_logprob": -0.10086860656738281, "compression_ratio": 1.7396825396825397, "no_speech_prob": 0.022276975214481354}, {"id": 241, "seek": 143008, "start": 1439.84, "end": 1443.6799999999998, "text": " them are, but you don't have to do that. You just have to replicate. I clicked here, or this player", "tokens": [50852, 552, 366, 11, 457, 291, 500, 380, 362, 281, 360, 300, 13, 509, 445, 362, 281, 25356, 13, 286, 23370, 510, 11, 420, 341, 4256, 51044], "temperature": 0.0, "avg_logprob": -0.10086860656738281, "compression_ratio": 1.7396825396825397, "no_speech_prob": 0.022276975214481354}, {"id": 242, "seek": 143008, "start": 1443.6799999999998, "end": 1448.8, "text": " clicked here, and thus when I play my deterministic simulation forward, all the guys will move within", "tokens": [51044, 23370, 510, 11, 293, 8807, 562, 286, 862, 452, 15957, 3142, 16575, 2128, 11, 439, 264, 1074, 486, 1286, 1951, 51300], "temperature": 0.0, "avg_logprob": -0.10086860656738281, "compression_ratio": 1.7396825396825397, "no_speech_prob": 0.022276975214481354}, {"id": 243, "seek": 143008, "start": 1448.8, "end": 1451.28, "text": " my simulation. I don't have to communicate that data over the network.", "tokens": [51300, 452, 16575, 13, 286, 500, 380, 362, 281, 7890, 300, 1412, 670, 264, 3209, 13, 51424], "temperature": 0.0, "avg_logprob": -0.10086860656738281, "compression_ratio": 1.7396825396825397, "no_speech_prob": 0.022276975214481354}, {"id": 244, "seek": 143008, "start": 1451.84, "end": 1457.28, "text": " Okay, yeah, I can see that. So that's one way to do it. For MMOs, part of the reason they're so", "tokens": [51452, 1033, 11, 1338, 11, 286, 393, 536, 300, 13, 407, 300, 311, 472, 636, 281, 360, 309, 13, 1171, 376, 18976, 82, 11, 644, 295, 264, 1778, 436, 434, 370, 51724], "temperature": 0.0, "avg_logprob": -0.10086860656738281, "compression_ratio": 1.7396825396825397, "no_speech_prob": 0.022276975214481354}, {"id": 245, "seek": 145728, "start": 1457.28, "end": 1461.28, "text": " difficult is you can't do that, because I cannot possibly have the total state of the world", "tokens": [50364, 2252, 307, 291, 393, 380, 360, 300, 11, 570, 286, 2644, 6264, 362, 264, 3217, 1785, 295, 264, 1002, 50564], "temperature": 0.0, "avg_logprob": -0.12247313658396403, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.008840001188218594}, {"id": 246, "seek": 145728, "start": 1462.6399999999999, "end": 1468.72, "text": " on my client. It's too big, sort of fundamentally, by design. I can't put the whole world of", "tokens": [50632, 322, 452, 6423, 13, 467, 311, 886, 955, 11, 1333, 295, 17879, 11, 538, 1715, 13, 286, 393, 380, 829, 264, 1379, 1002, 295, 50936], "temperature": 0.0, "avg_logprob": -0.12247313658396403, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.008840001188218594}, {"id": 247, "seek": 145728, "start": 1468.72, "end": 1475.12, "text": " Warcraft and all its players on every single machine. Correct, alas, you cannot. So instead,", "tokens": [50936, 3630, 5611, 293, 439, 1080, 4150, 322, 633, 2167, 3479, 13, 12753, 11, 419, 296, 11, 291, 2644, 13, 407, 2602, 11, 51256], "temperature": 0.0, "avg_logprob": -0.12247313658396403, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.008840001188218594}, {"id": 248, "seek": 145728, "start": 1475.12, "end": 1482.0, "text": " what they do is typically the way this would work is you have your game server. That game server", "tokens": [51256, 437, 436, 360, 307, 5850, 264, 636, 341, 576, 589, 307, 291, 362, 428, 1216, 7154, 13, 663, 1216, 7154, 51600], "temperature": 0.0, "avg_logprob": -0.12247313658396403, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.008840001188218594}, {"id": 249, "seek": 145728, "start": 1482.0, "end": 1486.56, "text": " knows what a game client is, and when they connect, they know where the player is, and they have a", "tokens": [51600, 3255, 437, 257, 1216, 6423, 307, 11, 293, 562, 436, 1745, 11, 436, 458, 689, 264, 4256, 307, 11, 293, 436, 362, 257, 51828], "temperature": 0.0, "avg_logprob": -0.12247313658396403, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.008840001188218594}, {"id": 250, "seek": 148656, "start": 1486.56, "end": 1490.08, "text": " bunch of special logic to say, okay, I know what this player is, I know what they need, I'm going", "tokens": [50364, 3840, 295, 2121, 9952, 281, 584, 11, 1392, 11, 286, 458, 437, 341, 4256, 307, 11, 286, 458, 437, 436, 643, 11, 286, 478, 516, 50540], "temperature": 0.0, "avg_logprob": -0.07427240187121976, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.0011333232978358865}, {"id": 251, "seek": 148656, "start": 1490.08, "end": 1495.6, "text": " to send down that data to the client. And then I'm going to send down that data to the client", "tokens": [50540, 281, 2845, 760, 300, 1412, 281, 264, 6423, 13, 400, 550, 286, 478, 516, 281, 2845, 760, 300, 1412, 281, 264, 6423, 50816], "temperature": 0.0, "avg_logprob": -0.07427240187121976, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.0011333232978358865}, {"id": 252, "seek": 148656, "start": 1498.24, "end": 1502.96, "text": " let's say once a frame. So every frame, I will compute, okay, what has changed on the server,", "tokens": [50948, 718, 311, 584, 1564, 257, 3920, 13, 407, 633, 3920, 11, 286, 486, 14722, 11, 1392, 11, 437, 575, 3105, 322, 264, 7154, 11, 51184], "temperature": 0.0, "avg_logprob": -0.07427240187121976, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.0011333232978358865}, {"id": 253, "seek": 148656, "start": 1502.96, "end": 1506.8799999999999, "text": " and I'm going to send a bunch of messages down saying these are the new positions of all the", "tokens": [51184, 293, 286, 478, 516, 281, 2845, 257, 3840, 295, 7897, 760, 1566, 613, 366, 264, 777, 8432, 295, 439, 264, 51380], "temperature": 0.0, "avg_logprob": -0.07427240187121976, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.0011333232978358865}, {"id": 254, "seek": 148656, "start": 1506.8799999999999, "end": 1515.76, "text": " players. That's the typical way of doing it. Now, notably, this means that you have baked in", "tokens": [51380, 4150, 13, 663, 311, 264, 7476, 636, 295, 884, 309, 13, 823, 11, 31357, 11, 341, 1355, 300, 291, 362, 19453, 294, 51824], "temperature": 0.0, "avg_logprob": -0.07427240187121976, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.0011333232978358865}, {"id": 255, "seek": 151656, "start": 1517.52, "end": 1523.76, "text": " what your client wants to know about into your server code. Because you as the server need to", "tokens": [50412, 437, 428, 6423, 2738, 281, 458, 466, 666, 428, 7154, 3089, 13, 1436, 291, 382, 264, 7154, 643, 281, 50724], "temperature": 0.0, "avg_logprob": -0.1013868393436555, "compression_ratio": 1.910204081632653, "no_speech_prob": 0.0011334053706377745}, {"id": 256, "seek": 151656, "start": 1523.76, "end": 1528.32, "text": " know what they need to know, because you're going to do this streaming update to them. Yeah,", "tokens": [50724, 458, 437, 436, 643, 281, 458, 11, 570, 291, 434, 516, 281, 360, 341, 11791, 5623, 281, 552, 13, 865, 11, 50952], "temperature": 0.0, "avg_logprob": -0.1013868393436555, "compression_ratio": 1.910204081632653, "no_speech_prob": 0.0011334053706377745}, {"id": 257, "seek": 151656, "start": 1528.32, "end": 1534.24, "text": " so it's more complex than first, for example, let's say a web site with a GraphQL query,", "tokens": [50952, 370, 309, 311, 544, 3997, 813, 700, 11, 337, 1365, 11, 718, 311, 584, 257, 3670, 3621, 365, 257, 21884, 13695, 14581, 11, 51248], "temperature": 0.0, "avg_logprob": -0.1013868393436555, "compression_ratio": 1.910204081632653, "no_speech_prob": 0.0011334053706377745}, {"id": 258, "seek": 151656, "start": 1534.24, "end": 1538.3999999999999, "text": " because with a GraphQL query, you can say, Oh, I'm this client of client, and I want to know", "tokens": [51248, 570, 365, 257, 21884, 13695, 14581, 11, 291, 393, 584, 11, 876, 11, 286, 478, 341, 6423, 295, 6423, 11, 293, 286, 528, 281, 458, 51456], "temperature": 0.0, "avg_logprob": -0.1013868393436555, "compression_ratio": 1.910204081632653, "no_speech_prob": 0.0011334053706377745}, {"id": 259, "seek": 151656, "start": 1538.3999999999999, "end": 1542.24, "text": " all about this data. And I'm this kind of client, I want to know about this data. But because games", "tokens": [51456, 439, 466, 341, 1412, 13, 400, 286, 478, 341, 733, 295, 6423, 11, 286, 528, 281, 458, 466, 341, 1412, 13, 583, 570, 2813, 51648], "temperature": 0.0, "avg_logprob": -0.1013868393436555, "compression_ratio": 1.910204081632653, "no_speech_prob": 0.0011334053706377745}, {"id": 260, "seek": 154224, "start": 1542.24, "end": 1546.56, "text": " are streaming, and they need to go fast, and they have this tick based thing built into it.", "tokens": [50364, 366, 11791, 11, 293, 436, 643, 281, 352, 2370, 11, 293, 436, 362, 341, 5204, 2361, 551, 3094, 666, 309, 13, 50580], "temperature": 0.0, "avg_logprob": -0.05725827930480477, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.03731624782085419}, {"id": 261, "seek": 154224, "start": 1546.56, "end": 1552.32, "text": " Historically, people have built them so that you write all the code for synchronizing the", "tokens": [50580, 25108, 984, 11, 561, 362, 3094, 552, 370, 300, 291, 2464, 439, 264, 3089, 337, 19331, 3319, 264, 50868], "temperature": 0.0, "avg_logprob": -0.05725827930480477, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.03731624782085419}, {"id": 262, "seek": 154224, "start": 1552.32, "end": 1556.24, "text": " clients, and you build in some concepts, like you probably build in the concept of positions", "tokens": [50868, 6982, 11, 293, 291, 1322, 294, 512, 10392, 11, 411, 291, 1391, 1322, 294, 264, 3410, 295, 8432, 51064], "temperature": 0.0, "avg_logprob": -0.05725827930480477, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.03731624782085419}, {"id": 263, "seek": 154224, "start": 1556.24, "end": 1559.52, "text": " and of players, and that players want to know about things that are around them,", "tokens": [51064, 293, 295, 4150, 11, 293, 300, 4150, 528, 281, 458, 466, 721, 300, 366, 926, 552, 11, 51228], "temperature": 0.0, "avg_logprob": -0.05725827930480477, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.03731624782085419}, {"id": 264, "seek": 154224, "start": 1559.52, "end": 1564.72, "text": " and all of that good stuff. So if you were to then go build an AI that doesn't care about", "tokens": [51228, 293, 439, 295, 300, 665, 1507, 13, 407, 498, 291, 645, 281, 550, 352, 1322, 364, 7318, 300, 1177, 380, 1127, 466, 51488], "temperature": 0.0, "avg_logprob": -0.05725827930480477, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.03731624782085419}, {"id": 265, "seek": 154224, "start": 1564.72, "end": 1567.68, "text": " where certain players are, maybe it's trying to regrow the trees or something.", "tokens": [51488, 689, 1629, 4150, 366, 11, 1310, 309, 311, 1382, 281, 319, 26685, 264, 5852, 420, 746, 13, 51636], "temperature": 0.0, "avg_logprob": -0.05725827930480477, "compression_ratio": 1.78839590443686, "no_speech_prob": 0.03731624782085419}, {"id": 266, "seek": 156768, "start": 1568.48, "end": 1574.5600000000002, "text": " And it wants to listen to the data. No can do. You've already built in the particular query", "tokens": [50404, 400, 309, 2738, 281, 2140, 281, 264, 1412, 13, 883, 393, 360, 13, 509, 600, 1217, 3094, 294, 264, 1729, 14581, 50708], "temperature": 0.0, "avg_logprob": -0.17091341452165085, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.0035906846169382334}, {"id": 267, "seek": 156768, "start": 1574.5600000000002, "end": 1582.72, "text": " that wants to be done on that game server state. Right. So we're inverting the controls. So the", "tokens": [50708, 300, 2738, 281, 312, 1096, 322, 300, 1216, 7154, 1785, 13, 1779, 13, 407, 321, 434, 28653, 783, 264, 9003, 13, 407, 264, 51116], "temperature": 0.0, "avg_logprob": -0.17091341452165085, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.0035906846169382334}, {"id": 268, "seek": 156768, "start": 1582.72, "end": 1588.16, "text": " server knows what kind of things you would want and pushes those to you.", "tokens": [51116, 7154, 3255, 437, 733, 295, 721, 291, 576, 528, 293, 21020, 729, 281, 291, 13, 51388], "temperature": 0.0, "avg_logprob": -0.17091341452165085, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.0035906846169382334}, {"id": 269, "seek": 156768, "start": 1588.16, "end": 1594.48, "text": " Correct. So that really bakes in the server then has to have very fixed ideas about what", "tokens": [51388, 12753, 13, 407, 300, 534, 272, 3419, 294, 264, 7154, 550, 575, 281, 362, 588, 6806, 3487, 466, 437, 51704], "temperature": 0.0, "avg_logprob": -0.17091341452165085, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.0035906846169382334}, {"id": 270, "seek": 159448, "start": 1594.56, "end": 1598.24, "text": " kind of people connect and what they might want to do. Absolutely. Correct.", "tokens": [50368, 733, 295, 561, 1745, 293, 437, 436, 1062, 528, 281, 360, 13, 7021, 13, 12753, 13, 50552], "temperature": 0.0, "avg_logprob": -0.13496428615642045, "compression_ratio": 1.6743295019157087, "no_speech_prob": 0.0041968184523284435}, {"id": 271, "seek": 159448, "start": 1599.44, "end": 1603.3600000000001, "text": " What space time to be does is the opposite. We actually treat it sort of from a formal database", "tokens": [50612, 708, 1901, 565, 281, 312, 775, 307, 264, 6182, 13, 492, 767, 2387, 309, 1333, 295, 490, 257, 9860, 8149, 50808], "temperature": 0.0, "avg_logprob": -0.13496428615642045, "compression_ratio": 1.6743295019157087, "no_speech_prob": 0.0041968184523284435}, {"id": 272, "seek": 159448, "start": 1603.3600000000001, "end": 1607.84, "text": " perspective and say, actually, clients are just going to write queries, which are going to be", "tokens": [50808, 4585, 293, 584, 11, 767, 11, 6982, 366, 445, 516, 281, 2464, 24109, 11, 597, 366, 516, 281, 312, 51032], "temperature": 0.0, "avg_logprob": -0.13496428615642045, "compression_ratio": 1.6743295019157087, "no_speech_prob": 0.0041968184523284435}, {"id": 273, "seek": 159448, "start": 1607.84, "end": 1616.88, "text": " executed with a query engine in a subscription based streaming way. So first, we connect,", "tokens": [51032, 17577, 365, 257, 14581, 2848, 294, 257, 17231, 2361, 11791, 636, 13, 407, 700, 11, 321, 1745, 11, 51484], "temperature": 0.0, "avg_logprob": -0.13496428615642045, "compression_ratio": 1.6743295019157087, "no_speech_prob": 0.0041968184523284435}, {"id": 274, "seek": 159448, "start": 1617.6, "end": 1620.48, "text": " and we send a query, and we say, I want to listen to all of these players in this", "tokens": [51520, 293, 321, 2845, 257, 14581, 11, 293, 321, 584, 11, 286, 528, 281, 2140, 281, 439, 295, 613, 4150, 294, 341, 51664], "temperature": 0.0, "avg_logprob": -0.13496428615642045, "compression_ratio": 1.6743295019157087, "no_speech_prob": 0.0041968184523284435}, {"id": 275, "seek": 162048, "start": 1621.1200000000001, "end": 1625.92, "text": " region or whatever we are interested in. And then that data will be incrementally streamed", "tokens": [50396, 4458, 420, 2035, 321, 366, 3102, 294, 13, 400, 550, 300, 1412, 486, 312, 26200, 379, 4309, 292, 50636], "temperature": 0.0, "avg_logprob": -0.09825122581337983, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.00555415078997612}, {"id": 276, "seek": 162048, "start": 1625.92, "end": 1630.48, "text": " down. So as the data changes in the database, we compute that query for all the subscribe things", "tokens": [50636, 760, 13, 407, 382, 264, 1412, 2962, 294, 264, 8149, 11, 321, 14722, 300, 14581, 337, 439, 264, 3022, 721, 50864], "temperature": 0.0, "avg_logprob": -0.09825122581337983, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.00555415078997612}, {"id": 277, "seek": 162048, "start": 1630.48, "end": 1636.4, "text": " and we send it down to their clients. Then you can think of their clients as having a replica", "tokens": [50864, 293, 321, 2845, 309, 760, 281, 641, 6982, 13, 1396, 291, 393, 519, 295, 641, 6982, 382, 1419, 257, 35456, 51160], "temperature": 0.0, "avg_logprob": -0.09825122581337983, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.00555415078997612}, {"id": 278, "seek": 162048, "start": 1637.2, "end": 1642.72, "text": " of the server database. Now that replica is a subset of the data, and it is only prefix", "tokens": [51200, 295, 264, 7154, 8149, 13, 823, 300, 35456, 307, 257, 25993, 295, 264, 1412, 11, 293, 309, 307, 787, 46969, 51476], "temperature": 0.0, "avg_logprob": -0.09825122581337983, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.00555415078997612}, {"id": 279, "seek": 162048, "start": 1642.72, "end": 1647.44, "text": " consistent. So it's not strongly consistent. Would you mean by prefix consistent?", "tokens": [51476, 8398, 13, 407, 309, 311, 406, 10613, 8398, 13, 6068, 291, 914, 538, 46969, 8398, 30, 51712], "temperature": 0.0, "avg_logprob": -0.09825122581337983, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.00555415078997612}, {"id": 280, "seek": 164744, "start": 1648.0800000000002, "end": 1657.6000000000001, "text": " You have the database state as it existed at some point in time in the past. So you have all of the", "tokens": [50396, 509, 362, 264, 8149, 1785, 382, 309, 13135, 412, 512, 935, 294, 565, 294, 264, 1791, 13, 407, 291, 362, 439, 295, 264, 50872], "temperature": 0.0, "avg_logprob": -0.1268291473388672, "compression_ratio": 1.7442922374429224, "no_speech_prob": 0.0021825351286679506}, {"id": 281, "seek": 164744, "start": 1657.6000000000001, "end": 1665.2, "text": " updates in a prefix of the message log, of the write ahead log, up to a certain point. That's", "tokens": [50872, 9205, 294, 257, 46969, 295, 264, 3636, 3565, 11, 295, 264, 2464, 2286, 3565, 11, 493, 281, 257, 1629, 935, 13, 663, 311, 51252], "temperature": 0.0, "avg_logprob": -0.1268291473388672, "compression_ratio": 1.7442922374429224, "no_speech_prob": 0.0021825351286679506}, {"id": 282, "seek": 164744, "start": 1665.2, "end": 1669.6000000000001, "text": " what I mean. Now it's a subset. So it's not, I have the whole database, I have some set of the", "tokens": [51252, 437, 286, 914, 13, 823, 309, 311, 257, 25993, 13, 407, 309, 311, 406, 11, 286, 362, 264, 1379, 8149, 11, 286, 362, 512, 992, 295, 264, 51472], "temperature": 0.0, "avg_logprob": -0.1268291473388672, "compression_ratio": 1.7442922374429224, "no_speech_prob": 0.0021825351286679506}, {"id": 283, "seek": 164744, "start": 1669.6000000000001, "end": 1675.76, "text": " data as it was in time. So it's not eventually consistent. I don't see any weird things about", "tokens": [51472, 1412, 382, 309, 390, 294, 565, 13, 407, 309, 311, 406, 4728, 8398, 13, 286, 500, 380, 536, 604, 3657, 721, 466, 51780], "temperature": 0.0, "avg_logprob": -0.1268291473388672, "compression_ratio": 1.7442922374429224, "no_speech_prob": 0.0021825351286679506}, {"id": 284, "seek": 167576, "start": 1675.84, "end": 1680.8, "text": " it. I will see the database state as it was maybe like five milliseconds ago, or if I'm far away", "tokens": [50368, 309, 13, 286, 486, 536, 264, 8149, 1785, 382, 309, 390, 1310, 411, 1732, 34184, 2057, 11, 420, 498, 286, 478, 1400, 1314, 50616], "temperature": 0.0, "avg_logprob": -0.08947865168253581, "compression_ratio": 1.7174887892376682, "no_speech_prob": 0.006095323711633682}, {"id": 285, "seek": 167576, "start": 1680.8, "end": 1687.04, "text": " a hundred milliseconds ago. Right, yeah. And so what that allows us to do is then you can query", "tokens": [50616, 257, 3262, 34184, 2057, 13, 1779, 11, 1338, 13, 400, 370, 437, 300, 4045, 505, 281, 360, 307, 550, 291, 393, 14581, 50928], "temperature": 0.0, "avg_logprob": -0.08947865168253581, "compression_ratio": 1.7174887892376682, "no_speech_prob": 0.006095323711633682}, {"id": 286, "seek": 167576, "start": 1687.04, "end": 1693.2, "text": " your local database as though it were the actual database. And so you can get this information", "tokens": [50928, 428, 2654, 8149, 382, 1673, 309, 645, 264, 3539, 8149, 13, 400, 370, 291, 393, 483, 341, 1589, 51236], "temperature": 0.0, "avg_logprob": -0.08947865168253581, "compression_ratio": 1.7174887892376682, "no_speech_prob": 0.006095323711633682}, {"id": 287, "seek": 167576, "start": 1693.2, "end": 1700.72, "text": " out from your local database much more conveniently and faster than you might otherwise do in a", "tokens": [51236, 484, 490, 428, 2654, 8149, 709, 544, 44375, 293, 4663, 813, 291, 1062, 5911, 360, 294, 257, 51612], "temperature": 0.0, "avg_logprob": -0.08947865168253581, "compression_ratio": 1.7174887892376682, "no_speech_prob": 0.006095323711633682}, {"id": 288, "seek": 170072, "start": 1700.72, "end": 1706.08, "text": " normal game server. You'll forgive me being really boring here, but I'm translating this", "tokens": [50364, 2710, 1216, 7154, 13, 509, 603, 10718, 385, 885, 534, 9989, 510, 11, 457, 286, 478, 35030, 341, 50632], "temperature": 0.0, "avg_logprob": -0.14119728575361537, "compression_ratio": 1.64, "no_speech_prob": 0.020323239266872406}, {"id": 289, "seek": 170072, "start": 1706.08, "end": 1715.04, "text": " into a non gaming world. And I can see I can imagine I as a as a client of the second client", "tokens": [50632, 666, 257, 2107, 9703, 1002, 13, 400, 286, 393, 536, 286, 393, 3811, 286, 382, 257, 382, 257, 6423, 295, 264, 1150, 6423, 51080], "temperature": 0.0, "avg_logprob": -0.14119728575361537, "compression_ratio": 1.64, "no_speech_prob": 0.020323239266872406}, {"id": 290, "seek": 170072, "start": 1715.04, "end": 1722.48, "text": " of a bank or trading platform, I might want to have all the data relating to my accounts and", "tokens": [51080, 295, 257, 3765, 420, 9529, 3663, 11, 286, 1062, 528, 281, 362, 439, 264, 1412, 23968, 281, 452, 9402, 293, 51452], "temperature": 0.0, "avg_logprob": -0.14119728575361537, "compression_ratio": 1.64, "no_speech_prob": 0.020323239266872406}, {"id": 291, "seek": 170072, "start": 1722.48, "end": 1729.1200000000001, "text": " maybe some of my counterparties, but not the entire bank's data. And then I want to be able to", "tokens": [51452, 1310, 512, 295, 452, 22335, 530, 11, 457, 406, 264, 2302, 3765, 311, 1412, 13, 400, 550, 286, 528, 281, 312, 1075, 281, 51784], "temperature": 0.0, "avg_logprob": -0.14119728575361537, "compression_ratio": 1.64, "no_speech_prob": 0.020323239266872406}, {"id": 292, "seek": 172912, "start": 1729.36, "end": 1734.4799999999998, "text": " optimistically make transactions on that data. They get sent back to the central server and I get", "tokens": [50376, 5028, 20458, 652, 16856, 322, 300, 1412, 13, 814, 483, 2279, 646, 281, 264, 5777, 7154, 293, 286, 483, 50632], "temperature": 0.0, "avg_logprob": -0.19058790012281768, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.00048761750804260373}, {"id": 293, "seek": 172912, "start": 1734.4799999999998, "end": 1739.84, "text": " told if that works, but I can progress as though it did. Yes. And that would be exactly the same", "tokens": [50632, 1907, 498, 300, 1985, 11, 457, 286, 393, 4205, 382, 1673, 309, 630, 13, 1079, 13, 400, 300, 576, 312, 2293, 264, 912, 50900], "temperature": 0.0, "avg_logprob": -0.19058790012281768, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.00048761750804260373}, {"id": 294, "seek": 172912, "start": 1739.84, "end": 1746.08, "text": " architecture we're talking about in the gaming world. 100%. Yes. So what we are in sense, sense", "tokens": [50900, 9482, 321, 434, 1417, 466, 294, 264, 9703, 1002, 13, 2319, 6856, 1079, 13, 407, 437, 321, 366, 294, 2020, 11, 2020, 51212], "temperature": 0.0, "avg_logprob": -0.19058790012281768, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.00048761750804260373}, {"id": 295, "seek": 172912, "start": 1746.08, "end": 1753.1999999999998, "text": " trying to do is unify across both of those things. A lot of people in why, why is that important?", "tokens": [51212, 1382, 281, 360, 307, 517, 2505, 2108, 1293, 295, 729, 721, 13, 316, 688, 295, 561, 294, 983, 11, 983, 307, 300, 1021, 30, 51568], "temperature": 0.0, "avg_logprob": -0.19058790012281768, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.00048761750804260373}, {"id": 296, "seek": 175320, "start": 1754.16, "end": 1763.92, "text": " Because many people have tried to make a game service, game server back end kind of thing,", "tokens": [50412, 1436, 867, 561, 362, 3031, 281, 652, 257, 1216, 2643, 11, 1216, 7154, 646, 917, 733, 295, 551, 11, 50900], "temperature": 0.0, "avg_logprob": -0.18735329310099283, "compression_ratio": 1.64, "no_speech_prob": 0.008845648728311062}, {"id": 297, "seek": 175320, "start": 1763.92, "end": 1770.88, "text": " like a game engine, but for the server, right? So there's unity, you've got Unreal. Wouldn't it", "tokens": [50900, 411, 257, 1216, 2848, 11, 457, 337, 264, 7154, 11, 558, 30, 407, 456, 311, 18205, 11, 291, 600, 658, 34464, 13, 26291, 380, 309, 51248], "temperature": 0.0, "avg_logprob": -0.18735329310099283, "compression_ratio": 1.64, "no_speech_prob": 0.008845648728311062}, {"id": 298, "seek": 175320, "start": 1770.88, "end": 1774.8, "text": " be nice if somebody made that for the back end? The problem that people have is that", "tokens": [51248, 312, 1481, 498, 2618, 1027, 300, 337, 264, 646, 917, 30, 440, 1154, 300, 561, 362, 307, 300, 51444], "temperature": 0.0, "avg_logprob": -0.18735329310099283, "compression_ratio": 1.64, "no_speech_prob": 0.008845648728311062}, {"id": 299, "seek": 175320, "start": 1775.76, "end": 1781.3600000000001, "text": " when you think about what a game is on the client, it's the same across all games. If I'm playing", "tokens": [51492, 562, 291, 519, 466, 437, 257, 1216, 307, 322, 264, 6423, 11, 309, 311, 264, 912, 2108, 439, 2813, 13, 759, 286, 478, 2433, 51772], "temperature": 0.0, "avg_logprob": -0.18735329310099283, "compression_ratio": 1.64, "no_speech_prob": 0.008845648728311062}, {"id": 300, "seek": 178136, "start": 1782.0, "end": 1787.6, "text": " chess or solitaire, what I want to do on the client is very similar to what I want to do in", "tokens": [50396, 24122, 420, 1404, 30914, 11, 437, 286, 528, 281, 360, 322, 264, 6423, 307, 588, 2531, 281, 437, 286, 528, 281, 360, 294, 50676], "temperature": 0.0, "avg_logprob": -0.11117041738409746, "compression_ratio": 1.8605577689243027, "no_speech_prob": 0.0018097655847668648}, {"id": 301, "seek": 178136, "start": 1787.6, "end": 1793.84, "text": " World of Warcraft. Let's say I'm making a 3D solitaire. I am rendering objects on a screen", "tokens": [50676, 3937, 295, 3630, 5611, 13, 961, 311, 584, 286, 478, 1455, 257, 805, 35, 1404, 30914, 13, 286, 669, 22407, 6565, 322, 257, 2568, 50988], "temperature": 0.0, "avg_logprob": -0.11117041738409746, "compression_ratio": 1.8605577689243027, "no_speech_prob": 0.0018097655847668648}, {"id": 302, "seek": 178136, "start": 1793.84, "end": 1799.4399999999998, "text": " and I have all of that stuff. It's all kind of the same across both games. I want to render a 3D", "tokens": [50988, 293, 286, 362, 439, 295, 300, 1507, 13, 467, 311, 439, 733, 295, 264, 912, 2108, 1293, 2813, 13, 286, 528, 281, 15529, 257, 805, 35, 51268], "temperature": 0.0, "avg_logprob": -0.11117041738409746, "compression_ratio": 1.8605577689243027, "no_speech_prob": 0.0018097655847668648}, {"id": 303, "seek": 178136, "start": 1799.4399999999998, "end": 1805.6799999999998, "text": " world. I want to loop that, apply some logic to the state of that world. And then I want to,", "tokens": [51268, 1002, 13, 286, 528, 281, 6367, 300, 11, 3079, 512, 9952, 281, 264, 1785, 295, 300, 1002, 13, 400, 550, 286, 528, 281, 11, 51580], "temperature": 0.0, "avg_logprob": -0.11117041738409746, "compression_ratio": 1.8605577689243027, "no_speech_prob": 0.0018097655847668648}, {"id": 304, "seek": 178136, "start": 1805.6799999999998, "end": 1810.3999999999999, "text": " yes, and I want to turn it into 3D objects and I want to project them onto a screen and I want", "tokens": [51580, 2086, 11, 293, 286, 528, 281, 1261, 309, 666, 805, 35, 6565, 293, 286, 528, 281, 1716, 552, 3911, 257, 2568, 293, 286, 528, 51816], "temperature": 0.0, "avg_logprob": -0.11117041738409746, "compression_ratio": 1.8605577689243027, "no_speech_prob": 0.0018097655847668648}, {"id": 305, "seek": 181040, "start": 1810.4, "end": 1814.88, "text": " to do lighting effects and I want to do sound effects and I want to do all of that. Every game", "tokens": [50364, 281, 360, 9577, 5065, 293, 286, 528, 281, 360, 1626, 5065, 293, 286, 528, 281, 360, 439, 295, 300, 13, 2048, 1216, 50588], "temperature": 0.0, "avg_logprob": -0.10086320241292318, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0018672990845516324}, {"id": 306, "seek": 181040, "start": 1814.88, "end": 1819.8400000000001, "text": " from the client perspective is not identical, but they rhyme. They have a lie in common that", "tokens": [50588, 490, 264, 6423, 4585, 307, 406, 14800, 11, 457, 436, 34753, 13, 814, 362, 257, 4544, 294, 2689, 300, 50836], "temperature": 0.0, "avg_logprob": -0.10086320241292318, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0018672990845516324}, {"id": 307, "seek": 181040, "start": 1819.8400000000001, "end": 1825.1200000000001, "text": " an engine could do that we don't have to write over and over and over again, essentially. On the", "tokens": [50836, 364, 2848, 727, 360, 300, 321, 500, 380, 362, 281, 2464, 670, 293, 670, 293, 670, 797, 11, 4476, 13, 1282, 264, 51100], "temperature": 0.0, "avg_logprob": -0.10086320241292318, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0018672990845516324}, {"id": 308, "seek": 181040, "start": 1825.1200000000001, "end": 1830.48, "text": " server, if you think about what chess versus World of Warcraft is, those architectures are,", "tokens": [51100, 7154, 11, 498, 291, 519, 466, 437, 24122, 5717, 3937, 295, 3630, 5611, 307, 11, 729, 6331, 1303, 366, 11, 51368], "temperature": 0.0, "avg_logprob": -0.10086320241292318, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0018672990845516324}, {"id": 309, "seek": 181040, "start": 1831.2800000000002, "end": 1836.48, "text": " they share nothing. They might as well, one is like a web app kind of, right? Like a chess move.", "tokens": [51408, 436, 2073, 1825, 13, 814, 1062, 382, 731, 11, 472, 307, 411, 257, 3670, 724, 733, 295, 11, 558, 30, 1743, 257, 24122, 1286, 13, 51668], "temperature": 0.0, "avg_logprob": -0.10086320241292318, "compression_ratio": 1.6832740213523132, "no_speech_prob": 0.0018672990845516324}, {"id": 310, "seek": 183648, "start": 1837.3600000000001, "end": 1842.4, "text": " I could build that with a web server and Node.js and all that. And the other one is a very complex", "tokens": [50408, 286, 727, 1322, 300, 365, 257, 3670, 7154, 293, 38640, 13, 25530, 293, 439, 300, 13, 400, 264, 661, 472, 307, 257, 588, 3997, 50660], "temperature": 0.0, "avg_logprob": -0.12829254070917764, "compression_ratio": 1.6033755274261603, "no_speech_prob": 0.0011334167793393135}, {"id": 311, "seek": 183648, "start": 1844.8, "end": 1851.92, "text": " multi-user, fast-changing state thing, which synchronizes data persistently to the database", "tokens": [50780, 4825, 12, 18088, 11, 2370, 12, 27123, 1785, 551, 11, 597, 19331, 5660, 1412, 13233, 2276, 281, 264, 8149, 51136], "temperature": 0.0, "avg_logprob": -0.12829254070917764, "compression_ratio": 1.6033755274261603, "no_speech_prob": 0.0011334167793393135}, {"id": 312, "seek": 183648, "start": 1851.92, "end": 1856.56, "text": " and updates positions and all of that. So what we're trying to do in some sense with SpacetimeDB", "tokens": [51136, 293, 9205, 8432, 293, 439, 295, 300, 13, 407, 437, 321, 434, 1382, 281, 360, 294, 512, 2020, 365, 1738, 326, 9764, 27735, 51368], "temperature": 0.0, "avg_logprob": -0.12829254070917764, "compression_ratio": 1.6033755274261603, "no_speech_prob": 0.0011334167793393135}, {"id": 313, "seek": 183648, "start": 1856.56, "end": 1861.28, "text": " is close over all of those things and you really have to go all the way back to the database", "tokens": [51368, 307, 1998, 670, 439, 295, 729, 721, 293, 291, 534, 362, 281, 352, 439, 264, 636, 646, 281, 264, 8149, 51604], "temperature": 0.0, "avg_logprob": -0.12829254070917764, "compression_ratio": 1.6033755274261603, "no_speech_prob": 0.0011334167793393135}, {"id": 314, "seek": 186128, "start": 1861.28, "end": 1865.52, "text": " for it to be general enough to actually apply to both of those scenarios.", "tokens": [50364, 337, 309, 281, 312, 2674, 1547, 281, 767, 3079, 281, 1293, 295, 729, 15077, 13, 50576], "temperature": 0.0, "avg_logprob": -0.11925290294529237, "compression_ratio": 1.5541125541125542, "no_speech_prob": 0.009123176336288452}, {"id": 315, "seek": 186128, "start": 1866.8, "end": 1872.48, "text": " Yeah. Okay. I can see that. It sounds like a colossal amount of work to do well, though.", "tokens": [50640, 865, 13, 1033, 13, 286, 393, 536, 300, 13, 467, 3263, 411, 257, 48683, 304, 2372, 295, 589, 281, 360, 731, 11, 1673, 13, 50924], "temperature": 0.0, "avg_logprob": -0.11925290294529237, "compression_ratio": 1.5541125541125542, "no_speech_prob": 0.009123176336288452}, {"id": 316, "seek": 186128, "start": 1873.2, "end": 1881.52, "text": " It does. Nobody knows this better than I do. Let me put it to you this way, though, with respect to", "tokens": [50960, 467, 775, 13, 9297, 3255, 341, 1101, 813, 286, 360, 13, 961, 385, 829, 309, 281, 291, 341, 636, 11, 1673, 11, 365, 3104, 281, 51376], "temperature": 0.0, "avg_logprob": -0.11925290294529237, "compression_ratio": 1.5541125541125542, "no_speech_prob": 0.009123176336288452}, {"id": 317, "seek": 186128, "start": 1881.52, "end": 1888.32, "text": " that. When we decided we were going to make BitCraft, we were committed to making such a system.", "tokens": [51376, 300, 13, 1133, 321, 3047, 321, 645, 516, 281, 652, 9101, 34, 4469, 11, 321, 645, 7784, 281, 1455, 1270, 257, 1185, 13, 51716], "temperature": 0.0, "avg_logprob": -0.11925290294529237, "compression_ratio": 1.5541125541125542, "no_speech_prob": 0.009123176336288452}, {"id": 318, "seek": 188832, "start": 1888.3999999999999, "end": 1893.84, "text": " The fact that it's available as its own standalone thing is not really that much more work.", "tokens": [50368, 440, 1186, 300, 309, 311, 2435, 382, 1080, 1065, 37454, 551, 307, 406, 534, 300, 709, 544, 589, 13, 50640], "temperature": 0.0, "avg_logprob": -0.07934446667515954, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.0005883576814085245}, {"id": 319, "seek": 188832, "start": 1894.3999999999999, "end": 1902.3999999999999, "text": " Every MMO that you have ever seen has an architecture which is at least as complicated", "tokens": [50668, 2048, 376, 18976, 300, 291, 362, 1562, 1612, 575, 364, 9482, 597, 307, 412, 1935, 382, 6179, 51068], "temperature": 0.0, "avg_logprob": -0.07934446667515954, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.0005883576814085245}, {"id": 320, "seek": 188832, "start": 1902.96, "end": 1910.96, "text": " as SpacetimeDB. And I actually know that some of them, I can't necessarily name them,", "tokens": [51096, 382, 1738, 326, 9764, 27735, 13, 400, 286, 767, 458, 300, 512, 295, 552, 11, 286, 393, 380, 4725, 1315, 552, 11, 51496], "temperature": 0.0, "avg_logprob": -0.07934446667515954, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.0005883576814085245}, {"id": 321, "seek": 188832, "start": 1912.56, "end": 1917.6799999999998, "text": " operate in the same sort of stored procedure way because it's the sort of convergent evolution", "tokens": [51576, 9651, 294, 264, 912, 1333, 295, 12187, 10747, 636, 570, 309, 311, 264, 1333, 295, 9652, 6930, 9303, 51832], "temperature": 0.0, "avg_logprob": -0.07934446667515954, "compression_ratio": 1.5474137931034482, "no_speech_prob": 0.0005883576814085245}, {"id": 322, "seek": 191768, "start": 1917.68, "end": 1923.68, "text": " that they arrived at, but they just didn't formally call it a database. In some sense,", "tokens": [50364, 300, 436, 6678, 412, 11, 457, 436, 445, 994, 380, 25983, 818, 309, 257, 8149, 13, 682, 512, 2020, 11, 50664], "temperature": 0.0, "avg_logprob": -0.06929122077094184, "compression_ratio": 1.6044444444444443, "no_speech_prob": 0.0005702532944269478}, {"id": 323, "seek": 191768, "start": 1923.68, "end": 1931.04, "text": " an easier problem because if you treat it as a database formally, you get to use all of the", "tokens": [50664, 364, 3571, 1154, 570, 498, 291, 2387, 309, 382, 257, 8149, 25983, 11, 291, 483, 281, 764, 439, 295, 264, 51032], "temperature": 0.0, "avg_logprob": -0.06929122077094184, "compression_ratio": 1.6044444444444443, "no_speech_prob": 0.0005702532944269478}, {"id": 324, "seek": 191768, "start": 1931.04, "end": 1938.8, "text": " research and learnings that 50 years of database research has brought about. You do not have to", "tokens": [51032, 2132, 293, 2539, 82, 300, 2625, 924, 295, 8149, 2132, 575, 3038, 466, 13, 509, 360, 406, 362, 281, 51420], "temperature": 0.0, "avg_logprob": -0.06929122077094184, "compression_ratio": 1.6044444444444443, "no_speech_prob": 0.0005702532944269478}, {"id": 325, "seek": 191768, "start": 1938.8, "end": 1947.04, "text": " reinvent the wheel, is what I'm saying on a lot of these things. And so we were always", "tokens": [51420, 33477, 264, 5589, 11, 307, 437, 286, 478, 1566, 322, 257, 688, 295, 613, 721, 13, 400, 370, 321, 645, 1009, 51832], "temperature": 0.0, "avg_logprob": -0.06929122077094184, "compression_ratio": 1.6044444444444443, "no_speech_prob": 0.0005702532944269478}, {"id": 326, "seek": 194704, "start": 1947.04, "end": 1953.84, "text": " destined to create a system that's like this. As soon as we decided we wanted to actually create", "tokens": [50364, 33169, 281, 1884, 257, 1185, 300, 311, 411, 341, 13, 1018, 2321, 382, 321, 3047, 321, 1415, 281, 767, 1884, 50704], "temperature": 0.0, "avg_logprob": -0.13509581565856935, "compression_ratio": 1.5991189427312775, "no_speech_prob": 0.00599744962528348}, {"id": 327, "seek": 194704, "start": 1953.84, "end": 1960.8, "text": " this kind of thing. Ours is arguably just not sort of shoestring and duct tape, not to", "tokens": [50704, 341, 733, 295, 551, 13, 422, 2156, 307, 26771, 445, 406, 1333, 295, 2223, 377, 2937, 293, 25954, 7314, 11, 406, 281, 51052], "temperature": 0.0, "avg_logprob": -0.13509581565856935, "compression_ratio": 1.5991189427312775, "no_speech_prob": 0.00599744962528348}, {"id": 328, "seek": 194704, "start": 1960.8, "end": 1966.32, "text": " disparage anyone else. It's very hard to build an MMORPG, but that's kind of how I would think", "tokens": [51052, 14548, 609, 2878, 1646, 13, 467, 311, 588, 1152, 281, 1322, 364, 34191, 2483, 47, 38, 11, 457, 300, 311, 733, 295, 577, 286, 576, 519, 51328], "temperature": 0.0, "avg_logprob": -0.13509581565856935, "compression_ratio": 1.5991189427312775, "no_speech_prob": 0.00599744962528348}, {"id": 329, "seek": 194704, "start": 1966.32, "end": 1971.36, "text": " about it. Let's say rather than that, it's not an afterthought. Not an afterthought,", "tokens": [51328, 466, 309, 13, 961, 311, 584, 2831, 813, 300, 11, 309, 311, 406, 364, 934, 43135, 13, 1726, 364, 934, 43135, 11, 51580], "temperature": 0.0, "avg_logprob": -0.13509581565856935, "compression_ratio": 1.5991189427312775, "no_speech_prob": 0.00599744962528348}, {"id": 330, "seek": 197136, "start": 1971.36, "end": 1979.6799999999998, "text": " yes, correct. Okay, so what we've got here is a system where I as the game programmer,", "tokens": [50364, 2086, 11, 3006, 13, 1033, 11, 370, 437, 321, 600, 658, 510, 307, 257, 1185, 689, 286, 382, 264, 1216, 32116, 11, 50780], "temperature": 0.0, "avg_logprob": -0.19672166147539694, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.020321359857916832}, {"id": 331, "seek": 197136, "start": 1981.28, "end": 1987.28, "text": " updating a row in a date, someone moves the joystick up, I update the Y position", "tokens": [50860, 25113, 257, 5386, 294, 257, 4002, 11, 1580, 6067, 264, 48074, 493, 11, 286, 5623, 264, 398, 2535, 51160], "temperature": 0.0, "avg_logprob": -0.19672166147539694, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.020321359857916832}, {"id": 332, "seek": 197136, "start": 1987.9199999999998, "end": 1995.52, "text": " of their player's row in a database. Correct. Magic Clitty, that's going to be synchronized", "tokens": [51192, 295, 641, 4256, 311, 5386, 294, 257, 8149, 13, 12753, 13, 16154, 2033, 10016, 11, 300, 311, 516, 281, 312, 19331, 1602, 51572], "temperature": 0.0, "avg_logprob": -0.19672166147539694, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.020321359857916832}, {"id": 333, "seek": 197136, "start": 1995.52, "end": 2000.8, "text": " to the server without me worrying about it. And roll back if it turned out it didn't work.", "tokens": [51572, 281, 264, 7154, 1553, 385, 18788, 466, 309, 13, 400, 3373, 646, 498, 309, 3574, 484, 309, 994, 380, 589, 13, 51836], "temperature": 0.0, "avg_logprob": -0.19672166147539694, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.020321359857916832}, {"id": 334, "seek": 200080, "start": 2000.8, "end": 2004.8799999999999, "text": " And then I just have a rendering function that's also looking at my local database", "tokens": [50364, 400, 550, 286, 445, 362, 257, 22407, 2445, 300, 311, 611, 1237, 412, 452, 2654, 8149, 50568], "temperature": 0.0, "avg_logprob": -0.14137087062913545, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.00020335963927209377}, {"id": 335, "seek": 200080, "start": 2006.08, "end": 2009.6, "text": " and drawing it to the screen. That is correct, yes, that's essentially correct.", "tokens": [50628, 293, 6316, 309, 281, 264, 2568, 13, 663, 307, 3006, 11, 2086, 11, 300, 311, 4476, 3006, 13, 50804], "temperature": 0.0, "avg_logprob": -0.14137087062913545, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.00020335963927209377}, {"id": 336, "seek": 200080, "start": 2011.52, "end": 2018.6399999999999, "text": " Okay, let's start with the first objection. That's going to be too slow, even", "tokens": [50900, 1033, 11, 718, 311, 722, 365, 264, 700, 35756, 13, 663, 311, 516, 281, 312, 886, 2964, 11, 754, 51256], "temperature": 0.0, "avg_logprob": -0.14137087062913545, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.00020335963927209377}, {"id": 337, "seek": 200080, "start": 2019.9199999999998, "end": 2023.44, "text": " even if you don't have to do the server round trip every time.", "tokens": [51320, 754, 498, 291, 500, 380, 362, 281, 360, 264, 7154, 3098, 4931, 633, 565, 13, 51496], "temperature": 0.0, "avg_logprob": -0.14137087062913545, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.00020335963927209377}, {"id": 338, "seek": 200080, "start": 2024.56, "end": 2030.32, "text": " So let me ask a follow up question to your question. What specifically would be too slow?", "tokens": [51552, 407, 718, 385, 1029, 257, 1524, 493, 1168, 281, 428, 1168, 13, 708, 4682, 576, 312, 886, 2964, 30, 51840], "temperature": 0.0, "avg_logprob": -0.14137087062913545, "compression_ratio": 1.6040816326530611, "no_speech_prob": 0.00020335963927209377}, {"id": 339, "seek": 203080, "start": 2030.8799999999999, "end": 2036.8, "text": " Because what I want to ascertain is exactly what you're talking about. There is a perception", "tokens": [50368, 1436, 437, 286, 528, 281, 15526, 1408, 307, 2293, 437, 291, 434, 1417, 466, 13, 821, 307, 257, 12860, 50664], "temperature": 0.0, "avg_logprob": -0.13262901522896506, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.00023047045397106558}, {"id": 340, "seek": 203080, "start": 2036.8, "end": 2042.3999999999999, "text": " that databases are slow, and perhaps that's what you're driving at.", "tokens": [50664, 300, 22380, 366, 2964, 11, 293, 4317, 300, 311, 437, 291, 434, 4840, 412, 13, 50944], "temperature": 0.0, "avg_logprob": -0.13262901522896506, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.00023047045397106558}, {"id": 341, "seek": 203080, "start": 2042.3999999999999, "end": 2051.2799999999997, "text": " I think because, okay, it's got to be transactional. It's probably iterate. Once you get into things", "tokens": [50944, 286, 519, 570, 11, 1392, 11, 309, 311, 658, 281, 312, 46688, 1966, 13, 467, 311, 1391, 44497, 13, 3443, 291, 483, 666, 721, 51388], "temperature": 0.0, "avg_logprob": -0.13262901522896506, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.00023047045397106558}, {"id": 342, "seek": 203080, "start": 2051.2799999999997, "end": 2056.96, "text": " like, oh, my bullet's flying across the screen and hitting people, it's updating a considerable", "tokens": [51388, 411, 11, 1954, 11, 452, 11632, 311, 7137, 2108, 264, 2568, 293, 8850, 561, 11, 309, 311, 25113, 257, 24167, 51672], "temperature": 0.0, "avg_logprob": -0.13262901522896506, "compression_ratio": 1.600896860986547, "no_speech_prob": 0.00023047045397106558}, {"id": 343, "seek": 205696, "start": 2056.96, "end": 2062.96, "text": " amount of data. And collision detection, it's got to happen a lot of times a second. I won't", "tokens": [50364, 2372, 295, 1412, 13, 400, 24644, 17784, 11, 309, 311, 658, 281, 1051, 257, 688, 295, 1413, 257, 1150, 13, 286, 1582, 380, 50664], "temperature": 0.0, "avg_logprob": -0.09200880478839485, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0004877267056144774}, {"id": 344, "seek": 205696, "start": 2062.96, "end": 2070.32, "text": " give you the number, you can give it to me. But that feels like that's going to grind on a", "tokens": [50664, 976, 291, 264, 1230, 11, 291, 393, 976, 309, 281, 385, 13, 583, 300, 3417, 411, 300, 311, 516, 281, 16700, 322, 257, 51032], "temperature": 0.0, "avg_logprob": -0.09200880478839485, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0004877267056144774}, {"id": 345, "seek": 205696, "start": 2070.32, "end": 2075.84, "text": " transactional database. Okay, so this is a great question. And I understand where you're coming", "tokens": [51032, 46688, 1966, 8149, 13, 1033, 11, 370, 341, 307, 257, 869, 1168, 13, 400, 286, 1223, 689, 291, 434, 1348, 51308], "temperature": 0.0, "avg_logprob": -0.09200880478839485, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0004877267056144774}, {"id": 346, "seek": 205696, "start": 2075.84, "end": 2084.48, "text": " from. And we had to be a little bit crazy to think that this was a thing that should be done", "tokens": [51308, 490, 13, 400, 321, 632, 281, 312, 257, 707, 857, 3219, 281, 519, 300, 341, 390, 257, 551, 300, 820, 312, 1096, 51740], "temperature": 0.0, "avg_logprob": -0.09200880478839485, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.0004877267056144774}, {"id": 347, "seek": 208448, "start": 2084.48, "end": 2091.2, "text": " originally. But for several reasons, which I'm about to outline, I think you will come to agree", "tokens": [50364, 7993, 13, 583, 337, 2940, 4112, 11, 597, 286, 478, 466, 281, 16387, 11, 286, 519, 291, 486, 808, 281, 3986, 50700], "temperature": 0.0, "avg_logprob": -0.09581299362895644, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.0028003202751278877}, {"id": 348, "seek": 208448, "start": 2091.2, "end": 2095.04, "text": " that actually that's completely possible and plausible to do within a database context.", "tokens": [50700, 300, 767, 300, 311, 2584, 1944, 293, 39925, 281, 360, 1951, 257, 8149, 4319, 13, 50892], "temperature": 0.0, "avg_logprob": -0.09581299362895644, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.0028003202751278877}, {"id": 349, "seek": 208448, "start": 2095.84, "end": 2100.4, "text": " So the first thing I will draw your attention to is that we're not, by no means the first,", "tokens": [50932, 407, 264, 700, 551, 286, 486, 2642, 428, 3202, 281, 307, 300, 321, 434, 406, 11, 538, 572, 1355, 264, 700, 11, 51160], "temperature": 0.0, "avg_logprob": -0.09581299362895644, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.0028003202751278877}, {"id": 350, "seek": 208448, "start": 2100.4, "end": 2107.36, "text": " to do things like this in history. There is a database called times 10,", "tokens": [51160, 281, 360, 721, 411, 341, 294, 2503, 13, 821, 307, 257, 8149, 1219, 1413, 1266, 11, 51508], "temperature": 0.0, "avg_logprob": -0.09581299362895644, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.0028003202751278877}, {"id": 351, "seek": 208448, "start": 2107.36, "end": 2110.88, "text": " which was developed in the 90s. Oh, that was bought out by Oracle, wasn't it?", "tokens": [51508, 597, 390, 4743, 294, 264, 4289, 82, 13, 876, 11, 300, 390, 4243, 484, 538, 25654, 11, 2067, 380, 309, 30, 51684], "temperature": 0.0, "avg_logprob": -0.09581299362895644, "compression_ratio": 1.606060606060606, "no_speech_prob": 0.0028003202751278877}, {"id": 352, "seek": 211088, "start": 2110.96, "end": 2115.76, "text": " It was bought out by Oracle, correct. And it actually has a very similar architecture to", "tokens": [50368, 467, 390, 4243, 484, 538, 25654, 11, 3006, 13, 400, 309, 767, 575, 257, 588, 2531, 9482, 281, 50608], "temperature": 0.0, "avg_logprob": -0.13433138917132123, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.0025506876409053802}, {"id": 353, "seek": 211088, "start": 2115.76, "end": 2122.88, "text": " SpacetimeDB. So a couple of things. One, it's fully in memory. So the whole purpose of that", "tokens": [50608, 1738, 326, 9764, 27735, 13, 407, 257, 1916, 295, 721, 13, 1485, 11, 309, 311, 4498, 294, 4675, 13, 407, 264, 1379, 4334, 295, 300, 50964], "temperature": 0.0, "avg_logprob": -0.13433138917132123, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.0025506876409053802}, {"id": 354, "seek": 211088, "start": 2122.88, "end": 2127.52, "text": " database was that for certain very high throughput, low latency applications,", "tokens": [50964, 8149, 390, 300, 337, 1629, 588, 1090, 44629, 11, 2295, 27043, 5821, 11, 51196], "temperature": 0.0, "avg_logprob": -0.13433138917132123, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.0025506876409053802}, {"id": 355, "seek": 211088, "start": 2128.7200000000003, "end": 2134.48, "text": " current databases weren't hacking it, not even that currently server architectures weren't", "tokens": [51256, 2190, 22380, 4999, 380, 31422, 309, 11, 406, 754, 300, 4362, 7154, 6331, 1303, 4999, 380, 51544], "temperature": 0.0, "avg_logprob": -0.13433138917132123, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.0025506876409053802}, {"id": 356, "seek": 213448, "start": 2134.56, "end": 2142.16, "text": " hacking it. So what they decided to do is to have a database, have in memory state in that", "tokens": [50368, 31422, 309, 13, 407, 437, 436, 3047, 281, 360, 307, 281, 362, 257, 8149, 11, 362, 294, 4675, 1785, 294, 300, 50748], "temperature": 0.0, "avg_logprob": -0.08334888570448931, "compression_ratio": 1.9076923076923078, "no_speech_prob": 0.005219778046011925}, {"id": 357, "seek": 213448, "start": 2142.16, "end": 2149.12, "text": " database, put the logic of your program, physically within the same process as that database, and", "tokens": [50748, 8149, 11, 829, 264, 9952, 295, 428, 1461, 11, 9762, 1951, 264, 912, 1399, 382, 300, 8149, 11, 293, 51096], "temperature": 0.0, "avg_logprob": -0.08334888570448931, "compression_ratio": 1.9076923076923078, "no_speech_prob": 0.005219778046011925}, {"id": 358, "seek": 213448, "start": 2149.12, "end": 2156.32, "text": " then have you access the data within the same process. So you're literally reaching into your", "tokens": [51096, 550, 362, 291, 2105, 264, 1412, 1951, 264, 912, 1399, 13, 407, 291, 434, 3736, 9906, 666, 428, 51456], "temperature": 0.0, "avg_logprob": -0.08334888570448931, "compression_ratio": 1.9076923076923078, "no_speech_prob": 0.005219778046011925}, {"id": 359, "seek": 213448, "start": 2156.32, "end": 2161.12, "text": " current program memory, you're treating your program memory as though it were a database.", "tokens": [51456, 2190, 1461, 4675, 11, 291, 434, 15083, 428, 1461, 4675, 382, 1673, 309, 645, 257, 8149, 13, 51696], "temperature": 0.0, "avg_logprob": -0.08334888570448931, "compression_ratio": 1.9076923076923078, "no_speech_prob": 0.005219778046011925}, {"id": 360, "seek": 216112, "start": 2162.08, "end": 2167.52, "text": " And then what they do is all the updates to that data, they append in an append-only fashion", "tokens": [50412, 400, 550, 437, 436, 360, 307, 439, 264, 9205, 281, 300, 1412, 11, 436, 34116, 294, 364, 34116, 12, 25202, 6700, 50684], "temperature": 0.0, "avg_logprob": -0.15247084673713235, "compression_ratio": 1.5150214592274678, "no_speech_prob": 0.0007095863111317158}, {"id": 361, "seek": 216112, "start": 2168.08, "end": 2177.2, "text": " to a write-ahead log. And this was developed for telecom processing, like routing calls,", "tokens": [50712, 281, 257, 2464, 12, 545, 2056, 3565, 13, 400, 341, 390, 4743, 337, 4304, 1112, 9007, 11, 411, 32722, 5498, 11, 51168], "temperature": 0.0, "avg_logprob": -0.15247084673713235, "compression_ratio": 1.5150214592274678, "no_speech_prob": 0.0007095863111317158}, {"id": 362, "seek": 216112, "start": 2178.48, "end": 2183.7599999999998, "text": " these kinds of very, very low latency high throughput things. That's the almost identical", "tokens": [51232, 613, 3685, 295, 588, 11, 588, 2295, 27043, 1090, 44629, 721, 13, 663, 311, 264, 1920, 14800, 51496], "temperature": 0.0, "avg_logprob": -0.15247084673713235, "compression_ratio": 1.5150214592274678, "no_speech_prob": 0.0007095863111317158}, {"id": 363, "seek": 216112, "start": 2183.7599999999998, "end": 2189.04, "text": " architecture actually to how SpacetimeDB operates. We have just modernized it for", "tokens": [51496, 9482, 767, 281, 577, 1738, 326, 9764, 27735, 22577, 13, 492, 362, 445, 4363, 1602, 309, 337, 51760], "temperature": 0.0, "avg_logprob": -0.15247084673713235, "compression_ratio": 1.5150214592274678, "no_speech_prob": 0.0007095863111317158}, {"id": 364, "seek": 219112, "start": 2191.2, "end": 2196.24, "text": " use with WebAssembly and whatever language you would like, and some nice things on top of that,", "tokens": [50368, 764, 365, 9573, 10884, 19160, 293, 2035, 2856, 291, 576, 411, 11, 293, 512, 1481, 721, 322, 1192, 295, 300, 11, 50620], "temperature": 0.0, "avg_logprob": -0.119926268054593, "compression_ratio": 1.54, "no_speech_prob": 0.001986229792237282}, {"id": 365, "seek": 219112, "start": 2196.24, "end": 2201.7599999999998, "text": " including subscribing to the database, which I don't believe TimeSend actually provides that", "tokens": [50620, 3009, 19981, 281, 264, 8149, 11, 597, 286, 500, 380, 1697, 6161, 50, 521, 767, 6417, 300, 50896], "temperature": 0.0, "avg_logprob": -0.119926268054593, "compression_ratio": 1.54, "no_speech_prob": 0.001986229792237282}, {"id": 366, "seek": 219112, "start": 2201.7599999999998, "end": 2209.7599999999998, "text": " information. Okay, but that write-ahead log that we've got into persistence, which you said is", "tokens": [50896, 1589, 13, 1033, 11, 457, 300, 2464, 12, 545, 2056, 3565, 300, 321, 600, 658, 666, 37617, 11, 597, 291, 848, 307, 51296], "temperature": 0.0, "avg_logprob": -0.119926268054593, "compression_ratio": 1.54, "no_speech_prob": 0.001986229792237282}, {"id": 367, "seek": 219112, "start": 2209.7599999999998, "end": 2219.12, "text": " important, isn't that a blocker to the performance? Not typically. So first thing I would say is that", "tokens": [51296, 1021, 11, 1943, 380, 300, 257, 3461, 260, 281, 264, 3389, 30, 1726, 5850, 13, 407, 700, 551, 286, 576, 584, 307, 300, 51764], "temperature": 0.0, "avg_logprob": -0.119926268054593, "compression_ratio": 1.54, "no_speech_prob": 0.001986229792237282}, {"id": 368, "seek": 221912, "start": 2220.0, "end": 2226.24, "text": " appending to a write-ahead log is actually quite performant on modern hardware. So that's actually", "tokens": [50408, 724, 2029, 281, 257, 2464, 12, 545, 2056, 3565, 307, 767, 1596, 2042, 394, 322, 4363, 8837, 13, 407, 300, 311, 767, 50720], "temperature": 0.0, "avg_logprob": -0.08781769810890665, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.000570257194340229}, {"id": 369, "seek": 221912, "start": 2226.24, "end": 2230.16, "text": " how Kafka works, and it's how it's assumed to work. And Kafka is known as sort of a low latency", "tokens": [50720, 577, 47064, 1985, 11, 293, 309, 311, 577, 309, 311, 15895, 281, 589, 13, 400, 47064, 307, 2570, 382, 1333, 295, 257, 2295, 27043, 50916], "temperature": 0.0, "avg_logprob": -0.08781769810890665, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.000570257194340229}, {"id": 370, "seek": 221912, "start": 2230.16, "end": 2236.0, "text": " streaming thing. It's not that low latency because of details, but it's relative to what a lot of", "tokens": [50916, 11791, 551, 13, 467, 311, 406, 300, 2295, 27043, 570, 295, 4365, 11, 457, 309, 311, 4972, 281, 437, 257, 688, 295, 51208], "temperature": 0.0, "avg_logprob": -0.08781769810890665, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.000570257194340229}, {"id": 371, "seek": 221912, "start": 2236.0, "end": 2242.16, "text": " people use, very low latency. The other thing that's important to know about Kafka and systems like", "tokens": [51208, 561, 764, 11, 588, 2295, 27043, 13, 440, 661, 551, 300, 311, 1021, 281, 458, 466, 47064, 293, 3652, 411, 51516], "temperature": 0.0, "avg_logprob": -0.08781769810890665, "compression_ratio": 1.6610169491525424, "no_speech_prob": 0.000570257194340229}, {"id": 372, "seek": 224216, "start": 2242.16, "end": 2250.0, "text": " that is that you can trade off throughput for latency. So in the case of Kafka, you can batch", "tokens": [50364, 300, 307, 300, 291, 393, 4923, 766, 44629, 337, 27043, 13, 407, 294, 264, 1389, 295, 47064, 11, 291, 393, 15245, 50756], "temperature": 0.0, "avg_logprob": -0.07736027031614069, "compression_ratio": 1.8352941176470587, "no_speech_prob": 0.21726183593273163}, {"id": 373, "seek": 224216, "start": 2250.0, "end": 2255.04, "text": " more things up, which will cause the latency to increase, but will cause the throughput to go", "tokens": [50756, 544, 721, 493, 11, 597, 486, 3082, 264, 27043, 281, 3488, 11, 457, 486, 3082, 264, 44629, 281, 352, 51008], "temperature": 0.0, "avg_logprob": -0.07736027031614069, "compression_ratio": 1.8352941176470587, "no_speech_prob": 0.21726183593273163}, {"id": 374, "seek": 224216, "start": 2255.04, "end": 2260.3999999999996, "text": " up. You can always say, I care about latency more than I care about throughput. So I will", "tokens": [51008, 493, 13, 509, 393, 1009, 584, 11, 286, 1127, 466, 27043, 544, 813, 286, 1127, 466, 44629, 13, 407, 286, 486, 51276], "temperature": 0.0, "avg_logprob": -0.07736027031614069, "compression_ratio": 1.8352941176470587, "no_speech_prob": 0.21726183593273163}, {"id": 375, "seek": 224216, "start": 2261.6, "end": 2265.7599999999998, "text": " decrease it down to just one transaction. So that would make sense for I want a really high,", "tokens": [51336, 11514, 309, 760, 281, 445, 472, 14425, 13, 407, 300, 576, 652, 2020, 337, 286, 528, 257, 534, 1090, 11, 51544], "temperature": 0.0, "avg_logprob": -0.07736027031614069, "compression_ratio": 1.8352941176470587, "no_speech_prob": 0.21726183593273163}, {"id": 376, "seek": 224216, "start": 2265.7599999999998, "end": 2271.68, "text": " fast-paced game where I really want the lowest possible latency, or I don't really care if things", "tokens": [51544, 2370, 12, 47038, 1216, 689, 286, 534, 528, 264, 12437, 1944, 27043, 11, 420, 286, 500, 380, 534, 1127, 498, 721, 51840], "temperature": 0.0, "avg_logprob": -0.07736027031614069, "compression_ratio": 1.8352941176470587, "no_speech_prob": 0.21726183593273163}, {"id": 377, "seek": 227168, "start": 2271.68, "end": 2279.04, "text": " come in late. So that's one thing. The next thing I would say is that for games, or really any", "tokens": [50364, 808, 294, 3469, 13, 407, 300, 311, 472, 551, 13, 440, 958, 551, 286, 576, 584, 307, 300, 337, 2813, 11, 420, 534, 604, 50732], "temperature": 0.0, "avg_logprob": -0.07520176209125322, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.0010003586066886783}, {"id": 378, "seek": 227168, "start": 2279.04, "end": 2286.3999999999996, "text": " application, choosing the level of durability that you want should be configuration and not code.", "tokens": [50732, 3861, 11, 10875, 264, 1496, 295, 33664, 300, 291, 528, 820, 312, 11694, 293, 406, 3089, 13, 51100], "temperature": 0.0, "avg_logprob": -0.07520176209125322, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.0010003586066886783}, {"id": 379, "seek": 227168, "start": 2286.96, "end": 2293.8399999999997, "text": " So what I mean by that is I ought to be able to decide that I want to listen to data that might", "tokens": [51128, 407, 437, 286, 914, 538, 300, 307, 286, 13416, 281, 312, 1075, 281, 4536, 300, 286, 528, 281, 2140, 281, 1412, 300, 1062, 51472], "temperature": 0.0, "avg_logprob": -0.07520176209125322, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.0010003586066886783}, {"id": 380, "seek": 227168, "start": 2293.8399999999997, "end": 2300.24, "text": " not be persisted to disk, because I don't actually care about that. For a player movement, if my", "tokens": [51472, 406, 312, 13233, 292, 281, 12355, 11, 570, 286, 500, 380, 767, 1127, 466, 300, 13, 1171, 257, 4256, 3963, 11, 498, 452, 51792], "temperature": 0.0, "avg_logprob": -0.07520176209125322, "compression_ratio": 1.6176470588235294, "no_speech_prob": 0.0010003586066886783}, {"id": 381, "seek": 230024, "start": 2300.24, "end": 2308.56, "text": " server crashes and they move back 10 feet, don't really care about that. If I'm running a bank", "tokens": [50364, 7154, 28642, 293, 436, 1286, 646, 1266, 3521, 11, 500, 380, 534, 1127, 466, 300, 13, 759, 286, 478, 2614, 257, 3765, 50780], "temperature": 0.0, "avg_logprob": -0.10816360049777561, "compression_ratio": 1.58008658008658, "no_speech_prob": 0.0032721622847020626}, {"id": 382, "seek": 230024, "start": 2308.56, "end": 2315.7599999999998, "text": " transaction and it rolls back the last 10 seconds or whatever of bank transactions, it could be a", "tokens": [50780, 14425, 293, 309, 15767, 646, 264, 1036, 1266, 3949, 420, 2035, 295, 3765, 16856, 11, 309, 727, 312, 257, 51140], "temperature": 0.0, "avg_logprob": -0.10816360049777561, "compression_ratio": 1.58008658008658, "no_speech_prob": 0.0032721622847020626}, {"id": 383, "seek": 230024, "start": 2315.7599999999998, "end": 2319.6, "text": " problem, because they might have already given away the item that the guy bought, right?", "tokens": [51140, 1154, 11, 570, 436, 1062, 362, 1217, 2212, 1314, 264, 3174, 300, 264, 2146, 4243, 11, 558, 30, 51332], "temperature": 0.0, "avg_logprob": -0.10816360049777561, "compression_ratio": 1.58008658008658, "no_speech_prob": 0.0032721622847020626}, {"id": 384, "seek": 230024, "start": 2319.6, "end": 2325.2, "text": " Okay, yeah, yeah. So when you say that's configuration, are you configuring it on a", "tokens": [51332, 1033, 11, 1338, 11, 1338, 13, 407, 562, 291, 584, 300, 311, 11694, 11, 366, 291, 6662, 1345, 309, 322, 257, 51612], "temperature": 0.0, "avg_logprob": -0.10816360049777561, "compression_ratio": 1.58008658008658, "no_speech_prob": 0.0032721622847020626}, {"id": 385, "seek": 232520, "start": 2325.2799999999997, "end": 2333.6, "text": " per object type basis? So could I make some match levels of persistence, you guaranteed?", "tokens": [50368, 680, 2657, 2010, 5143, 30, 407, 727, 286, 652, 512, 2995, 4358, 295, 37617, 11, 291, 18031, 30, 50784], "temperature": 0.0, "avg_logprob": -0.14536812634972052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.02296570874750614}, {"id": 386, "seek": 232520, "start": 2333.6, "end": 2338.8799999999997, "text": " You actually configure it on a subscriber basis. So you would say, hey, I'm going to subscribe to", "tokens": [50784, 509, 767, 22162, 309, 322, 257, 26122, 5143, 13, 407, 291, 576, 584, 11, 4177, 11, 286, 478, 516, 281, 3022, 281, 51048], "temperature": 0.0, "avg_logprob": -0.14536812634972052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.02296570874750614}, {"id": 387, "seek": 232520, "start": 2338.8799999999997, "end": 2344.8799999999997, "text": " this data. And for this particular subscription, I want to see the data as soon as it updates.", "tokens": [51048, 341, 1412, 13, 400, 337, 341, 1729, 17231, 11, 286, 528, 281, 536, 264, 1412, 382, 2321, 382, 309, 9205, 13, 51348], "temperature": 0.0, "avg_logprob": -0.14536812634972052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.02296570874750614}, {"id": 388, "seek": 232520, "start": 2344.8799999999997, "end": 2350.08, "text": " I don't care if it's ready. Like, I want to hear about, so there's sort of levels at which you", "tokens": [51348, 286, 500, 380, 1127, 498, 309, 311, 1919, 13, 1743, 11, 286, 528, 281, 1568, 466, 11, 370, 456, 311, 1333, 295, 4358, 412, 597, 291, 51608], "temperature": 0.0, "avg_logprob": -0.14536812634972052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.02296570874750614}, {"id": 389, "seek": 232520, "start": 2350.08, "end": 2355.12, "text": " can listen in. So there's a pipeline of data that comes in. My message happens, I update the data,", "tokens": [51608, 393, 2140, 294, 13, 407, 456, 311, 257, 15517, 295, 1412, 300, 1487, 294, 13, 1222, 3636, 2314, 11, 286, 5623, 264, 1412, 11, 51860], "temperature": 0.0, "avg_logprob": -0.14536812634972052, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.02296570874750614}, {"id": 390, "seek": 235512, "start": 2355.8399999999997, "end": 2360.24, "text": " that changes the stuff in memory, I write it to disk, I replicate it to other machines,", "tokens": [50400, 300, 2962, 264, 1507, 294, 4675, 11, 286, 2464, 309, 281, 12355, 11, 286, 25356, 309, 281, 661, 8379, 11, 50620], "temperature": 0.0, "avg_logprob": -0.1202216894448209, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.0018667898839339614}, {"id": 391, "seek": 235512, "start": 2360.24, "end": 2363.3599999999997, "text": " all of this. And at any point in time, you can decide, like, you know what, it's good enough,", "tokens": [50620, 439, 295, 341, 13, 400, 412, 604, 935, 294, 565, 11, 291, 393, 4536, 11, 411, 11, 291, 458, 437, 11, 309, 311, 665, 1547, 11, 50776], "temperature": 0.0, "avg_logprob": -0.1202216894448209, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.0018667898839339614}, {"id": 392, "seek": 235512, "start": 2363.3599999999997, "end": 2367.3599999999997, "text": " I want to listen in here, right? So I want to listen in after it's been updated memory versus", "tokens": [50776, 286, 528, 281, 2140, 294, 510, 11, 558, 30, 407, 286, 528, 281, 2140, 294, 934, 309, 311, 668, 10588, 4675, 5717, 50976], "temperature": 0.0, "avg_logprob": -0.1202216894448209, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.0018667898839339614}, {"id": 393, "seek": 235512, "start": 2367.3599999999997, "end": 2372.56, "text": " I want to listen after it's been persisted disk versus I want to listen only when it's been replicated", "tokens": [50976, 286, 528, 281, 2140, 934, 309, 311, 668, 13233, 292, 12355, 5717, 286, 528, 281, 2140, 787, 562, 309, 311, 668, 46365, 51236], "temperature": 0.0, "avg_logprob": -0.1202216894448209, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.0018667898839339614}, {"id": 394, "seek": 235512, "start": 2372.56, "end": 2379.04, "text": " to five machines. That's a sort of a different level of listening, if that makes sense.", "tokens": [51236, 281, 1732, 8379, 13, 663, 311, 257, 1333, 295, 257, 819, 1496, 295, 4764, 11, 498, 300, 1669, 2020, 13, 51560], "temperature": 0.0, "avg_logprob": -0.1202216894448209, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.0018667898839339614}, {"id": 395, "seek": 235512, "start": 2379.04, "end": 2383.68, "text": " I'm jumping around trying to get my handle or my hands all over. But, okay, so how does that", "tokens": [51560, 286, 478, 11233, 926, 1382, 281, 483, 452, 4813, 420, 452, 2377, 439, 670, 13, 583, 11, 1392, 11, 370, 577, 775, 300, 51792], "temperature": 0.0, "avg_logprob": -0.1202216894448209, "compression_ratio": 1.8695652173913044, "no_speech_prob": 0.0018667898839339614}, {"id": 396, "seek": 238368, "start": 2383.68, "end": 2390.3999999999996, "text": " work programming? I let's say the score, player score, is gradually ticking up. It's not the", "tokens": [50364, 589, 9410, 30, 286, 718, 311, 584, 264, 6175, 11, 4256, 6175, 11, 307, 13145, 33999, 493, 13, 467, 311, 406, 264, 50700], "temperature": 0.0, "avg_logprob": -0.1221460869641808, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.0023959435056895018}, {"id": 397, "seek": 238368, "start": 2390.3999999999996, "end": 2396.8799999999997, "text": " end of the world if it maybe rolls back a little bit. Am I writing some code that just subscribes", "tokens": [50700, 917, 295, 264, 1002, 498, 309, 1310, 15767, 646, 257, 707, 857, 13, 2012, 286, 3579, 512, 3089, 300, 445, 2325, 6446, 51024], "temperature": 0.0, "avg_logprob": -0.1221460869641808, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.0023959435056895018}, {"id": 398, "seek": 238368, "start": 2396.8799999999997, "end": 2403.12, "text": " to the score changing and just renders that corner of the screen? You certainly could do that.", "tokens": [51024, 281, 264, 6175, 4473, 293, 445, 6125, 433, 300, 4538, 295, 264, 2568, 30, 509, 3297, 727, 360, 300, 13, 51336], "temperature": 0.0, "avg_logprob": -0.1221460869641808, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.0023959435056895018}, {"id": 399, "seek": 238368, "start": 2403.68, "end": 2407.2, "text": " Typically, what a client will do is they'll subscribe to all the data that they want right", "tokens": [51364, 23129, 11, 437, 257, 6423, 486, 360, 307, 436, 603, 3022, 281, 439, 264, 1412, 300, 436, 528, 558, 51540], "temperature": 0.0, "avg_logprob": -0.1221460869641808, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.0023959435056895018}, {"id": 400, "seek": 238368, "start": 2407.2, "end": 2410.96, "text": " up front. So they'll say, like, let's say it's a chess match, you'll say, I want to subscribe to", "tokens": [51540, 493, 1868, 13, 407, 436, 603, 584, 11, 411, 11, 718, 311, 584, 309, 311, 257, 24122, 2995, 11, 291, 603, 584, 11, 286, 528, 281, 3022, 281, 51728], "temperature": 0.0, "avg_logprob": -0.1221460869641808, "compression_ratio": 1.7262773722627738, "no_speech_prob": 0.0023959435056895018}, {"id": 401, "seek": 241096, "start": 2410.96, "end": 2415.04, "text": " all the peace positions. Or I want to subscribe to, it depends on how you program that match,", "tokens": [50364, 439, 264, 4336, 8432, 13, 1610, 286, 528, 281, 3022, 281, 11, 309, 5946, 322, 577, 291, 1461, 300, 2995, 11, 50568], "temperature": 0.0, "avg_logprob": -0.13594129134197624, "compression_ratio": 1.9222972972972974, "no_speech_prob": 0.04740937799215317}, {"id": 402, "seek": 241096, "start": 2415.04, "end": 2419.68, "text": " but let's say you're going to do it in a certain way. I'm going to listen to all the peace positions", "tokens": [50568, 457, 718, 311, 584, 291, 434, 516, 281, 360, 309, 294, 257, 1629, 636, 13, 286, 478, 516, 281, 2140, 281, 439, 264, 4336, 8432, 50800], "temperature": 0.0, "avg_logprob": -0.13594129134197624, "compression_ratio": 1.9222972972972974, "no_speech_prob": 0.04740937799215317}, {"id": 403, "seek": 241096, "start": 2419.68, "end": 2424.0, "text": " and I want to subscribe to the score. You don't actually, a lot of cases, you can actually", "tokens": [50800, 293, 286, 528, 281, 3022, 281, 264, 6175, 13, 509, 500, 380, 767, 11, 257, 688, 295, 3331, 11, 291, 393, 767, 51016], "temperature": 0.0, "avg_logprob": -0.13594129134197624, "compression_ratio": 1.9222972972972974, "no_speech_prob": 0.04740937799215317}, {"id": 404, "seek": 241096, "start": 2424.0, "end": 2429.36, "text": " compute the score on the client based on the state of the game. But let's say you can't,", "tokens": [51016, 14722, 264, 6175, 322, 264, 6423, 2361, 322, 264, 1785, 295, 264, 1216, 13, 583, 718, 311, 584, 291, 393, 380, 11, 51284], "temperature": 0.0, "avg_logprob": -0.13594129134197624, "compression_ratio": 1.9222972972972974, "no_speech_prob": 0.04740937799215317}, {"id": 405, "seek": 241096, "start": 2429.36, "end": 2433.28, "text": " for some reason, in this game, you would subscribe to the score as well. And then that will be", "tokens": [51284, 337, 512, 1778, 11, 294, 341, 1216, 11, 291, 576, 3022, 281, 264, 6175, 382, 731, 13, 400, 550, 300, 486, 312, 51480], "temperature": 0.0, "avg_logprob": -0.13594129134197624, "compression_ratio": 1.9222972972972974, "no_speech_prob": 0.04740937799215317}, {"id": 406, "seek": 241096, "start": 2433.28, "end": 2440.08, "text": " updated in a row and you'll just say from score table, subscribe, select off star from essentially.", "tokens": [51480, 10588, 294, 257, 5386, 293, 291, 603, 445, 584, 490, 6175, 3199, 11, 3022, 11, 3048, 766, 3543, 490, 4476, 13, 51820], "temperature": 0.0, "avg_logprob": -0.13594129134197624, "compression_ratio": 1.9222972972972974, "no_speech_prob": 0.04740937799215317}, {"id": 407, "seek": 244008, "start": 2440.48, "end": 2446.88, "text": " Am I doing like a, am I joining those datasets? So select all from pieces, union, select all from", "tokens": [50384, 2012, 286, 884, 411, 257, 11, 669, 286, 5549, 729, 42856, 30, 407, 3048, 439, 490, 3755, 11, 11671, 11, 3048, 439, 490, 50704], "temperature": 0.0, "avg_logprob": -0.18323626783159044, "compression_ratio": 1.558659217877095, "no_speech_prob": 0.00040436143171973526}, {"id": 408, "seek": 244008, "start": 2447.44, "end": 2454.56, "text": " score? Yeah. So in this case, you're going to basically select a subset of each server table.", "tokens": [50732, 6175, 30, 865, 13, 407, 294, 341, 1389, 11, 291, 434, 516, 281, 1936, 3048, 257, 25993, 295, 1184, 7154, 3199, 13, 51088], "temperature": 0.0, "avg_logprob": -0.18323626783159044, "compression_ratio": 1.558659217877095, "no_speech_prob": 0.00040436143171973526}, {"id": 409, "seek": 244008, "start": 2454.56, "end": 2463.92, "text": " We do not yet support subscription joins. We do actually. So we support what's called a", "tokens": [51088, 492, 360, 406, 1939, 1406, 17231, 24397, 13, 492, 360, 767, 13, 407, 321, 1406, 437, 311, 1219, 257, 51556], "temperature": 0.0, "avg_logprob": -0.18323626783159044, "compression_ratio": 1.558659217877095, "no_speech_prob": 0.00040436143171973526}, {"id": 410, "seek": 246392, "start": 2464.88, "end": 2471.76, "text": " semi-join. So you may filter out rows from a table based on a join from another table. So for", "tokens": [50412, 12909, 12, 5134, 259, 13, 407, 291, 815, 6608, 484, 13241, 490, 257, 3199, 2361, 322, 257, 3917, 490, 1071, 3199, 13, 407, 337, 50756], "temperature": 0.0, "avg_logprob": -0.10112336277961731, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.13291944563388824}, {"id": 411, "seek": 246392, "start": 2471.76, "end": 2480.08, "text": " example, I might want to subscribe to all players who's, who are friends with this other person.", "tokens": [50756, 1365, 11, 286, 1062, 528, 281, 3022, 281, 439, 4150, 567, 311, 11, 567, 366, 1855, 365, 341, 661, 954, 13, 51172], "temperature": 0.0, "avg_logprob": -0.10112336277961731, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.13291944563388824}, {"id": 412, "seek": 246392, "start": 2480.08, "end": 2485.52, "text": " So I would write a join and I could, but I would always get the whole player row.", "tokens": [51172, 407, 286, 576, 2464, 257, 3917, 293, 286, 727, 11, 457, 286, 576, 1009, 483, 264, 1379, 4256, 5386, 13, 51444], "temperature": 0.0, "avg_logprob": -0.10112336277961731, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.13291944563388824}, {"id": 413, "seek": 246392, "start": 2486.32, "end": 2491.12, "text": " And I'm not going to get any like player plus others data. If you want to do that,", "tokens": [51484, 400, 286, 478, 406, 516, 281, 483, 604, 411, 4256, 1804, 2357, 1412, 13, 759, 291, 528, 281, 360, 300, 11, 51724], "temperature": 0.0, "avg_logprob": -0.10112336277961731, "compression_ratio": 1.6359447004608294, "no_speech_prob": 0.13291944563388824}, {"id": 414, "seek": 249112, "start": 2491.12, "end": 2494.64, "text": " you would subscribe to the other table as well. And then we union all of those together and send", "tokens": [50364, 291, 576, 3022, 281, 264, 661, 3199, 382, 731, 13, 400, 550, 321, 11671, 439, 295, 729, 1214, 293, 2845, 50540], "temperature": 0.0, "avg_logprob": -0.12537190972304926, "compression_ratio": 1.5723905723905724, "no_speech_prob": 0.0031706837471574545}, {"id": 415, "seek": 249112, "start": 2494.64, "end": 2502.88, "text": " them down. Okay. And are we writing this query in SQL? SQL. Currently. We, there's no reason we", "tokens": [50540, 552, 760, 13, 1033, 13, 400, 366, 321, 3579, 341, 14581, 294, 19200, 30, 19200, 13, 19964, 13, 492, 11, 456, 311, 572, 1778, 321, 50952], "temperature": 0.0, "avg_logprob": -0.12537190972304926, "compression_ratio": 1.5723905723905724, "no_speech_prob": 0.0031706837471574545}, {"id": 416, "seek": 249112, "start": 2502.88, "end": 2507.2, "text": " can't also support other query languages like GraphQL in the future. It's just for right now,", "tokens": [50952, 393, 380, 611, 1406, 661, 14581, 8650, 411, 21884, 13695, 294, 264, 2027, 13, 467, 311, 445, 337, 558, 586, 11, 51168], "temperature": 0.0, "avg_logprob": -0.12537190972304926, "compression_ratio": 1.5723905723905724, "no_speech_prob": 0.0031706837471574545}, {"id": 417, "seek": 249112, "start": 2507.2, "end": 2512.7999999999997, "text": " for building an MMO or RPG, we need SQL. Okay. So as a game programmer, I'm writing,", "tokens": [51168, 337, 2390, 364, 376, 18976, 420, 22614, 11, 321, 643, 19200, 13, 1033, 13, 407, 382, 257, 1216, 32116, 11, 286, 478, 3579, 11, 51448], "temperature": 0.0, "avg_logprob": -0.12537190972304926, "compression_ratio": 1.5723905723905724, "no_speech_prob": 0.0031706837471574545}, {"id": 418, "seek": 249112, "start": 2514.64, "end": 2520.4, "text": " like you say, very much like stored procedures that have a mixture of SQL and coding. And like,", "tokens": [51540, 411, 291, 584, 11, 588, 709, 411, 12187, 13846, 300, 362, 257, 9925, 295, 19200, 293, 17720, 13, 400, 411, 11, 51828], "temperature": 0.0, "avg_logprob": -0.12537190972304926, "compression_ratio": 1.5723905723905724, "no_speech_prob": 0.0031706837471574545}, {"id": 419, "seek": 252040, "start": 2520.4, "end": 2525.84, "text": " what's the language? So the language is the module that you're writing is a WebAssembly module.", "tokens": [50364, 437, 311, 264, 2856, 30, 407, 264, 2856, 307, 264, 10088, 300, 291, 434, 3579, 307, 257, 9573, 10884, 19160, 10088, 13, 50636], "temperature": 0.0, "avg_logprob": -0.10539292859601544, "compression_ratio": 1.8382978723404255, "no_speech_prob": 0.0014535697409883142}, {"id": 420, "seek": 252040, "start": 2525.84, "end": 2532.56, "text": " So it's any language that you want that compiles to WebAssembly. Notably, we support Rust and Csharp", "tokens": [50636, 407, 309, 311, 604, 2856, 300, 291, 528, 300, 715, 4680, 281, 9573, 10884, 19160, 13, 1726, 1188, 11, 321, 1406, 34952, 293, 383, 2716, 6529, 50972], "temperature": 0.0, "avg_logprob": -0.10539292859601544, "compression_ratio": 1.8382978723404255, "no_speech_prob": 0.0014535697409883142}, {"id": 421, "seek": 252040, "start": 2532.56, "end": 2536.2400000000002, "text": " in terms of building a library of nice things for you to use in those languages.", "tokens": [50972, 294, 2115, 295, 2390, 257, 6405, 295, 1481, 721, 337, 291, 281, 764, 294, 729, 8650, 13, 51156], "temperature": 0.0, "avg_logprob": -0.10539292859601544, "compression_ratio": 1.8382978723404255, "no_speech_prob": 0.0014535697409883142}, {"id": 422, "seek": 252040, "start": 2537.36, "end": 2542.2400000000002, "text": " In principle, anybody else could do whatever language they want that compiles to WebAssembly.", "tokens": [51212, 682, 8665, 11, 4472, 1646, 727, 360, 2035, 2856, 436, 528, 300, 715, 4680, 281, 9573, 10884, 19160, 13, 51456], "temperature": 0.0, "avg_logprob": -0.10539292859601544, "compression_ratio": 1.8382978723404255, "no_speech_prob": 0.0014535697409883142}, {"id": 423, "seek": 252040, "start": 2543.28, "end": 2545.92, "text": " But yeah, those are the two that we support right now. Okay.", "tokens": [51508, 583, 1338, 11, 729, 366, 264, 732, 300, 321, 1406, 558, 586, 13, 1033, 13, 51640], "temperature": 0.0, "avg_logprob": -0.10539292859601544, "compression_ratio": 1.8382978723404255, "no_speech_prob": 0.0014535697409883142}, {"id": 424, "seek": 254592, "start": 2546.4, "end": 2551.6800000000003, "text": " I risk framing this all as objections, but I'm trying to think...", "tokens": [50388, 286, 3148, 28971, 341, 439, 382, 44649, 11, 457, 286, 478, 1382, 281, 519, 485, 50652], "temperature": 0.0, "avg_logprob": -0.1621732531853442, "compression_ratio": 1.683794466403162, "no_speech_prob": 0.000803886039648205}, {"id": 425, "seek": 254592, "start": 2551.6800000000003, "end": 2559.6, "text": " Sure. No, no, please. There is an objectionable idea that happens to work. And so it's quite", "tokens": [50652, 4894, 13, 883, 11, 572, 11, 1767, 13, 821, 307, 364, 35756, 712, 1558, 300, 2314, 281, 589, 13, 400, 370, 309, 311, 1596, 51048], "temperature": 0.0, "avg_logprob": -0.1621732531853442, "compression_ratio": 1.683794466403162, "no_speech_prob": 0.000803886039648205}, {"id": 426, "seek": 254592, "start": 2559.6, "end": 2564.96, "text": " exciting. Okay. So the other thing that people always complain about with stored procedures,", "tokens": [51048, 4670, 13, 1033, 13, 407, 264, 661, 551, 300, 561, 1009, 11024, 466, 365, 12187, 13846, 11, 51316], "temperature": 0.0, "avg_logprob": -0.1621732531853442, "compression_ratio": 1.683794466403162, "no_speech_prob": 0.000803886039648205}, {"id": 427, "seek": 254592, "start": 2564.96, "end": 2568.7200000000003, "text": " I mean, a lot of people dislike stored procedures. And I think the reason is,", "tokens": [51316, 286, 914, 11, 257, 688, 295, 561, 26006, 12187, 13846, 13, 400, 286, 519, 264, 1778, 307, 11, 51504], "temperature": 0.0, "avg_logprob": -0.1621732531853442, "compression_ratio": 1.683794466403162, "no_speech_prob": 0.000803886039648205}, {"id": 428, "seek": 254592, "start": 2570.0, "end": 2574.48, "text": " I think there's two reasons. One is the language can be weird for stored procedures. Personally,", "tokens": [51568, 286, 519, 456, 311, 732, 4112, 13, 1485, 307, 264, 2856, 393, 312, 3657, 337, 12187, 13846, 13, 21079, 11, 51792], "temperature": 0.0, "avg_logprob": -0.1621732531853442, "compression_ratio": 1.683794466403162, "no_speech_prob": 0.000803886039648205}, {"id": 429, "seek": 257448, "start": 2574.56, "end": 2579.12, "text": " I reject that one. If it's valuable enough, you'll learn the language. The real one is", "tokens": [50368, 286, 8248, 300, 472, 13, 759, 309, 311, 8263, 1547, 11, 291, 603, 1466, 264, 2856, 13, 440, 957, 472, 307, 50596], "temperature": 0.0, "avg_logprob": -0.10608033211000505, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.0011331697460263968}, {"id": 430, "seek": 257448, "start": 2579.12, "end": 2585.6, "text": " management of stored procedures is a misery. Correct. Yes, it is. And I think these are the...", "tokens": [50596, 4592, 295, 12187, 13846, 307, 257, 32309, 13, 12753, 13, 1079, 11, 309, 307, 13, 400, 286, 519, 613, 366, 264, 485, 50920], "temperature": 0.0, "avg_logprob": -0.10608033211000505, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.0011331697460263968}, {"id": 431, "seek": 257448, "start": 2585.6, "end": 2589.76, "text": " So I would actually go a little bit further too. The permissions model of stored procedures", "tokens": [50920, 407, 286, 576, 767, 352, 257, 707, 857, 3052, 886, 13, 440, 32723, 2316, 295, 12187, 13846, 51128], "temperature": 0.0, "avg_logprob": -0.10608033211000505, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.0011331697460263968}, {"id": 432, "seek": 257448, "start": 2589.76, "end": 2599.84, "text": " at times can be arcane as well. So I believe it's really, to your point, fundamentally a user", "tokens": [51128, 412, 1413, 393, 312, 10346, 1929, 382, 731, 13, 407, 286, 1697, 309, 311, 534, 11, 281, 428, 935, 11, 17879, 257, 4195, 51632], "temperature": 0.0, "avg_logprob": -0.10608033211000505, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.0011331697460263968}, {"id": 433, "seek": 259984, "start": 2599.84, "end": 2606.32, "text": " experience problem, not a theoretical or technological problem, if that makes sense.", "tokens": [50364, 1752, 1154, 11, 406, 257, 20864, 420, 18439, 1154, 11, 498, 300, 1669, 2020, 13, 50688], "temperature": 0.0, "avg_logprob": -0.14879959704829196, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.03513064980506897}, {"id": 434, "seek": 259984, "start": 2606.32, "end": 2610.96, "text": " Yeah. It's like developer experience rather than this simply doesn't work.", "tokens": [50688, 865, 13, 467, 311, 411, 10754, 1752, 2831, 813, 341, 2935, 1177, 380, 589, 13, 50920], "temperature": 0.0, "avg_logprob": -0.14879959704829196, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.03513064980506897}, {"id": 435, "seek": 259984, "start": 2610.96, "end": 2614.7200000000003, "text": " Yes. I mean, why... If you actually think about stored procedures as they were,", "tokens": [50920, 1079, 13, 286, 914, 11, 983, 485, 759, 291, 767, 519, 466, 12187, 13846, 382, 436, 645, 11, 51108], "temperature": 0.0, "avg_logprob": -0.14879959704829196, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.03513064980506897}, {"id": 436, "seek": 259984, "start": 2614.7200000000003, "end": 2619.6000000000004, "text": " it's a nightmare. You have data that's in your database operating that's opaque because somebody", "tokens": [51108, 309, 311, 257, 18724, 13, 509, 362, 1412, 300, 311, 294, 428, 8149, 7447, 300, 311, 42687, 570, 2618, 51352], "temperature": 0.0, "avg_logprob": -0.14879959704829196, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.03513064980506897}, {"id": 437, "seek": 259984, "start": 2619.6000000000004, "end": 2622.56, "text": " updated it, but you don't... It's not in version control. You don't have any idea like,", "tokens": [51352, 10588, 309, 11, 457, 291, 500, 380, 485, 467, 311, 406, 294, 3037, 1969, 13, 509, 500, 380, 362, 604, 1558, 411, 11, 51500], "temperature": 0.0, "avg_logprob": -0.14879959704829196, "compression_ratio": 1.6434108527131783, "no_speech_prob": 0.03513064980506897}, {"id": 438, "seek": 262256, "start": 2623.44, "end": 2630.56, "text": " what was running? Did somebody change it? It's like, where is it stored? It's just a nightmare.", "tokens": [50408, 437, 390, 2614, 30, 2589, 2618, 1319, 309, 30, 467, 311, 411, 11, 689, 307, 309, 12187, 30, 467, 311, 445, 257, 18724, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1090723363364615, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.01640024408698082}, {"id": 439, "seek": 262256, "start": 2632.4, "end": 2637.04, "text": " It's a great point. What I will say to this is actually, we didn't set out to build the database", "tokens": [50856, 467, 311, 257, 869, 935, 13, 708, 286, 486, 584, 281, 341, 307, 767, 11, 321, 994, 380, 992, 484, 281, 1322, 264, 8149, 51088], "temperature": 0.0, "avg_logprob": -0.1090723363364615, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.01640024408698082}, {"id": 440, "seek": 262256, "start": 2637.04, "end": 2641.7599999999998, "text": " in stored procedures. What actually happened is we built a system that had the right UX for what", "tokens": [51088, 294, 12187, 13846, 13, 708, 767, 2011, 307, 321, 3094, 257, 1185, 300, 632, 264, 558, 40176, 337, 437, 51324], "temperature": 0.0, "avg_logprob": -0.1090723363364615, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.01640024408698082}, {"id": 441, "seek": 262256, "start": 2641.7599999999998, "end": 2645.92, "text": " we wanted our developers to have and then looked at it and said like, oh, from this angle, actually,", "tokens": [51324, 321, 1415, 527, 8849, 281, 362, 293, 550, 2956, 412, 309, 293, 848, 411, 11, 1954, 11, 490, 341, 5802, 11, 767, 11, 51532], "temperature": 0.0, "avg_logprob": -0.1090723363364615, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.01640024408698082}, {"id": 442, "seek": 262256, "start": 2645.92, "end": 2649.84, "text": " this is just a database with stored procedures. So it was very much a... We backed into it,", "tokens": [51532, 341, 307, 445, 257, 8149, 365, 12187, 13846, 13, 407, 309, 390, 588, 709, 257, 485, 492, 20391, 666, 309, 11, 51728], "temperature": 0.0, "avg_logprob": -0.1090723363364615, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.01640024408698082}, {"id": 443, "seek": 264984, "start": 2649.84, "end": 2654.32, "text": " we didn't arrive there. So that's number one. Developer experience is the most important aspect", "tokens": [50364, 321, 994, 380, 8881, 456, 13, 407, 300, 311, 1230, 472, 13, 44915, 1752, 307, 264, 881, 1021, 4171, 50588], "temperature": 0.0, "avg_logprob": -0.11404306380475154, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.000732140731997788}, {"id": 444, "seek": 264984, "start": 2654.32, "end": 2659.28, "text": " of space time DB. And if it is bad, there's no point to doing it. That was why we created it in the", "tokens": [50588, 295, 1901, 565, 26754, 13, 400, 498, 309, 307, 1578, 11, 456, 311, 572, 935, 281, 884, 309, 13, 663, 390, 983, 321, 2942, 309, 294, 264, 50836], "temperature": 0.0, "avg_logprob": -0.11404306380475154, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.000732140731997788}, {"id": 445, "seek": 264984, "start": 2659.28, "end": 2664.6400000000003, "text": " first place. The way we solve these problems are, number one is we put all of the stored procedures", "tokens": [50836, 700, 1081, 13, 440, 636, 321, 5039, 613, 2740, 366, 11, 1230, 472, 307, 321, 829, 439, 295, 264, 12187, 13846, 51104], "temperature": 0.0, "avg_logprob": -0.11404306380475154, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.000732140731997788}, {"id": 446, "seek": 264984, "start": 2665.44, "end": 2671.92, "text": " as the root of your database. It is all in a single module that's based from a single repo,", "tokens": [51144, 382, 264, 5593, 295, 428, 8149, 13, 467, 307, 439, 294, 257, 2167, 10088, 300, 311, 2361, 490, 257, 2167, 49040, 11, 51468], "temperature": 0.0, "avg_logprob": -0.11404306380475154, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.000732140731997788}, {"id": 447, "seek": 264984, "start": 2671.92, "end": 2678.88, "text": " in this case, that you can version in version control and then you can see the versions of it.", "tokens": [51468, 294, 341, 1389, 11, 300, 291, 393, 3037, 294, 3037, 1969, 293, 550, 291, 393, 536, 264, 9606, 295, 309, 13, 51816], "temperature": 0.0, "avg_logprob": -0.11404306380475154, "compression_ratio": 1.740072202166065, "no_speech_prob": 0.000732140731997788}, {"id": 448, "seek": 267888, "start": 2678.96, "end": 2684.1600000000003, "text": " The thing I would liken it to, from a developer experience perspective, and now I'm going to", "tokens": [50368, 440, 551, 286, 576, 36946, 309, 281, 11, 490, 257, 10754, 1752, 4585, 11, 293, 586, 286, 478, 516, 281, 50628], "temperature": 0.0, "avg_logprob": -0.15369707743326824, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.00041719709406606853}, {"id": 449, "seek": 267888, "start": 2684.1600000000003, "end": 2693.04, "text": " say something that will maybe trigger a lot of people, but it's similar in principle to smart", "tokens": [50628, 584, 746, 300, 486, 1310, 7875, 257, 688, 295, 561, 11, 457, 309, 311, 2531, 294, 8665, 281, 4069, 51072], "temperature": 0.0, "avg_logprob": -0.15369707743326824, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.00041719709406606853}, {"id": 450, "seek": 267888, "start": 2693.04, "end": 2699.84, "text": " contracts. So from there, you... Nobody thinks the developer experience of those is bad, except", "tokens": [51072, 13952, 13, 407, 490, 456, 11, 291, 485, 9297, 7309, 264, 10754, 1752, 295, 729, 307, 1578, 11, 3993, 51412], "temperature": 0.0, "avg_logprob": -0.15369707743326824, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.00041719709406606853}, {"id": 451, "seek": 267888, "start": 2699.84, "end": 2704.7200000000003, "text": " the fact that they have to deal with the blockchain. But ultimately... And the programming language", "tokens": [51412, 264, 1186, 300, 436, 362, 281, 2028, 365, 264, 17176, 13, 583, 6284, 485, 400, 264, 9410, 2856, 51656], "temperature": 0.0, "avg_logprob": -0.15369707743326824, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.00041719709406606853}, {"id": 452, "seek": 267888, "start": 2704.7200000000003, "end": 2707.84, "text": " can be pretty terrible. And the programming language can be pretty terrible. But fortunately,", "tokens": [51656, 393, 312, 1238, 6237, 13, 400, 264, 9410, 2856, 393, 312, 1238, 6237, 13, 583, 25511, 11, 51812], "temperature": 0.0, "avg_logprob": -0.15369707743326824, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.00041719709406606853}, {"id": 453, "seek": 270784, "start": 2707.84, "end": 2712.96, "text": " we've solved both of those problems by removing the blockchain and making it so you can use whatever", "tokens": [50364, 321, 600, 13041, 1293, 295, 729, 2740, 538, 12720, 264, 17176, 293, 1455, 309, 370, 291, 393, 764, 2035, 50620], "temperature": 0.0, "avg_logprob": -0.11472417513529459, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.004904830362647772}, {"id": 454, "seek": 270784, "start": 2712.96, "end": 2720.6400000000003, "text": " programming language you'd like. But it's the same idea, right? You do not need a DevOps team", "tokens": [50620, 9410, 2856, 291, 1116, 411, 13, 583, 309, 311, 264, 912, 1558, 11, 558, 30, 509, 360, 406, 643, 257, 43051, 1469, 51004], "temperature": 0.0, "avg_logprob": -0.11472417513529459, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.004904830362647772}, {"id": 455, "seek": 270784, "start": 2721.2000000000003, "end": 2726.56, "text": " to maintain or an operations team or any of that or AWS credit or any of that to run your", "tokens": [51032, 281, 6909, 420, 364, 7705, 1469, 420, 604, 295, 300, 420, 17650, 5397, 420, 604, 295, 300, 281, 1190, 428, 51300], "temperature": 0.0, "avg_logprob": -0.11472417513529459, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.004904830362647772}, {"id": 456, "seek": 270784, "start": 2728.4, "end": 2733.36, "text": " smart contract. What you do is you say publish, you set it, you forget it, you walk away. You", "tokens": [51392, 4069, 4364, 13, 708, 291, 360, 307, 291, 584, 11374, 11, 291, 992, 309, 11, 291, 2870, 309, 11, 291, 1792, 1314, 13, 509, 51640], "temperature": 0.0, "avg_logprob": -0.11472417513529459, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.004904830362647772}, {"id": 457, "seek": 270784, "start": 2733.36, "end": 2737.6000000000004, "text": " don't have to deal with that ever again. It's running, someone's running it for you. You really", "tokens": [51640, 500, 380, 362, 281, 2028, 365, 300, 1562, 797, 13, 467, 311, 2614, 11, 1580, 311, 2614, 309, 337, 291, 13, 509, 534, 51852], "temperature": 0.0, "avg_logprob": -0.11472417513529459, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.004904830362647772}, {"id": 458, "seek": 273760, "start": 2737.6, "end": 2742.16, "text": " truly don't care. And that is the promise of the developer experience that I think we can provide", "tokens": [50364, 4908, 500, 380, 1127, 13, 400, 300, 307, 264, 6228, 295, 264, 10754, 1752, 300, 286, 519, 321, 393, 2893, 50592], "temperature": 0.0, "avg_logprob": -0.1335355622427804, "compression_ratio": 1.872053872053872, "no_speech_prob": 0.0008556593675166368}, {"id": 459, "seek": 273760, "start": 2742.16, "end": 2746.3199999999997, "text": " with store procedures. And it's very easy in the case of smart contracts to keep them in sync.", "tokens": [50592, 365, 3531, 13846, 13, 400, 309, 311, 588, 1858, 294, 264, 1389, 295, 4069, 13952, 281, 1066, 552, 294, 20271, 13, 50800], "temperature": 0.0, "avg_logprob": -0.1335355622427804, "compression_ratio": 1.872053872053872, "no_speech_prob": 0.0008556593675166368}, {"id": 460, "seek": 273760, "start": 2746.3199999999997, "end": 2749.7599999999998, "text": " Normally, actually, in a lot of systems, you can't update your smart contracts. So that's one thing.", "tokens": [50800, 17424, 11, 767, 11, 294, 257, 688, 295, 3652, 11, 291, 393, 380, 5623, 428, 4069, 13952, 13, 407, 300, 311, 472, 551, 13, 50972], "temperature": 0.0, "avg_logprob": -0.1335355622427804, "compression_ratio": 1.872053872053872, "no_speech_prob": 0.0008556593675166368}, {"id": 461, "seek": 273760, "start": 2750.56, "end": 2756.24, "text": " But in our case, you can update a space-time-due module. And it comes from a database, and you", "tokens": [51012, 583, 294, 527, 1389, 11, 291, 393, 5623, 257, 1901, 12, 3766, 12, 67, 622, 10088, 13, 400, 309, 1487, 490, 257, 8149, 11, 293, 291, 51296], "temperature": 0.0, "avg_logprob": -0.1335355622427804, "compression_ratio": 1.872053872053872, "no_speech_prob": 0.0008556593675166368}, {"id": 462, "seek": 273760, "start": 2756.24, "end": 2759.44, "text": " can see the version that was up there. And the version is stored in the log. So", "tokens": [51296, 393, 536, 264, 3037, 300, 390, 493, 456, 13, 400, 264, 3037, 307, 12187, 294, 264, 3565, 13, 407, 51456], "temperature": 0.0, "avg_logprob": -0.1335355622427804, "compression_ratio": 1.872053872053872, "no_speech_prob": 0.0008556593675166368}, {"id": 463, "seek": 273760, "start": 2762.24, "end": 2766.3199999999997, "text": " the fact that you're updating your whole database and you can do migrations within your", "tokens": [51596, 264, 1186, 300, 291, 434, 25113, 428, 1379, 8149, 293, 291, 393, 360, 6186, 12154, 1951, 428, 51800], "temperature": 0.0, "avg_logprob": -0.1335355622427804, "compression_ratio": 1.872053872053872, "no_speech_prob": 0.0008556593675166368}, {"id": 464, "seek": 276760, "start": 2767.8399999999997, "end": 2774.7999999999997, "text": " module, and you're doing the whole module at a time, vastly, vastly improves it. Then you have", "tokens": [50376, 10088, 11, 293, 291, 434, 884, 264, 1379, 10088, 412, 257, 565, 11, 41426, 11, 41426, 24771, 309, 13, 1396, 291, 362, 50724], "temperature": 0.0, "avg_logprob": -0.09552435702588184, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.0009997785091400146}, {"id": 465, "seek": 276760, "start": 2774.7999999999997, "end": 2778.4, "text": " the language that you want to work within, which is a normal programming language.", "tokens": [50724, 264, 2856, 300, 291, 528, 281, 589, 1951, 11, 597, 307, 257, 2710, 9410, 2856, 13, 50904], "temperature": 0.0, "avg_logprob": -0.09552435702588184, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.0009997785091400146}, {"id": 466, "seek": 276760, "start": 2779.2, "end": 2782.7999999999997, "text": " And then on top of that, we have built a permissions model that allows you to", "tokens": [50944, 400, 550, 322, 1192, 295, 300, 11, 321, 362, 3094, 257, 32723, 2316, 300, 4045, 291, 281, 51124], "temperature": 0.0, "avg_logprob": -0.09552435702588184, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.0009997785091400146}, {"id": 467, "seek": 276760, "start": 2784.0, "end": 2790.7999999999997, "text": " have complex logic, which is easy to understand by the developer, if that makes sense.", "tokens": [51184, 362, 3997, 9952, 11, 597, 307, 1858, 281, 1223, 538, 264, 10754, 11, 498, 300, 1669, 2020, 13, 51524], "temperature": 0.0, "avg_logprob": -0.09552435702588184, "compression_ratio": 1.5981308411214954, "no_speech_prob": 0.0009997785091400146}, {"id": 468, "seek": 279080, "start": 2791.44, "end": 2798.48, "text": " Let's go through the permissions thing. For instance, if I've got access to subscribing", "tokens": [50396, 961, 311, 352, 807, 264, 32723, 551, 13, 1171, 5197, 11, 498, 286, 600, 658, 2105, 281, 19981, 50748], "temperature": 0.0, "avg_logprob": -0.16247276826338333, "compression_ratio": 1.5225225225225225, "no_speech_prob": 0.036716949194669724}, {"id": 469, "seek": 279080, "start": 2798.48, "end": 2804.88, "text": " to data from the server, I wouldn't. Hypothetical black hat me would very much like to use it to", "tokens": [50748, 281, 1412, 490, 264, 7154, 11, 286, 2759, 380, 13, 45649, 900, 27800, 2211, 2385, 385, 576, 588, 709, 411, 281, 764, 309, 281, 51068], "temperature": 0.0, "avg_logprob": -0.16247276826338333, "compression_ratio": 1.5225225225225225, "no_speech_prob": 0.036716949194669724}, {"id": 470, "seek": 279080, "start": 2804.88, "end": 2808.7200000000003, "text": " cheat on the game. By subscribing to other people's data.", "tokens": [51068, 17470, 322, 264, 1216, 13, 3146, 19981, 281, 661, 561, 311, 1412, 13, 51260], "temperature": 0.0, "avg_logprob": -0.16247276826338333, "compression_ratio": 1.5225225225225225, "no_speech_prob": 0.036716949194669724}, {"id": 471, "seek": 279080, "start": 2808.7200000000003, "end": 2816.7200000000003, "text": " Okay. So first thing I'll note, all games of the first type that I described, where they have a", "tokens": [51260, 1033, 13, 407, 700, 551, 286, 603, 3637, 11, 439, 2813, 295, 264, 700, 2010, 300, 286, 7619, 11, 689, 436, 362, 257, 51660], "temperature": 0.0, "avg_logprob": -0.16247276826338333, "compression_ratio": 1.5225225225225225, "no_speech_prob": 0.036716949194669724}, {"id": 472, "seek": 281672, "start": 2816.72, "end": 2822.0, "text": " deterministic client and they're replicating inputs, must know about all data in those games.", "tokens": [50364, 15957, 3142, 6423, 293, 436, 434, 3248, 30541, 15743, 11, 1633, 458, 466, 439, 1412, 294, 729, 2813, 13, 50628], "temperature": 0.0, "avg_logprob": -0.11089694310748388, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.010983608663082123}, {"id": 473, "seek": 281672, "start": 2822.0, "end": 2827.52, "text": " So League of Legends, you can cheat. In fact, they're doing like a kernel extension to prevent", "tokens": [50628, 407, 11199, 295, 28103, 11, 291, 393, 17470, 13, 682, 1186, 11, 436, 434, 884, 411, 257, 28256, 10320, 281, 4871, 50904], "temperature": 0.0, "avg_logprob": -0.11089694310748388, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.010983608663082123}, {"id": 474, "seek": 281672, "start": 2827.52, "end": 2836.0, "text": " people from cheating. But beside the point, they require you to see all data. So if you see Fog", "tokens": [50904, 561, 490, 18309, 13, 583, 15726, 264, 935, 11, 436, 3651, 291, 281, 536, 439, 1412, 13, 407, 498, 291, 536, 479, 664, 51328], "temperature": 0.0, "avg_logprob": -0.11089694310748388, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.010983608663082123}, {"id": 475, "seek": 281672, "start": 2836.0, "end": 2841.3599999999997, "text": " of War in an RTS, you could get data, everything under that Fog of War is there. You could remove", "tokens": [51328, 295, 3630, 294, 364, 497, 7327, 11, 291, 727, 483, 1412, 11, 1203, 833, 300, 479, 664, 295, 3630, 307, 456, 13, 509, 727, 4159, 51596], "temperature": 0.0, "avg_logprob": -0.11089694310748388, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.010983608663082123}, {"id": 476, "seek": 281672, "start": 2841.3599999999997, "end": 2845.7599999999998, "text": " the Fog of War on your client and see all of the units. So sad times. So first of all, they're", "tokens": [51596, 264, 479, 664, 295, 3630, 322, 428, 6423, 293, 536, 439, 295, 264, 6815, 13, 407, 4227, 1413, 13, 407, 700, 295, 439, 11, 436, 434, 51816], "temperature": 0.0, "avg_logprob": -0.11089694310748388, "compression_ratio": 1.7345454545454546, "no_speech_prob": 0.010983608663082123}, {"id": 477, "seek": 284576, "start": 2845.76, "end": 2851.44, "text": " just right out. They don't provide that to you at all. In our case, what you can do is", "tokens": [50364, 445, 558, 484, 13, 814, 500, 380, 2893, 300, 281, 291, 412, 439, 13, 682, 527, 1389, 11, 437, 291, 393, 360, 307, 50648], "temperature": 0.0, "avg_logprob": -0.09702645755204999, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.0010004155337810516}, {"id": 478, "seek": 284576, "start": 2852.5600000000004, "end": 2856.0800000000004, "text": " there's two types of permissions. There's sort of write permissions and then there's read permissions.", "tokens": [50704, 456, 311, 732, 3467, 295, 32723, 13, 821, 311, 1333, 295, 2464, 32723, 293, 550, 456, 311, 1401, 32723, 13, 50880], "temperature": 0.0, "avg_logprob": -0.09702645755204999, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.0010004155337810516}, {"id": 479, "seek": 284576, "start": 2856.0800000000004, "end": 2862.0800000000004, "text": " So if you want to update the database, clients are only allowed to update the database through", "tokens": [50880, 407, 498, 291, 528, 281, 5623, 264, 8149, 11, 6982, 366, 787, 4350, 281, 5623, 264, 8149, 807, 51180], "temperature": 0.0, "avg_logprob": -0.09702645755204999, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.0010004155337810516}, {"id": 480, "seek": 284576, "start": 2862.0800000000004, "end": 2866.32, "text": " the module. And so what that will be is like, let's say I wanted to move a player, but I try to", "tokens": [51180, 264, 10088, 13, 400, 370, 437, 300, 486, 312, 307, 411, 11, 718, 311, 584, 286, 1415, 281, 1286, 257, 4256, 11, 457, 286, 853, 281, 51392], "temperature": 0.0, "avg_logprob": -0.09702645755204999, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.0010004155337810516}, {"id": 481, "seek": 284576, "start": 2868.1600000000003, "end": 2872.5600000000004, "text": " move a player in a way that's illegal. Like I'm trying to go into this level, this place where", "tokens": [51484, 1286, 257, 4256, 294, 257, 636, 300, 311, 11905, 13, 1743, 286, 478, 1382, 281, 352, 666, 341, 1496, 11, 341, 1081, 689, 51704], "temperature": 0.0, "avg_logprob": -0.09702645755204999, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.0010004155337810516}, {"id": 482, "seek": 287256, "start": 2872.56, "end": 2879.7599999999998, "text": " I need to be level 56 and I'm only level 50. What the server will do is it will check the", "tokens": [50364, 286, 643, 281, 312, 1496, 19687, 293, 286, 478, 787, 1496, 2625, 13, 708, 264, 7154, 486, 360, 307, 309, 486, 1520, 264, 50724], "temperature": 0.0, "avg_logprob": -0.09756115700701158, "compression_ratio": 1.6964856230031948, "no_speech_prob": 0.0003682816750369966}, {"id": 483, "seek": 287256, "start": 2879.7599999999998, "end": 2883.2799999999997, "text": " level of the player because you're just writing the logic and you'll just fail the transaction.", "tokens": [50724, 1496, 295, 264, 4256, 570, 291, 434, 445, 3579, 264, 9952, 293, 291, 603, 445, 3061, 264, 14425, 13, 50900], "temperature": 0.0, "avg_logprob": -0.09756115700701158, "compression_ratio": 1.6964856230031948, "no_speech_prob": 0.0003682816750369966}, {"id": 484, "seek": 287256, "start": 2883.2799999999997, "end": 2886.72, "text": " So you'll just say, no, you can't do that. We roll everything back and we throw it away.", "tokens": [50900, 407, 291, 603, 445, 584, 11, 572, 11, 291, 393, 380, 360, 300, 13, 492, 3373, 1203, 646, 293, 321, 3507, 309, 1314, 13, 51072], "temperature": 0.0, "avg_logprob": -0.09756115700701158, "compression_ratio": 1.6964856230031948, "no_speech_prob": 0.0003682816750369966}, {"id": 485, "seek": 287256, "start": 2887.52, "end": 2892.24, "text": " All right, so that's the first thing. The way that works is each client has an identifier,", "tokens": [51112, 1057, 558, 11, 370, 300, 311, 264, 700, 551, 13, 440, 636, 300, 1985, 307, 1184, 6423, 575, 364, 45690, 11, 51348], "temperature": 0.0, "avg_logprob": -0.09756115700701158, "compression_ratio": 1.6964856230031948, "no_speech_prob": 0.0003682816750369966}, {"id": 486, "seek": 287256, "start": 2892.24, "end": 2896.48, "text": " which is called the identity, makes sense. It's kind of like an Ethereum address,", "tokens": [51348, 597, 307, 1219, 264, 6575, 11, 1669, 2020, 13, 467, 311, 733, 295, 411, 364, 26894, 2985, 11, 51560], "temperature": 0.0, "avg_logprob": -0.09756115700701158, "compression_ratio": 1.6964856230031948, "no_speech_prob": 0.0003682816750369966}, {"id": 487, "seek": 287256, "start": 2896.48, "end": 2899.6, "text": " if you want to liken it to something in that regard, you can see who the person is.", "tokens": [51560, 498, 291, 528, 281, 36946, 309, 281, 746, 294, 300, 3843, 11, 291, 393, 536, 567, 264, 954, 307, 13, 51716], "temperature": 0.0, "avg_logprob": -0.09756115700701158, "compression_ratio": 1.6964856230031948, "no_speech_prob": 0.0003682816750369966}, {"id": 488, "seek": 289960, "start": 2900.56, "end": 2906.72, "text": " And then you can say, you do all the procedural checks you want in the whole world.", "tokens": [50412, 400, 550, 291, 393, 584, 11, 291, 360, 439, 264, 43951, 13834, 291, 528, 294, 264, 1379, 1002, 13, 50720], "temperature": 0.0, "avg_logprob": -0.10574850261720836, "compression_ratio": 1.6741573033707866, "no_speech_prob": 0.0006878139683976769}, {"id": 489, "seek": 289960, "start": 2907.2799999999997, "end": 2911.92, "text": " Is this player friends with that or do they know each other, whatever it is,", "tokens": [50748, 1119, 341, 4256, 1855, 365, 300, 420, 360, 436, 458, 1184, 661, 11, 2035, 309, 307, 11, 50980], "temperature": 0.0, "avg_logprob": -0.10574850261720836, "compression_ratio": 1.6741573033707866, "no_speech_prob": 0.0006878139683976769}, {"id": 490, "seek": 289960, "start": 2911.92, "end": 2916.56, "text": " and then fail the transaction if it's not allowed? So that's the right. So right is super simple,", "tokens": [50980, 293, 550, 3061, 264, 14425, 498, 309, 311, 406, 4350, 30, 407, 300, 311, 264, 558, 13, 407, 558, 307, 1687, 2199, 11, 51212], "temperature": 0.0, "avg_logprob": -0.10574850261720836, "compression_ratio": 1.6741573033707866, "no_speech_prob": 0.0006878139683976769}, {"id": 491, "seek": 289960, "start": 2916.56, "end": 2922.7999999999997, "text": " very, very easy to do. From a read perspective, there's a couple layers that you can do. So first", "tokens": [51212, 588, 11, 588, 1858, 281, 360, 13, 3358, 257, 1401, 4585, 11, 456, 311, 257, 1916, 7914, 300, 291, 393, 360, 13, 407, 700, 51524], "temperature": 0.0, "avg_logprob": -0.10574850261720836, "compression_ratio": 1.6741573033707866, "no_speech_prob": 0.0006878139683976769}, {"id": 492, "seek": 289960, "start": 2922.7999999999997, "end": 2928.64, "text": " of all, what we implement today is private tables. So that's just, hey, this table is only", "tokens": [51524, 295, 439, 11, 437, 321, 4445, 965, 307, 4551, 8020, 13, 407, 300, 311, 445, 11, 4177, 11, 341, 3199, 307, 787, 51816], "temperature": 0.0, "avg_logprob": -0.10574850261720836, "compression_ratio": 1.6741573033707866, "no_speech_prob": 0.0006878139683976769}, {"id": 493, "seek": 292864, "start": 2928.64, "end": 2933.2799999999997, "text": " viewable by the owner of the module. So based with the database creator.", "tokens": [50364, 1910, 712, 538, 264, 7289, 295, 264, 10088, 13, 407, 2361, 365, 264, 8149, 14181, 13, 50596], "temperature": 0.0, "avg_logprob": -0.10221396422967678, "compression_ratio": 1.6287128712871286, "no_speech_prob": 0.0005526876775547862}, {"id": 494, "seek": 292864, "start": 2935.6, "end": 2941.2799999999997, "text": " And we would like to add, so we have not yet added because it's not yet 1.0,", "tokens": [50712, 400, 321, 576, 411, 281, 909, 11, 370, 321, 362, 406, 1939, 3869, 570, 309, 311, 406, 1939, 502, 13, 15, 11, 50996], "temperature": 0.0, "avg_logprob": -0.10221396422967678, "compression_ratio": 1.6287128712871286, "no_speech_prob": 0.0005526876775547862}, {"id": 495, "seek": 292864, "start": 2942.48, "end": 2949.04, "text": " both column permissions and then column read permissions and then row level security. So", "tokens": [51056, 1293, 7738, 32723, 293, 550, 7738, 1401, 32723, 293, 550, 5386, 1496, 3825, 13, 407, 51384], "temperature": 0.0, "avg_logprob": -0.10221396422967678, "compression_ratio": 1.6287128712871286, "no_speech_prob": 0.0005526876775547862}, {"id": 496, "seek": 292864, "start": 2949.04, "end": 2955.7599999999998, "text": " what that means is you should be able to write a function inside of your module that says,", "tokens": [51384, 437, 300, 1355, 307, 291, 820, 312, 1075, 281, 2464, 257, 2445, 1854, 295, 428, 10088, 300, 1619, 11, 51720], "temperature": 0.0, "avg_logprob": -0.10221396422967678, "compression_ratio": 1.6287128712871286, "no_speech_prob": 0.0005526876775547862}, {"id": 497, "seek": 295576, "start": 2956.1600000000003, "end": 2961.28, "text": " well, in the case of column, you're just going to annotate columns as being private, right?", "tokens": [50384, 731, 11, 294, 264, 1389, 295, 7738, 11, 291, 434, 445, 516, 281, 25339, 473, 13766, 382, 885, 4551, 11, 558, 30, 50640], "temperature": 0.0, "avg_logprob": -0.12629861667238432, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.0015010489150881767}, {"id": 498, "seek": 295576, "start": 2961.28, "end": 2967.5200000000004, "text": " And that's that's pretty sure for for row level security. That means like, can this person see", "tokens": [50640, 400, 300, 311, 300, 311, 1238, 988, 337, 337, 5386, 1496, 3825, 13, 663, 1355, 411, 11, 393, 341, 954, 536, 50952], "temperature": 0.0, "avg_logprob": -0.12629861667238432, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.0015010489150881767}, {"id": 499, "seek": 295576, "start": 2967.5200000000004, "end": 2971.6000000000004, "text": " this row? So if they subscribe to these players, maybe this player is invisible, and I shouldn't", "tokens": [50952, 341, 5386, 30, 407, 498, 436, 3022, 281, 613, 4150, 11, 1310, 341, 4256, 307, 14603, 11, 293, 286, 4659, 380, 51156], "temperature": 0.0, "avg_logprob": -0.12629861667238432, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.0015010489150881767}, {"id": 500, "seek": 295576, "start": 2971.6000000000004, "end": 2975.92, "text": " be able to see them right now. Right. So you want to be able to write a filter function", "tokens": [51156, 312, 1075, 281, 536, 552, 558, 586, 13, 1779, 13, 407, 291, 528, 281, 312, 1075, 281, 2464, 257, 6608, 2445, 51372], "temperature": 0.0, "avg_logprob": -0.12629861667238432, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.0015010489150881767}, {"id": 501, "seek": 295576, "start": 2976.88, "end": 2981.5200000000004, "text": " on a table. So a filter function that applies to a table that allows you to do arbitrary", "tokens": [51420, 322, 257, 3199, 13, 407, 257, 6608, 2445, 300, 13165, 281, 257, 3199, 300, 4045, 291, 281, 360, 23211, 51652], "temperature": 0.0, "avg_logprob": -0.12629861667238432, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.0015010489150881767}, {"id": 502, "seek": 298152, "start": 2981.52, "end": 2988.0, "text": " procedural logic that basically says whether or not this player should be or this row in this table", "tokens": [50364, 43951, 9952, 300, 1936, 1619, 1968, 420, 406, 341, 4256, 820, 312, 420, 341, 5386, 294, 341, 3199, 50688], "temperature": 0.0, "avg_logprob": -0.12180923396705562, "compression_ratio": 1.8262548262548262, "no_speech_prob": 0.005384186282753944}, {"id": 503, "seek": 298152, "start": 2988.0, "end": 2997.04, "text": " should be visible to this subscriber. So if I had like a hypothetical card game of some kind,", "tokens": [50688, 820, 312, 8974, 281, 341, 26122, 13, 407, 498, 286, 632, 411, 257, 33053, 2920, 1216, 295, 512, 733, 11, 51140], "temperature": 0.0, "avg_logprob": -0.12180923396705562, "compression_ratio": 1.8262548262548262, "no_speech_prob": 0.005384186282753944}, {"id": 504, "seek": 298152, "start": 2997.04, "end": 3002.64, "text": " where I have cards that only I can see, cards that all my teammates can see, and cards that", "tokens": [51140, 689, 286, 362, 5632, 300, 787, 286, 393, 536, 11, 5632, 300, 439, 452, 20461, 393, 536, 11, 293, 5632, 300, 51420], "temperature": 0.0, "avg_logprob": -0.12180923396705562, "compression_ratio": 1.8262548262548262, "no_speech_prob": 0.005384186282753944}, {"id": 505, "seek": 298152, "start": 3002.64, "end": 3007.52, "text": " the opponent can also see, would I be able to model that? You certainly would. So you'd be able,", "tokens": [51420, 264, 10620, 393, 611, 536, 11, 576, 286, 312, 1075, 281, 2316, 300, 30, 509, 3297, 576, 13, 407, 291, 1116, 312, 1075, 11, 51664], "temperature": 0.0, "avg_logprob": -0.12180923396705562, "compression_ratio": 1.8262548262548262, "no_speech_prob": 0.005384186282753944}, {"id": 506, "seek": 298152, "start": 3007.52, "end": 3011.04, "text": " what you'd do is you'd say, let's say you just have one table called cards and you'd write", "tokens": [51664, 437, 291, 1116, 360, 307, 291, 1116, 584, 11, 718, 311, 584, 291, 445, 362, 472, 3199, 1219, 5632, 293, 291, 1116, 2464, 51840], "temperature": 0.0, "avg_logprob": -0.12180923396705562, "compression_ratio": 1.8262548262548262, "no_speech_prob": 0.005384186282753944}, {"id": 507, "seek": 301152, "start": 3012.08, "end": 3017.2, "text": " a function that says, this is the subscriber, which is like this is the identity of the subscriber.", "tokens": [50392, 257, 2445, 300, 1619, 11, 341, 307, 264, 26122, 11, 597, 307, 411, 341, 307, 264, 6575, 295, 264, 26122, 13, 50648], "temperature": 0.0, "avg_logprob": -0.10542591347182093, "compression_ratio": 1.9205020920502092, "no_speech_prob": 0.0006666341214440763}, {"id": 508, "seek": 301152, "start": 3018.24, "end": 3022.0, "text": " Do you want to show this row or these batch of rows or however we end up", "tokens": [50700, 1144, 291, 528, 281, 855, 341, 5386, 420, 613, 15245, 295, 13241, 420, 4461, 321, 917, 493, 50888], "temperature": 0.0, "avg_logprob": -0.10542591347182093, "compression_ratio": 1.9205020920502092, "no_speech_prob": 0.0006666341214440763}, {"id": 509, "seek": 301152, "start": 3022.0, "end": 3027.12, "text": " ultimately implementing it for performance reasons? And you would look through the row and you would", "tokens": [50888, 6284, 18114, 309, 337, 3389, 4112, 30, 400, 291, 576, 574, 807, 264, 5386, 293, 291, 576, 51144], "temperature": 0.0, "avg_logprob": -0.10542591347182093, "compression_ratio": 1.9205020920502092, "no_speech_prob": 0.0006666341214440763}, {"id": 510, "seek": 301152, "start": 3027.12, "end": 3033.04, "text": " say, ah, is this who is the owner of this card? I am the owner of this card. I can see it. Oh,", "tokens": [51144, 584, 11, 3716, 11, 307, 341, 567, 307, 264, 7289, 295, 341, 2920, 30, 286, 669, 264, 7289, 295, 341, 2920, 13, 286, 393, 536, 309, 13, 876, 11, 51440], "temperature": 0.0, "avg_logprob": -0.10542591347182093, "compression_ratio": 1.9205020920502092, "no_speech_prob": 0.0006666341214440763}, {"id": 511, "seek": 301152, "start": 3033.04, "end": 3037.52, "text": " I'm not the owner of this card. Is the owner of this card my teammate? Okay, I can see it.", "tokens": [51440, 286, 478, 406, 264, 7289, 295, 341, 2920, 13, 1119, 264, 7289, 295, 341, 2920, 452, 25467, 30, 1033, 11, 286, 393, 536, 309, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10542591347182093, "compression_ratio": 1.9205020920502092, "no_speech_prob": 0.0006666341214440763}, {"id": 512, "seek": 303752, "start": 3038.24, "end": 3041.92, "text": " I am, you know, and so forth and whatever conflicts logic you want.", "tokens": [50400, 286, 669, 11, 291, 458, 11, 293, 370, 5220, 293, 2035, 19807, 9952, 291, 528, 13, 50584], "temperature": 0.0, "avg_logprob": -0.21445547365674786, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.011325487866997719}, {"id": 513, "seek": 303752, "start": 3041.92, "end": 3045.2, "text": " Okay. And I'm writing those functions in the same language?", "tokens": [50584, 1033, 13, 400, 286, 478, 3579, 729, 6828, 294, 264, 912, 2856, 30, 50748], "temperature": 0.0, "avg_logprob": -0.21445547365674786, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.011325487866997719}, {"id": 514, "seek": 303752, "start": 3045.2, "end": 3051.28, "text": " In, yes, in Rust or whatever language. Okay. So the language to define security roles is", "tokens": [50748, 682, 11, 2086, 11, 294, 34952, 420, 2035, 2856, 13, 1033, 13, 407, 264, 2856, 281, 6964, 3825, 9604, 307, 51052], "temperature": 0.0, "avg_logprob": -0.21445547365674786, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.011325487866997719}, {"id": 515, "seek": 303752, "start": 3051.28, "end": 3055.36, "text": " the general purpose language. The general purpose language. And it's a procedural language,", "tokens": [51052, 264, 2674, 4334, 2856, 13, 440, 2674, 4334, 2856, 13, 400, 309, 311, 257, 43951, 2856, 11, 51256], "temperature": 0.0, "avg_logprob": -0.21445547365674786, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.011325487866997719}, {"id": 516, "seek": 303752, "start": 3056.32, "end": 3062.56, "text": " not going very fancy. Obviously, you can do what, for example, SuperBase does, which is they have", "tokens": [51304, 406, 516, 588, 10247, 13, 7580, 11, 291, 393, 360, 437, 11, 337, 1365, 11, 4548, 33, 651, 775, 11, 597, 307, 436, 362, 51616], "temperature": 0.0, "avg_logprob": -0.21445547365674786, "compression_ratio": 1.698744769874477, "no_speech_prob": 0.011325487866997719}, {"id": 517, "seek": 306256, "start": 3062.56, "end": 3069.44, "text": " you write those row level security rules in SQL. So we may also support that. I'm not sure right", "tokens": [50364, 291, 2464, 729, 5386, 1496, 3825, 4474, 294, 19200, 13, 407, 321, 815, 611, 1406, 300, 13, 286, 478, 406, 988, 558, 50708], "temperature": 0.0, "avg_logprob": -0.10755422982302579, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.003375719301402569}, {"id": 518, "seek": 306256, "start": 3069.44, "end": 3076.16, "text": " now, but boy, it is a lot easier to write Rust than some arcane SQL query about row level security.", "tokens": [50708, 586, 11, 457, 3237, 11, 309, 307, 257, 688, 3571, 281, 2464, 34952, 813, 512, 10346, 1929, 19200, 14581, 466, 5386, 1496, 3825, 13, 51044], "temperature": 0.0, "avg_logprob": -0.10755422982302579, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.003375719301402569}, {"id": 519, "seek": 306256, "start": 3076.16, "end": 3080.72, "text": " I'll tell you that. Okay. Right. Where does that leave us? So", "tokens": [51044, 286, 603, 980, 291, 300, 13, 1033, 13, 1779, 13, 2305, 775, 300, 1856, 505, 30, 407, 51272], "temperature": 0.0, "avg_logprob": -0.10755422982302579, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.003375719301402569}, {"id": 520, "seek": 306256, "start": 3084.0, "end": 3089.12, "text": " is my experience programming the server side similar to my experience program in the client", "tokens": [51436, 307, 452, 1752, 9410, 264, 7154, 1252, 2531, 281, 452, 1752, 1461, 294, 264, 6423, 51692], "temperature": 0.0, "avg_logprob": -0.10755422982302579, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.003375719301402569}, {"id": 521, "seek": 308912, "start": 3089.2, "end": 3091.92, "text": " side? Okay, this is a fantastic question.", "tokens": [50368, 1252, 30, 1033, 11, 341, 307, 257, 5456, 1168, 13, 50504], "temperature": 0.0, "avg_logprob": -0.14804879550276132, "compression_ratio": 1.545, "no_speech_prob": 0.00019715832604561}, {"id": 522, "seek": 308912, "start": 3095.6, "end": 3101.52, "text": " Let me tell you where we are today. And the vision for where we want to be with SpaceMDB.", "tokens": [50688, 961, 385, 980, 291, 689, 321, 366, 965, 13, 400, 264, 5201, 337, 689, 321, 528, 281, 312, 365, 8705, 44, 27735, 13, 50984], "temperature": 0.0, "avg_logprob": -0.14804879550276132, "compression_ratio": 1.545, "no_speech_prob": 0.00019715832604561}, {"id": 523, "seek": 308912, "start": 3102.24, "end": 3108.3199999999997, "text": " So where we are today is you write your server module that runs on the server. It's written in,", "tokens": [51020, 407, 689, 321, 366, 965, 307, 291, 2464, 428, 7154, 10088, 300, 6676, 322, 264, 7154, 13, 467, 311, 3720, 294, 11, 51324], "temperature": 0.0, "avg_logprob": -0.14804879550276132, "compression_ratio": 1.545, "no_speech_prob": 0.00019715832604561}, {"id": 524, "seek": 308912, "start": 3108.3199999999997, "end": 3114.0, "text": " let's say, Rust. You write your client. We have a Rust SDK. And what that does is", "tokens": [51324, 718, 311, 584, 11, 34952, 13, 509, 2464, 428, 6423, 13, 492, 362, 257, 34952, 37135, 13, 400, 437, 300, 775, 307, 51608], "temperature": 0.0, "avg_logprob": -0.14804879550276132, "compression_ratio": 1.545, "no_speech_prob": 0.00019715832604561}, {"id": 525, "seek": 311400, "start": 3114.96, "end": 3120.32, "text": " gives you a bunch of functions that you can use like subscribe function where you can pass in", "tokens": [50412, 2709, 291, 257, 3840, 295, 6828, 300, 291, 393, 764, 411, 3022, 2445, 689, 291, 393, 1320, 294, 50680], "temperature": 0.0, "avg_logprob": -0.12939438066984477, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.002050474053248763}, {"id": 526, "seek": 311400, "start": 3120.32, "end": 3124.32, "text": " all your SQL queries, and then you can get all the data back. The Rust SDK currently stores that", "tokens": [50680, 439, 428, 19200, 24109, 11, 293, 550, 291, 393, 483, 439, 264, 1412, 646, 13, 440, 34952, 37135, 4362, 9512, 300, 50880], "temperature": 0.0, "avg_logprob": -0.12939438066984477, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.002050474053248763}, {"id": 527, "seek": 311400, "start": 3124.32, "end": 3130.16, "text": " data internally. So it has this like data, little mini database, if you will, like a little mini", "tokens": [50880, 1412, 19501, 13, 407, 309, 575, 341, 411, 1412, 11, 707, 8382, 8149, 11, 498, 291, 486, 11, 411, 257, 707, 8382, 51172], "temperature": 0.0, "avg_logprob": -0.12939438066984477, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.002050474053248763}, {"id": 528, "seek": 311400, "start": 3130.16, "end": 3135.76, "text": " memory, and you can query that data. The querying of that data is relatively rudimentary. It's based", "tokens": [51172, 4675, 11, 293, 291, 393, 14581, 300, 1412, 13, 440, 7083, 1840, 295, 300, 1412, 307, 7226, 32109, 2328, 822, 13, 467, 311, 2361, 51452], "temperature": 0.0, "avg_logprob": -0.12939438066984477, "compression_ratio": 1.7321428571428572, "no_speech_prob": 0.002050474053248763}, {"id": 529, "seek": 313576, "start": 3135.84, "end": 3144.7200000000003, "text": " on code generation that we do. So your module has a bunch of types, right? And a bunch of", "tokens": [50368, 322, 3089, 5125, 300, 321, 360, 13, 407, 428, 10088, 575, 257, 3840, 295, 3467, 11, 558, 30, 400, 257, 3840, 295, 50812], "temperature": 0.0, "avg_logprob": -0.10488956532579788, "compression_ratio": 1.8258706467661692, "no_speech_prob": 0.03731732815504074}, {"id": 530, "seek": 313576, "start": 3144.7200000000003, "end": 3150.0, "text": " schemas and all that stuff. You can take a module, and then you can extract the schema from that", "tokens": [50812, 22627, 296, 293, 439, 300, 1507, 13, 509, 393, 747, 257, 10088, 11, 293, 550, 291, 393, 8947, 264, 34078, 490, 300, 51076], "temperature": 0.0, "avg_logprob": -0.10488956532579788, "compression_ratio": 1.8258706467661692, "no_speech_prob": 0.03731732815504074}, {"id": 531, "seek": 313576, "start": 3150.0, "end": 3154.6400000000003, "text": " module, and then you can code generate whatever type of clients you want. So for example,", "tokens": [51076, 10088, 11, 293, 550, 291, 393, 3089, 8460, 2035, 2010, 295, 6982, 291, 528, 13, 407, 337, 1365, 11, 51308], "temperature": 0.0, "avg_logprob": -0.10488956532579788, "compression_ratio": 1.8258706467661692, "no_speech_prob": 0.03731732815504074}, {"id": 532, "seek": 313576, "start": 3155.84, "end": 3162.32, "text": " you can call a particular function from the client. You can get the type, so if you have a", "tokens": [51368, 291, 393, 818, 257, 1729, 2445, 490, 264, 6423, 13, 509, 393, 483, 264, 2010, 11, 370, 498, 291, 362, 257, 51692], "temperature": 0.0, "avg_logprob": -0.10488956532579788, "compression_ratio": 1.8258706467661692, "no_speech_prob": 0.03731732815504074}, {"id": 533, "seek": 316232, "start": 3162.32, "end": 3167.6000000000004, "text": " Rust module and a C sharp client, as we do, you can get that C sharp equivalent type to the Rust", "tokens": [50364, 34952, 10088, 293, 257, 383, 8199, 6423, 11, 382, 321, 360, 11, 291, 393, 483, 300, 383, 8199, 10344, 2010, 281, 264, 34952, 50628], "temperature": 0.0, "avg_logprob": -0.18104978942871094, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0028893135022372007}, {"id": 534, "seek": 316232, "start": 3167.6000000000004, "end": 3173.92, "text": " type on your client, if that makes sense. Okay. Which is important because that's another thing", "tokens": [50628, 2010, 322, 428, 6423, 11, 498, 300, 1669, 2020, 13, 1033, 13, 3013, 307, 1021, 570, 300, 311, 1071, 551, 50944], "temperature": 0.0, "avg_logprob": -0.18104978942871094, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0028893135022372007}, {"id": 535, "seek": 316232, "start": 3173.92, "end": 3179.6800000000003, "text": " with with store procedures is that like, oh, the type, like you hopefully the types work because", "tokens": [50944, 365, 365, 3531, 13846, 307, 300, 411, 11, 1954, 11, 264, 2010, 11, 411, 291, 4696, 264, 3467, 589, 570, 51232], "temperature": 0.0, "avg_logprob": -0.18104978942871094, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0028893135022372007}, {"id": 536, "seek": 316232, "start": 3179.6800000000003, "end": 3184.1600000000003, "text": " it's like dynamic, who knows, it's just crazy the way they do things. Or you have to sort of like", "tokens": [51232, 309, 311, 411, 8546, 11, 567, 3255, 11, 309, 311, 445, 3219, 264, 636, 436, 360, 721, 13, 1610, 291, 362, 281, 1333, 295, 411, 51456], "temperature": 0.0, "avg_logprob": -0.18104978942871094, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0028893135022372007}, {"id": 537, "seek": 316232, "start": 3184.1600000000003, "end": 3190.96, "text": " apply a type and you have to maintain the types. We are code generating a lot of it's like protobuf,", "tokens": [51456, 3079, 257, 2010, 293, 291, 362, 281, 6909, 264, 3467, 13, 492, 366, 3089, 17746, 257, 688, 295, 309, 311, 411, 1742, 996, 2947, 11, 51796], "temperature": 0.0, "avg_logprob": -0.18104978942871094, "compression_ratio": 1.781021897810219, "no_speech_prob": 0.0028893135022372007}, {"id": 538, "seek": 319096, "start": 3190.96, "end": 3197.12, "text": " right? So you, you have your schema, we scoop that out of your module. It's like a protobuf", "tokens": [50364, 558, 30, 407, 291, 11, 291, 362, 428, 34078, 11, 321, 19555, 300, 484, 295, 428, 10088, 13, 467, 311, 411, 257, 1742, 996, 2947, 50672], "temperature": 0.0, "avg_logprob": -0.12283657966776097, "compression_ratio": 1.58008658008658, "no_speech_prob": 0.00030530677759088576}, {"id": 539, "seek": 319096, "start": 3197.12, "end": 3201.76, "text": " representation of your schema, you can then code generate on whatever client you want,", "tokens": [50672, 10290, 295, 428, 34078, 11, 291, 393, 550, 3089, 8460, 322, 2035, 6423, 291, 528, 11, 50904], "temperature": 0.0, "avg_logprob": -0.12283657966776097, "compression_ratio": 1.58008658008658, "no_speech_prob": 0.00030530677759088576}, {"id": 540, "seek": 319096, "start": 3201.76, "end": 3205.52, "text": " whatever types you need. So TypeScript, we support for right now TypeScript, Python,", "tokens": [50904, 2035, 3467, 291, 643, 13, 407, 15576, 14237, 11, 321, 1406, 337, 558, 586, 15576, 14237, 11, 15329, 11, 51092], "temperature": 0.0, "avg_logprob": -0.12283657966776097, "compression_ratio": 1.58008658008658, "no_speech_prob": 0.00030530677759088576}, {"id": 541, "seek": 319096, "start": 3206.64, "end": 3213.52, "text": " Rust and C sharp for clients. Okay. Yeah, but when I call those functions, they're still going to the", "tokens": [51148, 34952, 293, 383, 8199, 337, 6982, 13, 1033, 13, 865, 11, 457, 562, 286, 818, 729, 6828, 11, 436, 434, 920, 516, 281, 264, 51492], "temperature": 0.0, "avg_logprob": -0.12283657966776097, "compression_ratio": 1.58008658008658, "no_speech_prob": 0.00030530677759088576}, {"id": 542, "seek": 321352, "start": 3213.52, "end": 3222.24, "text": " local space time to be client instance. Okay. So they do and then they, they get sent out to the", "tokens": [50364, 2654, 1901, 565, 281, 312, 6423, 5197, 13, 1033, 13, 407, 436, 360, 293, 550, 436, 11, 436, 483, 2279, 484, 281, 264, 50800], "temperature": 0.0, "avg_logprob": -0.16621686021486917, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.03409167006611824}, {"id": 543, "seek": 321352, "start": 3222.24, "end": 3226.96, "text": " server. We don't automatically do client side prediction right now. That is something that", "tokens": [50800, 7154, 13, 492, 500, 380, 6772, 360, 6423, 1252, 17630, 558, 586, 13, 663, 307, 746, 300, 51036], "temperature": 0.0, "avg_logprob": -0.16621686021486917, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.03409167006611824}, {"id": 544, "seek": 321352, "start": 3226.96, "end": 3234.72, "text": " for example, in bitcraft, we have to replicate the, the logic of so if you move a player, you have", "tokens": [51036, 337, 1365, 11, 294, 857, 5611, 11, 321, 362, 281, 25356, 264, 11, 264, 9952, 295, 370, 498, 291, 1286, 257, 4256, 11, 291, 362, 51424], "temperature": 0.0, "avg_logprob": -0.16621686021486917, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.03409167006611824}, {"id": 545, "seek": 321352, "start": 3234.72, "end": 3239.2, "text": " to move them fit like yourself is to rewrite the logic and C sharp and then you have to write the", "tokens": [51424, 281, 1286, 552, 3318, 411, 1803, 307, 281, 28132, 264, 9952, 293, 383, 8199, 293, 550, 291, 362, 281, 2464, 264, 51648], "temperature": 0.0, "avg_logprob": -0.16621686021486917, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.03409167006611824}, {"id": 546, "seek": 323920, "start": 3239.2, "end": 3244.96, "text": " logic in Rust. That's typically how a lot of people do this, these things and it is a huge pain.", "tokens": [50364, 9952, 294, 34952, 13, 663, 311, 5850, 577, 257, 688, 295, 561, 360, 341, 11, 613, 721, 293, 309, 307, 257, 2603, 1822, 13, 50652], "temperature": 0.0, "avg_logprob": -0.1185911091891202, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.013634690083563328}, {"id": 547, "seek": 323920, "start": 3244.96, "end": 3248.3999999999996, "text": " They duplicate the logic and they have to do this thing and it's a huge pain. Yeah.", "tokens": [50652, 814, 23976, 264, 9952, 293, 436, 362, 281, 360, 341, 551, 293, 309, 311, 257, 2603, 1822, 13, 865, 13, 50824], "temperature": 0.0, "avg_logprob": -0.1185911091891202, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.013634690083563328}, {"id": 548, "seek": 323920, "start": 3249.12, "end": 3252.24, "text": " Some more clever people, actually, I know of some that are developing", "tokens": [50860, 2188, 544, 13494, 561, 11, 767, 11, 286, 458, 295, 512, 300, 366, 6416, 51016], "temperature": 0.0, "avg_logprob": -0.1185911091891202, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.013634690083563328}, {"id": 549, "seek": 323920, "start": 3255.2799999999997, "end": 3264.24, "text": " an RTS use web assembly and they run the server both on the client and the server", "tokens": [51168, 364, 497, 7327, 764, 3670, 12103, 293, 436, 1190, 264, 7154, 1293, 322, 264, 6423, 293, 264, 7154, 51616], "temperature": 0.0, "avg_logprob": -0.1185911091891202, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.013634690083563328}, {"id": 550, "seek": 323920, "start": 3264.24, "end": 3267.2, "text": " and they do that. And so that's ultimately where we'd like to go with this. So ultimately,", "tokens": [51616, 293, 436, 360, 300, 13, 400, 370, 300, 311, 6284, 689, 321, 1116, 411, 281, 352, 365, 341, 13, 407, 6284, 11, 51764], "temperature": 0.0, "avg_logprob": -0.1185911091891202, "compression_ratio": 1.7407407407407407, "no_speech_prob": 0.013634690083563328}, {"id": 551, "seek": 326720, "start": 3267.2, "end": 3271.7599999999998, "text": " we want to run space and to be not only in the server, but also in the client and have them", "tokens": [50364, 321, 528, 281, 1190, 1901, 293, 281, 312, 406, 787, 294, 264, 7154, 11, 457, 611, 294, 264, 6423, 293, 362, 552, 50592], "temperature": 0.0, "avg_logprob": -0.11433580489385696, "compression_ratio": 1.9451476793248945, "no_speech_prob": 0.0169108547270298}, {"id": 552, "seek": 326720, "start": 3271.7599999999998, "end": 3276.3199999999997, "text": " synchronized between each other automatically based on your subscriptions. And then you have", "tokens": [50592, 19331, 1602, 1296, 1184, 661, 6772, 2361, 322, 428, 44951, 13, 400, 550, 291, 362, 50820], "temperature": 0.0, "avg_logprob": -0.11433580489385696, "compression_ratio": 1.9451476793248945, "no_speech_prob": 0.0169108547270298}, {"id": 553, "seek": 326720, "start": 3276.3199999999997, "end": 3282.0, "text": " a fully running module. So the same module is running the server is running on the client.", "tokens": [50820, 257, 4498, 2614, 10088, 13, 407, 264, 912, 10088, 307, 2614, 264, 7154, 307, 2614, 322, 264, 6423, 13, 51104], "temperature": 0.0, "avg_logprob": -0.11433580489385696, "compression_ratio": 1.9451476793248945, "no_speech_prob": 0.0169108547270298}, {"id": 554, "seek": 326720, "start": 3283.12, "end": 3289.68, "text": " And when you update, when you do a call, actually we run the actual server logic on your client,", "tokens": [51160, 400, 562, 291, 5623, 11, 562, 291, 360, 257, 818, 11, 767, 321, 1190, 264, 3539, 7154, 9952, 322, 428, 6423, 11, 51488], "temperature": 0.0, "avg_logprob": -0.11433580489385696, "compression_ratio": 1.9451476793248945, "no_speech_prob": 0.0169108547270298}, {"id": 555, "seek": 326720, "start": 3289.68, "end": 3293.6, "text": " update that and then that does the whole reconciliation. So you automatically get client", "tokens": [51488, 5623, 300, 293, 550, 300, 775, 264, 1379, 31281, 13, 407, 291, 6772, 483, 6423, 51684], "temperature": 0.0, "avg_logprob": -0.11433580489385696, "compression_ratio": 1.9451476793248945, "no_speech_prob": 0.0169108547270298}, {"id": 556, "seek": 329360, "start": 3293.6, "end": 3298.72, "text": " side prediction for free. Really, how far away do you think that is?", "tokens": [50364, 1252, 17630, 337, 1737, 13, 4083, 11, 577, 1400, 1314, 360, 291, 519, 300, 307, 30, 50620], "temperature": 0.0, "avg_logprob": -0.16638392732854476, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.009120653383433819}, {"id": 557, "seek": 329360, "start": 3299.6, "end": 3303.52, "text": " It's a good question. So in a sense, we're already doing it on the,", "tokens": [50664, 467, 311, 257, 665, 1168, 13, 407, 294, 257, 2020, 11, 321, 434, 1217, 884, 309, 322, 264, 11, 50860], "temperature": 0.0, "avg_logprob": -0.16638392732854476, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.009120653383433819}, {"id": 558, "seek": 329360, "start": 3304.3199999999997, "end": 3308.16, "text": " what we call space and to be cloud, which is our cloud office. So we have, okay, there are two", "tokens": [50900, 437, 321, 818, 1901, 293, 281, 312, 4588, 11, 597, 307, 527, 4588, 3398, 13, 407, 321, 362, 11, 1392, 11, 456, 366, 732, 51092], "temperature": 0.0, "avg_logprob": -0.16638392732854476, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.009120653383433819}, {"id": 559, "seek": 329360, "start": 3308.16, "end": 3312.3199999999997, "text": " versions of space and to be there's space and to be standalone, which is the open source version", "tokens": [51092, 9606, 295, 1901, 293, 281, 312, 456, 311, 1901, 293, 281, 312, 37454, 11, 597, 307, 264, 1269, 4009, 3037, 51300], "temperature": 0.0, "avg_logprob": -0.16638392732854476, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.009120653383433819}, {"id": 560, "seek": 329360, "start": 3312.3199999999997, "end": 3318.16, "text": " that's on GitHub. You can take a look at that, everything that'll run like a single node clustered", "tokens": [51300, 300, 311, 322, 23331, 13, 509, 393, 747, 257, 574, 412, 300, 11, 1203, 300, 603, 1190, 411, 257, 2167, 9984, 596, 38624, 51592], "temperature": 0.0, "avg_logprob": -0.16638392732854476, "compression_ratio": 1.6811023622047243, "no_speech_prob": 0.009120653383433819}, {"id": 561, "seek": 331816, "start": 3319.12, "end": 3325.6, "text": " as though it were your own personal instance of space and to be, we also have cloud, which is a", "tokens": [50412, 382, 1673, 309, 645, 428, 1065, 2973, 5197, 295, 1901, 293, 281, 312, 11, 321, 611, 362, 4588, 11, 597, 307, 257, 50736], "temperature": 0.0, "avg_logprob": -0.08254244592454699, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.0012840812560170889}, {"id": 562, "seek": 331816, "start": 3325.6, "end": 3331.12, "text": " distributed system, which will run many machines in coordinate between them all. And the way we", "tokens": [50736, 12631, 1185, 11, 597, 486, 1190, 867, 8379, 294, 15670, 1296, 552, 439, 13, 400, 264, 636, 321, 51012], "temperature": 0.0, "avg_logprob": -0.08254244592454699, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.0012840812560170889}, {"id": 563, "seek": 331816, "start": 3331.12, "end": 3334.96, "text": " replicate from one to the other is sort of the normal way in which you would replicate", "tokens": [51012, 25356, 490, 472, 281, 264, 661, 307, 1333, 295, 264, 2710, 636, 294, 597, 291, 576, 25356, 51204], "temperature": 0.0, "avg_logprob": -0.08254244592454699, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.0012840812560170889}, {"id": 564, "seek": 331816, "start": 3334.96, "end": 3339.2799999999997, "text": " a client. So they're all just clients of each other is an interesting thing. Right.", "tokens": [51204, 257, 6423, 13, 407, 436, 434, 439, 445, 6982, 295, 1184, 661, 307, 364, 1880, 551, 13, 1779, 13, 51420], "temperature": 0.0, "avg_logprob": -0.08254244592454699, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.0012840812560170889}, {"id": 565, "seek": 331816, "start": 3339.2799999999997, "end": 3342.72, "text": " And that has a lot of implications for strong consistency, but I don't think we have time to", "tokens": [51420, 400, 300, 575, 257, 688, 295, 16602, 337, 2068, 14416, 11, 457, 286, 500, 380, 519, 321, 362, 565, 281, 51592], "temperature": 0.0, "avg_logprob": -0.08254244592454699, "compression_ratio": 1.6851851851851851, "no_speech_prob": 0.0012840812560170889}, {"id": 566, "seek": 334272, "start": 3342.72, "end": 3348.64, "text": " get into that. But either way, we're working towards that, I suppose on the server. And then", "tokens": [50364, 483, 666, 300, 13, 583, 2139, 636, 11, 321, 434, 1364, 3030, 300, 11, 286, 7297, 322, 264, 7154, 13, 400, 550, 50660], "temperature": 0.0, "avg_logprob": -0.09219142263249834, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.011685334146022797}, {"id": 567, "seek": 334272, "start": 3349.9199999999996, "end": 3354.0, "text": " we will do that as soon as we can on the client. We're also building an MMORPG. So we're a little", "tokens": [50724, 321, 486, 360, 300, 382, 2321, 382, 321, 393, 322, 264, 6423, 13, 492, 434, 611, 2390, 364, 34191, 2483, 47, 38, 13, 407, 321, 434, 257, 707, 50928], "temperature": 0.0, "avg_logprob": -0.09219142263249834, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.011685334146022797}, {"id": 568, "seek": 334272, "start": 3354.0, "end": 3359.7599999999998, "text": " bit busy. So I'm not sure exactly when that'll be, but it is still useful in the way that it is right", "tokens": [50928, 857, 5856, 13, 407, 286, 478, 406, 988, 2293, 562, 300, 603, 312, 11, 457, 309, 307, 920, 4420, 294, 264, 636, 300, 309, 307, 558, 51216], "temperature": 0.0, "avg_logprob": -0.09219142263249834, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.011685334146022797}, {"id": 569, "seek": 334272, "start": 3359.7599999999998, "end": 3364.48, "text": " now that is to say, not automatically doing client side prediction. But we will, we will", "tokens": [51216, 586, 300, 307, 281, 584, 11, 406, 6772, 884, 6423, 1252, 17630, 13, 583, 321, 486, 11, 321, 486, 51452], "temperature": 0.0, "avg_logprob": -0.09219142263249834, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.011685334146022797}, {"id": 570, "seek": 334272, "start": 3364.48, "end": 3368.48, "text": " eventually do that. I envision world. So here's the secret. Here's the real secret to what space", "tokens": [51452, 4728, 360, 300, 13, 286, 24739, 1002, 13, 407, 510, 311, 264, 4054, 13, 1692, 311, 264, 957, 4054, 281, 437, 1901, 51652], "temperature": 0.0, "avg_logprob": -0.09219142263249834, "compression_ratio": 1.6890459363957597, "no_speech_prob": 0.011685334146022797}, {"id": 571, "seek": 336848, "start": 3368.56, "end": 3375.52, "text": " and to be is actually it's not really a database at all. What it really is, is a distributed", "tokens": [50368, 293, 281, 312, 307, 767, 309, 311, 406, 534, 257, 8149, 412, 439, 13, 708, 309, 534, 307, 11, 307, 257, 12631, 50716], "temperature": 0.0, "avg_logprob": -0.1632965363954243, "compression_ratio": 1.4635416666666667, "no_speech_prob": 0.006096556782722473}, {"id": 572, "seek": 336848, "start": 3375.52, "end": 3383.52, "text": " operating system in the spirit of plan nine, which has never sort of taken off. Let me explain. Okay.", "tokens": [50716, 7447, 1185, 294, 264, 3797, 295, 1393, 4949, 11, 597, 575, 1128, 1333, 295, 2726, 766, 13, 961, 385, 2903, 13, 1033, 13, 51116], "temperature": 0.0, "avg_logprob": -0.1632965363954243, "compression_ratio": 1.4635416666666667, "no_speech_prob": 0.006096556782722473}, {"id": 573, "seek": 336848, "start": 3385.04, "end": 3392.88, "text": " Briefly. So space and to be cloud, as I mentioned, runs over, let's say 100 computers,", "tokens": [51192, 39805, 356, 13, 407, 1901, 293, 281, 312, 4588, 11, 382, 286, 2835, 11, 6676, 670, 11, 718, 311, 584, 2319, 10807, 11, 51584], "temperature": 0.0, "avg_logprob": -0.1632965363954243, "compression_ratio": 1.4635416666666667, "no_speech_prob": 0.006096556782722473}, {"id": 574, "seek": 339288, "start": 3392.88, "end": 3398.32, "text": " right? So you've got this, this thing that's running from the outside, it looks like just one", "tokens": [50364, 558, 30, 407, 291, 600, 658, 341, 11, 341, 551, 300, 311, 2614, 490, 264, 2380, 11, 309, 1542, 411, 445, 472, 50636], "temperature": 0.0, "avg_logprob": -0.09691528962037274, "compression_ratio": 1.748936170212766, "no_speech_prob": 0.010011251084506512}, {"id": 575, "seek": 339288, "start": 3398.32, "end": 3403.12, "text": " instance of space time to be. So you can't really tell that it is made up of 100 computers.", "tokens": [50636, 5197, 295, 1901, 565, 281, 312, 13, 407, 291, 393, 380, 534, 980, 300, 309, 307, 1027, 493, 295, 2319, 10807, 13, 50876], "temperature": 0.0, "avg_logprob": -0.09691528962037274, "compression_ratio": 1.748936170212766, "no_speech_prob": 0.010011251084506512}, {"id": 576, "seek": 339288, "start": 3403.6800000000003, "end": 3406.6400000000003, "text": " And what you're doing is you're taking a program and you're running it", "tokens": [50904, 400, 437, 291, 434, 884, 307, 291, 434, 1940, 257, 1461, 293, 291, 434, 2614, 309, 51052], "temperature": 0.0, "avg_logprob": -0.09691528962037274, "compression_ratio": 1.748936170212766, "no_speech_prob": 0.010011251084506512}, {"id": 577, "seek": 339288, "start": 3407.6, "end": 3412.56, "text": " on that distributed computer. So it looks again, like a single", "tokens": [51100, 322, 300, 12631, 3820, 13, 407, 309, 1542, 797, 11, 411, 257, 2167, 51348], "temperature": 0.0, "avg_logprob": -0.09691528962037274, "compression_ratio": 1.748936170212766, "no_speech_prob": 0.010011251084506512}, {"id": 578, "seek": 339288, "start": 3414.32, "end": 3420.1600000000003, "text": " computer. And you're running a program on it. And we're abstracting away the hardware. Boy,", "tokens": [51436, 3820, 13, 400, 291, 434, 2614, 257, 1461, 322, 309, 13, 400, 321, 434, 12649, 278, 1314, 264, 8837, 13, 9486, 11, 51728], "temperature": 0.0, "avg_logprob": -0.09691528962037274, "compression_ratio": 1.748936170212766, "no_speech_prob": 0.010011251084506512}, {"id": 579, "seek": 342016, "start": 3420.16, "end": 3426.24, "text": " that does sound like an operating system, doesn't it? And so that is really ultimately where we'd", "tokens": [50364, 300, 775, 1626, 411, 364, 7447, 1185, 11, 1177, 380, 309, 30, 400, 370, 300, 307, 534, 6284, 689, 321, 1116, 50668], "temperature": 0.0, "avg_logprob": -0.0866232415040334, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.000503242074046284}, {"id": 580, "seek": 342016, "start": 3426.24, "end": 3434.08, "text": " like to go is a place where the cloud is not this collection of hardware and services that you", "tokens": [50668, 411, 281, 352, 307, 257, 1081, 689, 264, 4588, 307, 406, 341, 5765, 295, 8837, 293, 3328, 300, 291, 51060], "temperature": 0.0, "avg_logprob": -0.0866232415040334, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.000503242074046284}, {"id": 581, "seek": 342016, "start": 3434.08, "end": 3442.08, "text": " have to piece together in this grotesque fashion. But really, it is just a giant computer. And", "tokens": [51060, 362, 281, 2522, 1214, 294, 341, 677, 17251, 1077, 6700, 13, 583, 534, 11, 309, 307, 445, 257, 7410, 3820, 13, 400, 51460], "temperature": 0.0, "avg_logprob": -0.0866232415040334, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.000503242074046284}, {"id": 582, "seek": 342016, "start": 3442.08, "end": 3445.8399999999997, "text": " you're going to take your program and you're going to run it on that giant computer. And that's it.", "tokens": [51460, 291, 434, 516, 281, 747, 428, 1461, 293, 291, 434, 516, 281, 1190, 309, 322, 300, 7410, 3820, 13, 400, 300, 311, 309, 13, 51648], "temperature": 0.0, "avg_logprob": -0.0866232415040334, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.000503242074046284}, {"id": 583, "seek": 344584, "start": 3446.6400000000003, "end": 3450.1600000000003, "text": " This is going to be even more blurred when you've got a series of clients connecting", "tokens": [50404, 639, 307, 516, 281, 312, 754, 544, 43525, 562, 291, 600, 658, 257, 2638, 295, 6982, 11015, 50580], "temperature": 0.0, "avg_logprob": -0.11423421146893742, "compression_ratio": 1.5680933852140078, "no_speech_prob": 0.0007790591917000711}, {"id": 584, "seek": 344584, "start": 3450.1600000000003, "end": 3453.2000000000003, "text": " into that who are themselves similarly programmed.", "tokens": [50580, 666, 300, 567, 366, 2969, 14138, 31092, 13, 50732], "temperature": 0.0, "avg_logprob": -0.11423421146893742, "compression_ratio": 1.5680933852140078, "no_speech_prob": 0.0007790591917000711}, {"id": 585, "seek": 344584, "start": 3453.84, "end": 3461.2000000000003, "text": " Correct. And so what you might say is that you're building a gigantic distributed", "tokens": [50764, 12753, 13, 400, 370, 437, 291, 1062, 584, 307, 300, 291, 434, 2390, 257, 26800, 12631, 51132], "temperature": 0.0, "avg_logprob": -0.11423421146893742, "compression_ratio": 1.5680933852140078, "no_speech_prob": 0.0007790591917000711}, {"id": 586, "seek": 344584, "start": 3462.48, "end": 3469.2000000000003, "text": " operating system that the whole world runs on top of, right? You could say that if you were so bold.", "tokens": [51196, 7447, 1185, 300, 264, 1379, 1002, 6676, 322, 1192, 295, 11, 558, 30, 509, 727, 584, 300, 498, 291, 645, 370, 11928, 13, 51532], "temperature": 0.0, "avg_logprob": -0.11423421146893742, "compression_ratio": 1.5680933852140078, "no_speech_prob": 0.0007790591917000711}, {"id": 587, "seek": 344584, "start": 3469.84, "end": 3473.76, "text": " And I don't know that we are yet, but one day, perhaps we will. So the idea would be", "tokens": [51564, 400, 286, 500, 380, 458, 300, 321, 366, 1939, 11, 457, 472, 786, 11, 4317, 321, 486, 13, 407, 264, 1558, 576, 312, 51760], "temperature": 0.0, "avg_logprob": -0.11423421146893742, "compression_ratio": 1.5680933852140078, "no_speech_prob": 0.0007790591917000711}, {"id": 588, "seek": 347376, "start": 3474.5600000000004, "end": 3482.1600000000003, "text": " that you're all operating on the same protocol to speak with each other and that you can't really", "tokens": [50404, 300, 291, 434, 439, 7447, 322, 264, 912, 10336, 281, 1710, 365, 1184, 661, 293, 300, 291, 393, 380, 534, 50784], "temperature": 0.0, "avg_logprob": -0.07820134778176585, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.006900880951434374}, {"id": 589, "seek": 347376, "start": 3482.1600000000003, "end": 3487.6800000000003, "text": " even tell. I mean, there's a lot of details in this one. And to be quite honest, I haven't thought", "tokens": [50784, 754, 980, 13, 286, 914, 11, 456, 311, 257, 688, 295, 4365, 294, 341, 472, 13, 400, 281, 312, 1596, 3245, 11, 286, 2378, 380, 1194, 51060], "temperature": 0.0, "avg_logprob": -0.07820134778176585, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.006900880951434374}, {"id": 590, "seek": 347376, "start": 3487.6800000000003, "end": 3491.76, "text": " through all of it. But if everybody's speaking the same language, you have all of these modules", "tokens": [51060, 807, 439, 295, 309, 13, 583, 498, 2201, 311, 4124, 264, 912, 2856, 11, 291, 362, 439, 295, 613, 16679, 51264], "temperature": 0.0, "avg_logprob": -0.07820134778176585, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.006900880951434374}, {"id": 591, "seek": 347376, "start": 3491.76, "end": 3496.48, "text": " subscribing to each other, it's just the actor model, you know what it is. It's very similar", "tokens": [51264, 19981, 281, 1184, 661, 11, 309, 311, 445, 264, 8747, 2316, 11, 291, 458, 437, 309, 307, 13, 467, 311, 588, 2531, 51500], "temperature": 0.0, "avg_logprob": -0.07820134778176585, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.006900880951434374}, {"id": 592, "seek": 347376, "start": 3496.48, "end": 3501.6000000000004, "text": " to Erlang, right? It's got the same kind of spirit. You've got these actors, and they are", "tokens": [51500, 281, 3300, 25241, 11, 558, 30, 467, 311, 658, 264, 912, 733, 295, 3797, 13, 509, 600, 658, 613, 10037, 11, 293, 436, 366, 51756], "temperature": 0.0, "avg_logprob": -0.07820134778176585, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.006900880951434374}, {"id": 593, "seek": 350160, "start": 3501.6, "end": 3506.48, "text": " sending messages to each other, and they're listening to messages that are being sent to them,", "tokens": [50364, 7750, 7897, 281, 1184, 661, 11, 293, 436, 434, 4764, 281, 7897, 300, 366, 885, 2279, 281, 552, 11, 50608], "temperature": 0.0, "avg_logprob": -0.0871732301182217, "compression_ratio": 1.7861842105263157, "no_speech_prob": 0.0029780243057757616}, {"id": 594, "seek": 350160, "start": 3506.48, "end": 3511.8399999999997, "text": " and they're updating their state, and they're moving on. So it's very much in that spirit.", "tokens": [50608, 293, 436, 434, 25113, 641, 1785, 11, 293, 436, 434, 2684, 322, 13, 407, 309, 311, 588, 709, 294, 300, 3797, 13, 50876], "temperature": 0.0, "avg_logprob": -0.0871732301182217, "compression_ratio": 1.7861842105263157, "no_speech_prob": 0.0029780243057757616}, {"id": 595, "seek": 350160, "start": 3511.8399999999997, "end": 3516.08, "text": " Okay. Let me ask you this, and you may not like this question, but I'm going to ask it anyway.", "tokens": [50876, 1033, 13, 961, 385, 1029, 291, 341, 11, 293, 291, 815, 406, 411, 341, 1168, 11, 457, 286, 478, 516, 281, 1029, 309, 4033, 13, 51088], "temperature": 0.0, "avg_logprob": -0.0871732301182217, "compression_ratio": 1.7861842105263157, "no_speech_prob": 0.0029780243057757616}, {"id": 596, "seek": 350160, "start": 3516.72, "end": 3520.3199999999997, "text": " If someone thought this is a great idea, but I'm not waiting for you to do it,", "tokens": [51120, 759, 1580, 1194, 341, 307, 257, 869, 1558, 11, 457, 286, 478, 406, 3806, 337, 291, 281, 360, 309, 11, 51300], "temperature": 0.0, "avg_logprob": -0.0871732301182217, "compression_ratio": 1.7861842105263157, "no_speech_prob": 0.0029780243057757616}, {"id": 597, "seek": 350160, "start": 3520.3199999999997, "end": 3525.2799999999997, "text": " I'm going to build this on Erlang myself. Sure. What parts would they be missing? What", "tokens": [51300, 286, 478, 516, 281, 1322, 341, 322, 3300, 25241, 2059, 13, 4894, 13, 708, 3166, 576, 436, 312, 5361, 30, 708, 51548], "temperature": 0.0, "avg_logprob": -0.0871732301182217, "compression_ratio": 1.7861842105263157, "no_speech_prob": 0.0029780243057757616}, {"id": 598, "seek": 350160, "start": 3525.2799999999997, "end": 3529.8399999999997, "text": " parts would they find hard? Yeah, so the whole database part, right? So don't forget about that.", "tokens": [51548, 3166, 576, 436, 915, 1152, 30, 865, 11, 370, 264, 1379, 8149, 644, 11, 558, 30, 407, 500, 380, 2870, 466, 300, 13, 51776], "temperature": 0.0, "avg_logprob": -0.0871732301182217, "compression_ratio": 1.7861842105263157, "no_speech_prob": 0.0029780243057757616}, {"id": 599, "seek": 352984, "start": 3529.92, "end": 3535.52, "text": " So I've thought about this in a sense. So let's say you want to build this on Erlang. Cool.", "tokens": [50368, 407, 286, 600, 1194, 466, 341, 294, 257, 2020, 13, 407, 718, 311, 584, 291, 528, 281, 1322, 341, 322, 3300, 25241, 13, 8561, 13, 50648], "temperature": 0.0, "avg_logprob": -0.10653402309606572, "compression_ratio": 1.645021645021645, "no_speech_prob": 0.00043049268424510956}, {"id": 600, "seek": 352984, "start": 3536.2400000000002, "end": 3540.08, "text": " What is Erlang missing? Well, it's missing the persistence. I know they have persistent actors,", "tokens": [50684, 708, 307, 3300, 25241, 5361, 30, 1042, 11, 309, 311, 5361, 264, 37617, 13, 286, 458, 436, 362, 24315, 10037, 11, 50876], "temperature": 0.0, "avg_logprob": -0.10653402309606572, "compression_ratio": 1.645021645021645, "no_speech_prob": 0.00043049268424510956}, {"id": 601, "seek": 352984, "start": 3541.36, "end": 3549.44, "text": " but the performance of that is key. The size of each actor is key. So within a space on DB actor,", "tokens": [50940, 457, 264, 3389, 295, 300, 307, 2141, 13, 440, 2744, 295, 1184, 8747, 307, 2141, 13, 407, 1951, 257, 1901, 322, 26754, 8747, 11, 51344], "temperature": 0.0, "avg_logprob": -0.10653402309606572, "compression_ratio": 1.645021645021645, "no_speech_prob": 0.00043049268424510956}, {"id": 602, "seek": 352984, "start": 3549.44, "end": 3556.6400000000003, "text": " if you think about them as actors, we also do multi-version concurrency control so that we can", "tokens": [51344, 498, 291, 519, 466, 552, 382, 10037, 11, 321, 611, 360, 4825, 12, 29153, 23702, 10457, 1969, 370, 300, 321, 393, 51704], "temperature": 0.0, "avg_logprob": -0.10653402309606572, "compression_ratio": 1.645021645021645, "no_speech_prob": 0.00043049268424510956}, {"id": 603, "seek": 355664, "start": 3556.64, "end": 3562.3199999999997, "text": " run as many transactions as possible within one machine as sort of one actor as you might", "tokens": [50364, 1190, 382, 867, 16856, 382, 1944, 1951, 472, 3479, 382, 1333, 295, 472, 8747, 382, 291, 1062, 50648], "temperature": 0.0, "avg_logprob": -0.10909310761872712, "compression_ratio": 1.78544061302682, "no_speech_prob": 0.003272355068475008}, {"id": 604, "seek": 355664, "start": 3562.3199999999997, "end": 3568.3199999999997, "text": " possibly be able to do. So you want each actor to be as large as possible before you start going", "tokens": [50648, 6264, 312, 1075, 281, 360, 13, 407, 291, 528, 1184, 8747, 281, 312, 382, 2416, 382, 1944, 949, 291, 722, 516, 50948], "temperature": 0.0, "avg_logprob": -0.10909310761872712, "compression_ratio": 1.78544061302682, "no_speech_prob": 0.003272355068475008}, {"id": 605, "seek": 355664, "start": 3568.3199999999997, "end": 3571.3599999999997, "text": " into other actors because as soon as you go into distributed systems, it's complicated,", "tokens": [50948, 666, 661, 10037, 570, 382, 2321, 382, 291, 352, 666, 12631, 3652, 11, 309, 311, 6179, 11, 51100], "temperature": 0.0, "avg_logprob": -0.10909310761872712, "compression_ratio": 1.78544061302682, "no_speech_prob": 0.003272355068475008}, {"id": 606, "seek": 355664, "start": 3572.08, "end": 3578.3199999999997, "text": " and you can do a lot with a single machine, it turns out. Although each actor could in principle", "tokens": [51136, 293, 291, 393, 360, 257, 688, 365, 257, 2167, 3479, 11, 309, 4523, 484, 13, 5780, 1184, 8747, 727, 294, 8665, 51448], "temperature": 0.0, "avg_logprob": -0.10909310761872712, "compression_ratio": 1.78544061302682, "no_speech_prob": 0.003272355068475008}, {"id": 607, "seek": 355664, "start": 3578.3199999999997, "end": 3582.48, "text": " be more than one machine, but I digress. That's another direction to go in down in the future.", "tokens": [51448, 312, 544, 813, 472, 3479, 11, 457, 286, 2528, 735, 13, 663, 311, 1071, 3513, 281, 352, 294, 760, 294, 264, 2027, 13, 51656], "temperature": 0.0, "avg_logprob": -0.10909310761872712, "compression_ratio": 1.78544061302682, "no_speech_prob": 0.003272355068475008}, {"id": 608, "seek": 358248, "start": 3583.36, "end": 3589.12, "text": " And then there's the whole relational model. So you need to build on top of Erlang the ability", "tokens": [50408, 400, 550, 456, 311, 264, 1379, 38444, 2316, 13, 407, 291, 643, 281, 1322, 322, 1192, 295, 3300, 25241, 264, 3485, 50696], "temperature": 0.0, "avg_logprob": -0.11969863418984202, "compression_ratio": 1.5859649122807018, "no_speech_prob": 0.0015977371949702501}, {"id": 609, "seek": 358248, "start": 3589.12, "end": 3594.4, "text": " to do queries on the rows and get the actual row data out, all of the type system stuff.", "tokens": [50696, 281, 360, 24109, 322, 264, 13241, 293, 483, 264, 3539, 5386, 1412, 484, 11, 439, 295, 264, 2010, 1185, 1507, 13, 50960], "temperature": 0.0, "avg_logprob": -0.11969863418984202, "compression_ratio": 1.5859649122807018, "no_speech_prob": 0.0015977371949702501}, {"id": 610, "seek": 358248, "start": 3594.4, "end": 3598.96, "text": " You'd want to be able to run in whatever language you would like to because maybe", "tokens": [50960, 509, 1116, 528, 281, 312, 1075, 281, 1190, 294, 2035, 2856, 291, 576, 411, 281, 570, 1310, 51188], "temperature": 0.0, "avg_logprob": -0.11969863418984202, "compression_ratio": 1.5859649122807018, "no_speech_prob": 0.0015977371949702501}, {"id": 611, "seek": 358248, "start": 3600.0, "end": 3603.36, "text": " your programmers are familiar with C-Sharp because they're Unity developers and all that.", "tokens": [51240, 428, 41504, 366, 4963, 365, 383, 12, 50, 5854, 79, 570, 436, 434, 27913, 8849, 293, 439, 300, 13, 51408], "temperature": 0.0, "avg_logprob": -0.11969863418984202, "compression_ratio": 1.5859649122807018, "no_speech_prob": 0.0015977371949702501}, {"id": 612, "seek": 358248, "start": 3604.16, "end": 3609.36, "text": " Let's say also now, what about the subscription? So actors in the Erlang model, as I understand,", "tokens": [51448, 961, 311, 584, 611, 586, 11, 437, 466, 264, 17231, 30, 407, 10037, 294, 264, 3300, 25241, 2316, 11, 382, 286, 1223, 11, 51708], "temperature": 0.0, "avg_logprob": -0.11969863418984202, "compression_ratio": 1.5859649122807018, "no_speech_prob": 0.0015977371949702501}, {"id": 613, "seek": 360936, "start": 3609.36, "end": 3612.4, "text": " you can send messages to other clients, but that's kind of like the old way of", "tokens": [50364, 291, 393, 2845, 7897, 281, 661, 6982, 11, 457, 300, 311, 733, 295, 411, 264, 1331, 636, 295, 50516], "temperature": 0.0, "avg_logprob": -0.07213180784195189, "compression_ratio": 1.9044117647058822, "no_speech_prob": 0.007342726923525333}, {"id": 614, "seek": 360936, "start": 3612.4, "end": 3616.4, "text": " doing it with the game servers where I need to know what this other actor wants to know", "tokens": [50516, 884, 309, 365, 264, 1216, 15909, 689, 286, 643, 281, 458, 437, 341, 661, 8747, 2738, 281, 458, 50716], "temperature": 0.0, "avg_logprob": -0.07213180784195189, "compression_ratio": 1.9044117647058822, "no_speech_prob": 0.007342726923525333}, {"id": 615, "seek": 360936, "start": 3617.36, "end": 3621.2000000000003, "text": " or build a subscription system where they send me a message, which is their subscription,", "tokens": [50764, 420, 1322, 257, 17231, 1185, 689, 436, 2845, 385, 257, 3636, 11, 597, 307, 641, 17231, 11, 50956], "temperature": 0.0, "avg_logprob": -0.07213180784195189, "compression_ratio": 1.9044117647058822, "no_speech_prob": 0.007342726923525333}, {"id": 616, "seek": 360936, "start": 3621.2000000000003, "end": 3625.52, "text": " and then I run the whole query engine and then I send them what they need to know,", "tokens": [50956, 293, 550, 286, 1190, 264, 1379, 14581, 2848, 293, 550, 286, 2845, 552, 437, 436, 643, 281, 458, 11, 51172], "temperature": 0.0, "avg_logprob": -0.07213180784195189, "compression_ratio": 1.9044117647058822, "no_speech_prob": 0.007342726923525333}, {"id": 617, "seek": 360936, "start": 3625.52, "end": 3629.76, "text": " which is what we have done. So you have to build that whole query subscription system up", "tokens": [51172, 597, 307, 437, 321, 362, 1096, 13, 407, 291, 362, 281, 1322, 300, 1379, 14581, 17231, 1185, 493, 51384], "temperature": 0.0, "avg_logprob": -0.07213180784195189, "compression_ratio": 1.9044117647058822, "no_speech_prob": 0.007342726923525333}, {"id": 618, "seek": 360936, "start": 3630.8, "end": 3635.1200000000003, "text": " from the ground as well. So good luck to you. And I would love to see and use your system", "tokens": [51436, 490, 264, 2727, 382, 731, 13, 407, 665, 3668, 281, 291, 13, 400, 286, 576, 959, 281, 536, 293, 764, 428, 1185, 51652], "temperature": 0.0, "avg_logprob": -0.07213180784195189, "compression_ratio": 1.9044117647058822, "no_speech_prob": 0.007342726923525333}, {"id": 619, "seek": 363512, "start": 3635.12, "end": 3641.04, "text": " if you do that because we wanted to make a game. We are doing this because we must.", "tokens": [50364, 498, 291, 360, 300, 570, 321, 1415, 281, 652, 257, 1216, 13, 492, 366, 884, 341, 570, 321, 1633, 13, 50660], "temperature": 0.0, "avg_logprob": -0.1221572588074882, "compression_ratio": 1.5330578512396693, "no_speech_prob": 0.06946288794279099}, {"id": 620, "seek": 363512, "start": 3642.16, "end": 3647.52, "text": " Okay. Then perhaps we should wrap it up with the last two questions. If someone decides they", "tokens": [50716, 1033, 13, 1396, 4317, 321, 820, 7019, 309, 493, 365, 264, 1036, 732, 1651, 13, 759, 1580, 14898, 436, 50984], "temperature": 0.0, "avg_logprob": -0.1221572588074882, "compression_ratio": 1.5330578512396693, "no_speech_prob": 0.06946288794279099}, {"id": 621, "seek": 363512, "start": 3647.52, "end": 3654.24, "text": " don't want to do that, what state is SpacetimeDB in for me as a user? Can I go and play with it?", "tokens": [50984, 500, 380, 528, 281, 360, 300, 11, 437, 1785, 307, 1738, 326, 9764, 27735, 294, 337, 385, 382, 257, 4195, 30, 1664, 286, 352, 293, 862, 365, 309, 30, 51320], "temperature": 0.0, "avg_logprob": -0.1221572588074882, "compression_ratio": 1.5330578512396693, "no_speech_prob": 0.06946288794279099}, {"id": 622, "seek": 363512, "start": 3655.12, "end": 3659.3599999999997, "text": " You absolutely can. So you can go to spacetimedb.com. You can play with a demo. It's right there.", "tokens": [51364, 509, 3122, 393, 13, 407, 291, 393, 352, 281, 39404, 9764, 67, 65, 13, 1112, 13, 509, 393, 862, 365, 257, 10723, 13, 467, 311, 558, 456, 13, 51576], "temperature": 0.0, "avg_logprob": -0.1221572588074882, "compression_ratio": 1.5330578512396693, "no_speech_prob": 0.06946288794279099}, {"id": 623, "seek": 365936, "start": 3660.32, "end": 3664.7200000000003, "text": " You can also very quickly go to our quick start guide, install spacetimedb,", "tokens": [50412, 509, 393, 611, 588, 2661, 352, 281, 527, 1702, 722, 5934, 11, 3625, 39404, 9764, 67, 65, 11, 50632], "temperature": 0.0, "avg_logprob": -0.09073198887339809, "compression_ratio": 1.7975206611570247, "no_speech_prob": 0.06186145544052124}, {"id": 624, "seek": 365936, "start": 3664.7200000000003, "end": 3669.52, "text": " get a local instance of it running, spacetime standalone. You can upload a module to that.", "tokens": [50632, 483, 257, 2654, 5197, 295, 309, 2614, 11, 39404, 9764, 37454, 13, 509, 393, 6580, 257, 10088, 281, 300, 13, 50872], "temperature": 0.0, "avg_logprob": -0.09073198887339809, "compression_ratio": 1.7975206611570247, "no_speech_prob": 0.06186145544052124}, {"id": 625, "seek": 365936, "start": 3669.52, "end": 3674.8, "text": " You can connect to that. You can call functions on that. You can also upload to our testnet.", "tokens": [50872, 509, 393, 1745, 281, 300, 13, 509, 393, 818, 6828, 322, 300, 13, 509, 393, 611, 6580, 281, 527, 1500, 7129, 13, 51136], "temperature": 0.0, "avg_logprob": -0.09073198887339809, "compression_ratio": 1.7975206611570247, "no_speech_prob": 0.06186145544052124}, {"id": 626, "seek": 365936, "start": 3674.8, "end": 3680.08, "text": " So our testnet is a version of spacetimedb cloud, which is relatively nascent,", "tokens": [51136, 407, 527, 1500, 7129, 307, 257, 3037, 295, 39404, 9764, 67, 65, 4588, 11, 597, 307, 7226, 5382, 2207, 11, 51400], "temperature": 0.0, "avg_logprob": -0.09073198887339809, "compression_ratio": 1.7975206611570247, "no_speech_prob": 0.06186145544052124}, {"id": 627, "seek": 365936, "start": 3680.7200000000003, "end": 3685.36, "text": " but it's meant for you to play around with what the cloud version will be. It's completely free.", "tokens": [51432, 457, 309, 311, 4140, 337, 291, 281, 862, 926, 365, 437, 264, 4588, 3037, 486, 312, 13, 467, 311, 2584, 1737, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09073198887339809, "compression_ratio": 1.7975206611570247, "no_speech_prob": 0.06186145544052124}, {"id": 628, "seek": 368536, "start": 3685.84, "end": 3693.92, "text": " We give you a free amount of energy. Energy is what powers these things. It's not actual energy,", "tokens": [50388, 492, 976, 291, 257, 1737, 2372, 295, 2281, 13, 14939, 307, 437, 8674, 613, 721, 13, 467, 311, 406, 3539, 2281, 11, 50792], "temperature": 0.0, "avg_logprob": -0.19886650641759238, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.005059252958744764}, {"id": 629, "seek": 368536, "start": 3693.92, "end": 3698.96, "text": " to be clear. It's just points. You can give it AWS credits. We give you AWS credits.", "tokens": [50792, 281, 312, 1850, 13, 467, 311, 445, 2793, 13, 509, 393, 976, 309, 17650, 16816, 13, 492, 976, 291, 17650, 16816, 13, 51044], "temperature": 0.0, "avg_logprob": -0.19886650641759238, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.005059252958744764}, {"id": 630, "seek": 368536, "start": 3701.28, "end": 3709.2000000000003, "text": " You can go to town on that. Then notably for the testnet, we reserve the right monthly to", "tokens": [51160, 509, 393, 352, 281, 3954, 322, 300, 13, 1396, 31357, 337, 264, 1500, 7129, 11, 321, 17824, 264, 558, 12878, 281, 51556], "temperature": 0.0, "avg_logprob": -0.19886650641759238, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.005059252958744764}, {"id": 631, "seek": 368536, "start": 3709.76, "end": 3714.48, "text": " wipe the data because we're still updating the ABI and we don't want to be locked in yet.", "tokens": [51584, 14082, 264, 1412, 570, 321, 434, 920, 25113, 264, 316, 11291, 293, 321, 500, 380, 528, 281, 312, 9376, 294, 1939, 13, 51820], "temperature": 0.0, "avg_logprob": -0.19886650641759238, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.005059252958744764}, {"id": 632, "seek": 371536, "start": 3715.76, "end": 3724.4, "text": " Early this year, we're trying for, let's say, April to move into 1.0 and the main net. The main net", "tokens": [50384, 18344, 341, 1064, 11, 321, 434, 1382, 337, 11, 718, 311, 584, 11, 6929, 281, 1286, 666, 502, 13, 15, 293, 264, 2135, 2533, 13, 440, 2135, 2533, 50816], "temperature": 0.0, "avg_logprob": -0.12321030839960626, "compression_ratio": 1.6064814814814814, "no_speech_prob": 0.000742854957934469}, {"id": 633, "seek": 371536, "start": 3724.4, "end": 3729.1200000000003, "text": " of spacetimedb will be the version of spacetimedb where we guarantee that your data is going to", "tokens": [50816, 295, 39404, 9764, 67, 65, 486, 312, 264, 3037, 295, 39404, 9764, 67, 65, 689, 321, 10815, 300, 428, 1412, 307, 516, 281, 51052], "temperature": 0.0, "avg_logprob": -0.12321030839960626, "compression_ratio": 1.6064814814814814, "no_speech_prob": 0.000742854957934469}, {"id": 634, "seek": 371536, "start": 3729.1200000000003, "end": 3734.4, "text": " be there forever and it will be persisted and replicated and all that good stuff.", "tokens": [51052, 312, 456, 5680, 293, 309, 486, 312, 13233, 292, 293, 46365, 293, 439, 300, 665, 1507, 13, 51316], "temperature": 0.0, "avg_logprob": -0.12321030839960626, "compression_ratio": 1.6064814814814814, "no_speech_prob": 0.000742854957934469}, {"id": 635, "seek": 371536, "start": 3736.6400000000003, "end": 3740.56, "text": " You can begin building your applications now for a launch post-April.", "tokens": [51428, 509, 393, 1841, 2390, 428, 5821, 586, 337, 257, 4025, 2183, 12, 32, 1424, 388, 13, 51624], "temperature": 0.0, "avg_logprob": -0.12321030839960626, "compression_ratio": 1.6064814814814814, "no_speech_prob": 0.000742854957934469}, {"id": 636, "seek": 374056, "start": 3740.96, "end": 3745.92, "text": " Okay. Here's another dangerous question because there's only really one right answer.", "tokens": [50384, 1033, 13, 1692, 311, 1071, 5795, 1168, 570, 456, 311, 787, 534, 472, 558, 1867, 13, 50632], "temperature": 0.0, "avg_logprob": -0.20321832701217296, "compression_ratio": 1.5865724381625441, "no_speech_prob": 0.005999889224767685}, {"id": 637, "seek": 374056, "start": 3746.7999999999997, "end": 3750.0, "text": " Is your game, BitCraft, going to be running on that testnet?", "tokens": [50676, 1119, 428, 1216, 11, 9101, 34, 4469, 11, 516, 281, 312, 2614, 322, 300, 1500, 7129, 30, 50836], "temperature": 0.0, "avg_logprob": -0.20321832701217296, "compression_ratio": 1.5865724381625441, "no_speech_prob": 0.005999889224767685}, {"id": 638, "seek": 374056, "start": 3750.0, "end": 3751.36, "text": " On that main net?", "tokens": [50836, 1282, 300, 2135, 2533, 30, 50904], "temperature": 0.0, "avg_logprob": -0.20321832701217296, "compression_ratio": 1.5865724381625441, "no_speech_prob": 0.005999889224767685}, {"id": 639, "seek": 374056, "start": 3751.36, "end": 3752.16, "text": " It already is.", "tokens": [50904, 467, 1217, 307, 13, 50944], "temperature": 0.0, "avg_logprob": -0.20321832701217296, "compression_ratio": 1.5865724381625441, "no_speech_prob": 0.005999889224767685}, {"id": 640, "seek": 374056, "start": 3752.16, "end": 3758.7999999999997, "text": " So, yes, 100%. We are working on, so a lot of our focus right now is getting the performance", "tokens": [50944, 407, 11, 2086, 11, 2319, 6856, 492, 366, 1364, 322, 11, 370, 257, 688, 295, 527, 1879, 558, 586, 307, 1242, 264, 3389, 51276], "temperature": 0.0, "avg_logprob": -0.20321832701217296, "compression_ratio": 1.5865724381625441, "no_speech_prob": 0.005999889224767685}, {"id": 641, "seek": 374056, "start": 3759.7599999999998, "end": 3763.36, "text": " to where it needs to be. BitCraft used to run on what we called janktimedb,", "tokens": [51324, 281, 689, 309, 2203, 281, 312, 13, 9101, 34, 4469, 1143, 281, 1190, 322, 437, 321, 1219, 361, 657, 3766, 67, 65, 11, 51504], "temperature": 0.0, "avg_logprob": -0.20321832701217296, "compression_ratio": 1.5865724381625441, "no_speech_prob": 0.005999889224767685}, {"id": 642, "seek": 374056, "start": 3763.36, "end": 3767.44, "text": " which was like spacetimedb, but it was the thing that we built first and it was not its own product.", "tokens": [51504, 597, 390, 411, 39404, 9764, 67, 65, 11, 457, 309, 390, 264, 551, 300, 321, 3094, 700, 293, 309, 390, 406, 1080, 1065, 1674, 13, 51708], "temperature": 0.0, "avg_logprob": -0.20321832701217296, "compression_ratio": 1.5865724381625441, "no_speech_prob": 0.005999889224767685}, {"id": 643, "seek": 376744, "start": 3768.2400000000002, "end": 3775.68, "text": " And that works quite well, but it actually was more like the traditional old servers where", "tokens": [50404, 400, 300, 1985, 1596, 731, 11, 457, 309, 767, 390, 544, 411, 264, 5164, 1331, 15909, 689, 50776], "temperature": 0.0, "avg_logprob": -0.14461887091921086, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0018092719838023186}, {"id": 644, "seek": 376744, "start": 3775.68, "end": 3781.04, "text": " the server knew what the client wanted and it was relatively performant. And we're now", "tokens": [50776, 264, 7154, 2586, 437, 264, 6423, 1415, 293, 309, 390, 7226, 2042, 394, 13, 400, 321, 434, 586, 51044], "temperature": 0.0, "avg_logprob": -0.14461887091921086, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0018092719838023186}, {"id": 645, "seek": 376744, "start": 3781.6, "end": 3786.4, "text": " getting back to that point that right around now, we had the same performance of janktimedb", "tokens": [51072, 1242, 646, 281, 300, 935, 300, 558, 926, 586, 11, 321, 632, 264, 912, 3389, 295, 361, 657, 3766, 67, 65, 51312], "temperature": 0.0, "avg_logprob": -0.14461887091921086, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0018092719838023186}, {"id": 646, "seek": 376744, "start": 3786.4, "end": 3791.28, "text": " and now as we gear up for the alpha, which, by the way, signed up for the BitCraft alpha,", "tokens": [51312, 293, 586, 382, 321, 7394, 493, 337, 264, 8961, 11, 597, 11, 538, 264, 636, 11, 8175, 493, 337, 264, 9101, 34, 4469, 8961, 11, 51556], "temperature": 0.0, "avg_logprob": -0.14461887091921086, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0018092719838023186}, {"id": 647, "seek": 376744, "start": 3791.28, "end": 3793.44, "text": " it's happening early this year as well.", "tokens": [51556, 309, 311, 2737, 2440, 341, 1064, 382, 731, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14461887091921086, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0018092719838023186}, {"id": 648, "seek": 376744, "start": 3793.44, "end": 3794.88, "text": " I'll put a link in the show notes.", "tokens": [51664, 286, 603, 829, 257, 2113, 294, 264, 855, 5570, 13, 51736], "temperature": 0.0, "avg_logprob": -0.14461887091921086, "compression_ratio": 1.650190114068441, "no_speech_prob": 0.0018092719838023186}, {"id": 649, "seek": 379488, "start": 3795.6800000000003, "end": 3804.2400000000002, "text": " Yes. And we are getting to the point where we are at that performance level that we need for", "tokens": [50404, 1079, 13, 400, 321, 366, 1242, 281, 264, 935, 689, 321, 366, 412, 300, 3389, 1496, 300, 321, 643, 337, 50832], "temperature": 0.0, "avg_logprob": -0.12086580670069134, "compression_ratio": 1.6131386861313868, "no_speech_prob": 0.004069079179316759}, {"id": 650, "seek": 379488, "start": 3804.2400000000002, "end": 3809.28, "text": " that alpha. So that's like, well, I don't know how much I can say without upsetting the BitCraft team,", "tokens": [50832, 300, 8961, 13, 407, 300, 311, 411, 11, 731, 11, 286, 500, 380, 458, 577, 709, 286, 393, 584, 1553, 44109, 264, 9101, 34, 4469, 1469, 11, 51084], "temperature": 0.0, "avg_logprob": -0.12086580670069134, "compression_ratio": 1.6131386861313868, "no_speech_prob": 0.004069079179316759}, {"id": 651, "seek": 379488, "start": 3809.28, "end": 3812.7200000000003, "text": " but it's many more users than we had previously, concurrently, running in the game.", "tokens": [51084, 457, 309, 311, 867, 544, 5022, 813, 321, 632, 8046, 11, 37702, 356, 11, 2614, 294, 264, 1216, 13, 51256], "temperature": 0.0, "avg_logprob": -0.12086580670069134, "compression_ratio": 1.6131386861313868, "no_speech_prob": 0.004069079179316759}, {"id": 652, "seek": 379488, "start": 3813.36, "end": 3817.04, "text": " Right. Cool. Well, you've got a busy year, a busy few years coming up.", "tokens": [51288, 1779, 13, 8561, 13, 1042, 11, 291, 600, 658, 257, 5856, 1064, 11, 257, 5856, 1326, 924, 1348, 493, 13, 51472], "temperature": 0.0, "avg_logprob": -0.12086580670069134, "compression_ratio": 1.6131386861313868, "no_speech_prob": 0.004069079179316759}, {"id": 653, "seek": 379488, "start": 3817.04, "end": 3818.88, "text": " We surely do. We surely do.", "tokens": [51472, 492, 11468, 360, 13, 492, 11468, 360, 13, 51564], "temperature": 0.0, "avg_logprob": -0.12086580670069134, "compression_ratio": 1.6131386861313868, "no_speech_prob": 0.004069079179316759}, {"id": 654, "seek": 379488, "start": 3818.88, "end": 3822.88, "text": " Awesome. Well, good luck with spacetimedb. I hope it takes off.", "tokens": [51564, 10391, 13, 1042, 11, 665, 3668, 365, 39404, 9764, 67, 65, 13, 286, 1454, 309, 2516, 766, 13, 51764], "temperature": 0.0, "avg_logprob": -0.12086580670069134, "compression_ratio": 1.6131386861313868, "no_speech_prob": 0.004069079179316759}, {"id": 655, "seek": 382288, "start": 3822.96, "end": 3826.4, "text": " Good luck with BitCraft. I hope that takes off. And if they both take off,", "tokens": [50368, 2205, 3668, 365, 9101, 34, 4469, 13, 286, 1454, 300, 2516, 766, 13, 400, 498, 436, 1293, 747, 766, 11, 50540], "temperature": 0.0, "avg_logprob": -0.12807764830412688, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0007791488897055387}, {"id": 656, "seek": 382288, "start": 3826.4, "end": 3828.6400000000003, "text": " you're going to invite me to your private yacht for a follow-up.", "tokens": [50540, 291, 434, 516, 281, 7980, 385, 281, 428, 4551, 39629, 337, 257, 1524, 12, 1010, 13, 50652], "temperature": 0.0, "avg_logprob": -0.12807764830412688, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0007791488897055387}, {"id": 657, "seek": 382288, "start": 3829.2000000000003, "end": 3833.12, "text": " I don't know that I'll have one of those. I'll be too busy on the next part of spacetimedb.", "tokens": [50680, 286, 500, 380, 458, 300, 286, 603, 362, 472, 295, 729, 13, 286, 603, 312, 886, 5856, 322, 264, 958, 644, 295, 39404, 9764, 67, 65, 13, 50876], "temperature": 0.0, "avg_logprob": -0.12807764830412688, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0007791488897055387}, {"id": 658, "seek": 382288, "start": 3833.12, "end": 3836.0, "text": " So good luck. I need satellite from there.", "tokens": [50876, 407, 665, 3668, 13, 286, 643, 16016, 490, 456, 13, 51020], "temperature": 0.0, "avg_logprob": -0.12807764830412688, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0007791488897055387}, {"id": 659, "seek": 382288, "start": 3837.28, "end": 3839.28, "text": " You'll be able to afford it if both of those work.", "tokens": [51084, 509, 603, 312, 1075, 281, 6157, 309, 498, 1293, 295, 729, 589, 13, 51184], "temperature": 0.0, "avg_logprob": -0.12807764830412688, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0007791488897055387}, {"id": 660, "seek": 382288, "start": 3839.28, "end": 3840.6400000000003, "text": " I guess so. I guess so.", "tokens": [51184, 286, 2041, 370, 13, 286, 2041, 370, 13, 51252], "temperature": 0.0, "avg_logprob": -0.12807764830412688, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0007791488897055387}, {"id": 661, "seek": 382288, "start": 3841.44, "end": 3843.28, "text": " Tyler, thanks very much for joining us. Cheers.", "tokens": [51292, 16869, 11, 3231, 588, 709, 337, 5549, 505, 13, 13006, 13, 51384], "temperature": 0.0, "avg_logprob": -0.12807764830412688, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0007791488897055387}, {"id": 662, "seek": 382288, "start": 3843.28, "end": 3846.4, "text": " Thanks for having me. And that's all from Tyler. Thank you very much.", "tokens": [51384, 2561, 337, 1419, 385, 13, 400, 300, 311, 439, 490, 16869, 13, 1044, 291, 588, 709, 13, 51540], "temperature": 0.0, "avg_logprob": -0.12807764830412688, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0007791488897055387}, {"id": 663, "seek": 382288, "start": 3847.04, "end": 3852.48, "text": " You know, in among all the things we discussed in there, I think Tyler must be something like", "tokens": [51572, 509, 458, 11, 294, 3654, 439, 264, 721, 321, 7152, 294, 456, 11, 286, 519, 16869, 1633, 312, 746, 411, 51844], "temperature": 0.0, "avg_logprob": -0.12807764830412688, "compression_ratio": 1.736842105263158, "no_speech_prob": 0.0007791488897055387}, {"id": 664, "seek": 385248, "start": 3852.48, "end": 3856.64, "text": " our third guest to reference the Plan 9 operating system.", "tokens": [50364, 527, 2636, 8341, 281, 6408, 264, 8112, 1722, 7447, 1185, 13, 50572], "temperature": 0.0, "avg_logprob": -0.06293294810447372, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.012414485216140747}, {"id": 665, "seek": 385248, "start": 3857.2, "end": 3860.48, "text": " And I don't know much about Plan 9, except it never took off,", "tokens": [50600, 400, 286, 500, 380, 458, 709, 466, 8112, 1722, 11, 3993, 309, 1128, 1890, 766, 11, 50764], "temperature": 0.0, "avg_logprob": -0.06293294810447372, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.012414485216140747}, {"id": 666, "seek": 385248, "start": 3861.04, "end": 3863.84, "text": " but it was a huge influence for a lot of people.", "tokens": [50792, 457, 309, 390, 257, 2603, 6503, 337, 257, 688, 295, 561, 13, 50932], "temperature": 0.0, "avg_logprob": -0.06293294810447372, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.012414485216140747}, {"id": 667, "seek": 385248, "start": 3863.84, "end": 3867.44, "text": " I think we might have to have some kind of retrospective", "tokens": [50932, 286, 519, 321, 1062, 362, 281, 362, 512, 733, 295, 34997, 488, 51112], "temperature": 0.0, "avg_logprob": -0.06293294810447372, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.012414485216140747}, {"id": 668, "seek": 385248, "start": 3867.44, "end": 3870.96, "text": " what we could have learned as an industry episode on Plan 9 one day.", "tokens": [51112, 437, 321, 727, 362, 3264, 382, 364, 3518, 3500, 322, 8112, 1722, 472, 786, 13, 51288], "temperature": 0.0, "avg_logprob": -0.06293294810447372, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.012414485216140747}, {"id": 669, "seek": 385248, "start": 3871.6, "end": 3875.92, "text": " So if you're a Plan 9 expert, or if you know one, please get in touch.", "tokens": [51320, 407, 498, 291, 434, 257, 8112, 1722, 5844, 11, 420, 498, 291, 458, 472, 11, 1767, 483, 294, 2557, 13, 51536], "temperature": 0.0, "avg_logprob": -0.06293294810447372, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.012414485216140747}, {"id": 670, "seek": 385248, "start": 3876.64, "end": 3880.16, "text": " And the way you get in touch is the same way you send us any feedback.", "tokens": [51572, 400, 264, 636, 291, 483, 294, 2557, 307, 264, 912, 636, 291, 2845, 505, 604, 5824, 13, 51748], "temperature": 0.0, "avg_logprob": -0.06293294810447372, "compression_ratio": 1.6515151515151516, "no_speech_prob": 0.012414485216140747}, {"id": 671, "seek": 388016, "start": 3880.16, "end": 3882.3999999999996, "text": " My contact details are in the show notes.", "tokens": [50364, 1222, 3385, 4365, 366, 294, 264, 855, 5570, 13, 50476], "temperature": 0.0, "avg_logprob": -0.06668762969970703, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.022961923852562904}, {"id": 672, "seek": 388016, "start": 3882.3999999999996, "end": 3885.7599999999998, "text": " If you're on YouTube, there's a comment box just down there.", "tokens": [50476, 759, 291, 434, 322, 3088, 11, 456, 311, 257, 2871, 2424, 445, 760, 456, 13, 50644], "temperature": 0.0, "avg_logprob": -0.06668762969970703, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.022961923852562904}, {"id": 673, "seek": 388016, "start": 3886.48, "end": 3891.7599999999998, "text": " Spotify has a Q&A thing for each episode these days, and so on and so on. Check your app.", "tokens": [50680, 29036, 575, 257, 1249, 5, 32, 551, 337, 1184, 3500, 613, 1708, 11, 293, 370, 322, 293, 370, 322, 13, 6881, 428, 724, 13, 50944], "temperature": 0.0, "avg_logprob": -0.06668762969970703, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.022961923852562904}, {"id": 674, "seek": 388016, "start": 3892.64, "end": 3895.68, "text": " On the subject of feedback and the future episodes,", "tokens": [50988, 1282, 264, 3983, 295, 5824, 293, 264, 2027, 9313, 11, 51140], "temperature": 0.0, "avg_logprob": -0.06668762969970703, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.022961923852562904}, {"id": 675, "seek": 388016, "start": 3895.68, "end": 3899.52, "text": " if you enjoyed this episode, please leave a like or a comment.", "tokens": [51140, 498, 291, 4626, 341, 3500, 11, 1767, 1856, 257, 411, 420, 257, 2871, 13, 51332], "temperature": 0.0, "avg_logprob": -0.06668762969970703, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.022961923852562904}, {"id": 676, "seek": 388016, "start": 3900.16, "end": 3903.12, "text": " If you think other people should find this podcast,", "tokens": [51364, 759, 291, 519, 661, 561, 820, 915, 341, 7367, 11, 51512], "temperature": 0.0, "avg_logprob": -0.06668762969970703, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.022961923852562904}, {"id": 677, "seek": 388016, "start": 3903.12, "end": 3905.2799999999997, "text": " please rate it or share it with a friend.", "tokens": [51512, 1767, 3314, 309, 420, 2073, 309, 365, 257, 1277, 13, 51620], "temperature": 0.0, "avg_logprob": -0.06668762969970703, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.022961923852562904}, {"id": 678, "seek": 388016, "start": 3905.92, "end": 3909.2799999999997, "text": " And make sure you're subscribed because we're going to be back next week", "tokens": [51652, 400, 652, 988, 291, 434, 16665, 570, 321, 434, 516, 281, 312, 646, 958, 1243, 51820], "temperature": 0.0, "avg_logprob": -0.06668762969970703, "compression_ratio": 1.6573426573426573, "no_speech_prob": 0.022961923852562904}, {"id": 679, "seek": 390928, "start": 3909.28, "end": 3912.5600000000004, "text": " with more interesting voices from the software development world.", "tokens": [50364, 365, 544, 1880, 9802, 490, 264, 4722, 3250, 1002, 13, 50528], "temperature": 0.0, "avg_logprob": -0.16064431819509953, "compression_ratio": 1.3309859154929577, "no_speech_prob": 0.01762346364557743}, {"id": 680, "seek": 390928, "start": 3913.2000000000003, "end": 3916.1600000000003, "text": " Until then, I've been your host, Chris Jenkins.", "tokens": [50560, 9088, 550, 11, 286, 600, 668, 428, 3975, 11, 6688, 41273, 13, 50708], "temperature": 0.0, "avg_logprob": -0.16064431819509953, "compression_ratio": 1.3309859154929577, "no_speech_prob": 0.01762346364557743}, {"id": 681, "seek": 390928, "start": 3916.1600000000003, "end": 3919.28, "text": " This has been Developer Voices with Tyler Clute here.", "tokens": [50708, 639, 575, 668, 44915, 7518, 1473, 365, 16869, 2033, 1169, 510, 13, 50864], "temperature": 0.0, "avg_logprob": -0.16064431819509953, "compression_ratio": 1.3309859154929577, "no_speech_prob": 0.01762346364557743}, {"id": 682, "seek": 390928, "start": 3919.28, "end": 3920.2400000000002, "text": " Thanks for listening.", "tokens": [50864, 2561, 337, 4764, 13, 50912], "temperature": 0.0, "avg_logprob": -0.16064431819509953, "compression_ratio": 1.3309859154929577, "no_speech_prob": 0.01762346364557743}, {"id": 683, "seek": 393928, "start": 3939.28, "end": 3940.7400000000002, "text": " you", "tokens": [50412, 291, 50437], "temperature": 0.0, "avg_logprob": -0.9720725417137146, "compression_ratio": 0.2727272727272727, "no_speech_prob": 0.9567493796348572}], "language": "en"}