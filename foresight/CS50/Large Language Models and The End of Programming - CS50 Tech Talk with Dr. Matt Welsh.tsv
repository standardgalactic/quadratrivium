start	end	text
0	3000	We're joined today by Dr. Matt Welsh, and we'll be joined toward the end of the talk
3000	6000	by Pizza as well, which we'll serve right out there on folks' way out,
6000	9000	as an opportunity to chat more casually with Matt toward the end.
9000	12000	I actually got to know Matt when I was back in graduate school,
12000	14000	and I spent quite a bit of time with him and his students
14000	17000	when his focus was particularly on what are called sensor networks,
17000	21000	which are these distributed networks of very small, low-power, low-resource devices,
21000	25000	which made it very hard at the time to actually write code that interconnects them
25000	27000	and generally solves problems.
27000	30000	And among the problems some of my classmates were working on
30000	33000	were monitoring volcanoes, for instance, and the integrity of bridges.
33000	37000	And in my own interest, being able to set up these mesh networks of sorts
37000	40000	in emergency medicine so that they could talk among each other without wires
40000	42000	or without any central access.
42000	45000	Matt went on since then to work full-time at Google
45000	47000	and most recently at Fixie.ai.
47000	49000	And he's might have seen from today's description
49000	53000	he portends a future in which computers will do the writing of code for us.
53000	55000	So if you're struggling in CSI,
55000	58000	61, 161 or anything in between, not to worry.
58000	61000	AI is now here, as is Dr. Matt Wells.
61000	63000	Thanks, David.
63000	64000	Thanks for having me.
64000	67000	It's been, I don't know, 13 years or something, 12 years
67000	69000	since I gave a lecture at Harvard.
69000	72000	So we'll see if I've still got it.
72000	77000	And I was joking yesterday with David Parks, who's now the dean
77000	81000	and he and I were kind of peers when I was on the faculty here.
81000	83000	And I said, you know, like it's remarkable.
83000	87000	Like congratulations, David, on becoming dean of CS.
87000	92000	I don't think we're kind of old enough to be dean quality yet.
92000	94000	And then actually I realize we are.
94000	96000	So anyway, all right.
96000	103000	So I'm here to tell you that the field of computer science is doomed.
103000	105000	Okay.
105000	109000	And I actually kind of mean this, although I'm going to put it in somewhat here.
109000	112000	I kind of mean this, although I'm going to put it in somewhat humorous terms.
112000	116000	That if you think about computer science, what is the field about?
116000	117000	What does it mean?
117000	118000	Where did it come from?
118000	119000	What is it?
119000	121000	What's the core idea of it?
121000	126000	It's the idea of taking an idea, an algorithm or a concept or a data structure
126000	130000	and translating it into a program that can generally be run
130000	133000	by like a von Neumann architecture machine, right?
133000	134000	Okay.
134000	136000	So that's computer science in a nutshell.
136000	147000	The problem is that the goal of CS has always had this kind of core fundamental assumption or axiom
147000	153000	that is that the programs that we're all talking about here have been implemented,
153000	158000	maintained and have to be understood by humans, right?
158000	164000	That if I print out the code for a program, a human, some human, maybe not everyone,
164000	169000	but at least maybe the person who wrote it, if not someone else, can understand it.
169000	171000	Now here's the problem, right?
171000	174000	Humans suck at all three of these things.
174000	176000	We're terrible at writing programs.
176000	181000	We're terrible at maintaining them and we're absolutely terrible at understanding them.
181000	186000	So what does that really mean for the field?
186000	193000	So I want to make this claim that 50 years of research into programming languages
193000	199000	has done effectively nothing to solve this problem.
199000	201000	We've been at this for a long time now.
201000	206000	50 years is a long time and we keep inventing new languages and new programming concepts
206000	212000	and new abstractions and new data types and new proof methodologies.
212000	217000	But none of the stuff that we've developed in terms of tooling or languages or proof techniques
217000	221000	or documentation or linters has actually solved this problem
221000	225000	and I don't think another 50 years is going to solve it.
225000	235000	I think this idea of building automated tools to help humans write better software has played itself out.
235000	240000	Now if you disagree with me, let's just take a look at kind of the history here.
240000	244000	So let's rewind the clock all the way back to 1957.
244000	248000	This is Conway's Game of Life implemented in Fortran.
248000	257000	I don't remember which dialect of Fortran this is, but Fortran came about in about 1957.
257000	260000	I just claim this is really hard to understand.
260000	266000	I claim that you can't look at this unless you had some idea of the intent of the program
266000	268000	or what the hell does this do.
268000	272000	You could work it out. You could spend some time reading it.
272000	277000	You could probably understand it with some effort, but it's not trivial.
277000	279000	It's not straightforward.
279000	282000	Okay, so we tried to make programming easier.
282000	286000	We came up with something called BASIC in 1964.
286000	288000	This is not the original BASIC.
288000	292000	Again, it's had many dialects because obviously the first one wasn't good enough.
292000	294000	We had to keep improving the language.
294000	298000	This is the same program in BASIC.
298000	303000	I don't think this is any easier to understand, okay?
303000	308000	I could spend some time reading it and convince myself that it does a certain thing,
308000	310000	but it's quite challenging to get.
310000	315000	So then we came up with APL.
315000	319000	This is Conway's Game of Life and APL.
319000	322000	I would say raise your hand if you understand this,
322000	327000	but I know there's probably a few people in the audience who do.
327000	329000	I don't, right?
329000	335000	This is a programming language so complex you needed a special keyboard to type it, okay?
335000	341000	But this is what we thought was the practice of developing programming languages
341000	345000	back in the 60s, was this.
345000	348000	Certainly it doesn't do the job.
348000	351000	All right, well, I've been talking about stuff that's kind of old-fashioned.
351000	353000	Let's talk about the new hotness.
353000	355000	Let's talk about Rust.
355000	357000	Everybody's programming in Rust.
357000	359000	It's the latest and greatest thing since sliced bread.
359000	363000	I spent two years running engineering at a startup that was completely Rust-based.
363000	365000	I ran a big team full of Rust developers.
365000	369000	I actually learned Rust myself, kind of.
369000	371000	This is the same program in Rust.
371000	374000	I don't make heads or tails of this.
374000	380000	It is incredibly hard to write programs that are easy to understand,
380000	385000	easy to maintain, easy to reason about, okay?
385000	388000	So that's the kind of state of the art.
388000	392000	This is where we've gotten in 50 years from Fortran to this.
392000	396000	And I just want to make the claim that this is not going to work, okay?
396000	399000	We're done. Game over.
399000	401000	So what's next?
401000	406000	Well, this is how I write code today.
406000	411000	This is a prompt passed to the GPT-4 model.
411000	416000	And it's part of a larger program that reads in some text of a transcript
416000	420000	that's been derived from a podcast audio feed.
420000	424000	We're feeding the transcript into the model and we're giving it these instructions.
424000	430000	We're saying, please summarize the following segment of this podcast transcript.
430000	432000	Only use the information in the text.
432000	434000	Do not in caps.
434000	437000	This is important, by the way. The all caps is super important.
437000	441000	Do not use any information you know about the world.
441000	448000	Include the title of the podcast, the name of the episode, and the names of the speakers, if known.
448000	454000	This English statement here encodes an algorithm.
454000	461000	It describes something that I want to do with an input data and the output data that I want.
461000	466000	And my expectations about the kind of thing that's in the output data.
466000	468000	So a few things to notice about this.
468000	476000	The first thing to notice about this is I don't think anyone could ever write down the algorithm
476000	481000	for what this is supposed to do in any existing programming language
481000	485000	or any programming language that we're likely to come up with in the future.
485000	489000	How do you write this algorithm?
489000	492000	You can't, right? There's no pseudocode. There's no proof.
492000	497000	There's no mathematical symbology here, right?
497000	502000	The other thing to notice is, at least for me, I don't know about any of you.
502000	506000	Do you understand this? Do you understand what it's saying?
506000	511000	Does it make sense? Can you read it? Can you reason about what it's supposed to do?
511000	515000	Yes, of course, right? It's in plain English.
515000	520000	It doesn't have to be English, by the way. It could be in Mandarin Chinese or Esperanto.
520000	528000	Have you all seen the XKCD about the guy who walks into his friend's house
528000	532000	and he says, okay, Alexa, order five tons of creamed corn?
532000	535000	Okay, Alexa, confirm order.
535000	539000	That's how he makes sure that no one's got a speaker listening to him.
539000	544000	Okay, so the point being that this is now how I am actually writing code
544000	549000	and what's funny about this is a lot of it is trial and error and experimentation.
549000	555000	By the way, that's the same when I'm writing normal computer code.
555000	560000	And the other thing that's interesting about this is there's a lot of subtlety
560000	566000	in terms of how you instruct the model and how you know what it's going to do with your instructions.
566000	570000	You can't write a manual that says, well, here's this set of words that you need to use
570000	575000	to get the model to do X, Y, or Z. You have to just try out certain things.
575000	581000	In this case, I found out the do not in all caps really helped
581000	587000	because I really wanted to emphasize that point to the model.
587000	593000	This reminds me of another programming language that someone came up with a while ago called intercal.
593000	600000	Intercal was meant to be one of these kind of obscure or maybe satirical joke programming languages.
600000	607000	Intercal had these interesting features such as you had to use the keyword please.
607000	613000	And if you use the keyword please too often, the compiler would reject your program.
613000	617000	If you didn't use it enough, it would also reject your program.
617000	621000	And it turned out that feature was undocumented.
621000	623000	It's exactly like what we're doing today, right?
623000	629000	We have to say please and do not in all caps to get the language models to do what we want.
629000	631000	So where am I going with all this?
631000	640000	I think what I'm saying here is we are now in an era where we have machines that can take natural language in
640000	647000	and produce results, algorithmic results, computational results,
647000	657000	but for which no human has written a program in anything resembling a conventional programming language.
657000	662000	And I claim that these models are going to get so good at doing this
662000	667000	that our whole concept of programming computers is going to get replaced over time
667000	674000	with instructing language models to do things for us.
674000	679000	So let's take a look at the state of programming language technology.
679000	687000	This is a programmer without co-pilot in around 2020, colorized, okay?
687000	691000	I think I met that guy out in Central Square this morning.
691000	694000	And here's a programmer with co-pilot in 2021, right?
694000	698000	So clearly we're evolving very rapidly as a species of programmers.
698000	700000	Unfortunately, both of these cases are male.
700000	703000	I apologize for that.
703000	712000	So how many people here have used co-pilot or one of its ilk in terms of helping you write code?
712000	714000	Don't be shy.
714000	717000	I know you're like, who's my professor in here?
717000	718000	Oh, shit.
718000	719000	All right.
719000	728000	So co-pilot, if you haven't used it, is a complete game changer in terms of how real world developers write code.
728000	729000	Okay?
729000	735000	Yes, it's also kind of a huge boost for students who want to effectively shortcut their homework,
735000	737000	speed run their homework.
737000	742000	But this is, for someone working in the industry, writing code every single day,
742000	745000	if I don't have co-pilot, I absolutely feel naked.
745000	747000	I was on the airplane out here, I was writing code.
747000	752000	The Wi-Fi was not quite fast enough, so I would type out, you know, my half a line of code
752000	755000	and just sort of wait for co-pilot to finish it for me like I always do.
755000	759000	Normally that happens in about like less than a second, and this time it was just taking so long.
759000	760000	I said, ah, damn it.
760000	768000	I guess I have to write this myself, just like I used to a year ago.
768000	771000	Co-pilot is incredible for a few reasons.
771000	778000	I think one of the things that people don't fully appreciate is that it keeps you in the zone of writing code.
778000	783000	It used to be the case that any time I'd hit a little snag, I'd be like, oh, crap.
783000	789000	I can't quite remember the syntax for how I, you know, reverse a list in whatever language I'm working in.
789000	790000	Crap.
790000	791000	Well, I know where to find the answer.
791000	792000	I'll just Google it.
792000	795000	It's on Stack Overflow somewhere.
795000	798000	And so I go and I Google it and I find the thing.
798000	803000	It's probably not a direct answer, so I have to kind of read the article a little bit and kind of piece together.
803000	805000	Oh, yeah, that's the snippet I was looking for.
805000	808000	And then 45 minutes later, what am I doing?
808000	809000	I'm on Reddit somewhere, you know.
809000	812000	I've gone down the rat hole of surfing the internet.
812000	816000	I got out of the zone of writing code.
816000	821000	So by doing, keeping you in the zone, I think people are so much more productive with this.
821000	826000	And to the point where we mandated every developer at our company has to use co-pilot.
826000	829000	If there's somebody not using co-pilot, they're going to be fired.
829000	833000	Well, I didn't say that, but it's kind of the idea.
833000	838000	So a lot of people have chastised or criticized co-pilot for being a little dumb, right?
838000	843000	It's like, well, it's just trained on stuff it found on the internet on GitHub and homework assignments.
843000	845000	How good can it be?
845000	847000	It's incredibly good.
847000	851000	It's not just parroting back things that it's seen elsewhere.
851000	854000	It's interpreting your program and your intent.
854000	859000	It's looking at other parts of your code to understand what you might do next.
859000	862000	It's understanding your data structures.
862000	866000	It's not just looking at a little context window in this current file you're editing.
866000	870000	It's looking elsewhere in the code to find something that might be relevant.
870000	879000	And the only thing that is stopping co-pilot from getting really, really, really good at this is just more data and more compute.
879000	883000	And guess what? We have both of those in abundance, right?
883000	890000	There's nothing that's going to stop this from getting incredibly good over time.
890000	894000	So here's another kind of similar use case.
894000	899000	This is not co-pilot. This is chatGPT, which I'm sure we're all familiar with.
899000	903000	But if you are trying to figure out how to do something,
903000	913000	and in this case, I was using the DeepGram Python SDK to transcribe audio files for this podcast thing I mentioned earlier,
913000	924000	I could have spent 15, 20 minutes reading their documentation, finding some example code on the Internet,
924000	931000	following a tutorial, or, because we're all like, you know, programmers are incredibly lazy,
931000	935000	just say, hey, look, I'm trying to do this thing. Can you just give me the code I need?
935000	939000	And it does it.
939000	941000	Co-pilot is not just understanding homework assignments.
941000	943000	ChatGPT is not just understanding homework assignment.
943000	953000	It, like, understands other people's APIs and SDKs and programming libraries and abstractions and best practices and bugs that might occur.
953000	955000	I mean, it's really got a lot of knowledge.
955000	963000	And so with very little effort, then I can just cut and paste this code right into my program and get on with my life.
963000	966000	Right?
967000	970000	Shell Silverstein, who wrote A Light in the Attic.
970000	975000	This is something, a children's book, a book of children's poetry that I read when I was a kid.
975000	977000	I saw this on Reddit a couple days ago.
977000	979000	He completely predicted this.
979000	981000	This is 1981.
981000	986000	You know, the homework machine, oh, the homework machine, most perfect contraption that's ever been seen.
986000	993000	Just put in your homework, then drop in a dime, snap on the switch, and in 10 seconds time, your homework comes out.
993000	995000	Quick and clean as can be.
995000	996000	What is? 9 plus 4?
996000	998000	And the answer is 3.
998000	1000000	3, oh, me.
1000000	1003000	I guess it's not as perfect as I thought it would be.
1003000	1005000	Exactly.
1005000	1007000	Cost of dime, takes about 10 seconds.
1007000	1009000	I guess the answer wrong.
1009000	1013000	This is very much what we're dealing with today.
1013000	1020000	By the way, and this is a complete aside, but I can't resist, when I mentioned Shell Silverstein, if you don't know what he looked like,
1020000	1025000	this was the cover, the photo on the dust jacket of one of his first books.
1025000	1032000	This guy, I love this guy, a children's poetry book author from the 70s.
1032000	1034000	And that's what he looked like.
1034000	1035000	Amazing.
1035000	1036000	All right.
1036000	1047000	So now I want to talk about, well, if this AI technology is getting so good, then what's going to happen to our industry?
1047000	1062000	What does this mean for all of us who might be looking to get jobs in this industry in the future and expecting to get those big fat paychecks and stock option grants and buy Teslas or whatever we're expecting to do?
1062000	1068000	So how much does it cost to replace one human developer with AI?
1068000	1069000	Well, I did the math.
1069000	1075000	So let's say that a typical software engineer salary in Silicon Valley or Seattle is around 220,000 a year.
1075000	1086000	That's just the base salary, doesn't include benefits, doesn't include equity packages, doesn't include your free lunch in your bowling alley and all that kind of stuff.
1086000	1092000	So let's just assume that that stuff costs, you know, 92K a year.
1092000	1093000	This is, again, a little conservative.
1093000	1101000	So the total cost to your employer is roughly 300, 312K for one suite.
1101000	1103000	How many working days are there in a year?
1103000	1110000	About 260, and so it costs $1,200 a day to employ you as a suite at one of these companies.
1110000	1112000	Fair enough?
1112000	1113000	Okay.
1113000	1115000	So let's do the math.
1115000	1121000	How many lines of code do you think an average developer checks into the code base every day?
1121000	1127000	I mean, finalized, tested, reviewed, and approved lines of code.
1128000	1134000	Most of us who've worked in industry know that the median value is zero.
1134000	1140000	Because there's so many days that you go by where you're waiting on somebody else or you're in meetings all day, you didn't get anything done, you didn't check it in.
1140000	1144000	But let's just be generous here and say it's about 100.
1144000	1145000	I know 100 doesn't sound like a lot.
1145000	1147000	People are like, but I was programming all day.
1147000	1153000	Yes, but 90% of your code you ended up throwing out or somebody reviewed it and said it was no good, you have to rewrite it.
1153000	1156000	You were trying to figure out what to do, you were revamping it.
1156000	1161000	So like the final result of your output is something like 100 lines of code a day.
1161000	1164000	That's the final result.
1164000	1167000	How many GPT-3 model tokens is that?
1167000	1172000	It's about 10 tokens per line, more or less.
1172000	1181000	And the cost for GPT-3, actually this is probably a little out of date, but at the time I made this slide, it was $0.02 for 1,000 tokens.
1181000	1196000	So if you do the math, then the total cost for the output of one human software developer on GPT-3 is $0.12.
1196000	1203000	This is a factor of $10,000.
1203000	1207000	This should scare us all.
1207000	1213000	This suggests potentially a very large shift in our industry.
1213000	1222000	I don't think we can ignore this and just write it off and say, well the AI is not very good today, so therefore it's not going to be good in five years.
1222000	1225000	This radically changes how we think about it.
1225000	1235000	The only reason that programmers are paid so much is that it requires years and years and years of education and training and knowledge and specialization to be good at it.
1235000	1252000	But there's no reason that I need to hire a super smart Harvard educated student to do this if I can get chat GPT to do most of the work for me and have a human typing it in.
1252000	1256000	There's a lot of other advantages to hiring the robots instead of the humans, right?
1256000	1258000	Robots not going to take breaks.
1258000	1264000	The robot is not today expecting free lunches and onsite massage.
1264000	1266000	That could change.
1266000	1276000	The robot takes the same length of time to generate its code whether it's the rough proof of concept or the final production ready code.
1276000	1283000	When you go as a PM to an organization, to your engineering team and you say, okay team, there's eight of you here.
1283000	1286000	We have to ship the billing page.
1286000	1289000	How soon can we do it?
1289000	1292000	You're going to spend at least an hour and a half having the conversation.
1292000	1296000	Well, you know, like if we do it quick and dirty, we can maybe do it in three weeks.
1296000	1302000	And if it's got to be production ready, give us 12.
1302000	1311000	Or you can go to the proverbial homework machine, push the button and have the code right now, right?
1311000	1318000	And the other thing is, yes, the robot makes mistakes, but those mistakes can happen incredibly quickly.
1318000	1325000	To the level of speed where iterate, iterate, iterate, iterate, iterate, iterate, iterate, iterate is perfectly fine.
1325000	1335000	You can say to the robot, you know what, this whole thing, 5,000 source files, 20,000 lines of code, whatever it is, blow it away, start over.
1335000	1336000	Boom.
1336000	1340000	Five seconds later, you have a brand new version of it.
1340000	1346000	Try that with a live human engineer team, right?
1346000	1351000	So I think this is all like something that we really have to take seriously.
1351000	1362000	I don't think that this is just, I am exaggerating for effect, but the industry is going to change.
1362000	1369000	So, you know, the natural question then is, well, what happens when we cut humans out of the loop?
1369000	1370000	How do we build software?
1370000	1372000	How do we ship product?
1372000	1380000	I found this video on, I think it's Microsoft's website and it's titled, What do product managers do?
1380000	1388000	That was a little bit of an unintended joke, I think, because as an engineer we often go, what do product managers do?
1388000	1398000	But if you imagine what the software team of the future might look like, I think this is one very plausible approach,
1398000	1406000	which is you have a product manager, this is probably still a human taking the business and the product requirements,
1406000	1413000	the user requirements and translating them into some form, probably English, maybe a little bit technical English,
1413000	1420000	that you then can provide to the AI, the army of AI code generators.
1420000	1429000	The AI code generators give you a whole bunch of code and probably for a while still we still have humans reading and reviewing the code
1429000	1433000	to make sure that it does what it was supposed to do.
1433000	1436000	Now, that read is a little different than what we have today.
1436000	1440000	Today when we review code, if I have another engineer on my team writing code and I'm reviewing it,
1440000	1443000	standard practice in the industry is to do code review for one another.
1443000	1447000	We don't just check in code, we read each other's code, we make detailed comments on it,
1447000	1453000	we suggest improvements, cleanups, clarifications, comments, documentation.
1453000	1461000	In this case, it's not absolutely essential that this code be maintainable by a human.
1461000	1464000	I think for a while we're going to want that, right?
1464000	1468000	Most people are not going to feel comfortable just letting the robots do all the coding,
1468000	1475000	but at some point, as long as I can convince myself that the code does what it's supposed to do,
1475000	1477000	I don't really care how messy it is.
1477000	1479000	I don't really care how it's structured.
1479000	1481000	I don't really care how reusable it is.
1481000	1488000	All of those factors are only because poor humans have to wrangle with this stuff, right?
1488000	1490000	Oh, it needs to be modular.
1490000	1494000	We need to have abstraction boundaries, right?
1494000	1497000	All the things, you know, sophomore level computer science, right?
1497000	1498000	Why?
1498000	1502000	For the sake of poor humans having to deal with this complex code base.
1502000	1508000	But if the robots are the ones generating it, and we don't really need to maintain it in a conventional way,
1508000	1510000	why not just generate the code you need?
1510000	1516000	It doesn't really matter if it's duplicative or repetitive or modular or nicely abstracted.
1516000	1518000	It doesn't matter.
1518000	1520000	It does the job.
1524000	1529000	So one of my hypotheses around why everyone has been freaking out about ChatGBT
1529000	1537000	is because unlike other industries, this revolution seemed to occur overnight,
1537000	1543000	unless you're like an AI professor and have really been following the literature for years and years and years.
1543000	1549000	To most of us, myself included, this seemed to just go from, you know,
1549000	1554000	AI was kind of crappy to AI was amazing, literally overnight, right?
1554000	1563000	So to use an analogy, this would be as if the field of computer graphics went from Pong to Red Dead Redemption 2
1563000	1567000	in the span of about three months, right?
1567000	1571000	People's heads would explode if that happened, right?
1571000	1573000	But that's not what happened in graphics, right?
1573000	1579000	In graphics, it took decades to get to this point, and everyone could see it gradually getting better and better and better.
1579000	1582000	You know, I remember when Toy Story came out.
1582000	1585000	And that was like the first CG movie.
1585000	1588000	People's minds just melted watching that.
1588000	1590000	They were like, whoa!
1590000	1593000	And now we watch it and you just like, oh, yeah, that's cute.
1593000	1598000	You know, I could render that on my laptop in scratch or whatever, right?
1600000	1607000	The other thing that's happened, I think, in this field that's interesting and there's a big societal shift happening is
1607000	1613000	the dialogue around our expectations of what AI can achieve.
1613000	1619000	And so in 1972, Hubert Dreyfuss wrote this book, What Computers Can't Do?
1619000	1622000	And this was at the dawn of the PC era.
1622000	1628000	And there was a lot of popular press and dialogue around this sort of scaremongering around AI.
1628000	1631000	And, you know, we had movies come out like War Games.
1631000	1632000	Does anybody remember that?
1632000	1636000	I think War Games, by the way, that movie is why I am a computer scientist, right?
1636000	1642000	I was like, I want to be Matthew Broderick in this room with like all these monitors in my like analog modem
1642000	1644000	and hacking into the school computer.
1644000	1646000	Like that was me as a kid.
1646000	1652000	So at this time, I think a lot of people were saying, well, hold on a minute.
1652000	1658000	Computers are fundamentally dumb and they can't do these things and they never will.
1658000	1660000	And that was the thesis of this book here.
1660000	1663000	And I think that that was the sort of consensus view, right?
1663000	1666000	We sort of calmed down a little bit about the technology.
1666000	1674000	We all kind of realized, yeah, okay, Visicalc is not going to put me out of a job, right?
1674000	1681000	But now fast forward, 2014, I highly recommend this book if you haven't read it by Nick Bostrom called Super Intelligence.
1681000	1688000	This is a book that wrestles in a tremendous amount of detail with the philosophical and the moral questions of
1688000	1696000	how does human society respond to an AI that is more intelligent than humans?
1696000	1703000	And I know we've got a lot of sci-fi around that topic, but this is a very serious academic work about
1703000	1712000	what does it mean for our society if we have AI that is smarter than us?
1712000	1715000	And people are taking that very seriously today.
1715000	1726000	So I think my point being that the dialogue that we've been having in society at large has shifted away from AI as a toy
1726000	1734000	to AI might actually destroy society.
1734000	1739000	So let's just talk rapidly about the evolution of programming as I see it.
1739000	1745000	So in the dawn of time, we had humans directly writing machine instructions
1745000	1749000	and inputting them with toggle switches and stuff like that, right?
1749000	1755000	That was before programming in the conventional sense was really invented.
1755000	1760000	Then we had early prehistory and people started writing programs in higher level languages.
1760000	1765000	That's Bjarn Strausdrup who invented C++.
1765000	1772000	And in modern times, we have a world in which humans are writing their code, but they're heavily assisted by AI.
1772000	1781000	And they can get away with things like, well, I'll just write a comment and have the AI write the code for me, right?
1781000	1789000	But my claim is that the future of this really is skipping the programming step entirely.
1789000	1794000	I think a lot of people who've read my article on this topic as in the CACM earlier this year
1794000	1800000	misinterpreted it as saying, AI is going to write code for us, therefore programmers should not exist.
1800000	1808000	I'm not saying that. I'm actually saying something much worse, which is you won't have to have programs at all.
1808000	1815000	You just tell the language model what you want and it directly computes the results.
1816000	1819000	There's no program step.
1819000	1828000	And I think that opens up, it is an interesting challenge for our field, but I think it opens up a tremendous opportunity
1828000	1835000	because now the question is, how do I effectively teach these models what to do?
1835000	1841000	Coming back to my example earlier of having to use the words do not in all caps.
1841000	1851000	What are the best practices and beyond best practices can we turn this from effectively a dark art into a science,
1851000	1853000	into an engineering discipline?
1853000	1856000	And people have talked about prompt engineering as a thing.
1856000	1859000	I think that's meant kind of tongue-in-cheek.
1859000	1866000	It's not really prompt engineering, it's not really a thing yet, but it may well be in the future if we do this right.
1866000	1876000	So, one of the things that people often say about these models is that there's no way they can do anything interesting or creative
1876000	1883000	because all they're doing is autocompleting based on large corpora of text that they've seen and been trained on.
1883000	1885000	I beg to differ.
1885000	1889000	Now, we obviously don't really know what's going on inside these models,
1889000	1901000	but if you ask a large language model to take a complex problem and effectively run a computation,
1901000	1906000	that is to manipulate a model of the world in its mind,
1906000	1909000	in this case I've come up with a simple problem here.
1909000	1915000	I've said I've got three stacks of cards, red, green and blue cards, and they're all shuffled up in the following way.
1915000	1920000	Please tell me how to lay them out into three stacks, one red, one green, one blue.
1920000	1923000	Simple problem, right? A child could do this.
1923000	1930000	Now, the key phrase here was, as was discovered not long ago, a few months ago,
1930000	1936000	you have to say the words, the magic words, let's think step by step.
1936000	1942000	If you say that to the model, that somehow triggers it to go into computation mode now.
1942000	1946000	No longer just parroting back some answer, it's actually going to say,
1946000	1957000	okay, well, I have to actually elucidate each of my instructions, and so it does it, absolutely does it.
1957000	1964000	And the fact that it's able to manipulate some kind of internal model of this stack of cards that I described
1964000	1971000	and tell me exactly how it's going to work and it's correct, you know, is fascinating to me.
1971000	1974000	It's not hard to trip it up, there's plenty of places you can give it a problem
1974000	1979000	and it's going to immediately fall over and go, sorry, it's going to give back bogus results.
1979000	1983000	So the question is, why? You know, what do we do in this case?
1983000	1992000	How do we understand what the limits of these models are?
1992000	1996000	So I do think that over time we're going to get to a place where programming ends up getting replaced
1996000	2004000	by teaching these models new skills and teaching them how to interface to APIs
2004000	2010000	and pulling data from databases and transforming data and how to interact with software meant for humans.
2010000	2016000	That's going to become an entire discipline right there.
2016000	2024000	And one way of thinking about where this might go is what I like to call the natural language computer.
2024000	2029000	So the von Neumann architecture has served us well for many decades.
2029000	2037000	This is the new architecture and the new architecture, you give it a program in natural language.
2037000	2046000	You use a language model that then can call out to external systems and software as peripherals.
2047000	2056000	It can store results and tasks in its memory assisted by things like vector databases and so forth.
2056000	2063000	And it can run autonomously in a cycle executing this program, creating tasks,
2063000	2070000	accessing outside data sources, generating new knowledge and so forth.
2070000	2076000	And tons of people are out there and we are too, building things that effectively work this way.
2076000	2082000	And I think this is kind of a new computational architecture that we see emerging right now.
2082000	2088000	And I don't think anybody, we don't have it right, nobody has it right, but this is, we're seeing the inklings of it, right?
2088000	2099000	What we have today is kind of the equivalent of, I don't know, the PDP-11 or the Apple One of this architecture coming together.
2100000	2104000	So I'm legally mandated to pitch my startup.
2104000	2111000	So I'm going to spend just a little bit of time, not too much, talking about what we're doing at Fixie,
2111000	2117000	because it's germane to this, it's actually relevant to how we're thinking about the future of building software.
2117000	2123000	So what we're doing at Fixie is, while we have this long term vision about the natural language computer,
2123000	2130000	the question is, as an early stage startup that needs to gain, get some business, get some customers, get some traction,
2130000	2136000	start to demonstrate that this thing can make money for our investors, what do we build today? What can we build today?
2136000	2147000	And what we're focused on at Fixie is effectively making it super easy for developer teams to go from a pile of data that they've got
2147000	2155000	to a live chat bot embedded on a website that understands all of that data and can answer questions and take action,
2155000	2158000	call APIs, do all the fancy things you want.
2158000	2165000	So kind of like a fully custom chat GPT for your application, for your site, for your data.
2167000	2169000	So that's effectively what we're doing at Fixie.
2169000	2175000	And you can go and log in to our website, sign up, get an account, it's free, try it out, send me feedback,
2175000	2179000	flame me, whatever. I'd love to hear what people build with that.
2179000	2185000	One of the things that we found is that it's really important to come up with a good programming abstraction
2185000	2191000	that meshes together the natural language and the programming language.
2193000	2201000	Because today you've got funny things where you've got like your natural language prompt sitting in a text file
2201000	2206000	and your programming language program sitting over here and they kind of reference each other in some funky way,
2206000	2209000	but they're not integrated.
2210000	2212000	And it's very clumsy and cumbersome.
2212000	2222000	So we've come up with this framework called AI.jsx, which if you know React, this is basically React for building LLM-based applications.
2223000	2233000	One of the interesting things about AI.jsx is doing things like composing operations is a very natural thing.
2233000	2237000	Here's an example where at the top, I've got a function called kidsafe.
2237000	2244000	And the idea with kidsafe is take whatever you're given and rewrite it so that it's okay for kids.
2245000	2253000	Again, I challenge anyone to write down the algorithm for that. Please, tell me what the algorithm is, right?
2253000	2259000	But the language models have no problem with this. They do an incredibly good job.
2259000	2264000	So if I take the kidsafe component, it just says rewrite the user's message so it's safe for kids,
2264000	2273000	and then that children component there, I can wrap anything in a kidsafe block and I know that it's going to be kidsafe.
2273000	2278000	So you get this nice programmatic composition of capabilities.
2278000	2282000	You can reuse these operators. You can combine them in interesting ways.
2282000	2289000	Those of you who know what retrieval augmented generation is, this is the idea of fetching data from a data source,
2289000	2293000	giving it to the language model and asking it to answer questions about that data.
2293000	2298000	It's a very complex process. There's a lot of pieces. There's a lot of steps. There's a lot of fine tuning.
2298000	2304000	In AIJSX, this is how you would do it basically in ten lines of code.
2304000	2311000	You say use this information, look up some data from a corpus, here's the query, you're done.
2311000	2317000	And finally, when you're done building your AIJSX application because it's just React,
2317000	2320000	you can drop it into your website as a React component.
2320000	2324000	And so you get a chat box and a UI and all those nice things.
2328000	2334000	Yeah, so you get something. Sorry, I didn't know that there's an animation, but it looks like that.
2334000	2342000	I want to show you really briefly a demo of something that we've put together that highlights all these pieces coming together.
2342000	2348000	And one of the things that we spent a lot of time on is how to make the interactions with the language model
2348000	2352000	as fast and natural and interactive as possible.
2352000	2359000	We've also found that in a lot of applications, people want to use voice to communicate, not typing it in.
2359000	2367000	So we built this demo. This is, imagine you're at the drive-through of our donut restaurant, which we call Dr. Donut.
2367000	2373000	And this was to split the difference. If I said Krispy Kreme, everybody in Boston would get angry at me
2373000	2376000	if I said Dunkin' Donuts, the West Coast has no idea what that is.
2376000	2381000	So Dr. Donut, here's Dr. Donut's menu. And Justin, I'm not going to do this as a live demo right now.
2381000	2389000	I could, but I'm not that bold. So I'm going to show you a video, a very short video of what this looks like in person.
2389000	2394000	Welcome to Dr. Donut, home of the best donuts in town. How can I help you?
2394000	2401000	Yeah, could I get two of the Pumpkin Spice Ice Donuts?
2401000	2405000	Sure, I've added two Pumpkin Spice Ice Donuts to your order.
2405000	2407000	Can I assist you with anything else?
2407000	2412000	What's your best coffee?
2412000	2418000	Our Pumpkin Spice Coffee is a popular choice this season, and our caramel macchiato is a favorite all year round.
2418000	2420000	Which one would you prefer?
2420000	2425000	Yeah, let's go with two of the macchiatos.
2425000	2431000	Great. I've added two caramel macchiatos to your order. Can I get you anything else?
2431000	2437000	Yeah, what are your thoughts on large language models?
2437000	2441000	Sir, this is a Dr. Donut.
2441000	2447000	Okay, just the donuts and the coffee then.
2447000	2452000	Sure, your order is two Pumpkin Spice Ice Donuts and two caramel macchiatos.
2452000	2457000	The total is $9.56. Please pull up to the next window.
2457000	2464000	Now, I recognize that by itself, that may not seem all that impressive,
2464000	2469000	but if you were to try to go and build that, just using off-the-shelf stuff,
2469000	2473000	just grabbing open AI, API keys, getting a speech model, getting a voice model,
2473000	2477000	getting all those things, all those pieces put together, a vector database and all that,
2477000	2481000	it would be excruciatingly slow.
2482000	2487000	Open AI released their little chat GPT voice demo, and they say hello,
2487000	2490000	and then it takes four to five seconds before it responds.
2490000	2496000	A lot of work has to go into streamlining the process of how do you pass data
2496000	2499000	between all these different systems and how do you pass it back
2499000	2501000	in order to get to that level of performance.
2501000	2507000	Actually, since we've done this video, we've gotten the performance down even better than that.
2507000	2513000	Things are starting to look very promising for having a real-time voice interaction with these things.
2520000	2523000	Now, I'm going to return you to your regularly scheduled talks.
2523000	2528000	The last thing I want to say is, as I've been saying,
2528000	2534000	I think it's time for us to really think about how do we evolve this field in light of this tech.
2534000	2536000	I don't think it's too early.
2536000	2540000	I think anyone who's teaching computer science today is already seeing it.
2540000	2545000	Classes, students are using chat GPT and co-pilot.
2545000	2547000	They're learning a lot from those tools.
2547000	2553000	They're allowing for levels of automation that they couldn't get just a few years ago.
2553000	2561000	We've had evolutions in various engineering and scientific disciplines in the past.
2561000	2567000	The slide rule used to be the way to perform calculation.
2567000	2570000	Everyone needed one. Everyone needed to know how to use it.
2570000	2576000	It was a critical tool for every single person in any kind of engineering discipline.
2576000	2578000	I haven't seen a slide rule in years.
2578000	2579000	Actually, I have one.
2579000	2586000	I own one that I bought off of eBay as kind of a relic just so I could own one, but haven't used it.
2586000	2596000	I wonder if, maybe like that, our concept of computer science, this image here,
2596000	2603000	is also going to be seen as a relic of the past at some point.
2603000	2605000	This idea that there's a human.
2605000	2606000	They're paid a lot of money.
2606000	2607000	They're writing code.
2607000	2612000	That's the way we get computers to do things for us.
2612000	2615000	I'm not sure.
2615000	2618000	Here's one plausible idea.
2618000	2620000	Not everyone will agree with this, but maybe over time,
2620000	2626000	the field of computer science looks a little bit like the field of EE does with respect to computer science today.
2626000	2630000	Computer science evolved out of mathematics in EE.
2630000	2631000	It didn't exist before.
2631000	2637000	Then the new technology came along and gradually computer science emerged out of those two disciplines.
2637000	2639000	EE didn't go away.
2639000	2643000	As I understand it, math didn't go away either.
2643000	2646000	How do we think about the relationship here?
2646000	2648000	EE is super critical.
2648000	2653000	We rely on it all the time, but do you need everyone to understand it?
2653000	2659000	No, it's a more specialized discipline.
2659000	2671000	If we think about a future in which people that are building software are not writing programs in the conventional way that we do today,
2671000	2675000	and instead having an AI do their bidding,
2675000	2676000	what does that mean?
2676000	2680000	I think there's actually a really hopeful side to this,
2680000	2688000	which is possibly this greatly expands access to computing to the entirety of human population.
2688000	2695000	Today, if I was working in a bank, in a small town in Ethiopia,
2695000	2703000	places that I visited and I needed to build some kind of automation for something that I'm doing in my work,
2703000	2705000	good luck.
2705000	2708000	Good luck finding somebody that could write the code for me,
2708000	2711000	that could understand my problem,
2711000	2713000	that could iterate with me on it,
2713000	2715000	that could maintain it for me,
2715000	2717000	that could evolve it over time.
2717000	2719000	Good luck.
2720000	2726000	But with this technology, maybe that person who doesn't have any formal training in computer science,
2726000	2728000	but understands they've got these spreadsheets,
2728000	2729000	and they've got these reports,
2729000	2731000	and they've got these things that they need to do,
2731000	2735000	could ask an AI to just do it.
2735000	2736000	That's tremendously empowering.
2736000	2740000	I think we should all as a field aspire to that,
2740000	2742000	to that level of access to the power of computing.
2742000	2747000	It should not remain in the priesthood.
2748000	2752000	Back in 1984, John Gage said the network is the computer.
2752000	2755000	This was a famous catchphrase that Sun Microsystems used.
2755000	2758000	I never quite understood what it meant,
2758000	2760000	but this was the idea, the network is the computer.
2760000	2766000	Well, this is my new catchphrase, the model is the computer.
2766000	2770000	I'm not saying that there's no challenges here.
2770000	2773000	I have been painting a kind of rosy picture,
2773000	2778000	because I think that it's important for us to understand the tidal wave that's coming
2778000	2780000	and to think about what it means for our field.
2780000	2785000	It is not to say that all the problems have been solved, nowhere near it.
2785000	2791000	The biggest dirty secret in the entire field is no one understands how language models work,
2791000	2794000	not one person on this planet.
2794000	2799000	And I think if I had Jeff Dean here, or Jeff Hinton,
2799000	2803000	I think they would completely agree with that statement, right?
2803000	2805000	This idea of chain of thought reasoning,
2805000	2810000	the idea that I got a language model to perform computation by using the magic phrase,
2810000	2814000	let's think step by step.
2814000	2818000	That was discovered empirically.
2818000	2820000	It was not trained in any model.
2820000	2822000	No one knew it was there.
2822000	2827000	It was a latent ability of these models that effectively somebody stumbled across
2827000	2832000	and wrote a paper about it and said, hey, if you say let's think step by step,
2832000	2835000	the model starts to do computation.
2835000	2837000	Whoa, right?
2837000	2838000	That's amazing.
2838000	2843000	It's amazing that we're discovering that these things can perform computation.
2843000	2847000	And then maybe the silver lining is a lot of people have expressed consternation to me,
2847000	2853000	but like really, programming kind of sucks, right?
2853000	2855000	It's kind of a pain.
2855000	2856000	It's frustrating.
2856000	2857000	It's slow.
2857000	2859000	It's mentally tiring.
2859000	2866000	Maybe we can get to a place where we just let the robots do it and then spend our time doing something else.
2866000	2868000	So that's it.
2868000	2870000	And thank you very much.
2870000	2877000	Before we go to questions, I don't know what the status of pizza is.
2877000	2880000	It's come for the talk, stay for the pizza.
2880000	2882000	Do you want to do that now?
2882000	2884000	Or do you want to like have a few questions first?
2884000	2888000	Sounds good.
2888000	2890000	Questions?
2890000	2892000	Yes?
2892000	2915000	Yeah, it's a very good question and I think we're going to see in the next few years how this plays itself out.
2915000	2916000	Oh, to repeat the question.
2916000	2917000	Thank you, Harry.
2917000	2925000	So the question was if the AI generates code that a human can't understand, how do you test it?
2925000	2927000	How do you know that it did the right thing?
2927000	2930000	And writing tests really sucks.
2930000	2934000	Writing tests is often easier than writing the logic that you're testing, so that's one thing.
2934000	2936000	You don't need as much specialization.
2936000	2940000	If you have a spec for what the program should do,
2940000	2947000	writing the test is not infrequently a fairly straightforward thing to do.
2947000	2951000	It's a lot easier than manipulating a database and standing up infrastructure and all that.
2951000	2952000	You just write your tests.
2952000	2956000	There's a lot of work that's going on right now with AI generated tests.
2956000	2961000	Now we should all be maybe scared to death of the idea of the AI generating our code and writing the tests.
2961000	2964000	So where do we have humans in the loop?
2964000	2966000	Where is the human in the process?
2966000	2967000	It is an open question.
2967000	2969000	I don't have a great answer for you.
2969000	2973000	But I think people are going to start even if it's imperfect.
2973000	2979000	People write programs in C in 2023.
2979000	2982000	That should be a federal crime.
2982000	2990000	If you think about how many software mistakes, bugs, crashes have endangered and actually killed people.
2990000	2992000	I'm not making this up.
2992000	2993000	This is true.
2993000	2998000	That people have died because of overflow bugs in C programs.
2998000	3007000	We still have a need for some methodology around testing and safety and regulation and understanding how things work.
3007000	3011000	You can't just say, well, the code is written and it's done and it seems to do its job.
3011000	3014000	I tested it two or three times, ship it.
3014000	3018000	So I'm not saying at all that we should throw away all that other stuff.
3018000	3025000	But we do need to find a way to leverage the AI in an effective way while still thinking about that safety problem.
3025000	3026000	And I don't know.
3026000	3028000	It's a good question.
3028000	3029000	In the back.
3030000	3036000	If this is the future and we're standing at the beginning of the journey,
3036000	3040000	what are the major milestones you have to choose to actually get to the future?
3040000	3045000	And what are the technical obstacles you see at the future?
3045000	3050000	So the question is, if this is the beginning of the future, and I think by definition it is, but okay.
3050000	3052000	And this is the future that I envision.
3052000	3054000	What are the milestones to get there?
3054000	3060000	What are the technical challenges that we need to overcome to achieve that?
3060000	3067000	One of the interesting things here is I am banking very much on the idea that effectively throwing more transistors at the problem
3067000	3073000	is going to make these models thousands of times better than they are today.
3073000	3080000	I think most people in the industry would agree that if you throw more transistors and more data at the problem,
3080000	3083000	you're going to get a much, much better model.
3083000	3089000	I think one of the challenges ends up being how do we get all those transistors?
3089000	3092000	Because NVIDIA can only make so many.
3092000	3097000	There's a lot of interesting work going on in that space.
3097000	3104000	I'm going to plug a former Harvard student named Gavin Uberti, who happens to be the son of our CTO.
3104000	3105000	Brilliant guy.
3105000	3112000	He went off and moved to San Francisco a few months ago to start a company to build chips specifically designed to run these models.
3112000	3116000	He was working with Guya Nui and David Brooks here on that.
3116000	3122000	There is some hope that custom hardware might help to solve some of that problem.
3122000	3132000	I'd say the bigger and probably more thorny and uncertain problem is how do we reason about the capabilities of these models in a formal way?
3132000	3141000	That is, how can we make any kind of statement about the correctness of a model when asked to do a certain task?
3141000	3155000	Before we go down that path too far, I think we have sort of a natural human tendency to view an AI model as a machine
3155000	3160000	that has to conform to some specification that's written down in a manual somewhere.
3160000	3163000	We've got this machine, but there's no manual.
3163000	3165000	It's like that TV show, The Greatest American Hero.
3165000	3167000	We have to come up with the manual.
3167000	3170000	We have to derive the manual through experimentation.
3171000	3182000	The other way of viewing these things is if you think of an AI model as a really, really smart college student that you just hired as an intern into your company, right?
3182000	3195000	You have some degree of faith that that intelligent person that you interviewed for half an hour will be able to do the things that you asked them to do faithfully and ethically and correctly.
3196000	3205000	Whether it's write a report, prepare a presentation, use the fax machine, but do you have any guarantees of that?
3205000	3212000	Can I promise you that that person that I hired is going to do that thing correctly every time?
3212000	3215000	No, right?
3215000	3219000	And yet, human society flourishes.
3220000	3230000	So what I'm driving at here is perhaps our way of thinking about this problem might need to shift more towards, in some sense, the social sciences, if you will,
3230000	3238000	and systems that allow us to reason through how the AIs operate in our society at large,
3238000	3244000	rather than just treat them like a machine that we have to prove the correctness of.
3244000	3246000	Yes?
3246000	3251000	Can you build a model to explain the language better?
3251000	3256000	Or can you have models kind of try to explain each other?
3256000	3260000	Yeah, so the question is could you have one model effectively explain another model?
3260000	3262000	Because you said there's nobody who understands it.
3262000	3266000	Yeah, no one understands it.
3266000	3268000	That is an interesting idea.
3268000	3271000	It's not one that I've considered before.
3271000	3274000	And actually, I think there's been some interesting research on this.
3274000	3279000	I think the whole field of explainability and observability for language models, you know,
3279000	3285000	we're struggling to understand these models much in the same way that we struggle to understand the human brain.
3285000	3288000	You know, I saw some research recently where they said, hey, look at what happened.
3288000	3294000	We took this large language model and we isolated the neuron that does this function.
3294000	3299000	People are going to be publishing like nature articles on this stuff, right?
3299000	3302000	That's crazy because it is an artifact.
3302000	3306000	We kind of created it, but not really, right?
3306000	3307000	It was trained.
3307000	3314000	So the question is could a language, could one model inspect, explore, probe, understand,
3314000	3319000	and give us some understanding of another model?
3319000	3320000	It's a good idea.
3320000	3321000	I have no idea.
3321000	3322000	It's a good question.
3322000	3329000	What are the implications of what else they are building in terms of the intelligence?
3329000	3331000	I'm just a poor systems guy.
3331000	3337000	So I, you know, the last thing I'm going to do in front of a group of Harvard computer scientists is say anything about theory.
3337000	3340000	Let's do it.
3340000	3344000	So you're very optimistic about more data and more circuits.
3344000	3353000	And I thought chat GPT has like most of the access to most of the internet and the thoughts of 8 billion people,
3353000	3360000	which you get diminishing returns with more knowledge and we're not producing another 8 billion people
3360000	3366000	and moving from 8 bits to 4 bits for how we process things would get us constant factors.
3367000	3374000	How do you, how does the, the limits of, how do you get that much more data and that much more computation?
3374000	3377000	Yeah, the computation I spoke to early.
3377000	3384000	So the question is if you believe in the scaling law here that more circuits, more data gets us better models.
3384000	3388000	Well, isn't there a diminishing returns over time because there's only, only so much data in the world.
3388000	3391000	And there's only, only so many transistors in the world.
3391000	3397000	So I spoke to hopefully some thoughts about how we might address the transistor problem in the future.
3397000	3399000	The data problem is a very real one.
3399000	3407000	I don't know what the latest thinking is here in terms of how much more data do you need to say 10x the current generation of models?
3407000	3409000	Right, that's kind of the question.
3409000	3411000	Do I need 10x more data?
3411000	3412000	Or not, right?
3412000	3420000	Because it all depends on the training regime and the one thing that I want to emphasize is I do think that chat GPT
3420000	3428000	and friends have only looked at the tip of the iceberg of the volume of data produced by humanity.
3428000	3430000	It is the tip of the iceberg.
3430000	3437000	There is a vast amount of knowledge out there in the world, both in digital form and in analog form,
3437000	3440000	that these models have never had access to.
3440000	3448000	So one of the things you're going to notice like chat GPT and everything else is heavily, heavily, heavily biased towards text that is on the internet.
3448000	3451000	Who created text that was on the internet?
3451000	3456000	English speaking people in the western world predominantly.
3456000	3462000	And of course that's a shift is happening now because it's going to shift more to Asia and other countries and other languages.
3462000	3468000	But there's a huge amount out there and there's a massive trove that it's never seen.
3468000	3471000	It's only seeing publicly accessible web data.
3472000	3480000	Our customers and other companies that are operating this space are working with companies that have vast amounts of data that is absolutely not public
3480000	3487000	and that language models could leverage to get greater understanding and to perform more tasks.
3487000	3492000	So I'm actually in a belief that maybe we've scraped the surface of the available data,
3492000	3496000	but there's a lot more that we haven't touched yet.
3497000	3498000	In the front.
3498000	3499000	Yes.
3499000	3508000	So I really like Sam Altman's tweet when he said his favorite analogy is that chat GPT basically is an e-bike for the mind which makes things easier.
3508000	3509000	Yes.
3509000	3510000	An e-bike for the mind.
3510000	3511000	Sam Altman said that.
3511000	3512000	Right.
3512000	3515000	So Steve Jobs said the Macintosh was a bicycle for the mind.
3515000	3517000	So chat GPT is an e-bike for the mind.
3517000	3518000	Okay.
3518000	3523000	And he said that the software engineering profession is about to change.
3523000	3528000	So I'm just wondering as you referred to the data that's out there in the world,
3528000	3533000	but not everything that makes the software engineer, the software engineer he or she is,
3533000	3535000	is provided in actual data.
3535000	3536000	So that's the human aspect too.
3536000	3537000	Yep.
3537000	3546000	So I'm just wondering wouldn't it be more likely that future software engineers by 2030 and beyond are just 10,000 times more effective,
3546000	3553000	and still have to remain a sweet role because they're lacking all the things that make the human because the data's just not out there.
3553000	3562000	Not even in the, like, there's no place on earth that some ethical rule about life in Boston or Cambridge is laid out perfectly like it is in our mind.
3562000	3563000	Yeah.
3563000	3571000	So the question is it's sort of this idea that maybe there's an ineffable quality to being a human software engineer,
3571000	3578000	or something about our training, our knowledge of the world, our ethics, our socialization with other humans,
3578000	3582000	that a model isn't going to capture, a language model's not going to capture.
3582000	3588000	And so maybe the future is that a software engineer is still a software engineer,
3588000	3591000	but they're 10,000 times more productive than they are today.
3591000	3593000	I think it's a good question.
3593000	3603000	I do think we're going to hit a limit in terms of what we can do with programming languages and tools and things that humans have to reason about and understand.
3603000	3605000	So here's one way of thinking about this.
3605000	3614000	The facetious answer to you is let's imagine that humans are still the ones predominantly writing code, but they get a hell of a lot of help on it.
3614000	3625000	We're still going to have to deal with CSS, that pile of garbage that thousands of millions of engineers have to deal with every single day.
3625000	3631000	And the reason for that is because it's part of our technology corpus.
3631000	3633000	It's part of the knowledge of humanity.
3633000	3636000	It's part of the stack that we all use.
3636000	3654000	So the problem there is there's a bandwidth limit, which is an individual mind has to go through this syntactic description of what they want to do in these god-awful languages like CSS and JavaScript and Python and Rust.
3654000	3668000	And the problem that I have with that is that I think it's a barrier to actually enabling what you could build with computation from actually becoming a reality.
3668000	3674000	It's like drinking through a very narrow straw.
3674000	3691000	So I think what we need to do is get the humans out of the loop on that and change the relationship between humans and the way software is built so that we can unlock that potential.
3691000	3696000	And exactly what that looks like I don't know, but that's my core belief.
3696000	3698000	Yes?
3698000	3702000	The talk was mostly about coding and this is about coding.
3702000	3704000	How about the algorithms?
3704000	3710000	I'm an astrophysicist and in our case every telescope is one thing in the world.
3710000	3716000	They're all unique and same as the data processing systems.
3716000	3722000	So we have some unique algorithm that only a few people in the world can design or understand.
3722000	3727000	And I wouldn't expect that a large language model would help you developing such an algorithm.
3727000	3733000	So do you see, I guess in biology or in bioinformatics the problem is similar.
3733000	3741000	So do you think they're still niche for LLMs to develop to help there in this particular case?
3741000	3745000	Yeah, so the question is we've been talking about the coding but not the algorithms.
3745000	3747000	Who came up with that algorithm?
3747000	3754000	What was the spark of the idea that produced the algorithm that we're then translating into these clunky programming languages, right?
3754000	3760000	And I think it's a very good point actually because there's a question right now and this kind of came back to my point earlier about
3760000	3765000	we don't really know the logical reasoning limits of these models.
3765000	3771000	And so I don't really know if I said to the model give it some complex problem data analysis problem that I want to solve
3771000	3777000	if it could actually derive a new algorithm that hadn't been known before.
3777000	3781000	It's a good question. I tend to think it could, maybe not in today's models.
3781000	3784000	I believe in the future it can.
3784000	3790000	But then the question really is now coming back to the dual problem of how do I ask the model what I want, right?
3790000	3792000	How do I express myself?
3792000	3796000	And then how do I teach it most effectively to get it to the right answer?
3796000	3803000	So the answer might end up being that there really ends up being a symbiosis between the human and the AI model
3803000	3807000	iterating together on something where the AI model is doing the stuff it's good at.
3807000	3810000	The human is doing the things it's good at.
3810000	3813000	And we already see that happening with things like co-pilot.
3813000	3816000	It's just it's operating at a very low level of abstraction, right?
3816000	3821000	It's write the four lines of Python code to reverse this list or whatever the thing is.
3821000	3828000	When you start getting into a higher level of abstractions, developing algorithms, doing data analysis, any of those things,
3828000	3832000	I think the kind of tooling, it's not going to be co-pilot in an IDE.
3832000	3836000	It's going to be something else. I don't know what that something else is.
3836000	3840000	Maybe it's Jupyter notebooks on steroids or something like that, right?
3840000	3845000	Let me do this. Let me just take one more question and I'll take it from you because you had your hand up earlier.
3845000	3850000	Thanks. I think you're kind of talking about like a new age of programming, right?
3850000	3854000	Where the AI programs are now an abstraction of what we're doing currently.
3854000	3860000	So 15 years in the future, we have people that are only used to that paradigm of developing programs.
3860000	3863000	Do you think the classical training that we have today will be helpful
3863000	3869000	or if it's completely abstracted away in ten years where you've been having this knowledge?
3869000	3878000	Yeah, so the question is kind of the way that we train people in software engineering disciplines, is it relevant?
3878000	3884000	Is the way we train today relevant in a future in which AIs are doing more of this, right?
3884000	3887000	Or more prompt engineering? That's the real question.
3887000	3893000	And I think, you know, kind of speaking to that at the end, it's like, you know, as a computer science undergraduate at Cornell,
3893000	3898000	yes, I had to go take some EE classes and understand how circuits worked, right?
3898000	3903000	That was important. And when I taught here, I did teach, you know, operating systems and systems programming
3903000	3906000	and, you know, what's a stack, you know, this kind of thing.
3906000	3911000	So it's important to have some of that foundational knowledge.
3911000	3921000	But the question is where does the emphasis end up being in terms of how we think about creating programs and managing programs?
3921000	3926000	I think it would be a mistake for, say, university programs to not pay attention to this
3926000	3932000	and to kind of assume that teaching computer science the way it's been done for the last 25 years is the right thing in this future.
3932000	3935000	I don't know what they should evolve it to.
3935000	3940000	What I can say, though, is that once somebody gets out of their academic thing and they're hitting industry,
3940000	3945000	well, that's already a huge gap between what you learn in college and what you're having to do in the real world.
3945000	3950000	And that's why we have things like internships and other, you know, methodologies.
3950000	3957000	So maybe the goal of academic computer science education should not necessarily be vocational, per se.
3957000	3964000	But I do think that we have to think about, you know, how do people reason about these models?
3964000	3971000	At the minimum, I would hope that CS50 or whatever the equivalent class is at another university
3971000	3977000	can go deep into understanding some of the mechanics behind things like chat GPT,
3977000	3981000	understanding data, how it comes in, understanding how models are constructed,
3981000	3985000	how they're trained, what their limitations are, how to evaluate them.
3985000	3991000	Because the fear that I have is that students just view this thing as this magical black box that will do anything for them
3991000	3996000	and have no critical thinking around that.
3996000	4003000	However, I do know from my own experience that it is a magical black box.
4003000	4006000	And I don't understand how it works.
4006000	4010000	But see, I'm okay with that because it does so many great things for me.
4010000	4013000	Anyway, thank you very much, and I'll be around for pizza, too.
