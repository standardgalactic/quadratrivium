1
00:00:00,000 --> 00:00:01,560
All right.

2
00:00:01,560 --> 00:00:03,560
Well, this is CS50 Tech Talk.

3
00:00:03,560 --> 00:00:04,920
Thank you all so much for coming.

4
00:00:04,920 --> 00:00:06,960
So about a week ago, we circulated the Google Form,

5
00:00:06,960 --> 00:00:09,660
as you might have seen, at 10.52 AM.

6
00:00:09,660 --> 00:00:12,600
And by, like, 11.52 AM, we had 100 RSVPs,

7
00:00:12,600 --> 00:00:14,680
which I think is sort of testament to just how much interest

8
00:00:14,680 --> 00:00:18,100
there is in this world of AI, and open AI, and GPT, chat

9
00:00:18,100 --> 00:00:19,200
GPT, and the like.

10
00:00:19,200 --> 00:00:21,840
And in fact, if you're sort of generally familiar with what

11
00:00:21,840 --> 00:00:24,320
everyone's talking about, but you haven't tried it yourself,

12
00:00:24,320 --> 00:00:26,680
this is the URL, which you can try out this tool

13
00:00:26,680 --> 00:00:29,120
that you've probably heard about, chat GPT.

14
00:00:29,120 --> 00:00:30,680
You can sign up for a free account there

15
00:00:30,680 --> 00:00:32,800
and start tinkering with what everyone else has been

16
00:00:32,800 --> 00:00:33,640
tinkering with.

17
00:00:33,640 --> 00:00:36,400
And then if you're more of the app-minded type, which you probably

18
00:00:36,400 --> 00:00:39,720
are if you are here with us today, open AI in particular

19
00:00:39,720 --> 00:00:43,240
has its own low-level APIs via which you can integrate AI

20
00:00:43,240 --> 00:00:44,560
into your own software.

21
00:00:44,560 --> 00:00:46,920
But of course, as is the case in computer science,

22
00:00:46,920 --> 00:00:49,040
there's all the more abstractions and services

23
00:00:49,040 --> 00:00:51,200
that have been built on top of these technologies.

24
00:00:51,200 --> 00:00:53,840
And we're so happy today to be joined by our friends

25
00:00:53,840 --> 00:00:56,280
from McGill University and Steamship,

26
00:00:56,320 --> 00:00:58,720
Sill and Ted, from whom you'll hear in just a moment,

27
00:00:58,720 --> 00:01:02,160
to speak to us about how they are making it easier to build,

28
00:01:02,160 --> 00:01:04,680
to deploy, to share applications using some

29
00:01:04,680 --> 00:01:05,960
of these very same technologies.

30
00:01:05,960 --> 00:01:08,240
So our thanks to them for hosting today.

31
00:01:08,240 --> 00:01:10,080
Our friends at Plimpton, Jenny Lee and alumna,

32
00:01:10,080 --> 00:01:12,120
who's here with us today, but without further ado,

33
00:01:12,120 --> 00:01:13,840
allow me to turn things over to Ted and Sill.

34
00:01:13,840 --> 00:01:18,000
And pizza will be served shortly after 1 PM outside.

35
00:01:18,000 --> 00:01:19,760
All right, over to you, Ted.

36
00:01:19,760 --> 00:01:21,400
Thanks a lot.

37
00:01:21,400 --> 00:01:23,280
Hey, everybody, it's great to be here.

38
00:01:23,280 --> 00:01:25,800
I think we've got a really good talk for you today.

39
00:01:25,800 --> 00:01:28,080
Sill's gonna provide some research grounding

40
00:01:28,080 --> 00:01:30,920
into how it all works, what's going inside,

41
00:01:30,920 --> 00:01:34,120
the brain of GPT as well as other language models.

42
00:01:34,120 --> 00:01:36,000
And then I'll show you some examples that we're seeing

43
00:01:36,000 --> 00:01:38,240
on the ground of how people are building apps

44
00:01:38,240 --> 00:01:40,380
and what apps tend to work in the real world.

45
00:01:40,380 --> 00:01:43,480
So our perspective is we're building AWS for AI apps.

46
00:01:43,480 --> 00:01:45,160
So we get to talk to a lot of the makers

47
00:01:45,160 --> 00:01:46,600
who are building and deploying their apps.

48
00:01:46,600 --> 00:01:48,920
And through that, see both the experimental end

49
00:01:48,920 --> 00:01:51,800
of the spectrum and also see what kinds of apps

50
00:01:51,800 --> 00:01:53,720
are getting pushed out there and turned into companies,

51
00:01:53,720 --> 00:01:55,520
turned into side projects.

52
00:01:55,560 --> 00:01:59,200
We did a cool hackathon yesterday.

53
00:01:59,200 --> 00:02:02,000
Many thanks to Neiman, to David Malin and CS50

54
00:02:02,000 --> 00:02:03,400
for helping us put all of this together,

55
00:02:03,400 --> 00:02:04,760
to Harvard for hosting it.

56
00:02:04,760 --> 00:02:07,920
And there were two sessions, lots of folks built things.

57
00:02:07,920 --> 00:02:11,100
If you go to steamship.com slash hackathon,

58
00:02:11,100 --> 00:02:12,400
you'll find a lot of guides,

59
00:02:12,400 --> 00:02:13,840
a lot of projects that people built.

60
00:02:13,840 --> 00:02:16,560
And you can follow along, we have a text guide as well,

61
00:02:16,560 --> 00:02:18,440
just as a quick plug for that,

62
00:02:18,440 --> 00:02:21,240
if you want to do it remotely or on your own.

63
00:02:21,240 --> 00:02:23,880
So to tee up Sill, we're gonna talk about

64
00:02:23,880 --> 00:02:27,160
basically two things today that I hope you'll walk away with

65
00:02:27,160 --> 00:02:29,840
and really know how to then use as you develop

66
00:02:29,840 --> 00:02:30,680
and as you tinker.

67
00:02:30,680 --> 00:02:33,160
One is what is GPT and how is it working?

68
00:02:33,160 --> 00:02:35,240
Get a good sense of what's going on inside of it

69
00:02:35,240 --> 00:02:38,280
other than as just this magical machine that predicts things.

70
00:02:38,280 --> 00:02:40,720
And then two is how are people building with it?

71
00:02:40,720 --> 00:02:42,800
And then importantly, how can I build with it too

72
00:02:42,800 --> 00:02:43,680
if you're a developer?

73
00:02:43,680 --> 00:02:45,800
And if you have CS50 background,

74
00:02:45,800 --> 00:02:47,160
you should be able to pick things up

75
00:02:47,160 --> 00:02:48,160
and start building some great apps.

76
00:02:48,160 --> 00:02:50,080
I've already met some of the CS50 grads yesterday

77
00:02:50,080 --> 00:02:51,800
and the things that they were doing were pretty amazing.

78
00:02:51,800 --> 00:02:53,000
So hope this is useful.

79
00:02:53,000 --> 00:02:54,320
I'm gonna kick it over to Sill

80
00:02:54,320 --> 00:02:59,280
and talk about some of the theoretical background of GPT.

81
00:02:59,280 --> 00:03:01,160
Yeah, so thank you, Ted.

82
00:03:01,160 --> 00:03:02,000
My name is Sill.

83
00:03:02,000 --> 00:03:04,560
I'm a graduate student of Digital Humanities at McGill.

84
00:03:04,560 --> 00:03:06,560
I study literature and computer science

85
00:03:06,560 --> 00:03:08,480
and linguistics in the same breath.

86
00:03:08,480 --> 00:03:10,520
And I've published some research over the last couple of years

87
00:03:10,520 --> 00:03:13,800
exploring what is possible with language models

88
00:03:13,800 --> 00:03:15,640
and culture in particular.

89
00:03:15,640 --> 00:03:19,760
And my half or whatever of the presentation

90
00:03:19,760 --> 00:03:21,880
is to describe to you what is GPT.

91
00:03:21,880 --> 00:03:24,240
That's really difficult to explain in 15 minutes.

92
00:03:24,240 --> 00:03:26,720
And there are even a lot of things that we don't know,

93
00:03:26,720 --> 00:03:28,040
but a good way to approach that

94
00:03:28,040 --> 00:03:30,200
is to first consider all the things

95
00:03:30,200 --> 00:03:33,320
that people call GPT by or descriptors.

96
00:03:33,320 --> 00:03:35,680
So you can call them large language models.

97
00:03:35,680 --> 00:03:38,000
You can call them universal approximators

98
00:03:38,000 --> 00:03:39,040
from computer science.

99
00:03:39,040 --> 00:03:42,440
You can say that it is a generative AI.

100
00:03:42,440 --> 00:03:44,040
We know that they are neural networks.

101
00:03:44,040 --> 00:03:46,440
We know that it is an artificial intelligence.

102
00:03:46,440 --> 00:03:48,160
To some, it's a simulator of culture.

103
00:03:48,160 --> 00:03:50,280
To others, it just predicts text.

104
00:03:50,320 --> 00:03:51,480
It's also a writing assistant.

105
00:03:51,480 --> 00:03:52,840
If you've ever used ChatGPT,

106
00:03:52,840 --> 00:03:55,000
you can plug in a bit of your essay, get some feedback.

107
00:03:55,000 --> 00:03:56,520
It's amazing for that.

108
00:03:56,520 --> 00:03:57,560
It's a content generator.

109
00:03:57,560 --> 00:04:00,760
People use it to do copywriting, Jasper.AI,

110
00:04:00,760 --> 00:04:02,200
pseudo-write, et cetera.

111
00:04:02,200 --> 00:04:03,640
It's an agent.

112
00:04:03,640 --> 00:04:05,160
So the really hot thing right now,

113
00:04:05,160 --> 00:04:08,480
if you might have seen it on Twitter, auto-GPT, baby-AGI,

114
00:04:08,480 --> 00:04:10,560
people are giving these things tools

115
00:04:10,560 --> 00:04:13,160
and letting them run a little bit free in the wild

116
00:04:13,160 --> 00:04:16,120
to interact with the world computers, et cetera.

117
00:04:16,120 --> 00:04:18,160
We use them as chatbots, obviously.

118
00:04:18,160 --> 00:04:21,840
And the actual architecture is a transformer.

119
00:04:21,840 --> 00:04:24,480
So there's lots of ways to describe GPT.

120
00:04:24,480 --> 00:04:27,760
And any of them is a really perfectly adequate way

121
00:04:27,760 --> 00:04:29,640
to begin the conversation.

122
00:04:29,640 --> 00:04:31,320
But for our purposes, we can think of it

123
00:04:31,320 --> 00:04:32,480
as a large language model,

124
00:04:32,480 --> 00:04:34,920
and more specifically, a language model.

125
00:04:34,920 --> 00:04:39,080
And a language model is a model of language,

126
00:04:39,080 --> 00:04:40,360
if you allow me the tautology,

127
00:04:40,360 --> 00:04:41,960
but really what it does is it produces

128
00:04:41,960 --> 00:04:44,760
a probability distribution over some vocabulary.

129
00:04:44,760 --> 00:04:47,520
So let us imagine that we had the task

130
00:04:48,040 --> 00:04:51,000
of predicting the next word of the sequence I am.

131
00:04:51,000 --> 00:04:55,360
So if I give a neural network the words I am,

132
00:04:55,360 --> 00:04:57,880
what of all words in English

133
00:04:57,880 --> 00:05:00,000
is the next most likely word to follow?

134
00:05:00,000 --> 00:05:04,680
That, at its very core, is what GPT is trained to answer.

135
00:05:04,680 --> 00:05:08,680
And how it does it is it has a vocabulary of 50,000 words,

136
00:05:08,680 --> 00:05:12,040
and it knows, roughly, given the entire internet,

137
00:05:12,040 --> 00:05:14,840
which words are likely to follow other words

138
00:05:15,840 --> 00:05:17,960
of those 50,000 in some sequence,

139
00:05:17,960 --> 00:05:21,200
up to 2,000 words, up to 4,000, up to 8,000,

140
00:05:21,200 --> 00:05:23,640
and now up to 32,000 GPT4.

141
00:05:23,640 --> 00:05:26,200
So you give it a sequence, here I am,

142
00:05:26,200 --> 00:05:29,120
and over the vocabulary of 50,000 words,

143
00:05:29,120 --> 00:05:32,480
it gives you the likelihood of every single word that follows.

144
00:05:32,480 --> 00:05:36,920
So here it's I am, perhaps the word happy is fairly frequent,

145
00:05:36,920 --> 00:05:38,360
so we'll get that high probability

146
00:05:38,360 --> 00:05:41,480
if we look at all words, all utterances of English.

147
00:05:41,480 --> 00:05:44,800
It might be I am sad, maybe that's a little bit less probable,

148
00:05:45,000 --> 00:05:46,880
I am school, that really should be at the end

149
00:05:46,880 --> 00:05:48,800
because I don't think anybody would ever say that,

150
00:05:48,800 --> 00:05:51,760
I am Bjork, that's a little bit, it's not very probable,

151
00:05:51,760 --> 00:05:53,720
but it's less probable than happy sad,

152
00:05:53,720 --> 00:05:55,800
but there's still some probability attached to it.

153
00:05:55,800 --> 00:05:58,280
And when we say it's probable, that's literally a percentage,

154
00:05:58,280 --> 00:06:03,280
that's like happy follows I am maybe like 5% of the time,

155
00:06:03,400 --> 00:06:06,960
sad follows I am maybe 2% of the time, or whatever.

156
00:06:06,960 --> 00:06:11,520
So for every word that we give GPT,

157
00:06:11,520 --> 00:06:13,920
it tries to predict what the next word is

158
00:06:13,920 --> 00:06:16,920
across 50,000 words, and it gives every single one

159
00:06:16,920 --> 00:06:21,920
of those 50,000 words a number that reflects how probable it is.

160
00:06:23,160 --> 00:06:25,360
And the really magical thing that happens

161
00:06:25,360 --> 00:06:30,280
is you can generate new text, so if you give GPT I am,

162
00:06:30,280 --> 00:06:34,240
and it predicts happy as being the most probable word

163
00:06:34,240 --> 00:06:37,880
over 50,000, you can then append it to I am,

164
00:06:37,880 --> 00:06:41,360
so now you say I am happy, and you feed it into the model again,

165
00:06:41,480 --> 00:06:43,680
you sample another word, you feed it into the model again,

166
00:06:43,680 --> 00:06:45,240
and again, and again, and again,

167
00:06:45,240 --> 00:06:47,720
and there's lots of different ways that I am happy,

168
00:06:47,720 --> 00:06:50,920
I am sad, can go, and you add a little bit of randomness,

169
00:06:50,920 --> 00:06:52,520
and all of a sudden you have a language model

170
00:06:52,520 --> 00:06:54,840
that can write essays, that can talk,

171
00:06:54,840 --> 00:06:57,760
and a whole lot of things, which is really unexpected,

172
00:06:57,760 --> 00:06:59,120
and something that we didn't predict

173
00:06:59,120 --> 00:07:01,880
even five years ago, so this is all relevant.

174
00:07:01,880 --> 00:07:06,880
And if we move on, as we scale up the model,

175
00:07:07,520 --> 00:07:10,680
and we give it more compute, in 2012 AlexNet came out,

176
00:07:10,680 --> 00:07:15,280
and we figured out we can run the model on GPUs,

177
00:07:15,280 --> 00:07:16,920
so we can speed up the process,

178
00:07:16,920 --> 00:07:18,960
we can give the model lots of information

179
00:07:18,960 --> 00:07:20,320
downloaded from the internet,

180
00:07:20,320 --> 00:07:21,840
and it learns more and more and more,

181
00:07:21,840 --> 00:07:24,520
and the probabilities that it gives you

182
00:07:24,520 --> 00:07:26,120
get better as it sees more examples

183
00:07:26,120 --> 00:07:27,600
of English on the internet,

184
00:07:27,600 --> 00:07:30,160
so we have to train the model to be really large,

185
00:07:30,160 --> 00:07:33,000
really wide, and we have to train it for a really long time,

186
00:07:33,000 --> 00:07:35,840
and as we do that, the model gets more and more better,

187
00:07:35,840 --> 00:07:37,720
and expressive and capable,

188
00:07:37,720 --> 00:07:39,760
and it also gets a little bit intelligent,

189
00:07:39,760 --> 00:07:42,200
and for reasons we don't understand.

190
00:07:42,200 --> 00:07:45,880
So, but the issue is that because it learns

191
00:07:45,880 --> 00:07:47,600
to replicate the internet,

192
00:07:47,600 --> 00:07:51,000
it knows how to speak in a lot of different genres of text,

193
00:07:51,000 --> 00:07:52,520
and a lot of different registers.

194
00:07:52,520 --> 00:07:55,120
If you begin the conversation like, chat GPT,

195
00:07:55,120 --> 00:07:56,760
can you explain the moon landing to a six year old

196
00:07:56,760 --> 00:07:58,760
in a few sentences, GPT three,

197
00:07:58,760 --> 00:08:01,080
this is an example drawn from the Instruct GPT paper

198
00:08:01,080 --> 00:08:05,640
from OpenAI, GPT three would have just been like,

199
00:08:05,640 --> 00:08:07,640
okay, so you're giving me an example,

200
00:08:07,640 --> 00:08:09,640
like explain the moon landing to a six year old,

201
00:08:09,640 --> 00:08:11,480
I'm gonna give you a whole bunch of similar things

202
00:08:11,480 --> 00:08:13,640
because those seem very likely to come in a sequence.

203
00:08:13,640 --> 00:08:15,520
It doesn't necessarily understand that it's being asked

204
00:08:15,520 --> 00:08:18,320
that question has to respond with an answer.

205
00:08:18,320 --> 00:08:21,560
GPT three did not have that apparatus,

206
00:08:21,560 --> 00:08:24,000
that interface for responding to questions,

207
00:08:24,000 --> 00:08:29,000
and the scientist at OpenAI came up with the solution,

208
00:08:29,280 --> 00:08:31,640
and that's, let's give it a whole bunch of examples

209
00:08:31,640 --> 00:08:33,240
of question and answers,

210
00:08:33,240 --> 00:08:35,640
such that we first train it on the internet,

211
00:08:35,640 --> 00:08:37,640
and then we train it with a whole bunch of questions

212
00:08:37,640 --> 00:08:41,320
and answers such that it has the knowledge of the internet,

213
00:08:41,320 --> 00:08:44,200
but really knows that it has to be answering questions,

214
00:08:44,200 --> 00:08:47,640
and that is when chat GPT was born,

215
00:08:47,640 --> 00:08:50,520
and that's when it gained 100 million users in one month,

216
00:08:50,520 --> 00:08:53,360
I think it beat TikTok's record at 20 million in one month,

217
00:08:53,360 --> 00:08:56,560
it was a huge thing, and for a lot of people,

218
00:08:56,560 --> 00:08:58,720
they went, oh, this thing is intelligent,

219
00:08:58,720 --> 00:09:01,400
I can answer, I can ask it questions, it answers back,

220
00:09:01,400 --> 00:09:03,600
we can work together to come to a solution,

221
00:09:03,600 --> 00:09:06,400
and that's because it's still predicting words,

222
00:09:06,400 --> 00:09:08,120
it's still a language model,

223
00:09:08,120 --> 00:09:11,440
but it knows to predict words in the framework

224
00:09:11,440 --> 00:09:14,560
of a question and answer, so that's what a prompt is,

225
00:09:14,560 --> 00:09:17,560
that's what instruction tuning is, that's a key word,

226
00:09:17,560 --> 00:09:21,920
that's what RLHF is, if you've ever seen that acronym,

227
00:09:21,920 --> 00:09:24,760
Reinforcement Alignment with Human Feedback,

228
00:09:24,760 --> 00:09:27,840
and all those combined means that the models

229
00:09:27,840 --> 00:09:28,920
that are coming out today,

230
00:09:28,920 --> 00:09:30,600
the types of language predictors

231
00:09:30,600 --> 00:09:31,840
that are coming out today,

232
00:09:31,840 --> 00:09:34,000
work to operate in a Q and A form.

233
00:09:34,000 --> 00:09:38,400
GPT-4 exclusively only has the aligned model available,

234
00:09:38,400 --> 00:09:42,920
and this is a really great, solid foundation to build on,

235
00:09:42,920 --> 00:09:44,360
because you can do all sorts of things,

236
00:09:44,360 --> 00:09:46,440
you can ask chat GPT, can you do this for me,

237
00:09:46,440 --> 00:09:47,480
can you do that for me?

238
00:09:47,480 --> 00:09:48,680
You might have seen that OpenAI

239
00:09:48,680 --> 00:09:51,020
has allowed plugin access to chat GPT,

240
00:09:51,020 --> 00:09:53,800
so it can access Wolfram, it can search the web,

241
00:09:53,800 --> 00:09:56,280
it can search, it can do Instacart for you,

242
00:09:56,280 --> 00:10:00,520
it can look up recipes, once the model knows

243
00:10:00,520 --> 00:10:02,640
that not only it has to predict language,

244
00:10:02,640 --> 00:10:05,000
but that it has to solve a problem,

245
00:10:05,920 --> 00:10:07,640
and the problem here being,

246
00:10:07,640 --> 00:10:09,560
give me a good answer to my question,

247
00:10:09,560 --> 00:10:11,560
it's suddenly able to interface with the world

248
00:10:11,560 --> 00:10:13,000
in a really solid way,

249
00:10:13,000 --> 00:10:15,720
and from there on, there's been all sorts of tools

250
00:10:15,720 --> 00:10:19,600
that it build on this Q and A form that chat GPT uses,

251
00:10:19,600 --> 00:10:22,800
you have auto GPT, you have Langchain,

252
00:10:22,800 --> 00:10:26,840
you have React, there was a React paper

253
00:10:26,840 --> 00:10:28,140
where a lot of these come from,

254
00:10:28,140 --> 00:10:30,880
and turning the model into an agent

255
00:10:31,480 --> 00:10:34,560
which to achieve any ambiguous goal

256
00:10:34,560 --> 00:10:36,080
is where the future is going,

257
00:10:36,080 --> 00:10:38,360
and this is all thanks to instruction tuning,

258
00:10:38,360 --> 00:10:41,720
and with that, I think I will hand it off to Ted,

259
00:10:41,720 --> 00:10:43,320
who will be giving a demo,

260
00:10:43,320 --> 00:10:44,560
or something along those lines,

261
00:10:44,560 --> 00:10:49,360
for how to use GPT as an agent, so.

262
00:10:51,920 --> 00:10:54,640
All right, so I'm a super applied guy,

263
00:10:54,640 --> 00:10:56,800
I kinda look at things and think,

264
00:10:56,800 --> 00:11:00,080
okay, how can I add this Lego, add that Lego,

265
00:11:00,120 --> 00:11:02,520
and clip them together and build something with it,

266
00:11:02,520 --> 00:11:06,760
and right now, if you look back in computer science history,

267
00:11:06,760 --> 00:11:08,200
when you look at the kinds of things

268
00:11:08,200 --> 00:11:10,240
that were being done in 1970,

269
00:11:10,240 --> 00:11:11,980
right after computing was invented,

270
00:11:11,980 --> 00:11:14,080
the microprocessors were invented,

271
00:11:14,080 --> 00:11:15,240
people were doing research like,

272
00:11:15,240 --> 00:11:17,120
how do I sort a list of numbers,

273
00:11:17,120 --> 00:11:18,360
and that was meaningful work,

274
00:11:18,360 --> 00:11:20,760
and importantly, it was work that's accessible to everybody,

275
00:11:20,760 --> 00:11:22,960
because nobody knows what we can build

276
00:11:22,960 --> 00:11:25,760
with this new kind of oil, this new kind of electricity,

277
00:11:25,760 --> 00:11:28,840
this new kind of unit of computation we've created,

278
00:11:28,880 --> 00:11:30,160
and anything was game,

279
00:11:30,160 --> 00:11:32,240
and anybody could participate in that game

280
00:11:32,240 --> 00:11:33,080
to figure it out,

281
00:11:33,080 --> 00:11:34,440
and I think one of the really exciting things

282
00:11:34,440 --> 00:11:37,240
about GPT right now is, yes,

283
00:11:37,240 --> 00:11:38,920
in and of itself, it's amazing,

284
00:11:38,920 --> 00:11:41,520
but then, what could we do with it

285
00:11:41,520 --> 00:11:43,160
if we call it over and over again,

286
00:11:43,160 --> 00:11:44,900
if we build it into our algorithms,

287
00:11:44,900 --> 00:11:46,520
and start to build it into broader software,

288
00:11:46,520 --> 00:11:47,960
so the world really is yours

289
00:11:47,960 --> 00:11:50,080
to figure out those fundamental questions

290
00:11:50,080 --> 00:11:52,600
about what could you do if you could script

291
00:11:52,600 --> 00:11:55,280
computation itself over and over again

292
00:11:55,280 --> 00:11:56,940
in the way that computers can do,

293
00:11:56,940 --> 00:11:59,540
not just talk with it, but build things atop it,

294
00:11:59,540 --> 00:12:02,100
so we're a hosting company, we host apps,

295
00:12:02,100 --> 00:12:04,520
and these are just some of the things that we see,

296
00:12:04,520 --> 00:12:06,260
I'm gonna show you demos of this with code

297
00:12:06,260 --> 00:12:08,740
and try to explain some of the thought process,

298
00:12:08,740 --> 00:12:10,740
but I wanted to give you a high level overview of,

299
00:12:10,740 --> 00:12:12,740
you've probably seen these on Twitter,

300
00:12:12,740 --> 00:12:14,660
but when it all sorts out to the top,

301
00:12:14,660 --> 00:12:16,260
these are some of the things that we're seeing

302
00:12:16,260 --> 00:12:19,540
built and deployed with language models today,

303
00:12:19,540 --> 00:12:22,500
companionship, that's everything from I need a friend,

304
00:12:22,500 --> 00:12:23,820
to I need a friend with a purpose,

305
00:12:23,820 --> 00:12:25,940
I want a coach, I want somebody to tell me,

306
00:12:25,940 --> 00:12:27,380
go to the gym and do these exercises,

307
00:12:27,380 --> 00:12:29,620
I want somebody to help me study a foreign language,

308
00:12:29,620 --> 00:12:31,400
question answering, this is a big one,

309
00:12:31,400 --> 00:12:33,100
this is everything from your newsroom,

310
00:12:33,100 --> 00:12:35,540
having a slack bot that helps assist you,

311
00:12:35,540 --> 00:12:39,260
does this article conform to the style guidelines

312
00:12:39,260 --> 00:12:41,500
of our newsroom, all the way through to,

313
00:12:41,500 --> 00:12:42,740
and you need help on my homework,

314
00:12:42,740 --> 00:12:44,540
or hey, I have some questions that I want you to ask,

315
00:12:44,540 --> 00:12:46,860
Wikipedia, combine it with something else,

316
00:12:46,860 --> 00:12:48,980
synthesize the answer and give it to me.

317
00:12:48,980 --> 00:12:51,940
Utility functions, I would describe this as,

318
00:12:51,940 --> 00:12:54,860
there's a large set of things for which

319
00:12:54,900 --> 00:12:57,580
human beings can do them, if only,

320
00:12:57,580 --> 00:13:00,060
or computers could do them, if only they had access

321
00:13:00,060 --> 00:13:01,820
to language computation, language knowledge,

322
00:13:01,820 --> 00:13:03,340
an example of this would be,

323
00:13:03,340 --> 00:13:06,460
read every tweet on Twitter, tell me the ones I should read,

324
00:13:06,460 --> 00:13:07,940
that way I only get to read the ones

325
00:13:07,940 --> 00:13:09,140
that actually make sense to me

326
00:13:09,140 --> 00:13:10,740
and I don't have to skim through the rest,

327
00:13:10,740 --> 00:13:13,460
creativity, image generation, text generation,

328
00:13:13,460 --> 00:13:15,980
storytelling, proposing other ways to do things,

329
00:13:15,980 --> 00:13:19,740
and then these wild experiments and kind of baby AGI,

330
00:13:19,740 --> 00:13:21,380
as people are calling them,

331
00:13:21,380 --> 00:13:23,500
in which the AI itself decides what to do

332
00:13:23,500 --> 00:13:25,300
and is self-directed, so I'll show you examples

333
00:13:25,300 --> 00:13:27,180
of many of these and what the code looks like,

334
00:13:27,180 --> 00:13:29,740
and if I were you, I would think about these

335
00:13:29,740 --> 00:13:32,820
as categories within which to both think about

336
00:13:32,820 --> 00:13:37,140
what you might build and then also seek out starter projects

337
00:13:37,140 --> 00:13:39,660
for how you might go about building them online.

338
00:13:42,500 --> 00:13:43,820
All right, so I'm just gonna dive straight into

339
00:13:43,820 --> 00:13:45,500
demos and code for some of these,

340
00:13:45,500 --> 00:13:47,180
because I know that's what's interesting to see

341
00:13:47,180 --> 00:13:49,860
as fellow builders, with a high level diagram

342
00:13:49,860 --> 00:13:51,580
for some of these as to how it works.

343
00:13:51,580 --> 00:13:54,780
So approximately, you can think of a companionship bot

344
00:13:54,780 --> 00:13:57,620
as a friend that has a purpose to you,

345
00:13:57,620 --> 00:14:00,100
and there are many ways to build all of these things,

346
00:14:00,100 --> 00:14:01,780
but one of the ways you can build this

347
00:14:01,780 --> 00:14:04,660
is simply to wrap GPT or a language model

348
00:14:04,660 --> 00:14:07,860
in an endpoint that additionally injects into the prompt

349
00:14:07,860 --> 00:14:10,700
some particular perspective or some particular goal

350
00:14:10,700 --> 00:14:11,980
that you want to use.

351
00:14:11,980 --> 00:14:13,820
It really is that easy in a way,

352
00:14:13,820 --> 00:14:16,140
but it's also very hard because you need to iterate

353
00:14:16,140 --> 00:14:19,820
and engineer the prompt so that it consistently performs

354
00:14:19,820 --> 00:14:22,140
the way you want it to perform.

355
00:14:22,140 --> 00:14:24,700
So a good example of this is something somebody built

356
00:14:24,700 --> 00:14:25,620
in the hackathon yesterday,

357
00:14:25,620 --> 00:14:27,940
and I just wanted to show you the project that they built.

358
00:14:27,940 --> 00:14:29,540
It was a Mandarin idiom coach,

359
00:14:29,540 --> 00:14:31,820
and I'll show you what the code looked like first.

360
00:14:31,820 --> 00:14:33,860
I'll show you the demo first.

361
00:14:33,860 --> 00:14:35,300
I think I already pulled it up.

362
00:14:38,140 --> 00:14:39,300
Here we go.

363
00:14:39,300 --> 00:14:42,820
So the buddy that this person wanted to create

364
00:14:42,820 --> 00:14:47,220
was a friend that if you gave it a particular problem

365
00:14:47,220 --> 00:14:49,900
you were having, it would pick a Chinese idiom,

366
00:14:49,900 --> 00:14:53,100
a four character Cheng Yu, that described poetically,

367
00:14:53,100 --> 00:14:56,100
like here's a particular way you could say this,

368
00:14:56,100 --> 00:14:57,780
and it would tell it to her so that the person

369
00:14:57,780 --> 00:14:59,700
who built this was studying Chinese

370
00:14:59,700 --> 00:15:01,980
and she wanted to learn more about it.

371
00:15:01,980 --> 00:15:06,820
So I might say something like I'm feeling very sad,

372
00:15:08,140 --> 00:15:10,420
and it would think a little bit,

373
00:15:10,420 --> 00:15:12,780
and if everything's up and running,

374
00:15:12,780 --> 00:15:16,260
it will generate one of these four character phrases,

375
00:15:16,260 --> 00:15:19,700
and it will respond to it with an example.

376
00:15:19,700 --> 00:15:21,020
Now, I don't know if this is correct or not,

377
00:15:21,020 --> 00:15:22,380
so if somebody can call me out,

378
00:15:22,380 --> 00:15:25,220
if this is actually incorrect, please call me out,

379
00:15:26,220 --> 00:15:28,420
and it will then finish up with something encouraging,

380
00:15:28,420 --> 00:15:30,980
saying hey, you can do it, I know this is hard, keep going.

381
00:15:30,980 --> 00:15:32,340
So let me show you how they built this,

382
00:15:32,340 --> 00:15:37,340
and I pulled up the code right here.

383
00:15:40,540 --> 00:15:45,060
So this was the particular starter replete

384
00:15:45,060 --> 00:15:47,420
that folks were using in the hackathon yesterday,

385
00:15:47,420 --> 00:15:49,940
and we pulled things up into basically,

386
00:15:49,940 --> 00:15:52,700
you have a wrapper around GPT,

387
00:15:52,700 --> 00:15:54,380
and there's many things you could do,

388
00:15:54,380 --> 00:15:56,300
but we're gonna make it easy for you to do two things.

389
00:15:56,300 --> 00:16:00,060
One of them is to inject some personality into the prompt,

390
00:16:00,060 --> 00:16:02,660
and I'll explain what that prompt is in a second,

391
00:16:02,660 --> 00:16:04,140
and then the second is add tools

392
00:16:04,140 --> 00:16:05,580
that might go out and do a particular thing,

393
00:16:05,580 --> 00:16:08,260
search the web or generate an image

394
00:16:08,260 --> 00:16:09,700
or add something to a database

395
00:16:09,700 --> 00:16:11,780
or fetch something from a database.

396
00:16:11,780 --> 00:16:13,100
So having done that,

397
00:16:13,100 --> 00:16:15,340
now you have something more than GPT.

398
00:16:15,340 --> 00:16:17,780
Now you have GPT, which we all know what it is

399
00:16:17,780 --> 00:16:19,100
and how we can interact with it,

400
00:16:19,100 --> 00:16:21,700
but you've also added a particular lens

401
00:16:21,700 --> 00:16:22,700
through which it's talking to you

402
00:16:22,700 --> 00:16:23,660
and potentially some tools.

403
00:16:23,660 --> 00:16:27,140
So this particular Chinese tutor,

404
00:16:27,140 --> 00:16:30,320
all it took to build that was four lines.

405
00:16:30,320 --> 00:16:31,660
So here's a question that I think

406
00:16:31,660 --> 00:16:34,700
is frying the minds of everybody in the industry right now.

407
00:16:35,700 --> 00:16:38,300
So is this something that we'll all do casually

408
00:16:38,300 --> 00:16:39,300
and nobody really knows?

409
00:16:39,300 --> 00:16:41,260
Will we just all say in the future to the LLM,

410
00:16:41,260 --> 00:16:42,500
hey, for the next five minutes,

411
00:16:42,500 --> 00:16:45,140
please talk like a teacher, and maybe?

412
00:16:45,140 --> 00:16:47,180
But also, definitely in the meantime,

413
00:16:47,180 --> 00:16:48,140
and maybe in the future,

414
00:16:48,140 --> 00:16:51,100
it makes sense to wrap up these personalized endpoints

415
00:16:51,100 --> 00:16:52,500
so that when I'm talking to GPT,

416
00:16:52,500 --> 00:16:53,900
I'm not just talking to GPT,

417
00:16:53,900 --> 00:16:55,700
I have a whole army of different buddies,

418
00:16:55,700 --> 00:16:58,140
of different companions that I can talk to.

419
00:16:58,140 --> 00:16:59,060
They're kind of human

420
00:16:59,060 --> 00:17:00,700
and kind of talk to me interactively,

421
00:17:00,700 --> 00:17:02,540
but because I preloaded them with,

422
00:17:02,540 --> 00:17:05,100
hey, by the way, you particular,

423
00:17:05,100 --> 00:17:06,940
I want you to be a kind, helpful Chinese teacher

424
00:17:06,940 --> 00:17:08,460
that responds to every situation

425
00:17:08,460 --> 00:17:10,260
by explaining the Chongyu that fits it.

426
00:17:10,300 --> 00:17:12,780
Speak in English and explain the Chongyu in its meaning.

427
00:17:12,780 --> 00:17:15,740
Then provide a note of encouragement about learning language.

428
00:17:15,740 --> 00:17:18,020
And so just adding something like that,

429
00:17:18,020 --> 00:17:19,900
even if you're a non-programmer,

430
00:17:19,900 --> 00:17:21,500
you can just type deploy,

431
00:17:24,220 --> 00:17:26,500
and it'll pop it up to the web,

432
00:17:26,500 --> 00:17:28,140
it'll take it over to a telegram bot

433
00:17:28,140 --> 00:17:29,540
that then you can even interact with,

434
00:17:29,540 --> 00:17:32,100
hey, I'm feeling too busy,

435
00:17:33,340 --> 00:17:35,940
and interact with it over telegram, over the web,

436
00:17:35,940 --> 00:17:38,580
and this is the kind of thing that's now within reach

437
00:17:38,580 --> 00:17:41,940
for everybody from a CS 101 grad,

438
00:17:41,940 --> 00:17:44,380
sorry, I'm using the general purpose framing,

439
00:17:44,380 --> 00:17:46,940
all the way through to professionals in the industry,

440
00:17:46,940 --> 00:17:49,580
that you can do just with a little bit of manipulation

441
00:17:49,580 --> 00:17:51,940
on top of sort of this raw unit

442
00:17:51,940 --> 00:17:54,620
of conversation and intelligence.

443
00:17:57,100 --> 00:18:00,180
So companionship is one of the first

444
00:18:00,180 --> 00:18:02,740
common types of apps that we're seeing.

445
00:18:04,820 --> 00:18:07,780
So a second kind of app that we're seeing,

446
00:18:07,780 --> 00:18:12,780
and for those of you who are on Twitter followers,

447
00:18:12,860 --> 00:18:15,900
this blew up, I think the last few months,

448
00:18:15,900 --> 00:18:16,980
is question-answering,

449
00:18:16,980 --> 00:18:18,580
and I wanna unpack a couple of different ways

450
00:18:18,580 --> 00:18:20,620
this can work, because I know many of you

451
00:18:20,620 --> 00:18:22,820
have probably already tried to build

452
00:18:22,820 --> 00:18:23,780
some of these kinds of apps,

453
00:18:23,780 --> 00:18:25,500
there's a couple of different ways that it works.

454
00:18:25,500 --> 00:18:29,740
The general framework is a user queries GPT,

455
00:18:29,740 --> 00:18:31,300
and maybe it has general purpose knowledge,

456
00:18:31,300 --> 00:18:33,140
maybe it doesn't have general purpose knowledge,

457
00:18:33,140 --> 00:18:35,980
but what you want it to say back to you

458
00:18:35,980 --> 00:18:38,660
is something specific about an article you wrote,

459
00:18:38,660 --> 00:18:41,500
or something specific about your course syllabus,

460
00:18:41,500 --> 00:18:44,660
or something specific about a particular set of documents

461
00:18:44,660 --> 00:18:46,940
from the United Nations on a particular topic.

462
00:18:46,940 --> 00:18:48,260
And so what you're really seeking is

463
00:18:48,260 --> 00:18:50,460
what we all hoped the customer service bot would be,

464
00:18:50,460 --> 00:18:52,580
like we've all interacted with these customer service bots,

465
00:18:52,580 --> 00:18:54,180
and we're kind of smashing our heads

466
00:18:54,180 --> 00:18:55,820
on the keyboard as we do it,

467
00:18:55,820 --> 00:18:58,460
but pretty soon we're gonna start to see

468
00:18:58,460 --> 00:19:01,500
very high fidelity bots that interact with us comfortably,

469
00:19:01,500 --> 00:19:03,580
and this is approximately how to do it as an engineer.

470
00:19:03,580 --> 00:19:05,900
So here's your game plan as an engineer,

471
00:19:05,900 --> 00:19:10,660
step one, take the documents that you want it to respond to.

472
00:19:11,740 --> 00:19:13,660
Step two, cut them up.

473
00:19:13,660 --> 00:19:15,980
Now, if you're an engineer, this is gonna madden you.

474
00:19:15,980 --> 00:19:18,540
You don't cut them up in a way that you would hope.

475
00:19:18,540 --> 00:19:20,540
For example, you could cut them up

476
00:19:20,540 --> 00:19:22,740
into clean sentences or clean paragraphs,

477
00:19:22,740 --> 00:19:24,660
or semantically coherent sections,

478
00:19:24,660 --> 00:19:26,340
and that would be really nice.

479
00:19:26,340 --> 00:19:28,420
Honestly, the way that most folks do it,

480
00:19:28,420 --> 00:19:32,060
and this is a simplification that tends to be just fine,

481
00:19:32,060 --> 00:19:34,460
is you window, you have a sliding window

482
00:19:34,460 --> 00:19:35,980
that goes over the document,

483
00:19:35,980 --> 00:19:38,860
and you just pull out fragments of text.

484
00:19:38,860 --> 00:19:40,660
Having pulled out those fragments of text,

485
00:19:40,660 --> 00:19:43,020
you turn them into something called an embedding vector.

486
00:19:43,020 --> 00:19:46,100
So an embedding vector is a list of numbers

487
00:19:46,100 --> 00:19:49,260
that approximate some point of meaning.

488
00:19:49,260 --> 00:19:50,700
So you've already all dealt

489
00:19:50,700 --> 00:19:52,620
with embedding vectors yourself in regular life,

490
00:19:52,620 --> 00:19:54,420
and the reason you have, and I know you have,

491
00:19:54,420 --> 00:19:57,020
is because everybody's ordered food from Yelp before.

492
00:19:57,020 --> 00:19:58,540
So when you order food from Yelp,

493
00:19:58,540 --> 00:20:01,340
you look at what genre of restaurant is it?

494
00:20:01,340 --> 00:20:02,700
Is it a pizza restaurant?

495
00:20:02,700 --> 00:20:03,820
Is it an Italian restaurant?

496
00:20:03,820 --> 00:20:05,500
Is it a Korean barbecue place?

497
00:20:05,500 --> 00:20:06,980
You look at how many stars does it have?

498
00:20:06,980 --> 00:20:08,860
One, two, three, four, five?

499
00:20:08,860 --> 00:20:09,980
You look at where is it?

500
00:20:09,980 --> 00:20:12,820
So all of these you can think of as points in space,

501
00:20:12,820 --> 00:20:14,060
dimensions in space.

502
00:20:14,060 --> 00:20:17,100
Korean barbecue restaurant, four stars near my house.

503
00:20:17,100 --> 00:20:20,820
That's a three number vector.

504
00:20:20,820 --> 00:20:21,820
That's all this is.

505
00:20:21,820 --> 00:20:23,660
So this is a thousand number vector,

506
00:20:23,660 --> 00:20:24,780
or a 10,000 number vector.

507
00:20:24,780 --> 00:20:27,100
Different models produce different size vectors.

508
00:20:27,100 --> 00:20:30,260
All it is is chunking pieces of text,

509
00:20:30,260 --> 00:20:32,480
turning it into a vector that approximates meaning,

510
00:20:32,480 --> 00:20:34,240
and then you put it in something called a vector database.

511
00:20:34,240 --> 00:20:36,520
And a vector database is just a database

512
00:20:36,520 --> 00:20:38,520
that stores numbers.

513
00:20:38,520 --> 00:20:42,440
But having that database, now when I ask a question,

514
00:20:42,440 --> 00:20:44,680
I can search the database, and I can say, hey, the question

515
00:20:44,680 --> 00:20:47,280
was, what does CS50 teach?

516
00:20:47,280 --> 00:20:50,520
What pieces of text in the database

517
00:20:50,520 --> 00:20:56,000
have vectors similar to the question, what does CS50 teach?

518
00:20:56,000 --> 00:20:58,320
And there's all sorts of tricks and empires

519
00:20:58,320 --> 00:21:01,600
being made on refinements of this general approach.

520
00:21:01,640 --> 00:21:06,400
But at the end, you, the developer, model it simply as thus.

521
00:21:06,400 --> 00:21:08,840
And then when you have your query, you embed it,

522
00:21:08,840 --> 00:21:11,280
you find the document fragments, and then you put them

523
00:21:11,280 --> 00:21:11,880
into a prompt.

524
00:21:11,880 --> 00:21:15,800
And now we're just back to the personality, the companionship

525
00:21:15,800 --> 00:21:16,400
bot.

526
00:21:16,400 --> 00:21:17,800
Now it's just a prompt.

527
00:21:17,800 --> 00:21:20,920
And the prompt is, you're an expert in answering questions.

528
00:21:20,920 --> 00:21:24,040
Please answer user provided question.

529
00:21:24,040 --> 00:21:27,120
Using source documents results from the database.

530
00:21:27,120 --> 00:21:28,760
That's it.

531
00:21:28,760 --> 00:21:30,600
So after all of these decades of engineering

532
00:21:30,600 --> 00:21:31,680
and these customer service bots, it

533
00:21:31,680 --> 00:21:33,360
turns out with a couple of lines of code.

534
00:21:33,360 --> 00:21:34,120
You can build this.

535
00:21:34,120 --> 00:21:37,360
So let me show you, I made one just before the class

536
00:21:37,360 --> 00:21:39,080
with the CS50 syllabus.

537
00:21:39,080 --> 00:21:43,760
So we can pull that up.

538
00:21:43,760 --> 00:21:47,040
And I can say, I added the PDF right here.

539
00:21:47,040 --> 00:21:49,200
So I just, I searched, I don't know if, I apologize.

540
00:21:49,200 --> 00:21:51,240
I don't know if it's an accurate or recent syllabus.

541
00:21:51,240 --> 00:21:53,920
I just searched the web for CS50 syllabus PDF.

542
00:21:53,920 --> 00:21:56,840
I put the URL in here, it loaded it into here.

543
00:21:56,840 --> 00:21:59,920
This is just a 100 line piece of code deployed

544
00:21:59,960 --> 00:22:02,200
that will now let me talk to it.

545
00:22:02,200 --> 00:22:07,640
And I can say, what will CS50 teach me?

546
00:22:07,640 --> 00:22:09,240
So under the hood now, what's happening

547
00:22:09,240 --> 00:22:10,880
is exactly what that slide just showed you.

548
00:22:10,880 --> 00:22:13,360
It takes that question, what will CS50 teach me?

549
00:22:13,360 --> 00:22:15,200
It turns it into a vector.

550
00:22:15,200 --> 00:22:18,880
That vector approximates without exactly representing

551
00:22:18,880 --> 00:22:21,160
the meaning of that question.

552
00:22:21,160 --> 00:22:23,640
It looks into a vector database that

553
00:22:23,640 --> 00:22:27,760
steamship hosts of fragments from that PDF.

554
00:22:27,760 --> 00:22:30,120
And then it pulls out a document and then passes it

555
00:22:30,120 --> 00:22:32,920
to a prompt that says, hey, you're an expert

556
00:22:32,920 --> 00:22:34,480
at answering questions.

557
00:22:34,480 --> 00:22:37,080
Someone has asked you, what does CS50 teach?

558
00:22:37,080 --> 00:22:39,920
Please answer it using only the source documents

559
00:22:39,920 --> 00:22:41,800
and source materials I've provided.

560
00:22:41,800 --> 00:22:43,640
Now those source materials materials

561
00:22:43,640 --> 00:22:45,560
are dynamically loaded into the prompt.

562
00:22:45,560 --> 00:22:46,720
It's just basic prompt engineering.

563
00:22:46,720 --> 00:22:49,280
And I want to keep harping back onto that.

564
00:22:49,280 --> 00:22:51,720
What's amazing about right now as builders

565
00:22:51,720 --> 00:22:54,000
is that so many things just boil down

566
00:22:54,040 --> 00:22:59,400
into very creative, tactical rearrangement of prompts

567
00:22:59,400 --> 00:23:01,880
and then using those over and over again in an algorithm

568
00:23:01,880 --> 00:23:03,040
and putting that into software.

569
00:23:03,040 --> 00:23:05,360
So the result, and again, it could be lying.

570
00:23:05,360 --> 00:23:06,280
It could be making things up.

571
00:23:06,280 --> 00:23:07,520
It could be hallucinating.

572
00:23:07,520 --> 00:23:09,840
Is CS50 will teach students how to think algorithmically

573
00:23:09,840 --> 00:23:11,680
and solve problems efficiently, focusing on topics

574
00:23:11,680 --> 00:23:13,440
such as abstraction, dot, dot, dot, dot, dot.

575
00:23:13,440 --> 00:23:15,600
And then it returns the source document

576
00:23:15,600 --> 00:23:16,600
from which it was found.

577
00:23:16,600 --> 00:23:19,120
So this is another big category of which there

578
00:23:19,120 --> 00:23:22,720
are tons of potential applications

579
00:23:22,720 --> 00:23:25,120
because you can repeat for each context.

580
00:23:25,120 --> 00:23:27,800
You can create arbitrarily many of these once it's software

581
00:23:27,800 --> 00:23:30,840
because once it's software, you can just repeat it

582
00:23:30,840 --> 00:23:31,680
over and over again.

583
00:23:31,680 --> 00:23:34,600
So for your dorm, for your club, for your slack,

584
00:23:34,600 --> 00:23:37,560
for your telegram, you can start to begin putting

585
00:23:37,560 --> 00:23:40,560
pieces of information in and then responding to it.

586
00:23:40,560 --> 00:23:42,040
And it doesn't have to be documents.

587
00:23:42,040 --> 00:23:44,940
You can also load it straight into the prompt.

588
00:23:46,200 --> 00:23:47,800
I think I have it pulled up here.

589
00:23:47,800 --> 00:23:50,200
And if I don't, I'll just skip it.

590
00:23:50,200 --> 00:23:51,040
Oh, here we go.

591
00:23:52,040 --> 00:23:54,400
One other way you can do question answering,

592
00:23:55,520 --> 00:23:57,600
because I think it's healthy to always encourage

593
00:23:57,600 --> 00:24:00,520
the simplest possible approach to something.

594
00:24:00,520 --> 00:24:02,960
You don't need to engineer this giant system.

595
00:24:02,960 --> 00:24:04,200
It's great to have a database.

596
00:24:04,200 --> 00:24:05,240
It's great to use embeddings.

597
00:24:05,240 --> 00:24:06,480
It's great to use this big approach.

598
00:24:06,480 --> 00:24:07,680
It's fancy at scales.

599
00:24:07,680 --> 00:24:09,480
You can do a lot of things.

600
00:24:09,480 --> 00:24:11,960
But you can also get away with a lot

601
00:24:11,960 --> 00:24:13,880
by just pushing it all into a prompt.

602
00:24:13,880 --> 00:24:16,280
And as an engineer, I'm, you know,

603
00:24:16,280 --> 00:24:17,720
that's one of our team who's here always says,

604
00:24:17,720 --> 00:24:19,200
like, engineers should aspire to be lazy.

605
00:24:19,200 --> 00:24:20,800
And I couldn't agree more.

606
00:24:20,880 --> 00:24:23,880
You, as an engineer, should want to set yourself up

607
00:24:23,880 --> 00:24:27,360
so that you can pursue the lazy path to something.

608
00:24:27,360 --> 00:24:30,720
So here's how you might do the equivalent

609
00:24:30,720 --> 00:24:32,600
of a question answering system with a prompt alone.

610
00:24:32,600 --> 00:24:35,200
Let's say you have 30 friends.

611
00:24:35,200 --> 00:24:37,080
And each friend is good at a particular thing,

612
00:24:37,080 --> 00:24:39,000
or you can, you know, this is isomorphic

613
00:24:39,000 --> 00:24:40,560
to many other problems.

614
00:24:40,560 --> 00:24:43,060
You can simply just say, hey, I know certain things.

615
00:24:43,060 --> 00:24:44,720
Here's the things I know.

616
00:24:44,720 --> 00:24:49,160
A user's gonna ask me something, how should we respond?

617
00:24:49,160 --> 00:24:50,840
And then you load that into an agent.

618
00:24:50,840 --> 00:24:53,480
That agent has access to GPT.

619
00:24:53,480 --> 00:24:54,840
You can ship deploy it.

620
00:24:54,840 --> 00:24:57,680
And now you've got a bot that you can connect to Telegram.

621
00:24:57,680 --> 00:24:59,360
You can connect to Slack.

622
00:24:59,360 --> 00:25:02,520
And that bot, now it won't always give you the right answer.

623
00:25:02,520 --> 00:25:03,480
Because at a certain level,

624
00:25:03,480 --> 00:25:06,660
we can't control the variance of the model underneath.

625
00:25:06,660 --> 00:25:10,240
But it will tend to answer with respect to this list.

626
00:25:10,240 --> 00:25:13,120
And the degree to which it tends to is to a certain extent,

627
00:25:13,120 --> 00:25:15,080
something that both industry is working on

628
00:25:15,080 --> 00:25:17,640
to just give everybody as a capacity.

629
00:25:17,640 --> 00:25:19,720
But also you doing prompt engineering

630
00:25:19,720 --> 00:25:23,340
to tighten up the error bars on it.

631
00:25:26,900 --> 00:25:29,280
So I'll show you just a few more examples.

632
00:25:29,280 --> 00:25:31,520
And then in about eight minutes,

633
00:25:31,520 --> 00:25:32,620
I'll turn it over to questions,

634
00:25:32,620 --> 00:25:34,280
because I'm sure you've got a lot about how to build things.

635
00:25:34,280 --> 00:25:37,020
So just to give you a sense of where we are.

636
00:25:41,000 --> 00:25:43,200
This is one, I don't have a demo for you.

637
00:25:43,200 --> 00:25:46,500
But if you were to come to me and you were to say, Ted,

638
00:25:46,500 --> 00:25:49,540
I want a weekend hustle, man, what should I build?

639
00:25:49,540 --> 00:25:51,100
Holy moly.

640
00:25:51,100 --> 00:25:53,300
There are a set of applications

641
00:25:53,300 --> 00:25:55,060
that I would describe as utility functions.

642
00:25:55,060 --> 00:25:56,260
I don't like that name,

643
00:25:56,260 --> 00:25:57,460
because it doesn't sound exciting,

644
00:25:57,460 --> 00:25:59,180
and this is really exciting.

645
00:25:59,180 --> 00:26:02,380
And it's low hanging fruits that automate tasks

646
00:26:02,380 --> 00:26:04,220
that require basic language understanding.

647
00:26:04,220 --> 00:26:08,140
So examples for this are generate a unit test.

648
00:26:08,140 --> 00:26:10,860
I don't know how many of you have ever been writing tests

649
00:26:10,860 --> 00:26:12,260
and you're just like, oh, come on,

650
00:26:12,260 --> 00:26:13,980
I can get through this, I can get through this.

651
00:26:13,980 --> 00:26:15,180
If you're a person who likes writing tests,

652
00:26:15,180 --> 00:26:16,860
you're a lucky individual.

653
00:26:16,860 --> 00:26:18,620
Looking up the documentation for a function,

654
00:26:18,620 --> 00:26:20,580
rewriting a function, making something conform

655
00:26:20,580 --> 00:26:23,620
to your company guidelines, doing a brand check.

656
00:26:23,620 --> 00:26:24,860
All of these things are things

657
00:26:24,860 --> 00:26:29,460
that are kind of relatively context-free operations

658
00:26:29,460 --> 00:26:33,140
or scoped context operations on a piece of information

659
00:26:33,140 --> 00:26:35,140
that requires linguistic understanding.

660
00:26:36,300 --> 00:26:39,580
And really, you can think of them as something

661
00:26:39,580 --> 00:26:42,420
that is now available to you as a software builder,

662
00:26:42,420 --> 00:26:44,180
as a weekend project builder,

663
00:26:44,180 --> 00:26:46,220
as a startup builder.

664
00:26:46,220 --> 00:26:48,740
And you just have to build the interface around it

665
00:26:48,740 --> 00:26:51,460
and present it to other people in a context

666
00:26:51,460 --> 00:26:54,180
in which it's meaningful for them to consume.

667
00:26:54,180 --> 00:26:57,220
And so the space of this is extraordinary.

668
00:26:57,220 --> 00:26:59,380
I mean, it's the space of all human endeavor,

669
00:26:59,380 --> 00:27:00,900
now with this new tool, I think,

670
00:27:00,900 --> 00:27:02,180
is the way to think about it.

671
00:27:02,180 --> 00:27:04,780
People often joke about how when you're building a company,

672
00:27:04,780 --> 00:27:05,820
when you're building a project,

673
00:27:05,820 --> 00:27:07,420
you don't want to start with a hammer,

674
00:27:07,420 --> 00:27:09,500
because you want to start with a problem instead.

675
00:27:09,500 --> 00:27:11,980
And it's generally true, but my God,

676
00:27:11,980 --> 00:27:13,820
we've just got a really cool new hammer.

677
00:27:13,820 --> 00:27:15,820
And to a certain extent, I would encourage you

678
00:27:15,820 --> 00:27:17,340
to at least casually, on the weekends,

679
00:27:17,340 --> 00:27:18,580
run around and hit stuff with it

680
00:27:18,580 --> 00:27:20,580
and see what can happen from a builder's,

681
00:27:20,580 --> 00:27:23,980
from a tinkerers, from an experimentalist's point of view.

682
00:27:27,940 --> 00:27:31,020
And then the final one is creativity.

683
00:27:31,020 --> 00:27:32,940
This is another huge mega app.

684
00:27:32,940 --> 00:27:35,660
Now, I'm primarily living the text world,

685
00:27:35,660 --> 00:27:37,940
and so I'm gonna talk about text-based things.

686
00:27:37,940 --> 00:27:41,420
I think so far, this has mostly been growing

687
00:27:41,420 --> 00:27:44,220
in the imagery world, because we're such visual creatures,

688
00:27:44,220 --> 00:27:45,620
and the images you can generate

689
00:27:45,620 --> 00:27:48,540
are just staggering with AI.

690
00:27:48,540 --> 00:27:50,260
Certainly brings up a lot of questions, too,

691
00:27:50,260 --> 00:27:52,160
around IP and artistic style.

692
00:27:53,140 --> 00:27:55,660
But the template for this, if you're a builder,

693
00:27:55,660 --> 00:27:57,580
that we're seeing in the wild,

694
00:27:57,580 --> 00:27:58,820
is approximately the following.

695
00:27:58,820 --> 00:28:01,540
And the thing I want to point out is domain knowledge here.

696
00:28:01,540 --> 00:28:02,980
This is really the purpose of this slide,

697
00:28:02,980 --> 00:28:06,760
is to touch on the importance of the domain knowledge.

698
00:28:06,760 --> 00:28:10,760
So, many people approximately

699
00:28:10,760 --> 00:28:12,960
find the creative process as follows.

700
00:28:12,960 --> 00:28:14,220
Come up with a big idea.

701
00:28:15,560 --> 00:28:18,400
Over-generate possibilities.

702
00:28:18,400 --> 00:28:21,240
Edit down what you over-generated.

703
00:28:21,240 --> 00:28:22,720
Repeat, right?

704
00:28:22,720 --> 00:28:24,240
Like anybody who's been a writer

705
00:28:24,240 --> 00:28:26,480
knows when you write, you write way too much,

706
00:28:26,480 --> 00:28:28,240
and then you have to delete lots of it.

707
00:28:28,240 --> 00:28:29,960
And then you revise, and you write way too much,

708
00:28:29,960 --> 00:28:31,520
and you have to delete lots of it.

709
00:28:31,520 --> 00:28:34,640
This particular task is fantastic for AI.

710
00:28:34,640 --> 00:28:36,680
One of the reasons it's fantastic for AI

711
00:28:36,680 --> 00:28:38,400
is because it allows the AI to be wrong.

712
00:28:38,400 --> 00:28:39,720
You know, you've pre-agreed,

713
00:28:39,720 --> 00:28:40,640
you're gonna delete lots of it.

714
00:28:40,640 --> 00:28:43,560
And so, if you pre-agreed, hey, I'm just gonna build,

715
00:28:43,560 --> 00:28:46,240
generate five possibilities of the story I might tell.

716
00:28:46,240 --> 00:28:48,520
Five possibilities of the advertising headline.

717
00:28:48,520 --> 00:28:52,800
Five possibilities of what I might write my thesis on.

718
00:28:52,800 --> 00:28:54,440
You pre-agreed, it's okay if it's a little wrong,

719
00:28:54,440 --> 00:28:56,960
because you are going to be the editor that steps in.

720
00:28:56,960 --> 00:28:58,800
And here's the thing that you really

721
00:28:58,800 --> 00:29:01,000
should bring to the table, is don't think about this

722
00:29:01,000 --> 00:29:02,000
as a technical activity.

723
00:29:02,000 --> 00:29:04,320
Think about this as your opportunity

724
00:29:04,320 --> 00:29:06,840
not to put GPT in charge.

725
00:29:06,840 --> 00:29:10,080
Instead, for you to grasp the steering wheel tighter,

726
00:29:10,080 --> 00:29:12,520
I think, at least, in Python,

727
00:29:12,520 --> 00:29:14,520
or the language you're using to program,

728
00:29:14,520 --> 00:29:16,600
because you have the domain knowledge

729
00:29:16,600 --> 00:29:19,080
to wield GPT in the generation of those.

730
00:29:19,080 --> 00:29:21,240
So let me show you an example of what I mean by that.

731
00:29:21,240 --> 00:29:26,240
So, this is a cool app that someone created

732
00:29:26,640 --> 00:29:27,800
for the Writing Atlas project.

733
00:29:27,800 --> 00:29:30,800
So Writing Atlas is a set of short stories,

734
00:29:31,800 --> 00:29:35,200
and you can think of it as good reads for short stories.

735
00:29:35,200 --> 00:29:38,000
So you can go in here, you can browse different stories,

736
00:29:38,000 --> 00:29:39,480
and this was something somebody created

737
00:29:39,480 --> 00:29:42,760
where you can type in a story description that you like,

738
00:29:42,760 --> 00:29:44,360
and this is gonna take about a minute to generate,

739
00:29:44,360 --> 00:29:46,280
so I'm gonna talk while it's generating.

740
00:29:46,280 --> 00:29:51,280
And while it's working, what it's doing,

741
00:29:51,440 --> 00:29:52,920
and I'll show you the code in a second,

742
00:29:52,920 --> 00:29:55,400
is it's searching through the collection of stories

743
00:29:55,400 --> 00:29:56,800
for similar stories, and here's where

744
00:29:56,800 --> 00:29:58,520
the domain knowledge part comes in.

745
00:29:58,640 --> 00:30:02,600
Then it uses GPT to look at what it was that you wanted,

746
00:30:02,600 --> 00:30:04,840
and use knowledge of how an editor,

747
00:30:04,840 --> 00:30:07,160
how a bookseller thinks, to generate

748
00:30:07,160 --> 00:30:10,200
a set of suggestions specifically through the lens

749
00:30:10,200 --> 00:30:12,360
of that perspective with the goal of writing

750
00:30:12,360 --> 00:30:13,960
that beautiful handwritten note

751
00:30:13,960 --> 00:30:16,200
that we sometimes see in a local bookstore

752
00:30:16,200 --> 00:30:19,480
tacked on underneath a book.

753
00:30:19,480 --> 00:30:21,840
And so it doesn't just say, hey, you might like this,

754
00:30:21,840 --> 00:30:24,980
here's a general purpose reason why you might like this,

755
00:30:24,980 --> 00:30:27,800
but specifically, here's why you might like this

756
00:30:27,840 --> 00:30:29,640
with respect to what you gave it.

757
00:30:29,640 --> 00:30:32,680
It's either stalling out, or it's taking a long time.

758
00:30:32,680 --> 00:30:33,520
Oh, there we go.

759
00:30:34,600 --> 00:30:39,600
So here's its suggestions, and in particular, these things,

760
00:30:39,800 --> 00:30:41,560
these are things that only a human could know,

761
00:30:41,560 --> 00:30:45,240
at least for now, two humans specifically,

762
00:30:45,240 --> 00:30:47,360
the human who said they wanted to read a story,

763
00:30:47,360 --> 00:30:48,720
that's the text that came in,

764
00:30:48,720 --> 00:30:51,680
and then the human who added domain knowledge

765
00:30:51,680 --> 00:30:54,160
to script a sequence of interactions

766
00:30:54,160 --> 00:30:56,760
with the language model so that you could provide

767
00:30:56,800 --> 00:30:59,440
very targeted reasoning over something

768
00:30:59,440 --> 00:31:01,520
that was informed by that domain knowledge.

769
00:31:01,520 --> 00:31:05,500
So for these utility apps, bring your domain knowledge.

770
00:31:09,640 --> 00:31:12,160
Let me actually show you how this looks and code,

771
00:31:12,160 --> 00:31:14,720
because I think it's useful to see how simple

772
00:31:14,720 --> 00:31:15,940
and accessible this is.

773
00:31:15,940 --> 00:31:18,400
This is really a set of prompts.

774
00:31:18,400 --> 00:31:22,240
So why might they, like a particular location,

775
00:31:22,240 --> 00:31:23,640
well, here's the prompt that did that,

776
00:31:23,640 --> 00:31:25,880
this is an open source project,

777
00:31:25,880 --> 00:31:27,520
and it has a bunch of examples,

778
00:31:27,520 --> 00:31:31,000
and then it says, well, here's the one that we're interested in.

779
00:31:31,000 --> 00:31:32,880
Here's the audience, here's a couple of examples

780
00:31:32,880 --> 00:31:35,080
of why might people like a particular thing

781
00:31:35,080 --> 00:31:37,400
in terms of audience, it's just another prompt.

782
00:31:42,320 --> 00:31:44,520
Same for topic, same for explanation,

783
00:31:44,520 --> 00:31:47,320
and if you go down here and look at how it was done,

784
00:31:49,340 --> 00:31:51,560
suggesting the story is, what is this,

785
00:31:51,560 --> 00:31:54,840
line 174 to line 203, it really is,

786
00:31:54,840 --> 00:31:56,320
and again, over and over again,

787
00:31:56,320 --> 00:31:59,180
I wanna impress upon you, this really is within reach.

788
00:31:59,180 --> 00:32:03,720
It's really just what, 20 odd lines of step one,

789
00:32:03,720 --> 00:32:06,600
search in the database for similar stories,

790
00:32:06,600 --> 00:32:09,880
step two, given that I have similar stories,

791
00:32:09,880 --> 00:32:12,480
pull out the data, step three,

792
00:32:12,480 --> 00:32:15,160
with my domain knowledge in Python,

793
00:32:15,160 --> 00:32:17,600
now run these prompts, step four,

794
00:32:17,600 --> 00:32:19,020
prepare that into an output.

795
00:32:19,020 --> 00:32:21,440
So the thing we're scripting itself

796
00:32:21,440 --> 00:32:24,680
is some approximation of human cognition.

797
00:32:24,680 --> 00:32:26,560
If you're willing to go there metaphorically,

798
00:32:26,560 --> 00:32:28,720
we're not sure, I'm not gonna weigh in

799
00:32:28,720 --> 00:32:33,720
on where we are on this open AI, a life form argument.

800
00:32:36,160 --> 00:32:39,920
All right, one really far out there thing,

801
00:32:39,920 --> 00:32:42,360
and then I'll tie it up for questions,

802
00:32:42,360 --> 00:32:43,480
because I know there's probably a lot,

803
00:32:43,480 --> 00:32:46,240
and I also wanna make sure you get great pizza

804
00:32:46,240 --> 00:32:51,240
in your bellies, and that is a baby AGI auto GPT

805
00:32:52,180 --> 00:32:53,920
is what you might have heard them called on Twitter.

806
00:32:53,920 --> 00:32:56,120
I think of them as multi-step planning bots.

807
00:32:56,120 --> 00:32:58,320
So everything I showed you so far

808
00:32:58,320 --> 00:33:02,520
was approximately one shot interactions with GPT.

809
00:33:02,520 --> 00:33:05,400
So this is, the user says they want something,

810
00:33:05,400 --> 00:33:09,200
and then either Python mediates interactions with GPT,

811
00:33:09,200 --> 00:33:12,640
or GPT itself does some things with the inflection

812
00:33:12,640 --> 00:33:14,320
of a personality that you've added

813
00:33:14,320 --> 00:33:16,400
from some prompt engineering.

814
00:33:16,400 --> 00:33:19,480
Really useful, pretty easy to control.

815
00:33:19,480 --> 00:33:20,840
If you wanna go to production,

816
00:33:20,840 --> 00:33:22,200
if you wanna build a weekend project,

817
00:33:22,200 --> 00:33:23,040
if you wanna build a company,

818
00:33:23,040 --> 00:33:25,160
that's a great way to do it right now.

819
00:33:26,360 --> 00:33:29,960
This is wild, and if you haven't seen this stuff on Twitter,

820
00:33:29,960 --> 00:33:32,260
I would definitely recommend going to search for it.

821
00:33:32,260 --> 00:33:35,500
This is what happens, the simple way to put it is,

822
00:33:35,500 --> 00:33:37,920
if you put GPT in a for loop,

823
00:33:37,920 --> 00:33:39,680
if you let GPT talk to itself,

824
00:33:39,680 --> 00:33:42,060
and then tell itself what to do.

825
00:33:42,060 --> 00:33:46,560
So it's an emergent behavior,

826
00:33:46,560 --> 00:33:48,040
and like all emergent behaviors,

827
00:33:48,040 --> 00:33:49,600
it starts with a few simple steps,

828
00:33:49,600 --> 00:33:53,520
the Conways game of life, many elements of reality,

829
00:33:53,520 --> 00:33:56,480
turn out to be math equations that fit on a t-shirt,

830
00:33:56,480 --> 00:33:58,040
but then when you play them forward in time,

831
00:33:58,040 --> 00:34:00,960
they generate DNA, they generate human life.

832
00:34:00,960 --> 00:34:04,520
So this is approximately,

833
00:34:04,520 --> 00:34:07,340
step one, take a human objective,

834
00:34:07,340 --> 00:34:10,560
step two, your first task is to write yourself

835
00:34:10,560 --> 00:34:14,300
a list of steps, and here's the critical part, repeat.

836
00:34:14,300 --> 00:34:16,000
Now do the list of steps.

837
00:34:16,000 --> 00:34:18,580
Now you have to embody your agent

838
00:34:18,580 --> 00:34:20,020
with the ability to do things.

839
00:34:20,020 --> 00:34:21,860
So it's really only limited to do what you give it

840
00:34:21,860 --> 00:34:24,700
the tools to do, and what it has the skills to do.

841
00:34:24,700 --> 00:34:27,340
So obviously this is still very much

842
00:34:27,340 --> 00:34:29,300
a set of experiments that are running right now,

843
00:34:29,300 --> 00:34:31,340
and but it's something that we'll see unfold

844
00:34:31,340 --> 00:34:33,180
over the coming years, and this is the scenario

845
00:34:33,180 --> 00:34:35,180
in which Python stops becoming so important

846
00:34:35,180 --> 00:34:36,540
because we've given it the ability

847
00:34:36,540 --> 00:34:39,420
to actually self-direct what it's doing,

848
00:34:39,420 --> 00:34:41,380
and then it finally gives you a result.

849
00:34:41,380 --> 00:34:43,380
And I wanna give you an example still of just, again,

850
00:34:43,380 --> 00:34:45,880
impressing upon you how much of this is prompt engineering,

851
00:34:45,880 --> 00:34:48,140
which is wild, how little code this is.

852
00:34:48,140 --> 00:34:52,240
Let me show you what BabyAGI looks like.

853
00:34:53,760 --> 00:34:57,940
So here is a BabyAGI that you can connect to Telegram,

854
00:35:01,260 --> 00:35:03,960
and this is an agent that has two tools.

855
00:35:03,960 --> 00:35:05,500
So I haven't explained to you what an agent is,

856
00:35:05,500 --> 00:35:07,220
I haven't explained to you what tools are,

857
00:35:07,220 --> 00:35:08,900
I'll give you a quick one sentence description.

858
00:35:08,900 --> 00:35:12,180
An agent is just a word to mean GPT

859
00:35:12,180 --> 00:35:14,780
plus some bigger body in which it's living.

860
00:35:14,780 --> 00:35:17,100
Maybe that body has a personality, maybe it has tools,

861
00:35:17,140 --> 00:35:18,980
maybe it has Python mediating its experience

862
00:35:18,980 --> 00:35:20,100
with other things.

863
00:35:20,100 --> 00:35:22,760
Tools are simply ways in which the agent

864
00:35:22,760 --> 00:35:24,020
can choose to do things.

865
00:35:24,020 --> 00:35:26,620
Like imagine if GPT could say order a pizza,

866
00:35:26,620 --> 00:35:28,860
and instead of you seeing the text order a pizza,

867
00:35:28,860 --> 00:35:32,100
that caused a pizza to be ordered, that's a tool.

868
00:35:32,100 --> 00:35:33,340
So these are two tools it has,

869
00:35:33,340 --> 00:35:35,280
one tool is generated to-do list,

870
00:35:35,280 --> 00:35:38,420
one tool is do a search on the web,

871
00:35:42,360 --> 00:35:46,060
and then down here it has a prompt saying,

872
00:35:46,100 --> 00:35:48,540
hey, your goal is to build a task list

873
00:35:48,540 --> 00:35:49,900
and then do that task list,

874
00:35:49,900 --> 00:35:52,540
and then this is just placed into a harness

875
00:35:52,540 --> 00:35:53,740
that does it over and over again.

876
00:35:53,740 --> 00:35:56,220
So after the next task, kind of unqueue the results

877
00:35:56,220 --> 00:35:58,820
of that task and keep it going.

878
00:35:58,820 --> 00:36:02,000
And so in doing that, you get this kickstarted loop

879
00:36:02,000 --> 00:36:04,140
where essentially you kickstart it,

880
00:36:04,140 --> 00:36:07,300
and then the agent is talking to itself.

881
00:36:07,300 --> 00:36:09,020
So this, unless I'm wrong,

882
00:36:09,020 --> 00:36:11,140
I don't think this has yet reached production

883
00:36:11,140 --> 00:36:12,700
in terms of what we're seeing in the field

884
00:36:12,700 --> 00:36:14,520
of how people are deploying software,

885
00:36:14,520 --> 00:36:17,200
but if you wanna dive into sort of the wildest part

886
00:36:17,200 --> 00:36:18,840
of experimentation, this is definitely one

887
00:36:18,840 --> 00:36:21,900
of the places you can start, and it's really within reach.

888
00:36:21,900 --> 00:36:23,880
All you have to do is download one

889
00:36:23,880 --> 00:36:25,720
of the starter projects for it,

890
00:36:25,720 --> 00:36:27,440
and you can kind of see right in the prompting,

891
00:36:27,440 --> 00:36:31,120
here's how you kickstart that process of iteration.

892
00:36:37,960 --> 00:36:40,200
All right, so I know that was super high level.

893
00:36:40,200 --> 00:36:42,000
I hope it was useful.

894
00:36:42,000 --> 00:36:44,040
It's, I think from the field, from the bottoms up,

895
00:36:44,040 --> 00:36:45,360
what we're seeing and what people are building,

896
00:36:45,360 --> 00:36:48,800
kind of the high level categories of apps

897
00:36:48,800 --> 00:36:50,120
that people are making.

898
00:36:50,120 --> 00:36:52,220
All of these apps are apps that are within reach

899
00:36:52,220 --> 00:36:54,940
to everybody, which is really, really exciting.

900
00:36:54,940 --> 00:36:56,880
And there's, I suggest Twitter is a great place

901
00:36:56,880 --> 00:36:59,840
to hang out and build things.

902
00:36:59,840 --> 00:37:02,840
There's a lot of AI builders on Twitter publishing.

903
00:37:02,840 --> 00:37:04,320
And I think we've got a couple minutes

904
00:37:04,320 --> 00:37:06,560
before pizza is arriving, maybe 10 minutes.

905
00:37:06,560 --> 00:37:07,920
Keep on going.

906
00:37:07,920 --> 00:37:10,840
So if there's any questions, why don't we kick it to that?

907
00:37:10,840 --> 00:37:13,680
Because I'm sure there's some questions that you all have,

908
00:37:13,720 --> 00:37:15,040
I guess I ended it a little early.

909
00:37:15,040 --> 00:37:15,880
Yes?

910
00:37:15,880 --> 00:37:18,920
Yeah, so I have a question around hallucination.

911
00:37:18,920 --> 00:37:21,160
And so, you know, whenever building these sorts

912
00:37:21,160 --> 00:37:23,960
of applications in apps, for example, let's say,

913
00:37:25,440 --> 00:37:27,440
I'm giving it like a physics problem from a PSET

914
00:37:27,440 --> 00:37:28,440
and we want to do that.

915
00:37:28,440 --> 00:37:29,280
Yeah.

916
00:37:29,280 --> 00:37:33,040
And, you know, it's 40% of the time just raw.

917
00:37:33,040 --> 00:37:33,880
Yeah.

918
00:37:33,880 --> 00:37:35,600
Do you have any like actionable recommendations

919
00:37:35,600 --> 00:37:37,440
that these developers should be doing

920
00:37:37,440 --> 00:37:38,760
to make it hallucinate less?

921
00:37:38,760 --> 00:37:41,880
Or maybe even things that like open AI on the back end

922
00:37:41,880 --> 00:37:43,640
should be doing to reduce hallucination.

923
00:37:43,640 --> 00:37:46,480
So it would be something where you use RLHF.

924
00:37:47,840 --> 00:37:49,200
Yeah, I didn't get the answer.

925
00:37:49,200 --> 00:37:51,800
So the question was how, approximately,

926
00:37:51,800 --> 00:37:53,720
how do you manage the hallucination problem?

927
00:37:53,720 --> 00:37:56,080
Like if you give it a physics lecture

928
00:37:56,080 --> 00:37:58,720
and you ask it a question, on the one hand,

929
00:37:58,720 --> 00:38:00,720
it appears to be answering you correctly.

930
00:38:00,720 --> 00:38:03,320
On the other hand, it appears to be wrong

931
00:38:03,320 --> 00:38:05,480
to an expert's eye 40% of the time,

932
00:38:05,480 --> 00:38:07,320
70% of the time, 10% of the time.

933
00:38:07,320 --> 00:38:08,360
It's a huge problem.

934
00:38:08,360 --> 00:38:11,160
And then what are some ways as developers practically

935
00:38:11,160 --> 00:38:13,200
you can use to mitigate that?

936
00:38:13,200 --> 00:38:14,040
I'll give an answer.

937
00:38:14,040 --> 00:38:15,400
So you may have some specific things too.

938
00:38:15,400 --> 00:38:17,000
So one high level answer is,

939
00:38:17,000 --> 00:38:18,440
the same thing that makes these things

940
00:38:18,440 --> 00:38:20,200
capable of synthesizing information

941
00:38:20,200 --> 00:38:22,160
is part of the reason why it hallucinates for you.

942
00:38:22,160 --> 00:38:23,960
So it's hard to have your cake you need it to

943
00:38:23,960 --> 00:38:25,280
to a certain extent.

944
00:38:25,280 --> 00:38:26,640
So this is part of the game.

945
00:38:26,640 --> 00:38:28,160
In fact, humans do it too.

946
00:38:28,160 --> 00:38:29,920
Like people talk about, you know,

947
00:38:29,920 --> 00:38:32,400
just folks who kind of are too aggressive

948
00:38:32,400 --> 00:38:33,680
in their assumptions about knowledge.

949
00:38:33,680 --> 00:38:35,680
I can't remember the name for that phenomenon

950
00:38:35,680 --> 00:38:36,720
where you'll just say stuff, right?

951
00:38:36,720 --> 00:38:37,600
So we do it too.

952
00:38:38,560 --> 00:38:42,200
Some things you can do are kind of a range of activities

953
00:38:42,200 --> 00:38:43,760
depending on how much money you really need to spend,

954
00:38:43,760 --> 00:38:44,920
how much technical expertise you have,

955
00:38:44,920 --> 00:38:48,480
that can range from fine tuning a model to practically,

956
00:38:48,480 --> 00:38:49,800
so I'm in the applied world.

957
00:38:49,800 --> 00:38:51,680
So I'm very much in the world of duct tape

958
00:38:51,680 --> 00:38:53,200
and sort of how developers get stuff done.

959
00:38:53,200 --> 00:38:54,400
So some of the answers I'll give you

960
00:38:54,400 --> 00:38:56,120
are sort of very duct-tapy answers.

961
00:38:56,120 --> 00:38:59,040
Giving it examples tends to work for acute things.

962
00:38:59,040 --> 00:39:00,640
If it's behaving in wild ways,

963
00:39:00,640 --> 00:39:03,040
the more examples you give it, the better.

964
00:39:03,040 --> 00:39:06,000
That's not gonna solve the domain of all of physics.

965
00:39:06,000 --> 00:39:07,360
So for the domain of all of physics,

966
00:39:07,800 --> 00:39:08,920
I'm gonna bail and give it to you

967
00:39:08,920 --> 00:39:10,400
because I think you are far more equipped than me

968
00:39:10,400 --> 00:39:11,240
to speak on that.

969
00:39:11,240 --> 00:39:14,680
Sure, so the model doesn't have a ground truth.

970
00:39:14,680 --> 00:39:16,080
It doesn't know anything.

971
00:39:16,080 --> 00:39:17,600
Any sense of meaning that it's derived

972
00:39:17,600 --> 00:39:21,960
from the training process is purely out of differentiation.

973
00:39:21,960 --> 00:39:23,360
One word is not another word.

974
00:39:23,360 --> 00:39:26,160
Words are not used in the same context.

975
00:39:26,160 --> 00:39:29,000
It understands everything only through examples

976
00:39:29,000 --> 00:39:29,840
given through language.

977
00:39:29,840 --> 00:39:32,680
It's like someone who learned English or how to speak,

978
00:39:32,680 --> 00:39:34,680
but they grew up in a featureless gray room.

979
00:39:34,680 --> 00:39:36,400
They've never seen the outside world.

980
00:39:36,400 --> 00:39:37,920
They have nothing to rest on that tells them

981
00:39:37,920 --> 00:39:40,840
that something is true and something is not true.

982
00:39:40,840 --> 00:39:42,480
So from the model's perspective,

983
00:39:42,480 --> 00:39:43,880
everything that it says it's true.

984
00:39:43,880 --> 00:39:46,560
It's trying its best to give you the best answer possible.

985
00:39:46,560 --> 00:39:49,080
And if it lying a little bit

986
00:39:49,080 --> 00:39:50,840
or conflating two different topics

987
00:39:50,840 --> 00:39:51,920
is the best way to achieve that,

988
00:39:51,920 --> 00:39:53,800
then it will decide to do so.

989
00:39:53,800 --> 00:39:54,920
It's a part of the architecture.

990
00:39:54,920 --> 00:39:56,320
We can't get around it.

991
00:39:56,320 --> 00:39:58,560
There are a number of cheap tricks

992
00:39:58,560 --> 00:40:02,040
that surprisingly get it to confabulate or hallucinate less.

993
00:40:02,040 --> 00:40:03,320
One of them includes recently,

994
00:40:03,320 --> 00:40:05,040
there was a paper that's a little funny.

995
00:40:05,040 --> 00:40:08,400
If you get it to prepend to its answer,

996
00:40:08,400 --> 00:40:11,520
my best guess is that will actually improve

997
00:40:11,520 --> 00:40:14,440
or reduce hallucinations by about 80%.

998
00:40:14,440 --> 00:40:15,880
So clearly it has some sense

999
00:40:15,880 --> 00:40:17,560
that some things are true and other things are not,

1000
00:40:17,560 --> 00:40:19,240
but we're not quite sure what that is.

1001
00:40:19,240 --> 00:40:20,680
To add on to what Ted was saying,

1002
00:40:20,680 --> 00:40:23,240
a few cheap things you can do include

1003
00:40:23,240 --> 00:40:25,120
letting it Google or Bing,

1004
00:40:25,120 --> 00:40:26,400
as in Bing Chat, what they're doing,

1005
00:40:26,400 --> 00:40:28,360
it cites this information,

1006
00:40:28,360 --> 00:40:31,440
asking it to make sure its own response is good.

1007
00:40:31,440 --> 00:40:34,720
If you've ever had JetGBT generate a program,

1008
00:40:34,720 --> 00:40:35,840
there's some kind of problem,

1009
00:40:35,840 --> 00:40:38,440
and you ask ChatGBT, I think there's a mistake.

1010
00:40:38,440 --> 00:40:40,920
Often it'll locate the mistake itself.

1011
00:40:40,920 --> 00:40:43,800
Why didn't produce the right answer at the very beginning?

1012
00:40:43,800 --> 00:40:44,800
We're still not sure,

1013
00:40:44,800 --> 00:40:45,800
but we're moving in the direction

1014
00:40:45,800 --> 00:40:46,840
of reducing hallucinations.

1015
00:40:46,840 --> 00:40:48,800
Now with respect to physics,

1016
00:40:48,800 --> 00:40:51,220
you're gonna have to give it an external database

1017
00:40:51,220 --> 00:40:53,840
to rest on because internally,

1018
00:40:53,840 --> 00:40:56,920
for really, really domain specific knowledge,

1019
00:40:56,920 --> 00:41:01,920
it's not going to be as deterministic as one would like.

1020
00:41:02,320 --> 00:41:04,120
These things work in continuous spaces.

1021
00:41:04,120 --> 00:41:06,560
These things, they don't know what is wrong,

1022
00:41:06,560 --> 00:41:10,360
what is true, and as a result, we have to give it tools.

1023
00:41:10,360 --> 00:41:12,760
So everything that Ted demoed today is really

1024
00:41:14,520 --> 00:41:16,760
striving at reducing hallucinations, actually, really,

1025
00:41:16,760 --> 00:41:18,200
and giving it more abilities.

1026
00:41:18,200 --> 00:41:20,560
I hope that answers your question.

1027
00:41:20,560 --> 00:41:22,760
One of the ways to, I mean, I'm a simple guy.

1028
00:41:22,760 --> 00:41:25,400
Like I tend to think that all of the world

1029
00:41:25,400 --> 00:41:27,920
tends to be just a few things repeated over and over again,

1030
00:41:27,920 --> 00:41:29,720
and we have human systems for this.

1031
00:41:29,720 --> 00:41:31,600
You know, in a team, like companies work,

1032
00:41:31,600 --> 00:41:33,520
or a team playing sport,

1033
00:41:33,600 --> 00:41:34,720
and we're not right all the time,

1034
00:41:34,720 --> 00:41:35,960
even when we aspire to be,

1035
00:41:35,960 --> 00:41:39,000
and so we have systems that we've developed as humans

1036
00:41:39,000 --> 00:41:41,120
to deal with things that may be wrong.

1037
00:41:41,120 --> 00:41:43,880
So, you know, human number one proposes an answer,

1038
00:41:43,880 --> 00:41:45,800
human number two checks their work,

1039
00:41:45,800 --> 00:41:48,320
human number three provides the final sign off.

1040
00:41:48,320 --> 00:41:49,480
This is really common.

1041
00:41:49,480 --> 00:41:50,640
Anybody who's worked in a company

1042
00:41:50,640 --> 00:41:51,960
has seen this in practice.

1043
00:41:51,960 --> 00:41:55,440
The interesting thing about the state of software right now,

1044
00:41:55,440 --> 00:41:56,920
we tend to be in this mode,

1045
00:41:56,920 --> 00:42:00,080
in which we're just talking to GPT as one entity.

1046
00:42:00,080 --> 00:42:02,640
But once we start thinking in terms of teams,

1047
00:42:02,640 --> 00:42:05,600
so to speak, where each team member is its own agent

1048
00:42:05,600 --> 00:42:07,880
with its own set of objectives and skills,

1049
00:42:07,880 --> 00:42:10,680
I suspect we're going to start seeing a programming model

1050
00:42:10,680 --> 00:42:13,720
in which the way to solve this might not necessarily be,

1051
00:42:13,720 --> 00:42:15,800
make a single brain smarter,

1052
00:42:15,800 --> 00:42:19,040
but instead be draw upon the collective intelligence

1053
00:42:19,040 --> 00:42:22,080
of multiple software agents, each playing a role.

1054
00:42:22,080 --> 00:42:24,600
And I think that that would certainly follow

1055
00:42:24,600 --> 00:42:26,560
the human pattern of how we deal with this.

1056
00:42:26,560 --> 00:42:29,160
To give an analogy, space shuttles,

1057
00:42:29,160 --> 00:42:31,720
things that go into space, spacecraft,

1058
00:42:31,720 --> 00:42:33,200
they have to be good.

1059
00:42:33,200 --> 00:42:34,480
If they're not good, people die.

1060
00:42:34,480 --> 00:42:38,000
They have no margin for error at all.

1061
00:42:38,000 --> 00:42:40,680
And as a result, we over engineer in those systems,

1062
00:42:40,680 --> 00:42:42,680
most spacecraft have three computers

1063
00:42:42,680 --> 00:42:44,360
and they all have to agree in unison

1064
00:42:44,360 --> 00:42:46,760
on a particular step to go forward.

1065
00:42:46,760 --> 00:42:49,320
If one does not agree, then they recalculate,

1066
00:42:49,320 --> 00:42:50,720
they recalculate, they recalculate

1067
00:42:50,720 --> 00:42:52,120
until they arrive at something.

1068
00:42:52,120 --> 00:42:54,240
The good thing is that hallucinations

1069
00:42:54,240 --> 00:42:55,720
are generally not a systemic problem

1070
00:42:55,720 --> 00:42:57,360
in terms of its knowledge.

1071
00:42:57,360 --> 00:43:00,200
It's often a one off, the model, something tripped it up

1072
00:43:00,200 --> 00:43:02,840
and it just produced a hallucination in that one instance.

1073
00:43:02,840 --> 00:43:04,600
So if there's three models working in unison,

1074
00:43:04,600 --> 00:43:07,880
just as Ted is saying, that will, generally speaking,

1075
00:43:07,880 --> 00:43:09,240
improve your success.

1076
00:43:10,800 --> 00:43:11,640
Yes, sir.

1077
00:43:11,640 --> 00:43:13,920
A number of the examples you show have assertions

1078
00:43:13,920 --> 00:43:18,120
like you are an engineer, you are an AI, you are a teacher.

1079
00:43:18,120 --> 00:43:20,840
What's the mechanism by which that influences

1080
00:43:20,840 --> 00:43:23,240
this computation of probabilities?

1081
00:43:23,240 --> 00:43:25,080
Sure, I'm gonna give you what might be

1082
00:43:25,080 --> 00:43:28,200
an unsatisfying answer, which is it tends to work.

1083
00:43:28,200 --> 00:43:30,160
But I think we know why it tends to work,

1084
00:43:30,160 --> 00:43:32,720
and again, it's because these language models approximate

1085
00:43:32,720 --> 00:43:34,160
how we talk to each other.

1086
00:43:34,160 --> 00:43:36,560
So if I were to say to you, hey, help me out,

1087
00:43:36,560 --> 00:43:39,000
I need you to mock interview me.

1088
00:43:39,000 --> 00:43:40,440
That's a direct statement I can make

1089
00:43:40,440 --> 00:43:42,680
that kicks you into a certain mode of interaction.

1090
00:43:42,680 --> 00:43:44,880
Or if I say to you, help me out,

1091
00:43:44,880 --> 00:43:46,840
I'm trying to apologize to my wife,

1092
00:43:46,840 --> 00:43:49,280
she's really mad at me, can you role play with me?

1093
00:43:49,280 --> 00:43:51,160
That kicks you into another mode of interaction.

1094
00:43:51,160 --> 00:43:54,360
And so it's really just a shorthand that people have found

1095
00:43:54,360 --> 00:43:56,680
to kick the agent in, to kick the LLM in,

1096
00:43:56,680 --> 00:43:58,480
to a certain mode of interaction

1097
00:43:58,480 --> 00:43:59,920
that it tends to work in the way

1098
00:43:59,920 --> 00:44:03,560
that I, as a software developer, am hoping it would work.

1099
00:44:03,560 --> 00:44:06,400
And to really quickly add on to that,

1100
00:44:06,400 --> 00:44:09,080
being in the digital humanities that I am,

1101
00:44:09,080 --> 00:44:10,520
I like to think of it as a narrative.

1102
00:44:10,520 --> 00:44:12,360
A narrative will have a few different characters

1103
00:44:12,360 --> 00:44:15,280
talking to each other, their roles are clearly defined,

1104
00:44:15,280 --> 00:44:16,760
two people are not the same.

1105
00:44:17,640 --> 00:44:20,360
This interaction with GPT, it assumes a personality,

1106
00:44:20,360 --> 00:44:22,000
it can simulate personalities.

1107
00:44:22,000 --> 00:44:23,880
It itself is not conscious in any way,

1108
00:44:23,880 --> 00:44:27,720
but it can certainly predict what a conscious being

1109
00:44:27,720 --> 00:44:29,600
would react like in a particular situation.

1110
00:44:29,600 --> 00:44:34,200
So when we're going URX, it is drawing up that personality

1111
00:44:34,200 --> 00:44:36,040
and talking as though it is that person.

1112
00:44:36,040 --> 00:44:38,320
Because it is like completing a transcript

1113
00:44:38,320 --> 00:44:41,600
or completing a story in which that character is present

1114
00:44:41,600 --> 00:44:44,520
and interacting and is active.

1115
00:44:44,520 --> 00:44:46,280
So, yeah.

1116
00:44:46,280 --> 00:44:49,120
I think we got about five minutes until the pizza outside.

1117
00:44:49,120 --> 00:44:49,960
Eight minutes.

1118
00:44:53,120 --> 00:44:53,960
Yes, sir.

1119
00:44:54,960 --> 00:44:59,720
So I'm not a CF person, but it's been a fun thing with this.

1120
00:44:59,720 --> 00:45:03,080
And I understand the sort of word-by-word generation

1121
00:45:03,080 --> 00:45:06,440
and the sort of vibe, the feeling of it in the narrative.

1122
00:45:07,400 --> 00:45:11,080
Some of my friends and I have tried giving it logic problems,

1123
00:45:11,080 --> 00:45:13,200
like things from the LSAT, for example,

1124
00:45:13,200 --> 00:45:14,840
and it doesn't work.

1125
00:45:14,840 --> 00:45:16,920
Like, and I'm just wondering why that would be.

1126
00:45:16,920 --> 00:45:19,960
So it will generate answers that sound

1127
00:45:19,960 --> 00:45:21,600
very plausible rhetorically.

1128
00:45:21,600 --> 00:45:24,520
Like, given this condition X, given this Y,

1129
00:45:24,520 --> 00:45:27,600
but it'll often, like, even contradict itself

1130
00:45:27,600 --> 00:45:30,840
in its answers, but it's almost never correct.

1131
00:45:30,840 --> 00:45:33,800
So I was wondering what, why that would be?

1132
00:45:33,800 --> 00:45:37,040
Like, it just can't reason, it can't, like, think.

1133
00:45:37,040 --> 00:45:41,080
And, like, can you, would we get to a place where it can,

1134
00:45:41,080 --> 00:45:41,920
so to speak?

1135
00:45:41,920 --> 00:45:43,120
I mean, not, you know what I mean?

1136
00:45:43,120 --> 00:45:44,720
I don't mean to think, like, it's conscious.

1137
00:45:44,720 --> 00:45:46,640
I mean, like, have thoughts, not-

1138
00:45:46,640 --> 00:45:48,800
You want to talk about react?

1139
00:45:48,800 --> 00:45:53,160
So GPT-4, when GPT-4 released back in March,

1140
00:45:53,160 --> 00:45:55,680
I think it was, it was passing LSAT.

1141
00:45:55,680 --> 00:45:56,520
It was.

1142
00:45:56,520 --> 00:45:57,360
It was, yeah.

1143
00:45:57,360 --> 00:45:58,200
Yes.

1144
00:45:58,200 --> 00:46:00,320
Yes, it just passed, as I understand it.

1145
00:46:00,320 --> 00:46:02,560
Well, maybe it's because we're not GPT.

1146
00:46:02,560 --> 00:46:03,840
That's one of the weird things.

1147
00:46:03,840 --> 00:46:04,680
Is that-

1148
00:46:04,680 --> 00:46:05,520
At GPT.

1149
00:46:05,520 --> 00:46:06,840
Yeah.

1150
00:46:06,840 --> 00:46:08,640
If you pay for chat GPT, they give you access

1151
00:46:08,640 --> 00:46:09,840
to the better model.

1152
00:46:09,840 --> 00:46:13,640
And one of the interesting things with it is prompting.

1153
00:46:13,640 --> 00:46:14,760
It's so finicky.

1154
00:46:14,760 --> 00:46:17,880
If you, it's very sensitive to the way that you prompt.

1155
00:46:17,880 --> 00:46:20,480
There were earlier on when GPT-3 came out,

1156
00:46:20,480 --> 00:46:21,560
some people were going,

1157
00:46:21,560 --> 00:46:23,040
look, I can pass literacy tests,

1158
00:46:23,040 --> 00:46:25,240
or no, it can't pass literacy tests.

1159
00:46:25,240 --> 00:46:28,160
And then people who are pro or anti-GPT would be like,

1160
00:46:28,160 --> 00:46:29,480
I modified the prompt a little bit,

1161
00:46:29,480 --> 00:46:31,400
suddenly it can't, or suddenly it can't.

1162
00:46:31,400 --> 00:46:33,600
These things are not conscious.

1163
00:46:33,600 --> 00:46:36,000
Their ability to reason is like an alien's.

1164
00:46:36,000 --> 00:46:36,840
They're not us.

1165
00:46:36,840 --> 00:46:37,800
They don't think like people.

1166
00:46:37,800 --> 00:46:38,960
They're not human.

1167
00:46:38,960 --> 00:46:42,360
But they certainly are capable of passing some things

1168
00:46:42,360 --> 00:46:44,680
empirically, which demonstrates some sort of

1169
00:46:44,680 --> 00:46:46,680
rationale or logic within the model.

1170
00:46:46,680 --> 00:46:48,560
But we're still slowly figuring out,

1171
00:46:48,560 --> 00:46:49,880
like a prompt whisperer,

1172
00:46:49,880 --> 00:46:51,560
what exactly the right approach is.

1173
00:46:54,120 --> 00:46:54,960
Yeah?

1174
00:46:56,160 --> 00:47:01,200
Obviously, having GPT-3 running and prompting it

1175
00:47:01,200 --> 00:47:04,640
continuously is very expensive in terms of the user.

1176
00:47:04,640 --> 00:47:08,760
Have you seen instances where it directly creates

1177
00:47:08,760 --> 00:47:11,880
some sort of business value in for a whisperer,

1178
00:47:11,880 --> 00:47:15,480
for a company with a real added value of having

1179
00:47:15,480 --> 00:47:19,480
for these real AI apps in terms of

1180
00:47:19,480 --> 00:47:22,600
like a review of the drives and the actual digital stuff?

1181
00:47:22,600 --> 00:47:24,960
Yeah, I mean, we host companies on top of us,

1182
00:47:24,960 --> 00:47:27,480
who that's their primary product.

1183
00:47:27,480 --> 00:47:31,480
The value that it adds is like any company.

1184
00:47:31,480 --> 00:47:33,600
I mean, it's, you know, what is the Y Combinator motto,

1185
00:47:33,600 --> 00:47:34,640
make something people want?

1186
00:47:34,640 --> 00:47:37,840
I mean, I wouldn't think of this as GPT inherently

1187
00:47:37,840 --> 00:47:40,040
provides value for you as a builder.

1188
00:47:40,040 --> 00:47:41,120
Like that's their product.

1189
00:47:41,120 --> 00:47:42,160
That's OpenAI's product.

1190
00:47:42,160 --> 00:47:45,080
You pay chat GPT for prioritized access.

1191
00:47:45,080 --> 00:47:47,880
Where your product might be is how you take that

1192
00:47:47,880 --> 00:47:50,760
and combine it with your data, somebody else's data,

1193
00:47:50,760 --> 00:47:53,480
some domain knowledge, some interface

1194
00:47:53,480 --> 00:47:56,320
that then helps apply it to something.

1195
00:47:56,320 --> 00:47:58,000
It is, two things are both true.

1196
00:47:58,000 --> 00:48:00,960
There are a lot of experiments going on right now,

1197
00:48:00,960 --> 00:48:03,640
both for fun and people trying to figure out

1198
00:48:03,640 --> 00:48:05,240
where the economic value is.

1199
00:48:05,240 --> 00:48:07,160
But folks are also spinning up companies

1200
00:48:07,160 --> 00:48:10,000
that are 100% supported by applying this to data.

1201
00:48:10,000 --> 00:48:13,760
Okay, first, a company that wouldn't have,

1202
00:48:13,760 --> 00:48:17,520
sort of, wouldn't be AI focused as an input, right?

1203
00:48:17,520 --> 00:48:19,680
As it's just using or developing, like,

1204
00:48:19,680 --> 00:48:23,680
announcements that use GPT for productivity.

1205
00:48:25,480 --> 00:48:30,000
I think that it is likely that today we call this GPT

1206
00:48:30,000 --> 00:48:31,360
and today we call these LLMs

1207
00:48:31,360 --> 00:48:33,640
and tomorrow it will just slide into the ether.

1208
00:48:33,640 --> 00:48:36,080
I mean, imagine what the progression is going to be.

1209
00:48:36,080 --> 00:48:37,680
Today there's one of these

1210
00:48:37,680 --> 00:48:39,360
that people are primarily playing with.

1211
00:48:39,360 --> 00:48:40,600
There's many of them that exist,

1212
00:48:40,600 --> 00:48:42,600
but one, people are primarily bidding on top.

1213
00:48:42,600 --> 00:48:45,800
Tomorrow we can expect that there will be many of them

1214
00:48:45,800 --> 00:48:47,360
and the day after that we can expect

1215
00:48:47,360 --> 00:48:48,440
they're going to be on our phones

1216
00:48:48,440 --> 00:48:50,720
and they're not even going to be connected to the internet.

1217
00:48:50,720 --> 00:48:53,600
And for that reason, I think that,

1218
00:48:53,600 --> 00:48:56,760
like today we don't call our software microprocessor tools

1219
00:48:56,760 --> 00:49:00,080
or microprocessor apps, like the processor just exists.

1220
00:49:00,080 --> 00:49:03,640
I think that one useful model, five years out,

1221
00:49:03,640 --> 00:49:07,080
10 years out, is to, even if it's only metaphorically true

1222
00:49:07,080 --> 00:49:10,320
and not literally true, I think it's useful

1223
00:49:10,320 --> 00:49:12,120
to think of this as a second processor.

1224
00:49:12,120 --> 00:49:15,160
We had this before with what floating point co-processors

1225
00:49:15,160 --> 00:49:18,840
and graphics co-processors already as recently as the 90s

1226
00:49:18,840 --> 00:49:21,600
where it's useful to think of the trajectory of this

1227
00:49:21,600 --> 00:49:24,600
as just another thing that computers to do can do

1228
00:49:24,600 --> 00:49:27,040
and it will be incorporated into absolutely everything.

1229
00:49:27,040 --> 00:49:29,800
Hence the term foundation model, which also crops up.

1230
00:49:31,440 --> 00:49:34,000
So, pizza's ready?

1231
00:49:34,000 --> 00:49:34,980
One more quick.

1232
00:49:34,980 --> 00:49:37,720
Maybe one more and then we'll break for some food.

1233
00:49:40,520 --> 00:49:42,080
In the glasses right there, sorry.

1234
00:49:43,120 --> 00:49:48,560
Sorry, I was just being told we need to get two more.

1235
00:49:48,560 --> 00:49:49,400
So, yeah.

1236
00:49:58,440 --> 00:50:00,080
It's hard to get it to do that reliably.

1237
00:50:00,080 --> 00:50:02,360
It's incredibly useful to get it to do reliably.

1238
00:50:02,360 --> 00:50:05,720
So some tricks you can use are, you can give it examples.

1239
00:50:05,720 --> 00:50:07,380
You can just ask it directly.

1240
00:50:08,480 --> 00:50:10,760
Those are two common tricks.

1241
00:50:10,760 --> 00:50:13,200
And look at the prompts that others have used to work.

1242
00:50:13,200 --> 00:50:15,800
I mean, there's a lot of art to finding the right prompt

1243
00:50:15,800 --> 00:50:16,640
right now.

1244
00:50:16,640 --> 00:50:19,240
A lot of it is magic incantation.

1245
00:50:19,240 --> 00:50:22,440
Another thing you can do is post-process it

1246
00:50:22,440 --> 00:50:23,840
so that you can do some checking

1247
00:50:23,840 --> 00:50:25,400
and you can have a happy path

1248
00:50:25,400 --> 00:50:27,280
in which it's a one shot and you get your answer

1249
00:50:27,280 --> 00:50:29,480
and then a sad path in which maybe you fall back

1250
00:50:29,480 --> 00:50:30,320
on other prompts.

1251
00:50:30,320 --> 00:50:32,400
So then you're going for the diversity of approach

1252
00:50:32,400 --> 00:50:34,680
where it's fast by default.

1253
00:50:34,680 --> 00:50:36,640
It's slow but ultimately converging

1254
00:50:36,640 --> 00:50:38,960
upon higher likelihood of success if it fails.

1255
00:50:39,160 --> 00:50:40,880
And then something that I'm sure we'll see

1256
00:50:40,880 --> 00:50:44,040
and people do later on is fine-tune instruction

1257
00:50:44,040 --> 00:50:46,960
tuning style models, which are more likely to respond

1258
00:50:46,960 --> 00:50:49,720
with the computer parsable output.

1259
00:50:49,720 --> 00:50:51,360
I guess one last question?

1260
00:50:51,360 --> 00:50:52,200
Sure.

1261
00:50:52,200 --> 00:50:55,000
So one of the, you talked a couple of things.

1262
00:50:55,000 --> 00:50:57,640
One is, is you talked about domain expertise here

1263
00:50:57,640 --> 00:51:00,280
and you were coding a bunch of domain expertise

1264
00:51:00,280 --> 00:51:03,040
in terms of the prompts that you're going for.

1265
00:51:03,040 --> 00:51:05,000
What is that, where do those prompts end up?

1266
00:51:05,000 --> 00:51:07,480
Do those prompts end up back in the gene chat

1267
00:51:08,080 --> 00:51:11,640
and is there a privacy issue associated with that?

1268
00:51:11,640 --> 00:51:12,480
That's a great question.

1269
00:51:12,480 --> 00:51:13,680
So the question was, and I apologize,

1270
00:51:13,680 --> 00:51:14,840
I just realized we haven't been repeating

1271
00:51:14,840 --> 00:51:16,720
all the questions for the YouTube listeners.

1272
00:51:16,720 --> 00:51:18,120
So I'm sorry for the folks on YouTube

1273
00:51:18,120 --> 00:51:20,240
if you weren't able to hear some of the questions.

1274
00:51:20,240 --> 00:51:22,120
The question was, what are the privacy implications

1275
00:51:22,120 --> 00:51:22,960
of some of these prompts?

1276
00:51:22,960 --> 00:51:26,080
If one of the messages is so much depends upon your prompt

1277
00:51:26,080 --> 00:51:27,560
and the fine-tuning of this prompt,

1278
00:51:27,560 --> 00:51:29,800
what does that mean with respect to my IP?

1279
00:51:29,800 --> 00:51:32,360
Maybe the prompt is my business.

1280
00:51:32,360 --> 00:51:34,200
I can't offer you the exact answer

1281
00:51:34,200 --> 00:51:36,280
but I can paint for you what approximately

1282
00:51:36,280 --> 00:51:37,420
the landscape looks like.

1283
00:51:37,420 --> 00:51:40,580
So in all of software and so too with AI,

1284
00:51:40,580 --> 00:51:42,540
what we see is they're the SaaS companies

1285
00:51:42,540 --> 00:51:44,940
where you're using somebody else's API

1286
00:51:44,940 --> 00:51:46,820
and you're trusting that their terms of service

1287
00:51:46,820 --> 00:51:48,420
will be upheld.

1288
00:51:48,420 --> 00:51:51,580
There's the set of companies in which they provide a model

1289
00:51:51,580 --> 00:51:53,940
for hosting on one of the big cloud providers

1290
00:51:53,940 --> 00:51:56,020
and this is a version of the same thing

1291
00:51:56,020 --> 00:51:57,700
but I think with slightly different mechanics.

1292
00:51:57,700 --> 00:51:59,500
This tends to be thought of as the enterprise version

1293
00:51:59,500 --> 00:52:01,260
of software and by and large,

1294
00:52:01,260 --> 00:52:03,300
the industry has moved over the past 20 years

1295
00:52:03,300 --> 00:52:05,060
from running my own servers to trusting

1296
00:52:05,060 --> 00:52:07,820
that Microsoft or Amazon or Google can run servers for me

1297
00:52:07,820 --> 00:52:09,540
and they say it's my private server

1298
00:52:09,540 --> 00:52:10,820
even though I know they're running it

1299
00:52:10,820 --> 00:52:11,980
and I'm okay with that.

1300
00:52:11,980 --> 00:52:14,660
And you've already started to see that Amazon

1301
00:52:14,660 --> 00:52:16,700
with Huggingface, Microsoft with OpenAI,

1302
00:52:16,700 --> 00:52:18,780
Google too with their own version of Bard

1303
00:52:18,780 --> 00:52:21,660
are going to do these where you'll have the SaaS version

1304
00:52:21,660 --> 00:52:23,820
and then you'll also have the private VPC version

1305
00:52:23,820 --> 00:52:25,100
and then there's a third version

1306
00:52:25,100 --> 00:52:27,180
that I think we haven't yet seen practically emerge

1307
00:52:27,180 --> 00:52:29,140
but this would be the maximalist.

1308
00:52:29,140 --> 00:52:32,540
I wanna make sure my IP is maximally safe version of events

1309
00:52:32,540 --> 00:52:34,620
in which you are running your own machines.

1310
00:52:34,620 --> 00:52:36,140
You are running your own models

1311
00:52:36,140 --> 00:52:37,780
and then the question is,

1312
00:52:37,780 --> 00:52:40,340
is the open source and or privately available version

1313
00:52:40,340 --> 00:52:43,300
of the model as good as the publicly hosted one

1314
00:52:43,300 --> 00:52:44,540
and does that matter to me?

1315
00:52:44,540 --> 00:52:46,460
And the answers right now, realistically,

1316
00:52:46,460 --> 00:52:48,180
it probably matters a lot.

1317
00:52:48,180 --> 00:52:49,620
In the fullness of time,

1318
00:52:49,620 --> 00:52:52,540
you can think of any one particular task you need to achieve

1319
00:52:52,540 --> 00:52:55,620
as requiring some fixed point of intelligence to achieve.

1320
00:52:55,620 --> 00:52:57,740
And so over time, what we'll see is

1321
00:52:57,740 --> 00:52:59,960
the privately obtainable versions of these models

1322
00:52:59,960 --> 00:53:01,340
will cross that threshold

1323
00:53:01,340 --> 00:53:03,540
and with respect to that one task,

1324
00:53:03,540 --> 00:53:05,260
yeah, sure, use the open source version,

1325
00:53:05,260 --> 00:53:06,540
run it on your own machine,

1326
00:53:06,540 --> 00:53:09,580
but we'll also see the SaaS intelligence get smarter.

1327
00:53:09,580 --> 00:53:10,780
It'll probably stay ahead.

1328
00:53:10,780 --> 00:53:12,020
And then your question is,

1329
00:53:12,020 --> 00:53:13,620
well, which one do I care more about?

1330
00:53:13,620 --> 00:53:15,740
Do I want like the better aggregate intelligence

1331
00:53:15,740 --> 00:53:17,780
or is my task somewhat fixed point

1332
00:53:17,780 --> 00:53:20,020
and I can just use the open source available one

1333
00:53:20,020 --> 00:53:21,660
for which I know it'll perform well enough

1334
00:53:21,660 --> 00:53:23,180
because it's crossed the threshold.

1335
00:53:23,180 --> 00:53:25,160
So to answer your question specifically,

1336
00:53:25,160 --> 00:53:27,580
yes, you might be glad to know

1337
00:53:27,580 --> 00:53:30,100
Chachi PT recently updated their privacy policy

1338
00:53:30,100 --> 00:53:32,940
to not use prompts for the training process,

1339
00:53:32,940 --> 00:53:35,100
but up until now, everything went back into the bin

1340
00:53:35,100 --> 00:53:37,660
to be trained on again, okay.

1341
00:53:37,660 --> 00:53:39,300
And that's just a fact.

1342
00:53:39,300 --> 00:53:42,220
So I think pizza is now pizza time.

1343
00:53:42,220 --> 00:53:43,380
Okay, okay.

1344
00:53:43,380 --> 00:53:44,220
Okay.

1345
00:53:44,220 --> 00:53:45,220
Yeah.

1346
00:53:45,220 --> 00:53:48,340
But we'll have to talk about Q&A's and everything else.

1347
00:53:48,340 --> 00:53:49,180
Perfect.

