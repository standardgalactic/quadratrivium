start	end	text
0	1560	All right.
1560	3560	Well, this is CS50 Tech Talk.
3560	4920	Thank you all so much for coming.
4920	6960	So about a week ago, we circulated the Google Form,
6960	9660	as you might have seen, at 10.52 AM.
9660	12600	And by, like, 11.52 AM, we had 100 RSVPs,
12600	14680	which I think is sort of testament to just how much interest
14680	18100	there is in this world of AI, and open AI, and GPT, chat
18100	19200	GPT, and the like.
19200	21840	And in fact, if you're sort of generally familiar with what
21840	24320	everyone's talking about, but you haven't tried it yourself,
24320	26680	this is the URL, which you can try out this tool
26680	29120	that you've probably heard about, chat GPT.
29120	30680	You can sign up for a free account there
30680	32800	and start tinkering with what everyone else has been
32800	33640	tinkering with.
33640	36400	And then if you're more of the app-minded type, which you probably
36400	39720	are if you are here with us today, open AI in particular
39720	43240	has its own low-level APIs via which you can integrate AI
43240	44560	into your own software.
44560	46920	But of course, as is the case in computer science,
46920	49040	there's all the more abstractions and services
49040	51200	that have been built on top of these technologies.
51200	53840	And we're so happy today to be joined by our friends
53840	56280	from McGill University and Steamship,
56320	58720	Sill and Ted, from whom you'll hear in just a moment,
58720	62160	to speak to us about how they are making it easier to build,
62160	64680	to deploy, to share applications using some
64680	65960	of these very same technologies.
65960	68240	So our thanks to them for hosting today.
68240	70080	Our friends at Plimpton, Jenny Lee and alumna,
70080	72120	who's here with us today, but without further ado,
72120	73840	allow me to turn things over to Ted and Sill.
73840	78000	And pizza will be served shortly after 1 PM outside.
78000	79760	All right, over to you, Ted.
79760	81400	Thanks a lot.
81400	83280	Hey, everybody, it's great to be here.
83280	85800	I think we've got a really good talk for you today.
85800	88080	Sill's gonna provide some research grounding
88080	90920	into how it all works, what's going inside,
90920	94120	the brain of GPT as well as other language models.
94120	96000	And then I'll show you some examples that we're seeing
96000	98240	on the ground of how people are building apps
98240	100380	and what apps tend to work in the real world.
100380	103480	So our perspective is we're building AWS for AI apps.
103480	105160	So we get to talk to a lot of the makers
105160	106600	who are building and deploying their apps.
106600	108920	And through that, see both the experimental end
108920	111800	of the spectrum and also see what kinds of apps
111800	113720	are getting pushed out there and turned into companies,
113720	115520	turned into side projects.
115560	119200	We did a cool hackathon yesterday.
119200	122000	Many thanks to Neiman, to David Malin and CS50
122000	123400	for helping us put all of this together,
123400	124760	to Harvard for hosting it.
124760	127920	And there were two sessions, lots of folks built things.
127920	131100	If you go to steamship.com slash hackathon,
131100	132400	you'll find a lot of guides,
132400	133840	a lot of projects that people built.
133840	136560	And you can follow along, we have a text guide as well,
136560	138440	just as a quick plug for that,
138440	141240	if you want to do it remotely or on your own.
141240	143880	So to tee up Sill, we're gonna talk about
143880	147160	basically two things today that I hope you'll walk away with
147160	149840	and really know how to then use as you develop
149840	150680	and as you tinker.
150680	153160	One is what is GPT and how is it working?
153160	155240	Get a good sense of what's going on inside of it
155240	158280	other than as just this magical machine that predicts things.
158280	160720	And then two is how are people building with it?
160720	162800	And then importantly, how can I build with it too
162800	163680	if you're a developer?
163680	165800	And if you have CS50 background,
165800	167160	you should be able to pick things up
167160	168160	and start building some great apps.
168160	170080	I've already met some of the CS50 grads yesterday
170080	171800	and the things that they were doing were pretty amazing.
171800	173000	So hope this is useful.
173000	174320	I'm gonna kick it over to Sill
174320	179280	and talk about some of the theoretical background of GPT.
179280	181160	Yeah, so thank you, Ted.
181160	182000	My name is Sill.
182000	184560	I'm a graduate student of Digital Humanities at McGill.
184560	186560	I study literature and computer science
186560	188480	and linguistics in the same breath.
188480	190520	And I've published some research over the last couple of years
190520	193800	exploring what is possible with language models
193800	195640	and culture in particular.
195640	199760	And my half or whatever of the presentation
199760	201880	is to describe to you what is GPT.
201880	204240	That's really difficult to explain in 15 minutes.
204240	206720	And there are even a lot of things that we don't know,
206720	208040	but a good way to approach that
208040	210200	is to first consider all the things
210200	213320	that people call GPT by or descriptors.
213320	215680	So you can call them large language models.
215680	218000	You can call them universal approximators
218000	219040	from computer science.
219040	222440	You can say that it is a generative AI.
222440	224040	We know that they are neural networks.
224040	226440	We know that it is an artificial intelligence.
226440	228160	To some, it's a simulator of culture.
228160	230280	To others, it just predicts text.
230320	231480	It's also a writing assistant.
231480	232840	If you've ever used ChatGPT,
232840	235000	you can plug in a bit of your essay, get some feedback.
235000	236520	It's amazing for that.
236520	237560	It's a content generator.
237560	240760	People use it to do copywriting, Jasper.AI,
240760	242200	pseudo-write, et cetera.
242200	243640	It's an agent.
243640	245160	So the really hot thing right now,
245160	248480	if you might have seen it on Twitter, auto-GPT, baby-AGI,
248480	250560	people are giving these things tools
250560	253160	and letting them run a little bit free in the wild
253160	256120	to interact with the world computers, et cetera.
256120	258160	We use them as chatbots, obviously.
258160	261840	And the actual architecture is a transformer.
261840	264480	So there's lots of ways to describe GPT.
264480	267760	And any of them is a really perfectly adequate way
267760	269640	to begin the conversation.
269640	271320	But for our purposes, we can think of it
271320	272480	as a large language model,
272480	274920	and more specifically, a language model.
274920	279080	And a language model is a model of language,
279080	280360	if you allow me the tautology,
280360	281960	but really what it does is it produces
281960	284760	a probability distribution over some vocabulary.
284760	287520	So let us imagine that we had the task
288040	291000	of predicting the next word of the sequence I am.
291000	295360	So if I give a neural network the words I am,
295360	297880	what of all words in English
297880	300000	is the next most likely word to follow?
300000	304680	That, at its very core, is what GPT is trained to answer.
304680	308680	And how it does it is it has a vocabulary of 50,000 words,
308680	312040	and it knows, roughly, given the entire internet,
312040	314840	which words are likely to follow other words
315840	317960	of those 50,000 in some sequence,
317960	321200	up to 2,000 words, up to 4,000, up to 8,000,
321200	323640	and now up to 32,000 GPT4.
323640	326200	So you give it a sequence, here I am,
326200	329120	and over the vocabulary of 50,000 words,
329120	332480	it gives you the likelihood of every single word that follows.
332480	336920	So here it's I am, perhaps the word happy is fairly frequent,
336920	338360	so we'll get that high probability
338360	341480	if we look at all words, all utterances of English.
341480	344800	It might be I am sad, maybe that's a little bit less probable,
345000	346880	I am school, that really should be at the end
346880	348800	because I don't think anybody would ever say that,
348800	351760	I am Bjork, that's a little bit, it's not very probable,
351760	353720	but it's less probable than happy sad,
353720	355800	but there's still some probability attached to it.
355800	358280	And when we say it's probable, that's literally a percentage,
358280	363280	that's like happy follows I am maybe like 5% of the time,
363400	366960	sad follows I am maybe 2% of the time, or whatever.
366960	371520	So for every word that we give GPT,
371520	373920	it tries to predict what the next word is
373920	376920	across 50,000 words, and it gives every single one
376920	381920	of those 50,000 words a number that reflects how probable it is.
383160	385360	And the really magical thing that happens
385360	390280	is you can generate new text, so if you give GPT I am,
390280	394240	and it predicts happy as being the most probable word
394240	397880	over 50,000, you can then append it to I am,
397880	401360	so now you say I am happy, and you feed it into the model again,
401480	403680	you sample another word, you feed it into the model again,
403680	405240	and again, and again, and again,
405240	407720	and there's lots of different ways that I am happy,
407720	410920	I am sad, can go, and you add a little bit of randomness,
410920	412520	and all of a sudden you have a language model
412520	414840	that can write essays, that can talk,
414840	417760	and a whole lot of things, which is really unexpected,
417760	419120	and something that we didn't predict
419120	421880	even five years ago, so this is all relevant.
421880	426880	And if we move on, as we scale up the model,
427520	430680	and we give it more compute, in 2012 AlexNet came out,
430680	435280	and we figured out we can run the model on GPUs,
435280	436920	so we can speed up the process,
436920	438960	we can give the model lots of information
438960	440320	downloaded from the internet,
440320	441840	and it learns more and more and more,
441840	444520	and the probabilities that it gives you
444520	446120	get better as it sees more examples
446120	447600	of English on the internet,
447600	450160	so we have to train the model to be really large,
450160	453000	really wide, and we have to train it for a really long time,
453000	455840	and as we do that, the model gets more and more better,
455840	457720	and expressive and capable,
457720	459760	and it also gets a little bit intelligent,
459760	462200	and for reasons we don't understand.
462200	465880	So, but the issue is that because it learns
465880	467600	to replicate the internet,
467600	471000	it knows how to speak in a lot of different genres of text,
471000	472520	and a lot of different registers.
472520	475120	If you begin the conversation like, chat GPT,
475120	476760	can you explain the moon landing to a six year old
476760	478760	in a few sentences, GPT three,
478760	481080	this is an example drawn from the Instruct GPT paper
481080	485640	from OpenAI, GPT three would have just been like,
485640	487640	okay, so you're giving me an example,
487640	489640	like explain the moon landing to a six year old,
489640	491480	I'm gonna give you a whole bunch of similar things
491480	493640	because those seem very likely to come in a sequence.
493640	495520	It doesn't necessarily understand that it's being asked
495520	498320	that question has to respond with an answer.
498320	501560	GPT three did not have that apparatus,
501560	504000	that interface for responding to questions,
504000	509000	and the scientist at OpenAI came up with the solution,
509280	511640	and that's, let's give it a whole bunch of examples
511640	513240	of question and answers,
513240	515640	such that we first train it on the internet,
515640	517640	and then we train it with a whole bunch of questions
517640	521320	and answers such that it has the knowledge of the internet,
521320	524200	but really knows that it has to be answering questions,
524200	527640	and that is when chat GPT was born,
527640	530520	and that's when it gained 100 million users in one month,
530520	533360	I think it beat TikTok's record at 20 million in one month,
533360	536560	it was a huge thing, and for a lot of people,
536560	538720	they went, oh, this thing is intelligent,
538720	541400	I can answer, I can ask it questions, it answers back,
541400	543600	we can work together to come to a solution,
543600	546400	and that's because it's still predicting words,
546400	548120	it's still a language model,
548120	551440	but it knows to predict words in the framework
551440	554560	of a question and answer, so that's what a prompt is,
554560	557560	that's what instruction tuning is, that's a key word,
557560	561920	that's what RLHF is, if you've ever seen that acronym,
561920	564760	Reinforcement Alignment with Human Feedback,
564760	567840	and all those combined means that the models
567840	568920	that are coming out today,
568920	570600	the types of language predictors
570600	571840	that are coming out today,
571840	574000	work to operate in a Q and A form.
574000	578400	GPT-4 exclusively only has the aligned model available,
578400	582920	and this is a really great, solid foundation to build on,
582920	584360	because you can do all sorts of things,
584360	586440	you can ask chat GPT, can you do this for me,
586440	587480	can you do that for me?
587480	588680	You might have seen that OpenAI
588680	591020	has allowed plugin access to chat GPT,
591020	593800	so it can access Wolfram, it can search the web,
593800	596280	it can search, it can do Instacart for you,
596280	600520	it can look up recipes, once the model knows
600520	602640	that not only it has to predict language,
602640	605000	but that it has to solve a problem,
605920	607640	and the problem here being,
607640	609560	give me a good answer to my question,
609560	611560	it's suddenly able to interface with the world
611560	613000	in a really solid way,
613000	615720	and from there on, there's been all sorts of tools
615720	619600	that it build on this Q and A form that chat GPT uses,
619600	622800	you have auto GPT, you have Langchain,
622800	626840	you have React, there was a React paper
626840	628140	where a lot of these come from,
628140	630880	and turning the model into an agent
631480	634560	which to achieve any ambiguous goal
634560	636080	is where the future is going,
636080	638360	and this is all thanks to instruction tuning,
638360	641720	and with that, I think I will hand it off to Ted,
641720	643320	who will be giving a demo,
643320	644560	or something along those lines,
644560	649360	for how to use GPT as an agent, so.
651920	654640	All right, so I'm a super applied guy,
654640	656800	I kinda look at things and think,
656800	660080	okay, how can I add this Lego, add that Lego,
660120	662520	and clip them together and build something with it,
662520	666760	and right now, if you look back in computer science history,
666760	668200	when you look at the kinds of things
668200	670240	that were being done in 1970,
670240	671980	right after computing was invented,
671980	674080	the microprocessors were invented,
674080	675240	people were doing research like,
675240	677120	how do I sort a list of numbers,
677120	678360	and that was meaningful work,
678360	680760	and importantly, it was work that's accessible to everybody,
680760	682960	because nobody knows what we can build
682960	685760	with this new kind of oil, this new kind of electricity,
685760	688840	this new kind of unit of computation we've created,
688880	690160	and anything was game,
690160	692240	and anybody could participate in that game
692240	693080	to figure it out,
693080	694440	and I think one of the really exciting things
694440	697240	about GPT right now is, yes,
697240	698920	in and of itself, it's amazing,
698920	701520	but then, what could we do with it
701520	703160	if we call it over and over again,
703160	704900	if we build it into our algorithms,
704900	706520	and start to build it into broader software,
706520	707960	so the world really is yours
707960	710080	to figure out those fundamental questions
710080	712600	about what could you do if you could script
712600	715280	computation itself over and over again
715280	716940	in the way that computers can do,
716940	719540	not just talk with it, but build things atop it,
719540	722100	so we're a hosting company, we host apps,
722100	724520	and these are just some of the things that we see,
724520	726260	I'm gonna show you demos of this with code
726260	728740	and try to explain some of the thought process,
728740	730740	but I wanted to give you a high level overview of,
730740	732740	you've probably seen these on Twitter,
732740	734660	but when it all sorts out to the top,
734660	736260	these are some of the things that we're seeing
736260	739540	built and deployed with language models today,
739540	742500	companionship, that's everything from I need a friend,
742500	743820	to I need a friend with a purpose,
743820	745940	I want a coach, I want somebody to tell me,
745940	747380	go to the gym and do these exercises,
747380	749620	I want somebody to help me study a foreign language,
749620	751400	question answering, this is a big one,
751400	753100	this is everything from your newsroom,
753100	755540	having a slack bot that helps assist you,
755540	759260	does this article conform to the style guidelines
759260	761500	of our newsroom, all the way through to,
761500	762740	and you need help on my homework,
762740	764540	or hey, I have some questions that I want you to ask,
764540	766860	Wikipedia, combine it with something else,
766860	768980	synthesize the answer and give it to me.
768980	771940	Utility functions, I would describe this as,
771940	774860	there's a large set of things for which
774900	777580	human beings can do them, if only,
777580	780060	or computers could do them, if only they had access
780060	781820	to language computation, language knowledge,
781820	783340	an example of this would be,
783340	786460	read every tweet on Twitter, tell me the ones I should read,
786460	787940	that way I only get to read the ones
787940	789140	that actually make sense to me
789140	790740	and I don't have to skim through the rest,
790740	793460	creativity, image generation, text generation,
793460	795980	storytelling, proposing other ways to do things,
795980	799740	and then these wild experiments and kind of baby AGI,
799740	801380	as people are calling them,
801380	803500	in which the AI itself decides what to do
803500	805300	and is self-directed, so I'll show you examples
805300	807180	of many of these and what the code looks like,
807180	809740	and if I were you, I would think about these
809740	812820	as categories within which to both think about
812820	817140	what you might build and then also seek out starter projects
817140	819660	for how you might go about building them online.
822500	823820	All right, so I'm just gonna dive straight into
823820	825500	demos and code for some of these,
825500	827180	because I know that's what's interesting to see
827180	829860	as fellow builders, with a high level diagram
829860	831580	for some of these as to how it works.
831580	834780	So approximately, you can think of a companionship bot
834780	837620	as a friend that has a purpose to you,
837620	840100	and there are many ways to build all of these things,
840100	841780	but one of the ways you can build this
841780	844660	is simply to wrap GPT or a language model
844660	847860	in an endpoint that additionally injects into the prompt
847860	850700	some particular perspective or some particular goal
850700	851980	that you want to use.
851980	853820	It really is that easy in a way,
853820	856140	but it's also very hard because you need to iterate
856140	859820	and engineer the prompt so that it consistently performs
859820	862140	the way you want it to perform.
862140	864700	So a good example of this is something somebody built
864700	865620	in the hackathon yesterday,
865620	867940	and I just wanted to show you the project that they built.
867940	869540	It was a Mandarin idiom coach,
869540	871820	and I'll show you what the code looked like first.
871820	873860	I'll show you the demo first.
873860	875300	I think I already pulled it up.
878140	879300	Here we go.
879300	882820	So the buddy that this person wanted to create
882820	887220	was a friend that if you gave it a particular problem
887220	889900	you were having, it would pick a Chinese idiom,
889900	893100	a four character Cheng Yu, that described poetically,
893100	896100	like here's a particular way you could say this,
896100	897780	and it would tell it to her so that the person
897780	899700	who built this was studying Chinese
899700	901980	and she wanted to learn more about it.
901980	906820	So I might say something like I'm feeling very sad,
908140	910420	and it would think a little bit,
910420	912780	and if everything's up and running,
912780	916260	it will generate one of these four character phrases,
916260	919700	and it will respond to it with an example.
919700	921020	Now, I don't know if this is correct or not,
921020	922380	so if somebody can call me out,
922380	925220	if this is actually incorrect, please call me out,
926220	928420	and it will then finish up with something encouraging,
928420	930980	saying hey, you can do it, I know this is hard, keep going.
930980	932340	So let me show you how they built this,
932340	937340	and I pulled up the code right here.
940540	945060	So this was the particular starter replete
945060	947420	that folks were using in the hackathon yesterday,
947420	949940	and we pulled things up into basically,
949940	952700	you have a wrapper around GPT,
952700	954380	and there's many things you could do,
954380	956300	but we're gonna make it easy for you to do two things.
956300	960060	One of them is to inject some personality into the prompt,
960060	962660	and I'll explain what that prompt is in a second,
962660	964140	and then the second is add tools
964140	965580	that might go out and do a particular thing,
965580	968260	search the web or generate an image
968260	969700	or add something to a database
969700	971780	or fetch something from a database.
971780	973100	So having done that,
973100	975340	now you have something more than GPT.
975340	977780	Now you have GPT, which we all know what it is
977780	979100	and how we can interact with it,
979100	981700	but you've also added a particular lens
981700	982700	through which it's talking to you
982700	983660	and potentially some tools.
983660	987140	So this particular Chinese tutor,
987140	990320	all it took to build that was four lines.
990320	991660	So here's a question that I think
991660	994700	is frying the minds of everybody in the industry right now.
995700	998300	So is this something that we'll all do casually
998300	999300	and nobody really knows?
999300	1001260	Will we just all say in the future to the LLM,
1001260	1002500	hey, for the next five minutes,
1002500	1005140	please talk like a teacher, and maybe?
1005140	1007180	But also, definitely in the meantime,
1007180	1008140	and maybe in the future,
1008140	1011100	it makes sense to wrap up these personalized endpoints
1011100	1012500	so that when I'm talking to GPT,
1012500	1013900	I'm not just talking to GPT,
1013900	1015700	I have a whole army of different buddies,
1015700	1018140	of different companions that I can talk to.
1018140	1019060	They're kind of human
1019060	1020700	and kind of talk to me interactively,
1020700	1022540	but because I preloaded them with,
1022540	1025100	hey, by the way, you particular,
1025100	1026940	I want you to be a kind, helpful Chinese teacher
1026940	1028460	that responds to every situation
1028460	1030260	by explaining the Chongyu that fits it.
1030300	1032780	Speak in English and explain the Chongyu in its meaning.
1032780	1035740	Then provide a note of encouragement about learning language.
1035740	1038020	And so just adding something like that,
1038020	1039900	even if you're a non-programmer,
1039900	1041500	you can just type deploy,
1044220	1046500	and it'll pop it up to the web,
1046500	1048140	it'll take it over to a telegram bot
1048140	1049540	that then you can even interact with,
1049540	1052100	hey, I'm feeling too busy,
1053340	1055940	and interact with it over telegram, over the web,
1055940	1058580	and this is the kind of thing that's now within reach
1058580	1061940	for everybody from a CS 101 grad,
1061940	1064380	sorry, I'm using the general purpose framing,
1064380	1066940	all the way through to professionals in the industry,
1066940	1069580	that you can do just with a little bit of manipulation
1069580	1071940	on top of sort of this raw unit
1071940	1074620	of conversation and intelligence.
1077100	1080180	So companionship is one of the first
1080180	1082740	common types of apps that we're seeing.
1084820	1087780	So a second kind of app that we're seeing,
1087780	1092780	and for those of you who are on Twitter followers,
1092860	1095900	this blew up, I think the last few months,
1095900	1096980	is question-answering,
1096980	1098580	and I wanna unpack a couple of different ways
1098580	1100620	this can work, because I know many of you
1100620	1102820	have probably already tried to build
1102820	1103780	some of these kinds of apps,
1103780	1105500	there's a couple of different ways that it works.
1105500	1109740	The general framework is a user queries GPT,
1109740	1111300	and maybe it has general purpose knowledge,
1111300	1113140	maybe it doesn't have general purpose knowledge,
1113140	1115980	but what you want it to say back to you
1115980	1118660	is something specific about an article you wrote,
1118660	1121500	or something specific about your course syllabus,
1121500	1124660	or something specific about a particular set of documents
1124660	1126940	from the United Nations on a particular topic.
1126940	1128260	And so what you're really seeking is
1128260	1130460	what we all hoped the customer service bot would be,
1130460	1132580	like we've all interacted with these customer service bots,
1132580	1134180	and we're kind of smashing our heads
1134180	1135820	on the keyboard as we do it,
1135820	1138460	but pretty soon we're gonna start to see
1138460	1141500	very high fidelity bots that interact with us comfortably,
1141500	1143580	and this is approximately how to do it as an engineer.
1143580	1145900	So here's your game plan as an engineer,
1145900	1150660	step one, take the documents that you want it to respond to.
1151740	1153660	Step two, cut them up.
1153660	1155980	Now, if you're an engineer, this is gonna madden you.
1155980	1158540	You don't cut them up in a way that you would hope.
1158540	1160540	For example, you could cut them up
1160540	1162740	into clean sentences or clean paragraphs,
1162740	1164660	or semantically coherent sections,
1164660	1166340	and that would be really nice.
1166340	1168420	Honestly, the way that most folks do it,
1168420	1172060	and this is a simplification that tends to be just fine,
1172060	1174460	is you window, you have a sliding window
1174460	1175980	that goes over the document,
1175980	1178860	and you just pull out fragments of text.
1178860	1180660	Having pulled out those fragments of text,
1180660	1183020	you turn them into something called an embedding vector.
1183020	1186100	So an embedding vector is a list of numbers
1186100	1189260	that approximate some point of meaning.
1189260	1190700	So you've already all dealt
1190700	1192620	with embedding vectors yourself in regular life,
1192620	1194420	and the reason you have, and I know you have,
1194420	1197020	is because everybody's ordered food from Yelp before.
1197020	1198540	So when you order food from Yelp,
1198540	1201340	you look at what genre of restaurant is it?
1201340	1202700	Is it a pizza restaurant?
1202700	1203820	Is it an Italian restaurant?
1203820	1205500	Is it a Korean barbecue place?
1205500	1206980	You look at how many stars does it have?
1206980	1208860	One, two, three, four, five?
1208860	1209980	You look at where is it?
1209980	1212820	So all of these you can think of as points in space,
1212820	1214060	dimensions in space.
1214060	1217100	Korean barbecue restaurant, four stars near my house.
1217100	1220820	That's a three number vector.
1220820	1221820	That's all this is.
1221820	1223660	So this is a thousand number vector,
1223660	1224780	or a 10,000 number vector.
1224780	1227100	Different models produce different size vectors.
1227100	1230260	All it is is chunking pieces of text,
1230260	1232480	turning it into a vector that approximates meaning,
1232480	1234240	and then you put it in something called a vector database.
1234240	1236520	And a vector database is just a database
1236520	1238520	that stores numbers.
1238520	1242440	But having that database, now when I ask a question,
1242440	1244680	I can search the database, and I can say, hey, the question
1244680	1247280	was, what does CS50 teach?
1247280	1250520	What pieces of text in the database
1250520	1256000	have vectors similar to the question, what does CS50 teach?
1256000	1258320	And there's all sorts of tricks and empires
1258320	1261600	being made on refinements of this general approach.
1261640	1266400	But at the end, you, the developer, model it simply as thus.
1266400	1268840	And then when you have your query, you embed it,
1268840	1271280	you find the document fragments, and then you put them
1271280	1271880	into a prompt.
1271880	1275800	And now we're just back to the personality, the companionship
1275800	1276400	bot.
1276400	1277800	Now it's just a prompt.
1277800	1280920	And the prompt is, you're an expert in answering questions.
1280920	1284040	Please answer user provided question.
1284040	1287120	Using source documents results from the database.
1287120	1288760	That's it.
1288760	1290600	So after all of these decades of engineering
1290600	1291680	and these customer service bots, it
1291680	1293360	turns out with a couple of lines of code.
1293360	1294120	You can build this.
1294120	1297360	So let me show you, I made one just before the class
1297360	1299080	with the CS50 syllabus.
1299080	1303760	So we can pull that up.
1303760	1307040	And I can say, I added the PDF right here.
1307040	1309200	So I just, I searched, I don't know if, I apologize.
1309200	1311240	I don't know if it's an accurate or recent syllabus.
1311240	1313920	I just searched the web for CS50 syllabus PDF.
1313920	1316840	I put the URL in here, it loaded it into here.
1316840	1319920	This is just a 100 line piece of code deployed
1319960	1322200	that will now let me talk to it.
1322200	1327640	And I can say, what will CS50 teach me?
1327640	1329240	So under the hood now, what's happening
1329240	1330880	is exactly what that slide just showed you.
1330880	1333360	It takes that question, what will CS50 teach me?
1333360	1335200	It turns it into a vector.
1335200	1338880	That vector approximates without exactly representing
1338880	1341160	the meaning of that question.
1341160	1343640	It looks into a vector database that
1343640	1347760	steamship hosts of fragments from that PDF.
1347760	1350120	And then it pulls out a document and then passes it
1350120	1352920	to a prompt that says, hey, you're an expert
1352920	1354480	at answering questions.
1354480	1357080	Someone has asked you, what does CS50 teach?
1357080	1359920	Please answer it using only the source documents
1359920	1361800	and source materials I've provided.
1361800	1363640	Now those source materials materials
1363640	1365560	are dynamically loaded into the prompt.
1365560	1366720	It's just basic prompt engineering.
1366720	1369280	And I want to keep harping back onto that.
1369280	1371720	What's amazing about right now as builders
1371720	1374000	is that so many things just boil down
1374040	1379400	into very creative, tactical rearrangement of prompts
1379400	1381880	and then using those over and over again in an algorithm
1381880	1383040	and putting that into software.
1383040	1385360	So the result, and again, it could be lying.
1385360	1386280	It could be making things up.
1386280	1387520	It could be hallucinating.
1387520	1389840	Is CS50 will teach students how to think algorithmically
1389840	1391680	and solve problems efficiently, focusing on topics
1391680	1393440	such as abstraction, dot, dot, dot, dot, dot.
1393440	1395600	And then it returns the source document
1395600	1396600	from which it was found.
1396600	1399120	So this is another big category of which there
1399120	1402720	are tons of potential applications
1402720	1405120	because you can repeat for each context.
1405120	1407800	You can create arbitrarily many of these once it's software
1407800	1410840	because once it's software, you can just repeat it
1410840	1411680	over and over again.
1411680	1414600	So for your dorm, for your club, for your slack,
1414600	1417560	for your telegram, you can start to begin putting
1417560	1420560	pieces of information in and then responding to it.
1420560	1422040	And it doesn't have to be documents.
1422040	1424940	You can also load it straight into the prompt.
1426200	1427800	I think I have it pulled up here.
1427800	1430200	And if I don't, I'll just skip it.
1430200	1431040	Oh, here we go.
1432040	1434400	One other way you can do question answering,
1435520	1437600	because I think it's healthy to always encourage
1437600	1440520	the simplest possible approach to something.
1440520	1442960	You don't need to engineer this giant system.
1442960	1444200	It's great to have a database.
1444200	1445240	It's great to use embeddings.
1445240	1446480	It's great to use this big approach.
1446480	1447680	It's fancy at scales.
1447680	1449480	You can do a lot of things.
1449480	1451960	But you can also get away with a lot
1451960	1453880	by just pushing it all into a prompt.
1453880	1456280	And as an engineer, I'm, you know,
1456280	1457720	that's one of our team who's here always says,
1457720	1459200	like, engineers should aspire to be lazy.
1459200	1460800	And I couldn't agree more.
1460880	1463880	You, as an engineer, should want to set yourself up
1463880	1467360	so that you can pursue the lazy path to something.
1467360	1470720	So here's how you might do the equivalent
1470720	1472600	of a question answering system with a prompt alone.
1472600	1475200	Let's say you have 30 friends.
1475200	1477080	And each friend is good at a particular thing,
1477080	1479000	or you can, you know, this is isomorphic
1479000	1480560	to many other problems.
1480560	1483060	You can simply just say, hey, I know certain things.
1483060	1484720	Here's the things I know.
1484720	1489160	A user's gonna ask me something, how should we respond?
1489160	1490840	And then you load that into an agent.
1490840	1493480	That agent has access to GPT.
1493480	1494840	You can ship deploy it.
1494840	1497680	And now you've got a bot that you can connect to Telegram.
1497680	1499360	You can connect to Slack.
1499360	1502520	And that bot, now it won't always give you the right answer.
1502520	1503480	Because at a certain level,
1503480	1506660	we can't control the variance of the model underneath.
1506660	1510240	But it will tend to answer with respect to this list.
1510240	1513120	And the degree to which it tends to is to a certain extent,
1513120	1515080	something that both industry is working on
1515080	1517640	to just give everybody as a capacity.
1517640	1519720	But also you doing prompt engineering
1519720	1523340	to tighten up the error bars on it.
1526900	1529280	So I'll show you just a few more examples.
1529280	1531520	And then in about eight minutes,
1531520	1532620	I'll turn it over to questions,
1532620	1534280	because I'm sure you've got a lot about how to build things.
1534280	1537020	So just to give you a sense of where we are.
1541000	1543200	This is one, I don't have a demo for you.
1543200	1546500	But if you were to come to me and you were to say, Ted,
1546500	1549540	I want a weekend hustle, man, what should I build?
1549540	1551100	Holy moly.
1551100	1553300	There are a set of applications
1553300	1555060	that I would describe as utility functions.
1555060	1556260	I don't like that name,
1556260	1557460	because it doesn't sound exciting,
1557460	1559180	and this is really exciting.
1559180	1562380	And it's low hanging fruits that automate tasks
1562380	1564220	that require basic language understanding.
1564220	1568140	So examples for this are generate a unit test.
1568140	1570860	I don't know how many of you have ever been writing tests
1570860	1572260	and you're just like, oh, come on,
1572260	1573980	I can get through this, I can get through this.
1573980	1575180	If you're a person who likes writing tests,
1575180	1576860	you're a lucky individual.
1576860	1578620	Looking up the documentation for a function,
1578620	1580580	rewriting a function, making something conform
1580580	1583620	to your company guidelines, doing a brand check.
1583620	1584860	All of these things are things
1584860	1589460	that are kind of relatively context-free operations
1589460	1593140	or scoped context operations on a piece of information
1593140	1595140	that requires linguistic understanding.
1596300	1599580	And really, you can think of them as something
1599580	1602420	that is now available to you as a software builder,
1602420	1604180	as a weekend project builder,
1604180	1606220	as a startup builder.
1606220	1608740	And you just have to build the interface around it
1608740	1611460	and present it to other people in a context
1611460	1614180	in which it's meaningful for them to consume.
1614180	1617220	And so the space of this is extraordinary.
1617220	1619380	I mean, it's the space of all human endeavor,
1619380	1620900	now with this new tool, I think,
1620900	1622180	is the way to think about it.
1622180	1624780	People often joke about how when you're building a company,
1624780	1625820	when you're building a project,
1625820	1627420	you don't want to start with a hammer,
1627420	1629500	because you want to start with a problem instead.
1629500	1631980	And it's generally true, but my God,
1631980	1633820	we've just got a really cool new hammer.
1633820	1635820	And to a certain extent, I would encourage you
1635820	1637340	to at least casually, on the weekends,
1637340	1638580	run around and hit stuff with it
1638580	1640580	and see what can happen from a builder's,
1640580	1643980	from a tinkerers, from an experimentalist's point of view.
1647940	1651020	And then the final one is creativity.
1651020	1652940	This is another huge mega app.
1652940	1655660	Now, I'm primarily living the text world,
1655660	1657940	and so I'm gonna talk about text-based things.
1657940	1661420	I think so far, this has mostly been growing
1661420	1664220	in the imagery world, because we're such visual creatures,
1664220	1665620	and the images you can generate
1665620	1668540	are just staggering with AI.
1668540	1670260	Certainly brings up a lot of questions, too,
1670260	1672160	around IP and artistic style.
1673140	1675660	But the template for this, if you're a builder,
1675660	1677580	that we're seeing in the wild,
1677580	1678820	is approximately the following.
1678820	1681540	And the thing I want to point out is domain knowledge here.
1681540	1682980	This is really the purpose of this slide,
1682980	1686760	is to touch on the importance of the domain knowledge.
1686760	1690760	So, many people approximately
1690760	1692960	find the creative process as follows.
1692960	1694220	Come up with a big idea.
1695560	1698400	Over-generate possibilities.
1698400	1701240	Edit down what you over-generated.
1701240	1702720	Repeat, right?
1702720	1704240	Like anybody who's been a writer
1704240	1706480	knows when you write, you write way too much,
1706480	1708240	and then you have to delete lots of it.
1708240	1709960	And then you revise, and you write way too much,
1709960	1711520	and you have to delete lots of it.
1711520	1714640	This particular task is fantastic for AI.
1714640	1716680	One of the reasons it's fantastic for AI
1716680	1718400	is because it allows the AI to be wrong.
1718400	1719720	You know, you've pre-agreed,
1719720	1720640	you're gonna delete lots of it.
1720640	1723560	And so, if you pre-agreed, hey, I'm just gonna build,
1723560	1726240	generate five possibilities of the story I might tell.
1726240	1728520	Five possibilities of the advertising headline.
1728520	1732800	Five possibilities of what I might write my thesis on.
1732800	1734440	You pre-agreed, it's okay if it's a little wrong,
1734440	1736960	because you are going to be the editor that steps in.
1736960	1738800	And here's the thing that you really
1738800	1741000	should bring to the table, is don't think about this
1741000	1742000	as a technical activity.
1742000	1744320	Think about this as your opportunity
1744320	1746840	not to put GPT in charge.
1746840	1750080	Instead, for you to grasp the steering wheel tighter,
1750080	1752520	I think, at least, in Python,
1752520	1754520	or the language you're using to program,
1754520	1756600	because you have the domain knowledge
1756600	1759080	to wield GPT in the generation of those.
1759080	1761240	So let me show you an example of what I mean by that.
1761240	1766240	So, this is a cool app that someone created
1766640	1767800	for the Writing Atlas project.
1767800	1770800	So Writing Atlas is a set of short stories,
1771800	1775200	and you can think of it as good reads for short stories.
1775200	1778000	So you can go in here, you can browse different stories,
1778000	1779480	and this was something somebody created
1779480	1782760	where you can type in a story description that you like,
1782760	1784360	and this is gonna take about a minute to generate,
1784360	1786280	so I'm gonna talk while it's generating.
1786280	1791280	And while it's working, what it's doing,
1791440	1792920	and I'll show you the code in a second,
1792920	1795400	is it's searching through the collection of stories
1795400	1796800	for similar stories, and here's where
1796800	1798520	the domain knowledge part comes in.
1798640	1802600	Then it uses GPT to look at what it was that you wanted,
1802600	1804840	and use knowledge of how an editor,
1804840	1807160	how a bookseller thinks, to generate
1807160	1810200	a set of suggestions specifically through the lens
1810200	1812360	of that perspective with the goal of writing
1812360	1813960	that beautiful handwritten note
1813960	1816200	that we sometimes see in a local bookstore
1816200	1819480	tacked on underneath a book.
1819480	1821840	And so it doesn't just say, hey, you might like this,
1821840	1824980	here's a general purpose reason why you might like this,
1824980	1827800	but specifically, here's why you might like this
1827840	1829640	with respect to what you gave it.
1829640	1832680	It's either stalling out, or it's taking a long time.
1832680	1833520	Oh, there we go.
1834600	1839600	So here's its suggestions, and in particular, these things,
1839800	1841560	these are things that only a human could know,
1841560	1845240	at least for now, two humans specifically,
1845240	1847360	the human who said they wanted to read a story,
1847360	1848720	that's the text that came in,
1848720	1851680	and then the human who added domain knowledge
1851680	1854160	to script a sequence of interactions
1854160	1856760	with the language model so that you could provide
1856800	1859440	very targeted reasoning over something
1859440	1861520	that was informed by that domain knowledge.
1861520	1865500	So for these utility apps, bring your domain knowledge.
1869640	1872160	Let me actually show you how this looks and code,
1872160	1874720	because I think it's useful to see how simple
1874720	1875940	and accessible this is.
1875940	1878400	This is really a set of prompts.
1878400	1882240	So why might they, like a particular location,
1882240	1883640	well, here's the prompt that did that,
1883640	1885880	this is an open source project,
1885880	1887520	and it has a bunch of examples,
1887520	1891000	and then it says, well, here's the one that we're interested in.
1891000	1892880	Here's the audience, here's a couple of examples
1892880	1895080	of why might people like a particular thing
1895080	1897400	in terms of audience, it's just another prompt.
1902320	1904520	Same for topic, same for explanation,
1904520	1907320	and if you go down here and look at how it was done,
1909340	1911560	suggesting the story is, what is this,
1911560	1914840	line 174 to line 203, it really is,
1914840	1916320	and again, over and over again,
1916320	1919180	I wanna impress upon you, this really is within reach.
1919180	1923720	It's really just what, 20 odd lines of step one,
1923720	1926600	search in the database for similar stories,
1926600	1929880	step two, given that I have similar stories,
1929880	1932480	pull out the data, step three,
1932480	1935160	with my domain knowledge in Python,
1935160	1937600	now run these prompts, step four,
1937600	1939020	prepare that into an output.
1939020	1941440	So the thing we're scripting itself
1941440	1944680	is some approximation of human cognition.
1944680	1946560	If you're willing to go there metaphorically,
1946560	1948720	we're not sure, I'm not gonna weigh in
1948720	1953720	on where we are on this open AI, a life form argument.
1956160	1959920	All right, one really far out there thing,
1959920	1962360	and then I'll tie it up for questions,
1962360	1963480	because I know there's probably a lot,
1963480	1966240	and I also wanna make sure you get great pizza
1966240	1971240	in your bellies, and that is a baby AGI auto GPT
1972180	1973920	is what you might have heard them called on Twitter.
1973920	1976120	I think of them as multi-step planning bots.
1976120	1978320	So everything I showed you so far
1978320	1982520	was approximately one shot interactions with GPT.
1982520	1985400	So this is, the user says they want something,
1985400	1989200	and then either Python mediates interactions with GPT,
1989200	1992640	or GPT itself does some things with the inflection
1992640	1994320	of a personality that you've added
1994320	1996400	from some prompt engineering.
1996400	1999480	Really useful, pretty easy to control.
1999480	2000840	If you wanna go to production,
2000840	2002200	if you wanna build a weekend project,
2002200	2003040	if you wanna build a company,
2003040	2005160	that's a great way to do it right now.
2006360	2009960	This is wild, and if you haven't seen this stuff on Twitter,
2009960	2012260	I would definitely recommend going to search for it.
2012260	2015500	This is what happens, the simple way to put it is,
2015500	2017920	if you put GPT in a for loop,
2017920	2019680	if you let GPT talk to itself,
2019680	2022060	and then tell itself what to do.
2022060	2026560	So it's an emergent behavior,
2026560	2028040	and like all emergent behaviors,
2028040	2029600	it starts with a few simple steps,
2029600	2033520	the Conways game of life, many elements of reality,
2033520	2036480	turn out to be math equations that fit on a t-shirt,
2036480	2038040	but then when you play them forward in time,
2038040	2040960	they generate DNA, they generate human life.
2040960	2044520	So this is approximately,
2044520	2047340	step one, take a human objective,
2047340	2050560	step two, your first task is to write yourself
2050560	2054300	a list of steps, and here's the critical part, repeat.
2054300	2056000	Now do the list of steps.
2056000	2058580	Now you have to embody your agent
2058580	2060020	with the ability to do things.
2060020	2061860	So it's really only limited to do what you give it
2061860	2064700	the tools to do, and what it has the skills to do.
2064700	2067340	So obviously this is still very much
2067340	2069300	a set of experiments that are running right now,
2069300	2071340	and but it's something that we'll see unfold
2071340	2073180	over the coming years, and this is the scenario
2073180	2075180	in which Python stops becoming so important
2075180	2076540	because we've given it the ability
2076540	2079420	to actually self-direct what it's doing,
2079420	2081380	and then it finally gives you a result.
2081380	2083380	And I wanna give you an example still of just, again,
2083380	2085880	impressing upon you how much of this is prompt engineering,
2085880	2088140	which is wild, how little code this is.
2088140	2092240	Let me show you what BabyAGI looks like.
2093760	2097940	So here is a BabyAGI that you can connect to Telegram,
2101260	2103960	and this is an agent that has two tools.
2103960	2105500	So I haven't explained to you what an agent is,
2105500	2107220	I haven't explained to you what tools are,
2107220	2108900	I'll give you a quick one sentence description.
2108900	2112180	An agent is just a word to mean GPT
2112180	2114780	plus some bigger body in which it's living.
2114780	2117100	Maybe that body has a personality, maybe it has tools,
2117140	2118980	maybe it has Python mediating its experience
2118980	2120100	with other things.
2120100	2122760	Tools are simply ways in which the agent
2122760	2124020	can choose to do things.
2124020	2126620	Like imagine if GPT could say order a pizza,
2126620	2128860	and instead of you seeing the text order a pizza,
2128860	2132100	that caused a pizza to be ordered, that's a tool.
2132100	2133340	So these are two tools it has,
2133340	2135280	one tool is generated to-do list,
2135280	2138420	one tool is do a search on the web,
2142360	2146060	and then down here it has a prompt saying,
2146100	2148540	hey, your goal is to build a task list
2148540	2149900	and then do that task list,
2149900	2152540	and then this is just placed into a harness
2152540	2153740	that does it over and over again.
2153740	2156220	So after the next task, kind of unqueue the results
2156220	2158820	of that task and keep it going.
2158820	2162000	And so in doing that, you get this kickstarted loop
2162000	2164140	where essentially you kickstart it,
2164140	2167300	and then the agent is talking to itself.
2167300	2169020	So this, unless I'm wrong,
2169020	2171140	I don't think this has yet reached production
2171140	2172700	in terms of what we're seeing in the field
2172700	2174520	of how people are deploying software,
2174520	2177200	but if you wanna dive into sort of the wildest part
2177200	2178840	of experimentation, this is definitely one
2178840	2181900	of the places you can start, and it's really within reach.
2181900	2183880	All you have to do is download one
2183880	2185720	of the starter projects for it,
2185720	2187440	and you can kind of see right in the prompting,
2187440	2191120	here's how you kickstart that process of iteration.
2197960	2200200	All right, so I know that was super high level.
2200200	2202000	I hope it was useful.
2202000	2204040	It's, I think from the field, from the bottoms up,
2204040	2205360	what we're seeing and what people are building,
2205360	2208800	kind of the high level categories of apps
2208800	2210120	that people are making.
2210120	2212220	All of these apps are apps that are within reach
2212220	2214940	to everybody, which is really, really exciting.
2214940	2216880	And there's, I suggest Twitter is a great place
2216880	2219840	to hang out and build things.
2219840	2222840	There's a lot of AI builders on Twitter publishing.
2222840	2224320	And I think we've got a couple minutes
2224320	2226560	before pizza is arriving, maybe 10 minutes.
2226560	2227920	Keep on going.
2227920	2230840	So if there's any questions, why don't we kick it to that?
2230840	2233680	Because I'm sure there's some questions that you all have,
2233720	2235040	I guess I ended it a little early.
2235040	2235880	Yes?
2235880	2238920	Yeah, so I have a question around hallucination.
2238920	2241160	And so, you know, whenever building these sorts
2241160	2243960	of applications in apps, for example, let's say,
2245440	2247440	I'm giving it like a physics problem from a PSET
2247440	2248440	and we want to do that.
2248440	2249280	Yeah.
2249280	2253040	And, you know, it's 40% of the time just raw.
2253040	2253880	Yeah.
2253880	2255600	Do you have any like actionable recommendations
2255600	2257440	that these developers should be doing
2257440	2258760	to make it hallucinate less?
2258760	2261880	Or maybe even things that like open AI on the back end
2261880	2263640	should be doing to reduce hallucination.
2263640	2266480	So it would be something where you use RLHF.
2267840	2269200	Yeah, I didn't get the answer.
2269200	2271800	So the question was how, approximately,
2271800	2273720	how do you manage the hallucination problem?
2273720	2276080	Like if you give it a physics lecture
2276080	2278720	and you ask it a question, on the one hand,
2278720	2280720	it appears to be answering you correctly.
2280720	2283320	On the other hand, it appears to be wrong
2283320	2285480	to an expert's eye 40% of the time,
2285480	2287320	70% of the time, 10% of the time.
2287320	2288360	It's a huge problem.
2288360	2291160	And then what are some ways as developers practically
2291160	2293200	you can use to mitigate that?
2293200	2294040	I'll give an answer.
2294040	2295400	So you may have some specific things too.
2295400	2297000	So one high level answer is,
2297000	2298440	the same thing that makes these things
2298440	2300200	capable of synthesizing information
2300200	2302160	is part of the reason why it hallucinates for you.
2302160	2303960	So it's hard to have your cake you need it to
2303960	2305280	to a certain extent.
2305280	2306640	So this is part of the game.
2306640	2308160	In fact, humans do it too.
2308160	2309920	Like people talk about, you know,
2309920	2312400	just folks who kind of are too aggressive
2312400	2313680	in their assumptions about knowledge.
2313680	2315680	I can't remember the name for that phenomenon
2315680	2316720	where you'll just say stuff, right?
2316720	2317600	So we do it too.
2318560	2322200	Some things you can do are kind of a range of activities
2322200	2323760	depending on how much money you really need to spend,
2323760	2324920	how much technical expertise you have,
2324920	2328480	that can range from fine tuning a model to practically,
2328480	2329800	so I'm in the applied world.
2329800	2331680	So I'm very much in the world of duct tape
2331680	2333200	and sort of how developers get stuff done.
2333200	2334400	So some of the answers I'll give you
2334400	2336120	are sort of very duct-tapy answers.
2336120	2339040	Giving it examples tends to work for acute things.
2339040	2340640	If it's behaving in wild ways,
2340640	2343040	the more examples you give it, the better.
2343040	2346000	That's not gonna solve the domain of all of physics.
2346000	2347360	So for the domain of all of physics,
2347800	2348920	I'm gonna bail and give it to you
2348920	2350400	because I think you are far more equipped than me
2350400	2351240	to speak on that.
2351240	2354680	Sure, so the model doesn't have a ground truth.
2354680	2356080	It doesn't know anything.
2356080	2357600	Any sense of meaning that it's derived
2357600	2361960	from the training process is purely out of differentiation.
2361960	2363360	One word is not another word.
2363360	2366160	Words are not used in the same context.
2366160	2369000	It understands everything only through examples
2369000	2369840	given through language.
2369840	2372680	It's like someone who learned English or how to speak,
2372680	2374680	but they grew up in a featureless gray room.
2374680	2376400	They've never seen the outside world.
2376400	2377920	They have nothing to rest on that tells them
2377920	2380840	that something is true and something is not true.
2380840	2382480	So from the model's perspective,
2382480	2383880	everything that it says it's true.
2383880	2386560	It's trying its best to give you the best answer possible.
2386560	2389080	And if it lying a little bit
2389080	2390840	or conflating two different topics
2390840	2391920	is the best way to achieve that,
2391920	2393800	then it will decide to do so.
2393800	2394920	It's a part of the architecture.
2394920	2396320	We can't get around it.
2396320	2398560	There are a number of cheap tricks
2398560	2402040	that surprisingly get it to confabulate or hallucinate less.
2402040	2403320	One of them includes recently,
2403320	2405040	there was a paper that's a little funny.
2405040	2408400	If you get it to prepend to its answer,
2408400	2411520	my best guess is that will actually improve
2411520	2414440	or reduce hallucinations by about 80%.
2414440	2415880	So clearly it has some sense
2415880	2417560	that some things are true and other things are not,
2417560	2419240	but we're not quite sure what that is.
2419240	2420680	To add on to what Ted was saying,
2420680	2423240	a few cheap things you can do include
2423240	2425120	letting it Google or Bing,
2425120	2426400	as in Bing Chat, what they're doing,
2426400	2428360	it cites this information,
2428360	2431440	asking it to make sure its own response is good.
2431440	2434720	If you've ever had JetGBT generate a program,
2434720	2435840	there's some kind of problem,
2435840	2438440	and you ask ChatGBT, I think there's a mistake.
2438440	2440920	Often it'll locate the mistake itself.
2440920	2443800	Why didn't produce the right answer at the very beginning?
2443800	2444800	We're still not sure,
2444800	2445800	but we're moving in the direction
2445800	2446840	of reducing hallucinations.
2446840	2448800	Now with respect to physics,
2448800	2451220	you're gonna have to give it an external database
2451220	2453840	to rest on because internally,
2453840	2456920	for really, really domain specific knowledge,
2456920	2461920	it's not going to be as deterministic as one would like.
2462320	2464120	These things work in continuous spaces.
2464120	2466560	These things, they don't know what is wrong,
2466560	2470360	what is true, and as a result, we have to give it tools.
2470360	2472760	So everything that Ted demoed today is really
2474520	2476760	striving at reducing hallucinations, actually, really,
2476760	2478200	and giving it more abilities.
2478200	2480560	I hope that answers your question.
2480560	2482760	One of the ways to, I mean, I'm a simple guy.
2482760	2485400	Like I tend to think that all of the world
2485400	2487920	tends to be just a few things repeated over and over again,
2487920	2489720	and we have human systems for this.
2489720	2491600	You know, in a team, like companies work,
2491600	2493520	or a team playing sport,
2493600	2494720	and we're not right all the time,
2494720	2495960	even when we aspire to be,
2495960	2499000	and so we have systems that we've developed as humans
2499000	2501120	to deal with things that may be wrong.
2501120	2503880	So, you know, human number one proposes an answer,
2503880	2505800	human number two checks their work,
2505800	2508320	human number three provides the final sign off.
2508320	2509480	This is really common.
2509480	2510640	Anybody who's worked in a company
2510640	2511960	has seen this in practice.
2511960	2515440	The interesting thing about the state of software right now,
2515440	2516920	we tend to be in this mode,
2516920	2520080	in which we're just talking to GPT as one entity.
2520080	2522640	But once we start thinking in terms of teams,
2522640	2525600	so to speak, where each team member is its own agent
2525600	2527880	with its own set of objectives and skills,
2527880	2530680	I suspect we're going to start seeing a programming model
2530680	2533720	in which the way to solve this might not necessarily be,
2533720	2535800	make a single brain smarter,
2535800	2539040	but instead be draw upon the collective intelligence
2539040	2542080	of multiple software agents, each playing a role.
2542080	2544600	And I think that that would certainly follow
2544600	2546560	the human pattern of how we deal with this.
2546560	2549160	To give an analogy, space shuttles,
2549160	2551720	things that go into space, spacecraft,
2551720	2553200	they have to be good.
2553200	2554480	If they're not good, people die.
2554480	2558000	They have no margin for error at all.
2558000	2560680	And as a result, we over engineer in those systems,
2560680	2562680	most spacecraft have three computers
2562680	2564360	and they all have to agree in unison
2564360	2566760	on a particular step to go forward.
2566760	2569320	If one does not agree, then they recalculate,
2569320	2570720	they recalculate, they recalculate
2570720	2572120	until they arrive at something.
2572120	2574240	The good thing is that hallucinations
2574240	2575720	are generally not a systemic problem
2575720	2577360	in terms of its knowledge.
2577360	2580200	It's often a one off, the model, something tripped it up
2580200	2582840	and it just produced a hallucination in that one instance.
2582840	2584600	So if there's three models working in unison,
2584600	2587880	just as Ted is saying, that will, generally speaking,
2587880	2589240	improve your success.
2590800	2591640	Yes, sir.
2591640	2593920	A number of the examples you show have assertions
2593920	2598120	like you are an engineer, you are an AI, you are a teacher.
2598120	2600840	What's the mechanism by which that influences
2600840	2603240	this computation of probabilities?
2603240	2605080	Sure, I'm gonna give you what might be
2605080	2608200	an unsatisfying answer, which is it tends to work.
2608200	2610160	But I think we know why it tends to work,
2610160	2612720	and again, it's because these language models approximate
2612720	2614160	how we talk to each other.
2614160	2616560	So if I were to say to you, hey, help me out,
2616560	2619000	I need you to mock interview me.
2619000	2620440	That's a direct statement I can make
2620440	2622680	that kicks you into a certain mode of interaction.
2622680	2624880	Or if I say to you, help me out,
2624880	2626840	I'm trying to apologize to my wife,
2626840	2629280	she's really mad at me, can you role play with me?
2629280	2631160	That kicks you into another mode of interaction.
2631160	2634360	And so it's really just a shorthand that people have found
2634360	2636680	to kick the agent in, to kick the LLM in,
2636680	2638480	to a certain mode of interaction
2638480	2639920	that it tends to work in the way
2639920	2643560	that I, as a software developer, am hoping it would work.
2643560	2646400	And to really quickly add on to that,
2646400	2649080	being in the digital humanities that I am,
2649080	2650520	I like to think of it as a narrative.
2650520	2652360	A narrative will have a few different characters
2652360	2655280	talking to each other, their roles are clearly defined,
2655280	2656760	two people are not the same.
2657640	2660360	This interaction with GPT, it assumes a personality,
2660360	2662000	it can simulate personalities.
2662000	2663880	It itself is not conscious in any way,
2663880	2667720	but it can certainly predict what a conscious being
2667720	2669600	would react like in a particular situation.
2669600	2674200	So when we're going URX, it is drawing up that personality
2674200	2676040	and talking as though it is that person.
2676040	2678320	Because it is like completing a transcript
2678320	2681600	or completing a story in which that character is present
2681600	2684520	and interacting and is active.
2684520	2686280	So, yeah.
2686280	2689120	I think we got about five minutes until the pizza outside.
2689120	2689960	Eight minutes.
2693120	2693960	Yes, sir.
2694960	2699720	So I'm not a CF person, but it's been a fun thing with this.
2699720	2703080	And I understand the sort of word-by-word generation
2703080	2706440	and the sort of vibe, the feeling of it in the narrative.
2707400	2711080	Some of my friends and I have tried giving it logic problems,
2711080	2713200	like things from the LSAT, for example,
2713200	2714840	and it doesn't work.
2714840	2716920	Like, and I'm just wondering why that would be.
2716920	2719960	So it will generate answers that sound
2719960	2721600	very plausible rhetorically.
2721600	2724520	Like, given this condition X, given this Y,
2724520	2727600	but it'll often, like, even contradict itself
2727600	2730840	in its answers, but it's almost never correct.
2730840	2733800	So I was wondering what, why that would be?
2733800	2737040	Like, it just can't reason, it can't, like, think.
2737040	2741080	And, like, can you, would we get to a place where it can,
2741080	2741920	so to speak?
2741920	2743120	I mean, not, you know what I mean?
2743120	2744720	I don't mean to think, like, it's conscious.
2744720	2746640	I mean, like, have thoughts, not-
2746640	2748800	You want to talk about react?
2748800	2753160	So GPT-4, when GPT-4 released back in March,
2753160	2755680	I think it was, it was passing LSAT.
2755680	2756520	It was.
2756520	2757360	It was, yeah.
2757360	2758200	Yes.
2758200	2760320	Yes, it just passed, as I understand it.
2760320	2762560	Well, maybe it's because we're not GPT.
2762560	2763840	That's one of the weird things.
2763840	2764680	Is that-
2764680	2765520	At GPT.
2765520	2766840	Yeah.
2766840	2768640	If you pay for chat GPT, they give you access
2768640	2769840	to the better model.
2769840	2773640	And one of the interesting things with it is prompting.
2773640	2774760	It's so finicky.
2774760	2777880	If you, it's very sensitive to the way that you prompt.
2777880	2780480	There were earlier on when GPT-3 came out,
2780480	2781560	some people were going,
2781560	2783040	look, I can pass literacy tests,
2783040	2785240	or no, it can't pass literacy tests.
2785240	2788160	And then people who are pro or anti-GPT would be like,
2788160	2789480	I modified the prompt a little bit,
2789480	2791400	suddenly it can't, or suddenly it can't.
2791400	2793600	These things are not conscious.
2793600	2796000	Their ability to reason is like an alien's.
2796000	2796840	They're not us.
2796840	2797800	They don't think like people.
2797800	2798960	They're not human.
2798960	2802360	But they certainly are capable of passing some things
2802360	2804680	empirically, which demonstrates some sort of
2804680	2806680	rationale or logic within the model.
2806680	2808560	But we're still slowly figuring out,
2808560	2809880	like a prompt whisperer,
2809880	2811560	what exactly the right approach is.
2814120	2814960	Yeah?
2816160	2821200	Obviously, having GPT-3 running and prompting it
2821200	2824640	continuously is very expensive in terms of the user.
2824640	2828760	Have you seen instances where it directly creates
2828760	2831880	some sort of business value in for a whisperer,
2831880	2835480	for a company with a real added value of having
2835480	2839480	for these real AI apps in terms of
2839480	2842600	like a review of the drives and the actual digital stuff?
2842600	2844960	Yeah, I mean, we host companies on top of us,
2844960	2847480	who that's their primary product.
2847480	2851480	The value that it adds is like any company.
2851480	2853600	I mean, it's, you know, what is the Y Combinator motto,
2853600	2854640	make something people want?
2854640	2857840	I mean, I wouldn't think of this as GPT inherently
2857840	2860040	provides value for you as a builder.
2860040	2861120	Like that's their product.
2861120	2862160	That's OpenAI's product.
2862160	2865080	You pay chat GPT for prioritized access.
2865080	2867880	Where your product might be is how you take that
2867880	2870760	and combine it with your data, somebody else's data,
2870760	2873480	some domain knowledge, some interface
2873480	2876320	that then helps apply it to something.
2876320	2878000	It is, two things are both true.
2878000	2880960	There are a lot of experiments going on right now,
2880960	2883640	both for fun and people trying to figure out
2883640	2885240	where the economic value is.
2885240	2887160	But folks are also spinning up companies
2887160	2890000	that are 100% supported by applying this to data.
2890000	2893760	Okay, first, a company that wouldn't have,
2893760	2897520	sort of, wouldn't be AI focused as an input, right?
2897520	2899680	As it's just using or developing, like,
2899680	2903680	announcements that use GPT for productivity.
2905480	2910000	I think that it is likely that today we call this GPT
2910000	2911360	and today we call these LLMs
2911360	2913640	and tomorrow it will just slide into the ether.
2913640	2916080	I mean, imagine what the progression is going to be.
2916080	2917680	Today there's one of these
2917680	2919360	that people are primarily playing with.
2919360	2920600	There's many of them that exist,
2920600	2922600	but one, people are primarily bidding on top.
2922600	2925800	Tomorrow we can expect that there will be many of them
2925800	2927360	and the day after that we can expect
2927360	2928440	they're going to be on our phones
2928440	2930720	and they're not even going to be connected to the internet.
2930720	2933600	And for that reason, I think that,
2933600	2936760	like today we don't call our software microprocessor tools
2936760	2940080	or microprocessor apps, like the processor just exists.
2940080	2943640	I think that one useful model, five years out,
2943640	2947080	10 years out, is to, even if it's only metaphorically true
2947080	2950320	and not literally true, I think it's useful
2950320	2952120	to think of this as a second processor.
2952120	2955160	We had this before with what floating point co-processors
2955160	2958840	and graphics co-processors already as recently as the 90s
2958840	2961600	where it's useful to think of the trajectory of this
2961600	2964600	as just another thing that computers to do can do
2964600	2967040	and it will be incorporated into absolutely everything.
2967040	2969800	Hence the term foundation model, which also crops up.
2971440	2974000	So, pizza's ready?
2974000	2974980	One more quick.
2974980	2977720	Maybe one more and then we'll break for some food.
2980520	2982080	In the glasses right there, sorry.
2983120	2988560	Sorry, I was just being told we need to get two more.
2988560	2989400	So, yeah.
2998440	3000080	It's hard to get it to do that reliably.
3000080	3002360	It's incredibly useful to get it to do reliably.
3002360	3005720	So some tricks you can use are, you can give it examples.
3005720	3007380	You can just ask it directly.
3008480	3010760	Those are two common tricks.
3010760	3013200	And look at the prompts that others have used to work.
3013200	3015800	I mean, there's a lot of art to finding the right prompt
3015800	3016640	right now.
3016640	3019240	A lot of it is magic incantation.
3019240	3022440	Another thing you can do is post-process it
3022440	3023840	so that you can do some checking
3023840	3025400	and you can have a happy path
3025400	3027280	in which it's a one shot and you get your answer
3027280	3029480	and then a sad path in which maybe you fall back
3029480	3030320	on other prompts.
3030320	3032400	So then you're going for the diversity of approach
3032400	3034680	where it's fast by default.
3034680	3036640	It's slow but ultimately converging
3036640	3038960	upon higher likelihood of success if it fails.
3039160	3040880	And then something that I'm sure we'll see
3040880	3044040	and people do later on is fine-tune instruction
3044040	3046960	tuning style models, which are more likely to respond
3046960	3049720	with the computer parsable output.
3049720	3051360	I guess one last question?
3051360	3052200	Sure.
3052200	3055000	So one of the, you talked a couple of things.
3055000	3057640	One is, is you talked about domain expertise here
3057640	3060280	and you were coding a bunch of domain expertise
3060280	3063040	in terms of the prompts that you're going for.
3063040	3065000	What is that, where do those prompts end up?
3065000	3067480	Do those prompts end up back in the gene chat
3068080	3071640	and is there a privacy issue associated with that?
3071640	3072480	That's a great question.
3072480	3073680	So the question was, and I apologize,
3073680	3074840	I just realized we haven't been repeating
3074840	3076720	all the questions for the YouTube listeners.
3076720	3078120	So I'm sorry for the folks on YouTube
3078120	3080240	if you weren't able to hear some of the questions.
3080240	3082120	The question was, what are the privacy implications
3082120	3082960	of some of these prompts?
3082960	3086080	If one of the messages is so much depends upon your prompt
3086080	3087560	and the fine-tuning of this prompt,
3087560	3089800	what does that mean with respect to my IP?
3089800	3092360	Maybe the prompt is my business.
3092360	3094200	I can't offer you the exact answer
3094200	3096280	but I can paint for you what approximately
3096280	3097420	the landscape looks like.
3097420	3100580	So in all of software and so too with AI,
3100580	3102540	what we see is they're the SaaS companies
3102540	3104940	where you're using somebody else's API
3104940	3106820	and you're trusting that their terms of service
3106820	3108420	will be upheld.
3108420	3111580	There's the set of companies in which they provide a model
3111580	3113940	for hosting on one of the big cloud providers
3113940	3116020	and this is a version of the same thing
3116020	3117700	but I think with slightly different mechanics.
3117700	3119500	This tends to be thought of as the enterprise version
3119500	3121260	of software and by and large,
3121260	3123300	the industry has moved over the past 20 years
3123300	3125060	from running my own servers to trusting
3125060	3127820	that Microsoft or Amazon or Google can run servers for me
3127820	3129540	and they say it's my private server
3129540	3130820	even though I know they're running it
3130820	3131980	and I'm okay with that.
3131980	3134660	And you've already started to see that Amazon
3134660	3136700	with Huggingface, Microsoft with OpenAI,
3136700	3138780	Google too with their own version of Bard
3138780	3141660	are going to do these where you'll have the SaaS version
3141660	3143820	and then you'll also have the private VPC version
3143820	3145100	and then there's a third version
3145100	3147180	that I think we haven't yet seen practically emerge
3147180	3149140	but this would be the maximalist.
3149140	3152540	I wanna make sure my IP is maximally safe version of events
3152540	3154620	in which you are running your own machines.
3154620	3156140	You are running your own models
3156140	3157780	and then the question is,
3157780	3160340	is the open source and or privately available version
3160340	3163300	of the model as good as the publicly hosted one
3163300	3164540	and does that matter to me?
3164540	3166460	And the answers right now, realistically,
3166460	3168180	it probably matters a lot.
3168180	3169620	In the fullness of time,
3169620	3172540	you can think of any one particular task you need to achieve
3172540	3175620	as requiring some fixed point of intelligence to achieve.
3175620	3177740	And so over time, what we'll see is
3177740	3179960	the privately obtainable versions of these models
3179960	3181340	will cross that threshold
3181340	3183540	and with respect to that one task,
3183540	3185260	yeah, sure, use the open source version,
3185260	3186540	run it on your own machine,
3186540	3189580	but we'll also see the SaaS intelligence get smarter.
3189580	3190780	It'll probably stay ahead.
3190780	3192020	And then your question is,
3192020	3193620	well, which one do I care more about?
3193620	3195740	Do I want like the better aggregate intelligence
3195740	3197780	or is my task somewhat fixed point
3197780	3200020	and I can just use the open source available one
3200020	3201660	for which I know it'll perform well enough
3201660	3203180	because it's crossed the threshold.
3203180	3205160	So to answer your question specifically,
3205160	3207580	yes, you might be glad to know
3207580	3210100	Chachi PT recently updated their privacy policy
3210100	3212940	to not use prompts for the training process,
3212940	3215100	but up until now, everything went back into the bin
3215100	3217660	to be trained on again, okay.
3217660	3219300	And that's just a fact.
3219300	3222220	So I think pizza is now pizza time.
3222220	3223380	Okay, okay.
3223380	3224220	Okay.
3224220	3225220	Yeah.
3225220	3228340	But we'll have to talk about Q&A's and everything else.
3228340	3229180	Perfect.
