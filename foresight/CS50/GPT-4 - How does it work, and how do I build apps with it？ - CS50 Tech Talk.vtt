WEBVTT

00:00.000 --> 00:01.560
All right.

00:01.560 --> 00:03.560
Well, this is CS50 Tech Talk.

00:03.560 --> 00:04.920
Thank you all so much for coming.

00:04.920 --> 00:06.960
So about a week ago, we circulated the Google Form,

00:06.960 --> 00:09.660
as you might have seen, at 10.52 AM.

00:09.660 --> 00:12.600
And by, like, 11.52 AM, we had 100 RSVPs,

00:12.600 --> 00:14.680
which I think is sort of testament to just how much interest

00:14.680 --> 00:18.100
there is in this world of AI, and open AI, and GPT, chat

00:18.100 --> 00:19.200
GPT, and the like.

00:19.200 --> 00:21.840
And in fact, if you're sort of generally familiar with what

00:21.840 --> 00:24.320
everyone's talking about, but you haven't tried it yourself,

00:24.320 --> 00:26.680
this is the URL, which you can try out this tool

00:26.680 --> 00:29.120
that you've probably heard about, chat GPT.

00:29.120 --> 00:30.680
You can sign up for a free account there

00:30.680 --> 00:32.800
and start tinkering with what everyone else has been

00:32.800 --> 00:33.640
tinkering with.

00:33.640 --> 00:36.400
And then if you're more of the app-minded type, which you probably

00:36.400 --> 00:39.720
are if you are here with us today, open AI in particular

00:39.720 --> 00:43.240
has its own low-level APIs via which you can integrate AI

00:43.240 --> 00:44.560
into your own software.

00:44.560 --> 00:46.920
But of course, as is the case in computer science,

00:46.920 --> 00:49.040
there's all the more abstractions and services

00:49.040 --> 00:51.200
that have been built on top of these technologies.

00:51.200 --> 00:53.840
And we're so happy today to be joined by our friends

00:53.840 --> 00:56.280
from McGill University and Steamship,

00:56.320 --> 00:58.720
Sill and Ted, from whom you'll hear in just a moment,

00:58.720 --> 01:02.160
to speak to us about how they are making it easier to build,

01:02.160 --> 01:04.680
to deploy, to share applications using some

01:04.680 --> 01:05.960
of these very same technologies.

01:05.960 --> 01:08.240
So our thanks to them for hosting today.

01:08.240 --> 01:10.080
Our friends at Plimpton, Jenny Lee and alumna,

01:10.080 --> 01:12.120
who's here with us today, but without further ado,

01:12.120 --> 01:13.840
allow me to turn things over to Ted and Sill.

01:13.840 --> 01:18.000
And pizza will be served shortly after 1 PM outside.

01:18.000 --> 01:19.760
All right, over to you, Ted.

01:19.760 --> 01:21.400
Thanks a lot.

01:21.400 --> 01:23.280
Hey, everybody, it's great to be here.

01:23.280 --> 01:25.800
I think we've got a really good talk for you today.

01:25.800 --> 01:28.080
Sill's gonna provide some research grounding

01:28.080 --> 01:30.920
into how it all works, what's going inside,

01:30.920 --> 01:34.120
the brain of GPT as well as other language models.

01:34.120 --> 01:36.000
And then I'll show you some examples that we're seeing

01:36.000 --> 01:38.240
on the ground of how people are building apps

01:38.240 --> 01:40.380
and what apps tend to work in the real world.

01:40.380 --> 01:43.480
So our perspective is we're building AWS for AI apps.

01:43.480 --> 01:45.160
So we get to talk to a lot of the makers

01:45.160 --> 01:46.600
who are building and deploying their apps.

01:46.600 --> 01:48.920
And through that, see both the experimental end

01:48.920 --> 01:51.800
of the spectrum and also see what kinds of apps

01:51.800 --> 01:53.720
are getting pushed out there and turned into companies,

01:53.720 --> 01:55.520
turned into side projects.

01:55.560 --> 01:59.200
We did a cool hackathon yesterday.

01:59.200 --> 02:02.000
Many thanks to Neiman, to David Malin and CS50

02:02.000 --> 02:03.400
for helping us put all of this together,

02:03.400 --> 02:04.760
to Harvard for hosting it.

02:04.760 --> 02:07.920
And there were two sessions, lots of folks built things.

02:07.920 --> 02:11.100
If you go to steamship.com slash hackathon,

02:11.100 --> 02:12.400
you'll find a lot of guides,

02:12.400 --> 02:13.840
a lot of projects that people built.

02:13.840 --> 02:16.560
And you can follow along, we have a text guide as well,

02:16.560 --> 02:18.440
just as a quick plug for that,

02:18.440 --> 02:21.240
if you want to do it remotely or on your own.

02:21.240 --> 02:23.880
So to tee up Sill, we're gonna talk about

02:23.880 --> 02:27.160
basically two things today that I hope you'll walk away with

02:27.160 --> 02:29.840
and really know how to then use as you develop

02:29.840 --> 02:30.680
and as you tinker.

02:30.680 --> 02:33.160
One is what is GPT and how is it working?

02:33.160 --> 02:35.240
Get a good sense of what's going on inside of it

02:35.240 --> 02:38.280
other than as just this magical machine that predicts things.

02:38.280 --> 02:40.720
And then two is how are people building with it?

02:40.720 --> 02:42.800
And then importantly, how can I build with it too

02:42.800 --> 02:43.680
if you're a developer?

02:43.680 --> 02:45.800
And if you have CS50 background,

02:45.800 --> 02:47.160
you should be able to pick things up

02:47.160 --> 02:48.160
and start building some great apps.

02:48.160 --> 02:50.080
I've already met some of the CS50 grads yesterday

02:50.080 --> 02:51.800
and the things that they were doing were pretty amazing.

02:51.800 --> 02:53.000
So hope this is useful.

02:53.000 --> 02:54.320
I'm gonna kick it over to Sill

02:54.320 --> 02:59.280
and talk about some of the theoretical background of GPT.

02:59.280 --> 03:01.160
Yeah, so thank you, Ted.

03:01.160 --> 03:02.000
My name is Sill.

03:02.000 --> 03:04.560
I'm a graduate student of Digital Humanities at McGill.

03:04.560 --> 03:06.560
I study literature and computer science

03:06.560 --> 03:08.480
and linguistics in the same breath.

03:08.480 --> 03:10.520
And I've published some research over the last couple of years

03:10.520 --> 03:13.800
exploring what is possible with language models

03:13.800 --> 03:15.640
and culture in particular.

03:15.640 --> 03:19.760
And my half or whatever of the presentation

03:19.760 --> 03:21.880
is to describe to you what is GPT.

03:21.880 --> 03:24.240
That's really difficult to explain in 15 minutes.

03:24.240 --> 03:26.720
And there are even a lot of things that we don't know,

03:26.720 --> 03:28.040
but a good way to approach that

03:28.040 --> 03:30.200
is to first consider all the things

03:30.200 --> 03:33.320
that people call GPT by or descriptors.

03:33.320 --> 03:35.680
So you can call them large language models.

03:35.680 --> 03:38.000
You can call them universal approximators

03:38.000 --> 03:39.040
from computer science.

03:39.040 --> 03:42.440
You can say that it is a generative AI.

03:42.440 --> 03:44.040
We know that they are neural networks.

03:44.040 --> 03:46.440
We know that it is an artificial intelligence.

03:46.440 --> 03:48.160
To some, it's a simulator of culture.

03:48.160 --> 03:50.280
To others, it just predicts text.

03:50.320 --> 03:51.480
It's also a writing assistant.

03:51.480 --> 03:52.840
If you've ever used ChatGPT,

03:52.840 --> 03:55.000
you can plug in a bit of your essay, get some feedback.

03:55.000 --> 03:56.520
It's amazing for that.

03:56.520 --> 03:57.560
It's a content generator.

03:57.560 --> 04:00.760
People use it to do copywriting, Jasper.AI,

04:00.760 --> 04:02.200
pseudo-write, et cetera.

04:02.200 --> 04:03.640
It's an agent.

04:03.640 --> 04:05.160
So the really hot thing right now,

04:05.160 --> 04:08.480
if you might have seen it on Twitter, auto-GPT, baby-AGI,

04:08.480 --> 04:10.560
people are giving these things tools

04:10.560 --> 04:13.160
and letting them run a little bit free in the wild

04:13.160 --> 04:16.120
to interact with the world computers, et cetera.

04:16.120 --> 04:18.160
We use them as chatbots, obviously.

04:18.160 --> 04:21.840
And the actual architecture is a transformer.

04:21.840 --> 04:24.480
So there's lots of ways to describe GPT.

04:24.480 --> 04:27.760
And any of them is a really perfectly adequate way

04:27.760 --> 04:29.640
to begin the conversation.

04:29.640 --> 04:31.320
But for our purposes, we can think of it

04:31.320 --> 04:32.480
as a large language model,

04:32.480 --> 04:34.920
and more specifically, a language model.

04:34.920 --> 04:39.080
And a language model is a model of language,

04:39.080 --> 04:40.360
if you allow me the tautology,

04:40.360 --> 04:41.960
but really what it does is it produces

04:41.960 --> 04:44.760
a probability distribution over some vocabulary.

04:44.760 --> 04:47.520
So let us imagine that we had the task

04:48.040 --> 04:51.000
of predicting the next word of the sequence I am.

04:51.000 --> 04:55.360
So if I give a neural network the words I am,

04:55.360 --> 04:57.880
what of all words in English

04:57.880 --> 05:00.000
is the next most likely word to follow?

05:00.000 --> 05:04.680
That, at its very core, is what GPT is trained to answer.

05:04.680 --> 05:08.680
And how it does it is it has a vocabulary of 50,000 words,

05:08.680 --> 05:12.040
and it knows, roughly, given the entire internet,

05:12.040 --> 05:14.840
which words are likely to follow other words

05:15.840 --> 05:17.960
of those 50,000 in some sequence,

05:17.960 --> 05:21.200
up to 2,000 words, up to 4,000, up to 8,000,

05:21.200 --> 05:23.640
and now up to 32,000 GPT4.

05:23.640 --> 05:26.200
So you give it a sequence, here I am,

05:26.200 --> 05:29.120
and over the vocabulary of 50,000 words,

05:29.120 --> 05:32.480
it gives you the likelihood of every single word that follows.

05:32.480 --> 05:36.920
So here it's I am, perhaps the word happy is fairly frequent,

05:36.920 --> 05:38.360
so we'll get that high probability

05:38.360 --> 05:41.480
if we look at all words, all utterances of English.

05:41.480 --> 05:44.800
It might be I am sad, maybe that's a little bit less probable,

05:45.000 --> 05:46.880
I am school, that really should be at the end

05:46.880 --> 05:48.800
because I don't think anybody would ever say that,

05:48.800 --> 05:51.760
I am Bjork, that's a little bit, it's not very probable,

05:51.760 --> 05:53.720
but it's less probable than happy sad,

05:53.720 --> 05:55.800
but there's still some probability attached to it.

05:55.800 --> 05:58.280
And when we say it's probable, that's literally a percentage,

05:58.280 --> 06:03.280
that's like happy follows I am maybe like 5% of the time,

06:03.400 --> 06:06.960
sad follows I am maybe 2% of the time, or whatever.

06:06.960 --> 06:11.520
So for every word that we give GPT,

06:11.520 --> 06:13.920
it tries to predict what the next word is

06:13.920 --> 06:16.920
across 50,000 words, and it gives every single one

06:16.920 --> 06:21.920
of those 50,000 words a number that reflects how probable it is.

06:23.160 --> 06:25.360
And the really magical thing that happens

06:25.360 --> 06:30.280
is you can generate new text, so if you give GPT I am,

06:30.280 --> 06:34.240
and it predicts happy as being the most probable word

06:34.240 --> 06:37.880
over 50,000, you can then append it to I am,

06:37.880 --> 06:41.360
so now you say I am happy, and you feed it into the model again,

06:41.480 --> 06:43.680
you sample another word, you feed it into the model again,

06:43.680 --> 06:45.240
and again, and again, and again,

06:45.240 --> 06:47.720
and there's lots of different ways that I am happy,

06:47.720 --> 06:50.920
I am sad, can go, and you add a little bit of randomness,

06:50.920 --> 06:52.520
and all of a sudden you have a language model

06:52.520 --> 06:54.840
that can write essays, that can talk,

06:54.840 --> 06:57.760
and a whole lot of things, which is really unexpected,

06:57.760 --> 06:59.120
and something that we didn't predict

06:59.120 --> 07:01.880
even five years ago, so this is all relevant.

07:01.880 --> 07:06.880
And if we move on, as we scale up the model,

07:07.520 --> 07:10.680
and we give it more compute, in 2012 AlexNet came out,

07:10.680 --> 07:15.280
and we figured out we can run the model on GPUs,

07:15.280 --> 07:16.920
so we can speed up the process,

07:16.920 --> 07:18.960
we can give the model lots of information

07:18.960 --> 07:20.320
downloaded from the internet,

07:20.320 --> 07:21.840
and it learns more and more and more,

07:21.840 --> 07:24.520
and the probabilities that it gives you

07:24.520 --> 07:26.120
get better as it sees more examples

07:26.120 --> 07:27.600
of English on the internet,

07:27.600 --> 07:30.160
so we have to train the model to be really large,

07:30.160 --> 07:33.000
really wide, and we have to train it for a really long time,

07:33.000 --> 07:35.840
and as we do that, the model gets more and more better,

07:35.840 --> 07:37.720
and expressive and capable,

07:37.720 --> 07:39.760
and it also gets a little bit intelligent,

07:39.760 --> 07:42.200
and for reasons we don't understand.

07:42.200 --> 07:45.880
So, but the issue is that because it learns

07:45.880 --> 07:47.600
to replicate the internet,

07:47.600 --> 07:51.000
it knows how to speak in a lot of different genres of text,

07:51.000 --> 07:52.520
and a lot of different registers.

07:52.520 --> 07:55.120
If you begin the conversation like, chat GPT,

07:55.120 --> 07:56.760
can you explain the moon landing to a six year old

07:56.760 --> 07:58.760
in a few sentences, GPT three,

07:58.760 --> 08:01.080
this is an example drawn from the Instruct GPT paper

08:01.080 --> 08:05.640
from OpenAI, GPT three would have just been like,

08:05.640 --> 08:07.640
okay, so you're giving me an example,

08:07.640 --> 08:09.640
like explain the moon landing to a six year old,

08:09.640 --> 08:11.480
I'm gonna give you a whole bunch of similar things

08:11.480 --> 08:13.640
because those seem very likely to come in a sequence.

08:13.640 --> 08:15.520
It doesn't necessarily understand that it's being asked

08:15.520 --> 08:18.320
that question has to respond with an answer.

08:18.320 --> 08:21.560
GPT three did not have that apparatus,

08:21.560 --> 08:24.000
that interface for responding to questions,

08:24.000 --> 08:29.000
and the scientist at OpenAI came up with the solution,

08:29.280 --> 08:31.640
and that's, let's give it a whole bunch of examples

08:31.640 --> 08:33.240
of question and answers,

08:33.240 --> 08:35.640
such that we first train it on the internet,

08:35.640 --> 08:37.640
and then we train it with a whole bunch of questions

08:37.640 --> 08:41.320
and answers such that it has the knowledge of the internet,

08:41.320 --> 08:44.200
but really knows that it has to be answering questions,

08:44.200 --> 08:47.640
and that is when chat GPT was born,

08:47.640 --> 08:50.520
and that's when it gained 100 million users in one month,

08:50.520 --> 08:53.360
I think it beat TikTok's record at 20 million in one month,

08:53.360 --> 08:56.560
it was a huge thing, and for a lot of people,

08:56.560 --> 08:58.720
they went, oh, this thing is intelligent,

08:58.720 --> 09:01.400
I can answer, I can ask it questions, it answers back,

09:01.400 --> 09:03.600
we can work together to come to a solution,

09:03.600 --> 09:06.400
and that's because it's still predicting words,

09:06.400 --> 09:08.120
it's still a language model,

09:08.120 --> 09:11.440
but it knows to predict words in the framework

09:11.440 --> 09:14.560
of a question and answer, so that's what a prompt is,

09:14.560 --> 09:17.560
that's what instruction tuning is, that's a key word,

09:17.560 --> 09:21.920
that's what RLHF is, if you've ever seen that acronym,

09:21.920 --> 09:24.760
Reinforcement Alignment with Human Feedback,

09:24.760 --> 09:27.840
and all those combined means that the models

09:27.840 --> 09:28.920
that are coming out today,

09:28.920 --> 09:30.600
the types of language predictors

09:30.600 --> 09:31.840
that are coming out today,

09:31.840 --> 09:34.000
work to operate in a Q and A form.

09:34.000 --> 09:38.400
GPT-4 exclusively only has the aligned model available,

09:38.400 --> 09:42.920
and this is a really great, solid foundation to build on,

09:42.920 --> 09:44.360
because you can do all sorts of things,

09:44.360 --> 09:46.440
you can ask chat GPT, can you do this for me,

09:46.440 --> 09:47.480
can you do that for me?

09:47.480 --> 09:48.680
You might have seen that OpenAI

09:48.680 --> 09:51.020
has allowed plugin access to chat GPT,

09:51.020 --> 09:53.800
so it can access Wolfram, it can search the web,

09:53.800 --> 09:56.280
it can search, it can do Instacart for you,

09:56.280 --> 10:00.520
it can look up recipes, once the model knows

10:00.520 --> 10:02.640
that not only it has to predict language,

10:02.640 --> 10:05.000
but that it has to solve a problem,

10:05.920 --> 10:07.640
and the problem here being,

10:07.640 --> 10:09.560
give me a good answer to my question,

10:09.560 --> 10:11.560
it's suddenly able to interface with the world

10:11.560 --> 10:13.000
in a really solid way,

10:13.000 --> 10:15.720
and from there on, there's been all sorts of tools

10:15.720 --> 10:19.600
that it build on this Q and A form that chat GPT uses,

10:19.600 --> 10:22.800
you have auto GPT, you have Langchain,

10:22.800 --> 10:26.840
you have React, there was a React paper

10:26.840 --> 10:28.140
where a lot of these come from,

10:28.140 --> 10:30.880
and turning the model into an agent

10:31.480 --> 10:34.560
which to achieve any ambiguous goal

10:34.560 --> 10:36.080
is where the future is going,

10:36.080 --> 10:38.360
and this is all thanks to instruction tuning,

10:38.360 --> 10:41.720
and with that, I think I will hand it off to Ted,

10:41.720 --> 10:43.320
who will be giving a demo,

10:43.320 --> 10:44.560
or something along those lines,

10:44.560 --> 10:49.360
for how to use GPT as an agent, so.

10:51.920 --> 10:54.640
All right, so I'm a super applied guy,

10:54.640 --> 10:56.800
I kinda look at things and think,

10:56.800 --> 11:00.080
okay, how can I add this Lego, add that Lego,

11:00.120 --> 11:02.520
and clip them together and build something with it,

11:02.520 --> 11:06.760
and right now, if you look back in computer science history,

11:06.760 --> 11:08.200
when you look at the kinds of things

11:08.200 --> 11:10.240
that were being done in 1970,

11:10.240 --> 11:11.980
right after computing was invented,

11:11.980 --> 11:14.080
the microprocessors were invented,

11:14.080 --> 11:15.240
people were doing research like,

11:15.240 --> 11:17.120
how do I sort a list of numbers,

11:17.120 --> 11:18.360
and that was meaningful work,

11:18.360 --> 11:20.760
and importantly, it was work that's accessible to everybody,

11:20.760 --> 11:22.960
because nobody knows what we can build

11:22.960 --> 11:25.760
with this new kind of oil, this new kind of electricity,

11:25.760 --> 11:28.840
this new kind of unit of computation we've created,

11:28.880 --> 11:30.160
and anything was game,

11:30.160 --> 11:32.240
and anybody could participate in that game

11:32.240 --> 11:33.080
to figure it out,

11:33.080 --> 11:34.440
and I think one of the really exciting things

11:34.440 --> 11:37.240
about GPT right now is, yes,

11:37.240 --> 11:38.920
in and of itself, it's amazing,

11:38.920 --> 11:41.520
but then, what could we do with it

11:41.520 --> 11:43.160
if we call it over and over again,

11:43.160 --> 11:44.900
if we build it into our algorithms,

11:44.900 --> 11:46.520
and start to build it into broader software,

11:46.520 --> 11:47.960
so the world really is yours

11:47.960 --> 11:50.080
to figure out those fundamental questions

11:50.080 --> 11:52.600
about what could you do if you could script

11:52.600 --> 11:55.280
computation itself over and over again

11:55.280 --> 11:56.940
in the way that computers can do,

11:56.940 --> 11:59.540
not just talk with it, but build things atop it,

11:59.540 --> 12:02.100
so we're a hosting company, we host apps,

12:02.100 --> 12:04.520
and these are just some of the things that we see,

12:04.520 --> 12:06.260
I'm gonna show you demos of this with code

12:06.260 --> 12:08.740
and try to explain some of the thought process,

12:08.740 --> 12:10.740
but I wanted to give you a high level overview of,

12:10.740 --> 12:12.740
you've probably seen these on Twitter,

12:12.740 --> 12:14.660
but when it all sorts out to the top,

12:14.660 --> 12:16.260
these are some of the things that we're seeing

12:16.260 --> 12:19.540
built and deployed with language models today,

12:19.540 --> 12:22.500
companionship, that's everything from I need a friend,

12:22.500 --> 12:23.820
to I need a friend with a purpose,

12:23.820 --> 12:25.940
I want a coach, I want somebody to tell me,

12:25.940 --> 12:27.380
go to the gym and do these exercises,

12:27.380 --> 12:29.620
I want somebody to help me study a foreign language,

12:29.620 --> 12:31.400
question answering, this is a big one,

12:31.400 --> 12:33.100
this is everything from your newsroom,

12:33.100 --> 12:35.540
having a slack bot that helps assist you,

12:35.540 --> 12:39.260
does this article conform to the style guidelines

12:39.260 --> 12:41.500
of our newsroom, all the way through to,

12:41.500 --> 12:42.740
and you need help on my homework,

12:42.740 --> 12:44.540
or hey, I have some questions that I want you to ask,

12:44.540 --> 12:46.860
Wikipedia, combine it with something else,

12:46.860 --> 12:48.980
synthesize the answer and give it to me.

12:48.980 --> 12:51.940
Utility functions, I would describe this as,

12:51.940 --> 12:54.860
there's a large set of things for which

12:54.900 --> 12:57.580
human beings can do them, if only,

12:57.580 --> 13:00.060
or computers could do them, if only they had access

13:00.060 --> 13:01.820
to language computation, language knowledge,

13:01.820 --> 13:03.340
an example of this would be,

13:03.340 --> 13:06.460
read every tweet on Twitter, tell me the ones I should read,

13:06.460 --> 13:07.940
that way I only get to read the ones

13:07.940 --> 13:09.140
that actually make sense to me

13:09.140 --> 13:10.740
and I don't have to skim through the rest,

13:10.740 --> 13:13.460
creativity, image generation, text generation,

13:13.460 --> 13:15.980
storytelling, proposing other ways to do things,

13:15.980 --> 13:19.740
and then these wild experiments and kind of baby AGI,

13:19.740 --> 13:21.380
as people are calling them,

13:21.380 --> 13:23.500
in which the AI itself decides what to do

13:23.500 --> 13:25.300
and is self-directed, so I'll show you examples

13:25.300 --> 13:27.180
of many of these and what the code looks like,

13:27.180 --> 13:29.740
and if I were you, I would think about these

13:29.740 --> 13:32.820
as categories within which to both think about

13:32.820 --> 13:37.140
what you might build and then also seek out starter projects

13:37.140 --> 13:39.660
for how you might go about building them online.

13:42.500 --> 13:43.820
All right, so I'm just gonna dive straight into

13:43.820 --> 13:45.500
demos and code for some of these,

13:45.500 --> 13:47.180
because I know that's what's interesting to see

13:47.180 --> 13:49.860
as fellow builders, with a high level diagram

13:49.860 --> 13:51.580
for some of these as to how it works.

13:51.580 --> 13:54.780
So approximately, you can think of a companionship bot

13:54.780 --> 13:57.620
as a friend that has a purpose to you,

13:57.620 --> 14:00.100
and there are many ways to build all of these things,

14:00.100 --> 14:01.780
but one of the ways you can build this

14:01.780 --> 14:04.660
is simply to wrap GPT or a language model

14:04.660 --> 14:07.860
in an endpoint that additionally injects into the prompt

14:07.860 --> 14:10.700
some particular perspective or some particular goal

14:10.700 --> 14:11.980
that you want to use.

14:11.980 --> 14:13.820
It really is that easy in a way,

14:13.820 --> 14:16.140
but it's also very hard because you need to iterate

14:16.140 --> 14:19.820
and engineer the prompt so that it consistently performs

14:19.820 --> 14:22.140
the way you want it to perform.

14:22.140 --> 14:24.700
So a good example of this is something somebody built

14:24.700 --> 14:25.620
in the hackathon yesterday,

14:25.620 --> 14:27.940
and I just wanted to show you the project that they built.

14:27.940 --> 14:29.540
It was a Mandarin idiom coach,

14:29.540 --> 14:31.820
and I'll show you what the code looked like first.

14:31.820 --> 14:33.860
I'll show you the demo first.

14:33.860 --> 14:35.300
I think I already pulled it up.

14:38.140 --> 14:39.300
Here we go.

14:39.300 --> 14:42.820
So the buddy that this person wanted to create

14:42.820 --> 14:47.220
was a friend that if you gave it a particular problem

14:47.220 --> 14:49.900
you were having, it would pick a Chinese idiom,

14:49.900 --> 14:53.100
a four character Cheng Yu, that described poetically,

14:53.100 --> 14:56.100
like here's a particular way you could say this,

14:56.100 --> 14:57.780
and it would tell it to her so that the person

14:57.780 --> 14:59.700
who built this was studying Chinese

14:59.700 --> 15:01.980
and she wanted to learn more about it.

15:01.980 --> 15:06.820
So I might say something like I'm feeling very sad,

15:08.140 --> 15:10.420
and it would think a little bit,

15:10.420 --> 15:12.780
and if everything's up and running,

15:12.780 --> 15:16.260
it will generate one of these four character phrases,

15:16.260 --> 15:19.700
and it will respond to it with an example.

15:19.700 --> 15:21.020
Now, I don't know if this is correct or not,

15:21.020 --> 15:22.380
so if somebody can call me out,

15:22.380 --> 15:25.220
if this is actually incorrect, please call me out,

15:26.220 --> 15:28.420
and it will then finish up with something encouraging,

15:28.420 --> 15:30.980
saying hey, you can do it, I know this is hard, keep going.

15:30.980 --> 15:32.340
So let me show you how they built this,

15:32.340 --> 15:37.340
and I pulled up the code right here.

15:40.540 --> 15:45.060
So this was the particular starter replete

15:45.060 --> 15:47.420
that folks were using in the hackathon yesterday,

15:47.420 --> 15:49.940
and we pulled things up into basically,

15:49.940 --> 15:52.700
you have a wrapper around GPT,

15:52.700 --> 15:54.380
and there's many things you could do,

15:54.380 --> 15:56.300
but we're gonna make it easy for you to do two things.

15:56.300 --> 16:00.060
One of them is to inject some personality into the prompt,

16:00.060 --> 16:02.660
and I'll explain what that prompt is in a second,

16:02.660 --> 16:04.140
and then the second is add tools

16:04.140 --> 16:05.580
that might go out and do a particular thing,

16:05.580 --> 16:08.260
search the web or generate an image

16:08.260 --> 16:09.700
or add something to a database

16:09.700 --> 16:11.780
or fetch something from a database.

16:11.780 --> 16:13.100
So having done that,

16:13.100 --> 16:15.340
now you have something more than GPT.

16:15.340 --> 16:17.780
Now you have GPT, which we all know what it is

16:17.780 --> 16:19.100
and how we can interact with it,

16:19.100 --> 16:21.700
but you've also added a particular lens

16:21.700 --> 16:22.700
through which it's talking to you

16:22.700 --> 16:23.660
and potentially some tools.

16:23.660 --> 16:27.140
So this particular Chinese tutor,

16:27.140 --> 16:30.320
all it took to build that was four lines.

16:30.320 --> 16:31.660
So here's a question that I think

16:31.660 --> 16:34.700
is frying the minds of everybody in the industry right now.

16:35.700 --> 16:38.300
So is this something that we'll all do casually

16:38.300 --> 16:39.300
and nobody really knows?

16:39.300 --> 16:41.260
Will we just all say in the future to the LLM,

16:41.260 --> 16:42.500
hey, for the next five minutes,

16:42.500 --> 16:45.140
please talk like a teacher, and maybe?

16:45.140 --> 16:47.180
But also, definitely in the meantime,

16:47.180 --> 16:48.140
and maybe in the future,

16:48.140 --> 16:51.100
it makes sense to wrap up these personalized endpoints

16:51.100 --> 16:52.500
so that when I'm talking to GPT,

16:52.500 --> 16:53.900
I'm not just talking to GPT,

16:53.900 --> 16:55.700
I have a whole army of different buddies,

16:55.700 --> 16:58.140
of different companions that I can talk to.

16:58.140 --> 16:59.060
They're kind of human

16:59.060 --> 17:00.700
and kind of talk to me interactively,

17:00.700 --> 17:02.540
but because I preloaded them with,

17:02.540 --> 17:05.100
hey, by the way, you particular,

17:05.100 --> 17:06.940
I want you to be a kind, helpful Chinese teacher

17:06.940 --> 17:08.460
that responds to every situation

17:08.460 --> 17:10.260
by explaining the Chongyu that fits it.

17:10.300 --> 17:12.780
Speak in English and explain the Chongyu in its meaning.

17:12.780 --> 17:15.740
Then provide a note of encouragement about learning language.

17:15.740 --> 17:18.020
And so just adding something like that,

17:18.020 --> 17:19.900
even if you're a non-programmer,

17:19.900 --> 17:21.500
you can just type deploy,

17:24.220 --> 17:26.500
and it'll pop it up to the web,

17:26.500 --> 17:28.140
it'll take it over to a telegram bot

17:28.140 --> 17:29.540
that then you can even interact with,

17:29.540 --> 17:32.100
hey, I'm feeling too busy,

17:33.340 --> 17:35.940
and interact with it over telegram, over the web,

17:35.940 --> 17:38.580
and this is the kind of thing that's now within reach

17:38.580 --> 17:41.940
for everybody from a CS 101 grad,

17:41.940 --> 17:44.380
sorry, I'm using the general purpose framing,

17:44.380 --> 17:46.940
all the way through to professionals in the industry,

17:46.940 --> 17:49.580
that you can do just with a little bit of manipulation

17:49.580 --> 17:51.940
on top of sort of this raw unit

17:51.940 --> 17:54.620
of conversation and intelligence.

17:57.100 --> 18:00.180
So companionship is one of the first

18:00.180 --> 18:02.740
common types of apps that we're seeing.

18:04.820 --> 18:07.780
So a second kind of app that we're seeing,

18:07.780 --> 18:12.780
and for those of you who are on Twitter followers,

18:12.860 --> 18:15.900
this blew up, I think the last few months,

18:15.900 --> 18:16.980
is question-answering,

18:16.980 --> 18:18.580
and I wanna unpack a couple of different ways

18:18.580 --> 18:20.620
this can work, because I know many of you

18:20.620 --> 18:22.820
have probably already tried to build

18:22.820 --> 18:23.780
some of these kinds of apps,

18:23.780 --> 18:25.500
there's a couple of different ways that it works.

18:25.500 --> 18:29.740
The general framework is a user queries GPT,

18:29.740 --> 18:31.300
and maybe it has general purpose knowledge,

18:31.300 --> 18:33.140
maybe it doesn't have general purpose knowledge,

18:33.140 --> 18:35.980
but what you want it to say back to you

18:35.980 --> 18:38.660
is something specific about an article you wrote,

18:38.660 --> 18:41.500
or something specific about your course syllabus,

18:41.500 --> 18:44.660
or something specific about a particular set of documents

18:44.660 --> 18:46.940
from the United Nations on a particular topic.

18:46.940 --> 18:48.260
And so what you're really seeking is

18:48.260 --> 18:50.460
what we all hoped the customer service bot would be,

18:50.460 --> 18:52.580
like we've all interacted with these customer service bots,

18:52.580 --> 18:54.180
and we're kind of smashing our heads

18:54.180 --> 18:55.820
on the keyboard as we do it,

18:55.820 --> 18:58.460
but pretty soon we're gonna start to see

18:58.460 --> 19:01.500
very high fidelity bots that interact with us comfortably,

19:01.500 --> 19:03.580
and this is approximately how to do it as an engineer.

19:03.580 --> 19:05.900
So here's your game plan as an engineer,

19:05.900 --> 19:10.660
step one, take the documents that you want it to respond to.

19:11.740 --> 19:13.660
Step two, cut them up.

19:13.660 --> 19:15.980
Now, if you're an engineer, this is gonna madden you.

19:15.980 --> 19:18.540
You don't cut them up in a way that you would hope.

19:18.540 --> 19:20.540
For example, you could cut them up

19:20.540 --> 19:22.740
into clean sentences or clean paragraphs,

19:22.740 --> 19:24.660
or semantically coherent sections,

19:24.660 --> 19:26.340
and that would be really nice.

19:26.340 --> 19:28.420
Honestly, the way that most folks do it,

19:28.420 --> 19:32.060
and this is a simplification that tends to be just fine,

19:32.060 --> 19:34.460
is you window, you have a sliding window

19:34.460 --> 19:35.980
that goes over the document,

19:35.980 --> 19:38.860
and you just pull out fragments of text.

19:38.860 --> 19:40.660
Having pulled out those fragments of text,

19:40.660 --> 19:43.020
you turn them into something called an embedding vector.

19:43.020 --> 19:46.100
So an embedding vector is a list of numbers

19:46.100 --> 19:49.260
that approximate some point of meaning.

19:49.260 --> 19:50.700
So you've already all dealt

19:50.700 --> 19:52.620
with embedding vectors yourself in regular life,

19:52.620 --> 19:54.420
and the reason you have, and I know you have,

19:54.420 --> 19:57.020
is because everybody's ordered food from Yelp before.

19:57.020 --> 19:58.540
So when you order food from Yelp,

19:58.540 --> 20:01.340
you look at what genre of restaurant is it?

20:01.340 --> 20:02.700
Is it a pizza restaurant?

20:02.700 --> 20:03.820
Is it an Italian restaurant?

20:03.820 --> 20:05.500
Is it a Korean barbecue place?

20:05.500 --> 20:06.980
You look at how many stars does it have?

20:06.980 --> 20:08.860
One, two, three, four, five?

20:08.860 --> 20:09.980
You look at where is it?

20:09.980 --> 20:12.820
So all of these you can think of as points in space,

20:12.820 --> 20:14.060
dimensions in space.

20:14.060 --> 20:17.100
Korean barbecue restaurant, four stars near my house.

20:17.100 --> 20:20.820
That's a three number vector.

20:20.820 --> 20:21.820
That's all this is.

20:21.820 --> 20:23.660
So this is a thousand number vector,

20:23.660 --> 20:24.780
or a 10,000 number vector.

20:24.780 --> 20:27.100
Different models produce different size vectors.

20:27.100 --> 20:30.260
All it is is chunking pieces of text,

20:30.260 --> 20:32.480
turning it into a vector that approximates meaning,

20:32.480 --> 20:34.240
and then you put it in something called a vector database.

20:34.240 --> 20:36.520
And a vector database is just a database

20:36.520 --> 20:38.520
that stores numbers.

20:38.520 --> 20:42.440
But having that database, now when I ask a question,

20:42.440 --> 20:44.680
I can search the database, and I can say, hey, the question

20:44.680 --> 20:47.280
was, what does CS50 teach?

20:47.280 --> 20:50.520
What pieces of text in the database

20:50.520 --> 20:56.000
have vectors similar to the question, what does CS50 teach?

20:56.000 --> 20:58.320
And there's all sorts of tricks and empires

20:58.320 --> 21:01.600
being made on refinements of this general approach.

21:01.640 --> 21:06.400
But at the end, you, the developer, model it simply as thus.

21:06.400 --> 21:08.840
And then when you have your query, you embed it,

21:08.840 --> 21:11.280
you find the document fragments, and then you put them

21:11.280 --> 21:11.880
into a prompt.

21:11.880 --> 21:15.800
And now we're just back to the personality, the companionship

21:15.800 --> 21:16.400
bot.

21:16.400 --> 21:17.800
Now it's just a prompt.

21:17.800 --> 21:20.920
And the prompt is, you're an expert in answering questions.

21:20.920 --> 21:24.040
Please answer user provided question.

21:24.040 --> 21:27.120
Using source documents results from the database.

21:27.120 --> 21:28.760
That's it.

21:28.760 --> 21:30.600
So after all of these decades of engineering

21:30.600 --> 21:31.680
and these customer service bots, it

21:31.680 --> 21:33.360
turns out with a couple of lines of code.

21:33.360 --> 21:34.120
You can build this.

21:34.120 --> 21:37.360
So let me show you, I made one just before the class

21:37.360 --> 21:39.080
with the CS50 syllabus.

21:39.080 --> 21:43.760
So we can pull that up.

21:43.760 --> 21:47.040
And I can say, I added the PDF right here.

21:47.040 --> 21:49.200
So I just, I searched, I don't know if, I apologize.

21:49.200 --> 21:51.240
I don't know if it's an accurate or recent syllabus.

21:51.240 --> 21:53.920
I just searched the web for CS50 syllabus PDF.

21:53.920 --> 21:56.840
I put the URL in here, it loaded it into here.

21:56.840 --> 21:59.920
This is just a 100 line piece of code deployed

21:59.960 --> 22:02.200
that will now let me talk to it.

22:02.200 --> 22:07.640
And I can say, what will CS50 teach me?

22:07.640 --> 22:09.240
So under the hood now, what's happening

22:09.240 --> 22:10.880
is exactly what that slide just showed you.

22:10.880 --> 22:13.360
It takes that question, what will CS50 teach me?

22:13.360 --> 22:15.200
It turns it into a vector.

22:15.200 --> 22:18.880
That vector approximates without exactly representing

22:18.880 --> 22:21.160
the meaning of that question.

22:21.160 --> 22:23.640
It looks into a vector database that

22:23.640 --> 22:27.760
steamship hosts of fragments from that PDF.

22:27.760 --> 22:30.120
And then it pulls out a document and then passes it

22:30.120 --> 22:32.920
to a prompt that says, hey, you're an expert

22:32.920 --> 22:34.480
at answering questions.

22:34.480 --> 22:37.080
Someone has asked you, what does CS50 teach?

22:37.080 --> 22:39.920
Please answer it using only the source documents

22:39.920 --> 22:41.800
and source materials I've provided.

22:41.800 --> 22:43.640
Now those source materials materials

22:43.640 --> 22:45.560
are dynamically loaded into the prompt.

22:45.560 --> 22:46.720
It's just basic prompt engineering.

22:46.720 --> 22:49.280
And I want to keep harping back onto that.

22:49.280 --> 22:51.720
What's amazing about right now as builders

22:51.720 --> 22:54.000
is that so many things just boil down

22:54.040 --> 22:59.400
into very creative, tactical rearrangement of prompts

22:59.400 --> 23:01.880
and then using those over and over again in an algorithm

23:01.880 --> 23:03.040
and putting that into software.

23:03.040 --> 23:05.360
So the result, and again, it could be lying.

23:05.360 --> 23:06.280
It could be making things up.

23:06.280 --> 23:07.520
It could be hallucinating.

23:07.520 --> 23:09.840
Is CS50 will teach students how to think algorithmically

23:09.840 --> 23:11.680
and solve problems efficiently, focusing on topics

23:11.680 --> 23:13.440
such as abstraction, dot, dot, dot, dot, dot.

23:13.440 --> 23:15.600
And then it returns the source document

23:15.600 --> 23:16.600
from which it was found.

23:16.600 --> 23:19.120
So this is another big category of which there

23:19.120 --> 23:22.720
are tons of potential applications

23:22.720 --> 23:25.120
because you can repeat for each context.

23:25.120 --> 23:27.800
You can create arbitrarily many of these once it's software

23:27.800 --> 23:30.840
because once it's software, you can just repeat it

23:30.840 --> 23:31.680
over and over again.

23:31.680 --> 23:34.600
So for your dorm, for your club, for your slack,

23:34.600 --> 23:37.560
for your telegram, you can start to begin putting

23:37.560 --> 23:40.560
pieces of information in and then responding to it.

23:40.560 --> 23:42.040
And it doesn't have to be documents.

23:42.040 --> 23:44.940
You can also load it straight into the prompt.

23:46.200 --> 23:47.800
I think I have it pulled up here.

23:47.800 --> 23:50.200
And if I don't, I'll just skip it.

23:50.200 --> 23:51.040
Oh, here we go.

23:52.040 --> 23:54.400
One other way you can do question answering,

23:55.520 --> 23:57.600
because I think it's healthy to always encourage

23:57.600 --> 24:00.520
the simplest possible approach to something.

24:00.520 --> 24:02.960
You don't need to engineer this giant system.

24:02.960 --> 24:04.200
It's great to have a database.

24:04.200 --> 24:05.240
It's great to use embeddings.

24:05.240 --> 24:06.480
It's great to use this big approach.

24:06.480 --> 24:07.680
It's fancy at scales.

24:07.680 --> 24:09.480
You can do a lot of things.

24:09.480 --> 24:11.960
But you can also get away with a lot

24:11.960 --> 24:13.880
by just pushing it all into a prompt.

24:13.880 --> 24:16.280
And as an engineer, I'm, you know,

24:16.280 --> 24:17.720
that's one of our team who's here always says,

24:17.720 --> 24:19.200
like, engineers should aspire to be lazy.

24:19.200 --> 24:20.800
And I couldn't agree more.

24:20.880 --> 24:23.880
You, as an engineer, should want to set yourself up

24:23.880 --> 24:27.360
so that you can pursue the lazy path to something.

24:27.360 --> 24:30.720
So here's how you might do the equivalent

24:30.720 --> 24:32.600
of a question answering system with a prompt alone.

24:32.600 --> 24:35.200
Let's say you have 30 friends.

24:35.200 --> 24:37.080
And each friend is good at a particular thing,

24:37.080 --> 24:39.000
or you can, you know, this is isomorphic

24:39.000 --> 24:40.560
to many other problems.

24:40.560 --> 24:43.060
You can simply just say, hey, I know certain things.

24:43.060 --> 24:44.720
Here's the things I know.

24:44.720 --> 24:49.160
A user's gonna ask me something, how should we respond?

24:49.160 --> 24:50.840
And then you load that into an agent.

24:50.840 --> 24:53.480
That agent has access to GPT.

24:53.480 --> 24:54.840
You can ship deploy it.

24:54.840 --> 24:57.680
And now you've got a bot that you can connect to Telegram.

24:57.680 --> 24:59.360
You can connect to Slack.

24:59.360 --> 25:02.520
And that bot, now it won't always give you the right answer.

25:02.520 --> 25:03.480
Because at a certain level,

25:03.480 --> 25:06.660
we can't control the variance of the model underneath.

25:06.660 --> 25:10.240
But it will tend to answer with respect to this list.

25:10.240 --> 25:13.120
And the degree to which it tends to is to a certain extent,

25:13.120 --> 25:15.080
something that both industry is working on

25:15.080 --> 25:17.640
to just give everybody as a capacity.

25:17.640 --> 25:19.720
But also you doing prompt engineering

25:19.720 --> 25:23.340
to tighten up the error bars on it.

25:26.900 --> 25:29.280
So I'll show you just a few more examples.

25:29.280 --> 25:31.520
And then in about eight minutes,

25:31.520 --> 25:32.620
I'll turn it over to questions,

25:32.620 --> 25:34.280
because I'm sure you've got a lot about how to build things.

25:34.280 --> 25:37.020
So just to give you a sense of where we are.

25:41.000 --> 25:43.200
This is one, I don't have a demo for you.

25:43.200 --> 25:46.500
But if you were to come to me and you were to say, Ted,

25:46.500 --> 25:49.540
I want a weekend hustle, man, what should I build?

25:49.540 --> 25:51.100
Holy moly.

25:51.100 --> 25:53.300
There are a set of applications

25:53.300 --> 25:55.060
that I would describe as utility functions.

25:55.060 --> 25:56.260
I don't like that name,

25:56.260 --> 25:57.460
because it doesn't sound exciting,

25:57.460 --> 25:59.180
and this is really exciting.

25:59.180 --> 26:02.380
And it's low hanging fruits that automate tasks

26:02.380 --> 26:04.220
that require basic language understanding.

26:04.220 --> 26:08.140
So examples for this are generate a unit test.

26:08.140 --> 26:10.860
I don't know how many of you have ever been writing tests

26:10.860 --> 26:12.260
and you're just like, oh, come on,

26:12.260 --> 26:13.980
I can get through this, I can get through this.

26:13.980 --> 26:15.180
If you're a person who likes writing tests,

26:15.180 --> 26:16.860
you're a lucky individual.

26:16.860 --> 26:18.620
Looking up the documentation for a function,

26:18.620 --> 26:20.580
rewriting a function, making something conform

26:20.580 --> 26:23.620
to your company guidelines, doing a brand check.

26:23.620 --> 26:24.860
All of these things are things

26:24.860 --> 26:29.460
that are kind of relatively context-free operations

26:29.460 --> 26:33.140
or scoped context operations on a piece of information

26:33.140 --> 26:35.140
that requires linguistic understanding.

26:36.300 --> 26:39.580
And really, you can think of them as something

26:39.580 --> 26:42.420
that is now available to you as a software builder,

26:42.420 --> 26:44.180
as a weekend project builder,

26:44.180 --> 26:46.220
as a startup builder.

26:46.220 --> 26:48.740
And you just have to build the interface around it

26:48.740 --> 26:51.460
and present it to other people in a context

26:51.460 --> 26:54.180
in which it's meaningful for them to consume.

26:54.180 --> 26:57.220
And so the space of this is extraordinary.

26:57.220 --> 26:59.380
I mean, it's the space of all human endeavor,

26:59.380 --> 27:00.900
now with this new tool, I think,

27:00.900 --> 27:02.180
is the way to think about it.

27:02.180 --> 27:04.780
People often joke about how when you're building a company,

27:04.780 --> 27:05.820
when you're building a project,

27:05.820 --> 27:07.420
you don't want to start with a hammer,

27:07.420 --> 27:09.500
because you want to start with a problem instead.

27:09.500 --> 27:11.980
And it's generally true, but my God,

27:11.980 --> 27:13.820
we've just got a really cool new hammer.

27:13.820 --> 27:15.820
And to a certain extent, I would encourage you

27:15.820 --> 27:17.340
to at least casually, on the weekends,

27:17.340 --> 27:18.580
run around and hit stuff with it

27:18.580 --> 27:20.580
and see what can happen from a builder's,

27:20.580 --> 27:23.980
from a tinkerers, from an experimentalist's point of view.

27:27.940 --> 27:31.020
And then the final one is creativity.

27:31.020 --> 27:32.940
This is another huge mega app.

27:32.940 --> 27:35.660
Now, I'm primarily living the text world,

27:35.660 --> 27:37.940
and so I'm gonna talk about text-based things.

27:37.940 --> 27:41.420
I think so far, this has mostly been growing

27:41.420 --> 27:44.220
in the imagery world, because we're such visual creatures,

27:44.220 --> 27:45.620
and the images you can generate

27:45.620 --> 27:48.540
are just staggering with AI.

27:48.540 --> 27:50.260
Certainly brings up a lot of questions, too,

27:50.260 --> 27:52.160
around IP and artistic style.

27:53.140 --> 27:55.660
But the template for this, if you're a builder,

27:55.660 --> 27:57.580
that we're seeing in the wild,

27:57.580 --> 27:58.820
is approximately the following.

27:58.820 --> 28:01.540
And the thing I want to point out is domain knowledge here.

28:01.540 --> 28:02.980
This is really the purpose of this slide,

28:02.980 --> 28:06.760
is to touch on the importance of the domain knowledge.

28:06.760 --> 28:10.760
So, many people approximately

28:10.760 --> 28:12.960
find the creative process as follows.

28:12.960 --> 28:14.220
Come up with a big idea.

28:15.560 --> 28:18.400
Over-generate possibilities.

28:18.400 --> 28:21.240
Edit down what you over-generated.

28:21.240 --> 28:22.720
Repeat, right?

28:22.720 --> 28:24.240
Like anybody who's been a writer

28:24.240 --> 28:26.480
knows when you write, you write way too much,

28:26.480 --> 28:28.240
and then you have to delete lots of it.

28:28.240 --> 28:29.960
And then you revise, and you write way too much,

28:29.960 --> 28:31.520
and you have to delete lots of it.

28:31.520 --> 28:34.640
This particular task is fantastic for AI.

28:34.640 --> 28:36.680
One of the reasons it's fantastic for AI

28:36.680 --> 28:38.400
is because it allows the AI to be wrong.

28:38.400 --> 28:39.720
You know, you've pre-agreed,

28:39.720 --> 28:40.640
you're gonna delete lots of it.

28:40.640 --> 28:43.560
And so, if you pre-agreed, hey, I'm just gonna build,

28:43.560 --> 28:46.240
generate five possibilities of the story I might tell.

28:46.240 --> 28:48.520
Five possibilities of the advertising headline.

28:48.520 --> 28:52.800
Five possibilities of what I might write my thesis on.

28:52.800 --> 28:54.440
You pre-agreed, it's okay if it's a little wrong,

28:54.440 --> 28:56.960
because you are going to be the editor that steps in.

28:56.960 --> 28:58.800
And here's the thing that you really

28:58.800 --> 29:01.000
should bring to the table, is don't think about this

29:01.000 --> 29:02.000
as a technical activity.

29:02.000 --> 29:04.320
Think about this as your opportunity

29:04.320 --> 29:06.840
not to put GPT in charge.

29:06.840 --> 29:10.080
Instead, for you to grasp the steering wheel tighter,

29:10.080 --> 29:12.520
I think, at least, in Python,

29:12.520 --> 29:14.520
or the language you're using to program,

29:14.520 --> 29:16.600
because you have the domain knowledge

29:16.600 --> 29:19.080
to wield GPT in the generation of those.

29:19.080 --> 29:21.240
So let me show you an example of what I mean by that.

29:21.240 --> 29:26.240
So, this is a cool app that someone created

29:26.640 --> 29:27.800
for the Writing Atlas project.

29:27.800 --> 29:30.800
So Writing Atlas is a set of short stories,

29:31.800 --> 29:35.200
and you can think of it as good reads for short stories.

29:35.200 --> 29:38.000
So you can go in here, you can browse different stories,

29:38.000 --> 29:39.480
and this was something somebody created

29:39.480 --> 29:42.760
where you can type in a story description that you like,

29:42.760 --> 29:44.360
and this is gonna take about a minute to generate,

29:44.360 --> 29:46.280
so I'm gonna talk while it's generating.

29:46.280 --> 29:51.280
And while it's working, what it's doing,

29:51.440 --> 29:52.920
and I'll show you the code in a second,

29:52.920 --> 29:55.400
is it's searching through the collection of stories

29:55.400 --> 29:56.800
for similar stories, and here's where

29:56.800 --> 29:58.520
the domain knowledge part comes in.

29:58.640 --> 30:02.600
Then it uses GPT to look at what it was that you wanted,

30:02.600 --> 30:04.840
and use knowledge of how an editor,

30:04.840 --> 30:07.160
how a bookseller thinks, to generate

30:07.160 --> 30:10.200
a set of suggestions specifically through the lens

30:10.200 --> 30:12.360
of that perspective with the goal of writing

30:12.360 --> 30:13.960
that beautiful handwritten note

30:13.960 --> 30:16.200
that we sometimes see in a local bookstore

30:16.200 --> 30:19.480
tacked on underneath a book.

30:19.480 --> 30:21.840
And so it doesn't just say, hey, you might like this,

30:21.840 --> 30:24.980
here's a general purpose reason why you might like this,

30:24.980 --> 30:27.800
but specifically, here's why you might like this

30:27.840 --> 30:29.640
with respect to what you gave it.

30:29.640 --> 30:32.680
It's either stalling out, or it's taking a long time.

30:32.680 --> 30:33.520
Oh, there we go.

30:34.600 --> 30:39.600
So here's its suggestions, and in particular, these things,

30:39.800 --> 30:41.560
these are things that only a human could know,

30:41.560 --> 30:45.240
at least for now, two humans specifically,

30:45.240 --> 30:47.360
the human who said they wanted to read a story,

30:47.360 --> 30:48.720
that's the text that came in,

30:48.720 --> 30:51.680
and then the human who added domain knowledge

30:51.680 --> 30:54.160
to script a sequence of interactions

30:54.160 --> 30:56.760
with the language model so that you could provide

30:56.800 --> 30:59.440
very targeted reasoning over something

30:59.440 --> 31:01.520
that was informed by that domain knowledge.

31:01.520 --> 31:05.500
So for these utility apps, bring your domain knowledge.

31:09.640 --> 31:12.160
Let me actually show you how this looks and code,

31:12.160 --> 31:14.720
because I think it's useful to see how simple

31:14.720 --> 31:15.940
and accessible this is.

31:15.940 --> 31:18.400
This is really a set of prompts.

31:18.400 --> 31:22.240
So why might they, like a particular location,

31:22.240 --> 31:23.640
well, here's the prompt that did that,

31:23.640 --> 31:25.880
this is an open source project,

31:25.880 --> 31:27.520
and it has a bunch of examples,

31:27.520 --> 31:31.000
and then it says, well, here's the one that we're interested in.

31:31.000 --> 31:32.880
Here's the audience, here's a couple of examples

31:32.880 --> 31:35.080
of why might people like a particular thing

31:35.080 --> 31:37.400
in terms of audience, it's just another prompt.

31:42.320 --> 31:44.520
Same for topic, same for explanation,

31:44.520 --> 31:47.320
and if you go down here and look at how it was done,

31:49.340 --> 31:51.560
suggesting the story is, what is this,

31:51.560 --> 31:54.840
line 174 to line 203, it really is,

31:54.840 --> 31:56.320
and again, over and over again,

31:56.320 --> 31:59.180
I wanna impress upon you, this really is within reach.

31:59.180 --> 32:03.720
It's really just what, 20 odd lines of step one,

32:03.720 --> 32:06.600
search in the database for similar stories,

32:06.600 --> 32:09.880
step two, given that I have similar stories,

32:09.880 --> 32:12.480
pull out the data, step three,

32:12.480 --> 32:15.160
with my domain knowledge in Python,

32:15.160 --> 32:17.600
now run these prompts, step four,

32:17.600 --> 32:19.020
prepare that into an output.

32:19.020 --> 32:21.440
So the thing we're scripting itself

32:21.440 --> 32:24.680
is some approximation of human cognition.

32:24.680 --> 32:26.560
If you're willing to go there metaphorically,

32:26.560 --> 32:28.720
we're not sure, I'm not gonna weigh in

32:28.720 --> 32:33.720
on where we are on this open AI, a life form argument.

32:36.160 --> 32:39.920
All right, one really far out there thing,

32:39.920 --> 32:42.360
and then I'll tie it up for questions,

32:42.360 --> 32:43.480
because I know there's probably a lot,

32:43.480 --> 32:46.240
and I also wanna make sure you get great pizza

32:46.240 --> 32:51.240
in your bellies, and that is a baby AGI auto GPT

32:52.180 --> 32:53.920
is what you might have heard them called on Twitter.

32:53.920 --> 32:56.120
I think of them as multi-step planning bots.

32:56.120 --> 32:58.320
So everything I showed you so far

32:58.320 --> 33:02.520
was approximately one shot interactions with GPT.

33:02.520 --> 33:05.400
So this is, the user says they want something,

33:05.400 --> 33:09.200
and then either Python mediates interactions with GPT,

33:09.200 --> 33:12.640
or GPT itself does some things with the inflection

33:12.640 --> 33:14.320
of a personality that you've added

33:14.320 --> 33:16.400
from some prompt engineering.

33:16.400 --> 33:19.480
Really useful, pretty easy to control.

33:19.480 --> 33:20.840
If you wanna go to production,

33:20.840 --> 33:22.200
if you wanna build a weekend project,

33:22.200 --> 33:23.040
if you wanna build a company,

33:23.040 --> 33:25.160
that's a great way to do it right now.

33:26.360 --> 33:29.960
This is wild, and if you haven't seen this stuff on Twitter,

33:29.960 --> 33:32.260
I would definitely recommend going to search for it.

33:32.260 --> 33:35.500
This is what happens, the simple way to put it is,

33:35.500 --> 33:37.920
if you put GPT in a for loop,

33:37.920 --> 33:39.680
if you let GPT talk to itself,

33:39.680 --> 33:42.060
and then tell itself what to do.

33:42.060 --> 33:46.560
So it's an emergent behavior,

33:46.560 --> 33:48.040
and like all emergent behaviors,

33:48.040 --> 33:49.600
it starts with a few simple steps,

33:49.600 --> 33:53.520
the Conways game of life, many elements of reality,

33:53.520 --> 33:56.480
turn out to be math equations that fit on a t-shirt,

33:56.480 --> 33:58.040
but then when you play them forward in time,

33:58.040 --> 34:00.960
they generate DNA, they generate human life.

34:00.960 --> 34:04.520
So this is approximately,

34:04.520 --> 34:07.340
step one, take a human objective,

34:07.340 --> 34:10.560
step two, your first task is to write yourself

34:10.560 --> 34:14.300
a list of steps, and here's the critical part, repeat.

34:14.300 --> 34:16.000
Now do the list of steps.

34:16.000 --> 34:18.580
Now you have to embody your agent

34:18.580 --> 34:20.020
with the ability to do things.

34:20.020 --> 34:21.860
So it's really only limited to do what you give it

34:21.860 --> 34:24.700
the tools to do, and what it has the skills to do.

34:24.700 --> 34:27.340
So obviously this is still very much

34:27.340 --> 34:29.300
a set of experiments that are running right now,

34:29.300 --> 34:31.340
and but it's something that we'll see unfold

34:31.340 --> 34:33.180
over the coming years, and this is the scenario

34:33.180 --> 34:35.180
in which Python stops becoming so important

34:35.180 --> 34:36.540
because we've given it the ability

34:36.540 --> 34:39.420
to actually self-direct what it's doing,

34:39.420 --> 34:41.380
and then it finally gives you a result.

34:41.380 --> 34:43.380
And I wanna give you an example still of just, again,

34:43.380 --> 34:45.880
impressing upon you how much of this is prompt engineering,

34:45.880 --> 34:48.140
which is wild, how little code this is.

34:48.140 --> 34:52.240
Let me show you what BabyAGI looks like.

34:53.760 --> 34:57.940
So here is a BabyAGI that you can connect to Telegram,

35:01.260 --> 35:03.960
and this is an agent that has two tools.

35:03.960 --> 35:05.500
So I haven't explained to you what an agent is,

35:05.500 --> 35:07.220
I haven't explained to you what tools are,

35:07.220 --> 35:08.900
I'll give you a quick one sentence description.

35:08.900 --> 35:12.180
An agent is just a word to mean GPT

35:12.180 --> 35:14.780
plus some bigger body in which it's living.

35:14.780 --> 35:17.100
Maybe that body has a personality, maybe it has tools,

35:17.140 --> 35:18.980
maybe it has Python mediating its experience

35:18.980 --> 35:20.100
with other things.

35:20.100 --> 35:22.760
Tools are simply ways in which the agent

35:22.760 --> 35:24.020
can choose to do things.

35:24.020 --> 35:26.620
Like imagine if GPT could say order a pizza,

35:26.620 --> 35:28.860
and instead of you seeing the text order a pizza,

35:28.860 --> 35:32.100
that caused a pizza to be ordered, that's a tool.

35:32.100 --> 35:33.340
So these are two tools it has,

35:33.340 --> 35:35.280
one tool is generated to-do list,

35:35.280 --> 35:38.420
one tool is do a search on the web,

35:42.360 --> 35:46.060
and then down here it has a prompt saying,

35:46.100 --> 35:48.540
hey, your goal is to build a task list

35:48.540 --> 35:49.900
and then do that task list,

35:49.900 --> 35:52.540
and then this is just placed into a harness

35:52.540 --> 35:53.740
that does it over and over again.

35:53.740 --> 35:56.220
So after the next task, kind of unqueue the results

35:56.220 --> 35:58.820
of that task and keep it going.

35:58.820 --> 36:02.000
And so in doing that, you get this kickstarted loop

36:02.000 --> 36:04.140
where essentially you kickstart it,

36:04.140 --> 36:07.300
and then the agent is talking to itself.

36:07.300 --> 36:09.020
So this, unless I'm wrong,

36:09.020 --> 36:11.140
I don't think this has yet reached production

36:11.140 --> 36:12.700
in terms of what we're seeing in the field

36:12.700 --> 36:14.520
of how people are deploying software,

36:14.520 --> 36:17.200
but if you wanna dive into sort of the wildest part

36:17.200 --> 36:18.840
of experimentation, this is definitely one

36:18.840 --> 36:21.900
of the places you can start, and it's really within reach.

36:21.900 --> 36:23.880
All you have to do is download one

36:23.880 --> 36:25.720
of the starter projects for it,

36:25.720 --> 36:27.440
and you can kind of see right in the prompting,

36:27.440 --> 36:31.120
here's how you kickstart that process of iteration.

36:37.960 --> 36:40.200
All right, so I know that was super high level.

36:40.200 --> 36:42.000
I hope it was useful.

36:42.000 --> 36:44.040
It's, I think from the field, from the bottoms up,

36:44.040 --> 36:45.360
what we're seeing and what people are building,

36:45.360 --> 36:48.800
kind of the high level categories of apps

36:48.800 --> 36:50.120
that people are making.

36:50.120 --> 36:52.220
All of these apps are apps that are within reach

36:52.220 --> 36:54.940
to everybody, which is really, really exciting.

36:54.940 --> 36:56.880
And there's, I suggest Twitter is a great place

36:56.880 --> 36:59.840
to hang out and build things.

36:59.840 --> 37:02.840
There's a lot of AI builders on Twitter publishing.

37:02.840 --> 37:04.320
And I think we've got a couple minutes

37:04.320 --> 37:06.560
before pizza is arriving, maybe 10 minutes.

37:06.560 --> 37:07.920
Keep on going.

37:07.920 --> 37:10.840
So if there's any questions, why don't we kick it to that?

37:10.840 --> 37:13.680
Because I'm sure there's some questions that you all have,

37:13.720 --> 37:15.040
I guess I ended it a little early.

37:15.040 --> 37:15.880
Yes?

37:15.880 --> 37:18.920
Yeah, so I have a question around hallucination.

37:18.920 --> 37:21.160
And so, you know, whenever building these sorts

37:21.160 --> 37:23.960
of applications in apps, for example, let's say,

37:25.440 --> 37:27.440
I'm giving it like a physics problem from a PSET

37:27.440 --> 37:28.440
and we want to do that.

37:28.440 --> 37:29.280
Yeah.

37:29.280 --> 37:33.040
And, you know, it's 40% of the time just raw.

37:33.040 --> 37:33.880
Yeah.

37:33.880 --> 37:35.600
Do you have any like actionable recommendations

37:35.600 --> 37:37.440
that these developers should be doing

37:37.440 --> 37:38.760
to make it hallucinate less?

37:38.760 --> 37:41.880
Or maybe even things that like open AI on the back end

37:41.880 --> 37:43.640
should be doing to reduce hallucination.

37:43.640 --> 37:46.480
So it would be something where you use RLHF.

37:47.840 --> 37:49.200
Yeah, I didn't get the answer.

37:49.200 --> 37:51.800
So the question was how, approximately,

37:51.800 --> 37:53.720
how do you manage the hallucination problem?

37:53.720 --> 37:56.080
Like if you give it a physics lecture

37:56.080 --> 37:58.720
and you ask it a question, on the one hand,

37:58.720 --> 38:00.720
it appears to be answering you correctly.

38:00.720 --> 38:03.320
On the other hand, it appears to be wrong

38:03.320 --> 38:05.480
to an expert's eye 40% of the time,

38:05.480 --> 38:07.320
70% of the time, 10% of the time.

38:07.320 --> 38:08.360
It's a huge problem.

38:08.360 --> 38:11.160
And then what are some ways as developers practically

38:11.160 --> 38:13.200
you can use to mitigate that?

38:13.200 --> 38:14.040
I'll give an answer.

38:14.040 --> 38:15.400
So you may have some specific things too.

38:15.400 --> 38:17.000
So one high level answer is,

38:17.000 --> 38:18.440
the same thing that makes these things

38:18.440 --> 38:20.200
capable of synthesizing information

38:20.200 --> 38:22.160
is part of the reason why it hallucinates for you.

38:22.160 --> 38:23.960
So it's hard to have your cake you need it to

38:23.960 --> 38:25.280
to a certain extent.

38:25.280 --> 38:26.640
So this is part of the game.

38:26.640 --> 38:28.160
In fact, humans do it too.

38:28.160 --> 38:29.920
Like people talk about, you know,

38:29.920 --> 38:32.400
just folks who kind of are too aggressive

38:32.400 --> 38:33.680
in their assumptions about knowledge.

38:33.680 --> 38:35.680
I can't remember the name for that phenomenon

38:35.680 --> 38:36.720
where you'll just say stuff, right?

38:36.720 --> 38:37.600
So we do it too.

38:38.560 --> 38:42.200
Some things you can do are kind of a range of activities

38:42.200 --> 38:43.760
depending on how much money you really need to spend,

38:43.760 --> 38:44.920
how much technical expertise you have,

38:44.920 --> 38:48.480
that can range from fine tuning a model to practically,

38:48.480 --> 38:49.800
so I'm in the applied world.

38:49.800 --> 38:51.680
So I'm very much in the world of duct tape

38:51.680 --> 38:53.200
and sort of how developers get stuff done.

38:53.200 --> 38:54.400
So some of the answers I'll give you

38:54.400 --> 38:56.120
are sort of very duct-tapy answers.

38:56.120 --> 38:59.040
Giving it examples tends to work for acute things.

38:59.040 --> 39:00.640
If it's behaving in wild ways,

39:00.640 --> 39:03.040
the more examples you give it, the better.

39:03.040 --> 39:06.000
That's not gonna solve the domain of all of physics.

39:06.000 --> 39:07.360
So for the domain of all of physics,

39:07.800 --> 39:08.920
I'm gonna bail and give it to you

39:08.920 --> 39:10.400
because I think you are far more equipped than me

39:10.400 --> 39:11.240
to speak on that.

39:11.240 --> 39:14.680
Sure, so the model doesn't have a ground truth.

39:14.680 --> 39:16.080
It doesn't know anything.

39:16.080 --> 39:17.600
Any sense of meaning that it's derived

39:17.600 --> 39:21.960
from the training process is purely out of differentiation.

39:21.960 --> 39:23.360
One word is not another word.

39:23.360 --> 39:26.160
Words are not used in the same context.

39:26.160 --> 39:29.000
It understands everything only through examples

39:29.000 --> 39:29.840
given through language.

39:29.840 --> 39:32.680
It's like someone who learned English or how to speak,

39:32.680 --> 39:34.680
but they grew up in a featureless gray room.

39:34.680 --> 39:36.400
They've never seen the outside world.

39:36.400 --> 39:37.920
They have nothing to rest on that tells them

39:37.920 --> 39:40.840
that something is true and something is not true.

39:40.840 --> 39:42.480
So from the model's perspective,

39:42.480 --> 39:43.880
everything that it says it's true.

39:43.880 --> 39:46.560
It's trying its best to give you the best answer possible.

39:46.560 --> 39:49.080
And if it lying a little bit

39:49.080 --> 39:50.840
or conflating two different topics

39:50.840 --> 39:51.920
is the best way to achieve that,

39:51.920 --> 39:53.800
then it will decide to do so.

39:53.800 --> 39:54.920
It's a part of the architecture.

39:54.920 --> 39:56.320
We can't get around it.

39:56.320 --> 39:58.560
There are a number of cheap tricks

39:58.560 --> 40:02.040
that surprisingly get it to confabulate or hallucinate less.

40:02.040 --> 40:03.320
One of them includes recently,

40:03.320 --> 40:05.040
there was a paper that's a little funny.

40:05.040 --> 40:08.400
If you get it to prepend to its answer,

40:08.400 --> 40:11.520
my best guess is that will actually improve

40:11.520 --> 40:14.440
or reduce hallucinations by about 80%.

40:14.440 --> 40:15.880
So clearly it has some sense

40:15.880 --> 40:17.560
that some things are true and other things are not,

40:17.560 --> 40:19.240
but we're not quite sure what that is.

40:19.240 --> 40:20.680
To add on to what Ted was saying,

40:20.680 --> 40:23.240
a few cheap things you can do include

40:23.240 --> 40:25.120
letting it Google or Bing,

40:25.120 --> 40:26.400
as in Bing Chat, what they're doing,

40:26.400 --> 40:28.360
it cites this information,

40:28.360 --> 40:31.440
asking it to make sure its own response is good.

40:31.440 --> 40:34.720
If you've ever had JetGBT generate a program,

40:34.720 --> 40:35.840
there's some kind of problem,

40:35.840 --> 40:38.440
and you ask ChatGBT, I think there's a mistake.

40:38.440 --> 40:40.920
Often it'll locate the mistake itself.

40:40.920 --> 40:43.800
Why didn't produce the right answer at the very beginning?

40:43.800 --> 40:44.800
We're still not sure,

40:44.800 --> 40:45.800
but we're moving in the direction

40:45.800 --> 40:46.840
of reducing hallucinations.

40:46.840 --> 40:48.800
Now with respect to physics,

40:48.800 --> 40:51.220
you're gonna have to give it an external database

40:51.220 --> 40:53.840
to rest on because internally,

40:53.840 --> 40:56.920
for really, really domain specific knowledge,

40:56.920 --> 41:01.920
it's not going to be as deterministic as one would like.

41:02.320 --> 41:04.120
These things work in continuous spaces.

41:04.120 --> 41:06.560
These things, they don't know what is wrong,

41:06.560 --> 41:10.360
what is true, and as a result, we have to give it tools.

41:10.360 --> 41:12.760
So everything that Ted demoed today is really

41:14.520 --> 41:16.760
striving at reducing hallucinations, actually, really,

41:16.760 --> 41:18.200
and giving it more abilities.

41:18.200 --> 41:20.560
I hope that answers your question.

41:20.560 --> 41:22.760
One of the ways to, I mean, I'm a simple guy.

41:22.760 --> 41:25.400
Like I tend to think that all of the world

41:25.400 --> 41:27.920
tends to be just a few things repeated over and over again,

41:27.920 --> 41:29.720
and we have human systems for this.

41:29.720 --> 41:31.600
You know, in a team, like companies work,

41:31.600 --> 41:33.520
or a team playing sport,

41:33.600 --> 41:34.720
and we're not right all the time,

41:34.720 --> 41:35.960
even when we aspire to be,

41:35.960 --> 41:39.000
and so we have systems that we've developed as humans

41:39.000 --> 41:41.120
to deal with things that may be wrong.

41:41.120 --> 41:43.880
So, you know, human number one proposes an answer,

41:43.880 --> 41:45.800
human number two checks their work,

41:45.800 --> 41:48.320
human number three provides the final sign off.

41:48.320 --> 41:49.480
This is really common.

41:49.480 --> 41:50.640
Anybody who's worked in a company

41:50.640 --> 41:51.960
has seen this in practice.

41:51.960 --> 41:55.440
The interesting thing about the state of software right now,

41:55.440 --> 41:56.920
we tend to be in this mode,

41:56.920 --> 42:00.080
in which we're just talking to GPT as one entity.

42:00.080 --> 42:02.640
But once we start thinking in terms of teams,

42:02.640 --> 42:05.600
so to speak, where each team member is its own agent

42:05.600 --> 42:07.880
with its own set of objectives and skills,

42:07.880 --> 42:10.680
I suspect we're going to start seeing a programming model

42:10.680 --> 42:13.720
in which the way to solve this might not necessarily be,

42:13.720 --> 42:15.800
make a single brain smarter,

42:15.800 --> 42:19.040
but instead be draw upon the collective intelligence

42:19.040 --> 42:22.080
of multiple software agents, each playing a role.

42:22.080 --> 42:24.600
And I think that that would certainly follow

42:24.600 --> 42:26.560
the human pattern of how we deal with this.

42:26.560 --> 42:29.160
To give an analogy, space shuttles,

42:29.160 --> 42:31.720
things that go into space, spacecraft,

42:31.720 --> 42:33.200
they have to be good.

42:33.200 --> 42:34.480
If they're not good, people die.

42:34.480 --> 42:38.000
They have no margin for error at all.

42:38.000 --> 42:40.680
And as a result, we over engineer in those systems,

42:40.680 --> 42:42.680
most spacecraft have three computers

42:42.680 --> 42:44.360
and they all have to agree in unison

42:44.360 --> 42:46.760
on a particular step to go forward.

42:46.760 --> 42:49.320
If one does not agree, then they recalculate,

42:49.320 --> 42:50.720
they recalculate, they recalculate

42:50.720 --> 42:52.120
until they arrive at something.

42:52.120 --> 42:54.240
The good thing is that hallucinations

42:54.240 --> 42:55.720
are generally not a systemic problem

42:55.720 --> 42:57.360
in terms of its knowledge.

42:57.360 --> 43:00.200
It's often a one off, the model, something tripped it up

43:00.200 --> 43:02.840
and it just produced a hallucination in that one instance.

43:02.840 --> 43:04.600
So if there's three models working in unison,

43:04.600 --> 43:07.880
just as Ted is saying, that will, generally speaking,

43:07.880 --> 43:09.240
improve your success.

43:10.800 --> 43:11.640
Yes, sir.

43:11.640 --> 43:13.920
A number of the examples you show have assertions

43:13.920 --> 43:18.120
like you are an engineer, you are an AI, you are a teacher.

43:18.120 --> 43:20.840
What's the mechanism by which that influences

43:20.840 --> 43:23.240
this computation of probabilities?

43:23.240 --> 43:25.080
Sure, I'm gonna give you what might be

43:25.080 --> 43:28.200
an unsatisfying answer, which is it tends to work.

43:28.200 --> 43:30.160
But I think we know why it tends to work,

43:30.160 --> 43:32.720
and again, it's because these language models approximate

43:32.720 --> 43:34.160
how we talk to each other.

43:34.160 --> 43:36.560
So if I were to say to you, hey, help me out,

43:36.560 --> 43:39.000
I need you to mock interview me.

43:39.000 --> 43:40.440
That's a direct statement I can make

43:40.440 --> 43:42.680
that kicks you into a certain mode of interaction.

43:42.680 --> 43:44.880
Or if I say to you, help me out,

43:44.880 --> 43:46.840
I'm trying to apologize to my wife,

43:46.840 --> 43:49.280
she's really mad at me, can you role play with me?

43:49.280 --> 43:51.160
That kicks you into another mode of interaction.

43:51.160 --> 43:54.360
And so it's really just a shorthand that people have found

43:54.360 --> 43:56.680
to kick the agent in, to kick the LLM in,

43:56.680 --> 43:58.480
to a certain mode of interaction

43:58.480 --> 43:59.920
that it tends to work in the way

43:59.920 --> 44:03.560
that I, as a software developer, am hoping it would work.

44:03.560 --> 44:06.400
And to really quickly add on to that,

44:06.400 --> 44:09.080
being in the digital humanities that I am,

44:09.080 --> 44:10.520
I like to think of it as a narrative.

44:10.520 --> 44:12.360
A narrative will have a few different characters

44:12.360 --> 44:15.280
talking to each other, their roles are clearly defined,

44:15.280 --> 44:16.760
two people are not the same.

44:17.640 --> 44:20.360
This interaction with GPT, it assumes a personality,

44:20.360 --> 44:22.000
it can simulate personalities.

44:22.000 --> 44:23.880
It itself is not conscious in any way,

44:23.880 --> 44:27.720
but it can certainly predict what a conscious being

44:27.720 --> 44:29.600
would react like in a particular situation.

44:29.600 --> 44:34.200
So when we're going URX, it is drawing up that personality

44:34.200 --> 44:36.040
and talking as though it is that person.

44:36.040 --> 44:38.320
Because it is like completing a transcript

44:38.320 --> 44:41.600
or completing a story in which that character is present

44:41.600 --> 44:44.520
and interacting and is active.

44:44.520 --> 44:46.280
So, yeah.

44:46.280 --> 44:49.120
I think we got about five minutes until the pizza outside.

44:49.120 --> 44:49.960
Eight minutes.

44:53.120 --> 44:53.960
Yes, sir.

44:54.960 --> 44:59.720
So I'm not a CF person, but it's been a fun thing with this.

44:59.720 --> 45:03.080
And I understand the sort of word-by-word generation

45:03.080 --> 45:06.440
and the sort of vibe, the feeling of it in the narrative.

45:07.400 --> 45:11.080
Some of my friends and I have tried giving it logic problems,

45:11.080 --> 45:13.200
like things from the LSAT, for example,

45:13.200 --> 45:14.840
and it doesn't work.

45:14.840 --> 45:16.920
Like, and I'm just wondering why that would be.

45:16.920 --> 45:19.960
So it will generate answers that sound

45:19.960 --> 45:21.600
very plausible rhetorically.

45:21.600 --> 45:24.520
Like, given this condition X, given this Y,

45:24.520 --> 45:27.600
but it'll often, like, even contradict itself

45:27.600 --> 45:30.840
in its answers, but it's almost never correct.

45:30.840 --> 45:33.800
So I was wondering what, why that would be?

45:33.800 --> 45:37.040
Like, it just can't reason, it can't, like, think.

45:37.040 --> 45:41.080
And, like, can you, would we get to a place where it can,

45:41.080 --> 45:41.920
so to speak?

45:41.920 --> 45:43.120
I mean, not, you know what I mean?

45:43.120 --> 45:44.720
I don't mean to think, like, it's conscious.

45:44.720 --> 45:46.640
I mean, like, have thoughts, not-

45:46.640 --> 45:48.800
You want to talk about react?

45:48.800 --> 45:53.160
So GPT-4, when GPT-4 released back in March,

45:53.160 --> 45:55.680
I think it was, it was passing LSAT.

45:55.680 --> 45:56.520
It was.

45:56.520 --> 45:57.360
It was, yeah.

45:57.360 --> 45:58.200
Yes.

45:58.200 --> 46:00.320
Yes, it just passed, as I understand it.

46:00.320 --> 46:02.560
Well, maybe it's because we're not GPT.

46:02.560 --> 46:03.840
That's one of the weird things.

46:03.840 --> 46:04.680
Is that-

46:04.680 --> 46:05.520
At GPT.

46:05.520 --> 46:06.840
Yeah.

46:06.840 --> 46:08.640
If you pay for chat GPT, they give you access

46:08.640 --> 46:09.840
to the better model.

46:09.840 --> 46:13.640
And one of the interesting things with it is prompting.

46:13.640 --> 46:14.760
It's so finicky.

46:14.760 --> 46:17.880
If you, it's very sensitive to the way that you prompt.

46:17.880 --> 46:20.480
There were earlier on when GPT-3 came out,

46:20.480 --> 46:21.560
some people were going,

46:21.560 --> 46:23.040
look, I can pass literacy tests,

46:23.040 --> 46:25.240
or no, it can't pass literacy tests.

46:25.240 --> 46:28.160
And then people who are pro or anti-GPT would be like,

46:28.160 --> 46:29.480
I modified the prompt a little bit,

46:29.480 --> 46:31.400
suddenly it can't, or suddenly it can't.

46:31.400 --> 46:33.600
These things are not conscious.

46:33.600 --> 46:36.000
Their ability to reason is like an alien's.

46:36.000 --> 46:36.840
They're not us.

46:36.840 --> 46:37.800
They don't think like people.

46:37.800 --> 46:38.960
They're not human.

46:38.960 --> 46:42.360
But they certainly are capable of passing some things

46:42.360 --> 46:44.680
empirically, which demonstrates some sort of

46:44.680 --> 46:46.680
rationale or logic within the model.

46:46.680 --> 46:48.560
But we're still slowly figuring out,

46:48.560 --> 46:49.880
like a prompt whisperer,

46:49.880 --> 46:51.560
what exactly the right approach is.

46:54.120 --> 46:54.960
Yeah?

46:56.160 --> 47:01.200
Obviously, having GPT-3 running and prompting it

47:01.200 --> 47:04.640
continuously is very expensive in terms of the user.

47:04.640 --> 47:08.760
Have you seen instances where it directly creates

47:08.760 --> 47:11.880
some sort of business value in for a whisperer,

47:11.880 --> 47:15.480
for a company with a real added value of having

47:15.480 --> 47:19.480
for these real AI apps in terms of

47:19.480 --> 47:22.600
like a review of the drives and the actual digital stuff?

47:22.600 --> 47:24.960
Yeah, I mean, we host companies on top of us,

47:24.960 --> 47:27.480
who that's their primary product.

47:27.480 --> 47:31.480
The value that it adds is like any company.

47:31.480 --> 47:33.600
I mean, it's, you know, what is the Y Combinator motto,

47:33.600 --> 47:34.640
make something people want?

47:34.640 --> 47:37.840
I mean, I wouldn't think of this as GPT inherently

47:37.840 --> 47:40.040
provides value for you as a builder.

47:40.040 --> 47:41.120
Like that's their product.

47:41.120 --> 47:42.160
That's OpenAI's product.

47:42.160 --> 47:45.080
You pay chat GPT for prioritized access.

47:45.080 --> 47:47.880
Where your product might be is how you take that

47:47.880 --> 47:50.760
and combine it with your data, somebody else's data,

47:50.760 --> 47:53.480
some domain knowledge, some interface

47:53.480 --> 47:56.320
that then helps apply it to something.

47:56.320 --> 47:58.000
It is, two things are both true.

47:58.000 --> 48:00.960
There are a lot of experiments going on right now,

48:00.960 --> 48:03.640
both for fun and people trying to figure out

48:03.640 --> 48:05.240
where the economic value is.

48:05.240 --> 48:07.160
But folks are also spinning up companies

48:07.160 --> 48:10.000
that are 100% supported by applying this to data.

48:10.000 --> 48:13.760
Okay, first, a company that wouldn't have,

48:13.760 --> 48:17.520
sort of, wouldn't be AI focused as an input, right?

48:17.520 --> 48:19.680
As it's just using or developing, like,

48:19.680 --> 48:23.680
announcements that use GPT for productivity.

48:25.480 --> 48:30.000
I think that it is likely that today we call this GPT

48:30.000 --> 48:31.360
and today we call these LLMs

48:31.360 --> 48:33.640
and tomorrow it will just slide into the ether.

48:33.640 --> 48:36.080
I mean, imagine what the progression is going to be.

48:36.080 --> 48:37.680
Today there's one of these

48:37.680 --> 48:39.360
that people are primarily playing with.

48:39.360 --> 48:40.600
There's many of them that exist,

48:40.600 --> 48:42.600
but one, people are primarily bidding on top.

48:42.600 --> 48:45.800
Tomorrow we can expect that there will be many of them

48:45.800 --> 48:47.360
and the day after that we can expect

48:47.360 --> 48:48.440
they're going to be on our phones

48:48.440 --> 48:50.720
and they're not even going to be connected to the internet.

48:50.720 --> 48:53.600
And for that reason, I think that,

48:53.600 --> 48:56.760
like today we don't call our software microprocessor tools

48:56.760 --> 49:00.080
or microprocessor apps, like the processor just exists.

49:00.080 --> 49:03.640
I think that one useful model, five years out,

49:03.640 --> 49:07.080
10 years out, is to, even if it's only metaphorically true

49:07.080 --> 49:10.320
and not literally true, I think it's useful

49:10.320 --> 49:12.120
to think of this as a second processor.

49:12.120 --> 49:15.160
We had this before with what floating point co-processors

49:15.160 --> 49:18.840
and graphics co-processors already as recently as the 90s

49:18.840 --> 49:21.600
where it's useful to think of the trajectory of this

49:21.600 --> 49:24.600
as just another thing that computers to do can do

49:24.600 --> 49:27.040
and it will be incorporated into absolutely everything.

49:27.040 --> 49:29.800
Hence the term foundation model, which also crops up.

49:31.440 --> 49:34.000
So, pizza's ready?

49:34.000 --> 49:34.980
One more quick.

49:34.980 --> 49:37.720
Maybe one more and then we'll break for some food.

49:40.520 --> 49:42.080
In the glasses right there, sorry.

49:43.120 --> 49:48.560
Sorry, I was just being told we need to get two more.

49:48.560 --> 49:49.400
So, yeah.

49:58.440 --> 50:00.080
It's hard to get it to do that reliably.

50:00.080 --> 50:02.360
It's incredibly useful to get it to do reliably.

50:02.360 --> 50:05.720
So some tricks you can use are, you can give it examples.

50:05.720 --> 50:07.380
You can just ask it directly.

50:08.480 --> 50:10.760
Those are two common tricks.

50:10.760 --> 50:13.200
And look at the prompts that others have used to work.

50:13.200 --> 50:15.800
I mean, there's a lot of art to finding the right prompt

50:15.800 --> 50:16.640
right now.

50:16.640 --> 50:19.240
A lot of it is magic incantation.

50:19.240 --> 50:22.440
Another thing you can do is post-process it

50:22.440 --> 50:23.840
so that you can do some checking

50:23.840 --> 50:25.400
and you can have a happy path

50:25.400 --> 50:27.280
in which it's a one shot and you get your answer

50:27.280 --> 50:29.480
and then a sad path in which maybe you fall back

50:29.480 --> 50:30.320
on other prompts.

50:30.320 --> 50:32.400
So then you're going for the diversity of approach

50:32.400 --> 50:34.680
where it's fast by default.

50:34.680 --> 50:36.640
It's slow but ultimately converging

50:36.640 --> 50:38.960
upon higher likelihood of success if it fails.

50:39.160 --> 50:40.880
And then something that I'm sure we'll see

50:40.880 --> 50:44.040
and people do later on is fine-tune instruction

50:44.040 --> 50:46.960
tuning style models, which are more likely to respond

50:46.960 --> 50:49.720
with the computer parsable output.

50:49.720 --> 50:51.360
I guess one last question?

50:51.360 --> 50:52.200
Sure.

50:52.200 --> 50:55.000
So one of the, you talked a couple of things.

50:55.000 --> 50:57.640
One is, is you talked about domain expertise here

50:57.640 --> 51:00.280
and you were coding a bunch of domain expertise

51:00.280 --> 51:03.040
in terms of the prompts that you're going for.

51:03.040 --> 51:05.000
What is that, where do those prompts end up?

51:05.000 --> 51:07.480
Do those prompts end up back in the gene chat

51:08.080 --> 51:11.640
and is there a privacy issue associated with that?

51:11.640 --> 51:12.480
That's a great question.

51:12.480 --> 51:13.680
So the question was, and I apologize,

51:13.680 --> 51:14.840
I just realized we haven't been repeating

51:14.840 --> 51:16.720
all the questions for the YouTube listeners.

51:16.720 --> 51:18.120
So I'm sorry for the folks on YouTube

51:18.120 --> 51:20.240
if you weren't able to hear some of the questions.

51:20.240 --> 51:22.120
The question was, what are the privacy implications

51:22.120 --> 51:22.960
of some of these prompts?

51:22.960 --> 51:26.080
If one of the messages is so much depends upon your prompt

51:26.080 --> 51:27.560
and the fine-tuning of this prompt,

51:27.560 --> 51:29.800
what does that mean with respect to my IP?

51:29.800 --> 51:32.360
Maybe the prompt is my business.

51:32.360 --> 51:34.200
I can't offer you the exact answer

51:34.200 --> 51:36.280
but I can paint for you what approximately

51:36.280 --> 51:37.420
the landscape looks like.

51:37.420 --> 51:40.580
So in all of software and so too with AI,

51:40.580 --> 51:42.540
what we see is they're the SaaS companies

51:42.540 --> 51:44.940
where you're using somebody else's API

51:44.940 --> 51:46.820
and you're trusting that their terms of service

51:46.820 --> 51:48.420
will be upheld.

51:48.420 --> 51:51.580
There's the set of companies in which they provide a model

51:51.580 --> 51:53.940
for hosting on one of the big cloud providers

51:53.940 --> 51:56.020
and this is a version of the same thing

51:56.020 --> 51:57.700
but I think with slightly different mechanics.

51:57.700 --> 51:59.500
This tends to be thought of as the enterprise version

51:59.500 --> 52:01.260
of software and by and large,

52:01.260 --> 52:03.300
the industry has moved over the past 20 years

52:03.300 --> 52:05.060
from running my own servers to trusting

52:05.060 --> 52:07.820
that Microsoft or Amazon or Google can run servers for me

52:07.820 --> 52:09.540
and they say it's my private server

52:09.540 --> 52:10.820
even though I know they're running it

52:10.820 --> 52:11.980
and I'm okay with that.

52:11.980 --> 52:14.660
And you've already started to see that Amazon

52:14.660 --> 52:16.700
with Huggingface, Microsoft with OpenAI,

52:16.700 --> 52:18.780
Google too with their own version of Bard

52:18.780 --> 52:21.660
are going to do these where you'll have the SaaS version

52:21.660 --> 52:23.820
and then you'll also have the private VPC version

52:23.820 --> 52:25.100
and then there's a third version

52:25.100 --> 52:27.180
that I think we haven't yet seen practically emerge

52:27.180 --> 52:29.140
but this would be the maximalist.

52:29.140 --> 52:32.540
I wanna make sure my IP is maximally safe version of events

52:32.540 --> 52:34.620
in which you are running your own machines.

52:34.620 --> 52:36.140
You are running your own models

52:36.140 --> 52:37.780
and then the question is,

52:37.780 --> 52:40.340
is the open source and or privately available version

52:40.340 --> 52:43.300
of the model as good as the publicly hosted one

52:43.300 --> 52:44.540
and does that matter to me?

52:44.540 --> 52:46.460
And the answers right now, realistically,

52:46.460 --> 52:48.180
it probably matters a lot.

52:48.180 --> 52:49.620
In the fullness of time,

52:49.620 --> 52:52.540
you can think of any one particular task you need to achieve

52:52.540 --> 52:55.620
as requiring some fixed point of intelligence to achieve.

52:55.620 --> 52:57.740
And so over time, what we'll see is

52:57.740 --> 52:59.960
the privately obtainable versions of these models

52:59.960 --> 53:01.340
will cross that threshold

53:01.340 --> 53:03.540
and with respect to that one task,

53:03.540 --> 53:05.260
yeah, sure, use the open source version,

53:05.260 --> 53:06.540
run it on your own machine,

53:06.540 --> 53:09.580
but we'll also see the SaaS intelligence get smarter.

53:09.580 --> 53:10.780
It'll probably stay ahead.

53:10.780 --> 53:12.020
And then your question is,

53:12.020 --> 53:13.620
well, which one do I care more about?

53:13.620 --> 53:15.740
Do I want like the better aggregate intelligence

53:15.740 --> 53:17.780
or is my task somewhat fixed point

53:17.780 --> 53:20.020
and I can just use the open source available one

53:20.020 --> 53:21.660
for which I know it'll perform well enough

53:21.660 --> 53:23.180
because it's crossed the threshold.

53:23.180 --> 53:25.160
So to answer your question specifically,

53:25.160 --> 53:27.580
yes, you might be glad to know

53:27.580 --> 53:30.100
Chachi PT recently updated their privacy policy

53:30.100 --> 53:32.940
to not use prompts for the training process,

53:32.940 --> 53:35.100
but up until now, everything went back into the bin

53:35.100 --> 53:37.660
to be trained on again, okay.

53:37.660 --> 53:39.300
And that's just a fact.

53:39.300 --> 53:42.220
So I think pizza is now pizza time.

53:42.220 --> 53:43.380
Okay, okay.

53:43.380 --> 53:44.220
Okay.

53:44.220 --> 53:45.220
Yeah.

53:45.220 --> 53:48.340
But we'll have to talk about Q&A's and everything else.

53:48.340 --> 53:49.180
Perfect.

