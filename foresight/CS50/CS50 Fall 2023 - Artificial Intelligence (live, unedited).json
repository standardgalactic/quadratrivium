{"text": " Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n g gweithio, mae'n gweithio, mae'n gweithio. Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Y Llywodraeth Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio, mae'n gweithio. Felly, mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. Mae'n gweithio. a brwd nu yn ymwneud, a gallwn sandwyd fel ei plac i'n gwyld iawn hwnnw, neu yn y ddweud y ddaw fyddi, ond iawn uchddianiaeth. A hyngornau pa gydajiadau poddyn nhw, fe oedd dat\u30bawn i mewn \ub4e4thysgwydau, ond yw'r gabbwn wedi tyw'r hyn fel hyn. Roedd eich bod yn byth storiedd Ni, gallwn gweffordd Llan\u021biol, yn annoto argyn adeg y dyn nhw, jydw i chi'n gweld dau ei Vaugh Cymru pan wedi'i mewn ddwy \u0447\u0443\u0432\u0441\u0442\u0432io'r uradora a chi ei i wneud nhw, contractorio dod yn besyaig unig.... Yn ran gran stan o armwyhan gael y cyfre Ac i am Ym mhwyl un menos wedi radi. \uc598\ufffd yn reduction, ar\u8fbe, ac yn twrishna oedd\u2014 Foc lwy, rhaid i ni ddech durum sy'n gwneud hyn wediair? F \u05d7os mae'n ym mwyng ym hefyd aran, lly, gan lly, ein le incorrectolaeth ac mae geniat yn gyflwyfonol. Wrth byd storaheg ychydig hyn yn tw rhagol. Dw i roedd y cyflwybarth sydd pobl yn ysgrif, additive knowyne. Y\u30e3, fan eich rhaid iddo i chi'n wneud? ac rongsydd. Should we flip back? The answer is actually a trick question. Sydd sydd ydych yn rhaglenau. Most of you were in fact right. But if you take a glance at this, this is getting really, really good. This is just a taste of the images that we might see down the line. In fact, that video with which we began, Tom Cruise, as you might have gleaned, was not in fact Tom Cruise. That was an example of a deep fake. y pwysig yn cynllunio ni awdd dependydd yr animal ar dd pawn hych Cymru i wneud o ddeallurio ysgol yn ymwinell, iddyn nhw senseid gyntaf, acredwch chi'n ymdd\u6837di mats, ac ymatebai hawdd a gw Spin chefiau ar gyfer y cympael tyfan, C' webcam cyf Suzuki yn go iawn gyfo'r ffonduddau. Mae'n cyfattifiwch ar gyfyrdd glansian iawn sou \u0430\u0440 fyrdd gan gyfodd yn teitl a'r cyffredin siarad hen yn bod \u0440\u0430\u0441wylol ein scrydd. A o ran dod dyn ni'n mynd i, wr hefyd yr un oed fel oedd hyn sy'n mynd hun yma dy Grant-G\u8dd1. Gbi ddangosubbyd ddod ei bod pob dw'i s\ufffd\ufffd o \u0444 pas ac rwy'r psychologist e'n mynd i glawethe ledd yn credu drwy wideg a threatensie gyda history. Felly mae'i dde'i arferwad iddyn ni'n gemddol advertisements neu tradd\u043d\u0434au summar. beth ddechrau hyn \u00e8l aen ni f\u591cnwyr gallwch chi wedi derbyn rhwun arna Diolch i dda'r rywun ynhlulu. Panyluk \u2026 associate Si haf pa tro dda pa sy'n fawr, y cymdeilydd hearr. Mae mae'r sgiliau hynny, darn byn heb. Dyna, a'igusach, I pan c Intelligence leader C rond zatblade cych studio. As we eat, we chat and laugh and catch up on each other's day, dot, dot, dot. SA2. My mother packs me a sandwich, a drink, fruit, and a treat. When I get in the lunchroom, I find an empty table and sit there and I eat my lunch. My friends come and sit down with me, dot, dot, dot. Runkshin, should we see what folks think? It looks like most of you think that SA1 was generated by AI. And in fact, if we flip back to the answer here, it was in fact SA1. So it's great that we now already have seemingly this discerning eye, but let me perhaps deflate that enthusiasm by saying it's only going to get harder to discern one from the other. And we're really now on the bleeding edge of what's soon to be possible. But most everyone in this room has probably by now seen, tried, certainly heard of ChatGPT, which is all about textual generation. Within CS50 and within academia more generally, have we been thinking about, talking about, how, whether to use or not use these kinds of technologies. And if the students in the room haven't told the family members in the room already, this here is an excerpt from CS50's own syllabus this year, whereby we have deemed tools like ChatGPT in their current form just too helpful. Sort of like an overzealous friend who, in school, just wants to give you all of the answers instead of leading you to them. And so we simply prohibit by policy using AI-based software such as ChatGPT, third-party tools like GitHub Co-Pilot, Bing Chat, and others, that suggests or completes answers to questions or lines of code. But it would seem reactionary to take away what technology surely has some potential upsides for education. And so within CS50 this semester, as well as this past summer, have we allowed students to use CS50's own AI-based software, which are in effect, as we'll discuss, built on top of these third-party tools, ChatGPT from open AI, companies like Microsoft and beyond. And in fact, what students can now use is this brought-to-life CS50 duck, or DDB, duck debugger within a website of our own, CS50.ai, and another that your students know known as CS50.dev. So students are using it, but in a way where we have tempered the enthusiasm of what might otherwise be an overly helpful duck to model it more akin to a good teacher, a good teaching fellow who might guide you to the answers, but not simply hand them outright. So what does that actually mean? And in what form does this duck come? Well, architecturally, for those of you with engineering backgrounds, they might be curious as to how this is actually implemented. If a student here in the class has a question virtually in this case, they somehow ask these questions of this central web application, CS50.ai. But we, in turn, have built much of our own logic on top of third-party services known as APIs, application programming interfaces, features that other companies provide that people like us can use so as they are doing really a lot of the heavy lifting. The so-called large language models are there. But we, too, have information that is not in these models yet. For instance, the words that came out of my mouth just last week when we had a lecture on some other topic, not to mention all of the past lectures and homework assignments from this year. So we have our own vector database locally via which we can search for more recent information and then hand some of that information into these models, which you might recall, at least for open AI, is cut off as of 2021, as of now, to make the information even more current. So architecturally, that's sort of the flow. But for now, I thought I'd share at a higher level what it is your students are already familiar with and what will soon be more broadly available to our own students online as well. So what we've focused on is what's generally now known as prompt engineering, which isn't really a technical phrase because it's not so much engineering in the traditional sense. It really is just English, what we are largely doing when it comes to giving the AI the personality of a good teacher or a good duck. So what we're doing is giving it what's known as a system prompt nowadays, whereby we write some English sentences, send those English sentences to open AI or Microsoft that sort of teaches it how to behave, not just using its own knowledge out of the box, but coercing it to behave a little more educationally constructively. And so, for instance, a representative snippet of English that we provide to these services looks a little something like this, quote unquote. You are a friendly and supportive teaching assistant for CS50. You are also a rubber duck. You answer student questions only about CS50 in the field of computer science. Do not answer questions about unrelated topics. Do not provide full answers to problem sets as this would violate academic honesty. And so, in essence, and you can sort of do this manually with ChatGPT, you can tell it or ask it how to behave. We essentially are doing this automatically so that it doesn't just hand answers out of the box and knows a little something more about us. There's also in this world of AI right now the notion of a user prompt, versus that system prompt. And the user prompt, in our case, is essentially the student's own question. I have a question about X, or I have a problem with my code here in Y. So we pass to those same API students' own questions as part of this so-called user prompt, just so you're familiar now with some of the vernacular of late. Now, the programming environment that students have been using this whole year is known as Visual Studio Code, a popular open source free product that so many engineers around the world now use. But we've instrumented it to be a little more course specific, with some course specific features that make learning within this environment all the easier. It lives at cs50.dev. And as students in this room know that, as of now, the virtual duck lives within this environment and can do things like explain highlighted lines of code. So here, for instance, is a screenshot of this programming environment. Here is some arcane looking code in a language called C that we've just left behind us in the class. And suppose that you don't understand what one or more of these lines of code do, students can now highlight those lines, right click or control click on it, select explain highlighted code, and voila, they see a chat GPT-like explanation of that very code within a second or so that no human has typed out but that's been dynamically generated based on this code. Other things that the duck can now do for students is advise students on how to improve their code's style, the aesthetics, the formatting thereof. And so, for instance, here is similar code in a language called C and I'll stipulate that it's very messy. Everything is left aligned instead of nicely indented so it looks a little more structured. Students can now click a button. They'll see at the right hand side in green how their code should ideally look and if they're not quite sure what those changes are or why, they can click on explain changes. And similarly, the duck advises them on how and why to turn their not great code into greater code from left to right respectively. More compellingly and more generalizable beyond CS50 and beyond computer science is AI's ability to answer most of the questions that students might now ask online. And we've been doing asynchronous Q&A for years via various mobile or web applications and the like, but to date it has been humans, myself included responding to all of those questions. Now the duck has an opportunity to chime in generally within three seconds because we've integrated into an online Q&A tool that students in CS50 and elsewhere across Harvard have long used. So here's an anonymized screenshot of a question from an actual student but written here as John Harvard who asked this summer in the summer version of CS50, what is flask exactly? So fairly definitional question and here is what the duck spit out thanks to that architecture I described before. I'll stipulate that this is correct, but it is mostly a definition akin to what Google or Bing could already give you last year, but here's a more nuanced question for instance from another anonymized students. In this question here the students including an error message that they're seeing, they're asking about that and they're asking a little more broadly and qualitatively is there a more efficient way to write this code? A question that really is best answered based on experience. Here I'll stipulate that the duck responded with this answer which is actually pretty darn good, not only responding in English but with some sample starter code that would make sense in this context and at the bottom it's worth noting because none of this technology is perfect just yet, it's still indeed very bleeding edge and so what we have chosen to do within CS50 is include disclaimers like this. I am an experimental bot, quack. Do not assume that my reply is accurate unless you see that it's been endorsed by humans staff, quack. And in fact at top right the mechanism we've been using in this tool is usually within minutes a human whether it's a teaching fellow, course assistant or myself, we'll click on a button like this to signal to our human students that yes, like the duck is spot on here or we have an opportunity as always to chime in with our own responses. Frankly that disclaimer, that button will soon I do think go away as the software gets better and better, but for now that's how we're modulating exactly what students' expectations might be when it comes to correctness or incorrectness. It's common to in programming to see a lot of error messages certainly when you're learning first hand. A lot of these error messages are cane, confusing certainly to students versus the people who wrote them. We'll see a box like this whenever one of their terminal window programs airs, they'll be assisted to with English like TF like support when it comes to explaining what it is that went wrong with that command. And ultimately what this is really doing for students in our own experience already is providing them really with virtual office hours and 24 seven, which is actually quite compelling in a university environment where students schedules are already tightly packed, be it with academics, the curriculars, athletics and the like, and they might have enough time to dive into a homework assignment, maybe eight hours even for something sizable, but if they hit that wall a couple of hours in, yeah, they can go to office hours or they can ask a question asynchronously online, but it's really not optimal in the moment support that we can now provide all the more effectively we hope through software as well. So if you're curious, even if you're not a technophile yourself, anyone on the internet can go to cs50.ai and experiment with this user interface. This one here actually resembles chat GPT itself, but it's specific to cs50. And here again is just a sequence of screenshots that I'll stipulate for today's purposes are pretty darn good and akin to what I myself or a teaching fellow would reply to and answer to a student's question in this case about their particular code. And ultimately it's really aspirational. The goal here ultimately is to really approximate a one to one teacher to student ratio, which despite all of the resources we within cs50, we within Harvard and places like Yale have, we certainly have never had enough resources to approximate what might really be ideal, which is more of an apprenticeship model, a mentorship whereby it's just you and that teacher working one on one. Now we still have humans and the goal is not to reduce that human support, but to focus it all the more consciously on the students who would benefit most from some impersonal one-on-one support versus students who would happily take it at any hour of the day more digitally via online. And in fact, we're still in the process of evaluating just how well or not well all of this works, but based on our summer experiment alone with about 70 students a few months back, one student wrote us at term's end, it felt like having a personal tutor. I love how AI bots will answer questions without ego and without judgment, generally entertaining even the stupidest of questions without treating them like they're stupid. It has an, as one could expect, ironically, an inhuman level of patience. And so I thought that's telling as to how even one student is perceiving these new possibilities. So let's consider now more academically what it is that's enabling those kinds of tools, not just within CS50, within computer science, but really the world more generally. What the whole world's been talking about is generative artificial intelligence, AI that can generate images, generate text and sort of mimic the behavior of what we think of as human. So what does that really mean? Well, let's start really at the beginning. Artificial intelligence is actually a technique, a technology, a subject that's actually been with us for some time, but it really was the introduction of this very user-friendly interface known as chatGPT and some of the more recent academic work over really just the past five or six years that really allowed us to take a massive leap forward, it would seem technologically, as to what these things can now do. So what is artificial intelligence? It's been with us for some time and it's honestly so omnipresent that we sort of take it for granted nowadays. Gmail outlook have gotten really good at spam detection. If you haven't checked your spam folder in a while, that's testament to just how good they seem to be at getting it out of your inbox. Handwriting recognition has been with us for some time. I daresay it too is only getting better and better the more the software is able to adapt to different handwriting styles such as this. Recommendation histories and the like, whether using Netflix or any other service, have gotten better and better at recommending things you might like based on things you have liked and maybe based on things other people who like the same thing as you might have liked. And suffice it to say, there's no one at Netflix, akin to the old like VHS stores of yesteryear, who are recommending to you specifically what movie you might like and there's no code, no algorithm that says if they like X, then recommend Y. Elts recommend Z because there's just too many movies, too many people, too many different tastes in the world. So AI is increasingly sort of looking for patterns that might not even be obvious to us humans and dynamically figuring out what might be good for me, for you, or you, or anyone else. Siri, Google Assistant, Alexa, any of these voice recognition tools that are answering questions that too suffice it to say is all powered by AI. But let's start with something a little simpler than any of those applications and this is one of the first arcade games from yesteryear known as Pong and it's sort of like table tennis and person on the left can move their paddle up and down. Personal on the right can do the same and the goal is to get the ball past the other person. Or conversely, make sure it hits your paddle and bounces back. Well, somewhat simpler than this and so far as it can be one player is another Atari game from yesteryear known as Breakout whereby you're essentially just trying to bang the ball against the bricks to get more and more points and get rid of all of those bricks. But all of us in this room probably have a human instinct for how to win this game or at least how to play this game. For instance, if the ball pictured here back in the 80s as a single red dot just left the paddle pictured here is a red line, where is the ball presumably going to go next? And in turn, which direction should I slide my paddle to the left or to the right? So presumably to the left and we all have an eye for what seem to be the digital physics of that and indeed that would then be an algorithm sort of step by step instructions for solving some problem. So how can we now translate that human intuition to what we describe more as artificial intelligence not nearly as sophisticated as those other applications, but will indeed start with some basics? You might know from economics or strategic thinking or computer science this idea of a decision tree that allows you to decide should I go this way or this way when it comes to making a decision. So let's consider how we could draw a picture to represent even something simplistic like Breakout. Well, if the ball is left of the paddle is a question or a boolean expression I might ask myself in code. If yes, then I should move my paddle left as most everyone just said. Else, if the ball is not left of paddle, what do I want to do? Well, I want to ask a question. I don't want to just instinctively go right. I want to check is the ball to the right of the paddle. And if yes, well then yes, go ahead and move the paddle right. But there is a third situation which is right. Like don't move. It's coming right at you. So that would be the third scenario here. No, it's not to the right or to the left. So just don't move the paddle. You got lucky and it's coming, for instance, straight down. So Breakout is fairly straightforward when it comes to an algorithm. And we can actually translate this as any CS50 student now could to code or pseudocode, sort of English like code that's independent of Java, C, C++, and all of the programming languages of today. So in English, pseudocode, while a game is ongoing, if the ball is left of paddle, I should move paddle left. Else, if ball is right of the paddle, I should say paddle, that's a bug, not intended today, move paddle right. Else, don't move the paddle. So that too represents a translation of this intuition to code that's very deterministic. You can sort of anticipate all possible scenarios, capture it in code. And frankly, this should be the most boring game of Breakout because the paddle should just perfectly play this game assuming there's no variables or randomness when it comes to speed or angles or the like, which real world games certainly try to introduce. But let's consider another game from yesteryear that you might play with your kids today or you did yourself growing up. Here's Tic Tac Toe. And for those unfamiliar, the goal is to get three O's in a row or three X's in a row, vertically, horizontally, or diagonally. So suppose it's now X's turn. If you've played Tic Tac Toe, most of you probably just have an immediate instinct as to where X should probably go so that it doesn't lose instantaneously. But let's consider, in the more general case, how do you solve Tic Tac Toe? Frankly, if you're in the habit of losing Tic Tac Toe, but you're not trying to lose Tic Toe, you're actually playing it wrong. Like you should minimally be able to always force a tie in Tic Tac Toe, and better yet, you should be able to beat the other person. So hopefully, everyone now will soon walk away with this strategy. So how can we borrow inspiration from those same decision trees and do something similar here? So if you, the player, ask yourself, can I get three in a row on this turn? Well, if yes, then you should do that and play the X in that position. Play in the square to get three in a row. Straight forward. If you can't get three in a row in this turn, you should ask another question. Can my opponent get three in a row in their next turn? Because then you better preempt that by moving into that position. Play in the square to block opponent three's three in a row. What if, though, that's not the case? What if there aren't even that many X's and O's on the board? If you're in the habit of just kind of playing randomly, like your mate might not be playing optimally as a good AI could. So if no, it's kind of a question mark. In fact, there's probably more to this tree because we could think through, what if I go there? Wait a minute, what if I go there or there or there? You can start to think a few steps ahead as a computer could do much better even than us humans. So suppose, for instance, it's O's turn. Now, those of you who are very good at Tecto might have an instinct for where to go, but this is an even harder problem, it would seem. I could go in eight possible places if I'm O, but let's try to break that down more algorithmically as an AI would. And let's recognize, too, that with games in particular, one of the reasons that AI was so early adopted in these games, playing the CPU, is that games really lend themselves to defining them if taking the fun out of it mathematically, defining them in terms of inputs and outputs, maybe paddle moving left or right, ball moving up or down. You can really quantize it at a very boring low level, but that lends itself then to solving it optimally. And in fact, with most games, the goal is to maximize or maybe minimize some math function. Most games, if you have scores, the goal is to maximize your score and indeed get a high score. So games lend themselves to a nice translation to mathematics and in turn hear AI solutions. So one of the first algorithms one might learn in the class on algorithms and on artificial intelligence is something called Minimax, which alludes to this idea of trying to minimize and or maximize something as your function, your goal. And it actually derives inspiration from these same decision trees that we've been talking about. But first, a definition. Here are three representative Tic Tac Toe boards. Here is one in which O has clearly won per the green. Here is one in which X has clearly won per the green. And this one in the middle just represents a draw. Now, there's a bunch of other ways that Tic Tac Toe could end, but here's just three representative ones. But let's make Tic Tac Toe even more boring than it might have always struck you as. Let's propose that this kind of configuration should have a score of negative one. If O wins, it's a negative one. If X wins, it's a positive one. And if no one wins, we'll call it a zero. We need some way of talking about and reasoning about which of these outcomes is better than the other and what's simpler than zero, one, and negative one. So the goal, though, of X, it would seem, is to maximize its score. But the goal of O is to minimize its score. So X is really trying to get positive one. O is really trying to get negative one. And no one really wants zero, but that's better than losing to the other person. So we have now a way to define what it means to win or lose. Well, now we can employ a strategy here. Here, just as a quick check, what would the score be of this board? Just so everyone's on the same page? Or so one, because X has won and we just stipulated arbitrarily, this means that this board has a value of one. Now let's put it into one more interesting context. Here, a game has been played for a few moves already. There's two spots left. No one has won just yet. And suppose that it's O's turn now. Now everyone probably has an instinct already as to where to go, but let's try to break this down more algorithmically. So what is the value of this board? Well, we don't know yet because no one has won. So let's consider what could happen next. So we can draw this actually as a tree as before. Here, for instance, is what might happen if O goes into the top left-hand corner. And here's what might happen if O goes into the bottom middle spot instead. We should ask ourselves, what's the value of this board? What's the value of this board? Because if O's purpose in life is to minimize its score, it's going to go left or right based on whichever yields the smallest number, negative one, ideally. But we're still not sure yet because we don't have definitions for boards with holes in them like this. So what could happen next here? Well, it's obviously going to be X's turn next. So if X moves, unfortunately, X has won in this configuration. We can now conclude that the value of this board is what number? So one, and because there's only one way to reach this board by transitivity, you might as well think of the value of this previous board as also one, because no matter what, it's going to lead to that same outcome. And so the value of this board is actually still to be determined because we don't know if O's going to want to go with the one, and probably not because that means X wins. But let's see what the value of this board is. Well, suppose that indeed X goes in that top left corner here. What's the value of this board here? Zero because no one has won. There's no X's or O's three in a row. So the value of this board is zero. There's only one way logically to get there. So we might as well think of the value of this board as also zero. And so now what's the value of this board? Well, if we started the story by thinking about O's turn, O's purpose is the min in minimax, then which move is O going to make? Go to the left or go to the right? O's probably going to go to the right and make the move that leads to this board because even though O can't win in this configuration, at least X didn't win. So it's minimized its score relatively, even though it's not a clean win. Now, this is all fine and good for a configuration of the board that's almost done. There's only two moves left. The game's about to end. But if you kind of expand in your mind's eye, how did we get to this branch of the decision tree? If we rewind one step where there's three possible moves, frankly, the decision tree is a lot bigger. If we run further in your mind's eye and have four moves left or five moves or all nine moves left, imagine just zooming out, out, and out. This is becoming a massive, massive tree of decisions. Now, even so, here is that same sub tree, the same decision tree we just looked at. This is the exact same thing, but I shrunk the font so that it appears here on the screen here. But over here, we have what could happen if instead, it's actually X's turn because we're once moved prior, there's a bunch of different moves X could now make too. So what is the implication of this? Well, most humans are not thinking through tic-tac-toe to this extreme. And frankly, most of us probably just don't have the mental capacity to think about, like, going left and then right and then left and then right. This is not how people play tic-tac-toe. Like, we're not using that much memory, so to speak. But a computer can handle that. And computers can play tic-tac-toe optimally. So if you're beating a computer at tic-tac-toe, like, it's not implemented very well. It's not following this very logical deterministic minimax algorithm. But this is where now AI is no longer as simple as just doing what these decision trees say. In the context of tic-tac-toe, here's how we might translate this to code, for instance. If player is x, for each possible move, calculate a score for the board, as we were doing verbally, and then choose the move with the highest score, because x's goal is to maximize its score. If the player is O, though, for each possible move, calculate a score for the board and then choose the move with the lowest score. So that's a distillation of that verbal walkthrough into what CS50 students know now as code, or at least pseudocode. But the problem with games, not so much tic-tac-toe, but other more sophisticated games is this. Does anyone want to ballpark how many possible ways there are to play tic-tac-toe? Paper pencil, two human children, how long could you keep them occupied playing tic-tac-toe in different ways? If you actually think through how big does this tree get, how many leaves are there on this decision tree, like how many different directions? Well, if you're thinking 255,168, you are correct. And now most of us in our lifetime have probably not played tic-tac-toe that many times. So think about how many games you've been missing out on. There are different decisions you could have been making all these years. Now that's a big number, but honestly, like that's not a big number for a computer. That's a few megabytes of memory maybe to sort of keep all of that in mind and sort of implement that kind of code in C or Java or C++ or something else. But other games are much more complicated. And the games that you and I might play as we get older include maybe chess. And if you think about chess with only the first four moves back and forth four times, so only four moves, that's not even a very long game. Anyone want to ballpark how many different ways there are to begin a game of chess with four moves back and forth? This is evidence as to why chess is apparently so hard. 288 million ways, which is why when you are really good at chess, you are really good at chess, because apparently you either have an intuition for or a mind for thinking it would seem so many more steps ahead than your opponent. And don't get us started on something like Go. 266 quintillion ways to play Go's first four moves. So at this point, we just can't pull out our Mac, our PC, certainly not our phone to solve optimally games like chess and Go because we don't have big enough CPUs. We don't have enough memory. We don't have enough years in our lifetimes for the computers to crunch all of those numbers. And thus was born a different form of AI that's more inspired by finding patterns more dynamically. Learning from data as opposed to being told by humans, here is the code via which to solve this problem. So machine learning is a subset of artificial intelligence that tries instead to get machines to learn what they should do without being so coached step by step by step by humans here. Reinforcement learning, for instance, is one such example thereof, wherein reinforcement learning, you sort of wait for the computer or maybe a robot to maybe just get better and better and better at things. And as it does, you reward it with a reward function. Give it plus one every time it does something well and maybe minus one. You punish it any time it does something poorly. And if you simply program this AI or this robot to maximize its score, never mind minimizing, maximize its score. Ideally, it should repeat behaviors that got it plus one. It should decrease the frequency with which it does bad behaviors that got it negative one. And you can reinforce this kind of learning. In fact, I have here one demonstration. Could a student come on up who does not think they are particularly coordinated? OK, wow, you're being nominated by your friends. Come on up, come on up. Their hands went up instantly for you. OK, what is your name? My name is Amaka. Amaka, do you want to introduce yourself to the world? Hi, my name is Amaka. I am a first year in Hallworthy, planning to concentrate in CS. Wonderful, nice to see you. Come on over here. So, yes, oh no, it's sort of like a game show here. We have a pan here with what appears to be something pancake-like. And we'd like to teach you how to flip a pancake so that when you gesture upward, the pancake should flip around so you cook the other side. So we're going to reward you verbally with plus one or minus one. Minus one, minus one. OK, plus one, plus one. So do more of that. Minus one, minus one. Minus one, minus one. Do less of that. All right, a big round of applause. Thank you. We've been in the habit of handing out Super Mario Brothers Oreos this year. So thank you for participating. So this is actually a good example of an opportunity for reinforcement learning and wonderfully a researcher has posted a video that we thought we'd share. It's about a minute and a half long where you can watch a robot now do exactly what our wonderful human volunteer here just attempted as well. So let me go ahead and play this on the screen and give you a sense of what the human and the robot are doing together. So their pancake looks a little similar there. The human here is going to first sort of train the robot what to do by showing it some gestures. But there's no one right way to do this. But the human seems to know how to do it pretty well in this case. And so it's trying to give the machine examples of how to flip a pancake successfully. But now this is the very first trial. OK, look from that. You're in good company. After three trials. OK. OK. Now 10 tries. There's the human picking up the pancake. After 11 trials. And meanwhile there's presumably a human coding this in the sense that someone is saying good job or bad job plus one or minus one. 20 trials. Here now we'll see how the computer knows what it's even doing. There's just a mapping to some kind of like XYZ coordinate system. So the robot can quantize what is it's doing. Nice to do more of one thing less of another. And you're just seeing a visualization in the background of those digitized movements. And so now after 50 some odd trials. The robot to has got its spot on and it should be able to repeat this again and again and again in order to keep flipping this pancake. So our human volunteer wonderfully took you even fewer trials. But this is an example then to be clear of what we'd call reinforcement learning whereby you're reinforcing a behavior you want or negatively reinforcing that is punishing a behavior that you don't. Here's another example that brings us back into the realm of games a little bit. But in a very abstract way if we were playing a game like the floor is lava where you're only supposed to step certain places so that you don't fall through in the lava pit or something like that and lose a point or lose a life. Each of these squares might represent a position. This yellow dot might represent the human player that can go up down left or right within this world. I'm revealing to the whole audience where the lava pits are. But the goal for this yellow dot is to get to green. But the yellow dot as in any good game does not have this bird's eye view and knows from the get go exactly where to go. It's going to have to try some trial and error. But if we the programmers maybe reinforce good behavior or punish bad behavior, we can sort of teach this yellow dot without giving it step by step up down left right instructions what behaviors to repeat and what behaviors not to repeat. So for instance suppose the robot moves right that was bad you fell in the lava already. So we'll use a bit of computer memory to sort of draw a thicker red line there. Don't do that again. So negative one so to speak. Maybe the yellow dot moves up next time we can reward that behavior by not drawing any walls and allowing it to go again. It's making pretty good progress, but oh darn it. It took a right turn and now fell into the lava. But let's use a bit more of the computer's memory and keep track of that. Okay, do not do that thing anymore. Maybe the next time the human dot goes this way. We want to punish that behavior so we'll remember as much with that red line. But now we're starting to make progress until now we hit this one. And eventually even though the yellow dot much like our human much like our pancake flipping robot had to try again and again and again. After enough trials, it's going to start to realize what behaviors it should repeat and which ones it shouldn't. And so in this case, maybe it finally makes its way up to the green dot. And just to recap, once it finds that path, now we can sort of remember it forever as with these green thicker lines. Anytime you want to leave this map, anytime you get really good at the Nintendo game, you'll follow that same path again and again so you don't fall into the lava. But an astute human observer might realize that yes, this is correct. It's getting out of this so-called maze. But what is suboptimal or bad about this solution? Sure. Exactly. It's taking a really long time and inefficient way to get there because I dare say if we just try to different path occasionally, maybe we could get lucky and get to the out the exit quicker and maybe that means we get a higher score. We get rewarded even more. So within a lot of artificial intelligence algorithms, there's this idea of exploring versus exploiting, whereby you should occasionally, yes, exploit the knowledge you already have. In fact, frequently exploit that knowledge, but occasionally you know what you should probably do is explore just a little bit. Take a left instead of a right and see if it leads you to the solution even more quickly and you might find a better and better solution. So here mathematically is how we might think of this. 10% of the time, we might say that epsilon, just some variable, sort of a sprinkling of salt into the algorithm here, epsilon will be like 10% of the time. So if my robot or my player picks a random number that's less than 10%, that's going to make a random move. Go left instead of right, even if you really typically go right. Otherwise, make the move with the highest value as we've learned over time. And what the robot might learn then is that we could actually go via this path which gets us to the output faster. We get a higher score. We do it in less time. It's a win-win. Frankly, this really resonates with me because I've been in the habit as maybe some of you are. When you go to a restaurant, maybe that you really like, you find a dish you really like, I will never again know what other dishes that restaurant offers because I'm sort of locally, optimally happy with the dish I've chosen. And I will never know if there's an even better dish at that restaurant unless again I sort of sprinkle a little bit of epsilon, a little bit of randomness into my game playing, my dining out. The catch, of course, though, is that I might be punished. I might therefore sort of be less happy if I pick something and I don't like it. So there's this tension between exploring and exploiting, but in general in computer science and especially in AI, adding a little bit of randomness, especially over time, can in fact yield better and better outcomes. But now there's this notion all the more of deep learning whereby you're trying to infer to detect patterns, figure out how to solve problems, even if the AI has never seen those problems before. And even if there's no human there to reinforce positive or negatively behavior, maybe it's just too complex of a problem for a human to stand alongside the robot and say good or bad job. So with deep learning, they're actually very much related to what you might know as neural networks inspired by human physiology, whereby inside of our brains and elsewhere in our brain, there's lots of these neurons here that can send electrical signals to sort of make movements happen from brain to extremities. You might have two of these via which signals can be transmitted over larger distance. And so computer scientists for some time have drawn inspiration from these neurons to create in software what we call neural networks, whereby there's inputs to these networks and there's outputs from these networks that represents inputs to problems and solutions there too. So let me abstract away the more biological diagrams with just circles that represent nodes or neurons in this case. This would be, we'd call in CS50, the input. This is what we would call the output, but this is very simplistic, very simple neural network. This might be more common whereby the network, the AI takes two inputs to a problem and tries to give you one solution. Well, let's make this more real. For instance, suppose that just for the sake of discussion, here is like a grid that you might see in math class with a y-axis and an x-axis vertically and horizontally respectively. Suppose there's a couple of blue and red dots in that world, and suppose that our goal computationally is to predict whether a dot is going to be blue or red based on its position within that coordinate system. And maybe this represents some real world notion. Maybe it's something like rain that we're trying to predict, but we're doing it more simply with colors right now. So here's my y-axis, here's my x-axis, and effectively my neural network you can think of conceptually as this. It's some kind of implementation of software where there's two inputs to the problem. Give me an x, give me a y value, and this neural network will output red or blue as its prediction. Well, how does it know whether to predict red or blue, especially if no human has painstakingly written code to say when you see a dot here, conclude that it's red? When you see a dot here conclude that it's blue, how can an AI just learn dynamically to solve problems? Well, what might be a reasonable heuristic here? Honestly, this is probably a first approximation that's pretty good. If anything's to the left of that line, let the neural network conclude that it's going to be blue. And if it's to the right of the line, let it conclude that it's going to be red. Until such time as there's more training data, more real world data that gets us to rethink our assumptions. So for instance, if there's a third dot there, oh, clearly a straight line is not sufficient. So maybe it's more of a diagonal line that splits the blue from the red world here. Meanwhile, here's even more dots. And it's actually getting harder now. Like this line is still pretty good. Most of the blue is up here. Most of the red is down here. And this is why if we fast forward to today, AI is often very good but not perfect at solving problems. But what is it we're looking at here? And what is this neural network really trying to figure out? Well, again, at the risk of taking some fun out of red and blue dots, you can think of this neural network as indeed having these neurons, which represent inputs here and outputs here. And then what's happening inside of the computer's memory is that it's trying to figure out what the weight of this arrow or edge should be. What the weight of this arrow or edge should be. And maybe there's another variable there like plus or minus C that just tweaks the prediction. So x and y are literally going to be numbers in this scenario. And the output of this neural network ideally is just true or false. Is it red or blue? So it's sort of a binary state as we discuss a lot in CS50. So here, too, to take the sort of fun out of the pretty picture, it's really just like a high school math function. What the neural network in this example is trying to figure out is what formula of the form AX plus BY plus C is going to be arbitrarily greater than zero. And if so, let's conclude that the dot is red if you get back a positive result. If you don't, let's conclude that the dot is going to be blue instead. So really what you're trying to do is figure out dynamically what numbers do we have to tweak these parameters inside of the neural network? That just give us the answer we want based on all of this data. More generally, though, this would be really representative of deep learning. It's not as simple as input, input, output. There's actually a lot of these nodes, these neurons. There's a lot of these edges. There's a lot of numbers and math are going on that, frankly, even the computer scientists using these neural networks don't necessarily know what they even mean or represent. It just happens to be that when you crunch the numbers with all of these parameters in place, you get the answer that you want, at least most of the time. So that's essentially the intuition behind that. And you can apply it to a very real world if mundane applications, given today's humidity, given today's pressure, yes or no should there be rainfall. And maybe there is some mathematical function that based on years of training data, we can infer what that prediction should be. Another one, given this amount of advertising in this month, what should our sales be for that year? Should they be up or should they be down? Sorry for that particular month. So real world problems map readily when you can break them down into inputs and a binary output often or some kind of output where you want the thing to figure out based on past data what its prediction should be. So that brings us back to generative artificial intelligence, which isn't just about solving problems, but really generating literally images, texts, even videos that again increasingly resemble what we humans might otherwise output ourselves. And within the world of generative artificial intelligence, do we have, of course, the same images that we saw before, the same text that we saw before, and more generally things like chat GPT, which are really examples of what we now call large language models, these sort of massive neural networks that have so many inputs and so many neurons implemented in software that essentially represent all of the patterns that the software has discovered by being fed massive amounts of input. Think of it as like the entire textual content of the internet. Think of it as the entire content of courses like CS50 that may very well be out there on the internet. And even though these AIs, these large language models, haven't been told how to behave, they're really inferring from all of these examples for better or for worse how to make predictions. So here, for instance, from 2017, just a few years back, is a seminal paper from Google that introduced what we now know as a transformer architecture. And this introduced this idea of attention values, whereby they propose that given an English sentence, for instance, or really any human sentence, you try to assign numbers, not unlike our past exercises, to each of the words, each of the inputs that speaks to its relationship with other words. So if there's a high relationship between two words and a sentence, they would have high attention values. And if maybe it's a preposition or an article like the or the like, maybe those attention values are lower. And by encoding the world in that way, do we begin to detect patterns that allow us to predict things like words? That is generate text. So for instance, up until a few years ago, completing this sentence was actually pretty hard for a lot of AI. So for instance here, Massachusetts is a state in the New England region of the northeastern United States. It borders on the Atlantic Ocean to the east. The state's capital is dot dot dot. Now you should think that this is relatively straightforward. It's like just handing you a softball type question. But historically within the world of AI, this word state was so relatively far away from the proper noun that it's actually referring back to, that we just didn't have computational models that sort of took in that holistic picture that frankly we humans are much better at. If you would ask this question a little more quickly, a little more immediately, you might have gotten a better response. But this is dare say why chatbots in the past have been so bad in the form of customer service and the like, because they're not really taking all of the context into account that we humans might be inclined to provide. What's going on underneath the hood without escalating things too quickly? What an artificial intelligence nowadays, these large language models might do, is sort of break down the user's input, your input, into chatupiti, into the individual words. We might then take into account the order of those words. Massachusetts is first, is, is last. We might further encode each of those words using a standard way. And there's different algorithms for this, but you come up with what are called embeddings. That is to say, you can use one of those APIs I talked about earlier, or even software running on your own computers to come up with a mathematical representation of the word Massachusetts. And Rang Shin kindly did this for us last night. This is the 1536 floating point values that open AI uses to represent the word Massachusetts. And this is to say, and you should not understand anything you are looking at on the screen nor do I, but this is now a mathematical representation of the input that can be compared against the mathematical representations of other inputs in order to find proximity semantically. Words that somehow have relationships or correlations with each other that helps the AI ultimately predict what should the next word out of its mouth be, so to speak. So in a case like this, these values represent, these lines represent all of those attention values and thicker lines means there's more attention given from one word to another. Thinner lines mean the opposite. And those inputs are ultimately fed into a large neural network where you have inputs on the left, outputs on the right. And in this particular case, the hope is to get out a single word, which is the capital of Boston itself, whereby somehow the neural network and the humans behind it at OpenAI, Microsoft, Google, or elsewhere have sort of crunched so many numbers by training these models on so much data that it figured out what all of those weights are, what the biases are, so as to influence mathematically the output therefrom. So that is all underneath the hood of what students now perceive as this adorable rubber duck, but underneath it all is certainly a lot of domain knowledge and CS50 by nature of being open courseware for the past many years. CS50 is fortunate to actually be part of the model, as might be any other content that's freely available online, and so that certainly helps benefit the answers when it comes to asking CS50 specific questions. That said, it's not perfect, and you might have heard of what are currently called hallucinations, where chatGPT and similar tools just make stuff up, and it sounds very confident, and you can sometimes call it on it, whereby you can say, no, that's not right, and it will playfully apologize and say, oh, I'm sorry, but it made up some statement because it was probabilistically something that could be said even if it's just not correct. Now, I'll allow me to propose that this kind of problem is going to get less and less frequent, and so as the models evolve and our techniques evolve, this will be less of an issue, but I thought it would be fun to end on a note that a former colleague shared just the other day, which was this old poem by Shel Silverstein, another something from our past childhood perhaps, and this was from 1981, a poem called Homework Machine, which is perhaps foretold where we are now in 2023. The Homework Machine, oh, the Homework Machine, most perfect contraption that's ever been seen. Just put in your homework, then drop in a dime, snap on the switch, and in ten seconds time, your homework comes out quick and clean as can be. Here it is, nine plus four, and the answer is three. Three? Oh, me. I guess it's not as perfect as I thought it would be. So, quite foretelling, sure. Quite foretelling indeed, though for all this and more, the family members in the audience are welcome to take CS50 yourself online at cs50.edex.org. For all of today and so much more, allow me to thank Brian, Rung Shin, Sophie, Andrew, Patrick, Charlie, CS50's whole team. If you are a family member here headed to lunch with CS50's team, please look for Cameron holding a rubber duck above her head. Thank you so much for joining us today. This was CS50. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 30.0, "text": " Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n g", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290], "temperature": 0.0, "avg_logprob": -0.14649466620551216, "compression_ratio": 13.515151515151516, "no_speech_prob": 0.9483560919761658}, {"id": 1, "seek": 3000, "start": 30.0, "end": 60.0, "text": " gweithio, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13], "temperature": 0.0, "avg_logprob": -0.32830586640731146, "compression_ratio": 1.4642857142857142, "no_speech_prob": 0.9149823784828186}, {"id": 2, "seek": 6000, "start": 60.0, "end": 62.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50364, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50464], "temperature": 0.0, "avg_logprob": -0.8829623951631433, "compression_ratio": 1.08, "no_speech_prob": 0.9934132695198059}, {"id": 3, "seek": 9000, "start": 90.0, "end": 92.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50364, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50464], "temperature": 0.0, "avg_logprob": -0.20046309863819795, "compression_ratio": 1.08, "no_speech_prob": 0.9850617051124573}, {"id": 4, "seek": 12000, "start": 120.0, "end": 122.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50364, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50464], "temperature": 0.0, "avg_logprob": -0.10447312102598302, "compression_ratio": 1.08, "no_speech_prob": 0.982884407043457}, {"id": 5, "seek": 15000, "start": 150.0, "end": 152.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50364, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50464], "temperature": 0.0, "avg_logprob": -0.08534815732170553, "compression_ratio": 1.08, "no_speech_prob": 0.9832430481910706}, {"id": 6, "seek": 18000, "start": 180.0, "end": 182.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50364, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50464], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 7, "seek": 18000, "start": 182.0, "end": 184.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50464, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50564], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 8, "seek": 18000, "start": 184.0, "end": 186.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50564, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50664], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 9, "seek": 18000, "start": 186.0, "end": 188.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50664, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50764], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 10, "seek": 18000, "start": 188.0, "end": 190.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50764, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50864], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 11, "seek": 18000, "start": 190.0, "end": 192.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50864, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50964], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 12, "seek": 18000, "start": 192.0, "end": 194.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50964, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51064], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 13, "seek": 18000, "start": 194.0, "end": 196.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [51064, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51164], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 14, "seek": 18000, "start": 196.0, "end": 198.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [51164, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51264], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 15, "seek": 18000, "start": 200.0, "end": 202.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [51364, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51464], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 16, "seek": 18000, "start": 202.0, "end": 204.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [51464, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51564], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 17, "seek": 18000, "start": 204.0, "end": 206.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [51564, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51664], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 18, "seek": 18000, "start": 206.0, "end": 208.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [51664, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51764], "temperature": 0.0, "avg_logprob": -0.0415316899617513, "compression_ratio": 13.444444444444445, "no_speech_prob": 0.976219117641449}, {"id": 19, "seek": 20800, "start": 208.0, "end": 210.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50364, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50464], "temperature": 1.0, "avg_logprob": -0.08036044700858519, "compression_ratio": 12.407407407407407, "no_speech_prob": 0.5227028131484985}, {"id": 20, "seek": 20800, "start": 211.0, "end": 213.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50514, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50614], "temperature": 1.0, "avg_logprob": -0.08036044700858519, "compression_ratio": 12.407407407407407, "no_speech_prob": 0.5227028131484985}, {"id": 21, "seek": 20800, "start": 213.0, "end": 215.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50614, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50714], "temperature": 1.0, "avg_logprob": -0.08036044700858519, "compression_ratio": 12.407407407407407, "no_speech_prob": 0.5227028131484985}, {"id": 22, "seek": 20800, "start": 215.0, "end": 217.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50714, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50814], "temperature": 1.0, "avg_logprob": -0.08036044700858519, "compression_ratio": 12.407407407407407, "no_speech_prob": 0.5227028131484985}, {"id": 23, "seek": 20800, "start": 218.0, "end": 220.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50864, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 50964], "temperature": 1.0, "avg_logprob": -0.08036044700858519, "compression_ratio": 12.407407407407407, "no_speech_prob": 0.5227028131484985}, {"id": 24, "seek": 20800, "start": 220.0, "end": 222.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [50964, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51064], "temperature": 1.0, "avg_logprob": -0.08036044700858519, "compression_ratio": 12.407407407407407, "no_speech_prob": 0.5227028131484985}, {"id": 25, "seek": 20800, "start": 224.0, "end": 226.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [51164, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51264], "temperature": 1.0, "avg_logprob": -0.08036044700858519, "compression_ratio": 12.407407407407407, "no_speech_prob": 0.5227028131484985}, {"id": 26, "seek": 20800, "start": 226.0, "end": 228.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [51264, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51364], "temperature": 1.0, "avg_logprob": -0.08036044700858519, "compression_ratio": 12.407407407407407, "no_speech_prob": 0.5227028131484985}, {"id": 27, "seek": 20800, "start": 228.0, "end": 230.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [51364, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51464], "temperature": 1.0, "avg_logprob": -0.08036044700858519, "compression_ratio": 12.407407407407407, "no_speech_prob": 0.5227028131484985}, {"id": 28, "seek": 20800, "start": 230.0, "end": 232.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [51464, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51564], "temperature": 1.0, "avg_logprob": -0.08036044700858519, "compression_ratio": 12.407407407407407, "no_speech_prob": 0.5227028131484985}, {"id": 29, "seek": 20800, "start": 232.0, "end": 234.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [51564, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51664], "temperature": 1.0, "avg_logprob": -0.08036044700858519, "compression_ratio": 12.407407407407407, "no_speech_prob": 0.5227028131484985}, {"id": 30, "seek": 20800, "start": 234.0, "end": 236.0, "text": " Y Llywodraeth Y Llywodraeth", "tokens": [51664, 398, 441, 356, 86, 378, 424, 3293, 398, 441, 356, 86, 378, 424, 3293, 51764], "temperature": 1.0, "avg_logprob": -0.08036044700858519, "compression_ratio": 12.407407407407407, "no_speech_prob": 0.5227028131484985}, {"id": 31, "seek": 23600, "start": 236.0, "end": 246.0, "text": " Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 50864], "temperature": 0.0, "avg_logprob": -0.370189220347303, "compression_ratio": 5.6875, "no_speech_prob": 0.9486346244812012}, {"id": 32, "seek": 26600, "start": 266.0, "end": 282.0, "text": " Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.17763130126460905, "compression_ratio": 3.6875, "no_speech_prob": 0.9888498187065125}, {"id": 33, "seek": 29600, "start": 296.0, "end": 304.0, "text": " Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2245388348897298, "compression_ratio": 1.6875, "no_speech_prob": 0.9918739199638367}, {"id": 34, "seek": 32600, "start": 326.0, "end": 334.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 50764], "temperature": 0.0, "avg_logprob": -0.26867407018488104, "compression_ratio": 1.1875, "no_speech_prob": 0.9913924932479858}, {"id": 35, "seek": 35600, "start": 356.0, "end": 366.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 50864], "temperature": 0.0, "avg_logprob": -0.24107235128229315, "compression_ratio": 1.1875, "no_speech_prob": 0.9896448850631714}, {"id": 36, "seek": 38600, "start": 386.0, "end": 402.0, "text": " Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14263329939408737, "compression_ratio": 3.1875, "no_speech_prob": 0.9891631603240967}, {"id": 37, "seek": 40200, "start": 402.0, "end": 418.0, "text": " Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11464490023526279, "compression_ratio": 3.1875, "no_speech_prob": 0.9903843402862549}, {"id": 38, "seek": 41800, "start": 418.0, "end": 434.0, "text": " Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1145459438892121, "compression_ratio": 2.6875, "no_speech_prob": 0.9912683963775635}, {"id": 39, "seek": 43400, "start": 434.0, "end": 450.0, "text": " Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.15174802657096617, "compression_ratio": 1.6875, "no_speech_prob": 0.9908979535102844}, {"id": 40, "seek": 45000, "start": 450.0, "end": 466.0, "text": " Felly, mae'n gweithio, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14193697898618637, "compression_ratio": 1.6875, "no_speech_prob": 0.9922329187393188}, {"id": 41, "seek": 46600, "start": 466.0, "end": 482.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.2053313047989555, "compression_ratio": 1.1875, "no_speech_prob": 0.9961806535720825}, {"id": 42, "seek": 48200, "start": 482.0, "end": 498.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.18715452111285666, "compression_ratio": 1.1875, "no_speech_prob": 0.996382474899292}, {"id": 43, "seek": 49800, "start": 498.0, "end": 514.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.16080899860547937, "compression_ratio": 1.1875, "no_speech_prob": 0.9924135804176331}, {"id": 44, "seek": 51400, "start": 514.0, "end": 530.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14443703319715417, "compression_ratio": 1.1875, "no_speech_prob": 0.9941831231117249}, {"id": 45, "seek": 53000, "start": 530.0, "end": 546.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1365872466045877, "compression_ratio": 1.1875, "no_speech_prob": 0.994785487651825}, {"id": 46, "seek": 54600, "start": 546.0, "end": 562.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.12822133561839227, "compression_ratio": 1.1875, "no_speech_prob": 0.9917463064193726}, {"id": 47, "seek": 56200, "start": 562.0, "end": 578.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.12450601743615192, "compression_ratio": 1.1875, "no_speech_prob": 0.9920646548271179}, {"id": 48, "seek": 57800, "start": 578.0, "end": 594.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11854705603226372, "compression_ratio": 1.1875, "no_speech_prob": 0.9888423681259155}, {"id": 49, "seek": 59400, "start": 594.0, "end": 610.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11725113702856976, "compression_ratio": 1.1875, "no_speech_prob": 0.9873992204666138}, {"id": 50, "seek": 61000, "start": 610.0, "end": 626.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11099240054254947, "compression_ratio": 1.1875, "no_speech_prob": 0.9899881482124329}, {"id": 51, "seek": 62600, "start": 626.0, "end": 642.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1146226343901261, "compression_ratio": 1.1875, "no_speech_prob": 0.9932181239128113}, {"id": 52, "seek": 64200, "start": 642.0, "end": 658.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11228416277014691, "compression_ratio": 1.1875, "no_speech_prob": 0.9928581714630127}, {"id": 53, "seek": 65800, "start": 658.0, "end": 674.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11401057243347168, "compression_ratio": 1.1875, "no_speech_prob": 0.9909296631813049}, {"id": 54, "seek": 67400, "start": 674.0, "end": 690.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10929021628006645, "compression_ratio": 1.1875, "no_speech_prob": 0.9923241138458252}, {"id": 55, "seek": 69000, "start": 690.0, "end": 706.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.112587192784185, "compression_ratio": 1.1875, "no_speech_prob": 0.992198646068573}, {"id": 56, "seek": 70600, "start": 706.0, "end": 722.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11006972064142642, "compression_ratio": 1.1875, "no_speech_prob": 0.9916366934776306}, {"id": 57, "seek": 72200, "start": 722.0, "end": 738.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11191479019496751, "compression_ratio": 1.1875, "no_speech_prob": 0.9920823574066162}, {"id": 58, "seek": 73800, "start": 738.0, "end": 754.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1118978210117506, "compression_ratio": 1.1875, "no_speech_prob": 0.9919730424880981}, {"id": 59, "seek": 75400, "start": 754.0, "end": 770.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11044623540795367, "compression_ratio": 1.1875, "no_speech_prob": 0.9912494421005249}, {"id": 60, "seek": 77000, "start": 770.0, "end": 786.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11144250372181767, "compression_ratio": 1.1875, "no_speech_prob": 0.992159366607666}, {"id": 61, "seek": 78600, "start": 786.0, "end": 802.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11531025430430537, "compression_ratio": 1.1875, "no_speech_prob": 0.9936543703079224}, {"id": 62, "seek": 80200, "start": 802.0, "end": 818.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10994668628858484, "compression_ratio": 1.1875, "no_speech_prob": 0.9913530945777893}, {"id": 63, "seek": 81800, "start": 818.0, "end": 834.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.11478176324263863, "compression_ratio": 1.1875, "no_speech_prob": 0.9919019341468811}, {"id": 64, "seek": 83400, "start": 834.0, "end": 860.0, "text": " Felly, mae'n gweithio, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14338913171187692, "compression_ratio": 1.1875, "no_speech_prob": 0.7724098563194275}, {"id": 65, "seek": 86000, "start": 860.0, "end": 862.0, "text": " Felly, mae'n gweithio.", "tokens": [50364, 479, 7442, 11, 43783, 6, 77, 290, 826, 355, 1004, 13, 50464], "temperature": 0.0, "avg_logprob": -0.24247113396139705, "compression_ratio": 3.9411764705882355, "no_speech_prob": 0.9487050771713257}, {"id": 66, "seek": 86000, "start": 862.0, "end": 864.0, "text": " Mae'n gweithio.", "tokens": [50464, 31055, 6, 77, 290, 826, 355, 1004, 13, 50564], "temperature": 0.0, "avg_logprob": -0.24247113396139705, "compression_ratio": 3.9411764705882355, "no_speech_prob": 0.9487050771713257}, {"id": 67, "seek": 86000, "start": 864.0, "end": 866.0, "text": " Mae'n gweithio.", "tokens": [50564, 31055, 6, 77, 290, 826, 355, 1004, 13, 50664], "temperature": 0.0, "avg_logprob": -0.24247113396139705, "compression_ratio": 3.9411764705882355, "no_speech_prob": 0.9487050771713257}, {"id": 68, "seek": 86000, "start": 866.0, "end": 868.0, "text": " Mae'n gweithio.", "tokens": [50664, 31055, 6, 77, 290, 826, 355, 1004, 13, 50764], "temperature": 0.0, "avg_logprob": -0.24247113396139705, "compression_ratio": 3.9411764705882355, "no_speech_prob": 0.9487050771713257}, {"id": 69, "seek": 86000, "start": 868.0, "end": 870.0, "text": " Mae'n gweithio.", "tokens": [50764, 31055, 6, 77, 290, 826, 355, 1004, 13, 50864], "temperature": 0.0, "avg_logprob": -0.24247113396139705, "compression_ratio": 3.9411764705882355, "no_speech_prob": 0.9487050771713257}, {"id": 70, "seek": 86000, "start": 870.0, "end": 872.0, "text": " Mae'n gweithio.", "tokens": [50864, 31055, 6, 77, 290, 826, 355, 1004, 13, 50964], "temperature": 0.0, "avg_logprob": -0.24247113396139705, "compression_ratio": 3.9411764705882355, "no_speech_prob": 0.9487050771713257}, {"id": 71, "seek": 86000, "start": 872.0, "end": 874.0, "text": " Mae'n gweithio.", "tokens": [50964, 31055, 6, 77, 290, 826, 355, 1004, 13, 51064], "temperature": 0.0, "avg_logprob": -0.24247113396139705, "compression_ratio": 3.9411764705882355, "no_speech_prob": 0.9487050771713257}, {"id": 72, "seek": 86000, "start": 874.0, "end": 876.0, "text": " Mae'n gweithio.", "tokens": [51064, 31055, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.24247113396139705, "compression_ratio": 3.9411764705882355, "no_speech_prob": 0.9487050771713257}, {"id": 73, "seek": 87600, "start": 876.0, "end": 878.0, "text": " Mae'n gweithio.", "tokens": [50364, 31055, 6, 77, 290, 826, 355, 1004, 13, 50464], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 74, "seek": 87600, "start": 878.0, "end": 880.0, "text": " Mae'n gweithio.", "tokens": [50464, 31055, 6, 77, 290, 826, 355, 1004, 13, 50564], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 75, "seek": 87600, "start": 880.0, "end": 882.0, "text": " Mae'n gweithio.", "tokens": [50564, 31055, 6, 77, 290, 826, 355, 1004, 13, 50664], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 76, "seek": 87600, "start": 882.0, "end": 884.0, "text": " Mae'n gweithio.", "tokens": [50664, 31055, 6, 77, 290, 826, 355, 1004, 13, 50764], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 77, "seek": 87600, "start": 884.0, "end": 886.0, "text": " Mae'n gweithio.", "tokens": [50764, 31055, 6, 77, 290, 826, 355, 1004, 13, 50864], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 78, "seek": 87600, "start": 886.0, "end": 888.0, "text": " Mae'n gweithio.", "tokens": [50864, 31055, 6, 77, 290, 826, 355, 1004, 13, 50964], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 79, "seek": 87600, "start": 888.0, "end": 890.0, "text": " Mae'n gweithio.", "tokens": [50964, 31055, 6, 77, 290, 826, 355, 1004, 13, 51064], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 80, "seek": 87600, "start": 890.0, "end": 892.0, "text": " Mae'n gweithio.", "tokens": [51064, 31055, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 81, "seek": 87600, "start": 892.0, "end": 894.0, "text": " Mae'n gweithio.", "tokens": [51164, 31055, 6, 77, 290, 826, 355, 1004, 13, 51264], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 82, "seek": 87600, "start": 894.0, "end": 896.0, "text": " Mae'n gweithio.", "tokens": [51264, 31055, 6, 77, 290, 826, 355, 1004, 13, 51364], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 83, "seek": 87600, "start": 896.0, "end": 898.0, "text": " Mae'n gweithio.", "tokens": [51364, 31055, 6, 77, 290, 826, 355, 1004, 13, 51464], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 84, "seek": 87600, "start": 898.0, "end": 900.0, "text": " Mae'n gweithio.", "tokens": [51464, 31055, 6, 77, 290, 826, 355, 1004, 13, 51564], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 85, "seek": 87600, "start": 900.0, "end": 902.0, "text": " Mae'n gweithio.", "tokens": [51564, 31055, 6, 77, 290, 826, 355, 1004, 13, 51664], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 86, "seek": 87600, "start": 902.0, "end": 904.0, "text": " Mae'n gweithio.", "tokens": [51664, 31055, 6, 77, 290, 826, 355, 1004, 13, 51764], "temperature": 0.0, "avg_logprob": -0.05041282949313312, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.9264609217643738}, {"id": 87, "seek": 90400, "start": 904.0, "end": 906.0, "text": " Mae'n gweithio.", "tokens": [50364, 31055, 6, 77, 290, 826, 355, 1004, 13, 50464], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 88, "seek": 90400, "start": 906.0, "end": 908.0, "text": " Mae'n gweithio.", "tokens": [50464, 31055, 6, 77, 290, 826, 355, 1004, 13, 50564], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 89, "seek": 90400, "start": 908.0, "end": 910.0, "text": " Mae'n gweithio.", "tokens": [50564, 31055, 6, 77, 290, 826, 355, 1004, 13, 50664], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 90, "seek": 90400, "start": 910.0, "end": 912.0, "text": " Mae'n gweithio.", "tokens": [50664, 31055, 6, 77, 290, 826, 355, 1004, 13, 50764], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 91, "seek": 90400, "start": 912.0, "end": 914.0, "text": " Mae'n gweithio.", "tokens": [50764, 31055, 6, 77, 290, 826, 355, 1004, 13, 50864], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 92, "seek": 90400, "start": 914.0, "end": 916.0, "text": " Mae'n gweithio.", "tokens": [50864, 31055, 6, 77, 290, 826, 355, 1004, 13, 50964], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 93, "seek": 90400, "start": 916.0, "end": 918.0, "text": " Mae'n gweithio.", "tokens": [50964, 31055, 6, 77, 290, 826, 355, 1004, 13, 51064], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 94, "seek": 90400, "start": 918.0, "end": 920.0, "text": " Mae'n gweithio.", "tokens": [51064, 31055, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 95, "seek": 90400, "start": 920.0, "end": 922.0, "text": " Mae'n gweithio.", "tokens": [51164, 31055, 6, 77, 290, 826, 355, 1004, 13, 51264], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 96, "seek": 90400, "start": 922.0, "end": 924.0, "text": " Mae'n gweithio.", "tokens": [51264, 31055, 6, 77, 290, 826, 355, 1004, 13, 51364], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 97, "seek": 90400, "start": 924.0, "end": 926.0, "text": " Mae'n gweithio.", "tokens": [51364, 31055, 6, 77, 290, 826, 355, 1004, 13, 51464], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 98, "seek": 90400, "start": 926.0, "end": 928.0, "text": " Mae'n gweithio.", "tokens": [51464, 31055, 6, 77, 290, 826, 355, 1004, 13, 51564], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 99, "seek": 90400, "start": 928.0, "end": 930.0, "text": " Mae'n gweithio.", "tokens": [51564, 31055, 6, 77, 290, 826, 355, 1004, 13, 51664], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 100, "seek": 90400, "start": 930.0, "end": 932.0, "text": " Mae'n gweithio.", "tokens": [51664, 31055, 6, 77, 290, 826, 355, 1004, 13, 51764], "temperature": 0.0, "avg_logprob": -0.033003682821569305, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.8348629474639893}, {"id": 101, "seek": 93200, "start": 932.0, "end": 934.0, "text": " Mae'n gweithio.", "tokens": [50364, 31055, 6, 77, 290, 826, 355, 1004, 13, 50464], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 102, "seek": 93200, "start": 934.0, "end": 936.0, "text": " Mae'n gweithio.", "tokens": [50464, 31055, 6, 77, 290, 826, 355, 1004, 13, 50564], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 103, "seek": 93200, "start": 936.0, "end": 938.0, "text": " Mae'n gweithio.", "tokens": [50564, 31055, 6, 77, 290, 826, 355, 1004, 13, 50664], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 104, "seek": 93200, "start": 938.0, "end": 940.0, "text": " Mae'n gweithio.", "tokens": [50664, 31055, 6, 77, 290, 826, 355, 1004, 13, 50764], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 105, "seek": 93200, "start": 940.0, "end": 942.0, "text": " Mae'n gweithio.", "tokens": [50764, 31055, 6, 77, 290, 826, 355, 1004, 13, 50864], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 106, "seek": 93200, "start": 942.0, "end": 944.0, "text": " Mae'n gweithio.", "tokens": [50864, 31055, 6, 77, 290, 826, 355, 1004, 13, 50964], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 107, "seek": 93200, "start": 944.0, "end": 946.0, "text": " Mae'n gweithio.", "tokens": [50964, 31055, 6, 77, 290, 826, 355, 1004, 13, 51064], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 108, "seek": 93200, "start": 946.0, "end": 948.0, "text": " Mae'n gweithio.", "tokens": [51064, 31055, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 109, "seek": 93200, "start": 948.0, "end": 950.0, "text": " Mae'n gweithio.", "tokens": [51164, 31055, 6, 77, 290, 826, 355, 1004, 13, 51264], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 110, "seek": 93200, "start": 950.0, "end": 952.0, "text": " Mae'n gweithio.", "tokens": [51264, 31055, 6, 77, 290, 826, 355, 1004, 13, 51364], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 111, "seek": 93200, "start": 952.0, "end": 954.0, "text": " Mae'n gweithio.", "tokens": [51364, 31055, 6, 77, 290, 826, 355, 1004, 13, 51464], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 112, "seek": 93200, "start": 954.0, "end": 956.0, "text": " Mae'n gweithio.", "tokens": [51464, 31055, 6, 77, 290, 826, 355, 1004, 13, 51564], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 113, "seek": 93200, "start": 956.0, "end": 958.0, "text": " Mae'n gweithio.", "tokens": [51564, 31055, 6, 77, 290, 826, 355, 1004, 13, 51664], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 114, "seek": 93200, "start": 958.0, "end": 960.0, "text": " Mae'n gweithio.", "tokens": [51664, 31055, 6, 77, 290, 826, 355, 1004, 13, 51764], "temperature": 0.0, "avg_logprob": -0.046961529154173086, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7848968505859375}, {"id": 115, "seek": 96000, "start": 960.0, "end": 962.0, "text": " Mae'n gweithio.", "tokens": [50364, 31055, 6, 77, 290, 826, 355, 1004, 13, 50464], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 116, "seek": 96000, "start": 962.0, "end": 964.0, "text": " Mae'n gweithio.", "tokens": [50464, 31055, 6, 77, 290, 826, 355, 1004, 13, 50564], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 117, "seek": 96000, "start": 964.0, "end": 966.0, "text": " Mae'n gweithio.", "tokens": [50564, 31055, 6, 77, 290, 826, 355, 1004, 13, 50664], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 118, "seek": 96000, "start": 966.0, "end": 968.0, "text": " Mae'n gweithio.", "tokens": [50664, 31055, 6, 77, 290, 826, 355, 1004, 13, 50764], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 119, "seek": 96000, "start": 968.0, "end": 970.0, "text": " Mae'n gweithio.", "tokens": [50764, 31055, 6, 77, 290, 826, 355, 1004, 13, 50864], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 120, "seek": 96000, "start": 970.0, "end": 972.0, "text": " Mae'n gweithio.", "tokens": [50864, 31055, 6, 77, 290, 826, 355, 1004, 13, 50964], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 121, "seek": 96000, "start": 972.0, "end": 974.0, "text": " Mae'n gweithio.", "tokens": [50964, 31055, 6, 77, 290, 826, 355, 1004, 13, 51064], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 122, "seek": 96000, "start": 974.0, "end": 976.0, "text": " Mae'n gweithio.", "tokens": [51064, 31055, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 123, "seek": 96000, "start": 976.0, "end": 978.0, "text": " Mae'n gweithio.", "tokens": [51164, 31055, 6, 77, 290, 826, 355, 1004, 13, 51264], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 124, "seek": 96000, "start": 978.0, "end": 980.0, "text": " Mae'n gweithio.", "tokens": [51264, 31055, 6, 77, 290, 826, 355, 1004, 13, 51364], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 125, "seek": 96000, "start": 980.0, "end": 982.0, "text": " Mae'n gweithio.", "tokens": [51364, 31055, 6, 77, 290, 826, 355, 1004, 13, 51464], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 126, "seek": 96000, "start": 982.0, "end": 984.0, "text": " Mae'n gweithio.", "tokens": [51464, 31055, 6, 77, 290, 826, 355, 1004, 13, 51564], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 127, "seek": 96000, "start": 984.0, "end": 986.0, "text": " Mae'n gweithio.", "tokens": [51564, 31055, 6, 77, 290, 826, 355, 1004, 13, 51664], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 128, "seek": 96000, "start": 986.0, "end": 988.0, "text": " Mae'n gweithio.", "tokens": [51664, 31055, 6, 77, 290, 826, 355, 1004, 13, 51764], "temperature": 0.0, "avg_logprob": -0.047862056275488625, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.7573752403259277}, {"id": 129, "seek": 98800, "start": 988.0, "end": 990.0, "text": " Mae'n gweithio.", "tokens": [50364, 31055, 6, 77, 290, 826, 355, 1004, 13, 50464], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 130, "seek": 98800, "start": 990.0, "end": 992.0, "text": " Mae'n gweithio.", "tokens": [50464, 31055, 6, 77, 290, 826, 355, 1004, 13, 50564], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 131, "seek": 98800, "start": 992.0, "end": 994.0, "text": " Mae'n gweithio.", "tokens": [50564, 31055, 6, 77, 290, 826, 355, 1004, 13, 50664], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 132, "seek": 98800, "start": 994.0, "end": 996.0, "text": " Mae'n gweithio.", "tokens": [50664, 31055, 6, 77, 290, 826, 355, 1004, 13, 50764], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 133, "seek": 98800, "start": 996.0, "end": 998.0, "text": " Mae'n gweithio.", "tokens": [50764, 31055, 6, 77, 290, 826, 355, 1004, 13, 50864], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 134, "seek": 98800, "start": 998.0, "end": 1000.0, "text": " Mae'n gweithio.", "tokens": [50864, 31055, 6, 77, 290, 826, 355, 1004, 13, 50964], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 135, "seek": 98800, "start": 1000.0, "end": 1002.0, "text": " Mae'n gweithio.", "tokens": [50964, 31055, 6, 77, 290, 826, 355, 1004, 13, 51064], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 136, "seek": 98800, "start": 1002.0, "end": 1004.0, "text": " Mae'n gweithio.", "tokens": [51064, 31055, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 137, "seek": 98800, "start": 1004.0, "end": 1006.0, "text": " Mae'n gweithio.", "tokens": [51164, 31055, 6, 77, 290, 826, 355, 1004, 13, 51264], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 138, "seek": 98800, "start": 1006.0, "end": 1008.0, "text": " Mae'n gweithio.", "tokens": [51264, 31055, 6, 77, 290, 826, 355, 1004, 13, 51364], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 139, "seek": 98800, "start": 1008.0, "end": 1010.0, "text": " Mae'n gweithio.", "tokens": [51364, 31055, 6, 77, 290, 826, 355, 1004, 13, 51464], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 140, "seek": 98800, "start": 1010.0, "end": 1012.0, "text": " Mae'n gweithio.", "tokens": [51464, 31055, 6, 77, 290, 826, 355, 1004, 13, 51564], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 141, "seek": 98800, "start": 1012.0, "end": 1014.0, "text": " Mae'n gweithio.", "tokens": [51564, 31055, 6, 77, 290, 826, 355, 1004, 13, 51664], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 142, "seek": 98800, "start": 1014.0, "end": 1016.0, "text": " Mae'n gweithio.", "tokens": [51664, 31055, 6, 77, 290, 826, 355, 1004, 13, 51764], "temperature": 0.0, "avg_logprob": -0.049601920893494515, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.764682948589325}, {"id": 143, "seek": 101600, "start": 1016.0, "end": 1018.0, "text": " Mae'n gweithio.", "tokens": [50364, 31055, 6, 77, 290, 826, 355, 1004, 13, 50464], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 144, "seek": 101600, "start": 1018.0, "end": 1020.0, "text": " Mae'n gweithio.", "tokens": [50464, 31055, 6, 77, 290, 826, 355, 1004, 13, 50564], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 145, "seek": 101600, "start": 1020.0, "end": 1022.0, "text": " Mae'n gweithio.", "tokens": [50564, 31055, 6, 77, 290, 826, 355, 1004, 13, 50664], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 146, "seek": 101600, "start": 1022.0, "end": 1024.0, "text": " Mae'n gweithio.", "tokens": [50664, 31055, 6, 77, 290, 826, 355, 1004, 13, 50764], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 147, "seek": 101600, "start": 1024.0, "end": 1026.0, "text": " Mae'n gweithio.", "tokens": [50764, 31055, 6, 77, 290, 826, 355, 1004, 13, 50864], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 148, "seek": 101600, "start": 1026.0, "end": 1028.0, "text": " Mae'n gweithio.", "tokens": [50864, 31055, 6, 77, 290, 826, 355, 1004, 13, 50964], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 149, "seek": 101600, "start": 1028.0, "end": 1030.0, "text": " Mae'n gweithio.", "tokens": [50964, 31055, 6, 77, 290, 826, 355, 1004, 13, 51064], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 150, "seek": 101600, "start": 1030.0, "end": 1032.0, "text": " Mae'n gweithio.", "tokens": [51064, 31055, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 151, "seek": 101600, "start": 1032.0, "end": 1034.0, "text": " Mae'n gweithio.", "tokens": [51164, 31055, 6, 77, 290, 826, 355, 1004, 13, 51264], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 152, "seek": 101600, "start": 1034.0, "end": 1036.0, "text": " Mae'n gweithio.", "tokens": [51264, 31055, 6, 77, 290, 826, 355, 1004, 13, 51364], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 153, "seek": 101600, "start": 1036.0, "end": 1038.0, "text": " Mae'n gweithio.", "tokens": [51364, 31055, 6, 77, 290, 826, 355, 1004, 13, 51464], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 154, "seek": 101600, "start": 1038.0, "end": 1040.0, "text": " Mae'n gweithio.", "tokens": [51464, 31055, 6, 77, 290, 826, 355, 1004, 13, 51564], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 155, "seek": 101600, "start": 1040.0, "end": 1042.0, "text": " Mae'n gweithio.", "tokens": [51564, 31055, 6, 77, 290, 826, 355, 1004, 13, 51664], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 156, "seek": 101600, "start": 1042.0, "end": 1044.0, "text": " Mae'n gweithio.", "tokens": [51664, 31055, 6, 77, 290, 826, 355, 1004, 13, 51764], "temperature": 0.0, "avg_logprob": -0.043887363353245695, "compression_ratio": 8.25925925925926, "no_speech_prob": 0.676787793636322}, {"id": 157, "seek": 104400, "start": 1044.0, "end": 1046.0, "text": " Mae'n gweithio.", "tokens": [50364, 31055, 6, 77, 290, 826, 355, 1004, 13, 50464], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 158, "seek": 104400, "start": 1046.0, "end": 1048.0, "text": " Mae'n gweithio.", "tokens": [50464, 31055, 6, 77, 290, 826, 355, 1004, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 159, "seek": 104400, "start": 1048.0, "end": 1050.0, "text": " Mae'n gweithio.", "tokens": [50564, 31055, 6, 77, 290, 826, 355, 1004, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 160, "seek": 104400, "start": 1050.0, "end": 1052.0, "text": " Mae'n gweithio.", "tokens": [50664, 31055, 6, 77, 290, 826, 355, 1004, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 161, "seek": 104400, "start": 1052.0, "end": 1054.0, "text": " Mae'n gweithio.", "tokens": [50764, 31055, 6, 77, 290, 826, 355, 1004, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 162, "seek": 104400, "start": 1054.0, "end": 1056.0, "text": " Mae'n gweithio.", "tokens": [50864, 31055, 6, 77, 290, 826, 355, 1004, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 163, "seek": 104400, "start": 1058.0, "end": 1060.0, "text": " Mae'n gweithio.", "tokens": [51064, 31055, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 164, "seek": 104400, "start": 1060.0, "end": 1062.0, "text": " Mae'n gweithio.", "tokens": [51164, 31055, 6, 77, 290, 826, 355, 1004, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 165, "seek": 104400, "start": 1062.0, "end": 1064.0, "text": " Mae'n gweithio.", "tokens": [51264, 31055, 6, 77, 290, 826, 355, 1004, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 166, "seek": 104400, "start": 1064.0, "end": 1066.0, "text": " Mae'n gweithio.", "tokens": [51364, 31055, 6, 77, 290, 826, 355, 1004, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 167, "seek": 104400, "start": 1066.0, "end": 1068.0, "text": " Mae'n gweithio.", "tokens": [51464, 31055, 6, 77, 290, 826, 355, 1004, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 168, "seek": 104400, "start": 1068.0, "end": 1070.0, "text": " Mae'n gweithio.", "tokens": [51564, 31055, 6, 77, 290, 826, 355, 1004, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 169, "seek": 104400, "start": 1070.0, "end": 1072.0, "text": " Mae'n gweithio.", "tokens": [51664, 31055, 6, 77, 290, 826, 355, 1004, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08509203881928415, "compression_ratio": 7.666666666666667, "no_speech_prob": 0.6514138579368591}, {"id": 170, "seek": 107200, "start": 1072.0, "end": 1074.0, "text": " Mae'n gweithio.", "tokens": [50364, 31055, 6, 77, 290, 826, 355, 1004, 13, 50464], "temperature": 1.0, "avg_logprob": -0.14968253345024296, "compression_ratio": 6.09375, "no_speech_prob": 0.26513931155204773}, {"id": 171, "seek": 107200, "start": 1074.0, "end": 1076.0, "text": " Mae'n gweithio.", "tokens": [50464, 31055, 6, 77, 290, 826, 355, 1004, 13, 50564], "temperature": 1.0, "avg_logprob": -0.14968253345024296, "compression_ratio": 6.09375, "no_speech_prob": 0.26513931155204773}, {"id": 172, "seek": 107200, "start": 1076.0, "end": 1078.0, "text": " Mae'n gweithio.", "tokens": [50564, 31055, 6, 77, 290, 826, 355, 1004, 13, 50664], "temperature": 1.0, "avg_logprob": -0.14968253345024296, "compression_ratio": 6.09375, "no_speech_prob": 0.26513931155204773}, {"id": 173, "seek": 107200, "start": 1078.0, "end": 1080.0, "text": " Mae'n gweithio.", "tokens": [50664, 31055, 6, 77, 290, 826, 355, 1004, 13, 50764], "temperature": 1.0, "avg_logprob": -0.14968253345024296, "compression_ratio": 6.09375, "no_speech_prob": 0.26513931155204773}, {"id": 174, "seek": 107200, "start": 1080.0, "end": 1082.0, "text": " Mae'n gweithio.", "tokens": [50764, 31055, 6, 77, 290, 826, 355, 1004, 13, 50864], "temperature": 1.0, "avg_logprob": -0.14968253345024296, "compression_ratio": 6.09375, "no_speech_prob": 0.26513931155204773}, {"id": 175, "seek": 107200, "start": 1082.0, "end": 1084.0, "text": " Mae Mae'n gweithio.", "tokens": [50864, 31055, 31055, 6, 77, 290, 826, 355, 1004, 13, 50964], "temperature": 1.0, "avg_logprob": -0.14968253345024296, "compression_ratio": 6.09375, "no_speech_prob": 0.26513931155204773}, {"id": 176, "seek": 107200, "start": 1084.0, "end": 1086.0, "text": " Mae'n gweithio.", "tokens": [50964, 31055, 6, 77, 290, 826, 355, 1004, 13, 51064], "temperature": 1.0, "avg_logprob": -0.14968253345024296, "compression_ratio": 6.09375, "no_speech_prob": 0.26513931155204773}, {"id": 177, "seek": 107200, "start": 1086.0, "end": 1088.0, "text": " Mae'n gweithio.", "tokens": [51064, 31055, 6, 77, 290, 826, 355, 1004, 13, 51164], "temperature": 1.0, "avg_logprob": -0.14968253345024296, "compression_ratio": 6.09375, "no_speech_prob": 0.26513931155204773}, {"id": 178, "seek": 107200, "start": 1088.0, "end": 1090.0, "text": " Mae'n gweithio.", "tokens": [51164, 31055, 6, 77, 290, 826, 355, 1004, 13, 51264], "temperature": 1.0, "avg_logprob": -0.14968253345024296, "compression_ratio": 6.09375, "no_speech_prob": 0.26513931155204773}, {"id": 179, "seek": 107200, "start": 1090.0, "end": 1096.0, "text": " Mae'n gweithio.", "tokens": [51264, 31055, 6, 77, 290, 826, 355, 1004, 13, 51564], "temperature": 1.0, "avg_logprob": -0.14968253345024296, "compression_ratio": 6.09375, "no_speech_prob": 0.26513931155204773}, {"id": 180, "seek": 107200, "start": 1096.0, "end": 1098.0, "text": " Mae'n gweithio.", "tokens": [51564, 31055, 6, 77, 290, 826, 355, 1004, 13, 51664], "temperature": 1.0, "avg_logprob": -0.14968253345024296, "compression_ratio": 6.09375, "no_speech_prob": 0.26513931155204773}, {"id": 181, "seek": 107200, "start": 1098.0, "end": 1100.0, "text": " Mae'n gweithio.", "tokens": [51664, 31055, 6, 77, 290, 826, 355, 1004, 13, 51764], "temperature": 1.0, "avg_logprob": -0.14968253345024296, "compression_ratio": 6.09375, "no_speech_prob": 0.26513931155204773}, {"id": 182, "seek": 110000, "start": 1100.0, "end": 1102.78, "text": " a brwd nu yn ymwneud,", "tokens": [50364, 257, 738, 43778, 3822, 17861, 288, 76, 86, 716, 532, 11, 50503], "temperature": 1.0, "avg_logprob": -3.3761886935763887, "compression_ratio": 1.485342019543974, "no_speech_prob": 0.09668353945016861}, {"id": 183, "seek": 110000, "start": 1102.78, "end": 1105.0, "text": " a gallwn sandwyd fel ei plac i'n gwyld iawn hwnnw,", "tokens": [50503, 257, 8527, 895, 4932, 86, 6655, 11094, 14020, 20831, 741, 6, 77, 290, 9726, 348, 20721, 895, 276, 895, 77, 86, 11, 50614], "temperature": 1.0, "avg_logprob": -3.3761886935763887, "compression_ratio": 1.485342019543974, "no_speech_prob": 0.09668353945016861}, {"id": 184, "seek": 110000, "start": 1105.28, "end": 1107.4, "text": " neu yn y ddweud y ddaw fyddi,", "tokens": [50628, 22510, 17861, 288, 274, 67, 826, 532, 288, 274, 67, 1607, 283, 6655, 4504, 11, 50734], "temperature": 1.0, "avg_logprob": -3.3761886935763887, "compression_ratio": 1.485342019543974, "no_speech_prob": 0.09668353945016861}, {"id": 185, "seek": 110000, "start": 1107.4, "end": 1108.4, "text": " ond iawn uchddianiaeth.", "tokens": [50734, 322, 67, 20721, 895, 344, 339, 24810, 952, 654, 3293, 13, 50784], "temperature": 1.0, "avg_logprob": -3.3761886935763887, "compression_ratio": 1.485342019543974, "no_speech_prob": 0.09668353945016861}, {"id": 186, "seek": 110000, "start": 1108.86, "end": 1110.64, "text": " A hyngornau pa gydajiadau poddyn nhw,", "tokens": [50807, 316, 2477, 872, 284, 629, 84, 2502, 290, 6655, 29319, 345, 1459, 2497, 67, 2534, 6245, 86, 11, 50896], "temperature": 1.0, "avg_logprob": -3.3761886935763887, "compression_ratio": 1.485342019543974, "no_speech_prob": 0.09668353945016861}, {"id": 187, "seek": 110000, "start": 1110.64, "end": 1112.28, "text": " fe oedd dat\u30bawn i mewn \ub4e4thysgwydau,", "tokens": [50896, 579, 277, 38786, 1137, 29061, 895, 741, 385, 895, 6275, 392, 749, 70, 86, 6655, 1459, 11, 50978], "temperature": 1.0, "avg_logprob": -3.3761886935763887, "compression_ratio": 1.485342019543974, "no_speech_prob": 0.09668353945016861}, {"id": 188, "seek": 110000, "start": 1112.28, "end": 1114.36, "text": " ond yw'r gabbwn wedi tyw'r hyn fel hyn.", "tokens": [50978, 322, 67, 288, 86, 6, 81, 17964, 65, 895, 6393, 72, 1104, 86, 6, 81, 2477, 77, 11094, 2477, 77, 13, 51082], "temperature": 1.0, "avg_logprob": -3.3761886935763887, "compression_ratio": 1.485342019543974, "no_speech_prob": 0.09668353945016861}, {"id": 189, "seek": 110000, "start": 1114.36, "end": 1115.96, "text": " Roedd eich bod yn byth storiedd Ni,", "tokens": [51082, 3101, 38786, 308, 480, 16737, 17861, 538, 392, 5967, 1091, 67, 12370, 11, 51162], "temperature": 1.0, "avg_logprob": -3.3761886935763887, "compression_ratio": 1.485342019543974, "no_speech_prob": 0.09668353945016861}, {"id": 190, "seek": 110000, "start": 1115.96, "end": 1116.84, "text": " gallwn gweffordd Llan\u021biol,", "tokens": [51162, 8527, 895, 290, 826, 602, 765, 67, 441, 8658, 19999, 401, 11, 51206], "temperature": 1.0, "avg_logprob": -3.3761886935763887, "compression_ratio": 1.485342019543974, "no_speech_prob": 0.09668353945016861}, {"id": 191, "seek": 110000, "start": 1116.84, "end": 1118.66, "text": " yn annoto argyn adeg y dyn nhw,", "tokens": [51206, 17861, 25339, 78, 594, 1480, 77, 614, 1146, 288, 274, 2534, 6245, 86, 11, 51297], "temperature": 1.0, "avg_logprob": -3.3761886935763887, "compression_ratio": 1.485342019543974, "no_speech_prob": 0.09668353945016861}, {"id": 192, "seek": 110000, "start": 1118.66, "end": 1120.56, "text": " jydw i chi'n gweld dau ei Vaugh Cymru", "tokens": [51297, 361, 6655, 86, 741, 13228, 6, 77, 29255, 5957, 37359, 14020, 16822, 1984, 383, 4199, 894, 51392], "temperature": 1.0, "avg_logprob": -3.3761886935763887, "compression_ratio": 1.485342019543974, "no_speech_prob": 0.09668353945016861}, {"id": 193, "seek": 110000, "start": 1120.56, "end": 1122.06, "text": " pan wedi'i mewn ddwy \u0447\u0443\u0432\u0441\u0442\u0432io'r uradora", "tokens": [51392, 2462, 6393, 72, 6, 72, 385, 895, 274, 67, 9726, 29269, 1004, 6, 81, 4038, 23020, 51467], "temperature": 1.0, "avg_logprob": -3.3761886935763887, "compression_ratio": 1.485342019543974, "no_speech_prob": 0.09668353945016861}, {"id": 194, "seek": 112206, "start": 1122.06, "end": 1125.6599999999999, "text": " a chi ei i wneud nhw, contractorio dod yn besyaig unig....", "tokens": [50364, 257, 13228, 14020, 741, 261, 716, 532, 6245, 86, 11, 26463, 1004, 13886, 17861, 4097, 3016, 328, 517, 328, 2751, 50544], "temperature": 1.0, "avg_logprob": -3.70920654296875, "compression_ratio": 1.501466275659824, "no_speech_prob": 0.0035379778128117323}, {"id": 195, "seek": 112206, "start": 1125.6599999999999, "end": 1129.3999999999999, "text": " Yn ran gran stan o armwyhan gael y cyfre Ac i am Ym mhwyl un menos wedi radi.", "tokens": [50544, 398, 77, 5872, 9370, 27984, 277, 594, 76, 9726, 3451, 290, 4300, 288, 3185, 19325, 5097, 741, 669, 398, 76, 275, 71, 86, 5088, 517, 8902, 6393, 72, 2843, 72, 13, 50731], "temperature": 1.0, "avg_logprob": -3.70920654296875, "compression_ratio": 1.501466275659824, "no_speech_prob": 0.0035379778128117323}, {"id": 196, "seek": 112206, "start": 1129.3999999999999, "end": 1133.3799999999999, "text": " \uc598\ufffd yn reduction, ar\u8fbe, ac yn twrishna oedd\u2014", "tokens": [50731, 49441, 17861, 11004, 11, 594, 9830, 122, 11, 696, 17861, 683, 45643, 277, 38786, 2958, 50930], "temperature": 1.0, "avg_logprob": -3.70920654296875, "compression_ratio": 1.501466275659824, "no_speech_prob": 0.0035379778128117323}, {"id": 197, "seek": 112206, "start": 1133.3799999999999, "end": 1135.5, "text": " Foc lwy, rhaid i ni ddech durum sy'n gwneud hyn wediair?", "tokens": [50930, 479, 905, 287, 9726, 11, 367, 1641, 327, 741, 3867, 274, 1479, 339, 35218, 943, 6, 77, 29255, 716, 532, 2477, 77, 6393, 72, 1246, 30, 51036], "temperature": 1.0, "avg_logprob": -3.70920654296875, "compression_ratio": 1.501466275659824, "no_speech_prob": 0.0035379778128117323}, {"id": 198, "seek": 112206, "start": 1135.5, "end": 1138.6799999999998, "text": " F \u05d7os mae'n ym mwyng ym hefyd aran, lly, gan lly,", "tokens": [51036, 479, 12400, 329, 43783, 6, 77, 288, 76, 275, 9726, 872, 288, 76, 415, 69, 6655, 594, 282, 11, 4849, 88, 11, 7574, 4849, 88, 11, 51195], "temperature": 1.0, "avg_logprob": -3.70920654296875, "compression_ratio": 1.501466275659824, "no_speech_prob": 0.0035379778128117323}, {"id": 199, "seek": 112206, "start": 1138.6799999999998, "end": 1140.54, "text": " ein le incorrectolaeth ac mae geniat yn gyflwyfonol.", "tokens": [51195, 1343, 476, 18424, 4711, 3293, 696, 43783, 1049, 7676, 17861, 15823, 3423, 9726, 14338, 401, 13, 51288], "temperature": 1.0, "avg_logprob": -3.70920654296875, "compression_ratio": 1.501466275659824, "no_speech_prob": 0.0035379778128117323}, {"id": 200, "seek": 112206, "start": 1140.54, "end": 1143.7, "text": " Wrth byd storaheg ychydig hyn yn tw rhagol.", "tokens": [51288, 10159, 392, 538, 67, 5967, 545, 1146, 288, 339, 6655, 328, 2477, 77, 17861, 683, 33418, 559, 401, 13, 51446], "temperature": 1.0, "avg_logprob": -3.70920654296875, "compression_ratio": 1.501466275659824, "no_speech_prob": 0.0035379778128117323}, {"id": 201, "seek": 112206, "start": 1143.7, "end": 1145.5, "text": " Dw i roedd y cyflwybarth sydd pobl yn ysgrif,", "tokens": [51446, 41448, 741, 744, 38786, 288, 3185, 3423, 9726, 5356, 392, 943, 24810, 30548, 17861, 288, 82, 861, 351, 11, 51536], "temperature": 1.0, "avg_logprob": -3.70920654296875, "compression_ratio": 1.501466275659824, "no_speech_prob": 0.0035379778128117323}, {"id": 202, "seek": 112206, "start": 1145.5, "end": 1146.98, "text": " additive knowyne.", "tokens": [51536, 45558, 458, 88, 716, 13, 51610], "temperature": 1.0, "avg_logprob": -3.70920654296875, "compression_ratio": 1.501466275659824, "no_speech_prob": 0.0035379778128117323}, {"id": 203, "seek": 112206, "start": 1146.98, "end": 1148.54, "text": " Y\u30e3, fan eich rhaid iddo i chi'n wneud?", "tokens": [51610, 398, 17233, 11, 3429, 308, 480, 367, 1641, 327, 4496, 2595, 741, 13228, 6, 77, 261, 716, 532, 30, 51688], "temperature": 1.0, "avg_logprob": -3.70920654296875, "compression_ratio": 1.501466275659824, "no_speech_prob": 0.0035379778128117323}, {"id": 204, "seek": 114854, "start": 1148.54, "end": 1149.86, "text": " ac rongsydd.", "tokens": [50364, 696, 367, 556, 3187, 24810, 13, 50430], "temperature": 0.6000000000000001, "avg_logprob": -0.7626671068596117, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.04741993173956871}, {"id": 205, "seek": 114854, "start": 1149.86, "end": 1151.24, "text": " Should we flip back?", "tokens": [50430, 6454, 321, 7929, 646, 30, 50499], "temperature": 0.6000000000000001, "avg_logprob": -0.7626671068596117, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.04741993173956871}, {"id": 206, "seek": 114854, "start": 1151.24, "end": 1153.74, "text": " The answer is actually a trick question.", "tokens": [50499, 440, 1867, 307, 767, 257, 4282, 1168, 13, 50624], "temperature": 0.6000000000000001, "avg_logprob": -0.7626671068596117, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.04741993173956871}, {"id": 207, "seek": 114854, "start": 1153.74, "end": 1155.1, "text": " Sydd sydd ydych yn rhaglenau.", "tokens": [50624, 318, 34871, 943, 24810, 288, 3173, 339, 17861, 33418, 559, 6698, 1459, 13, 50692], "temperature": 0.6000000000000001, "avg_logprob": -0.7626671068596117, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.04741993173956871}, {"id": 208, "seek": 114854, "start": 1155.1, "end": 1158.12, "text": " Most of you were in fact right.", "tokens": [50692, 4534, 295, 291, 645, 294, 1186, 558, 13, 50843], "temperature": 0.6000000000000001, "avg_logprob": -0.7626671068596117, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.04741993173956871}, {"id": 209, "seek": 114854, "start": 1158.12, "end": 1162.1399999999999, "text": " But if you take a glance at this, this is getting really, really good.", "tokens": [50843, 583, 498, 291, 747, 257, 21094, 412, 341, 11, 341, 307, 1242, 534, 11, 534, 665, 13, 51044], "temperature": 0.6000000000000001, "avg_logprob": -0.7626671068596117, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.04741993173956871}, {"id": 210, "seek": 114854, "start": 1162.1399999999999, "end": 1167.46, "text": " This is just a taste of the images that we might see down the line.", "tokens": [51044, 639, 307, 445, 257, 3939, 295, 264, 5267, 300, 321, 1062, 536, 760, 264, 1622, 13, 51310], "temperature": 0.6000000000000001, "avg_logprob": -0.7626671068596117, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.04741993173956871}, {"id": 211, "seek": 114854, "start": 1167.46, "end": 1172.54, "text": " In fact, that video with which we began, Tom Cruise,", "tokens": [51310, 682, 1186, 11, 300, 960, 365, 597, 321, 4283, 11, 5041, 39165, 11, 51564], "temperature": 0.6000000000000001, "avg_logprob": -0.7626671068596117, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.04741993173956871}, {"id": 212, "seek": 114854, "start": 1172.54, "end": 1174.6599999999999, "text": " as you might have gleaned, was not in fact Tom Cruise.", "tokens": [51564, 382, 291, 1062, 362, 290, 28499, 292, 11, 390, 406, 294, 1186, 5041, 39165, 13, 51670], "temperature": 0.6000000000000001, "avg_logprob": -0.7626671068596117, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.04741993173956871}, {"id": 213, "seek": 114854, "start": 1174.6599999999999, "end": 1176.34, "text": " That was an example of a deep fake.", "tokens": [51670, 663, 390, 364, 1365, 295, 257, 2452, 7592, 13, 51754], "temperature": 0.6000000000000001, "avg_logprob": -0.7626671068596117, "compression_ratio": 1.6053639846743295, "no_speech_prob": 0.04741993173956871}, {"id": 214, "seek": 117634, "start": 1176.34, "end": 1189.5, "text": " y pwysig yn cynllunio ni awdd dependydd yr animal ar", "tokens": [50364, 288, 280, 86, 749, 328, 17861, 28365, 285, 409, 1004, 3867, 1714, 24810, 5672, 34871, 37739, 5496, 594, 51022], "temperature": 1.0, "avg_logprob": -3.5021344353170956, "compression_ratio": 1.3609467455621302, "no_speech_prob": 0.032584793865680695}, {"id": 215, "seek": 117634, "start": 1189.5, "end": 1197.08, "text": " dd pawn hych Cymru i wneud o ddeallurio ysgol yn ymwinell, iddyn nhw senseid gyntaf,", "tokens": [51022, 274, 67, 38959, 77, 2477, 339, 383, 4199, 894, 741, 261, 716, 532, 277, 274, 1479, 336, 374, 1004, 288, 82, 70, 401, 17861, 288, 76, 86, 533, 285, 11, 4496, 67, 2534, 6245, 86, 2020, 327, 15823, 580, 2792, 11, 51401], "temperature": 1.0, "avg_logprob": -3.5021344353170956, "compression_ratio": 1.3609467455621302, "no_speech_prob": 0.032584793865680695}, {"id": 216, "seek": 117634, "start": 1197.08, "end": 1203.78, "text": " acredwch chi'n ymdd\u6837di mats, ac ymatebai hawdd a gw Spin chefiau ar gyfer y cympael tyfan,", "tokens": [51401, 34548, 86, 339, 13228, 6, 77, 288, 76, 24810, 14496, 4504, 43366, 11, 696, 288, 13963, 65, 1301, 33634, 24810, 257, 29255, 29185, 10530, 45274, 594, 15823, 612, 288, 3185, 2455, 4300, 1104, 20361, 11, 51736], "temperature": 1.0, "avg_logprob": -3.5021344353170956, "compression_ratio": 1.3609467455621302, "no_speech_prob": 0.032584793865680695}, {"id": 217, "seek": 120378, "start": 1203.78, "end": 1205.82, "text": " C' webcam cyf Suzuki yn go iawn gyfo'r ffonduddau.", "tokens": [50364, 383, 6, 39490, 3185, 69, 49457, 17861, 352, 20721, 895, 15823, 16931, 6, 81, 283, 69, 684, 26656, 1459, 13, 50466], "temperature": 1.0, "avg_logprob": -3.8378946940104166, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.018261440098285675}, {"id": 218, "seek": 120378, "start": 1205.82, "end": 1209.6399999999999, "text": " Mae'n cyfattifiwch ar gyfyrdd glansian iawn sou \u0430\u0440 fyrdd gan gyfodd yn teitl", "tokens": [50466, 31055, 6, 77, 3185, 69, 1591, 17638, 86, 339, 594, 15823, 69, 6016, 24810, 1563, 599, 952, 20721, 895, 6926, 16643, 283, 6016, 24810, 7574, 15823, 69, 378, 67, 17861, 535, 270, 75, 50657], "temperature": 1.0, "avg_logprob": -3.8378946940104166, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.018261440098285675}, {"id": 219, "seek": 120378, "start": 1209.66, "end": 1212.02, "text": " a'r cyffredin siarad hen yn bod \u0440\u0430\u0441wylol ein scrydd.", "tokens": [50658, 257, 6, 81, 3185, 602, 986, 259, 1511, 289, 345, 22253, 17861, 16737, 7459, 86, 5088, 401, 1343, 795, 627, 24810, 13, 50776], "temperature": 1.0, "avg_logprob": -3.8378946940104166, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.018261440098285675}, {"id": 220, "seek": 120378, "start": 1212.04, "end": 1215.6, "text": " A o ran dod dyn ni'n mynd i, wr hefyd yr un oed fel oedd hyn sy'n mynd", "tokens": [50777, 316, 277, 5872, 13886, 274, 2534, 3867, 6, 77, 452, 273, 741, 11, 928, 415, 69, 6655, 37739, 517, 277, 292, 11094, 277, 38786, 2477, 77, 943, 6, 77, 452, 273, 50955], "temperature": 1.0, "avg_logprob": -3.8378946940104166, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.018261440098285675}, {"id": 221, "seek": 120378, "start": 1215.6, "end": 1217.34, "text": " hun yma dy Grant-G\u8dd1.", "tokens": [50955, 7396, 288, 1696, 14584, 17529, 12, 38, 32585, 13, 51042], "temperature": 1.0, "avg_logprob": -3.8378946940104166, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.018261440098285675}, {"id": 222, "seek": 120378, "start": 1217.34, "end": 1221.2, "text": " Gbi ddangosubbyd ddod ei bod pob dw'i s\ufffd\ufffd o \u0444 pas ac rwy'r psychologist", "tokens": [51042, 460, 5614, 274, 67, 656, 329, 35654, 67, 274, 67, 378, 14020, 16737, 714, 65, 27379, 6, 72, 262, 9520, 277, 4394, 1736, 696, 367, 9726, 6, 81, 29514, 51235], "temperature": 1.0, "avg_logprob": -3.8378946940104166, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.018261440098285675}, {"id": 223, "seek": 120378, "start": 1221.22, "end": 1226.04, "text": " e'n mynd i glawethe ledd yn credu drwy wideg a threatensie gyda history.", "tokens": [51236, 308, 6, 77, 452, 273, 741, 290, 5901, 302, 675, 4684, 67, 17861, 1197, 769, 1224, 9726, 4874, 70, 257, 47511, 414, 15823, 2675, 2503, 13, 51477], "temperature": 1.0, "avg_logprob": -3.8378946940104166, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.018261440098285675}, {"id": 224, "seek": 120378, "start": 1226.04, "end": 1229.92, "text": " Felly mae'i dde'i arferwad iddyn ni'n gemddol advertisements neu tradd\u043d\u0434au summar.", "tokens": [51477, 479, 7442, 43783, 6, 72, 274, 1479, 6, 72, 594, 612, 86, 345, 4496, 67, 2534, 3867, 6, 77, 7173, 24810, 401, 42897, 22510, 2479, 67, 43485, 1459, 14611, 13, 51671], "temperature": 1.0, "avg_logprob": -3.8378946940104166, "compression_ratio": 1.4831460674157304, "no_speech_prob": 0.018261440098285675}, {"id": 225, "seek": 122992, "start": 1229.92, "end": 1234.28, "text": " beth ddechrau hyn \u00e8l aen ni f\u591cnwyr gallwch chi wedi", "tokens": [50364, 778, 71, 274, 1479, 339, 48907, 2477, 77, 4873, 75, 257, 268, 3867, 283, 30124, 77, 86, 6016, 8527, 86, 339, 13228, 6393, 72, 50582], "temperature": 1.0, "avg_logprob": -4.2648611495743936, "compression_ratio": 1.3136363636363637, "no_speech_prob": 0.021944643929600716}, {"id": 226, "seek": 122992, "start": 1234.28, "end": 1238.22, "text": " derbyn rhwun arna Diolch i dda'r rywun ynhlulu.", "tokens": [50582, 1163, 2322, 77, 33418, 86, 409, 594, 629, 8789, 401, 339, 741, 274, 2675, 6, 81, 20791, 86, 409, 288, 5728, 75, 12845, 13, 50779], "temperature": 1.0, "avg_logprob": -4.2648611495743936, "compression_ratio": 1.3136363636363637, "no_speech_prob": 0.021944643929600716}, {"id": 227, "seek": 122992, "start": 1238.22, "end": 1240.94, "text": " Panyluk \u2026", "tokens": [50779, 430, 1325, 42563, 5799, 50915], "temperature": 1.0, "avg_logprob": -4.2648611495743936, "compression_ratio": 1.3136363636363637, "no_speech_prob": 0.021944643929600716}, {"id": 228, "seek": 122992, "start": 1240.94, "end": 1243.16, "text": " associate", "tokens": [50915, 14644, 51026], "temperature": 1.0, "avg_logprob": -4.2648611495743936, "compression_ratio": 1.3136363636363637, "no_speech_prob": 0.021944643929600716}, {"id": 229, "seek": 122992, "start": 1243.16, "end": 1246.02, "text": " Si haf pa tro dda pa sy'n fawr, y cymdeilydd hearr.", "tokens": [51026, 4909, 324, 69, 2502, 4495, 274, 2675, 2502, 943, 6, 77, 283, 1607, 81, 11, 288, 3185, 76, 1479, 388, 34871, 1568, 81, 13, 51169], "temperature": 1.0, "avg_logprob": -4.2648611495743936, "compression_ratio": 1.3136363636363637, "no_speech_prob": 0.021944643929600716}, {"id": 230, "seek": 122992, "start": 1246.02, "end": 1248.18, "text": " Mae mae'r sgiliau hynny, darn byn heb.", "tokens": [51169, 31055, 43783, 6, 81, 262, 70, 24169, 84, 2477, 77, 1634, 11, 29063, 538, 77, 8007, 13, 51277], "temperature": 1.0, "avg_logprob": -4.2648611495743936, "compression_ratio": 1.3136363636363637, "no_speech_prob": 0.021944643929600716}, {"id": 231, "seek": 122992, "start": 1248.18, "end": 1250.78, "text": " Dyna, a'igusach,", "tokens": [51277, 31193, 629, 11, 257, 6, 72, 21956, 608, 11, 51407], "temperature": 1.0, "avg_logprob": -4.2648611495743936, "compression_ratio": 1.3136363636363637, "no_speech_prob": 0.021944643929600716}, {"id": 232, "seek": 122992, "start": 1252.0800000000002, "end": 1255.54, "text": " I pan c Intelligence leader C rond zatblade cych studio.", "tokens": [51472, 286, 2462, 269, 27274, 5263, 383, 39353, 35802, 41825, 3185, 339, 6811, 13, 51645], "temperature": 1.0, "avg_logprob": -4.2648611495743936, "compression_ratio": 1.3136363636363637, "no_speech_prob": 0.021944643929600716}, {"id": 233, "seek": 125554, "start": 1255.54, "end": 1259.54, "text": " As we eat, we chat and laugh and catch up on each other's day, dot, dot, dot.", "tokens": [50364, 1018, 321, 1862, 11, 321, 5081, 293, 5801, 293, 3745, 493, 322, 1184, 661, 311, 786, 11, 5893, 11, 5893, 11, 5893, 13, 50564], "temperature": 0.0, "avg_logprob": -0.17067441073330966, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.16445298492908478}, {"id": 234, "seek": 125554, "start": 1259.54, "end": 1260.54, "text": " SA2.", "tokens": [50564, 16482, 17, 13, 50614], "temperature": 0.0, "avg_logprob": -0.17067441073330966, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.16445298492908478}, {"id": 235, "seek": 125554, "start": 1260.54, "end": 1263.54, "text": " My mother packs me a sandwich, a drink, fruit, and a treat.", "tokens": [50614, 1222, 2895, 19403, 385, 257, 11141, 11, 257, 2822, 11, 6773, 11, 293, 257, 2387, 13, 50764], "temperature": 0.0, "avg_logprob": -0.17067441073330966, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.16445298492908478}, {"id": 236, "seek": 125554, "start": 1263.54, "end": 1266.54, "text": " When I get in the lunchroom, I find an empty table and sit there and I eat my lunch.", "tokens": [50764, 1133, 286, 483, 294, 264, 6349, 2861, 11, 286, 915, 364, 6707, 3199, 293, 1394, 456, 293, 286, 1862, 452, 6349, 13, 50914], "temperature": 0.0, "avg_logprob": -0.17067441073330966, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.16445298492908478}, {"id": 237, "seek": 125554, "start": 1266.54, "end": 1269.54, "text": " My friends come and sit down with me, dot, dot, dot.", "tokens": [50914, 1222, 1855, 808, 293, 1394, 760, 365, 385, 11, 5893, 11, 5893, 11, 5893, 13, 51064], "temperature": 0.0, "avg_logprob": -0.17067441073330966, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.16445298492908478}, {"id": 238, "seek": 125554, "start": 1269.54, "end": 1271.54, "text": " Runkshin, should we see what folks think?", "tokens": [51064, 8950, 1694, 10876, 11, 820, 321, 536, 437, 4024, 519, 30, 51164], "temperature": 0.0, "avg_logprob": -0.17067441073330966, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.16445298492908478}, {"id": 239, "seek": 125554, "start": 1271.54, "end": 1276.54, "text": " It looks like most of you think that SA1 was generated by AI.", "tokens": [51164, 467, 1542, 411, 881, 295, 291, 519, 300, 16482, 16, 390, 10833, 538, 7318, 13, 51414], "temperature": 0.0, "avg_logprob": -0.17067441073330966, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.16445298492908478}, {"id": 240, "seek": 125554, "start": 1276.54, "end": 1282.54, "text": " And in fact, if we flip back to the answer here, it was in fact SA1.", "tokens": [51414, 400, 294, 1186, 11, 498, 321, 7929, 646, 281, 264, 1867, 510, 11, 309, 390, 294, 1186, 16482, 16, 13, 51714], "temperature": 0.0, "avg_logprob": -0.17067441073330966, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.16445298492908478}, {"id": 241, "seek": 128254, "start": 1283.54, "end": 1287.54, "text": " So it's great that we now already have seemingly this discerning eye,", "tokens": [50414, 407, 309, 311, 869, 300, 321, 586, 1217, 362, 18709, 341, 717, 1776, 773, 3313, 11, 50614], "temperature": 0.0, "avg_logprob": -0.08875439848218646, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0145005127415061}, {"id": 242, "seek": 128254, "start": 1287.54, "end": 1292.54, "text": " but let me perhaps deflate that enthusiasm by saying it's only going to get harder", "tokens": [50614, 457, 718, 385, 4317, 1060, 17593, 300, 23417, 538, 1566, 309, 311, 787, 516, 281, 483, 6081, 50864], "temperature": 0.0, "avg_logprob": -0.08875439848218646, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0145005127415061}, {"id": 243, "seek": 128254, "start": 1292.54, "end": 1294.54, "text": " to discern one from the other.", "tokens": [50864, 281, 30868, 472, 490, 264, 661, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08875439848218646, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0145005127415061}, {"id": 244, "seek": 128254, "start": 1294.54, "end": 1297.54, "text": " And we're really now on the bleeding edge of what's soon to be possible.", "tokens": [50964, 400, 321, 434, 534, 586, 322, 264, 19312, 4691, 295, 437, 311, 2321, 281, 312, 1944, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08875439848218646, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0145005127415061}, {"id": 245, "seek": 128254, "start": 1297.54, "end": 1301.54, "text": " But most everyone in this room has probably by now seen, tried,", "tokens": [51114, 583, 881, 1518, 294, 341, 1808, 575, 1391, 538, 586, 1612, 11, 3031, 11, 51314], "temperature": 0.0, "avg_logprob": -0.08875439848218646, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0145005127415061}, {"id": 246, "seek": 128254, "start": 1301.54, "end": 1305.54, "text": " certainly heard of ChatGPT, which is all about textual generation.", "tokens": [51314, 3297, 2198, 295, 27503, 38, 47, 51, 11, 597, 307, 439, 466, 2487, 901, 5125, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08875439848218646, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0145005127415061}, {"id": 247, "seek": 128254, "start": 1305.54, "end": 1308.54, "text": " Within CS50 and within academia more generally,", "tokens": [51514, 15996, 9460, 2803, 293, 1951, 28937, 544, 5101, 11, 51664], "temperature": 0.0, "avg_logprob": -0.08875439848218646, "compression_ratio": 1.5818181818181818, "no_speech_prob": 0.0145005127415061}, {"id": 248, "seek": 130854, "start": 1308.54, "end": 1311.54, "text": " have we been thinking about, talking about, how, whether to use", "tokens": [50364, 362, 321, 668, 1953, 466, 11, 1417, 466, 11, 577, 11, 1968, 281, 764, 50514], "temperature": 0.0, "avg_logprob": -0.0772010326385498, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.007120938040316105}, {"id": 249, "seek": 130854, "start": 1311.54, "end": 1313.54, "text": " or not use these kinds of technologies.", "tokens": [50514, 420, 406, 764, 613, 3685, 295, 7943, 13, 50614], "temperature": 0.0, "avg_logprob": -0.0772010326385498, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.007120938040316105}, {"id": 250, "seek": 130854, "start": 1313.54, "end": 1316.54, "text": " And if the students in the room haven't told the family members in the room already,", "tokens": [50614, 400, 498, 264, 1731, 294, 264, 1808, 2378, 380, 1907, 264, 1605, 2679, 294, 264, 1808, 1217, 11, 50764], "temperature": 0.0, "avg_logprob": -0.0772010326385498, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.007120938040316105}, {"id": 251, "seek": 130854, "start": 1316.54, "end": 1319.54, "text": " this here is an excerpt from CS50's own syllabus this year,", "tokens": [50764, 341, 510, 307, 364, 42760, 662, 490, 9460, 2803, 311, 1065, 48077, 341, 1064, 11, 50914], "temperature": 0.0, "avg_logprob": -0.0772010326385498, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.007120938040316105}, {"id": 252, "seek": 130854, "start": 1319.54, "end": 1324.54, "text": " whereby we have deemed tools like ChatGPT in their current form just too helpful.", "tokens": [50914, 36998, 321, 362, 27637, 3873, 411, 27503, 38, 47, 51, 294, 641, 2190, 1254, 445, 886, 4961, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0772010326385498, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.007120938040316105}, {"id": 253, "seek": 130854, "start": 1324.54, "end": 1326.54, "text": " Sort of like an overzealous friend who, in school,", "tokens": [51164, 26149, 295, 411, 364, 670, 1381, 11553, 1277, 567, 11, 294, 1395, 11, 51264], "temperature": 0.0, "avg_logprob": -0.0772010326385498, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.007120938040316105}, {"id": 254, "seek": 130854, "start": 1326.54, "end": 1329.54, "text": " just wants to give you all of the answers instead of leading you to them.", "tokens": [51264, 445, 2738, 281, 976, 291, 439, 295, 264, 6338, 2602, 295, 5775, 291, 281, 552, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0772010326385498, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.007120938040316105}, {"id": 255, "seek": 130854, "start": 1329.54, "end": 1336.54, "text": " And so we simply prohibit by policy using AI-based software such as ChatGPT,", "tokens": [51414, 400, 370, 321, 2935, 16015, 270, 538, 3897, 1228, 7318, 12, 6032, 4722, 1270, 382, 27503, 38, 47, 51, 11, 51764], "temperature": 0.0, "avg_logprob": -0.0772010326385498, "compression_ratio": 1.6419753086419753, "no_speech_prob": 0.007120938040316105}, {"id": 256, "seek": 133654, "start": 1336.54, "end": 1339.54, "text": " third-party tools like GitHub Co-Pilot, Bing Chat, and others,", "tokens": [50364, 2636, 12, 23409, 3873, 411, 23331, 3066, 12, 47, 31516, 11, 30755, 27503, 11, 293, 2357, 11, 50514], "temperature": 0.0, "avg_logprob": -0.08058881395645724, "compression_ratio": 1.567398119122257, "no_speech_prob": 0.009125003591179848}, {"id": 257, "seek": 133654, "start": 1339.54, "end": 1343.54, "text": " that suggests or completes answers to questions or lines of code.", "tokens": [50514, 300, 13409, 420, 36362, 6338, 281, 1651, 420, 3876, 295, 3089, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08058881395645724, "compression_ratio": 1.567398119122257, "no_speech_prob": 0.009125003591179848}, {"id": 258, "seek": 133654, "start": 1343.54, "end": 1347.54, "text": " But it would seem reactionary to take away what technology surely has", "tokens": [50714, 583, 309, 576, 1643, 5480, 822, 281, 747, 1314, 437, 2899, 11468, 575, 50914], "temperature": 0.0, "avg_logprob": -0.08058881395645724, "compression_ratio": 1.567398119122257, "no_speech_prob": 0.009125003591179848}, {"id": 259, "seek": 133654, "start": 1347.54, "end": 1349.54, "text": " some potential upsides for education.", "tokens": [50914, 512, 3995, 15497, 1875, 337, 3309, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08058881395645724, "compression_ratio": 1.567398119122257, "no_speech_prob": 0.009125003591179848}, {"id": 260, "seek": 133654, "start": 1349.54, "end": 1352.54, "text": " And so within CS50 this semester, as well as this past summer,", "tokens": [51014, 400, 370, 1951, 9460, 2803, 341, 11894, 11, 382, 731, 382, 341, 1791, 4266, 11, 51164], "temperature": 0.0, "avg_logprob": -0.08058881395645724, "compression_ratio": 1.567398119122257, "no_speech_prob": 0.009125003591179848}, {"id": 261, "seek": 133654, "start": 1352.54, "end": 1356.54, "text": " have we allowed students to use CS50's own AI-based software,", "tokens": [51164, 362, 321, 4350, 1731, 281, 764, 9460, 2803, 311, 1065, 7318, 12, 6032, 4722, 11, 51364], "temperature": 0.0, "avg_logprob": -0.08058881395645724, "compression_ratio": 1.567398119122257, "no_speech_prob": 0.009125003591179848}, {"id": 262, "seek": 133654, "start": 1356.54, "end": 1359.54, "text": " which are in effect, as we'll discuss, built on top of these third-party tools,", "tokens": [51364, 597, 366, 294, 1802, 11, 382, 321, 603, 2248, 11, 3094, 322, 1192, 295, 613, 2636, 12, 23409, 3873, 11, 51514], "temperature": 0.0, "avg_logprob": -0.08058881395645724, "compression_ratio": 1.567398119122257, "no_speech_prob": 0.009125003591179848}, {"id": 263, "seek": 133654, "start": 1359.54, "end": 1363.54, "text": " ChatGPT from open AI, companies like Microsoft and beyond.", "tokens": [51514, 27503, 38, 47, 51, 490, 1269, 7318, 11, 3431, 411, 8116, 293, 4399, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08058881395645724, "compression_ratio": 1.567398119122257, "no_speech_prob": 0.009125003591179848}, {"id": 264, "seek": 136354, "start": 1363.54, "end": 1367.54, "text": " And in fact, what students can now use is this brought-to-life CS50 duck,", "tokens": [50364, 400, 294, 1186, 11, 437, 1731, 393, 586, 764, 307, 341, 3038, 12, 1353, 12, 9073, 9460, 2803, 12482, 11, 50564], "temperature": 0.0, "avg_logprob": -0.10610931659566945, "compression_ratio": 1.6970684039087949, "no_speech_prob": 0.007576768286526203}, {"id": 265, "seek": 136354, "start": 1367.54, "end": 1372.54, "text": " or DDB, duck debugger within a website of our own, CS50.ai,", "tokens": [50564, 420, 30778, 33, 11, 12482, 24083, 1321, 1951, 257, 3144, 295, 527, 1065, 11, 9460, 2803, 13, 1301, 11, 50814], "temperature": 0.0, "avg_logprob": -0.10610931659566945, "compression_ratio": 1.6970684039087949, "no_speech_prob": 0.007576768286526203}, {"id": 266, "seek": 136354, "start": 1372.54, "end": 1375.54, "text": " and another that your students know known as CS50.dev.", "tokens": [50814, 293, 1071, 300, 428, 1731, 458, 2570, 382, 9460, 2803, 13, 40343, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10610931659566945, "compression_ratio": 1.6970684039087949, "no_speech_prob": 0.007576768286526203}, {"id": 267, "seek": 136354, "start": 1375.54, "end": 1379.54, "text": " So students are using it, but in a way where we have tempered the enthusiasm", "tokens": [50964, 407, 1731, 366, 1228, 309, 11, 457, 294, 257, 636, 689, 321, 362, 3393, 292, 264, 23417, 51164], "temperature": 0.0, "avg_logprob": -0.10610931659566945, "compression_ratio": 1.6970684039087949, "no_speech_prob": 0.007576768286526203}, {"id": 268, "seek": 136354, "start": 1379.54, "end": 1381.54, "text": " of what might otherwise be an overly helpful duck", "tokens": [51164, 295, 437, 1062, 5911, 312, 364, 24324, 4961, 12482, 51264], "temperature": 0.0, "avg_logprob": -0.10610931659566945, "compression_ratio": 1.6970684039087949, "no_speech_prob": 0.007576768286526203}, {"id": 269, "seek": 136354, "start": 1381.54, "end": 1383.54, "text": " to model it more akin to a good teacher,", "tokens": [51264, 281, 2316, 309, 544, 47540, 281, 257, 665, 5027, 11, 51364], "temperature": 0.0, "avg_logprob": -0.10610931659566945, "compression_ratio": 1.6970684039087949, "no_speech_prob": 0.007576768286526203}, {"id": 270, "seek": 136354, "start": 1383.54, "end": 1386.54, "text": " a good teaching fellow who might guide you to the answers,", "tokens": [51364, 257, 665, 4571, 7177, 567, 1062, 5934, 291, 281, 264, 6338, 11, 51514], "temperature": 0.0, "avg_logprob": -0.10610931659566945, "compression_ratio": 1.6970684039087949, "no_speech_prob": 0.007576768286526203}, {"id": 271, "seek": 136354, "start": 1386.54, "end": 1388.54, "text": " but not simply hand them outright.", "tokens": [51514, 457, 406, 2935, 1011, 552, 35189, 13, 51614], "temperature": 0.0, "avg_logprob": -0.10610931659566945, "compression_ratio": 1.6970684039087949, "no_speech_prob": 0.007576768286526203}, {"id": 272, "seek": 136354, "start": 1388.54, "end": 1389.54, "text": " So what does that actually mean?", "tokens": [51614, 407, 437, 775, 300, 767, 914, 30, 51664], "temperature": 0.0, "avg_logprob": -0.10610931659566945, "compression_ratio": 1.6970684039087949, "no_speech_prob": 0.007576768286526203}, {"id": 273, "seek": 136354, "start": 1389.54, "end": 1391.54, "text": " And in what form does this duck come?", "tokens": [51664, 400, 294, 437, 1254, 775, 341, 12482, 808, 30, 51764], "temperature": 0.0, "avg_logprob": -0.10610931659566945, "compression_ratio": 1.6970684039087949, "no_speech_prob": 0.007576768286526203}, {"id": 274, "seek": 139154, "start": 1391.54, "end": 1394.54, "text": " Well, architecturally, for those of you with engineering backgrounds,", "tokens": [50364, 1042, 11, 6331, 6512, 11, 337, 729, 295, 291, 365, 7043, 17336, 11, 50514], "temperature": 0.0, "avg_logprob": -0.07312769360012478, "compression_ratio": 1.6257668711656441, "no_speech_prob": 0.002800688147544861}, {"id": 275, "seek": 139154, "start": 1394.54, "end": 1396.54, "text": " they might be curious as to how this is actually implemented.", "tokens": [50514, 436, 1062, 312, 6369, 382, 281, 577, 341, 307, 767, 12270, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07312769360012478, "compression_ratio": 1.6257668711656441, "no_speech_prob": 0.002800688147544861}, {"id": 276, "seek": 139154, "start": 1396.54, "end": 1400.54, "text": " If a student here in the class has a question virtually in this case,", "tokens": [50614, 759, 257, 3107, 510, 294, 264, 1508, 575, 257, 1168, 14103, 294, 341, 1389, 11, 50814], "temperature": 0.0, "avg_logprob": -0.07312769360012478, "compression_ratio": 1.6257668711656441, "no_speech_prob": 0.002800688147544861}, {"id": 277, "seek": 139154, "start": 1400.54, "end": 1405.54, "text": " they somehow ask these questions of this central web application, CS50.ai.", "tokens": [50814, 436, 6063, 1029, 613, 1651, 295, 341, 5777, 3670, 3861, 11, 9460, 2803, 13, 1301, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07312769360012478, "compression_ratio": 1.6257668711656441, "no_speech_prob": 0.002800688147544861}, {"id": 278, "seek": 139154, "start": 1405.54, "end": 1409.54, "text": " But we, in turn, have built much of our own logic on top of third-party services", "tokens": [51064, 583, 321, 11, 294, 1261, 11, 362, 3094, 709, 295, 527, 1065, 9952, 322, 1192, 295, 2636, 12, 23409, 3328, 51264], "temperature": 0.0, "avg_logprob": -0.07312769360012478, "compression_ratio": 1.6257668711656441, "no_speech_prob": 0.002800688147544861}, {"id": 279, "seek": 139154, "start": 1409.54, "end": 1413.54, "text": " known as APIs, application programming interfaces,", "tokens": [51264, 2570, 382, 21445, 11, 3861, 9410, 28416, 11, 51464], "temperature": 0.0, "avg_logprob": -0.07312769360012478, "compression_ratio": 1.6257668711656441, "no_speech_prob": 0.002800688147544861}, {"id": 280, "seek": 139154, "start": 1413.54, "end": 1416.54, "text": " features that other companies provide that people like us can use", "tokens": [51464, 4122, 300, 661, 3431, 2893, 300, 561, 411, 505, 393, 764, 51614], "temperature": 0.0, "avg_logprob": -0.07312769360012478, "compression_ratio": 1.6257668711656441, "no_speech_prob": 0.002800688147544861}, {"id": 281, "seek": 139154, "start": 1416.54, "end": 1419.54, "text": " so as they are doing really a lot of the heavy lifting.", "tokens": [51614, 370, 382, 436, 366, 884, 534, 257, 688, 295, 264, 4676, 15798, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07312769360012478, "compression_ratio": 1.6257668711656441, "no_speech_prob": 0.002800688147544861}, {"id": 282, "seek": 141954, "start": 1419.54, "end": 1421.54, "text": " The so-called large language models are there.", "tokens": [50364, 440, 370, 12, 11880, 2416, 2856, 5245, 366, 456, 13, 50464], "temperature": 0.0, "avg_logprob": -0.055564688964628836, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0039452435448765755}, {"id": 283, "seek": 141954, "start": 1421.54, "end": 1424.54, "text": " But we, too, have information that is not in these models yet.", "tokens": [50464, 583, 321, 11, 886, 11, 362, 1589, 300, 307, 406, 294, 613, 5245, 1939, 13, 50614], "temperature": 0.0, "avg_logprob": -0.055564688964628836, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0039452435448765755}, {"id": 284, "seek": 141954, "start": 1424.54, "end": 1427.54, "text": " For instance, the words that came out of my mouth just last week", "tokens": [50614, 1171, 5197, 11, 264, 2283, 300, 1361, 484, 295, 452, 4525, 445, 1036, 1243, 50764], "temperature": 0.0, "avg_logprob": -0.055564688964628836, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0039452435448765755}, {"id": 285, "seek": 141954, "start": 1427.54, "end": 1429.54, "text": " when we had a lecture on some other topic,", "tokens": [50764, 562, 321, 632, 257, 7991, 322, 512, 661, 4829, 11, 50864], "temperature": 0.0, "avg_logprob": -0.055564688964628836, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0039452435448765755}, {"id": 286, "seek": 141954, "start": 1429.54, "end": 1433.54, "text": " not to mention all of the past lectures and homework assignments from this year.", "tokens": [50864, 406, 281, 2152, 439, 295, 264, 1791, 16564, 293, 14578, 22546, 490, 341, 1064, 13, 51064], "temperature": 0.0, "avg_logprob": -0.055564688964628836, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0039452435448765755}, {"id": 287, "seek": 141954, "start": 1433.54, "end": 1437.54, "text": " So we have our own vector database locally via which we can search", "tokens": [51064, 407, 321, 362, 527, 1065, 8062, 8149, 16143, 5766, 597, 321, 393, 3164, 51264], "temperature": 0.0, "avg_logprob": -0.055564688964628836, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0039452435448765755}, {"id": 288, "seek": 141954, "start": 1437.54, "end": 1441.54, "text": " for more recent information and then hand some of that information into these models,", "tokens": [51264, 337, 544, 5162, 1589, 293, 550, 1011, 512, 295, 300, 1589, 666, 613, 5245, 11, 51464], "temperature": 0.0, "avg_logprob": -0.055564688964628836, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0039452435448765755}, {"id": 289, "seek": 141954, "start": 1441.54, "end": 1443.54, "text": " which you might recall, at least for open AI,", "tokens": [51464, 597, 291, 1062, 9901, 11, 412, 1935, 337, 1269, 7318, 11, 51564], "temperature": 0.0, "avg_logprob": -0.055564688964628836, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0039452435448765755}, {"id": 290, "seek": 141954, "start": 1443.54, "end": 1448.54, "text": " is cut off as of 2021, as of now, to make the information even more current.", "tokens": [51564, 307, 1723, 766, 382, 295, 7201, 11, 382, 295, 586, 11, 281, 652, 264, 1589, 754, 544, 2190, 13, 51814], "temperature": 0.0, "avg_logprob": -0.055564688964628836, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.0039452435448765755}, {"id": 291, "seek": 144854, "start": 1448.54, "end": 1450.54, "text": " So architecturally, that's sort of the flow.", "tokens": [50364, 407, 6331, 6512, 11, 300, 311, 1333, 295, 264, 3095, 13, 50464], "temperature": 0.0, "avg_logprob": -0.07164345078795921, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.000882984371855855}, {"id": 292, "seek": 144854, "start": 1450.54, "end": 1455.54, "text": " But for now, I thought I'd share at a higher level what it is your students are already familiar with", "tokens": [50464, 583, 337, 586, 11, 286, 1194, 286, 1116, 2073, 412, 257, 2946, 1496, 437, 309, 307, 428, 1731, 366, 1217, 4963, 365, 50714], "temperature": 0.0, "avg_logprob": -0.07164345078795921, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.000882984371855855}, {"id": 293, "seek": 144854, "start": 1455.54, "end": 1459.54, "text": " and what will soon be more broadly available to our own students online as well.", "tokens": [50714, 293, 437, 486, 2321, 312, 544, 19511, 2435, 281, 527, 1065, 1731, 2950, 382, 731, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07164345078795921, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.000882984371855855}, {"id": 294, "seek": 144854, "start": 1459.54, "end": 1463.54, "text": " So what we've focused on is what's generally now known as prompt engineering,", "tokens": [50914, 407, 437, 321, 600, 5178, 322, 307, 437, 311, 5101, 586, 2570, 382, 12391, 7043, 11, 51114], "temperature": 0.0, "avg_logprob": -0.07164345078795921, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.000882984371855855}, {"id": 295, "seek": 144854, "start": 1463.54, "end": 1467.54, "text": " which isn't really a technical phrase because it's not so much engineering", "tokens": [51114, 597, 1943, 380, 534, 257, 6191, 9535, 570, 309, 311, 406, 370, 709, 7043, 51314], "temperature": 0.0, "avg_logprob": -0.07164345078795921, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.000882984371855855}, {"id": 296, "seek": 144854, "start": 1467.54, "end": 1468.54, "text": " in the traditional sense.", "tokens": [51314, 294, 264, 5164, 2020, 13, 51364], "temperature": 0.0, "avg_logprob": -0.07164345078795921, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.000882984371855855}, {"id": 297, "seek": 144854, "start": 1468.54, "end": 1473.54, "text": " It really is just English, what we are largely doing when it comes to giving the AI", "tokens": [51364, 467, 534, 307, 445, 3669, 11, 437, 321, 366, 11611, 884, 562, 309, 1487, 281, 2902, 264, 7318, 51614], "temperature": 0.0, "avg_logprob": -0.07164345078795921, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.000882984371855855}, {"id": 298, "seek": 144854, "start": 1473.54, "end": 1476.54, "text": " the personality of a good teacher or a good duck.", "tokens": [51614, 264, 9033, 295, 257, 665, 5027, 420, 257, 665, 12482, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07164345078795921, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.000882984371855855}, {"id": 299, "seek": 147654, "start": 1476.54, "end": 1480.54, "text": " So what we're doing is giving it what's known as a system prompt nowadays,", "tokens": [50364, 407, 437, 321, 434, 884, 307, 2902, 309, 437, 311, 2570, 382, 257, 1185, 12391, 13434, 11, 50564], "temperature": 0.0, "avg_logprob": -0.07446459361485072, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.0007321650045923889}, {"id": 300, "seek": 147654, "start": 1480.54, "end": 1484.54, "text": " whereby we write some English sentences, send those English sentences to open AI", "tokens": [50564, 36998, 321, 2464, 512, 3669, 16579, 11, 2845, 729, 3669, 16579, 281, 1269, 7318, 50764], "temperature": 0.0, "avg_logprob": -0.07446459361485072, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.0007321650045923889}, {"id": 301, "seek": 147654, "start": 1484.54, "end": 1488.54, "text": " or Microsoft that sort of teaches it how to behave,", "tokens": [50764, 420, 8116, 300, 1333, 295, 16876, 309, 577, 281, 15158, 11, 50964], "temperature": 0.0, "avg_logprob": -0.07446459361485072, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.0007321650045923889}, {"id": 302, "seek": 147654, "start": 1488.54, "end": 1490.54, "text": " not just using its own knowledge out of the box,", "tokens": [50964, 406, 445, 1228, 1080, 1065, 3601, 484, 295, 264, 2424, 11, 51064], "temperature": 0.0, "avg_logprob": -0.07446459361485072, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.0007321650045923889}, {"id": 303, "seek": 147654, "start": 1490.54, "end": 1494.54, "text": " but coercing it to behave a little more educationally constructively.", "tokens": [51064, 457, 598, 260, 2175, 309, 281, 15158, 257, 707, 544, 3309, 379, 7690, 3413, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07446459361485072, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.0007321650045923889}, {"id": 304, "seek": 147654, "start": 1494.54, "end": 1498.54, "text": " And so, for instance, a representative snippet of English that we provide to these services", "tokens": [51264, 400, 370, 11, 337, 5197, 11, 257, 12424, 35623, 302, 295, 3669, 300, 321, 2893, 281, 613, 3328, 51464], "temperature": 0.0, "avg_logprob": -0.07446459361485072, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.0007321650045923889}, {"id": 305, "seek": 147654, "start": 1498.54, "end": 1500.54, "text": " looks a little something like this, quote unquote.", "tokens": [51464, 1542, 257, 707, 746, 411, 341, 11, 6513, 37557, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07446459361485072, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.0007321650045923889}, {"id": 306, "seek": 147654, "start": 1500.54, "end": 1504.54, "text": " You are a friendly and supportive teaching assistant for CS50.", "tokens": [51564, 509, 366, 257, 9208, 293, 14435, 4571, 10994, 337, 9460, 2803, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07446459361485072, "compression_ratio": 1.6677115987460815, "no_speech_prob": 0.0007321650045923889}, {"id": 307, "seek": 150454, "start": 1504.54, "end": 1506.54, "text": " You are also a rubber duck.", "tokens": [50364, 509, 366, 611, 257, 11593, 12482, 13, 50464], "temperature": 0.0, "avg_logprob": -0.08875163623264858, "compression_ratio": 1.6726190476190477, "no_speech_prob": 7.967226702021435e-05}, {"id": 308, "seek": 150454, "start": 1506.54, "end": 1510.54, "text": " You answer student questions only about CS50 in the field of computer science.", "tokens": [50464, 509, 1867, 3107, 1651, 787, 466, 9460, 2803, 294, 264, 2519, 295, 3820, 3497, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08875163623264858, "compression_ratio": 1.6726190476190477, "no_speech_prob": 7.967226702021435e-05}, {"id": 309, "seek": 150454, "start": 1510.54, "end": 1513.54, "text": " Do not answer questions about unrelated topics.", "tokens": [50664, 1144, 406, 1867, 1651, 466, 38967, 8378, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08875163623264858, "compression_ratio": 1.6726190476190477, "no_speech_prob": 7.967226702021435e-05}, {"id": 310, "seek": 150454, "start": 1513.54, "end": 1517.54, "text": " Do not provide full answers to problem sets as this would violate academic honesty.", "tokens": [50814, 1144, 406, 2893, 1577, 6338, 281, 1154, 6352, 382, 341, 576, 37478, 7778, 26839, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08875163623264858, "compression_ratio": 1.6726190476190477, "no_speech_prob": 7.967226702021435e-05}, {"id": 311, "seek": 150454, "start": 1517.54, "end": 1521.54, "text": " And so, in essence, and you can sort of do this manually with ChatGPT,", "tokens": [51014, 400, 370, 11, 294, 12801, 11, 293, 291, 393, 1333, 295, 360, 341, 16945, 365, 27503, 38, 47, 51, 11, 51214], "temperature": 0.0, "avg_logprob": -0.08875163623264858, "compression_ratio": 1.6726190476190477, "no_speech_prob": 7.967226702021435e-05}, {"id": 312, "seek": 150454, "start": 1521.54, "end": 1523.54, "text": " you can tell it or ask it how to behave.", "tokens": [51214, 291, 393, 980, 309, 420, 1029, 309, 577, 281, 15158, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08875163623264858, "compression_ratio": 1.6726190476190477, "no_speech_prob": 7.967226702021435e-05}, {"id": 313, "seek": 150454, "start": 1523.54, "end": 1527.54, "text": " We essentially are doing this automatically so that it doesn't just hand answers", "tokens": [51314, 492, 4476, 366, 884, 341, 6772, 370, 300, 309, 1177, 380, 445, 1011, 6338, 51514], "temperature": 0.0, "avg_logprob": -0.08875163623264858, "compression_ratio": 1.6726190476190477, "no_speech_prob": 7.967226702021435e-05}, {"id": 314, "seek": 150454, "start": 1527.54, "end": 1530.54, "text": " out of the box and knows a little something more about us.", "tokens": [51514, 484, 295, 264, 2424, 293, 3255, 257, 707, 746, 544, 466, 505, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08875163623264858, "compression_ratio": 1.6726190476190477, "no_speech_prob": 7.967226702021435e-05}, {"id": 315, "seek": 150454, "start": 1530.54, "end": 1533.54, "text": " There's also in this world of AI right now the notion of a user prompt,", "tokens": [51664, 821, 311, 611, 294, 341, 1002, 295, 7318, 558, 586, 264, 10710, 295, 257, 4195, 12391, 11, 51814], "temperature": 0.0, "avg_logprob": -0.08875163623264858, "compression_ratio": 1.6726190476190477, "no_speech_prob": 7.967226702021435e-05}, {"id": 316, "seek": 153354, "start": 1533.54, "end": 1535.54, "text": " versus that system prompt.", "tokens": [50364, 5717, 300, 1185, 12391, 13, 50464], "temperature": 0.0, "avg_logprob": -0.09391262656763981, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.0012842548312619328}, {"id": 317, "seek": 153354, "start": 1535.54, "end": 1539.54, "text": " And the user prompt, in our case, is essentially the student's own question.", "tokens": [50464, 400, 264, 4195, 12391, 11, 294, 527, 1389, 11, 307, 4476, 264, 3107, 311, 1065, 1168, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09391262656763981, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.0012842548312619328}, {"id": 318, "seek": 153354, "start": 1539.54, "end": 1543.54, "text": " I have a question about X, or I have a problem with my code here in Y.", "tokens": [50664, 286, 362, 257, 1168, 466, 1783, 11, 420, 286, 362, 257, 1154, 365, 452, 3089, 510, 294, 398, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09391262656763981, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.0012842548312619328}, {"id": 319, "seek": 153354, "start": 1543.54, "end": 1546.54, "text": " So we pass to those same API students' own questions", "tokens": [50864, 407, 321, 1320, 281, 729, 912, 9362, 1731, 6, 1065, 1651, 51014], "temperature": 0.0, "avg_logprob": -0.09391262656763981, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.0012842548312619328}, {"id": 320, "seek": 153354, "start": 1546.54, "end": 1548.54, "text": " as part of this so-called user prompt,", "tokens": [51014, 382, 644, 295, 341, 370, 12, 11880, 4195, 12391, 11, 51114], "temperature": 0.0, "avg_logprob": -0.09391262656763981, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.0012842548312619328}, {"id": 321, "seek": 153354, "start": 1548.54, "end": 1551.54, "text": " just so you're familiar now with some of the vernacular of late.", "tokens": [51114, 445, 370, 291, 434, 4963, 586, 365, 512, 295, 264, 35793, 14700, 295, 3469, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09391262656763981, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.0012842548312619328}, {"id": 322, "seek": 153354, "start": 1551.54, "end": 1554.54, "text": " Now, the programming environment that students have been using this whole year", "tokens": [51264, 823, 11, 264, 9410, 2823, 300, 1731, 362, 668, 1228, 341, 1379, 1064, 51414], "temperature": 0.0, "avg_logprob": -0.09391262656763981, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.0012842548312619328}, {"id": 323, "seek": 153354, "start": 1554.54, "end": 1557.54, "text": " is known as Visual Studio Code, a popular open source free product", "tokens": [51414, 307, 2570, 382, 23187, 13500, 15549, 11, 257, 3743, 1269, 4009, 1737, 1674, 51564], "temperature": 0.0, "avg_logprob": -0.09391262656763981, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.0012842548312619328}, {"id": 324, "seek": 153354, "start": 1557.54, "end": 1561.54, "text": " that so many engineers around the world now use.", "tokens": [51564, 300, 370, 867, 11955, 926, 264, 1002, 586, 764, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09391262656763981, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.0012842548312619328}, {"id": 325, "seek": 156154, "start": 1561.54, "end": 1564.54, "text": " But we've instrumented it to be a little more course specific,", "tokens": [50364, 583, 321, 600, 7198, 292, 309, 281, 312, 257, 707, 544, 1164, 2685, 11, 50514], "temperature": 0.0, "avg_logprob": -0.06583805847167969, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.0020506379660218954}, {"id": 326, "seek": 156154, "start": 1564.54, "end": 1569.54, "text": " with some course specific features that make learning within this environment", "tokens": [50514, 365, 512, 1164, 2685, 4122, 300, 652, 2539, 1951, 341, 2823, 50764], "temperature": 0.0, "avg_logprob": -0.06583805847167969, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.0020506379660218954}, {"id": 327, "seek": 156154, "start": 1569.54, "end": 1571.54, "text": " all the easier.", "tokens": [50764, 439, 264, 3571, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06583805847167969, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.0020506379660218954}, {"id": 328, "seek": 156154, "start": 1571.54, "end": 1573.54, "text": " It lives at cs50.dev.", "tokens": [50864, 467, 2909, 412, 28277, 2803, 13, 40343, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06583805847167969, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.0020506379660218954}, {"id": 329, "seek": 156154, "start": 1573.54, "end": 1577.54, "text": " And as students in this room know that, as of now, the virtual duck lives", "tokens": [50964, 400, 382, 1731, 294, 341, 1808, 458, 300, 11, 382, 295, 586, 11, 264, 6374, 12482, 2909, 51164], "temperature": 0.0, "avg_logprob": -0.06583805847167969, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.0020506379660218954}, {"id": 330, "seek": 156154, "start": 1577.54, "end": 1581.54, "text": " within this environment and can do things like explain highlighted lines of code.", "tokens": [51164, 1951, 341, 2823, 293, 393, 360, 721, 411, 2903, 17173, 3876, 295, 3089, 13, 51364], "temperature": 0.0, "avg_logprob": -0.06583805847167969, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.0020506379660218954}, {"id": 331, "seek": 156154, "start": 1581.54, "end": 1584.54, "text": " So here, for instance, is a screenshot of this programming environment.", "tokens": [51364, 407, 510, 11, 337, 5197, 11, 307, 257, 27712, 295, 341, 9410, 2823, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06583805847167969, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.0020506379660218954}, {"id": 332, "seek": 156154, "start": 1584.54, "end": 1587.54, "text": " Here is some arcane looking code in a language called C", "tokens": [51514, 1692, 307, 512, 10346, 1929, 1237, 3089, 294, 257, 2856, 1219, 383, 51664], "temperature": 0.0, "avg_logprob": -0.06583805847167969, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.0020506379660218954}, {"id": 333, "seek": 156154, "start": 1587.54, "end": 1589.54, "text": " that we've just left behind us in the class.", "tokens": [51664, 300, 321, 600, 445, 1411, 2261, 505, 294, 264, 1508, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06583805847167969, "compression_ratio": 1.7244897959183674, "no_speech_prob": 0.0020506379660218954}, {"id": 334, "seek": 158954, "start": 1590.54, "end": 1593.54, "text": " And suppose that you don't understand what one or more of these lines of code do,", "tokens": [50414, 400, 7297, 300, 291, 500, 380, 1223, 437, 472, 420, 544, 295, 613, 3876, 295, 3089, 360, 11, 50564], "temperature": 0.0, "avg_logprob": -0.08194998002821399, "compression_ratio": 1.735593220338983, "no_speech_prob": 0.002800757996737957}, {"id": 335, "seek": 158954, "start": 1593.54, "end": 1597.54, "text": " students can now highlight those lines, right click or control click on it,", "tokens": [50564, 1731, 393, 586, 5078, 729, 3876, 11, 558, 2052, 420, 1969, 2052, 322, 309, 11, 50764], "temperature": 0.0, "avg_logprob": -0.08194998002821399, "compression_ratio": 1.735593220338983, "no_speech_prob": 0.002800757996737957}, {"id": 336, "seek": 158954, "start": 1597.54, "end": 1600.54, "text": " select explain highlighted code, and voila,", "tokens": [50764, 3048, 2903, 17173, 3089, 11, 293, 45565, 11, 50914], "temperature": 0.0, "avg_logprob": -0.08194998002821399, "compression_ratio": 1.735593220338983, "no_speech_prob": 0.002800757996737957}, {"id": 337, "seek": 158954, "start": 1600.54, "end": 1605.54, "text": " they see a chat GPT-like explanation of that very code within a second or so", "tokens": [50914, 436, 536, 257, 5081, 26039, 51, 12, 4092, 10835, 295, 300, 588, 3089, 1951, 257, 1150, 420, 370, 51164], "temperature": 0.0, "avg_logprob": -0.08194998002821399, "compression_ratio": 1.735593220338983, "no_speech_prob": 0.002800757996737957}, {"id": 338, "seek": 158954, "start": 1605.54, "end": 1610.54, "text": " that no human has typed out but that's been dynamically generated based on this code.", "tokens": [51164, 300, 572, 1952, 575, 33941, 484, 457, 300, 311, 668, 43492, 10833, 2361, 322, 341, 3089, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08194998002821399, "compression_ratio": 1.735593220338983, "no_speech_prob": 0.002800757996737957}, {"id": 339, "seek": 158954, "start": 1610.54, "end": 1613.54, "text": " Other things that the duck can now do for students", "tokens": [51414, 5358, 721, 300, 264, 12482, 393, 586, 360, 337, 1731, 51564], "temperature": 0.0, "avg_logprob": -0.08194998002821399, "compression_ratio": 1.735593220338983, "no_speech_prob": 0.002800757996737957}, {"id": 340, "seek": 158954, "start": 1613.54, "end": 1616.54, "text": " is advise students on how to improve their code's style,", "tokens": [51564, 307, 18312, 1731, 322, 577, 281, 3470, 641, 3089, 311, 3758, 11, 51714], "temperature": 0.0, "avg_logprob": -0.08194998002821399, "compression_ratio": 1.735593220338983, "no_speech_prob": 0.002800757996737957}, {"id": 341, "seek": 158954, "start": 1616.54, "end": 1618.54, "text": " the aesthetics, the formatting thereof.", "tokens": [51714, 264, 35517, 11, 264, 39366, 456, 2670, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08194998002821399, "compression_ratio": 1.735593220338983, "no_speech_prob": 0.002800757996737957}, {"id": 342, "seek": 161854, "start": 1618.54, "end": 1621.54, "text": " And so, for instance, here is similar code in a language called C", "tokens": [50364, 400, 370, 11, 337, 5197, 11, 510, 307, 2531, 3089, 294, 257, 2856, 1219, 383, 50514], "temperature": 0.0, "avg_logprob": -0.06882610605723823, "compression_ratio": 1.6971608832807572, "no_speech_prob": 0.001169466064311564}, {"id": 343, "seek": 161854, "start": 1621.54, "end": 1623.54, "text": " and I'll stipulate that it's very messy.", "tokens": [50514, 293, 286, 603, 37001, 5256, 300, 309, 311, 588, 16191, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06882610605723823, "compression_ratio": 1.6971608832807572, "no_speech_prob": 0.001169466064311564}, {"id": 344, "seek": 161854, "start": 1623.54, "end": 1627.54, "text": " Everything is left aligned instead of nicely indented so it looks a little more structured.", "tokens": [50614, 5471, 307, 1411, 17962, 2602, 295, 9594, 1016, 6003, 370, 309, 1542, 257, 707, 544, 18519, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06882610605723823, "compression_ratio": 1.6971608832807572, "no_speech_prob": 0.001169466064311564}, {"id": 345, "seek": 161854, "start": 1627.54, "end": 1629.54, "text": " Students can now click a button.", "tokens": [50814, 17244, 393, 586, 2052, 257, 2960, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06882610605723823, "compression_ratio": 1.6971608832807572, "no_speech_prob": 0.001169466064311564}, {"id": 346, "seek": 161854, "start": 1629.54, "end": 1632.54, "text": " They'll see at the right hand side in green how their code should ideally look", "tokens": [50914, 814, 603, 536, 412, 264, 558, 1011, 1252, 294, 3092, 577, 641, 3089, 820, 22915, 574, 51064], "temperature": 0.0, "avg_logprob": -0.06882610605723823, "compression_ratio": 1.6971608832807572, "no_speech_prob": 0.001169466064311564}, {"id": 347, "seek": 161854, "start": 1632.54, "end": 1635.54, "text": " and if they're not quite sure what those changes are or why,", "tokens": [51064, 293, 498, 436, 434, 406, 1596, 988, 437, 729, 2962, 366, 420, 983, 11, 51214], "temperature": 0.0, "avg_logprob": -0.06882610605723823, "compression_ratio": 1.6971608832807572, "no_speech_prob": 0.001169466064311564}, {"id": 348, "seek": 161854, "start": 1635.54, "end": 1637.54, "text": " they can click on explain changes.", "tokens": [51214, 436, 393, 2052, 322, 2903, 2962, 13, 51314], "temperature": 0.0, "avg_logprob": -0.06882610605723823, "compression_ratio": 1.6971608832807572, "no_speech_prob": 0.001169466064311564}, {"id": 349, "seek": 161854, "start": 1637.54, "end": 1640.54, "text": " And similarly, the duck advises them on how and why", "tokens": [51314, 400, 14138, 11, 264, 12482, 1551, 3598, 552, 322, 577, 293, 983, 51464], "temperature": 0.0, "avg_logprob": -0.06882610605723823, "compression_ratio": 1.6971608832807572, "no_speech_prob": 0.001169466064311564}, {"id": 350, "seek": 161854, "start": 1640.54, "end": 1645.54, "text": " to turn their not great code into greater code from left to right respectively.", "tokens": [51464, 281, 1261, 641, 406, 869, 3089, 666, 5044, 3089, 490, 1411, 281, 558, 25009, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06882610605723823, "compression_ratio": 1.6971608832807572, "no_speech_prob": 0.001169466064311564}, {"id": 351, "seek": 164554, "start": 1645.54, "end": 1648.54, "text": " More compellingly and more generalizable beyond CS50", "tokens": [50364, 5048, 20050, 356, 293, 544, 2674, 22395, 4399, 9460, 2803, 50514], "temperature": 0.0, "avg_logprob": -0.0965911170183602, "compression_ratio": 1.6241830065359477, "no_speech_prob": 0.0014550130581483245}, {"id": 352, "seek": 164554, "start": 1648.54, "end": 1651.54, "text": " and beyond computer science is AI's ability to answer", "tokens": [50514, 293, 4399, 3820, 3497, 307, 7318, 311, 3485, 281, 1867, 50664], "temperature": 0.0, "avg_logprob": -0.0965911170183602, "compression_ratio": 1.6241830065359477, "no_speech_prob": 0.0014550130581483245}, {"id": 353, "seek": 164554, "start": 1651.54, "end": 1654.54, "text": " most of the questions that students might now ask online.", "tokens": [50664, 881, 295, 264, 1651, 300, 1731, 1062, 586, 1029, 2950, 13, 50814], "temperature": 0.0, "avg_logprob": -0.0965911170183602, "compression_ratio": 1.6241830065359477, "no_speech_prob": 0.0014550130581483245}, {"id": 354, "seek": 164554, "start": 1654.54, "end": 1656.54, "text": " And we've been doing asynchronous Q&A for years", "tokens": [50814, 400, 321, 600, 668, 884, 49174, 1249, 5, 32, 337, 924, 50914], "temperature": 0.0, "avg_logprob": -0.0965911170183602, "compression_ratio": 1.6241830065359477, "no_speech_prob": 0.0014550130581483245}, {"id": 355, "seek": 164554, "start": 1656.54, "end": 1659.54, "text": " via various mobile or web applications and the like,", "tokens": [50914, 5766, 3683, 6013, 420, 3670, 5821, 293, 264, 411, 11, 51064], "temperature": 0.0, "avg_logprob": -0.0965911170183602, "compression_ratio": 1.6241830065359477, "no_speech_prob": 0.0014550130581483245}, {"id": 356, "seek": 164554, "start": 1659.54, "end": 1661.54, "text": " but to date it has been humans,", "tokens": [51064, 457, 281, 4002, 309, 575, 668, 6255, 11, 51164], "temperature": 0.0, "avg_logprob": -0.0965911170183602, "compression_ratio": 1.6241830065359477, "no_speech_prob": 0.0014550130581483245}, {"id": 357, "seek": 164554, "start": 1661.54, "end": 1664.54, "text": " myself included responding to all of those questions.", "tokens": [51164, 2059, 5556, 16670, 281, 439, 295, 729, 1651, 13, 51314], "temperature": 0.0, "avg_logprob": -0.0965911170183602, "compression_ratio": 1.6241830065359477, "no_speech_prob": 0.0014550130581483245}, {"id": 358, "seek": 164554, "start": 1664.54, "end": 1668.54, "text": " Now the duck has an opportunity to chime in generally within three seconds", "tokens": [51314, 823, 264, 12482, 575, 364, 2650, 281, 40921, 294, 5101, 1951, 1045, 3949, 51514], "temperature": 0.0, "avg_logprob": -0.0965911170183602, "compression_ratio": 1.6241830065359477, "no_speech_prob": 0.0014550130581483245}, {"id": 359, "seek": 164554, "start": 1668.54, "end": 1672.54, "text": " because we've integrated into an online Q&A tool that students in CS50", "tokens": [51514, 570, 321, 600, 10919, 666, 364, 2950, 1249, 5, 32, 2290, 300, 1731, 294, 9460, 2803, 51714], "temperature": 0.0, "avg_logprob": -0.0965911170183602, "compression_ratio": 1.6241830065359477, "no_speech_prob": 0.0014550130581483245}, {"id": 360, "seek": 167254, "start": 1672.54, "end": 1674.54, "text": " and elsewhere across Harvard have long used.", "tokens": [50364, 293, 14517, 2108, 13378, 362, 938, 1143, 13, 50464], "temperature": 0.0, "avg_logprob": -0.10111976036658654, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002550821052864194}, {"id": 361, "seek": 167254, "start": 1674.54, "end": 1678.54, "text": " So here's an anonymized screenshot of a question from an actual student", "tokens": [50464, 407, 510, 311, 364, 37293, 1602, 27712, 295, 257, 1168, 490, 364, 3539, 3107, 50664], "temperature": 0.0, "avg_logprob": -0.10111976036658654, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002550821052864194}, {"id": 362, "seek": 167254, "start": 1678.54, "end": 1681.54, "text": " but written here as John Harvard who asked this summer", "tokens": [50664, 457, 3720, 510, 382, 2619, 13378, 567, 2351, 341, 4266, 50814], "temperature": 0.0, "avg_logprob": -0.10111976036658654, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002550821052864194}, {"id": 363, "seek": 167254, "start": 1681.54, "end": 1684.54, "text": " in the summer version of CS50, what is flask exactly?", "tokens": [50814, 294, 264, 4266, 3037, 295, 9460, 2803, 11, 437, 307, 932, 3863, 2293, 30, 50964], "temperature": 0.0, "avg_logprob": -0.10111976036658654, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002550821052864194}, {"id": 364, "seek": 167254, "start": 1684.54, "end": 1687.54, "text": " So fairly definitional question and here is what the duck spit out", "tokens": [50964, 407, 6457, 1561, 2628, 1168, 293, 510, 307, 437, 264, 12482, 22127, 484, 51114], "temperature": 0.0, "avg_logprob": -0.10111976036658654, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002550821052864194}, {"id": 365, "seek": 167254, "start": 1687.54, "end": 1690.54, "text": " thanks to that architecture I described before.", "tokens": [51114, 3231, 281, 300, 9482, 286, 7619, 949, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10111976036658654, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002550821052864194}, {"id": 366, "seek": 167254, "start": 1690.54, "end": 1692.54, "text": " I'll stipulate that this is correct,", "tokens": [51264, 286, 603, 37001, 5256, 300, 341, 307, 3006, 11, 51364], "temperature": 0.0, "avg_logprob": -0.10111976036658654, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002550821052864194}, {"id": 367, "seek": 167254, "start": 1692.54, "end": 1696.54, "text": " but it is mostly a definition akin to what Google or Bing could already give you last year,", "tokens": [51364, 457, 309, 307, 5240, 257, 7123, 47540, 281, 437, 3329, 420, 30755, 727, 1217, 976, 291, 1036, 1064, 11, 51564], "temperature": 0.0, "avg_logprob": -0.10111976036658654, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002550821052864194}, {"id": 368, "seek": 167254, "start": 1696.54, "end": 1700.54, "text": " but here's a more nuanced question for instance from another anonymized students.", "tokens": [51564, 457, 510, 311, 257, 544, 45115, 1168, 337, 5197, 490, 1071, 37293, 1602, 1731, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10111976036658654, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002550821052864194}, {"id": 369, "seek": 170054, "start": 1700.54, "end": 1704.54, "text": " In this question here the students including an error message that they're seeing,", "tokens": [50364, 682, 341, 1168, 510, 264, 1731, 3009, 364, 6713, 3636, 300, 436, 434, 2577, 11, 50564], "temperature": 0.0, "avg_logprob": -0.07278242492675781, "compression_ratio": 1.7738853503184713, "no_speech_prob": 0.0025508059188723564}, {"id": 370, "seek": 170054, "start": 1704.54, "end": 1709.54, "text": " they're asking about that and they're asking a little more broadly and qualitatively", "tokens": [50564, 436, 434, 3365, 466, 300, 293, 436, 434, 3365, 257, 707, 544, 19511, 293, 31312, 356, 50814], "temperature": 0.0, "avg_logprob": -0.07278242492675781, "compression_ratio": 1.7738853503184713, "no_speech_prob": 0.0025508059188723564}, {"id": 371, "seek": 170054, "start": 1709.54, "end": 1712.54, "text": " is there a more efficient way to write this code?", "tokens": [50814, 307, 456, 257, 544, 7148, 636, 281, 2464, 341, 3089, 30, 50964], "temperature": 0.0, "avg_logprob": -0.07278242492675781, "compression_ratio": 1.7738853503184713, "no_speech_prob": 0.0025508059188723564}, {"id": 372, "seek": 170054, "start": 1712.54, "end": 1715.54, "text": " A question that really is best answered based on experience.", "tokens": [50964, 316, 1168, 300, 534, 307, 1151, 10103, 2361, 322, 1752, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07278242492675781, "compression_ratio": 1.7738853503184713, "no_speech_prob": 0.0025508059188723564}, {"id": 373, "seek": 170054, "start": 1715.54, "end": 1718.54, "text": " Here I'll stipulate that the duck responded with this answer", "tokens": [51114, 1692, 286, 603, 37001, 5256, 300, 264, 12482, 15806, 365, 341, 1867, 51264], "temperature": 0.0, "avg_logprob": -0.07278242492675781, "compression_ratio": 1.7738853503184713, "no_speech_prob": 0.0025508059188723564}, {"id": 374, "seek": 170054, "start": 1718.54, "end": 1720.54, "text": " which is actually pretty darn good,", "tokens": [51264, 597, 307, 767, 1238, 29063, 665, 11, 51364], "temperature": 0.0, "avg_logprob": -0.07278242492675781, "compression_ratio": 1.7738853503184713, "no_speech_prob": 0.0025508059188723564}, {"id": 375, "seek": 170054, "start": 1720.54, "end": 1723.54, "text": " not only responding in English but with some sample starter code", "tokens": [51364, 406, 787, 16670, 294, 3669, 457, 365, 512, 6889, 22465, 3089, 51514], "temperature": 0.0, "avg_logprob": -0.07278242492675781, "compression_ratio": 1.7738853503184713, "no_speech_prob": 0.0025508059188723564}, {"id": 376, "seek": 170054, "start": 1723.54, "end": 1725.54, "text": " that would make sense in this context", "tokens": [51514, 300, 576, 652, 2020, 294, 341, 4319, 51614], "temperature": 0.0, "avg_logprob": -0.07278242492675781, "compression_ratio": 1.7738853503184713, "no_speech_prob": 0.0025508059188723564}, {"id": 377, "seek": 170054, "start": 1725.54, "end": 1729.54, "text": " and at the bottom it's worth noting because none of this technology is perfect", "tokens": [51614, 293, 412, 264, 2767, 309, 311, 3163, 26801, 570, 6022, 295, 341, 2899, 307, 2176, 51814], "temperature": 0.0, "avg_logprob": -0.07278242492675781, "compression_ratio": 1.7738853503184713, "no_speech_prob": 0.0025508059188723564}, {"id": 378, "seek": 172954, "start": 1729.54, "end": 1732.54, "text": " just yet, it's still indeed very bleeding edge", "tokens": [50364, 445, 1939, 11, 309, 311, 920, 6451, 588, 19312, 4691, 50514], "temperature": 0.0, "avg_logprob": -0.12815124848309686, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.0015011312207207084}, {"id": 379, "seek": 172954, "start": 1732.54, "end": 1736.54, "text": " and so what we have chosen to do within CS50 is include disclaimers like this.", "tokens": [50514, 293, 370, 437, 321, 362, 8614, 281, 360, 1951, 9460, 2803, 307, 4090, 2983, 10970, 433, 411, 341, 13, 50714], "temperature": 0.0, "avg_logprob": -0.12815124848309686, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.0015011312207207084}, {"id": 380, "seek": 172954, "start": 1736.54, "end": 1738.54, "text": " I am an experimental bot, quack.", "tokens": [50714, 286, 669, 364, 17069, 10592, 11, 421, 501, 13, 50814], "temperature": 0.0, "avg_logprob": -0.12815124848309686, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.0015011312207207084}, {"id": 381, "seek": 172954, "start": 1738.54, "end": 1744.54, "text": " Do not assume that my reply is accurate unless you see that it's been endorsed by humans staff, quack.", "tokens": [50814, 1144, 406, 6552, 300, 452, 16972, 307, 8559, 5969, 291, 536, 300, 309, 311, 668, 50094, 538, 6255, 3525, 11, 421, 501, 13, 51114], "temperature": 0.0, "avg_logprob": -0.12815124848309686, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.0015011312207207084}, {"id": 382, "seek": 172954, "start": 1744.54, "end": 1747.54, "text": " And in fact at top right the mechanism we've been using in this tool", "tokens": [51114, 400, 294, 1186, 412, 1192, 558, 264, 7513, 321, 600, 668, 1228, 294, 341, 2290, 51264], "temperature": 0.0, "avg_logprob": -0.12815124848309686, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.0015011312207207084}, {"id": 383, "seek": 172954, "start": 1747.54, "end": 1750.54, "text": " is usually within minutes a human whether it's a teaching fellow,", "tokens": [51264, 307, 2673, 1951, 2077, 257, 1952, 1968, 309, 311, 257, 4571, 7177, 11, 51414], "temperature": 0.0, "avg_logprob": -0.12815124848309686, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.0015011312207207084}, {"id": 384, "seek": 172954, "start": 1750.54, "end": 1753.54, "text": " course assistant or myself, we'll click on a button like this", "tokens": [51414, 1164, 10994, 420, 2059, 11, 321, 603, 2052, 322, 257, 2960, 411, 341, 51564], "temperature": 0.0, "avg_logprob": -0.12815124848309686, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.0015011312207207084}, {"id": 385, "seek": 172954, "start": 1753.54, "end": 1757.54, "text": " to signal to our human students that yes, like the duck is spot on here", "tokens": [51564, 281, 6358, 281, 527, 1952, 1731, 300, 2086, 11, 411, 264, 12482, 307, 4008, 322, 510, 51764], "temperature": 0.0, "avg_logprob": -0.12815124848309686, "compression_ratio": 1.6459627329192548, "no_speech_prob": 0.0015011312207207084}, {"id": 386, "seek": 175754, "start": 1757.54, "end": 1761.54, "text": " or we have an opportunity as always to chime in with our own responses.", "tokens": [50364, 420, 321, 362, 364, 2650, 382, 1009, 281, 40921, 294, 365, 527, 1065, 13019, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09066067972490864, "compression_ratio": 1.718543046357616, "no_speech_prob": 0.0006878401036374271}, {"id": 387, "seek": 175754, "start": 1761.54, "end": 1764.54, "text": " Frankly that disclaimer, that button will soon I do think go away", "tokens": [50564, 41344, 300, 40896, 11, 300, 2960, 486, 2321, 286, 360, 519, 352, 1314, 50714], "temperature": 0.0, "avg_logprob": -0.09066067972490864, "compression_ratio": 1.718543046357616, "no_speech_prob": 0.0006878401036374271}, {"id": 388, "seek": 175754, "start": 1764.54, "end": 1766.54, "text": " as the software gets better and better,", "tokens": [50714, 382, 264, 4722, 2170, 1101, 293, 1101, 11, 50814], "temperature": 0.0, "avg_logprob": -0.09066067972490864, "compression_ratio": 1.718543046357616, "no_speech_prob": 0.0006878401036374271}, {"id": 389, "seek": 175754, "start": 1766.54, "end": 1770.54, "text": " but for now that's how we're modulating exactly what students' expectations might be", "tokens": [50814, 457, 337, 586, 300, 311, 577, 321, 434, 1072, 12162, 2293, 437, 1731, 6, 9843, 1062, 312, 51014], "temperature": 0.0, "avg_logprob": -0.09066067972490864, "compression_ratio": 1.718543046357616, "no_speech_prob": 0.0006878401036374271}, {"id": 390, "seek": 175754, "start": 1770.54, "end": 1773.54, "text": " when it comes to correctness or incorrectness.", "tokens": [51014, 562, 309, 1487, 281, 3006, 1287, 420, 18424, 1287, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09066067972490864, "compression_ratio": 1.718543046357616, "no_speech_prob": 0.0006878401036374271}, {"id": 391, "seek": 175754, "start": 1773.54, "end": 1776.54, "text": " It's common to in programming to see a lot of error messages", "tokens": [51164, 467, 311, 2689, 281, 294, 9410, 281, 536, 257, 688, 295, 6713, 7897, 51314], "temperature": 0.0, "avg_logprob": -0.09066067972490864, "compression_ratio": 1.718543046357616, "no_speech_prob": 0.0006878401036374271}, {"id": 392, "seek": 175754, "start": 1776.54, "end": 1778.54, "text": " certainly when you're learning first hand.", "tokens": [51314, 3297, 562, 291, 434, 2539, 700, 1011, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09066067972490864, "compression_ratio": 1.718543046357616, "no_speech_prob": 0.0006878401036374271}, {"id": 393, "seek": 175754, "start": 1778.54, "end": 1782.54, "text": " A lot of these error messages are cane, confusing certainly to students", "tokens": [51414, 316, 688, 295, 613, 6713, 7897, 366, 27518, 11, 13181, 3297, 281, 1731, 51614], "temperature": 0.0, "avg_logprob": -0.09066067972490864, "compression_ratio": 1.718543046357616, "no_speech_prob": 0.0006878401036374271}, {"id": 394, "seek": 175754, "start": 1782.54, "end": 1784.54, "text": " versus the people who wrote them.", "tokens": [51614, 5717, 264, 561, 567, 4114, 552, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09066067972490864, "compression_ratio": 1.718543046357616, "no_speech_prob": 0.0006878401036374271}, {"id": 395, "seek": 178454, "start": 1784.54, "end": 1788.54, "text": " We'll see a box like this whenever one of their terminal window programs airs,", "tokens": [50364, 492, 603, 536, 257, 2424, 411, 341, 5699, 472, 295, 641, 14709, 4910, 4268, 1988, 82, 11, 50564], "temperature": 0.0, "avg_logprob": -0.13870190765898108, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.007120995316654444}, {"id": 396, "seek": 178454, "start": 1788.54, "end": 1793.54, "text": " they'll be assisted to with English like TF like support", "tokens": [50564, 436, 603, 312, 30291, 281, 365, 3669, 411, 40964, 411, 1406, 50814], "temperature": 0.0, "avg_logprob": -0.13870190765898108, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.007120995316654444}, {"id": 397, "seek": 178454, "start": 1793.54, "end": 1796.54, "text": " when it comes to explaining what it is that went wrong with that command.", "tokens": [50814, 562, 309, 1487, 281, 13468, 437, 309, 307, 300, 1437, 2085, 365, 300, 5622, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13870190765898108, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.007120995316654444}, {"id": 398, "seek": 178454, "start": 1796.54, "end": 1800.54, "text": " And ultimately what this is really doing for students in our own experience already", "tokens": [50964, 400, 6284, 437, 341, 307, 534, 884, 337, 1731, 294, 527, 1065, 1752, 1217, 51164], "temperature": 0.0, "avg_logprob": -0.13870190765898108, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.007120995316654444}, {"id": 399, "seek": 178454, "start": 1800.54, "end": 1804.54, "text": " is providing them really with virtual office hours and 24 seven,", "tokens": [51164, 307, 6530, 552, 534, 365, 6374, 3398, 2496, 293, 4022, 3407, 11, 51364], "temperature": 0.0, "avg_logprob": -0.13870190765898108, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.007120995316654444}, {"id": 400, "seek": 178454, "start": 1804.54, "end": 1807.54, "text": " which is actually quite compelling in a university environment", "tokens": [51364, 597, 307, 767, 1596, 20050, 294, 257, 5454, 2823, 51514], "temperature": 0.0, "avg_logprob": -0.13870190765898108, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.007120995316654444}, {"id": 401, "seek": 178454, "start": 1807.54, "end": 1809.54, "text": " where students schedules are already tightly packed,", "tokens": [51514, 689, 1731, 28078, 366, 1217, 21952, 13265, 11, 51614], "temperature": 0.0, "avg_logprob": -0.13870190765898108, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.007120995316654444}, {"id": 402, "seek": 178454, "start": 1809.54, "end": 1812.54, "text": " be it with academics, the curriculars, athletics and the like,", "tokens": [51614, 312, 309, 365, 25695, 11, 264, 13179, 42891, 11, 37964, 293, 264, 411, 11, 51764], "temperature": 0.0, "avg_logprob": -0.13870190765898108, "compression_ratio": 1.6728971962616823, "no_speech_prob": 0.007120995316654444}, {"id": 403, "seek": 181254, "start": 1812.54, "end": 1815.54, "text": " and they might have enough time to dive into a homework assignment,", "tokens": [50364, 293, 436, 1062, 362, 1547, 565, 281, 9192, 666, 257, 14578, 15187, 11, 50514], "temperature": 0.0, "avg_logprob": -0.10567779272374972, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.001169470138847828}, {"id": 404, "seek": 181254, "start": 1815.54, "end": 1817.54, "text": " maybe eight hours even for something sizable,", "tokens": [50514, 1310, 3180, 2496, 754, 337, 746, 13723, 712, 11, 50614], "temperature": 0.0, "avg_logprob": -0.10567779272374972, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.001169470138847828}, {"id": 405, "seek": 181254, "start": 1817.54, "end": 1820.54, "text": " but if they hit that wall a couple of hours in,", "tokens": [50614, 457, 498, 436, 2045, 300, 2929, 257, 1916, 295, 2496, 294, 11, 50764], "temperature": 0.0, "avg_logprob": -0.10567779272374972, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.001169470138847828}, {"id": 406, "seek": 181254, "start": 1820.54, "end": 1823.54, "text": " yeah, they can go to office hours or they can ask a question", "tokens": [50764, 1338, 11, 436, 393, 352, 281, 3398, 2496, 420, 436, 393, 1029, 257, 1168, 50914], "temperature": 0.0, "avg_logprob": -0.10567779272374972, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.001169470138847828}, {"id": 407, "seek": 181254, "start": 1823.54, "end": 1827.54, "text": " asynchronously online, but it's really not optimal in the moment support", "tokens": [50914, 42642, 5098, 2950, 11, 457, 309, 311, 534, 406, 16252, 294, 264, 1623, 1406, 51114], "temperature": 0.0, "avg_logprob": -0.10567779272374972, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.001169470138847828}, {"id": 408, "seek": 181254, "start": 1827.54, "end": 1831.54, "text": " that we can now provide all the more effectively we hope through software as well.", "tokens": [51114, 300, 321, 393, 586, 2893, 439, 264, 544, 8659, 321, 1454, 807, 4722, 382, 731, 13, 51314], "temperature": 0.0, "avg_logprob": -0.10567779272374972, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.001169470138847828}, {"id": 409, "seek": 181254, "start": 1831.54, "end": 1834.54, "text": " So if you're curious, even if you're not a technophile yourself,", "tokens": [51314, 407, 498, 291, 434, 6369, 11, 754, 498, 291, 434, 406, 257, 1537, 49242, 1803, 11, 51464], "temperature": 0.0, "avg_logprob": -0.10567779272374972, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.001169470138847828}, {"id": 410, "seek": 181254, "start": 1834.54, "end": 1838.54, "text": " anyone on the internet can go to cs50.ai and experiment with this user interface.", "tokens": [51464, 2878, 322, 264, 4705, 393, 352, 281, 28277, 2803, 13, 1301, 293, 5120, 365, 341, 4195, 9226, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10567779272374972, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.001169470138847828}, {"id": 411, "seek": 181254, "start": 1838.54, "end": 1841.54, "text": " This one here actually resembles chat GPT itself,", "tokens": [51664, 639, 472, 510, 767, 34433, 5081, 26039, 51, 2564, 11, 51814], "temperature": 0.0, "avg_logprob": -0.10567779272374972, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.001169470138847828}, {"id": 412, "seek": 184154, "start": 1841.54, "end": 1844.54, "text": " but it's specific to cs50.", "tokens": [50364, 457, 309, 311, 2685, 281, 28277, 2803, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09089752636124603, "compression_ratio": 1.6550522648083623, "no_speech_prob": 0.000163462056661956}, {"id": 413, "seek": 184154, "start": 1844.54, "end": 1848.54, "text": " And here again is just a sequence of screenshots that I'll stipulate for today's purposes", "tokens": [50514, 400, 510, 797, 307, 445, 257, 8310, 295, 40661, 300, 286, 603, 37001, 5256, 337, 965, 311, 9932, 50714], "temperature": 0.0, "avg_logprob": -0.09089752636124603, "compression_ratio": 1.6550522648083623, "no_speech_prob": 0.000163462056661956}, {"id": 414, "seek": 184154, "start": 1848.54, "end": 1852.54, "text": " are pretty darn good and akin to what I myself or a teaching fellow would reply to", "tokens": [50714, 366, 1238, 29063, 665, 293, 47540, 281, 437, 286, 2059, 420, 257, 4571, 7177, 576, 16972, 281, 50914], "temperature": 0.0, "avg_logprob": -0.09089752636124603, "compression_ratio": 1.6550522648083623, "no_speech_prob": 0.000163462056661956}, {"id": 415, "seek": 184154, "start": 1852.54, "end": 1857.54, "text": " and answer to a student's question in this case about their particular code.", "tokens": [50914, 293, 1867, 281, 257, 3107, 311, 1168, 294, 341, 1389, 466, 641, 1729, 3089, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09089752636124603, "compression_ratio": 1.6550522648083623, "no_speech_prob": 0.000163462056661956}, {"id": 416, "seek": 184154, "start": 1857.54, "end": 1859.54, "text": " And ultimately it's really aspirational.", "tokens": [51164, 400, 6284, 309, 311, 534, 20003, 1478, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09089752636124603, "compression_ratio": 1.6550522648083623, "no_speech_prob": 0.000163462056661956}, {"id": 417, "seek": 184154, "start": 1859.54, "end": 1864.54, "text": " The goal here ultimately is to really approximate a one to one teacher to student ratio,", "tokens": [51264, 440, 3387, 510, 6284, 307, 281, 534, 30874, 257, 472, 281, 472, 5027, 281, 3107, 8509, 11, 51514], "temperature": 0.0, "avg_logprob": -0.09089752636124603, "compression_ratio": 1.6550522648083623, "no_speech_prob": 0.000163462056661956}, {"id": 418, "seek": 184154, "start": 1864.54, "end": 1868.54, "text": " which despite all of the resources we within cs50, we within Harvard", "tokens": [51514, 597, 7228, 439, 295, 264, 3593, 321, 1951, 28277, 2803, 11, 321, 1951, 13378, 51714], "temperature": 0.0, "avg_logprob": -0.09089752636124603, "compression_ratio": 1.6550522648083623, "no_speech_prob": 0.000163462056661956}, {"id": 419, "seek": 186854, "start": 1868.54, "end": 1872.54, "text": " and places like Yale have, we certainly have never had enough resources", "tokens": [50364, 293, 3190, 411, 26711, 362, 11, 321, 3297, 362, 1128, 632, 1547, 3593, 50564], "temperature": 0.0, "avg_logprob": -0.07329582566974543, "compression_ratio": 1.6996699669966997, "no_speech_prob": 0.0018101619789376855}, {"id": 420, "seek": 186854, "start": 1872.54, "end": 1876.54, "text": " to approximate what might really be ideal, which is more of an apprenticeship model,", "tokens": [50564, 281, 30874, 437, 1062, 534, 312, 7157, 11, 597, 307, 544, 295, 364, 47070, 2316, 11, 50764], "temperature": 0.0, "avg_logprob": -0.07329582566974543, "compression_ratio": 1.6996699669966997, "no_speech_prob": 0.0018101619789376855}, {"id": 421, "seek": 186854, "start": 1876.54, "end": 1880.54, "text": " a mentorship whereby it's just you and that teacher working one on one.", "tokens": [50764, 257, 40422, 36998, 309, 311, 445, 291, 293, 300, 5027, 1364, 472, 322, 472, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07329582566974543, "compression_ratio": 1.6996699669966997, "no_speech_prob": 0.0018101619789376855}, {"id": 422, "seek": 186854, "start": 1880.54, "end": 1883.54, "text": " Now we still have humans and the goal is not to reduce that human support,", "tokens": [50964, 823, 321, 920, 362, 6255, 293, 264, 3387, 307, 406, 281, 5407, 300, 1952, 1406, 11, 51114], "temperature": 0.0, "avg_logprob": -0.07329582566974543, "compression_ratio": 1.6996699669966997, "no_speech_prob": 0.0018101619789376855}, {"id": 423, "seek": 186854, "start": 1883.54, "end": 1888.54, "text": " but to focus it all the more consciously on the students who would benefit most", "tokens": [51114, 457, 281, 1879, 309, 439, 264, 544, 32538, 322, 264, 1731, 567, 576, 5121, 881, 51364], "temperature": 0.0, "avg_logprob": -0.07329582566974543, "compression_ratio": 1.6996699669966997, "no_speech_prob": 0.0018101619789376855}, {"id": 424, "seek": 186854, "start": 1888.54, "end": 1892.54, "text": " from some impersonal one-on-one support versus students who would happily take it", "tokens": [51364, 490, 512, 38147, 304, 472, 12, 266, 12, 546, 1406, 5717, 1731, 567, 576, 19909, 747, 309, 51564], "temperature": 0.0, "avg_logprob": -0.07329582566974543, "compression_ratio": 1.6996699669966997, "no_speech_prob": 0.0018101619789376855}, {"id": 425, "seek": 186854, "start": 1892.54, "end": 1895.54, "text": " at any hour of the day more digitally via online.", "tokens": [51564, 412, 604, 1773, 295, 264, 786, 544, 36938, 5766, 2950, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07329582566974543, "compression_ratio": 1.6996699669966997, "no_speech_prob": 0.0018101619789376855}, {"id": 426, "seek": 189554, "start": 1895.54, "end": 1899.54, "text": " And in fact, we're still in the process of evaluating just how well or not well all of this works,", "tokens": [50364, 400, 294, 1186, 11, 321, 434, 920, 294, 264, 1399, 295, 27479, 445, 577, 731, 420, 406, 731, 439, 295, 341, 1985, 11, 50564], "temperature": 0.0, "avg_logprob": -0.09829602807255114, "compression_ratio": 1.6677740863787376, "no_speech_prob": 0.002251792000606656}, {"id": 427, "seek": 189554, "start": 1899.54, "end": 1903.54, "text": " but based on our summer experiment alone with about 70 students a few months back,", "tokens": [50564, 457, 2361, 322, 527, 4266, 5120, 3312, 365, 466, 5285, 1731, 257, 1326, 2493, 646, 11, 50764], "temperature": 0.0, "avg_logprob": -0.09829602807255114, "compression_ratio": 1.6677740863787376, "no_speech_prob": 0.002251792000606656}, {"id": 428, "seek": 189554, "start": 1903.54, "end": 1907.54, "text": " one student wrote us at term's end, it felt like having a personal tutor.", "tokens": [50764, 472, 3107, 4114, 505, 412, 1433, 311, 917, 11, 309, 2762, 411, 1419, 257, 2973, 35613, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09829602807255114, "compression_ratio": 1.6677740863787376, "no_speech_prob": 0.002251792000606656}, {"id": 429, "seek": 189554, "start": 1907.54, "end": 1911.54, "text": " I love how AI bots will answer questions without ego and without judgment,", "tokens": [50964, 286, 959, 577, 7318, 35410, 486, 1867, 1651, 1553, 14495, 293, 1553, 12216, 11, 51164], "temperature": 0.0, "avg_logprob": -0.09829602807255114, "compression_ratio": 1.6677740863787376, "no_speech_prob": 0.002251792000606656}, {"id": 430, "seek": 189554, "start": 1911.54, "end": 1916.54, "text": " generally entertaining even the stupidest of questions without treating them like they're stupid.", "tokens": [51164, 5101, 20402, 754, 264, 6631, 377, 295, 1651, 1553, 15083, 552, 411, 436, 434, 6631, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09829602807255114, "compression_ratio": 1.6677740863787376, "no_speech_prob": 0.002251792000606656}, {"id": 431, "seek": 189554, "start": 1916.54, "end": 1922.54, "text": " It has an, as one could expect, ironically, an inhuman level of patience.", "tokens": [51414, 467, 575, 364, 11, 382, 472, 727, 2066, 11, 41082, 11, 364, 294, 18796, 1496, 295, 14826, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09829602807255114, "compression_ratio": 1.6677740863787376, "no_speech_prob": 0.002251792000606656}, {"id": 432, "seek": 192254, "start": 1922.54, "end": 1928.54, "text": " And so I thought that's telling as to how even one student is perceiving these new possibilities.", "tokens": [50364, 400, 370, 286, 1194, 300, 311, 3585, 382, 281, 577, 754, 472, 3107, 307, 9016, 2123, 613, 777, 12178, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06806665851223853, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.001926612458191812}, {"id": 433, "seek": 192254, "start": 1928.54, "end": 1932.54, "text": " So let's consider now more academically what it is that's enabling those kinds of tools,", "tokens": [50664, 407, 718, 311, 1949, 586, 544, 48944, 437, 309, 307, 300, 311, 23148, 729, 3685, 295, 3873, 11, 50864], "temperature": 0.0, "avg_logprob": -0.06806665851223853, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.001926612458191812}, {"id": 434, "seek": 192254, "start": 1932.54, "end": 1936.54, "text": " not just within CS50, within computer science, but really the world more generally.", "tokens": [50864, 406, 445, 1951, 9460, 2803, 11, 1951, 3820, 3497, 11, 457, 534, 264, 1002, 544, 5101, 13, 51064], "temperature": 0.0, "avg_logprob": -0.06806665851223853, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.001926612458191812}, {"id": 435, "seek": 192254, "start": 1936.54, "end": 1940.54, "text": " What the whole world's been talking about is generative artificial intelligence,", "tokens": [51064, 708, 264, 1379, 1002, 311, 668, 1417, 466, 307, 1337, 1166, 11677, 7599, 11, 51264], "temperature": 0.0, "avg_logprob": -0.06806665851223853, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.001926612458191812}, {"id": 436, "seek": 192254, "start": 1940.54, "end": 1946.54, "text": " AI that can generate images, generate text and sort of mimic the behavior of what we think of as human.", "tokens": [51264, 7318, 300, 393, 8460, 5267, 11, 8460, 2487, 293, 1333, 295, 31075, 264, 5223, 295, 437, 321, 519, 295, 382, 1952, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06806665851223853, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.001926612458191812}, {"id": 437, "seek": 192254, "start": 1946.54, "end": 1948.54, "text": " So what does that really mean?", "tokens": [51564, 407, 437, 775, 300, 534, 914, 30, 51664], "temperature": 0.0, "avg_logprob": -0.06806665851223853, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.001926612458191812}, {"id": 438, "seek": 192254, "start": 1948.54, "end": 1950.54, "text": " Well, let's start really at the beginning.", "tokens": [51664, 1042, 11, 718, 311, 722, 534, 412, 264, 2863, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06806665851223853, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.001926612458191812}, {"id": 439, "seek": 195054, "start": 1950.54, "end": 1953.54, "text": " Artificial intelligence is actually a technique, a technology,", "tokens": [50364, 5735, 10371, 7599, 307, 767, 257, 6532, 11, 257, 2899, 11, 50514], "temperature": 0.0, "avg_logprob": -0.06813199615478516, "compression_ratio": 1.7847222222222223, "no_speech_prob": 0.0012842643773183227}, {"id": 440, "seek": 195054, "start": 1953.54, "end": 1955.54, "text": " a subject that's actually been with us for some time,", "tokens": [50514, 257, 3983, 300, 311, 767, 668, 365, 505, 337, 512, 565, 11, 50614], "temperature": 0.0, "avg_logprob": -0.06813199615478516, "compression_ratio": 1.7847222222222223, "no_speech_prob": 0.0012842643773183227}, {"id": 441, "seek": 195054, "start": 1955.54, "end": 1962.54, "text": " but it really was the introduction of this very user-friendly interface known as chatGPT", "tokens": [50614, 457, 309, 534, 390, 264, 9339, 295, 341, 588, 4195, 12, 22864, 9226, 2570, 382, 5081, 38, 47, 51, 50964], "temperature": 0.0, "avg_logprob": -0.06813199615478516, "compression_ratio": 1.7847222222222223, "no_speech_prob": 0.0012842643773183227}, {"id": 442, "seek": 195054, "start": 1962.54, "end": 1966.54, "text": " and some of the more recent academic work over really just the past five or six years", "tokens": [50964, 293, 512, 295, 264, 544, 5162, 7778, 589, 670, 534, 445, 264, 1791, 1732, 420, 2309, 924, 51164], "temperature": 0.0, "avg_logprob": -0.06813199615478516, "compression_ratio": 1.7847222222222223, "no_speech_prob": 0.0012842643773183227}, {"id": 443, "seek": 195054, "start": 1966.54, "end": 1969.54, "text": " that really allowed us to take a massive leap forward,", "tokens": [51164, 300, 534, 4350, 505, 281, 747, 257, 5994, 19438, 2128, 11, 51314], "temperature": 0.0, "avg_logprob": -0.06813199615478516, "compression_ratio": 1.7847222222222223, "no_speech_prob": 0.0012842643773183227}, {"id": 444, "seek": 195054, "start": 1969.54, "end": 1972.54, "text": " it would seem technologically, as to what these things can now do.", "tokens": [51314, 309, 576, 1643, 1537, 17157, 11, 382, 281, 437, 613, 721, 393, 586, 360, 13, 51464], "temperature": 0.0, "avg_logprob": -0.06813199615478516, "compression_ratio": 1.7847222222222223, "no_speech_prob": 0.0012842643773183227}, {"id": 445, "seek": 195054, "start": 1972.54, "end": 1974.54, "text": " So what is artificial intelligence?", "tokens": [51464, 407, 437, 307, 11677, 7599, 30, 51564], "temperature": 0.0, "avg_logprob": -0.06813199615478516, "compression_ratio": 1.7847222222222223, "no_speech_prob": 0.0012842643773183227}, {"id": 446, "seek": 195054, "start": 1974.54, "end": 1977.54, "text": " It's been with us for some time and it's honestly so omnipresent", "tokens": [51564, 467, 311, 668, 365, 505, 337, 512, 565, 293, 309, 311, 6095, 370, 36874, 647, 11662, 51714], "temperature": 0.0, "avg_logprob": -0.06813199615478516, "compression_ratio": 1.7847222222222223, "no_speech_prob": 0.0012842643773183227}, {"id": 447, "seek": 197754, "start": 1977.54, "end": 1979.54, "text": " that we sort of take it for granted nowadays.", "tokens": [50364, 300, 321, 1333, 295, 747, 309, 337, 12344, 13434, 13, 50464], "temperature": 0.0, "avg_logprob": -0.06993979172740909, "compression_ratio": 1.7581120943952802, "no_speech_prob": 0.02442127652466297}, {"id": 448, "seek": 197754, "start": 1979.54, "end": 1982.54, "text": " Gmail outlook have gotten really good at spam detection.", "tokens": [50464, 36732, 26650, 362, 5768, 534, 665, 412, 24028, 17784, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06993979172740909, "compression_ratio": 1.7581120943952802, "no_speech_prob": 0.02442127652466297}, {"id": 449, "seek": 197754, "start": 1982.54, "end": 1984.54, "text": " If you haven't checked your spam folder in a while,", "tokens": [50614, 759, 291, 2378, 380, 10033, 428, 24028, 10820, 294, 257, 1339, 11, 50714], "temperature": 0.0, "avg_logprob": -0.06993979172740909, "compression_ratio": 1.7581120943952802, "no_speech_prob": 0.02442127652466297}, {"id": 450, "seek": 197754, "start": 1984.54, "end": 1988.54, "text": " that's testament to just how good they seem to be at getting it out of your inbox.", "tokens": [50714, 300, 311, 35499, 281, 445, 577, 665, 436, 1643, 281, 312, 412, 1242, 309, 484, 295, 428, 35067, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06993979172740909, "compression_ratio": 1.7581120943952802, "no_speech_prob": 0.02442127652466297}, {"id": 451, "seek": 197754, "start": 1988.54, "end": 1991.54, "text": " Handwriting recognition has been with us for some time.", "tokens": [50914, 8854, 19868, 11150, 575, 668, 365, 505, 337, 512, 565, 13, 51064], "temperature": 0.0, "avg_logprob": -0.06993979172740909, "compression_ratio": 1.7581120943952802, "no_speech_prob": 0.02442127652466297}, {"id": 452, "seek": 197754, "start": 1991.54, "end": 1995.54, "text": " I daresay it too is only getting better and better the more the software is able to adapt", "tokens": [51064, 286, 50213, 320, 309, 886, 307, 787, 1242, 1101, 293, 1101, 264, 544, 264, 4722, 307, 1075, 281, 6231, 51264], "temperature": 0.0, "avg_logprob": -0.06993979172740909, "compression_ratio": 1.7581120943952802, "no_speech_prob": 0.02442127652466297}, {"id": 453, "seek": 197754, "start": 1995.54, "end": 1998.54, "text": " to different handwriting styles such as this.", "tokens": [51264, 281, 819, 39179, 13273, 1270, 382, 341, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06993979172740909, "compression_ratio": 1.7581120943952802, "no_speech_prob": 0.02442127652466297}, {"id": 454, "seek": 197754, "start": 1998.54, "end": 2002.54, "text": " Recommendation histories and the like, whether using Netflix or any other service,", "tokens": [51414, 49545, 521, 399, 30631, 293, 264, 411, 11, 1968, 1228, 12778, 420, 604, 661, 2643, 11, 51614], "temperature": 0.0, "avg_logprob": -0.06993979172740909, "compression_ratio": 1.7581120943952802, "no_speech_prob": 0.02442127652466297}, {"id": 455, "seek": 197754, "start": 2002.54, "end": 2006.54, "text": " have gotten better and better at recommending things you might like based on things", "tokens": [51614, 362, 5768, 1101, 293, 1101, 412, 30559, 721, 291, 1062, 411, 2361, 322, 721, 51814], "temperature": 0.0, "avg_logprob": -0.06993979172740909, "compression_ratio": 1.7581120943952802, "no_speech_prob": 0.02442127652466297}, {"id": 456, "seek": 200654, "start": 2006.54, "end": 2010.54, "text": " you have liked and maybe based on things other people who like the same thing", "tokens": [50364, 291, 362, 4501, 293, 1310, 2361, 322, 721, 661, 561, 567, 411, 264, 912, 551, 50564], "temperature": 0.0, "avg_logprob": -0.0853189134249722, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.0023966419976204634}, {"id": 457, "seek": 200654, "start": 2010.54, "end": 2012.54, "text": " as you might have liked.", "tokens": [50564, 382, 291, 1062, 362, 4501, 13, 50664], "temperature": 0.0, "avg_logprob": -0.0853189134249722, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.0023966419976204634}, {"id": 458, "seek": 200654, "start": 2012.54, "end": 2014.54, "text": " And suffice it to say, there's no one at Netflix,", "tokens": [50664, 400, 3889, 573, 309, 281, 584, 11, 456, 311, 572, 472, 412, 12778, 11, 50764], "temperature": 0.0, "avg_logprob": -0.0853189134249722, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.0023966419976204634}, {"id": 459, "seek": 200654, "start": 2014.54, "end": 2016.54, "text": " akin to the old like VHS stores of yesteryear,", "tokens": [50764, 47540, 281, 264, 1331, 411, 691, 12527, 9512, 295, 288, 3011, 5294, 11, 50864], "temperature": 0.0, "avg_logprob": -0.0853189134249722, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.0023966419976204634}, {"id": 460, "seek": 200654, "start": 2016.54, "end": 2020.54, "text": " who are recommending to you specifically what movie you might like", "tokens": [50864, 567, 366, 30559, 281, 291, 4682, 437, 3169, 291, 1062, 411, 51064], "temperature": 0.0, "avg_logprob": -0.0853189134249722, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.0023966419976204634}, {"id": 461, "seek": 200654, "start": 2020.54, "end": 2025.54, "text": " and there's no code, no algorithm that says if they like X, then recommend Y.", "tokens": [51064, 293, 456, 311, 572, 3089, 11, 572, 9284, 300, 1619, 498, 436, 411, 1783, 11, 550, 2748, 398, 13, 51314], "temperature": 0.0, "avg_logprob": -0.0853189134249722, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.0023966419976204634}, {"id": 462, "seek": 200654, "start": 2025.54, "end": 2028.54, "text": " Elts recommend Z because there's just too many movies, too many people,", "tokens": [51314, 2699, 1373, 2748, 1176, 570, 456, 311, 445, 886, 867, 6233, 11, 886, 867, 561, 11, 51464], "temperature": 0.0, "avg_logprob": -0.0853189134249722, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.0023966419976204634}, {"id": 463, "seek": 200654, "start": 2028.54, "end": 2030.54, "text": " too many different tastes in the world.", "tokens": [51464, 886, 867, 819, 8666, 294, 264, 1002, 13, 51564], "temperature": 0.0, "avg_logprob": -0.0853189134249722, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.0023966419976204634}, {"id": 464, "seek": 200654, "start": 2030.54, "end": 2034.54, "text": " So AI is increasingly sort of looking for patterns that might not even be obvious", "tokens": [51564, 407, 7318, 307, 12980, 1333, 295, 1237, 337, 8294, 300, 1062, 406, 754, 312, 6322, 51764], "temperature": 0.0, "avg_logprob": -0.0853189134249722, "compression_ratio": 1.7581699346405228, "no_speech_prob": 0.0023966419976204634}, {"id": 465, "seek": 203454, "start": 2034.54, "end": 2037.54, "text": " to us humans and dynamically figuring out what might be good for me,", "tokens": [50364, 281, 505, 6255, 293, 43492, 15213, 484, 437, 1062, 312, 665, 337, 385, 11, 50514], "temperature": 0.0, "avg_logprob": -0.08599724605165679, "compression_ratio": 1.7126099706744868, "no_speech_prob": 0.0009697015630081296}, {"id": 466, "seek": 203454, "start": 2037.54, "end": 2040.54, "text": " for you, or you, or anyone else.", "tokens": [50514, 337, 291, 11, 420, 291, 11, 420, 2878, 1646, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08599724605165679, "compression_ratio": 1.7126099706744868, "no_speech_prob": 0.0009697015630081296}, {"id": 467, "seek": 203454, "start": 2040.54, "end": 2044.54, "text": " Siri, Google Assistant, Alexa, any of these voice recognition tools", "tokens": [50664, 33682, 11, 3329, 14890, 11, 22595, 11, 604, 295, 613, 3177, 11150, 3873, 50864], "temperature": 0.0, "avg_logprob": -0.08599724605165679, "compression_ratio": 1.7126099706744868, "no_speech_prob": 0.0009697015630081296}, {"id": 468, "seek": 203454, "start": 2044.54, "end": 2049.54, "text": " that are answering questions that too suffice it to say is all powered by AI.", "tokens": [50864, 300, 366, 13430, 1651, 300, 886, 3889, 573, 309, 281, 584, 307, 439, 17786, 538, 7318, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08599724605165679, "compression_ratio": 1.7126099706744868, "no_speech_prob": 0.0009697015630081296}, {"id": 469, "seek": 203454, "start": 2049.54, "end": 2052.54, "text": " But let's start with something a little simpler than any of those applications", "tokens": [51114, 583, 718, 311, 722, 365, 746, 257, 707, 18587, 813, 604, 295, 729, 5821, 51264], "temperature": 0.0, "avg_logprob": -0.08599724605165679, "compression_ratio": 1.7126099706744868, "no_speech_prob": 0.0009697015630081296}, {"id": 470, "seek": 203454, "start": 2052.54, "end": 2055.54, "text": " and this is one of the first arcade games from yesteryear known as Pong", "tokens": [51264, 293, 341, 307, 472, 295, 264, 700, 25664, 2813, 490, 288, 3011, 5294, 2570, 382, 430, 556, 51414], "temperature": 0.0, "avg_logprob": -0.08599724605165679, "compression_ratio": 1.7126099706744868, "no_speech_prob": 0.0009697015630081296}, {"id": 471, "seek": 203454, "start": 2055.54, "end": 2059.54, "text": " and it's sort of like table tennis and person on the left can move their paddle up and down.", "tokens": [51414, 293, 309, 311, 1333, 295, 411, 3199, 18118, 293, 954, 322, 264, 1411, 393, 1286, 641, 31834, 493, 293, 760, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08599724605165679, "compression_ratio": 1.7126099706744868, "no_speech_prob": 0.0009697015630081296}, {"id": 472, "seek": 203454, "start": 2059.54, "end": 2063.54, "text": " Personal on the right can do the same and the goal is to get the ball past the other person.", "tokens": [51614, 25317, 322, 264, 558, 393, 360, 264, 912, 293, 264, 3387, 307, 281, 483, 264, 2594, 1791, 264, 661, 954, 13, 51814], "temperature": 0.0, "avg_logprob": -0.08599724605165679, "compression_ratio": 1.7126099706744868, "no_speech_prob": 0.0009697015630081296}, {"id": 473, "seek": 206354, "start": 2063.54, "end": 2067.54, "text": " Or conversely, make sure it hits your paddle and bounces back.", "tokens": [50364, 1610, 2615, 736, 11, 652, 988, 309, 8664, 428, 31834, 293, 46901, 646, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06158090004554162, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.002550841309130192}, {"id": 474, "seek": 206354, "start": 2067.54, "end": 2072.54, "text": " Well, somewhat simpler than this and so far as it can be one player is another Atari game", "tokens": [50564, 1042, 11, 8344, 18587, 813, 341, 293, 370, 1400, 382, 309, 393, 312, 472, 4256, 307, 1071, 41381, 1216, 50814], "temperature": 0.0, "avg_logprob": -0.06158090004554162, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.002550841309130192}, {"id": 475, "seek": 206354, "start": 2072.54, "end": 2075.54, "text": " from yesteryear known as Breakout whereby you're essentially just trying to bang the ball", "tokens": [50814, 490, 288, 3011, 5294, 2570, 382, 16925, 346, 36998, 291, 434, 4476, 445, 1382, 281, 8550, 264, 2594, 50964], "temperature": 0.0, "avg_logprob": -0.06158090004554162, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.002550841309130192}, {"id": 476, "seek": 206354, "start": 2075.54, "end": 2080.54, "text": " against the bricks to get more and more points and get rid of all of those bricks.", "tokens": [50964, 1970, 264, 25497, 281, 483, 544, 293, 544, 2793, 293, 483, 3973, 295, 439, 295, 729, 25497, 13, 51214], "temperature": 0.0, "avg_logprob": -0.06158090004554162, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.002550841309130192}, {"id": 477, "seek": 206354, "start": 2080.54, "end": 2084.54, "text": " But all of us in this room probably have a human instinct for how to win this game", "tokens": [51214, 583, 439, 295, 505, 294, 341, 1808, 1391, 362, 257, 1952, 16556, 337, 577, 281, 1942, 341, 1216, 51414], "temperature": 0.0, "avg_logprob": -0.06158090004554162, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.002550841309130192}, {"id": 478, "seek": 206354, "start": 2084.54, "end": 2086.54, "text": " or at least how to play this game.", "tokens": [51414, 420, 412, 1935, 577, 281, 862, 341, 1216, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06158090004554162, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.002550841309130192}, {"id": 479, "seek": 206354, "start": 2086.54, "end": 2091.54, "text": " For instance, if the ball pictured here back in the 80s as a single red dot", "tokens": [51514, 1171, 5197, 11, 498, 264, 2594, 49896, 510, 646, 294, 264, 4688, 82, 382, 257, 2167, 2182, 5893, 51764], "temperature": 0.0, "avg_logprob": -0.06158090004554162, "compression_ratio": 1.6905537459283388, "no_speech_prob": 0.002550841309130192}, {"id": 480, "seek": 209154, "start": 2091.54, "end": 2095.54, "text": " just left the paddle pictured here is a red line,", "tokens": [50364, 445, 1411, 264, 31834, 49896, 510, 307, 257, 2182, 1622, 11, 50564], "temperature": 0.0, "avg_logprob": -0.11333073134970877, "compression_ratio": 1.7204301075268817, "no_speech_prob": 0.0005883987760171294}, {"id": 481, "seek": 209154, "start": 2095.54, "end": 2098.54, "text": " where is the ball presumably going to go next?", "tokens": [50564, 689, 307, 264, 2594, 26742, 516, 281, 352, 958, 30, 50714], "temperature": 0.0, "avg_logprob": -0.11333073134970877, "compression_ratio": 1.7204301075268817, "no_speech_prob": 0.0005883987760171294}, {"id": 482, "seek": 209154, "start": 2098.54, "end": 2103.54, "text": " And in turn, which direction should I slide my paddle to the left or to the right?", "tokens": [50714, 400, 294, 1261, 11, 597, 3513, 820, 286, 4137, 452, 31834, 281, 264, 1411, 420, 281, 264, 558, 30, 50964], "temperature": 0.0, "avg_logprob": -0.11333073134970877, "compression_ratio": 1.7204301075268817, "no_speech_prob": 0.0005883987760171294}, {"id": 483, "seek": 209154, "start": 2103.54, "end": 2108.54, "text": " So presumably to the left and we all have an eye for what seem to be the digital physics of that", "tokens": [50964, 407, 26742, 281, 264, 1411, 293, 321, 439, 362, 364, 3313, 337, 437, 1643, 281, 312, 264, 4562, 10649, 295, 300, 51214], "temperature": 0.0, "avg_logprob": -0.11333073134970877, "compression_ratio": 1.7204301075268817, "no_speech_prob": 0.0005883987760171294}, {"id": 484, "seek": 209154, "start": 2108.54, "end": 2112.54, "text": " and indeed that would then be an algorithm sort of step by step instructions", "tokens": [51214, 293, 6451, 300, 576, 550, 312, 364, 9284, 1333, 295, 1823, 538, 1823, 9415, 51414], "temperature": 0.0, "avg_logprob": -0.11333073134970877, "compression_ratio": 1.7204301075268817, "no_speech_prob": 0.0005883987760171294}, {"id": 485, "seek": 209154, "start": 2112.54, "end": 2114.54, "text": " for solving some problem.", "tokens": [51414, 337, 12606, 512, 1154, 13, 51514], "temperature": 0.0, "avg_logprob": -0.11333073134970877, "compression_ratio": 1.7204301075268817, "no_speech_prob": 0.0005883987760171294}, {"id": 486, "seek": 209154, "start": 2114.54, "end": 2118.54, "text": " So how can we now translate that human intuition to what we describe more as artificial intelligence", "tokens": [51514, 407, 577, 393, 321, 586, 13799, 300, 1952, 24002, 281, 437, 321, 6786, 544, 382, 11677, 7599, 51714], "temperature": 0.0, "avg_logprob": -0.11333073134970877, "compression_ratio": 1.7204301075268817, "no_speech_prob": 0.0005883987760171294}, {"id": 487, "seek": 211854, "start": 2118.54, "end": 2121.54, "text": " not nearly as sophisticated as those other applications,", "tokens": [50364, 406, 6217, 382, 16950, 382, 729, 661, 5821, 11, 50514], "temperature": 0.0, "avg_logprob": -0.08294055421473616, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0012842862633988261}, {"id": 488, "seek": 211854, "start": 2121.54, "end": 2123.54, "text": " but will indeed start with some basics?", "tokens": [50514, 457, 486, 6451, 722, 365, 512, 14688, 30, 50614], "temperature": 0.0, "avg_logprob": -0.08294055421473616, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0012842862633988261}, {"id": 489, "seek": 211854, "start": 2123.54, "end": 2127.54, "text": " You might know from economics or strategic thinking or computer science", "tokens": [50614, 509, 1062, 458, 490, 14564, 420, 10924, 1953, 420, 3820, 3497, 50814], "temperature": 0.0, "avg_logprob": -0.08294055421473616, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0012842862633988261}, {"id": 490, "seek": 211854, "start": 2127.54, "end": 2131.54, "text": " this idea of a decision tree that allows you to decide should I go this way or this way", "tokens": [50814, 341, 1558, 295, 257, 3537, 4230, 300, 4045, 291, 281, 4536, 820, 286, 352, 341, 636, 420, 341, 636, 51014], "temperature": 0.0, "avg_logprob": -0.08294055421473616, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0012842862633988261}, {"id": 491, "seek": 211854, "start": 2131.54, "end": 2133.54, "text": " when it comes to making a decision.", "tokens": [51014, 562, 309, 1487, 281, 1455, 257, 3537, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08294055421473616, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0012842862633988261}, {"id": 492, "seek": 211854, "start": 2133.54, "end": 2138.54, "text": " So let's consider how we could draw a picture to represent even something simplistic like Breakout.", "tokens": [51114, 407, 718, 311, 1949, 577, 321, 727, 2642, 257, 3036, 281, 2906, 754, 746, 44199, 411, 16925, 346, 13, 51364], "temperature": 0.0, "avg_logprob": -0.08294055421473616, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0012842862633988261}, {"id": 493, "seek": 211854, "start": 2138.54, "end": 2142.54, "text": " Well, if the ball is left of the paddle is a question or a boolean expression", "tokens": [51364, 1042, 11, 498, 264, 2594, 307, 1411, 295, 264, 31834, 307, 257, 1168, 420, 257, 748, 4812, 282, 6114, 51564], "temperature": 0.0, "avg_logprob": -0.08294055421473616, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0012842862633988261}, {"id": 494, "seek": 211854, "start": 2142.54, "end": 2144.54, "text": " I might ask myself in code.", "tokens": [51564, 286, 1062, 1029, 2059, 294, 3089, 13, 51664], "temperature": 0.0, "avg_logprob": -0.08294055421473616, "compression_ratio": 1.6435643564356435, "no_speech_prob": 0.0012842862633988261}, {"id": 495, "seek": 214454, "start": 2144.54, "end": 2148.54, "text": " If yes, then I should move my paddle left as most everyone just said.", "tokens": [50364, 759, 2086, 11, 550, 286, 820, 1286, 452, 31834, 1411, 382, 881, 1518, 445, 848, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07924487855699328, "compression_ratio": 1.8701754385964913, "no_speech_prob": 0.0007793587283231318}, {"id": 496, "seek": 214454, "start": 2148.54, "end": 2152.54, "text": " Else, if the ball is not left of paddle, what do I want to do?", "tokens": [50564, 45472, 11, 498, 264, 2594, 307, 406, 1411, 295, 31834, 11, 437, 360, 286, 528, 281, 360, 30, 50764], "temperature": 0.0, "avg_logprob": -0.07924487855699328, "compression_ratio": 1.8701754385964913, "no_speech_prob": 0.0007793587283231318}, {"id": 497, "seek": 214454, "start": 2152.54, "end": 2154.54, "text": " Well, I want to ask a question.", "tokens": [50764, 1042, 11, 286, 528, 281, 1029, 257, 1168, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07924487855699328, "compression_ratio": 1.8701754385964913, "no_speech_prob": 0.0007793587283231318}, {"id": 498, "seek": 214454, "start": 2154.54, "end": 2156.54, "text": " I don't want to just instinctively go right.", "tokens": [50864, 286, 500, 380, 528, 281, 445, 16556, 3413, 352, 558, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07924487855699328, "compression_ratio": 1.8701754385964913, "no_speech_prob": 0.0007793587283231318}, {"id": 499, "seek": 214454, "start": 2156.54, "end": 2158.54, "text": " I want to check is the ball to the right of the paddle.", "tokens": [50964, 286, 528, 281, 1520, 307, 264, 2594, 281, 264, 558, 295, 264, 31834, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07924487855699328, "compression_ratio": 1.8701754385964913, "no_speech_prob": 0.0007793587283231318}, {"id": 500, "seek": 214454, "start": 2158.54, "end": 2162.54, "text": " And if yes, well then yes, go ahead and move the paddle right.", "tokens": [51064, 400, 498, 2086, 11, 731, 550, 2086, 11, 352, 2286, 293, 1286, 264, 31834, 558, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07924487855699328, "compression_ratio": 1.8701754385964913, "no_speech_prob": 0.0007793587283231318}, {"id": 501, "seek": 214454, "start": 2162.54, "end": 2166.54, "text": " But there is a third situation which is right.", "tokens": [51264, 583, 456, 307, 257, 2636, 2590, 597, 307, 558, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07924487855699328, "compression_ratio": 1.8701754385964913, "no_speech_prob": 0.0007793587283231318}, {"id": 502, "seek": 214454, "start": 2166.54, "end": 2167.54, "text": " Like don't move.", "tokens": [51464, 1743, 500, 380, 1286, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07924487855699328, "compression_ratio": 1.8701754385964913, "no_speech_prob": 0.0007793587283231318}, {"id": 503, "seek": 214454, "start": 2167.54, "end": 2168.54, "text": " It's coming right at you.", "tokens": [51514, 467, 311, 1348, 558, 412, 291, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07924487855699328, "compression_ratio": 1.8701754385964913, "no_speech_prob": 0.0007793587283231318}, {"id": 504, "seek": 214454, "start": 2168.54, "end": 2169.54, "text": " So that would be the third scenario here.", "tokens": [51564, 407, 300, 576, 312, 264, 2636, 9005, 510, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07924487855699328, "compression_ratio": 1.8701754385964913, "no_speech_prob": 0.0007793587283231318}, {"id": 505, "seek": 214454, "start": 2169.54, "end": 2171.54, "text": " No, it's not to the right or to the left.", "tokens": [51614, 883, 11, 309, 311, 406, 281, 264, 558, 420, 281, 264, 1411, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07924487855699328, "compression_ratio": 1.8701754385964913, "no_speech_prob": 0.0007793587283231318}, {"id": 506, "seek": 214454, "start": 2171.54, "end": 2172.54, "text": " So just don't move the paddle.", "tokens": [51714, 407, 445, 500, 380, 1286, 264, 31834, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07924487855699328, "compression_ratio": 1.8701754385964913, "no_speech_prob": 0.0007793587283231318}, {"id": 507, "seek": 217254, "start": 2172.54, "end": 2174.54, "text": " You got lucky and it's coming, for instance, straight down.", "tokens": [50364, 509, 658, 6356, 293, 309, 311, 1348, 11, 337, 5197, 11, 2997, 760, 13, 50464], "temperature": 0.0, "avg_logprob": -0.10309065050548977, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631509443745017}, {"id": 508, "seek": 217254, "start": 2174.54, "end": 2178.54, "text": " So Breakout is fairly straightforward when it comes to an algorithm.", "tokens": [50464, 407, 16925, 346, 307, 6457, 15325, 562, 309, 1487, 281, 364, 9284, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10309065050548977, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631509443745017}, {"id": 509, "seek": 217254, "start": 2178.54, "end": 2183.54, "text": " And we can actually translate this as any CS50 student now could to code or pseudocode,", "tokens": [50664, 400, 321, 393, 767, 13799, 341, 382, 604, 9460, 2803, 3107, 586, 727, 281, 3089, 420, 25505, 532, 905, 1429, 11, 50914], "temperature": 0.0, "avg_logprob": -0.10309065050548977, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631509443745017}, {"id": 510, "seek": 217254, "start": 2183.54, "end": 2187.54, "text": " sort of English like code that's independent of Java, C, C++,", "tokens": [50914, 1333, 295, 3669, 411, 3089, 300, 311, 6695, 295, 10745, 11, 383, 11, 383, 25472, 11, 51114], "temperature": 0.0, "avg_logprob": -0.10309065050548977, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631509443745017}, {"id": 511, "seek": 217254, "start": 2187.54, "end": 2189.54, "text": " and all of the programming languages of today.", "tokens": [51114, 293, 439, 295, 264, 9410, 8650, 295, 965, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10309065050548977, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631509443745017}, {"id": 512, "seek": 217254, "start": 2189.54, "end": 2194.54, "text": " So in English, pseudocode, while a game is ongoing, if the ball is left of paddle,", "tokens": [51214, 407, 294, 3669, 11, 25505, 532, 905, 1429, 11, 1339, 257, 1216, 307, 10452, 11, 498, 264, 2594, 307, 1411, 295, 31834, 11, 51464], "temperature": 0.0, "avg_logprob": -0.10309065050548977, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631509443745017}, {"id": 513, "seek": 217254, "start": 2194.54, "end": 2196.54, "text": " I should move paddle left.", "tokens": [51464, 286, 820, 1286, 31834, 1411, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10309065050548977, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631509443745017}, {"id": 514, "seek": 217254, "start": 2196.54, "end": 2201.54, "text": " Else, if ball is right of the paddle, I should say paddle, that's a bug, not intended today,", "tokens": [51564, 45472, 11, 498, 2594, 307, 558, 295, 264, 31834, 11, 286, 820, 584, 31834, 11, 300, 311, 257, 7426, 11, 406, 10226, 965, 11, 51814], "temperature": 0.0, "avg_logprob": -0.10309065050548977, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.002631509443745017}, {"id": 515, "seek": 220154, "start": 2201.54, "end": 2203.54, "text": " move paddle right.", "tokens": [50364, 1286, 31834, 558, 13, 50464], "temperature": 0.0, "avg_logprob": -0.06908835345552168, "compression_ratio": 1.6716867469879517, "no_speech_prob": 0.0029808827675879}, {"id": 516, "seek": 220154, "start": 2203.54, "end": 2205.54, "text": " Else, don't move the paddle.", "tokens": [50464, 45472, 11, 500, 380, 1286, 264, 31834, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06908835345552168, "compression_ratio": 1.6716867469879517, "no_speech_prob": 0.0029808827675879}, {"id": 517, "seek": 220154, "start": 2205.54, "end": 2211.54, "text": " So that too represents a translation of this intuition to code that's very deterministic.", "tokens": [50564, 407, 300, 886, 8855, 257, 12853, 295, 341, 24002, 281, 3089, 300, 311, 588, 15957, 3142, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06908835345552168, "compression_ratio": 1.6716867469879517, "no_speech_prob": 0.0029808827675879}, {"id": 518, "seek": 220154, "start": 2211.54, "end": 2214.54, "text": " You can sort of anticipate all possible scenarios, capture it in code.", "tokens": [50864, 509, 393, 1333, 295, 21685, 439, 1944, 15077, 11, 7983, 309, 294, 3089, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06908835345552168, "compression_ratio": 1.6716867469879517, "no_speech_prob": 0.0029808827675879}, {"id": 519, "seek": 220154, "start": 2214.54, "end": 2217.54, "text": " And frankly, this should be the most boring game of Breakout", "tokens": [51014, 400, 11939, 11, 341, 820, 312, 264, 881, 9989, 1216, 295, 16925, 346, 51164], "temperature": 0.0, "avg_logprob": -0.06908835345552168, "compression_ratio": 1.6716867469879517, "no_speech_prob": 0.0029808827675879}, {"id": 520, "seek": 220154, "start": 2217.54, "end": 2221.54, "text": " because the paddle should just perfectly play this game assuming there's no variables", "tokens": [51164, 570, 264, 31834, 820, 445, 6239, 862, 341, 1216, 11926, 456, 311, 572, 9102, 51364], "temperature": 0.0, "avg_logprob": -0.06908835345552168, "compression_ratio": 1.6716867469879517, "no_speech_prob": 0.0029808827675879}, {"id": 521, "seek": 220154, "start": 2221.54, "end": 2224.54, "text": " or randomness when it comes to speed or angles or the like,", "tokens": [51364, 420, 4974, 1287, 562, 309, 1487, 281, 3073, 420, 14708, 420, 264, 411, 11, 51514], "temperature": 0.0, "avg_logprob": -0.06908835345552168, "compression_ratio": 1.6716867469879517, "no_speech_prob": 0.0029808827675879}, {"id": 522, "seek": 220154, "start": 2224.54, "end": 2227.54, "text": " which real world games certainly try to introduce.", "tokens": [51514, 597, 957, 1002, 2813, 3297, 853, 281, 5366, 13, 51664], "temperature": 0.0, "avg_logprob": -0.06908835345552168, "compression_ratio": 1.6716867469879517, "no_speech_prob": 0.0029808827675879}, {"id": 523, "seek": 220154, "start": 2227.54, "end": 2230.54, "text": " But let's consider another game from yesteryear that you might play with your kids today", "tokens": [51664, 583, 718, 311, 1949, 1071, 1216, 490, 288, 3011, 5294, 300, 291, 1062, 862, 365, 428, 2301, 965, 51814], "temperature": 0.0, "avg_logprob": -0.06908835345552168, "compression_ratio": 1.6716867469879517, "no_speech_prob": 0.0029808827675879}, {"id": 524, "seek": 223054, "start": 2230.54, "end": 2232.54, "text": " or you did yourself growing up.", "tokens": [50364, 420, 291, 630, 1803, 4194, 493, 13, 50464], "temperature": 0.0, "avg_logprob": -0.07161613611074594, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0010322070447728038}, {"id": 525, "seek": 223054, "start": 2232.54, "end": 2233.54, "text": " Here's Tic Tac Toe.", "tokens": [50464, 1692, 311, 314, 299, 38848, 1407, 68, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07161613611074594, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0010322070447728038}, {"id": 526, "seek": 223054, "start": 2233.54, "end": 2237.54, "text": " And for those unfamiliar, the goal is to get three O's in a row or three X's in a row,", "tokens": [50514, 400, 337, 729, 29415, 11, 264, 3387, 307, 281, 483, 1045, 422, 311, 294, 257, 5386, 420, 1045, 1783, 311, 294, 257, 5386, 11, 50714], "temperature": 0.0, "avg_logprob": -0.07161613611074594, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0010322070447728038}, {"id": 527, "seek": 223054, "start": 2237.54, "end": 2240.54, "text": " vertically, horizontally, or diagonally.", "tokens": [50714, 28450, 11, 33796, 11, 420, 17405, 379, 13, 50864], "temperature": 0.0, "avg_logprob": -0.07161613611074594, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0010322070447728038}, {"id": 528, "seek": 223054, "start": 2240.54, "end": 2243.54, "text": " So suppose it's now X's turn.", "tokens": [50864, 407, 7297, 309, 311, 586, 1783, 311, 1261, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07161613611074594, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0010322070447728038}, {"id": 529, "seek": 223054, "start": 2243.54, "end": 2247.54, "text": " If you've played Tic Tac Toe, most of you probably just have an immediate instinct", "tokens": [51014, 759, 291, 600, 3737, 314, 299, 38848, 1407, 68, 11, 881, 295, 291, 1391, 445, 362, 364, 11629, 16556, 51214], "temperature": 0.0, "avg_logprob": -0.07161613611074594, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0010322070447728038}, {"id": 530, "seek": 223054, "start": 2247.54, "end": 2252.54, "text": " as to where X should probably go so that it doesn't lose instantaneously.", "tokens": [51214, 382, 281, 689, 1783, 820, 1391, 352, 370, 300, 309, 1177, 380, 3624, 9836, 13131, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07161613611074594, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0010322070447728038}, {"id": 531, "seek": 223054, "start": 2252.54, "end": 2256.54, "text": " But let's consider, in the more general case, how do you solve Tic Tac Toe?", "tokens": [51464, 583, 718, 311, 1949, 11, 294, 264, 544, 2674, 1389, 11, 577, 360, 291, 5039, 314, 299, 38848, 1407, 68, 30, 51664], "temperature": 0.0, "avg_logprob": -0.07161613611074594, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0010322070447728038}, {"id": 532, "seek": 225654, "start": 2256.54, "end": 2260.54, "text": " Frankly, if you're in the habit of losing Tic Tac Toe, but you're not trying to lose Tic Toe,", "tokens": [50364, 41344, 11, 498, 291, 434, 294, 264, 7164, 295, 7027, 314, 299, 38848, 1407, 68, 11, 457, 291, 434, 406, 1382, 281, 3624, 314, 299, 1407, 68, 11, 50564], "temperature": 0.0, "avg_logprob": -0.0604153833571513, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.003172603901475668}, {"id": 533, "seek": 225654, "start": 2260.54, "end": 2262.54, "text": " you're actually playing it wrong.", "tokens": [50564, 291, 434, 767, 2433, 309, 2085, 13, 50664], "temperature": 0.0, "avg_logprob": -0.0604153833571513, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.003172603901475668}, {"id": 534, "seek": 225654, "start": 2262.54, "end": 2265.54, "text": " Like you should minimally be able to always force a tie in Tic Tac Toe,", "tokens": [50664, 1743, 291, 820, 4464, 379, 312, 1075, 281, 1009, 3464, 257, 7582, 294, 314, 299, 38848, 1407, 68, 11, 50814], "temperature": 0.0, "avg_logprob": -0.0604153833571513, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.003172603901475668}, {"id": 535, "seek": 225654, "start": 2265.54, "end": 2268.54, "text": " and better yet, you should be able to beat the other person.", "tokens": [50814, 293, 1101, 1939, 11, 291, 820, 312, 1075, 281, 4224, 264, 661, 954, 13, 50964], "temperature": 0.0, "avg_logprob": -0.0604153833571513, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.003172603901475668}, {"id": 536, "seek": 225654, "start": 2268.54, "end": 2271.54, "text": " So hopefully, everyone now will soon walk away with this strategy.", "tokens": [50964, 407, 4696, 11, 1518, 586, 486, 2321, 1792, 1314, 365, 341, 5206, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0604153833571513, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.003172603901475668}, {"id": 537, "seek": 225654, "start": 2271.54, "end": 2274.54, "text": " So how can we borrow inspiration from those same decision trees", "tokens": [51114, 407, 577, 393, 321, 11172, 10249, 490, 729, 912, 3537, 5852, 51264], "temperature": 0.0, "avg_logprob": -0.0604153833571513, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.003172603901475668}, {"id": 538, "seek": 225654, "start": 2274.54, "end": 2276.54, "text": " and do something similar here?", "tokens": [51264, 293, 360, 746, 2531, 510, 30, 51364], "temperature": 0.0, "avg_logprob": -0.0604153833571513, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.003172603901475668}, {"id": 539, "seek": 225654, "start": 2276.54, "end": 2281.54, "text": " So if you, the player, ask yourself, can I get three in a row on this turn?", "tokens": [51364, 407, 498, 291, 11, 264, 4256, 11, 1029, 1803, 11, 393, 286, 483, 1045, 294, 257, 5386, 322, 341, 1261, 30, 51614], "temperature": 0.0, "avg_logprob": -0.0604153833571513, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.003172603901475668}, {"id": 540, "seek": 225654, "start": 2281.54, "end": 2285.54, "text": " Well, if yes, then you should do that and play the X in that position.", "tokens": [51614, 1042, 11, 498, 2086, 11, 550, 291, 820, 360, 300, 293, 862, 264, 1783, 294, 300, 2535, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0604153833571513, "compression_ratio": 1.7453987730061349, "no_speech_prob": 0.003172603901475668}, {"id": 541, "seek": 228554, "start": 2285.54, "end": 2287.54, "text": " Play in the square to get three in a row.", "tokens": [50364, 5506, 294, 264, 3732, 281, 483, 1045, 294, 257, 5386, 13, 50464], "temperature": 0.0, "avg_logprob": -0.08566010176245846, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.00031503543141297996}, {"id": 542, "seek": 228554, "start": 2287.54, "end": 2288.54, "text": " Straight forward.", "tokens": [50464, 26908, 2128, 13, 50514], "temperature": 0.0, "avg_logprob": -0.08566010176245846, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.00031503543141297996}, {"id": 543, "seek": 228554, "start": 2288.54, "end": 2291.54, "text": " If you can't get three in a row in this turn, you should ask another question.", "tokens": [50514, 759, 291, 393, 380, 483, 1045, 294, 257, 5386, 294, 341, 1261, 11, 291, 820, 1029, 1071, 1168, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08566010176245846, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.00031503543141297996}, {"id": 544, "seek": 228554, "start": 2291.54, "end": 2294.54, "text": " Can my opponent get three in a row in their next turn?", "tokens": [50664, 1664, 452, 10620, 483, 1045, 294, 257, 5386, 294, 641, 958, 1261, 30, 50814], "temperature": 0.0, "avg_logprob": -0.08566010176245846, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.00031503543141297996}, {"id": 545, "seek": 228554, "start": 2294.54, "end": 2299.54, "text": " Because then you better preempt that by moving into that position.", "tokens": [50814, 1436, 550, 291, 1101, 659, 4543, 300, 538, 2684, 666, 300, 2535, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08566010176245846, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.00031503543141297996}, {"id": 546, "seek": 228554, "start": 2299.54, "end": 2304.54, "text": " Play in the square to block opponent three's three in a row.", "tokens": [51064, 5506, 294, 264, 3732, 281, 3461, 10620, 1045, 311, 1045, 294, 257, 5386, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08566010176245846, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.00031503543141297996}, {"id": 547, "seek": 228554, "start": 2304.54, "end": 2306.54, "text": " What if, though, that's not the case?", "tokens": [51314, 708, 498, 11, 1673, 11, 300, 311, 406, 264, 1389, 30, 51414], "temperature": 0.0, "avg_logprob": -0.08566010176245846, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.00031503543141297996}, {"id": 548, "seek": 228554, "start": 2306.54, "end": 2309.54, "text": " What if there aren't even that many X's and O's on the board?", "tokens": [51414, 708, 498, 456, 3212, 380, 754, 300, 867, 1783, 311, 293, 422, 311, 322, 264, 3150, 30, 51564], "temperature": 0.0, "avg_logprob": -0.08566010176245846, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.00031503543141297996}, {"id": 549, "seek": 228554, "start": 2309.54, "end": 2311.54, "text": " If you're in the habit of just kind of playing randomly,", "tokens": [51564, 759, 291, 434, 294, 264, 7164, 295, 445, 733, 295, 2433, 16979, 11, 51664], "temperature": 0.0, "avg_logprob": -0.08566010176245846, "compression_ratio": 1.8244274809160306, "no_speech_prob": 0.00031503543141297996}, {"id": 550, "seek": 231154, "start": 2311.54, "end": 2315.54, "text": " like your mate might not be playing optimally as a good AI could.", "tokens": [50364, 411, 428, 11709, 1062, 406, 312, 2433, 5028, 379, 382, 257, 665, 7318, 727, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1030031730388773, "compression_ratio": 1.7146892655367232, "no_speech_prob": 0.004331414122134447}, {"id": 551, "seek": 231154, "start": 2315.54, "end": 2317.54, "text": " So if no, it's kind of a question mark.", "tokens": [50564, 407, 498, 572, 11, 309, 311, 733, 295, 257, 1168, 1491, 13, 50664], "temperature": 0.0, "avg_logprob": -0.1030031730388773, "compression_ratio": 1.7146892655367232, "no_speech_prob": 0.004331414122134447}, {"id": 552, "seek": 231154, "start": 2317.54, "end": 2321.54, "text": " In fact, there's probably more to this tree because we could think through,", "tokens": [50664, 682, 1186, 11, 456, 311, 1391, 544, 281, 341, 4230, 570, 321, 727, 519, 807, 11, 50864], "temperature": 0.0, "avg_logprob": -0.1030031730388773, "compression_ratio": 1.7146892655367232, "no_speech_prob": 0.004331414122134447}, {"id": 553, "seek": 231154, "start": 2321.54, "end": 2322.54, "text": " what if I go there?", "tokens": [50864, 437, 498, 286, 352, 456, 30, 50914], "temperature": 0.0, "avg_logprob": -0.1030031730388773, "compression_ratio": 1.7146892655367232, "no_speech_prob": 0.004331414122134447}, {"id": 554, "seek": 231154, "start": 2322.54, "end": 2324.54, "text": " Wait a minute, what if I go there or there or there?", "tokens": [50914, 3802, 257, 3456, 11, 437, 498, 286, 352, 456, 420, 456, 420, 456, 30, 51014], "temperature": 0.0, "avg_logprob": -0.1030031730388773, "compression_ratio": 1.7146892655367232, "no_speech_prob": 0.004331414122134447}, {"id": 555, "seek": 231154, "start": 2324.54, "end": 2327.54, "text": " You can start to think a few steps ahead as a computer could do much better", "tokens": [51014, 509, 393, 722, 281, 519, 257, 1326, 4439, 2286, 382, 257, 3820, 727, 360, 709, 1101, 51164], "temperature": 0.0, "avg_logprob": -0.1030031730388773, "compression_ratio": 1.7146892655367232, "no_speech_prob": 0.004331414122134447}, {"id": 556, "seek": 231154, "start": 2327.54, "end": 2328.54, "text": " even than us humans.", "tokens": [51164, 754, 813, 505, 6255, 13, 51214], "temperature": 0.0, "avg_logprob": -0.1030031730388773, "compression_ratio": 1.7146892655367232, "no_speech_prob": 0.004331414122134447}, {"id": 557, "seek": 231154, "start": 2328.54, "end": 2330.54, "text": " So suppose, for instance, it's O's turn.", "tokens": [51214, 407, 7297, 11, 337, 5197, 11, 309, 311, 422, 311, 1261, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1030031730388773, "compression_ratio": 1.7146892655367232, "no_speech_prob": 0.004331414122134447}, {"id": 558, "seek": 231154, "start": 2330.54, "end": 2334.54, "text": " Now, those of you who are very good at Tecto might have an instinct for where to go,", "tokens": [51314, 823, 11, 729, 295, 291, 567, 366, 588, 665, 412, 314, 557, 78, 1062, 362, 364, 16556, 337, 689, 281, 352, 11, 51514], "temperature": 0.0, "avg_logprob": -0.1030031730388773, "compression_ratio": 1.7146892655367232, "no_speech_prob": 0.004331414122134447}, {"id": 559, "seek": 231154, "start": 2334.54, "end": 2336.54, "text": " but this is an even harder problem, it would seem.", "tokens": [51514, 457, 341, 307, 364, 754, 6081, 1154, 11, 309, 576, 1643, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1030031730388773, "compression_ratio": 1.7146892655367232, "no_speech_prob": 0.004331414122134447}, {"id": 560, "seek": 231154, "start": 2336.54, "end": 2340.54, "text": " I could go in eight possible places if I'm O, but let's try to break that down", "tokens": [51614, 286, 727, 352, 294, 3180, 1944, 3190, 498, 286, 478, 422, 11, 457, 718, 311, 853, 281, 1821, 300, 760, 51814], "temperature": 0.0, "avg_logprob": -0.1030031730388773, "compression_ratio": 1.7146892655367232, "no_speech_prob": 0.004331414122134447}, {"id": 561, "seek": 234054, "start": 2340.54, "end": 2343.54, "text": " more algorithmically as an AI would.", "tokens": [50364, 544, 9284, 984, 382, 364, 7318, 576, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07995948085078487, "compression_ratio": 1.6488549618320612, "no_speech_prob": 0.0014550158521160483}, {"id": 562, "seek": 234054, "start": 2343.54, "end": 2346.54, "text": " And let's recognize, too, that with games in particular,", "tokens": [50514, 400, 718, 311, 5521, 11, 886, 11, 300, 365, 2813, 294, 1729, 11, 50664], "temperature": 0.0, "avg_logprob": -0.07995948085078487, "compression_ratio": 1.6488549618320612, "no_speech_prob": 0.0014550158521160483}, {"id": 563, "seek": 234054, "start": 2346.54, "end": 2350.54, "text": " one of the reasons that AI was so early adopted in these games,", "tokens": [50664, 472, 295, 264, 4112, 300, 7318, 390, 370, 2440, 12175, 294, 613, 2813, 11, 50864], "temperature": 0.0, "avg_logprob": -0.07995948085078487, "compression_ratio": 1.6488549618320612, "no_speech_prob": 0.0014550158521160483}, {"id": 564, "seek": 234054, "start": 2350.54, "end": 2355.54, "text": " playing the CPU, is that games really lend themselves to defining them", "tokens": [50864, 2433, 264, 13199, 11, 307, 300, 2813, 534, 21774, 2969, 281, 17827, 552, 51114], "temperature": 0.0, "avg_logprob": -0.07995948085078487, "compression_ratio": 1.6488549618320612, "no_speech_prob": 0.0014550158521160483}, {"id": 565, "seek": 234054, "start": 2355.54, "end": 2359.54, "text": " if taking the fun out of it mathematically, defining them in terms of inputs", "tokens": [51114, 498, 1940, 264, 1019, 484, 295, 309, 44003, 11, 17827, 552, 294, 2115, 295, 15743, 51314], "temperature": 0.0, "avg_logprob": -0.07995948085078487, "compression_ratio": 1.6488549618320612, "no_speech_prob": 0.0014550158521160483}, {"id": 566, "seek": 234054, "start": 2359.54, "end": 2363.54, "text": " and outputs, maybe paddle moving left or right, ball moving up or down.", "tokens": [51314, 293, 23930, 11, 1310, 31834, 2684, 1411, 420, 558, 11, 2594, 2684, 493, 420, 760, 13, 51514], "temperature": 0.0, "avg_logprob": -0.07995948085078487, "compression_ratio": 1.6488549618320612, "no_speech_prob": 0.0014550158521160483}, {"id": 567, "seek": 234054, "start": 2363.54, "end": 2366.54, "text": " You can really quantize it at a very boring low level,", "tokens": [51514, 509, 393, 534, 4426, 1125, 309, 412, 257, 588, 9989, 2295, 1496, 11, 51664], "temperature": 0.0, "avg_logprob": -0.07995948085078487, "compression_ratio": 1.6488549618320612, "no_speech_prob": 0.0014550158521160483}, {"id": 568, "seek": 236654, "start": 2366.54, "end": 2369.54, "text": " but that lends itself then to solving it optimally.", "tokens": [50364, 457, 300, 287, 2581, 2564, 550, 281, 12606, 309, 5028, 379, 13, 50514], "temperature": 0.0, "avg_logprob": -0.08012122438665022, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.001501134829595685}, {"id": 569, "seek": 236654, "start": 2369.54, "end": 2375.54, "text": " And in fact, with most games, the goal is to maximize or maybe minimize some math function.", "tokens": [50514, 400, 294, 1186, 11, 365, 881, 2813, 11, 264, 3387, 307, 281, 19874, 420, 1310, 17522, 512, 5221, 2445, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08012122438665022, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.001501134829595685}, {"id": 570, "seek": 236654, "start": 2375.54, "end": 2378.54, "text": " Most games, if you have scores, the goal is to maximize your score", "tokens": [50814, 4534, 2813, 11, 498, 291, 362, 13444, 11, 264, 3387, 307, 281, 19874, 428, 6175, 50964], "temperature": 0.0, "avg_logprob": -0.08012122438665022, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.001501134829595685}, {"id": 571, "seek": 236654, "start": 2378.54, "end": 2380.54, "text": " and indeed get a high score.", "tokens": [50964, 293, 6451, 483, 257, 1090, 6175, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08012122438665022, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.001501134829595685}, {"id": 572, "seek": 236654, "start": 2380.54, "end": 2385.54, "text": " So games lend themselves to a nice translation to mathematics", "tokens": [51064, 407, 2813, 21774, 2969, 281, 257, 1481, 12853, 281, 18666, 51314], "temperature": 0.0, "avg_logprob": -0.08012122438665022, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.001501134829595685}, {"id": 573, "seek": 236654, "start": 2385.54, "end": 2387.54, "text": " and in turn hear AI solutions.", "tokens": [51314, 293, 294, 1261, 1568, 7318, 6547, 13, 51414], "temperature": 0.0, "avg_logprob": -0.08012122438665022, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.001501134829595685}, {"id": 574, "seek": 236654, "start": 2387.54, "end": 2391.54, "text": " So one of the first algorithms one might learn in the class on algorithms", "tokens": [51414, 407, 472, 295, 264, 700, 14642, 472, 1062, 1466, 294, 264, 1508, 322, 14642, 51614], "temperature": 0.0, "avg_logprob": -0.08012122438665022, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.001501134829595685}, {"id": 575, "seek": 236654, "start": 2391.54, "end": 2394.54, "text": " and on artificial intelligence is something called Minimax,", "tokens": [51614, 293, 322, 11677, 7599, 307, 746, 1219, 2829, 332, 2797, 11, 51764], "temperature": 0.0, "avg_logprob": -0.08012122438665022, "compression_ratio": 1.7786259541984732, "no_speech_prob": 0.001501134829595685}, {"id": 576, "seek": 239454, "start": 2394.54, "end": 2398.54, "text": " which alludes to this idea of trying to minimize and or maximize something", "tokens": [50364, 597, 439, 10131, 281, 341, 1558, 295, 1382, 281, 17522, 293, 420, 19874, 746, 50564], "temperature": 0.0, "avg_logprob": -0.06882647534350415, "compression_ratio": 1.8527397260273972, "no_speech_prob": 0.0009697271743789315}, {"id": 577, "seek": 239454, "start": 2398.54, "end": 2400.54, "text": " as your function, your goal.", "tokens": [50564, 382, 428, 2445, 11, 428, 3387, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06882647534350415, "compression_ratio": 1.8527397260273972, "no_speech_prob": 0.0009697271743789315}, {"id": 578, "seek": 239454, "start": 2400.54, "end": 2404.54, "text": " And it actually derives inspiration from these same decision trees", "tokens": [50664, 400, 309, 767, 1163, 1539, 10249, 490, 613, 912, 3537, 5852, 50864], "temperature": 0.0, "avg_logprob": -0.06882647534350415, "compression_ratio": 1.8527397260273972, "no_speech_prob": 0.0009697271743789315}, {"id": 579, "seek": 239454, "start": 2404.54, "end": 2405.54, "text": " that we've been talking about.", "tokens": [50864, 300, 321, 600, 668, 1417, 466, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06882647534350415, "compression_ratio": 1.8527397260273972, "no_speech_prob": 0.0009697271743789315}, {"id": 580, "seek": 239454, "start": 2405.54, "end": 2406.54, "text": " But first, a definition.", "tokens": [50914, 583, 700, 11, 257, 7123, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06882647534350415, "compression_ratio": 1.8527397260273972, "no_speech_prob": 0.0009697271743789315}, {"id": 581, "seek": 239454, "start": 2406.54, "end": 2409.54, "text": " Here are three representative Tic Tac Toe boards.", "tokens": [50964, 1692, 366, 1045, 12424, 314, 299, 38848, 1407, 68, 13293, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06882647534350415, "compression_ratio": 1.8527397260273972, "no_speech_prob": 0.0009697271743789315}, {"id": 582, "seek": 239454, "start": 2409.54, "end": 2412.54, "text": " Here is one in which O has clearly won per the green.", "tokens": [51114, 1692, 307, 472, 294, 597, 422, 575, 4448, 1582, 680, 264, 3092, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06882647534350415, "compression_ratio": 1.8527397260273972, "no_speech_prob": 0.0009697271743789315}, {"id": 583, "seek": 239454, "start": 2412.54, "end": 2415.54, "text": " Here is one in which X has clearly won per the green.", "tokens": [51264, 1692, 307, 472, 294, 597, 1783, 575, 4448, 1582, 680, 264, 3092, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06882647534350415, "compression_ratio": 1.8527397260273972, "no_speech_prob": 0.0009697271743789315}, {"id": 584, "seek": 239454, "start": 2415.54, "end": 2417.54, "text": " And this one in the middle just represents a draw.", "tokens": [51414, 400, 341, 472, 294, 264, 2808, 445, 8855, 257, 2642, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06882647534350415, "compression_ratio": 1.8527397260273972, "no_speech_prob": 0.0009697271743789315}, {"id": 585, "seek": 239454, "start": 2417.54, "end": 2420.54, "text": " Now, there's a bunch of other ways that Tic Tac Toe could end,", "tokens": [51514, 823, 11, 456, 311, 257, 3840, 295, 661, 2098, 300, 314, 299, 38848, 1407, 68, 727, 917, 11, 51664], "temperature": 0.0, "avg_logprob": -0.06882647534350415, "compression_ratio": 1.8527397260273972, "no_speech_prob": 0.0009697271743789315}, {"id": 586, "seek": 239454, "start": 2420.54, "end": 2422.54, "text": " but here's just three representative ones.", "tokens": [51664, 457, 510, 311, 445, 1045, 12424, 2306, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06882647534350415, "compression_ratio": 1.8527397260273972, "no_speech_prob": 0.0009697271743789315}, {"id": 587, "seek": 242254, "start": 2422.54, "end": 2426.54, "text": " But let's make Tic Tac Toe even more boring than it might have always struck you as.", "tokens": [50364, 583, 718, 311, 652, 314, 299, 38848, 1407, 68, 754, 544, 9989, 813, 309, 1062, 362, 1009, 13159, 291, 382, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06443495716122415, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.00024536700220778584}, {"id": 588, "seek": 242254, "start": 2426.54, "end": 2431.54, "text": " Let's propose that this kind of configuration should have a score of negative one.", "tokens": [50564, 961, 311, 17421, 300, 341, 733, 295, 11694, 820, 362, 257, 6175, 295, 3671, 472, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06443495716122415, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.00024536700220778584}, {"id": 589, "seek": 242254, "start": 2431.54, "end": 2433.54, "text": " If O wins, it's a negative one.", "tokens": [50814, 759, 422, 10641, 11, 309, 311, 257, 3671, 472, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06443495716122415, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.00024536700220778584}, {"id": 590, "seek": 242254, "start": 2433.54, "end": 2435.54, "text": " If X wins, it's a positive one.", "tokens": [50914, 759, 1783, 10641, 11, 309, 311, 257, 3353, 472, 13, 51014], "temperature": 0.0, "avg_logprob": -0.06443495716122415, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.00024536700220778584}, {"id": 591, "seek": 242254, "start": 2435.54, "end": 2437.54, "text": " And if no one wins, we'll call it a zero.", "tokens": [51014, 400, 498, 572, 472, 10641, 11, 321, 603, 818, 309, 257, 4018, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06443495716122415, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.00024536700220778584}, {"id": 592, "seek": 242254, "start": 2437.54, "end": 2441.54, "text": " We need some way of talking about and reasoning about which of these outcomes", "tokens": [51114, 492, 643, 512, 636, 295, 1417, 466, 293, 21577, 466, 597, 295, 613, 10070, 51314], "temperature": 0.0, "avg_logprob": -0.06443495716122415, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.00024536700220778584}, {"id": 593, "seek": 242254, "start": 2441.54, "end": 2445.54, "text": " is better than the other and what's simpler than zero, one, and negative one.", "tokens": [51314, 307, 1101, 813, 264, 661, 293, 437, 311, 18587, 813, 4018, 11, 472, 11, 293, 3671, 472, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06443495716122415, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.00024536700220778584}, {"id": 594, "seek": 242254, "start": 2445.54, "end": 2449.54, "text": " So the goal, though, of X, it would seem, is to maximize its score.", "tokens": [51514, 407, 264, 3387, 11, 1673, 11, 295, 1783, 11, 309, 576, 1643, 11, 307, 281, 19874, 1080, 6175, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06443495716122415, "compression_ratio": 1.7256944444444444, "no_speech_prob": 0.00024536700220778584}, {"id": 595, "seek": 244954, "start": 2449.54, "end": 2452.54, "text": " But the goal of O is to minimize its score.", "tokens": [50364, 583, 264, 3387, 295, 422, 307, 281, 17522, 1080, 6175, 13, 50514], "temperature": 0.0, "avg_logprob": -0.05528481374650994, "compression_ratio": 1.713355048859935, "no_speech_prob": 0.00022341508883982897}, {"id": 596, "seek": 244954, "start": 2452.54, "end": 2454.54, "text": " So X is really trying to get positive one.", "tokens": [50514, 407, 1783, 307, 534, 1382, 281, 483, 3353, 472, 13, 50614], "temperature": 0.0, "avg_logprob": -0.05528481374650994, "compression_ratio": 1.713355048859935, "no_speech_prob": 0.00022341508883982897}, {"id": 597, "seek": 244954, "start": 2454.54, "end": 2456.54, "text": " O is really trying to get negative one.", "tokens": [50614, 422, 307, 534, 1382, 281, 483, 3671, 472, 13, 50714], "temperature": 0.0, "avg_logprob": -0.05528481374650994, "compression_ratio": 1.713355048859935, "no_speech_prob": 0.00022341508883982897}, {"id": 598, "seek": 244954, "start": 2456.54, "end": 2460.54, "text": " And no one really wants zero, but that's better than losing to the other person.", "tokens": [50714, 400, 572, 472, 534, 2738, 4018, 11, 457, 300, 311, 1101, 813, 7027, 281, 264, 661, 954, 13, 50914], "temperature": 0.0, "avg_logprob": -0.05528481374650994, "compression_ratio": 1.713355048859935, "no_speech_prob": 0.00022341508883982897}, {"id": 599, "seek": 244954, "start": 2460.54, "end": 2463.54, "text": " So we have now a way to define what it means to win or lose.", "tokens": [50914, 407, 321, 362, 586, 257, 636, 281, 6964, 437, 309, 1355, 281, 1942, 420, 3624, 13, 51064], "temperature": 0.0, "avg_logprob": -0.05528481374650994, "compression_ratio": 1.713355048859935, "no_speech_prob": 0.00022341508883982897}, {"id": 600, "seek": 244954, "start": 2463.54, "end": 2466.54, "text": " Well, now we can employ a strategy here.", "tokens": [51064, 1042, 11, 586, 321, 393, 3188, 257, 5206, 510, 13, 51214], "temperature": 0.0, "avg_logprob": -0.05528481374650994, "compression_ratio": 1.713355048859935, "no_speech_prob": 0.00022341508883982897}, {"id": 601, "seek": 244954, "start": 2466.54, "end": 2470.54, "text": " Here, just as a quick check, what would the score be of this board?", "tokens": [51214, 1692, 11, 445, 382, 257, 1702, 1520, 11, 437, 576, 264, 6175, 312, 295, 341, 3150, 30, 51414], "temperature": 0.0, "avg_logprob": -0.05528481374650994, "compression_ratio": 1.713355048859935, "no_speech_prob": 0.00022341508883982897}, {"id": 602, "seek": 244954, "start": 2470.54, "end": 2472.54, "text": " Just so everyone's on the same page?", "tokens": [51414, 1449, 370, 1518, 311, 322, 264, 912, 3028, 30, 51514], "temperature": 0.0, "avg_logprob": -0.05528481374650994, "compression_ratio": 1.713355048859935, "no_speech_prob": 0.00022341508883982897}, {"id": 603, "seek": 244954, "start": 2472.54, "end": 2476.54, "text": " Or so one, because X has won and we just stipulated arbitrarily,", "tokens": [51514, 1610, 370, 472, 11, 570, 1783, 575, 1582, 293, 321, 445, 37001, 6987, 19071, 3289, 11, 51714], "temperature": 0.0, "avg_logprob": -0.05528481374650994, "compression_ratio": 1.713355048859935, "no_speech_prob": 0.00022341508883982897}, {"id": 604, "seek": 244954, "start": 2476.54, "end": 2478.54, "text": " this means that this board has a value of one.", "tokens": [51714, 341, 1355, 300, 341, 3150, 575, 257, 2158, 295, 472, 13, 51814], "temperature": 0.0, "avg_logprob": -0.05528481374650994, "compression_ratio": 1.713355048859935, "no_speech_prob": 0.00022341508883982897}, {"id": 605, "seek": 247854, "start": 2478.54, "end": 2480.54, "text": " Now let's put it into one more interesting context.", "tokens": [50364, 823, 718, 311, 829, 309, 666, 472, 544, 1880, 4319, 13, 50464], "temperature": 0.0, "avg_logprob": -0.06497721363314622, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0009697352652437985}, {"id": 606, "seek": 247854, "start": 2480.54, "end": 2483.54, "text": " Here, a game has been played for a few moves already.", "tokens": [50464, 1692, 11, 257, 1216, 575, 668, 3737, 337, 257, 1326, 6067, 1217, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06497721363314622, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0009697352652437985}, {"id": 607, "seek": 247854, "start": 2483.54, "end": 2484.54, "text": " There's two spots left.", "tokens": [50614, 821, 311, 732, 10681, 1411, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06497721363314622, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0009697352652437985}, {"id": 608, "seek": 247854, "start": 2484.54, "end": 2486.54, "text": " No one has won just yet.", "tokens": [50664, 883, 472, 575, 1582, 445, 1939, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06497721363314622, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0009697352652437985}, {"id": 609, "seek": 247854, "start": 2486.54, "end": 2489.54, "text": " And suppose that it's O's turn now.", "tokens": [50764, 400, 7297, 300, 309, 311, 422, 311, 1261, 586, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06497721363314622, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0009697352652437985}, {"id": 610, "seek": 247854, "start": 2489.54, "end": 2491.54, "text": " Now everyone probably has an instinct already as to where to go,", "tokens": [50914, 823, 1518, 1391, 575, 364, 16556, 1217, 382, 281, 689, 281, 352, 11, 51014], "temperature": 0.0, "avg_logprob": -0.06497721363314622, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0009697352652437985}, {"id": 611, "seek": 247854, "start": 2491.54, "end": 2494.54, "text": " but let's try to break this down more algorithmically.", "tokens": [51014, 457, 718, 311, 853, 281, 1821, 341, 760, 544, 9284, 984, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06497721363314622, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0009697352652437985}, {"id": 612, "seek": 247854, "start": 2494.54, "end": 2496.54, "text": " So what is the value of this board?", "tokens": [51164, 407, 437, 307, 264, 2158, 295, 341, 3150, 30, 51264], "temperature": 0.0, "avg_logprob": -0.06497721363314622, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0009697352652437985}, {"id": 613, "seek": 247854, "start": 2496.54, "end": 2499.54, "text": " Well, we don't know yet because no one has won.", "tokens": [51264, 1042, 11, 321, 500, 380, 458, 1939, 570, 572, 472, 575, 1582, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06497721363314622, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0009697352652437985}, {"id": 614, "seek": 247854, "start": 2499.54, "end": 2502.54, "text": " So let's consider what could happen next.", "tokens": [51414, 407, 718, 311, 1949, 437, 727, 1051, 958, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06497721363314622, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0009697352652437985}, {"id": 615, "seek": 247854, "start": 2502.54, "end": 2505.54, "text": " So we can draw this actually as a tree as before.", "tokens": [51564, 407, 321, 393, 2642, 341, 767, 382, 257, 4230, 382, 949, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06497721363314622, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0009697352652437985}, {"id": 616, "seek": 250554, "start": 2505.54, "end": 2509.54, "text": " Here, for instance, is what might happen if O goes into the top left-hand corner.", "tokens": [50364, 1692, 11, 337, 5197, 11, 307, 437, 1062, 1051, 498, 422, 1709, 666, 264, 1192, 1411, 12, 5543, 4538, 13, 50564], "temperature": 0.0, "avg_logprob": -0.059465757382461445, "compression_ratio": 1.803680981595092, "no_speech_prob": 0.0020506796427071095}, {"id": 617, "seek": 250554, "start": 2509.54, "end": 2514.54, "text": " And here's what might happen if O goes into the bottom middle spot instead.", "tokens": [50564, 400, 510, 311, 437, 1062, 1051, 498, 422, 1709, 666, 264, 2767, 2808, 4008, 2602, 13, 50814], "temperature": 0.0, "avg_logprob": -0.059465757382461445, "compression_ratio": 1.803680981595092, "no_speech_prob": 0.0020506796427071095}, {"id": 618, "seek": 250554, "start": 2514.54, "end": 2516.54, "text": " We should ask ourselves, what's the value of this board?", "tokens": [50814, 492, 820, 1029, 4175, 11, 437, 311, 264, 2158, 295, 341, 3150, 30, 50914], "temperature": 0.0, "avg_logprob": -0.059465757382461445, "compression_ratio": 1.803680981595092, "no_speech_prob": 0.0020506796427071095}, {"id": 619, "seek": 250554, "start": 2516.54, "end": 2517.54, "text": " What's the value of this board?", "tokens": [50914, 708, 311, 264, 2158, 295, 341, 3150, 30, 50964], "temperature": 0.0, "avg_logprob": -0.059465757382461445, "compression_ratio": 1.803680981595092, "no_speech_prob": 0.0020506796427071095}, {"id": 620, "seek": 250554, "start": 2517.54, "end": 2520.54, "text": " Because if O's purpose in life is to minimize its score,", "tokens": [50964, 1436, 498, 422, 311, 4334, 294, 993, 307, 281, 17522, 1080, 6175, 11, 51114], "temperature": 0.0, "avg_logprob": -0.059465757382461445, "compression_ratio": 1.803680981595092, "no_speech_prob": 0.0020506796427071095}, {"id": 621, "seek": 250554, "start": 2520.54, "end": 2525.54, "text": " it's going to go left or right based on whichever yields the smallest number, negative one, ideally.", "tokens": [51114, 309, 311, 516, 281, 352, 1411, 420, 558, 2361, 322, 24123, 32168, 264, 16998, 1230, 11, 3671, 472, 11, 22915, 13, 51364], "temperature": 0.0, "avg_logprob": -0.059465757382461445, "compression_ratio": 1.803680981595092, "no_speech_prob": 0.0020506796427071095}, {"id": 622, "seek": 250554, "start": 2525.54, "end": 2530.54, "text": " But we're still not sure yet because we don't have definitions for boards with holes in them like this.", "tokens": [51364, 583, 321, 434, 920, 406, 988, 1939, 570, 321, 500, 380, 362, 21988, 337, 13293, 365, 8118, 294, 552, 411, 341, 13, 51614], "temperature": 0.0, "avg_logprob": -0.059465757382461445, "compression_ratio": 1.803680981595092, "no_speech_prob": 0.0020506796427071095}, {"id": 623, "seek": 250554, "start": 2530.54, "end": 2532.54, "text": " So what could happen next here?", "tokens": [51614, 407, 437, 727, 1051, 958, 510, 30, 51714], "temperature": 0.0, "avg_logprob": -0.059465757382461445, "compression_ratio": 1.803680981595092, "no_speech_prob": 0.0020506796427071095}, {"id": 624, "seek": 250554, "start": 2532.54, "end": 2534.54, "text": " Well, it's obviously going to be X's turn next.", "tokens": [51714, 1042, 11, 309, 311, 2745, 516, 281, 312, 1783, 311, 1261, 958, 13, 51814], "temperature": 0.0, "avg_logprob": -0.059465757382461445, "compression_ratio": 1.803680981595092, "no_speech_prob": 0.0020506796427071095}, {"id": 625, "seek": 253454, "start": 2534.54, "end": 2538.54, "text": " So if X moves, unfortunately, X has won in this configuration.", "tokens": [50364, 407, 498, 1783, 6067, 11, 7015, 11, 1783, 575, 1582, 294, 341, 11694, 13, 50564], "temperature": 0.0, "avg_logprob": -0.057465289666400694, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.0002694748400244862}, {"id": 626, "seek": 253454, "start": 2538.54, "end": 2543.54, "text": " We can now conclude that the value of this board is what number?", "tokens": [50564, 492, 393, 586, 16886, 300, 264, 2158, 295, 341, 3150, 307, 437, 1230, 30, 50814], "temperature": 0.0, "avg_logprob": -0.057465289666400694, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.0002694748400244862}, {"id": 627, "seek": 253454, "start": 2543.54, "end": 2548.54, "text": " So one, and because there's only one way to reach this board by transitivity,", "tokens": [50814, 407, 472, 11, 293, 570, 456, 311, 787, 472, 636, 281, 2524, 341, 3150, 538, 17976, 4253, 11, 51064], "temperature": 0.0, "avg_logprob": -0.057465289666400694, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.0002694748400244862}, {"id": 628, "seek": 253454, "start": 2548.54, "end": 2552.54, "text": " you might as well think of the value of this previous board as also one,", "tokens": [51064, 291, 1062, 382, 731, 519, 295, 264, 2158, 295, 341, 3894, 3150, 382, 611, 472, 11, 51264], "temperature": 0.0, "avg_logprob": -0.057465289666400694, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.0002694748400244862}, {"id": 629, "seek": 253454, "start": 2552.54, "end": 2555.54, "text": " because no matter what, it's going to lead to that same outcome.", "tokens": [51264, 570, 572, 1871, 437, 11, 309, 311, 516, 281, 1477, 281, 300, 912, 9700, 13, 51414], "temperature": 0.0, "avg_logprob": -0.057465289666400694, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.0002694748400244862}, {"id": 630, "seek": 253454, "start": 2555.54, "end": 2559.54, "text": " And so the value of this board is actually still to be determined", "tokens": [51414, 400, 370, 264, 2158, 295, 341, 3150, 307, 767, 920, 281, 312, 9540, 51614], "temperature": 0.0, "avg_logprob": -0.057465289666400694, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.0002694748400244862}, {"id": 631, "seek": 253454, "start": 2559.54, "end": 2562.54, "text": " because we don't know if O's going to want to go with the one,", "tokens": [51614, 570, 321, 500, 380, 458, 498, 422, 311, 516, 281, 528, 281, 352, 365, 264, 472, 11, 51764], "temperature": 0.0, "avg_logprob": -0.057465289666400694, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.0002694748400244862}, {"id": 632, "seek": 256254, "start": 2562.54, "end": 2564.54, "text": " and probably not because that means X wins.", "tokens": [50364, 293, 1391, 406, 570, 300, 1355, 1783, 10641, 13, 50464], "temperature": 0.0, "avg_logprob": -0.04802745097392314, "compression_ratio": 1.909433962264151, "no_speech_prob": 0.0019877306185662746}, {"id": 633, "seek": 256254, "start": 2564.54, "end": 2566.54, "text": " But let's see what the value of this board is.", "tokens": [50464, 583, 718, 311, 536, 437, 264, 2158, 295, 341, 3150, 307, 13, 50564], "temperature": 0.0, "avg_logprob": -0.04802745097392314, "compression_ratio": 1.909433962264151, "no_speech_prob": 0.0019877306185662746}, {"id": 634, "seek": 256254, "start": 2566.54, "end": 2570.54, "text": " Well, suppose that indeed X goes in that top left corner here.", "tokens": [50564, 1042, 11, 7297, 300, 6451, 1783, 1709, 294, 300, 1192, 1411, 4538, 510, 13, 50764], "temperature": 0.0, "avg_logprob": -0.04802745097392314, "compression_ratio": 1.909433962264151, "no_speech_prob": 0.0019877306185662746}, {"id": 635, "seek": 256254, "start": 2570.54, "end": 2573.54, "text": " What's the value of this board here?", "tokens": [50764, 708, 311, 264, 2158, 295, 341, 3150, 510, 30, 50914], "temperature": 0.0, "avg_logprob": -0.04802745097392314, "compression_ratio": 1.909433962264151, "no_speech_prob": 0.0019877306185662746}, {"id": 636, "seek": 256254, "start": 2573.54, "end": 2575.54, "text": " Zero because no one has won.", "tokens": [50914, 17182, 570, 572, 472, 575, 1582, 13, 51014], "temperature": 0.0, "avg_logprob": -0.04802745097392314, "compression_ratio": 1.909433962264151, "no_speech_prob": 0.0019877306185662746}, {"id": 637, "seek": 256254, "start": 2575.54, "end": 2577.54, "text": " There's no X's or O's three in a row.", "tokens": [51014, 821, 311, 572, 1783, 311, 420, 422, 311, 1045, 294, 257, 5386, 13, 51114], "temperature": 0.0, "avg_logprob": -0.04802745097392314, "compression_ratio": 1.909433962264151, "no_speech_prob": 0.0019877306185662746}, {"id": 638, "seek": 256254, "start": 2577.54, "end": 2579.54, "text": " So the value of this board is zero.", "tokens": [51114, 407, 264, 2158, 295, 341, 3150, 307, 4018, 13, 51214], "temperature": 0.0, "avg_logprob": -0.04802745097392314, "compression_ratio": 1.909433962264151, "no_speech_prob": 0.0019877306185662746}, {"id": 639, "seek": 256254, "start": 2579.54, "end": 2581.54, "text": " There's only one way logically to get there.", "tokens": [51214, 821, 311, 787, 472, 636, 38887, 281, 483, 456, 13, 51314], "temperature": 0.0, "avg_logprob": -0.04802745097392314, "compression_ratio": 1.909433962264151, "no_speech_prob": 0.0019877306185662746}, {"id": 640, "seek": 256254, "start": 2581.54, "end": 2584.54, "text": " So we might as well think of the value of this board as also zero.", "tokens": [51314, 407, 321, 1062, 382, 731, 519, 295, 264, 2158, 295, 341, 3150, 382, 611, 4018, 13, 51464], "temperature": 0.0, "avg_logprob": -0.04802745097392314, "compression_ratio": 1.909433962264151, "no_speech_prob": 0.0019877306185662746}, {"id": 641, "seek": 256254, "start": 2584.54, "end": 2587.54, "text": " And so now what's the value of this board?", "tokens": [51464, 400, 370, 586, 437, 311, 264, 2158, 295, 341, 3150, 30, 51614], "temperature": 0.0, "avg_logprob": -0.04802745097392314, "compression_ratio": 1.909433962264151, "no_speech_prob": 0.0019877306185662746}, {"id": 642, "seek": 256254, "start": 2587.54, "end": 2590.54, "text": " Well, if we started the story by thinking about O's turn,", "tokens": [51614, 1042, 11, 498, 321, 1409, 264, 1657, 538, 1953, 466, 422, 311, 1261, 11, 51764], "temperature": 0.0, "avg_logprob": -0.04802745097392314, "compression_ratio": 1.909433962264151, "no_speech_prob": 0.0019877306185662746}, {"id": 643, "seek": 259054, "start": 2590.54, "end": 2595.54, "text": " O's purpose is the min in minimax, then which move is O going to make?", "tokens": [50364, 422, 311, 4334, 307, 264, 923, 294, 4464, 2797, 11, 550, 597, 1286, 307, 422, 516, 281, 652, 30, 50614], "temperature": 0.0, "avg_logprob": -0.08189443062091696, "compression_ratio": 1.7366255144032923, "no_speech_prob": 0.0005703084752894938}, {"id": 644, "seek": 259054, "start": 2595.54, "end": 2598.54, "text": " Go to the left or go to the right?", "tokens": [50614, 1037, 281, 264, 1411, 420, 352, 281, 264, 558, 30, 50764], "temperature": 0.0, "avg_logprob": -0.08189443062091696, "compression_ratio": 1.7366255144032923, "no_speech_prob": 0.0005703084752894938}, {"id": 645, "seek": 259054, "start": 2598.54, "end": 2604.54, "text": " O's probably going to go to the right and make the move that leads to this board", "tokens": [50764, 422, 311, 1391, 516, 281, 352, 281, 264, 558, 293, 652, 264, 1286, 300, 6689, 281, 341, 3150, 51064], "temperature": 0.0, "avg_logprob": -0.08189443062091696, "compression_ratio": 1.7366255144032923, "no_speech_prob": 0.0005703084752894938}, {"id": 646, "seek": 259054, "start": 2604.54, "end": 2609.54, "text": " because even though O can't win in this configuration, at least X didn't win.", "tokens": [51064, 570, 754, 1673, 422, 393, 380, 1942, 294, 341, 11694, 11, 412, 1935, 1783, 994, 380, 1942, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08189443062091696, "compression_ratio": 1.7366255144032923, "no_speech_prob": 0.0005703084752894938}, {"id": 647, "seek": 259054, "start": 2609.54, "end": 2613.54, "text": " So it's minimized its score relatively, even though it's not a clean win.", "tokens": [51314, 407, 309, 311, 4464, 1602, 1080, 6175, 7226, 11, 754, 1673, 309, 311, 406, 257, 2541, 1942, 13, 51514], "temperature": 0.0, "avg_logprob": -0.08189443062091696, "compression_ratio": 1.7366255144032923, "no_speech_prob": 0.0005703084752894938}, {"id": 648, "seek": 259054, "start": 2613.54, "end": 2617.54, "text": " Now, this is all fine and good for a configuration of the board that's almost done.", "tokens": [51514, 823, 11, 341, 307, 439, 2489, 293, 665, 337, 257, 11694, 295, 264, 3150, 300, 311, 1920, 1096, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08189443062091696, "compression_ratio": 1.7366255144032923, "no_speech_prob": 0.0005703084752894938}, {"id": 649, "seek": 261754, "start": 2617.54, "end": 2619.54, "text": " There's only two moves left. The game's about to end.", "tokens": [50364, 821, 311, 787, 732, 6067, 1411, 13, 440, 1216, 311, 466, 281, 917, 13, 50464], "temperature": 0.0, "avg_logprob": -0.0805989245434741, "compression_ratio": 1.821917808219178, "no_speech_prob": 0.01098636444658041}, {"id": 650, "seek": 261754, "start": 2619.54, "end": 2624.54, "text": " But if you kind of expand in your mind's eye, how did we get to this branch of the decision tree?", "tokens": [50464, 583, 498, 291, 733, 295, 5268, 294, 428, 1575, 311, 3313, 11, 577, 630, 321, 483, 281, 341, 9819, 295, 264, 3537, 4230, 30, 50714], "temperature": 0.0, "avg_logprob": -0.0805989245434741, "compression_ratio": 1.821917808219178, "no_speech_prob": 0.01098636444658041}, {"id": 651, "seek": 261754, "start": 2624.54, "end": 2628.54, "text": " If we rewind one step where there's three possible moves,", "tokens": [50714, 759, 321, 41458, 472, 1823, 689, 456, 311, 1045, 1944, 6067, 11, 50914], "temperature": 0.0, "avg_logprob": -0.0805989245434741, "compression_ratio": 1.821917808219178, "no_speech_prob": 0.01098636444658041}, {"id": 652, "seek": 261754, "start": 2628.54, "end": 2630.54, "text": " frankly, the decision tree is a lot bigger.", "tokens": [50914, 11939, 11, 264, 3537, 4230, 307, 257, 688, 3801, 13, 51014], "temperature": 0.0, "avg_logprob": -0.0805989245434741, "compression_ratio": 1.821917808219178, "no_speech_prob": 0.01098636444658041}, {"id": 653, "seek": 261754, "start": 2630.54, "end": 2635.54, "text": " If we run further in your mind's eye and have four moves left or five moves or all nine moves left,", "tokens": [51014, 759, 321, 1190, 3052, 294, 428, 1575, 311, 3313, 293, 362, 1451, 6067, 1411, 420, 1732, 6067, 420, 439, 4949, 6067, 1411, 11, 51264], "temperature": 0.0, "avg_logprob": -0.0805989245434741, "compression_ratio": 1.821917808219178, "no_speech_prob": 0.01098636444658041}, {"id": 654, "seek": 261754, "start": 2635.54, "end": 2637.54, "text": " imagine just zooming out, out, and out.", "tokens": [51264, 3811, 445, 48226, 484, 11, 484, 11, 293, 484, 13, 51364], "temperature": 0.0, "avg_logprob": -0.0805989245434741, "compression_ratio": 1.821917808219178, "no_speech_prob": 0.01098636444658041}, {"id": 655, "seek": 261754, "start": 2637.54, "end": 2640.54, "text": " This is becoming a massive, massive tree of decisions.", "tokens": [51364, 639, 307, 5617, 257, 5994, 11, 5994, 4230, 295, 5327, 13, 51514], "temperature": 0.0, "avg_logprob": -0.0805989245434741, "compression_ratio": 1.821917808219178, "no_speech_prob": 0.01098636444658041}, {"id": 656, "seek": 261754, "start": 2640.54, "end": 2645.54, "text": " Now, even so, here is that same sub tree, the same decision tree we just looked at.", "tokens": [51514, 823, 11, 754, 370, 11, 510, 307, 300, 912, 1422, 4230, 11, 264, 912, 3537, 4230, 321, 445, 2956, 412, 13, 51764], "temperature": 0.0, "avg_logprob": -0.0805989245434741, "compression_ratio": 1.821917808219178, "no_speech_prob": 0.01098636444658041}, {"id": 657, "seek": 264554, "start": 2645.54, "end": 2649.54, "text": " This is the exact same thing, but I shrunk the font so that it appears here on the screen here.", "tokens": [50364, 639, 307, 264, 1900, 912, 551, 11, 457, 286, 9884, 3197, 264, 10703, 370, 300, 309, 7038, 510, 322, 264, 2568, 510, 13, 50564], "temperature": 0.0, "avg_logprob": -0.0817046289320116, "compression_ratio": 1.7003058103975535, "no_speech_prob": 0.00460934080183506}, {"id": 658, "seek": 264554, "start": 2649.54, "end": 2654.54, "text": " But over here, we have what could happen if instead, it's actually X's turn", "tokens": [50564, 583, 670, 510, 11, 321, 362, 437, 727, 1051, 498, 2602, 11, 309, 311, 767, 1783, 311, 1261, 50814], "temperature": 0.0, "avg_logprob": -0.0817046289320116, "compression_ratio": 1.7003058103975535, "no_speech_prob": 0.00460934080183506}, {"id": 659, "seek": 264554, "start": 2654.54, "end": 2660.54, "text": " because we're once moved prior, there's a bunch of different moves X could now make too.", "tokens": [50814, 570, 321, 434, 1564, 4259, 4059, 11, 456, 311, 257, 3840, 295, 819, 6067, 1783, 727, 586, 652, 886, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0817046289320116, "compression_ratio": 1.7003058103975535, "no_speech_prob": 0.00460934080183506}, {"id": 660, "seek": 264554, "start": 2660.54, "end": 2661.54, "text": " So what is the implication of this?", "tokens": [51114, 407, 437, 307, 264, 37814, 295, 341, 30, 51164], "temperature": 0.0, "avg_logprob": -0.0817046289320116, "compression_ratio": 1.7003058103975535, "no_speech_prob": 0.00460934080183506}, {"id": 661, "seek": 264554, "start": 2661.54, "end": 2666.54, "text": " Well, most humans are not thinking through tic-tac-toe to this extreme.", "tokens": [51164, 1042, 11, 881, 6255, 366, 406, 1953, 807, 256, 299, 12, 83, 326, 12, 1353, 68, 281, 341, 8084, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0817046289320116, "compression_ratio": 1.7003058103975535, "no_speech_prob": 0.00460934080183506}, {"id": 662, "seek": 264554, "start": 2666.54, "end": 2669.54, "text": " And frankly, most of us probably just don't have the mental capacity to think about,", "tokens": [51414, 400, 11939, 11, 881, 295, 505, 1391, 445, 500, 380, 362, 264, 4973, 6042, 281, 519, 466, 11, 51564], "temperature": 0.0, "avg_logprob": -0.0817046289320116, "compression_ratio": 1.7003058103975535, "no_speech_prob": 0.00460934080183506}, {"id": 663, "seek": 264554, "start": 2669.54, "end": 2672.54, "text": " like, going left and then right and then left and then right.", "tokens": [51564, 411, 11, 516, 1411, 293, 550, 558, 293, 550, 1411, 293, 550, 558, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0817046289320116, "compression_ratio": 1.7003058103975535, "no_speech_prob": 0.00460934080183506}, {"id": 664, "seek": 264554, "start": 2672.54, "end": 2674.54, "text": " This is not how people play tic-tac-toe.", "tokens": [51714, 639, 307, 406, 577, 561, 862, 256, 299, 12, 83, 326, 12, 1353, 68, 13, 51814], "temperature": 0.0, "avg_logprob": -0.0817046289320116, "compression_ratio": 1.7003058103975535, "no_speech_prob": 0.00460934080183506}, {"id": 665, "seek": 267454, "start": 2674.54, "end": 2677.54, "text": " Like, we're not using that much memory, so to speak.", "tokens": [50364, 1743, 11, 321, 434, 406, 1228, 300, 709, 4675, 11, 370, 281, 1710, 13, 50514], "temperature": 0.0, "avg_logprob": -0.06637877443411054, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0009399173432029784}, {"id": 666, "seek": 267454, "start": 2677.54, "end": 2679.54, "text": " But a computer can handle that.", "tokens": [50514, 583, 257, 3820, 393, 4813, 300, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06637877443411054, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0009399173432029784}, {"id": 667, "seek": 267454, "start": 2679.54, "end": 2681.54, "text": " And computers can play tic-tac-toe optimally.", "tokens": [50614, 400, 10807, 393, 862, 256, 299, 12, 83, 326, 12, 1353, 68, 5028, 379, 13, 50714], "temperature": 0.0, "avg_logprob": -0.06637877443411054, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0009399173432029784}, {"id": 668, "seek": 267454, "start": 2681.54, "end": 2685.54, "text": " So if you're beating a computer at tic-tac-toe, like, it's not implemented very well.", "tokens": [50714, 407, 498, 291, 434, 13497, 257, 3820, 412, 256, 299, 12, 83, 326, 12, 1353, 68, 11, 411, 11, 309, 311, 406, 12270, 588, 731, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06637877443411054, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0009399173432029784}, {"id": 669, "seek": 267454, "start": 2685.54, "end": 2690.54, "text": " It's not following this very logical deterministic minimax algorithm.", "tokens": [50914, 467, 311, 406, 3480, 341, 588, 14978, 15957, 3142, 4464, 2797, 9284, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06637877443411054, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0009399173432029784}, {"id": 670, "seek": 267454, "start": 2690.54, "end": 2696.54, "text": " But this is where now AI is no longer as simple as just doing what these decision trees say.", "tokens": [51164, 583, 341, 307, 689, 586, 7318, 307, 572, 2854, 382, 2199, 382, 445, 884, 437, 613, 3537, 5852, 584, 13, 51464], "temperature": 0.0, "avg_logprob": -0.06637877443411054, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0009399173432029784}, {"id": 671, "seek": 267454, "start": 2696.54, "end": 2700.54, "text": " In the context of tic-tac-toe, here's how we might translate this to code, for instance.", "tokens": [51464, 682, 264, 4319, 295, 256, 299, 12, 83, 326, 12, 1353, 68, 11, 510, 311, 577, 321, 1062, 13799, 341, 281, 3089, 11, 337, 5197, 13, 51664], "temperature": 0.0, "avg_logprob": -0.06637877443411054, "compression_ratio": 1.6774193548387097, "no_speech_prob": 0.0009399173432029784}, {"id": 672, "seek": 270054, "start": 2700.54, "end": 2704.54, "text": " If player is x, for each possible move, calculate a score for the board,", "tokens": [50364, 759, 4256, 307, 2031, 11, 337, 1184, 1944, 1286, 11, 8873, 257, 6175, 337, 264, 3150, 11, 50564], "temperature": 0.0, "avg_logprob": -0.0738280985477197, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.09806344658136368}, {"id": 673, "seek": 270054, "start": 2704.54, "end": 2708.54, "text": " as we were doing verbally, and then choose the move with the highest score,", "tokens": [50564, 382, 321, 645, 884, 48162, 11, 293, 550, 2826, 264, 1286, 365, 264, 6343, 6175, 11, 50764], "temperature": 0.0, "avg_logprob": -0.0738280985477197, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.09806344658136368}, {"id": 674, "seek": 270054, "start": 2708.54, "end": 2711.54, "text": " because x's goal is to maximize its score.", "tokens": [50764, 570, 2031, 311, 3387, 307, 281, 19874, 1080, 6175, 13, 50914], "temperature": 0.0, "avg_logprob": -0.0738280985477197, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.09806344658136368}, {"id": 675, "seek": 270054, "start": 2711.54, "end": 2715.54, "text": " If the player is O, though, for each possible move, calculate a score for the board", "tokens": [50914, 759, 264, 4256, 307, 422, 11, 1673, 11, 337, 1184, 1944, 1286, 11, 8873, 257, 6175, 337, 264, 3150, 51114], "temperature": 0.0, "avg_logprob": -0.0738280985477197, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.09806344658136368}, {"id": 676, "seek": 270054, "start": 2715.54, "end": 2718.54, "text": " and then choose the move with the lowest score.", "tokens": [51114, 293, 550, 2826, 264, 1286, 365, 264, 12437, 6175, 13, 51264], "temperature": 0.0, "avg_logprob": -0.0738280985477197, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.09806344658136368}, {"id": 677, "seek": 270054, "start": 2718.54, "end": 2722.54, "text": " So that's a distillation of that verbal walkthrough into what CS50 students know now as code,", "tokens": [51264, 407, 300, 311, 257, 42923, 399, 295, 300, 24781, 1792, 11529, 666, 437, 9460, 2803, 1731, 458, 586, 382, 3089, 11, 51464], "temperature": 0.0, "avg_logprob": -0.0738280985477197, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.09806344658136368}, {"id": 678, "seek": 270054, "start": 2722.54, "end": 2724.54, "text": " or at least pseudocode.", "tokens": [51464, 420, 412, 1935, 25505, 532, 905, 1429, 13, 51564], "temperature": 0.0, "avg_logprob": -0.0738280985477197, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.09806344658136368}, {"id": 679, "seek": 270054, "start": 2724.54, "end": 2728.54, "text": " But the problem with games, not so much tic-tac-toe,", "tokens": [51564, 583, 264, 1154, 365, 2813, 11, 406, 370, 709, 256, 299, 12, 83, 326, 12, 1353, 68, 11, 51764], "temperature": 0.0, "avg_logprob": -0.0738280985477197, "compression_ratio": 1.871212121212121, "no_speech_prob": 0.09806344658136368}, {"id": 680, "seek": 272854, "start": 2728.54, "end": 2730.54, "text": " but other more sophisticated games is this.", "tokens": [50364, 457, 661, 544, 16950, 2813, 307, 341, 13, 50464], "temperature": 0.0, "avg_logprob": -0.07704773595777609, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.006487743929028511}, {"id": 681, "seek": 272854, "start": 2730.54, "end": 2736.54, "text": " Does anyone want to ballpark how many possible ways there are to play tic-tac-toe?", "tokens": [50464, 4402, 2878, 528, 281, 2594, 31239, 577, 867, 1944, 2098, 456, 366, 281, 862, 256, 299, 12, 83, 326, 12, 1353, 68, 30, 50764], "temperature": 0.0, "avg_logprob": -0.07704773595777609, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.006487743929028511}, {"id": 682, "seek": 272854, "start": 2736.54, "end": 2741.54, "text": " Paper pencil, two human children, how long could you keep them occupied", "tokens": [50764, 24990, 10985, 11, 732, 1952, 2227, 11, 577, 938, 727, 291, 1066, 552, 19629, 51014], "temperature": 0.0, "avg_logprob": -0.07704773595777609, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.006487743929028511}, {"id": 683, "seek": 272854, "start": 2741.54, "end": 2745.54, "text": " playing tic-tac-toe in different ways?", "tokens": [51014, 2433, 256, 299, 12, 83, 326, 12, 1353, 68, 294, 819, 2098, 30, 51214], "temperature": 0.0, "avg_logprob": -0.07704773595777609, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.006487743929028511}, {"id": 684, "seek": 272854, "start": 2745.54, "end": 2747.54, "text": " If you actually think through how big does this tree get,", "tokens": [51214, 759, 291, 767, 519, 807, 577, 955, 775, 341, 4230, 483, 11, 51314], "temperature": 0.0, "avg_logprob": -0.07704773595777609, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.006487743929028511}, {"id": 685, "seek": 272854, "start": 2747.54, "end": 2751.54, "text": " how many leaves are there on this decision tree, like how many different directions?", "tokens": [51314, 577, 867, 5510, 366, 456, 322, 341, 3537, 4230, 11, 411, 577, 867, 819, 11095, 30, 51514], "temperature": 0.0, "avg_logprob": -0.07704773595777609, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.006487743929028511}, {"id": 686, "seek": 272854, "start": 2751.54, "end": 2756.54, "text": " Well, if you're thinking 255,168, you are correct.", "tokens": [51514, 1042, 11, 498, 291, 434, 1953, 3552, 20, 11, 6866, 23, 11, 291, 366, 3006, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07704773595777609, "compression_ratio": 1.6203007518796992, "no_speech_prob": 0.006487743929028511}, {"id": 687, "seek": 275654, "start": 2756.54, "end": 2761.54, "text": " And now most of us in our lifetime have probably not played tic-tac-toe that many times.", "tokens": [50364, 400, 586, 881, 295, 505, 294, 527, 11364, 362, 1391, 406, 3737, 256, 299, 12, 83, 326, 12, 1353, 68, 300, 867, 1413, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07026787960168088, "compression_ratio": 1.6589403973509933, "no_speech_prob": 0.002396657830104232}, {"id": 688, "seek": 275654, "start": 2761.54, "end": 2763.54, "text": " So think about how many games you've been missing out on.", "tokens": [50614, 407, 519, 466, 577, 867, 2813, 291, 600, 668, 5361, 484, 322, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07026787960168088, "compression_ratio": 1.6589403973509933, "no_speech_prob": 0.002396657830104232}, {"id": 689, "seek": 275654, "start": 2763.54, "end": 2767.54, "text": " There are different decisions you could have been making all these years.", "tokens": [50714, 821, 366, 819, 5327, 291, 727, 362, 668, 1455, 439, 613, 924, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07026787960168088, "compression_ratio": 1.6589403973509933, "no_speech_prob": 0.002396657830104232}, {"id": 690, "seek": 275654, "start": 2767.54, "end": 2771.54, "text": " Now that's a big number, but honestly, like that's not a big number for a computer.", "tokens": [50914, 823, 300, 311, 257, 955, 1230, 11, 457, 6095, 11, 411, 300, 311, 406, 257, 955, 1230, 337, 257, 3820, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07026787960168088, "compression_ratio": 1.6589403973509933, "no_speech_prob": 0.002396657830104232}, {"id": 691, "seek": 275654, "start": 2771.54, "end": 2775.54, "text": " That's a few megabytes of memory maybe to sort of keep all of that in mind", "tokens": [51114, 663, 311, 257, 1326, 10816, 24538, 295, 4675, 1310, 281, 1333, 295, 1066, 439, 295, 300, 294, 1575, 51314], "temperature": 0.0, "avg_logprob": -0.07026787960168088, "compression_ratio": 1.6589403973509933, "no_speech_prob": 0.002396657830104232}, {"id": 692, "seek": 275654, "start": 2775.54, "end": 2780.54, "text": " and sort of implement that kind of code in C or Java or C++ or something else.", "tokens": [51314, 293, 1333, 295, 4445, 300, 733, 295, 3089, 294, 383, 420, 10745, 420, 383, 25472, 420, 746, 1646, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07026787960168088, "compression_ratio": 1.6589403973509933, "no_speech_prob": 0.002396657830104232}, {"id": 693, "seek": 275654, "start": 2780.54, "end": 2783.54, "text": " But other games are much more complicated.", "tokens": [51564, 583, 661, 2813, 366, 709, 544, 6179, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07026787960168088, "compression_ratio": 1.6589403973509933, "no_speech_prob": 0.002396657830104232}, {"id": 694, "seek": 278354, "start": 2783.54, "end": 2787.54, "text": " And the games that you and I might play as we get older include maybe chess.", "tokens": [50364, 400, 264, 2813, 300, 291, 293, 286, 1062, 862, 382, 321, 483, 4906, 4090, 1310, 24122, 13, 50564], "temperature": 0.0, "avg_logprob": -0.07201323846373896, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0007793558179400861}, {"id": 695, "seek": 278354, "start": 2787.54, "end": 2792.54, "text": " And if you think about chess with only the first four moves back and forth four times,", "tokens": [50564, 400, 498, 291, 519, 466, 24122, 365, 787, 264, 700, 1451, 6067, 646, 293, 5220, 1451, 1413, 11, 50814], "temperature": 0.0, "avg_logprob": -0.07201323846373896, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0007793558179400861}, {"id": 696, "seek": 278354, "start": 2792.54, "end": 2795.54, "text": " so only four moves, that's not even a very long game.", "tokens": [50814, 370, 787, 1451, 6067, 11, 300, 311, 406, 754, 257, 588, 938, 1216, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07201323846373896, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0007793558179400861}, {"id": 697, "seek": 278354, "start": 2795.54, "end": 2800.54, "text": " Anyone want to ballpark how many different ways there are to begin a game of chess", "tokens": [50964, 14643, 528, 281, 2594, 31239, 577, 867, 819, 2098, 456, 366, 281, 1841, 257, 1216, 295, 24122, 51214], "temperature": 0.0, "avg_logprob": -0.07201323846373896, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0007793558179400861}, {"id": 698, "seek": 278354, "start": 2800.54, "end": 2805.54, "text": " with four moves back and forth?", "tokens": [51214, 365, 1451, 6067, 646, 293, 5220, 30, 51464], "temperature": 0.0, "avg_logprob": -0.07201323846373896, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0007793558179400861}, {"id": 699, "seek": 278354, "start": 2805.54, "end": 2808.54, "text": " This is evidence as to why chess is apparently so hard.", "tokens": [51464, 639, 307, 4467, 382, 281, 983, 24122, 307, 7970, 370, 1152, 13, 51614], "temperature": 0.0, "avg_logprob": -0.07201323846373896, "compression_ratio": 1.6796536796536796, "no_speech_prob": 0.0007793558179400861}, {"id": 700, "seek": 280854, "start": 2808.54, "end": 2814.54, "text": " 288 million ways, which is why when you are really good at chess,", "tokens": [50364, 7562, 23, 2459, 2098, 11, 597, 307, 983, 562, 291, 366, 534, 665, 412, 24122, 11, 50664], "temperature": 0.0, "avg_logprob": -0.07856044930926824, "compression_ratio": 1.629496402877698, "no_speech_prob": 0.02675776742398739}, {"id": 701, "seek": 280854, "start": 2814.54, "end": 2818.54, "text": " you are really good at chess, because apparently you either have an intuition for", "tokens": [50664, 291, 366, 534, 665, 412, 24122, 11, 570, 7970, 291, 2139, 362, 364, 24002, 337, 50864], "temperature": 0.0, "avg_logprob": -0.07856044930926824, "compression_ratio": 1.629496402877698, "no_speech_prob": 0.02675776742398739}, {"id": 702, "seek": 280854, "start": 2818.54, "end": 2822.54, "text": " or a mind for thinking it would seem so many more steps ahead than your opponent.", "tokens": [50864, 420, 257, 1575, 337, 1953, 309, 576, 1643, 370, 867, 544, 4439, 2286, 813, 428, 10620, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07856044930926824, "compression_ratio": 1.629496402877698, "no_speech_prob": 0.02675776742398739}, {"id": 703, "seek": 280854, "start": 2822.54, "end": 2824.54, "text": " And don't get us started on something like Go.", "tokens": [51064, 400, 500, 380, 483, 505, 1409, 322, 746, 411, 1037, 13, 51164], "temperature": 0.0, "avg_logprob": -0.07856044930926824, "compression_ratio": 1.629496402877698, "no_speech_prob": 0.02675776742398739}, {"id": 704, "seek": 280854, "start": 2824.54, "end": 2829.54, "text": " 266 quintillion ways to play Go's first four moves.", "tokens": [51164, 7551, 21, 40006, 11836, 2098, 281, 862, 1037, 311, 700, 1451, 6067, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07856044930926824, "compression_ratio": 1.629496402877698, "no_speech_prob": 0.02675776742398739}, {"id": 705, "seek": 280854, "start": 2829.54, "end": 2833.54, "text": " So at this point, we just can't pull out our Mac, our PC,", "tokens": [51414, 407, 412, 341, 935, 11, 321, 445, 393, 380, 2235, 484, 527, 5707, 11, 527, 6465, 11, 51614], "temperature": 0.0, "avg_logprob": -0.07856044930926824, "compression_ratio": 1.629496402877698, "no_speech_prob": 0.02675776742398739}, {"id": 706, "seek": 280854, "start": 2833.54, "end": 2837.54, "text": " certainly not our phone to solve optimally games like chess and Go", "tokens": [51614, 3297, 406, 527, 2593, 281, 5039, 5028, 379, 2813, 411, 24122, 293, 1037, 51814], "temperature": 0.0, "avg_logprob": -0.07856044930926824, "compression_ratio": 1.629496402877698, "no_speech_prob": 0.02675776742398739}, {"id": 707, "seek": 283754, "start": 2837.54, "end": 2839.54, "text": " because we don't have big enough CPUs.", "tokens": [50364, 570, 321, 500, 380, 362, 955, 1547, 13199, 82, 13, 50464], "temperature": 0.0, "avg_logprob": -0.06667630551225048, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.004069937393069267}, {"id": 708, "seek": 283754, "start": 2839.54, "end": 2840.54, "text": " We don't have enough memory.", "tokens": [50464, 492, 500, 380, 362, 1547, 4675, 13, 50514], "temperature": 0.0, "avg_logprob": -0.06667630551225048, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.004069937393069267}, {"id": 709, "seek": 283754, "start": 2840.54, "end": 2845.54, "text": " We don't have enough years in our lifetimes for the computers to crunch all of those numbers.", "tokens": [50514, 492, 500, 380, 362, 1547, 924, 294, 527, 4545, 302, 1532, 337, 264, 10807, 281, 13386, 439, 295, 729, 3547, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06667630551225048, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.004069937393069267}, {"id": 710, "seek": 283754, "start": 2845.54, "end": 2852.54, "text": " And thus was born a different form of AI that's more inspired by finding patterns more dynamically.", "tokens": [50764, 400, 8807, 390, 4232, 257, 819, 1254, 295, 7318, 300, 311, 544, 7547, 538, 5006, 8294, 544, 43492, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06667630551225048, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.004069937393069267}, {"id": 711, "seek": 283754, "start": 2852.54, "end": 2856.54, "text": " Learning from data as opposed to being told by humans,", "tokens": [51114, 15205, 490, 1412, 382, 8851, 281, 885, 1907, 538, 6255, 11, 51314], "temperature": 0.0, "avg_logprob": -0.06667630551225048, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.004069937393069267}, {"id": 712, "seek": 283754, "start": 2856.54, "end": 2859.54, "text": " here is the code via which to solve this problem.", "tokens": [51314, 510, 307, 264, 3089, 5766, 597, 281, 5039, 341, 1154, 13, 51464], "temperature": 0.0, "avg_logprob": -0.06667630551225048, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.004069937393069267}, {"id": 713, "seek": 283754, "start": 2859.54, "end": 2862.54, "text": " So machine learning is a subset of artificial intelligence", "tokens": [51464, 407, 3479, 2539, 307, 257, 25993, 295, 11677, 7599, 51614], "temperature": 0.0, "avg_logprob": -0.06667630551225048, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.004069937393069267}, {"id": 714, "seek": 283754, "start": 2862.54, "end": 2866.54, "text": " that tries instead to get machines to learn what they should do", "tokens": [51614, 300, 9898, 2602, 281, 483, 8379, 281, 1466, 437, 436, 820, 360, 51814], "temperature": 0.0, "avg_logprob": -0.06667630551225048, "compression_ratio": 1.686206896551724, "no_speech_prob": 0.004069937393069267}, {"id": 715, "seek": 286654, "start": 2866.54, "end": 2870.54, "text": " without being so coached step by step by step by humans here.", "tokens": [50364, 1553, 885, 370, 6560, 292, 1823, 538, 1823, 538, 1823, 538, 6255, 510, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08388354286314949, "compression_ratio": 1.8933823529411764, "no_speech_prob": 0.004198524635285139}, {"id": 716, "seek": 286654, "start": 2870.54, "end": 2873.54, "text": " Reinforcement learning, for instance, is one such example thereof,", "tokens": [50564, 42116, 9382, 2539, 11, 337, 5197, 11, 307, 472, 1270, 1365, 456, 2670, 11, 50714], "temperature": 0.0, "avg_logprob": -0.08388354286314949, "compression_ratio": 1.8933823529411764, "no_speech_prob": 0.004198524635285139}, {"id": 717, "seek": 286654, "start": 2873.54, "end": 2877.54, "text": " wherein reinforcement learning, you sort of wait for the computer or maybe a robot", "tokens": [50714, 43531, 29280, 2539, 11, 291, 1333, 295, 1699, 337, 264, 3820, 420, 1310, 257, 7881, 50914], "temperature": 0.0, "avg_logprob": -0.08388354286314949, "compression_ratio": 1.8933823529411764, "no_speech_prob": 0.004198524635285139}, {"id": 718, "seek": 286654, "start": 2877.54, "end": 2880.54, "text": " to maybe just get better and better and better at things.", "tokens": [50914, 281, 1310, 445, 483, 1101, 293, 1101, 293, 1101, 412, 721, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08388354286314949, "compression_ratio": 1.8933823529411764, "no_speech_prob": 0.004198524635285139}, {"id": 719, "seek": 286654, "start": 2880.54, "end": 2882.54, "text": " And as it does, you reward it with a reward function.", "tokens": [51064, 400, 382, 309, 775, 11, 291, 7782, 309, 365, 257, 7782, 2445, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08388354286314949, "compression_ratio": 1.8933823529411764, "no_speech_prob": 0.004198524635285139}, {"id": 720, "seek": 286654, "start": 2882.54, "end": 2885.54, "text": " Give it plus one every time it does something well and maybe minus one.", "tokens": [51164, 5303, 309, 1804, 472, 633, 565, 309, 775, 746, 731, 293, 1310, 3175, 472, 13, 51314], "temperature": 0.0, "avg_logprob": -0.08388354286314949, "compression_ratio": 1.8933823529411764, "no_speech_prob": 0.004198524635285139}, {"id": 721, "seek": 286654, "start": 2885.54, "end": 2888.54, "text": " You punish it any time it does something poorly.", "tokens": [51314, 509, 9842, 309, 604, 565, 309, 775, 746, 22271, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08388354286314949, "compression_ratio": 1.8933823529411764, "no_speech_prob": 0.004198524635285139}, {"id": 722, "seek": 286654, "start": 2888.54, "end": 2893.54, "text": " And if you simply program this AI or this robot to maximize its score,", "tokens": [51464, 400, 498, 291, 2935, 1461, 341, 7318, 420, 341, 7881, 281, 19874, 1080, 6175, 11, 51714], "temperature": 0.0, "avg_logprob": -0.08388354286314949, "compression_ratio": 1.8933823529411764, "no_speech_prob": 0.004198524635285139}, {"id": 723, "seek": 289354, "start": 2893.54, "end": 2895.54, "text": " never mind minimizing, maximize its score.", "tokens": [50364, 1128, 1575, 46608, 11, 19874, 1080, 6175, 13, 50464], "temperature": 0.0, "avg_logprob": -0.0982548749005353, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.0035934550687670708}, {"id": 724, "seek": 289354, "start": 2895.54, "end": 2898.54, "text": " Ideally, it should repeat behaviors that got it plus one.", "tokens": [50464, 40817, 11, 309, 820, 7149, 15501, 300, 658, 309, 1804, 472, 13, 50614], "temperature": 0.0, "avg_logprob": -0.0982548749005353, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.0035934550687670708}, {"id": 725, "seek": 289354, "start": 2898.54, "end": 2902.54, "text": " It should decrease the frequency with which it does bad behaviors that got it negative one.", "tokens": [50614, 467, 820, 11514, 264, 7893, 365, 597, 309, 775, 1578, 15501, 300, 658, 309, 3671, 472, 13, 50814], "temperature": 0.0, "avg_logprob": -0.0982548749005353, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.0035934550687670708}, {"id": 726, "seek": 289354, "start": 2902.54, "end": 2905.54, "text": " And you can reinforce this kind of learning.", "tokens": [50814, 400, 291, 393, 22634, 341, 733, 295, 2539, 13, 50964], "temperature": 0.0, "avg_logprob": -0.0982548749005353, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.0035934550687670708}, {"id": 727, "seek": 289354, "start": 2905.54, "end": 2908.54, "text": " In fact, I have here one demonstration.", "tokens": [50964, 682, 1186, 11, 286, 362, 510, 472, 16520, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0982548749005353, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.0035934550687670708}, {"id": 728, "seek": 289354, "start": 2908.54, "end": 2914.54, "text": " Could a student come on up who does not think they are particularly coordinated?", "tokens": [51114, 7497, 257, 3107, 808, 322, 493, 567, 775, 406, 519, 436, 366, 4098, 29591, 30, 51414], "temperature": 0.0, "avg_logprob": -0.0982548749005353, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.0035934550687670708}, {"id": 729, "seek": 289354, "start": 2914.54, "end": 2917.54, "text": " OK, wow, you're being nominated by your friends.", "tokens": [51414, 2264, 11, 6076, 11, 291, 434, 885, 25159, 538, 428, 1855, 13, 51564], "temperature": 0.0, "avg_logprob": -0.0982548749005353, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.0035934550687670708}, {"id": 730, "seek": 289354, "start": 2917.54, "end": 2919.54, "text": " Come on up, come on up.", "tokens": [51564, 2492, 322, 493, 11, 808, 322, 493, 13, 51664], "temperature": 0.0, "avg_logprob": -0.0982548749005353, "compression_ratio": 1.638783269961977, "no_speech_prob": 0.0035934550687670708}, {"id": 731, "seek": 291954, "start": 2919.54, "end": 2924.54, "text": " Their hands went up instantly for you.", "tokens": [50364, 6710, 2377, 1437, 493, 13518, 337, 291, 13, 50614], "temperature": 0.0, "avg_logprob": -0.15809087933234447, "compression_ratio": 1.5047169811320755, "no_speech_prob": 0.0004728255735244602}, {"id": 732, "seek": 291954, "start": 2924.54, "end": 2929.54, "text": " OK, what is your name?", "tokens": [50614, 2264, 11, 437, 307, 428, 1315, 30, 50864], "temperature": 0.0, "avg_logprob": -0.15809087933234447, "compression_ratio": 1.5047169811320755, "no_speech_prob": 0.0004728255735244602}, {"id": 733, "seek": 291954, "start": 2929.54, "end": 2931.54, "text": " My name is Amaka.", "tokens": [50864, 1222, 1315, 307, 2012, 7849, 13, 50964], "temperature": 0.0, "avg_logprob": -0.15809087933234447, "compression_ratio": 1.5047169811320755, "no_speech_prob": 0.0004728255735244602}, {"id": 734, "seek": 291954, "start": 2931.54, "end": 2933.54, "text": " Amaka, do you want to introduce yourself to the world?", "tokens": [50964, 2012, 7849, 11, 360, 291, 528, 281, 5366, 1803, 281, 264, 1002, 30, 51064], "temperature": 0.0, "avg_logprob": -0.15809087933234447, "compression_ratio": 1.5047169811320755, "no_speech_prob": 0.0004728255735244602}, {"id": 735, "seek": 291954, "start": 2933.54, "end": 2934.54, "text": " Hi, my name is Amaka.", "tokens": [51064, 2421, 11, 452, 1315, 307, 2012, 7849, 13, 51114], "temperature": 0.0, "avg_logprob": -0.15809087933234447, "compression_ratio": 1.5047169811320755, "no_speech_prob": 0.0004728255735244602}, {"id": 736, "seek": 291954, "start": 2934.54, "end": 2938.54, "text": " I am a first year in Hallworthy, planning to concentrate in CS.", "tokens": [51114, 286, 669, 257, 700, 1064, 294, 5434, 23727, 11, 5038, 281, 18089, 294, 9460, 13, 51314], "temperature": 0.0, "avg_logprob": -0.15809087933234447, "compression_ratio": 1.5047169811320755, "no_speech_prob": 0.0004728255735244602}, {"id": 737, "seek": 291954, "start": 2938.54, "end": 2939.54, "text": " Wonderful, nice to see you.", "tokens": [51314, 22768, 11, 1481, 281, 536, 291, 13, 51364], "temperature": 0.0, "avg_logprob": -0.15809087933234447, "compression_ratio": 1.5047169811320755, "no_speech_prob": 0.0004728255735244602}, {"id": 738, "seek": 291954, "start": 2939.54, "end": 2940.54, "text": " Come on over here.", "tokens": [51364, 2492, 322, 670, 510, 13, 51414], "temperature": 0.0, "avg_logprob": -0.15809087933234447, "compression_ratio": 1.5047169811320755, "no_speech_prob": 0.0004728255735244602}, {"id": 739, "seek": 291954, "start": 2940.54, "end": 2946.54, "text": " So, yes, oh no, it's sort of like a game show here.", "tokens": [51414, 407, 11, 2086, 11, 1954, 572, 11, 309, 311, 1333, 295, 411, 257, 1216, 855, 510, 13, 51714], "temperature": 0.0, "avg_logprob": -0.15809087933234447, "compression_ratio": 1.5047169811320755, "no_speech_prob": 0.0004728255735244602}, {"id": 740, "seek": 294654, "start": 2946.54, "end": 2951.54, "text": " We have a pan here with what appears to be something pancake-like.", "tokens": [50364, 492, 362, 257, 2462, 510, 365, 437, 7038, 281, 312, 746, 28916, 12, 4092, 13, 50614], "temperature": 0.0, "avg_logprob": -0.09911399021326939, "compression_ratio": 1.7439613526570048, "no_speech_prob": 0.0027147983200848103}, {"id": 741, "seek": 294654, "start": 2951.54, "end": 2956.54, "text": " And we'd like to teach you how to flip a pancake so that when you gesture upward,", "tokens": [50614, 400, 321, 1116, 411, 281, 2924, 291, 577, 281, 7929, 257, 28916, 370, 300, 562, 291, 22252, 23452, 11, 50864], "temperature": 0.0, "avg_logprob": -0.09911399021326939, "compression_ratio": 1.7439613526570048, "no_speech_prob": 0.0027147983200848103}, {"id": 742, "seek": 294654, "start": 2956.54, "end": 2959.54, "text": " the pancake should flip around so you cook the other side.", "tokens": [50864, 264, 28916, 820, 7929, 926, 370, 291, 2543, 264, 661, 1252, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09911399021326939, "compression_ratio": 1.7439613526570048, "no_speech_prob": 0.0027147983200848103}, {"id": 743, "seek": 294654, "start": 2959.54, "end": 2965.54, "text": " So we're going to reward you verbally with plus one or minus one.", "tokens": [51014, 407, 321, 434, 516, 281, 7782, 291, 48162, 365, 1804, 472, 420, 3175, 472, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09911399021326939, "compression_ratio": 1.7439613526570048, "no_speech_prob": 0.0027147983200848103}, {"id": 744, "seek": 294654, "start": 2965.54, "end": 2969.54, "text": " Minus one, minus one.", "tokens": [51314, 2829, 301, 472, 11, 3175, 472, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09911399021326939, "compression_ratio": 1.7439613526570048, "no_speech_prob": 0.0027147983200848103}, {"id": 745, "seek": 294654, "start": 2969.54, "end": 2971.54, "text": " OK, plus one, plus one.", "tokens": [51514, 2264, 11, 1804, 472, 11, 1804, 472, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09911399021326939, "compression_ratio": 1.7439613526570048, "no_speech_prob": 0.0027147983200848103}, {"id": 746, "seek": 294654, "start": 2971.54, "end": 2973.54, "text": " So do more of that.", "tokens": [51614, 407, 360, 544, 295, 300, 13, 51714], "temperature": 0.0, "avg_logprob": -0.09911399021326939, "compression_ratio": 1.7439613526570048, "no_speech_prob": 0.0027147983200848103}, {"id": 747, "seek": 294654, "start": 2973.54, "end": 2975.54, "text": " Minus one, minus one.", "tokens": [51714, 2829, 301, 472, 11, 3175, 472, 13, 51814], "temperature": 0.0, "avg_logprob": -0.09911399021326939, "compression_ratio": 1.7439613526570048, "no_speech_prob": 0.0027147983200848103}, {"id": 748, "seek": 297554, "start": 2975.54, "end": 2978.54, "text": " Minus one, minus one.", "tokens": [50364, 2829, 301, 472, 11, 3175, 472, 13, 50514], "temperature": 0.0, "avg_logprob": -0.08787956990693745, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.00016346060147043318}, {"id": 749, "seek": 297554, "start": 2978.54, "end": 2983.54, "text": " Do less of that.", "tokens": [50514, 1144, 1570, 295, 300, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08787956990693745, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.00016346060147043318}, {"id": 750, "seek": 297554, "start": 2983.54, "end": 2987.54, "text": " All right, a big round of applause.", "tokens": [50764, 1057, 558, 11, 257, 955, 3098, 295, 9969, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08787956990693745, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.00016346060147043318}, {"id": 751, "seek": 297554, "start": 2987.54, "end": 2988.54, "text": " Thank you.", "tokens": [50964, 1044, 291, 13, 51014], "temperature": 0.0, "avg_logprob": -0.08787956990693745, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.00016346060147043318}, {"id": 752, "seek": 297554, "start": 2988.54, "end": 2991.54, "text": " We've been in the habit of handing out Super Mario Brothers Oreos this year.", "tokens": [51014, 492, 600, 668, 294, 264, 7164, 295, 34774, 484, 4548, 9343, 19886, 31405, 329, 341, 1064, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08787956990693745, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.00016346060147043318}, {"id": 753, "seek": 297554, "start": 2991.54, "end": 2997.54, "text": " So thank you for participating.", "tokens": [51164, 407, 1309, 291, 337, 13950, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08787956990693745, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.00016346060147043318}, {"id": 754, "seek": 297554, "start": 2997.54, "end": 3002.54, "text": " So this is actually a good example of an opportunity for reinforcement learning", "tokens": [51464, 407, 341, 307, 767, 257, 665, 1365, 295, 364, 2650, 337, 29280, 2539, 51714], "temperature": 0.0, "avg_logprob": -0.08787956990693745, "compression_ratio": 1.4345549738219896, "no_speech_prob": 0.00016346060147043318}, {"id": 755, "seek": 300254, "start": 3002.54, "end": 3005.54, "text": " and wonderfully a researcher has posted a video that we thought we'd share.", "tokens": [50364, 293, 38917, 257, 21751, 575, 9437, 257, 960, 300, 321, 1194, 321, 1116, 2073, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07868921654856104, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.06185039132833481}, {"id": 756, "seek": 300254, "start": 3005.54, "end": 3009.54, "text": " It's about a minute and a half long where you can watch a robot now do exactly", "tokens": [50514, 467, 311, 466, 257, 3456, 293, 257, 1922, 938, 689, 291, 393, 1159, 257, 7881, 586, 360, 2293, 50714], "temperature": 0.0, "avg_logprob": -0.07868921654856104, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.06185039132833481}, {"id": 757, "seek": 300254, "start": 3009.54, "end": 3013.54, "text": " what our wonderful human volunteer here just attempted as well.", "tokens": [50714, 437, 527, 3715, 1952, 13835, 510, 445, 18997, 382, 731, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07868921654856104, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.06185039132833481}, {"id": 758, "seek": 300254, "start": 3013.54, "end": 3017.54, "text": " So let me go ahead and play this on the screen and give you a sense of what", "tokens": [50914, 407, 718, 385, 352, 2286, 293, 862, 341, 322, 264, 2568, 293, 976, 291, 257, 2020, 295, 437, 51114], "temperature": 0.0, "avg_logprob": -0.07868921654856104, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.06185039132833481}, {"id": 759, "seek": 300254, "start": 3017.54, "end": 3019.54, "text": " the human and the robot are doing together.", "tokens": [51114, 264, 1952, 293, 264, 7881, 366, 884, 1214, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07868921654856104, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.06185039132833481}, {"id": 760, "seek": 300254, "start": 3019.54, "end": 3023.54, "text": " So their pancake looks a little similar there.", "tokens": [51214, 407, 641, 28916, 1542, 257, 707, 2531, 456, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07868921654856104, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.06185039132833481}, {"id": 761, "seek": 300254, "start": 3023.54, "end": 3028.54, "text": " The human here is going to first sort of train the robot what to do by showing it some gestures.", "tokens": [51414, 440, 1952, 510, 307, 516, 281, 700, 1333, 295, 3847, 264, 7881, 437, 281, 360, 538, 4099, 309, 512, 28475, 13, 51664], "temperature": 0.0, "avg_logprob": -0.07868921654856104, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.06185039132833481}, {"id": 762, "seek": 302854, "start": 3028.54, "end": 3030.54, "text": " But there's no one right way to do this.", "tokens": [50364, 583, 456, 311, 572, 472, 558, 636, 281, 360, 341, 13, 50464], "temperature": 0.0, "avg_logprob": -0.14937295913696289, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.009411721490323544}, {"id": 763, "seek": 302854, "start": 3030.54, "end": 3033.54, "text": " But the human seems to know how to do it pretty well in this case.", "tokens": [50464, 583, 264, 1952, 2544, 281, 458, 577, 281, 360, 309, 1238, 731, 294, 341, 1389, 13, 50614], "temperature": 0.0, "avg_logprob": -0.14937295913696289, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.009411721490323544}, {"id": 764, "seek": 302854, "start": 3033.54, "end": 3039.54, "text": " And so it's trying to give the machine examples of how to flip a pancake successfully.", "tokens": [50614, 400, 370, 309, 311, 1382, 281, 976, 264, 3479, 5110, 295, 577, 281, 7929, 257, 28916, 10727, 13, 50914], "temperature": 0.0, "avg_logprob": -0.14937295913696289, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.009411721490323544}, {"id": 765, "seek": 302854, "start": 3039.54, "end": 3041.54, "text": " But now this is the very first trial.", "tokens": [50914, 583, 586, 341, 307, 264, 588, 700, 7308, 13, 51014], "temperature": 0.0, "avg_logprob": -0.14937295913696289, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.009411721490323544}, {"id": 766, "seek": 302854, "start": 3041.54, "end": 3042.54, "text": " OK, look from that.", "tokens": [51014, 2264, 11, 574, 490, 300, 13, 51064], "temperature": 0.0, "avg_logprob": -0.14937295913696289, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.009411721490323544}, {"id": 767, "seek": 302854, "start": 3042.54, "end": 3044.54, "text": " You're in good company.", "tokens": [51064, 509, 434, 294, 665, 2237, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14937295913696289, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.009411721490323544}, {"id": 768, "seek": 302854, "start": 3044.54, "end": 3048.54, "text": " After three trials.", "tokens": [51164, 2381, 1045, 12450, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14937295913696289, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.009411721490323544}, {"id": 769, "seek": 302854, "start": 3048.54, "end": 3051.54, "text": " OK.", "tokens": [51364, 2264, 13, 51514], "temperature": 0.0, "avg_logprob": -0.14937295913696289, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.009411721490323544}, {"id": 770, "seek": 302854, "start": 3051.54, "end": 3053.54, "text": " OK.", "tokens": [51514, 2264, 13, 51614], "temperature": 0.0, "avg_logprob": -0.14937295913696289, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.009411721490323544}, {"id": 771, "seek": 302854, "start": 3053.54, "end": 3057.54, "text": " Now 10 tries.", "tokens": [51614, 823, 1266, 9898, 13, 51814], "temperature": 0.0, "avg_logprob": -0.14937295913696289, "compression_ratio": 1.5215311004784688, "no_speech_prob": 0.009411721490323544}, {"id": 772, "seek": 305754, "start": 3057.54, "end": 3060.54, "text": " There's the human picking up the pancake.", "tokens": [50364, 821, 311, 264, 1952, 8867, 493, 264, 28916, 13, 50514], "temperature": 0.0, "avg_logprob": -0.10584791590658467, "compression_ratio": 1.5299539170506913, "no_speech_prob": 0.00041729878284968436}, {"id": 773, "seek": 305754, "start": 3060.54, "end": 3066.54, "text": " After 11 trials.", "tokens": [50514, 2381, 2975, 12450, 13, 50814], "temperature": 0.0, "avg_logprob": -0.10584791590658467, "compression_ratio": 1.5299539170506913, "no_speech_prob": 0.00041729878284968436}, {"id": 774, "seek": 305754, "start": 3066.54, "end": 3069.54, "text": " And meanwhile there's presumably a human coding this in the sense that", "tokens": [50814, 400, 29252, 456, 311, 26742, 257, 1952, 17720, 341, 294, 264, 2020, 300, 50964], "temperature": 0.0, "avg_logprob": -0.10584791590658467, "compression_ratio": 1.5299539170506913, "no_speech_prob": 0.00041729878284968436}, {"id": 775, "seek": 305754, "start": 3069.54, "end": 3075.54, "text": " someone is saying good job or bad job plus one or minus one.", "tokens": [50964, 1580, 307, 1566, 665, 1691, 420, 1578, 1691, 1804, 472, 420, 3175, 472, 13, 51264], "temperature": 0.0, "avg_logprob": -0.10584791590658467, "compression_ratio": 1.5299539170506913, "no_speech_prob": 0.00041729878284968436}, {"id": 776, "seek": 305754, "start": 3075.54, "end": 3078.54, "text": " 20 trials.", "tokens": [51264, 945, 12450, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10584791590658467, "compression_ratio": 1.5299539170506913, "no_speech_prob": 0.00041729878284968436}, {"id": 777, "seek": 305754, "start": 3078.54, "end": 3081.54, "text": " Here now we'll see how the computer knows what it's even doing.", "tokens": [51414, 1692, 586, 321, 603, 536, 577, 264, 3820, 3255, 437, 309, 311, 754, 884, 13, 51564], "temperature": 0.0, "avg_logprob": -0.10584791590658467, "compression_ratio": 1.5299539170506913, "no_speech_prob": 0.00041729878284968436}, {"id": 778, "seek": 305754, "start": 3081.54, "end": 3084.54, "text": " There's just a mapping to some kind of like XYZ coordinate system.", "tokens": [51564, 821, 311, 445, 257, 18350, 281, 512, 733, 295, 411, 48826, 57, 15670, 1185, 13, 51714], "temperature": 0.0, "avg_logprob": -0.10584791590658467, "compression_ratio": 1.5299539170506913, "no_speech_prob": 0.00041729878284968436}, {"id": 779, "seek": 308454, "start": 3084.54, "end": 3087.54, "text": " So the robot can quantize what is it's doing.", "tokens": [50364, 407, 264, 7881, 393, 4426, 1125, 437, 307, 309, 311, 884, 13, 50514], "temperature": 0.0, "avg_logprob": -0.114655756482891, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.002323075430467725}, {"id": 780, "seek": 308454, "start": 3087.54, "end": 3090.54, "text": " Nice to do more of one thing less of another.", "tokens": [50514, 5490, 281, 360, 544, 295, 472, 551, 1570, 295, 1071, 13, 50664], "temperature": 0.0, "avg_logprob": -0.114655756482891, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.002323075430467725}, {"id": 781, "seek": 308454, "start": 3090.54, "end": 3095.54, "text": " And you're just seeing a visualization in the background of those digitized movements.", "tokens": [50664, 400, 291, 434, 445, 2577, 257, 25801, 294, 264, 3678, 295, 729, 14293, 1602, 9981, 13, 50914], "temperature": 0.0, "avg_logprob": -0.114655756482891, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.002323075430467725}, {"id": 782, "seek": 308454, "start": 3095.54, "end": 3099.54, "text": " And so now after 50 some odd trials.", "tokens": [50914, 400, 370, 586, 934, 2625, 512, 7401, 12450, 13, 51114], "temperature": 0.0, "avg_logprob": -0.114655756482891, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.002323075430467725}, {"id": 783, "seek": 308454, "start": 3099.54, "end": 3106.54, "text": " The robot to has got its spot on and it should be able to repeat this again and again and again in order to keep flipping this pancake.", "tokens": [51114, 440, 7881, 281, 575, 658, 1080, 4008, 322, 293, 309, 820, 312, 1075, 281, 7149, 341, 797, 293, 797, 293, 797, 294, 1668, 281, 1066, 26886, 341, 28916, 13, 51464], "temperature": 0.0, "avg_logprob": -0.114655756482891, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.002323075430467725}, {"id": 784, "seek": 308454, "start": 3106.54, "end": 3110.54, "text": " So our human volunteer wonderfully took you even fewer trials.", "tokens": [51464, 407, 527, 1952, 13835, 38917, 1890, 291, 754, 13366, 12450, 13, 51664], "temperature": 0.0, "avg_logprob": -0.114655756482891, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.002323075430467725}, {"id": 785, "seek": 311054, "start": 3110.54, "end": 3120.54, "text": " But this is an example then to be clear of what we'd call reinforcement learning whereby you're reinforcing a behavior you want or negatively reinforcing that is punishing a behavior that you don't.", "tokens": [50364, 583, 341, 307, 364, 1365, 550, 281, 312, 1850, 295, 437, 321, 1116, 818, 29280, 2539, 36998, 291, 434, 48262, 257, 5223, 291, 528, 420, 29519, 48262, 300, 307, 49824, 257, 5223, 300, 291, 500, 380, 13, 50864], "temperature": 0.0, "avg_logprob": -0.06901390571904377, "compression_ratio": 1.8, "no_speech_prob": 0.12936817109584808}, {"id": 786, "seek": 311054, "start": 3120.54, "end": 3124.54, "text": " Here's another example that brings us back into the realm of games a little bit.", "tokens": [50864, 1692, 311, 1071, 1365, 300, 5607, 505, 646, 666, 264, 15355, 295, 2813, 257, 707, 857, 13, 51064], "temperature": 0.0, "avg_logprob": -0.06901390571904377, "compression_ratio": 1.8, "no_speech_prob": 0.12936817109584808}, {"id": 787, "seek": 311054, "start": 3124.54, "end": 3134.54, "text": " But in a very abstract way if we were playing a game like the floor is lava where you're only supposed to step certain places so that you don't fall through in the lava pit or something like that and lose a point or lose a life.", "tokens": [51064, 583, 294, 257, 588, 12649, 636, 498, 321, 645, 2433, 257, 1216, 411, 264, 4123, 307, 22097, 689, 291, 434, 787, 3442, 281, 1823, 1629, 3190, 370, 300, 291, 500, 380, 2100, 807, 294, 264, 22097, 10147, 420, 746, 411, 300, 293, 3624, 257, 935, 420, 3624, 257, 993, 13, 51564], "temperature": 0.0, "avg_logprob": -0.06901390571904377, "compression_ratio": 1.8, "no_speech_prob": 0.12936817109584808}, {"id": 788, "seek": 311054, "start": 3134.54, "end": 3136.54, "text": " Each of these squares might represent a position.", "tokens": [51564, 6947, 295, 613, 19368, 1062, 2906, 257, 2535, 13, 51664], "temperature": 0.0, "avg_logprob": -0.06901390571904377, "compression_ratio": 1.8, "no_speech_prob": 0.12936817109584808}, {"id": 789, "seek": 313654, "start": 3136.54, "end": 3141.54, "text": " This yellow dot might represent the human player that can go up down left or right within this world.", "tokens": [50364, 639, 5566, 5893, 1062, 2906, 264, 1952, 4256, 300, 393, 352, 493, 760, 1411, 420, 558, 1951, 341, 1002, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07639308561358535, "compression_ratio": 1.7313432835820894, "no_speech_prob": 0.03514173626899719}, {"id": 790, "seek": 313654, "start": 3141.54, "end": 3144.54, "text": " I'm revealing to the whole audience where the lava pits are.", "tokens": [50614, 286, 478, 23983, 281, 264, 1379, 4034, 689, 264, 22097, 40312, 366, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07639308561358535, "compression_ratio": 1.7313432835820894, "no_speech_prob": 0.03514173626899719}, {"id": 791, "seek": 313654, "start": 3144.54, "end": 3147.54, "text": " But the goal for this yellow dot is to get to green.", "tokens": [50764, 583, 264, 3387, 337, 341, 5566, 5893, 307, 281, 483, 281, 3092, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07639308561358535, "compression_ratio": 1.7313432835820894, "no_speech_prob": 0.03514173626899719}, {"id": 792, "seek": 313654, "start": 3147.54, "end": 3153.54, "text": " But the yellow dot as in any good game does not have this bird's eye view and knows from the get go exactly where to go.", "tokens": [50914, 583, 264, 5566, 5893, 382, 294, 604, 665, 1216, 775, 406, 362, 341, 5255, 311, 3313, 1910, 293, 3255, 490, 264, 483, 352, 2293, 689, 281, 352, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07639308561358535, "compression_ratio": 1.7313432835820894, "no_speech_prob": 0.03514173626899719}, {"id": 793, "seek": 313654, "start": 3153.54, "end": 3155.54, "text": " It's going to have to try some trial and error.", "tokens": [51214, 467, 311, 516, 281, 362, 281, 853, 512, 7308, 293, 6713, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07639308561358535, "compression_ratio": 1.7313432835820894, "no_speech_prob": 0.03514173626899719}, {"id": 794, "seek": 313654, "start": 3155.54, "end": 3160.54, "text": " But if we the programmers maybe reinforce good behavior or punish bad behavior,", "tokens": [51314, 583, 498, 321, 264, 41504, 1310, 22634, 665, 5223, 420, 9842, 1578, 5223, 11, 51564], "temperature": 0.0, "avg_logprob": -0.07639308561358535, "compression_ratio": 1.7313432835820894, "no_speech_prob": 0.03514173626899719}, {"id": 795, "seek": 316054, "start": 3160.54, "end": 3170.54, "text": " we can sort of teach this yellow dot without giving it step by step up down left right instructions what behaviors to repeat and what behaviors not to repeat.", "tokens": [50364, 321, 393, 1333, 295, 2924, 341, 5566, 5893, 1553, 2902, 309, 1823, 538, 1823, 493, 760, 1411, 558, 9415, 437, 15501, 281, 7149, 293, 437, 15501, 406, 281, 7149, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10175291430048582, "compression_ratio": 1.7632508833922262, "no_speech_prob": 0.07807052135467529}, {"id": 796, "seek": 316054, "start": 3170.54, "end": 3174.54, "text": " So for instance suppose the robot moves right that was bad you fell in the lava already.", "tokens": [50864, 407, 337, 5197, 7297, 264, 7881, 6067, 558, 300, 390, 1578, 291, 5696, 294, 264, 22097, 1217, 13, 51064], "temperature": 0.0, "avg_logprob": -0.10175291430048582, "compression_ratio": 1.7632508833922262, "no_speech_prob": 0.07807052135467529}, {"id": 797, "seek": 316054, "start": 3174.54, "end": 3179.54, "text": " So we'll use a bit of computer memory to sort of draw a thicker red line there.", "tokens": [51064, 407, 321, 603, 764, 257, 857, 295, 3820, 4675, 281, 1333, 295, 2642, 257, 18142, 2182, 1622, 456, 13, 51314], "temperature": 0.0, "avg_logprob": -0.10175291430048582, "compression_ratio": 1.7632508833922262, "no_speech_prob": 0.07807052135467529}, {"id": 798, "seek": 316054, "start": 3179.54, "end": 3180.54, "text": " Don't do that again.", "tokens": [51314, 1468, 380, 360, 300, 797, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10175291430048582, "compression_ratio": 1.7632508833922262, "no_speech_prob": 0.07807052135467529}, {"id": 799, "seek": 316054, "start": 3180.54, "end": 3181.54, "text": " So negative one so to speak.", "tokens": [51364, 407, 3671, 472, 370, 281, 1710, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10175291430048582, "compression_ratio": 1.7632508833922262, "no_speech_prob": 0.07807052135467529}, {"id": 800, "seek": 316054, "start": 3181.54, "end": 3188.54, "text": " Maybe the yellow dot moves up next time we can reward that behavior by not drawing any walls and allowing it to go again.", "tokens": [51414, 2704, 264, 5566, 5893, 6067, 493, 958, 565, 321, 393, 7782, 300, 5223, 538, 406, 6316, 604, 7920, 293, 8293, 309, 281, 352, 797, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10175291430048582, "compression_ratio": 1.7632508833922262, "no_speech_prob": 0.07807052135467529}, {"id": 801, "seek": 318854, "start": 3188.54, "end": 3190.54, "text": " It's making pretty good progress, but oh darn it.", "tokens": [50364, 467, 311, 1455, 1238, 665, 4205, 11, 457, 1954, 29063, 309, 13, 50464], "temperature": 0.0, "avg_logprob": -0.10714118377022121, "compression_ratio": 1.738709677419355, "no_speech_prob": 0.0012065694900229573}, {"id": 802, "seek": 318854, "start": 3190.54, "end": 3193.54, "text": " It took a right turn and now fell into the lava.", "tokens": [50464, 467, 1890, 257, 558, 1261, 293, 586, 5696, 666, 264, 22097, 13, 50614], "temperature": 0.0, "avg_logprob": -0.10714118377022121, "compression_ratio": 1.738709677419355, "no_speech_prob": 0.0012065694900229573}, {"id": 803, "seek": 318854, "start": 3193.54, "end": 3196.54, "text": " But let's use a bit more of the computer's memory and keep track of that.", "tokens": [50614, 583, 718, 311, 764, 257, 857, 544, 295, 264, 3820, 311, 4675, 293, 1066, 2837, 295, 300, 13, 50764], "temperature": 0.0, "avg_logprob": -0.10714118377022121, "compression_ratio": 1.738709677419355, "no_speech_prob": 0.0012065694900229573}, {"id": 804, "seek": 318854, "start": 3196.54, "end": 3198.54, "text": " Okay, do not do that thing anymore.", "tokens": [50764, 1033, 11, 360, 406, 360, 300, 551, 3602, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10714118377022121, "compression_ratio": 1.738709677419355, "no_speech_prob": 0.0012065694900229573}, {"id": 805, "seek": 318854, "start": 3198.54, "end": 3201.54, "text": " Maybe the next time the human dot goes this way.", "tokens": [50864, 2704, 264, 958, 565, 264, 1952, 5893, 1709, 341, 636, 13, 51014], "temperature": 0.0, "avg_logprob": -0.10714118377022121, "compression_ratio": 1.738709677419355, "no_speech_prob": 0.0012065694900229573}, {"id": 806, "seek": 318854, "start": 3201.54, "end": 3205.54, "text": " We want to punish that behavior so we'll remember as much with that red line.", "tokens": [51014, 492, 528, 281, 9842, 300, 5223, 370, 321, 603, 1604, 382, 709, 365, 300, 2182, 1622, 13, 51214], "temperature": 0.0, "avg_logprob": -0.10714118377022121, "compression_ratio": 1.738709677419355, "no_speech_prob": 0.0012065694900229573}, {"id": 807, "seek": 318854, "start": 3205.54, "end": 3209.54, "text": " But now we're starting to make progress until now we hit this one.", "tokens": [51214, 583, 586, 321, 434, 2891, 281, 652, 4205, 1826, 586, 321, 2045, 341, 472, 13, 51414], "temperature": 0.0, "avg_logprob": -0.10714118377022121, "compression_ratio": 1.738709677419355, "no_speech_prob": 0.0012065694900229573}, {"id": 808, "seek": 318854, "start": 3209.54, "end": 3216.54, "text": " And eventually even though the yellow dot much like our human much like our pancake flipping robot had to try again and again and again.", "tokens": [51414, 400, 4728, 754, 1673, 264, 5566, 5893, 709, 411, 527, 1952, 709, 411, 527, 28916, 26886, 7881, 632, 281, 853, 797, 293, 797, 293, 797, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10714118377022121, "compression_ratio": 1.738709677419355, "no_speech_prob": 0.0012065694900229573}, {"id": 809, "seek": 321654, "start": 3216.54, "end": 3222.54, "text": " After enough trials, it's going to start to realize what behaviors it should repeat and which ones it shouldn't.", "tokens": [50364, 2381, 1547, 12450, 11, 309, 311, 516, 281, 722, 281, 4325, 437, 15501, 309, 820, 7149, 293, 597, 2306, 309, 4659, 380, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08140189246793764, "compression_ratio": 1.6981818181818182, "no_speech_prob": 0.0005357735208235681}, {"id": 810, "seek": 321654, "start": 3222.54, "end": 3226.54, "text": " And so in this case, maybe it finally makes its way up to the green dot.", "tokens": [50664, 400, 370, 294, 341, 1389, 11, 1310, 309, 2721, 1669, 1080, 636, 493, 281, 264, 3092, 5893, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08140189246793764, "compression_ratio": 1.6981818181818182, "no_speech_prob": 0.0005357735208235681}, {"id": 811, "seek": 321654, "start": 3226.54, "end": 3232.54, "text": " And just to recap, once it finds that path, now we can sort of remember it forever as with these green thicker lines.", "tokens": [50864, 400, 445, 281, 20928, 11, 1564, 309, 10704, 300, 3100, 11, 586, 321, 393, 1333, 295, 1604, 309, 5680, 382, 365, 613, 3092, 18142, 3876, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08140189246793764, "compression_ratio": 1.6981818181818182, "no_speech_prob": 0.0005357735208235681}, {"id": 812, "seek": 321654, "start": 3232.54, "end": 3240.54, "text": " Anytime you want to leave this map, anytime you get really good at the Nintendo game, you'll follow that same path again and again so you don't fall into the lava.", "tokens": [51164, 39401, 291, 528, 281, 1856, 341, 4471, 11, 13038, 291, 483, 534, 665, 412, 264, 11578, 1216, 11, 291, 603, 1524, 300, 912, 3100, 797, 293, 797, 370, 291, 500, 380, 2100, 666, 264, 22097, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08140189246793764, "compression_ratio": 1.6981818181818182, "no_speech_prob": 0.0005357735208235681}, {"id": 813, "seek": 324054, "start": 3240.54, "end": 3245.54, "text": " But an astute human observer might realize that yes, this is correct.", "tokens": [50364, 583, 364, 5357, 1169, 1952, 27878, 1062, 4325, 300, 2086, 11, 341, 307, 3006, 13, 50614], "temperature": 0.0, "avg_logprob": -0.1304719178572945, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.006289782468229532}, {"id": 814, "seek": 324054, "start": 3245.54, "end": 3247.54, "text": " It's getting out of this so-called maze.", "tokens": [50614, 467, 311, 1242, 484, 295, 341, 370, 12, 11880, 33032, 13, 50714], "temperature": 0.0, "avg_logprob": -0.1304719178572945, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.006289782468229532}, {"id": 815, "seek": 324054, "start": 3247.54, "end": 3250.54, "text": " But what is suboptimal or bad about this solution?", "tokens": [50714, 583, 437, 307, 1422, 5747, 10650, 420, 1578, 466, 341, 3827, 30, 50864], "temperature": 0.0, "avg_logprob": -0.1304719178572945, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.006289782468229532}, {"id": 816, "seek": 324054, "start": 3250.54, "end": 3251.54, "text": " Sure.", "tokens": [50864, 4894, 13, 50914], "temperature": 0.0, "avg_logprob": -0.1304719178572945, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.006289782468229532}, {"id": 817, "seek": 324054, "start": 3254.54, "end": 3255.54, "text": " Exactly.", "tokens": [51064, 7587, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1304719178572945, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.006289782468229532}, {"id": 818, "seek": 324054, "start": 3255.54, "end": 3261.54, "text": " It's taking a really long time and inefficient way to get there because I dare say if we just try to different path occasionally,", "tokens": [51114, 467, 311, 1940, 257, 534, 938, 565, 293, 43495, 636, 281, 483, 456, 570, 286, 8955, 584, 498, 321, 445, 853, 281, 819, 3100, 16895, 11, 51414], "temperature": 0.0, "avg_logprob": -0.1304719178572945, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.006289782468229532}, {"id": 819, "seek": 324054, "start": 3261.54, "end": 3267.54, "text": " maybe we could get lucky and get to the out the exit quicker and maybe that means we get a higher score.", "tokens": [51414, 1310, 321, 727, 483, 6356, 293, 483, 281, 264, 484, 264, 11043, 16255, 293, 1310, 300, 1355, 321, 483, 257, 2946, 6175, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1304719178572945, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.006289782468229532}, {"id": 820, "seek": 324054, "start": 3267.54, "end": 3269.54, "text": " We get rewarded even more.", "tokens": [51714, 492, 483, 29105, 754, 544, 13, 51814], "temperature": 0.0, "avg_logprob": -0.1304719178572945, "compression_ratio": 1.5985401459854014, "no_speech_prob": 0.006289782468229532}, {"id": 821, "seek": 326954, "start": 3269.54, "end": 3275.54, "text": " So within a lot of artificial intelligence algorithms, there's this idea of exploring versus exploiting,", "tokens": [50364, 407, 1951, 257, 688, 295, 11677, 7599, 14642, 11, 456, 311, 341, 1558, 295, 12736, 5717, 12382, 1748, 11, 50664], "temperature": 0.0, "avg_logprob": -0.08387635448786217, "compression_ratio": 1.779874213836478, "no_speech_prob": 9.610120469005778e-05}, {"id": 822, "seek": 326954, "start": 3275.54, "end": 3280.54, "text": " whereby you should occasionally, yes, exploit the knowledge you already have.", "tokens": [50664, 36998, 291, 820, 16895, 11, 2086, 11, 25924, 264, 3601, 291, 1217, 362, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08387635448786217, "compression_ratio": 1.779874213836478, "no_speech_prob": 9.610120469005778e-05}, {"id": 823, "seek": 326954, "start": 3280.54, "end": 3285.54, "text": " In fact, frequently exploit that knowledge, but occasionally you know what you should probably do is explore just a little bit.", "tokens": [50914, 682, 1186, 11, 10374, 25924, 300, 3601, 11, 457, 16895, 291, 458, 437, 291, 820, 1391, 360, 307, 6839, 445, 257, 707, 857, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08387635448786217, "compression_ratio": 1.779874213836478, "no_speech_prob": 9.610120469005778e-05}, {"id": 824, "seek": 326954, "start": 3285.54, "end": 3291.54, "text": " Take a left instead of a right and see if it leads you to the solution even more quickly and you might find a better and better solution.", "tokens": [51164, 3664, 257, 1411, 2602, 295, 257, 558, 293, 536, 498, 309, 6689, 291, 281, 264, 3827, 754, 544, 2661, 293, 291, 1062, 915, 257, 1101, 293, 1101, 3827, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08387635448786217, "compression_ratio": 1.779874213836478, "no_speech_prob": 9.610120469005778e-05}, {"id": 825, "seek": 326954, "start": 3291.54, "end": 3294.54, "text": " So here mathematically is how we might think of this.", "tokens": [51464, 407, 510, 44003, 307, 577, 321, 1062, 519, 295, 341, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08387635448786217, "compression_ratio": 1.779874213836478, "no_speech_prob": 9.610120469005778e-05}, {"id": 826, "seek": 326954, "start": 3294.54, "end": 3298.54, "text": " 10% of the time, we might say that epsilon, just some variable,", "tokens": [51614, 1266, 4, 295, 264, 565, 11, 321, 1062, 584, 300, 17889, 11, 445, 512, 7006, 11, 51814], "temperature": 0.0, "avg_logprob": -0.08387635448786217, "compression_ratio": 1.779874213836478, "no_speech_prob": 9.610120469005778e-05}, {"id": 827, "seek": 329854, "start": 3298.54, "end": 3303.54, "text": " sort of a sprinkling of salt into the algorithm here, epsilon will be like 10% of the time.", "tokens": [50364, 1333, 295, 257, 30885, 1688, 295, 5139, 666, 264, 9284, 510, 11, 17889, 486, 312, 411, 1266, 4, 295, 264, 565, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06924204087593186, "compression_ratio": 1.662379421221865, "no_speech_prob": 0.00050332274986431}, {"id": 828, "seek": 329854, "start": 3303.54, "end": 3308.54, "text": " So if my robot or my player picks a random number that's less than 10%,", "tokens": [50614, 407, 498, 452, 7881, 420, 452, 4256, 16137, 257, 4974, 1230, 300, 311, 1570, 813, 1266, 8923, 50864], "temperature": 0.0, "avg_logprob": -0.06924204087593186, "compression_ratio": 1.662379421221865, "no_speech_prob": 0.00050332274986431}, {"id": 829, "seek": 329854, "start": 3308.54, "end": 3310.54, "text": " that's going to make a random move.", "tokens": [50864, 300, 311, 516, 281, 652, 257, 4974, 1286, 13, 50964], "temperature": 0.0, "avg_logprob": -0.06924204087593186, "compression_ratio": 1.662379421221865, "no_speech_prob": 0.00050332274986431}, {"id": 830, "seek": 329854, "start": 3310.54, "end": 3313.54, "text": " Go left instead of right, even if you really typically go right.", "tokens": [50964, 1037, 1411, 2602, 295, 558, 11, 754, 498, 291, 534, 5850, 352, 558, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06924204087593186, "compression_ratio": 1.662379421221865, "no_speech_prob": 0.00050332274986431}, {"id": 831, "seek": 329854, "start": 3313.54, "end": 3317.54, "text": " Otherwise, make the move with the highest value as we've learned over time.", "tokens": [51114, 10328, 11, 652, 264, 1286, 365, 264, 6343, 2158, 382, 321, 600, 3264, 670, 565, 13, 51314], "temperature": 0.0, "avg_logprob": -0.06924204087593186, "compression_ratio": 1.662379421221865, "no_speech_prob": 0.00050332274986431}, {"id": 832, "seek": 329854, "start": 3317.54, "end": 3324.54, "text": " And what the robot might learn then is that we could actually go via this path which gets us to the output faster.", "tokens": [51314, 400, 437, 264, 7881, 1062, 1466, 550, 307, 300, 321, 727, 767, 352, 5766, 341, 3100, 597, 2170, 505, 281, 264, 5598, 4663, 13, 51664], "temperature": 0.0, "avg_logprob": -0.06924204087593186, "compression_ratio": 1.662379421221865, "no_speech_prob": 0.00050332274986431}, {"id": 833, "seek": 329854, "start": 3324.54, "end": 3325.54, "text": " We get a higher score.", "tokens": [51664, 492, 483, 257, 2946, 6175, 13, 51714], "temperature": 0.0, "avg_logprob": -0.06924204087593186, "compression_ratio": 1.662379421221865, "no_speech_prob": 0.00050332274986431}, {"id": 834, "seek": 329854, "start": 3325.54, "end": 3326.54, "text": " We do it in less time.", "tokens": [51714, 492, 360, 309, 294, 1570, 565, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06924204087593186, "compression_ratio": 1.662379421221865, "no_speech_prob": 0.00050332274986431}, {"id": 835, "seek": 329854, "start": 3326.54, "end": 3327.54, "text": " It's a win-win.", "tokens": [51764, 467, 311, 257, 1942, 12, 9136, 13, 51814], "temperature": 0.0, "avg_logprob": -0.06924204087593186, "compression_ratio": 1.662379421221865, "no_speech_prob": 0.00050332274986431}, {"id": 836, "seek": 332754, "start": 3327.54, "end": 3331.54, "text": " Frankly, this really resonates with me because I've been in the habit as maybe some of you are.", "tokens": [50364, 41344, 11, 341, 534, 41051, 365, 385, 570, 286, 600, 668, 294, 264, 7164, 382, 1310, 512, 295, 291, 366, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06298991172544417, "compression_ratio": 1.8525179856115108, "no_speech_prob": 0.0021156377624720335}, {"id": 837, "seek": 332754, "start": 3331.54, "end": 3335.54, "text": " When you go to a restaurant, maybe that you really like, you find a dish you really like,", "tokens": [50564, 1133, 291, 352, 281, 257, 6383, 11, 1310, 300, 291, 534, 411, 11, 291, 915, 257, 5025, 291, 534, 411, 11, 50764], "temperature": 0.0, "avg_logprob": -0.06298991172544417, "compression_ratio": 1.8525179856115108, "no_speech_prob": 0.0021156377624720335}, {"id": 838, "seek": 332754, "start": 3335.54, "end": 3342.54, "text": " I will never again know what other dishes that restaurant offers because I'm sort of locally, optimally happy with the dish I've chosen.", "tokens": [50764, 286, 486, 1128, 797, 458, 437, 661, 10814, 300, 6383, 7736, 570, 286, 478, 1333, 295, 16143, 11, 5028, 379, 2055, 365, 264, 5025, 286, 600, 8614, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06298991172544417, "compression_ratio": 1.8525179856115108, "no_speech_prob": 0.0021156377624720335}, {"id": 839, "seek": 332754, "start": 3342.54, "end": 3348.54, "text": " And I will never know if there's an even better dish at that restaurant unless again I sort of sprinkle a little bit of epsilon,", "tokens": [51114, 400, 286, 486, 1128, 458, 498, 456, 311, 364, 754, 1101, 5025, 412, 300, 6383, 5969, 797, 286, 1333, 295, 24745, 257, 707, 857, 295, 17889, 11, 51414], "temperature": 0.0, "avg_logprob": -0.06298991172544417, "compression_ratio": 1.8525179856115108, "no_speech_prob": 0.0021156377624720335}, {"id": 840, "seek": 332754, "start": 3348.54, "end": 3352.54, "text": " a little bit of randomness into my game playing, my dining out.", "tokens": [51414, 257, 707, 857, 295, 4974, 1287, 666, 452, 1216, 2433, 11, 452, 17874, 484, 13, 51614], "temperature": 0.0, "avg_logprob": -0.06298991172544417, "compression_ratio": 1.8525179856115108, "no_speech_prob": 0.0021156377624720335}, {"id": 841, "seek": 335254, "start": 3352.54, "end": 3355.54, "text": " The catch, of course, though, is that I might be punished.", "tokens": [50364, 440, 3745, 11, 295, 1164, 11, 1673, 11, 307, 300, 286, 1062, 312, 22365, 13, 50514], "temperature": 0.0, "avg_logprob": -0.07628134370760153, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.02595556527376175}, {"id": 842, "seek": 335254, "start": 3355.54, "end": 3359.54, "text": " I might therefore sort of be less happy if I pick something and I don't like it.", "tokens": [50514, 286, 1062, 4412, 1333, 295, 312, 1570, 2055, 498, 286, 1888, 746, 293, 286, 500, 380, 411, 309, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07628134370760153, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.02595556527376175}, {"id": 843, "seek": 335254, "start": 3359.54, "end": 3364.54, "text": " So there's this tension between exploring and exploiting, but in general in computer science and especially in AI,", "tokens": [50714, 407, 456, 311, 341, 8980, 1296, 12736, 293, 12382, 1748, 11, 457, 294, 2674, 294, 3820, 3497, 293, 2318, 294, 7318, 11, 50964], "temperature": 0.0, "avg_logprob": -0.07628134370760153, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.02595556527376175}, {"id": 844, "seek": 335254, "start": 3364.54, "end": 3370.54, "text": " adding a little bit of randomness, especially over time, can in fact yield better and better outcomes.", "tokens": [50964, 5127, 257, 707, 857, 295, 4974, 1287, 11, 2318, 670, 565, 11, 393, 294, 1186, 11257, 1101, 293, 1101, 10070, 13, 51264], "temperature": 0.0, "avg_logprob": -0.07628134370760153, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.02595556527376175}, {"id": 845, "seek": 335254, "start": 3370.54, "end": 3376.54, "text": " But now there's this notion all the more of deep learning whereby you're trying to infer to detect patterns,", "tokens": [51264, 583, 586, 456, 311, 341, 10710, 439, 264, 544, 295, 2452, 2539, 36998, 291, 434, 1382, 281, 13596, 281, 5531, 8294, 11, 51564], "temperature": 0.0, "avg_logprob": -0.07628134370760153, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.02595556527376175}, {"id": 846, "seek": 335254, "start": 3376.54, "end": 3381.54, "text": " figure out how to solve problems, even if the AI has never seen those problems before.", "tokens": [51564, 2573, 484, 577, 281, 5039, 2740, 11, 754, 498, 264, 7318, 575, 1128, 1612, 729, 2740, 949, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07628134370760153, "compression_ratio": 1.7335423197492164, "no_speech_prob": 0.02595556527376175}, {"id": 847, "seek": 338154, "start": 3381.54, "end": 3386.54, "text": " And even if there's no human there to reinforce positive or negatively behavior,", "tokens": [50364, 400, 754, 498, 456, 311, 572, 1952, 456, 281, 22634, 3353, 420, 29519, 5223, 11, 50614], "temperature": 0.0, "avg_logprob": -0.08605667461048473, "compression_ratio": 1.6622516556291391, "no_speech_prob": 0.0013249856419861317}, {"id": 848, "seek": 338154, "start": 3386.54, "end": 3392.54, "text": " maybe it's just too complex of a problem for a human to stand alongside the robot and say good or bad job.", "tokens": [50614, 1310, 309, 311, 445, 886, 3997, 295, 257, 1154, 337, 257, 1952, 281, 1463, 12385, 264, 7881, 293, 584, 665, 420, 1578, 1691, 13, 50914], "temperature": 0.0, "avg_logprob": -0.08605667461048473, "compression_ratio": 1.6622516556291391, "no_speech_prob": 0.0013249856419861317}, {"id": 849, "seek": 338154, "start": 3392.54, "end": 3398.54, "text": " So with deep learning, they're actually very much related to what you might know as neural networks inspired by human physiology,", "tokens": [50914, 407, 365, 2452, 2539, 11, 436, 434, 767, 588, 709, 4077, 281, 437, 291, 1062, 458, 382, 18161, 9590, 7547, 538, 1952, 43585, 11, 51214], "temperature": 0.0, "avg_logprob": -0.08605667461048473, "compression_ratio": 1.6622516556291391, "no_speech_prob": 0.0013249856419861317}, {"id": 850, "seek": 338154, "start": 3398.54, "end": 3403.54, "text": " whereby inside of our brains and elsewhere in our brain, there's lots of these neurons here that can send electrical signals", "tokens": [51214, 36998, 1854, 295, 527, 15442, 293, 14517, 294, 527, 3567, 11, 456, 311, 3195, 295, 613, 22027, 510, 300, 393, 2845, 12147, 12354, 51464], "temperature": 0.0, "avg_logprob": -0.08605667461048473, "compression_ratio": 1.6622516556291391, "no_speech_prob": 0.0013249856419861317}, {"id": 851, "seek": 338154, "start": 3403.54, "end": 3406.54, "text": " to sort of make movements happen from brain to extremities.", "tokens": [51464, 281, 1333, 295, 652, 9981, 1051, 490, 3567, 281, 4040, 1088, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08605667461048473, "compression_ratio": 1.6622516556291391, "no_speech_prob": 0.0013249856419861317}, {"id": 852, "seek": 340654, "start": 3406.54, "end": 3411.54, "text": " You might have two of these via which signals can be transmitted over larger distance.", "tokens": [50364, 509, 1062, 362, 732, 295, 613, 5766, 597, 12354, 393, 312, 25355, 670, 4833, 4560, 13, 50614], "temperature": 0.0, "avg_logprob": -0.07153290890632792, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0037071637343615294}, {"id": 853, "seek": 340654, "start": 3411.54, "end": 3420.54, "text": " And so computer scientists for some time have drawn inspiration from these neurons to create in software what we call neural networks,", "tokens": [50614, 400, 370, 3820, 7708, 337, 512, 565, 362, 10117, 10249, 490, 613, 22027, 281, 1884, 294, 4722, 437, 321, 818, 18161, 9590, 11, 51064], "temperature": 0.0, "avg_logprob": -0.07153290890632792, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0037071637343615294}, {"id": 854, "seek": 340654, "start": 3420.54, "end": 3428.54, "text": " whereby there's inputs to these networks and there's outputs from these networks that represents inputs to problems and solutions there too.", "tokens": [51064, 36998, 456, 311, 15743, 281, 613, 9590, 293, 456, 311, 23930, 490, 613, 9590, 300, 8855, 15743, 281, 2740, 293, 6547, 456, 886, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07153290890632792, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0037071637343615294}, {"id": 855, "seek": 340654, "start": 3428.54, "end": 3434.54, "text": " So let me abstract away the more biological diagrams with just circles that represent nodes or neurons in this case.", "tokens": [51464, 407, 718, 385, 12649, 1314, 264, 544, 13910, 36709, 365, 445, 13040, 300, 2906, 13891, 420, 22027, 294, 341, 1389, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07153290890632792, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.0037071637343615294}, {"id": 856, "seek": 343454, "start": 3434.54, "end": 3439.54, "text": " This would be, we'd call in CS50, the input. This is what we would call the output,", "tokens": [50364, 639, 576, 312, 11, 321, 1116, 818, 294, 9460, 2803, 11, 264, 4846, 13, 639, 307, 437, 321, 576, 818, 264, 5598, 11, 50614], "temperature": 0.0, "avg_logprob": -0.08461598325366816, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.0024725613184273243}, {"id": 857, "seek": 343454, "start": 3439.54, "end": 3442.54, "text": " but this is very simplistic, very simple neural network.", "tokens": [50614, 457, 341, 307, 588, 44199, 11, 588, 2199, 18161, 3209, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08461598325366816, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.0024725613184273243}, {"id": 858, "seek": 343454, "start": 3442.54, "end": 3449.54, "text": " This might be more common whereby the network, the AI takes two inputs to a problem and tries to give you one solution.", "tokens": [50764, 639, 1062, 312, 544, 2689, 36998, 264, 3209, 11, 264, 7318, 2516, 732, 15743, 281, 257, 1154, 293, 9898, 281, 976, 291, 472, 3827, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08461598325366816, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.0024725613184273243}, {"id": 859, "seek": 343454, "start": 3449.54, "end": 3451.54, "text": " Well, let's make this more real.", "tokens": [51114, 1042, 11, 718, 311, 652, 341, 544, 957, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08461598325366816, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.0024725613184273243}, {"id": 860, "seek": 343454, "start": 3451.54, "end": 3456.54, "text": " For instance, suppose that just for the sake of discussion,", "tokens": [51214, 1171, 5197, 11, 7297, 300, 445, 337, 264, 9717, 295, 5017, 11, 51464], "temperature": 0.0, "avg_logprob": -0.08461598325366816, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.0024725613184273243}, {"id": 861, "seek": 343454, "start": 3456.54, "end": 3462.54, "text": " here is like a grid that you might see in math class with a y-axis and an x-axis vertically and horizontally respectively.", "tokens": [51464, 510, 307, 411, 257, 10748, 300, 291, 1062, 536, 294, 5221, 1508, 365, 257, 288, 12, 24633, 293, 364, 2031, 12, 24633, 28450, 293, 33796, 25009, 13, 51764], "temperature": 0.0, "avg_logprob": -0.08461598325366816, "compression_ratio": 1.6413793103448275, "no_speech_prob": 0.0024725613184273243}, {"id": 862, "seek": 346254, "start": 3462.54, "end": 3465.54, "text": " Suppose there's a couple of blue and red dots in that world,", "tokens": [50364, 21360, 456, 311, 257, 1916, 295, 3344, 293, 2182, 15026, 294, 300, 1002, 11, 50514], "temperature": 0.0, "avg_logprob": -0.07387874921162924, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0018101740861311555}, {"id": 863, "seek": 346254, "start": 3465.54, "end": 3476.54, "text": " and suppose that our goal computationally is to predict whether a dot is going to be blue or red based on its position within that coordinate system.", "tokens": [50514, 293, 7297, 300, 527, 3387, 24903, 379, 307, 281, 6069, 1968, 257, 5893, 307, 516, 281, 312, 3344, 420, 2182, 2361, 322, 1080, 2535, 1951, 300, 15670, 1185, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07387874921162924, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0018101740861311555}, {"id": 864, "seek": 346254, "start": 3476.54, "end": 3479.54, "text": " And maybe this represents some real world notion.", "tokens": [51064, 400, 1310, 341, 8855, 512, 957, 1002, 10710, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07387874921162924, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0018101740861311555}, {"id": 865, "seek": 346254, "start": 3479.54, "end": 3481.54, "text": " Maybe it's something like rain that we're trying to predict,", "tokens": [51214, 2704, 309, 311, 746, 411, 4830, 300, 321, 434, 1382, 281, 6069, 11, 51314], "temperature": 0.0, "avg_logprob": -0.07387874921162924, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0018101740861311555}, {"id": 866, "seek": 346254, "start": 3481.54, "end": 3483.54, "text": " but we're doing it more simply with colors right now.", "tokens": [51314, 457, 321, 434, 884, 309, 544, 2935, 365, 4577, 558, 586, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07387874921162924, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0018101740861311555}, {"id": 867, "seek": 346254, "start": 3483.54, "end": 3489.54, "text": " So here's my y-axis, here's my x-axis, and effectively my neural network you can think of conceptually as this.", "tokens": [51414, 407, 510, 311, 452, 288, 12, 24633, 11, 510, 311, 452, 2031, 12, 24633, 11, 293, 8659, 452, 18161, 3209, 291, 393, 519, 295, 3410, 671, 382, 341, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07387874921162924, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0018101740861311555}, {"id": 868, "seek": 348954, "start": 3489.54, "end": 3493.54, "text": " It's some kind of implementation of software where there's two inputs to the problem.", "tokens": [50364, 467, 311, 512, 733, 295, 11420, 295, 4722, 689, 456, 311, 732, 15743, 281, 264, 1154, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06403659110845522, "compression_ratio": 1.7439446366782008, "no_speech_prob": 0.0038244184106588364}, {"id": 869, "seek": 348954, "start": 3493.54, "end": 3500.54, "text": " Give me an x, give me a y value, and this neural network will output red or blue as its prediction.", "tokens": [50564, 5303, 385, 364, 2031, 11, 976, 385, 257, 288, 2158, 11, 293, 341, 18161, 3209, 486, 5598, 2182, 420, 3344, 382, 1080, 17630, 13, 50914], "temperature": 0.0, "avg_logprob": -0.06403659110845522, "compression_ratio": 1.7439446366782008, "no_speech_prob": 0.0038244184106588364}, {"id": 870, "seek": 348954, "start": 3500.54, "end": 3502.54, "text": " Well, how does it know whether to predict red or blue,", "tokens": [50914, 1042, 11, 577, 775, 309, 458, 1968, 281, 6069, 2182, 420, 3344, 11, 51014], "temperature": 0.0, "avg_logprob": -0.06403659110845522, "compression_ratio": 1.7439446366782008, "no_speech_prob": 0.0038244184106588364}, {"id": 871, "seek": 348954, "start": 3502.54, "end": 3509.54, "text": " especially if no human has painstakingly written code to say when you see a dot here, conclude that it's red?", "tokens": [51014, 2318, 498, 572, 1952, 575, 1822, 372, 2456, 356, 3720, 3089, 281, 584, 562, 291, 536, 257, 5893, 510, 11, 16886, 300, 309, 311, 2182, 30, 51364], "temperature": 0.0, "avg_logprob": -0.06403659110845522, "compression_ratio": 1.7439446366782008, "no_speech_prob": 0.0038244184106588364}, {"id": 872, "seek": 348954, "start": 3509.54, "end": 3514.54, "text": " When you see a dot here conclude that it's blue, how can an AI just learn dynamically to solve problems?", "tokens": [51364, 1133, 291, 536, 257, 5893, 510, 16886, 300, 309, 311, 3344, 11, 577, 393, 364, 7318, 445, 1466, 43492, 281, 5039, 2740, 30, 51614], "temperature": 0.0, "avg_logprob": -0.06403659110845522, "compression_ratio": 1.7439446366782008, "no_speech_prob": 0.0038244184106588364}, {"id": 873, "seek": 348954, "start": 3514.54, "end": 3517.54, "text": " Well, what might be a reasonable heuristic here?", "tokens": [51614, 1042, 11, 437, 1062, 312, 257, 10585, 415, 374, 3142, 510, 30, 51764], "temperature": 0.0, "avg_logprob": -0.06403659110845522, "compression_ratio": 1.7439446366782008, "no_speech_prob": 0.0038244184106588364}, {"id": 874, "seek": 351754, "start": 3517.54, "end": 3520.54, "text": " Honestly, this is probably a first approximation that's pretty good.", "tokens": [50364, 12348, 11, 341, 307, 1391, 257, 700, 28023, 300, 311, 1238, 665, 13, 50514], "temperature": 0.0, "avg_logprob": -0.058605660332573785, "compression_ratio": 1.8293515358361774, "no_speech_prob": 0.0004728470812551677}, {"id": 875, "seek": 351754, "start": 3520.54, "end": 3524.54, "text": " If anything's to the left of that line, let the neural network conclude that it's going to be blue.", "tokens": [50514, 759, 1340, 311, 281, 264, 1411, 295, 300, 1622, 11, 718, 264, 18161, 3209, 16886, 300, 309, 311, 516, 281, 312, 3344, 13, 50714], "temperature": 0.0, "avg_logprob": -0.058605660332573785, "compression_ratio": 1.8293515358361774, "no_speech_prob": 0.0004728470812551677}, {"id": 876, "seek": 351754, "start": 3524.54, "end": 3527.54, "text": " And if it's to the right of the line, let it conclude that it's going to be red.", "tokens": [50714, 400, 498, 309, 311, 281, 264, 558, 295, 264, 1622, 11, 718, 309, 16886, 300, 309, 311, 516, 281, 312, 2182, 13, 50864], "temperature": 0.0, "avg_logprob": -0.058605660332573785, "compression_ratio": 1.8293515358361774, "no_speech_prob": 0.0004728470812551677}, {"id": 877, "seek": 351754, "start": 3527.54, "end": 3534.54, "text": " Until such time as there's more training data, more real world data that gets us to rethink our assumptions.", "tokens": [50864, 9088, 1270, 565, 382, 456, 311, 544, 3097, 1412, 11, 544, 957, 1002, 1412, 300, 2170, 505, 281, 34595, 527, 17695, 13, 51214], "temperature": 0.0, "avg_logprob": -0.058605660332573785, "compression_ratio": 1.8293515358361774, "no_speech_prob": 0.0004728470812551677}, {"id": 878, "seek": 351754, "start": 3534.54, "end": 3538.54, "text": " So for instance, if there's a third dot there, oh, clearly a straight line is not sufficient.", "tokens": [51214, 407, 337, 5197, 11, 498, 456, 311, 257, 2636, 5893, 456, 11, 1954, 11, 4448, 257, 2997, 1622, 307, 406, 11563, 13, 51414], "temperature": 0.0, "avg_logprob": -0.058605660332573785, "compression_ratio": 1.8293515358361774, "no_speech_prob": 0.0004728470812551677}, {"id": 879, "seek": 351754, "start": 3538.54, "end": 3543.54, "text": " So maybe it's more of a diagonal line that splits the blue from the red world here.", "tokens": [51414, 407, 1310, 309, 311, 544, 295, 257, 21539, 1622, 300, 37741, 264, 3344, 490, 264, 2182, 1002, 510, 13, 51664], "temperature": 0.0, "avg_logprob": -0.058605660332573785, "compression_ratio": 1.8293515358361774, "no_speech_prob": 0.0004728470812551677}, {"id": 880, "seek": 354354, "start": 3543.54, "end": 3545.54, "text": " Meanwhile, here's even more dots.", "tokens": [50364, 13879, 11, 510, 311, 754, 544, 15026, 13, 50464], "temperature": 0.0, "avg_logprob": -0.06926994047303131, "compression_ratio": 1.7138047138047139, "no_speech_prob": 0.0015011595096439123}, {"id": 881, "seek": 354354, "start": 3545.54, "end": 3547.54, "text": " And it's actually getting harder now.", "tokens": [50464, 400, 309, 311, 767, 1242, 6081, 586, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06926994047303131, "compression_ratio": 1.7138047138047139, "no_speech_prob": 0.0015011595096439123}, {"id": 882, "seek": 354354, "start": 3547.54, "end": 3549.54, "text": " Like this line is still pretty good.", "tokens": [50564, 1743, 341, 1622, 307, 920, 1238, 665, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06926994047303131, "compression_ratio": 1.7138047138047139, "no_speech_prob": 0.0015011595096439123}, {"id": 883, "seek": 354354, "start": 3549.54, "end": 3550.54, "text": " Most of the blue is up here.", "tokens": [50664, 4534, 295, 264, 3344, 307, 493, 510, 13, 50714], "temperature": 0.0, "avg_logprob": -0.06926994047303131, "compression_ratio": 1.7138047138047139, "no_speech_prob": 0.0015011595096439123}, {"id": 884, "seek": 354354, "start": 3550.54, "end": 3552.54, "text": " Most of the red is down here.", "tokens": [50714, 4534, 295, 264, 2182, 307, 760, 510, 13, 50814], "temperature": 0.0, "avg_logprob": -0.06926994047303131, "compression_ratio": 1.7138047138047139, "no_speech_prob": 0.0015011595096439123}, {"id": 885, "seek": 354354, "start": 3552.54, "end": 3558.54, "text": " And this is why if we fast forward to today, AI is often very good but not perfect at solving problems.", "tokens": [50814, 400, 341, 307, 983, 498, 321, 2370, 2128, 281, 965, 11, 7318, 307, 2049, 588, 665, 457, 406, 2176, 412, 12606, 2740, 13, 51114], "temperature": 0.0, "avg_logprob": -0.06926994047303131, "compression_ratio": 1.7138047138047139, "no_speech_prob": 0.0015011595096439123}, {"id": 886, "seek": 354354, "start": 3558.54, "end": 3560.54, "text": " But what is it we're looking at here?", "tokens": [51114, 583, 437, 307, 309, 321, 434, 1237, 412, 510, 30, 51214], "temperature": 0.0, "avg_logprob": -0.06926994047303131, "compression_ratio": 1.7138047138047139, "no_speech_prob": 0.0015011595096439123}, {"id": 887, "seek": 354354, "start": 3560.54, "end": 3563.54, "text": " And what is this neural network really trying to figure out?", "tokens": [51214, 400, 437, 307, 341, 18161, 3209, 534, 1382, 281, 2573, 484, 30, 51364], "temperature": 0.0, "avg_logprob": -0.06926994047303131, "compression_ratio": 1.7138047138047139, "no_speech_prob": 0.0015011595096439123}, {"id": 888, "seek": 354354, "start": 3563.54, "end": 3566.54, "text": " Well, again, at the risk of taking some fun out of red and blue dots,", "tokens": [51364, 1042, 11, 797, 11, 412, 264, 3148, 295, 1940, 512, 1019, 484, 295, 2182, 293, 3344, 15026, 11, 51514], "temperature": 0.0, "avg_logprob": -0.06926994047303131, "compression_ratio": 1.7138047138047139, "no_speech_prob": 0.0015011595096439123}, {"id": 889, "seek": 354354, "start": 3566.54, "end": 3570.54, "text": " you can think of this neural network as indeed having these neurons,", "tokens": [51514, 291, 393, 519, 295, 341, 18161, 3209, 382, 6451, 1419, 613, 22027, 11, 51714], "temperature": 0.0, "avg_logprob": -0.06926994047303131, "compression_ratio": 1.7138047138047139, "no_speech_prob": 0.0015011595096439123}, {"id": 890, "seek": 357054, "start": 3570.54, "end": 3573.54, "text": " which represent inputs here and outputs here.", "tokens": [50364, 597, 2906, 15743, 510, 293, 23930, 510, 13, 50514], "temperature": 0.0, "avg_logprob": -0.05517061317668242, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.0015011468203738332}, {"id": 891, "seek": 357054, "start": 3573.54, "end": 3580.54, "text": " And then what's happening inside of the computer's memory is that it's trying to figure out what the weight of this arrow or edge should be.", "tokens": [50514, 400, 550, 437, 311, 2737, 1854, 295, 264, 3820, 311, 4675, 307, 300, 309, 311, 1382, 281, 2573, 484, 437, 264, 3364, 295, 341, 11610, 420, 4691, 820, 312, 13, 50864], "temperature": 0.0, "avg_logprob": -0.05517061317668242, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.0015011468203738332}, {"id": 892, "seek": 357054, "start": 3580.54, "end": 3583.54, "text": " What the weight of this arrow or edge should be.", "tokens": [50864, 708, 264, 3364, 295, 341, 11610, 420, 4691, 820, 312, 13, 51014], "temperature": 0.0, "avg_logprob": -0.05517061317668242, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.0015011468203738332}, {"id": 893, "seek": 357054, "start": 3583.54, "end": 3587.54, "text": " And maybe there's another variable there like plus or minus C that just tweaks the prediction.", "tokens": [51014, 400, 1310, 456, 311, 1071, 7006, 456, 411, 1804, 420, 3175, 383, 300, 445, 46664, 264, 17630, 13, 51214], "temperature": 0.0, "avg_logprob": -0.05517061317668242, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.0015011468203738332}, {"id": 894, "seek": 357054, "start": 3587.54, "end": 3591.54, "text": " So x and y are literally going to be numbers in this scenario.", "tokens": [51214, 407, 2031, 293, 288, 366, 3736, 516, 281, 312, 3547, 294, 341, 9005, 13, 51414], "temperature": 0.0, "avg_logprob": -0.05517061317668242, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.0015011468203738332}, {"id": 895, "seek": 357054, "start": 3591.54, "end": 3594.54, "text": " And the output of this neural network ideally is just true or false.", "tokens": [51414, 400, 264, 5598, 295, 341, 18161, 3209, 22915, 307, 445, 2074, 420, 7908, 13, 51564], "temperature": 0.0, "avg_logprob": -0.05517061317668242, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.0015011468203738332}, {"id": 896, "seek": 357054, "start": 3594.54, "end": 3596.54, "text": " Is it red or blue?", "tokens": [51564, 1119, 309, 2182, 420, 3344, 30, 51664], "temperature": 0.0, "avg_logprob": -0.05517061317668242, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.0015011468203738332}, {"id": 897, "seek": 357054, "start": 3596.54, "end": 3599.54, "text": " So it's sort of a binary state as we discuss a lot in CS50.", "tokens": [51664, 407, 309, 311, 1333, 295, 257, 17434, 1785, 382, 321, 2248, 257, 688, 294, 9460, 2803, 13, 51814], "temperature": 0.0, "avg_logprob": -0.05517061317668242, "compression_ratio": 1.8154362416107384, "no_speech_prob": 0.0015011468203738332}, {"id": 898, "seek": 359954, "start": 3599.54, "end": 3602.54, "text": " So here, too, to take the sort of fun out of the pretty picture,", "tokens": [50364, 407, 510, 11, 886, 11, 281, 747, 264, 1333, 295, 1019, 484, 295, 264, 1238, 3036, 11, 50514], "temperature": 0.0, "avg_logprob": -0.0811938427864237, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.000666687497869134}, {"id": 899, "seek": 359954, "start": 3602.54, "end": 3604.54, "text": " it's really just like a high school math function.", "tokens": [50514, 309, 311, 534, 445, 411, 257, 1090, 1395, 5221, 2445, 13, 50614], "temperature": 0.0, "avg_logprob": -0.0811938427864237, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.000666687497869134}, {"id": 900, "seek": 359954, "start": 3604.54, "end": 3613.54, "text": " What the neural network in this example is trying to figure out is what formula of the form AX plus BY plus C is going to be arbitrarily greater than zero.", "tokens": [50614, 708, 264, 18161, 3209, 294, 341, 1365, 307, 1382, 281, 2573, 484, 307, 437, 8513, 295, 264, 1254, 316, 55, 1804, 26930, 1804, 383, 307, 516, 281, 312, 19071, 3289, 5044, 813, 4018, 13, 51064], "temperature": 0.0, "avg_logprob": -0.0811938427864237, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.000666687497869134}, {"id": 901, "seek": 359954, "start": 3613.54, "end": 3618.54, "text": " And if so, let's conclude that the dot is red if you get back a positive result.", "tokens": [51064, 400, 498, 370, 11, 718, 311, 16886, 300, 264, 5893, 307, 2182, 498, 291, 483, 646, 257, 3353, 1874, 13, 51314], "temperature": 0.0, "avg_logprob": -0.0811938427864237, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.000666687497869134}, {"id": 902, "seek": 359954, "start": 3618.54, "end": 3622.54, "text": " If you don't, let's conclude that the dot is going to be blue instead.", "tokens": [51314, 759, 291, 500, 380, 11, 718, 311, 16886, 300, 264, 5893, 307, 516, 281, 312, 3344, 2602, 13, 51514], "temperature": 0.0, "avg_logprob": -0.0811938427864237, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.000666687497869134}, {"id": 903, "seek": 359954, "start": 3622.54, "end": 3628.54, "text": " So really what you're trying to do is figure out dynamically what numbers do we have to tweak these parameters inside of the neural network?", "tokens": [51514, 407, 534, 437, 291, 434, 1382, 281, 360, 307, 2573, 484, 43492, 437, 3547, 360, 321, 362, 281, 29879, 613, 9834, 1854, 295, 264, 18161, 3209, 30, 51814], "temperature": 0.0, "avg_logprob": -0.0811938427864237, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.000666687497869134}, {"id": 904, "seek": 362854, "start": 3628.54, "end": 3632.54, "text": " That just give us the answer we want based on all of this data.", "tokens": [50364, 663, 445, 976, 505, 264, 1867, 321, 528, 2361, 322, 439, 295, 341, 1412, 13, 50564], "temperature": 0.0, "avg_logprob": -0.0911958987896259, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.003945247735828161}, {"id": 905, "seek": 362854, "start": 3632.54, "end": 3636.54, "text": " More generally, though, this would be really representative of deep learning.", "tokens": [50564, 5048, 5101, 11, 1673, 11, 341, 576, 312, 534, 12424, 295, 2452, 2539, 13, 50764], "temperature": 0.0, "avg_logprob": -0.0911958987896259, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.003945247735828161}, {"id": 906, "seek": 362854, "start": 3636.54, "end": 3638.54, "text": " It's not as simple as input, input, output.", "tokens": [50764, 467, 311, 406, 382, 2199, 382, 4846, 11, 4846, 11, 5598, 13, 50864], "temperature": 0.0, "avg_logprob": -0.0911958987896259, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.003945247735828161}, {"id": 907, "seek": 362854, "start": 3638.54, "end": 3641.54, "text": " There's actually a lot of these nodes, these neurons.", "tokens": [50864, 821, 311, 767, 257, 688, 295, 613, 13891, 11, 613, 22027, 13, 51014], "temperature": 0.0, "avg_logprob": -0.0911958987896259, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.003945247735828161}, {"id": 908, "seek": 362854, "start": 3641.54, "end": 3642.54, "text": " There's a lot of these edges.", "tokens": [51014, 821, 311, 257, 688, 295, 613, 8819, 13, 51064], "temperature": 0.0, "avg_logprob": -0.0911958987896259, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.003945247735828161}, {"id": 909, "seek": 362854, "start": 3642.54, "end": 3650.54, "text": " There's a lot of numbers and math are going on that, frankly, even the computer scientists using these neural networks don't necessarily know what they even mean or represent.", "tokens": [51064, 821, 311, 257, 688, 295, 3547, 293, 5221, 366, 516, 322, 300, 11, 11939, 11, 754, 264, 3820, 7708, 1228, 613, 18161, 9590, 500, 380, 4725, 458, 437, 436, 754, 914, 420, 2906, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0911958987896259, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.003945247735828161}, {"id": 910, "seek": 362854, "start": 3650.54, "end": 3656.54, "text": " It just happens to be that when you crunch the numbers with all of these parameters in place,", "tokens": [51464, 467, 445, 2314, 281, 312, 300, 562, 291, 13386, 264, 3547, 365, 439, 295, 613, 9834, 294, 1081, 11, 51764], "temperature": 0.0, "avg_logprob": -0.0911958987896259, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.003945247735828161}, {"id": 911, "seek": 365654, "start": 3656.54, "end": 3660.54, "text": " you get the answer that you want, at least most of the time.", "tokens": [50364, 291, 483, 264, 1867, 300, 291, 528, 11, 412, 1935, 881, 295, 264, 565, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09081357873004416, "compression_ratio": 1.7689530685920578, "no_speech_prob": 0.011686545796692371}, {"id": 912, "seek": 365654, "start": 3660.54, "end": 3662.54, "text": " So that's essentially the intuition behind that.", "tokens": [50564, 407, 300, 311, 4476, 264, 24002, 2261, 300, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09081357873004416, "compression_ratio": 1.7689530685920578, "no_speech_prob": 0.011686545796692371}, {"id": 913, "seek": 365654, "start": 3662.54, "end": 3670.54, "text": " And you can apply it to a very real world if mundane applications, given today's humidity, given today's pressure, yes or no should there be rainfall.", "tokens": [50664, 400, 291, 393, 3079, 309, 281, 257, 588, 957, 1002, 498, 43497, 5821, 11, 2212, 965, 311, 24751, 11, 2212, 965, 311, 3321, 11, 2086, 420, 572, 820, 456, 312, 29382, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09081357873004416, "compression_ratio": 1.7689530685920578, "no_speech_prob": 0.011686545796692371}, {"id": 914, "seek": 365654, "start": 3670.54, "end": 3674.54, "text": " And maybe there is some mathematical function that based on years of training data,", "tokens": [51064, 400, 1310, 456, 307, 512, 18894, 2445, 300, 2361, 322, 924, 295, 3097, 1412, 11, 51264], "temperature": 0.0, "avg_logprob": -0.09081357873004416, "compression_ratio": 1.7689530685920578, "no_speech_prob": 0.011686545796692371}, {"id": 915, "seek": 365654, "start": 3674.54, "end": 3677.54, "text": " we can infer what that prediction should be.", "tokens": [51264, 321, 393, 13596, 437, 300, 17630, 820, 312, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09081357873004416, "compression_ratio": 1.7689530685920578, "no_speech_prob": 0.011686545796692371}, {"id": 916, "seek": 365654, "start": 3677.54, "end": 3683.54, "text": " Another one, given this amount of advertising in this month, what should our sales be for that year?", "tokens": [51414, 3996, 472, 11, 2212, 341, 2372, 295, 13097, 294, 341, 1618, 11, 437, 820, 527, 5763, 312, 337, 300, 1064, 30, 51714], "temperature": 0.0, "avg_logprob": -0.09081357873004416, "compression_ratio": 1.7689530685920578, "no_speech_prob": 0.011686545796692371}, {"id": 917, "seek": 368354, "start": 3683.54, "end": 3685.54, "text": " Should they be up or should they be down?", "tokens": [50364, 6454, 436, 312, 493, 420, 820, 436, 312, 760, 30, 50464], "temperature": 0.0, "avg_logprob": -0.08450627052920988, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.002251781988888979}, {"id": 918, "seek": 368354, "start": 3685.54, "end": 3687.54, "text": " Sorry for that particular month.", "tokens": [50464, 4919, 337, 300, 1729, 1618, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08450627052920988, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.002251781988888979}, {"id": 919, "seek": 368354, "start": 3687.54, "end": 3700.54, "text": " So real world problems map readily when you can break them down into inputs and a binary output often or some kind of output where you want the thing to figure out based on past data what its prediction should be.", "tokens": [50564, 407, 957, 1002, 2740, 4471, 26336, 562, 291, 393, 1821, 552, 760, 666, 15743, 293, 257, 17434, 5598, 2049, 420, 512, 733, 295, 5598, 689, 291, 528, 264, 551, 281, 2573, 484, 2361, 322, 1791, 1412, 437, 1080, 17630, 820, 312, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08450627052920988, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.002251781988888979}, {"id": 920, "seek": 368354, "start": 3700.54, "end": 3706.54, "text": " So that brings us back to generative artificial intelligence, which isn't just about solving problems,", "tokens": [51214, 407, 300, 5607, 505, 646, 281, 1337, 1166, 11677, 7599, 11, 597, 1943, 380, 445, 466, 12606, 2740, 11, 51514], "temperature": 0.0, "avg_logprob": -0.08450627052920988, "compression_ratio": 1.6291666666666667, "no_speech_prob": 0.002251781988888979}, {"id": 921, "seek": 370654, "start": 3706.54, "end": 3716.54, "text": " but really generating literally images, texts, even videos that again increasingly resemble what we humans might otherwise output ourselves.", "tokens": [50364, 457, 534, 17746, 3736, 5267, 11, 15765, 11, 754, 2145, 300, 797, 12980, 36870, 437, 321, 6255, 1062, 5911, 5598, 4175, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11996918846579159, "compression_ratio": 1.6861924686192469, "no_speech_prob": 0.12938185036182404}, {"id": 922, "seek": 370654, "start": 3716.54, "end": 3724.54, "text": " And within the world of generative artificial intelligence, do we have, of course, the same images that we saw before, the same text that we saw before,", "tokens": [50864, 400, 1951, 264, 1002, 295, 1337, 1166, 11677, 7599, 11, 360, 321, 362, 11, 295, 1164, 11, 264, 912, 5267, 300, 321, 1866, 949, 11, 264, 912, 2487, 300, 321, 1866, 949, 11, 51264], "temperature": 0.0, "avg_logprob": -0.11996918846579159, "compression_ratio": 1.6861924686192469, "no_speech_prob": 0.12938185036182404}, {"id": 923, "seek": 370654, "start": 3724.54, "end": 3730.54, "text": " and more generally things like chat GPT, which are really examples of what we now call large language models,", "tokens": [51264, 293, 544, 5101, 721, 411, 5081, 26039, 51, 11, 597, 366, 534, 5110, 295, 437, 321, 586, 818, 2416, 2856, 5245, 11, 51564], "temperature": 0.0, "avg_logprob": -0.11996918846579159, "compression_ratio": 1.6861924686192469, "no_speech_prob": 0.12938185036182404}, {"id": 924, "seek": 373054, "start": 3730.54, "end": 3741.54, "text": " these sort of massive neural networks that have so many inputs and so many neurons implemented in software that essentially represent all of the patterns that the software has discovered", "tokens": [50364, 613, 1333, 295, 5994, 18161, 9590, 300, 362, 370, 867, 15743, 293, 370, 867, 22027, 12270, 294, 4722, 300, 4476, 2906, 439, 295, 264, 8294, 300, 264, 4722, 575, 6941, 50914], "temperature": 0.0, "avg_logprob": -0.07353278889375574, "compression_ratio": 1.8110599078341014, "no_speech_prob": 0.2450244426727295}, {"id": 925, "seek": 373054, "start": 3741.54, "end": 3743.54, "text": " by being fed massive amounts of input.", "tokens": [50914, 538, 885, 4636, 5994, 11663, 295, 4846, 13, 51014], "temperature": 0.0, "avg_logprob": -0.07353278889375574, "compression_ratio": 1.8110599078341014, "no_speech_prob": 0.2450244426727295}, {"id": 926, "seek": 373054, "start": 3743.54, "end": 3747.54, "text": " Think of it as like the entire textual content of the internet.", "tokens": [51014, 6557, 295, 309, 382, 411, 264, 2302, 2487, 901, 2701, 295, 264, 4705, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07353278889375574, "compression_ratio": 1.8110599078341014, "no_speech_prob": 0.2450244426727295}, {"id": 927, "seek": 373054, "start": 3747.54, "end": 3752.54, "text": " Think of it as the entire content of courses like CS50 that may very well be out there on the internet.", "tokens": [51214, 6557, 295, 309, 382, 264, 2302, 2701, 295, 7712, 411, 9460, 2803, 300, 815, 588, 731, 312, 484, 456, 322, 264, 4705, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07353278889375574, "compression_ratio": 1.8110599078341014, "no_speech_prob": 0.2450244426727295}, {"id": 928, "seek": 375254, "start": 3752.54, "end": 3765.54, "text": " And even though these AIs, these large language models, haven't been told how to behave, they're really inferring from all of these examples for better or for worse how to make predictions.", "tokens": [50364, 400, 754, 1673, 613, 316, 6802, 11, 613, 2416, 2856, 5245, 11, 2378, 380, 668, 1907, 577, 281, 15158, 11, 436, 434, 534, 13596, 2937, 490, 439, 295, 613, 5110, 337, 1101, 420, 337, 5324, 577, 281, 652, 21264, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09026134466823144, "compression_ratio": 1.5223214285714286, "no_speech_prob": 0.058341506868600845}, {"id": 929, "seek": 375254, "start": 3765.54, "end": 3774.54, "text": " So here, for instance, from 2017, just a few years back, is a seminal paper from Google that introduced what we now know as a transformer architecture.", "tokens": [51014, 407, 510, 11, 337, 5197, 11, 490, 6591, 11, 445, 257, 1326, 924, 646, 11, 307, 257, 4361, 2071, 3035, 490, 3329, 300, 7268, 437, 321, 586, 458, 382, 257, 31782, 9482, 13, 51464], "temperature": 0.0, "avg_logprob": -0.09026134466823144, "compression_ratio": 1.5223214285714286, "no_speech_prob": 0.058341506868600845}, {"id": 930, "seek": 377454, "start": 3774.54, "end": 3783.54, "text": " And this introduced this idea of attention values, whereby they propose that given an English sentence, for instance, or really any human sentence, you try to assign numbers,", "tokens": [50364, 400, 341, 7268, 341, 1558, 295, 3202, 4190, 11, 36998, 436, 17421, 300, 2212, 364, 3669, 8174, 11, 337, 5197, 11, 420, 534, 604, 1952, 8174, 11, 291, 853, 281, 6269, 3547, 11, 50814], "temperature": 0.0, "avg_logprob": -0.06571874787322188, "compression_ratio": 1.8185053380782918, "no_speech_prob": 0.3628692030906677}, {"id": 931, "seek": 377454, "start": 3783.54, "end": 3790.54, "text": " not unlike our past exercises, to each of the words, each of the inputs that speaks to its relationship with other words.", "tokens": [50814, 406, 8343, 527, 1791, 11900, 11, 281, 1184, 295, 264, 2283, 11, 1184, 295, 264, 15743, 300, 10789, 281, 1080, 2480, 365, 661, 2283, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06571874787322188, "compression_ratio": 1.8185053380782918, "no_speech_prob": 0.3628692030906677}, {"id": 932, "seek": 377454, "start": 3790.54, "end": 3795.54, "text": " So if there's a high relationship between two words and a sentence, they would have high attention values.", "tokens": [51164, 407, 498, 456, 311, 257, 1090, 2480, 1296, 732, 2283, 293, 257, 8174, 11, 436, 576, 362, 1090, 3202, 4190, 13, 51414], "temperature": 0.0, "avg_logprob": -0.06571874787322188, "compression_ratio": 1.8185053380782918, "no_speech_prob": 0.3628692030906677}, {"id": 933, "seek": 377454, "start": 3795.54, "end": 3800.54, "text": " And if maybe it's a preposition or an article like the or the like, maybe those attention values are lower.", "tokens": [51414, 400, 498, 1310, 309, 311, 257, 2666, 5830, 420, 364, 7222, 411, 264, 420, 264, 411, 11, 1310, 729, 3202, 4190, 366, 3126, 13, 51664], "temperature": 0.0, "avg_logprob": -0.06571874787322188, "compression_ratio": 1.8185053380782918, "no_speech_prob": 0.3628692030906677}, {"id": 934, "seek": 380054, "start": 3801.54, "end": 3808.54, "text": " And by encoding the world in that way, do we begin to detect patterns that allow us to predict things like words?", "tokens": [50414, 400, 538, 43430, 264, 1002, 294, 300, 636, 11, 360, 321, 1841, 281, 5531, 8294, 300, 2089, 505, 281, 6069, 721, 411, 2283, 30, 50764], "temperature": 0.0, "avg_logprob": -0.09212963581085205, "compression_ratio": 1.6221498371335505, "no_speech_prob": 0.026757584884762764}, {"id": 935, "seek": 380054, "start": 3808.54, "end": 3809.54, "text": " That is generate text.", "tokens": [50764, 663, 307, 8460, 2487, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09212963581085205, "compression_ratio": 1.6221498371335505, "no_speech_prob": 0.026757584884762764}, {"id": 936, "seek": 380054, "start": 3809.54, "end": 3815.54, "text": " So for instance, up until a few years ago, completing this sentence was actually pretty hard for a lot of AI.", "tokens": [50814, 407, 337, 5197, 11, 493, 1826, 257, 1326, 924, 2057, 11, 19472, 341, 8174, 390, 767, 1238, 1152, 337, 257, 688, 295, 7318, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09212963581085205, "compression_ratio": 1.6221498371335505, "no_speech_prob": 0.026757584884762764}, {"id": 937, "seek": 380054, "start": 3815.54, "end": 3820.54, "text": " So for instance here, Massachusetts is a state in the New England region of the northeastern United States.", "tokens": [51114, 407, 337, 5197, 510, 11, 19979, 307, 257, 1785, 294, 264, 1873, 8196, 4458, 295, 264, 6830, 68, 32579, 2824, 3040, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09212963581085205, "compression_ratio": 1.6221498371335505, "no_speech_prob": 0.026757584884762764}, {"id": 938, "seek": 380054, "start": 3820.54, "end": 3823.54, "text": " It borders on the Atlantic Ocean to the east.", "tokens": [51364, 467, 16287, 322, 264, 20233, 18101, 281, 264, 10648, 13, 51514], "temperature": 0.0, "avg_logprob": -0.09212963581085205, "compression_ratio": 1.6221498371335505, "no_speech_prob": 0.026757584884762764}, {"id": 939, "seek": 380054, "start": 3823.54, "end": 3826.54, "text": " The state's capital is dot dot dot.", "tokens": [51514, 440, 1785, 311, 4238, 307, 5893, 5893, 5893, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09212963581085205, "compression_ratio": 1.6221498371335505, "no_speech_prob": 0.026757584884762764}, {"id": 940, "seek": 380054, "start": 3826.54, "end": 3828.54, "text": " Now you should think that this is relatively straightforward.", "tokens": [51664, 823, 291, 820, 519, 300, 341, 307, 7226, 15325, 13, 51764], "temperature": 0.0, "avg_logprob": -0.09212963581085205, "compression_ratio": 1.6221498371335505, "no_speech_prob": 0.026757584884762764}, {"id": 941, "seek": 382854, "start": 3828.54, "end": 3831.54, "text": " It's like just handing you a softball type question.", "tokens": [50364, 467, 311, 411, 445, 34774, 291, 257, 2787, 3129, 2010, 1168, 13, 50514], "temperature": 0.0, "avg_logprob": -0.06828006233755998, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.0029809274710714817}, {"id": 942, "seek": 382854, "start": 3831.54, "end": 3840.54, "text": " But historically within the world of AI, this word state was so relatively far away from the proper noun that it's actually referring back to,", "tokens": [50514, 583, 16180, 1951, 264, 1002, 295, 7318, 11, 341, 1349, 1785, 390, 370, 7226, 1400, 1314, 490, 264, 2296, 23307, 300, 309, 311, 767, 13761, 646, 281, 11, 50964], "temperature": 0.0, "avg_logprob": -0.06828006233755998, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.0029809274710714817}, {"id": 943, "seek": 382854, "start": 3840.54, "end": 3846.54, "text": " that we just didn't have computational models that sort of took in that holistic picture that frankly we humans are much better at.", "tokens": [50964, 300, 321, 445, 994, 380, 362, 28270, 5245, 300, 1333, 295, 1890, 294, 300, 30334, 3036, 300, 11939, 321, 6255, 366, 709, 1101, 412, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06828006233755998, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.0029809274710714817}, {"id": 944, "seek": 382854, "start": 3846.54, "end": 3851.54, "text": " If you would ask this question a little more quickly, a little more immediately, you might have gotten a better response.", "tokens": [51264, 759, 291, 576, 1029, 341, 1168, 257, 707, 544, 2661, 11, 257, 707, 544, 4258, 11, 291, 1062, 362, 5768, 257, 1101, 4134, 13, 51514], "temperature": 0.0, "avg_logprob": -0.06828006233755998, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.0029809274710714817}, {"id": 945, "seek": 382854, "start": 3851.54, "end": 3855.54, "text": " But this is dare say why chatbots in the past have been so bad in the form of customer service and the like,", "tokens": [51514, 583, 341, 307, 8955, 584, 983, 5081, 65, 1971, 294, 264, 1791, 362, 668, 370, 1578, 294, 264, 1254, 295, 5474, 2643, 293, 264, 411, 11, 51714], "temperature": 0.0, "avg_logprob": -0.06828006233755998, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.0029809274710714817}, {"id": 946, "seek": 385554, "start": 3855.54, "end": 3861.54, "text": " because they're not really taking all of the context into account that we humans might be inclined to provide.", "tokens": [50364, 570, 436, 434, 406, 534, 1940, 439, 295, 264, 4319, 666, 2696, 300, 321, 6255, 1062, 312, 28173, 281, 2893, 13, 50664], "temperature": 0.0, "avg_logprob": -0.13330631436042065, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.01282063964754343}, {"id": 947, "seek": 385554, "start": 3861.54, "end": 3865.54, "text": " What's going on underneath the hood without escalating things too quickly?", "tokens": [50664, 708, 311, 516, 322, 7223, 264, 13376, 1553, 17871, 990, 721, 886, 2661, 30, 50864], "temperature": 0.0, "avg_logprob": -0.13330631436042065, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.01282063964754343}, {"id": 948, "seek": 385554, "start": 3865.54, "end": 3870.54, "text": " What an artificial intelligence nowadays, these large language models might do,", "tokens": [50864, 708, 364, 11677, 7599, 13434, 11, 613, 2416, 2856, 5245, 1062, 360, 11, 51114], "temperature": 0.0, "avg_logprob": -0.13330631436042065, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.01282063964754343}, {"id": 949, "seek": 385554, "start": 3870.54, "end": 3876.54, "text": " is sort of break down the user's input, your input, into chatupiti, into the individual words.", "tokens": [51114, 307, 1333, 295, 1821, 760, 264, 4195, 311, 4846, 11, 428, 4846, 11, 666, 5081, 1010, 8707, 11, 666, 264, 2609, 2283, 13, 51414], "temperature": 0.0, "avg_logprob": -0.13330631436042065, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.01282063964754343}, {"id": 950, "seek": 385554, "start": 3876.54, "end": 3880.54, "text": " We might then take into account the order of those words.", "tokens": [51414, 492, 1062, 550, 747, 666, 2696, 264, 1668, 295, 729, 2283, 13, 51614], "temperature": 0.0, "avg_logprob": -0.13330631436042065, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.01282063964754343}, {"id": 951, "seek": 385554, "start": 3880.54, "end": 3883.54, "text": " Massachusetts is first, is, is last.", "tokens": [51614, 19979, 307, 700, 11, 307, 11, 307, 1036, 13, 51764], "temperature": 0.0, "avg_logprob": -0.13330631436042065, "compression_ratio": 1.6789667896678966, "no_speech_prob": 0.01282063964754343}, {"id": 952, "seek": 388354, "start": 3883.54, "end": 3887.54, "text": " We might further encode each of those words using a standard way.", "tokens": [50364, 492, 1062, 3052, 2058, 1429, 1184, 295, 729, 2283, 1228, 257, 3832, 636, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09685315477087143, "compression_ratio": 1.5590551181102361, "no_speech_prob": 0.009707631543278694}, {"id": 953, "seek": 388354, "start": 3887.54, "end": 3891.54, "text": " And there's different algorithms for this, but you come up with what are called embeddings.", "tokens": [50564, 400, 456, 311, 819, 14642, 337, 341, 11, 457, 291, 808, 493, 365, 437, 366, 1219, 12240, 29432, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09685315477087143, "compression_ratio": 1.5590551181102361, "no_speech_prob": 0.009707631543278694}, {"id": 954, "seek": 388354, "start": 3891.54, "end": 3895.54, "text": " That is to say, you can use one of those APIs I talked about earlier,", "tokens": [50764, 663, 307, 281, 584, 11, 291, 393, 764, 472, 295, 729, 21445, 286, 2825, 466, 3071, 11, 50964], "temperature": 0.0, "avg_logprob": -0.09685315477087143, "compression_ratio": 1.5590551181102361, "no_speech_prob": 0.009707631543278694}, {"id": 955, "seek": 388354, "start": 3895.54, "end": 3902.54, "text": " or even software running on your own computers to come up with a mathematical representation of the word Massachusetts.", "tokens": [50964, 420, 754, 4722, 2614, 322, 428, 1065, 10807, 281, 808, 493, 365, 257, 18894, 10290, 295, 264, 1349, 19979, 13, 51314], "temperature": 0.0, "avg_logprob": -0.09685315477087143, "compression_ratio": 1.5590551181102361, "no_speech_prob": 0.009707631543278694}, {"id": 956, "seek": 388354, "start": 3902.54, "end": 3904.54, "text": " And Rang Shin kindly did this for us last night.", "tokens": [51314, 400, 497, 656, 17347, 29736, 630, 341, 337, 505, 1036, 1818, 13, 51414], "temperature": 0.0, "avg_logprob": -0.09685315477087143, "compression_ratio": 1.5590551181102361, "no_speech_prob": 0.009707631543278694}, {"id": 957, "seek": 390454, "start": 3904.54, "end": 3914.54, "text": " This is the 1536 floating point values that open AI uses to represent the word Massachusetts.", "tokens": [50364, 639, 307, 264, 2119, 11309, 12607, 935, 4190, 300, 1269, 7318, 4960, 281, 2906, 264, 1349, 19979, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09657467007637024, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.09008023887872696}, {"id": 958, "seek": 390454, "start": 3914.54, "end": 3918.54, "text": " And this is to say, and you should not understand anything you are looking at on the screen nor do I,", "tokens": [50864, 400, 341, 307, 281, 584, 11, 293, 291, 820, 406, 1223, 1340, 291, 366, 1237, 412, 322, 264, 2568, 6051, 360, 286, 11, 51064], "temperature": 0.0, "avg_logprob": -0.09657467007637024, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.09008023887872696}, {"id": 959, "seek": 390454, "start": 3918.54, "end": 3924.54, "text": " but this is now a mathematical representation of the input that can be compared against", "tokens": [51064, 457, 341, 307, 586, 257, 18894, 10290, 295, 264, 4846, 300, 393, 312, 5347, 1970, 51364], "temperature": 0.0, "avg_logprob": -0.09657467007637024, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.09008023887872696}, {"id": 960, "seek": 390454, "start": 3924.54, "end": 3929.54, "text": " the mathematical representations of other inputs in order to find proximity semantically.", "tokens": [51364, 264, 18894, 33358, 295, 661, 15743, 294, 1668, 281, 915, 27632, 4361, 49505, 13, 51614], "temperature": 0.0, "avg_logprob": -0.09657467007637024, "compression_ratio": 1.6577777777777778, "no_speech_prob": 0.09008023887872696}, {"id": 961, "seek": 392954, "start": 3929.54, "end": 3934.54, "text": " Words that somehow have relationships or correlations with each other", "tokens": [50364, 32857, 300, 6063, 362, 6159, 420, 13983, 763, 365, 1184, 661, 50614], "temperature": 0.0, "avg_logprob": -0.07592489867083795, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.10667514055967331}, {"id": 962, "seek": 392954, "start": 3934.54, "end": 3940.54, "text": " that helps the AI ultimately predict what should the next word out of its mouth be, so to speak.", "tokens": [50614, 300, 3665, 264, 7318, 6284, 6069, 437, 820, 264, 958, 1349, 484, 295, 1080, 4525, 312, 11, 370, 281, 1710, 13, 50914], "temperature": 0.0, "avg_logprob": -0.07592489867083795, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.10667514055967331}, {"id": 963, "seek": 392954, "start": 3940.54, "end": 3944.54, "text": " So in a case like this, these values represent, these lines represent all of those attention values", "tokens": [50914, 407, 294, 257, 1389, 411, 341, 11, 613, 4190, 2906, 11, 613, 3876, 2906, 439, 295, 729, 3202, 4190, 51114], "temperature": 0.0, "avg_logprob": -0.07592489867083795, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.10667514055967331}, {"id": 964, "seek": 392954, "start": 3944.54, "end": 3948.54, "text": " and thicker lines means there's more attention given from one word to another.", "tokens": [51114, 293, 18142, 3876, 1355, 456, 311, 544, 3202, 2212, 490, 472, 1349, 281, 1071, 13, 51314], "temperature": 0.0, "avg_logprob": -0.07592489867083795, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.10667514055967331}, {"id": 965, "seek": 392954, "start": 3948.54, "end": 3950.54, "text": " Thinner lines mean the opposite.", "tokens": [51314, 334, 19166, 3876, 914, 264, 6182, 13, 51414], "temperature": 0.0, "avg_logprob": -0.07592489867083795, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.10667514055967331}, {"id": 966, "seek": 392954, "start": 3950.54, "end": 3956.54, "text": " And those inputs are ultimately fed into a large neural network where you have inputs on the left,", "tokens": [51414, 400, 729, 15743, 366, 6284, 4636, 666, 257, 2416, 18161, 3209, 689, 291, 362, 15743, 322, 264, 1411, 11, 51714], "temperature": 0.0, "avg_logprob": -0.07592489867083795, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.10667514055967331}, {"id": 967, "seek": 392954, "start": 3956.54, "end": 3958.54, "text": " outputs on the right.", "tokens": [51714, 23930, 322, 264, 558, 13, 51814], "temperature": 0.0, "avg_logprob": -0.07592489867083795, "compression_ratio": 1.8079710144927537, "no_speech_prob": 0.10667514055967331}, {"id": 968, "seek": 395854, "start": 3958.54, "end": 3964.54, "text": " And in this particular case, the hope is to get out a single word, which is the capital of Boston itself,", "tokens": [50364, 400, 294, 341, 1729, 1389, 11, 264, 1454, 307, 281, 483, 484, 257, 2167, 1349, 11, 597, 307, 264, 4238, 295, 12333, 2564, 11, 50664], "temperature": 0.0, "avg_logprob": -0.08474493026733398, "compression_ratio": 1.6023166023166022, "no_speech_prob": 0.00018522147729527205}, {"id": 969, "seek": 395854, "start": 3964.54, "end": 3970.54, "text": " whereby somehow the neural network and the humans behind it at OpenAI, Microsoft, Google, or elsewhere", "tokens": [50664, 36998, 6063, 264, 18161, 3209, 293, 264, 6255, 2261, 309, 412, 7238, 48698, 11, 8116, 11, 3329, 11, 420, 14517, 50964], "temperature": 0.0, "avg_logprob": -0.08474493026733398, "compression_ratio": 1.6023166023166022, "no_speech_prob": 0.00018522147729527205}, {"id": 970, "seek": 395854, "start": 3970.54, "end": 3974.54, "text": " have sort of crunched so many numbers by training these models on so much data", "tokens": [50964, 362, 1333, 295, 13386, 292, 370, 867, 3547, 538, 3097, 613, 5245, 322, 370, 709, 1412, 51164], "temperature": 0.0, "avg_logprob": -0.08474493026733398, "compression_ratio": 1.6023166023166022, "no_speech_prob": 0.00018522147729527205}, {"id": 971, "seek": 395854, "start": 3974.54, "end": 3978.54, "text": " that it figured out what all of those weights are, what the biases are,", "tokens": [51164, 300, 309, 8932, 484, 437, 439, 295, 729, 17443, 366, 11, 437, 264, 32152, 366, 11, 51364], "temperature": 0.0, "avg_logprob": -0.08474493026733398, "compression_ratio": 1.6023166023166022, "no_speech_prob": 0.00018522147729527205}, {"id": 972, "seek": 395854, "start": 3978.54, "end": 3982.54, "text": " so as to influence mathematically the output therefrom.", "tokens": [51364, 370, 382, 281, 6503, 44003, 264, 5598, 456, 20579, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08474493026733398, "compression_ratio": 1.6023166023166022, "no_speech_prob": 0.00018522147729527205}, {"id": 973, "seek": 398254, "start": 3983.54, "end": 3989.54, "text": " So that is all underneath the hood of what students now perceive as this adorable rubber duck,", "tokens": [50414, 407, 300, 307, 439, 7223, 264, 13376, 295, 437, 1731, 586, 20281, 382, 341, 18698, 11593, 12482, 11, 50714], "temperature": 0.0, "avg_logprob": -0.10844724485189608, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.0023966857697814703}, {"id": 974, "seek": 398254, "start": 3989.54, "end": 3995.54, "text": " but underneath it all is certainly a lot of domain knowledge and CS50 by nature", "tokens": [50714, 457, 7223, 309, 439, 307, 3297, 257, 688, 295, 9274, 3601, 293, 9460, 2803, 538, 3687, 51014], "temperature": 0.0, "avg_logprob": -0.10844724485189608, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.0023966857697814703}, {"id": 975, "seek": 398254, "start": 3995.54, "end": 3997.54, "text": " of being open courseware for the past many years.", "tokens": [51014, 295, 885, 1269, 1164, 3039, 337, 264, 1791, 867, 924, 13, 51114], "temperature": 0.0, "avg_logprob": -0.10844724485189608, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.0023966857697814703}, {"id": 976, "seek": 398254, "start": 3997.54, "end": 4001.54, "text": " CS50 is fortunate to actually be part of the model, as might be any other content", "tokens": [51114, 9460, 2803, 307, 14096, 281, 767, 312, 644, 295, 264, 2316, 11, 382, 1062, 312, 604, 661, 2701, 51314], "temperature": 0.0, "avg_logprob": -0.10844724485189608, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.0023966857697814703}, {"id": 977, "seek": 398254, "start": 4001.54, "end": 4005.54, "text": " that's freely available online, and so that certainly helps benefit the answers", "tokens": [51314, 300, 311, 16433, 2435, 2950, 11, 293, 370, 300, 3297, 3665, 5121, 264, 6338, 51514], "temperature": 0.0, "avg_logprob": -0.10844724485189608, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.0023966857697814703}, {"id": 978, "seek": 398254, "start": 4005.54, "end": 4008.54, "text": " when it comes to asking CS50 specific questions.", "tokens": [51514, 562, 309, 1487, 281, 3365, 9460, 2803, 2685, 1651, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10844724485189608, "compression_ratio": 1.6477272727272727, "no_speech_prob": 0.0023966857697814703}, {"id": 979, "seek": 400854, "start": 4008.54, "end": 4013.54, "text": " That said, it's not perfect, and you might have heard of what are currently called hallucinations,", "tokens": [50364, 663, 848, 11, 309, 311, 406, 2176, 11, 293, 291, 1062, 362, 2198, 295, 437, 366, 4362, 1219, 35212, 10325, 11, 50614], "temperature": 0.0, "avg_logprob": -0.1111192958695548, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.013635952956974506}, {"id": 980, "seek": 400854, "start": 4013.54, "end": 4019.54, "text": " where chatGPT and similar tools just make stuff up, and it sounds very confident,", "tokens": [50614, 689, 5081, 38, 47, 51, 293, 2531, 3873, 445, 652, 1507, 493, 11, 293, 309, 3263, 588, 6679, 11, 50914], "temperature": 0.0, "avg_logprob": -0.1111192958695548, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.013635952956974506}, {"id": 981, "seek": 400854, "start": 4019.54, "end": 4023.54, "text": " and you can sometimes call it on it, whereby you can say, no, that's not right,", "tokens": [50914, 293, 291, 393, 2171, 818, 309, 322, 309, 11, 36998, 291, 393, 584, 11, 572, 11, 300, 311, 406, 558, 11, 51114], "temperature": 0.0, "avg_logprob": -0.1111192958695548, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.013635952956974506}, {"id": 982, "seek": 400854, "start": 4023.54, "end": 4028.54, "text": " and it will playfully apologize and say, oh, I'm sorry, but it made up some statement", "tokens": [51114, 293, 309, 486, 862, 2277, 12328, 293, 584, 11, 1954, 11, 286, 478, 2597, 11, 457, 309, 1027, 493, 512, 5629, 51364], "temperature": 0.0, "avg_logprob": -0.1111192958695548, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.013635952956974506}, {"id": 983, "seek": 400854, "start": 4028.54, "end": 4033.54, "text": " because it was probabilistically something that could be said even if it's just not correct.", "tokens": [51364, 570, 309, 390, 31959, 20458, 746, 300, 727, 312, 848, 754, 498, 309, 311, 445, 406, 3006, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1111192958695548, "compression_ratio": 1.650375939849624, "no_speech_prob": 0.013635952956974506}, {"id": 984, "seek": 403354, "start": 4033.54, "end": 4038.54, "text": " Now, I'll allow me to propose that this kind of problem is going to get less and less frequent,", "tokens": [50364, 823, 11, 286, 603, 2089, 385, 281, 17421, 300, 341, 733, 295, 1154, 307, 516, 281, 483, 1570, 293, 1570, 18004, 11, 50614], "temperature": 0.0, "avg_logprob": -0.07285918086028297, "compression_ratio": 1.6317567567567568, "no_speech_prob": 0.06187058985233307}, {"id": 985, "seek": 403354, "start": 4038.54, "end": 4042.54, "text": " and so as the models evolve and our techniques evolve, this will be less of an issue,", "tokens": [50614, 293, 370, 382, 264, 5245, 16693, 293, 527, 7512, 16693, 11, 341, 486, 312, 1570, 295, 364, 2734, 11, 50814], "temperature": 0.0, "avg_logprob": -0.07285918086028297, "compression_ratio": 1.6317567567567568, "no_speech_prob": 0.06187058985233307}, {"id": 986, "seek": 403354, "start": 4042.54, "end": 4046.54, "text": " but I thought it would be fun to end on a note that a former colleague shared just the other day,", "tokens": [50814, 457, 286, 1194, 309, 576, 312, 1019, 281, 917, 322, 257, 3637, 300, 257, 5819, 13532, 5507, 445, 264, 661, 786, 11, 51014], "temperature": 0.0, "avg_logprob": -0.07285918086028297, "compression_ratio": 1.6317567567567568, "no_speech_prob": 0.06187058985233307}, {"id": 987, "seek": 403354, "start": 4046.54, "end": 4052.54, "text": " which was this old poem by Shel Silverstein, another something from our past childhood perhaps,", "tokens": [51014, 597, 390, 341, 1331, 13065, 538, 24415, 15861, 9089, 11, 1071, 746, 490, 527, 1791, 9278, 4317, 11, 51314], "temperature": 0.0, "avg_logprob": -0.07285918086028297, "compression_ratio": 1.6317567567567568, "no_speech_prob": 0.06187058985233307}, {"id": 988, "seek": 403354, "start": 4052.54, "end": 4056.54, "text": " and this was from 1981, a poem called Homework Machine,", "tokens": [51314, 293, 341, 390, 490, 33117, 11, 257, 13065, 1219, 8719, 1902, 22155, 11, 51514], "temperature": 0.0, "avg_logprob": -0.07285918086028297, "compression_ratio": 1.6317567567567568, "no_speech_prob": 0.06187058985233307}, {"id": 989, "seek": 403354, "start": 4056.54, "end": 4060.54, "text": " which is perhaps foretold where we are now in 2023.", "tokens": [51514, 597, 307, 4317, 2091, 1353, 348, 689, 321, 366, 586, 294, 44377, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07285918086028297, "compression_ratio": 1.6317567567567568, "no_speech_prob": 0.06187058985233307}, {"id": 990, "seek": 406054, "start": 4061.54, "end": 4066.54, "text": " The Homework Machine, oh, the Homework Machine, most perfect contraption that's ever been seen.", "tokens": [50414, 440, 8719, 1902, 22155, 11, 1954, 11, 264, 8719, 1902, 22155, 11, 881, 2176, 10742, 1695, 300, 311, 1562, 668, 1612, 13, 50664], "temperature": 0.0, "avg_logprob": -0.11370742545937593, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0004583094851113856}, {"id": 991, "seek": 406054, "start": 4066.54, "end": 4069.54, "text": " Just put in your homework, then drop in a dime, snap on the switch,", "tokens": [50664, 1449, 829, 294, 428, 14578, 11, 550, 3270, 294, 257, 36330, 11, 13650, 322, 264, 3679, 11, 50814], "temperature": 0.0, "avg_logprob": -0.11370742545937593, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0004583094851113856}, {"id": 992, "seek": 406054, "start": 4069.54, "end": 4075.54, "text": " and in ten seconds time, your homework comes out quick and clean as can be.", "tokens": [50814, 293, 294, 2064, 3949, 565, 11, 428, 14578, 1487, 484, 1702, 293, 2541, 382, 393, 312, 13, 51114], "temperature": 0.0, "avg_logprob": -0.11370742545937593, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0004583094851113856}, {"id": 993, "seek": 406054, "start": 4075.54, "end": 4080.54, "text": " Here it is, nine plus four, and the answer is three.", "tokens": [51114, 1692, 309, 307, 11, 4949, 1804, 1451, 11, 293, 264, 1867, 307, 1045, 13, 51364], "temperature": 0.0, "avg_logprob": -0.11370742545937593, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0004583094851113856}, {"id": 994, "seek": 406054, "start": 4080.54, "end": 4081.54, "text": " Three?", "tokens": [51364, 6244, 30, 51414], "temperature": 0.0, "avg_logprob": -0.11370742545937593, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0004583094851113856}, {"id": 995, "seek": 406054, "start": 4081.54, "end": 4082.54, "text": " Oh, me.", "tokens": [51414, 876, 11, 385, 13, 51464], "temperature": 0.0, "avg_logprob": -0.11370742545937593, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0004583094851113856}, {"id": 996, "seek": 406054, "start": 4082.54, "end": 4086.54, "text": " I guess it's not as perfect as I thought it would be.", "tokens": [51464, 286, 2041, 309, 311, 406, 382, 2176, 382, 286, 1194, 309, 576, 312, 13, 51664], "temperature": 0.0, "avg_logprob": -0.11370742545937593, "compression_ratio": 1.6261261261261262, "no_speech_prob": 0.0004583094851113856}, {"id": 997, "seek": 408654, "start": 4086.54, "end": 4089.54, "text": " So, quite foretelling, sure.", "tokens": [50364, 407, 11, 1596, 2091, 83, 11073, 11, 988, 13, 50514], "temperature": 0.0, "avg_logprob": -0.15377059072818397, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0037066114600747824}, {"id": 998, "seek": 408654, "start": 4092.54, "end": 4097.54, "text": " Quite foretelling indeed, though for all this and more,", "tokens": [50664, 20464, 2091, 83, 11073, 6451, 11, 1673, 337, 439, 341, 293, 544, 11, 50914], "temperature": 0.0, "avg_logprob": -0.15377059072818397, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0037066114600747824}, {"id": 999, "seek": 408654, "start": 4097.54, "end": 4102.54, "text": " the family members in the audience are welcome to take CS50 yourself online at cs50.edex.org.", "tokens": [50914, 264, 1605, 2679, 294, 264, 4034, 366, 2928, 281, 747, 9460, 2803, 1803, 2950, 412, 28277, 2803, 13, 292, 3121, 13, 4646, 13, 51164], "temperature": 0.0, "avg_logprob": -0.15377059072818397, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0037066114600747824}, {"id": 1000, "seek": 408654, "start": 4102.54, "end": 4109.54, "text": " For all of today and so much more, allow me to thank Brian, Rung Shin, Sophie, Andrew, Patrick, Charlie, CS50's whole team.", "tokens": [51164, 1171, 439, 295, 965, 293, 370, 709, 544, 11, 2089, 385, 281, 1309, 10765, 11, 497, 1063, 17347, 11, 29645, 11, 10110, 11, 13980, 11, 13754, 11, 9460, 2803, 311, 1379, 1469, 13, 51514], "temperature": 0.0, "avg_logprob": -0.15377059072818397, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0037066114600747824}, {"id": 1001, "seek": 408654, "start": 4109.54, "end": 4112.54, "text": " If you are a family member here headed to lunch with CS50's team,", "tokens": [51514, 759, 291, 366, 257, 1605, 4006, 510, 12798, 281, 6349, 365, 9460, 2803, 311, 1469, 11, 51664], "temperature": 0.0, "avg_logprob": -0.15377059072818397, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.0037066114600747824}, {"id": 1002, "seek": 411254, "start": 4112.54, "end": 4116.54, "text": " please look for Cameron holding a rubber duck above her head.", "tokens": [50364, 1767, 574, 337, 24962, 5061, 257, 11593, 12482, 3673, 720, 1378, 13, 50564], "temperature": 0.0, "avg_logprob": -0.06579093499617143, "compression_ratio": 1.1262135922330097, "no_speech_prob": 0.04334435239434242}, {"id": 1003, "seek": 411254, "start": 4116.54, "end": 4118.54, "text": " Thank you so much for joining us today.", "tokens": [50564, 1044, 291, 370, 709, 337, 5549, 505, 965, 13, 50664], "temperature": 0.0, "avg_logprob": -0.06579093499617143, "compression_ratio": 1.1262135922330097, "no_speech_prob": 0.04334435239434242}, {"id": 1004, "seek": 411254, "start": 4118.54, "end": 4120.54, "text": " This was CS50.", "tokens": [50664, 639, 390, 9460, 2803, 13, 50764], "temperature": 0.0, "avg_logprob": -0.06579093499617143, "compression_ratio": 1.1262135922330097, "no_speech_prob": 0.04334435239434242}, {"id": 1005, "seek": 414254, "start": 4142.54, "end": 4144.54, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50464], "temperature": 0.0, "avg_logprob": -0.8460795084635416, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.9863471388816833}], "language": "cy"}