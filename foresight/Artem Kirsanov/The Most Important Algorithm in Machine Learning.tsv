start	end	text
0	8240	What do nearly all machine learning systems have in common, from GPT and MeJourney to AlphaFold and various models of the brain?
9080	16720	Despite being designed to solve different problems, having completely different architectures, and being trained on different data,
17080	19720	there is something that unites all of them.
20400	26160	A single algorithm that runs under the hood of the training procedures in all of those cases,
26280	32600	this algorithm, called backpropagation, is the foundation of the entire field of machine learning,
33120	35560	although its details are often overlooked.
36840	44280	Surprisingly, what enables artificial networks to learn is also what makes them fundamentally different from the brain and
44880	49160	incompatible with biology. This video is the first in a two-part series.
49800	54840	Today, we will explore the concept of backpropagation in artificial systems and
55240	62360	develop an intuitive understanding of what it is, why it works, and how you could have developed it from scratch yourself.
63160	69920	In the next video, we will focus on synaptic plasticity, enabling learning in biological brains, and
70360	79880	discuss whether backpropagation is biologically relevant, and if not, what kind of algorithms the brain may be using instead. If you're interested, stay tuned.
84840	97000	Despite its transformative impact, it's hard to say who invented backpropagation in the first place, as certain concepts can be traced back to
97000	104520	light needs in 17th century. However, it is believed that the first modern formulation of the algorithm, still in use today,
104720	113320	was published by Seppo Linenma in his master's thesis in 1970, although he did not reference any neural networks explicitly.
114320	122000	Another significant milestone occurred in 1986, when David Rumelhardt, Joffrey Hinton, and Ronald Williams
122320	127360	published a paper titled Learning Representations by Backpropagating Errors.
127440	134120	They applied the backpropagation algorithm to multi-layer perceptrons, a type of a neural network, and
134680	137840	demonstrated for the first time that training with backpropagation
138520	148280	enables the network to successfully solve problems and develop meaningful representations at the hidden neuron level, capturing important regularities in the task.
149400	158720	As the field progressed, researchers scaled up these models significantly and introduced various architectures, but the fundamental principles of training
158880	166480	remained largely unchanged. To gain a comprehensive understanding of what exactly it means to train a network,
166520	172520	let's try to build the concept of backpropagation from the ground up. Consider the following problem.
173080	180160	Suppose you have collected a set of points x, y on the plane, and you want to describe their relationship.
180760	186480	To achieve this, you need to fit a curve y of x that best represents the data.
187480	192120	Since there are infinitely many possible functions, we need to make some assumptions.
192520	200200	For instance, let's assume we want to find a smooth approximation of the data using a polynomial of degree 5.
201040	209400	That means that the resulting curve we are looking for will be a combination of a constant term, a polynomial of degree 0, a
210120	216800	straight line, a parabola, and so on up to a power of 5, each weightened by specific coefficients.
217040	224400	In other words, the equation for the curve is as follows. Where each k is some arbitrary real number.
225000	232560	Our job then becomes finding the configuration of k0 through k5, which leads to the best fitting curve.
232840	238480	To make the problem totally unambiguous, we need to agree on what the best curve even means.
239040	246080	While you can just visually inspect the data points and estimate whether a given curve captures the pattern or not,
246320	251400	this approach is highly subjective and impractical when dealing with large data sets.
252000	258360	Instead, we need an objective measurement, a numerical value that quantifies the quality of a fit.
258960	265320	One popular method is to measure the square distance between data points and the fitted curve.
265720	273640	A high value suggests that the data points are significantly far from the curve, indicating a poor approximation.
274640	281320	Conversely, low values indicate a better fit as the curve closely aligns with the data points.
281800	287960	This measurement is commonly referred to as a loss and the objective is to minimize it.
288360	293800	Now notice that for a fixed data, this distance, the value of the loss,
294440	302280	depends only on the defining characteristics of the curve. In our case, the coefficients from k0 through k5.
303080	310760	This means that it is effectively a function of parameters, so people usually refer to it as a loss function.
311200	316520	It's important not to confuse two different functions we are implicitly dealing with here.
316520	323080	The first one is the function y of x, which has one input number and one output number and
323440	329160	defines the curve itself. It has this polynomial form given by k's.
329440	335120	There are infinitely many such functions and we would like to find the best one. To achieve this,
335120	342360	we introduce a loss function, which instead has six inputs, numbers k0 through k5.
342920	347280	And for each configuration, it constructs the corresponding curve y,
348120	357040	calculates the distance between observed data points and the curve, and outputs a single number, the particular value of the loss.
357760	363960	Our job then becomes finding the configuration of k's that yields a minimum loss or
364840	367840	minimizing the loss function with respect to the coefficients.
367920	375920	Then, plugging these optimal k's into the general equation for the curve will give us the best curve of describing the data.
376520	383120	All right, great, but how do we find this magic configuration of k's that minimizes the loss?
383560	385560	Well, we might need some help.
385800	392520	Let's build a machine called Curve Fitter 6000, designed to simplify manual calculations.
392520	399800	It is equipped with six adjustable knobs for k0 through k5, which we can freely turn.
400120	407120	To begin, we initialize the machine with our data points and then, for each setting of the knobs,
407120	410120	it will evaluate the curve y of x,
410600	416680	compute the distance from it to the data points and print out the value of the loss function.
417320	421640	Now, we can begin twisting the knobs in order to find the minimum loss.
422280	428840	For example, let's start with some initial setting and slightly notch knob number one to the right.
429240	435880	The resulting curve changed as well, and we can see that the value of the loss function slightly decreased.
436440	438840	Great, it means we are on the right track.
439320	443000	Let's turn knob number one in the same direction once again.
443000	446840	Uh-oh, this time the fit gets worse and the loss function increases.
447720	450760	Apparently, that last notch was a bit too much.
450760	455320	So, let's revert the knob to the previous position and try knob two.
455320	458680	And we can keep doing this iteratively many, many times,
459240	465400	nudging each individual knob one at a time to see whether the resulting curve is a better fit.
465560	473000	This is a so-called random perturbation method, since we are essentially wandering in the dark,
473000	478200	not knowing in advance how each adjustment will affect the loss function.
478200	481320	This would certainly work, but it's not very efficient.
481320	486280	Is there a way we can be more intelligent about the knob adjustments?
486280	490760	In the most general case, when the machine is a complete black box,
490760	494920	nothing better than a random perturbation is guaranteed to exist.
494920	501160	However, a great deal of computations, including what's carried out under the hood of our curvefitter,
501880	506120	have a special property to them, something called differentiability
506120	510600	that allows us to compute the optimal knob setting much more efficiently.
511160	515640	We will dive deeper into what differentiability means in just a minute.
515640	520360	But for now, let's quickly see the big picture overview of where we are going.
521160	528040	Our goal would be to upgrade the machine so that it would have a tiny screen next to each knob.
528600	534280	And for any configuration, those screens should say which direction you need to
534280	539240	nudge each knob in order to decrease the loss function and by how much.
540200	541400	Think about it for a second.
542200	548040	We are essentially asking the machine to predict the future and estimate the effect
548040	553880	of the knob adjustment on the loss function without actually performing that adjustment,
553880	558680	calculating the loss and then reverting the knob back like we did previously.
559240	563800	Wouldn't this glance into the future violate some sort of principle?
564600	569640	After all, we are jumping to the result of the computation without performing it.
570280	571720	Sounds like cheating, right?
572920	577960	Well, it turns out that this idea lies on a very simple mathematical foundation
577960	581320	so let's spend the next few minutes building it up from scratch.
583560	586840	All right, let's consider a simpler case first.
586840	589800	Where we freeze five out of six knobs.
589800	594680	For example, suppose someone tells you that the rest of them are already in the optimal position.
595240	599960	So all you need to do is to find the best value for one remaining knob.
599960	605560	Essentially, the machine now has only one variable parameter k1 that we can tweak.
606120	609480	And so the loss function is also a simpler function
609480	615480	which accepts one number, the knob setting, and outputs another number, the loss value.
615480	621960	As a function of one variable, it can be conveniently visualized as a graph in a two-dimensional plane
621960	625720	which captures the relationship between the input and the output.
625720	632200	For example, it may have this shape right here and our goal is to find this value of k1
632200	635080	which corresponds to the minimum of the loss function.
635080	638680	But we don't have access to the true underlying shape.
638680	642120	All we can do is to set the knob at a chosen position
642680	646360	and kind of query the machine for the value of the loss.
646360	652280	In other words, we can only sample individual points along the function we're trying to minimize.
652840	658440	And we are essentially blind to how the function behaves in between the known points
658440	660040	before we sample them.
660040	663560	But suppose we would like to know something more about the function.
663560	665640	Not just each value at each point.
666520	670520	For example, whether at this point the function is going up or down.
671160	674760	This information will ultimately guide our adjustments.
675320	680040	Because if you know that the function is going down as you increase the input,
680040	683080	turning the knob to the right is a safe bet,
683080	687000	since you are guaranteed to decrease the loss with this manipulation.
687560	691640	Let's put this notion of going up or down around a point
691640	693880	on a stronger mathematical ground.
693880	698360	Suppose we have just sampled the point x0, y0 on this graph.
698360	703640	What we can do is increase the input by a small amount delta x.
703640	708360	This new adjusted input will result in a new value of y,
708360	712040	which will differ from the old value by some delta y.
712600	716440	This delta depends on the magnitude of our adjustment.
716440	721080	For example, if we take a step delta x, which is 10 times smaller,
721080	725240	delta y will also be approximately 10 times as small.
726680	731960	This is why it makes sense to take the ratio delta y over delta x,
731960	736280	the amount of change in the output per unit change in the input.
736920	741640	Graphically, this ratio corresponds to a slope of a straight line.
741640	746360	Going through the points x0, y0 and x0 plus delta x,
746440	747960	y0 plus delta y.
748920	752680	Notice that as we take smaller and smaller steps,
752680	757400	this straight line will more and more accurately align with the graph
757400	760200	in the neighborhood of the point x0, y0.
760920	767320	Let's take a limit of this ratio as delta x goes to infinitely small values.
767320	771800	Then this limiting case value, which this ratio converges to
771800	777640	for infinitesimally small delta x's, is what is called the derivative oa function,
778200	781320	and it is denoted by dy over dx.
781960	785960	Visually, the derivative oa function at some point
785960	789880	is the slope of the line that is tangent to the graph,
789880	793400	and thus corresponds to the instantaneous rate of change,
793400	797160	or steepness of that function around that point.
797160	801640	But different points along the graph might have different steepness values,
801960	806520	so the derivative of the entire function is not a single number.
806520	812520	In fact, the derivative dy by dx is itself a function of x
812520	820200	that takes an arbitrary value of x and outputs the local steepness of y of x at that point.
820200	825240	This definition assigns to every function its derivative alter ego.
825240	829160	Another function operating on the same input domain,
829160	834120	which carries information about the steepness of the original function.
834120	835880	There is a bit of a subtlety.
835880	839000	Strictly speaking, the derivative may not exist
839000	842280	if the function doesn't have a steepness around some point.
842920	846680	For example, if it has sharp corners or discontinuities.
847720	852360	However, for the remainder of the video, we are going to assume that all functions we are
852360	856600	dealing with are smooth, so that the derivative always exists.
857560	861080	This is a reasonable claim, because we can control
861080	864520	what sort of functions go into our models when we build them.
865080	869960	And people usually restrict everything to smooth or differentiable functions
869960	872120	to make all the math work out nicely.
872680	873800	All right, great.
873800	877720	Now, along with the underlying loss as a function of k1,
877720	882040	which is hidden from us, we can also reason about its derivative.
882680	886120	Another function of k1, which we also don't know,
886120	889800	that is equal to the steepness of the loss function at that point.
891160	895400	Let's suppose that similarly to how we can query the loss function
895400	899000	by running our machine and obtaining individual samples.
899720	904040	There is a mechanism for us to sample the derivative function as well.
905400	911880	So, for every input value of k1, the machine will output the value of the loss
911880	915640	and the local steepness of the loss function around that point.
916280	920600	Notice that this derivative information is exactly the sort of
920600	925080	look into the future we were looking for to make smarter knob adjustments.
925720	930600	For example, let's use it to efficiently find the optimal value of k1.
931400	933000	What we can do is the following.
933880	936600	First, start at some random position.
937560	940120	Ask the machine for the value of the loss
940120	943320	and the derivative of the loss function at that position.
944440	948600	Take a tiny step in the direction opposite of the derivative.
949240	953240	If the derivative is negative, it means that the function is going down.
953960	956520	And so, if we want to arrive at the minimum,
956520	960440	we need to move in the direction of increasing value of k1.
961080	966280	Repeat this procedure until you reach the point where the derivative is zero,
966280	970600	which essentially corresponds to the minimum where the tangent line is flat.
971240	975000	Essentially, each adjustment in such a guided fashion
975000	981080	works kind of like a ball rolling down the hill along the graph until it reaches a valley.
983480	987560	Although in the beginning we froze five out of six knobs for simplicity,
988120	991880	this process is easily carried out to higher dimensions.
992840	998600	For example, suppose now we are free to tweak two different knobs, k1 and k2.
999640	1005800	The loss would become a function of two variables, which can be visualized as a surface.
1006680	1008680	But what about the derivative?
1008680	1012920	Recall that by definition, the derivative at each point
1012920	1017800	tells us how the output changes per unit change of the input.
1017800	1019880	But now we have two different inputs.
1020440	1023720	Should we nudge only k1, k2 or both?
1025640	1029800	Essentially, our function will have two different derivatives
1030440	1037000	that are usually called partial derivatives because of this ambiguity which input to nudge.
1037000	1041400	Namely, when we have two knobs, the derivative of the loss function
1041400	1045080	with respect to parameter k1 is written like this.
1045320	1053480	It is how much the output changes per unit change in k1 if you hold k2 constant.
1054120	1059320	And conversely, this expression tells you the rate of change of the output
1059320	1063480	if you hold k1 constant and slightly nudge k2.
1064040	1070760	Geometrically, you can imagine slicing the surface with planes parallel to the axes,
1070760	1073960	intersecting at the point of interest k1 k2.
1074600	1080440	So that each of the two cross sections is like a one-dimensional graph of the loss
1080440	1084680	as a function of one variable while the other one is kept constant.
1085320	1089240	Then the slope of a tangent line at each cross section
1089240	1093640	will give you a corresponding partial derivative of the loss at that point.
1094760	1098520	While thinking about partial derivatives as two separate surfaces,
1099080	1102360	one for each variable, is a perfectly valid way.
1103080	1109880	People usually plug the two different values into a vector called a gradient vector.
1109880	1116120	Essentially, this is a mapping from two input values to another two numbers
1116120	1122680	where the first signifies how much the output changes per tiny change in the first input.
1123400	1125400	And similarly, for the second input.
1126520	1130680	Geometrically, this vector points in the direction of steepest ascent.
1131480	1136360	So if you want to minimize a function, like in the case for our loss,
1137080	1141480	we need to take steps in the direction opposite to this gradient.
1142840	1149960	This iterative procedure of nudging the parameters in the direction opposite of the gradient vector
1149960	1153720	is called gradient descent, which you have probably heard of.
1153720	1158520	This is analogous to a ball rolling down the hill for the two-dimensional case.
1158520	1163640	And the partial derivatives essentially tell you which direction is downhill.
1164440	1169080	Going beyond two dimensions is impossible to visualize directly,
1169080	1171480	but the math stays exactly the same.
1172440	1177000	For instance, if we are now free to tweak all the six knobs,
1177000	1181160	the loss function is a hyper surface in six dimensions.
1181800	1185800	And the gradient vector now has six numbers packed into it.
1186360	1190280	But it still points in the direction of steepest ascent.
1190280	1195160	So if we iteratively take small steps in the direction opposite to it,
1195880	1200440	we are going to roll the ball down the hill in six dimensions
1200440	1203640	and eventually reach the minimum of the loss function.
1204520	1206040	Great, let's back up a bit.
1206760	1211160	Remember how we were looking for ways to add screens next to each knob
1211160	1214280	that would give us the direction of optimal adjustment?
1215240	1220600	Well, it is essentially nothing more but the components of the gradient vector.
1220600	1225160	If at a particular configuration, the partial derivative of the loss
1225160	1232520	with respect to k1 is positive, it means that increasing k1 will lead to increased loss.
1233080	1237400	So we need to decrease the value of the knob by turning it to the left.
1238040	1240680	And similarly for all other parameters.
1241640	1246760	This is how the derivatives serve as these windows into the future
1246760	1251720	by providing us with information about local behavior of the function.
1251720	1255160	And once we have a way of accessing the derivative,
1255160	1261160	we can perform gradient descent and efficiently find the minimum of the loss function,
1261160	1263720	thus solving the optimization problem.
1264280	1267160	However, there is an elephant in a room.
1267160	1271960	So far we have implicitly assumed the derivative information is given to us.
1272520	1276200	Or that we can sample the derivative at a given point.
1276200	1279560	Similarly to how we sample the loss function itself
1279560	1281880	by running the calculation of the machine.
1281880	1284600	But how do you actually find the derivative?
1284600	1289320	As we will see further, this is the main purpose of the back propagation algorithm.
1290120	1295560	Essentially, the way we find derivatives of arbitrarily complex functions is the following.
1296200	1299960	First, there are a handful of building blocks to begin with.
1299960	1303960	Simple functions, derivatives of which are known from calculus.
1304680	1308600	These are the kind of derivative formulas you often memorize in college.
1309400	1315880	For example, if the function is linear, it's pretty clear that its derivative will be a constant,
1315880	1321640	equal to the slope of that line everywhere, which coincides with its own tangent line.
1322600	1328120	A parabola x squared becomes more steep as you increase x.
1328120	1330680	And its derivative is actually 2x.
1331560	1336680	In fact, there is a more general formula for the derivative of x to the power of n.
1337480	1342760	Similarly, derivatives of the exponent and logarithm can be written down explicitly.
1343640	1348200	But these are just individual examples of simple, well-known functions.
1348840	1355960	In order to compute arbitrary derivatives, we need a way to combine such atomic building blocks
1355960	1359480	together. There are a few rules how to do it.
1360280	1366440	For instance, the derivative of a sum of two functions is the sum of the derivatives.
1366440	1370680	There is also a formula for the derivative of a product of two functions.
1371560	1377320	This gives you a way to compute things like the derivative of 3x squared minus equal to the power
1377320	1384600	of x. But to complete the picture and to be able to find derivatives of almost everything,
1384600	1391800	we need one other rule called the chain rule, which powers the entire field of machine learning.
1392520	1397320	It tells you how to compute the derivative of a combination of two functions,
1397320	1402680	when one of them is an input to another. Here is a way to reason about this.
1403640	1409800	Suppose you take one of those simpler machines, which receives a single input x that you can
1409800	1418600	vary with an ALP, and spits out an output, j of x. Now, you take a second machine of this kind,
1418600	1426600	which performs a different function, f of x. What would happen if you connect them in sequence,
1426600	1432520	so that the output of the first machine is fed into the second one as an input?
1433480	1440680	Notice that such a construction can be thought of as a single function, which also receives one
1440680	1447240	input number and gives an output by computing a more complicated function, which is a composition
1447240	1454280	of the two simpler functions. In fact, if you put a black box around it to conceal the fact
1454280	1461160	that there are actually two machines operating sequentially, you can treat it as a single machine
1461160	1468040	and ask, well, if I notch the input on one end, how will it affect the output on another end?
1468760	1472600	In other words, what is the derivative of the resulting function?
1473880	1480520	Suppose we know the individual derivatives of the two machines, f and j. If the knob is set at
1480520	1489560	some value x, local steepness of the first function is evaluated at x. However, the number that is
1489560	1495720	fed into the second machine is not x, because it was already processed by the first function.
1496760	1503480	So, the thing that is being plugged into the second function is j of x. And so, the local rate of
1503480	1512360	change of the second machine is thus the derivative of f evaluated at the point j of x. Now, imagine
1512360	1519640	you notch the knob x by a tiny amount, delta. That input notch, when it comes out of the first machine,
1519640	1526120	will be multiplied by the derivative of j, since the derivative is the rate of change in the output
1526120	1532840	per unit change of the input. So, after the first function, the output will increase by delta,
1532840	1540360	multiplied by the derivative of j. This expression is essentially a tiny notch in the input to the
1540360	1547640	second machine, whose derivative at that point is given by this expression. This means that for
1547640	1556360	each delta increase in the input, we bump the output by this much. Hence, the derivative when
1556360	1564360	you divide that by delta will look like this. You can think about it as a set of three interconnected
1564360	1571800	cog wheels, where the first one represents the input knob x. And the other two wheels are functions,
1571800	1578600	j of x and f of j of x, respectively. When you notch the first wheel, it induces a
1578600	1584360	notch in the middle wheel and the amplitude of that change is given by the derivative of j,
1585080	1590840	which in turn causes the third wheel to rotate, and the amplitude of that resulting
1590840	1598680	notch is given by changing the derivatives together. Alright, great. Now we have a straightforward way
1598680	1605320	of obtaining a derivative of any arbitrarily complex function, as long as it can be decomposed
1605320	1611880	into building blocks. Simple functions with explicit derivative formulas, such as summations,
1611880	1619080	multiplications, exponents, logarithms, etc. But how can it be used to find the best curve
1619080	1625320	using our curve fitter? The big picture we are aiming for is the following. For each of our
1625320	1632040	parameter knobs, we will write down its effect on the loss in terms of simple, easily differentiable
1632040	1639720	operations. Once we have that sequence of building blocks, no matter how long, we should be able to
1639720	1645960	sequentially apply the chain rule to each of them in order to find the value of the derivative
1645960	1652520	of the loss function with respect to each of the input knobs and perform iterative gradient descent
1652520	1659720	to minimize the loss. Let's see an example of this. First, we are going to create a knob
1659720	1666120	for each number the loss function can possibly depend on. This obviously includes the parameters,
1666680	1673240	but there is also the data itself, coordinates of points to which we are fitting the curve
1673240	1680120	in the first place. Now, during optimization, the data points are set in stone, so changing them
1680120	1687480	in order to obtain a lower loss would make no sense. However, for conceptual purposes,
1687480	1694360	we can think about these values as fixed knobs set in one position so that we cannot nudge them.
1695320	1701880	Once we have all the existing numbers being fed into the machine, we can start to break down the
1701880	1709640	loss calculation. Remember, by definition, it is the sum of squared vertical distances
1709640	1717240	from each point to the curve parameterized by k's. So, for instance, let's take the first
1717320	1727560	data point, x1, y1, multiply the x coordinate by k1, add that to the squared value of x1 multiplied
1727560	1736440	by k2, and so on for other k's, including the constant term k0. This sum of weight and powers of
1736440	1745960	x1 is the value of y predicted by the current curve, f of x1. Let's call it y1 hat. Next,
1745960	1752440	we need to take the squared difference between the actual value and the predicted value. This is
1752440	1758600	how much the first data point contributes to the resulting value of the loss function.
1759800	1767480	Repeating the same procedure for all remaining data points and summing up the resulting squared
1767480	1775800	distances gives us the overall total loss that we are trying to minimize. The computation we just
1775800	1782920	performed, finding the value of the loss for a given configuration of parameter and data knobs,
1783560	1791400	is known as the forward step. The entire sequence of calculations can be visualized
1791400	1798920	as this kind of computational graph, where each node is some simple operation like addition or
1798920	1807400	multiplication. Forward step then corresponds to computations flowing from left to right.
1807400	1814040	But to perform optimization, we also need information about gradients, how each node
1814040	1821880	influences the loss. Now we are going to do what's known as the backward step, and unroll the sequence
1821880	1829240	of calculations in reverse order to find derivatives. What makes the backward step possible
1829240	1835400	is the fact that every node in our compute graph is an easily differentiable operation.
1835400	1842920	Think of individual nodes as these tiny machines which simply add, multiply or take powers. We
1842920	1850040	know their derivatives, and because their outputs are connected sequentially, we can apply the chain
1850040	1858840	rule. This means that for each node we can find its gradient, the partial derivative of the output
1858840	1867320	loss with respect to that node. Let's see how it can be done. Consider a region of the compute
1867320	1875160	graph, where two number nodes A and B are being fed into a machine that performs addition, and its
1875160	1882040	result A plus B is further processed by the system to compute the overall output L.
1883240	1889640	Suppose we already computed the gradient of A plus B earlier, so that we know how
1889640	1897480	nudging the sum will affect the output. The question is, what are individual gradients of A and B?
1897800	1906600	Well, intuitively, if you nudge A by sum amount, A plus B will be nudged by this same amount,
1906600	1913000	so the gradient or the partial derivative of the loss with respect to A is the same as the gradient
1913000	1920440	of the sum, and similarly for B. This can be seen more formally by writing down the chain rule
1920440	1927240	and noticing that the derivative of A plus B with respect to A is just one. In other words,
1927320	1933720	when you encounter this situation in the compute graph, then the gradient of the sum
1933720	1940200	just simply propagates into the gradients of the nodes that plug into the sum machine.
1940200	1946040	Another possible scenario is when A and B are multiplied. Just like before,
1946040	1952280	suppose we know the gradient of their product because it was computed before. In this case,
1952280	1959320	individual nudge to A will be scaled by a factor of B, so the product will be nudged
1959320	1966600	B times as much, which propagates into the output. So, whatever the derivative of the
1966600	1973720	output with respect to the product of A B is, the output derivative with respect to A
1973720	1980440	will get scaled by a factor of B, and vice versa for the gradient of B. Once again,
1980440	1987800	it can be seen more formally by examining the chain rule. In other words, the multiplication node
1987800	1994920	in the compute graph distributes the downstream gradient across incoming nodes by multiplying
1994920	2001960	it crossways by their values. Similar rules can be easily formulated for other building block
2001960	2008360	calculations, such as raising a number to a power or taking the logarithm. Finally,
2008360	2013960	when a single node takes part in multiple branches of the compute graph, gradients from the
2013960	2019640	corresponding branches are simply added together. Indeed, suppose you have the following structure
2019640	2026280	in the graph, where the C-minode A plugs into two different operations that contribute to
2026280	2033560	the overall loss. Then, if you nudge A by delta, the output will be simultaneously nudged by this
2033560	2040520	derivative from the first branch and this derivative from the second branch. So, the overall effect of
2040520	2047320	nudging A will be the sum of the two gradients. Alright, great. Now that we have constructed
2047320	2054360	a computational graph and established how to process individual chunks of it, we can just
2054360	2060520	sequentially apply those rules starting from the output and working our way backwards.
2061480	2066840	For instance, the rightmost node in the graph is the resulting value of the loss function.
2066840	2073240	How does the incremental change in that node affect the output? Well, it is the output,
2073240	2079960	so its gradient is by definition equal to 1. Next, the loss function is the sum of many delta
2079960	2086200	y's squared. We know what to do with the summation node. It just copies whatever the gradient value
2086200	2092840	is to the right of it into all incoming nodes. Consequently, the gradients of all delta y's
2092840	2100600	squared will also be equal to 1. Each of those nodes is the squared value of the corresponding delta y
2100600	2105880	and we know how to differentiate this squaring operation. The derivative of the loss function
2105880	2112360	with respect to delta y1 will be 2 times the delta y1, which is just the number we found
2112360	2118040	during the forward calculation. And we can keep doing this propagation of sequential derivative
2118040	2124280	calculation backwards along our compute graph until we reach the leftmost nodes,
2124280	2130360	which are the data and parameter knobs. The derivatives of the loss with respect to the input
2130360	2136920	data don't really matter, but the derivatives with respect to the parameters is exactly what we want.
2136920	2143400	Once these parameter gradients are found, we can perform one iteration of gradient descent.
2143400	2148600	Namely, we are going to slightly tweak the knobs in the directions opposite to the gradient.
2149160	2155000	The exact magnitude of each adjustment being the negative product of the gradient
2155000	2162120	and some small number called the learning rate, for example, 0.01. Note that after the adjustment
2162120	2167560	is performed, the configuration of the machine and the resulting loss are different.
2168280	2172680	And so the old gradient values we found no longer hold.
2173720	2180360	So we need to run the forward and backward calculations once again to obtain updated
2180360	2188040	gradients and the new decreased loss. Performing this loop of forward pass, backward pass,
2188040	2193640	notch, repeat is the essence of training every modern machine learning system.
2194200	2199640	And exactly the same algorithm is used today in even the most complicated models.
2199640	2204600	As long as the problem you are trying to solve with a given model architecture
2204600	2210760	can be decomposed into individual operations that are differentiable, you can sequentially
2210760	2216680	apply the chain rule many times to arrive at the optimal setting of the parameters.
2216680	2221880	For instance, a feed-forward neural network is essentially a bunch of multiplications and
2221880	2227560	summations with a few non-linear activation functions sprinkled between the layers.
2227560	2233800	Each of those atomic computations is differentiable, so you can construct the compute graph
2233800	2241080	and run the backward pass on it to find how each parameter, like connection weights between neurons,
2241080	2246440	influence the loss function. And because neural networks, given enough neurons,
2246440	2253080	can in theory approximate any function imaginable, we can create a large enough sequence of these
2253080	2259000	building block mathematical machines to solve problems such as classifying images and even
2259000	2264200	generating new text. This seems like a very elegant and efficient solution.
2264200	2270280	After all, if you want to solve the optimization problem, derivatives tell you exactly which
2270280	2275800	adjustments are necessary. But how similar is this to what the brain actually does?
2276520	2283000	When we learn to walk, speak and read, is the brain also minimizing some sort of loss function?
2283000	2288040	Does it calculate derivatives? Or could it be doing something totally different?
2288680	2293320	In the next video, we are going to dive into the world of synaptic plasticity
2293320	2296120	and talk about how biological neural networks learn.
2297080	2299880	In keeping with the topic of biological learning,
2299880	2304760	I'd like to take a moment to give a shout out to Shortform, a longtime partner of this channel.
2305720	2309720	Shortform is a platform which lets you take your reading to the next level.
2310440	2317080	They offer book guides, which are supercharged book summaries. Not only do you get the condensed
2317080	2323720	version of all the key points, but they are also supplemented by ideas from related sources,
2323800	2329160	such as other books and research papers. I really love this feature because it allows
2329160	2333560	you to get the big picture overview and promotes the interlinking of ideas.
2334120	2339240	The existing library contains books from a variety of genres, including science,
2339240	2345000	education and technology, and new books are being added every week. Personally, I found
2345000	2349880	Shortform to be really valuable when it comes to choosing books to read, as well as taking
2349880	2355560	efficient notes. Don't hesitate to give it a try by following the link down in the description
2355560	2360600	to get 5 days of unlimited access and 20% off the annual membership.
2361240	2365320	If you enjoyed this video, press the like button, share it with your friends and colleagues,
2365320	2370280	and subscribe to the channel if you haven't already. Stay tuned for more interesting topics
2370280	2386200	coming up. Goodbye and thank you for the interest in the brain.
2400280	2401660	you
