{"text": " Recently, this amazing AI called GPT chat came out that will generate text based on your prompts. And the whole world is still kind of getting used to it because it's just so powerful. The neat thing is it can write Python scripts for Blender as well. The workflow is very different, so I've seen a lot of people experimenting, but today I will show you three examples that are actually useful for speeding up your routine and improving your art in Blender. If you find this interesting, please consider leaving a like on this video and let me know what you think of GPT chat. And you can also subscribe to stay updated on future tutorials. So to start, you're going to go to this website, chat.openair.com, and you need to make an account to use this chatbot. Once you log in, you get this screen where you can type your prompts over here. And it also gives you some examples, explains about the capabilities and the limitations. I'm also going to explain about the limitations and troubleshooting later in this video. But we're going to start with the first example, and that is scattering objects around your scene. We're going to create our first prompt for the AI. And I'm going to ask it specifically to write a Python script for Blender. And to just start out simply, let's create 10 cubes and scatter them around our scene with a maximum distance to the world origin of 10. Once you've tied your prompt, you can simply hit enter and it will output something. This usually takes a few seconds, but you can see it's already generating a text and here it's generating a Python script. So it's now done with the script and we can actually see that it creates a new scene and sets the world origin and everything. And it will also create an explanation of your script right here. So let's test it out by going into Blender and opening the text editor over here. And we will create a new text file. And we're just going to paste the code that the AI just gave us. We're going to go to text and run the script. You can also press alt P and see what happens. Here we go. Okay, so we have I think 10 cubes. Yes, there are 10 over here and they are scattered around the scene. This one is actually still at the world origin. So I wonder if this is the original cube or yeah, it must be because it can't just be randomly at the starting point. We can also scatter the objects in a non-random way. Going back to GPT chat, I'm going to ask it to make a circular array of circles. Again, we're going to ask it to write a Python script in Blender to do this. Also, you want to be specific. So I'm going to ask for 16 individual circles. And the main circle that it's going to be scattered along, I'm going to specify the radius. So let's see what it comes up with now. We can actually see that it's adding a primitive curve. So it understands that. So our AI is done writing the code. Again, it gives a full explanation also at every line of the code. It gives a small explanation, which is very useful. We're just going to copy the code and paste it into our text editor. Let's run our script and see what happens. All right, so it's pretty hard to see, but there is definitely a circular array. Yeah, if we select all of them, wow, this is actually pretty perfect because they align here. This actually turned out better than I even imagined. I just expected any size whatsoever, but it made it the size so that they perfectly line up with each other. To be honest, I wouldn't even know how to do this in Blender, let alone this quickly. Going on to the next example, this might be the most useful use case for GPT chat. And that is bulk actions. So let's say we've imported this character, but we can see every object has a different material, even though some objects have the same color. Where there are only four colors in this character, but there are a bunch of materials. This can happen sometimes when you switch objects between programs, or especially when you import a bunch of vector graphics. This is a prime example where GPT chat can save us hours of time. Going back to our GPT chat window, I'm going to ask the AI to look through all the materials and see which materials have the same hex color value in their base color. If it has the same hex value, it means it's the same color. And then I'll ask it to combine those duplicate materials into one combined material and then apply that material to the objects. All right, the script is done. And it says the script will iterate over every material and get the base color of the material and then convert it to a hex string and create a dictionary out of it. Next time it finds a material, it checks if it's already in the dictionary. And if yes, it will add it to the list of materials with the same color. And if it's not, it will create a new entry in the dictionary with a different color. Then the script will iterate over all those colors and see if there are colors with multiple materials. If yes, it will create a combined material, so a new material, and then apply that to the objects. So let's go back to our text editor and just paste our script here and run this and see what it does. Okay, so we can see that it tries to delete all the materials at the very end and something is going wrong. Function material is expected a material type, not list. I guess it's going wrong because it's trying to make a list called materials, but maybe that term is already taken somewhere else. So we're just going to get rid of that last sentence. Nevertheless, if we now go to our object, we can see that it has the correctly combined material. So all these objects with the same color now have a combined material. So we don't have to go through every object and select our material right here because that saves a lot of time. So for the last portion of this video, I want to get creative. I want to ask the AI to actually generate a mesh for us. One thing that's pretty complicated to generate normally in Blender is a fractal. So we're going to create a Mandelbrot set. And once again, it's as simple as creating a specific prompt for GPT chat. I've been experimenting with creating fractals using GPT chat. And it's a hit or miss situation. Sometimes it works, sometimes it doesn't. I haven't managed to create an actual 3D fractal yet, but I have managed to create this 2D fractal. Trying to get it to actually create a mesh itself, it seems to have a lot of trouble with that. You'd have to try this in the future though, because this chatbot is constantly being updated. So what I'm going to do is I'm going to create a fractal using a point cloud. It's similar to the method from bad normals and his whole fractal machine add-on. So it's not like there's no other way to create them, but it's just really cool to see how simple it is. So I'm once again asking it to create a Python script for Blender. I'm going to ask it to make a Mandobrot set out of points that is one layer thick. I'm also asking it to convert points to vertices so we can instantly see what the shape looks like. GPT chat needs a little more time than usual to create this, but we can see that it is now creating something. It's very interesting because it's using a completely different method than before. But yeah, it's still working with complex numbers and doing all sorts of math that I am not qualified enough to understand. So it's now creating the point cloud Mandobrot set. It's even naming everything. It's so cool. Okay, so our script seems to be done. Let's copy it and see if it works. It's the moment of truth. Let's see. Okay, so I don't know what this is, but it doesn't really resemble anything close to a Mandobrot set. It just looks like an array of random points, but that's no problem. We're just going to ask GPT chat again. I also like to specify what happened because maybe the AI will see what went wrong. So let's try to specify it as clearly as possible. Currently, I can't get it to actually create the script that I got yesterday. I'm just going to show you what it came up with yesterday. Unfortunately, I have no footage of me giving the prompt and getting back that response. So you'd have to trust me on the fact that I don't know anything about coding and that the AI just made it for me. So running the script actually takes quite a long time and it will create this Mandobrot pillar. It's actually a 3D shape, but it's just a bunch of 2D Mandobrot slices stacked on top of each other. You could definitely change the script so it outputs one slice, but I just deleted every slice but one. We're going to quickly hop into geometry notes and actually make something cool out of this. So a quick way to make this look interesting is just instancing cubes on every point. We're going to grab an instance on points node and just add them right here, and then we're going to create a cube as well. And set the size to 0.01 and let's just connect this to our mesh. And yeah, we have this pretty nice looking grid. Obviously, this is just a static mesh. It doesn't grow or anything. If you want to change the parameters, you'd have to generate a new one. Over here, I have this Mandobob as well. We can quickly give it the geometry nodes group. Yeah, there we go. Of course, we can also use these points to create a mesh. Let's again create a new geometry nodes group and let's add a mesh to points node because these are actually vertices and not points. Next, we're going to add a points to volume node. And let's just play around with these settings a little bit. The radius is way too high, so let's put it at 0.1 is too small, maybe 0.2. We can still barely see it, so let's just create a volume to mesh node next. If we want a more detailed shape, let's up the voxel threshold to 500. There we go. That's already looking more like a fractal. And we can also play with the threshold of the volume to mesh node a little bit if we want to. So yeah, we have a very quick Mandobob set. I suggest just try asking a lot of questions to the AI. Ask them in different ways and it will give you some surprising stuff. Actually, one thing that I can't even explain is this thing. It was a similar kind of point cloud setup and then change it into a mesh. But what is even going on here? We can maybe see this inflection point right here, but I couldn't tell you how this shape works or what it looks like. If you recognize this shape, if it has a name, let me know in the comments below because it just looks so asymmetrical and abstract. And yeah, the AI just generated this. It generated a point cloud and then I just did the same as we did before with the Mandobob set. Just converted it to a mesh and yeah, pretty neat. Couldn't have made this myself for sure. So yeah, that concludes our introduction to GPT Chat. It has some very interesting use cases. Let me know in the comments what is the craziest response you got from GPT Chat. I would love to know. Without further ado, I'll catch you next time. Leave a like on this video if you find it interesting and subscribe for future tutorials. There are building something here. It's been a hell to actually make this video, but I'll see you next time. Bye bye.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.92, "text": " Recently, this amazing AI called GPT chat came out that will generate text based on your prompts.", "tokens": [50364, 20072, 11, 341, 2243, 7318, 1219, 26039, 51, 5081, 1361, 484, 300, 486, 8460, 2487, 2361, 322, 428, 41095, 13, 50660], "temperature": 0.0, "avg_logprob": -0.11867141723632812, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.01881358213722706}, {"id": 1, "seek": 0, "start": 5.92, "end": 10.16, "text": " And the whole world is still kind of getting used to it because it's just so powerful.", "tokens": [50660, 400, 264, 1379, 1002, 307, 920, 733, 295, 1242, 1143, 281, 309, 570, 309, 311, 445, 370, 4005, 13, 50872], "temperature": 0.0, "avg_logprob": -0.11867141723632812, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.01881358213722706}, {"id": 2, "seek": 0, "start": 10.16, "end": 13.76, "text": " The neat thing is it can write Python scripts for Blender as well.", "tokens": [50872, 440, 10654, 551, 307, 309, 393, 2464, 15329, 23294, 337, 2177, 3216, 382, 731, 13, 51052], "temperature": 0.0, "avg_logprob": -0.11867141723632812, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.01881358213722706}, {"id": 3, "seek": 0, "start": 13.76, "end": 17.52, "text": " The workflow is very different, so I've seen a lot of people experimenting,", "tokens": [51052, 440, 20993, 307, 588, 819, 11, 370, 286, 600, 1612, 257, 688, 295, 561, 29070, 11, 51240], "temperature": 0.0, "avg_logprob": -0.11867141723632812, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.01881358213722706}, {"id": 4, "seek": 0, "start": 17.52, "end": 22.96, "text": " but today I will show you three examples that are actually useful for speeding up your routine", "tokens": [51240, 457, 965, 286, 486, 855, 291, 1045, 5110, 300, 366, 767, 4420, 337, 35593, 493, 428, 9927, 51512], "temperature": 0.0, "avg_logprob": -0.11867141723632812, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.01881358213722706}, {"id": 5, "seek": 0, "start": 22.96, "end": 27.76, "text": " and improving your art in Blender. If you find this interesting, please consider leaving a", "tokens": [51512, 293, 11470, 428, 1523, 294, 2177, 3216, 13, 759, 291, 915, 341, 1880, 11, 1767, 1949, 5012, 257, 51752], "temperature": 0.0, "avg_logprob": -0.11867141723632812, "compression_ratio": 1.6132075471698113, "no_speech_prob": 0.01881358213722706}, {"id": 6, "seek": 2776, "start": 27.76, "end": 31.12, "text": " like on this video and let me know what you think of GPT chat.", "tokens": [50364, 411, 322, 341, 960, 293, 718, 385, 458, 437, 291, 519, 295, 26039, 51, 5081, 13, 50532], "temperature": 0.0, "avg_logprob": -0.11464232951402664, "compression_ratio": 1.7534722222222223, "no_speech_prob": 0.23339731991291046}, {"id": 7, "seek": 2776, "start": 31.12, "end": 34.800000000000004, "text": " And you can also subscribe to stay updated on future tutorials.", "tokens": [50532, 400, 291, 393, 611, 3022, 281, 1754, 10588, 322, 2027, 17616, 13, 50716], "temperature": 0.0, "avg_logprob": -0.11464232951402664, "compression_ratio": 1.7534722222222223, "no_speech_prob": 0.23339731991291046}, {"id": 8, "seek": 2776, "start": 34.800000000000004, "end": 38.400000000000006, "text": " So to start, you're going to go to this website, chat.openair.com,", "tokens": [50716, 407, 281, 722, 11, 291, 434, 516, 281, 352, 281, 341, 3144, 11, 5081, 13, 15752, 1246, 13, 1112, 11, 50896], "temperature": 0.0, "avg_logprob": -0.11464232951402664, "compression_ratio": 1.7534722222222223, "no_speech_prob": 0.23339731991291046}, {"id": 9, "seek": 2776, "start": 38.400000000000006, "end": 41.44, "text": " and you need to make an account to use this chatbot.", "tokens": [50896, 293, 291, 643, 281, 652, 364, 2696, 281, 764, 341, 5081, 18870, 13, 51048], "temperature": 0.0, "avg_logprob": -0.11464232951402664, "compression_ratio": 1.7534722222222223, "no_speech_prob": 0.23339731991291046}, {"id": 10, "seek": 2776, "start": 41.44, "end": 44.72, "text": " Once you log in, you get this screen where you can type your prompts over here.", "tokens": [51048, 3443, 291, 3565, 294, 11, 291, 483, 341, 2568, 689, 291, 393, 2010, 428, 41095, 670, 510, 13, 51212], "temperature": 0.0, "avg_logprob": -0.11464232951402664, "compression_ratio": 1.7534722222222223, "no_speech_prob": 0.23339731991291046}, {"id": 11, "seek": 2776, "start": 44.72, "end": 49.44, "text": " And it also gives you some examples, explains about the capabilities and the limitations.", "tokens": [51212, 400, 309, 611, 2709, 291, 512, 5110, 11, 13948, 466, 264, 10862, 293, 264, 15705, 13, 51448], "temperature": 0.0, "avg_logprob": -0.11464232951402664, "compression_ratio": 1.7534722222222223, "no_speech_prob": 0.23339731991291046}, {"id": 12, "seek": 2776, "start": 49.44, "end": 54.72, "text": " I'm also going to explain about the limitations and troubleshooting later in this video.", "tokens": [51448, 286, 478, 611, 516, 281, 2903, 466, 264, 15705, 293, 15379, 47011, 1780, 294, 341, 960, 13, 51712], "temperature": 0.0, "avg_logprob": -0.11464232951402664, "compression_ratio": 1.7534722222222223, "no_speech_prob": 0.23339731991291046}, {"id": 13, "seek": 5472, "start": 54.72, "end": 59.68, "text": " But we're going to start with the first example, and that is scattering objects around your scene.", "tokens": [50364, 583, 321, 434, 516, 281, 722, 365, 264, 700, 1365, 11, 293, 300, 307, 42314, 6565, 926, 428, 4145, 13, 50612], "temperature": 0.0, "avg_logprob": -0.08774391521107067, "compression_ratio": 1.6893939393939394, "no_speech_prob": 0.002322988584637642}, {"id": 14, "seek": 5472, "start": 59.68, "end": 61.92, "text": " We're going to create our first prompt for the AI.", "tokens": [50612, 492, 434, 516, 281, 1884, 527, 700, 12391, 337, 264, 7318, 13, 50724], "temperature": 0.0, "avg_logprob": -0.08774391521107067, "compression_ratio": 1.6893939393939394, "no_speech_prob": 0.002322988584637642}, {"id": 15, "seek": 5472, "start": 61.92, "end": 66.64, "text": " And I'm going to ask it specifically to write a Python script for Blender.", "tokens": [50724, 400, 286, 478, 516, 281, 1029, 309, 4682, 281, 2464, 257, 15329, 5755, 337, 2177, 3216, 13, 50960], "temperature": 0.0, "avg_logprob": -0.08774391521107067, "compression_ratio": 1.6893939393939394, "no_speech_prob": 0.002322988584637642}, {"id": 16, "seek": 5472, "start": 66.64, "end": 71.12, "text": " And to just start out simply, let's create 10 cubes and scatter them around our scene", "tokens": [50960, 400, 281, 445, 722, 484, 2935, 11, 718, 311, 1884, 1266, 25415, 293, 34951, 552, 926, 527, 4145, 51184], "temperature": 0.0, "avg_logprob": -0.08774391521107067, "compression_ratio": 1.6893939393939394, "no_speech_prob": 0.002322988584637642}, {"id": 17, "seek": 5472, "start": 71.12, "end": 74.48, "text": " with a maximum distance to the world origin of 10.", "tokens": [51184, 365, 257, 6674, 4560, 281, 264, 1002, 4957, 295, 1266, 13, 51352], "temperature": 0.0, "avg_logprob": -0.08774391521107067, "compression_ratio": 1.6893939393939394, "no_speech_prob": 0.002322988584637642}, {"id": 18, "seek": 5472, "start": 78.32, "end": 82.48, "text": " Once you've tied your prompt, you can simply hit enter and it will output something.", "tokens": [51544, 3443, 291, 600, 9601, 428, 12391, 11, 291, 393, 2935, 2045, 3242, 293, 309, 486, 5598, 746, 13, 51752], "temperature": 0.0, "avg_logprob": -0.08774391521107067, "compression_ratio": 1.6893939393939394, "no_speech_prob": 0.002322988584637642}, {"id": 19, "seek": 8248, "start": 82.48, "end": 86.48, "text": " This usually takes a few seconds, but you can see it's already generating", "tokens": [50364, 639, 2673, 2516, 257, 1326, 3949, 11, 457, 291, 393, 536, 309, 311, 1217, 17746, 50564], "temperature": 0.0, "avg_logprob": -0.07606679946184158, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.00394485192373395}, {"id": 20, "seek": 8248, "start": 86.48, "end": 90.16, "text": " a text and here it's generating a Python script.", "tokens": [50564, 257, 2487, 293, 510, 309, 311, 17746, 257, 15329, 5755, 13, 50748], "temperature": 0.0, "avg_logprob": -0.07606679946184158, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.00394485192373395}, {"id": 21, "seek": 8248, "start": 90.16, "end": 94.08, "text": " So it's now done with the script and we can actually see that it creates a new scene", "tokens": [50748, 407, 309, 311, 586, 1096, 365, 264, 5755, 293, 321, 393, 767, 536, 300, 309, 7829, 257, 777, 4145, 50944], "temperature": 0.0, "avg_logprob": -0.07606679946184158, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.00394485192373395}, {"id": 22, "seek": 8248, "start": 94.08, "end": 95.84, "text": " and sets the world origin and everything.", "tokens": [50944, 293, 6352, 264, 1002, 4957, 293, 1203, 13, 51032], "temperature": 0.0, "avg_logprob": -0.07606679946184158, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.00394485192373395}, {"id": 23, "seek": 8248, "start": 95.84, "end": 100.16, "text": " And it will also create an explanation of your script right here.", "tokens": [51032, 400, 309, 486, 611, 1884, 364, 10835, 295, 428, 5755, 558, 510, 13, 51248], "temperature": 0.0, "avg_logprob": -0.07606679946184158, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.00394485192373395}, {"id": 24, "seek": 8248, "start": 100.16, "end": 104.56, "text": " So let's test it out by going into Blender and opening the text editor over here.", "tokens": [51248, 407, 718, 311, 1500, 309, 484, 538, 516, 666, 2177, 3216, 293, 5193, 264, 2487, 9839, 670, 510, 13, 51468], "temperature": 0.0, "avg_logprob": -0.07606679946184158, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.00394485192373395}, {"id": 25, "seek": 8248, "start": 105.36, "end": 107.44, "text": " And we will create a new text file.", "tokens": [51508, 400, 321, 486, 1884, 257, 777, 2487, 3991, 13, 51612], "temperature": 0.0, "avg_logprob": -0.07606679946184158, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.00394485192373395}, {"id": 26, "seek": 8248, "start": 108.08000000000001, "end": 111.36, "text": " And we're just going to paste the code that the AI just gave us.", "tokens": [51644, 400, 321, 434, 445, 516, 281, 9163, 264, 3089, 300, 264, 7318, 445, 2729, 505, 13, 51808], "temperature": 0.0, "avg_logprob": -0.07606679946184158, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.00394485192373395}, {"id": 27, "seek": 11136, "start": 111.36, "end": 113.92, "text": " We're going to go to text and run the script.", "tokens": [50364, 492, 434, 516, 281, 352, 281, 2487, 293, 1190, 264, 5755, 13, 50492], "temperature": 0.0, "avg_logprob": -0.0909514698555799, "compression_ratio": 1.6174242424242424, "no_speech_prob": 0.00884612649679184}, {"id": 28, "seek": 11136, "start": 113.92, "end": 116.24, "text": " You can also press alt P and see what happens.", "tokens": [50492, 509, 393, 611, 1886, 4955, 430, 293, 536, 437, 2314, 13, 50608], "temperature": 0.0, "avg_logprob": -0.0909514698555799, "compression_ratio": 1.6174242424242424, "no_speech_prob": 0.00884612649679184}, {"id": 29, "seek": 11136, "start": 117.36, "end": 118.24, "text": " Here we go.", "tokens": [50664, 1692, 321, 352, 13, 50708], "temperature": 0.0, "avg_logprob": -0.0909514698555799, "compression_ratio": 1.6174242424242424, "no_speech_prob": 0.00884612649679184}, {"id": 30, "seek": 11136, "start": 118.24, "end": 120.48, "text": " Okay, so we have I think 10 cubes.", "tokens": [50708, 1033, 11, 370, 321, 362, 286, 519, 1266, 25415, 13, 50820], "temperature": 0.0, "avg_logprob": -0.0909514698555799, "compression_ratio": 1.6174242424242424, "no_speech_prob": 0.00884612649679184}, {"id": 31, "seek": 11136, "start": 120.48, "end": 124.64, "text": " Yes, there are 10 over here and they are scattered around the scene.", "tokens": [50820, 1079, 11, 456, 366, 1266, 670, 510, 293, 436, 366, 21986, 926, 264, 4145, 13, 51028], "temperature": 0.0, "avg_logprob": -0.0909514698555799, "compression_ratio": 1.6174242424242424, "no_speech_prob": 0.00884612649679184}, {"id": 32, "seek": 11136, "start": 125.28, "end": 127.36, "text": " This one is actually still at the world origin.", "tokens": [51060, 639, 472, 307, 767, 920, 412, 264, 1002, 4957, 13, 51164], "temperature": 0.0, "avg_logprob": -0.0909514698555799, "compression_ratio": 1.6174242424242424, "no_speech_prob": 0.00884612649679184}, {"id": 33, "seek": 11136, "start": 127.36, "end": 131.28, "text": " So I wonder if this is the original cube or yeah,", "tokens": [51164, 407, 286, 2441, 498, 341, 307, 264, 3380, 13728, 420, 1338, 11, 51360], "temperature": 0.0, "avg_logprob": -0.0909514698555799, "compression_ratio": 1.6174242424242424, "no_speech_prob": 0.00884612649679184}, {"id": 34, "seek": 11136, "start": 131.28, "end": 134.88, "text": " it must be because it can't just be randomly at the starting point.", "tokens": [51360, 309, 1633, 312, 570, 309, 393, 380, 445, 312, 16979, 412, 264, 2891, 935, 13, 51540], "temperature": 0.0, "avg_logprob": -0.0909514698555799, "compression_ratio": 1.6174242424242424, "no_speech_prob": 0.00884612649679184}, {"id": 35, "seek": 11136, "start": 134.88, "end": 138.32, "text": " We can also scatter the objects in a non-random way.", "tokens": [51540, 492, 393, 611, 34951, 264, 6565, 294, 257, 2107, 12, 3699, 298, 636, 13, 51712], "temperature": 0.0, "avg_logprob": -0.0909514698555799, "compression_ratio": 1.6174242424242424, "no_speech_prob": 0.00884612649679184}, {"id": 36, "seek": 13832, "start": 138.32, "end": 143.51999999999998, "text": " Going back to GPT chat, I'm going to ask it to make a circular array of circles.", "tokens": [50364, 10963, 646, 281, 26039, 51, 5081, 11, 286, 478, 516, 281, 1029, 309, 281, 652, 257, 16476, 10225, 295, 13040, 13, 50624], "temperature": 0.0, "avg_logprob": -0.08473290337456597, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.0016483210492879152}, {"id": 37, "seek": 13832, "start": 144.23999999999998, "end": 148.4, "text": " Again, we're going to ask it to write a Python script in Blender to do this.", "tokens": [50660, 3764, 11, 321, 434, 516, 281, 1029, 309, 281, 2464, 257, 15329, 5755, 294, 2177, 3216, 281, 360, 341, 13, 50868], "temperature": 0.0, "avg_logprob": -0.08473290337456597, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.0016483210492879152}, {"id": 38, "seek": 13832, "start": 151.28, "end": 152.95999999999998, "text": " Also, you want to be specific.", "tokens": [51012, 2743, 11, 291, 528, 281, 312, 2685, 13, 51096], "temperature": 0.0, "avg_logprob": -0.08473290337456597, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.0016483210492879152}, {"id": 39, "seek": 13832, "start": 152.95999999999998, "end": 156.16, "text": " So I'm going to ask for 16 individual circles.", "tokens": [51096, 407, 286, 478, 516, 281, 1029, 337, 3165, 2609, 13040, 13, 51256], "temperature": 0.0, "avg_logprob": -0.08473290337456597, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.0016483210492879152}, {"id": 40, "seek": 13832, "start": 156.16, "end": 160.32, "text": " And the main circle that it's going to be scattered along,", "tokens": [51256, 400, 264, 2135, 6329, 300, 309, 311, 516, 281, 312, 21986, 2051, 11, 51464], "temperature": 0.0, "avg_logprob": -0.08473290337456597, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.0016483210492879152}, {"id": 41, "seek": 13832, "start": 160.32, "end": 162.4, "text": " I'm going to specify the radius.", "tokens": [51464, 286, 478, 516, 281, 16500, 264, 15845, 13, 51568], "temperature": 0.0, "avg_logprob": -0.08473290337456597, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.0016483210492879152}, {"id": 42, "seek": 13832, "start": 165.04, "end": 166.56, "text": " So let's see what it comes up with now.", "tokens": [51700, 407, 718, 311, 536, 437, 309, 1487, 493, 365, 586, 13, 51776], "temperature": 0.0, "avg_logprob": -0.08473290337456597, "compression_ratio": 1.68348623853211, "no_speech_prob": 0.0016483210492879152}, {"id": 43, "seek": 16656, "start": 167.52, "end": 170.96, "text": " We can actually see that it's adding a primitive curve.", "tokens": [50412, 492, 393, 767, 536, 300, 309, 311, 5127, 257, 28540, 7605, 13, 50584], "temperature": 0.0, "avg_logprob": -0.2091852271038553, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.004069660324603319}, {"id": 44, "seek": 16656, "start": 170.96, "end": 172.48, "text": " So it understands that.", "tokens": [50584, 407, 309, 15146, 300, 13, 50660], "temperature": 0.0, "avg_logprob": -0.2091852271038553, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.004069660324603319}, {"id": 45, "seek": 16656, "start": 172.48, "end": 174.88, "text": " So our AI is done writing the code.", "tokens": [50660, 407, 527, 7318, 307, 1096, 3579, 264, 3089, 13, 50780], "temperature": 0.0, "avg_logprob": -0.2091852271038553, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.004069660324603319}, {"id": 46, "seek": 16656, "start": 174.88, "end": 179.2, "text": " Again, it gives a full explanation also at every line of the code.", "tokens": [50780, 3764, 11, 309, 2709, 257, 1577, 10835, 611, 412, 633, 1622, 295, 264, 3089, 13, 50996], "temperature": 0.0, "avg_logprob": -0.2091852271038553, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.004069660324603319}, {"id": 47, "seek": 16656, "start": 179.2, "end": 182.24, "text": " It gives a small explanation, which is very useful.", "tokens": [50996, 467, 2709, 257, 1359, 10835, 11, 597, 307, 588, 4420, 13, 51148], "temperature": 0.0, "avg_logprob": -0.2091852271038553, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.004069660324603319}, {"id": 48, "seek": 16656, "start": 182.24, "end": 185.76, "text": " We're just going to copy the code and paste it into our text editor.", "tokens": [51148, 492, 434, 445, 516, 281, 5055, 264, 3089, 293, 9163, 309, 666, 527, 2487, 9839, 13, 51324], "temperature": 0.0, "avg_logprob": -0.2091852271038553, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.004069660324603319}, {"id": 49, "seek": 16656, "start": 185.76, "end": 187.6, "text": " Let's run our script and see what happens.", "tokens": [51324, 961, 311, 1190, 527, 5755, 293, 536, 437, 2314, 13, 51416], "temperature": 0.0, "avg_logprob": -0.2091852271038553, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.004069660324603319}, {"id": 50, "seek": 16656, "start": 189.12, "end": 193.12, "text": " All right, so it's pretty hard to see, but there is definitely a circular array.", "tokens": [51492, 1057, 558, 11, 370, 309, 311, 1238, 1152, 281, 536, 11, 457, 456, 307, 2138, 257, 16476, 10225, 13, 51692], "temperature": 0.0, "avg_logprob": -0.2091852271038553, "compression_ratio": 1.6486486486486487, "no_speech_prob": 0.004069660324603319}, {"id": 51, "seek": 19312, "start": 193.36, "end": 200.64000000000001, "text": " Yeah, if we select all of them, wow, this is actually pretty perfect because they align here.", "tokens": [50376, 865, 11, 498, 321, 3048, 439, 295, 552, 11, 6076, 11, 341, 307, 767, 1238, 2176, 570, 436, 7975, 510, 13, 50740], "temperature": 0.0, "avg_logprob": -0.13334265622225674, "compression_ratio": 1.5977443609022557, "no_speech_prob": 0.02975226193666458}, {"id": 52, "seek": 19312, "start": 203.20000000000002, "end": 205.84, "text": " This actually turned out better than I even imagined.", "tokens": [50868, 639, 767, 3574, 484, 1101, 813, 286, 754, 16590, 13, 51000], "temperature": 0.0, "avg_logprob": -0.13334265622225674, "compression_ratio": 1.5977443609022557, "no_speech_prob": 0.02975226193666458}, {"id": 53, "seek": 19312, "start": 205.84, "end": 208.4, "text": " I just expected any size whatsoever,", "tokens": [51000, 286, 445, 5176, 604, 2744, 17076, 11, 51128], "temperature": 0.0, "avg_logprob": -0.13334265622225674, "compression_ratio": 1.5977443609022557, "no_speech_prob": 0.02975226193666458}, {"id": 54, "seek": 19312, "start": 208.4, "end": 212.08, "text": " but it made it the size so that they perfectly line up with each other.", "tokens": [51128, 457, 309, 1027, 309, 264, 2744, 370, 300, 436, 6239, 1622, 493, 365, 1184, 661, 13, 51312], "temperature": 0.0, "avg_logprob": -0.13334265622225674, "compression_ratio": 1.5977443609022557, "no_speech_prob": 0.02975226193666458}, {"id": 55, "seek": 19312, "start": 212.08, "end": 216.08, "text": " To be honest, I wouldn't even know how to do this in Blender, let alone this quickly.", "tokens": [51312, 1407, 312, 3245, 11, 286, 2759, 380, 754, 458, 577, 281, 360, 341, 294, 2177, 3216, 11, 718, 3312, 341, 2661, 13, 51512], "temperature": 0.0, "avg_logprob": -0.13334265622225674, "compression_ratio": 1.5977443609022557, "no_speech_prob": 0.02975226193666458}, {"id": 56, "seek": 19312, "start": 216.64000000000001, "end": 222.08, "text": " Going on to the next example, this might be the most useful use case for GPT chat.", "tokens": [51540, 10963, 322, 281, 264, 958, 1365, 11, 341, 1062, 312, 264, 881, 4420, 764, 1389, 337, 26039, 51, 5081, 13, 51812], "temperature": 0.0, "avg_logprob": -0.13334265622225674, "compression_ratio": 1.5977443609022557, "no_speech_prob": 0.02975226193666458}, {"id": 57, "seek": 22208, "start": 222.08, "end": 223.84, "text": " And that is bulk actions.", "tokens": [50364, 400, 300, 307, 16139, 5909, 13, 50452], "temperature": 0.0, "avg_logprob": -0.07440322637557983, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0044677648693323135}, {"id": 58, "seek": 22208, "start": 225.84, "end": 227.60000000000002, "text": " So let's say we've imported this character,", "tokens": [50552, 407, 718, 311, 584, 321, 600, 25524, 341, 2517, 11, 50640], "temperature": 0.0, "avg_logprob": -0.07440322637557983, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0044677648693323135}, {"id": 59, "seek": 22208, "start": 227.60000000000002, "end": 231.36, "text": " but we can see every object has a different material,", "tokens": [50640, 457, 321, 393, 536, 633, 2657, 575, 257, 819, 2527, 11, 50828], "temperature": 0.0, "avg_logprob": -0.07440322637557983, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0044677648693323135}, {"id": 60, "seek": 22208, "start": 231.36, "end": 233.76000000000002, "text": " even though some objects have the same color.", "tokens": [50828, 754, 1673, 512, 6565, 362, 264, 912, 2017, 13, 50948], "temperature": 0.0, "avg_logprob": -0.07440322637557983, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0044677648693323135}, {"id": 61, "seek": 22208, "start": 234.4, "end": 236.48000000000002, "text": " Where there are only four colors in this character,", "tokens": [50980, 2305, 456, 366, 787, 1451, 4577, 294, 341, 2517, 11, 51084], "temperature": 0.0, "avg_logprob": -0.07440322637557983, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0044677648693323135}, {"id": 62, "seek": 22208, "start": 236.48000000000002, "end": 239.12, "text": " but there are a bunch of materials.", "tokens": [51084, 457, 456, 366, 257, 3840, 295, 5319, 13, 51216], "temperature": 0.0, "avg_logprob": -0.07440322637557983, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0044677648693323135}, {"id": 63, "seek": 22208, "start": 239.12, "end": 242.56, "text": " This can happen sometimes when you switch objects between programs,", "tokens": [51216, 639, 393, 1051, 2171, 562, 291, 3679, 6565, 1296, 4268, 11, 51388], "temperature": 0.0, "avg_logprob": -0.07440322637557983, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0044677648693323135}, {"id": 64, "seek": 22208, "start": 242.56, "end": 245.84, "text": " or especially when you import a bunch of vector graphics.", "tokens": [51388, 420, 2318, 562, 291, 974, 257, 3840, 295, 8062, 11837, 13, 51552], "temperature": 0.0, "avg_logprob": -0.07440322637557983, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0044677648693323135}, {"id": 65, "seek": 22208, "start": 245.84, "end": 250.4, "text": " This is a prime example where GPT chat can save us hours of time.", "tokens": [51552, 639, 307, 257, 5835, 1365, 689, 26039, 51, 5081, 393, 3155, 505, 2496, 295, 565, 13, 51780], "temperature": 0.0, "avg_logprob": -0.07440322637557983, "compression_ratio": 1.7203065134099618, "no_speech_prob": 0.0044677648693323135}, {"id": 66, "seek": 25040, "start": 250.4, "end": 252.72, "text": " Going back to our GPT chat window,", "tokens": [50364, 10963, 646, 281, 527, 26039, 51, 5081, 4910, 11, 50480], "temperature": 0.0, "avg_logprob": -0.06450389846553647, "compression_ratio": 1.8793774319066148, "no_speech_prob": 0.006386805325746536}, {"id": 67, "seek": 25040, "start": 252.72, "end": 255.52, "text": " I'm going to ask the AI to look through all the materials", "tokens": [50480, 286, 478, 516, 281, 1029, 264, 7318, 281, 574, 807, 439, 264, 5319, 50620], "temperature": 0.0, "avg_logprob": -0.06450389846553647, "compression_ratio": 1.8793774319066148, "no_speech_prob": 0.006386805325746536}, {"id": 68, "seek": 25040, "start": 255.52, "end": 260.24, "text": " and see which materials have the same hex color value in their base color.", "tokens": [50620, 293, 536, 597, 5319, 362, 264, 912, 23291, 2017, 2158, 294, 641, 3096, 2017, 13, 50856], "temperature": 0.0, "avg_logprob": -0.06450389846553647, "compression_ratio": 1.8793774319066148, "no_speech_prob": 0.006386805325746536}, {"id": 69, "seek": 25040, "start": 260.24, "end": 263.44, "text": " If it has the same hex value, it means it's the same color.", "tokens": [50856, 759, 309, 575, 264, 912, 23291, 2158, 11, 309, 1355, 309, 311, 264, 912, 2017, 13, 51016], "temperature": 0.0, "avg_logprob": -0.06450389846553647, "compression_ratio": 1.8793774319066148, "no_speech_prob": 0.006386805325746536}, {"id": 70, "seek": 25040, "start": 263.44, "end": 268.0, "text": " And then I'll ask it to combine those duplicate materials into one combined material", "tokens": [51016, 400, 550, 286, 603, 1029, 309, 281, 10432, 729, 23976, 5319, 666, 472, 9354, 2527, 51244], "temperature": 0.0, "avg_logprob": -0.06450389846553647, "compression_ratio": 1.8793774319066148, "no_speech_prob": 0.006386805325746536}, {"id": 71, "seek": 25040, "start": 268.0, "end": 270.24, "text": " and then apply that material to the objects.", "tokens": [51244, 293, 550, 3079, 300, 2527, 281, 264, 6565, 13, 51356], "temperature": 0.0, "avg_logprob": -0.06450389846553647, "compression_ratio": 1.8793774319066148, "no_speech_prob": 0.006386805325746536}, {"id": 72, "seek": 25040, "start": 271.12, "end": 272.8, "text": " All right, the script is done.", "tokens": [51400, 1057, 558, 11, 264, 5755, 307, 1096, 13, 51484], "temperature": 0.0, "avg_logprob": -0.06450389846553647, "compression_ratio": 1.8793774319066148, "no_speech_prob": 0.006386805325746536}, {"id": 73, "seek": 25040, "start": 272.8, "end": 275.92, "text": " And it says the script will iterate over every material", "tokens": [51484, 400, 309, 1619, 264, 5755, 486, 44497, 670, 633, 2527, 51640], "temperature": 0.0, "avg_logprob": -0.06450389846553647, "compression_ratio": 1.8793774319066148, "no_speech_prob": 0.006386805325746536}, {"id": 74, "seek": 25040, "start": 275.92, "end": 277.92, "text": " and get the base color of the material", "tokens": [51640, 293, 483, 264, 3096, 2017, 295, 264, 2527, 51740], "temperature": 0.0, "avg_logprob": -0.06450389846553647, "compression_ratio": 1.8793774319066148, "no_speech_prob": 0.006386805325746536}, {"id": 75, "seek": 27792, "start": 277.92, "end": 281.52000000000004, "text": " and then convert it to a hex string and create a dictionary out of it.", "tokens": [50364, 293, 550, 7620, 309, 281, 257, 23291, 6798, 293, 1884, 257, 25890, 484, 295, 309, 13, 50544], "temperature": 0.0, "avg_logprob": -0.04835511329478787, "compression_ratio": 2.007905138339921, "no_speech_prob": 0.010982289910316467}, {"id": 76, "seek": 27792, "start": 281.52000000000004, "end": 282.88, "text": " Next time it finds a material,", "tokens": [50544, 3087, 565, 309, 10704, 257, 2527, 11, 50612], "temperature": 0.0, "avg_logprob": -0.04835511329478787, "compression_ratio": 2.007905138339921, "no_speech_prob": 0.010982289910316467}, {"id": 77, "seek": 27792, "start": 282.88, "end": 285.04, "text": " it checks if it's already in the dictionary.", "tokens": [50612, 309, 13834, 498, 309, 311, 1217, 294, 264, 25890, 13, 50720], "temperature": 0.0, "avg_logprob": -0.04835511329478787, "compression_ratio": 2.007905138339921, "no_speech_prob": 0.010982289910316467}, {"id": 78, "seek": 27792, "start": 285.04, "end": 288.32, "text": " And if yes, it will add it to the list of materials with the same color.", "tokens": [50720, 400, 498, 2086, 11, 309, 486, 909, 309, 281, 264, 1329, 295, 5319, 365, 264, 912, 2017, 13, 50884], "temperature": 0.0, "avg_logprob": -0.04835511329478787, "compression_ratio": 2.007905138339921, "no_speech_prob": 0.010982289910316467}, {"id": 79, "seek": 27792, "start": 288.32, "end": 292.08000000000004, "text": " And if it's not, it will create a new entry in the dictionary with a different color.", "tokens": [50884, 400, 498, 309, 311, 406, 11, 309, 486, 1884, 257, 777, 8729, 294, 264, 25890, 365, 257, 819, 2017, 13, 51072], "temperature": 0.0, "avg_logprob": -0.04835511329478787, "compression_ratio": 2.007905138339921, "no_speech_prob": 0.010982289910316467}, {"id": 80, "seek": 27792, "start": 292.08000000000004, "end": 294.32, "text": " Then the script will iterate over all those colors", "tokens": [51072, 1396, 264, 5755, 486, 44497, 670, 439, 729, 4577, 51184], "temperature": 0.0, "avg_logprob": -0.04835511329478787, "compression_ratio": 2.007905138339921, "no_speech_prob": 0.010982289910316467}, {"id": 81, "seek": 27792, "start": 294.32, "end": 297.36, "text": " and see if there are colors with multiple materials.", "tokens": [51184, 293, 536, 498, 456, 366, 4577, 365, 3866, 5319, 13, 51336], "temperature": 0.0, "avg_logprob": -0.04835511329478787, "compression_ratio": 2.007905138339921, "no_speech_prob": 0.010982289910316467}, {"id": 82, "seek": 27792, "start": 297.36, "end": 299.92, "text": " If yes, it will create a combined material,", "tokens": [51336, 759, 2086, 11, 309, 486, 1884, 257, 9354, 2527, 11, 51464], "temperature": 0.0, "avg_logprob": -0.04835511329478787, "compression_ratio": 2.007905138339921, "no_speech_prob": 0.010982289910316467}, {"id": 83, "seek": 27792, "start": 299.92, "end": 302.88, "text": " so a new material, and then apply that to the objects.", "tokens": [51464, 370, 257, 777, 2527, 11, 293, 550, 3079, 300, 281, 264, 6565, 13, 51612], "temperature": 0.0, "avg_logprob": -0.04835511329478787, "compression_ratio": 2.007905138339921, "no_speech_prob": 0.010982289910316467}, {"id": 84, "seek": 30288, "start": 303.52, "end": 308.56, "text": " So let's go back to our text editor and just paste our script here", "tokens": [50396, 407, 718, 311, 352, 646, 281, 527, 2487, 9839, 293, 445, 9163, 527, 5755, 510, 50648], "temperature": 0.0, "avg_logprob": -0.07654830321524907, "compression_ratio": 1.6893617021276597, "no_speech_prob": 0.03513673320412636}, {"id": 85, "seek": 30288, "start": 308.56, "end": 310.32, "text": " and run this and see what it does.", "tokens": [50648, 293, 1190, 341, 293, 536, 437, 309, 775, 13, 50736], "temperature": 0.0, "avg_logprob": -0.07654830321524907, "compression_ratio": 1.6893617021276597, "no_speech_prob": 0.03513673320412636}, {"id": 86, "seek": 30288, "start": 312.24, "end": 318.56, "text": " Okay, so we can see that it tries to delete all the materials at the very end", "tokens": [50832, 1033, 11, 370, 321, 393, 536, 300, 309, 9898, 281, 12097, 439, 264, 5319, 412, 264, 588, 917, 51148], "temperature": 0.0, "avg_logprob": -0.07654830321524907, "compression_ratio": 1.6893617021276597, "no_speech_prob": 0.03513673320412636}, {"id": 87, "seek": 30288, "start": 318.56, "end": 319.84, "text": " and something is going wrong.", "tokens": [51148, 293, 746, 307, 516, 2085, 13, 51212], "temperature": 0.0, "avg_logprob": -0.07654830321524907, "compression_ratio": 1.6893617021276597, "no_speech_prob": 0.03513673320412636}, {"id": 88, "seek": 30288, "start": 321.12, "end": 324.4, "text": " Function material is expected a material type, not list.", "tokens": [51276, 11166, 882, 2527, 307, 5176, 257, 2527, 2010, 11, 406, 1329, 13, 51440], "temperature": 0.0, "avg_logprob": -0.07654830321524907, "compression_ratio": 1.6893617021276597, "no_speech_prob": 0.03513673320412636}, {"id": 89, "seek": 30288, "start": 324.4, "end": 328.08, "text": " I guess it's going wrong because it's trying to make a list called materials,", "tokens": [51440, 286, 2041, 309, 311, 516, 2085, 570, 309, 311, 1382, 281, 652, 257, 1329, 1219, 5319, 11, 51624], "temperature": 0.0, "avg_logprob": -0.07654830321524907, "compression_ratio": 1.6893617021276597, "no_speech_prob": 0.03513673320412636}, {"id": 90, "seek": 30288, "start": 328.08, "end": 330.64, "text": " but maybe that term is already taken somewhere else.", "tokens": [51624, 457, 1310, 300, 1433, 307, 1217, 2726, 4079, 1646, 13, 51752], "temperature": 0.0, "avg_logprob": -0.07654830321524907, "compression_ratio": 1.6893617021276597, "no_speech_prob": 0.03513673320412636}, {"id": 91, "seek": 33064, "start": 330.64, "end": 333.03999999999996, "text": " So we're just going to get rid of that last sentence.", "tokens": [50364, 407, 321, 434, 445, 516, 281, 483, 3973, 295, 300, 1036, 8174, 13, 50484], "temperature": 0.0, "avg_logprob": -0.04040846704434948, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.003593236906453967}, {"id": 92, "seek": 33064, "start": 335.84, "end": 338.15999999999997, "text": " Nevertheless, if we now go to our object,", "tokens": [50624, 26554, 11, 498, 321, 586, 352, 281, 527, 2657, 11, 50740], "temperature": 0.0, "avg_logprob": -0.04040846704434948, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.003593236906453967}, {"id": 93, "seek": 33064, "start": 338.15999999999997, "end": 341.28, "text": " we can see that it has the correctly combined material.", "tokens": [50740, 321, 393, 536, 300, 309, 575, 264, 8944, 9354, 2527, 13, 50896], "temperature": 0.0, "avg_logprob": -0.04040846704434948, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.003593236906453967}, {"id": 94, "seek": 33064, "start": 341.28, "end": 345.91999999999996, "text": " So all these objects with the same color now have a combined material.", "tokens": [50896, 407, 439, 613, 6565, 365, 264, 912, 2017, 586, 362, 257, 9354, 2527, 13, 51128], "temperature": 0.0, "avg_logprob": -0.04040846704434948, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.003593236906453967}, {"id": 95, "seek": 33064, "start": 345.91999999999996, "end": 349.84, "text": " So we don't have to go through every object and select our material right here", "tokens": [51128, 407, 321, 500, 380, 362, 281, 352, 807, 633, 2657, 293, 3048, 527, 2527, 558, 510, 51324], "temperature": 0.0, "avg_logprob": -0.04040846704434948, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.003593236906453967}, {"id": 96, "seek": 33064, "start": 349.84, "end": 351.68, "text": " because that saves a lot of time.", "tokens": [51324, 570, 300, 19155, 257, 688, 295, 565, 13, 51416], "temperature": 0.0, "avg_logprob": -0.04040846704434948, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.003593236906453967}, {"id": 97, "seek": 33064, "start": 351.68, "end": 354.8, "text": " So for the last portion of this video, I want to get creative.", "tokens": [51416, 407, 337, 264, 1036, 8044, 295, 341, 960, 11, 286, 528, 281, 483, 5880, 13, 51572], "temperature": 0.0, "avg_logprob": -0.04040846704434948, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.003593236906453967}, {"id": 98, "seek": 33064, "start": 354.8, "end": 358.88, "text": " I want to ask the AI to actually generate a mesh for us.", "tokens": [51572, 286, 528, 281, 1029, 264, 7318, 281, 767, 8460, 257, 17407, 337, 505, 13, 51776], "temperature": 0.0, "avg_logprob": -0.04040846704434948, "compression_ratio": 1.7567567567567568, "no_speech_prob": 0.003593236906453967}, {"id": 99, "seek": 35888, "start": 358.96, "end": 363.04, "text": " One thing that's pretty complicated to generate normally in Blender is a fractal.", "tokens": [50368, 1485, 551, 300, 311, 1238, 6179, 281, 8460, 5646, 294, 2177, 3216, 307, 257, 17948, 304, 13, 50572], "temperature": 0.0, "avg_logprob": -0.08573868604210334, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.002082550898194313}, {"id": 100, "seek": 35888, "start": 363.04, "end": 365.44, "text": " So we're going to create a Mandelbrot set.", "tokens": [50572, 407, 321, 434, 516, 281, 1884, 257, 15458, 338, 1443, 310, 992, 13, 50692], "temperature": 0.0, "avg_logprob": -0.08573868604210334, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.002082550898194313}, {"id": 101, "seek": 35888, "start": 365.44, "end": 371.12, "text": " And once again, it's as simple as creating a specific prompt for GPT chat.", "tokens": [50692, 400, 1564, 797, 11, 309, 311, 382, 2199, 382, 4084, 257, 2685, 12391, 337, 26039, 51, 5081, 13, 50976], "temperature": 0.0, "avg_logprob": -0.08573868604210334, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.002082550898194313}, {"id": 102, "seek": 35888, "start": 371.12, "end": 374.88, "text": " I've been experimenting with creating fractals using GPT chat.", "tokens": [50976, 286, 600, 668, 29070, 365, 4084, 17948, 1124, 1228, 26039, 51, 5081, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08573868604210334, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.002082550898194313}, {"id": 103, "seek": 35888, "start": 375.92, "end": 378.32, "text": " And it's a hit or miss situation.", "tokens": [51216, 400, 309, 311, 257, 2045, 420, 1713, 2590, 13, 51336], "temperature": 0.0, "avg_logprob": -0.08573868604210334, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.002082550898194313}, {"id": 104, "seek": 35888, "start": 378.32, "end": 380.24, "text": " Sometimes it works, sometimes it doesn't.", "tokens": [51336, 4803, 309, 1985, 11, 2171, 309, 1177, 380, 13, 51432], "temperature": 0.0, "avg_logprob": -0.08573868604210334, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.002082550898194313}, {"id": 105, "seek": 35888, "start": 380.24, "end": 383.36, "text": " I haven't managed to create an actual 3D fractal yet,", "tokens": [51432, 286, 2378, 380, 6453, 281, 1884, 364, 3539, 805, 35, 17948, 304, 1939, 11, 51588], "temperature": 0.0, "avg_logprob": -0.08573868604210334, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.002082550898194313}, {"id": 106, "seek": 35888, "start": 383.36, "end": 386.32, "text": " but I have managed to create this 2D fractal.", "tokens": [51588, 457, 286, 362, 6453, 281, 1884, 341, 568, 35, 17948, 304, 13, 51736], "temperature": 0.0, "avg_logprob": -0.08573868604210334, "compression_ratio": 1.691119691119691, "no_speech_prob": 0.002082550898194313}, {"id": 107, "seek": 38632, "start": 386.32, "end": 390.0, "text": " Trying to get it to actually create a mesh itself,", "tokens": [50364, 20180, 281, 483, 309, 281, 767, 1884, 257, 17407, 2564, 11, 50548], "temperature": 0.0, "avg_logprob": -0.060841181506849314, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002251633442938328}, {"id": 108, "seek": 38632, "start": 390.0, "end": 392.0, "text": " it seems to have a lot of trouble with that.", "tokens": [50548, 309, 2544, 281, 362, 257, 688, 295, 5253, 365, 300, 13, 50648], "temperature": 0.0, "avg_logprob": -0.060841181506849314, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002251633442938328}, {"id": 109, "seek": 38632, "start": 392.0, "end": 393.76, "text": " You'd have to try this in the future though,", "tokens": [50648, 509, 1116, 362, 281, 853, 341, 294, 264, 2027, 1673, 11, 50736], "temperature": 0.0, "avg_logprob": -0.060841181506849314, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002251633442938328}, {"id": 110, "seek": 38632, "start": 393.76, "end": 396.48, "text": " because this chatbot is constantly being updated.", "tokens": [50736, 570, 341, 5081, 18870, 307, 6460, 885, 10588, 13, 50872], "temperature": 0.0, "avg_logprob": -0.060841181506849314, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002251633442938328}, {"id": 111, "seek": 38632, "start": 396.48, "end": 400.56, "text": " So what I'm going to do is I'm going to create a fractal using a point cloud.", "tokens": [50872, 407, 437, 286, 478, 516, 281, 360, 307, 286, 478, 516, 281, 1884, 257, 17948, 304, 1228, 257, 935, 4588, 13, 51076], "temperature": 0.0, "avg_logprob": -0.060841181506849314, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002251633442938328}, {"id": 112, "seek": 38632, "start": 400.56, "end": 404.64, "text": " It's similar to the method from bad normals and his whole fractal machine add-on.", "tokens": [51076, 467, 311, 2531, 281, 264, 3170, 490, 1578, 2026, 1124, 293, 702, 1379, 17948, 304, 3479, 909, 12, 266, 13, 51280], "temperature": 0.0, "avg_logprob": -0.060841181506849314, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002251633442938328}, {"id": 113, "seek": 38632, "start": 404.64, "end": 407.2, "text": " So it's not like there's no other way to create them,", "tokens": [51280, 407, 309, 311, 406, 411, 456, 311, 572, 661, 636, 281, 1884, 552, 11, 51408], "temperature": 0.0, "avg_logprob": -0.060841181506849314, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002251633442938328}, {"id": 114, "seek": 38632, "start": 407.2, "end": 410.64, "text": " but it's just really cool to see how simple it is.", "tokens": [51408, 457, 309, 311, 445, 534, 1627, 281, 536, 577, 2199, 309, 307, 13, 51580], "temperature": 0.0, "avg_logprob": -0.060841181506849314, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002251633442938328}, {"id": 115, "seek": 38632, "start": 410.64, "end": 414.15999999999997, "text": " So I'm once again asking it to create a Python script for Blender.", "tokens": [51580, 407, 286, 478, 1564, 797, 3365, 309, 281, 1884, 257, 15329, 5755, 337, 2177, 3216, 13, 51756], "temperature": 0.0, "avg_logprob": -0.060841181506849314, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002251633442938328}, {"id": 116, "seek": 41416, "start": 414.16, "end": 419.20000000000005, "text": " I'm going to ask it to make a Mandobrot set out of points that is one layer thick.", "tokens": [50364, 286, 478, 516, 281, 1029, 309, 281, 652, 257, 15458, 996, 10536, 992, 484, 295, 2793, 300, 307, 472, 4583, 5060, 13, 50616], "temperature": 0.0, "avg_logprob": -0.07102611384440943, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.0027147242799401283}, {"id": 117, "seek": 41416, "start": 419.84000000000003, "end": 422.32000000000005, "text": " I'm also asking it to convert points to vertices", "tokens": [50648, 286, 478, 611, 3365, 309, 281, 7620, 2793, 281, 32053, 50772], "temperature": 0.0, "avg_logprob": -0.07102611384440943, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.0027147242799401283}, {"id": 118, "seek": 41416, "start": 422.32000000000005, "end": 424.64000000000004, "text": " so we can instantly see what the shape looks like.", "tokens": [50772, 370, 321, 393, 13518, 536, 437, 264, 3909, 1542, 411, 13, 50888], "temperature": 0.0, "avg_logprob": -0.07102611384440943, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.0027147242799401283}, {"id": 119, "seek": 41416, "start": 430.32000000000005, "end": 433.36, "text": " GPT chat needs a little more time than usual to create this,", "tokens": [51172, 26039, 51, 5081, 2203, 257, 707, 544, 565, 813, 7713, 281, 1884, 341, 11, 51324], "temperature": 0.0, "avg_logprob": -0.07102611384440943, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.0027147242799401283}, {"id": 120, "seek": 41416, "start": 433.36, "end": 437.6, "text": " but we can see that it is now creating something.", "tokens": [51324, 457, 321, 393, 536, 300, 309, 307, 586, 4084, 746, 13, 51536], "temperature": 0.0, "avg_logprob": -0.07102611384440943, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.0027147242799401283}, {"id": 121, "seek": 41416, "start": 437.6, "end": 442.08000000000004, "text": " It's very interesting because it's using a completely different method than before.", "tokens": [51536, 467, 311, 588, 1880, 570, 309, 311, 1228, 257, 2584, 819, 3170, 813, 949, 13, 51760], "temperature": 0.0, "avg_logprob": -0.07102611384440943, "compression_ratio": 1.6042553191489362, "no_speech_prob": 0.0027147242799401283}, {"id": 122, "seek": 44208, "start": 443.03999999999996, "end": 446.4, "text": " But yeah, it's still working with complex numbers", "tokens": [50412, 583, 1338, 11, 309, 311, 920, 1364, 365, 3997, 3547, 50580], "temperature": 0.0, "avg_logprob": -0.14712107181549072, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.011866866610944271}, {"id": 123, "seek": 44208, "start": 446.4, "end": 451.2, "text": " and doing all sorts of math that I am not qualified enough to understand.", "tokens": [50580, 293, 884, 439, 7527, 295, 5221, 300, 286, 669, 406, 15904, 1547, 281, 1223, 13, 50820], "temperature": 0.0, "avg_logprob": -0.14712107181549072, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.011866866610944271}, {"id": 124, "seek": 44208, "start": 451.2, "end": 454.64, "text": " So it's now creating the point cloud Mandobrot set.", "tokens": [50820, 407, 309, 311, 586, 4084, 264, 935, 4588, 15458, 996, 10536, 992, 13, 50992], "temperature": 0.0, "avg_logprob": -0.14712107181549072, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.011866866610944271}, {"id": 125, "seek": 44208, "start": 454.64, "end": 457.2, "text": " It's even naming everything. It's so cool.", "tokens": [50992, 467, 311, 754, 25290, 1203, 13, 467, 311, 370, 1627, 13, 51120], "temperature": 0.0, "avg_logprob": -0.14712107181549072, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.011866866610944271}, {"id": 126, "seek": 44208, "start": 457.2, "end": 458.96, "text": " Okay, so our script seems to be done.", "tokens": [51120, 1033, 11, 370, 527, 5755, 2544, 281, 312, 1096, 13, 51208], "temperature": 0.0, "avg_logprob": -0.14712107181549072, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.011866866610944271}, {"id": 127, "seek": 44208, "start": 458.96, "end": 461.03999999999996, "text": " Let's copy it and see if it works.", "tokens": [51208, 961, 311, 5055, 309, 293, 536, 498, 309, 1985, 13, 51312], "temperature": 0.0, "avg_logprob": -0.14712107181549072, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.011866866610944271}, {"id": 128, "seek": 44208, "start": 462.64, "end": 464.0, "text": " It's the moment of truth. Let's see.", "tokens": [51392, 467, 311, 264, 1623, 295, 3494, 13, 961, 311, 536, 13, 51460], "temperature": 0.0, "avg_logprob": -0.14712107181549072, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.011866866610944271}, {"id": 129, "seek": 46400, "start": 464.72, "end": 472.24, "text": " Okay, so I don't know what this is,", "tokens": [50400, 1033, 11, 370, 286, 500, 380, 458, 437, 341, 307, 11, 50776], "temperature": 0.0, "avg_logprob": -0.11605839927991231, "compression_ratio": 1.5, "no_speech_prob": 0.03566973656415939}, {"id": 130, "seek": 46400, "start": 473.2, "end": 478.08, "text": " but it doesn't really resemble anything close to a Mandobrot set.", "tokens": [50824, 457, 309, 1177, 380, 534, 36870, 1340, 1998, 281, 257, 15458, 996, 10536, 992, 13, 51068], "temperature": 0.0, "avg_logprob": -0.11605839927991231, "compression_ratio": 1.5, "no_speech_prob": 0.03566973656415939}, {"id": 131, "seek": 46400, "start": 478.08, "end": 480.8, "text": " It just looks like an array of random points,", "tokens": [51068, 467, 445, 1542, 411, 364, 10225, 295, 4974, 2793, 11, 51204], "temperature": 0.0, "avg_logprob": -0.11605839927991231, "compression_ratio": 1.5, "no_speech_prob": 0.03566973656415939}, {"id": 132, "seek": 46400, "start": 480.8, "end": 484.0, "text": " but that's no problem. We're just going to ask GPT chat again.", "tokens": [51204, 457, 300, 311, 572, 1154, 13, 492, 434, 445, 516, 281, 1029, 26039, 51, 5081, 797, 13, 51364], "temperature": 0.0, "avg_logprob": -0.11605839927991231, "compression_ratio": 1.5, "no_speech_prob": 0.03566973656415939}, {"id": 133, "seek": 46400, "start": 484.0, "end": 488.8, "text": " I also like to specify what happened because maybe the AI will see what went wrong.", "tokens": [51364, 286, 611, 411, 281, 16500, 437, 2011, 570, 1310, 264, 7318, 486, 536, 437, 1437, 2085, 13, 51604], "temperature": 0.0, "avg_logprob": -0.11605839927991231, "compression_ratio": 1.5, "no_speech_prob": 0.03566973656415939}, {"id": 134, "seek": 46400, "start": 488.8, "end": 491.92, "text": " So let's try to specify it as clearly as possible.", "tokens": [51604, 407, 718, 311, 853, 281, 16500, 309, 382, 4448, 382, 1944, 13, 51760], "temperature": 0.0, "avg_logprob": -0.11605839927991231, "compression_ratio": 1.5, "no_speech_prob": 0.03566973656415939}, {"id": 135, "seek": 49192, "start": 492.88, "end": 498.16, "text": " Currently, I can't get it to actually create the script that I got yesterday.", "tokens": [50412, 19964, 11, 286, 393, 380, 483, 309, 281, 767, 1884, 264, 5755, 300, 286, 658, 5186, 13, 50676], "temperature": 0.0, "avg_logprob": -0.08846127135413033, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0018100370652973652}, {"id": 136, "seek": 49192, "start": 498.16, "end": 501.04, "text": " I'm just going to show you what it came up with yesterday.", "tokens": [50676, 286, 478, 445, 516, 281, 855, 291, 437, 309, 1361, 493, 365, 5186, 13, 50820], "temperature": 0.0, "avg_logprob": -0.08846127135413033, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0018100370652973652}, {"id": 137, "seek": 49192, "start": 501.04, "end": 505.20000000000005, "text": " Unfortunately, I have no footage of me giving the prompt and getting back that response.", "tokens": [50820, 8590, 11, 286, 362, 572, 9556, 295, 385, 2902, 264, 12391, 293, 1242, 646, 300, 4134, 13, 51028], "temperature": 0.0, "avg_logprob": -0.08846127135413033, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0018100370652973652}, {"id": 138, "seek": 49192, "start": 505.20000000000005, "end": 508.32, "text": " So you'd have to trust me on the fact that I don't know anything about coding", "tokens": [51028, 407, 291, 1116, 362, 281, 3361, 385, 322, 264, 1186, 300, 286, 500, 380, 458, 1340, 466, 17720, 51184], "temperature": 0.0, "avg_logprob": -0.08846127135413033, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0018100370652973652}, {"id": 139, "seek": 49192, "start": 508.32, "end": 510.08000000000004, "text": " and that the AI just made it for me.", "tokens": [51184, 293, 300, 264, 7318, 445, 1027, 309, 337, 385, 13, 51272], "temperature": 0.0, "avg_logprob": -0.08846127135413033, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0018100370652973652}, {"id": 140, "seek": 49192, "start": 510.8, "end": 514.72, "text": " So running the script actually takes quite a long time", "tokens": [51308, 407, 2614, 264, 5755, 767, 2516, 1596, 257, 938, 565, 51504], "temperature": 0.0, "avg_logprob": -0.08846127135413033, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0018100370652973652}, {"id": 141, "seek": 49192, "start": 514.72, "end": 518.16, "text": " and it will create this Mandobrot pillar.", "tokens": [51504, 293, 309, 486, 1884, 341, 15458, 996, 10536, 27592, 13, 51676], "temperature": 0.0, "avg_logprob": -0.08846127135413033, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.0018100370652973652}, {"id": 142, "seek": 51816, "start": 518.16, "end": 522.0799999999999, "text": " It's actually a 3D shape, but it's just a bunch of 2D Mandobrot", "tokens": [50364, 467, 311, 767, 257, 805, 35, 3909, 11, 457, 309, 311, 445, 257, 3840, 295, 568, 35, 15458, 996, 10536, 50560], "temperature": 0.0, "avg_logprob": -0.08811036152626152, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.03208024799823761}, {"id": 143, "seek": 51816, "start": 522.0799999999999, "end": 524.16, "text": " slices stacked on top of each other.", "tokens": [50560, 19793, 28867, 322, 1192, 295, 1184, 661, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08811036152626152, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.03208024799823761}, {"id": 144, "seek": 51816, "start": 524.16, "end": 527.04, "text": " You could definitely change the script so it outputs one slice,", "tokens": [50664, 509, 727, 2138, 1319, 264, 5755, 370, 309, 23930, 472, 13153, 11, 50808], "temperature": 0.0, "avg_logprob": -0.08811036152626152, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.03208024799823761}, {"id": 145, "seek": 51816, "start": 527.04, "end": 529.8399999999999, "text": " but I just deleted every slice but one.", "tokens": [50808, 457, 286, 445, 22981, 633, 13153, 457, 472, 13, 50948], "temperature": 0.0, "avg_logprob": -0.08811036152626152, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.03208024799823761}, {"id": 146, "seek": 51816, "start": 529.8399999999999, "end": 533.76, "text": " We're going to quickly hop into geometry notes and actually make something cool out of this.", "tokens": [50948, 492, 434, 516, 281, 2661, 3818, 666, 18426, 5570, 293, 767, 652, 746, 1627, 484, 295, 341, 13, 51144], "temperature": 0.0, "avg_logprob": -0.08811036152626152, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.03208024799823761}, {"id": 147, "seek": 51816, "start": 533.76, "end": 536.16, "text": " So a quick way to make this look interesting is just", "tokens": [51144, 407, 257, 1702, 636, 281, 652, 341, 574, 1880, 307, 445, 51264], "temperature": 0.0, "avg_logprob": -0.08811036152626152, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.03208024799823761}, {"id": 148, "seek": 51816, "start": 536.16, "end": 538.48, "text": " instancing cubes on every point.", "tokens": [51264, 1058, 8779, 25415, 322, 633, 935, 13, 51380], "temperature": 0.0, "avg_logprob": -0.08811036152626152, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.03208024799823761}, {"id": 149, "seek": 51816, "start": 538.48, "end": 540.7199999999999, "text": " We're going to grab an instance on points node", "tokens": [51380, 492, 434, 516, 281, 4444, 364, 5197, 322, 2793, 9984, 51492], "temperature": 0.0, "avg_logprob": -0.08811036152626152, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.03208024799823761}, {"id": 150, "seek": 51816, "start": 541.8399999999999, "end": 545.6, "text": " and just add them right here, and then we're going to create a cube as well.", "tokens": [51548, 293, 445, 909, 552, 558, 510, 11, 293, 550, 321, 434, 516, 281, 1884, 257, 13728, 382, 731, 13, 51736], "temperature": 0.0, "avg_logprob": -0.08811036152626152, "compression_ratio": 1.7363013698630136, "no_speech_prob": 0.03208024799823761}, {"id": 151, "seek": 54560, "start": 546.0, "end": 553.84, "text": " And set the size to 0.01 and let's just connect this to our mesh.", "tokens": [50384, 400, 992, 264, 2744, 281, 1958, 13, 10607, 293, 718, 311, 445, 1745, 341, 281, 527, 17407, 13, 50776], "temperature": 0.0, "avg_logprob": -0.13018139203389487, "compression_ratio": 1.5316455696202531, "no_speech_prob": 0.020326809957623482}, {"id": 152, "seek": 54560, "start": 554.8000000000001, "end": 558.4, "text": " And yeah, we have this pretty nice looking grid.", "tokens": [50824, 400, 1338, 11, 321, 362, 341, 1238, 1481, 1237, 10748, 13, 51004], "temperature": 0.0, "avg_logprob": -0.13018139203389487, "compression_ratio": 1.5316455696202531, "no_speech_prob": 0.020326809957623482}, {"id": 153, "seek": 54560, "start": 558.4, "end": 560.48, "text": " Obviously, this is just a static mesh.", "tokens": [51004, 7580, 11, 341, 307, 445, 257, 13437, 17407, 13, 51108], "temperature": 0.0, "avg_logprob": -0.13018139203389487, "compression_ratio": 1.5316455696202531, "no_speech_prob": 0.020326809957623482}, {"id": 154, "seek": 54560, "start": 560.48, "end": 562.32, "text": " It doesn't grow or anything.", "tokens": [51108, 467, 1177, 380, 1852, 420, 1340, 13, 51200], "temperature": 0.0, "avg_logprob": -0.13018139203389487, "compression_ratio": 1.5316455696202531, "no_speech_prob": 0.020326809957623482}, {"id": 155, "seek": 54560, "start": 562.32, "end": 565.6800000000001, "text": " If you want to change the parameters, you'd have to generate a new one.", "tokens": [51200, 759, 291, 528, 281, 1319, 264, 9834, 11, 291, 1116, 362, 281, 8460, 257, 777, 472, 13, 51368], "temperature": 0.0, "avg_logprob": -0.13018139203389487, "compression_ratio": 1.5316455696202531, "no_speech_prob": 0.020326809957623482}, {"id": 156, "seek": 54560, "start": 565.6800000000001, "end": 568.08, "text": " Over here, I have this Mandobob as well.", "tokens": [51368, 4886, 510, 11, 286, 362, 341, 15458, 996, 996, 382, 731, 13, 51488], "temperature": 0.0, "avg_logprob": -0.13018139203389487, "compression_ratio": 1.5316455696202531, "no_speech_prob": 0.020326809957623482}, {"id": 157, "seek": 54560, "start": 568.08, "end": 571.36, "text": " We can quickly give it the geometry nodes group.", "tokens": [51488, 492, 393, 2661, 976, 309, 264, 18426, 13891, 1594, 13, 51652], "temperature": 0.0, "avg_logprob": -0.13018139203389487, "compression_ratio": 1.5316455696202531, "no_speech_prob": 0.020326809957623482}, {"id": 158, "seek": 54560, "start": 571.36, "end": 572.32, "text": " Yeah, there we go.", "tokens": [51652, 865, 11, 456, 321, 352, 13, 51700], "temperature": 0.0, "avg_logprob": -0.13018139203389487, "compression_ratio": 1.5316455696202531, "no_speech_prob": 0.020326809957623482}, {"id": 159, "seek": 57232, "start": 572.6400000000001, "end": 576.48, "text": " Of course, we can also use these points to create a mesh.", "tokens": [50380, 2720, 1164, 11, 321, 393, 611, 764, 613, 2793, 281, 1884, 257, 17407, 13, 50572], "temperature": 0.0, "avg_logprob": -0.11917687219286723, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.003483024425804615}, {"id": 160, "seek": 57232, "start": 576.48, "end": 580.8000000000001, "text": " Let's again create a new geometry nodes group and let's add a mesh to points node", "tokens": [50572, 961, 311, 797, 1884, 257, 777, 18426, 13891, 1594, 293, 718, 311, 909, 257, 17407, 281, 2793, 9984, 50788], "temperature": 0.0, "avg_logprob": -0.11917687219286723, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.003483024425804615}, {"id": 161, "seek": 57232, "start": 580.8000000000001, "end": 583.84, "text": " because these are actually vertices and not points.", "tokens": [50788, 570, 613, 366, 767, 32053, 293, 406, 2793, 13, 50940], "temperature": 0.0, "avg_logprob": -0.11917687219286723, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.003483024425804615}, {"id": 162, "seek": 57232, "start": 583.84, "end": 586.5600000000001, "text": " Next, we're going to add a points to volume node.", "tokens": [50940, 3087, 11, 321, 434, 516, 281, 909, 257, 2793, 281, 5523, 9984, 13, 51076], "temperature": 0.0, "avg_logprob": -0.11917687219286723, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.003483024425804615}, {"id": 163, "seek": 57232, "start": 587.9200000000001, "end": 590.0, "text": " And let's just play around with these settings a little bit.", "tokens": [51144, 400, 718, 311, 445, 862, 926, 365, 613, 6257, 257, 707, 857, 13, 51248], "temperature": 0.0, "avg_logprob": -0.11917687219286723, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.003483024425804615}, {"id": 164, "seek": 57232, "start": 590.0, "end": 595.2800000000001, "text": " The radius is way too high, so let's put it at 0.1 is too small, maybe 0.2.", "tokens": [51248, 440, 15845, 307, 636, 886, 1090, 11, 370, 718, 311, 829, 309, 412, 1958, 13, 16, 307, 886, 1359, 11, 1310, 1958, 13, 17, 13, 51512], "temperature": 0.0, "avg_logprob": -0.11917687219286723, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.003483024425804615}, {"id": 165, "seek": 57232, "start": 596.08, "end": 601.5200000000001, "text": " We can still barely see it, so let's just create a volume to mesh node next.", "tokens": [51552, 492, 393, 920, 10268, 536, 309, 11, 370, 718, 311, 445, 1884, 257, 5523, 281, 17407, 9984, 958, 13, 51824], "temperature": 0.0, "avg_logprob": -0.11917687219286723, "compression_ratio": 1.7432950191570882, "no_speech_prob": 0.003483024425804615}, {"id": 166, "seek": 60232, "start": 602.5600000000001, "end": 607.12, "text": " If we want a more detailed shape, let's up the voxel threshold to 500.", "tokens": [50376, 759, 321, 528, 257, 544, 9942, 3909, 11, 718, 311, 493, 264, 1650, 87, 338, 14678, 281, 5923, 13, 50604], "temperature": 0.0, "avg_logprob": -0.08232311188705324, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.001700598280876875}, {"id": 167, "seek": 60232, "start": 607.12, "end": 607.6800000000001, "text": " There we go.", "tokens": [50604, 821, 321, 352, 13, 50632], "temperature": 0.0, "avg_logprob": -0.08232311188705324, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.001700598280876875}, {"id": 168, "seek": 60232, "start": 607.6800000000001, "end": 610.6400000000001, "text": " That's already looking more like a fractal.", "tokens": [50632, 663, 311, 1217, 1237, 544, 411, 257, 17948, 304, 13, 50780], "temperature": 0.0, "avg_logprob": -0.08232311188705324, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.001700598280876875}, {"id": 169, "seek": 60232, "start": 610.6400000000001, "end": 615.2, "text": " And we can also play with the threshold of the volume to mesh node a little bit if we want to.", "tokens": [50780, 400, 321, 393, 611, 862, 365, 264, 14678, 295, 264, 5523, 281, 17407, 9984, 257, 707, 857, 498, 321, 528, 281, 13, 51008], "temperature": 0.0, "avg_logprob": -0.08232311188705324, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.001700598280876875}, {"id": 170, "seek": 60232, "start": 615.84, "end": 617.7600000000001, "text": " So yeah, we have a very quick Mandobob set.", "tokens": [51040, 407, 1338, 11, 321, 362, 257, 588, 1702, 15458, 996, 996, 992, 13, 51136], "temperature": 0.0, "avg_logprob": -0.08232311188705324, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.001700598280876875}, {"id": 171, "seek": 60232, "start": 617.7600000000001, "end": 621.2, "text": " I suggest just try asking a lot of questions to the AI.", "tokens": [51136, 286, 3402, 445, 853, 3365, 257, 688, 295, 1651, 281, 264, 7318, 13, 51308], "temperature": 0.0, "avg_logprob": -0.08232311188705324, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.001700598280876875}, {"id": 172, "seek": 60232, "start": 621.2, "end": 626.0, "text": " Ask them in different ways and it will give you some surprising stuff.", "tokens": [51308, 12320, 552, 294, 819, 2098, 293, 309, 486, 976, 291, 512, 8830, 1507, 13, 51548], "temperature": 0.0, "avg_logprob": -0.08232311188705324, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.001700598280876875}, {"id": 173, "seek": 60232, "start": 626.0, "end": 629.44, "text": " Actually, one thing that I can't even explain is this thing.", "tokens": [51548, 5135, 11, 472, 551, 300, 286, 393, 380, 754, 2903, 307, 341, 551, 13, 51720], "temperature": 0.0, "avg_logprob": -0.08232311188705324, "compression_ratio": 1.5818815331010454, "no_speech_prob": 0.001700598280876875}, {"id": 174, "seek": 62944, "start": 629.6800000000001, "end": 634.8000000000001, "text": " It was a similar kind of point cloud setup and then change it into a mesh.", "tokens": [50376, 467, 390, 257, 2531, 733, 295, 935, 4588, 8657, 293, 550, 1319, 309, 666, 257, 17407, 13, 50632], "temperature": 0.0, "avg_logprob": -0.17817193157268021, "compression_ratio": 1.596774193548387, "no_speech_prob": 0.0758199542760849}, {"id": 175, "seek": 62944, "start": 634.8000000000001, "end": 637.2, "text": " But what is even going on here?", "tokens": [50632, 583, 437, 307, 754, 516, 322, 510, 30, 50752], "temperature": 0.0, "avg_logprob": -0.17817193157268021, "compression_ratio": 1.596774193548387, "no_speech_prob": 0.0758199542760849}, {"id": 176, "seek": 62944, "start": 637.2, "end": 644.72, "text": " We can maybe see this inflection point right here, but I couldn't tell you how this shape works", "tokens": [50752, 492, 393, 1310, 536, 341, 1536, 5450, 935, 558, 510, 11, 457, 286, 2809, 380, 980, 291, 577, 341, 3909, 1985, 51128], "temperature": 0.0, "avg_logprob": -0.17817193157268021, "compression_ratio": 1.596774193548387, "no_speech_prob": 0.0758199542760849}, {"id": 177, "seek": 62944, "start": 644.72, "end": 646.24, "text": " or what it looks like.", "tokens": [51128, 420, 437, 309, 1542, 411, 13, 51204], "temperature": 0.0, "avg_logprob": -0.17817193157268021, "compression_ratio": 1.596774193548387, "no_speech_prob": 0.0758199542760849}, {"id": 178, "seek": 62944, "start": 646.24, "end": 650.48, "text": " If you recognize this shape, if it has a name, let me know in the comments below", "tokens": [51204, 759, 291, 5521, 341, 3909, 11, 498, 309, 575, 257, 1315, 11, 718, 385, 458, 294, 264, 3053, 2507, 51416], "temperature": 0.0, "avg_logprob": -0.17817193157268021, "compression_ratio": 1.596774193548387, "no_speech_prob": 0.0758199542760849}, {"id": 179, "seek": 62944, "start": 650.48, "end": 654.24, "text": " because it just looks so asymmetrical and abstract.", "tokens": [51416, 570, 309, 445, 1542, 370, 37277, 32283, 293, 12649, 13, 51604], "temperature": 0.0, "avg_logprob": -0.17817193157268021, "compression_ratio": 1.596774193548387, "no_speech_prob": 0.0758199542760849}, {"id": 180, "seek": 62944, "start": 654.24, "end": 656.4000000000001, "text": " And yeah, the AI just generated this.", "tokens": [51604, 400, 1338, 11, 264, 7318, 445, 10833, 341, 13, 51712], "temperature": 0.0, "avg_logprob": -0.17817193157268021, "compression_ratio": 1.596774193548387, "no_speech_prob": 0.0758199542760849}, {"id": 181, "seek": 65640, "start": 656.88, "end": 661.12, "text": " It generated a point cloud and then I just did the same as we did before with the Mandobob", "tokens": [50388, 467, 10833, 257, 935, 4588, 293, 550, 286, 445, 630, 264, 912, 382, 321, 630, 949, 365, 264, 15458, 996, 996, 50600], "temperature": 0.0, "avg_logprob": -0.09305877961974213, "compression_ratio": 1.6592356687898089, "no_speech_prob": 0.04956592991948128}, {"id": 182, "seek": 65640, "start": 661.12, "end": 661.4399999999999, "text": " set.", "tokens": [50600, 992, 13, 50616], "temperature": 0.0, "avg_logprob": -0.09305877961974213, "compression_ratio": 1.6592356687898089, "no_speech_prob": 0.04956592991948128}, {"id": 183, "seek": 65640, "start": 661.4399999999999, "end": 664.9599999999999, "text": " Just converted it to a mesh and yeah, pretty neat.", "tokens": [50616, 1449, 16424, 309, 281, 257, 17407, 293, 1338, 11, 1238, 10654, 13, 50792], "temperature": 0.0, "avg_logprob": -0.09305877961974213, "compression_ratio": 1.6592356687898089, "no_speech_prob": 0.04956592991948128}, {"id": 184, "seek": 65640, "start": 664.9599999999999, "end": 666.8, "text": " Couldn't have made this myself for sure.", "tokens": [50792, 35800, 380, 362, 1027, 341, 2059, 337, 988, 13, 50884], "temperature": 0.0, "avg_logprob": -0.09305877961974213, "compression_ratio": 1.6592356687898089, "no_speech_prob": 0.04956592991948128}, {"id": 185, "seek": 65640, "start": 667.6, "end": 670.48, "text": " So yeah, that concludes our introduction to GPT Chat.", "tokens": [50924, 407, 1338, 11, 300, 24643, 527, 9339, 281, 26039, 51, 27503, 13, 51068], "temperature": 0.0, "avg_logprob": -0.09305877961974213, "compression_ratio": 1.6592356687898089, "no_speech_prob": 0.04956592991948128}, {"id": 186, "seek": 65640, "start": 670.48, "end": 673.04, "text": " It has some very interesting use cases.", "tokens": [51068, 467, 575, 512, 588, 1880, 764, 3331, 13, 51196], "temperature": 0.0, "avg_logprob": -0.09305877961974213, "compression_ratio": 1.6592356687898089, "no_speech_prob": 0.04956592991948128}, {"id": 187, "seek": 65640, "start": 673.04, "end": 677.52, "text": " Let me know in the comments what is the craziest response you got from GPT Chat.", "tokens": [51196, 961, 385, 458, 294, 264, 3053, 437, 307, 264, 46339, 4134, 291, 658, 490, 26039, 51, 27503, 13, 51420], "temperature": 0.0, "avg_logprob": -0.09305877961974213, "compression_ratio": 1.6592356687898089, "no_speech_prob": 0.04956592991948128}, {"id": 188, "seek": 65640, "start": 677.52, "end": 678.9599999999999, "text": " I would love to know.", "tokens": [51420, 286, 576, 959, 281, 458, 13, 51492], "temperature": 0.0, "avg_logprob": -0.09305877961974213, "compression_ratio": 1.6592356687898089, "no_speech_prob": 0.04956592991948128}, {"id": 189, "seek": 65640, "start": 678.9599999999999, "end": 681.36, "text": " Without further ado, I'll catch you next time.", "tokens": [51492, 9129, 3052, 22450, 11, 286, 603, 3745, 291, 958, 565, 13, 51612], "temperature": 0.0, "avg_logprob": -0.09305877961974213, "compression_ratio": 1.6592356687898089, "no_speech_prob": 0.04956592991948128}, {"id": 190, "seek": 65640, "start": 681.36, "end": 685.1999999999999, "text": " Leave a like on this video if you find it interesting and subscribe for future tutorials.", "tokens": [51612, 9825, 257, 411, 322, 341, 960, 498, 291, 915, 309, 1880, 293, 3022, 337, 2027, 17616, 13, 51804], "temperature": 0.0, "avg_logprob": -0.09305877961974213, "compression_ratio": 1.6592356687898089, "no_speech_prob": 0.04956592991948128}, {"id": 191, "seek": 68520, "start": 685.9200000000001, "end": 687.5200000000001, "text": " There are building something here.", "tokens": [50400, 821, 366, 2390, 746, 510, 13, 50480], "temperature": 0.0, "avg_logprob": -0.18321990966796875, "compression_ratio": 1.1584158415841583, "no_speech_prob": 0.10208757221698761}, {"id": 192, "seek": 68520, "start": 687.5200000000001, "end": 691.76, "text": " It's been a hell to actually make this video, but I'll see you next time.", "tokens": [50480, 467, 311, 668, 257, 4921, 281, 767, 652, 341, 960, 11, 457, 286, 603, 536, 291, 958, 565, 13, 50692], "temperature": 0.0, "avg_logprob": -0.18321990966796875, "compression_ratio": 1.1584158415841583, "no_speech_prob": 0.10208757221698761}, {"id": 193, "seek": 68520, "start": 691.76, "end": 692.4000000000001, "text": " Bye bye.", "tokens": [50692, 4621, 6543, 13, 50724], "temperature": 0.0, "avg_logprob": -0.18321990966796875, "compression_ratio": 1.1584158415841583, "no_speech_prob": 0.10208757221698761}], "language": "en"}