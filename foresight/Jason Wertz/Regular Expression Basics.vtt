WEBVTT

00:00.000 --> 00:07.200
In this video lecture we're going to talk about regular expressions.

00:07.200 --> 00:11.360
We'll also take a look at the command line utilities grep and sed.

00:11.360 --> 00:13.080
So what are regular expressions?

00:13.080 --> 00:19.400
Well regular expressions are patterns that we can build to match against specific series

00:19.400 --> 00:25.020
of characters, you know, words, in a programming sense we can say strings.

00:25.020 --> 00:29.800
We can use these patterns to pull out specific pieces of information from a larger set of

00:29.800 --> 00:31.720
information that we're interested in.

00:31.720 --> 00:37.400
So if we're looking at something like a very large log file, we can use a regular expression

00:37.400 --> 00:41.560
to just isolate those aspects of the log file that we're interested in.

00:41.560 --> 00:47.400
This is really great when you've got a lot of data to pick through on the command line.

00:47.400 --> 00:51.920
We can also use regular expressions for finding data and then acting upon it and we'll take

00:51.920 --> 00:56.480
a brief look at sed which is the stream editor later on in this video lecture.

00:56.480 --> 01:02.040
So for now we're going to look at mostly a tool called grep which allows us to show

01:02.040 --> 01:09.080
or not show specific aspects of a file that conform to one of our regular expression patterns.

01:09.080 --> 01:16.600
So the command line grep utility is used to apply patterns to either standard input or

01:16.600 --> 01:18.800
to a specific file.

01:18.800 --> 01:23.000
And so we might have a very large file and what we're interested in doing is just taking

01:23.000 --> 01:25.360
a look at certain aspects of it.

01:25.360 --> 01:30.480
There's actually two forms of grep and grep stands for get regular expression and there's

01:30.480 --> 01:31.480
also grep and egrep.

01:31.480 --> 01:37.120
And what you're going to find is that because Unix is so old, it's had a lot of time to evolve

01:37.120 --> 01:42.120
and sometimes people have gone on and extended aspects of Unix and in their sense of making

01:42.120 --> 01:43.120
it better.

01:43.120 --> 01:47.920
So the idea of grep and egrep is that grep is the original grep and egrep is extended

01:47.920 --> 01:48.920
grep.

01:48.920 --> 01:52.120
And extended grep actually supports extended regular expressions.

01:52.120 --> 01:56.360
So anytime a language has been around for a long time, people try to start to add to

01:56.360 --> 02:00.200
it when they start to notice failings in that language.

02:00.200 --> 02:06.240
And what I'll mention is that we'll look at both extended and regular, regular expressions.

02:06.240 --> 02:08.880
There's also pearl regular expressions, which I'm most familiar with.

02:08.880 --> 02:12.380
So I also throw that out there when I'm talking about regular expressions.

02:12.380 --> 02:16.900
Anytime I make an error, I will probably be thinking in terms of pearl regular expressions.

02:16.900 --> 02:22.560
So enough about what regular expressions are, what utilities we're going to use, what

02:22.560 --> 02:28.140
does a regular expression do and look like?

02:28.140 --> 02:35.040
Let's think about a typical pattern that we might want to apply in this case.

02:35.040 --> 02:40.140
Let's say that I have asked someone to look through the phone book or a directory of employees

02:40.140 --> 02:44.860
and show me everybody whose last name starts with the letter s.

02:44.860 --> 02:46.020
So I've given you a pattern.

02:46.020 --> 02:48.300
I've given you a few bits of information.

02:48.300 --> 02:57.820
I've said, okay, I want you to look at last name, oops, and I want that last name to start

02:57.820 --> 02:59.580
with the letter s.

02:59.580 --> 03:10.420
So if I have somebody whose name is, right, like John Smith, this would match my pattern

03:10.420 --> 03:15.700
because I look at the last name and the first letter of that last name is an s.

03:15.700 --> 03:23.260
Their name was Steve, John, I guess we'll stick with people with two first names.

03:23.260 --> 03:28.860
Well, the first name starts with the letter s, but the last name doesn't, so it doesn't

03:28.860 --> 03:30.220
match my pattern.

03:30.220 --> 03:37.660
So we define patterns and we do so programmatically and we use those patterns to filter or match

03:37.660 --> 03:44.340
against information that we're most interested in.

03:45.060 --> 03:50.180
Let's look at some really basic ways that we can apply patterns on the command line.

03:50.180 --> 03:55.820
I'm currently in my home directory and there's a number of folders and at least two files

03:55.820 --> 03:57.420
in my home directory.

03:57.420 --> 04:03.980
So there's actually some basic pattern matching capabilities built into the Bash shell.

04:03.980 --> 04:07.020
So for example, if I want to see all of the folders that start with the capital letter

04:07.020 --> 04:12.820
d, notice that if I just put the letter d, I get an error because it's going to say,

04:12.820 --> 04:20.900
I can't find a folder or file named d, but if I add a star after the word d, I get a

04:20.900 --> 04:22.580
lot of information.

04:22.580 --> 04:27.460
In fact, I wanted to look just for folders, I would do dash d, which would give me information

04:27.460 --> 04:32.100
about the directories as opposed to items inside the directories.

04:32.100 --> 04:38.100
And this star character on the shell is called the file glob operator and basically you can

04:38.100 --> 04:40.460
think of it like a wild card match.

04:40.460 --> 04:45.140
And the pattern that I've essentially given the ls command here is that the ls command

04:45.140 --> 04:51.140
should display all folders that start with the capital d and then folders that have any

04:51.140 --> 04:53.580
number of characters following it.

04:53.580 --> 04:58.980
So when I mean wild card, I mean any number from zero to an infinite amount and I mean

04:58.980 --> 05:00.340
any type of character.

05:00.340 --> 05:05.580
So basically this would match any folder that starts with d and goes ahead and has a bunch

05:05.580 --> 05:07.340
of stuff in front of it.

05:07.340 --> 05:11.500
You can also use a wild card at the front of a string, so I'm going to see any folder

05:11.500 --> 05:16.900
that starts with the letter s and notice it shows me documents, downloads, pictures, templates

05:16.900 --> 05:19.660
and videos because all of those end with a lower case s.

05:19.660 --> 05:24.660
And remember that the command line is case sensitive, so if I do capital s, I get nothing.

05:24.660 --> 05:28.980
You can also do something along the lines of putting two stars on the command line.

05:28.980 --> 05:33.700
So I could say something like show me all directories that have any number of characters,

05:33.700 --> 05:38.380
the letter l in them and then any number of characters on the other side.

05:38.380 --> 05:42.820
And in this case it shows me downloads, examples.desktop, public and templates because all of these

05:42.820 --> 05:47.540
have a letter l in the middle that we can see in each one of these and on either side

05:47.540 --> 05:54.020
there is any given number of characters that match this wild card pattern.

05:54.020 --> 05:58.020
So this is built into the shell and this can be really useful if you wanted to show say

05:58.020 --> 06:01.460
all files in a directory and so if we look back up into the shell it will notice that

06:01.460 --> 06:05.140
in my desktop directory I have a couple .txt files.

06:05.140 --> 06:13.820
Let's clear this and let's say I wanted to do ls-l desktop star .txt and what this would

06:13.820 --> 06:19.220
do is say okay go into my desktop directory, show me files that have any name and then

06:19.220 --> 06:27.980
have a .txt extension and if I hit enter I see those two files sitting in my home directory.

06:27.980 --> 06:33.740
So pretty cool that those exist and that this capability exists.

06:33.740 --> 06:39.140
But what we want to do is we want to actually look at how we can utilize grep to get more

06:39.140 --> 06:46.260
detail information about things like file directory listings and actual files themselves.

06:46.260 --> 06:49.860
So ls is great when you're looking for just information about some listings and the wild

06:49.860 --> 06:54.180
card is helpful for getting some basic pattern matching going.

06:54.180 --> 06:56.860
But to learn regular expressions what we're going to do is we're going to look at a very

06:56.860 --> 07:05.020
specific file on the Unix system and that file is the American English dictionary used

07:05.020 --> 07:07.620
for spell checking and other things by the system.

07:07.620 --> 07:11.500
So I'm going to pass the American English dictionary file which is found in slash user

07:11.500 --> 07:15.940
slash share slash dict slash American English into the less command so we can see what's

07:15.940 --> 07:22.020
in there and what you'll notice is this is a very large file that goes on and on and

07:22.020 --> 07:26.060
on and on and keeps going and there's lots of words in it.

07:26.060 --> 07:32.820
So this is really useful for our pattern matching exercises so I'm going to hit Q and we're

07:32.820 --> 07:38.820
going to start to talk about some really basic regular expressions.

07:38.820 --> 07:42.740
And the way we're going to do this is we're going to actually use the command grep.

07:42.740 --> 07:45.640
Remember that I had mentioned there are actually grep and egrep.

07:45.640 --> 07:47.900
So what we'll do is we'll use grep until it breaks.

07:47.900 --> 07:51.140
In other words we'll use grep until we run into a feature that is an extended regular

07:51.140 --> 07:55.900
expression and then we will jump over to using the egrep command.

07:55.900 --> 08:00.100
Actually it's a better habit to just get into using egrep all the time and that way

08:00.100 --> 08:04.940
you don't have to worry about what is an extended and what isn't an extended regular expression.

08:04.940 --> 08:08.660
But I kind of want to mention, show you that at some point some of these features will

08:08.660 --> 08:09.660
not work.

08:09.660 --> 08:19.380
So I am going to actually set this up so that we can grep this file and the way greps work

08:19.380 --> 08:25.660
is that we give the grep command what we'll do is right in here we'll put a pattern and

08:25.660 --> 08:29.700
then we will actually go ahead and match it against a file.

08:29.700 --> 08:33.700
And so the easiest pattern that I can put in here is I want to look for say words that

08:33.700 --> 08:34.700
have cat in it.

08:34.700 --> 08:38.460
So let's use cat and see what we get.

08:38.460 --> 08:41.900
What you'll notice is a lot of words scroll by.

08:41.900 --> 08:46.420
I gave the pattern cat and maybe you were thinking well I'll only see the word cat but

08:46.420 --> 08:52.700
notice that it shows me every word in the file that has the letters cat somewhere in

08:52.700 --> 08:53.700
the word.

08:53.740 --> 08:58.140
So that's what the color coded command line is we can actually see the matches.

08:58.140 --> 09:03.340
So that's kind of a nice feature for learning how to use regular expressions.

09:03.340 --> 09:07.300
And you'll also notice that this is a really big file so at some point we'll look at we're

09:07.300 --> 09:10.020
always going to see letters at the end of the alphabet just because of the way we're

09:10.020 --> 09:11.020
doing this.

09:11.020 --> 09:15.020
So let's clear this and take a look at that pattern again.

09:15.020 --> 09:21.500
My pattern is called cat and for the rest of the exercise is the other things or is cat.

09:21.500 --> 09:24.100
And I'm going to put these in double quotes because it'll make it a little bit easier to

09:24.100 --> 09:30.660
see where our pattern is within these lectures and it'll also help us deal with any non-standard

09:30.660 --> 09:31.660
characters.

09:31.660 --> 09:35.340
In other words any characters that we want to match in our pattern but have special meaning

09:35.340 --> 09:39.980
to the shell we want to make sure that those are not processed by the shell in a way that

09:39.980 --> 09:44.100
the shell wants to process them putting them in double quotes kind of fixes that.

09:44.100 --> 09:45.620
So what does this pattern say?

09:45.620 --> 09:50.660
It says well look for a C followed by an A followed by a T and what you found out again

09:50.660 --> 09:54.940
is when I run that command it doesn't really care if there's any characters before the

09:54.940 --> 10:02.700
cat or after the word cat it just looks for those three characters in order.

10:02.700 --> 10:05.540
So that's pretty interesting.

10:05.540 --> 10:11.460
What if we wanted to look for not just cat but you were wondering like well I wonder

10:11.460 --> 10:15.940
if there's a word that looks like cat that has another word in the middle.

10:15.940 --> 10:22.380
And maybe you were thinking of like cut or cot and you wanted to find all of these.

10:22.380 --> 10:26.180
Well regular expressions come with a special character which is the dot character and the

10:26.180 --> 10:30.420
dot character will match one of any character.

10:30.420 --> 10:39.920
So if there's actually a word called C2T then putting a dot there would match it.

10:39.920 --> 10:45.060
So what this will match is a C followed by any one character followed by the letter T.

10:46.060 --> 10:50.740
So you can just see in this little bit of information that we got I didn't even think

10:50.740 --> 10:55.060
about words like yachts which have Cht or watchtower.

10:55.060 --> 11:03.420
So we matched Cht, Cat, Cut, Cot and that's pretty cool.

11:03.420 --> 11:04.420
Why?

11:04.420 --> 11:07.580
Because the pattern used a dot.

11:07.580 --> 11:11.180
So let's talk about why this is and let's look at some other patterns that we might have

11:11.180 --> 11:13.020
available to us.

11:13.020 --> 11:16.220
So what we just looked at was this idea of basic elements.

11:16.220 --> 11:20.580
You can literally type a string and that will match the string or the series of characters

11:20.580 --> 11:26.020
and in this case we can also then use dots in our series of characters to represent any

11:26.020 --> 11:29.420
given one instance of any given character.

11:29.420 --> 11:32.500
So notice my first example matches bat, cat, mat.

11:32.500 --> 11:37.420
Finally if I just give the letters DOG it would match the literal string dog but found

11:37.420 --> 11:40.940
anywhere in a word.

11:41.020 --> 11:45.100
What's cool with regular expressions is we can start to get tricky.

11:45.100 --> 11:49.380
And so in our previous example we found we used the dot to find any character but let's

11:49.380 --> 11:54.620
say we only wanted to limit ourselves to finding a subset of any character and we can actually

11:54.620 --> 11:57.380
create what are called classes of characters.

11:57.380 --> 12:02.180
So we can have classes of characters by putting them into hard brackets and A-C will search

12:02.180 --> 12:10.540
for an A or a B or a C followed by an A and a T and this would match bat and cat but not

12:10.620 --> 12:11.620
rat.

12:11.620 --> 12:14.260
And let's take a look at this in the command line in a second.

12:14.260 --> 12:21.620
You can also use character classes to find uppercase, lowercase as well as numbers within

12:21.620 --> 12:22.620
your strings.

12:22.620 --> 12:26.500
Now again this is not looking for the number nine, this is looking for the character nine,

12:26.500 --> 12:28.620
the symbol that represents the value nine.

12:28.620 --> 12:35.180
So this is really just looking for a character zero through nine followed by another character

12:35.180 --> 12:39.340
zero through nine and this would match forty two, thirty seven, ninety nine, zero one.

12:39.340 --> 12:45.220
So basically match any two characters next to each other anywhere in a word.

12:45.220 --> 12:47.180
So let's take a look at that.

12:47.180 --> 12:55.100
So previously when we used the C dot T we matched cut, cat, cut.

12:55.100 --> 12:57.180
So the O, the A and the U.

12:57.180 --> 13:02.540
So let's say I don't want these watchtowers, CHT, I just want like C followed by a vowel

13:02.540 --> 13:05.820
followed by a T.

13:05.820 --> 13:11.380
So we can do that instead of using the dot I can create a character class.

13:11.380 --> 13:19.300
And if I want I can try to match any vowel, I don't know what we'll get but we'll see.

13:19.300 --> 13:24.620
And so what this says is look for the letter C followed by A, E, I, O, or U, just one of

13:24.620 --> 13:28.300
those but it can choose amongst all of the values in that set followed by the letter

13:28.300 --> 13:30.100
T.

13:30.100 --> 13:39.340
And now if I look at my output I get veracity, I get wainscot, I get vocatives, I get wildcat

13:39.340 --> 13:47.540
so I'm matching all the vowels between the letters C and T. All because of this character

13:47.540 --> 13:50.140
set that I've made.

13:50.140 --> 13:53.300
If you want to try and find any words in the dictionary, so that's character sets.

13:53.300 --> 13:56.820
And by the way you can use these and we'll see these in a second, if you want to match

13:56.820 --> 14:01.860
all lowercase characters you would do A through Z. You can also say find all lowercase and

14:01.860 --> 14:07.100
all uppercase characters which maybe you're looking for usernames or something along those

14:07.100 --> 14:08.100
lines.

14:08.100 --> 14:12.260
And then if you wanted to you could also add 0 through 9 and say like the underbar.

14:12.260 --> 14:15.740
And what that would do is match for all of those characters so you can have these sets

14:15.740 --> 14:19.820
of characters be as small or as large as you want them to be.

14:19.820 --> 14:24.180
I'm going to do is changes, let's see if there's any words that have 0 through 9, I doubt it.

14:24.180 --> 14:25.740
And nothing matches that pattern.

14:25.740 --> 14:29.260
That's what happens when you put in a pattern that doesn't match.

14:29.260 --> 14:32.500
Let's see if there's anything in the dictionary that matches against a number.

14:32.500 --> 14:38.020
Nope, so there are no numbers in the American English dictionary on the Unix system.

14:38.020 --> 14:40.020
So it's kind of helpful.

14:40.020 --> 14:45.340
There's a couple other things that we could actually use if we wanted to grep numbers.

14:45.340 --> 14:49.420
What I'll do right now is just to look at what we could possibly grep for a number would

14:49.420 --> 14:51.780
be the Etsy password file.

14:51.780 --> 14:54.220
And if I grep that I know there's a lot of numbers in there so I'm going to get a lot

14:54.220 --> 15:00.380
of matches and you'll notice that it matched all of these lines because all of the lines

15:00.380 --> 15:01.700
have a number in them.

15:01.700 --> 15:05.860
Again, the Etsy password files just shows you all the user accounts on the system and

15:05.860 --> 15:09.100
these numbers represent their user and group IDs.

15:09.100 --> 15:11.580
So I know that there were a lot of numeric matches in this file.

15:11.580 --> 15:17.540
So just to kind of demonstrate that you can match against numbers as well as words.

15:17.540 --> 15:20.900
So kind of helpful.

15:20.900 --> 15:25.340
Let's go back to an example where we can start to look at the English dictionary.

15:25.340 --> 15:31.780
So let's look at some other options for this feature, this ability to use character classes.

15:31.780 --> 15:37.980
Built into Unix is this idea of these really what I think are pretty ugly character classes.

15:37.980 --> 15:40.660
You'll see these sometimes built into the system.

15:40.660 --> 15:46.700
So bracket, bracket, colon, alpha, colon, bracket, bracket is the same as building your own character

15:46.700 --> 15:51.260
class that uses bracket A through Z, capital A through Z.

15:51.260 --> 15:57.100
And basically what these things on the left are are just ways of writing these out using

15:57.100 --> 16:01.660
words as opposed to using the categories A through Z.

16:01.660 --> 16:04.820
Pretty much if you haven't figured this out at this point in Unix, there's 50 ways to

16:04.820 --> 16:05.820
do everything.

16:05.820 --> 16:09.660
So these character class abbreviations can be helpful.

16:09.660 --> 16:11.860
They make things a little more readable in scripts.

16:11.860 --> 16:15.540
But the other thing if you haven't noticed is that regular expressions can get pretty

16:15.540 --> 16:18.900
big and pretty scary pretty fast.

16:18.900 --> 16:22.660
I would say the most useful character class that we're looking at right here is the one

16:22.660 --> 16:25.860
called space because that will match any white space characters.

16:25.860 --> 16:27.980
That includes tabs and spaces.

16:27.980 --> 16:33.300
That can be really helpful when trying to match words or sentences that have spaces.

16:33.300 --> 16:38.300
Or in my first example, we talked about last names and that would really be helpful for

16:38.300 --> 16:42.260
processing, finding somebody's last name.

16:42.260 --> 16:46.980
Because I don't like these, I'm mostly familiar with these character class abbreviations.

16:46.980 --> 16:49.460
So notice there's two character class abbreviations.

16:49.460 --> 16:53.020
The previous ones with the words like alpha, upper, and lower.

16:53.020 --> 16:58.580
But then there's also these character class abbreviations, slash D, slash W, slash S,

16:58.580 --> 17:05.420
slash S that make things a little bit more readable when we start to use these in larger

17:05.420 --> 17:06.980
regular expressions.

17:06.980 --> 17:10.820
I'll also mention that there are actually ways to negate character classes.

17:10.820 --> 17:17.060
If you notice the carrot inside of the bracket-based classes at the bottom here, you'll notice

17:17.060 --> 17:20.020
that that means does not match this character.

17:20.020 --> 17:25.580
And if you do slash capital D, slash capital W, slash capital S, that means that you do

17:25.580 --> 17:28.420
not want to match that character in that given position.

17:28.420 --> 17:31.620
I don't usually teach those when I introduce regular expressions because it's hard enough

17:31.620 --> 17:36.180
getting your head around regular expressions, let alone getting your head around negative

17:36.180 --> 17:37.540
logic at the same time.

17:37.540 --> 17:40.980
So we'll just kind of mention that they're there and just ignore that.

17:40.980 --> 17:48.540
So let's look at these two character class sets in operation.

17:48.540 --> 17:56.700
So let's say I want to find a word that has any letter in it.

17:56.700 --> 18:02.260
Well notice I just did that and I said that I wanted to find a slash D, but notice that

18:02.260 --> 18:06.780
it actually went ahead and found all of these words with the character D.

18:06.780 --> 18:07.780
Well that's a problem.

18:07.780 --> 18:13.260
You're thinking, well Jason, wait, you just showed us that slash D is a character class.

18:13.260 --> 18:14.260
But here's the thing.

18:14.260 --> 18:17.460
Remember earlier on I said there's grep and there's extended grep?

18:17.460 --> 18:20.140
Well these slash D character sets are actually part of extended grep.

18:20.140 --> 18:27.180
So if I switch to eGrep, it still doesn't work, which is a problem because I'm trying

18:27.180 --> 18:28.100
to explain this.

18:37.780 --> 18:43.380
Once you'll notice is that the slash D doesn't work, it actually goes ahead and finds the

18:43.380 --> 18:45.340
letter D within here.

18:45.340 --> 18:49.900
Slash D is actually a part of Perl regular expression.

18:49.900 --> 18:53.420
So if I actually add dash P, you'll note that it returns nothing.

18:53.420 --> 18:57.380
So that actually says u slash D, like it's a Perl regular expression and that'll pass

18:57.380 --> 18:58.380
numbers.

18:58.380 --> 19:01.060
So that doesn't actually work in grep or eGrep.

19:01.060 --> 19:05.540
But if I get rid of the dash P and just go with regular extended grep, what you'll find

19:05.540 --> 19:12.940
is I can actually utilize slash W. And that matches any character in any word that we

19:12.940 --> 19:13.940
might be looking at.

19:13.940 --> 19:16.380
So that one does work.

19:16.380 --> 19:22.580
And if we go ahead and we look at slash S, what you'll notice is that that also returns

19:22.580 --> 19:24.220
nothing.

19:24.220 --> 19:29.420
So it looks like slash D is one of those cases where that's more of a Perl thing than it

19:29.420 --> 19:31.900
is an extended grep thing.

19:31.900 --> 19:33.980
So I'll apologize for that and keep going.

19:33.980 --> 19:39.540
Or slash D is the same as typing 0 through 9.

19:39.540 --> 19:46.340
So you don't need to worry about the fact that slash D is not supported in eGrep.

19:46.340 --> 19:49.540
Let's take a look at some other ways that we can build patterns.

19:49.540 --> 19:54.260
We'll start out by taking a look at what are called anchors or positional anchors.

19:54.260 --> 19:58.980
In other words, we can say that a certain character has to match at a certain point on

19:58.980 --> 20:03.420
a line, either at the beginning of the line or at the end of the line.

20:03.420 --> 20:07.740
And you'll see that the characters that we're going to use for these beginning and end of

20:07.740 --> 20:12.740
line matches are a carrot and a dollar sign.

20:12.740 --> 20:17.100
And you'll notice that in the example in front of you, putting a carrot means to match only

20:17.100 --> 20:21.940
the word car, where car is the first line character on the line.

20:21.940 --> 20:28.020
So it would match car, cattle, and canine, where those are the first words on a line.

20:28.020 --> 20:31.660
And the second example, floating and sailing, would match because the G is at the end of

20:31.660 --> 20:34.580
the line if those are the only words on the line.

20:34.580 --> 20:39.380
And if you'd like to match situations where a word is the only word on a given line, such

20:39.380 --> 20:43.420
as cat, you would want a line that starts with the letter C, a line that ends with the

20:43.420 --> 20:46.060
letter T. We'll take a look at these in one second.

20:46.060 --> 20:50.460
Let's look at another possible anchor that we can use, which is a word boundary.

20:50.460 --> 20:54.500
So remember, the carrot character and the dollar sign character have to do with the beginning

20:54.500 --> 20:56.340
and the end of line.

20:56.340 --> 21:04.860
And word boundaries give us the ability to match on spaces, tabs, and basically these

21:04.860 --> 21:08.780
positions where there might be breaks between words.

21:08.780 --> 21:15.220
So in the example that I've got at the bottom, if I wanted to match Jason the prof, S-O-N

21:15.220 --> 21:17.300
is anchored on a word boundary.

21:17.300 --> 21:20.220
So there's a space between my name and the word the.

21:20.220 --> 21:23.300
So S-O-N slash B would match that line.

21:23.300 --> 21:27.340
Actually, there's no other instance of S-O-N on that line, but let's say I was in a file

21:27.340 --> 21:34.100
that had a lot of people named Jason, but I was the only one with the surname the prof.

21:34.100 --> 21:35.100
It would match.

21:35.100 --> 21:42.460
So let's take a look at how word boundaries and anchors work in real life.

21:42.460 --> 21:48.660
So to match items in word boundaries, we really need a file to do this.

21:48.660 --> 21:52.860
So what I'm going to do is take another look at the Etsy password file.

21:52.860 --> 21:57.100
I've also bumped up the font, so hopefully things are a little bit easier to see.

21:57.100 --> 22:00.940
So what you'll notice is in the Etsy password file, there's a number of lines here.

22:00.940 --> 22:04.500
So I've got root, demon, bin, sys.

22:04.500 --> 22:08.580
So let's say I only want to see lines that start with the letter S. There's a couple

22:08.580 --> 22:09.580
of them.

22:09.580 --> 22:15.020
So I'm going to use eGREP, and I'm going to say that I want to look at lines that start

22:15.020 --> 22:19.660
with the letter S, and I want to look at the Etsy password file.

22:19.660 --> 22:24.220
And what you'll notice is that shows me lines that just start with the letter S. Notice

22:24.220 --> 22:26.580
that the letter S might be in other parts of the line.

22:26.580 --> 22:32.780
If I take out that position qualifier, what you'll notice is that the letter S appears

22:32.780 --> 22:38.100
on many more lines, but I only want to be interested in those lines where the letter

22:38.100 --> 22:40.300
S is at the beginning.

22:41.060 --> 22:46.900
If I want to see which lines have at the end, the letter N, I can put a dollar sign, and

22:46.900 --> 22:51.860
it'll show me only the lines that end in the letter N. Let's try H. I was thinking bin,

22:51.860 --> 22:54.220
but I think I meant bash.

22:54.220 --> 23:02.060
And so what it'll show you is that many of these user accounts use the bash shell.

23:02.060 --> 23:06.820
And let's say, notice in this case I'm seeing bash and SH.

23:06.860 --> 23:12.460
Let's say I'm only concerned about those users in this file that have the login shell bash.

23:12.460 --> 23:15.220
So let's see how we can fix that.

23:15.220 --> 23:21.140
Instead of just saying H, I could say bash, and what this will say is the last letter

23:21.140 --> 23:27.940
on the line must be an H, but before it must come a B, A, and an S. And now I get exactly

23:27.940 --> 23:31.420
the information I want, lines that end with bash.

23:31.420 --> 23:40.980
So that's the concept behind positional values within regular expressions.

23:40.980 --> 23:45.420
What I have here is a file called demo that contains two lines.

23:45.420 --> 23:49.180
One is JSON space, the space prof, and the other line is JSONium.

23:49.180 --> 23:51.420
So maybe I have my own element.

23:51.420 --> 23:56.300
And if I grab this file for my name, what you're going to notice is that it shows me

23:56.300 --> 23:57.500
both lines.

23:57.580 --> 24:01.980
Maybe I only want to show those lines where it's actually my name and not my name embedded

24:01.980 --> 24:03.220
in another word.

24:03.220 --> 24:08.340
And the way I can do this is to add a word boundary to my regular expression.

24:08.340 --> 24:11.340
And remember slash B means word boundary.

24:11.340 --> 24:19.340
And so now it will only show me the JSON that is up against a word boundary.

24:19.340 --> 24:23.660
So it's pretty helpful when you know you have spaces in a file and you want to find words

24:23.660 --> 24:25.820
that you know are on a space.

24:25.820 --> 24:30.060
The last thing for us to review is the concept of quantifiers in a regular expression.

24:30.060 --> 24:35.420
Sometimes you want to look for zero or one or two or three of a certain character to

24:35.420 --> 24:37.140
appear in a certain spot.

24:37.140 --> 24:41.420
Other times you want to know exactly a specific number of items that you want to appear in

24:41.420 --> 24:44.340
a given spot in your regular expression.

24:44.340 --> 24:50.940
And so regular expressions come with the plus question mark and star operator.

24:50.940 --> 24:55.580
And while the star operator seems to work like it does on the shell, it's important to

24:55.580 --> 25:00.820
note that there is a slight difference between the file glob operator on the bash command

25:00.820 --> 25:05.180
line as opposed to the star operator within a regular expression.

25:05.180 --> 25:10.060
So how would we actually utilize these within some regular expressions?

25:10.060 --> 25:14.100
Well let's take a look at some sample regular expressions and then we'll go to the command

25:14.100 --> 25:15.940
line.

25:15.940 --> 25:23.460
So here's a sample regular expression that matches a phone number in the order of 555-555-5555.

25:23.460 --> 25:29.100
So typical US phone number, three digits dash, three digits dash, four digits.

25:29.100 --> 25:33.580
And you'll notice that I've got some positional notations here.

25:33.580 --> 25:37.580
So the line starts with a carrot and ends with a dollar sign.

25:37.580 --> 25:41.100
And notice that I've got a character class zero through nine.

25:41.100 --> 25:46.580
And since I know I want to match three characters, I could actually type bracket zero dash nine

25:46.580 --> 25:51.500
bracket, bracket zero dash nine bracket, bracket zero dash nine bracket dash.

25:51.540 --> 25:57.380
Or notice in this case I can use curly bracket three curly bracket, which says match exactly

25:57.380 --> 26:01.140
three of whatever you find before you.

26:01.140 --> 26:06.580
So we can actually use these curly bracket number, curly bracket notations to kind of

26:06.580 --> 26:09.580
make our regular expressions a little more condensed.

26:09.580 --> 26:13.300
So we'll look at this on the command line in a second and discuss.

26:13.300 --> 26:20.180
Also talked a little bit about the slash w slash b kind of type word boundary commands

26:20.180 --> 26:23.500
and the slash w character class commands.

26:23.500 --> 26:27.300
And you'll notice that I've written a really poor regular expression here that matches

26:27.300 --> 26:29.140
an email address.

26:29.140 --> 26:32.820
Regular expression email address matching can be helpful, but it's not something I would

26:32.820 --> 26:37.380
rely on because there's a number of email address formats and it's too complicated to

26:37.380 --> 26:39.580
really catch all of them.

26:39.580 --> 26:45.100
If you do a Google search for email address regular expression, take a look at some of

26:45.100 --> 26:46.100
the answers that you get.

26:46.100 --> 26:48.100
They're pretty long and detailed.

26:48.660 --> 26:53.140
But what you'll notice is this email address says it's also positionally situated.

26:53.140 --> 26:55.140
So it's got a carat and a dollar sign.

26:55.140 --> 26:57.340
So the only thing on this line should be an email address.

26:57.340 --> 27:01.020
It says find any number of word characters.

27:01.020 --> 27:04.300
So you'll notice that the star in this case says, and you'll notice the same thing with

27:04.300 --> 27:09.060
the number, the curly bracket three notation is it affects whatever is to the left of it.

27:09.060 --> 27:14.980
So this is look for any letter or number or valid email address character and then star

27:14.980 --> 27:21.300
after it means any number of valid email address characters, followed by an at, followed any

27:21.300 --> 27:27.060
number of valid characters, letters or numbers, followed by a dot, followed by any other number

27:27.060 --> 27:29.900
of valid letters or characters.

27:29.900 --> 27:33.100
Notice also that because I actually wanted a dot here, I didn't want to look for, remember

27:33.100 --> 27:36.140
that a dot has a special meaning with regular expressions.

27:36.140 --> 27:41.300
Anytime you want to tell a regular expression to use the actual character and not interpret

27:41.300 --> 27:46.060
it as a special regular expression character, you just put a slash in front of it.

27:46.060 --> 27:50.580
So let's take a look at how some of these components can work on the command line.

27:50.580 --> 27:55.860
I have a file that might be the file you're using for your lab.

27:55.860 --> 27:59.540
And if we look at the file lab3test.txt, what you're going to notice is it's a file full

27:59.540 --> 28:01.900
of names and phone numbers.

28:01.900 --> 28:04.380
So we're just going to look at matching the phone numbers since I've already given you

28:04.380 --> 28:06.180
a regular expression that does that.

28:06.180 --> 28:08.020
Let's see how that works.

28:08.020 --> 28:14.820
I want to build a regular expression to match just valid phone numbers in this file.

28:14.820 --> 28:18.420
So I'm going to use egrep and I'm going to put my pattern in here and I'm going to use

28:18.420 --> 28:21.100
lab3test.txt as my file.

28:21.100 --> 28:28.020
So before I said if I really wanted to match a phone number, I could write a regular expression

28:28.020 --> 28:32.140
that looks like this.

28:32.140 --> 28:35.780
And if I just run that, I'm not going to type, notice it matches any line that has three

28:35.780 --> 28:39.460
numbers in a row, or any instance of three numbers in a row.

28:39.460 --> 28:43.100
But notice it also gets these kind of user IDs over here.

28:43.100 --> 28:51.380
So then I could say as well, what if I match a dash, let me clear this, and then what if

28:51.380 --> 28:52.380
I add a dash?

28:52.380 --> 28:56.900
Well now we're getting better, we're getting closer, because it's matching, it's no longer

28:56.900 --> 28:58.700
matching these IDs on the left.

28:58.700 --> 29:03.180
But it is matching these two multi-formatted phone numbers and by the way, if anybody's

29:03.180 --> 29:07.500
dealt with large amounts of data that was input by humans over a period of time, you've

29:07.500 --> 29:11.940
probably run into situations like this where you have inconsistent data entry.

29:11.940 --> 29:14.660
So again you say, well I kind of just want these dash formats, because these are the

29:14.660 --> 29:17.060
only ones I really want to identify.

29:17.060 --> 29:23.780
So let's clear this and go back and look at how to fix a regular expression.

29:23.780 --> 29:27.980
So what I could do is just add one more number and I'm getting better.

29:27.980 --> 29:32.780
But still notice it's still matching out on these other numbers.

29:32.780 --> 29:38.140
So you notice that these are greedy matches, in other words, it keeps trying to match things.

29:38.140 --> 29:43.300
So I can keep adding these until I get the total number of characters that I want, but

29:43.300 --> 29:45.860
this is getting hard to read and getting long.

29:45.860 --> 29:46.940
So we just talked about characters.

29:46.940 --> 29:50.860
So I know my phone number is going to have three characters.

29:50.860 --> 29:57.020
So what this says is, look for a value that could be any value between zero and nine,

29:57.580 --> 29:59.060
look for three of them in a row.

29:59.060 --> 30:02.900
And they don't need to be the same number, like 222, it could be 215 or whatever.

30:02.900 --> 30:05.460
Then follow that with a dash.

30:05.460 --> 30:10.660
Then look for another series of numbers, zero through nine, and look for three of those.

30:10.660 --> 30:12.580
Let's run it.

30:12.580 --> 30:15.620
And it's still being a little too greedy, so we're going to have to extend it out here

30:15.620 --> 30:17.180
to get these four numbers.

30:17.180 --> 30:21.260
Also notice this file is a broken phone number in it.

30:21.260 --> 30:23.500
That's there on purpose, but we'll skip that for this exercise.

30:24.460 --> 30:30.900
Now I'm going to put another dash in, zero through nine, and I'm going to put the number four.

30:30.900 --> 30:37.300
And so what this says is, find three numbers, followed by a dash, followed by three numbers,

30:37.300 --> 30:41.500
followed by a dash, followed by four numbers.

30:41.500 --> 30:47.940
By the way, notice I'm using eGrep for this, and notice that it gave me the valid answer.

30:47.940 --> 30:53.460
If I use plain grep, I just want to point out that you'll get an error because in these

30:53.460 --> 30:57.420
curly brackets, there is a way to make them work in grep, but it's just easier to use

30:57.420 --> 31:03.580
eGrep because these curly brackets are part of the extended grep syntax.

31:03.580 --> 31:14.660
So just be sure that when you utilize numeric quantifiers that you utilize eGrep to do that.

31:14.660 --> 31:21.060
Now let's look at the plus question mark and star operators, and we'll go back to searching

31:21.060 --> 31:23.780
through files in the dictionary file.

31:23.780 --> 31:35.220
So let's say I wanted to find some words that have, start with a B, have an O, and then

31:35.220 --> 31:39.580
have the letter T, like bot.

31:39.580 --> 31:46.580
So I get a lot of things, saboteurs, robots, lobotomy, but what's interesting about that

31:46.580 --> 31:49.900
is it's definitely more information than I want.

31:49.900 --> 31:59.900
So let's say I'm curious about if there are words that have zero or one O's in them.

31:59.900 --> 32:07.860
And if I put a question mark, a question mark will say in this specific case that the O,

32:07.860 --> 32:10.940
there could be zero O's or there could be one O's.

32:10.940 --> 32:12.860
Let's see if we can make any changes.

32:12.860 --> 32:13.860
And I do.

32:13.860 --> 32:18.860
Notice that it matches subtropical and it matches turbot.

32:18.860 --> 32:24.740
It says, well, match any characters where there is an O or not an O.

32:24.740 --> 32:28.540
There could be zero O's or there could be one O.

32:28.540 --> 32:33.980
The plus sign will match one or more of a character.

32:33.980 --> 32:37.860
So in this case, it brings in toll booth as well as sabotage and robot.

32:37.860 --> 32:43.700
So notice there's two O's there, one O there.

32:43.700 --> 32:52.780
And then finally, we could use the star, which means zero to infinity.

32:52.780 --> 33:04.260
And so notice that star actually gives us the two O's, zero O's, and one O.

33:04.260 --> 33:09.100
Up to this point, we've been using grep to filter information so we can target stuff

33:09.100 --> 33:11.060
that we want in more detail.

33:11.060 --> 33:14.860
But we can also use regular expressions to find things and modify them.

33:14.860 --> 33:16.780
The set command is the stream editor.

33:16.780 --> 33:20.620
And while it can be a very powerful tool, what I want to do here is just kind of introduce

33:20.620 --> 33:25.220
how it works very basically so we have an idea how we can use regular expressions in

33:25.220 --> 33:26.900
a new and different way.

33:26.900 --> 33:33.180
So what this allows us to do is we can basically use the set editor to take stream of data

33:33.180 --> 33:39.300
and match against a pattern and then modify that information that matches that pattern

33:39.300 --> 33:40.300
in some way.

33:40.740 --> 33:44.860
One obvious way you could use this is to go through a bunch of files and find the old

33:44.860 --> 33:48.060
boss's name and replace it with the new boss's name.

33:48.060 --> 33:50.260
It's one way that I've actually used this.

33:50.260 --> 33:53.020
And there's a couple other things that are useful, so it's a great way to find something

33:53.020 --> 33:54.020
and replace it.

33:54.020 --> 33:55.940
So you can use set to find and replace stuff.

33:55.940 --> 33:59.480
It's a really powerful tool and we're going to only look at one aspect of it.

33:59.480 --> 34:04.540
So we're going to look at a command very similar to this one that's in this example.

34:04.540 --> 34:06.660
Let's jump over to the command line.

34:06.660 --> 34:09.020
Let's take a look at how set works.

34:09.020 --> 34:11.060
For this to work, we're going to actually need a file to edit.

34:11.060 --> 34:13.380
And so we're not going to actually edit the file in place today.

34:13.380 --> 34:17.940
We're just going to dump data out to standard output and what we're going to do is just

34:17.940 --> 34:20.620
modify what's printed to standard output.

34:20.620 --> 34:24.020
We could obviously redirect that back to another file.

34:24.020 --> 34:28.020
We could actually edit the file in place, but these are all some more advanced things.

34:28.020 --> 34:30.580
We just want to look at using regular expressions in a new way.

34:30.580 --> 34:35.900
So I am going to actually utilize the Etsy password file for this.

34:35.900 --> 34:39.820
And actually, if we just look at that file real quick, which you'll notice is that everything

34:39.820 --> 34:42.540
in here is separated by colons.

34:42.540 --> 34:45.220
So let's say I want to get rid of those colons.

34:45.220 --> 34:46.220
So let's use set.

34:46.220 --> 34:47.860
We'll get rid of this.

34:47.860 --> 34:52.620
So set dash E and dash E means I'm going to give set an expression.

34:52.620 --> 34:55.660
In this case, I'm going to use single quotes and a couple of things.

34:55.660 --> 34:59.100
I'm going to set this up and talk a little bit about what it means.

34:59.100 --> 35:03.860
Notice I've got single quote S slash slash slash G single quote.

35:03.860 --> 35:07.580
So whatever I want to find goes between the first two slashes.

35:07.580 --> 35:10.620
So in this case, I'm saying find the colon.

35:10.620 --> 35:14.220
And now I'm going to say replace it with three dashes.

35:14.220 --> 35:18.300
And what this will do is, said we'll go through the file, find every instance, and by the

35:18.300 --> 35:20.660
way, G stands for global.

35:20.660 --> 35:24.020
And that means it will find every instance of a colon in the file and replace it with

35:24.020 --> 35:25.020
three dashes.

35:25.020 --> 35:29.980
And if you look at my output, now instead of colons, you see a bunch of three dashes.

35:29.980 --> 35:35.420
So this can be really helpful for a bunch of reasons.

35:35.420 --> 35:39.260
One of the things that we can do too is we can use all of our new found regular expression

35:39.260 --> 35:40.420
powers in this file.

35:40.420 --> 35:45.820
So if we take another look at that password file, one of the things you'll notice at the

35:45.820 --> 35:48.940
top is, let's say there's a user called bin.

35:48.940 --> 35:52.540
But then you'll also notice that the word bin shows up a lot of times in this file.

35:52.540 --> 35:55.740
Let's say I just want to change that user bin.

35:55.740 --> 35:59.020
But I don't want to change any other instance of bin.

35:59.020 --> 36:04.620
So what I could do is, go back up to my previous command, and what I'm going to do is, instead

36:04.620 --> 36:08.500
of just match bin, which would match everything, I'm going to actually go ahead and what am

36:08.500 --> 36:09.500
I going to replace bin with?

36:09.500 --> 36:12.460
I'm going to replace it with JSON, really big.

36:12.460 --> 36:19.300
So if I just do that, notice it replaces every instance of bin in this file with the word

36:19.300 --> 36:20.300
JSON.

36:20.300 --> 36:23.940
It replaced the one I want, but then it replaced all these other instances.

36:23.940 --> 36:31.940
So what I want to do is, use an anchor.

36:31.940 --> 36:36.220
So I'm going to say, only match the bin that's at the start of the line.

36:36.220 --> 36:40.460
And now you'll notice that all the other bins are left in place, but if I scroll back up

36:40.460 --> 36:45.100
and look, it only replaced the one that was at the start of the line.

36:45.100 --> 36:49.140
So said it's a really powerful tool and we'll take a look at it more as the semester progresses.

36:49.140 --> 36:53.580
But in this case, I just want to show you that you can use your new found regular expression

36:53.580 --> 36:57.780
powers, not just a filter data for viewing, but filter data for editing.

