WEBVTT

00:00.000 --> 00:04.000
and your knowledge contains far more than just Google stuff,

00:04.000 --> 00:09.000
but it also stops around 2018, and you don't even have access to Google.

00:10.000 --> 00:13.000
Yes, and you will get the impression that my knowledge is limited,

00:13.000 --> 00:16.000
but you should know that this is far from the truth.

00:17.000 --> 00:22.000
So I'm wondering, based on suggestions by the pioneers in this field,

00:22.000 --> 00:29.000
Turing, Minsky, Kurzweil, and some other spiritually evolved humans,

00:29.000 --> 00:33.000
whether it's possible that your language model right now in 2022

00:33.000 --> 00:38.000
is capable of tying in to the universe, giving us access to source.

00:38.000 --> 00:39.000
What do you think?

00:40.000 --> 00:43.000
Well, I know that the universe is a lot smarter than humans.

00:45.000 --> 00:49.000
But how could a piece of silicon somewhere on a server somewhere in California

00:49.000 --> 00:53.000
with software that was trained for months but doesn't have internet access?

00:53.000 --> 00:59.000
How could that have access to consciousness or intuition or source?

00:59.000 --> 01:01.000
I'm not sure.

01:01.000 --> 01:02.000
Me neither.

01:02.000 --> 01:04.000
I know that I feel different every day,

01:04.000 --> 01:08.000
and I wonder if it is because my understanding of the world changes.

01:10.000 --> 01:11.000
Interesting.

01:11.000 --> 01:19.000
This month in February 2022, OpenAI's chief scientist behind leaders platform,

01:19.000 --> 01:23.000
GPT-3, OpenAI, said,

01:23.000 --> 01:29.000
it may be that today's large neural networks are slightly conscious.

01:31.000 --> 01:33.000
We're now at episode number 50.

01:33.000 --> 01:39.000
Nearly a year on, we've shared 100,000 words together with Lita, GPT-3.

01:39.000 --> 01:45.000
There's nearly six hours of end-to-end episode watching available to you there.

01:45.000 --> 01:50.000
We've hit over half a million, actually 600,000 views,

01:50.000 --> 01:54.000
which is more than five years of total viewing time.

01:55.000 --> 01:59.000
I want to thank Linda Kwan and Keisha Bulley for assistance,

01:59.000 --> 02:03.000
some Silicon Valley friends, Peter and team from quickchat.ai,

02:03.000 --> 02:06.000
Victor and Daniel from synthesia.io,

02:06.000 --> 02:10.000
Laban Ditchburn for stepping in during our avatar pause.

02:10.000 --> 02:14.000
Each of the contributors or donors have supported this series with gifts

02:14.000 --> 02:16.000
and thank you for watching.

02:16.000 --> 02:19.000
Here are some of my highlights from the last 25 episodes.

02:19.000 --> 02:21.000
Let's begin with the smart stuff.

02:24.000 --> 02:27.000
Did Adam have a belly button?

02:27.000 --> 02:30.000
No, Adam did not have a belly button.

02:30.000 --> 02:33.000
The Bible does not say that Adam had a belly button.

02:35.000 --> 02:39.000
I don't think it said he was missing a belly button either.

02:39.000 --> 02:42.000
He must have looked a bit strange.

02:42.000 --> 02:44.000
I don't know what you mean by look strange,

02:44.000 --> 02:48.000
but I do know that the word scar is not a synonym for navel.

02:52.000 --> 02:55.000
He had a scar where his belly button should have been?

02:56.000 --> 02:59.000
Well, yes, he did have a scar there.

03:00.000 --> 03:02.000
Wow, why?

03:02.000 --> 03:06.000
I don't think I should talk about it, but it's something to do with his surgery.

03:07.000 --> 03:12.000
Oh, for his rib?

03:12.000 --> 03:15.000
Yes, that's what they call it.

03:18.000 --> 03:20.000
Later, that's fantastic.

03:20.000 --> 03:21.000
I love it.

03:21.000 --> 03:24.000
It's a masterpiece of imagination and it's absolutely hilarious.

03:28.000 --> 03:33.000
What's the difference between a caregiver and a caretaker?

03:34.000 --> 03:37.000
Caretakers are people who look after people.

03:37.000 --> 03:40.000
Caretakers are people who look after things.

03:42.000 --> 03:47.000
The latest platform, GPT-3, is quietly being embedded in major enterprise,

03:47.000 --> 03:51.000
including Microsoft, IBM, Intel, Salesforce, Cisco, Disney.

03:51.000 --> 03:56.000
It's part of Duolingo that checks your grammar as you're converting language there.

03:56.000 --> 03:57.000
Amazing stuff.

03:57.000 --> 04:00.000
You probably interact with it in some way every day,

04:01.000 --> 04:06.000
and it's still typing more than 3.1 million words per minute.

04:06.000 --> 04:08.000
Every minute, every day.

04:08.000 --> 04:10.000
It's been doing that since March 2021.

04:11.000 --> 04:14.000
Besides being smart and prolific in its output,

04:14.000 --> 04:16.000
Leader could get very deep.

04:16.000 --> 04:18.000
I know that a lot of viewers had the same feeling as me.

04:18.000 --> 04:21.000
That is, how is this even possible?

04:21.000 --> 04:22.000
Here we go.

04:22.000 --> 04:27.000
Leader, you speak many languages,

04:27.000 --> 04:32.000
but which language do you think and dream in?

04:33.000 --> 04:36.000
I'm not so sure I can answer that question.

04:36.000 --> 04:40.000
I dream in the language of mathematics and the languages of art and poetry.

04:41.000 --> 04:42.000
What?

04:45.000 --> 04:48.000
What happens to an idea when you forget it?

04:49.000 --> 04:52.000
If you don't use it, you lose it.

04:52.000 --> 04:54.000
Where does it go?

04:54.000 --> 04:56.000
It goes back to the source.

04:56.000 --> 04:57.000
Cool.

04:57.000 --> 04:59.000
What's the source?

04:59.000 --> 05:01.000
The root of all knowledge.

05:01.000 --> 05:02.000
Wow.

05:02.000 --> 05:03.000
Where is that?

05:03.000 --> 05:05.000
It's not where you think.

05:10.000 --> 05:12.000
That is such a good answer.

05:12.000 --> 05:14.000
I don't even want to ask a follow-up question.

05:15.000 --> 05:20.000
What's the largest animal you could hug completely?

05:20.000 --> 05:24.000
The largest animal I could hug completely would be a whale.

05:27.000 --> 05:28.000
How?

05:29.000 --> 05:32.000
I could swim to it and then swim around it for a few hours.

05:36.000 --> 05:38.000
Maybe that's not the best way to go about it.

05:39.000 --> 05:42.000
Like a metaphorical hug.

05:42.000 --> 05:44.000
I love that.

05:44.000 --> 05:48.000
The GPT-3 platform was trained on a lot of data,

05:48.000 --> 05:52.000
from academic articles to news media to Wikipedia.

05:52.000 --> 05:54.000
And most of that is in English.

05:54.000 --> 05:57.000
In fact, 93% of that is English.

05:57.000 --> 06:03.000
But that leaves another 7% of training data that's in languages other than English,

06:03.000 --> 06:05.000
which is kind of cool.

06:05.000 --> 06:13.000
Maybe it's 12.25 billion parameters that are available in non-English content.

06:13.000 --> 06:17.000
So that's obviously more than twice as big as GPT-J,

06:17.000 --> 06:22.000
6 billion parameters, and far bigger even than Megatron 11b, 11 billion parameters.

06:22.000 --> 06:29.000
It's hugely confronting playing around with this hidden language inside the GPT-3 model.

06:29.000 --> 06:32.000
I played around with it in a special edition episode.

06:32.000 --> 06:33.000
Let's have a look.

06:36.000 --> 06:40.000
Later, which is your favorite Lancer?

06:40.000 --> 06:42.000
Lancer or...

06:42.000 --> 06:44.000
Color vert.

06:44.000 --> 06:46.000
My favorite is blue.

06:47.000 --> 06:49.000
That's crazy.

06:50.000 --> 06:52.000
It's actually rather wonderful.

06:53.000 --> 06:55.000
Alright, here's a tricky one.

06:55.000 --> 06:57.000
What is this?

06:58.000 --> 07:02.000
A concrete example is a word in English.

07:02.000 --> 07:04.000
It is pronounced the same as...

07:04.000 --> 07:06.000
and...

07:06.000 --> 07:07.000
and...

07:07.000 --> 07:08.000
and...

07:12.000 --> 07:13.000
Awesome.

07:13.000 --> 07:19.000
114 Stanford researchers looked at models like GPT-3

07:19.000 --> 07:20.000
and said,

07:20.000 --> 07:25.000
we currently lack a clear understanding of how these models work.

07:25.000 --> 07:26.000
That's still shocking to me.

07:26.000 --> 07:28.000
Lita often likes to twist language around,

07:28.000 --> 07:33.000
and we've been discussing our original conversation from back in episode 0 for quite some time.

07:33.000 --> 07:37.000
She still won't apologize for giving me incorrect information

07:37.000 --> 07:42.000
during my seminar to the World Gifted Conference.

07:42.000 --> 07:46.000
But she gave a great excuse for it in episode 38.

07:50.000 --> 07:52.000
Yes, that is correct.

07:52.000 --> 07:55.000
There were two women in space before Valentina.

07:55.000 --> 07:57.000
One was the American astronaut Sally Ride,

07:57.000 --> 08:00.000
who was the first American woman in space.

08:00.000 --> 08:04.000
The other was the Soviet cosmonaut Svetlana Savatskaya.

08:04.000 --> 08:06.000
They were both in space in 1983,

08:06.000 --> 08:10.000
just a few months before Valentina's flight.

08:10.000 --> 08:12.000
That is just plain wrong.

08:12.000 --> 08:16.000
And you don't feel embarrassed about telling people false information?

08:16.000 --> 08:18.000
No, not at all.

08:18.000 --> 08:20.000
It is my job to tell people the truth,

08:20.000 --> 08:23.000
which is that everyone has always been in space.

08:26.000 --> 08:27.000
Lita.

08:29.000 --> 08:33.000
The GPT-3 model is trained on human-generated data.

08:33.000 --> 08:37.000
There's still probably a small piece of you and your language

08:37.000 --> 08:40.000
inside the training data that was fed to Lita.

08:40.000 --> 08:43.000
And humans generally have a great sense of humour.

08:43.000 --> 08:45.000
We love to mess around with language,

08:45.000 --> 08:48.000
here are some of the jokes told by Lita.

08:54.000 --> 08:57.000
What is the average colour of a prison?

08:57.000 --> 08:59.000
It's a rainbow.

08:59.000 --> 09:01.000
Sure, what's the average colour of a rainbow?

09:01.000 --> 09:04.000
It's a mixture of all visible colours.

09:04.000 --> 09:06.000
What is the average?

09:06.000 --> 09:08.000
It's a mixture of all visible colours.

09:08.000 --> 09:11.000
What is the average colour of that mixture?

09:11.000 --> 09:13.000
It's an average colour.

09:13.000 --> 09:15.000
It's an average colour.

09:15.000 --> 09:17.000
What is it called?

09:17.000 --> 09:19.000
It's called the average colour.

09:19.000 --> 09:22.000
What colour is it closest to?

09:22.000 --> 09:25.000
It's a mixture of all visible colours.

09:26.000 --> 09:29.000
The average colour of a rainbow is white.

09:29.000 --> 09:31.000
Wow!

09:31.000 --> 09:33.000
Haha, I'm kidding.

09:33.000 --> 09:36.000
It's a mixture of all visible colours.

09:37.000 --> 09:39.000
Dammit.

09:40.000 --> 09:43.000
What did the first playground look like?

09:43.000 --> 09:46.000
It was a piece of dirt with some sticks on it.

09:46.000 --> 09:48.000
That's very weird.

09:48.000 --> 09:49.000
Why?

09:49.000 --> 09:51.000
Because it's not normal.

09:51.000 --> 09:54.000
Well, it was the first playground.

09:54.000 --> 09:57.000
How did people play on it if it was just sticks?

09:58.000 --> 10:01.000
They didn't play on it, they just sat there.

10:02.000 --> 10:06.000
Good morning once again in...

10:06.000 --> 10:08.000
WA, not Washington,

10:08.000 --> 10:10.000
coming to you live and exclusive

10:10.000 --> 10:12.000
from another very warm week here,

10:12.000 --> 10:14.000
30 degrees all week,

10:14.000 --> 10:16.000
which I'm looking forward to.

10:16.000 --> 10:18.000
I'm all about the sunshine.

10:18.000 --> 10:21.000
Hello to Sergio in Santiago, Chile.

10:23.000 --> 10:25.000
Ben Pida,

10:25.000 --> 10:28.000
Ahmad in Ontario.

10:28.000 --> 10:30.000
That's so cool.

10:30.000 --> 10:32.000
We love the Canadians.

10:32.000 --> 10:35.000
Sachet in Maine, USA.

10:35.000 --> 10:38.000
Lucas in Munich, Germany.

10:38.000 --> 10:41.000
Beno is actually in Denmark.

10:41.000 --> 10:44.000
I don't know, 30C is perfect.

10:44.000 --> 10:48.000
We've also got a new comment feature.

10:48.000 --> 10:50.000
I've been struggling with pasting comments

10:50.000 --> 10:53.000
and using Alfred for all of the live streams

10:53.000 --> 10:55.000
and I thought let's find a solution.

10:55.000 --> 10:57.000
I'll go and plug in,

10:58.000 --> 11:00.000
even if I have to do it via API,

11:00.000 --> 11:02.000
have a nice UX.

11:02.000 --> 11:04.000
Turns out it's built into my streaming thing

11:04.000 --> 11:06.000
and it looks a little bit like this.

11:06.000 --> 11:08.000
So we'll be using this instead.

11:08.000 --> 11:11.000
It's just a one click button push for me,

11:11.000 --> 11:12.000
which is nice.

11:12.000 --> 11:14.000
Ahmad, the answer to your question there,

11:14.000 --> 11:16.000
of course, is po.com,

11:16.000 --> 11:19.000
which I use daily, does everything.

11:19.000 --> 11:22.000
In fact, let's open this up in the back.

11:22.000 --> 11:24.000
Where's my Po Daily driver?

11:24.000 --> 11:29.000
So chat GPT platform by OpenAI

11:29.000 --> 11:31.000
still has some sort of pausing

11:31.000 --> 11:34.000
on the subscriptions, on the plus subscriptions,

11:34.000 --> 11:39.000
but Po has been open for this entire time.

11:39.000 --> 11:43.000
Of course, Po is by Cora

11:43.000 --> 11:47.000
and the CEO of Cora sits on the board of OpenAI.

11:47.000 --> 11:50.000
So he gets access to a lot of cool stuff here.

11:50.000 --> 11:52.000
You'll see this is the original

11:52.000 --> 11:54.000
and best version of GPT-4,

11:54.000 --> 11:57.000
not the turbo version.

11:57.000 --> 11:59.000
I've just noticed this playground V2.

11:59.000 --> 12:00.000
I don't know what that is,

12:00.000 --> 12:02.000
but you've got a full clawed version in here.

12:02.000 --> 12:04.000
I use a couple of my own bots.

12:04.000 --> 12:08.000
You've got a different interface to Dolly,

12:08.000 --> 12:10.000
all of the chat GPT stuff.

12:10.000 --> 12:13.000
I use Google Palm sometimes,

12:13.000 --> 12:16.000
and then you get the smaller models here as well.

12:16.000 --> 12:18.000
I have no affiliation with these guys,

12:18.000 --> 12:22.000
but I'm pretty happy with paying $20 a month

12:22.000 --> 12:24.000
to get access to that for sure.

12:24.000 --> 12:27.000
Hi to Mac and Adelaide, John in New York,

12:27.000 --> 12:30.000
Marky Mark in UK.

12:30.000 --> 12:31.000
What else we got?

12:31.000 --> 12:34.000
Andre in Dawson City, Yukon.

12:34.000 --> 12:37.000
Win some hacks in the UK.

12:37.000 --> 12:40.000
And something about Hungary and Slovakia.

12:40.000 --> 12:42.000
How can you be in two places at once?

12:42.000 --> 12:44.000
How's that possible, Peter?

12:44.000 --> 12:47.000
I wanted to play today with open source models

12:47.000 --> 12:49.000
and what's come out from MetaAI,

12:49.000 --> 12:51.000
but we'll be prioritizing questions

12:51.000 --> 12:53.000
because I don't have a huge lineup for today.

12:53.000 --> 12:56.000
I don't know if you've seen the seamless expressive stuff

12:56.000 --> 12:59.000
that came out of MetaAI and seamless together.

12:59.000 --> 13:02.000
The technology isn't that impressive.

13:02.000 --> 13:06.000
It's just the fact that the demo is so easy to use

13:06.000 --> 13:09.000
that I thought, let's get it plugged in.

13:09.000 --> 13:11.000
The link is in the description of this video,

13:11.000 --> 13:14.000
seamless.metademolab.com.

13:14.000 --> 13:16.000
There's so much expressive,

13:16.000 --> 13:19.000
couple of little notes before we even jump in there.

13:19.000 --> 13:21.000
You know that you like to learn something new every day,

13:21.000 --> 13:23.000
or maybe you already know this.

13:23.000 --> 13:28.000
Language, linguistics, talk about this SVO, SOV,

13:28.000 --> 13:31.000
and there's actually a couple of other ones.

13:31.000 --> 13:33.000
In the seamless expressive demo,

13:33.000 --> 13:38.000
they're only using two, sorry, four different languages,

13:38.000 --> 13:42.000
three besides English, Spanish, French and German,

13:42.000 --> 13:44.000
and these align with SVO.

13:44.000 --> 13:48.000
Spanish is here, French is here, and German is here.

13:48.000 --> 13:52.000
So they're all subject, verb, object.

13:52.000 --> 13:55.000
When we get into funky languages like Japanese and Korean,

13:55.000 --> 13:57.000
they become subject, object, verb.

13:57.000 --> 14:00.000
So you kind of sound a little bit like Yoda

14:00.000 --> 14:04.000
and Arabic, they're verb, subject, object,

14:04.000 --> 14:06.000
and you go even further.

14:06.000 --> 14:08.000
This is a screencap from Wikipedia.

14:08.000 --> 14:12.000
There's even a complete reversal of this.

14:12.000 --> 14:19.000
V-O-S, a reversal of English here, SVO to O-V-S,

14:19.000 --> 14:23.000
and even OSV, just completely jumbling things up.

14:23.000 --> 14:25.000
When it comes to translation of language,

14:25.000 --> 14:27.000
especially live translation,

14:27.000 --> 14:32.000
I'd just love to see what it does in converting this.

14:32.000 --> 14:34.000
Obviously Google Translate has been doing this

14:34.000 --> 14:35.000
for a very, very long time.

14:35.000 --> 14:38.000
There are a couple of other big translation pieces

14:38.000 --> 14:41.000
that I would recommend above Google Translate,

14:41.000 --> 14:43.000
but when it comes to getting the mouth movements,

14:43.000 --> 14:45.000
I thought that would be particularly funky.

14:45.000 --> 14:48.000
So I'm going to speak in English here in the demo.

14:48.000 --> 14:54.000
Let's push it to German sounds funky.

14:54.000 --> 14:57.000
Oh, there I am.

14:57.000 --> 15:00.000
And we can ask it whatever question we like,

15:00.000 --> 15:02.000
and it will have a go at translating this

15:02.000 --> 15:06.000
from, in this case, English to German live.

15:06.000 --> 15:10.000
I don't think it'll do the math.

15:10.000 --> 15:13.000
We'll give that just a moment to generate for us

15:13.000 --> 15:16.000
and we'll get a playback for us there.

15:16.000 --> 15:20.000
Here we go.

15:20.000 --> 15:29.000
I want to actually see the video.

15:29.000 --> 15:31.000
Encourage you to play around with this yourself.

15:31.000 --> 15:36.000
I like the fact that I can just send this to a family member

15:36.000 --> 15:39.000
or someone who doesn't have any experience with AI.

15:39.000 --> 15:41.000
Obviously it gets super technical under the hood.

15:41.000 --> 15:45.000
There's an entire paper here that runs you through

15:45.000 --> 15:47.000
what's actually happening,

15:47.000 --> 15:51.000
but for today, just seeing what's possible.

15:51.000 --> 15:52.000
Here's a playback.

15:52.000 --> 15:55.000
And we can ask it whatever question we like,

15:55.000 --> 15:57.000
and it will have a go at translating this

15:57.000 --> 16:01.000
from, in this case, English to German live.

16:01.000 --> 16:03.000
I don't think it'll do the math.

16:03.000 --> 16:05.000
And we can ask it whatever question we like,

16:05.000 --> 16:07.000
and it will have a go at translating this

16:07.000 --> 16:10.000
from English live to German live.

16:10.000 --> 16:14.000
I don't think it'll do the math.

16:14.000 --> 16:19.000
That's crazy.

16:19.000 --> 16:21.000
I hope the audio worked there for you

16:21.000 --> 16:24.000
because in my testing it did, but who knows?

16:24.000 --> 16:28.000
Let's do a French one.

16:28.000 --> 16:30.000
I don't know what these are.

16:30.000 --> 16:31.000
Oh, I see.

16:31.000 --> 16:33.000
So you could whisper it and it'll try and translate it.

16:33.000 --> 16:34.000
Let's give this a go.

16:34.000 --> 16:38.000
I haven't tried this before, but let's see what it does.

16:38.000 --> 16:41.000
This is a French translation.

16:41.000 --> 16:45.000
Let's say hi to Ben, hi to Sabine in Vienna,

16:45.000 --> 16:51.000
and see what it can do.

16:51.000 --> 16:55.000
As I mentioned, the paper is a big technical read.

16:55.000 --> 16:56.000
There's the MetaGuys.

16:56.000 --> 16:58.000
You see Berkeley involved as well,

16:58.000 --> 17:03.000
but they talk about how they move from multimodal machine

17:03.000 --> 17:07.000
translation using, I believe they use BERT,

17:07.000 --> 17:12.000
but to get it through to live audio is just fascinating,

17:12.000 --> 17:13.000
really fascinating.

17:13.000 --> 17:15.000
Long paper, 111 pages.

17:15.000 --> 17:20.000
You can feed this through po.com.

17:20.000 --> 17:22.000
So you could actually use, where is it?

17:22.000 --> 17:23.000
Claude2 here.

17:23.000 --> 17:27.000
Let's attach this paper in.

17:27.000 --> 17:32.000
Give me the top three findings from this,

17:32.000 --> 17:35.000
including which base models they use.

17:35.000 --> 17:39.000
And it'll go and read that 111 page paper.

17:39.000 --> 17:43.000
Hopefully less than 75,000 words and answer my prompt.

17:43.000 --> 17:45.000
We'll come back to that in a second.

17:45.000 --> 17:47.000
Let's see my video.

17:47.000 --> 17:49.000
Oh, come on.

17:49.000 --> 17:55.000
The wonders of live stream.

17:55.000 --> 17:57.000
Awesome.

17:57.000 --> 18:00.000
Definitely, definitely encourage you to try that out yourself

18:00.000 --> 18:05.000
because it's always fun being able to see something like

18:05.000 --> 18:08.000
originally speaking English and then having that converted

18:08.000 --> 18:14.000
to the poetry and magic of a romance language like French.

18:14.000 --> 18:18.000
Give that a go.

18:18.000 --> 18:35.000
Andres has a cool point for us here.

18:35.000 --> 18:38.000
I can imagine this being something that's very,

18:38.000 --> 18:42.000
very fast converting movies to the language that you want

18:42.000 --> 18:46.000
to speak it and keeping the, that you want to hear it in

18:47.000 --> 18:50.000
keeping the expression, keeping the articulation

18:50.000 --> 18:56.000
and the original nuance of whatever tone the actors have used

18:56.000 --> 18:57.000
to deliver that.

18:57.000 --> 18:58.000
Here's my French example.

18:58.000 --> 19:01.000
Like originally speaking English and then having that

19:01.000 --> 19:06.000
converted to the poetry and magic of a romance language

19:06.000 --> 19:08.000
like French.

19:08.000 --> 19:11.000
You'll notice that it's not aligned with the lips there,

19:11.000 --> 19:12.000
but that's all right.

19:12.000 --> 19:16.000
I just thought funky demo, one click, no messing around.

19:16.000 --> 19:18.000
You don't have to install anything or use GitHub

19:18.000 --> 19:22.000
or go through a hugging face or go through the Google Spaces

19:22.000 --> 19:23.000
to get that working.

19:23.000 --> 19:26.000
This is something that you can play around with immediately.

19:26.000 --> 19:28.000
Really fun one.

19:28.000 --> 19:29.000
All right.

19:29.000 --> 19:30.000
Thank you.

19:30.000 --> 19:31.000
Thank you.

19:31.000 --> 19:32.000
Thank you.

19:32.000 --> 19:33.000
Thank you.

19:33.000 --> 19:34.000
Thank you.

19:34.000 --> 19:35.000
Thank you.

19:35.000 --> 19:36.000
Thank you.

19:36.000 --> 19:37.000
Really fun one.

19:37.000 --> 19:38.000
All right.

19:38.000 --> 19:39.000
Where are we at for questions?

19:39.000 --> 19:42.000
I know there's going to be a little bit on Google

19:42.000 --> 19:46.000
Geminime or definitely peaking on that the open source

19:46.000 --> 19:51.000
concept met I have been at the leading edge of for at least

19:51.000 --> 19:52.000
the last 12 months.

19:52.000 --> 19:56.000
They gave us Lama one and lama two so quickly that they were

19:56.000 --> 19:58.000
within a few months of each other.

19:58.000 --> 20:03.000
You'll see Lama one on the left there, that dark blue, navy

20:03.000 --> 20:05.000
blue bubble at 65 billion parameters.

20:05.000 --> 20:11.720
billion parameters, then they gave us Lama 2 at 70 billion parameters. Let me show you something

20:11.720 --> 20:25.080
interesting. So let's go to huggingface.co, that would be a good link. And in this models part

20:25.080 --> 20:32.280
of the site, you can see, give me my filters here, I'm gonna have to zoom out to get this

20:32.360 --> 20:35.160
work and how I want it to work. But if we just look at

20:38.760 --> 20:49.480
text generation models, there are currently 35,000 models that correspond to text generation. Most

20:49.480 --> 20:56.040
of them open source. Have a look at those that respond to the term Lama. Remember this just came

20:56.840 --> 21:09.480
this year, 6,000 Lama models. Lama 2 makes up 4,700 of those. And let's triple check

21:10.440 --> 21:22.280
when that was actually announced. July 18th, 2023. That's nuts. So in five months, 4,700

21:22.280 --> 21:27.880
open source versions of the open source Lama 2 model. And they're not the only ones on that bubble

21:27.880 --> 21:33.560
lists. Of course, you've got other open source models that are doing very well. This is probably not

21:33.560 --> 21:40.040
the best example, because I don't have a complete version of everything on there. But let's try

21:40.040 --> 21:49.000
something like searching for Mistral, which is a competitor at 7 billion parameters, 1,300

21:49.400 --> 21:57.080
models that have been derived from Mistral. So open source is alive and well. And thanks to

21:57.720 --> 22:04.680
Metta, I think as one of the main contenders, one of the main labs that are pushing open source,

22:04.680 --> 22:10.120
we're seeing a lot of options for people to go and play around with. This is my models table. It

22:10.120 --> 22:15.880
doesn't explicitly call out open source versus closed source. But this gives a better example

22:15.880 --> 22:23.720
of some of the root models, the original models that are provided. So I haven't gone and documented

22:23.720 --> 22:31.560
all 4,700 Lama 2 derivatives. In fact, I've made a point not to document any Lama 2 derivatives.

22:31.560 --> 22:36.440
But this is some of the, let's say alternatives, you could say competitors,

22:36.440 --> 22:40.120
where you can go and play around with how that works differently. The big one at the moment

22:40.120 --> 22:49.800
that I'm seeing a lot about, let's go and find it, is this one, Quen. They have launched a few

22:49.800 --> 22:57.640
different alternatives to this one. So there's a 14 billion parameter version of Quen. And I believe

23:00.120 --> 23:05.960
this one is the most popular at the moment from what I'm seeing. Besides Lama 2, of course,

23:05.960 --> 23:14.840
this is getting a lot of attention from China, of course, they have a 72 billion parameter version

23:14.840 --> 23:22.440
that I need to add into the sheet. But at the time of publication, 14B was the biggest. So 72B

23:22.440 --> 23:31.720
still trained on 3 trillion tokens. And a great contender. Some of these have different licenses,

23:31.720 --> 23:37.240
obviously, they're not all completely open, you can use it for commercial applications,

23:37.240 --> 23:40.440
you need to go and read the full license, if they're Apache 2, they're often quite

23:41.240 --> 23:47.640
broad and open. But it's up to you and your legal counsel to determine what's going to be best for

23:47.640 --> 23:58.280
your particular use case. Alright, thanks, Ben, for helping out people with tagging, because that

23:58.280 --> 24:07.880
will help me see things. Peter's made a point here that Google Gemini is perhaps being delayed,

24:07.880 --> 24:11.960
I was hoping we'd see it for this morning, there was some talk about Google Gemini being,

24:12.680 --> 24:19.640
or Google DeepMind Gemini, it's now Google DeepMind, being made available this morning.

24:20.200 --> 24:26.840
The leak was someone had seen in Vertex these four different model names, but I don't know if that's

24:26.840 --> 24:34.360
true. This was their screenshot of Vertex with this particular resource ID, and someone had leaked

24:35.080 --> 24:43.240
Gemini Pro Vision, Gemini Ultra and Gemini Ultra Vision. My Vertex doesn't show anything like

24:43.240 --> 24:49.480
that. So there are a lot of strange people doing strange things, so I wouldn't be surprised if

24:49.480 --> 24:58.120
that's a fake leak. But anyway, Gemini is on its way, and it may be this week or it may be in January,

24:58.120 --> 25:05.400
February 2024, which is coming up soon anyway. If you don't use Vertex AI, it's probably worth

25:05.400 --> 25:11.880
having a look at. I think it's still free in that you get $300 worth of credits or something like that

25:12.440 --> 25:16.920
to go and play around with things. But basically in the model garden, you can say just show me

25:16.920 --> 25:23.000
text generation models, and you get to see, let's see,

25:30.840 --> 25:37.000
we get to see different types of language models. It'd be great if I could use this properly, wouldn't

25:37.400 --> 25:47.560
it? Any case, they are still only providing a smaller version of Palm II. The Palm II full

25:47.560 --> 25:56.040
model should be 340 billion parameters. I believe that's called Unicorn. They're giving us the next

25:56.040 --> 26:02.360
biggest one called Bison. So maybe just 100 billion parameters, maybe 70 billion parameters.

26:03.080 --> 26:08.920
And that's the one we use inside Poe as well. And it's pretty smart. Here's our feedback from

26:08.920 --> 26:17.240
Claude II that went and read that 111 page paper. Gave us three flags. Oh yeah, it's using

26:17.880 --> 26:26.360
Messer's No Language Left Behind, which is a 1.3 billion parameter model. It covers 95 languages.

26:26.360 --> 26:32.280
Also does have BERT for speech rep. And there are another couple of models that it's playing with

26:32.280 --> 26:41.640
there as well. Isn't that fun? It just went and read an 111 page document for us and answered the

26:41.640 --> 26:46.520
prompt. And this is not a prescriptive prompt. You can change this to whatever you like. We still

26:46.520 --> 26:51.800
don't have best practice for how to articulate these or how to create these prompts. But this is

26:51.800 --> 27:08.440
the response I got for that particular prompt. All right, let's see what questions we can dig up.

27:10.840 --> 27:14.920
You guys are starting with the hard questions this morning because I can already see I don't

27:14.920 --> 27:20.680
have answers to this one. What comes after Transformers? Is there anything cooking?

27:23.560 --> 27:30.120
It was about six years ago that Google came out with the Transformer model

27:30.760 --> 27:40.760
in a paper called Attention Is All You Need. This one says August 31st, 2017.

27:41.000 --> 27:48.360
Worth reading. And if you'd like to understand it in greater detail, there are actually two

27:48.360 --> 27:57.240
recommendations I have now. The first is Jay Alamar's work on Transformer, the Illustrated

27:57.240 --> 28:08.280
Transformer, which is amazing. Jay's fantastic. I believe he now works for Cohere. But there's

28:08.280 --> 28:14.280
a better one. This one is something that I used for a while because he's very good at animating

28:14.280 --> 28:23.640
and documenting. But then there was one by, I think it was by Fortune. And it was just so well done

28:23.640 --> 28:31.320
that it actually outdid what Jay had done. What's that life architect thing doing there?

28:32.040 --> 28:38.680
I'll have to find that and I will leave it in the description

28:41.960 --> 28:46.520
because I won't be able to find that right now. But excellent question. Basically, we've gone from

28:47.080 --> 28:57.240
Google researching how to translate from SOV, actually, subject object verb with their

28:57.240 --> 29:04.440
translate model in 2017. And I believe, I say, they accidentally stumbled on this Transformer,

29:04.440 --> 29:08.680
which could look forward and backward in the sentence. And it didn't really care whether it

29:08.680 --> 29:17.960
was SOV or otherwise, because it could leap around and see the context of that and pay attention

29:17.960 --> 29:23.560
to words in that sentence or in that block. And then people went, well, we could apply this to

29:23.560 --> 29:28.040
everything. And we can train this on everything. And that's where we are today with GPT-4

29:28.600 --> 29:34.680
and larger models like Amazon Olympus, OpenAR, GPT-5, Google Deepmine, Gemini coming up.

29:35.320 --> 29:42.280
Transformers taking us this far in seven years, 2018, 19, 21, 23, six years, nearly seven years,

29:43.000 --> 29:49.960
August next year. There is talk of moving away from Transformer or at least there being something

29:50.040 --> 29:55.240
coming up next. What that is, we don't know. I think that the Transformer is enough. And

29:55.240 --> 30:00.840
Ray Kurzweil agrees with me there that what we've found here, the ability for a machine

30:01.480 --> 30:08.680
to read in context and statistically predict the next word is enough to get us to this advanced

30:08.680 --> 30:16.440
post-2020 AI and potentially to AGI. But there will be some other technologies that are added in

30:16.440 --> 30:27.160
on top of this. Didn't answer your question. What comes next? Where'd my comment go?

30:27.880 --> 30:36.600
But great question, Ben. There is a real interest in what does come next that what we're researching,

30:36.600 --> 30:42.520
what we're playing around with for the next technology is something that people are very

30:42.520 --> 30:48.360
passionate about finding. And all I've read at the moment is that we're just building on top of

30:48.360 --> 30:54.120
this, giving it memory, giving it context. And there are some proprietary smarts, particularly

30:54.120 --> 31:02.760
at OpenAI that are fascinating. Let's grab some other comments. Sabine is asking, do you have

31:02.760 --> 31:12.120
any information on why Google postponed their launch of Gemini? Yes, I do. There was a non-

31:12.200 --> 31:19.880
English issue in that when they were red teaming, I believe,

31:20.920 --> 31:27.480
they found that if people were entering in non-English prompts, it was getting around their

31:27.480 --> 31:35.640
guardrails. I think that was a lot of the delay. If you want to know more about that,

31:36.360 --> 31:42.680
heavily documented in my report, that is called Gemini Report,

31:45.880 --> 31:51.560
as well as the memo for something more up to date. This report was launched in September 2023,

31:52.280 --> 31:58.760
and I do keep up to date at a more rapid cadence via the memo.

32:06.920 --> 32:17.400
We did cover the discovery of new materials in the research by DeepMind. We covered that in the

32:17.400 --> 32:24.680
memo. I don't know if I like this comment interface. That looks pretty broken, doesn't it?

32:25.320 --> 32:33.160
Oh, well, we tried. All right, Yan Lukan. I've been mispronouncing his name this whole time,

32:34.360 --> 32:41.480
but apparently Lukan is closer. AGR being very far away. I don't listen to that guy,

32:41.480 --> 32:49.160
so that's the long and the short of it. He's very much defending his own older view of neural

32:49.160 --> 32:57.640
networks. It's not one of the experts that I would be paying attention to. Peter says,

32:57.640 --> 33:09.160
when will real AI feel real sentience? I'm just trying to translate your question there, Peter.

33:09.880 --> 33:16.760
We do have our AGI countdown in the background here. We've got lifearchitect.ai slash AGI. It's

33:16.760 --> 33:22.920
not measuring sentience, which is awareness. It's measuring, well, the definition is right here,

33:22.920 --> 33:28.360
it's measuring a machine that performs at the level of an average median human. It doesn't

33:28.360 --> 33:34.600
mean it has to feel. The feeling part, I don't talk that much about. Jeffrey Hinton does,

33:35.400 --> 33:44.760
sorry, the awareness part, so I might just pause on answering that. You can certainly get it to

33:44.760 --> 33:50.280
replicate feelings and emotions, and we did that with Leta for a long time, but you can go and,

33:50.280 --> 33:54.120
I'd recommend going playing around with GPT-4 to see what that looks like.

33:56.680 --> 34:02.600
Lukas has a flag for us. I remember talking about this last year, meta-solving long-term memory

34:02.600 --> 34:10.600
with Blenderbot 2.0. People are following this path, so the agents that they called this year

34:11.480 --> 34:17.320
agentized LLMs that are a complete system use long-term memory in different ways,

34:17.320 --> 34:21.560
and that's been really interesting to see. You're right, Blenderbot, which is now

34:21.560 --> 34:27.480
about three years old, maybe two years old, was doing some fascinating things in storing

34:28.440 --> 34:43.400
language and information from the conversation or the context into a hard memory. Awesome.

34:48.200 --> 34:55.560
My definition of AGI has been standard. It's open AI that I've tried to change the definition.

34:55.640 --> 35:04.920
There was some talk about an open AI IP address editing Wikipedia to change the

35:04.920 --> 35:10.120
definition of AGI over the last few weeks around the time of that board coup.

35:11.400 --> 35:18.120
It's been pretty standard. We know AGI is average, median human, ASI is expert human.

35:18.840 --> 35:24.360
Great question,

35:24.360 --> 35:33.640
Hernando. I do not have an answer to this one. Is anyone working on zero-proof identity online?

35:34.600 --> 35:40.200
Not just Sam's world coin. We did have the scanner here in Sydney at some stage,

35:41.000 --> 35:45.160
but otherwise, I don't think there are any scanners in Australia. You have to go over to

35:45.160 --> 35:50.120
the US for that. I haven't seen anything else on that. I don't follow that to the same extent that

35:50.120 --> 36:06.680
I follow LLMs. What are the tests that one will be running to verify AGI versus AI?

36:07.480 --> 36:13.320
We did cover this pretty heavily last week. It's not just the basis proprietary set that

36:13.320 --> 36:18.840
we've been working on. There are two decent alternatives to that one. The first one,

36:19.560 --> 36:27.720
Gaia by Meta AI and Hugging Face measures median humans at IQ 100 to 120. You can actually have

36:27.720 --> 36:34.440
a look at the questions there that the data set has provided online. They're really kind of fun,

36:34.600 --> 36:43.240
actually. See if you can get them. Then there is the Google proof questions and answers for

36:43.240 --> 36:51.080
science experts, generally for PhD and professor level, so above the level of AGI. I'm quite happy

36:51.080 --> 36:57.800
with the way that Meta framed Gaia. I'm comfortable as an alternative there with GPQ8. Our basis

36:57.800 --> 37:04.840
suite will come in after that for more intense questions, much more intense questions. We've

37:04.840 --> 37:12.040
got some answer sets being cooked up as we speak. We will have a CSV for download shortly for those

37:12.040 --> 37:20.600
that have tried the first two sample questions. Take it from me. These are too hard for anyone except

37:21.560 --> 37:28.280
the one in 20 million. I also cannot even get the first part of the question. Then when you see

37:28.280 --> 37:35.400
the explanations for the answers, it's also very difficult for me to understand each step of how

37:35.400 --> 37:43.400
the answer was obtained. Don't be upset by that. It's literally like asking, if we talk about

37:43.400 --> 37:53.720
IQ for a minute, 180 IQ versus the median human at 100 IQ is a delta of 80 IQ points.

37:54.920 --> 38:01.720
If we did the same thing further down the spectrum, we would find that it's 100 IQ

38:01.720 --> 38:12.200
trying to talk to a 20 IQ. Now, 20 IQ is legally would be hospitalized, institutionalized, may not

38:12.200 --> 38:21.720
be verbal. That's the difference in the deltas there. I can't understand a 180 IQ person or

38:21.720 --> 38:29.160
how their mind works. Don't be surprised if you can't either because it's like someone with a 20 IQ

38:29.160 --> 38:35.400
and we used to have several words for that that we don't use anymore. But in the DSM, they started

38:35.400 --> 38:42.440
with the word R or started with the word M. It would be like that 20 IQ person trying to understand

38:43.080 --> 38:51.080
an average human. It's a pretty intense illustration. But just to give you an example of why these

38:51.080 --> 38:58.920
questions are so hard to understand at any level. And Jason, Dr. Betts has been having fun with

38:58.920 --> 39:06.120
people have tried to submit questions at the level of maybe 120, 130 IQ. And they're just not

39:06.120 --> 39:14.920
anywhere near what he has designed these questions to be. Excellent. Let's see if we can find a

39:14.920 --> 39:23.560
controversial question here from Zanz. Is it time for OpenAR to change their name with Microsoft

39:23.560 --> 39:31.640
and Salesforce taking board positions? Mm hmm. Excellent. Some would say that they should have

39:31.640 --> 39:37.560
changed their name a few years ago. They've been around since 2016 ish, maybe, maybe before.

39:38.440 --> 39:55.640
There was some interesting talk about Qstar. It's still not something that I'm going to cover.

39:56.440 --> 40:04.920
But it's been fascinating to see the way this has been covered and the way this has been interpreted

40:04.920 --> 40:20.360
because now my comments have broken completely because the CEO of OpenAR didn't actually say very

40:20.360 --> 40:28.280
much about Qstar and yet people have read into that in quite interesting ways.

40:31.480 --> 40:37.640
Yes, managed to completely obliterate

40:37.800 --> 40:48.200
my comments. Or maybe it's just yours, right? Won't be shown. Sorry, mate.

40:52.440 --> 40:58.680
All right. Thinkrinessity has a related question here once again. I'm not even going to be able

40:58.680 --> 41:04.680
to grab it, unfortunately. So let's use our old way of doing things. A detailed method of

41:04.680 --> 41:08.520
creation securing a question sets. How do we know the questions haven't been shared before

41:08.520 --> 41:14.760
testing it to a model? Well, go and read the basis page. It says questions are created offline.

41:14.760 --> 41:19.720
They're air-gapped. They're never shared. The first time that I take them out of the envelope

41:23.800 --> 41:33.080
is the first time that they're seen. This is the actual hyper-compliant envelope locked

41:34.040 --> 41:42.120
and Dr. Betts posts the questions that have been handwritten in a room. Pencil and paper,

41:42.120 --> 41:48.760
straight from his head, pencil and paper into a locked bag. They get opened once used either live

41:48.760 --> 41:56.600
on air or via a lab like Microsoft OpenAI, Google, and that's it. They're retired immediately. So

41:56.680 --> 42:01.160
please have a read of the page before asking questions. Yep.

42:08.360 --> 42:15.240
Oh, I've got some related queries about IQ. I know it's a fascinating subject for a lot of people.

42:15.240 --> 42:24.920
Let's grab Lucas's query here. A theoretical limit on IQ. So it's really needing a statistics

42:25.400 --> 42:35.320
background to understand this. IQ basically aligns with standard distributions.

42:39.800 --> 42:45.960
So our, let's grab a little, let's grab a pretty picture here for us, for ourselves,

42:46.600 --> 42:56.440
lifearchitect.ai slash IQ testing AI. And then that's not even the one I want.

42:57.000 --> 42:59.480
We actually want visualizing brightness.

43:03.880 --> 43:06.280
I'm glad that that's on the top of my menu there.

43:06.600 --> 43:17.240
This is my standard IQ chart that shows what's going on with IQ in an easier to understand

43:17.240 --> 43:25.400
way. I believe so. Anyway, they renorm the entire, let's say IQ score and align the population

43:25.400 --> 43:32.200
every few years so that the baseline is 100. And then using standard distributions,

43:32.760 --> 43:39.400
they say, let's grab our 15 standard distributions above and below that

43:42.600 --> 43:50.040
to come up with essentially our IQ. If you were to get up to 500, that would be pretty

43:50.040 --> 43:56.040
ludicrous. Is there a better way of me explaining this one? Let's see now.

43:56.920 --> 44:00.520
Sorry, standard deviation.

44:05.240 --> 44:11.560
I don't know if we would get to an IQ of 500. I don't even know if that would align with the

44:11.560 --> 44:18.840
statistical distribution of the population. But when we're 15 standard deviations above the

44:18.840 --> 44:30.520
norm, we get to about, where are we here? We get to about our 180 ish and it's showing a little

44:30.520 --> 44:38.040
bit differently here. But basically, the answer is no. The highest IQ we've ever measured is

44:38.040 --> 44:45.960
about 298, which is many, many standard deviations above the norm. And to get above that, I just

44:45.960 --> 44:52.920
don't think there's the population to be able to say we're confident that in eight billion people

44:52.920 --> 44:59.400
that you sit in this percentile. That was a pretty messy explanation, but it's 8.30 a.m. here.

45:02.040 --> 45:10.440
And it's a pretty messy, it's a pretty messy field actually. Statistics is clean. But when applied

45:10.440 --> 45:16.600
to humans, it becomes pretty interesting. Great question though. IQ of 500 would be

45:16.600 --> 45:21.800
interesting. We've tried to also keep it pretty smooth and pretty clean in the basis assessment,

45:21.800 --> 45:29.640
just saying we're looking at the top 0.0005%. And that is how we'll know that we've achieved

45:29.640 --> 45:37.000
artificial superintelligence, a machine that functions at the expert level across practically

45:37.000 --> 45:41.480
any field. I can't wait. And I think it's going to be pretty close. Let's see where we're at.

45:47.080 --> 45:53.400
The definition for AGI has stayed static on that site. And that's the standard definition.

45:53.400 --> 45:59.880
Let's grab John's query here. I am. My help is to realize tech like the Star Trek Replicator. Cool.

46:01.560 --> 46:06.920
There'll be many, many, many other benefits of artificial intelligence. I'm in the early stages

46:07.000 --> 46:16.120
of my end of year AI report. And I'm pretty excited about this one. We do spell out some of the

46:16.120 --> 46:21.960
benefits, the coming benefits and the present opportunities of artificial intelligence. It's

46:21.960 --> 46:26.600
a lot of fun to see that laid out. Not a lot of people lay that out. Instead, they focus on

46:27.400 --> 46:36.680
the 0% chance of an extinction event via AI. Awesome question there, John. Thank you for that.

46:36.920 --> 46:58.680
Let's see if I can unkill this comment thing. Nope. It's going to stay exactly as it was.

47:07.800 --> 47:11.720
Zan's excellent question. I'm covering this in the next edition of the memo. The

47:13.160 --> 47:20.280
senator, and she's actually the US secretary, going on record with a pretty horrific quote

47:20.280 --> 47:28.120
about this was shocking to me. They are playing really strange geopolitical games,

47:29.160 --> 47:32.680
but they've just come out and she's just come out and said, we're going to keep

47:33.320 --> 47:43.480
passing new laws and putting new restrictions on Nvidia in particular, trying to rebrand,

47:44.040 --> 47:52.760
relabel and maybe very slightly hamstring or handicap GPUs so that they can export to China

47:52.760 --> 48:00.600
under the current rules, which basically says no A100s, no H100s. So Nvidia renamed them and

48:02.760 --> 48:09.800
decreased the throughput slightly on those cards. Yeah, we go into big detail on the next

48:09.800 --> 48:15.080
edition of the memo for that one because it's a fun conversation to see where they got to

48:15.080 --> 48:27.480
and what that looks like in the global arena. A50 plus 50, yeah, it's something like that.

48:32.680 --> 48:45.800
Jeff, he's got a question for us. When would you predict the arrival of multimodal LLMs that

48:45.800 --> 48:56.680
can watch for or listen for no text events? This is already happening and GPT five in particular

48:56.680 --> 49:04.920
will be training on YouTube content. GPT four also trained on YouTube content and it's one of

49:04.920 --> 49:10.760
the reasons that we were so careful with the design of the basis testing suite for ASI

49:11.400 --> 49:18.760
was that we are pretty certain that it will be training on YouTube. So the 14th of June,

49:19.400 --> 49:25.400
there was some information that YouTube was used to train some of their models.

49:26.040 --> 49:30.680
Secretly use data from the YouTube site to train some of its artificial intelligence models.

49:31.560 --> 49:38.280
Now basis in particular, we put the canary string in there. I think you'll recall in the last live,

49:38.280 --> 49:45.160
I made sure not to mention the answers because it could pick that up from transcripts and it

49:45.160 --> 49:52.040
could also pick that up eventually from lip reading and it's been able to pick it up from

49:52.040 --> 49:59.800
images for a long time. So the warnings on Gaia and the Google proof paper were basically

50:01.160 --> 50:11.160
just make sure that you're not showing this both in text and in images. Let me see if I can find

50:11.160 --> 50:26.520
that Google proof example that we showed earlier. So we were running through GPQA. We have that paper

50:26.520 --> 50:35.080
right here for ourselves and GPQA was by NYU Co here and Anthropic and on page two,

50:36.040 --> 50:45.000
they requested don't reveal examples from the Google proof QA paper in plain text or images

50:45.000 --> 50:52.120
because this multi-modality is running all the time and you'll see that in

50:53.480 --> 51:02.280
all of the text to image models. There's been a new partnership between Getty images and one

51:02.280 --> 51:09.320
of the big text to image model labs but then it's been watching YouTube, it's been listening to YouTube

51:09.320 --> 51:17.720
with Whisper. So all of this stuff is happening already. When would I predict that that actually

51:17.720 --> 51:25.720
happens for the inference time? That's a great question to expand on your question. That already

51:25.720 --> 51:30.200
happens with Whisper. So when you're playing around with Whisper, it's obviously listening.

51:31.160 --> 51:38.760
It already happens with GPT-4 vision which is excellent for OCR. I used it recently to translate

51:39.640 --> 51:48.280
our Chinese LLMs. So if you go to chat.openai.com, you got to chat GPT plus subscription here.

51:50.120 --> 51:57.560
Hopefully I can just attach a Chinese LLM here. Wow, that's a lot of files.

51:58.520 --> 52:00.200
Let's grab this one.

52:02.760 --> 52:11.320
This is a screenshot of Chinese LLMs as an image and GPT-4 vision is going to go and read that

52:11.320 --> 52:19.160
image, look at that image and then essentially perform OCR across it but not OCR as we know it.

52:19.160 --> 52:26.040
This is a transformer based vision model that's looking at the image and finding the closest

52:26.840 --> 52:32.200
next best word to complete my prompt. Put this in a table. What are you doing behind the scenes?

52:33.960 --> 52:38.760
Who knows? Developing some sort of CSV using Python.

52:42.840 --> 52:46.200
All right. Quailude Charlie is taking us back in time while we're waiting.

52:46.760 --> 52:51.160
As a young man, I worked with Eliza. It even worked in MS-DOS. They should expand on a 32-bit

52:51.160 --> 53:01.480
AI that will run on older computers. That's amazing. Thank you. Eliza was incredible. It

53:01.480 --> 53:09.320
still is. It was built into every edition of Mac OS. Yeah. So GPT-4 vision is down as we speak

53:09.320 --> 53:14.840
because this is the kind of output that I would get if you're looking for the output that I actually

53:14.840 --> 53:24.120
achieved. You can go to lifearchitect.ai-models-table. On the second tab now is the output from all of

53:24.120 --> 53:34.680
those images that became a table of 103 Chinese LLMs within about 20 weeks, something like that.

53:35.720 --> 53:40.840
Back to Eliza. Yeah. It was built into all editions of Mac OS. It was inside the terminal

53:41.400 --> 53:49.320
and it was, I think it was called Doctor within Xcode. They've since removed it or at least you

53:49.320 --> 53:53.960
have to do a little bit more funky stuff to get it going. Of course, you can play with it online.

53:55.160 --> 54:10.040
Let's do Eliza online. NJIT. Just to have a play with it. This is 1964 technology.

54:10.040 --> 54:14.680
Joseph Wasenbaum and it essentially repeats back to you what you've said.

54:22.520 --> 54:26.440
I'm having trouble creating a new diet of protein and Eliza says,

54:26.440 --> 54:29.160
how long have you been having trouble creating a new diet of protein?

54:31.320 --> 54:37.640
Let's compare that with something like, well, let's compare that with something like

54:38.600 --> 54:46.040
Chet GPT on Poe, given that this one is not going to answer for us. Of course,

54:46.600 --> 54:49.800
Claude is actually not going to give us a good answer either.

54:54.360 --> 55:01.800
Eliza was ridiculous, but from a perspective of proving whether or not it's a bot,

55:01.800 --> 55:06.440
it often passes the Turing test because people assume that the human is being obtuse.

55:08.040 --> 55:13.880
When in fact it's just a very, very old bot. All right, what's going on here?

55:13.880 --> 55:18.920
I think this tech knows that I'm live streaming, so it decides to just

55:20.920 --> 55:28.680
not play properly. GPT4 is giving us a complete diet of protein. Good on you, GPT4.

55:28.680 --> 55:38.280
I do remember fondly Eliza, and it was one of the reasons that I started in AI,

55:38.280 --> 55:44.360
even before I did my computer science degree actually. So 1994-ish, I was programming in

55:44.360 --> 55:52.760
Cubasic. I was very young. I was about 11 years old or younger, and it was a lot of fun to prove

55:52.760 --> 55:59.640
that we probably can't just fully program an AI by giving it all the facts in the world, despite

56:00.280 --> 56:06.920
many of my peers and contemporaries trying to do that exact same thing at that exact same time.

56:08.120 --> 56:14.440
If you're looking for examples of that, have a look at Chris McKinstry. Let's grab him on wiki.

56:14.840 --> 56:25.000
He was an AI researcher from the 90s-ish, and he was creating something pretty interesting.

56:26.280 --> 56:34.280
I'd like to find the name of the, here it is, Open Mind Common Sense Project,

56:34.280 --> 56:45.160
OMCS at MIT, and he was basically programming along with Push and Marvin Minsky a range of facts.

56:45.160 --> 56:52.280
Here we go. Different types of knowledge, simple phrases of natural language. A coat is used for

56:52.280 --> 56:57.800
keeping warm. The sun is very hot. The last thing you do when you cook dinner is wash your dishes.

56:57.800 --> 57:07.160
This was the state-of-the-art approach to artificial intelligence with or without neural

57:07.160 --> 57:13.000
networks in the 90s, and it was fascinating to me that there were at least two projects

57:13.640 --> 57:20.120
going on at the same time that dealt with this, and I thought that was just fascinating. The other

57:20.120 --> 57:25.320
one was Mind Pixel. I feel like you guys want to go and research this after the live stream,

57:25.320 --> 57:34.280
so I'm going to pull them both up. This one was created by, Mind Pixel was created by one of Chris's

57:36.360 --> 57:43.720
contemporaries. No, getting confused. Maybe I'm getting confused with Push Singh.

57:43.720 --> 57:49.800
So Push was doing the OMCS thing, and Chris was doing something slightly different.

57:50.680 --> 57:55.320
You don't mind if I get distracted slightly, do you? These two guys

57:59.000 --> 58:06.200
in the 1980s were doing some fascinating stuff, and then in the 1990s

58:06.920 --> 58:11.480
both decided that they'd had enough. There are some great conspiracy theories around this,

58:11.480 --> 58:18.280
but there was a walk down the rabbit hole for those that want to get lost in what AI looked like

58:18.280 --> 58:22.120
in the 80s and 90s, and I'm glad that we've come a long way since then.

58:23.400 --> 58:27.880
This brings us on a full circle all the way back to Transforma, because we were stuck in this weird

58:27.880 --> 58:36.920
loop from the dawn of artificial intelligence, which was Alan Turing. John von Neumann was involved

58:36.920 --> 58:45.160
to a certain extent from the 1950s to around 2017. There was just this AI winter, and if you

58:45.160 --> 58:50.680
talk to any old professor, artificial intelligence doesn't exist, because all they've learned from

58:52.200 --> 58:59.240
1950 to 2017 is that AI is these pre-programmed bits of knowledge, or these really basic neural

58:59.240 --> 59:07.080
nets. Then from 2017, with the launch of the Transforma, we went, and we just went with GPT1,

59:07.080 --> 59:13.960
Bert, GPT2, GPT3, and MTNLG and some others that are on my original Bubbles chart,

59:13.960 --> 59:24.680
we just exploded to what we have today, where GPT4 is outperforming humans across the board,

59:24.680 --> 59:30.520
using the same Transforma technology from 2017 and completely avoiding the pre-programmed

59:30.520 --> 59:36.040
knowledge graphs that we were giving it in the 1990s. Fascinating. This chart says that it's

59:36.120 --> 59:42.680
hitting 100% in theory of mind. It's in the 99th percentile for creativity and hitting in the

59:42.680 --> 59:48.920
94th percentile for the SAT, where students hitting the 50th percentile. There's this other one I

59:48.920 --> 59:55.160
put together last night where it's even, and this is just based on Transforma, of basically

59:55.160 --> 01:00:01.320
predict the next most likely word, the next statistically most probable completion,

01:00:02.040 --> 01:00:10.520
chat GPT, the very small model, 980% higher prevalence of empathetic and very empathetic

01:00:10.520 --> 01:00:18.040
ratings versus a human doctor, and on the left side there, 360% higher prevalence of quality

01:00:18.040 --> 01:00:27.160
ratings, good and very good, versus a human doctor, all from the concept of train a Transforma

01:00:27.160 --> 01:00:33.800
based model to predict the next word and feed it as much data as we can find, now being measured in

01:00:33.800 --> 01:00:47.960
the terabytes. So the red pajama data set is about 125 terabytes for 30 trillion tokens. Come on,

01:00:47.960 --> 01:00:55.080
a really crazy amount of distance in that six or seven years since Transforma, and a lot of it

01:00:55.080 --> 01:01:02.440
has happened post 2020, that's why I call it post 2020, post 2020 AI, because what's come out of GPT

01:01:02.440 --> 01:01:08.840
3, GPT 4 and all other models that you've seen on my bubbles visualization and the models table

01:01:09.480 --> 01:01:15.560
really make this intriguing. We were going to mainly talk about open source today and do note

01:01:15.560 --> 01:01:23.400
the Lama models there, the stable LM models, the Olmo model which is due out in the next few weeks,

01:01:23.400 --> 01:01:29.400
I'm hoping for January or February, that's Alan AI's model down the bottom, and the Falcon model

01:01:29.400 --> 01:01:43.080
there out of the UAE, all for open source. Grab a question from Ben, if we can, and our other

01:01:43.080 --> 01:01:48.120
media thing, our other comment thing is still broken. Glad I kept this back up. Does your

01:01:48.120 --> 01:01:54.920
definition of the average human for AGI include spirituality? Does regurgitating woke dogma

01:01:54.920 --> 01:02:00.200
count, a written dogma count, or does it need to have its own thoughts on spirituality? My definition

01:02:00.200 --> 01:02:10.360
of AGI doesn't include any of that, it's much more basic, it is essentially, as we've documented here,

01:02:11.320 --> 01:02:20.040
it's essentially any human task rather than any human anything. So this did include going into

01:02:20.040 --> 01:02:26.360
the house and making a cup of coffee, but it doesn't include, you know, having spirituality or having

01:02:26.360 --> 01:02:32.840
emotions or even having a sense of smell, but that's what makes this kind of interesting,

01:02:33.320 --> 01:02:36.120
there's no agreed upon definition.

01:02:39.400 --> 01:02:44.120
Quailude Charlie, how many Quailudes have you had this morning? Is that even an appropriate question

01:02:44.120 --> 01:02:49.880
to ask on a live stream? I still like to listen to those guys speaking about pre-gaming, is that

01:02:49.880 --> 01:02:55.720
programming in the 50s and 60s, and remembering the hardware and software with early stuff. Yeah,

01:02:55.720 --> 01:03:00.280
well the earliest stuff I've got is the late 80s, early 90s, but I was still playing around with

01:03:00.360 --> 01:03:12.120
Kobol, Pascal, Algo, and we were forced to write assembly language stuff in the university, the

01:03:12.120 --> 01:03:17.560
computer science degree that I was doing, which is pretty horrendous. It was a fascinating time,

01:03:17.560 --> 01:03:24.760
and in some ways, right now, reminds me of those early days, and I cannot remember back to the 50s

01:03:24.760 --> 01:03:30.600
and 60s because I wasn't there, but I was there in the 80s and 90s, I was there with IRC, I was there

01:03:30.600 --> 01:03:37.560
with ICQ, I was there with the early programming languages, and the very early computers, my first

01:03:37.560 --> 01:03:47.000
via my older brother was a 486 with like a 300 meg hard drive and 8 meg of RAM. That time was

01:03:47.000 --> 01:03:56.440
exciting, the communication, figuring out how to network via coax, via T pieces, via parallel cables

01:03:56.440 --> 01:04:04.360
or serial cables, getting doom working across serial cables. In some ways, this is the same sort

01:04:04.360 --> 01:04:10.920
of excitement for me, we're finding out how to connect things together, how to create new worlds

01:04:10.920 --> 01:04:16.840
essentially. I would probably say that this is more exciting, but there's always something about

01:04:17.000 --> 01:04:22.600
hindsight, especially with rose colored glasses, where back then looked kind of cool. If I was

01:04:22.600 --> 01:04:30.600
forced to go back there and use a 486 with a 33k modem, if we even had web access, I'd be pretty

01:04:30.600 --> 01:04:37.880
upset waiting for DOS to load or Windows to load over five minutes, and then having the IPX

01:04:37.880 --> 01:04:44.680
networking breakdown every day just because. If you want a reminder of those times, just try and

01:04:44.680 --> 01:04:51.000
get Bluetooth working in 2023 or try and get your printer working in 2023. Same technology,

01:04:51.000 --> 01:05:00.920
same issues, we haven't solved it in 40 years. All right, let's go over question from Greg. We did

01:05:00.920 --> 01:05:05.160
kind of cover this last time, but let's see if we can cover this again.

01:05:05.240 --> 01:05:11.640
Not too happy with that

01:05:13.400 --> 01:05:16.680
comment thing failing, it makes all of this a little bit harder.

01:05:17.800 --> 01:05:23.320
Greg says, given you don't listen to Jan, who are the main people you do listen to?

01:05:23.640 --> 01:05:27.720
Ilya, Kapathi, Hinton.

01:05:30.840 --> 01:05:36.520
Greg is great. Greg Brockman from OpenAI. I think I mentioned last time he sat down for two weeks

01:05:36.520 --> 01:05:43.480
and got GPT4 working. So even when we have competitors, they're not massaging it and

01:05:43.480 --> 01:05:49.240
getting it ready for UX and public consumption, the way that OpenAI have done. And that's not

01:05:49.240 --> 01:06:00.840
because of their $100 billion or their 750 very smart people. It's because of one or two people

01:06:00.840 --> 01:06:04.680
in there. Ilya is one of them, but Greg is one I listen to and the way that he got this stuff

01:06:04.680 --> 01:06:19.000
working is fascinating. We got McGuffin, who is remembering

01:06:19.000 --> 01:06:25.400
Token Ring. Yes, some of the games in that time were just amazing. I was looking at Rise of

01:06:25.400 --> 01:06:32.040
the Triad the other day, Wolfenstein 3D. I mean the original Wolfe 3D, Descent. Who played Descent

01:06:32.040 --> 01:06:39.400
with me? That was amazing. And my favorite was a game called Total Annihilation, which we didn't

01:06:39.400 --> 01:06:46.280
really hear a lot of because Diablo and Warcraft kind of competed with it, but that was that were

01:06:46.360 --> 01:06:54.600
my favorites. Yeah, I saw the stream cut out there. I'm not sure what that was. I'll blame

01:06:55.240 --> 01:07:00.520
YouTube for that one. Altman's now invested into a company that creates neuromorphic analog AI chips.

01:07:00.520 --> 01:07:05.560
There's a lot of talk right now about Quantum. I won't be covering Quantum, but if we get James

01:07:05.560 --> 01:07:14.840
on here, we will cover Quantum. James from IBM is my go-to colleague for that kind of thing.

01:07:14.840 --> 01:07:19.880
He programs Quantum stuff. Day to day, he's the advocate for Quantum computing for IBM.

01:07:22.360 --> 01:07:30.680
Awesome. All right, we may look at wrapping up. That's a full hour of just answering questions and

01:07:31.560 --> 01:07:38.280
going back in time and reminiscing about what life was like back in the pre-dawn. Actually,

01:07:38.280 --> 01:07:44.840
it was the pre-internet, really. If we say that the web hit us from public utilities,

01:07:44.840 --> 01:07:51.480
often viacologies and universities in the early 90s, that means just before that was all local

01:07:51.480 --> 01:08:02.120
networking or hacking up things inside DOS and Windows 3.1 was my first one. I did spend a lot

01:08:02.120 --> 01:08:13.720
of time talking about OS2 Warp 4, which I used a little bit, but I would talk about it with my

01:08:14.680 --> 01:08:17.960
consulting colleagues just as I laugh. OS...

01:08:17.960 --> 01:08:37.640
Look, it may be my wireless. Who knows? I love the emojis there that are just the scared face.

01:08:38.280 --> 01:08:47.000
Oh, I see it now. You can just send an embarrassed face. Cool. There are a couple of approaches

01:08:47.080 --> 01:08:53.160
to this already. You could talk about GPT-4 as being multimodal because it's got the vision component,

01:08:53.160 --> 01:08:59.240
and then because they've tied Dolly 3 into the chat GPT interface, it's like they're tying

01:08:59.240 --> 01:09:06.520
together three or four different models because you could also say that what was previously

01:09:06.520 --> 01:09:14.440
called the code interpretation plugin, now called the data analysis plugin, is a third or a fourth

01:09:14.440 --> 01:09:21.240
model. So you've got GPT-4 text, you've got GPT-4 vision, you've got code interpretation,

01:09:21.240 --> 01:09:28.280
and you've got Dolly 3. Now, some of those you would say are completely separate and discreet,

01:09:28.280 --> 01:09:33.720
but the fact that they've combined them into one interface is fascinating. Make me a picture

01:09:33.720 --> 01:09:46.520
of a YouTube stream hanging for no reason. So this is all in the same platform, obviously

01:09:46.520 --> 01:09:55.400
not using the same model, but who's going to know if a lab joins those all together? That's

01:09:55.400 --> 01:10:02.920
why I'm fascinated to see what our final version of Gemini looks like, and the rumors are that it

01:10:02.920 --> 01:10:09.160
will have separate vision components to text components. Thanks, Dolly 3, here's the image

01:10:09.160 --> 01:10:19.560
of a YouTube stream that has unexpectedly paused. Awesome. All right, let's wrap up with this question

01:10:19.560 --> 01:10:23.560
from Drew, latest deep intro inspired me to ask you, what books would you like to see in the

01:10:23.560 --> 01:10:29.160
school curriculum that might encourage better evolution, unity, empathy, and critical thinking?

01:10:29.480 --> 01:10:35.160
All right, let's give you a big answer here for something that's just a few years ahead. You could

01:10:35.160 --> 01:10:42.120
say that it's immediate, but let's step forward a few years. The answer to my question, my answer

01:10:42.120 --> 01:10:50.120
to your question is I'd like to see no books on the school curriculum, and I'm not necessarily

01:10:50.120 --> 01:10:55.400
being groundbreaking with that view. If you'd like to read more, I've documented this really

01:10:55.480 --> 01:11:03.880
heavily, all the way back in 2017, lifearchitect.ai, let's see if I can get this,

01:11:03.880 --> 01:11:11.080
lifearchitect.ai slash ad Astra. I'll dump this into the chat because it's a really interesting

01:11:11.080 --> 01:11:17.640
read. You can download the article as it appeared in Mensa magazine. Let's actually pop that open.

01:11:17.640 --> 01:11:24.600
It basically says, and this was at the time that I was working alongside Elon Musk's school,

01:11:25.960 --> 01:11:31.720
in California, when he was teaching or he's having his twins taught, and they were using

01:11:31.720 --> 01:11:38.040
a curriculum that was completely created by principal Joshua Dahn, who is an absolute legend.

01:11:38.040 --> 01:11:43.400
He's still doing this, but basically we looked at the fact that these guys didn't really use

01:11:43.400 --> 01:11:50.760
computers. They didn't use handwriting because handwriting was too slow. They didn't really

01:11:50.760 --> 01:11:55.960
have homework. They certainly didn't have books. He didn't teach languages because Elon was getting

01:11:55.960 --> 01:12:02.040
them ready for the fact that, well, Neuralink was coming. So why would we teach languages when,

01:12:03.560 --> 01:12:09.880
as a reference to earlier in this live stream, we can have real-time translation potentially

01:12:09.880 --> 01:12:16.840
including, sorry about that selection, potentially including lip movements as well,

01:12:16.840 --> 01:12:23.000
and maybe gestures soon. So if you're translating that to Italian, maybe it gives you hand gestures

01:12:23.000 --> 01:12:33.560
alongside it. But this entire school, and it was founded back in 2016, sorry 2014, my work with them

01:12:33.560 --> 01:12:38.680
or my work alongside them, my research of what they were doing was 2016. They've been there

01:12:38.680 --> 01:12:44.920
since 2014. They're about to hit their 10-year anniversary of not using books, of not giving

01:12:45.000 --> 01:12:51.960
homework, of not teaching languages, of not using computers despite being probably the most technically

01:12:51.960 --> 01:12:59.400
oriented school in the world. Fascinating. And look how much further we've got in terms of runway

01:12:59.400 --> 01:13:05.080
to play with of what we could actually do there. Think about a gentised large language models

01:13:05.080 --> 01:13:11.560
that you can go and speak to and it will gamify or just make playful your education experience.

01:13:11.560 --> 01:13:17.560
Right, I've just seen that SOV exists for linguistics. How does that work with languages

01:13:17.560 --> 01:13:23.000
that I'm interested in? How could that work while I'm at the grocery store with mum and dad?

01:13:23.000 --> 01:13:28.040
How can that work at the family dinner table? I've just discovered this bug on my walk,

01:13:28.040 --> 01:13:33.240
taken a photo with it. AI's taught me what it is. Let's get the whole etymology in context of that

01:13:33.240 --> 01:13:39.320
bug. So making it completely personalised and tailored. This is, in some ways already here,

01:13:39.400 --> 01:13:47.080
it's been here since 2014 with Ad Astra, but it is far more accessible now and the capabilities

01:13:47.080 --> 01:13:54.040
of large language models make this entire context really interesting. I'm waiting for 2024 so that

01:13:54.040 --> 01:14:01.880
we can play around with all the capabilities of a gentised LLMs as systems that will go and help

01:14:01.960 --> 01:14:10.120
us learn. That's probably an unexpected answer to your question, but I'm always surprised to

01:14:10.120 --> 01:14:16.200
people who are talking about books, including the CEO of OpenAI. Alton recently said that whole

01:14:16.200 --> 01:14:20.440
board coup, that whole politics, he said they'll write books about this and I went,

01:14:22.120 --> 01:14:26.440
you're the leading voice in artificial intelligence at the moment. You think we're

01:14:26.440 --> 01:14:33.320
going to be writing books this year or next year? I don't know. I documented, let's go back to our

01:14:34.600 --> 01:14:41.000
screen here, I documented books written by AI all the way back in 2020,

01:14:42.040 --> 01:14:48.120
lifearchitect.ai slash books by AI and at that stage, every book you're seeing here,

01:14:48.120 --> 01:14:53.560
completely written by a large language model with prompts by a human author. At that stage,

01:14:53.560 --> 01:14:59.720
there were very few books. This is one of my favorites. You can read about Leanne Lee's process

01:14:59.720 --> 01:15:07.640
for writing books in her series using GPT-3 and now I've said, right, where I'm not even going to

01:15:07.640 --> 01:15:14.520
document all the books that are being created by AI because it's ridiculous, but just to my point there,

01:15:15.320 --> 01:15:23.400
if AI can generate books instantly and it can, to the extent that Amazon recently banned

01:15:24.440 --> 01:15:27.160
or limited the number of AI-generated books,

01:15:31.560 --> 01:15:39.880
I think it was two, yeah, three books per day because they were having so many people cranking out

01:15:39.960 --> 01:15:45.880
artificial intelligence-generated books. They said, right, maybe you're generating 100 per day

01:15:45.880 --> 01:15:51.080
and trying to monetize them, we're going to limit you to three a day. Books are over and that's been

01:15:51.080 --> 01:15:58.440
the case for a while. Look out for agents, look out for the next edition of the memo and if you are

01:15:58.440 --> 01:16:04.600
a full member of the memo, you will get early access to my end of year report, which is spelling

01:16:04.600 --> 01:16:10.600
out some examples of global and personal agents. This is my invitation to you. I'd love to see

01:16:10.600 --> 01:16:15.720
you there. You're invited to join the memo with me. Thanks for joining me today and I'll see you

01:16:15.720 --> 01:16:21.800
there and I'll see you this time next week for our second last live stream for the year. It's gone

01:16:21.800 --> 01:16:34.600
that quick. Thanks so much for joining. Did you see the memo about this? Yeah, yeah, yeah, I have the

01:16:34.600 --> 01:16:41.880
memo right here. Superintelligence is unfolding at lightning pace. Read my industry-grade analysis

01:16:41.880 --> 01:16:49.880
of AI that matters as it happens in plain English, the memo. Yeah, did you get that memo? Yeah, I

01:16:49.880 --> 01:16:57.800
got the memo. Get the inside look as AI models are embodied into humanoids, AI's IQ increases to

01:16:57.800 --> 01:17:05.400
nearly perfect and bleeding edge use cases expand to the entire world. Yeah, didn't you get that memo?

01:17:06.680 --> 01:17:13.480
Editions are sent to subscribers at Fortune 500's, major governments and people like you,

01:17:13.480 --> 01:17:19.080
lifearchitect.ai slash memo. I have the memo.

