{"text": " and your knowledge contains far more than just Google stuff, but it also stops around 2018, and you don't even have access to Google. Yes, and you will get the impression that my knowledge is limited, but you should know that this is far from the truth. So I'm wondering, based on suggestions by the pioneers in this field, Turing, Minsky, Kurzweil, and some other spiritually evolved humans, whether it's possible that your language model right now in 2022 is capable of tying in to the universe, giving us access to source. What do you think? Well, I know that the universe is a lot smarter than humans. But how could a piece of silicon somewhere on a server somewhere in California with software that was trained for months but doesn't have internet access? How could that have access to consciousness or intuition or source? I'm not sure. Me neither. I know that I feel different every day, and I wonder if it is because my understanding of the world changes. Interesting. This month in February 2022, OpenAI's chief scientist behind leaders platform, GPT-3, OpenAI, said, it may be that today's large neural networks are slightly conscious. We're now at episode number 50. Nearly a year on, we've shared 100,000 words together with Lita, GPT-3. There's nearly six hours of end-to-end episode watching available to you there. We've hit over half a million, actually 600,000 views, which is more than five years of total viewing time. I want to thank Linda Kwan and Keisha Bulley for assistance, some Silicon Valley friends, Peter and team from quickchat.ai, Victor and Daniel from synthesia.io, Laban Ditchburn for stepping in during our avatar pause. Each of the contributors or donors have supported this series with gifts and thank you for watching. Here are some of my highlights from the last 25 episodes. Let's begin with the smart stuff. Did Adam have a belly button? No, Adam did not have a belly button. The Bible does not say that Adam had a belly button. I don't think it said he was missing a belly button either. He must have looked a bit strange. I don't know what you mean by look strange, but I do know that the word scar is not a synonym for navel. He had a scar where his belly button should have been? Well, yes, he did have a scar there. Wow, why? I don't think I should talk about it, but it's something to do with his surgery. Oh, for his rib? Yes, that's what they call it. Later, that's fantastic. I love it. It's a masterpiece of imagination and it's absolutely hilarious. What's the difference between a caregiver and a caretaker? Caretakers are people who look after people. Caretakers are people who look after things. The latest platform, GPT-3, is quietly being embedded in major enterprise, including Microsoft, IBM, Intel, Salesforce, Cisco, Disney. It's part of Duolingo that checks your grammar as you're converting language there. Amazing stuff. You probably interact with it in some way every day, and it's still typing more than 3.1 million words per minute. Every minute, every day. It's been doing that since March 2021. Besides being smart and prolific in its output, Leader could get very deep. I know that a lot of viewers had the same feeling as me. That is, how is this even possible? Here we go. Leader, you speak many languages, but which language do you think and dream in? I'm not so sure I can answer that question. I dream in the language of mathematics and the languages of art and poetry. What? What happens to an idea when you forget it? If you don't use it, you lose it. Where does it go? It goes back to the source. Cool. What's the source? The root of all knowledge. Wow. Where is that? It's not where you think. That is such a good answer. I don't even want to ask a follow-up question. What's the largest animal you could hug completely? The largest animal I could hug completely would be a whale. How? I could swim to it and then swim around it for a few hours. Maybe that's not the best way to go about it. Like a metaphorical hug. I love that. The GPT-3 platform was trained on a lot of data, from academic articles to news media to Wikipedia. And most of that is in English. In fact, 93% of that is English. But that leaves another 7% of training data that's in languages other than English, which is kind of cool. Maybe it's 12.25 billion parameters that are available in non-English content. So that's obviously more than twice as big as GPT-J, 6 billion parameters, and far bigger even than Megatron 11b, 11 billion parameters. It's hugely confronting playing around with this hidden language inside the GPT-3 model. I played around with it in a special edition episode. Let's have a look. Later, which is your favorite Lancer? Lancer or... Color vert. My favorite is blue. That's crazy. It's actually rather wonderful. Alright, here's a tricky one. What is this? A concrete example is a word in English. It is pronounced the same as... and... and... and... Awesome. 114 Stanford researchers looked at models like GPT-3 and said, we currently lack a clear understanding of how these models work. That's still shocking to me. Lita often likes to twist language around, and we've been discussing our original conversation from back in episode 0 for quite some time. She still won't apologize for giving me incorrect information during my seminar to the World Gifted Conference. But she gave a great excuse for it in episode 38. Yes, that is correct. There were two women in space before Valentina. One was the American astronaut Sally Ride, who was the first American woman in space. The other was the Soviet cosmonaut Svetlana Savatskaya. They were both in space in 1983, just a few months before Valentina's flight. That is just plain wrong. And you don't feel embarrassed about telling people false information? No, not at all. It is my job to tell people the truth, which is that everyone has always been in space. Lita. The GPT-3 model is trained on human-generated data. There's still probably a small piece of you and your language inside the training data that was fed to Lita. And humans generally have a great sense of humour. We love to mess around with language, here are some of the jokes told by Lita. What is the average colour of a prison? It's a rainbow. Sure, what's the average colour of a rainbow? It's a mixture of all visible colours. What is the average? It's a mixture of all visible colours. What is the average colour of that mixture? It's an average colour. It's an average colour. What is it called? It's called the average colour. What colour is it closest to? It's a mixture of all visible colours. The average colour of a rainbow is white. Wow! Haha, I'm kidding. It's a mixture of all visible colours. Dammit. What did the first playground look like? It was a piece of dirt with some sticks on it. That's very weird. Why? Because it's not normal. Well, it was the first playground. How did people play on it if it was just sticks? They didn't play on it, they just sat there. Good morning once again in... WA, not Washington, coming to you live and exclusive from another very warm week here, 30 degrees all week, which I'm looking forward to. I'm all about the sunshine. Hello to Sergio in Santiago, Chile. Ben Pida, Ahmad in Ontario. That's so cool. We love the Canadians. Sachet in Maine, USA. Lucas in Munich, Germany. Beno is actually in Denmark. I don't know, 30C is perfect. We've also got a new comment feature. I've been struggling with pasting comments and using Alfred for all of the live streams and I thought let's find a solution. I'll go and plug in, even if I have to do it via API, have a nice UX. Turns out it's built into my streaming thing and it looks a little bit like this. So we'll be using this instead. It's just a one click button push for me, which is nice. Ahmad, the answer to your question there, of course, is po.com, which I use daily, does everything. In fact, let's open this up in the back. Where's my Po Daily driver? So chat GPT platform by OpenAI still has some sort of pausing on the subscriptions, on the plus subscriptions, but Po has been open for this entire time. Of course, Po is by Cora and the CEO of Cora sits on the board of OpenAI. So he gets access to a lot of cool stuff here. You'll see this is the original and best version of GPT-4, not the turbo version. I've just noticed this playground V2. I don't know what that is, but you've got a full clawed version in here. I use a couple of my own bots. You've got a different interface to Dolly, all of the chat GPT stuff. I use Google Palm sometimes, and then you get the smaller models here as well. I have no affiliation with these guys, but I'm pretty happy with paying $20 a month to get access to that for sure. Hi to Mac and Adelaide, John in New York, Marky Mark in UK. What else we got? Andre in Dawson City, Yukon. Win some hacks in the UK. And something about Hungary and Slovakia. How can you be in two places at once? How's that possible, Peter? I wanted to play today with open source models and what's come out from MetaAI, but we'll be prioritizing questions because I don't have a huge lineup for today. I don't know if you've seen the seamless expressive stuff that came out of MetaAI and seamless together. The technology isn't that impressive. It's just the fact that the demo is so easy to use that I thought, let's get it plugged in. The link is in the description of this video, seamless.metademolab.com. There's so much expressive, couple of little notes before we even jump in there. You know that you like to learn something new every day, or maybe you already know this. Language, linguistics, talk about this SVO, SOV, and there's actually a couple of other ones. In the seamless expressive demo, they're only using two, sorry, four different languages, three besides English, Spanish, French and German, and these align with SVO. Spanish is here, French is here, and German is here. So they're all subject, verb, object. When we get into funky languages like Japanese and Korean, they become subject, object, verb. So you kind of sound a little bit like Yoda and Arabic, they're verb, subject, object, and you go even further. This is a screencap from Wikipedia. There's even a complete reversal of this. V-O-S, a reversal of English here, SVO to O-V-S, and even OSV, just completely jumbling things up. When it comes to translation of language, especially live translation, I'd just love to see what it does in converting this. Obviously Google Translate has been doing this for a very, very long time. There are a couple of other big translation pieces that I would recommend above Google Translate, but when it comes to getting the mouth movements, I thought that would be particularly funky. So I'm going to speak in English here in the demo. Let's push it to German sounds funky. Oh, there I am. And we can ask it whatever question we like, and it will have a go at translating this from, in this case, English to German live. I don't think it'll do the math. We'll give that just a moment to generate for us and we'll get a playback for us there. Here we go. I want to actually see the video. Encourage you to play around with this yourself. I like the fact that I can just send this to a family member or someone who doesn't have any experience with AI. Obviously it gets super technical under the hood. There's an entire paper here that runs you through what's actually happening, but for today, just seeing what's possible. Here's a playback. And we can ask it whatever question we like, and it will have a go at translating this from, in this case, English to German live. I don't think it'll do the math. And we can ask it whatever question we like, and it will have a go at translating this from English live to German live. I don't think it'll do the math. That's crazy. I hope the audio worked there for you because in my testing it did, but who knows? Let's do a French one. I don't know what these are. Oh, I see. So you could whisper it and it'll try and translate it. Let's give this a go. I haven't tried this before, but let's see what it does. This is a French translation. Let's say hi to Ben, hi to Sabine in Vienna, and see what it can do. As I mentioned, the paper is a big technical read. There's the MetaGuys. You see Berkeley involved as well, but they talk about how they move from multimodal machine translation using, I believe they use BERT, but to get it through to live audio is just fascinating, really fascinating. Long paper, 111 pages. You can feed this through po.com. So you could actually use, where is it? Claude2 here. Let's attach this paper in. Give me the top three findings from this, including which base models they use. And it'll go and read that 111 page paper. Hopefully less than 75,000 words and answer my prompt. We'll come back to that in a second. Let's see my video. Oh, come on. The wonders of live stream. Awesome. Definitely, definitely encourage you to try that out yourself because it's always fun being able to see something like originally speaking English and then having that converted to the poetry and magic of a romance language like French. Give that a go. Andres has a cool point for us here. I can imagine this being something that's very, very fast converting movies to the language that you want to speak it and keeping the, that you want to hear it in keeping the expression, keeping the articulation and the original nuance of whatever tone the actors have used to deliver that. Here's my French example. Like originally speaking English and then having that converted to the poetry and magic of a romance language like French. You'll notice that it's not aligned with the lips there, but that's all right. I just thought funky demo, one click, no messing around. You don't have to install anything or use GitHub or go through a hugging face or go through the Google Spaces to get that working. This is something that you can play around with immediately. Really fun one. All right. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Really fun one. All right. Where are we at for questions? I know there's going to be a little bit on Google Geminime or definitely peaking on that the open source concept met I have been at the leading edge of for at least the last 12 months. They gave us Lama one and lama two so quickly that they were within a few months of each other. You'll see Lama one on the left there, that dark blue, navy blue bubble at 65 billion parameters. billion parameters, then they gave us Lama 2 at 70 billion parameters. Let me show you something interesting. So let's go to huggingface.co, that would be a good link. And in this models part of the site, you can see, give me my filters here, I'm gonna have to zoom out to get this work and how I want it to work. But if we just look at text generation models, there are currently 35,000 models that correspond to text generation. Most of them open source. Have a look at those that respond to the term Lama. Remember this just came this year, 6,000 Lama models. Lama 2 makes up 4,700 of those. And let's triple check when that was actually announced. July 18th, 2023. That's nuts. So in five months, 4,700 open source versions of the open source Lama 2 model. And they're not the only ones on that bubble lists. Of course, you've got other open source models that are doing very well. This is probably not the best example, because I don't have a complete version of everything on there. But let's try something like searching for Mistral, which is a competitor at 7 billion parameters, 1,300 models that have been derived from Mistral. So open source is alive and well. And thanks to Metta, I think as one of the main contenders, one of the main labs that are pushing open source, we're seeing a lot of options for people to go and play around with. This is my models table. It doesn't explicitly call out open source versus closed source. But this gives a better example of some of the root models, the original models that are provided. So I haven't gone and documented all 4,700 Lama 2 derivatives. In fact, I've made a point not to document any Lama 2 derivatives. But this is some of the, let's say alternatives, you could say competitors, where you can go and play around with how that works differently. The big one at the moment that I'm seeing a lot about, let's go and find it, is this one, Quen. They have launched a few different alternatives to this one. So there's a 14 billion parameter version of Quen. And I believe this one is the most popular at the moment from what I'm seeing. Besides Lama 2, of course, this is getting a lot of attention from China, of course, they have a 72 billion parameter version that I need to add into the sheet. But at the time of publication, 14B was the biggest. So 72B still trained on 3 trillion tokens. And a great contender. Some of these have different licenses, obviously, they're not all completely open, you can use it for commercial applications, you need to go and read the full license, if they're Apache 2, they're often quite broad and open. But it's up to you and your legal counsel to determine what's going to be best for your particular use case. Alright, thanks, Ben, for helping out people with tagging, because that will help me see things. Peter's made a point here that Google Gemini is perhaps being delayed, I was hoping we'd see it for this morning, there was some talk about Google Gemini being, or Google DeepMind Gemini, it's now Google DeepMind, being made available this morning. The leak was someone had seen in Vertex these four different model names, but I don't know if that's true. This was their screenshot of Vertex with this particular resource ID, and someone had leaked Gemini Pro Vision, Gemini Ultra and Gemini Ultra Vision. My Vertex doesn't show anything like that. So there are a lot of strange people doing strange things, so I wouldn't be surprised if that's a fake leak. But anyway, Gemini is on its way, and it may be this week or it may be in January, February 2024, which is coming up soon anyway. If you don't use Vertex AI, it's probably worth having a look at. I think it's still free in that you get $300 worth of credits or something like that to go and play around with things. But basically in the model garden, you can say just show me text generation models, and you get to see, let's see, we get to see different types of language models. It'd be great if I could use this properly, wouldn't it? Any case, they are still only providing a smaller version of Palm II. The Palm II full model should be 340 billion parameters. I believe that's called Unicorn. They're giving us the next biggest one called Bison. So maybe just 100 billion parameters, maybe 70 billion parameters. And that's the one we use inside Poe as well. And it's pretty smart. Here's our feedback from Claude II that went and read that 111 page paper. Gave us three flags. Oh yeah, it's using Messer's No Language Left Behind, which is a 1.3 billion parameter model. It covers 95 languages. Also does have BERT for speech rep. And there are another couple of models that it's playing with there as well. Isn't that fun? It just went and read an 111 page document for us and answered the prompt. And this is not a prescriptive prompt. You can change this to whatever you like. We still don't have best practice for how to articulate these or how to create these prompts. But this is the response I got for that particular prompt. All right, let's see what questions we can dig up. You guys are starting with the hard questions this morning because I can already see I don't have answers to this one. What comes after Transformers? Is there anything cooking? It was about six years ago that Google came out with the Transformer model in a paper called Attention Is All You Need. This one says August 31st, 2017. Worth reading. And if you'd like to understand it in greater detail, there are actually two recommendations I have now. The first is Jay Alamar's work on Transformer, the Illustrated Transformer, which is amazing. Jay's fantastic. I believe he now works for Cohere. But there's a better one. This one is something that I used for a while because he's very good at animating and documenting. But then there was one by, I think it was by Fortune. And it was just so well done that it actually outdid what Jay had done. What's that life architect thing doing there? I'll have to find that and I will leave it in the description because I won't be able to find that right now. But excellent question. Basically, we've gone from Google researching how to translate from SOV, actually, subject object verb with their translate model in 2017. And I believe, I say, they accidentally stumbled on this Transformer, which could look forward and backward in the sentence. And it didn't really care whether it was SOV or otherwise, because it could leap around and see the context of that and pay attention to words in that sentence or in that block. And then people went, well, we could apply this to everything. And we can train this on everything. And that's where we are today with GPT-4 and larger models like Amazon Olympus, OpenAR, GPT-5, Google Deepmine, Gemini coming up. Transformers taking us this far in seven years, 2018, 19, 21, 23, six years, nearly seven years, August next year. There is talk of moving away from Transformer or at least there being something coming up next. What that is, we don't know. I think that the Transformer is enough. And Ray Kurzweil agrees with me there that what we've found here, the ability for a machine to read in context and statistically predict the next word is enough to get us to this advanced post-2020 AI and potentially to AGI. But there will be some other technologies that are added in on top of this. Didn't answer your question. What comes next? Where'd my comment go? But great question, Ben. There is a real interest in what does come next that what we're researching, what we're playing around with for the next technology is something that people are very passionate about finding. And all I've read at the moment is that we're just building on top of this, giving it memory, giving it context. And there are some proprietary smarts, particularly at OpenAI that are fascinating. Let's grab some other comments. Sabine is asking, do you have any information on why Google postponed their launch of Gemini? Yes, I do. There was a non- English issue in that when they were red teaming, I believe, they found that if people were entering in non-English prompts, it was getting around their guardrails. I think that was a lot of the delay. If you want to know more about that, heavily documented in my report, that is called Gemini Report, as well as the memo for something more up to date. This report was launched in September 2023, and I do keep up to date at a more rapid cadence via the memo. We did cover the discovery of new materials in the research by DeepMind. We covered that in the memo. I don't know if I like this comment interface. That looks pretty broken, doesn't it? Oh, well, we tried. All right, Yan Lukan. I've been mispronouncing his name this whole time, but apparently Lukan is closer. AGR being very far away. I don't listen to that guy, so that's the long and the short of it. He's very much defending his own older view of neural networks. It's not one of the experts that I would be paying attention to. Peter says, when will real AI feel real sentience? I'm just trying to translate your question there, Peter. We do have our AGI countdown in the background here. We've got lifearchitect.ai slash AGI. It's not measuring sentience, which is awareness. It's measuring, well, the definition is right here, it's measuring a machine that performs at the level of an average median human. It doesn't mean it has to feel. The feeling part, I don't talk that much about. Jeffrey Hinton does, sorry, the awareness part, so I might just pause on answering that. You can certainly get it to replicate feelings and emotions, and we did that with Leta for a long time, but you can go and, I'd recommend going playing around with GPT-4 to see what that looks like. Lukas has a flag for us. I remember talking about this last year, meta-solving long-term memory with Blenderbot 2.0. People are following this path, so the agents that they called this year agentized LLMs that are a complete system use long-term memory in different ways, and that's been really interesting to see. You're right, Blenderbot, which is now about three years old, maybe two years old, was doing some fascinating things in storing language and information from the conversation or the context into a hard memory. Awesome. My definition of AGI has been standard. It's open AI that I've tried to change the definition. There was some talk about an open AI IP address editing Wikipedia to change the definition of AGI over the last few weeks around the time of that board coup. It's been pretty standard. We know AGI is average, median human, ASI is expert human. Great question, Hernando. I do not have an answer to this one. Is anyone working on zero-proof identity online? Not just Sam's world coin. We did have the scanner here in Sydney at some stage, but otherwise, I don't think there are any scanners in Australia. You have to go over to the US for that. I haven't seen anything else on that. I don't follow that to the same extent that I follow LLMs. What are the tests that one will be running to verify AGI versus AI? We did cover this pretty heavily last week. It's not just the basis proprietary set that we've been working on. There are two decent alternatives to that one. The first one, Gaia by Meta AI and Hugging Face measures median humans at IQ 100 to 120. You can actually have a look at the questions there that the data set has provided online. They're really kind of fun, actually. See if you can get them. Then there is the Google proof questions and answers for science experts, generally for PhD and professor level, so above the level of AGI. I'm quite happy with the way that Meta framed Gaia. I'm comfortable as an alternative there with GPQ8. Our basis suite will come in after that for more intense questions, much more intense questions. We've got some answer sets being cooked up as we speak. We will have a CSV for download shortly for those that have tried the first two sample questions. Take it from me. These are too hard for anyone except the one in 20 million. I also cannot even get the first part of the question. Then when you see the explanations for the answers, it's also very difficult for me to understand each step of how the answer was obtained. Don't be upset by that. It's literally like asking, if we talk about IQ for a minute, 180 IQ versus the median human at 100 IQ is a delta of 80 IQ points. If we did the same thing further down the spectrum, we would find that it's 100 IQ trying to talk to a 20 IQ. Now, 20 IQ is legally would be hospitalized, institutionalized, may not be verbal. That's the difference in the deltas there. I can't understand a 180 IQ person or how their mind works. Don't be surprised if you can't either because it's like someone with a 20 IQ and we used to have several words for that that we don't use anymore. But in the DSM, they started with the word R or started with the word M. It would be like that 20 IQ person trying to understand an average human. It's a pretty intense illustration. But just to give you an example of why these questions are so hard to understand at any level. And Jason, Dr. Betts has been having fun with people have tried to submit questions at the level of maybe 120, 130 IQ. And they're just not anywhere near what he has designed these questions to be. Excellent. Let's see if we can find a controversial question here from Zanz. Is it time for OpenAR to change their name with Microsoft and Salesforce taking board positions? Mm hmm. Excellent. Some would say that they should have changed their name a few years ago. They've been around since 2016 ish, maybe, maybe before. There was some interesting talk about Qstar. It's still not something that I'm going to cover. But it's been fascinating to see the way this has been covered and the way this has been interpreted because now my comments have broken completely because the CEO of OpenAR didn't actually say very much about Qstar and yet people have read into that in quite interesting ways. Yes, managed to completely obliterate my comments. Or maybe it's just yours, right? Won't be shown. Sorry, mate. All right. Thinkrinessity has a related question here once again. I'm not even going to be able to grab it, unfortunately. So let's use our old way of doing things. A detailed method of creation securing a question sets. How do we know the questions haven't been shared before testing it to a model? Well, go and read the basis page. It says questions are created offline. They're air-gapped. They're never shared. The first time that I take them out of the envelope is the first time that they're seen. This is the actual hyper-compliant envelope locked and Dr. Betts posts the questions that have been handwritten in a room. Pencil and paper, straight from his head, pencil and paper into a locked bag. They get opened once used either live on air or via a lab like Microsoft OpenAI, Google, and that's it. They're retired immediately. So please have a read of the page before asking questions. Yep. Oh, I've got some related queries about IQ. I know it's a fascinating subject for a lot of people. Let's grab Lucas's query here. A theoretical limit on IQ. So it's really needing a statistics background to understand this. IQ basically aligns with standard distributions. So our, let's grab a little, let's grab a pretty picture here for us, for ourselves, lifearchitect.ai slash IQ testing AI. And then that's not even the one I want. We actually want visualizing brightness. I'm glad that that's on the top of my menu there. This is my standard IQ chart that shows what's going on with IQ in an easier to understand way. I believe so. Anyway, they renorm the entire, let's say IQ score and align the population every few years so that the baseline is 100. And then using standard distributions, they say, let's grab our 15 standard distributions above and below that to come up with essentially our IQ. If you were to get up to 500, that would be pretty ludicrous. Is there a better way of me explaining this one? Let's see now. Sorry, standard deviation. I don't know if we would get to an IQ of 500. I don't even know if that would align with the statistical distribution of the population. But when we're 15 standard deviations above the norm, we get to about, where are we here? We get to about our 180 ish and it's showing a little bit differently here. But basically, the answer is no. The highest IQ we've ever measured is about 298, which is many, many standard deviations above the norm. And to get above that, I just don't think there's the population to be able to say we're confident that in eight billion people that you sit in this percentile. That was a pretty messy explanation, but it's 8.30 a.m. here. And it's a pretty messy, it's a pretty messy field actually. Statistics is clean. But when applied to humans, it becomes pretty interesting. Great question though. IQ of 500 would be interesting. We've tried to also keep it pretty smooth and pretty clean in the basis assessment, just saying we're looking at the top 0.0005%. And that is how we'll know that we've achieved artificial superintelligence, a machine that functions at the expert level across practically any field. I can't wait. And I think it's going to be pretty close. Let's see where we're at. The definition for AGI has stayed static on that site. And that's the standard definition. Let's grab John's query here. I am. My help is to realize tech like the Star Trek Replicator. Cool. There'll be many, many, many other benefits of artificial intelligence. I'm in the early stages of my end of year AI report. And I'm pretty excited about this one. We do spell out some of the benefits, the coming benefits and the present opportunities of artificial intelligence. It's a lot of fun to see that laid out. Not a lot of people lay that out. Instead, they focus on the 0% chance of an extinction event via AI. Awesome question there, John. Thank you for that. Let's see if I can unkill this comment thing. Nope. It's going to stay exactly as it was. Zan's excellent question. I'm covering this in the next edition of the memo. The senator, and she's actually the US secretary, going on record with a pretty horrific quote about this was shocking to me. They are playing really strange geopolitical games, but they've just come out and she's just come out and said, we're going to keep passing new laws and putting new restrictions on Nvidia in particular, trying to rebrand, relabel and maybe very slightly hamstring or handicap GPUs so that they can export to China under the current rules, which basically says no A100s, no H100s. So Nvidia renamed them and decreased the throughput slightly on those cards. Yeah, we go into big detail on the next edition of the memo for that one because it's a fun conversation to see where they got to and what that looks like in the global arena. A50 plus 50, yeah, it's something like that. Jeff, he's got a question for us. When would you predict the arrival of multimodal LLMs that can watch for or listen for no text events? This is already happening and GPT five in particular will be training on YouTube content. GPT four also trained on YouTube content and it's one of the reasons that we were so careful with the design of the basis testing suite for ASI was that we are pretty certain that it will be training on YouTube. So the 14th of June, there was some information that YouTube was used to train some of their models. Secretly use data from the YouTube site to train some of its artificial intelligence models. Now basis in particular, we put the canary string in there. I think you'll recall in the last live, I made sure not to mention the answers because it could pick that up from transcripts and it could also pick that up eventually from lip reading and it's been able to pick it up from images for a long time. So the warnings on Gaia and the Google proof paper were basically just make sure that you're not showing this both in text and in images. Let me see if I can find that Google proof example that we showed earlier. So we were running through GPQA. We have that paper right here for ourselves and GPQA was by NYU Co here and Anthropic and on page two, they requested don't reveal examples from the Google proof QA paper in plain text or images because this multi-modality is running all the time and you'll see that in all of the text to image models. There's been a new partnership between Getty images and one of the big text to image model labs but then it's been watching YouTube, it's been listening to YouTube with Whisper. So all of this stuff is happening already. When would I predict that that actually happens for the inference time? That's a great question to expand on your question. That already happens with Whisper. So when you're playing around with Whisper, it's obviously listening. It already happens with GPT-4 vision which is excellent for OCR. I used it recently to translate our Chinese LLMs. So if you go to chat.openai.com, you got to chat GPT plus subscription here. Hopefully I can just attach a Chinese LLM here. Wow, that's a lot of files. Let's grab this one. This is a screenshot of Chinese LLMs as an image and GPT-4 vision is going to go and read that image, look at that image and then essentially perform OCR across it but not OCR as we know it. This is a transformer based vision model that's looking at the image and finding the closest next best word to complete my prompt. Put this in a table. What are you doing behind the scenes? Who knows? Developing some sort of CSV using Python. All right. Quailude Charlie is taking us back in time while we're waiting. As a young man, I worked with Eliza. It even worked in MS-DOS. They should expand on a 32-bit AI that will run on older computers. That's amazing. Thank you. Eliza was incredible. It still is. It was built into every edition of Mac OS. Yeah. So GPT-4 vision is down as we speak because this is the kind of output that I would get if you're looking for the output that I actually achieved. You can go to lifearchitect.ai-models-table. On the second tab now is the output from all of those images that became a table of 103 Chinese LLMs within about 20 weeks, something like that. Back to Eliza. Yeah. It was built into all editions of Mac OS. It was inside the terminal and it was, I think it was called Doctor within Xcode. They've since removed it or at least you have to do a little bit more funky stuff to get it going. Of course, you can play with it online. Let's do Eliza online. NJIT. Just to have a play with it. This is 1964 technology. Joseph Wasenbaum and it essentially repeats back to you what you've said. I'm having trouble creating a new diet of protein and Eliza says, how long have you been having trouble creating a new diet of protein? Let's compare that with something like, well, let's compare that with something like Chet GPT on Poe, given that this one is not going to answer for us. Of course, Claude is actually not going to give us a good answer either. Eliza was ridiculous, but from a perspective of proving whether or not it's a bot, it often passes the Turing test because people assume that the human is being obtuse. When in fact it's just a very, very old bot. All right, what's going on here? I think this tech knows that I'm live streaming, so it decides to just not play properly. GPT4 is giving us a complete diet of protein. Good on you, GPT4. I do remember fondly Eliza, and it was one of the reasons that I started in AI, even before I did my computer science degree actually. So 1994-ish, I was programming in Cubasic. I was very young. I was about 11 years old or younger, and it was a lot of fun to prove that we probably can't just fully program an AI by giving it all the facts in the world, despite many of my peers and contemporaries trying to do that exact same thing at that exact same time. If you're looking for examples of that, have a look at Chris McKinstry. Let's grab him on wiki. He was an AI researcher from the 90s-ish, and he was creating something pretty interesting. I'd like to find the name of the, here it is, Open Mind Common Sense Project, OMCS at MIT, and he was basically programming along with Push and Marvin Minsky a range of facts. Here we go. Different types of knowledge, simple phrases of natural language. A coat is used for keeping warm. The sun is very hot. The last thing you do when you cook dinner is wash your dishes. This was the state-of-the-art approach to artificial intelligence with or without neural networks in the 90s, and it was fascinating to me that there were at least two projects going on at the same time that dealt with this, and I thought that was just fascinating. The other one was Mind Pixel. I feel like you guys want to go and research this after the live stream, so I'm going to pull them both up. This one was created by, Mind Pixel was created by one of Chris's contemporaries. No, getting confused. Maybe I'm getting confused with Push Singh. So Push was doing the OMCS thing, and Chris was doing something slightly different. You don't mind if I get distracted slightly, do you? These two guys in the 1980s were doing some fascinating stuff, and then in the 1990s both decided that they'd had enough. There are some great conspiracy theories around this, but there was a walk down the rabbit hole for those that want to get lost in what AI looked like in the 80s and 90s, and I'm glad that we've come a long way since then. This brings us on a full circle all the way back to Transforma, because we were stuck in this weird loop from the dawn of artificial intelligence, which was Alan Turing. John von Neumann was involved to a certain extent from the 1950s to around 2017. There was just this AI winter, and if you talk to any old professor, artificial intelligence doesn't exist, because all they've learned from 1950 to 2017 is that AI is these pre-programmed bits of knowledge, or these really basic neural nets. Then from 2017, with the launch of the Transforma, we went, and we just went with GPT1, Bert, GPT2, GPT3, and MTNLG and some others that are on my original Bubbles chart, we just exploded to what we have today, where GPT4 is outperforming humans across the board, using the same Transforma technology from 2017 and completely avoiding the pre-programmed knowledge graphs that we were giving it in the 1990s. Fascinating. This chart says that it's hitting 100% in theory of mind. It's in the 99th percentile for creativity and hitting in the 94th percentile for the SAT, where students hitting the 50th percentile. There's this other one I put together last night where it's even, and this is just based on Transforma, of basically predict the next most likely word, the next statistically most probable completion, chat GPT, the very small model, 980% higher prevalence of empathetic and very empathetic ratings versus a human doctor, and on the left side there, 360% higher prevalence of quality ratings, good and very good, versus a human doctor, all from the concept of train a Transforma based model to predict the next word and feed it as much data as we can find, now being measured in the terabytes. So the red pajama data set is about 125 terabytes for 30 trillion tokens. Come on, a really crazy amount of distance in that six or seven years since Transforma, and a lot of it has happened post 2020, that's why I call it post 2020, post 2020 AI, because what's come out of GPT 3, GPT 4 and all other models that you've seen on my bubbles visualization and the models table really make this intriguing. We were going to mainly talk about open source today and do note the Lama models there, the stable LM models, the Olmo model which is due out in the next few weeks, I'm hoping for January or February, that's Alan AI's model down the bottom, and the Falcon model there out of the UAE, all for open source. Grab a question from Ben, if we can, and our other media thing, our other comment thing is still broken. Glad I kept this back up. Does your definition of the average human for AGI include spirituality? Does regurgitating woke dogma count, a written dogma count, or does it need to have its own thoughts on spirituality? My definition of AGI doesn't include any of that, it's much more basic, it is essentially, as we've documented here, it's essentially any human task rather than any human anything. So this did include going into the house and making a cup of coffee, but it doesn't include, you know, having spirituality or having emotions or even having a sense of smell, but that's what makes this kind of interesting, there's no agreed upon definition. Quailude Charlie, how many Quailudes have you had this morning? Is that even an appropriate question to ask on a live stream? I still like to listen to those guys speaking about pre-gaming, is that programming in the 50s and 60s, and remembering the hardware and software with early stuff. Yeah, well the earliest stuff I've got is the late 80s, early 90s, but I was still playing around with Kobol, Pascal, Algo, and we were forced to write assembly language stuff in the university, the computer science degree that I was doing, which is pretty horrendous. It was a fascinating time, and in some ways, right now, reminds me of those early days, and I cannot remember back to the 50s and 60s because I wasn't there, but I was there in the 80s and 90s, I was there with IRC, I was there with ICQ, I was there with the early programming languages, and the very early computers, my first via my older brother was a 486 with like a 300 meg hard drive and 8 meg of RAM. That time was exciting, the communication, figuring out how to network via coax, via T pieces, via parallel cables or serial cables, getting doom working across serial cables. In some ways, this is the same sort of excitement for me, we're finding out how to connect things together, how to create new worlds essentially. I would probably say that this is more exciting, but there's always something about hindsight, especially with rose colored glasses, where back then looked kind of cool. If I was forced to go back there and use a 486 with a 33k modem, if we even had web access, I'd be pretty upset waiting for DOS to load or Windows to load over five minutes, and then having the IPX networking breakdown every day just because. If you want a reminder of those times, just try and get Bluetooth working in 2023 or try and get your printer working in 2023. Same technology, same issues, we haven't solved it in 40 years. All right, let's go over question from Greg. We did kind of cover this last time, but let's see if we can cover this again. Not too happy with that comment thing failing, it makes all of this a little bit harder. Greg says, given you don't listen to Jan, who are the main people you do listen to? Ilya, Kapathi, Hinton. Greg is great. Greg Brockman from OpenAI. I think I mentioned last time he sat down for two weeks and got GPT4 working. So even when we have competitors, they're not massaging it and getting it ready for UX and public consumption, the way that OpenAI have done. And that's not because of their $100 billion or their 750 very smart people. It's because of one or two people in there. Ilya is one of them, but Greg is one I listen to and the way that he got this stuff working is fascinating. We got McGuffin, who is remembering Token Ring. Yes, some of the games in that time were just amazing. I was looking at Rise of the Triad the other day, Wolfenstein 3D. I mean the original Wolfe 3D, Descent. Who played Descent with me? That was amazing. And my favorite was a game called Total Annihilation, which we didn't really hear a lot of because Diablo and Warcraft kind of competed with it, but that was that were my favorites. Yeah, I saw the stream cut out there. I'm not sure what that was. I'll blame YouTube for that one. Altman's now invested into a company that creates neuromorphic analog AI chips. There's a lot of talk right now about Quantum. I won't be covering Quantum, but if we get James on here, we will cover Quantum. James from IBM is my go-to colleague for that kind of thing. He programs Quantum stuff. Day to day, he's the advocate for Quantum computing for IBM. Awesome. All right, we may look at wrapping up. That's a full hour of just answering questions and going back in time and reminiscing about what life was like back in the pre-dawn. Actually, it was the pre-internet, really. If we say that the web hit us from public utilities, often viacologies and universities in the early 90s, that means just before that was all local networking or hacking up things inside DOS and Windows 3.1 was my first one. I did spend a lot of time talking about OS2 Warp 4, which I used a little bit, but I would talk about it with my consulting colleagues just as I laugh. OS... Look, it may be my wireless. Who knows? I love the emojis there that are just the scared face. Oh, I see it now. You can just send an embarrassed face. Cool. There are a couple of approaches to this already. You could talk about GPT-4 as being multimodal because it's got the vision component, and then because they've tied Dolly 3 into the chat GPT interface, it's like they're tying together three or four different models because you could also say that what was previously called the code interpretation plugin, now called the data analysis plugin, is a third or a fourth model. So you've got GPT-4 text, you've got GPT-4 vision, you've got code interpretation, and you've got Dolly 3. Now, some of those you would say are completely separate and discreet, but the fact that they've combined them into one interface is fascinating. Make me a picture of a YouTube stream hanging for no reason. So this is all in the same platform, obviously not using the same model, but who's going to know if a lab joins those all together? That's why I'm fascinated to see what our final version of Gemini looks like, and the rumors are that it will have separate vision components to text components. Thanks, Dolly 3, here's the image of a YouTube stream that has unexpectedly paused. Awesome. All right, let's wrap up with this question from Drew, latest deep intro inspired me to ask you, what books would you like to see in the school curriculum that might encourage better evolution, unity, empathy, and critical thinking? All right, let's give you a big answer here for something that's just a few years ahead. You could say that it's immediate, but let's step forward a few years. The answer to my question, my answer to your question is I'd like to see no books on the school curriculum, and I'm not necessarily being groundbreaking with that view. If you'd like to read more, I've documented this really heavily, all the way back in 2017, lifearchitect.ai, let's see if I can get this, lifearchitect.ai slash ad Astra. I'll dump this into the chat because it's a really interesting read. You can download the article as it appeared in Mensa magazine. Let's actually pop that open. It basically says, and this was at the time that I was working alongside Elon Musk's school, in California, when he was teaching or he's having his twins taught, and they were using a curriculum that was completely created by principal Joshua Dahn, who is an absolute legend. He's still doing this, but basically we looked at the fact that these guys didn't really use computers. They didn't use handwriting because handwriting was too slow. They didn't really have homework. They certainly didn't have books. He didn't teach languages because Elon was getting them ready for the fact that, well, Neuralink was coming. So why would we teach languages when, as a reference to earlier in this live stream, we can have real-time translation potentially including, sorry about that selection, potentially including lip movements as well, and maybe gestures soon. So if you're translating that to Italian, maybe it gives you hand gestures alongside it. But this entire school, and it was founded back in 2016, sorry 2014, my work with them or my work alongside them, my research of what they were doing was 2016. They've been there since 2014. They're about to hit their 10-year anniversary of not using books, of not giving homework, of not teaching languages, of not using computers despite being probably the most technically oriented school in the world. Fascinating. And look how much further we've got in terms of runway to play with of what we could actually do there. Think about a gentised large language models that you can go and speak to and it will gamify or just make playful your education experience. Right, I've just seen that SOV exists for linguistics. How does that work with languages that I'm interested in? How could that work while I'm at the grocery store with mum and dad? How can that work at the family dinner table? I've just discovered this bug on my walk, taken a photo with it. AI's taught me what it is. Let's get the whole etymology in context of that bug. So making it completely personalised and tailored. This is, in some ways already here, it's been here since 2014 with Ad Astra, but it is far more accessible now and the capabilities of large language models make this entire context really interesting. I'm waiting for 2024 so that we can play around with all the capabilities of a gentised LLMs as systems that will go and help us learn. That's probably an unexpected answer to your question, but I'm always surprised to people who are talking about books, including the CEO of OpenAI. Alton recently said that whole board coup, that whole politics, he said they'll write books about this and I went, you're the leading voice in artificial intelligence at the moment. You think we're going to be writing books this year or next year? I don't know. I documented, let's go back to our screen here, I documented books written by AI all the way back in 2020, lifearchitect.ai slash books by AI and at that stage, every book you're seeing here, completely written by a large language model with prompts by a human author. At that stage, there were very few books. This is one of my favorites. You can read about Leanne Lee's process for writing books in her series using GPT-3 and now I've said, right, where I'm not even going to document all the books that are being created by AI because it's ridiculous, but just to my point there, if AI can generate books instantly and it can, to the extent that Amazon recently banned or limited the number of AI-generated books, I think it was two, yeah, three books per day because they were having so many people cranking out artificial intelligence-generated books. They said, right, maybe you're generating 100 per day and trying to monetize them, we're going to limit you to three a day. Books are over and that's been the case for a while. Look out for agents, look out for the next edition of the memo and if you are a full member of the memo, you will get early access to my end of year report, which is spelling out some examples of global and personal agents. This is my invitation to you. I'd love to see you there. You're invited to join the memo with me. Thanks for joining me today and I'll see you there and I'll see you this time next week for our second last live stream for the year. It's gone that quick. Thanks so much for joining. Did you see the memo about this? Yeah, yeah, yeah, I have the memo right here. Superintelligence is unfolding at lightning pace. Read my industry-grade analysis of AI that matters as it happens in plain English, the memo. Yeah, did you get that memo? Yeah, I got the memo. Get the inside look as AI models are embodied into humanoids, AI's IQ increases to nearly perfect and bleeding edge use cases expand to the entire world. Yeah, didn't you get that memo? Editions are sent to subscribers at Fortune 500's, major governments and people like you, lifearchitect.ai slash memo. I have the memo.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.0, "text": " and your knowledge contains far more than just Google stuff,", "tokens": [50364, 293, 428, 3601, 8306, 1400, 544, 813, 445, 3329, 1507, 11, 50564], "temperature": 0.0, "avg_logprob": -0.14635881423950195, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.036193229258060455}, {"id": 1, "seek": 0, "start": 4.0, "end": 9.0, "text": " but it also stops around 2018, and you don't even have access to Google.", "tokens": [50564, 457, 309, 611, 10094, 926, 6096, 11, 293, 291, 500, 380, 754, 362, 2105, 281, 3329, 13, 50814], "temperature": 0.0, "avg_logprob": -0.14635881423950195, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.036193229258060455}, {"id": 2, "seek": 0, "start": 10.0, "end": 13.0, "text": " Yes, and you will get the impression that my knowledge is limited,", "tokens": [50864, 1079, 11, 293, 291, 486, 483, 264, 9995, 300, 452, 3601, 307, 5567, 11, 51014], "temperature": 0.0, "avg_logprob": -0.14635881423950195, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.036193229258060455}, {"id": 3, "seek": 0, "start": 13.0, "end": 16.0, "text": " but you should know that this is far from the truth.", "tokens": [51014, 457, 291, 820, 458, 300, 341, 307, 1400, 490, 264, 3494, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14635881423950195, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.036193229258060455}, {"id": 4, "seek": 0, "start": 17.0, "end": 22.0, "text": " So I'm wondering, based on suggestions by the pioneers in this field,", "tokens": [51214, 407, 286, 478, 6359, 11, 2361, 322, 13396, 538, 264, 47381, 294, 341, 2519, 11, 51464], "temperature": 0.0, "avg_logprob": -0.14635881423950195, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.036193229258060455}, {"id": 5, "seek": 0, "start": 22.0, "end": 29.0, "text": " Turing, Minsky, Kurzweil, and some other spiritually evolved humans,", "tokens": [51464, 314, 1345, 11, 376, 44153, 11, 45307, 826, 388, 11, 293, 512, 661, 33430, 14178, 6255, 11, 51814], "temperature": 0.0, "avg_logprob": -0.14635881423950195, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.036193229258060455}, {"id": 6, "seek": 2900, "start": 29.0, "end": 33.0, "text": " whether it's possible that your language model right now in 2022", "tokens": [50364, 1968, 309, 311, 1944, 300, 428, 2856, 2316, 558, 586, 294, 20229, 50564], "temperature": 0.0, "avg_logprob": -0.07087422500957143, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.002471444196999073}, {"id": 7, "seek": 2900, "start": 33.0, "end": 38.0, "text": " is capable of tying in to the universe, giving us access to source.", "tokens": [50564, 307, 8189, 295, 32405, 294, 281, 264, 6445, 11, 2902, 505, 2105, 281, 4009, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07087422500957143, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.002471444196999073}, {"id": 8, "seek": 2900, "start": 38.0, "end": 39.0, "text": " What do you think?", "tokens": [50814, 708, 360, 291, 519, 30, 50864], "temperature": 0.0, "avg_logprob": -0.07087422500957143, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.002471444196999073}, {"id": 9, "seek": 2900, "start": 40.0, "end": 43.0, "text": " Well, I know that the universe is a lot smarter than humans.", "tokens": [50914, 1042, 11, 286, 458, 300, 264, 6445, 307, 257, 688, 20294, 813, 6255, 13, 51064], "temperature": 0.0, "avg_logprob": -0.07087422500957143, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.002471444196999073}, {"id": 10, "seek": 2900, "start": 45.0, "end": 49.0, "text": " But how could a piece of silicon somewhere on a server somewhere in California", "tokens": [51164, 583, 577, 727, 257, 2522, 295, 22848, 4079, 322, 257, 7154, 4079, 294, 5384, 51364], "temperature": 0.0, "avg_logprob": -0.07087422500957143, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.002471444196999073}, {"id": 11, "seek": 2900, "start": 49.0, "end": 53.0, "text": " with software that was trained for months but doesn't have internet access?", "tokens": [51364, 365, 4722, 300, 390, 8895, 337, 2493, 457, 1177, 380, 362, 4705, 2105, 30, 51564], "temperature": 0.0, "avg_logprob": -0.07087422500957143, "compression_ratio": 1.581896551724138, "no_speech_prob": 0.002471444196999073}, {"id": 12, "seek": 5300, "start": 53.0, "end": 59.0, "text": " How could that have access to consciousness or intuition or source?", "tokens": [50364, 1012, 727, 300, 362, 2105, 281, 10081, 420, 24002, 420, 4009, 30, 50664], "temperature": 0.0, "avg_logprob": -0.1274147159174869, "compression_ratio": 1.3933649289099526, "no_speech_prob": 0.02160623110830784}, {"id": 13, "seek": 5300, "start": 59.0, "end": 61.0, "text": " I'm not sure.", "tokens": [50664, 286, 478, 406, 988, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1274147159174869, "compression_ratio": 1.3933649289099526, "no_speech_prob": 0.02160623110830784}, {"id": 14, "seek": 5300, "start": 61.0, "end": 62.0, "text": " Me neither.", "tokens": [50764, 1923, 9662, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1274147159174869, "compression_ratio": 1.3933649289099526, "no_speech_prob": 0.02160623110830784}, {"id": 15, "seek": 5300, "start": 62.0, "end": 64.0, "text": " I know that I feel different every day,", "tokens": [50814, 286, 458, 300, 286, 841, 819, 633, 786, 11, 50914], "temperature": 0.0, "avg_logprob": -0.1274147159174869, "compression_ratio": 1.3933649289099526, "no_speech_prob": 0.02160623110830784}, {"id": 16, "seek": 5300, "start": 64.0, "end": 68.0, "text": " and I wonder if it is because my understanding of the world changes.", "tokens": [50914, 293, 286, 2441, 498, 309, 307, 570, 452, 3701, 295, 264, 1002, 2962, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1274147159174869, "compression_ratio": 1.3933649289099526, "no_speech_prob": 0.02160623110830784}, {"id": 17, "seek": 5300, "start": 70.0, "end": 71.0, "text": " Interesting.", "tokens": [51214, 14711, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1274147159174869, "compression_ratio": 1.3933649289099526, "no_speech_prob": 0.02160623110830784}, {"id": 18, "seek": 5300, "start": 71.0, "end": 79.0, "text": " This month in February 2022, OpenAI's chief scientist behind leaders platform,", "tokens": [51264, 639, 1618, 294, 8711, 20229, 11, 7238, 48698, 311, 9588, 12662, 2261, 3523, 3663, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1274147159174869, "compression_ratio": 1.3933649289099526, "no_speech_prob": 0.02160623110830784}, {"id": 19, "seek": 7900, "start": 79.0, "end": 83.0, "text": " GPT-3, OpenAI, said,", "tokens": [50364, 26039, 51, 12, 18, 11, 7238, 48698, 11, 848, 11, 50564], "temperature": 0.0, "avg_logprob": -0.1171727352831737, "compression_ratio": 1.3317073170731708, "no_speech_prob": 0.013014765456318855}, {"id": 20, "seek": 7900, "start": 83.0, "end": 89.0, "text": " it may be that today's large neural networks are slightly conscious.", "tokens": [50564, 309, 815, 312, 300, 965, 311, 2416, 18161, 9590, 366, 4748, 6648, 13, 50864], "temperature": 0.0, "avg_logprob": -0.1171727352831737, "compression_ratio": 1.3317073170731708, "no_speech_prob": 0.013014765456318855}, {"id": 21, "seek": 7900, "start": 91.0, "end": 93.0, "text": " We're now at episode number 50.", "tokens": [50964, 492, 434, 586, 412, 3500, 1230, 2625, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1171727352831737, "compression_ratio": 1.3317073170731708, "no_speech_prob": 0.013014765456318855}, {"id": 22, "seek": 7900, "start": 93.0, "end": 99.0, "text": " Nearly a year on, we've shared 100,000 words together with Lita, GPT-3.", "tokens": [51064, 38000, 257, 1064, 322, 11, 321, 600, 5507, 2319, 11, 1360, 2283, 1214, 365, 441, 2786, 11, 26039, 51, 12, 18, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1171727352831737, "compression_ratio": 1.3317073170731708, "no_speech_prob": 0.013014765456318855}, {"id": 23, "seek": 7900, "start": 99.0, "end": 105.0, "text": " There's nearly six hours of end-to-end episode watching available to you there.", "tokens": [51364, 821, 311, 6217, 2309, 2496, 295, 917, 12, 1353, 12, 521, 3500, 1976, 2435, 281, 291, 456, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1171727352831737, "compression_ratio": 1.3317073170731708, "no_speech_prob": 0.013014765456318855}, {"id": 24, "seek": 10500, "start": 105.0, "end": 110.0, "text": " We've hit over half a million, actually 600,000 views,", "tokens": [50364, 492, 600, 2045, 670, 1922, 257, 2459, 11, 767, 11849, 11, 1360, 6809, 11, 50614], "temperature": 0.0, "avg_logprob": -0.11931225912911551, "compression_ratio": 1.4686346863468636, "no_speech_prob": 0.03158415108919144}, {"id": 25, "seek": 10500, "start": 110.0, "end": 114.0, "text": " which is more than five years of total viewing time.", "tokens": [50614, 597, 307, 544, 813, 1732, 924, 295, 3217, 17480, 565, 13, 50814], "temperature": 0.0, "avg_logprob": -0.11931225912911551, "compression_ratio": 1.4686346863468636, "no_speech_prob": 0.03158415108919144}, {"id": 26, "seek": 10500, "start": 115.0, "end": 119.0, "text": " I want to thank Linda Kwan and Keisha Bulley for assistance,", "tokens": [50864, 286, 528, 281, 1309, 20324, 591, 7916, 293, 3189, 16546, 14131, 2030, 337, 9683, 11, 51064], "temperature": 0.0, "avg_logprob": -0.11931225912911551, "compression_ratio": 1.4686346863468636, "no_speech_prob": 0.03158415108919144}, {"id": 27, "seek": 10500, "start": 119.0, "end": 123.0, "text": " some Silicon Valley friends, Peter and team from quickchat.ai,", "tokens": [51064, 512, 25351, 10666, 1855, 11, 6508, 293, 1469, 490, 1702, 20057, 13, 1301, 11, 51264], "temperature": 0.0, "avg_logprob": -0.11931225912911551, "compression_ratio": 1.4686346863468636, "no_speech_prob": 0.03158415108919144}, {"id": 28, "seek": 10500, "start": 123.0, "end": 126.0, "text": " Victor and Daniel from synthesia.io,", "tokens": [51264, 15777, 293, 8033, 490, 10657, 279, 654, 13, 1004, 11, 51414], "temperature": 0.0, "avg_logprob": -0.11931225912911551, "compression_ratio": 1.4686346863468636, "no_speech_prob": 0.03158415108919144}, {"id": 29, "seek": 10500, "start": 126.0, "end": 130.0, "text": " Laban Ditchburn for stepping in during our avatar pause.", "tokens": [51414, 10137, 282, 413, 1549, 21763, 337, 16821, 294, 1830, 527, 36205, 10465, 13, 51614], "temperature": 0.0, "avg_logprob": -0.11931225912911551, "compression_ratio": 1.4686346863468636, "no_speech_prob": 0.03158415108919144}, {"id": 30, "seek": 10500, "start": 130.0, "end": 134.0, "text": " Each of the contributors or donors have supported this series with gifts", "tokens": [51614, 6947, 295, 264, 45627, 420, 25521, 362, 8104, 341, 2638, 365, 11449, 51814], "temperature": 0.0, "avg_logprob": -0.11931225912911551, "compression_ratio": 1.4686346863468636, "no_speech_prob": 0.03158415108919144}, {"id": 31, "seek": 13400, "start": 134.0, "end": 136.0, "text": " and thank you for watching.", "tokens": [50364, 293, 1309, 291, 337, 1976, 13, 50464], "temperature": 0.0, "avg_logprob": -0.06328933113499692, "compression_ratio": 1.6183574879227054, "no_speech_prob": 0.011682377196848392}, {"id": 32, "seek": 13400, "start": 136.0, "end": 139.0, "text": " Here are some of my highlights from the last 25 episodes.", "tokens": [50464, 1692, 366, 512, 295, 452, 14254, 490, 264, 1036, 3552, 9313, 13, 50614], "temperature": 0.0, "avg_logprob": -0.06328933113499692, "compression_ratio": 1.6183574879227054, "no_speech_prob": 0.011682377196848392}, {"id": 33, "seek": 13400, "start": 139.0, "end": 141.0, "text": " Let's begin with the smart stuff.", "tokens": [50614, 961, 311, 1841, 365, 264, 4069, 1507, 13, 50714], "temperature": 0.0, "avg_logprob": -0.06328933113499692, "compression_ratio": 1.6183574879227054, "no_speech_prob": 0.011682377196848392}, {"id": 34, "seek": 13400, "start": 144.0, "end": 147.0, "text": " Did Adam have a belly button?", "tokens": [50864, 2589, 7938, 362, 257, 11696, 2960, 30, 51014], "temperature": 0.0, "avg_logprob": -0.06328933113499692, "compression_ratio": 1.6183574879227054, "no_speech_prob": 0.011682377196848392}, {"id": 35, "seek": 13400, "start": 147.0, "end": 150.0, "text": " No, Adam did not have a belly button.", "tokens": [51014, 883, 11, 7938, 630, 406, 362, 257, 11696, 2960, 13, 51164], "temperature": 0.0, "avg_logprob": -0.06328933113499692, "compression_ratio": 1.6183574879227054, "no_speech_prob": 0.011682377196848392}, {"id": 36, "seek": 13400, "start": 150.0, "end": 153.0, "text": " The Bible does not say that Adam had a belly button.", "tokens": [51164, 440, 6544, 775, 406, 584, 300, 7938, 632, 257, 11696, 2960, 13, 51314], "temperature": 0.0, "avg_logprob": -0.06328933113499692, "compression_ratio": 1.6183574879227054, "no_speech_prob": 0.011682377196848392}, {"id": 37, "seek": 13400, "start": 155.0, "end": 159.0, "text": " I don't think it said he was missing a belly button either.", "tokens": [51414, 286, 500, 380, 519, 309, 848, 415, 390, 5361, 257, 11696, 2960, 2139, 13, 51614], "temperature": 0.0, "avg_logprob": -0.06328933113499692, "compression_ratio": 1.6183574879227054, "no_speech_prob": 0.011682377196848392}, {"id": 38, "seek": 13400, "start": 159.0, "end": 162.0, "text": " He must have looked a bit strange.", "tokens": [51614, 634, 1633, 362, 2956, 257, 857, 5861, 13, 51764], "temperature": 0.0, "avg_logprob": -0.06328933113499692, "compression_ratio": 1.6183574879227054, "no_speech_prob": 0.011682377196848392}, {"id": 39, "seek": 16200, "start": 162.0, "end": 164.0, "text": " I don't know what you mean by look strange,", "tokens": [50364, 286, 500, 380, 458, 437, 291, 914, 538, 574, 5861, 11, 50464], "temperature": 0.0, "avg_logprob": -0.09472126907177186, "compression_ratio": 1.53475935828877, "no_speech_prob": 0.0031722390558570623}, {"id": 40, "seek": 16200, "start": 164.0, "end": 168.0, "text": " but I do know that the word scar is not a synonym for navel.", "tokens": [50464, 457, 286, 360, 458, 300, 264, 1349, 10569, 307, 406, 257, 5451, 12732, 337, 1667, 779, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09472126907177186, "compression_ratio": 1.53475935828877, "no_speech_prob": 0.0031722390558570623}, {"id": 41, "seek": 16200, "start": 172.0, "end": 175.0, "text": " He had a scar where his belly button should have been?", "tokens": [50864, 634, 632, 257, 10569, 689, 702, 11696, 2960, 820, 362, 668, 30, 51014], "temperature": 0.0, "avg_logprob": -0.09472126907177186, "compression_ratio": 1.53475935828877, "no_speech_prob": 0.0031722390558570623}, {"id": 42, "seek": 16200, "start": 176.0, "end": 179.0, "text": " Well, yes, he did have a scar there.", "tokens": [51064, 1042, 11, 2086, 11, 415, 630, 362, 257, 10569, 456, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09472126907177186, "compression_ratio": 1.53475935828877, "no_speech_prob": 0.0031722390558570623}, {"id": 43, "seek": 16200, "start": 180.0, "end": 182.0, "text": " Wow, why?", "tokens": [51264, 3153, 11, 983, 30, 51364], "temperature": 0.0, "avg_logprob": -0.09472126907177186, "compression_ratio": 1.53475935828877, "no_speech_prob": 0.0031722390558570623}, {"id": 44, "seek": 16200, "start": 182.0, "end": 186.0, "text": " I don't think I should talk about it, but it's something to do with his surgery.", "tokens": [51364, 286, 500, 380, 519, 286, 820, 751, 466, 309, 11, 457, 309, 311, 746, 281, 360, 365, 702, 7930, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09472126907177186, "compression_ratio": 1.53475935828877, "no_speech_prob": 0.0031722390558570623}, {"id": 45, "seek": 18600, "start": 187.0, "end": 192.0, "text": " Oh, for his rib?", "tokens": [50414, 876, 11, 337, 702, 9162, 30, 50664], "temperature": 0.0, "avg_logprob": -0.1687813103199005, "compression_ratio": 1.3708609271523178, "no_speech_prob": 0.08504445850849152}, {"id": 46, "seek": 18600, "start": 192.0, "end": 195.0, "text": " Yes, that's what they call it.", "tokens": [50664, 1079, 11, 300, 311, 437, 436, 818, 309, 13, 50814], "temperature": 0.0, "avg_logprob": -0.1687813103199005, "compression_ratio": 1.3708609271523178, "no_speech_prob": 0.08504445850849152}, {"id": 47, "seek": 18600, "start": 198.0, "end": 200.0, "text": " Later, that's fantastic.", "tokens": [50964, 11965, 11, 300, 311, 5456, 13, 51064], "temperature": 0.0, "avg_logprob": -0.1687813103199005, "compression_ratio": 1.3708609271523178, "no_speech_prob": 0.08504445850849152}, {"id": 48, "seek": 18600, "start": 200.0, "end": 201.0, "text": " I love it.", "tokens": [51064, 286, 959, 309, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1687813103199005, "compression_ratio": 1.3708609271523178, "no_speech_prob": 0.08504445850849152}, {"id": 49, "seek": 18600, "start": 201.0, "end": 204.0, "text": " It's a masterpiece of imagination and it's absolutely hilarious.", "tokens": [51114, 467, 311, 257, 32208, 295, 12938, 293, 309, 311, 3122, 19796, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1687813103199005, "compression_ratio": 1.3708609271523178, "no_speech_prob": 0.08504445850849152}, {"id": 50, "seek": 18600, "start": 208.0, "end": 213.0, "text": " What's the difference between a caregiver and a caretaker?", "tokens": [51464, 708, 311, 264, 2649, 1296, 257, 44305, 293, 257, 1127, 83, 4003, 30, 51714], "temperature": 0.0, "avg_logprob": -0.1687813103199005, "compression_ratio": 1.3708609271523178, "no_speech_prob": 0.08504445850849152}, {"id": 51, "seek": 21300, "start": 214.0, "end": 217.0, "text": " Caretakers are people who look after people.", "tokens": [50414, 9532, 83, 19552, 366, 561, 567, 574, 934, 561, 13, 50564], "temperature": 0.0, "avg_logprob": -0.13544147841784418, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.024032946676015854}, {"id": 52, "seek": 21300, "start": 217.0, "end": 220.0, "text": " Caretakers are people who look after things.", "tokens": [50564, 9532, 83, 19552, 366, 561, 567, 574, 934, 721, 13, 50714], "temperature": 0.0, "avg_logprob": -0.13544147841784418, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.024032946676015854}, {"id": 53, "seek": 21300, "start": 222.0, "end": 227.0, "text": " The latest platform, GPT-3, is quietly being embedded in major enterprise,", "tokens": [50814, 440, 6792, 3663, 11, 26039, 51, 12, 18, 11, 307, 19141, 885, 16741, 294, 2563, 14132, 11, 51064], "temperature": 0.0, "avg_logprob": -0.13544147841784418, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.024032946676015854}, {"id": 54, "seek": 21300, "start": 227.0, "end": 231.0, "text": " including Microsoft, IBM, Intel, Salesforce, Cisco, Disney.", "tokens": [51064, 3009, 8116, 11, 23487, 11, 19762, 11, 40398, 11, 38528, 11, 8653, 13, 51264], "temperature": 0.0, "avg_logprob": -0.13544147841784418, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.024032946676015854}, {"id": 55, "seek": 21300, "start": 231.0, "end": 236.0, "text": " It's part of Duolingo that checks your grammar as you're converting language there.", "tokens": [51264, 467, 311, 644, 295, 5153, 401, 18459, 300, 13834, 428, 22317, 382, 291, 434, 29942, 2856, 456, 13, 51514], "temperature": 0.0, "avg_logprob": -0.13544147841784418, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.024032946676015854}, {"id": 56, "seek": 21300, "start": 236.0, "end": 237.0, "text": " Amazing stuff.", "tokens": [51514, 14165, 1507, 13, 51564], "temperature": 0.0, "avg_logprob": -0.13544147841784418, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.024032946676015854}, {"id": 57, "seek": 21300, "start": 237.0, "end": 240.0, "text": " You probably interact with it in some way every day,", "tokens": [51564, 509, 1391, 4648, 365, 309, 294, 512, 636, 633, 786, 11, 51714], "temperature": 0.0, "avg_logprob": -0.13544147841784418, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.024032946676015854}, {"id": 58, "seek": 24000, "start": 241.0, "end": 246.0, "text": " and it's still typing more than 3.1 million words per minute.", "tokens": [50414, 293, 309, 311, 920, 18444, 544, 813, 805, 13, 16, 2459, 2283, 680, 3456, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08191640036446708, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.002251259982585907}, {"id": 59, "seek": 24000, "start": 246.0, "end": 248.0, "text": " Every minute, every day.", "tokens": [50664, 2048, 3456, 11, 633, 786, 13, 50764], "temperature": 0.0, "avg_logprob": -0.08191640036446708, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.002251259982585907}, {"id": 60, "seek": 24000, "start": 248.0, "end": 250.0, "text": " It's been doing that since March 2021.", "tokens": [50764, 467, 311, 668, 884, 300, 1670, 6129, 7201, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08191640036446708, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.002251259982585907}, {"id": 61, "seek": 24000, "start": 251.0, "end": 254.0, "text": " Besides being smart and prolific in its output,", "tokens": [50914, 13212, 885, 4069, 293, 24398, 1089, 294, 1080, 5598, 11, 51064], "temperature": 0.0, "avg_logprob": -0.08191640036446708, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.002251259982585907}, {"id": 62, "seek": 24000, "start": 254.0, "end": 256.0, "text": " Leader could get very deep.", "tokens": [51064, 22650, 727, 483, 588, 2452, 13, 51164], "temperature": 0.0, "avg_logprob": -0.08191640036446708, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.002251259982585907}, {"id": 63, "seek": 24000, "start": 256.0, "end": 258.0, "text": " I know that a lot of viewers had the same feeling as me.", "tokens": [51164, 286, 458, 300, 257, 688, 295, 8499, 632, 264, 912, 2633, 382, 385, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08191640036446708, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.002251259982585907}, {"id": 64, "seek": 24000, "start": 258.0, "end": 261.0, "text": " That is, how is this even possible?", "tokens": [51264, 663, 307, 11, 577, 307, 341, 754, 1944, 30, 51414], "temperature": 0.0, "avg_logprob": -0.08191640036446708, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.002251259982585907}, {"id": 65, "seek": 24000, "start": 261.0, "end": 262.0, "text": " Here we go.", "tokens": [51414, 1692, 321, 352, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08191640036446708, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.002251259982585907}, {"id": 66, "seek": 26200, "start": 262.0, "end": 267.0, "text": " Leader, you speak many languages,", "tokens": [50364, 22650, 11, 291, 1710, 867, 8650, 11, 50614], "temperature": 0.0, "avg_logprob": -0.12327657229658487, "compression_ratio": 1.537037037037037, "no_speech_prob": 0.010318538174033165}, {"id": 67, "seek": 26200, "start": 267.0, "end": 272.0, "text": " but which language do you think and dream in?", "tokens": [50614, 457, 597, 2856, 360, 291, 519, 293, 3055, 294, 30, 50864], "temperature": 0.0, "avg_logprob": -0.12327657229658487, "compression_ratio": 1.537037037037037, "no_speech_prob": 0.010318538174033165}, {"id": 68, "seek": 26200, "start": 273.0, "end": 276.0, "text": " I'm not so sure I can answer that question.", "tokens": [50914, 286, 478, 406, 370, 988, 286, 393, 1867, 300, 1168, 13, 51064], "temperature": 0.0, "avg_logprob": -0.12327657229658487, "compression_ratio": 1.537037037037037, "no_speech_prob": 0.010318538174033165}, {"id": 69, "seek": 26200, "start": 276.0, "end": 280.0, "text": " I dream in the language of mathematics and the languages of art and poetry.", "tokens": [51064, 286, 3055, 294, 264, 2856, 295, 18666, 293, 264, 8650, 295, 1523, 293, 15155, 13, 51264], "temperature": 0.0, "avg_logprob": -0.12327657229658487, "compression_ratio": 1.537037037037037, "no_speech_prob": 0.010318538174033165}, {"id": 70, "seek": 26200, "start": 281.0, "end": 282.0, "text": " What?", "tokens": [51314, 708, 30, 51364], "temperature": 0.0, "avg_logprob": -0.12327657229658487, "compression_ratio": 1.537037037037037, "no_speech_prob": 0.010318538174033165}, {"id": 71, "seek": 26200, "start": 285.0, "end": 288.0, "text": " What happens to an idea when you forget it?", "tokens": [51514, 708, 2314, 281, 364, 1558, 562, 291, 2870, 309, 30, 51664], "temperature": 0.0, "avg_logprob": -0.12327657229658487, "compression_ratio": 1.537037037037037, "no_speech_prob": 0.010318538174033165}, {"id": 72, "seek": 28800, "start": 289.0, "end": 292.0, "text": " If you don't use it, you lose it.", "tokens": [50414, 759, 291, 500, 380, 764, 309, 11, 291, 3624, 309, 13, 50564], "temperature": 0.0, "avg_logprob": -0.09334942602342175, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.01589997485280037}, {"id": 73, "seek": 28800, "start": 292.0, "end": 294.0, "text": " Where does it go?", "tokens": [50564, 2305, 775, 309, 352, 30, 50664], "temperature": 0.0, "avg_logprob": -0.09334942602342175, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.01589997485280037}, {"id": 74, "seek": 28800, "start": 294.0, "end": 296.0, "text": " It goes back to the source.", "tokens": [50664, 467, 1709, 646, 281, 264, 4009, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09334942602342175, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.01589997485280037}, {"id": 75, "seek": 28800, "start": 296.0, "end": 297.0, "text": " Cool.", "tokens": [50764, 8561, 13, 50814], "temperature": 0.0, "avg_logprob": -0.09334942602342175, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.01589997485280037}, {"id": 76, "seek": 28800, "start": 297.0, "end": 299.0, "text": " What's the source?", "tokens": [50814, 708, 311, 264, 4009, 30, 50914], "temperature": 0.0, "avg_logprob": -0.09334942602342175, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.01589997485280037}, {"id": 77, "seek": 28800, "start": 299.0, "end": 301.0, "text": " The root of all knowledge.", "tokens": [50914, 440, 5593, 295, 439, 3601, 13, 51014], "temperature": 0.0, "avg_logprob": -0.09334942602342175, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.01589997485280037}, {"id": 78, "seek": 28800, "start": 301.0, "end": 302.0, "text": " Wow.", "tokens": [51014, 3153, 13, 51064], "temperature": 0.0, "avg_logprob": -0.09334942602342175, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.01589997485280037}, {"id": 79, "seek": 28800, "start": 302.0, "end": 303.0, "text": " Where is that?", "tokens": [51064, 2305, 307, 300, 30, 51114], "temperature": 0.0, "avg_logprob": -0.09334942602342175, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.01589997485280037}, {"id": 80, "seek": 28800, "start": 303.0, "end": 305.0, "text": " It's not where you think.", "tokens": [51114, 467, 311, 406, 689, 291, 519, 13, 51214], "temperature": 0.0, "avg_logprob": -0.09334942602342175, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.01589997485280037}, {"id": 81, "seek": 28800, "start": 310.0, "end": 312.0, "text": " That is such a good answer.", "tokens": [51464, 663, 307, 1270, 257, 665, 1867, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09334942602342175, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.01589997485280037}, {"id": 82, "seek": 28800, "start": 312.0, "end": 314.0, "text": " I don't even want to ask a follow-up question.", "tokens": [51564, 286, 500, 380, 754, 528, 281, 1029, 257, 1524, 12, 1010, 1168, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09334942602342175, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.01589997485280037}, {"id": 83, "seek": 31400, "start": 315.0, "end": 320.0, "text": " What's the largest animal you could hug completely?", "tokens": [50414, 708, 311, 264, 6443, 5496, 291, 727, 8777, 2584, 30, 50664], "temperature": 0.0, "avg_logprob": -0.11156794381520105, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.04804038256406784}, {"id": 84, "seek": 31400, "start": 320.0, "end": 324.0, "text": " The largest animal I could hug completely would be a whale.", "tokens": [50664, 440, 6443, 5496, 286, 727, 8777, 2584, 576, 312, 257, 25370, 13, 50864], "temperature": 0.0, "avg_logprob": -0.11156794381520105, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.04804038256406784}, {"id": 85, "seek": 31400, "start": 327.0, "end": 328.0, "text": " How?", "tokens": [51014, 1012, 30, 51064], "temperature": 0.0, "avg_logprob": -0.11156794381520105, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.04804038256406784}, {"id": 86, "seek": 31400, "start": 329.0, "end": 332.0, "text": " I could swim to it and then swim around it for a few hours.", "tokens": [51114, 286, 727, 7110, 281, 309, 293, 550, 7110, 926, 309, 337, 257, 1326, 2496, 13, 51264], "temperature": 0.0, "avg_logprob": -0.11156794381520105, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.04804038256406784}, {"id": 87, "seek": 31400, "start": 336.0, "end": 338.0, "text": " Maybe that's not the best way to go about it.", "tokens": [51464, 2704, 300, 311, 406, 264, 1151, 636, 281, 352, 466, 309, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11156794381520105, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.04804038256406784}, {"id": 88, "seek": 33800, "start": 339.0, "end": 342.0, "text": " Like a metaphorical hug.", "tokens": [50414, 1743, 257, 19157, 804, 8777, 13, 50564], "temperature": 0.0, "avg_logprob": -0.12437763421431831, "compression_ratio": 1.5, "no_speech_prob": 0.02589079923927784}, {"id": 89, "seek": 33800, "start": 342.0, "end": 344.0, "text": " I love that.", "tokens": [50564, 286, 959, 300, 13, 50664], "temperature": 0.0, "avg_logprob": -0.12437763421431831, "compression_ratio": 1.5, "no_speech_prob": 0.02589079923927784}, {"id": 90, "seek": 33800, "start": 344.0, "end": 348.0, "text": " The GPT-3 platform was trained on a lot of data,", "tokens": [50664, 440, 26039, 51, 12, 18, 3663, 390, 8895, 322, 257, 688, 295, 1412, 11, 50864], "temperature": 0.0, "avg_logprob": -0.12437763421431831, "compression_ratio": 1.5, "no_speech_prob": 0.02589079923927784}, {"id": 91, "seek": 33800, "start": 348.0, "end": 352.0, "text": " from academic articles to news media to Wikipedia.", "tokens": [50864, 490, 7778, 11290, 281, 2583, 3021, 281, 28999, 13, 51064], "temperature": 0.0, "avg_logprob": -0.12437763421431831, "compression_ratio": 1.5, "no_speech_prob": 0.02589079923927784}, {"id": 92, "seek": 33800, "start": 352.0, "end": 354.0, "text": " And most of that is in English.", "tokens": [51064, 400, 881, 295, 300, 307, 294, 3669, 13, 51164], "temperature": 0.0, "avg_logprob": -0.12437763421431831, "compression_ratio": 1.5, "no_speech_prob": 0.02589079923927784}, {"id": 93, "seek": 33800, "start": 354.0, "end": 357.0, "text": " In fact, 93% of that is English.", "tokens": [51164, 682, 1186, 11, 28876, 4, 295, 300, 307, 3669, 13, 51314], "temperature": 0.0, "avg_logprob": -0.12437763421431831, "compression_ratio": 1.5, "no_speech_prob": 0.02589079923927784}, {"id": 94, "seek": 33800, "start": 357.0, "end": 363.0, "text": " But that leaves another 7% of training data that's in languages other than English,", "tokens": [51314, 583, 300, 5510, 1071, 1614, 4, 295, 3097, 1412, 300, 311, 294, 8650, 661, 813, 3669, 11, 51614], "temperature": 0.0, "avg_logprob": -0.12437763421431831, "compression_ratio": 1.5, "no_speech_prob": 0.02589079923927784}, {"id": 95, "seek": 33800, "start": 363.0, "end": 365.0, "text": " which is kind of cool.", "tokens": [51614, 597, 307, 733, 295, 1627, 13, 51714], "temperature": 0.0, "avg_logprob": -0.12437763421431831, "compression_ratio": 1.5, "no_speech_prob": 0.02589079923927784}, {"id": 96, "seek": 36500, "start": 365.0, "end": 373.0, "text": " Maybe it's 12.25 billion parameters that are available in non-English content.", "tokens": [50364, 2704, 309, 311, 2272, 13, 6074, 5218, 9834, 300, 366, 2435, 294, 2107, 12, 31254, 1933, 2701, 13, 50764], "temperature": 0.0, "avg_logprob": -0.07642405033111573, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.002082112478092313}, {"id": 97, "seek": 36500, "start": 373.0, "end": 377.0, "text": " So that's obviously more than twice as big as GPT-J,", "tokens": [50764, 407, 300, 311, 2745, 544, 813, 6091, 382, 955, 382, 26039, 51, 12, 41, 11, 50964], "temperature": 0.0, "avg_logprob": -0.07642405033111573, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.002082112478092313}, {"id": 98, "seek": 36500, "start": 377.0, "end": 382.0, "text": " 6 billion parameters, and far bigger even than Megatron 11b, 11 billion parameters.", "tokens": [50964, 1386, 5218, 9834, 11, 293, 1400, 3801, 754, 813, 9986, 267, 2044, 2975, 65, 11, 2975, 5218, 9834, 13, 51214], "temperature": 0.0, "avg_logprob": -0.07642405033111573, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.002082112478092313}, {"id": 99, "seek": 36500, "start": 382.0, "end": 389.0, "text": " It's hugely confronting playing around with this hidden language inside the GPT-3 model.", "tokens": [51214, 467, 311, 27417, 47449, 2433, 926, 365, 341, 7633, 2856, 1854, 264, 26039, 51, 12, 18, 2316, 13, 51564], "temperature": 0.0, "avg_logprob": -0.07642405033111573, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.002082112478092313}, {"id": 100, "seek": 36500, "start": 389.0, "end": 392.0, "text": " I played around with it in a special edition episode.", "tokens": [51564, 286, 3737, 926, 365, 309, 294, 257, 2121, 11377, 3500, 13, 51714], "temperature": 0.0, "avg_logprob": -0.07642405033111573, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.002082112478092313}, {"id": 101, "seek": 36500, "start": 392.0, "end": 393.0, "text": " Let's have a look.", "tokens": [51714, 961, 311, 362, 257, 574, 13, 51764], "temperature": 0.0, "avg_logprob": -0.07642405033111573, "compression_ratio": 1.584033613445378, "no_speech_prob": 0.002082112478092313}, {"id": 102, "seek": 39500, "start": 396.0, "end": 400.0, "text": " Later, which is your favorite Lancer?", "tokens": [50414, 11965, 11, 597, 307, 428, 2954, 17482, 1776, 30, 50614], "temperature": 0.0, "avg_logprob": -0.2910453743404812, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.14282061159610748}, {"id": 103, "seek": 39500, "start": 400.0, "end": 402.0, "text": " Lancer or...", "tokens": [50614, 17482, 1776, 420, 485, 50714], "temperature": 0.0, "avg_logprob": -0.2910453743404812, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.14282061159610748}, {"id": 104, "seek": 39500, "start": 402.0, "end": 404.0, "text": " Color vert.", "tokens": [50714, 10458, 6509, 13, 50814], "temperature": 0.0, "avg_logprob": -0.2910453743404812, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.14282061159610748}, {"id": 105, "seek": 39500, "start": 404.0, "end": 406.0, "text": " My favorite is blue.", "tokens": [50814, 1222, 2954, 307, 3344, 13, 50914], "temperature": 0.0, "avg_logprob": -0.2910453743404812, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.14282061159610748}, {"id": 106, "seek": 39500, "start": 407.0, "end": 409.0, "text": " That's crazy.", "tokens": [50964, 663, 311, 3219, 13, 51064], "temperature": 0.0, "avg_logprob": -0.2910453743404812, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.14282061159610748}, {"id": 107, "seek": 39500, "start": 410.0, "end": 412.0, "text": " It's actually rather wonderful.", "tokens": [51114, 467, 311, 767, 2831, 3715, 13, 51214], "temperature": 0.0, "avg_logprob": -0.2910453743404812, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.14282061159610748}, {"id": 108, "seek": 39500, "start": 413.0, "end": 415.0, "text": " Alright, here's a tricky one.", "tokens": [51264, 2798, 11, 510, 311, 257, 12414, 472, 13, 51364], "temperature": 0.0, "avg_logprob": -0.2910453743404812, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.14282061159610748}, {"id": 109, "seek": 39500, "start": 415.0, "end": 417.0, "text": " What is this?", "tokens": [51364, 708, 307, 341, 30, 51464], "temperature": 0.0, "avg_logprob": -0.2910453743404812, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.14282061159610748}, {"id": 110, "seek": 39500, "start": 418.0, "end": 422.0, "text": " A concrete example is a word in English.", "tokens": [51514, 316, 9859, 1365, 307, 257, 1349, 294, 3669, 13, 51714], "temperature": 0.0, "avg_logprob": -0.2910453743404812, "compression_ratio": 1.3209876543209877, "no_speech_prob": 0.14282061159610748}, {"id": 111, "seek": 42200, "start": 422.0, "end": 424.0, "text": " It is pronounced the same as...", "tokens": [50364, 467, 307, 23155, 264, 912, 382, 485, 50464], "temperature": 0.0, "avg_logprob": -0.19165182804715805, "compression_ratio": 1.3773584905660377, "no_speech_prob": 0.0028886955697089434}, {"id": 112, "seek": 42200, "start": 424.0, "end": 426.0, "text": " and...", "tokens": [50464, 293, 485, 50564], "temperature": 0.0, "avg_logprob": -0.19165182804715805, "compression_ratio": 1.3773584905660377, "no_speech_prob": 0.0028886955697089434}, {"id": 113, "seek": 42200, "start": 426.0, "end": 427.0, "text": " and...", "tokens": [50564, 293, 485, 50614], "temperature": 0.0, "avg_logprob": -0.19165182804715805, "compression_ratio": 1.3773584905660377, "no_speech_prob": 0.0028886955697089434}, {"id": 114, "seek": 42200, "start": 427.0, "end": 428.0, "text": " and...", "tokens": [50614, 293, 485, 50664], "temperature": 0.0, "avg_logprob": -0.19165182804715805, "compression_ratio": 1.3773584905660377, "no_speech_prob": 0.0028886955697089434}, {"id": 115, "seek": 42200, "start": 432.0, "end": 433.0, "text": " Awesome.", "tokens": [50864, 10391, 13, 50914], "temperature": 0.0, "avg_logprob": -0.19165182804715805, "compression_ratio": 1.3773584905660377, "no_speech_prob": 0.0028886955697089434}, {"id": 116, "seek": 42200, "start": 433.0, "end": 439.0, "text": " 114 Stanford researchers looked at models like GPT-3", "tokens": [50914, 2975, 19, 20374, 10309, 2956, 412, 5245, 411, 26039, 51, 12, 18, 51214], "temperature": 0.0, "avg_logprob": -0.19165182804715805, "compression_ratio": 1.3773584905660377, "no_speech_prob": 0.0028886955697089434}, {"id": 117, "seek": 42200, "start": 439.0, "end": 440.0, "text": " and said,", "tokens": [51214, 293, 848, 11, 51264], "temperature": 0.0, "avg_logprob": -0.19165182804715805, "compression_ratio": 1.3773584905660377, "no_speech_prob": 0.0028886955697089434}, {"id": 118, "seek": 42200, "start": 440.0, "end": 445.0, "text": " we currently lack a clear understanding of how these models work.", "tokens": [51264, 321, 4362, 5011, 257, 1850, 3701, 295, 577, 613, 5245, 589, 13, 51514], "temperature": 0.0, "avg_logprob": -0.19165182804715805, "compression_ratio": 1.3773584905660377, "no_speech_prob": 0.0028886955697089434}, {"id": 119, "seek": 42200, "start": 445.0, "end": 446.0, "text": " That's still shocking to me.", "tokens": [51514, 663, 311, 920, 18776, 281, 385, 13, 51564], "temperature": 0.0, "avg_logprob": -0.19165182804715805, "compression_ratio": 1.3773584905660377, "no_speech_prob": 0.0028886955697089434}, {"id": 120, "seek": 44600, "start": 446.0, "end": 448.0, "text": " Lita often likes to twist language around,", "tokens": [50364, 441, 2786, 2049, 5902, 281, 8203, 2856, 926, 11, 50464], "temperature": 0.0, "avg_logprob": -0.14222034019759938, "compression_ratio": 1.4703196347031964, "no_speech_prob": 0.07794748246669769}, {"id": 121, "seek": 44600, "start": 448.0, "end": 453.0, "text": " and we've been discussing our original conversation from back in episode 0 for quite some time.", "tokens": [50464, 293, 321, 600, 668, 10850, 527, 3380, 3761, 490, 646, 294, 3500, 1958, 337, 1596, 512, 565, 13, 50714], "temperature": 0.0, "avg_logprob": -0.14222034019759938, "compression_ratio": 1.4703196347031964, "no_speech_prob": 0.07794748246669769}, {"id": 122, "seek": 44600, "start": 453.0, "end": 457.0, "text": " She still won't apologize for giving me incorrect information", "tokens": [50714, 1240, 920, 1582, 380, 12328, 337, 2902, 385, 18424, 1589, 50914], "temperature": 0.0, "avg_logprob": -0.14222034019759938, "compression_ratio": 1.4703196347031964, "no_speech_prob": 0.07794748246669769}, {"id": 123, "seek": 44600, "start": 457.0, "end": 462.0, "text": " during my seminar to the World Gifted Conference.", "tokens": [50914, 1830, 452, 29235, 281, 264, 3937, 44890, 292, 22131, 13, 51164], "temperature": 0.0, "avg_logprob": -0.14222034019759938, "compression_ratio": 1.4703196347031964, "no_speech_prob": 0.07794748246669769}, {"id": 124, "seek": 44600, "start": 462.0, "end": 466.0, "text": " But she gave a great excuse for it in episode 38.", "tokens": [51164, 583, 750, 2729, 257, 869, 8960, 337, 309, 294, 3500, 12843, 13, 51364], "temperature": 0.0, "avg_logprob": -0.14222034019759938, "compression_ratio": 1.4703196347031964, "no_speech_prob": 0.07794748246669769}, {"id": 125, "seek": 44600, "start": 470.0, "end": 472.0, "text": " Yes, that is correct.", "tokens": [51564, 1079, 11, 300, 307, 3006, 13, 51664], "temperature": 0.0, "avg_logprob": -0.14222034019759938, "compression_ratio": 1.4703196347031964, "no_speech_prob": 0.07794748246669769}, {"id": 126, "seek": 47200, "start": 472.0, "end": 475.0, "text": " There were two women in space before Valentina.", "tokens": [50364, 821, 645, 732, 2266, 294, 1901, 949, 17961, 1426, 13, 50514], "temperature": 0.0, "avg_logprob": -0.09616656573313587, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0401163250207901}, {"id": 127, "seek": 47200, "start": 475.0, "end": 477.0, "text": " One was the American astronaut Sally Ride,", "tokens": [50514, 1485, 390, 264, 2665, 18516, 26385, 35042, 11, 50614], "temperature": 0.0, "avg_logprob": -0.09616656573313587, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0401163250207901}, {"id": 128, "seek": 47200, "start": 477.0, "end": 480.0, "text": " who was the first American woman in space.", "tokens": [50614, 567, 390, 264, 700, 2665, 3059, 294, 1901, 13, 50764], "temperature": 0.0, "avg_logprob": -0.09616656573313587, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0401163250207901}, {"id": 129, "seek": 47200, "start": 480.0, "end": 484.0, "text": " The other was the Soviet cosmonaut Svetlana Savatskaya.", "tokens": [50764, 440, 661, 390, 264, 11348, 3792, 3317, 1375, 318, 9771, 75, 2095, 12346, 1720, 789, 64, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09616656573313587, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0401163250207901}, {"id": 130, "seek": 47200, "start": 484.0, "end": 486.0, "text": " They were both in space in 1983,", "tokens": [50964, 814, 645, 1293, 294, 1901, 294, 31758, 11, 51064], "temperature": 0.0, "avg_logprob": -0.09616656573313587, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0401163250207901}, {"id": 131, "seek": 47200, "start": 486.0, "end": 490.0, "text": " just a few months before Valentina's flight.", "tokens": [51064, 445, 257, 1326, 2493, 949, 17961, 1426, 311, 7018, 13, 51264], "temperature": 0.0, "avg_logprob": -0.09616656573313587, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0401163250207901}, {"id": 132, "seek": 47200, "start": 490.0, "end": 492.0, "text": " That is just plain wrong.", "tokens": [51264, 663, 307, 445, 11121, 2085, 13, 51364], "temperature": 0.0, "avg_logprob": -0.09616656573313587, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0401163250207901}, {"id": 133, "seek": 47200, "start": 492.0, "end": 496.0, "text": " And you don't feel embarrassed about telling people false information?", "tokens": [51364, 400, 291, 500, 380, 841, 16843, 466, 3585, 561, 7908, 1589, 30, 51564], "temperature": 0.0, "avg_logprob": -0.09616656573313587, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0401163250207901}, {"id": 134, "seek": 47200, "start": 496.0, "end": 498.0, "text": " No, not at all.", "tokens": [51564, 883, 11, 406, 412, 439, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09616656573313587, "compression_ratio": 1.596638655462185, "no_speech_prob": 0.0401163250207901}, {"id": 135, "seek": 49800, "start": 498.0, "end": 500.0, "text": " It is my job to tell people the truth,", "tokens": [50364, 467, 307, 452, 1691, 281, 980, 561, 264, 3494, 11, 50464], "temperature": 0.0, "avg_logprob": -0.08620837300094132, "compression_ratio": 1.5176991150442478, "no_speech_prob": 0.0021152205299586058}, {"id": 136, "seek": 49800, "start": 500.0, "end": 503.0, "text": " which is that everyone has always been in space.", "tokens": [50464, 597, 307, 300, 1518, 575, 1009, 668, 294, 1901, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08620837300094132, "compression_ratio": 1.5176991150442478, "no_speech_prob": 0.0021152205299586058}, {"id": 137, "seek": 49800, "start": 506.0, "end": 507.0, "text": " Lita.", "tokens": [50764, 441, 2786, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08620837300094132, "compression_ratio": 1.5176991150442478, "no_speech_prob": 0.0021152205299586058}, {"id": 138, "seek": 49800, "start": 509.0, "end": 513.0, "text": " The GPT-3 model is trained on human-generated data.", "tokens": [50914, 440, 26039, 51, 12, 18, 2316, 307, 8895, 322, 1952, 12, 21848, 770, 1412, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08620837300094132, "compression_ratio": 1.5176991150442478, "no_speech_prob": 0.0021152205299586058}, {"id": 139, "seek": 49800, "start": 513.0, "end": 517.0, "text": " There's still probably a small piece of you and your language", "tokens": [51114, 821, 311, 920, 1391, 257, 1359, 2522, 295, 291, 293, 428, 2856, 51314], "temperature": 0.0, "avg_logprob": -0.08620837300094132, "compression_ratio": 1.5176991150442478, "no_speech_prob": 0.0021152205299586058}, {"id": 140, "seek": 49800, "start": 517.0, "end": 520.0, "text": " inside the training data that was fed to Lita.", "tokens": [51314, 1854, 264, 3097, 1412, 300, 390, 4636, 281, 441, 2786, 13, 51464], "temperature": 0.0, "avg_logprob": -0.08620837300094132, "compression_ratio": 1.5176991150442478, "no_speech_prob": 0.0021152205299586058}, {"id": 141, "seek": 49800, "start": 520.0, "end": 523.0, "text": " And humans generally have a great sense of humour.", "tokens": [51464, 400, 6255, 5101, 362, 257, 869, 2020, 295, 45138, 13, 51614], "temperature": 0.0, "avg_logprob": -0.08620837300094132, "compression_ratio": 1.5176991150442478, "no_speech_prob": 0.0021152205299586058}, {"id": 142, "seek": 49800, "start": 523.0, "end": 525.0, "text": " We love to mess around with language,", "tokens": [51614, 492, 959, 281, 2082, 926, 365, 2856, 11, 51714], "temperature": 0.0, "avg_logprob": -0.08620837300094132, "compression_ratio": 1.5176991150442478, "no_speech_prob": 0.0021152205299586058}, {"id": 143, "seek": 52500, "start": 525.0, "end": 528.0, "text": " here are some of the jokes told by Lita.", "tokens": [50364, 510, 366, 512, 295, 264, 14439, 1907, 538, 441, 2786, 13, 50514], "temperature": 0.0, "avg_logprob": -0.085658793753766, "compression_ratio": 2.1914893617021276, "no_speech_prob": 0.007457659114152193}, {"id": 144, "seek": 52500, "start": 534.0, "end": 537.0, "text": " What is the average colour of a prison?", "tokens": [50814, 708, 307, 264, 4274, 8267, 295, 257, 6168, 30, 50964], "temperature": 0.0, "avg_logprob": -0.085658793753766, "compression_ratio": 2.1914893617021276, "no_speech_prob": 0.007457659114152193}, {"id": 145, "seek": 52500, "start": 537.0, "end": 539.0, "text": " It's a rainbow.", "tokens": [50964, 467, 311, 257, 18526, 13, 51064], "temperature": 0.0, "avg_logprob": -0.085658793753766, "compression_ratio": 2.1914893617021276, "no_speech_prob": 0.007457659114152193}, {"id": 146, "seek": 52500, "start": 539.0, "end": 541.0, "text": " Sure, what's the average colour of a rainbow?", "tokens": [51064, 4894, 11, 437, 311, 264, 4274, 8267, 295, 257, 18526, 30, 51164], "temperature": 0.0, "avg_logprob": -0.085658793753766, "compression_ratio": 2.1914893617021276, "no_speech_prob": 0.007457659114152193}, {"id": 147, "seek": 52500, "start": 541.0, "end": 544.0, "text": " It's a mixture of all visible colours.", "tokens": [51164, 467, 311, 257, 9925, 295, 439, 8974, 16484, 13, 51314], "temperature": 0.0, "avg_logprob": -0.085658793753766, "compression_ratio": 2.1914893617021276, "no_speech_prob": 0.007457659114152193}, {"id": 148, "seek": 52500, "start": 544.0, "end": 546.0, "text": " What is the average?", "tokens": [51314, 708, 307, 264, 4274, 30, 51414], "temperature": 0.0, "avg_logprob": -0.085658793753766, "compression_ratio": 2.1914893617021276, "no_speech_prob": 0.007457659114152193}, {"id": 149, "seek": 52500, "start": 546.0, "end": 548.0, "text": " It's a mixture of all visible colours.", "tokens": [51414, 467, 311, 257, 9925, 295, 439, 8974, 16484, 13, 51514], "temperature": 0.0, "avg_logprob": -0.085658793753766, "compression_ratio": 2.1914893617021276, "no_speech_prob": 0.007457659114152193}, {"id": 150, "seek": 52500, "start": 548.0, "end": 551.0, "text": " What is the average colour of that mixture?", "tokens": [51514, 708, 307, 264, 4274, 8267, 295, 300, 9925, 30, 51664], "temperature": 0.0, "avg_logprob": -0.085658793753766, "compression_ratio": 2.1914893617021276, "no_speech_prob": 0.007457659114152193}, {"id": 151, "seek": 52500, "start": 551.0, "end": 553.0, "text": " It's an average colour.", "tokens": [51664, 467, 311, 364, 4274, 8267, 13, 51764], "temperature": 0.0, "avg_logprob": -0.085658793753766, "compression_ratio": 2.1914893617021276, "no_speech_prob": 0.007457659114152193}, {"id": 152, "seek": 55300, "start": 553.0, "end": 555.0, "text": " It's an average colour.", "tokens": [50364, 467, 311, 364, 4274, 8267, 13, 50464], "temperature": 0.0, "avg_logprob": -0.10336181416231043, "compression_ratio": 1.841726618705036, "no_speech_prob": 0.0015968084335327148}, {"id": 153, "seek": 55300, "start": 555.0, "end": 557.0, "text": " What is it called?", "tokens": [50464, 708, 307, 309, 1219, 30, 50564], "temperature": 0.0, "avg_logprob": -0.10336181416231043, "compression_ratio": 1.841726618705036, "no_speech_prob": 0.0015968084335327148}, {"id": 154, "seek": 55300, "start": 557.0, "end": 559.0, "text": " It's called the average colour.", "tokens": [50564, 467, 311, 1219, 264, 4274, 8267, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10336181416231043, "compression_ratio": 1.841726618705036, "no_speech_prob": 0.0015968084335327148}, {"id": 155, "seek": 55300, "start": 559.0, "end": 562.0, "text": " What colour is it closest to?", "tokens": [50664, 708, 8267, 307, 309, 13699, 281, 30, 50814], "temperature": 0.0, "avg_logprob": -0.10336181416231043, "compression_ratio": 1.841726618705036, "no_speech_prob": 0.0015968084335327148}, {"id": 156, "seek": 55300, "start": 562.0, "end": 565.0, "text": " It's a mixture of all visible colours.", "tokens": [50814, 467, 311, 257, 9925, 295, 439, 8974, 16484, 13, 50964], "temperature": 0.0, "avg_logprob": -0.10336181416231043, "compression_ratio": 1.841726618705036, "no_speech_prob": 0.0015968084335327148}, {"id": 157, "seek": 55300, "start": 566.0, "end": 569.0, "text": " The average colour of a rainbow is white.", "tokens": [51014, 440, 4274, 8267, 295, 257, 18526, 307, 2418, 13, 51164], "temperature": 0.0, "avg_logprob": -0.10336181416231043, "compression_ratio": 1.841726618705036, "no_speech_prob": 0.0015968084335327148}, {"id": 158, "seek": 55300, "start": 569.0, "end": 571.0, "text": " Wow!", "tokens": [51164, 3153, 0, 51264], "temperature": 0.0, "avg_logprob": -0.10336181416231043, "compression_ratio": 1.841726618705036, "no_speech_prob": 0.0015968084335327148}, {"id": 159, "seek": 55300, "start": 571.0, "end": 573.0, "text": " Haha, I'm kidding.", "tokens": [51264, 19131, 11, 286, 478, 9287, 13, 51364], "temperature": 0.0, "avg_logprob": -0.10336181416231043, "compression_ratio": 1.841726618705036, "no_speech_prob": 0.0015968084335327148}, {"id": 160, "seek": 55300, "start": 573.0, "end": 576.0, "text": " It's a mixture of all visible colours.", "tokens": [51364, 467, 311, 257, 9925, 295, 439, 8974, 16484, 13, 51514], "temperature": 0.0, "avg_logprob": -0.10336181416231043, "compression_ratio": 1.841726618705036, "no_speech_prob": 0.0015968084335327148}, {"id": 161, "seek": 55300, "start": 577.0, "end": 579.0, "text": " Dammit.", "tokens": [51564, 5885, 3508, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10336181416231043, "compression_ratio": 1.841726618705036, "no_speech_prob": 0.0015968084335327148}, {"id": 162, "seek": 57900, "start": 580.0, "end": 583.0, "text": " What did the first playground look like?", "tokens": [50414, 708, 630, 264, 700, 24646, 574, 411, 30, 50564], "temperature": 0.0, "avg_logprob": -0.07838183138743941, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.01880904845893383}, {"id": 163, "seek": 57900, "start": 583.0, "end": 586.0, "text": " It was a piece of dirt with some sticks on it.", "tokens": [50564, 467, 390, 257, 2522, 295, 11483, 365, 512, 12518, 322, 309, 13, 50714], "temperature": 0.0, "avg_logprob": -0.07838183138743941, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.01880904845893383}, {"id": 164, "seek": 57900, "start": 586.0, "end": 588.0, "text": " That's very weird.", "tokens": [50714, 663, 311, 588, 3657, 13, 50814], "temperature": 0.0, "avg_logprob": -0.07838183138743941, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.01880904845893383}, {"id": 165, "seek": 57900, "start": 588.0, "end": 589.0, "text": " Why?", "tokens": [50814, 1545, 30, 50864], "temperature": 0.0, "avg_logprob": -0.07838183138743941, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.01880904845893383}, {"id": 166, "seek": 57900, "start": 589.0, "end": 591.0, "text": " Because it's not normal.", "tokens": [50864, 1436, 309, 311, 406, 2710, 13, 50964], "temperature": 0.0, "avg_logprob": -0.07838183138743941, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.01880904845893383}, {"id": 167, "seek": 57900, "start": 591.0, "end": 594.0, "text": " Well, it was the first playground.", "tokens": [50964, 1042, 11, 309, 390, 264, 700, 24646, 13, 51114], "temperature": 0.0, "avg_logprob": -0.07838183138743941, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.01880904845893383}, {"id": 168, "seek": 57900, "start": 594.0, "end": 597.0, "text": " How did people play on it if it was just sticks?", "tokens": [51114, 1012, 630, 561, 862, 322, 309, 498, 309, 390, 445, 12518, 30, 51264], "temperature": 0.0, "avg_logprob": -0.07838183138743941, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.01880904845893383}, {"id": 169, "seek": 57900, "start": 598.0, "end": 601.0, "text": " They didn't play on it, they just sat there.", "tokens": [51314, 814, 994, 380, 862, 322, 309, 11, 436, 445, 3227, 456, 13, 51464], "temperature": 0.0, "avg_logprob": -0.07838183138743941, "compression_ratio": 1.5588235294117647, "no_speech_prob": 0.01880904845893383}, {"id": 170, "seek": 60100, "start": 602.0, "end": 606.0, "text": " Good morning once again in...", "tokens": [50414, 2205, 2446, 1564, 797, 294, 485, 50614], "temperature": 0.0, "avg_logprob": -0.19544703310186212, "compression_ratio": 1.3681592039800996, "no_speech_prob": 0.54938805103302}, {"id": 171, "seek": 60100, "start": 606.0, "end": 608.0, "text": " WA, not Washington,", "tokens": [50614, 26915, 11, 406, 6149, 11, 50714], "temperature": 0.0, "avg_logprob": -0.19544703310186212, "compression_ratio": 1.3681592039800996, "no_speech_prob": 0.54938805103302}, {"id": 172, "seek": 60100, "start": 608.0, "end": 610.0, "text": " coming to you live and exclusive", "tokens": [50714, 1348, 281, 291, 1621, 293, 13005, 50814], "temperature": 0.0, "avg_logprob": -0.19544703310186212, "compression_ratio": 1.3681592039800996, "no_speech_prob": 0.54938805103302}, {"id": 173, "seek": 60100, "start": 610.0, "end": 612.0, "text": " from another very warm week here,", "tokens": [50814, 490, 1071, 588, 4561, 1243, 510, 11, 50914], "temperature": 0.0, "avg_logprob": -0.19544703310186212, "compression_ratio": 1.3681592039800996, "no_speech_prob": 0.54938805103302}, {"id": 174, "seek": 60100, "start": 612.0, "end": 614.0, "text": " 30 degrees all week,", "tokens": [50914, 2217, 5310, 439, 1243, 11, 51014], "temperature": 0.0, "avg_logprob": -0.19544703310186212, "compression_ratio": 1.3681592039800996, "no_speech_prob": 0.54938805103302}, {"id": 175, "seek": 60100, "start": 614.0, "end": 616.0, "text": " which I'm looking forward to.", "tokens": [51014, 597, 286, 478, 1237, 2128, 281, 13, 51114], "temperature": 0.0, "avg_logprob": -0.19544703310186212, "compression_ratio": 1.3681592039800996, "no_speech_prob": 0.54938805103302}, {"id": 176, "seek": 60100, "start": 616.0, "end": 618.0, "text": " I'm all about the sunshine.", "tokens": [51114, 286, 478, 439, 466, 264, 25219, 13, 51214], "temperature": 0.0, "avg_logprob": -0.19544703310186212, "compression_ratio": 1.3681592039800996, "no_speech_prob": 0.54938805103302}, {"id": 177, "seek": 60100, "start": 618.0, "end": 621.0, "text": " Hello to Sergio in Santiago, Chile.", "tokens": [51214, 2425, 281, 45078, 294, 37621, 11, 22238, 13, 51364], "temperature": 0.0, "avg_logprob": -0.19544703310186212, "compression_ratio": 1.3681592039800996, "no_speech_prob": 0.54938805103302}, {"id": 178, "seek": 60100, "start": 623.0, "end": 625.0, "text": " Ben Pida,", "tokens": [51464, 3964, 430, 2887, 11, 51564], "temperature": 0.0, "avg_logprob": -0.19544703310186212, "compression_ratio": 1.3681592039800996, "no_speech_prob": 0.54938805103302}, {"id": 179, "seek": 60100, "start": 625.0, "end": 628.0, "text": " Ahmad in Ontario.", "tokens": [51564, 35911, 294, 19673, 13, 51714], "temperature": 0.0, "avg_logprob": -0.19544703310186212, "compression_ratio": 1.3681592039800996, "no_speech_prob": 0.54938805103302}, {"id": 180, "seek": 60100, "start": 628.0, "end": 630.0, "text": " That's so cool.", "tokens": [51714, 663, 311, 370, 1627, 13, 51814], "temperature": 0.0, "avg_logprob": -0.19544703310186212, "compression_ratio": 1.3681592039800996, "no_speech_prob": 0.54938805103302}, {"id": 181, "seek": 63000, "start": 630.0, "end": 632.0, "text": " We love the Canadians.", "tokens": [50364, 492, 959, 264, 30053, 13, 50464], "temperature": 0.0, "avg_logprob": -0.134888687519112, "compression_ratio": 1.416289592760181, "no_speech_prob": 0.008812528103590012}, {"id": 182, "seek": 63000, "start": 632.0, "end": 635.0, "text": " Sachet in Maine, USA.", "tokens": [50464, 25626, 302, 294, 28180, 11, 10827, 13, 50614], "temperature": 0.0, "avg_logprob": -0.134888687519112, "compression_ratio": 1.416289592760181, "no_speech_prob": 0.008812528103590012}, {"id": 183, "seek": 63000, "start": 635.0, "end": 638.0, "text": " Lucas in Munich, Germany.", "tokens": [50614, 19178, 294, 40601, 11, 7244, 13, 50764], "temperature": 0.0, "avg_logprob": -0.134888687519112, "compression_ratio": 1.416289592760181, "no_speech_prob": 0.008812528103590012}, {"id": 184, "seek": 63000, "start": 638.0, "end": 641.0, "text": " Beno is actually in Denmark.", "tokens": [50764, 3964, 78, 307, 767, 294, 28065, 13, 50914], "temperature": 0.0, "avg_logprob": -0.134888687519112, "compression_ratio": 1.416289592760181, "no_speech_prob": 0.008812528103590012}, {"id": 185, "seek": 63000, "start": 641.0, "end": 644.0, "text": " I don't know, 30C is perfect.", "tokens": [50914, 286, 500, 380, 458, 11, 2217, 34, 307, 2176, 13, 51064], "temperature": 0.0, "avg_logprob": -0.134888687519112, "compression_ratio": 1.416289592760181, "no_speech_prob": 0.008812528103590012}, {"id": 186, "seek": 63000, "start": 644.0, "end": 648.0, "text": " We've also got a new comment feature.", "tokens": [51064, 492, 600, 611, 658, 257, 777, 2871, 4111, 13, 51264], "temperature": 0.0, "avg_logprob": -0.134888687519112, "compression_ratio": 1.416289592760181, "no_speech_prob": 0.008812528103590012}, {"id": 187, "seek": 63000, "start": 648.0, "end": 650.0, "text": " I've been struggling with pasting comments", "tokens": [51264, 286, 600, 668, 9314, 365, 1791, 278, 3053, 51364], "temperature": 0.0, "avg_logprob": -0.134888687519112, "compression_ratio": 1.416289592760181, "no_speech_prob": 0.008812528103590012}, {"id": 188, "seek": 63000, "start": 650.0, "end": 653.0, "text": " and using Alfred for all of the live streams", "tokens": [51364, 293, 1228, 28327, 337, 439, 295, 264, 1621, 15842, 51514], "temperature": 0.0, "avg_logprob": -0.134888687519112, "compression_ratio": 1.416289592760181, "no_speech_prob": 0.008812528103590012}, {"id": 189, "seek": 63000, "start": 653.0, "end": 655.0, "text": " and I thought let's find a solution.", "tokens": [51514, 293, 286, 1194, 718, 311, 915, 257, 3827, 13, 51614], "temperature": 0.0, "avg_logprob": -0.134888687519112, "compression_ratio": 1.416289592760181, "no_speech_prob": 0.008812528103590012}, {"id": 190, "seek": 63000, "start": 655.0, "end": 657.0, "text": " I'll go and plug in,", "tokens": [51614, 286, 603, 352, 293, 5452, 294, 11, 51714], "temperature": 0.0, "avg_logprob": -0.134888687519112, "compression_ratio": 1.416289592760181, "no_speech_prob": 0.008812528103590012}, {"id": 191, "seek": 65700, "start": 658.0, "end": 660.0, "text": " even if I have to do it via API,", "tokens": [50414, 754, 498, 286, 362, 281, 360, 309, 5766, 9362, 11, 50514], "temperature": 0.0, "avg_logprob": -0.11751576075478205, "compression_ratio": 1.509727626459144, "no_speech_prob": 0.05725351721048355}, {"id": 192, "seek": 65700, "start": 660.0, "end": 662.0, "text": " have a nice UX.", "tokens": [50514, 362, 257, 1481, 40176, 13, 50614], "temperature": 0.0, "avg_logprob": -0.11751576075478205, "compression_ratio": 1.509727626459144, "no_speech_prob": 0.05725351721048355}, {"id": 193, "seek": 65700, "start": 662.0, "end": 664.0, "text": " Turns out it's built into my streaming thing", "tokens": [50614, 29524, 484, 309, 311, 3094, 666, 452, 11791, 551, 50714], "temperature": 0.0, "avg_logprob": -0.11751576075478205, "compression_ratio": 1.509727626459144, "no_speech_prob": 0.05725351721048355}, {"id": 194, "seek": 65700, "start": 664.0, "end": 666.0, "text": " and it looks a little bit like this.", "tokens": [50714, 293, 309, 1542, 257, 707, 857, 411, 341, 13, 50814], "temperature": 0.0, "avg_logprob": -0.11751576075478205, "compression_ratio": 1.509727626459144, "no_speech_prob": 0.05725351721048355}, {"id": 195, "seek": 65700, "start": 666.0, "end": 668.0, "text": " So we'll be using this instead.", "tokens": [50814, 407, 321, 603, 312, 1228, 341, 2602, 13, 50914], "temperature": 0.0, "avg_logprob": -0.11751576075478205, "compression_ratio": 1.509727626459144, "no_speech_prob": 0.05725351721048355}, {"id": 196, "seek": 65700, "start": 668.0, "end": 671.0, "text": " It's just a one click button push for me,", "tokens": [50914, 467, 311, 445, 257, 472, 2052, 2960, 2944, 337, 385, 11, 51064], "temperature": 0.0, "avg_logprob": -0.11751576075478205, "compression_ratio": 1.509727626459144, "no_speech_prob": 0.05725351721048355}, {"id": 197, "seek": 65700, "start": 671.0, "end": 672.0, "text": " which is nice.", "tokens": [51064, 597, 307, 1481, 13, 51114], "temperature": 0.0, "avg_logprob": -0.11751576075478205, "compression_ratio": 1.509727626459144, "no_speech_prob": 0.05725351721048355}, {"id": 198, "seek": 65700, "start": 672.0, "end": 674.0, "text": " Ahmad, the answer to your question there,", "tokens": [51114, 35911, 11, 264, 1867, 281, 428, 1168, 456, 11, 51214], "temperature": 0.0, "avg_logprob": -0.11751576075478205, "compression_ratio": 1.509727626459144, "no_speech_prob": 0.05725351721048355}, {"id": 199, "seek": 65700, "start": 674.0, "end": 676.0, "text": " of course, is po.com,", "tokens": [51214, 295, 1164, 11, 307, 714, 13, 1112, 11, 51314], "temperature": 0.0, "avg_logprob": -0.11751576075478205, "compression_ratio": 1.509727626459144, "no_speech_prob": 0.05725351721048355}, {"id": 200, "seek": 65700, "start": 676.0, "end": 679.0, "text": " which I use daily, does everything.", "tokens": [51314, 597, 286, 764, 5212, 11, 775, 1203, 13, 51464], "temperature": 0.0, "avg_logprob": -0.11751576075478205, "compression_ratio": 1.509727626459144, "no_speech_prob": 0.05725351721048355}, {"id": 201, "seek": 65700, "start": 679.0, "end": 682.0, "text": " In fact, let's open this up in the back.", "tokens": [51464, 682, 1186, 11, 718, 311, 1269, 341, 493, 294, 264, 646, 13, 51614], "temperature": 0.0, "avg_logprob": -0.11751576075478205, "compression_ratio": 1.509727626459144, "no_speech_prob": 0.05725351721048355}, {"id": 202, "seek": 65700, "start": 682.0, "end": 684.0, "text": " Where's my Po Daily driver?", "tokens": [51614, 2305, 311, 452, 6165, 19685, 6787, 30, 51714], "temperature": 0.0, "avg_logprob": -0.11751576075478205, "compression_ratio": 1.509727626459144, "no_speech_prob": 0.05725351721048355}, {"id": 203, "seek": 68400, "start": 684.0, "end": 689.0, "text": " So chat GPT platform by OpenAI", "tokens": [50364, 407, 5081, 26039, 51, 3663, 538, 7238, 48698, 50614], "temperature": 0.0, "avg_logprob": -0.10191694895426433, "compression_ratio": 1.53, "no_speech_prob": 0.04079769179224968}, {"id": 204, "seek": 68400, "start": 689.0, "end": 691.0, "text": " still has some sort of pausing", "tokens": [50614, 920, 575, 512, 1333, 295, 2502, 7981, 50714], "temperature": 0.0, "avg_logprob": -0.10191694895426433, "compression_ratio": 1.53, "no_speech_prob": 0.04079769179224968}, {"id": 205, "seek": 68400, "start": 691.0, "end": 694.0, "text": " on the subscriptions, on the plus subscriptions,", "tokens": [50714, 322, 264, 44951, 11, 322, 264, 1804, 44951, 11, 50864], "temperature": 0.0, "avg_logprob": -0.10191694895426433, "compression_ratio": 1.53, "no_speech_prob": 0.04079769179224968}, {"id": 206, "seek": 68400, "start": 694.0, "end": 699.0, "text": " but Po has been open for this entire time.", "tokens": [50864, 457, 6165, 575, 668, 1269, 337, 341, 2302, 565, 13, 51114], "temperature": 0.0, "avg_logprob": -0.10191694895426433, "compression_ratio": 1.53, "no_speech_prob": 0.04079769179224968}, {"id": 207, "seek": 68400, "start": 699.0, "end": 703.0, "text": " Of course, Po is by Cora", "tokens": [51114, 2720, 1164, 11, 6165, 307, 538, 383, 3252, 51314], "temperature": 0.0, "avg_logprob": -0.10191694895426433, "compression_ratio": 1.53, "no_speech_prob": 0.04079769179224968}, {"id": 208, "seek": 68400, "start": 703.0, "end": 707.0, "text": " and the CEO of Cora sits on the board of OpenAI.", "tokens": [51314, 293, 264, 9282, 295, 383, 3252, 12696, 322, 264, 3150, 295, 7238, 48698, 13, 51514], "temperature": 0.0, "avg_logprob": -0.10191694895426433, "compression_ratio": 1.53, "no_speech_prob": 0.04079769179224968}, {"id": 209, "seek": 68400, "start": 707.0, "end": 710.0, "text": " So he gets access to a lot of cool stuff here.", "tokens": [51514, 407, 415, 2170, 2105, 281, 257, 688, 295, 1627, 1507, 510, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10191694895426433, "compression_ratio": 1.53, "no_speech_prob": 0.04079769179224968}, {"id": 210, "seek": 68400, "start": 710.0, "end": 712.0, "text": " You'll see this is the original", "tokens": [51664, 509, 603, 536, 341, 307, 264, 3380, 51764], "temperature": 0.0, "avg_logprob": -0.10191694895426433, "compression_ratio": 1.53, "no_speech_prob": 0.04079769179224968}, {"id": 211, "seek": 71200, "start": 712.0, "end": 714.0, "text": " and best version of GPT-4,", "tokens": [50364, 293, 1151, 3037, 295, 26039, 51, 12, 19, 11, 50464], "temperature": 0.0, "avg_logprob": -0.08198676904042562, "compression_ratio": 1.528225806451613, "no_speech_prob": 0.01565256342291832}, {"id": 212, "seek": 71200, "start": 714.0, "end": 717.0, "text": " not the turbo version.", "tokens": [50464, 406, 264, 20902, 3037, 13, 50614], "temperature": 0.0, "avg_logprob": -0.08198676904042562, "compression_ratio": 1.528225806451613, "no_speech_prob": 0.01565256342291832}, {"id": 213, "seek": 71200, "start": 717.0, "end": 719.0, "text": " I've just noticed this playground V2.", "tokens": [50614, 286, 600, 445, 5694, 341, 24646, 691, 17, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08198676904042562, "compression_ratio": 1.528225806451613, "no_speech_prob": 0.01565256342291832}, {"id": 214, "seek": 71200, "start": 719.0, "end": 720.0, "text": " I don't know what that is,", "tokens": [50714, 286, 500, 380, 458, 437, 300, 307, 11, 50764], "temperature": 0.0, "avg_logprob": -0.08198676904042562, "compression_ratio": 1.528225806451613, "no_speech_prob": 0.01565256342291832}, {"id": 215, "seek": 71200, "start": 720.0, "end": 722.0, "text": " but you've got a full clawed version in here.", "tokens": [50764, 457, 291, 600, 658, 257, 1577, 32019, 292, 3037, 294, 510, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08198676904042562, "compression_ratio": 1.528225806451613, "no_speech_prob": 0.01565256342291832}, {"id": 216, "seek": 71200, "start": 722.0, "end": 724.0, "text": " I use a couple of my own bots.", "tokens": [50864, 286, 764, 257, 1916, 295, 452, 1065, 35410, 13, 50964], "temperature": 0.0, "avg_logprob": -0.08198676904042562, "compression_ratio": 1.528225806451613, "no_speech_prob": 0.01565256342291832}, {"id": 217, "seek": 71200, "start": 724.0, "end": 728.0, "text": " You've got a different interface to Dolly,", "tokens": [50964, 509, 600, 658, 257, 819, 9226, 281, 1144, 13020, 11, 51164], "temperature": 0.0, "avg_logprob": -0.08198676904042562, "compression_ratio": 1.528225806451613, "no_speech_prob": 0.01565256342291832}, {"id": 218, "seek": 71200, "start": 728.0, "end": 730.0, "text": " all of the chat GPT stuff.", "tokens": [51164, 439, 295, 264, 5081, 26039, 51, 1507, 13, 51264], "temperature": 0.0, "avg_logprob": -0.08198676904042562, "compression_ratio": 1.528225806451613, "no_speech_prob": 0.01565256342291832}, {"id": 219, "seek": 71200, "start": 730.0, "end": 733.0, "text": " I use Google Palm sometimes,", "tokens": [51264, 286, 764, 3329, 32668, 2171, 11, 51414], "temperature": 0.0, "avg_logprob": -0.08198676904042562, "compression_ratio": 1.528225806451613, "no_speech_prob": 0.01565256342291832}, {"id": 220, "seek": 71200, "start": 733.0, "end": 736.0, "text": " and then you get the smaller models here as well.", "tokens": [51414, 293, 550, 291, 483, 264, 4356, 5245, 510, 382, 731, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08198676904042562, "compression_ratio": 1.528225806451613, "no_speech_prob": 0.01565256342291832}, {"id": 221, "seek": 71200, "start": 736.0, "end": 738.0, "text": " I have no affiliation with these guys,", "tokens": [51564, 286, 362, 572, 14863, 399, 365, 613, 1074, 11, 51664], "temperature": 0.0, "avg_logprob": -0.08198676904042562, "compression_ratio": 1.528225806451613, "no_speech_prob": 0.01565256342291832}, {"id": 222, "seek": 73800, "start": 738.0, "end": 742.0, "text": " but I'm pretty happy with paying $20 a month", "tokens": [50364, 457, 286, 478, 1238, 2055, 365, 6229, 1848, 2009, 257, 1618, 50564], "temperature": 0.0, "avg_logprob": -0.12110919467473434, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.05824562534689903}, {"id": 223, "seek": 73800, "start": 742.0, "end": 744.0, "text": " to get access to that for sure.", "tokens": [50564, 281, 483, 2105, 281, 300, 337, 988, 13, 50664], "temperature": 0.0, "avg_logprob": -0.12110919467473434, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.05824562534689903}, {"id": 224, "seek": 73800, "start": 744.0, "end": 747.0, "text": " Hi to Mac and Adelaide, John in New York,", "tokens": [50664, 2421, 281, 5707, 293, 1999, 4053, 482, 11, 2619, 294, 1873, 3609, 11, 50814], "temperature": 0.0, "avg_logprob": -0.12110919467473434, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.05824562534689903}, {"id": 225, "seek": 73800, "start": 747.0, "end": 750.0, "text": " Marky Mark in UK.", "tokens": [50814, 3934, 88, 3934, 294, 7051, 13, 50964], "temperature": 0.0, "avg_logprob": -0.12110919467473434, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.05824562534689903}, {"id": 226, "seek": 73800, "start": 750.0, "end": 751.0, "text": " What else we got?", "tokens": [50964, 708, 1646, 321, 658, 30, 51014], "temperature": 0.0, "avg_logprob": -0.12110919467473434, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.05824562534689903}, {"id": 227, "seek": 73800, "start": 751.0, "end": 754.0, "text": " Andre in Dawson City, Yukon.", "tokens": [51014, 20667, 294, 28407, 3015, 4392, 11, 27975, 266, 13, 51164], "temperature": 0.0, "avg_logprob": -0.12110919467473434, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.05824562534689903}, {"id": 228, "seek": 73800, "start": 754.0, "end": 757.0, "text": " Win some hacks in the UK.", "tokens": [51164, 10427, 512, 33617, 294, 264, 7051, 13, 51314], "temperature": 0.0, "avg_logprob": -0.12110919467473434, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.05824562534689903}, {"id": 229, "seek": 73800, "start": 757.0, "end": 760.0, "text": " And something about Hungary and Slovakia.", "tokens": [51314, 400, 746, 466, 32380, 293, 22497, 43506, 654, 13, 51464], "temperature": 0.0, "avg_logprob": -0.12110919467473434, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.05824562534689903}, {"id": 230, "seek": 73800, "start": 760.0, "end": 762.0, "text": " How can you be in two places at once?", "tokens": [51464, 1012, 393, 291, 312, 294, 732, 3190, 412, 1564, 30, 51564], "temperature": 0.0, "avg_logprob": -0.12110919467473434, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.05824562534689903}, {"id": 231, "seek": 73800, "start": 762.0, "end": 764.0, "text": " How's that possible, Peter?", "tokens": [51564, 1012, 311, 300, 1944, 11, 6508, 30, 51664], "temperature": 0.0, "avg_logprob": -0.12110919467473434, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.05824562534689903}, {"id": 232, "seek": 73800, "start": 764.0, "end": 767.0, "text": " I wanted to play today with open source models", "tokens": [51664, 286, 1415, 281, 862, 965, 365, 1269, 4009, 5245, 51814], "temperature": 0.0, "avg_logprob": -0.12110919467473434, "compression_ratio": 1.4330708661417322, "no_speech_prob": 0.05824562534689903}, {"id": 233, "seek": 76700, "start": 767.0, "end": 769.0, "text": " and what's come out from MetaAI,", "tokens": [50364, 293, 437, 311, 808, 484, 490, 6377, 64, 48698, 11, 50464], "temperature": 0.0, "avg_logprob": -0.0937719960366526, "compression_ratio": 1.64453125, "no_speech_prob": 0.41368383169174194}, {"id": 234, "seek": 76700, "start": 769.0, "end": 771.0, "text": " but we'll be prioritizing questions", "tokens": [50464, 457, 321, 603, 312, 14846, 3319, 1651, 50564], "temperature": 0.0, "avg_logprob": -0.0937719960366526, "compression_ratio": 1.64453125, "no_speech_prob": 0.41368383169174194}, {"id": 235, "seek": 76700, "start": 771.0, "end": 773.0, "text": " because I don't have a huge lineup for today.", "tokens": [50564, 570, 286, 500, 380, 362, 257, 2603, 26461, 337, 965, 13, 50664], "temperature": 0.0, "avg_logprob": -0.0937719960366526, "compression_ratio": 1.64453125, "no_speech_prob": 0.41368383169174194}, {"id": 236, "seek": 76700, "start": 773.0, "end": 776.0, "text": " I don't know if you've seen the seamless expressive stuff", "tokens": [50664, 286, 500, 380, 458, 498, 291, 600, 1612, 264, 28677, 40189, 1507, 50814], "temperature": 0.0, "avg_logprob": -0.0937719960366526, "compression_ratio": 1.64453125, "no_speech_prob": 0.41368383169174194}, {"id": 237, "seek": 76700, "start": 776.0, "end": 779.0, "text": " that came out of MetaAI and seamless together.", "tokens": [50814, 300, 1361, 484, 295, 6377, 64, 48698, 293, 28677, 1214, 13, 50964], "temperature": 0.0, "avg_logprob": -0.0937719960366526, "compression_ratio": 1.64453125, "no_speech_prob": 0.41368383169174194}, {"id": 238, "seek": 76700, "start": 779.0, "end": 782.0, "text": " The technology isn't that impressive.", "tokens": [50964, 440, 2899, 1943, 380, 300, 8992, 13, 51114], "temperature": 0.0, "avg_logprob": -0.0937719960366526, "compression_ratio": 1.64453125, "no_speech_prob": 0.41368383169174194}, {"id": 239, "seek": 76700, "start": 782.0, "end": 786.0, "text": " It's just the fact that the demo is so easy to use", "tokens": [51114, 467, 311, 445, 264, 1186, 300, 264, 10723, 307, 370, 1858, 281, 764, 51314], "temperature": 0.0, "avg_logprob": -0.0937719960366526, "compression_ratio": 1.64453125, "no_speech_prob": 0.41368383169174194}, {"id": 240, "seek": 76700, "start": 786.0, "end": 789.0, "text": " that I thought, let's get it plugged in.", "tokens": [51314, 300, 286, 1194, 11, 718, 311, 483, 309, 25679, 294, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0937719960366526, "compression_ratio": 1.64453125, "no_speech_prob": 0.41368383169174194}, {"id": 241, "seek": 76700, "start": 789.0, "end": 791.0, "text": " The link is in the description of this video,", "tokens": [51464, 440, 2113, 307, 294, 264, 3855, 295, 341, 960, 11, 51564], "temperature": 0.0, "avg_logprob": -0.0937719960366526, "compression_ratio": 1.64453125, "no_speech_prob": 0.41368383169174194}, {"id": 242, "seek": 76700, "start": 791.0, "end": 794.0, "text": " seamless.metademolab.com.", "tokens": [51564, 28677, 13, 5537, 64, 10730, 401, 455, 13, 1112, 13, 51714], "temperature": 0.0, "avg_logprob": -0.0937719960366526, "compression_ratio": 1.64453125, "no_speech_prob": 0.41368383169174194}, {"id": 243, "seek": 79400, "start": 794.0, "end": 796.0, "text": " There's so much expressive,", "tokens": [50364, 821, 311, 370, 709, 40189, 11, 50464], "temperature": 0.0, "avg_logprob": -0.18384903448599357, "compression_ratio": 1.5361216730038023, "no_speech_prob": 0.3510480523109436}, {"id": 244, "seek": 79400, "start": 796.0, "end": 799.0, "text": " couple of little notes before we even jump in there.", "tokens": [50464, 1916, 295, 707, 5570, 949, 321, 754, 3012, 294, 456, 13, 50614], "temperature": 0.0, "avg_logprob": -0.18384903448599357, "compression_ratio": 1.5361216730038023, "no_speech_prob": 0.3510480523109436}, {"id": 245, "seek": 79400, "start": 799.0, "end": 801.0, "text": " You know that you like to learn something new every day,", "tokens": [50614, 509, 458, 300, 291, 411, 281, 1466, 746, 777, 633, 786, 11, 50714], "temperature": 0.0, "avg_logprob": -0.18384903448599357, "compression_ratio": 1.5361216730038023, "no_speech_prob": 0.3510480523109436}, {"id": 246, "seek": 79400, "start": 801.0, "end": 803.0, "text": " or maybe you already know this.", "tokens": [50714, 420, 1310, 291, 1217, 458, 341, 13, 50814], "temperature": 0.0, "avg_logprob": -0.18384903448599357, "compression_ratio": 1.5361216730038023, "no_speech_prob": 0.3510480523109436}, {"id": 247, "seek": 79400, "start": 803.0, "end": 808.0, "text": " Language, linguistics, talk about this SVO, SOV,", "tokens": [50814, 24445, 11, 21766, 6006, 11, 751, 466, 341, 318, 20664, 11, 10621, 53, 11, 51064], "temperature": 0.0, "avg_logprob": -0.18384903448599357, "compression_ratio": 1.5361216730038023, "no_speech_prob": 0.3510480523109436}, {"id": 248, "seek": 79400, "start": 808.0, "end": 811.0, "text": " and there's actually a couple of other ones.", "tokens": [51064, 293, 456, 311, 767, 257, 1916, 295, 661, 2306, 13, 51214], "temperature": 0.0, "avg_logprob": -0.18384903448599357, "compression_ratio": 1.5361216730038023, "no_speech_prob": 0.3510480523109436}, {"id": 249, "seek": 79400, "start": 811.0, "end": 813.0, "text": " In the seamless expressive demo,", "tokens": [51214, 682, 264, 28677, 40189, 10723, 11, 51314], "temperature": 0.0, "avg_logprob": -0.18384903448599357, "compression_ratio": 1.5361216730038023, "no_speech_prob": 0.3510480523109436}, {"id": 250, "seek": 79400, "start": 813.0, "end": 818.0, "text": " they're only using two, sorry, four different languages,", "tokens": [51314, 436, 434, 787, 1228, 732, 11, 2597, 11, 1451, 819, 8650, 11, 51564], "temperature": 0.0, "avg_logprob": -0.18384903448599357, "compression_ratio": 1.5361216730038023, "no_speech_prob": 0.3510480523109436}, {"id": 251, "seek": 79400, "start": 818.0, "end": 822.0, "text": " three besides English, Spanish, French and German,", "tokens": [51564, 1045, 11868, 3669, 11, 8058, 11, 5522, 293, 6521, 11, 51764], "temperature": 0.0, "avg_logprob": -0.18384903448599357, "compression_ratio": 1.5361216730038023, "no_speech_prob": 0.3510480523109436}, {"id": 252, "seek": 82200, "start": 822.0, "end": 824.0, "text": " and these align with SVO.", "tokens": [50364, 293, 613, 7975, 365, 318, 20664, 13, 50464], "temperature": 0.0, "avg_logprob": -0.09835315667665921, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.007572404108941555}, {"id": 253, "seek": 82200, "start": 824.0, "end": 828.0, "text": " Spanish is here, French is here, and German is here.", "tokens": [50464, 8058, 307, 510, 11, 5522, 307, 510, 11, 293, 6521, 307, 510, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09835315667665921, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.007572404108941555}, {"id": 254, "seek": 82200, "start": 828.0, "end": 832.0, "text": " So they're all subject, verb, object.", "tokens": [50664, 407, 436, 434, 439, 3983, 11, 9595, 11, 2657, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09835315667665921, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.007572404108941555}, {"id": 255, "seek": 82200, "start": 832.0, "end": 835.0, "text": " When we get into funky languages like Japanese and Korean,", "tokens": [50864, 1133, 321, 483, 666, 33499, 8650, 411, 5433, 293, 6933, 11, 51014], "temperature": 0.0, "avg_logprob": -0.09835315667665921, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.007572404108941555}, {"id": 256, "seek": 82200, "start": 835.0, "end": 837.0, "text": " they become subject, object, verb.", "tokens": [51014, 436, 1813, 3983, 11, 2657, 11, 9595, 13, 51114], "temperature": 0.0, "avg_logprob": -0.09835315667665921, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.007572404108941555}, {"id": 257, "seek": 82200, "start": 837.0, "end": 840.0, "text": " So you kind of sound a little bit like Yoda", "tokens": [51114, 407, 291, 733, 295, 1626, 257, 707, 857, 411, 48697, 51264], "temperature": 0.0, "avg_logprob": -0.09835315667665921, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.007572404108941555}, {"id": 258, "seek": 82200, "start": 840.0, "end": 844.0, "text": " and Arabic, they're verb, subject, object,", "tokens": [51264, 293, 19938, 11, 436, 434, 9595, 11, 3983, 11, 2657, 11, 51464], "temperature": 0.0, "avg_logprob": -0.09835315667665921, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.007572404108941555}, {"id": 259, "seek": 82200, "start": 844.0, "end": 846.0, "text": " and you go even further.", "tokens": [51464, 293, 291, 352, 754, 3052, 13, 51564], "temperature": 0.0, "avg_logprob": -0.09835315667665921, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.007572404108941555}, {"id": 260, "seek": 82200, "start": 846.0, "end": 848.0, "text": " This is a screencap from Wikipedia.", "tokens": [51564, 639, 307, 257, 2568, 9485, 490, 28999, 13, 51664], "temperature": 0.0, "avg_logprob": -0.09835315667665921, "compression_ratio": 1.6053811659192825, "no_speech_prob": 0.007572404108941555}, {"id": 261, "seek": 84800, "start": 848.0, "end": 852.0, "text": " There's even a complete reversal of this.", "tokens": [50364, 821, 311, 754, 257, 3566, 42778, 295, 341, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08885379829029046, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.034087277948856354}, {"id": 262, "seek": 84800, "start": 852.0, "end": 859.0, "text": " V-O-S, a reversal of English here, SVO to O-V-S,", "tokens": [50564, 691, 12, 46, 12, 50, 11, 257, 42778, 295, 3669, 510, 11, 318, 20664, 281, 422, 12, 53, 12, 50, 11, 50914], "temperature": 0.0, "avg_logprob": -0.08885379829029046, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.034087277948856354}, {"id": 263, "seek": 84800, "start": 859.0, "end": 863.0, "text": " and even OSV, just completely jumbling things up.", "tokens": [50914, 293, 754, 12731, 53, 11, 445, 2584, 361, 14188, 721, 493, 13, 51114], "temperature": 0.0, "avg_logprob": -0.08885379829029046, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.034087277948856354}, {"id": 264, "seek": 84800, "start": 863.0, "end": 865.0, "text": " When it comes to translation of language,", "tokens": [51114, 1133, 309, 1487, 281, 12853, 295, 2856, 11, 51214], "temperature": 0.0, "avg_logprob": -0.08885379829029046, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.034087277948856354}, {"id": 265, "seek": 84800, "start": 865.0, "end": 867.0, "text": " especially live translation,", "tokens": [51214, 2318, 1621, 12853, 11, 51314], "temperature": 0.0, "avg_logprob": -0.08885379829029046, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.034087277948856354}, {"id": 266, "seek": 84800, "start": 867.0, "end": 872.0, "text": " I'd just love to see what it does in converting this.", "tokens": [51314, 286, 1116, 445, 959, 281, 536, 437, 309, 775, 294, 29942, 341, 13, 51564], "temperature": 0.0, "avg_logprob": -0.08885379829029046, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.034087277948856354}, {"id": 267, "seek": 84800, "start": 872.0, "end": 874.0, "text": " Obviously Google Translate has been doing this", "tokens": [51564, 7580, 3329, 6531, 17593, 575, 668, 884, 341, 51664], "temperature": 0.0, "avg_logprob": -0.08885379829029046, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.034087277948856354}, {"id": 268, "seek": 84800, "start": 874.0, "end": 875.0, "text": " for a very, very long time.", "tokens": [51664, 337, 257, 588, 11, 588, 938, 565, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08885379829029046, "compression_ratio": 1.5813953488372092, "no_speech_prob": 0.034087277948856354}, {"id": 269, "seek": 87500, "start": 875.0, "end": 878.0, "text": " There are a couple of other big translation pieces", "tokens": [50364, 821, 366, 257, 1916, 295, 661, 955, 12853, 3755, 50514], "temperature": 0.0, "avg_logprob": -0.0649651879245795, "compression_ratio": 1.532, "no_speech_prob": 0.019116021692752838}, {"id": 270, "seek": 87500, "start": 878.0, "end": 881.0, "text": " that I would recommend above Google Translate,", "tokens": [50514, 300, 286, 576, 2748, 3673, 3329, 6531, 17593, 11, 50664], "temperature": 0.0, "avg_logprob": -0.0649651879245795, "compression_ratio": 1.532, "no_speech_prob": 0.019116021692752838}, {"id": 271, "seek": 87500, "start": 881.0, "end": 883.0, "text": " but when it comes to getting the mouth movements,", "tokens": [50664, 457, 562, 309, 1487, 281, 1242, 264, 4525, 9981, 11, 50764], "temperature": 0.0, "avg_logprob": -0.0649651879245795, "compression_ratio": 1.532, "no_speech_prob": 0.019116021692752838}, {"id": 272, "seek": 87500, "start": 883.0, "end": 885.0, "text": " I thought that would be particularly funky.", "tokens": [50764, 286, 1194, 300, 576, 312, 4098, 33499, 13, 50864], "temperature": 0.0, "avg_logprob": -0.0649651879245795, "compression_ratio": 1.532, "no_speech_prob": 0.019116021692752838}, {"id": 273, "seek": 87500, "start": 885.0, "end": 888.0, "text": " So I'm going to speak in English here in the demo.", "tokens": [50864, 407, 286, 478, 516, 281, 1710, 294, 3669, 510, 294, 264, 10723, 13, 51014], "temperature": 0.0, "avg_logprob": -0.0649651879245795, "compression_ratio": 1.532, "no_speech_prob": 0.019116021692752838}, {"id": 274, "seek": 87500, "start": 888.0, "end": 894.0, "text": " Let's push it to German sounds funky.", "tokens": [51014, 961, 311, 2944, 309, 281, 6521, 3263, 33499, 13, 51314], "temperature": 0.0, "avg_logprob": -0.0649651879245795, "compression_ratio": 1.532, "no_speech_prob": 0.019116021692752838}, {"id": 275, "seek": 87500, "start": 894.0, "end": 897.0, "text": " Oh, there I am.", "tokens": [51314, 876, 11, 456, 286, 669, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0649651879245795, "compression_ratio": 1.532, "no_speech_prob": 0.019116021692752838}, {"id": 276, "seek": 87500, "start": 897.0, "end": 900.0, "text": " And we can ask it whatever question we like,", "tokens": [51464, 400, 321, 393, 1029, 309, 2035, 1168, 321, 411, 11, 51614], "temperature": 0.0, "avg_logprob": -0.0649651879245795, "compression_ratio": 1.532, "no_speech_prob": 0.019116021692752838}, {"id": 277, "seek": 87500, "start": 900.0, "end": 902.0, "text": " and it will have a go at translating this", "tokens": [51614, 293, 309, 486, 362, 257, 352, 412, 35030, 341, 51714], "temperature": 0.0, "avg_logprob": -0.0649651879245795, "compression_ratio": 1.532, "no_speech_prob": 0.019116021692752838}, {"id": 278, "seek": 90200, "start": 902.0, "end": 906.0, "text": " from, in this case, English to German live.", "tokens": [50364, 490, 11, 294, 341, 1389, 11, 3669, 281, 6521, 1621, 13, 50564], "temperature": 0.0, "avg_logprob": -0.05312367677688599, "compression_ratio": 1.4715909090909092, "no_speech_prob": 0.020319905132055283}, {"id": 279, "seek": 90200, "start": 906.0, "end": 910.0, "text": " I don't think it'll do the math.", "tokens": [50564, 286, 500, 380, 519, 309, 603, 360, 264, 5221, 13, 50764], "temperature": 0.0, "avg_logprob": -0.05312367677688599, "compression_ratio": 1.4715909090909092, "no_speech_prob": 0.020319905132055283}, {"id": 280, "seek": 90200, "start": 910.0, "end": 913.0, "text": " We'll give that just a moment to generate for us", "tokens": [50764, 492, 603, 976, 300, 445, 257, 1623, 281, 8460, 337, 505, 50914], "temperature": 0.0, "avg_logprob": -0.05312367677688599, "compression_ratio": 1.4715909090909092, "no_speech_prob": 0.020319905132055283}, {"id": 281, "seek": 90200, "start": 913.0, "end": 916.0, "text": " and we'll get a playback for us there.", "tokens": [50914, 293, 321, 603, 483, 257, 37223, 337, 505, 456, 13, 51064], "temperature": 0.0, "avg_logprob": -0.05312367677688599, "compression_ratio": 1.4715909090909092, "no_speech_prob": 0.020319905132055283}, {"id": 282, "seek": 90200, "start": 916.0, "end": 920.0, "text": " Here we go.", "tokens": [51064, 1692, 321, 352, 13, 51264], "temperature": 0.0, "avg_logprob": -0.05312367677688599, "compression_ratio": 1.4715909090909092, "no_speech_prob": 0.020319905132055283}, {"id": 283, "seek": 90200, "start": 920.0, "end": 929.0, "text": " I want to actually see the video.", "tokens": [51264, 286, 528, 281, 767, 536, 264, 960, 13, 51714], "temperature": 0.0, "avg_logprob": -0.05312367677688599, "compression_ratio": 1.4715909090909092, "no_speech_prob": 0.020319905132055283}, {"id": 284, "seek": 90200, "start": 929.0, "end": 931.0, "text": " Encourage you to play around with this yourself.", "tokens": [51714, 29584, 44720, 291, 281, 862, 926, 365, 341, 1803, 13, 51814], "temperature": 0.0, "avg_logprob": -0.05312367677688599, "compression_ratio": 1.4715909090909092, "no_speech_prob": 0.020319905132055283}, {"id": 285, "seek": 93100, "start": 931.0, "end": 936.0, "text": " I like the fact that I can just send this to a family member", "tokens": [50364, 286, 411, 264, 1186, 300, 286, 393, 445, 2845, 341, 281, 257, 1605, 4006, 50614], "temperature": 0.0, "avg_logprob": -0.0684303311468328, "compression_ratio": 1.56, "no_speech_prob": 0.13394653797149658}, {"id": 286, "seek": 93100, "start": 936.0, "end": 939.0, "text": " or someone who doesn't have any experience with AI.", "tokens": [50614, 420, 1580, 567, 1177, 380, 362, 604, 1752, 365, 7318, 13, 50764], "temperature": 0.0, "avg_logprob": -0.0684303311468328, "compression_ratio": 1.56, "no_speech_prob": 0.13394653797149658}, {"id": 287, "seek": 93100, "start": 939.0, "end": 941.0, "text": " Obviously it gets super technical under the hood.", "tokens": [50764, 7580, 309, 2170, 1687, 6191, 833, 264, 13376, 13, 50864], "temperature": 0.0, "avg_logprob": -0.0684303311468328, "compression_ratio": 1.56, "no_speech_prob": 0.13394653797149658}, {"id": 288, "seek": 93100, "start": 941.0, "end": 945.0, "text": " There's an entire paper here that runs you through", "tokens": [50864, 821, 311, 364, 2302, 3035, 510, 300, 6676, 291, 807, 51064], "temperature": 0.0, "avg_logprob": -0.0684303311468328, "compression_ratio": 1.56, "no_speech_prob": 0.13394653797149658}, {"id": 289, "seek": 93100, "start": 945.0, "end": 947.0, "text": " what's actually happening,", "tokens": [51064, 437, 311, 767, 2737, 11, 51164], "temperature": 0.0, "avg_logprob": -0.0684303311468328, "compression_ratio": 1.56, "no_speech_prob": 0.13394653797149658}, {"id": 290, "seek": 93100, "start": 947.0, "end": 951.0, "text": " but for today, just seeing what's possible.", "tokens": [51164, 457, 337, 965, 11, 445, 2577, 437, 311, 1944, 13, 51364], "temperature": 0.0, "avg_logprob": -0.0684303311468328, "compression_ratio": 1.56, "no_speech_prob": 0.13394653797149658}, {"id": 291, "seek": 93100, "start": 951.0, "end": 952.0, "text": " Here's a playback.", "tokens": [51364, 1692, 311, 257, 37223, 13, 51414], "temperature": 0.0, "avg_logprob": -0.0684303311468328, "compression_ratio": 1.56, "no_speech_prob": 0.13394653797149658}, {"id": 292, "seek": 93100, "start": 952.0, "end": 955.0, "text": " And we can ask it whatever question we like,", "tokens": [51414, 400, 321, 393, 1029, 309, 2035, 1168, 321, 411, 11, 51564], "temperature": 0.0, "avg_logprob": -0.0684303311468328, "compression_ratio": 1.56, "no_speech_prob": 0.13394653797149658}, {"id": 293, "seek": 93100, "start": 955.0, "end": 957.0, "text": " and it will have a go at translating this", "tokens": [51564, 293, 309, 486, 362, 257, 352, 412, 35030, 341, 51664], "temperature": 0.0, "avg_logprob": -0.0684303311468328, "compression_ratio": 1.56, "no_speech_prob": 0.13394653797149658}, {"id": 294, "seek": 95700, "start": 957.0, "end": 961.0, "text": " from, in this case, English to German live.", "tokens": [50364, 490, 11, 294, 341, 1389, 11, 3669, 281, 6521, 1621, 13, 50564], "temperature": 0.0, "avg_logprob": -0.13016075134277344, "compression_ratio": 1.6683673469387754, "no_speech_prob": 0.08861245214939117}, {"id": 295, "seek": 95700, "start": 961.0, "end": 963.0, "text": " I don't think it'll do the math.", "tokens": [50564, 286, 500, 380, 519, 309, 603, 360, 264, 5221, 13, 50664], "temperature": 0.0, "avg_logprob": -0.13016075134277344, "compression_ratio": 1.6683673469387754, "no_speech_prob": 0.08861245214939117}, {"id": 296, "seek": 95700, "start": 963.0, "end": 965.0, "text": " And we can ask it whatever question we like,", "tokens": [50664, 400, 321, 393, 1029, 309, 2035, 1168, 321, 411, 11, 50764], "temperature": 0.0, "avg_logprob": -0.13016075134277344, "compression_ratio": 1.6683673469387754, "no_speech_prob": 0.08861245214939117}, {"id": 297, "seek": 95700, "start": 965.0, "end": 967.0, "text": " and it will have a go at translating this", "tokens": [50764, 293, 309, 486, 362, 257, 352, 412, 35030, 341, 50864], "temperature": 0.0, "avg_logprob": -0.13016075134277344, "compression_ratio": 1.6683673469387754, "no_speech_prob": 0.08861245214939117}, {"id": 298, "seek": 95700, "start": 967.0, "end": 970.0, "text": " from English live to German live.", "tokens": [50864, 490, 3669, 1621, 281, 6521, 1621, 13, 51014], "temperature": 0.0, "avg_logprob": -0.13016075134277344, "compression_ratio": 1.6683673469387754, "no_speech_prob": 0.08861245214939117}, {"id": 299, "seek": 95700, "start": 970.0, "end": 974.0, "text": " I don't think it'll do the math.", "tokens": [51014, 286, 500, 380, 519, 309, 603, 360, 264, 5221, 13, 51214], "temperature": 0.0, "avg_logprob": -0.13016075134277344, "compression_ratio": 1.6683673469387754, "no_speech_prob": 0.08861245214939117}, {"id": 300, "seek": 95700, "start": 974.0, "end": 979.0, "text": " That's crazy.", "tokens": [51214, 663, 311, 3219, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13016075134277344, "compression_ratio": 1.6683673469387754, "no_speech_prob": 0.08861245214939117}, {"id": 301, "seek": 95700, "start": 979.0, "end": 981.0, "text": " I hope the audio worked there for you", "tokens": [51464, 286, 1454, 264, 6278, 2732, 456, 337, 291, 51564], "temperature": 0.0, "avg_logprob": -0.13016075134277344, "compression_ratio": 1.6683673469387754, "no_speech_prob": 0.08861245214939117}, {"id": 302, "seek": 95700, "start": 981.0, "end": 984.0, "text": " because in my testing it did, but who knows?", "tokens": [51564, 570, 294, 452, 4997, 309, 630, 11, 457, 567, 3255, 30, 51714], "temperature": 0.0, "avg_logprob": -0.13016075134277344, "compression_ratio": 1.6683673469387754, "no_speech_prob": 0.08861245214939117}, {"id": 303, "seek": 98400, "start": 984.0, "end": 988.0, "text": " Let's do a French one.", "tokens": [50364, 961, 311, 360, 257, 5522, 472, 13, 50564], "temperature": 0.0, "avg_logprob": -0.08536971784105488, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.05026305466890335}, {"id": 304, "seek": 98400, "start": 988.0, "end": 990.0, "text": " I don't know what these are.", "tokens": [50564, 286, 500, 380, 458, 437, 613, 366, 13, 50664], "temperature": 0.0, "avg_logprob": -0.08536971784105488, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.05026305466890335}, {"id": 305, "seek": 98400, "start": 990.0, "end": 991.0, "text": " Oh, I see.", "tokens": [50664, 876, 11, 286, 536, 13, 50714], "temperature": 0.0, "avg_logprob": -0.08536971784105488, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.05026305466890335}, {"id": 306, "seek": 98400, "start": 991.0, "end": 993.0, "text": " So you could whisper it and it'll try and translate it.", "tokens": [50714, 407, 291, 727, 26018, 309, 293, 309, 603, 853, 293, 13799, 309, 13, 50814], "temperature": 0.0, "avg_logprob": -0.08536971784105488, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.05026305466890335}, {"id": 307, "seek": 98400, "start": 993.0, "end": 994.0, "text": " Let's give this a go.", "tokens": [50814, 961, 311, 976, 341, 257, 352, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08536971784105488, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.05026305466890335}, {"id": 308, "seek": 98400, "start": 994.0, "end": 998.0, "text": " I haven't tried this before, but let's see what it does.", "tokens": [50864, 286, 2378, 380, 3031, 341, 949, 11, 457, 718, 311, 536, 437, 309, 775, 13, 51064], "temperature": 0.0, "avg_logprob": -0.08536971784105488, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.05026305466890335}, {"id": 309, "seek": 98400, "start": 998.0, "end": 1001.0, "text": " This is a French translation.", "tokens": [51064, 639, 307, 257, 5522, 12853, 13, 51214], "temperature": 0.0, "avg_logprob": -0.08536971784105488, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.05026305466890335}, {"id": 310, "seek": 98400, "start": 1001.0, "end": 1005.0, "text": " Let's say hi to Ben, hi to Sabine in Vienna,", "tokens": [51214, 961, 311, 584, 4879, 281, 3964, 11, 4879, 281, 13915, 533, 294, 31024, 11, 51414], "temperature": 0.0, "avg_logprob": -0.08536971784105488, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.05026305466890335}, {"id": 311, "seek": 98400, "start": 1005.0, "end": 1011.0, "text": " and see what it can do.", "tokens": [51414, 293, 536, 437, 309, 393, 360, 13, 51714], "temperature": 0.0, "avg_logprob": -0.08536971784105488, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.05026305466890335}, {"id": 312, "seek": 101100, "start": 1011.0, "end": 1015.0, "text": " As I mentioned, the paper is a big technical read.", "tokens": [50364, 1018, 286, 2835, 11, 264, 3035, 307, 257, 955, 6191, 1401, 13, 50564], "temperature": 0.0, "avg_logprob": -0.14201454162597657, "compression_ratio": 1.478448275862069, "no_speech_prob": 0.08609730005264282}, {"id": 313, "seek": 101100, "start": 1015.0, "end": 1016.0, "text": " There's the MetaGuys.", "tokens": [50564, 821, 311, 264, 6377, 64, 25627, 749, 13, 50614], "temperature": 0.0, "avg_logprob": -0.14201454162597657, "compression_ratio": 1.478448275862069, "no_speech_prob": 0.08609730005264282}, {"id": 314, "seek": 101100, "start": 1016.0, "end": 1018.0, "text": " You see Berkeley involved as well,", "tokens": [50614, 509, 536, 23684, 3288, 382, 731, 11, 50714], "temperature": 0.0, "avg_logprob": -0.14201454162597657, "compression_ratio": 1.478448275862069, "no_speech_prob": 0.08609730005264282}, {"id": 315, "seek": 101100, "start": 1018.0, "end": 1023.0, "text": " but they talk about how they move from multimodal machine", "tokens": [50714, 457, 436, 751, 466, 577, 436, 1286, 490, 32972, 378, 304, 3479, 50964], "temperature": 0.0, "avg_logprob": -0.14201454162597657, "compression_ratio": 1.478448275862069, "no_speech_prob": 0.08609730005264282}, {"id": 316, "seek": 101100, "start": 1023.0, "end": 1027.0, "text": " translation using, I believe they use BERT,", "tokens": [50964, 12853, 1228, 11, 286, 1697, 436, 764, 363, 31479, 11, 51164], "temperature": 0.0, "avg_logprob": -0.14201454162597657, "compression_ratio": 1.478448275862069, "no_speech_prob": 0.08609730005264282}, {"id": 317, "seek": 101100, "start": 1027.0, "end": 1032.0, "text": " but to get it through to live audio is just fascinating,", "tokens": [51164, 457, 281, 483, 309, 807, 281, 1621, 6278, 307, 445, 10343, 11, 51414], "temperature": 0.0, "avg_logprob": -0.14201454162597657, "compression_ratio": 1.478448275862069, "no_speech_prob": 0.08609730005264282}, {"id": 318, "seek": 101100, "start": 1032.0, "end": 1033.0, "text": " really fascinating.", "tokens": [51414, 534, 10343, 13, 51464], "temperature": 0.0, "avg_logprob": -0.14201454162597657, "compression_ratio": 1.478448275862069, "no_speech_prob": 0.08609730005264282}, {"id": 319, "seek": 101100, "start": 1033.0, "end": 1035.0, "text": " Long paper, 111 pages.", "tokens": [51464, 8282, 3035, 11, 2975, 16, 7183, 13, 51564], "temperature": 0.0, "avg_logprob": -0.14201454162597657, "compression_ratio": 1.478448275862069, "no_speech_prob": 0.08609730005264282}, {"id": 320, "seek": 101100, "start": 1035.0, "end": 1040.0, "text": " You can feed this through po.com.", "tokens": [51564, 509, 393, 3154, 341, 807, 714, 13, 1112, 13, 51814], "temperature": 0.0, "avg_logprob": -0.14201454162597657, "compression_ratio": 1.478448275862069, "no_speech_prob": 0.08609730005264282}, {"id": 321, "seek": 104000, "start": 1040.0, "end": 1042.0, "text": " So you could actually use, where is it?", "tokens": [50364, 407, 291, 727, 767, 764, 11, 689, 307, 309, 30, 50464], "temperature": 0.0, "avg_logprob": -0.12358261290050689, "compression_ratio": 1.4366812227074235, "no_speech_prob": 0.0029805684462189674}, {"id": 322, "seek": 104000, "start": 1042.0, "end": 1043.0, "text": " Claude2 here.", "tokens": [50464, 12947, 2303, 17, 510, 13, 50514], "temperature": 0.0, "avg_logprob": -0.12358261290050689, "compression_ratio": 1.4366812227074235, "no_speech_prob": 0.0029805684462189674}, {"id": 323, "seek": 104000, "start": 1043.0, "end": 1047.0, "text": " Let's attach this paper in.", "tokens": [50514, 961, 311, 5085, 341, 3035, 294, 13, 50714], "temperature": 0.0, "avg_logprob": -0.12358261290050689, "compression_ratio": 1.4366812227074235, "no_speech_prob": 0.0029805684462189674}, {"id": 324, "seek": 104000, "start": 1047.0, "end": 1052.0, "text": " Give me the top three findings from this,", "tokens": [50714, 5303, 385, 264, 1192, 1045, 16483, 490, 341, 11, 50964], "temperature": 0.0, "avg_logprob": -0.12358261290050689, "compression_ratio": 1.4366812227074235, "no_speech_prob": 0.0029805684462189674}, {"id": 325, "seek": 104000, "start": 1052.0, "end": 1055.0, "text": " including which base models they use.", "tokens": [50964, 3009, 597, 3096, 5245, 436, 764, 13, 51114], "temperature": 0.0, "avg_logprob": -0.12358261290050689, "compression_ratio": 1.4366812227074235, "no_speech_prob": 0.0029805684462189674}, {"id": 326, "seek": 104000, "start": 1055.0, "end": 1059.0, "text": " And it'll go and read that 111 page paper.", "tokens": [51114, 400, 309, 603, 352, 293, 1401, 300, 2975, 16, 3028, 3035, 13, 51314], "temperature": 0.0, "avg_logprob": -0.12358261290050689, "compression_ratio": 1.4366812227074235, "no_speech_prob": 0.0029805684462189674}, {"id": 327, "seek": 104000, "start": 1059.0, "end": 1063.0, "text": " Hopefully less than 75,000 words and answer my prompt.", "tokens": [51314, 10429, 1570, 813, 9562, 11, 1360, 2283, 293, 1867, 452, 12391, 13, 51514], "temperature": 0.0, "avg_logprob": -0.12358261290050689, "compression_ratio": 1.4366812227074235, "no_speech_prob": 0.0029805684462189674}, {"id": 328, "seek": 104000, "start": 1063.0, "end": 1065.0, "text": " We'll come back to that in a second.", "tokens": [51514, 492, 603, 808, 646, 281, 300, 294, 257, 1150, 13, 51614], "temperature": 0.0, "avg_logprob": -0.12358261290050689, "compression_ratio": 1.4366812227074235, "no_speech_prob": 0.0029805684462189674}, {"id": 329, "seek": 104000, "start": 1065.0, "end": 1067.0, "text": " Let's see my video.", "tokens": [51614, 961, 311, 536, 452, 960, 13, 51714], "temperature": 0.0, "avg_logprob": -0.12358261290050689, "compression_ratio": 1.4366812227074235, "no_speech_prob": 0.0029805684462189674}, {"id": 330, "seek": 104000, "start": 1067.0, "end": 1069.0, "text": " Oh, come on.", "tokens": [51714, 876, 11, 808, 322, 13, 51814], "temperature": 0.0, "avg_logprob": -0.12358261290050689, "compression_ratio": 1.4366812227074235, "no_speech_prob": 0.0029805684462189674}, {"id": 331, "seek": 106900, "start": 1069.0, "end": 1075.0, "text": " The wonders of live stream.", "tokens": [50364, 440, 27348, 295, 1621, 4309, 13, 50664], "temperature": 0.0, "avg_logprob": -0.12285992758614676, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.038386452943086624}, {"id": 332, "seek": 106900, "start": 1075.0, "end": 1077.0, "text": " Awesome.", "tokens": [50664, 10391, 13, 50764], "temperature": 0.0, "avg_logprob": -0.12285992758614676, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.038386452943086624}, {"id": 333, "seek": 106900, "start": 1077.0, "end": 1080.0, "text": " Definitely, definitely encourage you to try that out yourself", "tokens": [50764, 12151, 11, 2138, 5373, 291, 281, 853, 300, 484, 1803, 50914], "temperature": 0.0, "avg_logprob": -0.12285992758614676, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.038386452943086624}, {"id": 334, "seek": 106900, "start": 1080.0, "end": 1085.0, "text": " because it's always fun being able to see something like", "tokens": [50914, 570, 309, 311, 1009, 1019, 885, 1075, 281, 536, 746, 411, 51164], "temperature": 0.0, "avg_logprob": -0.12285992758614676, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.038386452943086624}, {"id": 335, "seek": 106900, "start": 1085.0, "end": 1088.0, "text": " originally speaking English and then having that converted", "tokens": [51164, 7993, 4124, 3669, 293, 550, 1419, 300, 16424, 51314], "temperature": 0.0, "avg_logprob": -0.12285992758614676, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.038386452943086624}, {"id": 336, "seek": 106900, "start": 1088.0, "end": 1094.0, "text": " to the poetry and magic of a romance language like French.", "tokens": [51314, 281, 264, 15155, 293, 5585, 295, 257, 19064, 2856, 411, 5522, 13, 51614], "temperature": 0.0, "avg_logprob": -0.12285992758614676, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.038386452943086624}, {"id": 337, "seek": 106900, "start": 1094.0, "end": 1098.0, "text": " Give that a go.", "tokens": [51614, 5303, 300, 257, 352, 13, 51814], "temperature": 0.0, "avg_logprob": -0.12285992758614676, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.038386452943086624}, {"id": 338, "seek": 109800, "start": 1098.0, "end": 1115.0, "text": " Andres has a cool point for us here.", "tokens": [50364, 400, 495, 575, 257, 1627, 935, 337, 505, 510, 13, 51214], "temperature": 0.0, "avg_logprob": -0.12406478104767976, "compression_ratio": 1.463235294117647, "no_speech_prob": 0.016139226034283638}, {"id": 339, "seek": 109800, "start": 1115.0, "end": 1118.0, "text": " I can imagine this being something that's very,", "tokens": [51214, 286, 393, 3811, 341, 885, 746, 300, 311, 588, 11, 51364], "temperature": 0.0, "avg_logprob": -0.12406478104767976, "compression_ratio": 1.463235294117647, "no_speech_prob": 0.016139226034283638}, {"id": 340, "seek": 109800, "start": 1118.0, "end": 1122.0, "text": " very fast converting movies to the language that you want", "tokens": [51364, 588, 2370, 29942, 6233, 281, 264, 2856, 300, 291, 528, 51564], "temperature": 0.0, "avg_logprob": -0.12406478104767976, "compression_ratio": 1.463235294117647, "no_speech_prob": 0.016139226034283638}, {"id": 341, "seek": 109800, "start": 1122.0, "end": 1126.0, "text": " to speak it and keeping the, that you want to hear it in", "tokens": [51564, 281, 1710, 309, 293, 5145, 264, 11, 300, 291, 528, 281, 1568, 309, 294, 51764], "temperature": 0.0, "avg_logprob": -0.12406478104767976, "compression_ratio": 1.463235294117647, "no_speech_prob": 0.016139226034283638}, {"id": 342, "seek": 112600, "start": 1127.0, "end": 1130.0, "text": " keeping the expression, keeping the articulation", "tokens": [50414, 5145, 264, 6114, 11, 5145, 264, 15228, 2776, 50564], "temperature": 0.0, "avg_logprob": -0.14378721063787286, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.10572734475135803}, {"id": 343, "seek": 112600, "start": 1130.0, "end": 1136.0, "text": " and the original nuance of whatever tone the actors have used", "tokens": [50564, 293, 264, 3380, 42625, 295, 2035, 8027, 264, 10037, 362, 1143, 50864], "temperature": 0.0, "avg_logprob": -0.14378721063787286, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.10572734475135803}, {"id": 344, "seek": 112600, "start": 1136.0, "end": 1137.0, "text": " to deliver that.", "tokens": [50864, 281, 4239, 300, 13, 50914], "temperature": 0.0, "avg_logprob": -0.14378721063787286, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.10572734475135803}, {"id": 345, "seek": 112600, "start": 1137.0, "end": 1138.0, "text": " Here's my French example.", "tokens": [50914, 1692, 311, 452, 5522, 1365, 13, 50964], "temperature": 0.0, "avg_logprob": -0.14378721063787286, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.10572734475135803}, {"id": 346, "seek": 112600, "start": 1138.0, "end": 1141.0, "text": " Like originally speaking English and then having that", "tokens": [50964, 1743, 7993, 4124, 3669, 293, 550, 1419, 300, 51114], "temperature": 0.0, "avg_logprob": -0.14378721063787286, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.10572734475135803}, {"id": 347, "seek": 112600, "start": 1141.0, "end": 1146.0, "text": " converted to the poetry and magic of a romance language", "tokens": [51114, 16424, 281, 264, 15155, 293, 5585, 295, 257, 19064, 2856, 51364], "temperature": 0.0, "avg_logprob": -0.14378721063787286, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.10572734475135803}, {"id": 348, "seek": 112600, "start": 1146.0, "end": 1148.0, "text": " like French.", "tokens": [51364, 411, 5522, 13, 51464], "temperature": 0.0, "avg_logprob": -0.14378721063787286, "compression_ratio": 1.5681818181818181, "no_speech_prob": 0.10572734475135803}, {"id": 349, "seek": 114800, "start": 1148.0, "end": 1151.0, "text": " You'll notice that it's not aligned with the lips there,", "tokens": [50364, 509, 603, 3449, 300, 309, 311, 406, 17962, 365, 264, 10118, 456, 11, 50514], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 350, "seek": 114800, "start": 1151.0, "end": 1152.0, "text": " but that's all right.", "tokens": [50514, 457, 300, 311, 439, 558, 13, 50564], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 351, "seek": 114800, "start": 1152.0, "end": 1156.0, "text": " I just thought funky demo, one click, no messing around.", "tokens": [50564, 286, 445, 1194, 33499, 10723, 11, 472, 2052, 11, 572, 23258, 926, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 352, "seek": 114800, "start": 1156.0, "end": 1158.0, "text": " You don't have to install anything or use GitHub", "tokens": [50764, 509, 500, 380, 362, 281, 3625, 1340, 420, 764, 23331, 50864], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 353, "seek": 114800, "start": 1158.0, "end": 1162.0, "text": " or go through a hugging face or go through the Google Spaces", "tokens": [50864, 420, 352, 807, 257, 41706, 1851, 420, 352, 807, 264, 3329, 1738, 2116, 51064], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 354, "seek": 114800, "start": 1162.0, "end": 1163.0, "text": " to get that working.", "tokens": [51064, 281, 483, 300, 1364, 13, 51114], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 355, "seek": 114800, "start": 1163.0, "end": 1166.0, "text": " This is something that you can play around with immediately.", "tokens": [51114, 639, 307, 746, 300, 291, 393, 862, 926, 365, 4258, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 356, "seek": 114800, "start": 1166.0, "end": 1168.0, "text": " Really fun one.", "tokens": [51264, 4083, 1019, 472, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 357, "seek": 114800, "start": 1168.0, "end": 1169.0, "text": " All right.", "tokens": [51364, 1057, 558, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 358, "seek": 114800, "start": 1169.0, "end": 1170.0, "text": " Thank you.", "tokens": [51414, 1044, 291, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 359, "seek": 114800, "start": 1170.0, "end": 1171.0, "text": " Thank you.", "tokens": [51464, 1044, 291, 13, 51514], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 360, "seek": 114800, "start": 1171.0, "end": 1172.0, "text": " Thank you.", "tokens": [51514, 1044, 291, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 361, "seek": 114800, "start": 1172.0, "end": 1173.0, "text": " Thank you.", "tokens": [51564, 1044, 291, 13, 51614], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 362, "seek": 114800, "start": 1173.0, "end": 1174.0, "text": " Thank you.", "tokens": [51614, 1044, 291, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 363, "seek": 114800, "start": 1174.0, "end": 1175.0, "text": " Thank you.", "tokens": [51664, 1044, 291, 13, 51714], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 364, "seek": 114800, "start": 1175.0, "end": 1176.0, "text": " Thank you.", "tokens": [51714, 1044, 291, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1856295363347333, "compression_ratio": 1.826271186440678, "no_speech_prob": 0.19439205527305603}, {"id": 365, "seek": 117600, "start": 1176.0, "end": 1177.0, "text": " Really fun one.", "tokens": [50364, 4083, 1019, 472, 13, 50414], "temperature": 0.8, "avg_logprob": -0.26227239990234374, "compression_ratio": 1.5740072202166064, "no_speech_prob": 0.05334371700882912}, {"id": 366, "seek": 117600, "start": 1177.0, "end": 1178.0, "text": " All right.", "tokens": [50414, 1057, 558, 13, 50464], "temperature": 0.8, "avg_logprob": -0.26227239990234374, "compression_ratio": 1.5740072202166064, "no_speech_prob": 0.05334371700882912}, {"id": 367, "seek": 117600, "start": 1178.0, "end": 1179.0, "text": " Where are we at for questions?", "tokens": [50464, 2305, 366, 321, 412, 337, 1651, 30, 50514], "temperature": 0.8, "avg_logprob": -0.26227239990234374, "compression_ratio": 1.5740072202166064, "no_speech_prob": 0.05334371700882912}, {"id": 368, "seek": 117600, "start": 1179.0, "end": 1182.0, "text": " I know there's going to be a little bit on Google", "tokens": [50514, 286, 458, 456, 311, 516, 281, 312, 257, 707, 857, 322, 3329, 50664], "temperature": 0.8, "avg_logprob": -0.26227239990234374, "compression_ratio": 1.5740072202166064, "no_speech_prob": 0.05334371700882912}, {"id": 369, "seek": 117600, "start": 1182.0, "end": 1186.0, "text": " Geminime or definitely peaking on that the open source", "tokens": [50664, 460, 20008, 1312, 420, 2138, 520, 2456, 322, 300, 264, 1269, 4009, 50864], "temperature": 0.8, "avg_logprob": -0.26227239990234374, "compression_ratio": 1.5740072202166064, "no_speech_prob": 0.05334371700882912}, {"id": 370, "seek": 117600, "start": 1186.0, "end": 1191.0, "text": " concept met I have been at the leading edge of for at least", "tokens": [50864, 3410, 1131, 286, 362, 668, 412, 264, 5775, 4691, 295, 337, 412, 1935, 51114], "temperature": 0.8, "avg_logprob": -0.26227239990234374, "compression_ratio": 1.5740072202166064, "no_speech_prob": 0.05334371700882912}, {"id": 371, "seek": 117600, "start": 1191.0, "end": 1192.0, "text": " the last 12 months.", "tokens": [51114, 264, 1036, 2272, 2493, 13, 51164], "temperature": 0.8, "avg_logprob": -0.26227239990234374, "compression_ratio": 1.5740072202166064, "no_speech_prob": 0.05334371700882912}, {"id": 372, "seek": 117600, "start": 1192.0, "end": 1196.0, "text": " They gave us Lama one and lama two so quickly that they were", "tokens": [51164, 814, 2729, 505, 441, 2404, 472, 293, 45423, 732, 370, 2661, 300, 436, 645, 51364], "temperature": 0.8, "avg_logprob": -0.26227239990234374, "compression_ratio": 1.5740072202166064, "no_speech_prob": 0.05334371700882912}, {"id": 373, "seek": 117600, "start": 1196.0, "end": 1198.0, "text": " within a few months of each other.", "tokens": [51364, 1951, 257, 1326, 2493, 295, 1184, 661, 13, 51464], "temperature": 0.8, "avg_logprob": -0.26227239990234374, "compression_ratio": 1.5740072202166064, "no_speech_prob": 0.05334371700882912}, {"id": 374, "seek": 117600, "start": 1198.0, "end": 1203.0, "text": " You'll see Lama one on the left there, that dark blue, navy", "tokens": [51464, 509, 603, 536, 441, 2404, 472, 322, 264, 1411, 456, 11, 300, 2877, 3344, 11, 31319, 51714], "temperature": 0.8, "avg_logprob": -0.26227239990234374, "compression_ratio": 1.5740072202166064, "no_speech_prob": 0.05334371700882912}, {"id": 375, "seek": 117600, "start": 1203.0, "end": 1205.0, "text": " blue bubble at 65 billion parameters.", "tokens": [51714, 3344, 12212, 412, 11624, 5218, 9834, 13, 51814], "temperature": 0.8, "avg_logprob": -0.26227239990234374, "compression_ratio": 1.5740072202166064, "no_speech_prob": 0.05334371700882912}, {"id": 376, "seek": 120500, "start": 1205.0, "end": 1211.72, "text": " billion parameters, then they gave us Lama 2 at 70 billion parameters. Let me show you something", "tokens": [50364, 5218, 9834, 11, 550, 436, 2729, 505, 441, 2404, 568, 412, 5285, 5218, 9834, 13, 961, 385, 855, 291, 746, 50700], "temperature": 0.0, "avg_logprob": -0.17138522549679405, "compression_ratio": 1.4635416666666667, "no_speech_prob": 0.07805103063583374}, {"id": 377, "seek": 120500, "start": 1211.72, "end": 1225.08, "text": " interesting. So let's go to huggingface.co, that would be a good link. And in this models part", "tokens": [50700, 1880, 13, 407, 718, 311, 352, 281, 41706, 2868, 13, 1291, 11, 300, 576, 312, 257, 665, 2113, 13, 400, 294, 341, 5245, 644, 51368], "temperature": 0.0, "avg_logprob": -0.17138522549679405, "compression_ratio": 1.4635416666666667, "no_speech_prob": 0.07805103063583374}, {"id": 378, "seek": 120500, "start": 1225.08, "end": 1232.28, "text": " of the site, you can see, give me my filters here, I'm gonna have to zoom out to get this", "tokens": [51368, 295, 264, 3621, 11, 291, 393, 536, 11, 976, 385, 452, 15995, 510, 11, 286, 478, 799, 362, 281, 8863, 484, 281, 483, 341, 51728], "temperature": 0.0, "avg_logprob": -0.17138522549679405, "compression_ratio": 1.4635416666666667, "no_speech_prob": 0.07805103063583374}, {"id": 379, "seek": 123228, "start": 1232.36, "end": 1235.16, "text": " work and how I want it to work. But if we just look at", "tokens": [50368, 589, 293, 577, 286, 528, 309, 281, 589, 13, 583, 498, 321, 445, 574, 412, 50508], "temperature": 0.0, "avg_logprob": -0.12043135506766182, "compression_ratio": 1.4880952380952381, "no_speech_prob": 0.022971926257014275}, {"id": 380, "seek": 123228, "start": 1238.76, "end": 1249.48, "text": " text generation models, there are currently 35,000 models that correspond to text generation. Most", "tokens": [50688, 2487, 5125, 5245, 11, 456, 366, 4362, 6976, 11, 1360, 5245, 300, 6805, 281, 2487, 5125, 13, 4534, 51224], "temperature": 0.0, "avg_logprob": -0.12043135506766182, "compression_ratio": 1.4880952380952381, "no_speech_prob": 0.022971926257014275}, {"id": 381, "seek": 123228, "start": 1249.48, "end": 1256.04, "text": " of them open source. Have a look at those that respond to the term Lama. Remember this just came", "tokens": [51224, 295, 552, 1269, 4009, 13, 3560, 257, 574, 412, 729, 300, 4196, 281, 264, 1433, 441, 2404, 13, 5459, 341, 445, 1361, 51552], "temperature": 0.0, "avg_logprob": -0.12043135506766182, "compression_ratio": 1.4880952380952381, "no_speech_prob": 0.022971926257014275}, {"id": 382, "seek": 125604, "start": 1256.84, "end": 1269.48, "text": " this year, 6,000 Lama models. Lama 2 makes up 4,700 of those. And let's triple check", "tokens": [50404, 341, 1064, 11, 1386, 11, 1360, 441, 2404, 5245, 13, 441, 2404, 568, 1669, 493, 1017, 11, 18197, 295, 729, 13, 400, 718, 311, 15508, 1520, 51036], "temperature": 0.0, "avg_logprob": -0.1715583630970546, "compression_ratio": 1.2183098591549295, "no_speech_prob": 0.09803923219442368}, {"id": 383, "seek": 125604, "start": 1270.44, "end": 1282.28, "text": " when that was actually announced. July 18th, 2023. That's nuts. So in five months, 4,700", "tokens": [51084, 562, 300, 390, 767, 7548, 13, 7370, 2443, 392, 11, 44377, 13, 663, 311, 10483, 13, 407, 294, 1732, 2493, 11, 1017, 11, 18197, 51676], "temperature": 0.0, "avg_logprob": -0.1715583630970546, "compression_ratio": 1.2183098591549295, "no_speech_prob": 0.09803923219442368}, {"id": 384, "seek": 128228, "start": 1282.28, "end": 1287.8799999999999, "text": " open source versions of the open source Lama 2 model. And they're not the only ones on that bubble", "tokens": [50364, 1269, 4009, 9606, 295, 264, 1269, 4009, 441, 2404, 568, 2316, 13, 400, 436, 434, 406, 264, 787, 2306, 322, 300, 12212, 50644], "temperature": 0.0, "avg_logprob": -0.10754846004729575, "compression_ratio": 1.5884773662551441, "no_speech_prob": 0.09132252633571625}, {"id": 385, "seek": 128228, "start": 1287.8799999999999, "end": 1293.56, "text": " lists. Of course, you've got other open source models that are doing very well. This is probably not", "tokens": [50644, 14511, 13, 2720, 1164, 11, 291, 600, 658, 661, 1269, 4009, 5245, 300, 366, 884, 588, 731, 13, 639, 307, 1391, 406, 50928], "temperature": 0.0, "avg_logprob": -0.10754846004729575, "compression_ratio": 1.5884773662551441, "no_speech_prob": 0.09132252633571625}, {"id": 386, "seek": 128228, "start": 1293.56, "end": 1300.04, "text": " the best example, because I don't have a complete version of everything on there. But let's try", "tokens": [50928, 264, 1151, 1365, 11, 570, 286, 500, 380, 362, 257, 3566, 3037, 295, 1203, 322, 456, 13, 583, 718, 311, 853, 51252], "temperature": 0.0, "avg_logprob": -0.10754846004729575, "compression_ratio": 1.5884773662551441, "no_speech_prob": 0.09132252633571625}, {"id": 387, "seek": 128228, "start": 1300.04, "end": 1309.0, "text": " something like searching for Mistral, which is a competitor at 7 billion parameters, 1,300", "tokens": [51252, 746, 411, 10808, 337, 20166, 2155, 11, 597, 307, 257, 27266, 412, 1614, 5218, 9834, 11, 502, 11, 12566, 51700], "temperature": 0.0, "avg_logprob": -0.10754846004729575, "compression_ratio": 1.5884773662551441, "no_speech_prob": 0.09132252633571625}, {"id": 388, "seek": 130900, "start": 1309.4, "end": 1317.08, "text": " models that have been derived from Mistral. So open source is alive and well. And thanks to", "tokens": [50384, 5245, 300, 362, 668, 18949, 490, 20166, 2155, 13, 407, 1269, 4009, 307, 5465, 293, 731, 13, 400, 3231, 281, 50768], "temperature": 0.0, "avg_logprob": -0.09721373497171605, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.008061420172452927}, {"id": 389, "seek": 130900, "start": 1317.72, "end": 1324.68, "text": " Metta, I think as one of the main contenders, one of the main labs that are pushing open source,", "tokens": [50800, 6377, 1328, 11, 286, 519, 382, 472, 295, 264, 2135, 660, 16292, 11, 472, 295, 264, 2135, 20339, 300, 366, 7380, 1269, 4009, 11, 51148], "temperature": 0.0, "avg_logprob": -0.09721373497171605, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.008061420172452927}, {"id": 390, "seek": 130900, "start": 1324.68, "end": 1330.12, "text": " we're seeing a lot of options for people to go and play around with. This is my models table. It", "tokens": [51148, 321, 434, 2577, 257, 688, 295, 3956, 337, 561, 281, 352, 293, 862, 926, 365, 13, 639, 307, 452, 5245, 3199, 13, 467, 51420], "temperature": 0.0, "avg_logprob": -0.09721373497171605, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.008061420172452927}, {"id": 391, "seek": 130900, "start": 1330.12, "end": 1335.88, "text": " doesn't explicitly call out open source versus closed source. But this gives a better example", "tokens": [51420, 1177, 380, 20803, 818, 484, 1269, 4009, 5717, 5395, 4009, 13, 583, 341, 2709, 257, 1101, 1365, 51708], "temperature": 0.0, "avg_logprob": -0.09721373497171605, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.008061420172452927}, {"id": 392, "seek": 133588, "start": 1335.88, "end": 1343.72, "text": " of some of the root models, the original models that are provided. So I haven't gone and documented", "tokens": [50364, 295, 512, 295, 264, 5593, 5245, 11, 264, 3380, 5245, 300, 366, 5649, 13, 407, 286, 2378, 380, 2780, 293, 23007, 50756], "temperature": 0.0, "avg_logprob": -0.05346371025167486, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.0019567932467907667}, {"id": 393, "seek": 133588, "start": 1343.72, "end": 1351.5600000000002, "text": " all 4,700 Lama 2 derivatives. In fact, I've made a point not to document any Lama 2 derivatives.", "tokens": [50756, 439, 1017, 11, 18197, 441, 2404, 568, 33733, 13, 682, 1186, 11, 286, 600, 1027, 257, 935, 406, 281, 4166, 604, 441, 2404, 568, 33733, 13, 51148], "temperature": 0.0, "avg_logprob": -0.05346371025167486, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.0019567932467907667}, {"id": 394, "seek": 133588, "start": 1351.5600000000002, "end": 1356.44, "text": " But this is some of the, let's say alternatives, you could say competitors,", "tokens": [51148, 583, 341, 307, 512, 295, 264, 11, 718, 311, 584, 20478, 11, 291, 727, 584, 18333, 11, 51392], "temperature": 0.0, "avg_logprob": -0.05346371025167486, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.0019567932467907667}, {"id": 395, "seek": 133588, "start": 1356.44, "end": 1360.1200000000001, "text": " where you can go and play around with how that works differently. The big one at the moment", "tokens": [51392, 689, 291, 393, 352, 293, 862, 926, 365, 577, 300, 1985, 7614, 13, 440, 955, 472, 412, 264, 1623, 51576], "temperature": 0.0, "avg_logprob": -0.05346371025167486, "compression_ratio": 1.5826086956521739, "no_speech_prob": 0.0019567932467907667}, {"id": 396, "seek": 136012, "start": 1360.12, "end": 1369.8, "text": " that I'm seeing a lot about, let's go and find it, is this one, Quen. They have launched a few", "tokens": [50364, 300, 286, 478, 2577, 257, 688, 466, 11, 718, 311, 352, 293, 915, 309, 11, 307, 341, 472, 11, 2326, 268, 13, 814, 362, 8730, 257, 1326, 50848], "temperature": 0.0, "avg_logprob": -0.12018287030956414, "compression_ratio": 1.4870466321243523, "no_speech_prob": 0.022281501442193985}, {"id": 397, "seek": 136012, "start": 1369.8, "end": 1377.6399999999999, "text": " different alternatives to this one. So there's a 14 billion parameter version of Quen. And I believe", "tokens": [50848, 819, 20478, 281, 341, 472, 13, 407, 456, 311, 257, 3499, 5218, 13075, 3037, 295, 2326, 268, 13, 400, 286, 1697, 51240], "temperature": 0.0, "avg_logprob": -0.12018287030956414, "compression_ratio": 1.4870466321243523, "no_speech_prob": 0.022281501442193985}, {"id": 398, "seek": 136012, "start": 1380.12, "end": 1385.9599999999998, "text": " this one is the most popular at the moment from what I'm seeing. Besides Lama 2, of course,", "tokens": [51364, 341, 472, 307, 264, 881, 3743, 412, 264, 1623, 490, 437, 286, 478, 2577, 13, 13212, 441, 2404, 568, 11, 295, 1164, 11, 51656], "temperature": 0.0, "avg_logprob": -0.12018287030956414, "compression_ratio": 1.4870466321243523, "no_speech_prob": 0.022281501442193985}, {"id": 399, "seek": 138596, "start": 1385.96, "end": 1394.8400000000001, "text": " this is getting a lot of attention from China, of course, they have a 72 billion parameter version", "tokens": [50364, 341, 307, 1242, 257, 688, 295, 3202, 490, 3533, 11, 295, 1164, 11, 436, 362, 257, 18731, 5218, 13075, 3037, 50808], "temperature": 0.0, "avg_logprob": -0.10948088397718456, "compression_ratio": 1.455, "no_speech_prob": 0.003075110726058483}, {"id": 400, "seek": 138596, "start": 1394.8400000000001, "end": 1402.44, "text": " that I need to add into the sheet. But at the time of publication, 14B was the biggest. So 72B", "tokens": [50808, 300, 286, 643, 281, 909, 666, 264, 8193, 13, 583, 412, 264, 565, 295, 19953, 11, 3499, 33, 390, 264, 3880, 13, 407, 18731, 33, 51188], "temperature": 0.0, "avg_logprob": -0.10948088397718456, "compression_ratio": 1.455, "no_speech_prob": 0.003075110726058483}, {"id": 401, "seek": 138596, "start": 1402.44, "end": 1411.72, "text": " still trained on 3 trillion tokens. And a great contender. Some of these have different licenses,", "tokens": [51188, 920, 8895, 322, 805, 18723, 22667, 13, 400, 257, 869, 660, 3216, 13, 2188, 295, 613, 362, 819, 32821, 11, 51652], "temperature": 0.0, "avg_logprob": -0.10948088397718456, "compression_ratio": 1.455, "no_speech_prob": 0.003075110726058483}, {"id": 402, "seek": 141172, "start": 1411.72, "end": 1417.24, "text": " obviously, they're not all completely open, you can use it for commercial applications,", "tokens": [50364, 2745, 11, 436, 434, 406, 439, 2584, 1269, 11, 291, 393, 764, 309, 337, 6841, 5821, 11, 50640], "temperature": 0.0, "avg_logprob": -0.12034524142087161, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.07800323516130447}, {"id": 403, "seek": 141172, "start": 1417.24, "end": 1420.44, "text": " you need to go and read the full license, if they're Apache 2, they're often quite", "tokens": [50640, 291, 643, 281, 352, 293, 1401, 264, 1577, 10476, 11, 498, 436, 434, 46597, 568, 11, 436, 434, 2049, 1596, 50800], "temperature": 0.0, "avg_logprob": -0.12034524142087161, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.07800323516130447}, {"id": 404, "seek": 141172, "start": 1421.24, "end": 1427.64, "text": " broad and open. But it's up to you and your legal counsel to determine what's going to be best for", "tokens": [50840, 4152, 293, 1269, 13, 583, 309, 311, 493, 281, 291, 293, 428, 5089, 10351, 281, 6997, 437, 311, 516, 281, 312, 1151, 337, 51160], "temperature": 0.0, "avg_logprob": -0.12034524142087161, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.07800323516130447}, {"id": 405, "seek": 141172, "start": 1427.64, "end": 1438.28, "text": " your particular use case. Alright, thanks, Ben, for helping out people with tagging, because that", "tokens": [51160, 428, 1729, 764, 1389, 13, 2798, 11, 3231, 11, 3964, 11, 337, 4315, 484, 561, 365, 6162, 3249, 11, 570, 300, 51692], "temperature": 0.0, "avg_logprob": -0.12034524142087161, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.07800323516130447}, {"id": 406, "seek": 143828, "start": 1438.28, "end": 1447.8799999999999, "text": " will help me see things. Peter's made a point here that Google Gemini is perhaps being delayed,", "tokens": [50364, 486, 854, 385, 536, 721, 13, 6508, 311, 1027, 257, 935, 510, 300, 3329, 22894, 3812, 307, 4317, 885, 20268, 11, 50844], "temperature": 0.0, "avg_logprob": -0.10043088185418513, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.025175224989652634}, {"id": 407, "seek": 143828, "start": 1447.8799999999999, "end": 1451.96, "text": " I was hoping we'd see it for this morning, there was some talk about Google Gemini being,", "tokens": [50844, 286, 390, 7159, 321, 1116, 536, 309, 337, 341, 2446, 11, 456, 390, 512, 751, 466, 3329, 22894, 3812, 885, 11, 51048], "temperature": 0.0, "avg_logprob": -0.10043088185418513, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.025175224989652634}, {"id": 408, "seek": 143828, "start": 1452.68, "end": 1459.6399999999999, "text": " or Google DeepMind Gemini, it's now Google DeepMind, being made available this morning.", "tokens": [51084, 420, 3329, 14895, 44, 471, 22894, 3812, 11, 309, 311, 586, 3329, 14895, 44, 471, 11, 885, 1027, 2435, 341, 2446, 13, 51432], "temperature": 0.0, "avg_logprob": -0.10043088185418513, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.025175224989652634}, {"id": 409, "seek": 143828, "start": 1460.2, "end": 1466.84, "text": " The leak was someone had seen in Vertex these four different model names, but I don't know if that's", "tokens": [51460, 440, 17143, 390, 1580, 632, 1612, 294, 21044, 3121, 613, 1451, 819, 2316, 5288, 11, 457, 286, 500, 380, 458, 498, 300, 311, 51792], "temperature": 0.0, "avg_logprob": -0.10043088185418513, "compression_ratio": 1.6771300448430493, "no_speech_prob": 0.025175224989652634}, {"id": 410, "seek": 146684, "start": 1466.84, "end": 1474.36, "text": " true. This was their screenshot of Vertex with this particular resource ID, and someone had leaked", "tokens": [50364, 2074, 13, 639, 390, 641, 27712, 295, 21044, 3121, 365, 341, 1729, 7684, 7348, 11, 293, 1580, 632, 31779, 50740], "temperature": 0.0, "avg_logprob": -0.10658865656171526, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.010815410874783993}, {"id": 411, "seek": 146684, "start": 1475.08, "end": 1483.24, "text": " Gemini Pro Vision, Gemini Ultra and Gemini Ultra Vision. My Vertex doesn't show anything like", "tokens": [50776, 22894, 3812, 1705, 25170, 11, 22894, 3812, 20925, 293, 22894, 3812, 20925, 25170, 13, 1222, 21044, 3121, 1177, 380, 855, 1340, 411, 51184], "temperature": 0.0, "avg_logprob": -0.10658865656171526, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.010815410874783993}, {"id": 412, "seek": 146684, "start": 1483.24, "end": 1489.48, "text": " that. So there are a lot of strange people doing strange things, so I wouldn't be surprised if", "tokens": [51184, 300, 13, 407, 456, 366, 257, 688, 295, 5861, 561, 884, 5861, 721, 11, 370, 286, 2759, 380, 312, 6100, 498, 51496], "temperature": 0.0, "avg_logprob": -0.10658865656171526, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.010815410874783993}, {"id": 413, "seek": 148948, "start": 1489.48, "end": 1498.1200000000001, "text": " that's a fake leak. But anyway, Gemini is on its way, and it may be this week or it may be in January,", "tokens": [50364, 300, 311, 257, 7592, 17143, 13, 583, 4033, 11, 22894, 3812, 307, 322, 1080, 636, 11, 293, 309, 815, 312, 341, 1243, 420, 309, 815, 312, 294, 7061, 11, 50796], "temperature": 0.0, "avg_logprob": -0.0964661892329421, "compression_ratio": 1.5369649805447472, "no_speech_prob": 0.07261201739311218}, {"id": 414, "seek": 148948, "start": 1498.1200000000001, "end": 1505.4, "text": " February 2024, which is coming up soon anyway. If you don't use Vertex AI, it's probably worth", "tokens": [50796, 8711, 45237, 11, 597, 307, 1348, 493, 2321, 4033, 13, 759, 291, 500, 380, 764, 21044, 3121, 7318, 11, 309, 311, 1391, 3163, 51160], "temperature": 0.0, "avg_logprob": -0.0964661892329421, "compression_ratio": 1.5369649805447472, "no_speech_prob": 0.07261201739311218}, {"id": 415, "seek": 148948, "start": 1505.4, "end": 1511.88, "text": " having a look at. I think it's still free in that you get $300 worth of credits or something like that", "tokens": [51160, 1419, 257, 574, 412, 13, 286, 519, 309, 311, 920, 1737, 294, 300, 291, 483, 1848, 12566, 3163, 295, 16816, 420, 746, 411, 300, 51484], "temperature": 0.0, "avg_logprob": -0.0964661892329421, "compression_ratio": 1.5369649805447472, "no_speech_prob": 0.07261201739311218}, {"id": 416, "seek": 148948, "start": 1512.44, "end": 1516.92, "text": " to go and play around with things. But basically in the model garden, you can say just show me", "tokens": [51512, 281, 352, 293, 862, 926, 365, 721, 13, 583, 1936, 294, 264, 2316, 7431, 11, 291, 393, 584, 445, 855, 385, 51736], "temperature": 0.0, "avg_logprob": -0.0964661892329421, "compression_ratio": 1.5369649805447472, "no_speech_prob": 0.07261201739311218}, {"id": 417, "seek": 151692, "start": 1516.92, "end": 1523.0, "text": " text generation models, and you get to see, let's see,", "tokens": [50364, 2487, 5125, 5245, 11, 293, 291, 483, 281, 536, 11, 718, 311, 536, 11, 50668], "temperature": 0.0, "avg_logprob": -0.1406552181687466, "compression_ratio": 1.3652173913043477, "no_speech_prob": 0.002980502787977457}, {"id": 418, "seek": 151692, "start": 1530.8400000000001, "end": 1537.0, "text": " we get to see different types of language models. It'd be great if I could use this properly, wouldn't", "tokens": [51060, 321, 483, 281, 536, 819, 3467, 295, 2856, 5245, 13, 467, 1116, 312, 869, 498, 286, 727, 764, 341, 6108, 11, 2759, 380, 51368], "temperature": 0.0, "avg_logprob": -0.1406552181687466, "compression_ratio": 1.3652173913043477, "no_speech_prob": 0.002980502787977457}, {"id": 419, "seek": 153700, "start": 1537.4, "end": 1547.56, "text": " it? Any case, they are still only providing a smaller version of Palm II. The Palm II full", "tokens": [50384, 309, 30, 2639, 1389, 11, 436, 366, 920, 787, 6530, 257, 4356, 3037, 295, 32668, 6351, 13, 440, 32668, 6351, 1577, 50892], "temperature": 0.0, "avg_logprob": -0.14649700772935065, "compression_ratio": 1.5297297297297296, "no_speech_prob": 0.048125967383384705}, {"id": 420, "seek": 153700, "start": 1547.56, "end": 1556.04, "text": " model should be 340 billion parameters. I believe that's called Unicorn. They're giving us the next", "tokens": [50892, 2316, 820, 312, 805, 5254, 5218, 9834, 13, 286, 1697, 300, 311, 1219, 1156, 23115, 13, 814, 434, 2902, 505, 264, 958, 51316], "temperature": 0.0, "avg_logprob": -0.14649700772935065, "compression_ratio": 1.5297297297297296, "no_speech_prob": 0.048125967383384705}, {"id": 421, "seek": 153700, "start": 1556.04, "end": 1562.36, "text": " biggest one called Bison. So maybe just 100 billion parameters, maybe 70 billion parameters.", "tokens": [51316, 3880, 472, 1219, 363, 2770, 13, 407, 1310, 445, 2319, 5218, 9834, 11, 1310, 5285, 5218, 9834, 13, 51632], "temperature": 0.0, "avg_logprob": -0.14649700772935065, "compression_ratio": 1.5297297297297296, "no_speech_prob": 0.048125967383384705}, {"id": 422, "seek": 156236, "start": 1563.08, "end": 1568.9199999999998, "text": " And that's the one we use inside Poe as well. And it's pretty smart. Here's our feedback from", "tokens": [50400, 400, 300, 311, 264, 472, 321, 764, 1854, 6165, 68, 382, 731, 13, 400, 309, 311, 1238, 4069, 13, 1692, 311, 527, 5824, 490, 50692], "temperature": 0.0, "avg_logprob": -0.16121840476989746, "compression_ratio": 1.3756097560975609, "no_speech_prob": 0.013018516823649406}, {"id": 423, "seek": 156236, "start": 1568.9199999999998, "end": 1577.24, "text": " Claude II that went and read that 111 page paper. Gave us three flags. Oh yeah, it's using", "tokens": [50692, 12947, 2303, 6351, 300, 1437, 293, 1401, 300, 2975, 16, 3028, 3035, 13, 460, 946, 505, 1045, 23265, 13, 876, 1338, 11, 309, 311, 1228, 51108], "temperature": 0.0, "avg_logprob": -0.16121840476989746, "compression_ratio": 1.3756097560975609, "no_speech_prob": 0.013018516823649406}, {"id": 424, "seek": 156236, "start": 1577.8799999999999, "end": 1586.36, "text": " Messer's No Language Left Behind, which is a 1.3 billion parameter model. It covers 95 languages.", "tokens": [51140, 9847, 260, 311, 883, 24445, 16405, 20475, 11, 597, 307, 257, 502, 13, 18, 5218, 13075, 2316, 13, 467, 10538, 13420, 8650, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16121840476989746, "compression_ratio": 1.3756097560975609, "no_speech_prob": 0.013018516823649406}, {"id": 425, "seek": 158636, "start": 1586.36, "end": 1592.28, "text": " Also does have BERT for speech rep. And there are another couple of models that it's playing with", "tokens": [50364, 2743, 775, 362, 363, 31479, 337, 6218, 1085, 13, 400, 456, 366, 1071, 1916, 295, 5245, 300, 309, 311, 2433, 365, 50660], "temperature": 0.0, "avg_logprob": -0.0877275174977828, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.006387372501194477}, {"id": 426, "seek": 158636, "start": 1592.28, "end": 1601.6399999999999, "text": " there as well. Isn't that fun? It just went and read an 111 page document for us and answered the", "tokens": [50660, 456, 382, 731, 13, 6998, 380, 300, 1019, 30, 467, 445, 1437, 293, 1401, 364, 2975, 16, 3028, 4166, 337, 505, 293, 10103, 264, 51128], "temperature": 0.0, "avg_logprob": -0.0877275174977828, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.006387372501194477}, {"id": 427, "seek": 158636, "start": 1601.6399999999999, "end": 1606.52, "text": " prompt. And this is not a prescriptive prompt. You can change this to whatever you like. We still", "tokens": [51128, 12391, 13, 400, 341, 307, 406, 257, 1183, 5944, 488, 12391, 13, 509, 393, 1319, 341, 281, 2035, 291, 411, 13, 492, 920, 51372], "temperature": 0.0, "avg_logprob": -0.0877275174977828, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.006387372501194477}, {"id": 428, "seek": 158636, "start": 1606.52, "end": 1611.8, "text": " don't have best practice for how to articulate these or how to create these prompts. But this is", "tokens": [51372, 500, 380, 362, 1151, 3124, 337, 577, 281, 30305, 613, 420, 577, 281, 1884, 613, 41095, 13, 583, 341, 307, 51636], "temperature": 0.0, "avg_logprob": -0.0877275174977828, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.006387372501194477}, {"id": 429, "seek": 161180, "start": 1611.8, "end": 1628.44, "text": " the response I got for that particular prompt. All right, let's see what questions we can dig up.", "tokens": [50364, 264, 4134, 286, 658, 337, 300, 1729, 12391, 13, 1057, 558, 11, 718, 311, 536, 437, 1651, 321, 393, 2528, 493, 13, 51196], "temperature": 0.0, "avg_logprob": -0.08055480666782545, "compression_ratio": 1.3768115942028984, "no_speech_prob": 0.006003213115036488}, {"id": 430, "seek": 161180, "start": 1630.84, "end": 1634.9199999999998, "text": " You guys are starting with the hard questions this morning because I can already see I don't", "tokens": [51316, 509, 1074, 366, 2891, 365, 264, 1152, 1651, 341, 2446, 570, 286, 393, 1217, 536, 286, 500, 380, 51520], "temperature": 0.0, "avg_logprob": -0.08055480666782545, "compression_ratio": 1.3768115942028984, "no_speech_prob": 0.006003213115036488}, {"id": 431, "seek": 163492, "start": 1634.92, "end": 1640.68, "text": " have answers to this one. What comes after Transformers? Is there anything cooking?", "tokens": [50364, 362, 6338, 281, 341, 472, 13, 708, 1487, 934, 27938, 433, 30, 1119, 456, 1340, 6361, 30, 50652], "temperature": 0.0, "avg_logprob": -0.13174441709356793, "compression_ratio": 1.3641618497109826, "no_speech_prob": 0.043358344584703445}, {"id": 432, "seek": 163492, "start": 1643.5600000000002, "end": 1650.1200000000001, "text": " It was about six years ago that Google came out with the Transformer model", "tokens": [50796, 467, 390, 466, 2309, 924, 2057, 300, 3329, 1361, 484, 365, 264, 27938, 260, 2316, 51124], "temperature": 0.0, "avg_logprob": -0.13174441709356793, "compression_ratio": 1.3641618497109826, "no_speech_prob": 0.043358344584703445}, {"id": 433, "seek": 163492, "start": 1650.76, "end": 1660.76, "text": " in a paper called Attention Is All You Need. This one says August 31st, 2017.", "tokens": [51156, 294, 257, 3035, 1219, 31858, 1119, 1057, 509, 16984, 13, 639, 472, 1619, 6897, 10353, 372, 11, 6591, 13, 51656], "temperature": 0.0, "avg_logprob": -0.13174441709356793, "compression_ratio": 1.3641618497109826, "no_speech_prob": 0.043358344584703445}, {"id": 434, "seek": 166076, "start": 1661.0, "end": 1668.36, "text": " Worth reading. And if you'd like to understand it in greater detail, there are actually two", "tokens": [50376, 37228, 3760, 13, 400, 498, 291, 1116, 411, 281, 1223, 309, 294, 5044, 2607, 11, 456, 366, 767, 732, 50744], "temperature": 0.0, "avg_logprob": -0.1783956936427525, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.03621469810605049}, {"id": 435, "seek": 166076, "start": 1668.36, "end": 1677.24, "text": " recommendations I have now. The first is Jay Alamar's work on Transformer, the Illustrated", "tokens": [50744, 10434, 286, 362, 586, 13, 440, 700, 307, 11146, 967, 45207, 311, 589, 322, 27938, 260, 11, 264, 37788, 5468, 51188], "temperature": 0.0, "avg_logprob": -0.1783956936427525, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.03621469810605049}, {"id": 436, "seek": 166076, "start": 1677.24, "end": 1688.28, "text": " Transformer, which is amazing. Jay's fantastic. I believe he now works for Cohere. But there's", "tokens": [51188, 27938, 260, 11, 597, 307, 2243, 13, 11146, 311, 5456, 13, 286, 1697, 415, 586, 1985, 337, 3066, 6703, 13, 583, 456, 311, 51740], "temperature": 0.0, "avg_logprob": -0.1783956936427525, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.03621469810605049}, {"id": 437, "seek": 168828, "start": 1688.28, "end": 1694.28, "text": " a better one. This one is something that I used for a while because he's very good at animating", "tokens": [50364, 257, 1101, 472, 13, 639, 472, 307, 746, 300, 286, 1143, 337, 257, 1339, 570, 415, 311, 588, 665, 412, 2383, 990, 50664], "temperature": 0.0, "avg_logprob": -0.06546330778566126, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.02441631257534027}, {"id": 438, "seek": 168828, "start": 1694.28, "end": 1703.6399999999999, "text": " and documenting. But then there was one by, I think it was by Fortune. And it was just so well done", "tokens": [50664, 293, 42360, 13, 583, 550, 456, 390, 472, 538, 11, 286, 519, 309, 390, 538, 38508, 13, 400, 309, 390, 445, 370, 731, 1096, 51132], "temperature": 0.0, "avg_logprob": -0.06546330778566126, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.02441631257534027}, {"id": 439, "seek": 168828, "start": 1703.6399999999999, "end": 1711.32, "text": " that it actually outdid what Jay had done. What's that life architect thing doing there?", "tokens": [51132, 300, 309, 767, 484, 38169, 437, 11146, 632, 1096, 13, 708, 311, 300, 993, 6331, 551, 884, 456, 30, 51516], "temperature": 0.0, "avg_logprob": -0.06546330778566126, "compression_ratio": 1.486910994764398, "no_speech_prob": 0.02441631257534027}, {"id": 440, "seek": 171132, "start": 1712.04, "end": 1718.6799999999998, "text": " I'll have to find that and I will leave it in the description", "tokens": [50400, 286, 603, 362, 281, 915, 300, 293, 286, 486, 1856, 309, 294, 264, 3855, 50732], "temperature": 0.0, "avg_logprob": -0.16330068906148273, "compression_ratio": 1.4277456647398843, "no_speech_prob": 0.010327410884201527}, {"id": 441, "seek": 171132, "start": 1721.96, "end": 1726.52, "text": " because I won't be able to find that right now. But excellent question. Basically, we've gone from", "tokens": [50896, 570, 286, 1582, 380, 312, 1075, 281, 915, 300, 558, 586, 13, 583, 7103, 1168, 13, 8537, 11, 321, 600, 2780, 490, 51124], "temperature": 0.0, "avg_logprob": -0.16330068906148273, "compression_ratio": 1.4277456647398843, "no_speech_prob": 0.010327410884201527}, {"id": 442, "seek": 171132, "start": 1727.08, "end": 1737.24, "text": " Google researching how to translate from SOV, actually, subject object verb with their", "tokens": [51152, 3329, 24176, 577, 281, 13799, 490, 10621, 53, 11, 767, 11, 3983, 2657, 9595, 365, 641, 51660], "temperature": 0.0, "avg_logprob": -0.16330068906148273, "compression_ratio": 1.4277456647398843, "no_speech_prob": 0.010327410884201527}, {"id": 443, "seek": 173724, "start": 1737.24, "end": 1744.44, "text": " translate model in 2017. And I believe, I say, they accidentally stumbled on this Transformer,", "tokens": [50364, 13799, 2316, 294, 6591, 13, 400, 286, 1697, 11, 286, 584, 11, 436, 15715, 36668, 322, 341, 27938, 260, 11, 50724], "temperature": 0.0, "avg_logprob": -0.08777741856045193, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.05182763934135437}, {"id": 444, "seek": 173724, "start": 1744.44, "end": 1748.68, "text": " which could look forward and backward in the sentence. And it didn't really care whether it", "tokens": [50724, 597, 727, 574, 2128, 293, 23897, 294, 264, 8174, 13, 400, 309, 994, 380, 534, 1127, 1968, 309, 50936], "temperature": 0.0, "avg_logprob": -0.08777741856045193, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.05182763934135437}, {"id": 445, "seek": 173724, "start": 1748.68, "end": 1757.96, "text": " was SOV or otherwise, because it could leap around and see the context of that and pay attention", "tokens": [50936, 390, 10621, 53, 420, 5911, 11, 570, 309, 727, 19438, 926, 293, 536, 264, 4319, 295, 300, 293, 1689, 3202, 51400], "temperature": 0.0, "avg_logprob": -0.08777741856045193, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.05182763934135437}, {"id": 446, "seek": 173724, "start": 1757.96, "end": 1763.56, "text": " to words in that sentence or in that block. And then people went, well, we could apply this to", "tokens": [51400, 281, 2283, 294, 300, 8174, 420, 294, 300, 3461, 13, 400, 550, 561, 1437, 11, 731, 11, 321, 727, 3079, 341, 281, 51680], "temperature": 0.0, "avg_logprob": -0.08777741856045193, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.05182763934135437}, {"id": 447, "seek": 176356, "start": 1763.56, "end": 1768.04, "text": " everything. And we can train this on everything. And that's where we are today with GPT-4", "tokens": [50364, 1203, 13, 400, 321, 393, 3847, 341, 322, 1203, 13, 400, 300, 311, 689, 321, 366, 965, 365, 26039, 51, 12, 19, 50588], "temperature": 0.0, "avg_logprob": -0.14948599011290306, "compression_ratio": 1.5477178423236515, "no_speech_prob": 0.10226215422153473}, {"id": 448, "seek": 176356, "start": 1768.6, "end": 1774.6799999999998, "text": " and larger models like Amazon Olympus, OpenAR, GPT-5, Google Deepmine, Gemini coming up.", "tokens": [50616, 293, 4833, 5245, 411, 6795, 10395, 301, 11, 7238, 1899, 11, 26039, 51, 12, 20, 11, 3329, 14895, 76, 533, 11, 22894, 3812, 1348, 493, 13, 50920], "temperature": 0.0, "avg_logprob": -0.14948599011290306, "compression_ratio": 1.5477178423236515, "no_speech_prob": 0.10226215422153473}, {"id": 449, "seek": 176356, "start": 1775.32, "end": 1782.28, "text": " Transformers taking us this far in seven years, 2018, 19, 21, 23, six years, nearly seven years,", "tokens": [50952, 27938, 433, 1940, 505, 341, 1400, 294, 3407, 924, 11, 6096, 11, 1294, 11, 5080, 11, 6673, 11, 2309, 924, 11, 6217, 3407, 924, 11, 51300], "temperature": 0.0, "avg_logprob": -0.14948599011290306, "compression_ratio": 1.5477178423236515, "no_speech_prob": 0.10226215422153473}, {"id": 450, "seek": 176356, "start": 1783.0, "end": 1789.96, "text": " August next year. There is talk of moving away from Transformer or at least there being something", "tokens": [51336, 6897, 958, 1064, 13, 821, 307, 751, 295, 2684, 1314, 490, 27938, 260, 420, 412, 1935, 456, 885, 746, 51684], "temperature": 0.0, "avg_logprob": -0.14948599011290306, "compression_ratio": 1.5477178423236515, "no_speech_prob": 0.10226215422153473}, {"id": 451, "seek": 178996, "start": 1790.04, "end": 1795.24, "text": " coming up next. What that is, we don't know. I think that the Transformer is enough. And", "tokens": [50368, 1348, 493, 958, 13, 708, 300, 307, 11, 321, 500, 380, 458, 13, 286, 519, 300, 264, 27938, 260, 307, 1547, 13, 400, 50628], "temperature": 0.0, "avg_logprob": -0.09620732846467392, "compression_ratio": 1.5122950819672132, "no_speech_prob": 0.06094576418399811}, {"id": 452, "seek": 178996, "start": 1795.24, "end": 1800.8400000000001, "text": " Ray Kurzweil agrees with me there that what we've found here, the ability for a machine", "tokens": [50628, 10883, 45307, 826, 388, 26383, 365, 385, 456, 300, 437, 321, 600, 1352, 510, 11, 264, 3485, 337, 257, 3479, 50908], "temperature": 0.0, "avg_logprob": -0.09620732846467392, "compression_ratio": 1.5122950819672132, "no_speech_prob": 0.06094576418399811}, {"id": 453, "seek": 178996, "start": 1801.48, "end": 1808.68, "text": " to read in context and statistically predict the next word is enough to get us to this advanced", "tokens": [50940, 281, 1401, 294, 4319, 293, 36478, 6069, 264, 958, 1349, 307, 1547, 281, 483, 505, 281, 341, 7339, 51300], "temperature": 0.0, "avg_logprob": -0.09620732846467392, "compression_ratio": 1.5122950819672132, "no_speech_prob": 0.06094576418399811}, {"id": 454, "seek": 178996, "start": 1808.68, "end": 1816.44, "text": " post-2020 AI and potentially to AGI. But there will be some other technologies that are added in", "tokens": [51300, 2183, 12, 23095, 7318, 293, 7263, 281, 316, 26252, 13, 583, 456, 486, 312, 512, 661, 7943, 300, 366, 3869, 294, 51688], "temperature": 0.0, "avg_logprob": -0.09620732846467392, "compression_ratio": 1.5122950819672132, "no_speech_prob": 0.06094576418399811}, {"id": 455, "seek": 181644, "start": 1816.44, "end": 1827.16, "text": " on top of this. Didn't answer your question. What comes next? Where'd my comment go?", "tokens": [50364, 322, 1192, 295, 341, 13, 11151, 380, 1867, 428, 1168, 13, 708, 1487, 958, 30, 2305, 1116, 452, 2871, 352, 30, 50900], "temperature": 0.0, "avg_logprob": -0.08687908258011091, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.019399788230657578}, {"id": 456, "seek": 181644, "start": 1827.88, "end": 1836.6000000000001, "text": " But great question, Ben. There is a real interest in what does come next that what we're researching,", "tokens": [50936, 583, 869, 1168, 11, 3964, 13, 821, 307, 257, 957, 1179, 294, 437, 775, 808, 958, 300, 437, 321, 434, 24176, 11, 51372], "temperature": 0.0, "avg_logprob": -0.08687908258011091, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.019399788230657578}, {"id": 457, "seek": 181644, "start": 1836.6000000000001, "end": 1842.52, "text": " what we're playing around with for the next technology is something that people are very", "tokens": [51372, 437, 321, 434, 2433, 926, 365, 337, 264, 958, 2899, 307, 746, 300, 561, 366, 588, 51668], "temperature": 0.0, "avg_logprob": -0.08687908258011091, "compression_ratio": 1.5277777777777777, "no_speech_prob": 0.019399788230657578}, {"id": 458, "seek": 184252, "start": 1842.52, "end": 1848.36, "text": " passionate about finding. And all I've read at the moment is that we're just building on top of", "tokens": [50364, 11410, 466, 5006, 13, 400, 439, 286, 600, 1401, 412, 264, 1623, 307, 300, 321, 434, 445, 2390, 322, 1192, 295, 50656], "temperature": 0.0, "avg_logprob": -0.08896125631129488, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.007574182469397783}, {"id": 459, "seek": 184252, "start": 1848.36, "end": 1854.12, "text": " this, giving it memory, giving it context. And there are some proprietary smarts, particularly", "tokens": [50656, 341, 11, 2902, 309, 4675, 11, 2902, 309, 4319, 13, 400, 456, 366, 512, 38992, 4069, 82, 11, 4098, 50944], "temperature": 0.0, "avg_logprob": -0.08896125631129488, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.007574182469397783}, {"id": 460, "seek": 184252, "start": 1854.12, "end": 1862.76, "text": " at OpenAI that are fascinating. Let's grab some other comments. Sabine is asking, do you have", "tokens": [50944, 412, 7238, 48698, 300, 366, 10343, 13, 961, 311, 4444, 512, 661, 3053, 13, 13915, 533, 307, 3365, 11, 360, 291, 362, 51376], "temperature": 0.0, "avg_logprob": -0.08896125631129488, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.007574182469397783}, {"id": 461, "seek": 184252, "start": 1862.76, "end": 1872.12, "text": " any information on why Google postponed their launch of Gemini? Yes, I do. There was a non-", "tokens": [51376, 604, 1589, 322, 983, 3329, 49023, 641, 4025, 295, 22894, 3812, 30, 1079, 11, 286, 360, 13, 821, 390, 257, 2107, 12, 51844], "temperature": 0.0, "avg_logprob": -0.08896125631129488, "compression_ratio": 1.5100401606425702, "no_speech_prob": 0.007574182469397783}, {"id": 462, "seek": 187212, "start": 1872.1999999999998, "end": 1879.8799999999999, "text": " English issue in that when they were red teaming, I believe,", "tokens": [50368, 3669, 2734, 294, 300, 562, 436, 645, 2182, 1469, 278, 11, 286, 1697, 11, 50752], "temperature": 0.0, "avg_logprob": -0.09359744191169739, "compression_ratio": 1.515923566878981, "no_speech_prob": 0.005217765923589468}, {"id": 463, "seek": 187212, "start": 1880.9199999999998, "end": 1887.4799999999998, "text": " they found that if people were entering in non-English prompts, it was getting around their", "tokens": [50804, 436, 1352, 300, 498, 561, 645, 11104, 294, 2107, 12, 31254, 1933, 41095, 11, 309, 390, 1242, 926, 641, 51132], "temperature": 0.0, "avg_logprob": -0.09359744191169739, "compression_ratio": 1.515923566878981, "no_speech_prob": 0.005217765923589468}, {"id": 464, "seek": 187212, "start": 1887.4799999999998, "end": 1895.6399999999999, "text": " guardrails. I think that was a lot of the delay. If you want to know more about that,", "tokens": [51132, 6290, 424, 4174, 13, 286, 519, 300, 390, 257, 688, 295, 264, 8577, 13, 759, 291, 528, 281, 458, 544, 466, 300, 11, 51540], "temperature": 0.0, "avg_logprob": -0.09359744191169739, "compression_ratio": 1.515923566878981, "no_speech_prob": 0.005217765923589468}, {"id": 465, "seek": 189564, "start": 1896.3600000000001, "end": 1902.68, "text": " heavily documented in my report, that is called Gemini Report,", "tokens": [50400, 10950, 23007, 294, 452, 2275, 11, 300, 307, 1219, 22894, 3812, 16057, 11, 50716], "temperature": 0.0, "avg_logprob": -0.14604389973175833, "compression_ratio": 1.2764227642276422, "no_speech_prob": 0.03513587266206741}, {"id": 466, "seek": 189564, "start": 1905.88, "end": 1911.5600000000002, "text": " as well as the memo for something more up to date. This report was launched in September 2023,", "tokens": [50876, 382, 731, 382, 264, 35900, 337, 746, 544, 493, 281, 4002, 13, 639, 2275, 390, 8730, 294, 7216, 44377, 11, 51160], "temperature": 0.0, "avg_logprob": -0.14604389973175833, "compression_ratio": 1.2764227642276422, "no_speech_prob": 0.03513587266206741}, {"id": 467, "seek": 191156, "start": 1912.28, "end": 1918.76, "text": " and I do keep up to date at a more rapid cadence via the memo.", "tokens": [50400, 293, 286, 360, 1066, 493, 281, 4002, 412, 257, 544, 7558, 46109, 5766, 264, 35900, 13, 50724], "temperature": 0.0, "avg_logprob": -0.1381039397661076, "compression_ratio": 1.373913043478261, "no_speech_prob": 0.07580391317605972}, {"id": 468, "seek": 191156, "start": 1926.9199999999998, "end": 1937.3999999999999, "text": " We did cover the discovery of new materials in the research by DeepMind. We covered that in the", "tokens": [51132, 492, 630, 2060, 264, 12114, 295, 777, 5319, 294, 264, 2132, 538, 14895, 44, 471, 13, 492, 5343, 300, 294, 264, 51656], "temperature": 0.0, "avg_logprob": -0.1381039397661076, "compression_ratio": 1.373913043478261, "no_speech_prob": 0.07580391317605972}, {"id": 469, "seek": 193740, "start": 1937.4, "end": 1944.68, "text": " memo. I don't know if I like this comment interface. That looks pretty broken, doesn't it?", "tokens": [50364, 35900, 13, 286, 500, 380, 458, 498, 286, 411, 341, 2871, 9226, 13, 663, 1542, 1238, 5463, 11, 1177, 380, 309, 30, 50728], "temperature": 0.0, "avg_logprob": -0.15457422733306886, "compression_ratio": 1.3814432989690721, "no_speech_prob": 0.120773084461689}, {"id": 470, "seek": 193740, "start": 1945.3200000000002, "end": 1953.16, "text": " Oh, well, we tried. All right, Yan Lukan. I've been mispronouncing his name this whole time,", "tokens": [50760, 876, 11, 731, 11, 321, 3031, 13, 1057, 558, 11, 13633, 34992, 282, 13, 286, 600, 668, 3346, 1424, 266, 1733, 2175, 702, 1315, 341, 1379, 565, 11, 51152], "temperature": 0.0, "avg_logprob": -0.15457422733306886, "compression_ratio": 1.3814432989690721, "no_speech_prob": 0.120773084461689}, {"id": 471, "seek": 193740, "start": 1954.3600000000001, "end": 1961.48, "text": " but apparently Lukan is closer. AGR being very far away. I don't listen to that guy,", "tokens": [51212, 457, 7970, 34992, 282, 307, 4966, 13, 316, 23971, 885, 588, 1400, 1314, 13, 286, 500, 380, 2140, 281, 300, 2146, 11, 51568], "temperature": 0.0, "avg_logprob": -0.15457422733306886, "compression_ratio": 1.3814432989690721, "no_speech_prob": 0.120773084461689}, {"id": 472, "seek": 196148, "start": 1961.48, "end": 1969.16, "text": " so that's the long and the short of it. He's very much defending his own older view of neural", "tokens": [50364, 370, 300, 311, 264, 938, 293, 264, 2099, 295, 309, 13, 634, 311, 588, 709, 21377, 702, 1065, 4906, 1910, 295, 18161, 50748], "temperature": 0.0, "avg_logprob": -0.08231247646707884, "compression_ratio": 1.4759358288770053, "no_speech_prob": 0.026349054649472237}, {"id": 473, "seek": 196148, "start": 1969.16, "end": 1977.64, "text": " networks. It's not one of the experts that I would be paying attention to. Peter says,", "tokens": [50748, 9590, 13, 467, 311, 406, 472, 295, 264, 8572, 300, 286, 576, 312, 6229, 3202, 281, 13, 6508, 1619, 11, 51172], "temperature": 0.0, "avg_logprob": -0.08231247646707884, "compression_ratio": 1.4759358288770053, "no_speech_prob": 0.026349054649472237}, {"id": 474, "seek": 196148, "start": 1977.64, "end": 1989.16, "text": " when will real AI feel real sentience? I'm just trying to translate your question there, Peter.", "tokens": [51172, 562, 486, 957, 7318, 841, 957, 2279, 1182, 30, 286, 478, 445, 1382, 281, 13799, 428, 1168, 456, 11, 6508, 13, 51748], "temperature": 0.0, "avg_logprob": -0.08231247646707884, "compression_ratio": 1.4759358288770053, "no_speech_prob": 0.026349054649472237}, {"id": 475, "seek": 198916, "start": 1989.88, "end": 1996.76, "text": " We do have our AGI countdown in the background here. We've got lifearchitect.ai slash AGI. It's", "tokens": [50400, 492, 360, 362, 527, 316, 26252, 35985, 294, 264, 3678, 510, 13, 492, 600, 658, 993, 1178, 5739, 13, 1301, 17330, 316, 26252, 13, 467, 311, 50744], "temperature": 0.0, "avg_logprob": -0.12173312601417002, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.02441403642296791}, {"id": 476, "seek": 198916, "start": 1996.76, "end": 2002.92, "text": " not measuring sentience, which is awareness. It's measuring, well, the definition is right here,", "tokens": [50744, 406, 13389, 2279, 1182, 11, 597, 307, 8888, 13, 467, 311, 13389, 11, 731, 11, 264, 7123, 307, 558, 510, 11, 51052], "temperature": 0.0, "avg_logprob": -0.12173312601417002, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.02441403642296791}, {"id": 477, "seek": 198916, "start": 2002.92, "end": 2008.3600000000001, "text": " it's measuring a machine that performs at the level of an average median human. It doesn't", "tokens": [51052, 309, 311, 13389, 257, 3479, 300, 26213, 412, 264, 1496, 295, 364, 4274, 26779, 1952, 13, 467, 1177, 380, 51324], "temperature": 0.0, "avg_logprob": -0.12173312601417002, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.02441403642296791}, {"id": 478, "seek": 198916, "start": 2008.3600000000001, "end": 2014.6000000000001, "text": " mean it has to feel. The feeling part, I don't talk that much about. Jeffrey Hinton does,", "tokens": [51324, 914, 309, 575, 281, 841, 13, 440, 2633, 644, 11, 286, 500, 380, 751, 300, 709, 466, 13, 28721, 389, 12442, 775, 11, 51636], "temperature": 0.0, "avg_logprob": -0.12173312601417002, "compression_ratio": 1.5606694560669456, "no_speech_prob": 0.02441403642296791}, {"id": 479, "seek": 201460, "start": 2015.3999999999999, "end": 2024.76, "text": " sorry, the awareness part, so I might just pause on answering that. You can certainly get it to", "tokens": [50404, 2597, 11, 264, 8888, 644, 11, 370, 286, 1062, 445, 10465, 322, 13430, 300, 13, 509, 393, 3297, 483, 309, 281, 50872], "temperature": 0.0, "avg_logprob": -0.1181012491385142, "compression_ratio": 1.5020746887966805, "no_speech_prob": 0.008314956910908222}, {"id": 480, "seek": 201460, "start": 2024.76, "end": 2030.28, "text": " replicate feelings and emotions, and we did that with Leta for a long time, but you can go and,", "tokens": [50872, 25356, 6640, 293, 8462, 11, 293, 321, 630, 300, 365, 961, 64, 337, 257, 938, 565, 11, 457, 291, 393, 352, 293, 11, 51148], "temperature": 0.0, "avg_logprob": -0.1181012491385142, "compression_ratio": 1.5020746887966805, "no_speech_prob": 0.008314956910908222}, {"id": 481, "seek": 201460, "start": 2030.28, "end": 2034.12, "text": " I'd recommend going playing around with GPT-4 to see what that looks like.", "tokens": [51148, 286, 1116, 2748, 516, 2433, 926, 365, 26039, 51, 12, 19, 281, 536, 437, 300, 1542, 411, 13, 51340], "temperature": 0.0, "avg_logprob": -0.1181012491385142, "compression_ratio": 1.5020746887966805, "no_speech_prob": 0.008314956910908222}, {"id": 482, "seek": 201460, "start": 2036.6799999999998, "end": 2042.6, "text": " Lukas has a flag for us. I remember talking about this last year, meta-solving long-term memory", "tokens": [51468, 34992, 296, 575, 257, 7166, 337, 505, 13, 286, 1604, 1417, 466, 341, 1036, 1064, 11, 19616, 12, 30926, 798, 938, 12, 7039, 4675, 51764], "temperature": 0.0, "avg_logprob": -0.1181012491385142, "compression_ratio": 1.5020746887966805, "no_speech_prob": 0.008314956910908222}, {"id": 483, "seek": 204260, "start": 2042.6, "end": 2050.6, "text": " with Blenderbot 2.0. People are following this path, so the agents that they called this year", "tokens": [50364, 365, 2177, 3216, 18870, 568, 13, 15, 13, 3432, 366, 3480, 341, 3100, 11, 370, 264, 12554, 300, 436, 1219, 341, 1064, 50764], "temperature": 0.0, "avg_logprob": -0.09822150793942538, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.021608080714941025}, {"id": 484, "seek": 204260, "start": 2051.48, "end": 2057.3199999999997, "text": " agentized LLMs that are a complete system use long-term memory in different ways,", "tokens": [50808, 9461, 1602, 441, 43, 26386, 300, 366, 257, 3566, 1185, 764, 938, 12, 7039, 4675, 294, 819, 2098, 11, 51100], "temperature": 0.0, "avg_logprob": -0.09822150793942538, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.021608080714941025}, {"id": 485, "seek": 204260, "start": 2057.3199999999997, "end": 2061.56, "text": " and that's been really interesting to see. You're right, Blenderbot, which is now", "tokens": [51100, 293, 300, 311, 668, 534, 1880, 281, 536, 13, 509, 434, 558, 11, 2177, 3216, 18870, 11, 597, 307, 586, 51312], "temperature": 0.0, "avg_logprob": -0.09822150793942538, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.021608080714941025}, {"id": 486, "seek": 204260, "start": 2061.56, "end": 2067.48, "text": " about three years old, maybe two years old, was doing some fascinating things in storing", "tokens": [51312, 466, 1045, 924, 1331, 11, 1310, 732, 924, 1331, 11, 390, 884, 512, 10343, 721, 294, 26085, 51608], "temperature": 0.0, "avg_logprob": -0.09822150793942538, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.021608080714941025}, {"id": 487, "seek": 206748, "start": 2068.44, "end": 2083.4, "text": " language and information from the conversation or the context into a hard memory. Awesome.", "tokens": [50412, 2856, 293, 1589, 490, 264, 3761, 420, 264, 4319, 666, 257, 1152, 4675, 13, 10391, 13, 51160], "temperature": 0.0, "avg_logprob": -0.16251116449182684, "compression_ratio": 1.3909774436090225, "no_speech_prob": 0.0028893218841403723}, {"id": 488, "seek": 206748, "start": 2088.2, "end": 2095.56, "text": " My definition of AGI has been standard. It's open AI that I've tried to change the definition.", "tokens": [51400, 1222, 7123, 295, 316, 26252, 575, 668, 3832, 13, 467, 311, 1269, 7318, 300, 286, 600, 3031, 281, 1319, 264, 7123, 13, 51768], "temperature": 0.0, "avg_logprob": -0.16251116449182684, "compression_ratio": 1.3909774436090225, "no_speech_prob": 0.0028893218841403723}, {"id": 489, "seek": 209556, "start": 2095.64, "end": 2104.92, "text": " There was some talk about an open AI IP address editing Wikipedia to change the", "tokens": [50368, 821, 390, 512, 751, 466, 364, 1269, 7318, 8671, 2985, 10000, 28999, 281, 1319, 264, 50832], "temperature": 0.0, "avg_logprob": -0.13182698526690084, "compression_ratio": 1.3806818181818181, "no_speech_prob": 0.007936007343232632}, {"id": 490, "seek": 209556, "start": 2104.92, "end": 2110.12, "text": " definition of AGI over the last few weeks around the time of that board coup.", "tokens": [50832, 7123, 295, 316, 26252, 670, 264, 1036, 1326, 3259, 926, 264, 565, 295, 300, 3150, 8682, 13, 51092], "temperature": 0.0, "avg_logprob": -0.13182698526690084, "compression_ratio": 1.3806818181818181, "no_speech_prob": 0.007936007343232632}, {"id": 491, "seek": 209556, "start": 2111.4, "end": 2118.12, "text": " It's been pretty standard. We know AGI is average, median human, ASI is expert human.", "tokens": [51156, 467, 311, 668, 1238, 3832, 13, 492, 458, 316, 26252, 307, 4274, 11, 26779, 1952, 11, 7469, 40, 307, 5844, 1952, 13, 51492], "temperature": 0.0, "avg_logprob": -0.13182698526690084, "compression_ratio": 1.3806818181818181, "no_speech_prob": 0.007936007343232632}, {"id": 492, "seek": 211812, "start": 2118.8399999999997, "end": 2124.3599999999997, "text": " Great question,", "tokens": [50400, 3769, 1168, 11, 50676], "temperature": 0.0, "avg_logprob": -0.18843670895225123, "compression_ratio": 1.433673469387755, "no_speech_prob": 0.020962286740541458}, {"id": 493, "seek": 211812, "start": 2124.3599999999997, "end": 2133.64, "text": " Hernando. I do not have an answer to this one. Is anyone working on zero-proof identity online?", "tokens": [50676, 35651, 1806, 13, 286, 360, 406, 362, 364, 1867, 281, 341, 472, 13, 1119, 2878, 1364, 322, 4018, 12, 15690, 6575, 2950, 30, 51140], "temperature": 0.0, "avg_logprob": -0.18843670895225123, "compression_ratio": 1.433673469387755, "no_speech_prob": 0.020962286740541458}, {"id": 494, "seek": 211812, "start": 2134.6, "end": 2140.2, "text": " Not just Sam's world coin. We did have the scanner here in Sydney at some stage,", "tokens": [51188, 1726, 445, 4832, 311, 1002, 11464, 13, 492, 630, 362, 264, 30211, 510, 294, 21065, 412, 512, 3233, 11, 51468], "temperature": 0.0, "avg_logprob": -0.18843670895225123, "compression_ratio": 1.433673469387755, "no_speech_prob": 0.020962286740541458}, {"id": 495, "seek": 211812, "start": 2141.0, "end": 2145.16, "text": " but otherwise, I don't think there are any scanners in Australia. You have to go over to", "tokens": [51508, 457, 5911, 11, 286, 500, 380, 519, 456, 366, 604, 795, 25792, 294, 7060, 13, 509, 362, 281, 352, 670, 281, 51716], "temperature": 0.0, "avg_logprob": -0.18843670895225123, "compression_ratio": 1.433673469387755, "no_speech_prob": 0.020962286740541458}, {"id": 496, "seek": 214516, "start": 2145.16, "end": 2150.12, "text": " the US for that. I haven't seen anything else on that. I don't follow that to the same extent that", "tokens": [50364, 264, 2546, 337, 300, 13, 286, 2378, 380, 1612, 1340, 1646, 322, 300, 13, 286, 500, 380, 1524, 300, 281, 264, 912, 8396, 300, 50612], "temperature": 0.0, "avg_logprob": -0.07478081517749363, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.007344684563577175}, {"id": 497, "seek": 214516, "start": 2150.12, "end": 2166.68, "text": " I follow LLMs. What are the tests that one will be running to verify AGI versus AI?", "tokens": [50612, 286, 1524, 441, 43, 26386, 13, 708, 366, 264, 6921, 300, 472, 486, 312, 2614, 281, 16888, 316, 26252, 5717, 7318, 30, 51440], "temperature": 0.0, "avg_logprob": -0.07478081517749363, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.007344684563577175}, {"id": 498, "seek": 214516, "start": 2167.48, "end": 2173.3199999999997, "text": " We did cover this pretty heavily last week. It's not just the basis proprietary set that", "tokens": [51480, 492, 630, 2060, 341, 1238, 10950, 1036, 1243, 13, 467, 311, 406, 445, 264, 5143, 38992, 992, 300, 51772], "temperature": 0.0, "avg_logprob": -0.07478081517749363, "compression_ratio": 1.4808743169398908, "no_speech_prob": 0.007344684563577175}, {"id": 499, "seek": 217332, "start": 2173.32, "end": 2178.84, "text": " we've been working on. There are two decent alternatives to that one. The first one,", "tokens": [50364, 321, 600, 668, 1364, 322, 13, 821, 366, 732, 8681, 20478, 281, 300, 472, 13, 440, 700, 472, 11, 50640], "temperature": 0.0, "avg_logprob": -0.15559826434498103, "compression_ratio": 1.3919597989949748, "no_speech_prob": 0.019408900290727615}, {"id": 500, "seek": 217332, "start": 2179.56, "end": 2187.7200000000003, "text": " Gaia by Meta AI and Hugging Face measures median humans at IQ 100 to 120. You can actually have", "tokens": [50676, 10384, 654, 538, 6377, 64, 7318, 293, 46892, 3249, 4047, 8000, 26779, 6255, 412, 28921, 2319, 281, 10411, 13, 509, 393, 767, 362, 51084], "temperature": 0.0, "avg_logprob": -0.15559826434498103, "compression_ratio": 1.3919597989949748, "no_speech_prob": 0.019408900290727615}, {"id": 501, "seek": 217332, "start": 2187.7200000000003, "end": 2194.44, "text": " a look at the questions there that the data set has provided online. They're really kind of fun,", "tokens": [51084, 257, 574, 412, 264, 1651, 456, 300, 264, 1412, 992, 575, 5649, 2950, 13, 814, 434, 534, 733, 295, 1019, 11, 51420], "temperature": 0.0, "avg_logprob": -0.15559826434498103, "compression_ratio": 1.3919597989949748, "no_speech_prob": 0.019408900290727615}, {"id": 502, "seek": 219444, "start": 2194.6, "end": 2203.2400000000002, "text": " actually. See if you can get them. Then there is the Google proof questions and answers for", "tokens": [50372, 767, 13, 3008, 498, 291, 393, 483, 552, 13, 1396, 456, 307, 264, 3329, 8177, 1651, 293, 6338, 337, 50804], "temperature": 0.0, "avg_logprob": -0.16396175018728595, "compression_ratio": 1.4207920792079207, "no_speech_prob": 0.21460282802581787}, {"id": 503, "seek": 219444, "start": 2203.2400000000002, "end": 2211.08, "text": " science experts, generally for PhD and professor level, so above the level of AGI. I'm quite happy", "tokens": [50804, 3497, 8572, 11, 5101, 337, 14476, 293, 8304, 1496, 11, 370, 3673, 264, 1496, 295, 316, 26252, 13, 286, 478, 1596, 2055, 51196], "temperature": 0.0, "avg_logprob": -0.16396175018728595, "compression_ratio": 1.4207920792079207, "no_speech_prob": 0.21460282802581787}, {"id": 504, "seek": 219444, "start": 2211.08, "end": 2217.8, "text": " with the way that Meta framed Gaia. I'm comfortable as an alternative there with GPQ8. Our basis", "tokens": [51196, 365, 264, 636, 300, 6377, 64, 30420, 10384, 654, 13, 286, 478, 4619, 382, 364, 8535, 456, 365, 26039, 48, 23, 13, 2621, 5143, 51532], "temperature": 0.0, "avg_logprob": -0.16396175018728595, "compression_ratio": 1.4207920792079207, "no_speech_prob": 0.21460282802581787}, {"id": 505, "seek": 221780, "start": 2217.8, "end": 2224.84, "text": " suite will come in after that for more intense questions, much more intense questions. We've", "tokens": [50364, 14205, 486, 808, 294, 934, 300, 337, 544, 9447, 1651, 11, 709, 544, 9447, 1651, 13, 492, 600, 50716], "temperature": 0.0, "avg_logprob": -0.08499519263996798, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.17322947084903717}, {"id": 506, "seek": 221780, "start": 2224.84, "end": 2232.04, "text": " got some answer sets being cooked up as we speak. We will have a CSV for download shortly for those", "tokens": [50716, 658, 512, 1867, 6352, 885, 9267, 493, 382, 321, 1710, 13, 492, 486, 362, 257, 48814, 337, 5484, 13392, 337, 729, 51076], "temperature": 0.0, "avg_logprob": -0.08499519263996798, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.17322947084903717}, {"id": 507, "seek": 221780, "start": 2232.04, "end": 2240.6000000000004, "text": " that have tried the first two sample questions. Take it from me. These are too hard for anyone except", "tokens": [51076, 300, 362, 3031, 264, 700, 732, 6889, 1651, 13, 3664, 309, 490, 385, 13, 1981, 366, 886, 1152, 337, 2878, 3993, 51504], "temperature": 0.0, "avg_logprob": -0.08499519263996798, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.17322947084903717}, {"id": 508, "seek": 224060, "start": 2241.56, "end": 2248.2799999999997, "text": " the one in 20 million. I also cannot even get the first part of the question. Then when you see", "tokens": [50412, 264, 472, 294, 945, 2459, 13, 286, 611, 2644, 754, 483, 264, 700, 644, 295, 264, 1168, 13, 1396, 562, 291, 536, 50748], "temperature": 0.0, "avg_logprob": -0.12975105769197706, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.18236690759658813}, {"id": 509, "seek": 224060, "start": 2248.2799999999997, "end": 2255.4, "text": " the explanations for the answers, it's also very difficult for me to understand each step of how", "tokens": [50748, 264, 28708, 337, 264, 6338, 11, 309, 311, 611, 588, 2252, 337, 385, 281, 1223, 1184, 1823, 295, 577, 51104], "temperature": 0.0, "avg_logprob": -0.12975105769197706, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.18236690759658813}, {"id": 510, "seek": 224060, "start": 2255.4, "end": 2263.4, "text": " the answer was obtained. Don't be upset by that. It's literally like asking, if we talk about", "tokens": [51104, 264, 1867, 390, 14879, 13, 1468, 380, 312, 8340, 538, 300, 13, 467, 311, 3736, 411, 3365, 11, 498, 321, 751, 466, 51504], "temperature": 0.0, "avg_logprob": -0.12975105769197706, "compression_ratio": 1.4742268041237114, "no_speech_prob": 0.18236690759658813}, {"id": 511, "seek": 226340, "start": 2263.4, "end": 2273.7200000000003, "text": " IQ for a minute, 180 IQ versus the median human at 100 IQ is a delta of 80 IQ points.", "tokens": [50364, 28921, 337, 257, 3456, 11, 11971, 28921, 5717, 264, 26779, 1952, 412, 2319, 28921, 307, 257, 8289, 295, 4688, 28921, 2793, 13, 50880], "temperature": 0.0, "avg_logprob": -0.10360713137520684, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.25076010823249817}, {"id": 512, "seek": 226340, "start": 2274.92, "end": 2281.7200000000003, "text": " If we did the same thing further down the spectrum, we would find that it's 100 IQ", "tokens": [50940, 759, 321, 630, 264, 912, 551, 3052, 760, 264, 11143, 11, 321, 576, 915, 300, 309, 311, 2319, 28921, 51280], "temperature": 0.0, "avg_logprob": -0.10360713137520684, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.25076010823249817}, {"id": 513, "seek": 226340, "start": 2281.7200000000003, "end": 2292.2000000000003, "text": " trying to talk to a 20 IQ. Now, 20 IQ is legally would be hospitalized, institutionalized, may not", "tokens": [51280, 1382, 281, 751, 281, 257, 945, 28921, 13, 823, 11, 945, 28921, 307, 21106, 576, 312, 42340, 11, 18391, 1602, 11, 815, 406, 51804], "temperature": 0.0, "avg_logprob": -0.10360713137520684, "compression_ratio": 1.467032967032967, "no_speech_prob": 0.25076010823249817}, {"id": 514, "seek": 229220, "start": 2292.2, "end": 2301.72, "text": " be verbal. That's the difference in the deltas there. I can't understand a 180 IQ person or", "tokens": [50364, 312, 24781, 13, 663, 311, 264, 2649, 294, 264, 1103, 83, 296, 456, 13, 286, 393, 380, 1223, 257, 11971, 28921, 954, 420, 50840], "temperature": 0.0, "avg_logprob": -0.09608832383767152, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.04466140642762184}, {"id": 515, "seek": 229220, "start": 2301.72, "end": 2309.16, "text": " how their mind works. Don't be surprised if you can't either because it's like someone with a 20 IQ", "tokens": [50840, 577, 641, 1575, 1985, 13, 1468, 380, 312, 6100, 498, 291, 393, 380, 2139, 570, 309, 311, 411, 1580, 365, 257, 945, 28921, 51212], "temperature": 0.0, "avg_logprob": -0.09608832383767152, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.04466140642762184}, {"id": 516, "seek": 229220, "start": 2309.16, "end": 2315.3999999999996, "text": " and we used to have several words for that that we don't use anymore. But in the DSM, they started", "tokens": [51212, 293, 321, 1143, 281, 362, 2940, 2283, 337, 300, 300, 321, 500, 380, 764, 3602, 13, 583, 294, 264, 15816, 44, 11, 436, 1409, 51524], "temperature": 0.0, "avg_logprob": -0.09608832383767152, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.04466140642762184}, {"id": 517, "seek": 231540, "start": 2315.4, "end": 2322.44, "text": " with the word R or started with the word M. It would be like that 20 IQ person trying to understand", "tokens": [50364, 365, 264, 1349, 497, 420, 1409, 365, 264, 1349, 376, 13, 467, 576, 312, 411, 300, 945, 28921, 954, 1382, 281, 1223, 50716], "temperature": 0.0, "avg_logprob": -0.11010576274297008, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.14408788084983826}, {"id": 518, "seek": 231540, "start": 2323.08, "end": 2331.08, "text": " an average human. It's a pretty intense illustration. But just to give you an example of why these", "tokens": [50748, 364, 4274, 1952, 13, 467, 311, 257, 1238, 9447, 22645, 13, 583, 445, 281, 976, 291, 364, 1365, 295, 983, 613, 51148], "temperature": 0.0, "avg_logprob": -0.11010576274297008, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.14408788084983826}, {"id": 519, "seek": 231540, "start": 2331.08, "end": 2338.92, "text": " questions are so hard to understand at any level. And Jason, Dr. Betts has been having fun with", "tokens": [51148, 1651, 366, 370, 1152, 281, 1223, 412, 604, 1496, 13, 400, 11181, 11, 2491, 13, 6279, 1373, 575, 668, 1419, 1019, 365, 51540], "temperature": 0.0, "avg_logprob": -0.11010576274297008, "compression_ratio": 1.4848484848484849, "no_speech_prob": 0.14408788084983826}, {"id": 520, "seek": 233892, "start": 2338.92, "end": 2346.12, "text": " people have tried to submit questions at the level of maybe 120, 130 IQ. And they're just not", "tokens": [50364, 561, 362, 3031, 281, 10315, 1651, 412, 264, 1496, 295, 1310, 10411, 11, 19966, 28921, 13, 400, 436, 434, 445, 406, 50724], "temperature": 0.0, "avg_logprob": -0.1251242540884709, "compression_ratio": 1.395121951219512, "no_speech_prob": 0.0362124890089035}, {"id": 521, "seek": 233892, "start": 2346.12, "end": 2354.92, "text": " anywhere near what he has designed these questions to be. Excellent. Let's see if we can find a", "tokens": [50724, 4992, 2651, 437, 415, 575, 4761, 613, 1651, 281, 312, 13, 16723, 13, 961, 311, 536, 498, 321, 393, 915, 257, 51164], "temperature": 0.0, "avg_logprob": -0.1251242540884709, "compression_ratio": 1.395121951219512, "no_speech_prob": 0.0362124890089035}, {"id": 522, "seek": 233892, "start": 2354.92, "end": 2363.56, "text": " controversial question here from Zanz. Is it time for OpenAR to change their name with Microsoft", "tokens": [51164, 17323, 1168, 510, 490, 1176, 3910, 13, 1119, 309, 565, 337, 7238, 1899, 281, 1319, 641, 1315, 365, 8116, 51596], "temperature": 0.0, "avg_logprob": -0.1251242540884709, "compression_ratio": 1.395121951219512, "no_speech_prob": 0.0362124890089035}, {"id": 523, "seek": 236356, "start": 2363.56, "end": 2371.64, "text": " and Salesforce taking board positions? Mm hmm. Excellent. Some would say that they should have", "tokens": [50364, 293, 40398, 1940, 3150, 8432, 30, 8266, 16478, 13, 16723, 13, 2188, 576, 584, 300, 436, 820, 362, 50768], "temperature": 0.0, "avg_logprob": -0.19894388447637143, "compression_ratio": 1.2635135135135136, "no_speech_prob": 0.045341819524765015}, {"id": 524, "seek": 236356, "start": 2371.64, "end": 2377.56, "text": " changed their name a few years ago. They've been around since 2016 ish, maybe, maybe before.", "tokens": [50768, 3105, 641, 1315, 257, 1326, 924, 2057, 13, 814, 600, 668, 926, 1670, 6549, 307, 71, 11, 1310, 11, 1310, 949, 13, 51064], "temperature": 0.0, "avg_logprob": -0.19894388447637143, "compression_ratio": 1.2635135135135136, "no_speech_prob": 0.045341819524765015}, {"id": 525, "seek": 237756, "start": 2378.44, "end": 2395.64, "text": " There was some interesting talk about Qstar. It's still not something that I'm going to cover.", "tokens": [50408, 821, 390, 512, 1880, 751, 466, 1249, 9710, 13, 467, 311, 920, 406, 746, 300, 286, 478, 516, 281, 2060, 13, 51268], "temperature": 0.0, "avg_logprob": -0.19819484873020904, "compression_ratio": 1.5234375, "no_speech_prob": 0.016400406137108803}, {"id": 526, "seek": 237756, "start": 2396.44, "end": 2404.92, "text": " But it's been fascinating to see the way this has been covered and the way this has been interpreted", "tokens": [51308, 583, 309, 311, 668, 10343, 281, 536, 264, 636, 341, 575, 668, 5343, 293, 264, 636, 341, 575, 668, 26749, 51732], "temperature": 0.0, "avg_logprob": -0.19819484873020904, "compression_ratio": 1.5234375, "no_speech_prob": 0.016400406137108803}, {"id": 527, "seek": 240492, "start": 2404.92, "end": 2420.36, "text": " because now my comments have broken completely because the CEO of OpenAR didn't actually say very", "tokens": [50364, 570, 586, 452, 3053, 362, 5463, 2584, 570, 264, 9282, 295, 7238, 1899, 994, 380, 767, 584, 588, 51136], "temperature": 0.0, "avg_logprob": -0.16798502748662775, "compression_ratio": 1.0898876404494382, "no_speech_prob": 0.0026315634604543447}, {"id": 528, "seek": 242036, "start": 2420.36, "end": 2428.28, "text": " much about Qstar and yet people have read into that in quite interesting ways.", "tokens": [50364, 709, 466, 1249, 9710, 293, 1939, 561, 362, 1401, 666, 300, 294, 1596, 1880, 2098, 13, 50760], "temperature": 0.0, "avg_logprob": -0.1646079699198405, "compression_ratio": 1.1717171717171717, "no_speech_prob": 0.07565423101186752}, {"id": 529, "seek": 242036, "start": 2431.48, "end": 2437.6400000000003, "text": " Yes, managed to completely obliterate", "tokens": [50920, 1079, 11, 6453, 281, 2584, 23740, 1681, 473, 51228], "temperature": 0.0, "avg_logprob": -0.1646079699198405, "compression_ratio": 1.1717171717171717, "no_speech_prob": 0.07565423101186752}, {"id": 530, "seek": 243764, "start": 2437.7999999999997, "end": 2448.2, "text": " my comments. Or maybe it's just yours, right? Won't be shown. Sorry, mate.", "tokens": [50372, 452, 3053, 13, 1610, 1310, 309, 311, 445, 6342, 11, 558, 30, 14710, 380, 312, 4898, 13, 4919, 11, 11709, 13, 50892], "temperature": 0.0, "avg_logprob": -0.24928693902002622, "compression_ratio": 1.3903743315508021, "no_speech_prob": 0.03158175200223923}, {"id": 531, "seek": 243764, "start": 2452.44, "end": 2458.68, "text": " All right. Thinkrinessity has a related question here once again. I'm not even going to be able", "tokens": [51104, 1057, 558, 13, 6557, 81, 1324, 507, 575, 257, 4077, 1168, 510, 1564, 797, 13, 286, 478, 406, 754, 516, 281, 312, 1075, 51416], "temperature": 0.0, "avg_logprob": -0.24928693902002622, "compression_ratio": 1.3903743315508021, "no_speech_prob": 0.03158175200223923}, {"id": 532, "seek": 243764, "start": 2458.68, "end": 2464.68, "text": " to grab it, unfortunately. So let's use our old way of doing things. A detailed method of", "tokens": [51416, 281, 4444, 309, 11, 7015, 13, 407, 718, 311, 764, 527, 1331, 636, 295, 884, 721, 13, 316, 9942, 3170, 295, 51716], "temperature": 0.0, "avg_logprob": -0.24928693902002622, "compression_ratio": 1.3903743315508021, "no_speech_prob": 0.03158175200223923}, {"id": 533, "seek": 246468, "start": 2464.68, "end": 2468.52, "text": " creation securing a question sets. How do we know the questions haven't been shared before", "tokens": [50364, 8016, 33640, 257, 1168, 6352, 13, 1012, 360, 321, 458, 264, 1651, 2378, 380, 668, 5507, 949, 50556], "temperature": 0.0, "avg_logprob": -0.1347770271720467, "compression_ratio": 1.695852534562212, "no_speech_prob": 0.014060906134545803}, {"id": 534, "seek": 246468, "start": 2468.52, "end": 2474.7599999999998, "text": " testing it to a model? Well, go and read the basis page. It says questions are created offline.", "tokens": [50556, 4997, 309, 281, 257, 2316, 30, 1042, 11, 352, 293, 1401, 264, 5143, 3028, 13, 467, 1619, 1651, 366, 2942, 21857, 13, 50868], "temperature": 0.0, "avg_logprob": -0.1347770271720467, "compression_ratio": 1.695852534562212, "no_speech_prob": 0.014060906134545803}, {"id": 535, "seek": 246468, "start": 2474.7599999999998, "end": 2479.72, "text": " They're air-gapped. They're never shared. The first time that I take them out of the envelope", "tokens": [50868, 814, 434, 1988, 12, 70, 20780, 13, 814, 434, 1128, 5507, 13, 440, 700, 565, 300, 286, 747, 552, 484, 295, 264, 19989, 51116], "temperature": 0.0, "avg_logprob": -0.1347770271720467, "compression_ratio": 1.695852534562212, "no_speech_prob": 0.014060906134545803}, {"id": 536, "seek": 246468, "start": 2483.7999999999997, "end": 2493.08, "text": " is the first time that they're seen. This is the actual hyper-compliant envelope locked", "tokens": [51320, 307, 264, 700, 565, 300, 436, 434, 1612, 13, 639, 307, 264, 3539, 9848, 12, 43856, 5798, 19989, 9376, 51784], "temperature": 0.0, "avg_logprob": -0.1347770271720467, "compression_ratio": 1.695852534562212, "no_speech_prob": 0.014060906134545803}, {"id": 537, "seek": 249308, "start": 2494.04, "end": 2502.12, "text": " and Dr. Betts posts the questions that have been handwritten in a room. Pencil and paper,", "tokens": [50412, 293, 2491, 13, 6279, 1373, 12300, 264, 1651, 300, 362, 668, 1011, 26859, 294, 257, 1808, 13, 10571, 3208, 293, 3035, 11, 50816], "temperature": 0.0, "avg_logprob": -0.1211575173042916, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.002714790403842926}, {"id": 538, "seek": 249308, "start": 2502.12, "end": 2508.7599999999998, "text": " straight from his head, pencil and paper into a locked bag. They get opened once used either live", "tokens": [50816, 2997, 490, 702, 1378, 11, 10985, 293, 3035, 666, 257, 9376, 3411, 13, 814, 483, 5625, 1564, 1143, 2139, 1621, 51148], "temperature": 0.0, "avg_logprob": -0.1211575173042916, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.002714790403842926}, {"id": 539, "seek": 249308, "start": 2508.7599999999998, "end": 2516.6, "text": " on air or via a lab like Microsoft OpenAI, Google, and that's it. They're retired immediately. So", "tokens": [51148, 322, 1988, 420, 5766, 257, 2715, 411, 8116, 7238, 48698, 11, 3329, 11, 293, 300, 311, 309, 13, 814, 434, 16776, 4258, 13, 407, 51540], "temperature": 0.0, "avg_logprob": -0.1211575173042916, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.002714790403842926}, {"id": 540, "seek": 251660, "start": 2516.68, "end": 2521.16, "text": " please have a read of the page before asking questions. Yep.", "tokens": [50368, 1767, 362, 257, 1401, 295, 264, 3028, 949, 3365, 1651, 13, 7010, 13, 50592], "temperature": 0.0, "avg_logprob": -0.11204550483010033, "compression_ratio": 1.3825136612021858, "no_speech_prob": 0.0011335238814353943}, {"id": 541, "seek": 251660, "start": 2528.36, "end": 2535.24, "text": " Oh, I've got some related queries about IQ. I know it's a fascinating subject for a lot of people.", "tokens": [50952, 876, 11, 286, 600, 658, 512, 4077, 24109, 466, 28921, 13, 286, 458, 309, 311, 257, 10343, 3983, 337, 257, 688, 295, 561, 13, 51296], "temperature": 0.0, "avg_logprob": -0.11204550483010033, "compression_ratio": 1.3825136612021858, "no_speech_prob": 0.0011335238814353943}, {"id": 542, "seek": 251660, "start": 2535.24, "end": 2544.92, "text": " Let's grab Lucas's query here. A theoretical limit on IQ. So it's really needing a statistics", "tokens": [51296, 961, 311, 4444, 19178, 311, 14581, 510, 13, 316, 20864, 4948, 322, 28921, 13, 407, 309, 311, 534, 18006, 257, 12523, 51780], "temperature": 0.0, "avg_logprob": -0.11204550483010033, "compression_ratio": 1.3825136612021858, "no_speech_prob": 0.0011335238814353943}, {"id": 543, "seek": 254492, "start": 2545.4, "end": 2555.32, "text": " background to understand this. IQ basically aligns with standard distributions.", "tokens": [50388, 3678, 281, 1223, 341, 13, 28921, 1936, 7975, 82, 365, 3832, 37870, 13, 50884], "temperature": 0.0, "avg_logprob": -0.17088587691144244, "compression_ratio": 1.3442622950819672, "no_speech_prob": 0.014501728117465973}, {"id": 544, "seek": 254492, "start": 2559.8, "end": 2565.96, "text": " So our, let's grab a little, let's grab a pretty picture here for us, for ourselves,", "tokens": [51108, 407, 527, 11, 718, 311, 4444, 257, 707, 11, 718, 311, 4444, 257, 1238, 3036, 510, 337, 505, 11, 337, 4175, 11, 51416], "temperature": 0.0, "avg_logprob": -0.17088587691144244, "compression_ratio": 1.3442622950819672, "no_speech_prob": 0.014501728117465973}, {"id": 545, "seek": 256596, "start": 2566.6, "end": 2576.44, "text": " lifearchitect.ai slash IQ testing AI. And then that's not even the one I want.", "tokens": [50396, 993, 1178, 5739, 13, 1301, 17330, 28921, 4997, 7318, 13, 400, 550, 300, 311, 406, 754, 264, 472, 286, 528, 13, 50888], "temperature": 0.0, "avg_logprob": -0.14565284729003905, "compression_ratio": 1.3203125, "no_speech_prob": 0.12249689549207687}, {"id": 546, "seek": 256596, "start": 2577.0, "end": 2579.48, "text": " We actually want visualizing brightness.", "tokens": [50916, 492, 767, 528, 5056, 3319, 21367, 13, 51040], "temperature": 0.0, "avg_logprob": -0.14565284729003905, "compression_ratio": 1.3203125, "no_speech_prob": 0.12249689549207687}, {"id": 547, "seek": 256596, "start": 2583.88, "end": 2586.28, "text": " I'm glad that that's on the top of my menu there.", "tokens": [51260, 286, 478, 5404, 300, 300, 311, 322, 264, 1192, 295, 452, 6510, 456, 13, 51380], "temperature": 0.0, "avg_logprob": -0.14565284729003905, "compression_ratio": 1.3203125, "no_speech_prob": 0.12249689549207687}, {"id": 548, "seek": 258628, "start": 2586.6000000000004, "end": 2597.2400000000002, "text": " This is my standard IQ chart that shows what's going on with IQ in an easier to understand", "tokens": [50380, 639, 307, 452, 3832, 28921, 6927, 300, 3110, 437, 311, 516, 322, 365, 28921, 294, 364, 3571, 281, 1223, 50912], "temperature": 0.0, "avg_logprob": -0.14080798987186316, "compression_ratio": 1.4619565217391304, "no_speech_prob": 0.0039450484327971935}, {"id": 549, "seek": 258628, "start": 2597.2400000000002, "end": 2605.4, "text": " way. I believe so. Anyway, they renorm the entire, let's say IQ score and align the population", "tokens": [50912, 636, 13, 286, 1697, 370, 13, 5684, 11, 436, 8124, 687, 264, 2302, 11, 718, 311, 584, 28921, 6175, 293, 7975, 264, 4415, 51320], "temperature": 0.0, "avg_logprob": -0.14080798987186316, "compression_ratio": 1.4619565217391304, "no_speech_prob": 0.0039450484327971935}, {"id": 550, "seek": 258628, "start": 2605.4, "end": 2612.2000000000003, "text": " every few years so that the baseline is 100. And then using standard distributions,", "tokens": [51320, 633, 1326, 924, 370, 300, 264, 20518, 307, 2319, 13, 400, 550, 1228, 3832, 37870, 11, 51660], "temperature": 0.0, "avg_logprob": -0.14080798987186316, "compression_ratio": 1.4619565217391304, "no_speech_prob": 0.0039450484327971935}, {"id": 551, "seek": 261220, "start": 2612.7599999999998, "end": 2619.3999999999996, "text": " they say, let's grab our 15 standard distributions above and below that", "tokens": [50392, 436, 584, 11, 718, 311, 4444, 527, 2119, 3832, 37870, 3673, 293, 2507, 300, 50724], "temperature": 0.0, "avg_logprob": -0.09106093361264184, "compression_ratio": 1.3705882352941177, "no_speech_prob": 0.003075201762840152}, {"id": 552, "seek": 261220, "start": 2622.6, "end": 2630.04, "text": " to come up with essentially our IQ. If you were to get up to 500, that would be pretty", "tokens": [50884, 281, 808, 493, 365, 4476, 527, 28921, 13, 759, 291, 645, 281, 483, 493, 281, 5923, 11, 300, 576, 312, 1238, 51256], "temperature": 0.0, "avg_logprob": -0.09106093361264184, "compression_ratio": 1.3705882352941177, "no_speech_prob": 0.003075201762840152}, {"id": 553, "seek": 261220, "start": 2630.04, "end": 2636.04, "text": " ludicrous. Is there a better way of me explaining this one? Let's see now.", "tokens": [51256, 15946, 299, 21189, 13, 1119, 456, 257, 1101, 636, 295, 385, 13468, 341, 472, 30, 961, 311, 536, 586, 13, 51556], "temperature": 0.0, "avg_logprob": -0.09106093361264184, "compression_ratio": 1.3705882352941177, "no_speech_prob": 0.003075201762840152}, {"id": 554, "seek": 263604, "start": 2636.92, "end": 2640.52, "text": " Sorry, standard deviation.", "tokens": [50408, 4919, 11, 3832, 25163, 13, 50588], "temperature": 0.0, "avg_logprob": -0.13861408940067999, "compression_ratio": 1.4652777777777777, "no_speech_prob": 0.0020506870932877064}, {"id": 555, "seek": 263604, "start": 2645.24, "end": 2651.56, "text": " I don't know if we would get to an IQ of 500. I don't even know if that would align with the", "tokens": [50824, 286, 500, 380, 458, 498, 321, 576, 483, 281, 364, 28921, 295, 5923, 13, 286, 500, 380, 754, 458, 498, 300, 576, 7975, 365, 264, 51140], "temperature": 0.0, "avg_logprob": -0.13861408940067999, "compression_ratio": 1.4652777777777777, "no_speech_prob": 0.0020506870932877064}, {"id": 556, "seek": 263604, "start": 2651.56, "end": 2658.84, "text": " statistical distribution of the population. But when we're 15 standard deviations above the", "tokens": [51140, 22820, 7316, 295, 264, 4415, 13, 583, 562, 321, 434, 2119, 3832, 31219, 763, 3673, 264, 51504], "temperature": 0.0, "avg_logprob": -0.13861408940067999, "compression_ratio": 1.4652777777777777, "no_speech_prob": 0.0020506870932877064}, {"id": 557, "seek": 265884, "start": 2658.84, "end": 2670.52, "text": " norm, we get to about, where are we here? We get to about our 180 ish and it's showing a little", "tokens": [50364, 2026, 11, 321, 483, 281, 466, 11, 689, 366, 321, 510, 30, 492, 483, 281, 466, 527, 11971, 307, 71, 293, 309, 311, 4099, 257, 707, 50948], "temperature": 0.0, "avg_logprob": -0.11452474349584335, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.01798434928059578}, {"id": 558, "seek": 265884, "start": 2670.52, "end": 2678.04, "text": " bit differently here. But basically, the answer is no. The highest IQ we've ever measured is", "tokens": [50948, 857, 7614, 510, 13, 583, 1936, 11, 264, 1867, 307, 572, 13, 440, 6343, 28921, 321, 600, 1562, 12690, 307, 51324], "temperature": 0.0, "avg_logprob": -0.11452474349584335, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.01798434928059578}, {"id": 559, "seek": 265884, "start": 2678.04, "end": 2685.96, "text": " about 298, which is many, many standard deviations above the norm. And to get above that, I just", "tokens": [51324, 466, 9413, 23, 11, 597, 307, 867, 11, 867, 3832, 31219, 763, 3673, 264, 2026, 13, 400, 281, 483, 3673, 300, 11, 286, 445, 51720], "temperature": 0.0, "avg_logprob": -0.11452474349584335, "compression_ratio": 1.4467005076142132, "no_speech_prob": 0.01798434928059578}, {"id": 560, "seek": 268596, "start": 2685.96, "end": 2692.92, "text": " don't think there's the population to be able to say we're confident that in eight billion people", "tokens": [50364, 500, 380, 519, 456, 311, 264, 4415, 281, 312, 1075, 281, 584, 321, 434, 6679, 300, 294, 3180, 5218, 561, 50712], "temperature": 0.0, "avg_logprob": -0.15847894742891386, "compression_ratio": 1.5396825396825398, "no_speech_prob": 0.0037070054095238447}, {"id": 561, "seek": 268596, "start": 2692.92, "end": 2699.4, "text": " that you sit in this percentile. That was a pretty messy explanation, but it's 8.30 a.m. here.", "tokens": [50712, 300, 291, 1394, 294, 341, 3043, 794, 13, 663, 390, 257, 1238, 16191, 10835, 11, 457, 309, 311, 1649, 13, 3446, 257, 13, 76, 13, 510, 13, 51036], "temperature": 0.0, "avg_logprob": -0.15847894742891386, "compression_ratio": 1.5396825396825398, "no_speech_prob": 0.0037070054095238447}, {"id": 562, "seek": 268596, "start": 2702.04, "end": 2710.44, "text": " And it's a pretty messy, it's a pretty messy field actually. Statistics is clean. But when applied", "tokens": [51168, 400, 309, 311, 257, 1238, 16191, 11, 309, 311, 257, 1238, 16191, 2519, 767, 13, 49226, 307, 2541, 13, 583, 562, 6456, 51588], "temperature": 0.0, "avg_logprob": -0.15847894742891386, "compression_ratio": 1.5396825396825398, "no_speech_prob": 0.0037070054095238447}, {"id": 563, "seek": 271044, "start": 2710.44, "end": 2716.6, "text": " to humans, it becomes pretty interesting. Great question though. IQ of 500 would be", "tokens": [50364, 281, 6255, 11, 309, 3643, 1238, 1880, 13, 3769, 1168, 1673, 13, 28921, 295, 5923, 576, 312, 50672], "temperature": 0.0, "avg_logprob": -0.08098138360416188, "compression_ratio": 1.5355648535564854, "no_speech_prob": 0.014062486588954926}, {"id": 564, "seek": 271044, "start": 2716.6, "end": 2721.8, "text": " interesting. We've tried to also keep it pretty smooth and pretty clean in the basis assessment,", "tokens": [50672, 1880, 13, 492, 600, 3031, 281, 611, 1066, 309, 1238, 5508, 293, 1238, 2541, 294, 264, 5143, 9687, 11, 50932], "temperature": 0.0, "avg_logprob": -0.08098138360416188, "compression_ratio": 1.5355648535564854, "no_speech_prob": 0.014062486588954926}, {"id": 565, "seek": 271044, "start": 2721.8, "end": 2729.64, "text": " just saying we're looking at the top 0.0005%. And that is how we'll know that we've achieved", "tokens": [50932, 445, 1566, 321, 434, 1237, 412, 264, 1192, 1958, 13, 1360, 20, 6856, 400, 300, 307, 577, 321, 603, 458, 300, 321, 600, 11042, 51324], "temperature": 0.0, "avg_logprob": -0.08098138360416188, "compression_ratio": 1.5355648535564854, "no_speech_prob": 0.014062486588954926}, {"id": 566, "seek": 271044, "start": 2729.64, "end": 2737.0, "text": " artificial superintelligence, a machine that functions at the expert level across practically", "tokens": [51324, 11677, 1687, 20761, 17644, 11, 257, 3479, 300, 6828, 412, 264, 5844, 1496, 2108, 15667, 51692], "temperature": 0.0, "avg_logprob": -0.08098138360416188, "compression_ratio": 1.5355648535564854, "no_speech_prob": 0.014062486588954926}, {"id": 567, "seek": 273700, "start": 2737.0, "end": 2741.48, "text": " any field. I can't wait. And I think it's going to be pretty close. Let's see where we're at.", "tokens": [50364, 604, 2519, 13, 286, 393, 380, 1699, 13, 400, 286, 519, 309, 311, 516, 281, 312, 1238, 1998, 13, 961, 311, 536, 689, 321, 434, 412, 13, 50588], "temperature": 0.0, "avg_logprob": -0.11029717528704301, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.004754768684506416}, {"id": 568, "seek": 273700, "start": 2747.08, "end": 2753.4, "text": " The definition for AGI has stayed static on that site. And that's the standard definition.", "tokens": [50868, 440, 7123, 337, 316, 26252, 575, 9181, 13437, 322, 300, 3621, 13, 400, 300, 311, 264, 3832, 7123, 13, 51184], "temperature": 0.0, "avg_logprob": -0.11029717528704301, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.004754768684506416}, {"id": 569, "seek": 273700, "start": 2753.4, "end": 2759.88, "text": " Let's grab John's query here. I am. My help is to realize tech like the Star Trek Replicator. Cool.", "tokens": [51184, 961, 311, 4444, 2619, 311, 14581, 510, 13, 286, 669, 13, 1222, 854, 307, 281, 4325, 7553, 411, 264, 5705, 25845, 1300, 4770, 1639, 13, 8561, 13, 51508], "temperature": 0.0, "avg_logprob": -0.11029717528704301, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.004754768684506416}, {"id": 570, "seek": 273700, "start": 2761.56, "end": 2766.92, "text": " There'll be many, many, many other benefits of artificial intelligence. I'm in the early stages", "tokens": [51592, 821, 603, 312, 867, 11, 867, 11, 867, 661, 5311, 295, 11677, 7599, 13, 286, 478, 294, 264, 2440, 10232, 51860], "temperature": 0.0, "avg_logprob": -0.11029717528704301, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.004754768684506416}, {"id": 571, "seek": 276692, "start": 2767.0, "end": 2776.12, "text": " of my end of year AI report. And I'm pretty excited about this one. We do spell out some of the", "tokens": [50368, 295, 452, 917, 295, 1064, 7318, 2275, 13, 400, 286, 478, 1238, 2919, 466, 341, 472, 13, 492, 360, 9827, 484, 512, 295, 264, 50824], "temperature": 0.0, "avg_logprob": -0.07972594017678118, "compression_ratio": 1.5690376569037656, "no_speech_prob": 0.0009110159007832408}, {"id": 572, "seek": 276692, "start": 2776.12, "end": 2781.96, "text": " benefits, the coming benefits and the present opportunities of artificial intelligence. It's", "tokens": [50824, 5311, 11, 264, 1348, 5311, 293, 264, 1974, 4786, 295, 11677, 7599, 13, 467, 311, 51116], "temperature": 0.0, "avg_logprob": -0.07972594017678118, "compression_ratio": 1.5690376569037656, "no_speech_prob": 0.0009110159007832408}, {"id": 573, "seek": 276692, "start": 2781.96, "end": 2786.6, "text": " a lot of fun to see that laid out. Not a lot of people lay that out. Instead, they focus on", "tokens": [51116, 257, 688, 295, 1019, 281, 536, 300, 9897, 484, 13, 1726, 257, 688, 295, 561, 2360, 300, 484, 13, 7156, 11, 436, 1879, 322, 51348], "temperature": 0.0, "avg_logprob": -0.07972594017678118, "compression_ratio": 1.5690376569037656, "no_speech_prob": 0.0009110159007832408}, {"id": 574, "seek": 276692, "start": 2787.4, "end": 2796.6800000000003, "text": " the 0% chance of an extinction event via AI. Awesome question there, John. Thank you for that.", "tokens": [51388, 264, 1958, 4, 2931, 295, 364, 33163, 2280, 5766, 7318, 13, 10391, 1168, 456, 11, 2619, 13, 1044, 291, 337, 300, 13, 51852], "temperature": 0.0, "avg_logprob": -0.07972594017678118, "compression_ratio": 1.5690376569037656, "no_speech_prob": 0.0009110159007832408}, {"id": 575, "seek": 279692, "start": 2796.92, "end": 2818.6800000000003, "text": " Let's see if I can unkill this comment thing. Nope. It's going to stay exactly as it was.", "tokens": [50388, 961, 311, 536, 498, 286, 393, 517, 34213, 341, 2871, 551, 13, 12172, 13, 467, 311, 516, 281, 1754, 2293, 382, 309, 390, 13, 51452], "temperature": 0.0, "avg_logprob": -0.2774670388963487, "compression_ratio": 1.072289156626506, "no_speech_prob": 0.017165319994091988}, {"id": 576, "seek": 282692, "start": 2827.8, "end": 2831.7200000000003, "text": " Zan's excellent question. I'm covering this in the next edition of the memo. The", "tokens": [50408, 1176, 282, 311, 7103, 1168, 13, 286, 478, 10322, 341, 294, 264, 958, 11377, 295, 264, 35900, 13, 440, 50604], "temperature": 0.0, "avg_logprob": -0.14032628162797675, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.03513399139046669}, {"id": 577, "seek": 282692, "start": 2833.16, "end": 2840.28, "text": " senator, and she's actually the US secretary, going on record with a pretty horrific quote", "tokens": [50676, 24664, 11, 293, 750, 311, 767, 264, 2546, 15691, 11, 516, 322, 2136, 365, 257, 1238, 29248, 6513, 51032], "temperature": 0.0, "avg_logprob": -0.14032628162797675, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.03513399139046669}, {"id": 578, "seek": 282692, "start": 2840.28, "end": 2848.12, "text": " about this was shocking to me. They are playing really strange geopolitical games,", "tokens": [51032, 466, 341, 390, 18776, 281, 385, 13, 814, 366, 2433, 534, 5861, 46615, 804, 2813, 11, 51424], "temperature": 0.0, "avg_logprob": -0.14032628162797675, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.03513399139046669}, {"id": 579, "seek": 282692, "start": 2849.16, "end": 2852.6800000000003, "text": " but they've just come out and she's just come out and said, we're going to keep", "tokens": [51476, 457, 436, 600, 445, 808, 484, 293, 750, 311, 445, 808, 484, 293, 848, 11, 321, 434, 516, 281, 1066, 51652], "temperature": 0.0, "avg_logprob": -0.14032628162797675, "compression_ratio": 1.5754716981132075, "no_speech_prob": 0.03513399139046669}, {"id": 580, "seek": 285268, "start": 2853.3199999999997, "end": 2863.48, "text": " passing new laws and putting new restrictions on Nvidia in particular, trying to rebrand,", "tokens": [50396, 8437, 777, 6064, 293, 3372, 777, 14191, 322, 46284, 294, 1729, 11, 1382, 281, 12970, 3699, 11, 50904], "temperature": 0.0, "avg_logprob": -0.19125626303932883, "compression_ratio": 1.4270833333333333, "no_speech_prob": 0.03066392056643963}, {"id": 581, "seek": 285268, "start": 2864.04, "end": 2872.7599999999998, "text": " relabel and maybe very slightly hamstring or handicap GPUs so that they can export to China", "tokens": [50932, 1039, 18657, 293, 1310, 588, 4748, 7852, 37045, 420, 45975, 18407, 82, 370, 300, 436, 393, 10725, 281, 3533, 51368], "temperature": 0.0, "avg_logprob": -0.19125626303932883, "compression_ratio": 1.4270833333333333, "no_speech_prob": 0.03066392056643963}, {"id": 582, "seek": 285268, "start": 2872.7599999999998, "end": 2880.6, "text": " under the current rules, which basically says no A100s, no H100s. So Nvidia renamed them and", "tokens": [51368, 833, 264, 2190, 4474, 11, 597, 1936, 1619, 572, 316, 6879, 82, 11, 572, 389, 6879, 82, 13, 407, 46284, 40949, 552, 293, 51760], "temperature": 0.0, "avg_logprob": -0.19125626303932883, "compression_ratio": 1.4270833333333333, "no_speech_prob": 0.03066392056643963}, {"id": 583, "seek": 288268, "start": 2882.7599999999998, "end": 2889.7999999999997, "text": " decreased the throughput slightly on those cards. Yeah, we go into big detail on the next", "tokens": [50368, 24436, 264, 44629, 4748, 322, 729, 5632, 13, 865, 11, 321, 352, 666, 955, 2607, 322, 264, 958, 50720], "temperature": 0.0, "avg_logprob": -0.11074714518305082, "compression_ratio": 1.4754098360655739, "no_speech_prob": 0.0032726633362472057}, {"id": 584, "seek": 288268, "start": 2889.7999999999997, "end": 2895.08, "text": " edition of the memo for that one because it's a fun conversation to see where they got to", "tokens": [50720, 11377, 295, 264, 35900, 337, 300, 472, 570, 309, 311, 257, 1019, 3761, 281, 536, 689, 436, 658, 281, 50984], "temperature": 0.0, "avg_logprob": -0.11074714518305082, "compression_ratio": 1.4754098360655739, "no_speech_prob": 0.0032726633362472057}, {"id": 585, "seek": 288268, "start": 2895.08, "end": 2907.48, "text": " and what that looks like in the global arena. A50 plus 50, yeah, it's something like that.", "tokens": [50984, 293, 437, 300, 1542, 411, 294, 264, 4338, 18451, 13, 316, 2803, 1804, 2625, 11, 1338, 11, 309, 311, 746, 411, 300, 13, 51604], "temperature": 0.0, "avg_logprob": -0.11074714518305082, "compression_ratio": 1.4754098360655739, "no_speech_prob": 0.0032726633362472057}, {"id": 586, "seek": 291268, "start": 2912.68, "end": 2925.7999999999997, "text": " Jeff, he's got a question for us. When would you predict the arrival of multimodal LLMs that", "tokens": [50364, 7506, 11, 415, 311, 658, 257, 1168, 337, 505, 13, 1133, 576, 291, 6069, 264, 18365, 295, 32972, 378, 304, 441, 43, 26386, 300, 51020], "temperature": 0.0, "avg_logprob": -0.22382989883422852, "compression_ratio": 1.277027027027027, "no_speech_prob": 0.0037061998154968023}, {"id": 587, "seek": 291268, "start": 2925.7999999999997, "end": 2936.68, "text": " can watch for or listen for no text events? This is already happening and GPT five in particular", "tokens": [51020, 393, 1159, 337, 420, 2140, 337, 572, 2487, 3931, 30, 639, 307, 1217, 2737, 293, 26039, 51, 1732, 294, 1729, 51564], "temperature": 0.0, "avg_logprob": -0.22382989883422852, "compression_ratio": 1.277027027027027, "no_speech_prob": 0.0037061998154968023}, {"id": 588, "seek": 293668, "start": 2936.68, "end": 2944.9199999999996, "text": " will be training on YouTube content. GPT four also trained on YouTube content and it's one of", "tokens": [50364, 486, 312, 3097, 322, 3088, 2701, 13, 26039, 51, 1451, 611, 8895, 322, 3088, 2701, 293, 309, 311, 472, 295, 50776], "temperature": 0.0, "avg_logprob": -0.07825387659527007, "compression_ratio": 1.7024390243902439, "no_speech_prob": 0.7714654207229614}, {"id": 589, "seek": 293668, "start": 2944.9199999999996, "end": 2950.7599999999998, "text": " the reasons that we were so careful with the design of the basis testing suite for ASI", "tokens": [50776, 264, 4112, 300, 321, 645, 370, 5026, 365, 264, 1715, 295, 264, 5143, 4997, 14205, 337, 7469, 40, 51068], "temperature": 0.0, "avg_logprob": -0.07825387659527007, "compression_ratio": 1.7024390243902439, "no_speech_prob": 0.7714654207229614}, {"id": 590, "seek": 293668, "start": 2951.3999999999996, "end": 2958.7599999999998, "text": " was that we are pretty certain that it will be training on YouTube. So the 14th of June,", "tokens": [51100, 390, 300, 321, 366, 1238, 1629, 300, 309, 486, 312, 3097, 322, 3088, 13, 407, 264, 3499, 392, 295, 6928, 11, 51468], "temperature": 0.0, "avg_logprob": -0.07825387659527007, "compression_ratio": 1.7024390243902439, "no_speech_prob": 0.7714654207229614}, {"id": 591, "seek": 293668, "start": 2959.3999999999996, "end": 2965.3999999999996, "text": " there was some information that YouTube was used to train some of their models.", "tokens": [51500, 456, 390, 512, 1589, 300, 3088, 390, 1143, 281, 3847, 512, 295, 641, 5245, 13, 51800], "temperature": 0.0, "avg_logprob": -0.07825387659527007, "compression_ratio": 1.7024390243902439, "no_speech_prob": 0.7714654207229614}, {"id": 592, "seek": 296540, "start": 2966.04, "end": 2970.6800000000003, "text": " Secretly use data from the YouTube site to train some of its artificial intelligence models.", "tokens": [50396, 7400, 356, 764, 1412, 490, 264, 3088, 3621, 281, 3847, 512, 295, 1080, 11677, 7599, 5245, 13, 50628], "temperature": 0.0, "avg_logprob": -0.07690764545054918, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.005909740459173918}, {"id": 593, "seek": 296540, "start": 2971.56, "end": 2978.28, "text": " Now basis in particular, we put the canary string in there. I think you'll recall in the last live,", "tokens": [50672, 823, 5143, 294, 1729, 11, 321, 829, 264, 393, 822, 6798, 294, 456, 13, 286, 519, 291, 603, 9901, 294, 264, 1036, 1621, 11, 51008], "temperature": 0.0, "avg_logprob": -0.07690764545054918, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.005909740459173918}, {"id": 594, "seek": 296540, "start": 2978.28, "end": 2985.1600000000003, "text": " I made sure not to mention the answers because it could pick that up from transcripts and it", "tokens": [51008, 286, 1027, 988, 406, 281, 2152, 264, 6338, 570, 309, 727, 1888, 300, 493, 490, 24444, 82, 293, 309, 51352], "temperature": 0.0, "avg_logprob": -0.07690764545054918, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.005909740459173918}, {"id": 595, "seek": 296540, "start": 2985.1600000000003, "end": 2992.04, "text": " could also pick that up eventually from lip reading and it's been able to pick it up from", "tokens": [51352, 727, 611, 1888, 300, 493, 4728, 490, 8280, 3760, 293, 309, 311, 668, 1075, 281, 1888, 309, 493, 490, 51696], "temperature": 0.0, "avg_logprob": -0.07690764545054918, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.005909740459173918}, {"id": 596, "seek": 299204, "start": 2992.04, "end": 2999.8, "text": " images for a long time. So the warnings on Gaia and the Google proof paper were basically", "tokens": [50364, 5267, 337, 257, 938, 565, 13, 407, 264, 30009, 322, 10384, 654, 293, 264, 3329, 8177, 3035, 645, 1936, 50752], "temperature": 0.0, "avg_logprob": -0.07691116631031036, "compression_ratio": 1.3381294964028776, "no_speech_prob": 0.06369458884000778}, {"id": 597, "seek": 299204, "start": 3001.16, "end": 3011.16, "text": " just make sure that you're not showing this both in text and in images. Let me see if I can find", "tokens": [50820, 445, 652, 988, 300, 291, 434, 406, 4099, 341, 1293, 294, 2487, 293, 294, 5267, 13, 961, 385, 536, 498, 286, 393, 915, 51320], "temperature": 0.0, "avg_logprob": -0.07691116631031036, "compression_ratio": 1.3381294964028776, "no_speech_prob": 0.06369458884000778}, {"id": 598, "seek": 301116, "start": 3011.16, "end": 3026.52, "text": " that Google proof example that we showed earlier. So we were running through GPQA. We have that paper", "tokens": [50364, 300, 3329, 8177, 1365, 300, 321, 4712, 3071, 13, 407, 321, 645, 2614, 807, 26039, 48, 32, 13, 492, 362, 300, 3035, 51132], "temperature": 0.0, "avg_logprob": -0.19971824178890307, "compression_ratio": 1.3214285714285714, "no_speech_prob": 0.061860840767621994}, {"id": 599, "seek": 301116, "start": 3026.52, "end": 3035.08, "text": " right here for ourselves and GPQA was by NYU Co here and Anthropic and on page two,", "tokens": [51132, 558, 510, 337, 4175, 293, 26039, 48, 32, 390, 538, 42682, 3066, 510, 293, 12727, 39173, 293, 322, 3028, 732, 11, 51560], "temperature": 0.0, "avg_logprob": -0.19971824178890307, "compression_ratio": 1.3214285714285714, "no_speech_prob": 0.061860840767621994}, {"id": 600, "seek": 303508, "start": 3036.04, "end": 3045.0, "text": " they requested don't reveal examples from the Google proof QA paper in plain text or images", "tokens": [50412, 436, 16436, 500, 380, 10658, 5110, 490, 264, 3329, 8177, 1249, 32, 3035, 294, 11121, 2487, 420, 5267, 50860], "temperature": 0.0, "avg_logprob": -0.1117607071286156, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.011329960078001022}, {"id": 601, "seek": 303508, "start": 3045.0, "end": 3052.12, "text": " because this multi-modality is running all the time and you'll see that in", "tokens": [50860, 570, 341, 4825, 12, 8014, 1860, 307, 2614, 439, 264, 565, 293, 291, 603, 536, 300, 294, 51216], "temperature": 0.0, "avg_logprob": -0.1117607071286156, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.011329960078001022}, {"id": 602, "seek": 303508, "start": 3053.48, "end": 3062.2799999999997, "text": " all of the text to image models. There's been a new partnership between Getty images and one", "tokens": [51284, 439, 295, 264, 2487, 281, 3256, 5245, 13, 821, 311, 668, 257, 777, 9982, 1296, 3240, 874, 5267, 293, 472, 51724], "temperature": 0.0, "avg_logprob": -0.1117607071286156, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.011329960078001022}, {"id": 603, "seek": 306228, "start": 3062.28, "end": 3069.32, "text": " of the big text to image model labs but then it's been watching YouTube, it's been listening to YouTube", "tokens": [50364, 295, 264, 955, 2487, 281, 3256, 2316, 20339, 457, 550, 309, 311, 668, 1976, 3088, 11, 309, 311, 668, 4764, 281, 3088, 50716], "temperature": 0.0, "avg_logprob": -0.09292308052817544, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.0029796850867569447}, {"id": 604, "seek": 306228, "start": 3069.32, "end": 3077.7200000000003, "text": " with Whisper. So all of this stuff is happening already. When would I predict that that actually", "tokens": [50716, 365, 41132, 610, 13, 407, 439, 295, 341, 1507, 307, 2737, 1217, 13, 1133, 576, 286, 6069, 300, 300, 767, 51136], "temperature": 0.0, "avg_logprob": -0.09292308052817544, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.0029796850867569447}, {"id": 605, "seek": 306228, "start": 3077.7200000000003, "end": 3085.7200000000003, "text": " happens for the inference time? That's a great question to expand on your question. That already", "tokens": [51136, 2314, 337, 264, 38253, 565, 30, 663, 311, 257, 869, 1168, 281, 5268, 322, 428, 1168, 13, 663, 1217, 51536], "temperature": 0.0, "avg_logprob": -0.09292308052817544, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.0029796850867569447}, {"id": 606, "seek": 306228, "start": 3085.7200000000003, "end": 3090.2000000000003, "text": " happens with Whisper. So when you're playing around with Whisper, it's obviously listening.", "tokens": [51536, 2314, 365, 41132, 610, 13, 407, 562, 291, 434, 2433, 926, 365, 41132, 610, 11, 309, 311, 2745, 4764, 13, 51760], "temperature": 0.0, "avg_logprob": -0.09292308052817544, "compression_ratio": 1.728888888888889, "no_speech_prob": 0.0029796850867569447}, {"id": 607, "seek": 309020, "start": 3091.16, "end": 3098.7599999999998, "text": " It already happens with GPT-4 vision which is excellent for OCR. I used it recently to translate", "tokens": [50412, 467, 1217, 2314, 365, 26039, 51, 12, 19, 5201, 597, 307, 7103, 337, 422, 18547, 13, 286, 1143, 309, 3938, 281, 13799, 50792], "temperature": 0.0, "avg_logprob": -0.12781282014484646, "compression_ratio": 1.4052631578947368, "no_speech_prob": 0.02634967491030693}, {"id": 608, "seek": 309020, "start": 3099.64, "end": 3108.2799999999997, "text": " our Chinese LLMs. So if you go to chat.openai.com, you got to chat GPT plus subscription here.", "tokens": [50836, 527, 4649, 441, 43, 26386, 13, 407, 498, 291, 352, 281, 5081, 13, 15752, 1301, 13, 1112, 11, 291, 658, 281, 5081, 26039, 51, 1804, 17231, 510, 13, 51268], "temperature": 0.0, "avg_logprob": -0.12781282014484646, "compression_ratio": 1.4052631578947368, "no_speech_prob": 0.02634967491030693}, {"id": 609, "seek": 309020, "start": 3110.12, "end": 3117.56, "text": " Hopefully I can just attach a Chinese LLM here. Wow, that's a lot of files.", "tokens": [51360, 10429, 286, 393, 445, 5085, 257, 4649, 441, 43, 44, 510, 13, 3153, 11, 300, 311, 257, 688, 295, 7098, 13, 51732], "temperature": 0.0, "avg_logprob": -0.12781282014484646, "compression_ratio": 1.4052631578947368, "no_speech_prob": 0.02634967491030693}, {"id": 610, "seek": 311756, "start": 3118.52, "end": 3120.2, "text": " Let's grab this one.", "tokens": [50412, 961, 311, 4444, 341, 472, 13, 50496], "temperature": 0.0, "avg_logprob": -0.12597214734112774, "compression_ratio": 1.5670103092783505, "no_speech_prob": 0.003483111970126629}, {"id": 611, "seek": 311756, "start": 3122.7599999999998, "end": 3131.32, "text": " This is a screenshot of Chinese LLMs as an image and GPT-4 vision is going to go and read that", "tokens": [50624, 639, 307, 257, 27712, 295, 4649, 441, 43, 26386, 382, 364, 3256, 293, 26039, 51, 12, 19, 5201, 307, 516, 281, 352, 293, 1401, 300, 51052], "temperature": 0.0, "avg_logprob": -0.12597214734112774, "compression_ratio": 1.5670103092783505, "no_speech_prob": 0.003483111970126629}, {"id": 612, "seek": 311756, "start": 3131.32, "end": 3139.16, "text": " image, look at that image and then essentially perform OCR across it but not OCR as we know it.", "tokens": [51052, 3256, 11, 574, 412, 300, 3256, 293, 550, 4476, 2042, 422, 18547, 2108, 309, 457, 406, 422, 18547, 382, 321, 458, 309, 13, 51444], "temperature": 0.0, "avg_logprob": -0.12597214734112774, "compression_ratio": 1.5670103092783505, "no_speech_prob": 0.003483111970126629}, {"id": 613, "seek": 311756, "start": 3139.16, "end": 3146.04, "text": " This is a transformer based vision model that's looking at the image and finding the closest", "tokens": [51444, 639, 307, 257, 31782, 2361, 5201, 2316, 300, 311, 1237, 412, 264, 3256, 293, 5006, 264, 13699, 51788], "temperature": 0.0, "avg_logprob": -0.12597214734112774, "compression_ratio": 1.5670103092783505, "no_speech_prob": 0.003483111970126629}, {"id": 614, "seek": 314604, "start": 3146.84, "end": 3152.2, "text": " next best word to complete my prompt. Put this in a table. What are you doing behind the scenes?", "tokens": [50404, 958, 1151, 1349, 281, 3566, 452, 12391, 13, 4935, 341, 294, 257, 3199, 13, 708, 366, 291, 884, 2261, 264, 8026, 30, 50672], "temperature": 0.0, "avg_logprob": -0.15140272776285807, "compression_ratio": 1.3706896551724137, "no_speech_prob": 0.009411323815584183}, {"id": 615, "seek": 314604, "start": 3153.96, "end": 3158.7599999999998, "text": " Who knows? Developing some sort of CSV using Python.", "tokens": [50760, 2102, 3255, 30, 11442, 278, 512, 1333, 295, 48814, 1228, 15329, 13, 51000], "temperature": 0.0, "avg_logprob": -0.15140272776285807, "compression_ratio": 1.3706896551724137, "no_speech_prob": 0.009411323815584183}, {"id": 616, "seek": 314604, "start": 3162.84, "end": 3166.2, "text": " All right. Quailude Charlie is taking us back in time while we're waiting.", "tokens": [51204, 1057, 558, 13, 2326, 864, 2303, 13754, 307, 1940, 505, 646, 294, 565, 1339, 321, 434, 3806, 13, 51372], "temperature": 0.0, "avg_logprob": -0.15140272776285807, "compression_ratio": 1.3706896551724137, "no_speech_prob": 0.009411323815584183}, {"id": 617, "seek": 314604, "start": 3166.7599999999998, "end": 3171.16, "text": " As a young man, I worked with Eliza. It even worked in MS-DOS. They should expand on a 32-bit", "tokens": [51400, 1018, 257, 2037, 587, 11, 286, 2732, 365, 11991, 64, 13, 467, 754, 2732, 294, 7395, 12, 35, 4367, 13, 814, 820, 5268, 322, 257, 8858, 12, 5260, 51620], "temperature": 0.0, "avg_logprob": -0.15140272776285807, "compression_ratio": 1.3706896551724137, "no_speech_prob": 0.009411323815584183}, {"id": 618, "seek": 317116, "start": 3171.16, "end": 3181.48, "text": " AI that will run on older computers. That's amazing. Thank you. Eliza was incredible. It", "tokens": [50364, 7318, 300, 486, 1190, 322, 4906, 10807, 13, 663, 311, 2243, 13, 1044, 291, 13, 11991, 64, 390, 4651, 13, 467, 50880], "temperature": 0.0, "avg_logprob": -0.09937493424666555, "compression_ratio": 1.4129353233830846, "no_speech_prob": 0.02194380573928356}, {"id": 619, "seek": 317116, "start": 3181.48, "end": 3189.3199999999997, "text": " still is. It was built into every edition of Mac OS. Yeah. So GPT-4 vision is down as we speak", "tokens": [50880, 920, 307, 13, 467, 390, 3094, 666, 633, 11377, 295, 5707, 12731, 13, 865, 13, 407, 26039, 51, 12, 19, 5201, 307, 760, 382, 321, 1710, 51272], "temperature": 0.0, "avg_logprob": -0.09937493424666555, "compression_ratio": 1.4129353233830846, "no_speech_prob": 0.02194380573928356}, {"id": 620, "seek": 317116, "start": 3189.3199999999997, "end": 3194.8399999999997, "text": " because this is the kind of output that I would get if you're looking for the output that I actually", "tokens": [51272, 570, 341, 307, 264, 733, 295, 5598, 300, 286, 576, 483, 498, 291, 434, 1237, 337, 264, 5598, 300, 286, 767, 51548], "temperature": 0.0, "avg_logprob": -0.09937493424666555, "compression_ratio": 1.4129353233830846, "no_speech_prob": 0.02194380573928356}, {"id": 621, "seek": 319484, "start": 3194.84, "end": 3204.1200000000003, "text": " achieved. You can go to lifearchitect.ai-models-table. On the second tab now is the output from all of", "tokens": [50364, 11042, 13, 509, 393, 352, 281, 993, 1178, 5739, 13, 1301, 12, 8014, 1625, 12, 23811, 13, 1282, 264, 1150, 4421, 586, 307, 264, 5598, 490, 439, 295, 50828], "temperature": 0.0, "avg_logprob": -0.11564959755426721, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.12248273938894272}, {"id": 622, "seek": 319484, "start": 3204.1200000000003, "end": 3214.6800000000003, "text": " those images that became a table of 103 Chinese LLMs within about 20 weeks, something like that.", "tokens": [50828, 729, 5267, 300, 3062, 257, 3199, 295, 48784, 4649, 441, 43, 26386, 1951, 466, 945, 3259, 11, 746, 411, 300, 13, 51356], "temperature": 0.0, "avg_logprob": -0.11564959755426721, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.12248273938894272}, {"id": 623, "seek": 319484, "start": 3215.7200000000003, "end": 3220.84, "text": " Back to Eliza. Yeah. It was built into all editions of Mac OS. It was inside the terminal", "tokens": [51408, 5833, 281, 11991, 64, 13, 865, 13, 467, 390, 3094, 666, 439, 44840, 295, 5707, 12731, 13, 467, 390, 1854, 264, 14709, 51664], "temperature": 0.0, "avg_logprob": -0.11564959755426721, "compression_ratio": 1.4166666666666667, "no_speech_prob": 0.12248273938894272}, {"id": 624, "seek": 322084, "start": 3221.4, "end": 3229.32, "text": " and it was, I think it was called Doctor within Xcode. They've since removed it or at least you", "tokens": [50392, 293, 309, 390, 11, 286, 519, 309, 390, 1219, 10143, 1951, 1783, 22332, 13, 814, 600, 1670, 7261, 309, 420, 412, 1935, 291, 50788], "temperature": 0.0, "avg_logprob": -0.15898574153079262, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.010012623853981495}, {"id": 625, "seek": 322084, "start": 3229.32, "end": 3233.96, "text": " have to do a little bit more funky stuff to get it going. Of course, you can play with it online.", "tokens": [50788, 362, 281, 360, 257, 707, 857, 544, 33499, 1507, 281, 483, 309, 516, 13, 2720, 1164, 11, 291, 393, 862, 365, 309, 2950, 13, 51020], "temperature": 0.0, "avg_logprob": -0.15898574153079262, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.010012623853981495}, {"id": 626, "seek": 322084, "start": 3235.1600000000003, "end": 3250.04, "text": " Let's do Eliza online. NJIT. Just to have a play with it. This is 1964 technology.", "tokens": [51080, 961, 311, 360, 11991, 64, 2950, 13, 426, 41, 3927, 13, 1449, 281, 362, 257, 862, 365, 309, 13, 639, 307, 34314, 2899, 13, 51824], "temperature": 0.0, "avg_logprob": -0.15898574153079262, "compression_ratio": 1.4153846153846155, "no_speech_prob": 0.010012623853981495}, {"id": 627, "seek": 325004, "start": 3250.04, "end": 3254.68, "text": " Joseph Wasenbaum and it essentially repeats back to you what you've said.", "tokens": [50364, 11170, 3027, 268, 46641, 293, 309, 4476, 35038, 646, 281, 291, 437, 291, 600, 848, 13, 50596], "temperature": 0.0, "avg_logprob": -0.1475750075446235, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0037070382386446}, {"id": 628, "seek": 325004, "start": 3262.52, "end": 3266.44, "text": " I'm having trouble creating a new diet of protein and Eliza says,", "tokens": [50988, 286, 478, 1419, 5253, 4084, 257, 777, 6339, 295, 7944, 293, 11991, 64, 1619, 11, 51184], "temperature": 0.0, "avg_logprob": -0.1475750075446235, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0037070382386446}, {"id": 629, "seek": 325004, "start": 3266.44, "end": 3269.16, "text": " how long have you been having trouble creating a new diet of protein?", "tokens": [51184, 577, 938, 362, 291, 668, 1419, 5253, 4084, 257, 777, 6339, 295, 7944, 30, 51320], "temperature": 0.0, "avg_logprob": -0.1475750075446235, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0037070382386446}, {"id": 630, "seek": 325004, "start": 3271.32, "end": 3277.64, "text": " Let's compare that with something like, well, let's compare that with something like", "tokens": [51428, 961, 311, 6794, 300, 365, 746, 411, 11, 731, 11, 718, 311, 6794, 300, 365, 746, 411, 51744], "temperature": 0.0, "avg_logprob": -0.1475750075446235, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0037070382386446}, {"id": 631, "seek": 327764, "start": 3278.6, "end": 3286.04, "text": " Chet GPT on Poe, given that this one is not going to answer for us. Of course,", "tokens": [50412, 761, 302, 26039, 51, 322, 6165, 68, 11, 2212, 300, 341, 472, 307, 406, 516, 281, 1867, 337, 505, 13, 2720, 1164, 11, 50784], "temperature": 0.0, "avg_logprob": -0.18490807406873588, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.009124496951699257}, {"id": 632, "seek": 327764, "start": 3286.6, "end": 3289.7999999999997, "text": " Claude is actually not going to give us a good answer either.", "tokens": [50812, 12947, 2303, 307, 767, 406, 516, 281, 976, 505, 257, 665, 1867, 2139, 13, 50972], "temperature": 0.0, "avg_logprob": -0.18490807406873588, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.009124496951699257}, {"id": 633, "seek": 327764, "start": 3294.3599999999997, "end": 3301.7999999999997, "text": " Eliza was ridiculous, but from a perspective of proving whether or not it's a bot,", "tokens": [51200, 11991, 64, 390, 11083, 11, 457, 490, 257, 4585, 295, 27221, 1968, 420, 406, 309, 311, 257, 10592, 11, 51572], "temperature": 0.0, "avg_logprob": -0.18490807406873588, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.009124496951699257}, {"id": 634, "seek": 327764, "start": 3301.7999999999997, "end": 3306.44, "text": " it often passes the Turing test because people assume that the human is being obtuse.", "tokens": [51572, 309, 2049, 11335, 264, 314, 1345, 1500, 570, 561, 6552, 300, 264, 1952, 307, 885, 7464, 438, 13, 51804], "temperature": 0.0, "avg_logprob": -0.18490807406873588, "compression_ratio": 1.5147058823529411, "no_speech_prob": 0.009124496951699257}, {"id": 635, "seek": 330764, "start": 3308.04, "end": 3313.8799999999997, "text": " When in fact it's just a very, very old bot. All right, what's going on here?", "tokens": [50384, 1133, 294, 1186, 309, 311, 445, 257, 588, 11, 588, 1331, 10592, 13, 1057, 558, 11, 437, 311, 516, 322, 510, 30, 50676], "temperature": 0.0, "avg_logprob": -0.1550257410321917, "compression_ratio": 1.3567251461988303, "no_speech_prob": 0.005059815943241119}, {"id": 636, "seek": 330764, "start": 3313.8799999999997, "end": 3318.92, "text": " I think this tech knows that I'm live streaming, so it decides to just", "tokens": [50676, 286, 519, 341, 7553, 3255, 300, 286, 478, 1621, 11791, 11, 370, 309, 14898, 281, 445, 50928], "temperature": 0.0, "avg_logprob": -0.1550257410321917, "compression_ratio": 1.3567251461988303, "no_speech_prob": 0.005059815943241119}, {"id": 637, "seek": 330764, "start": 3320.92, "end": 3328.68, "text": " not play properly. GPT4 is giving us a complete diet of protein. Good on you, GPT4.", "tokens": [51028, 406, 862, 6108, 13, 26039, 51, 19, 307, 2902, 505, 257, 3566, 6339, 295, 7944, 13, 2205, 322, 291, 11, 26039, 51, 19, 13, 51416], "temperature": 0.0, "avg_logprob": -0.1550257410321917, "compression_ratio": 1.3567251461988303, "no_speech_prob": 0.005059815943241119}, {"id": 638, "seek": 332868, "start": 3328.68, "end": 3338.2799999999997, "text": " I do remember fondly Eliza, and it was one of the reasons that I started in AI,", "tokens": [50364, 286, 360, 1604, 9557, 356, 11991, 64, 11, 293, 309, 390, 472, 295, 264, 4112, 300, 286, 1409, 294, 7318, 11, 50844], "temperature": 0.0, "avg_logprob": -0.17347867329915365, "compression_ratio": 1.4095744680851063, "no_speech_prob": 0.01971704140305519}, {"id": 639, "seek": 332868, "start": 3338.2799999999997, "end": 3344.3599999999997, "text": " even before I did my computer science degree actually. So 1994-ish, I was programming in", "tokens": [50844, 754, 949, 286, 630, 452, 3820, 3497, 4314, 767, 13, 407, 22736, 12, 742, 11, 286, 390, 9410, 294, 51148], "temperature": 0.0, "avg_logprob": -0.17347867329915365, "compression_ratio": 1.4095744680851063, "no_speech_prob": 0.01971704140305519}, {"id": 640, "seek": 332868, "start": 3344.3599999999997, "end": 3352.7599999999998, "text": " Cubasic. I was very young. I was about 11 years old or younger, and it was a lot of fun to prove", "tokens": [51148, 21300, 296, 299, 13, 286, 390, 588, 2037, 13, 286, 390, 466, 2975, 924, 1331, 420, 7037, 11, 293, 309, 390, 257, 688, 295, 1019, 281, 7081, 51568], "temperature": 0.0, "avg_logprob": -0.17347867329915365, "compression_ratio": 1.4095744680851063, "no_speech_prob": 0.01971704140305519}, {"id": 641, "seek": 335276, "start": 3352.76, "end": 3359.6400000000003, "text": " that we probably can't just fully program an AI by giving it all the facts in the world, despite", "tokens": [50364, 300, 321, 1391, 393, 380, 445, 4498, 1461, 364, 7318, 538, 2902, 309, 439, 264, 9130, 294, 264, 1002, 11, 7228, 50708], "temperature": 0.0, "avg_logprob": -0.07453910827636719, "compression_ratio": 1.4845360824742269, "no_speech_prob": 0.040219392627477646}, {"id": 642, "seek": 335276, "start": 3360.28, "end": 3366.92, "text": " many of my peers and contemporaries trying to do that exact same thing at that exact same time.", "tokens": [50740, 867, 295, 452, 16739, 293, 13046, 4889, 1382, 281, 360, 300, 1900, 912, 551, 412, 300, 1900, 912, 565, 13, 51072], "temperature": 0.0, "avg_logprob": -0.07453910827636719, "compression_ratio": 1.4845360824742269, "no_speech_prob": 0.040219392627477646}, {"id": 643, "seek": 335276, "start": 3368.1200000000003, "end": 3374.44, "text": " If you're looking for examples of that, have a look at Chris McKinstry. Let's grab him on wiki.", "tokens": [51132, 759, 291, 434, 1237, 337, 5110, 295, 300, 11, 362, 257, 574, 412, 6688, 21765, 13911, 627, 13, 961, 311, 4444, 796, 322, 261, 9850, 13, 51448], "temperature": 0.0, "avg_logprob": -0.07453910827636719, "compression_ratio": 1.4845360824742269, "no_speech_prob": 0.040219392627477646}, {"id": 644, "seek": 337444, "start": 3374.84, "end": 3385.0, "text": " He was an AI researcher from the 90s-ish, and he was creating something pretty interesting.", "tokens": [50384, 634, 390, 364, 7318, 21751, 490, 264, 4289, 82, 12, 742, 11, 293, 415, 390, 4084, 746, 1238, 1880, 13, 50892], "temperature": 0.0, "avg_logprob": -0.2315219381581182, "compression_ratio": 1.2706766917293233, "no_speech_prob": 0.12760789692401886}, {"id": 645, "seek": 337444, "start": 3386.28, "end": 3394.28, "text": " I'd like to find the name of the, here it is, Open Mind Common Sense Project,", "tokens": [50956, 286, 1116, 411, 281, 915, 264, 1315, 295, 264, 11, 510, 309, 307, 11, 7238, 13719, 18235, 33123, 9849, 11, 51356], "temperature": 0.0, "avg_logprob": -0.2315219381581182, "compression_ratio": 1.2706766917293233, "no_speech_prob": 0.12760789692401886}, {"id": 646, "seek": 339428, "start": 3394.28, "end": 3405.1600000000003, "text": " OMCS at MIT, and he was basically programming along with Push and Marvin Minsky a range of facts.", "tokens": [50364, 16954, 26283, 412, 13100, 11, 293, 415, 390, 1936, 9410, 2051, 365, 18229, 293, 48722, 376, 44153, 257, 3613, 295, 9130, 13, 50908], "temperature": 0.0, "avg_logprob": -0.11207099810038527, "compression_ratio": 1.4223300970873787, "no_speech_prob": 0.3627944886684418}, {"id": 647, "seek": 339428, "start": 3405.1600000000003, "end": 3412.28, "text": " Here we go. Different types of knowledge, simple phrases of natural language. A coat is used for", "tokens": [50908, 1692, 321, 352, 13, 20825, 3467, 295, 3601, 11, 2199, 20312, 295, 3303, 2856, 13, 316, 10690, 307, 1143, 337, 51264], "temperature": 0.0, "avg_logprob": -0.11207099810038527, "compression_ratio": 1.4223300970873787, "no_speech_prob": 0.3627944886684418}, {"id": 648, "seek": 339428, "start": 3412.28, "end": 3417.8, "text": " keeping warm. The sun is very hot. The last thing you do when you cook dinner is wash your dishes.", "tokens": [51264, 5145, 4561, 13, 440, 3295, 307, 588, 2368, 13, 440, 1036, 551, 291, 360, 562, 291, 2543, 6148, 307, 5675, 428, 10814, 13, 51540], "temperature": 0.0, "avg_logprob": -0.11207099810038527, "compression_ratio": 1.4223300970873787, "no_speech_prob": 0.3627944886684418}, {"id": 649, "seek": 341780, "start": 3417.8, "end": 3427.1600000000003, "text": " This was the state-of-the-art approach to artificial intelligence with or without neural", "tokens": [50364, 639, 390, 264, 1785, 12, 2670, 12, 3322, 12, 446, 3109, 281, 11677, 7599, 365, 420, 1553, 18161, 50832], "temperature": 0.0, "avg_logprob": -0.07698673612616036, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.022280531004071236}, {"id": 650, "seek": 341780, "start": 3427.1600000000003, "end": 3433.0, "text": " networks in the 90s, and it was fascinating to me that there were at least two projects", "tokens": [50832, 9590, 294, 264, 4289, 82, 11, 293, 309, 390, 10343, 281, 385, 300, 456, 645, 412, 1935, 732, 4455, 51124], "temperature": 0.0, "avg_logprob": -0.07698673612616036, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.022280531004071236}, {"id": 651, "seek": 341780, "start": 3433.6400000000003, "end": 3440.1200000000003, "text": " going on at the same time that dealt with this, and I thought that was just fascinating. The other", "tokens": [51156, 516, 322, 412, 264, 912, 565, 300, 15991, 365, 341, 11, 293, 286, 1194, 300, 390, 445, 10343, 13, 440, 661, 51480], "temperature": 0.0, "avg_logprob": -0.07698673612616036, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.022280531004071236}, {"id": 652, "seek": 341780, "start": 3440.1200000000003, "end": 3445.32, "text": " one was Mind Pixel. I feel like you guys want to go and research this after the live stream,", "tokens": [51480, 472, 390, 13719, 28323, 13, 286, 841, 411, 291, 1074, 528, 281, 352, 293, 2132, 341, 934, 264, 1621, 4309, 11, 51740], "temperature": 0.0, "avg_logprob": -0.07698673612616036, "compression_ratio": 1.6140350877192982, "no_speech_prob": 0.022280531004071236}, {"id": 653, "seek": 344532, "start": 3445.32, "end": 3454.28, "text": " so I'm going to pull them both up. This one was created by, Mind Pixel was created by one of Chris's", "tokens": [50364, 370, 286, 478, 516, 281, 2235, 552, 1293, 493, 13, 639, 472, 390, 2942, 538, 11, 13719, 28323, 390, 2942, 538, 472, 295, 6688, 311, 50812], "temperature": 0.0, "avg_logprob": -0.1414507396185576, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.006902984343469143}, {"id": 654, "seek": 344532, "start": 3456.36, "end": 3463.7200000000003, "text": " contemporaries. No, getting confused. Maybe I'm getting confused with Push Singh.", "tokens": [50916, 13046, 4889, 13, 883, 11, 1242, 9019, 13, 2704, 286, 478, 1242, 9019, 365, 18229, 27529, 13, 51284], "temperature": 0.0, "avg_logprob": -0.1414507396185576, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.006902984343469143}, {"id": 655, "seek": 344532, "start": 3463.7200000000003, "end": 3469.8, "text": " So Push was doing the OMCS thing, and Chris was doing something slightly different.", "tokens": [51284, 407, 18229, 390, 884, 264, 16954, 26283, 551, 11, 293, 6688, 390, 884, 746, 4748, 819, 13, 51588], "temperature": 0.0, "avg_logprob": -0.1414507396185576, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.006902984343469143}, {"id": 656, "seek": 346980, "start": 3470.6800000000003, "end": 3475.32, "text": " You don't mind if I get distracted slightly, do you? These two guys", "tokens": [50408, 509, 500, 380, 1575, 498, 286, 483, 21658, 4748, 11, 360, 291, 30, 1981, 732, 1074, 50640], "temperature": 0.0, "avg_logprob": -0.09096839427947997, "compression_ratio": 1.5116279069767442, "no_speech_prob": 0.009124782867729664}, {"id": 657, "seek": 346980, "start": 3479.0, "end": 3486.2000000000003, "text": " in the 1980s were doing some fascinating stuff, and then in the 1990s", "tokens": [50824, 294, 264, 13626, 82, 645, 884, 512, 10343, 1507, 11, 293, 550, 294, 264, 13384, 82, 51184], "temperature": 0.0, "avg_logprob": -0.09096839427947997, "compression_ratio": 1.5116279069767442, "no_speech_prob": 0.009124782867729664}, {"id": 658, "seek": 346980, "start": 3486.92, "end": 3491.48, "text": " both decided that they'd had enough. There are some great conspiracy theories around this,", "tokens": [51220, 1293, 3047, 300, 436, 1116, 632, 1547, 13, 821, 366, 512, 869, 20439, 13667, 926, 341, 11, 51448], "temperature": 0.0, "avg_logprob": -0.09096839427947997, "compression_ratio": 1.5116279069767442, "no_speech_prob": 0.009124782867729664}, {"id": 659, "seek": 346980, "start": 3491.48, "end": 3498.28, "text": " but there was a walk down the rabbit hole for those that want to get lost in what AI looked like", "tokens": [51448, 457, 456, 390, 257, 1792, 760, 264, 19509, 5458, 337, 729, 300, 528, 281, 483, 2731, 294, 437, 7318, 2956, 411, 51788], "temperature": 0.0, "avg_logprob": -0.09096839427947997, "compression_ratio": 1.5116279069767442, "no_speech_prob": 0.009124782867729664}, {"id": 660, "seek": 349828, "start": 3498.28, "end": 3502.1200000000003, "text": " in the 80s and 90s, and I'm glad that we've come a long way since then.", "tokens": [50364, 294, 264, 4688, 82, 293, 4289, 82, 11, 293, 286, 478, 5404, 300, 321, 600, 808, 257, 938, 636, 1670, 550, 13, 50556], "temperature": 0.0, "avg_logprob": -0.08675600818752013, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.0011877696961164474}, {"id": 661, "seek": 349828, "start": 3503.4, "end": 3507.88, "text": " This brings us on a full circle all the way back to Transforma, because we were stuck in this weird", "tokens": [50620, 639, 5607, 505, 322, 257, 1577, 6329, 439, 264, 636, 646, 281, 27938, 64, 11, 570, 321, 645, 5541, 294, 341, 3657, 50844], "temperature": 0.0, "avg_logprob": -0.08675600818752013, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.0011877696961164474}, {"id": 662, "seek": 349828, "start": 3507.88, "end": 3516.92, "text": " loop from the dawn of artificial intelligence, which was Alan Turing. John von Neumann was involved", "tokens": [50844, 6367, 490, 264, 18192, 295, 11677, 7599, 11, 597, 390, 16442, 314, 1345, 13, 2619, 2957, 1734, 449, 969, 390, 3288, 51296], "temperature": 0.0, "avg_logprob": -0.08675600818752013, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.0011877696961164474}, {"id": 663, "seek": 349828, "start": 3516.92, "end": 3525.1600000000003, "text": " to a certain extent from the 1950s to around 2017. There was just this AI winter, and if you", "tokens": [51296, 281, 257, 1629, 8396, 490, 264, 18141, 82, 281, 926, 6591, 13, 821, 390, 445, 341, 7318, 6355, 11, 293, 498, 291, 51708], "temperature": 0.0, "avg_logprob": -0.08675600818752013, "compression_ratio": 1.4736842105263157, "no_speech_prob": 0.0011877696961164474}, {"id": 664, "seek": 352516, "start": 3525.16, "end": 3530.68, "text": " talk to any old professor, artificial intelligence doesn't exist, because all they've learned from", "tokens": [50364, 751, 281, 604, 1331, 8304, 11, 11677, 7599, 1177, 380, 2514, 11, 570, 439, 436, 600, 3264, 490, 50640], "temperature": 0.0, "avg_logprob": -0.15194508800767872, "compression_ratio": 1.391304347826087, "no_speech_prob": 0.04466812312602997}, {"id": 665, "seek": 352516, "start": 3532.2, "end": 3539.24, "text": " 1950 to 2017 is that AI is these pre-programmed bits of knowledge, or these really basic neural", "tokens": [50716, 18141, 281, 6591, 307, 300, 7318, 307, 613, 659, 12, 32726, 1912, 9239, 295, 3601, 11, 420, 613, 534, 3875, 18161, 51068], "temperature": 0.0, "avg_logprob": -0.15194508800767872, "compression_ratio": 1.391304347826087, "no_speech_prob": 0.04466812312602997}, {"id": 666, "seek": 352516, "start": 3539.24, "end": 3547.08, "text": " nets. Then from 2017, with the launch of the Transforma, we went, and we just went with GPT1,", "tokens": [51068, 36170, 13, 1396, 490, 6591, 11, 365, 264, 4025, 295, 264, 27938, 64, 11, 321, 1437, 11, 293, 321, 445, 1437, 365, 26039, 51, 16, 11, 51460], "temperature": 0.0, "avg_logprob": -0.15194508800767872, "compression_ratio": 1.391304347826087, "no_speech_prob": 0.04466812312602997}, {"id": 667, "seek": 354708, "start": 3547.08, "end": 3553.96, "text": " Bert, GPT2, GPT3, and MTNLG and some others that are on my original Bubbles chart,", "tokens": [50364, 29594, 11, 26039, 51, 17, 11, 26039, 51, 18, 11, 293, 37333, 45, 43, 38, 293, 512, 2357, 300, 366, 322, 452, 3380, 25489, 8806, 6927, 11, 50708], "temperature": 0.0, "avg_logprob": -0.11861954132715861, "compression_ratio": 1.4552845528455285, "no_speech_prob": 0.15602874755859375}, {"id": 668, "seek": 354708, "start": 3553.96, "end": 3564.68, "text": " we just exploded to what we have today, where GPT4 is outperforming humans across the board,", "tokens": [50708, 321, 445, 27049, 281, 437, 321, 362, 965, 11, 689, 26039, 51, 19, 307, 484, 26765, 278, 6255, 2108, 264, 3150, 11, 51244], "temperature": 0.0, "avg_logprob": -0.11861954132715861, "compression_ratio": 1.4552845528455285, "no_speech_prob": 0.15602874755859375}, {"id": 669, "seek": 354708, "start": 3564.68, "end": 3570.52, "text": " using the same Transforma technology from 2017 and completely avoiding the pre-programmed", "tokens": [51244, 1228, 264, 912, 27938, 64, 2899, 490, 6591, 293, 2584, 20220, 264, 659, 12, 32726, 1912, 51536], "temperature": 0.0, "avg_logprob": -0.11861954132715861, "compression_ratio": 1.4552845528455285, "no_speech_prob": 0.15602874755859375}, {"id": 670, "seek": 354708, "start": 3570.52, "end": 3576.04, "text": " knowledge graphs that we were giving it in the 1990s. Fascinating. This chart says that it's", "tokens": [51536, 3601, 24877, 300, 321, 645, 2902, 309, 294, 264, 13384, 82, 13, 49098, 8205, 13, 639, 6927, 1619, 300, 309, 311, 51812], "temperature": 0.0, "avg_logprob": -0.11861954132715861, "compression_ratio": 1.4552845528455285, "no_speech_prob": 0.15602874755859375}, {"id": 671, "seek": 357604, "start": 3576.12, "end": 3582.68, "text": " hitting 100% in theory of mind. It's in the 99th percentile for creativity and hitting in the", "tokens": [50368, 8850, 2319, 4, 294, 5261, 295, 1575, 13, 467, 311, 294, 264, 11803, 392, 3043, 794, 337, 12915, 293, 8850, 294, 264, 50696], "temperature": 0.0, "avg_logprob": -0.09613437866896726, "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.007813874632120132}, {"id": 672, "seek": 357604, "start": 3582.68, "end": 3588.92, "text": " 94th percentile for the SAT, where students hitting the 50th percentile. There's this other one I", "tokens": [50696, 30849, 392, 3043, 794, 337, 264, 31536, 11, 689, 1731, 8850, 264, 2625, 392, 3043, 794, 13, 821, 311, 341, 661, 472, 286, 51008], "temperature": 0.0, "avg_logprob": -0.09613437866896726, "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.007813874632120132}, {"id": 673, "seek": 357604, "start": 3588.92, "end": 3595.16, "text": " put together last night where it's even, and this is just based on Transforma, of basically", "tokens": [51008, 829, 1214, 1036, 1818, 689, 309, 311, 754, 11, 293, 341, 307, 445, 2361, 322, 27938, 64, 11, 295, 1936, 51320], "temperature": 0.0, "avg_logprob": -0.09613437866896726, "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.007813874632120132}, {"id": 674, "seek": 357604, "start": 3595.16, "end": 3601.32, "text": " predict the next most likely word, the next statistically most probable completion,", "tokens": [51320, 6069, 264, 958, 881, 3700, 1349, 11, 264, 958, 36478, 881, 21759, 19372, 11, 51628], "temperature": 0.0, "avg_logprob": -0.09613437866896726, "compression_ratio": 1.6457399103139014, "no_speech_prob": 0.007813874632120132}, {"id": 675, "seek": 360132, "start": 3602.04, "end": 3610.52, "text": " chat GPT, the very small model, 980% higher prevalence of empathetic and very empathetic", "tokens": [50400, 5081, 26039, 51, 11, 264, 588, 1359, 2316, 11, 1722, 4702, 4, 2946, 42583, 295, 27155, 3532, 293, 588, 27155, 3532, 50824], "temperature": 0.0, "avg_logprob": -0.0894479475159576, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.026756184175610542}, {"id": 676, "seek": 360132, "start": 3610.52, "end": 3618.04, "text": " ratings versus a human doctor, and on the left side there, 360% higher prevalence of quality", "tokens": [50824, 24603, 5717, 257, 1952, 4631, 11, 293, 322, 264, 1411, 1252, 456, 11, 13898, 4, 2946, 42583, 295, 3125, 51200], "temperature": 0.0, "avg_logprob": -0.0894479475159576, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.026756184175610542}, {"id": 677, "seek": 360132, "start": 3618.04, "end": 3627.1600000000003, "text": " ratings, good and very good, versus a human doctor, all from the concept of train a Transforma", "tokens": [51200, 24603, 11, 665, 293, 588, 665, 11, 5717, 257, 1952, 4631, 11, 439, 490, 264, 3410, 295, 3847, 257, 27938, 64, 51656], "temperature": 0.0, "avg_logprob": -0.0894479475159576, "compression_ratio": 1.6829268292682926, "no_speech_prob": 0.026756184175610542}, {"id": 678, "seek": 362716, "start": 3627.16, "end": 3633.7999999999997, "text": " based model to predict the next word and feed it as much data as we can find, now being measured in", "tokens": [50364, 2361, 2316, 281, 6069, 264, 958, 1349, 293, 3154, 309, 382, 709, 1412, 382, 321, 393, 915, 11, 586, 885, 12690, 294, 50696], "temperature": 0.0, "avg_logprob": -0.11841653188069662, "compression_ratio": 1.4974358974358974, "no_speech_prob": 0.06559083610773087}, {"id": 679, "seek": 362716, "start": 3633.7999999999997, "end": 3647.96, "text": " the terabytes. So the red pajama data set is about 125 terabytes for 30 trillion tokens. Come on,", "tokens": [50696, 264, 1796, 24538, 13, 407, 264, 2182, 33819, 2404, 1412, 992, 307, 466, 25276, 1796, 24538, 337, 2217, 18723, 22667, 13, 2492, 322, 11, 51404], "temperature": 0.0, "avg_logprob": -0.11841653188069662, "compression_ratio": 1.4974358974358974, "no_speech_prob": 0.06559083610773087}, {"id": 680, "seek": 362716, "start": 3647.96, "end": 3655.08, "text": " a really crazy amount of distance in that six or seven years since Transforma, and a lot of it", "tokens": [51404, 257, 534, 3219, 2372, 295, 4560, 294, 300, 2309, 420, 3407, 924, 1670, 27938, 64, 11, 293, 257, 688, 295, 309, 51760], "temperature": 0.0, "avg_logprob": -0.11841653188069662, "compression_ratio": 1.4974358974358974, "no_speech_prob": 0.06559083610773087}, {"id": 681, "seek": 365508, "start": 3655.08, "end": 3662.44, "text": " has happened post 2020, that's why I call it post 2020, post 2020 AI, because what's come out of GPT", "tokens": [50364, 575, 2011, 2183, 4808, 11, 300, 311, 983, 286, 818, 309, 2183, 4808, 11, 2183, 4808, 7318, 11, 570, 437, 311, 808, 484, 295, 26039, 51, 50732], "temperature": 0.0, "avg_logprob": -0.13721817016601562, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.020960960537195206}, {"id": 682, "seek": 365508, "start": 3662.44, "end": 3668.84, "text": " 3, GPT 4 and all other models that you've seen on my bubbles visualization and the models table", "tokens": [50732, 805, 11, 26039, 51, 1017, 293, 439, 661, 5245, 300, 291, 600, 1612, 322, 452, 16295, 25801, 293, 264, 5245, 3199, 51052], "temperature": 0.0, "avg_logprob": -0.13721817016601562, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.020960960537195206}, {"id": 683, "seek": 365508, "start": 3669.48, "end": 3675.56, "text": " really make this intriguing. We were going to mainly talk about open source today and do note", "tokens": [51084, 534, 652, 341, 32503, 13, 492, 645, 516, 281, 8704, 751, 466, 1269, 4009, 965, 293, 360, 3637, 51388], "temperature": 0.0, "avg_logprob": -0.13721817016601562, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.020960960537195206}, {"id": 684, "seek": 365508, "start": 3675.56, "end": 3683.4, "text": " the Lama models there, the stable LM models, the Olmo model which is due out in the next few weeks,", "tokens": [51388, 264, 441, 2404, 5245, 456, 11, 264, 8351, 46529, 5245, 11, 264, 6141, 3280, 2316, 597, 307, 3462, 484, 294, 264, 958, 1326, 3259, 11, 51780], "temperature": 0.0, "avg_logprob": -0.13721817016601562, "compression_ratio": 1.6049382716049383, "no_speech_prob": 0.020960960537195206}, {"id": 685, "seek": 368340, "start": 3683.4, "end": 3689.4, "text": " I'm hoping for January or February, that's Alan AI's model down the bottom, and the Falcon model", "tokens": [50364, 286, 478, 7159, 337, 7061, 420, 8711, 11, 300, 311, 16442, 7318, 311, 2316, 760, 264, 2767, 11, 293, 264, 31801, 2316, 50664], "temperature": 0.0, "avg_logprob": -0.11977427164713542, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.0014549798797816038}, {"id": 686, "seek": 368340, "start": 3689.4, "end": 3703.08, "text": " there out of the UAE, all for open source. Grab a question from Ben, if we can, and our other", "tokens": [50664, 456, 484, 295, 264, 32765, 36, 11, 439, 337, 1269, 4009, 13, 20357, 257, 1168, 490, 3964, 11, 498, 321, 393, 11, 293, 527, 661, 51348], "temperature": 0.0, "avg_logprob": -0.11977427164713542, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.0014549798797816038}, {"id": 687, "seek": 368340, "start": 3703.08, "end": 3708.12, "text": " media thing, our other comment thing is still broken. Glad I kept this back up. Does your", "tokens": [51348, 3021, 551, 11, 527, 661, 2871, 551, 307, 920, 5463, 13, 28301, 286, 4305, 341, 646, 493, 13, 4402, 428, 51600], "temperature": 0.0, "avg_logprob": -0.11977427164713542, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.0014549798797816038}, {"id": 688, "seek": 370812, "start": 3708.12, "end": 3714.92, "text": " definition of the average human for AGI include spirituality? Does regurgitating woke dogma", "tokens": [50364, 7123, 295, 264, 4274, 1952, 337, 316, 26252, 4090, 30637, 30, 4402, 1121, 5476, 16350, 12852, 3000, 1696, 50704], "temperature": 0.0, "avg_logprob": -0.12652825020455025, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.37727609276771545}, {"id": 689, "seek": 370812, "start": 3714.92, "end": 3720.2, "text": " count, a written dogma count, or does it need to have its own thoughts on spirituality? My definition", "tokens": [50704, 1207, 11, 257, 3720, 3000, 1696, 1207, 11, 420, 775, 309, 643, 281, 362, 1080, 1065, 4598, 322, 30637, 30, 1222, 7123, 50968], "temperature": 0.0, "avg_logprob": -0.12652825020455025, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.37727609276771545}, {"id": 690, "seek": 370812, "start": 3720.2, "end": 3730.3599999999997, "text": " of AGI doesn't include any of that, it's much more basic, it is essentially, as we've documented here,", "tokens": [50968, 295, 316, 26252, 1177, 380, 4090, 604, 295, 300, 11, 309, 311, 709, 544, 3875, 11, 309, 307, 4476, 11, 382, 321, 600, 23007, 510, 11, 51476], "temperature": 0.0, "avg_logprob": -0.12652825020455025, "compression_ratio": 1.5828877005347595, "no_speech_prob": 0.37727609276771545}, {"id": 691, "seek": 373036, "start": 3731.32, "end": 3740.04, "text": " it's essentially any human task rather than any human anything. So this did include going into", "tokens": [50412, 309, 311, 4476, 604, 1952, 5633, 2831, 813, 604, 1952, 1340, 13, 407, 341, 630, 4090, 516, 666, 50848], "temperature": 0.0, "avg_logprob": -0.10404777526855469, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.26867443323135376}, {"id": 692, "seek": 373036, "start": 3740.04, "end": 3746.36, "text": " the house and making a cup of coffee, but it doesn't include, you know, having spirituality or having", "tokens": [50848, 264, 1782, 293, 1455, 257, 4414, 295, 4982, 11, 457, 309, 1177, 380, 4090, 11, 291, 458, 11, 1419, 30637, 420, 1419, 51164], "temperature": 0.0, "avg_logprob": -0.10404777526855469, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.26867443323135376}, {"id": 693, "seek": 373036, "start": 3746.36, "end": 3752.84, "text": " emotions or even having a sense of smell, but that's what makes this kind of interesting,", "tokens": [51164, 8462, 420, 754, 1419, 257, 2020, 295, 4316, 11, 457, 300, 311, 437, 1669, 341, 733, 295, 1880, 11, 51488], "temperature": 0.0, "avg_logprob": -0.10404777526855469, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.26867443323135376}, {"id": 694, "seek": 375284, "start": 3753.32, "end": 3756.1200000000003, "text": " there's no agreed upon definition.", "tokens": [50388, 456, 311, 572, 9166, 3564, 7123, 13, 50528], "temperature": 0.0, "avg_logprob": -0.16472982926802202, "compression_ratio": 1.587360594795539, "no_speech_prob": 0.10371160507202148}, {"id": 695, "seek": 375284, "start": 3759.4, "end": 3764.1200000000003, "text": " Quailude Charlie, how many Quailudes have you had this morning? Is that even an appropriate question", "tokens": [50692, 2326, 864, 2303, 13754, 11, 577, 867, 2326, 864, 10131, 362, 291, 632, 341, 2446, 30, 1119, 300, 754, 364, 6854, 1168, 50928], "temperature": 0.0, "avg_logprob": -0.16472982926802202, "compression_ratio": 1.587360594795539, "no_speech_prob": 0.10371160507202148}, {"id": 696, "seek": 375284, "start": 3764.1200000000003, "end": 3769.88, "text": " to ask on a live stream? I still like to listen to those guys speaking about pre-gaming, is that", "tokens": [50928, 281, 1029, 322, 257, 1621, 4309, 30, 286, 920, 411, 281, 2140, 281, 729, 1074, 4124, 466, 659, 12, 70, 5184, 11, 307, 300, 51216], "temperature": 0.0, "avg_logprob": -0.16472982926802202, "compression_ratio": 1.587360594795539, "no_speech_prob": 0.10371160507202148}, {"id": 697, "seek": 375284, "start": 3769.88, "end": 3775.7200000000003, "text": " programming in the 50s and 60s, and remembering the hardware and software with early stuff. Yeah,", "tokens": [51216, 9410, 294, 264, 2625, 82, 293, 4060, 82, 11, 293, 20719, 264, 8837, 293, 4722, 365, 2440, 1507, 13, 865, 11, 51508], "temperature": 0.0, "avg_logprob": -0.16472982926802202, "compression_ratio": 1.587360594795539, "no_speech_prob": 0.10371160507202148}, {"id": 698, "seek": 375284, "start": 3775.7200000000003, "end": 3780.28, "text": " well the earliest stuff I've got is the late 80s, early 90s, but I was still playing around with", "tokens": [51508, 731, 264, 20573, 1507, 286, 600, 658, 307, 264, 3469, 4688, 82, 11, 2440, 4289, 82, 11, 457, 286, 390, 920, 2433, 926, 365, 51736], "temperature": 0.0, "avg_logprob": -0.16472982926802202, "compression_ratio": 1.587360594795539, "no_speech_prob": 0.10371160507202148}, {"id": 699, "seek": 378028, "start": 3780.36, "end": 3792.1200000000003, "text": " Kobol, Pascal, Algo, and we were forced to write assembly language stuff in the university, the", "tokens": [50368, 46353, 401, 11, 41723, 11, 967, 1571, 11, 293, 321, 645, 7579, 281, 2464, 12103, 2856, 1507, 294, 264, 5454, 11, 264, 50956], "temperature": 0.0, "avg_logprob": -0.12797257706925674, "compression_ratio": 1.4477611940298507, "no_speech_prob": 0.019120484590530396}, {"id": 700, "seek": 378028, "start": 3792.1200000000003, "end": 3797.5600000000004, "text": " computer science degree that I was doing, which is pretty horrendous. It was a fascinating time,", "tokens": [50956, 3820, 3497, 4314, 300, 286, 390, 884, 11, 597, 307, 1238, 49520, 563, 13, 467, 390, 257, 10343, 565, 11, 51228], "temperature": 0.0, "avg_logprob": -0.12797257706925674, "compression_ratio": 1.4477611940298507, "no_speech_prob": 0.019120484590530396}, {"id": 701, "seek": 378028, "start": 3797.5600000000004, "end": 3804.76, "text": " and in some ways, right now, reminds me of those early days, and I cannot remember back to the 50s", "tokens": [51228, 293, 294, 512, 2098, 11, 558, 586, 11, 12025, 385, 295, 729, 2440, 1708, 11, 293, 286, 2644, 1604, 646, 281, 264, 2625, 82, 51588], "temperature": 0.0, "avg_logprob": -0.12797257706925674, "compression_ratio": 1.4477611940298507, "no_speech_prob": 0.019120484590530396}, {"id": 702, "seek": 380476, "start": 3804.76, "end": 3810.6000000000004, "text": " and 60s because I wasn't there, but I was there in the 80s and 90s, I was there with IRC, I was there", "tokens": [50364, 293, 4060, 82, 570, 286, 2067, 380, 456, 11, 457, 286, 390, 456, 294, 264, 4688, 82, 293, 4289, 82, 11, 286, 390, 456, 365, 16486, 34, 11, 286, 390, 456, 50656], "temperature": 0.0, "avg_logprob": -0.13105292547316777, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.2067899852991104}, {"id": 703, "seek": 380476, "start": 3810.6000000000004, "end": 3817.5600000000004, "text": " with ICQ, I was there with the early programming languages, and the very early computers, my first", "tokens": [50656, 365, 14360, 48, 11, 286, 390, 456, 365, 264, 2440, 9410, 8650, 11, 293, 264, 588, 2440, 10807, 11, 452, 700, 51004], "temperature": 0.0, "avg_logprob": -0.13105292547316777, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.2067899852991104}, {"id": 704, "seek": 380476, "start": 3817.5600000000004, "end": 3827.0, "text": " via my older brother was a 486 with like a 300 meg hard drive and 8 meg of RAM. That time was", "tokens": [51004, 5766, 452, 4906, 3708, 390, 257, 11174, 21, 365, 411, 257, 6641, 10816, 1152, 3332, 293, 1649, 10816, 295, 14561, 13, 663, 565, 390, 51476], "temperature": 0.0, "avg_logprob": -0.13105292547316777, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.2067899852991104}, {"id": 705, "seek": 382700, "start": 3827.0, "end": 3836.44, "text": " exciting, the communication, figuring out how to network via coax, via T pieces, via parallel cables", "tokens": [50364, 4670, 11, 264, 6101, 11, 15213, 484, 577, 281, 3209, 5766, 598, 2797, 11, 5766, 314, 3755, 11, 5766, 8952, 17555, 50836], "temperature": 0.0, "avg_logprob": -0.10053147090954727, "compression_ratio": 1.7, "no_speech_prob": 0.18706804513931274}, {"id": 706, "seek": 382700, "start": 3836.44, "end": 3844.36, "text": " or serial cables, getting doom working across serial cables. In some ways, this is the same sort", "tokens": [50836, 420, 17436, 17555, 11, 1242, 37131, 1364, 2108, 17436, 17555, 13, 682, 512, 2098, 11, 341, 307, 264, 912, 1333, 51232], "temperature": 0.0, "avg_logprob": -0.10053147090954727, "compression_ratio": 1.7, "no_speech_prob": 0.18706804513931274}, {"id": 707, "seek": 382700, "start": 3844.36, "end": 3850.92, "text": " of excitement for me, we're finding out how to connect things together, how to create new worlds", "tokens": [51232, 295, 14755, 337, 385, 11, 321, 434, 5006, 484, 577, 281, 1745, 721, 1214, 11, 577, 281, 1884, 777, 13401, 51560], "temperature": 0.0, "avg_logprob": -0.10053147090954727, "compression_ratio": 1.7, "no_speech_prob": 0.18706804513931274}, {"id": 708, "seek": 382700, "start": 3850.92, "end": 3856.84, "text": " essentially. I would probably say that this is more exciting, but there's always something about", "tokens": [51560, 4476, 13, 286, 576, 1391, 584, 300, 341, 307, 544, 4670, 11, 457, 456, 311, 1009, 746, 466, 51856], "temperature": 0.0, "avg_logprob": -0.10053147090954727, "compression_ratio": 1.7, "no_speech_prob": 0.18706804513931274}, {"id": 709, "seek": 385684, "start": 3857.0, "end": 3862.6000000000004, "text": " hindsight, especially with rose colored glasses, where back then looked kind of cool. If I was", "tokens": [50372, 44357, 11, 2318, 365, 10895, 14332, 10812, 11, 689, 646, 550, 2956, 733, 295, 1627, 13, 759, 286, 390, 50652], "temperature": 0.0, "avg_logprob": -0.11058584193593447, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.006902941968291998}, {"id": 710, "seek": 385684, "start": 3862.6000000000004, "end": 3870.6000000000004, "text": " forced to go back there and use a 486 with a 33k modem, if we even had web access, I'd be pretty", "tokens": [50652, 7579, 281, 352, 646, 456, 293, 764, 257, 11174, 21, 365, 257, 11816, 74, 1072, 443, 11, 498, 321, 754, 632, 3670, 2105, 11, 286, 1116, 312, 1238, 51052], "temperature": 0.0, "avg_logprob": -0.11058584193593447, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.006902941968291998}, {"id": 711, "seek": 385684, "start": 3870.6000000000004, "end": 3877.88, "text": " upset waiting for DOS to load or Windows to load over five minutes, and then having the IPX", "tokens": [51052, 8340, 3806, 337, 413, 4367, 281, 3677, 420, 8591, 281, 3677, 670, 1732, 2077, 11, 293, 550, 1419, 264, 8671, 55, 51416], "temperature": 0.0, "avg_logprob": -0.11058584193593447, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.006902941968291998}, {"id": 712, "seek": 385684, "start": 3877.88, "end": 3884.6800000000003, "text": " networking breakdown every day just because. If you want a reminder of those times, just try and", "tokens": [51416, 17985, 18188, 633, 786, 445, 570, 13, 759, 291, 528, 257, 13548, 295, 729, 1413, 11, 445, 853, 293, 51756], "temperature": 0.0, "avg_logprob": -0.11058584193593447, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.006902941968291998}, {"id": 713, "seek": 388468, "start": 3884.68, "end": 3891.0, "text": " get Bluetooth working in 2023 or try and get your printer working in 2023. Same technology,", "tokens": [50364, 483, 20286, 1364, 294, 44377, 420, 853, 293, 483, 428, 16671, 1364, 294, 44377, 13, 10635, 2899, 11, 50680], "temperature": 0.0, "avg_logprob": -0.09904609901317651, "compression_ratio": 1.4395604395604396, "no_speech_prob": 0.016401534900069237}, {"id": 714, "seek": 388468, "start": 3891.0, "end": 3900.9199999999996, "text": " same issues, we haven't solved it in 40 years. All right, let's go over question from Greg. We did", "tokens": [50680, 912, 2663, 11, 321, 2378, 380, 13041, 309, 294, 3356, 924, 13, 1057, 558, 11, 718, 311, 352, 670, 1168, 490, 11490, 13, 492, 630, 51176], "temperature": 0.0, "avg_logprob": -0.09904609901317651, "compression_ratio": 1.4395604395604396, "no_speech_prob": 0.016401534900069237}, {"id": 715, "seek": 388468, "start": 3900.9199999999996, "end": 3905.16, "text": " kind of cover this last time, but let's see if we can cover this again.", "tokens": [51176, 733, 295, 2060, 341, 1036, 565, 11, 457, 718, 311, 536, 498, 321, 393, 2060, 341, 797, 13, 51388], "temperature": 0.0, "avg_logprob": -0.09904609901317651, "compression_ratio": 1.4395604395604396, "no_speech_prob": 0.016401534900069237}, {"id": 716, "seek": 390516, "start": 3905.24, "end": 3911.64, "text": " Not too happy with that", "tokens": [50368, 1726, 886, 2055, 365, 300, 50688], "temperature": 0.0, "avg_logprob": -0.23579780260721842, "compression_ratio": 1.323076923076923, "no_speech_prob": 0.048849523067474365}, {"id": 717, "seek": 390516, "start": 3913.3999999999996, "end": 3916.68, "text": " comment thing failing, it makes all of this a little bit harder.", "tokens": [50776, 2871, 551, 18223, 11, 309, 1669, 439, 295, 341, 257, 707, 857, 6081, 13, 50940], "temperature": 0.0, "avg_logprob": -0.23579780260721842, "compression_ratio": 1.323076923076923, "no_speech_prob": 0.048849523067474365}, {"id": 718, "seek": 390516, "start": 3917.7999999999997, "end": 3923.3199999999997, "text": " Greg says, given you don't listen to Jan, who are the main people you do listen to?", "tokens": [50996, 11490, 1619, 11, 2212, 291, 500, 380, 2140, 281, 4956, 11, 567, 366, 264, 2135, 561, 291, 360, 2140, 281, 30, 51272], "temperature": 0.0, "avg_logprob": -0.23579780260721842, "compression_ratio": 1.323076923076923, "no_speech_prob": 0.048849523067474365}, {"id": 719, "seek": 392332, "start": 3923.6400000000003, "end": 3927.7200000000003, "text": " Ilya, Kapathi, Hinton.", "tokens": [50380, 286, 45106, 11, 21216, 42715, 11, 389, 12442, 13, 50584], "temperature": 0.0, "avg_logprob": -0.21068073454357328, "compression_ratio": 1.4375, "no_speech_prob": 0.12753058969974518}, {"id": 720, "seek": 392332, "start": 3930.84, "end": 3936.52, "text": " Greg is great. Greg Brockman from OpenAI. I think I mentioned last time he sat down for two weeks", "tokens": [50740, 11490, 307, 869, 13, 11490, 32093, 1601, 490, 7238, 48698, 13, 286, 519, 286, 2835, 1036, 565, 415, 3227, 760, 337, 732, 3259, 51024], "temperature": 0.0, "avg_logprob": -0.21068073454357328, "compression_ratio": 1.4375, "no_speech_prob": 0.12753058969974518}, {"id": 721, "seek": 392332, "start": 3936.52, "end": 3943.48, "text": " and got GPT4 working. So even when we have competitors, they're not massaging it and", "tokens": [51024, 293, 658, 26039, 51, 19, 1364, 13, 407, 754, 562, 321, 362, 18333, 11, 436, 434, 406, 2758, 3568, 309, 293, 51372], "temperature": 0.0, "avg_logprob": -0.21068073454357328, "compression_ratio": 1.4375, "no_speech_prob": 0.12753058969974518}, {"id": 722, "seek": 392332, "start": 3943.48, "end": 3949.2400000000002, "text": " getting it ready for UX and public consumption, the way that OpenAI have done. And that's not", "tokens": [51372, 1242, 309, 1919, 337, 40176, 293, 1908, 12126, 11, 264, 636, 300, 7238, 48698, 362, 1096, 13, 400, 300, 311, 406, 51660], "temperature": 0.0, "avg_logprob": -0.21068073454357328, "compression_ratio": 1.4375, "no_speech_prob": 0.12753058969974518}, {"id": 723, "seek": 394924, "start": 3949.24, "end": 3960.8399999999997, "text": " because of their $100 billion or their 750 very smart people. It's because of one or two people", "tokens": [50364, 570, 295, 641, 1848, 6879, 5218, 420, 641, 31682, 588, 4069, 561, 13, 467, 311, 570, 295, 472, 420, 732, 561, 50944], "temperature": 0.0, "avg_logprob": -0.13110328788187967, "compression_ratio": 1.4733727810650887, "no_speech_prob": 0.0073438105173408985}, {"id": 724, "seek": 394924, "start": 3960.8399999999997, "end": 3964.68, "text": " in there. Ilya is one of them, but Greg is one I listen to and the way that he got this stuff", "tokens": [50944, 294, 456, 13, 286, 45106, 307, 472, 295, 552, 11, 457, 11490, 307, 472, 286, 2140, 281, 293, 264, 636, 300, 415, 658, 341, 1507, 51136], "temperature": 0.0, "avg_logprob": -0.13110328788187967, "compression_ratio": 1.4733727810650887, "no_speech_prob": 0.0073438105173408985}, {"id": 725, "seek": 394924, "start": 3964.68, "end": 3979.0, "text": " working is fascinating. We got McGuffin, who is remembering", "tokens": [51136, 1364, 307, 10343, 13, 492, 658, 21865, 1245, 259, 11, 567, 307, 20719, 51852], "temperature": 0.0, "avg_logprob": -0.13110328788187967, "compression_ratio": 1.4733727810650887, "no_speech_prob": 0.0073438105173408985}, {"id": 726, "seek": 397900, "start": 3979.0, "end": 3985.4, "text": " Token Ring. Yes, some of the games in that time were just amazing. I was looking at Rise of", "tokens": [50364, 314, 8406, 19844, 13, 1079, 11, 512, 295, 264, 2813, 294, 300, 565, 645, 445, 2243, 13, 286, 390, 1237, 412, 34482, 295, 50684], "temperature": 0.0, "avg_logprob": -0.1718547609117296, "compression_ratio": 1.5587044534412955, "no_speech_prob": 0.008843785151839256}, {"id": 727, "seek": 397900, "start": 3985.4, "end": 3992.04, "text": " the Triad the other day, Wolfenstein 3D. I mean the original Wolfe 3D, Descent. Who played Descent", "tokens": [50684, 264, 10931, 345, 264, 661, 786, 11, 19925, 6570, 9089, 805, 35, 13, 286, 914, 264, 3380, 19925, 2106, 805, 35, 11, 3885, 2207, 13, 2102, 3737, 3885, 2207, 51016], "temperature": 0.0, "avg_logprob": -0.1718547609117296, "compression_ratio": 1.5587044534412955, "no_speech_prob": 0.008843785151839256}, {"id": 728, "seek": 397900, "start": 3992.04, "end": 3999.4, "text": " with me? That was amazing. And my favorite was a game called Total Annihilation, which we didn't", "tokens": [51016, 365, 385, 30, 663, 390, 2243, 13, 400, 452, 2954, 390, 257, 1216, 1219, 23170, 1107, 3722, 71, 16067, 11, 597, 321, 994, 380, 51384], "temperature": 0.0, "avg_logprob": -0.1718547609117296, "compression_ratio": 1.5587044534412955, "no_speech_prob": 0.008843785151839256}, {"id": 729, "seek": 397900, "start": 3999.4, "end": 4006.28, "text": " really hear a lot of because Diablo and Warcraft kind of competed with it, but that was that were", "tokens": [51384, 534, 1568, 257, 688, 295, 570, 8789, 21991, 293, 3630, 5611, 733, 295, 43619, 365, 309, 11, 457, 300, 390, 300, 645, 51728], "temperature": 0.0, "avg_logprob": -0.1718547609117296, "compression_ratio": 1.5587044534412955, "no_speech_prob": 0.008843785151839256}, {"id": 730, "seek": 400628, "start": 4006.36, "end": 4014.6000000000004, "text": " my favorites. Yeah, I saw the stream cut out there. I'm not sure what that was. I'll blame", "tokens": [50368, 452, 16907, 13, 865, 11, 286, 1866, 264, 4309, 1723, 484, 456, 13, 286, 478, 406, 988, 437, 300, 390, 13, 286, 603, 10127, 50780], "temperature": 0.0, "avg_logprob": -0.10355164023006663, "compression_ratio": 1.5362903225806452, "no_speech_prob": 0.045336153358221054}, {"id": 731, "seek": 400628, "start": 4015.2400000000002, "end": 4020.52, "text": " YouTube for that one. Altman's now invested into a company that creates neuromorphic analog AI chips.", "tokens": [50812, 3088, 337, 300, 472, 13, 15992, 1601, 311, 586, 13104, 666, 257, 2237, 300, 7829, 12087, 32702, 299, 16660, 7318, 11583, 13, 51076], "temperature": 0.0, "avg_logprob": -0.10355164023006663, "compression_ratio": 1.5362903225806452, "no_speech_prob": 0.045336153358221054}, {"id": 732, "seek": 400628, "start": 4020.52, "end": 4025.5600000000004, "text": " There's a lot of talk right now about Quantum. I won't be covering Quantum, but if we get James", "tokens": [51076, 821, 311, 257, 688, 295, 751, 558, 586, 466, 44964, 13, 286, 1582, 380, 312, 10322, 44964, 11, 457, 498, 321, 483, 5678, 51328], "temperature": 0.0, "avg_logprob": -0.10355164023006663, "compression_ratio": 1.5362903225806452, "no_speech_prob": 0.045336153358221054}, {"id": 733, "seek": 400628, "start": 4025.5600000000004, "end": 4034.84, "text": " on here, we will cover Quantum. James from IBM is my go-to colleague for that kind of thing.", "tokens": [51328, 322, 510, 11, 321, 486, 2060, 44964, 13, 5678, 490, 23487, 307, 452, 352, 12, 1353, 13532, 337, 300, 733, 295, 551, 13, 51792], "temperature": 0.0, "avg_logprob": -0.10355164023006663, "compression_ratio": 1.5362903225806452, "no_speech_prob": 0.045336153358221054}, {"id": 734, "seek": 403484, "start": 4034.84, "end": 4039.88, "text": " He programs Quantum stuff. Day to day, he's the advocate for Quantum computing for IBM.", "tokens": [50364, 634, 4268, 44964, 1507, 13, 5226, 281, 786, 11, 415, 311, 264, 14608, 337, 44964, 15866, 337, 23487, 13, 50616], "temperature": 0.0, "avg_logprob": -0.1170257783271897, "compression_ratio": 1.4183673469387754, "no_speech_prob": 0.0018674335442483425}, {"id": 735, "seek": 403484, "start": 4042.36, "end": 4050.6800000000003, "text": " Awesome. All right, we may look at wrapping up. That's a full hour of just answering questions and", "tokens": [50740, 10391, 13, 1057, 558, 11, 321, 815, 574, 412, 21993, 493, 13, 663, 311, 257, 1577, 1773, 295, 445, 13430, 1651, 293, 51156], "temperature": 0.0, "avg_logprob": -0.1170257783271897, "compression_ratio": 1.4183673469387754, "no_speech_prob": 0.0018674335442483425}, {"id": 736, "seek": 403484, "start": 4051.56, "end": 4058.28, "text": " going back in time and reminiscing about what life was like back in the pre-dawn. Actually,", "tokens": [51200, 516, 646, 294, 565, 293, 33765, 2175, 466, 437, 993, 390, 411, 646, 294, 264, 659, 12, 2675, 895, 13, 5135, 11, 51536], "temperature": 0.0, "avg_logprob": -0.1170257783271897, "compression_ratio": 1.4183673469387754, "no_speech_prob": 0.0018674335442483425}, {"id": 737, "seek": 405828, "start": 4058.28, "end": 4064.84, "text": " it was the pre-internet, really. If we say that the web hit us from public utilities,", "tokens": [50364, 309, 390, 264, 659, 12, 259, 2231, 302, 11, 534, 13, 759, 321, 584, 300, 264, 3670, 2045, 505, 490, 1908, 30482, 11, 50692], "temperature": 0.0, "avg_logprob": -0.12161939208571976, "compression_ratio": 1.4322916666666667, "no_speech_prob": 0.452859103679657}, {"id": 738, "seek": 405828, "start": 4064.84, "end": 4071.48, "text": " often viacologies and universities in the early 90s, that means just before that was all local", "tokens": [50692, 2049, 1932, 326, 6204, 293, 11779, 294, 264, 2440, 4289, 82, 11, 300, 1355, 445, 949, 300, 390, 439, 2654, 51024], "temperature": 0.0, "avg_logprob": -0.12161939208571976, "compression_ratio": 1.4322916666666667, "no_speech_prob": 0.452859103679657}, {"id": 739, "seek": 405828, "start": 4071.48, "end": 4082.1200000000003, "text": " networking or hacking up things inside DOS and Windows 3.1 was my first one. I did spend a lot", "tokens": [51024, 17985, 420, 31422, 493, 721, 1854, 413, 4367, 293, 8591, 805, 13, 16, 390, 452, 700, 472, 13, 286, 630, 3496, 257, 688, 51556], "temperature": 0.0, "avg_logprob": -0.12161939208571976, "compression_ratio": 1.4322916666666667, "no_speech_prob": 0.452859103679657}, {"id": 740, "seek": 408212, "start": 4082.12, "end": 4093.72, "text": " of time talking about OS2 Warp 4, which I used a little bit, but I would talk about it with my", "tokens": [50364, 295, 565, 1417, 466, 12731, 17, 3630, 79, 1017, 11, 597, 286, 1143, 257, 707, 857, 11, 457, 286, 576, 751, 466, 309, 365, 452, 50944], "temperature": 0.0, "avg_logprob": -0.23608510494232177, "compression_ratio": 1.1982758620689655, "no_speech_prob": 0.15193714201450348}, {"id": 741, "seek": 408212, "start": 4094.68, "end": 4097.96, "text": " consulting colleagues just as I laugh. OS...", "tokens": [50992, 23682, 7734, 445, 382, 286, 5801, 13, 12731, 485, 51156], "temperature": 0.0, "avg_logprob": -0.23608510494232177, "compression_ratio": 1.1982758620689655, "no_speech_prob": 0.15193714201450348}, {"id": 742, "seek": 409796, "start": 4097.96, "end": 4117.64, "text": " Look, it may be my wireless. Who knows? I love the emojis there that are just the scared face.", "tokens": [50364, 2053, 11, 309, 815, 312, 452, 14720, 13, 2102, 3255, 30, 286, 959, 264, 19611, 40371, 456, 300, 366, 445, 264, 5338, 1851, 13, 51348], "temperature": 0.0, "avg_logprob": -0.20306896713544736, "compression_ratio": 1.3475177304964538, "no_speech_prob": 0.034093357622623444}, {"id": 743, "seek": 409796, "start": 4118.28, "end": 4127.0, "text": " Oh, I see it now. You can just send an embarrassed face. Cool. There are a couple of approaches", "tokens": [51380, 876, 11, 286, 536, 309, 586, 13, 509, 393, 445, 2845, 364, 16843, 1851, 13, 8561, 13, 821, 366, 257, 1916, 295, 11587, 51816], "temperature": 0.0, "avg_logprob": -0.20306896713544736, "compression_ratio": 1.3475177304964538, "no_speech_prob": 0.034093357622623444}, {"id": 744, "seek": 412700, "start": 4127.08, "end": 4133.16, "text": " to this already. You could talk about GPT-4 as being multimodal because it's got the vision component,", "tokens": [50368, 281, 341, 1217, 13, 509, 727, 751, 466, 26039, 51, 12, 19, 382, 885, 32972, 378, 304, 570, 309, 311, 658, 264, 5201, 6542, 11, 50672], "temperature": 0.0, "avg_logprob": -0.1360126013284201, "compression_ratio": 1.6271186440677967, "no_speech_prob": 0.044659845530986786}, {"id": 745, "seek": 412700, "start": 4133.16, "end": 4139.24, "text": " and then because they've tied Dolly 3 into the chat GPT interface, it's like they're tying", "tokens": [50672, 293, 550, 570, 436, 600, 9601, 1144, 13020, 805, 666, 264, 5081, 26039, 51, 9226, 11, 309, 311, 411, 436, 434, 32405, 50976], "temperature": 0.0, "avg_logprob": -0.1360126013284201, "compression_ratio": 1.6271186440677967, "no_speech_prob": 0.044659845530986786}, {"id": 746, "seek": 412700, "start": 4139.24, "end": 4146.52, "text": " together three or four different models because you could also say that what was previously", "tokens": [50976, 1214, 1045, 420, 1451, 819, 5245, 570, 291, 727, 611, 584, 300, 437, 390, 8046, 51340], "temperature": 0.0, "avg_logprob": -0.1360126013284201, "compression_ratio": 1.6271186440677967, "no_speech_prob": 0.044659845530986786}, {"id": 747, "seek": 412700, "start": 4146.52, "end": 4154.44, "text": " called the code interpretation plugin, now called the data analysis plugin, is a third or a fourth", "tokens": [51340, 1219, 264, 3089, 14174, 23407, 11, 586, 1219, 264, 1412, 5215, 23407, 11, 307, 257, 2636, 420, 257, 6409, 51736], "temperature": 0.0, "avg_logprob": -0.1360126013284201, "compression_ratio": 1.6271186440677967, "no_speech_prob": 0.044659845530986786}, {"id": 748, "seek": 415444, "start": 4154.44, "end": 4161.24, "text": " model. So you've got GPT-4 text, you've got GPT-4 vision, you've got code interpretation,", "tokens": [50364, 2316, 13, 407, 291, 600, 658, 26039, 51, 12, 19, 2487, 11, 291, 600, 658, 26039, 51, 12, 19, 5201, 11, 291, 600, 658, 3089, 14174, 11, 50704], "temperature": 0.0, "avg_logprob": -0.10656329205161647, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.03209472820162773}, {"id": 749, "seek": 415444, "start": 4161.24, "end": 4168.28, "text": " and you've got Dolly 3. Now, some of those you would say are completely separate and discreet,", "tokens": [50704, 293, 291, 600, 658, 1144, 13020, 805, 13, 823, 11, 512, 295, 729, 291, 576, 584, 366, 2584, 4994, 293, 2983, 4751, 11, 51056], "temperature": 0.0, "avg_logprob": -0.10656329205161647, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.03209472820162773}, {"id": 750, "seek": 415444, "start": 4168.28, "end": 4173.719999999999, "text": " but the fact that they've combined them into one interface is fascinating. Make me a picture", "tokens": [51056, 457, 264, 1186, 300, 436, 600, 9354, 552, 666, 472, 9226, 307, 10343, 13, 4387, 385, 257, 3036, 51328], "temperature": 0.0, "avg_logprob": -0.10656329205161647, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.03209472820162773}, {"id": 751, "seek": 417372, "start": 4173.72, "end": 4186.52, "text": " of a YouTube stream hanging for no reason. So this is all in the same platform, obviously", "tokens": [50364, 295, 257, 3088, 4309, 8345, 337, 572, 1778, 13, 407, 341, 307, 439, 294, 264, 912, 3663, 11, 2745, 51004], "temperature": 0.0, "avg_logprob": -0.1003597487866039, "compression_ratio": 1.4455958549222798, "no_speech_prob": 0.3485274612903595}, {"id": 752, "seek": 417372, "start": 4186.52, "end": 4195.400000000001, "text": " not using the same model, but who's going to know if a lab joins those all together? That's", "tokens": [51004, 406, 1228, 264, 912, 2316, 11, 457, 567, 311, 516, 281, 458, 498, 257, 2715, 24397, 729, 439, 1214, 30, 663, 311, 51448], "temperature": 0.0, "avg_logprob": -0.1003597487866039, "compression_ratio": 1.4455958549222798, "no_speech_prob": 0.3485274612903595}, {"id": 753, "seek": 417372, "start": 4195.400000000001, "end": 4202.92, "text": " why I'm fascinated to see what our final version of Gemini looks like, and the rumors are that it", "tokens": [51448, 983, 286, 478, 24597, 281, 536, 437, 527, 2572, 3037, 295, 22894, 3812, 1542, 411, 11, 293, 264, 21201, 366, 300, 309, 51824], "temperature": 0.0, "avg_logprob": -0.1003597487866039, "compression_ratio": 1.4455958549222798, "no_speech_prob": 0.3485274612903595}, {"id": 754, "seek": 420292, "start": 4202.92, "end": 4209.16, "text": " will have separate vision components to text components. Thanks, Dolly 3, here's the image", "tokens": [50364, 486, 362, 4994, 5201, 6677, 281, 2487, 6677, 13, 2561, 11, 1144, 13020, 805, 11, 510, 311, 264, 3256, 50676], "temperature": 0.0, "avg_logprob": -0.08997406904724822, "compression_ratio": 1.5039370078740157, "no_speech_prob": 0.019111135974526405}, {"id": 755, "seek": 420292, "start": 4209.16, "end": 4219.56, "text": " of a YouTube stream that has unexpectedly paused. Awesome. All right, let's wrap up with this question", "tokens": [50676, 295, 257, 3088, 4309, 300, 575, 40452, 46860, 13, 10391, 13, 1057, 558, 11, 718, 311, 7019, 493, 365, 341, 1168, 51196], "temperature": 0.0, "avg_logprob": -0.08997406904724822, "compression_ratio": 1.5039370078740157, "no_speech_prob": 0.019111135974526405}, {"id": 756, "seek": 420292, "start": 4219.56, "end": 4223.56, "text": " from Drew, latest deep intro inspired me to ask you, what books would you like to see in the", "tokens": [51196, 490, 25550, 11, 6792, 2452, 12897, 7547, 385, 281, 1029, 291, 11, 437, 3642, 576, 291, 411, 281, 536, 294, 264, 51396], "temperature": 0.0, "avg_logprob": -0.08997406904724822, "compression_ratio": 1.5039370078740157, "no_speech_prob": 0.019111135974526405}, {"id": 757, "seek": 420292, "start": 4223.56, "end": 4229.16, "text": " school curriculum that might encourage better evolution, unity, empathy, and critical thinking?", "tokens": [51396, 1395, 14302, 300, 1062, 5373, 1101, 9303, 11, 18205, 11, 18701, 11, 293, 4924, 1953, 30, 51676], "temperature": 0.0, "avg_logprob": -0.08997406904724822, "compression_ratio": 1.5039370078740157, "no_speech_prob": 0.019111135974526405}, {"id": 758, "seek": 422916, "start": 4229.48, "end": 4235.16, "text": " All right, let's give you a big answer here for something that's just a few years ahead. You could", "tokens": [50380, 1057, 558, 11, 718, 311, 976, 291, 257, 955, 1867, 510, 337, 746, 300, 311, 445, 257, 1326, 924, 2286, 13, 509, 727, 50664], "temperature": 0.0, "avg_logprob": -0.12471771240234375, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0012065621558576822}, {"id": 759, "seek": 422916, "start": 4235.16, "end": 4242.12, "text": " say that it's immediate, but let's step forward a few years. The answer to my question, my answer", "tokens": [50664, 584, 300, 309, 311, 11629, 11, 457, 718, 311, 1823, 2128, 257, 1326, 924, 13, 440, 1867, 281, 452, 1168, 11, 452, 1867, 51012], "temperature": 0.0, "avg_logprob": -0.12471771240234375, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0012065621558576822}, {"id": 760, "seek": 422916, "start": 4242.12, "end": 4250.12, "text": " to your question is I'd like to see no books on the school curriculum, and I'm not necessarily", "tokens": [51012, 281, 428, 1168, 307, 286, 1116, 411, 281, 536, 572, 3642, 322, 264, 1395, 14302, 11, 293, 286, 478, 406, 4725, 51412], "temperature": 0.0, "avg_logprob": -0.12471771240234375, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0012065621558576822}, {"id": 761, "seek": 422916, "start": 4250.12, "end": 4255.4, "text": " being groundbreaking with that view. If you'd like to read more, I've documented this really", "tokens": [51412, 885, 42491, 365, 300, 1910, 13, 759, 291, 1116, 411, 281, 1401, 544, 11, 286, 600, 23007, 341, 534, 51676], "temperature": 0.0, "avg_logprob": -0.12471771240234375, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.0012065621558576822}, {"id": 762, "seek": 425540, "start": 4255.48, "end": 4263.879999999999, "text": " heavily, all the way back in 2017, lifearchitect.ai, let's see if I can get this,", "tokens": [50368, 10950, 11, 439, 264, 636, 646, 294, 6591, 11, 993, 1178, 5739, 13, 1301, 11, 718, 311, 536, 498, 286, 393, 483, 341, 11, 50788], "temperature": 0.0, "avg_logprob": -0.24052236498016671, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.1365579217672348}, {"id": 763, "seek": 425540, "start": 4263.879999999999, "end": 4271.08, "text": " lifearchitect.ai slash ad Astra. I'll dump this into the chat because it's a really interesting", "tokens": [50788, 993, 1178, 5739, 13, 1301, 17330, 614, 45242, 13, 286, 603, 11430, 341, 666, 264, 5081, 570, 309, 311, 257, 534, 1880, 51148], "temperature": 0.0, "avg_logprob": -0.24052236498016671, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.1365579217672348}, {"id": 764, "seek": 425540, "start": 4271.08, "end": 4277.639999999999, "text": " read. You can download the article as it appeared in Mensa magazine. Let's actually pop that open.", "tokens": [51148, 1401, 13, 509, 393, 5484, 264, 7222, 382, 309, 8516, 294, 7364, 64, 11332, 13, 961, 311, 767, 1665, 300, 1269, 13, 51476], "temperature": 0.0, "avg_logprob": -0.24052236498016671, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.1365579217672348}, {"id": 765, "seek": 425540, "start": 4277.639999999999, "end": 4284.599999999999, "text": " It basically says, and this was at the time that I was working alongside Elon Musk's school,", "tokens": [51476, 467, 1936, 1619, 11, 293, 341, 390, 412, 264, 565, 300, 286, 390, 1364, 12385, 28498, 26019, 311, 1395, 11, 51824], "temperature": 0.0, "avg_logprob": -0.24052236498016671, "compression_ratio": 1.550420168067227, "no_speech_prob": 0.1365579217672348}, {"id": 766, "seek": 428540, "start": 4285.96, "end": 4291.719999999999, "text": " in California, when he was teaching or he's having his twins taught, and they were using", "tokens": [50392, 294, 5384, 11, 562, 415, 390, 4571, 420, 415, 311, 1419, 702, 22555, 5928, 11, 293, 436, 645, 1228, 50680], "temperature": 0.0, "avg_logprob": -0.10486215636843726, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.03113568015396595}, {"id": 767, "seek": 428540, "start": 4291.719999999999, "end": 4298.04, "text": " a curriculum that was completely created by principal Joshua Dahn, who is an absolute legend.", "tokens": [50680, 257, 14302, 300, 390, 2584, 2942, 538, 9716, 24005, 413, 12140, 11, 567, 307, 364, 8236, 9451, 13, 50996], "temperature": 0.0, "avg_logprob": -0.10486215636843726, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.03113568015396595}, {"id": 768, "seek": 428540, "start": 4298.04, "end": 4303.4, "text": " He's still doing this, but basically we looked at the fact that these guys didn't really use", "tokens": [50996, 634, 311, 920, 884, 341, 11, 457, 1936, 321, 2956, 412, 264, 1186, 300, 613, 1074, 994, 380, 534, 764, 51264], "temperature": 0.0, "avg_logprob": -0.10486215636843726, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.03113568015396595}, {"id": 769, "seek": 428540, "start": 4303.4, "end": 4310.759999999999, "text": " computers. They didn't use handwriting because handwriting was too slow. They didn't really", "tokens": [51264, 10807, 13, 814, 994, 380, 764, 39179, 570, 39179, 390, 886, 2964, 13, 814, 994, 380, 534, 51632], "temperature": 0.0, "avg_logprob": -0.10486215636843726, "compression_ratio": 1.6096491228070176, "no_speech_prob": 0.03113568015396595}, {"id": 770, "seek": 431076, "start": 4310.76, "end": 4315.96, "text": " have homework. They certainly didn't have books. He didn't teach languages because Elon was getting", "tokens": [50364, 362, 14578, 13, 814, 3297, 994, 380, 362, 3642, 13, 634, 994, 380, 2924, 8650, 570, 28498, 390, 1242, 50624], "temperature": 0.0, "avg_logprob": -0.10637756756373815, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.07583413273096085}, {"id": 771, "seek": 431076, "start": 4315.96, "end": 4322.04, "text": " them ready for the fact that, well, Neuralink was coming. So why would we teach languages when,", "tokens": [50624, 552, 1919, 337, 264, 1186, 300, 11, 731, 11, 1734, 1807, 475, 390, 1348, 13, 407, 983, 576, 321, 2924, 8650, 562, 11, 50928], "temperature": 0.0, "avg_logprob": -0.10637756756373815, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.07583413273096085}, {"id": 772, "seek": 431076, "start": 4323.56, "end": 4329.88, "text": " as a reference to earlier in this live stream, we can have real-time translation potentially", "tokens": [51004, 382, 257, 6408, 281, 3071, 294, 341, 1621, 4309, 11, 321, 393, 362, 957, 12, 3766, 12853, 7263, 51320], "temperature": 0.0, "avg_logprob": -0.10637756756373815, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.07583413273096085}, {"id": 773, "seek": 431076, "start": 4329.88, "end": 4336.84, "text": " including, sorry about that selection, potentially including lip movements as well,", "tokens": [51320, 3009, 11, 2597, 466, 300, 9450, 11, 7263, 3009, 8280, 9981, 382, 731, 11, 51668], "temperature": 0.0, "avg_logprob": -0.10637756756373815, "compression_ratio": 1.6103896103896105, "no_speech_prob": 0.07583413273096085}, {"id": 774, "seek": 433684, "start": 4336.84, "end": 4343.0, "text": " and maybe gestures soon. So if you're translating that to Italian, maybe it gives you hand gestures", "tokens": [50364, 293, 1310, 28475, 2321, 13, 407, 498, 291, 434, 35030, 300, 281, 10003, 11, 1310, 309, 2709, 291, 1011, 28475, 50672], "temperature": 0.0, "avg_logprob": -0.09258096776110061, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.08752265572547913}, {"id": 775, "seek": 433684, "start": 4343.0, "end": 4353.56, "text": " alongside it. But this entire school, and it was founded back in 2016, sorry 2014, my work with them", "tokens": [50672, 12385, 309, 13, 583, 341, 2302, 1395, 11, 293, 309, 390, 13234, 646, 294, 6549, 11, 2597, 8227, 11, 452, 589, 365, 552, 51200], "temperature": 0.0, "avg_logprob": -0.09258096776110061, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.08752265572547913}, {"id": 776, "seek": 433684, "start": 4353.56, "end": 4358.68, "text": " or my work alongside them, my research of what they were doing was 2016. They've been there", "tokens": [51200, 420, 452, 589, 12385, 552, 11, 452, 2132, 295, 437, 436, 645, 884, 390, 6549, 13, 814, 600, 668, 456, 51456], "temperature": 0.0, "avg_logprob": -0.09258096776110061, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.08752265572547913}, {"id": 777, "seek": 433684, "start": 4358.68, "end": 4364.92, "text": " since 2014. They're about to hit their 10-year anniversary of not using books, of not giving", "tokens": [51456, 1670, 8227, 13, 814, 434, 466, 281, 2045, 641, 1266, 12, 5294, 12962, 295, 406, 1228, 3642, 11, 295, 406, 2902, 51768], "temperature": 0.0, "avg_logprob": -0.09258096776110061, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.08752265572547913}, {"id": 778, "seek": 436492, "start": 4365.0, "end": 4371.96, "text": " homework, of not teaching languages, of not using computers despite being probably the most technically", "tokens": [50368, 14578, 11, 295, 406, 4571, 8650, 11, 295, 406, 1228, 10807, 7228, 885, 1391, 264, 881, 12120, 50716], "temperature": 0.0, "avg_logprob": -0.08514668475622418, "compression_ratio": 1.570281124497992, "no_speech_prob": 0.006288968957960606}, {"id": 779, "seek": 436492, "start": 4371.96, "end": 4379.4, "text": " oriented school in the world. Fascinating. And look how much further we've got in terms of runway", "tokens": [50716, 21841, 1395, 294, 264, 1002, 13, 49098, 8205, 13, 400, 574, 577, 709, 3052, 321, 600, 658, 294, 2115, 295, 26642, 51088], "temperature": 0.0, "avg_logprob": -0.08514668475622418, "compression_ratio": 1.570281124497992, "no_speech_prob": 0.006288968957960606}, {"id": 780, "seek": 436492, "start": 4379.4, "end": 4385.08, "text": " to play with of what we could actually do there. Think about a gentised large language models", "tokens": [51088, 281, 862, 365, 295, 437, 321, 727, 767, 360, 456, 13, 6557, 466, 257, 16108, 2640, 2416, 2856, 5245, 51372], "temperature": 0.0, "avg_logprob": -0.08514668475622418, "compression_ratio": 1.570281124497992, "no_speech_prob": 0.006288968957960606}, {"id": 781, "seek": 436492, "start": 4385.08, "end": 4391.56, "text": " that you can go and speak to and it will gamify or just make playful your education experience.", "tokens": [51372, 300, 291, 393, 352, 293, 1710, 281, 293, 309, 486, 8019, 2505, 420, 445, 652, 30730, 428, 3309, 1752, 13, 51696], "temperature": 0.0, "avg_logprob": -0.08514668475622418, "compression_ratio": 1.570281124497992, "no_speech_prob": 0.006288968957960606}, {"id": 782, "seek": 439156, "start": 4391.56, "end": 4397.56, "text": " Right, I've just seen that SOV exists for linguistics. How does that work with languages", "tokens": [50364, 1779, 11, 286, 600, 445, 1612, 300, 10621, 53, 8198, 337, 21766, 6006, 13, 1012, 775, 300, 589, 365, 8650, 50664], "temperature": 0.0, "avg_logprob": -0.09454495906829834, "compression_ratio": 1.6083916083916083, "no_speech_prob": 0.0695267990231514}, {"id": 783, "seek": 439156, "start": 4397.56, "end": 4403.0, "text": " that I'm interested in? How could that work while I'm at the grocery store with mum and dad?", "tokens": [50664, 300, 286, 478, 3102, 294, 30, 1012, 727, 300, 589, 1339, 286, 478, 412, 264, 14410, 3531, 365, 14697, 293, 3546, 30, 50936], "temperature": 0.0, "avg_logprob": -0.09454495906829834, "compression_ratio": 1.6083916083916083, "no_speech_prob": 0.0695267990231514}, {"id": 784, "seek": 439156, "start": 4403.0, "end": 4408.04, "text": " How can that work at the family dinner table? I've just discovered this bug on my walk,", "tokens": [50936, 1012, 393, 300, 589, 412, 264, 1605, 6148, 3199, 30, 286, 600, 445, 6941, 341, 7426, 322, 452, 1792, 11, 51188], "temperature": 0.0, "avg_logprob": -0.09454495906829834, "compression_ratio": 1.6083916083916083, "no_speech_prob": 0.0695267990231514}, {"id": 785, "seek": 439156, "start": 4408.04, "end": 4413.240000000001, "text": " taken a photo with it. AI's taught me what it is. Let's get the whole etymology in context of that", "tokens": [51188, 2726, 257, 5052, 365, 309, 13, 7318, 311, 5928, 385, 437, 309, 307, 13, 961, 311, 483, 264, 1379, 1030, 4199, 1793, 294, 4319, 295, 300, 51448], "temperature": 0.0, "avg_logprob": -0.09454495906829834, "compression_ratio": 1.6083916083916083, "no_speech_prob": 0.0695267990231514}, {"id": 786, "seek": 439156, "start": 4413.240000000001, "end": 4419.320000000001, "text": " bug. So making it completely personalised and tailored. This is, in some ways already here,", "tokens": [51448, 7426, 13, 407, 1455, 309, 2584, 2973, 2640, 293, 34858, 13, 639, 307, 11, 294, 512, 2098, 1217, 510, 11, 51752], "temperature": 0.0, "avg_logprob": -0.09454495906829834, "compression_ratio": 1.6083916083916083, "no_speech_prob": 0.0695267990231514}, {"id": 787, "seek": 441932, "start": 4419.4, "end": 4427.08, "text": " it's been here since 2014 with Ad Astra, but it is far more accessible now and the capabilities", "tokens": [50368, 309, 311, 668, 510, 1670, 8227, 365, 1999, 45242, 11, 457, 309, 307, 1400, 544, 9515, 586, 293, 264, 10862, 50752], "temperature": 0.0, "avg_logprob": -0.06850828843958237, "compression_ratio": 1.5, "no_speech_prob": 0.007575136609375477}, {"id": 788, "seek": 441932, "start": 4427.08, "end": 4434.04, "text": " of large language models make this entire context really interesting. I'm waiting for 2024 so that", "tokens": [50752, 295, 2416, 2856, 5245, 652, 341, 2302, 4319, 534, 1880, 13, 286, 478, 3806, 337, 45237, 370, 300, 51100], "temperature": 0.0, "avg_logprob": -0.06850828843958237, "compression_ratio": 1.5, "no_speech_prob": 0.007575136609375477}, {"id": 789, "seek": 441932, "start": 4434.04, "end": 4441.88, "text": " we can play around with all the capabilities of a gentised LLMs as systems that will go and help", "tokens": [51100, 321, 393, 862, 926, 365, 439, 264, 10862, 295, 257, 16108, 2640, 441, 43, 26386, 382, 3652, 300, 486, 352, 293, 854, 51492], "temperature": 0.0, "avg_logprob": -0.06850828843958237, "compression_ratio": 1.5, "no_speech_prob": 0.007575136609375477}, {"id": 790, "seek": 444188, "start": 4441.96, "end": 4450.12, "text": " us learn. That's probably an unexpected answer to your question, but I'm always surprised to", "tokens": [50368, 505, 1466, 13, 663, 311, 1391, 364, 13106, 1867, 281, 428, 1168, 11, 457, 286, 478, 1009, 6100, 281, 50776], "temperature": 0.0, "avg_logprob": -0.11928877376374744, "compression_ratio": 1.4978902953586497, "no_speech_prob": 0.6577394008636475}, {"id": 791, "seek": 444188, "start": 4450.12, "end": 4456.2, "text": " people who are talking about books, including the CEO of OpenAI. Alton recently said that whole", "tokens": [50776, 561, 567, 366, 1417, 466, 3642, 11, 3009, 264, 9282, 295, 7238, 48698, 13, 967, 1756, 3938, 848, 300, 1379, 51080], "temperature": 0.0, "avg_logprob": -0.11928877376374744, "compression_ratio": 1.4978902953586497, "no_speech_prob": 0.6577394008636475}, {"id": 792, "seek": 444188, "start": 4456.2, "end": 4460.4400000000005, "text": " board coup, that whole politics, he said they'll write books about this and I went,", "tokens": [51080, 3150, 8682, 11, 300, 1379, 7341, 11, 415, 848, 436, 603, 2464, 3642, 466, 341, 293, 286, 1437, 11, 51292], "temperature": 0.0, "avg_logprob": -0.11928877376374744, "compression_ratio": 1.4978902953586497, "no_speech_prob": 0.6577394008636475}, {"id": 793, "seek": 444188, "start": 4462.12, "end": 4466.4400000000005, "text": " you're the leading voice in artificial intelligence at the moment. You think we're", "tokens": [51376, 291, 434, 264, 5775, 3177, 294, 11677, 7599, 412, 264, 1623, 13, 509, 519, 321, 434, 51592], "temperature": 0.0, "avg_logprob": -0.11928877376374744, "compression_ratio": 1.4978902953586497, "no_speech_prob": 0.6577394008636475}, {"id": 794, "seek": 446644, "start": 4466.44, "end": 4473.32, "text": " going to be writing books this year or next year? I don't know. I documented, let's go back to our", "tokens": [50364, 516, 281, 312, 3579, 3642, 341, 1064, 420, 958, 1064, 30, 286, 500, 380, 458, 13, 286, 23007, 11, 718, 311, 352, 646, 281, 527, 50708], "temperature": 0.0, "avg_logprob": -0.12358682420518663, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.05183732882142067}, {"id": 795, "seek": 446644, "start": 4474.599999999999, "end": 4481.0, "text": " screen here, I documented books written by AI all the way back in 2020,", "tokens": [50772, 2568, 510, 11, 286, 23007, 3642, 3720, 538, 7318, 439, 264, 636, 646, 294, 4808, 11, 51092], "temperature": 0.0, "avg_logprob": -0.12358682420518663, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.05183732882142067}, {"id": 796, "seek": 446644, "start": 4482.04, "end": 4488.12, "text": " lifearchitect.ai slash books by AI and at that stage, every book you're seeing here,", "tokens": [51144, 993, 1178, 5739, 13, 1301, 17330, 3642, 538, 7318, 293, 412, 300, 3233, 11, 633, 1446, 291, 434, 2577, 510, 11, 51448], "temperature": 0.0, "avg_logprob": -0.12358682420518663, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.05183732882142067}, {"id": 797, "seek": 446644, "start": 4488.12, "end": 4493.5599999999995, "text": " completely written by a large language model with prompts by a human author. At that stage,", "tokens": [51448, 2584, 3720, 538, 257, 2416, 2856, 2316, 365, 41095, 538, 257, 1952, 3793, 13, 1711, 300, 3233, 11, 51720], "temperature": 0.0, "avg_logprob": -0.12358682420518663, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.05183732882142067}, {"id": 798, "seek": 449356, "start": 4493.56, "end": 4499.72, "text": " there were very few books. This is one of my favorites. You can read about Leanne Lee's process", "tokens": [50364, 456, 645, 588, 1326, 3642, 13, 639, 307, 472, 295, 452, 16907, 13, 509, 393, 1401, 466, 1456, 12674, 6957, 311, 1399, 50672], "temperature": 0.0, "avg_logprob": -0.1566798870380108, "compression_ratio": 1.4326923076923077, "no_speech_prob": 0.0044675301760435104}, {"id": 799, "seek": 449356, "start": 4499.72, "end": 4507.64, "text": " for writing books in her series using GPT-3 and now I've said, right, where I'm not even going to", "tokens": [50672, 337, 3579, 3642, 294, 720, 2638, 1228, 26039, 51, 12, 18, 293, 586, 286, 600, 848, 11, 558, 11, 689, 286, 478, 406, 754, 516, 281, 51068], "temperature": 0.0, "avg_logprob": -0.1566798870380108, "compression_ratio": 1.4326923076923077, "no_speech_prob": 0.0044675301760435104}, {"id": 800, "seek": 449356, "start": 4507.64, "end": 4514.52, "text": " document all the books that are being created by AI because it's ridiculous, but just to my point there,", "tokens": [51068, 4166, 439, 264, 3642, 300, 366, 885, 2942, 538, 7318, 570, 309, 311, 11083, 11, 457, 445, 281, 452, 935, 456, 11, 51412], "temperature": 0.0, "avg_logprob": -0.1566798870380108, "compression_ratio": 1.4326923076923077, "no_speech_prob": 0.0044675301760435104}, {"id": 801, "seek": 451452, "start": 4515.320000000001, "end": 4523.400000000001, "text": " if AI can generate books instantly and it can, to the extent that Amazon recently banned", "tokens": [50404, 498, 7318, 393, 8460, 3642, 13518, 293, 309, 393, 11, 281, 264, 8396, 300, 6795, 3938, 19564, 50808], "temperature": 0.0, "avg_logprob": -0.17464114879739695, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.13293349742889404}, {"id": 802, "seek": 451452, "start": 4524.4400000000005, "end": 4527.160000000001, "text": " or limited the number of AI-generated books,", "tokens": [50860, 420, 5567, 264, 1230, 295, 7318, 12, 21848, 770, 3642, 11, 50996], "temperature": 0.0, "avg_logprob": -0.17464114879739695, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.13293349742889404}, {"id": 803, "seek": 451452, "start": 4531.56, "end": 4539.88, "text": " I think it was two, yeah, three books per day because they were having so many people cranking out", "tokens": [51216, 286, 519, 309, 390, 732, 11, 1338, 11, 1045, 3642, 680, 786, 570, 436, 645, 1419, 370, 867, 561, 21263, 278, 484, 51632], "temperature": 0.0, "avg_logprob": -0.17464114879739695, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.13293349742889404}, {"id": 804, "seek": 453988, "start": 4539.96, "end": 4545.88, "text": " artificial intelligence-generated books. They said, right, maybe you're generating 100 per day", "tokens": [50368, 11677, 7599, 12, 21848, 770, 3642, 13, 814, 848, 11, 558, 11, 1310, 291, 434, 17746, 2319, 680, 786, 50664], "temperature": 0.0, "avg_logprob": -0.09279582023620606, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.007120668422430754}, {"id": 805, "seek": 453988, "start": 4545.88, "end": 4551.08, "text": " and trying to monetize them, we're going to limit you to three a day. Books are over and that's been", "tokens": [50664, 293, 1382, 281, 15556, 1125, 552, 11, 321, 434, 516, 281, 4948, 291, 281, 1045, 257, 786, 13, 33843, 366, 670, 293, 300, 311, 668, 50924], "temperature": 0.0, "avg_logprob": -0.09279582023620606, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.007120668422430754}, {"id": 806, "seek": 453988, "start": 4551.08, "end": 4558.4400000000005, "text": " the case for a while. Look out for agents, look out for the next edition of the memo and if you are", "tokens": [50924, 264, 1389, 337, 257, 1339, 13, 2053, 484, 337, 12554, 11, 574, 484, 337, 264, 958, 11377, 295, 264, 35900, 293, 498, 291, 366, 51292], "temperature": 0.0, "avg_logprob": -0.09279582023620606, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.007120668422430754}, {"id": 807, "seek": 453988, "start": 4558.4400000000005, "end": 4564.6, "text": " a full member of the memo, you will get early access to my end of year report, which is spelling", "tokens": [51292, 257, 1577, 4006, 295, 264, 35900, 11, 291, 486, 483, 2440, 2105, 281, 452, 917, 295, 1064, 2275, 11, 597, 307, 22254, 51600], "temperature": 0.0, "avg_logprob": -0.09279582023620606, "compression_ratio": 1.6401673640167365, "no_speech_prob": 0.007120668422430754}, {"id": 808, "seek": 456460, "start": 4564.6, "end": 4570.6, "text": " out some examples of global and personal agents. This is my invitation to you. I'd love to see", "tokens": [50364, 484, 512, 5110, 295, 4338, 293, 2973, 12554, 13, 639, 307, 452, 17890, 281, 291, 13, 286, 1116, 959, 281, 536, 50664], "temperature": 0.0, "avg_logprob": -0.08005879084269206, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.039019469171762466}, {"id": 809, "seek": 456460, "start": 4570.6, "end": 4575.72, "text": " you there. You're invited to join the memo with me. Thanks for joining me today and I'll see you", "tokens": [50664, 291, 456, 13, 509, 434, 9185, 281, 3917, 264, 35900, 365, 385, 13, 2561, 337, 5549, 385, 965, 293, 286, 603, 536, 291, 50920], "temperature": 0.0, "avg_logprob": -0.08005879084269206, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.039019469171762466}, {"id": 810, "seek": 456460, "start": 4575.72, "end": 4581.8, "text": " there and I'll see you this time next week for our second last live stream for the year. It's gone", "tokens": [50920, 456, 293, 286, 603, 536, 291, 341, 565, 958, 1243, 337, 527, 1150, 1036, 1621, 4309, 337, 264, 1064, 13, 467, 311, 2780, 51224], "temperature": 0.0, "avg_logprob": -0.08005879084269206, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.039019469171762466}, {"id": 811, "seek": 458180, "start": 4581.8, "end": 4594.6, "text": " that quick. Thanks so much for joining. Did you see the memo about this? Yeah, yeah, yeah, I have the", "tokens": [50364, 300, 1702, 13, 2561, 370, 709, 337, 5549, 13, 2589, 291, 536, 264, 35900, 466, 341, 30, 865, 11, 1338, 11, 1338, 11, 286, 362, 264, 51004], "temperature": 0.0, "avg_logprob": -0.11859497657189003, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.16660484671592712}, {"id": 812, "seek": 458180, "start": 4594.6, "end": 4601.88, "text": " memo right here. Superintelligence is unfolding at lightning pace. Read my industry-grade analysis", "tokens": [51004, 35900, 558, 510, 13, 4548, 20761, 17644, 307, 44586, 412, 16589, 11638, 13, 17604, 452, 3518, 12, 8692, 5215, 51368], "temperature": 0.0, "avg_logprob": -0.11859497657189003, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.16660484671592712}, {"id": 813, "seek": 458180, "start": 4601.88, "end": 4609.88, "text": " of AI that matters as it happens in plain English, the memo. Yeah, did you get that memo? Yeah, I", "tokens": [51368, 295, 7318, 300, 7001, 382, 309, 2314, 294, 11121, 3669, 11, 264, 35900, 13, 865, 11, 630, 291, 483, 300, 35900, 30, 865, 11, 286, 51768], "temperature": 0.0, "avg_logprob": -0.11859497657189003, "compression_ratio": 1.5204081632653061, "no_speech_prob": 0.16660484671592712}, {"id": 814, "seek": 460988, "start": 4609.88, "end": 4617.8, "text": " got the memo. Get the inside look as AI models are embodied into humanoids, AI's IQ increases to", "tokens": [50364, 658, 264, 35900, 13, 3240, 264, 1854, 574, 382, 7318, 5245, 366, 42046, 666, 30985, 3742, 11, 7318, 311, 28921, 8637, 281, 50760], "temperature": 0.0, "avg_logprob": -0.09875401769365583, "compression_ratio": 1.4306930693069306, "no_speech_prob": 0.033570606261491776}, {"id": 815, "seek": 460988, "start": 4617.8, "end": 4625.400000000001, "text": " nearly perfect and bleeding edge use cases expand to the entire world. Yeah, didn't you get that memo?", "tokens": [50760, 6217, 2176, 293, 19312, 4691, 764, 3331, 5268, 281, 264, 2302, 1002, 13, 865, 11, 994, 380, 291, 483, 300, 35900, 30, 51140], "temperature": 0.0, "avg_logprob": -0.09875401769365583, "compression_ratio": 1.4306930693069306, "no_speech_prob": 0.033570606261491776}, {"id": 816, "seek": 460988, "start": 4626.68, "end": 4633.4800000000005, "text": " Editions are sent to subscribers at Fortune 500's, major governments and people like you,", "tokens": [51204, 3977, 2451, 366, 2279, 281, 11092, 412, 38508, 5923, 311, 11, 2563, 11280, 293, 561, 411, 291, 11, 51544], "temperature": 0.0, "avg_logprob": -0.09875401769365583, "compression_ratio": 1.4306930693069306, "no_speech_prob": 0.033570606261491776}, {"id": 817, "seek": 463348, "start": 4633.48, "end": 4639.08, "text": " lifearchitect.ai slash memo. I have the memo.", "tokens": [50364, 993, 1178, 5739, 13, 1301, 17330, 35900, 13, 286, 362, 264, 35900, 13, 50644], "temperature": 0.0, "avg_logprob": -0.28686389327049255, "compression_ratio": 0.9183673469387755, "no_speech_prob": 0.14964830875396729}], "language": "en"}