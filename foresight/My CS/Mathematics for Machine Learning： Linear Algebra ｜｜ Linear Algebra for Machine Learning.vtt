WEBVTT

00:00.000 --> 00:06.040
Okay, so welcome to the first lecture on the vectors course. This is the basics, vectors

00:06.040 --> 00:12.560
versus scalars, vector notation, addition and scaling, and properties. Alright, so begin

00:12.560 --> 00:19.040
at the beginning. Let's list some scalar quantities. Think about mass, duration, length, temperature,

00:19.040 --> 00:24.200
charge. These physical quantities are all well described with a single number. Really

00:24.200 --> 00:29.200
they just have a magnitude, although some of them may go negative, so it's a magnitude

00:29.400 --> 00:34.120
and a sign. But still, just a simple number is adequate to describe these things. How

00:34.120 --> 00:38.680
about vector quantities? What's different about vector quantities? Well, think about

00:38.680 --> 00:44.400
these things, force, velocity, and therefore acceleration, or momentum. These things also

00:44.400 --> 00:52.200
have a strength or a magnitude. However, so let's put that down, they have a magnitude.

00:52.200 --> 00:58.360
However, they also have a direction. More than just a sign, they have a full on direction

00:58.360 --> 01:02.860
in three-dimensional space. So it's not enough to know that a force is three Newtons. I want

01:02.860 --> 01:07.320
to know in which direction is that force applied. And that then is the difference between a

01:07.320 --> 01:12.400
vector and a scalar quantity. We're going to think about how we manipulate them. Alright,

01:12.400 --> 01:19.120
so first off, the notation that we're going to use when we talk about our vectors. What

01:19.120 --> 01:25.280
I'm going to do is I'm going to use a symbol such as the letter A. So let's write that

01:25.320 --> 01:31.160
out, but I'm going to underline it. So an underlined symbol indicates a vector rather

01:31.160 --> 01:35.720
than a simple number. And when I need to specify that vector, I'm going to write it, so we're

01:35.720 --> 01:39.400
going to be three-dimensional. I'm going to write the three numbers in a column form

01:39.400 --> 01:44.400
like this. Now, if you haven't seen a vector specified before, what does it mean? Well,

01:44.400 --> 01:53.960
think of the Cartesian axes, the x, the x, y, z axes. Think in this case about coming

01:53.960 --> 02:02.600
out from the origin two in the direction of x and one in the direction of y and three

02:02.600 --> 02:07.400
in the direction of z. What we're going to do is we're going to think of our vector as

02:07.400 --> 02:13.800
an arrow, an arrow that comes from the origin to this point in space. And that arrow itself,

02:13.800 --> 02:21.000
whether or not it comes from the origin, that direction and that length of arrow is our visualization

02:21.120 --> 02:27.320
of the vector. So let me just change color to green and go ahead and draw the tip of

02:27.320 --> 02:32.920
my arrow there. There we are. So the vector is coming towards us out of the screen and

02:32.920 --> 02:38.200
it has those particular three components, two, one, three. Other people may use other

02:38.200 --> 02:45.560
notations. For example, a line over the symbol A is commonly used. When people write out the

02:45.600 --> 02:50.760
components, they may choose to do it as a row like this or even using pointy brackets

02:50.760 --> 02:56.280
like this. Now, all these notations are basically getting at the same thing. You'll be able

02:56.280 --> 03:00.800
to read textbooks or look online and see these things and understand what they mean. But

03:00.800 --> 03:06.600
within this course of videos, we're just going to use the notation that I've introduced

03:06.600 --> 03:13.000
above. So I'll erase those for now. Now, the simplest thing that you might want to do

03:13.000 --> 03:16.920
if you have a couple of vectors is to add them up. So let's think about that vector

03:16.920 --> 03:21.040
addition. What does it mean? So let's give ourselves a second vector B. We'll make it

03:21.040 --> 03:26.960
five minus two zero, let's say. I want to add these two vectors together. So we'll write

03:26.960 --> 03:31.720
that out. I simply want to add A underline plus B underline. What does that mean? Let's

03:31.720 --> 03:39.440
just substitute in two, three. Add it on two, five minus two, zero. Now, what we do is we

03:39.440 --> 03:45.720
simply add the first component of vector A to the first component of vector B and so

03:45.720 --> 03:51.800
on down the list. Very, very simple. So we're adding two plus five. We're going to add one

03:51.800 --> 03:57.720
plus minus two and three plus zero. And we just tidy that up. So that's going to be

03:57.720 --> 04:08.200
seven minus one and three. Now, how about scaling a vector? Okay. So what we can do

04:08.240 --> 04:16.240
is we can multiply a vector by a simple number and correspondingly, we'll just end up multiplying

04:16.240 --> 04:22.400
each of its components. So let's take an example, three, nine, minus twelve. What we notice

04:22.400 --> 04:27.080
is each of the three components is a multiple of three. We can just take that common factor

04:27.080 --> 04:33.480
out in front and write this instead as three times one, three, minus four. Same thing.

04:33.760 --> 04:38.120
All right? Or equivalently, someone might give us a vector that's already written in

04:38.120 --> 04:44.440
this form. It could be, let's say three over two onto two, four, minus four. Let's make

04:44.440 --> 04:51.000
it one. All right? And we can just multiply that in, in a component by component basis.

04:51.000 --> 04:55.000
So we just write ourselves a new column. Of course, three times two is three. Three times

04:55.040 --> 05:04.040
minus four is minus six. And three over two times one is three over two. Okay? So there

05:04.160 --> 05:10.560
we are. We can scale our vectors by a number in this simple way. So with these definitions

05:10.560 --> 05:15.960
of addition and scaling, can we say anything about the properties? Okay. So if I have two

05:15.960 --> 05:20.600
regular numbers a and b, then of course, a plus b is the same as b plus a. I'm not saying

05:20.600 --> 05:25.200
anything fancy here. It's as simple as, I don't know, seven plus minus three is equal

05:25.200 --> 05:30.680
to minus three plus seven. Obviously it is. We know that. Now, if we think about the same

05:30.680 --> 05:37.080
statement for vectors, a plus b, vector b, is it the same as vector b plus a? Well, it

05:37.080 --> 05:42.520
must be. Let's just write out an example, seven zero minus one, three, one, two. Is it equal

05:42.520 --> 05:51.960
to three, one, two vector plus the vector seven zero minus one? Of course it is because

05:51.960 --> 05:57.760
of the way we've defined vector addition as just being the addition of each element

05:57.760 --> 06:04.480
to the corresponding element. And this property is called being commutative. Okay. So vector

06:04.480 --> 06:10.400
addition is commutative. How about this second example? If we have three basic quantities,

06:10.400 --> 06:16.520
ordinary numbers, then if we have a plus b plus c, it's the same as a plus b plus c.

06:16.520 --> 06:20.680
It doesn't matter the order that we do them in. Is that going to be true for vectors? Well,

06:20.680 --> 06:25.160
of course, it is going to have to be true to vectors because the way we define vector

06:25.160 --> 06:30.880
addition is to add each component to the corresponding component. It's just addition. So this is

06:31.280 --> 06:41.160
for vectors. Let's write down what we mean. We mean that vector a plus b plus c as a previously

06:41.160 --> 06:49.840
worked out thing is equal to vector a plus vector b and then add on c. It doesn't matter

06:49.840 --> 06:54.680
the order we do these things. All right. And there's a name for that property. It's called

06:54.680 --> 07:07.240
being associative. All right. So vector addition has that property also. Now let's think about

07:07.240 --> 07:11.240
our scaling property. If we have ordinary numbers again, then we could take some scale

07:11.240 --> 07:17.240
factor k and multiply it into a plus b and it would just give us k times a plus k times

07:17.240 --> 07:21.400
b. Again, I'm not saying anything that isn't utterly obvious here. Say for example, I don't

07:21.420 --> 07:30.920
know, 2 into 1 plus minus 3 is equal to 2 times 1 plus 2 times minus 3. Of course it

07:30.920 --> 07:36.840
is. So how about for vectors? Is it true that some scale factor k times the sum vector a

07:36.840 --> 07:43.240
plus vector b, a plus b, and let's stress that this scale factor is just a pure number?

07:43.560 --> 07:51.560
Yes indeed. It's going to be just k times a plus k times b. So just to stress what we're

07:51.560 --> 07:56.920
doing here, let's copy down this sum of two vectors we were playing with up here. This

07:56.920 --> 08:02.760
7, 0 minus 1 thing plus 3, 1, 2. Put it inside curly brackets maybe for a variety. It doesn't

08:02.760 --> 08:07.960
have to be curly brackets. Multiply it by some factor. Let's have 3 over 2. Had that before.

08:07.960 --> 08:11.960
Unimaginative. There we are. What's that going to be? It's just going to be 3 over 2 times

08:11.960 --> 08:20.600
the first vector 7, 0, 1 and then plus 3 over 2 times the second vector 3, 1, 2. Okay. So

08:21.560 --> 08:27.160
everything as you kind of would expect it works out. It must. And this latter property is called

08:27.160 --> 08:37.400
being distributive, so scaling is distributive over addition. And that's the end of our first video.

08:38.040 --> 08:45.720
Welcome to the second of these videos. We're going to look here at the vector dot product, also

08:45.720 --> 08:49.720
called the scalar product. We'll look at also the magnitude of a vector and the meaning of unit

08:49.720 --> 08:55.560
vectors, the geometric meaning of the dot product, and finding the angle between vectors using the

08:55.560 --> 09:03.960
dot product. Okay. So the dot product is a way of combining two vectors in order to produce a

09:04.280 --> 09:09.080
scalar, hence the alternate name scalar product. Let's give ourselves a couple of vectors. Let's

09:09.080 --> 09:18.840
have a, well, vector a can be 4 minus 4. Let's have 2, 1. And we'll have a vector b, which can be

09:20.760 --> 09:30.200
3, 1, 3. And we're going to do the dot product of these two guys. So we write that as vector a,

09:30.200 --> 09:36.440
a nice, nice clear central dot vector b. And then we write that out as the two column vectors.

09:37.240 --> 09:43.080
And we need to understand how we compute the dot product. And the answer is we're simply going to

09:43.080 --> 09:49.160
multiply each component by its opposite number and then add them up. So we're going to multiply

09:49.160 --> 09:55.960
the first component minus 4 by 3. And then add that to the second component to multiply by

09:55.960 --> 10:02.280
its opposite number 1. And finally, the third components, 1 and 3. So that's minus 4 times

10:02.280 --> 10:16.840
by 3. Add it on to 2 times by 1. Add it on to 1 times by 3. So minus 12 plus 2 plus 3. That's

10:16.840 --> 10:24.680
going to be minus, minus 7. All right. There's the dot product worked out. It's pretty straightforward.

10:24.680 --> 10:29.080
And of course, as you can see, it can be a minus number. It can be 0. It can be a positive number.

10:29.080 --> 10:35.640
But it's a simple, pure number. Okay. So now, let's see what happens if we do the dot product

10:35.640 --> 10:41.400
of a vector with itself. Let's do a dotted with itself. So that's going to be minus 4 to 1 dotted

10:41.400 --> 10:48.040
with minus 4 to 1. Now, of course, because we're multiplying each component by itself, that will

10:48.040 --> 10:54.360
always be a positive number. 16, minus 4 by minus 4. And 2, 2 is a 4. And 1, 1 is 1. And so that's

10:54.360 --> 10:59.080
going to add up to 21. It must add up to a positive number. It's made of three positive

10:59.080 --> 11:05.800
numbers summed. Now, I want to introduce a second vector called a hat. It's related to a just by

11:05.800 --> 11:11.320
scaling it. And we're going to scale it by 1 over the square root of the earlier dot product with

11:11.320 --> 11:18.360
itself. So 1 over square root 21. And then just minus 4, 2, 1 as before. So that's just a scaled

11:18.360 --> 11:23.880
version of a. What's interesting about it? Well, now let's see what happens if we take the dot product

11:23.880 --> 11:32.120
of a hat with a hat with itself. So we're going to get 1 over square root of 21 times 1 over

11:32.120 --> 11:39.720
square root of 21, which is 1 over 21. And then, of course, we're going to get a dotted with a,

11:39.720 --> 11:45.480
the original dot product we did, which is just 21, as we know. So, of course, the dot product

11:45.480 --> 11:52.200
of a hat with itself is just 1. That means that a hat has a special property. It's what's called

11:52.200 --> 11:58.520
a unit vector. Unity being, of course, a fancy word for the number 1. So when we scale a vector,

11:58.520 --> 12:03.240
so that it, when dotted with itself, it comes out as 1, then it is a unit vector.

12:03.880 --> 12:10.680
Meanwhile, in general for a vector, the square root of the dot product with itself has the name

12:10.680 --> 12:17.320
magnitude. This is the magnitude of a vector. And it is also magnitude. It is also the length

12:17.320 --> 12:25.400
of the arrow, if we think in terms of a vector as a physical displacement and arrow that lives

12:25.400 --> 12:29.960
in three-dimensional space, then it would be the length of that arrow, as you can see from Pythagoras.

12:29.960 --> 12:35.960
Okay, now then, a different thing. The dot product between two vectors has an alternative definition,

12:35.960 --> 12:42.200
which we can show is the same as the definition we've been using so far. a dot b is also the

12:42.200 --> 12:49.080
magnitude of a times the magnitude of b times cos of some angle. And what is that angle? It's

12:49.080 --> 12:55.080
actually just the angle between the two vectors, between their directions. So here I'm drawing a

12:55.080 --> 13:00.520
vector a going in one direction and almost in the opposite direction vector b. And then the angle in

13:00.520 --> 13:06.040
question would be this angle that we see between the two vectors when we draw them coming from a

13:06.040 --> 13:11.880
common point of origin. Okay, so it's important to understand then that this angle can be more

13:11.880 --> 13:17.400
than 90 degrees. Here's what it isn't. Here's a mistake that's sometimes made by people as they

13:17.400 --> 13:22.440
start to play with the vectors. They want the angle, for some reason, they want it to be less than 90

13:22.440 --> 13:27.640
degrees. So they try and contrive this by putting the vectors together in a way that will give them

13:27.640 --> 13:34.680
less than 90 degrees, like this, for example. And then we could try and draw an angle between these

13:34.680 --> 13:42.120
two lines. Let's see, like, let's use a red to show that it's not correct. What we should have is

13:42.120 --> 13:46.440
the two vectors coming from a common origin. Then we see that the angle between them can be more or

13:46.440 --> 13:51.320
less than 90 degrees. If it was exactly 90 degrees, then of course the dot product would be zero

13:51.320 --> 13:57.640
because cos of 90 is zero. That has interesting consequences. But right now let's work out the

13:57.640 --> 14:03.400
angle between a couple of vectors. Let's give ourselves a, we'll make it one, zero minus one,

14:03.400 --> 14:09.640
and b. We're going to make it four, one, minus one. And we'll do the dot product between those

14:09.640 --> 14:15.240
guys. So first we'll work out the dot product. Actually, let's make it minus one. So a can

14:15.240 --> 14:19.080
be minus one, zero, minus one. I think that will come out better. So we have minus four from minus

14:19.080 --> 14:23.800
one times four. We have zero times one is zero. We have minus one times minus one is one. So it's

14:23.800 --> 14:29.000
going to be minus three for the total dot product between these two guys. But we also need to find

14:29.000 --> 14:33.320
out the magnitude. Fair enough. Magnitude of a is going to be the square root of minus one times

14:33.320 --> 14:39.560
one times one. And again, one. So that would be the square root of two. Nice and straightforward.

14:39.560 --> 14:47.080
Meanwhile, the magnitude of b is going to be four fours of sixteen plus one plus one. It's going

14:47.080 --> 14:53.560
to be eighteen. The square root of eighteen. But I think we can do better than that. Square root

14:53.560 --> 14:58.600
of eighteen is actually square root of nine times the square root of two. And that means it's three

14:58.600 --> 15:03.720
times the square root of two. Okay, now we've got everything we need. Let's pull down a copy of that

15:04.520 --> 15:10.600
definition there relating a dot b to its magnitudes in the angle and fill in what we know for this

15:10.600 --> 15:18.840
particular choice of a and b. We've got minus three is therefore equal to root two times three root

15:18.840 --> 15:24.520
two times cos of the angle that we're after. So now we just need to rearrange. That means that

15:25.240 --> 15:32.360
cos of the angle is going to be equal to minus three divided by what we've got two lots of

15:32.360 --> 15:37.240
root two. So that's just three times two. And if we simplify that down, it's just minus a half.

15:37.800 --> 15:43.560
Now we may just remember or use a calculator to find out. This means that the angle in question

15:44.120 --> 15:48.680
is in fact going to be simply one hundred and twenty degrees. Or you can use radians if you

15:48.680 --> 15:52.680
prefer radians. So there we are. That's the answer. The angle between these two vectors,

15:52.680 --> 15:59.400
120 degrees. And that's it for the second video. In this video, we're going to see how to calculate

15:59.400 --> 16:04.680
something called the cross product of two vectors. It's also called the vector product because the

16:04.680 --> 16:10.760
output is a new vector. And we'll see how to test that the answer is correct. So here I've written

16:10.760 --> 16:16.520
a cross b is equal to c. And notice that the symbol for the cross product is just the multiplication

16:16.520 --> 16:22.440
symbol that you're familiar with from basic arithmetic. I've given the vector a a particular

16:22.440 --> 16:28.680
form, this two, three, four column vector. And similarly b is written as four, five, six. So

16:28.680 --> 16:33.800
we're going to go ahead and find out what is the cross product of these two vectors c. Because it's

16:33.800 --> 16:38.840
a vector, we'll need to do some working for each of the three components. Now what I'm going to do

16:38.840 --> 16:44.360
is I'm going to paste up some structure to help us work through the problem. So don't worry because

16:44.360 --> 16:48.600
it's going to look like a lot. But you don't need to write all this out every time you want to do a

16:48.600 --> 16:53.720
cross product. I'm just putting it here so we can really spell out the process. Okay so let's go

16:53.720 --> 16:58.040
ahead and work out the first component of the output vector c. Strangely enough what we're going

16:58.040 --> 17:03.160
to do is we're going to ignore the first component of vectors a and b. So I'm just going to cross

17:03.160 --> 17:08.200
those out. Those aren't used. And what we're going to do is we're going to multiply a certain of the

17:08.200 --> 17:12.600
other components. What we're going to do is we're going to multiply the second component of vector

17:12.600 --> 17:17.880
a with the third component of vector b. I call that the falling diagonal. Because when we draw it

17:17.880 --> 17:23.720
like this we start high and then go low. And then we're going to subtract off the multiple

17:23.720 --> 17:30.520
of the rising diagonal 4 and 6 here. The last component of vector a and the middle component

17:30.520 --> 17:38.440
of vector b. So what we have here is 21, that's 7 3's a 21, minus 6 4's a 24, that's minus 3.

17:38.440 --> 17:44.120
We can go ahead now and write that in as our first element minus 3. Now let's move to the

17:44.120 --> 17:50.920
second element of the output vector c. We'll start by ignoring the second component of the

17:50.920 --> 17:55.400
two source vectors a and b. We can cross those off. And again we're not going to multiply

17:55.400 --> 18:01.320
some diagonals. But what's different here is we start with the rising diagonal 4 times 5.

18:01.320 --> 18:07.960
The last component of vector a times the first component of vector b. The rising diagonal 5

18:07.960 --> 18:15.000
4's a 20. And then we subtract off the falling diagonal. So 2 7's a 14 and that's going to give

18:15.000 --> 18:22.120
us 6. So we can put that in. Now let's move to the third and final component. As before we start

18:22.120 --> 18:28.920
by noting that we will ignore the third component of the two source vectors. And we're going to

18:28.920 --> 18:34.680
need some diagonals. It's the same pattern as the first falling diagonal first. So 2 times 6

18:34.680 --> 18:40.040
and subtract which is 12 and then subtract off the rising diagonal 5 3's a 15.

18:41.320 --> 18:46.840
All right so that's going to be minus 3. Pop that in. We see that we have quite a simple

18:46.840 --> 18:54.040
vector here. There's a common factor of 3. Let's bring that out. 3 then minus 1 to minus 1. That

18:54.040 --> 19:01.080
is our vector c. That is a cross b. Notice again the pattern. It was the falling diagonal minus the

19:01.080 --> 19:08.040
rising diagonal for the first component. And then the rising diagonal minus the falling diagonal

19:08.040 --> 19:13.000
for the second component. And then for the third it was back to the same pattern as for the first.

19:13.000 --> 19:17.240
Now these look a bit like letters to me. They look a bit like a v. The middle one perhaps an

19:17.240 --> 19:25.560
n and the final one a v. I like to remember that as a little sentence which is voles never

19:26.360 --> 19:32.920
vary. Because in my opinion voles don't vary very much. Here's a vol. This one doesn't vary at all

19:32.920 --> 19:38.040
because it's stuffed in a museum. However if you compare it to some other voles which I found these

19:38.040 --> 19:42.760
on the internet I think they're all pretty much identical and it's a big difference there. So

19:42.760 --> 19:48.120
for me voles never vary. If for you they do seem to vary then think of a different way of remembering

19:48.120 --> 19:52.520
it. But the important thing is that the first thing is the falling diagonal and then subtract

19:52.520 --> 19:59.640
the rising diagonal of v shape and it alternates. Okay how to check your cross product has been

19:59.640 --> 20:04.360
worked out correctly. This is really useful stuff. So let's give ourselves another example. We'll have

20:04.360 --> 20:09.960
two three one and then we'll have let's say three seven minus one. Let's get a minus in there.

20:09.960 --> 20:14.520
And that's going to be equal to something. We'll work it out in a minute. For now I'll put x, y, z.

20:15.480 --> 20:20.440
Now how am I going to test once I found those x, y and z that I haven't made some kind of slip? I

20:20.440 --> 20:24.200
mean there's a lot of mental arithmetic. If we don't write it all out we're going to be doing a

20:24.200 --> 20:30.120
bunch of multiplications. I could easily slip up. How am I going to test that? It turns out

20:30.120 --> 20:34.920
there's a very interesting property of the vector c that we get out after the operation

20:34.920 --> 20:42.040
if we've done it correctly. That is as I've written here that a dot dot product with vector c is zero

20:42.040 --> 20:49.000
and so is b. So either of the input vectors a and b dotted with the correct cross product c

20:49.000 --> 20:53.880
should give us zero and that's great because the dot product is very easy to work out even by i

20:53.880 --> 20:59.000
as a check. Let's go ahead and do it. So I've copied it down here. We're going to want to work down

20:59.000 --> 21:04.840
our various components. Let's do the first component of c. So what do we do? We ignore the first

21:04.840 --> 21:10.200
components of a and b and we do the falling diagonal. So that's going to be three times minus one and

21:10.200 --> 21:17.320
we subtract the rising diagonal one times seven. So that's just let's just write that out. Normally

21:17.320 --> 21:20.680
I wouldn't bother to write all this out but let's go ahead and do it here. So it's minus three

21:20.680 --> 21:25.640
minus seven and so that's going to be minus ten as our first component. Now we work out

21:25.640 --> 21:30.360
second component. We ignore the second component on the input vectors. We do the rising diagonal

21:30.360 --> 21:37.240
one times three and subtract the falling diagonal two times minus one. So what have we got? We've

21:37.240 --> 21:45.720
got three here minus minus two and so that's going to give us five and then finally the third component

21:45.800 --> 21:50.120
ignore the third component of the input vectors. Do the falling diagonal. Two times seven seven

21:50.120 --> 21:55.560
two is a fourteen. Subtract the rising diagonal three three's a nine. So we're going to have

21:56.520 --> 22:03.640
for our final component fourteen minus nine which is another five. So that's quite a simple

22:03.640 --> 22:09.800
vector. It has a common factor of five in there if we wanted to write it out that way. Now let's

22:09.800 --> 22:18.040
test that guy versus the a and b vectors to see if it passes our test or have we made a slip.

22:19.080 --> 22:25.000
So let's just be completely explicit about that. We're going to start by testing the dot product

22:25.640 --> 22:32.600
of the vector a with our hopefully correct cross product c. I'll write it out two three one

22:33.400 --> 22:39.160
dot product minus ten five five. What's that going to be equal to minus twenty

22:39.800 --> 22:45.400
and then three fives of fifteen and then one five is five. Aha! It does equal zero. That's

22:45.400 --> 22:50.600
correct. That's a very very encouraging thing but for real thoroughness we're going to test the other

22:50.600 --> 22:57.880
one as well. So this is b dot c. Let's check that out. So that's three seven minus one dotted with

22:57.880 --> 23:04.360
again minus ten five five. This time it's going to be minus uh minus thirty from three times minus

23:04.360 --> 23:10.600
ten and then seven fives of thirty five but then minus five from the last element zero again. Aha!

23:10.600 --> 23:15.320
So it has in fact passed both of our tests and we're now very confident that's correct.

23:15.320 --> 23:20.440
This is a great test to do. One word of warning though the one thing it won't pick up is if you've

23:20.440 --> 23:25.560
done your rising and falling diagonals in exactly the wrong way around by starting with the wrong

23:25.560 --> 23:32.920
pattern. So do remember the VNV pattern and this test will check for any particular slips in your

23:32.920 --> 23:41.800
multiplications and that's the end of the video. Okay so in this short video I'm just going to look

23:41.800 --> 23:47.080
at four more examples of the cross product for practice and here they are. Okay so here's the

23:47.080 --> 23:53.000
first one. We want the first element of this cross product so we ignore the first elements of the

23:53.000 --> 23:59.240
two source vectors. We do the falling diagonal three times zero that's zero and we subtract the

23:59.240 --> 24:04.200
rising diagonal seven times minus one that is minus seven so we're subtracting minus seven

24:04.200 --> 24:09.560
that means we'll get plus seven. So the first element here is in the seven. Okay so now we

24:09.560 --> 24:13.640
want the second element that means we ignore the second element of the two source vectors.

24:13.640 --> 24:18.920
We do however the rising diagonal first seven two is fourteen minus one times zero is zero

24:18.920 --> 24:24.280
so that's fourteen. So the second one was the rising diagonal first if you follow me

24:24.280 --> 24:28.840
and then finally to get the third component we ignore the third component of the source vectors

24:28.840 --> 24:35.400
and we do the falling diagonal one times minus one is minus one minus three two six so that is minus

24:35.400 --> 24:44.600
seven. Okay so there's our solution seven fourteen minus seven but is that correct or have we made

24:45.560 --> 24:51.080
a slip? It's a good time to check the old dot product trick so if we call this A cross B equals

24:51.080 --> 24:55.960
C then we should find that if we do the dot product of one of the input vectors say B

24:55.960 --> 25:00.600
with C then it should be zero. Let's check that seven twos are fourteen minus one times fourteen

25:00.600 --> 25:05.240
is minus fourteen zero times minus seven is zero so that's fourteen minus fourteen it's correct

25:05.240 --> 25:11.400
let's do the other one it's harder so one times seven is seven three times fourteen is forty two

25:11.400 --> 25:18.440
that's forty nine in total and then the final term here seven sevens are forty nine but that

25:18.440 --> 25:25.320
was with a minus number so we've got in fact forty nine minus forty nine is zero so another one of

25:25.320 --> 25:34.840
those dot products is correctly zero so what we found out is that A dot C and B dot C are both

25:34.840 --> 25:40.040
equal to zero as they must be so we're now very confident that we have the right cross product

25:40.360 --> 25:47.640
let's do another one okay so we're going to want the first element so we ignore the first element

25:47.640 --> 25:55.320
of the two source vectors and we do eight threes eight threes are twenty four minus two two times

25:55.320 --> 25:59.960
one is two so that's twenty two let's do the next element so we ignore the middle elements and we

25:59.960 --> 26:05.880
do the rising diagonal four twos are eight minus eight that's just going to be zero and then finally

26:05.880 --> 26:11.240
we ignore the bottom elements and we do the falling diagonal minus the rising diagonal one minus

26:11.240 --> 26:18.040
twelve is minus eleven so there's our solution twenty two zero minus eleven we notice we could

26:18.040 --> 26:22.840
take eleven out of that as a common factor it would make the next stage very easy but let's just

26:23.400 --> 26:29.080
let's do it the hard way and do the dot product so four times twenty two is eighty eight one times

26:29.080 --> 26:33.800
zero zero and minus eighty eight actually pretty easy to confirm that zero let's do the other one

26:33.800 --> 26:40.200
one times twenty two is twenty two three times zero and again two times uh minus eleven again zero

26:40.200 --> 26:47.240
so that's fine that one's past its checks as well on to the third one okay so um this time I think

26:47.240 --> 26:52.600
I might take a common factor out just to show us doing that because I see that this twenty five

26:52.600 --> 26:58.120
five fifteen chap is going to lead to some pretty big numbers but maybe I don't need to do that I

26:58.120 --> 27:03.320
can just take the common factor of five out of the first vector we're calling it vector a so that's

27:03.320 --> 27:09.480
just five one minus three and then I go ahead and write vector b which can't be simplified it's just

27:09.480 --> 27:15.080
one three minus two we'll do this cross cross pod excuse me we'll do this cross product and then

27:15.080 --> 27:20.760
we'll put the factor of five in at the end that's fine to do it that way around okay so let's go

27:20.760 --> 27:25.880
ahead and write that out there's our factor of five and here's our cross product so the first

27:25.880 --> 27:29.880
element of our cross product we ignore the first elements of the two source vectors we do the falling

27:29.880 --> 27:35.000
diagonal that gives us a minus two we subtract the rising diagonal that's a minus nine so that's

27:35.000 --> 27:41.480
minus two plus nine that's going to give us a seven and now the middle element we ignore the

27:41.480 --> 27:46.040
middle elements on the two source vectors we do the rising diagonal this time gives us minus three

27:46.040 --> 27:51.240
we subtract the falling diagonal that gives us minus uh ten which means we're gonna have to add

27:51.240 --> 27:58.040
on ten so that's minus three plus ten it's another seven okay and then finally the third element we

27:58.040 --> 28:03.880
ignore the third elements on the source vector we do the falling diagonal that's five threes of 15

28:03.880 --> 28:10.360
and we subtract the rising diagonal one that's going to give us another uh a 14 so in fact a

28:10.360 --> 28:16.120
really simple vector here because we could take out a factor of seven if we want to but um let's

28:16.120 --> 28:21.640
check those dot products do it before or after we take out the factor of seven it's pretty easy

28:22.360 --> 28:29.080
that's going to be uh four times seven minus uh and minus two times 14 yes that goes to zero

28:29.080 --> 28:39.320
let's do this one just quickly uh 35 and another seven is 42 but minus three times 14 is exactly

28:39.320 --> 28:45.080
minus 42 so that one is also satisfied we've passed our checks that looks pretty good we can

28:45.080 --> 28:51.720
leave it like this or if we want we can take out that factor of seven and do 35 times one one two

28:51.720 --> 28:57.480
very simple very nice uh vector there okay let's come here uh now come down to the bottom and look

28:57.480 --> 29:02.440
at the final one we notice is actually the cross product of a vector with itself it's the same vector

29:02.440 --> 29:07.560
here so what are we going to get well we can just easily enough work it out we ignore the first two

29:07.560 --> 29:13.320
elements and we do four um two times minus four and minus four times two so it's something minus

29:13.320 --> 29:19.640
itself that's just going to give us a zero obviously and uh let's keep going if we ignore the middle

29:19.640 --> 29:25.400
terms and do the rising diagonal minus the falling diagonal again threes and minus fours the same

29:25.400 --> 29:31.320
product so something minus itself zero and it's going to be the same for the final element so

29:31.320 --> 29:39.080
the cross product of a vector with itself is always going to be uh the zero vector now it's

29:39.080 --> 29:45.000
important not to write that just as the scalar zero because it is a different object it's the

29:45.000 --> 29:51.160
vector zero it's a set of in three-dimensional space three zeros that's what we get when we cross a

29:51.800 --> 30:01.160
vector with itself of course this is going to trivially satisfy our condition on the a dot c

30:01.720 --> 30:08.360
is equal to zero and b dot z is equal to zero that's clear and so uh i think that's a nice set of

30:08.360 --> 30:12.920
four examples done quite quickly there they're not too bad are they so that's the end of the video

30:14.360 --> 30:18.760
okay in this video we're going to look again at the cross product but this time we're going to ask

30:18.760 --> 30:26.120
about its geometric meaning and its properties when we come to manipulate it okay so if some

30:26.120 --> 30:32.840
vector c is the cross product of two other vectors a and b we've already seen how to work that out

30:32.840 --> 30:40.920
but what we can reasonably now ask is what does that vector c look like you know if we imagine a

30:40.920 --> 30:49.160
particular couple of vectors a and b there in space where is this vector c how is it related

30:49.160 --> 30:55.400
to them we know how to work it out but what's its relationship with them how should we think about it

30:56.440 --> 31:01.720
and that's what we're gonna we're gonna figure out now so we know that c is a vector so it has

31:01.720 --> 31:07.480
two properties it has its magnitude and direction let's think about the magnitude first what is the

31:07.480 --> 31:13.960
magnitude of c and how does that relate to um a and b what is the length of that vector it's pretty

31:13.960 --> 31:21.800
simple the magnitude of c is the magnitude of a times the magnitude of b times sine of the angle

31:21.800 --> 31:27.800
between a and b this is very similar to the dot product except with a sine instead of a cos

31:28.760 --> 31:36.040
so there we are there's our two vectors a and b and an angle between them and from those

31:36.760 --> 31:41.320
magnitude to the lengths of those two vectors in the angle we can work out the magnitude of c

31:41.320 --> 31:46.200
note that if we cross a vector with itself the angle will be zero and so the cross product will be

31:46.200 --> 31:53.240
zero just as we've already seen in our examples that was easy enough what about the direction

31:53.240 --> 32:01.720
of this new vector c how does that relate okay here's the thing the direction of c is perpendicular

32:01.720 --> 32:11.000
sorry for my writing there we'll be writing c is perpendicular to both vectors a and b so

32:11.000 --> 32:17.640
it's at right angles to each of those vectors separately and simultaneously what does that

32:17.640 --> 32:22.600
look like well actually we can draw it in one of two ways one of which is right and one is wrong

32:22.600 --> 32:29.800
let's just do that so here's um here's our vector a here's our vector b if we draw c like that and

32:29.800 --> 32:33.880
make it clear with this little symbol that it's at right angles to those two vectors

32:33.880 --> 32:38.920
that would be perpendicular to them both how about this we could also draw a vector a draw

32:38.920 --> 32:44.360
vector b again and we could go in the opposite direction simply literally the opposite direction

32:44.360 --> 32:49.800
and that would also be perpendicular to these two vectors one of these is actually strictly

32:49.800 --> 32:57.880
the correct case and the other is wrong by essentially a minus a minus one multiple what's

32:57.880 --> 33:03.160
the way to work that out so let's let's now figure that out there's actually a rule to remember it

33:03.160 --> 33:10.520
by it's called the right hand screw rule so let's draw that out kind of really clearly one more time

33:11.240 --> 33:19.880
we have two vectors a and b and we are going to say that a cross b is equal to some vector c

33:20.760 --> 33:28.600
that's fine so what we do is we put on the line along which we know c must lie

33:28.600 --> 33:33.960
so this is the line that's perpendicular to both a and b and we simply have to ask ourselves

33:34.200 --> 33:43.400
um in in this picture does the vector c uh go upwards or does it go downwards the trick is

33:43.400 --> 33:50.520
to write on the angle between a and b and give it a direction so that it's increasing from

33:50.520 --> 33:57.080
a to b it's the angle from a to b then you imagine taking your right hand and gripping

33:57.080 --> 34:05.080
that line in such a way that your fingers curl in the same direction as the angle increases

34:05.080 --> 34:11.240
and then your thumb points in the direction that the uh in the actual direction of c

34:11.240 --> 34:17.560
let's do another example uh just to uh really make that clear here's a and b again

34:19.000 --> 34:23.640
so we know we need to be I've drawn these lying in a plane so we I'm now trying to draw a line

34:23.640 --> 34:29.720
that's perpendicular to that plane vector c must lie in one direction or the other along this line

34:29.720 --> 34:36.040
what do we do we draw on the angle we now take our right hand and we imagine gripping that that line

34:36.040 --> 34:43.160
we've just drawn in such a way that our fingers curl uh in the direction in which the angle is

34:43.160 --> 34:49.400
increasing so it's like the anticlockwise direction in this picture and that's and then our thumb points

34:49.400 --> 34:54.360
in the correct direction for that vector so it's in fact these are the two opposite cases

34:55.560 --> 35:02.280
so that's the rule that allows you to construct the correct direction for your vector geometrically

35:02.280 --> 35:09.080
geometrically okay uh then let's just finally wrap up by thinking about the cross product

35:09.080 --> 35:14.600
and asking whether it has those properties that we looked at before for a vector addition

35:14.600 --> 35:21.240
the commutative property so for example is a cross b equal to b cross a it is not

35:21.880 --> 35:28.520
it is not equal to it unlike the dot product unlike addition this one the cross product

35:28.520 --> 35:36.040
it matters the order and in fact it simply uh introduces a minus sign if you swap the order

35:36.040 --> 35:41.000
of a and b so it's not commutative it nearly is in the sense that it gives you something similar it

35:41.000 --> 35:47.720
gives you uh the same thing up to a minus sign it's important to remember and you can just verify

35:47.720 --> 35:53.480
that by thinking about how we work out a and b with those diagonal products now how about the

35:53.480 --> 35:59.720
associative property can we say that a cross b cross c where b and c have already been worked out

35:59.720 --> 36:06.680
it's the same as a cross b and then cross c uh what do we think is that going to work or not in fact

36:07.400 --> 36:15.640
it uh this is the associative property we might ask whether this is true and the answer is no

36:15.640 --> 36:22.200
again uh the cross product does not have this property so the order in which you do your cross

36:22.200 --> 36:27.880
product if you have doing the cross product of three vectors does matter we can easily convince

36:27.880 --> 36:34.520
ourselves of this just by looking at a particularly uh convenient example let's just use cartesian

36:34.520 --> 36:40.840
vectors i j k so let's just remind ourselves where these guys lie they're perpendicular to each other

36:40.840 --> 36:47.960
i j and k just our unit vectors going in the x y and z direction so suppose we have this guy i cross

36:47.960 --> 36:54.520
i cross k if we try evaluating it this way around with the i cross k being worked out first well

36:54.520 --> 37:00.040
that's just going to give us in fact minus j which you can confirm with the right hand rule that we

37:00.040 --> 37:07.160
just introduced and then that in turn will give us k that's fine so we've worked out um in that

37:07.160 --> 37:12.840
instance the answer is minus k now let's do it the other way around i cross i if we do that first

37:12.840 --> 37:18.200
that's just going to be zero because i cross i is zero so it's game over already at that point

37:18.200 --> 37:23.160
so we can see two radically different answers here just depending on our order finally we could ask

37:23.160 --> 37:30.920
about the distributive property so are we allowed to multiply through using the cross product uh if

37:30.920 --> 37:38.760
we um if the second object in our cross product is a sum of two vectors can we do this well uh

37:38.760 --> 37:44.280
this at last is something that we are going to be allowed to do it is the distributive property

37:45.400 --> 37:52.360
and the cross product operation the vector product does have this property we are allowed to do that

37:52.360 --> 37:59.720
but of course we must make sure to make uh to keep the order the same okay so i think that's

37:59.720 --> 38:07.080
everything for this video okay in this lecture we're going to be looking at something called the

38:07.080 --> 38:18.760
scalar triple product so what we're dealing with here is taking three vectors and combining them

38:18.760 --> 38:27.160
in a certain way in order to yield a single one scalar quantity so three vectors into one scalar

38:27.160 --> 38:36.040
scalar triple product suppose we have a we dot it with b which itself is crossed with c that is the

38:36.040 --> 38:40.840
scalar triple product that combination now here i've put brackets to emphasize to do the cross

38:40.840 --> 38:50.280
product first but we can just write a dot b cross c without the brackets why because we have to do

38:50.280 --> 38:57.480
it in the correct order if we try to do a dot b first and then cross that with c it's a nonsense

38:57.480 --> 39:03.240
because that will be a scalar cross-producted with a vector doesn't make sense all right then

39:03.240 --> 39:10.600
so let's do one we'll make up some vectors let's have a is equal to three one minus one

39:10.600 --> 39:23.720
and b is equal to two zero four and c is equal to minus one minus two three okay there are vectors

39:23.720 --> 39:28.600
and let's go ahead and work it out so first we'll need to do the cross product b cross c so let's

39:28.600 --> 39:33.640
write that out so i'm bringing these down now remember you can work out the cross product by

39:33.640 --> 39:39.320
whatever your favorite method is i'm just going to do it in the method i introduced before which

39:39.320 --> 39:44.040
is we ignore the first elements and we do the falling diagonal here zero and subtract the

39:44.040 --> 39:49.800
rising diagonal minus eight that gives us the first element eight then we ignore the middle

39:49.800 --> 39:54.360
elements and we do the rising diagonal gives us minus four subtract the falling diagonal

39:54.360 --> 40:01.960
which is six so that's going to give us a minus 10 entry and then we ignore the third elements

40:01.960 --> 40:08.040
we do the falling diagonal gives us a minus four and subtract zero so that's going to be minus four

40:08.040 --> 40:12.600
that is our candidate for our cross product but it's always good to test how do we test a cross

40:12.600 --> 40:18.920
product we try dotting it with either of the input vectors and check we get zero so here we'll get

40:18.920 --> 40:24.280
eight twos are 16 and four minus four is minus 16 add it up that is zero and now we try the other

40:24.280 --> 40:33.000
combination here we're going to have minus one on eight minus eight and then plus 20 and then

40:33.000 --> 40:39.720
minus 12 that does indeed add up to zero it's past our checks those were just checks but it was good

40:39.720 --> 40:45.320
to do them and so we're now very happy that that is the correct cross product to finish the scalar

40:45.320 --> 40:53.000
triple product we now just need to dot that with a so let's write it out again minus 10 minus four

40:53.000 --> 41:01.800
and do the dot product that's 24 minus 10 plus four is going to be 18 that's the answer that's

41:01.800 --> 41:05.880
our scalar triple product it could have been a positive number a negative number could have been

41:05.880 --> 41:13.640
zero in this case it's 18 now let's do another one so I'll erase this but we'll simply use the same

41:14.600 --> 41:21.800
the same three vectors but we'll do them in a different order as our second example

41:21.800 --> 41:32.120
so let's do b dotted with c cross a so of course we have to start by doing that c cross a combination

41:32.120 --> 41:42.360
first so let me write that down quickly minus one minus two three crossed with three one minus one

41:42.360 --> 41:48.040
so we start with the falling diagonal that's going to be two and then we subtract three that's minus

41:48.040 --> 41:53.960
one and then we have a rising diagonal that's going to be nine and subtract one that's eight

41:53.960 --> 41:59.400
and then we have a falling diagonal minus one and subtract minus six so that's going to be

42:00.840 --> 42:07.960
five in all okay did I get that cross product correct or not do the dot product test

42:08.680 --> 42:16.040
minus three minus three eight minus five that one's passed let's try this dot product combination

42:16.040 --> 42:24.280
as a second check double check one minus 16 plus 15 that's also going to come out at zero

42:24.280 --> 42:30.120
so it's passed both of my checks that one is zero as well we're happy that this is indeed the cross

42:30.200 --> 42:37.560
product c cross a we now need to complete it so what we're doing is um b which was 204

42:38.280 --> 42:45.800
dotted with what we found our cross product minus 185 so again go ahead and value this

42:45.800 --> 42:55.320
minus 20 and 20 18 again all right so our second example has also given us 18 does this

42:55.320 --> 43:01.400
mean that it doesn't matter in which order we do the elements of the uh scalar triple product

43:02.120 --> 43:06.600
let me just write down the answer to that and then we'll look at it it turns out that for

43:06.600 --> 43:14.760
any vectors a b and c then a dot b cross c is equal to b dot c cross a these were the two

43:14.760 --> 43:24.280
cases we looked at and it's also equal in fact to c dot um a cross b this will always be true

43:24.280 --> 43:29.480
in this case it was equal to 18 but these three things will always be equal there are three other

43:29.480 --> 43:34.280
combinations we could write down in principle there are three other ways to combine a b and c

43:34.840 --> 43:47.160
we could have a dot c cross b or we could have b dot a cross c or we could have c dot b cross a

43:47.800 --> 43:52.680
now it turns out that those things are easy to see what they will be because

43:52.760 --> 43:57.880
let's just look at the difference from the ones above i've just swapped the order of the cross

43:57.880 --> 44:04.680
product and we know that when we oops we know that when we swap the order of a cross product

44:04.680 --> 44:10.920
we introduce a minus sign so if the top three cases were equal to 18 the bottom three cases

44:10.920 --> 44:18.200
must be equal to each other and equal to minus 18 and in general uh this is the same rule for all

44:18.520 --> 44:24.200
uh uh scalar triple products your three of them are equal and three of them uh are equal to

44:24.200 --> 44:29.400
one another but equal to the minus of the first three so to speak and and how can you tell which

44:29.400 --> 44:36.120
ones are equal it's helpful to write out this little cycle a b and c written in a circle like this

44:36.760 --> 44:43.960
if we are going around in a clockwise direction here b dot c cross a but that's clockwise around our

44:43.960 --> 44:51.160
wheel then um and here's another one that's clockwise c dot a cross b those guys all belong

44:51.160 --> 44:55.800
together so the guys that are in the clockwise direction all belong together and the anti-clockwise

44:55.800 --> 45:03.400
guys they belong uh together and they're the minus of one another these two groups all right so um

45:03.400 --> 45:09.720
that's uh that's i think all we need to do as practice for uh doing the scalar triple product

45:09.720 --> 45:14.120
and uh knowing what we ought to get let's think about something else i'm going to introduce you

45:14.120 --> 45:19.560
to something called the parallely pipette uh that's why i say i'm not sure how to pronounce it

45:19.560 --> 45:26.120
parallely pipette anyway this guy is a three-dimensional shape but first i'm going to remind you of what

45:26.120 --> 45:33.640
a parallelogram looks like so here's a rectangle and here's a parallelogram that we get um if we

45:33.640 --> 45:39.960
have uh the pairs of the sides are parallel to each other but they are not at right angle at

45:39.960 --> 45:48.120
right angles around the vertex now consider this rectangular box and let's tie it up there we are

45:48.120 --> 45:56.520
and consider what happens if we uh build it out of edges that are in groups of parallel edges but

45:56.520 --> 46:02.280
are not all at right angles to each other so uh let's see if i can draw this reasonably

46:02.920 --> 46:08.920
realistically as a three-dimensional object so i'm going to draw this and then i'm going to stress

46:08.920 --> 46:15.640
which edges are parallel to each other all right here we are okay let me change color

46:15.640 --> 46:22.680
so consider these four edges of the object are all parallel to each other in exactly the same way

46:22.680 --> 46:29.160
that in our simple parallelogram these opposing edges were parallel and then these four edges

46:29.720 --> 46:34.920
are all parallel to one another again in our 3d shape just as these two edges are parallel

46:35.720 --> 46:41.640
and then we have another set these four edges here in yellow are also going to be parallel to one

46:41.640 --> 46:50.040
another that object is a particular three-dimensional solid it's clearly a generalization of the uh

46:50.040 --> 46:56.280
of the box in that we're allowing ourselves to um have slanting edges if we want to now let's introduce

46:56.280 --> 47:01.720
three vectors a b and c to represent these three kinds of edges you see that all the green edges

47:01.720 --> 47:11.400
are the same vector a and so on what happens if we do a dot b cross c that it turns out the

47:11.400 --> 47:17.880
magnitude of that if we drop the sign then the magnitude is just the volume of this shape so it

47:17.880 --> 47:24.440
contains uh uh of course the simple case of a rectangular box as a special case but this will

47:24.440 --> 47:31.800
work for any parallel parallel pipette uh that we care to think of with those three vectors

47:31.800 --> 47:35.240
can always be combined with the scalar triple product to give us the volume

47:37.080 --> 47:44.040
and that's the end of the video welcome to the uh third um topic in this video series

47:44.040 --> 47:50.280
where i'll be introducing the matrix and thinking about what is a matrix product

47:51.160 --> 47:59.240
all right so essentially a matrix is nothing more than a grid of numbers simply a grid of

47:59.240 --> 48:07.800
numbers that could be positive or negative or fractional or zeros and when we uh specify the shape

48:07.800 --> 48:15.800
of our grid of numbers or we do so simply by stating how many rows we have and how many columns

48:16.600 --> 48:23.480
so we're gonna hear about rows and columns a lot in this video um in this video course i'm going

48:23.480 --> 48:31.240
to use a particular uh way of writing a matrix as a symbol and i need to do that i'm going to just

48:31.240 --> 48:41.400
use a capital letter and i'm going to the letter is going to be double underlined i'll double

48:41.400 --> 48:49.240
underline that symbol so here we go a underline that means the matrix a and how would we write it

48:50.360 --> 48:56.360
so that's uh just like this essentially a grid of numbers and we put it in curvy brackets just

48:56.360 --> 49:01.720
to give it some structure so this is three rows two columns that one here's a matrix b

49:01.720 --> 49:08.120
let's make it a square matrix let's put in a fraction to show we can minus 10 zero okay so

49:08.120 --> 49:14.440
there are two different examples of a matrix easy enough but it gets more interesting when we try and

49:14.440 --> 49:22.920
combine them so i want to talk about matrix multiplication addition is simple and it's

49:22.920 --> 49:31.640
just an element by element addition but multiplication is not so simple so here's how we write it

49:31.640 --> 49:37.880
the multiplication of matrix a by matrix b is simply written like this a b and it gives us

49:37.880 --> 49:44.760
some new matrix c which may be a difference shape from both a and b as we'll see let's give ourselves

49:44.760 --> 49:55.720
a couple of examples um three zero minus one two three four and matrix b can be just um one two zero

49:55.720 --> 50:02.440
minus three so there are our two matrices here i've chosen them such that a b that multiplication

50:02.440 --> 50:09.000
will work it will exist but actually if we try it the other way around it will turn out that the

50:09.000 --> 50:15.000
multiple the multiple of those two matrices doesn't even exist it's not a well-defined thing so this

50:15.000 --> 50:21.320
is an extreme case of an operation uh not being reversible in its order in other words matrix

50:21.320 --> 50:31.880
multiplication is not commutative okay so uh let's just erase that and go ahead and see

50:32.760 --> 50:42.440
how the multiplication actually works the trick is to multiply the each row of matrix a the first

50:42.440 --> 50:52.120
matrix by each entire column of matrix b what does that mean well let's write out our example

50:52.120 --> 51:01.720
three two zero three minus four minus one minus one four uh one zero two minus three now i know

51:01.720 --> 51:07.640
that this guy is going to have uh three rows and two columns the output matrix you'll see why in a

51:07.640 --> 51:13.480
bit i'll just put these blanks in for now the question is how to work out each of these numbers

51:13.480 --> 51:20.280
let's choose this one first okay now notice this guy's address if you like is row one column one

51:20.280 --> 51:26.920
of the output matrix c i'm going to need to in order to work this guy out i'll need to look at

51:26.920 --> 51:37.320
the whole of um row one in the first matrix in matrix a and the whole of column one in the matrix

51:37.880 --> 51:43.880
i'll need to combine those guys and how do i combine them i just multiply element by element as i go

51:43.880 --> 51:51.000
along the row and down the column so three times one just gives me three and then i add on the next

51:51.000 --> 51:58.520
combination two times two is four so three plus four is going to give me seven that's how i combine

51:58.520 --> 52:07.880
those two i'll jump back here and i'll erase there and i'll just put in my seven all right so that's

52:07.880 --> 52:13.720
the the general way it works let's go ahead and do the other elements of our matrix c let's do this

52:13.720 --> 52:20.040
one notice this is still row one so i want that first row it's now column two that's its address

52:20.040 --> 52:26.040
so i want the second column three times zero and two times minus three is how i'll work that out

52:26.040 --> 52:33.480
and that's just going to be minus six so let me jump backwards um and erase my blank symbol and

52:33.480 --> 52:40.840
write in minus six okay maybe i went a bit fast let me um spell this one out more explicitly okay

52:40.840 --> 52:47.400
so here i now have row two column one that's the address of that guy i want all of row two

52:47.400 --> 52:53.080
and all of column one i want to look at those guys and i want to multiply along so zero times one

52:53.080 --> 52:59.640
and three times two that's going to give us just six in total when we add them up so let me erase

52:59.640 --> 53:06.280
and put in six and now this element that's uh row two column two so i want all of row two

53:06.280 --> 53:14.600
want all of column two and multiply zero times zero and uh three times minus three is minus nine

53:14.600 --> 53:20.440
so that's going to be a minus nine if i go backwards and just put in minus nine here now

53:20.440 --> 53:26.120
we're finally on to the final third row so we're going to want the third row of a and in this case

53:26.120 --> 53:32.120
the first column so that's one times minus one and four times two is eight that's going to be seven

53:32.120 --> 53:38.600
minus one plus eight and then finally last row last column uh four times minus three is twelve

53:38.600 --> 53:47.560
and zero minus twelve all right so there we are that is our matrix product c formed by combining

53:47.560 --> 53:52.120
each row in each column it's quite a lot of work and it would be even more if we had bigger matrices

53:52.840 --> 53:58.280
but we said that um we get something quite different if we try multiplying a and b in the

53:58.280 --> 54:05.320
other order so let's go ahead and do that now what if we have one zero two minus three that's b

54:05.880 --> 54:13.720
on to three two zero three minus one four that's a so we can try it we try and multiply row one

54:13.720 --> 54:19.240
by column one and we immediately find we cannot because they are a different length a different

54:19.240 --> 54:25.880
list so there is no third element of our row to multiply with our third element of the column

54:25.880 --> 54:32.680
just pause the video here um and have a look at that and see why that must be impossible for us

54:32.680 --> 54:40.200
and so sometimes matrix multiplication is impossible all right let's look at a few uh little um

54:40.200 --> 54:44.280
further examples and you may want to pause the video to convince yourself in each case it's true

54:44.280 --> 54:51.080
is this thing possible for example pause it and think this one is not possible this is not possible

54:51.080 --> 54:58.040
again because there are two elements in say the first row of a and three elements in the column

54:58.040 --> 55:03.960
single column of b there's no way to do that as a series of element by element products how about

55:03.960 --> 55:12.840
this we just have this row matrix and this column matrix can we do that yes this one is perfectly

55:12.840 --> 55:22.440
possible actually it just produces a single number in fact it's a bit like a like a um a dot product

55:22.440 --> 55:29.560
it's the whole of row one times which is the entire matrix um and then the whole whole of column one

55:30.520 --> 55:36.440
this thing is called a row matrix and this other guy is called a column matrix for obvious reasons

55:38.440 --> 55:43.320
okay how about this let's have a look at this one what if i swap the order of my own column i

55:43.320 --> 55:50.440
just swap them around can i do that is that going to produce a legitimate matrix actually yes it will

55:50.440 --> 55:57.480
this time swapping our two matrices a and b around has produced um something which exists it's actually

55:57.480 --> 56:03.080
a huge matrix it's three by three it must have three rows and three columns because a has three rows

56:03.080 --> 56:07.720
and b has three columns how does it work let's look at that guy for example it's just simply the number

56:07.720 --> 56:13.880
there which is row one is just a number and column two is just a number single number so we just do

56:13.880 --> 56:20.360
that product there's no problem pause the video if it's confusing all right so again the point here

56:20.360 --> 56:28.360
is that um a times b is generally not equal to b times a even if they both exist they may not be

56:28.360 --> 56:32.760
the same they may not even be the same shape uh however we can go on and ask about the other

56:32.760 --> 56:39.880
kinds of properties of the matrix product operation a onto b times c is that the same as a times b

56:39.880 --> 56:45.720
onto c does the order matter actually it is the same it does work in other words we have the

56:45.720 --> 56:52.200
associative property how about a into b plus c some of two matrices yes we can have a onto b

56:52.200 --> 57:00.520
plus a onto c that is therefore the distributive property matrix multiplication does satisfy those

57:00.520 --> 57:07.080
things it's just not commutative okay let me make a bit more room up here in the top of the screen

57:07.880 --> 57:13.960
and put one final puzzle up suppose i have this two row three column matrix and then a mystery

57:13.960 --> 57:21.320
matrix m and then i have a simple column matrix of two rows and i'm asking what shape should

57:21.320 --> 57:29.320
matrix m be or is it even is it is it possible pause and think about that and in fact it's just

57:29.320 --> 57:34.600
a column matrix of three elements you may want to uh just meditate on that and see that it's correct

57:35.240 --> 57:40.680
okay that's the end of this video okay welcome to this video in this one we're going to take

57:40.680 --> 57:47.480
a look at how to work out a determinant what is it how can you find determinants of varying sizes

57:48.040 --> 57:55.080
so a determinant is a scalar it's just a number could be positive could be negative could be zero

57:55.080 --> 58:02.040
and it's derived from a square matrix a single number derived from an entire matrix

58:02.920 --> 58:10.360
um now the determinant of m would be written with m with the modulus signs either side of it

58:10.360 --> 58:15.720
even though it can be a negative number so here's an example of m and here is how we would write

58:15.720 --> 58:22.200
the determinant of m note that we don't bother writing squares uh straight sides and curved

58:22.200 --> 58:27.240
brackets as well there's no point in that it's just enough to have the straight line sides

58:27.960 --> 58:37.000
so let's start with the definition of a uh two by two determinant that's the easy case to look at

58:37.720 --> 58:45.560
so let's write out um a general two by two just using symbols we'll have a b c d written inside

58:45.560 --> 58:53.400
our straight line sides indicates a determinant it's simply a d minus b c okay so that's the

58:53.400 --> 58:59.880
falling diagonal the leading diagonal is also called minus the rising diagonal multiplied together

58:59.880 --> 59:07.080
very simple very simple and that is how you can just look at and evaluate a two by two determinant

59:07.640 --> 59:15.000
so for our example one two three four one times four is four subtract off a two times three is six

59:15.800 --> 59:19.560
and so that's going to give us minus two is the determinant

59:20.120 --> 59:30.280
okay so a three by three determinant is um going to be a bit more work what we do is when we have

59:30.280 --> 59:38.280
a three by three determinant we evaluate it by breaking it up into a number um up to three

59:38.920 --> 59:44.520
smaller determinants each of which is a two by two and for that we have our definition for

59:44.680 --> 59:49.720
immediate evaluation so we break up bigger determinants into little ones and then evaluate

59:49.720 --> 59:54.440
them now i'm going to write out something here that's like a chess board but instead of black and

59:54.440 --> 59:59.560
white i have pluses and minuses you'll see why in a moment the thing to notice though is that we

59:59.560 --> 01:00:06.520
alternate plus minus plus minus along each row and each column in this three by three grid okay

01:00:06.760 --> 01:00:14.440
so now let's work out a three by three determinant again i will just use general symbols a b c

01:00:15.160 --> 01:00:25.160
d e f g h i right now first i have to choose a row or a column i'm going to choose this top row

01:00:25.160 --> 01:00:31.560
for the first example and i'm going to work along this row and i'm going to start with the a symbol

01:00:32.040 --> 01:00:37.960
now i go and i look on my chart and i see that there's a plus sign in that in that slot of my

01:00:37.960 --> 01:00:45.800
grid that means i put down plus a and now what i do is i ignore the whole row and the whole column

01:00:45.800 --> 01:00:52.680
that a is in and i look at the remaining four numbers and i write a little determinant just

01:00:52.680 --> 01:01:00.120
made out of those guys in the same order they appear so e f um is going to be uh in my main

01:01:00.200 --> 01:01:06.440
determinant there and hi those are the remaining four guys in the same order they appear now b

01:01:06.440 --> 01:01:13.880
the next term that has a minus sign according to my chart so i will put in minus b and multiply it

01:01:13.880 --> 01:01:20.280
by again a smaller two by two determinant the one i get if i delete the row and the column with b in

01:01:20.280 --> 01:01:29.080
it and look at the remaining guys d f g i and i just i just uh write those guys out um in the same

01:01:29.080 --> 01:01:37.160
order they appear as a small two by two determinant finally there's c c appears with a plus sign

01:01:37.160 --> 01:01:46.360
according to my chart um so i need to put down plus c and i need to multiply by well we delete the

01:01:46.360 --> 01:01:57.560
row and column with c in it and we just see the remaining determinant d e um gh so uh i simply

01:01:57.560 --> 01:02:02.760
imagine that that row and column was not there and then that's what the determinant becomes

01:02:03.480 --> 01:02:08.920
and then of course those two by two determinants i can just write down what they are using my uh

01:02:10.280 --> 01:02:14.680
rule of multiplying down the diagonal and subtracting the anti-diagonal

01:02:16.440 --> 01:02:23.720
okay there we are so that is uh in general what a three by three determinant evaluates to

01:02:23.720 --> 01:02:29.320
but it's not the only way to do it let's write it out again and this time choose uh let's choose a

01:02:29.320 --> 01:02:34.760
column and a different one let's choose this column i'm also allowed to work down this so i

01:02:34.760 --> 01:02:41.080
would start with b as my first term and i delete the row and column with it in and i'd see what i

01:02:41.080 --> 01:02:49.800
are the remaining terms and write them d f g i except i've forgotten something uh there's a

01:02:49.800 --> 01:02:56.520
minus sign attached to that particular entry so that should actually have been minus b all right

01:02:56.520 --> 01:03:04.760
and then similarly plus e and i delete the row and column which has e in it and then i just make a

01:03:04.760 --> 01:03:11.320
two by two determinant from in this case it would be the corner elements a c g i and then finally

01:03:11.320 --> 01:03:18.760
minus h and delete the row and column with h in it make a two by two determinant determinant of

01:03:18.760 --> 01:03:28.440
what's left a c d f okay and of course i could then write out these two by two determinants

01:03:28.440 --> 01:03:34.520
explicitly but the point is it will get give me the same answer let's do an example and see why

01:03:34.520 --> 01:03:39.160
we would choose one method or the other so here are just some random numbers i'm making up let's

01:03:39.160 --> 01:03:46.200
stick that in it's three by three first off let's work along the top row and as uh as we did in our

01:03:46.200 --> 01:03:50.920
first example so that's going to be three uh let's put in the full determinant here

01:03:51.560 --> 01:03:57.960
and then minus one and again the determinant i get by excluding the top row and middle column

01:03:57.960 --> 01:04:06.520
and then plus two uh that's going to be seven zero five minus one and i can go ahead and i can

01:04:06.520 --> 01:04:12.520
work out explicitly what this comes out at as you can see i'm doing here and in fact it will be

01:04:12.520 --> 01:04:19.880
12 plus 20 minus 14 and it comes out as 18 so there we are we've worked out a three by three

01:04:19.880 --> 01:04:24.680
but we could have done it in a different way let's say we went along this bottom row that's

01:04:24.680 --> 01:04:32.120
fine so then it will be five and i will be left with one two zero four for my mini terminate

01:04:32.120 --> 01:04:37.640
and the next element along a minus sign and it was a minus number anyway minus minus one

01:04:37.640 --> 01:04:43.720
that's going to be three two seven four let's just see how we've done that three two seven four

01:04:43.720 --> 01:04:49.880
by deleting the bottom row and middle column of that now what about the third element here

01:04:49.880 --> 01:04:55.880
well we actually have a zero plus zero times sum determinant i don't even care what that is because

01:04:55.880 --> 01:05:01.000
it's been multiplied by zero that's the beauty of it so i've got five into four minus zero

01:05:01.960 --> 01:05:07.080
and then we're going to have four threes of 12 minus 14 so that's going to give us 20 minus

01:05:07.080 --> 01:05:15.160
two is 18 same answer as before okay what about if we have even bigger determinants than our three

01:05:15.160 --> 01:05:22.280
by three example there if we have if we go bigger still we for example a four by four we're just

01:05:22.280 --> 01:05:27.960
going to break it up into a number of three by threes and each of those would have to be broken up

01:05:27.960 --> 01:05:36.040
into two by twos lots of work so here we are here's a general four by four we are going to expand it

01:05:36.040 --> 01:05:42.040
along a row or column let's say we want to expand it along this row for example and we'll take in

01:05:42.040 --> 01:05:48.360
turn a b c d and we'll need to know what sign to use so here's our checker board or our chess board

01:05:48.360 --> 01:05:55.080
pattern of pluses and minuses just extend it out now to a four by four and you can see the rule here

01:05:55.080 --> 01:06:01.160
is that if you like if the row number plus the column number is an even number then there's going

01:06:01.160 --> 01:06:05.640
to be a plus sign and if it's odd it's going to be a minus sign you can confirm that for yourself

01:06:05.640 --> 01:06:12.440
look at this one it's going to be at row two and column three and that's five and so that's a minus

01:06:12.440 --> 01:06:17.800
that's one way to remember it or just draw it out anyway we're going to use that rule so we go

01:06:17.800 --> 01:06:24.280
ahead and we write plus a and now we need to do the entire three by three determinant that we get

01:06:24.280 --> 01:06:30.120
when we delete the row and column with a in it so we just write out that little square block

01:06:30.120 --> 01:06:35.800
that we see it's quite easy to copy across and now we're going to have minus b and we need to delete

01:06:35.800 --> 01:06:42.200
the row and column and then transcribe across the elements that are left as a three by three

01:06:42.200 --> 01:06:49.080
just being careful not to make any slips and you see that we're going to continue so let's

01:06:49.080 --> 01:06:53.720
delete this just to be completely explicit I'll finish the job off so I think I hope it's off

01:06:53.720 --> 01:07:04.120
is what we're doing we're onto plus c and now we're going to just have e f h i j l and m n p

01:07:04.840 --> 01:07:12.680
and then finally minus d um onto what we get if we delete the top row and right most column

01:07:12.680 --> 01:07:20.440
which is left over then e f g i j k m n oh there we are that's how we handle a four by four each

01:07:20.440 --> 01:07:25.880
of these three by threes would then have to be evaluated and so on so a lot of work and

01:07:25.880 --> 01:07:32.040
that's the end of the video okay welcome to this fifth topic which is eigenvalues and eigenvectors

01:07:32.040 --> 01:07:37.560
we'll introduce the problem and we'll see how to find eigenvalues finding eigenvectors is for

01:07:37.560 --> 01:07:48.440
the next video so suppose that we are given a square matrix um n just some matrix but we are

01:07:48.440 --> 01:07:58.200
told that m multiplied by v is equal to lambda multiplied by v for some scalar just some number

01:07:58.200 --> 01:08:08.040
lambda and for some column matrix uh v and a column matrix of course the same as a vector

01:08:08.760 --> 01:08:15.240
I will just say vector from now on okay so this scalar lambda could be positive negative or zero

01:08:16.120 --> 01:08:23.000
meanwhile this vector v could be anything except the trivial boring case of just zeros

01:08:23.000 --> 01:08:28.360
it's something other than that our challenge then is that we're going to be given a square matrix m

01:08:28.360 --> 01:08:34.360
and we have to look for any scalar lambda and vector v that satisfies the equation

01:08:35.080 --> 01:08:40.440
and such a scalar is called an eigenvalue and such a vector is called an eigenvector

01:08:40.520 --> 01:08:47.720
so in that language m multiplied by some eigenvector gives us back that eigenvector just

01:08:47.720 --> 01:08:56.440
multiplied by a scalar the eigenvalue okay so first off let's notice that if we are given

01:08:56.440 --> 01:09:02.440
a candidate a possible eigenvector v to try perhaps for a multiple choice then it's easy

01:09:02.440 --> 01:09:09.160
to test we'll just go ahead and try it so here's a square matrix a two by two two four one minus one

01:09:09.800 --> 01:09:21.400
and uh suppose we write down v is equal to one minus one and this is suggested as a possible

01:09:21.400 --> 01:09:27.480
eigenvector well then we would just test it out to see if it matches our equation

01:09:28.120 --> 01:09:35.160
we try multiplying m by v so here we go two four one minus one and v is one minus one

01:09:35.160 --> 01:09:42.360
that's a column and so we do row times column that's two and minus four is minus two and again row

01:09:42.360 --> 01:09:48.760
and column that's going to be one plus one is two and we notice we can take out minus two as a factor

01:09:48.760 --> 01:09:55.240
and then it will be the vector left is one minus one but that is just v so minus two is indeed a

01:09:55.240 --> 01:10:02.120
scalar that multiplies v and we've succeeded improving that v is our eigenvector and our

01:10:02.120 --> 01:10:07.800
eigenvalue that goes with it is minus two okay so that's great if we're given eigenvectors to

01:10:07.800 --> 01:10:15.000
check out but what if we're not given any eigenvectors or eigenvalues then we must find any possible

01:10:15.000 --> 01:10:21.240
eigenvalues for ourselves there could be more than one and for each we must find the corresponding

01:10:21.240 --> 01:10:27.560
eigenvector v and in this first video we're just going to be finding those eigenvalues

01:10:28.360 --> 01:10:34.520
okay so here's a little bit of quick manipulation and a side we know our equation is mv is equal

01:10:34.520 --> 01:10:40.840
to lambda v i can certainly just bring it all to the left hand side and write mv minus lambda v

01:10:40.840 --> 01:10:45.080
is equal to zero as long as i don't remember to write that as vector zero but now let's do

01:10:45.080 --> 01:10:50.600
something interesting let's insert the identity matrix which won't change the equation but it

01:10:50.600 --> 01:11:02.200
will be important for the next step mv minus lambda times the identity times v is equal to

01:11:02.200 --> 01:11:07.720
vector zero the identity doesn't change the equation but now i can factor out both those two matrices the

01:11:07.720 --> 01:11:14.200
m and the minus lambda times the identity that's a matrix i can factor those out and it allows

01:11:14.200 --> 01:11:21.080
me to write that line now that if form of the equation it turns out this can only be solved

01:11:21.080 --> 01:11:29.160
for any interesting v any v other than just zeros if the following equation is true which we can

01:11:29.160 --> 01:11:35.240
easily prove but we're not going to prove in this video m minus lambda times the identity the determinant

01:11:35.240 --> 01:11:39.720
of that is equal to zero so we're going to have plenty of time to think about that but let me just

01:11:39.720 --> 01:11:46.520
put a green box around it because that is the fundamental equation we're going to use this

01:11:46.520 --> 01:11:58.120
will allow us to find all the eigenvalues that satisfy our basic eigenvalue equation so let's

01:11:58.120 --> 01:12:04.440
do an example it's the best thing let's do m as a two four this was the one we had before two four

01:12:04.440 --> 01:12:10.440
minus one little square matrix and so let's write down what this lambda times the identity is

01:12:10.440 --> 01:12:16.280
for a two by two it's going to be lambda zero zero lambda very simple and so this matrix that's the

01:12:16.280 --> 01:12:22.600
difference of the two of them two minus lambda four one minus one minus lambda just the difference of

01:12:22.600 --> 01:12:29.720
those two things as a determinant is equal to zero that's all so there we have it we've just

01:12:29.720 --> 01:12:34.440
subtracted lambda off the down the diagonal but now we need to solve this so we just write out

01:12:34.440 --> 01:12:39.240
the determinant two minus lambda multiplied by minus one minus lambda down the diagonal minus

01:12:39.240 --> 01:12:46.200
four the off diagonal is equal to zero all right so we expand this out minus two minus two lambda

01:12:46.200 --> 01:12:53.960
plus lambda um plus lambda squared minus four equals zero let's come over here for a bit more

01:12:53.960 --> 01:13:04.520
space tidy that up a bit what if we got lambda squared minus lambda minus six is equal to zero

01:13:04.520 --> 01:13:11.640
can we solve this actually it's quite easy to factor that's going to be lambda minus three

01:13:12.200 --> 01:13:19.800
into lambda plus two is equal to zero so that's true if either lambda is equal to three

01:13:20.440 --> 01:13:28.040
or it's equal to minus two and those are our two eigenvalues we found them using that equation in

01:13:28.040 --> 01:13:39.560
the square box let's crack on and do one with a three by three matrix m here we go matrix m

01:13:39.560 --> 01:13:47.000
is equal to let's have minus two one three one minus one zero and minus one one two i've worked

01:13:47.720 --> 01:13:55.080
i've checked that before and it will work for us nicely now let's remember of course the rule

01:13:55.080 --> 01:14:03.240
from the previous screen and we just need to apply that so let's go ahead and write it as a

01:14:05.080 --> 01:14:11.880
write our determinant out we need to have minus two minus lambda and then just one and minus one

01:14:11.880 --> 01:14:19.560
and then one minus one minus lambda and then one and three zero two minus lambda i'm just

01:14:19.560 --> 01:14:24.600
subtracting lambdas down the diagonal making it a determinant setting it equal to zero

01:14:24.600 --> 01:14:28.680
now i'm going to work along this row because it's got a zero in it so that makes me like it a bit

01:14:28.680 --> 01:14:34.600
more as a determinant the first number is going to be minus one why because it's a one and let me

01:14:34.600 --> 01:14:39.080
just quickly write out our little lookup table of pluses and minuses for doing determinants

01:14:39.800 --> 01:14:44.680
so it was a one and then it picked up a minus sign and then we have the mini determinant that's made

01:14:44.680 --> 01:14:52.840
out of those four terms so that's one three one and two minus lambda all right and then the next

01:14:52.840 --> 01:14:58.520
term is going to be plus and then it's going to be the term itself is minus one minus lambda

01:14:58.520 --> 01:15:04.360
and the mini determinant that we get when we exclude that row and that column is just made

01:15:04.360 --> 01:15:12.680
out of the corner terms that's going to be minus two minus lambda and three and one and two minus

01:15:12.680 --> 01:15:19.320
lambda and that's it because the zero term gives us nothing so it was only those two mini determinants

01:15:19.320 --> 01:15:25.240
let's write them out minus one two times lambda and then three times one is three let's expand that

01:15:25.240 --> 01:15:31.560
one out and then this one has the term in front minus of one plus lambda and then we have to expand

01:15:31.560 --> 01:15:38.600
out the determinant minus two minus lambda times two minus lambda down the league diagonal

01:15:38.600 --> 01:15:43.800
minus minus three is plus three there we are is equal to zero and then we just need to tidy that

01:15:43.800 --> 01:15:50.440
up we need to clean it up a bit that's going to be minus of minus lambda minus one for the first

01:15:50.440 --> 01:15:56.200
term let's turn that it one into pluses multiply through by the minus one and here we have minus

01:15:56.200 --> 01:16:01.160
let's make that lambda plus one right that way around and then tidy up inside here we expand

01:16:01.160 --> 01:16:08.520
it out minus four plus two lambda minus two lambda plus lambda squared and this three is

01:16:08.520 --> 01:16:13.400
equal to zero we need to keep on working to tidy that a bit more this term here is in fact going

01:16:13.400 --> 01:16:18.280
to be just I see the lambdas cancel out lambda squared minus one that's very nice that's come

01:16:18.280 --> 01:16:24.120
down very very neatly so now we can really tidy that up and we can take out a common factor of

01:16:24.120 --> 01:16:29.720
lambda plus one and the first term was just that so there's one for that and the second term we've

01:16:29.720 --> 01:16:36.760
just found is lambda squared minus one pause the video and check you agree that that's tidied up

01:16:36.760 --> 01:16:40.840
version of the equation now the way that can be zero is either the first term is zero which

01:16:40.840 --> 01:16:47.000
requires lambda is equal to minus one so there's one eigenvalue for us that's one option one of

01:16:47.000 --> 01:16:53.240
our eigenvalues has been found or the second term here has to be zero so let's do a bit more work

01:16:53.240 --> 01:17:01.240
with that what we're saying is to neaten that up we're saying that lambda two minus lambda squared

01:17:01.240 --> 01:17:08.840
is equal to zero in other words lambda squared is equal to two and so lambda is going to be

01:17:08.840 --> 01:17:15.560
plus or minus square root of two that's two more eigenvalues three in all that we found for this

01:17:15.560 --> 01:17:21.800
three by three matrix and in the next video we'll see how to take each of these values

01:17:21.800 --> 01:17:29.000
and derive the corresponding vector this is the second of two videos that looks at eigenvalues

01:17:29.000 --> 01:17:39.480
and eigenvectors in the first video we have seen how to find eigenvalues and we write these as lambda

01:17:40.760 --> 01:17:47.240
for each lambda how do we find the eigenvector an eigenvector that goes with it

01:17:47.240 --> 01:17:56.840
we know that our fundamental equation that we're working with here is that when matrix m multiplies

01:17:56.840 --> 01:18:03.560
an eigenvector v it just gives us back that v scaled by lambda and another way to write that

01:18:03.560 --> 01:18:09.960
is the m minus lambda times the identity multiplied by v is equal to vector zero this is the same

01:18:09.960 --> 01:18:16.520
equation written two different ways what we need to know now that we um have obtained our lambda

01:18:16.520 --> 01:18:22.440
values we just need to look at one of these equations and figure out an acceptable vector

01:18:23.320 --> 01:18:26.520
i find that it's more useful to use the form on the right hand side

01:18:28.600 --> 01:18:36.360
okay let's look at a particular example we'll have the matrix two four one minus one we looked at

01:18:36.360 --> 01:18:43.880
this before and we found already that its eigenvalues are equal to three and minus two

01:18:44.040 --> 01:18:51.880
what we're going to do now is we're going to take those values one at a time and figure out an acceptable

01:18:51.880 --> 01:18:59.640
eigenvector we're going to write our vector that we need to find as just x and y where we need to

01:18:59.640 --> 01:19:06.600
find these x y values now take a look at this green underlined equation and in particular the matrix

01:19:06.600 --> 01:19:13.480
which is a difference of two different matrices m and lambda times the identity now that we have

01:19:13.480 --> 01:19:19.560
our lambda value of three we could write out that difference that difference matrix it's going to be

01:19:19.560 --> 01:19:27.640
two minus three and then just four and then just one and minus one minus three there it is

01:19:27.640 --> 01:19:32.280
we're saying that when that multiplies our vector x y it gives us zero zero

01:19:34.120 --> 01:19:39.800
so let's go ahead and clean this equation up we have minus one four one minus four

01:19:39.800 --> 01:19:46.200
four onto x and y if you want to be explicit about that we can multiply out it means minus x

01:19:46.200 --> 01:19:55.800
plus four y and x minus four y and that we know is equal to zero zero now what we immediately notice

01:19:55.800 --> 01:20:03.000
here is that whilst this this equation between two columns two column vectors is telling us two

01:20:03.000 --> 01:20:09.320
things it's actually telling us the same equation twice so we can see here that we're saying

01:20:09.320 --> 01:20:16.360
minus x plus four y is equal to zero we're also saying that x minus four y is equal to zero

01:20:16.360 --> 01:20:22.600
that's telling us the same thing is that a problem no that's exactly what we want to see

01:20:22.600 --> 01:20:29.080
at this stage we should find that when we work on uh eigenvalue and eigenvector problems based on a

01:20:29.080 --> 01:20:36.760
two by two matrix then really only one of these rows in the final expression uh constrains us

01:20:36.760 --> 01:20:43.160
and the other one doesn't add any new constraint so this is exactly what we want so now how do we

01:20:43.160 --> 01:20:51.080
go ahead and solve it we're saying that uh minus x plus four y is equal to zero of course we can

01:20:51.080 --> 01:20:59.080
just rearrange this to say instead that four y is equal to x and that's the only constraint we have

01:20:59.080 --> 01:21:11.160
what we're allowed to do is choose we can choose the simplest values of x and y that will make

01:21:11.160 --> 01:21:16.680
this work so i'm going to choose y is equal to one and then i'll find that x is equal to four

01:21:17.880 --> 01:21:26.680
and that is a perfectly acceptable eigenvector for one to go with my eigenvalue we will always

01:21:26.680 --> 01:21:34.440
have this freedom in choosing the elements of our eigenvector really this freedom simply corresponds

01:21:34.440 --> 01:21:40.840
to choosing how long the eigenvector is in other words its magnitude because if a particular

01:21:40.840 --> 01:21:48.120
eigenvector and eigenvector satisfies our equations a scaled version of that same eigenvector will

01:21:48.120 --> 01:21:56.360
still satisfy with the same eigenvalue now while the eigenvector can have any length we might

01:21:56.360 --> 01:22:03.560
specifically have been asked for a normalized eigenvector that simply means we need to take

01:22:03.560 --> 01:22:10.280
the one that we found and scale it to have unit length so in this case since it's four one we

01:22:10.280 --> 01:22:20.040
need to divide by uh root seventeen to scale to unit length simple as that so there we are

01:22:20.040 --> 01:22:26.680
that's our eigenvector and a normalized version of it now we still haven't found the eigenvector for

01:22:26.680 --> 01:22:33.240
the other eigenvalue which was minus two let me just move this up on the screen to make space to

01:22:33.240 --> 01:22:38.520
do that at the bottom so here we go we do exactly the same procedure we subtract minus two on the

01:22:38.520 --> 01:22:45.640
diagonal two minus minus two and four and one minus one minus minus two lots of minus is there

01:22:45.720 --> 01:22:53.720
so let's uh tidy that up that's going to be four four one and in fact another one

01:22:54.520 --> 01:23:01.640
and then times x y is equal to zero zero as before we see that really these this is the

01:23:01.640 --> 01:23:07.160
same equation twice there's only one constraint and we can read it off simply as x is equal to

01:23:07.160 --> 01:23:13.800
minus y so if i choose x is equal to one for example then i'm going to write down an eigenvector

01:23:13.800 --> 01:23:17.640
one minus one or if i've chosen y is equal to one then it would have been

01:23:17.640 --> 01:23:23.400
minus one one it doesn't matter they're both correct eigenvectors to go with our eigenvalue

01:23:23.400 --> 01:23:29.400
but if we want to normalize well they need to divide by the magnitude one over root two okay

01:23:29.400 --> 01:23:38.600
so there are acceptable eigenvectors to go with the eigenvalue minus two okay so now let's find

01:23:39.400 --> 01:23:47.880
the eigenvectors that go with the eigenvalues for our three by three matrix m which was

01:23:49.400 --> 01:23:59.960
minus two one three one minus one zero minus one one two we looked at that before in the

01:23:59.960 --> 01:24:10.520
previous video and we found the eigenvalues which were minus one root two and minus root two

01:24:11.160 --> 01:24:16.600
and i've put little subscripts on our lambdas here so we know which one we're dealing with

01:24:16.600 --> 01:24:21.480
let's deal with lambda one first which is the one that has value minus one

01:24:23.080 --> 01:24:27.160
so i'll write over here the little equation that we're using over and over again

01:24:27.160 --> 01:24:32.600
which is that m minus lambda times the identity multiplied by our vector is zero

01:24:33.640 --> 01:24:38.840
okay we need this difference matrix so we subtract off the diagonal one minus minus one

01:24:38.840 --> 01:24:48.200
and then one three one and minus one minus minus one and zero minus one one and two minus minus one

01:24:49.320 --> 01:24:53.800
and that's on x y and z because we now need an eigenvector with three elements

01:24:54.760 --> 01:25:03.480
and it's going to be equal to uh we simplify the matrix to minus one one three one zero zero

01:25:03.480 --> 01:25:15.240
minus one one and that'll be a three and that again is on our x y z eigenvector is equal to zero

01:25:15.640 --> 01:25:24.280
zero now what we immediately notice is that as before we don't really have three different

01:25:24.280 --> 01:25:31.000
equations captured by our matrix equation we only have two in fact this is very obvious in

01:25:31.000 --> 01:25:38.120
this case because the bottom row is the same as the top row that's not always the case it's not

01:25:38.120 --> 01:25:44.040
always the case that the rows are actually identical but we will always find if we check

01:25:44.040 --> 01:25:49.400
that there are only really two independent equations when we're dealing with three by

01:25:49.400 --> 01:25:57.320
three eigenvalue problems we only have two equations really now i'm going to uh highlight

01:25:57.320 --> 01:26:02.920
this row here one zero zero that's just saying in fact that x is equal to zero

01:26:04.680 --> 01:26:11.000
now if we take uh either the top row or the bottom run we have minus x plus y plus three z

01:26:11.000 --> 01:26:20.120
is equal to zero or y is equal to minus three z okay so now we simply uh choose any values

01:26:20.120 --> 01:26:27.080
of y and z x has been dictated to us but any values of i y and z that satisfy these rows

01:26:28.040 --> 01:26:32.200
so if i choose z is equal to one that's going to give me y is equal to minus three

01:26:32.840 --> 01:26:38.120
and i can straight away then write down a satisfactory eigenvector it will be zero

01:26:38.120 --> 01:26:43.880
minus three one as simple as that it doesn't matter whether minus sign is i could equivalently

01:26:43.880 --> 01:26:51.800
have chosen z is equal to minus one and then i'd have zero three minus one if i normalize then

01:26:51.800 --> 01:26:59.160
i'll need one over root ten that being three squared plus one squared and so that is a complete

01:26:59.160 --> 01:27:04.840
solution for our first eigenvector we found it in simple form and in normalized form this is the

01:27:04.840 --> 01:27:11.800
eigenvector that goes with eigenvalue minus one we can go ahead however and check this eigenvector

01:27:11.800 --> 01:27:19.720
to make sure that it works so for that we'll simply need to write out our matrix m the original matrix

01:27:19.720 --> 01:27:30.920
which was minus two one three one minus one zero minus one one two we have our

01:27:31.720 --> 01:27:38.680
vector zero three minus one we just need to do this sum so the first element is going to be

01:27:39.320 --> 01:27:44.600
a minus two times zero and then so three and i see there's a minus three so that does give us zero

01:27:45.160 --> 01:27:49.560
and our second element is the only non zero element will be minus three

01:27:50.520 --> 01:27:57.640
and our third third element there gives us one and we can write that as simply minus one

01:27:57.640 --> 01:28:05.240
onto zero three minus one and so indeed we found that this vector works with the eigenvalue of

01:28:05.240 --> 01:28:13.000
minus one now we can continue to look at uh to find the other eigenvectors but first let's take a

01:28:13.000 --> 01:28:22.280
pause and review the steps involved so we're looking at rules for solving eigenvector problems

01:28:22.280 --> 01:28:27.480
eigenvector problem is where we have a square matrix m and we say that m multiplied by some

01:28:27.480 --> 01:28:35.560
special eigenvector gives us back that eigenvector times just by a value the eigenvalue we find the

01:28:35.560 --> 01:28:41.640
possible eigenvalues using this equation involving a determinant of a difference of two matrices

01:28:43.480 --> 01:28:50.280
in general there are going to be n solutions for an n by n matrix so two solutions for a two by two

01:28:50.280 --> 01:28:56.120
three solutions three solutions for a three by three matrix that's because when we write the

01:28:56.120 --> 01:29:03.240
determinant it will have lambda to the power of n as its highest order so for example we have

01:29:03.240 --> 01:29:10.280
cubed to deal with when we're working out for three by three matrices now having found those

01:29:10.360 --> 01:29:16.120
eigenvalues we then for each value need to figure out an acceptable eigenvector

01:29:18.040 --> 01:29:24.680
what we've noticed is that generally we only have to use n minus one of the rows in the equation

01:29:24.680 --> 01:29:30.520
that we're working to satisfy and that meant just one row in the case of two by two problems

01:29:31.240 --> 01:29:33.640
and two of the rows in the three by three problems

01:29:33.640 --> 01:29:42.600
we had some freedom as to what values to choose for our eigenvector and in fact that freedom

01:29:42.600 --> 01:29:49.960
corresponded to just scaling the entire eigenvector to a greater or smaller magnitude and if we were

01:29:49.960 --> 01:29:54.920
asked to normalize we would simply work it out using whatever values we like the simplest values

01:29:55.560 --> 01:30:02.600
and scale it at the last step so that it has unit length okay so we've covered a lot of ground

01:30:02.600 --> 01:30:08.120
for one video and this would be a good place to just stop watching if you like but i would like to

01:30:08.120 --> 01:30:14.200
carry on and solve the remaining two eigenvectors for our three by three example because they involve

01:30:14.200 --> 01:30:19.000
a square root two they're actually a bit more messy and tricky to do and in a way i think that makes

01:30:19.000 --> 01:30:25.880
for a good interesting example to see so let me go ahead and cut back to the screen that we had

01:30:25.880 --> 01:30:32.920
before with our matrix m spelt out and our possible eigenvalues and we'll now take the value lambda

01:30:32.920 --> 01:30:40.760
subscript two which is square root two so then as usual we need to subtract that down the diagonal

01:30:40.760 --> 01:30:48.680
so we'll have minus two minus square root two one three one minus one minus square root two zero

01:30:49.480 --> 01:30:57.000
minus one one two minus square root two and that is the thing which when multiplied by

01:30:57.000 --> 01:31:04.600
our unknown eigenvector xyz should give us zero zero zero now one thing we notice here is the rows

01:31:04.600 --> 01:31:10.600
look all different it looks like we've got three different equations captured in this matrix equation

01:31:10.600 --> 01:31:16.040
but they are not if we examine them carefully enough we'd find that we could generate one of these

01:31:16.680 --> 01:31:22.120
rows from the other two and in fact we're only therefore going to need to use two of them

01:31:22.120 --> 01:31:25.960
you could pause the video and play with it and see if you can show this but it must always be

01:31:25.960 --> 01:31:31.400
the case unless we've made a slip earlier okay so i see that the middle row has a zero so i'm

01:31:31.400 --> 01:31:38.040
going to start with that one it says x plus minus two minus root two times y is equal to zero

01:31:39.240 --> 01:31:44.360
and that means that if i choose a simple value for y of one then i can immediately say

01:31:44.360 --> 01:31:53.000
that x moving across is going to be one plus root two good so now i'll use the top line which is

01:31:53.000 --> 01:32:00.200
minus two minus root two x plus y plus three z is equal to zero and i'll substitute in the values

01:32:00.200 --> 01:32:10.680
that i've already picked and inferred so i'm going to get one plus root two onto minus two minus

01:32:10.680 --> 01:32:16.120
root two that's the x term plus the y is one plus three z yet to be found is equal to zero

01:32:16.760 --> 01:32:23.160
rearrange so put z on one side divided by a third expand this thing out minus two

01:32:24.600 --> 01:32:36.120
minus root two minus two root two minus two plus one all right oh and there's a minus sign

01:32:36.680 --> 01:32:41.960
because we've moved it all to the other side from the z of course now we need to tide this up

01:32:41.960 --> 01:32:47.800
but what i notice is that inside the brackets i have a minus three and a minus three root two

01:32:47.800 --> 01:32:52.440
and that will cancel cancel with a factor of a minus and third of front and just give us a very

01:32:52.440 --> 01:33:00.520
simple expression of one plus root two so that's our z term okay we've found a compatible set of

01:33:00.520 --> 01:33:07.000
x y and z values so we can now write down an accept acceptable eigenvector one plus root two

01:33:07.000 --> 01:33:12.840
one one plus root two there we are that is an acceptable eigenvector and here's where we found

01:33:12.840 --> 01:33:18.920
those numbers uh that goes with the eigenvalue lambda two is equal to square root two note that

01:33:18.920 --> 01:33:26.680
i use the same subscript two on my vector so that i make it clear that lambda subscript two goes along

01:33:26.680 --> 01:33:35.800
with vector subscript two so now our only remaining task is to look at the third eigenvalue which was

01:33:35.800 --> 01:33:42.120
negative root two and find a compatible eigenvector for that one so as always what we need to do is

01:33:42.120 --> 01:33:48.600
take the vector m and subtract that the lambda value we found off down the diagonal and because

01:33:48.600 --> 01:33:54.280
we're subtracting minus a minus number we can just add it instead of course so that will be minus two

01:33:55.000 --> 01:34:02.440
plus root two and then one and then three and then one and minus one plus root two and zero

01:34:02.440 --> 01:34:09.720
and minus one and one and two plus root two and that matrix when multiplied by our unknown

01:34:09.720 --> 01:34:17.080
eigenvector x y z will give us zero zero zero now as before our middle row looks nicest here

01:34:17.080 --> 01:34:23.960
it's just telling us that x plus root two minus one put it that way around y times y is equal to

01:34:23.960 --> 01:34:30.840
zero that means if i chose y is equal to one obvious choice then x is equal to one minus root two

01:34:30.840 --> 01:34:36.760
watching for signs now if i take the let's say the bottom row i can have minus x plus y

01:34:37.960 --> 01:34:44.280
plus two plus two root plus two plus root two times z is equal to zero but i can substitute

01:34:44.280 --> 01:34:51.720
in the values i found so that will say that square root two minus one plus one plus two

01:34:51.720 --> 01:34:58.120
plus root two z is equal to zero okay i've got some work to do to find out the value of z here

01:34:58.120 --> 01:35:08.200
i'll start by rearranging just to put two plus root two z is equal to minus root two on the other

01:35:08.200 --> 01:35:13.480
side but i still need to do a bit more work divide both sides i notice i can simplify

01:35:13.480 --> 01:35:20.200
simplify by a factor of root two i can write this as z is minus one over root two plus one

01:35:20.200 --> 01:35:25.960
pause the video and check you agree with me um and then i'm not happy with that because i don't

01:35:25.960 --> 01:35:31.480
want to leave z as a fraction i could do but that would make a very messy looking eigenvector

01:35:31.480 --> 01:35:37.320
i noticed there's a trick in up i have up my sleeve i know that if i multiply the top and bottom

01:35:37.320 --> 01:35:45.640
of a fraction like that by root two minus one it will simplify i will then find that the top of course

01:35:45.640 --> 01:35:53.960
is one minus root two uh but the bottom will be two plus root two minus root two minus one

01:35:53.960 --> 01:36:01.240
and that whole expression just comes down to one finally then z is equal to one minus root two

01:36:01.240 --> 01:36:07.080
we've now found our x y and z values that are acceptable so we're seeing saying that vector

01:36:07.080 --> 01:36:13.000
three that goes with the lambda three value is one minus root two one one minus root two that is

01:36:13.000 --> 01:36:19.400
an acceptable eigenvector so we're done for our three by three matrix m we found that three

01:36:19.400 --> 01:36:25.480
eigenvalues and for each of them an eigenvector the last two of these which involve the root two

01:36:25.480 --> 01:36:29.960
were uh more tricky just because there was more to keep track of more messy expressions

01:36:29.960 --> 01:36:37.080
but the basic maths is the same every time in this series of videos we'll talk about linear

01:36:37.080 --> 01:36:51.400
regression and least squares and the problem that we'll be solving is first in the most

01:36:51.400 --> 01:37:06.920
abstract setting if you're given a subspace w of r m and a vector let's call it b also in

01:37:06.920 --> 01:37:17.640
r m the question that we want to solve is which vector w in this subspace w is closest to the

01:37:17.640 --> 01:37:29.800
vector b now just intuitively if we take the orthogonal projection of b onto w let's call that

01:37:30.360 --> 01:37:37.720
p subscript capital w b so the projection of b onto the subspace w the orthogonal projection

01:37:38.920 --> 01:37:43.880
we suspect that that would minimize this distance and the distance so the distance that we're trying

01:37:43.880 --> 01:37:56.360
to minimize is b minus w minimize this over all w inside of this subspace w equivalently you can

01:37:56.360 --> 01:38:03.800
minimize the square of the distances and this is why this problem is called least squares because

01:38:03.800 --> 01:38:07.640
we're minimizing the squares of each of the components of these differences when you add

01:38:07.640 --> 01:38:19.240
them all up so that's the statement of the problem is to find w inside of w such that

01:38:19.880 --> 01:38:26.600
that the distance between w is minimized

01:38:31.320 --> 01:38:39.400
and it turns out that the solution to this problem is exactly w equals the projection

01:38:40.200 --> 01:38:45.560
of b onto w and i won't give a precise proof of this statement but we should at least get

01:38:45.560 --> 01:38:50.840
an intuition for why this is true looking at this picture i've already drawn the projection of

01:38:50.840 --> 01:39:00.680
b onto w and another arbitrary vector w now these three vectors form

01:39:03.240 --> 01:39:08.440
a right triangle so it looks a little bit skewed from this angle but if you turn this this way

01:39:09.000 --> 01:39:15.000
that triangle looks something like here's b here's the projection of b onto w

01:39:15.640 --> 01:39:22.280
and here's some arbitrary vector w in the subspace w these two vectors are in w

01:39:24.520 --> 01:39:31.640
and so this line connecting them is also in w the vector b is perpendicular to the subspace w

01:39:32.520 --> 01:39:41.400
and therefore this angle is a right angle here this is the hypotenuse of this triangle

01:39:41.400 --> 01:39:49.000
and it's the distance from b to w and this distance is the minimizing distance supposedly

01:39:49.640 --> 01:40:03.160
so that's just b minus the projection of b onto w so i i you know misused a little bit of notation

01:40:03.160 --> 01:40:08.360
here um i hope you understand that this w now is different from this one this is the actual solution

01:40:09.640 --> 01:40:15.960
and because this is a hypotenuse of this triangle we know that this distance is always going to be

01:40:15.960 --> 01:40:21.880
greater than or equal to either of these two distances no matter what w is this will always

01:40:21.880 --> 01:40:30.200
create a triangle a right triangle unless w equals this vector right here and in all other cases

01:40:30.200 --> 01:40:36.280
except this one this distance is always going to be strictly greater than this distance so what are

01:40:36.280 --> 01:40:50.200
some ways to compute this projection so one way is to actually find an orthonormal basis of w

01:40:51.880 --> 01:40:54.600
so given an orthonormal basis

01:40:57.960 --> 01:41:03.800
let's call it w1 up to wk let's say k is the dimension of w

01:41:06.760 --> 01:41:16.360
then the projection of b onto w is just take the dot product remember the dot product of

01:41:16.360 --> 01:41:24.600
b with any of these normal orthonormal vectors gives you the shadow of b onto that vector and

01:41:24.600 --> 01:41:32.280
then multiply again by that vector here to give you the shadow of b onto this line in that same

01:41:32.280 --> 01:41:38.360
direction so we take the dot product or the inner product i'll write the inner product with brackets

01:41:40.040 --> 01:41:47.160
of each of these vectors and then we'll multiply by that vector again so that we have a vector in

01:41:47.160 --> 01:41:53.000
the end and then sum up all of these different contributions from these different shadows

01:41:54.200 --> 01:42:00.360
so this is how you would compute the orthogonal projection of a vector onto a specific subspace

01:42:01.320 --> 01:42:07.800
you would need for instance an orthonormal basis for that subspace but sometimes you're not given

01:42:07.800 --> 01:42:13.640
an orthonormal basis so it might be difficult to compute it one thing you could do is you can choose

01:42:13.640 --> 01:42:19.240
any basis of w pick arbitrary vectors that are in w and once you find k of them and you know that

01:42:19.240 --> 01:42:25.160
they're linearly independent then you know that that forms a basis then in order to find an orthonormal

01:42:25.160 --> 01:42:30.760
basis you would apply the Gram-Schmidt procedure to obtain an orthonormal one but you know how

01:42:30.760 --> 01:42:35.160
difficult that is maybe you can do it for the first few vectors pretty easily but then after a while

01:42:35.160 --> 01:42:49.800
it gets pretty messy so we'll look at a special case of this problem where w happens to equal

01:42:49.800 --> 01:43:00.520
the column space of some m by n matrix where a is an m by m matrix m by n matrix

01:43:02.600 --> 01:43:06.040
so in other words you can think of a as a linear transformation

01:43:09.960 --> 01:43:12.440
from r n to r m

01:43:12.760 --> 01:43:22.920
and in this special case we'll find a very interesting solution to this problem in general

01:43:22.920 --> 01:43:28.520
when we look at this problem and we're given a vector b so now let's suppose that this subspace

01:43:28.520 --> 01:43:37.320
is the column space of a and we have some vector b that's not necessarily in the column space what

01:43:37.320 --> 01:43:52.600
this means is that the linear system ax equals b does not have a solution unless

01:43:55.000 --> 01:44:01.960
a is onto or more specifically or more precisely

01:44:07.400 --> 01:44:12.920
unless the vector b is in the column space of a

01:44:20.840 --> 01:44:24.920
but because this doesn't happen in general instead of trying to solve this system which

01:44:24.920 --> 01:44:31.160
might not have a solution we can solve an associated system instead that says okay I might not be able

01:44:31.160 --> 01:44:39.800
to find an x in our domain here that sort of maps to the vector b because it's impossible all x's

01:44:39.800 --> 01:44:46.520
get mapped to this subspace what instead we can try to find is project b onto this subspace

01:44:49.320 --> 01:44:56.040
and now this vector the projection of b onto that subspace is by definition inside the column

01:44:56.040 --> 01:45:02.280
space of a and therefore we can solve that associated system so we make a definition

01:45:04.120 --> 01:45:12.280
based on this idea that a least squares approximation

01:45:12.520 --> 01:45:25.720
to the linear system ax equals b is a solution

01:45:26.840 --> 01:45:35.000
to the associated linear system ax equals the projection onto the column space of a

01:45:35.640 --> 01:45:44.680
apply to our given vector b and it's this problem that we'll be focusing on solving

01:45:44.680 --> 01:45:51.160
in the next few videos let's first state a theorem that makes it a lot easier to compute

01:45:51.160 --> 01:45:55.160
the least square solution to a given problem in the special case that we mentioned at the

01:45:55.160 --> 01:46:03.400
end of the video in the in the last session so the theorem says given a linear transformation

01:46:05.400 --> 01:46:05.720
from

01:46:08.520 --> 01:46:18.600
r n to r m that's called a let me write it here and a vector b in the co-domain of this linear

01:46:18.600 --> 01:46:36.360
transformation a let's say x in the domain in the domain that's r n is a least squares

01:46:37.960 --> 01:46:46.200
approximation to ax equals b now this is using the definition that we had made before

01:46:46.200 --> 01:46:51.320
which remember was x is the least squares approximation to ax equals b if and only if

01:46:52.680 --> 01:47:02.040
ax equals the projection of b onto w where w is the column space of a if and only if

01:47:02.920 --> 01:47:20.920
x is a solution to the system a transpose ax equals a transpose b

01:47:22.600 --> 01:47:29.640
now we mentioned last time that so let me just say here w equals the column space of a throughout

01:47:29.640 --> 01:47:36.040
this entire discussion now we mentioned last time that if we have an orthonormal basis of w

01:47:36.760 --> 01:47:41.480
we can actually solve this problem relatively easily but in general we're not given an orthonormal

01:47:41.480 --> 01:47:49.720
basis of w so this formulation of the problem makes it much simpler to compute so i said it but i

01:47:49.720 --> 01:47:56.360
should also write this that this means the taking the transpose of this matrix and taking the

01:47:56.360 --> 01:48:02.040
transpose is easy you just swap the columns with the rows so this just gives you a new linear system

01:48:03.000 --> 01:48:07.800
and in general this is much much easier to solve than something like this and the reason this

01:48:07.800 --> 01:48:13.560
simplification occurs is because we've taken our subspace to be the column space of some matrix

01:48:15.560 --> 01:48:20.920
so before we give some examples of how to apply this theorem we'll give the proof if you want

01:48:20.920 --> 01:48:28.200
to skip the proof you can go to the next video so this is an if and only if proof so we'll prove

01:48:28.200 --> 01:48:39.320
it in two directions let's let's first suppose that x is a least squares suppose x is a least

01:48:39.400 --> 01:48:55.080
square solution to ax equals b i.e x solves ax equals a projection of b onto w

01:48:58.040 --> 01:49:03.720
now here's a little picture that'll help us visualize everything let's say this is the vector b

01:49:04.520 --> 01:49:15.000
this is the subspace w this is the projection of b onto w if we take the difference of b with

01:49:15.000 --> 01:49:25.320
the projection onto w so b minus the projection of b onto w then that difference is exactly this

01:49:26.040 --> 01:49:32.200
line that's orthogonal to w in other words this vector is in the orthogonal complement

01:49:34.680 --> 01:49:47.560
of w and because it's in the orthogonal complement of w we know that no matter which

01:49:47.560 --> 01:49:53.400
vector we take in this subspace let's call any vector here a and the reason we're going to call it

01:49:53.400 --> 01:50:04.200
a is because a is an element in the column space of of the matrix capital a then the dot product

01:50:04.200 --> 01:50:08.520
of a with any of these vectors i mean with this specific vector

01:50:11.320 --> 01:50:17.000
equals zero for all a in the column space of a

01:50:17.320 --> 01:50:23.080
in particular

01:50:29.160 --> 01:50:31.720
if we take the actual columns of a

01:50:34.280 --> 01:50:39.000
so a e i let's say and we dot this is the i-th column of a

01:50:39.880 --> 01:50:45.080
as a matrix and we dot it with

01:50:47.720 --> 01:50:56.200
this vector this is always going to equal zero for all i from and in this case since the domain

01:50:56.200 --> 01:51:07.160
of a is r n it's for all i going from one to n we can write this dot product using the transpose

01:51:07.160 --> 01:51:13.080
so remember the dot product is the the multiple you multiply each of the entries in the vectors

01:51:13.080 --> 01:51:17.800
and then you add them all up and the way you can express that is using the transpose of a particular

01:51:17.800 --> 01:51:24.120
vector if we write this as a column vector then we can write this as a row vector by taking the

01:51:24.120 --> 01:51:32.920
transpose and then matrix multiplying these entries so we would take a e i transpose

01:51:33.880 --> 01:51:47.640
times the vector b minus p w b equals zero for all i but this transpose the fact that

01:51:48.200 --> 01:51:55.640
um if we take if we look at this um column of a and we take its transpose and if this is true

01:51:55.640 --> 01:52:01.720
for all i then this is saying that this vector is the dot product of this vector with each

01:52:01.720 --> 01:52:11.400
of the transpose vectors from a dotted with this is zero therefore if we take the matrix a and transpose

01:52:11.400 --> 01:52:19.880
it and we multiply it matrix multiply it with this vector it will always equal zero

01:52:23.320 --> 01:52:29.560
and now rewrite this by moving everything over to one side we get a transpose times the vector b

01:52:30.280 --> 01:52:33.800
equals a transpose times this projection

01:52:36.680 --> 01:52:44.200
but by assumption this projection we know that x solves this equation so we know that this also

01:52:44.200 --> 01:52:53.560
equals a transpose ax and this shows that if x is the least square solution in other words if

01:52:53.560 --> 01:53:03.400
it solves this problem then a transpose a transpose a acting on x equals a transpose b so this proves

01:53:03.400 --> 01:53:10.200
the theorem in one direction to prove the theorem in the other direction

01:53:13.000 --> 01:53:16.680
i'm running out of space here but i can give you at least the sketch of this proof

01:53:17.560 --> 01:53:26.600
now suppose that um this equation is satisfied so suppose x is a solution

01:53:28.440 --> 01:53:34.440
to a transpose ax equals a transpose b

01:53:38.040 --> 01:53:42.760
we can move everything over again as we did sort of going backwards in this calculation

01:53:42.760 --> 01:53:49.640
and we can express this by saying that a transpose acting on ax minus b

01:53:50.680 --> 01:53:54.600
equals zero in other words this vector

01:53:56.840 --> 01:54:04.280
ax minus b is in the orthogonal complement of the column space of a so it's in the orthogonal

01:54:04.360 --> 01:54:16.760
complement of w now if we go back to our picture we know that the vector b can be uniquely decomposed

01:54:16.760 --> 01:54:24.360
as the sum of two vectors one a vector in w and one a vector in the orthogonal complement of w

01:54:25.000 --> 01:54:31.400
so this is a theorem um that you might cover uh in in the part of your linear algebra course on

01:54:31.960 --> 01:54:41.640
um when you talk when you discuss orthogonality so b has a unique decomposition

01:54:47.560 --> 01:54:54.840
into a vector in w plus a vector let's say in the orthogonal complement let's call it v

01:54:55.800 --> 01:55:04.280
where w is in w and v is in the orthogonal complement of w

01:55:06.600 --> 01:55:12.120
but this equation here says that if we take the difference ax minus b and we get in the

01:55:12.120 --> 01:55:23.000
orthogonal complement we know that this has to equal some vector so ax minus b equals a vector

01:55:23.000 --> 01:55:29.640
in this orthogonal complement let's just call it v for now because it's in the orthogonal complement

01:55:29.640 --> 01:55:40.120
rewriting this equation says that b must equal ax minus v

01:55:40.680 --> 01:55:53.480
and a where is ax ax is in the column space of a in other words it's already in w

01:55:55.000 --> 01:56:02.120
so this is the vector in w and therefore this vector right here has to be in the orthogonal

01:56:02.120 --> 01:56:09.080
complement and this uniqueness decomposition theorem tells us that this vector is exactly

01:56:10.040 --> 01:56:19.080
b minus ax so this looks this is going to look a little bit silly but b equals ax minus

01:56:21.560 --> 01:56:23.960
ax minus b

01:56:24.120 --> 01:56:32.920
and the uniqueness decomposition theorem tells us that this vector that's in the orthogonal

01:56:32.920 --> 01:56:42.120
complement must equal the projection of b onto that subspace w in other words ax this term right

01:56:42.120 --> 01:56:50.040
here has to equal the projection of b onto w minus this vector right here

01:56:54.280 --> 01:57:04.840
in other words ax equals the projection of w onto of b onto w and that means that x is

01:57:04.840 --> 01:57:09.960
a least square solution because it solves this equation so that follows from the uniqueness

01:57:09.960 --> 01:57:18.440
of orthogonal decomposition of a vector into two parts if you have a given subspace one

01:57:18.440 --> 01:57:23.640
into a vector in that subspace that's where this ax equals the projection of b onto w comes from

01:57:23.640 --> 01:57:28.360
and the other vector is just the orthogonal complement the projection onto the orthogonal

01:57:28.360 --> 01:57:33.320
complement which is just the difference of the vector itself minus that vector in the orthogonal

01:57:33.320 --> 01:57:40.040
subspace so this is the the proof of this theorem that allows us to say if we want to solve a least

01:57:40.040 --> 01:57:45.880
square solution problem when w equals the column space of a we merely have to solve this system

01:57:45.880 --> 01:57:50.360
so the next few videos will do lots of different examples of how to actually

01:57:51.400 --> 01:57:55.400
so the example that we'll be working out it's a quite a long example because of the

01:57:55.400 --> 01:58:02.040
generality that we'll do it in is if you're given data and let's say the data you're given

01:58:03.320 --> 01:58:09.400
is you have a bunch of x values and a bunch of y values so these are one dimensional input and

01:58:09.400 --> 01:58:18.600
one dimensional output values so suppose you have given data x1 y1 x2 y2 and so on up until

01:58:18.600 --> 01:58:29.240
the number of data points that you have x dyd and if you try to plot these data points let's say

01:58:29.240 --> 01:58:38.360
they look maybe something like this the question that you want to solve is can you try to find

01:58:39.080 --> 01:58:50.520
a line that sort of best approximates these data so that's the problem

01:58:53.880 --> 01:58:59.560
is to find a best fit whatever that means

01:59:02.200 --> 01:59:06.120
straight line let's say of the form

01:59:08.760 --> 01:59:16.120
y equals mx plus b now if we wanted to actually try to solve this problem

01:59:16.760 --> 01:59:21.480
and suppose that all of these points actually lied on this line we would want to solve this entire

01:59:21.480 --> 01:59:27.160
system now m and b are our unknowns we don't know the slope we don't know the y-intercept

01:59:27.160 --> 01:59:35.640
so we'd have y1 we want to set it equal to mx1 plus b similarly for y2 our second data point

01:59:36.200 --> 01:59:47.800
mx2 plus b and we keep going yd equals mxd plus b now in general this is an over constrained system

01:59:47.800 --> 01:59:52.280
because we have d equations and if d is relatively large in particular if it's bigger than two

01:59:53.080 --> 01:59:58.680
if it's relatively large it's very unlikely for us to find a solution to this problem

01:59:58.680 --> 02:00:07.560
we can rewrite this problem as a matrix equation by saying that we have the vector y

02:00:07.560 --> 02:00:14.120
which is the vector of our data points in fact let me even write y as a column vector

02:00:15.560 --> 02:00:20.120
so let's write it like y1 all the way to yd

02:00:21.000 --> 02:00:30.360
and if we notice this our coefficients are always being added in a linear fashion

02:00:30.360 --> 02:00:35.560
and the only thing that's changing is the value of x1 so you could actually write this

02:00:36.920 --> 02:00:45.720
as a d by 2 matrix acting on the vector mb now what should this matrix be

02:00:45.720 --> 02:00:52.680
we want it to satisfy the equation y1 equals mx1 so x1 has to go in this column

02:00:53.560 --> 02:01:00.440
plus b times what's the only thing that's going to leave b exactly where it is the number one

02:01:01.720 --> 02:01:07.640
and the same thing here if we had y2 we would want to write y2 equals m

02:01:08.600 --> 02:01:18.200
x2 plus one times b and so on all the way down to xd and one so this matrix equation

02:01:18.200 --> 02:01:24.600
which we can write as y vector equals a and i don't want to write x as we did before because

02:01:24.600 --> 02:01:30.840
i don't want to conflate it with the data points that are also labeled by x and so instead we'll

02:01:30.840 --> 02:01:39.080
write this as ax so this is the system that we would like to solve but we know that there is in

02:01:39.080 --> 02:01:46.760
general no solution to this problem so what can we do now in this case the column space of a

02:01:46.760 --> 02:01:56.600
happens to be a two-dimensional subspace of r what of rd so the column space of a is a two-dimensional

02:01:56.600 --> 02:02:02.680
subspace of rd so we can actually draw something like this although the space that's in is might

02:02:02.680 --> 02:02:09.080
be significantly larger and we have the vector y somewhere out here in general it's not in the

02:02:09.080 --> 02:02:13.480
column space in general this line does not go through every single one of these data points

02:02:14.200 --> 02:02:20.600
so we have some vector y and instead of trying to solve this specific equation which in general is

02:02:20.600 --> 02:02:29.880
unsolvable we can project y onto this subspace w and we can solve that associated system and then

02:02:29.880 --> 02:02:35.560
we'll say what that means in a moment in fact actually we can say what it means right now

02:02:35.560 --> 02:02:41.640
if we take the difference of these two vectors y minus this projection

02:02:42.040 --> 02:02:50.440
what are we minimizing so an arbitrary vector in this subspace let's write w as an arbitrary vector

02:02:50.440 --> 02:02:57.640
in the subspace is a linear combination of these columns so let's write that linear combination

02:02:57.640 --> 02:03:06.920
as m suggestively a e1 which is the first column of a which is just all of these x data points

02:03:07.000 --> 02:03:16.360
x data points plus b times the second column of a and we want to minimize the distance between our

02:03:16.360 --> 02:03:22.920
data set our data vector y with this vector so in other words if we take this difference

02:03:22.920 --> 02:03:27.720
let's let's replace this with w for now because let's imagine we don't yet know that this is the

02:03:27.720 --> 02:03:36.440
projection so this difference is trying to minimize y minus m a e1

02:03:40.040 --> 02:03:50.040
plus b a e2 and if we look at what each of these components give you then this equals

02:03:50.040 --> 02:03:56.520
let's square this just so we don't have to deal with square roots then this is the sum so first

02:03:56.520 --> 02:04:09.240
let's take an arbitrary ith component here it's yi minus m times xi plus b and that's it and then we

02:04:09.240 --> 02:04:16.520
take the sum of these squares because that's what this means and we sum over all i from one to d

02:04:17.240 --> 02:04:23.160
so we want to minimize this expression in other words we're taking our actual data set y and

02:04:23.240 --> 02:04:32.120
we're taking this which is our best fit curve using our data set x and so we're trying to minimize

02:04:32.120 --> 02:04:40.600
all of these distances so these are actually the vertical distances between the best fit curve

02:04:40.600 --> 02:04:46.120
and this line it's the vertical distances because this is seeing our y data point minus

02:04:47.080 --> 02:04:54.280
the value of this line at that point and we take that distance that difference which is this

02:04:54.280 --> 02:05:00.360
little vertical height we square that height and then we add up all of these heights and we want to

02:05:00.360 --> 02:05:05.720
minimize that expression so the solution to this least squares problem is graphically given by

02:05:06.360 --> 02:05:12.920
an expression like that and we know how to solve this to solve this we apply our previous theorem

02:05:17.080 --> 02:05:22.120
and we know that to solve this we can solve instead

02:05:24.360 --> 02:05:34.360
a transpose a equals a sorry a transpose a x equals a transpose oh and x is xi

02:05:35.480 --> 02:05:41.640
let me write this as xi and a transpose y so this is the problem that we want to solve

02:05:41.640 --> 02:05:49.000
and we want to solve this for xi and xi is our vector of unknowns so in order to do this we have

02:05:49.000 --> 02:05:53.720
to write down what a is we already know what a is we have to write down its transpose we have

02:05:53.720 --> 02:05:58.440
to multiply those two things there's a lot of things we have to calculate so let's do that

02:05:59.160 --> 02:06:06.360
on a fresh board space so i've written the problem setup and we have the matrix a with

02:06:06.440 --> 02:06:11.800
our data points for x and our vector y with y and i've taken the transpose and i've written it

02:06:11.800 --> 02:06:17.560
on the left because we'll be applying matrix multiplication to this side to solve for a transpose

02:06:17.560 --> 02:06:24.280
a and then we'll also matrix multiply a transpose with y so if we multiply these two matrices

02:06:26.520 --> 02:06:31.320
it's the first row here times the first take the dot product with this with this column

02:06:31.880 --> 02:06:40.040
and that's x1 squared plus x2 squared plus xd squared so the first top left entry is the sum

02:06:40.040 --> 02:06:43.480
of the squares of these entries from 1 to d

02:06:47.240 --> 02:06:54.760
and the second entry on the top is the first row times the second column of a and that's x1 times

02:06:54.840 --> 02:07:00.200
1 plus x2 times 1 in other words we're just summing up all of the different x values

02:07:03.720 --> 02:07:08.600
and on the bottom left it's this first this the second row here with the first column

02:07:08.600 --> 02:07:10.760
that's the same as it was in the top right

02:07:13.960 --> 02:07:20.600
and then the last entry on the bottom right is the second row with the second column and that's

02:07:20.600 --> 02:07:26.840
one times one plus one times one plus one times one d times which is just d itself

02:07:28.760 --> 02:07:36.520
so this is a transpose a and a transpose y equals first of all notice that it's just a

02:07:36.520 --> 02:07:42.360
two by two matrix so we're going to be solving a rather simple system it's just a two by two

02:07:42.360 --> 02:07:48.360
so a transpose y is now take the values of x multiply them with the values of y

02:07:49.000 --> 02:07:58.040
it's sum i equals one to d x i with y i this time and then it's the second row with this

02:07:58.040 --> 02:07:59.560
and that's just the sum of the y's

02:08:02.600 --> 02:08:08.920
and it's our vector with two components here and we want to solve this system

02:08:10.120 --> 02:08:16.440
now it's only a two by two so on the one hand we could probably set this up as a

02:08:16.920 --> 02:08:24.360
as a row reduction an augmented matrix problem row reduce and isolate whatever we need to so that

02:08:24.360 --> 02:08:33.560
we can solve for this vector c on the other hand it's only a two by two matrix and row reduction

02:08:33.560 --> 02:08:42.040
might be a little bit complicated for instance we might want to maybe divide this entry by

02:08:42.120 --> 02:08:47.160
the sum of the squares of all of the entries but maybe that's a problem if every single one of

02:08:47.160 --> 02:08:53.160
these is zero you know it's a little bit tricky so it's very convenient to first of all find out

02:08:53.960 --> 02:08:59.480
when this matrix is invertible and if this matrix is invertible we can multiply both

02:08:59.480 --> 02:09:09.160
sides by the inverse so if a transpose a inverse exists and we'll figure out what that means

02:09:09.240 --> 02:09:13.240
we'll compute the determinant of this to determine when this inverse actually exists

02:09:13.880 --> 02:09:19.960
then we can solve this system pretty easily and it's c which is again remember our vector of

02:09:19.960 --> 02:09:31.240
unknown coefficients m and b then this equals a transpose a inverse times this vector right here

02:09:32.200 --> 02:09:40.360
a transpose y which we've already computed so you know in terms of the setup it's relatively

02:09:40.360 --> 02:09:44.360
straightforward maybe calculating this actual inverse might be a little bit of a challenge

02:09:44.360 --> 02:09:50.760
because of the arbitrariness the generality that we're doing this in so first let's compute the

02:09:50.760 --> 02:09:58.600
determinant of this matrix and that's just this times this minus this times this now because

02:09:58.680 --> 02:10:05.400
we're multiplying these two sums we really have to be careful about the indices remember this is a

02:10:05.400 --> 02:10:12.680
sum of stuff multiplied by a sum of stuff so we can't just say that this is sum xi squared it's

02:10:12.680 --> 02:10:19.000
actually there's a lot of foiling going on and this is given by d the sum of the squares

02:10:21.160 --> 02:10:26.840
that's from the first term this times this minus this times this and in order in order to make that

02:10:26.920 --> 02:10:31.960
calculation a little bit more straightforward i'll rewrite one of the indices as a j instead of an

02:10:31.960 --> 02:10:38.600
i so that we don't get confused so this is xi times xj and each of these sums there's actually

02:10:38.600 --> 02:10:45.560
two sums here one for the index i and one for the index j and they both go from one to d so this

02:10:45.560 --> 02:10:54.520
is the determinant and i won't do the rest of this calculation out but this i'll make a claim

02:10:54.680 --> 02:11:06.440
and you should check this that this equals zero if and only if xi equals xj for all i and j

02:11:08.120 --> 02:11:13.720
so the only time that this determinant vanishes if all of the xi data points

02:11:14.280 --> 02:11:20.200
happen to be equal to each other now it takes a little bit of time to actually show that but you

02:11:20.200 --> 02:11:27.560
can do it and this is the only instance when this matrix is not invertible and if you're

02:11:27.560 --> 02:11:33.000
thinking about data this basically would mean that all of your data points lie along a vertical line

02:11:33.560 --> 02:11:39.080
and then it makes sense that you can't find a function of the form y equals mx plus b to fit this

02:11:39.720 --> 02:11:44.520
because the only line that'll work is a vertical line and in that case the slope is infinite so you

02:11:44.520 --> 02:11:50.520
won't find a solution so it makes a lot of sense why this is the only case where that happens

02:11:50.520 --> 02:11:56.600
otherwise if you have even a single point that's off of this line you will be able to find some curve

02:11:57.400 --> 02:12:03.080
that best approximates this data although you would think that maybe if all of these points

02:12:03.080 --> 02:12:09.480
lie here and there's a data point way out here then maybe this data point is there's something wrong

02:12:09.480 --> 02:12:15.880
with it or more investigation is needed such a point in this situation would be called an outlier

02:12:16.840 --> 02:12:21.080
and I may discuss about this at some point but that's not the focus of this specific

02:12:22.360 --> 02:12:28.200
video right now so that's the claim so this determinant vanishes if and only if

02:12:28.200 --> 02:12:31.240
all of these data points are equal so let's assume that this does not happen

02:12:31.640 --> 02:12:40.600
assume there exists an i and a j that's not equal an i and a j which they are not equal

02:12:40.600 --> 02:12:48.680
and such that xi is different from xj so we just need to assume that we have at least two data points

02:12:48.680 --> 02:12:57.480
that do not lie on um that are not the same when we make this assumption we can compute this inverse

02:13:01.320 --> 02:13:07.000
and this is easy because it's just two by two we maybe remember this formula we just divide by

02:13:07.000 --> 02:13:13.080
the determinant we swap these two entries and we negate these so this is just one over this

02:13:13.080 --> 02:13:18.760
determinant and i don't want to keep writing it so let me just write determinant of a transpose a

02:13:18.760 --> 02:13:25.480
and just remember that it equals this and then we swap these entries so this is d and here we have

02:13:25.480 --> 02:13:30.760
some and there's lots of indices now and i don't want to conflate any of these indices with each

02:13:30.760 --> 02:13:39.160
other so i'm now going to call these k or something so this is k equals one to d and this is x k

02:13:39.160 --> 02:13:53.000
squared and here we have minus some x k oops k goes from one to d and this is minus k from one

02:13:53.960 --> 02:13:57.480
to d and this here is the inverse of our matrix

02:14:00.120 --> 02:14:03.640
and then what we have to do is you have to take this complicated expression

02:14:03.640 --> 02:14:09.800
and multiply it by this vector and once we do that we'll find out what the values of m and b are

02:14:09.800 --> 02:14:16.200
so we'll need again a little bit more board space to do that so here i've rewritten our problem and

02:14:16.200 --> 02:14:22.520
remember we're trying to solve for the coefficients m and b for linear regression for an arbitrary

02:14:22.520 --> 02:14:29.400
data set and we computed that a transpose a as a matrix equals one over the determinant of that

02:14:29.400 --> 02:14:45.080
matrix which we found was d times that's a d times xi squared minus let's use the indices i and j here

02:14:45.080 --> 02:14:52.840
xi times xj so this is one over the determinant times our matrix which was

02:14:55.640 --> 02:14:58.840
to not conflate these indices let's call these indices k

02:14:59.640 --> 02:15:06.600
this was i believe d here for the inverse on the bottom right we had sum of the squares

02:15:07.320 --> 02:15:18.680
x k squared minus k x k i'll stop writing from one to d it's just getting a little bit annoying

02:15:18.680 --> 02:15:28.120
minus sum k x k but i'll always write the the subscript that we're summing over so this is

02:15:28.200 --> 02:15:31.880
a transpose a inverse now a transpose y

02:15:35.880 --> 02:15:42.040
well i can't remember if i wrote it but if you remember what a transpose looks like

02:15:42.840 --> 02:15:48.680
oh we computed a transpose y yeah now i remember but the thing is that we'll have to be careful

02:15:48.680 --> 02:15:54.440
about indices because i believe we use the indices i there as well and we've already used i we've

02:15:54.440 --> 02:16:03.480
already used j we've already used k so let me call them l so this was sum x l y l l goes from one to

02:16:03.480 --> 02:16:11.560
d and on the bottom part of this uh two component vector it was just the sum of the y's

02:16:14.440 --> 02:16:20.760
okay so all of this mess is the left hand side of this expression let's multiply these two matrices

02:16:20.760 --> 02:16:30.920
and see what we get um so let's just do that then we get and let's keep this determinant factor here

02:16:35.560 --> 02:16:40.120
and i'm writing all of this because you'll see that it relates to something you may have seen

02:16:40.680 --> 02:16:43.320
in a course on statistics or probability

02:16:44.200 --> 02:16:54.840
so then we multiply d by this and we multiply this by this i'm just going to do this all out

02:16:54.840 --> 02:17:03.560
d times this sum uh over it's just l one index x l y l minus this expression there's two sums

02:17:03.560 --> 02:17:12.200
here now k and l x k y l that's the first component of this vector and the second component

02:17:12.200 --> 02:17:17.880
is this times this now we have a bunch of stuff going on here um plus this times this so let me

02:17:17.880 --> 02:17:27.640
write the plus on the left this becomes sum over k and l and x k squared which we can write as x k

02:17:27.640 --> 02:17:36.040
you know let's just write it x k squared y l minus x k now this is a little bit different right because

02:17:36.120 --> 02:17:41.640
we have two sums k and l and this time it's not x k squared it's x k x l

02:17:44.040 --> 02:17:48.200
y l and this is what equals m b

02:17:52.360 --> 02:18:01.320
now so this actually solves the whole problem so we know that m equals this first expression here

02:18:01.320 --> 02:18:08.600
divided by this determinant and the y intercept equals this expression here divided by that determinant

02:18:10.760 --> 02:18:14.920
now does it equal anything um familiar if we look at m itself

02:18:18.440 --> 02:18:25.560
and we divide the numerator and the denominator by d we get that m equals

02:18:25.560 --> 02:18:32.280
sum over l x l y l minus

02:18:34.360 --> 02:18:42.760
one over d sum k and l x k y l divided by

02:18:43.480 --> 02:18:54.360
x i squared minus i j x i x j

02:18:57.320 --> 02:19:04.760
now each of these expressions um actually show up in statistics quite often and they're actually

02:19:04.760 --> 02:19:11.080
given special names we call the let's do the denominator first since this one's only involves

02:19:11.080 --> 02:19:18.200
a single data set this is called the variance of the data set x

02:19:20.760 --> 02:19:27.080
where x vector equals x one through x d and it's also written as var oops var of x

02:19:30.440 --> 02:19:36.600
and this just equals by definition the sum of the x i squares minus x i j

02:19:37.560 --> 02:19:44.440
x i x j so that's what the variance is by definition and the covariance

02:19:50.440 --> 02:19:57.560
um is involves two data sets our x's and our y's so it's of x and y

02:19:58.120 --> 02:20:01.800
and this is defined by

02:20:04.040 --> 02:20:07.480
i think you know people have different notation i don't know what the notation is i don't really

02:20:08.600 --> 02:20:19.800
care um but it's this expression on top so this is sum l x l y l minus one over d

02:20:19.800 --> 02:20:23.880
oh did i forget a one over d i did this should have a one over d here

02:20:27.640 --> 02:20:28.520
minus one over d

02:20:31.160 --> 02:20:40.680
x k y l that's an l subscript on that last y

02:20:43.560 --> 02:20:49.320
so we have that our linear regression problem actually derives for us the variance and the

02:20:49.320 --> 02:20:54.360
covariance of our data set and we also have explicit expressions if we wanted to

02:20:54.600 --> 02:21:01.560
um for the least squares uh solution if we want to fit data to a straight line curve

02:21:03.080 --> 02:21:10.520
in the next video we won't apply this general result because i don't think anybody would

02:21:10.520 --> 02:21:15.000
expect you to memorize something like this instead we'll set up the problem in an explicit example

02:21:15.560 --> 02:21:21.080
redo the whole procedure just so you get a feel for it with specific numbers involved and um

02:21:21.640 --> 02:21:25.160
and how you would actually compute the inverse without all of these sums or anything like that

02:21:25.160 --> 02:21:29.960
if you're just given a relatively small data set if you're given relatively large data sets

02:21:29.960 --> 02:21:34.280
then you might want to go through this approach or you might have to program something that does it

02:21:34.280 --> 02:21:43.800
for you so let's actually do an explicit example using actual numbers um here's a a graph and here's

02:21:43.800 --> 02:21:53.720
some data points um the x axis is the horizontal axis and the y axis is the vertical one and let's

02:21:53.720 --> 02:22:01.000
just use a unit grid so that the distance between any two of these grid lines has length one so the

02:22:01.000 --> 02:22:09.400
data that we're given uh according to this plot is um we have our data vector and we want to try

02:22:09.400 --> 02:22:17.400
to fit to a line of the form y equals mx plus b so let's write down our matrix a and our matrix a

02:22:17.400 --> 02:22:26.120
remember consists of all of the x's if we write it in this form and ones all along the right column

02:22:26.120 --> 02:22:32.920
so how many data points do we have so what's d one two three four five six seven three four five

02:22:32.920 --> 02:22:41.080
six seven so you should have seven um entries in this column in the columns of a and let's go

02:22:41.080 --> 02:22:46.360
in order from left to right filling in all of these entries the order that you go in doesn't

02:22:46.360 --> 02:22:51.240
really matter as long as you're consistent with the value with the corresponding values of y that

02:22:51.240 --> 02:22:59.800
you use so in this case the first value of x is at x equals negative four negative three negative

02:22:59.800 --> 02:23:05.880
one zero one three four i've chosen it to be somewhat symmetric just for convenience of the

02:23:06.760 --> 02:23:15.320
computation so it's negative four negative three negative one zero and the x values positive x

02:23:15.320 --> 02:23:21.640
values are one three and four so this is the matrix a and the vector y

02:23:22.200 --> 02:23:32.360
is the corresponding values of y so for x equals negative four the value of y is at negative one

02:23:34.200 --> 02:23:40.440
again there are d there are d entries here as well the next one is zero then it's one zero one

02:23:42.760 --> 02:23:45.480
and the last one the last two are two and four

02:23:46.360 --> 02:23:50.760
so this is all of the information that we need

02:23:53.320 --> 02:23:55.080
and if we compute a transpose a

02:23:57.720 --> 02:24:02.600
what do we get so i won't write out a transpose just take the transpose of this

02:24:03.240 --> 02:24:07.240
then we know that we're taking the dot product of this vector with itself to get the top left

02:24:07.240 --> 02:24:13.400
entry here so what's the dot product of this with itself it's four squared times two so it's

02:24:13.400 --> 02:24:22.200
16 times two which is 32 nine plus nine which is 18 so 32 plus 18 which is 50 plus two

02:24:23.240 --> 02:24:30.920
so it's 52 on the top left the dot product of this with this is zero because all the negatives

02:24:30.920 --> 02:24:35.880
cancel out all of the positive entries again i chose that specifically so that this happens

02:24:35.880 --> 02:24:40.760
so that computing the inverse is much easier and we can immediately solve this system

02:24:41.160 --> 02:24:50.200
now a transpose acting on y oh sorry the bottom entry is um is is just d itself and d is seven

02:24:51.480 --> 02:24:52.760
now a transpose y

02:24:55.720 --> 02:25:01.160
is this times this plus so negative four times negative one plus negative three times zero

02:25:01.160 --> 02:25:06.040
plus negative one times one and so on so negative four with negative one gives you four

02:25:07.000 --> 02:25:12.280
that with zero doesn't change anything so we still have four then that's negative one from four so

02:25:12.280 --> 02:25:20.440
that gives us three leftover this one brings it back up to four then this six brings it up to 10

02:25:21.000 --> 02:25:24.520
and this is 16 so we get 26 in the first entry

02:25:28.520 --> 02:25:30.520
maybe you have faster ways of doing this i don't know

02:25:31.400 --> 02:25:37.080
um so then uh a transpose if we take the second row here of a transpose

02:25:37.720 --> 02:25:43.320
which is this column of ones and we dot it with this these cancel these add so we get seven

02:25:45.880 --> 02:25:54.840
now solving this system is pretty straightforward um right this is 52007 in one side 267 we just

02:25:54.840 --> 02:26:01.560
have to divide everything by 50 the first row by 52 the second row by seven and we immediately arrive

02:26:01.560 --> 02:26:14.920
at the vector mb our vector of unknowns is one half and one so this tells us that the best fit

02:26:14.920 --> 02:26:22.200
approximation that minimizes the vertical distance squared between between that line

02:26:23.000 --> 02:26:30.280
and all of these data points has slope one half and y intercept one so the line that we

02:26:30.280 --> 02:26:36.360
want to fit this to is one half x plus one and if we try to sketch what that graph looks like

02:26:36.360 --> 02:26:39.720
we know that it goes through one so let's include that point here

02:26:42.360 --> 02:26:48.120
and it has slope one half so when it gets to this when it moves two units over it moves one

02:26:48.120 --> 02:26:54.200
unit up so here's the next data point we connect these two with a straight line and moving over

02:26:54.200 --> 02:26:59.400
two units to the right one unit up we connect that with a straight line and we keep doing this

02:26:59.400 --> 02:27:04.280
i mean this is how i draw um if i don't have um a ruler or anything on hand

02:27:06.120 --> 02:27:07.720
i would try to draw something like this

02:27:11.720 --> 02:27:16.840
so this straight line here if you notice it happens to actually go through one of the data points

02:27:17.800 --> 02:27:23.080
that might not happen but as you can see it doesn't go through most of them but it's a pretty

02:27:23.080 --> 02:27:29.880
reasonable approximation to this data set so this is how you would actually solve a least squares

02:27:29.880 --> 02:27:37.480
problem specifically in the context of a fitting data to a linear curve or rather an affine curve

02:27:37.480 --> 02:27:44.840
to be technically correct and this is how you do it in such an example in the next few videos

02:27:44.840 --> 02:27:49.960
we're going to generalize the idea of linear regression just in terms of a straight line

02:27:49.960 --> 02:27:56.760
data fitting to linear regression in the sense that you can data fit your data to sort of any

02:27:56.760 --> 02:28:02.760
curve almost any curve and the way that we're going to do this is we're going to set up

02:28:04.280 --> 02:28:13.000
some notation and we're going to let f1 through fk be linearly independent

02:28:15.720 --> 02:28:19.800
functions

02:28:23.320 --> 02:28:28.120
and what i mean by this is it's the same definition of linear independence of vectors

02:28:28.120 --> 02:28:34.440
namely that um there does not exist a set of numbers a1 through ak such that when you sum up

02:28:35.160 --> 02:28:39.880
um so let me just say this i.e there does not exist

02:28:46.040 --> 02:28:50.040
a set of numbers a1 through ak

02:28:52.920 --> 02:28:57.160
so these are real numbers or complex if these are complex valued functions

02:28:57.240 --> 02:29:06.040
such that the sum of ai fi equals zero as a function

02:29:09.880 --> 02:29:15.320
so um let's just say the domain of our function is whatever we need to specify it to be for

02:29:15.320 --> 02:29:22.280
example the the whole real line or maybe an interval or something like that so and imagine your given

02:29:22.280 --> 02:29:32.120
data points and let's say the given data points again we're going to use our x and y variables

02:29:32.120 --> 02:29:39.160
so your input is x and your output is y and you have a whole list of data x1 x2

02:29:40.920 --> 02:29:43.880
up to xd where d is the number of data points

02:29:44.840 --> 02:29:52.760
and you want to fit these points to these functions so in other words your hope

02:29:54.760 --> 02:30:08.280
is to somehow fit y1 equals to a1 f1 of x1 plus dot dot dot ak f

02:30:08.280 --> 02:30:12.360
k x1

02:30:14.760 --> 02:30:19.000
and not only do you want this but you also want this to hold for all of your data points

02:30:19.000 --> 02:30:35.960
so up to yd a1 f1 xd now plus dot dot dot ak fk xd so this is your hope but if d

02:30:35.960 --> 02:30:43.160
is much much greater than k then this is unlikely

02:30:50.440 --> 02:30:54.600
it's usually impossible to find coefficients that fit all of these data

02:30:57.640 --> 02:31:04.360
so before moving on let's try to rewrite this expression in a linear way so that we can relate

02:31:04.360 --> 02:31:11.720
it to the linear regression problem we solved earlier so set y to be this vector here so let's

02:31:11.720 --> 02:31:20.600
call this the vector y and what you notice here is that each of these numbers so f1 x1 is a specific

02:31:20.600 --> 02:31:25.640
number we're taking a linear combination of these numbers with coefficients coming from the a's

02:31:26.280 --> 02:31:36.440
so this looks like the vector y1 down to yd this is what this equation is represented by

02:31:36.440 --> 02:31:46.280
a matrix whose entries are given by these values of f so f1 x1 in the first column and up to yd

02:31:46.280 --> 02:31:57.000
the coefficient front of a1 is f1 xd and then this goes up to fk still x1 so x1 is the first row

02:31:57.800 --> 02:32:10.200
and down to fk xd in the last row and this matrix is applied to the vector of unknowns a1 through ak

02:32:11.160 --> 02:32:21.400
so this is again of the form y equals a and let's call it xc instead of x to not confuse ourselves

02:32:21.400 --> 02:32:26.440
with the variable x that we've used for our data so in general it's impossible to solve this

02:32:28.760 --> 02:32:37.080
and the way that we would like to solve this is again a least square solution so a least squares

02:32:40.440 --> 02:32:42.280
solution or approximation to

02:32:45.720 --> 02:32:50.680
this is a actual solution to

02:32:54.520 --> 02:33:04.520
a transpose y equals a transpose ax so just apply a transpose on the left on both sides

02:33:04.680 --> 02:33:11.000
and this is generally what we're going to solve for and this will be our this will be fitting our

02:33:11.560 --> 02:33:18.200
data to the set of functions defined by these but there are a few restrictions that have to be made

02:33:18.840 --> 02:33:24.600
for example the first maybe obvious restriction if you think about it is that these coefficients

02:33:24.600 --> 02:33:30.600
should be independent and independent in the sense that I can't take any one of these coefficients

02:33:30.600 --> 02:33:35.000
and sort of re-express it in terms of the others I'm not talking about linear independence I'm just

02:33:35.000 --> 02:33:46.840
talking about independence so we assume the coefficients are independent and this just means

02:33:47.640 --> 02:33:50.360
i.e. there does not exist an i

02:33:56.760 --> 02:34:01.400
from one through k such that

02:34:04.440 --> 02:34:06.440
a i is determined by

02:34:06.920 --> 02:34:18.440
a j by all the other a j's so let's just say the set of a j's where j is now

02:34:19.560 --> 02:34:26.040
from one excluding i so I read a little hat over that to exclude i up to k so in other words in

02:34:26.040 --> 02:34:31.240
terms of all of the other coefficients so we assume that they're independent and this is sort

02:34:31.320 --> 02:34:36.200
of obvious right because if you wanted to fit your data to these functions and you assume that these

02:34:36.200 --> 02:34:41.320
were all unknown coefficients and you wanted to find the best value for them then if you

02:34:41.320 --> 02:34:46.120
suddenly did that arbitrarily then it's unlikely that this relationship between them holds

02:34:47.080 --> 02:34:51.800
in that situation so in general we definitely want to make sure these coefficients are independent

02:34:52.440 --> 02:34:57.480
not only that we also should assume that the functions are linearly independent so

02:34:58.440 --> 02:35:05.400
we assume that these functions are independent

02:35:08.600 --> 02:35:10.600
as well and this is because

02:35:14.840 --> 02:35:22.680
so suppose that one of these actually depended on the other so because if let's say

02:35:22.680 --> 02:35:31.960
f i equal to some linear combination of the other ones so let's say bj fj so j goes from

02:35:31.960 --> 02:35:37.880
one to k but j is not equal to i so we're just saying like for these to be linearly independent

02:35:37.880 --> 02:35:43.000
another way is saying that well at least um none of them can be expressed in terms of the other so

02:35:43.000 --> 02:35:48.040
if that fails at least one of them can be expressed in terms of the others so because if for some

02:35:48.440 --> 02:35:50.440
numbers bj

02:35:53.880 --> 02:35:58.760
then what happens is expressions so then if we take

02:36:02.360 --> 02:36:07.640
so then if we take f and we take its linear combinations so let's say

02:36:08.600 --> 02:36:14.760
a i sorry let me not use the index i let me use the index j now so let's take some of a j

02:36:18.280 --> 02:36:24.200
fj and this breaks up into two parts now right because we have a sum over j where j is not equal to i

02:36:27.000 --> 02:36:35.800
so this is j um not equal to i and the sum goes from one to k so this is a j fj but then we also

02:36:35.800 --> 02:36:46.280
have plus a i f i but this term equals this so this equals sum over all j not equal to i

02:36:46.920 --> 02:36:55.080
another sum over all j that are not equal to i so we have a i sorry a j i'm just copying

02:36:55.080 --> 02:37:09.400
this term fj plus a i times this so a i times bj fj and then this is all in parentheses

02:37:09.480 --> 02:37:16.760
and now you notice that fj is a common factor so when you factor that out you get sum j not

02:37:16.760 --> 02:37:28.440
equal to i and then this is a j plus a i bj fj so now what we've done is we've re-expressed

02:37:28.440 --> 02:37:33.400
our linear combination of these functions so the way everything that's on the right hand side here

02:37:33.400 --> 02:37:41.080
in particular and we've re-expressed it in terms of functions in terms of k minus one functions

02:37:41.800 --> 02:37:46.200
and now our coefficients have changed so in other words there was already a dependence on

02:37:46.200 --> 02:37:51.880
the coefficients in some sense and so we usually demand that the functions are linearly independent

02:37:51.880 --> 02:38:01.480
so that we avoid this issue in the next video we'll explain more generally a simple situation

02:38:01.480 --> 02:38:07.640
that occurs in which this function this linear system is always um solvable by the method that

02:38:07.640 --> 02:38:15.800
we used earlier namely by taking a transpose a inverse let's now understand when we can solve

02:38:16.360 --> 02:38:24.920
a transpose y equals a transpose a c using the method of taking the inverse of a transpose a

02:38:25.480 --> 02:38:27.320
now in order to take the inverse of this

02:38:33.320 --> 02:38:39.000
we know that we need to require that the kernel of this matrix so by the way if a is a

02:38:40.600 --> 02:38:49.560
is a d by k matrix and again d is typically much much larger than k then we want to know when this

02:38:49.640 --> 02:38:53.480
exists so one of the situations when this exists is when

02:38:56.600 --> 02:39:03.480
the kernel of this matrix vanishes that's one of the criteria

02:39:06.840 --> 02:39:12.600
so zero as a vector space as a vector subspace um of r k

02:39:13.240 --> 02:39:21.800
so when does something like this happen so to understand when we can apply this method

02:39:24.600 --> 02:39:32.520
let's suppose that this is the matrix a a goes from r k this is r d here and this here

02:39:33.720 --> 02:39:34.680
is the image of a

02:39:35.080 --> 02:39:43.000
if we take the orthogonal complement of this image in this case you know unfortunately i

02:39:43.000 --> 02:39:47.560
can only draw the orthogonal complement as having a single dimension but you could imagine that it

02:39:47.560 --> 02:39:56.040
has um a much much larger dimension especially if these much much larger than k so the first

02:39:56.040 --> 02:40:06.680
claim that will prove is that the orthogonal complement of the image of a

02:40:09.720 --> 02:40:15.560
equals the kernel now in order for this to make sense i need to take the kernel of some matrix

02:40:15.560 --> 02:40:22.680
now the image of a is in r d its orthogonal complement is also in r d and i can't take the

02:40:22.680 --> 02:40:26.680
kernel of a because that wouldn't make sense the kernel would live here so i have to take

02:40:27.320 --> 02:40:31.560
the only other thing i can take the kernel of is maybe the kernel of a transpose

02:40:31.560 --> 02:40:36.600
so we'll do that so we'll take the kernel of a transpose and it turns out that these two are

02:40:36.600 --> 02:40:48.200
equal so how do we see this let's visualize a as a um as a matrix of vectors so a one through a k

02:40:48.200 --> 02:40:55.320
and when we take the transpose these rows these columns just become the rows

02:40:56.360 --> 02:41:01.480
so we'll do this proof just by showing that one is contained in the other just to make it very

02:41:01.480 --> 02:41:12.600
explicit so suppose that the vector v is let's start with the um let's start with being an element

02:41:12.600 --> 02:41:21.000
in the orthogonal complement so let's say v is perpendicular to a the um the image of a

02:41:24.680 --> 02:41:29.800
and then let's see if it's in the kernel of a transpose so when we take a transpose applied

02:41:29.800 --> 02:41:35.800
to v what do we get so we'll write the matrix a transpose now we take these columns and turn them

02:41:35.800 --> 02:41:48.760
into rows and we apply it to the vector v but matrix multiplication tells us that when we do this

02:41:48.760 --> 02:41:55.160
we take this row multiply it by this vector in other words we take the dot product so this equals

02:41:55.800 --> 02:42:06.920
another vector and it's a it's a vector in r k and what we get is a one dot product with v

02:42:08.200 --> 02:42:16.360
as the first entry all the way down to ak dot product with v but if v is in the orthogonal

02:42:16.360 --> 02:42:21.960
complement of a then it has to be that all of these dot products are zero so this is actually

02:42:21.960 --> 02:42:32.840
the zero vector and therefore therefore the um this containment holds the image of the orthogonal

02:42:32.840 --> 02:42:38.040
complement of the image of a is in the kernel of a transpose so that shows half of the theorem

02:42:40.360 --> 02:42:42.600
now let's suppose so conversely

02:42:43.240 --> 02:42:51.400
suppose that the vector u is in the kernel of a transpose

02:42:54.920 --> 02:42:58.520
then by the same argument being in the kernel of a transpose

02:42:59.080 --> 02:43:12.840
a transpose u equals zero but a transpose u is a one dot u all the way down to ak dot u

02:43:13.640 --> 02:43:20.120
but the zero vector says that all of those are zero and because the image of a is spanned by

02:43:20.200 --> 02:43:31.240
the vectors a one through ak we know automatically by the same exact argument that u is perpendicular

02:43:31.240 --> 02:43:37.320
to the image of a so it's almost the same argument which is why i'm not writing it and therefore

02:43:40.680 --> 02:43:45.560
this containment holds and that's the other half of the theorem so that's the proof that

02:43:46.520 --> 02:43:51.000
the kernel of a transpose equals the orthogonal complement of the image of a

02:43:52.920 --> 02:43:53.880
why is this useful

02:43:57.560 --> 02:44:00.040
it's useful for the following very important reason

02:44:03.160 --> 02:44:12.280
and it says that the kernel of a equals the kernel of a transpose a

02:44:13.240 --> 02:44:18.760
you can already see why this is going to be useful because instead of looking at the kernel of a

02:44:18.760 --> 02:44:23.560
transpose a which we take two matrices multiply them it's going to be a little bit more difficult

02:44:23.560 --> 02:44:28.040
matrix to work with if we could just look at the kernel of a that would probably save us some time

02:44:30.200 --> 02:44:36.120
so let's prove this in one direction it's pretty obvious but i'll write it out anyway

02:44:36.120 --> 02:44:39.560
so let's first prove the direction that the kernel of a is inside here

02:44:40.200 --> 02:44:47.080
so let's prove on this containment so if u satisfies

02:44:50.200 --> 02:45:00.120
a u equals zero then a transpose a u because this thing is zero also equals zero

02:45:01.640 --> 02:45:06.440
so that direction is pretty straightforward let's look at the other containment

02:45:06.600 --> 02:45:11.320
so suppose v satisfies

02:45:15.720 --> 02:45:25.800
a transpose a v equals zero then what this means is that a v is in the kernel of a transpose

02:45:26.040 --> 02:45:37.960
i.e. a v is in the kernel of a transpose but by the previous claim the kernel of a transpose

02:45:38.680 --> 02:45:43.800
equals the image of a taking the orthogonal complement of the image of a

02:45:47.480 --> 02:45:53.320
so what's the picture here actually let's go back right here so we have that a v which by the way

02:45:53.320 --> 02:46:00.040
is in this plane also is contained in the orthogonal complement of that image

02:46:00.680 --> 02:46:07.480
and the only vector that's contained both in a and in the orthogonal complement is the zero vector

02:46:09.880 --> 02:46:16.520
this implies that a v equals the zero vector in other words v is in the kernel of a

02:46:16.760 --> 02:46:26.520
and now the containment has been shown in both directions and that's the conclusion of the proof

02:46:27.480 --> 02:46:31.240
and let me just write out the final corollary which is the useful one for us

02:46:33.480 --> 02:46:34.680
it's like corollary two

02:46:34.680 --> 02:46:48.280
is that at least so let's say a transpose how do I say this a transpose a inverse exists

02:46:50.040 --> 02:46:58.600
if and only if the kernel of a is trivial so it's only the zero vector now

02:46:59.000 --> 02:47:10.440
why is this reasonable so this is this isn't really an example it's sort of an idea for why

02:47:10.440 --> 02:47:17.640
this is uh this usually occurs when you're trying to fit data so our matrix a is typically going

02:47:17.640 --> 02:47:29.080
to be of the form f 1 x 1 dot dot dot f um what was it x k f k x 1 all the way down to f 1 x d

02:47:30.920 --> 02:47:36.600
f k x d so typically our matrix a looks something like this

02:47:39.320 --> 02:47:45.240
and what would it mean for this to have trivial kernel it would say that none of these so all

02:47:45.240 --> 02:47:50.200
of these vectors are linearly the set of these vectors the column vectors are linearly independent

02:47:50.840 --> 02:47:59.880
is that likely so when when might something like that happen so for instance if one of these functions

02:48:01.240 --> 02:48:07.400
did depend on the others in a linear way so for instance in the last video we said that

02:48:07.400 --> 02:48:11.800
we assume that these functions were linearly independent if they were dependent what could

02:48:11.800 --> 02:48:16.360
happen one of these column vectors could be expressed as a linear combination of the others

02:48:17.000 --> 02:48:22.600
and therefore these columns would be linearly dependent and if these are dependent then this

02:48:22.600 --> 02:48:28.680
has a non-trivial kernel so that's at least the sufficient that's at least one condition

02:48:28.680 --> 02:48:37.240
that's a necessary condition for this to have um a non-trivial kernel so we demand that these

02:48:37.240 --> 02:48:42.040
functions are linearly independent but furthermore not only do we ask that these functions are

02:48:42.040 --> 02:48:47.080
linearly independent but it also implies that these specific vectors after we apply our data are

02:48:47.080 --> 02:48:53.640
linearly independent but if d is much much much larger than k we only have very few of these

02:48:53.640 --> 02:49:01.400
vectors right so the number of entries is d but we only have k vectors so it's kind of easy if you

02:49:01.400 --> 02:49:06.920
randomly chose if you arbitrary and randomly chose k vectors in a very large dimensional space

02:49:07.560 --> 02:49:13.640
randomly with almost almost surely it will be that those vectors are linearly independent

02:49:13.640 --> 02:49:22.920
think about it just choose random numbers so for example let's write pi e 1 2 square root of 3 3

02:49:22.920 --> 02:49:33.400
and the vector 1 1 1 i'm pretty sure that these three vectors are linearly independent in r3 and

02:49:33.400 --> 02:49:39.000
i randomly chose them so even if d is not drastically larger than k but even if it's just

02:49:39.000 --> 02:49:45.000
greater than k almost surely you'll pick linearly independent vectors so if your data is sufficiently

02:49:45.000 --> 02:49:50.040
you know distributed well and it's not lying exactly on one line or something like that then

02:49:50.040 --> 02:49:58.120
chances are these vectors are linearly independent so that's where it's going to be useful and in

02:49:58.120 --> 02:50:03.480
the next video we'll actually apply this to a simple example that you probably don't need a calculator

02:50:03.480 --> 02:50:09.720
to compute with in the next few videos we're going to be working with arithmetic modular two

02:50:10.920 --> 02:50:17.960
so we're going to deal with all even numbers are equal to zero and all odd numbers are equal to one

02:50:18.520 --> 02:50:25.320
so for instance two times three is six which is an even number so zero and seven plus three

02:50:25.320 --> 02:50:31.480
is ten which is also even which is zero for another example is negative three equals one

02:50:31.480 --> 02:50:36.920
in this case so anytime we do arithmetic for the most part when we add we're only going to be

02:50:36.920 --> 02:50:43.000
caring about the parity of that number and this is going to be there are multiple reasons for this

02:50:43.000 --> 02:50:48.280
one of which is simplicity the other of which is is that it's related to computer science

02:50:49.720 --> 02:50:58.440
so we're going to let z mod two be exactly those numbers and with the arithmetic that I just said

02:50:58.440 --> 02:51:03.640
so zero plus zero zero zero plus one is one one plus one is two which is zero and then

02:51:03.640 --> 02:51:10.360
multiplication similarly zero times one is zero and one times one is one and we'll also work with

02:51:10.360 --> 02:51:20.840
vectors whose entries are elements of z mod two so these are going to be vectors of the form x one

02:51:20.840 --> 02:51:24.360
all the way up to x n where x one through x n

02:51:27.480 --> 02:51:34.600
are in z mod two and we can also do arithmetic the way we usually do with vectors with vectors of

02:51:34.600 --> 02:51:41.240
this sort by just adding component wise and scalar multiplication on each components as well

02:51:43.400 --> 02:51:51.720
the interesting thing about this vector space is that unlike the vector space r to the n this

02:51:51.720 --> 02:51:57.560
has finitely many vectors so how many vectors does this vector space have well first of all here

02:51:57.560 --> 02:52:07.400
there are two elements and if you have n component vectors think how many entries think what possibilities

02:52:07.400 --> 02:52:11.880
you can put in the first entry you can either put a zero or a one and as soon as you move to the next

02:52:11.880 --> 02:52:17.960
entry you can also put a zero or a one and therefore each time you go through these entries you have

02:52:18.600 --> 02:52:29.880
two to the n total possibilities so the number of vectors in z mod two to the n is two to the n

02:52:30.680 --> 02:52:37.720
and one of those vectors is very special namely the zero vector and the non-zero vectors well

02:52:37.800 --> 02:52:39.400
there's just one less of them

02:52:44.760 --> 02:52:49.640
and i know that sounds like a trivial thing to point out but it'll actually be important

02:52:49.640 --> 02:52:58.040
in our discussion and so for example this is the main example that we'll be working with

02:52:59.000 --> 02:53:03.160
z mod two to the third power has seven non-zero vectors

02:53:06.600 --> 02:53:13.800
for example so let's make a definition first first we're going to be exploring a lot of

02:53:13.800 --> 02:53:19.720
mathematical curiosities and then we'll see how they apply to an actual physical situation

02:53:20.600 --> 02:53:24.680
and i rather you have a little bit of suspense before we get there so first we're going to do

02:53:24.680 --> 02:53:29.720
some math and then we'll talk about the applications so a hamming matrix

02:53:34.840 --> 02:53:37.080
is a matrix h

02:53:37.480 --> 02:53:48.440
with k rows and the columns

02:53:50.840 --> 02:53:55.720
of h consist of all

02:53:59.000 --> 02:54:00.520
the non-zero vectors

02:54:00.920 --> 02:54:12.840
in z mod two to the kth power so k here is a non negative integer in fact let's just

02:54:13.640 --> 02:54:24.120
yes suppose it's a positive integer so for example when k is three we have seven non-zero

02:54:24.120 --> 02:54:29.400
vectors and what this is telling us all right now let's try to understand these two matrices a

02:54:29.400 --> 02:54:36.760
little bit more the matrices m and h that we introduced earlier so recall that h was the matrix

02:54:36.760 --> 02:54:43.720
it was the identity matrix a three by three in this case and another matrix q and m

02:54:45.880 --> 02:54:51.320
was q and then the identity four by four matrix and both of these numbers can be generalized

02:54:51.320 --> 02:54:57.000
as long as it's an appropriate size and it satisfies the requirements that we made earlier

02:54:57.000 --> 02:55:02.520
namely that h consists of all of the non-zero vectors in the vector space

02:55:04.040 --> 02:55:08.600
z mod two to the power where the power is determined by the number of rows here

02:55:10.200 --> 02:55:14.200
so given the setup let's introduce a little bit more notation

02:55:15.160 --> 02:55:21.080
and that notation is going to be we're going to define these that subspace which was the

02:55:21.080 --> 02:55:28.440
kernel of h and also the image of m so let's call these image of m which is also the kernel of m

02:55:30.040 --> 02:55:39.320
kernel of h rather let's denote this by c so for the rest of these videos c will refer to exactly

02:55:39.320 --> 02:55:46.600
that subspace now remember this is a four-dimensional subspace inside of z mod two to the seventh

02:55:47.560 --> 02:55:50.600
okay we're also going to introduce other notation

02:55:52.280 --> 02:56:02.520
let's see subscript i be that subspace shifted by the i-th unit vector in z mod two so it's

02:56:02.520 --> 02:56:10.680
going to be c plus e i and this just means by definition the set of all vectors of the form

02:56:10.680 --> 02:56:19.320
v plus e i where v is in c

02:56:21.720 --> 02:56:27.400
now this is not a subspace right because we can't add two vectors and stay within the subspace

02:56:28.280 --> 02:56:34.520
yes stay within the subset but at the very least you can think of this as the subspace

02:56:34.520 --> 02:56:37.480
shifted by some vector and we can define this for all i

02:56:40.840 --> 02:56:45.720
between one and seven because that's how many non-zero vectors there are

02:56:45.720 --> 02:56:53.320
in sorry that's that's that gives us a basis of vectors in z mod two to the seventh power

02:56:54.120 --> 02:57:03.480
and now let's write some additional facts regarding these subs these subsets

02:57:08.200 --> 02:57:15.400
so the first thing is that we already know that c is the solution set of a homogeneous system

02:57:15.400 --> 02:57:21.400
namely it's the kernel of h ci is also the solution set of some system though it's no

02:57:21.400 --> 02:57:34.680
longer homogeneous ci is the solution set of the inhomogeneous system h x equals h e i

02:57:37.160 --> 02:57:48.600
where this is this whole thing h e i is the i-th column of h

02:57:51.560 --> 02:57:53.240
secondly

02:57:56.680 --> 02:58:06.360
if we take any two of these different subsets ci and cj then ci intersect cj so if we look at all

02:58:06.360 --> 02:58:12.360
of the vectors that are common to both of them it turns out there are none so it's the empty set

02:58:13.080 --> 02:58:15.800
for all i not equal to j

02:58:16.600 --> 02:58:20.600
third

02:58:23.560 --> 02:58:30.360
each of these subsets are also disjoint from the solution set of the homogeneous system

02:58:31.080 --> 02:58:35.800
so c intersect ci is also empty for all i

02:58:36.760 --> 02:58:45.160
and finally and this is maybe the most interesting part of it is that

02:58:47.640 --> 02:58:53.960
the entire vector space of all vectors is the union of every single one of these

02:58:54.840 --> 02:59:02.280
so it's the solution set of the homogeneous system with all of these other inhomogeneous

02:59:02.280 --> 02:59:11.000
solution sets and because these are all disjoint this is a disjoint union

02:59:11.000 --> 02:59:18.840
so every vector in z mod 2 is in exactly one of these subsets it's either a solution set of

02:59:18.840 --> 02:59:25.480
the homogeneous system or it's in one of these solution sets of the different inhomogeneous

02:59:25.480 --> 02:59:33.400
systems so this is a very important claim so let's actually let's actually prove it

02:59:36.920 --> 02:59:46.120
so the first claim now when we solve inhomogeneous systems all we have to do is find one particular

02:59:46.120 --> 02:59:51.560
solution and if we find that a solution exists then the solution set of the inhomogeneous system

02:59:51.560 --> 02:59:55.880
is that particular solution plus the homogeneous solution that we obtained

02:59:57.000 --> 03:00:05.880
from solving well for the kernel of h so notice however that we can just take x to be e i to get

03:00:05.880 --> 03:00:19.400
a solution set so e i is a particular solution and therefore the solution set of the whole system

03:00:22.280 --> 03:00:34.040
of h x equals h e i is that particular solution plus the homogeneous one

03:00:36.760 --> 03:00:45.400
and that's exactly what the claim is c i is the solution set of this now let's look at the second

03:00:45.480 --> 03:00:53.160
claim the second claim says that these are all different all of these subsets for different i

03:00:53.160 --> 03:01:04.200
and j have no common intersection so in order to prove that let's pick two vectors one in c i one in

03:01:04.200 --> 03:01:09.960
c j and they're going to be relatively they're going to be arbitrary and then we're going to show

03:01:09.960 --> 03:01:15.400
that the only way that they can be equal to each other is if those subscripts are equal if i and

03:01:15.400 --> 03:01:23.800
j are equal so let's start suppose that we have two vectors now because we're a solution set of

03:01:23.800 --> 03:01:28.840
the homogeneous system the kernel of h and the kernel of h equals the image of h our vectors

03:01:28.840 --> 03:01:41.320
are going to have this form so suppose m u 1 plus e i so this is our vector in c i equals m u 2 because

03:01:41.320 --> 03:01:46.200
we don't know if right these two could have different they have come from different vectors

03:01:47.000 --> 03:01:53.560
plus e j so suppose these we have these two vectors and this one is in c i this one is in c j

03:01:54.280 --> 03:02:02.280
okay now if we apply h to these vectors so let me just write that this is in c i this is in c j so we're totally

03:02:02.280 --> 03:02:15.400
clear now apply h to these this to this equality what happens well because these functions are linear

03:02:16.360 --> 03:02:32.360
and we apply h to both on the left hand side this becomes h m u 1 plus h e i equals h m u 2 plus h e j

03:02:33.720 --> 03:02:43.240
right and h m of u 1 is zero because h m is the zero matrix so this is zero that's zero and we're

03:02:43.400 --> 03:02:52.040
left with h e i equals h e j now the only way that this is possible is if i and j are both equal to

03:02:52.040 --> 03:03:01.640
each other and the reason is because h by definition is the set of all non-zero vectors in z mod 2 to

03:03:01.640 --> 03:03:07.960
the third power and they never repeat so we only use those vectors once and only one so to better

03:03:08.040 --> 03:03:15.400
understand this application let's first notice that if we apply m acting on any vector u the

03:03:15.400 --> 03:03:23.720
vector we get is q applied to u in the top part of that um entries of those of that vector and we

03:03:23.720 --> 03:03:30.440
retain a copy of u in the bottom this is because the matrix m was q on top and then the identity

03:03:30.440 --> 03:03:37.880
matrix on bottom so this is true for all u in z mod 2 to the fourth

03:03:41.400 --> 03:03:47.400
and so a copy of your original vector sits inside of this vector so imagine you're trying to send

03:03:47.400 --> 03:03:54.680
a message u across some sort of a channel a communication channel and you want a receiver

03:03:54.680 --> 03:04:01.320
to obtain um that message and you would like it for them to obtain exactly the message you sent

03:04:01.320 --> 03:04:06.440
because if you hear something else on the other end of that line or you see something else

03:04:06.440 --> 03:04:13.640
then you may misinterpret what the sender is trying to tell you so there's a sender and a

03:04:13.640 --> 03:04:20.440
receiver and so for example um during this transmission there could be

03:04:25.000 --> 03:04:30.040
some noise or maybe something that alters that message you hear this all the time when you're

03:04:30.040 --> 03:04:34.840
on the phone and sometimes the signal isn't working too well you might not hear exactly what the other

03:04:34.840 --> 03:04:40.840
person is saying or you might hear something a little bit different so there may be disturbance

03:04:40.840 --> 03:04:47.480
along such a line so for example if we were sending um let's say my name across this channel

03:04:48.440 --> 03:04:53.480
and at the end of the line the receiver sees um

03:04:56.840 --> 03:05:03.720
the word archer for example now what was the original message that was supposed to be sent

03:05:03.720 --> 03:05:08.360
in this context you have you know you know the english language so you know that there may be

03:05:08.520 --> 03:05:13.400
a specific word that this is corresponding to but in this example you have two possibilities

03:05:13.400 --> 03:05:21.160
that this word could be at least one of them could be archer or maybe arthur

03:05:23.080 --> 03:05:28.520
and in order for the receiver to verify what the message was or one way to verify what the

03:05:28.520 --> 03:05:33.960
message is is they could send that same message back and then basically ask you know is this the

03:05:33.960 --> 03:05:41.880
message you intended to send okay so now imagine that this person sends um let's say this person

03:05:41.880 --> 03:05:51.560
sends archer back and imagine another error occurs and imagine that the error occurs um takes place

03:05:51.560 --> 03:05:58.280
let's say in the first entry and it becomes archer

03:05:59.240 --> 03:06:06.280
and then the person is like wait did you want to send me the word archer like what are you doing

03:06:06.280 --> 03:06:16.680
with this message um are you trying to tell me escher or archer and so this person is going to

03:06:16.680 --> 03:06:21.720
send another message back um asking and you can see that this could keep happening for a very long

03:06:21.720 --> 03:06:28.920
time um so it would be very convenient to either this person can send multiple copies of that message

03:06:28.920 --> 03:06:34.520
and then with lower and lower probability the more messages you send the more likely it is

03:06:34.520 --> 03:06:39.720
that the person on the other end will figure out what that message is supposed to say so that's one

03:06:39.720 --> 03:06:44.440
option um but this option seems to take up a lot of resources right sending a message over and over

03:06:44.440 --> 03:06:48.680
and over again is sort of multiplying the number of resources you need by the number of times you

03:06:48.680 --> 03:06:55.320
send that message it would be very convenient if you could somehow have a scheme where the sender

03:06:55.320 --> 03:07:01.640
is sending a message and the receiver can apply a certain method that both the receiver and

03:07:01.640 --> 03:07:08.040
sender have agreed upon in advance to possibly identify if if an error occurred and where an

03:07:08.040 --> 03:07:16.920
error occurred during that transmission so that's what we're going to do and we're going to simplify

03:07:17.000 --> 03:07:22.280
the problem by not looking at the english language we're going to look at vectors whose entries are

03:07:22.280 --> 03:07:27.160
just zeros and ones the simplest possible language that we can come up with or at least the simplest

03:07:28.040 --> 03:07:36.360
list of the simplest alphabet we can come up with an alphabet containing two um symbols so let's say

03:07:36.360 --> 03:07:45.080
we initially send the vector zero one one zero across this channel now once this channel goes

03:07:45.080 --> 03:07:50.600
i should have written it from right to left as i've been doing so but let's go um counter to

03:07:50.600 --> 03:07:57.960
this now if one error occurs suppose one error occurred that means that error is going to occur

03:07:57.960 --> 03:08:04.040
in one of these four entries and if it occurs in the first entry the only possible thing that

03:08:04.040 --> 03:08:11.240
that zero could become because our language only has two symbols is one so one possibility is that

03:08:11.240 --> 03:08:17.000
we get one one one zero at the under the line another possibility is if the error occurs in

03:08:17.000 --> 03:08:23.480
the second entry in which case we would have zero zero one zero and so on so in the third entry zero

03:08:23.480 --> 03:08:32.680
one zero zero and in the last entry zero one one one so these are the possible outcomes if we have

03:08:32.680 --> 03:08:38.360
exactly one error of course if no error occurs then the receiver will see the original message

03:08:38.360 --> 03:08:45.880
but how do they even know that an error didn't occur or not so the way that we're going to solve

03:08:45.880 --> 03:08:53.000
this problem is by using the previous situation that we had developed we can take our original

03:08:53.000 --> 03:09:00.360
message encode it in some larger message and then this message is going to be contained in the subspace

03:09:00.360 --> 03:09:07.240
c so if we send the message u it's going to be contained in that subspace c and if we send that

03:09:07.320 --> 03:09:14.120
message across the channel instead what could happen to it so initially the sender is sending the

03:09:14.920 --> 03:09:21.960
the letter the message u is contained in the bottom part but now mu is contained in z mod

03:09:21.960 --> 03:09:27.720
two to the seventh power so it seems like a more complicated vector but the only real messages that

03:09:27.720 --> 03:09:34.600
could have been sent the ones that have no errors are exactly in that subspace c any other vector in

03:09:34.600 --> 03:09:43.240
this vector space is not a message that the sender could have sent because they're only working with

03:09:43.240 --> 03:09:53.080
images the image of the transformation associated to m so this message is going through now imagine

03:09:53.080 --> 03:10:02.200
that an error occurs somewhere along the way error and the message becomes mu plus now there are seven

03:10:02.200 --> 03:10:08.120
entries in the vector mu so there are now seven possible errors that could occur and these errors

03:10:08.120 --> 03:10:16.680
are exactly quantified by adding the unit vector in the ife row or entry of that vector so this

03:10:16.680 --> 03:10:23.880
error occurs but the reader on the other end is going to see this vector v they don't know that it

03:10:23.880 --> 03:10:29.800
is a priori this sort of combination all they see is some vector of zeros and ones

03:10:31.400 --> 03:10:42.040
but they can use h to identify what form the vector v is in remember we said that if h of v

03:10:42.040 --> 03:10:48.520
equals zero and this implies that the vector v is in the subspace c which is the image of m

03:10:48.840 --> 03:10:59.400
and if h of v equals a non-zero vector then that non-zero vector is one of the columns of h

03:11:01.000 --> 03:11:12.280
this tells us that v is in ci but remember what ci was it was this subspace plus the unit vector

03:11:12.280 --> 03:11:21.000
ei so it tells us that if a receiver receives receives the vector v and they apply h to it

03:11:21.000 --> 03:11:27.960
they can identify which of these subsets it's in and if the vector that they see after they

03:11:27.960 --> 03:11:36.120
apply h is zero that tells us that no error occurred so we're going to assume at most

03:11:36.520 --> 03:11:43.240
at most one error occurs during the transmission

03:11:50.520 --> 03:11:57.400
and if we make that assumption then these two applications an application of h to v will tell

03:11:57.400 --> 03:12:05.000
us where an error occurred and if we've identified where the error occurs right this says that if

03:12:05.000 --> 03:12:11.880
we see that the h of v is hei then we know that the vectors of this form and how do we fix it

03:12:12.520 --> 03:12:20.920
so if if it's let's say this is case one and this is case two in case one how would the receiver

03:12:21.720 --> 03:12:27.480
identify what the original message is they would look at the last four entries of the vector v

03:12:27.480 --> 03:12:32.440
because that's where u is and we know that no error occurred so the original

03:12:33.080 --> 03:12:43.160
message sent by the sender is the vector corresponding to the last four entries

03:12:48.760 --> 03:12:58.600
of the vector v and in the second case what happens then well if in the second case we found that

03:12:59.400 --> 03:13:03.160
h of v equals h of v i then an error occurred

03:13:07.480 --> 03:13:18.360
in the ith entry of v and how would we fix that while we would just subtract e i but

03:13:18.360 --> 03:13:23.400
subtracting in addition are the same in z mod 2 so to fix

03:13:23.480 --> 03:13:34.280
we know that the original message will be v plus e i well not the original message but

03:13:34.840 --> 03:13:42.200
what the receiver sent after applying the transformation m and when they do this then they

03:13:42.200 --> 03:13:52.200
can read off the last four entries of this vector the last meaning the bottom four

03:13:55.400 --> 03:14:00.120
of this vector v plus e i is the original message

03:14:04.440 --> 03:14:08.440
so let's just do this in an example just to see how exactly this works

03:14:09.160 --> 03:14:19.400
so imagine you're the receiver and you see the vector v equals zero zero one one zero one one

03:14:23.240 --> 03:14:27.880
if you apply h to this vector so i'll write h to remind you because otherwise

03:14:28.200 --> 03:14:37.160
how are we going to do this computation huh so this is one one one zero one one one zero one

03:14:38.200 --> 03:14:41.560
one zero and then we apply the vector v here

03:14:46.200 --> 03:14:54.440
and if we apply matrix operations here we will get the vector three two three but three is one

03:14:54.440 --> 03:15:01.560
in z mod two and two is zero so this becomes one zero one so we take this vector and look

03:15:01.560 --> 03:15:09.560
where it appears in this matrix and in this case it is the sixth column of h this means that an

03:15:09.560 --> 03:15:19.880
error occurred in the sixth entry of this vector here so error in sixth entry of v

03:15:20.120 --> 03:15:29.080
and therefore the if we alter the sixth entry that would mean we change this one the second

03:15:29.080 --> 03:15:41.960
last one to a zero so that means the original message message is one zero zero one

03:15:42.280 --> 03:15:49.880
because we take the last four entries of this vector and then we switch the sixth entry

03:15:49.880 --> 03:15:55.240
if we had found that the second entry was um an error occurred in the second entry we would

03:15:55.240 --> 03:16:00.840
have changed that zero to a one and left the original message here and that would have been our

03:16:00.840 --> 03:16:07.960
the message that was sent by the sender so um that's the basic idea of how this works

03:16:07.960 --> 03:16:14.200
and again we worked with a case where we were dealing with um sending messages of length four

03:16:15.720 --> 03:16:23.400
and we used um an additional a larger vector space to encode the possibilities of computing

03:16:23.400 --> 03:16:33.160
those errors and you could also do it by um using the um by having h to be a matrix consisting of

03:16:33.160 --> 03:16:40.120
all the non zero vectors in z mod two to the k it will allow us to encode a message of length

03:16:41.800 --> 03:16:49.480
given by the number of columns in that matrix q and we already calculated that the number

03:16:49.480 --> 03:16:54.840
of columns in that matrix q is two to the k minus one because of the zero vector minus an

03:16:54.840 --> 03:17:00.680
additional k from the k vectors we used on the left hand side of the matrix h so we can encode

03:17:00.680 --> 03:17:08.840
quite a large um number of messages under the assumption that at most one error occurs during

03:17:08.840 --> 03:17:13.960
transmission so let's now analyze in a little bit more detail

03:17:19.240 --> 03:17:26.920
what is q u actually doing so we know that that matrix m that we had it was broken up into two parts

03:17:27.480 --> 03:17:34.360
and when we send a message u across a channel we will keep our original message in one part

03:17:34.360 --> 03:17:40.920
of that vector but we'll add a bunch of fluff to it and what is the meaning of that fluff from

03:17:40.920 --> 03:17:49.560
maybe a more a different perspective um it turns out that there's a very interesting sort of uh

03:17:50.520 --> 03:17:58.120
logical thing that's going on between the entries of u and what q is doing to those entries

03:17:58.120 --> 03:18:02.680
and the idea is that it's adding those entries in such a way as to maintain the sort of consistency

03:18:03.480 --> 03:18:10.360
so if we take actually q u and we apply that matrix q that was left over the vector we would get

03:18:11.000 --> 03:18:14.600
in terms of the entries of u so u is going to be u one through u four

03:18:15.560 --> 03:18:23.720
the entries of this vector are going to be u one plus u three plus u four

03:18:25.080 --> 03:18:31.640
u one plus u two plus u four and the third entry because this is a three by four matrix

03:18:31.640 --> 03:18:42.840
is going to be u one plus u two plus u three and these entries here are called well let's call them

03:18:42.840 --> 03:18:49.720
p one p two and p three for now and they are called parity bits

03:18:57.640 --> 03:19:03.160
and the reason they're called parity bits is because when this message gets sent across a channel

03:19:04.120 --> 03:19:11.880
if an error occurs these entries are summing up the entries of the vector u in some specific way

03:19:11.960 --> 03:19:20.360
and if an error occurred right we have some vector p one p two p three and then u one u

03:19:20.360 --> 03:19:29.240
two u three and u four if an error occurred in one of these entries then these parity bits will

03:19:29.240 --> 03:19:36.440
detect if an error occurred and where the error occurred based on the consistency of this formula

03:19:37.400 --> 03:19:45.640
so let's see how this works in an explicit example let's say we have the vector zero zero one

03:19:46.360 --> 03:19:51.080
and i'll break this up into the two different parts so that we isolate the parity bits versus the

03:19:51.080 --> 03:19:56.040
original message and by the way this isn't the original message that i'm writing right now this

03:19:56.040 --> 03:20:01.880
is what happens after it's sent and let's see the receiver sees this message i believe this may be

03:20:01.960 --> 03:20:08.600
the example we were working with a moment ago so let's now look at these formulas and see what

03:20:08.600 --> 03:20:18.680
they say so p one on the one hand equals zero but let's see if the sum of these entries is also

03:20:18.680 --> 03:20:25.480
equal to zero so if we take u one plus u three plus u four we get one plus one plus one is three

03:20:25.480 --> 03:20:37.240
which is one which is not equal to one which equals u one plus u three plus u four what does

03:20:37.240 --> 03:20:55.480
this mean this means an error occurred in one of these entries

03:20:56.120 --> 03:21:07.240
and when i say one of these entries i mean either p one u one u three or u four so let's

03:21:07.240 --> 03:21:15.480
write that down p one u one u three or u four and we know it has to be exactly one because again

03:21:15.480 --> 03:21:22.040
we're assuming at most one error occurred and because of this inconsistency we're guaranteed

03:21:22.040 --> 03:21:28.200
that an error occurred the only way no error would occur is if all of these would be consistent so if

03:21:28.200 --> 03:21:33.000
p one does equal this p two does equal that p three does equal that because this would say

03:21:33.000 --> 03:21:40.440
that our vector is of this form m applied to the original vector u so that doesn't exactly tell us

03:21:40.440 --> 03:21:46.840
which of the errors it is yet is it p one u one u three or u four so for that we'll look at the other

03:21:47.480 --> 03:21:55.640
parity bits so let's look at p two the vector we see says p two is zero is that consistent with

03:21:55.640 --> 03:22:03.480
this formula u one plus u two plus u four so u one plus u two plus u four is zero so that actually is

03:22:03.480 --> 03:22:16.200
consistent what does this tell us this tells us that no error occurred in any of these entries

03:22:16.280 --> 03:22:22.520
because if one error occurred it is impossible for these two to be equal to each other so this means

03:22:25.960 --> 03:22:30.920
p two u one u two and u four are all

03:22:33.560 --> 03:22:41.080
error free now let's compare this to the first one that we analyzed the first one said

03:22:41.720 --> 03:22:48.040
it was possible that the error occurred at u one and it was also possible that the error occurred

03:22:48.040 --> 03:22:56.280
at u four this new observation tells us those two possibilities it's not possible that an error

03:22:56.280 --> 03:23:02.520
occurred in those entries so now the only possibilities left are p one and maybe u three

03:23:03.160 --> 03:23:08.440
so we'll keep that in mind when we go to the last parity bit which will then isolate exactly

03:23:08.520 --> 03:23:15.320
where the error occurred so p three is equal to well from this it's one and is that equal to

03:23:15.320 --> 03:23:21.640
u one plus u two plus u three u one plus u two plus u three it's equal to zero so that's not equal

03:23:21.640 --> 03:23:36.200
to this which is u one plus u two plus u three now this tells us that error is in one of p three

03:23:37.080 --> 03:23:42.760
u one u two or you or u three

03:23:45.640 --> 03:23:54.680
we already know that u one and u two are not possible right u one and u four are not possible

03:23:57.320 --> 03:24:05.080
and the only error that's common to both of these right because we know an error

03:24:05.080 --> 03:24:12.360
one error occurred in either p one or p r u three or it's possible that an occurred in p three or

03:24:12.360 --> 03:24:19.480
u three but if it was p three right suppose that the error occurred in p three then this would

03:24:19.480 --> 03:24:24.520
have been fine it would have been unaltered because we wouldn't have detected an error

03:24:24.520 --> 03:24:30.680
u three would have also been okay so the only possibility in this case is that an error occurred

03:24:30.760 --> 03:24:37.960
in u three the one that's singled out from these three parity bits so error

03:24:39.400 --> 03:24:46.280
in u three and therefore if we go to this original message the message that we received rather

03:24:46.840 --> 03:24:52.440
and then we um this is sorry this is the message we received but we would have to alter is the

03:24:52.440 --> 03:24:58.360
u three entry of this to get back the original message therefore the original message

03:25:01.400 --> 03:25:10.040
is the last four entries as it was before but now we alter that third message that third entry

03:25:10.040 --> 03:25:16.280
to get one zero zero one as the original message being sent and this is consistent I believe

03:25:16.280 --> 03:25:23.560
with the answer that we obtained earlier so you might be wondering okay this is a little bit more

03:25:23.560 --> 03:25:29.640
intuitive because we're sort of counting up our different entries in different ways and sort of

03:25:29.640 --> 03:25:36.200
using a process of elimination method to isolate exactly where the error occurred now of course

03:25:36.200 --> 03:25:40.600
that is a little bit more straightforward it's easier to work with it's easier to think about

03:25:41.160 --> 03:25:46.280
um the first time you see it perhaps on the other hand the linear algebra method

03:25:47.400 --> 03:25:53.000
it allows you to see it from a maybe potentially different perspective and I would think that if

03:25:53.000 --> 03:25:59.080
you're working with a much much larger message that the linear algebra method seems to be a

03:25:59.080 --> 03:26:03.880
lot easier to work with especially when you look at the way that we multiply those matrices

03:26:04.680 --> 03:26:10.920
and the form of the hamming matrix that we constructed so let me just say this that

03:26:10.920 --> 03:26:16.840
the cs hamming matrix looks a little bit different for instance I think it starts out with

03:26:18.120 --> 03:26:24.520
one zero zero zero one zero but then the third column is not zero zero one I think the fourth

03:26:24.520 --> 03:26:32.680
column is zero zero one and these other four columns are some permutation of the leftover

03:26:32.680 --> 03:26:38.440
columns I had and now you can see if you were to manipulate this with the other matrix m that's

03:26:38.440 --> 03:26:43.480
associated to this one by demanding that the kernel of h equals the image of that matrix m

03:26:44.760 --> 03:26:49.160
the algebra would be a little bit more we can't just break this up into do blocks identity

03:26:49.160 --> 03:26:57.880
and the leftover part instead it has sort of this interpretation but I believe the linear

03:26:57.880 --> 03:27:03.720
algebra calculations are much much simpler if you work with a block die a block matrix

03:27:04.440 --> 03:27:10.680
of the form that I indicated earlier now this may change if you try to look at what happens if

03:27:10.680 --> 03:27:16.920
multiple errors occur how would you potentially correct for all of those additional errors

03:27:17.640 --> 03:27:23.000
and I'll leave you to think about that and to check out the literature in the next few videos

03:27:23.000 --> 03:27:32.440
we're going to compute the square root of a positive matrix and the way we're going to do this

03:27:32.440 --> 03:27:39.080
is by introducing something called the functional calculus and in fact we'll learn how to compute

03:27:40.200 --> 03:27:46.840
given any function under suitable conditions what it means to apply that function to a given

03:27:46.840 --> 03:27:53.080
square matrix so let me go ahead and state the statement of the theorem that will prove

03:27:54.600 --> 03:27:59.320
and we'll prove this theorem first by doing an example and then we'll prove the general

03:27:59.320 --> 03:28:07.160
result from scratch so it says let a be a diagonalizable

03:28:10.920 --> 03:28:12.040
n by n matrix

03:28:17.800 --> 03:28:26.920
and let f be a function be a complex valued function let's say

03:28:30.280 --> 03:28:42.440
defined on what I'm going to call sigma of a and sigma of a is the set of all eigenvalues of a

03:28:50.600 --> 03:28:56.280
now if we have this setup we can already define what f of a is so let's do that

03:28:59.560 --> 03:29:09.400
so f of a is going to be defined as p f of d p inverse where

03:29:14.120 --> 03:29:25.960
p is the n by n matrix is a matrix of eigenvectors

03:29:29.880 --> 03:29:39.960
of a written as columns and d is the corresponding

03:29:42.840 --> 03:29:46.920
matrix of eigenvalues

03:29:47.480 --> 03:29:53.240
and what do I mean by f of d

03:29:56.040 --> 03:30:05.240
and f of d is defined to be now d is a diagonal matrix so let me just write out exactly what

03:30:07.240 --> 03:30:14.120
we're doing if we have a matrix of eigenvalues and these eigenvalues can repeat so let me just

03:30:14.120 --> 03:30:23.320
write all n of them and then this is zero everywhere else we define f of this matrix to be f applied

03:30:23.320 --> 03:30:29.400
to the elements along the diagonal and zero everywhere else so this is f of lambda one

03:30:30.840 --> 03:30:40.200
f of lambda n and zero everywhere else so so far all we've done is set up our assumptions

03:30:40.200 --> 03:30:45.960
so we have a matrix we have the eigenvalues we can define f applied to a provided that we

03:30:45.960 --> 03:30:52.120
have a complex valued function defined on the set of eigenvalues and here's the statement of the

03:30:52.120 --> 03:31:01.480
theorem then there exists a polynomial

03:31:04.440 --> 03:31:17.960
q such that q of a now what do I mean by q of a q is a polynomial and it makes sense to multiply

03:31:18.680 --> 03:31:22.600
so we can take a we can square it we can cube it we can also take it to the zero

03:31:22.600 --> 03:31:27.880
power that's just the identity matrix and then we can also multiply these by coefficients so if I

03:31:27.880 --> 03:31:33.880
have any polynomial it's very easy to define what q of a is you just write your polynomial

03:31:33.880 --> 03:31:40.920
and where you have your variable you replace it with the matrix a so this is some polynomial in a

03:31:41.880 --> 03:31:50.280
but it turns out to equal f of a as defined previously by this method of breaking a matrix up

03:31:50.280 --> 03:31:55.160
into its eigenvalues and getting its eigenvectors and constructing it this way

03:31:55.880 --> 03:32:01.880
so that's what the statement of this theorem is and it's very surprising because in general you

03:32:01.880 --> 03:32:08.360
can think of a very strange function such as the square root and this is telling you that there

03:32:08.360 --> 03:32:14.600
is a way to write the square root of that given matrix in terms of a single polynomial

03:32:15.400 --> 03:32:21.480
and what we're going to do first is do this through a simple example and illustrate it with

03:32:21.480 --> 03:32:26.520
that simple two by two matrix and then we'll prove the general theorem so we might as well start

03:32:26.520 --> 03:32:35.640
this example now and continue it in the next video so the example is going to be let a equal 10

03:32:36.360 --> 03:32:55.800
6 6 10 and our goal is to compute the square root of a so the first step is find the eigenvalues

03:32:58.280 --> 03:33:03.240
so another thing that we'll do is we'll review how to do these things so to find the eigenvalues

03:33:03.240 --> 03:33:12.680
compute the determinant of 10 minus lambda 6 6 10 minus lambda and this equals 100

03:33:14.840 --> 03:33:24.920
plus lambda squared minus 20 lambda minus 36 and some of this simplifies we get lambda squared

03:33:25.880 --> 03:33:45.240
minus 20 lambda plus 64 and this also factors into lambda minus four and lambda minus 16

03:33:46.200 --> 03:33:49.720
so we know what our two eigenvalues are they are four and 16

03:33:55.560 --> 03:34:03.240
and while we wait for the next video you can try to compute the corresponding eigenvectors

03:34:03.240 --> 03:34:07.480
and I'll just give you the answer there in a moment so here's the matrix that we're looking at

03:34:07.480 --> 03:34:12.680
the associated eigenvalues that we found before and corresponding eigenvectors which you should have

03:34:12.680 --> 03:34:20.440
found by computing the corresponding eigenvectors and so now let's compute what f and f meaning the

03:34:20.440 --> 03:34:28.280
square root of a so what is f of sorry f of the diagonal matrix d associated to these eigenvalues

03:34:29.320 --> 03:34:34.520
this is taking the square root of each of the corresponding entries on the diagonal so it's

03:34:34.520 --> 03:34:44.040
just two and four and the matrix p is writing down these two eigenvectors so it's just one negative

03:34:44.040 --> 03:34:55.560
one one one its corresponding inverse is the determinant here is two so it's one half and

03:34:55.560 --> 03:35:02.760
then the rest of this matrix we swap and we negate so that's the corresponding inverse of this matrix

03:35:03.400 --> 03:35:08.120
so what happens when we compute p f of d

03:35:10.600 --> 03:35:18.200
p inverse supposedly we should get the square root of our matrix which means that if we square it

03:35:18.200 --> 03:35:26.120
then we get back our matrix a so if we multiply some of these out i'll skip some of the steps

03:35:26.120 --> 03:35:38.840
so if we take one half when we multiply p with f of d we get two four negative two four

03:35:39.800 --> 03:35:43.880
and then we also have p inverse still here i've already pulled that one half out

03:35:47.960 --> 03:35:54.360
and multiplying these matrices out we get well that distributes out so we can just have one two

03:35:54.360 --> 03:36:06.760
negative one two and when we multiply those we get three one one three so let's check that if we

03:36:06.760 --> 03:36:14.840
square this matrix so let's um let's just call this f of a this is the definition that we gave

03:36:14.840 --> 03:36:24.760
of f of a so what happens when we square this matrix f of a squared we get exactly 10 6 6 10

03:36:24.760 --> 03:36:31.560
so we do get our original matrix back so this is one way of computing the square root of a matrix

03:36:31.560 --> 03:36:38.920
or at least if it has positive eigenvalues um by computing the corresponding eigenvectors and

03:36:38.920 --> 03:36:45.960
eigenvalues and supposedly we have another way of doing this and the interesting thing about

03:36:45.960 --> 03:36:52.280
the following method is that we will not be able we will not need to use the corresponding eigenvectors

03:36:52.280 --> 03:36:58.520
all we need to use are the corresponding eigenvalues and we'll find that polynomial that

03:36:58.520 --> 03:37:05.160
allows us to compute the square root of this matrix so how do we do that for the time being

03:37:05.160 --> 03:37:10.680
what we'll first do is we'll find a polynomial

03:37:14.760 --> 03:37:26.280
q such that q of lambda one equals the square root of lambda one or f of lambda one

03:37:27.400 --> 03:37:34.360
and q of lambda two equals f of lambda two so in this case these are the square roots

03:37:34.440 --> 03:37:38.680
and we already know exactly what their values are this is two and this is four

03:37:40.120 --> 03:37:44.520
so we're trying to do at this point now we're doing a different problem it seems like

03:37:44.520 --> 03:37:50.360
because now we're just trying to find a polynomial that interpolates these two values of a function

03:37:51.560 --> 03:38:00.120
so what we're trying to do is so here's lambda one here's lambda two and we have a function

03:38:01.080 --> 03:38:09.000
which is just the square root and we know that f applied to lambda one is two and f of lambda

03:38:10.200 --> 03:38:16.040
two is four now this is not drawn to scale in any way but what we're trying to do is

03:38:16.040 --> 03:38:21.160
find a polynomial that goes through these two points now you know that two points determine

03:38:21.160 --> 03:38:26.920
a line so a straight line goes through these two points and that straight line of the form

03:38:27.000 --> 03:38:36.280
y equals mx plus b so our goal is to find out what are m and what are b such that

03:38:36.280 --> 03:38:41.000
when we plug in x which is our values of lambda we get the corresponding values of y

03:38:42.760 --> 03:38:47.800
so this isn't a very difficult problem but what we're going to do is set it up as a linear algebra

03:38:47.800 --> 03:38:52.760
problem even though you could probably immediately solve for m and b and the reason we'll do that

03:38:52.760 --> 03:38:59.000
will be made more apparent later when we try to compute f of matrices of larger sizes

03:38:59.000 --> 03:39:03.640
where it will be more difficult to do the simpler method and it's more reasonable

03:39:03.640 --> 03:39:08.280
to solve that system of linear equations using techniques of linear algebra

03:39:09.880 --> 03:39:17.320
so when we set this up we write on this side since this is our y we have m lambda one

03:39:17.320 --> 03:39:25.400
plus b and this equals m of lambda two plus b and our unknowns are m and b so if we set up our

03:39:25.400 --> 03:39:34.600
matrix system we get and what i'll do for convenience is i'll put the ones on the left

03:39:34.600 --> 03:39:43.000
so i'll put my b's on the left column so it's really b plus mx one one and then this is lambda one

03:39:43.000 --> 03:39:50.600
lambda two and our two corresponding values f of lambda one which in this case is two and four

03:39:53.400 --> 03:39:57.720
and we know what lambda one and lambda two are they are four and sixteen

03:39:57.720 --> 03:40:02.920
so really this is equal to one four one sixteen two four

03:40:05.240 --> 03:40:11.400
and if we try to row reduce this system and solve it what we end up getting is

03:40:12.120 --> 03:40:14.600
b equals four thirds

03:40:17.000 --> 03:40:19.560
and m equals

03:40:22.040 --> 03:40:32.520
one sixth so this line is of the form y equals four thirds plus one sixth x

03:40:33.880 --> 03:40:37.000
and that's our polynomial this is our q of x

03:40:37.080 --> 03:40:47.640
and what we'll do in the next video is we will actually apply this polynomial to our matrix

03:40:47.640 --> 03:40:54.120
and see if it also satisfies the same equation so here's the polynomial that we found

03:40:54.840 --> 03:41:03.080
as a real valued function in this case and if we wanted to define q of any matrix i'm just

03:41:03.080 --> 03:41:09.560
going to write a but it's for any matrix a we would the associated polynomial on matrices

03:41:09.560 --> 03:41:15.880
would be four thirds times the identity matrix which in this case is an n by n matrix well

03:41:15.880 --> 03:41:24.280
in this case it's two by two matrix plus one sixth a so let's see what happens when we actually

03:41:24.360 --> 03:41:29.960
compute this so we have four thirds of the identity

03:41:33.400 --> 03:41:42.440
both along the diagonal plus one sixth of our matrix a so it's 10 over six which is five thirds

03:41:42.600 --> 03:41:55.160
one one five thirds and if we add these two matrices what do we get nine thirds which is three

03:41:55.960 --> 03:42:03.720
one one three which is exactly what we found for f of a before so we already know that when

03:42:03.720 --> 03:42:11.400
we square this matrix we get exactly our matrix a back now let's look at the more general situation

03:42:13.160 --> 03:42:21.400
so we're going to go back to our setup where we have an n by n matrix a a function f on the

03:42:21.400 --> 03:42:31.880
set of eigenvalues so we write if a is n by n and lambda one through lambda n are the eigenvalues

03:42:31.960 --> 03:42:38.520
and f is a function

03:42:41.880 --> 03:42:49.640
on the set of eigenvalues to let's say the complex numbers we're going to find a polynomial q

03:42:50.520 --> 03:42:55.960
that first satisfies the initial equation we wrote down for the associated eigenvalues

03:42:55.960 --> 03:43:00.520
so our goal is to find a polynomial

03:43:04.520 --> 03:43:18.200
q such that q of when we plug in our corresponding eigenvalues we get f applied to those corresponding

03:43:18.200 --> 03:43:25.080
eigenvalues and we already know that that's problem will help us solve this one by a

03:43:25.080 --> 03:43:30.680
similar analysis that's why we're reducing our problem to finding a polynomial on just a finite

03:43:30.680 --> 03:43:38.120
set of numbers rather than trying to find the answer to our matrix problem and in fact when we

03:43:38.120 --> 03:43:43.560
look at the degree of this polynomial we notice that it was also matching the degree of the size

03:43:43.560 --> 03:43:49.480
of our matrix and that's going to be true in general we'll be able to find the polynomial whose

03:43:49.480 --> 03:43:58.280
degree is at most the size of the matrix that will solve that problem namely q of a equals f of a

03:43:59.480 --> 03:44:06.200
and why that happens is precisely because of this equation because there are going to be

03:44:06.200 --> 03:44:13.640
at most n distinct eigenvalues and so we only need to find a polynomial so let me draw this as

03:44:14.280 --> 03:44:20.760
visually let's just assume everything is real so it's simple to draw this so if we have lambda 1

03:44:20.760 --> 03:44:29.960
here lambda 3 here lambda 2 maybe another lambda 4 somewhere out here and let's say lambda 2 equals

03:44:29.960 --> 03:44:37.160
lambda 5 for instance and if we apply f to these numbers let's say they look something like this

03:44:38.120 --> 03:44:46.600
what we're going to try to do is find the polynomial that fits through these in this case four points

03:44:46.600 --> 03:44:53.720
and the reason it's four is because two of our eigenvalues are repeated and so we have to find

03:44:53.720 --> 03:45:04.520
the polynomial through these four points so and if we had n distinct eigenvalues we would have

03:45:04.600 --> 03:45:09.720
n distinct points through which we would have to find a polynomial sorry i misspoke i think i

03:45:09.720 --> 03:45:15.720
said degree two i meant degree one because one is the highest power but it starts from zero

03:45:16.680 --> 03:45:21.720
so in this case we would find a degree in this case we would find a degree three polynomial

03:45:22.280 --> 03:45:35.080
and in general it would be at most n minus one degree so and again if we have multiplicity

03:45:35.080 --> 03:45:40.600
that's non z that's um bigger than one then the problem is going to be a little bit easier

03:45:40.600 --> 03:45:45.560
to solve because we can find a polynomial of a lower degree so let's just assume

03:45:45.560 --> 03:45:51.160
that all eigenvalues

03:45:54.520 --> 03:46:01.160
are distinct just it's not it's not actually making our problem easier it's making it a little bit

03:46:01.160 --> 03:46:06.840
harder because if some of them repeat then the problem is reduced to a smaller and simpler

03:46:06.840 --> 03:46:12.280
matrix algebra problem so if we assume all the eigenvalues that are distinct we're really doing

03:46:12.280 --> 03:46:23.480
the hardest case now when such a thing happens we can write our polynomial q of x as a zero plus

03:46:23.480 --> 03:46:31.240
a one x plus a two x squared all the way up to the highest degree which you know just by

03:46:31.240 --> 03:46:37.640
looking at the pictures we're assuming it's of the form a n minus one x to the n minus one

03:46:37.640 --> 03:46:44.680
and if we write down all of these different equations we're going to get another linear system

03:46:45.720 --> 03:46:48.840
and the unknowns of that linear system are these a's

03:46:52.840 --> 03:46:58.760
and we know the values of x's those are different eigenvalues and we know the q of those x's are

03:46:58.760 --> 03:47:04.040
it's f applied to those values so the associated linear system that we get

03:47:04.840 --> 03:47:13.240
that looks like one ones along the vertical on the left side corresponding to the coefficient

03:47:13.240 --> 03:47:19.000
in front of a zero the coefficients in front of a one are the different eigenvalues

03:47:23.080 --> 03:47:30.360
the coefficients in front of a in front of x squared are the squares of our eigenvalues

03:47:34.280 --> 03:47:40.840
and then the coefficients in front of our highest degree are

03:47:43.960 --> 03:47:47.640
our eigenvalues to the power of that highest degree

03:47:53.320 --> 03:47:59.800
and the augmented side of our matrix is the value of those different eigenvalues

03:48:04.680 --> 03:48:15.000
so our goal will be to try to solve this system well actually our goal is a little bit easier than

03:48:15.000 --> 03:48:23.320
that the statement of the theorem says that there exists a polynomial q that satisfies the equation

03:48:23.320 --> 03:48:29.880
q of a equals f of a and so all we really have to do is show that such a polynomial exists

03:48:30.760 --> 03:48:38.120
so we don't have to solve this solving it is what is q so given a matrix a what is what is q

03:48:38.120 --> 03:48:43.160
the what is that polynomial q we're just trying to show that one exists in other words what we

03:48:43.160 --> 03:48:50.200
want to do is answer the question does a solution to this system exist and if we want to know

03:48:50.360 --> 03:48:52.760
how a solution exists

03:48:56.280 --> 03:49:05.400
if well if we can solve this system right and one criteria that allows us to solve this system

03:49:05.960 --> 03:49:13.720
is that if this matrix here which is an n by an n minus what is this an n by n matrix

03:49:14.440 --> 03:49:21.960
right it's an n by n matrix and if this matrix is invertible and when is the matrix invertible

03:49:21.960 --> 03:49:27.400
if the determinant of this matrix is non-zero so solution exists if the determinant of

03:49:28.280 --> 03:49:32.360
this matrix which is called a van der man matrix

03:49:37.960 --> 03:49:40.840
if this determinant is non-zero

03:49:44.680 --> 03:49:51.400
so what we're going to do is it's going to be a little bit of a brute force method

03:49:51.400 --> 03:49:57.320
but we will find one way to compute the determinant of this matrix and therefore

03:49:57.960 --> 03:50:02.200
show whether or not it's zero and see if we can answer our problem

03:50:04.360 --> 03:50:09.000
whenever we have a problem with arbitrary n it's a little bit difficult to see what the

03:50:09.080 --> 03:50:14.600
pattern is without doing an example so i think it's good to try out a simple example

03:50:15.320 --> 03:50:23.240
or at least somewhat simpler by computing the determinant of the same matrix but where n equals

03:50:24.440 --> 03:50:27.960
let's say three so we have a three by three

03:50:31.480 --> 03:50:36.920
and we want to compute this determinant and we want to compute it in such a way

03:50:39.160 --> 03:50:42.440
so that we can use some of the ideas for computing this determinant

03:50:42.440 --> 03:50:49.960
and abstract it to that more general case now this isn't the most simplest way to do such a thing

03:50:49.960 --> 03:50:55.480
but it's one way and i'm sure there are many many other ways to compute this determinant

03:50:56.200 --> 03:51:00.280
some of which may be certainly more clever than the approach that we'll take

03:51:01.720 --> 03:51:04.760
so we're going to do this by essentially row reduction

03:51:04.760 --> 03:51:11.480
and for the first step we're going to get rid of the ones underneath the top left one

03:51:11.480 --> 03:51:15.720
and by just subtracting the first row from those

03:51:17.320 --> 03:51:26.200
so if we do that that doesn't change the determinant and we get the top row is left alone

03:51:27.080 --> 03:51:35.000
and then the rows below it look like zero zero lambda two minus one

03:51:36.360 --> 03:51:47.080
lambda three minus one and this becomes lambda three cubed minus lambda one cubed uh sorry squared

03:51:49.320 --> 03:51:52.520
and lambda two squared minus lambda one squared

03:51:56.520 --> 03:52:04.120
now when we uh lambda two minus lambda one is actually a common factor in this second row

03:52:04.120 --> 03:52:07.720
because this becomes lambda two plus lambda one when we pull that out

03:52:07.720 --> 03:52:15.320
and this is lambda three plus lambda one so when we distribute out we get lambda two minus lambda one

03:52:16.920 --> 03:52:24.280
lambda three minus lambda one times the determinant of what's left over which is one

03:52:24.280 --> 03:52:25.800
lambda one lambda one squared

03:52:29.480 --> 03:52:34.920
zero one zero one lambda

03:52:38.280 --> 03:52:42.840
one plus lambda two lambda one plus lambda three

03:52:45.960 --> 03:52:51.000
and this happened because the determinant remember when you take the determinant and you multiply

03:52:51.000 --> 03:52:56.520
any row or any column by a number you can distribute out that one number for that one

03:52:56.520 --> 03:53:01.000
column in this determinant you can think of the volume if you scale one side of the room

03:53:01.000 --> 03:53:05.880
by a factor and another side of the room by a different factor then the determinant is computing

03:53:05.880 --> 03:53:12.520
the area and you scale by both of those but for each side you only distribute one of them

03:53:15.720 --> 03:53:19.720
so now we're looking at this and we want to compute the determinant of this

03:53:19.720 --> 03:53:24.600
now of course what's left over is a two by two so it's very easy to compute the determinant

03:53:24.600 --> 03:53:29.400
but if we wanted to have an inductive proof if we did a similar calculation here for a larger

03:53:29.400 --> 03:53:35.560
matrix what we would have is lambda one through lambda one to the n minus first power up here

03:53:35.560 --> 03:53:39.720
and we have a much larger matrix which isn't very easy to compute the determinant of

03:53:39.720 --> 03:53:46.520
by some explicit formula it's sort of complicated to write so what we want to do is we want to

03:53:46.520 --> 03:53:53.080
think of how to compute this maybe more conceptually and what we can do is notice that lambda one

03:53:53.080 --> 03:54:00.360
appears here in each of these two terms and if we multiply the second column by lambda one

03:54:01.320 --> 03:54:08.360
and subtract what happens is this cancels the lambda one cancels the lambda one cancels and

03:54:08.360 --> 03:54:14.120
you're only left with lambda two and lambda three and you also don't change the determinant because

03:54:14.120 --> 03:54:20.040
you're taking one column and adding it to another so this is also equal to

03:54:25.080 --> 03:54:27.960
the determinant of what's left over after you do that subtraction

03:54:32.280 --> 03:54:38.520
this is zero zero one zero one and then just lambda two and lambda three left over

03:54:39.240 --> 03:54:44.920
well you can even do something even a little bit more simpler now now you have a one here

03:54:44.920 --> 03:54:49.320
you can multiply this by lambda one to get rid of that so i'm not even going to write that whole

03:54:49.320 --> 03:55:01.880
step out we can just erase this and put a zero here and now here's the amazing part what's left over

03:55:02.440 --> 03:55:11.320
after you perform these operations is another van der man matrix on the bottom right corner

03:55:12.840 --> 03:55:20.040
and we can continue this process now because the determinant of this because this is a one

03:55:20.040 --> 03:55:26.440
is equal to the determinant of this so we've reduced our problem

03:55:26.680 --> 03:55:37.880
from an n by n matrix to an n minus one by n minus one matrix of the same form

03:55:39.880 --> 03:55:45.160
and if we keep going down further up until maybe this step or even further than that

03:55:45.800 --> 03:55:51.480
then we would find out what the determinant of this matrix is so if we did that procedure again

03:55:51.480 --> 03:55:55.240
of course you can compute the determinant of a two by two no problem but if you did that procedure

03:55:55.240 --> 03:56:02.600
again subtract you get a zero here move that over you end up getting lambda two minus lambda three

03:56:02.600 --> 03:56:10.680
it's already of that it already breaks up like that pretty easily and you get lambda two minus

03:56:10.680 --> 03:56:19.080
lambda three that pops out so you end up getting is the product of i and j let's say i is less than

03:56:19.080 --> 03:56:27.080
j and j is less than or equal to three and i is greater than or equal to one of lambda j minus

03:56:27.080 --> 03:56:34.760
lambda i so you actually get the product of the differences of all of these different eigenvalues

03:56:36.360 --> 03:56:42.520
and because we're assuming that the eigenvalues are distinct all of these numbers are not zero

03:56:43.160 --> 03:56:48.440
therefore this is not equal to zero and so we automatically know that the determinant of this

03:56:48.440 --> 03:56:59.080
matrix is non-zero so we can make a guess that the determinant of that more general matrix

03:56:59.800 --> 03:57:03.640
of that more general van der man matrix

03:57:14.280 --> 03:57:19.640
is exactly the product of the differences of all of the eigenvalues

03:57:29.800 --> 03:57:36.120
and therefore is not zero if they're distinct

03:57:39.800 --> 03:57:43.160
and we can prove this by induction we already know what happens when n equals one

03:57:43.960 --> 03:57:50.840
or when n equals two and not even n equals three and so what we can do is if we assume that this

03:57:50.840 --> 03:57:58.600
formula is true for n and go to n plus one then what we want to do is reduce that problem to this

03:57:58.600 --> 03:58:05.400
one and show that those numbers factor out and then we can apply our induction hypothesis

03:58:05.960 --> 03:58:08.600
and prove that this formula holds more generally

03:58:12.040 --> 03:58:15.640
and the way we do that is very similar to this so i'll put a question mark here

03:58:16.280 --> 03:58:23.080
and i'll write what this equals by doing this first step which was here sorry this first step

03:58:23.080 --> 03:58:29.160
in subtracting the first row from all of the rows below it what we end up getting is

03:58:30.360 --> 03:58:35.560
the determinant of and here we have a bunch of zeros below the ones so we have one

03:58:36.760 --> 03:58:43.560
and i'll write two rows just so we see more of the pattern uh this is a zero sorry zero

03:58:45.160 --> 03:58:49.320
lambda one and then this is lambda two minus lambda one

03:58:50.040 --> 03:58:55.000
and this is all the way down to lambda n minus lambda one

03:58:57.240 --> 03:59:03.880
all the way up to and let me write two additional terms here this is going to be lambda n minus two

03:59:04.680 --> 03:59:16.680
lambda one n minus one now this is lambda two to the n minus tooth power minus lambda

03:59:17.640 --> 03:59:19.720
one to the n minus tooth power

03:59:22.360 --> 03:59:34.040
and here we have lambda n minus one minus sorry two minus one

03:59:34.520 --> 03:59:37.400
so

03:59:46.040 --> 03:59:46.600
that's a one

03:59:49.720 --> 03:59:50.040
okay

03:59:54.680 --> 03:59:59.960
now at this point we can follow a similar procedure by pulling out a lambda two minus

03:59:59.960 --> 04:00:06.200
lambda one from each of the terms but then we would have to figure out what is lambda two to some

04:00:06.200 --> 04:00:12.920
power minus lambda one to that same power divided by lambda two minus lambda one we could do that

04:00:12.920 --> 04:00:19.240
and factor it out by using um polynomial division find out what the corresponding factors are but

04:00:19.240 --> 04:00:24.840
maybe that's not the best way to do it another option although that method of course you know

04:00:24.840 --> 04:00:29.000
teaches you a lot about how to do polynomial division in case you haven't seen it before it's

04:00:29.240 --> 04:00:35.480
quite nice but maybe there's another easier way similar to what we did over here and what we did

04:00:35.480 --> 04:00:41.560
here was we took the second last column and we multiplied it by lambda one and we took the

04:00:41.560 --> 04:00:46.360
difference here we could have also done that in this step it just might have been a little bit it

04:00:46.360 --> 04:00:50.840
might have looked a little bit more complicated because of the higher powers but let's try to

04:00:50.840 --> 04:01:00.760
do that anyway if we multiply the second last column by lambda one from the last column

04:01:02.280 --> 04:01:07.480
the power here will be n minus one which will match this one and these two terms will cancel and

04:01:07.480 --> 04:01:14.120
you'll just get zero what happens to this term if you multiply this by lambda one so let's write this

04:01:14.120 --> 04:01:21.640
out so we have lambda two n minus one minus lambda one to the n minus one minus multiply this whole

04:01:21.640 --> 04:01:32.360
term by lambda one that becomes a plus lambda one to the n minus one and then what's left over is

04:01:32.360 --> 04:01:39.720
minus lambda one lambda two to the n minus two these two terms conveniently cancel and what

04:01:39.720 --> 04:01:51.480
you're left over with is lambda two appears the highest common factor is lambda two to the n minus

04:01:51.480 --> 04:01:59.480
two so we can pull that out and what's left over after we pull that out is lambda two minus lambda

04:01:59.480 --> 04:02:08.120
one and therefore we can much more easily see that this factors out after we do this subtraction

04:02:08.920 --> 04:02:14.840
now we've done imagine we've done that for the last column here now we have this second last

04:02:14.840 --> 04:02:19.240
column which still has all of these complicated terms but what does this term before it look like

04:02:21.320 --> 04:02:30.280
lambda one to the n minus three and then it's lambda two to the n minus three minus lambda one

04:02:30.280 --> 04:02:37.560
to the n minus three so you can just see it's of the form n minus j and if we multiply this by

04:02:37.560 --> 04:02:43.960
lambda one and subtract it well these two terms will cancel and a similar thing will happen here

04:02:43.960 --> 04:02:49.960
it's just that the power will now be not lambda two to the n minus two but lambda two to the n minus

04:02:49.960 --> 04:02:58.200
three after we take this difference and so if we keep going in this direction taking all of those

04:02:58.280 --> 04:03:04.440
successive differences we will be left over with so this determinant equals

04:03:07.160 --> 04:03:16.520
the product of lambda j minus lambda one and j goes from two to n

04:03:17.080 --> 04:03:26.680
and we're left over with the determinant of

04:03:27.720 --> 04:03:35.240
a smaller bandermen matrix which looks like one zero zero and this term is one

04:03:36.280 --> 04:03:41.640
and it's all the way one's all the way down let me write just the first and last ones

04:03:42.520 --> 04:03:46.920
we also have zeros here up to the last term

04:03:50.120 --> 04:03:55.400
now what is this term here it's lambda two to the n minus two now

04:03:57.560 --> 04:04:04.920
all the way down to lambda n to the n minus two and if we assume the induction hypothesis

04:04:04.920 --> 04:04:10.680
then we know that the determinant here is the product of lambda let me use a different letter k

04:04:10.680 --> 04:04:19.160
and l so k minus l where k is greater than strictly greater than l and l runs from this

04:04:19.160 --> 04:04:29.400
time two to n and and and k so we end up getting after all of this work by using that induction

04:04:29.400 --> 04:04:35.640
hypothesis we get that this is this expression right here

04:04:41.320 --> 04:04:47.160
and in particular this says that our determinant is non-zero so we can compute the inverse of

04:04:47.160 --> 04:04:54.520
this matrix if we wanted to now that we have all of this set up we can prove our main theorem

04:04:55.240 --> 04:05:08.040
which remember said that given any diagonalizable matrix a there exists and a function f on its

04:05:08.040 --> 04:05:18.360
set of eigenvalues there exists a polynomial q such that q of a equals f of a and so far

04:05:18.920 --> 04:05:29.800
based on the facts that we just proved we know there exists a polynomial

04:05:33.160 --> 04:05:42.920
q such that q of lambda i equals f of lambda i for all of the eigenvalues

04:05:43.560 --> 04:05:47.800
of that matrix therefore

04:05:52.280 --> 04:06:01.880
if we compute f of d which was defined to be f of lambda one f of lambda n

04:06:02.200 --> 04:06:13.560
of our diagonal matrix d then this is the same exact thing as q of lambda one

04:06:15.320 --> 04:06:23.560
q of lambda n with zero everywhere else by this result we can find a single polynomial q that

04:06:23.560 --> 04:06:38.920
satisfies this but this is exactly the same thing as q of d well why is that well if we

04:06:38.920 --> 04:06:45.960
write our diagonal matrix d out and we apply the polynomial q to it right so let's just see why this

04:06:45.960 --> 04:06:56.760
is true if we take our diagonal matrix and then we plug in our polynomial so we had what was it

04:06:56.760 --> 04:07:05.640
it was a zero times the identity n by n matrix this is what if we view q as a polynomial and we

04:07:05.640 --> 04:07:15.400
plug in the formula for q of d this is by definition of a matrix applied to a polynomial

04:07:16.280 --> 04:07:27.960
sorry a polynomial um with input a matrix plus a1d plus a2d squared plus a n minus 1

04:07:28.840 --> 04:07:35.320
d to the n minus 1 and we know what this looks like as a matrix this is the identity

04:07:35.320 --> 04:07:39.560
it looks like a zero all along the diagonals

04:07:42.040 --> 04:07:50.280
and zero everywhere else this is a one times lambda one all the way down to a one times lambda

04:07:50.920 --> 04:08:00.600
to the n lambda n and then here we have plus a2d squared now d squared since d is the diagonal

04:08:00.600 --> 04:08:08.600
matrix is just lambda i squared in each of the diagonal terms so it's a2 lambda one squared

04:08:09.320 --> 04:08:15.240
all the way down to a2 lambda n squared and similarly for all of the other terms

04:08:16.280 --> 04:08:21.640
up until this last one then what happens when you add all of these matrices together well you get

04:08:21.640 --> 04:08:27.800
a zero on the top left term you get a zero plus a1 lambda one plus a2 lambda one squared plus dot

04:08:27.800 --> 04:08:34.680
dot dot a n one minus lambda one to the n minus one that's exactly what q of lambda one is

04:08:35.640 --> 04:08:41.560
and similarly for all of the other terms so this justifies why this equality holds

04:08:44.360 --> 04:08:52.440
and of course q of any matrix is defined similarly so in particular q of a equals a zero times the

04:08:52.440 --> 04:09:03.640
identity plus a1 times a plus a2 times a squared and so on so now let's show that f of a equals q

04:09:03.640 --> 04:09:15.000
of a now f of a by definition of f of a is p times f of the diagonal matrix times p inverse where p is

04:09:15.000 --> 04:09:22.360
the matrix of eigen vectors corresponding to those eigen values is a matrix of eigen vectors

04:09:24.200 --> 04:09:29.720
now f of d by this calculation is also q applied to d

04:09:35.240 --> 04:09:37.720
and so that equation is true by what we just showed

04:09:37.720 --> 04:09:44.360
now we know what q of d looks like it looks like this and we also know what happens when

04:09:44.360 --> 04:09:55.160
we distribute p throughout so we get something that looks like a zero p times p inverse plus

04:09:55.720 --> 04:10:10.040
a1 pd p inverse all the way up to a n minus one pd to the n minus one p inverse

04:10:12.360 --> 04:10:17.400
that's just what that looks like when you distribute p and p inverse on both sides

04:10:17.880 --> 04:10:29.720
now this is a and what is this expression and likewise for all of the terms in between well

04:10:32.520 --> 04:10:39.240
let's just let's just look at what happens if we um if we set f n is like three or something like

04:10:39.240 --> 04:10:48.040
that or maybe even two is enough um so let's look at this term p d squared p inverse so p

04:10:48.760 --> 04:11:00.680
d squared p inverse also equals p times d times d times p inverse and because p and p inverse are

04:11:00.680 --> 04:11:08.520
well inverses of each other we can plug in a p inverse p between these two d's and

04:11:09.480 --> 04:11:21.400
this gives us p d p inverse times p d p inverse again and this is just a and this is just a

04:11:22.040 --> 04:11:29.320
so we get a squared therefore when we actually write out what all of these things equal we get

04:11:29.400 --> 04:11:39.320
a zero p p inverse plus a one which is the identity sorry this is the identity matrix

04:11:40.280 --> 04:11:50.200
and this is a plus a two a squared plus all the way up to a n minus one a to the n minus one

04:11:50.280 --> 04:12:02.280
and this is the definition of q of a so this shows us that that theorem is true

04:12:04.600 --> 04:12:06.440
so this has an interesting corollary

04:12:11.160 --> 04:12:13.000
so let a be diagonalizable

04:12:13.560 --> 04:12:22.840
and let b be any square matrix of the same size

04:12:29.400 --> 04:12:31.000
and suppose that they satisfy

04:12:35.480 --> 04:12:39.880
the fact that when we multiply them in any order they're equal to each other

04:12:43.080 --> 04:12:47.320
then f of a

04:12:49.800 --> 04:12:55.880
b equals b f of a for all functions

04:12:58.360 --> 04:13:04.120
that are defined on the eigenvalues of a

04:13:04.120 --> 04:13:08.120
and how do we prove this

04:13:10.040 --> 04:13:19.720
well because a is diagonalizable then f of a equals q of a for some polynomial

04:13:23.880 --> 04:13:33.320
q and because it's a polynomial if we replace this expression with q of a times b

04:13:34.840 --> 04:13:44.680
so if we have q of a times b this is a polynomial in a and each of the terms look like

04:13:45.320 --> 04:13:48.280
a to the jth power times b

04:13:50.760 --> 04:13:55.720
right so you have a to the jth power times b now a to the jth power means you write the

04:13:55.720 --> 04:14:01.960
matrix a j times and if you have a b on one side you can use this to move each of those a's

04:14:01.960 --> 04:14:05.560
one over at a time you can move them over one at a time

04:14:06.280 --> 04:14:11.960
therefore a j a to the jth times b equals b times a to the jth therefore

04:14:13.080 --> 04:14:21.560
it's immediate that this equals b times q of a and it immediately solves this problem because

04:14:21.560 --> 04:14:29.080
q of a equals f of a and the interesting thing about this is that b can be any matrix whatsoever

04:14:29.080 --> 04:14:32.120
and a only has to be diagonalizable for this to be true

04:14:34.520 --> 04:14:42.840
so hopefully this is an interesting fact namely that given any function at least that's defined

04:14:42.840 --> 04:14:50.520
on the set of eigenvalues of a it could be defined on a larger set of the subset of the complex numbers

04:14:50.520 --> 04:14:56.840
but at the very least if it's defined on those eigenvalues then we can always find a polynomial

04:14:56.840 --> 04:15:05.080
for which when we apply that function which could be completely wild such such as the

04:15:05.080 --> 04:15:11.400
logarithm or something like that then there's a polynomial that gives us the same value for that

04:15:11.400 --> 04:15:17.160
matrix if we apply the polynomials of the matrix versus if we apply the function to that matrix

04:15:19.240 --> 04:15:25.560
and a lot of this has to do with the fact that we're working with finite dimensional matrices

04:15:27.000 --> 04:15:33.160
one of the interesting things about linear algebra is what happens when your matrices become of

04:15:33.160 --> 04:15:40.120
infinite order and then this really becomes a much more subtle issue and clearly the method that we've

04:15:40.120 --> 04:15:44.760
used should probably break down for instance we're not working with polynomials anymore

04:15:45.400 --> 04:15:50.840
and a lot of this is explored for instance in functional analysis and spectral theory

04:15:51.640 --> 04:15:54.840
and the functional calculus for such operators

04:15:57.080 --> 04:16:03.960
in these next few videos we'll learn about affine subspaces affine combinations and affine

04:16:03.960 --> 04:16:09.640
transformations which are very slight generalizations of linear transformations as we'll see

04:16:11.240 --> 04:16:17.320
so the first definition that we'll need is what an affine combination of vectors is

04:16:17.560 --> 04:16:24.120
so but to do that we'll recall what a linear combination is so a linear combination

04:16:28.760 --> 04:16:40.360
of vectors v1 through vk in rn is a combination of the form

04:16:47.480 --> 04:16:57.560
lambda 1 v1 so we add up all our vectors with some weights and these weights

04:16:58.600 --> 04:17:00.360
will take to be real numbers

04:17:03.720 --> 04:17:05.720
so that's what a linear combination is

04:17:08.200 --> 04:17:14.600
and closely related to this an affine combination

04:17:17.560 --> 04:17:19.880
of these same vectors

04:17:27.000 --> 04:17:28.280
is a linear combination

04:17:32.440 --> 04:17:37.480
and for short I may often write just using the summation notation

04:17:37.880 --> 04:17:48.040
oops let's call this not k but j and this goes from j equals one to k

04:17:51.560 --> 04:17:57.560
such that the sum of these coefficients is equal to one

04:18:00.760 --> 04:18:06.600
so it's basically a linear combination but we have an additional constraint on the

04:18:06.680 --> 04:18:16.360
coefficients so for example when k equals two we have two vectors let's say v1 and v2

04:18:18.360 --> 04:18:29.320
then every such affine combination is of the form t v2 plus one minus t v1

04:18:29.320 --> 04:18:38.200
where t is a real number and you can look at what this says let's say these two vectors are

04:18:38.200 --> 04:18:47.560
different let's say v1 is here and v2 is here then at t equals zero so this right this is

04:18:47.560 --> 04:18:54.520
describing the set of all such combinations and when t equals zero this gives me v1 so at t equals

04:18:54.520 --> 04:19:04.040
zero i'm here and when t equals one i'm at v2 and as you vary t over the set of real numbers

04:19:04.680 --> 04:19:13.320
you get all the points along the straight line through v1 and v2 this is very different than

04:19:13.320 --> 04:19:19.240
the set of all linear combinations of v1 and v2 because if let's say the zero vector were here

04:19:19.240 --> 04:19:27.800
then v1 would be this corresponding vector v2 would be this corresponding vector and all

04:19:27.800 --> 04:19:36.200
linear combinations of these two vectors is actually the plane obtained from v1 and v2

04:19:37.880 --> 04:19:44.200
that's what the span of these two vectors are but all affine combinations is just this line

04:19:44.840 --> 04:19:53.720
and so just like we can define the span of vectors we can also define the affine span of vectors

04:19:54.520 --> 04:19:57.800
so the affine span

04:20:01.720 --> 04:20:08.200
of the vectors v1 through vk is and we denote it by aff

04:20:08.200 --> 04:20:20.200
and it's defined to be the set of all affine combinations so the set of all

04:20:22.440 --> 04:20:33.960
lambda j vj such that all of the lambda j's are in r and the sum of them equals one

04:20:38.440 --> 04:20:48.680
so let's look at another example where we take three vectors so let's say v1 v2 v3

04:20:50.120 --> 04:20:55.080
and let's just be concrete and let's say we're in r3 so that we can visualize this a little bit

04:20:55.080 --> 04:21:04.040
better so there are several cases that we can take just like for linear combinations for instance if

04:21:04.040 --> 04:21:08.120
one of these vectors was a linear combination of the other then the span of this would be a plane

04:21:08.520 --> 04:21:12.120
and if all of them are scaled on multiples of each other then the span is a line

04:21:12.680 --> 04:21:18.520
and if they are all the zero vector then we just get the zero vector and if they're all

04:21:18.520 --> 04:21:22.520
linearly independent then we get all of r3 there are many different cases depending on the

04:21:22.520 --> 04:21:29.240
relationships between v1 through v3 same thing happens for affine span in the sense that it

04:21:29.240 --> 04:21:33.080
depends on how these vectors are related so let's look at three possible cases

04:21:33.880 --> 04:21:39.400
so case one let's say v1 v2 and v3

04:21:41.480 --> 04:21:51.080
are not collinear so this means that all these three points don't lie on the same line so maybe

04:21:51.080 --> 04:21:57.080
they look something like this like for instance you can take the unit vectors e1 e2 and e3 and r3

04:21:57.320 --> 04:22:08.200
then the affine span of these three vectors is equal to the two-dimensional plane

04:22:11.960 --> 04:22:15.960
containing these vectors

04:22:21.000 --> 04:22:24.520
and it's not so immediately obvious that that's what happens but let's just

04:22:25.160 --> 04:22:31.400
think about this if we take v1 and v2 then it includes the affine span

04:22:33.240 --> 04:22:40.840
of these two vectors which means we have this line through these two vectors is in our affine span

04:22:40.840 --> 04:22:48.600
and likewise the line through v2 and v3 is here likewise the line v1 through v3 is here

04:22:49.720 --> 04:22:54.040
and now that we have all of these lines in here we can also take affine combinations of these points

04:22:54.600 --> 04:22:57.720
so you can take for instance the affine combination of this point with this point

04:22:57.720 --> 04:23:02.360
which gives us this line this point with this point which gives us this line

04:23:02.360 --> 04:23:06.360
and you can see by taking all such combinations all such affine combinations

04:23:06.360 --> 04:23:13.000
of these three vectors we can actually get any point in the plane that contains these three points

04:23:13.240 --> 04:23:17.480
in case two

04:23:20.040 --> 04:23:23.960
let's imagine that v1 v2 v3 are collinear

04:23:28.040 --> 04:23:28.280
but

04:23:31.240 --> 04:23:32.040
at least two

04:23:35.560 --> 04:23:36.280
are distinct

04:23:36.680 --> 04:23:46.120
so in this case so i'm assuming that at least two so either the possibilities are something like

04:23:46.120 --> 04:23:52.120
they're all different but they lie on the same line in which case the affine span of these three

04:23:52.120 --> 04:23:59.400
points is equal to the straight line through those two points those three points or the other

04:23:59.400 --> 04:24:06.040
cases the affine span if two of them happen to coincide then we just have two points

04:24:06.920 --> 04:24:12.360
but i'm assuming that they're collinear and at least two are distinct so we also get the

04:24:12.360 --> 04:24:18.360
straight line through those two points and the final case case three

04:24:20.680 --> 04:24:24.600
is when all those vectors are exactly the same vector

04:24:25.240 --> 04:24:34.600
and when this happens we only have a single point and all affine combinations of a single point

04:24:39.320 --> 04:24:44.840
is just that point itself so these are some of the basic constructions that you can do with

04:24:44.840 --> 04:24:50.120
vectors besides just taking linear combinations you can also take affine combinations there's yet

04:24:50.120 --> 04:24:56.200
another type which we won't discuss is if you require that the sum of these coefficients adds

04:24:56.200 --> 04:25:03.240
up to one but they're also not just real numbers but they're strictly non-negative so they have to

04:25:03.240 --> 04:25:09.160
be at least zero and that's called a convex combination which is a closely related idea

04:25:10.440 --> 04:25:16.760
and in the case of these three vectors for instance it would be the triangle

04:25:17.640 --> 04:25:26.920
who's three vertices are those three vectors that we had here and in this case if we took

04:25:26.920 --> 04:25:35.640
convex combinations it would be the interval between these two farthest end points and in this case

04:25:36.760 --> 04:25:41.560
we would have the same situation as we had here where we would just get a single point

04:25:42.440 --> 04:25:49.720
a common question that we ask given a set of vectors is if we have another vector when is

04:25:49.720 --> 04:25:55.800
that vector in the span of those vectors and this shows up for instance if we solve a homogeneous

04:25:55.800 --> 04:26:02.120
linear system and we have a bunch of solutions that we know are actually solving that system

04:26:02.120 --> 04:26:06.680
but let's say we don't know exactly what that system is we just know we have this collection of

04:26:06.680 --> 04:26:12.760
solutions and if somebody hands us another vector then we can ask is that vector

04:26:13.720 --> 04:26:19.080
a definitely a solution of the system that we have and in this case since we don't know the

04:26:19.080 --> 04:26:25.400
system we can't plug in that vector to check instead what we have to do is check if that vector is

04:26:25.400 --> 04:26:31.400
in the span of the vectors that we have already if that vector is in the span of the vectors that

04:26:31.400 --> 04:26:38.440
we already have then that vector is definitely a solution but it doesn't tell us that if it's not

04:26:38.440 --> 04:26:42.120
in the span of those vectors and it's not a solution because we might not have had

04:26:42.920 --> 04:26:47.480
a set of vectors that span the solution set but at the very least it gives us a criteria for

04:26:49.480 --> 04:26:56.360
guaranteeing that if that vector is in the span it's definitely a solution and likewise you can

04:26:56.360 --> 04:27:02.680
ask well if I have a bunch of vectors that I happen to know solve an inhomogeneous equation

04:27:02.680 --> 04:27:08.520
and somebody hands me another vector is there a similar criteria and there is and that involves

04:27:08.520 --> 04:27:15.080
the notion of affine span which we talked about in the last video so the question that we could

04:27:15.160 --> 04:27:26.200
ask is given vectors v1 through vk and another vector u in rn

04:27:28.280 --> 04:27:38.440
when is u in the affine span of these vectors v1 through vk

04:27:39.320 --> 04:27:47.560
now in order for us to solve this problem then we have to be able to write u as a linear combination

04:27:49.800 --> 04:28:00.920
of v1 through vk right but because it's an affine combination we have an additional

04:28:00.920 --> 04:28:07.720
constraint on what these coefficients could be and that constraint is that lambda 1 plus lambda k

04:28:09.320 --> 04:28:16.120
equals 1 which is also a linear system in the unknowns lambda 1 through lambda k

04:28:17.000 --> 04:28:22.360
and therefore if we want to solve this system this question is equivalent to

04:28:29.160 --> 04:28:37.240
the following one which is is the augmented matrix where we take our vectors v1 through vk

04:28:38.520 --> 04:28:44.600
and we can also write vk through vk through vk through vk through vk through vk through vk

04:28:44.600 --> 04:28:50.840
augmented with the vector u but in addition augment this further by one additional row

04:28:51.480 --> 04:28:59.880
stating that one equals so now this is the number one equals one dot dot dot one let me write this

04:28:59.880 --> 04:29:04.920
one so it's clear so this vector is just denoting the fact that it could have several entries

04:29:05.880 --> 04:29:11.480
so we have an additional row in our augmented matrix and the question is is this consistent

04:29:16.120 --> 04:29:19.560
so this is actually how we would solve such a problem and

04:29:21.960 --> 04:29:27.400
how does it show up in solving inhomogeneous systems we'll get to that after we talk about

04:29:27.400 --> 04:29:33.080
what an affine subspace is and the fact that the solution set of an inhomogeneous system

04:29:33.080 --> 04:29:38.440
is an affine subspace so for this let's just briefly recall

04:29:41.480 --> 04:29:48.760
a vector subspace i'll put vector usually in parentheses but a vector subspace

04:29:50.280 --> 04:29:58.120
of our n is a first of all a subset let's call it v

04:29:58.520 --> 04:30:06.200
such that three conditions hold now there are many equivalent ways to define such a thing

04:30:06.200 --> 04:30:13.640
but this one seems pretty concise and simple and the first condition is that the zero vector is in v

04:30:15.960 --> 04:30:22.440
the second condition is that if you take a vector in v and you scale it by any number

04:30:22.440 --> 04:30:31.160
then that scalar multiple is also in v so lambda v is in v provided that the vector v was in v to

04:30:31.160 --> 04:30:41.880
begin with and lambda is a real number and three the third condition is that if i take any two

04:30:41.880 --> 04:30:50.760
vectors in v then the sum of them are in v so let's write u plus v is in v for all pairs

04:30:50.760 --> 04:30:57.400
u and v that are already in v and this is what a vector subspace is

04:31:00.760 --> 04:31:07.800
now this definition of a vector space is a little bit algebraic it's telling us when

04:31:07.800 --> 04:31:13.400
certain vectors are in v and we can have a little bit more of a geometric interpretation of a what

04:31:13.400 --> 04:31:26.280
a vector subspace is by using affine combinations so equivalently v satisfies

04:31:28.120 --> 04:31:31.800
which means that if v satisfies the following conditions i'm about to write then it satisfies

04:31:31.800 --> 04:31:39.080
this one and conversely let's call it instead of i and two so let's use i because the first one's the

04:31:39.080 --> 04:31:45.320
same the zero vector is in v and the second condition which is sort of a combination of these

04:31:45.320 --> 04:32:00.040
two is that t u plus one minus t v is in v for all t in real numbers and for all u and v in v

04:32:02.040 --> 04:32:07.480
now this is exactly a linear combination of the vectors u and v so if i take two vectors u and v

04:32:08.280 --> 04:32:13.480
inside of v then this affine combination is describing the set of all points

04:32:14.280 --> 04:32:19.960
along the straight line through those two vectors so this is saying that a subspace

04:32:20.520 --> 04:32:28.120
can also be described as a plane that contains the zero vector and plane could mean hyper plane

04:32:28.120 --> 04:32:32.760
and this is because we always have the straight line through any two points in our subspace

04:32:33.320 --> 04:32:38.920
now the fact that we've written it this way allows us to define an affine subspace

04:32:39.640 --> 04:32:45.240
in a much more closely related fashion to this definition because for an affine subspace we'll

04:32:45.240 --> 04:32:53.240
only be able to combine combine vectors in an affine way so we define an affine subspace

04:32:53.800 --> 04:33:08.920
is a subset a of r n such that and now we drop this first condition so all we require

04:33:08.920 --> 04:33:16.600
is that affine combinations of two vectors are always inside so t u plus one minus t v

04:33:16.600 --> 04:33:21.320
are in v for all same conditions as here

04:33:24.280 --> 04:33:29.400
and you can ask well maybe an affine subspace should be if i take any collection of points

04:33:29.400 --> 04:33:35.720
inside of it then the affine span of those points is inside of v and that actually follows

04:33:35.720 --> 04:33:41.560
from this condition and the usual properties of scalar multiplication and vector spaces

04:33:41.560 --> 04:33:50.840
and how you add them so the main example that we want to illustrate is the solution set

04:33:54.200 --> 04:34:02.440
of any linear system ax equals b this is just notation for a linear system where b

04:34:03.240 --> 04:34:15.960
is a vector in r m and a is an m by n matrix

04:34:19.240 --> 04:34:24.040
so the solution set of this is an affine subspace

04:34:24.360 --> 04:34:31.000
of r n

04:34:34.360 --> 04:34:39.960
now the solution set of an inhomogeneous system is not a vector subspace because in

04:34:39.960 --> 04:34:47.160
general zero is not a solution in fact when zero is a solution then it exactly is a subspace

04:34:47.160 --> 04:34:52.040
and when zero is not a solution we get this more general notion of an affine subspace

04:34:52.600 --> 04:34:54.760
and it's a fact

04:34:57.960 --> 04:35:00.120
that affine subspaces

04:35:04.680 --> 04:35:05.800
are translates

04:35:09.160 --> 04:35:10.920
of vector subspaces

04:35:17.000 --> 04:35:18.280
and what do i mean by that

04:35:22.200 --> 04:35:28.280
a is an affine subspace

04:35:32.680 --> 04:35:41.960
if and only if there exists a vector v in r n such that if i take the subs

04:35:41.960 --> 04:35:50.280
if i take this affine subspace a and subtract v from it now what this means is the set of all

04:35:51.000 --> 04:35:55.720
vectors of the form u minus v where u is in a

04:36:01.240 --> 04:36:06.840
if this subset of r n is a subspace

04:36:09.320 --> 04:36:11.560
in this sense is a vector subspace

04:36:17.000 --> 04:36:17.720
in fact

04:36:21.240 --> 04:36:30.760
we can use any vector inside of a to translate it to the origin so in fact v

04:36:33.960 --> 04:36:40.840
will be a vector in a in fact any vector in a will make this a vector subspace

04:36:41.880 --> 04:36:44.600
so the picture for this is actually really nice

04:36:44.760 --> 04:36:52.520
i guess i shouldn't have called it a because i called this linear system a that may be

04:36:52.520 --> 04:37:00.200
potentially confusing so maybe let's call this script a so let me use a script a here

04:37:02.680 --> 04:37:11.000
and fortunately the letter a was only used in this one example but let me write it like this here

04:37:11.000 --> 04:37:16.120
so it's the same so there's no conflicting notation

04:37:18.520 --> 04:37:28.360
okay so here's our affine subspace a and if we take any vector in here let's call it u no let's

04:37:28.360 --> 04:37:38.280
call it v so v points from zero up to where that vector is and if we take this vector and we

04:37:38.280 --> 04:37:47.320
subtract it then v minus itself will be zero so i know that this plane is going to contain the zero

04:37:47.320 --> 04:37:56.680
vector and so here we have a minus v and no matter which v we picked right if we picked another one

04:37:58.920 --> 04:38:05.320
let's say we picked this vector right here let's call this one u then if we translate that

04:38:05.320 --> 04:38:09.320
u minus itself is zero so we also get this plane back as well

04:38:12.920 --> 04:38:15.240
and so a good application of this

04:38:18.520 --> 04:38:22.840
of this sort of mathematical object is

04:38:23.720 --> 04:38:37.480
if the vector xp p for particular is a solution to ax equals b for some linear system like in the

04:38:38.200 --> 04:38:50.600
previous example then the solution set meaning all the solutions of ax equals b

04:38:53.080 --> 04:39:00.840
is as we know the particular solution plus the homogeneous solution set so it's a set of all

04:39:01.560 --> 04:39:10.760
all sums of particular solutions with homogeneous solutions so axp solves the system this and

04:39:13.320 --> 04:39:23.000
ax homogeneous solves the associated homogeneous system so if a represented the solution set

04:39:23.000 --> 04:39:29.480
of an inhomogeneous system and a minus v represents the solution set of a homogeneous system and all

04:39:29.480 --> 04:39:35.880
we have to do is pick one of these solutions and then all of these solutions and then take that

04:39:35.880 --> 04:39:43.480
solution and translate it by that vector which was a particular solution of the inhomogeneous system

04:39:45.320 --> 04:39:50.520
just as we can define linear transformations which are functions that take linear combinations

04:39:50.520 --> 04:39:55.400
to linear combinations we can also define affine transformations and the idea is that

04:39:55.400 --> 04:40:01.000
they take affine combinations to affine combinations which translates geometrically to

04:40:01.000 --> 04:40:08.360
it takes lines or hyperplanes to other lines and hyperplanes as well so the definition

04:40:09.400 --> 04:40:12.360
of an affine transformation is exactly that

04:40:12.520 --> 04:40:32.120
an affine transformation in this case from rn to rm is a function first and foremost

04:40:33.000 --> 04:40:40.680
and i will write my arrows as usual from right to left so it's a function let's call it s

04:40:42.840 --> 04:40:43.480
such that

04:40:46.920 --> 04:41:03.000
s of lambda u plus 1 minus lambda v is equal to lambda s of u plus 1 minus lambda s of v for all

04:41:03.400 --> 04:41:17.880
u and v in rn and for all lambda in r and it's a consequence of this definition that if we take any

04:41:17.880 --> 04:41:23.480
affine transfer if we take any affine combination of vectors then s of that affine combination

04:41:24.440 --> 04:41:25.240
is going to be

04:41:27.720 --> 04:41:31.560
the affine combination of s applied to each of those vectors

04:41:33.480 --> 04:41:51.160
this is a little less obvious than it is if you take linear transformations and you show that

04:41:51.160 --> 04:41:56.120
it follows from the assumptions of a linear transformation that it takes linear combinations

04:41:56.120 --> 04:42:04.040
to linear combinations and the reason it's a little bit slightly more challenging is that

04:42:04.040 --> 04:42:09.480
if you apply this in a binary fashion right if you take two vectors u and v so you think of this

04:42:09.480 --> 04:42:17.560
as a function from let's say r cross r to the n cross r to the n to r to the m then in order to

04:42:17.560 --> 04:42:23.000
apply this here you have to put parentheses in an appropriate place but in order to have an affine

04:42:23.080 --> 04:42:28.200
combination with the appropriate parentheses you have to be a little bit careful about what

04:42:28.200 --> 04:42:34.040
your resulting coefficients are and it's not so easy to see how to do that but it can be done

04:42:37.800 --> 04:42:42.760
and here's the example that I really like to think of when comparing linear transformations

04:42:42.760 --> 04:42:49.960
to affine transformations and things you might have seen from a while back not in my lectures but

04:42:49.960 --> 04:42:57.240
in your early learnings of math perhaps so if we take the usual equation of the form

04:42:57.240 --> 04:43:06.040
y of x equals mx plus b where m and b are both real numbers and x is a variable

04:43:07.480 --> 04:43:11.880
and y is the function of x then this is an affine

04:43:11.880 --> 04:43:16.120
transformation

04:43:18.600 --> 04:43:25.960
from r to r because it takes a real number r x and it gives us another real number

04:43:27.640 --> 04:43:28.680
and it's linear

04:43:33.000 --> 04:43:39.240
if and only if b equals zero linear in the sense of being a linear transformation

04:43:39.240 --> 04:43:46.760
so this will help you perhaps relate the difference between an affine transformation

04:43:46.760 --> 04:43:52.360
and a linear one and we'll later talk about a theorem that relates the two exactly together

04:43:53.720 --> 04:44:02.840
in fact we'll state that theorem now so the theorem says the following are equivalent for a function

04:44:05.880 --> 04:44:07.320
now we're just describing a function

04:44:09.800 --> 04:44:17.640
and these conditions are that s is affine is an affine transformation

04:44:19.800 --> 04:44:23.960
so i'm not assuming any linearity this is just an ordinary function so s is affine

04:44:25.560 --> 04:44:36.120
if i take the function s and subtract s of zero from it so if i take s minus s of zero

04:44:36.120 --> 04:44:40.920
now this is a function in the sense that if i take any x the function associated to this is

04:44:40.920 --> 04:44:50.360
defined by s of x minus s is s of zero so this is also a function from r into rm if this is linear

04:44:50.680 --> 04:44:53.480
and c

04:44:56.120 --> 04:44:59.000
there exists an m by n matrix

04:45:02.600 --> 04:45:06.280
m and a vector b

04:45:10.040 --> 04:45:17.800
in rm such that s of x equals mx plus b

04:45:20.680 --> 04:45:27.160
and the reason i mentioned this example is precisely because of this theorem because it allows us to relate

04:45:29.160 --> 04:45:34.280
linear transfer affine transformations to transformations that we may have seen a long

04:45:34.280 --> 04:45:40.680
time ago and i personally think it's instructive to prove this theorem to get a feeling for how

04:45:40.680 --> 04:45:47.880
affine combinations work so let's actually prove it and we'll prove this by proving a implies b

04:45:47.880 --> 04:45:56.120
implies c implies a so for the first part of this proof we're going to define we i don't want to

04:45:56.120 --> 04:46:04.040
keep writing s minus s of zero so we're going to define l to be this function s minus s of zero

04:46:07.400 --> 04:46:13.080
and the goal is to prove that this function is linear so we have to check the associated

04:46:13.080 --> 04:46:20.280
conditions for linearity and before we do that let's just establish that if we apply zero to l

04:46:20.840 --> 04:46:26.280
if we apply l to zero then we get exactly zero because this is s of zero minus s of zero so it

04:46:26.280 --> 04:46:32.120
definitely preserved zero and we know that this doesn't give us a sufficient condition for linearity

04:46:32.120 --> 04:46:41.480
but it's definitely necessary so second if we take a coefficient lambda any real number lambda

04:46:41.560 --> 04:46:50.520
and if we take a vector u that's inside of our n then by this definition this is s of lambda u

04:46:51.560 --> 04:47:04.120
minus s of zero and this is an interesting combination of lambda u and zero this also

04:47:04.120 --> 04:47:13.560
equals s of lambda u plus one minus lambda of the zero vector right the zero vector is in the domain

04:47:13.560 --> 04:47:19.400
of s and so i can multiply by any number and i still get zero and now the interesting thing

04:47:19.400 --> 04:47:24.600
about this is that this is an affine combination of the vectors u and zero so that's what this

04:47:24.600 --> 04:47:31.960
term is and this just comes along for the ride because s is affine i can take these coefficients

04:47:31.960 --> 04:47:35.720
out

04:47:39.320 --> 04:47:47.960
and this is also an affine combination of itself so i can write minus lambda s of zero

04:47:48.840 --> 04:47:52.120
minus one minus lambda s of zero

04:47:55.000 --> 04:48:00.360
and so what do we have we have lambda of s of u in parentheses minus s of zero

04:48:00.440 --> 04:48:05.800
which is exactly l of u and these two terms cancel so we're left over with lambda

04:48:07.080 --> 04:48:13.000
l of u when we're done with this calculation so it's linear in this it's the first condition

04:48:13.000 --> 04:48:17.880
of linearity is proven and the second condition is if we take a linear combination

04:48:19.880 --> 04:48:26.040
this also has to go to a linear combination as well so let's just use the definition this is s of

04:48:26.040 --> 04:48:35.000
u plus v minus s of zero and now let's draw a picture here because this is going to help

04:48:35.000 --> 04:48:41.720
let's say we have the vector u here and the vector v here and this is the zero vector

04:48:43.240 --> 04:48:48.280
now the vector u plus v is somewhere here

04:48:49.240 --> 04:49:00.040
now can we express u plus v as some convenient affine combination of vectors for which we know what s

04:49:00.040 --> 04:49:09.640
does to those vectors well if we extend u so we take combinations of u and combinations of v

04:49:11.000 --> 04:49:16.120
then u plus v can be written as an affine combination of some multiple of u and some

04:49:16.120 --> 04:49:20.760
multiple of v in fact it can be written like that in many ways all i have to do is pick any

04:49:20.760 --> 04:49:28.520
point here and draw the straight line through this point and u plus v and then find out what

04:49:28.520 --> 04:49:35.160
that vector is or we can take a simple shortcut and just notice that if we multiply this by two

04:49:36.120 --> 04:49:38.200
this by two then

04:49:41.320 --> 04:49:49.000
those two points to u and to v are on the same line that goes are on the line that goes through

04:49:49.000 --> 04:49:54.920
u plus v and how do i know that well if i take half of this and half of this i get exactly this

04:49:54.920 --> 04:50:05.480
and half and half is an affine combination so this equals s of one half to u plus one half

04:50:05.480 --> 04:50:14.680
to v minus s of zero and because this is an affine combination we have one half s of two u

04:50:15.080 --> 04:50:24.600
plus one half s of two v and now we can also subtract half of s of zero here

04:50:27.480 --> 04:50:35.160
minus one half s of zero again and now one half is a common factor here so this gives us one half

04:50:35.880 --> 04:50:47.000
l of two u plus one half l of two v but by the thing we just proved we know that we can pull out

04:50:47.000 --> 04:50:57.480
scalars from l so this gives us l of u plus l of v and this together proves the linearity

04:50:57.480 --> 04:51:03.720
so this is the proof that a implies b but if we have an affine transformation we subtract

04:51:03.720 --> 04:51:10.440
by what it applies to when you plug in zero then we get a linear transformation now the rest of

04:51:10.440 --> 04:51:22.920
the proof is actually not bad afterwards because for b implies c if we have a linear transformation

04:51:22.920 --> 04:51:28.440
we already know we have a matrix corresponding to it so because l is linear

04:51:29.320 --> 04:51:34.360
we get an m by m matrix

04:51:38.680 --> 04:51:40.840
such that l of x equals m of x

04:51:43.080 --> 04:51:49.960
equals m times x for all x in the domain of s which is r n

04:51:50.600 --> 04:52:07.240
so set b to be equal to s of zero and when we make when we set that to be that then since l is

04:52:07.240 --> 04:52:17.720
s minus s of zero then we take s equals l plus s zero which is b then we get y then we get the

04:52:17.720 --> 04:52:25.560
equation of the form s of x equals m x plus b so that that's what how b implies c and then

04:52:25.560 --> 04:52:31.000
if we have c to imply a this is much much it's very similar to these kinds of calculations of

04:52:31.000 --> 04:52:40.520
taking affine combinations if we take s of like let's say lambda u plus one minus lambda v plug

04:52:40.520 --> 04:52:45.400
that in here we know m acts in a linear way this is a matrix we apply matrix multiplication

04:52:45.400 --> 04:52:50.920
distributivity associativity of all these properties of addition of vectors and scalar

04:52:50.920 --> 04:52:59.880
multiplication of vectors in r m and we get that s is affine from this assumption so these three

04:52:59.880 --> 04:53:07.720
conditions are equivalent for any function from r n to r m that characterize what it means for

04:53:07.800 --> 04:53:15.400
transformation to be affine as we know functions can be composed provided that the domains and

04:53:15.400 --> 04:53:22.280
codomains of these functions match up similarly affine transformations compose and the composition

04:53:22.280 --> 04:53:27.720
is affine in an analogous way to how linear combinations are composed and the resulting

04:53:27.800 --> 04:53:39.080
composition is also linear so we have a fact and this fact is that the composition

04:53:50.280 --> 04:53:53.560
of two affine transformations s and t

04:53:57.880 --> 04:54:02.600
is also affine

04:54:08.920 --> 04:54:14.680
and because it's affine and we know that each of these transformations can be written in the form

04:54:14.680 --> 04:54:20.600
of mx plus b for some appropriate matrices and appropriate vectors b we can ask what is the

04:54:20.600 --> 04:54:26.920
resulting matrix for what is what are the resulting matrices and vectors for the composition

04:54:27.000 --> 04:54:43.800
of two affine transformations so let's write s of x as mx plus b and t of y as nx plus ny plus c

04:54:48.760 --> 04:54:55.800
and let's just be careful about composing these so if we take the composition s composed with t

04:54:56.920 --> 04:55:03.160
and we apply a vector y then this by definition is s applied to t of y

04:55:05.880 --> 04:55:07.480
and we know that t is of this form

04:55:11.400 --> 04:55:12.920
so we get ny plus c

04:55:13.560 --> 04:55:25.800
and this equals m times the input of this function which is ny

04:55:30.040 --> 04:55:36.360
plus c plus the associated b oh this should be a plus from the transformation s

04:55:37.080 --> 04:55:41.720
and if you distribute this all out we get mn

04:55:46.360 --> 04:55:47.000
times y

04:55:49.320 --> 04:55:59.000
plus mc plus b so the associated matrix that we get is actually just the multiplication of

04:55:59.000 --> 04:56:05.560
the matrices that we started with and the associated vector b is some interesting combination

04:56:05.560 --> 04:56:13.560
of the original vectors b and c but also with the matrix m and in particular

04:56:19.720 --> 04:56:30.840
if s from same setup rm rn to rm is invertible

04:56:31.560 --> 04:56:39.240
and we wrote our decomposition like this then we could ask what are the matrices and vectors

04:56:39.240 --> 04:56:44.520
associated to the inverse of this matrix and that is exactly

04:56:47.800 --> 04:56:51.400
so s inverse let's write of y just because we're changing the

04:56:52.200 --> 04:57:00.520
codomains with the domains we get the inverse of m plus well rather minus

04:57:01.320 --> 04:57:08.840
m inverse of the vector b and why does this work well if you just take s for instance and you

04:57:08.840 --> 04:57:13.880
apply it to this result we know what this combination looks like we get m applied to this term which

04:57:13.880 --> 04:57:19.480
gives us just y back m applied to this term which gives us negative b but we have a plus b and those

04:57:19.480 --> 04:57:26.840
two cancel so just like the composition of linear transformations need not commute similarly the

04:57:26.840 --> 04:57:31.560
composition of affine transformations need not commute so let's look at an example

04:57:34.120 --> 04:57:41.080
and a common affine transformation is leave everything alone just translate by some vector

04:57:41.080 --> 04:57:45.480
so let's just keep things very simple and let's assume that we translate by the vector

04:57:45.480 --> 04:57:48.360
one zero so we shift everything along the x axis

04:57:50.760 --> 04:57:57.160
in r2 so we shift everything along the x axis so let's say the vector let's draw a smiley face here

04:57:58.600 --> 04:58:03.320
this smiley face transforms under this transformation let's say smiley face is it

04:58:03.320 --> 04:58:08.200
contained in the unit box so i have to make this a little bit bigger and it gets translated along the

04:58:08.200 --> 04:58:13.400
x axis in the positive direction so let's call this transformation t

04:58:15.480 --> 04:58:19.080
another transformation that we can look at let's call this one s

04:58:21.320 --> 04:58:29.080
is rotation by 90 degrees so when we rotate the face looks something like this

04:58:30.600 --> 04:58:37.000
and then we can ask what happens when we apply s and t in that order or if we apply t then s

04:58:37.720 --> 04:58:41.560
and what are the matrices and vectors associated to these transformations let's actually answer

04:58:41.560 --> 04:58:49.560
that question first so t of any vector x equals well it's just translate so it says

04:58:49.560 --> 04:58:55.480
leave everything in the plane alone so that's the matrix corresponding to the identity and

04:58:55.480 --> 04:59:02.520
shift by the unit vector in the x direction so i call that e1 so remember e1 equals the vector

04:59:03.480 --> 04:59:14.200
1 0 and s of x is the transformation that rotates by 90 degrees so i'm going to write

04:59:14.200 --> 04:59:23.080
that in matrix form because rotation by 90 degrees is 0 negative 1 1 0 applied to the

04:59:23.080 --> 04:59:29.640
vector x and the b here is 0 because this is in actually this is actually a linear transformation

04:59:30.600 --> 04:59:38.680
so what happens when we compose these in different orders so let's just think about this imagine

04:59:38.680 --> 04:59:47.320
you translate first and then you rotate this rotation is occurring about the origin so when

04:59:47.320 --> 04:59:54.120
we apply t first and then we apply s again we're rotating this picture by 90 degrees with respect

04:59:54.120 --> 04:59:59.160
to this origin so this face is actually going to be further out than it would have been if we

04:59:59.560 --> 05:00:04.280
applied the transfer if we apply the rotation initially and then translated you can already

05:00:04.280 --> 05:00:14.120
see the big difference between these two pictures so if we apply first t and s apply to this picture

05:00:14.120 --> 05:00:21.480
let's start with our initial configuration that what happens after you apply this will first you

05:00:21.480 --> 05:00:27.400
rotate and then you translate so this translates everything to something that looks like this

05:00:27.560 --> 05:00:36.120
but if instead we applied s after t to the same initial configuration

05:00:38.360 --> 05:00:43.080
well first we would translate and then we would rotate by 90 degrees that would look

05:00:43.080 --> 05:00:46.600
much much different so if i were to draw this as a unit grid

05:00:48.760 --> 05:00:54.680
that face would now be in this box rotated by 90 degrees so it looks something like that

05:00:54.680 --> 05:01:01.800
so now let's just check the math out to make sure that this is consistent with these geometric

05:01:01.800 --> 05:01:08.760
interpretations so if we apply t after s to any vector x

05:01:11.560 --> 05:01:19.320
what do we get well t says first translate then rotate so we end up translating by x

05:01:19.880 --> 05:01:29.320
then rotating because we do matrix multiplication and the resulting vector b is just e1 so we get

05:01:29.320 --> 05:01:40.280
rotation apply to x plus e1 which is exactly what we expected from our picture here if we did it in

05:01:40.280 --> 05:01:49.960
the other order well in that case first we translate and then we rotate and when we rotate

05:01:49.960 --> 05:01:54.920
we not only apply the rotation to our initial vector x but we also apply the rotation to the

05:01:54.920 --> 05:02:03.000
vector e1 and e1 gets rotated by a 90 degree rotation to the vector e2 so in this case we get

05:02:03.560 --> 05:02:16.680
this instead so and this is consistent with this picture because if we rotate first our face ends

05:02:16.680 --> 05:02:21.160
up somewhere here like in this picture and then how do we get from this picture to this one we

05:02:21.160 --> 05:02:30.360
translate up by a unit vector by the unit vector e2 the next few videos are going to be a sort of

05:02:30.440 --> 05:02:37.800
combination of probability theory and matrix algebra and we'll start by talking about finite

05:02:37.800 --> 05:02:42.760
sets and stochastic matrices or what I call stochastic maps and we'll try to get through

05:02:42.760 --> 05:02:50.040
a lot of interesting topics so first I just want to make sure that we have all these definitions

05:02:50.040 --> 05:02:55.800
at hand and the first one that I want to make is a probability measure

05:02:59.720 --> 05:03:06.680
and for simplicity we will be working with finite sets all the time so a probability measure on x

05:03:06.680 --> 05:03:18.040
where here x is a finite set is a function that takes every element of x and it gives me a number

05:03:18.440 --> 05:03:23.800
and that number is between 0 and 1 and the sum of these numbers

05:03:28.040 --> 05:03:33.800
when I sum over all elements in x and let me just set notation that when I apply this probability

05:03:33.800 --> 05:03:40.840
measure to x instead of writing p of x I will write p subscript x so such that the sum of these

05:03:40.840 --> 05:03:49.000
numbers equals 1 and a stochastic map is something very similar to this

05:03:58.120 --> 05:04:02.760
ah and let me even set some more notation the set of all probability measures

05:04:02.760 --> 05:04:15.880
on x is denoted by px

05:04:18.200 --> 05:04:27.720
so a stochastic map from x to y so another finite set is a function

05:04:27.720 --> 05:04:41.000
from x to probability measures on y let's call that f and

05:04:43.400 --> 05:04:48.760
we're going to introduce a convenient notation for such stochastic maps

05:04:50.200 --> 05:04:56.280
so first let's explain a convenient notation for how to write f so if we take an element x

05:04:56.280 --> 05:05:02.760
and we apply it we'll get a probability measure on y for now let's just call this f of x

05:05:03.960 --> 05:05:08.920
because this is a probability measure it takes an element y and y and gives me a number between

05:05:08.920 --> 05:05:21.720
0 and 1 so this takes an element y and maps it to f of x of y now it's a little bit annoying

05:05:21.720 --> 05:05:26.680
to write something like this and potentially confusing so instead of writing this we will write

05:05:27.720 --> 05:05:35.240
f subscript y x and the reason we write the y on the left is because we will end up in y

05:05:35.880 --> 05:05:40.840
and x on the right because we started in x we'll see why this is convenient in a moment when we

05:05:40.840 --> 05:05:47.880
talk about composition of stochastic maps and we'll also introduce graphical notation for this

05:05:52.680 --> 05:05:59.640
instead of writing a map from x to py we will replace this by a map from x to y

05:06:00.680 --> 05:06:07.320
but we'll use slightly different notation for our arrows and we'll make them squiggly arrows like this

05:06:10.920 --> 05:06:17.080
and the reason we want to do this is because there's a very nice example of a stochastic map

05:06:17.800 --> 05:06:23.400
if we have a function so if x to y is a function

05:06:26.760 --> 05:06:29.320
this actually gives us a natural stochastic map

05:06:35.560 --> 05:06:40.520
and just for this example we'll call it delta f oops these should be squiggly arrows now

05:06:40.520 --> 05:06:51.400
so delta f to y which sends an element x to a probability measure on y and what should that

05:06:51.400 --> 05:06:57.720
probability measure be well if i take let's call this delta f for now if i take an element in y

05:06:58.920 --> 05:07:04.280
and i plug in our initial element x so again we're using this notation here then this is

05:07:04.280 --> 05:07:13.560
defined to be the chronicer delta so if we take the element x apply f to it we know what that is

05:07:13.560 --> 05:07:19.800
because we have a function already and then we plug in y so visually how do i think of something

05:07:19.800 --> 05:07:26.440
like this well a stochastic map is telling us if we start off in x let me draw the arrows

05:07:26.440 --> 05:07:33.320
backwards for a moment then it takes an element in x and it spreads that element out over y by

05:07:33.320 --> 05:07:40.040
giving us a probability distribution on y but if we already have a function then we know where

05:07:40.040 --> 05:07:47.560
that element x goes it goes to a specific element which we call f of x and therefore it does give

05:07:47.560 --> 05:07:54.840
us a probability distribution and that probability distribution is one when we evaluated at f of x

05:07:54.840 --> 05:08:01.400
and zero everywhere else so i think of this as a deterministic process in some sense because we know

05:08:01.400 --> 05:08:07.960
given an input we know exactly what the output would be with 100 probability

05:08:09.640 --> 05:08:15.880
so we notice that there's this close relationship between functions and stochastic maps in fact

05:08:15.880 --> 05:08:20.760
functions are special kinds of stochastic maps and instead of writing delta f all the time

05:08:20.760 --> 05:08:31.160
we'll simply write xf and we will think of this as a stochastic map but we'll write it as a straight

05:08:31.160 --> 05:08:36.520
arrow another example

05:08:41.000 --> 05:08:46.760
there is a one-to-one correspondence between

05:08:49.080 --> 05:08:50.280
stochastic maps

05:08:50.760 --> 05:09:02.040
from a single element set into another finite set x so this is going to be my notation for

05:09:02.040 --> 05:09:10.120
a set containing a single element which i'm just calling bullet and probability measures

05:09:10.120 --> 05:09:22.840
on x why is that well if i have a stochastic map i apply an element of it i apply it to an element

05:09:22.840 --> 05:09:27.720
of the domain and that gives me a probability measure on x but this only has one element

05:09:27.720 --> 05:09:32.440
so i only get one probability measure so in general a stochastic map is you can think of

05:09:32.440 --> 05:09:37.960
it as a family of probability measures indexed by the domain of that stochastic map

05:09:40.120 --> 05:09:43.080
stochastic maps define conditional probabilities

05:09:51.160 --> 05:09:55.560
or at least some kind of restricted notion of conditional probabilities

05:09:55.880 --> 05:10:14.520
and the reason is because f y x you can think of this as the probability of y occurring given

05:10:14.520 --> 05:10:24.920
that x has occurred and you can if you know if you have a definition of conditional probability

05:10:24.920 --> 05:10:30.920
and you are looking at single element events then this definition coincides with the one

05:10:30.920 --> 05:10:37.880
you're thinking of for finite sets and again single element events but if you're not then

05:10:37.880 --> 05:10:45.640
we're going to think of this as our notion of a conditional probability so for being very concrete

05:10:47.080 --> 05:10:53.320
let's take x to be the set whose elements are so pick your favorite supermarket

05:10:53.320 --> 05:10:57.240
and let's say there's a good sale at that supermarket

05:11:01.160 --> 05:11:05.480
and let me think of that as one element of this set x and the other element is going to be

05:11:07.400 --> 05:11:13.640
a not great sale or a not good sale at that same supermarket so two elements

05:11:13.640 --> 05:11:18.360
and let y be

05:11:21.080 --> 05:11:26.040
the elements that state whether I go to the supermarket this week or you go or whatever

05:11:26.040 --> 05:11:35.960
or I don't go so I go to the supermarket let's say this week or something like that or I don't go

05:11:43.800 --> 05:11:45.880
and let's say if there's a good sale

05:11:49.880 --> 05:11:56.360
let's say the probability right because I might have a lot of food stocked in my pantry I may or

05:11:56.360 --> 05:12:01.720
may not go to the grocery store this week but if there's a good sale maybe there's a good chance

05:12:01.720 --> 05:12:06.920
that I'll go let's say there's a 90% chance that I'll go

05:12:11.640 --> 05:12:18.920
and if there isn't a good sale well it might be that I still need to get food so there's

05:12:18.920 --> 05:12:25.320
still going to be some chance that I go but perhaps it'll be less I'll be less enticed to go to that

05:12:25.400 --> 05:12:30.680
supermarket this week let's just say that there is a 60% chance I'll go

05:12:35.880 --> 05:12:42.760
and with this information we can define a stochastic map from x to y so this actually

05:12:42.760 --> 05:12:47.720
defines the stochastic map and we'll come back to this in several examples that we'll look at

05:12:48.440 --> 05:12:53.880
later on because it's a nice simple example and the reason you can figure out what the rest of

05:12:53.880 --> 05:12:59.000
this is is just by using probabilities because if there is a good sale the chance that I go

05:12:59.000 --> 05:13:03.640
is 90% then there's a 10% chance I won't go and conversely if there isn't a good sale then there's

05:13:03.640 --> 05:13:13.160
a 40% chance I don't go so that defines this stochastic map just like with functions we can

05:13:13.160 --> 05:13:19.320
compose stochastic maps as well but this is going to have a really nice picture so I rather

05:13:19.320 --> 05:13:25.320
give that its own video and we'll talk about compositions in a moment all right so if we

05:13:25.320 --> 05:13:34.280
have two finite sets rather three finite sets x y and z and a stochastic maps between them

05:13:35.640 --> 05:13:41.800
in such a way so that the codomain of f lines up with the domain of g and I really mean source

05:13:41.800 --> 05:13:47.240
and target here because again if I really think of x as a function it's a map from x to probability

05:13:47.240 --> 05:13:53.400
measures on y but the domain of g is not probability measures on y it's y itself so it's really

05:13:53.400 --> 05:13:59.160
better to think of this a little bit categorically where I'm thinking of the target of f and the

05:13:59.160 --> 05:14:13.320
source of g so given this given stochastic maps we can define a composition of these two and before

05:14:13.320 --> 05:14:21.080
I write down the formula let's think about how we would do this so here's x here's y here's z

05:14:24.680 --> 05:14:33.560
what we want to define is an ocean of composition which is determined by if I give if you give me

05:14:33.560 --> 05:14:42.600
an element in x and you give me an element in z I want to know given x what is the probability

05:14:42.600 --> 05:14:52.040
that z occurs and there's an intermediary y here so the way that you get that is well I look at

05:14:52.040 --> 05:15:00.280
all the elements of y and I look at given x what is the probability of that element y occurring

05:15:00.280 --> 05:15:07.560
let's call this let's say that this is the element y then this is f y x so given x the probability

05:15:07.560 --> 05:15:13.960
that y occurs and going from y what's the probability that z occurs that also has a probability which

05:15:13.960 --> 05:15:23.880
is gzy and so the probability of given x the probability of z given x is taking all of these

05:15:23.880 --> 05:15:32.440
probabilities by varying y and multiplying the corresponding ones when they match up and then

05:15:32.520 --> 05:15:38.360
adding them all so this is defined to be the sum over all elements in y

05:15:40.920 --> 05:15:50.920
with their respective probabilities gzy f y x so this is what the composition of

05:15:53.080 --> 05:15:56.920
stochastic maps is

05:16:03.160 --> 05:16:13.640
and now you can see why I chose this notation earlier of writing our subscripts in this particular

05:16:13.640 --> 05:16:19.720
order because if I think of these as matrices indexed by the elements of these sets that we

05:16:19.720 --> 05:16:25.720
have then this ends up just being matrix multiplication so sometimes these are also

05:16:25.720 --> 05:16:31.080
called stochastic matrices but I'm going to stick to the calling them stochastic maps

05:16:33.160 --> 05:16:39.800
so let's look at some interesting special cases of this definition so first let's look at the

05:16:39.800 --> 05:16:48.600
special case where x is replaced by a single element set y is a set x and g is a function

05:16:48.600 --> 05:16:58.120
not just a stochastic map so let's take this special example so let's take y a function f

05:16:58.120 --> 05:17:09.560
and a probability measure on x so first of all what is a probability measure on x look like

05:17:09.560 --> 05:17:15.000
well if I think of x as a set so let's draw some of the elements of x here

05:17:19.320 --> 05:17:25.640
let's say here we have nine elements a probability measure sort of gives me a size

05:17:25.720 --> 05:17:33.080
to each of these elements so I can think of these as water droplets each with a specific size

05:17:38.680 --> 05:17:39.640
namely the volume

05:17:42.440 --> 05:17:48.200
so this is sort of what a generic x looks like with a probability measure on it

05:17:49.080 --> 05:17:52.840
and the sum of the volumes of these water droplets is equal to one

05:17:52.840 --> 05:18:03.720
now if I have a function f from y to x then the composite here gives me a probability measure on

05:18:03.720 --> 05:18:10.840
y what is that probability measure well if I just use the definition

05:18:13.960 --> 05:18:21.160
p followed by f and I evaluated at y this is equal to just straight from the definition

05:18:21.160 --> 05:18:31.000
we know that this is the sum over all elements in x of the function on the left which is f

05:18:31.000 --> 05:18:38.840
but f is a function so we know that it corresponds to the direct delta the chronicle delta f

05:18:41.320 --> 05:18:50.600
y f of x with the probability measure px now if I substitute what this looks like this says

05:18:50.600 --> 05:18:56.600
this only gives me a non-zero contribution if f of x equals y in other words if y

05:18:57.640 --> 05:19:04.040
is in the image of f of x is in the image of f and it comes from some x so if we look at the

05:19:04.040 --> 05:19:09.480
inverse image of y that's going to give me a bunch of elements and that's the only case where this

05:19:09.480 --> 05:19:17.160
gives me a non-zero contribution and what that means is that this breaks down into the sum of all

05:19:17.160 --> 05:19:27.720
elements x in the inverse image of y so here we have the sum of all the px's that are in the

05:19:27.720 --> 05:19:35.160
inverse image of an element y so let's look at this element y here the inverse image of this

05:19:35.160 --> 05:19:44.280
under a map f so let's imagine that f identifies all the elements that are in the vertical direction

05:19:45.000 --> 05:19:51.480
so right because a function f might not be one to one so it might identify some of the elements

05:19:51.480 --> 05:19:56.440
and that's why I've drawn it this way it takes these four elements and gives me the single output y

05:19:58.040 --> 05:20:05.320
and these two elements gives me another output and what this condition says is that the probability

05:20:06.920 --> 05:20:12.280
here is the sum of these probabilities in other words the volume of this water droplet is the

05:20:12.280 --> 05:20:18.440
sum of the volumes of those water droplets likewise here in order to make the volume somewhat

05:20:18.440 --> 05:20:24.440
geometrically similar to these this would be the resulting volume after we apply this function f

05:20:24.440 --> 05:20:32.440
and here maybe it's this big so this gives us a nice picture of what compositions like this look like

05:20:34.120 --> 05:20:40.120
it essentially says that we take these water droplets and then we combine them and when you

05:20:40.120 --> 05:20:46.680
combine the associated water droplets their volumes add as another example let's go back to

05:20:46.680 --> 05:20:51.560
our previous situation in fact let me write that example here because it's a little bit it can fit

05:20:51.560 --> 05:20:59.000
here so in this case we had that set x to be there's a good sale at the supermarket this week and

05:20:59.000 --> 05:21:06.520
there's not a good sale and the set y is I go to the supermarket or I don't now what if we happen to

05:21:06.520 --> 05:21:13.000
know the statistics or the probabilities of whether there is a good sale or not at the specific

05:21:13.000 --> 05:21:18.760
supermarket given that specific week so you compile all of your data over the course of a year for

05:21:18.760 --> 05:21:23.960
instance and you just ignore the seasons you ignore the months you just look at when is there a good

05:21:23.960 --> 05:21:31.160
sale for whatever definition of good you might have for for you and let's just say that the

05:21:31.160 --> 05:21:41.720
probability of a good sale is maybe only 30 percent so roughly 30 percent of the time there's a good

05:21:41.720 --> 05:21:49.240
sale on a given week and therefore the probability of a not so good sale is 70 percent and so you

05:21:49.240 --> 05:21:57.080
might ask what is the probability that I go to the supermarket question mark so that's the end of

05:21:57.080 --> 05:22:02.360
the statement so all we know is that if there's a good sale we already know what those probabilities

05:22:02.360 --> 05:22:07.880
are I think they were 90 percent and if there is a good sale and 60 percent if there isn't a good sale

05:22:08.760 --> 05:22:13.400
because I still need to eat and if we happen to know the probability that there's a good sale

05:22:14.360 --> 05:22:21.960
and therefore the probability of there being a bad sale or not good rather is 70 percent

05:22:22.920 --> 05:22:26.040
then you could still ask what is the probability that I actually end up going

05:22:27.720 --> 05:22:32.840
and that's where this composition comes in where instead of having an f like this

05:22:34.200 --> 05:22:38.680
we instead have our f from our previous example but we also know the probabilities

05:22:38.680 --> 05:22:42.840
of whether or not there's a good sale so it's a slight generalization of this example

05:22:43.880 --> 05:22:46.200
and therefore the probability that I go

05:22:46.760 --> 05:22:56.440
to the supermarket is equal to and in this case I'm going to take the probability

05:22:57.720 --> 05:23:05.000
that there is a good sale times the probability that I go given that there's a good sale plus

05:23:05.720 --> 05:23:12.280
so let me actually write that one down so that's 90 percent times 30 percent the probability that

05:23:12.360 --> 05:23:17.240
there's a good sale times the probability that I go plus the probability that there isn't a good

05:23:17.240 --> 05:23:23.480
sale but I still go and the probability that I go given that there isn't a good sale is 60 percent

05:23:23.480 --> 05:23:29.960
and the probability that there is not a good sale is 70 percent and the resulting probability

05:23:29.960 --> 05:23:39.560
that I go is 69 percent so given those statistics we still know that if I just chose an arbitrary

05:23:39.560 --> 05:23:44.120
week in the year there's a 69 chance that I'll go to the supermarket that week

05:23:46.600 --> 05:23:50.360
so now let's look at another example and this example again will come back

05:23:50.920 --> 05:23:56.280
will come back to this perhaps a few more times so now let's look at another example

05:23:56.840 --> 05:24:02.840
this one may seem a little bit abstract but it's a very useful one anyway

05:24:03.800 --> 05:24:11.720
so let's take the diagonal map from x to x cross x what this does is it takes an element x

05:24:13.320 --> 05:24:18.680
so far we've talked about stochastic maps and how to compose them and how to view ordinary

05:24:18.680 --> 05:24:24.360
functions as specific examples of stochastic maps what we'll do now is describe how to take the

05:24:24.360 --> 05:24:29.480
product of two stochastic maps in a way that generalizes the usual notion of the Cartesian

05:24:29.480 --> 05:24:43.080
product of two functions so given stochastic maps f and g

05:24:48.920 --> 05:24:50.440
we can form their product

05:24:51.400 --> 05:24:59.400
and it's another stochastic map

05:25:07.240 --> 05:25:13.800
that essentially takes the product of these two problems of the associated probabilities

05:25:13.800 --> 05:25:24.520
point-wise so it's determined by the formula f cross g now remember what our notation is

05:25:24.520 --> 05:25:29.800
for each element in the domain we get a probability distribution on the co-domain

05:25:29.800 --> 05:25:35.640
and that probability distribution is determined by what it does to points because we're working

05:25:35.640 --> 05:25:42.200
with finite sets so that probability distribution is determined by the value of our initial input

05:25:42.200 --> 05:25:49.560
with our our output and it's just the product of the associated probabilities from f and g

05:25:57.880 --> 05:26:03.560
and let's just check that make sure that this coincides with our usual definition of Cartesian

05:26:03.560 --> 05:26:07.560
product when we specify that these stochastic maps correspond to functions

05:26:08.120 --> 05:26:12.040
so if f and g are functions

05:26:15.160 --> 05:26:20.920
or how I think of them as being deterministic then this product

05:26:30.200 --> 05:26:35.240
is given by well we know what happens when these are functions then we use the the

05:26:35.320 --> 05:26:43.640
chronicle delta and this is x prime f of x while this is delta y prime g of y

05:26:46.360 --> 05:26:55.880
and this is nothing but it's the same exact thing as requiring that x prime coincides with

05:26:56.520 --> 05:27:03.720
f of x simultaneously as g as y prime corresponds with coincides with g of y

05:27:04.680 --> 05:27:09.720
and this is the usual way we think about the Cartesian product because it says what is the

05:27:09.720 --> 05:27:16.520
value of f cross g at x y well it's f of x comma g of y and this is exactly what

05:27:17.720 --> 05:27:25.400
encompasses that idea and all of the structure that we've defined so far the idea of this

05:27:25.400 --> 05:27:31.240
stochastic map it's definition how it composes the fact that functions are special cases in

05:27:31.320 --> 05:27:36.200
particular the identity function is a special kind of stochastic map it turns out that

05:27:36.200 --> 05:27:43.320
composition is associative the identity is an identity for the composition for any finite set

05:27:44.040 --> 05:27:50.040
and this Cartesian product it also satisfies the type of associativity condition

05:27:51.080 --> 05:27:59.720
and together all of this all of these data give the collection of finite sets with stochastic

05:27:59.720 --> 05:28:06.600
maps and this associated product this it gives it the structure of a symmetric minoidal category

05:28:07.880 --> 05:28:13.320
but there's another thing that we haven't yet discussed which is a notion of almost everywhere

05:28:13.320 --> 05:28:19.960
equivalence or in other words an almost surely notion of equivalence and this essentially takes

05:28:19.960 --> 05:28:26.200
care of when probabilities happen to vanish and when such a thing happens we can have a

05:28:26.200 --> 05:28:33.320
notion of equivalence between functions when their probabilities are equal versus when they're not

05:28:33.320 --> 05:28:39.880
when they're zero and so we get a very natural definition of what it means for two stochastic

05:28:39.880 --> 05:28:49.800
maps very similar to the way we define almost everywhere equivalence for functions so given two

05:28:49.800 --> 05:29:01.400
stochastic maps so I'm using different notation than what's up here so given two stochastic maps

05:29:01.400 --> 05:29:03.640
and a probability measure on x

05:29:12.680 --> 05:29:20.520
we say that f is p almost everywhere equivalent to

05:29:21.240 --> 05:29:33.240
g if and only if and the way we define equivalence is that these stochastic maps agree

05:29:34.040 --> 05:29:39.800
everywhere outside a set of measure zero so outside of events that have probability zero

05:29:40.520 --> 05:29:47.720
so the way we write that is if and only if the probability of the set of points on the domains

05:29:47.800 --> 05:29:53.400
of these corresponding stochastic maps where these two stochastic maps differ

05:29:57.960 --> 05:30:06.120
is equal to zero now what does this inequality mean now f of x and g of x are both probability

05:30:06.120 --> 05:30:14.520
measures on y so when I write that they're not equal that means f subscript y x is not is is not

05:30:14.520 --> 05:30:22.920
equal to g subscript y x for some y so this is a very intuitive notion of almost everywhere

05:30:22.920 --> 05:30:32.280
equivalence there's another sort of diagrammatic way that you can encompass these definitions as well

05:30:34.920 --> 05:30:39.080
so I'll write this as a theorem but we'll use this idea later on

05:30:39.640 --> 05:30:47.640
so it turns out that given f g and p as in this definition

05:30:54.760 --> 05:31:01.640
f is almost everywhere equivalent to g so this is the notation that we'll use if and only if

05:31:03.400 --> 05:31:08.600
the diagram now this is going to be a little bit of an interesting diagram

05:31:09.880 --> 05:31:22.200
so we're going to produce our probability on x we're going to duplicate x using the map that we

05:31:22.200 --> 05:31:31.480
introduced earlier and on each of these two factors we will apply our associated

05:31:31.640 --> 05:31:42.840
maps f and g on their corresponding terms so in this case we'll have the identity on x here cross

05:31:43.720 --> 05:31:51.640
f and here it's the identity on x cross g where this product is the one that we justified so if

05:31:51.640 --> 05:32:00.600
and only if this diagram commutes so first of all this is a very interesting statement

05:32:00.600 --> 05:32:05.880
it tells us that this notion of almost everywhere equivalence can be encompassed in some diagrammatic

05:32:05.880 --> 05:32:14.840
form and secondly if we ever discuss these in these videos we'll find out that this is very

05:32:14.840 --> 05:32:21.240
closer related to a notion of almost everywhere equivalence in a non-commutative setting where

05:32:21.240 --> 05:32:27.160
we replace our finite sets and stochastic maps with certain kinds of c star algebras

05:32:27.160 --> 05:32:33.720
and completely positive unital maps and these sorts of objects are relevant in quantum information

05:32:33.720 --> 05:32:43.000
theory okay so before we prove this we'll have a little bit of a lemma just to make the calculation

05:32:43.000 --> 05:32:54.680
a little bit easier and that lemma is the composition of two maps of two stochastic maps

05:32:54.680 --> 05:33:04.840
that are of this form so if i have a map phi from u into v and the map psi from u into v

05:33:08.120 --> 05:33:14.360
and i pre-compose with this diagonal map then this composition is given by

05:33:15.880 --> 05:33:24.360
the formula so we take phi cross psi composed with this diagonal and how do we evaluate this well

05:33:24.360 --> 05:33:30.600
the domain has a u and the codomain has a v and a w so we can evaluate it v comma w and u

05:33:31.560 --> 05:33:36.760
and the claim is that this is given by taking just the product of these where two of the points

05:33:36.760 --> 05:33:48.040
happen to match up so this is phi v u psi w u for all v u and w so the proof of this is pretty

05:33:49.000 --> 05:33:55.960
pretty easy once we have all of our definitions in place and the left hand side of this expression

05:33:55.960 --> 05:34:04.200
by definition of the composition and by using the definition of the product is equal to a sum

05:34:04.200 --> 05:34:12.200
and what's our intermediary step it's the sum over u cross u and u cross u therefore we have

05:34:12.200 --> 05:34:16.600
to sum over two elements we've already we're already using a letter u so we're going to have to

05:34:16.600 --> 05:34:22.360
introduce u prime and u double prime for instance so it's going to be u prime u double prime both

05:34:22.360 --> 05:34:33.480
elements in u and the product here is going to be phi v u prime psi w u double prime because that's

05:34:33.480 --> 05:34:42.440
the second coordinate and this is as we recall the direct the chronicle delta twice using the

05:34:42.440 --> 05:34:50.360
coordinate u and u double prime and u prime so it's u prime u delta u double prime u so this

05:34:50.360 --> 05:34:57.080
gives us two delta functions and we have a summation over those and as a result these two letters

05:34:57.080 --> 05:35:04.120
coincide so this is exactly the right hand side quick and simple proof so this is the proof of the

05:35:04.120 --> 05:35:15.400
lemma and then the proof of the theorem we'll now talk about Bayes theorem and first we'll

05:35:15.960 --> 05:35:21.320
state the theorem given a probability distribution on x

05:35:21.720 --> 05:35:34.120
and a conditional probability from x to y call it f so it's the stochastic map

05:35:39.000 --> 05:35:48.280
there exists another map going in the opposite direction let's call it g such that

05:35:48.760 --> 05:35:50.760
the diagram

05:35:53.720 --> 05:36:00.760
now the diagram looks a little bit complicated but it's not too bad when we write out the equation

05:36:00.760 --> 05:36:08.760
we'll see exactly what it means so here we'll have p and here notice we can compose p with f

05:36:08.760 --> 05:36:10.760
to get another probability distribution

05:36:11.240 --> 05:36:21.720
on y and we'll call that q so we have our probability distribution on x on one on y we duplicate x

05:36:25.560 --> 05:36:31.880
we duplicate y this almost reminds me of the definition of a equivalence

05:36:32.680 --> 05:36:42.520
x cross y and here we will apply the only maps we can and to go from x to y we apply f

05:36:45.000 --> 05:36:47.160
and to go from y to x we apply g

05:36:49.800 --> 05:36:52.200
so the statement is that this diagram commutes

05:36:54.440 --> 05:36:55.560
and furthermore

05:36:56.360 --> 05:37:05.320
for any other stochastic map that also goes in the opposite direction let's call it g prime

05:37:07.960 --> 05:37:08.920
satisfying this

05:37:14.600 --> 05:37:22.920
then these two maps are q are almost everywhere equivalent and in the sense of our probability q

05:37:26.440 --> 05:37:32.200
so this is the formal statement of Bayes theorem and if you've seen if you've seen Bayes theorem in

05:37:32.200 --> 05:37:38.840
a different context this may seem totally strange but let's just see exactly what it says

05:37:43.320 --> 05:37:46.360
when we look at the composition of all of these arrows

05:37:48.440 --> 05:37:51.480
we've actually computed expressions just like this if you remember

05:37:52.040 --> 05:37:55.960
the this left hand side when we were doing the notion of almost everywhere equivalence

05:37:55.960 --> 05:38:01.160
in that diagrammatic perspective we computed something I think it may have been exactly

05:38:01.160 --> 05:38:06.040
this expression actually so commutativity says

05:38:06.120 --> 05:38:21.480
says that f y x times p x equals and if we did that same calculation but on the right hand

05:38:21.480 --> 05:38:26.760
side of this diagram it looks almost the same it's just that the g is on the other side nevertheless

05:38:26.760 --> 05:38:34.760
we still get g x y q y and this holds for all x y

05:38:36.280 --> 05:38:44.680
of course x is an x and y is in y now let's introduce some notation to see how to understand this

05:38:46.920 --> 05:38:56.200
let's define p of y given x so this is the probability of y given x to be exactly f y x

05:38:58.600 --> 05:39:01.720
that's exactly what f means f is this stochastic map it says

05:39:02.440 --> 05:39:07.240
it's not corresponding to a function it says if you give me x I will give you y with

05:39:07.240 --> 05:39:12.760
some probability the probability is exactly f y x so that's exactly what this conditional

05:39:12.760 --> 05:39:23.560
probability is and the probability of x is just little p x the conditional probability of x given

05:39:23.560 --> 05:39:29.480
y now this is going in the opposite direction it says if you give me y what's the probability of x

05:39:29.480 --> 05:39:40.120
occurring that's exactly g x y and finally the probability of y occurring is q y and so if we

05:39:40.120 --> 05:39:46.520
write down these expressions commutativity is of this diagram says nothing but the probability of

05:39:46.520 --> 05:39:54.360
x given y times the probability of x is equal to the probability of y of x given y times the

05:39:54.360 --> 05:40:01.560
probability of y which is perhaps a slightly more familiar form of base theorem at least when

05:40:01.560 --> 05:40:08.120
your events are singleton sets and with the appropriate definitions you can also extend this

05:40:09.080 --> 05:40:13.240
you can look at what this diagram means because these are corresponding to probability measures

05:40:13.240 --> 05:40:19.720
and you can also define a notion of conditional probability where you replace this point with

05:40:19.720 --> 05:40:25.240
a subset and you can use the probabilities on your corresponding spaces to make sense of what

05:40:25.240 --> 05:40:31.320
this means when x is replaced by some event a perhaps and y is replaced by some event b

05:40:31.960 --> 05:40:36.280
nevertheless the same equation still follows from commutativity of this diagram

05:40:37.480 --> 05:40:44.200
so let's look at our earlier example just to see what this is saying and how to interpret it in

05:40:44.200 --> 05:40:53.960
sort of a real-life situation so if you remember we had x and y two sets with each of which contains

05:40:53.960 --> 05:41:04.920
two elements and x corresponded to the set where there's a good sale and the other element was

05:41:04.920 --> 05:41:12.440
not a great sale not good sale and y is the set of elements the set containing the elements

05:41:12.440 --> 05:41:20.200
i go to the store the grocery the grocery store or i don't go

05:41:24.040 --> 05:41:28.920
and we also had probabilities on each of these spaces and we also knew the probabilities that

05:41:28.920 --> 05:41:34.440
if there's a good sale how likely am i to go right that was nine nine ninety percent so ninety

05:41:34.440 --> 05:41:44.360
percent if good i go with ninety percent probability and if not good then i still go

05:41:45.240 --> 05:41:54.120
but with sixty percent chance and likewise the other probabilities are given by the fact that

05:41:54.120 --> 05:41:59.080
it's one minus this one minus this and we also know the probability of there actually being a good

05:41:59.080 --> 05:42:04.920
sale so we know what p of good sale is and the probability is thirty percent and the probability

05:42:04.920 --> 05:42:13.000
of a not good sale is therefore seventy percent so we have all of this information now imagine you're

05:42:13.000 --> 05:42:20.200
in that store this particular week and you happen to see me there so in that case you happen to know

05:42:20.200 --> 05:42:28.520
i'm already at the store then you can ask what is the probability that there's a good sale this week

05:42:28.520 --> 05:42:33.560
given the information that you see and knowing this information as well so initially you also

05:42:33.560 --> 05:42:38.680
know the statistics that says the if i look over the entire year the probability that there's a

05:42:38.680 --> 05:42:43.960
good sale is thirty percent but you also know that i'm more likely to go to the store if there is

05:42:43.960 --> 05:42:48.680
a sale so if you see me then there might be a better chance that there's a sale this week

05:42:50.040 --> 05:42:54.840
and how do you figure that out well if we look at this expression and we

05:42:55.800 --> 05:42:58.440
compare these two sides then

05:43:00.840 --> 05:43:05.480
we can say that f corresponds to the if there's a good sale versus if there's not a good sale

05:43:05.480 --> 05:43:12.120
how likely am i to go or not as f y x and the probability that there's a good sale

05:43:12.120 --> 05:43:21.320
is p x and if we wanted to know so let's say g is on the other side so g of x given y so this says

05:43:21.320 --> 05:43:27.080
if you see me at the store so here this element y is i'm at the store

05:43:31.480 --> 05:43:34.440
and x is there's a good sale

05:43:38.680 --> 05:43:42.280
so if you see me at the store what's the probability of there being good sale

05:43:42.280 --> 05:43:50.680
and we divide that by q y which we've already determined last time so q y was the probability

05:43:50.760 --> 05:43:52.520
that i went to the store

05:43:59.240 --> 05:44:03.080
and we know that that equals the sum of the product of the probability of

05:44:03.080 --> 05:44:05.560
if there's a good sale i go and if there's not a good sale i go

05:44:06.440 --> 05:44:10.840
multiplied by the corresponding probabilities corresponding to here and we found that to be

05:44:10.840 --> 05:44:20.040
69 percent so in this case this equals 90 percent 30 percent divided by 69 percent

05:44:21.080 --> 05:44:27.960
and when you write out what this equals it's roughly approximately equal to 39 percent

05:44:29.080 --> 05:44:32.920
so you've updated your hypothesis based on what you see

05:44:33.880 --> 05:44:39.880
and this is known as Bayesian inference

05:44:43.320 --> 05:44:51.880
or inversion inversion and in fact the map g constructed here

05:44:55.000 --> 05:44:57.160
a g from Bayes theorem

05:44:57.560 --> 05:45:08.840
is called a Bayesian inverse

05:45:12.680 --> 05:45:16.200
of f and it would be a little bit inappropriate to say

05:45:16.760 --> 05:45:23.160
that it only depends on f because it also depends on your prior probability distribution p

05:45:23.400 --> 05:45:34.040
so this is an interesting reformulation of Bayes theorem that seems to be totally in the

05:45:34.040 --> 05:45:41.720
language of category theory and it therefore makes it amenable to a wide range of techniques

05:45:41.720 --> 05:45:47.160
that could be used to analyze and understand it and perhaps even generalize this idea to other contexts

